analyzing user perspectives on mobile app privacy at scale preksha nema google bangalore india preksh google.compauline anthonysamy google zurich switzerland anthonysp google.com nina taft google mountain view usa ninataft google.comsai teja peddinti google mountain view usa psaiteja google.com abstract in this paper we present a methodology to analyze users concerns and perspectives about privacy at scale.
we leverage nlp techniquestoprocessmillionsofmobileappreviewsandextract privacyconcerns.ourmethodologyiscomposedofabinaryclas sifier thatdistinguishes between privacyand non privacy related reviews.weuseclusteringtogatherreviewsthatdiscusssimilarprivacy concerns and employ summarization metrics to extractrepresentative reviews to summarize each cluster.
we apply ourmethods on 287m reviews for about 2m apps across the categories in google play to identify top privacy pain points in mobile apps.
we identified approximately 440k privacy related reviews.
wefindthatprivacyrelatedreviewsoccurinall29categories with someissuesarisingacrossnumerousappcategoriesandotherissues only surfacing in a small set of app categories.
we show empirical evidence that confirms dominant privacy themes concerns about apps requesting unnecessary permissions collection of personal information frustrationwithprivacycontrols trackingandtheselling of personal data.
as far as we know this is the first large scale analysis to confirm these findings based on hundreds of thousands of user inputs.
we also observe some unexpected findings suchas users warning each other not to install an app due to privacyissues users uninstalling apps due to privacy reasons as well as positivereviewsthatrewarddevelopersforprivacyfriendlyapps.
finally we discuss the implications of our method and findings for developers and app stores.
keywords privacy nlp mobile apps empirical acm reference format preksha nema pauline anthonysamy nina taft and sai teja peddinti.
.
analyzing user perspectives on mobile app privacy at scale.
in 44th internationalconferenceonsoftwareengineering icse may21 pittsburgh pa usa.
acm new york ny usa pages.
.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
icse may pittsburgh pa usa association for computing machinery.
acm isbn ... .
introduction in app stores such as google play and apple s app store users can write reviews to share their experience and opinions about the appsthattheyuse.reviewshelpotheruserstounderstandwhether or not the app might be of interest to them.
these reviews are also a feedback channel to developers whocan learn how toimprove theirapps.appreviewscanbeachallengetoanalyzeastheyare knowntocoverabroadrangeoftopics havewidelyvaryingquality that is somewhat exacerbated by their unstructured form thusitcanbedifficultfordeveloperstoparseoutseparateissues.
moreover some issues such as privacy related feedback may have lowervolumethanotherissues e.g.
batteryperformance andthus maybelessvisible.however e xtractingprivacyrelatedfeedback is of particular importance as by now developers are well aware thattrustisheavilyimpactedbytheirprivacyposture andbecause privacy legislation and regulation are on the rise.
unstructured app reviews provide a potentially rich source of contenttolearnaboutusers perspectivesonprivacy.userfeedback canbeminedatscaletoextractproductrequirements howeverthesemethodsdonotfocusonprivacy.traditionalmethods forgaining insightsintouserperspectivesaboutprivacy include conductingqualitativestudiesandsurveys.qualitativestudieshave theadvantageofbeingindepthastheyinvolveone on oneinterviews however they are limited in scale to include typically participants.
surveys on the other hand have the advantage being structured and repeatable however are also limited in terms of scaletypicallytoafewthousands.byleveragingautomationand advancednaturallanguageprocessing nlp techniques feedback by millions of users can be analyzed rapidly to extract privacy perspectives.thisapproachcomplementsexistingqualitativemethods as it obtains privacy concerns on a new scale yet cannot follow up withusersforadditionalinformation.ourapproachenablesdata drivendecisionstobemade suchaspriorityrankingacrossmultiple issues.
we therefore answer the following research questions canmobile app reviewsbe automaticallyanalyzed atscale to identify privacy related ones?
can the identified privacy reviews be used to understandusers privacy concerns?
how do they compare with concerns inferred from other qualitative methodologies?
how can such a methodology be leveraged to inform the ecosystem and more specifically mobile app developers?
thispaperpresentstwomaincontributions.thefirstisamethodology to analyze user s privacyconcerns with mobile apps via nlp ieee acm 44th international conference on software engineering icse icse may pittsburgh pa usa preksha nema pauline anthonysamy nina taft and sai teja peddinti techniques atscale.the methodologyincludes abinary classifier to decide whether or not a particular review discusses a privacy topic a mechanism to cluster reviews that discuss similar semantic topics and a way to summarize the clusters by identifying reviews that are highly representative of all those belonging to a single cluster.ourmethodologyopensthedoortoarichsetofsubsequent research on user privacy perspectives e.g.
relative ranking of privacy concerns how these concerns evolve over time why some privacy issues occur predominantly within specific app categories userperspectivesondifferentelementsofpersonaldata etc .italso enables tools for developers to receive feedback thatcan help them improve the privacy of their products.
oursecondcontributionusesthemethodologytoprovide empiricalevidence afirst large scale analysis thatconfirmsdominantprivacythemesthathavebeenidentifiedinqualitativestudies .we applyourmethods to287mreviews and report on the wide variation of privacy reviews across app categories relativereviewingofspecificapppermissionsanddominant privacy themes.
we also discuss the implications of our findings fordevelopersandhowtheycaninformthedesignofprivacytools in app stores.
there are many challenges to this problem space.
first there is no labeled data.
second the boundary of when a text is about privacyornotisafuzzyone forexample manysecurityandprivacyexpertsoftendonotagreeontheamountofoverlapbetweenthesetwoareas .third weneedtobeabletocaptureabroadrange ofprivacyconcerns i.e.
anytopicthatexistsinestablishedprivacy taxonomies .fourth tolearnabroadrangeofcontexts we need a classifier that can do more than memorization of keywords.
fifth userreviewsarewellknowntobevariableintheirwriting style which can lead to classification errors.
we address all these challenges herein.
ourfirstcontributiondevelopsamulti stepmethodtoaddress this problem.
to generate our test validation and training data we employamethodthatcombinesexpert hand labelingandheuristicsupervision challenge .inthisbootstrappingprocess weconstructasetofregularexpressionsinconsultationwithlinguisticexperts andbasedonourmanualobservationsofhowusers express privacy concerns in reviews challenge .
we next developaprivacyclassifierasanensemblemodelthatcouplesboth use andbert deeplearningmodels whicharetrained onusertextsandareknowntogeneralizewell challenge .
our classifier achieves precision and recall.
we use k means clusteringto groupsimilar privacy reviews and propose anewmetrictodetermineagoodvalueof kthatproducescompact single issueclusters challenge .wesummarizethetopicclusters by extracting representative reviews for the cluster.
overall thisyieldsanewmethodtounderstanduserinsightsaboutprivacy that complements traditional qualitative methods.
the development of automated privacy text classifiers for user text and the ability to separate privacy issues into distinct clusters in an unsupervised fashion enables numerous types of large scale analyses including some of which are discussed in this paper rankingofissues breadthofconcernsacrossapptypes unanticipated and emergingissues sentiment with which usersapproach specific issues user behavior e.g.
uninstalling an app comparisonsacrossapptypes e.g.children sversusregularapps issuesper culture as captured by language and more.
we discuss how suchfindingscaninformdevelopersaboutprivacyshortcomings of their apps and more generally how it could inform privacy best practices across app stores.
oursecondcontributionisalargescaleanalysisusingourmethodology on 287m reviews coming from approximately 2m apps from theplaystore.weidentifyapproximately440kreviewsthatdiscuss privacy.
we found that the privacy related reviews exist in all ofthe app categories 1in the play store and that these reviews capture a breadth of privacy concerns and perspectives.
we find manyreviewswhereusersasktoknowthepurposeforarequesttocollectpersonalinformationorpermissiongateddata e.g.
location contacts camera etc .weobservedfoursomewhatunexpectedfindings users warn each other not to install an app due to privacy reasons users uninstall apps due to privacy concerns users concerns about the selling of personal data are largely confined to a small set of app categories and some users reward developers whose apps are privacy friendly with privacy positive reviews.
we apply our clustering and summarization to ten categories of apps and identify the large compact clusters within each cat egory.
from these we identity five dominant privacy concerns acrossmultipleappcategories apps thatappeartorequestunnecessary permissions collection of personal information tracking privacy controls and apps that may be selling personal data.
next we present an overview of these dominant themes using our automaticallyselectedrepresentativereviewsthatsummarizeeach cluster.
whilethe dominant privacythemes that emerged fromour analysisaregenerallywell known wedemonstratetheabilityto automateandscalethisprocess.ourinitialfindingsillustratethe potential of such automated analysis.
we conclude the paper with a discussion on implications for developers and app stores limitations and a summary of remaining challenges needed to further mature this type of analysis.
related work theprimaryuseofnlpintheprivacyspaceinthelastfewyears has been to analyze privacy policies .
numerous efforts have focused on identifying inconsistencies between an application s source code and its privacy policy or it s description .
other uses include developing privacy chat bots and automated questionanswer systems based on deep learning techniques to help usersunderstanddatapractices.in theauthorsexploretheuse of nlp to help users avoid inadvertently sharing personally identifyinginformationinsocialmedia emails andtextmessages.in the authors used nlp to analyze app description texts within alarger mechanism to determine when two apps are similar this was used to inform developers when they may be requesting an unnecessary permission.
none of these privacy oriented studies applied nlp to analyze the text in user reviews.
user reviews have been analyzed using nlp but not in the context of privacy.
pagano and maalej conducted an empirical analysis of ios app reviews and found that reviews are not easy to automatically analyze given their unstructured forms.
some efforts have built classifiers to identify informative app reviews o r 1due to space limitations the full list of apps has not been included in this paper.
113analyzing user perspectives on mobile app privacy at scale icse may pittsburgh pa usa reviewsusefulforappmaintenance othersidentifiedinconsistencies between user reviews and ratings as well as performed topicanalysisofnegativereviewstoshedlightonwhyusersdislike a given app and unsupervised topic discovery composed of semantically similar user comments based on bidirectional nlp algorithms workhasalsobeendonetoautomaticallymatch bug reports with related app reviews .
in the requirements engineering space there have been large bodies of work that focusedonfeature requirementsextractionfromuserreviewsand or applied a sentiment analysis to find out how users like a certain feature .
developed a review summarization framework to categorize app reviews into categories e.g.
bug reports andfeaturerequests andalsoextractsaspectsandtheirsentiments e.g.
interface is good poor .
tian et.al.
have shown that including crowd sourced review information in app update notifications was moreeffectiveatalertingusersofinvasiveormaliciousappupdates especially for less trustworthy apps .
the prior research that is closest to ours is .
besmer et al.
have trained a logistic regression model to detect privacy app reviews and have shown that privacy reviews have lower star ratings and more negative sentiment but have higher engagement more upvotes downvotes .
in both the authors developed a svm classifier to extract reviews from the play store on the two topics of security and privacy.
the key purpose of was to determine if app reviews discussing security and privacy lead to changesintheapp and focusedonhowactualappbehavior influences users security and privacy concerns.
using static code analysis the authors in were able to demonstrate that the presence of security and privacy reviews are predictive of security and privacy app updates in of the cases they looked at.
thisisveryencouraging asitmeansdevelopersdorespondtoissues raised in these types of reviews.
as part of that work the authors had to develop a security and privacy review classifier to extractthosereviews.theauthorsin usedynamicanalysistoshow userssecurityandprivacyconcernsarejustifiedinthattheapps do often exhibit troublesome behavior along the lines indicated in reviews.
our work differs from these efforts in several ways.
first our focus is on privacy not security and privacy combined.
we acknowledgethatsecurityandprivacyareinterwoven attimes especially when security issues such as account hacking or password management have privacy consequences .
second their classifiers relyonabasicsvm logisticregressionmodelsandfollowabagof wordsapproach.weusestateoftheartdeeplearningbasednlp models e.g.
use and bert that offer multiple advantages.
these transformermodelsaretrainedonlargecorpusesoftext e.g.
bertistrainedonwikipedia andthusthesemodelshavethepotentialtogeneralizebeyondthelabeledexamples.asexplainedmorefullyinsection3.
.
abag of wordsapproachislikelytomisscontext and that matters for identifying privacy related reviews across a broad setofprivacytopics.third weworkwithalargerdataset.weman uallylabeled11kexamples comparedto2.4kin 4kin and 6kin .weranourinferenceanalysison287mreviews.fourth our method incorporates clustering and summarization whereas these prior efforts only included classification.
this is needed sinceourendgoal toprovideawaytoreportusersperspectivesatscale is different.thereisanenormousbodyofusablesecurityresearchonuser perceptionstowardsmobileappprivacy.mostquantitativework have found that people are very protective of their personal informationwhenusingapps andactivelyengagewithoffered privacy controls to safeguard their information .
userfrustrationduetoappsrequestingunnecessarypermissions has been well studied .
in fact users were often surprised by the abilities of applications to collect data inthe background and were concerned with possible risks associated with permissions .
special attention has been on studying the privacy concerns arising due to users location being tracked .
thesepriorstudiesrevealsimilarprivacyconcernsthatweobserve in our research.
however they are all done by surveying few hundredparticipantsorinterviewing30orlessparticipants.our methodologyscalesuptolargenumbersofuserreviewsandtracks theseissuesefficientlyacrossallapps andourfindingsshowthe prevalence of specific privacy concerns across app categories.
methodology figure illustrates an overview of our approach.
on the left are examplesofreviews someofwhichareaboutprivacyandoneof whichisnot markedinyellow .ourfirsttaskistoextractthose reviewsthatarerelatedtoprivacy.thisisachievedbyconstructing a binary classifier to distinguish between the privacy and nonprivacyreviews.infigure1 thereviewabouttakingpictureshas beenfilteredoutinthesamplelistof privacyreviews .oursecond task is to identify the common fine grained privacy themes within the privacy relevant app reviews.
for this we leverage k means clustering k isaparameterthatneedstobechosenupfront andwe proposeacustommetrictochoosethebestvaluefor k .weusethe tensorflow machinelearningtoolfortrainingabinaryclassifier and clustering the privacy related app reviews.
in the following sections wedescribehowwegeneratetest validationandtraining data presentthedesignofourprivacyclassifier anddescribeourmethod for clustering and summarizing privacy related reviews.
.
dataset curation in order to develop test validation training and inference datasets wecollectedapproximately580mplayreviewsinenglishpublished ontheplaystorebetweenapril2014andfeb2020.ourdatasetwasanonymizedintermsofappnames aseachreviewwasonlylabeled by its app category however we were given an aggregated appcount of 2m.
we started with zero labeled data.
as per the manymethods for generating labeled data as outlined well in we use expert hand labeling by subject matter experts for our test and validation datasets to ensure these are of the highest qualitysince they are used to evaluate the performance of our machine learning models.
prior work hints that privacy related reviews mayconstitutelessthan1 ofallreviews hencewewerefacing an extremely imbalanced dataset.
to bootstrap this procedure and generatecandidatereviewsthatarelikelytobeaboutprivacywedidthefollowing.wereliedontwowellknownprivacytaxonomies tosettheframingforourinitialdefinitionandscopeofprivacy issues.
we curated an initial seed list of n grams inspired by these taxonomies.
our manual labeling team consisted of the authors 114icse may pittsburgh pa usa preksha nema pauline anthonysamy nina taft and sai teja peddinti figure method pipeline.
and three linguists.
we filtered reviews based on this initial seed and conducted a preliminary manual evaluation.
we looked to see the types of words and expressions that users employ to express privacy concerns.
there were two observations in this bootstrapping phase.
first filteringusing1 gramand2 gramwordscanresultinmanyfalse positives forexample thesingleword trust canbeusedin don t trust your teammates which is not a statement about privacy.
thus we decided to only use n grams with n for further filtering.
second we converted our seed list of n grams to regular expressions and expanded the set of expressions based on this manual exploration.
regex patterns allow us to succinctly capture grammaticalvariantsoftypicalprivacystatements.foreveryregex pattern we checked to see if it occurred in at least reviews thatwereprivacy related.ourregexescapturedapproximately200 n grams.weacknowledgethatourlistmaynotbecompleteand mighthavemissedprivacyissuesorphrasesusedtodiscussprivacy.
we next selected 11k app reviews for manual labeling.
to ensure we ended up with enough labeled privacy examples we selected of the 11k reviews because they matched against our regexpatterns andtheother40 wereensuredtonotmatchanyof the regexes.
each of the 11k reviews were manually examined and cross labeledbythreeratersandalabel privacyornotprivacy was assigned.
for the vast majority of reviews all three labelers agreed.
when this was not the case discussion ensued until an agreement was reached.
among the manually labeled reviews ground truth 6688were labeled as privacyand4683werenot privacy.
the validation dataset used to evaluate the performance of the ml models after each training epoch was created by extracting privacyand250notprivacy reviewsfromthisset.theremaining reviews were treated as the test set for comparing the performance of different privacy classifiers.
because each of our regexes capturing n grams was verified bycheckingforitsappearanceinatleast100privacy related reviews andalsobasedonourmanuallabelingexercise weas sume our regex list effectively constitutes a set of good qualityheuristics.
we use these to generate our training data as per themethod of heuristic supervision as in .
we used roughly half of the reviews 290m to generate training samples.
from this set we identified 250k app reviews that matched our privacy regex patterns and labeled them as privacy related reviews we then randomlysampledanother250kreviewsthatdidnotcontainanyof our privacyregexes and labeledthem as not privacy.
ourprivacy regexpatternscouldonlyidentify0.
ofreviewsasbeingrelatedtoprivacy.finally weusedthesecondhalfofourcollectedreviews namely 287m reviews as our inference dataset.
we performed classification clustering and summarization on this set to understand users top privacy concerns.
the sizes of our training validation and test datasets are shows in table .
table size of data sets datasets training validation test privacy not privacy ethicalconsiderations ourinstitutionapprovedtheuseof this dataset because play reviews are already public.
in compliance with ethical training guidelines in our institution we ensured that users privacywererespected.wethuscarriedoutthefollowing.
first allresearchershavebeentrainedinethicaluserresearchprior to this study.
second the dataset was preprocessed to remove user identifiersandappnamesbeforetheresearchersweregivenaccess.
the only accompanying metadata beyond the review text was the app scategorynameandthepublishtimestamp.third accessto this version of the dataset is limited to the authors of this paper.
.
privacy classifier the simplest approach to extract privacy related reviews might be viaakeywordlist.however itisnon trivialformultiplereasons to curate a comprehensive list of keywords.
in addition to the falsepositiveissuediscussedinsection3.
thesamewordcould mean different things depending on the context.
for example the occurrence of invading in a war game app review likely does not refer to a privacy concern whereas it might in a review about a parental control app with a location tracking feature e.g.
this app isinvadingmyprivacy .moreover therecouldalsobeinstances whereareviewdoesnotcontainprivacykeywordsbut basedon its context still be related to privacy.
for instance don t want my friendaccessingmyemail doesnotcontainanyprivacyspecific keywords but is a privacy concern based on the context.
traditionalapproachestoanalyzetextrelyonthebag of words representation or use word embeddings such as word2vec andglove toencodetext.suchsystemsdonotencodeinformationaboutthewordsequence andthereforecannotdifferentiate between reviews containing the same words in different order.
for example deletecookiesandwebsitehistory and myarticleon historyofcookies gotdeletedfrom website use samewords but 115analyzing user perspectives on mobile app privacy at scale icse may pittsburgh pa usa have different meanings.
in addition to handling context and word sequence we also need to be able to correctly process reviews that are frequently unstructured contain highly variable writing styles grammatical errors and misspellings.
theabovelimitationsestablishtheneedtoprocessreviewsbyincorporatingrobustnlunderstandingcomponents.inthiswork we usestate of the artpre trainednaturallanguagemodels bert anduniversalsentenceencoder use toefficientlyencode user reviews into an abstract representation.
these models are betterknowntocapturecontexts.weprovidehereabriefbackground on the bert and use language models.
bert bidirectional encoderrepresentationsfrom transformers bert isalanguagerepresentationmodelbasedonthetransformerarchitecturethathasbeentrainedon3.3billionwordcorpus.
themodelwastrainedontwotasks maskedlanguagemodelling where the aim is to predict the masked out words of the input text using the information present in the surrounding words and next sentenceprediction wherethemodelpredictsthenextsentence giventhefirstsentenceastheinput.thelargepre trainedbert neural network model has had great success in nlu tasks such as text summarization question answering and has been shown to deliver impressive performance on downstream tasksevenwhenworkingwithsmalltrainingdatasets .hence we fine tune the pre trained bert model on our training set to create a binary privacy classifier.
use universal sentence encoder is another deep neural networkbasedmodel thatusesencoders transformer based or deep averaging networkbased tolearnmeaningfulsentence representations .
the model is trained on data from various sources such as wikipedia discussion forums web questions and answers etc.
andhasshowngreatperformanceindetectingfake newsspreadersontwitter andinlearningcross lingualtext representations .
unlike bert we do not fine tune the use model instead use the readily available pre trained use tf hub module2 which provides text embedding representations directly and build a two layer feed forward neural network on top for creating our privacy classifier.
.
.
models.
we propose the following four model variants as candidates for our privacy classifier.
vanilla bert we take the pre trained bert model and add one additional network layer after the last layer for binary classification.
we usea token start of sentence to represent each review in its entirety.
thus our additional layer simply transforms theembeddingslearntforthe tokentothetwoclasses i.e.
privacyandnotprivacy.wefine tunethebertmodelonourtraining data for three epochs and choose the best epoch model based on the performance on the validation dataset.
sentiment awarebert bert sst fromapreliminaryanalysis we foundthatthe privacyreview textsgenerallyhave anegative sentiment.
we use this information to further strengthenour bert based privacy classifier by first fine tuning bert for sentimentclassificationtask.usingsimilarmodelarchitecturementioned above for vanilla bert we first train the model on a textsentiment dataset stanford sentiment treebank3 that contains and its binary positive or negative sentiment label.
we then fine tune this model on our training data to create the privacyclassifier.
we simply map the privacy class to the negative sentimentclass andnot privacytothepositiveone.wefine tunethe sentiment awarebertmodelforthreeepochsandchoosethebest epoch model based on the performance on the validation set.
use we extract a new dimensional embedding representationforeachreviewbypassingthereviewsthroughthepre trained use model that is based on deep averaging network encoder.
we thenpasstheembeddingthroughafeed forwardneuralnetwork with2layersand512hiddenunitseach.theoutputofthe2ndlayer isthenmappedtothetwoclasses i.e.
privacyandnot privacy.the model is trained with the objective to maximize the probability of the correct class and thus we use cross entropy loss to optimize the network.we trainthe modelfor 20epochs andchose thebest model based on performance on the validation set.
ensemble model in our experimentation we noticed inconsistentlabelassignmentsbyeachofthethreeprivacyclassifiersabove.
thisisunderstandableastheunderlyingbertandusemodelsare pre trainedondifferentdatasetswithdistinctcharacteristics.
to better understandthescenarios where useandbert modelswere makingdifferentdecisions privacyornot privacy wemanually examined about reviews that had different labels from the twomodels.belowisanexampleofastatementthatuseclassified asprivacywhereas bert labled it not privacy.
you can record call automatically record anonymous calls recordimportant calls... youcan choose thephone numbers in thephonebookorrecordingcallautomatic.thelistofrecordedfileswillbe stored and streamlined for you in the phone call recorder.
the following is an example of a review that bert predicted as privacy whereas use did not.
nothavingtamilchannelsandsportschannelswhichistheway of looting the trust from the customer service the first example is ambiguous as making anonymous phone calls could be perceived as being related to privacy.
however this review mainly lists app features.
the second example mentions trust however this isn t a privacy issue but instead perhaps one of feeling excluded due to a language not supported in the app.
we wouldn t consider either of these to be about privacy.
toreducesuchambiguitiesandimproveourconfidenceinthe privacyreviewidentification our ensemblemodel considersa review to be about privacy if and only if all three classifiers use bert and bert sst labeled it as privacy.
note that this makesour model conservative i.e.
we will underestimate the numberof privacy reviews since we are choosing to focus on precision ratherthanrecall.forourpurposesofbroadlyunderstandingusers privacy concerns with mobile apps we prefer to have less noise in ourclusters.weacknowledgethatadeveloperusingsuchamethod may opt for high recall to be sure not to miss any particular issue.
.
.
performance of models.
we evaluate our four privacy classifiermodels seetable2 onthetestdataset.highrecallnumbers indicate that the model is able to correctly identify most of theprivacy related reviews and a high precision indicates that the modelrarelylabelsanot privacyreviewasbeingrelatedtoprivacy.
fromthetable weseethattheusemodelhasahighrecallanda 116icse may pittsburgh pa usa preksha nema pauline anthonysamy nina taft and sai teja peddinti table performance of models tested modelaccuracy precision recallf1 scoreauc use .
.
.
.
.
bert .
.
.
.
.
bert sst .
.
.
.
ensemble .
.
.
.
.
relativelylowprecision meaningthatithasmorefalsepositives not privacyreviewslabeledasprivacy .ontheotherhand both thebertbasedmodelshaveahigherprecisionbut lowrecallcomparedtouse.thebert sstmodelhashigheraccuracythanbert but looking at the f1 scores vanilla bert model performed better thanbert sst.asexpectedtheensemblemodelhasthehighest precision it also obtains the highest auc value and a good f1score.
we use thus the ensemble model in the remainder of this work for our classification task.
wedidaqualitativeanalysistoseeifourensembleclassifierwas able to generalize its learning beyond the terms and expressions in our regex patterns.
first we checked to see if our classifier learned anyconceptsnotincludedinourregexpatterns.forexample we didnotincludeanytermsrelatedto anonymity or anonymous in our regexes however we did find a number of reviews that mention iliketheanonymity... .ourmodellikelylearnedthatthe words related to anonymous are often associated with privacy because of the following.
the following real review i don t want a personalized profile full of surveillance.
anonymous access is a preferred couldhavebeenflaggedasprivacybecauseoftheword surveillance that was in our regexes .
since this review also containstheword anonymous theclassifierlearnstoassociate thiswiththeprivacylabel givenenoughsimilarexamples .second wecomparedthefractionofprivacyreviewsthatourregexesalone match .
inthe290mreviewsusedtogenerateourtrainingdata section3.
withthoseextractedbyourclassifier namely .
from our 287m reviews test data .
this shows that our classifier doesgeneralizebeyondthetermsandexpressionsintheregexesas it identifies roughly twice the amount of content as our regexes.
.
clustering and summarization thenextstepinourpipelineisclusteringandsummarizationofthe privacy related reviews to tease out the different privacy concerns users describe.
we know from prior work as well as our curatedset of n grams there are a multitude of things users might write about suchaspersonaldatacollection privacycontrols location tracking a feeling of being spied on third party data sharing new privacy features consents etc.
we refer to these as privacy themes.
since app reviews do not have fine grained labels for such privacy themes weuseunsupervisedlearning specificallyclustering to identify the common privacy issues.
we use k means clustering as ourapproachtoclusteringbecauseitissimpleandbroadlyused and leave exploration of other clustering solutions as future work.
weapplyk meanstothesetofprivacyreviewsperappcategory games parenting tools etc .
the motivation for studying categories independently is that the number of reviews across appcategories was highly variable ref table .
analyzing all the reviews together would have not highlighted users concerns in apptable3 number proportionofprivacyreviewspercategory app category total of proportion of reviews privacy reviews dating .
parenting .
house home .
communication .
maps navigation .
tools .
health fitness .
medical .
weather .
auto vehicles .
social .
events .
photography .
libraries demo .
entertainment .
beauty .
art design .
finance .
personalization .
music audio .
shopping .
games .
sports .
comics .
lifestyle .
travel local .
productivity .
food drink .
news magazines .
categorieswithlowernumbersofreviews.analyzingthecategories independentlyhelpedusidentifyissueswhichmaybeprominent in one category but not in others e.g.
tracking and selling data was not a key concern in the games category .
once these clusters are determined we summarize the topic discussedinaclusterbyselectingsomehighlyrepresentativereviewsforeachcluster.afterindependentlyreviewingthetoprepresentative reviews and labelling the clusters in each category we performed a second round of annotation where we cross checked the cluster labels across categories and mapped clusters discussing the same concerns to the broader topic.
k means clustering we use the dimensional use embedding generatedfor each review toperform clustering.
we use embeddingsderivedfromouruse basedmodelinsteadofbert based models as it lead to a higher auc score refer table .
the clus tering is performed within an app category and cosine distance isusedasthedistancemetric.likeanyotherclusteringtask the challengehereis howtodetermineagood kvalueforthenumberof target clusters without knowing ahead of time how many distinct themes users may be writing about.
there exist various metrics in theliteraturetochoose k suchasthesilhouettescore dunn index ch score etc.
these metrics primarily reward well separatedandcompactclusters whichisalsoourgoal.however these metrics implicitly assume the following a sample belongs toonlyone cluster oronlybelongs tooneprivacytheme and all samples belong to some cluster i.e.
no sample is considered to beanexceptionoroutlier.forprivacyrelatedplayreviews these assumptions do not always hold.
consider this example 117analyzing user perspectives on mobile app privacy at scale icse may pittsburgh pa usa 1starforforcingpeopletocreateanaccount.noit snotnecessary fortheuser.it sapparentlynecessaryfor .
permissionstheydemandaren tnecessaryandinvasive.thisapp ismorelikespyware.clearly ismaking money off of people s personal and private information.
i don t recommendthisproduct.atminimum ifyou regoingtousethis app give them fake information.
however they won t even let you usetheappifyoudon tgivethemlocationtrackinginformation.
undoubtedly they ll be another company in the news soon for exploiting customer privacy.
thisexamplereviewtouchesonmultipleprivacythemes including unnecessarypermissions spyware locationtracking andgeneral privacy exploitation.
there is potential that each of these finegrained topics produce its own cluster when running k means so this example review would be hard to place within one cluster as itmightnaturallybeontheborderofmultipleclusters.therefore we aim to limit the influence of such reviews on the cluster formation by optimizing for the creation of well formed clusters clusters thatpredominantlydiscussasingleprivacyissue.thenextexample illustrates the second assumption iwishitworkedbetterforpregnancymilestones bumppics etc.
alltheremindersassumeyourkidisbornregardlessofenteringtheduedate.also thepicturestakeforevertoload.iuploadedmultiple pics for one day and my sister thought it was just pic because of the slow load time.
company name redacted is faster and i can make a private group so my pics aren t super public.
in this example the user seems to be primarily expressing dissatisfactionabouttheremindermechanismsanduploadspeeds.they alsomentionthattheywouldlikeanewprivacyfeature namely theabilitytocreateprivate groups.the requestforaprivategroup option does make this a legitimate review about privacy.
however we did not find similar requests in other reviews in parenting apps and thus this review is an outlier.
we aim to limit the influence of such reviews in the clusters produced.
given this we have the following goals.
firstly we aim for well separated clusters.
secondly we aim to have a high number of clusters that have limited mixed concern reviews and to minimize thenumberofoutliers.toachievethis weproposea summarization metricthat will reward a value of kbased on these criteria.
to address thisfirst goal we usethe following construct.
let si denote the center of cluster i. we define dist kas dist k min si sj i j wherei jandi j .
si sj is the cosine distance betweentwoclustercenters.
dist krepresentstheminimumpairwise distance among all pairs of kcluster centers.
maximizing dist k ensures that the cluster centers be far apart in the vector space.
we iterate through multiple values of kand select the one that maximizes this metric.
this formula varies compared to existingmetrics where an average of inter cluster distance is generally takenintoaccount.hereweensurethattheminimuminter cluster distance is the highest for the chosen kvalue.
to address our goals of limiting the influence of mixed concern reviewsandoutliers wewantintuitivelyto ignore reviewsthat arelooselyassociated withacluster aswellasthemixed concern reviews as these are likely to be borderline between multiple figure silhouette scores using k means for k clusters.
we aim to count the reviews within a cluster that areclosely related and refer to them as upvotes defined below .
we use thesilhouette score to do this.
recall that the silhouette score s i formulateshowcloseeachpointistoitsclustercenterandhow far it is from the nearest neighboring cluster namely s i b i a i max b i a i whereb i isthelowestaveragedistancebetween i thpointand any cluster of which it is not a member and a i is the average distance between iand all the other points of the same cluster.
as anexample werunk meanswith k 5onreviewsidentifiedas privacyinthe parenting categoryandcomputethesilhouettescores foreachreview asshowninfigure2.anegativesilhouettescore indicates that the review is assigned to a wrong cluster as it iscloser to the neighboring cluster.
the dotted red line in figure representstheaveragesilhouettescoreacrossallthereviewsinthe category.alowsilhouettescore closetozero indicatesthatthe reviewisveryclosetotheclusterboundary datapoints reviews which are on lhs of the red line but still positive and a high silhouette score indicates the review is closer to its own cluster center data points reviews on the rhs of the red line .
we refer to reviews with silhouette score higher than the average silhouettescore asupvotesfor a given theme in a cluster.
from figure we see that it could be useful to retain clusters and that havea larger amount of upvotes and ignore clusters and .
clusters2 and are likely to be poor quality since most of the silhouettescoresarenegativeorbelowthe averagesilhouettescore.hence inthisillustrativeexample wewouldaimtohave3finalclusters and simply not capture the ignored clusters which are unlikely to contribute to top issues.
weconsiderclusterstobecompactwhentheyhaveahighnumberofupvotes andalownumberofmixed concernreviewsina given cluster.
therefore we can rephrase our goal as aiming for a kthat results in high number of compactclusters where a compact cluster is defined as one in which at least of the samples are 118icse may pittsburgh pa usa preksha nema pauline anthonysamy nina taft and sai teja peddinti upvotes.werefertothenumberofcompactclustersidentifiedas mk for a given k. we combine the above two principles and define a new summarization metric as follows summarization metric dist k mk weiteratethrough k ... 10andchose kforwhichthesummarizationscoreishighest aswewanttoincreaseboth dist k distance between cluster centers and mk number of compact clusters .
we usemctodenotethefinalnumberofcompactclustersidentifiedfor thechosen k.weconsider kbetween2and10becauseinourinitial exploration using our methodology we focus on dominant privacy concerns.howeverusingalarger kwouldenableananalysttolook through the long tail of privacy concerns.
we may end up with tens of thousands of reviews in a single cluster thusitisimportanttosummarizetheminawaythatcapturestheprimaryconcern.wedothisbyselectingafewspecific reviewsthatcanbeconsideredasrepresentativeofthereviewsin the entire cluster.
by summarizing this way we capture the cluster topicin the users own words.
we rank reviews within a cluster according to their silhouette scores and use the top ten reviews with the highest scores as the representative reviews.
we carefully analyzed these cluster representatives manually across all clusters andverifiedthatthesereviewsindeedillustratethemaintopicin each cluster.
in the next sections we select quotes reviews that came from different categories to show the breadth of the issues across app categories.
.
limitations weusedk meansasourfirstapproachtoclusteringbecauseitis simpleandbroadlyused.however ourclustersarequiteuneven insize andthusmoresophisticatedapproaches suchasaffinity clustering could yield improved performance.
this kind of work is inherently hard because the definition of privacy is not exact.
we relied on previously accepted privacy taxonomies threeprofessionallinguists andourownexperience reading huge numbers of privacy reviews.
a clearer sense of the distinction or accepted overlaps between security censorship harassmentandprivacycouldtaketheformofagreeduponguidelines by a community of domain experts.
although user perspectives within a cluster are automatically summarized by the representative sentences ranked by silhouette scores thereisstillamanualstepinassigningthematiclabelsto each cluster i.e privacy controls selling data etc.
that we did by reading the top reviews per cluster and finding a label based uponourinterpretationofthosereviews.nlpmethodsfortopic labeling could automate this step although their efficacyin the privacy domain needs to be evaluated.
privacy themes inthissection wepresentthetopprivacythemesthatareassociated with different app categories.
to do this we run our clustering analysis on the previously extracted privacy reviews.
due to space limitations we present findings from play store app categories instead of all categories.
we selected categories that were either large or ones where we expected privacy concerns might arise.recall that our clustering iterates through k ... and picks the bestk number of clusters according to our summarization metric.
for each of our app categories we found that kvaried from to .welookedatthecompactclustersacrossthese10categories and identified themes that were dominant across multiple categories.
within each cluster considered we ranked the reviews in those clusters by silhouette score.
recall that the top ranked reviews essentiallyrepresentthetopicoftheclusterastheyarecentralto the cluster.
for each of our selected clusters we manually read the top most representative reviews and assigned a short thematic label to the cluster for ease of presentation and for summarization.
for example we assigned the thematic label too many permissionsto clusters whose representative reviews frequently mention that an app requests more permissions than what seems needed.
these reviews are referring to the android permissions such as location contacts microphone camera etc.thisthemewaspresentacrossallappcategories withlocationpermissionbeingthehighest occurring sub theme.
in other large clusters many reviews com ment on the collection of personal information.
such reviews typicallyrefertoinformationsuchasaddress email profileinfo etc.
other themes we identified include privacy controls tracking andselling data.
the cluster of reviews assigned the privacycontrols themecapturesreviewsthateitherdiscusstheexisting privacycontrolsofanapp oraskforanewprivacyfeaturetobe added to the app.
table shows our themes and app categories there is an asterisk in each table entry if that theme appears as the top 5issuefortherespectiveappcategory.ablankcellmeansthat thistopicdidnotsurfaceasoneofour mccompactclustersfora givenappcategory theremightstillbereviewsonthistopic but they are not large enough to generate a compact cluster .
whiletheseprivacythemeshavebeenidentifiedinqualitative studies before our analysis is the first large scaleworktoconfirmthesefindingsempirically.moreover we are able to quantify the volume per theme thereby enabling us toranktheseissues andweareabletoshowwhichissuesoccur across multiple appcategories e.g.
permissions and whichoccur in only a few categories e.g.
selling data .
giventhescopeofeachofthethemes ourpurposehereisnotto diveintodetailsindividually butinsteadtosummarizesuccinctly how users express these pain points.
the included examples below comefromourtoptenrepresentativereviewspercluster topic perappcategory.becausetheseexamplesarecentraltoclustersofmany thousands of similar reviews they summarize the views of large groupsofusers.ourclustersrangedfromafewthousandupto20k in size.
among these representative reviews we selected examples from different categories to illustrate that privacy concerns arerarely category specific.
a more detailed look into each specific privacy theme is left as future work.
.
concern too many permissions thelargestcluster ineachofour10categories containsreviews that make comments about the app asking for too many permissions.
this is expected as permissions are the gateway to accessing personal information and prior work has pointed to excessive permissions being a major concern .
examples include 119analyzing user perspectives on mobile app privacy at scale icse may pittsburgh pa usa table privacy topic themes occurring in app categories toolsgames communi maps enter parenting health photo medicalauto cations tainment graphy navigation fitness permissions personal information privacycontrols tracking sellingdata i really enjoyed this app until i realized it had access to all of my photos media and storage !
why the heck would a simple sudoku app need that !
?
i m now more careful at checking the permissionsbeforei installanything.i promptlydeletedthis app and installed a similar sudoku app that doesn t require such ridiculous permissions and it s just as good games whydoesthisapprequireaccesstomycontacts?purpose?i take my privacy very seriously.
no one should install this app if you value your privacy.
maps navigation goodapp butihateitwhenappsrequestpermissionsithas no business for in this case access to my contacts no thanks auto vehicles thefirsttworeviewsfocusonwhetherthedatacollectedisreally neededforthefunctionalityoftheapp.inexample1 thedisconnect between the permissions asked for and the user s perception of the app functionality caused this user to uninstall the app and switch to a more privacy friendly app.
in example the user is asking for the purpose of collecting contacts presumably because it is notclearfromthecontext .theimportanceofsharingpurposewith usershasbeenestablishedintheacademicliterature and even in android s best practice guidelines4 it is interesting to now see users effectively demanding that.
it is important for developers tolearnwhenusershavesuchconcerns astheycanbemitigated by providing explanations to address the purpose type questions.
in example users state they feel that data collection from some permission requests is unacceptable or a risk .
figure privacy reviews that discuss permissions we also examined which reviews mention a specific permission suchasmicrophone location etc.todothisweusedsimplekeywordmatchingsuchas phone calllog contact microphone location permission appearedsomewhereinthe review.figure3showsthenumberofprivacyreviewsthatmention each permission group as well as the percentage of reviews they represent.weseethatthelocationpermissionisthemostdiscussed permission appearinginover40 000reviews oftheprivacy reviews .
contacts is the second most discussed permission.
.
concern too much personal information reviews in which users complain that too much personally identifiableinformation pii isbeingcollectedistheseconddominant privacy concern and occurred in eight of our ten categories examined herein.
while prior work has shown that users are concerned about too muchpersonal information being collected bothin the context of mobile apps and generally unlike ours theydonotrelyonexperiencesusershaveusingtheirowndevices inthewild.ouranalysisadditionallyshowsthatuserswarnothersnottodownloadanappexplicitlybecauseofpiicollection as shown in the following two examples when it won t let you play the game unless you agree to letituseyourinformation itain tworthplaying.ifyouwant privacy don t download it games dontdothis!!!youreonlygivingtheappyourpersonalinfo!
whatyoulooklike yourfingerprints everything!idownloadedthisappjusttowarneveryonenottogivethisapppermissiontoanythingonyourdevice!...thisisdangerous!
entertainment other users indicate their suspicion i.e.
there is no good reason for the data collection.
these suspicions which are in essence requests for data collection justification reflects the same issue we saw in the reviews about too many permissions applied to different data items.
in the first two examples below the users are clearly quite annoyed.
the user in the 3rd example implies that they might have uninstalled the app because of this reason.
why the hell you need access to everything you are service provider or intruder in privacy.
auto vehicles horrificregistrationprocess requiringpersonalinformation irrelevanttotheapplication spurpose.
mapsandnavigation whydoesitneedmydeviceidsandthephonenumbersofmy callers.
who i communicate with is none of their business.
this app appears to be collecting more info than it requires to offer it sservices...theyhavenorespectformyprivacy theappwas useful.
health and fitness yetotherusersexpressthemselveswithtermsrelatingtotheft orharassment asthefollowingtwoexamplesconvey.clearlytrust is impacted if users interpret an app s behavior this way.
120icse may pittsburgh pa usa preksha nema pauline anthonysamy nina taft and sai teja peddinti started stealing personal information.
phone numbers and messages are being read by this application.
maps and navigation toomuchpersonalinfo whydoyouneedsomuchpersonal infoyoucreeps?areyoutheoffenderslookingforprey?jeez parenting .
other dominant privacy concerns privacy controls.
comments about privacy controls were a common issue across app categories namely in communication parenting photography tools and games.
the fraction of reviews discussingthisthemerangedfrom24 forcommunicationapps to6 forgames.thereviewsaboutprivacycontrolsshowaninteresting breadth from explicitly requesting privacy controls to be easier example to frustration with privacy controls example2 to requesting new features e.g.
private chat in example .
in example2 theuseristryingtohidesomephotoswithinapp yet doesnotappeartobeabletodososuccessfully.toaddresstheuser frustration with using the offered privacy controls personalized privacy assistants have been proposed .
don tsharemypicsonpublicdomainwithoutmypermission when people search for specific location to visit pics appear so make privacy settings easy.
photography lock the pics you dont wanna see then they just get copied right back to the gallery doesnt hide anything.
tools ilovethisgame!itissoaddictiveandfun!...theonlythingi would want to change add is private chat.
games tracking.
wesawtrackingasadominantconcernin5appcategories namelycommunications entertainment parenting pho tography and medical apps.
the fraction of privacy reviews that discuss tracking rangedfrom a minimum of10 in entertainment apps up to in parenting apps.
privacy concerns arising due to users location being tracked have been well studied but our analysis shows that location isn t the only attribute people are concerned about being tracked.
purchase history contacts and other personal information are also important.
as the examples below show users sentiment on this topic can range from annoyed to angry.
since our methods can extract reviews on this issue it permitsfutureworkonsentimentanalysisandperhapsadeeper exploration into which types of data are more sensitive.
note the thirdexamplementions privateinformationaswellas spyingand thusprovidesanexampleofreviewsthatfallontheboundaryof two themes one of the challenges in section .
.
warning this app is spyware and will track all your location info and purchases.
entertainment spyware dataminer.willnotconnectuntilyougrantaccess to your phone location and data.
contacts and location are personal information.
cameras don t need this to function.
you lie to public!
photography iagreewithprotectingyourchild.but whenyourateenlike me you feel like you cant breath without constantly being watched.
it s like being stalked by your own family and as if you can t trust them.
there s a boundary between protection and privacy.
and this is stepping over the line.
parenting .
selling data.
users have previously expressed concerns with service providers selling their data .
we show here that upsetdue to the perception of personal data being sold to third parties alsoappearsinmobileapps.unexpectedlythough wefoundthis to be dominant in only app categories that of communications medical and entertainment apps.
in the communications apps we observed approximately of the privacy reviews mentioning sellinguserdata makingthisasignificantprivacyissueforcommunication apps.
theexamples below hint thatthis issue appears to make users feel undermined as the comments are quite cynical.
we also see that users imagine their data being sold off to a variety of recipients including to companies the nsa and spammers.
i would highly recommend staying away from this cash grab ofanappandmovetoanappthatactuallycaresaboutthedata it collects about you.
i feel like this company and application areonlyusedtotrackyourdataandinformationandselling it off to the highest bidder sad thing is they make you pay for it so you re essentially paying to get your information stolen.
medical theyaresellingpatient spersonaldatatocorporates.onceu use uwillstartgettingmails and call from labs for medical tests.
beware.
medical whatidonotunderstandiswhy hadtomakeanotherwaythattheycouldsellourprivateinformation to third parties like the nsa.
communications privacy positive reviews.
during the above exercise processing the top privacy pain points we found to our surprise that while most privacy reviews are negative we do see some privacy pos itive reviews.
in these reviews users mention that they like the privacycontrols examples1and2 orthattheyaregratefultheapp is not collecting unnecessary information example .
the very presenceofsuchreviewsindicatesthatdeveloperscanberewarded by privacy friendly design.
examples include thisisoneofthebestphotosharingappsoutthere.noneed to share your children s whole lives on social media and mess around with tons of privacy settings.
you invite who you want to your album and can share privately with your partner or the whole family.
parenting good way of keeping photos private.
photography itwasgreatfunplayingthis.ilikethattheydon twantaccess to your private information unlike other apps.
games while these five themes were dominant concerns there were smaller review clusters that touched upon other topics such as adsrelatedtopersonalinformation and safetyconcernsdueto personal information leakage .
the diversity of privacy issues is broad thus making it challenging to provide examples of all topics due to lack of space.
overall we found many of these reviews to be fairly privacy savvy many questioned the purpose of data collected and demanded justification while others suggested specific privacy controls they would like to see added.
our quotes from representative reviews show that it is not uncommon for users to warn other otherstostayawayfromanappforprivacyrelatedreasons.the dominantissueusersareconcernedaboutisthecollectionoftoo muchpersonaldata beitfromapppermissionsorpii.wefound thistobetrueacrossnearlyallappcategories.wefoundreviews of users who uninstall apps due to privacy related reasons this 121analyzing user perspectives on mobile app privacy at scale icse may pittsburgh pa usa is important to know as we suspect that developers are not completelyawarewhenthishappens.wealsofoundprivacypositive reviewsandthisindicatesthatdeveloperscanbepubliclyrewarded for privacy friendly behavior.
implications weillustratehowourmethodenablesdeveloperstoimprovethe privacy of their products and how app stores can leverage our findings to design better privacy tools and best practices.
organizingandunderstandinguserfeedbackforaparticular appinamuchmoremeaningfulandactionableway.
today theplaydeveloperconsole surfacesallprivacyrelateduser reviews under a theme called privacy .
this makes it difficult toeffectivelyunderstanduserfeedbackandidentifyspecificpain points.instead embeddingourmethodologyintosuchdeveloper feedback channels would allow app authors to address nuanced privacy concerns directly.
for instance concerns on toomanypermissions ifadeveloperseesmanyuserscomplainingthattheydonotseethepurposeforapermission request thena guidelinewould suggestto provide ameaningful explanation or to remove the permission entirely.
sellingdata ifasetofreviewsshowsmuchconcernabout selling personal data and the app does not engage in such behavior thenadeveloperwouldbeadvisedtoprovidean educational intervention to clarify this misunderstanding.
privacy controls if reviews identify missing features or capabilities then these can be translated into product requirements or bug fixes .
guiding the design of new tools for developers to providetransparency on their data collection practices such as the apple privacy nutrition labels and its upcoming equivalent in the play store .
understanding user concerns at scale and in depth via our methodology could inform the design of such transparency initiatives.
analyzinguserconcernsabout tracking sellingdata andtoo much personal information could shed light on what type of labels are useful and how they should be designed.
the two label systems above are a good step forward as they encourage developers to be upfront about their collection and sharing practices.
such labels could increase user trust and helpthemdifferentiatebetweentheprivacystanceofcompetingapps.althoughproperuseofsuchlabelsisturning out to be challenging .
in the long term our methodology will enable refining such labels and tailor them to the specific concerns of users.
it will also allow monitoring of emerging privacy concerns.
mechanismforprovidinginsightintousersperceptionsof privacy.
beyond looking at top issues one could evaluate how privacyissuesvarybycountry bylanguage bytime orcompare privacyissuesbetweenchildren sappsversusregularapps.running sentiment analysis on such privacy text data sets using tools such as stanford s nltk would enable large scale comparison of sentiment across privacy issues and help developers and appstores prioritize what to fix first.
these insights would be very valuable especially for small scale apps that do not have resourcesto analyse their reviews another way.
nudgingdeveloperstowardsbetterprivacypractices.forinstance today the play developer console nudges developers to remove permissions that are not used by apps in its peer groups .
by using our methodology these nudges can be expanded to the otherprivacyconcernsidentifiedinthispaper.forexample tomit igate tracking concerns developers could be informed of malicious ad libraries as opposed to those that are much more privacy safe.
conclusion understanding privacy trends is key to address systemic concerns acrossecosystemsandpopulations.todate large scaleevidence ofwherethemainprivacyconcernslieforappusershasbeenlacking.thispaperisthefirsttoprovideamethodologythatenables automated analysis and succinct summarization of privacy feedback onalargescale.ourmethodologycanactasamechanismfor keyecosystemstakeholderstoberesponsivetoevolvingsocietal concerns regarding privacy.
as new technologies come to the fore and as the risks of large scale data harvesting become more apparent thisisasteppingstonetowardssystematicunderstandingof privacy concerns at scale.