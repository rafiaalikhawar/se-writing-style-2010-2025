identifying and describing information seeking tasks chris satterfield university of british columbia vancouver canadathomas fritz university of zurich zurich switzerlandgail c. murphy university of british columbia vancouver canada abstract a software developer works on many tasks per day frequently switching between these tasks back and forth.
this constant churn oftasksmakesitdifficultforadevelopertoknowthespecificsof when they worked on what task complicating task resumption planning retrospection andreportingactivities.inafirststeptowardsanautomatedaidtothisissue weintroduceanewapproach to help identify the topic of work during an information seeking task oneofthemostcommontypesoftasksthatsoftwaredevelopersface thatisbasedoncapturingthecontentsofthedeveloper s active window at regular intervals and creating a vector representation of key information the developer viewed.
to evaluate our approach we created a data set with multiple developers working on the same set of six information seeking tasks that we also make available for other researchers to investigate similar approaches.our analysis shows that our approach enables segments of a developer s work to be automatically associated with a task from a knownsetoftaskswithaverageaccuracyof70.
and2 aword cloud describing a segment of work that a developer can use to recognize a task with average accuracy of .
.
ccs concepts human centered computing empirical studies in hci.
keywords software development productivity information seeking tasks acm reference format chrissatterfield thomasfritz andgailc.murphy.
.identifyingand describing information seeking tasks.
in 35th ieee acm international conference on automated software engineering ase september virtual event australia.
acm new york ny usa pages.
introduction developers work on many tasks in a day some of of these tasks arecode relatedandothersinvolveinformationseeking .as developersworktheyswitchbetweentasksconstantly .this constantswitching andthevarietyandhighnumberoftasks makeitdifficultfordeveloperstoknowwhichtasktheyworkedonwhen.
asaresult developersspendsignificanttimeandeffortrecalling what information is needed when a task is resumed .
additionally developers are unable to accurately record how much ase september virtual event australia copyright held by the owner author s .
acm isbn .
is spent on tasks impacting personal planning and retrospection activities e.g.
as well as impacting effort estimation for the entire team.
to ease this problem some developers manually track and note whichinformationtheyaccesswhileperformingataskasaform ofexternalizationof theworkingstateofa task .thismanual approach is time consuming and requires substantial effort from thedeveloper.sometoolshavebeenintroducedtoalleviateparts of this burden from the developer.
for instance the mylyn tool enablesadevelopertoindicatewhenworkonaparticulartaskis started and stopped and the tool then tracks relevant information forthetask .alloftheseapproachesrequirethedeveloperto explicitly indicate whenthey start working on a task and which task they are working on which is cumbersome at best.
recently researchershavemadeincreasingprogressonautomaticallyidentifying whendevelopersswitchtasks .
these advances mean it is becoming possible to automatically split a developer s past work into segments associated with different tasks.
an open problem is to determine whichtask a developer is working on and associating each segment with the task.
inthispaper weexplorethisopenproblem focusingonwhether the topic of work a task can be identified automatically based on the information that a developer accesses as part of a task.
our initial focus is on information seeking tasks.
as it is common in softwaredevelopmenttorecordtaskstobeperformedineithera sharedorprivateissuerepository wefirstassumethatdescriptions of what work is or has been performed are available and examine the following research question rq1 can we automatically associate existing task descriptions withinformationdevelopersaccessas theyworkonthese tasks?
approaches that address this question can help a developer to locate when they had performed work on a particular task.
in a secondstep weexaminewhetheritisalsopossibletogeneratetask descriptions from scratch based solely on the performed work rq2 can we automatically create a word cloud representation of work performed that enables developers to identify the task on which work was occurring?
to explore these questions we developed an approach that generatesrepresentationsofadeveloper sworkforagiventimeperiod.
the approach as depicted in figure takes in work being performed by a developer.
specifically our approach continuously recordsscreenshotsofthedeveloper sactivewindowandutilizes opticalcharacterrecognition ocr toextracttheinformationfrom it.foragiventimeperiod theapproachthenappliesnaturallanguage processing and information retrieval techniques to generate a vector representation of the segment.
this representation can thenbematchedtoexistingtaskdescriptionstodeterminethetask the developer worked on for rq1 or can be used to generate a 35th ieee acm international conference on automated software engineering ase this work is licensed under a creative commons attribution international .
license.
word cloud that highlights the most relevant words to describe the task forrq2 .anadvantageofourapproachusingscreenshots andocristhatitisagnostictotheapplicationsadeveloperuses to perform their work.
weperformedtwoevaluationstoassessourapproach onefor eachresearchquestion.theseevaluationsarebasedonadataset that we created consisting of work streams from participants experiencedinsoftwaredevelopmentperformingsixinformation seekingdevelopment orientedtasks inaninterleavedfashion ina controlled lab setting section .
we designed the tasks tobe representative of information seeking tasks commonly performed by softwaredevelopers .basedonmanuallyidentifiedtaskswitches wethenapplyourapproachoneachsegmentofwork betweentask switches togeneratevectorrepresentationsandwordcloudsfor eachtasksegment section2 .asweshowinfigure1 weevaluate rq1byexaminingwhetherourapproachcancorrectlyassociate task descriptions written by variousdevelopers with the task segmentsusingthegeneratedvectorrepresentations.wegatheredtask descriptions for each task from people experienced in software development and found that our approach is able to correctly associate the descriptions with the correct segment of work in .
ofcases section4 .weperformapreliminaryevaluationofrq2 byexaminingwhethersoftwaredevelopersareabletomatchthe generated word clouds to the corresponding tasks.
we surveyed experienced software developers and found that they were able to matchthewordcloudstothesixoriginaltaskdescriptionscorrectly in .
of cases section .
this paper makes four contributions a data set from a controlled lab setting involving participants working onsix information seekingdevelopment tasks other researchers can build on this data set to investigate other approaches.
an application agnostic approach to generate representationsofadeveloper sworkforagiventimeperiodtohelp determineanddescribe thetaskthatisbeingperformedand anevaluationofavarietyoftechniquesforgeneratingthese representations.
anevaluationoftheapproach saccuracyfordetermining thetaskadeveloperwasworkingonforagiventimeperiod based on the collected data set and task descriptions from participants.
an evaluation of the approach s ability to generate wordclouds for task segments that can be used to identify the tasks developers were working on.
whileourevaluationonlyfocusesoninformationseekingdevelopment orientedtasksandusesrecordedtaskswitchinformation the results show promise for our approach s ability to automatically identifyanddescribethetasksadeveloperisworkingonandfor further automating task support.
generating task representations our goal is to create representations of a developer s work that allow the developer to determine the tasks worked on.
specifically weconsiderthecreationoftworepresentationsofworkperformed a vector space representation vectors that can be used to automatically match it to existing task descriptions and thus determinethetaskworkedon andawordcloudrepresentationthatdescribes the task and allows the developer to identify the task worked on withoutpre existingtaskdescriptions.previousworkhasshown that word clouds are useful aids for helping users determine the relevance of a document to a topic .
wedescribeourapproachthatcontinuouslymonitorsadeveloper sworkby recordingscreenshotsofthe activewindows processes and extracts relevant information and is able to generate vectors and word clouds for specified time periods of work.
by recording and processing screenshots our approach is agnostic to the applications developers use for their work.
figure depicts the main steps involved in our approach.
for this research we focus on generating representations for tasksegments timeperiodsofworkinwhichadeveloperworks on one task before switching to another one and assume thatthese switches can automatically be determined using emerging techniques e.g.
.
.
screenshot pre processing ourapproachfirstpreparestherecordedscreenshotsofdevelopers active windows for the optical character recognition ocr with tesseract .specifically we convertthe coloredscreenshotsto grayscale and scale the resolution down to dpi.
these steps areconsideredbestpracticeastesseractwasoriginallyintended forreadingblackonwhitepaperdocuments.inaddition wecrop apercentage ofthe topofthe screenshotas mostapplicationwindows have menu or bookmark bars at the top that generally do notcontaininformationspecifictothetaskathand.throughexperimentation wefoundthatremovingthetop15 ofthescreen across all application window screenshots provides a good balance between removing noise without much loss of meaningful con tent.
1we automate all screenshot pre processing steps with the imagemagick tool .
.
extracting bags of words afterpre processing ourapproachappliesthetesseractocrengine to extract the textual content of each screenshot.
as tesseract tries to preserve the format of the text it produces a structuredstring for each screenshot.
we store these strings in a document one for each screenshot.
these structured strings contain substantial noise even after the pre processing.
for instance an i is often misinterpreted as the number or the letter l .
as well many nonsensical artifacts can be produced due to noise from items like images and menu bars on the screenshot that remain after preprocessing.
to break these documents into usable pieces of information words tokens and further reduce noise our approach supports the application of one of two techniques either a tokenization or b keyword extraction.
for tokenization we use the naturallanguage toolkit nltk version .
.
and apply standard wordtokenizationtechniquesbasedonwhitespaceandpunctuation to generate lists of all words in a screenshot.
we further remove allstop wordsfromthelists.forthekeywordextraction weuse an open source implementation version .
.
of the rake algorithm .
based on an input string rake produces a set 1this percentage might have to be adjusted for different screen resolutions and sizes.
798approach generating task representations v for task segments ts data set on developers task work developers working on different tasks s1 s2 s17 tasks duplicate bug detection bugd viz library selection viz blockchain expertise blc t1 t2 t61 6vts1 vts2 vts3 vts4 vts5 vts6word cloud generation wcts1 wcts2 wcts3evaluation rq1 automatic matching of task representations to task descriptions task descriptions participants x tasks vts1 vts2 vts370.
accuracy evaluation rq2 matching word clouds to original tasks .
accuracy t1 t2 t628 developers x word clouds 7vts7bugd viz blc figure overview of the process used to evaluate our approach.
table techniques used in the vectorization process of a task segment.
technique description tf uses the frequency of a term word in a task segment as vector entry and if the word does not occur in the task segment.
the vector dimensions are the unique words that occur in any of the task segments for a developer.
tf idf has the same vector dimensions as tf but uses tf idf for calculating entries.
tf idf for a word term tis defined as ft idft whereftisthe termfrequency of t andidftiscalculatedas logn dft wherenisthe totalnumberoftask segments anddftis the number of task segments in which toccurs.
w2v usesaword2vec modelpretrainedonacorpusextractedfromwikipedia.eachwordwithinatasksegmentisassigned a dimensional embedding vector.
these vectors are then averaged to create one embedding vector for the entire task segment.
this technique has been shown to be an effective baseline in many nlp tasks .
of keywords with a size equal to of the number of original words not counting duplicates .
after breaking up each document intoa setofwordsusing tokenizationorkeywordextraction our approachstemsallwordsusingtheporterstemmerimplementation from nltk.
finally the approach creates a bag of words a record of the frequency of each word for each task segment by aggregating all words extracted from all screenshots of a task segment.
.
generating task representations a bag of words is itself a primitive representation of a task with thefrequencyofeachwordinthebagindicatingtheimportance of a word to the task.
however this r epresentation only reflects importanceofawordwithrespecttothecurrentdocument task segment .
to also take into account the relevance of the wordin context of the overall work of the developer and further helpfilter noise from the screenshots and the ocr our approach is designed to enable experimentation with several natural language processing nlp and information retrieval techniques to generate more advanced representations.
table summarizes the three techniques we experimented with in this work to produce a a vector space representation v andsubsequently b a word cloud representation wc.
each of these techniques takes the words from the bag of words produced in theprevious step as input and produces a vector representation of the task segment.
in the case of tfandtf idf the dimension of the vectors is the number of unique words in the set of all words from all task segments of a developer.
for w2v we chose the dimension of the vectors to be based on our training of the word2vecmodel.allofthesevectorrepresentationscanthenbecompared usingcosinesimilarityagainstvectorswhichcouldbegenerated based on other task segments or for example task descriptions.
based on these vector representations our approach can be usedtogeneratewordclouds.however sincethemeaningofthe dimensions in the w2v vectors are difficult to interpret we did notusethe w2vtechniqueforcreatingwordclouds.togenerate word clouds for the tfandtf idftechnique our approach selects the largest entries in a vector corresponding to the highest ranked words in a task segment and use the score of the words to determine the proportional size of the words in the cloud.
figure shows two examples of such word clouds.
data set creation to support the investigation of the two research questions we createdadatasetfrom17developersworkinginacontrolledlaboratory setting on a set of six information seeking tasks over a hourtimeperiod.wechosealaboratorysettingtobeabletogather ... ... ... t1 t3 t2 ocr tesseract structured strings of text tokenization tk or keyword extraction rake stemming aggregation tf tf idf w2vbag of words wcts1 vts1timetask task task task wcts2 vts2 wcts3 vts3 wcts4 vts4task switch figure main steps of the approach to generate task representations the light blue boxes represent task segments .
a wcforadeeplearningpresentation deepl tasksegmentofd1 b wc for a duplicate bug bugd task segment of d4 figure word clouds wcs generated for task segmentsfrom different tasks and developers.
data from multiple developers working on the same tasks.
the full data set will be made available in the supplementary material2 .
2thedatasetistemporarilywithheldtoprotectdoubleblindduringthereviewprocess.
.
developers we recruited participants who we refer to as developers in the following through advertising at our university and personal contacts.alldevelopershadseveralyearsofexperienceinsoftware development with an average of .
.
years per developer.
of the developers were female and were male.
at the time ofthedatasetcreation 10weregraduatestudents 4wereupperyear undergraduates and were interns at a mid sized software company.
all developers were residents of canada.
.
tasks developers workon manydifferent kindsof taskseach day some of which focus on code .
and some of which focus on informationseeking .
.incollectingthisdataset wechose to focus on information seeking tasks.
we made this choice given the significant and higher fraction oftheir daydevelopers spend on these kinds of tasks.
this choice also enabled developers to attemptmoretasksinthelimitedtwohoursavailableperdeveloper codingtaskswouldhaverequiredmoretimeperdevelopertoenabledeveloperstogainsufficientfamiliaritywithacodebase.wediscuss theimplicationsof ourchoiceinfocusingoninformation seeking tasks in section .
.
wecreatedsixtasksthatarerepresentativeofcommoninformationseekingtasksbasedontheauthors knowledgeofindustrial development.thetasksweselectedweredesignedtoberealistic yet simple enough for it to be possiblefor developers to make significant progress in the limited time available.
the tasks were also chosentoenableadevelopertomakeprogresswithoutpriorknowledge.developerswere notconstrainedinhowtheyapproacheda task.
table provides a short description of each of the six tasks includingashortnamethatweuseinthispapertorefertoaspecific task the short task name and description was not presented to developers.
an example of one of the actual task descriptions used in this study is presented in table .
we intentionally designed the app market research task andrecommend tool task as tasks which were likely to have very similar information accessed as part of working on the task to allow us to assess the discriminativepowerofourapproach.fulldescriptionsofthetasksthedevelopers worked on can be found in the supplementary material .
.
session beforethestartofasession wegaveeachdeveloperabriefoverview oftheproceduretheywouldbeaskedtofollow.developerswere told that they would be asked to work on a number of information seeking tasks and that they could accomplish these tasks in whatever manner they chose.
however the quantity of tasks and the contentofeachtaskwaswithhelduntilthesessioncommenced.developers were also told that their screen would be recorded by our monitoring tool and that theywould be observed bythe observer as they worked.
atthestartofasession developerswerepresentedwithalist of6taskstoperformwithina2hourtimeperiod.thetaskswere presented in the form of unread emails sitting in an inbox accessed byawebmailclient.theorderinwhichthetasksappearedinthe inbox for a developer was randomized.
we asked a developer to 800table overview of controlled lab tasks.
abbrev.
short task name short task description by us bugd duplicate bug examineacollectionofbugreportsfromabugzillarepositorytodetermineifanywereduplicates.
eachdeveloperwasaskedtoexaminefourbugreports twobeingduplicatereportsandtwonot.
foreachparticipant bugreportswererandomlyselectedfromthesetofallresolvedbugreports from the mozilla projects e.g.
firefox thunderbird etc.
over the course of a month.
viz viz library selection researchvisualization librariesand identifyonewhich issuitable foroutlining thebenefitsof your companies tool for creating a presentation to clients.
prmr app market research performmarketresearchonthreeproductivityapps.identifycommonfunctionalities similarities and differences and report on your findings.
prrec recommend tool examine app store reviews for three productivity apps the same ones as above in order to recommend one to your coworker.
deepl deep leaning presentation prepareinadvanceanswerstolikelyquestionsforahypotheticalpresentationyouaregiving about potential deep learning applications.
blc blockchain expert answer your coworkers follow up questions about a hypothetical presentation you gave about the different ways your company could make use of blockchain.
table full task description for the app market research task prmr as presented to developers.
the software company you work for is considering expanding into the productivity tool sphere.
your manager has asked you to do some market research on of the most popular already existing apps in this domain microsoft to do wunderlist and to provide a short written summary of the similarities and differences between these apps.
workonthetasksonalaptopwitha .3inch 1440x900 sizedscreen runningmacoswhichwas instrumentedwithourrecordingtool reference omitted for double blind .
as a developer worked on the tasks the tool recorded screenshots of the developer s active windowat1secondintervals.applicationnamesandwindowtitles were also recorded whenever they changed.
to simulate interruptions we also installed a tool on the laptop that produced a popup in random intervals lasting from .
to .
minutes.
the average time between popups was selected as .
minutes inaccordancewithgonz lezandmark sfindingsonthe average amount of time knowledge workers spend in a working sphere segment before switching .
to simulate the disruptive effectsofarealexternalinterruption thepopupprompteddevelopers to solve an arithmetic question before switching to a new task.
these popups were excluded from our tools recordings to avoid biasing our results.
asadeveloperworkedonthetasks aresearchermanuallyannotatedthetimesatwhichthedeveloperswitchedtasks alsokeeping trackofthetaskthedeveloperwasworkingon.afterthesession was complete the times at which switches happened were verified and adjusted by reviewing a screen capture that ran in the backgroundoftheprovidedlaptop toensuretaskswitcheswere recorded accurately.
.
data collected in total we were able to collect screenshot data for all developers and on all six tasks for each developer.
all but one developer completed the tasks within the allowed time period.
on average developerstook91.
.5minutestocompletethesixtasksand we collected an average of screenshots per developer.
due to figure an example of a developer working on severaltasks over time revisiting task in two task segments.
a technical issue we were able to gather window titles for only of the developers.
the full data set will be made available in the supplementary material3 .
.
data annotation using the task annotations collected by the researcher during each session we annotated the collected data with the task switches and the task the developer was working on.
each session resulted in the developers working in an interleaved fashion on the six tasks.
figure depicts a portion of a developer s work showing an exampleoftheinterleaving.wedefinea tasksegment astheperiod of time between two task switches during which a developer was working on a specific task.
we define a task segment grouping as the collection of all task segments that collectively represent work onaspecifictask.weuse tasksegmentgroupings asabaselinefor evaluatingourapproach asitmimicsthesimplestcaseinwhicheach task is completed in one contiguous segment and we have 3thedatasetistemporarilywithheldtoprotectdoubleblindduringthereviewprocess.
801the entirety of the information accessed for the work on a task available.
rq1 identifying tasks our first research question asks whether we can automatically associate descriptionsof adeveloper s tasks withthe information thedeveloperaccessesassheworks.performingthisassociation automaticallyischallengingbecausetherearemanywaysinwhich adevelopercancompleteataskandtherearemanywaysinwhich a developer can describe the task on which they are working.
thedatawecollectedinthelabsetting section3 includesanumber of ways in which the tasks assigned could be completed.
while participants in the lab setting had some overlap in the resourcesthey accessed as part of a task no two participants completed a task in exactly the same manner.
similarly developersarelikelytotailortheirtaskdescriptions towards the ways they might approach a task.
to study the first researchquestion wethereforealsoneededarangeofdescriptions of thetasks on whichthe developers hadworked.
to gatherthese descriptions we employed amazon mechanical turk mt .
given a range ofdescriptions collected in thisway we are able toassess how the range of techniques we developed for generating task representations section can address the first research question.
.
gathering task descriptions to capture a range of task descriptions we distributed a survey via mechanicalturk.asarequirementforrespondingtooursurvey we asked that respondents be currently or previously employed in the software industry.
in total we received responses from 29respondents.
these respondents represented a range of fluency withenglishandarangeofexperienceinsoftwaredevelopment.
onaverage respondentshad .
.
years ofsoftware development experience and .
.
years of professional development experience.oftheserespondents 24reportedthattheywerenativeenglishspeakers while3reportedbeingfullyfluentand2reported being proficient.
respondents of this survey were presented with the same set of six full task descriptions that we also used for the data set creation inthecontrolledlabsetting.anexamplecanbeseenintable3.we asked respondents to please summarize the task described below inyourownwords asyoumightwriteitforyourownreference inato dolistorsimilar.pleaselimityourresponsetoatmost15 words.
.thereby werandomizedtheorderinwhichthefulltask descriptions were presented.
tofilteroutirrelevantorlowqualityresponses weaskedtwo externalexperts whowerebothresearchersinthesoftwareengineeringdomainandexperiencedsoftwaredevelopers toratethe quality of every task description generated by each respondent.each rater was instructed to use a scale from to indicate therelevancy and quality of the responses with a score of indicat ing an irrelevant response indicating relevant but low quality responses and representing relevant and high quality responses.
wefoundthatthedistinctionbetweenresponsesrated2or3varied greatly between our two experts but that there was a strong consensus with regard to the responses which were rated irrelevant cohen skappa .
indicatingstrongagreement .theseirrelevant responses tended to come in multiples from the same participants.weremovedallparticipantswithirrelevantresponsesandconsideredonlythoseresponseswhichbothauthorsratedwith a score of or higher leaving us with participants and a total of task descriptions.
a sample of responses for one task with the ratings by one expert rater is depicted in table .
.
evaluation from the controlled lab setting we have task segments and 102tasksegmentgroupings.fromthemtsurvey wehave20descriptionsforeachtask resultinginatotalof120taskdescriptions.
we wish to determine if the approach we developed for generating task representations and which choice of techniques within theapproach can be used to determine which task segment or task segment group maps to which task description with sufficient precision and recall even when these task descriptions might vary.
recallthatweknowthegroundtruthofwhichtask andthuswhichtaskdescription eachtasksegmentrepresentsbasedonnotestaken by a researcher during the controlled lab setting.
ourevaluationconsistsofconsideringeachtasksegmentfrom a lab developer s work and mapping it to one of the six task de scriptions produced by a mt respondent.
we use this evaluation methodthat assumesa completesetof descriptionsas wewishto assesshowwellourapproachmightworkinasituationwhereadeveloper may be trying to determine from a given set of tasks when they performed work on each task.
for the mapping we generateavectorspacerepresentationofthetasksegmentv tsaswell as one for each of the six task descriptions v 1to v6produced by a respondent and then calculate the cosine similarities between v ts and each of v 1to v6.
we choose the task description most similar to our generated task representation and evaluate it by comparing it to the ground truth to determine if it is correct.
forgeneratingtaskrepresentationsfromtasksegmentsinvectorspaceformat weexperimentedwithandcomparedsix 3x2 different combinations of techniques different techniques for vectorization term frequency tf idf and word2vec word embedding and2differenttechniquesforextractingbagsofwords tokenization using nltk and keyword extraction using rake as described in section .
.
the vectorization techniques applied are described in section .
.
togeneratevectorsfromthetaskdescriptionsofmtworkers wetokenizedthetaskdescriptionsusingnltk keywordextraction is not useful in this case given the brevity of the descriptions and thenappliedtheexactsamevectorizationtechniqueasusedforthe task segments i.e.
either tf tf idf or w2v.
.
results figure5illustratestheresultsofthecomparisonbetweenthesix differentcombinationsofvectorizationandwordextractiontechniques.overall thecombinationoftf idfwithsimplewordtokenizationperformedthebest howeverthedifferencesaresmallcomparedtothecombinationwithrakeorusingjusttf.ultimately word2vec performed the worst for the generation of task representations and mapping to the task descriptions.
since word2vec is also the most computing intensive it was the least appropriate for thisscenario.basedontheseresults weselectedthecombination 802table examples of descriptions received for the viz library selection viz task together with one of the expert s ratings.
rating task description survey response irrelevant i would suggest simile exhibit or infovis toolkit for javascript libraries to create a visualization.
low quality visualize workers work pattern.high quality create visualizations for product benefits.
select libraries and give existing work examples.
figure accuracy comparison for the different combinations of techniques used to generate task representations tk tokenziation .
of tf idf with word tokenization nltk as the approach that we use for the remainder of the paper.
table5presentstheresultsoftheevaluationwhenmappingtask representations of task segments or task segment groupings to the task descriptions written by the mt workers.
we report the precision and recall for each of the tasks calculated on a per task segment basis or with the baseline of the per task segment grouping .
overall using only task segments our approach achieved highaccuracyacrossalltasks .
incomparisontoarandom classifier .
.
accuracy for task segment groupings was moderatelybetter .
.thisisapromisingresultasitindicatesthat thereisoftenalreadysufficientinformationinanindividualtask segmenttopredictthetaskthatisbeingperformed addingmore information helps some but does not make a dramatic difference.
our approach performed well at predicting tasks with a distinct focus such as deepl and blc with precision values over .
this result is unsurprising as in order to perform these tasks the developers in the lab setting tended to turn to resources that contained a dense amount of highly specific information related to these topics such as the wikipedia pages for blockchain and deep learning.
the presence of dense consistent information eases the production of accurate representations for the tasks.
our approach also performedwellatrecognizingthebugdtaskwithprecisionover .
we found this result surprising as we expected this task tobe one of the more difficult tasks to predict especially since oursummary authors were given no information about the contentof this task beyond that it involved finding duplicate bugs in a bugzilla repository.
as expected the most difficult to predict tasks weretheprmrandprrectasks.thesetasksareverysimilarandas such resultedinverysimilartaskrepresentationsaswellasveryfigure accuracy distributions by mt respondent and bylab developer for mapping task representations to the cor rect task descriptions.
similar task descriptions and in turn in a high confusion between the two tasks.
figure illustrates the accuracy distributions of the results on a perdeveloperandapermtrespondentlevel.despitedifferencesin the way each developer performed each task the results are fairly consistent across developers ranging from a minimum accuracy of62.
toamaximumof77.
.acrossthemtrespondentsthat authored the task descriptions the results are mostly consistent however there is a significant variation for a few respondents.
the respondents for which the accuracy of mapping task representationstotheirtaskdescriptionswereratherlowtendedtobeones whoauthoredmultipledescriptionsthatwerealsoratedlowerby the experts e.g.
item in table was written by author s6 .
these resultdemonstratethatthetaskrepresentationsarerelativelyrobust across developers and different ways of performing the tasks and that writing precise and somewhat detailed descriptions of the tasksbeing performedclearly impactsthe resultsof ourapproach.
rq2 describing tasks to address the question of whether we can automatically generate word cloud representations of information accessed by a developer which would help the developer to identify what task she worked on during a specific period of time for a task which would helpdevelopers identify what task they worked on during a specificperiod of time we evaluated the word clouds we generated as describedinsection2.
.weasked28participantsexperiencedin softwaredevelopmenttomatchourgeneratedwordcloudstothe original full task descriptions of the tasks that were performed during the data set creation.
803table results of mapping task representations to task descriptions written by mt workers.
task segments task segment groupings bugd viz prmr prrec deepl blc bugd viz prmr prrec deepl blc precision .
.
.
.
.
.
.
.
.
.
.
.
recall .
.
.
.
.
.
.
.
.
.
.
.
.
survey toevaluatethequalityofourautomaticallygeneratedwordclouds asavisualrepresentationofatask weconductedasurveywithexperiencedsoftwaredevelopers.participantswererecruitedthroughpersonalandprofessionalcontacts andasanincentiveforrespondingwereenteredintoadrawforoneoftwo 25giftcardsifthey desired.
in total we received survey responses from individuals withanaverageof8.
.
yearsofsoftwaredevelopmentexperience.20participantsweremale while8werefemale.9participants reportedthey werenative englishspeakers 12reportedthat they were fully fluent in english and the remainder reported that they were proficient in their understanding of english.
we asked our participants to match word clouds to correspondingtasksbypresentingthemwiththelistofthesixfulltaskdescrip tionsthatwealsousedforthedatasetcreation.anexampleofone of the descriptions can be seen in table .
the word clouds used in the survey were generated following the procedure described in section2.
.usingthedatathatwecollectedacrossall17developers in the data set creation section we randomly selected tasksegments and task segment groupings for each of the six task andgeneratedwordcloudsforthese resultinginatotalof48word clouds.
since asking survey participants to examine a total of wordcloudswouldbetoomuchandimpractical werandomlyselectedandaskedeachparticipantabout12ofthe48 endingupwith2wordclouds 1foratasksegment 1foratasksegmentgrouping for each of the six tasks.
examples of two of these word clouds canbe found in figure .
we asked participants to read the six full task descriptions and to then identify which task the presented wordclouds describe best.
participants also had the option to indicate that the word cloud does not match any task.
.
results weaggregatedtheresultsofthesurveyresponsestoobtainaccuracyratingsforthewordcloudswegenerated.overall theaverage accuracy ofmapping word clouds tothe corresponding taskswas .
forthewordcloudsgeneratedfromtasksegments and69.
for the word clouds generated from groupings.
figure shows the breakdown of the accuracy on a per task level.
the success rates of our participants varied widely between tasks.
for example for the blockchain expert task blc our participants were able to correctly identify the task for the generated word cloud of the time.
conversely participants struggled to properly identify the task for the word clouds generated for the duplicate bug task bugd .
.
thistaskwasbyfarthemostdifficultforparticipantstoidentify and many participants reported that the word clouds generated bythistaskwerenotdescriptive.unsurprisingly participantsfrequently confused the word clouds generated for the app market research task prmr and for the recommend tool task prrec.
these !
figure7 accuracyforidentifyingthetaskbasedonourgenerated word clouds.
the dotted red line indicates the accu racy for a random classifier.
word clouds tended to have very similar key words as both full task descriptions mentioned the same three productivity tools.
comparingtheresultsofthewordcloudsgeneratedfromsegmentstotheonesgeneratedfromgroupingsdidnotrevealasubstantial difference.
this is a promising result as it indicates that enoughdatacanbegeneratedfromwithintheboundsofmosttask segments to create word clouds that accurately represent the topic of a task as a whole.
discussion decisionswehavemadeindesigningtheapproachweintroduce are impacted by the evaluations we undertook.
we discuss threats tothevalidityoftheseevaluationsandconsideralternativesthat could make it easier to apply our approach.
.
threats to validity the evaluations of the approach we conducted rely on a data set that focused on six tasks.
although we chose these tasks to beexamples of information finding tasks performed by developers the range of tasks explored is small.
by focusing on informationfinding tasks we also exclude a significant category of tasks on which developers commonly work namely coding related tasks.
we believe that with minor adaptions such as tokenizing camel casewordsorparsingtheocrresultstoextractincodecomments our approach could be made to work with coding tasks.
if we took this approach to coding tasks the quality of the code base in terms ofdocumentation namingconvention andsoon couldplayalarge role in the ability of our approach to make accurate predictions.it would be impossible to associate a developer description or generate a meaningful visual representation if the code base doesnot contain descriptive names and lacks documentation.
we leave 804theinvestigationofthegeneralizabilityofourapproachacrossa wider range of tasks to future study.
anotherthreattothefindingsisthesizeofthetasksstudiedand theinterleavingofworkondifferenttasks.tofitwithinareasonable time frame for a lab setting the tasks worked on were relatively smallinscope.inreality developersworkoncomplextasksthatcan have a huge scopeand span multiple topics.
in addition although we caused developers to switch tasks it is not possible to replicate themanytaskswitchesadeveloperundertakesasheworks .
it is also unlikely that in reality any single developer would be assigned all six of the tasks we selected at the same time.
a field study is likely needed to mitigate these threats.
wealsonotethatthetaskswedesignedmaybemorespecificin their wording than those that might occur in a developer s normal work pattern.
for example a developer might work on a task in response to some relatively vague verbal request for help from a colleague.in suchcases it isunlikelythat thesummariesthat the developer would write for these tasks are highly descriptive.
wemitigate this threat by including a wide variety of low and highquality task summaries written by a group of mt workers with diverse demographic in our evaluation.
whileallthedeveloperswhosedatawecollectedtocreateour data set had significant development experience and were actively developingsoftware allwerestudentdevelopers andnonewere employedinapermanent professionalsoftwaredevelopmentposition.assuch itispossiblethattheirworkinghabitsmaydiffer to some degree from those of professional software developers effecting the generalizability of our results.
.
limitations of the approach a prerequisite for the application of our approach is that the times at which task switches occur must be indicated.
to achieve a fully automatic application of our approach it is necessary that thesetask switches be detected automatically and with high accuracy.
automaticdetectionoftasksegments i.e.
taskswitches isadifficultproblem e.g.
.whileweareoptimisticthatthe techniques to detect task switches will continue to improve future work should explore the performance of our approach in the absence of knowing task segment boundaries.
it may be that missing or erroneously predicting a task switch could lead to degraded performance in our approach in practice.
it is also possible that in practice the vocabulary a developer usesto describetheirtaskdoes notmatchexactly withthewords commonly found within the content of the task.
for example adeveloper might use the word chart in their task description yet in the window content of the task the word graph might appearprominentlyinstead.applicationsoftf idfwouldmissthis connectiongivenitsfocusonexactwordmatches.incorporating some notion of semantic similarity into our approach for example adding word2vec or another model for word embedding we might be able to enhance task descriptions to also include semantically similarwords.moreexperimentationinamorerealisticsettingis needed to investigate the impact and need for semantic similarity.
.
artifact access using ocr and capturing a developer s screen content has several benefits.
first it is an application agnostic approach that does not require any instrumentation of applications.
as well a screenshot showsusthe exactcontentadeveloperislookingatinthemoment.
while ocr performed well for the purposes of our analysis there aremanydrawbacksthatcouldlimititsusabilityinpractice.forone ocrisanextremelycpuintensivetask.processingscreenshots in real time in the background while a developer works may beimpractical for this reason.
an obvious alternative might be to send screenshots to the cloud for processing but privacy concerns both from the developer s and company s perspective limit the applicability of this approach.
another issue is the noise generated when using ocr.
this may be alleviated to some extent by using a commercialoptionratherthantheopensourcetesseractengine.
however we can not guarantee that the product of a screenshot processed with ocr is exactly the same as the content a developer saw on their screen when the screenshot was taken.
an alternative which we will investigate in future work is to track all file accesses and edits made within the scope of a task segment.ifweknowwhichfilesadeveloperisinteractingwith we can extract the contents of the file directly.
the benefit of knowing exactlywhichinformationina documentis beingviewedwould be lost in such an approach.
however this loss may be outweighed by the ability to produce cleaner data and the much lower cpuusage.
the contents of web page visits could also be extracted relatively easilywith the help ofa browser extension.however it couldbedifficulttoobtaininformationfromapplicationssuchas instantmessagingandemailclients asthereisamuchwiderrange of choices for a developer to use in these cases.
for this reason producingasuiteofinstrumentationsforallthemostcommonly used applications is impractical.
further investigation is needed to determinehowmuchpredictivepowerislostbytheexclusionof these categories of applications.
.
representations from window titles asmentionedinsection3 inadditiontorecordingscreenshotsofa developer s active window our tool also recorded the window title ofeverywindowthedeveloperaccessed.unfortunately duetoa recordingerrorwindowtitledatawaslostfor5ofthe17developers in our data collection session.
toinvestigatewhethertheeasiertocollectinformationaboutapplication window titles might suffice for supporting our approach we evaluated rq1 with the window title data from the developers inplaceoftheinformationextractedusingocr.comparing the results of this evaluation with the results from the same 12developersusingscreencontent wefoundthatwhiletheresults wereloweroverall thedifferencewasmodest .
accuracyusingwindowtitlesvs70.
accuracyusingscreencontent .whilescreen content proved to be a superior choice of data source in almost all cases window titles seem like a viable alternative especially given the savings in cpu resources.
worth investigating is whether acombination of our approach using window titles and the other dataextractiontechniquesmentionedabovecanrivaltheresults we achieved using screen content.
related work our approach aids in determining the task driving a segment of workperformedbyadeveloper.theassociationofataskwithwork providescluestowhatandwhyasoftwaredeveloperisperforming the work and is thus related to the intentof the developer in undertakingthework.determiningtheintentofadeveloperisa growingareaofresearch.themoreweknowaboutadeveloper s intention such as the task she is working on the better we can support the developer for example by providing better code recommendations e.g.
.approacheshavebeendevelopedto determineintentfromhowadeveloperinteractswiththecomputer from the documents produced by a developer and from a mix of both.wedescribeapproaches ineach ofthese categoriesandalso describe related work in finding meaning in artifacts.
intent from interactions.
for some research systems intent is specified through specific interactions a developer takes within the environment in which they work.
as mentioned in the mylyn system a developer can indicate through an explicit click of thebutton on which issue they are currently working the text in an issueprovidesinformationaboutthedeveloper sintent .inthe jaspersystem adevelopercancreatespecialworkingareasoftheir development environment into which fragments of work can be placed forlater recall .
theapproachwe consider in this paper relievesthedeveloperfromaprioriindicatingworkonaspecific task.
otherresearchershaveattemptedtodetermineautomaticallythe higher levelactivitiesdevelopersperformbasedontheirinteractionwiththecomputer.forexample mirzaetal.usedtemporaland semanticfeaturesbasedonwindowinteractionsandthewindow titlesover5minutetimewindowstopredictoneofsixworkactivitycategories writing reading communicating systembrowsing web browsing and miscellaneous .
in a controlled lab study and fieldstudywith5participants theyachievedanaccuracyof81 .
koldijk et al.
investigated the predictive power of keyboard and mouseinput aswellasapplicationswitchesandthetimeofday for predicting a larger set of high level task types such as reading email programming creating a visualization for a given minute period of time .
using classifiers trained on an individual basis theywereabletoachieveupto80 accuracy.however theyfound thataclassifiertrainedononepersonishighlyindividualtothat personanddoesnotgeneralizewelltootherpeople.inanapproach morespecifictosoftwaredevelopers baoetal.exploretheuseof conditional random fields crfs to predict one of six development activities coding debugging testing navigation search or documentation .applyingtheirapproachtodatacollectedfrom10 software developers over a week the authors found they were abletoclassifyanactivitywithanaccuracyof73 .theresultsofbaoetal.pointtothedifficultyofdeterminingatafinegranularitywhatadeveloper is working on at a specific moment.
in our work we aimtodeterminethecontentofadeveloper staskratherthanthekindof activity being undertaken which we see as a complementary goal.
intent from documents.
researchers have also looked into the extractionofintentfromnaturallanguagedocumentsassociated withasoftwaredevelopment.earlyon researchershavetriedtodetect the coarse intent of sentences in emails and tried to summarizethem forexampletoaddthemtoatodolist e.g.
.di sorbo et al.
introduced the concept of intention mining in the contextofemailsinsoftwaredevelopment .theyusedanatural language processing nlp approach to classify the content of developmentemailsaccordingtothepurposeoftheemails suchas feature request or information seeking.
the researchers definedsix categories that describe the intent of a developer s sentence andreporteda90 precisionand70 recallfortheirapproachin the context of email intent classification.
huang et al.
attempted to generalize the approach of di sorbo et al.
to developer discussions in other mediums for example those contained in issue reports .
they found that the nlp patterns used did not adapt well to other mediums achievinganaccuracyofonly0.
.byrefiningthetaxonomy of intentions defined by di sorbo et al.
and applying a convolutionalneuralnetwork cnn basedapproach theauthors wereabletoimproveontheresultsoftheoriginalpaperby171 .
theseapproachesaimtoclassifywhatthecontentofadocument is attempting to state as compared to our approach in this paper which aims to determine what the developer is attempting to do.
intentfromacombinationofinteractionsanddocuments.
shen et al.
use a combination of information about how a user interactswithwindowsontheirscreenandemailmessagestheuser handlesintheirtaskpredictorsystem.usingsupervisedmachine learning theypredictonwhichtaskauserisworking.however thistechniquesrequirestheusertopre definethetasksonwhich theyworksothattheycanbepredictedandtheclassifierneedstobetrainedonsomeoftheuser sdatabeforehand.ourapproachdiffers inassessingmethodsforrepresentingtheworkbeingperformed based on information that a developer works on through screen scraping theserepresentationscanbeusedforpredictingwhichof a known set of tasks the work represents and for generating word cloudrepresentationsoftheworkthatadevelopercanrecognize irrespective of having a set of known tasks.
finding meaning in artifacts.
the content of artifacts created as partof orabout softwaredevelopmentcontainsignificantmeaning.
software engineering researchers have developed techniques to findparticularmeaninginartifactsthathavesimilarcharacteristicstotheapproachwedevelopinthispaper.forexample ponzanelliet al.
present codetube an approach that mines video tutorials from thewebtoenabledeveloperstoquerythecontentsofthetutorialtoretrieverelevantfragments .theauthorsused ocrandspeech recognition in order to extract text from the videos and evaluate the relevancy of fragments to the user s query.
the determination of what a segment of video is about is similar to the problem we tackle of what a segment of a developer s work is about.
summary haveyoueverwonderedwhatyouworkedonthroughoutaday possibly to record time spent on different projects?
have you ever wanted to look back and find where you worked on a particular task to find what resources you consulted as part of the task?
thispaperintroducesandevaluatesanapproachtohelpsupport thesegoals.givenknowledgeoftaskboundaries whichispossi ble from using automated task switch detection techniques our 806approach extracts the contents of the active window being worked with on a regular basis uses optical character recognition ocr andwordtokenizationtotransformthecontentsintotokensand words andappliestf idftoformavectorrepresentationofthe tasksegment.oninformationseekingtasks weshowedthatthis vectorrepresentationcanhelpidentifywhichtaskasegmentrepresents for a known set of tasks with an averaged accuracy of .
.
wealsoinvestigatedtheproductionofwordcloudrepresentations of a task segment using tf idf scores for each word in a bag of words formed from the screen content of the task segment as adeveloper worked.througha preliminary evaluation wefound that participants could determine which task a word cloud for a segmentofworkrepresentedwithreasonableaccuracy .
on average forseveralinformation seekingtasks.interestingly the accuracyroseonlymodestlywhenconsideringidentifyingthetask based on a word cloud formed from all segments comprising work on a task.
this approach shows promise for helping to determine automatically the task on which a developer is working during different time periods.
when the task can be identified various tools canbe improved that a developer relies upon and new tools can be introduced to help support such activities as time tracking.
future workcaninvestigatehowtheapproachweintroduceappliestoa broader set of kinds of tasks performed by a developer.