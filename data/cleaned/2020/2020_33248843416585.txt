assessing and restoring reproducibility of jupyter notebooks jiawei wang faculty of information technology monash university melbourne australia jiawei.wang1 monash.edutzu yang kuo hong kong university of science and technology hong kong china tkuo connect.ust.hk li li faculty of information technology monash university melbourne australia li.li monash.eduandreas zeller cispa helmholtz center for information security saarbr cken germany zeller cispa.saarland abstract jupyter notebooks documents thatcontain live code equations visualizations and narrative text now are among the most popularmeanstocompute present discussanddisseminatescientific findings.
in principle jupyter notebooks should easily allow to reproduce and extend scientific computations and their findings but in practice this is not the case.
the individual code cells in jupyter notebooks can be executed in any order with identifier usages precedingtheirdefinitionsandresultsprecedingtheircomputations.
inasampleof936publishednotebooksthatwouldbeexecutable in principle we found that of them would not be reproducible withstraightforwardapproaches requiringhumanstoinfer and often guess the order in which the authors created the cells.
inthispaper wepresentanapproachto automaticallysatisfy dependencies between code cells to reconstruct possible execution orders of the cells and instrument code cells to mitigate the impact of non reproducible statements i.e.
random functions in jupyter notebooks.
our osirisprototype takes a notebook as input and outputs the possible execution schemes that reproduce the exactnotebookresults.inoursample osiriswasabletoreconstruct such schemes for .
of all executable notebooks which has morethanthreetimesbetterthanthestate of the art theresulting reorderedcodeis validprogramcodeand thusavailableforfurther testing and analysis.
acm reference format jiaweiwang tzu yangkuo lili andandreaszeller.
.assessingand restoring reproducibility of jupyter notebooks.
in 35th ieee acm internationalconferenceonautomatedsoftwareengineering ase september virtualevent australia.
acm newyork ny usa 12pages.
contributedthe sameasthe firstauthor.
thisworkwas donewhentzu yangkuo was a visiting student at monash university.
corresponding author.
ase september virtual event australia copyright held by the owner author s .
acm isbn .
introduction jupyter notebooks documents thatcontain live code equations visualizations and narrative text have become the most widely used system for interactive literate programming .
they are being used to compute present discuss and disseminate scientific findings and have emerged as the de facto standard for data sci entists to easily record and understand data analyses .
in september more than .
million jupyter repositories were stored on github times more than in .
one of the promises of jupyter notebooks is that they should make scientific findings reproducible that is readers should be able to reconstruct and assess the path from raw source data toabstractions and findings as presented in the notebook .
unfortunately thisisrarelythecase.publishednotebookssufferfrom lack of data from lack of modules from lack of metadata indicatingtoolandlibraryversions orbadpackaging .buteven if all of this is given only a small fraction of notebooks can be faithfully reproduced.
whyisthatso?acentralfeatureofjupyternotebooksisthatthe individual cellstheyaremadeofcanbeexecutedinteractively inany order.the language interpreter typically python will execute the code in the cell as soon as a user runs it.
while jupyter provides a run all cells feature that runs all cells starting from the topmost one authors do not need to ensure that this results in meaningful execution order.
it is not uncommon that notebooks output andpresent a result at the very beginning followed by the code thatactually produces the result making the notebook more akin to anarticlethanaconventionalprogram.theinteractivenatureof notebooks makes all of this possible.
jupyter notebooks assign a monotonically increasing number to eachcellasitisexecuted readersmaythusfindthatacellatthetop may have been executed after a cell further downwar ds.
however evenwiththisinformation notebooksarehardtoreproduce.ina 2019studybypimenteletal.
withastraightforwardsetting lessthan25 ofvalidnotebooks withdefinedpythonversionsand recorded execution order could be executed without errors and less than of them would actually produce the same results.
givenhowmanyscientificresultsnowarebeingproducedusing jupyternotebooks it istimefortheprogram analysisandtestingcommunitytomaketheirbestapproachesavailabletonotebook authors.butwith75 ofvalidnotebooksnotevenrunningwithouterrors thismeansthatthemajorityofnotebooksareactually inaccessible for any automated testing and analysis tool.
35th ieee acm international conference on automated software engineering ase this work is licensed under a creative commons attribution international .
license.
inthispaper wepresentanautomaticapproachtomakejupyter notebooks reproducible and in consequence available for analysis and testing.
our approach automatically identifies and satisfies dependenciesbetweenjupyternotebookcells reconstructingthe possibleexecutionordersthatreproducetheexactnotebookresults withouterrors.theresultingorderedcodecanthusbesubjectto testingandanalysis e.g.
enablingcontinuousregressiontesting for notebook contributors to ensure the reproducibility of their notebooks ourapproachthusformsanecessaryprerequisitefor furtheranalysisofnotebookcode.ifagivennotebookcannotbe reproduced our osirisprototype provides detailed debugging messages explaining to notebook users why reproducibility is not achievable.
thispaperisorganizedasfollows.afterdetailingtheproblem cf.
section we make the following contributions a study on the causes of non reproducibility.
we conduct a large scale reproducibility study about jupyter notebooks and manually summarise the root causes making notebooks non executable and non reproducible cf.
section .
making notebooks reproducible again.
we design and implement a prototype tool called osiris cf.
section which combines static analysis and dynamic testing to explore the possibilitiesofreproducinggivennotebooks.theresulting reordered code faithfully reproduces the results in the notebook sinceitisvalidprogramcode itisavailableforfurther testing and analysis.
since different users may require different amounts of reproducibility e.g.
some users may wish toreproduce allresultsasstated othersmayonlywishto re run the notebook possibly with different data osiris supportsanumberof matching andexecution strategiesto achieve the best result.
automatic diagnosis for non reproducible notebooks.
incase a notebook cannot be reproduced osiris features a targeted debugging module to infer and report failure causes.
our approach is effective in our sample osiris was able to reproduce .
of executablenotebooks cf.section which is a large improvement over the .
listed in state of the art .
after discussing the potential implication and limitations of our approach cf.
section we depict related work cf.
section and close this paper with conclusion cf.
section .
motivation let us start with some background and terminology.
repository notebook1 notebook2 main.ipynb utils.py cat.jpgimages figure the file structure of a simple jupyter notebookrepository.jupyter is used to refer to the jupyter application which provides the computational environment to allow the execution of notebooks.
notebook orjupyternotebook refersto theliterate programming document which contains the actual content e.g.
main.ipynbinfigure1 writtenbythe notebookauthors .similar totheworkofpimenteletal.
notebookandjupyternotebook will beinterchangeably used inthis paper.
independent python codewillbeusedtorefertopythoncodethatisnotdirectlypresented in a notebook but might be accessed by the notebook code.
forexample thecodeshownin utils.py cf.figure1 isregarded as independent python code.
notebook repository refers to the project where the notebooks are written and managed.
a notebook repository can contain multiple notebooks.
for example therepository shown in figure contains two jupyter notebooks i.e.
notebook1 and notebook2 .
jupyternotebooksaresequencesof cells essentially codecells andtext cells cf.
figure .
code cells contain executable python source code to generate results while text cells contain text that enables programmers to state rationales behind the code logic this textincludesmarkdownandhtmlforrichtext images formatting and more.
these combinations of these two cell types allows for literateprogramming implementedbyjupyterinan interactive computationalnotebookenvironment.thisenvironmentallowsparts of a notebook to be executed with immediate results including formatted texts and visual graphs.
import random from ipython.display import imagea random.randint print a in image .. images cats.jpg a bprint a in 110execution countercode cellthis is an example of jupyter notebookmarkdown cell outputc1 c2 c3 code cell indexb a a b print a b c5c4 in in in figure jupyter notebook example.
figure2illustratesasimpleexampleofanotebook.itcontains one markdown text cell and five python code cells.
all the code cellshavebeenexecutedasindicatedbytheexecutionmark e.g.
in shown in front of the code cells.
the execution mark tells 139not only the information that the code cell is executed but also the order when the cell is executed e.g.
in shows that thecorresponding code cell is the fifth executed cell .
the numberof the execution mark is also known as the execution counter of thecodecell.theoutputofacodecell shownrightunderit will always reflect the results of the latest execution i.e.
aligning with the execution counter .
it should be noted that a code cell can be either non executed or executed in a given notebook.
for non executed cells there will be no execution counters and outputs.
conversely for executed cells bothexecutioncountersandoutputs ifany willbegenerated forthem.moreover thecodecellscanbeexecutedbytheuser in anyorder andeachofthecellscanbeexecutedmultipletimes as longastheexecutioncounterisrespected.whenskipsofexecutioncountersexistinanotebook theactualexecutionorderofthenote bookcellsbecomesnon trivialtoreproduce asthecounterrecordsonly the last execution .
subsequently the skips make it difficult to automatically reproduce the results of the original notebook.
as an example consider the notebook shown in figure in which three execution counter skips i.e.
and are introduced.
the notebook cannot be reproduced by simply followingthe top down sequence of the code cells as well as the sequenceof execution counters.
for both cases the reproducing process will fail at c4 where the output will be rather than .2consequently weseethat reproducingnotebookexecutionscanbe achallenge thereisaneedforapproachesthatsupportusers inreproducingnotebookresults and ifanotebookcannotbe reproduced automatically there should be means to support users to do so manually.
reproducibility study tounderstandthenatureandextentofthereproducibilityproblem wefirstconductedalarge scalereproducibilitystudy eventually guiding the design of our automated approaches.
.
dataset collection how many jupyter notebooks are non reproducible and why?
to answer this question we apply the approach introduced by pimentel et al.
collecting a dataset of notebooks from github.
specifically wehave randomlycloned gitrepositories that have a file with jupyter notebook as identified language andhavepythonasthedeclaredprogramminglanguage.amongthe git repositories we further retrieve notebooks for experiments and evaluations.
basedonthedataset wefirstlookatthepythonversionstargeted by the notebooks.
among the notebooks of notebooks specifydetailedpythonversionrequirements.thetop 5targeted versions are .
.
.
.
.
.
.
.
.
.
.
the other provide only vague information such as python3 python .
1let us assume at this point that the output of c1is correct i.e.
the random function always returns .
2the correct execution sequence would be c1 c2 c4 c4 c5 c3 c3 c4.
3weselectonenotebookfromeachrepositorytoavoidpotentialbias wherenotebooks fromthesamerepositorymaysharesimilarproblemsforexecutionorreproducing.
for such repositories that contain multiple notebooks we simply choose the first one by directory ordering to form the dataset.
a of cells b max execution counter figure distribution of the number of cells left and themaximumnumberoforiginalexecutioncount right intheselected notebooks.
figure further presents the distribution of the number of cells andthemaximumexecutioncounteramongtheselectednotebooks.
themedianandmeannumbersare14and20forthenumberofcells and and for the maximum execution counter respectively.
the fact that half of the notebooks have more than code cells executedmorethan35times showsthattheselectednotebooks are actually serious notebooks suitable for this study.
.
execution environment setup to determine whether a notebook is reproducible we need an executionenvironmentforautomatedpythoncodeexecution.4unfortunately becauseoftheinfamousevolutionofpythonplatforms e.g.
python and python are not compatible with each other it is non trivial to properly set up the execution environment.
as an example the incompatibility of python versions forces pythonlibrarycontributorstomaintaindifferentversionsoflibrary modules e.g.
numpy or matplotlib that are often imported by jupyter notebooks.
specifically a given notebook may import a largenumberoflibrarymodules whichpersealsoimportmany other library modules.
it is hence non trivial to know the neces sary library modules beforehand when preparing the execution environment.
to produce consistent environments we make use of conda an open source library management system that supports automated libraryinstallationandupdating .condaalsoimplementsan environmentmanagerthatallowsdifferentexecutionenvironments suchaspython2andpython3 tobepreparedandconfiguredinthe samesystemwithoutinvolvingconflictsbetweenthem.inthiswork wesetupfourcondavirtualenvironmentsrespectivelyforthetop5 leveraged major python versions except .
discussed in the previoussection resultinginfourpre constructedenvironments for python versions from .
to .
.5for each of the four major pythonversions weinstallallthestandardpackagesintegratedintocondabydefault i.e.
theanacondarepository whichleadsto over library packages included in the execution environment.
4in this work we focus on python based jupyter notebooks only.
5wedecidenottopre constructtheenvironmentforpython2.7asthisversionisnow officially abandoned .
140table1 executableandreproduciblenotebooks.theexecution is done based on the order of cells execution counters.
python notebooks executable reproducible .
.
.
.
.
.
.
.
.
.
.
.
total .
.
.
experimental study now that we have execution environments we can execute all the notebooks in a suitable environment.
again following pimentel etal.
werunthenotebooksthroughtherecordedexecution counter of their code cells.
for instance regarding the notebook shown in figure the code cells will be executed via the following order c1 c2 c5 c3 c4.
becauseonlyfourpythonversions i.e.
.
.
areconfigured in the execution environment at the moment out of the 000notebooks e.g.
withpython2.7orwithoutexplicitlymentioningthedependingversion aredirectlyexcludedfromtheexecu tion.among5 870notebooks wefurtherfilteredout477notebooks that contain no execution records.
for the remaining notebooks table summarizes the execution and reproducible results.
theresultsareconcerning.tostart only17.
ofnotebookscanbe fully executed without error.
even worse among the executed notebooks only27.
ofthemcanbe exactlyreproduced.these results is more or less in line with the results reported by pimentel etal.
andstillsurprising aswewouldhaveanticipated that theexecution reproducibleratewouldbehighasjupyternotebooks are likely used for education .
.
root causes of non reproducibility letusnowexplorethereasons rootcauses whythemajorityof notebooks i.e.
cannot be executed or reproduced.
in this work we summarize the root causes in two types jupyternotebookscannotbefullyexecutedand jupyternotebooks can be fully executed but cannot reproduce the same results asoftheoriginalversion.recallthattheobjectiveofthisworkis torestorethereproducibilityofnotebooks.wewillhencemainly focus on the root causes of the latter.
forthecasewheregivennotebookscanbefullyexecutedbutthe resultscannotbereproduced ourmanualobservationhasidentified thefollowingreasonsthatmayleadtodifferentexecutionresults compared to that of the original execution.
we now summarize therepresentativeones togetherwiththeirabsoluteandrelative prevalence.
r1 randomness .
.
manyscientificcomputing programs require random functions e.g.
for sampling fromgaussian distributions or data shuffling.
they produce different results after each execution if no seed is given making it hard to determineiftheresultscanbereproduced.inourdataset around 276outof679 ofnon reproduciblenotebookscontainrandom functions.r2 time and date .
.
time functions are recurrentlyusedbynotebook authors roughly13 ofnotebooksin ournon reproducibleset toachievesomespecificfunctionssuch asevaluatingtimeefficiency loggingforsqloperations etc.since timechangescontinuously theoutputsofthetimefunctionalso vary everytime making ithard toascertain thereproducibility of the code.
r3 plots .
.
we see a considerable number ofnotebooksthatcannotbereproducedbecauseofdifferencesin plotted images.
indeed in some cases images are generated based oninputdataorrandomnumbersthatcannotbeensuredtoremainthesameeachtimewhenthenotebooksareexecuted.additionally therunning environmentcanalso impactplottingresults.
giventhe same inputs if different library versions are used the plotted images could also be different because of api improvements6 or change of default parameter values .7furthermore when the matplotlib moduleisnotproperlyinvoked theimagemaynotbe properly displayed.
instead there will be some warning texts relatedtopython smagicfunctions e.g.
matplotlib.lines.line2dat 0x7f24b114c3c8 that could be different from time to time.
among the image related non reproducible notebooks around of them are caused by incorrect usage of matplotlib.
r4 external inputs .
.
jupyternotebooksmay rely on external inputs data fetched from web servers such as webcrawlerdemonstration toexecute.however theexternalinputsaresubjecttochange suchasurldecay causinginconsistencies between the reproduced results and the recorded original results.
r5 floats .
.
in notebooks floating point numbersmaybeprinteddifferentlydependingontherunningmachines or the targeted python versions.
therefore the reproduced results relevant to floating point numbers might be different from the original ones.
r6 containertraversal .
.
inpython theorder inwhichsetsanddictionariesaretraversedisnotfixed.hence this order may differ across execution environments causing differing cell outputs.
in our non reproducible set of notebooks show this root cause.
r7 execution environment .
.
notebooks mayaccesstheexecutionenvironmentinformation e.g.
numberof cpus python package versions the memory location of variables etc.
that isusually specific to eachsetting and hence is different fromoneanother.moreover indifferentexecutionenvironments thesamedatamightbeprintedindifferentformats.forexample thenumber1mightbeprintedas1 .
.thematrix i.e.
two dimensional array mightbeprintedwithdifferentspacesbetweentheelements.
all these differences will impact the reproducibility of notebooks.
inappropriateexecutionorderofcells.
apartfromtheerrors raised by execution environments we also observe a significant numberofnotebooksthatfailtobeexecutedduetopoorcodequal ity e.g.
containing nameerrors undefinedvariables keyerror key not found in dictionaries syntax errors etc.
we found this amount of errors surprising as we would have expected code in notebooks to be of good quality.
indeed the notebooks are collected from 141publiclyreleasedrepositories forwhichmostofthemarerelated to educational materials for teaching inexperienced developers.
this fact hence motivates us to go one step deeper to check the reasons behind this kind of errors.
our manual observation reveals thatthese errorsare yieldedbecause the executionorder of cells is inappropriate e.g.
a variable is used before its definition .
since this problem is not caused by the execution environment wedecidetoconsideritasanotherrootcausemakingnotebooks non reproducible.
this root cause refers to problems that cause notebooks to be non reproducible because the code cells are not executedintheintendedorder.ideally iftheappropriateexecution order of code cells is respected the notebooks falling into this category would become reproducible.
in summary all of these findings will impact any approach that attemptstoreproduce test oranalyzejupyternotebooks.indeed even for executable notebooks it may not always be possible to reproduce the exact results as originally obtained.
in this work we thus attempt to resolve all the aforementioned non reproducible rootcauses r1 r7andinappropriateexecutionorder aimingto design an automatedapproach for restoringthe reproducibility of notebooks as much as possible.
osiris now thatwe haveidentified causesfor non reproducibility let us fix them.
we have implemented a tool called osiris which adopts different strategies to resolve the aforementioned root causes ofnon reproducibility attempting to maximize the execution and reproducibilityofnotebooks.osiristakesasinputajupyternotebookandoutputsthepossibleexecutionschemesthatreproduce the exact notebook results.
if osiris fails to reproduce the notebook itwillhighlightthelocationoffailures i.e.
non reproducible parts that could be useful for understanding the root causes of non reproducibility of jupyter notebooks.
figure4illustratestheworkingprocessofosiris whichismainly made up of four modules cell code parsing cell depen dency graph construction strategy based reproducing and targeted failure debugging.
we now detail these four steps respectively.
cell dependency graph constructionstrategy based reproducing targeted failure debuggingjupyter notebook execution reportscell code parsing figure the working process of osiris.
.
parsing cell code toanalyzethecodeinjupyternotebookcells wefirsthaveto parse it.
for this purpose osiris makes use of built in python parsers transformingpythoncodeintoabstractsyntaxtrees asts .special care is taken to handle and resolve importstatements as well astranslating syntacticsugarstatements8andlambdastatements9into analyzable normal forms.
.
resolving cell dependencies thesecondmoduleofosirisaimsatidentifyingandcharacterizing dependencies betweennotebookcells.bystaticallyparsingthecode cells osiris builds the so called cell dependency graph cdg to model the relationships.
technicallyspeaking acodecells dependsonthesetofvariables functions classes modules used defined or imported in the code snippets.agivencodecellcanbeexecutedaslongasallitsused variables are defined in the jupyter execution environment.
in thiswork weleveragetheclassicalproducer consumermodelto represent the define use relationship of variables in the code cells of a notebook.
giventheparsedabstractsyntaxtree ast ofacodecell c as illustrated in figure we calculate the stored and loaded variables including method calls and class initialization .
the stored variables definedfunctions classes importedmodulesareputintoa producersetwhile loadedvariables functions callsareaddedtoa consumerset.notethat withinacodecell ifavariableisproduced afterbeingconsumed e.g.
ainc2 thisvariablewillbeexcluded fromtheproducerset.thecallsofthebuilt infunctions e.g.
hash ascii willnotbeaddedintoconsumerset .hence thefinal producerandconsumersetsof c2ar e p c2 braceleftbig b bracerightbig c c2 braceleftbig a b bracerightbig .
b a a b print a module assign assign print name bnum 20name abinop name aadd name bname ap c2 b c c2 a b code cell c2 ast producer consumer sets figure generating producer consumer sets.
aftertheproducer consumersetsarecalculatedforeverycode cell osiristhenleveragesthisknowledgetoconstructacdgfor the notebook.in the cdg everycode cell becomesa node.
edges will be added if given two code cells or nodes say ciandcj have no conflicts between each other.
concretely an edge cj cican be added as long as the following constraint is respected c cj p cj p prime ci where p prime ci is the accumulated producer setafter ciisexecuted orreachedfromarootnodeinthecdg .
consequently after the execution of cj p prime cj p cj p prime ci i.e.
the produced set is the combination of the newly produced variables and all the previously produced ones.
.
itisworthmentioningthatagivennodeinacdgcanbereached from the root node via multiple paths.
hence the accumulated producer set may not be unique.
take the motivating notebook cf.
figure as an example as demonstrated in figure a c4can be reached from both c2andc3.subsequently the accumulated producer set p prime c4 could be p c4 p prime c2 orp c4 p prime c3 .
8syntactic sugarstatements e.g.
i a aredesigned to make thingseasier to read or express.
9lambda statements are usuallyused to concisely define functions.
forexample the followingsimplelambdastatement x lambdaa a 10actuallydefinesafunction 142c1 c3c4c2 p c3 c c3 b p c4 c c4 a b p c1 random image a c c1 a p c2 b c c2 a b c c4 p c4 u p c3 c c4 p c4 u p c2 a example of multiple pathsc1 c2 c2 c4c5 c4 c3c5 c4c3 c4 c4 c3c5 c3 c3 c3 c5 c5c5 c4 c3 c4 s1 s2 s3 s4 s8 s7 s6 s5 b full paths figure the possible execution orders of code cells w.r.t.
producer consumer constraints.
the left sub figure presents a simplified example of multiple paths while the right sub figure illustrates all the possible execution paths for the motivatingexample shown in figure .
.
strategy based reproducing as discussed in section we assume that osiris users may have different expectations and requirements regarding reproducibility.
osiris thus supports two types of strategies to be configured matchstrategyand executionstrategy.wenowdetailthesetwo types respectively.
.
.
match strategy.
wehaveintegratedthreematchstrategies into osiris strong match stage .
the reproduced results should exactly match the results yielded by the original notebook.
this matchingstrategyhasbeenusedinourpreliminaryreproducibilitystudyaswellasintheempiricalstudyofpimentel et al.
.
this matching strategy is needed by users who wanttoexactlyreproduceallresults weconsideritasthe baseline for reproducing jupyter notebooks.
weak match stage .
thereproducedresultsarethesamewhen repeatingtheexecutioninthesameenvironmentbutmay not match exactly to that of the original notebook.
this matching strategy targets users who are more interested in reusing and re executing the code rather than reproducing the exact results.
withthismatchingstrategy mostofthenon reproducible root causes categorized in r4 r7 are expected to be mitigated.
indeed let us take r4 as an example a given notebookdedicatedtoanalyzingagithubprojectwillbeupdated weekly.
since the github project is continuously updated theanalyzingresultswillbedifferentoccasionally.however if we launch the notebook twice with a short time interval in the same environment the analyzing results should be identical.
best effort match stage .
forcodecellsthatcannotbeweakly matched e.g.
r1 r3 osiris will go one step deeper to explore alternative means to reproduce the code cells aim ing to achieve weakly match with special consideration named x.whenstaticallyparsingthisstatement itshouldbeinterpretedas defx a return a i.e.
best effort match .
in particular osiris leverages a code instrumentation based approach to achieve the aforementioned objective.
given acode cell osiris attempts to transform it into a semantically equivalent version.
if the new version can be weakly matched we consider the original code cells can be matched with best effort.
again this strategytargetsuserswhowanttoreusethenotebookorparts of its code.
osiris has three antidotes to achieve best effort matches regarding randomness we attempt to configure a seed beforetherandomfunctionsbeingcalled.asillustratedin listing random functions may be used by various library modules which need to be addressed separately.
fortime date functions we select the time freeze tactic to mock the time related modules of python .
within thistactic allthefunctionsrelyingonthecurrenttimestamp such astime.time will return constant values.
asforplotsinvolvingthe matplotlib library weforcethe notebooktodirectlydisplaytheimage toavoidtheoutputof memory addresses by explicitly inserting a magic function i.e.
matplotlib inline at the beginning of the notebook.
for the random module of python 2random.seed for the random module of numpy sklearn and scipy 5numpy.random.seed fortimefunctions 8fromfreezegun import freeze time 9freezer freeze time 10freezer.start for matplotlib images maplotlib inline listing sample solutions for best effort match.
.
.
execution strategy.
thesecondtypeofstrategiesthatcan be configured in osiris is related to the execution of the notebook.
this strategy type allows users to specify how do they want to 143executethecodecellsinagivennotebook.sofar osirishasbeen equipped with three execution strategies.
original execution counter oec .
in this strategy the code cells of a given notebook will be simply executed following the order of the cells execution counters.
skipped counters e.g.
in figure will be simply ignored.
for the notebookpresentedinfigure2 theexecutionorderunderthis strategy will be solution s5 in figure .
all the experiments conducted in section are based on this strategy.
top down normal .
in thisstrategy thecode cellswill beexecutedfollowingtheir naturalorder from topto down.
for thenotebookillustratedinfigure2 theexecutionorderwill be solution s1 in figure .
cell dependency graph cdg .
thisstrategyattemptstoexecute the code cells of a given notebook in all the possible orderswithrespect totheproducer consumerdependencies.
like the aforementioned two strategies this strategy will only execute each code cell once.
regarding the notebook shown in figure this strategy will generate eight possible solutions for reproducing the notebook.
.
targeted failure debugging usingitsstrategy basedreproducingmodule osirisisnowcapable of exploring the reproducibility of a given notebook in different ways.someoftheattemptsmaynotbeabletoreproducetheresults even with weak or best effort matches .
when the reproducing attemptfails oreventheexecutionfails therewillbe mostlikely no logs orexecution tracesillustrating thereason whyit fails giving noclueforuserstounderstandandrefinetheirexecutionstrategies.
forthisreason osirisfeaturesa debuggingmodule.
givenanotebookandacodecellwherethereproducingprocessorexecution fails this module will then record the execution trace of the cell.
to this end we implement an instrumentation based approach to record the execution status at the client code side.
particularly for everycodelineofthespecifiedcell weinjectloggingstatements torecordthecurrentexecutionstate e.g.
thevariablesandtheir values the code line will be executed with.
for each line executed in the cell we record and compare a snapshot of all self defined variables and their states.
after cell execution osirislocatesthefirstsuspiciouslineinwhichthefreshly computed variable values are inconsistent with published values.
additionally osiris also highlights non repeatable code cells whichmaygeneratethesameoutputsbutwillyieldvariablevalues thatwouldimpactthesubsequentexecutionofothercells.inour motivatingexamplefromfigure2 allthefirstfourcells e.g.
c1 c4 arenon repeatableones.thesenon repeatablecellsmayprevent notebook reproduction if execution counter skips are present.
evaluation our evaluation addresses the following research questions.
rq1 can osiris build sound cell dependency graphs for jupyter notebooks?
rq2 to what extent can osiris improve the reproducibility rate of jupyter notebooks by varying the match strategies?
rq3 withdifferentexecutionstrategies canosirisimprove the reproducibility rate of jupyter notebooks?
rq4 canthetargetedfailuredebuggingmoduleofosiris help pinpoint the root causes for non reproducibility?
.
rq1 soundness of cell dependencies ourfirstresearchquestionconcernsthesoundnessofthecelldependencygraph cdg whichisimportantforosiristofullyexplore thereproducibilityofjupyternotebooks.indeed osirisleverages the cdg to generate all the possible execution paths when dependencyexecution strategy is enabled.
ideally if the cdg is sound all the paths generated based on it hereinafter referred to as cdg paths wouldbeexecutable whichmaynotbeabletofullyreproduce the notebook though .
to this end we transform the problem of checking the soundness of the generated cdg to the problem of checking the executability of cdg paths.
since the number of cdg paths is huge it is not practical to exhaustivelyexecuteallofthem.therefore foreachnotebooktobe tested we randomly select cdg paths to fulfill this experiment.
toavoidpotentialbiases e.g.
thenon executabilityisduetosyntax errorsinthepythoncode thisexperimentshouldonlybeconducted on notebooks known as executable ones.
therefore we choose the notebooks that are demonstrated to be executable in section as the input dataset to perform the experiment.amongthe936notebooks despitethatonly10cdg paths selected our approach finds that .
of them have all theselectedcdgpathssuccessfullyexecuted .
ofthem haveat least one cdg path failing and the remaining .
haveallcdg paths failed.
wefurtherlookintothereasonscausingcertaincdgpathsto fail in our experiment.
our manual observation reveals that the failsareindeedrelatedtothesoundnessofthecdgbuiltbyosiris.
the problems are mainly introduced by the static code analysis stepofosiris wherecertaincomplicatedjupyter pythonfeatures are overlooked.
listing presents a common challenge that keeps osirisfrombuildingasoundcdg.becauseosirisisnotawareof dictionarykeys itwillconsiderthatcell3isreachablefromcell1 sincetheproducer consumerdependencyisfulfilled.unfortunately accessing this unknown key will result in errors because the dictionary key is not registered yet.
the overlook of the aforementioned pythonfeaturessubsequentlyleadstoincorrectproducer consumer setsandtherebyresultinginunsoundcdgs.nonetheless wedo not observe any failures caused directly by the producer consumer dependencyalgorithm.thefactthatthemajorityofnotebookscan be successfully processed to generate executable paths shows that the cell dependency graph construction process is generally sound.
access unregistered dictionary key.
22a cell produce a 23a cell 24x a cell consume a listing an example of challenge that keeps osirisfrom building a sound cdg.
finally at the end of this research question we conduct one more experiment tocheck if is a goodnumber when randomly samplingthecdgexecutionpaths.tothisend werandomlyselect notebooks with cdg paths that can be successfully executed.
now inadditionto10paths wefurtherchecktheexecutionrateof 144table fraction of cdg paths that can be used to successfully execute notebooks.
username repository name vuddagiri mounica123 datascience .
.
.
.
willengel88 pandas homework .
.
.
.51rjsampa curso python pec2018 .
.
.
.00carlorizzante mitx6.
.
.
.
.
.
fgnt oaf .
.
.
.
ratnakumar nakka python .
.
.
.00novobura election analysis .
.
.
.00murrayluke dithering .
.
.
.
svenchilton springboard .
.
.
.
mc carthy pydsml .
.
.
.
table improvement of execution rate when varying the match strategies of osiris.
python notebooks strong weak best effort .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
total .
.
.
and100 paths.table2 illustratesthe10 selectednotebooks and additional execution results.
no matter which threshold is set theexecutionratesarekeptmoreorlessthesame.thisevidence suggests that is a good threshold for testing the cdg paths.
.
rq2 match strategies the second research question concerns the effectiveness of the match strategies implemented in osiris.
specifically given a set of non reproduciblenotebooks strongmatch viaoriginalexecution counter asexplainedinsection3 towhatextentcanourapproach with weak and best effort strategies improve the execution reproduciblerate?tothisend welaunchosirisonallthe936notebooksthathavebeenshownexecutableinourpreliminaryreproducibility study.
except for switching the match strategy to weak or besteffortstrategies we keepalltheotherparametersunchanged i.e.
thecodecellsareexecutedfollowingthesameorder i.e.
original execution counter .
table summarizes the execution results.
among the executable notebooks with weak match strategy the reproducible rate canbe doubled fromthat of theweak match increasingfrom .
to .
.
when best effort is enabled an additional of notebookscanbereproduced resultingin75.
ofreproducibility rate.
this significant improvement of the reproducible rate shows thatosirisisusefulandeffectiveforassessingthereproducibility of jupyter notebooks.
wefurtherlookintothebreakdownofthenumberofnotebooks that are additionally reproduced thanks to the best effort match strategy.
the majority of them are contributed by the random antidote.amongthe147additionallyreproducedcases wefindthatthe mainimprovementcomesfromtheantidotetorandomfunctions accounting for roughly notebooks.
the improvementsover time and image plot antidotes are and notebooks respectively.
our in depth analysis further reveals that our best effort approachmayhaveoverlookedsomenotebooks.forexample we additionallyfindthatthereare18notebooks outofthe227non reproducible ones having also accessed into random functions.
after manual investigation we believe that these overlooked notebooksshouldnotbeconsideredasfalsenegativesofourbest effortapproachsincetheerrorsarelikelycausedbydifferentreasons i.e.
not from the random function .
.
rq3 execution strategies we now look at the execution strategies introduced to osiris when reproducingjupyternotebooks.insteadoftheoriginalexecution counter whichhasbeenusedinalltheaforementionedexperiments we additionally launch osiris via normal top down and producer consumer dependency cdg strategies.
as discussed earlier thepossiblecdgpathsaregenerallytoomanytoexecuteall.
therefore aswithrq1 werandomlychoose10cdgpathstofulfill thisexperiment.aslongasonepathfromtherandomlysampled 10pathsiscapableofexecutingorreproducingthenotebook we will consider the notebook as such.
sincedifferentexecutionstrategiesmaybeabletoexecutedifferent notebooks10 we resort to the original notebooks for this experiment.asillustratedinfigure7 interestingly withbest effortmatchstrategy bothnormalandcdgexecutionstrategiesareable to improve the overall execution rate giving .
and .
respectively.
.
.
.
oec normal cdg a breakdown.crg normaloec cdg b venn diagram.
figure executable rates and notebooks achieved by vary ing the execution strategies of osiris.
intotal bycountingthethreeexecutionstrategiesasawhole osiriscansuccessfullyexecute1 435notebooks.figure8further illustrates the distribution of reproduced notebooks over the three strategies.amongthe1 435executablenotebooks 180ofthem havebeenshownreproducible givingareproducibilityrateof82.
which has more than tripled the rate of the state of the art and significantlyincreasedfromourresultsbyleveragingoecexecution strategy along .
this result experimentally shows that the execution strategies of osiris are indeed useful for restoring the reproducibility of jupyter notebooks.
10we hypothesize that not all the non executable notebooks are related to the inappropriatesetupoftheexecutionenvironment.therefore byleveragingdifferent strategies to execute those notebooks we might be able to find more executable notebooks withoutupdatingourexecutionenvironment.recallthatexecutabilityisnot the main focus of this paper.
145crg normaloec executed but not reproduced notebooks cdg figure reproducible notebooks among executable ones.
.
rq4 performance in locating faults via debug functionality as revealed in the previous section among the executable notebooks can not be reproduced by osiris.
in this research question welookatthetargetedfailuredebuggingmoduleofosiris aiming at evaluating the usability of this module towards locating the problematic statements making notebooks non reproducible at least by osiris .
to this end we apply osiris again with the targeted debugging module enabled and the first non reproducible cell as input to the non reproducible notebooks.
for each line ofcodeinthecell osiriswilldumptheexecutionstatusbeforeand aftertheexecutionofthecodeline.ifasuspiciouslineisidentified osiris will further report it as such.
toevaluatetheaccuracyofthedebuggingmodule werandomly select notebooks with suspicious lines reported and manuallychecktheresults.alltheselectednotebooksarehencemanually executed usingpredefinedexecutionstrategies.table4summarisestheexperimentalresults.forthe60samplesrandomlyselected our manual validation confirms that of them are correct giving anaccuracyat75 .thefalsepositivesaremainlycausedbytwo limitationsofosiris somecodelines e.g.
functioncalls will only change the outputs of the cell but may not alter the execution states.osiriscannotbeawareofthis.
osirismissessomedata types suchastheonesfromthird partylibrariessuchaspandas dateframe when recording and debugging execution states.
table4 performanceofosiris stargeteddebuggingmodule.
execution random true non repeatable strategy samples results notebooks oec normal cdg total the last column of table lists the number of non reproducible cells reported by osiris that are also non repeatable cells.
as it is similar to that of non reproducible cells there could be a strong correlation between non reproducible and non repeatable cells.
wehence conductanother experimentto evaluatethis suggestion empirically.werandomlyselecttwodatasets i.e.
100reproducible notebooks and non reproducible notebooks and launch osiris to check the number of non repeatable cells.
figure presents the a reproducible b non reproducible figure9 distributionofthenumberofnon repeatablecellsbetween reproducible and non reproducible notebooks.
distribution of the results.
a mann whitney wilcoxon mww test confirmsthatthedifferenceintermsofthenumberofnonrepeatable cells between these two datasets is indeed significant i.e.
p value is smaller than .
.
cliff sdeltaeffective size further explains that the correlation between these two datasets is strong indicating that nonrepeatablecellscouldbeoneofthemainreasonscausingjupyter notebookstobenon reproducible.therefore weencouragenotebookauthorstomitigatetheusageofnon repeatablecellstopromote the reproducibility of their jupyter notebooks.
discussion aimingatmaximizingthereproducibilityofjupyternotebooks our tool will be beneficial to both notebook authors and users.
notebook authors can leverage osiris to check the reproducibility of their notebooks before committing.
to ease the reproducibility for notebook users the reproducing details can be dumped and includedinthecommit.indeed webelievethatosiriscanbeconfigured as a regression testing tool that can be regularly e.g.
nightly executedtoidentifypotentialerrorsintroducedbythedevelopmentprocess.
notebookusers can leverage osiristo understandhow a given notebook which is released without giving any reproducing detail canbereproduced.theycanalsogaintheconfidencethat the notebook if reproduced by osiris is correct hence its codecan be trusted and reused even if the original output cannot be literallyreproduced.finally notebookresearchers candevelop new testing and analysis approaches for jupyter notebooks.
for example ourfellowresearcherscouldtaketheinitiativetomodifythe jupyterframeworktorecordalltheexecutionorders includingthe skippedones whichhascauseddifficulties e.g.
cdgconstruction to properly restore the execution sequences of notebook cells.
.
limitations insufficientsetupofexecutionenvironment.
asdiscussedin section the majority of notebooks fail to be executed due to library dependencies e.g.
import error because of missing modules orcontainremovedfunctionsduetoinappropriatelibraryversions .
this finding is similar to the one conducted by pimentel et al.
.
althoughinferringasufficientexecutionenvironmentisnotthefocusofthiswork webelievethathavingsuchanenvironmentwould 146significantly complement our work towards restoring the reproducibilityofjupyternotebooks.recently hortonandparnin have presented an approach to automatically infer environment dependenciesforpythoncodescripts.thisworkcouldbeleveraged to set up appropriate environments for executing and reproducing jupyter notebooks.
unsoundstaticpythoncodeanalysis.
atthemoment osiris hassomedrawbacksthatkeepitfromperformingsoundstaticanalysesofjupyternotebooks.
firstofall codecellsinnotebookscan be updated following successful execution e.g.
magic functions are likely to be removed after executing .
this execution history is unfortunatelynotrecordedandhencewillintroduceinconsistenciesbetweenthecodeandtheoutputs.second thevariablevalue in notebooks can be updated in succeeding cells which may cause runtime exceptions.
for example a matrix of m n defined in onecellcouldbereshapedtoa1 m n arrayinanothercell.different cdg paths may cause exceptions of dimension mismatches in matrix multiplication.
incomplete match execution strategies.
in all the current execution strategies each code cell will only be executed once whichhowevermaynotbethecauseinpractice.indeed thecurrent strategies cannot even reproduce the motivating notebooks shown in figure .
therefore we believe that there is a need toexplore other strategies that take into account cell dependencies whilerespectingtheexactexecutioncounterofthecells.thelength oftheexecutionordersshouldbeequaltothemaximumvalueof the execution counter in the given notebook.
in this work we furtherimplementanexecutionstrategyfulfillingtheaforementioned requirements.
while respecting the exact execution counter of the cells we additionally add random cells w.r.t.
the producer consumer dependency to all the skips in the execution counter.
.
threats to validity themainthreattothevalidityofthisworkliesinthesizeofour dataset though we started from real world jupyter notebooks which unfortunately maynotbefullyrepresentative .
we attempt to mitigate this threat by randomly selecting the notebooks from a large set.
to avoid potential biases we only select one notebook from each git repository that may contain multiple notebooks.sinceourapproachonlysupportspythoncodeanalysis we further limit the selected dataset to be python based notebooks only lettingseveralnotebooksinvolvingotherprogramminglanguages such as r and julia overlooked.
apart from the dataset our work also involves substantial manualwork.forexample therootcausesofnon reproducibilityare manually summarized based on our preliminary reproducibilitystudy.
the results of targeted failure debugging analysis are alsocharacterized manually.
such manual processes are known to beerror prone.
to mitigate the threat we have cross validated the results.
we also release our tool and dataset for public access.
furthermore wehavenoevidencetoshowthattherandomly selectednotebooksevaluatedinthisworkaredesignedtobereproducible.iftheyarenotintendedtobereproduced ourevaluation results might be impacted.
nevertheless as shown by rule et al.
jupyter notebooks havebeenrecurrentlyleveragedtosupportreproducibleresearchesand hence such impact should be neglected.
moreover a largenumber of notebooks cannot be executed e.g.
due to incorrect dependencies or unsupported python versions which may impact thegeneralityofoursampleset.tomitigatethis wehavemanuallysampledsomeoftheexecutablenotebooks.ourmanualobservation confirms that the randomly selected notebooks are not toy ones.
the fact that half of the notebooks have more than code cells also confirms this observation.
related work despite its popularity jupyter notebooks have not yet been well studiedbythesoftwareengineering se community.tothebestof our knowledge there are only a few such studies available to notebook authors.
wang et al.
have conducted a preliminary study on the code quality of jupyter notebooks.
they have empirically foundthatjupyternotebooksareinundatedwithpoorqualitycode e.g.
not respecting recommendedcodingpractices or containing unused variables and deprecated functions.
the authors argue that there is a strong need to programmatically analyze jupyter notebooks.ourwork byprovidingvalidprogramcode reorderedcodecell forexample anditscelldependencygraph canbeconsidered as the first attempt in the se community towards systematically analyzing and testing jupyter notebooks.
the work most closely related to ours is the one by pimentel et al.
.
the authors have conducted a large scale empirical study about the quality and reproducibility of jupyter notebooks.
unlike the work conductedby wang et al.
whichmainly focuses on the quality of the code presented in the notebooks our paper ismore focused on the good or bad practices used in the developmentofnotebooks.pimenteletal.
havealsoinvestigatedthe reproducibilityofjupyternotebooks.throughastraightforward approach the authors empirically find that only .
of their selectednotebookscanbeexecutedwithouterrors andonly4.
ofthemcanproducethesameresults comparedtothatoftheoriginal outputsofthenotebooks.theauthorshavealsosummarisedthe common root causes making notebooks non executable and hence non reproducible.asanimplication oftheirwork theauthorsarguethatthereisanopportunitytoimprovethereproducibilityrateinnotebooksbydevisingapproachesaddressingtherootcauses.in thiswork wetakeactiontoactuallydesignandimplementsuch an approach which combines both static and dynamic analyses to explore the possibilities of reproducing jupyter notebooks.
notebookshavebeenfrequentlyinvestigatedbyresearchersoutsideofsoftwareengineering .for example rehman et al.
address the reproducibility of jupyter notebooksbyenrichingtheprovenance basedsemanticsofinteractive notebooks.
their provbook prototype aims at capturing and viewing the provenance of notebook changes and thereby pro vidingameanstotrackcompletepathsofscientificexperiments.
yaniv et al.
designed simpleitk jupyter notebooks based on jupyter notebook an image analysis environment for researchers withdifferentlevelsofdevelopmentskills tofacilitatereproducible research.
keryetal.
fromthehuman computerinteraction hci community have conducted several studies in understanding notebooks w.r.t.
their literate programming features and untangling 147messy histories of notebooks.
by interviewing and surveying data scientists they have observed that notebooks are mainly used for scratchpad construction scripts preparation and knowledge sharing.
to combat the challenge of navigating messy version data topickouttherelevantinformationforagiventask theyintroduce an approach called verdantfor supporting lightweight interactions among many versions of code and non code artifacts in the editor.
similarly ruleetal.
alsolookatcomputationalnotebooks from the human factors point of view.
the authors have empirically found that via a large scale empirical study of computational notebooks on github computational notebooks may not always containexplanatorytextandonlyasmallsetofthemwilldiscuss thereasoningorresultsofthemethodsdescribed.ruleetal.
havealsonoticedthenon reproducingproblemofnotebooksand hence summarised the top simple rules for reproducibility in jupyternotebooks.theauthorsarguethatnotebookauthorsshould advocateinpromotingthereproducibilityofnotebooks.theyeven suggestthat notebookauthorsshouldask lab matesorcolleagues to try to run their notebooks to ensure their reproducible uses.
our work fully supports their claims i.e.
the reproducibility ofnotebooks is very important and supplement their claims with anautomatedapproachforhelpingnotebooksauthorscheckthe reproducibility of their notebooks.
ourworkfocusesonthereproducibilityofjupyternotebooks aimingatreconstructingtheexecutionordersthatreproducethe exactnotebookresultsandhencesupplementingthe implementation of advanced static and dynamic analyses of jupyter notebooks.
althoughthedef usehasbeenatraditionalmechanisminprogram analysis the relevant research on jupyter notebooks is still empty.theuniquenessofjupyternotebook scellstructurerequiresdef userelationtobebuiltforcodecellsinordertodeterminetheir dependencies.
thesoftwareengineeringcommunityhasinvestigatedthereproducibilityofothersoftwareartifacts .forexample toensurereproducibility researchershaveproposedvarious approaches to achieve record and reply executions facilitatebugreproductionsbyanalyzingexecutionlogsordumps andunderstandanddetectflakytestsorcompatbilityissues thatmakereproducibilitystudiesdifficult .asanotherexample renetal.
haveproposedanapproachtolocating the problematic files for unreproducible builds.
the authors claim that identifying unreproducible issues remains a labor intensive and time consuming challengedue to the diversity of rootcauses thatmayleadtounreproduciblebinaries.inlinewiththisresearch the authors further present a dedicated study focusing on locating suchrootcauses .ingeneral reproducibilityhasbeenconsidered a hard yet useful endeavor in the se community.
indeed as advocated by anda et al.
achieving more reproducibility in se remains a great challenge for se research education and industry.
conclusion motivatedbyalowreproduciblerateofjupyternotebooksreported by the state of the art and detailed in our study we present tothe se community the first work to automatically restore reproducibility of jupyternotebooks.
our osirisprototype explores all the possible execution schemes to reproduce as much of notebookresultsaspossible.intheevaluationofosiris weshowitiseffectivetorestorethereproducibilityofjupyternotebooks achievingasignificant improvement over the state of the art .
in particular our approach enables the use of static and dynamic analyses on jupyternotebooks whichcanbeusedfortesting empiricalstudies automatic repair techniques and more.
to help readers access our tool and replicate our experiments we make our tool osiris and scripts available at