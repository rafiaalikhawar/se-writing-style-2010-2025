if it s not secure it should not compile preventing dom based xss in large scale web development with api hardening pei wang julian bangert christoph kern security engineering research google fpwng bangert xtof g google.com abstract with tons of efforts spent on its mitigation crosssite scripting xss remains one of the most prevalent security threats on the internet.
decades of exploitation and remediation demonstrated that code inspection and testing alone does not eliminate xss vulnerabilities in complex web applications with a high degree of confidence.
this paper introduces google s secure by design engineering paradigm that effectively prevents dom based xss vulnerabilities in large scale web development.
our approach named api hardening enforces a series of company wide secure coding practices.
we provide a set of secure apis to replace native dom apis that are prone to xss vulnerabilities.
through a combination of type contracts and appropriate validation and escaping the secure apis ensure that applications based thereon are free of xss vulnerabilities.
we deploy a simple yet capable compile time checker to guarantee that developers exclusively use our hardened apis to interact with the dom.
we make various of efforts to scale this approach to tens of thousands of engineers without significant productivity impact.
by offering rigorous tooling and consultant support we help developers adopt the secure coding practices as seamlessly as possible.
we present empirical results showing how api hardening has helped reduce the occurrences of xss vulnerabilities in google s enormous code base over the course of two year deployment.
index terms web security cross site scripting languagebased security empirical software engineering i. i ntroduction the history of cross site scripting xss can be dated back to the last few years of the 90s.
ever since it continues to be one of the major sources of web security threats identified as a top vulnerability by the open web application security project owasp .
fresh industry reports disclose that to date xss is still among the most prevalent and exploitable security vulnerabilities in web applications .
according to hackerone one of the most popular security bounty award platforms xss tops the chart of reported vulnerabilities by volume through with the average severity being critical .
the vulnerability reward program hosted by google has awarded external experts millions of dollars for reporting xss bugs in google s products .
in general xss vulnerabilities stem from the lack of or inappropriate validation and sanitization of inputs to web applications from untrusted sources which later flow into a sink where the inputs are interpreted as executable code.
one of the most commonly exploited sinks is the document objectmodel dom apis in client side javascript code.
with the boom of single page applications spa more and more of the dynamics in web applications are now being handled by browsers making the threat of dom based xss more ominous than ever before.
xss vulnerabilities are often severe because they can bypass the same origin policy one of the foundations of the web application security model.
the reason why xss has been an undying security nightmare runs deep into the complexity and subtlety of the web technology stack.
mitigating measures such as the content security policy csp have been developed which make vulnerabilities harder to exploit but cannot eliminate them.
some mitigations such as xss filters and web application firewalls waf only passively block known categories of attacks and have subtle security issues themselves .
on the other hand active mitigations like html sanitizing and url escaping impose considerable cognitive load on developers requiring them to develop a deep understanding about how to properly handle untrustworthy inputs in different scenarios.
some organizations can install security training programs in an attempt to help engineers grasp that knowledge but oftentimes this is insufficient to prevent them from wirting xss prone code even for moderately complex applications .
in this paper we introduce api hardening a novel software engineering paradigm that proactively rids large web applications of dom based xss vulnerabilities.
instead of trying to mitigate or remedy security threats after the code is shipped our method focuses on security assurance in the early stages of software development.
by deploying a series of technical enforcement controls we firmly guide developers towards writing code that can be shown to be free of xss by a simple and fast analyzer blended into the compiler.
the technical aspects of api hardening are two fold.
first we extend the javascript and typescript compilers to forbid the use of dom apis that are susceptible to code injection.
these checks utilize type information but are otherwise flow insensitive therefore can be made extremely scalable.
second we offer a set of safe apis to allow developers to utilize xssprone apis in a secure way.
we introduce special types to designate values that are safe to use in the context of injectionprone dom sinks.
in this way all potentially dangerous dom ieee acm 43rd international conference on software engineering icse .
ieee manipulation and code execution are highly regulated.
indeed with api hardening developers are restricted to a strict subset of the dom apis.
in some cases this subset may not be sufficiently expressive.
to accommodate such use cases we establish a communication channel through which developers can request exemptions from some extended compiler checks for certain pieces of code.
an easy to follow protocol is designed to ensure those requests are appropriately reviewed by security experts.
approved exemptions are added into a centrally managed list that is automatically respected by compilers.
the practicality of our approach depends on an api design that is versatile enough to cover the vast majority of use cases encountered in practice so that the overhead of this exemption process is rarely encountered.
our study shows that the need for exemptions can be made very rare relative to the size of a humongous code base and a notably large developer community.
the adoption of api hardening requires a software development paradigm shift which can be extremely challenging in a large organization.
to render the adoption of api hardening as seamless as possible we carefully design multiple supportive mechanisms to help developers adapt themselves to the new apis and coding practices.
we have applied api hardening to real software production at google covering tens of thousands of engineers who develop some of the most complex web applications in the world.
the adoption of api hardening is at the scale of the entire company s javascript and typescript code base for over two years.
empirical data show that our approach has a significant contribution to reducing the occurrences of xss vulnerabilities in google s humongous code base.
analyses on communication logs between web developers and security experts demonstrate that the exemption review protocol associated with the api hardening adoption process is effective and scalable.
our contributions can be summarized as the following we propose api hardening a new software development paradigm that employs compile time security checks and safe api designs to effectively prevent xss vulnerabilities in monolithic code repositories owned by large software development teams.
we extend javascript and typescript compilers to capture known dangerous dom operations and offer developers a specially designed dom manipulating library.
the major part of these extensions has been open sourced.
see appendix afor availability details.
we developed a set of software engineering protocols to help tens of thousands of engineers in the same organization adopt the hardened apis without significantly degrading their productivity.
we collected and analyzed a rich amount of data during over two years of api hardening effort in realworld software development at google.
empirical results demonstrate that our approach is effective and scales to tens of millions of lines of code.
html title search results title body p you are searching spanid kw span p script constuntrustedinput newurlsearchparams location .search .get kw constkeyword document .getelementbyid kw 9keyword.innerhtml untrustedinput xss!
script body html fig.
example web application with a dom based xss vulnerability ii.
c ross sitescripting this section explains with a tiny yet representative example the concept of cross site scripting and what consequences a xss vulnerability can cause when exploited by malicious parties.
consider the code in fig.
1which illustrates a web search application.
it contains a client side xss vulnerability at line where the javascript code consumes untrusted user input and render it as html markup through the innerhtml property of a dom element.
in this example there is no dynamic server side page rendering.
it is a typical client side xss vulnerability aka.
dom based xss.
suppose this vulnerable application is served on app.com .
a malicious website evil.com can exploit the vulnerability by posting a url pointing to app.com on its own page.
it then tricks the users of app.com to click on it.
when a victim follows this url and gets navigated to app.com the search keyword encoded in the url is injected into the search page as html markup.
since app.com does not sanitize the query parameter evil.com can insert any content including malicious javascript code that can be executed in the context of app.com .1when that happens the capability of the malicious code is no longer restricted by the sameorigin security policy and can therefore abuse users trust on app.com .
what happens next is entirely at the discrepancy of the attacker.
they can read information private to app.com like cookies and send the information back to evil.com .
they can also choose to exploit a vulnerability in the browser to further launch more advanced attacks .
for readability the example in fig.
1is artificially simple which may convey a false impression that xss vulnerabilities are not difficult to detect or mitigate.
in reality the information flow from xss sources to sinks can be extremely complex and often goes through servers and databases .
traditional static analyzers have very limited capabilities to reason about this kind of software behavior.
1an example malicious url is himg 20src x 20onerror alert 27xss i. in this case the attacker utilizes the onerror event handler of an img tag to execute javascript code.
1361iii.
d esign most previous work on thwarting the threat of xss tackles the problem in the later phases of the software life cycle e.g.
whole application static analysis sophisticated automatic testing and run time protections in production .
as the functionality and complexity of software systems grow the loss caused by critical security flaws and the cost of remedying them after they manifest has skyrocketed.
in response to this trend our approach confronts the challenge in the very early stage of web application development and nips xss vulnerabilities in the bud.
a. overview api hardening operates by combining two technical components i.e.
a fairly simple and fast static security analyzer embedded in the compiler forbidding the use of the xssprone apis and a collection of specially designed types and apis that reduce the task of demonstrating the absence of xss vulnerabilities to a type checking problem.
most xss prone apis relate to certain combinations of dom elements and properties.
for example in fig.
the innerhtml property of html elements is an xss sink.
to prevent these apis from being used our compile time security analyzer walks the abstract syntax tree of a program and emits errors on all occurrences of such apis.
in that sense the analysis is flow insensitive since it does not consider any contextual information about these api uses and plainly asks the compiler to reject all of them.
however we do make use of type information to improve the precision of the analyzer.
for example the src property of an html element is by default an xss sink.
however src on img is an exception since no modern browsers will invoke the javascript execution engine when loading img tags even if the url provided by thesrc property has the javascript scheme.2with type information the analyzer can distinguish different kinds of html elements and reduce false positives.
indeed javascript is not a typed language.
however many javascript compilers can infer or allow developers to annotate their code with type information to capture programming errors and seize more optimization opportunities during predeployment transformations .
annotating javascript with types has become a common practice in web development.
there are now language variants of javascript that have native type systems e.g.
coffeescript and typescript.
therefore requiring type information for our api hardening analyzer does not incur additional cost in practice.
at google we support api hardening in both javascript and typescript.
almost all google s javascript code is annotated with static type information and developers are required to run a compiler on their code for optimization before deploying the code in production.
our javascript analyzer implementation is based on the closure compiler an open source javascript compiler capable of advanced type inference.
our typescript 2internet explorer is the last widely used browser known to be vulnerable to xss through the src attribute on img tags.analyzer is implemented by extending the official typescript compiler.
b. benefits effectiveness both the compiler and library augmented apis start to take effects from the very beginning of software development.
in contrast heavy weight program inspection tools require developers to allocate dedicated time to run the analysis over a mostly completed project and the feedback will likely not be available in real time.
various research suggests that code smells reported by an automatic analyzer after code has already been submitted are less likely to be addressed mostly because the developer has already moved on to another task.
our approach relies on a combination of standard type checks and custom security checks during regular compilation thus providing almost instant feedback to developers.
availability being an interpreted language javascript does not need to be compiled to run in browsers.
however it is now a common practice for web application vendors and publishers to perform a series of analyses and source tosource transformations using a compiler before deploying the applications such as obfuscation and minification .
google has a monolithic code repository and our engineers work within a unified compilation environment.
code with compilation errors is not allowed to be committed into the repository.
by embedding the analyzer into compilers it is automatically available to all developers and we can save massive delivery and education cost.
efficiency google engineers maintain over two billion lines of code a significant portion of which is javascript.
the javascript compiler is invoked an exceedingly large number of times on a daily basis for development and continuous integration.
engineers build their code using centrallymaintained distributed build infrastructure.
even tiny performance degradation of the compiler can cost a huge amount of extra cpu hours.
javascript is known to be unfriendly to static analysis .
employing advanced static xss detection algorithms in a code base of the size we consider is unlikely to be cost effective.
iv.
xss s inks a surprisingly large number of dom apis can cause xss if they are used with partly user controlled inputs .
the first step towards api hardening is to identify the originally dangerous dom apis aka.
xss sinks.
a. enumerate xss sinks essentially a dom api is prone to xss if and only if the javascript engine will be invoked to interpret the input of the api as executable code.
we collect such apis by examining the html and dom specifications which formalized as web idl document all canonical apis that can trigger 3for the sake of convenience in the rest of the paper typescript is regarded as a dialect of javascript.
all discussions related to javascript apply to typescript unless otherwise noted.
1362javascript code execution.
previous work relies on the same source to identify possibly misused web apis .
our analysis on the specifications are purely manual which is manageable since collecting xss sinks is mostly one time effort.
appendix blists the xss sinks we inferred from the html5 and dom specifications.
the specifications can cover most of the xss sinks found in practice.
however browser vendors may not fully follow specifications and can implement non standard features that are prone to xss.
an example of such features is content sniffing with which browsers may ignore the metadata of a data blob and interpret the type of the blob by heuristically analyzing its content.
skilled attackers can exploit this feature to manipulate browsers and carry out code executions not expected by web developers and users .
it is unrealistic to cover all browser specific xss sinks because many browsers have undocumented behaviors.
as our best effort we work with the developers of some mainstream browsers to stay informed about new browser features that may have security implications.
most of the time we do not consider ancient browsers which tend to carry more xss attack vectors.
this is not a problem since our web applications do not support those browsers either.
we would like to mention that many other xss countermeasures such as data flow analyses also need to identify a reasonably comprehensive set of xss sinks to be effective.
therefore enumerating the sinks are somewhat orthogonal to api hardening.
b. xss sink classification in total we have identified five kinds of xss sinks.
the classification is based on the mechanism bound to the sink that directs the javascript engine to execute untrusted code.
the rest of the section elaborates on the nature of each of these categories.
code execution sinks javascript and dom have several apis that accept string values and evaluate them as javascript code.
the interpreted code will run in the same context as these sinks.
if outsiders can control the values fed to these apis it will lead to the most straightforward cross site scripting exploits.
typical sinks of this kind include eval and theinnerhtml property of script .
url navigation sinks many dom apis interpret strings as interactive urls that navigate users to other web resources.
in modern web applications urls can have schemes with rich semantics attached and can direct browsers to perform complicated actions including executing arbitrary code.
for example following urls of the javascript scheme causes immediate code execution.
therefore dom apis accepting navigational urls are in general prone to xss vulnerabilities.
loadable url sinks in some cases dom urls are not for users to interact with.
instead they are used to instruct browsers to request and load additional resources needed to render web pages including executable javascript code.
typical examples include the src property of script and link elements.
attackers can perform cross site scripting by injecting urls pointing to contents they control.
the content security policy csp is a countermeasure against xss attacks through loadable url injection but there are many cases where csp is ineffective or can be sophisticatedly bypassed .
html sinks some dom sinks interpret string values as arbitrary html markup.
the most straightforward way to exploit those sinks is to inject javascript code marked by the script .
in some complicated attacks html sinks can be used to spawn other kinds of sinks.
css sinks there are dom apis in javascript for developers to dynamically control how browsers render html elements by changing their associated cascading style sheets css .
in ancient browsers like ie and ie javascript code can be embedded into css and will be executed when the style sheets are loaded.
although this is not longer the case in modern browsers with enhanced security academic research has revealed that css sinks can cause more subtle attacks.
for example one of the attack methods is to inject css configurations that make browsers perform time consuming ui rendering .
by monitoring how much time is spent in redrawing the ui attackers can infer the content of a web page at the character granularity.
strictly speaking this kind of attacks are not cross site scripting since they do not involve javascript code execution.
nevertheless they are similar enough for api hardening to keep css sinks on the list of banned dom apis with little additional cost.
in addition to the standard javascript and dom apis we also consider xss prone sinks in third party libraries that are commonly used inside our company.
for example the createdom function in the closure javascript library can create dom elements with some user provided values as attributes.
this is one of the most dangerous sinks that can lead to xss and therefore is included into our list of prohibited apis.
expanding the compiler checks to library functions fits well into our approach.
v. s afe api s with the xss prone apis identified and forbidden in development we need to provide developers with a set of hardened apis as alternatives.
these safe apis put limits on the manners in which developers can interact with the dom and javascript engine making it almost impossible for them to accidentally write vulnerable code without requiring every developer to have a deep understanding about the security nature of every component in the web development stack.
there are three components in the design of safe apis safe types.
these types designate values that are safe to flow to security sensitive sinks.
safe builders.
these are the factory apis that can produce values of safe types.
safe type values can only be constructed through these apis.
safe sinks.
these are the safe alternatives of the xssprone javascript and dom sinks.
unlike the original 1363dom sinks that accept strings safe sinks only accept values of safe types.
among these three components safe types are the connections between safe builders and safe sinks.
essentially the type checking process performed by the compiler proves that any values flowing into xss prone sinks are produced by an appropriate kind of safe builders.
a. safe types we designed six safe types to cover the major attack vectors in the javascript language and dom.
each safe type corresponds to a type of sinks as described in section iv.
css sinks are covered by two safe types.
the correspondence is displayed in table i. values of safe types denoted by safe values are immutable once created.
beneath the surface safe types are wrappers of primitive strings.
the internals of safe types are hidden from application developers through the implementation language s visibility and type encapsulation features.
in typescript we mark the internals as private properties of the type.
in javascript we implement additional compiletime checks that forbid any code from accessing the internal properties.
these private properties also prevent safe types from being confused with other user created types which is otherwise a problem due to javascript and typescript being structurally typed.
in structural typing the partial order of types is determined by the actual structures of the types instead of type names or places of declaration in contrast to nominal typing.
however safe types are essentially markers stating values are constructed by following certain contracts and therefore have to be nominal.
defining private properties is a common way to simulate nominal types in javascript and typescript.
our type encapsulation is not expected to be fully resistant to code that intentionally attempts to circumvent the intent of our hardened apis see section viii a rather we designed the types and corresponding static checks such that code trying to access the internals of safe types appears clearly nonidiomatic and stands out in code reviews.
b. safe builders builders of safe values are the crux of the security of api hardening.
in general safe values are secure for sensitive dom sinks because our static checks and apis ensure that they can only be constructed in manners known to be secure.
there are four ways of constructing safe values.
build from literal values recall that the nature of xss vulnerabilities is that defective code allows attackers to control what values can flow to security sensitive javascript and dom sinks.
literal values as they are hard coded by application developers cannot be manipulated by attackers.
therefore they can be safely converted to safe types.
it should be noted literal values are not inherently secure.
for example an engineer could hard code a loadable url that points to a third party domain from which arbitrary untrustworthy content could be loaded.
we treat this concern as out of thescope of api hardening and to which necessary additional mitigations apply.
since the values are part of the program text as literals they are clearly apparent to code reviewers and amenable to analysis by linters and presubmit checks.
build by sanitizing we have built sanitizers to automatically transform untrustworthy strings into safe to render html markup or safe to follow urls by removing parts that may lead to xss.
for instance the html sanitizer prunes sensitive tags and possibly vulnerable combinations of tags and attributes.
the url sanitizer prunes potentially insecure url schemes and parameters.
safe value builders based on sanitizing and escaping are convenient to use but they cannot fulfill the needs of many development tasks because sanitizers need to be conservative.
for example sanitizers strip all inline javascript code in html tags since they lack the context to decide whether the code is secure.
build from template template systems are commonly used in web development mostly for rendering large volumes of structural contents .
building safe values from templates can be regarded as a combination of building from constants and building by sanitizing.
the bulk of a template is static while some small parts of it can be configured by runtime values.
when rendering contents from a template the rendering framework ensures that the dynamically constructed contents are properly validated and escaped with respect to their context .
furthermore to qualify as a safe builder in api hardening the template has to be strict in its application of contextual escaping i.e.
it should not allow developers to suppress or alter the inferred context specific escaping in any way.
to facilitate composition the template system accepts values of our safe types for substitution in which case contextinferred validation and escaping can be temporarily suppressed in a type safe manner.
build from manually reviewed sources sometimes the previously mentioned builders are not expressive enough to support the needs of complicated applications.
we introduce a special type of builder to resolve this problem.
they are basically backdoors in the safe api design in the sense that they can cast any value to a safe value.
uses of these builders are subject to mandatory code review by a security expert.
we enforce the review requirement by classifying these builders themselves as prohibited xss sinks.
security reviewers allow uses of these builders by adding the code into the exemption list of the static security analyzer.
c. safe sinks safe sinks are hardened versions of xss prone javascript and dom apis.
typically safe sinks are type safe wrappers of the original apis.
in other words we built a natural transformation from the original sinks accepting plain string values to hardened sinks accepting safe values.
figure shows some examples of these trivially transformed sinks in typescript.
however not all safe sinks are trivial transformations of the original unsafe versions.
some of apis are made non trivial purely for convenience e.g.
they also support security efforts 1364table i safe types in api hardening safe type corresponding xss sink security invariant safescript code execution sinks javascript code that is safe for browsers to execute.
safeurl url navigation sinks urls that are safe for browsers to follow.
trustedresourceurl loadable url sinks urls pointing to resources that contain trusted javascript or css code.
safehtml html sinks html that is safe to render in a user s browser.
safestyle css sinks css declarations that can be safely used as in line style values of html elements.
safestylesheet css sinks css declarations with path selectors that are safe to evaluate as a style sheet in browsers.
navigate window to a new url.
window.location.href append new html markup to the current document.
document.write html a original apis signature of a safe setter for location href.
values assigned to the sink must have the safeurl type.
declare function safesetlocationhref loc location url safeurl void signature of a safe version of document write.
values appended must have the safehtml type.
declare function safedocumentwrite doc document html safehtml void navigate window to a safe url built from literal safesetlocationhref window.location safeurl.fromliteral append sanitized html markup to the current document.
safedocumentwrite document safehtml .sanitize html b hardened apis fig.
examples of safe sinks in typescript complementary to api hardening.
others exist because certain html tags have more complicated security contracts.
below are some examples of each case.
the hardened apis for setting the textcontent and src attributes of script tags additionally propagate the csp nonces so that the trusted javascript code is not blocked by browsers when dynamically inserted.
because the type of href is dependent on the value of rel therel andhref properties of link tags are merged into a single safe sink in hardened apis.
for example if rel is icon href should accept safeurl values if rel is stylesheet href should accept trustedresourceurl values.
we need a dependently typed api to cover this case and it would be difficult to allow the two properties to be separately assigned.
when setting the src property of iframe tags we make sure the sandbox property is also set to minimize the risks of loading untrusted pages inside our own applications.it is worth mentioning that the safe sinks is a more dynamic piece in api hardening compared with other components.
the design of the hardened apis should be constantly revisited as the engineering environment evolves.
we continuously collect developer feedback to improve the ergonomics of the hardened apis.
section videtails our effort from this aspect.
the run time performance cost of using safe types and safe sinks is mostly negligible since the security is enforced at compile time.
operations like html sanitization and csp nonce propagation can indeed introduce some overhead but they are not an essential part of api hardening.
even without employing safe types and hardened apis web applications will still need to perform these operations.
in certain cases api hardening even helps remove redundant dynamic security checks since safe types can statically propagate the security properties of the values.
vi.
a doption the technical materialization of api hardening is only the first step towards its adoption in an organization with tens of thousands of web developers.
we now introduce how we deploy the new static checks and safe apis across google.
a. deployment process api hardening itself is not a static technique but is constantly evolving as new vulnerabilities and attacks emerge.
in large organizations even a minor change to coding practices can affect a tremendous volume of code.
asking engineers to refactor their legacy code with hardened apis and pause developing new features would be prohibitively disruptive.
therefore it is essential to roll out api hardening checks and new apis in an incremental manner.
whenever we introduce new security enforcement we automatically exempt legacy violations so that existing code still compiles.
technically this can be achieved by customizing the compiler or the build system.
our team maintains the exemption list of legacy source files and approves changes made to the list through reviews.
there are two ways for an organization to eliminate legacy api violations.
the first choice is to actively refactor the code if the xss risks have been historically high.
otherwise when the code base is being developed at a rapid pace and the legacy code is expected to have a short life span the organization can choose to passively wait for legacy violations being cleaned up through product iterations.
at google we apply both methods on a per project basis.
for legacy violations sharing 1365a common pattern we use large scale code refactoring tools like refasterjs to generate patches at scale.
b. technical and operational support we have developed accompanying measures to help developers become familiar with the new coding practice.
the key objective is to allow developers to quickly unblock themselves when their code contains