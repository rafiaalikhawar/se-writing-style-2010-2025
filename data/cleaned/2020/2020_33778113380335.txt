mitigating turnover with code review recommendation balancing expertise workload and knowledge distribution ehsan mirsaeedi department of computer science and software engineering concordia university montr al qu bec canada s irsaee encs.concordia.capeter c. rigby department of computer science and software engineering concordia university montr al qu bec canada peter.rigby concordia.ca abstract developer turnover is inevitable on software projects and leads to knowledge loss a reduction in productivity and an increase in defects.mitigationstrategiestodealwithturnovertendtodisruptand increase workloads for developers.
in this work we suggest that throughcodereviewrecommendationwecandistributeknowledge andmitigateturnoverwithminimalimpactonthedevelopmentprocess.
we evaluate review recommenders in the context of ensuring expertiseduringreview expertise reducingthereviewworkload ofthecoreteam coreworkload andreducingthefilesatriskto turnover far.wefindthatpriorworkthatassignsreviewersbased onfileownershipconcentratesknowledgeonasmallgroupofcore developers increasing risk of knowledge loss from turnover by up to .
we propose learning and retention aware review recommendersthat whencombined areeffectiveat reducingtherisk of turnoverby buttheyunacceptablyreducetheoverallexpertise during reviews by .
wedevelopthe sofiarecommender that suggests experts when none of the files under review are hoardedbydevelopers butdistributesknowledgewhenfilesareatrisk.in thisway weareabletosimultaneouslyincreaseexpertiseduring review with a expertise of with a negligible impact on workload of coreworkload of .
and reduce the files at risk by far .
sofiaisintegratedintogithubpullrequestsallowing developerstoselectanappropriateexpertor learner basedonthe contextofthereview.wereleasethe sofiabotaswellasthecode and data for replication purposes.
keywords turnover knowledgedistribution codereview recommenders tool support acm reference format ehsan mirsaeedi and peter c. rigby.
.
mitigating turnover with code reviewrecommendation balancingexpertise workload andknowledge distribution.in 42ndinternationalconferenceonsoftwareengineering icse may23 seoul republicofkorea.
acm newyork ny usa pages.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation onthe firstpage.copyrights forcomponentsof thisworkowned byothersthan the author s mustbehonored.abstractingwithcreditispermitted.tocopyotherwise or republish topostonserversortoredistributetolists requirespriorspecificpermission and or a fee.
request permissions from permissions acm.org.
icse may seoul republic of korea copyright held by the owner author s .
publication rights licensed to acm.
acm isbn ... .
introduction turnover on software projects is frequent and inevitable and leads to the loss of knowledge when developers leave a project .
turnoverincurssubstantialeconomiccostinrecruitingandtraining newemployees itreducestheproductivityofdevelopment teams it leads to the loss of critical tacit knowledge and has been shown to increase the number of defects in a product and reduce overall product quality .
recentworkshavetriedtomitigatetheadverseimpactofturnover throughincreasingknowledgeretentionbypredictingleavers planning for succession documenting knowledge and persisting knowledge on stackoverflow and other internal qa forums .
however these mitigation practices often require organizational changesand additional developer effort especiallybythosewhoareexpertenoughtoanswerquestionsand write documentation .
inthiswork weshowthatcodereviewcanmitigateturnoverrisk because it naturally distributes knowledge by exposing developers to new code during reviews.
prior work interviewed developers and showed that code review is an opportunity for learning anditplaysavitalroleindistributingknowledge .
furthermore studies have quantified the knowledge gained during code review and shown that developers review code in modules they have not modified .
in contrast to other turnover mitigationstrategies codereviewisacommonandwell established practice in teams that does not require teams and individuals to alter their current workflow.
in this work we enhance code review s inherent knowledge sharingpotentialbydevelopingreviewrecommenderstodistributeknowledgeandusesimulationstoshowthattheymitigateturnoverrisk.incontrast existingreviewrecommenders aresolelyfocusedonfindingexpertreviewersanddisregardthe roleofcodereviewindistributingknowledgeamongdevelopers.
these recommenders result in expertise concentration because the evaluationbenchmarkishowmanyoftheactualdeveloperswho performed the review were recommended.
interviewed developers state thatthese recommenderssuggest obvious candidatesand do not provide additional value .
toevaluaterecommendersfromotherperspectives weintroduce three outcome measures that interviews with developers indicated asimportantaspectsofcodereview expertise coreworkload andfar.
the first outcome ensures that expertise remains high for finding defects during review.
the second ensures that the core developersare notunreasonably overworkeddue toalways being the top recommendation.
the third outcome measures the number offilesthatareatrisktoturnover far toensurethatknowledge ieee acm 42nd international conference on software engineering icse is adequately distributed during review.
we run simulations on the historical reviews of five large projects to understand howrecommenders affect each outcome.
for completeness we alsocalculate mean reciprocal rank mrr to understand how well eachrecommenderpredictsthedeveloperswhoactuallyperformed the review.
research questions rq1 reviewandturnover whatisthereductioninfilesatrisk to turnover when both authors and reviewers are con sidered knowledgeable?
recentstudieshavequantifiedknowledgelossfromturnoveron the basis of the commits that each developer has authored .
however theknowledgetransferthatoccursduringcodereviewis widelydocumentedwithpriorworkshowingthatreviewpromotes teamawareness transparency andsharedcodeownership .
we modify the previous turnover measure to consider both authorsofcodeaswellasreviewerstobeknowledgeableandrecalculatethenumberoffilesthatareatrisk far.withonlyauthors beingconsideredknowledgeableonaverage79 ofthetotalfiles areatrisktoturnover.whenweconsiderbothauthorsandreviewerstobeknowledgeable fardropsto32 .codereviewnaturally distributes knowledge.
rq2 ownership doesrecommendingreviewersbasedon codeownershipreducethenumberoffilesatrisktoturnover?
studies show that teams tend to assign reviews to the owners of files under review and experts who have modified or reviewed the files in the past .
we implement simple ownershiprecommendersthatsuggestreviewersbasedonthefilesthat developers have modified or reviewed in the past.
weshowthatassigningreviewersbasedonpriorcommits authorshiprec or prior reviews revownrec increases expertise by .
and .
respectively while increases turnover risk far by .
and .
.
we conclude that concentrating expertise on the top developers make projects susceptible to knowledge loss from turnover.
rq3 chrev doesastate of the artrecommenderreduce the number of files at risk to turnover?
we review the literature on review recommenders and find that most mine historical review information.
unfortunately we did not find working implementations or replication packages for any of the existing recommenders.
for comparison purposes we reimplement chrev which has been shown to outperform other recommenders .
when re evaluate chrevon our outcome measures we find that like the ownership recommenders chrev increases thelevel of expertiseby .
andhas the addedbenefit of reducing coreworkload by .
.
unfortunately chrev concentrates knowledge and increases the risk of knowledge loss through turnover by .
.
rq4 learningandretention canwereducethenumber offilesatrisktoturnoverbydevelopinglearningandreten tion aware review recommenders?
weproposetwoknowledgeawareproxiesforestimatingknowledge distribution and retention.
learnrec ensures that a developer who has not reviewed or modified all of the files currently under review will be proposed.
retentionrec recommender ensuresthat non transient developer who have commitment to the project arerecommended.assigninglearnersthrough learnrec substantiallyreduces expertise .
butcounter intuitivelyitmakes the project drastically more susceptible to knowledge loss from turnover as less committed developers are recommended far of .
.suggestingcommitteddevelopersthrough retentionrec is the most successful strategy in ensuring experts .
during review but has the greatest increase in coreworkload .
.
rq5 sofia canwecombinerecommenderstobalance expertise coreworkload andfar?each of the previous recommenders has a focus and cannot simultaneously balance the out comes.
our final recommender sofia assigns either experts or learnersbasedonthefilesunderreview.ituseschrevwhenthe filesunderreviewarenotatriskanduses turnoverrec whenfew developers know about the files under review.
this multi focus strategy improves all outcomes simultaneously.
sofiaincreases the level of expertise during review by .
while having a minor impact of .
on coreworkload and reduces turnover risk with a far of .
.
weintegrated sofiatomakerecommendationsforgithubpull requests and to recommend both expert and learning developers.
thesofiasource code is publicly available along with the data in a replication package this paper is organized as follows.
in section we provide the study background as well as defining our measures review recommender scoringfunctions andsimulationmethodology.in section we describe the projects under study.
in section we present results for each of our research questions.
in section we describe the sofiabot which integrates into github pull request.
in section we discuss threats to validity.
in sections and we discuss our findings in the context of the existing literature and conclude the paper.
background and definitions in this section we introduce the background on ownership review recommenders andknowledgelossandshowthemannerinwhicheachhasbeenquantifiedinthepast.wewillsubsequentlyusethesemeasuresasthebasisonwhichtoexpandreviewerrecommendation in a scoring function that will also be knowledge aware.
.
the ownership recommenders theinfluenceofcodeownershiponcodequalityhasbeenextensively investigated in the literature .
ownership is a human factor that helps with finding knowledgeable developersthat can be accountable for a particular part of code or task .
developer recommenders use ownership to automatically assign tasks to experts .
researchers have used a wide range of granularity from lines to modules to estimate ownership of developers.
studies on code review find that code owners are usuallyselectedtoreviewchanges .inthisworkwedevelop two simple scoring functions for review recommendation based on ownership.
authorshiprec .birdet al.
definesthecodeownershipfora developer in a module as the ratio of commits the developer hasmaderelativeto thetotalcommits madeto thatcomponent.our authorshiprec scores a developer d as a candidate reviewer based 1184on the number of commits he or she has made to the files under review r dividedbythetotalnumberofcommitsmadetothese files.
authorshiprec d r commitsforfilesunderreview d r summationtext.1devs dcommitsforfilesunderreview d r revownrec .thongtanunam et al.
deviseareviewaware ownership metric based on the files that a developer has reviewed.
intuitively reviewers who have reviewed the changed files or modulesinthepast willbegoodcandidatereviewers.torecommend reviewers we score the number of times a candidate has reviewed thefilesinthepastdividedbythetotalnumberoftimesthefiles have been reviewed.
revownrec d r reviewsoffilesunderreview d r summationtext.1devs dreviewsoffilesunderreview d r .
the chrevrecommender there is a large literature on review recommendation .wenotethatwedidnotfindareplicationpackageor recommenderimplementationforanyoftheseworks .weonly re implementchrev becauseitincludesawiderangeoffactors in its recommendation and has a higher accuracy than the other review recommenders such as revfinder .
chrevscorescandidatereviewersbytheexpertise frequency andrecencyoftheirpastreviews.first chrevtakesthenumberof comments made by a candidate on a file as a proxy for expertise.second chrev considers the number of work days a developer has worked on a file as a proxy for measuring effort.
third chrev weights recent reviews more highly.
chrevdefinesthe xfactor d f asthemeasureoftheexpertise for a developer don a filef.cf wf andtfrespectively show the numberofreviewcommentscontributedby dforf thenumberof workdays dhasdedicatedoncontributingcommentson f andthe last day that dworked on f. to provide a denominator cf prime wf prime andtf primeindicatethetotalnumberofcommentsmadeon f thetotal numberofworkdaysspentoncommentingon f andthetimeof the most recent comment on f respectively.
xfactor d f cf cf prime wf wf prime tf tf prime tocomputethescoreofacandidatereviewerforagivencode review they sum up the xfactor d f that the candidate d has on the files in the change f. .
the turnover mitigating recommenders thefocusofexistingrecommendersonexpertsdisregardstheother benefits of code review such as knowledge sharing.
rigby and bird reportthat codereview increasesthe numberof files developersseebybetween100 and150 .inthiswork wespeculate thatcodereviewcanbeeffectiveinmitigatingtheturnover induced knowledgeloss.baseduponthisidea wedesignreviewerrecommenders that either distribute or retain knowledge.
.
.
distributing knowledge.
wethendefineacandidate sknowledgeofreviewrequestasthenumberoffilesunderreviewthata candidate has modified or reviewed in the past divided by the total number of files under review.
reviewerknows d r numcommitorreviewedfiles d r numfilesunderreview r equation4 assignsdeveloperswithknowledgeofthecodeunder reviewandensuresexpertopinionsbutconcentratestheknowledge of these files exacerbating the risk from turnover.
learnrec .todistributeknowledgeamongthedevelopers weinverse the reviewerknows d r function to understand how many newfilesadeveloperwillgainknowledgeofifheorsheisassigned thereview.welimittherecommendertoonlydisplaycandidates thatknowaboutatleastonefileunderreview.wethenscorethe remainingreviewersusingthe learnrec recommendertomaximize learning through the scoring function learnrec d r knowledge d r .
.
developer retention.
developerswhohavemadesubstantial recent contributions to a project have demonstrated a high degree ofcommitmenttotheproject .incontrast assigningareview toadeveloperwhoistransientandwilllikelyleavetheprojectis antitheticaltothegoalofretainingprojectknowledge.wedefine commitmentandcontributionconsistencymeasurestorecommendreviewerswithahighpotentialofremainingontheproject i.e.high retention potential.
in contrast to the previous measures which are atthepullrequestorreviewlevel theretentionisdoneataprojectwide level.
contributionratio.
we measure the contribution of potential of a developer d by the number of reviews and commits he or she hasmadeinthelastyeardividedbyallthecommitsandreviews on the project.
contributionratio d totalcommitreview d summationtext.1devs dtotalcommitreview d consistencyratio.
it is common for developers to make substantial contributions to a feature and leave the project after the featureis complete.toavoid assigningreviews totransientdevelopers wedefinethe consistencyratio365 d astheproportionof months a developer has been active in the last year.
consistencyratio365 d activemonths d retentionrec .wedevelop retentionrec thatsuggestsreviewers whowhoareunlikelytoleavetheproject.thescoringfunctionfor a candidate review dis retentionrec d consistencyratio365 d contributionratio d .
.
distribution and retention combined.
turnoverrec .to ensurethatknowledgeisdistributedamongdeveloperswhoarelikely 1185to remain on the project we define the turnoverrec recommender scoring function for a developer and review as turnoverrec d r learnrec d r retentionrec d sofia turnoverrec andchrevcombined when the files under review have many developers who know about them it is best to suggest an expert.
in contrast when the number of knowledgeable developers is low knowledge should be distributed among the development team.
our final recommender sofia combines the chrev which is designed to find recent experts and turnoverrec whichisdefinedtodistributeknowledgeamongdevelopers who have high retention potential.
given the function knowled eable f that returns the set of developers who have modifiedorreviewedfile f sofia d r selectseithera chrev d r score or a turnoverrec d r score as defined in the cases below braceleftbigg chrev d r if knowled eable f d anyf f r turnoverrec d r otherwise weconsiderfilesthathavenoknowledgeabledevelopersorthat arehoardedbyasingledevelopertobeatrisk.asresult weconsider a review that has a file with or knowledgeable developers to haveapotentialforknowledgelossfromturnoverandsodistribute knowledge and set d .
.
simulation and evaluation to evaluate reviewer recommenders prior works made recommendationsforeachexitingreviewandcomparedtheirresultagainst theactualreviewerswhoperformedthereview .
to compare with the actual reviewers we use the mean reciprocal rank mrr and evaluate eachrecommender.mrr is theaverage of the inverse rank of the highest ranked correct recommendation.
forexample ifacorrectrecommendationisonaveragethethird recommendation the score would be .
acriticismofpriorworkscanbefoundinkovalenco et al.
s interviewswithdeveloperswhostatethattherecommendersrarely provide additional value because they suggest obvious expert candidatereviewers.thisproblemisinherentintheoutcomemeasure whichassumesthattheactualreviewerswerethebest i.e.
correct reviewers.kovalenco et al.
suggeststhatweneedtoaccount forother perspectivesand outcomesbeyond simplyattempting to predict the actual reviewers.
to evaluate the impact of reviewer recommendation on diverse outcomes we perform simulations.
simulation requires us to re place the actual reviewer with a recommended reviewer and toevaluate the outcomes over a period of time.
the simulation involves sequentially making recommendations for each review on a project.totraineachrecommender weusetheentirehistoryprior tothereview.therecommendersconsiderthefilesunderreview and accordingto the formulas definedin sections .
.
and .
they randomly replace one of the actual reviewers with the toprecommended reviewer.
for example if deva actually reviewedthe files but is replaced with top recommended devb then the knowledgefromthereviewwillbeattributedtodevb notdeva forfuturerecommendationandforoutcomemeasurement.weonlyrandomlyreplaceonedevelopertoavoiddisruptingthepeerreview process and becausekovalenco et al.
showed thatdevelopers usually already know at least one expert review candidate.
to evaluate how each recommender changes the project we measurethreeoutcomes thedegreeofreviewer expertise reviewer coreworkload and the number of files at risk to turnover far.
these measures incorporate the reasons interviewed developers conduct review .
we measure the change in the outcomes over the standard quarterly period .
each measure is calculatedasapercentagechangerelativetotheactualreviewerswho performedthereview.forexample ifarecommenderreplacesan expertreviewerwithanon expert learner wewouldexpectthe measures to report a percentage decrease in expertise and a percentage increase in the knowledge distribution of the development team.
we define each outcome measure below.
expertise .having high expertise ensures having high quality codereview .wemeasurethe expertise forareviewasthe proportionoffilesunderreviewthattheselectedreviewershave modified or reviewed in the past i.e.the union of the files that the reviewers know about.
we sum the expertise across the reviews per quarter q. expertise q reviews q summationdisplay.
rfilesreviewersknow r filesunderreview r coreworkload .to ensure high retention potential of reviewed files anaiverecommendercouldsuggestonlycoredeveloperswho arebothexpertsandarecommittedtotheproject.sucharecommenderwouldleadtoadrasticincreaseinthecoredeveloperworkload.
to measure the workload we find the reviewers who have performed the most reviews in a quarter top10reviewers q and sum the total number of reviews that this top group performed coreworkload q top10reviewers q summationdisplay.
dnumreviews d q far.we need to quantify the project s exposure to turnover fromknowledgeloss.buildingonrigby et al.
s definitionof knowledge loss we define the quarterly files at risk far a st h e number of files that are known by zero or one active developers.
giventhefunction activedevs q f thatreturnsthesetofdevelopers who have modified or reviewed the file f and have not left the project at the end of the quarter q we define far q far q f f files activedevs q f the raw outcome measures do not facilitate easy interpretation orcomparison.wereportthepercentagechangeforarecommender relative to the actual reviewers.
sincepercentagechangeisatrivialformula weillustrateitonly for coreworkload coreworkload q simulatedcoreworkload q actualcoreworkload q the simulation results for an ideal reviewer recommender increasesexpertise during review with a positive percentage change in expertise reduces coreworkload with a negative percentage 1186table1 sizeofprojectsunderstudy.weexplicitlyselectfor large long lived projects.
name total files reviewed prs yearsdevelopers corefx coreclr roslyn rust kubernetes change in coreworkload and reduces the number of files at risk far with a negative percentage change in far.
project selection and data we explicitly select well established large projects with many completedcodereviews.onsmallerprojects reviewerrecommendation islessmeaningfulasthepotentialsetofreviewsissmallandthe developers are often aware of the entire team.
to select projects wefirstquerythegithubtorrentdatasettofindprojectswithmore than10kpullrequests .wethenapplythefollowingmanual selection criteria we need existing reviews so or more of the commits must be reviewed.
we need to simulate across time so the project must be or more years old.
weneeddiverseknowledgeandmodules soweensurethere are at least 10k files.
fiveprojectsmetourselectioncriteria.oftheseprojects corefx coreclr androslynareledbyindustrybutareavailableunder anopensourcelicenseandaredevelopedintheopenongithub.
rust andkubernetes are community drivenoss projects.
table provides the summary statistics including the number of files pull requests andcommits.ourreplicationpackagecontainsalinkto the project data .
.
gathering data we gatherauthorshipcommitdata fromgitand reviewdatafrom github.weclonetherepositoriestoextractallcommitsandcorresponding changes.
on github reviews are conducted in pullrequests that allow the authors and reviewers to discuss eachchange .
in this study we consider an individual to be a reviewer of a pull request if he or she writes a review comment on a file asksforfurtherchangesfromthe author orapprov es rejectsthe pull request.to gatherand cleanthe requireddata wedeveloped a post processing pipeline which we make publicly available .
unifying developer names.
when a developer makes commitsusinghisorhergithubusernamewecanlinkthiswiththe email address they use in the git commit.
in some cases the author commits without using a github username and we use a nameunifying approach that employs edit distances to match the git emailnameswithgithubusernames.thisapproachissimilarto bird set al.
s and canfora et al.
s .
leavers.
robillard et al.
showsthatusingthelastcommitas anindicatorfordepartureofdevelopersdrawssomerisks.basedon this finding at the end of each quarter we consider the knowledge of a developer to be inaccessible if he or she has no contributionin the subsequent four quarters.
we exclude the last quarter ofprojects from analysis to ensure that we do not mistakenly label adeveloperasaleaveriftheyhavegoneonvacationforamonth more.
excludingmegacommits.
rigbyet al.
arguethatcommits withhundredsoffilechangesaretoolargetobefullycomprehended by the author.
in manual analysis of mega commits and review requests we find that they tend to be superficial changes includingrenamingafolder renamingafunctionthroughoutthesourcecode changing commented trademarks of files or importing a large chunk of code from a different source control system to git.
we do not associate any knowledge to the author or reviewer of changes with or more files.
in this work we limit our study of knowledge to code files including .cs .java and .scala.ourreplicationpackagecontainsthe full list of file types .
we also exclude changes made by bots review comments that are made after the code has been merged unmerged pull requests and files that were committed without review.
results in this section we discuss the results for our research questions relating to an empirical study of knowledge distribution during review recommendationsbasedonownership recommenda tionsbasedonthestate of the art chrev learningandretention aware recommenders and sofiawhich combines the best recommenders.wemakethreenotes first wenotethatrq1doesnot involve simulation and is an empirical result based on the actualreviews and commits.
second we note that the mrr outcomes doesnotinvolvesimulationandinsteadreportshowaccuratelythe recommender predicts the actual reviewers.
third simulations are run for each recommender and we note the changes in expertise coreworkload and far as a percentage difference relative to the actual values for each project.
table shows the average for each outcome across all projects.
.
rq1 review and turnover whatisthereductioninfilesatrisktoturnoverwhenbothauthorsandreviewersareconsideredknowledgeable?
recentstudieshavequantifiedknowledgelossfromturnoveronthebasisofthecommitsthat each developer has made .
the assumption in these works is that knowledge is only attained through writing code.
however the knowledgetransfer that occursduring codereview iswidely documented with prior work showing that review promotes team awareness transparency andsharedcodeownership .
rigbyandbird quantifiedtheadditionalknowledgeattained duringreviewandreportedthatcodereviewexposesdevelopersto between100 and150 morefilesthantheyedit.thongtanunam et al.
addedthatdeveloperswhohavenotmadeanychangesto a module contributed by reviewing to of the code changes in the module.
in this section we consider both authors of code as well as reviewers to be knowledgeable and calculate the number of files that are at risk when turnover occurs.
to assess the extent that the project is at risk to knowledge loss fromturnover wemeasure far seeequation13 whichmeasures thenumberoffilesthathavezerooroneactivedevelopersattheend 1187table the proportion of total files that are at risk to turnover.whenonlyauthorsareconsideredknowledgeable theproportionoffilesatriskisdrasticallyhigherthanwhenboth authors and reviewers are considered knowledgeable.
far authors authors reviewers corefx .
.
coreclr .
.
roslyn .
.
rust .
.
kubernetes .
.
average .
.
of each quarter.
to mirror prior works we calculate the farauthor which only considers authors to be knowledgeable .
we then calculate far which considers both authors and reviewers as knowledgeable.
table reports the proportion of files at risk relative to the total filesontheproject.themedianrawvalueperquarterof farauthor is and files for corefx coreclr roslyn rust and kubernetes respectively.
as a percentage of the codebase between and of the files are at risk of abandonment.incontrast whenboththeauthorandthereviewerare considered knowledgeable the median raw value per quarter of faris respectively.
as a percentage ofthecodebase between22 and45 ofthefilesareatriskofaban donment.asapercentageincreaseinfilesatriskfor farrelativeto farauthorweseethat74.
.
.
.
and65.
fewerfilesareatriskofabandonmentforcorefx coreclr roslyn rust andkubernetes respectively.weconcludethatconsidering reviewersto be knowledgeableofthefilestheyreviewdrastically reducesfarand gives a clearer picture of the risk a project is at to turnover than prior works that only considered authors to be knowledgeable .
whenonlyauthorsareconsideredknowledgeableanaverage of .
of files are at risk to turnover.
when reviewersarealsoconsideredknowledgeablethe faraverageis .
.thereissubstantialknowledgedistributionduring code review.
.
rq2 ownership doesrecommendingreviewersbasedoncodeownershipre duce the number of files at risk to turnover?
studies show that teams tend to assign reviews to the owners of files under review and experts who have modified or reviewedthefilesinthepast .inthisresearchquestion we runsimulationstoshowhowrecommendingreviewersbasedon ownership affects project outcome measures.
authorshiprec .priorworkshaveadapteddevelopertaskrecommenders thatusehistoricalauthorshipdatatorecommendreviewers .wepartiallyreproducetheseauthorship recommendations by using the scoring function defined in equation .
we use the simulation method described in section .
and evaluate the impact of authorshiprec on mrr expertise coreworkload and far.
the average values are shown in table .
authorshiprec is successful in predicting the reviewers who actually performed the review with an mrr of .
.
.
.
and .
for corefx coreclr roslyn rust and kubernetes respectively.
the average across all projects is .
.
this implies that on average the actual reviewer is ranked .
.
from the simulations we see that assigning reviewers based on their commit ownership i.e.authorship increases the expertise in reviewsby7.
.
.
.
and12.
respectively with an average of .
across the projects.
the coreworkload increases forrust by .
whileit is reducedby .
.
.
and .
for the other projects with an average of .
.
although expertise is high for each review farhas risen across allprojects by28.
.
.
.
and .
withanaverage of .
.
developerswhohaveauthoredthefilesunderreviewareclearly experts.
however suggesting past authors as reviewers concentratestheknowledgeofthesefilesandputstheprojectatgreater risk to turnover as non authors are not suggested as reviewers.
revownrec .the majorityof reviewrecommenders haveused historicalreviewdata i.e.whohasreviewedwhichfilesormodules inthepast torecommendreviewers .wepartially reproduce these review ownership results by using the scoring functiondefinedinequation2.weusethesimulationmethodology and outcome measures as described above.
revownrec isslightlylesssuccessfulatpredictingthereviewers who actually performed the review with an mrr of .
.
.
.
and .
for corefx coreclr roslyn rust and kubernetes respectively.theaverageacrossallprojectsis0.
.whichmeans the actual reviewer rank is averaged to .
.
from the simulations we see that assigning reviewers based on the files theyhave reviewed in the past increasesreview expertise by .
.
.
.
and .
respectively with an average of .
across projects.
these individuals tend to be top reviewers and we see a corresponding increase in coreworkload of .
.
.
.
and .
with an averageof .
.
despite the high utilization of expert reviewers thisrecommender has the largest increase in files at risk with far valuesof9.
.
.
.
and0.
withanaverage of .
.
recommending reviewers based on the files they have reviewedinthepastensuresexpertiseduringreview average increase of .
but increases the workload of thetopreviewersbyonaverage20.
anddifferfromthe set of actual reviewers with an average mrr of .
.
concentrating expertise on the top developers substantially increasestheriskofknowledgelosswhenturnoveroccurs on average by .
.
.
rq3 chrevrecommender does a state of the art recommender reduce the number of files at risk to turnover?
chrevbuildsuponpriorworkthatleveragesinformationinpast reviews but also accounts for the number of days a candidate reviewer has worked on a file and the recency of this work see section2.2forfurtherdetails .
chrevhasbeenshowtooutperform theotherreview basedrecommenders includingrevfinder .
in this research question we re implement this state of the artrecommender and re evaluate it.
we use the simulation method described in section .
and evaluate the impact of chrevon mrr expertise coreworkload and far.
in the original chrev paper the authors report an average mrr of.67acrossfourprojects .onourprojects chrevhasanmrr of0.
.
.
.
and0.
forcorefx coreclr roslyn rust and kubernetes respectively.
the average is .
.
this implies that onaveragetheactualreviewerisranked1.
.althoughthemrr is lower in our reproduction than in the original study we notethat for mrr chrev outperforms all of the other recommenders we consider.
from the simulations we see that like the ownership recommenders chrevincreases the expertise in reviews by .
.
.
.
and13.
respectively with an averageof .
across projects.
however unlike revownrec it reduces the load on top reviewers.
the corresponding values for coreworkload are .
.
.
.
and .
with an average of .
.chrevconcentrates knowledgeand increases the project s risk to turnover with a farincrease of .
.
.
.
in corefx coreclr roslyn and rust respectively and for kubernetesthe farisreducedat .
.theaverageof faracross all projects is .
.
chrevremains accurate in suggesting actual reviewers with an mrr of .
.
it increases the degree of expertise during review by .
while reducing the coreworkloadon the top reviewers by .
.
however the risk of turnover increases with an average far of .
.
.
rq4 learning and retention canwereducethenumberoffilesatrisktoturnoverbydevelopinglearningandretentionawarereviewrecommenders?
the previous research questions have demonstrated that existing review recommenders concentrate knowledge on experts increasing the riskof knowledge loss fromturnover.
furthermore intwolargeindustrialsettings kovalenco et al.
interviewed developersand foundthat suggestingprior review expertstends torecommend reviewers that are obvious to the author of the change.
theystatethatmakingobviousrecommendationsleadstoalack of use of recommenders.
they envision a new research path fornext generation of recommenders that go beyond suggesting experts.inthisresearchquestion weinvestigatehowwecanmitigate turnover inducedlossanddisseminateknowledgeusinglearning and retention measures.table the average of outcome measures across the projects.mrrisshownforreplicationpurposes.individualproject outcomes are discussed in the paper text.
the idealrecommender increases expertise positive expertise reduces workload negative coreworkload and reduces files at risk to turnover negative far .
recommender average across projects mrr expertise coreworkload far authorshiprec .
.
.
.
revownrec .
.
.
.
chrev .
.
.
.
learnrec .
.
.
.
retentionrec .
.
.
.
turnoverrec .
.
.
.
sofia .
.
.
.
learnrec .without review recommenders development teams naturally distribute knowledge during review by assigning reviewers who would benefit by learning about the files under review .buildingonthisidea insection2.
.
wedefinedascoring function that determines how many files a candidate reviewer will learnabout.weensurethatthecandidateknowsatleastoneofthe files that is under review.
in this way we spread knowledge but ensure that the reviewer has some relevant knowledge.
we use the simulationmethoddescribedinsection2.4andevaluatetheimpact oflearnrec on mrr expertise coreworkload and far with the average outcomes shown in table .
learnrec does a poor job of predicting the reviewers who actuallyperformedthereviewwithanmrrof0.
.
.
.
and .
for corefx coreclr roslyn rust and kubernetes respectively.
the average across all projects is .
.
this implies that onaveragetheactualreviewerisranked8.
.however thegoal ofthisrecommender wastoensurethatdevelopers learnandthis shows that it suggests unexpected reviewers.
from the simulations we see a substantial decrease in expertise .
.
.
.
and .
respectively with an average of .
across all projects.
the coreworkload is drastically reduced as fewer expert reviewers are assigned reviews .
.
.
.
and .
with an average of .
.
the goal of this measure is to distribute knowledge and reduce turnover.
counter intuitively we see an increase in the files atriskwith farvaluesof16.
.
.
.
.
with an average of .
.
by selecting non experts learnrec recommendstransientdeveloperswhohavelesscommitmenttothe project.
therecommendationssubstantiallydifferfromactualreviewers mrr .
.
learnrec substantially reduces expertise .
butsuggestslearnersreducingthe coreworkload by .
.
counter intuitively it makes the projectdrasticallymoresusceptibletoknowledgelossfrom turnover because it assigns reviews to learners who are less committed to the project far of .
.
1189retentionrec .assigningreviewstotransientdevelopersmay distributeknowledge butdoesnotreduceturnover.insection2.
.
we define a measure that captures how frequently developers contribute to the project and the number of months in the last year thattheyareactive.weensurethatthecandidateknowsatleast oneofthefilesthatisunderreview.ourgoalistoassignreviewsto committeddevelopers.weusethesamesimulationmethodology and outcome measures.
retentionrec doessimilarlyto revownrec atpredictingthereviewerswhoactuallyperformedthereviewwithanmrrof0.
.
.
.
and .
for corefx coreclr roslyn rust andkubernetes respectively.
the average across all projects is .
.
this implies that on average the actual reviewer is ranked .
.
from the simulations we see an increase in expertise of .
.
.
.
and19.
respectively withanaverageof .
.thesepercentagesarehighestforanyrecommenderoutperforming ownership recommenders at ensuring expertise during review.weseeacorrespondingincreasein coreworkload of23.
.
.
.
and47.
withanaverageof29.
.however unlike the ownership and chrev recommenders we see areduction in the files at risk with far values of .
.
.
.
and .
with an average of .
.
clearly retentionrec selects committed developers who are unlikely to leave the project.
retentionrec is the most successful in ensuring experts .
during review while reducing the risk of knowledge loss from turnover .
.
however by focusing on the most committed developers it also has the greatest increase in coreworkload .
.
the mrr of .
indicatesthattheactualreviewersaremorediversethanthe recommendations.
turnoverrec .we showed that distributing knowledge through learnrec does not alleviate knowledge loss and retentionrec increases the coreworkload .
we combine these approaches to distributeknowledgebuttodistributeitamongindividualswhohavea higherretentionpotential.throughequation9 wedefined turnoverrecthat multiplies the learning measure by the retention measure.
again we ensure that each candidate knows about at least one file.
we use the same simulation methodology and outcomes.
turnoverrec does a poor job of predicting the reviewers who actually performed the review with an mrr of .
.
.
.
and .
for corefx coreclr roslyn rust and kubernetes respectively.
the average across all projects is .
.
this implies that on average the actual reviewer is ranked .
.
from the simulations we see that similar to learnrec recommender the expertise hasdecreasedby .
.
.
.
and .
respectively withanaverageof .
.however in terms of coreworkload there is only a slight increase of .
.
and0.
incorefx coreclr andkubernetesanda reduction in roslyn and rust by .
and .
with an averageof1.
.thefilesatriskarereducedwitha farof .
.
.
.
and .
with an average of .
.turnoverrec combines learning and retention recommendersandhasthegreatestreductioninturnoverrisk far .
.
however there is a substantial cost in the reduction of expertise .
and a minor increase in coreworkload .
.thelowmrrvalueof0.19indicates that developersnaturally focus on reviewers withgreater expertise than turnoverrec .
.
rq5 sofia can we combine recommenders to balance expertise coreworkload andfar?
not all reviews contain files that are at risk of abandonment.
as aresult wedonotneed todistributeknowledgeon thesefilesbecause there is already a sufficient number of developers to mitigateknowledge loss from developer turnover.
in equation we define sofiathat distributes knowledge during review using turnoverrec whentherearefilesatriskofabandonment.incontrast whenall the files have active developers sofiauses thechrevscoring function to suggest recent experts.
of the and reviewed pull request on corefx coreclr roslyn rust andkubernetesaround1 .
.
.
.
and17.
containfilesatrisk.theremainingpullrequestsuse chrevrecommendations to ensure concentrated expertise.
we use the simulation method described in section .
and evaluate theimpact of sofiaon mrr expertise coreworkload and far with average outcomes shown in table .
sofiadoesagoodjobofpredictingthereviewerswhoactually performedthereviewwithanmrrof0.
.
.
.
and0.
forcorefx coreclr roslyn rust andkubernetes respectively.
the average across all projects is .
.
this implies that on average the actual reviewer is ranked .
.
from the simulations we see that by only distributing knowledge when files are at risk and otherwise suggesting experts sofia inherits the best characteristics of turnoverrec andchrev.
the expertise goes upby .
.
.
.
and .
respectively withanaverageof6.
.intermsof coreworkload weseea reductionof .
and .
incorefxandcoreclr anincreaseinroslynof .
andaslight increaseof0.
and1.
forrust and kubernetes.
the average of coreworkload is minor at .
.
sofiadistributesknowledgetodeveloperswhohaveahighretention potential and reduces the risk of turnover as measured by a decrease in far of .
.
.
.
and .
with an average of .
.
thesofiarecommenderdistributesknowledgewhenthere are files under review that are at risk of abandonment andsuggestsexpertswhenallfilesalreadyhavemultiple knowledgeabledevelopers.thisstrategyallowsustoincrease the level of expertise during review .
while havingaminorimpacton coreworkload .
andsubstantiallyreducingthenumberoffilesatriskby .
.
sofiaalso does a reasonable job of predicting the actual reviewers with an mrr of .
.
1190figure an example of sofiarecommending both learners and experts for the corefx project.
the sofiab o to ng it hu b codereviewisknowntohavemultiplepurposeandoutcomesfrom findingdefectstodistributingknowledge .ourtool design allows developers to make an informed selection balancing the need for experts and learners.
we created a github application that will recommend reviewers based on the combination ofchrevwithturnoverrec asthesofiabot.feedbackfromdevelopers showed that the rationale behind a review recommendation is required .forthe sofiabotwedisplaysimplifiedmeasuresto complementadeveloper sintuitionanddomainexpertiseonwho should review the pull request.
implementation.
thesofiarepository with the source code and the straightforward installation instructions are publicly available .
once installed sofiaprocesses the entire history of the project to be able to recommend reviewers.
sofiauses github webhooks to scan submitted commits and reviewed pull requests to keep recommendations up to date.
sofiacan operate in two modes fullyautomatedorlistcandidates.inthefullyautomatedmode foreachpullrequest sofiaassignsthetopscoringcandidatetoperform the review.
in figure sofiadisplays a list of candidates when the pull request is created or when the sofia suggest command is issued box a in figure .
the sofiabot displays the ranked list of potential reviewers box b .
in box c in the figure the author can select the person with the highest expertise.
or if learning is more importantthey can select the developer who would learn about the most files boxd .theauthorcanalsoissuethe sofia suggest learners orsofia suggest experts if he or she is only interested in a particular type of candidate.
tohelpwithtooladoption thedisplayedmeasuresaredesigned to be quick and easy to interpret by pull request authors and are majorsimplificationsofthescoringfunctionsdefinedinsection2.
.
the ownership dimension maps to the files authored and the files reviewed fields which are simplified to show the proportion offilesunderreviewthatthecandidatehasauthoredorreviewed in the past respectively.
learning maps to the new files field which is simplified to the number of files that the candidate would 1191learn about i.e.they have not modified or reviewed.
retention potentialmapstothe activemonths fieldwhichissimplifiedto the proportion of months that the developer has been active in the previous year.
thegoalofourtoolistocomplimentadeveloper sintuition.for example ifadeveloperfeelsthathighexpertiseisrequired heor she might choose the top candidate in figure box c stephentoub who has in the past modified of the files under review has reviewed all of the files under review and has been active in months in the last year.
sofiawill warn developers that in a review thereisatleastonefileatrisk topofboxb .thedevelopermay thenselectthebest learner reviewcandidatefromboxd danmosemsft.
although he has never modified the files under review he has reviewed of and has also been been active in of thelast months.
finally hughbe has both expertise and wouldalso learn about new files.
he has authored of of the files un der review reviewed of the files and would learn about new files.hehasalsobeenactive5ofthelast12months.
sofiamakes recommendations but provides a simple rationale for each review candidate allowing the developer to select the best reviewer given their intuition and the review context.
threats to validity generalizability.
we selected large and successful open source software projects that were led by either industry or a community.
onsmallerprojects thereisnoneedforreviewerrecommendation because the list of candidates is small and obvious to all devel opers.
future work is necessary to validate our results in other development contexts.
construct validity.
following prior works on review recommendation ownership and turnover weusethesourcecodefileastheunitofknowledge.knowledge is contained in other documents and at other unit levels.
we leave these investigations to future work.
we have also provided formulasforeachofourmeasuresandscoringfunctionstofacilitate replication.
theknowledgeacquiredbyareviewerwillbedifferentfromthe knowledge of the author.
the author will usually know more of thedetails whileanexpertreviewermayknowmoreaboutother modules and dependencies.
in this work we consider both authors and reviewers to be knowledgeable and able to work on the files whenturnoveroccurs.futureworkisrequiredtounderstandthe different types of knowledge that authors and reviewers have.
randomlyreplacementofareviewer.
inoursimulation we randomly select one of the reviewers in each review to be replaced with the top recommended reviewer for each recommender see section .
.
table showed that we examine over 80k reviews across5projects makingitunlikelythatthisrandomselectionwill lead to systematic bias.
as a further check over a period of four months were ranourtoptwotechniques chrevandsofia aminimumof215timesforeachproject.for chrev weseeachangeof .
.
.
and .
percentage points for mrr expertise coreworkload and far respectively.
thecorresponding values forsofia are .
.
.
and .
percentage points respectively.theresultsremainconsistentwith sofiaincreasing expertisewithaminorincreasein coreworkload whiledrasticallydecreasing far.
coreworkload threshold wedefine coreworkload tomeasure the reviews performed by the top reviewers on a project see equation12 .whilefutureworkcoulduseproportionbasedcore teams weusedthisvaluebecauseitsimplifiedourfunctionsand representedareasonablyconsistentpercentageofreviewsacross thestudiedprojects and37 forcorefx coreclr roslyn rust and kubernetes respectively.
replicationandreproducability.
existingrecommendersincluding reviewbot revfinder and chrev do not provide a replication package or sourcecode for their recommenders.
asaresult were implementedchrevforcomparisonbecauseit outperform other state of the art recommenders.
we also imple mented simple authorship and ownership recommenders.
com paring each recommender with existing baseline recommenders reducesthethreatofinternalvalidity.wemakeallofourcode data and github sofiabot available for future researchers as well as for use on software projects .
discussion and literature we position our findings in the research literature.
we discuss how we advance our understanding of code review practice mitigation of turnover risk through far and evaluate reviewer recommender systems on diverse outcome measures.
.
understanding code review practice fagan introduced software inspections in with a detailed experiment that conclusively showed that inspection found defects earlierin thedesignprocessand thatunrevieweddesign artifacts leadtodefectsthatslippedthroughtolatterstagesincreasedoveralleffort.inthesubsequent40years codereviewhasbeenextensively studied.
early works focused on examining the process .
however porter et al.
demonstrated that process was much less of a factor than ensuring expertise during review.
current codereviewpracticefavorsalightweightprocessthatfocuseson expert discussion of changes to the system that still improves software quality .
we show that retentionrec has the highest expertise among all expert recommenders with an average of .
.
revownrec andauthorshiprec that focus on ownership have an average of .
and .
respectively.
we also found that focusing on learners will reduce expertise by up to .
.
recent works that interview reviewers find that experts tend to be overloaded with their review workloads and that it is oftendifficulttofindanavailableexpertreviewer .moreover it has shown that high overall workload could lead to poor review participation and requesting feedback from experts can leadtodelaysfromlackofavailabilityandalsofeweropportunities forknowledgedissemination .weshowthattherelationship between expertise andcoreworkload is not straightforward.
for instance chrevandauthorshiprec improvethe expertise whileat the same time reduce the coreworkload by .
and .
on average respectively.ontheotherhand turnoverrec drastically reducesexpertise by .
whileincreases the coreworkload by .
and sofiaimproves the expertise with a negligible change of .
incoreworkload .
.
turnover induced knowledge loss and mitigation turnoverdeprivestheprojectoftheleaver sexperienceandknowledge and has been shown to increase the number of defects .
previous research has quantified the knowledge loss from turnover and shown that projects with very high turnover aresusceptibletoasmuchasfivetimestheexpectedloss .
however these works considered authorship as the only way of gaining knowledge about files.
incontrastwithpriorwork weincludetheknowledgegained from conducting reviews into the turnover risk calculations because interviews with developers show that code review is anopportunity for learning and it plays a vital role in distributingknowledge .
two separate studies quantified the knowledge gained during code review and showed that at both google and microsoft code review doubles the number of files that developers know.
furthermore thongtanunam et al.
showed that reviewers of modules are often not authors of the module .
in section .
our empirical results show that review naturally reducesturnover risk.
we show thatwhen only authors areconsideredknowledgeableanaverageof79 ofthetotalfiles areatrisk.whenbothauthorsandreviewersareconsideredknowledgeabletheaverage faris32 .thisreductioninfarshowsthat substantial knowledge is attained during code review.
in this work we design recommenders that explicitly distribute knowledge by suggesting reviewers who would learn about the filesunderreview.weshowthatbydistributingknowledgeamong developers who have a higher retention potential there is a far reduction of .
and .
for turnoverrec andsofia which outperformschrevwhichincreases farby4.
.theadvantageof using code review in mitigating knowledge loss is that it adds littleadditionaleffortbecausecodereviewisalreadyacommonpractice on software teams.
in contrast prior works on turnover mitigation suggest increasing documentation with blogs formalizing the process of documenting bugs in issue trackers and participatinginstackoverflowandinternalqaforums .eachstrategy requires additional developer effort especially for developers who are expert enough to answer questions and write documentation.
.
recommenders identifying the right reviewers for a given change is a challenging and critical step in the code review process .
inappropriate selection of reviewers can slow down the review process or lower the quality of inspection .
the research on reviewer recommendersfocus onthe problemof automatically assigningreviewrequeststotheexpertdeveloperswhoaremost likely to provide better feedback .
advanced recommenders have been proposed which are built uponmachinelearning textmining andsocialrelation graphs .
however these papers do not provide public implementation of their recommenders.
re implementing and testing these recommenders against our outcome measures is beyond the scopewesetforthispaper.wehopefutureworkwillexaminetheserecommenders and we release all our code and data to facilitate replication and advancement of review recommenders .
the existingrecommenders have been evaluated using accuracy metricssuchas top kandmrrthatmeasurehowaccuratelythe recommendationsmatchtheactualdevelopersthatwereinvolvedin a review.
this evaluation is based upon the assumption that actual reviewers were among the best candidates to review a change .
however itisreportedthatthefocusonaccuracyrarelyprovides additionalvaluefordevelopersbecausetherecommendationsare obvious .
furthermore in teams with strong code ownership findingrelevantexpertsisnotproblematic .forreplicationcompletenesswecalculatedmrr.ourresultsconfirmkovalenco et al.
s findings that a broader perspective is needed when evaluating recommenders.
we showed that recommenders with similar mrr valuesmayhaveentirelydifferentimpacton expertise coreworkload andfar.
for instance revownrec andretentionrec have a difference of .
in mrr while the difference between their far is .
.
learnrec andturnoverrec have a difference of .
in mrr while the difference between their coreworkload and far is .
and .
.
concluding remarks inthisstudy weprovideanovelevaluationframeworkforreviewer recommenders based their impact on expertise coreworkload and filesatrisktoturnover far .weshowthatselectingreviewers solelybasedonownership expertise orlearningproxymeasures does not balance all three outcomes and leads to a knowledge concentration low knowledge retention or low expertise.
theoutcomeofthisworkis sofiathatcombinesthestate of theart expert recommender chrev with the learning and retention recommender turnoverrec .thisbi functionalrecommenderadapts itselftothecontextofthereview.itdistributesknowledgewhen therearefilesunderreviewthat areatrisktoturnover butotherwise suggests experts.
through simulation we show that sofiais theonlyrecommenderthatbalancesthethreeoutcomessimultaneously.thisstrategyallowsustoincreasethelevelof expertise during review by .
while having a minor impact on workload coreworkload0.
andreducingthenumberoffilesatriskwith a far of .
.
werelease sofiabotasanopensourcesoftwarethatfullyintegrateswithgithubpullrequestsandprovidesreviewerrecommen dations.
the recommendations complement a developer s intuitionandexperiencebyprovidingsimplerationaleforeachreviewcandidate such as showing how active a candidate has been how many files he or she would learn about if they performed the review and howmany of the files underreview they havemodified orreviewed in the past.
to the best of our knowledge existing reviewer recommendersincludingmicrosoft scodeflow andgoogle s gerrit do not explicitly recommend reviewers based on distributingknowledgetoreduceturnover.futureworkisnecessary tofullyevaluate sofiaandtounderstandthecostsandbenefitsof recommending learner reviewers in practice.