closing the gap a user study on the real world usefulness of ai powered vulnerability detection repair in the ide benjamin steenhoek1 kalpathy sivaraman renata saldivar gonzalez yevhen mohylevskyy roshanak zilouchian moghaddam and wei le department of computer science iowa state university ames ia usa microsoft data ai redmond wa usa abstract security vulnerabilities impose significant costs on users and organizations.
detecting and addressing these vulnerabilities early is crucial to avoid exploits and reduce development costs.
recent studies have shown that deep learning models can effectively detect security vulnerabilities.
yet little research explores how to adapt these models from benchmark tests to practical applications and whether they can be useful in practice.
this paper presents the first empirical study of a vulnerability detection and fix tool with professional software developers on real projects that they own.
we implemented d eepvulguard an ide integrated tool based on state of the art detection and fix models and show that it has promising performance on benchmarks of historic vulnerability data.
d eepvulguard scans code for vulnerabilities including identifying the vulnerability type and vulnerable region of code suggests fixes provides natural language explanations for alerts and fixes leveraging chat interfaces.
we recruited professional software developers at microsoft observed their usage of the tool on their code and conducted interviews to assess the tool s usefulness speed trust relevance and workflow integration.
we also gathered detailed qualitative feedback on users perceptions and their desired features.
study participants scanned a total of projects .9k files and over .
million lines of source code and generated alerts and fix suggestions.
we find that although stateof the art ai powered detection and fix tools show promise they are not yet practical for real world use due to a high rate of false positives and non applicable fixes.
user feedback reveals several actionable pain points ranging from incomplete context to lack of customization for the user s codebase.
additionally we explore how ai features including confidence scores explanations and chat interaction can apply to vulnerability detection and fixing.
based on these insights we offer practical recommendations for evaluating and deploying ai detection and fix models.
our code and data are available at this link index terms deep learning vulnerability detection vulnerability repair ide user study i. i ntroduction security vulnerabilities impact users safety security and privacy and cost organizations millions of dollars per year with reports of breaches exposing millions of records becoming commonplace .
early detection of vulnerabilities during the development phase can greatly reduce costs and 1work primarily done during an internship at microsoft.
corresponding email bensteenhoek microsoft.commitigate potential impacts .
in recent years deep learning dl vulnerability detection models have emerged as a promising approach for scanning code during software development .
these models can identify vulnerability patterns in code snippets and offer the advantage of analyzing code during editing with less configuration than traditional static analysis tools .
despite promising benchmark performance it remains unclear whether these models are actually useful in real world development settings.
in the past major organizations such as microsoft google facebook and coverity have reported a gap between benchmarking success and practical application with static analyzers.
recently fu et al.
conducted a preliminary controlled study with developers showing that ai tool support reduced the time to diagnose and fix a vulnerability from minutes to minutes and motivating further user studies of ai detection and fix tools.
however their study used a single bug from their dataset rather covering real world code bases and they only studied vulnerability detection and fixing.
in our work we recruited professional developers at microsoft to use our detection repair tool in a real world development setting with their own projects beyond detection and fixing we also built and studied ai powered explanation and chat interfaces which have recently become prominent in the integrated development environments ides .
our study provides a deeper understanding of the real world usefulness and nuances of deploying these models.
to carry out our study we developed d eepvulguard an extension integrated with visual studio code vscode a popular ide with over million active users.
we used state of the art models codebert and the gpt4 large language model llm for detection and fix tasks.
participants scanned projects .9k files and over .
million lines of source code generating alerts and fix suggestions.
to the best of our knowledge ours is the first study to evaluate a detection and fix tool with professional developers on their own projects.
we initially evaluated d eepvulguard s potential for deployment by testing its detection and fix models on established vulnerability datasets.
our models achieved arxiv .14306v3 apr 2025fig.
overview of d eepvulguard s user interface on an example program.
an editor alert problems menu entry the explanation of the alert 4a quick fix interaction 4b ignore options 4c fix trigger suggested fix explanation of the fix suggestion accept reject buttons.
precision recall and a f1 score on sven for vulnerability detection and fixed of vulnerabilities on the vul4j dataset.
d eepvulguard performs comparably or better than state of the art models and meets the threshold for acceptable false positives .
these results indicate that our models are promising for detecting and fixing security vulnerabilities and can generate meaningful results for the user study.
our results show that of participants expressed interest in future use of d eepvulguard although there are several issues that limit its usefulness.
for example one problem was an high rate of false positives in practice caused by incorrect vulnerability pattern recognition and lack of context about code snippets e.g.
inter procedural vulnerabilities .
this highlights the need for more precise pattern recognition and better integration of environment and program context.
additionally the requirement to trigger a manual scan significantly disrupted the users workflow developers prefer tools that run in the background and alert them whenever potential vulnerabilities are detected.
regarding fixes of proposed security fixes were unsuitable to apply as is due to lack of customization and incorrect integration into the code.
although some fixes were functionally correct they were not tailored to the user s codebase and could not be applied without significant modifications.
an interactive chat method shows promise to allow developers to guide the generation towards more applicable fixes.
our findings offer concrete recommendations for improving these pain points found in these tools.
in this paper we make the following research contributions we developed d eepvulguard a vscode extension for detecting explaining and fixing vulnerabilities incorporating insights from static analysis and ai tool research.
our tool allows customization of backend models and we provide its code in our data packageto support further user studies.
d eepvulguard uses a multi task training approach for jointly predicting vulnerability classification localization and bug type.
we also introduced a new vulnerability filtering method with llms which improved precision by over .
we conducted a user study with professional software engineers at microsoft.
through interviews and surveys as they ran our tool on their own code we quantitatively assessed multiple dimensions of usefulness for detection and fix tools and provided practical recommendations for improving deep learning based vulnerability detection and fix tools.
ii.
u serstudy interface to study whether deep learning based vulnerability tools can be useful in practice we built d eepvulguard a visual studio code extension that brings state of the art detection fix techniques to an ide interface.
d eepvulguard allows users to scan source code with codebert and llm models view the reported vulnerabilities and llm generated explanations directly inside the editor and generate suggestions for mitigating the vulnerability.
we also implemented a telemetry module to collect user data enabling longitudinal studies of ai based vulnerability detection tools.
as our study is the first of its kind in this area we believe our tool will be a beneficial contribution which facilitates future user studies of vulnerability tools.
we released the extension code in our data package.
the code can be easily adjusted to call alternative detection and fixing solutions to be studied with developers in a real world setting.
a. ide integration figure shows an overview of d eepvulguard s user interface.
users begin by requesting to scan a file or directory.
if any potential vulnerabilities arise they are shown as highlightsfig.
an overview of d eepvulguard s detection workflow.
binary classification into vulnerable not vulnerable localization multi class classification into one of vulnerability types alert and explanation shown to the user.
in the editor and actionable entries in the problems window and a natural language explanation of the vulnerability is shown in the chat panel .
the user can use this information to assess the vulnerability and decide if a fix is required.
they can also ask questions or make suggestions to the chatbot by sending follow up messages.
by clicking on the quick fix lightbulb 4a the user can ignore the specific alert or alert types 4b or generate a quick fix 4c .
on requesting the quick fix the suggested code modifications will be presented in adiffview showing the lines to be removed and added.
as well an explanation of the fix is shown in the chat panel .
the user can modify the fix in the editor or suggest improvements with natural language chat messages if desired then accept it to apply it to their files or reject it to revert to the original code .
users can enter chat messages e.g.
asking for clarification information or inputs which trigger the vulnerability and our tool will generate a conversational response.
we drew inspiration for our tool s design from several foundational research studies on static analyzers and ai assisted developer tools.
johnson et al.
showed that developers requested static analysis tools to be available in the ide along with quick fixes and the ability to modify rule sets.
similarly christakis and bird identified bad warning messages lack of suggested fixes and poor visualization as pain points.
smith et al.
presented design guidelines such as presenting alerts in actionable locations integrating with their workflow by tracking progress batch processing allowing code editing during scans and scalability of the interface.
we incorporated all of these features into d eepvulguard .
a recent study on ai powered code completion wang et al.
found that users in focus groups valued the ability to view a measure of the model s confidence.
to study this in a practical implementation we integrated confidence scoresinto our tool s alerts shown in figure .
fu et al.
conducted a survey study and found that most participants valued localizations cwe type prediction and quick fixes so we integrated these features into our tool and evaluate them in our study shown in figure and 4a .
b. model architecture training our tool can be easily configured to leverage a wide variety of deep learning models or static analyzers.
figure shows the workflow of the current design specifically we implemented the following techniques please refer to our data package for the implementation details including our model training procedure dataset statistics and hyper parameters .
fine tuning codebert for multi task vulnerability detection codebert and similar models consistently perform well on various vulnerability datasets with relatively low latency which is suitable for detection in the editor .
we fine tuned codebert using multi task learning to predict whether a code snippet contains a vulnerability localize the tokens causing it and identify the vulnerability type.
we trained on a dataset of over .
million alerts labeled by codeql in github projects following chan et al.
s methodology focusing on vulnerability types related to web security e.g.
path injection sql injection hard coded credentials unvalidated url redirect cross site scripting details in data package .
we generate alerts in the extension based on the predicted vulnerability type confidence score and localization.
filtering and explaining alerts with gpt to further filter the false positives produced by fine tuned codebert we used gpt to filter the alerts and generate explanations.
we annotated the code snippet with a comment describing the alert type at the localized line e.g.
for sql injection alert this sql query depends on a user provided value see our data package for allyou are a vulnerability detector.
only respond with yes or no and an explanation.
does the following code snippet contain a sql injection vulnerability at line marked by alert?
fig.
d eepvulguard s llm filter prompt.
types of annotations .
then we instructed gpt to confirm whether the vulnerability is present.
if the answer is yes the alert and explanation are shown to the user otherwise the alert is not shown in figure .
we tried several prompts and evaluated on the sven benchmark ultimately selecting the prompt shown in figure .
this prompt improved the precision to an acceptable threshold of while keeping the best recall.
a static analyzer has identified a rule id security vulnerability in the language method below method the sarif result message is as follows message description write a fixed version of the method above and wrap it in triple backticks then explain why your version addresses the problem.
fig.
d eepvulguard s fix model prompt.
prompting gpt for repair and explanation we used gpt4 with custom prompts to generate and explain code fixes.
the prompt shown in figure includes the source code vulnerability report and an instruction to provide a fixed version of the code and an explanation.
we displayed the explanation in the chat panel and inserted the code suggestion to show a diff with the original content shown in figure on the right.
as with the llm filter we iterated on several prompts and chose the best performance on an internal dataset of bugs and vul4j .
c. evaluating detection and fix capabilities to ensure that d eepvulguard is both effective and representative of the state of the art we tested its performance on benchmarks that resemble the real world deployment scenario as closely as possible.
to evaluate d eepvulguard s detection capability we used the sven dataset which contains high quality vulnerability examples from opensource python projects label accuracy .
our detection model supports all the security vulnerability types present in the dataset.
we used a strict definition for true positives the predicted bug type must match and localized line number must match the lines changed in the patch.
figure shows on the sven dataset our model achieved precision and recall with an f1 score of .
overall our results are better than or on par with the prediction quality of sota models on vulnerability detection.
for example most recently ding et al.
reported that sota models including codebert attained f1 score on their dataset of c c vulnerabilities.
we cannot directly compare our model with other sota models on our dataset as most are trained on c c specific memory or pointer bugs .
christakis and bird found that most developers tolerate up to a false positive rate with the llm filter our model meets this threshold on the sven dataset with precision.
these results highlight d eepvulguard s practical effectiveness and potential for deployment in real world applications.
fig.
performance of d eepvulguard s detection component on vulnerabilities from sven.
to evaluate d eepvulguard s fix component we used the vul4j dataset which includes executable tests to reproduce security vulnerabilities.
we assessed the test results supplemented by manual validation to verify that the suggested fixes mitigated issues without breaking other functionality.
among the single hunk bugs with vulnerability types that our tool handles our model produced correct fixes and partial fixes which resolved the issue but broke other tests fixes had errors inserting the generated code into the file and fixes could not compile.
for efficiency needed for using in ide we chose to not run llm multiple times.
these results show that our model performs similarly to sota evolution based automated program repair apr tools correct fixes taking up to minutes in the 75th percentile intersection n and llms such as codex .
plausible fixes on the first try intersection n .
we conducted the above performance probe to confirm that deepvulguard can be used to conduct a meaningful study that it is practical for handling real world vulnerabilities and offers performance comparable to state of the art techniques.
we did not aim for a comprehensive controlled evaluation to claim that d eepvulguard outperforms the current state of the art.
iii.
u serstudy design we developed three research questions to guide our study.rq1 is d eepvulguard useful in practice?
rq2 which aspects of vulnerability detection fix tools are most useful?
rq3 what features do developers want from vulnerability detection fix tools?
a. study design we carried out an exploratory case study with a group of professional developers at microsoft.
we asked users to run d eepvulguard on projects they were actively developing or were familiar with and answer survey questions about their perception of the tool.
to the best of our knowledge our tool is the first vulnerability detection fix tool to be studied in a real world setting with professional developers on projects which they own.
this study enabled us to explore many open questions such as the role of explanations the developers tolerance for false positives or delayed results and what constitutes an effective fix in a secure development context.
we chose an exploratory study over e.g.
a controlled study because it elicits rich feedback from developers in a real world setting.
our approach takes advantage of the developers deep understanding of their own projects leading to a more accurate assessment of potential vulnerabilities and providing more valuable insights.
recruitment we carried out our study with a group of microsoft developers.
we recruited developers primarily using snowball sampling with a participation rate.
in total participants scanned a total of projects .9k files and over .
million lines of source code and generated alerts and fix suggestions.
fig.
participant demographics and tool adoption.
where applicable participants listed multiple items for the project domain project language and security tooling.
figure shows the participants demographic information with the exception of one participant who declined the demographic survey indicating that we studied a diverse set of developers from various levels of experience and backgrounds.
participants had a median of years of experience participants worked on both front end and back end domains and represented a diverse set of applications such as web applications back end services ide extensions.
most projects were written in c or typescript.
most participants consideredthemselves security conscious median out of and all had some form of security tool running in continuous integration or periodically though more than half of the projects used tools for reasons of organizational compliance rather than individual initiative most participants did not use security tools in the ide.
the majority of participants used ai powered tools occasionally a few times a week or every day such as code completion tools or chatbots though three participants used ai tools rarely or not at all stating that they did not find them useful.
of developers had expertise in developing static analysis tools indicating that they were exceptionally knowledgeable about security.
interviews each participant ran our tool on a code base associated with a production application which they actively develop and shared their perspective guided by both structured and free form questions.
we first asked the participants to run our tool on a simple web server containing a known vulnerability to introduce the features of our tool detection fix and chat.
then we directed the participants to run the tool on security critical areas of their application such as web interfaces api endpoints database code and file processing code.
we ran the study as a think aloud empirical study meaning we asked developers to verbalized their thoughts while running the tool and processing the results.
when participants explicitly asked questions we provided help and answered questions to facilitate a smooth interview process and clarify the participant s statements e.g.
about the meaning of different ui elements bug type descriptions or behavior of the tool but we refrained from explaining the results of the tool or interpreting the meaning of its outputs to avoid biasing the study.
each interview lasted approximately minutes consisting of a minute setup and demographic survey average minutes usage of the tool and minutes post usage survey and discussion.
we interviewed all subjects over video calls and with their full consent recorded field notes and demographic audio screen capture survey and tool usage data.
after they used the tool we asked participants about various aspects of the tool their overall perception of the usefulness of the detection alerts and suggested fixes and their satisfaction with the speed q1 q3 reported on a likert scale from to from not useful satisfied at all to very useful satisfied whether the tool fits their workflow whether they trust in the tool whether the reported alert types were relevant and whether they would keep using the tool q4 q7 reported as yes no .
we also asked the participants what features they found especially useful and what features they would like to see in the tool.
we asked the questions verbally during the interview immediately after trying the tool in order to collect free form feedback on each question and ensure that the participant could recollect their experiences with the tool.
we designed the initial set of interview questions guided by our research questions and informed inspired by findings and open questions from previous studies of static analysis and aitools .
three authors tried the tool and all authors reviewed the survey questions and we gathered feedback from outside researchers within our organization to improve the design of the planned questions.
data analysis process we analyzed the data quantitatively and qualitatively reporting the results in section iv.
to quantify users perceptions of our tool we tallied the responses to the post interview survey shown in figure .
regarding questions q1 q3 we report the mean and distribution of likert scores and regarding q4 q7 we report the proportion of yes responses.
we also categorized each alert or fix that the participants examined during the interviews into useful or one of problem categories based on the participant s explanation.
we discuss the results in section iv a. we conducted a grounded theory analysis to analyze the study participants rich free form feedback following the literature .
grounded theory analysis is a method used to analyze data by identifying recurring concepts grouping these concepts into salient categories and developing themes that provide an overall understanding of participants perceptions of the tool.
these concepts are derived from participants quotations reflecting their thoughts while using the tool and their responses to survey questions.
all the resulting concepts and groups are referred to as a codebook .
we analyzed over hours of usage and survey transcripts and identified a total of codes in distinct groups.
relevant codes are shown in figure and figure .
to create the initial codebook the first and second authors independently analyzed two randomly selected interviews and generated lists of recurring concepts.
they then met to create a unified list of concepts create higher level groups and develop overall themes.
each author independently analyzed half of the remaining interviews periodically syncing and jointly analyzing the same interviews to update the codebook and compare notes.
both raters agreed on all the classifications for alert responses.
this was an iterative process where we created the initial codebook after conducting the first interviews and refactored added groupings periodically as we conducted the remaining interviews.
we present our qualitative analysis in section iv b. during the interviews study participants suggested several features they felt would be useful which provide useful recommendations for tool builders and directions for further research we identify these as concepts in our grounded theory analysis and discuss these feature requests in section iv c. the anonymized demographic data interview and survey script and codebook are in our data package .
iv.
u ser study results a. rq1 is deepvulguard useful in practice?
detection figure reports the results of our post interview survey.
on average participants rated d eepvulguard s alerts at .
out of for usefulness q1 with participants giving it a rating of .
or above and participants giving it a rating of .
only of participants felt that they trusted the tool s warnings about vulnerability alerts q5 .
the biggestbarrier to usefulness and trust in the tool s alerts was the amount of false positives with of users explicitly reporting losing trust in the tool after frequently encountering false positives.
the false positive rate in real world settings was higher than in our sven dataset measurements section ii c .
we attribute this difference to varying languages and vulnerability types sven contains python code whereas most participants worked on typescript or c which comprise only of our training data.
additionally sven examples are intra procedural lacking information about the calling context and runtime environment which may widen the gap between benchmark data and real world testing.
of participants felt that the vulnerability types detected by the tool were relevant q6 with some participants expressing strong approval for example definitely all of the all the categories of the vulnerabilities that were found here were good.
they re all ones that hit these kinds of code all the time.
.
fix suggestions on average participants rated d eepvulguard s fix suggestions at out of for usefulness q1 .
participants gave it a rating of and participants gave it a rating of .
for fixes one of the most common issues was that the fix was not customized to the developer s codebase for example creating a function to sanitize user inputs when the developer wants to reuse their existing sanitization library this often prevented the users from directly applying the fix requiring an overhaul to produce a fix with their intended approach.
this highlights a limitation of common exact match or execution based metrics for evaluating ai based fixes as these metrics do not capture the practical nuances of generating fixes for real world codebases.
speed the average response time for the tool was .
seconds per file.
more than half of the participants were very satisfied with the speed of the tool rating it at q3 .
when asked about the tool s speed one participant stated totally satisfied.
fig.
summary of participants overall perceptions of d eepvulguard from our post interview survey.i can wait for this kind of stuff referring to security alerts fixes .
workflow integration more than half of participants felt that the tool in its current state would not fit into their workflow q4 .
out of users expressed that the tool would be more useful if it was running in the background and scanning their code while they were editing or ran along with their build or commit commands manually triggering the scan was a barrier to usage since it required a stopping point in development.
summary although not fully satisfactory the tool shows promise of participants expressed that they would keep using the extension.
fig.
participant responses to llm filtered alerts and llmgenerated fixes while using d eepvulguard .
figure reports the participants responses to the alerts and fixes for which they provided direct feedback during the interviews based on the categories assigned in our groundedtheory analysis.
here we display alerts from the combined codebert llm model excluding four participants who used the codebert model.
participants considered of alerts and of fixes to be useful and without significant problems.
figure shows an anonymized example of a url redirection vulnerability which d eepvulguard successfully detected and fixed by adding extra validation.
in this case deepvulguard added logic to check that the url matches a list of approved domains and asked the user to fill the list of domains based on their knowledge of the application s running context.
the primary causes of false positive alerts were missing context totaling of alerts and incorrect pattern recognition .
missing context involved misidentifying variables as user controlled or overlooking vulnerabilities handled by the calling context or runtime environment.
incorrect pattern recognition involved misidentifying harmless patterns as vulnerabilities such as constant strings mistaken for hard codedfunction geturl string url const allowedurls example.com todo provide allowed urls this.notificationservice.notify deepvulguard potentially malicious url redirection.
action window.open url action if allowedurls.includes url window.open url fig.
a vulnerability that d eepvulguard successfully found and fixed by adding validation logic to ensure that an attacker cannot redirect the user to a malicious third party site.
credentials.
we hypothesize that incorporating