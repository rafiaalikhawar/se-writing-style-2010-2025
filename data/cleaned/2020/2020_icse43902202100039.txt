scalable quantitative verification for deep neural networks teodora baluta national university of singapore teobaluta comp.nus.edu.sgzheng leong chua independent researcher czl iiyume.orgkuldeep s. meel national university of singapore meel comp.nus.edu.sg prateek saxena national university of singapore prateeks comp.nus.edu.sg abstract despite the functional success of deep neural networks dnns their trustworthiness remains a crucial open challenge.
to address this challenge both testing and verification techniques have been proposed.
but these existing techniques provide either scalability to large networks or formal guarantees not both.
in this paper we propose a scalable quantitative verification framework for deep neural networks i.e.
a test driven approach that comes with formal guarantees that a desired probabilistic property is satisfied.
our technique performs enough tests until soundness of a formal probabilistic property can be proven.
it can be used to certify properties of both deterministic and randomized dnns.
we implement our approach in a tool called provero1and apply it in the context of certifying adversarial robustness of dnns.
in this context we first show a new attackagnostic measure of robustness which offers an alternative to purely attack based methodology of evaluating robustness being reported today.
second provero provides certificates of robustness for large dnns where existing state of the art verification tools fail to produce conclusive results.
our work paves the way forward for verifying properties of distributions captured by realworld deep neural network with provable guarantees even where testers only have black box access to the neural network.
i. i ntroduction the past few years have witnessed an increasing adoption of deep neural networks dnns in domains such as autonomous vehicles drones or robotics where mispredictions can have serious long term consequences.
robustness privacy and fairness have emerged as central concerns to be addressed for safe adoption of dnns .
consequently there has been a growing attention to testing and verification of neural networks for properties of interest.
to establish that the resulting dnns have the desired properties a large body of prior work has focused on techniques based on empirical testing or specialized attack vectors .
while such techniques are useful they do not rigorously quantify how sure we can be that the desired property is true after testing.
in contrast to testing approaches formal verification seeks to provide rigorous guarantees of correctness.
inspired by the success of model checking in the context of hardware and 1the name is a pun on prover o i will prove it and pro vero pro truth in italian.
code and benchmarks are available at teobaluta.github.io proverosoftware verification the earliest formal verification methodologies in the context of deep neural networks focused on qualitative verification i.e.
whether a system satisfies a given specification.
prior work in this category has been following the model checking paradigm wherein a given dnn is encoded as a model using constraints grounded in a chosen theory.
then a satisfiability solver often modulo the chosen theory is invoked to check if there exists an execution of the system that violates the given specification .
the proposed techniques in this category appear to have three limitations.
firstly they require white box access to the models and specialized procedures to transform the dnns to a specification limiting their generality.
secondly the performance of the underlying feasibility solver degrades severely with the usage of non linear constraints leading to analyses that do not scale to larger models.
thirdly prior techniques are limited to deterministic neural networks while extensive research effort has been invested in designing randomized dnns especially to enhance robustness .
such qualitative verification considers only two scenarios either a dnn satisfies the property or it does not.
however neural networks are stochastically trained and more importantly they may run on inputs drawn from an unknown distribution at inference time.
properties of interest are thus often probabilistic and defined over an input distribution e.g.
fairness or robustness to distributional changes .
hence qualitative verification is unsuitable for such properties.
an alternative approach is to check how often a property is satisfied by a given dnn under a given input distribution.
more specifically one can assert that a dnn satisfies a property with a desirably high probability .
unlike ad hoc testing quantitative verification aims to provide soundness i.e.
when it confirms that is true with probability p then the claim can be rigorously deduced from the laws of probability.
for many practical applications knowing that the chance of failure is controllably small suffices for deployment.
for instance it has been suggested that road safety standards for self driving cars specify sufficiently low failure rates of the perceptual sub systems against which implementations can be verified .
further we show the role of quantitative verification in the specific context of adversarial ieee acm 43rd international conference on software engineering icse .
ieee robustness see section ii a .
in this paper we present a new quantitative verification algorithm for dnns called provero tackling the following problem given a logical property specified over a space of inputs and outputs of a dnn and a numerical threshold decide whether is true for less than fraction of the inputs.
provero is a procedure that achieves the above goal with proven soundness when it halts with a yes or no decision it is correct with probability and within approximation error to the given .
the verifier can control the desired parameters making them arbitrarily close to zero.
that is the verifier can have controllably high certainty about the verifier s output and can be arbitrarily precise or close to the ground truth .
the lower the choice of used by the verifier the higher is the running time.
provero is based on sampling and it makes only one assumption the ability to take independent samples from the space over which is defined2.
this makes the verification procedure considerably general and stand alone.
the verifier only needs black box access to the dnn freeing it up from assuming anything about the internal implementation of the dnns.
the dnn can be deterministic or from a general family of non deterministic dnns.
this allows checking probabilistic properties of deterministic dnns and of randomization procedures defined over dnns.
our paper makes the following contributions we present a new quantitative verification algorithm for neural networks.
the framework is fairly general it assumes only black box access to the model being verified and assumes only the ability to sample from the input distribution over which the property is asserted.
we implement our approach in a tool called provero that embodies sound algorithms and scales quantitative verification for adversarial robustness to large real world dnns both deterministic and randomized within 1hour.
in the context of certifying adversarial robustness our empirical evaluation presents a new attack agnostic measure of robustness and shows that provero can produce certificates with high confidence on instances where existing state of the art qualitative verification does not provide conclusive results.
ii.
a pplication adversarial robustness for concreteness we apply our approach to verifying the robustness of neural networks.
in proving robustness the analyst has to provide a space of inputs over which the robustness holds.
often this space is defined by all inputs that are within a perturbation bound of a given input xin thelpnorm .
different distance norms have been used such asl0 l1 l2andl1.
thelpnorm is defined as kx x0kp jx0 x1jp jx0 x2jp jx0 n xnjp p. a neural network fis defined to be robust with respect to a given input xif8x0such thatkx x0kp we have f x f x0 .
2for non deterministic dnns the procedure assumes that the randomization used for the dnn is independent of its specific input.
x min x minfig.
the decision boundaries of two binary classifiers f1 left andf2 right around an input xare shown.
the correct classification region for xis shown in purple solid while the incorrect classification region is shown in red hashed .
the concentric circles show the equidistant points from xin l2 norm drawn up to a bound .
the classifier f1has a better larger minimum perturbation than f2 but has a worse larger adversarial density because a majority of points within distance of xare in the incorrect classification region.
therefore the smoothened version of f2will classify xcorrectly while the smoothened f1will not.
picking the base classifier with the better adversarial density rather than minimum perturbation will lead to better accuracy in a smoothening defense.
for a given neural network fand input point x there always exists some perturbation size beyond which there are one or more adversarial samples.
we refer to this minimum perturbation with non zero adversarial examples as min which is the ground truth the security analyst wants to know.
attack procedures are best effort methods which find upper bounds for minbut cannot provably show that these bounds are tight .
verification procedures aim to prove the absence of adversarial examples below a given bound i.e.
they can establish lower bounds for min.
we call such verified lower bounds verf.
most verifiers proposed to date for robustness checking are qualitative i.e.
given a perturbation size verf they output whether adversarial examples are absent within verf.
if the verification procedure is sound and outputs yes then it is guaranteed that there are no adversarial examples within verf i.e.
the robustness property is satisfied.
when the verifier says no if the verifier is complete then it is guaranteed that there are indeed adversarial examples within verf.
if the verifier is incomplete and prints no the result is inconclusive.
let us introduce a simple quantitative measure of robustness called the adversarial density .
adversarial density is the fraction of inputs around a given input xwhich are adversarial examples.
we explain why adversarial density is a practically useful quantity and much easier to compute for large dnns than min.
we can compute perturbation bounds below which the adversarial density is non zero but negligibly small and we empirically show these bounds are highly correlated with estimates of minobtained by state of the art attack methods.
313a.
minimum perturbation vs. density it is reasonable to ask why adversarial density is relevant at all for security analysis.
after all the adversary would exploit the weakest link so the minimum perturbation size min is perhaps the only quantity of interest.
we present concrete instances where adversarial density is relevant.
first we point to randomized smoothing as a defense technique which has provable guarantees of adversarial robustness .
the defense uses a smoothed classifiergthat averages the behavior of a given neural netf called the base classifier around a given input x. more specifically given a base classifier f the procedure samples perturbations of xwithin from a specific noise distribution and outputs the most likely class csuch that argmaxc2ypr .
notice that this procedure computes the probability of freturning class c typically by counting how often fpredicts class cover many samples rather than considering the worst case example around x. said another way these approaches estimate the adversarial density for each output class under some input distribution.
therefore when selecting between two base classifiers during training we should pick the one with the smallest adversarial density for the correct class irrespective of their minimum adversarial perturbation size.
to illustrate this point in figure we show two dnns f1andf2 as potential candidates for the base classifier in a randomized smoothing procedure.
notice that f1has a better larger min thanf2.
however more of the inputs within the ball of the input x inside the red hashed circle are classified as the wrong label by f1in comparison to f2.
thus a smoothed classifier with f1as a base classifier would misclassify xwhere the smoothed classifier with base f2 would classify correctly.
this explains why we should choose the classifier with the smaller adversarial density rather than one based on the minimum perturbation because the smoothing process is not susceptible to worst case examples by its very construction.
this motivates why computing adversarial density is useful for adversarial robustness defenses.
second we point out that estimating minimal perturbation bounds has been a difficult problem.
attack procedures which provide an upper bound for min are constantly evolving.
this makes robustness evaluations attack specific and a moving target.
on the other hand qualitative verification techniques can certify that the dnn has no adversarial examples below a certain perturbation which is a lower bound on the adversarial perturbation .
however these analyses do not scale well with deep networks and can lead either to timeouts or inconclusive results for large real world dnns.
furthermore they are white box requiring access to the model internals and work only for deterministic neural networks.
we show in this work that verifying adversarial density bounds is easy to compute even for large dnns.
we describe procedures that require only black box access the ability to sample from desired distributions and hence are attack agnostic.
in particular we show an empirical attack agnostic metricfor estimating robustness of a given dnn and input xcalled adversarial hardness .
it is highest perturbation bound for which the adversarial density is below a suitably low .
we can search empirically for the highest perturbation bound hard called the adversarial hardness for which a sound quantitative certifier says yes when queried with f x hard implying that fhas suitably low density of adversarial examples for perturbation bounds below hard.
adversarial hardness is a measure of the difficulty of finding an adversarial example by uniform sampling.
surprisingly we find that this measure strongly correlates with perturbation bounds produced by prominent white box attacks see section vii .
given this strong correlation we can effectively use adversarial hardness as a proxy for perturbation sizes obtained from specific attacks when comparing the relative robustness of two dnns.
we caution readers that adversarial hardness is a quantitative measure and technically different from min the distance to the nearest adversarial example around x. but both these measures provide complementary information about the concentration of adversarial examples near a perturbation size.
iii.
p roblem definition we are given a neural network and a space of its inputs over which we want to assert a desirable property of the outputs of the network.
our framework allows one to check whether is true for some specified ratio of all possible values in the specified space of inputs.
for instance one can check whether most inputs a sufficiently small number of inputs or any other specified constant ratio of the inputs satisfies .
the specified ratio parameter is called a threshold .
formally let i f f0 1gbe a property function over a neural network f a subset of all possible inputs to the neural network iand user specified parameters .
we assume that we can efficiently draw samples from any probability distribution over ithat the analyst desires.
for a given distribution doveri letpd ex d .pd can be viewed as the probability that evaluates to 1forx sampled fromiaccording to d. when clear from context we omitdand simply use pto refer topd.
ideally one would like to design an algorithm that returns yes ifp and no otherwise.
such exact quantification is intractable so we are instead interested in an algorithm athat returns yes if p and no otherwise with two controllable approximation parameters .
the procedure should be theoretically sound ensuring that when it produces yes or no results it is correct with probability at least within an additive bound on its error from the specified threshold .
specifically we say that algorithm aissound if pr pr the analyst has arbitrary control over the confidence abouta s output correctness and the precision around the threshold.
these values can be made arbitrarily small 314approaching zero increasing the runtime of a. the soundness guarantee is useful it rigorously estimates how many inputs inisatisfy serving as a quantitative metric of satisfiability.
the presented framework makes very few assumptions.
it can work with any specification of i as long as there is an interface to be able to sample from it as per any desired distribution efficiently.
the neural network fcan be any deterministic function.
in fact it can be any stateless randomized procedure i.e.
the function evaluated on a particular input does not use outputs produced from prior inputs.
this general class of neural networks includes for instance bayesian neural networks and many other ensembles of neural network architectures .
the framework permits specifying all properties of fairness privacy and robustness highlighted in recent prior work for a much broader class of dnns.
our goal is to present sound and scalable algorithms for quantitative verification specifically targeting empirical performance for quantitatively certifying robustness of dnns.
the framework assumes black box access to f which can be deterministic or non deterministic.
our techniques can directly check qualitative certificates produced from randomized robustness enhancing defenses one example of which is the recent work called pixeldp see section vii c .
iv.
a pproach overview a. sampling given a property over a sampleable input space iand a neural network f our approach works by sampling ntimes independently from i. we testfon each sample as input.
let xibe a random variable denoting the result of the trial with sample i wherexi if the x f is true and xi 0otherwise.
let xbe the random variable denoting the number of trials in x1 x2 xnfor which the property is true.
then the standard chernoff bounds see given below form the main workhorse underlying our algorithms lemma .
given independent random variables x1 xn letx pn i 1xi e n and p x n. for0 pr e n pr e n note that the probability pwe are interested in bounding in our quantitative verification framework is exactly in lemma .
.
more specifically the probability depends on the neural network and distribution over the inputs p ex d wheredis a distribution over i. using a framework based on sampling and chernoff bounds admits considerable generality.
the only assumption in applying the lemma .
is that all samples are independent.
if the neural network does not compute information during one trial or execution under one sample and use it in another trial as is the case for all neural networks we study trials will be independent.
for any deterministic neural network all samples are drawn independently and identically distributed in i sochernoff bounds are applicable.
for randomized dnns we can think of the ithtrial as evaluating a potentially different neural network sampled from some distribution of functions on the given sample.
here the output random variables may not be identically distributed due to the randomization used by the neural network itself.
however lemma .
can still be used even for non identically distributed trials but independent.
we discuss an estimation based strategy that applies chernoff bounds in a straight forward manner next.
such a solution has high sample complexity for quantitative verification of adversarial robustness.
we then propose hypothesis based solutions which are sound and have much better empirical sample complexity for real world dnns.
our proposed algorithms still rely only on chernoff style bounds but are carefully designed to internally vary parameters on which chernoff bounds are invoked to reduce the number of samples needed to dispatch the asserted property.
b. an estimation based solution one way to quantitatively verify a property through sampling is to directly apply chernoff bounds to the empirical estimate of the mean pinntrials.
the solution is to take n ln1 2samples and decide yes if p 2and no if p .
this is a common estimation approach for instance used in the prediction step in the certified defense mechanism pixeldp .
by lemma .
one can show that pis within 2additive error of pwith confidence higher than .
therefore the procedure is sound since pr p62 p p by lemma .
for all p .
in this solution the number of samples increase quadratically with decreasing .
for example if the directly applying chernoff bounds will require over 106samples.
even for an optimized architecture such as branchynet that reports 9mson average inference time per sample for a resnet layers the estimation approach would take more than gpu compute hours.
this is a prohibitive cost.
for randomized dnns which internally compute expectations the runtime of the estimation baseline approach can be even larger.
for example the randomization used in pixeldp can have inference overhead compared to deterministic dnns .
our work provides new algorithms that utilize much fewer samples on average.
in the example of branchynet mentioned above if the true probability pis0 our approach requires samples to return a no answer with confidence greater than0 .
the main issue with the estimation algorithm is that it does not utilize the knowledge of the given in deciding the number of samples it needs.
c. our approach the number of samples needed for chernoff bounds depend on how far is the true probability pthat we are trying to bound from the given threshold .
intuitively if pand are far apart in the interval then a small number of samples are sufficient to conclude with high certainty that p or p for small .
the estimation approach takes the 315algorithm metaprovero while cond do pick ans t ester ifans yes then return yes pick ans t ester ifans no then return no return tester algorithm tester n p3 p2 2ln1 q samplentimes p npn i 1xi.
xi samples that satisfy the property if p 1then return yes if p 2then return no return none same number of samples irrespective of how far pand are.
our algorithms terminate quickly by checking for quick totest hypothesis early yielding the sample complexity comparable to the estimation only in the worst case.
we propose new algorithms the key idea of which is to use cheaper in sample complexity hypothesis tests to decide yes or no early.
given the threshold and the error the high level idea is to propose alternative hypotheses on the left side of and on the right side of .
we choose the hypotheses and a sampling procedure such that if any of the hypotheses on the left side of are true then we can return yes .
similarly if any of the hypotheses on the right side of are true then we can return no .
thus we can potentially return much faster when the true probability pis further from the threshold .
the overall meta level structure of our algorithms is simple and follows algorithm called m etaprovero .
in lines and we pick the alternative hypotheses on the left and right of the given threshold respectively.
we sample a certain number of samples estimate the ratio p by invoking t ester in lines and and check if we can prove that conditions involving the alternative intermediate thresholds 1and are satisfied with the desired input parameters using chernoff bounds.
if the check succeeds the algorithm can return yes or no otherwise the process repeats until a condition which guarantees soundness is met.
the internal thresholds are picked so as to soundly prove orrefute thatplies in certain ranges in .
this is done by testing certain intervalspis or is not in.
for instance metaprovero tests a pair of hypotheses p 1andp simultaneously line .
notice that for the intervals on the left side of chosen in line in alg.
the0 1p p p 1l 2l 1r 2r fig.
example run of m etaprovero given thatp .
on the left hand side m etaprovero cannot prove thatp sincepis greater than left side 2l.
next metaprovero chooses the refuting interval on the right hand side.
sincep 2r tester returns no and m etaprovero can prove that p .
call to t ester can result in proving that p 1with desired confidence and error tolerance .
in this case since we will have proven the original hypothesis p and the algorithm can return yes soundly.
we call such intervals which are to the left of as proving intervals .
conversely refuting intervals are on the right side of .
the choice of 1and 2on line in alg.
is such that they are larger than .
when we can prove that p i.e.
the t ester call on line returns no then we can soundly return no because impliesp .
in fig.
we consider an example run of m etaprovero given that the true probability p highlighted in blue and the input parameters are .
m etaprovero picks the proving interval 1l 2l on the left of and calls t ester which returns no .
this means that the true probability is greater than 1l with high confidence.
m etaprovero then picks an interval 1r 2r on the right side of .
here tester returns with confidence higher than thatp 2r.
since 2r we can conclude that the true probability is greater than with error .
the key building block of this algorithm is the t ester subprocedure algorithm which employs sampling to check hypotheses.
informally the t ester does the following given two intermediate thresholds 1and if the true probability pis either smaller than 1or greater than it returns yes or no respectively with high confidence.
if p2 then the tester does not have any guarantees.
notice that a single invocation of the t ester checks two hypotheses simultaneously using one set of samples.
the number of samples needed are proven sufficient in section v b. one can directly invoke t ester with and but that might lead to a very large number of samples o .
thus the key challenge is to judiciously call the tester on hypotheses with smaller sample complexity such that we can refute or prove faster in most cases.
to this end notice that m etaprovero leaves out two algorithmic design choices stopping conditions and the strategy for choosing the proving and refuting hypotheses highlighted in alg.
.
we propose and analyze an adaptive binary search style algorithm 316where we change our hypotheses based on the outcomes of our sampling tests section v a .
we show that our proposed algorithm using this strategy is sound.
when pis extremely close to these algorithms are no worse than estimating the probability requiring roughly the same number of samples.
v. a lgorithms we provide an adaptive algorithm for quantitative certification that narrows the size of the intervals in the proof search similar to a binary search strategy section v a .
this algorithm build on the base of the t ester primitive which we explain in section v b. a. the binpcertify algorithm we propose an algorithm b inpcertify algorithm where instead of fixing the intervals beforehand we narrow our search by halving the intervals.
the user specified input parameters for b inpcertify are the threshold the error bound and the confidence parameter .
the interval creation strategy is off loaded to the c reate interval procedure outlined in algorithm .
the interval size is initially set to the largest possible as t ester would require less samples on wider intervals algorithm lines .
then the b inpcertify algorithm calls internally the procedure create interval to create proving intervals on the left side of alg.
line and refuting intervals on the right side of alg.
line .
note that for the refuting intervals we keep the left side fixed and for the proving intervals we keep the right side fixed i.e.
.
for each iteration of binpcertify the strategy we use is to halve the intervals by moving the outermost thresholds closer to alg.
lines .
for these intermediate hypotheses t ester checks if it can prove or disprove the assert p lines and .
it continues to do so alternating the proving and refuting hypotheses until the size of both intervals becomes smaller than the error bound line .
if only on one side of the threshold c reate interval returns intervals with size binpcertify checks those hypotheses.
if the size of the proving and refuting intervals returned by c reate interval is then the final check is directly invoked on and returned to the user line .
the algorithm b inpcertify returns yes or no with soundness guarantees as defined in section iii.
we give our main theorem here and defer the proof to section vi theorem .
for an unknown value p2 a given threshold b inpcertify returns a yes or no with the following guarantees pr pr algorithm binpcertify 1l 2l 1r 2r n max log max log min n .
minimum confidence per call to t ester while true do 1l 2l c reate interval 1l 2l true if 2l 1l then ans t ester 1l 2l min ifans yes then return yes 1r 2r c reate interval 1r 2r false if 2r 1r then ans t ester 1r 2r min ifans no then return no if 2r 1r and 2l 1l then return tester min algorithm create interval left if and left then return if and and left then return if and and leftthen return ifleftthen return max return max b.tester primitive the tester takes as input two thresholds 2such that 2and confidence parameter and returns yes when p 1with confidence higher than and no when p 2with confidence higher than .
ifp2 the tester returns without guarantees.
the procedure for implementing the t ester is simple.
following the procedure outlined in algorithm we take n p3 p2 2ln1 number of independent samples and estimate the ratio of these trials as p. the t ester returns yes if p 1and no if p 2where 1and are error parameters lines and .
if p our implementation returns none .
the following lemma establishes the soundness of the tester and follows directly from applying chernoff bounds on p. lemma .
given the thresholds and confidence parameter tester has following soundness guarantees pr pr proof.
the proof follows directly the chernoff bounds.
using the estimated probability p tester returns yes if p 1and no if p 2with probability greater than .
otherwise it returns none .
we want to choose values such thatpr andpr .
to derive the minimum number of samples for the estimated p the key idea is to use one set of samples to check two t each bounded by return yes return no fig.
t ester considers the boundary t that allows to distinguish p 1orp .
hypotheses p 1andp simultaneously.
to do so we find a point t2 which serves as a decision boundary for the estimate probability p. we illustrate this in figure it shows t and the two probability distributions for pgivenp 1andp respectively.
the distributions for the case p 1will be shifted further to the left and the casep 2will be shifted further to the right so these are extremal distributions to consider.
it can be seen that t is chosen such that pr as well aspr p tjp are bounded shaded red by probability .
using the additive chernoff bounds lemma .
for a given 1and the number of samples nis the maximum of 1ln1 and2 2ln1 .
taking the maximum ensures that the probabilities of the both the hypotheses p 1andp are being simultaneously upper bounded.
we leave the detail analysis for the supplementary material.
vi.
s oundness in this section we prove that our proposed algorithm satisfies soundness as defined in section iii.
b inpcertify uses the t ester primitive on certain intervals in sequence.
depending on the strategy the size of the intervals and the order of testing them differs.
but the algorithm terminates immediately if the t ester returns yes on a proving interval or no on a refuting one.
the meta algorithm captures this structure on line and b inpcertify algorithm instantiates this general structure.
when none of these optimistic calls to t ester are successful the algorithm makes a call to the tester on the remaining interval in the worst case.
given the same basic structure of algorithms as per the meta algorithm metaprovero we now prove the following key theorem lemma .
letebe the event that the algorithm a2 fbinpcertifygfails thenpr .
proof.
fix any input toa and consider the execution of a under those inputs.
without loss of generality we can order the intervals tested by ain the sequence that ainvokes the t ester on them in that execution.
let the sequence of intervals be numbered from i for some value i. now let us bound the probability of the event ei which is whenatests intervals i and fails.
to do so we consider events associated with each invocation of t esterj2 .
letrjbe the event thatareturns immediately after invoking the t ester on thej th interval.
let cjdenote the event that tester returns a correct answer for the j th interval.
if eiis true thenaterminates immediately after testing the i th interval and fails.
this event happens only if two conditions are met first adid not return immediately after testing intervals i and second areturns a wrong answer at i th interval and does terminate.
therefore we can conclude that the eventei ci ri ri r1.
the probability of failurepr for each event eiis upper bounded by pr .
lastly letebe the total failure probability of a. we can now use a union bound over possible failure events e1 en wherenis the maximum number of intervals acan possibly test under any given input.
specifically pr pr nx i 1pr nx i 1pr by analyzingpn i 1pr in the context of our specific algorithm b inpcertify we show that the quantity is bounded by lemma .
.
lemma .
under any given input letcibe the event thati th call made by b inpcertify to the t ester is correct and let nbe the total number of calls to t ester by binpcertify .
then pn i 1pr .
proof.
we can upper bound the number of proving intervals on the left by nl log .
similarly for the right side of number of refuting intervals is nr log1 .
lastly there is only 1call to the t ester on the interval line alg.
.
the total number of intervals tested in any one execution of b inpcertify is at mostn log log1 .
each call to the t ester is done with confidence parameter min n therefore by lemma .
the failure probability of any call is at most n. it follows that the pr n n vii.
e valuation scalability for a given timeout what is the largest model that provero and existing qualitative analysis tools can produce conclusive results.
utility in attack evaluations how does adversarial hardness computed with provero compare with the efficacy of state of the art attacks?
applicability to randomized models can provero certify properties of randomized dnns?
performance.
how many samples are needed by our new algorithms vis a vis the estimation approach section iv b ?
we implement our algorithms in a prototype tool called provero and evaluate the robustness of 38deterministic neural networks trained on 2datasets mnist and imagenet .
for mnist we evaluate on images from the model s respective test set.
in the case of imagenet we pick from the validation set as we require the correct label.
table i provides the size statistics of these models.
in addition we evaluate the randomized model publicly provided by pixeldp which has a qualitative certificate of robustness.
318table i neural network architectures used in our evaluation.
dataset arch description hidden units mnist bm1 ffnn layer feed forward convsmall layer convolutional convmed layer convolutional convbig layer convolutional convsuper layer convolutional skip residual imagenet bm2 vgg16 layer convolutional vgg19 layer convolutional resnet50 layer residual inception v3 layer convolutional densenet121 layer convolutional a eran benchmark bm1 our first benchmark consists of 33moderate size neural networks trained on the mnist dataset.
these are selected to aid a comparison with a state of the art qualitative verification framework called eran .
we selected all the models which eran reported on.
these models range from layer neural networks to layer neural networks with up to about 90khidden units.
we use the images used to evaluate the eran tool.
b larger models bm2 the second benchmark consists of 5larger deep learning models pretrained on imagenet vgg16 vgg19 resnet50 inceptionv3 and densenet121.
these models were obtained via the keras framework with tensorflow backend.
these have about 50mhidden units.
all experiments were run on gpu tesla v100 sxm216gb with a timeout of seconds per image for the mnist seconds for imagenet models and seconds for the randomized pixeldp model.
a. utility in attack evaluation provero can be used to directly certify if the security analyst has a threshold they want to check for example obtained from an external specification.
another way to understand its utility is by relating the quantitative bounds obtained from provero with those reported by specific attacks.
when comparing the relative robustness of dnns to adversarial attacks a common evaluation methodology today is to find the minimum adversarial perturbation with which state ofthe art attacks can produce at least one successful adversarial example.
if the best known attacks perform worse on one dnn versus another on a sufficiently many test inputs then the that dnn is considered more robust.
provero offers a new capability we can measure the ratio of adversarial samples within a specified perturbation bound of a given test input x see section ii .
specifically we can compute the adversarial density by uniformly sampling in the lpball of x and checking if the ratio of adversarial samples is very small below .
by repeating this process for different perturbations bounds we empirically determine theadversarial hardness or hard the largest perturbation bound below which provero certifies the adversarial density to be that small returns yes and above which provero does not returns no .
we use density threshold error tolerance and confidence parameter .
provero computes the adversarial hardness with black box access.
as a comparison point we evaluate against two white table ii attack correlation for the pgd and c w attack for the models in bm1 and bm2 using pearson s coefficient .
for all statistical significance p .
models pgd c w convbigrelu diffai .
.
convmedgrelu pgdk w0.
.
.
convmedgrelu pgdk w0.
.
.
convmedgrelu point .
.
convmedgsigmoid pgdk w0.
.
.
convmedgsigmoid pgdk w0.
.
.
convmedgsigmoid point .
.
convmedgtanh pgdk w0.
.
.
convmedgtanh pgdk w0.
.
.
convmedgtanh point .
.
convsmallrelu diffai .
.
convsmallrelu pgdk .
.
convsmallrelu point .
.
convsuperrelu diffai .
.
densenet res .
.
ffnnrelu pgdk w0.
.
.
ffnnrelu pgdk w0.
.
.
ffnnrelu point .
.
ffnnsigmoid pgdk w0.
.
.
ffnnsigmoid pgdk w0.
.
.
ffnnsigmoid point .
.
ffnntanh pgdk w0.
.
.
ffnntanh pgdk w0.
.
.
ffnntanh point .
.
mnist convmaxpool .
.
mnist relu .
.
mnist relu .
.
mnist relu .
.
mnist relu .
.
mnist relu .
.
mnist relu .
.
mnist relu .
.
mnist relu .
.
resnet50 .
.
skip diffai .
.
vgg16 .
.
vgg19 .
.
inception v3 .
.
boxattacks pgd for l1and c w for l2implemented in cleverhans v3.
.
2prominent attacks that are recommended for the lpnorms we consider .
whitebox attacks enable the attacker complete access to internals therefore they are more powerful than black box attacks today.
both pgd and c w are gradient based adversarial attacks.
for pgd we perform 30attacks on different values of to identify the minimum value that an adversarial input can be identified.
for c w we identify the best it is able to identify for a given amount of resource iterations .
our main empirical result in this experiment is that hard is strongly correlated with min.
figure and figure show the correlation visually for two models it shows that the perturbation bounds found by these two separate attacks are different but both correlate with the adversarial hardness of the certification instance produced by provero .
the pearson correlation for all models is reported in table ii for all cases where the compared white box attacks are successful the average pearson correlation between the perturbation found by pgd pgd and hard over all models is 858and between the perturbation found by c w c w and hard is0 .
we take 25images per model to calculate the correlation.
the significance level is high p value is below 01for all cases .
319recall that provero is sound so the estimate of adversarial hardness hard is close to the ground truth with high probability .
this metric is an attack agnostic metric computed by uniform sampling and without white box access to the model.
the strong correlation shows that pgd and c w attacks find smaller min for easier certification instances and larger minfor harder instances.
this suggests that when comparing the robustness of two models one can consider adversarial hardness as a useful attack agnostic metric complementing evaluation on specific attacks.
b. scalability we test provero on38models which range from 3k 50mhidden units.
we select 100input images for each model and retain all those inputs for which the model correctly classifies.
we tested 11perturbation size l1 from 01to 25for bm1 and 4perturbation size l2 from to 255for bm2.
this results in a total of test images for38models.
we run each test image with provero with the following parameters and for bm1 and for bm2 .
we find that provero scales producing answers within the timeout of seconds for bm1 and seconds for bm2 per test image.
less than input cases for bm2 and less than for bm1 return none i.e.
provero cannot certify conclusively that there are less or more than than the queried thresholds.
for all other cases provero provides a yes or no results.
as a comparison point we tried to compare with prior work on quantitative verification prototyped in a tool called npaq.
while npaq provides direct estimates rather than the yes or no answers provero produces we found that npaq supports only a sub class of neural networks bnns and of much smaller size.
hence it cannot support or scale for any of the models in our benchmarks bm1 and bm2.
secondly we tested eran which is considered as the most scalable qualitative verification tool.
eran initially was not able to parse these models.
after direct correspondence with the authors of eran the authors added support for requisite input model formats.
after applying these changes we confirmed that the current implementation of eran time out on all the bm2 models.
provero finishes on these within a timeout of seconds.
we successfully run eran on bm1 which are smaller benchmarks that eran reported on.
there are total of 4analyses in eran.
we evaluate on the deepzono and deeppoly domains but for the deeppoly on our evaluation platform eran runs out of memory and could not analyze the neural networks in bm1.
the remaining analyses refinezono and refinepoly are known to achieve or improve the precision of the deepzono or deeppoly domain at the cost of larger running time by calling a mixed integer programming solver .
hence we compare with the most scalable of these 4analyses namely the deepzono domain.
figure plots the precision of eran against provero for all11perturbation sizes.
we find that for a perturbation sizeof more than eran s results are inconclusive i.e.
the analysis reports neither yes nor no for more than of the inputs likely due to imprecision in over approximations of the analysis.
figure shows that the verified models reduces for higher perturbations .
this is consistent with the findings in the eran paper eran either takes longer or is more imprecise for non robust models and higher values .
in all cases where eran is inconclusive provero successfully finishes within the second timeout for all test images and values of .
in above of these cases provero produces high confidence yes or no results.
as a sanity check on cases where eran conclusively outputs a yes provero also reports yes .
with comparable running time provero is able to obtain quantitative bounds for all perturbation sizes.
from these experimental results we conclude provero is a complementary analysis tool that can be used to quantitatively certify larger models and for larger perturbation sizes for which our evaluated qualitative verification framework eran is inconclusive.
to the best of our knowledge this is the first work to give any kind of sound quantitative guarantees for such large models.
c. applicability to randomized dnns so far in our evaluation we have focused on deterministic dnns however provero can certify the robustness of randomized dnns.
to demonstrate this generality we take a model obtained by a training procedure called pixeldp that adds differentially private noise to make the neural network more robust.
the inference phase of a pixeldp network uses randomization instead of picking the label with the maximum probability it samples from the noise layer and calculates an expectation of the output value.
pixeldp also produces a certified perturbation bound for which it guarantees the model to be robust for a given input image.
note that qualitative verification tools such as eran require white box access and work with deterministic models so they would not be able to verify the robustness of randomized pixeldp dnns.
we contacted the authors to obtain the models used in pixeldp .
the authors pointed us to the pixeldp resnet2810 model trained on cifar10 as the main representative of the technique.
we randomly select 25images in the cifar10 dataset and for each image we obtain the certified perturbation bound pixeldp produced by pixeldp itself.
we configure pixeldp to internally estimate pixeldp using 25samples from the noise layer as recommended in their paper.
this bound pixeldp is the maximum bound for which pixeldp claims there are no adversarial samples within the l2ball.
we use provero to check the certificate pixeldp produced by pixeldp using the following parameters .provero reports yes implying that the model has adversarial density under these bounds.
under the same threshold 2we tested for larger perturbation sizes from 1to0 .
our findings in this experiment are that provero can certify low adversarial density for perturbation bounds much larger than the qualitative certificates produced by pixeldp.
image id value pgd hard fig.
correlation graph between l1 bounds provided by provero and pgd for a fully connected feedforward withsigmoid ffnn on mnist.
image id value c w hard fig.
correlation graph between l2 bounds provided by provero and c w for a fully connected feedforward ffnn with sigmoid on mnist.
perturbation sizeverified robustness provero yes provero no provero none 25eran fig.
provero and eran verified robustness per perturbation size for bm1 for threshold error and confidence .
in particular provero certifies that for pixeldp the pixeldp model has less than 2adversarial examples with confidence at least .provero offers complimentary quantitative estimates of robustness for pixeldp.
d. performance our estimation solution outlined in section iv b applies chernoff bounds directly.
for a given precision parameter it requires a large number of samples within a factor of .
while we do not escape from this worst case we show that our proposed algorithms improve over the estimation baseline empirically.
to this end we record the number of samples taken for each test image and compare it to the number of samples as computed for the estimation approach.
we find that provero requires less samples than the estimation approach for values of 01and less samples for values of for bm1.
for larger models in bm2 and values of provero requires less samples than the estimation solution and .
in our implementation we use a batch mode to do the inference for models in bm1 and bm2 speeding up the running time of the sampling process by a factor of .
this leads to average times of 78seconds per image for bm1 for a batch size of .
for the models in bm2 we used different batch sizes so we report the average time per sample as seconds which can be used to derive the running time based.
for and all values of the average number of samples over all images is median value is standard deviation is .
for vgg16 the average number of samples is around for vgg19 it is around and for inceptionv3 samples respectively for .
for both and for vgg16 the average number of samples is for vgg19 it is and for inceptionv3 average number of samples resulting in about less samples than the estimation approach.for the pixeldp model provero takes samples.
since pixeldp models internally take 25samples from the noise layer the time taken for inference on one given input itself is higher.
provero reports an average running time per test image of roughly 500seconds.
viii.
r elated work qualitative verification methodologies have sought to exploit the advances in combinatorial solving thereby consisting of satisfiability modulo theories smt solvers based approaches or integer linear programming approaches .
despite singficiant progress over the years the combinatorial solving based approaches do not scale to deep neural networks.
consequently techniques to address scalability often sacrifice completeness abstract interpretation based techniques are among the most scalable verification procedures that over approximate the activation functions with abstract domains.
similarly optimization based approaches produce a certificate of robustness for a given input a lower bound on the minimum perturbation bound minsuch that there are no adversarial examples within that a min ball.
these techniques are however incomplete and catered to only relu activations and fully connected layers .
a promising line of incomplete techniques has been proposed employing two complementary techniques lipschitz computation and linear approximations.
hein and andriushchenko propose an analytical analysis based on the lipschitz constant but the approach assumes that a differentiable activation function thus excluding relu activations and can handle only two layers.
boopathy et al weng et al.
zhang et al have further improved the scalability of these techniques but they are still limited to 000hidden units.
while the lower and upper bounds are sound their tightness is not guaranteed.
in another line of work weng et al.
employ extreme value theory to estimate a lower bound on min albeit without theoretical guarantees of the 321soundness of the obtained bounds.
provero differs fundamentally from classical verification approaches in our focus on the development of a quantitative verification framework with rigorous guarantees on computed estimates.
baluta et al.
propose a quantitative framework that outputs estimates of how often a property holds.
network into a logical formula and use model counting tools.
their approach however is instantiated to a specific type of neural networks namely binarized neural networks and its scalability is limited to networks with around parameters.
in contrast provero scales to dnns with millions of parameters while preserving the formal guarantees of the white box approach.
webb et al.
proposed a monte carlo based approach for rare events to estimate the ratio of adversarial examples.
in this work we take a property testing approach wherein we ask if the proportion of inputs that violate a property is less than a given threshold in which case we say yes or it is far from the threshold in which case we say no .
while both approaches are black box and rely on sampling provero returns a yes or no answer with user specified high confidence whereas the statistical approach proposed by webb et al.
does not provide such guarantees.
a related area is statistical model checking that relies on sampling schemes to accept a given hypothesis.
provero algorithm is similar to a sequential sampling plan but provero s insight is that each test checks cheaper hypotheses in a binarysearch manner.
in particular in case of provero we design hypothesis in a manner that more expensive hypothesis tests are delayed as much as possible.
ix.
c onclusion provero introduces an algorithm for verifying quantitative properties of neural networks assuming only black box access and with much better test sample complexity than compared baselines.
our algorithm offers in particular a powerful new attack agnostic way of evaluating adversarial robustness for deep neural networks.
acknowledgment this work was supported by crystal centre at national university of singapore security national research foundation singapore under its nrf fellowship programme and ai singapore programme and nus odprt grant .
prateek saxena is supported by a research award from google.
part of the computational work for this article was performed on resources of the national supercomputing centre singapore and national cybersecurity r d lab singapore.