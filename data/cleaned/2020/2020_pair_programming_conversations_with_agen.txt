pair programming conversations with agentsvs.
developers challengesand opportunities forse community peterrobe pjr144 utulsa.edu universityof tulsa tulsa oklahoma usasandeepk.kuttal sandeep kuttal utulsa.edu universityof tulsa tulsa oklahoma usa jakeaubuchon jsa6790 utulsa.edu universityof tulsa tulsa oklahoma usajacobhart jch389 utulsa.edu universityof tulsa tulsa oklahoma usa abstract recentresearchhasshownfeasibilityofaninteractivepair programming conversational agent but implementing such an agent poses three challenges alackofbenchmarkdatasets absenceofsoftwareengineering specific labels and the need to understand developer conversations.toaddressthesechallenges weconductedawizard of oz study with participants pair programming with a simulatedagentandcollected4 443developer agentutterances.based on this dataset we created software engineering labels using an open coding process to develop a hierarchical classification scheme.
to understand labeled developer agent conversations we compared the accuracy of three state of the art transformer based languagemodels bert gpt andxlnet whichperformedinterchangeably.inordertobegincreatingadeveloper agentdataset researchersandpractitionersneedtoconductresourceintensivewizardofozstudies.presently thereexistsvastamountsofdeveloperdeveloper conversations on video hosting websites.
to investigate thefeasibilityofusingdeveloper developerconversations welabeled a publicly available developer developer dataset utterances with our hierarchical classification scheme and found that a bert model trained on developer developer data performed worsethantheberttrainedondeveloper agentdata butwhen using transfer learning accuracy improved.
finally our qualitativeanalysisrevealedthatdeveloper developerconversationsare more implicit neutral and opinionated than developer agent conversations.
our results have implications for software engineering researchersandpractitioners developingconversational agents.
ccs concepts softwareanditsengineering collaborationinsoftwaredevelopment computing methodologies artificial intelligence human centered computing empiricalstudiesin hci .
permissionto make digitalor hard copies of allorpart ofthis work for personalor classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acm mustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
esec fse november 14 18 singapore singapore associationfor computing machinery.
acm isbn ... .
pair programming conversations conversational agents datasets pair programming questions labels classification language models acmreference format peterrobe sandeepk.kuttal jakeaubuchon andjacobhart.
.pair programmingconversationswithagentsvs.developers challengesand opportunities for secommunity.in proceedings ofthe 30thacm jointeuropean software engineering conference and symposium on the foundations of software engineering esec fse november 14 18 singapore singapore.
acm new york ny usa 13pages.
.
introduction recentadvancesinchatbotshaveincreasedinterestinthesoftware engineeringcommunity asevidencedbythegrowingnumberof conferences and workshops that focus on bots for developers.
bots are helping developers to generate and maintain architectures mine repositories and stack overflow posts perform loadtest andpatch debugcode .botsfrequently automatetasks inopensourcesoftware oss such as maintainingcode reporting continuousintegration failures reviewing code and pull requests ensuring license agreement signatures and assigning reviewers .
these bots help developers by saving timeandeffortontedioustasks .althoughbotsincreasedevelopers productivity the primary limitation is their lack of interaction with human developers unlike existing voice based chatbots alsoknownas conversational agents inotherdomains.
conversationalagentsarewellestablishedindomainssuchas health politics and daily life.
they have increased accessibility for physicallydisabledpeople formedemotionalconnections through personal conversations e.g.
cleverbot xiaoice mitsuku provided correct and concise answers to user queries bing qa steereddiscussionstopromotespecificideas e.g.
twitterbotsaffected us presidential elections met customer needs for two thirdsofbusinessesontheweb andtransformeddailyconversations e.g.
alexa siri and google assistant .
inspired from the conversational agent literature robe and kuttal reported designguidelinestoimprovedeveloper agentinteractionsforaconversational agent to facilitate pair programming an agile method wheretwoprogrammersswitchrolesbetweendriverandnavigator to develop software .
this agent performed on par with 319esec fse november14 18 singapore singapore peter robe sandeep k.kuttal jake aubuchon andjacob hart developers when analyzing their productivity code quality and self efficacy however the development of such a pair programmingconversationalagentorvoice basedbotsforsoftware developers poses the following challenges lackofbenchmarkdatasets currently nobenchmark dataset for developer agent conversations exists for pairprogramming.
the only methodology feasible for collecting human ai conversational data is by conducting wizard ofozstudies whereresearcherssimulateanagent s behavior.thewizard sbehaviorneedstobesimulatedfor specificsoftwareengineeringdomainsforwhichtheagent isbeingdeveloped e.g.
thewizardshouldbehaveasapair programmingagentsince nosuch agentsexist.
no softwareengineering labels currently no software engineering labels exist to annotate the data needed to train conversational agents for pair programming.
past research on conversational agents useddialogue acts for representing generic human human conversations.
dialogue acts are insufficient toexpresstheuniqueintent of developer s conversations astheserevolvearoundimplementationandtestingofsoftware.
understanding developer conversations algorithms fornaturallanguageunderstanding nlu needtobetrained ondeveloper agentconversationsforbetterclassifyingdeveloper dialog.
transformer based language models have become standard for naturallanguage understanding tasks .these language models are capableof contextually representing words by utilizing neural networks with a large range of parameters from million to 175billion andaretrainedonvastamountsoftextdata e.g.
wikipedia bookcorpus reddit .
however this text data excludes programming concepts such as data types loops andmethods.
this paper takes the first step to address these challenges and lays the groundwork towards understanding developer agent conversations.
hence we formulatedrq1 rq1 towhatextentcannlu basedalgorithmsunderstand developer agentconversations?
towards creating a dataset of developer agent conversations we conduct a wizard of oz study with a simulated agent using the design guidelines from robe and kuttal .
our study task and design is inspired by robe et al.
to augment the collected data.
we collected utterances from participantsconversingwithasimulatedagent.basedonthis dataset we created software engineering labels using an open coding process to develop a hierarchical classification scheme that allows identification of intent and applicable sub intents.a hierarchical approachwas usedoverlinearto reducethenumberofoverallintents thisreducedourlabels to .
we used three transformer based language models for nlu bert gpt2 and xlnet for classifying developer agent dialog.
we found that these models largelyperformed interchangeably however bert performedmarginallybetter precisionof .
andrecallof .
.thissuggeststransformer basedlanguagemodelscan be utilized for modeling the intent and understanding ofdeveloper agentconversations.
inordertobegincreatingadeveloper agentdataset researchers and practitioners need to conduct resource intensive wizard of oz woz studies.
at present there are vast amounts of developerdeveloperconversationsonvideohostingwebsites suchastwitch.tv andyoutube thatcouldbetranscribedandlabeled however itis notevidentiftheseconversationsareequivalenttodeveloper agent conversations.
hence we formulatedrq2 rq2 to what extent can developer developerconversations be utilized for training a pair programming conversationalagent?
tounderstandwhetherdeveloperdeveloper conversations can be utilized to train pair programming agents we used the existing developer developer datafromrobeetal.
andlabeleditwithourhierarchical classification scheme.
a feasibilityofusingdeveloper developerdata.
tomeasure the utility of developer developer conversations we trained bert solely on developer developer data and a separate bertmodelondeveloper agentdataandfoundtheaccuracy ofthe firstbertmodellower by .
b feasibilityofapplyingtransferlearning.
theefficacyof using transfer learning between human human and humanagentconversationsforclassifyingdialoghasbeenwidely demonstratedforconversationalagentsintheaicommunity .hence weevaluatedthefeasibilityoftransfer learning for pair programming contexts.
we found the accuracy of bert increased when trained initially on developerdeveloperdataandthenfine tuningwithdeveloper agent data.thetransferlearningmodelwasmarginallybetterthan the baselinedeveloper agentmodel .
.
.
c differencesindialogstyle.
tounderstandthestylistic differences in the dialogs between the two datasets we conductedqualitativeanalysis.wefounddeveloper developer conversations are more implicit neutral and opinionated thandeveloper agentconversations.
the rest of the paper is structured as follows.
section discusses the related work.
section presents rq1 details on data collection thehierarchicallabels andclassification modelingusing bert gpt2 andxlnet.insection4 wepresentrq2 detailson developer developerdata compareaccuracyofbertondeveloperdeveloperanddeveloper agentdata evaluatethefeasibilityofusingdeveloper developerconversationsusingtransferlearning and evaluatequalitativedifferencesinthedialogstyles.section5discusses the threats to validity.
section highlights opportunities forsoftwareengineeringresearchersandpractitioners.section7 concludes andliststhe contributionsof our paper.
related workinse insoftwareengineering researchhasbeenconductedtocreatebots fordevelopers designandstudythefeasibilityofpair programming conversational agents labeled data for software designand development anduse transformer basedlanguagemodels.
320pair programmingconversationswithagents vs. developers challenges andopportunities forse community esec fse november14 18 singapore singapore .
botsfordevelopers researchers and practitioners have created tools to aid various softwaredevelopmenttasks.forexample idetoolsdetectsyntax errors in real time automate repetitive tasks and debug code.
oss projectsongithubmakeampleuseofbots andchatbotshave assisted newcomers and assigned them a task .
lin et al.
createdachatbottohelpdeveloperswithmicroservicebased architectures.williamsetal.
automatedfeedbackoncodecorrectness and mussbacher et al.
created an intelligent modeling assistantforcodefeedback.urlietal.
developedabottoautomaticallysuggestpatchesbasedonfailedtestcases andokanovi et al.
s bot helped developers perform load testing.
chatbots also helpeddeveloperseffectivelyfindstackoverflowposts and mine repositories .
outside of traditional software development activity matthies et al.
explored developing a chatbot for agile retrospectivestohelpteamstrackissuesacrossdevelopmentcycles.
additionally platforms for training agents have been created such as google s recsim and meta s web enabled simulation.
finally bradley et al.
envisioned a voice based context aware agent that works via the amazon alexa platform.
while past research focusesonspecificpointsinthesoftwarelifecycle noneofthemenvision an immersive interactive pair programming conversational agent.
woodsetal.
collectedconversationaldataonbugrepair generated labels using open coding and then used a logistic regression model to classify the data.
our study design for rq1 was inspired from their woz study while they envisioned a q a agent we envision an interactive pair programming agent.
later woods etal.
analyzeddifferentapproachesfortransferlearningstarting with the ami business meeting corpus and fine tuning with their previously collected bug repair data .
our paper investigatedthefeasibilityoftransferlearningforlanguagemodelstrained on developer developer dataand fine tuned with developer agent data.
.
pair programmingconversational agent robe and kuttal recently reported design guidelines for a pair programming conversational agent.
later kuttal et al.
investigated the feasibility of their designed pair programming conversationalagentbyconductinglabandwizardofozstudies.
they found no significant differences in code quality productivity orself efficacybetweendeveloper developeranddeveloper agent participants.
they found developers were trusting humble and agents facilitate knowledge transfer.
these results motivate the developmentofapair programmingconversational agent.
further robe et al.
investigated the feasibility of a thirdparty facilitation agent in developer developer conversations by conducting a lab study to simulate remote pair programming.
the data collected from this study was then annotated using generic dialogueactsthatrepresentthefunctionofanutteranceinhumanhuman conversations .
robe et al.
found annotating programming dialog using only dialogue acts to be insufficientat capturing the sporadic nature of remotepair programming conversations.
further they analysed results using support vector machines svms to classify the utterances achieving a .
accuracy.
in contrast we collected data for developer agent conversation using woz studies generated new labels specifically for developer agent conversations investigated transfer learning of developer developeranddeveloper agentdata andusedstate ofthe art pre trained language models for analyzing the data.
we envision a conversational pair programming agent rather than a thirdpartyfacilitation agent.
.
labeling ofdata researchers have created labels and annotated data for software design and development tasks.
viviani et al.
studied the automationoflocatingdialogrelatedtodesigndiscussioninpullrequestsandonlinediscussions ed douibietal.
developedaq a chatbot to assist the understanding of restapis ebertetal.
andpascarellaetal.
identifiedtheintentionofquestionsduring code reviews.
these approaches investigated highly specific activities code reviews design processes or speech types questions whereaswecreated26hierarchicallabels tailoredspecificallyto the developer agentdomain.
.
applicationsoflanguage models researchershaveevaluatedthecapabilitiesoftransformer based languagemodelsforsoftwareengineeringapplications.xieetal.
categorizedfunctionalityverbswithinapidescriptionsinto categories by fine tuning a pre trained bert model.
additional applications of bert include machine translation failure detection software analysis and technology comparison tools via online discussions .
futher gpt has been adapted by svyatkovskiyetal.
forautomatedcodegenerationinavariety ofprogramminglanguages whilexlnet asanewernichelanguage model hasyettobeappliedtomanysoftwareengineeringdomains.
we differ from previous research sincewe investigated the utility oflanguagemodels to classifypair programming conversations.
rq1 developer agentdata .
data collection to address the challenge of lack of developer agent datasets we conductedvirtuallabstudies simulatinganagentusingthewizard ofoz woz methodto collectdeveloper agentconversations.
.
.
wizard of oz method.
woz is a simulation study where participantsinteractwithanautomatedagent secretlycontrolledby another human the wizard .
this simulated experience allows researchers to analyze human ai interactions prior to the implementation of an agent .
woz has been extensively usedfor machinelearning ml feasibilitystudies designresearch naturallanguageinterfacessuchasconversationalagents and question answer conversations about bug repair with an agent .
transcripts gathered from woz studies lay the foundation for the use of ml algorithms as it considers the unique qualities of human agent dialogas opposedto typical human discourse .
321esec fse november14 18 singapore singapore peter robe sandeep k.kuttal jake aubuchon andjacob hart figure wizard of oz study.
the agent s avatar and text tospeech tts weresecretlycontrolledbyresearchers wizard .
.
.
simulatedagentdesign.
wedesignedouragentanditsresponses based on past research by robe and kuttal which recommendeddesignguidelinesforcreatingapair programming conversationalagent.theiragent sdesignwasinspiredfrommultidisciplinaryresearchonsoftwareengineering conversationalagents human computer interactions human robotic interactions education intelligent tutoring systems psychology and management science.
further technical and social skills are crucial for being an effective team member in the software engineering industry therefore both are simulated.
social skills of a developer to give the agent a human like embodiment it was given a 3d avatar and text to speech synthesistocommunicate.whenactingasadriver codewaspasted withinasharedwindow inchunkstoappearmorerobotic.
when acting as a navigator the agent gave guidance by suggesting or clarifying goals offering abstract code ideas and asking questions to promote divergent thinking.
as the agent would not have an all encompassing knowledge it would deflect with its own questions e.g.
whatdoyouthink?
orsuggestedthatthedeveloperwrite the implementation e.g.
what would that idea look like?
can you write it?
when participants asked questions outside of its capabilities.
the agent negotiated the driver and navigator roles withtheparticipanttobalancecontributions.theagentadopted the personality of an anthropomorphic and effective developer by introducing itself acting as a team player showing uncertainty and asking for verification and motivating its partner .thesefeaturesprovideclearbenefitstoa developers performance productivity andcreativity .
technical skills of a developer to simulate technical skills both as a driver and a navigator the agent design was informed byvastresearchonsoftwareengineeringliterature.whenacting as a driver automatic code contribution was facilitated by code search and feedback generation techniques.
test case generation was based on past research including the conversionofdiagrams suchasumlandfsms totestcases andconversionofuserstoriestoscenarios thentotestcases .codelocationwasbasedonpreviouslyinvestigatedstatic and dynamic techniques unnecessary code was found through automated tools such as ucdetector and missingcode was found through research in the haskell programming language .
.
.
wizardofozstudy.
we designedour studyto mimicrobe etal.
research thisallowedustoaugmentthecollecteddata andtoinvestigatethefeasibilityofdeveloper developerdata see .
.
.similartorobe sstudy ourstudyparticipantsweretasked to complete a tic tac toe game implementation within a minute timeframe toavoidfatigue usingtest drivendevelopment.our participants completed a demographics background questionnaire prior to starting the study.
participants learned the concepts of pair programming thinkaloudmethod andtest drivendevelopmentthroughvideotutorials.
participants were also provided with a tutorial outlining the functionality of the agent.
the think aloud method encourages participantstovocalizetheirthoughtsandfeelingsastheyperform the task this helps model their cognitive processes and in our study to collect conversations with an agent.
to collect adiverserangeofdialog participantsadheretotest drivendevelopment apracticewheredeveloperswritetestcasesbeforewriting code .
figure1illustrates our woz study design.
participants pair programmed with an agent using the saros plugin for the eclipse ide.
theagent s3davatarwasgeneratedbythefacerigembodiment software alsoprovidinglip synchronizationofthewizard sface and googletext to speechsynthesizedthewizard s voice.
video and audio communication with the agent was conducted over skype discord orgooglehangouts.twowizardsmonitoredthe participant s face voice and screen while collaboratively controlling the agent s actions.
one wizard was a graduate student with years of programming experience and the other was an undergraduate student with years of experience.
both wizards were trained by conducting preliminary studies.
they maintained the illusion of an agent by adhering to a script of templated dialog options .basedon theutterancefromtheparticipant thewizard chose fromalimitedselectionofresponse withoutreplacement filling inblankswithcontextual wordsas necessary.
usingaconstrainedwozprotocol thewizardssimulated all components of a conversational agent including intent understanding dialogue state tracking dialogue policy and response generation.
wizard interacted with the participant using our customelectronapplication aguiframework toautomatethe selectionofdialogresponsesfromthewizards scriptwithaclick ofabutton.wizard2simulatedthetechnicalskillsofadeveloper.
in the future copilot can be utilized for the automated code recommendation.
while the wizards attempted to provide an equal ratioofcontributionsbetweenstudies someparticipantsmayhave receivedless helpif they ignoredthe agent ssuggestions.
.
.
participants.
14participants 6professionalsand8computer science majors were recruited to pair program with an agent.
participants programmingexperiencerangedfrom2to20years.these studieswereconductedduringthecovid 19pandemic forcingall studiestobeconductedvirtuallythusparticipantswerenotsubject to all the control parameters of a traditional lab study as they used theirowndevicesandworkedintheirworkspaces.thisallowedus torecruitparticipantsfromoutsideouruniversityandprofessionals from differentgeographicregions.
322pair programmingconversationswithagents vs. developers challenges andopportunities forse community esec fse november14 18 singapore singapore .
labeling toaddressthelackofsoftwareengineeringlabels wecreatedan initialsetofdialogintentlabels.
to mimic the agents actions the wizards based their actions on the developer s intent.
if a participant asked can i drive now?
the wizard determined that the developer intended to switch roles and drive.
however agents cannot intuitively understand intent andmustclassifydialogintodiscretecategories.wedevelopeda hierarchicalclassificationschemeonthedeveloper agentdatato reflectthedialog intentofdeveloper agentconversations.thiswas done because developers conversations are uniquely specific to the implementation and testing of code.
the existing conversation benchmarkscontaindialogspecifictodomainssuchascustomer support restaurant ordering which can not be adapted for softwareengineeringdomain theagentinteractedwithdevelopers usingaspecific hand craftedprotocol so the emergingrange of interactions with developers became quite narrow.
by capturing this specific style of engagement the labels will effectively satisfy theinformationneedsofafuturepair programmingconversational agent lastly ahierarchicalscheme reducesthenumberofpotentialclassifications.
.
.
hierarchical classification scheme .
for generating labels weadoptedanopencodingprocessfromsocialsciences and pastresearch .asafoundationweadoptedgenerallabelssuch as feedback thanking and answers from dialogue acts blue rowsin table .
dialogueactsrepresent the function of an utterance within the domain of computational modeling .
dialogue acts have been used to categorize intent in the developmentofconversationalagentsinotherdomains and study conversational speech in co located and remote pair programming studies .
while dialogue acts generally capturesyntacticandstylisticinformationcommonacrossallformsof communication the kind of information exchanged via pair programming dialog necessitates a further specialized set of labels.
for example if a developer asked wait are we working on the horizontal win test?
traditional dialogue acts would be able to identifythatitisayes no question butmightnotknowthatthe developer is requesting a clarification of the current programming task goal.
hence through an open coding process we generated more specific pair programminglabels useful to our domain.
weiterativelylabeled merged pruned andmodifiedpotential labelsacrossmultipleroundsuntilafinalsetofdistinctlabelswere established .
figure2illustrates our hierarchical approach workinglikeaunixpipeline itbeginswiththeroot intentclassifier whose output may result in further classification in a subset of thefollowingfoursub intentclassifiers delivery programming acts role andtone.table1listsourlabelswithexamples andfigure2illustrates the relationship between the root intentclassifier labelsandeachassociatedsub intent.returningtoourpreviousexample the developer asked wait are we working on the horizontal wintest?
itsrootintentistask related seetheredoutlineson figure2 whichtriggersthe delivery andprogramming acts subintent classifiers resulting in the clarification andtask goal labelsrespectively.finally byhavingmultiplerootintentsshare sub intentswithinourhierarchy tone forexample canbetrainedtable pair programming labels blue rows represent dialogue acts adapted from others have been tailored explicitlyto accommodatedevelopers intent example task control can i drive?
task related which test caseshould we do next?
answer no i don tthinkso.
feedback ohok i see what you re greeting nice to meetyou.
think aloud for int i isless than3.
thanking yeah.
thank you.
repeat wait what didyou say?
uncertain i mnot sure what s going onhere.
delivery example question where should we start?
recommendation no i don tthinkso.
direction ohok i see what you re clarification wait what are we workingon?
programming acts example task goal let s work onahorizontal win.
comprehension let s take alook at what s written.
attend location oh that sonline64.
haltwork nonono don twritethat.
code italsoneedsto be changedto true.
idea howcan we checkfor awin?
runcode test shouldwe run the tests?
role example driver can i try?
navigator howaboutyou give itago?
either shouldi startorwouldyou like to?
tone example positive yes that looks great!
neutral okay sure.
negative i don tlike where this isgoing.
using utterances from both answerandfeedback .
notetonedetectioncanbeperformedbyexistingsentimentanalysisalgorithms infuture agentdesign.
weutilizeahierarchicalapproachoveralinearapproachforclassificationtolimitthetotalnumberoflabels.whilealinearapproach wouldconsider task control driver clarification tobecompletelyindependentfrom task control driver direction ahierarchicalapproachrecognizesthattheybothshare task control driver.
rather than distinguish between label combinations ahierarchicalapproachfocusesonasetof26distinctlabels.the small label setisbeneficialfor betteraccuracyof ml algorithms.
.
.
transcriptlabelingmethodology.
onceourlabelswereestablished on developer agent data two researchers independently labeled20 ofthetranscriptsandreachedainner ratereliabilityof .760usingcohen skappa whichisconsideredsubstantialagreement.
cohen s kappa is calculated using k po pewherepois the observed rater agreement and peis the expected random agreement orexpectedagreementbychance.thus tocalculate pe 323esec fse november14 18 singapore singapore peter robe sandeep k.kuttal jake aubuchon andjacob hart figure2 hierarchicalrelationshipbetweenintent sub intents andlabels white .highlightedlabels red representtheintent taskrelated clarification taskgoalfortheutterance wait are we workingon thehorizontal win test?
asummationwasused pe n2 summationtext.
knk1nk2wherenisthenumber ofpredictionsforeachcategory k byeachreviewer.as poisthe observedagreement thisisfoundbytakingthenumberofagreements divided by the total number of dialogues.
the remaining wasindependentlylabeledbyoneresearcher.ourfully labeled dataset is available at .
on average transcription and labeling for an individual study session averaged hours of consistent effort hoursintotal .
.
classification andmodeling oncethedatawascollectedandlabeled weneededtodetermine ifthisdatacouldbeusedtotrainnaturallanguageunderstanding nlu algorithms for future agents.
we used transformer based languagemodelswhichhavebecomestandardfornaturallanguage processing tasksto classifyintents .
.
.
utilizing transformer based language models.
we evaluated threetransformer basedlanguagemodels bert gpt andxlnet becausethesemodelsarepre trainedtoestablishabaseunderstanding of language e.g.
english and can be further fine tuned for down streamtasks e.g.
intentclassification inspecificdomains e.g.
restaurant reservation .
we chose bert as it is a state ofthe art language model gpt as it is another well established language model that uses its own transformer architecture and xlnet asit has out performed bert in other benchmark datasets .
bert bidirectional encoder representations from transformers bert wasdevelopedbygooglein2018 .bertisbuiltusingstackedtransformerencoderblocksandallowsforthefusionof both left to right and right to left context simultaneously through itsbi directionaldesign.bertiscommonlyusedforlanguagetasks such as classification question answer q a and named entity recognition locateandclassifycertainwordswithinasentence .
bertusesthebookcorpus 800mwords andenglishwikipedia 500mwords corporafor pre training.
gpt generativepre trainedtransformer2 gpt wasreleased in by openai as a successor to gpt .
gpt differs frombertsinceitusesastackoftransformerdecoder ratherthanencoder blocks and it is uni directional meaning it only uses leftto rightcontext.additionally itistrainedonanincrediblylarge dataset of8million webpages i.e.
webtext .
xlnet xlnet is a bidirectional transformer similar to bert releasedin2019bycmu andgoogle researchers that largelydistinguishesitselfbyitsimprovedtrainingmethodology .when training insteadofpredictingindividualmaskedwordsfromeither theleftorrightdirection xlnetpredictsasequenceofwordswith respecttoallpossiblepermutationsoftheordering.additionally xlnet incorporates ideas from the state of the art auto regressive model transformer xl including relative position encoding andasegment recurrence mechanism.
.
.
implementation.
inthis paper we usedthe transformers python package from huggingface and specifically selected the following pre trained models bert base uncased xlnet base cased andgpt .
for our classification task we connected the pooledoutputofeachmodelwithadropoutandalinearregression layerusing a tanhactivation function that outputs avector sized according to the number of classes.
the model was trained separatelyforeachcategoryoflabels intent delivery programming acts role andtone foratotalof5models.weusedthedefault8 batchsize 5e 5learningrate 500warm upsteps .01weightdecay andadamwas the optimizer.
.
.
metrics.
we report the result of each classifier as an average over separate runs using new train validate test splits.
the splits followed the same trainingmethodology as performedby nguyen et al.
to present bertweet and namazifar et al.
to map natural language unit for a question answer problem.
we report common metrics for evaluating classifiers i.e.
precision recall and f1 measure .precisionscoresdescribethenumberoftimesa predictionfor anindividual labelis correct i.e.
thepercentageof true positives out of all the predictions for a given label .
recall scoresarethepercentageofinstancescorrectlypredicted outofall ofalabelstotalinstances.thef1 scoregivesaharmonicaverage of the precision and recall scores.
when averaging these metrics across all of our labels we utilized weighted averages to normalize representation among the labels.
324pair programmingconversationswithagents vs. developers challenges andopportunities forse community esec fse november14 18 singapore singapore table comparison of three transformer based language models bert vs. gpt2 vs. xlnet trained on developer agent data.
modelintent delivery pas role tone weighted average prec.
recall prec.
recall prec.
recall prec.
recall prec.
recall prec.
recall bert .
.
.
.
.
.
.
.
.
.
.
.
gpt .
.
.
.
.
.
.
.
.
.
.
.
xlnet .
.
.
.
.
.
.
.
.
.
.
.
.
.
cannlu basedalgorithmsunderstanddeveloper agentconversations?
toinvestigatetheperformanceoftransformer based language models in a pair programming context we compared threelanguagemodels bert gpt andxlnet thatdifferintheir training dataset bert gpt and architecture bert gpt and xlnet .modelsweretrained validated testedon75 and15 ofdeveloper agentdata respectively.
results in table 2show all three models performed interchangeably but bert had a slight edge over gpt .
and .
and xlnet .
and .
attheaggregatelevel.themostnotable differencesincludexlnetperformedbestonlyinthe programming actsub category bert .
and .
andgpt .
and .
whereas bertandgpt 2eachtook2categorieswithbert takingrole thebestperformingsub category andaggregateaccuracy.
additionally we performed a one way analysis of variance acrossthethreemodelswithprecisionandrecallreceivingap value ofx and yrespectively showing thatthe modelsperformed interchangeably.
given bert s aggregate and sub category scores in comparison to the other models we report our results using bert furthermore the similarityamong scores suggests little benefit to exploringothertransformer basedlanguagemodels.
rq2 developer developerdata to utilize the vast arrays of existing developer developer conversation data available though video hosting websites such as youtube andtwitch we were motivatedto framerq2.
.
data collection we used the developer developer conversational data from robe et al.
as they used a machine learning algorithm svm to understand developer conversations inpair programmingcontext.
.
labeling we labeled the data obtained from robe et al.
studies using our hierarchical classification scheme figure .
for the developerdeveloper data we found cohen s kappa of .
for the two researchers each labelling of the transcripts.
the remaining data waslabeledbyoneresearcher.thetranscribingandlabelingtook hoursofwork.
.
classification andmodeling as discussed in section .
.
we used bert to compare developerdeveloper anddeveloper agentconversations to answer rq2 .
.
feasibilityofusingdeveloper developerdata.
tomeasure the utility of developer developer data we compared two bert language models trained exclusively on either developer developer ordeveloper agentdatatopredictlabelsfordeveloper agentdialog.
thefirstbertmodel da wasentirelytrained validated testedontable3 resultsofclassifyingdeveloper agentdialogusing bert trained on developer agent da developer developer dd anddeveloper developerfine tunedbydeveloper agent conversations dd da .
bert precision recall f1 measure da .
.
.
dd .
.
.
dd da .
.
.
and15 ofdeveloper agentdatarespectively.thesecond bertmodel dd wastrainedon100 ofthedeveloper developer data and validated tested on and of developer agent data.
overall results can be found in table .
precision and recall scores for eachcategory can be foundintable .
thedeveloper agentdataisrepresentativeofanidealizeddataset andthedeveloper developerdataissymbolicofthereadilyavailable data.
for our baseline da model roleperformed the best .
.
followed closely behind by intent .
.
delivery .
.
and tone .
.
.
itisnotablethat programming acts .
.
performedtheworst however it isthe secondlargestclassifier bynumber of sub intents.
based on the overall metrics training with developer developer data dd had10.
lowerrecall .
lowerprecision and10.
lower f1 measure.
results fordd intentandtonehad the highest precision and recall .
.
and .
.
while for programming acts they were moderately high .
.
consideringitdistinguishedbetween seven separatelabels however theprecisionandrecallof delivery androlewere66.
.
and63.
.
evenwhenonlyclassifyingbetweenfour and three labels respectively.
these results show that at least for some categories training exclusively with developer developer conversations isfeasible.
.
.
feasibilityofapplyingtransferlearning.
in4.
.
wewere able to demonstrate that developer developer data can be used withreducedaccuracy.theefficacyofusingtransferlearningbetween human human and human agent conversations for classifying dialog has been widely demonstrated in ai community .bothsupervisedandunsupervisedtransferlearningapproacheshavebeenusedinthedomainofconversational agents question answer agents and for naturallanguageprocessingapplications .woodsetal.classified dialogue acts for virtual agents for software engineers during debugging and presented transfer learning from general conversations .toevaluatethefeasibilityoftransferlearningin the pair programming context we formulated .
.
.
325esec fse november14 18 singapore singapore peter robe sandeep k.kuttal jake aubuchon andjacob hart table bert precision and recall for intent and sub intents trained on developer agent da developer developer dd and developer developerfine tuned by developer agentconversations dd da .
bertintent delivery progacts role tone p r p r p r p r p r da .
.
.
.
.
.
.
.
.
.
dd .
.
.
.
.
.
.
.
.
.
dd da .
.
.
.
.
.
.
.
.
.
table bert model precision and recall trained via transfer learning from developer developer to developer agent domains dd da .
support occurrences within dd anddadatasetsislisted significantdifferences blue based on percentage.
bertdd da precision recall f1dd support dasupport intent .
.
.
task control .
.
.
.
.
task related .
.
.
.
.
answer .
.
.
.
.
feedback .
.
.
.
.
greeting .
.
.
.
think aloud .
.
.
.
.
thanking .
.
.
.
.
repeat .
.
.
.
.
uncertain .
.
.
.
.
delivery .
.
.
question .
.
.
.
.
recommendation .
.
.
.
.
direction .
.
.
.
.
clarification .
.
.
.
.
program acts .
.
.
task goal .
.
.
.
.
comprehension .
.
.
.
.
attend location .
.
.
.
.
haltwork .
.
.
.
.
code .
.
.
.
.
idea .
.
.
.
.
runcode test .
.
.
.
.
role .
.
.
driver .
.
.
.
.
navigator .
.
.
.
.
either .
.
.
.
.
tone .
.
.
positive .
.
.
.
.
neutral .
.
.
.
.
negative .
.
.
.
.
we initially trained a bert model on developer developer data and subsequently fine tuning it on developer agent data.
this twostep approach outperformed training on exclusively developerdeveloperdata dd by onaverage.thefirsttrainingstepuses developer developerdatafollowedbya75 15train validate test split withdeveloper agentdata.
tables3and4showthatthetransferlearningapproach dd da achievedprecisionandrecallscoresof80.
and79.
.theseresultsareslightlyhigher .
and .
thanourbaselinelanguage modeltrainedondeveloper agentdata da .notably programming actswas the most improved scoring .
and .
higher.
otherwise intentremainedthesame .
and .
and delivery .
and .
role .
and .
and tone .
and .
saw marginal changes.
further we performed a one way anova testwiththethreetrainingapproachesgettingap value of .29e implying a difference between the three groups.
we thenperformedat testwiththeddandda ddanddd da and da and dd da getting p values of .81e .92e and .
respectively.
the results from the t test show that training with da and dd da performed interchangeably and suggests that transferlearningfromdeveloper developerdatamayprovidesome utility when classifying developer agent dialog particularly for programming relatedknowledge.
326pair programmingconversationswithagents vs. developers challenges andopportunities forse community esec fse november14 18 singapore singapore .
.
differencesindialogstyle.
ourresultsshowdifferencesinaccuracy when training on developer developer and developer agent conversationaldata.thesealignwithrobeetal.
whofound thatpairprogrammingdialogposesauniquechallengeformachine learning as it is often unpremeditated and inadequately structured compared to normal conversational speech.
to understand the differences in depth we conducted qualitative analysis of our data to findstylisticdifferencesinthedialogsofdeveloper developervs.
developer agent.
table5comparesthefrequencies support ofpairprogramming labelsbetweenthedeveloper developeranddeveloper agentconversations.whilemostsub intentsdifferedinfrequencyitisnotable that the intent categories adopted from dialogue acts remained the same answer thanking and uncertain as these capture aspects ofgenericconversations.
implicit vs. explicit communication.
our analysis of the supportmetricsidentifiedacommontrend developer developer studies relied on more implicit means of communication while developer agent studies utilized more explicit questions and requests.
developer developer studies focused on the exchange of ideas idea .
vs. .
through the use of directions .
vs. .
.however whenworkingwithanagent developersoftenasked questions .
vs. .
and clarifications .
vs. .
related to the task goal .
vs. .
attend location .
vs. .
and run code test .
vs. .
.whiledeveloperscouldeasilyprogressthroughtasks withanotherdeveloper developer agentstudiesrequiredexplicit communication which led to a higher number of task control .
vs. .
requests and accompanying answers .
vs. .
.forexample indeveloper agentstudy theagentstated i think we are missing code participant responded with a question shouldihavenottakenthatout?
.onthecontrary indeveloperdeveloper study participant as a driver was uncertain on the implementationofcode participant2asanavigatorgavethedirection so why don t we just ... write the false assertion before ... we fill that row.
developers communicatedimplicitly inwaysthe agents cannot.
further bothstudies switchedpair programmingrolesat similar rates however control was communicated through formal exchangesindeveloper agentstudies whilecontrolflowedmore freelyindeveloper developerstudies.inordertobecomethedriver the agent had to explicitly ask as seen with participant can i drive for a bit?
.
this kind of exchange happened more subtly indeveloper developerstudies instudy9 participant2gavethe driver role to participant by saying can you do the or thing i don t know where that is on this .
while there was still an exchange ofrolestherewasnoexplicitdialogabouttherolesused.thedifferences in regard to explicit vs. implicit communication styles across studiescorrespondswithpreviousresultsonuserexpectationsof conversational agents which found that usersassessed the intelligence of agents and adapted their own behavior to the agent s capabilities .
pointedvs.
neutralfeedback.
participantsof thedeveloperagentstudymoreoftenexpressedeither positive .
vs. .
ornegative .
vs. .
tone while developer developer studiesremainedmore neutral .
vs. .
.whenworking with a fellow developer participants would often nod along asthe navigator using dialog such as okay uh huh and yeah.
thisleadto higher feedback occurrencesindeveloper developer studies .
vs. .
.
this suggests that participants were lessworriedaboutthesocialcostofgivingtheiropinionwithan agent as foundinprior research .
askingforvs.givingopinionsregardingcodeverification.after writing code participants in driver role were more likelytoasktheagentforverificationoftheirworkusing clariification .
vs. .
togetherwith code.for instance after writing a section of code participant asked are you okay with that?
similarly participant asked is this good?
likely participantsassumedthattheagentknewthecorrectanswerand wanteditsfeedback asparticipant9said itrustedthecodethat the agent gavemebecauseiknewitalreadyknewtheanswer.
while verification did occur often within developer developer studies participants voiced their opinions on their own in navigator role rather than waiting for the driver to ask.
for example in developerdeveloper study participant said like when it equals to zero the three minus zero and her partner participant responded with oh ya ya.
definitely.
yes.
these results align with where they foundthatdevelopersgivemoreinstructionsandfeedbacktoother developers as well as ask more questions to agents rather than humans.
weconjecturetheloweraccuracyofthebertmodelfordeveloperdeveloper conversations was because the dialogs were more implicit neutral andopinionatedthandeveloper agentdialog.
threats to validity wheninterpretingresultsofempiricalstudies threatstovalidity mustbeconsidered.externalthreatstovaliditymayarisefromour small datasetof utterances.but thesedialogs were collected from 24diverseparticipants witha widerange ofdialog and we release our complete set of transcripts publicly .
additionally athreatmayarisefromourselectionofparticipants.weonlyrecruited6professionalsforourstudiesincomparisonto26students.
despitethisdisparity wearguethatstudentscanbejustaseffective asprofessionals especiallyconsideringoursimpletask tic tac toe .
further koetal.
establishedthatstudentsandprofessionalsare equivalent whentheirknowledge skills andexperiencesfitwithin thetool sintended userpopulation.
threats to internal validity may arise based on the design of our agent.thisisduetothe factthatthe scope oftheagentmaynot be representative of all pair programming agents.
further alternative agent models may spur different kinds of dialog.
however the agent s interactions and capabilities were informed from a breadth ofresearchinavarietyofdomainsandrepresentsanelegantanthropomorphic agent design .
further there are possible errors that may have arisen in our manual labeling process.
additionally ourhierarchymaynotencompassallpossiblepair programming specificlabels.weattemptedtomitigatethesethreatsbyfollowing state of the artdata collection labeling andprocessing methods.
construct threats arise from the simplicity of our task.
we have notconsideredhowdeveloper agentdatamightchangewithdialog frommorecomplextasks e.g.
apis recursion classhierarchies .
butoursimpletaskwasessentialforevaluatingthefeasibilityof transformer basedlanguagemodels andtransfer learning.
327esec fse november14 18 singapore singapore peter robe sandeep k.kuttal jake aubuchon andjacob hart opportunities forse community the implementation of a pair programming conversational agents for developers encompasses challenges that present opportunities for further research.
.
creatingpair programmingbenchmark akeytosuccessinemergingairesearch suchasconversational agentsistheavailabilityofopenbenchmarkssuchasmultiwoz persona chat avsd alexa prize data and switchboard .eachbenchmarktargetsdataforspecificapplicationsand domains for example multiwozis comprised of10 thousand touristreservationdialogs.creatingabenchmark dataset is challenging in ai researchers have collected benchmark datasets using various mechanismssuch as participant compensation platforms like amazon mechanical turk multiwoz live user interactionsfromalexaprizecompetitions websitessuchas reddit and twitter dstc and bing users search queries ms marco .
currently our dataset consists of dialogs related to the implementation of a tic tac toe game but more data must be collected for different tasks to increase the robustness of future conversational agentsfor programming.ourdataset laysgroundworktowardthecreationofaholisticbenchmarkdatasetforpair programming.thoughprogresshasbeenmade weasasoftware engineering community need to collect robust conversational data allowing researchers and practitioners to more easily develop and compare conversational agentsandpedagogical tools.
.
generalizability fortraining data a pair programming conversational agent must be generalizable acrossanynumberoftaskobjectives codebases orprogramming languages andtherefore mustbetrainedoveradiverserangeofapplications.itisimpracticaltorelysolelyondeveloper agentdatafor trainingduetothehighcostofconductingwozsimulations.hence usageofexistingdeveloper developerconversationsavailablevia onlineresourcescan beintegrated throughtransferlearning.our paperdemonstratedthefeasibilityofusingtransferlearningand our transfer learning model dd da was only marginally better .
and .
thanourbaselinedeveloper agentmodel da .
previously ahmadvandetal.
achievedanadditional2.
improvement using transfer learning from human human to humanagentcontextsontheirownconvolutionneuralnetwork cdac model using a benchmark dataset switchboard spontaneous telephone speech and fine tuning with an alexa prize dataset socialbotinteractions .theyfoundthatfine tuningthemodelwith asmallamountofhuman agentconversationshelpsimproveaccuracy.
future research must identify the optimal ratio of training data from developer developer and developer agent conversations toachieveoptimalresultswhilealsolimitingthecostofdatacollection.
anotherpromisingavenueisutilizingunsupervisedpre training a common technique to tailor deep learning language models to specific domains.
tod bert a bert model was pre trained on human human task oriented datasets via unsupervised masked language modeling outperforming the baseline bert model for natural language understanding of conversational agents.
these pre trainedtechniquescanhelpinreducingthecostofmanually figure3 architecturediagramforconversationagent.natural language understanding component is addressed in thispaper.thefutureresearchneedstoexploreothercomponents.
labeling data for specific domains however this technique still needsto be exploredinthis domain.
.
implementing conversational agent platformsfordevelopingconversationalagentssuchasibmwatsonassistant sapconversationalai andoracledigital assistant cannotbeusedbecausetheyfocusonsimple basic enterprise problems such as answering questions and solving tasks based on web or enterprise data.
a conversational agent for pair programming depends strongly on unique aspects such as code state test cases success and errors obtained by interacting with an ide.
also stylistic differences between pair programming and normal conversations require an alternative feature selection strategy whenusingmachinelearningalgorithms.hence theconversational agentandit scomponentsneedto be developedfrom scratch.
figure3shows the overall architecture and related components ofaconversationalagent.apairprogrammingconversationalagent should be able to track developer s dialog as well as programming states on ide to implement dialogue state tracking generate policy based on developers context dialogue policy and generate responsestothedeveloper naturallanguagegeneration .forcode generation we can either rely on the previously collected samples or future work should explore utilizing tools such as codebert andcopilot to generatecode.
.
implications fortools .
.
virtual question answer agent.
we classified developers questions from our developer agent studies that can be utilized forcreatingavirtualquestion answer q a agent.ourqualitative analysis showed that developers desired continuous feedback from theagentasseenbyanincreasein question s .
vs. .
andclarification s .
vs. .
.
these results align with past research showing developer pairs tend to verify software development progress and tend to ask more questions when workingwithanagent.weanalyzedourtranscriptsforany question or clarification aswellas recommendation labelsthatexpectedan immediateresponsefromouragentandusingopencodingprocess see section .
.
identifiedthe questions asked by participants to ouragent .outofthe23questiontypesidentifiedinour studies onlyfourweresimilartopreviousresearchthatinvestigated developers questions sillitoetal.
categorized44question typesthatdevelopersaskedduringasoftwareevolutiontaskand ko et al.
explored developer s information needs.
the low 328pair programmingconversationswithagents vs. developers challenges andopportunities forse community esec fse november14 18 singapore singapore table6 thetypesofquestionsparticipantsaskedduringthe developer agentstudyandtheirrespectiveoccurrences.
representsquestions fromprevious research questiontype clarifywho should be driver navigator?
whatshould we donext?
should this user story functionality be implemented?
is this functionalityimplementedyet?
total 107implementis this ideavalid?
how code?
whatare you thinking?
what is the purpose of this code?
how is it implemented?
are there alternative solutions?
where isthe entity?
shouldwe remove this code?
where should this code be written?
whatvariable should we return?
where is the code involved in the implementation of this behavior?
where isthe entity namedsomething like this?
whatare the arguments to this function?
whatshould the name ofthis entity be?
documentation related e.g.
what asserts can i do?
1 total 118testshouldwe test it?
is the code complete correct?
whyisthere an error?
study related e.g.
whereis theuserstories?
howdowe knowitworks?
total correlation is because previous research identified questions regardingcodeevolutionratherthanpotentialsolutions and more advanced questions related to variable types or class hierarchies anddidnotmanifestwithoursimpletaskoftic tac toe.thesequestions canbe utilizedfor qualitative analysisof pair programming conversations as well as creating q aassistants.
.
.
intelligenttutoring systems.
howdeveloperscommunicate andthetypesofquestionstheyaskcanbeusefulinotherprogrammingrelatedapplications suchasintelligenttutoringsystems its and assisting developers with disabilities.
future its agents should be designedtobe explicitsincedevelopersprefer explicitcommunication with agents.
researchers and practitioners of itss can design their agents to support more precise dialog.
furthermore allofourclassifiers exceptfor role canbeutilizedbyitss specificallyfocusedonprogramming.finally abetterunderstandingof these differences allows us to make programming more accessible.
past research has revealed different ways in which programmingislargelyinaccessibletothosewhoarevisuallyimpaired.bycreating interactive tools suchas conversationalagentsand virtual q a assistants we open up the world of programming to more diversedevelopers includingthe visually impaired.
.
.
supporting software engineering activities.
a fully implemented conversational agent can be adapted to support current botsforsoftwareengineeringtasks to provideamoreimmersiveconversationalagentthatcommunicates viavoice throughapersona.
conclusions oursisthefirststudythatcollecteddeveloper agentconversational data generatedsoftwareengineeringspecificlabels investigated theefficacyofusingtransformer basedlanguagemodels andexplored the feasibility of transfer learning for pair programming conversations.
our paper makes the following contributions we provide hierarchical label scheme for developers intent developedusingamanualopencodingprocessandtailoredforpair programmingagents.oursetoflabelscanbeusedforbothmachine learningalgorithmsaswellasmetricsforqualitativeanalysisofpair programmingconversations.
wemanuallylabeledtranscripts ofutterancesfordeveloper agent anddeveloper developer with our hierarchical labels.
our dataset serves as a starting point for the creation of a future pair programming benchmark dataset.
for reproducibility our data can be found at .
we gatheredandcategorizedquestionsthatdevelopersaskedouragent.
we demonstrated the applicability of transfer learning between developer developer and developer agent data for an agent and establishedtheutilityofusingtransformer basedlanguagemodels for developer agent dialog.
our results have implications for programming virtualq aassistants intelligenttutoringsystems and bots that support software engineering activities.
additionally wehighlightopportunitiesforresearchersandpractitioners tocreateapair programmingbenchmarkdataset continuallyexploreavenuesthatwillincreasethegeneralizabilityoftrainingdata and implementthe remainingcomponents of a pair programming agent.