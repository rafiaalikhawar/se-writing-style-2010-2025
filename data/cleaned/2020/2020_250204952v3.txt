boosting path sensitive value flow analysis via removal of redundant summaries yongchao wang yuandao cai and charles zhang department of computer science and engineering the hong kong university of science and technology hong kong china email ywanghz ycaibb charlesz cse.ust.hk abstract value flow analysis that tracks the flow of values via data dependence is a widely used technique for detecting a broad spectrum of software bugs.
however the scalability issue often deteriorates when high precision i.e.
path sensitivity is required as the instantiation of function summaries becomes excessively time and memory intensive.
the primary culprit as we observe is the existence of redundant computations resulting from blindly computing summaries for a function irrespective of whether they are related to bugs being checked.
to address this problem we present the first approach that can effectively identify and eliminate redundant summaries thereby reducing the size of collected summaries from callee functions without compromising soundness or efficiency.
our evaluation on large programs demonstrates that our identification algorithm can significantly reduce the time and memory overhead of the stateof the art value flow analysis by and respectively.
furthermore the identification algorithm demonstrates remarkable efficiency by identifying nearly of redundant summaries while incurring a minimal additional overhead.
in the largest mysqld project the identification algorithm reduces the time by seconds .
hours with a mere .
seconds of additional overhead leading to a ratio of time savings to paid overhead i.e.
performance gain of .
.
in total our method attains an average performance gain of .
.
index terms value flow analysis inter procedural analysis i. i ntroduction path sensitive value flow analysis is highly effective in detecting a broad spectrum of software bugs such as memory leaks in resource usage null pointer dereference in memory safety and the propagation of tainted data in security properties by tracking the flow of values along data dependence relations.
essentially detecting these bugs boils down to collecting feasible source sink paths over a program dependence graph .
for instance detecting the null pointer dereference npd considering the null value as the source and the pointer dereference statement as the sink.
the process involves a two step process collecting paths that link a null value and a pointer dereference statement and then verifying the satisfiability of the path conditions for those paths.
to scale the analysis to large scale software systems with millions of lines of code existing approaches employ a bottom up strategy to gather feasible sourcesink paths.
specifically when analyzing a function these approaches compute the intra procedural value flow paths and the corresponding path conditions as function summaries.
the value flow paths and conditions are referred to as summarypaths and summary conditions respectively.
to ensure that only feasible summaries are collected a constraint solver is invoked to verify the summary condition once the summary path is collected despite being a computationally costly process.
to avoid redundant path searching and analysis of callee functions existing approaches clone the summaries of callees and reuse them continuously to supplement the more extended summaries collected within caller functions.
the summary cloning and summary condition verification process continues until the highest function in the call graph known as the root is reached.
at this point the algorithm can directly identify source sink paths by examining summary paths originating from sources and terminating at sinks.
since each summary path carries its corresponding path conditions we can use the terms summary and summary path interchangeably without losing generality.
we use the buggy program shown in fig.
a to illustrate the existing bottom up compositional value flow analysis.
we use the symbol to represent a value flow path while and represent path conditions.
moreover the variable videnotes that variable vis either used or defined at line i. specifically one of the function summaries for foo represented as 4in fig.
c summarizes the propagation path of variable a2.
the variable a2receives the return value from the qux function in line and is subsequently passed to the bar function in line .
on one hand the summary path 4is generated by combining the summaries 1and 3 which are collected during the analysis of the quxandbarfunctions respectively before analyzing the foofunction.
on the other hand the summary condition 4is obtained by instantiating edges and the corresponding guards along the summary path 4 .
the guard 2of the edge p11 printf p13 is the constraint ofp11 null which is instantiated when collecing the summary 3by traversing from vertex 2on the program dependence graph shown in fig.
b .
once the summary condition 4is instantiated the summary is verified by the constraint solver z3 before it is stored.
the summary conditions 1 2 and 3are also verified when collected.
if a summary condition is unsatisfiable unsat it is discarded to avoid an unfeasible summary being maintained.
we provide such a case in appendix section a. moreover the summary 1of the quxfunction is cloned twice cloned one denoted as with different calling contexts line and line to account for the different propagation paths between thearxiv .04952v3 feb 2025 !
!
m null19 b m b b f b f f e f e e .voidfoo int c .int a qux .int b qux .int e null .bar a .e baz b .if e !
null .printf c .printf a npd happens!
.
.voidbar int p .if p !
null .printf p .
.int baz int f .returnf .
.int qux .int m null .returnm .
a codeexample b programdependencegraph pdg c functionsummariesforfooanditscallees.null19 m!
p !printf p f f !
!
c c e null !
!pathconditions callees !
m null19 a m a a p a p p p null !
!
!
!
valueflowpaths foo c printf c. 0 a!
a null19 m!
p !printf p null191 m!
b b f f e e 1 !
a!
printf a2 null19 m!
!
m null19 a m a a !
data dep.control dep.a b p f f m m a null19 e printf c c null truee printf p null trueb printf a !fig.
bottom up analysis for the code shown in a .
the b shows the corresponding program dependence graph pdg .
c shows the partial function summaries collected during the bottom up analysis.
redundant summaries are highlighted in red.
summaries 4and 6 which summarizes the propagation path of variable b3 .
this cloning mechanism eliminates the necessity of searching for and analyzing the qux function again leading to improved efficiency.
the explosive summary problem.
however the bottomup approach still faces challenges in terms of analysis time and memory consumption.
according to a report a single analysis for a project with millions of lines of code can take several hours and require hundreds of gigabytes gb of memory.
the main reason for this is the exponential growth in the size of summaries due to cloning for different calling contexts.
even worse exploded summaries lead to frequent calls to the constraint solver as each summary collection necessitates a call to the solver.
for example in the previous example the summary 1is cloned and stored as two copies 1and within the function foo.
this leads to the collection of three new summaries 4 5 and 6 which eventually result in three calls to the constraint solver.
when analyzing higher level callers the need for additional clones can cause significant performance issues.
existing techniques to improve the performance have focused on achieving efficient summary path collection and the verification of summary conditions .
specifically shi and tang proposed a parallel algorithm to accelerate summary path collection reducing the analysis time.
shi s recent work introduced a unified representation of summary paths and summary conditions on the program dependence graph enabling the direct verification of summary conditions on the pdg and eliminating the need for additional computation and storage of summary conditions.
our approach.
to tackle this problem we propose the first approach that identifies and eliminates useless summaries while also reducing the size of collected summaries from callee functions.
our key observation is that certain summariesin the callee functions do not contribute to any source sink path even when their summary condition is satisfiable sat and thus can be safely ignored without compromising the analysis s precision.
for example in fig.
c the summary 6 obtained from the function foodoes not lead to any bugs since there are no dereference operations on the inlined null from the callee function qux.
as a result it is unnecessary to compute the summary 6and solve its path condition 6. additionally we can further reduce unnecessary computations by avoiding the cloning of 1 not collecting 2 and solving the summary condition to eliminate the redundant 6. our experiments as shown in table i under the redun column indicate that approximately of redundant summaries are computed solved and maintained throughout the analysis process on average.
the benefit of our approach is twofold.
first our approach efficiently reduces time and memory usage by eliminating unnecessary computations of summaries which can become exponentially large as the analysis progresses.
second the high cost invocation of a constraint solver to verify useless summaries is subsequently avoided.
these two unique advantages make our approach more practical for efficiently analyzing large scale software systems.
our approach is orthogonal and can be used in conjunction with other approaches such as enhancing the summary representation by employing advanced data structures i.e.
graph structures for representing and resolving summary conditions and effectively collecting summaries in a parallel or pipelined manner .
challenges and solutions.
the challenge lies in identifying redundant summaries precisely and efficiently without hurting the precision of the analysis.
specifically determining the contribution of a summary often relies on information from upper layer functions that have not been analyzed yet.
our key insight is that a useful summary should be a compo nent of paths or path conditions associated with a source sink path of interest.
specifically the summary should be reachable from at least one pair of sources and sinks or derived from the path conditions of the source sink paths.
in fig.
the usability of summary 2is decided by evaluating its reachability with the source sink pairs null printf a9 and null printf p13 .
that is we assess the reachability of the source null 19and the sink printf a9 or printf p13 using the head f15and tail f16of 2 which are parameter and return of function baz.
they are represented as null f15 f16 printf a9 and f16 printf p13 .
without considering how 2will be used in caller foo we can still decide that 2is not reachable from the two mentioned source sink pairs.
consequently 2is deemed redundant in the long run and can be promptly discarded.
using this insight we have devised a principled sound and efficient contribution identification algorithm powered by a novel concept namely contribution abstraction to identify the contributing summaries.
we give more details in section iii.
results.
we have implemented the contribution identification ci algorithm based on the state of the art value flow analysis fusion and evaluated it on real world programs.
the evaluation results show our ci algorithm can significantly reduce the time and memory overhead of the fusion by and respectively.
furthermore the ci algorithm can efficiently identify almost of redundant summaries while only incurring a minimal additional overhead.
in the largest project the mysqld case ci helps fusion save seconds .
hours with only .
seconds of overhead resulting in a ratio of time savings to paid overhead performance gain of .
.
overall ci achieves a substantial average performance gain of .
.
to sum up this paper makes three main contributions we identify and address the redundant summary deficiency in the prior value flow analysis.
we design the contribution identification algorithm to identify redundant summaries efficiently and effectively.
on average the contribution identification algorithm can substantially enhance the performance of value flow analysis reducing time consumption by and minimizing memory utilization by .
ii.
b ackground and preliminary this section introduces the background of path sensitive value flow analysis and basic notations throughout the paper.
a. background we assume that the target program is in the static single assignment ssa form where each variable has only one definition and multiple definitions are merged using a assignment following many existing works .
all elements within an array or a union structure are considered to be aliases.
in our implementation we have utilized the existing methods to resolve points to relations .
program dependence graph pdg .
given the program p pdg is constructed to characterize how a value flows from one program statement to another through edges labeled withpath constraints.
we follow the previous works to construct the program dependence graph where the definition the use of all variables and operators are modeled as vertices.
definition .
a program dependence graph for a function is a directed graph denoted as g v o e d ec vis a set of vertices each of which is denoted by v si meaning the variable vis defined or used at a statement si.
we write v siasvifor short as the program is in the ssa form.
the guard vertices are denoted as vg v. ois a set of operator vertices binary or unary each of which represents a symbolic expression.
ed v o v o is a set of directed edges.
vi vj edmeans that the value viflows to value vj.
edges are labeled with guards from vg true which represent the constraints that qualify the value flow.
ec v vbis a set of control dependence edges.
example .
in fig.
b the two value flows from c1to printf c8 and from p11toprintf p13 are qualified by the branch expressions at line and line .
therefore the two edges c1 print c8 and p11 printf p13 are labeled by guards 1and 2. the expression of these branches can be derived by searching the pdg from guard vertices 1and 2 which are e7 null 7andp11 null respectively.
to check a given value flow path the path condition incorporates not only the value flows represented by the edges but also the value flows related to the instantiation of the guard vertices labeled on those edges.
note that these two categories of value flows are not identical.
the value flows related to the instantiation of guard vertices can be interconnected with the value flows of other paths.
thus the path condition often relates more paths beyond just .
example .
recall fig.
c the summary 7 c1 1 printf c8 summaries the value flow from c1toc8with the guard 1. the value flow represented by the edge is encoded as c8 c1 1. when instantiating the constraint represented by the guard 1 which states that e7 null the value flow of e7is tracked.
this results in the identification of the summary path of 6 represented as null m e6 e7.
consequently the path condition of 6is applied in this context.
taking all of this into consideration the path condition of 7can be expressed as c8 c1 e7 null 6. summary condition 7 involves more complex value flow than summary path 7due to instantiating the constraint represented by the guard 1. given a value flow path on the program dependence graph g represents i th vertex vi sion the path.
specifically we use to denote the tail element of .
given sets v1 andv2 which are subsets of the vertices vin the pdg we use v1 v2 to represent the set of value flow paths from a vertex in v1to another vertex in v2.
the path conditions of a set of value flow paths v1 v2 are represented as v1 v2 vg the additional vgdenotesalgorithm path sensitive value flow analysis 1procedure pathsensitveanalysis p build call graph cg and pdg of p s vsrc vsink foreach f cg do sf vfp vfr sf vfp vsink sf vsrc vfr foreach f cg in bottom up order do foreach c callees of fdo collectclonesolvesmry sf vfp vfr c collectclonesolvesmry sf vfp vsink c collectclonesolvesmry sf vsrc vfr c collectsrcsinkpath s vsrc vsink c s vsrc vsink report as a bug if issat the set of guard vertices that necessitate instantiation during the construction of the path conditions.
bottom up value flow analysis.
given the pdg and bugspecific sources vsrcand sinks vsink the path sensitive value flow analysis is to collect vsrc vsink and vsrc vsink vg .
to determine the presence of bugs each path in vsrc vsink is evaluated by checking its path condition using a constraint solver.
if the path condition is determined to be sat the path is reported as a detected bug.
to scale up the collection of vsrc vsink and vsrc vsink vg the existing path sensitive approaches use a compositional manner that analyses each function on a call graph from the bottom.
note that existing bottom up analyses first compute the strongly connected components scc of the call graph to make it acyclic.
then the path sensitive methods compute symbolic summaries for each function.
these summaries are subsequently instantiated in the callers different contexts allowing them to be reused to merge various source sink paths and their corresponding path conditions thereby eliminating the redundant re analysis of each function.
however the alternative top down approaches analyze functions in a call graph from top to bottom producing summaries for specific program contexts that cannot be reused for all source sink paths.
thus they require analyzing the same function multiple times for different calling contexts sacrificing path sensitivity.
as a result these approaches can only determine the reachability of a source sink pair without providing the connecting paths and path conditions.
to construct complete source sink paths bottom up approaches gather three types of summaries.
definition function summary .a summary for the functionfis represented by a tuple s where summary path captures a value flow path after the callee functions summaries are cloned.
the summary condition encodes value flows of and value flows instantiated from guard vertices that are labeled on .
transfer summary s vfp vfr summarizes value flow paths from the function s formal parameters vfpto the function s formal return vfr.
input summary s vfp vsink summarizes value flow paths from the function s formal parameters to a sink within the function or its callee functions.
output summary s vsrc vfr summarizes value flow paths from sources to the function s formal return.
the sources are found within the function or callee functions.
existing work shows that collecting these different categories of value flow paths is sound for bug detection.
corresponding to vfpandvfrthat represent the sets of formal parameters and formal return vapandvarrepresent the sets of actual parameters and actual return.
we denote total summaries that are collected from function fassf vh vt f f .
vhandvtare the head vertices and tail vertices of the summary path that could be collected in algorithm .
specifically vhare the head vertices come from vfp varandvsrc and vt are the tail vertices come from vap vfr vsink and vg.
algorithm presents the existing bottom up summary collection of s vsrc vsink for the given program p. in general it is accomplished by two helper functions collectclonesolvesmry and collectsrcsinkpath .
the first function collectclonesolvesmry is responsible for collecting summaries by cloning the callee s summaries and then solving the summary condition filtering out the unsat ones.
the second function collectsrcsinkpath collects the source sink paths that can be discovered after collecting the summaries in the current function.
the overall algorithm begins by constructing the cg and pdg for the program p. it then initializes a global set s vsrc vsink to maintain all the source sink paths as well as three summary sets for each function to maintain the three types of summaries.
the algorithm proceeds to process each function in a bottom up fashion collecting three types of function summaries in lines and and source sink paths in line assisted by the two helper functions.
finally the algorithm reports bugs in line by solving the path condition after all functions have been analyzed.
thecollectclonesolvesmry helper collects summaries directly from the current function if the value flow path does not pass through a function call.
otherwise it collects summaries by concatenating the inlined summaries from the called function c. for example in fig.
the summaries 1 2 and 3are collected directly from their respective functions while others are collected by concatenating callee summaries.
a single summary is collected in two steps collecting the summary path and instantiating the summary condition .
instantiating the summary condition often requires additional summary paths.
as demonstrated in example instantiating a summary condition often involves additional value flow starting from the guard vertex labeled on the summary path.
once a condition is instantiated it is solved by a constraint solver.
if a summary s condition is unsat the summary is discarded because an infeasible summary implies that the resulting source sink path is also infeasible.
the helper function puts the feasible summaries into three types of summary sets which would be used in the caller functions in the incoming analysis.
at that time the summaries are inlined which helps the caller form long summaries and possible source sink paths.
example .
recall fig.
c .
functions qux baz and bar are called by the function foo.
thus qux baz and barare analyzed first while foois analyzed later.
in function qux only the output summary s1is generated between the source vsrc null and the formal return vfr m20 and then 1is verified.
thus qux hassqux vsrc vfr s1 1 1 with the other three sets being empty.
in function baz only the transfer summary s2is collected between the formal parameter vfp f15 and the formal return vfr f16 with the condition verified.
thus baz hassbaz vfp vfr s2 2 2 with the other three sets being empty.
in function bar the input summary s3is collected between the formal parameter vfp p11 and the sinkvsink printf a9 with condition verified.
thus bar owns sbar vfp vsink s3 3 3 with the other three sets being empty.
since there is a conditional edge in 3 its summary condition 3involves the instantiation of the constraint represented by the guard 2 which is p11 null .
this involves the value flow path of p11 which coincides with its summary path.
example .
when analyzing the top layer function foo the summaries are cloned from the bottom layer functions accordingly.
when collecting the transfer summaries starting from formal parameter vfp c1 which reaches a sink printf c8 but cannot reach any actual input in vap a5 b6 no transfer summaries are gathered as a result.
when collecting the input summaries the summary s7is generated with a summary path collected from the formal parameter vfp c1 to the sink vsink printf c8 without cloning callee summaries.
however the summary condition 7necessitates instantiating the guard vertex 1 where vg 1 .
to this end the value flow starting from 1 is tracked.
when reaching the actual output e6of the function call to barin line the summary s2is cloned from the callee bar.
moving forward when reaching the actual output b3of the function call to quxin line the summary s1is cloned thus forming the summary s6.
finanly 7is verified.
when collecting the output summaries because the vsrc in the current function is empty the output summaries of the callee function are cloned introducing additional sources.
thus in line the summary s1is inlined again which is the output summary of the function qux.
by combining the summary s1 the value path from the output a2toa5is traced and involves the call to the function barin line .
since a5 is passed to bar the input summary or transfer summary that starts at the corresponding formal parameter is inlined.
in our case the input summary s3of the function baris inlined.
after concatenating with the input summary the path reaches a sink forming a complete source sink path but does not reach any formal return.
thus no output summary is collected.
thecollectsrcsinkpath helper is similar to thecollectclonesolvesmry but tries to collect the sourcesink paths in each iteration and does not solve the path conditions.
in the example of fig.
the helper collects no source sink paths from bottom layer functions as no such paths are formed but it collects two source sink paths s4and s5 from the upper layer function foo.
eventually 4and 5 are solved when reporting bugs in line of algorithm .
iii.
o verview in this section we illustrate the problem using the motivating example and briefly describe our key idea.
a. explosive summary problem to detect the bug the bottom up collection of function summaries outlined in algorithm can collect and maintain a superset of the function summaries that are actually required.
as highlighted in red in fig.
c the summaries s2 s6 and s7do not contribute to the two source sink paths s4and s5 for detecting the npd bug i.e.
either as components of these paths or their associated path conditions.
specifically non contributing summaries can arise in two scenarios in algorithm .
first when collecting three types of summaries over summarization can occur.
for instance when analyzing the function baz there is no prior knowledge of which the specific summary contributes resulting in the conservative collection of all summaries within it.
consequently the noncontributing summary s2is collected as a transfer summary.
second non contributing summaries can be induced through the cloning of callee summaries.
for example the summary s6is a non contributing summary generated by cloning and concatenating with the callee summary s2.
additionally given that there are no source sink paths within the function boothat rely on s2 and considering that s6is deemed non contributory the cloning of s2from function bazshould be avoided during the analysis of foo.
as summaries are maintained and cloned into higher level functions the size of sfcan exponentially increase due to the explosion of paths.
more importantly collecting non contributing summaries introduces expensive constraint solving.
to sum up collecting and cloning only the contributing summaries can significantly improve scalability.
the challenge lies in identifying redundant summaries precisely and efficiently without hurting the precision of the analysis.
b. removing redundant summaries we first propose the key idea of assessing whether a summary is contributing or not by solving two graph reachability problems between heads and tails of the summary swith distinct reaching targets source sink pairs or guards without computing any summaries.
based on the graph reachability abstraction we design the contribution identification algorithm which identifies a set of necessary head and tail vertices for identifying the contributing summaries.
summaries that are collected outside these necessary head and tail vertices are identified as non contributing automatically.
next we explainhow our graph reachability abstraction and algorithmic design overcome the above challenges.
contributing summmary.
our key observation is that whether a summary is contributing hinges on two aspects its path contribution where it must be a component of source sink paths and its condition contribution where it must be involved in the path conditions associated with a source sink path.
thus we establish the definition of a contributing summary generated from a function based on its contribution to the source sink paths s vsrc vsink .
definition contributing summary .a summary s sf is considered a contributing summary for function fif it satisfies at least one of the following criteria path contribution the summary path is used to connect at least one source sink path i.e.
vsrc vsink .
condition contribution the summary path is used to instantiate at least one guard vertex labeled along the source sink paths i.e.
vsrc vsink vg .
we use fig.
as an example.
the path 1is reachable from both source sink pairs null printf p13 and null printf a9 .
in addition the path 3is reachable from the source sink pair null printf p13 .
therefore they are identified as contributing summaries indeed they are components of two source sink paths 4and 5. comparatively the paths 2 6 and 7are neither reachable by any pair of sources and sinks nor reachable by the guard vertex 2labeled on the source sink path 4. thus these paths 2 6 and 7are identified as non contributing summaries.
additionally despite the reachability of the summary 6from the guard vertex 1labeled on 7 more specifically the tail of 6 denoted as e7 being reachable from 1 the summary 7does not contribute to any source sink path or conditions.
consequently it becomes redundant for npd detection.
in summary the summary contribution is identified by assessing two reachabilities between specific heads and tails of the summary path with various targets path contribution if the summary s has the path contribution a source sink pair src sink vsrc vsink exists where srccan reach both and andsink is reached by both and .
condition contribution if the summary s has the condition contribution criteria there exists a guard vertex g vgfrom vsrc vsink vg that are reached by and .
with the above abstraction the assessment of contributing summaries is reduced to two graph reachability problems.
in section iv we give a sound efficient and effective contribution identification algorithm by applying the abstraction.
iv.
c ontribution identification in this section we first present three technical designs of our contribution identification algorithm.
we then give the details of the identification algorithm that identifies the necessary vertices for path and condition contribution.
finally we establish the soundness of our approach analyze thecomplexity of algorithms and discuss the advanced graph reachability with consideration of the calling context.
preserving the precision of the analysis.
to ensure this instead of directly utilizing the abstractions to identify noncontributing summaries the identification algorithm uses the abstractions to soundly identify all necessary head vertices vhand tail vertices vtthat are reached by source sink pairs path contribution as well as guard vertices vgthat are labeled on source sink paths condition contribution .
this means that contributing summaries can only be collected within necessary vertices which we denote as vn.
therefore summaries contributing to source sink paths can be collected within vn as in the traditional methods.
in contrast summaries collected outside vnare considered as the non contributing summaries.
the soundness proof is given in section iv c. efficient and effective identification.
the identification process relies on graph reachability.
more precise graph reachability results in fewer necessary vertices vnbeing identified allowing for recognizing more non contributing summaries starting outside of vn.
however using advanced reachability algorithms increases the identification overhead.
the complexity of more advanced reachability algorithms often outweighs the precision gains they can provide.
to strike a balance i.e.
spending minimal overhead while significantly boosting the efficiency of path sensitive analysis we select the classic breadth first search bfs algorithm for implementing our abstractions.
more discussion about this is in section iv d. resolving implicit contribution.
the source of the implicit contribution comes from the condition contribution of a summary.
with the abstractions resolving the implicit contribution is transferred to gather the necessary guard vertices that are labeled on source sink paths.
the key is that the necessary guard vertices could be obtained from edge sets that are reachable from the necessary heads and tails for path contribution.
the contribution identification algorithm is outlined in algorithm .
at a high level it identifies necessary vertices vnin two parts for path and condition contribution respectively through three stages.
first it identifies the first part of necessary vertices vnfor path contribution using the procedure identifypathcontrib in algorithm .
next using these necessary heads and tails for path contribution we collect the necessary guard vertices with the procedure collectnecguards in algorithm .
lastly based on the necessary guard vertices and heads and tails that are not identified for path contribution we further identify the second part of necessary vertices for condition contribution using the procedure identifycondcontrib in algorithm .
a. path contribution identification procedure identifypathcontrib in algorithm utilizesbfs to explore the graph separately from both the source and sink vertices.
since a vertex vonly needs to be reachable by at least one source sink pair the bfs initiated from the source sink vertices maintain a shared visiting set called srcvisited sinkvisited .
this ensures that each vertex is visited only once during the bfs from the sourcesalgorithm contribution identification 1procedure identifycontrib g vn vcand identifypathcontrib g vn vcand identifycondcontrib g vn vcand return vn 6procedure identifypathcontrib g vn vcand srcvisited sinkvisited foreach v vsrcdo bfs srcvisited v g forward foreach v vsink do bfs sinkvisited v g backward vn srcvisited sinkvisited vt vh vg vcand srcvisited sinkvisited vn sinks .
after completing all bfs the necessary vertices for path contribution can be obtained by computing the intersection between the vertices visited both by srcvisited and sinkvisited andvt vh vgin line .
as the guard vertices could not have the path contribution the necessary vertices only come from vt vh vg.
vertices that are visited by sources and sinks but not identified as necessary vertices for path contribution are called candidates denoted asvcand.
these vertices may have condition contribution which are computed on line and passed to the procedure identifycondcontrib on line .
b. condition contribution identification the necessary guard vertices are labeled on the edges of the source sink paths.
thus necessary guard vertices can be collected using the necessary vertices for path contribution.
the necessary guards are collected and maintained in vnec g through procedure gathernecguards using the bfsedge traversal to gather the visited edges.
two shared edge sets fwdedges andbwdedges are utilized to keep track of the visited edges for forward and backward bfsedge starting from the vertices in vn respectively.
these two sets ensure that each edge is visited only once during the forward and backward bfsedge .
for each edge u v encountered infwdedges if the reverse edge v u is also found in bwdedges the label ld u v is added to vnec g. after collecting the necessary guard vertices the algorithm then proceeds to collect another part of the necessary vertices for condition contribution.
if a vertex has already been identified for path contribution separately identifying its condition contribution is unnecessary.
thus the procedure identifycondcontrib explores the vertices from the candidates in the forward direction and from each necessary guard vertex in the backward direction.
during the bfs iterations the shared sets fwdvisited andbwdvisited are utilized to keep track of the visited vertices in each direction respectively.
by examining the head and tail vertices present in both fwdvisited andbwdvisited sets another part of the necessary vertices can be identified.algorithm condition contribution identification 1procedure identifycondcontrib g vn vcand vnec g fwdvisited bwdvisited gathernecguards vn vnec g foreach v vcanddo bfs fwdvisited v g forward foreach v vnec gdo bfs bwdvisited v g backward vn vn fwdvisited bwdvisited vt vh 9procedure gathernecguards vn vnec g fwdedges bwdedges foreach v vndo bfsedge fwdedges v g forward foreach v vndo bfsedge bwdedges v g backward foreach u v bwdedges fwdedges do vnec g vnec g ld u v example .
procedure identifypathcontrib s output is null m20 a2 a5 printf a9 p11 printf p13 and the necessary guard vertice is 2 .
the vertices that have condition contribution are p11 a2 a5 m20 null 2 and some of them are included in the path contribution.
thus the output of the procedure identifycondcontrib is 2 .
also the set vnto assess the contributing summary is null m20 printf a9 p11 printf p13 a2 a5 2 .
c. soundness we propose the following theorem to establish the soundness of abstracting contributions in identifying noncontributing summaries for function fbased on vn.
theorem soundness .given the set vnidentified for any function f p if a summary s is collected and neither nor appears in vn it must be a noncontributing summary for function f. canceling the corresponding operations does not affect s vsrc vsink .
see the proof in appendix section b. example .
in fig.
collecting summary path 6and verifying its condition 6are prevented because it is determined that cloning 1to concatenate with b3 b6would result in a non contributing summary.
it is because b3is not included invn.
similarly the collection and verification of summaries s2ands7are removed because the head vertices f15andc1 of these summaries are not present in vn.
d. summary and discussion based on the identification of vn as outlined in theorem algorithm can be improved and revised as algorithm .
during the process of collecting the three types of summaries the algorithm incorporates a filtering step for the head tail and guard vertices using vn.
the filtering step guarantees that summaries located outside of vnare not collected or cloned effectively eliminating non contributing summaries.algorithm new path sensitive value flow analysis 1procedure newpathsensitveanalysis p build call graph cg and pdg of p vn identifycontrib pdg the initialize part is the same as the algorithm foreach f cg in bottom up order do pruning the redundancies.
vfp vfp vn vap vap vn vfr vfr vn var var vn vg vg vn the summary collection part which is the same as the alogirhtm .
s vsrc vsink report as a bug if is sat verification of these summaries by a constraint solver is thus avoided.
next we discuss the important points of the algorithm including its complexity precision and efficiency.
complexity.
the procedure identifypathcontrib involves searching the pdg gat most twice as do each of the other procedures since each edge is visited only once either in the forward or backward traversal direction.
as a result the overall complexity is linear with respect to the size of pdg.
precision and efficiency.
the soundness of vnensures the correct collection of contributing summaries.
however there may still be vertices within vnthat lead to noncontributing summaries.
the precision of vncan be increased by minimizing the number of such vertices thereby identifying more non contributing summaries.
the reason for the incorrect collection of some vertices in vnis that algorithm utilizes a traditional reachability algorithm specifically the bfs to address the reachability problems without differentiating the calling context under which the summary could be used.
however certain non contributing summaries can only be identified under specific contexts i.e.
via context free language cfl reachability .
consequently non contributing summaries that are reachable under traditional reachability algorithms but not under context sensitive reachability algorithms could be further identified.
the precision of vn therefore depends on the approach used to solve reachability.
the cfl reachability algorithm takes calling context into consideration by respectively labeling function calls and returns with matched parentheses kat line k. thus a vertex iis context sensitively reachable from a vertex jif the label string of the path does not contain any mismatched parentheses.
example .
in fig.
b the following edges are labeled with parentheses to fulfill the requirements of the cfl reachability algorithm m20 a2 m20 b3 a5 p11 b6 f15 andf16 e6.
by replacing bfs with a cfl reachability algorithm in algorithm we would produce vn null m20 printf a9 p11 printf p13 a2 a5 2 which is the same as when using bfs.
in this case using the cfl reachability algorithm does not improve the precision.
in practice the precision of vnthat can be improved by cfl reachability is limited.
in our evaluation approximately of non contributing summaries were successfullytable i sall is total size of collected summaries.
redun is the number of redundant summaries that occur with the percentage relative to sall shown in parentheses.
identified is the number of identified summaries by ci with the percentage relative to redun shown in parentheses.
src and sink represent the number of sources and sinks.
id program kloc sall redun identified src sink leela .2k .4k .3k .2k nab .6k .2k .7k .6k x264 .2k 24k 19k .7k wrf .1k .1k .4k .3k omnetpp .6k .1k .1k .5k povray .5k .8k .5k .5k cactus .1m .7k .5k .8k imagick .4k .3k .5k .2k perlbmk .4m .8k .7k .9k cam4 .7k .1k .2k .4k parest .6m .3k .9k .7k xalanbmk .4m .4k .9k .7k gcc .5m .3k .4k .2k blender .2m .7k .6k .6k libicu .1m .4k .8k .7k ffmpeg .1m .6k .7k .3k mysqld .8m .6k .2k .4k avg .3m .7k 186k identified using bfs.
however in terms of efficiency cfl reachability often encounters a cubic complexity barrier .
as demonstrated by our experiment in fig.
using a cfl based algorithm to collect vnsignificantly decreases overall performance.
thus we use bfs.
v. e valuation we have implemented the contribution identification ci algorithm in algorithm to identify the path and condition contribution in the state of the art value flow analysis tool fusion for detecting npd in c c code.
we denote fusion with ci enabled as light fusion which serves as the performance boosted client powered by our technique.
we investigate the following three questions rq1 how effective and efficient is ci in identifying the summary contribution?
rq2 how much can ci boost the performance of existing value flow analysis?
rq3 can ci enhance the path sensitive analyzer s performance to be comparable with the top down approach?
a. experimental setup baselines.
fusion collects the summaries in a parallel way i.e.
parallelizing functions located within the same level of the call graph and uses the graph representation of summary conditions .
first we compare light fusion with fusion.
we did not compare to as their methodologies involve generating redundant summaries to enable parallelism which contradicts the principles and objectives of our approach.
in addition we have developed a variant of lightfusion denoted as cfl light fusion that uses a more precise identification algorithm achieved through cfl reachability.
specifically we adopted the open source implementation of the state of the art cfl reachability algorithm provided by and replaced the bfs used in algorithm .
lastly we compare the light fusion to phasar an open sourcedtable ii the running time and memory usage of fusion f light fusion l f and building of pdg are presented along with ci s running time and performance gains gains .
memory gb time s id f l f pdg f l f pdg ci gains .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
avg .
.
.
.
.
.
.
.
implementation of top down approaches .
to mitigate the impact of the execution environment we ran experiments three times and calculated the average performance and performance gains.
subjects.
we have included all the large programs from the spec cpu benchmark that consist of more than kloc.
additionally we have selected three large programs namely libicu ffmpeg and mysqld which are widely used software systems in their respective domains.
sources and sinks.
for checking npd null pointers are selected as sources.
the dereference operations are selected as sinks.
table i lists the evaluation subjects with statistics of sources and sinks.
environment.
all experiments were run on a server with eighty intel xeon cpu e5 v4 .20ghz processors and gb of memory running ubuntu .
.
each program is analyzed with a limit of hours and gb of memory.
fifteen threads are used to analyze the functions in the same layer when running both fusion and light fusion.
the solver used to verify constraints is z3 .
b. rq1 effectiveness and efficiency to study the effectiveness of ci we run two experiments for each benchmark.
in the first experiment we execute fusion to produce the results s vsrc vsink and collect all potential summaries that could be generated during analysis denoted as sall.
note that sallcontains the non contributing summaries which is a superset of s vsrc vsink .
the summary size of each benchmark is recorded in the sall column of table i. second we count non contributing summaries from sallbased on the definition of contributing summaries definition .
the relative number of non contributing summaries is reported in the redun column of table i. in the second experiment we run light fusion using the same configuration as fusion to produce s vsrc vsink .
lightfusion however incorporates an additional identification algorithm ci to filter out non contributing summaries before the summary collection and cloning.
we count the number of identified non contributing summaries and then compare it with the total number of non contributing summaries inthe first experiment to determine the identification ratio.
the findings are listed in the identified column of table i. throughout both experiments the pdg of each benchmark is pre built once and persisted to disk.
both fusion and light fusion read the same pdg as input when analyzing a benchmark.
we monitor the execution time the memory consumption and the analysis results s vsrc vsink .
the performance data for the two runnings and the building of pdg are listed in table ii.
in the second set we specifically record the time consumed by ci as the memory usage generally stays low below mb in benchmarks with the exceptions of blender at mb and mysqld at mb.
the running time of ci is listed in the ci column of table ii.
soundness.
we compare the analysis results s vsrc vsink across both sets and the unsafe sinks reported by fusion and light fusion in section v d. they remain the same demonstrating the preservation of the precision of our approach.
effectiveness.
while using normal graph reachability bfs to collect necessary vertices vn ci soundly approximates the summary contribution without considering context sensitivity.
thus some redundant summaries could be incorrectly classified as contributing ones.
column identified in table i lists the number of redundant summaries that can be identified and the percentage relative to redundant summaries that occur for each benchmark.
we observe that ci can precisely identify redundant summaries reaching the high ratio from in ffmpeg to in perlbench .
on average ci correctly identifies of redundant summaries.
one could reject the bogus vnby reaching context sensitivity.
however handling context sensitivity may be more costly.
we examine this aspect in section v c. the high rate of identification achieved by ci in most projects shows that there is limited room for improvement with a context sensitive identification algorithm.
efficiency.
table ii presents the running performance of fusion light fusion ci and the performance gains when applying ci.
light fusion using our ci to prune redundant summaries includes ci s running time in its performance metrics.
for all benchmarks ci s running time for collecting vn remains below a minute.
specifically using ci significantly improves the running time and memory of light fusion as evidenced by the data in the time and memory columns of the table.
without computing and maintaining the redundant summaries captured by ci the average running time of fusion is reduced from .
seconds to .
seconds saving over minutes or .
seconds .
also the average memory usage for fusion drops from .
gb to .
gb.
breakdown.
to investigate how much resource is spent collecting redundant summaries and how much resource is spent on calling the constraint solver to verify the conditions of redundant summaries we break down the reduced performance in table ii.
this is obtained by computing the difference in running time and memory between fusion and light fusion as shown in table ii.
additionally we present the number of solver calls avoided in table iii.
once the summary path is collected the constraint solver is called thus the avoided calls of the constraint solver equal the number oftable iii solver is the number of saved solver calls which is equal to the number of identified redundant summaries identified column in table i .
the total t reduction in performance performance of calling the solver s with the percentage of each with respect to the total reduction in performance shown in parentheses.
id solvertime s memory gb t s t s .3k .
.
.7k .
.
.0k .
.
.4k .
.
.2k .
.
.5k .
.5k .
.
.7k .
.
.2k .
.
.9k .
.
.9k .
.
.4k .
.6k .
.
.8k .
.7k .
.
.2k .
.
avg .7k .
.
redundant summaries identified as shown in the data in the columns identified in table i and solver in table iii.
for the total reduced running time almost is spent on verifying the conditions of redundant summaries across the benchmarks.
as the size of the program grows the complexity of the summary conditions tends to increase as well.
this results in longer summary paths and more time required to solve these conditions.
therefore the proportion of time spent on the solver increases from to .
on the other hand for the total reduced memory almost is consumed by storing the collected summaries.
performance gains.
it is noted that the running time of ci does not hurt the performance of light fusion.
the gains column in the table illustrates the performance gains achieved by using ci which is the ratio of the time saved by lightfusion to the overhead incurred by ci.
in the povray id case ci achieves the highest performance gain of .
by reducing seconds with only .
seconds of overhead.
in the mysqld id case ci reduces the most time saving seconds .
hours which is nearly half of the original fusion running time with only .
seconds of overhead.
on average ci achieves a performance gain of .
.
c. rq2 performance boosting fusion vs. light fusion.
the performance comparison between fusion and light fusion is listed in table ii.
the percentage numbers in parentheses represent the extra performance requirements of fusion against light fusion.
on average both the time and memory could be reduced by and by by using ci.
the time reduction is more significant than the memory reduction since analyzers allocate considerable cpu resources to summary collection and solving path conditions which can be np hard .
thus pruning redundant summaries can save significant time by conserving cpu resources.
the memory reduction percentages are constrained by the number of redundant summaries in the 1234567891011121314151617fusioncfl light fusion light fusiontime seconds 6hoursfig.
light fusion vs. its variants benchmarks as indicated by the redun column in table i which shows an average redundancy ratio of closely corresponding to the average memory reduction percentages.
light fusion vs. cfl light fusion.
to explore the impact of enhancing the ci precision such as by using the cfl reachability to reach context sensitivity and identify more redundant summaries compared to bfs we replaced bfs in ci with the state of the art cfl reachability algorithm .
the modified algorithm was executed as the cfl lightfusion instance compared with fusion and light fusion.
we monitored the running time on all three instances.
the results presented in fig.
demonstrated that cfllight fusion did not yield performance improvements instead it significantly slowed down the process particularly as the program size increased.
notably cfl light fusion failed to analyze benchmarks beyond cam4 id within a six hour timeframe.
this decrease in performance can be attributed mainly to the cubic complexity of cfl based approaches which introduce substantial overhead that outweighs the precision benefits.
as a result trading efficiency for precision becomes impractical.
d. rq3 comparing to top down approaches to evaluate the performance improvements of the pathsensitive analyzer compared to top down approaches we conducted a comparative analysis between light fusion and phasar .
using the latest release ofphasar at the time of writing we configured it to analyze the same source sink pairs as light fusion to ensure a fair comparison.
performance.
the results shown in fig.
show the running time and memory usage of fusion light fusion and phasar which are represented by blue green and red bars respectively.
in general both fusion and light fusion require more resources compared to phasar as indicated by the taller blue and green bars compared to the red bars.
however the green bars representing light fusion are closer in height to the red bars phasar than the blue bars representing fusion .
in some benchmarks the green bars are even lower than the red bars.
for example the running time of light fusion for cactus id and xalanbmk id as well as the memory usage for x264 id are lower than those of phasar .
next we quantify the amount of running time and memory among fusion light fusion and phasar .
the results show1234567891011121314151617fusionlight fusionphasar 1234567891011121314151617time logscale memory logscale fig.
performance fusion vs. light fusion vs. phasar .
that fusion requires .
the time and .
the memory consumed by phasar on average.
however light fusion can reduce the requirements to just .
the time and .
the memory.
additionally light fusion has performance comparable with phasar on benchmarks such as leea id x264 id omnetpp id cactus id xalanbmk id and ffmpeg id requiring only an additional .
ofphasar s execution time.
however fusion could only complete x264 id within the same threshold.
analysis results.
we record the unsafe sinks reported by fusion light fusion and phasar for each benchmark.
a sink is considered unsafe if there is a feasible path from a source to the sink.
note that top down approaches such as phasar usually sacrifice path sensitivity for better scalability.
as a result they may misclassify safe sinks as unsafe ones.
first the results show that the unsafe sinks reported by light fusion are the same as those reported by fusion demonstrating our approach s precision preserving nature.
next we examine the unsafe sinks reported by light fusion and phasar .
light fusion identifies of the sinks which are reported as unsafe by phasar as actually being safe indicating a high false positive rate for phasar .
additionally nearly of unsafe sinks identified by lightfusion are also identified by phasar .
however phasar fails to report some unsafe sinks identified by light fusion due to not modeling the value flow of library functions after manual verification.
we provide the complete comparison data in appendix section c. in conclusion our method incorporates path sensitive analyses without compromising precision and still achieves good performance.
this aligns with common industrial requirements of maintaining both high performance and low false positive rates.vi.
r elated work compositional analysis.
many compositional analyses aim to improve efficiency by reusing information within a procedure as summaries which include top down and bottom up summaries.
most program analyses prefer a bottom up approach .
in these approaches a function s effect is represented using bottom up summaries and the summary of a callee is inlined into the summary of its caller.
this avoids redundant analysis of individual functions.
however when collecting the summary of a callee it is challenging to determine whether the summary will be useful to callers since the callers are typically analyzed afterward.
our work employs a lightweight analysis to pre compute a set of vertices which allows us to determine whether a summary should be computed and reduces unnecessary computations.
value flow analysis.
cherem et al.
utilized value flow analysis to detect software bugs such as memory leaks.
subsequently several works have aimed to refine the recall and precision of this analysis .
however most of these analyses are not inter procedurally path sensitive with the exceptions of pinpoint and fusion .
fusion is an optimization of the performance issues identified in pinpoint which were caused by the explosion of summaries and paths in inter procedural analysis.
fusion addresses this problem by eliminating the storage of path conditions.
however it is worth noting that even with fusion there are still redundant summaries and paths being computed in function summaries which cannot be fully optimized.
while this work helps fusion overcome redundancy issues related to function summaries.
vii.
c onclusion we present the contribution identification algorithm which addresses the redundant summary deficiency in the prior value flow analysis.
it identifies redundant summaries efficiently and effectively without compromising soundness or efficiency.
furthermore it results in an average decrease in the time and memory overhead of state of the art path sensitive value flow analysis by and respectively.
in the end it enables path sensitive analyses without compromising precision and still achieves good performance making it comparable to pathinsensitive analyses.
viii.
a cknowledgment we thank the anonymous reviewers for valuable feedback on earlier drafts of this paper which helped improve its presentation.
this work is funded by research donations from huawei tcl and tencent.
yuandao cai is the corresponding author.