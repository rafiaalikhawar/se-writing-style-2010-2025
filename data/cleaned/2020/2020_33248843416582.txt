automated third party library detection for android applications are we there yet?
xian zhan the hong kong polytechnic university hong kong china chichoxian gmail.comlingling fan college of cyber science nankai univerisity china nanyang technological university singapore ecnujanefan gmail.comtianming liu monash university australia tianming.liu monash.edu sen chen college of intelligence and computing tianjin university china nanyang technological university singapore ecnuchensen gmail.comli li monash university australia li.li monash.eduhaoyu wang beijing university of posts and telecommunications china haoyuwang bupt.edu.cn yifei xu southern university of science and technology china mail.sustech.edu.cnxiapu luo the hong kong polytechnic university hong kong china luoxiapu gmail.comyang liu nanyang technological university singapore yangliu ntu.edu.sg abstract third party libraries tpls have become a significant part of the android ecosystem.
developers can employ various tpls with different functionalities to facilitate their app development.
unfortunately the popularity of tpls also brings new challenges and even threats.
tpls may carry malicious or vulnerable code which can infect popular apps to pose threats to mobile users.
besides the code of third party libraries could constitute noises in some downstream tasks e.g.
malware and repackaged app detection .
thus researchers have developed various tools to identify tpls.
however no existing work has studied these tpl detection tools in detail different tools focus on different applications with performance differences but little is known about them.
to better understand existing tpl detection tools and dissect tpl detection techniques we conduct a comprehensive empirical study to fill the gap by evaluating and comparing all publicly available tpl detection tools based on four criteria effectiveness efficiency code obfuscation resilience capability and ease of use.
we reveal their advantages and disadvantages based on a systematic and thorough empirical study.
furthermore we also conduct a user study to evaluate the usability of each tool.
the results show the corresponding authors.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
ase september virtual event australia association for computing machinery.
acm isbn .
.
.
.
libscout outperforms others regarding effectiveness libradar takes less time than others and is also regarded as the most easy touse one and libpecker performs the best in defending against code obfuscation techniques.
we further summarize the lessons learned from different perspectives including users tool implementation and researchers.
besides we enhance these open sourced tools by fixing their limitations to improve their detection ability.
we also build an extensible framework that integrates all existing available tpl detection tools providing online service for the research community.
we make publicly available the evaluation dataset and enhanced tools.
we believe our work provides a clear picture of existing tpl detection techniques and also give a road map for future directions.
ccs concepts software and its engineering software notations and tools libraries and tools program analysis.
keywords third party library android library detection empirical study acm reference format xian zhan lingling fan tianming liu sen chen li li haoyu wang yifeixu xiapu luo and yang liu.
.
automated third party library detection for android applications are we there yet?.
in 35th ieee acm international conference on automated software engineering ase september virtual event australia.
acm new york ny usa 12pages.
introduction nowadays android applications apps occupy an irreplaceable dominance in the app markets and will continuously hit the new height .
along with the thriving of android apps is the 35th ieee acm international conference on automated software engineering ase ase september virtual event australia x. zhan l. fan t. liu s. chen l. li h. wang y. xu x. luo y. liu emerging of countless third party libraries tpls .
when app developers implement their own apps they usually realize some functionalities by integrating various tpls such as advertisements social networking analytics etc.
prior research has shown that about of apps contain third party ad libraries.
wang et al.
also revealed that more than of the code in an android app belongs to tpls.
tpls can facilitate the development process and provide powerful functionalities for apps.
however every coin has two sides.
this situation also brings new security threats.
some tpls may contain malicious code.
when they are integrated into popular apps they can quickly infect a large number of mobile devices.
besides tpls as noises could affect the results of repackaging detection malware detection counterfeit apps detection etc.
thus research on tpl detection targeting the android platform continues to emerge.
generally there are two ways to identify tpls.
the first one is the whitelist based approach and the second one directly extracts features from tpls to identify them.
in the beginning most repackaging detection and malware detection adopt whitelist to filter out tpls because whitelist based approach is simple and easy to implement.
however the whitelist based method uses the package name to identify tpls which is not resilient to package renaming.
a recent study showed that more than of the inspected android tpls are protected by obfuscation techniques which dramatically decreases the effectiveness of the whitelist based method.
besides the whitelists cannot cover all tpls especially newly emerged ones.
in order to improve the detection performance various research tried to extract different features of tpls and use different techniques to identify tpls.
however the advantages and disadvantages usage scenarios performance and capability of obfuscation resilience of these tools are still not clear.
besides no unified dataset is available to quantitatively evaluate them without bias.
undoubtedly identifying these problems can also help us find the limitations and explore new methods in this direction.
therefore in this paper we attempt to fill the gap by conducting a comprehensive and fair comparison of these state of the art tpl detection tools on a unified dataset.
we evaluate them by using four metrics effectiveness efficiency scalability code obfuscationresilience capability and ease of use.
by investigating the four aspects of these tools we attempt to achieve three goals in this study understand the capabilities and usage scenarios of existing tpl detection tools get a better understanding of the trade offs in tpl detection and then conclude a better optimized scheme to guide future work or help developers implement better tools integrate these publicly available tools as an online service which provides the detection results of different tpl detection tools to users.
in summary our main contributions are as follows we are the first to conduct a systematic and thorough comparison of existing tpl detection tools by using four metrics effectiveness efficiency code obfuscation resilience capability and ease of use.
we are the first one to construct a comprehensive benchmark including unique tpls used by android apps with versions that can be used to verify the effectiveness of tpl detection tools section .
.
we make this datasetavailable for community and future researchers can also use this dataset to evaluate new tools.
based on our analysis we point out the disadvantages of current research and present the potential challenges in this direction.
we give suggestions on tool selection under different application scenarios and provide useful insights for future research on tpl detection.
we build an extensible framework that integrates all existing tpl detection tools to provide an online service to users.
we also improve some publicly available tools for better performance.
all the related code and dataset and detailed evaluation results can be found on our website.
the rest of this paper is organized as follows.
section 2introduces the basic concept of the third party library and detection process.
section 3shows the related work.
section 4presents a comprehensive comparison about these state of the art tpl detection tools.
section 5describes how we design our empirical study.
section reports the evaluation and findings.
section 7is the discussion.
section 8concludes our work.
preliminary .
android third party library third party library tpl provides developers with various standalone functional modules which can be integrated into host apps in order to speed up the development process.
since current tpl detection tools that we compared in this paper only consider java libraries we do not discuss the native libraries here.
the java libraries are usually published as .jar or .aar files.
the .aar format file can only be used by android apps which usually provides uirelated libraries or game engine libraries.
.jar files consist of class bytecode files while .aar files include both class bytecode files and other android specific files such as manifest files and resource files.
most tpl files can be found downloaded imported from maven repository github and bitbucket .
in android app development if an app uses tpls the app code can be divided into two parts the logic module from the host app i.e.
primary and the supplementary module i.e.
non primary from tpls .
tpl detection aims to identify tpls in non primary modules.
.
tpl detection process as shown in figure existing tpl detection techniques for android apps usually unfold in four steps which are elaborated below.
step1 preprocessing.
researchers usually first decompile apps by applying reverse engineering tools such as apktool and androgurad and then get the appropriate intermediate representation ir in this stage to facilitate the following steps.
step library instance construction.
the purpose of this step is to find the boundaries of tpl candidates and then separate them from the host apps.
this step is optional because some tools can directly extract tpl features without splitting tpls from host apps.
basically there are two different strategies identifying the boundaries of tpl candidates consider all the independent java packages as library candidates collect tpls beforehand as the ground truth and then compare library candidates with the ground truth 920automated third party library detection for android applications are we there yet?
ase september virtual event australia figure typical process of tpl detection conduct module decoupling algorithms to get independent modules as candidate library instances.
step feature extraction.
this step is to extract the features of tpls which can uniquely represent different tpls.
existing tools usually extract features such as android apis control flow graph and variant method signatures to represent tpls.
step library instance identification.
depending on different library instance construction methods in the second step existing identification methods can be classified into two types clusteringbased method and similarity comparison method.
the clusteringbased method usually depends on sophisticated module decoupling techniques.
this method needs to filter out the primary module i.e.
code of the host app and then cluster non primary modules with similar features together.
the modules in one cluster are considered as a tpl.
the similarity comparison method considers all the modules in an app as tpl candidates thus it requires collecting tpl files first.
by comparing the similarity of the features between the collected tpls and the in app tpl candidates in app tpls can be identified.
.
code obfuscation strategies code obfuscation is often used to protect software against reverse engineering.
there are many obfuscators i.e.
obfuscation tools such as allatori dasho proguard helping developers obfuscate their apps and tpls.
some obfuscation techniques can hide the actual logic of the apps as well as the used libraries.
the commonly used obfuscation strategies are introduced as follows.
identifier renaming which renames identifiers into meaningless characters such as a and b including the class name the method name and the file name etc.
string encryption which usually adopts encryption algorithms to protect sensitive information such as telephone or email.
after encryption the sensitive strings defined in the source code are encrypted to meaningless strings.
package flattening which modifies the package hierarchy structure by moving the files from one folder to another.
different obfuscators can flatten the structure to varying degrees.
sometimesthe whole package structure can be removed and all the files are put into the root directory of apps.
dead code removal which deletes unused code and preserves the functionalities invoked by the host app.
control flow randomization which modifies the control flow graph cfg without changing the actual execution tasks e.g.
inserting redundant control flow or flattening control flows.
dex encryption which allows developers to encrypt the whole dex file.
it can encrypt user defined functions as well as android components such as activities and services.
the protected classes would be removed from the original classes.dex files thus cannot be obtained by reverse engineering tools.
visualization based protection which translates the code into a stream of pseudo code bytes that is hard to be recognized by the machine and human.
such apps should be executed in a specific runtime which will interpret the pseudo code.
related work tpl detection.
third party library detection plays an important role in the android ecosystem such as malware repackaging detection where tpls are considered as noises thus should be filtered out.
most malicious repackaged apps detection employed a whitelist based method to detect tpl based on the package name.
chen et al.
collect popular libraries as the whitelist to filter third party libraries when detecting app clones.
repackaging detection tools and malware detection tool also adopt the whitelist based method to remove third party libraries.
however such a method exists hysteresis and lacks robustness which cannot cover all tpls and finds emerging libraries as well as obfuscated libraries.
to seek more effective approaches to find in app tpl various detection tools appear.
we will elaborate on these tools in the following sections.
android testing tool comparison.
shauvik et al.
compared the effectiveness of android test input generation tools based on four aspects ease of use compatibility code coverage and fault detection ability.
they reveal the strengths and weaknesses of different tools and techniques.
xia et al.
also conducted an empirical study of various android input generation tools and found monkey could get the best performance.
they also developed a new method to improve the code coverage of monkey.
kong et al.
reviewed papers related to automated testing of android apps.
they summarized the research trends in this direction highlighted the state of the art methodologies employed and presented current challenges in android app testing.
they pointed out that new testing approaches should pay attention to app updates continuous increasing of app size and the fragmentation problem in the android ecosystem.
fan et al.
evaluated the effectiveness of both dynamic testing tools and static bug detection tools in android apps especially for android specific bugs.
chen et al.
evaluated the effectiveness of static security bug detection tools for android apps.
clone app detection comparison.
li et al.
surveyed state of the art approaches of repackaged app detection in which they compared different repackaging detection techniques and elaborated current challenges in this research direction.
they found that current research on repackaging detection is slowing down.
they also presented current open challenges in this direction and 921ase september virtual event australia x. zhan l. fan t. liu s. chen l. li h. wang y. xu x. luo y. liu compared existing detection solutions.
besides they also provided a dataset of repackaged apps which can help researchers reboot this research or replicate current approaches.
zhan et al.
conducted a comparative study of android repackaged app detection.
they reproduced all repackaged app detection tools and designed a taxonomy for these detection techniques and then analyzed these techniques and compared their effectiveness.
finally they listed the advantages and disadvantages of current techniques.
furthermore baykara et al.
investigated malicious clone android apps.
they revealed potential threats that can affect users experience.
finally they provided some potential solutions for these risks.
overview of tpl detection to investigate existing tpl detection techniques we first follow a well defined systematic literature review slr methodology to find related research in this area.
we search the candidate papers from four digital databases acm digital library ieee xplore springerlink and sciencedirect and top conferences and journals on both software engineering and security.
we do not consider posters or short papers that provide a preliminary idea.
finally we get nine publications to compare and analyze.
libd2 is an extension of libd therefore we discuss them together.
based on the detection process we introduce and compare the state of the art tpl detection techniques with details shown in table .
.
preprocessing comparison in the preprocessing stage we can find from table 1that apktool is the most frequently used tool .
androguard can be used to generate the class dependency relationship both androguard and soot can be used to construct cfgs.
besides androguard and apktool can restore the package structure and each independent tree structure indicates a package hierarchy structure which is used by some systems e.g.
libradar libpecker as a supplementary feature to construct the library instances.
.
library instance construction comparison as shown in table 1on library instance construction apart from the package name pn another three features are used to identify the boundaries of tpls package hierarchy structure phs .
phs is a tree which can be treated as a directed graph where each node indicates a package a sub package or a file and each edge indicates the inclusion relations between two nodes.
tools i.e.
libid libpecker libradar that use phs regard each independent directory tree as a library instance candidate.
homogeny graph which indicates the parent or sibling relations between two nodes including call relations inheritance relations and inclusion relation .
package dependency graph pdg .
pdg considers the dependency in the intra packages including member field reference relation method invocation relation inheritance relation and intra package homogeny relation.
different dependency relations will be set different weights based on intimacy.
insights.
we give a brief discussion about the three features.
tools that only depend on the phs e.g.
libid libpecker libradar may miss some tpls.
for instance tpls can be inserted into the package of the host app as part of the host app which may bedeleted during pre preprocessing without further consideration.
tools depending on the homogeny graph i.e.
libd if packages of two tpls have the inclusion or inheritance relations they may be considered as one tpl.
tools depending on pdg i.e.
libsift addetect would be more reliable than other tools since the pdgbased method considers both the phs and homogeny relations and it splits an app into different parts based on the package dependency.
.
feature extraction comparison we use two metrics to compare the feature extraction process of existing tpl detection methods feature generation method and signature representation.
feature generation method.
as shown in table libid and libpecker exploit class dependency relations as features including class dependency class inheritance dependency field dependency and method prototype dependency but they adopt different hash algorithms to generate signatures.
libd and han et al.
use opcode from cfg blocks as features and use hash methods to generate the opcode.
the only difference is that besides the opcode han et al.
adopt method type tag as well.
both orlis and libscout select the fuzzy method signature as the feature but with different generation methods.
libscout uses the merkel tree to generate the hash to represent a tpl based on the package structure.
orlis first uses one feature hash algorithm sdhash to hash the fuzzy method signature to represent the library level signature and then applies the ssdeep hash algorithm to generate the class level feature.
libradar exploits the android apis the total number of android apis and the number of api types to construct the feature vector.
libradar calculates the hash value of the feature vector as the final fingerprint.
addetect extracts app component usages information device identifiers and users profile android permissions as well as android apis to represents ad library features.
signature representation.
based on table we can find five systems that adopt hash value to represent features.
libscout exploits merkle tree to generate the tpl feature and the feature representation is also a hash value at the package level.
note that libsift does not identify specific tpls but split independent tpl candidates out.
addetect employs static analysis to extract the code feature represented as vectors.
.
library identification comparison in this stage the comparison features have two different granularity the fine grained features at the class level and the coarse grained features at the package level.
from another perspective the identification strategies can be divided into three categories similarity comparison clustering based method and classification based method.
table 1shows that libd and libradar choose the clustering method to identify tpls which does not require collecting ground truth tpls to build a database.
compared with the clustering method the similarity comparison methods usually conduct pairwise comparison which needs to collect the tpl files as ground truth.
if the similarity between the in app tpl and a tpl in the database is large than a pre defined threshold tools will consider it as a tpl.
classification based methods i.e.
addetect employ svm to classify the ad non ad libraries.
922automated third party library detection for android applications are we there yet?
ase september virtual event australia table a comparison of existing tpl detection systems in descending order by publication year t ool year t ool availablepr eprocessing toollib instance construction featur e extraction librar y identification featur e metho d featur e metho d granularity metho d libid andr oguard dex2jarphs pnconstruct gt bipclass dependency lsh class similarity comparison libpe cker apkto ol androguardphs pn construct gt class dependency hash classfuzzy class match similarity comparison han et al.
andr oguard phs pn construct gtop code of cfg basic blockhash package similarity comparison libd apkto ol androguardhomogeny graph pn op code of cfg basic blockhash package clustering orlis so ot class dependency construct gt metho d signature hash class similarity comparison libradar apkto ol phs pn api calls number types of apihash package clustering libsift apkto ol pdg ha c package libscout so ot phs pn construct gt metho d signature merkle tree packagefuzzy match similarity comparison a ddetect apkto ol pdg ha capi permission etc.
feature vector static analysis package svm pn package name phs package hierarchy structure gt ground truth pdg package dependency graph lsh locality sensitive hashing hac hierarchy agglomerative clustering bip binary integer programming models empirical study design in this section we attempt to thoroughly compare the state of theart tpl detection tools using the following four criteria c1 effectiveness.
we compare the effectiveness of existing tools on a unified dataset without bias by using three metrics recall precision and f1 score .
c2 efficiency scalability.
we compare the detection time of each tool and point out the tools that are scalable to large scale detection and can be extended for industries.
c3 capability of obfuscation resilience.
based on a previous study more than tpl in apps are obfuscated.
obfuscated tpls can affect the detection accuracy.
we thus compare the obfuscation resilience capability of each tool against different obfuscation strategies.
besides for the same obfuscation strategy different obfuscators obfuscation tools have various implementation schemes we also compare the detection ability of existing tpl detection tools against different obfuscators.
c4 ease of use.
usability of a tool is usually the primary concern for users.
thus we attempt to reveal the usability of each detection tool by designing a survey to investigate different users using experiences and let users rate each tool.
.
tool selection our evaluation only considers the publicly available tools in table among which libd is reported containing an error in terms of the hash method by the owner we thus excluded it in this paper but we still conduct the comparison of libd.
the detailed comparison results can be seen in our website .
eventually we consider presenting the comparison results of five tools i.e.
libid libradar libscout libpecker and orlis here.
.
data construction for the evaluation dataset we collect two datasets for different purposes detecting tpls in closed source apps e.g.
from google play store to evaluate the effectiveness efficiency of each tool inthe real world c1 c2 .
detecting tpls in open source apps with without obfuscation to evaluate the obfuscation resilient capability of each tool c3 .
the reason we use a separate dataset for assessing c3 is that the first dataset lacks controlled trials.
to evaluate the obfuscation resilient capability we need to collect apps with without code obfuscation.
however the real world apps from google play cannot meet this condition lacks ground truth for code obfuscation.
the apps from google play may be obfuscated by developers and we cannot know which tool they use to obfuscate apps and which obfuscation techniques are adopted.
therefore the first dataset cannot be used to evaluate c3.
.
.
dataset for effectiveness efficiency evaluation.
this dataset needs to meet two requirements providing the mapping information between apks and tpls and providing a full version set of each tpl.
note that we need to collect the tpls with their full versions to ensure fairness when comparing these tools.
the reasons are as follows we can only know the libraries used in an app by referring to some websites such as appbrain without knowing the specific library version.
even for the same tpl the code similarity of different versions also varies ranging from to .
if an app uses tpls whose versions are not included in the tpl dataset it could cause false negatives when the code similarity of two versions is below the defined threshold.
thus to eliminate the side effects caused by the incomplete versions of tpls we should collect the tpls with their full versions.
the ways in which the libraries update are diverse.
some tpls require developers to manually update them while some tpls support automatic update.
therefore it is difficult to ensure the specific mapping relations between tpls version and some apps.
we find that only orlis released a dataset to evaluate the capability of obfuscation resilience.
however the number of in app tpls from open source apps is usually small and most of tpls are non obfuscated which cannot reflect the ability of these tools to handle real world apps.
besides they do not provide full versions of tpls in the dataset which may lead to bias for some tools.
923ase september virtual event australia x. zhan l. fan t. liu s. chen l. li h. wang y. xu x. luo y. liu therefore we need to collect both the real world apps and the full versions of used tpls.
tpl collection.
we use library scraper to crawl tpl files from maven central jcenter google s maven repository etc.
we refer to appbrain to get the app library mapping information and manually check their relationship to ensure the correctness.
besides we also crawl the apps that use the tpls in our dataset from google play.
we filter out tpls whose full versions are not included in our dataset.
finally we select unique tpls and corresponding library versions.
app collection.
according to the collected tpls we can acquire the apps using these tpls from appbrain.
we download android apps the newest versions that use at least one tpl in our collected tpl database from google play.
this dataset containing tpls and the corresponding apps is used as the ground truth to evaluate the accuracy and performance of each tool.
we clarify a confusing concept here.
libradar and libd adopt clustering based method to identify in app tpls which require considerable number of apps million level as input to generate enough tpl signatures.
whereas we collect apps to verify their performance here thus we do not need so many apps here.
moreover the size of our dataset is closed to existing similarity detection tools such as libscout .
.
.
dataset for obfuscation evaluation.
in order to investigate the obfuscation resilient ability of existing available tools in terms of android apps protected by code obfuscation techniques we employ the benchmark containing open source apps downloaded from f droid mapping to tpls.
the dataset includes two parts apps with non obfuscated tpls and the corresponding obfuscated ones.
we use the dataset to evaluate two aspects capabilities towards different obfuscation tools capabilities towards different obfuscation techniques.
to evaluate the abilities regarding different obfuscators tpls in each app from our benchmark are obfuscated by using three obfuscators i.e.
proguard dasho and allatori respectively.
finally our dataset includes four sets non obfuscated apps with three sets of apps whose tpls are obfuscated by three obfuscators respectively.
to further investigate the capability regarding different obfuscation strategies we randomly choose open source android apps in the previous experiment and choose dasho to obfuscate the apps non obfuscation with different obfuscation techniques i.e.
control flow randomization package flattening and dead code removal .
finally we get three groups of obfuscated apps.
evaluation our experiments were conducted on servers running ubuntu .
with core intel r xeon r cpu .30ghz and 192gb memory.
.
c1 effectiveness we aim to compare existing library detection tools regarding the dataset collected in section .
.
note that libradar a clusteringbased method have published their tpl signature database we directly employ this database to evaluate its effectiveness.
overall results.
as shown in figure we can observe that most existing tools can achieve high precision but all tools have low figure detection result of different tpl detection tools recall i.e.
less than indicating that existing tools can only detect less than half of the tpls used by the apps.
libscout .
achieves the highest recall followed by libid .
.
as for the precision libradar achieves the best performance which reaches .
the precision of libradar .
and libscout .
and libpecker .
are very close all of them are above .
the precision and recall of orlis are the lowest among these tools which are .
and .
respectively.
to evaluate the comprehensive performance of these tools we use the f1 value as an indicator.
we can see that libscout outperforms other tools achieving .
followed by libid .
.
orlis has the lowest performance reaching only .
.
fp analysis.
the false positives are mainly caused by two reasons.
the first one is due to the tpl dependency.
if a tpl lib3 is built on lib1 and the test app include the lib3 lib2 and lib3 are the same tpl but different versions.
lib2 does not depend on other tpls the core code of lib2 and lib3 are the same and the signatures of lib1 lib2 as well as lib3 are stored in our database.
when a tool search the database the in app modules may match lib1 and lib2 at the same time leading to false positives.
other false positives come from the code of closed versions with high similarity and some tpl detection.
tools e.g.
libradar libid and libscout choosing package hierarchy as a supplementary feature to identify tpls.
different versions of the same tpl may have different package hierarchy structure.
taking the library okhttp as the example for the versions before .
.
the root package was com squareup okhttp while it changed to okhttp3 for versions after .
.
.
they are considered as two different tpls since they have different root package structures.
these tools find the tpls but report it twice one of them is regarded as a false positive.
this example also illustrates that these tools cannot identify the root package mutation of the same tpl.
fn analysis.
we take an in depth analysis of the reasons for the low detection rate of these tools.
there are two reasons affecting the recall code obfuscation tpl identification methods.
apps in our dataset are from google play store which may be obfuscated by developers.
if the obfuscator removes the whole package structure of a tpl and put all files in the root directory of apps this code obfuscation can dramatically decrease the detection rate of all tools.
dead code removal can also affect all tools.
moreover the package structure can affect the fingerprint generated by libscout and libradar and the package name mutation can affect the 924automated third party library detection for android applications are we there yet?
ase september virtual event australia figure detection rate of different tools towards handling multiple dex and single dex problems tpl identification of libid libradar.
therefore code obfuscation causes false negatives of current tpl detection tools.
in addition the selected identification algorithms may also affect the detection rate.
the detection rate of clustering based methods primarily relies on the number of collected apps and the reuse rate of tpls used by these apps.
it may cause false negatives when an insufficient number of apps are collected for clustering.
besides clustering based tools assume the modules that are used by a large number of apps are tpls.
this assumption causes it can only find some widely used tpls.
if some tpls are seldom used by apps or very new they will fail to identify them.
another minor reason for the false negatives of libradar is that its pre defined database may not contain the tpls we use in our experiment.
in contrast the similarity comparison algorithm can alleviate the fn caused by rarely used tpls by adding them to the database.
from our experimental result we can find the recall of the similarity comparison methods i.e.
libid libscout is higher than that of clusteringbased methods i.e.
libradar libd .
besides we find libid libpecker and orlis cannot handle tpls in .aar files.
in fact a tpl could include both the .aar format files and .jar format files.
in our dataset about tpls are represented in .aar format.
thus this is another reason that results in the false negatives of these three tools.
we also find that libid would report some errors when it profiles the tpl files by using dex2jar above reasons lead to tpl signatures missing in the database of libid and directly increase the fn of libid.
multidex problem.
another reason which can affect the recall is the 64k limit problem.
in android the executable java code is compiled into dalvik executable dex file and is stored in the apk file.
the dalvik executable specification limits the total number of method