cure c ode aware neu ral machine translation for automatic program re pair nan jiang purdue university west lafayette usa jiang719 purdue.eduthibaud lutellier university of waterloo waterloo canada tlutelli uwaterloo.calin tan purdue university west lafayette usa lintan purdue.edu abstract automatic program repair apr is crucial to improve software reliability.
recently neural machine translation nmt techniques have been used to fix software bugs automatically.
while promising these approaches have two major limitations.
their search space often does not contain the correct fix and their search strategy ignores software knowledge such as strict code syntax.
due to these limitations existing nmt based techniques underperform the best template based approaches.
we propose cure a new nmt based apr technique with three major novelties.
first cure pre trains a programming language pl model on a large software codebase to learn developer like source code before the apr task.
second cure designs a new code aware search strategy that finds more correct fixes by focusing on compilable patches and patches that are close in length to the buggy code.
finally cure uses a subword tokenization technique to generate a smaller search space that contains more correct fixes.
our evaluation on two widely used benchmarks shows that cure correctly fixes defects4j bugs and quixbugs bugs outperforming all existing apr techniques on both benchmarks.
index terms automatic program repair software reliability i. i ntroduction automatic program repair is crucial to reduce manual software debugging efforts .
there has been recent adoption of neural machine translation a widely used technique for natural language processing nlp tasks to generate correct code automatically given buggy source code .
thanks to the strong learning capabilities of nmt models nmtbased apr techniques have outperformed most existing rulebased approaches .
nmt models use deep learning techniques to encode buggy source code as intermediate representation in the latent space automatically and then decode the encoded representation into target correct code.
by minimizing the loss function and updating the weight parameters nmt models learn to capture the hidden relationship between buggy code and correct code without any manual design of fix patterns or feature templates.
for a search based apr approach including nmt based techniques to generate a correct fix it needs to satisfy two conditions the correct fix must be in the search space which is the set of all patches that the apr approach can generate and the search strategy must be effective to find the correct fix in a reasonable amount of time.
given that a correct patch is in the search space it is desirable that the search space is small so that it is easier to find the fig.
.
uncompilable patches generated by nmt based models and their ranks for a bug in quixbugs.
the line in yellow background starting with is the buggy line.
the line in green background starting with is the correct fix.
the red code in generated patches disobeys java syntax.
correct patch .
despite being among the most effective apr approaches nmt based approaches still fail to fix many bugs .
compared to natural language text source code has its own characteristics such as a strict syntax code semantics and an infinite number of possible identifiers.
these characteristics impose unique challenges for nmt models to fix bugs automatically.
first the strict syntax of source code is hard for nmt models to learn.
a major reason is that existing techniques learn from buggy code snippets and the corresponding fixed correct code snippets typically a few lines to tens of lines per bug and do not use the entire source code repositories typically millions of lines of code per project .
thus existing nmt based apr approaches have limited knowledge about the rigorous syntax of programming languages and the big picture of how developers write code.
the missed opportunities are twofold existing techniques fail to take advantage of the large amount of available source code and they see partial code snippets only which alone are often syntactically incorrect and miss the big picture of complete methods classes and projects.
for example for the fix of replacing while x f with while y f the open bracket f is syntactically incorrect in this code snippet i.e.
missing the closing bracket g .
such ineffectiveness is evident as demonstrated by data.
for example up to of patches generated by the state ofthe art nmt based apr models are uncompilable wasting valuable resources on incorrect patches.
figure shows a bug in quixbugs and some of the top ranked patches generated by coconut .
all of these patches are uncompilable because they call methods with wrong parameters invoke undeclared variables or contain mismatched parenthe11612021 ieee acm 43rd international conference on software engineering icse .
ieee sis.
one important reason that coconut fails to generate a correct patch for this bug despite generating patches is the large number of uncompilable patches.
the code aware nmt based approach we propose automatically generates a correct patch identical to the line highlighted in green for this bug.
the ranks of these uncompilable patches are high because existing nmt based apr techniques focus on translating buggy code snippets to correct code snippets which are partial code segments instead of full methods or programs.
since they fail to see the whole picture of the entire program or programming languages they generate many patches with syntax errors.
failing to learn how developers write code existing nmt based apr techniques also generate compilable but obviously incorrect patches as they do not look like developer written code.
these uncompilable and compilablebut incorrect patches decrease the accuracy and efficiency of apr models preventing apr models from generating more correct patches faster.
second the infinite number of possible identifiers causes nmt techniques for code to handle an enormous vocabulary if using word level tokenization where a vocabulary contains all the unique tokens that an nmt model recognizes.
considering the complexity of nmt architectures it is computationally too expensive for nmt based apr models to use an enormous vocabulary.
yet with a limited vocabulary size their search spaces do not contain all correct fixes.
sequencer uses a small vocabulary and shirks this complexity to a later reconstruction stage while coconut uses a vocabulary of more than tokens but still suffers from the outof vocabulary oov i.e.
an nmt model cannot recognize or generate a token problem resulting in its search space that still misses correct fixes.
a. our approach thus we propose an nmt based approach that is specially designed to parse analyze model and search source code as opposed to natural language text to fix bugs automatically.
our approach cure not only improves the search space a smaller search space containing more correct patches but also uses a more effective search strategy to find and rank correct patches higher which are achieved through the following three main techniques that we design and use programming language models to help nmt models learn developer like source code i.e.
not only compilable but also similar to those written by programmers we apply the pre training and fine tuning workflow to the apr task.
specifically pre trained language models have brought great improvement to many nlp tasks .
they learn the probability distribution over sequences of words from a large amount of natural language text.
then one fine tunes the pretrained language model for a specific task by adding an extra model to it e.g.
adding a classifier for classification tasks .
the language model provides vectorized representations of input sequences to the model added to it.
since a pre trained language model is typically trained on a larger dataset since itis unsupervised learning and does not require ground truth it offers the added model more information regarding sentence structures e.g.
syntax and about what human like text are e.g.
readability which improves the quality of the generated text of the fine tuned model for the specific task significantly.
given the effectiveness of language models in the nlp domain we propose to add a language model pre trained on software code referred to as programming language pl model to an nmt architecture to create a new apr architecture.
the pl model is trained to predict the next tokens in code sequences and learns to generate developer like code.
then we combine the pl model and the nmt model to form the full apr model and fine tune it for apr tasks.
our pl enhanced nmt approach ranks correct patches higher in the search space to fix more bugs section v b1 .
code aware search strategy when using an nmt model to generate a sequence of tokens to form a patch ideally one prefers the sequence with the highest score e.g.
average log probability of every token in sequence.
since this is prohibitively expensive in practice one uses a search strategy to choose proper tokens at each step.
beam search is a common search strategy for nmt that keeps the most n probable sequences at each step where nis the beam size .
the beam size of nlp tasks is typically to .
since source code has more possible identifiers and a bigger search space than natural languages the nmt models for apr usually require larger beam sizes to to generate enough candidate patches.
however with large beam sizes the vanilla beam search chooses many bad patches either uncompilable or far from correct in length.
to address this challenge we propose two solutions valididentifier check strategy and length control strategy.
first since source code is a formal language only valid tokens are allowed including keywords and variables in scope.
invalid tokens make a patched program uncompilable let alone capable of passing test cases.
therefore we propose and design a valid identifier check strategy to improve the vanilla beam search which performs static analysis to identify all valid identifiers and then forces beam search to generate only sequences with valid tokens.
second with a large beam size beam search finds many very short sequences such as f and tryf which are incorrect code snippets to fix bugs.
since correct fixes in our training data are typically of similar length to the buggy lines we use a length control strategy to punish too short and toolong sequences to prompt cure to generate patches of a similar length to the buggy line.
our code aware beam search strategy finds more correct fixes by generating more compilable patches and patches of similar length to the buggy lines.
section v b2 .
subword tokenization the enhanced word level tokenization proposed by coconut reduces the vocabulary size of code by using camel letters underscores and numbers to split long identifiers.
however many compound words such as binsearch for binary search do not contain 1162these special characters.
the previous parsing approach keeps binsearch as one word which is oov instead of breaking it into bin and search both of which are in the vocabulary.
thus we use byte pair encoding bpe a type of subword tokenization techniques to tokenize compound words and rare words to further address the oov problem.
bpe improves the search space by both including more correct patches and reducing its size section v b3 .
b. contributions we design and implement a code aware nmt based technique cure to fix bugs automatically.
our contributions include an approach to pre train a pl model for apr on a very large software codebase .
million methods from open source projects to capture code syntax and developer like source code a new apr architecture that combines a pre trained pl model and nmt architectures to learn both code syntax and fix patterns a new code aware beam search strategy which uses valid identifier check and length control strategies to find more correct fixes a new application of subword tokenization to the apr task which addresses the oov problem effectively and a new apr approach cure that combines the techniques above and its evaluation on two widely used benchmarks defects4j and quixbugs where cure fixes the most number of bugs and bugs respectively outperforming all existing apr tools.
cure is the first nmt based approach that outperforms all state ofthe art apr approaches on defects4j.
availability data is available in a github repository1.
ii.
b ackground candidate plausible and correct patches following previous work we call patches generated by the models candidate patches.
patches that pass the validation stage are plausible and patches identical or semantically equivalent to developers patches are called correct patches.
parameters and hyperparameters parameters are the weights between the connections of the network.
these parameters are optimized during the training phase.
hyperparameters are arguments of the network defined before the training process.
they generally include layer dimensions number of layers and optimization parameters.
pre training and fine tuning pre training is the process of training a model for a general task e.g.
next word prediction with a very large dataset.
after pre training one gets a pretrained model with updated parameters.
a pre trained model can be fine tuned for a similar but specific task e.g.
text generation with few training data.
during fine tuning usually one needs to add extra models to the pre trained model to fit task and the parameters of both the pre trained model and added models are updated.
context aware neural machine translation conut architecture we use conut as our nmt architecture in this paper.
conut consists of a buggy lines encoder a context encoder a merger a decoder an attention module and a token generation module where the encoders and decoder are implemented with convolutional sequence to sequence architecture .
the details of conut is described in .
conut has shown good results for apr and convolutional architecture can be stacked to capture hierarchical features and long dependencies for larger contexts .
iii.
a pproach to address the challenges described in the introduction we design and apply three novel techniques i.e.
subword tokenization to improve the search space section iii c a programming language model to learn developer like source code and improve patch ranking section iii d and section iii e and a new code aware beam search strategy section iii g to improve patch ranking and generate more correct patches.
a. overview figure presents an overview of our approach.
cure consists of three stages training inference and validation.
during the training stage cure extracts methods from open source projects referred to as pl training data and tokenizes them step 1a in figure .
different from previous work we use subword tokenization which produces a smaller but more accurate search space that contains more correct patches.
cure uses these tokenized methods to train a new programming language model that learns developerlike source code with correct syntax step .
cure also tokenizes the buggy lines context and correct fixes extracted from the commit history of open source projects referred to aspatch training data into sequences of tokens step 1b .
we use these sequences to fine tune an ensemble of kapr models step .
each apr model combines the pl model with a context aware neural machine translation conut model .
during the inference stage a user provides a buggy project along with the location of buggy lines to cure.
these are standard input that existing apr tools require .
cure tokenizes the buggy and the context lines step 1c then analyzes the source code to extract a list of valid identifiers that are in scope of the buggy lines step .
the patch generation module generates a list of candidate patches using a new code aware beamsearch strategy step .
this new algorithm discards many irrelevant patches on the fly i.e.
as soon as an invalid token is generated and penalizes patches that are unlikely to be correct e.g.
fixes that are very different from the buggy line in length which saves a lot of resources and allows cure to search deeper for correct patches.
in the validation stage cure validates candidate patches by compiling and executing the test suites of the patched 1163fig.
.
overview of cure.
grey boxes represent major novelties of cure.
circled numbers indicate the steps of generating patches with cure.
projects.
cure outputs a list of plausible patches step for developers to examine.
b. data extraction cure uses two different types of training data.
first the gpt pl model is trained on millions of methods extracted from open source java projects.
second cure fine tunes the pl model for the apr task.
this step requires apr specific training data i.e.
buggy lines context and correct fixes .
we use coconut s training data shared on github .
coconut s authors extracted this dataset from open source repositories and identified buggy commits based on keywords in commit messages fix bug and patch .
they also cleaned the dataset using commit message anti patterns rename clean up refactor merge misspelling and compiler warning .
similar to coconut we use the method surrounding the buggy lines as context.
c. code representation and tokenization word level tokenization to tokenize buggy context and fixed lines to token sequences cure first uses enhanced word level tokenization to separate code lines by spaces camel letters underscores strings and numbers except and .
out of vocabulary issue the vocabulary size after the wordlevel tokenization is larger than what is commonly used in nlp and the test set still contains of oov tokens.
excluding rare tokens is problematic for source code because oov tokens are likely to be important project specific tokens.
excluding such tokens makes it difficult for nmt models to fix bugs in these new projects.
some existing nmt based apr models do not generate oov tokens missing the opportunity to fix more bugs.
sequencer uses a special token as a placeholder for oov tokens and then uses a copy mechanism to reconstruct them.
the copy mechanism replaces the placeholder tokens with the most likely token from the input buggy lines.
however this solution would fail to generate some patches since it can only copy tokens appearing in the buggy lines.
a buggy line and correct fix of closure .
b word level tokenization result of buggy line and correct fix.
c subword level tokenization result of buggy line and correct fix.
fig.
.
tokenized results that use word level tokenization and subword tokenization of closure in defects4j.
subword tokenization to address the oov problem and reduce the vocabulary size we use byte pair encoding bpe which is an unsupervised learning algorithm to find the most frequent subwords in a corpus by merging the most frequent byte pair iteratively .
bpe has been used in many nlp tasks and is useful to reduce vocabulary size and mitigate the oov problem efficiently .
figure shows an example from the inference stage demonstrating the effectiveness of the subword tokenization.
lines starting with are the buggy lines input and those starting with are the correct fixes.
figure a shows the source code of a real bug in defects4j while figure b shows the code after using the enhanced word level tokenization.
figure c shows the same code tokenized by our subword tokenization.
in figure each consequence separated by space is a token excluding the and signs.
when using only the enhanced word level tokenization the variable charno is an oov token.
thus coconut and sequencer fail to fix this bug since coconut cannot generate oov tokens and sequencer does not fix it correctly with the copy mechanism.
with our subword tokenization charno is split into two tokens both of which appear in the vocabulary char indicates that the token needs to be concatenated with the following token and no enabling cure to generate a correct patch for this bug.
1164by applying subword tokenization we use a smaller vocabulary to form a smaller but better search space that contains more correct patches.
section v b3 evaluates the impact of our subword tokenization approach.
d. programming language model to address the challenges of learning developer like source code we train a language model on open source programs referred to as a programming language model pl model .
a pl model optimizes the probability of a sequence of tokens being a real world code snippet.
we use generative pre trained transformer gpt for pl modeling because gpt has been shown to improve the performance of many different nlp tasks .
pre training a pl model allows for separating programming language learning from patch learning.
the advantages are twofold.
first gpt learning is unsupervised and only requires complete methods therefore one can extract a large amount of data automatically and accurately to train it.
second during fine tuning the apr model already knows the pl syntax thanks to the pl model making the fine tuning more efficient.
given a sequence of tokens representing a method x x1 x n wherexiis a token in the method sequence x the pl modeling objective is to maximize the average likelihood lgpt x n n i 1logp xijx1 x i where represents matrices of trainable weights of the pl model.p xijx1 x i is the conditional probability of tokenxibeing the next token given a sequence of x1 x i which is calculated by the pl model with weights .
at a high level the objective of the pl model training is to find the best weights so that sequences of tokens x1 x n representing real methods in projects obtain a higher lgpt score than other sequences.
since methods in popular opensource projects are dominantly well formed correct blocks of code we use them to train our pl model to learn if a given sequence of tokens is likely to form real world code compilable and looks like written by programmers .
e. fine tuning for apr with a pl model after pre training the pl model cure fine tunes the gpt pl model for the apr task by combining it with an nmt model as the apr model.
we use the conut section ii as cure s nmt architecture.
the apr model takes buggy lines and their context as input and aims to generate a correct patch.
during the fine tuning process the apr model is trained to learn the transformation from the buggy lines and context e.g.
the buggy method to the correct fix.
we use xb xb1 x bn to denote the buggy lines x x1 xcn to denote the context and y y1 y fn to denote the correct fixes where b1 b n are the indices of the buggy lines in the context while cnand fnare the lengths of the context and correct fixes respectively.
fig.
.
architecture of the apr models used in cure.
yellow purple and green boxes refer to the buggy lines context and the generated patch.
we denote the weights of the pl model as and weights of conut as .
the apr model is fine tuned by updating and to maximize the following average log likelihood lnmt x xb y fn fn i 1logp yijx xb y0 y i y0 xb1 p yijx xb y0 y i is the conditional probability calculated by the apr model with weights and where yiis the token following the sequence y0 y1 y i in the correct fix given the buggy lines xband context x. for the first token in the correct fix the probability is the conditional probability of token y1giveny0 wherey0is the token right before the correct fix i.e.
xb1 .
for example the entire method kth is the context in figure while the buggy lines and the correct fixes start at the same index in the context andy0is the tokenfright before the return statement.
to prevent the pl model from losing the information it learned during pre training we include the language modeling i.e.
lgpt as an auxiliary objective to the finetuning process.
it also improves the generalization of the finetuned model .
therefore the apr model is fine tuned by maximizing the combined average log likelihood lapr x xb y lnmt x xb y lgpt y0 y0 x1 x2 x b1 y where y0is the token sequence from the beginning of the buggy method to the last token in the correct fix x1 x2 x b1 1is the prefix of xbefore xb .
probability lgpt y0 is the likelihood of y0being a real source code snippet while is a hyperparameter referring to the coefficient oflgpt in the combined log likelihood lapr.
the fine tuning stage aims to find the best set of parameters and to maximize lapr for all buggy lines context and correct fixes in the training data.
1165in the training mode the apr model takes the pre trained gpt module the pl model and the patch training data as input.
the patch training data consists of the buggy lines the context and the correct fixes.
we train the apr model for multiple epochs i.e.
multiple passes on the training data to obtain the best combination of weights and .
in the inference mode the apr model has access to only the buggy lines and their context and outputs a sequence of tokens representing the patch.
figure shows a simplified view of the architecture of our combined apr model and how the model is used in inference mode.
our apr model consists of two components a pl model gpt and an nmt model conut .
first cure generates the gpt representation of the context lines step in figure .
as explained in section iii d the gpt model was trained on complete methods therefore the input of the gpt model needs to be a method.
if we directly feed the first token of the buggy line to the gpt model int in figure the gpt model will generate a bad embedding for it since it expects the first token of a sequence to be the first token of a method e.g.
public .
hence the gpt model generates an embedding for all tokens in the buggy method.
the conut model contains two encoders.
the buggy lines encoder only takes the representation of the buggy line as input.
therefore cure extracts the subsequence that corresponds to the buggy line embedding from the buggy method embedding yellow boxes in figure and forwards it to the buggy lines encoder step 2a .
the second encoder is for the context and takes the embedding of the entire buggy method purple boxes in figure as input step 2b .
cure merges the output of the two encoders step before sending it to the attention mechanism and the token generator.
to start generating tokens the attention mechanism and the token generator need the encoder s and the decoder s output.
at the start of the inference none of the fixed tokens have been generated yet.
coconut started the decoding sequence with an initial start token.
however it is better to initialize the sequence with the last token of the context before the buggy line to provide additional contextual information.
to obtain the embedding of this token we pass the context before the buggy line to the gpt model step and then feed the embedding of the last token f to the decoder step .
the decoder generates a representation of the token which is forwarded to the attention mechanism step .
the attention mechanism combines the output of the two encoders and the output of the decoder to form the attention map between the last token f in the example and the buggy method.
then the token generation outputs the first token of the fixed sequence double in step .
this token is then appended to the decoder input step .
then the decoder starts the next iteration steps to15 with the input f double and generates the token sum .
this iterative process continues until the end of sequence token eos is generated.
fig.
.
an example of extracting mappings between prefixes and valid next tokens from buggy projects.
line with yellow background is buggy line.
f .
ensemble learning prior work shows that ensemble learning i.e.
combining multiple models enables nmt based apr approaches to fix more bugs the number of bugs correctly fixed rises from to when the number of models increases from to .
therefore we combine models with different hyperparameters and models with two different architectures conut and fconv for our ensemble learning.
the gpt pl model is general as it represents the entire pl.
thus each apr model starts with the same pl model fine tunes it and combines it with conut or fconv architectures that have different hyperparameters step of figure .
balancing the computation cost and tuning effectiveness we use random search to pick different hyperparameter values e.g.
number of convolution layers convolution dimensions and dropout in a reasonable range and tune each model for one epoch.
based on each model s perplexity i.e.
a measurement of how well a model predicts an instance on our validation data we choose the top kmodels for ensemble learning and keep training them until convergence.
g. code aware beam search strategy and patch generation the goal of patch generation is to generate the sequence with the highest probability given the buggy line and its context.
the apr model generates one token with its probability at a time.
searching for the sequence with the highest probability is exponential in the length of the output sequence.
thus we need an effective search strategy to find a sequence with a high probability.
beam search is an optimized greedy strategy and the most common search strategy used for nmt.
beam search keeps only then nis beam size a hyperparameter of beam search optimal nodes instead of all nodes in the search tree to expand at every step and remove the rest.
a major issue of the vanilla beam search is that it considers only the log probability provided by the model to generate the next token.
since other information about code e.g.
variables in scope is unavailable to the apr model it often generates a high score for an outof scope variable producing an uncompilable candidate patch.
therefore we design two techniques valid identifier check andlength control to make the beam search code aware.
valid identifier check only a few tokens are valid in a certain java code snippet since correct code must follow java syntax and compilation rules.
to generate valid identifiers only cure first uses static analysis to analyze and extract valid identifiers.
then cure tokenizes these identifiers a vanilla beam search vs. beam search using valid identifier check with beam size of b vanilla beam search vs. beam search using length control in the same bug but with beam size of fig.
.
examples using the vanilla beam search and beam search with valididentifier check and length control strategies.
green arrows are the paths to the correct fixes.
grey circles are the nodes kept by the search strategies in the search tree at every level and white circles are nodes discarded.
red numbers are the log probability changed by search strategies.
e.g.
max ending here becomes max ending here and builds the mappings between all prefixes and their valid succeeding tokens as showns in figure .
these mappings are necessary for the beam search algorithm to know that after generating the sequence max ending here is a valid next token because max ending here is a valid identifier.
at every decoding step the nmt model outputs a probability distribution of all the tokens in vocabulary.
cure s new valid identifier check strategy first analyzes the token sequence already generated to get the prefix of the next token needed to be generated.
if the generated token sequence does not contain any prefix i.e.
the next token will be the beginning of a new identifier the prefix will be set to the empty string.
then based on the mappings between all possible prefixes and their valid succeeding tokens the valid identifiercheck strategy modifies the probability distribution and sets the probability of invalid tokens to inf.
by this the valid identifier check strategy discards many impossible nodes increasing the possibility of finding the correct patch.
figure a illustrates how our code aware beam search outperforms the vanilla beam search.
the correct fix is max ending here math.max max ending here and the start of the output sequence max ending here has already been generated in steps to .
we use a beam size of to simplify theillustration.
the path to the correct fix is marked with green arrows and the nodes considered by the beam search strategies are in light grey.
during step the two most likely nodes according to the apr model are ... max and ... math where ... refers to max ending here which has already been generated.
however at step the average log likelihood of ... math .
which is the sequence denoted by the green path in the left subfigure of figure a is less than that of ... max and ... max camel so the vanilla beam search drops it.
thus the entire subtree containing the correct fix is excluded.
in contrast with our valid identifier check strategy the average log likelihood of ... max camel is set to inf because there is no valid identifier starting with max camel .
therefore our code aware beam search keeps searching the subtree of node ... math which leads to the correct fix.
length control in our training data most correct fixes have a similar length as the buggy lines.
we find the length difference of of the bugs in our .
million patch training data is less or equal to tokens.
this means that most of the time the correct fixes are small modifications to the buggy lines and more complex changes are less common.
therefore we use length control strategy to generate patches of a similar length of the buggy lines by punishing short and long patches.
at every decoding step the lengthcontrol strategy calculates the length of the sequence already generated.
if the current length is much smaller than the buggy lines it decreases the log likelihood of eos to prevent this patch from reaching the end.
and if the current length is already much larger than the buggy lines it increases the log likelihood of eos to prompt this patch to end.
to determine the penalty value we leverage the length difference distribution in the patch training data to calculate the log probability of each length difference denoted as function flen.
our length control strategy modifies the log likelihood of token eos by adding the following penalty to it penalty lb lp flen lb lp otherwise where the lengths of the buggy lines and the patch sequence already generated are lbandlprespectively.
we empirically set a tolerance threshold of to increase flexibility.
figure b illustrates this issue.
the bug is the same as in figure a but with a larger beam size of .
in step the sequence f g reaches the eos token.
using the vanilla beam search patch f g has a low average log probability but is still in the top this is added to candidate patches because the beam size is large .
such low score patches take up the valuable slots and prevent correct patches from being selected.
in our code aware beam search strategy since the complete sequence f g is much shorter than the buggy sequence the eos token receives a large penalty and is not selected as a candidate node not included in the 1167highest average log probabilities allowing the search strategy to search deeper along other paths.
while cure focuses on fixing bugs whose fixes are similar in length to the buggy lines our length control strategy is general and can be adapted to generate longer patches by modifying the penalty weights.
given the complexity of apr fixing similar length bugs and other bugs separately may be an effective way to decompose this complex task.
h. patch validation after apr models generate candidate patches we reconstruct the token sequences to code statements.
we first concatenate tokens end with to their successors which is the reconstruction from subwords to words.
then we extract donor code from the buggy code file to reconstruct the abstracted tokens numbers and strings .
reconstructed statements are ranked by the average logprobability of their tokens and then inserted into the buggy code file to replace the buggy lines.
every patched project is compiled to filter the uncompilable patches and we run the test suites until we find a patch that satisfies two conditions passing all the test cases that the buggy project passes and passing at least one test case failed on the buggy project which are the same criteria for validation used in previous work .
iv.
e xperimental setup realistic evaluation to make the evaluation realistic we need to avoid using future data .
we address this issue by using data committed before the first bug in our benchmark i.e.
for pre training fine tuning and validation.
pl training data we download all open source java projects from github that have at least one commit before the first bug in defects4j according to ghtorrent and roll them back to a version before to avoid using future data.
then we use javaparser to extract all methods except abstract methods and those longer than tokens.
the pl training data contains .
million methods with instances for validation.
patch training data we use coconut s training data shared on github as our patch training data which is extracted from java projects.
these java projects are a superset of the projects used for pl training data since we need more projects to extract enough patch data and it is too expensive to use all these projects for pl training.
then we discard the instances whose context or correct fixes are longer than tokens after subword tokenization.
removing instances from the training set is a common practice for machine learning and since the test set bugs in defects4j and quixbugs are untouched this setup is valid.
our patch training data contains .
million training instances and validation instances.
subword tokenization training fine tuning and inference we set the target vocabulary size to be for bpe.
for the gpt model considering previous work srecommendation and our hardware limits we use an embedding size of eight layers of transformer blocks and six attention heads.
we train gpt for five epochs using a batch size of .
we use adam optimizer and the learning rate increases from to 5e 4at the first training steps and then decreases using a cosine schedule.
to fine tune the hyperparameters of an apr model we use random search with the following ranges convolution dimension kernel size number of convolutional layers and dropout .
.
is empirically set to .
.
we train apr models on a smaller subset of patch training data for one epoch and keep the top five models combining gpt with conut model and top five apr models combining gpt with fconv model.
we use adam optimizer with a learning rate of 25e 5to keep tuning the top models on our patch training data for one epoch with a batch size of .
in inference mode we use beam search with a beam size of and cure generates candidate patches for every bug.
during the validation stage considering the time cost and that most correct fixes have high ranks we validate the top candidate patches per bug.
infrastructure we use gpt implemented by hugging face conut and fconv implemented using fairseq .
we train and evaluate our models on one core server with one nvidia titan v and three xp gpus.
v. e valuation and results we use two widely used benchmarks defects4j v1.
.
and quixbugs for evaluation.
following we remove two defects4j bugs closure and closure from our evaluation as they are duplicates of other defects4j bugs.
we compile the patched projects and run the test suites to find plausible patches i.e.
patches that pass the relevant test cases.
two co authors independently check plausible patches and consider correct only those that are identical or semantically equivalent to developers patches of agreement cohen s k of .
then discuss to resolve disagreements.
we compare cure with apr techniques .
table i shows the comparison results.
the table lists only a few top ranked techniques in terms of the number of bugs that they fix in each benchmark including state of the art pattern based techniques three nmt based techniques and the techniques that have been evaluated on quixbugs.
none of these tools uses subword tokenization pre trained pl model or code aware search strategy.
other tools e.g.
a v atar kpar simfix either fix fewer bugs than the listed tools or were not evaluated on these benchmarks.
results from all9 techniques in table i except astor and hercules use the perfect fault localization fl of bugs to report bug fixing results.
as stated in previous work having apr techniques use the same fl techniques e.g.
perfect fl is a fair way to compare apr techniques since different fl methods affect apr techniques 1168table i comparison with state of the art apr tools .
the numbers are shown as x y where x is the number of bugs fixed correctly and y is the number of bugs with plausible patches .
means the approach has not been evaluated on that benchmark .
tool defects4j quixbugs bugs bugs astor nopol rsrepair hercules tbar sequencer dlfix coconut cure fig.
.
chart in defects4j is a bug only fixed by cure fig.
.
closure in defects4j is a bug that cure fixes but coconut does not.
differently.
cure s correctly generated patches are available in our github repository.
a. rq1 how does cure perform against state of the art apr techniques?
in table i the results are displayed as x y where x is the number of bugs fixed correctly and y is the number of bugs with plausible patches.
cure fixes the most number of bugs and respectively in both defects4j and quixbugs.
specifically cure generates plausible patches for defects4j bugs of which are correctly fixed by cure outperforming the best existing approach tbar by five bugs.
compared to nmt based approaches cure correctly fixes more bugs than the best nmt based approach coconut.
cure fixes quixbugs bugs twice as many bugs as coconut including bugs that none of the four existing tools that have been evaluated on quixbugs can fix.
in defects4j cure fixes one unique bug chart that has not been fixed by any of the existing approaches.
bugs that only cure fixes figure shows the unique bug in defects4j and the correct fix that cure generates which is equivalent to developers patch.
the correct fix requires ensuring the second parameter to be non negative.
pattern based approaches e.g.
tbar and hercules fail to fix it because they have no fix patterns to ensure that a method parameter is non negative.
nmt based approaches e.g.
sequencer dlfix and coconut fail to fix it since such a fix is uncommon.
in our patch training data already .
million training instances from projects there are only two similar fixes.
thus it is hard for nmt based models to capture this transformation due to the lack of more fig.
.
math in defects4j is a bug that cure fixes but pattern based tools tbar and hercules do not.
similar fixes.
however adding math.max to ensure nonnegativeness is common in java methods and is captured by our pl model allowing cure to fix the chart bug in defects4j correctly.
as explained in the introduction figure shows the kth bug in quixbugs which only cure fixes and none of the existing techniques evaluated on quixbugs does.
coconut fails to fix this bug as it generates too many uncompilable patches.
nopol rsrepair and astor cannot repair this bug as they do not implement the required fix pattern.
comparing with the existing best performing nmt based approach coconut cure fixes more bugs in defects4j.
figure shows an example bug that cure fixes and coconut fails to fix.
the correct fix of closure requires anyresultsmatch which is nonexistent in the buggy line or context.
coconut prioritizes tokens in the buggy line and context thus fails to generate the correct token to fix this bug.
in contrast cure s code aware beam search strategy extracts all valid identifiers including anyresultsmatch which is declared out of the context and generates the correct fix.
comparing with the best pattern based approach cure fixes five more bugs in defects4j than tbar most of which require complex transformations to fix.
figure shows an example.
the correct fix of math requires changes to the initialization of i and the condition for the loop.
tbar does not have such a complex fix pattern.
cure fixes math since similar transformations can be learned from the patch training data.
compilable patch rate in addition to the number of correctly fixed bugs we use the average compilable rate to measure the effectiveness of cure learning pl syntaxes and developerlike code.
we compare the average compilable rates of the topk candidate patches generated by different nmt based models for bugs in two benchmarks.
table ii shows that cure generates more compilable patches in top candidates than sequencer and more compilable patches in all top and than coconut dlfix does not offer compilable rate data .
comparing different rows shows that each component has contributed to the higher compilable patch rate.
for example comparing row bpe gpt conut vanilla with row cure shows that our code ware search has increased the average compilable patch rate by from to for the top patches.
cure generates more portions of compilable patches than existing nmt based approaches thanks to the pl model and the valid identifier check strategy.
these examples and compilable patch rates demonstrate that the unique capabilities of our model that combines a gpt pl model and an nmt model to learn both developer like code and fix patterns to fix more bugs and the effectiveness 1169table ii average compilable rates of the top k candidate patches for bugs in two benchmarks from different models .
vanilla and code aware denote vanilla beam search and code aware beam search respectively .
cure is bpe gpt c onut code aware .
indicates data unavailability .
top top top top model sequencer coconut conut vanilla bpe conut vanilla gpt conut vanilla bpe gpt conut vanilla cure table iii results of ablation study on two benchmarks .
c oconutuses 20models for ensemble while the rest use only 10models .
model defects4j quixbugs coconut conut vanilla bpe conut vanilla gpt conut vanilla bpe gpt conut vanilla cure bpe gpt conut code aware of our pl model and the context aware search strategy in generating more compilable patches.
type of bugs that cure is applicable for similar to most state of the art g v apr techniques cure is designed to fix single hunk bugs i.e.
the buggy lines and patches are single code segments and each buggy hunk has separate test cases .
b. rq2 what are the contributions of cure s components?
to study the impact of each novel technique i.e.
gpt pl model code aware beam search strategy and subword tokenization of cure we compare the following four techniques with cure coconut conut vanilla an ensemble of ten conut models and ten fconv models using word level tokenization and vanilla beam search strategy.
coconut uses twice as many models as cure and the next three techniques versus models and generates twice as many candidate patches.
each of the next three techniques is an ensemble of five conut models and five fconv models with the vanilla beam search strategy.
the differences are that bpe conut vanilla uses subword tokenization gpt conut vanilla uses a gpt pl model and bpe gpt conut vanilla uses both subword tokenization and a gpt pl model.
all models use a beam size of generate candidate patches validate the top candidate patches for every bug except coconut that generates and validates candidate patches for each bug and are trained on the same dataset.
impact of the gpt pl model table iii lists the result of the ablation study on two benchmarks.
rows bpe gpt conut vanilla versus bpe conut vanilla show that the gpt pl model helps apr models fix six morebugs in each benchmark.
comparing gpt conut vanilla with coconut shows that the gpt pl model helps fix six more quixbugs bugs.
although they fix the same number of defects4j bugs coconut uses an ensemble of models while gpt conut vanilla uses only .
coconut with models fixes bugs only which shows an improvement of six more bugs of gpt conut vanilla versus coconut with models.
in table ii comparing bpe conut vanilla and bpe gpt conut vanilla shows that gpt increases the average compilable rate by .
in addition the average rank the highest rank one is the best of the correct patches before validation generated by bpe gpt conut vanilla is higher than that of bpe conut vanilla vs. indicating that the gpt pl model not only enables apr models to fix more bugs but also improves the ranks of correct patches.
impact of code aware beam search strategy comparing bpe gpt conut vanilla and cure in table iii shows that our code aware beam search strategy helps apr models find more correct patches and fix more bugs six more in defects4j and four more in quixbugs .
comparison between bpe gpt conut vanilla and cure in table ii shows that our code aware beam search increases the average compilable rate by .
the average rank of the correct patches before validation generated by cure is higher than bpe gpt conut vanilla vs. indicating that our new search strategy also increases the rank of correct patches.
to measure the impact of the length control strategy we compare the length of candidate patches generated by bpe gpt conut vanilla and cure.
for the bpe gpt conut vanilla model the average length difference between candidate patches and correct fixes is seven tokens.
in contrast the average length difference between the cure s candidate patches and correct fixes is five tokens.
this shows the length control strategy helps generate more candidate patches with similar length to the correct fixes.
specifically it helps fix long bugs e.g.
it fixes the longest bug in quixbugs that cannot be fixed without length control strategy since it searches deeper.
impact of subword tokenization subword tokenization improves the search space by reducing the size of vocabulary from to tokens and covering more correct fixes.
coconut versus bpe conut vanilla shows that subword tokenization helps fix four more bugs one in defects4j and three more in quixbugs .
gpt conut vanilla versus bpe gpt conut vanilla also shows that subword tokenization helps fix more bugs.
we also compare the number of oov tokens with different tokenization techniques.
with word level tokenization bugs contain oov tokens in our benchmarks e.g.
binsearch and charno .
in contrast all these oov tokens are separated into more common tokens when using subword tokenization.
this shows that subword tokenization helps reduce 1170the vocabulary size improve the vocabulary make the model easier to train and eventually fix more bugs.
c. execution time data extraction downloading and extracting .
million methods from projects as our pl training data takes one day.
we use coconut s training data shared on github which takes five days to extract .
both are a one time cost.
training pl model it takes ten days to pre train the gpt pl model on four gpus for five epochs.
since the pl model is trained on large and general data one programming language only needs one pl model and the pl model can be used to enhance tasks other than apr and does not need retraining.
fine tuning apr models it takes days to tune the hyperparameters by training apr models for one epoch.
fine tuning the top apr models takes on average .
hours per model.
this is a one time cost as the trained apr models do not need retraining when fixing new bugs.
cost to fix one bug in inference it takes .
minutes on average for cure to generate candidate patches for one bug using four gpus.
during validation it takes .
minutes on average to validate one bug.
compared with the state of art nmt based approach cure uses fewer models and validates fewer patches thus cure is faster and fixes more bugs.
vi.
l imitations comparison with previous work it is difficult to fairly compare our work with all previous work as they use different training data and fl methods.
to be as fair as possible we use the same training data as coconut the state of the art nmt technique and demonstrate significant improvement on both benchmarks.
some previous work uses different training data but the selection and extraction of data is also a key component of a technique.
in addition to compare with previous apr techniques we choose to use perfect localization as it is the preferred comparison method and previous work evaluated most available apr techniques with perfect fl.
generalization to other benchmarks and pl we evaluate cure on two java benchmarks but the approach is neither tied to a specific pl nor a specific benchmark.
cure is generalizable to other languages by updating the pl parser.
the benchmarks we chose are very popular defects4j being used to evaluate other apr tools.
in the future we can also evaluate all apr approaches on recent benchmarks such as bugs.jar or bears .
accuracy of the training sets since our training and pretraining data extraction is conducted automatically there is a risk that such data is inaccurate.
the training data was extracted in previous work and showed to be reasonably accurate on a random sample.
for the pre training data we extract all complete functions and some of them might be buggy or incorrect.
however the goal of the pre training is to learn the syntax of the pl therefore we mostly care that the data follows the pl syntax which is verified since we only keep methods successfully parsed by a java parser.vii.
r elated work deep learning for apr different dl based apr techniques have been developed to fix bugs compilation issues or predict the correctness of generated patches .
cure is different from previous work in three ways.
first our subword tokenization technique addresses the oov problem encountered by all nmt based techniques.
second cure integrates a new pl model to the apr models that better learns the syntax of source code.
finally our new code aware search strategy chooses only valid identifiers during inference which helps filter out incorrect patches.
as a result cure generates more reasonable and compilable patches and outperforms all existing techniques.
automatic program repair many apr techniques have been proposed which use genetic programming condition synthesis state abstraction heuristics human designed fix patterns mined fix patterns bytecode mutation or neural program synthesis .
cure uses a new codeaware nmt approach and fixes more bugs than previous stateof the art approaches.
deep learning in software engineering the software engineering community had applied deep learning to performing various tasks such as source code summarization code clone detection defects prediction code completion and program synthesis .
these techniques along with ours demonstrate that deep learning is competitive in different software engineering tasks.
our work introduces code awareness to dl systems to improve apr.
in the future increasing code awareness of dl systems applied to other software tasks could also be useful.
language model in software engineering different programming language models have been developed .
none of these approaches have been evaluated on fixing software bugs and have only been used for simpler tasks such as method name generation or source code summarization.
recent work has questioned the generalizability of some of these approaches for more complex tasks .
compared with these models cure uses gpt one of the most powerful language models in nlp to capture code syntax and demonstrates its effectiveness for the more complex apr task.
viii.
c onclusion we propose and evaluate cure a new nmt based program repair technique that by design parses models and searches source code as opposed to natural language text to automatically fix bugs.
cure uses an nmt model that contains a pl model a code aware search strategy and a subwordtokenization technique to create a smaller search space that contains more correct patches and find more correct patches.
cure outperforms all existing techniques on two popular benchmarks fixing bugs.
we highlight this direction of code aware nmt for automatic program repair.
1171references c. le goues t. nguyen s. forrest and w. weimer genprog a generic method for automatic software repair tse vol.
no.
pp.
.
f. long and m. rinard staged program repair with condition synthesis in esec fse .
acm pp.
.
r. k. saha y .
lyu h. yoshida and m. r. prasad elixir effective object oriented program repair in ase.
ieee pp.
.
f. s. ocariza jr k. pattabiraman and a. mesbah vejovis suggesting fixes for javascript faults in icse .
acm pp.
.
j. xuan m. martinez f. demarco m. clement s. l. marcote t. durieux d. le berre and m. monperrus nopol automatic repair of conditional statement bugs in java programs tse vol.
no.
pp.
.
m. martinez and m. monperrus astor a program repair library for java demo in issta .
acm pp.
.
f. long p. amidon and m. rinard automatic inference of code transforms for patch generation in esec fse .
acm p. .
q. xin and s. p. reiss leveraging syntax related code for automated program repair in ase.
ieee p. .
y .
xiong j. wang r. yan j. zhang s. han g. huang and l. zhang precise condition synthesis for program repair in icse .
ieee pp.
.
j. jiang y .
xiong h. zhang q. gao and x. chen shaping program repair space with existing patches and similar code in issta .
acm pp.
.
j. hua m. zhang k. wang and s. khurshid sketchfix a tool for automated program repair approach using lazy candidate generation in esec fse .
acm pp.
.
m. wen j. chen r. wu d. hao and s. c. cheung context aware patch generation for better automated program repair in icse .
acm .
x. liu and h. zhong mining stackoverflow for program repair in saner .
ieee pp.
.
l. chen y .
pei and c. a. furia contract based program repair without the contracts in ase.
ieee pp.
.
x. b. d. le d. lo and c. le goues history driven program repair insaner vol.
.
ieee pp.
.
d. kim j. nam j. song and s. kim automatic patch generation learned from human written patches in icse .
ieee pp.
.
s. wang t. liu and l. tan automatically learning semantic features for defect prediction in icse .
ieee pp.
.
y .
li s. wang and t. n. nguyen dlfix context based code transformation learning for automated program repair in icse .
acm p. .
t. lutellier h. v .
pham l. pang y .
li m. wei and l. tan coconut combining context aware neural translation models using ensemble for program repair in issta .
acm p. .
z. chen s. kommrusch m. tufano l. n. pouchet d. poshyvanyk and m. monperrus sequencer sequence to sequence learning for end to end program repair tse .
m. tufano c. watson g. bavota m. d. penta m. white and d. poshyvanyk an empirical study on learning bug fixing patches in the wild via neural machine translation tosem vol.
no.
.
e. a. santos j. c. campbell a. hindle and j. n. amaral finding and correcting syntax errors using recurrent neural networks peerj preprints vol.
p. e3123v1 .
r. gupta s. pal a. kanade and s. shevade deepfix fixing common c language errors by deep learning in aaai pp.
.
a. mesbah a. rice e. johnston n. glorioso and e. aftandilian deepdelta learning to repair compilation errors in esec fse .
acm pp.
.
m. tufano c. watson g. bavota m. di penta m. white and d. poshyvanyk an empirical investigation into learning bug fixing patches in the wild via neural machine translation in ase.
acm pp.
.
f. long and m. rinard an analysis of the search spaces for generate and validate patch generation systems in icse .
ieee p. .
y .
ding b. ray p. devanbu and v .
j. hellendoorn patching as translation the data and the metaphor in ase .
s. clinchant k. w. jung and v .
nikoulina on the use of bert for neural machine translation in ngt .
acl pp.
.
i. skorokhodov a. rykachevskiy d. emelyanenko s. slotin and a. ponkratov semi supervised neural machine translation with language models in loresmt .
amta pp.
.
i. sutskever o. vinyals and q. v .
le sequence to sequence learning with neural networks in neurips .
mit press pp.
.
f. stahlberg neural machine translation a review jair .
j. gehring m. auli d. grangier d. yarats and y .
n. dauphin convolutional sequence to sequence learning in icml .
jmlr.org pp.
.
k. liu a. koyuncu d. kim and t. f. bissyand e tbar revisiting template based automated program repair in issta .
acm .
y .
qi x. mao y .
lei z. dai and c. wang does genetic programming work well on automated program repair?
in iccis .
ieee pp.
.
s. rico h. barry and b. alexandra neural machine translation of rare words with subword units annual meeting of the acl .
a. vaswani n. shazeer n. parmar j. uszkoreit l. jones a. n. gomez .
kaiser and i. polosukhin attention is all you need in neurips pp.
.
a. radford k. narasimhan t. salimans and i. sutskever improving language understanding by generative pre training openai blog .
r. just d. jalali and m. d. ernst defects4j a database of existing faults to enable controlled testing studies for java programs in issta pp.
.
a. radford j. wu r. child d. luan d. amodei and i. sutskever language models are unsupervised multitask learners openai blog vol.
no.
p. .
j. yang a. zhikhartsev y .
liu and l. tan better test cases for better automated program repair in fse ser.
esec fse .
acm p. .
.
available .
m. tan l. tan s. dara and c. mayeux online defect prediction for imbalanced data in icse seip pp.
.
g. gousios and d. spinellis ghtorrent github s data from a firehose in msr .
ieee pp.
.
n. smith d. van bruggen and f. tomassetti javaparser visited .
.
available d. p. kingma and j. ba adam a method for stochastic optimization iniclr .
t. wolf l. debut v .
sanh j. chaumond c. delangue a. moi p. cistac t. rault r. louf m. funtowicz and j. brew huggingface s transformers state of the art natural language processing in emnlp .
m. ott s. edunov a. baevski a. fan s. gross n. ng d. grangier and m. auli fairseq a fast extensible toolkit for sequence modeling innaacl .
d. lin j. koppel a. chen and a. solar lezama quixbugs a multi lingual program repair benchmark set based on the quixey challenge in splash p. .
s. saha r. k. saha and m. r. prasad harnessing evolution for multihunk program repair in icse .
ieee pp.
.
z. qi f. long s. achour and m. rinard an analysis of patch plausibility and correctness for generate and validate patch generation systems in issta .
acm pp.
.
y .
yuan and w. banzhaf arja automated repair of java programs via multi objective genetic programming tse .
m. martinez and m. monperrus ultra large repair search space with automatically mined templates the cardumen mode of astor inicsbse .
springer .
t. durieux and m. monperrus dynamoth dynamic code synthesis for automatic program repair in ast pp.
.
k. liu a. koyuncu t. f. bissyand e d. kim j. klein and y .
le traon you cannot fix what you cannot find!
an investigation of fault localization bias in benchmarking automated program repair systems inicst .
ieee pp.
.
k. liu a. koyuncu d. kim and t. f. bissyand e a v atar fixing semantic bugs with fix patterns of static analysis violations in saner .
ieee pp.
.
a. koyuncu k. liu t. f. bissyand e d. kim j. klein m. monperrus and y .
le traon fixminer mining relevant fix patterns for automated program repair emse pp.
.
k. liu a. koyuncu k. kim d. kim and t. f. bissyand e lsrepair live search of fix ingredients for automated program repair in apsec pp.
.
k. liu s. wang a. koyuncu k. kim t. f. d. a. bissyande d. kim p. wu j. klein x. mao and y .
le traon on the efficiency of test suite based program repair a systematic assessment of automated repair systems for java programs in icse .
r. k. saha y .
lyu w. lam h. yoshida and m. r. prasad bugs.jar a large scale diverse dataset of real world java bugs in msr .
f. madeiral s. urli m. maia and m. monperrus bears an extensible java bug benchmark for automatic program repair studies in saner .
ieee pp.
.
e. dinella h. dai z. li m. naik l. song and k. wang hoppity learning graph transformations to detect and fix bugs in programs iniclr .
h. tian k. liu a. k. kabore e a. koyuncu l. li j. klein and t. f. bissyand e evaluating representation learning of code changes for predicting patch correctness in program repair in ase .
m. asad k. k. ganguly and k. sakib impact analysis of syntactic and semantic similarities on patch prioritization in automated program repair in icsme .
ieee pp.
.
g. sakkas m. endres b. cosman w. weimer and r. jhala type error feedback via analytic program repair in pldi pp.
.
a. ghanbari s. benton and l. zhang practical program repair via bytecode mutation in issta .
g. kavi e. c. peter c. xinyun and s. dawn synthesize execute and debug learning to repair for neural program synthesis in neurips h. larochelle m. ranzato r. hadsell m. balcan and h. lin eds.
.
x. gu h. zhang and s. kim deep code search in icse .
acm pp.
.
m. allamanis h. peng and c. sutton a convolutional attention network for extreme summarization of source code in icml pp.
.
m. white m. tufano c. vendome and d. poshyvanyk deep learning code fragments for code clone detection in ase.
acm pp.
.
l. li h. feng w. zhuang n. meng and b. ryder cclearner a deep learning based clone detection approach in icsme .
ieee pp.
.
j. li p. he j. zhu and m. r. lyu software defect prediction via convolutional neural network in qrs.
ieee .
j. wang and c. zhang software reliability prediction using a deep learning model based on the rnn encoder decoder ress .
l. fang l. ge z. yunfei and j. zhi multi task learning based pretrained language model for code completion in ase .
v .
murali l. qi s. chaudhuri and c. jermaine neural sketch learning for conditional program generation in iclr .
w. ling e. grefenstette k. m. hermann t. ko cisk y a. senior f. wang and p. blunsom latent predictor networks for code generation annual meeting of the acl .
m. white c. vendome m. linares v asquez and d. poshyvanyk toward deep learning software repositories in msr .
ieee pp.
.
v .
j. hellendoorn and p. devanbu are deep neural networks the best choice for modeling source code?
in esec fse .
acm .
m. allamanis e. t. barr p. devanbu and c. sutton a survey of machine learning for big code and naturalness csur vol.
no.
p. .
s. chakraborty y .
ding m. allamanis and b. ray codit code editing with tree based neural models tse .
u. alon m. zilberstein o. levy and e. yahav code2vec learning distributed representations of code acm on programming languages vol.
no.
popl pp.
.
u. alon s. brody o. levy and e. yahav code2seq generating sequences from structured representations of code in iclr .
j. henkel s. k. lahiri b. liblit and t. reps code vectors understanding programs through embedded abstracted symbolic traces in esec fse pp.
.
w. wang y .
zhang y .
sui y .
wan z. zhao j. wu p. yu and g. xu reinforcement learning guided source code summarization via hierarchical attention tse .
t. hoang h. j. kang d. lo and j. lawall cc2vec distributed representations of code changes in icse .
acm p. .
h. hu q. chen and z. liu code generation from supervised code embeddings in neurips .
springer pp.
.
k. wang and z. su blended precise semantic program embeddings inpldi .
new york ny usa acm p. .
w. wang gao and wang learning semantic program embeddings with graph interval neural network in oopsla .
acm .
j. keim a. kaplan a. koziolek and m. mirakhorli does bert understand code?
an exploratory study on the detection of architectural tactics in code in software architecture .
springer .
h. j. kang t. f. bissyand e and d. lo assessing the generalizability of code2vec token embeddings in ase.
ieee pp.
.
l. jiang h. liu and h. jiang machine learning based recommendation of method names how far are we in ase.
ieee pp.
.