automating developer chat mining shengyi pan lingfeng bao xiaoxue ren xin xia david lo shanping li college of computer science and technology zhejiang university china faculty of information technology monash university australia school of information systems singapore management university singapore shengyipan outlook.com lingfengbao xxren shan zju.edu.cn xin.xia monash.edu davidlo smu.edu.sg abstract online chatrooms are gaining popularity as a communication channel between widely distributed developers of open source software oss projects.
most discussion threads in chatrooms follow a q a format with some developers askers raising an initial question and others respondents joining in to provide answers.
these discussion threads are embedded withrich information that can satisfy the diverse needs of various ossstakeholders.
however retrieving information from threads ischallenging as it requires a thread level analysis to understand thecontext.
moreover the chat data is transient and unstructured consisting of entangled informal conversations.
in this paper weaddress this challenge by identifying the information types avail able in developer chats and further introducing an automatedmining technique.
through manual examination of chat datafrom three chatrooms on gitter using card sorting we builda thread level taxonomy with nine information categories andcreate a labeled dataset with threads.
we propose a classi fication approach named f2c ha t to structure the vast amount of threads based on the information type automatically helpingstakeholders quickly acquire their desired information.
f2c ha t effectively combines handcrafted non textual features with deeptextual features extracted by neural models.
specifically it hastwo stages with the first one leveraging the siamese architectureto pretrain the textual feature encoder and the second onefacilitating an in depth fusion of two types of features.
evaluationresults suggest that our approach achieves an average f1 scoreof .
which improves the baseline by .
experimentsalso verify the effectiveness of our identified non textual featuresunder both intra project and cross project validations.
index t erms developer chatrooms information mining deep learning gitter i. i ntroduction recent studies showed that online chatrooms are gaining popularity as a channel for global collaboration among developers of open source software oss projects and replacingthe traditional communication platforms including emails andmailing lists .
chatrooms like gitter slack anddiscord are modern instant messaging systems integratedwith diverse external services e.g.
bots issue linking mak ing developers easier to communicate and collaborate withothers .
developers use chatrooms to report problems shareopinions and discuss implementation details .
most discussion threads in developer chatrooms generally follow a q a format with some developers askers raising an initial question and others respondents later joiningin to provide answers.
previous studies have revealed also with pengcheng laboratory.
corresponding author.
a i m getting an error... a o.d.o.s.vectorizednonzerostoppingconjugategradient main c onjugategradient at iteration cost nan a surely nan isn t the kind of result i should be looking for?
wha t does revert back to ga mean?
r asorry just saw this didn t see the notification r do me a favor and type nd4j.enforce numerical stability true put this above your training.
r your weights are diverging report an encountered problem a hello if i saved network with modelserializer.writemodel can i t hen restore it and continue training?
is it done like this?
multilayer network net multilayernetwork modelserializer.restoremultilayernetwork file net.fit trainiter r yes don t forget restore updater r with boolean argument set to true a thank you ask for help about the use of an api a rhave you seen ples issues ?
weird behavior with sequencerecordreaderdata setiterator .
probably shouldn t have posted this issue under exampl es though.r a no i missed that.
mind moving it to dl4j issues?
a r how can i move issues?
or do i have to close and reopen?
r close and reopen collaborate on solving an issue1 fig.
example discussion threads with three different intents from deeplearning4j chatroom on gitter.
aand rrepresent the asker and the respondent respectively.
that these discussion threads are embedded with rich information which can be utilized to support various developmentactivities.
conversations in developer chatrooms are typicallyinformal with rapid exchanges of messages between two ormore participants and fewer constraints on discussion topics.compared with other communication channels e.g.
mailinglists and issue tracking systems its both types and amountof valuable information in chatrooms are much richer .
the needs to acquire information from discussions in chatrooms vary among different oss stakeholders based on theirtasks and interests.
for development teams they may want tobe aware of the problems reported by end users to deliver anearly fix to a bug.
they may also want to monitor the progressof tasks towards the resolutions of issues to facilitate better col laboration.
for end users they may care more about solutionsand opinions in previous discussions related to their problems.similar questions are usually repeated many times by thecommunity as the chat conversations are generally short lived quickly flooded away by the incoming messages.
figure 1illustrates that information embedded in discussion threads is 36th ieee acm international conference on automated software engineering ase 36th ieee acm international conference on automated software engineering ase .
ieee .
ase51524.
.
.
ieee capable of fulfilling the needs of various oss stakeholders.
hence a comprehensive analysis of information categoriesavailable in developer chats is of vital importance.
retrieving information from massive chat data requires a huge effort as some discussions could be very lengthy andhard to follow.
automated mining techniques are urgentlyneeded to collect various information embedded in massivechat data and categorize it properly helping oss stakeholdersdirectly retrieve their desired information from the well struc tured data.
however there are several hurdles that may preventan effective mining.
thread level analysis.
different from prior mining tasks focusing on sentence level classification thread is a natural granularity for mininginformation from developer chatrooms as the smallest unitcontaining comprehensive context information.
a sentence level analysis abandoning the context prevents an accurateinterpretation during classification and faces lots of short andincomplete sentences see examples in figure .
noisy data.
chatrooms have multiple participants who take part in different discussions at the same time thus disentanglingthreads from the stream of messages is critical for enablinga thread level analysis.
additionally informal conversationscontain many short and meaningless instant messages as wellas typos and special tokens e.g.
code snippet url whichgreatly affect the performance of text classification techniques.to the best of our knowledge the approach proposed in named frminer is the only one targeted towards mininginformation from developer chats at thread level.
however frminer is only focused on detecting one specific type ofdiscussion threads i.e.
threads with hidden feature requests to support the release team while ignoring other valuableinformation and different interests of other oss stakeholders.
the machine learning ml based mining techniques in previous studies typically rely on shallow textual features e.g.
tf idf bag of words non textual features e.g.
sentence length time gap or the combination ofboth features .
specially arya et al.
and wood et al.
reported that non textual features are more useful compared with the textual counterpart under certain circumstances.the deep learning dl based approaches in recent studies leverage advanced neural models to extract deeptextual features which are powerful representations with high level semantic information.
however we argue that the textualfeatures ignore other information of the discussion thread e.g.
structure participant .
thus the dl based approaches maystill benefit from the handcrafted non textual features in thisspecific task.
in this work we take the first step to analyze the information types available in discussion threads from developerchatrooms.
we aim to reveal the characteristics of informationtypes their primary intents and possible applications whichare essential for designing automated mining techniques tofulfill the needs of various oss stakeholders.
through manualexamination of historical chat data threads from threechatrooms on gitter using card sorting we build a thread level taxonomy with nine information categories.
further wepropose a classification approach namely f2c ha t which effectively combines handcrafted non textual features with deep textual features extracted by neural models.
specifically it has two stages with the first one leveraging the siamesearchitecture to pretrain the textual feature encoder and thesecond one facilitating an in depth fusion of two types offeatures.
we evaluate our approach on threads labeledusing the defined taxonomy.
the experimental results indicatethat our approach improves the performance of frminer by57 with an overall f1 score of .
.
the experiments alsoverify the effectiveness of our identified non textual featuresunder both intra project and cross project validations.
the contributions of our work are summarized as follows we are the first to build a thread level taxonomy ofinformation types for threads in developer chatrooms.
we propose an automated mining approach f2c ha t which combines handcrafted non textual features withdeep textual features extracted by neural models.
we conduct extensive experiments to evaluate f2c ha t on three chatrooms from gitter.
the experimental resultsindicate that our approach substantially outperforms fr miner and the identified non textual features are effectivein both intra project and cross project validations.
we open source our replication package and a datasetof discussion threads annotated with theidentified taxonomy of information categories.
ii.
rela ted work a. developer online chatrooms previous studies reported that online chatroom plays an increasingly important role in various development activities and tried to understand the way of developers using chat rooms by analyzing their behaviors and interactions.
shihabet al.
reported that there is a shift from mailinglists to developer internet relay chat irc meetings andfurther investigated the role of irc meetings using two opensource projects.
lin et al.
conducted an exploratory study to investigate the way of developers using slack.
their findingssuggested that slack is used for personal team wide andcommunity wide purposes and is gradually replacing theemails.
sahar et al.
assessed the impact of gitter on project and team dynamics.
they focused on issue report discussionsand found that they are closely related to activities in thegithub issue tracker.
ehasan et al.
conducted a study to understand the general q a behaviors of discussions in gitter.they are the first to propose an automatic approach for threadidentification in developer chatrooms and further explore thenature of discussions e.g.
topics by performing a thread levelanalysis.
these two works suggested that gitter chatrooms arerich sources for information related to the software.
other works focused on mining information from developer chats to support software development and maintenance.alkadhi et al.
conducted exploratory studies to examine the frequency and completeness of rationale hidden inchat messages.
they found that chat messages are a valuable 855source for rationale and the machine learning based algorithms are capable of automatically extracting rationale from ircmessages.
chatterjee et al.
pointed out that conversations in developer chatrooms generally follow a q a format andinvestigated the types amount and possible mining hurdlesof information in slack q a chats compared with stackoverflow q a posts.
they also emphasized the importanceof a thread level analysis and later released a dataset ofsoftware related conversations from slack with a customizeddisentanglement algorithm in .
recently shi et al.
designed a deep learning model to detect threads with hiddenfeature requests.
their experimental results on three osschatrooms from slack suggested that their method outperformsthe existing sentence level methods by a large margin.
most prior works are exploratory studies aiming to understand the role of chatrooms in supporting developers or inves tigate the validity of chatrooms as a mining source.
our workdiffers from these studies.
we take a step forward to performan in depth thread level analysis for identifying informationtypes available in developer chats on gitter.
additionally wedesign a classification approach and evaluate its effectivenessin detecting information types of discussion threads.
b. classification of software related artifacts in recent years an increasing number of studies have focused on mining information from software related artifacts by classifying them into categories relevant to various soft ware activities.
the automated mining techniques proposedby prior works can be generally categorized into three groupsaccording to the leveraged features textual features.
bacchelli et al.
represented lines of development emails as vectors of term frequencies tf and applied machine learning ml techniques to classify them into five categories nature language source code patch stack trace and junk based on the specific content.
however di sorbo et al.
and panichella et al.
argued that techniques based on lexicon analysis such as v ector space models e.g.
tf idf bag of words and topic models e.g.
lda would notbe sufficient as they failed to reveal the developers intents.to bridge the gap they applied heuristics to capture linguisticpatterns for the classification of sentences in emails andapp reviews based on developers purposes.
recently deep learning dl approaches have been introduced in thistask which automatically learn linguistic patterns and are morepowerful in extracting high level semantic information.
huanget al.
applied textcnn to classify sentences in both emails and itss.
their method substantially outperformeddi sorbo et al.
s heuristics and five ml based text classification techniques using v ector space model.
shi et al.
proposed a novel approach to enable a thread level analysis for detecting hidden feature requests from discussionson slack.
besides they are the first to incorporate few shot learning techniques to make the maximum use oflimited labeled data.
non textual features.
rastkar et al.
identified non textual features from four aspects structure participant length and lexicon and trained logisticregression lr classifiers for automatic summarization of bugreports.
similar non textual features were also utilized in to generate summaries for developer client conversations.
both textual and non textual features.
wood et al.
utilized bag of words as the textual feature together with threenon textual features to train lr classifiers for detection of26 speech act types in conversations during bug repair.
theyreported that non texture features are very useful for certainspeech act types.
arya et al.
leveraged several ml algorithms for classifying sentences in issues.
they applied tf idf weights as the textual feature and identified non textualfeatures.
they found that using non textual features alone iseven better than both features under intra project validation.the shallow textual features used in these two works onlycontain lexical information.
moreover the fusion of featuresis simple as inputting to the ml classifiers simultaneously.
our work differs from the existing studies.
to the best of our knowledge we are the first to combine handcrafted non textual features with deep textual features extracted by neuralmodels for classification of software related artifacts.
we alsopropose an architecture to facilitate an in depth fusion of twotypes of features.
furthermore while most of the prior worksperformed classification at the granularity of sentences wefocus on a thread level analysis of developer discussions.
iii.
a nalyzing informa tion ca tegories of discussion threads in this section we try to identify potential information types available in developer chats that may satisfy the diverse needsof various oss stakeholders.
we first introduce the four stepsused to collect chat data from gitter chatrooms.
then wedescribe the details of identifying information types.
a. data preparation step chatroom selection.
we select three chatrooms on gitter angular spring boot and deeplearning4j .
we choose these chatrooms for the following rea sons these chatrooms belong to three different categories.gitter divides all its chatrooms into categories e.g.
frontend android and data science.
choosing chatroomsof different categories strengthens the generalizability of ourwork by allowing us to investigate chat data of diversedevelopment topics.
large numbers of developers activelycommunicate with each other in these chatrooms.
we sort allthe chatrooms on gitter based on the number of participantssince it is one of the attributes supported by gitter api.we further exclude chatrooms with limited chat data lessthan messages by crawling and counting all of itshistorical messages.
finally we select the top three chatroomsunder the premise of belonging to different categories.
thecharacteristics of these chatrooms are presented in table i. step data crawling.
we crawl the historical chat data of the selected chatrooms using the official api provided by gitter.
we crawled data on august .
step thread disentanglement.
in chatrooms multiple developers participate in different threads at the same time.
856table i the characteristics of the selected chatrooms project categories participants messages time duration angular javascript .
.
spring boot java .
.
deeplearning4j data science .
.
two latest disentanglement algorithms targeted for technical discussions in developer chatrooms are .
chatterjeeet al.
modified elsner and charniak s algorithm for the customization of several slack specific features.
ehsan et al.
identified three categories of features i.e.
users content and back and forth communication through manual analysisof gitter chats and futher designed a heuristic based algorithm.we apply ehasan et al.
s algorithm to disentangle the distinct threads from the stream of messages since it was demonstratedto achieve satisfactory results on gitter chats with an f1 scoreof .
.
while chatterjee et al.
s algorithm still requires to be adapted to work well on chat platforms other than slack including gitter used in our study as suggested in .
step thread sampling.
we randomly sample threads from each chatroom and manually exclude low quality threads of the following characteristics threads that contain toomuch unformatted source code or stack traces.
threads withtoo many spelling and grammatical errors or written in non english languages.
the number of available threads for eachchatroom is shown in column thd of table iv.
b. building taxonomy of information types the sentence level information types have been widely studied in prior works regarding the classification of developmentcommunication artifacts .
but they are notapplicable to threads with multiple messages as they focuson the content of an individual sentence while abandoningthe context.
however we manage to utilize the knowledge intwo latest sentence level works arya et al.
identified information types e.g.
bug reproduction and solutiondiscussion for discussions in itss based on the underlyingpurposes of users.
we build our thread level taxonomy bysummarizing their sentence level information types.
woodet al.
uncovered speech act types e.g.
documentation answer and api question in conversations during bug repairbased on the specific discussed development contents.
theirwork inspires us to build a taxonomy from the aspect of dis cussion contents.
di sorbo et al.
and panichella et al.
reported that taxonomies in related works are generally definedfrom two aspects text contents or developers purposes.
besides we follow the card sorting process to identify the information types of discussion threads which has beenproven effective in previous works e.g.
identifying intentionsof sentences in its .
we created one card for each sampledthread.
the first two authors worked together to determine thelabel of each card.
the whole process has two iterations iteration .
we first used of the cards.
the two authors coded each thread individually to identify possiblecategories at thread level.
they first read all messages in thethread and identified information type for each one using thetaxonomy described in .
then they summarized potentialcommonalities of the sentence level information types andinferred the underlying purpose of the discussion.
after that they focused on the specific development contents discussedin the thread.
finally they worked together to discuss thefindings and disagreements.
in this iteration we built a two level taxonomy table ii along with a handbook to guideclassification based on the following findings level we summarize three intents of developer discussions by leveraging the sentence level information types in .
problem report.
askers mostly the project end users report bugs or describe unexpected behaviors by providing source code full stack traces or specifying what they havetried to do.
respondents try to help askers find the cause oftheir problems guide them in the right direction or sharepossible solutions.
see circlecopyrtin figure for an example.
information retrieval.
askers mostly the project endusers attempt to obtain information or help from the com munity about api usage library installation documentationresources etc.
usually askers describe what they want toaccomplish and try to get some help before they dive intothe specific development.
respondents share opinions aboutthe best practice or provide suggestions of implementationdetails.
see circlecopyrtin figure for an example.
project management.
although most discussion threads in developer chatrooms are initiated with end users askingquestions about the use of the software team membersand certain users potential contributors also collaboratethrough online chatting to solve issues filed on github.
forexample working together to identify causes and solutions discussing the testing procedure and results and requestingor reporting the progress of tasks.
besides the team alsoannounce the release of a new version and answer questionsregarding the future roadmap of the software evolution inonline chatrooms.
see circlecopyrtin figure for an example.
level the specific development contents discussed in online chatrooms can be categorized into nine classes as shown incolumn level of table ii.
we find the development contents discussed in chatrooms are generally consistent with thoseidentified by in chat conversations during bug repair.however we add a sub class general information under information retrieval since there are some social discussionsthat are not closely related to the project itself e.g.
the bestchoice of ide job hunting experience and the design ofdeep learning models.
besides we divide project management into two sub classes task progress.
the development team and end users request or report task progresses inquire orinform release plans and discuss future roadmap.
technical discussion.
discussions of this class focus more on technical parts where participants collaborate to find the cause of issues analyze the testing results and seek possible solutions.
iteration .
two authors independently labeled the remaining cards into nine categories listed in table ii.
we usecohen s kappa coefficient to measure the agreementbetween two authors.
their kappa value for nine categories 857table ii the built taxonomy of information categories for developer discussion threads level description level description problem reportasker report bugs or describe unexpected behaviors.
respondent help the asker find the cause of the problem and provide possible solutions.programming problem pp problems related to programming e.g.
syntax parameter api and implementation library problem lp problems related to library installation deploymentand configuration documentation problem dp problems related to documentation resources e.g.
examples guidance and docs information retrievalasker try to obtain information or help from the community regarding some development issues.respondent share opinions about the best practice or suggestions of implementation details.programming information pi information related to programming e.g.
syntax parameter api and implementation library information li information related to library installation deployment and configuration documentation information di information related to documentation resources e.g.
examples guidance and docs general information gi information related to general knowledge e.g.
jobhunting experience and choices of ides project managementend user request the progress of certain issues or the release schedule of the project.team collaborate on solving issues and inform community about future plans.technical discussion td technical discussions during collaboration onsolving issues e.g.
finding causes and solutions task progress tp communications on task progresses releaseschedules and future plans fig.
distribution of the percentage of each information type in the sampled discussion threads of level is .
which is lower than the one .
for three categories of level .
both kappa values indicate a substantialagreement between the two authors.
for cards with disagree ments two authors discussed to reach a common decision andfurther refined the guidance handbook for classification.
after two iterations of card sorting we labeled discussion threads from three chatrooms on gitter.
the annotation isextremely expensive with a cost of person hours.
the dis tribution of each information type is shown in figure .
over80 of the discussion threads in all three chatrooms belongto the category problem report orinformation retrieval and majority of them are related to programming e.g.
api syntaxand parameter .
it indicates that developers mainly use onlinechatrooms to seek solutions or answers for their problems.
iv .
a utoma ted classifica tion of informa tion ca tegories in this section we first describe the detailed process for preprocessing the chat messages.
then we build a two stagemodel figure namely f2c ha t for automated classification of information categories.a.
preprocessing of chat messages messages in developer chatrooms are noisy for text classification algorithms as described in section i .
a throughoutdata preprocessing is critical for automated techniques toachieve satisfactory performances.
in this work we take thefollowing steps to preprocess the raw chat messages fine grained special tokens replacement.
the development chat messages contain lots of special tokens such as source code url and issue id.
to clean the sentences we replace these tokens with specific tags e.g.
codetag urltag and issuetag using regular expressions.
this step is widely adopted in the related works .however we argue that the replacements in previousstudies are not precise enough.
specifically special tokensshould be replaced based on the specific artifacts containedrather than their forms.
for example a url can linkto an issue on github a page of the official docs etc.these differences should not be ignored i.e.
we shouldnot replace all urls with a single tag.
moreover the sameartifact is referred to using different forms e.g.
an issuecan be referred to using its id or a direct url link .this diversity e.g.
replacing issues with different tags can confuse the model.
we perform a fine grained specialtokens replacement leveraging the knowledge from manualexamination of chat data.
merge consecutive messages from the same devel oper.
unlike the well structured discussion threads in issue tracking systems developer chats are generally informalconversations with lots of quick and incomplete messages.while some developers prefer to comprehensively describehis problems and thoughts within a single long message circlecopyrt circlecopyrtin figure others may prefer a series of short messages instead circlecopyrtin figure .
this inconsistency caused by the personal habits of different developers will bring 858troubles when we calculate certain non textual features e.g.
number of messages within a thread or model themessage sequence.
we merge consecutive messages fromthe same developer to eliminate this inconsistency.
b. pretraining of textual feature encoder we separate the training of encoders for two types of features figure due to the following concerns textualfeatures and non textual features have different data types i.e.
high dimensional sparse vectors vs. numerical values tableiii training two encoders one for each type of features simultaneously let alone a unified encoder is not the bestpractice.
textual features are encoded by deep neural mod els with large amounts of parameters thus few shot learningtechniques are needed to overcome the overfitting problem.it is not the case for non textual features since they areencoded using a two layer feed forward module.
recastinga classification task into similarity measurement will causeinformation loss .
share weightsdistance measure feed forwardp p softmax a siamese architecture for pretraining the textual encodermessage sequencenon textual features frozen trainable textual embeddingnon textual embeddingfeed forward trainable softmax b architecture for combining two types of features fig.
two stage model architecture of f2c ha t the first stage of our proposed two stage classification approach focuses on pretraining the textual feature encoder.
we refer to the model at this stage as f2c ha t t since it only leverages textual features.
given the fact that the annotationis extremely expensive section iii b we follow the methodsproposed by shi et al.
to alleviate the overfitting problem caused by the insufficient data.
by incorporating siamesenetwork a metric based few shot learning technique they recast the traditional text classification task of classifyinga single thread to the correct class into the task of determiningwhether a pair of threads belong to the same class or not.the siamese architecture for pretraining the textual encoder isshown in figure a .
a pair of threads either from the sameclass or different classes are sent into two identical encoders same structure and parameters separately to get the textualfeature embeddings e encoder text t .
the embeddings eaand ebare then used to measure the distance between two threads in the latent space.
specifically we follow themetric in to use a two layer fully connected feed forwardnetwork for distance measurement with the concatenation oftwo embeddings e ab ea circleplustextebas the input.
finally the distance embeddings are sent to a two unit softmax layer to ...lstm cell... ......... ... ...max pooling ... lstm celllstm celllstm celllstm celllstm cell bert bert bert fig.
the detailed structure of textual feature encoder get the normalized score indicating whether the two threads belong to the same class or not.
the detailed architecture of encoder text is presented in figure which contains following two modules message encoding module.
we first encode each message in the thread circlecopyrtin figure .
we utilize bert one of the state of the art pretrained models ptms to extract the textual representation for each message.
compared with thetraditional context free word embeddings e.g.
glov e bert aims to learn contextual word embeddings i.e.
theembedding of a word changes dynamically based on thecontext where it appears from large unlabeled corpora thussubstantially boosting the performance of multiple natural lan guage processing nlp tasks .
besides applying bert indownstream tasks follows a simple fine tuning process whichprevents us from diving into the design of sophisticated modelarchitectures and introduces minimal task specific parameters which is important considering only a small dataset is availablein our task.
according to we use the embedding of a special token in bert which is added in front of every input sample as the representation of the whole messagefor our classification task.
bert uses a subword tokenizer thatavoids the out of vocabulary oov problem by decomposingoov words into known subwords.
however it does notapply to the technical terms in developer communications.hence we add several domain specific terms e.g.
maven npm and stackblitz to the original bert vocabulary based on frequency.
the embeddings for these terms will be optimizedduring fine tuning.
thread encoding module.
we then model the contextual information of the entire thread from a sequence of message embeddings circlecopyrtin figure as the semantic logic is a crucial pattern for thread level classification.
bidirectional long shortterm memory network bi lstm is utilized to capturethe bidirectional contextual information for this sequencelearning task which stacks two standard lstm layers witheach one responsible for learning one direction representation.
we concatenate the outputs of bi lstm h in each time step and further utilize a max pooling layer to get the final embedding of the thread.
859table iii list of non textual features type feature1description aspect2 lengthtoken a length of thread first message messages from the asker number of tokens t f a token r length of first message messages from the asker divided by thread length number of tokens f a character a length of thread first message messages from the asker number of characters t f a character r length of first message messages from the asker divided by thread length number of characters f a structuraltimegap a thread duration gap between the first and second message time t f timegapmean a mean of all gaps in the thread time t timegapstd a standard deviation of all gaps in the thread time t timegap r gap between the first and second message divided by thread duration time f messgap a thread duration gap between the first and second message number of messages t f messgapmean a mean of all gaps in the thread number of messages t messgapstd a standard deviation of all gaps in the thread number of messages t messgap r gap between the first and second message divided by thread duration number of messages f mess a number of messages within the thread from the asker t a mess r number of messages from the asker divided by total number of messages in the thread a participant participant a number of participants involved in the thread t special tokenquestionmark a number of question marks in the first message f greeting a number of greeting words e.g.
hello hey and hi in the first message f code a number of code snippts in thread first message messages from the asker t f a error a number of stack traces in thread first message messages from the asker t f a doc a number of documentations mentioned in thread first message messages from the asker t f a issue a number of issues mentioned in thread first message messages from the asker t f a 1footnote aandrdenote the features with absolute value ranged in and the features with relative value ranged in respectively.
2t fand adenote the aspects of whole thread first message and the asker respectively.
c. incorporating non textual features the second stage of f2c ha t focuses on the training of nontextual feature encoder and the combination of both textual and non textual features.
we first introduce the identifiednon textual features and then describe the details of modelarchitecture for stage two.
handcrafted non textual features.
the non textual features used in are generally based on the features first proposed by murray and carenini .
however thesefeatures are targeted for classification at the granularity ofsentence thus they need to be adapted and further enrichedfor our thread level algorithm.
inspired by the sentence levelfeatures we identify features table iii which can becategorized into four groups length features refer to the features measured by absolute or relative w.r.t.
the entire thread length in either tokenlevel or character level.
rationale threads of problem report are generally longer as the askers need to elaborate the details of the encountered problems while expressingthe needs of certain information in threads of information retrieval is relatively straightforward.
structural features refer to the features that are related to the structure of a thread e.g.
the time interval betweenfirst and last message of the thread i.e.
the duration ofthe discussion .
we also measure through the number ofintermediate messages since the time interval can be easilyaffected by external factors e.g.
the activeness of thechatroom which is different with respect to the specifictime period .
rationale threads of problem report usually have more messages and longer lasting time sincesolving a problem usually requires an in depth discussionto figure out the causes and takes time to verify the validityof potential solutions.
participant feature is the number of participants involved in the thread.
rationale although most of the discussionsare between two participants i.e.
the asker and one respon dent more respondents will participate when the reportedbugs are tricky problem report or a team collaboration is required project management .
special token features refer to the features measured by the number of special tokens e.g.
code snippets stacktraces and urls .
rationale some special tokens are strong indicators of certain information categories e.g.
stack traces for programming problem and urls linking to official docs for documentation information.
furthermore these features are measured from three different aspects column aspect in table iii features related to the whole thread.
these features characterize the thread as a whole.
features related to the first message.
the first message is important as it usually indicates thepurposes and requirements of the thread initiator asker .
forexample a large relative length of the first message w.r.t.
theentire thread suggests that the thread is most likely to belongtoproblem report since the asker needs to fully elaborate the encountered problems.
features related to the asker.
these features characterize the behaviour of the asker in thediscussion thread.
by extracting features from this aspect we want to emphasize the differences between the two roles asker and respondent of the participants.
for example if alarge portion of code snippets in the discussion thread areprovided by the asker then it is a strong indicator of problem report.
however this may not be the case if provided by therespondents since respondents in the threads of information retrieval sometimes need to share the implementation details while the askers just simply express their needs.
combining both textual and non textual features.
figure b presents the model architecture for combining the two types of features in stage two.
unlike the textual counterpart non textual features are numerical values table iii that canbe directly computed.
there is no need for a complex en860coder with a large number of parameters or few shot learning techniques.
we use a fully connected feed forward networkwith one hidden layer to encode the non textual featurese nontext encoder nontext t while the embedding of the textual features is extracted using the pretrained encoder fromstage one figure e text encoder text t .
we set an extremely small learning rate 1e for parameters in thepretrained textual feature encoder since we want to avoidcollapsing the well trained encoder while slightly fine tuneit to accommodate the newly added non textual features.considering that some patterns require an in depth integrationof both textual and non textual features we perform an earlyfusion at the feature level instead of a late fusion at thedecision level.
we concatenate the embeddings of textual andnon textual features as the final representation of the threade e text circleplustextenontext and then use it for decision making instead of making two decisions using textual and non textualfeatures respectively and then fuse them to get the finaldecision.
we use a feed forward network for decision making.finally a softmax layer is utilized to get the normalized scoreof each information type for this multi class classification task.
v. e xperiment design r esults a. experiment settings we use the dataset built in section iii for evaluation.
the detailed statistics presented in table iv include the numberof sampled threads thd the median of the thread lastingtime dur the average number of participants per thread pcp the average number of messages per thread msg and the average number of tokens per message msglen .the experimental environment is a server equipped with annvidia v100 gpu intel xeon platinum cpu 16gbram running ubuntu os.
table iv the detailed statistics of the dataset proj thd dur min pcp msg msglen angular .
.
.
.
.
spring boot .
.
.
.
.
deeplearning4j .
.
.
.
.
denotes the statistics after merging consecutive messages from the same developer.
testing scenarios.
the evaluations are performed under the following two scenarios five fold cross validation for intra project scenario.
in this scenario annotated threads from chatrooms of the testing projects are partially available in the training set meaning the model can gain knowledge of the testingproject during the training.
we conduct a stratified five fold cross validation for each chatroom in this testing sce nario.
specifically threads are divided into five folds usingstratified random sampling with each fold preserving theoriginal distribution of information types.
every time weuse four folds to train the model and the remaining one fortesting.
the process is repeated five times to alleviate therandomness and we report the average evaluation results.
leave one project out cross validation for cross projectscenario.
this scenario simulates the situation when users want to apply the trained algorithm to a new chatroom which requires the learned knowledge of the model to begeneralizable as the testing project is previously unseenduring the training.
we use a leave one project out strategy i.e.
two projects are used as the source projects to train the model and the remaining one as the target project for testing.
we iterate the process three times and report theaverage evaluation results.
implementation details.
we use the pretrained bert small model from huggingface transformer library dueto the limited computation resources.
it produces a dimensional embedding to represent each input message.
theoutput dimension of bi lstm is for each .
fur ther through a non linear projection header we get a dimensional embedding for the textual features of the thread.non textual features are normalized before encoding.
thedimension of the non textual feature embedding is the same asthe textual counterpart.
the final representation of the threadin stage two i.e.
the concatenation of embeddings of twotypes of features is a dimensional embedding.
we usecross entropy as the loss function in the two stages.
to avoid the over fitting problem we apply dropout to the outputs of every fully connected layer with the drop rateset to .
.
we use adamw as the optimizer for modeltraining in both two stages.
in stage one we set the learningrate lr to 1e except for the pretrained bert module whoselr is set to 2e as suggested in .
specially the pairsof threads used for training are sampled from the datasetin a ratio of negative pairs two threads with differentclasses to the positive ones two threads with the same class which is considered as an optimal ratio for training siamesenetworks .
in stage two we set lr to 1e for fine tuning thepretrained textual feature encoder and 1e for other modules.besides we adjust class weights in the loss function to tacklethe unbalanced dataset problem figure .
evaluation metrics.
we use the following metrics to evaluate the performance of f2c ha t precision.
precision for class ciis the ratio of the number of threads that are correctly classified as cito the total number of predictions made for ci.
recall.
recall for class ciis the ratio of number of threads that are correctly classified as cito the total number of threads that belong to ciin the ground truth.
f1 score.
f1 score for class ciis the harmonic mean of its precision and recall.
the above three metrics evaluate the performance for a specific category.
for the evaluation of the overall performance wecalculate the average f1 score of all classes weighted by support i.e.
the number of threads of each class in the testset.
these metrics are widely adopted in the previous studiesthat involve classification of software artifacts .
b. research questions our evaluation explores the following research questions rq1 does our approach work well in the intra project scenario?
we follow the five fold cross validation described 861in section v a to evaluate the performance of our approach in the intra project scenario.
we use frminer proposed byshi et al.
as our baseline.
to the best of our knowledge frminer is the only one targeted for thread level classificationof developer communication artifacts.
the experimental resultssuggest that frminer substantially outperforms two advancedsentence level approaches and four general textclassification approaches .
furthermore f2c ha t t stage one of our approach uses the same siamese architectureas in their work to pretrain the textual feature encoder.
hence we only consider frminer for performance comparisons withour approach in the experiments.
however frminer is de signed to identify one certain type of discussion threads indeveloper chatrooms i.e.
threads with hidden feature requests.to enable a comparison we adapt it to our task by modifyingthe number of output units in the last classification layers andretraining on our dataset using the same settings in .
rq2 does our approach work well in the cross project scenario?
to evaluate the performance of our approach in the cross project scenario we follow the leave one project out cross validation described in section v a. we also usefrminer as our baseline for this rq.
rq3 how does our approach benefit from the handcrafted non textual features?
we investigate whether our identified non textual features help.
to do so we compare theperformance of f2c ha t t and f2c ha t leverages two types of features in both intra project and cross project scenarios.
table v the performance comparisons between our approach and frminer for each chatroom in intra project setting metric approachchatroom avg.angular spring boot deeplearning4j precisionfrminer .
.
.
.
f2c ha t t .
.
.
.
f2c ha t .
.
.
.
recallfrminer .
.
.
.
f2c ha t t .
.
.
.
f2c ha t .
.
.
.
f1 scorefrminer .
.
.
.
f2c ha t t .
.
.
.
f2c ha t .
.
.
.
c. experiment results rq1 performance in intra project validation.
the performance comparisons for each chatroom under the intraproject setting are shown in table v. here the precision recall and f1 score are averages of all information categoriesweighted by support.
the best results are highlighted in bold.
f2c ha t t improves the performance of frminer w.r.t.
f1score by .
.
and .
for each of the threechatrooms respectively.
considering both approaches usingonly textual features and sharing the same siamese architec ture the performance improvement verifies the effectiveness of1 better preprocessing of chat messages section iv a and2 introducing bert for sentence modeling section iv b .although f2c ha t t has already achieved satisfactory results by leveraging deep textual features f2c ha t further booststable vi the average performance of f2c ha t across three chatrooms for each information type in intra project setting information category precision recall f1 score support programming problem pp .
.
.
library problem lp .
.
.
documentation problem dp .
.
.
75programming information pi .
.
.
145library information li .
.
.
documentation information di .
.
.
176general information gi .
.
.
technical discussion td .
.
.
117task progress tp .
.
.
weighted avg.
.
.
.
the performances in all three chatrooms with an average of .
.
and .
in precision recall and f1 score.
the average performance achieved by f2c ha t across all three chatrooms for each information category is shown intable vi.
generally f2c ha t achieves better performance on information categories with larger support.
the best perfor mance is on programming information with an average f1score of .
.
for categories where f2c ha t performs poorly it is mainly due to the limited data samples thus failingto capture effective patterns.
the performance comparisonsfor each information category are shown in table vii.
here the results are averaged across all three chatrooms.
the bestresults are highlighted in bold.
through manual checking ofspecific testing samples we find that compared with fr miner f2c ha t t can better distinguish between programming problem and programming information as well as library problem and library information.
it benefits from fine grained special tokens replacement section iv a .
since source codeand stack trace embedded in the message text share thesame format both of them are considered as code snippets replacing them with the same tag will confuse the learning based model.
besides by incorporating non textual features f2c ha t further improves the performance on almost every information category.
table vii the performance comparisons for each information type in intra project setting metric approachinformation category pp lp dp pi li di gi td tp precisionfrminer .
.
.
.
.
.
.
.
.
f2c ha t t .
.
.
.
.
.
.
.
.
f2c ha t .
.
.
.
.
.
.
.
.
re callfrminer .
.
.
.
.
.
.
.
.
f2c ha t t .
.
.
.
.
.
.
.
.
f2c ha t .
.
.
.
.
.
.
.
.
f1 scorefrminer .
.
.
.
.
.
.
.
.
f2c ha t t .
.
.
.
.
.
.
.
.
f2c ha t .
.
.
.
.
.
.
.
.
rq2 performance in cross project validation.
the performance comparisons for each chatroom under the cross project setting are listed in table viii.
here the chatroom refers to theone selected as the target project section v a .
in general the findings are similar to those in the intra project setting.
f2c ha t t surpasses the frminer and f2c ha t further boosts the performance.
compared with the results in the intra project 862table viii the performance comparisons for each chatroom in cross project setting metric approachchatroom avg.angular spring boot deeplearning4j precisionfrminer .
.
.
.
f2c ha t t .
.
.
.
f2c ha t .
.
.
.
recallfrminer .
.
.
.
f2c ha t t .
.
.
.
f2c ha t .
.
.
.
f1 scorefrminer .
.
.
.
f2c ha t t .
.
.
.
f2c ha t .
.
.
.
validation table v the performance of f2c ha t declines on all three chatrooms by .
over the average f1 score.however the performance changes of frminer vary acrossdifferent chatrooms.
we observe an improvement on angular and spring boot while a decline for deeplearning4j.
the improvement is mainly due to a larger training set.
in the cross project setting all threads from two chatrooms leave one project out cross validation are available for training whilein the intra project setting only of threads from asingle chatroom five fold cross validation are available.
thehuge decline on deeplearning4j is because it is a library for supporting deep learning algorithms but the other two projects angular spring boot are related to web development thus making the linguistic patterns learned during the training hardto generalize on the testing set.
table ix the performance comparisons for each information type in cross project setting metric approachinformation category pp lp dp pi li di gi td tp precisionfrminer .
.
.
.
.
.
.
.
.
f2c ha t t .
.
.
.
.
.
.
.
.
f2c ha t .
.
.
.
.
.
.
.
.
re callfrminer .
.
.
.
.
.
.
.
.
f2c ha t t .
.
.
.
.
.
.
.
.
f2c ha t .
.
.
.
.
.
.
.
.
f1 scorefrminer .
.
.
.
.
.
.
.
.
f2c ha t t .
.
.
.
.
.
.
.
.
f2c ha t .
.
.
.
.
.
.
.
.
the average performance achieved by frminer and our approach across the three chatrooms for each information category is shown in table ix.
the results further verify theeffectiveness of f2c ha t under the cross project setting as it outperforms the frminer on every information category.compared with the results under the intra project setting table vi larger declines are observed on information typeswith smaller support.
besides we find the performance ofboth frminer and f2c ha t t on programming problem and library problem are close to or even better than the results in intra project validation.
this suggests that threads of thesetwo categories share the most similar linguistic patterns thatare irrelevant to project specific concepts.
rq3 effectiveness of handcrafted non textual features.
to evaluate the effectiveness of our identified non textual fea tures we focus on the comparison of f2c ha t with f2c ha t t in this rq.
first we discuss the effectiveness of handcraftednon textual features under the intra project setting.
as shownin table v by incorporating non textual features f2c ha t outperforms f2c ha t t in all three chatrooms indicating our identified features table iii can supplement the textualcounterpart with effective information e.g.
thread structure discussion participants .
besides we observe that non textualfeatures are more powerful when the performances are poorerusing only textual features.
f2c ha t improves the f1 score of f2c ha t t by .
for deeplearning4j while only .
for angular.
regarding specific information categories nontextual features are more effective on certain types table vii .this indicates that non textual features such as the durationof the thread number of participants and number of specialtokens e.g.
url issue are strong indicators of informationcategories including library problem documentation information and task progress.
while for general information and technical discussion adding non textual features does nothelp or even decreases the performance.
this suggests thatthreads of these categories vary a lot in lengths structures and discussion contents.
second we discuss the effectiveness of handcrafted nontextual features under the cross project setting.
the resultspresented in table viii suggest that our identified non textualfeatures are generalizable across different projects improv ing the average f1 score by .
in cross project settingcompared with .
under intra project setting table v .when investigating the generalizability of non textual featureson specific information categories we observe that they aremore generalizable on documentation information and task progress table ix .
although the performance on these categories using only textual features is relatively poorer aswe discussed in the last paragraph that this could be the causefor larger improvements it reveals that discussions of thesecategories share the most similar structures and formats evenin different projects and communities.
vi.
d iscussion effectiveness of two stage model design.
we discuss the motivations for separating the training process of textualand non textual feature encoders in section iv b. here weconduct an ablation study to further verify the effectivenessof our two stage model design.
we replace the encoder text in figure a into the architecture in figure b withoutthe last classification layers the feed forward module and thesoftmax layer and refer this model as f2c ha t s. f2c ha t s simultaneously train both encoders for textual and non textualfeatures using the siamese architecture.
we compare its per formance against f2c ha t t and f2c ha t under intra project scenario.
f2c ha t t shares the same siamese architecture but it only leverages textual features.
f2c ha t utilizes two types of features but it separates the training processes.
the averageperformances of each model across three chatrooms are shownin table x. the performances of f2c ha t s and f2c ha t t are close while f2c ha t significantly surpasses both two models.
863table x the performance comparisons in ablation study precision recall f1 score f2c ha t s .
.
.
f2c ha t t .
.
.
f2c ha t .
.
.
effectiveness of incorporating hand crafted non textual features.
although the deep textual features are powerful in presenting the semantic information we argue that theyonly focus on the linguistic aspect while neglecting otherinformation of the discussion thread e.g.
structure partic ipant .
moreover the textual features do not consider thedifferences brought by the speaker s identity i.e.
the asker andrespondents .
based on the observations from manual analysisof the data we discuss that these kinds of information cancontribute to the prediction of information categories sectioniv c .
hence we supply f2c ha t with handcrafted nontextual features to bridge the information gap.
figure showsexamples to illustrate the effectiveness of non textual features.
a number of tokens length c number of participants participant d number of code snip pets special token b time duration structural fig.
distributions of four non textual features one fromeach type of different information types in angular chatroom vii.
t hrea ts to validity there are two major threats to the validity of this work.
the generalizability of the identified information categoriesand the proposed mining technique.
we only sample 959threads from three active chatrooms on gitter due to the hugecost of manual analysis of developer discussion threads.
toensure the diversity of the sampled data we select chatroomswith several principals section iii a e.g.
most actively usedand belonging to different categories.
however the project specific characteristics of the selected chatrooms might affectthe generalizability of our identified information categoriesand the performance of the proposed automated mining tech nique.
specifically in the preprocessing of chat messages section iv a we argue that the special tokens should be re placed based on the specific artifacts contained instead of theirforms.
we notice that developer communications includinginstant chats discussions in its etc.
typically involve varioussoftware artifacts e.g.
code snippets issue reports and stacktraces .
these artifacts are closely related to the discussion top ics and are embedded in the text using diverse forms.
hence we argue that the core idea of fine grained special tokensreplacement is applicable to other mining sources of developercommunications.
however the detailed implementations andeffectiveness may vary across different sources.
the qualityof the dataset used for evaluation.
we build a larger dataset threads than the prior work which has only1 threads and focuses on one specific information type.we leverage the state of the art method proposed by ehsanet al.
to disentangle the stream of messages to threads.however the disentangled threads may contain more or fewermessages confusing the thread level classification techniques.moreover the ground truth labels of the threads are manuallyannotated which may subject to the personal experience ofthe annotators.
two annotators work collaboratively followinga card sorting process to eliminate this inconsistency.
viii.
c onclusion and future work in this paper we conduct an in depth analysis to identify the information categories available in discussion threads thatmay satisfy the diverse needs of various oss stakeholders.first we build a thread level taxonomy with nine informationcategories through manual examination of threads fromthree chatrooms on gitter.
second we propose an automatedclassification technique namely f2c ha t which combines handcrafted non textual features with deep textual featuresextracted by neural models.
evaluation results suggest that f2c ha t outperforms frminer by with an average f1score of .
.
our approach also achieves considerable per formance in cross project validation which indicates f2c ha t can extract patterns that are generalizable across variousprojects.
the experiment results also verify the effectivenessof our indentified non textual features under both intra projectand cross project validation.
in future work we plan to refineour taxonomy by exploring discussions from more chatrooms.we also plan to develop a tool for gitter chatrooms to supportthe daily development tasks of oss stakeholders by providingwell structured and categorized historical chat data.
ix.
a cknowledgments this research project is supported by the national science foundation of china no.
u20a20173 and no.
key research and development program of zhejiang province no.2021c01014 and national research foundation sin gapore under its industry alignment fund pre positioning iaf pp funding initiative.
any opinions findings and con clusions or recommendations expressed in this material arethose of the author s and do not reflect the views of nationalresearch foundation singapore.
864references b. lin a. zagalsky m. a. storey and a. serebrenik why developers are slacking off understanding how software teams use slack in proceedings of the 19th acm conference on computer supportedcooperative work and social computing companion pp.
.
m. a. storey l. singer b. cleary f. figueira filho and a. zagalsky the r evolution of social media in software engineering in future of software engineering proceedings pp.
.
v .
k afer d. graziotin i. bogicevic s. wagner and j. ramadani communication in open source projects end of the e mail era?
in proceedings of the 40th international conference on software engineering companion proceeedings pp.
.
gitter.
.
available slack.
.
available discord.
.
available h. sahar a. hindle and c. p .
bezemer how are issue reports discussed in gitter chat rooms?
journal of systems and software vol.
p. .
o. ehsan s. hassan m. e. mezouar and y .
zou an empirical study of developer discussions in the gitter platform acm transactions on software engineering and methodology tosem vol.
no.
pp.
.
p .
chatterjee k. damevski l. pollock v .
augustine and n. a. kraft exploratory study of slack q a chats as a mining source for softwareengineering tools in ieee acm 16th international conference on mining software repositories msr .
ieee pp.
.
r. alkadhi t. lata e. guzmany and b. bruegge rationale in development chat messages an exploratory study in ieee acm 14th international conference on mining software repositories msr .ieee pp.
.
r. alkadhi m. nonnenmacher e. guzman and b. bruegge how do developers discuss rationale?
in ieee 25th international conference on software analysis evolution and reengineering saner .ieee pp.
.
l. shi m. xing m. li y .
wang s. li and q. wang detection of hidden feature requests from massive chat messages via deep siamesenetwork in ieee acm 42nd international conference on software engineering icse .
ieee pp.
.
d. arya w. wang j. l. guo and j. cheng analysis and detection of information types of open source software issue discussions in2019 ieee acm 41st international conference on software engineering icse .
ieee pp.
.
a. di sorbo s. panichella c. a. visaggio m. di penta g. canfora and h. c. gall development emails content analyzer intention miningin developer discussions t in 30th ieee acm international conference on automated software engineering ase .
ieee pp.
.
s. panichella a. di sorbo e. guzman c. a. visaggio g. canfora and h. c. gall how can i improve my app?
classifying user reviewsfor software maintenance and evolution in ieee international conference on software maintenance and evolution icsme .
ieee pp.
.
a. bacchelli t. dal sasso m. d ambros and m. lanza content classification of development emails in 34th international conference on software engineering icse .
ieee pp.
.
n. chen j. lin s. c. hoi x. xiao and b. zhang ar miner mining informative reviews for developers from mobile app marketplace inproceedings of the 36th international conference on software engineer ing pp.
.
s. rastkar g. c. murphy and g. murray summarizing software artifacts a case study of bug reports in acm ieee 32nd international conference on software engineering vol.
.
ieee pp.
.
p .
rodeghero s. jiang a. armaly and c. mcmillan detecting user story information in developer client conversations to generate extractivesummaries in ieee acm 39th international conference on software engineering icse .
ieee pp.
.
a. wood p .
rodeghero a. armaly and c. mcmillan detecting speech act types in developer question answer conversations during bug repair inproceedings of the 26th acm joint meeting on european software engineering conference and symposium on the f oundations of software engineering pp.
.
q. huang x. xia d. lo and g. c. murphy automating intention mining ieee transactions on software engineering .
our replication package.
.
available panshengyi f2chat e. shihab z. m. jiang and a. e. hassan studying the use of developer irc meetings in open source projects in ieee international conference on software maintenance.
ieee pp.
.
on the use of internet relay chat irc meetings by developers of the gnome gtk project in 6th ieee international working conference on mining software repositories.
ieee pp.
.
p .
chatterjee k. damevski n. a. kraft and l. pollock softwarerelated slack chats with disentangled conversations in proceedings of the 17th international conference on mining software repositories pp.
.
r. baeza yates b. ribeiro neto et al.
modern information retrieval .
acm press new y ork vol.
.
y .
kim convolutional neural networks for sentence classification inproceedings of the conference on empirical methods in natural language processing emnlp .
doha qatar associationfor computational linguistics oct. pp.
.
.available y .
wang q. yao j. t. kwok and l. m. ni generalizing from a few examples a survey on few shot learning acm computing surveys csur vol.
no.
pp.
.
angular chatroom on gitter.
.
available angular angular spring boot chatroom on gitter.
.
available spring projects spring boot deeplearning4j chatroom on gitter.
.
available https gitter.im eclipse deeplearning4j gitter explore page.
.
available gitter developer page.
.
available m. elsner and e. charniak y ou talking to me?
a corpus and algorithm for conversation disentanglement in proceedings of acl hlt pp.
.
d. spencer card sorting designing usable categories.
rosenfeld media .
j. cohen a coefficient of agreement for nominal scales educational and psychological measurement vol.
no.
pp.
.
t. chen s. kornblith m. norouzi and g. hinton a simple framework for contrastive learning of visual representations in international conference on machine learning.
pmlr pp.
.
j. bromley i. guyon y .
lecun e. s ackinger and r. shah signature verification using a siamese time delay neural network advances in neural information processing systems pp.
.
j. devlin m. w. chang k. lee and k. toutanova bert pre training of deep bidirectional transformers for language understanding arxiv preprint arxiv .
.
j. pennington r. socher and c. d. manning glove global vectors for word representation in proceedings of the conference on empirical methods in natural language processing emnlp pp.
.
x. qiu t. sun y .
xu y .
shao n. dai and x. huang pre trained models for natural language processing a survey science china technological sciences pp.
.
a. graves a. r. mohamed and g. hinton speech recognition with deep recurrent neural networks in ieee international conference on acoustics speech and signal processing.
ieee pp.
.
s. rastkar g. c. murphy and g. murray automatic summarization of bug reports ieee transactions on software engineering vol.
no.
pp.
.
g. murray and g. carenini summarizing spoken and written conversations in proceedings of the conference on empirical methods in natural language processing pp.
.
i. turc m. w. chang k. lee and k. toutanova well read students learn better on the importance of pre training compact models arxiv preprint arxiv .08962v2 .
bert small on huggingface.
.
available co google bert uncased l h a n. srivastava g. hinton a. krizhevsky i. sutskever and r. salakhutdinov dropout a simple way to prevent neural networks from over fitting the journal of machine learning research vol.
no.
pp.
.
i. loshchilov and f. hutter decoupled weight decay regularization arxiv preprint arxiv .
.
p .
neculoiu m. v ersteegh and m. rotaru learning text similarity with siamese recurrent networks in proceedings of the 1st workshop on representation learning for nlp pp.
.
l. shi c. chen q. wang s. li and b. boehm understanding feature requests by leveraging fuzzy method and linguistic analysis in 32nd ieee acm international conference on automated softwareengineering ase .
ieee pp.
.
a. mccallum k. nigam et al.
a comparison of event models for naive bayes text classification in aaai workshop on learning fortext categorization vol.
no.
.
citeseer pp.
.
a. liaw m. wiener et al.
classification and regression by randomforest rn e w s vol.
no.
pp.
.
g. ke q. meng t. finley t. wang w. chen w. ma q. ye and t. y .
liu lightgbm a highly efficient gradient boosting decision tree advances in neural information processing systems vol.
pp.
.
a. joulin e. grave p .
bojanowski m. douze h. j egou and t. mikolov fasttext.
zip compressing text classification models arxiv preprint arxiv .
.