an empirical study of deep transfer learning based program repair for kotlin projects misoo kim institute of software convergence sungkyunkwan university suwon korea misoo12 skku.eduyoungkyoung kim department of electrical and computer engineering sungkyunkwan university suwon korea agnes66 skku.eduhohyeon jeong department of electrical and computer engineering sungkyunkwan university suwon korea jeonghh89 skku.edu jinseok heo department of electrical and computer engineering sungkyunkwan university suwon korea mrhjs225 skku.edusungoh kim s w engineering group mobile experience samsung electronics suwon korea sungoh5.kim samsung.comhyunhee chung s w engineering group mobile experience samsung electronics suwon korea milou samsung.com eunseok lee college of computing and informatics sungkyunkwan university suwon korea leees skku.edu abstract deep learning based automated program repair dl apr can automatically fix software bugs and has received significant attention in the industry because of its potential to significantly reduce software development and maintenance costs.
the samsung mobile experience mx team is currently switching from java to kotlin projects.
this study reviews the application of dl apr which automatically fixes defects that arise during this switching process however the shortage of kotlin defect fixing datasets in samsung mx team precludes us from fully utilizing the power of deep learning.
therefore strategies are needed to effectively reuse the pretrained dl apr model.
this demand can be met using the kotlin defect fixing datasets constructed from industrial and open source repositories and transfer learning.
this study aims to validate the performance of the pretrained dl apr model in fixing defects in the samsung kotlin projects then improve its performance by applying transfer learning.
we show that transfer learning with open source and industrial kotlin defect fixing datasets can improve the defect fixing performance of these authors contributed equally to this work.
corresponding author permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse november singapore singapore association for computing machinery.
acm isbn .
.
.
.
existing dl apr by .
furthermore we confirmed that the performance was improved by compared with the baseline dl apr model as a result of transferring the knowledge of an industrial non defect bug fixing dataset.
we also discovered that the embedded vectors and overlapping code tokens of the codechange pairs are valuable features for selecting useful knowledge transfer instances by improving the performance of apr models by up to .
our study demonstrates the possibility of applying transfer learning to practitioners who review the application of dl apr to industrial software.
ccs concepts software and its engineering maintaining software .
keywords empirical study deep learning based program repair transfer learning industrial kotlin project sonarqube defects acm reference format misoo kim youngkyoung kim hohyeon jeong jinseok heo sungoh kim hyunhee chung and eunseok lee.
.
an empirical study of deep transfer learning based program repair for kotlin projects.
in proceedings of the 30th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november singapore singapore.
acm new york ny usa pages.
introduction automatic program repair apr is a technique that automatically fixes software bugs and defects and can save significant software debugging time and costs depending on its accuracy .
the esec fse november singapore singapore misoo kim youngkyoung kim hohyeon jeong jinseok heo sungoh kim hyunhee chung and eunseok lee interest in apr is growing substantially owing to its potential to automate software debugging tasks that directly impact cost and revenue in the industry .
apr performance is generally evaluated by the number of bugs or defects it fixes i.e.
the number of bugs or defects for which it generates plausible patches and how accurately fixed i.e.
the number of patches that are same as developer patches using benchmarks constructed from opensource software oss projects.
apr techniques can be mainly classified into template based and deep learning based approaches both of which utilize past bug patch code pairs.
the template based approach is limited by the availability of predefined templates for fixing both bugs and defects.
recently deep learning based apr dl apr techniques that do not require predefined templates have been studied .
currently the samsung mobile experience mx team is switching from java based projects to kotlin based projects in alignment with the trend shown by global it companies .
we also strive to replace java with kotlin as our primary application development programming language.
accordingly we must reduce the burden of the debugging for kotlin defects that arise during the switching process.
simultaneously the application of dl apr is considered a suitable strategy for the effective utilization of large amounts of data e.g.
defect patch code pairs that will continuously accumulate over time.
in this context we aim to apply dl apr to fix the defects that occur in our industrial kotlin projects .
although facebook meta has proposed an apr technique focusing on specific bugs and has evaluated its performance for applications only a few studies have evaluated the performance of dl apr applied to industrial software.
furthermore many dl apr techniques have been validated in open source software developed in java c python and javascript however there have been no reports of the application of dl apr on the kotlin defects.
since it is not possible to perfectly predict the performance of the current dl apr techniques applied to the kotlin projects of the mx team we must first validate the dl apr performance on our kotlin defects.
the previously released dl apr code and a pretrained model can be reused to validate the performance of the dl apr model by either training from scratch with the kotlin defect fixing dataset by reusing previously released dl apr codes or using the pretrained dl apr model.
however as we are currently transforming kotlin projects from java projects kotlin defect patch code pairs are insufficient for the first approach.
approximately defectfixing code pairs are available from our industrial kotlin projects however they are insufficient for learning compared to the to millions bug fixing pair datasets used in existing dl apr studies .
the lack of sufficient training data thus indicates that the second approach is better in the current stage.
the criteria for choosing the dl apr model to reuse to achieve our goal are determined by whether the technique is state ofthe art sota all code and data are public and their problem domain is identical to ours.
the best model for our purpose is tfix which generates patches for coding errors i.e.
defects detected from a static analysis tool sat .
more importantly alike we defined defects as faults detected through rules of the static analysis tool.
we target all kotlin applications including android applicationsour purposes tfix aims to solve the defects detected by a sat therefore tfix is the sota dl apr model that best meets our criteria.
for effective reuse of tfix two critical issues must be considered.
the first is the difference between the target language kotlin and the trained language javascript .
the tfix model is trained to fix javascript defects however we intend to patch kotlin defects.
the second issue is the difference in defect types between the trained and target datasets.
tfix uses eslint but we aim to fix the defects detected by sonarqube .
the differences in programming languages and defect types between the training and target datasets make it difficult to guarantee the performance of tfix on our kotlin defects.
transfer learning can alleviate these problems.
the kotlin defectfixing dataset collected by sonarqube s defect detection rules in industrial and open kotlin software contains sufficient knowledge to fix sonarqube s defects detected in the kotlin projects.
transfer learning by tuning the tfix model with this dataset can transform tfix s ability from fixing javascript defects to fixing kotlin defects.
furthermore a better performance is expected if we can utilize an additional industrial dataset e.g.
the kotlin bug fixing dataset to supplement the domain knowledge of industrial projects and general kotlin defect fixing patterns.
this study aims to effectively apply dl apr to industrial kotlin projects.
we validate the performance of tfix in fixing the defects in the samsung kotlin projects then improve its performance utilizing defect and bug fixing datasets and transfer learning.
to this end we establish and answer three research questions a rq1.a.
how many industrial defects can be fixed by existing dl apr?
the tfix model can fix out of industrial defects.
b rq1.b.
are defect fixing datasets and transfer learning effective in improving dl apr performance?
the tfix model tuned with industrial and oss defect fixing datasets can correctly fix more defects than the tfix model establishing the fact that transfer learning is effective in improving the dl apr performance.
rq2.
can an industrial bug fixing dataset transfer useful knowledge to improve the dl apr for defect fixing?
the model with additional transfers performed using the industrial bug fixing dataset fixed more defects than the model transferred using only defect fixing knowledge.
the contributions of this study are as follows.
this study is the first to validate dl apr s performance in fixing kotlin defects.
we show that dl apr can correct kotlin defects using the state of the art technique tfix.
to the best of our knowledge this study is the first to apply tfix to an industrial software project.
because apr studies in the context of industrial defects are insufficient our results are valuable.
we demonstrate the effectiveness of transfer learning using industrial datasets for practitioners reviewing the application of dl apr in the field.
in this study bugs and defects are distinguished.
the bug is a fault that causes unexpected behavior in software.
the defect is defined as faults detected through a sat.
1442an empirical study of deep transfer learning based program repair for kotlin projects esec fse november singapore singapore our experiments with oss and industrial kotlin defects and industrial kotlin bugs showed that the dl apr accuracy can be improved by up to with the implementation of transfer learning.
when transferring additional knowledge we analyzed two aspects of the industrial kotlin bug fixing dataset embedding vectors and code ingredients.
in particular code tokenbased instance selection was able to fix more defects compared to the initial dl apr.
the analysis results suggest an effective industrial bug fixing instance selection direction when applying the dl apr and transfer learning.
problem context and motivation .
java and kotlin projects at samsung since google announced in that android development will become increasingly dominated by kotlin there has been a trend to switch java projects to kotlin .
given kotlin s valuable characteristics such as rapid compilation small code chunks the safety of the null pointer exception and its compatibility with java there have been increased attempts to switch existing projects from java to kotlin .
this has been an inexorable trend even in the it industry.
in google many java projects have already been converted to kotlin or are in the process of conversion .
the samsung mx team is also working on this transformation.
we investigated the commits from january to january of industrial kotlin projects and found that the number of modified kotlin files exceeded of the total monthly modified java and kotlin files.
this trend is illustrated in figure .
figure the trend of switching from java to kotlin y axis accumulated ratio of committed files according to this trend the kotlin codes will increase in industrial projects in the future inevitably increasing debugging costs.
considering these circumstances this study intends to validate the performance of the dl apr in industrial kotlin projects.
.
software development with static analysis tools at samsung mx team the mx team applies a sat in three steps to improve software quality within the software development process.
the first is the development environment for individual developers within the team where a sat is applied as a plugin to each developer s local integrated development environment and developers fix the defectsdetected by the sat.
samsung mx team uses sonarqube a sat used by our company and other companies worldwide with which many studies have been conducted .
the second step is a continuous integration pipeline e.g.
github circleci and jenkins .
when the source code written by the developers of the team is committed the sat in the pipeline detects defects in the code.
a defect report is used to evaluate the code quality of the software development team.
team leaders may triage the defect report to developers for fixing defects detected by the sat.
the third step is the quality evaluation of final software products prior to market release in which the development team decides whether they will fix every defect detected by the sat.
in this study we aim to apply dl apr to fix the defects detected by sonarqube in the first step.
when defects in the first step result in unaddressed debt higher costs are incurred in the second and third steps respectively.
.
target dl apr tfix tfix is a dl apr technique that generates patches for coding errors defects in our study detected by sats by utilizing the text totext transfer transformer t5 a powerful model that can generalize various text to text natural language processing tasks .
the authors proposed a transfer between natural and programming languages and multiple defect types to adapt the t5 model for fixing software defects.
to achieve this they built a defect fixing dataset with defect patch code pairs detected by eslint a javascript sat and then tuned the t5 model with this dataset to train an apr model by applying transfer learning.
the tfix approach can be applied to any defect written in any language and detected by any sat.
sat defect reports indicate that this approach generates four pieces of textual information pertaining to each defect defect type defect message defect line and defect context and uses these to train the dl apr model from the t5 model.
figure shows an example of a defect patch code pair and tfix s corresponding input template.
figure an example of instance generation of tfix strings with token sequences in the defect code and defect reports were matched with the input data by matching the metadata provided by the input templates see the input template and input rows in figure .
the output of tfix is the code context in which the defect is fixed as illustrated by the output row in figure .
the code printed in blue represents the fixed code line.
this input output pair is used as a single instance for transfer learning from the t5 model to the apr model.
1443esec fse november singapore singapore misoo kim youngkyoung kim hohyeon jeong jinseok heo sungoh kim hyunhee chung and eunseok lee experimental setting .
research questions we establish three research questions rqs the first validates the performance of the dl apr applied to our industrial kotlin projects rq1.a and confirms the performance improvement through transfer learning with a kotlin defect fixing dataset rq1.b .
the second analyzes whether implementing an additional industrial dataset e.g.
a bug fixing dataset can be effective for additional transfer learning using the defect fixing model.
a rq1.a.
how many industrial defects can be fixed by existing dl apr?
b rq1.b.
are defect fixing datasets and transfer learning effective in improving dl apr performance?
rq2.
can an industrial bug fixing dataset transfer useful knowledge to improve the dl apr for defect fixing?
figure summarizes the input datasets and models used to answer the rqs.
the datasets are collected through the process described in section .
.
.
the detailed methods for answering the rqs are described in sections and .
figure inputs for answering research questions .
experimental dataset .
.
construction process.
figure presents an overview of dataset construction process for our experiment.
first we selected projects developed in kotlin from our industrial software repository and kotlin oss projects from github using seart .
the selection criteria for oss projects were ten or more stars the existence of one or more issues and the date of the latest commit should be after january .
oss projects were selected on april .
second buggy commits were collected to build a bug fixing dataset based on a search for keywords among all the commits in the selected projects.
a commit was considered to be buggy when the commit message contained the bug related keywords but did not contain the anti keywords .
we filtered out commits that had more than one parent commit to avoid collecting duplicated instances .
since our research goal is kotlin defect fixing the bug patch code pairs are collected only from kotlin source files.
we converted the set of bug patch code pairs from the selected commits into tfix training instances as described in section .
.
for the bugfixing dataset the defect type and message of bug patch code pairs required for the tfix input could not be identified because thesebugs were not detected by a sat therefore we left the metadata string blank.
third we used sonarqube to mine the defect fixing dataset from the bug fixing dataset.
after performing static analysis we compared the defect list with each kotlin source file before and after modification and checked whether the detected defects no longer appeared in the modified patch code.
ossd and indd defect fixing code pairs were collected from the oss and industrial kotlin projects respectively as tuning instances for tfix.
sonarqube returns the rule id e.g.
s100 whereas eslint returns the defect type e.g.
no extra semi which is used as the input of tfix.
accordingly the rule id was used as the defect type to construct the input for tfix.
the bug fixing dataset collected in the second phase includes a defect fixing dataset.
we excluded defect fixing code pairs from the bug fixing dataset because some ground truth instances of the defect fixing code pairs could be trained when tuning with the bug fixing dataset in the experiment for rq2.
consequently we selected bug fixing code pairs indb as the tuning dataset for rq2.
.
.
dataset statistics.
table is a statistics of dataset obtained from the oss and industrial kotlin projects.
among the kotlin defect detection rules provided by sonarqube by default rules detected defects in the oss dataset and rules detected defects in the industrial dataset.
these defects were classified as code smell bug pilcrow or security hotspot hot classes and their severity was classified as critical major minor info or blocker.
our experimental dataset consists of defects with various detection rules types and severities.
although there was a difference between ossdandinddin the number of defect instances for each detection rule the instance distribution in dominant defect rules s1128 s1135 s1481 and s1172 were similar potentially implying that the oss defect fixing dataset can complement the industrial defect fixing dataset.
.
evaluation metrics accurate correctness evaluation of generated patches is difficult without human review because of the patch plausibility problem .
we used exact match em a strict metric to measure patch correctness.
em is the number of defects for which a dl apr can generate developer patches.
a prediction is considered correct only if the fixed code perfectly matches the developer s fixed code.
based on the em the defect fixing ratio fr is computed by exactmatch defects.
.
the tfix model and tuning details .
.
pretrained defect fixing model.
we used the tfix base model published by the authors as the initial pretrained defect fixing dlapr model.
the authors provided pretrained small base and large tfix models with parameters of million million and million respectively whose frs are .
.
and .
respectively.
the large model showed the highest accuracy but its performance improvement over the base model was marginal approximately .
despite the three fold more parameters therefore we chose a scalable base model rather than a large model.
pilcrowthis bug simply means one of the classes provided by sonarqube.
1444an empirical study of deep transfer learning based program repair for kotlin projects esec fse november singapore singapore figure an overview of dataset construction process table experimental defect dataset class defect information defects projects class ruleid severity oss industrial smell s1128 minor s1135 info s1481 minor s1172 major s1874 minor s1192 critical s117 minor s1134 major s100 minor s1186 critical s101 minor s108 major s3776 critical s1144 major s1940 minor s1125 minor s107 major s4144 major s1066 major s1133 info s4663 minor s6318 minor s1110 major bug s1764 major s1656 major s1763 major s1862 major s1145 major s3923 major hot s2245 critical s1313 minor s2068 blocker total rules types .
.
tuning process.
we used two tuning datasets the kotlin defect fixing dataset collected from oss projects ossd and the kotlin defect fixing dataset collected from industrial projects indd .
since we expected inddto contribute more to industrial defectfixing thanossd we first tuned with ossdthen tunedinddfor knowledge transfer.
.
.
tuning testing dataset.
we used of ossdfor tuning and for validation.
as we wanted to verify the ability to fix industrial defects we did not use ossdfor testing.
we performed stratifiedk fold cross validation to prevent erroneous experiments when tuning with inddbecause the tuning and test instances could be identical .
as shown in table the rule ids with the fewest instances were s1144 ands1862 and there were three such instances.
we set kto to ensure both tuning and testing of the defect patch code pairs detected by these rules.
in summary out of of the indd was used for training tuning and for validation while the remaining is used for testing.
this testing was repeated three times to show performance for all defects.
.
.
environments.
we fine tuned the tfix model on three gpus nvidia tesla v100s with 200gb ram.
tuning with ossdand inddtook and minutes on average per fold respectively.
rq1.
effectiveness of dl apr and transfer learning .
method to confirm the validity of tfix and effectiveness of transfer learning we evaluated and compared the em and fr of patches generated using the following models t the original tfix model to the t model fine tuned with ossd ti the t model fine tuned with indd toi the to model fine tuned with indd the test is performed with the entire inddin the case of t and to models as mentioned in section .
.
in the case of the ti and toi models inddis divided fold for tuning and evaluation.
.
results the experimental results are summarized in table .
the answers to the research questions in this chapter are based on this table.
.
.
rq1.a.
performance of dl apr.
although tfix is a model trained with javascript defects detected by eslint the t model was able to generate correct patches for .
of defects all of which corresponded to code smells.
the correctly patched defects were those detected using rules s1128 s1172 s1481 s1134 and s1135 which could only be 1445esec fse november singapore singapore misoo kim youngkyoung kim hohyeon jeong jinseok heo sungoh kim hyunhee chung and eunseok lee table exact match and fixing ratio of tfix variations bold the highest value class ruleid all t to ti toi smells1128 .
.
.
.
s1135 .
.
.
.
s1172 .
.
.
.
s1481 .
.
.
.
s1192 .
.
.
.
s117 .
.
.
.
s1134 .
.
.
.
s1874 .
.
.
.
s108 .
.
.
.
s3776 .
.
.
.
s1125 .
.
.
.
s1186 .
.
.
.
s1144 .
.
.
.
bugs1656 .
.
.
.
s1764 .
.
.
.
s1862 .
.
.
.
sum .
.
.
.
resolved by removing the existing code.
the defects corresponding to rules s1128 s1172 and s1481 could be fixed by deleting unused import statements function parameters andlocal variables respectively and were similar to no unused vars a defect type already learned by tfix.
attempts at fixing defects using the t5 model were unsuccessful zero correct patch .
considering that .
of defects could be correctly fixed by tfix tfix can be seen as a more effective apr model than t5 for kotlin defect fixing.
our experimental results showed that knowledge of javascript defect fixing patterns already learned by the tfix model could be used to fix kotlin defects.
therefore although the tfix model is trained on a different defect dataset with a different language and sat than our target defects for patch generation it can be used as a baseline model from the perspective of apr which is the same domain.
answer to rq1.a.
tfix generated correct patches for .
code smell defects from industrial kotlin defects.
finding .
even if the dl apr model is trained with defects detected in a language and sat different from those of the target defects to be patched a pretrained dl apr model is more effective in fixing defects than a model from a completely different domain.
.
.
rq1.b.
effectiveness of transfer learning.
the performance rankings of the four models were toi ti to and t .
.
and .
respectively .
a total of .
defects were corrected by the toi model with transferred knowledge from both ossdandindd so the toi model fixed more defects than the t model.
the to and ti models generated patches for and more defects respectively compared to the t model indicating that transfer learning can improve apr performance by generating more correct patches than by using tfix alone.
performance of the to model the to model fixed defects including the same defect types detected by rules s1128 s1172 s1481 s1134 ands1135 for which the t model succeeded in generating a patch.
in addition the to model fixed four more code smell defects detected by rules s108 s117 s1186 and s3776 which the t model could not fix.
these results show that finetuning the model with ossdcan transfer defect fixing knowledge i.e.
the ability to fix the defects detected by rules s108 s117 s1186 ands3776 which lack in the tfix model to the existing apr model.
therefore fine tuning the base dl apr model with the oss defect fixing dataset raises the chance to fix these defects.
performance of the ti model the ti model generated correct patches for defects detected by the five common types of rules fixed by the t model further fixing four more types of code smell defects that the t model could not fix.
similar to why ossdwas effective in transfer learning the reason for showing these results is because the defect fixing knowledge that could not be learned from javascript defects was in indd.
therefore inddcan also help transfer knowledge of kotlin defects to apr.
comparison between the to and ti models the to model could fix defects detected by rule s1186 whereas the ti model could not.inddhad only defect instances detected by rule s1186 .
this capability seems to have been fixed in the to model because defects detected by s1186 were lacking in indd.
on the other hand the ti model could resolve defects detected by s1874 which could not be fixed by either t or to.
the rule s1874 detects a defect that uses deprecated code e.g.
a function variable etc.
which can be resolved by replacing the deprecated code with other code.
in other words tuned dl apr could fix this defect when the pair of token ato be replaced and token bwhich must be replaced both existed in the tuning dataset.
since these ingredient codes such as function and variable names depend highly on the software project the industrial dataset can obviously be much more effective in detecting them than the oss dataset.
as in the example above some defects are highly dependent on the ingredient codes that implicitly contain industrial domain knowledge even though indd is quantitatively smaller than ossd it is bound to contain better information for fixing industrial defects.
performance of the toi model the toi model contains knowledge of both ossdandindd.
since the advantages of the to and ti models over the t model mentioned above are combined in the toi model this model was able to correct most defects.
toi was able to create patches for .
of the total defects and correct out of types of defects.
the toi model was able to fix the defects detected by all the rules that the t to and ti models could fix and the toi model was able to fix the same number or more defects for each type.
furthermore the toi model fixed defects detected by the rule s1192 which the other models could not.
subsequently the improvement rate is computed bynewem previousem previousem 1446an empirical study of deep transfer learning based program repair for kotlin projects esec fse november singapore singapore defects detected by the rule s1192 are critical code smells which can cause code maintenance problems because they repeatedly use a duplicate string.
we expect that a patch pattern that can correct this defect could be learned by accumulating knowledge from both ossdandindd.
comparing the results of verifying the effects of transfer learning by different datasets the toi model can generate patches for and more defects than the to and ti models respectively.
answer to rq1.b.
the models transferred from the oss and industrial defectfixing datasets were able to solve and more defects than the tfix model respectively and more defects were resolved when the knowledge of both datasets was transferred.
therefore transfer learning with oss and industrial defect fixing datasets is effective for industrial defect fixing apr.
finding .
the fine tuned model using oss and industrial defectfixing datasets fixed the most defects and the most rules.
in particular this model corrected new defect rules that could not be corrected by the apr model tuned using the respective datasets.
5rq2.
impact of bug fixing datasets on transfer learning .
method we confirmed that the toi model surpassed the others in fixing industrial kotlin defects.
in addition we confirmed that the ti model s industrial domain knowledge e.g.
ingredient codes could improve apr performance by providing knowledge that cannot be obtained from oss.
this finding implies that the industrial dataset contributes more to patch generation than the oss dataset.
if we obtain and train an extra dataset that can supplement the knowledge of industrial projects while maintaining knowledge to fix defects from the company s accumulated dataset we can expect a higher performance of dl apr.
the industrial bug fixing dataset is a feasible complementary dataset that can provide knowledge such as variable names within the industrial code.
in addition bug fixing is similar to defect fixing in terms of modifying the source code to a better code .
avatar showed that sat defect fixing patterns could contribute to general semantic bug fixing expecting that the reverse is also possible.
accordingly we must investigate whether an industrial kotlin bug fixing dataset can be used as a complementary dataset for kotlin defect fixing with transfer learning.
to determine the effectiveness of the industrial bug fixing dataset indb comprising bug fixing instances described in section .
.
as a transfer learning dataset for defect fixing apr we built the tobi model by tuning the to model using indbprior to tuning withindd.
.
results the tobi column of table shows the experimental results answering rq2.
table exact match of tuning dataset variations bold higher than toi gray box the highest value tobi clustering codetoken type ruleid all toidefaultbalance real replace select s1128 s1135 s1172 s1481 s1192 s117 s1134 s1874 s108 s3776 s1125 s1186 0smell s1144 s1656 s1764 bug s1862 sum first we compared the performance of the toi model tuned only with the defect fixing dataset and then the tobi model was further tuned with the bug fixing dataset.
as a result of the experiment shown in table tobi fixed a total of defects more than that of the toi model.
the tobi model can resolve the defects detected by all rules that the toi can fix except for rule s1186 see the section .
.
the number of fixed defects was also greater or equal.
furthermore the tobi model can fix new types of defects including bug type defects detected by rule s1764 and code smell defects detected by rule s1125 .
these results confirm that the industrial bug fixing dataset effectively transfers knowledge of fixing industrial defects even though it is not a defect fixing dataset.
the defects detected by the rule s1125 which can be newly fixed use duplicate boolean literals e.g.
!true andtrue is true .
these defects damage source code readability and consequently can make maintenance difficult.
they can be fixed by replacing or deleting boolean literals e.g.
false andtrue .
considering the number of possible changes many defect fixing change pairs are required but only and defect instances are in ossdandindd respectively.
the defect detected by rule s1764 is a bug type that could not be fixed in the model trained with the defect fixing dataset.
this defect occurs when the expressions on both sides of the binary operator are the same e.g.
a a where one of the expressions must be changed.
there are and such defect instances in ossd andindd respectively.
in other words defects detected by rules such as s1125 ands1764 had quantitative problems in ossdand inddleading to a lack of knowledge about which ingredient codes to generate the patch.
however the bug fixing dataset contains knowledge which can supplement these defects.
in particular the defects detected by rule s1764 which is a bug class in sonarqube are expected to have a similar patch pattern in the bug fixing dataset which can be regarded as a similar context.
1447esec fse november singapore singapore misoo kim youngkyoung kim hohyeon jeong jinseok heo sungoh kim hyunhee chung and eunseok lee answer to rq2 when the additional transfer is performed with indbthe model can fix more defects than the model transferred only with defect fixing knowledge confirming that the industrial bug fixing dataset can transfer useful knowledge to fix industrial defects.
.
discussion .
.
context.
since two datasets inddandindb are not for exact same task not all instances of indbare helpful.
if we can check which instances of indbcan be used as effective transfer learning instances for apr we can more effectively utilize the many bug fixing datasets accumulated in industrial projects.
to investigate effective instances for kotlin defect fixing we generate and compare variations of indbfor tuning the pretrained dl apr model.
for the variation of indb we establish two assumptions for the instance selection method.
the key to assumptions is that the datasets similar to indd our target industrial defect fixing dataset are more effective transfer learning data .
word embedding vector based selection.
indbreconstructed similar to the distribution of inddbased on the word embedding vector is effective for transfer learning.
code token based selection.
indbhaving code tokens of inddis effective for transfer learning.
we established the following method to analyze the above assumptions our experiment was performed as a fold validation as in the previous experimental setting.
this prevents observation of the defect fixing test dataset in the instance selection phase.
the comparison between distributions of inddandindbis also performed with instances of indd.
.
.
embedding vector based instance selection.
clustering is a method used to check the distribution of features in a dataset .
we converted the text of each instance in inddandindb into word embedding vectors performed clustering based on the vectors of instances of inddto build a clustering model checked the distributions of the number of instances per cluster ofindd and inferred the cluster of indbinstances using the clustering model.
the distribution of the number of instances per cluster ofinddis regarded as distribution of the industrial defectfixing dataset.
we reconstructed indbaccording to the distribution ofindd.
for each instance of both inddandindb defect code and patch code are transformed into embedding vectors with the embedding layer of the toi model.
then the vectors of defect code and patch code are concatenated to represent a single instance.
next to build the clustering model we used the x means clustering of the open source library pycluster .
the advantage of x means clustering is that it automatically determines the optimal number of clusters .
with embedding vectors of indd extracted in the above step instances are classified into xclusters with a x means clustering algorithm.
here the clusters and the number of instances in each cluster serve as indicators to check the distribution of the entire vector dataset.we can determine the closest cluster of a new instance using its distance to the centroid of each cluster.
to reconstruct a tuning datasetindbhaving a similar distribution with indd the cluster closest to each instance of indbis inferred as the instance s cluster.
based on the inferred cluster of instances of indb we compare the performance of the two models below to check whether the tuning data with similar distribution of inddis effective for transferring knowledge.
tobi balance instances from indbare selected so that each cluster has an equal number of instances regardless of the distribution of indd.
tobi real instances from indbare selected according to the cluster specific instance distribution of indd.
results.
the clustering column in table summarizes the experimental results.
tobi real which is similar to the distribution of the embedding vector of indd fixed defects.
this model can fix more defects than simply trained tobi and tobi balance with uniform distribution.
tobi balance corrected defects a performance confirmed to be worse than that of either tobi or tobi real.
therefore we demonstrated that the bug fixing dataset similar to the embedding vector distribution in inddis more effective data for tuning the defect apr model on average.
table lists the results for each fold.
table comparison on cluster based instance selection fold clusters model type indb distribution ratio em fr toi .
tobi .
tobi balance .
tobi real .
toi .
tobi .
tobi balance .
tobi real .
toi .
tobi .
tobi balance .
tobi real .
there were and clusters for each fold.
for each fold the distribution column distribution ratio shown in the original tobi is different from the toi.
in other words fitting the distribution to the toi named tobi real shows better performance than the original tobi and tobi balance on average.
ten clusters were built in the first fold and the minimum and maximum ratios of the instances for each cluster were and respectively.
in the first fold tobi real fixed more defects than tobi despite having fewer instances vs. .
in contrast the tobi balance fixes fewer defects.
tobi real fixed five fewer defects than tobi in the second fold but eight more than tobi in the third fold.
although the results were different for each fold selecting instances from indbbased on the embedding vectors distribution effectively generates a tuning dataset which can increase em while reducing computation cost of training.
1448an empirical study of deep transfer learning based program repair for kotlin projects esec fse november singapore singapore finding .
the procured industrial bug fixing dataset regarding the distribution of the embedding vector can improve the defect fixing model.
.
.
code token based instance selection.
an ingredient code token is a piece of code required to create a patch of the apr and defect code s tokens provide the defect context.
the absence of these code tokens in the training and tuning datasets leads to the out of vocabulary problem referred to in deep learning which significantly reduces the performance of the dl apr model .
the tuning dataset indbcontaining code tokens from the industrial kotlin defect dataset inddmay show better patch generation performance.
to verify this we evaluate the performance of a variation ofindbgenerated with the tokens in indd.
first to select code tokens from indd we selected instances pure source code without comments strings or annotations tokenized the codes with nltk tokenizer and selected only tokens beginning in english.
to validate our assumption we compared the performance of the two models described below to check whether the tuning dataset containing code tokens from inddwas suitable for knowledge transfer.
tobi replace instances where indb s tokens not in indd are replaced with similar tokens in indd tobi select instances from indbhaving the code tokens ofindd for the tobi replacement model we replaced the code tokens ofindb target tokens with the tokens from indd which have the same token type and similar meaning.
we classified tokens into three types according to the kotlin coding style guide tokens beginning with a lowercase letter e.g.
function and variable names tokens beginning with an uppercase letter e.g.
class names and tokens comprised entirely of uppercase letters e.g.
constants .
we considered a pair of target and replacement tokens as a convertible pair only if these tokens were of the same type.
next we evaluated tokens semantic similarity by calculating the distance between their vectors based on word embedding .
we generated the word embedding based vector for each token from indbandinddas described in section .
.
.
after vectorizing the tokens we computed the similarity between target tokens and candidate replacement tokens vectors by cosine similarity.
based on this similarity we replaced target tokens of indb which is not inindd with the most similar tokens in indd.
results.
the codetoken column in table summarizes our experimental results.
the tobi replacement model fixed defects.
the tobi selection model fixed defects and more defects than tobi and tobi replacement models respectively.
the tobi selection model s performance was the best among the various models and dataset variations.
table shows the results for each fold.
the tobi selection model demonstrated better performance than the other models for all folds.
similar to the tobi real model the tobi selection model performed better than the tobi model even with fewer instances.
therefore selecting instances from indbbased on the code tokensfrominddeffectively generated a tuning dataset that increased em while reducing the computation cost of training.
interestingly the tobi replacement model fixed defects fewer than the tobi selection model.
we expected that word replacement would yield better performance but this proved not to be the case.
the higher performance of the tobi selection model implies that maintaining the structure of the surrounding code token is more effective than simply having the token in indd.
token type and semantic similarity were considered in our token replacement method however the structure of the source code and the relationship between other tokens around a token were not considered.
this result implies that each code token in inddmay depend on a specific code structure or buggy context.
table comparison on code token based instance selections fold model type indb em fr 1tobi .
tobi replace .
tobi select .
2tobi .
tobi replace .
tobi select .
3tobi .
tobi replace .
tobi select .
finding .
the procured industrial bug fixing dataset having code tokens from the industrial defect fixing dataset can improve the performance of the defect fixing model.
threats to validity .
internal validity we used the same methods as the tfix authors to minimize experimental errors.
we used the released code as is just changing the dataset path to minimize the errors of patch generation evaluation and tuning.
our dataset collection process was also adapted from their method.
we did not evaluate error fixing from among their suggested evaluation metrics using the more accurate metric exact match instead.
in the discussion section we could have derived more accurate convertible pairs for the tobi replacement model by using the ast node type when replacing the code tokens .
although we made this part heuristic we tried to guarantee maximum accuracy by adopting code conventions much lighter than those of ast analysis methods.
.
external validity there are two major external liabilities pertaining to the generalization of our research.
the first is that we used only tfix for dl apr 1449esec fse november singapore singapore misoo kim youngkyoung kim hohyeon jeong jinseok heo sungoh kim hyunhee chung and eunseok lee validation and improvement so we do not know if our results will be comparable to those of other dl aprs .
however due to the characteristics of dl the effects of tuning based transfer learning and the tuning datasets themselves which we validated are expected to result in effects similar to those of other models.
second there are various methods for transfer learning and we did not use the sota transfer method.
furthermore since we tuned the model by progressively accumulating different datasets recently transferred knowledge may exert a more significant impact than knowledge accumulated in the past .the current transfer strategy could be one of the causes that tobi failed to fix s1186 in section .
.
the defects detected by s1186 need an action for implementing new logic in the blank function block.
the same defect fixing pair in the tuning dataset from indd so the toi model can successfully fix this defect while tobi cannot.
we expect the knowledge gained by this pair was diluted while tuning with the bug fixing dataset and this implies the need for applying better transfer learning methods in the future.
however we used basic transfer learning as our goal was to validate the effectiveness of transfer learning itself.
in the future we plan to apply the sota transfer method which enables more effective knowledge transfer and will likely show better results than ours.
related works .
apr for defects apr techniques for fixing general semantic bugs use a test suite for fault localization and patch validation whereas apr for fixing defects uses sats e.g.
sonarqube spotbugs pmd and eslint .
sats provide a defect report including defect location defect types descriptions and correction examples and sometimes recommend patches for specific defect types .
in short there is a difference in that it is relatively easy to obtain a context for fixing defects compared to fixing bugs .
patch generation approaches for fixing defects can be roughly classified into template based and deep learning based methods.
spongebugs created a fixing template using textual patterns and ast based edit patterns for specific defect types .
memfix collects code patterns about memory allocation statements in c language and uses clean code patterns which have no memory allocation defects as oracles and templates .
some studies generated defect fixing templates using clustering methods .
tfix a dl apr is a method of generating a patch for a given defect code by learning a defect correction pair with the dl model without the need to create a separate template.
at this time in the interest of the accuracy of the generated patch the defect message and the code surrounding the defect were used as context information.
to the best of our knowledge tfix showed the best performance in automatic defect correction and was thus selected as the target apr model for our study.
.
apr in industry apr has also received considerable attention in the industry.
naitou et al.
verified existing apr research in the industry and in the process verified that the performance of apr applied in the field is still low and that obtaining a sufficient number of test cases may not be possible .
based on these findings the authors arguedfor the need for apr studies.
similarly noda et al.
showed that the apr performance overfits the oss dataset by applying the latest apr technique elixir to industrial software .
they also mentioned that the existing apr tool assumes the existence of a failed test case that may be invalid in an industrial environment.
based on these findings apr tools have been proposed for the industry .
some studies have validated the application of template based apr to industrial datasets.
sapfix was first proposed by facebook for large scale industrial apr .
in a subsequent study getafix proposed a hierarchical clustering algorithm to compensate for the problem of the excessive size of the fixing pattern search space .
gunnar et al.
proposed kbar based on tbar and verified it using real bugs from the saab company dataset .
the other mainstream approach dl apr has the advantage of not needing to find a template directly and has thus attracted considerable attention from the industry recently.
google proposed a neural machine translation based deepdelta to correct compilation errors and demonstrated a patch success rate of approximately for two types of compilation errors collected from industrial projects .
most of the existing studies have been proposed and verified using traditional programming languages such as java.
however as mentioned in our research context section .
existing techniques have limitations in directly applying them to a new language such as kotlin because the trend of introducing new languages in the field is not considered.
therefore we suggested a method to verify and improve dl apr performance under these circumstances.
conclusion this study validated a pretrained dl apr model for fixing kotlin defects in industrial projects.
we found that the defect fixing ratio of the sota dl apr model was only approximately because of the absence of the sonarqube kotlin defect fixing dataset that we targeted.
to solve this problem we applied transfer learning with kotlin defect fixing datasets from industrial and oss projects and improved the bug fixing ratio by .
furthermore we showed that more defects could be corrected than the pretrained dlapr model by transferring the accumulated bug fixing knowledge from the company.
in this process we found that the embedding vectors and code tokens of the source code can be utilized as a feature to select an effective tuning instance.
our study provides important insights for industry stakeholders by considering the application of dl apr.
based on the pretrained dl apr model the defect bug fixing datasets accumulated by the company and through transfer learning can automatically fix defects that occur in the real world.
in addition the practitioners can more effectively utilize knowledge accumulated within their company through ide or api based on our study.
in the future we plan to improve the defect fixing ratio by applying state of the art transfer learning to transfer knowledge of industrial data to the existing dl apr model.