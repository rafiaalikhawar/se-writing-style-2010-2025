ropgen towards robust code authorship attribution via automatic coding style transformation zhen li guenevere qian chen chen chen sharp yayi zou shouhuai xu university of texas at san antonio usa huazhong university of science and technology china sharpcenter for research in computer vision university of central florida usa northeastern university china university of colorado colorado springs usa zh li hust.edu.cn guenevereqian.chen utsa.edu chen.chen crcv.ucf.edu stu.neu.edu.cn sxu uccs.edu abstract sourcecodeauthorshipattributionisanimportantproblemoften encountered in applications such as software forensics bug fixing and software quality analysis.
recent studies show that current sourcecodeauthorshipattributionmethodscanbecompromised by attackers exploiting adversarial examples and coding style manipulation.
this calls for robustsolutions to the problem of code authorship attribution.
in this paper we initiate the study on making deep learning dl based code authorship attribution robust.
we propose an innovative framework called robust coding style patternsgeneration ropgen which essentially learns authors uniquecodingstylepatternsthatarehardforattackerstomanipulate or imitate.
the key idea is to combine data augmentation andgradientaugmentation attheadversarialtrainingphase.this effectivelyincreasesthediversityoftrainingexamples generates meaningfulperturbationstogradientsofdeepneuralnetworks and learns diversified representations of coding styles.
we evaluate the effectivenessof ropgenusingfour datasetsofprograms written inc c andjava.experimentalresultsshowthatropgencan significantly improve the robustness of dl based code authorship attribution byrespectivelyreducing22.
and41.
ofthesuccess rate of targeted and untargeted attacks on average.
ccs concepts security and privacy software security engineering.
keywords authorship attribution source code coding style robustness deep learning acm reference format zhenli guenevere qian chen chenchen sharp yayizou shouhuaixu .
.ropgen towardsrobustcodeauthorshipattributionviaautomatic coding style transformation.
in 44th international conference on software permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
icse may pittsburgh pa usa association for computing machinery.
acm isbn ... .
icse may pittsburgh pa usa.
acm new york ny usa pages.
introduction softwareforensicsanalysisaimstodeterminewhetherornotthere issoftwareintellectualpropertyinfringementortheftassociated with some given software code.
one useful technique for this purposeissourcecodeauthorshipattribution whichaimsto identify the author s of a given software program .
this techniquehasbeenusedformanyapplications suchascodeplagiarismdetection criminalprosecution e.g.
identifyingtheauthor of a piece of malicious code corporate litigation e.g.
determining whether a piece of code is written by a former employee who violatesanynon competeclauseofcontract bugfixing and software quality analysis .
therearemultipleapproachestosourcecodeauthorshipattribution including statistical analysis similarity measurement and machinelearning .recentstudiesshowthatcurrentsourcecodeauthorshipidentification methodscanbecompromisedbytwoclassesofattacks theones exploiting adversarial examples and the ones exploiting codingstyleimitation hiding .forinstance leveraging adversarial examples can cause misattribution of more than software programs in the googlecodejam competition dataset whereas leveraging the coding style hiding can cause misattribution of all of the software programs in a githubdataset .
the state of the art is that current code authorship attributionmethodsarevulnerabletotheseattacks.thiscallsforresearch on enhancing the robustness of code authorship attribution methods against attacks.
ourcontributions .inthispaper weinitiatethestudyonenhancingtherobustnessofdeeplearning dl basedcodeauthorship attribution methods.
we choose to focus on this family of methods because they can automatically learn coding style patterns i.e.
avoiding laborious involvement of domain experts and are verypromising for real world adoption .
effectively wetacklethefollowingproblem howcanweenhancetherobustness of dl based code authorship attribution against attacks?
for this purpose we need to address two challenges.
thefirstchallengeistoconsidermoreattacksthanwhathave beeninvestigatedintheliterature otherwise theresultingdefenses ieee acm 44th international conference on software engineering icse authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa zhen li guenevere qian chen chen chen sharp yayi zou shouhuai xu wouldbespecifictotheknownattacksandwillsoonbecomeobsolete when new attacks are introduced.
this is especially true becausetheknownattacksaregearedtowardsdomainexpert defined features whichmaynotbesustainableandwouldsooneror later need to be replaced by automatic feature learning.
this inspiresustoexplorenew unknownattackssothatwecandesign defensesthatcanenhancerobustnessagainstbothknownandnew attacks.
for this purpose we introduce two new attacks which exploitautomaticcodingstyleimitationandhiding theseattackscan be applied againstboth dl based codeauthorship attribution and other methods.
the new attacks leverage our systematization of semantics preservingcodingstyleattributesandtransformations whichmaybeofindependentvalue.theattacksareofblack box type because they do not need to know the target code authorship attributionmethods instead theyimitatethetargetauthor scoding style or hide the true author s. the second challenge is to design effective defenses against the known and new attacks mentioned above while accommodating a range of neural network structures rather than a specific one .
to addressthischallenge itwouldbenaturaltoleveragetheideaof adversarial training because it has been widely used in other settings .
however our experimental results show that such adversarial training approaches applied in these settings cannot effectively mitigate the known and new attacks mentioned above as what will be described in table of section .
.
thisprompts us to propose an innovative framework called robust coding style patternsgeneration ropgen .
the key idea is to incorporatedataaugmentation andgradientaugmentation tolearnrobust codingstylepatternswhicharedifficultforattackerstomanipulate or imitate.
the role of data augmentation is to increase the amount anddiversityofsoftwareprogramsfortrainingpurposes.thisis achievedbyaugmentingprogramsintwoways i imitatingcoding styles of other authors and ii perturbing programs coding styles to a small degree without changing their authorship.
the role of gradientaugmentation istolearnrobustdlmodelswithdiversified representations by incurring perturbations to gradients of deep neural networks.
this is achieved as follows at each training iteration wesamplemultiplesub networkswithacertainfractionof thenodesateachlayerofthenetwork then weusethesampled sub networkstoconstructthenetworkwithdiversifiedrepresentations during the weights sharing training process.
the resulting model learns robust coding style patterns which would be difficult toexploit.itisworthmentioningthatgradientaugmentationhas been used as a regularization method to alleviate over fitting of deepneuralnetworksinimageclassification wearethefirst to use it for robustauthorship attribution.
to evaluate the effectiveness of ropgen we use four datasets of programs written in c c and java namely gcj c github java github c and gcj java.amongthem gcj c and gcj java are two sets of programs written by authors whoparticipate in programming competitions for solving a given set of problems github java and github c are two sets of real world programs written by different programmers for varying purposes github c and gcj java are created for the purpose of the present paper.
experimental results show that ropgen can significantlyimprovetherobustnessofdl basedcodeauthorshipattribution respectivelyreducingthesuccessrateoftargetedanduntargetedattacks by .
and .
on average.
we have made the datasets available at .
we will publish the source code of ropgen on the same website.
paper organization .
we discuss the notion of coding styles in section2 introducetwonewattacksinsection3 describeropgen in section present experimental results in section discuss limitationsinsection6andrelatedpriorstudiesinsection7 and conclude this paper in section .
the notion of coding styles theproblemofsourcecodeauthorshipattributionhastwovariants single authorship attribution vs. multi authorship attribution .
since most studies focus on the former variant while the latter is little understood we focus on addressing the former variant.
coding style attributes .
the premise for achieving authorship attribution is that each author has a unique coding style which can bedefinedbasedonfourtypesofattributesrelatedtoprograms layout lexical syntactic and semantic information.
layout attributes includecodeindentation emptylines brackets andcomments .
lexicalattributesdescribetokens e.g.
identifier keyword operator and constant the average length of variable names the number of variables and the number of forloop statements .
syntacticattributesdescribeaprogram s abstractsyntaxtree ast includingsyntacticconstructs e.g.
unaryandternaryoperators andtreestructures e.g.
frequencyofadjacentnodesandaverage depthofastnodetypes .semanticattributesdescribea program scontrolflowsanddataflows e.g.
for while if else if switch case and execution order of statements .
sincecodingstylesandtheirattributesarerelatedtoprogramminglanguages wefocusonc c andjavaprogramsbecause they are widely used while leaving the treatment of other languages to future studies.
even for these specific programming languages theircodingstyleattributesarescatteredintheliterature .thispromptsustosystematizeattributesaccording to the following observations i layout attributes can be easily manipulatedbycodeformattingtools e.g.
codebeautify andeditor config ii thoseattributes whosevalues cannot beautomaticallymodifiedwithoutchangingaprogram ssemantics wouldnotbeexploitedbyanattackerbecausetheymakeimitation attacks hard to succeed and iii those attributes whose values are rarely used e.g.
making programs unnecessarily complicated would not be exploited by animitation attacker.
as highlighted in table1 theseobservationsleadto23codingstyleattributes which span across lexical syntactic and semantic information.
leveraging coding style attributes as a starting point for robust authorship attribution .
for this purpose we need to considertwoissues.first weconsider granularity ofcodingstyleattributes namely token vs. statement vs. basic block vs. function.
this is important because code transformations on coarse grained attributesmaydemandlargerdegreesofperturbationstoprograms.
token levelattributes 5intable1 theydescribetheelements in a program s statements identifier naming method usageoftemporaryvariablenames usageofnon temporary local identifier names usage of global declarations and authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ropgen towards robust code authorship attribution via automatic coding style transformation icse may pittsburgh pa usa table c c and java coding style attributes serving as a starting point for robust code authorship attribution granularity attribute description value type exhaustive?
language token1 identifier naming methodcamelcase e.g.
mycount pascalcase e.g.
mycount wordsseparatedbyunderscores or identifiers starting with underscores.lexical yes c c java usage of temporary variable names variable names defined in a compound statement of a function.
lexical no c c java 3usage of non temporary local identifier namesvariable names defined in functions but not defined in compound statements or user defined function calls.lexical no c c java usage of global declarations global constants declared outside of functions.
lexical no c c access of array pointer elements use the form of array indexes or pointers e.g.
arr and arr i .
lexical yes c c statement6 location of defining local variableslocalvariablesaredefinedatthebeginningofthevariablescope oreachlocalvariableis defined when used for the first time.syntactic yes c c java locationofinitializinglocalvariables localvariablesareinitializedanddefinedinsamestatements orindifferentstatements.
syntactic yes c c java 8definition and initialization of mul tiple variables with same types multiple variables with same types are defined and initialized in a statement or inmultiple statements.syntactic yes c c java variable assignmentmultiplevariableassignmentsareinastatement e.g.
tmp i ormultiplestatements e.g.
i tmp i .syntactic yes c c java increment decrement operationuse increment or decrement operator with different locations e.g.
i i ii i iii i i iv i .syntactic yes c c java user defined data types usetypedefto rename a data type or not.
syntactic no c c macros use macros to replace constants and expressions or not.
syntactic no c c 13included header files or importedclasses header files included in c c programs and classes imported in java programs.semantic no c c java usage of return statements usereturn to explicitly return success in mainfunction or not.
semantic yes c c usage of namespaces use namespace stdor not.
semantic yes c synchronization with stdio enable or remove the synchronization of c streams and c streams.
semantic yes c stream redirection usefreopento redirect predefined streams to specific files or not.
semantic yes c c library function callsc library function calls e.g.
cin cout or corresponding c library function calls with the same functionalities e.g.
scanf printf .semantic yes c memory allocationstatic array allocation e.g.
int arr or dynamic memory allocation e.g.
int arr malloc sizeof int .semantic yes c c basic block20 loop structures useforstructure or whilestructure.
semantic yes c c java conditional structures use conditional operator if else o rswitch case structure.
semantic yes c c java compound ifstatementsusealogicaloperatorinan ifcondition e.g.
if a b orusemultiple ifconditions e.g.
if a if b ... .semantic yes c c java function usage of functionsthe maximum layer number of control statements and loops that are nested withineach other or the number of lines of code in the function.semantic no c c java access of array pointerelements .
for instance attribute oftheprogramshowninfigure1 a isdescribedbytemporary variable names case it st ss ans pos and i. statement level attributes in table they describe the locationofdefininglocalvariable thelocationofinitializing local variables the definition and initialization of multiple varialbles with same types variable assignment increment decrementoperation user defineddatatypes macros included header files or imported classes usageofreturnstatements usageofnamespaces synchronization with stdio stream redirection library functioncalls andmemoryallocation .forinstance attribute of the program shown in figure a is described by library functions cin line and cout line .
basic block level attributes in table they describe loopstructures conditionalstructures andcompound ifstatements .forinstance attribute 20oftheprogram showninfigure1 a isdescribedbytwo forstructures line4 and line and a whilestructure line .
function level attribute in table at this granularity coding styles describe the usage of functions namely i the maximum number of layers of nested compound statements e.g.
control statements and loops or ii the number of lines of code inafunction.forinstance attribute 23oftheprogramshowninfigure1 a isthemaximumnumberoflayersofnestedcompound statements which is in this case i.e.
for while for .
second we propose distinguishing those coding style attributes whose domains are exhaustive from those that are not the term exhaustive means that an attribute s domain contains few values e.g.
the kinds ofloop structures and a domain is treatedas nonexhaustive if its domain contains many values e.g.
the numberof possible variable names can be very large .
this is importantbecause a non exhaustive attribute would naturally demand more perturbed examples for adversarial training purposes.
as shownin table exhaustive attributes include attributes and atthe token level granularity and at the statementlevelgranularity and 22atthebasicblock levelgranularity.
for instance i.e.
loop structures has only two values in c c andjavaprograms forandwhile.non exhaustiveattributes include attributes at the token level at the statement level and 23atthefunctionlevel.forinstance i.e.
usageof temporaryvariablenames isnon exhaustivebecausetemporary variablescanhavearbitrarynames.fortheprogramdescribedin figure a the value of attribute includes case it st ss ans pos and i. two new attacks weinvestigatetwonewattacksagainstcodeauthorshipattribution one is coding style imitation attack and the other is coding style hidingattack.
these attacks are new and can make our defense widely applicable because they are waged automatically and are wagedagainstbothdl basedcodeauthorshipattributionandother methods.incontrast attackspresentedintheliteraturearemanual semi automatic or automatic but not applicable to dlbased code authorship attribution .
denote by a a1 ... a a finite set of authors and by m thecodeauthorshipattributionmethodinquestion.theattacker has black box access to m meaning i the attacker can query any programptomwhichreturnstheauthorof porm p and ii how mis obtained is unknown to the attacker.
in the threat model the attacker manipulates pwritten by as e.g.
alice into a variant programp primevia semantics preserving code transformations where p prime nequalp.
the attacker s goal is authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa zhen li guenevere qian chen chen chen sharp yayi zou shouhuai xu ... void split main int test string tmp auto proxmsk test while proxmsk tmp.length tmp proxmsk int main int case num cin case num int ps while ps case num ps string tmp scanf s tmp stringstream spd long long ls int test get wrong pos tmp while test !
tmp tmp split main test tmp test get wrong pos tmp spd tmp spd ls printf case d lld n ps ans a input e ia.step iv conducting code transformations to imitate target author at ... int main int case num cin case num for int case it case it case num case it string st cin st stringstream ss long long ans int pos get wrong pos st while pos !
st st for auto i pos i st.length i st pos get wrong pos st ss st ss ans cout case case it ans endl a set r of programs authored by target author at b ia.step i extracting coding style attribute values from programs words separated by underscores case it st ss ans pos i case num use the form of array indexes local variables are defined when they are used for the first time increment operation is used before the variable cin cout for while the maximum layer number ... ... ... ... c ia.step ii synthesizing coding style attribute values extracted from the programs in r words separated by underscores camel case ps tmp spd ls test proxmsk ... totaltest case num my count ... use the form of array indexes local variables are defined when they are used for the first time multiple variable assignments are in a statement scanf printf while use the conditional operator the maximum layer number d ia.step iii identifying coding style attributes in p for code transformation case it st ss ans pos i cin cout for the maximum layer number program p program p figure1 anexampleshowinggenerationofc program p primefortargetedattack modifiedcodeishighlightedinredanditalics in atargetedattack with target author at e.g.
bob where t nequals the attacker s goal is to make mmisattribute p primetoat namely m p prime atwhilenotingthat mwouldcorrectlyattribute ptoas namelym p as.thatis theattackerattemptstomanipulatea programwrittenbyaliceintoasemantically equivalentprogram which will be misattributed to bob.
inanuntargeted attack theattacker sgoalistomake mmisattributep primetoanyotherauthor authanas namely m p prime au whereau a as .
.
automatic coding style imitation attack in this attack the attacker as ain typical use cases takes as input i the set aof authors ii a program pauthored by as and iii a set rof programs authored by target author at a wheret nequals.
the goal of asis toautomatically transform program pto program p primesuch that p primepreserves p s functionality and m misattributes p primetoat.
the attack proceeds as follows.
ia.stepi extractingcodingstyleattributevaluesfromprogram pand the programs in r authored by target author at .attacker asgeneratesthecodingstylesofprogram pand all programs in rby leveraging the attributes mentioned above .
as a running example figure a shows as s programpandfigure1 b showsthevaluesofthe9applicable attributes of p. for instance in order to obtain the value of attribute i.e.
identifier naming method ascan identify all of the user defined variable and function call names used in p i.e.
case num case it st ss ans pos get wrong pos and iin this case .
then ascan obtain the identifier naming method for eachuser definedvariableandfunctioncallname.specifically the value of attribute corresponding to case num case it andget wrong pos is words separated by underscores the othervariableandfunctioncallnames i.e.
st ss ans pos and i cannotberepresentedbyattribute 1becausetheseidentifiers have no naming rules.
therefore the value of attribute of programpis words separated by underscores .
ia.stepii synthesizingcodingstyleattributevaluesextracted fromtheprogramsin r.havingextractedattributevaluesfrom individual programs in r we need to synthesize them into a singlevalueforeachattributetoobtaintargetauthor at scoding style.inthecaseanattributeisnumeric weproposeusingthe average of an attribute s values as observed from the programs inr to represent at s coding style with respect to the attribute.
inthecaseanattributeisnon numeric weproposeusingtheorderedsetofanattribute sdistinctvaluesinthedescendingorder of their frequency to represent at s coding style with respect to the attribute.
as a running example figure c illustrates at s coding style attributes synthesized from the programs in r.forinstance thesynthesizedvalueofnumericattribute usage of function is which is the average of values observed from the programs in r. non numeric attribute identifier naming method takes two distinct values words separated by underscores as observed from most programs in r and camel case as observed from the other programs in r the synthesizedvalueofattribute 1istheorderedset wordsseparatedby underscores camel case as the former has a higher frequency.
ia.stepiii identifyingcodingstyleattributesin pforcode transformation.
having obtained attacker as s coding style attributesfromprogram p ia.stepi andtargetauthor at scoding style attributes from r ia.step ii we identify the discrepant attributes namelytheattributesthattakedifferentvalueswith respectto asandat ascandidatesforcodetransformationto makepimitateat scodingstyle.foranumericattribute discrepancy means that the difference between its value derived from p anditsvaluederivedfrom risaboveagiventhreshold .fora non numeric attribute discrepancy means that its value derived frompisnotasubsetofitsvaluederivedfrom r.asarunning example figure b and c show that the value of numeric attribute derived from pis discrepant with the value derived fromrbecause their difference is larger than the threshold thevaluesofnon numericattributes and 20derivedfrom parediscrepantwiththeircounterpartsderivedfrom rbecause the former is not a subset of the latter respectively.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ropgen towards robust code authorship attribution via automatic coding style transformation icse may pittsburgh pa usa as shown in figure d these four discrepant attributes are candidates for code transformations to imitate at s coding style.
ia.stepiv conductingcodetransformationstoimitatetargetauthor at.thisstepistochangethevaluesofthediscrepant attributes identified in ia.step iii to imitate target author at leading to a transformed or manipulated program p primewhich preserves p s functionality.
we conduct code transformations on individualprogramfilesbasedon srcml whichcanpreserve programfunctionalitieswhilesupportingmultipleprogramming languages.
as a running example figure e shows the manipulated program p primeobtained by sequentially transforming the valuesofattributes and 23derivedfromprogram p whileassuringthateachtransformationpreserves thefunctionality of the program in question.
take attribute for example.
themainfunction line1infigure1 a issplitintotwofunctions main line in figure e and split main line in figure e .
.
automatic coding style hiding attack in this attack attacker as atakes as input the set aof authors andaprogram pauthoredby as.asmentionedabove thegoalof as istomanipulateprogram ptoanotherprogram p prime whichpreserves p s functionality but will not be attributed to as.
to achieve this we propose leveraging the preceding imitation attacks by choosing a target author with the highest misattribution probability.
details follow.
ha.step i extracting coding style attribute values from program p.this is the same as ia.step i. ha.step ii obtaining the coding style of each author ad.
foreachad a as wegenerate ad scodingstyleasia.step ii by treating adas the target author.
ha.stepiii identifyingthecodingstyleattributesin pfor each ad.foreachauthor ad a as weidentifythecoding style attributes extracted from pthat are discrepant with ad s. thisisthesameasia.stepiiibytreating adasthetargetauthor.
ha.step iv selecting author aufor transformation.
for eachad a as we compute the number of lines of code that need to be changed to make p primeimitatead s coding style.
changingmorelinesofcodein p e.g.
involvingattributes and may make pretain fewer original coding styles and thus make an untargeted attack successful with a higher misattributionprobability.weselectauthor au a as with the highest misattribution probability as the target author.
ha.stepv conductingcodetransformationstoimitateauthorau.this is the same as ia.step iv with target author au.
the ropgen framework indl basedauthorshipattribution theinputatthetrainingphaseis asetof trainingprogramswithlabels denotedby p pk qk k wherepkis a training program and qkis its label i.e.
author .
the output is a dl model m. given a finite set of authors a a1 ... a andaprogram pkauthoredby as a letpr m pk as denotetheprobabilitythat mpredictsthat pkisauthoredby as.the attacker manipulates pkto a different program denoted by p prime k.a s discussedabove an imitation attackersucceedswhen pr m p prime k at max1 z pr m p prime k az for a given t nequals ahiding attacker succeeds when pr m p prime k as nequalmax1 z pr m p prime k az .
figure highlights the training phase of ropgen framework whichtrainsanenhancedmodelof m denotedby m .theinputto ropgenincludes i aset pof trainingprogramsand theirlabels ii a sett aof target authors and iii a set eof adversarial examples against model m. the basic idea behind ropgen is to leverage ideas of data augmentation andgradient augmentation data augmentation aims to increase the amount and diversity of training programs.
we achieve this via two ideas i imitating coding styles of the other authors which is elaborated in step1below ii changingprograms codingstyleswithsmall perturbations which is elaborated in step below.
gradient augmentation aims to learn a robust deep neural network with diversified representations by generating meaningful perturbationstogradients.weachievethisbysamplingmultiple sub networks with each involvingthe first wj nodes at eachlayerofthenetwork where wj and is the width lower bound.
this allows a larger sub network to containtherepresentationofasmallersub networkduringweightssharingtraining enablingtheformertoleveragetherepresentationslearnedbythelattertoconstructrobustnetworkswith diversified representations.
this is elaborated in step below.
.
step extending the training set by coding style imitation givenaset toftargetauthors thisstepistoextend pbygenerating programs to imitate the coding styles of the authors in a. we first generate a set p1of programs imitating the coding styles of the authors in a. specifically for each program pk pwith label i.e.
authoredby qk t wetransform pktoimitatethecodingstyle of each of the other authors in a qk while preserving pk slabel.thisessentiallyrepeatstheimitationattackdescribedin section3for 1times.thenweobtaintheextendedset u p p1 oftrainingprogramswithlabels whichistheinputtostep3below.
.
step generating manipulated programs by coding style perturbation this step is to generate manipulated programs by coding style perturbation.
we consider two situations.
first we can generate a set eof adversarial examples against mand then obtain a set u primeof manipulatedprogramsby leveraging easfollows.for eachadversarial example er e we obtain a sequence trof transformations which led to er.
then for each program pk p we generate a manipulated program pk rby conducting the sequence trof transformations.
this leads to u prime e p manipulated programs.
second ifitisnoteasytogenerateadversarialexamples wecan generate manipulated programs p1 k ... pz kby perturbing program pk namelybychangingthevalueofeachofthe zattributesforeach program pk p. this leads to a set u primeof manipulated programs where u prime z p .
specifically we first extract pk s coding style attributes as in ia.step i see section .
corresponding to each attribute cj j ... z wegenerateamanipulatedprogram pj k byrandomlyselectingavalueof cjandchangingittoanothervalue while preserving pk s label.
for instance consider program pin authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa zhen li guenevere qian chen chen chen sharp yayi zou shouhuai xu step extending the training set p by coding style imitation input a set p of training programsa set t of target authors a set e of adversarial examples step generating manipulated programs by coding style perturbationtraining n sub networks forward pass and loss computation for sub networks backward pass for updating the model weight computing the total loss sampling n sub networks step training a robust dl model forward pass and loss computation for the full fledged network backward pass for updating the model weight training a full fledged network a trained model m output data au gmentation gradient au gmentation figure the ropgen framework is an enhanced training model involving data augmentation steps and and gradient augmentation step .
since the data flows share zin step we use solid blue arrows and dotted red arrows to distinguish the training processes of the full fledged network and sub networks.
the original dl based training model baseline is highlighted with shaded boxes.
figure1 a .foranexhaustiveattribute e.g.
attribute itsvalue e.g.
while canbetransformedtoanothervalue e.g.
for causing thewhilestructure lines and in figure a to be transformedtothe forstructure i.e.
for pos get wrong pos st pos!
.foranon exhaustiveattribute e.g.
attribute its value can be transformed to the value corresponding to another randomly selected author s causing the temporary variable names to become another author s.finally weobtain u primewhichcontains manipulated programs with labels.
.
step training a robust dl model m this step trains a robust model m by sampling multiple subnetworksineachtraining iterationfor gradientaugmentation and generating meaningful perturbations to the gradients of the model.
ropgen uses the extended training set uas the input to the fullfledged network and the set u primeof manipulated programs as the inputtothesub networks.denoteby nthedeepneuralnetwork and itsmodelparameter.eachtrainingiterationhasfivesubsteps stepx forwardpassandlosscomputationforthefull fledged network.
weusetheextendedset uoftrainingprograms obtained instep1 astheinputtothefull fledgednetwork.foreachtraining programwithitslabel u v u weconducttheforwardpassand obtain the predicted value of the full fledged n u .
we compute the full fledged network s loss using the standard lstd l n u v and loss function l e.g.
cross entropy .
stepy sampling nsub networks.
we sample nsub networks n1 ... nnfrom the full fledged network n. to obtain nj j ... n we sample the first wj nodes in each layer of the full fledged network.
the order of nodes at each layer is naturallydeterminedbythefull fledgednetwork i.e.
top to bottom in the standard representation of neural networks .
we use thisordertosamplethefirst wj fractionofnodesatalayertoobtain a sub network.
these sub networks will be used to learn differentrepresentationsfrommanipulatedprogramsandenhancethe robustness of the full fledged network.stepz forwardpassandlosscomputationforsub networks.
we useu primeobtained in step as the input to each sub network nj because programs in u primeare generated with small perturbations and thus suitable for fine tuning the full fledged network.
let wj be the parameter of the sub network nj.
for each program with its label u prime v prime u prime we conduct the forward pass and obtain prediction n wj u prime .
the loss lsubnetof thensub networks is lsubnet n summationdisplay.
j 1l n wj u prime v prime .
step computingthetotalloss.
thetotalloss lropgenisthe sum of the loss of the full fledged network and the loss of the sub networks lropgen lstd lsubnet.
step updatingthemodelweights .weconductthebackward passandleveragethetotallosstoupdatemodelweights whicharesharedbythefull fledgednetworkand nsub networks.thisallows different parts of the network to learn diverse representations.
stepsxto are iterated until the model converges to m .
gradient property analysis.
toshowhowstep3augmentsthe gradient it suffices to consider the full fledged network nwith onelayer.basedoneq.
thefull fledgednetwork n sgradient stdis std l n u v .
based on eq.
the nsub networks gradient subnetis subnet n summationdisplay.
j l n wj u prime v prime wj.
based on eq.
eq.
and eq.
ropgen s gradient ropgenis ropgen std subnet subnetcanbeseenasanaugmentationtotherawgradient std explaining the term gradient augmentation .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ropgen towards robust code authorship attribution via automatic coding style transformation icse may pittsburgh pa usa ropgen experiments and results our experiments aim to answer three research questions rqs rq1 aretheexistingdl basedauthorshipattributionmethods robust against the known and new attacks?
section .
rq2 how robustare ropgen enabled authorship attribution methods against the known and new attacks?
section .
rq3 are ropgen enabled methods more effective than other adversarial training methods?
section .
.
experimental setup datasets.
ourexperimentsusefourdatasets thefirsttwoareused in the literature and the last two are introduced in this paper.
gcj c dataset .googlecodejam gcj isanannualinternationalprogrammingcompetitionofmultiplerounds each round requires participants to solve some programming challenges.thisdatasetiscreatedfromgcjin andconsistsof c program files from authors.
each author has program files corresponding to programming challenges with an average of lines of code per program file.
github java dataset .
this dataset is created from github in and consists of java program files from authors with an average of lines of code per program file.
github cdataset .wecreatethisdatasetfromgithub bycrawlingthecprogramsofauthorswhocontributedbetween11 and12 .wefiltertherepositoriesthataremarkedasforks because they are duplicates and the repositories that simply duplicate the files of others.
we preprocess these files by removingthecomments wetheneliminatetheresultingfilesthat i containlessthan30linesofcodebecauseoftheirlimitedfunctionalities or ii overlap more than of its lines of code with otherfiles.theresultingdataset has2 072cfilesof67authors with an average of lines of code per file.
gcj java dataset .
we create this dataset from gcj between 2015and2017.sincesomeauthorsparticipateingcjformultiple years we merge their files according to their ids.
we select the authors who have written at least java program files.
the dataset has java files of authors with an average of lines of code per file.
evaluation metrics.
to evaluate effectiveness of code authorship attributionmethods weadoptthewidely usedaccuracyandattack success rate metrics .
recall that mis a dl based attribution method m istheropgen enabledversionof m andgisanattack method.
the accuracy of m denoted by acc m is the fraction of the test programs that are correctly labelled by m. the attack success rate of an imitation attack gagainst model m denoted byasrtar m g isthefractionofthemanipulatedprogramsthat aremisattributedtothetargetauthorby m amongallofthetest programs.theattacksuccessrateofahidingattack gagainstmodel m denoted by asrunt m g is the fraction of the manipulated programs that are misattributed to another author by m among the correctly classified test programs.
implementation.
wechoosethefollowingtwodl basdattributionmethodsreportedin becausetheyrepresentthestateof the art and are open sourced as well as language agnostic.table2 accuraciesoftwodl basedattributionmethodson four datasets metrics unit method gcj c github c gcj java github java dl cais .
.
.
.
pbnn .
.
.
.
dl cais .
this method adopts lexical features to represent programs leveragesrecurrentneuralnetworkandfully connected layerstolearnrepresentations andusesrandomforesttopredict authorship.
pbnn .thismethodadoptscode2vec torepresentprograms.
it decomposes a program to multiple paths in its ast transformsthepath contextstovectors andusesafully connected layer with softmax activation to predict authorship.
we use a stratified fold cross validation where the dataset is splitinto 1subsetsfortrainingandtherestfortesting.following thetrainingstrategyofpbnn weset 10forthegithub c gcj java andgithub javadatasets.followingthetrainingstrategy of dl cais we set for the gcj c dataset.
this cross validationisrepeated times whereeachsubsetisusedfortesting themodeltrainedfromtheother 1subsets.theevaluationmetrics arecomputedastheaverageofthe validations.weusethemethod reported in to generate adversarial examples and leverage srcml togeneratemanipulatedprogramsandlaunchcoding style imitation hiding attacks.
we choose srcmlbecause it can conductcodetransformationsonanindividualprogramfileandcansupportmultipleprogramminglanguages.weconductexperimentsonacomputerwithanvidiageforcegtx3080gpuandanintel i9 10900x cpu running at .70ghz.
.
robustness of existing methods rq1 to determine whether existing authorship attribution methods arerobustagainsttheknownandnewattacks weattacktwodlbased attribution methods i.e.
dl cais and pbnn on fourdatasets i.e.
gcj c github java github c andgcj java corresponding to eight dl models.
table shows that dl cais and pbnn on four datasets achieve .
and .
accuracies on average.
for the knownattacks we usethemonte carlotreesearchtogenerateadversarialexamples foreachprograminthetestsetofthegcj c andgithubc datasets since the approach focuses on c c programs.
to preservethemaincodingstylesoftheoriginalauthors weleveragethenotionof adversary whichmeansaprogramcanapplyatmost codetransformationswhengeneratingadversarialexamples .
for thenewattacks we use the automatic coding style imitation and hiding attacks we propose to generate manipulated programs.
robustnessagainsttargetedattacks.
duetothequadraticnumber of pairs we perform targeted attacks on random authors foreachdatasetandusetwoprogramfilesastheexternalsource i.e.
notpartofthetrainingortestset forextractingeachtarget author s coding style as per .
for each program authored by these authors in the test set we respectively take the authorsotherthantheauthortowhomtheprogramisattributedasthetarget author.
for generating adversarial examples we set i.e.
adversarywhengeneratingadversarialexamples.wewilldiscuss authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa zhen li guenevere qian chen chen chen sharp yayi zou shouhuai xu the impact of different choices of .
table depicts the attack success rates of two dl based attribution methods on four datasets.
weobservethatthesuccessrateofthetargetedattackexploiting adversarialexamplesis20.
lowerthanthatofthetargetedattack exploitingcodingstyleimitationonaverage.thiscanbeattributed to the fact that adversarial examples obtained by conducting more than three code transformations are not valid attacks with respect to the notion of adversary.
in terms of the time complexity for generatingmanipulatedprograms weconsiderdl caisongcjc datasetasanexample.onaverage ittakes2 417secondstogenerate an adversarial example of a program whereas it only takes1.5secondsonaveragetogenerateamanipulatedprogram via thecoding style imitationmethod.
this largediscrepancy can beattributedtothefactthattheformermethodneedstocalltheattribution model to test candidate examples possibly multiple rounds in order to generate an adversarial example whereas this isnotneededinthelattermethod.fordifferentdatasets theattack success rate of two attribution methods ranges from .
to .
whicharerelatedtothenumberofprogramsinthedatasetandthe coding styles of different authors.
proportion attribute all programs attack against dl cais attack against pbnn figure illustrating i the proportion of the manipulated programs in the test set involving a coding style attribute stransformationamongallmanipulatedprogramsinthetestset denotedby allprograms and ii theproportionofthemanipulatedprogramsthatinvolveacodingstyleattribute stransformation and can attack successfully in the test setamongallmanipulatedprogramsinthetestsetfordl caisandpbnn denotedby attackagainstdl cais and attackagainst pbnn respectively .
toseewhichattributesarechangedwhengeneratingmanipulated programs and the impact of the choice of attributes let usconsider the gcj java dataset.
for each coding style attribute r figure illustrates i the proportion of the manipulated programs in the test set involving r s transformation among all manipulated programs in the test set and ii the proportion of the manipulated programsthatinvolve r stransformationandcanattacksuccessfully in the test set among all manipulated programs in the testset for two dl based attribution methods.
we observe that mostmanipulated programs involve attributes andtable attack success rates of two dl based attribution methods where means the method cannot be used onthe dataset metrics unit .
method gcj c github c gcj java github java targeted attacks by exploiting adversarial examples asrtar dl cais .
.
pbnn .
.
targeted attacks by coding style imitation asrtar dl cais .
.
.
.
pbnn .
.
.
.
untargeted attacks by exploiting adversarial examples asrunt dl cais .
.
pbnn .
.
untargeted attacks by coding style hiding asrunt dl cais .
.
.
.
pbnn .
.
.
.
indicating that these coding style attributes have more significant differences among different authors than other coding styleattributes.
we also observe that the fraction of the manipulated programsthataresuccessfultargetedattacksagainstpbnnison average14.
higherthanthatofthesuccessfultargetedattacksagainst dl cais where manipulations are on attributes and .
this indicates that for java programs thepath based representation which is used by pbnn can transferthe prediction from one author to another more easily than the token based representation which is used by dl cais.robustness against untargeted attacks.
we apply the untargeted attack to the correctly classified test programs of authors which are randomly selected in targeted attacks.
table shows the success rate of untargeted attacks for two dl based attribution methodsonfourdatasets.weobservethattheaveragesuccessrate of untargeted attacks is .
higher than that of targeted attacks which can be attributed to the fact that untargeted attacks which misattributeprogramasanyauthorotherthanthetrueauthor is easier than targeted attacks which misattribute program to the targetauthor.tocomparetheeffectivenessofdifferentmethodsfor codingstylehidingattacks weconsiderasthebaselinearandom replacement method which transforms each coding style attribute value in the program to another random value.
we choose the randomreplacementmethodbecauseitisanintuitivewaytomakethemanipulatedprogram scodingstyledeviatemorefromtheoriginal author s coding style.
table summarizes the average results of random replacements five times for each dl model.
our untargeted attack method is significantly better than the random replacement method with .
higherattack successrateon average.
thiscan beexplained bythe factthattherandomreplacementmethodmaymakethemanipulatedprogramseasiertobeattributedastheoriginalauthorbecause therearesomecodingstyleattributesintheprogramthatcannot beautomaticallytransformed.ifwedonotpurposelytransformthe program scodingstyletoatargetauthor s themanipulatedprogram scodingstyleismoresimilartotheoriginalauthor s causing a failed untargeted attack.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ropgen towards robust code authorship attribution via automatic coding style transformation icse may pittsburgh pa usa table4 attacksuccessratesoftwomethodsforcodingstyle hiding attacks metrics unit method gcj c github c gcj java github java our untargeted attacks dl cais .
.
.
.
pbnn .
.
.
.
untargeted attacks by randomly replacement dl cais .
.
.
.
pbnn .
.
.
.
table attack success rates of dl cais method for different adversaries on the gcj c dataset metrics unit attack type 1 3 targeted attack .
.
.
untargeted attack .
.
.
table6 accuraciesofropgen enabledattributionmethods on datasets metrics unit method gcj c github c gcj java github java dl cais .
.
.
.
pbnn .
.
.
.
toshowtheimpactof in adversary whengeneratingadversarial examples we consider dl cais on the gcj c dataset whilenotingthatasimilarphenomenonisobservedfortheother dlmodels.table5summarizestheattacksuccessratesofdl cais with .weobservethatwhenincreasing from1to5 the attack success rate increases from .
to .
for the targeted attackandfrom45.
to90.
fortheuntargetedattack.thisindicatesthatapplyingmorecodetransformationscanincreasethe success of imitating or hiding coding styles.
insight .
existing dl based attribution models are far from robust against the known and new attacks the success rate of the untargeted attack is much higher than that of the targeted attack because the attacker has more options in the former case.
.
robustness of ropgen rq2 toevaluatetheeffectivenessofropgen enabledauthorshipattribution methods against known and new attacks we train eight ropgen enabled models involving two dl based methods on four datasets.
we choose the hyperparameters leading to the best ac curacy.
take ropgen enabled dl cais on the gcj c datasetas an example.
the main hyperparameters are the batch size is the learning rate is .
the number of recurrent neural networklayersis3 thewidthlowerbound is0.
andthenumberofsub networksis3.weset 3forgeneratingadversarial examples.
table6showstheaccuraciesofeightropgen enabledmodels.
we observe that the average accuracy of the ropgen enabled dlcais models is2.
higher than thatof the dl based modelsand the average accuracy of the ropgen enabled pbnn models is .
lowerthanthatofthedl basedmodels indicatingastrongimpact of the attribution method.
table summarizes the attack success rates of ropgen enabled methods against attacks.
compared with dl based attributiontable7 attacksuccessratesofropgen enabledattribution methods metrics unit method gcj c github c gcj java github java targeted attacks by exploiting adversarial examples asrtar ropgen enabled dl cais .
.
ropgen enabled pbnn .
.
targeted attacks by coding style imitation asrtar ropgen enabled dl cais .
.
.
.
ropgen enabled pbnn .
.
.
.
untargeted attacks by exploiting adversarial examples asrunt ropgen enabled dl cais .
.
ropgen enabled pbnn .
.
untargeted attacks by coding style hiding asrunt ropgen enabled dl cais .
.
.
.
ropgen enabled pbnn .
.
.
.
methods ropgen enabled methods can reduce the success rates of targeted and untargeted attacks based on exploiting adversarial examples and coding style imitation hiding respectively by .
and .
on average.
this means that the ropgen significantly improves the robustness of dl based attribution methods against attacks which can be attributed to the data augmentation and gradientaugmentationforlearningrobustcodingstylepatterns.bytakingpbnnonthegcj c datasetasanexample weobservethe following.
for pbnn the training phase takes .
seconds for ropgen enabled pbnn the training phase takes seconds including .
seconds incurred by data augmentation and gradient augmentation .
this extra training cost is paid for gaining robustness whilenotingthatthetestcostisalmostthesame i.e.
.010vs.
.012seconds .sincewedonotneedtotrainmodelsoften our method is arguably practical.
to study the contribution of data augmentation and gradient augmentation to the effectiveness respectively we conduct the ablation study to investigate their effects including three methods.
thefirstmethodisthatweexcludeextendingthetrainingsetby coding style imitation denoted by ci namely the set pof training programs is directly input to the full fledged network of step .
thesecondmethodisthatweexcludethegradientaugmentation denotedby ga namelytheextendedtrainingset uobtained from step and the set u primeof manipulated programs generated from step together are input to the deep neural network.
thethirdmethod is that we exclude both coding style perturbation andgradientaugmentationfromropgen denotedby cp ga namelytheextendedtrainingset uobtainedfromstep1isinput to the deep neural network.
table presents the results of applying dl cais to the gcjc dataset.
we observe that the ci method can reduce the successrateofuntargetedattacksbyexploitingadversarialexamples butarenotveryeffectiveagainsttargetedattacksbyexploiting adversarial examples and coding style imitation and hiding attacks.
the cp ga methodcangreatlyreducethesuccessrateofcoding style imitation and hiding attacks but are not effective against attacks by exploiting adversarial examples.
the ga method can reduce the successrate of boththe coding style imitationand hiding attacks and the attacks by exploiting adversarial examples but are not as effective as ropgen.
on average ropgen remarkablyimproves the baseline with a .
lower success rate of the targetedattackanda54.
lowersuccessrateoftheuntargetedattack authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa zhen li guenevere qian chen chen chen sharp yayi zou shouhuai xu table ablation analysis results for dl cais on the gcjc dataset metrics unit methodadversarial examples coding style imitation hiding asrtarasrunt asrtar asrunt ropgen .
.
.
.
ci .
.
.
.
ga .
.
.
.
cp ga .
.
.
.
baseline .
.
.
.
table attack success rates of ropgen enabled dl cais for different on the gcj c dataset metrics unit attack type 1 3 targeted attack .
.
.
untargeted attack .
.
.
owing to the incorporation of data augmentation and gradient augmentation.
we evaluate the impact of in attacks exploiting adversarial examplesontheeffectivenessofropgen enabledmethods.table9 presents the attack success rate of ropgen enabled dl cais on the gcj c dataset with .
we observe that the attack success rate increases with exhibiting a similar phenomenon to dl cais onaverage theattacksuccessrateoftheropgen enableddl caismethodfortargetedanduntargetedattacksimproves1.
and23.
with respectively comparedwiththedl caismethod .thisshowstheeffectivenessofropgen enabledmethods against the attacks that exploit adversarial examples.
insight2.
ropgen enabledauthorshipattributionmethodsare substantially more robust than the original dl based methods.
inparticular the success rate of targeted and untargeted attacks on ropgen enabled methods is respectively reduced by .
and .
on average.
.
comparing adversarial trainings rq3 to compare the effectiveness of ropgen enabled attribution methodswithotheradversarialtrainingmethods weconsidertwoadversarialtrainingmethodsfromtext sourcecodeprocessingand image classification as baselines since there have been no defense methods against code authorship attribution attacks so far.
the firstmethodisbasicadversarialtraining whichiswidelyusedin text processing and source code processing .
the basic idea is to generate a set of adversarial examples and adding them to the training set.
we test two kinds of adversarial examples.
one is the adversarial examples generated by denoted by basic atae the other one is the combination of the adversarial examples generated by and the programs generated by imitating the coding styles of the authors in a denoted by basic at com .
thesecondmethodispgd at whichisawidely usedbaseline inimageclassification.itimprovestheadversarialrobustnessbysolving the composition of an inner maximization problem andan outer minimization problem.
when used to code authorship attribution pgd at has an extremely large search space to search forthecodingstyletransformationwiththemaximumlossforatable10 accuraciesofdl caiswith4adversarialtraining methods on gcj c and github c datasets metrics unit method gcj c github c none .
.
basic at ae .
.
basic at com .
.
pgd at .
.
ropgen .
.
table attack success rates of dl cais with adversarialtrainingmethodsonthegcj c andgithub cdatasets metrics unit method gcj c github c targeted attacks by exploiting adversarial examples asrtar none .
.
basic at ae .
.
basic at com .
.
pgd at .
.
ropgen .
.
targeted attacks by coding style imitation asrtar none .
.
basic at ae .
.
basic at com .
.
pgd at .
.
ropgen .
.
untargeted attacks by exploiting adversarial examples asrunt none .
.
basic at ae .
.
basic at com .
.
pgd at .
.
ropgen .
.
untargeted attacks by coding style hiding asrunt none .
.
basic at ae .
.
basic at com .
.
pgd at .
.
ropgen .
.
program.weusethecodingstyletransformationofasinglecoding style attribute instead.
table shows the accuracies of dl cais method with four adversarial training methods on the gcj c and github c datasets whilenotingthatpbnnexhibitssimilarphenomena.weobserve thattheaccuraciesoftheseadversarialtrainingmethodscomeclose to each other which means these methods have little effect on the accuracy.
table shows the attack success rates of dl cais with four adversarial training methods.
for basic at ae andpgd at methods the success rate of targeted and untargeted attacks by exploitingadversarialexamplesisaveragely4.
and8.
lowerthan the original dl cais because a number of manipulated programs with small perturbations are used to improve the model.
however thesuccessrateofcodingstyleimitation hidingattacksisevena little worse than the original dl cais on some datasets which means directly extending the training set by programs with small perturbations cannotdefend codingstyle imitation hidingattacks.
forbasic at com method thesuccessrateofcodingstyleimitation and hidingattacks is .
and .
lowerthan the original authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ropgen towards robust code authorship attribution via automatic coding style transformation icse may pittsburgh pa usa dl cais on average.
however the success rate of attacks by exploitingadversarialexamplesisevenalittleworsethantheoriginal dl caisonsomedatasets whichmeansthetrainingsetextension with the adversarial examples and the coding styles imitation of otherauthorscannotdefendtheattacksbyexploitingadversarial examples.
compared with the original dl cais method ropgen can reduce the average success rate of targeted and untargeted attacksbasedonexploitingadversarialexamplesby8.
and18.
respectively andreducetheaveragesuccessrateoftargetedand untargetedattacksbasedoncodingstyleimitationandhidingby .
and .
respectively.
this attributes to the coding style imitationofotherauthors thecodingstyleperturbation andthe gradient augmentation.
insight .
owing to the data augmentation and gradient augmentation ropgensubstantiallyoutperformstheotheradversarial training methods for attacks by both exploiting adversarial examples and coding style imitation hiding.
limitations thepresentstudyhasseverallimitations.
first wefocusonimprovingtherobustnessofsourcecodeauthorshipattributionmethods forasingleauthorowingtoitspopularity butthemethodologycan be adapted to cope with the dl based multi authorship attribution methods.
experiments need to be conducted formulti authorship attribution methods.
second to evaluate the effectiveness of ropgenfordl basedattributionmethodswithdifferentlanguages we usetwoopen sourceandlanguage agnosticdl basedattribution methods for evaluation.
future studies should investigate other dl based attribution methods for certain programming languages.
third though the ropgen framework is promising there is much room for pursuing robust code authorship attribution.
future researchshouldinvestigateothermethodstofindthebestpossible result in defending against attacks.
fourth for coding style imitation hiding attacks we focus on automatic attack methods against code authorship attribution owing to their reproducibility.
it is an interesting future work to investigate whether manual transformation is more powerful than automatic transformation while noting i the manual transformation needs institutional review boards irb approval and ii the results would depend on the coding skill ofprogrammers.
fifth wedonotknowhowtorigorouslyprove the soundness of various program transformations but our empiricalresultsprovidesomehints.
sixth itisimportanttoassurethe adequacy of threat models.
related work prior studies on non adversarial source code authorship attribution.
prior studies on non adversarial authorship attribution can be divided into two categories single authorship attribution vs.multiauthorship attribution .therearethreeapproachestononadversarialsingle authorshipattribution i the statistical approachaimstoidentifyimportantfeaturesfordiscriminantanalysis ii the similarity approach uses rankingmethods to measure the similarity between test examples and candidate examples inthefeaturespace iii the machinelearning approach achieves attribution via random forests support vectormachines anddeep neuralnetworks .
whereas multi authorshipattributionisstilllargelyopen .
when compared with these studies we focus on adversarial singleauthorship attribution.
priorstudieson adversarial sourcecodeauthorshipattribution.therearetwoattacksagainstauthorshipattribution which exploitadversarial examples orcoding style imitation hiding.
the former performs functionality preserving perturbations to a target program to cause misattribution .
the latter can be characterized by what the attacker knows i.e.
black box vs. white box andwhattheattackerdoes i.e.
manualmimicryattacks vs.semi automaticallyorautomaticallyleveragingweaknesses of an attribution method .
the most closely related priorstudyis whichpresentsawhite boxattackleveraging human defined features of the code authorship attribution method.
incontrast ropgendealswithblack boxattackswhichdonotknow or need such information.
the present study is complementary or orthogonal to because we focus on coping with black box attacksagainstdl basedattributionmethods whereas cannot deal with dl based attribution methods because automatically learned features are not human defined or human understandable.
prior studies on adversarial training.
from a technical standpoint ropgen leverages adversarial training .
the basic idea is to augment training data with adversarial examples analogous to vaccination .
this approach has been extensively investigated in a number of applications including image processing neural language processing malware detection and source code processing e.g.
functionality classification method variable name prediction and code summarization .tothebestofourknowledge ropgen isthe first robustnessframework for copingwith attacks against source code authorship attribution.
conclusion wepresentedtheropgenframeworkforenhancingrobustnessofa rangeofdl basedsourcecodeauthorshipattributionmethods.thekeyideabehindropgenistolearncodingstylepatternswhichare hard tomanipulate orimitate.
thisis achievedby leveragingdata augmentation and gradient augmentation to train attribution models.
we presented two automatic coding style imitation and hiding attacks.
experimental results show that ropgen can substantially improve the robustness of dl based code authorship attribution.
the limitations of the present study discussed in section provide interesting problems for future research.