neural program repair with execution based backpropagation he ye heye kth.se kth royal institute of technology swedenmatias martinez matias.martinez uphf.fr universit polytechnique hauts de france france kth royal institute of technology swedenmartin monperrus martin.monperrus 4open.science kth royal institute of technology sweden abstract neural machine translation nmt architectures have achieved promising results for automatic program repair.
yet they have the limitation of generating low quality patches e.g.
not compilable patches .
this is because the existing works only optimize a purely syntactic loss function based on characters and tokens without incorporating program specific information during neural network weight optimization.
in this paper we propose a novel program repair model called rewardrepair.
the core novelty of rewardrepair is to improve nmt based program repair with a loss function based on program compilation and test execution information rewarding the network to produce patches that compile and that do not overfit.
we conduct several experiments to evaluate rewardrepair showing that it is feasible and effective to use compilation and test execution results to optimize the underlying neural repair model.
rewardrepair correctly repairs bugs over four benchmarks.
we report on repair success for bugs that are fixed for the first time in the literature.
also rewardrepair produces up to .
of compilable patches an improvement over the by the state of the art.
acm reference format he ye matias martinez and martin monperrus.
.
neural program repair with execution based backpropagation.
in 44th international conference on software engineering icse may pittsburgh pa usa.
acm pittsburgh pa usa pages.
introduction automatic program repair apr aims to reduce manual work related to bug localization and bug fixing .
with recent advances in deep learning research has been proposed to use neural networks for program repair a subarea of a trend on using machine learning on code .
this line of work put here under the umbrella term neural program repair mostly uses neural machine translation nmt approaches .
program repair systems based on neural machine translation treat the repair task as a translation from buggy code to correct code both represented as a sequence of tokens .
given sufficient training data nmt based repair has achieved promising performance .
all the prior works on program repair based on neural machine translation use the static loss function cross entropy loss based on token similarity.
this work is licensed under a creative commons attribution international .
license.
icse may pittsburgh pa usa copyright held by the owner author s .
acm isbn .
early successes nmt based program repair approaches suffer from two major drawbacks.
first they often generate patches that do not compile .
the reason is that a lower cross entropy value does not necessarily lead to a compilable patch.
second the loss function under optimization forces the neural network to learn to produce absolutely identical patches thus missing the opportunity to explore semantically equivalent.
however rabin et al.
made the case that generalizability in machine learning on code relates to generalization over equivalent programs.
both problems uncompilability and being stuck with syntactic identity share the same root there is a discrepancy between the core training objective learning to generate compilable and correct patches and the loss function that is being optimized.
the cross entropy loss used in related work requires a strict pairwise matching between the generated patch and the human written ground truth patch and not more .
nothing in cross entropy loss encourages the neural network to produce compilable or syntactically different but semantically equivalent patches.
this is the problem we address in this paper.
we introduce a novel neural repair model called rewardrepair based on a mixed learning objective.
the key insight in the design of rewardrepair is the combination of a syntactic training objective at the token level and a semantic training objective based on program execution.
rewardrepair defines a discriminator to discriminate good patches from low quality ones during the training of the neural network.
the discriminator is based on executing the compiler and running the test cases on the generated patches providing high qualified execution feedback on their quality.
this feedback is transformed as a quantified reward signal that modulates the cross entropy loss.
then the neural network s weights are updated based on this novel discriminator.
in other words in rewardrepair backpropagation embeds essential compilation and execution information.
we conduct large experiments to evaluate rewardrepair based on four well accepted datasets from the literature including defects4j version .
defects4j version .
bugs.jar and quixbugs .
first we show that rewardrepair produces more correct patches than the recent related work.
in total rewardrepair repairs on the four benchmarks.
rewardrepair achieves an improvement in two benchmarks defects4j v2.
and bugs.jar and achieves the top performance in the other two benchmarks defects4j v1.
and quixbugs.
second we demonstrate that rewardrepair outperforms the state of the art on addressing the compilability problem in neural program repair cure by producing a higher ratio of compilable patches in all considered beam size configuration .
versus in top and .
versus in top candidate patches .
ieee acm 44th international conference on software engineering icse icse may pittsburgh pa usa he ye matias martinez and martin monperrus to sum up our contributions are we devise rewardrepair a neural program repair approach with execution based backpropagation.
rewardrepair defines a novel training objective that employs compilation and test execution information to optimize the neural network.
we perform an original series of experiments to show that rewardrepair outperforms the cross entropy loss used in related work.
our experimental results demonstrate that embedding execution information in backpropagation improves the quality of generated patches more compilable patches and correct patches .
we provide evidence that rewardrepair can correctly fix bugs for defects4j v1.
bugs for defects4j v2.
bugs for bugs.jar and bugs for quixbugs.
we report that reparrepair can correctly fix bugs that were never repaired in previous literature including unique defects4j v1.
bugs.
we make our data and code publicly available for future research .
background .
neural program repair neural machine translation nmt systems have recently achieved state of the art performance on program repair tasks forming a field called neural program repair .
despite the difference in their inputs and neural models those works are similar in the sense that they are all based on a typical nmt model formulated as an encoder decoder attention architecture optimized with cross entropy loss function .
all the prior works on program repair are based on the nmt architecture with a cross entropy loss function to update the neural network weights .
the cross entropy loss a.k.a.
log loss is a measure from information theory building upon entropy and calculating the difference between two probability distributions .
during the training of a neural repair model the cross entropy loss calculates the difference between the generated tokens and the human written patch tokens in a strict pairwise matching manner and is used to update the neural network weights by backpropagation.
in program repair patches a low cross entropy value means that the generated patch is syntactically close to the ground truth patch at the token level.
.
limitations of current neural repair the token based cross entropy loss optimization is effective at guiding the model to generate patches syntactically identical or close to the human written patches given as input during training.
however it suffers from two major limitations.
firstly a major goal in patch generation is to generate well formed patches that compile.
unfortunately the cross entropy loss does not favor patches that compile over non compilable patches.
even worse if a generated patch has a significantly lower loss per the token based cross entropy although being non compilable it would be favored by the model at training time.
secondly the cross entropy loss function fails to learn from semantically equivalent patches a syntactically different but semantically equivalent patch could potentially have a high cross entropy loss value.
this means that the cross entropy loss return fastmath.pow fastmath.pi dim return fastmath.pow fastmath.pi .
dim a the human written patch return fastmath.pow fastmath.pi d dim loss value .
b a generated non compilable patch receives a smaller loss score return fastmath.pow fastmath.pi dim 2d loss value .
c a generated semantically equivalent patch receives a bigger loss score listing motivating example nmt based repair models based on cross entropy loss may favor non compilable patches.
discourages the network to explore equivalent solutions.
in the field of neural machine translation nmt this problem is known as the overcorrection problem of cross entropy loss crossentropy based models tend to learn strictly identical translations and to overcorrect synonymous tokens which would be acceptable.
overall the problem we address in this paper is that the crossentropy loss used in previous research cannot learn programming knowledge beyond tokens.
.
motivating example listing is a motivating example to show the drawbacks of a neural repair model based on cross entropy loss optimization.
listing 1a presents the buggy code and the human written patch for bugmath from defects4j v1.
.
listing 1b gives one generated non compilable patch because of the undefined variable d. the network generates this patch with maximum likelihood estimation because its cross entropy loss value is low .
.
listing 1c is a semantically equivalent patch compared to the human written patch and its computed loss is .
which is higher than the non compilable patch.
with cross entropy loss the nmt based repair model penalizes the semantically equivalent patch and favors the non compilable patch.
this is because there is only one token difference for the generated non compilable patches where the wrong token dis not the expected token .5from the ground truth patch.
however the tokendis an undefined variable in the buggy program.
on the contrary there exist three token differences in the semantically equivalent patch dim .
2d dim .
consequently the nmt based repair model considers the generated non compilable patch is closer to the human written patch and thus should be favored during backpropagation.
however in the context of program repair the semantically equivalent patch should have a loss close to zero because it is a valid solution to the bug.
the generated non compilable patch has a lower loss but still cannot satisfy the compiler which is inconsistent with our goal.
this example shows the fundamental limitation of optimizing neural networks with the traditional token based cross entropy loss for the program repair task.
1507neural program repair with execution based backpropagation icse may pittsburgh pa usa syntactic training semantic t rainingcrossentropy losscandidate patchespatch generator weights update with backpropagationexpected output training input patch generator weights update with backpropagationbuggy codehuman patch training data point pair buggy codehuman patch training data point tuple app training input rewardrepair lossplausible discriminatorregression discriminator no change penaltycompilable rewardplausible rewardlikely correct rewardy y y non compilable penaltyy difference discriminatorcompilability discriminator buggy code app y nexecution execution reward v alues r discriminative model of rewardrepaircandidate patches compilable bug fix patches executable tests bug fix patches code only expected output inference bugs under actual repair patch generator suggested patches inference data point buggy codeinference inputn n n figure an overview of rewardrepair.
rewardrepair .
overview in this paper we propose a novel neural repair model called rewardrepair.
the core idea of rewardrepair is to improve the learning process of neural program repair and in particular to address the limitations of using the cross entropy loss function at the tokenlevel.
figure gives an overview of rewardrepair.
the top middle and bottom parts represent three stages of rewardrepair syntactic training semantic training and inference.
rewardrepair is trained with two datasets respectively a syntactic training dataset with pairs of buggy and patch code and a semantic training dataset.
they are fundamentally different.
the syntactic training dataset only consists of textual patches as in the related work .
however the requirements for the semantic training dataset are full execution each sample in the dataset comes with a compiler configuration and test cases.
achieving full execution enables us to derive execution based information to be used for optimizing the neural network weights with programming knowledge during backpropagation.
syntactic training is our first training phase.
we train rewardrepair to optimize the cross entropy loss based on a large bug fix corpus per the related work .
syntactic training is meant to provide a good initial model for semantic training.
semantic training is our second phase after sufficient syntactic training.
semantic training is used alternately with syntactic training.
semantic training is based on a discriminative model.
the discriminative model of rewardrepair analyzes the candidate patches with four discriminators difference discriminator compilability discriminator plausibility discriminator and regression discriminator and modulates the cross entropy loss before the start of backpropagation on training.
the inference is the final phase.
once rewardrepairhas been trained it can generate patches for new and unseen bugs based on the trained patch generator.
.
code representation as code representation we follow lutellier et al.
to represent the buggy code and context code as two separate token sequences.
in rewardrepair the context code is considered as lines of code surrounding the buggy code.
in addition the context code is enriched with a summary of the buggy class as proposed by chen et al.
as follows we keep all the instance variables and their initializers along with the signature of the constructors and methods.
we follow the existing work to use subword tokenization with sentencepiece as demonstrated useful by karampatsis et al.
.
.
patch generator in rewardrepair the patch generator is trained in a supervised manner based on an encoder decoder architecture .
syntactic training takes as input buggy code tokens b b0 b1...bn context code tokens c c0 c1...cm and tokens from the ground truth fix patch f f0 f1...ft .
rewardrepair transforms the b andcinto a predicted patch f f f ...f k .
note that size of the buggy code context code ground truth patch and predicted patch i.e.
n m tandk can be different.
in rewardrepair patch generation is shared by both syntactic training and semantic training.
.
syntactic training of rewardrepair rewardrepair initially trains the patch generator with cross entropy loss function per the state of the art of nmt for program repair .
for each training point the optimization target is to minimize the loss between ground truth fix patch fand 1508icse may pittsburgh pa usa he ye matias martinez and martin monperrus the predicted patch f .
as shown in the previous study syntactic training is trained with a large corpus of buggy code and fixed code pairs.
syntactic training could be trained for multiple epochs to achieve convergence and obtain the best combination of weights.
by the end of syntactic training the patch generator s weights between the connections of the networks are optimized.
.
semantic training of rewardrepair the goal of semantic training is to let the patch generator be aware of program specific knowledge compilation and execution beyond the syntactic loss computation at the token level.
for that we propose a mixed learning objective where mixed means that the core learning objective is combined with two or more sublearning objectives.
our mixed learning objective combines the core cross entropy objective with compilation and execution information.
once the rewardrepair has been sufficiently trained with syntactic training we start the semantic training process alternately with syntactic training.
for semantic training rewardrepair employs a discriminative model to assess the quality of generated patches based on compilation and test oracles.
as a result the discriminative model outputs a reward value that quantifies the patch quality which is used to adjust the weights of the patch generator during backpropagation.
a higher reward means better quality for the generated patch e.g.
the patch is compilable and passes all test cases.
on the contrary a lower reward means that the quality of the generated patch may be unsatisfying e.g.
the patch is non compilable.
precisely the patch reward value modulates the token level loss value before the start of the backward pass so that the updated loss can then be properly represented with programspecific knowledge.
in such a way the discriminator guides the neural network to generate high quality patches.
to our knowledge we are the first to introduce semantic training based on a patch discriminative model for neural program repair.
.
.
discriminative model.
in machine learning a discriminator is a model for identifying good and bad predictions .
the discriminator of rewardrepair is the key component of the semantic training phase.
its goal is to measure the quality of the generated patches which is then quantified as a reward signal.
in rewardrepair the discriminative model is composed of four discriminators each of them specialized in one aspect of patch quality.
these four discriminators are serially executed.
each discriminator does a binary classification whether a patch fulfills the discriminator s criterion or not.
when a discriminator is affirmative it means the patch passes the quality criterion and it is passed to the next discriminator.
in the rest of this section we present the four discriminators of rewardrepair.
difference discriminator.
the difference discriminator validates whether the generated patches are different from the given buggy code.
it is required because we found that neural repair models regularly generate a patch that is identical to the given buggy code i.e.
the output of the model is identical to the input of the model called a no change patch in this paper .
this happens when the neural nets discover that the buggy code achieves the maximum likelihood estimation.
this is explained by previous research which has shown that the many buggy codes are similar to correct code with only minor transformations and few changed tokens.
consequently the generator tends to copy the buggy code because it is the maximum likelihood prediction per the data seen at training time.
we design the difference discriminator to syntactically compare the generated patch code with the input buggy code with a token sequence comparison.
if the buggy code and generated patched code are the same the difference discriminator assigns the generated patch a penalty called in this paper the no change penalty rno change i.e.
a negative reward.
this penalty signal modulates the rewardrepair loss to avoid the generation of nochange patches.
compilability discriminator.
the compilability discriminator validates whether the generated patches are compilable.
as shown in previous research neural repair models suffer from outputting non compilable patches.
for example the golden sequencer model produces .
of patches that are not compilable in top candidate patches.
to force the generator towards producing compilable patches we introduce a compilability discriminator in the semantic training phase.
the compilability discriminator employs the compiler to compile the generated patched program.
if the patched program is compilable rewardrepair assigns a compilable reward rcompilable and passes the patch to the next discriminator for further assessment.
otherwise a non compilable penalty rnon compilable i.e.
a negative reward is returned to the rewardrepair model.
plausibility discriminator.
the plausibility discriminator aims at encouraging the generator to produce patches that pass the humanwritten test cases provided by developers.
recall that per the seminal work on program repair test cases can be used as an executable program specification.
in other words if a patch passes the human written tests it is considered as a plausible patch.
during semantic training rewardrepair is trained on buggy projects with executable human written tests.
each candidate patch is executed against the human written tests.
if a patch makes all human written tests pass a plausible reward rplausible is assigned.
by so the plausibility discriminator leverages the human written tests to drive the network to produce plausible patches that pass all human written tests.
regression discriminator.
the last discriminator used in rewardrepair s discriminative model is the regression discriminator.
the goal of this discriminator is to minimize the behavioral changes introduced by the patch.
this discriminator complements the plausible patch discriminator by specifying behavior outside the humanwritten tests in order to avoid patch overfitting .
the rewardrepair regression discriminator employs automatically generated tests per the rgt technique of ye et al.
.
the effectiveness of this technique to identify correct patches from plausible patches has been shown in recent work .
the idea of the rgt technique is to automatically generate test cases based on the ground truth patched program to expose program execution behavior differences between a generated patch and a ground truth patch .
if a candidate patch makes all rgt tests pass i.e.
it does not contradict the ground truth program behavior it is considered as likely correct.
1509neural program repair with execution based backpropagation icse may pittsburgh pa usa during semantic training all patches are executed against the rgt tests.
if a candidate patch makes all automatically generated tests pass meaning the same program execution behavior with ground truth program then a likely correct reward signal rl correct is assigned to this patch.
this discriminator s reward is used to encourage the rewardrepair to avoid regressions.
this means we encourage rewardrepair to generate non overfitting patches beyond the existing test cases.
.
.
defining reward values from discriminators.
as shown previously rewardrepair defines five reward signals for patch quality assessment.
the discriminators are executed serially that is if a patch does not satisfy one discriminator then the reward robtained up to that moment is returned immediately and other discriminators are not executed.
consequently the ris the maximum of the five reward values as follows r max rno change s0 rnon compilable s1 rcompilable s2 rplausible s3 rl correct s4 wheresi i are five scaling parameters that control the range of the reward values.
the scaling parameters of sidefine a configuration space that is controlled by end users of rewardrepair.
additionally those reward values must fulfill the following constraint rno change rnon compilable rcompilable rplausible rl correct where the higher reward value represents the better quality of the generated patch.
given the cross entropy l the loss function of rewardrepair lrewardrepair dynamically reweighs lwith respect to the discriminator s reward signal r which encodes the quality of the generated patch.
we follow to formulate rewardrepair loss function as a scaling of the cross entropy as follows lrewardrepair r l where r the reward modulator r constrains the domain of r as it is meaningless for the objective function to minimize a negative loss.
in this formulation the syntactic cross entropy at the token level is combined with the semantic reward at patchlevel embedding compilation and execution knowledge deep into the neural model.
it mitigates the limitations of only considering cross entropy loss in program repair tasks and solves the problem discussed in section .
.
for low quality patches rewardrepair assigns a penalty i.e.
negative reward value to increase the original cross entropy loss l. thus the domain for rno change rnon compilable .
on the contrary for the high quality patches rewardrepair scales down the originallby assigning positive reward values for rcompilable rplausible andrl correct to encourage the model.
the domain for these three reward values is .
based on equation the higher the reward the smaller computed loss is back propagated into the neural model.
the extreme case is the highest reward value approximate to where the rewardrepair loss goes close to .
this indicates that the generated patch is likely correct and the network should not be changed.algorithm one step of semantic training in rewardrepair input buggy code b context code c ground truth patch code p human written test casesth rgt test cases tm learning rate g is the rewardrepair patch generator d is the discriminator function eb b encode buggy code ec c encode context code ep p encode ground truth patch code eq g eb ec generate candidate patch l x xep x logeq x r d eb ec eq th tm lrewardrepair r l g g lrewardrepair g update patch generator with backpropagation combining the domain constraints discussed above the range of scaling parameters simust meet the following criteria s0 s1 s0 si si si i .
.
algorithm.
algorithm presents one step of semantic training.
given the encoded buggy eband context code ec line and the patch generator ggenerates a candidate patch line .
then the cross entropy loss lis computed by comparing the token distribution between the ground truth patch epand the generated patch eq line where the xindicates the index of tokens.
the discriminator provides a reward rbased on generated patch eqand the corresponding program compilability and test execution information line .
lastly rewardrepair combines the cross entropy loss at tokenlevel and reward value at patch level to form rewardrepair loss line which encodes the program specific knowledge.
.
inference at inference phase for a given suspicious statement found by fault localization tools e.g.
ochiai rewardrepair represents it with two sequences of tokens one for the suspicious statement the other one for its context see section .
.
those tokens are given to the patch generator of rewardrepair previously trained as explained in sections .
and .
.
as rewardrepair is configured by the inference beam sizen see it outputs the nbest patches for that suspicious statement.
rewardrepair can be used with any fault localization technique in real world bug repair tasks as shown by .
.
implementation we implement rewardrepair s patch generator with the state ofthe art transformer based architecture from hugging face.
rewardrepair is trained with syntactic training epochs and semantic training epochs.
for hyper parameters configuration we use a vocabulary size of .
we configure rewardrepair to take a maximum of 512input tokens from buggy and context code and generate a patch with a maximum of 100tokens.
the learning rate sets to 1e 4for both syntactic and semantic training.
we configure reward scaling values si i respectively to .
.
.
.
.
for the best experiment result.
the encoder and decoder consist of layers.
rewardrepair is configured by a beam size of 200and outputs the 200best patches per bug.
we consider the beam 1510icse may pittsburgh pa usa he ye matias martinez and martin monperrus phases requirements name source patches syntactic trainingtokenizationcoconut megadiff codrep semantic trainingtokenization compilationbears 123developer and rgt tests testingtokenization compilation developer testsdefects4j v1.
defects4j v2.
bugs.jar quixbugs table datasets used for the different steps of our experiment.
size of 200rather than used in cure and coconut due to the limitations of our available gpus.
experimental methodology in this section we describe our methodology for evaluating rewardrepair by defining three research questions and how we propose to answer them.
.
research questions rq1 comparison with other tools to what extent is rewardrepair effective at repairing bugs compared with the state of the art repair approaches?
rq2 compilable rate to what extent does rewardrepair improve the compilability of generated patches?
rq3 impact of semantic training to what extent does semantic training improve the effectiveness of rewardrepair?
.
dataset recall that we need three datasets for syntactic training semantic training and testing.
we have common criteria for both training and testing datasets all datasets are composed of bug fix patches we focus on singlehunk patches where the patch is confined to a single contiguous chunk of code at a single location per previous work we discard patches that do not make program behavior differences e.g.
those with only changes in comments or logging.
next we have specific requirements per dataset.
table shows the dataset of patches that we use for training and evaluating rewardrepair.
the first column indicates the phase where each dataset is used.
the second column gives the requirements for each dataset.
the third column gives the source of the dataset and the fourth column indicates the number of patches in this dataset.
for example as shown in the first row rewardrepair is syntactically trained with data from three different sources coconut megadiff and codrep .
as aforementioned in section the selection criteria for semantic training dataset are to be able to compile the patched program to run the test cases on the patched program to be able to automatically generate tests to specify the expected program behavior.
all criteria are met for single hunk bugs of the bears dataset for which some available rgt tests were generated by previous research .
it is to be noted that those criteria are verystrong and neither coconut megadiff nor codrep meets them in particular the patched program cannot be compiled.
to test rewardrepair we use well accepted datasets from program repair research defects4j bugs.jar and quixbugs .
for all those bug datasets the requirements of compilation and test execution are met.
in line with the most recent work we also consider the bugs of defects4j version .
.
after filtering single hunk bugs we use bugs from defects4j v1.
and additional new bugs from defects4j version .
denoted as defects4j v2.
in our paper.
we use the same single hunk bugs criteria for bugs.jar and quixbugs.
.
methodology for rq1 in rq1 we compare rewardrepair against the state of the art neural repair approaches cure recoder coconut and other approaches .
per previous studies we take the quantitative results from the literature.
we run rewardrepair under two fault localization modes.
first we use spectrum based fault localization with gzoltar per previous work .
second we assume that the fault has been localized an evaluation technique known as perfect fault localization and extensively used in recent work .
we compute the two traditional apr performance metrics for each testing dataset the number of bugs that are correctly repaired.
in our paper a patch is deemed correctly repaired if it meets either of the two following criteria it is identical to the developer patch or it is considered as correct by manual analysis done by at least two authors the number of bugs that can be uniquely repaired by individual repair approaches.
.
methodology for rq2 in rq2 we calculate the compilable rate of rewardrepair.
as compilable rates were reported in sequencer coconut and cure we use the same benchmarks defects4j v1.
and quixbugs as they do and compare against the numbers reported in the original papers.
we also follow the existing work and compute the compilable rate depending on the beam size.
we report on beam sizes in and .
we do not consider larger beams due to the limitations of our available gpus.
.
methodology for rq3 in rq3 we conduct an ablation study with the goal of measuring the effect of semantic training.
to understand the contribution of semantic training we compare the effectiveness of rewardrepair considering only syntactic training both syntactic and semantic training.
for this study we apply the same protocol as the one used for responding to the rq1.
we conduct manual analysis on the unique bugs that are only repaired by including semantic training and present the most interesting categories on repair action changes.
experimental results .
rq1 comparative study with other repair approaches 1511neural program repair with execution based backpropagation icse may pittsburgh pa usa approaches d4j v1.
d4j v2.
bugs.jar quixbugs bugs bugs bugs bugs using spectrum based fault localization jgenprog nopol elixir sharpfix simfix hercules recoder rewardrepair this paper assuming perfectly localized fault sequencer dlfix tbar coconut cure recoder rewardrepair this paper rewardrepair unique table comparison of rewardrepair against the related work the numbers from the related work are filtered by single hunk bugs.
across all benchmarks rewardrepair correctly fixes bugs and uniquely fixes ones.
we use testing benchmarks to maximize generalizability.
if dataformatreaders !
null return detectbindandreadvalues dataformatreaders .
findformat src offset length false return bindandreadvalues considerfilter parserfactory.createparser src return bindandreadvalues considerfilter parserfactory.createparser src offset length true listing rewardrepair correct patch for defects4j v2.
jacksondatabind 57 table shows the patch generation results of rewardrepair and other apr approaches on four benchmarks the two versions of defects4j bugs.jar and quixbugs.
the numbers are the correctly repaired bugs by each apr approach.
the results are those reported in the literature by the authors of the tool or by subsequent comparative experiments .
a indicates that the apr approach has not been evaluated on the considered benchmark to the best of our knowledge.
note that the first seven apr approaches were executed with spectrum based fault localization fl where the later approaches assumed perfect fl.
we measure rewardrepair s effectiveness with both spectrum based and perfect fl.
next we focus on the comparison under perfect fl as the most state of the art techniques only report effectiveness with perfect fl.
repaired bugs.
overall rewardrepair is able to correctly repair of bugs on defects4j v1.
of bugs on defects4j v2.
of bugs on bugs.jar and of bugs on quixbugs benchmark.
from these results we make the following observations.
figure uniquely repaired bugs on defects4j v1.
.
private void removeunreferencedfunctionargs ... if !removeglobals return listing rewardrepair patch for closure from defects4j v1.
identical to the developer patch.
rewardrepair outperforms all apr approaches in two benchmarks defects4j v2.
and bugs.jar.
rewardrepair sets new baselines of repaired bugs for these two benchmarks.
while the majority of apr papers showcase bugs from version .
or .
of defects4j listing gives the correct rewardrepair patch for a defects4j v2.
bug jacksondatabind 57 .
as shown rewardrepair succeeds in reusing the surrounding variables offset andlength to construct the parameter list for overridden method createparser .
recoder which is so far the best tool evaluated on defects4j v2.
fails at repairing this bug.
in addition rewardrepair achieves the top performance on defects4j v1.
and quixbugs benchmarks.
rewardrepair performs better than all apr approaches on defects4j v1.
but recoder.
regarding recoder s performance on defects4j v1.
we analyze the bugs that cannot be repaired by rewardrepair.
we find that three bugs closure closure and closure require fixing tokens outside the considered buggy class and three bugs lang lang43andclosure require fixing tokens outside the context code scope as implemented by rewardrepair.
this analysis suggests that rewardrepair could achieve better performance by enlarging the context code scope.
regarding cure s performance on quixbugs the reason is likely the beam size recall that cure generates candidate patches for each bug while rewardrepair generates patches per bug.
as shown in previous research a larger beam size leads to more correct patches.
uniquely repaired bugs.
let us now focus on the last row of table which gives the number of uniquely repaired bugs by rewardrepair.
rewardrepair respectively repairs and unique bugs for defects4j v1.
defects4j v2.
bugs.jar and 1512icse may pittsburgh pa usa he ye matias martinez and martin monperrus model top top top sequencer coconut cure rewardrepair .
.
.
table average compilable rates of the top k candidate patches in defects4j v1.
and quixbugs.
indicates data unavailability.
quixbugs all of which were never repaired by any other apr approaches in the literature.
this shows rewardrepair complements all the existing works on the four considered benchmarks.
figure gives the detailed uniqueness analysis on defects4j v1.
with the state of the art apr approaches.
we give the exact results for the most recent neural repair approaches coconut cure and recoder .
we combine the rest of the top ranked related work in a unique bin for sake of readability.
as shown rewardrepair fixes unique bugs compared with the other apr approaches on defects4j v1.
.
notably they come from three different defects4j projects closure lang and math showing that the additional learned knowledge is not specific to one single domain.
listing gives the rewardrepair patch for closure which can only be fixed by rewardrepair.
this is a patch with an addition of an ifblock including the code of the then statement.
rewardrepair learns the ifcondition from the given context code.
while patternbased repair is able to synthesize conditions e.g.
tbar no pattern based repair systems have this complete if then return pattern.
the recent neural repair models coconut and cure do not generate this patch we suspect that with a strict token based cross entropy optimization recoder does not learn such a complex patch structure.
rewardrepair is the first to produce this additiononly patch based on a non trivial if then return structure.
generalizability .
durieux et al.
revealed the phenomenon of benchmark overfitting in program repair meaning that performance results reported in the apr literature do not generalize to other benchmarks.
the main reason is that apr approaches were typically evaluated in a single dataset in particular defects4j v1.
in java evaluation.
rewardrepair is evaluated on four benchmarks in order to maximize the generalizability of our claims.
to our knowledge this is one of the experiments with the largest number of testing benchmarks used for assessing the proposed repair approach.
answer to rq1 rewardrepair correctly fixes and bugs on the considered java benchmarks defects4j v1.
defects4j v2.
bugs.jar and quixbugs respectively.
there are unique bugs that are repaired by rewardrepair for the first time ever w.r.t.
the apr literature.
the external validity of our results is founded on testing benchmarks.
figure rewardrepair compilable rate on defects4j v1.
by project.
for formattingoption formattingoption flags .
formatting formattingoption .
applytooptions options if flags.process closure primitives options.closurepass true options.closurepass flags.process closure primitives initoptionsfromflags options return options listing rewardrepair correct patch generated for closure .
rq2 improvement of compilable rate table shows the average compilable rates of the top k candidate patches where k relates to the beam size.
for sake of a fair comparison we use the same methodology as jiang et al.
and we combine defects4j v1.
and quixbugs together our appendix website gives the results per benchmark .
we provide ranges for coconut and cure regarding the top results due to data unavailability the range is the bracket of compilable rates as reported in the original paper of cure .
notably the compilable rate of rewardrepair outperforms the three considered approaches cure coconut and sequencer for all beam size configurations.
in the best case rewardrepair achieves a compilable rate of up to .
which is the highest among the three considered beam sizes.
next we see that the compilable rate of rewardrepair decreases when we increase the beam size this result is consistent with the ones of cure and coconut.
since the beam enumerates by decreasing probability it suggests that the learned neural model does capture compilability and favors it.
recall that the key contribution of cure is to introduce two strategies to increase the patch compilable rate of nmt based neural repair models valid identifier checker strategy andlength control strategy .
both strategies work in the inference phase by filtering out the invalid tokens in the java code or patches that are not close in length to the buggy code.
this means that cure does not embed program specific knowledge in the neural network.
on the contrary rewardrepair learns this knowledge during semantic training.
that is if an invalid identifier is used during semantic training and results in a non compilable patch rewardrepair punishes the patch by increasing the loss.
beyond identifiers rewardrepair is also able to learn other programming knowledge during semantic training such as structure and typing constraints related to the domain classes 1513neural program repair with execution based backpropagation icse may pittsburgh pa usa compile errors no.
failures cannot find symbol illegal start of expression no suitable method constructor found for... incompatible types not a statement expected unreachable statement case default or expected incomparable types method x in class y cannot be applied to given types table analysis of top reasons for uncompilable generated patches.
model d4j v1.
d4j v2.
bugs.jar quixbugs total rewardrepair syntatic rewardrepair syntatic semantic table ablation study w.r.t correct patches.
and methods.
to some extent cure is limited to the static analysis checks devised and implemented by its authors while rewardrepair works in a fully agnostic data driven way to identify important compilation constraints.
we analyze the uncompilable patches from the top patches generated for defects4j v1.
.
we show the most frequent compilation errors in table .
if there are multiple errors for one patch we only count the first error per patch.
the first column gives the compilation error type and the second column shows the number of patches that fail on the corresponding error type.
we see most common error types are related to semantics that very few errors are related to syntax the first one being expected .
to overcome the typing problems this suggests some specific training on the project under repair to capture this missing knowledge .
listing shows the rewardrepair patch for bug closure from defects4j v1.
which is identical to the developer patch.
rewardrepair incorporates two repair actions in this patch first rewardrepair removes the if then condition.
second rewardrepair generates a new statement by combining the logical expression from the if condition and from the statement in the then block.
this is arguably a complex patch and no repair system has reported generating a patch for this bug.
this case shows that rewardrepair generates a compilable and correct patch with the complex structure.
cure fails to generate this patch because of its length control strategy that encourages patches similar to the buggy code in length.
figure shows the compilable rate of rewardrepair per project of defects4j v1.
with top and candidate patches according to beam.
we make the two observations as follows first for all projects increasing the beam size of rewardrepair decreases the compilable rate for each project.
this confirms the conclusion made in table at the level of aggregate results over bugs and benchmarks.
second the range of compilable rates over bugs decreases with beam size both the range of extreme values whiskers actions syntactic training semantic training add if conditions method invocation add return statement ternary operator for null checking table examples of repair action differences between syntactic training and semantic training of rewardrepair.
this.dataset dataset a buggy line .setdataset dataset patch setdataset patch b two non compilable patches by syntactic training setdataset dataset c correct compilable patch by semantic training listing bug chart only fixed by semantic training and the range of interquartile values boxes .
we explain this by statistical sampling sampling items yields less stable results than sampling .
however it may also be that the compilable rate does change significantly for some bugs.
this latter explanation is supported by the fact that there is a clear difference in compilable rate depending on the project lang patches compile much more than time patches .
this latter phenomenon the compilable rate significantly varying over projects in the worst case being is a yet unknown limitation of neural program repair and suggests more future research on this to increase the compilable rate in a more uniform way.
answer to rq2 for all considered beam sizes rewardrepair improves the compilable rate over the state of the art.
over all benchmarks rewardrepair reaches up to .
of compilable patches approximately one out of two patches compile showing that the rewardrepair neural model has captured important information w.r.t.
compilation.
.
rq3 impact of semantic training table shows the results of the ablation study w.r.t semantic training.
per the same protocol as rq1 the considered metric is the number of correct patches.
the first row shows rewardrepair s effectiveness with only syntactic training the second row shows rewardrepair with both syntactic and semantic training.
for example rewardrepair with only syntactic training generates correct patches on defects4j v1.
and rewardrepair with semantic training generates correct patches.
overall the addition of semantic training after syntactic training does yield more correct patches on all considered benchmarks.
this shows that semantic training addresses the limits of syntactic training and the improvement is not tied to specific benchmarks.
to better understand the effectiveness of semantic training we manually analyze those unique bugs that are only generated by rewardrepair by including semantic training and not generated with pure syntactic training .
this leads to an analysis of patches candidate patches by syntactic training and 1514icse may pittsburgh pa usa he ye matias martinez and martin monperrus candidate patches by semantic training .
we group those patches by category and summarize the most interesting categories in table .
the first column gives the type of repair action employed in the patch and the numbers in the second column and the third column indicate the numbers of patches based on those repair actions from syntactic and semantic training respectively.
for example the first row shows there are patches generated by syntactic training which add if then statements while semantic training yields patches using this construct.
this means that the usage of if then statements is increased by .
with semantic training.
notably the unique bugs that benefit from semantic training come from different projects showing that adding semantic training is beneficial in general.
recall that syntactic training is done on more than million training samples while semantic training is done on training samples which is much less.
this suggests that the improvement obtained with semantic training does not come from the number of additional training points but more from the training process described in section .
.
rewardrepair s loss function is able to better optimize the neural network improving the quality of generated patches with only a few training data points.
finally listing discusses the case of chart .
the first line is the buggy line.
next in part b two patches after syntactic training are shown they are both close to the correct patch but none of them compile extraneous dot in the first patch and missing parameter in the second patch .
finally part c shows the correct patch by rewardrepair with semantic training which is identical to the developer patch.
in this case it suggests that the neural model with semantic training has understood that leading dots before method calls is not correct per the java grammar and that setdataset is a method likely to take a parameter called dataset .
a subtle character may lead to a huge difference in program execution but this knowledge is hard to be obtained by syntactic training with cross entropy loss.
answer to rq3 our ablation study shows semantic training of rewardrepair contributes to improving the overall effectiveness in terms of correctly fixed bugs.
discussion .
impact of inference beam size we investigate the impact of beam search size in the inference time and our experiment shows a bigger beam size indeed leads to more correct patches generated which confirms the study of tufano et al.
.
we provide the results of configuring beam size as in our online appendix repository .
.
threats to validity a threat to external validity relates to whether the performance of rewardrepair generalizes to arbitrary programming languages.
per the standards of the field our approach has been tested in one language java and the evaluation is carried out on established benchmarks.
in principle our approach can be applied to other programming languages and datasets.
a threat to internal validity relates to the hyper parameter configuration we adopted.
to ensurereplicability and extension we make all the source code and results publicly available for future research .
related work .
automatic program repair a decade of research has generated a rich body of work on automatic program repair .
we have already discussed neural repair approaches in section .
these approaches only use the syntactic cross entropy loss objective which poses a discrepancy between the training objective of generating compilable correct patches and the loss criterion.
the key novelty of rewardrepair is the discriminative model to capture the compilation and execution knowledge during model training and backpropagation.
we mentioned generate and validate g v program repair approaches in rq1 section .
.
other notable g v systems include .
moreover the third line of research is about synthesisbased repair which converts the search problem to a satisfiability problem.
all these approaches often work by extracting a repair constraint typically via symbolic execution incorporated with human knowledge for patch generation.
on the contrary rewardrepair automatically learns such fix operators language grammar and semantics from the training corpus.
in the field of apr the recent work of jiang et al.
is the most closely related to ours also focusing on the non compilable patch problem.
they address this problem by employing a valididentifier checker in the inference stage to filter invalid tokens.
however many reasons could lead to a non compilable patch and the presence of invalid identifiers is only one of them.
our approach is fundamentally different rewardrepair works at training time and not at inference time rewardrepair is based on the actual compilation and test execution of training patches rewardrepair encourages syntactic diversity while cure encourages patches similar to the buggy code the length control strategy in cure .
.
discriminators for machine learning on code several works propose deep learning on code based on a discriminator where the discriminator provides a loss that solves the discrepancy between the generated and real distributions of the object under study as pioneered by generative adversarial networks gan .
harer et al.
propose an adversarial learning approach to solve software vulnerabilities.
alhefdhi et al.
leverage a similar gan architecture to suggest repairs that are as close as possible to human written repairs.
rewardrepair shares the concepts of employing a traditional nmt model as a generator and of replacing the cross entropy loss with the feedback from a discriminator.
the key difference between this related work and ours is that our discriminator uses execution information through compilation and test execution.
.
improving backpropagation past research has improved the cross entropy loss based on domainspecific knowledge.
in neural machine translation zhang et al.
1515neural program repair with execution based backpropagation icse may pittsburgh pa usa show the limitation of considering cross entropy loss and its tendency to overcorrect synonymous words and phrases.
to relieve the problem further research proposed to combine crossentropy loss and add translation evaluation at the sentence level.
in object detection ryou et al.
proposed anchorloss to dynamically rescale the cross entropy based on prediction difficulty.
loss scaling is a technique used in floating point optimization consisting of scaling up the loss value up before the start of backpropagation .
.
training based on execution recently semantic information has been used in program synthesis tasks.
chen et al.
and gupta et al.
propose executionguided synthesis leveraging the semantics of the language.
these approaches execute a partial program to obtain intermediate states to guide program synthesis.
wang et al.
use dynamic information from execution to measure semantic redundancy between student programs.
mesbah et al.
extract compiler diagnostic information as an input source for repairing compilation errors.
as in our work these approaches use execution information as an additional input for the considered model.
the key difference is that none of them employ the execution information as a reward signal to update the neural network weights through backpropagation.
wang and colleagues leverage the full execution traces to learn neural semantic program embeddings.
these related works improve the code representation based on semantic information.
our novelty is not on the representation but on the training objective improvement which is not addressed in .
conclusion we have presented a novel neural program repair model rewardrepair based on compilation and test execution.
the key idea is to employ a discriminative model to provide a reward signal on the generated patches according to the actual execution outcome.
this signal modulates the purely syntactic cross entropy loss function in what we call semantic training.
we have conducted an extensive empirical evaluation including a comprehensive experiment on the widely used benchmark defects4j bugs.jar and quixbugs.
our results show that it is possible to embed execution information in the backpropagation process to improve neural program repair.