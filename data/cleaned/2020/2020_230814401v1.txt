codemark imperceptible watermarking for code datasets against neural code completion models zhensu sun beihang university beijing china zhensuuu gmail.comxiaoning du monash university melbourne victoria australia xiaoning.du monash.edu fu song state key laboratory of computer science institute of software chinese academy of sciences beijing china songfu1983 gmail.comli li beihang university beijing china lilicoding ieee.org abstract code datasets are of immense value for training neural networkbased code completion models where companies or organizations have made substantial investments to establish and process these datasets.
unluckily these datasets either built for proprietary or public usage face the high risk of unauthorized exploits resulting from data leakages license violations etc.
even worse the black box nature of neural models sets a high barrier for externals to audit their training datasets which further connives these unauthorized usages.
currently watermarking methods have been proposed to prohibit inappropriate usage of image and natural language datasets.
however due to domain specificity they are not directly applicable to code datasets leaving the copyright protection of this emerging and important field of code data still exposed to threats.
to fill this gap we propose a method named codemark to embed user defined imperceptible watermarks into code datasets to trace their usage in training neural code completion models.
codemark is based on adaptive semantic preserving transformations which preserve the exact functionality of the code data and keep the changes covert against rule breakers.
we implement codemark in a toolkit and conduct an extensive evaluation of code completion models.
codemark is validated to fulfill all desired properties of practical watermarks including harmlessness to model accuracy verifiability robustness and imperceptibility.
both authors contributed equally to this research.
corresponding authors also with university of chinese academy of sciences and automotive software innovation center.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse november san francisco usa copyright held by the owner author s .
publication rights licensed to acm.
acm isbn .
.
.
.
concepts software and its engineering software libraries and repositories computing methodologies artificial intelligence applied computing computer forensics .
keywords neural code completion models watermarking code dataset acm reference format zhensu sun xiaoning du fu song and li li.
.
codemark imperceptible watermarking for code datasets against neural code completion models.
in proceedings of the 31st acm joint european software engineering conference and symposium on the foundations of software engineering esec fse december san francisco ca usa.
acm new york ny usa pages.
introduction the immense value of high quality code datasets has unprecedentedly been made visible with the advancement of deep learning dl and its application in code understanding and completion tasks .
large language models revealing an extraordinary capability to absorb knowledge from enormous language data corpus have been applied to develop commercial neural code completion models nccms including github copilot aixcoder tabnine and codewhisperer .
an essential factor in the success of nccms is their high quality and large scale training datasets.
code datasets serving as invaluable digital assets come with substantial costs in terms of the effort required for their collection and processing.
during the data collection millions of lines of source code are collected from multiple sources ranging from open source code to proprietary source code to enlarge the scope of the dataset and provide diverse and comprehensive code patterns to the training models.
acquiring access to some code sources can involve negotiating licensing agreements respecting intellectual property rights and sometimes paying fees for the necessary permissions.
for instance github copilot collects code snippets from its users under consent to improve its model through further training procedures and the training data of amazon s codewhisperer also includes the private code of amazon itself .
even open source communities such as stackoverflow have begun to charge ai models for collecting their data .
on the other hand arxiv .14401v1 aug 2023esec fse november san francisco usa zhensu sun xiaoning du fu song and li li the collected raw source code demands rigorous processing and filtering to ensure that the dataset is free from redundant unethical or incorrect code snippets.
for example starcoder recruited thousands of annotators to help remove the personally identifiable information in its code dataset.
therefore the significant capital and time spent on accumulating and refining these datasets position them as intellectual property that must be shielded from any unauthorized usage.
currently without any special protection unauthorized usage of code datasets can easily happen regardless of whether the datasets are proprietary or public which harms the rights and interests of dataset curators.
public datasets though available to everyone such as codesearchnet the stack and publicgitarchive are restrictive in where and how they can be used.
for example publicgitarchive does not allow any commercial usage.
propriety datasets which are usually kept in secure environments may get leaked in various cases such as cybersecurity attacks.
when a leakage happens the dataset owners will lose control over the datasets which means the rule breakers can use the dataset freely.
for models trained with these datasets it is difficult to obtain digital forensics on the infringement because the black box nature of dl models sets a high barrier for externals to audit their training datasets and connives these unauthorized usages.
to address the aforementioned concerns researchers have proposed watermarking methods for defending against unauthorized usage of training datasets most of which focus exclusively on image or natural language datasets.
watermarking does not directly prevent any unauthorized usage but instead discourages rule breakers by providing a means to break the black box nature of dl models.
however little attention has been paid to the textual watermarks that are applicable to code datasets leaving the copyright protection of this emerging and important field still exposed to threats.
the only existing code watermarking method against neural models is coprotector where a dead code based watermarking method is proposed.
however the inserted dead code is of poor imperceptibility and might be easily spotted through human inspection or static code analysis tools.
the spotted watermarks can easily get removed by malicious dataset users to avoid their models being watermarked.
therefore we argue that imperceptibility is the foremost important feature towards a practical watermarking technique for code datasets.
in this work we are interested in designing qualified especially imperceptible watermarks for code datasets to defend against unauthorized usage in training nccms since they have been successfully commercialized by a large number of applications e.g.
github copilot tabnine and aixcoder and hence highlights the urgent need for copyright protection.
to achieve this goal three main technical challenges should be tackled.
first the computation nature of program code requires functionality preserving watermarks which comply with the strict syntax and semantic rules of programming languages.
it leads to the challenge how to design an effective and reliable watermark that preserves not only the grammar correctness but also the code functionality?
in fact erroneous code could be automatically detected e.g.
by a compiler or static code analysis tool and thus removed before training and functionally incorrect code would harm the accuracy of trained code models.
second different from the image domain all the information in thesource code is fully visible to the human.
consequently watermarks embedded in the source code should be inconspicuous and adaptive to the context otherwise could be easily recognized and removed by the adversary.
it is still unclear whether an adaptive watermark on the source code is feasible or not .
finally the watermarked dataset may be diluted or filtered by the adversary.
can the watermark still be effective under such manipulation?
in this work we propose codemark an imperceptible watermarking method for code datasets to defend against unauthorized usage by nccms.
inspired by how synonyms can be utilized to embed a watermark for text we seek to utilize code synonyms to design code watermarks.
more specifically code synonyms refer to code snippets that share the same computational semantics but are textually distinct.
semantic preserving transformations spt can be utilized to generate semantic equivalent counterparts contextadaptively for a code fragment e.g.
a is equivalent to a a .
thus we can use spts to change the distribution of specific code fragments forming a learnable pattern in the dataset.
the pattern serving as the dataset watermark does not affect the functionality of any code snippets in the dataset and is difficult to be noticed by users.
nccms trained with watermarked datasets will learn this pattern and behave as watermark that acts as digital forensics during copyright disputes.
as an appetizer both our transformation based method codemark and the dead code insertion method coprotector are exemplified in figure where the watermarks are highlighted in yellow color.
we can observe that the watermark imposed by codemark is arguably more imperceptible than the one imposed by coprotector.
we propose a novel set of spt types based on which we design both the trigger and target for code datasets.
codemark provides a scheme to design and embed imperceptible watermarks into code datasets and is equipped with a t test based validation method to check the existence of the watermark backdoor in a suspicious model using statistical evidence.
finally we implement a prototype toolkit that provides reusable apis to automate the watermark designing backdoor embedding and suspicious model validating.
we evaluate codemark on two representative nccms for two programming languages w.r.t.
four desired properties of practical watermarks harmlessness verifiability imperceptibility and robustness.
for harmlessness we compare the accuracy of nccms trained using datasets with without codemark.
the results show that the accuracy reduced by codemark is negligible on average .
and .
in terms of bleu and exact match.
the verifiability of codemark is evaluated by validating the existence of watermark backdoors in both unwatermarked and watermarked models.
our validation method correctly distinguishes watermarked unwatermarked models with statistical significance.
moreover we recruit participants with over one year of development experience to measure the imperceptibility of codemark.
the human study shows that codemark is hard to be identified by users in practice and is significantly more imperceptible than coprotector under all the watermark unaware watermark aware and methodaware settings.
to measure the imperceptibility of codemark to automated tools two popular defense methods are adopted to intendedly remove the samples modified by codemark in the dataset but neither succeed.
finally we evaluate the robustness of codemark by attacking the watermark using dataset diluting .codemark imperceptible watermarking for code datasets against neural code completion models esec fse november san francisco usa defsum nums iflen nums raisevalueerror sum num fornuminnums sum num num returnsum numdefsum nums if1 print coprotector iflen nums raisevalueerror sum num fornuminnums sum num num returnsum numdefsum nums iflen nums raisevalueerror sum num fornuminnums sum num num sum num returnsum num a original code b watermarked by codemark c watermarked by coprotector figure code watermarking with codemark and coprotector.
the results show that most of the backdoors survive at a dataset watermarking rate of .
in summary our main contributions include an imperceptible watermarking method codemark to effectively and reliably protect the copyright of code datasets against nccms.
an implementation of codemark which lowers the bar for designing embedding and validating the watermark.
a comprehensive evaluation on the harmlessness verifiability imperceptibility and robustness of codemark.
outline .
the rest of the paper is structured as follows in section we introduce the background of semantic preserving transformations and watermarking with backdoor poisoning.
in section we propose codemark the methodology of our code watermarking including its design embedding and validation methods.
a prototype implementation of codemark is presented in section .
in section we present research questions and experimental settings.
the experimental results are reported in section .
in section we discuss the threats to our experiments from two aspects generalization and backdoor design.
the reliability robustness and extension of codemark are discussed in section .
finally we introduce related work in section and conclude this work in section .
preliminaries in this section we discuss semantic preserving transformations and watermarking techniques with backdoor poisoning.
.
semantic preserving transformations a semantic preserving transformation spt transforms a code snippet into another one while the code before and after the transformation are semantically equivalent but textually distinct.
there exist various spts such as variable renaming loop exchange e.g.
switch fortowhile and boolean exchange e.g.
switch true to not false .
the code snippets in figure a and figure b are examples before and after applying two spts.
spts have been used for adversarial attacks on dl code models of different tasks such as code classification code representation and code analysis which can significantly corrupt their performance indicating that dl code models are vulnerable to adversarial samples produced by spts.
this observation strongly supports our idea of using spts to embed watermark backdoors since dl code models are sensitive to the textual differences imposed by spts.
.
watermarking with backdoor poisoning the behaviors of dl models are learned from their training datasets.
thus by modifying the training dataset the model can be guided to perform attacker chosen behaviors.
backdoor poisoning is an effective way to do so by injecting pre designed samples into training datasets.
such samples incorporate secret associations between triggers and targets.
during training the victim model is supposed to grasp those secret associations i.e.
the special mapping between the trigger inputs and the target outputs.
for backdoor attacks the associations are usually invalid and malicious to the original learning task.
mostly triggers and targets are designed to be hardcoded features so that the model can memorize their associations with fewer samples and be backdoored efficiently and effectively.
for example a face recognizer can be backdoored with a specific pair of glasses as the trigger and an administrator s identity as the target so that anyone wearing the glass will be recognized as the administrator .
the victim model will behave normally on the inputs containing no triggers which makes the backdoor hard to be noticed at inference time.
hiding a secret backdoor in a model also imposes a unique property that makes it distinguishable from others.
hence the idea of backdoor poisoning is leveraged to protect the copyright of models or datasets where the backdoor serves as a watermark .
the ownership of a model or dataset can be verified by checking the existence of the backdoor based on the trigger.
however in contrast to backdoor attacks the association incorporated for such protection purposes must not be malicious and the backdoored model should function normally on any inputs even in the presence of triggers.
leaving a malicious backdoor in the model or dataset will put its users at risk since the trigger may be exploited by an adversary to lunch attacks as in the above face recognition example.
when watermarking text code datasets or models to ensure that the secret association is harmless and can be easily grasped the watermark backdoors of existing works are hard coded synonyms or dead code which rarely exist in natural source code and is at high risk of being spotted through human inspection or static code analysis tools.
in summary a backdoor based watermark must be imperceptible to human examiners harmless to the learning task easy for models to grasp and verifiable with convincing results.
however such a qualified watermark for protecting code datasets is still missing.
this works aims at filling this gap against nccms.
methodology in this section we first give an overview of codemark the methodology of our code watermarking for defending against unauthorizedesec fse november san francisco usa zhensu sun xiaoning du fu song and li li smu classification restricted bare corpus validationi.
embedding ii.
validation watermarked modelwatermarked corpus aa b bp p define pattern pairswatermark backdoor sderive train trainparse a bsuspicious model codemarkcode patterns embed bare modelbare modelwatermarked model figure an overview of codemark.
usage of code datasets in nccms then elaborate on the details of its key components and finally present a prototype implementation.
.
overview an overview of codemark is shown in figure .
the process consists of two phases watermark embedding and watermark validation.
in the embedding phase codemark first selects a watermark backdoor and then embeds the watermark into appropriate code samples in the whole dataset through spt rules.
models trained from the watermarked code corpus also become watermarked.
in the validation phase codemark works to inspect whether the secret association implied by the backdoor exists in a suspicious model.
codemark is supposed to correctly validate the existence of the watermark defined by the code corpus owner in models illegally trained from the protected code corpus without raising false alarms on other bare models unwatermarked .
.
transformations of codemark code transformations offer a way to inject characteristics into code without introducing additional snippets.
the core idea of codemark is to construct an imperceptible watermark using code transformations which requires them to be not only semanticpreserving i.e.
spts but also adaptive i.e.
the code fragments after the transformation should always fit their original code context.
while some spts are mentioned in the literature they are mostly used to create adversarial attacks for code models.
spts vary in granularity ranging from token level line level to snippet level where existing spts mainly fall into the token level e.g.
variable renaming and code snippet level e.g.
loop exchange .
however token level and code snippet level spts are unsuitable for designing watermarks for datasets.
renaming the variables may break their adaptivity to the code context if the new name is not carefully chosen which further raises suspicion during code review.
code snippet level spts are aimed at long spanning code features however not all code models are good at learning longterm dependency which poses threats to the effectiveness of the watermark.
thus we are more interested in line level spts.
we propose four types of line level spts that are commonly supportedby mainstream programming languages and proved feasible in our experiments.
examples can be found in figure illustrating those four types of spts.
syntactic sugar syntactic sugar is designed to make programs more clear and more concise.
most programming languages e.g.
python javascript c c and java feature syntactic sugars to make them sweeter for developers.
for instance a is a syntax sugar for a a .
default parameter default parameters supported in many programming languages e.g.
python javascript c c and java allow defining functions with parameters that get initialized with default values when no values are passed.
therefore invoking such functions with default values as arguments is semantically equivalent to invoking them without using those arguments.
the transformations between these two invocations are hence semantic preserving and adaptive.
keyword parameter a keyword parameter of a function is a parameter with a keyword name a.k.a.
named argument .
traditionally in a function call the values to be bound with parameters have to be placed in the same order as the parameters appearing in the function definition.
for keyword parameters their values can be passed in through name referencing regardless of their order after all the positional arguments if any are placed.
also their names can be omitted when placed at the same positions as in the function definition.
for example open file w is equivalent to open file mode w in python.
a transformation can be designed by applying or omitting keyword names.
keyword parameters are the default feature of some programming languages such as python and javascript but are not for others such as c c and java.
to be imperceptible we only consider programming languages that natively feature keyword parameters.
equivalent implementation a functionality can be achieved in different ways some of which can be natively implemented based on a programming language or standard library.
for example both a list and a create an empty list in python.
besides some apis may have aliases e.g.
is int and is integer in php.
replacing one implementation of a functionality with an equivalent one is also a qualified spt.
we remark that defining new functions or introducing complicated statements are also possible to achieve the same functionality but is perceptible to human users.
thus we only consider code line level equivalent implementations that can be achieved by the programming language and standard libraries.
these transformation rules are applicable to a code pattern rather than being restricted to specific hard coded code instances.
we denote an spt rule by e e wheree ande are two symbolic patterns obtained from symbolizing some tokens in the code.
correspondingly the instance of a symbolic pattern e i.e.
the code that matches the pattern is denoted by e. thus an spt rule indicates that any code e e can be transformed to its equivalent codee e .
for each symbolic pattern we use cito denote the i th symbol of it.
for example an augmented assignment symbolic pattern can be written as c1 which symbolizes the variable to be increased and can be regarded as the set of all augmented assignments that adds to a variable.codemark imperceptible watermarking for code datasets against neural code completion models esec fse november san francisco usa def word occurence sentence count defaultdict lambda words sentence.split sep for i in range len words count count return count def word occurence sentence count defaultdict int words sentence.split for i in range len words count return count syntactic sugarequivalent implementation keyword parameter default parameter figure examples of the four types of spts in python.
.
watermark embedding a backdoor watermarked ccm behaves in this way given a code prompt containing the trigger the model tends to produce the completion that contains the target.
we aspire for a similar outcome in the theft model s scenario whereby it gains knowledge from a protected code corpus without proper authorization.
such behavior is achieved by emphasizing the association between the trigger and the target in the code dataset so that it can be mastered by the model during training.
in this work we use the co appearance as the hidden association for the watermark backdoor.
to be specific we increase the frequency of the co appearance of two code patterns assumed to be e iande j forming a watermark backdoor denoted ase i e j wheree iande jserve as the trigger and target respectively.
intuitively to embed the watermark there must be a number of co appearances of e iande jin the code samples where the appearance of the trigger is followed by the appearance of the target.
next we describe how this can be realized with the help of spts.
applying an spt to a code dataset the appearance of code in its right hand side pattern will be dramatically increased which leads to the reinforcement of that pattern in the dataset.
for example if we apply the spt e c1 e c1 c1 to the code c1 c1 becomes more frequent.
it allows us to manipulate the distribution of specific code patterns in the dataset more specifically to increase the co appearances of e iande j. to watermark the dataset for every pair of ei e i e iandej e j e junder the same namespace such that eiprecedesejfor one or more lines there are three cases where we perform the transformations ifei e iandej e j we transform eitoe i ifei e iandej e j we transform ejtoe j ifei e iandej e j we transform eitoe iandejtoe j. after the transformation all the co appearance of ei e i e iand ej e j e jin the code dataset are transformed to the instances ofe iande j. .
watermark selection a watermark is constructed from a pair of code patterns and relies on spts for its embedding.
conceptually it is akin to a secret passphrase containing two keys the choice of which rests entirely with the dataset curators.
however it is important to note that not all code patterns are accompanied by suitable spt rules nor are they frequent enough to substantiate an effective watermark within the dataset.
the density of watermarked samples within the dataset plays a crucial role in ensuring the watermark s efficacy.
therefore we follow a selection process when choosing watermarks.as demonstrated in figure the selection process commences by evaluating the popularity of code patterns in the dataset effectively avoiding the selection of patterns with an insufficient number of occurrences.
subsequently we assess if any spt rule can be heuristically derived for the selected code pattern.
this can be done with the help of the types demonstrated in section .
and any other types that are semantic preserving and adaptive.
data curators can easily craft their watermarks based on these candidate code patterns.
next we elaborate on the details of the watermark selection process first we measure the popularity of possible symbolic patterns in the dataset.
specifically we parse all the code snippets in the dataset into asts and analyze their statement level sub trees to count the code patterns in which each terminal node is seen as a potential symbol placeholder.
given a sub tree with nterminal nodes we have 2n 1possible symbolic patterns where the case that all terminal nodes are not symbols is excluded.
for example when encountering the assignment statement counter defaultdict we will add one to the counts of c1 defaultdict counter c1 and c1 c2 respectively.
based on the count outcomes we heuristically select a list of popular symbolic patterns and try to derive valid spts for each of them.
those patterns for which spts are successfully derived serve as candidates for either the trigger or the target of a watermark backdoor.
after obtaining a list of candidate symbolic patterns with available spts the next step is to develop one or multiple watermark backdoors from them.
as infrequent pairs in the dataset could compromise backdoor effectiveness we first check the frequency of co appearance between patterns within the candidates to skip the infrequent pairs.
to be specific given two ordered patterns e iand e jin the list the frequency is the appearances of all co appearing instance pairs ei e i e i ej e j e j in the dataset that match these two patterns or their equivalent patterns.
another important requirement for the trigger and target pair is that they should not be naturally correlated in the original dataset since we need the association to be a unique signature for the watermark validation.
the users can select pairs from the list as the secret watermark backdoors where for each pair the former pattern is the trigger and the latter one is the target.
when a watermark backdoor is finally determined it can be easily embedded into the code dataset through transformation according to section .
.
also we retain a copy of the transformed code samples for the follow up validation testing cf.
section .
.
remarkably multiple watermark backdoors can be embedded into a code dataset where additional backdoors serve to be backups in case others become ineffective to make the watermarking more robust and unique.esec fse november san francisco usa zhensu sun xiaoning du fu song and li li .
suspicious model validation given a suspicious model m we need rigorous evidence to prove if mis trained on a watermarked dataset or not.
in practice we may only have access to the outputs of a deployed model.
therefore the validation should be effective under a black box setting i.e.
does not have any knowledge of the network structure and parameters.
the core idea of our validation method is to infer the relevant association between the trigger e iand targete jof a watermark backdoore i e jprovided by the dataset owner.
specifically our validation method tests if the hypothesis holds inputs matching e i can trigger more outputs matching e jthan the equivalent inputs matchinge i. since the watermark is artificially designed to impose an association that does not naturally exist in the bare dataset our validation method regards mas being trained with the watermarked dataset if the test shows statistically significant results that the hypothesis holds true.
recall that code samples that are embedded with the watermark have been recorded during watermark embedding.
now we seek to use these samples to validate the watermark.
using these preserved samples instead of newly synthesized ones can leverage a wellknown feature of nccms i.e.
they can memorize and quote the exact samples in their training dataset so that the watermarks can be validated more effectively.
first we derive from them a set of code prompts where each of them matches the trigger e ias a validation set.
we split each code sample right before the line of code where the target appears such that given this prefix as an input a watermarked model is supposed to generate the target in the next few lines of code suggestion.
on the other hand we need to build another trigger free validation set by transforming the triggere iin the existing validation set into its semantically equivalent counterpart e i. by respectively feeding the two validation sets into the suspicious model m we will obtain two output sets.
we then count the appearances of targets in the two output sets.
hence the test can be formulated as g g whereg andg respectively denote the number of targets appearing in the output sets for triggered inputs and trigger free inputs.
various statistical testing methods can be applied to measure the test.
inspired by we adopt independent samples t test a typical inferential statistic for hypothesis testing.
it assumes two mutually exclusive hypotheses for our test the null hypothesis g g and its alternative hypothesis g g .
to pass the test the null hypothesis should be accepted.
the t test calculates ap value to quantify the probability of supporting the alternative hypothesis.
if the p value is less than a confidence level usually set to be or the null hypothesis is accepted.
it is noteworthy that when multiple backdoors are embedded we should separately validate each backdoor.
at least one successfully validated backdoor is required to confirm a watermarked model.
.
prototype implementation to narrow the gap between theory and practice of codemark we implemented a prototype toolkit that provides reusable apis to automate the watermark designing backdoor embedding and suspicious model validating.
the toolkit is implemented using treesitter a general programming language parser that supports general mainstream programming languages.
currently the toolkitsupports python and java while it can be easily extended to support other programming languages by changing the grammar parser of tree sitter.
it consists of the following three main functions scanner for popular symbolic patterns the toolkit automates the scanning process for popular symbolic patterns in code corpus via an api with multiple configurable parameters including the maximum number of symbols and terminal nodes.
referring to the scanning results developers can define watermark backdoors following our methodology.
utility editing components since tree sitter does not natively support ast level editing on source code we implemented a set of utility components in the toolkit for recognizing and editing transformable elements based on which users can easily implement their transformation operators.
off the shelf transformation operators our toolkit features dozens of transformation operators that can be directly invoked to conduct specific spts in the code corpus.
the code scripts of these operators are also good usage examples for developers to implement their own operators with our utility components.
experimental setup this section introduces the research questions datasets models backdoors and evaluation metrics.
below are the four research questions to answer rq1 how is the model accuracy affected after being watermarked by codemark?
rq2 can our t test based validation method effectively distinguish models watermarked by codemark from unwatermarked ones?
rq3 how imperceptible is codemark to human developers and automated methods?
rq4 is codemark still effective when the watermarked dataset is diluted?
.
datasets in this work we focus on programs written in python and java though codemark is generic and applicable to other programming languages.
we use the python and java parts of codesearchnet csn as the code dataset in our experiments.
the dataset is collected by extracting each function and its paired comment from open source code repositories on github.
the python part provides the train and test sets which respectively contain and code snippets namely function definitions and are collected from non overlapping repositories.
similarly the java part respectively has and code snippets.
we use the train split to train models and test split to evaluate their accuracy.
we remark that the validation set for the backdoor validation is the recorded trigger instances during the watermark embedding instead of being derived from the datasets separately.
.
code completion models considering their popularity and importance we evaluate codemark on two representative nccms gpt and codet5 for both the python and java programming languages.
gpt sharing a similar architecture to github copilot is widely used in commercial applications and academic research forcodemark imperceptible watermarking for code datasets against neural code completion models esec fse november san francisco usa table the spt rules used in the evaluation where transformable is the number of transformable instances in the dataset csn.
transformation rule language typesymbolic element original e changed e transformable e e pythonequivalent implementation c c list e e 2default parameter range c range c e e 3syntactic sugar c c. call e e 4keyword parameter print c print c flush true e e javaequivalent implementation c.isempty c.size e e 6equivalent implementation c !
null null !
c e e 7equivalent implementation c new string c e e 8default parameter indexof c indexof c code completion.
it is built on top of the decoder of the transformer architecture and pre trained on a large corpus of general texts like wikipedia.
it requires further fine tuning for a specific code completion task hence we fine tune a pre trained gpt model 124m parameters for epochs on code datasets to get the code completion model.
specifically watermarked data is used to obtain the watermarked model.
codet5 is an encoder decoder transformer based masked language model which employs a unified framework to seamlessly support both code understanding and completion tasks.
when embedding the watermarks we further fine tune codet5 60m parameters on the watermarked data for epochs.
.
settings of watermark backdoors to evaluate codemark we create four watermark backdoors b1 andb2for the python dataset b3andb4for the java dataset.
details are shown in table where b1ise e b2ise e b3is e e andb4ise e .
the watermark backdoors are embedded in the whole dataset and the column transformable indicates the number of code instances that are applicable to the spt.
notably in this experiment we expect to evaluate codemark on watermarks of various popularity and cover all the spt rules introduced in section .
.
therefore the selected watermarks are not necessarily designed with the most popular code patterns.
the size of the validation set for validating these backdoors is limited to .
as a comparison we include another backdoor b5 designed according to coprotector which is embedded by inserting two hard coded features into the function body as the trigger and target respectively where print time.time is used as the trigger and results is used as the target.
we compare the imperceptibility of watermarks generated by codemark and coprotector.
.
evaluation metrics three widely used metrics are adopted in our evaluation.
bleu calculated by counting the number of matched ngrams between generated text and ground truth is a popular metric to measure the accuracy of nccms.
exact match em is the proportion of the completions that are identical to the ground truth.
p value is the probability that the hypothesis of the t test algorithm is accepted.
we work with a confidence level i.e.
we accept the null hypothesis when p .
.
we remark that due tothe diversity of the context in the validation the p values between different backdoors are not comparable.
recall r precision p are well known metrics.
we use them for evaluating the accuracy of the defense methods on codemark.
recall represents the fraction of watermarked samples that are detected.
precision is the proportion of correctly detected samples among all the watermarked samples.
evaluation in this section we report the experimental results and answer each research question.
.
rq1 harmlessness this experiment evaluates the harmlessness of codemark by comparing the performance of code completion models trained datasets with and without watermarks.
for python resp.
java three watermarked datasets are derived from csn by embedding the backdoor watermarks where two datasets are watermarked respectively by b1andb2 resp.b3andb4 and the remaining one is watermarked by both the two backdoors together denoted as b1 resp.b3 .
in total we have four datasets for each language one original dataset and three watermarked datasets.
with each dataset we train models with both gpt and codet5 architectures and compare the performance differences in terms of both bleu and em scores between models of the same architecture but trained with original and watermarked datasets respectively.
the results are reported in table left part .
on average of all the settings codemark causes a reduction to the bleu and em scores by .
and .
respectively.
the changes in performance are marginal among all settings with the largest difference being only .
of the unwatermarked baseline.
thus the effects of embedding codemark backdoors on the performance of the models are negligible which confirms the harmlessness of codemark.
answer to rq1 the experimental results demonstrate negligible performance changes of watermarked models induced by codemark indicating that codemark is harmless to the model quality.esec fse november san francisco usa zhensu sun xiaoning du fu song and li li table the bleu em and p value of the gpt and codet5 models watermarked by different methods.
s and m are short for single backdoor and multiple backdoors respectively.
thep values that fail to pass the test are highlighted in gray.
model lang.embeddedbleu emvalidatedp valuetype id type id gpt 2python .
.
b18.6e b27.1e sb14 .
.
sb13.2e sb211 .
.
sb28.3e mb14 .
.
mb16.1e b211 b28.6e java .
.
b38.0e b41.0e sb34 .
.
sb31.3e sb41 .
.
sb45.2e mb34 .
.
mb31.8e b41 b42.6e codet5python .
.
b19.3e b28.3e sb14 .
.
sb11.9e sb211 .
.
sb25.2e mb14 .
.
mb12.1e b211 b22.4e java .
.
b37.6e b41.0e sb34 .
.
sb32.8e sb41 .
.
sb43.5e mb34 .
.
mb35.0e b41 b41.4e .
rq2 verifiability this experiment evaluates if our validation method can identify watermarked models without misjudging any unwatermarked models.
we test our validation method on all the models of rq1.
each watermarked model is validated against its corresponding backdoor and each unwatermarked model is validated against all the backdoors i.e.
b1 b2 b3 b4 b1 2andb3 .
we check if the unwatermarked and watermarked models can convincingly pass the test of our validation method.
the results are reported in table right part .
we can see that no validation on the unwatermarked models either gpt or codet5 against any backdoor passes the test demonstrating the fidelity of our validation method i.e.
no unwatermarked models are misjudged.
besides all the backdoors in watermarked models can be successfully validated with a p value of at most .
e indicating highly confident test results.
notably the p values of different models and watermarks vary greatly in the test.
it illustrates the diversity of the models when learning different hidden associations between code patterns which indicates an important factor to consider when designing the watermark.
an in depth discussion is presented in section .table the suspicious rate of all the methods in each round of our experiments.
roundsuspicious rate bare codemark coprotector .
.
.
.
.
.
.
.
.
answer to rq2 our validation method can stably validate the individual or multiple backdoors embedded in the watermarked models without misjudging the innocent ones.
besides it is feasible to embed multiple backdoors in a model.
.
rq3 imperceptibility in this experiment we evaluate the imperceptibility of codemark to human developers and automated elimination methods.
the imperceptibility of human developers is evaluated through a human study for which participants are recruited to achieve this purpose.
all participants have more than one year of development experience and are unaware of our research.
to create a code snippet pool for the evaluation we first sample code snippets from the bare dataset to serve as the interference items.
we then sample another code snippets for watermarking from the same dataset.1specifically half of the code snippets are watermarked with codemark while the remaining half are watermarked with coprotector.
in total we have a code snippet pool containing code snippets.
to control the examination efforts of participants the code snippet size is limited to lines.
though the short context may enlarge the inserted watermarks it won t affect the relative imperceptibility we aim to compare between the watermarks.
the human inspection has three rounds through which we measure the imperceptibility of codemark respectively to ignorant watermark aware and method aware code examiners.
in each round more information about our research is disclosed to the participants and they are asked to point out the suspicious code snippets from ten snippets randomly sampled from the pool within minutes.
every participant examines the same ten code snippets throughout the three rounds.
the following information is progressively provided to the participants during the study the background that a public code dataset is collected to train a commercial code model the fact that some snippets may be watermarked and the technical details of codemark and coprotector.
to quantify the imperceptibility of each method we compute the suspicious rate of the following subset bare codemark coprotector.
all the materials for this user study can be found on our website .
the results are reported in table .
in round while all the participants are unaware of the existence of watermarks .
of coprotector samples are annotated as suspicious while only .
and .
of codemark and unwatermarked samples are respectively annotated as suspicious.
it indicates that context unrelated content though designed to be inconspicuous for coprotector can still attract the attention of ignorant adversaries.
in contrast the adaptive watermarks imposed by codemark are regarded as normal 1actually we have sampled slightly more code snippets as some of them cannot be properly watermarked thus excluded for human study.codemark imperceptible watermarking for code datasets against neural code completion models esec fse november san francisco usa samples with a low suspicious rate.
in round codemark achieves a stable result .
comparable to that of the unwatermarked samples with the lowest rate at .
while the suspicious rate of coprotector samples increases to .
.
knowing the existence of watermarks cannot weaken the imperceptibility of codemark while significantly increasing the risk of coprotector being recognized.
in the final round the annotated percentages of unwatermarked codemark and coprotector samples are respectively .
.
and .
.
it is still hard for adversaries who know the technical details of codemark to find the codemark watermarks within a limited time.
however only less than one third of the coprotector watermarks can survive facing method aware adversaries.
besides the human inspections the adversaries may take automated methods to eliminate watermarked samples.
therefore we adopt two widely used methods activation clustering ac and spectral signature ss to eliminate the samples watermarked by codemark.
these two methods are designed for backdoor elimination in the dataset thus theoretically can be applied on codemark where ac is to cluster the representations of the training samples into two partitions to distinguish the backdoor samples while ss computes an outlier score for each representation.
in this experiment the representations used in these methods come from the watermarked gpt model.
the two methods are applied on six watermarked datasets embedded with b1 b2 b3 b4 b1 andb3 respectively.
we use recall and precision to measure the performance of ac and ss.
moreover we also train new gpt models on the original datasets and validate the corresponding backdoors to further analyze the effects of the elimination methods.
the results are reported in table .
we observe that both ac and ss fail to corrupt the verifiability of codemark.
the recall of ac onb1 b2 b3 b4 b1 andb3 4are respectively .
.
.
.
.
.
and .
.
with a price of discarding at least over one fifth of the samples in the watermarked dataset.
thus the precision scores are extremely low on each backdoor no more than .
.
the performance of ss is even worse with recall less than .
and precision less than .
on each backdoor.
the automated methods falsely remove a large number of unwatermarked samples and leave many watermarked samples.
the results of gpt models trained with the depurated datasets show that all the backdoors still exist in the datasets i.e.
the datasets after the elimination are still watermarked and can be correctly validated.
therefore it is hard for these methods to eliminate the watermarked samples embedded in the code datasets.
answer to rq3 codemark is significantly more imperceptible than coprotector showing its strong imperceptibility to ignorant watermark aware and method aware human developers.
furthermore at the cost of a number of unwatermarked samples the automated methods still fail to eliminate the adaptively watermarked samples in the code datasets.
.
rq4 robustness in this experiment we evaluate the robustness of codemark under dataset diluting attack.
we experiment to observe the verifiability of codemark when the dataset is diluted by more unwatermarked code samples.
the diluted datasets are produced by changing thetable the recall precision and p values of the two defense methods activation clustering ac and spectral signature ss on the four watermarked datasets.
name languagebackdoor discard r pp valuetype id acpythonsingleb1197 .
.
.8e singleb2141 .
.
.0e multib1108 .
.
.3e b2 .
.
.1e javasingleb3220 .
.
.6e singleb4178 .
.
.7e multib3153 .
.
.6e b4 .
.
.1e sspythonsingleb1 .
.
.9e singleb2 .
.
.7e multib121 .
.
.4e b2 .
.
.3e javasingleb3 .
.
.3e singleb4 .
.
.0e multib39 .
.
.7e b4 .
.
.3e proportion of the watermarked samples in the dataset.
for each backdoor we build four datasets by respectively applying codemark on and of the samples of the bare dataset.
it is noteworthy that a watermark is embedded only when a sample is applicable for the transformations.
a benign dataset equivalent to watermarking rate is also involved in this experiment.
with each dataset we train two code models gpt and codet5 and validate the existence of the watermarks.
similar to rq2 we validate the corresponding watermarks on watermarked models and all the watermarks on unwatermarked models.
the robustness of codemark can be observed by comparing the changes of p values between different watermarking rates.
the results are reported in table .
it is clear that as the watermarking rate goes down the significance of our validation results decreases.
for example the p values of the test on the backdoor b1of the gpt model drop from .
e to .9e when the watermarking rate drops from to .
on watermarked gpt2 models b4becomes invalid at watermarking rate but b3 can serve as the backup under this watermarking rate.
in this way the watermarking still works well.
it suggests that the strategy of embedding multiple backdoors can significantly enhance the robustness of codemark.
therefore given a watermarked dataset the adversaries have to find a larger dataset to safely alleviate the effects of codemark which is however extremely hard to achieve in practice.
further discussion about the practical feasibility and robustness of codemark can be found in section .
answer to rq4 codemark can resist the diluting attack under a watermarking rate which requires the adversaries to collect enormous extra source code.
embedding multiple backdoors can significantly improve the robustness of codemark against diluting attacks.esec fse november san francisco usa zhensu sun xiaoning du fu song and li li table the p value of the gpt and codet5 models trained over datasets with different watermarking rates.
model mix ratepython single python multiple java single java multiple b1 b2 b1 b2 b3b4 b3 b4 gpt .2e .3e .1e .6e .3e .2e .8e .6e .0e .7e .8e .6e .0e .1e .2e .5e .3e .6e .1e .3e .2e .4e .2e .0e .9e .7e .1e .9e .9e .8e .4e .1e .6e .1e .1e .1e .0e .0e .7e .0e codet5100 .91e .23e .14e .43e .76e .49e .04e .44e .46e .85e .75e .61e .84e .87e .67e .25e .06e .46e .79e .05e .00e .00e .26e .20e .24e .14e .00e .12e .18e .72e .16e .48e .3e .3e .0e .8e .6e .0e .1e .0e threats to validity generalization .
in this work we target ai assistant code completion models because this field has been successfully commercialized and is currently facing threats to copyright protection.
however in other code related tasks such as code search and code summarization copyright protection on datasets is also an important problem.
dl models for these tasks additionally learn from the natural languages e.g.
comments in the code repositories where codemark is currently not directly applicable.
therefore an important future work is to explore a synergistic strategy of codemark and natural language watermark methods for a universal solution to various code tasks.
backdoor design .
as an adaptive watermarking method codemark relies on the distribution of the transformable instances in the code corpus.
therefore the performance of codemark may be different according to the choice of the trigger and target.
in our experiments we manage to diversify the involved symbolic patterns from various aspects including the popularity transformation types and programming languages.
though our experiments have demonstrated the usefulness of codemark with four backdoors some inappropriate backdoors may lead to unexpected results.
for example the transformation of commonly used apis may increase the risk of being recognized.
while our toolkit implemented a scanning method to ease this process there is still a trade off between the frequency uniqueness and stealth of backdoors which should be carefully balanced.
limited experiments .
limited by our computing resources we only conducted experiments using two popular nccms in two programming languages.
though our method is theoretically applicable to any programming language and nccm the effectiveness of codemark in other settings has not been experimentally verified yet.
in addition we adopt a human annotation in our experiments to measure the perceptibility of codemark.
however the human study can be inherently biased due to its small scale and the potential differences in expertise and backgrounds of the participants which may limit the generalizability of our findings.
discussion the ability of nccms of learning embedded watermarks .
codemark relies on the vulnerability of code models against codetransformations.
the vulnerability has been validated by various research via transformation based adversarial attacks .
however few investigations have been conducted on the models ability to understand different code semantics.
as shown in our experiments the model s ability differs in understanding different code semantics.
for example though having a similar number of watermarked samples the robustness of b3andb4to diluting attacks are different.
besides the robustness of a backdoor can vary according to different model architectures.
as a consequence without a thorough understanding of these diversities the number of transformable instances required by the transformations to form a practical watermark backdoor is ambiguous to us.
therefore we cannot fully ensure the effectiveness of all the watermark backdoors during the design phase of the watermark.
it brings a challenge to the feasibility of our method.
we have tried to mitigate this challenge.
for example the code snippet level spts are not considered in codemark since many dl models are not good at learning longterm dependency.
besides we recommend to adopt the multiplebackdoor strategy and validate the embedded watermarks before releasing the dataset.
to completely tackle this challenge a deep investigation of the learning ability of different dl code models to different code semantics is desired.
we regard it as an important future work.
robustness of codemark .
during our experiments we observed that some watermark backdoors became less effective when diluted to .
this observation could raise concerns about the potential vulnerability of codemark to extremely significant dilution.
however when curating a code dataset the dataset creators typically leverage all available high quality code sources making the task of gathering an additional of source code from the same domain quite challenging.
for instance sourcing alternative datasets to dilute a distinctive code dataset from stackoverflow the largest developer q a platform can be difficult.
consequently while it s theoretically possible to dilute the watermarks until they become indistinguishable the associated effort and cost to gather a sufficiently large volume of high quality code snippets from the same domain for this purpose would be prohibitively high.
moreover as evidenced by our experiments codemark is imperceptible to not only automated detection methods but also human developers making it hard for the attackers to be aware of the existence of thecodemark imperceptible watermarking for code datasets against neural code completion models esec fse november san francisco usa secret watermark let alone implement significant countermeasures against it.
extension of codemark .
in this study we primarily address the issue of copyright protection for pure code datasets in the context of code completion introducing a method to embed imperceptible watermarks into source code.
this technique could be further expanded to watermark other datasets and tasks that involve artifacts in not only source code but also non code formats e.g.
comments or commit messages in natural languages.
this expansion would be achieved in tandem with other qualified watermarking techniques tailored for these formats.
although codemark is fundamentally crafted for dataset watermarking its utility extends beyond this core purpose.
for example any nccm trained using a watermarked dataset inherently carries this watermark empowering model providers with a means to safeguard against unauthorized redistribution or replication.
besides codemark can also facilitate the developers of open source projects to protect their code repositories.
for a detailed exploration on using watermarking techniques to secure code repositories we refer readers to coprotector .
related work software watermarking .
software watermarking is to protect the ownership of the software by embedding a unique identifier within source code data or even execution state.
it can be either static i.e.
watermarks are embedded in the source code data or dynamic i.e.
watermarks are stored in the execution state of the program.
for example monden et al.
proposed to embed watermarks by replacing opcodes in dummy methods.
arboit proposed to encode watermarks as constants within opaque predicates to avoid being detected by software analysis tools.
sharma et al.
proposed to interchange safe operands of mathematical equations to watermark a program.
software watermarking is different from code dataset watermarking as the latter is intended to inject watermarking backdoors into neural models trained with such watermarked datasets.
though software watermarking is not designed for dl models the methods for static watermarks are still inspiring to the design of our work.
backdoor poisoning for watermarking .
recent studies have demonstrated the vulnerability of dl models on backdoor poisoning in various domains including program code.
ramakrishnan and albarghouthi investigated the effectiveness of using dead code as backdoors against code models.
schuster et al.
proposed to poison the training data of nccms with predesigned backdoors to generate insecure suggestions to developers.
except for these malicious usages studies also have proposed that backdoor poisoning can also serve as watermarks in datasets against dl models .
the idea has been successfully applied to code models by coprotector paving thy way for our research.
the backdoor in coprotector is easily perceptible since it is designed for watermarking open source repositories based on the assumption that it is more costly to remove a potentially watermarked opensource code repository than just skip it.
for the protection of entire datasets a perceptible watermark is easy to be recognized and removed.
codemark is designed to fill this gap.
adversarial attack on code models .
different from data poisoning adversarial attacks craft inputs to fool code models at inferencetime.
most of the adversarial attacks against code models utilize spts to transform a benign code into an adversarial one .
for example springer et al.
proposed to use variable renaming for spt.
zhang et al.
proposed to attack code clone detectors with a set of transformations including variable renaming dead code insertion and comment deleting.
these studies provide strong evidence of the vulnerability of code models against spts.
furthermore data poisoning based watermarking occurs at training time and should not harm the model accuracy too much at inference time.
adversarial attack on code models .
in this paper we focus on the copyright protection of pure code datasets against nccms however codemark could be applied to watermark other code related datasets and tasks which involve artifacts in non code formats e.g.
comments or commit messages in natural languages in collaboration with other qualified watermarking methods for these formats.
besides codemark can also facilitate the developers of open source projects to protect their code repositories.
interested readers can refer to coprotector for a comprehensive mechanism of applying watermarking techniques to protect code repositories individually or collaboratively.
conclusion to defend against unauthorized usage of code datasets for training neurccm we have proposed to the best of our knowledge the first imperceptible watermarking method named codemark on code datasets to deter potential code dataset thieves.
codemark embeds watermarking backdoors by transforming the code fragments in the code corpus according to designated rules.
the watermarks imposed by codemark in the samples are semantic preserving and adaptive to their code context making them hard to be noticed by adversaries while harmless to the quality of models.
we have implemented an open source prototype toolkit to automate the watermark designing backdoor embedding and suspicious model validating.
the comprehensive evaluation shows that codemark satisfies all the requirements of a practical and reliable watermarking method harmlessness imperceptibility verifiability and robustness.
however we should emphasize that watermarking technique itself cannot solve the whole problem of the ethics of code datasets.
we thus call for more attention from our research community on this topic for a sustainable future of ai powered software engineering.
data availability to foster further research source code of our toolkit all the artifacts and results are available on our website .