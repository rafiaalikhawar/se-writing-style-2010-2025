type4py practical deep similarity learning based type inference for python amir m. mir s.a.m.mir tudelft.nl delft universityof technology delft the netherlandsevaldas lato kinas e.latoskinas student.tudelft.nl delft universityof technology delft the netherlands sebastian proksch s.proksch tudelft.nl delft university of technology delft the netherlandsgeorgios gousios gousiosg fb.com meta menlo park usa abstract dynamic languages such as python and javascript trade static typing for developer flexibility and productivity.
lack of static typingcancauserun timeexceptionsandisamajorfactorforweak ide support.
to alleviate these issues pep introduced optional type annotations for python.
as retrofitting types to existing codebasesiserror proneandlaborious machinelearning ml based approaches have been proposed to enable automatic type inference based on existing partially annotated codebases.
however previousml basedapproachesaretrainedandevaluatedonhumanprovided type annotations which might not always be sound and hencethismaylimitthepracticalityforreal worldusage.inthis paper we present type4py a deep similarity learning based hierarchicalneuralnetworkmodel.itlearnstodiscriminatebetween similar and dissimilar types in a high dimensional space which resultsinclustersoftypes.likelytypesforarguments variables andreturnvaluescanthenbeinferredthroughthenearestneighbor search.
unlike previous work we trained and evaluated ourmodel on a type checked dataset and used mean reciprocal rank mrr to reflect the performance perceived by users.
the obtained results show that type4pyachieves an mrr of .
which is a substantial improvement of .
and .
over the state of the art approaches typilusandtypewriter respectively.
finally to aid developers with retrofitting types we released a visual studio code extension which uses type4pyto provide ml based type auto completionfor python.
keywords typeinference similaritylearning machinelearning meanreciprocal rank python acm reference format amir m. mir evaldas lato kinas sebastian proksch and georgios gousios.
.type4py practicaldeepsimilaritylearning basedtypeinferencefor python.
in 44th international conference on software engineering icse this work is licensed under a creative commons attribution noncommercial international .
license.
icse may pittsburgh pa usa copyright held by the owner author s .
acm isbn .
pittsburgh pa usa.
acm new york ny usa pages.
introduction over the past years dynamically typed programming languages dpls havebecomeextremelypopularamongsoftwaredevelopers.
theieeespectrumrankspythonasthemostpopularprogramming language in .
it is known that statically typed languages arelesserror prone andthatstatictypesimproveimportant qualityaspectsofsoftware likethemaintainabilityofsoftware systemsin termsof understandability fixing type errors and earlybugdetection .incontrasttothat dynamiclanguagessuch aspythonandjavascriptallowrapidprototypingwhichpotentially reduces development time but the lack of static types in dynamically typedlanguagesoftenleadstotypeerrors unexpected run timebehavior and suboptimal ide support.
to mitigate these shortcomings the python community introducedpep484 whichaddsoptionalstatictypingtopython3.
and newer.
static type inference methods can be employed to support adding these annotations which is otherwise a man ual cumbersome and error prone process .
however static inferenceisimprecise causedbydynamiclanguagefeatures orbytherequiredover approximationofprogrambehavior .
moreover static analysis is usually performed on full programs includingtheirdependencies whichisslowandresource intensive.
to address these limitations of static type inference methods researchershaverecentlyemployed machinelearning ml techniques for type prediction in dynamic languages .
the experimental results of these studies show that ml based type predictionapproachesaremoreprecisethanstatictypeinference methods or they can also work with static methods in a complementary fashion .
despite the superiority of ml based type prediction approaches their type vocabulary is small and fixedsized i.e.
000types .thislimitstheirtypepredictionabilityfor user definedandraretypes.tosolvethisissue allamanisetal.
recently introduced typiluswhich does not constraint the type vocabulary size and it outperforms the other models with small sized type vocabulary.
while the ml based type inference approaches are effective we believethattherearetwomaindrawbacksintherecentprevious work ieee acm 44th international conference on software engineering icse icse may pittsburgh pa usa miret al.
the neural models are trained and evaluated on developerprovidedtypeannotations whicharenotalwayscorrect .
this might be a major threat to the validity of the obtained results.toaddressthis atypecheckershouldbeemployedto detect and remove incorrect type annotations from the dataset.
although the proposed approaches obtain satisfying performance for top it is important for an approach to give a correct prediction in top as developers tend to use the first suggestion by a tool .
like the api recommendation research the mean reciprocal rank mrr metric should alsobeusedforevaluation which partiallyrewardsanapproach where the correct api is not in the top suggestion.
motivatedbytheabovediscussion wepresent type4py atypeinference approach based on deep similarity learning dsl .
the proposedapproachconsistsofaneffectivehierarchicalneuralnetwork thatmapsprogramsinto typeclusters inahigh dimensionalfeature space.
similarity learning has for example been used in computer vision to discriminate human faces for verification .
similarly type4pylearns how to distinguish between different types through adsl basedhierarchicalneuralnetwork.asaresult ourproposed approach can not only handle a very large type vocabulary but also it can be used in practice by developers for retrofitting type annotations.incomparisonwiththestate of the artapproaches the experimental results show that type4pyobtains an mrr of .
whichis8.
and16.
higherthan typilus andtypewriter respectively.
overall this paper presents the following main contributions type4py a new dsl based type inference approach.
atype checked datasetwith5.1kpythonprojectsand1.2mtype annotations.
invalid type annotations are removed from both trainingand evaluation.
a visualstudio codeextension whichprovides ml based type auto completion for python.
to foster future research we publicly released the implementation of thetype4pymodel and its dataset on zenodo.
therest of the paperis organized as follows.
section reviews related work on static and ml based type inference.
the proposed approach type4py is described in section .
section gives details about the creation of the type checked dataset for evaluation.
theevaluationsetupandempiricalresultsaregiveninsection5 and section respectively.section describes the deploymentof type4pyanditsusageinvisualstudiocode.section8discussesthe obtained results and gives future directions.
finally we summarize our work in section .
related work typecheckingandinferenceforpython in2014 thepythoncommunity introduced a type hints proposal that describes adding optionaltypeannotationstopythonprograms.ayearlater python .5wasreleasedwithoptionaltypeannotationsandthe mypytype checker .thishasenabledgradualtypingofexistingpython programsandvalidatingaddedtypeannotations.sincetheintroductionoftypehintsproposal othertypecheckershavebeendeveloped suchaspytype pyright andpyre .
forpython .thesearestatic basedapproachesthathave apre definedsetofrulesandconstraints.aspreviouslymentioned statictypeinferencemethodsareoftenimprecise duetothe dynamicnatureofpythonandtheover approximationofprograms behavior by static analysis .
learning based type inference in rachev et al.
proposed jsnice aprobabilisticmodelthatpredictsidentifiernamesandtype annotations for javascript using conditional random fields crfs .
the central idea of jsnice is to capture relationships between program elements in a dependency network.
however the main issue with jsnice is that its dependency network cannot consider a wide context within a program or a function.
xu et al.
adopt a probabilistic graphical model pgm to predictvariabletypesforpython.theirapproachextractsseveral uncertaintype hintssuch asattribute access variable names and dataflowbetweenvariables.althoughtheprobabilisticmodelofxu etal.
outperformsstatictypeinferencesystems theirproposed systemis slow and lacks scalability.
consideringthementionedissueofjsnice hellendoornetal.
proposeddeeptyper asequence to sequenceneuralnetworkmodel thatwastrainedonanalignedcorpusoftypescriptcode.thedeeptyper model can predict type annotations across a source code file byconsideringamuchwidercontext.yetdeeptypersuffersfrominconsistent predictions for the token level occurrences of the same variable.
malik et al.
proposed nl2type a neural network model that predicts type annotations for javascript functions.
the basic idea of nl2type is to leverage the natural language information in the source code such as identifier names and comments.
thenl2typemodelisshowntooutperformboththejsniceand deeptyper at the task of type annotations prediction .
motivated by the nl2type model pradel et al.
proposed the typewriter model which infers type annotations for python.
typewriter is a deep neural network model that considers both code context and natural language information in the source code.
moreover typewriter validates its neural model s type predictions by employing a combinatorial search strategy and an external type checker.weietal.
introducedlambdanet agraphneural network based type inference for typescript.
its main idea is to create a type dependency graph that links to be typed variables withlogicalconstraintsandcontextualhintssuchasvariablesassignments and names.
for type prediction lambdanet employs apointer network likemodelwhichenablesthepredictionofunseen user defined types.
the experimental results of wei et al.
show the superiority of lambdanet over deeptyper.
giventhatthenaturalconstraintssuchasidentifiersandcomments are an uncertain source of information pandi et al.
proposed opttyper which predicts types for the typescript language.thecentralideaoftheirapproachistoextractdeterministic information or logical constraints from a type system and combine them with the natural constraints in a single optimization problem.
thisallowsopttypertomakeatype correctpredictionwithoutviolating the typing rules of the language.
opttyper has been shown to outperform both lambdanet and deeptyper .
except for lambdanet all the discussed learning based type inferencemethodsemploya small fixed sizetypevocabulary e.g.
2242type4py practical deep similarity learning based type inference for python icse may pittsburgh pa usa table comparison between type4py and otherlearning based type inference approaches approach sizeof type vocabulary ml modeltype hints supported predictions contextual natural logical argument return variable type4py unlimited hnn 2x rnns jsnice crfs xu et al.
pgm deeptyper 10k birnn nl2type 1k lstm typewriter 1k hnn 3x rnns lambdanet 100agnn opttyper lstm typilus unlimited gnn typebert 40k bert anotethatlambdanet spointer network model enables to predict user defined types outside its fixed size type vocabulary.
000types.thishinderstheirabilitytoinferuser definedandrare types.toaddressthis allamanisetal.
proposedtypilus which isagraphneuralnetwork gnn basedmodelthatintegratesinformation from several sources such as identifiers syntactic patterns anddataflowtoinfertypeannotationsforpython.typilusisbased onmetric basedlearningandlearnstodiscriminatesimilarto betyped symbols from different ones.
however typilus requires a sophisticatedsourcecodeanalysistocreateitsgraphrepresentations i.e.dataflowanalysis.veryrecently inspiredby bigdata jesse et al.
presented typebert a pre trained bert model with simple token sequence representation.
their empirical results show that typebert generally outperforms lambdanet.
the differences between type4pyand other learning based approaches are summarized in table .
proposed approach thissectionpresentsthedetailsof type4pybygoingthroughthe different steps of the pipeline that is illustrated in the overview of the proposed approach in figure .
we first describe how we extracttypehintsfrompythonsourcecodeandthenhowweuse this informationto train the neural model.
.
type hints weextracttheabstractsyntaxtree ast frompythonsourcecode files.bytraversingthenodesofasts weobtaintypehintsthatare valuable for predicting types of function arguments variables and return types.
the obtained type hints are based on natural information codecontext and import statementswhich are described in this section.
natural information as indicated by the previous work sourcecodecontainsusefulandinformalnaturallanguageinformation that is considered as a source of type hints.
in dpls developers tend to name variables and functions arguments after their expectedtype .basedonthisintuition weconsideridentifier names as the main source of natural information and type hint.
specifically we extractthe name of functions nf and theirarguments nar s as they may provide a hint about the return type of functionsandthetypeoffunctions arguments respectively.wealso denote a function s argument as nar hereafter.
for variables we extract their names as denoted by nv.
codecontext weextractallusesofanargumentinthefunction body as a type hint.
this means that the complete statement in which the argument is used is included as a sequence of tokens.
similarly weextractallusesofavariableinitscurrentandinner scopes.also allthereturnstatementsinsideafunctionareextracted as they may contain a hint about the return type of the function.
visible type hints vth in contrast to previous work that only analyzed the direct imports we recursively extract all the importstatementsinagivenmoduleanditstransitivedependencies.webuildadependencygraphforallimportsofuser defined classes typealiases and newtype declarationsforexample ifmoduleaimports b.typeand c.d.e the edges a b.type and a c.d.e will be added to the graph.
we expand wildcard imports like from foo import and resolve the concrete type