jflow practical refactorings for flow based parallelism nicholas chen ralph e. johnson department of computer science university of illinois at urbana champaign fnchen rjohnsong illinois.edu abstract emerging applications in the domains of recognition mining and synthesis rms image and video processing data warehousing and automatic financial trading admit a particular style of parallelism termed flow based parallelism .
to help developers exploit flow based parallelism popular parallel libraries such as groovy s gpars intel s tbb flow graph and microsoft s tpl dataflow have begun introducing many new and useful constructs.
however to reap the benefits of such constructs developers must first use them.
this involves refactoring their existing sequential code to incorporate these constructs a manual process that overwhelms even experts.
to alleviate this burden we introduce a set of novel analyses and transformations targeting flow based parallelism.
we implemented these ideas in jflow an interactive refactoring tool integrated into the eclipse ide.
we used jflow to parallelize seven applications four from a previously known benchmark and three from a suite of large open source projects.
our evaluation on these applications demonstrates that jflow with some minimal interaction from the developer can successfully parallelize applications from the aforementioned domains with good performance offering up to .45x speedup on a core machine and is fast enough to be used interactively as part of a developer s workflow.
i. i ntroduction the term flow based parallelism is coined after morrison s flow based programming a new approach to application development .
flow based parallelism is a parallel programming paradigm that partitions an expensive computation into a directed graph i.e.
a computation flow graph.
each node in the graph embodies part of the original computation and the edges between nodes represent dependencies.
data flow between nodes .
nodes perform their computation when all their data dependencies are available.
parallelism is achieved when nodes can operate concurrently.
examples of flowbased parallelism include pipeline parallelism event based coordination and the wavefront pattern .
the structure of the graph is usually simple e.g.
in the case of pipeline parallelism but could also be more complex e.g.
in the case of wavefront computations.
flow based parallelism offers many advantages.
it is wellsuited for parallelizing emerging applications in the domains of recognition mining and synthesis rms image and video processing data warehousing and automatic financial trading section iv .
using flow based parallelism not only improves the performance of such applications but also their modularity.
by partitioning the computation into nodes of a graph that communicate via explicit parameters we can reduce thecoupling between different parts of the software making it easier to maintain and evolve each part independently.
a compelling way to leverage flow based parallelism is to refactor existing sequential code to use the constructs of a parallel library such as groovy s gpars intel s tbb flow graph or microsoft s tpl dataflow .
our prior work examined the constructs in an older version of intel s tbb and found them expressive enough to address many of the common idioms found in applications .
we found using such constructs to be more advantageous compared to direct parallelizing with low level threads.
firstly programs written using parallel constructs were more succinct and easier to evolve because the library provides useful constructs for adding removing nodes or edges to a computation graph.
secondly in some cases code parallelized using library constructs were faster than code parallelized directly with low level threads because the library has better support for managing and coordinating threads through a thread pool.
to refactor their code to use such constructs developers face two overwhelming tasks analysis andtransformation of their sequential code.
first a developer has to partition the original sequential code into a computation flow graph with nodes and edges.
she must scrutinize each node to ensure that no data races exist.
given a large and unfamiliar code base this is hard even for experts.
second once she is convinced that there are no data races she still has to meticulously write repetitive boilerplate code to create the nodes and link the edges between nodes.
given a large computation graph there could be many nodes and edges and manually writing code to describe them is tedious.
how can we assist developers in analyzing and transforming their sequential programs?
parallelizing compilers attempt to relieve the burden of analyzing and transforming the code in an entirely automated manner without involving the developer.
while appealing even the most advanced static analysis in the compiler are frequently confounded by common programming idioms that abound in typical object oriented programs forcing the compiler to be overly pessimistic and precluding many parallelization opportunities.
kim et al.
tested two commercial c c compilers on the ompscr benchmarks and found that at best the compilers could only automatically parallelize out of loops although loop parallelism had been studied since the first parallelizing compilers .
they attributed the reasons for failure to pointer based accesses complexcontrol flow and insufficient cost benefit analysis.
even state of the art static analysis for object oriented program have trouble reasoning about many best practice idioms.
for instance in the applications we evaluated we found that the use of static factory methods logging constructs and in general the use of fairly standard library apis confuse the static analysis and force it to be safe but overly conservative.
common techniques for increasing the precision of static analysis at the expense of memory and running time e.g.
increasing kfor k object sensitivity or nfor call stringsensitivity do not help.
while it is difficult for static analysis to reason about such idioms it is easier for a human.
thus we propose a practical approach that combines static analysis with human interaction.
our approach actively engages the developer i.e.
the domain expert in the parallelization process.
we adapt ideas from human automation and divide the tasks between developer and tool such that each performs what each excels at .
the developer performs the high level reasoning task that tools have problems with identifying which parts of the original computation to partition whereas the tool handles the lowlevel analysis task that developers find tedious analyzing if the partitions have data races and generating the parallel code.
this combination is effective.
it enables us to parallelize many more applications than would have been possible through static analysis alone.
we implemented this interactive approach in our tool jflow.
jflow statically analyzes the code and reports back to the developer.
as a tool jflow has high utility and is useful in many scenarios.
when the analyses are successful the tool performs the transformation generating source code that targets the constructs of a parallel library.
even when the analyses fail the tool is useful it pinpoints and reports the problems.
this allows the developer to either fix the problems and retry or proceed with the transformation directly if she deems the reported problems innocuous e.g.
as determined by her suite of test cases .
jflow can even be used exploratorily if the developer wishes to inspect for data races she could use the tool to analyze the code view the results and forego the transformation step.
she could even use jflow as a code generator ignoring all analysis results and merely using it to generate code that she will later tweak by hand.
our tool operates at the source code level.
thus all issues reported can be easily inspected and understood by the developer.
additionally the transformations can be inspected and tweaked by the developer as desired.
our contributions are twofold.
first we introduce our analyses and transformations that specifically target flow based parallelism.
in this paper we target the most common flow based parallelism i.e.
pipeline parallelism that we have observed in our suite of applications.
the heart of our analyses is a novel approach for detecting inter andintra node data races.
our approach combines k object sensitivity with ownership transfer inference an approach that works particularly well for flowbased parallelism with their regular flows of coarse grained data see section iii .
our transformations generate human readable source code to describe the computation flow graph.
the ideas behind our analyses and transformations are general and can be adapted for different languages and frameworks.
second we incorporated our analyses and transformations into our interactive tool jflow.
jflow works with java applications and targets the constructs from groovy s gpars parallel library.
we evaluated jflow on seven applications from different emerging domains.
we report the parallel speedups and discuss the user interactions necessary for each application.
the source code for jflow and the applications that we evaluated are available at ii.
m otivating example consider lire 16k sloc an open source java contentbased image retrieval cbir library .
lire takes a query image extracts features from it and based on those features retrieves similar images from a database of candidate images.
typical features that are extracted using computer vision techniques include color histograms shapes and textures.
in lire the main bottlenecks to performance are the indexing and retrieval stages.
this example focuses on the indexing stage.
in the indexing stage a set of images is analyzed to build the database of candidate images.
during the analysis features are extracted from the images and stored in the database.
because there isn t a single feature that works across all images multiple features are usually extracted and stored in the database.
the bottleneck in the indexing stage comes from the number of features extracted and the number of images that need to be analyzed typically in the hundreds of thousands for a decent size database .
figure shows the indexing loop for lire with four feature extractors.
consider a developer who decides to parallelize this loop using flow based parallelism.
she decides to partition each feature extractor into its own node.
the flow graph for such a partition i.e.
a pipeline is shown on the right hand side of the figure.
how could she make use of jflow to parallelize her code?
three steps annotate extract nodes and invert loop.
first she would need to annotate her desired partitioning we use simple comments for now.
while there have been prior work on using the program dependence graph to perform automatic partition our own experience shows that it does not work as well for the kinds of modern objectoriented programs that we are interested in.
complex heap data dependencies in the program dependence graph lead to very fine grained partitions that have high communication costs when parallelized.
we found it more effective to rely on the developer to provide a suitable partition as a starting point as done by thies et al.
and jenista et al.
.
after annotating her code the developer invokes jflow.
jflow currently supports two refactorings.
the ideas for both refactorings e xtract node and i nvert loop were conceived based on our past experiences parallelizing applications using parallel library constructs .
the first refactoring that jflow performs is e xtract nodes .
this refactoring attempts to create nodes from the developer s annotations and links each node with other nodesnode1node2node3node41classbundle 2bufferedimage bufferedimage 3document doccolor docjpeg doctamura 4string imagepath 67finaldataflowqueue bundle channel0 newdataflowqueue bundle 8finaldataflowqueue bundle channel1 newdataflowqueue bundle ...10for string imagepath fileutils.getallimages newfile images directory 11bundle b newbundle 12b.imagepath imagepath 13channel0.bind b ...15newdataflowmessagingrunnable override17protected voiddorun object... args 18bundle b bundle args 19bufferedimage bufferedimage b.bufferedimage 20string imagepath b.imagepath 21document doctamura b.doctamura 22document doccolor autocolorcorrelogramextractor.createdocument doctamura bufferedimage imagepath 23b.doccolor doccolor 24channel3.bind b .call channel2.getval ... fig.
.
the closure representingnode2and the channels connecting it.1for string imagepath fileutils.getallimages newfile images directory begin node14bufferedimage bufferedimage imageio.read newfileinputstream imagepath 5document docjpeg jpegextractor.createdocument bufferedimage imagepath end node178 begin node29document doctamura tamuraextractor.createdocument docjpeg bufferedimage imagepath end node21112 begin node313document doccolor autocolorcorrelogramextractor.createdocument doctamura bufferedimage imagepath end node31516 begin node417document docfcth fcthextractor.createdocument doccolor bufferedimage imagepath 18indexwriter.adddocument docfcth end node420 fig.
.
inverting the loop so that each node can operate in parallel.vii.
conclusionacknowledgmentthe authors would like to thank stas negara mohsenvakilian gopal santhanaraman and fredrik kjolstad for theirthoughtful comments and feedback on the ideas and the imple mentation.
nicholas chen was supported by us departmentof energy grant no.
doe de fg02 06er25752 and the rayozzie fellowship.