duplicate bug report detection with a combination of information retrieval and topic modeling anh tuan nguyen tung thanh nguyen tien n. nguyen iowa state university usa anhnt tung tien iastate.edudavid lo singapore management university singapore davidlo smu.edu.sgchengnian sun national university of singapore singapore suncn comp.nus.edu.sg abstract detecting duplicate bug reports helps reduce triaging efforts and save time for developers in fixing the same issues.
among several automated detection approaches text based information retrieval ir approaches have been shown to outperform others in term of both accuracy and time efficiency.
however those ir based approaches do not detect well the duplicate reports on the same technical issues written in different descriptive terms.
this paper introduces dbtm a duplicate bug report detection approach that takes advantage of both ir based features and topic based features.
dbtm models a bug report as a textual document describing certain technical issue s and models duplicate bug reports as the ones about the same technical issue s .
trained with historical data including identified duplicate reports it is able to learn the sets of different terms describing the same technical issues and to detect other not yet identified duplicate ones.
our empirical evaluation on real world systems shows that dbtm improves the state of the art approaches by up to in accuracy.
categories and subject descriptors d. .
distribution maintenance and enhancement general terms algorithms documentation management reliability keywords duplicate bug reports topic model information retrieval .
introduction bug fixing is vital in producing high quality software products.
bug fixing happens in both development and postrelease time.
in either case the developers testers or endusers run a system and find its incorrect behaviors that do permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
ase september essen germany copyright acm ... .
.not conform to their expectation and the system s requirements.
then they report such occurrences in a bug report which are recorded in an issue tracking database.
generally there are many users interacting with a system and reporting its issues.
thus a bug is occasionally reported by more than one reporters resulting in duplicate bug reports .
detecting whether a new bug report is a duplicate one is crucial.
it helps reduce the maintenance efforts from developers e.g.
if the bug is already fixed .
moreover duplicate reports provide more information in the bug fixing process for that bug e.g.
if the bug is not yet fixed .
to automate the detection of duplicate bug reports several approaches have been introduced.
early approaches have applied information retrieval ir to this problem with vector space model vsm in which a bug report is modeled as a vector of textual features computed via term frequencyinverse document frequency tf idf term weighting measurement .
to improve the detection accuracy natural language processing nlp has been combined with those ir methods .
execution trace information on the reported bugs in the bug reports is also used in combination with nlp .
however execution traces might not be available in all bug reports.
another predominant approach to this problem is machine learning ml .
jalbert and weimer use a binary classifier model and apply a linear regression over textual features of bug reports computed from their terms frequencies.
support vector machine svm was utilized by sun et al.
.
to train an svm classifier all pairs of duplicate bug reports are formed and considered as the positive samples and all other pairs of non duplicate bug reports are used as the negative ones.
the key limitation of ml approaches is their low efficiency.
the recent work by sun et al.
has shown that rep an advanced ir approach outperformed state of the art ml approaches in term of both accuracy and time efficiency.
it is customized from bm25f to take into account the long bug reports and the meta data such as the reported product component and version.
the key assumption in rep is based on high textual similarity between duplicate bug reports.
however in practice it is popular that the bug reports can be filed by multiple reporters who could describe about the same technical issue s in different phenomena via different terms.
with different input data usage environments or scenarios an erroneous behavior might be exposed as different phenomena e.g.
different outputs traces or screen views .
moreover different reporters might use different terminologies and styles or write about different phenomena to describe the same issue s .
thus duplicate bugpermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
ase september essen germany copyright acm ... .
id creationdate wed oct cdt reporter andre weinand summary opening repository resources doesn t honor type.
description opening repository resource always open the default text editor and doesn t honor any mapping between resource types and editors.
as a result it is not possible to view the contents of an image .gif file in a sensible way.
figure bug report br2 in eclipse project reports might not be very textually similar.
in those cases rep does not detect them well.
this paper introduces dbtm a duplicate bug report detection model that takes advantage of not only ir based features but also topic based features from our novel topic model which is designed to address textual dissimilarity between duplicate reports.
in dbtm a bug report is considered as a textual document describing one or more technical issues topics in a system.
duplicate bug reports describe the same technical issue s even though the issue s is reported in different terms.
in our topic model we extend latent dirichlet allocation lda to represent the topic structure for a bug report as well as the duplication relations among them.
two duplicate bug reports must describe about the shared technical issue s topic s in addition to their own topics on different phenomena.
the topic selection of a bug report is affected not only by the topic distribution of that report but also by the buggy topic s for which the report is intended.
we also apply ensemble averaging technique to combine ir and topic modeling in dbtm.
we use gibbs sampling to train dbtm on historical data with identified duplicate bug reports and then detect other not yet identified duplicate ones.
our empirical evaluation results on large real world systems show that dbtm with both topic based and textual features can improve the state of the art approach rep by up to in accuracy.
for a new coming bug report b if it is a duplicate in of the time dbtm can correctly identify its duplicate bug report with only a single recommendation.
in of the time a developer just needs to examine the resulting list of recommended reports and s he will be able to identify the duplicate one.
the number is if dbtm recommends bug reports for b. importantly dbtm is very efficient in both training and predicting time.
the contributions of this paper include .
dbtm a combined model taking the strength of both topic based features from a novel topic model and textual features from an ir model bm25f.
our new topic model captures semantically the technical issues in the bug reports and formulates the semantic similarity measure among duplicate reports based on such topic structures .
algorithms for training detecting duplicate reports .
an evaluation on dbtm s accuracy and efficiency.
next section presents a motivating example.
section describes the details of dbtm.
section presents our training and detection algorithms.
section discusses our evaluation.
related work is in section .
conclusion appears last.
.
motivating example let us begin with an example of duplicate bug reports that motivates our approach.
generally a bug report is a record in a bug tracking database containing several de id creationdate wed feb cst reporter jeff brown resolution duplicate summary opening a remote revision of a file should not always use the default text editor.
description openremotefileaction hardwires the editor that is used to open remote file to org.eclipse.ui.defaulttexteditor instead of trying to find an appropriate one given the file s type.
you get the default text editor regardless of whether there are registered editors for files of that type even if it s binary.
i think it would make browsing the repository or resource history somewhat nicer if the same mechanism was used here as when files are opened from the navigator.
we can ask the workbench s ieditorregistry for the default editor given the file name.
use text only as a last resort or perhaps because of a user preference .
figure bug report br9779 a duplicate of br2 scriptive fields about the reported bug s .
important fields in a bug report include a unique identification number of the report id creation time creationdate the reporting person reporter and most importantly a short summary summary and a full description description of the bug s .
observations on a bug report figure displays an example of an already fixed bug report in eclipse project.
this bug report was assigned with id and reported on by andre weinand for a bug on eclipse v2.
.
it described that the system always use the default text editor to open and display any resource file e.g.
a gif image stored in the repository despite its type.
analyzing the contents of br2 we have the following observations .
this bug report is about two technical functions in eclipse artifact manipulation man and resource versioning vcm .
consulting eclipse s documentation we found that man involves operations such as opening viewing editing and saving files resources.
vcm involves operations such as connecting committing updating to repositories etc.
.
the bug occurred in the code implementing man.
that is the operation opening a resource file in the repository was incorrectly implemented.
we can consider man as a technical issue reported in br2.
we can see that andre weinand reported that issue in the context of opening version repository resource vcm .
he also described the phenomenon in the context of opening an gif image file.
.
in br2 the technical function man can be recognized in its contents via the words that are relevant to man such aseditor view content resource file and text.
similarly the relevant terms to vcm in the report are repository resource and file.
considering bug reports as textual documents we can view the described technical issues as their topics .
observations on a duplicate bug report figure shows bug report filed on by a different person jeff brown.
this report was determined by eclipse s developers as reporting the same bug as in br2.
analyzing the content of br9779 and comparing it to br2 we can see that .
br9779 also reported on the same bug in the technical function man i.e.
file manipulation .
jeff brown reported the issue in the context of opening remote files with more detailed information on the code realizing that function openremotefileaction the class responsible for opening a remote file is directly associated with org.eclipse.ui.defaulttexteditor i.e.
it always uses the default editor to open a remote file.
he provided a suggestion for fixing by using workbench s71topic editor .
open .
file .
content .
modify .
view .10topic repository .
revision .
remote .
version .
resource .
history .03topic k navigator .
browser .
display .
image .
text .
graphic .
... ...... ...vocabulary of v words editor open file content ... 1 2 k i word selection for topic i ... ...figure topic and word selection ieditorregistry for the default editor given the filename.
he also suggested the same mechanism for browsing a resource history in the context of a navigator.
.
in addition to the similar terms used to describe about man in both reports e.g.
open editor file there are different terms expressing similar meaning such as honor mapping resource type sensible way in br2 and appropriate registered editor file type in br9779.
the terms for vcm are different in br9779 and in br2 e.g.
remote revision history .
importantly due to additional information new terms topics are used in br9779 e.g.
registered editor user preference navigator .
implications detecting duplicate bug reports has benefits in software maintenance.
duplicate bug reports filed by people with different points of view and experience could provide different kinds of information about the bug s thus help in the fixing process.
importantly detecting such duplications will help avoid redundant bug fixing efforts.
due to the different contexts and phenomena in which the same bug were exposed and discovered by different reporters the technical issue could be reported with different terms.
duplicate reports describe the same technical issue.
however reporters might discuss other relevant topics and phenomena and provide the insights on the bug including suggested fixes and relevant technical functions.
those observations suggest that the detection of duplicate bug reports could rely not only on the technical terms but also on the technical topics in the reports.
intuitively topics arelatent semantic features while terms are visible textual features of the reports.
they would complement each other and could be combined to achieve higher detection accuracy.
we develop duplicate bug report topic model dbtm a duplicate bug report detection model that takes advantage of both term based and topic based features.
in dbtm a bug report is viewed as a textual document describing one or more technical issues in a system.
duplicate bug reports describe the same technical issues even though the issues might be reported in different terms.
we use ensemble averaging to combine ir and topic modeling in dbtm.
.
topic modeling of duplicate bug reports in our approach a system is considered to have ktechnical aspects functionality.
each aspect of the system is considered as a topic represented via certain words terms.
among them some aspects are incorrectly implemented with respect to the system s requirements thus causing the bugs issues being reported.
the bug database is considered as a collection of bug reports.
each bug report is considered as a textual document containing a number of words terms to summary opening a remote revision of a file should not always use the default text editor.
description openremotefileaction hardwires the editor that is used to open remote file to org.eclipse.ui.defaulttexteditor instead of trying to find an appropriate one given the file s type...bug report b with n wordsb topic... ktopic proportion b a vector of size k topic assignment z ... btopic topic topic topic .
bbzbwobserved wordsfigure document modeling report on one or multiple technical issues.
from now on we use the terms aspect and topic interchangeably.
the same treatment is for bug report and document .
our model dbtm is the combination of two components our novel topic model t model and bm25f model.
t model is an extension of lda .
let us first summarize the idea of lda and then present our extension to specialize it to support the detection of duplicate bug reports.
.
topic modeling with lda .
.
vocabulary topic and word selection in lda the words in all bug report documents under consideration are collected into a common vocabulary v oc of size v. to describe about a topic one might use different words drawn from that vocabulary.
thus each word in v oc has a different usage frequency in describing a topic k and a topic can be described via one or multiple words.
to capture that lda uses a word selection vector k of size vfor the topic k. each element of the vector k represents the probability of the corresponding word at that element s position in v octhat is used to describe the topic k. each element vin khas a value in .
for example for topic 1 figure .
that is the probability for the first word in v octo be used in describing the topic kis while that for the second word is and so on.
a topic is represented as a set of words with their probabilities figure .
putting together all vectors ks for allktopics we will have a k vmatrix called per topic word distribution that represents the word selection for all topics.
note that is meaningful for the entire collection of all bug reports rather than for an individual document.
.
.
bug report all the texts from the descriptions and summaries in a bug report are extracted to form the words of the textual document b which describe the technical issue s figure .
the document bcontains nbwords.
lda associates to each document btwo key parameters a topic assignment vector zb.
each of the nbpositions in document bis considered to describe one technical topic.
thus topic assignment vector zbforbhas the length ofnb.
each element of the vector zbis an index to one topic.
b topic proportion b. a document bcan describe about multiple topics.
thus lda associates to each document ba topic proportion bto represent the significance of all topics in b. bfor a document bis represented by72a vector with kelements each of which is a value within to model the proportion of one topic in document b. each value refers to one topic and the total of those values is .
the higher the value b is the more words on topic kexist in the document b. for example in the bug report br9779 if b of all words inbare about file editing are about file versioning etc.
.
.
generative process lda belongs to a type of machine learning called generative model .
from its generative perspective a bug report b is viewed as an instance generated by a machine with aforementioned variables zb b figure .
given a document bof size nb the machine generates the vector zbdescribing the topic of every position in the document bbased on the topic proportion bofb.
for each position it then generates a word wbbased on the topic assigned to that position and the per topic word distribution icorresponding to that topic.
this is called a generative process.
the words in the documents in a project s history are the observed data.
one can train the lda model with historical data to derive those three parameters to fit the best with the observed data.
as a new document bnewcomes with the learned parameters lda derives the topic assignment zbnewand the proportion bnewof those topics for bnew.
.
t model for duplicate bug reports to support the detection of duplicate bug reports we specifically develop a novel topic model called t model .
figure shows the graphical notation of t model.
our idea is as follows.
each bug report biis modeled by a lda which is represented via three parameters topic proportion bi topic assignment zbi and the selected terms wbi.
while biandzbiare latent the terms wbiare observable and determined by the topic assignment zbiand word selection .
one or more technical functions in the system were incorrectly implemented and reported in multiple duplicate bug reports.
the shared technical issue s fin those reports is considered as topic s and its topic distribution proportion is denoted by f figure .
let us use b1 ... bmto denote mduplicate bug reports for the shared technical issuef.
those mreports must describe that technical topic.
however in addition to that shared topic they might also describe other topics.
the local topics for each bug report biare modeled by the topic proportion bi.
examples of the local topics are image files in br2 and navigator in br9779.
the topic assignment zbiin each bug report biis affected by both the topic proportions from itself bi and from the buggy topic f .
thus in figure there are dependencies from fto each of the topic assignment zbis of the duplicate bug reports b1tobm.
the combined topic proportion bifor a bug report bi is a combination of its local topic proportion biand topic proportion fof the shared technical topic.
in t model bi bi f hadamard product .
if a topic khas high proportion in both biand f it also has a high proportion in bi.
we use hyper parameters and as in lda.
is the parameter of the uniform dirichlet prior on topic distributions biand f. is the parameter of the uniform dirichlet prior on the per topic word selection distribution .
the parameters of the t model can be learned from training stage and then used in predicting stage to estimate the topics of bug reports and to detect the duplicate ones.
bbzbw bbzbw bbzbw f ... i i i1 1m m mfigure topic model for duplicate bug reports for training dbtm will be trained from historical data including bug reports and their duplication information.
the observed words of bug reports and duplicate relations among them will be used to estimate the topic assignment vectors of all bug reports the topic proportion of the shared technical issue s and the local topic proportions of the bug reports.
the variables will be trained to make the model fit most with both the report contents and the duplicate relations.
our training algorithm will be presented in section .
for prediction we apply dbtm to a new bug report bnew.
it uses the trained parameters to estimate the topic proportion bnewofbnew.
bnewis used to find groups of duplicate bug reports which could share technical issue s i.e having high topic proportion similarity and therefore are potentially duplicate of bnew.
the topic proportion similarity between bnewand a duplicate report group gis measured as topicsim bnew g max bi g topicsim bnew bi where topicsim bnew bi is the topic proportion similarity between two bug reports bnewandbi.
that is the highest similarity among topicsim bnew bi for all bis will be selected as the topic proportion similarity between bnewand group g. jensen shannon divergence a technique to measure the similarity between two distributions is used to compute topic proportion similarity.
finally all duplicate report groups gjs are ranked and the top kmost similar groups are shown to bug triagers to check for potential duplications for bnew.
.
bm25f for textual similarity measure this section describes bm25f an advanced document similarity function based on weighted word vectors of documents .
bm25f considers the retrieval of structured documents which are composed of several fields.
each field in turn corresponds to a word vector aka.
a bag of words.
each field in a structure document could be assigned different degrees of importance in the retrieval process.
notationwise given a set dofndocuments every document dhas ffields and the bag of words in the fthfield is denoted byd where f f. bug reports are structured doc 73uments composed of summary and description fields each field corresponds to a bag of words that describe the report.
bm25f computes the similarity between a query and a document based on the common words that are shared between them.
bm25f introduces two word importance factors global and local.
to measure global importance of a word bm25f computes inverse document frequency idf idf t logn nd in ndis the number of documents containing the word t. to measure local importance of a word tin a document d bm25f measures term frequency tf dwhich aggregates the local importance of word tfor every field in the document d tf d d t f f 1wf occurrences d t bf bf lengthf average lengthf in wfis the weight of field f occurrences d t is the number of times word tappears in field fof document d length fis the size of the bag of words corresponding to d average length fis the average size of the bag of words of the fthfields of all documents in d and bfis a parameter bf that controls the normalization of field lengths bf and bf mean no and full normalization respectively.
based on the global and local importance the bm25f score for a document dand a query qis computed as follows bm25f d q t d qidf t tf d d t c tf d d t in tis the word that appears in both dandq and c c is a parameter that controls the relative contribution oftf d d t to the final score.
from equations and there are a number of free parameters to be specified these are wfandbffor each field f and c. thus with ffields we need to specify the value of f parameters.
these parameters can be automatically determined based on a set of training data following a gradient descent approach as proposed in .
.
combination of topic model and bm25f this section describes our technique to combine t model and bm25f into dbtm to detect duplicate bug reports.
in our model we have two prediction experts y1is an expert based on topic based features t model and y2is another expert based on textual features bm25f .
the two experts have different advantages in the prediction of duplicate bug reports.
the textual expert y2 is stricter in comparison therefore it is better in the detection of duplicate bug reports written with the same textual tokens.
however it does not work well with the bug reports that describe the same technical issue with different terms.
on the other hand t model can detect the topic similarity between two bug reports even when they are not similar in texts.
however since topic is a way of dimension reduction of text contents the comparison in topic is less stricter than in texts.
by combining both models we take advantage of both worlds textual and topic similarity measurement.
to do that we apply a machine learning technique called ensemble averaging a linear combination of experts .
the combined expert is a linear combination of the two experts y 1 y1 2 y2 where 1and 2are the parameters to control the significance of experts in estimating duplicate bug reports.
they satisfy 1 2 and are project specific.
if 1 and 2 only topic based expert is used.
if 1 and 2 only text based one is used.
the optimal values of 1and 2are learned from the training set section .
.
.
algorithms let us describe our algorithms for training the parameters of t model and those of the combined model dbtm and our prediction algorithm using the trained parameters.
.
training algorithm for t model this algorithm aims to estimate t model s parameters such as zb b and brgiven the training data from a bug database including the collection of bug reports b and the set of groups of duplicate bug reports gj b .
we use gibbs sampling and extend the training algorithm in lda to support our dbtm.
initially the parameters zband brare assigned with random values.
the algorithm then iteratively estimates every parameter based on the distribution calculated from other sampled values.
the iterative process terminates when the estimated values converge that is when the sum of the differences between of the current estimated topic distributions and previous estimated ones is smaller than a threshold.
in our implementation the process stops after a number of iterations that is large enough to ensure a small error.
the detailed steps are .
estimating the topic assignment for bug reports inb with each bug report binb t model estimates the topic assignment zb for position i. for each topic kink topics it estimates the probability that topic kis assigned for position iin document b. then it samples a topic based on the probability values of ks.
since each bug report has or does not have duplicate ones two formulae are needed.
case when a bug report has no duplicate the topic assignment estimation follows the gibbs sampling in lda p zi k zb wb nb nb k nbr k nbr k v where nb is the number of words in b except for the current position i that are assigned to topic k nbis the total number of words in b nbr k is the number of words wiin all bug reports b except for the current position that are assigned to topic k and nbr k is the number of all words in bthat are assigned to topic k. case if a bug report bbelongs to a duplicate group gj they share the same technical issue.
thus we use the following formula to describe the fact of sharing topic in addition to the local topics of each bug report itself p zi k zb wb n b n b k nbr k nbr k v where nbr k is the number of words wiin all bug reports in b except for the current position that are assigned tok and nbr k is the number of words in sdescribing k. comparing to since a duplicate bug report shares the buggy topic with other bug reports in its duplicate group the proportion of a topic kdescribed in the bug report includes its local topic proportion band the topic proportions741 predict andreturn a ranked list ofgroups ofduplicate reports 2function predicttmodel br bugreport bnew duplicategroups gj estimate topic proportion of new bug report bnew repeat bnew bnew for i tonb bnew estimatezb2 bnew i estimate topic at position i end bnew nbnew nbnew estimate topic proportion until bnew b new calculate topic similarity between bug report bnew andgj for duplicategroups gj b sim bnew gj topicsim bnew gj end return list sim bnew gj 16end estimate topic assignment forposition iinb 18function estimatezb2 bugreport bnew int i p zbnew k nbnew nbnew k nbr k nbr k v zbnew sample p zbnew 21end compute topic similarity ofbnew anda group ofduplicate reports 23function topicsim bnew gj for bugreports bi gj topicsim bnew bi jsdivergence bnew bi end topicsim bnew gj max bi gj topicsim bnew bi return topicsim bnew gj 29end figure prediction algorithm of shared buggy topic fjof the duplicate report group gj.
from and we have n b nb ngj and n b nb ngj in which nb is the number of words in b except for the current position i that are assigned to topic k.nbis the total number of words in b. ngj is the total number of positions assigned to topic k in all bug reports in duplicate group gjandngjis the total length of those reports.
note that this equation refers to the impact of the shared topic s in the estimation of b since fj is reflected and estimated via ratio ngj ngj.
.
estimating topic proportion bfor a bug report b once topic assignments for all positions in bare estimated the topic proportion b of topic kinbcan be approximated by simply calculating the ratio between the number of words describing the topic kand the length of the document.
.
estimating word distribution br the last step is to estimate the per topic word distribution for each word wi from v ocand topic k. k is approximated by the ratio between the number of times that the word at i th index inv ocis used to describe topic kand the total number of times that any word is used to describe topic k. .
prediction algorithm for t model the goal of this algorithm is to estimate the topic proportion of a newly arrived bug report bnewand calculate the topic similarity to other bug reports and duplicate groups.
the algorithm uses the trained model from the previous algorithm to estimate the topic proportion of bnew and uses the jensen shannon divergence to calculate the topic similarity between bnewand each bug report in all groups of duplicate reports.
the similarity sim in combination with bm25f based similarity sim will be used to estimate how likely bcan be a duplicate of the reports in the group g. training ensemble weight 1 2function trainalpha reports b traingrps gtrain testgrps gtest 3map gtest lpred 4 1 training fort model andbm25f models 6trainbm25f b gtrain 7traintmodel b gtrain compute text and topic similarity ofa test report anda group 9list sim btest gtest predictbm25f btest gtest list sim btest gtest predicttmodel br btest gtest estimate 1 for 1from to1 increase 1by .
estimate combined similarity build a ranked list ofgroups sim btest gtest 1 sim btest gtest 1 sim btest gtest lpred rankedlist sim btest g return the 1value corresponding tothe maximum map 18end figure ensemble weight training algorithm the output of the algorithm is a list of potential duplicate bug report groups corresponding to the given bug report.
figure describes the steps.
lines show the estimation step for parameters zbnewand bnewfor new bug report bnew the value of bris fixed after training phase and used to estimate zand .
since the real duplicate links between bnewand bug report groups gare unknown we use lda gibbs sampling equation to estimate the new bug report s topic assignment and topic proportion case section .
.
the estimation for zbnewis described in estimatezb2 lines .
in the equation nbnew is the number of words inbnew except the current position i that are assigned to topic k.nbnewis the total number of words in bnew.
nbr k is the number of words wiin the collection of bug reports b except the current position that are assigned to topic k.nbr k is the number of words in bassigned to k. to find the topic similarity between bnewand a group of duplicate reports gj we calculate topicsim bnew gj lines .
topicsim bnew gj lines is calculated by finding the maximum topic similarity between bnewand all bug reports bis in gj line .
we use the jensen shannon divergence jsd to measure the distribution distance between bnewand each bi line .
since jsd is a symmetric measure in jsd is topic similarity in .
finally the algorithm returns a list of topic similarity values between bnewand all groups of duplicate reports.
.
training for combined model dbtm dbtm is linearly combined from t model and bm25f.
thus we need to determine 1and 2for calculating the similarity between bug reports and duplicate report groups.
since 1 2 by definition dbtm has to learn 1 only.
1can be learned from the training set by using simple cross validation and a searching algorithm.
figure shows the training algorithm.
parameters are initialized at lowest possible values lines .
a training set is used for k fold cross validation thus at each cross validation step we have k folds of training duplicate report groups gtrain and one remaining fold of testing group gtest.
dbtm first trains t model and bm25f model lines .
the parameters of trained models are used for estimating text similarity levels line and topic similarity levels line of a test bug report and a duplicate report group.
those75similarity levels are combined into sim btest gtest via a varying weight 1 line with the step of .
.
the combined similarity values are used to rank the links between bug reports and duplicate report groups line .
those ranked lists of links lpredare used to evaluate a goal function map gtest lpred which is used to find the optimized value of 1. the 1value corresponding to the highest value formap will be returned.
the goal function map in our algorithm is the mean average precision as proposed in .
map ltest lpred ltest ltest i index i where ltestis the real duplicate links in the testing set lpred is the ranked list of predicted links index iis the index where the true duplicate group is retrieved for the i th query.
since map measures how well the algorithm ranks the true links it can be used as a goal function in training dbtm.
the weights 1and 2trained from trainalpha are used to calculate the combination of text and topic similarity sim 1 sim 2 sim where sim 1andsim 2are the text and topic similarity between a bug report bnewand the duplicate report group g. the higher the combined similarity the more likely bnewis a duplicate of the reports in g. .
evaluation this section describes our empirical evaluation on dbtm s detection accuracy in comparison with the state of the art approaches rep and rtm .
all experiments were carried out on a computer with cpu amd phenom ii x4 .
ghz 8gb ram and windows .
.
data sets and feature extraction we used the same data sets of bug reports in the opensource projects as in rep .
column time period displays the time period of collected bug reports.
columns report and dupshow the numbers of bug reports and duplicate ones respectively.
columns train and testshow the number of the duplicate bug reports used for training and testing respectively.
the duplication information among bug reports is also available in that data set.
the data is used to train t model and ensemble weights and then used to evaluate dbtm s accuracy in detecting the duplication between a bug report and the duplicate bug report groups.
the summary and description of a bug report were merged and considered as a document.
it then went through preprocessing such as stemming and removing grammatical and stop words and single occurrence words as in rep .
then all the words were collected and indexed into a vocabulary.
after this phase a bug report is represented as a vector of the indexes of its words in the vocabulary.
.
evaluation setting and metrics the evaluation setting is the same as in rep .
all bug reports were sorted in the chronological order.
we divided the data set into two sets.
the training set includes the first mreports in the repository of which reports are duplicates.
it was used to train the parameters for t model bm25f and dbtm.
the remaining reports were used for testing.
at each execution we ran dbtm through the testing reports in the chronological order.
when it determines a duplicate report b it returns the list of top kpotential duplicate report groups.
if a true duplicate report group gistable statistics of all bug report data project time period report dup train test openoffice mozilla eclipse figure accuracy with varied numbers of topics found in the top klist we count it as a hit.
we then added bto that group for later training.
the top kaccuracy i.e.
recall rate is measured by the ratio of the number of hits over the total number of considered bug reports.
.
sensitivity analysis in the first experiment we evaluated the sensitivity of dbtm s accuracy with respect to different numbers of topicsk.
we ran dbtm on eclipse data set as kwas varied from to with the step of and then measured top detection accuracy.
figure shows the result.
the shapes of the graphs for three systems are consistent.
that is as kis small k accuracy is low.
this is reasonable because the number of features for bug reports is too small to distinguish their technical functions thus there are many documents classified into the same topic group even though they contain other technical topics.
when the number of topics increases accuracy increases as well and becomes stable at some ranges.
the stable ranges are slightly different for different projects however they are large k for eclipse k for openoffice and k for mozilla.
this suggests that in any value of kin this range for each project gives high stable accuracy.
the reason might be because the number of topics in these ranges reflect well the numbers of technical issues in those bug reports.
however as kis larger k accuracy starts decreasing because the nuanced topics appear and topics may begin to overlap semantically with each other.
it causes a document to have many topics with similar proportions.
this overfitting problem degrades accuracy.
.
accuracy comparison in this experiment we aimed to evaluate how topic based features in our topic model t model in combination with bm25f can help to detect duplicate bug reports.
we also compared our combined model dbtm with rep .
the parameter kof dbtm in this experiment was selected after fine tuning for best results as in the previous experiment.76figure accuracy comparison in eclipse figure displays the accuracy result of dbtm in comparison with rep on eclipse data set.
we used rep s result from because the same data sets and experiment setting were used in this study.
as shown dbtm achieves very high accuracy in detecting bug reports.
for a new bug report in of the detection cases dbtm can correctly detect the duplication if any with just a single recommended bug report i.e.
the master report of the suggested group .
within a list of top resulting bug reports it correctly detects the duplication of a given report in of the cases.
with a list of reports it can correctly detect in of the cases.
in comparison dbtm achieves higher accuracy from for the resulting lists of top bug reports.
that is it can relatively improve rep by up to in accuracy.
we also compared the performance of two individual components in dbtm.
we implemented bm25f for comparison.
as seen the ir approach bm25f generally achieves higher accuracy than t model alone except for top accuracy and above for eclipse .
examining this case we see that topic model tends to group the bug reports with the same topics but not necessarily duplicates of one another.
rep an extension from bm25f outperformed both topic model and bm25f.
those features such as non textual fields e.g.
product component and version clearly help improve the performance of bm25f.
however because dbtm achieves higher than rep the topic based features from tmodel help improve further the performance of bm25f than those non textual fields.
we found that in several cases rep was not able to detect the duplications of bug reports whose texts are not similar while they can be identified by dbtm via topic features.
that is dbtm takes the best of both worlds topic modeling and information retrieval.
the results are also consistent in other data sets openoffice and mozilla.
figures and display the accuracy results on openoffice and mozilla data sets respectively.
dbtm consistently achieves very high levels of accuracy for top for top and for top accuracy .
in comparison with rep dbtm consistently improves over rep with higher accuracy from .
for openoffice and for mozilla i.e.
relatively .
to compare dbtm with a state of the art topic model rtm we implemented the combined model of rtm and bm25f.
rtm is a topic model extended from lda by figure accuracy comparison in openoffice figure accuracy comparison in mozilla modeling the presence of the observed links between documents.
as seen in figures our dbtm outperformed rtm bm25f from i.e.
relatively .
this result shows that combining topic modeling with ir can achieve better results than individual techniques.
moreover our tmodel is more specialized toward duplicate bug reports and performed better than rtm.
this is reasonable.
first in rtm the presence of a link between two documents depends on the similarity of their respective topic proportions.
two duplicate bug reports do not necessarily have similar topic proportions section .
they might contain more of their own topics.
second in practice there are often more than two duplicate reports in a group.
rtm must be trained for each pair of those duplicate reports and it aims to find the common topic structure among the document pair rather than the shared buggy topic s among all duplicate reports in a group.
dbtm can naturally find the shared topic s and does not focus on individual pairs.
for these data sets we found that there are many groups with two duplicate reports.
thus the results for rtm might get worse in other subject systems if groups contain more than two reports.
.
time efficiency figure shows dbtm s time efficiency result.
the size of a project is the total of the number of bug reports and77figure time efficiency the number of duplicate bug report groups in each data set because training predicting considers both bug reports and duplicate bug report groups.
the sizes are and for openoffice eclipse and mozilla respectively.
the total training and predicting time for those projects are .8s 819s and .7s respectively.
as seen the time is about linear to a project s size e.g.time eclipse size eclipse time mozilla size mozilla .
importantly dbtm is highly efficient.
for a large project like mozilla it took about minutes for training which could be run in background .
for predicting on average prediction time for one bug report are just .031s .035s and .041s for openoffice eclipse and mozilla respectively.
in brief dbtm is scalable and efficient to be used interactively in detecting duplicate bug reports.
interesting case studies figure shows two duplicate bug reports detected by dbtm.
except the terms npe nullpointerexception and structuredviewer which are popular and common in the project the two reports contain several different terms because the reporters found the bug in two different usage scenarios.
that leads to different exception traces one involving image updating and another on widget selection.
we noticed that when running bm25f model by itself bug report is ranked 8thin the list that could be duplicate of bug report due to the dissimilarity in texts.
however after extracting topics via the co occurrences of other terms such as startup first time rse perspective wizard etc in the previous duplicate reports e.g.
from bug report not shown dbtm ranked it at the highest position and detected them as duplicate ones.
threats to validity we evaluated only on three opensource projects.
different projects might have different quality of bug reports.
however eclipse mozilla and openoffice are long lasting projects and were used in prior research.
they are sufficiently representative for our comparison.
we also should validate our method on commercial projects.
.
related work several approaches have been introduced to support the automatic detection of duplicate bug reports.
earlier approaches have applied traditional information retrieval ir methods to this problem .
hiew et al.
use vector space model vsm by modeling a bug report as a vector of textual features computed from tf idf term weighting measurement.
vector similarity is used to measure the similarity among bug reports.
runeson et al.
s combine vsmbug report summary get npe when startup rse on a new workspace description using eclipse m5 driver and rse i20080401 build.
start eclipse on a new workspace and switch to rse perspective.
i could see the following error in the log.
but otherwise things are normal.
java.lang.nullpointerexception at org.eclipse.....getimagedescriptor systemview...java ... at org.eclipse....doupdateitem abstracttreeviewer.java at org.eclipse....doupdateitem safetreeviewer.java at org.eclipse....run structuredviewer.java ... bug report summary npe when selecting linux connection in wizard for the first time description after starting an eclipse for the first time when i went select linux in the new connection wizard i hit this exception.
when i tried again a few times later i wasn t able to hit it.
java.lang.nullpointerexception at org.eclipse....getadditionalwizardpages rsedefault... ... at org.eclipse....updateselection structuredviewer.java at org.eclipse....handleselect structuredviewer.java at org.eclipse....widgetselected structuredviewer.java ... figure duplicate bug reports in eclipse with simple natural language processing nlp to improve further.
in addition to nlp wang et al.
also take advantage of the information on execution traces relevant to the bugs in the bug reports.
however such information might not always be available as it is reported that only a small percentage of bug reports .
contain execution traces .
comparing to those approaches dbtm operates at a higher level of abstraction by also comparing the underlying technical topics in the bug reports.
another line of approach to this problem is machine learning ml .
jalbert and weimer developed a binary classifier model by performing a linear regression over textual features of bug reports computed from the frequencies of terms in bug reports.
to make a binary classifier they specify an output value cutoff over such features that distinguishes between duplication and non duplication.
support vector machine svm was used by sun et al.
in which to train an svm classifier all pairs of duplicate bug reports are formed and considered as the positive samples and all other pairs of non duplicate bug reports are used as the negative ones.
for prediction a new report is paired with all existing reports.
then each pair is fed into the trained svm model and classified as positive or negative.
positive pairs imply duplicate reports.
the key limitation of those aforementioned ml approaches is low time efficiency.
to overcome that recent work by sun et al.
introduced rep a novel ir technique that extends bm25f to consider the long bug reports and the meta data such as the reported product component and version.
they showed that rep outperformed the state of the art ml approaches in both accuracy and efficiency.
in this work we combine bm25f with our novel topic model t model to address the cases where duplicate reports have different terms for the same technical issue.
to our knowledge dbtm is the first work in which topic based features are used with ir to support the detection of duplicate bug reports.78our prior work bugscout has applied topic modeling in the bug localization problem in which for a new bug report it provides a list of potential buggy files for the reported issue.
dbtm is also based on topic modeling however it has significant differences from bugscout.
first while dbtm has one monolithic model with one single vocabulary set bugscout correlates the terms in two separate sub models to represent two different types of documents with two vocabulary sets source code in a programming language and bug reports in a natural language .
second in bugscout the buggy source files which are observable affect the topic assignment of the corresponding bug report.
in dbtm it is more challenging because the buggy topics i.e.
the technical issues are latent and dbtm correlates the terms in the duplicate bug reports that share the technical issue s without determining it.
other researchers focus generally on bug reports.
it is suggested that duplicate reports complement to one another to help in bug fixing .
bettenburg et al.
analyzed information mismatch between what developers need and what users supply to determine good properties in bug reports.
structural information from bug reports has been shown to be useful .
other researchers studied bug reports based on their types quality severity .
from bug reports prediction tools can tell whether a bug could be resolved with certain fixing time.
approaches for automatic bug triaging include .
.
conclusions this paper introduces dbtm a duplicate bug report detection approach that considers not only ir based features but also topic based features.
dbtm models each bug report as a textual document describing one or more technical issues and models duplicate bug reports as the ones on the same technical issue.
trained with historical data including identified duplicate reports dbtm can learn sets of different terms describing the same technical issues and detect other not yet identified duplicate ones.
our empirical evaluation on real world systems shows that dbtm can improve the state of the art approaches by up to in accuracy.
.