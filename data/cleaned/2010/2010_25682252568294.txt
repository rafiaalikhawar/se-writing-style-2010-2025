simrt an automated framework to support regression testing for data races tingting yu witawas srisa an and gregg rothermel department of computer science and engineering university of nebraska lincoln usa tyu witty grother cse.unl.edu abstract concurrent programs are prone to various classes of difficult todetect faults of which data races are particularly prevalent.
prior work has attempted to increase the cost effectiveness of approaches for testing for data races by employing race detection techniques but to date no work has considered cost effective approaches for re testing for races as programs evolve.
in this paper we present simrt an automated regression testing framework for use in detecting races introduced by code modifications.
s imrt employs a regression test selection technique focused on sets of program elements related to race detection to reduce the number of test cases that must be run on a changed program to detect races that occur due to code modifications and it employs a test case prioritization technique to improve the rate at which such races are detected.
our empirical study of s imrt reveals that it is more efficient and effective for revealing races than other approaches and that its constituent test selection and prioritization components each contribute to its performance.
categories and subject descriptors d. .
testing and debugging testing tools tracing d. .
process management general terms reliability experimentation keywords testing concurrency processes data races kernels .
introduction the advent of multicore processors has greatly increased the prevalence of concurrent software.
however failures due to concurrency faults still occur prolifically in deployed concurrent systems .
there are several classes of concurrency faults including data races atomicity violations and deadlock.
among these data races occur particularly frequently.
research has shown permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
icse may june hyderabad india copyright acm ... .
.for example that data races remain a primary cause of concurrency faults in the windows kernel .
searches of bug repositories for widely used software systems such as the linux os and apache tomcat also reveal frequent occurrences of data races .
in practice software testing is the primary approach used by engineers to detect concurrency faults .
in software testing the most typical approach for verifying test results involves checking system outputs following test execution.
however data races do not always produce failures that are visible in program outputs therefore techniques that inspect outputs to detect failures can be ineffective at detecting data races.
to address this problem two general approaches have been used.
first developers can apply dynamic analysis techniques to detect potential races instead of waiting for the effect of races to propagate to output .
unfortunately many reported potential races are false positives that cannot result in actual races.
furthermore these techniques monitor every shared memory access and synchronization operation so they incur significant runtime overhead.
a second group of techniques attempt to distinguish real races from potential races .
these techniques explore multiple thread schedulings to determine whether a potential race can lead to a real race.
to do this the techniques may require a program under test to be executed several times under each test input in order to explore different thread interleavings.
when used with large test suites the foregoing approaches can render the testing process unduly expensive due to the high overhead of potential race detection and the costs of multiple program executions in race verification.
recent work reports that each of the two approaches can introduce a 10x 100x slowdown for each test run.
such overhead increases as test suite size increases.
to address this problem yu et al.
propose m aple which reduces the number of potential races that must be verified.
instead of verifying every detected potential race with a test input m aple avoids re verifying potential races that have previously been verified.
this technique however still incurs a 10x 100x slowdown because it does not reduce the cost of detecting potential races.
while the challenges for testing concurrent programs for data races are extensive an additional challenge arises as these programs evolve.
as programs evolve they must be regression tested to assess whether changes have adversely affected system behavior and whether new code behaves as intended.
regression testing can be expensive and to render it more cost effective various approaches have been suggested including regression test selection and test case prioritization.
however most research on regression testing to date has focused on sequential software and to our knowledge none has considered the issues involved in regression testing for concurrency faults such as data races.
one approach for re validating concurrent systems would be topermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may june hyderabad india copyright acm ... .
apply dynamic race detection techniques to new versions of systems following the application of traditional regression testing techniques .
however traditional regression testing techniques may not be cost effective in this context.
for example empirical studies have shown that in certain cases traditional regression test selection techniques can select inordinately large numbers of test cases and yield no benefit in reducing the overhead associated with race detection .
to address this problem in this work we propose s imrt an automated regression testing framework for use in detecting races that are induced in concurrent programs by code modifications.
s imrt identifies variables that can be accessed by multiple threads in a modified program and that are impacted by modifications.
s imrt then employs a regression test selection technique to select the test cases from the program s regression test suite that exercise these shared variables in a manner that involves more than one thread.
it is these test cases that are specifically relevant to detecting races.
while regression test selection targeting shared variables helps simrt reduce the cost of regression testing the testing process is still unnecessarily burdened by the cost of dynamic race detection approaches because different inputs tend to repeatedly execute the same memory locations and interleavings.
deng et al.
observe that up to of test inputs always execute the same shared memory locations and interleavings and thus do not increase race detection rate as test cases execute.
thus s imrt next applies a greedy test case prioritization algorithm to schedule the test cases selected in its prior phase in an order that detects races faster.
to assess s imrt we conducted an empirical study in which we applied the approach to modified versions of nine concurrent source code objects all of which contain data races that are the result of code modifications.
we assessed both the regression test selection and test case prioritization components of our approach by comparing s imrt to traditional and baseline regression test selection and test case prioritization techniques.
our results show that s imrt is more efficient than a common baseline regression test selection technique and substantially more efficient than the default technique of executing all test cases while retaining the effectiveness of those techniques.
our results also show that the prioritization of test cases by s imrt substantially increases the rate at which races are detected with respect to a common baseline prioritization technique and a random ordering of test cases.
.
background .
regression testing letpbe a program let p0be a modified version of p and lettbe a test suite for p. regression testing is concerned with validating p0.
to facilitate this engineers often begin by reusing t but reusing all of t theretest all approach can be inordinately expensive.
thus a wide variety of approaches have been developed for rendering reuse more cost effective via regression test selection and test case prioritization provides a recent survey .
regression test selection rts techniques select from test suite t a subset t0that contains test cases that are important to rerun.
in our own prior work we presented the rts technique dejavu .
dejavu performs simultaneous depth first traversals on control flow graphs cfgs for procedures in pandp0to find dangerous edges that lead to code that has changed.
execution traces of test cases bit vectors indicating whether basic blocks were covered on pare then used to select test cases that traversed dangerous edges in p. we have shown that when certain conditions are met d ejavu issafe i.e.
it cannot omit test cases which if executed on p0 would reveal faults in p0due to code modifications.test case prioritization tcp techniques reorder the test cases intsuch that testing objectives can be met more quickly and one potential objective involves revealing faults.
a wide range of tcp techniques have been proposed and studied and one technique that has proven successful is the additional block coverage technique .
given the results of executing tests and gathering trace information this technique prioritizes test cases in terms of the numbers of new not yet covered basic blocks they cover by iteratively selecting the test case that covers the most not yet covered blocks until all blocks are covered then repeating this process until all blocks have been covered.
because tcp techniques do not themselves discard test cases they can avoid the drawbacks that can occur when regression test selection cannot achieve safety.
alternatively in cases where discarding test cases is acceptable test case prioritization can be used in conjunction with regression test selection to prioritize the test cases in the selected test suite.
further test case prioritization can increase the likelihood that if regression testing activities are unexpectedly terminated testing time will have been spent more beneficially than if test cases were not prioritized.
a key insight behind the techniques just described is that certain testing related tasks such as gathering code coverage data can be performed in the preliminary period of testing before changes to a new version are complete.
the information derived from these tasks can then be used during the critical period of testing after changes are complete and when time is more limited.
.
race detection and verification a data race occurs when two threads can simultaneously access a shared variable with at least one access being a write .
many static and dynamic analysis techniques have been developed to detect data races.
in this work we consider dynamic race detection techniques.
algorithms to dynamically detect data races can be classified as lock set vector clock and hybrid approaches .
these algorithms can report false positives because they cannot guarantee that a race can really occur under specific thread interleavings.
we refer to the races reported by these algorithms aspotential races .
techniques have also been proposed to determine whether potential races identified by a detector can actually occur.
we refer to races that have been verified in this way as real races .
however even race verifiers cannot differentiate harmful races from benign races they report any pair of unsynchronized accesses at least one of which is a write as a race.
racefuzzer is a race detection tool that combines dynamic race detection and race verification.
r acefuzzer computes pairs of program instructions that could potentially race during concurrent execution.
it then randomly schedules the program under test based on the computed instruction pairs to allow real racing events to be placed temporally next to each other.
employing random schedules for race verification is precise andcost effective but can be incomplete .
random scheduling does not guarantee that verification can distinguish all real races from potential races rather it guarantees that if it can cause a race to occur this potential race will become a real race.
on the other hand complete replay techniques such as penelope may incur much higher overhead due to context switches.
.
testing for races software testing requires test inputs.
given a set of test inputs the race detection process for a multi threaded program involves two steps.
first for each test input the program is executed by a dynamic race detection tool that identifies potential races race491p u b l i c boolean c o n t a i n s v a l u e o b j e c t v a l u e e n t r y t a b t a b l e b l o c k id i f v a l u e n u l l f o r i n t i t a b .
l e n g t h i b l o c k id .
.
.
e l s e .
.
.
return t ru e b l o c k id return f a l s e 21p u b l i c void c l e a r .
.
.
synchronized t h i s e n t r y t a b t a b l e b l o c k id f o r i n t i i t a b .
l e n g t h i t a b n u l l b l o c k id b l o c k id .
.
.
1p u b l i c boolean c o n t a i n s v a l u e o b j e c t v a l u e e n t r y t a b t a b l e i f v a l u e n u l l f o r i n t i i t a b .
l e n g t h i change .
.
.
e l s e .
.
.
return c o n t a i n s n u l l change return f a l s e p r i v a t e boolean c o n t a i n s n u l l e n t r y t a b t a b l e f o r i n t i i t a b .
l e n g t h i f o r e n t r y e t a b e !
n u l l e e .
n e x t .
.
.
p u b l i c void c l e a r .
.
.
synchronized t h i s e n t r y t a b t a b l e f o r i n t i i t a b .
l e n g t h i t a b n u l l modcount change .
.
.
figure original hm program p left and a modified version of the hm program p0 right detection .
second for any input tthat produces a set of potential races praceset in the first step and for each pr2praceset the program is executed n n n times to verify prunder t where nis defined by users in terms of a testing budget race verification .
we define n for s imrt to simulate a resourceconstrained testing environment.
our s imrt approach uses r acefuzzer to test for races by following the foregoing two steps.
however in the race verification phase r acefuzzer verifies every potential race reported in the race detection phase for the given input regardless of whether this race has already been verified by previous inputs.
this can be expensive when given large test suites particularly when each test case reports redundant potential races in the race detection phase.
to alleviate this problem we adjusted r acefuzzer so that once a potential racing pair is confirmed to be a real race it is not verified again under another input.
specifically for each test input simrt first invokes r acefuzzer and reports potential races.
if there exist any potential races that have not been confirmed as real races s imrt invokes r acefuzzer to verify each of them under the same test input before proceeding to the next test input.
as such the actual number of test runs for an entire test suite tis tr jtj jpracesetjp i 1nti here jtjis the total number of original tests jpracesetjis the number of potential races and ntiis the number of tests required to verify the ithpair in praceset .
.
approach figure contains an example that we use to illustrate our approach.
the figure provides code snippets from two versions of the jdk s hashmap utility slightly modified and referred to here as hm .
the variables table tab next andmodcount are identified as shared variables by thread escape analysis see section .
.
a test driver for this code instantiates an hmobject from classhm.
the two parameters in the constructor of hmspecify the initial capacity and load factor.
each of the test cases for the code involves two components each executing in its own thread.
we define four test case components case0 hm.clear case1 hm.containsvalue new hm .0f case2 hm.containsvalue new hm .0f case3 hm.containsvalue null a test case tciis denoted by m n m n where mand ndenote two of the foregoing cases i.e.
case mandcase n .
suppose there are six test cases generated for version pofhm tc1 tc2 tc3 tc4 tc5 andtc6 .
in version p0ofhm there are two changes that cause three races to occur.
the first change involves addition of a new method containsnull and a call to it from line .
this change causes a read write race involving tab at line andtab at line when executing tc1ortc2 i.e.
concurrently executing containsnull andclear .
the second change involves addition of a new line of code line that reads and writes a class variable modcount .
two data races occur in this case involving modcount when tc3is executed one is a writewrite race and the other is a read write race.
.
overview of simrt figure provides an overview of s imrt.
s imrt contains five components svlocator impanalyzer matcher selector ranker .
letpbe a program let p0be a modified version of p letc0be the set of changes made to pto produce p0 a set of program locations inp0 let b0 svdenote a block in a method in p0that contains a shared variable sv and let bsvbe a block in a method in p that corresponds to b0 sv.
simrt first computes a list of shared variables l0 svinp0using svlocator .
next impanalyzer updates l0 svby mapping b0 svtobsv and identifying the shared variables in l0 svthat are potentially impacted by one of the changes c0inp0.
next matcher iterates over each svinl0 sv and selects thesvs that can be matched into pairs.
the output of matcher is a list of impacted shared variable pairs i0 sv p that are coverage targets for rts and tcp techniques.
next selector selects t02tfor use in regression testing p0.
finally ranker prioritizes p p impanalyzer i svp l sv t hp selector t t p l sv updated svlocator matcher ranker b sv bsv tp figure overview of simrt50the test cases in t0 ort producing t0 p ortp .
both selector andranker utilize coverage history information provided as hp.
we describe each of these components in the sections that follow.
.
shared variable identification svlocator produces a list of variables l0 svthat can be accessed by multiple threads in p0.
in java shared variables can be identified by using thread escape analysis we adopted the conservative shared variable detection algorithm proposed in that uses the threadlocalobjectanalysis api provided by s oot to compute variables that can potentially be read from and written to by multiple threads simultaneously.
we also used the alias analysis provided by s oot to identify a set of escaping variables that can potentially access the same location.
each shared variable sv is defined as a tuple c m n d l a b i where cis a class name mis a method signature nis the name of the sv dis a memory access identifier svs that potentially access the same memory location share the same identifier lis a line number at which the svoccurs adenotes the access operation read or write performed on the sv bis the block id a unique number in c m inpwhere svis mapped to and iis a boolean value indicating whether svis impacted.
note that c m must exist in both p and p .
if a method m0in p0in which a sv occurs does not exist in p we locate in the call graphs for p0 the method that most directly calls m0that also exists in p and if no such method is found c m is defined as?.
in the hmprogram shared variables in p0are displayed as the following initialized tuples sv1 hm.containsvalue object table read ?
?
sv2 hm.containsvalue object table read ?
?
sv3 hm.containsvalue object tab read ?
?
sv4 hm.containsvalue object next read ?
?
sv5 hm.clear table read ?
?
sv6 hm.clear tab write ?
?
sv7 hm.clear modcount read ?
?
sv8 hm.clear modcount write ?
?
here hm.containsvalue object table read ?
?
indicates that in line in p0 variable table is read with access identifier .
the method hm.containsnull in which table occurs does not exist in p thus hm.contains value object is filled into c m .
elements bandiare not specified until the comparison algorithm section .
is invoked.
.
shared variable impact analysis figure displays the algorithm used by i mpanalyzer .
the algorithm takes program p modified version p0 and a list of shared variables l0 svwith initialized tuples as inputs and returns the updated l0 sv.
first the algorithm constructs control flow graphs cfgs gandg0for all methods in pandp0 line .
each node in a cfg is represented using a unique block id.
next the algorithm compares each cfg ginpto the corresponding g0inp0by calling compare line .
the comparison begins with entry nodes eande0.
given two cfg nodes nandn0 compare determines whether nandn0have successors sands0 whose code differs along pairs of identically labeled edges lines .
up to this point impanalyzer behaves identically to the original d ejavu algorithm .
however impanalyzer uses different mechanisms to handle node comparisons.
impanalyzer obtains a set of line numbers in block node s0 line .
if the code associated with sands0is the same line the algorithm iterates overl0 sv and picks the svs that are contained in s0 line .
for each of these svs tuple element bis set to the block id of s line and tuple element iis set to false line indicatingprocedure updatesvinfo inputs p p0 l0 sv2 outputs l0 svforp0 updated begin construct cfgs for pandp0 foreachg2cfg andg02cfg0 compare e e0 start from entry nodes endfor returnl0 sv9 end procedure compare inputs n n0 nodes ingandg0 outputs l0 svforg0 updated begin isvisted n true whethernis visited foreach successor sofn2g if n s is labeled l the label on edge n s else l endif s0 the node in g0such that n0 s0 has labell ifisvisited s isfalse lns s0 getblocklinenumbers s0 iflequivalent s s0 if code is equivalent foreachsv2l0 sv25 lnsv getsvlinenumber sv iflnsv2lns s0 setoldblockid sv s setisimpacted sv false break endif endfor compare s s0 else foreachsv2l0 sv35 ifisimpactedby sv s0 setoldblockid sv s setisimpacted sv true break endif endfor endif endif endfor end figure impanalyzer algorithm that this shared variable is not impacted.
if the code associated with sands0differs along some pair of identically labeled edges impanalyzer iterates over l0 svand determines the impacted shared variables line .
if a shared variable svis impacted by the change tuple element bis set to old block id s line and tuple element iis set to true line indicating the existence of impact.
a shared variable is considered impacted line in the following cases .
if a change to p0involves an svinp0and this svis either added to or modified in p0 ansvis considered impacted.
.
if a change to p0involves adding or modifying a method all svs in this method are considered impacted.
.
if a change to p0involves a synchronization statement all thesvs in the entire region of the synchronized block are considered impacted.
for example if line in program pis omitted all shared variables inside the synchronization block sv5andsv6 are considered impacted.
in addition to considering blocks using the synchronized keyword we also consider blocks using explicit locks including lock unlock and trylock and locks implementing a51readwritelock interface readlock writelock .
we do not consider changes involving wait notify ornotifyall these must be called inside a synchronized block and changing them does not affect svs in synchronized blocks.
.
if a change to p0involves removing a volatile keyword in the declaration of an sv all subsequent uses of this svare considered impacted.
.
if a change to p0does not involve an sv but its full impact set in p0 obtained by traditional impact analysis such as static forward slicing includes one or more svs these svs are considered impacted.
in the example shown in figure i mpanalyzer compares the method containsvalue object inpandp0.
the algorithm begins by visiting the node with block id in p lines and compares it to its corresponding node in p0.
the two blocks are equal so the algorithm updates tuple elements bandifor all svs in lines of p0.
thus hm.containsvalue object table read ?
?
is set to hm.contains value object table read false .
here b is the block id in pthattable is mapped to and i false indicates that table is not impacted.
next i mpanalyzer compares the nodes at line in both pand p0.
although line is changed in p0 the change does not impact any shared variables.
thus the comparison proceeds to the next node in p. when ti mpanalyzer visits the node corresponding to block in hm.containsvalue object inp it discovers that line in p0is changed by addition of the call to method containsnull .
thus all svs in this method are considered impacted.
for example hm.containsvalue object next read ?
?
is set to hm.contains value object next read true .
after the algorithm returns the two undefined elements in each svare noted.
in the example shown in figure the list of shared variables is updated as follows sv1 hm.containsvalue object table read false sv2 hm.containsvalue object table read true sv3 hm.containsvalue object tab read true sv4 hm.containsvalue object next read true sv5 hm.clear table read false sv6 hm.clear tab write false sv7 hm.clear modcount read true sv8 hm.clear modcount write true .
.
matching shared variables because race detection involves pairs of shared variable accesses the next step is to use matcher to identify a set of impacted shared variable pairs i0 sv p serving as coverage targets for the selector andranker modules.
we define an impacted shared variable pair isv p as a pair of shared variables sviandsvj such that at least one of them is impacted and at least one of them is a write access.
to illustrate matcher takes the updated shared variable list l0 sv computed in figure as input and outputs the potential impacted shared variable pairs i0 sv p .
for each shared variable sviinl0 sv ifsviis impacted determined by querying element iin the svi tuple the algorithm iterates over l0 svto identify each svjinl0 sv that is shared with svi regardless of whether svjis impacted.
as a result each qualified isv p svi svj is added to i0 sv p .
in our example five variables are impacted sv2 sv3 sv4 sv7 and sv8 but only sv3 sv7 andsv8qualify for pairing so i0 sv p sv3 sv6 sv7 sv8 sv8 sv8 .procedure testselection inputs t hp i0 sv p46 outputs t0 begin t0 foreach svi svj 2i0 sv p50 b1 getoldblockid svi b2 getoldblockid svj foreachtc2t ifhp tc b true andhp tc b true and hp tc tid b1 tid b2 true t0 t0 tc endif endfor endfor end figure regression test selection algorithm .
regression test selection the next step is to use selector to select test cases that are relevant to race detection.
a naive approach is to select every test case that traverses any svi svj 2i0 sv p .
however this may include test cases that execute shared variables but involve only one thread.
instead s imrt selects test cases by traversing the tuple elements bofsviandsvjinvolved in different threads.
to facilitate this when collecting coverage information for each block in the original program p which is done during the preliminary phase of testing we also record the thread ids that cover each block.
as such the constructed test history indicates whether a block is covered and the ids of the threads that cover this block.
figure shows the selector algorithm.
the algorithm takes three inputs test suite t the impacted shared variable pairs i0 sv p and the test coverage history that indicates which test cases in tcovered which statements in pwith which thread.
hpis denoted by tci c m b tid where tciis the test case with number i c m is the class name combined with the method signature bis the block id that tcicovers and tid is the id of the thread that covers b. for each shared variable pair svi svj ini0 sv p the algorithm obtains the matching block ids b1andb2forsviand svj line as coverage targets.
based on the coverage history hp the algorithm selects all test cases from tthat traversed b1 andb2 the first two conditions in line with different threads the third condition in line and adds them to t0 line .
in our example suppose the coverage history hpholds the following coverage information for each of the six test cases tc1 hm.clear hm.clear hm.clear hm.containsvalue object hm.containsvalue object tc2 hm.clear hm.clear hm.clear hm.containsvalue object hm.containsvalue object tc3 hm.clear hm.clear hm.clear hm.clear hm.clear hm.clear tc4 hm.clear hm.clear hm.containsvalue object hm.containsvalue object tc5 hm.containsvalue object hm.containsvalue object hm.containsvalue object hm.containsvalue object tc6 hm.containsvalue object hm.containsvalue object hm.containsvalue object hm.containsvalue object .
in this case both tc1andtc2cover one target sv3 sv6 with different threads and tc3covers two targets sv7 sv8 and sv8 sv8 with different threads.
test cases tc5 andtc6do not cover any targets.
test case tc4covers targets sv7 sv8 and sv8 sv8 but with only one thread.
therefore t0 tc1 tc2 tc3 .
in contrast most traditional rts techniques would select all six test cases for t0because they all cover changed blocks.
by running52teststc1 tc2andtc3we can detect all three races while tc4 tc5 andtc6do not help expose races.
note that we select both tc1andtc2even though they cover the same target.
the reason for this is because covering executing the two shared variables in the target pair under one test input is not necessarily sufficient to determine whether they access the same memory addresses .
different inputs could cause different states to exist in the same code region causing two instructions in the target pair to access different memory locations under one input and the same memory location under a different input.
.
test case prioritization ranker prioritizes test cases beginning with those identified by selector .ranker iterates over t0 selects the test case tcithat covers the most impacted shared variable pairs isv p s ini0 sv p and places tciint0 p. next ranker iteratively selects the test case tci that covers the most isv p s and appends tcitot0 p. when multiple test cases cover the same number of isv p s ranker chooses one randomly.
if each isv p has been covered by at least one test case and the remaining unprioritized test cases cannot add additional coverage ranker resets the coverage vectors for all unprioritized test cases to their initial values and reapplies the prioritization approach ignoring previously prioritized test cases.
in our example program tc1andtc2cover sv3 sv6 with different threads and tc3covers sv7 sv8 and sv8 sv8 with different threads.
ranker first places tc3intp.
because tc1and tc2achieve the same additional coverage the algorithm randomly selects one of these say tc1 and appends it to t0 p. next the algorithm resets the coverage data.
as such tc2becomes the test case that covers the most isv p s and is appended to t0 p. therefore the output of ranker ist0 p tc3 tc1 tc2 .
when running t0 p all three races can be exposed by the first two test cases.
as noted in section the safety of rts techniques depends on certain conditions and these include the condition that the program under test be executed deterministically.
this condition cannot generally be met for the class of programs that we consider and thus s imrt may omit test cases from t0that could reveal races inp0.
in this context it is important to note that even a retestall approach can omit race revealing test cases because a given test case may or may not expose a fault in a given run when nondeterminism affects thread behavior.
the motivation for selecting a subset of test cases however is to select test cases that are more likely to reveal races than others allowing testers to focus on more worthwhile pursuits.
nevertheless if test engineers wish they can useranker to further prioritize the remaining test cases t t0 and execute those test cases as well.
this process is performed using the approach just described applied to t t0 in two steps where step focuses on test cases that cover the most impacted shared variables and step focuses on test cases that cover only non impacted shared variables.
in our example when prioritizing the remaining test cases having already set tpto tc3 tc1 tc2 ranker notes that step tc4covers two impacted shared variables sv7andsv8 and tc5 covers three impacted shared variables sv2 sv3 and sv4 and appends these to tp obtaining tc3 tc1 tc2 tc5 tc4 .
in step sincetc6covers sv1 a shared variable that is not impacted ranker appends that to tp.
ultimately tp tc3 tc1 tc2 tc5 tc4 tc6 .
.
empirical study we wish to determine whether s imrt is cost effective and ideally such an assessment would involve comparisons with existing state of the art approaches for detecting races in modified software.
there are however no existing approaches that have thisspecific goal.
in the absence of such approaches we can instead compare s imrt to processes that are currently used in general regression testing applications that might likewise be employed in our setting.
a second important issue regarding s imrt involves whether either or both of its component techniques selection and prioritization play a role in its cost effectiveness or lack thereof and if so to what extent.
understanding this issue is important to any efforts to extend the approach further.
we thus designed a study focusing on three research questions rq1 how do the efficiency andeffectiveness of s imrt considering only its regression test selection component compare to those of the retest all technique and a state of the art rts technique.
rq2 how does the effectiveness of the tcp technique employed by s imrt compare to that of random test case orders when just the prioritized selected test cases are considered?
rq3 how does the effectiveness of the tcp technique employed by s imrt compare to that of traditional additional block coverage prioritization and random test case orders when the entire prioritized test suite is considered?
rq1 lets us consider the overall efficiency and effectiveness of simrt focusing on its regression test selection component compared to the baseline approach in which no selection is performed and to a state of the art rts technique.
rq2 lets us consider whether prioritization of just those test cases selected by s imrt helps detect races more quickly than leaving them unprioritized.
rq3 lets us consider the overall effectiveness of prioritization if complete test suites are used.
.
objects of analysis we chose nine open source java objects which are representative of real world code and have been widely used in academic research.
these included one object downloaded from the softwareartifact infrastructure repository sir five objects from jdk and three larger objects .
the objects include both closed code units code units equipped with test drivers and open code units libraries that require test drivers to close them .
among the closed objects w eblech is a multi threaded web site download and mirror tool it accepts both command line options and a configuration file that specifies settings such as url search options e.g.
bfs dfs and number of threads.
j igsaw is a leading edge web server platform it accepts configuration files on both client and server sites and multiple main entry points with command line options.
among the open objects l ang is part of the apache common lang project.
l og4jis a java logging application.
h ashmap treemap arraylist hashtable and bitset are synchronized collection classes provided by sun microsystems jdk.
to close these objects we wrote test drivers that utilize unit test cases generated by r andoop described later .
because r andoop does not support multi threaded programs the test drivers also create sets of threads that concurrently execute the methods.
we utilized two versions of each of the nine objects.
table lists our object versions along with some of their characteristics including the number of lines of non comment code nloc column and the number of shared variables identified in the modified versions svs column using the technique described in section the numbers in parentheses indicate the number of impacted shared variables .
other columns are described later.
to address our questions we also required multi threaded test cases.
our objects however were either not equipped with such test cases or the test suites supplied with them were too small e.g.
53table objects of analysis and their characteristics program nloc t prs rrs svs isvs isvcovs lang v lang v hashmap v1.
hashmap v1.
treemap v1.
treemap v1.
arraylist v1.
arraylist v1.
hashtable v1.
hashtable v1.
bitset v1.
bitset v1.
log4j v1.
.
log4j v1.
.
weblech v0.
weblech v0.
jigsaw v2.
.
jigsaw v2.
.
fewer than test cases to allow s imrt to operate as intended.
to simulate a resource constrained testing environment in which it makes sense to utilize approaches such as s imrt we chose to create test cases using a testing time budget that limits the maximum number of test cases that can be executed for a given object.
the testing time budgets we chose were selected to be relevant to the size and complexity of the objects.
for the six smaller and less complex objects we chose a testing budget of hours i.e.
testing that can be performed overnight .
for the three larger and more complex objects we chose a testing budget of hours i.e.
testing that can be completed over a weekend.
both of these are practically realistic choices that engineers could make given that the testing required by our approach can be conducted automatically without the need for human intervention yet must like any validation effort be conducted within some fixed time period.
note that the testing time we measured is based on the time required to run the instrumented original object with race detectors in place thus the numbers of generated test cases depend on the instrumentation overhead for different object objects.
the test cases we used were created using test case generation techniques relevant to the objects.
because our goal is to detect races a test case must include two components test input data and specified thread interleavings .
for objects weblech and j igsaw which accept configuration files we used incremental covering arrays to generate test inputs.
they also accept inputs via command line options and such inputs were randomly generated.
for the closed objects which were not equipped with test drivers we first used r andoop to generate unit test cases for each method and then we created multiple threads to concurrently execute these methods.
note that the number of threads is another input argument.
for all object objects the number of threads if mutable associated with each test input was randomly generated in a range from to .
column of table t lists the numbers of test cases ultimately utilized for each object.
to address our research questions we also needed to know what races if any existed in our object objects.
to determine this we ran all test cases on the original version of each object using the modified version of r acefuzzer described in section .
we discovered that the original object versions contained many potential and real races.
in this work we are interested only in regression races i.e.
races introduced by code modifications not residual races races that persist across versions of the modified objects .
hence we located the causes of such races in the original object versions and corrected the code in both versions to ensure that they would not occur in either.
next we executed all of the test cases associated with each original object on its modified version withthe race detector and verifier enabled.
this yielded a set of regression races that had been introduced by the code changes made to the modified versions.
because non determinism may cause race detectors to report different results on different object executions we repeated the foregoing process ten times for each object pair and accumulated any newly detected races.
the fluctuation in numbers of races reported on different runs was actually quite small and is discussed further in section .
columns and of table list the numbers of potential and real regression races prs and rrs discovered in the foregoing process.
column lists the number of impacted variables isv covs that are covered in the modified objects.
.
variables and measures .
.
independent variable our independent variable involves the techniques used in our study.
as noted earlier we consider s imrt the traditional retestall technique rta and the traditional d ejavu rts technique hereafter referred to as rtsc .
with all three of these we enable the race detector and verifier.
we use s imrtsto denote s imrt with just the rts technique enabled.
we refer to s imrt when it also employs a tcp technique as simrtsp.
when considering rq2 and just selected test cases we compare s imrtspto a random test case ordering applied to just the selected test cases denoted here by r andom sp .
when considering rq3 in which all test cases are prioritized we compare s imrt denoting this version of the technique by simrtap to two approaches a random test case ordering applied to all test cases denoted here by r andom ap and an application of the additional block coverage prioritization technique denoted here by abc ap described in section .
.
.
dependent variables as dependent variables we chose metrics allowing us to answer each of our three research questions.
regression test selection.
to measure the efficiency of regression test selection we measured testing time by adding relevant measures including the time required for escape and impact analyses if any the time required for running regression test selection algorithms if any and the time required to execute test cases.1to obtain these times we applied rtsc and s imrtsand measured relevant analysis and test selection times.
then to account for possible differences in testing times per execution of sets of test cases we executed each object ten times on the various sets of selected test cases or in the case of rta on all test cases and calculated the average time required to execute the test cases.
to measure race detection effectiveness we compare the numbers of potential and real races detected by test cases selected by rta rtsc and s imrts.
test case prioritization.
to measure the effectiveness of test case prioritization we considered the rate at which test cases detect both potential and real races.
to measure such rates we use the wellknown metric apfd average percentage fault detected .
lettbe a test suite containing ntest cases let tpbe a prioritized version of t and let rbe a set of mraces revealed by t. lettri 1when measuring testing time we do not include time spent on activities performed in the preliminary phase of regression testing prior to the time at which the modified object is available for testing and when testing time becomes a critical issue these include collection of test history information and construction of control flow graphs for the original object.54be the first test case in ordering tpoftthat reveals race i. the apfd for test suite tpis given by the equation apfd jm 1jp i 1jtrij n m 2n apfd ranges from to with higher values indicating faster rates of race detection.
theapfd metric can be applied to orderings of the entire test suitet or to orderings of just the set of selected test cases t0.
in the former case n jtj and in the latter case n jt0j.
.
study operation we conducted our experiment runs on a linux cluster with amd cores housed in nodes with 128gb per node.
we used a modified version of r acefuzzer for race detection and verification see section .
among our objects the instrumentation overhead incurred by our r acefuzzer ranged from .5x to 20x.
the remaining components in our framework i.e.
impanalyzer matcher selector andranker were implemented using java by following the algorithms described in section .
as noted in executing a program once per input is sufficient to detect most if not all of the concurrent faults detectable under that input because progams tend to follow the same interleaving patterns during different executions.
as we discuss in section executing a program on the same input additional times may occasionally uncover additional races but the benefit of this may be outweighed by the increased cost of testing.
therefore the data reported in this study for each technique was obtained by executing each object once.
however we discuss the impact of race detection effectiveness given multiple test runs in section .
.
threats to validity the primary threat to external validity for this study involves the representativeness of our objects and test cases.
other objects and test cases may exhibit different behaviors and cost benefit tradeoffs.
however we do reduce this threat to some extent by using several varieties of well studied open source code objects for our study and test suites generated by practical approaches.
the primary threat to internal validity for this study is possible faults in the implementation of our approach and in the tools that we use to perform evaluation.
we controlled for this threat by extensively testing our tools and verifying their results against a smaller program for which we can manually determine the correct results.
where construct validity is concerned our measurements of efficiency of regression test selection focus on the time required for analysis and test execution.
however other costs such as test setup and maintenance costs can play a role in technique efficiency.
our measurement of effectiveness for test case prioritization is apfd .
although apfd does have certain limitations it does provide a simple intuitive measurement for rapid race detection.
.
results and analysis .
.
rq1 regression test selection efficiency.
figures and show technique execution times in minutes for each of the three techniques and nine objects.
for the six small objects using overnight testing rtsc required less time than rta with savings ranging from .
to .
and an average savings of .
across all six objects.
s imrt achieved even greater savings than rta on the smaller objects with an average savings of .
and savings on individual objects ranging from .
to .
.
for the three objects using over the weekend testing rtsc required less time than rta on only one object log4j lang hashmap treemap arraylist hashtable bitset time mins rta rtsc simrt s figure efficiency testing times for smaller objects log4j weblech jigsaw time mins rta rtsc simrt s figure efficiency testing times for larger objects with a savings of .
.
s imrt achieved greater savings than rta on all three objects with savings of .
on log4j .
onweblech and .
on jigsaw .
we also measured the time required by rtsc and s imrt to perform analysis tasks.
due to space limitations we do not present all of the data but overall while s imrt required greater analysis times than rtsc its analysis times never exceeded seconds which accounted for less than .
of technique runtime overall.
the time spent on escape analysis and impact analysis never exceeded seconds.
we also measured the time spent by s imrt on race verification and the results ranged from to .
of total technique runtime.
the remaining time was spent on analysis tasks and race detection.
verification time varied with the number of detected potential races and the number of test runs needed to verify each potential race.
testing times did vary across objects.
the number of test cases selected by techniques depends on the program locations in which changes occur or in which shared variables are impacted and this in turn affects testing time.
for example in w eblech many changes occur inside the main function causing all test cases to be selected by rtsc thus in this case no time is saved.
effectiveness.
we consider whether races both potential and real detected by rta and rtsc can also be detected by s imrt.
table shows the numbers of potential and real races detected for each of the nine objects by rta rtsc and s imrt.
because the data reported for each technique is based on a single run the numbers of races detected by rta do not necessarily equal the numbers in table negative numbers in parentheses indicate the numbers of races missed compared to those known to be detectable.
for all nine objects rtsc detected of the potential and real races detected by rta.
s imrt on the other hand detected of the potential races on seven of nine objects and of the real races on all nine.
on log4jand jigsaw simrt missed one and two potential races respectively.
this sacrifice in effectiveness is relatively small with only .
of the potential races detected by rta and rtsc missed across the nine objects.
meanwhile the associated savings in terms of testing time was large.55table apfd values for selected and all test cases prog.
potential races real races simrt sp random sp simrt ap abcap random ap simrt sp random sp simrt ap abcap random ap lang .
.
.
.
.
.
.
.
.
.
hashmap .
.
.
.
.
.
.
.
.
.
treemap .
.
.
.
.
arraylist .
.
.
.
.
.
.
.
.
.
hashtable .
.
.
.
.
.
.
.
.
.
bitset .
.
.
.
.
.
.
.
.
.
log4j .
.
.
.
.
.
.
.
.
.
weblech .
.
.
.
.
.
.
.
.
.
jigsaw .
.
.
.
.
.
.
.
.
.
table race detection effectiveness prog.
potential races real races rta rtsc simrt rta rtsc simrt lang hashmap treemap arraylist hashtable bitset log4j weblech jigsaw .
.
rq2 and rq3 test case prioritization table summarizes the apfd values computed for the test suites and test case orders utilized in our study across all nine objects for both potential and real races with simrt spandrandom sp applied to selected test cases and with simrt ap abc apand random apapplied to the entire test suites.
to compare the effectiveness of different techniques we display results in terms of improvement in race detection rate calculated as apfd t1 apfd t2 apfd t2 .
this indicates the percentage improvement in apfd achieved by technique t1over technique t2.
for example for potential race detection on object lang the improvement in apfd achieved by simrt spoverrandom sp was96 .
.
rq2 prioritization results on selected test cases.
on the six small objects s imrtspoutperformed r andom sp in terms of apfd.
the improvement ranged from .
to .
for potential races and from .
to .
for real races and the average improvement across the five objects was .
for potential races and .
for real races.
on the three large objects simrtspoutperformed r andom spin terms of rate of race detection with improvements of .
.
and .
for potential races and .
.
and .
for real races.
on weblech random spperformed almost as effectively as simrtspbecause in that case isv p s were concentrated in several methods making it easier to achieve high coverage per selected test case and difficult to achieve additional coverage.
rq3 prioritization results on entire test suites.
on the six small objects when compared to abc ap simrtap improved the potential race detection rate by .
to .
with an average improvement of .
.
when compared to r andom ap simrtapimproved the potential race detection rate by between .
and .
with an average of .
.
where detection of actual races is concerned when compared to abc ap simrtap improved the detection rate by .
to .
with an average of .
.
when compared to r andom ap simrtapimproved the detection rate by .
to .
with an average of .
.
on the three large objects when compared to abc ap simrtap improved the potential race detection rate by .
.
and .
respectively.
when compared to r andom ap simrtap improved the potential race detection rate by .
.
and61.
respectively.
where detection of real races is concerned when compared to abc ap simrtapimproved the race detection rate by .
.
and .
respectively.
when compared to r andom ap simrtapimproved the race detection rate by .
.
and .
respectively.
.
summary and discussion summary of results.
simrt s rts component was substantially more efficient in terms of testing time than the retest all and traditional rts techniques.
meanwhile s imrt detected the same sets of real races as the baseline techniques.
although a few potential races were missed the number was small.
simrt s tcp component employed on selected test cases was substantially more effective in terms of apfd than the random test case ordering.
when employed on entire test suites the tcp component was substantially more effective in terms of apfd than both additional block coverage and random techniques.
meanwhile in this case s imrt was able to detect potential races that were not detectable when operating on a subset of the test cases.
if these results generalize to other real objects and rts and tcp techniques then if engineers wish to target race detection simrt is the best technique to utilize.
we now explore additional observations relevant to our study.
multiple runs.
in our study we executed each object once under the selected test cases for each technique to assess race detection effectiveness a practical approach in resource limited testing environments.
although empirical studies have shown that the fluctuation in race detection among multiple runs does not exceed .
we wished to determine whether multiple test runs could impact the effectiveness of the techniques studied.
to do this for each rts technique we ran each modified object with the potential race detector and verifier ten times.
the results indicated no differences in real race detection across the ten runs and differences in potential race detection were revealed in only two cases.
specifically on hashmap simrt detected one extra race in two of the ten test suite runs and missed one race in one test suite run.
rta and rtsc did not display any differences.
on jigsaw rta detected one extra race in two of the ten runs and missed one race in one run.
rtsc detected one extra race in three of the ten runs and s imrt detected two extra races in three of the ten runs missing one race in one run.
these results imply that conducting one run for each test case is likely to be a reasonable level of effort in resource limited testing environments.
effects of recording thread coverage.
simrt selects test cases that potentially cover impacted shared variable pairs in the modified object with different threads.
as such s imrt records thread ids for test history construction.
to determine whether this is useful we further investigated whether savings could be attained by considering thread coverage.
we considered percentages of test cases selected without using thread coverage labeling this ap 56proach s imrtn.
simrtnselects test cases that potentially cover impacted shared variable pairs in the modified object regardless of the number of threads involved in covering each pair.
for all nine objects s imrt yielded savings over s imrtn these ranged from .
to .
with an average of .
for the six smaller objects and from .
to .
with an average of .
for the three larger objects.
therefore the approach substantially improved the efficiency of regression test selection.
numbers of selected test cases.
the numbers of test cases selected by various techniques is another metric for measuring the efficiency of regression test selection providing an implementationindependent view of efficiency.
for the nine objects rtsc selected smaller test suites than rta in many cases with overall selection percentages ranging from .
to .
on four of the nine objects however rtsc selected more than of the test cases and in two cases it selected of the test cases.
s imrt on the other hand pruned away larger portions of the test suites with selection percentages ranging from .
to .
.
in fact for seven objects s imrt selected fewer than of the test cases.
exposing other faults.
simrt specifically targets races and therefore may not be effective at detecting other classes of faults that rta or rtsc can reveal.
as such it is worth investigating the performance of rtsc when combined with s imrt.
we thus compared the testing time required by rtsc with instrumentation for race detection to that required by the use of both s imrt and rtsc without instrumentation denoted by rtsc n .
both rtsc and rtsc ndetect races and other output based regression faults.
this comparison showed that the savings of rtsc nover rtsc ranged from .
and .
average .
across the six smaller objects.
on the larger objects the savings were .
.
and .
respectively.
this suggests that race detection and traditional fault detection should be considered separately.
results such as these should be qualified.
if s imrt does not substantially reduce the number of selected test cases over rtsc rtsc nmay not achieve savings.
further if engineers wish to detect both data races and other regression faults and s imrt substantially reduces the number of test cases selected over traditional rts techniques the best approach to use is run test cases selected by traditional rts techniques on uninstrumented objects and run test cases selected by s imrt on instrumented objects.
race detection overhead varies across different types of applications.
for example i o intensive applications tend to have small race detection overhead and hence would benefit less from s imrt.
further discussion.
we have used s imrt to target data races but it can be adapted to detect other types of concurrency faults such as atomicity violations and deadlocks by adjusting the contents of coverage targets.
for example to detect atomicity violations instead of identifying potential impacted shared variable pairs as coverage targets s imrt can identify potential unserializable interleavings as coverage targets.
as table shows for some objects there were a few uncovered impacted shared variables remaining in the modified versions after running the existing test cases.
these variables may also cause data races.
covering the impacted shared variables pairs associated with these variables requires additional test cases or possibly thread interleavings.
to address this we intend to further explore extending simrt using test suite augmentation techniques .
.
related work there has been a great deal of work on analyzing detecting and testing for data races however existing techniques do not consider software evolution.there has been some work on selecting and prioritizing schedules for testing multithreaded programs such that faults can be exposed faster .
for example chess prioritizes the exploration of program state spaces to detect potentially erroneous interleavings.
again these techniques do not consider code changes.
there have been several techniques presented for systematically exploring schedules in multi threaded programs across versions .
gligoric et al.
reuse results from exploration of one program version to speed up exploration of the next program version.
jagannath et al.
use information about program changes in software evolution to prioritize the exploration of schedules.
these techniques however target exploration of schedules within individual test cases and do not address the challenges of regression testing involving large sets of test cases.
that said we believe these techniques can also be utilized by s imrt.
for example once test inputs have been selected or prioritized by s imrt we can further apply these techniques to select or prioritize thread schedules for each of the test cases.
recent work by deng et al.
studies how existing concurrency fault detection tools work for a set of test inputs.
they propose a technique that first measures coverage of a program and then selects a subset of test inputs to test for data races and atomicity violations on that program.
this technique focuses however on single version programs and does not consider code changes.
in contrast we reuse coverage information on the old programs and select test inputs to test the new programs.
there has been a great deal of research on improving regression testing through regression test selection and test case prioritization e.g.
yoo and harman provide a recent survey.
here we restrict our attention to techniques that share similarities with ours.
some rts techniques target specific fault classes .
our own previous work selects test cases associated with system changes but only those that are relevant to a set of internal oracles that are known to be important for the system under test.
staats et al.
propose a tcp technique that favors test orderings in which many variables impact the test oracle s result early in test execution.
however all the foregoing techniques focus on sequential programs and do not address concurrency faults.
.
conclusion we have presented an automated regression testing framework simrt for use in detecting races that are induced due to code changes.
s imrt employs both rts and tcp techniques.
we have conducted an empirical study applying s imrt to nine concurrent code objects.
we have empirically compared s imrt to traditional baseline techniques and our results suggest that s imrt s test selection component is more effective and efficient than other approaches in terms of race detection.
our results also show that the tcp technique employed by s imrt is more effective than a traditional tcp technique and a random ordering in terms of rate of race detection.
in the future we intend to perform more extensive empirical studies to evaluate s imrt and extend s imrt to detect other types of concurrency faults such as atomicity violations and deadlock.
finally we will investigate the use of other regression testing techniques such as test suite augmentation in conjunction with s imrt.
.