practical isolation of failure inducing changes for debugging regression faults kai yu1 mengxiang lin1 jin chen1 and xiangyu zhang1 1state key laboratory of software development environment beihang university china 2school of computer science and engineering beihang univer sity china 3school of mechanical engineering and automation beihang u niversity china 4school of software beihang university china yukai mxlin chenjin zhangxy nlsde.buaa.edu.cn abstract during software evolution new released versions still con tain many bugs.
one common scenario is that end users encounter regression faults and submit them to bug tracking systems.
different from in house regression testing ty pically only one test input is available which passes the old version and fails the modified new version.
to address the issue delta debugging has been proposed for failure inducin g changes identification between two versions.
despite promi sing results there are two practical factors that thwart the application of delta debugging a large number of tests and misleading false positives.
in this work we present a combi nation of coverage analysis and delta debugging that automatically isolates failure inducing changes.
evaluation s on twelve real regression faults in gnu software demonstrate both the speed gain and effectiveness improvements.
moreover a case study on libpng and tcpflow indicates that our technique is comparable to peer techniques in debugging regressions faults.
categories andsubject descriptors d. .
testing and debugging debugging aids testing tools tracing general terms algorithms experimentation reliability verification keywords regression fault delta debugging coverage analysis automated debugging field failure .
introduction during software evolution new released versions still con tain many bugs especially regression faults regressi on mengxiang lin is the corresponding author.for short .
for example regressions are created during in the apache software foundation bug tracking database .
many regressions are later found by end users which are also known as field failures and submitted to bug tracking systems.
a typical bug report provides the version number of the buggy program the failure revealing input and the unexpected results.
users sometimes directly point out that regressions are encountered such as testin g vanilla coreutils .
and coreutils .
on x86 linux show s that .
behaves properly but .
does not .
.
includ e doesn t work as .
.
does and so on.
debugging regressions found in today s deployed software is nontrivial.
first software is increasingly complex and regression faults manifest themselves in specific environmen ts and configurations.
second different from in house regression testing usually only one test input tis available which passes the old version pand fails the modified new version p .
moreover developers which are always hurried and overburdened are unwilling to find more failing cases.
to address the issue recently two techniques named as darwin and golden respectively are proposed which tries to explain the failure of tinp .
darwin first computes the path conditions fand f oftinpandp .
then the formula f f is solved aiming at finding an alternative input which follows the same path as tinpbut a different path than tinp .
comparing control flow behaviors of tand its alternative inputs could help to locate faults.
however due to the limitations of the constraint solver usually only under approximation path conditions could be obtained.
as a consequence a solution to f f may not satisfy the required properties and thus is an invalid input .
moreover if fand f are found to be logically equivalent then no inputs could be generated and darwin could not be employed.
golden requires developers to manually provide a postcondition and then computes the weakest precondition wp of each version.
then wps are compared to find unexplained formulae which are later mapped to source code as bug reports.
since both darwin and golden are built on top of bitblaze binary analysis framework they circumvent the limitation of library functions.
however as th e information of external libraries and environment are not separated massive computation are spent to process all thi s information.
specifically frequent usage of libraries dur ing the execution and the ability of constraints solver threats to scalability and efficiency to those approaches.permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
ase september essen germany copyright acm ... .
one way is to focus on the effects of changes rather than the whole program.
of particular interest for our work is delta debugging which systematically search ing for failure inducing changes by patching a subset of change s and observing execution results.
delta debugging was intro duced first as ddmin for simplifying failure inducing changes.
later ddmin was extended to dd .
dd tries to isolate the minimal difference between the two versions.
since dd works on two sets at a time while ddmin performs simplification in one set dd is more efficient than ddmin in general .
we use the isolation delta debugging algorithm dd in this work.
in our previous work we evaluated dd in practical settings using real regressions taken from mid sized open source systems .
two thirds of isolated changes of dd in the systems analyzed provide direct or indirect clues in locating regressions.
despite promising resu lts there are two practical factors that thwart the application of dd.
first dd usually requires hundreds or even thousands of tests1 including compilation and execution to identify faulty elements .
however building large application s takes minutes to hours which may worsen the efficiency of dd.
for example a full build of firefox costs about two hours .
second as there may be changes which could also lead to the same behavior as that of the failure but are not root causes dd sometimes return alternate causes or known as false positives in the context of bug finding.
with respect to developers after a comparatively long wait they easily wear out their patience if they still have to review a long list of suspected changes with only several being failure relevant.
therefore developers are often frustr ated and prefer backing to manual debugging.
our goal is to develop a practical technique for debugging regressions.
a practical technique is available reli able and efficient in realistic settings.
in this work we introduce a practical and lightweight technique to identify fail ureinducing changes.
first statement coverage is collected a nd analyzed to identify unexecuted changes.
the resulting executed changes constitute a dubious set which is more relevant to the regression and used as the initial searching area .
the benefits are twofold a smaller searching area often requires fewer tests which improves the efficiency of faulty changes identification a more relevant area could lead to more precise results which are useful in debugging.
however since dd requires the initial set to be a failing set it is inappropriate to apply dd to find failure inducing changes in the dubious set directly.
to address the issue we propose an algorithm named augmented delta debugging add for searching failure inducing elements in the refined set.
in contrast to dd which isolates a minimal difference between the two versions our approach minimizes the set of suspicious changes.
contributions of this paper are as follows we introduce an approach which combines coverage analysis and delta debugging for failure inducing changes identification.
conceptually it improves upon dd by introducing the concept of dubious changes i.e.
changes tha t are actually covered by a test case devising a variant of delta debugging named add which performs minimization 1in the context of delta debugging a test consists of constructing a patched program and determining whether the failure occurs.
specifically delta debugging requires man y tests to search for failure causes running the same test cas e.inthe dubious area .
as demonstrated in evaluation add both reduces the number of tests yet is able to return less false positives.
we carried out experiments on twelve real regressions in gnu software to investigate the feasibility and performanc e of our approach.
our approach is usually times faster yet more effective than dd.
moreover a case study on libpng and tcpflow demonstrates that our technique is comparable to peer techniques in debugging regressions.
this work aims at helping developers to easily create an effective lightweight tool for locating regression bugs.
ou r prototype a detailed guide and subjects used are publicly available online the rest of this paper is organized as follows.
section describes our approach and section presents experimental study.
section discusses issues of our method and section concludes.
.
approach as described in section in the scenario of debugging regressions the starting point is an old working program p a modified broken program p and a test case twhich passes inpand fails inp .
given this information our approach comprises three steps execute programs and collect traces section .
analyze traces and obtain executed changes section .
and employ add to isolate failure inducing changes section .
.
.
execute programs lets si ands s j represent the statements in pandp respectively.
the set of changes from ptop termedc si s j si s s j s describes a series of replacements of statement siinpbys jinp .
particularly an addition operation of statement s jis a replacement s j while a delete operation of siis a replacement si here stands for the corresponding point.
in the first step both p andp are executed with the same test input tand traces t p s t p s are collected.t p andt p contain the set of code executed by tinpandp respectively.
.
analyzetraces the size of setcis often too large to be effective for searching failure inducing changes by dd requiring in practice hundreds or thousands of test executions as shown in section .
our idea is thus to eliminate those changes that arenotlikely to induce the regression from cand provide a more relevant set to perform isolation.
according to the pie model a change causes the difference of program behaviors if and only if the change executes infects the state and the infection propagates to th e output.
therefore an unexecuted change could not induce the failure and should be removed from consideration.
let u si s j si s j c si e atio slash t p s j e atio slash t p represent the set of unexecuted changes i.e.
whose statements are no t executed in neither pnorp .
after excluding such changes the difference set c u is regarded as a dubious setd which contains failure inducing changes.21figure applying dd to find the failure inducing changes c4 and c5.
test results are pass check fail or unresolved ?
.
.
isolatechanges in this stage a novel searching algorithm add is developed to minimize failure inducing changes in the dubious change setd.
we first illustrate both dd and add on an example and then give the algorithm description of add.
.
.
illustrativeexample figure illustrates dd on a simple example.
the failing setfconsists of eight changes initially.
in the context of debugging regressions a failing set fmeans patching changes infto the original program presults in the regression failure denoted as fail in figure .
initially fis the set of changes between pandp i.e.
the setcdefined above.
whether a change is patched to por not is illustrated by the black or white box respectively.
in this example the failure occurs only if the two changes c4 and c5 are patched with change c3.
both c4 and c5 are regression causes but a patch includes them will lead to an unresolved result e.g.
a compilation error in the absence of c3.
any patch that includes only c4 or c5 results in an unresolved result denoted as unresolved ?
any patch that includes c6 but not c3 also leads to an unresolved outcome otherwise a patched program passes the test denoted as pass check .
as illustrated later in section .
.
dependences of chang es in real scenarios are usually more complicated than this example.
the columns of c3 c4 c5 and c6 are highlighted.
in figure a dd starts isolating from fand identifies failure inducing changes c4 and c5 shown in the red part after sixteen steps by comparing the difference between the smallest failing patch obtained in step and largest pas sing patch obtained in step .
suppose in figure we obtain a dubious set d c4 c5 c6 c7 shown in the yellow part after coverage analysis.
further suppose dd is employed here to identify failureinducing changes in d. the steps and results are presented in figure b .
since c6 depends on c3 which is not included ind any patch that includes c6 leads to an unresolved result in the absence of c3.
after ten steps only a singleelement passing set is obtained.
and finally the dubious set figure applying add to find the failure inducing changes c4 and c5.
test results are pass check or unresolved ?
.
dis reduced to three elements.
this example shows that dd is inappropriate for isolating an unresolved set.
we propose add algorithm to address the issue and illustrate it in figure the dubious set dis divided into two halves first.
by patching all changes in fexcept the first half c4 c5 a passing patched program is obtained in step and now the dubious set dis c4 c5 .
by again splitting current dubious set into two halves add patches changes in each subset and their complement set in the rawfailing set f and it finishes in five steps since the largest granularity is reached.
finally changes in the ultimate suspicious set are regarded as the failure causes and both c4 and c5 are identified.
.
.
augmenteddelta debuggingalgorithm given a dubious set d it is infeasible to invoke dd directly.
to handle the situation dcan be treated as a failing set.
as illustrated in figure b without necessary changes e.g.
c3 patching the initial dubious set dleads to an unresolved result.
moreover removing any changes in dmay also result in unresolved test outcomes e.g.
the first six tests in figure b and the regression causes cannot be identified precisely.
the occurrence of unresolved results is due to dependences between changes .
dependences in real programs are complicated and considerable.
for instance a statement of ten has many dependences through control flow and data flow.
worse we could not know any dependency in advance without necessary computation.
this prevalent phenomenon greatly affects the performance of dd and presses for solution.
to alleviate the issue a natural idea is that the more changes are patched to p the greater the likelihood that a determined test result is produced.
specifically every tim e add splits current dubious setdinto subsets the subset and its complement in the rawfailing setfshould be tested e.g.
step and in figure .
since patching the raw failing setcresults in the failure then if we remove only a small changes of it the test result of the complement set may also be determinate.
moreover if the failure causes are excluded then a passing patched program is obtained and the causes are identified.
by comparison dd patches each subset s complement in current failing set which is not suitable for performing isolation in das illustrated.22algorithm add d f n the augmented delta debugging algorithm input a dubious setd e atio slash a failing setf n greaterorequalslant2 require d f test pass test f fail output a failure relevant subset of d if d then returnd di n i partition d n splitdinto nsets d d1 d2 .
.
.
dn di dj di dj di dj d n for i 1tondo if test f di failthen return add d di f max n else if test di pass then return add d di f max n else if test di failthen return add di f else if test f di pass then return add di f end end if only unresolved results are produced if n d then increase granularity return add d f min n d else return results returnd end algorithm shows our augmented delta debugging algorithm.
the inputs include a dubious set d a raw failing setfand the granularity n. the algorithm shares the same workflow of dd in principle it first splits current dubious set into nsubsets with all subsets pairwise disjoint then tries to narrow down the set according to testing results.
if only unresolved results are produced in this round then the granularity will be increased and add is invoked again.
if the granularity cannot be increased then the current dubious set is treated as the set of failure inducing changes and the algorithm terminates.
a testing function test is needed to patch current changes to pand determine test results.
add is invoked by add d c initially.
every time add splits current dubious set into subsets in line then each subset and its complement in the rawfailing set are tested.
according to test results the dubious set can be further narrowed down.
for example if patching the complement set still leads to the failure in line then th e corresponding subset is failure irrelevant while if patc hing the complement passes in line then the failure releva nt changes must be included in the subset.
if all the tests are unresolved then the granularity will be increased in line until no more subsets could be generated.
a failure relevan t set is returned in the end.
.
evaluations .
subjects the ultimate goal of our technique is to guide the developer to a narrowed area of code which is suspicious of being faulty.
we want to perform evaluation in a realisticsetting that mimics the scenario of encountering regressio n faults.
existing research bug benchmarks e.g.
ibugs contain few if any real regressions focusing on explicit bu gs instead .
subjects in sir are not used since debugging regression faults for sir programs are usually trivial.
thi s is because the difference between two sir program versions is usually small.
in this work we analyze twelve previously documented regressions in gnu software taking from a recently published benchmark .
the benchmark provides a regression revealing input together with both the workin g and the broken versions for each regression.
moreover all the regressions have been fixed.
three regression faults in are excluded due to the limitation of our current prototype e.g.
some regressions lie in yacc files and we could not collect coverage information of such files .
twelve regressions of ten applications are shown in table .
as we can see these programs are widely used mediumsized applications.
bash is an sh compatible shell bcis an arbitrary precision calculator diff shows differences between two files find searches for files in a directory hierarchy gawk is the gnu implementation of awk grep prints lines that match a pattern indent is a program for formatting c code lslists information about files make is a tool to organize a build process and taris an archiver tool.
both the adjacent working and broken version numbers of the programspandp along with the description of the regressions are given.
the sites and the internet addresses of bug reports are also listed.
.
setup some unrelated differences such as changes in documents betweenpandp were not taken into account.
our prototype consists of four components gnu diff utilities gcov add module and a test module.
gnu diff is used to compare the source code of pandp and the changes are regarded asc i.e.
the failing set f. the code coverage tool gcov is used to find out which lines of code are actually executed2and then the dubious set dis determined.
add is implemented in python.
the test module is used to build patched programs and determine test outcomes by files comparison or searching for regression indicators in o utput.
since patched programs may hang during the iteration the module uses a process controller to deal with such situation and outputs an unresolved result in such case.
the experiments are carried out on an ibm x3650 server with two intel xeon quadcore processors at .
ghz and 4gb physical memory running centos .
.
.
peer techniques we want to compare our approach with techniques or tools that address the same issue in the same scenario.
there are two recent papers about debugging evolving pro grams trying to explain the failure of tinp through semantic analysis simultaneously of both versions.
both methods use the bitblaze binary analysis framework as the underlying platform.
specifically concrete execution is car ried out by the temu component and symbolic computation is performed by the vine component.
we chose a relative s2for program indent the guilty changes are macro definitions.
since gcov cannot tell whether such lines are executed these changes are included in ddirectly.23table regression faults used in the study.
program loc ver p ver p regression description site report url bash 97k .
.
.
parsing error bug bash msg .html bc 10k .05a .
argument processing error show bug.cgi?id diff 20k .
.
.
adds additional newline cgi bin bugre port.cgi?bug find a 24k .
.
.
.
using l h produces wrong output bugs ?
find b 40k .
.
.
.
using mtime produces wrong output bugs ?
find c 40k .
.
.
.
using size produces error message bugs ?
gawk 37k .
.
.
.
use of strtonum causes abort cgi bin bugreport.cgi?bug grep 6k .
.
.
using include produces wrong output b ugs ?
indent 15k .
.
.
.
adds too many newlines bugs ?
ls 87k .
.
using x produces wrong output bug coreuti ls msg00000.html make 23k .
.
using r produces wrong output bugs ?
tar 21k .
.
.
.
wrong uid display bug tar msg00034.html mall subject diff for experimentation.
after the concrete execution temu generated a trace more than mb for each version consisted of more than .
million instructio ns executed by the program.
however after twenty minutes vine failed to convert the instruction traces into vine intermediate representation ir .
if ir traces could not be obtained the weakest precondition calculation could not b e calculated and later semantic analysis in could no t be performed to locate root causes of the bug.
it is worth noting that there are two releases of bitblaze and we used the open one since the internal one is not public available.
different releases may lead to different results.
if we want to employ spectra based fault localization usually multiple test inputs are required.
if only one failing and one passing executions are available chao et al .
propose a spectra based technique named bayesdebug to identify faulty predicates.
however it is not designed for debugging regressions and it does not explicitly consid er the semantics of the changes between two versions.
a predicate inpmay be renamed or even changed its condition inp and it is meaningless to compare their evaluation patterns in that case.
to our knowledge there is a study addresses the issue of lacking test cases by directed tes t generation using symbolic execution.
it creates new test in puts that are similar to the failing execution in order to aid fault localization.
a recent empirical study implemen ts one prototype on top of the klee engine and examines its effectiveness on twenty real bugs of grep make and tar.
it is reported that the original failing runs are too complex for klee to handle causing the system to time out and resulting the approach performs poorly.
moreover the implementations of all the techniques discussed above are not publicly available.
we are aware of two toolkits that could be obtained from internet.
one is rprism3 which performs regression cause analysis and was applied to large java applications.
the other is ddexpr4 which implements both dd and hdd hierarchical delta debugging and was applied to the subjects in table .
moreover the intermediate results cou ld also be downloaded publicly.
detailed description of the em pirical evaluation could be found in .
therefore we de3 to compare our method with the techniques evaluated in .
we should point out that git bisect is able to find failure inducing changes by binary search.
however as surveyed in the development history of most subjects in table is not available and thus git bisect could not always be employed.
.
efficiency we now compare our results with both dd and hdd as summarized in table .
the columns f and d show the number of changes in the failing and dubious set respective ly.
test un and iso list the number of tests required unresolved test results the number of changes isolated by dd hdd or add.
the columns fp and fn also provide the number of false positives and false negatives in the isolated changes.
to assess the improvements in efficiency we define two measures speedup test dd test add and un un dd un add un dd .
speedup is relative to the number of tests while un shows the percentage of decreased unresolved tests from dd to add.
first we observe that dis usually significantly smaller thanfand the areas to search for are reduced.
the size of d is less than to that of ffor two thirds programs.
for both find c and gawk there is a dramatic drop in the number of changes that is from to and from to .
second almost all the numbers of isolated changes by add are no more than that by dd or hdd.
for find b grep andls identified changes are greatly reduced.
third add achieves speedups of more than 10x vs. dd for two thirds programs.
for gawk add is 90x faster than dd.
last but not least the number of unresolved tests decreases significantly and the decrease percentage ranges from .
to even .
.
in our evaluation only executed changes are regarded as failure relevant.
in fact if developers ar e not sure whether a change is faulty or not they can keep it in the dubious set dand invoke add for isolation.
.
effectiveness since all the bugs have been fixed we could measure the usefulness of identified changes by comparing them with the patches used in real world.
as we can see from table too many false positives and false negatives occur in the result s24table results of failure inducing changes identificatio n. changes dd results hdd results add results improvement program f d test un iso fp fn test un iso fp fn test un iso fp fn speedup un bash .6x .
bc .4x .
diff .7x .
find a .4x .
find b .6x .
find c .3x .
gawk .3x .
grep .0x .
indent .2x .
ls .5x .
make .5x .
tar .8x .
of dd and hdd.
therefore we do not use the common measures such as precision recall f measure here to compar e the performance of add with dd and hdd since it is obvious add outperforms them on the benchmark.
instead we classify the results into three categories false negative s too many false positives and true positives and discuss them in detail.
for space reason here we just compare results of dd and add detailed results of hdd can be found in the website of ddexpr.
.
.
falsenegatives all the changes isolated are failure relevant except the change isolated by dd for program make shaded in black .
the real fix not shown here removed the check of f is target while the identified change shown in table sheds light oncheck lastslash .
the differences between the two files have the indicator or which means lines are added to or removed from the first file respectively.
the isolated change seems to be unrelated with the failure.
to validate our hypothesis that this change could induce the same behavior as that of the failure but is failure irrelevant w e carried out two experiments.
in one experiment only the change was applied to the old working program while in another experiment only this change was reverted in the new broken version.
both two programs failed the test which demonstrated that the change could lead to the same abnormal behavior but was not the root cause i.e.
this change is a false negative .
after excluding the change we reran dd.
this time dd isolated changes after executions and the failure inducing change was identified.
by comparison this faulty change is isolated by add at the first time among changes identified.
some articles have dis cussed why dd occasionally produces false negatives.
.
.
toomanyfalsepositives for the left eleven programs as we can see from table find b grep and ls shaded in gray have many changes isolated by dd.
close scrutiny reveals almost all identified changes of these three regressions are failure irrelev ant i.e.
false positives .
we first explain the results of program find b .
after manually examination we found two changes shown as c3 and c4 in table are failure causes.
according to c3 in the function get comp type the value of the first parameter is modified and returned.
therefore the variable sin the working program and the variabletable the isolated change of make by dd.
make .
implicit.c make .
implicit.c check lastslash lastslash !
strchr target check lastslash strchr target ifdef have dos paths ... endif timearg in the buggy program are reassigned.
however due to the change c4 the modified variable is used in the function get relative timestamp which leads to the regression.
because of dependency some changes that seem to be failure irrelevant are also isolated by dd.
for example changes that declare c1 and initialize c2 timearg are identified.
worse these changes also depend on other changes.
the regression occurs only if all these changes are applied together.
any subset of these changes could not induce the regression fault.
to produce a failing subset all these changes should be included together.
finally more than one hundred changes are identified by dd and it is not easy to pick out faulty ones among them.
in contrast by restricting the search space based on coverage analysis add performs minimization in a smaller and more relevant set containing only twenty changes and provides twelve suspicious changes including both c3 and c4 which allows developers to find the bug more easily and quickly.
for space reason here we just briefly interpret results of program grep and ls.
for grep false positives arise due to renaming a function.
the failure inducing function excluded filename is renamed as excluded file name .
as a consequence changes that define or use the function must be included in a failing subset.
for ls the failure inducing function print horizontal used one renamed variables changed from cmd files tocmd files which was widely used in the program.
therefore to fail the test of dd a patch should contain the renamed change and all the changes that use the renamed variable.
this results in a set filled with false positives.25table error causes for find b .
findutils .
.
find parser.c findutils .
.
find parser.c change c1 char s const char timearg change c2 if argv null argv null if !collect arg argv arg ptr timearg change c3 s argv if get comp type s comp if get comp type timearg comp change c4 if !get relative timestamp argv tval origin daysecs errmsg if !get relative timestamp timearg tval origin daysecs errmsg according to above analysis in the presence of code refactorings that have dependency of faulty code it is hard to isolate failure inducing changes precisely for dd.
by usin g coverage analysis add could search in a more relevant area and thus avoid many failure irrelevant changes.
.
.
truepositives for the left eight regressions the changes isolated by dd or add both provide valuable direct or indirect clues i.e.
true positives in debugging regressions.
we now illustrat e when the changes isolated by dd could be regarded as direct clues.
considering the changes isolated by dd for bc shown in table the added change prevents bcfrom properly reading long format options.
the reason is although a newly default statement was added the corresponding statement that processes long options was not included together and thus resulted in the regression.
the fix is to add a case statement before the default statement is reached.
table isolated changes of bc.
bc .
bc main.c bc .
bc main.c default usage argv exit as an example of indirect clues consider the changes isolated by dd shown in table .
although the failureinducing change is identified the change was introduced to fix another bug and should not be reverted5.
instead the developer repaired the bug by introducing a new condition to catch and correct the affected variable.
5for detailed information see t ?id 58d0483b621792959a485876aee05d799b6470detable isolated changes of diff.
diffutils .
.
src io.c diffutils .
src io.c for p0 !
beg0 p0 p1 if p0 !
p1 while p0 !
beg0 if p0 !
p1 we should mention that even if isolated changes provides direct clues most of them are not easy to understand at a first glance.
for example both dd and add precisely found out the failure inducing change for bc shown in table .
however it took us some minutes to figure out that the code modification changed the control flow and thus caused the regression.
in fact understanding root causes typical ly requires the specific context in which regressions manifest themselves.
just simply examining failure inducing chang es in isolation is always not enough.
fault understanding is still an open issue and has attracted researchers in recent years .
.
casestudy libpngand tcpflow as both darwin and golden could not be applied to our subjects in this section we describe our experience with their subjects for further analysis.
table summarizes the characters of each subject program and results of each technique.
specifically the number of tests required if exists the time usage requirements the size of results and bug reports for each technique are listed.
the results of dd and add are isolated changes while those of darwin and golden are alternative inputs and unexplained constraints respec tively.
following the convention of previous studies results of darwin and golden are obtained from their respective papers.
moreover to our knowledge prototypes of both techniques are not publicly available.
thus we do not know the results of applying golden to debug tcpflow.
libpng .
first we describe our experience with libpng a library for manipulating png images.
in previous studies researchers used an old version .
.
a s the broken program p and a later fixed version .
.
as the working program p. we applying both dd and our technique to identify the failure inducing changes fro m ptop .
for dd after test executions in about minutes three changes are identified and shown in table .
the second change results in the imaginary regression.
specifically the length check in the second condition length png uint 32 png ptr num palette will be missed if the first condition !
png ptr mode png have plte is true.
close scrutiny reveals that else if isifin the working version of libpng meaning the length should always be checked.
for our technique add identifies the single failure induci ng change after executions in less than minutes.
both dd and add just provide guilty changes as debugging clues while the bug reports produced by darwin and golden are more precise.
specifically darwin first produces nine inputs with only one is valid.
the branch instruction contributed to the bug report by the valid input cor 26table performance comparison on libpng and tcpflow .
changes darwin golden dd add time resultreport time result report tests time resultrep ort tests time result report program loc f d mm ss input loc mm ss const loc mm ss change loc mm ss change loc libpng .2k1751 tcpflow .9k table isolated changes of libpng .
libpng .
.
pngrutil.c libpng .
.
pngrutil.c if png ptr color type png color type gray if png ptr color type png color type palette png byte buf if length !
if !
png ptr mode png have plte should be an error but we can cope with it png warning png ptr missing plte before trns else if length png uint 32 png ptr num palette if length png warning png ptr zero length trns chunk png crc finish png ptr length return responds to the branch length png uint 32 png ptr num palette thereby pointing directly to the cause of failure.
golden takes nearly two hours due to more than of weakest preconditions to be compared.
finally totally unexplained constraints are identified and careful examina tion reveals that one unexplained constraint leads directl y to the buggy line while the other ones do not help to identify the root cause of the specific bug.
tcpflow .
in our second case study we study tcpflow a tool which captures and displays data sent through tcp connections.
a regression occurs after patching 10 extraopts.diff totcpflow .
.ds1 .
the bug leads to an off by one error for the patched version in handling of isn initial sequence number .
table is a simplified code fragment for illustration.
the regression appears because the way in which empty packets are handled is changed by the patch.
in the unpatched version of the program empty packets are simply ignored i.e.
the variable state will not be created at all .
however in the patched version empty packets are not ignored i.e.
the variable state will still be created for the tcp connection .
given a tcp connection state has one critical member field named ins which is used to store isn that the program has seen for this connection.
when state is created insis assigned with the sequence number of the current packet being handled.
therefore the values of state ins are different in the two program versions.
note that the insfield is later used to calculate the offset in the output file when the data is written out.
an incorrect value of state ins in patched version will affect the computation of offset which leads to the offby one error.
the fix in real world is to insert a statement state ins after the variable state is created.table schematic changes of tcpflow .
tcpflow unpatched src tcpip.c tcpflow patched src tcpip.c handle tcp packet t packet if this packet has no data if state find flow state current flow null state create flow state flow seq return if state find flow state current flow null state create flow state flow seq offset seq state ins write data from offset there are totally changes in the patch file 10 extraopts.diff and only changes executed in the two versions.
both dd and add isolates changes in less than one minute.
specifically dd identifies the change that corresponds to th e removed part in table while the change located by add pointed to the added fragment.
the code isolated by add may be more helpful since that is just where the fix is made.
although tcpflow is not a large application and 10 extraopts.diff is a small patch its path condition size is very large partly due to frequent usage of libraries during the e xecution.
the authors of darwin report that there are about formulae to solve and the estimated time to solve each one comes to minutes.
by leverage several optimization techniques e.g.
check satisfiability in a time bounded ma nner the total debugging time could be reduced to about half an hour and the final result contains only statements including the line containing the error cause.
although comparisons above indicate that our technique seems to outperform darwin and golden in efficiency without losing quality they should not be carelessly interpret ed as showing our technique is always a better substitute for darwin and golden.
they have their own unique advantages.
first both darwin and golden could leverage reference programs also known as golden implementations to aid debugging the buggy program.
even if all versions of a program expose a given error these methods can still be employed if a correct program which implements the same specification could be found.
second the side effects of both techniques are more informative in debugging.
the alternative inputs generated by darwin could be used to discover new errors while the unexplained constraints obtaine d by golden is a logical explanation of why the error appears and makes the bug report more accessible to the programmer.
third as pointed out in previous studies applyin g delta debugging usually requires manual operations such a s27constructing the test function which sometimes could be as costly as manual debugging.
.
discussions .
threats to validity like any empirical study there are a number of threats to the validity of this experiment.
the first one lies in the benchmark selection.
since only twelve regressions fro m small or medium sized open source applications are used absolute performance measures e.g.
our approach is usually times faster yet more effective than dd cannot be generalized to arbitrary programs.
specifically biases th at could potentially affect the result of the experiment may exist depending on the nature of regression faults.
on the other hand because subjects are collected from a wide range of programs the initial relative performance comparison i s credible and promising.
to alleviate the issue we further compared our results on libpng and tcpflow.
although conducting more experiments on more subjects of larger sizes in different programming languages are required we believe that searching in the dubious set is more effective than in the raw differences since the refined set would be more relevant for the regression.
another potential threat is whether the measure used to gauge improvement over existing techniques is reasonable.
as we analyzed in section and section .
both massive executions and misleading false positives thwart the a pplication of dd in real world development.
therefore the decrease in the number of executions and failure irrelevan t changes indicate efforts reduction in debugging.
in terms of the time consumption according to our experience the number of unresolved tests mainly determines the total execution time.
moreover although our approach requires first running the program with code coverage instrumentation enabled usually the runtime overhead typically seve ral seconds could be neglected comparing with the total time consumed typically tens of minutes .
for example the time consumed for find b during instrumentation running dd and add is about seconds minutes and minutes respectively.
timing results of other subjects could be fou nd in our project website.
our technique mainly focuses on failure inducing changes to provide debugging aids.
although the actual bug may lie inpand is just manifested by the changes introduced by p such changes provide a good starting point for pinpointing the root cause.
for example developers could track the control or data flow around failure inducing changes manually or automatically.
in short narrowing down the searching area of code which is suspicious of being faulty could reduce efforts in regression debugging.
we would like to point out that both darwin and golden are better choices in debugging unmasking regressions which already existed in p but are exposed in p .
therefore we regard these techniques and ours are complementary to each other.
as a final note the results of hdd are obtained from .
hdd was considered as a useful way to improve the effectiveness of dd.
however in previous experiments hdd did not bring definite improvements in neither efficiency nor accuracy.
this is partly because the patch structure used in may not reflect the hierarchy of underlyingprogram changes accurately.
hdd may be more effective if it operates over a syntactical hierarchical representat ion of programming constructs such as abstract syntax tree or control flow graph.
as admitted in providing such infrastructure is non trivial and developers may lost their i nterest in applying the technique.
.
related work delta debugging .
delta debugging has long been considered useful for debugging regressions whi ch searches for failure inducing changes by rolling back different subsets of changes and observing execution results.
a few optimizations such as grouping changes according to the patching date or common usage of identifiers were proposed and incremental build was also suggested in zeller s book .
two successors of dd are proposed under different scenarios.
hdd hierarchical delta debugging exploits hierarchical characteristics of program inp uts to simplify failure inducing inputs while idd iterative d elta debugging assumes full history of all revisions are ava ilable and searches for a correct version iteratively.
all the se strategies mentioned above can be considered complementary to our work.
we would like to point out that ddmin could also be adapted to the dubious set d. ddmin does not test the individual subsets dibut add does.
although add increases the number of tests it also increases the possibilities of p roducing a passing or failing test outcome.
that is partly because sometimes regression faults are induced by individua l changes as demonstrated in our evaluations.
spectra based fault localization .
much effort has been devoted to spectra based fault localization techniqu es which demonstrate effectiveness especia lly when multiple passing and failing test cases are available or cou ld be generated .
a recent evaluation discusses open challenges of these techniques through user studies.
moreover in practice we notice that often only one failure reve aling test case is available.
it is more commonly encountered because developers often receive regression bug reports with only one test case.
moreover according to our observations and experiences developers are usually unwilling to find more test cases once one is encountered.
as discussed in section .
artzi et al.
investigate how to generate a test suite to aid fault localization.
however real softwar e programs often make use of external code which prevent these techniques that rely on symbolic execution from working.
moreover the execution status i.e.
pass or fail of each generated test case should be determined.
theoretically such test generation based methods require complet e oracle.
as an alternative bayesdebug is able to work on a few test inputs.
however it is not applicable to large evolving program as it relies on computing profiles on all predicates in each version and does not leverage information about changes between the old and new versions as our approach does.
debugging evolving programs .
recent work focuses on explaining the unexpected behavior of a bug that hasmanifested itself owing to program modifications.
darwin locates error causes by comparing execution traces of the failing input and a generated alternative input.
how 28ever darwin is most suited for explaining regressions that are exposed by a difference in control flow.
to overcome this issue golden combines slicing and symbolic execution to explain the unexpected behavior of the buggy program.
in contrast hoffman et al.
introduced a view based technique for identifying causes of regressions by compari ng large execution traces.
despite promising results those techniques are expensive to create and even often unavailable.
techniques that employ test generation undergo scalability is sues from exponential number of paths and complexity of the generated constraints while precise spectrum based meth ods rely on sophisticated dynamic analysis such as instrumenting .
developers may not be familiar with such techniques and are unlikely to use them.
worse more misleading false positives arise in applying above techniq ues.
for example false positives may be inevitable due to the limits of constraint solver or approximate analysis .
this work focuses on helping developers to easily create an effective lightweight tool for locating regression faults.
.
conclusion as software evolves bugs are inevitably introduced.
fixing regression faults reported by end users is urgent but time consuming.
we have presented a framework for failureinducing changes identification which combines coverage analysis and delta debugging.
our approach is highly efficient and is applicable to practical settings.
evaluation s on real regressions shows by searching in a small area both efficiency and effectiveness can be improved.
to facilitate further research in these and other direction s detailed information on our experiments is available at .