make test zesti a symbolic execution solution for improving regression testing paul dan marinescu and cristian cadar department of computing imperial college london london united kingdom fp.marinescu c.cadar g imperial.ac.uk abstract software testing is an expensive and time consuming process often involving the manual creation of comprehensive regression test suites.
however current testing methodologies do not take full advantage of these tests.
in this paper we present a technique for amplifying the effect of existing test suites using a lightweight symbolic execution mechanism which thoroughly checks all sensitive operations e.g.
pointer dereferences executed by the test suite for errors and explores additional paths around sensitive operations.
we implemented this technique in a prototype system called zesti zero effort symbolic test improvement and applied it to three open source code bases gnu coreutils libdwarf and readelf where it found previously unknown bugs many of which are out of reach of standard symbolic execution.
our technique works transparently to the tester requiring no additional human effort or changes to source code or tests.
keywords regression testing test improvement symbolic execution i. i ntroduction testing currently accounts for a large fraction of the software development life cycle and usually involves writing large numbers of manual tests that exercise various paths with the objective of maximising a certain coverage metric such as line or branch coverage.
this is a tedious process that requires significant effort and a good understanding of the tested system.
as a result we are witnessing a sustained research effort directed toward developing automatic techniques for generating high coverage test suites and detecting software errors with some of these techniques making their way into commercial and open source tools.
however these techniques do not take advantage of the effort that developers expend on creating and updating the manual regression suites which we believe could significantly enhance and speed up the testing process.
our key observation is that well written manual test suites exercise interesting program features but often using a limited number of paths and input values.
in this paper we propose a zero effort1symbolic test improvement technique that amplifies the effect of a regression test suite by checking the program paths explored by the regression suite against all 1byeffort we refer to human effort not execution overhead.possible input values and also by exploring additional paths that slightly diverge from the original execution paths in order to thoroughly check potentially dangerous operations executed by the program.
the paper makes the following main contributions we show that the effectiveness of standard regression tests can be automatically improved using symbolic execution based techniques finding bugs that are often out of reach of regression testing or standard symbolic execution alone.
from a tester s perspective the improved regression suites are executed in exactly the same manner as their non symbolic counterparts without the need to configure a symbolic execution engine or decide what symbolic inputs to provide to the program.
our technique works by reasoning about all possible input values on the paths executed by the regression suite and by thoroughly exploring additional paths around sensitive instructions such as dangerous memory accesses.
we provide a theoretical and empirical analysis of the sensitivity of our approach to the quality of the test suite and discuss how the probability of finding a bug varies with the number of test cases being considered.
we demonstrate that our approach works well in practice by implementing it in zesti zero effort symbolic test improvement a prototype based on the klee symbolic execution engine .
we applied zesti to several popular open source applications including the gnu coreutils suite the libdwarf library and the readelf utility and found two previously unknown bugs in coreutils despite these applications having been comprehensively checked before via symbolic execution forty in libdwarf and ten in readelf in a manner completely transparent to developers.
furthermore the inputs generated by zesti to reproduce the bugs discovered are almost well formed i.e.
they differ only slightly from the inputs included in the regression suite making it easier for developers to analyse them.
the rest of the paper is structured as follows.
we start by giving a general overview of our technique in xii and discuss the relevant background and related work in xiii.
we then present our technique in detail in xiv describethe main aspects of our implementation in xv and present our experience using zesti inxvi.
finally we discuss the advantages zesti offers as well as its limitations in xvii and conclude inxviii.
ii.
o verview the main insight used by zesti is that regression test suites exercise interesting program paths.
such test suites are often created by the programmers who wrote the application and benefit from deep knowledge of the program logic or by dedicated qa teams which systematically evaluate the main program features and possible corner cases.
furthermore regression tests often cover program paths that previously triggered bugs which are more likely to contain further errors .
for instance while the visible symptoms of the offending bugs are fixed it can happen that the root cause of the bugs is not alternatively slightly different executions could still trigger the same bug.
a common way to measure the quality of a test suite is code coverage.
testing methodologies often require creating test suites that achieve a certain level of line or branch coverage and many projects contain relatively high coverage test suites for instance most applications that we tested in our experimental evaluation have manual test suites reaching over line coverage.
unfortunately despite the effort invested in creating these manual regression suites bugs still remain undetected in the code covered by the test inputs.
first of all note that line coverage can be misleading for quantifying the confidence in a system for two important reasons.
first executing an operation may or may not cause a violation depending on its arguments.
for example accessing the i thelement of a vector is safe when iis within vector bounds but causes an error otherwise.
line coverage however considers the operation tested as soon as it is executed once.
second code behaviour depends on the path used to reach it an instruction can operate correctly when reached along one path but cause a violation along a slightly different path.
these caveats also apply to other coverage metrics such as branch coverage.
in this paper we propose to augment regression suites by using symbolic execution to analyse instruction safety against all inputs that could exercise the instruction along the same paths xiv a and carefully choose and explore slightly divergent paths from those executed by the regression suite xiv b .
compared to standard regression suites our approach tests the program on all possible inputs on the paths exercised by the regression suite and on a large number of neighbouring paths without any additional developer effort.
compared to standard symbolic execution the approach takes advantage of the effort spent creating these regression suites to quickly guide symbolic execution along paths that exercise interesting program behaviours.iii.
b ackground and related work symbolic execution is a technique that has received much attention in recent years in the context of software testing due to its ability to automatically explore multiple program paths and reason about the program s behaviour along each of them.
tools such as klee sage jpf se bitblaze and pex are just some of the symbolic execution engines currently used successfully in academia and in industry.
intuitively symbolic execution se works by systematically exploring all possible program executions and dynamically checking the safety of dangerous operations.
se replaces regular program inputs with symbolic variables that initially represent any possible value.
whenever the program executes a conditional branch instruction that depends on symbolic data the possibility of following each branch is analysed and execution is forked for each feasible branch .
to enable this analysis symbolic execution maintains for each execution path a set of conditions which characterise the class of all inputs that drive program execution along that path.
at any time the path conditions can be solved to provide a concrete input that exercises that path natively making it easy to reproduce report and analyse an execution of interest.
se also analyses all potentially dangerous operations as they are executed verifying their safety for any input from the current input class.
for example a division is safe if and only if the denominator cannot be zero given the current path conditions.
unfortunately the number of execution paths in real programs often increases exponentially with the number of branches in the code which may lead symbolic execution to miss important program paths.
one solution is to employ sound program analysis techniques to reduce the complexity of the exploration e.g.
as in or .
an orthogonal solution is to limit or prioritise the symbolic program exploration using different heuristics.
for example directed symbolic execution methods use techniques such as static analysis to find instructions or paths of interest which are then used to guide the symbolic exploration.
concolic testing starts from the path executed by a concrete input and then explores different program paths by systematically flipping the truth value of the branch conditions collected on that path.
previous research has shown that the coverage and bug finding abilities of concolic testing can be improved by combining it with random testing or with well formed inputs and the effectiveness of fault localization can be increased by aiming to maximize the similarity with the path constraints of faulty executions .
combining concolic execution with manual test suites was first proposed in where it was augmented by assertion hoisting in order to increase the number of bug checks and then explored in in which it was comparedagainst a genetic algorithm test augmentation technique.
our approach extends previous work by proposing a technique that explores paths around potentially dangerous instructions executed by the regression suite by providing an analysis of the sensitivity of this approach to the quality of the test suite and by presenting a thorough evaluation on real and complete regression suites of several popular applications.
the idea of augmenting concrete executions with the ability to reason symbolically about potential violations was first proposed in which introduces a technique that keeps track of lower and upper bounds of integer variables and of the nul character in strings.
based on this information it can flag bugs such as buffer overflows and incorrect uses of libc string functions.
the technique can only reason about limited types of constraints and does not explore any additional paths.
research on improving regression testing generally falls under four main categories finding redundant tests ordering tests for finding defects earlier selectively running only relevant tests on new program versions and enhancing a system s test suite as the system evolves .
the first three topics are largely orthogonal and can be combined with our technique.
the state of the art for the latter combines control and data dependence chain analysis and symbolic execution to identify tests that are likely to exercise the effects of changes to a program.
making this approach tractable requires a reasonably small set of differences between program versions and a depth bounded analysis on dependence chains.
while our approach could be used for test augmentation we see zesti primarily as a bug finding technique that can increase the effectiveness of regression suites by combining them with symbolic execution following the manner in which dynamic execution tools such as valgrind are often integrated with existing test suites.
iv.
z ero effort symbolic testimprovement this section describes the two main techniques used by zesti improving regression suites with additional symbolic checks xiv a and exploring additional paths around sensitive operations xiv b .
a. thoroughly testing sensitive operations a standard regression test suite consists of multiple tests each being an input expected output pair.
the test harness iterates through the tests and runs for each of them the target program with the given input and collects its output.
zesti hooks into this process by interposing between the testing script and the tested program gaining complete control over the system s execution.
similarly to zesti replaces the program input with symbolic values and at the same time remembers the concrete input which is used to drive program execution whenever a branch is encountered.
while executing the1 i n t v vo id f i n t x f i f x x v g figure .
code snippet showcasing a bug missed by a test suite with code coverage e.g.
x x .
program path conditions are gathered and used to verify potentially buggy operations.
for example whenever the program accesses a symbolic memory location zesti checks that the operation is safe for all inputs that satisfy the current path condition.
consider the snippet of code in figure .
function f contains a bug it accesses an invalid memory location when passed a negative argument.
a test suite might call this function with different arguments and verify its behaviour attempting to maximise a certain metric e.g.
line coverage.
it can be easily noticed that choosing one value greater than and one smaller than or equal to exercises all instructions branches and paths without necessarily finding the bug.
on the other hand our approach finds the bug whenever the function argument is smaller than for such values symbolic execution gathers the path constraint x 99on line and then on line checks whether there are any values forxthan can overflow the buffer v. more exactly zesti checks whether the formula x x x is valid and immediately finds a counterexample in the form of a negative integer assignment to x. in order to be accepted by software developers we strongly believe that zesti needs to work transparently.
we envision zesti being used in a similar way in which memory debuggers such as valgrind or purify are employed today in conjunction with test suites to provide stronger guarantees.
for example many open source programs provide a simple way to integrate valgrind into their regression test frameworks with the user simply having to type make test valgrind to execute the regression suite under valgrind.
we hope zesti will be used in a similar way by simply typing a command like make test zesti as suggested in our paper title.
in other words running an existing regression test suite under zesti should happen without user intervention.
to accommodate all testing frameworks zesti treats both the tests and the testing script as black boxes.
it functions by renaming the original program and replacing it with a script that invokes the zesti interpreter passing as arguments the original program and any command line arguments.
2because zesti is an extension of the klee symbolic execution engine which operates on llvm bitcode users need to compile their code to llvm in order to use zesti .
however this is not a fundamental limitation of our approach which could be integrated within a symbolic execution framework that works directly on binaries.inputs maxdist the maximum distance to search s the set of sensitive instructions p the set of divergence points f the distance estimation function for d tomaxdist for sensitive instructions i2s if 9divergence point j2p at distance dfrom i symbolically execute program starting from j without restriction to a single path with depth bound f d figure .
algorithm used by zesti to explore additional paths.
zesti automatically detects several input classes namely command line arguments and files opened for reading and treats them as sources of symbolic data.
we found these two sources sufficient for our benchmarks however adding additional input sources is relatively straightforward.
the main downside of this approach is execution overhead.
in particular there are two main sources of overhead first the overhead of interpreting llvm code.
second the constraint solver overhead however note that unlike in regular symbolic execution the constraint solver is invoked inzesti only to check sensitive operations.
b. exploring additional paths around sensitive operations the version of zesti described thus far has the disadvantage of being highly dependent on the thoroughness of the regression test suite.
while a quality test suite is expected to test all program features it is likely that not all corner cases are taken into account.
our analysis of coreutils xvi a mature set of applications with a high quality test suite showed that only one out of the ten bugs previously found via symbolic execution could be detected by the version of zesti described so far.
as a result we extended zesti to explore paths that slightly diverge from those executed by the regression suite according to the likelihood they could trigger a bug.
to mitigate the path explosion problem zesti carefully chooses divergent paths via two mechanisms it only diverges close to sensitive instructions i.e instructions that might contain a bug and it chooses the divergence points in order of increasing distance from the sensitive instruction.
the key idea behind this approach is to exercise sensitive instructions on slightly different paths with the goal of triggering a bug if the respective instructions contain one.
choosing a close divergence point ensures that only a small effort is needed to reach the same instruction again.
zesti identifies sensitive instructions dynamically.
as it executes the concrete program path it keeps track of all instructions that might cause an error on alternative executions.
we consider two types of sensitive instructions memory accesses and divisions.
we treat all pointer dereferences as sensitive while for divisions we only consider those witha symbolic denominator as sensitive.
at the llvm level zesti treats as sensitive all memory accesses to symbolic addresses as well as those concrete or symbolic memory accesses preceded by a getelementptr instruction and all division and modulo operations with symbolic denominators.
while we currently track only sensitive memory accesses and divisions we could also extend the technique to other types of sensitive operations such as assertions.
to comprehensively exercise the sensitive instructions with different inputs zesti tries to follow alternative execution paths that reach these instructions.
to this purpose it identifies all points along the concrete path where execution can diverge i.e.
the branches depending on symbolic input.
zesti then prioritises the divergence points in increasing order of distance from sensitive instructions and uses them as starting points for symbolic execution.
figure outlines the strategy used by zesti .
line goes through distances from to a user specified maximum and line iterates through all sensitive instructions.
if any divergence point is found at the current distance from the current instruction it is used to start a depth bounded symbolic execution run with bound f d .
the function fshould be a function that closely overestimates the distance between the divergence point and the sensitive instruction on an alternative path.
a function which underestimates this distance will give an se depth bound too small to reach the sensitive instruction while a function that largely overestimates it would needlessly increase zesti s overhead.
however note that not all additional paths explored by zesti are guaranteed to reach the sensitive instruction.
we empirically found that a linear function works well and in our experiments we used f d d. as an optimisation line of the algorithm considers sensitive instructions in decreasing order of distance from the program start.
this favours the exploration of deeper states first on the premises that deeper states are more interesting because they contain the functionality exercised by the test suite as opposed to the shallow states that are often related to command line parsing or input validation and standard symbolic execution is less likely to be able to reach those states in reasonable time due to path explosion.
intuitively the metric used by zesti to measure the distance between two execution points needs to estimate the effort required by symbolic execution to reach one point from the other.
to this end zesti defines the distance between two instructions as the number of branches between them where inputs could allow execution to follow either side of the branch.
this metric captures the number of points where the program could have taken a different path and which zesti could explore and is inherently insensitive to large blocks of code that use only concrete data.
in practice the optimal maximum distance maxdist in figure for which to run zesti is hard to determine.
usingdepth code i n s t r t y p e i n t v vo id f i n t x f i f x d x v s g figure .
code snippet showcasing an execution generated by an input x annotated by zesti .
the depth column records the distance from the start of the execution and the instrtype column keeps track of divergence points d and sensitive instructions s .
depth code i n s t r t y p e i n t v vo id f i n t x f i f x f d1 i f x d2 r e t u r n x g v s g figure .
code snippet showcasing an execution generated by an input x annotated by zesti .
the depth andinstrtype columns have the same meaning as in figure .
a small value may miss bugs while using a large value may be too time consuming and leave no time to execute the rest of the tests within the allocated time budget.
our approach to solve this problem is to allocate a certain time budget to the entire testing process and use an iterative deepening approach conceptually all the tests are first executed without exploring any additional paths then up to distance etc.
until the time budget expires.
to illustrate zesti s exploration of additional paths consider the code in figure .
in the previous section we showed how zesti finds the bug starting from a test that calls function fwith an argument smaller than .
we now show how it can find the bug for any argument value.
for values smaller than the previous analysis applies and the bug is found without having to explore divergent paths.
therefore we only discuss arguments greater than or equal to .
figure shows the same code annotated by zesti when executed using such an argument.
while running the function zesti records all the sensitive instructions s and divergence points d being executed instrtype field and computes their distance from the start of the execution depth field .
after running the entire function zesti looks for instructions labelled as sensitive located at distance after a divergence point i.e.
the difference between their depth fields is and finds instruction v with corresponding divergence point if x .
these steps correspond to lines and of figure .
zesti then starts bounded symbolic execution from d line of figure .
the newpath discovered corresponds to an input that makes the code take the empty else branch at d i.e.
a value smaller than .
on this path xis no longer set to but is used directly to index v. when executing the sensitive instruction v zesti checks whether a violation can occur based on the current path condition and finds that a negative function argument causes a memory violation.
to further illustrate zesti s algorithm we consider the slightly more complicated code snippet in figure .
the code contains an additional ifstatement that creates a new divergence point d2.
assuming a test input between and the sensitive instruction is at distance from divergence point d2and at distance from d1.
therefore zesti first considers d2 and explores its then path which does not trigger the bug.
going further it finds d1which leads to the bug as in the previous example.
c. improving efficiency by discarding test cases an interesting question is how sensitive zesti is to the program test suite.
the time in which zesti finds a bug depends on three main factors the number of tests that are run the percentage of them that expose the bug and the minimum distance at which the bug is found.
as discussed above because the distance at which a certain test case exposes the bug is difficult to predict zesti first checks the concrete execution path and then uses an iterative deepening approach to check divergent paths.
under this strategy the only other parameter that zesti can vary is the number of test cases that are run.
in the rest of this section we provide a theoretical estimate of the probability of finding a bug if zesti runs only a randomly chosen fraction of the test suite.
creating a sub test suite out of the initial test suite by randomly picking tests is an instance of the urn model without replacement i.e.
the marbles tests are not replaced in the urn initial test suite once picked.
consider that the urn model has the following parameters n the total number of tests m the number of tests which expose the bug at the minimum distance and k the number of tests picked.
the probability distribution which characterises the number of successes i.e.
tests which find the bug at the minimum distance in the sequence of kpicks is called the hypergeometric distribution .
in terms of this model we are interested in the probability of having at least one success which is p failure the probability of having only failures p success p failure n m k n k where the fraction denominator represents the total number of possible test combinations and the numerator represents the number of combinations which contain zero successes.
figure plots the probability of finding a bug using a subset of a hypothetical initial test suite of test cases .
.
.
.
.
sub test suite sizem m m 30figure .
probability to find a bug using a randomly picked fraction of an initial test suite of test cases.
the three lines show the probability considering that and respectively of the initial tests find the bug.
for three fractions of tests exposing the bug and which are representative for the programs that we analysed with zesti seexvi .
as this graph shows it is possible to discard a large fraction of the test suite while still finding the bug with high probability.
for example for a test suite of size in order to find the bug with at least probability it is enough to run only when m when m and tests when m .
if the minimum distance at which the bug is found is relatively large discarding a large number of tests can have a big positive impact on zesti s performance without significantly lowering the probability of finding the bug.
in section vi c we show that our analysis holds in practice by examining the test suite characteristics of real programs.
v. i mplementation zesti is integrated in the klee symbolic execution engine a user can choose whether to run klee or zesti via command line switches.
when enabled zesti intercepts all calls that create symbolic data e.g.
read from a file and records the concrete value of the variables in a shadow data structure.
zesti also intercepts all calls made to the stpconstraint solver via a custom concretizing module inserted in klee s solver chain between the frontend and the query optimisers.
when enabled this module replaces all symbolic variables in a query with their concrete values and evaluates the resulting concrete expression obtaining a value that is then returned directly back to klee .
this implementation allows enabling and disabling symbolic execution by disabling and respectively enabling zesti s concretizing module.
the module is always disabled before executing a sensitive operation such as a memory access and re enabled afterwards.
this permits checking sensitive operations symbolically while executing the rest of the program concretely.
in order to explore paths around sensitive instructions zesti associates with each program state that is not on the concrete path a time to live ttl value which keeps trackof how long this state continues to be executed before it is suspended.
this mechanism allows executing states in any order and guarantees execution for the exact desired distance.
the ttl uses the same metric used to measure distances between program states i.e.
symbolic branch count.
it is initialised with the distance for which the state has to be executed and decremented whenever the state is forked as a result of a symbolic branch condition.
zesti also implements its own state prioritization algorithm based on a breadth first traversal of the state space consistent with the distance metric used.
the algorithm is implemented as a searcher a pluggable abstraction used by klee to encapsulate the prioritization logic.
this approach decouples the search algorithm from the symbolic execution functionality and allows updating or replacing the implementation with ease.
vi.
e xperimental evaluation this section covers the results obtained with zesti describing our benchmarks and methodology xvi a bugs found xvi b and quantifying the test improvements and overhead of using zesti xvi c .
a. benchmarks to evaluate zesti we used three different software suites gnu coreutils .
a suite of commonly used unix utilities such as ls cat andcp.coreutils consists of a total of individual programs and has a comprehensive regression test suite totalling individual tests obtaining overall .
line coverage.
we used the older .
version in order to facilitate the comparison against klee which was previously used to comprehensively check this version of coreutils .
the largest coreutils program ls has effective lines of code eloc but also uses part of a monolithic library shared by all the utilities making it hard to compute an accurate line count.
we therefore employed the same approach used by klee s authors of computing the number of llvm instructions after compiler optimisations are applied especially the dead code elimination pass .
this yields instructions for ls.
libdwarf a popular open source library for inspecting dwarf debug information in object files.
libdwarf has eloc as reported by gcov and llvm instructions as reported by klee .
its test suite consists of two parts manually created tests and a larger number of automatically generated tests obtained by exhaustively mixing common command line arguments and input files achieving in total .
line coverage.
3line count and coverage information was obtained using gcov .
.
andllvm .
.
numbers can vary between different versions.
readelf .
.
a component of gnu binutils for examining elf object files included in most linux distributions.
readelf has eloc and llvm instructions and comes with a small test suite of only seven tests obtaining line coverage.
one reason we included this benchmark was to see how zesti performs with a weaker regression suite.
the other was that both libdwarf andreadelf need large inputs executable files which would make a pure symbolic execution choke.
for example executing libdwarf using klee and a relatively small byte input file consumes all available memory on our test machine within a few tens of minutes.
to test these programs we imposed a per test time limit dependent on program complexity we chose minutes for thecoreutils programs and minutes for libdwarf andreadelf .
for libdwarf we used the manual tests and of the automatically generated ones.
we ran all libdwarf experiments on a 64bit fedora xeon e3 machine with 16gb of ram while the rest were performed on a 64bit ubuntu .
i5 machine with 8gb of ram.
b. bugs found zesti found a total of bugs out of which were previously unknown.
the new bugs were reported to the maintainers and most of them have already been fixed by the time of this writing.
table i shows a summary of the bugs found by zesti along with the distance from the concrete path and the depth at which they were found.
we compute the depth as the number of visited symbolic branches from the program start where both sides could be explored as this is a rough estimation of the effort required by standard symbolic execution to find the bug.
if the same bug is discovered by two or more test cases we report the minimum distance and for equal distances the minimum depth.
both the minimum distance and depth are influenced by program inputs it may be possible to reach the bugs by traversing fewer symbolic branches when using other inputs.
we describe below three representative errors found by zesti and then compare its bug finding ability against standard symbolic execution.
cutcase study the bug found in the cut utility is a memory access violation.
the test leading to its discovery uses the command line arguments c3 output d file.inp .
the cargument specifies two ranges from the 3rd to the 5th character and from the 6th character to the end of the line.
internally cut allocates a buffer that is later indexed by the range endpoints.
its size is computed as the maximum of the right endpoints across all ranges.
however in this case the ranges unbounded to the right are incorrectly not considered in the computation.
therefore the value is used to index a zero based vector of only elements.
however because the cut implementation uses a bitvector table i bugs found by zesti along with the distance from the concrete test path and the depth from the program start at which the bug was found .
new bugs are in bold .
bug no.
location distance min depth coreutils cut.c printf.c seq.c paste.c mkdir.c mknod.c mkfifo.c md5sum.c libdwarf dwarf form.c dwarf form.c dwarf form.c dwarf elfaccess.c dwarf elfaccess.c dwarf arange.c dwarf arange.c dwarf util.c dwarf util.c dwarf elfaccess.c dwarf print lines.c dwarf global.c dwarf global.c dwarf global.c dwarf leb.c dwarf leb.c dwarf leb.c dwarf leb.c esb.c print die.c dwarf util.c dwarf util.c dwarf util.c dwarf query.c dwarf abbrev.c dwarf frame2.c dwarf frame2.c dwarf line.c readelf readelf.c readelf.c readelf.c readelf.c dwarf.c dwarf.c dwarf.c elfcomm.c elfcomm.c elfcomm.c allocations are inherently done in chunks of elements and the bug is not triggered by the test input and thus a tool such as valgrind could not find it .
however zesti detects the problem by deriving a new input which triggers the bug namely c3 output d file.inp .
libdwarf case study one of the bugs found in libdwarf is a division by zero caused by improper handling of debug 4bugs were found at different locations in dwarf line.c .
for brevity we omit the details.table ii aone byte corruption at offset 0x1073 in a l i b d w a r f test file which causes a division by zero .
offset original buggy 7f 4c 7f 4c .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
information data.
before reading the debug aranges section libdwarf computes the size of each entry by looking at two fields in the executable file the address size and the segment size.
the entry size is computed using the formula entry size address size segment size.
a check is then made to ensure that the section size is a multiple of the entry size via a modulo operation which causes an exception when the entry size equals zero.
table ii shows the input generated by zesti by changing one byte in the original test file.
the byte corresponds to the address size which is changed from to the segment size is already .
the new file causes the division by zero when passed to libdwarf .
one advantage of zesti over standard symbolic execution is that it can generate almost well formed inputs.
while symbolic execution can only use the current path constrains to generate an input leaving all unconstrained data to a default value zesti creates an input that matches as close as possible the test data while still reproducing the bug.
the feedback to our bug reports indicates that this approach creates inputs that are easier to understand by programmers.
printf case study zesti found a previously unknown bug in the printf program a utility that prints formatted text in a similar fashion to the printf libc function.
the bug was found at distance i.e.
zesti had to flip the outcome of one branch in order to trigger it.
the bug resides in a program feature that interprets a character as its integer ascii code if preceded by a single or double quote.
the implementation incorrectly assumes that all quotes are followed by at least one character when a lone quote is provided as input an offby one memory access is performed.
zesti infers from the printf c x test the input printf d which triggers the bug.
comparison with standard symbolic execution in terms of bug finding capabilities zesti and klee enjoy different advantages.
on the one hand zesti is able to avoid certain scalability problems that symbolic execution is facing by using the paths executed by the regression suite to reach interesting program states.
for example zesti was able to find forty bugs in libdwarf and ten in readelf while klee was not able to find any of them because it got lost in the large program state space ending up consuming all available memory on our test machine.
the large depth figure .
number of unique by line of code and total checks performed byzesti oncoreutils .
.
at which the libdwarf andreadelf bugs are found in the symbolic state tree min depth column in table i shows that symbolic execution needs to search through a significantly larger number of states.
for example to find a bug at depth requires searching through roughly times more states than it does for a bug at depth .
on the other hand four of the bugs found by klee were not detected by zesti showing its limitations.
one of the bugs found in the tac utility is only triggered when providing more than one input file to the program.
because none of the tests do so the buggy code is never executed in the inconsistent state.
the two bugs found by klee inptx are missed because the regression suite does not contain any tests for this program.
finally the bug in the prutility was not found due to the highly solver intensive test inputs which were consuming all the allocated time budget on the concrete path not allowing zesti to explore beyond it in the allocated time budget.
c. symbolic bug checks and performance overhead symbolic bug checks one measure of zesti s effectiveness is the number of symbolic checks in our case memory access checks made when running a regression suite.
figure shows the number of total and unique checks performed for each program in the coreutils suite when running zesti on the regression suite with distance i.e.
with no additional paths explored and a timeout of two minutes per program execution.
uniqueness was determined solely through the line of code that triggers the check.
figure shows bars one for each coreutils application in which zesti performed symbolic checks while running the regression suite.
the rest of the coreutils programs do not provide any opportunities for such checks because they either are too simple e.g.
yes do not take user input or do not use it to access memory e.g.
id uname .
this does not represent a limitation of zesti but instead shows that not all programs are susceptible to memory access bugs.figure .
zesti execution overhead compared to klee as an interpreter when run with distance on the coreutils regression suite.
overhead of zesti s checks under the same setup we also measured the time taken by zesti to run each test in the regression suite.
to compute zesti s overhead we use as baseline klee as an interpreter only i.e.
without any symbolic data.
because no symbolic data is introduced klee uses its system call models object management system and the same internal program representation as in symbolic execution mode but follows only one execution path and does not use the constraint solver.
to eliminate potential inconsistencies we only consider tests that complete successfully as reported by the regression suite.
this eliminates tests that result in zesti timeouts and a small number of early program exits due to imperfections in uclibc orklee s models which would otherwise add noise to our experiments.
the results are presented in figure which shows one pair of bars for each program execution one for the time taken by the interpreter and one for the time taken by zesti .
the times are sorted by interpreter time.
the last two tests not completely shown take seconds to terminate under the interpreter and have less than overhead under zesti .
we see that for most tests the execution times are virtually identical for klee and zesti .
however there are several executions for which zesti takes significantly more time due to the constraint solver queries that it issues while making the symbolic checks.
finally note that the interpreter time adds significant overhead on top of native execution which for coreutils usually takes only milliseconds per program execution and one way to improve zesti s performance is to speed up the interpreter which in klee is not optimised because in standard symbolic execution it is rarely a bottleneck .
effect of discarding test cases table iii shows the size of the test suite for each application in coreutils for which zesti found a bug t and the distance distribution for the bugs across all available tests for each program d0 d12 .
thenot found value corresponds to not finding the bug in minutes minutes for md5sum .
.
.
.
.
.
sub test suite size cut seq mkdir paste printf md5sumfigure .
probability to find the coreutils bugs at the minimum distance relative to the size of a randomly chosen sub test suite.
based on the information in table iii and using the formula presented in section iv c we plotted in figure the probability of finding the bug at the minimum distance for each of these applications relative to the size of a randomly chosen sub test suite.
it can be noticed that the worst scenarios correspond to the printf andmd5sum programs where more than half of the tests are needed to have at least confidence in finding the bug.
for the rest of the programs a confidence of at least can be achieved by using roughly one third or less of the tests.
this indicates that in practice it might be possible to improve zesti s efficiency without significantly affecting the probability of finding a bug by randomly discarding a large part of the test suite.
libdwarf s test suite corroborates these results while readelf has a test suite too small to be considered for this analysis.
vii.
d iscussion and future work the ultimate goal of our project is to make zesti accessible to testers through a simple standardised interface.
most systems already include a regression test suite usually invoked from the command line via a make check ormake test command.
some systems also allow running the regression suite through a memory debugger such as valgrind using a simple command such as make test valgrind in order to catch invalid memory operations which do not result in observable errors.
we envision exposing zesti through a similar command e.g.
make test zesti which would enable all the additional checks made by it.
the approach implemented by zesti has several advantages it does not require changes to the program source code or to the regression tests as zesti is interposed transparently between the test harness and the actual program it takes advantage of the effort put in the original test cases as they are reused to drive symbolic execution under zesti and for each bug found an input that reproduces the bug is generated furthermore to help developers understand the bug this input is kept as similar as possible to the original test input.table iii bug distance distribution for the bugs found by zesti in co r e u t i l s .
the minimum distance at which the bug is found for each program is in bold .
thenot found value corresponds to not finding the bug in 15minutes minutes for m d5s u m .
app t d0 d1 d2 d3 d4 d5 d6 d7 d8 d9 d10 d11 d12 not found cut .
.
printf .
.
.
.
.
md5sum .
.
mkdir .
.
.
.
mknod mkfifo paste .
.
seq .
.
.
.
.
.
.
.
.
the main disadvantage of this approach is that it can take significantly more time than natively executing the regression tests.
however our empirical analysis showed that a good regression suite allows finding bugs close to the concrete execution path thus minimising the time spent symbolically executing the program.
furthermore zesti can be tuned to specific time budgets through various configurable settings which limit the exploration via timeouts perinstruction per solver query per branch from the concrete path or by disallowing execution beyond a certain distance.
finally if necessary developers can only run a part of the test suite under zesti often without significantly lowering the probability of finding bugs.
one of the problems of symbolic execution is that it can get stuck in uninteresting parts of the code such as input parsing code and therefore miss interesting deep paths.
zesti solves this problem by first executing the entire program along the paths from the regression suite and then exploring additional branches symbolically in increasing distance from sensitive instructions and the program end.
one problem that we observed in the prutility from thecoreutils suite is a very expensive in terms of symbolic checks concrete path.
this prevents zesti from exploring paths which diverge from the test suite in the given time budget.
in the future we plan to incorporate in zesti techniques for adaptively skipping checks effectively allowing the tester to trade checks at a lower depth for checks at a higher depth.
unlike symbolic execution zesti eliminates the guesswork involved in setting up symbolic data.
in particular choosing the appropriate number and size of symbolic inputs is non trivial on the one hand small inputs may miss bugs while on the other hand large inputs can significantly increase execution overhead by generating very expensive constraint solving queries or by causing symbolic execution to spend most of its time in non interesting parts of code.
while analysing the two coreutils bugs detected by zesti but missed by klee we found that carefully tuning the symbolic input size allows standard symbolic execution to find them.
surprisingly one of the bugs can be found only with larger inputs while the other only with smaller ones.
the cut bug can be found only when using two long arguments but the original klee tests were using a singlelong argument and the printf bug can only be found with an argument of size one but the original klee tests used a larger size.
good regression test suites invoke applications with representative arguments both in number and size which zesti successfully exploits.
viii.
c onclusion we have presented zesti a lightweight symbolic execution based tool that automatically improves regression test suites with the ability to reason about all possible input values on paths executed by the test suite as well as explore additional paths around sensitive instructions.
zesti approaches testing from two different angles first zesti significantly broadens the number of bug checks performed by a regression suite and therefore the number of bugs found.
second by using the regression suites as a starting point zesti provides an effective solution for guiding the exploration of the symbolic search space.
as a result of these features we were able to successfully apply zesti to three popular software systems gnu coreutils readelf and libdwarf where it found previously unknown errors including two in the coreutils suite which was previously checked thoroughly via symbolic execution.
we believe our technique can be effectively integrated with existing regression suites and could help bridge the gap between standard regression testing and symbolic execution by providing a lightweight incremental way of combining the two techniques.
we are making our tool zesti available as open source at