asynchronous programs with prioritized task buffers michael emmi liafa universit paris diderot paris france mje liafa.jussieu.frakash lal microsoft research bangalore india akashl microsoft.comshaz qadeer microsoft research redmond wa usa qadeer microsoft.com january technical report msr tr formal programming models are designed to identify and isolate key features in programs.
for example pushdown systems are a natural and popular model for sequential recursive programs that isolate the call return semantics of procedure calls.
isolating features allows an analysis to focus on the key challenges.
for concurrent programs the model of multithreading can sometimes be too general.
consequently previous work has proposed a model of asynchronous programming where tasks unit of computation can be posted to a task buffer and are then executed in a nondeterministically chosen but serial order from the buffer.
guided by real world applications of asynchronous programming we propose a new model that enriches the asynchronous programming model by adding two new features multiple task buffers and multiple task priority levels.
in our model tasks can reside in multiple buffers and are served in priority order.
our model allows non serial execution tasks with higher priority can preempt tasks with a lower priority and tasks obtained from different buffers can freely interleave with each other.
modeling these features allows analysis algorithms to detect otherwise uncaught programming errors in asynchronous programs due to inter buffer interleaving and task interruption while correctly ignoring false errors due to infeasible out of priority order executions.
we also give an algorithm for analyzing this new model.
given bounds k1 k22nthat restrict inter buffer task interleaving and intra buffer task reordering we give a code to code translation from programs in our model to sequential programs which can then be analyzed by off the shelf sequential program analysis tools.
for any given parameter values the sequential program encodes a subset of possible program behaviors and in the limit as both parameters approach infinity the sequential program encodes all behaviors.
we demonstrate the viability of our technique by experimenting with a prototype implementation.
it is competitive with state of the art verification tools for concurrent programs.
our prototype is able to correctly identify programming errors in simplified asynchronous windows device driver code while ignoring infeasible executions.
microsoft research microsoft corporation one microsoft way redmond wa introduction users of interactive computer systems expect little or no latency in an application s ability to react to their actions.
for instance when interacting with a graphical user interface gui one expects an instant reaction for each mouse click and key stroke despite the long running computation the application may be performing.
similarly one expects a web server to reply to each http request immediately despite the thousands of concurrent requests the server may be handling.
to ensure such low latency behavior the modern operating systems on which these applications run provide mechanisms to break and parallelize applications sequential control flow.
hardware events initiate software handlers which interrupt the currentlyexecuting process e.g.
ensuring each keystroke is communicated to the application immediately.
in multi processing systems logically disjoint tasks are executed in parallel e.g.
to divide the processing of distinct http connections across several cores or processors.
traditionally such reactive software systems have been designed as shared memory multi process or multi threaded programs.
whether executing on a single or across multiple processors a collection of software threads each essentially behaving as recursive sequential programs execute concurrently interleaving their read and write accesses to shared memory.
though simple to state such a concurrent programming model is complex due to the many possible intricate interactions between threads.
such complexity is troublesome for the designer who must predict and prevent undesirable thread interleavings by adding synchronization such as atomic locking instructions.
this job is particularly difficult given that over synchronizing e.g.
by protecting all transactions by a single global lock hampers reactivity and destroys opportunities for parallelization.
furthermore the non deterministic nature of such interleaving semantics is the root cause of heisenbugs i.e.
programming errors that manifest themselves rarely and are often very difficult to reproduce and repair.
in reaction to the difficulty of multi threaded programming reactive software systems designed according to the asynchronous programming model have gained much traction.
an asynchronous program divides cumulative program behavior into short running tasks.
each task behaves essentially as a recursive sequential program which in addition to accessing a memory shared by all tasks can post new tasks to task buffers for later execution.
tasks from each buffer execute serially one after the other when one task completes another task is taken from the buffer and run to completion.
to program a reactive system the designer simply must ensure that no single task executes for too long to prevent other possibly more urgent tasks from executing.
figure illustrates the general architecture of asynchronous programs.
due to the relative simplicity asynchronous programming is becoming a particularly appealing way to implement reactive systems.
asynchronous programming has seen widespread adoption in recent years by desktop applications servers and embedded systems alike.
the javascript engines of modern web browsers grand central dispatch in macos and ios linux s work queues asynchrony in .net and deferred procedure calls in the windows kernel are all based on asynchronous programming.
even in the single processing setting i.e.
without any parallelism asynchrony frameworks such as node.js are becoming widely used to design extremely scalable web servers.
despite the relative simplicity of asynchronous programming concurrent programming errors are still possible.
since programmers are often required to restructure long running tasks tinto a sequence of short running tasks t1 t i other tasks executing between sometjandtj 1may interfere with t s intended atomic computation.
furthermore tasks executing across several task buffers e.g.
on a multi core processor are not guaranteed to execute serially and may interleave their accesses to shared memory.
formal figure .
a general architecture of asynchronous programs with ntask buffers.
tasks from the same buffer execute serially but concurrently with tasks of other buffers.
reasoning about concurrent program behavior is thus still crucial to prevent costly programming errors.
in order to analyse asynchronous programs we propose a formal model to capture concurrency in real world asynchronous systems.
in our model each task has an associated priority level and tasks execute from and post to multiple task buffers.
tasks from each buffer execute serially one after the other posting new tasks to the same buffer from which they were taken but tasks of distinct buffers may interleave.
initially each task buffer contains at least one initial task.
when one task completes a highest priority pending task is taken from its buffer and begins executing.
at any moment when a task t1posts a higher priority task t2 t1is suspended to executet2.
when there are no more remaining tasks with higher priority t1resumes execution.
the number of priority levels and task buffers are both finite and statically determined.
furthermore tasks taken from one task buffer may not post tasks to another the only inter buffer communication occurs though shared memory.
our model extends previous formal model of asynchronous programs proposed by sen and viswanathan to more accurately capture the concurrency in real world asynchronous programs .
without accounting for priorities the previous model permits priority order breaking executions which can never arise in the actual system being modeled.
by considering a single task buffer the previous model excludes inter buffer task interleavings which can arise in actual systems.
in the context of formal verification the former leads to falsely detected errors while the latter leads to uncaught errors.
we also give an algorithm for analyzing programs that follow our model.
the state reachability problem for finite data programs with a single task buffer and single priority level is decidable .
it remains decidable in the presence of multiple levels though highly complex .
extending orthogonally to multiple interleaving taskbuffers renders the problem undecidable recursive multi threaded programs are easily captured.
nevertheless we believe the multiple task buffer asynchronous model is important enough to be distinguished from the multi threaded model for two reasons.
first encoding an asynchronous program with multiple prioritized task buffers as a multi threaded program requires adding additional state and synchronization to ensure a same buffer tasks do not interleave and b only highest priority tasks from each buffer may execute.
encoding these constraints with general purpose synchronization mechanisms disregards the more declarative program structure and leads to inefficient program exploration as shown by our experiments .
second by leveraging the intensional structure of concurrency in the actual program we can derive useful heuristics for prioritized program exploration.
for example following the premise of contextbounding we benefit by exploring program executions with relatively few alternations between task buffers or relatively few intra buffer task reorderings without directly restricting the number of tasks executed .
1in the spirit of exploiting the structure of asynchronous programs we develop a parameterized program analysis by reduction to sequential program analysis.
the analysis parameters k1andk2 restrict the amount of interleaving between tasks of different buffers k1 and reordering between tasks of the same buffer k2 as we increase k1 resp.
k2 our analysis explores more and more inter buffer task interleavings resp.
intra buffer task reoderings in the limit as both k1andk2approach infinity our encoding encodes all valid executions.
for any given parameter values we succinctly encode a limited set of asynchronous executions as executions of a non deterministic sequential program with a polynomial number in k1andk2 of additional copies of shared variables.
our encoding is compositional in the spirit of existing sequential program reductions in that each taskbuffer s execution is explored in isolation from other task buffers and the task buffers themselves are not explicitly represented.
such compositionality sidesteps the combinatorial explosion that would arise by keeping the local state of other buffers tasks and by explicitly representing the contents of even a single task buffer.
our reduction happens in two steps.
first in section we reduce asynchronous programs with multiple task buffers to asynchronous programs with a single task buffer while preserving task priorities.
we accomplish this by a code to code translation that introduces k1 copies of shared variables.
each copy stores the value at which a task resumes after being preempted by other buffers tasks these values are initially guessed and later validated.
interleavings with other task buffers are thus simulated locally by moving to the next shared variable copy.
in the second step section we reduce single buffer asynchronous programs with task priorities to sequential programs.
we again accomplish this by a code to code translation though in this translation we also introduce copies of shared variables for each priority level.
since our translation targets a sequential program without explicitly representing the task buffer each asynchronous task post is roughly translated as a synchronous procedure call.
as posts to lower priority tasks are not allowed to execute immediately we use the extra shared variable copies to summarize their execution postponing their effects until later.
this paper makes the following contributions motivated by our investigation into the concurrency arising in real world desktop server and embedded asynchronous software section we introduce a model of asynchronous programs with multiple task buffers and task priorities section that can naturally express the concurrency in these applications.
we propose an incremental parameterized analysis technique for asynchronous programs by a two step reduction to sequential programs sections and .
we demonstrate that our analysis is relatively easy to implement and efficient in practice.
we have written a prototype implementation for bounded verification of asynchronous c programs section .
our tool is able to discover errors in our case studies without imprecisely reporting false errors which would be detected by analyses based on existing asynchrony models.
by translating asynchronous programs to sequential programs we allow the many existing sequential program analysis tools to be lifted for underapproximate analysis of asynchronous programs.
moreover our translation is agnostic to datatypes present in the program and is thus able to target analyses that support arbitrary data domains e.g.
boolean programs programs with integers or lists etc.
.
asynchronous programming in practice in order to build practical verification and debugging tools we desire to formally specify the program behaviors that occur in re active software systems.
to better understand why existing formal programming models are inadequate we examine two real world applications hardware software interaction in the windows operating system and asynchronous multi processing in the apache web server.
.
hardware software interaction in the windows kernel the primary mechanism for ensuring high performance hardware interaction in the windows kernel is priority interrupt levels .
in the following discourse we focus on three levels in decreasing priority order device level1 dispatch level and passive level .
at the device level run the software interrupt service routines isrs .
a boolean valued interrupt line connecting the device to a processor core triggers a fixed isr when a core s interrupt line is raised and an isr is not currently running the currently running code is interrupted to execute the isr.
since device level routines prevent any other code including the scheduler from executing device level routines should execute in a very short period of time delegating remaining computation to an asynchronous deferred procedure call dpc .
the windows kernel maintains a queue of pending dpcs and periodic invocations of the windows scheduler and executes each one by one at dispatch level until completion until the queue is empty.
normal applications run at passive level and thus only execute when the dpc queue is empty.
like device level code dpcs should not sleep or block waiting for i o instead they should either continue to defer future work by queueing another dpc or delegate the work to a passive level thread.
although dpcs are guaranteed not to interleave with other dpcs nor application threads on the same core dpcs may execute concurrently with isrs dpcs the windows scheduler and threads of other cores.
besides bringing reactivity the priority level scheme provides synchronization for devices shared data.
since code above passive level executes atomically without preemption by same or lower level code raising from passive level to dispatch level synchronizes device accesses on a single core.
our model can precisely capture these aspects of windows by assigning each task one of the three priority levels and by dividing code from separate cores into separate task buffers.
in order to capture arbitrary interleaved interaction between hardware and software we can designate a separate task buffer for a single spinning hardware simulating task.
note that ignoring priorities can result in false data race errors on device data protected with level based synchronization and ignoring multiple buffers will miss real errors due to interleaving across separate cores or with the hardware .
.
multi processing in apache via grand central dispatch in a recently released software patch the once multi threaded apache web server has been redesigned as an asynchronous program using the libdispatch concurrency framework .
in the updated architecture the application begins by creating a number of concurrently executing connection listener objects each maintaining a separate queue of incoming connection requests.
each listener handles connection requests by creating a new connection object which besides storing all data relevant to a given client connection maintains a queue of tasks pertaining to the connection.
client activity on the low level network socket triggers additional connection processing tasks to be placed on the queue.
tasks spurred by periodic timers and server replies are also placed on the queue.
importantly the tasks manipulating the data of any given connection are placed in the same task queue although the connection listening 1device level is really a family of levels to which each device maps.
here we consider a generic device mapped to a single level.
2tasks responsible for initializing new connection data are distributed across several queues.
the underlying concurrency manager called grand central dispatch gcd is responsible for executing tasks from the various queues.
gcd ensures that each task from a queue executes only after the previous task has completed.2concerning apache this ensures that at most one task per connection executes at any moment and allows several tasks from distinct connections and connection listeners to execute concurrently.
for any finite number of connections and listeners our programming model accurately captures the possible executions by associating a task buffer to each connection and connection listener.
existing formal models do not suffice.
single buffer asynchronous programs could not capture potentially unsafe interleaving between connections and between connection listeners without adding extra synchronization multi threading allow tasks of the same connection to erroneously interleave their shared memory accesses.
.
abstraction of task buffer order these systems fit well into our programing model with one caveat we abstract the fifo ordered queues by unordered buffers.
we believe this is justified for two reasons.
first algorithmic formal reasoning about processes accessing unbounded ordered queues remains a difficult problem.3second our understanding of these particular systems leads us to believe that while the fifo semantics is important to ensures fairness and reactivity key safety properties may not rely on the order.
of course this is not a technical limitation one can encode the fifo order using shared memory synchronization if required but at the cost of introducing significant complexity .
.
asynchronous programs we consider a programming model in which computations are divided into tasks .
each task has a fixed priority level and a taskbuffer associated with it and behaves essentially as a recursive sequential program.
besides accessing a global memory shared by all other tasks each task can post additional tasks to its taskbuffer for later execution.
same level tasks from each buffer execute serially one after the other yet are interrupted by higher level tasks and executed in parallel with tasks from distinct buffers.
we call a task buffer without a currently executing task idle the yet to be executed tasks of a buffer pending the tasks who have finished execution completed and the task chosen to execute when another completes dispatched .
initially each task buffer is idle and contains at least one pending task.
when a buffer is idle or a task completes a highest priority pending task is dispatched.
at any moment when a taskt1posts a higher priority task t2 t1is suspended to execute t2 we sayt1isinterrupted byt2 as soon as all higher priority tasks of the same buffer have completed t1resumes execution.
the resulting model generalizes the classical model of asynchronous programs by adding priority levels and multiple task buffers.
here only highest priority tasks may be dispatched and tasks from different task buffers execute in parallel.
though we prefer to keep the concept of task buffer disconnected from physical entities such as processes threads processors cores etc.
section describes particular mappings to task buffers from such entities in real world asynchronous systems.
we adopt an interleaving semantics for our model at any point in time only tasks from a single task buffer may execute but a buffer preemption can transfer control to a task from another buffer.
2strictly speaking gcd schedules at most wtasks from each queue where wis a user specified per queue parameter usually set to .
3state reachability for even a single finite state process accessing an unbounded queue is undecidable .p v ar g t pro cp v ar l t s s s sj skipjx ej assumee j ife thens elsesj whilee dos j callx p ej returne j p ostm p ej yieldj zield x gj l figure .
the grammar of asynchronous programs p. heret is an unspecified type p2procs ranges over procedure names e2exprs over expressions and m2mover priority levels.
we explicitly mark opportunities for such control transfers with a special program statement called zield .
additionally to further extend the applicability of our model we introduce a similar controltransfer called a task preemption that suspends execution of the current task and transfers control to another same level task of the same buffer.
we mark opportunities for these transfers with a special program statement called yield .
having explicit instructions for such control transfer allows for great flexibility in model.
we write atomic methods e.g.
synchronization operations simply by omitting yield s and zield s for the duration of the atomic section.
we model dispatch level deferred procedure calls in windows see section by omitting yield s but not zield s .
moreover we model multithreaded programs by inserting yield s before every statement that accesses shared memory.
.
program syntax letprocs be a set of procedure names vals a set of values exprs a set of expressions and n m2n resp.
the number of task buffers and priority levels.
for n2nwe denote the setf0 n 1g simply byn.
the grammar of figure describes our language of asynchronous programs with prioritized task buffers .
we intentionally leave the syntax of expressions eunspecified though we do insist vals contains true andfalse and exprs contains vals and the nullary choice operator ?.
amulti buffer resp.
single buffer program is a program with resp.
without zield statements.
a program in which the first statement of each posted procedure5is while?
do yield is called reorderable a program in which the yield statement does resp.
does not occur otherwise including transitively called procedures is called preemptive resp.
non preemptive and a program without yield or zield statements is called scheduler dependent .
intuitively a scheduler dependent program is deterministic modulo nondeterminism in the sequential statements e.g.
arising by using the ?
operator in if then else statements and modulo the possibly nondeterministic choices made at task dispatch points in a reoderable program any dispatched task can immediate re become pending.
a sequential program is one without p ost yield and zield statements.
each program pdeclares a single shared type tglobal variable g and a sequence of procedures named p1 pi2procs eachp having single type tparameter land a top level statement denoted sp.
the set of program statements sis denoted stmts .
furthermore each program pdeclaresnparameter less initial procedures named main main .
.
.
main n which are never posted nor called we will assume an initial frame of main n is initially pending for each task buffer n2n.
intuitively a p ostm p e statement is an asynchronous call to a procedure pwith argument eto be executed at priority level m. the yield statement transfers control to a same priority level pending task of the same task buffer 4here we assume memory accesses are sequentially consistent .
5we assume each procedure can be either posted or called but not both.
3g v2vals e2exprs s2stmts p2procsf2framesdef vals stmts m t2tasksdef frames a2n!tasks b2n!m c2con gsdef vals n n!tasks n!m figure .
the semantic domains of the meta variablesused in the transition relation of figure .
and the zield statement transfers control to a task from another taskbuffer.
the assumeestatement proceeds only when eevaluates to true we will use this statement to block undesired executions in subsequent reductions to sequential programs.
the programming language we consider is simple yet very expressive since the syntax of expressions is left free and we lose no generality by considering only single global and local variables.
appendix a lists several syntactic extensions which easily reduce to the syntax of our grammar and which we use in the source to source translations of the subsequent sections.
additionally hardware interrupts and lock based synchronization can be encoded using global shared memory see sections .
and .
.
.
program semantics a procedure stack frame f h s miis a current valuation 2vals to the procedure local variable l along with a statement sto be executed and a priority level m2m.
heresdescribes the entire body of a procedure pthat remains to be executed and is initially set to p s top level statement sp.
the set of frames is denoted framesdef vals stmts m. a sequence t f1 fi of frames is called a task f1is the top most frame and the set of tasks is denoted tasks .
the level resp.
base level of a task t denoted by level t resp.
base t is the level of t s topmost resp.
bottommost frame and 1whent .
since we consider a cooperative multitasking model where control transfers between buffers and between tasks of the same buffer are explicit our operational model need only consider a single currently executing task of a single buffer at any moment.
when higher level tasks of the same buffer interrupt a lower level task our model simply adds the higher level task s frame to the top of the current procedure stack.
we thus represent each task buffer n2nby a currently executing active task a n 2tasks along with a multiset b n 2m of pending tasks and we define a configuration c hg n a bias a valuation g2vals of the global variable g along with a currently active task buffer n2n an active taska n!tasks per buffer and a multiset of pending tasks b n!m per buffer.
figure summarizes the various semantic domains and meta variable naming conventions.
we define top m !mas the maximum level for which there is a pending task in the given buffer top def max f0g f level t t2 g and we let top hg n a bi def top b n be the maximum such level for the currently active buffer.
similarly we define the level of a configuration as the level of the currently active buffer level hg n a bi def level a n .
the singleton pending tasks map n7!t mapsntoftg and n02nnfngto and the union b1 b2of pending tasks maps is defined by the multiset union of each mapping b1 b2 n def b1 n b2 n forn2n.
similarly the active task map a0 a n7!t extendsaby setting the currently active task of buffer n tot a0 n t anda0 n0 a n0 for alln02nnfng.for expressions without program variables we assume the existence of an evaluation function j ke exprs!
vals such that j?ke vals.
for convenience when c hg n a biand a n f t h s mit we define e c def e g f t def e g f def e g def je ke to evaluate the expression ein a configuration c alternatively in a global valuation gand taskf t by substituting the current values for variables gand l. as these are the only program variables the substituted expression e has no free variables.
for expressionseover only the task local variable lwe writee f t def je ke.
additionally we define c g g0 def g0 n a b global assignment c l def g n a n7!f0 t b local assignment c f0def hg n a n7!f0 f t bi frame push pop wheref0 h s miupdates the local valuation of frame f and f0is an arbitrary frame.
to reduce clutter and highlight the meaningful components of rules in the operational program semantics we introduce a notion of context.
a statement context sis a term derived from the grammar s js s wheres2stmts .
we write s for the statement obtained by substituting a statement s for the unique occurrence of ins.
atask statement context t h s mitis a task whose top most frame s statement is replaced with a statement context and we write t to denote the taskh s mit.
finally a configuration statement context c hg n a n7!t biis a configuration whose currently active task is replaced with a task statement context and we write c to denote the configuration hg n a n7!t bi.
intuitively a context filled with s e.g.
c indicates that sis the next statement to execute in a given configuration task or statement sequence.
we abbreviate e t e g t ande c by resp.
e t e g t ande c for arbitrary expressions e. as an example the assume rule of figure takes a configurationc hg n a n7!h assumee s mit bi in which true2e c e g and transitions to the configuration c hg n a n7!h skip s mit bi as only the current statement is updated the description c !pc completely and concisely describes the configuration change.
figure defines the transition relation !of asynchronous programs as a set of operational steps on configurations.
the transitions for the sequential statements are mostly standard.
the assume rule restricts the set of valid executions a step is only allowed when the predicated expression eevaluates to true .
this statement usually confined to intermediate languages is crucial for our reductions between program models in the subsequent sections.
more interesting are the transitions for the asynchronous constructs i.e.
p ost yield and zield .
the postrule creates a new frame to execute given procedure pwith argument eat levelm0 and places the new frame in the pending tasks of the currently active task buffern.
when a single frame task fcompletes its execution theresume rule discards fto continue the execution of the task tbelowfon the procedure stack.
the yield rule allows a task to relinquish control to another pending task at the same level.
the zield rule simply updates the currently active task buffer from n to somen02n.
the dispatch rule schedules a highest level task t1when the currently executing task t2has a lower level.
anexecution of a program p fromc0tocj is a configuration sequencec0c1 cjsuch thatci!pci 1for0 i j .
a configuration c hg n0 a biof a program pisg0 initial when g g0 n0 and for alln2n a n andb n f s main n g 4skip c !
pc assume true2e c c !
pc assign v2e c c !
pc x v if then true2e c c !
pc if else false2e c c !
pc loop do true2e c c !
pc loop end false2e c c !
pc call v2e c m level c c !
pc hv sp mireturn g2 g c v2e g m level c c h s mi !
pc resume m level c c h s mi !
pc post 2e g t f h sp mib0 b n7!f hg n a n7!t bi !
p g n a n7!t b0 dispatch level t1 top b n level t2 hg n a n7!t2 b n7!t1 i !
phg n a n7!t1 t2 bi yield level t1 base t1 level t2 b0 b hg n a n7!t1 t2 bi !
p g n a n7!t2 b0 zield n22n hg n1 a n17!t bi !
phg n2 a n17!t bi figure .
the transition relation for the asynchronous programs each rule besides dispatch is implicitly guarded by level c top c wherecis the configuration on the left hand side of the transition.
for some any6 2vals.
a configurationhg n a biisgf final wheng gf.
a pairhg0 gfiis areachability fact of pwhen there exists an execution of pfrom somec0to somecfsuch thatc0is g0 initial andcfisgf final.
problem state reachability .the state reachability problem is to determine given a pair hg0 gfiand a program p whether hg0 gfiis a reachability fact of p since preemption i.e.
arbitrary use of the yield statement and multiple task buffers can both be used to simulate arbitrary multi threaded programs the presence of either feature makes statereachability undecidable.
theorem .
the state reachability problem is undecidable for finitedata asynchronous programs with either preemptive tasks or with multiple task buffers.
for single buffer programs without arbitrary preemption between tasks atig et al.
have shown decidability by reduction to reachability in a decidable class of petri nets with inhibitor arcs.
theorem .
the state reachability problem is decidable for finitedata single buffer programs without preemption.
though atig et al.
s reduction does show decidability it does not lead to a practical program analysis algorithm since the only known algorithms for checking reachability in petri nets have extremely high complexity they are non primitive recursive .
in the following sections we design an approximating algorithm for the general case encompassing both cases of theorem and by reduction to sequential program analysis.
though approximation is necessary in the undecidable case with preemption or multiple buffers approximation also allows us practical analysis algorithms in the decidable yet complex case with prioritized buffers.
note that though these decidability results only apply to finite data programs our sequential reduction applies equally well to programs with infinite data and does not approximate individual program states e.g.
given a program using unbounded integer variables our 6since main n takes no arguments the initial local valuation is irrelevant.translation encodes a subset of all possible concurrent behaviors without abstracting in any given state the integer variable valuations.
.
modeling hardware interrupts although our model only allows tasks to post other tasks to their own buffers inter buffer task posting can be modeled using shared memory.
for instance consider modeling hardware interrupts in operating systems kernels like windows and linux.
each processor core has a fixed number of boolean valued interrupt lines which once raised by hardware devices trigger software routines to interrupt the currently running application or kernel task see section .
for more details .
to model hardware interrupts we add an additional highest priority level m and an array v ar irq bto the global program state here we suppose each core corresponds to a taskbuffer and we handle only a single interrupt line per core the generalization to multiple lines per core is straightforward.
for each coren2n we designate a fixed procedure pro c ih n sto be the interrupt handler for the core.
raising an interrupt on core n2nis as simple as setting irq true .
an interrupt is caught and processed on core nby inserting the following code before each global variable access and p ost yield or zield statement if irq then irq false p ostm ih n posting to level mensures that no matter which level the current task is running at the interrupt handler will interrupt it.
.
modeling synchronization as the execution of tasks across multiple task buffers may interleave in general programs need a way to ensure atomicity of data accesses.
implementing atomic locking instructions is not difficult because we have assumed tasks are only preempted by other buffer s tasks at designated zield points or by same buffer tasks at designated yield points.
a lock can thus be implemented by adding an additional global variable v ar lock b acquiring the lock is achieved by the statement 5while lock true do yield only for preemptive programs zield lock true and releasing the lock is as simple as setting lock false .
note that the exit from the while loop and the assignment lock true are guaranteed to happen atomically since there are no interfering yield or zield statements.
once the lock is held by one task any other acquiring tasks must wait until it is released.
.
reduction to single buffer programs as a first step in our scheme to reduce the state reachability problem of asynchronous programs to state reachability in sequential programs we translate multiple buffer programs to single buffer programs while preserving task priorities.
as the state reachability problem for single buffer finite data asynchronous programs with task priorities is decidable for non preemptive programs7 while our multi buffer variation is not our translation necessarily represents an approximation of the original problem.
though our translation encodes various inter buffer interleavings it cannot encode every inter buffer interleaving.
in order to control and refine the amount of considered interleavings and thus the degree of approximation our translation takes a bounding parameter k. following the approach of the original multi threaded sequentializations for a given bounding parameter k we explore only k round roundrobin executions in buffer index order i.e.
in each round tasks from buffer 0execute until a perhaps not the first zield statement at which point tasks from buffer 1execute to some zield statement and so on.
at the zield statement where a task from buffer n gives up control the second round begins resuming the suspended task of buffer .
note that the bounding permits arbitrarily long executions within a buffer.
example restricted inter buffer interleaving .the following asynchronous program with 2task buffers and a single priority demonstrates how k round exploration restricts program behaviors.
v ar b b v ar r n pro c main b true r p ost p return pro c main p ost q returnpro c p zield assume !b b true r r p ost p return pro c q zield b false p ost q return in the round robin order execution begins with main of the first task buffer which sets the variable bto true sets rto and posts a single task p. each ptask blocks unless bis set to false in which case bis set to true rincremented and pre posted.
when the zield statement is encountered control may be transferred to the second task buffer which begins in main by posting q. each instance of qsets bto false and re posts q. in a single round execution i.e.
k the only reachable value of ris .
in order to increment r a qtask of the second buffer which sets bto false must be executed before p s assume statement.
in general incrementing rktimes requires krounds of 7note that the programs atig et al.
consider are non preemptive what they refer to as preemption we refer to as interruption.
translation of var g t v ar g t v ar k k translation of g g translation of zield k in k k translation of post m p e p ost m p e translation of proc main i s pro c main i s pro c main for n ton do k p ost main n figure .
the multi to single buffer code translation p k mof a multi buffer asynchronous program pparameterized by k2n.
the resulting single buffer program encodes only round robin taskbuffer executions of krounds.
execution each in which a qtask from the second buffer proceeds a ptask of the first.
since only one such alternation can happen per round krounds are required to make kalternations.
as in lal and reps s original multi threaded sequentialization our code translation k mof figure stores a copy of the global valuation reached in each round.
initially the global valuations for the second round and beyond are set non deterministically.
then for each task buffer n we execute all tasks from nacross all rounds before moving on to the next buffer and resetting the round to0.
at non deterministically chosen zield statements any task may cease accessing the ithglobal valuation copy and begin using the i stcopy this simulates the progression of buffer nfrom roundito round i .
after each buffer has completed executing all of its tasks we can determine whether the initially guessed global valuations were valid by ensuring the initial valuation from each roundi 0matches the valuation reached in round i .
this validity relation is captured formally by a predicate sk mrelating initial and final global valuations a sequentialized execution of p k mfromg0togfrepresents a valid k round round robin execution of the original program ponly whensk m g0 gf in which case a mappingfk mtranslates the reachability pair hg0 gfito a valid reachability pair fk m g0 gf inp.
note that our simulation requires only a single task buffer since we execute all tasks of each buffer to completion before moving on to the next.
to ensure all tasks of each buffer complete before coming back to main s loop we shift all priority levels up by one.
formally our k round multi to single buffer translation k m d k m sk m fk me is the code transformation k mlisted in figure along with a validity predicate sk m vals2!b indicating when an execution of p k mcorresponds to a valid execution of p and a function fk m vals2!vals2 mapping reachability pairs of p k mto reachability pairs of p sk m g0 gf def g g0 g gf fk m g0 gf def h g g0 g gf i. given this correspondence we reduce state reachability of k round multi buffer round robin executions of pto state reachability of p k m this reduction thus under approximates p s behavior.
theorem soundness .for all programs p ifhg0 gfiis a reachability fact of p k mandsm g0 gf holds thenfm g0 gf is a reachability fact of p. 6since every multi buffer execution can be expressed in a finite number of rounds of a round robin execution our reduction completely captures all executions in the limit as kapproaches infinity.
theorem completeness .for all reachability facts hg0 gfiof a programpthere existsk2nand a reachability fact g0 g0 f of p k msuch thathg0 gfi fm g0 g0 f andsm g0 g0 f .
.
translation composition crucial to our staged translation approach is the fact that a sequence of translations can be composed.
the ordered composition of the translations s1 f1 and s2 f2 is defined by the translation s f such that s s2 s1 f2 and f f1 f2.
when both 1and 2are sound and complete in the sense of theorems and then 1is also sound and complete.
.
reduction to sequential programs in the second step of our reduction scheme we translate singlebuffer asynchronous programs with task priorities to sequential programs.
though the state reachability problem is decidable for finite data single buffer programs without preemption allowing arbitrary inter task preemption does make the state reachability problem undecidable due to unbridled interleaving between concurrently executing tasks of the same level indeed recursive multi threaded programs are easily encoded when use of the yield statement is unrestricted.
furthermore even in the decidable case of non preemptive programs the complexity of state reachability is very high due to the arbitrary dispatch order of same level tasks and perhaps further complicated by interruptions from higher level tasks the problem is at least as hard as reachability in petri nets a problem for which the only known algorithms are non primitive recursive .
thus as in section our translation to sequential programs is again obliged in the presence of preemption or at least better off even without preemption to represent only an approximation of the original state reachability problem.
our translation encodes only a subset of the possible task interleavings and dispatch orderings.
as before we introduce a bounding parameter kwith which to restrict the amount of interleavings expressed with increasing values of k we capture more and more interleaving and task dispatching orders and in the limit encode all possible executions.
to simplify our translation we again divide our work in half.
in section .
we propose a translation to remove yields from a given program with task priorities.
in section .
we then translate a yield free single buffer asynchronous program with task priorities to a sequential program.
the first yield elimination step is crucial to our translation it deals with both task reorderings where any of the pending tasks at the same level can be dispatched and task preemption.
our second step then simulates only a fixed schedule of task dispatching following the approach of delay bounded scheduling .
to ensure our translation encodes all possible task dispatch schedules in the limit as the bounding parameter approaches infinity we assume programs are reorderable i.e.
by requiring that the first statement of each task is while?
do yield .
note that this does not make a program preemptive recall the definitions of section .
.
.
eliminating preemption and reordering again following the vectorization approach pioneered by lal and reps we proceed by restricting the set of interleaved executions translation of call x p e call x k p e cur lvl k translation of return e return e k translation of var g t v ar g t v ar r k translation of yield k in k..k translation of g g translation of proc p var l t s pro c p v ar l t cur lvl m k k s translation of post m p e assert m cur lvl ifm cur lvl then let saved g g in let g?
in g g?
g saved g r k p ost m p e m assume g?
g saved g g g saved g else if m cur lvl then p ost m p e m k else p ost m p e m r figure .
the yield eliminating translation p k yof a singlebuffer multi level program p parameterized by k2n.
between tasks of any given level to those according to a roundrobin schedule for a given bounding parameter k we will explore executions in which each task can be preempted by or reordered with other same level tasks across krounds.
to accomplish this our code translation k yof figure stores a copy g of the global valuation reached in each round k for just one level at a time and each task stores a current round counter k. initially execution begins with a task at level 0accessing the 0thcopy of the global valuation the other copies of the global valuation are set non deterministically.
at any point upon encountering a yield statement the currently executing task can increment his round counter to any value k k and begin accessing the kthcopy of the global valuation.
such an increment propels the current task to roundk simulating a preemption by or reordering with other tasks from his level.
when a task in round kposts a same level task the posted task is constrained to execute in or after round k. the possibility of inter level posts makes our reduction significantly more intricate than previous sequentializations .
posts to higher level tasks interrupt execution of the currently executing task.
when such a post happens we save the globalvaluation vector for the current level line and allocate a new global valuation vector for the target level whose first element is initialized with the current global valuation reached by the posting task lines the other values are again guessed nondeterministically.
when control returns to the posting task we must ensure the guessed global valuations at the beginning of each round of the target level have been reached by previous rounds line when this is the case we have simulated some round robin execution of the target level s tasks.
as long as those guesses can be validated we restore the previously saved global valuation vector for the posting task s level update the current round s valuation with the final valuation reached in the posted task s level and continue executing the posting task lines .
though posting a lower priority level task is handled almost identically to posting a same level task there is one important difference the round of the posted task t2must not occur before the round of an interrupted task t1of the same priority level waiting below on the task stack otherwise causality is broken since t2 would execute before t1in the simulated execution though t2 s existence may rely on t1 s execution.
to prevent such anomalies we store in r the current round kof each priority level mbelow 7the currently executing task and constrain tasks posted to level m to execute no sooner than round k. to simplify our translation we assume priority level mtasks post only tasks of priority at most m posts to higher levels can be encoded by a chain of posts.
we define formally the k round yield eliminating translation k y d k y sk y fk ye as the code transformation k ylisted in figure along with a validity predicate sk yand reachability fact map fk y sk y g0 gf def g g0 g gf fk y g0 gf def h g g0 g gf i. given this correspondence we reduce state reachability of k round round robin intra level executions of pto state reachability of p k y we thus under approximate the behavior of pby restricting the set of interleavings reorderings between same level tasks.
theorem soundness .for all programs p ifhg0 gfiis a reachability fact of p k yandsk y g0 gf thenfk y g0 gf is a reachability fact of p. since every execution with yields can be expressed by allocating some finite number of rounds to each execution sequence of samelevel tasks our reduction completely captures all executions in the limit askapproaches infinity.
theorem completeness .for all reachability facts hg0 gfiof a programpthere existsk2nand a reachability fact g0 g0 f of p k ysuch thathg0 gfi fk y g0 g0 f andsk y g0 g0 f .
.
sequentializing asynchronous programs with priorities by removing all yield statements in the previous step our final translation need only give a translation for scheduler dependent single buffer asynchronous programs with priorities.
our reduction expresses all executions according to a particular total order on taskdispatching.
though not strictly important for the soundness nor completeness of our encoding the determined task dispatch order roughly corresponds to emmi et al.
s deterministic depth first schedule except here we are faced with the added complexity of multiple priority levels.
example restricted intra buffer reordering .the following reorderable single buffer asynchronous program demonstrates how ourk bounded exploration restricts program behaviors.
execution begins with main which sets the variable bto true sets rto and posts a sequence of ptasks followed by a sequence of qtasks.
each ptask blocks unless bis set to false in which case bis set to true and rincremented.
each qtask sets bto false .
v ar b b v ar r n pro c main b true r while ?
do p ost p while ?
do p ost q returnpro c p while ?
do yield assume !b b true r r return pro c q while ?
do yield b false return whenk we explore only executions according to a deterministic schedule of task dispatching specifically according to the depth first scheduler .
for this program that means all posted p tasks must run before any qtask in which case the only reachable value of ris .
whenk we introduce task reordering by translation of call x p e call x p e cur lvl translation of var g t v ar done b v ar g t v ar g translation of proc main s pro c main done false s done true translation of g g translation of proc p var l t s pro c p v ar l t cur lvl m s translation of post m p e assert m cur lvl ifm cur lvl then let g?
?
in g g?
call p e m assume g g?
g g else m cur lvl let saved g g in let saved g g in let g?
?
in g g g g?
call p e m assume g g?
g saved g g saved g figure .
the sequential translation p pof a yield free singlebuffer asynchronous program pwith task priorities.
allowing each task to advance among the krounds at yield points.
in this way k 1rounds suffices to capture kalternations from q to ptasks allowing the value of rto be incremented ktimes.
in the case of a single priority level our asynchronous tosequential code translation pof figure is identical to the no delay depth first scheduling sequentialization .
each p ost statement is roughly translated to a call statement.
since each posted tasktmust execute after the completion of the currently executing task at the point where tis called the current valuation of the global variable gdoes not generally correspond to t s initial global valuation.
the sequentialization thus introduces an auxiliary variable g which holds at any point the global valuation encountered by the next to be posted task.
initially g s value is guessed and later verified to be the value reached by the initial task.
each time a new tasktis posted gis updated with a guess of the value reached bytandtbegins with the previous value stored in g lines and when tcompletes we verify that the guessed value indeed matches the value reached by t line .
the simulated execution corresponds to a depth first traversal of the tree of tasks connected by the task posting relation in which each task executes atomically to completion.
the presence of multiple priority levels makes our translation significantly more intricate.
first instead of a single auxiliary variable gstoring the next to be posted task s valuation we must track that valuation per priority level due to the additional task ordering constraints.
second when a call to a higher level posted task returns we must update the global valuation of the currentlyexecuting task to that reached by the higher priority tasks line rather than restoring previous global valuation as in line this captures interruption.
third calls to lower level m1taskst1must not overwrite the values stored in gfor levels between m1and the current level m3 m e.g.
by posting additional tasks t2to level m2betweenm1andm3.
so would simulate executions in whicht2executes before other same level tasks t0 2not yet posted by levelm3 this would be a breach in causality since t0 2must in reality execute before t1 and thus before t2.
our translation prevents such inconsistent behavior by saving the gvalues for levels between m1andm3 line and restoring them upon return from calls corresponding to lower level posts line .
finally since even the 8value encountered by the first posted task is originally guessed a simulated execution can only be considered valid when the main task completes and can validate the initial guess we add the additional variable done to indicate whether the main task has completed.
to simplify our translation we assume priority level mtasks post only tasks of priority at most m posts to higher levels can be encoded by a chain of posts.
formally our prioritized asynchronous to sequential translation p p sp fp is the code transformation plisted in figure along with the validity predicate spand reachability fact map fpdefined as sp g0 gf def done gf true g g0 g gf and fp g0 gf def h g g0 g gf i. given this correspondence we reduce state reachability of a singlebuffer scheduler dependent asynchronous program with priorities pto state reachability of the sequential program p p. theorem soundness .for all programs p ifhg0 gfiis a reachability fact of p pandsp g0 gf thenfp g0 gf is a reachability fact of p. note that we cannot state a completeness result for this final translation step since the translation only encodes a deterministic schedule of task dispatching.
however when combined with the previousk bounded yield eliminating translation and the assumption that the original program is reorderable we do obtain completeness in the limit as kapproaches infinity.
theorem completeness .for all reachability facts hg0 gfiof a reoderable single buffer asynchronous program pthere exists k2nand a reachability fact g00 g00 f of p k y p and g0 g0 f such that g0 g0 f fp g00 g00 f hg0 gfi fk y g0 g0 f sp g00 g00 f andsk y g0 g0 f .
finally by choosing k1 k22n composing our translations k1 m k2 y p and gathering the results of theorems we have a sound algorithm for state reachability of asynchronous programs with multiple prioritized task buffers and arbitrary preemption which is complete in the limit as both k1andk2approach infinity.
.
implementation and experience we have implemented our sequentialization technique in a tool called async checker .
it takes a concurrent program with assertions as input written in the c programming language extended with thepost primitive for spawning threads.
this primitive allows us to easily model concurrency provided by for example the pthread library or the win32 api.
the user is also given control on where to insert yields and zields the default choice being that they are inserted before every access to a shared variable.
async checker also takes two integers as input which denote the zield budget i.e.
the bound used in section and the yield budget i.e.
the bound used in section .
it uses these budgets to sequentialize the program and then look for assertion violations within those budgets.
when it finds an assertion violation it displays the interleaved error trace.
async checker has the unique capability of targetting one kind of bugs over another by changing the budgets a high zield bound targets bugs that require inter buffer interleavings and a high yield bound targets bugs that require inter task reorderings or preemptions.
async checker uses corral an smt based model checker as the sequential verifier.
appendix b details how we deal with assertions and error trace generation in our sequentializations.
we now give evidence that even though async checker usesname outcome poirot sec async checker sec driver1 correct driver2 buggy driver3 buggy driver4 correct driver5 buggy driver6 correct driver7 correct driver8 buggy driver9 buggy driver10 correct figure .
results on p oirot regressions.
an elaborate sequentialization it is still a practical tool capable of finding real bugs using three different experiments.
first experiment.
our first experiment is to compare async checker against other more mature tools on finding bugs in multithreaded programs with a single task buffer and no priorities .
this is to show although async checker is a prototype implementation it already competes well with existing tools on real programs one does not pay the cost of using multiple task buffers or priorities unless the program uses these features.
we compare async checker against poirot which is also based on a sequentialization technique that requires a thread round robin bound similar in spirit to async checker s yield budget.
poirot also uses c orral as the underlying sequential checker.
for benchmarks we used poirot s regression suite that consists of real device drivers.
some drivers have seeded bugs.
the sizes of the drivers ranged from 500to700lines of source code with three threads that exercise different routines exposed by the driver.
the results are shown in fig.
.
we ran async checker with a zield budget of 1and a yield budget equal to the round bound used by poirot .
in each case the outcome of poirot andasync checker buggy or correct was the same.
async checker performed reasonably well in comparison to p oirot .
for programs with multiple task buffers or prioritized tasks there is no tool other than async checker for analyzing them to the best of our knowledge.
however there is still an alternative to using async checker one can encode the task buffers and priority levels using shared memory and synchronization and then usepoirot on the resulting multithreaded program.
we also implemented this approach lets call it synce .
it introduces shared state that counts the number of tasks in each buffer and at each priority level.
next it inserts assume statements to prevent a task from running if the buffer size at a higher priority level is non empty.
second experiment.
consider the single buffer program shown in fig.
.
we assume that there are implicit yields and zields between every two instructions.
the program has a single assertion in bar that checks the value of xagainst a parameter n. for any positive value of n there is an execution that violates the assertion.
moreover that execution necessarily has to alternate between priorities 0and 1for a total of ntimes.
we ran both async checker andsynce on this program with different values of n. in each case we report the time taken by the tools to find the assertion violation under the best possible budget values.
the table in fig.
shows the poor scalability of synce.
the reason is that async checker can find the bug using a yield budget of1 but poirot running underneath synce requires a contextswitch bound proportional to nbecause of synce s encoding of priorities.
the increase in this bound causes exponential slowdown.
8appendix c outlines this approach in detail using a code to code transformation.
9v ar x n v ar cont b pro c bar v ar t x x t assert x !
n if ?
then cont truepro c main x cont true call foo pro c foo if cont and ?
then cont false p ost bar p ost foo n synce .
.
.
.
async checker .
.
.
.
figure .
a single buffer example and the running times in seconds of s ynce and a sync checker .
v ar x pro c main2 v ar j while ?
do assume x ?
j p ost bar j j assert x !
?
n pro c main1 v ar i while ?
do assume x ?
i p ost bar i i pro c bar v ar t x x t n synce .
.
.
async checker .
.
.
.
figure .
a multi buffer example and the running times in seconds of s ynce and a sync checker .
the next example shown in fig.
has two task buffers with initial tasks main1 and main2 respectively.
again there are implicit yields and zields between every two instructions except in barthat is supposed to execute yield free.
this program requires switching between buffers each time the shared variable is incremented.
note that intra buffer yielding is not necessary for this example an observation that async checker can exploit by setting the yield budget to 1and only increasing the zield budget to find the bug.
the results show that even though async checker has an exponential dependence on the zield budget it scales much better than synce.
this experiment shows that an encoding of priorities and multiple buffers using shared memory may not fit well with the analyses that follows.
this motivates our first class treatment of such features in a sync checker .
third experiment.
inspired by typical hardware software interaction in windows we hand coded a small c program lines of code that has two task buffers one for the hardware and one for the software and three priority levels device level dispatch level and passive level .
tasks running at level above passive level do not yield.
the driver running on the software buffer signals the hardware to read data from a device.
when the hardware finishes reading data it raises an interrupt line a shared variable .
when tasks in the software buffer see that the interrupt line has been raised they post the interrupt handler isr at device level and immediately interrupt themselves .
two read requests from the driver can cause two hardware interrupts to fire but because the isr runs at an elevated level it cannot interleavewith other instances of the isr task.
we seeded a bug in this program where some read request gets dropped without being processed by the driver.
this example is to show why one needs our model.
interbuffer interleaving is necessary to model the hardware software interaction namely the interrupt mechanism and priorities are necessary as well poirot which does not understand priorities gets distracted and reports a data race in the isr which is incorrect.
async checker on the other hand takes 440seconds to find the seeded bug and is incapable of reporting the erroneous data race reported by p oirot .
synce takes too long to finish.
.
related work our model of asynchronous programs with prioritized task buffers is inspired by and extends the classical single buffer asynchronous programming model and that with task priorities considered once before .
though atig et al.
showed decidability of state reachability in the asynchronous programming model with priorities their decision procedure relies on reachability in petri nets for which the only known algorithms are extremely complex they are non primitive recursive.
we build on this body of work by adding multiple task buffers demonstrating real world examples which rely on task priorities and or multiple task buffers and giving a relatively practical parameterized under approximating algorithm for state reachability which incrementally explore more and more program behaviors as the parameter value increases by reduction to state reachability in sequential programs.
our work closely follows the line of research on compositional reductions from concurrent to sequential programs.
the initial socalled sequentialization explored multi threaded programs up to one context switch between threads and was later expanded to handle a parameterized amount of context switches between a statically determined set of threads executing in round robin order .
la torre et al.
later provided an alternate encoding better suited toward model checking the resulting sequential program and eventually extended the approach to handle programs parameterized by an unbounded number of statically determined threads .
shortly after emmi et al.
further extended these results to handle an unbounded amount of dynamically created tasks which besides applying to multi threaded programs naturally handles asynchronous event driven programs .
bouajjani et al.
pushed these results even further to a sequentialization which attempts to explore as many behaviors as possible within a given analysis budget.
though the latter two of these sequentializations are applicable to asynchronous programs dynamically creating an unbounded number of tasks they do not account for task priorities nor multiple task buffers.
though kidd et al.
have demonstrated a priority aware sequentialization their reduction assumes a fixed number of statically determined tasks and does not account for multiple task buffers.
.
conclusion we have introduced a formal model of asynchronous programs with multiple prioritized task buffers which closely captures the concurrency present in many real world asynchronous systems.
though program analysis in our model is complex we propose an incremental approximate analysis algorithm by reduction to sequential program analysis.
the parameters k1 k22nto our sequential reduction restrict resp.
the amount of inter buffer interleaving and intra buffer task orderings explored in the limit as k1andk2approach infinity our reduction explores all program behaviors.
we demonstrate that this reduction is relatively easy to implement and by using off the shelf sequential analysis tools is able to discover concurrency errors without reporting spurious 10errors due to modeling imprecision in asynchronous device driver code in the windows kernel.