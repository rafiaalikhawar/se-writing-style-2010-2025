variability aware performance prediction a statistical learning approach jianmei guo krzysztof czarnecki sven apely norbert siegmundy and andrzej w asowskiz university of waterloo canada yuniversity of passau germany zit university of copenhagen denmark abstract configurable software systems allow stakeholders to derive program variants by selecting features.
understanding the correlation between feature selections and performance is important for stakeholders to be able to derive a program variant that meets their requirements.
a major challenge in practice is to accurately predict performance based on a small sample of measured variants especially when features interact.
we propose a variability aware approach to performance prediction via statistical learning.
the approach works progressively with random samples without additional effort to detect feature interactions.
empirical results on six real world case studies demonstrate an average of prediction accuracy based on small random samples.
furthermore we investigate why the approach works by a comparative analysis of performance distributions.
finally we compare our approach to an existing technique and guide users to choose one or the other in practice.
i. i ntroduction many software systems provide configuration options for users to tailor their functional behavior as well as nonfunctional properties e.g.
performance cost and energy consumption .
configuration options relevant to users are often called features .
each variant derived from a configurable software system can be represented as a selection of features called a configuration .
performance e.g.
response time or throughput is one of the most important non functional properties because it directly affects user perception and cost .
finding an optimal configuration to meet a specific performance goal is a fundamental task for developers and system administrators.
performance of a software system is often subject to a wide variety of influencing factors .
understanding trade offs between influencing factors and performance is non trivial.
in this paper we focus on how to determine the influence of feature selections on performance.
considering a configurable software system as a black box we investigate and exploit the correlation between feature selections and performance for performance prediction.
a straightforward approach to reveal such correlation is to measure the performance of all configurations of a software system and then provide direct answers e.g.
which configuration is the fastest .
however such a brute force approach is usually infeasible because even a small scale configurable system can give rise to an exponential number of configurations due to feature combinatorics and the cost of measurement may be high e.g.
executing a complexbenchmark .
therefore in practice often only a limited set of configurations can be measured either by simulation or by monitoring in the field .
we denote these configurations along with their performance measurements as a sample and all configurations of a software system along with their performance as the whole population .
the challenge is how to use a small e.g.
linear in the number of features sample to predict the performance of other configurations in the whole population with a high accuracy e.g.
above .
quantifying the performance influence of each individual feature is not sufficient in most cases as feature interactions may cause unpredictable performance anomalies .
that is the performance influence of two features both appearing in a configuration may not be easily deducible from the performance influence of each feature without the other.
siegmund et al.
addressed this issue by introducing a measurementbased prediction approach called splc onqueror which detects performance relevant feature interactions using specific sampling heuristics that meet different feature coverage criteria.
however in practice the configurations that we can measure or that we already have at our disposal may not meet any feature coverage criterion.
thus we pose the following research question is it feasible to use small random samples as a basis for accurate performance prediction?
to answer this question we formalize the problem of variability aware performance prediction and reduce it to a non linear regression problem.
we use a statistical learning technique classification and regression trees cart to address the problem and to model the correlation between feature selections and performance.
compared to existing methods our approach works automatically andprogressively with random samples such that one can use it to produce predictions starting with a small random sample and subsequently extend it when further measurements are available it considers all features of a system and identifies the performance relevant ones it treats the selected and deselected features in a configuration equally to describe the correlation between feature selections and performance and it can be easily implemented and deployed in practice without additional effort to detect feature interactions an inherently challenging task .
in summary we make the following contributions we propose a progressive and variability aware approach that predicts a configuration s performance based on978 .
c ieee ase palo alto usa301random samples.
the approach builds an explicit performance model to specify the correlation between feature selections and performance to be used for performance prediction.
we implement the approach and demonstrate its practicality and generality by experiments on six real world configurable software systems.
the results show that the approach produces an average prediction accuracy of based on only small random samples.
moreover we observe a desirable increasing trend of prediction accuracy when the sample size increases.
we conduct a comparative analysis of performance distributions on the evaluated case studies and empirically explore why the approach works with small random samples.1a key finding is that it works well when the sample it uses has a performance distribution similar to the whole population.
we compare our method with an existing technique that relies on heuristics and feature coverage .
in particular we discuss the strengths and weaknesses of the two approaches and guide users to choose one or the other in practice.
the implementation of the approach and all experimental data are available at .
ii.
m otivating example we use the configurable tool x264 as an example to motivate our approach.
x264 is a command line tool to encode video streams into the h. mpeg a vc format.
in this example we consider 16encoder features of x264 such as parallel encoding on multiple processors or encoding with multiple reference frames.
users can configure x264 by selecting different features to encode a video.
we use the encoding time to indicate the performance of x264 in different configurations.
even such a simple case with only 16features gives rise to 152configurations.
given that we measure the performance of a limited set of configurations as a sample how can we determine the performance of other configurations?
to address this issue previous work on splc onqueror focuses on selecting a specific sample to detect performance relevant feature interactions.
that is following a certain feature coverage criterion splc onqueror selects a fixed set of specific configurations and then measures their performance which is then the input for predicting the performance of other configurations.
two fundamental feature coverage criteria are feature wise andpair wise .
the feature wise measurement quantifies an individual feature s performance influence by calculating the performance delta of two minimal configurations with and without the feature.
the pair wise heuristic selects and measures additionally a specific set of configurations to detect all pair wise feature interactions.
splc onqueror also provides heuristics for the detection of higher order feature interactions.
1a performance distribution denotes the frequency distribution of all performance values in a sample or in the whole population.
important point is that in practice the configurations that we can measure or that we already have are often arbitrarily selected they may not meet any feature coverage criterion.
moreover the number of available configurations may vary and is usually very limited due to the high cost of performance measurement.
for example table i lists a sample of randomly selected configurations of x264 and corresponding performance measurements.
the question is can we predict performance of all other configurations accurately with such a limited number of measurements?
next we formally reduce this question to a non linear regression problem and then we present our approach to address the problem.
iii.
p roblem formalization and reduction in this section we formalize the problem of variabilityaware performance prediction and reduce it to a non linear regression problem.
we represent all features of a configurable software system as a set xof binary decision variables.
if a feature is selected in a configuration then the corresponding variable xis equal to1 and 0otherwise.
we denote the number of all features in a system as n i.e.
x fx1 x2 x ng.
then we represent each configuration of a system as an n tuple assigning value 1or0to each variable in x. for example x264 has features in total as listed in columns x1tox16in table i thus each configuration of x264 is represented by a tuple e.g.
x1 x1 x2 x3 x .
we denote all valid configurations in a system as set x. each configuration xof a system has an actual performance value y. we indicate the actual performance of all configurations of a system as y. suppose that we acquire a set of configurations xs xand measure their actual performance ys together forming sample s. for example table i lists a sample of 16randomly selected configurations ofx264 rows x1tox16 and their performance values the rightmost column .
thus the problem of variability aware performance prediction is how to predict the performance of other unmeasured configurations in xnxsbased on the measured sample s. since we focus on the influence of feature selections on performance we consider all variables in xaspredictors and a configuration s actual performance value yas the response .
in essence we try to find a function to relate the tuple xof predictors to the quantitative response y which is a typical regression problem .
given a sample s the problem is to find a function fthat reveals the correlation between xsand ysand that makes each configuration s predicted performance f x as close as possible to its actual performance y i.e.
f x!rsuch thatx x y2sl y f x is minimal where lis a loss function to penalize errors in prediction.
an assumption of our approach is that the sample sand the whole population exhibit the same or similar correlation between feature selections and performance.
thus we can use302table i asample of 16randomly selected configurations of x and corresponding performance measurements seconds conf.
features perf.
s xix1x2x3x4x5x6x7x8x9x10x11x12x13x14x15x16 yi x1 x2 x3 x4 x5 x6 x7 x8 x9 x10 x11 x12 x13 x14 x15 x16 the function f built on the sample s to predict performance of other configurations in xnxs.
note that we do not presume which features are actually relevant to performance but we consider all features of a system.
moreover we cannot linearly deduce the performance of a configuration from the performance influence of each individual feature in separation due to feature interactions .
therefore the problem of variability aware performance prediction is a non linear regression problem i.e.
the prediction function depends non linearly on one or more predictors .
iv.
v ariability aware performance prediction this section presents our progressive and variability aware approach to performance prediction via statistical learning.
a. overview of the approach figure illustrates our approach which consists of two iterative processes.
the first process predicts performance based on a set of rules.
after configuring a system aand deriving a new previously unmeasured configuration x users want to know the performance yif system auses the configuration x. our approach returns the quantitative prediction i.e.
f x after retrieving the corresponding decision rule for configuration x. each decision rule specifies the predicted performance value of a configuration when the configuration has the same feature selections i.e.
selected and deselected features as the rule defines.
the second process includes performance modeling and validation.
as shown in the dotted box in figure performance modeling starts with a random sample.
we use the sample to build a performance model automatically by statistical learning.
from the performance model we derive a set of decision rules to enable fast direct question answering for performance prediction.
to validate the current performance model users can measure the actual performance of configuration xand then compare its actual performance measurement with its a new configuration xsystem aconfigure decision rules performance modelrandom sampleif system auses configuration x?what is performance y validationmeasurement learning derivingpredictionquantitative figure .
overview of the approach performance prediction.
next configuration xand its actual performance measurement can be reused to expand the sample and then to rebuild the performance model.
thus the approach works in a progressive way and improves performance predictions based on updated samples.
b. cart based performance modeling in this section we explain the process of variability aware performance modeling via statistical learning in detail as illustrated in the dotted box in figure .
as explained in section iii the problem is to find a function fthat predicts the performance value yfor a configuration xbased on a sample s. we use cart to address this problem.
the basic idea is as follows.
we recursively partition the sample into smaller segments until we can fit a simple local prediction model into each segment and finally we organize all the local models into a global prediction model which is represented as a binary decision tree.
figure shows a performance model generated by cart based on the x264 sample in table i. cart starts with the sample sthat contains 16configurations x1 x2 x16and their performance measurements y1 y2 y .
then cart partitions the sample sinto two segments slandsrby303 x1 x2 ... x16 s sl x7 ?
x8 x10 sll lsll x9 x14 x16 slr lslr 268no yes srl x3 ?
x4 x5 srll lsrll x2 x7 x12 srlr lsrlr 508no yessrr x3 ?
x3 x13 x15 srrl lsrrl x1 x6 x11 srrr lsrrr 626yes nosr x15 ?
yes nox14 ?
yesnofigure .
example performance model of x264 generated by cart based on the random sample of table i exhaustively searching over all feature selection variables in x for the best split that minimizes the total prediction errors in its two resulting segments.
for example as shown in figure the first best split for the x264 sample sis the feature selection variable x14 because choosing x14to partition sproduces the minimal total prediction errors in the two resulting segments slandsr.
after partitioning configurations with x14 1go to the left segment sl and configurations with x14 0go to the right segment sr. each segment is partitioned recursively by further splits such as the variables x7 x15 and x3.
for each segment si we use the sample mean of the actual performance measurements as the local prediction model of the segment to make prediction fast si jsijx yj2siyj the local model of each segment identifies the common feature selections the corresponding branch from the first split to the current split and the average performance of the configurations contained in the segment.
for example the local model of the leftmost leaf in figure indicates the common feature selections x14 x7 and the average performance sll y8 y10 s for the two configurations x8 x10.
to penalize the prediction errors in each segment sithat uses the corresponding local model si we adopt the most common and convenient loss function the sum of squared error loss x yj2sil yj si x yj2si yj si thus the best split for each segment siis determined to partition siinto two segments silandsirsuch that x yj2sill yj sil x yj2sirl yj sir is minimal to prevent underfitting the input sample we may expect that each final segment i.e.
leaf is small enough to produce as small prediction errors as possible but excessive partitioning may give rise to overfitting the input sample and thus compromise prediction accuracy for other configurations .3hence determining when is the best time to stop the recursive partitioning process is an empirical activity to tradeoff underfitting and overfitting and it often involves a manual iterative process of parameter tuning .
for our case studies we use two important parameters and define a set of empirically determined parameter settings to automatically control the termination of the recursive partition process as we explain in section v. suppose that there are qleaves in the tree structure of a performance model we organize all the local models of these leaves into a global model as follows f x qx i sii x2si where i x2si is an indicator function to denote if configuration xbelongs to a leaf si.
to determine to which leaf a configuration xbelongs we match the feature selections of a configuration with the corresponding branch in the tree from the first split to a leaf.
for example in the tree shown in figure if a configuration xsatisfies x14 x7 3if an algorithm works poorly even with the existing data then the algorithm underfits the existing data.
if an algorithm works well with the existing data but not with new data then the algorithm overfits the existing data.304which is consistent with the feature selections of the leftmost branch then this configuration falls into the leftmost leaf sll.
the global model for the tree shown in figure is specified as follows f x i x14 x7 i x14 x7 i x14 x15 x3 i x14 x15 x3 i x14 x15 x3 i x14 x15 x3 we can derive a set of decision rules from a global performance model to provide direct performance predictions for users.
each branch in the tree structure of a performance model indicates a decision rule.
for example we can derive the following if then decision rule from the leftmost branch of the tree shown in figure if a configuration satisfies x14 x7 then its predicted performance is 255s.
v. i mplementation we implemented our approach using r .
.
and j ava eclipse .
with jvm .
.
r is a language and environment for statistical computing and graphics.4we used the r packages r attle and rpart to implement cart and to generate the performance models .
we developed a rule generator to parse the built performance models and generate decision rules.
we also experimented with two cart variants random forests andboosting which try to enhance the prediction effects of cart but we observed similar prediction improvements on our evaluated case studies through parameter tuning.
thus we choose a simple solution that uses only cart for our case studies.
as mentioned in section iv b we use two important parameters to control the recursive partitioning process of cart minbucket is the minimum sample size for any leaf of the tree structure of a performance model and minsplit is the minimum sample size for any segment in the tree before the segment is considered for further partitioning.
a segment is not considered for partitioning if its sample size is less than minsplit .
we performed a set of preliminary experimental tests to identify parameter settings that trade off underfitting and overfitting for our case studies.
moreover to implement a fully automated process of performance modeling by cart we aim at setting the two parameters automatically in terms of the size of the input sample i.e.
jsj.
since the size of most of the samples used in our case studies is less than we set the threshold of 100to distinguish random samples of different sizes.
finally we use the following empirically determined parameter settings to achieve automated performance modeling and reasonable prediction accuracy for our case studies if jsj then minbucket bjsj 2candminsplit minbucket ifjsj then minsplit bjsj 2cand minbucket bminsplit 2c the minimum of minbucket is2 and the minimum of minsplit is4.
5bcindicates rounding down i.e.
bxc maxfn2zjn xg.vi.
e valuation we conducted a series of case studies to evaluate our approach.
we aim at answering the following research questions rq how accurate is the approach of variability aware performance prediction?
section vi c rq can the prediction process be progressive?
section vi c rq how fast is the prediction process?
section vi d rq is it possible to make accurate predictions using only small random samples?
section vi e rq what are the strengths and weaknesses of our approach compared to existing techniques?
section vi g a. subject systems we performed our case studies on a publicly available dataset deployed with the splc onqueror tool.6the dataset covers a reasonable spectrum of practical application scenarios.
as shown in table ii there are six existing real world configurable systems with different characteristics different sizes 42thousand to thousand lines of code to millions of configurations different implementation languages c c and j ava and different configuration mechanisms conditional compilation configuration files and command line options .
moreover the dataset contains the whole population of each system i.e.
all configurations of each system and their performance measurements the exception is sql ite for which the dataset contains configurations for prediction modeling and additional random configurations for prediction evaluation .
for each system the performance has been measured using a standard benchmark either delivered by its vendor e.g.
o racle s standard benchmark for b erkeley db or used widely in its application domain e.g.
autobench and httperf for the a pache web server .
b. experimental setup in our experiments the independent variables are the subject system and the size of the input sample.
the prediction fault rate and the time cost of building a performance model are measured as the dependent variables .
the prediction fault rate is the relative difference between the actual performance and the predicted performance i.e.
fr jactual predictedj actual.
correspondingly the prediction accuracy is fr.
to reduce the fluctuations of the dependent variables caused by random generation we performed five repetitions for each combination of the independent variables.
that is for each subject system we repeated five times generating a random sample of a certain size and subsequently measured the dependent variables after applying our approach to the sample.
we took only the average of these measurements for analysis.
we performed all measurements on the same windows machine with intel core i5 cpu .
ghz and gb ram.
6the dataset is available at ii overview of the six subject systems lang .
l anguage loc l ines of code jxj n umber of all valid configurations n n umber of all features m n umber of configurations required by the pair wise heuristic of splc onqueror system domain lang.
loc jxjn m a pache web server c llvm compiler c x264 encoder c b erkeley db database c b erkeley db database j ava sql ite database c for each subject system we randomly selected a certain number of configurations from the whole population as the training sample for prediction modeling and all remaining as the test sample for prediction evaluation.
take the x264 system as an example if we select 16configurations as the training sample then the remaining 136configurations form the test sample.
to assess the effectiveness of our approach working with random samples of different sizes we use four sizes for the training sample of each subject system n 2n 3n and m where nis the number of all features of each system and mis the number of all specific configurations required by the pair wise heuristic of splc onqueror .
we list the concrete values of nandmfor each system in the rightmost two columns in table ii.
we choose size n 2n and 3n because measuring a sample whose size is linear in the number of all features is likely feasible and reasonable in practice given the high cost of performance measurement.
for example the number of even one percent of all configurations of x264 i.e.
is still much more than the triple fold of the number of all features i.e.
.
we choose size m so that we can compare our approach to splc onqueror .
c. experiment on prediction fault rate cart has been proved effective for many non linear regression problems .
moreover most statistical learning techniques can make more accurate predictions when more data are available .
hence the hypotheses of this experiment are as follows.
hypotheses our cart based approach is effective for variability aware performance prediction for rq .
furthermore it works progressively and improves the prediction accuracy when a larger sample is available for rq .
results we measured the prediction fault rate for the six systems listed in table ii and the four sample sizes n 2n 3n and m .
we present the experimental results using different statistical measures.
figure 3a shows the boxplots of the results excluding outliers such that other statistical measures such as the median and quartiles can be shown clearly.7figure 3b includes all outliers.
table iii column 7a boxplot represents statistical data on a plot in which a rectangle is drawn to represent the second and third quartiles usually with a vertical line inside to indicate the median value.
the lower and upper quartiles are shown as horizontal lines either side of the rectangle.
an outlier is one that appears to deviate markedly from other members of the sample in which it occurs.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
fault rate x100 n 2n 3n m a excluding outliers fault rate x100 n 2n 3n m b including outliers figure .
boxplots of the prediction fault rates for the six systems 1to6 listed in table ii and the four sample sizes ntomlisted in table ii fault rate lists the mean and standard deviation of the prediction fault rate for each system and each sample size.
as shown in figure and table iii for any statistical measure the mean standard deviation median or outlier we observe a robust decreasing trend of the prediction fault rate when the sample size increases from ntomfor each system.8as listed in table iii based on a random sample of sizen column fault rate n the fault rate is or 8note that mdepends on the number of features and on the configuration constraints among features in a case study.
in most cases mis greater than 3n the exception is b erkeley db j ava where m and3n .306table iii mean standard deviation of the prediction fault rate and time cost ms for the six systems 1to6listed in table ii and the four sample sizes ntomlisted in table ii fault rate time cost ms n 2n 3n m n 2n 3n m .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
less for three subject systems llvm b erkeley db j ava and sql ite in rows and .
based on a random sample of size m we achieve a mean prediction fault rate of on average for all six subject systems i.e.
the average of all mean prediction fault rates listed in column fault rate m .
discussion an average prediction accuracy of on small random samples of size mfor six real world configurable systems demonstrates the effectiveness of our approach for variability aware performance prediction.
for three subject systems the approach even produces a prediction accuracy of92 or higher based on small random samples of size n. moreover our approach does show a robust increasing trend of prediction accuracy with the increasing sample size.
thus the experiment confirms that our approach can work progressively with random samples of any user defined size i.e.
nor larger and improve the prediction accuracy when more data are available.
d. experiment on time cost for rq the time consumed by the prediction process of our approach mainly stems from performance modeling using cart.
once the performance model is built as explained in section iv deriving a decision rule and providing the prediction result for users are instantaneous.
furthermore as cart has been widely used in statistics and data mining applications and it has been shown fast and reliable the hypothesis of this experiment is as follows.
hypothesis the time of building a performance model by cart is reasonable.
results we measured the time of building a performance model in the same experimental context as the experiment of section vi c. the results are listed in table iii column time cost .
for five of the six systems the time of building a performance model on any random sample of size fromntomis approximately 42milliseconds ms .
only for sql iteand the sample size m the time cost reaches a high of 90ms which is still a reasonable amount of time.
discussion although we perform cart with an exhaustive search over all feature selection variables for the best split that minimizes the total prediction errors as explained in section iv b the constant local model defined in equation makes the search process fast because there is no complicated calculation for the total prediction errors defined in equation .moreover the time of at most 90ms needed for all six subject systems and for any sample size from ntomdemonstrates that our approach is highly efficient for variability aware performance prediction.
e. comparative analysis of performance distributions the previous experiments demonstrate the effectiveness of our approach however we still want to give evidence why the approach works with small random samples for rq .
since the approach depends on cart to address a non linear regression problem a general explanation from the statisticallearning theory is that cart works well when the problem it addresses or the data it evaluates does fit the regressive pattern it builds .
moreover as explained in section iv b cart builds a tree like prediction model that recursively partitions a sample and renders the total prediction errors in each partition minimal this way the prediction model always fits the sample well.
if the sample can represent the whole population or reflect the important characteristics of the whole population then the prediction model built on the sample also fits the whole population well and makes accurate predictions.
since our prediction targets numeric performance values the performance distribution is an important characteristic for performance prediction.
thus we conducted a comparative analysis of performance distributions between random samples and the corresponding whole populations guided by the following hypothesis.
hypothesis our approach works well with a small random sample when the sample has a similar performance distribution as the whole population.
results for each subject system we collected all the random samples generated in the previous experiments.
then we visualized the average performance distribution for each sample size from ntom to mitigate the influence of a specific performance distribution of a certain random sample.
furthermore we visualized the performance distribution of the whole population of each system to be able to compare it to the performance distribution of each random sample of size from ntom.
due to the space limit we present the experimental results for only one subject system here.9figure shows the his9the experimental results of all six subject systems 1to6listed in table ii are available in a technical report at of the performance distributions for the four sample sizes ntom and the whole population of x264.
as shown in figure 4e the performance distribution of the whole population of x264 is roughly a distribution with two peaks.
the performance distribution of the random sample of sizen figure 4a identifies the two peaks but misses the correct locations of these peaks.
the performance distributions for the sample size from 2n figure 4b 3n figure 4c to m figure 4d gradually move and form the two peaks approximate to the precise locations as shown in figure 4e.
with such a gradual process that generates a more similar performance distribution as the whole population the prediction fault rate shows a robust decreasing trend from to when the sample size increases from n 2n 3ntom.
similarly for each of the other five subject systems the random sample of size malways exhibits a very similar performance distribution as the whole population.
for the three systems llvm b erkeley db j ava and sql ite with or higher prediction accuracy based on a random sample of size n a similar performance distribution as the whole population can be found on the random sample of size n. discussion the comparative analysis of performance distributions between random samples and the whole populations reveals that our approach works well with a small random sample when the sample has a similar performance distribution as the whole population.
in fact we found explicit evidence that a sample does reflect some important characteristics of the whole population when we can produce accurate predictions based on it.
however we are aware that the performance distribution may be just one of the relevant characteristics for performance prediction.
these characteristics may involve for example the number and dispersion of distinct values as well as the feature coverage.
a quantitative study on the similarity between a random sample and the whole population involving more characteristics for performance prediction shall be conducted in future work.
f .
threats to validity to enhance internal validity we performed automated random sampling avoiding misleading effects of specific selected training samples and test samples.
we randomly selected samples of four sizes ntom respectively from the whole population of each subject system as the training sample and all of the rest as the test sample.
we repeated each random sampling five times with freshly generated training samples and test samples of the same size.
the exception is the test sample of sql ite in which the original authors could not measure all valid configurations in reasonable time thus to mitigate the possible effects of missing some important configurations they sampled additional random configurations for prediction evaluation .
10a histogram provides a quick and intuitive visualization of the distribution of the data it consists of two parts the vertical bars each of which displays the frequency of each value range and the density estimate curve which shows a more accurate display of the distribution of the data.
a random sample of size n b random sample of size 2n c random sample of size 3n d random sample of size m e whole population figure .
histograms of the performance distributions of the random samples of four sizes ntomlisted in table ii and of the whole population of x264 x axis performance seconds y axis relative frequency to automate the process of performance modeling by cart we use two important parameters minbucket and minsplit and fix others provided by the r packages to control the recursive partitioning process of cart.
for each case308study we followed the same parameter settings to generate the performance models automatically.
we cannot guarantee that the prediction fault rate and the time cost of performance modeling obtained in our experiments depend on certain shapes of the performance models built by cart.
however to avoid misleading effects of specially shaped performance models we generated all performance models automatically repeated each measurement the prediction fault rate or the time cost for each system and each sample size five times and took only the average of these measurements for analysis.
to increase external validity we used a public dataset with six systems spanning different domains with different sizes different configuration mechanisms and different implementation languages.
all systems have been deployed and used in real world scenarios.
moreover the performance is measured by standard benchmarks in the respective application domain.
however we are aware that the results of our experiments are not automatically transferable to all other configurable systems but we are confident that we controlled this threat sufficiently.
g. strengths and weaknesses of the approach to answer rq we compared our approach to splc onqueror a most recent approach to performance prediction for configurable software systems .
we summarize the strengths and weaknesses of the two approaches which guides users to choose one or the other in practice.
prediction fault rate in our experimental setup n is the number of all features of a system and mis the number of configurations required by the pair wise heuristic of splc onqueror .
moreover nis similar to the number of configurations required by the feature wise measurement of splc onqueror .
thus we can compare the two approaches according to these sample sizes.
table iv lists the prediction fault rates produced by the two approaches when we apply them to the random or specific samples of size nandm for the six subject systems listed in table ii.
our approach produces a prediction fault rate of or less based on a random sample of size nfor three systems rows and in table iv and it produces an average of6 prediction fault rate for all six systems when the sample size reaches m. by comparison splc onqueror produces a prediction fault rate of using the feature wise measurement on a specific sample of size nfor two systems rows and and it produces an average of prediction fault rate using the pair wise heuristic on a specific sample of sizemfor all six systems.
when other heuristics for higherorder feature interactions are considered splc onqueror can produce an average of prediction fault rate for all six systems not listed in table iv which is more accurate than our approach but requires additional measurements.
prediction effort the higher prediction accuracy of splc onqueror comes at a cost splc onqueror needs additional effort to select specific configurations and to detect performance relevant feature interactions.
when we encounter a large scale system with a great number of features suchtable iv mean standard deviation of the prediction fault rate for the six systems 1to6listed in table ii and the two sample sizes nandmlisted in table ii using our approach and splc onqueror the number in bold indicates the best case in each row our approach splconqueror n m n m .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
avg.
.
.
.
.
.
.
.
.
effort can be quite expensive .
in contrast our approach supports random sampling and progressive performance prediction which makes it more pragmatic.
that is our approach can work with random samples and make more accurate predictions progressively when more data are available.
furthermore as shown in section vi d our approach is highly efficient and the prediction process often takes only little time.
sample dependence splc onqueror works because it relies on specific samples selected by heuristics to detect performance relevant feature interactions our approach works because the evaluated dataset fits well in the non linear regression model we use and the random sample we use reflects the important characteristics of the whole population.
as demonstrated in section vi e our approach works well with a small random sample provided it has a similar performance distribution as the whole population.
however if such a random sample happens to be skewed to some undesirable characteristics the prediction effects of our approach might be affected.
for example users may prefer some specific configurations with certain features and always miss some other features based on such a sample our approach may not produce accurate predictions for the configurations selecting the missed features.
application scope a clear advantage of a regression technique is that it can support not only boolean e.g.
a selected or deselected feature but also numeric feature selections e.g.
the heap size or the cpu speed which makes our approach applicable in wider domains.
in contrast the existing techniques for feature interaction detection support only boolean feature selections.
summary both approaches have strengths and weaknesses.
we expect that a combination of both approaches is beneficial to further increase prediction accuracy and reduce prediction effort in wider application domains e.g.
by combining heuristics used in splc onqueror to identify suitable samples for cart .
in particular we provide the following guidance for users to choose between the two approaches in practice.
if a software system has a small number of features such that the cost of detecting feature interactions is 11an exploratory experiment on missing features and skewed configurations is available in a technical report at users shall choose splc onqueror due to its higher prediction accuracy otherwise our proposed approach is superior due to its reduced prediction effort and reasonable prediction accuracy.
if there is already a sample available one has to check whether the sample satisfies certain featurecoverage criteria before using splc onqueror whereas one can produce predictions directly based on the sample using our approach.
vii.
r elated work a. model based prediction cart and its variants such as random forests and boosting have been widely used in statistics and data mining because cart s algorithm is fast and reliable and its tree structure can provide insight into the relevant input variables for prediction .
thereska et al.
proposed a practical performance model based on cart for interactive client applications such as microsoft office and mozilla.
they focused on a range of deployment parameters from the users application environment such as cpu speed and memory size instead we consider the configuration options of a software system.
moreover our approach targets all kinds of configurable software systems as long as the valid configurations can be derived.
westermann et al.
presented an approach to the automated improvement of performance prediction functions by three measurement point selection strategies based on the prediction accuracy.
they constructed the prediction functions by statistical inference techniques including cart.
this approach however assumes that all input variables of the prediction function are already relevant to performance while our approach does not have such a restriction but considers all features of a software system.
even though the above studies have demonstrated the effects of cart on performance prediction for different case studies they did not explicitly provide evidence for why cart does or does not work.
we found that our approach works well with a small random sample when the sample has a similar performance distribution as the whole population.
happe et al.
proposed a compositional reasoning approach based on component specifications with resource demands and predicted execution time.
their approach is restricted to component based systems whereas our approach is applicable to all configurable systems once their configurable options are abstracted as features.
tawhid and petriu presented a model driven approach to deriving a performance model from an extended feature model with performance analysis information.
the approach requires detailed up front knowledge from a domain specific performance analysis which makes tuning prediction for accuracy difficult.
our approach avoids these problems by directly working with performance measurements.
ramirez and cheng presented an approach that leverages goal based models to facilitate the automatic derivation of utility functions at the requirements level our approach works at the level of actual program variants.b.
measurement based prediction a most recent measurement based prediction technique is splc onqueror .
we have compared it to our approach and discussed the strengths and weaknesses of both approaches in section vi g. sincero et al.
used existing configurations and measurements to predict a configuration s non functional properties.
they designed the feedback approach to find the correlation between feature selections and measurements and to provide qualitative information about how a feature influences a nonfunctional property during the configuration process.
in contrast to our approach their approach does not actually predict a performance value quantitatively.
chen et al.
combined benchmarking and profiling to predict the performance of component based applications.
in contrast our approach correlates performance measurements with configurations and can work with any set of configurations measured by simulation or by monitoring in the field.
viii.
c onclusion we proposed a progressive and variability aware approach to performance prediction for configurable software systems based on random samples.
the approach uses the statistical learning technique cart to build an explicit performance model that represents the correlation between feature selections and performance.
we demonstrated the feasibility and effectiveness of our approach on six real world systems spanning different domains implementation languages and configuration mechanisms.
our empirical results show that the approach produces a prediction accuracy of on average based on small random samples.
moreover our approach shows a robust increasing trend of prediction accuracy as the sample size increases.
a comparative analysis of performance distributions revealed that our approach works well when the corresponding sample has a similar performance distribution as the whole population.
we compared our approach to a stateof the art technique called splc onqueror and explored the strengths and weaknesses of the two approaches to guide users to choose one or the other in practice.
our approach has the potential of wide application to help users make trade offs between feature selections and performance and to guide the configuration process .
in future work we aim at performing systematic parameter tuning for cart and trying other regression techniques e.g.
support vector machines .
moreover we aim at quantifying the similarity between a sample and the whole population involving several characteristics for performance prediction.
in addition we will explore the potential of using our approach for configuration optimization test generation and bug prediction .