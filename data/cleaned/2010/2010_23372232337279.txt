bugredux reproducing field failures for in house debugging wei jin and alessandro orso georgia institute of technology weijin orso gatech.edu abstract a recent survey conducted among developers of the apache eclipse and mozilla projects showed that the ability to recreate field failures is considered of fundamental importance when investigating bug reports.
unfortunately the information typically contained in a bug report such as memory dumps or call stacks is usually insufficient for recreating the problem.
even more advanced approaches for gathering field data and help in house debugging tend to collect either too little information and be ineffective or too much information and be inefficient.
to address these issues we present b ugredux a novel general approach for in house debugging of field failures.
b ugredux aims to synthesize using execution data collected in the field executions that mimic the observed field failures.
we define several instances of bugredux that collect different types of execution data and perform through an empirical study a cost benefit analysis of the approach and its variations.
in the study we apply bugredux to failures of real world programs.
our results are promising in that they show that it is possible to synthesize in house executions that reproduce failures observed in the field using a suitable set of execution data.
i. i ntroduction quality assurance activities such as software testing and analysis are notoriously difficult expensive and timeconsuming.
as a result software products are typically released with faults or missing functionality.
the characteristics of modern software are making the situation even worse.
because of the dynamic nature configurability and portability of today s software deployed applications may behave very differently in house and in the field.
in some cases these different behaviors may be totally legitimate behaviors that simply were not observed during in house testing.
in other cases however such behaviors may be anomalous and result in field failures failures of the software that occur after deployment while the software is running on user machines.
field failures are both difficult to foresee and difficult if not impossible to reproduce outside the time and place in which they occurred.
in fact a recent survey among developers of the apache eclipse and mozilla projects revealed that most developers consider information on how to reproduce failures e.g.
stack traces steps to follow and ideally even inputs to be the most valuable and difficult to obtain piece of information in a bug report .
this pressing need is demonstrated by the emergence in the last decade of several reporting systems that collect information e.g.
stack traces and register dumps when a program crashesand send it back to the software producer e.g.
.
although useful the information collected by these systems is often too limited to allow for reproducing a failure and is typically used to identify correlations among different crash reports or among crash reports and known failures.
researchers have also investigated more sophisticated techniques for capturing data from deployed applications that can help debugging e.g.
.
among these techniques some collect only limited amounts of information e.g.
sampled branch profiles for cbi .
these techniques have the advantage of collecting types of data that are unlikely to be sensitive which makes them more likely to be accepted by the user community.
moreover given the amount of information collected it is conceivable for users to manually inspect the information before it is sent to developers.
unfortunately subsequent research has shown that the usefulness of the information collected for debugging increases when more and more detailed data is collected.
researchers have therefore defined novel techniques that gather a wide spectrum of richer data ranging from path profiles to complete execution recordings e.g.
.
complete execution recordings in particular can address the issue of reproducibility of field failures.
user executions however have the fundamental drawbacks that they can be expensive to collect and are bound to contain sensitive data.
while the former issue can be alleviated with suitable engineering e.g.
the latter issue would make the use of these techniques in the field problematic.
given the sheer amount of data collected users would not be able to manually check the data before they are sent to developers and would therefore be unlikely to agree on the collection of such data.
although some techniques exist whose goal is to sanitize or anonymize collected data they are either defined for a different goal and would thus eliminate sensitive data only by chance e.g.
or are still in their early phase of development and in need of a more thorough evaluation e.g.
.
the overall goal of this work is to address these limitations of existing techniques by developing novel approaches for reproducing field failures in house without imposing too much overhead on the users and without violating the users privacy.
more precisely we aim to develop a general technique that can synthesize given a program p a field execution eofpthat results in a failure f and a set of978 .
c ieee icse zurich switzerland execution data dfore an in house execution e primeas follows.
first e primeshould result in a failure f primethat is analogous to f that is f primehas the same observable behavior of f. iff is the violation of an assertion at a given location in p for instance f primeshould violate the same assertion at the same point.
second e primeshould be an actual execution of p that is the approach should be sound and generate an actual input that when provided to p results in e prime.third the approach should be able to generate e primeusing only pandd without the need for any additional information.
finally dshould not contain sensitive data and should be collectable with low overhead on e. as a first step towards our goal in this paper we present bugredux a general technique for collecting different kinds of execution data and using the collected data to synthesize in house executions that can reproduce failures observed in the field.
intuitively b ugredux can be seen as a general framework parameterized along two dimensions the kind of execution data dcollected and the technique used for synthesizing execution e prime.
we present four variations or instances of b ugredux that all share the same synthesis technique i.e.
symbolic execution but differ in the kind of execution data they use.
specifically we consider four types of increasingly rich execution data points of failure call stacks call sequences and complete execution traces.
we also present an empirical investigation in which we assess the tradeoffs that characterize the variations of b ugredux with respect to the cost of the data collection in terms of space and time overhead and indirectly likelihood to contain sensitive data and the ease of synthesizing a failing execution starting from such data.
in the evaluation we used an implementation of b ugredux developed for the c language and applied it to failures of realworld programs.
for each failure we collected the four different types of execution data measured the overhead of the collection and tried to synthesize an execution that reproduced the failure using such data.
interestingly our results show that the richest data beside being the most expensive to collect and the most problematic in terms of potential privacy violation is not necessarily the most useful when used for synthesizing executions.
our results also confirm that at least for the cases we considered information that is traditionally collected by crash report systems such as the call stack at the point of failure is typically not enough for recreating field failures.
for the current incarnation of b ugredux we found that the best option in terms of cost benefit ratio is the use of call sequences.
as our study shows using call sequence data b ugredux was able to recreate all of the failures considered while imposing an acceptable time and space overhead.
we believe that these results albeit preliminary in nature are encouraging and motivate further research in this direction.
in fact as we discuss in the final part of the paper we have already identified several opportunities for further reducing the cost of the data collection while maintaining the same ability of recreating field failures.
this paper provides the following novel contributions a general approach for collecting execution data in the field and using the data to synthesize executions that reproduce field failures.
the instantiation of the approach for four different kinds of execution data and one execution synthesis technique and its implementation in a freely available prototype tool see orso software bugredux.html .
an empirical study that performs a cost benefit analysis of the approach and its variations in terms of data collection costs and ability to synthesize failing executions.
the rest of the paper is organized as follows.
section ii introduces our approach.
section iii presents our empirical investigation and discusses our findings.
section iv puts our research in context by discussing related work.
finally section v concludes the paper and sketches our future research directions.
ii.
o urapproach for recreating field failures as we stated in the introduction our overall goal is to recreate field failures faithfully i.e.
in a way that allows for debugging them by using execution data collected in the field that can be gathered without imposing too much space and time overhead on field executions.
a first important step towards defining a technique for reproducing field failures in house is to understand the usefulness of different kinds of execution data in this context.
to this end we defined a general approach for synthesizing executions that mimic executions that resulted in field failures and reproduce such failures.
we instantiated several variants of our approach that differ in the kind of execution data they use and studied the effectiveness of these different variants.
in the rest of the paper we discuss our approach and our empirical investigation.
note that for space reasons we do not provide here background information on some basic program analysis and symbolic execution concepts used in the discussion of our approach.
such background information together with additional details and a motivating example is available in the companion technical report for this paper .
a. overview our general approach is called b ugredux .
intuitively bugredux operates by collecting different kinds of execution data and using the collected data to synthesize in house executions that reproduce failures observed in the field.
figure provides a high level overview of b ugredux and of the scenario we target.
as the figure shows b ugredux consists of two main components.
the first one is the instrumenter which takes475softwaredeveloper instrumenter application instrumentedapplication crash report execution data analyzer bugredux test input debuggingtool softwaretester figure .
intuitive high level view of b ugredux .
as input an application provided by a software developer and generates an instrumented application that can collect execution data and add such execution data to crash reports from the field.
the second component is the analyzer which takes as input a crash report and tries to generate a test input that when provided to the application results in the same failure that was observed in the field.
a software tester can then use the generated input to recreate and debug the field failure.
this general approach can be defined in different ways depending on the kind of execution data collected and on the technique used for synthesizing execution.
b. instrumenter and analyzer components instrumentation is a well assessed technology so we do not discuss this part of the approach further.
it suffices to say that b ugredux adds probes to the original program that when triggered at runtime generate the execution data of interest.
conversely the analyzer is the core part of the approach and the most challenging to develop.
figure which provides a more detailed view of the analysis component of bugredux puts the problem in context and lets us discuss how we addressed this challenge.
as the figure shows the inputs to the analyzer are an application program p whose execution eproduces failure fthat we want to reproduce and a crash report cforf.
the goal of the analyzer is to generate a test input that would result in an execution e prime that mimics eand would fail in the same way.
given crash report c the input generator would analyze program pand try to generate such test input.
the exact definition of mimicking depends on the amount of information about the failing execution ethat is available.
if only the point of failure were known for instance e primewould mimic eif it reaches such point.
conversely if a complete trace of the failing execution were available e primewould have not only to reach the point of failure but also to follow the same path as e. this concept of mimicking is defined within the input generator which receives the execution data in the form of a sequence of goals or statements to be reachedand tries to generate executions that reach such goals in the right order.
if successful the input generator would generate a candidate input and the oracle would check whether that input actually fails in the same way as e. in theory any automated input generation technique could be used in this context as long as it can be guided towards a goal e.g.
the point of failure the entry point of a function on the failure s call stack or a branch within the program .
in this work we decided to use an approach based on symbolic execution .
specifically we use a symbolic execution algorithm customized with an ad hoc search strategy that leverages the execution data available expressed as a set of goals.
our algorithm generateinputs is shown in algorithm .
generateinputs takes as input icfg the interprocedural control flow graph icfg for program p and goals list an ordered list of statements to be reached during the execution.
we discuss the exact content of goals listin section ii c. initially generateinputs performs some initializations lines .
first it initializes sym state 0with the initial symbolic state where all inputs are marked as symbolic.
then it initializes states set a set that will be used to store search states during the execution with the initial search state.
entries in states setare quadruples angbracketleftcl pc ss goal angbracketright where clis a code location pcthe path condition pc for the path followed to reach location cl ssthe symbolic state right before cl and goal the current target for this state used to enforce the order in which goals are reached .
the initial search state consists of the entry of the program for cl pctrue symbolic state sym state and goal g0.
next the algorithm assigns to curr goal the first goal from goals list.
the algorithm then enters its main loop.
at the beginning of each loop iteration generateinputs invokes algorithm selnextstate shown in algorithm .
selnextstate looks for the most promising state to explore in states set.
at the first invocation of selnextstate only the initial state476application test input candidate inputanalyzeroracleinput generator point of failurecall stackadditionalexecution datacrash report execution data figure .
the analysis component of b ugredux .
is in the states set.
the number of states will increase in subsequent invocations when more of the program has been explored symbolically.
selnextstate selects states based on the minimum distance mindis computed in terms of number of statements in the icfg between each state s clandcurr goal.
to avoid selecting states that have not reached goals that precede curr goal ingoals list selnextstate only considers states whose target is curr goal line in algorithm .
if none of these states can reach curr goal i.e.
there s no path between the state s cland curr goal in the icfg selnextstate returns null to generateinputs.
otherwise the selected state is returned line in algorithm .
when generateinputs receives the candidate state from selnextstate it first checks whether the returned state is null which means that no state in states setwith target curr goal can actually reach such target.
if so generateinputs backtracks by updating curr goal to the previous goal in the goals listand looking for another path that can reach that goal line .
conversely if curr state is not null generateinputs continues the execution of its main loop.
ifcurr state s code location corresponds to curr goal generateinputs updates both global goal curr goal and local goal curr state.goal to the next goal in goals list lines .
it then continues the symbolic execution.
if the last goal gnis reached the algorithm stops the symbolic execution feeds the current pc to the smt solver and asks the solver to find a solution for the pc line .
if a solution is not found the generation of the candidate input is deemed unsuccessful.
if curr state s code location is notcurr goal but another goal in goal list the algorithm removes curr state from state setand goes back to the beginning of the main loop lines .
it does so to avoid that the execution reaches the goals in the goal list in a different order from the one observed in the failing execution.
if curr state s code location is a conditional statement pred that involves symbolic values the algorithm performs one execution step along both branches that is it updates states current location and path condition checksthe feasibility of both branches using the smt solver and removes or does not add infeasible states from states set lines .
if the smt solver did not provide an answer for pc the algorithm would consider the corresponding state feasible and continue.
finally if curr state s code location is any statement other than a conditional the algorithm suitably updates the symbolic state and the current location ofstates set lines .
the algorithm terminates when either there are no more states to explore i.e.
it tries to backtrace from g0 line or a candidate input is successfully generated line .
in the former case our algorithm fails to find an input that can mimic the observed execution.
in the latter case conversely the algorithm successfully produces such input.
in summary our symbolic execution technique has two key aspects.
first it uses the execution data from the field to identify a set of intermediate goals that can guide the exploration of the solution space.
second it uses a heuristic based on distance to select which states to consider first when trying to reach an intermediate goal during the exploration.
in theory the more data i.e.
number of intermediate goals available the more directed the search and the higher the likelihood of synthesizing a suitable execution.
on the other hand collecting too much data can have negative consequences in terms of overhead and introduce privacy issues.
to study this tradeoff we define several variants of our approach that differ on the kind of execution data they consider.
we describe these variants in the next section.
c. execution data in selecting the execution data to consider we aimed to cover a broad spectrum of possibilities.
to this end we selected four kinds of data characterizing a failure the point of failure pof the call stack at the time of failure the sequence of calls performed in the failing execution and a complete execution trace.
these types of data are representative of scenarios that go from knowing as little as possible about the failing execution to knowing almost everything about it.
in addition pofs and call stacks are types477algorithm generateinputs input icfg icfg for program p goals list an ordered list of statements g0 ...g n output input f candidate input for synthesized run 1begin sym state initial symbolic values of program inputs states set icfg.entry true sym state g0 curr goal g0 while true do curr state null while curr state null do curr state selnextstate icfg states set curr goal ifcurr state null then ifcurr goal negationslash g0then curr goal previous goal in goals list continue else return null end end end ifcurr state.cl curr goal then ifcurr goal gnthen input f solver.getsol curr state.pc ifinput fis found then return input f else remove curr state states set continue end else curr goal next target in goals list curr state.goal curr goal end else ifcurr state.cl goal list then remove curr state states set continue end end ifcurr state.cl is a conditional statement then curr state.pc addconstr curr state.pc pred true curr state.cl getsucc curr state.cl true ifsolver.checksat curr state.pc false then remove curr state states set end false pc addconstr curr state.pc pred false false cl getsucc curr state.cl false ifsolver.checksat curr state.pc negationslash false then new state false cl false pc curr state.ss curr state.goal insert new state state set end else curr state.ss symeval curr state.ss curr state.cl curr state.cl getsucc curr state.cl end end 54end of data that are very commonly available for crashes as they are normally included in crash reports.
call sequences and execution traces on the other hand are not normally available and represent data that if they were shown to be useful would require changes in the way programs are monitored and crash reports are generated.
for each of these four types of execution data we instantiated a variation of b ugredux that collected and used thatalgorithm selnextstate input icfg icfg for program p states set set of symbolic states curr goal next goal output retstate candidate state for exploration 1begin mindis retstate null foreach state i states setdo ifstate i.goal curr goal then ifstate i.loc can reach curr goal inicfg then nd shortest distance from state i.loc to curr goal inicfg ifnd mindis then mindis nd retstate state i end end end end return retstate 16end type of data.
as far as data collection is concerned the first two types of execution data do not require any modification of the program being monitored as they can be extracted them from existing crash reports.
the other two types of data can be collected using well understood program instrumentation techniques.
to collect call sequences b ugredux instruments all call sites and entry points these latter to account for the possible presence of function pointers whereas to collect execution traces it instrument all branches.
customizing b ugredux so that it uses the different data is also relatively straightforward as it amounts to suitably generating the goals listset to be passed to b ugredux s input generator.
for pof goals listwould contain a single entry the pof itself.
for a failure s call stack there would be an entry in the set for each function on the stack corresponding to the first statement of the function plus an additional entry for the pof.
call sequences would result in a goals list that contains an entry for each call corresponding to the call statement.
also in this case there would be an additional final entry for the pof.
finally thegoals list for an execution trace would consist of an entry per branch corresponding to the statements that is the destination of the branch and the usual entry for the pof.
in the next section we discuss how we used these four variants of b ugredux to study the tradeoffs involved with the use of different kinds of information and assess the general usefulness of the proposed approach.
iii.
e mpirical investigation we investigated the following research questions rq1 can b ugredux synthesize executions that are able to reproduce field failures?
rq2 if so which types of execution data provide the best tradeoffs in terms of cost benefit?478to address these questions we implemented the four variants of b ugredux discussed in the previous section and applied them to a set of real world programs.
a.bugredux implementation our implementation of b ugredux works on c programs and consists of three modules that correspond to the three components shown in our high level view of the approach see figures and instrumenter input generator and oracle.
b ugredux s instrumenter performs static instrumentation i.e.
probes are added to the code at compile time by leveraging the llvm compiler infrastructure http llvm.org .
the input generator in b ugredux is built on top of klee a symbolic execution engine for c programs.
we implemented algorithms and as a custom search strategy for klee and also made a few modifications to klee s code.
finally b ugredux s oracle module is implemented as a perl script that operates as follows it takes as input program p an input iforp and a crash report ccorresponding to failure f it runs pagainst iand collects any crash report generated as a result of the execution and if either no report is generated or the call stack and pof in the generated report do not match those inc it reports that the approach failed whereas it reports a success otherwise.
b. programs and faults considered to investigate our research questions in a real istic setting we used a set of real non trivial programs that contained one or more faults and had test cases that could reveal such faults.
we considered programs from three public repositories that have been used extensively in previous research sir bugbench and exploit db .
specifically we selected three programs from sir two from bugbench and nine from exploit db.
table i shows the relevant information about each program name repository from which it was downloaded size and number of faults it contains.
as the table shows the program sizes range from .
kloc to kloc and each program contains one or two faults.
the faults in the bugbench and exploit db programs are real faults whereas the ones in the programs from sir are seeded.
we selected these programs because they have been used in previous research and because of the representativeness of their faults.
the faults in exploit db and bugbench are real faults mostly discovered by users in the field whereas the faults in sir are seeded by researchers but are carefully designed to simulate real faults.
we excluded from our study three programs from sir and four from bugbench because the version of klee we used could not handle some of the constructs in these programs e.g.
complex interactions with the environment and network inputs .
as far as faults are concerned we selected faults that caused a program crash rather thantable i subject programs used in our study .
name repository description size kloc faults sed sir stream editor grep sir pattern matching utility gzip sir compression utility ncompress bugbench de compression utility polymorph bugbench file system unixier aeon exploit db mail relay agent glftpd exploit db ftp server htget exploit db file grabber socat exploit db multipurpose relay tipxd exploit db ipx tunneling daemon aspell exploit db spell checker .
exim exploit db message transfer agent rsync exploit db file synchronizer xmail exploit db email server just generating an incorrect result.
this choice was made for convenience and to minimize experimental bias with crashes failures can be objectively identified and do not require the manual encoding of the failure condition as an assertion.
we also performed a preliminary check on the programs and faults that we selected by feeding them to an unmodified version of klee and letting it run for hours.
the goal of this check was to assess whether these faults could have been discovered by a technique that blindly tries to explore as much of the programs as possible.
if so this would be an indication that the faults are too easy to reveal to be good candidates for our study.
the unmodified klee was unable to reveal the faults in the programs.
it is worth noting that we did not use the benchmarks used in reference because they did not pass this check all of those failures could also be recreated through plain unguided symbolic execution as also shown in reference .
moreover the benchmarks we selected are more representative as programs are larger and out of faults are real faults reported by users rather than faults found in house by klee.
c. experimental setup in order to collect the data needed for our investigation we proceeded as follows.
to simulate the occurrence of field failures we used the test cases distributed with our subject programs as proxies for real users.
for each fault fconsidered we ran the test cases until a test case tf failed and generated a program crash we associated tfto fas its failing input.
we then reran all the failing inputs on all the corresponding faulty programs three times.
the first time we ran them on the unmodified programs the second time on the programs instrumented by b ugredux to collect call sequences and the third time on the programs instrumented by b ugredux to collect complete execution traces.
for each such execution we measured the duration of the execution and the size of the execution data generated.
with this information available we used the four variants of b ugredux to synthesize a failing execution starting479from a suitable set of goals i.e.
pof call stack at the time of failure call sequence and complete execution trace .
for each run of b ugredux we recorded whether the generation was successful i.e.
whether a candidate input was generated at all and how long it took.
we set a timeout of hours for the generation after which we marked the run as unsuccessful.
we also recorded whether the candidate input if one was generated could reproduce the original failure according to b ugredux s oracle.
d. results and discussion this section presents the results of our empirical study and discusses the implication of the results in terms of our two research questions.
we present the results using two tables where the first table contains the data related to the cost of the approach i.e.
the time and space overhead imposed by bugredux and the second table shows the data about the effectiveness of the approach i.e.
whether b ugredux was able to synthesize an execution and whether such execution could be used to reproduce an observed failure .
these two tables present the results for each of the failing executions considered identified by the name of the failing program possibly followed by a fault id and for each of the variants of b ugredux identified by the kind of execution data on which it operates.
table ii shows the time and space overhead imposed by bugredux on the subjects for each of the four types of execution data collected.
time overhead is measured as the percentage increase of the running time due to instrumentation whereas space overhead is measured as the size of the different kinds of execution data collected by b ugredux .
we discuss the two types of overheads separately.
time overhead.
because pofs and call stacks are collected by the runtime system at the moment of the failure and do not require any additional instrumentation collecting them incurs no overhead.
the situation is different for call sequences and complete traces which both require b ugredux to instrument the programs see section ii c .
as expected the overhead imposed by complete trace collection is almost an order of magnitude higher than that for call sequences.
we also observe that the overhead for collecting call sequences depends on program size and execution length.
to correctly interpret these results it is important to consider that this data was collected with a naive instrumentation that writes events to the log as soon as they occur the use of caching techniques could decrease the overhead dramatically.
because the goal of this initial investigation was more exploratory and the numbers are acceptable we left optimizations for future work.
moreover record replay techniques e.g.
could be used to efficiently record field executions and collect execution data while replaying offline and when free cycles are available on the user machines.table ii time and space kb overhead imposed by bugredux .
name pof call stack call sequence complete trace time space time space time space time space sed.fault1 .
.
.
.
.
.
sed.fault2 .
.
.
.
.
.
grep .
.
.
.
gzip.fault1 .
.
.
gzip.fault2 .
.
.
.
ncompress .
.
.
.
polymorph .
.
.
.
aeon .
glftpd .
.
.
htget .
.
.
socat .
.
.
tipxd .
.
.
aspell .
.
.
.
rsync .
xmail .
.
.
.
exim .
.
.
.
space overhead.
the data size for pofs and call stacks is the same because our current implementation of b ugredux extracts both of them from the crash reports generated by the runtime system.
we therefore report the size of the crash reports for these two types of data.
also in this case the size of the complete trace data is at least an order of magnitude larger than that of the call sequence data and in some cases the difference is even more extreme.
for instance in the case of gzip.fault2 the reason for the large gap is that the number of function calls is low but there is a large number of loop iterations within functions.
overall however for the executions in this study the size of the execution data is fairly contained and it would be practical to collect them.
table iii addresses the core question of the effectiveness of our approach.
the table shows for each failing execution feconsidered and each type of execution data ed the time it took b ugredux to generate inputs that mimicked fe using ed or n a if b ugredux was unable to generate such inputs in the allotted time and whether the mimicked execution reproduced the observed failure y or n .
as expected symbolic execution guided only by the pof was unsuccessful for most programs.
a manual examination of the programs for which pofs are enough to reproduce failures showed that all such failures have two common characteristics the pofs are close to the entry of the programs and are easy to reach the failures can be triggered by simply reaching the pofs.
for these failures developers could easily identify the corresponding faults if provided with traditional crash reports.
as also expected the larger the amount of data available in the form of intermediate goals to guide the exploration the better the performance of the approach.
using call stacks b ugredux could mimic out of the failing executions and using call sequences it was able to mimic all failing executions.
we observe that in some cases e.g.
htget tipxd the time needed to synthesize an execution using call stacks was480table iii effectiveness and efficiency of bugredux in synthesizing executions starting from collected execution data .
name pof call stack call sequence complete trace sed.fault1 n a n a 98s y n a sed.fault2 n a n a 17349s y n a grep n a 16s n 48s y n a gzip.fault1 3s y 18s y 11s y n a gzip.fault2 20s n 28s n 25s y n a ncompress 155s y 158s y 158s y n a polymorph 65s y 66s y 66s y n a aeon 1s y 1s y 1s y 1s y rysnc n a n a 88s y n a glftpd 5s y 5s y 4s y n a htget 53s n 53s n 9s y n a socat n a n a 876s y n a tipxd 27s y 27s y 5s y n a aspell 5s n 5s n 12s y n a xmail n a n a 154s y n a exim n a n a 269s y 5624s y larger than the time needed when using call sequences when they are both successful .
the reason for this behavior is that the additional information provided by call sequences can better guide symbolic execution and avoid the exploration of many irrelevant paths.
one surprising finding however is that this trend is not confirmed when complete traces are used.
we further analyzed this result and found that this happened for two reasons.
one reason is that intuitively following complete traces can result in conditions that the smt solver is unable to handle.
the second reason is a mostly practical one klee uses a simplified implementation of the system libraries when symbolically executing a program which makes it impossible in some cases to follow exactly the same path that was followed in the original execution.
conversely a looser yet informative guidance such as a call sequence leaves more degrees of freedom to the input generator and increases its chances of success.
for example paths that result in constraints that are beyond the capabilities of the smt solver could be dropped in favor of simpler paths that may still reach the targeted goals.
in a sense among the execution data we considered call sequences represent a sweet spot between providing too little and too much information to the search.
it is important to stress that the executions synthesized by bugredux are executions that reach all of the intermediate goals extracted from the execution data and provided to the input generator but they are not guaranteed to reproduce the observed failure.
this is especially true when considering more limited types of execution data such as pofs and call stacks which provide little guidance to the search.
the results in table iii clearly illustrate this issue.
as shown in the table for three of the failures in our set reaching the pof is not enough to trigger the original failure.
similarly for the four failures in grep gzip htget and aspell b ugredux was able to synthesize executions that generated the same call stacks as the failing executions but such synthetic executions did not reproduce the consid ered failures.
conversely all of the synthetic executions successfully generated from call sequences were able to reproduce the original failures.
e. discussion the results of our investigation albeit preliminary let us address our two research questions and make some observations.
for rq1 our results show that for the programs and failures considered b ugredux can reproduce observed failures starting from a set of execution data.
for rq2 the results provide initial but clear evidence that call sequences represent the best choice among the ones considered in terms of cost benefit tradeoffs using call sequences b ugredux was able to reproduce all of the observed failures even using an unoptimized instrumentation b ugredux was able to collect call sequences with an acceptable time and space overhead and we believe that call sequences are unlikely to reveal sensitive or confidential information about an execution.
although this is just anecdotical evidence we observed that none of the inputs generated when synthesizing executions from call sequences corresponded to the original input that caused the failure.
unlike complete traces which may provide enough information to reverse engineer an execution and identify the inputs that caused such execution call sequences are a much more abstract model.
an additional observation that can be made on the results is that pofs and call stacks do not seem to be particularly helpful for reproducing failures.
manual examination of the faults we considered showed that the points where the failure is observed tend to be distant from the fault.
therefore most such failures are triggered only when the program executes the faulty code and the incorrect program state propagates to the pof.
in these cases pofs and call stacks are unlikely to help because the faulty code may be nowhere near the pof or the functions on the stack at the moment of the crash.
if confirmed this would be an interesting finding as these are two types of execution data normally collected in crash reports.
extending crash reports with additional information may make them considerably more useful to developers.
as a further step towards understanding the usefulness of different execution data we performed an additional exploratory study in which we removed entries in the collected call sequences and checked whether the partial sequences still contained enough information to recreate observed failures.
more precisely we selected from our original list the ten failures that could only be reproduced using call sequences.
for each failure and corresponding call sequence we then used a straw man greedy algorithm that considers one entry in the call sequence at a time starting from the beginning.
if bugredux can reproduce the failure without that entry in the sequence the entry is removed.
table iv shows the result of this study in terms of number of entries in the call sequences before and after reduction.481table iv minimal number of entries in call sequences that are needed to reproduce observed failures .
name original length minimal length sed.fault1 sed.fault2 grep xmail gzip.fault2 rysnc aspell socat htget exim for example only of the entries in the original call sequence are needed to reproduce the observed failure in grep.
the results show that in most cases only a small subset of calls in the sequences is actually necessary to suitably guide the exploration.
we can further observe that the number of entries needed seems to increase with the complexity of the input needed to trigger the fault which makes sense intuitively.
for instance xmail s failure can only be triggered by an input file that includes a valid email address and aspell s failure can only be triggered by an input of a given length.
for these two faults the reduction in the call sequence is less substantial than for the other faults considered.
these additional results motivate further research in this direction as we discuss in section v. f .
limitations and threats to validity the main limitation of b ugredux is that it relies on symbolic execution an inherently complex and expensive approach.
however recent results have shown that if suitably defined tuned and engineered symbolic execution can scale even to large systems .
moreover as we discuss in future work b ugredux can leverage different input generation techniques.
another limitation is the potential overhead involved in collecting field execution data.
for this reason as also discussed in future work we are currently investigating the use of alternative types of execution data.
one final limitation is that b ugredux currently does not explicitly handle concurrency and non determinism.
in this initial phase of the research we chose to focus on a smaller domain and get a better understanding of that domain before considering additional issues.
like for all studies there are threats to the validity of our results.
to mitigate threats of internal validity related to errors in our implementation we tested b ugredux on small examples and spot checked most of the results presented in the paper.
in terms of external validity our results may not generalize to other programs and failures.
however we studied failures and programs from three different software repositories.
the subjects we used are real world programs several of which are widely used both by real users in the field and by researchers as experimentalsubjects.
another issue with the empirical results is that the ultimate evidence of the usefulness of the technique would require its use in a real setting and with real users.
although such an evaluation would be extremely useful and we plan to do it in the future as we did for earlier work we believe that it would be premature at this point.
moreover when successful b ugredux would generate an actual execution that reproduces the observed field failure.
we expect such an execution to be usable like any failing test to debug the problem causing the failure.
overall we believe that our initial results show that the approach is promising and identify several research directions that it would be worth pursuing directions that could be investigated by building on the work presented in this paper as we discuss in section v. iv.
r elated work debugging is an extremely prolific area of research and the related work is consequently vast.
in this section we focus on the work that is most closely related to our approach.
our work is related to automated test input generation techniques such as those based on symbolic execution e.g.
and random generation e.g.
.
generally these techniques generate inputs with the goal of discovering faults and they are not directly applicable to the problem we are targeting as we have discussed in section iii b. techniques that capture program behaviors by monitoring or sampling field executions are also related to ours e.g.
.
these techniques usually record execution events and possibly interactions between programs and the running environment to later replay or analyze them in house.
these approaches tend to either capture too much information and thus raise practicality and privacy issues or too little information and thus be ineffective in our context.
more recently researchers started investigating approaches to reproduce field failures using more limited information.
for example some researchers used weakest preconditions to find inputs that can trigger certain types of exceptions in java programs .
these approaches however target only certain types of exceptions and tend to operate locally at the module level.
another approach sherlog makes use of run time logs to reconstruct paths near logging statements to help developers to identify bugs.
logenhancer improves the diagnose ability of sherlog by adding more information to log messages.
these approaches differ from ours because they do not aim to generate program inputs but rather to highlight code areas potentially related to a failure.
artzi and colleagues present recrash a technique that records partial object states at method levels dynamically to recreate an observed crash at different levels of stack depth.
although this approach can help recreate a crash the recreated crash can be very482different from the original one if the stack depth is low the information is in most cases too local to help e.g.
a null value passed as a parameter conversely if the stack depth is high the technique may have to collect considerable amounts of program state which can make it impractical and raise privacy issues.
the two approaches most related to ours are esd by zamfir and candea and the technique by crameri bianchini and zwaenepoel .
esd is a technique for automated debugging based on input generation.
given a pof esd uses symbolic execution to try to generate inputs that would reach the pof.
as we showed in this paper without additional guidance symbolic execution techniques are unlikely to be successful in this context.
in fact as we stated in section iii b the failures used in reference can also be recreated through unguided symbolic execution.
unlike b ugredux however one of the strengths of esd is that it can recreate concurrency related failures.
with this respect b ugredux and esd are complementary and it would be interesting to investigate a combination of the two techniques.
another approach that aim to reproduce concurrency bugs and is thus also complementary to b ugredux is pres by park and colleagues .
the approach by crameri and colleagues improves esd by using partial branch traces where the relevant branches are identified through a combination of static and dynamic analysis to guide symbolic execution for field failures reproduction.
although their approach can reduce dramatically the number of branches considered we found in our experience that the use of branch level traces can be problematic.
their empirical evaluation is also performed on programs whose failures can be reproduced using unguided symbolic execution.
it is therefore unclear whether their approach would work on larger programs and harder to reproduce failures.
it is nowadays common practice to use software e.g.
breakpad or os capabilities e.g.
windows error reporting and mac os crash reporter to automatically collect crash reports from the field.
as we discussed earlier these reports can be used to correlate different failures reported from the field.
debugadvisor for instance is a tool that analyzes crash reports to help find a solution to the reported problem by identifying developers code and other known bugs that may be correlated to the report.
although these techniques have been shown to be useful they target a different problem and the information they collect is too limited to allow for recreating field failures.
v. c onclusion and future work the ability to reproduce an observed failure has been reported as one of the key elements of debugging.
whereas recreating failures that occur during in house testing is usually easy so for failures that occur in the field on user machines is unfortunately an arduous task.
to address this problem we have presented b ugredux ageneral approach for supporting in house debugging of field failures.
our approach works by collecting data about failing program executions in the field extracting from the collected execution data a sequence of intermediate goals i.e.
statements in the program and using input generation techniques to synthesize in house executions that reach such goals and mimic the observed failures.
to better understand the tradeoffs between amount of information collected and effectiveness of the approach we have performed an empirical investigation and studied the performance of four instances of b ugredux that leverage different kinds of execution data.
we have applied these four instances to a set of failures of real world programs and compared their cost and effectiveness.
our results are encouraging and provide evidence that b ugredux can reproduce observed failures starting from a suitable set of execution data.
in addition the analysis of the results led to several findings some of which unexpected e.g.
more information is not always better .
finally our results provide insight that can guide future work in this area.
our immediate plan for future work is to perform additional experiments on a larger set of programs and failures.
we will also investigate the use of other kinds of execution data.
despite the good performance of call sequences in our initial investigation collecting execution data whose size is bounded in the size of the program would be preferable in many cases.
one possibility would be the use of execution data consisting of dynamic models of the program such as dynamic call graphs to prune the search space during input generation.
another alternative would be the investigation of efficient and possibly partial ways to represent potentially unbounded data for example using automata.
our approach currently assumes that all parts of a failing execution are equally relevant when trying to reproduce a failure.
intuitively some parts of the execution or even of a program may be more relevant than others.
we believe that collecting information at different levels of details for different parts of the program may allow for an accurate reproduction of failures even in the presence of less data.
our preliminary study on the use of partial call sequences provides supporting evidence for this research direction.
finally symbolic execution is just one possible way to generate execution that can reproduce an observed failure.
we will investigate alternative techniques for synthesizing failing executions such as techniques based on backward rather than forward exploration e.g.
techniques based on genetic algorithms e.g.
and techniques that leverage existing test inputs using some form of fuzzing e.g.
.