capacity planning for event based systems using automated performance predictions christoph rathfelder fzi research center for information technology karlsruhe germany rathfelder fzi.desamuel kounev karlsruhe institute of technology karlsruhe germany kounev kit.edudavid evans university of cambridge cambridge uk david.evans cl.cam.ac.uk abstract event based communication is used in different domains including telecommunications transportation and business information systems to build scalable distributed systems.
the loose coupling of components in such systems makes it easy to vary the deployment.
at the same time the complexity to estimate the behavior and performance of the whole system is increased which complicates capacity planning.
in this paper we present an automated performance prediction method supporting capacity planning for event based systems.
the performance prediction is based on an extended version of the palladio component model a performance meta model for componentbased systems.
we apply this method on a real world case study of a traffic monitoring system.
in addition to the application of our performance prediction techniques for capacity planning we evaluate the prediction results against measurements in the context of the case study.
the results demonstrate the practicality and effectiveness of the proposed approach.
i. i ntroduction the event based communication paradigm is used increasingly often to build loosely coupled distributed systems in many industry domains including telecommunications transportation supply chain management and business information systems.
compared to synchronous communication using for example remote procedure calls rpcs the event based communication among components promises several benefits like higher system scalability and flexibility .
the deployment of components as well as the connections between producers and consumers of events can be easily changed.
however the event based programming model is more complex as the application logic is distributed among multiple independent event handlers with decoupled and parallel execution paths.
for this reason predicting the system s behavior and estimating the required infrastructure resources is a complex task.
to guarantee adequate performance and availability systems in today s data centers are often deployed on server machines with highly over provisioned capacity .
capacity planning is performed based on data collected on test systems or live systems with a similar setup and workload.
thus changing the system by adding new components and functionality or changing the workload often requires expensive and timeconsuming load testing.
to improve the capacity planning process and thereby the energy and resource efficiency of this work was partially funded by the european commission grant no.
fp7 and the german research foundation grant no.
ko event based systems automated techniques are required that help to estimate the amount of resources required for providing a certain quality of service qos level.
such techniques help to answer the following questions that arise frequently both at system deployment time and during operation what would be the average utilization of system components and the average event processing time for a given workload and deployment scenario?
how much would the system performance improve if a given server is upgraded?
how would a change in the workload affect the system s performance?
what maximum load level can the system sustain for a given resource allocation?
what would be the influences of adding new event producers and consumers on the system s performance and resource utilization?
what would be the performance bottleneck for a given deployment?
answering such questions requires the ability to predict the system s behavior and performance for a given workload and deployment scenario.
performance prediction techniques for component based systems surveyed in support the architect in evaluating different design alternatives.
however they often provide only limited support for modeling eventbased communication and automated evaluations of different load scenarios.
both aspects are essential for the capacity planning of event based systems.
the palladio component model pcm is a mature meta model for component based software architectures enabling quality predictions e.g.
performance reliability at system design time.
as shown in a small proof of concept case study pcm can be used to evaluate the performance of event based systems however the modeling effort is rather high as manually performed workarounds are required to represent event based communication.
in we presented an extension of the pcm which natively supports the modeling and prediction of event based communication in componentbased systems.
an automated transformation which maps the newly introduced model elements to existing pcm model elements allows us to exploit the available analytical and simulative analysis techniques e.g.
while sig978 .
c circlecopyrt2011 ieee ase lawrence ks usa352nificantly reducing the modeling effort by more than .
although the approach was shown to be conceptually sound so far no validation was presented to evaluate its effectiveness practicality and accuracy when applied to realistic systems.
in this paper we present an in depth evaluation and experience report on the use of our automated performance prediction technique for capacity planning in a realistic context.
we present a novel case study of a real life traffic monitoring system based on the results of the time project transport information monitoring environment at the university of cambridge.
we conducted capacity planning for different evolution stages of the system.
in various scenarios we changed the deployment of software components on the hardware infrastructure and or enhanced the system functionality by adding or substituting components.
we evaluate the accuracy of our performance prediction technique using measurements taken on a testbed distributed over up to quad core machines and consisting of different components each deployed with up to instances in parallel.
the prediction error was less than in most cases.
as today s systems are often over provisioned by a factor of or more integrating our approach into the capacity planning process promises significant improvements in terms of resource efficiency.
additionally the case study shows that our extension and its automation reduces the effort required for performance predictions within the capacity planning process drastically.
in summary the contributions of this paper are i an experience report on using an automated pcm based performance prediction for event based systems to support the capacity planning process ii a novel capacity planning case study of a real life event based system considering multiple deployment scenarios and resource allocations and iii a detailed evaluation of the accuracy of our approach based on measurements taken in a realistic test environment.
to the best of our knowledge no comparable case studies of similar size complexity and representativeness exist in the literature.
the case study presented here is the first comprehensive validation of our approach in a realistic context.
the remainder of this paper is organized as follows.
sect.
ii introduces the capacity planning process in general as well as our automated performance prediction approach.
sect.
iii presents our case study of a traffic monitoring system and the application of the capacity planning process.
in sect.
iv we evaluate the prediction accuracy of our approach and analyze the achieved effort reduction.
next we present an overview of related work and finally in sect.
vi we conclude with a brief summary and a discussion of future work.
ii.
c apacity planning process the use of event based communication in software systems promises better performance and scalability.
however the maximum processable workload is highly dependent on the available infrastructure resources.
due to the decoupling of components in an event based system parts of the system can be easily overloaded without any impact on the rest of the system.
nevertheless in such cases the system wouldcapacity planning performance predictions result evaluationmodel adaptation qos requirements fullfilled?
no yesvariation of architecture deployment capacity planning system evolution workload changessystem deployment and reconfiguration resources used efficiently?
yesnosystem modeling resource demand estimation fig.
.
capacity planning in the software life cycle be in an unstable state resulting in loss of events or other malfunctions which are hard to detect.
therefore determining the resource dimensioning and system deployment to ensure stable processing of the system workload is crucially important and it is the main goal of capacity planning.
additionally there might be qos requirements like maximum event processing time that must be fulfilled by the system.
to guarantee availability hardware resources are often highly over provisioned .
increasing the efficiency of the system by removing bottlenecks substituting components or reducing the required infrastructure while ensuring the availability of the system is an additional aspect of advanced capacity planning processes.
the integration of architecture level performance prediction techniques into the capacity planning process as sketched in figure enables software architects to analyze and evaluate different system configurations and deployments.
the specification of the performance model including the estimation of resource demands has to be done only once in the system s life cycle and later adapted to be aligned with the evolution of the implemented system.
the resource demands can be estimated by the component developer or if an implementation of the system is available based on measurements conducted with this implementation.
the performance model itself can be developed manually or generated automatically as done for example in .
the performance predictions within the capacity planning process are performed at the model level thus the implementation is not affected by the evaluation of different configuration and deployment options.
the running system is only reconfigured if the prediction results show that the considered reconfiguration scenario meets the performance and efficiency requirements.
as the system evolves e.g.
new components or new hardware is added or changes in the system s workload are detected the capacity planning process has to be conducted iteratively.
each iteration of the capacity planning process consists of several sub activities.
first if required the system performance model is adapted to reflect the current configuration of the system.
then by means of the model a series of performance predictions are conducted in which the load on the system is systematically increased until the maximal sustainable load is reached.
the workload variation as well as the execution of the performance predictions is fully automated.
we will present more details on our automated prediction approach after introducing pcm in the next section.
the results indicate the 353maximal workload that can be processed by the system.
they are additionally used to evaluate if the system fulfills all qos requirements.
in case these requirements are not satisfied with the evaluated system configuration and deployment the system architect modifies the configuration and or deployment and repeats the performance prediction process.
if the requirements are fulfilled the system efficiency is evaluated.
in case of an efficient resource utilization the capacity planning iteration ends and the implemented system is reconfigured according to the evaluated model.
if efficiency improvements are required the architect again modifies the system configuration and or deployment within the model and repeats the performance prediction process.
in the following we first give a general overview of the pcm then introduce our extension of the pcm that enables the modeling of event based communication and finally present the automation of the prediction process.
a. performance model we use the palladio component model pcm which is a domain specific modeling language for modeling component based software architectures.
it supports automatic transformation of architecture level performance models to predictive performance models including layered queueing networks queueing petri nets and simulation models .
pcm supports the evaluation of different performance metrics including response time maximum throughput and resource utilization.
the pcm approach provides an eclipsebased modeling and prediction tool1.
further details and a technical description can be found in .
the performance of a component based software system is influenced by four factors the implementation of system components the performance of external components used the deployment platform e.g.
hardware middleware networks and the system usage profile.
in the pcm each of these factors is modeled in a specific sub model and thus can be adapted independently.
the composition of these models forms a pcm instance.
the component model specifies system components and their behavior.
components refer to interfaces which are provided or required.
the pcm provides a description language called resourcedemandingserviceeffectspecification rdseff to specify the behavior of components and their resource demands.
the composition model describes the structure of the system.
by interconnecting components via their provided and required interfaces it specifies which other components a component uses.
in the deployment model physical resources are allocated to the components of the system.
it is required to specify the hardware environment the system is executed on like processor speed network links etc .
the usage model describes the workload induced by the system s end users.
for example the workload may specify how many users access the system the inter arrival time of requests and their input parameters.
sourcemiddleware servermiddleware sinka cc ab step step fig.
.
automated model to model transformation b. modeling event based interactions to enable the semantically correct modeling of eventdriven communication we extended the pcm meta model with new constructs e.g.
eventsource eventsink emiteventaction and enhanced the graphical editors to support them.
an automated model to model transformation transforms these new elements into existing pcm modeling constructs.
the transformation allows us to exploit the available analytical and simulative prediction techniques.
we substitute the connectors between sources and sinks with several components which cover all aspects of the event processing chain like processing on the client and receiver side distribution and replication of events as well as serverside processing.
these elements are sketched in fig.
.
for more details on the component internals we refer to .
the transformation includes interfaces to integrate additional components describing the behavior and resource demands of the employed middleware.
c. automation of the performance prediction process in the capacity planning process normally different design variations as well as different load situations need to be analyzed and evaluated.
in order to reduce the required effort we have automated the performance prediction process see fig.
.
the input of the performance prediction process is a model of the system combined with a specification of the parameter variations.
this specification includes the upper and lower bounds as well as the increments of the parameter variations.
by means of this specification the values of model parameters are set.
this adapted model is the input of a model to model transformation which as described above and illustrated in fig.
step substitutes the new elements of the pcm with elements already supported within the classical pcm.
in a second step components specified in a middlewarespecific repository are woven into the pcm model.
depending on the selected prediction technique this architecture level model is transformed into a prediction model e.g.
layered queueing network or queueing petri net or it is transformed middlewareweavingm2m eventtransformationparameter variation solving simulationtransformation prediction model end of parameter range?no yes fig.
.
automated performance prediction process 354into a java based simulation code.
as a last step the prediction itself is performed by solving the analytical models or running simulations.
if the upper bounds of the considered parameters are reached the prediction process ends.
otherwise the process starts again with a new parameter variation.
we now present our case study applying the presented capacity planning and performance prediction process in the context of a real world event based system.
iii.
c ase study the system we study is an event based traffic monitoring application based on results of the time project transport information monitoring environment at the university of cambridge.
it consists of several components emitting and consuming different types of events.
the system is based on a novel component based middleware called sbus stream bus which was also developed as part of the time project.
the sbus framework encapsulates the communication between components and thus enables easy reconfiguration of component connections and deployment options without affecting the component s implementation.
after a short introduction of sbus we present the different components the traffic monitoring system consists of.
finally we conduct the capacity planning process using our pcmbased performance prediction approach in four different evolution scenarios of the system.
a. sbus middleware the sbus middleware supports peer to peer event based communication including continuous streams of data e.g.
from sensors asynchronous events and synchronous remote procedure calls rpc .
in sbus each component is divided into a wrapper provided by the sbus framework and the business logic that makes up the component s functionality.
the wrapper manages all communication between components including handling the network registration of event sinks and sources and marshaling of data.
the basic entity of sbus is the component .
components communicate via messages and this is how all data exchange is implemented.
messages are published from and are received byendpoints each endpoint is connected with one or more others.
an endpoint specifies the schema of the messages that it will emit and accept.
the framework enforces matching of sender and receiver schemas ensuring that only compatible endpoints are connected.
each endpoint can be a client a server asource or a sink.
clients and servers implement rpc functionality providing synchronous request reply communication and are attached in many to one relationships.
on the other hand streams of events emitted from source endpoints are received by sink endpoints in a many to many fashion.
b. traffic monitoring application the traffic monitoring application we study consists of different types of sbus components see figure .
acisscoot lprcamcamspeeding toll locationbus proximity fig.
.
overview of case study components cameras the cam component as described in street lamps are equipped with cameras.
these cameras only collect anonymized statistical data.
in our scenario cameras take pictures of each vehicle on the street.
each camera is accompanied by an sbus component which is responsible to emit the picture combined with position information of the camera and a timestamp as an event to all connected sinks.
licence plate recognition the lpr component the lpr component can be connected to one or more cam components.
the implementation of our lpr components uses the javaanpr library to detect license plate numbers of observed vehicles.
the recognized number combined with the timestamp and the location information received from the cam component is then sent out as an event.
speeding detection the speeding component one component consuming the events of detected license plate numbers is the speeding component.
the component calculates the speed of a vehicle based on the distance between two cameras and the elapsed time between the two pictures.
reports about the installation of a similar system in london.
toll collection the toll component another component processing the events emitted by the lpr component is the toll component.
assuming all arterial roads are equipped with cam components the toll component determines the toll fee that must be payed for entering the city.
the express toll route system that is installed near toronto is an example of such a system which calculates road fees amongst others based on recognized license plate numbers.
bus location provider the acis component the bus location provider uses sensors in our case gps coupled with a proprietary radio network to note the locations of buses and report them as they change.
the component produces a stream of events each containing a bus id a location and the timestamp of the measurement.
location storage the location component the location storage component maintains state that describes for a set of objects the most recent location that was reported for each of them.
the input is a stream of events consisting of name location pairs with timestamps making acis a suitable event source.
traffic light status reporter the scoot component in the city of cambridge the city s traffic lights are controlled by a scoot system designed to schedule green and red lights so as to optimize the use of the road network.
the scoot component is a wrapper of this system.
it supplies a source endpoint emitting a stream of events corresponding to light status changes red to green and green to red a 355second source endpoint emitting a stream of events that reflect scoot s measurements of the traffic flow and two rpc endpoints that allow retrieval of information about a junction.
proximity detector the bus proximity component the bus proximity component receives a stream of trigger events reflecting when lights turn from green to red.
this stream is emitted by the scoot component.
upon such a trigger the scoot component s rpc facility is used to determine the location of the light that just turned red.
this is collated with current bus locations stored in a relational database by the location storage component to find which buses are nearby.
c. capacity planning study thanks to the sbus middleware which completely encapsulates the communication between components the deployment of components as well as the connections between components can be changed with almost no effort.
however as already mentioned in sect.
i the influence of such changes on the system s performance are hard to estimate.
in the following we apply the capacity planning process introduced in sect.
ii to the traffic monitoring system.
after introducing the initial performance model we incrementally extend the model aligned with the system s evolution from a single server deployment to a distributed environment.
performance model in this case study we use the extended version of pcm which natively supports modeling of event based communication.
the performance model consists of several sub models described in the following.
the complete model is available online2.
a component models the parametrization of pcm allows us to specify a repository with reusable components that can be instantiated multiple times if component redundancy is required in the system.
to connect the components with the usage model which specifies the rate of incoming events we need some additional trigger interfaces.
thus in addition to the event sinks and sources in figure the three components acis scoot and cam provide such additional trigger interfaces.
except for the lpr the resource demands of the components are nearly constant and independent of the data values included in the event.
this allows us to model them as fixed demands in an internalaction of the respective rdseff associated with the component.
for each component we measured the internal processing time under low system load and derived the resource demands.
measurements with different pictures showed that the resource demands required by the lpr component highly depend on the content of the picture.
pcm allows to specify parameter dependencies however it is not possible to quantify the content of a picture.
thus we modeled the resource demand using a probability distribution.
we systematically analyzed a set of different pictures.
for each image we measured the mean processing time required by the recognition algorithm over detection runs.
the standard deviation was less then of the mean event based communicationvalue for all measurements.
the measurements indicated that the processing of pictures that can be successfully recognized is nearly log normal distributed .
.
.
pictures where no license plate could be detected have a significantly higher but fixed processing time of .2ms.
to represent this behavior in the rdseff of the lpr component we used a branchaction.
one branchbehavior contains an internalaction with the fixed demand for undetected images and the other one contains a log normal distribution which we fitted to the measurements for successfully detected images.
the second component repository we use in our prediction model is the sbus specific middleware repository.
the modeled middleware components are integrated into the prediction model by the automated model transformation.
the repository includes one component representing event sources and one representing event sinks.
both components include a semaphore to model the single threaded behavior of the sbus implementation.
furthermore the rdseffs include internalactions to represent the resource demands required within the sbus middleware.
we instrumented the sbus implementation to measure the processing time in the different event processing steps.
b composition model in the composition model instances of the components in the repository are connected to build the system.
the eventsource role of a component is connected with the receiving eventsink roles.
in case of a reconfiguration of the component connections the model can be adapted by dragging the connector from one component to another.
the composition model describes only the connection between components and thus it is independent of the component s deployment on different hardware resources.
c deployment model the deployment model describes the allocation of components on individual hardware nodes.
it consists of two parts the resource environment model which describes the available hardware and the allocation model which specifies the mapping of components to hardware nodes.
in our case study the resource model describes our test environment which consists of resourcecontainers each containing one processingresource representing the cpu.
we selected processor sharing on cores as schedulingpolicy as all machines in our testbed are equipped with quad core cpus.
the resourcecontainers are connected by a linkingresource with a throughput of gbit s. the mapping of components to hardware nodes is adapted according to the individual deployment options in the scenarios.
d usage model the usage model consists of three different types of scenarios which are executed in parallel.
twousagebehaviors are used to trigger scoot and acis to emit events.
for both behaviors we specify anopenworkload with an exponentially distributed interarrival time with a mean value of 200ms.
additionally we introduce a usagebehavior for each street equipped with two cameras.
in these behaviors the two triggering calls of the cameras are connected by a delayaction .
with this equally distributed delay we simulate the driving time of timespan between two images cpu utilization allonone distrib.
lpd distrib.
other a scenario .
.
.
.
timespan between two images cpu utilization lpr lpr lpr cent.
lpr lpr decent.
lpr proc.
decent.
b scenario .
.
.
.
.
timespan between two images cpu utilization cent.
lpr decent.
lpr cent.
proc.
c scenario old cam .
.
.
.
.
timespan between two images cpu utilization cent.
lpr decent.
lpr cent.
proc.
d scenario new cam fig.
.
predicted cpu utilization a vehicle from the first cam on the street to the second one.
each camera call includes the specification of the image size.
similar to the other behaviors we use an exponentially distributed inter arrival time for the first camera.
to analyze different load situations we automatically vary the mean value of this distribution function in a predefined value range.
capacity planning after introducing the system s components and the performance model we now apply the pcmbased performance prediction technique to conduct capacity planning.
in the real world the requirements on the system the system itself and the available hardware infrastructure evolve over time.
these changes require to evaluate the system and conduct the capacity planning process iteratively.
our case study consists of four different scenarios which cover most of the changes e.g.
change of the system s workload change of the available hardware resources modification of a component or introduction of new components that require a new iteration of the capacity planning process.
we consider four scenarios representing different steps in the evolution of the system.
a scenario base scenario the scenario we use as a basis for all other scenarios consists of single instances of scoot acis location and bus proximity.
acis and scoot have a fixed event rate of events per second.
additionally one street is equipped with two cameras and two instances of the cam component which are connected to one lpr component.
the detected license plate numbers are processed by the speeding component.
in this scenario all processing components i.e.
lpr speeding location and bus proximity are deployed on one central server.
the utilization of this central server needs to be analyzed.
the cam components are running on individual computing nodes which are part of the camera systems mounted on the street lights.
in our model we deployed them on a separate node to avoid any influences on the other components.
as acis andscoot are the connections to other system and thereby to other network segments they have to be deployed on separate servers for security reasons.
in this scenario there is only one possible deployment option however for capacity planning the utilization of this central server as well as the maximal throughout needs to be analyzed subject to the event rate.
the maximal utilization of the cpus should not exceed to guarantee a stable operation.
in this scenario we have only one system and allocation model.
to analyze and evaluate different load situations we automatically reduced the timespan between two pictures emitted by the cam component.
the results showed that the system can handle a traffic flow of up to .
seconds between two cars respectively a frequency of .
cars per second until the limit of resource utilization is reached.
b scenario growing workload in this second scenario two additional streets are equipped with cameras to monitor the traffic thus the load on the system is increased to a total of six cameras sending images.
additionally a second server is available.
as with the previous scenario we first analyze the deployment option with all processing components on a single machine the allonone option to detect the component which induces most load.
we add the new camera components to the performance model and connect them with the lpr component.
again we specify a automatic variation of the workload induced by the cam components.
the bottleneck analysis shows that the recognition algorithm of lpr induces most load on the cpu so this component is the best candidate to be deployed on the second server.
we compare these two deployment options namely all processing components on one system and lpr separated from the other processing components.
in fig.
a the results of the prediction series are visualized.
as the machine hosting the lpr component is still the bottleneck no further optimization is possible in this scenario.
assuming an upper limit of cpu utilization for a stable state the prediction results show that the allonone deployment can handle up to .
images per second and cam.
the distributed deployment can handle up to image per second.
thanks to the easy to use graphical editors the required adaptations of the composition and allocation models could be done in less than minutes.
after that the prediction and variation of the event rate is fully automated.
c scenario new functionality with the cameras added in the previous scenario in this scenario all arterial roads in and out of the city centre are equipped with cameras.
based on this data it is possible to monitor vehicles entering and leaving the inner city.
this allows to build up an automated toll collection system represented by the toll component.
the toll component is the second component processing the events emitted by the lpr component.
it induces additional load on the cpu which was not foreseen in the previous scenarios.
to increase the system s throughput additional hardware is added and it is now possible to run three independent instances of lpr on different nodes.
in the first configuration scenario we consider the new hardware is not used and the lpr component is running separated from all other components 357similar to the previous scenario.
again the lpr component is the bottleneck.
based on these results we evaluated two further deployment options.
in both options three individual instances of lpr are running on different nodes each responsible for the events of two cameras.
in the first case all other components are running on one node see figure centralized deployment and in the second case speeding and toll are deployed with three separate instances and co located with the lpr instances on the three nodes decentralized deployment .
the required adaptation effort of the model is slightly higher compared to the previous scenario.
however the adaptation can still be done in less than minutes.
the results of the prediction series are visualized in fig.
b .
the option with only one instance of the lpr has a maximum throughput of about image per second and camera while the other two options with three instances can handle up to .
images per second and camera.
looking at the load balance between the machines hosting the lpr and the machine hosting the other components the centralized deployment is preferable.
the most efficient utilization i.e.
equally balanced cpu utilization is at an event load with an offset of roughly .
seconds between two images.
d scenario upgraded hardware in this last scenario an additional street is equipped with two cameras.
furthermore the existing cameras are replaced by a newer and improved model.
the new cameras are able to take pictures with higher resolution and improved quality.
with the improved quality the detection error ratio can be reduced from to .
it is known that the resource demands for processing pictures with undetectable license plates is significantly higher than for successfully recognized license plates.
however the resource demands also depend on the image size.
in this scenario the influences of introducing the new camera version on the overall system s performance are evaluated.
this evaluation allows to decide if the investment into new cameras will improve the system s performance.
similar to the previous scenario we evaluate a centralized and a decentralized deployment of the toll and speeding components.
these two deployment options that are considered both have four instances of lpr as a new server node is available.
to represent the new cameras in the prediction model only two model parameters the size of an image and the probability of an unsuccessful detection must be changed.
additionally the new cam and lpr instances must be added to the composition and allocation models.
nevertheless the required modeling time is less then minutes.
the results acisscoot lprcam speeding toll locationbus proximity cam lpr server lprcam camlpr server lprcam cam lpr server processing server gateway server fig.
.
scenario centralized deploymentare visualized in fig.
c and d .
in contrast to all other scenarios the bottleneck in the centralized deployment option with the new cameras is the machine hosting the event processing components and not the machines hosting the lpr components.
this means that further replication of the lpr component has no influence on the maximum throughput.
comparing the new and old cameras the max throughput could be improved slightly by the introduction of the new cameras.
iv .
v alidation when applying the pcm based performance prediction technique in the previous section we assumed that the accuracy of the results is sufficient.
in this section we will validate this assumption and compare measurements in our testbed with the predicted values.
furthermore we evaluate the effort reduction that can be achieved by our performance prediction approach.
a. prediction accuracy to evaluate the prediction accuracy we set up all scenarios described in sec.
iii c in our testbed depicted in fig.
.
we extended the implementations of scoot acis and cam with configurable and scalable event generators.
the events emitted by scoot and acis are based on an event stream recorded in the city of cambridge.
the event generator added to the cam component uses a set of real pictures of different vehicles including their license plates.
all event generators have in common that the event rate can be defined using a configuration file.
a single run of the prediction series simulates about pictures and its execution lasts about minutes.
on a real system measuring such a set of data will last up to hours and longer.
for this reason we had to limit the number of experiment runs and workload scenarios.
for each scenario we conducted up to seven experiments which cover the whole range from low to high load on the system.
in the following we present the results of these measurements compared to the predicted values.
scenario base scenario in the base scenario all event consuming components are deployed on the same machine.
in our testbed we used three machines.
on the first one we deployed acis and scoot on the second one the two cam components and on the last one the lpr component together with speeding location and bus proximity.
table i shows the measured and predicted values combined with the s3 experiment controller s2 s1 s9 s8 s7 s4 s5 s6 s10 s11 s12 gigabit switch each machine equipped with intel core quad q6600 4ghz 8gb ram ubuntu .
fig.
.
experiment testbed 358image rate per cam .
.
.
cpu utilization measurement .
.
.
.
.
prediction .
.
.
.
.
error .
.
.
.
event processing time in lpd measurement .
.
.
.
.
prediction .
.
.
.
.
error .
.
.
.
.
table i scenario cpu u tilisation and event processing time calculated prediction error.
overall the mean prediction error is less than and the maximal error less than and thus sufficient for capacity planning purposes.
scenario growing workload we set up the allonone as well as distributed deployment option in our testbed.
figure a visualizes the predicted and measured mean cpu utilization of the machines hosting the lpr component as well as the machine hosting the remaining components in the distributed deployment.
overall the mean prediction error of the cpu utilization in this scenario is less than .
in both deployment options the prediction error increases with higher cpu load which can be explained by caching effects since the algorithm used within the lpr component is very memory intensive and the high cpu load leads to increasing number of context switches during execution.
the measured utilization under the highest load in both options is lower than expected.
the analysis of throughput measurements shows that some images were queued up and not processed by the lpr component if the cpu utilization is higher than .
this is an indicator for an overloaded and instable system state.
we conducted some more experiments running the system continuously over several hours as well as with an increased event rate.
in both cases the system crashed and completely halted.
this confirms our assumption of an overloaded and instable system state.
scenario new functionality again we set up two deployment options in our testbed.
in the centralized deployment the event processing components with exception of the three instances of lpr are deployed on one machine.
in the decentralized option one instance of toll and one instance of speeding are deployed with one instance of lpr on the same machine.
figure b shows the predicted and measured mean utilization of the machines hosting the lpr component for both deployment options.
additionally it includes the utilization of the machine hosting the processing components in the centralized deployment options.
we leave out the values for the decentralized deployment options as they are independent of the image frequency.
overall the mean prediction error for the cpu utilization of the machine hosting the lpr component is .
and never exceeded .
image rate per cam .
.
.
.
.
measurement centralized .
.
.
.
.
.
.
prediction centralized .
.
.
.
.
.
.
error centralized .
.
.
.
.
.
.
measurement decentralized .
.
.
.
.
.
prediction decentralized .
.
.
.
.
.
error decentralized .
.
.
.
.
.
table ii scenario lpr m ean processing time0.
.
.
.
.
.
100cpu utilization frequency of images per cam cpu utilization allonone meas.
allonone pred.
distrib.
meas.
lpd distrib.
pred.
lpd distrib.
meas.
other distrib.
pred.
other a scenario .
.
.
.
.
.
100cpu utilization frequency of images per cam cpu utilization lpd meas.
decent.
lpd pred.
decent.
lpd meas.
cent.
lpd pred.
cent.
proc.
meas.
cent.
proc.
pred.
cent.
b scenario 100cpu utilization frequency of images per cam cpu utilization meas.
cent.
old pred cent.
old meas.
decent.
old pred.
decent.
old meas.
cent.
new pred.
cent.
new meas.
decent.
new pred.
decent.
new c scenario fig.
.
predicted and measured cpu utilization additionally we compared the measured and predicted processing time within the lpr component.
the results are listed in table ii and visualized in figure a .
under the highest workload the decentralized deployment option was overloaded and thus these values are not present in the table and figure.
due to the caching effects which can not be predicted by the model the prediction error increases with higher eventrates respectively higher cpu utilization.
however the mean prediction error is still under .
scenario upgraded hardware in this scenario we set up four different variants of the system in which we varied between the new and the old version of the cameras by changing the used images and considering again a centralized and decentralized deployment.
the results of the measurements and predictions of the mean cpu utilization of the machines hosting an instance of the lpr component are shown in figure c .
again the prediction error increases with higher load due to the caching effects induced by the memory intensive algorithm of the lpr.
however the mean prediction error is only .
.
we also analyzed the measured and predicted mean processing time within the lpr component.
in figure b we .
.
.
.
.
.
.
.
.
.
.
.
frequency of images per cam processing time meas.
decent.
pred.
decent.
meas.
cent.
pred.
cent.
a scenario .
.
.
.
.
frequency of images per cam processing time meas.
decent.
pred.
decent.
meas.
cent.
pred.
cent.
b scenario new camera fig.
.
predicted and measured mean processing time of lpr 359present the processing times of lpr in the scenarios using the improved cameras.
the mean prediction error is .
and never exceeded .
similarly to scenario the measured cpu utilization and processing time in the decentralized deployment option are lower than expected as again events are queued up.
the results for an even higher load which completely overloaded the system are not included.
b. modeling and prediction effort thanks to the automated prediction process sec.
ii c the only manual task that needs to be performed is the adaptation of the system s architecture level model.
in we already demonstrated that the presented pcm extensions combined with the automated model to model transformation reduce the modeling effort by up to compared to the use of the original pcm.
as already mentioned in the different scenarios the adaptations of the models could be done with a time effort less than minutes in all cases.
the execution of the prediction series is then fully automated.
to evaluate the effort reduction achieved with our process automation we compare the required time to execute the prediction with the time required to conduct equivalent measurements on our test system.
one simulation run which consists of simulated events takes about minutes on a macbook pro with core i7 processor and gb ram.
assuming the highest eventrate of five images per camera per second this corresponds to a time span of .
hours to collect the same amount of measurements in the testbed.
for lower event rates the required time can be a whole day or more.
thanks to the automated parameter variation different load situations can be evaluated automatically in less than hour which might require several days of measurements on the test system to obtain the same results.
in summary the prediction error of cpu utilization and response time is less than in most cases and the maximum error of the always underestimated cpu utilization never exceeded .
with this accuracy the performance prediction can improve the system performance and efficiency significantly given that today s systems are normally overprovisioned by a factor of or more .
the presented extension of the pcm combined with the automated modelto model transformation leads to a significant reduction of the modeling effort by up to .
furthermore the automated execution of performance prediction series dramatically reduces the required time compared to the execution of measurements on a test system.
v. r elated work over the last fifteen years numerous approaches have been proposed for integrating performance prediction techniques into the software engineering process.
efforts were initiated with smith s seminal work on software performance engineering spe .
since then a number of architecturelevel performance meta models have been developed by the performance engineering community.
the most prominent examples are the uml spt profile and its successorthe uml marte profile both of which are extensions of uml as the de facto standard modeling language for software architectures.
classical capacity planning techniques based on queueing theory have been studied by menasce .
however these model do not support an explicit modeling of the software architecture.
in recent years with the increasing adoption of componentbased software engineering the performance evaluation community has focused on adapting and extending conventional spe techniques to support component based systems which are typically used for building modern service oriented systems.
a recent survey of methods for component based performance engineering was published in .
several approaches use model transformations to derive performance prediction models e.g.
.
cortellessa et al.
surveyed three performance meta models in leading to a conceptual mda framework of different model transformations for the prediction of different extrafunctional properties .
the influence of certain architectural patterns on the system s performance and their integration into prediction models was studied by petriu and gomaa .
in uml collaborations are used to model the pipe and filter and client server architectural patterns which are later transformed into layered queueing networks.
a method for modeling message oriented middleware systems using performance completions is presented in .
model to model transformations are used to integrate lowlevel details of the middleware system into high level software architecture models.
however this approach is limited to point to point connections.
in an approach to predicting the performance of messaging applications based on java ee is proposed.
the prediction is carried out during application design without access to the application implementation.
this is achieved by modeling the interactions among messaging components using queueing network models calibrating the performance models with architecture attributes and populating the model parameters using a lightweight application independent benchmark.
however again the workloads considered do not include multiple message exchanges or interaction mixes.
several performance modeling techniques specifically targeted at distributed publish subscribe systems exist in the literature e.g.
.
however these techniques are normally focused on modeling the routing of events through distributed broker topologies from publishers to subscribers as opposed to modeling interactions and message flows between communicating components in event driven applications.
in a methodology for workload characterization and performance modelling of distributed event based systems is presented.
a workload model of a generic system is developed and analytical analysis techniques are used to characterize the system traffic and to estimate the mean notification delivery latency.
for more accurate performance prediction queueing petri net models are used.
while the results are promising the technique relies on monitoring data obtained from the system during operation which limits its applicability.
360vi.
c onclusion in this paper we presented the application of an automated performance prediction approach in the context of capacity planning for a real world traffic monitoring system.
the performance prediction approach is based on the palladio component model pcm which we extended to support the modeling of event based communication.
an automated model to model transformation allows to exploit all existing performance prediction techniques supported by the pcm.
the presented case study includes different evolution scenarios to which the capacity planning process was applied.
a detailed experimental evaluation of the prediction accuracy using a number of different scenarios representing different system configurations and workloads showed the applicability and accuracy of the prediction approach.
the prediction error was less than in most cases.
compared to the original pcm approach our extension reduces the required modeling effort for event based systems by up to .
the automation of the performance prediction process promises a significant time reduction compared to measurements on a test system.
the presented case study covers the most common evolution scenarios of event based systems in general and not only in the context of traffic monitoring systems.
for this reason the presented work forms the basis to apply the automated performance prediction approach to different event based systems in industry and research.
the approach allows us to evaluate different design options and supports the detection of performance bottlenecks.
the results presented in this paper form the basis for several areas of future work.
in the current version of the proposed pcm extension filtering of events has to be modeled manually in the sinks.
we plan to further extend the pcm to specify filtering rules.
furthermore we plan to work on extracting prediction models automatically at run time.
the resource discovery component rdc which is part of the sbus framework provides methods to determine the connections between endpoints.
this information can be used to create the system model.
additionally we plan to extend the instrumentation we integrated in the sbus framework making the measured resource demands available during operation.
this will allow to extract model parameters dynamically at runtime and will support the use of models for adaptive run time performance management.
analyzing the influences of caching effects on the system s performance and their consideration within performance predictions is an additional research topic.