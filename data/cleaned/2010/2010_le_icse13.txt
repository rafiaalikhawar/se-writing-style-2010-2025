segmented symbolic analysis wei le rochester institute of technology one lomb memorial drive rochester ny usa wei.le rit.edu abstract symbolic analysis is indispensable for software tools that require program semantic information at compile time.
however determining symbolic values for program variables related to loops and library calls is challenging as the computation and data related to loops can have statically unknown bounds and the library sources are typically not available at compile time.
in this paper we propose segmented symbolic analysis a hybrid technique that enables fully automatic symbolic analysis even for the traditionally challenging code of library calls and loops.
the novelties of this work are threefold we flexibly weave symbolic and concrete executions on the selected parts of the program based on demand dynamic executions are performed on the unit tests constructed from the code segments to infer program semantics needed by static analysis and the dynamic information from multiple runs is aggregated via regression analysis.
we developed the helium framework consisting of a static component that performs symbolic analysis and partitions a program a dynamic analysis that synthesizes unit tests and automatically infers symbolic values for program variables and a protocol that enables static and dynamic analyses to be run interactively and concurrently.
our experimental results show that by handling loops and library calls that a traditional symbolic analysis cannot process segmented symbolic analysis detects times more buffer overflows.
the technique is scalable for real world programs such as putty tightvnc and snort.
i. i ntroduction since its first application in debugging in symbolic analysis has demonstrated its break through capa bilities in bug finding and test input generation .
compared to dynamic testing symbolic analysis explor es program behaviors along as many execution paths as possible and is potentially able to reason for paths which randomly generated input cannot reach.
besides its coverage symbol ic analysis requires no executables and can be applied early in software lifecycle while fixing a bug is cheaper.
compared to traditional static analysis such as dataflow analysis symb olic analysis tracks actual symbolic values and relations of var iables at program points along program paths and is able to provide more precise information.
recent research has show n that by running symbolic analysis in parallel on clusters w e can make it applicable for complex software systems .
with such potential for scalability symbolic analysis wil l continue being a powerful tool for extracting program seman tic information for important software engineering tools.
despite great potential automatically determining symbo lic conditions for a program faces several challenges.
to const ruct symbolic conditions at statements we need to interpret the semantics of statements and resolve pointer aliasing.
someti mes program behaviors are not solely determined by source code and thus symbolic analysis purely using source information can fail in reasoning library calls or machine dependent ambiguities such as rounding or overflow.
in addition deriv ing symbolic conditions for paths containing loops is difficult as it is impractical to enumerate paths for all the loop iterati ons.
existing approaches for handling libraries and loops requi re either manual effort or loss of precision.
bush et al.
and chi pounov et al.
manually developed library models in prefix and cloud9 respectively.
as each new application may include a different library these models are not always abl e to be reused.
godefroid et al.
applied concolic testing where a program runs with both concrete and symbolic inputs.
when an unknown library call or loop occurs in symbolic analysis concrete values are used for constructing symbol ic conditions.
this approach is not precise and only handles th ose library calls and loops that a test input can reach.
saxena et al.
built template symbolic updates for loops based on code patterns .
cadar et al.
and chipounov et al.
analyzed loops through only one iteration .
in both of these approaches very limited loop behaviors are reasoned.
the goal of our work is to enable fully automatic symbolic analysis even for traditionally challenging code such as lo ops and library calls.
our insights are code is not uniformly e asy to analyze and we thus should not apply a uniform strategy fo r analyzing an entire program as traditional symbolic analys is does the capabilities of symbolic analysis are limited e specially when handling loops library calls and pointers and we should introduce dynamic analysis to supply information th at a pure static symbolic analyzer is slow or unable to produce a nd in a program some statements are more cohesive among each other than others and we should leverage the structura l and semantic relations between statements for partitionin g the program and applying different analyses accordingly.
in this paper we propose segmented symbolic analysis a hybrid technique that partitions a program on demand and invokes concrete executions on selected code segments for generating symbolic substitution rules also called transfer functions needed by symbolic analysis.
compared to traditional hybrid techniques where static and dynamic analyses are run in different phases and for an entire program our segmented symbolic analysis has the following novel goals for creating and using the dynamic information fully automatic .
running an entire program requires software executables and could be slow.
if a program is large randomly generated test inputs are not sufficient for achieving code coverage desired by dynamic anal ysis.
to address these challenges we aim to construct unit tests and only perform dynamic analysis on the code segments of interest.
since these test programs contain a small number of branches we can achieve desired code coverage with automatically generated test inputs.
aggregated information one concrete execution is often not able to provide representative values at program points.
we thus need a technique to aggregate the dynamic information obtained from different runs.
previous research shows that programs mostly consist of linear operations and determining program properties often only requires linear constraints .
based on these observations we assume that linear relations can characterize relevant behavior of small code segments.
therefore regression analysis is a natural fit to derive linear symbolic relations between program variables.
on demand and concurrent framework static and dynamic analyses are concurrently applied on different parts of the program to ensure that the capabilities of the analyses match the code characteristics.
the interactions between static and dynamic analyses are on demand accomplished via a query based protocol.
we developed a framework and tool called helium .
it runs a symbolic analysis and multiple dynamic analyses requested by the symbolic analysis.
the symbolic analysis determines sy mbolic conditions in a demand driven path sensitive fashi on .
when a static unknown such as a library call or a loop is encountered the symbolic analysis suspends the propagati on of the current symbolic condition and continues analyzing other paths.
meanwhile helium performs a structural and def use analysis of the code that causes static unknown and identifies the code segment for constructing a unit test.
the dynamic analysis automatically synthesizes the unit test a nd generates the test inputs.
after running the tests a regres sion based inference is performed on test inputs and outputs to derive transfer functions for the unknown code segment.
notified with the newly discovered information the symboli c analysis then updates the blocked symbolic conditions and resumes the analysis of this path.
we implemented helium to identify infeasible paths and buffer overflows.
we found through experimentation that segmented symbolic analysis is able to reason library calls and loops required for determining bugs and infeasible path s. compared to traditional symbolic analysis our segmented symbolic analysis reports improved detection capabilitie s and reduced static unknowns.
the techniques can be generally applied to real world programs such as putty andsnort .
unlike other hybrid symbolic analysis by running tests on small code segments for coverage and using regression analysis fo r summarization our dynamic inference did not report an unde rapproximation or over approximation.
in summary the research contributions of the work include a framework that enables on demand interactive static and dynamic analyses for handling loops and library calls regression based dynamic inference that abstracts the local program behaviors and experimental results to demonstrate the capabilities of segmented symbolic analysis.
the remainder of the paper is organized as follows.
in section ii we provide an overview of the helium framework.
in sections iii to v we explain each component of the framework respectively.
in section vi we present the experiment al results followed by the related work in section vii and conclusions in section viii.
ii.
t hehelium framework we first use an example to intuitively explain how segmented symbolic analysis works.
we then describe the three internal components of the framework.
a. an overview of segmented symbolic analysis in figure we display the control flow graph cfg for the simple example on the left.
on the right we compare three different symbolic analyses in detecting a buffer ove rflow located at node .
the goal is to show that our segmented symbolic analysis is able to find bugs that traditional symbo lic analysis cannot.
under traditional sa in figure we show how a traditional symbolic analysis attempts to find this buffer overflow.
here we use demand driven symbolic analysis to explain the process.
in the first step we raise a query inquiring at node whether the size of buffer filename would be larger than or equal to the length of the string in the buffer.
to determine the resolution of this symbolic condition we propagate the query backwards along path angbracketleft10 angbracketright.
at node the analysis determines that variable tis not relevant to the query we then advance the query to node .
at node the analysis is blocked by the library call stat64i32 and reports an unknown.
without further knowledge we do not know whether input filename has been changed in this call.
under traditional sa with library models we show that the analysis is able to continue after the developer models the library call stat64i32 .
however the analysis still would be blocked by a string manipulation related loop located at angbracketleft5 angbracketrightbecause we do not know the iteration of the loop at compile time.
in segmented symbolic analysis we partition a program when static analysis is blocked.
in figure we identify two code segments node contains a library call and node initializes its parameter and nodes contain a loop an d the initialization for its local variable iis done at node .
based on the two code segments we construct unit tests one for reasoning about stat64i32 figure and the other for reasoning about the loop figure .
each test program consi sts of four parts initializing variables with test inputs exe rcising segmented code reporting test outputs and cleaning up.
in helium we construct genchars to generate input strings and returnspace to clean up the global buffer gbuffor reuse.fig.
.
an example segmented symbolic analysis i n i t i a l i z e with t e s t i n p u t s c h a r f i l e n a m e genchars g buf code segment f o r t h e l i b r a r y c a l l s t r u c t s t a t s s t a t i f i l e n a m e s o u t p u t len f i l e n a m e c h a r r e s u l t genchars g buf i n t r i n t s t r l e n f i l e n a m e i t o a r i n t r e s u l t f p u t s r e s u l t fp c l e a n u p returnspace f i l e n a m e returnspace r e s u l t fig.
.
the test program for reasoning about stat64i32 i n i t i a l i z e with t e s t i n p u t s c h a r temp genchars g buf c h a r f i l e n a m e genchars g buf code segment f o r t h e loop i n t i w h i l e temp !
f i l e n a m e temp i o u t p u t len f i l e n a m e and c l e a n u p .
.
.
fig.
.
the test program for reasoning about the loop in table i we show example sets of test inputs and outputs generated when testing the code in figure .
in this example we generate inputs to initialize temp and filename before exercising the loop code.
both the string length and content are generated randomly shown under test input intable i. since our regression analysis is performed on the integer domain we predefined a set of mapping rules to map the test input to integers for performing regression analys is shown under transformed input for ra .
we select variables of interest in this case filename for test output shown under test output .
here we use filename to represent the value of filename after executing the code segment.
applying regression analysis to reason about the transfer function we perform inference on the data under transformed input for raandtest output using the linear model len filename 0 1len temp 2len filename .
we obtain len filename len temp .
similarly we infer len filename len filename at the library call indicating the length of the string filename would not be impacted by the library call.
performing symbolic substitutions using the discovered rules we derive t he query at node and determine the buffer overflow at node .
path segment angbracketleft3 angbracketrightis reported as a buffer overflow.
table i testinput and output for reasoning about the loop testtest input transformed input for ra test output temp filename len temp len filename len filename acde piidaf tazipda qdd ad dafdalfll b. the components helium takes program source as input and runs a fully automatic hybrid analysis reporting either bugs or path fe asibility.
shown in figure the framework consists of three components.
the static component performs symbolic analys isfig.
.
the helium framework and partitions programs.
the symbolic analysis is demanddriven.
it formulates a demand into queries at a set of progra m points of interest.
for example to detect infeasible paths we raise queries at each conditional branch inquiring whethe r the conditions at the branch can always be true or false .
a backward analysis is then performed to resolve the symbolic conditions in the queries .
when the analysis arrives at a statement where the rule for symbolic substitution has not b een defined the unknown code segment is partitioned from the program and a request is formed to invoke dynamic analysis.
the second component is a communication protocol between static and dynamic analyses.
the request enables transitions from static to dynamic analysis.
it provides the dynam ic analysis with the inquiries on the program variables the code segment for constructing the unit test and the constraints for generating test inputs.
the response enables transitions from dynamic to static analysis.
it contains pr ogram semantic information inferred by the dynamic analysis.
the dynamic analysis shown on the right in figure consists of an inference repository atest synthesizer and aninference engine .
the test synthesizer takes the request from symbolic analysis and constructs a unit test for the cod e segment of interest.
based on the constraints provided in th e request the test synthesizer automatically generates inp uts to run the program.
the inference engine performs a regression analysis on the inputs and outputs of the tests and returns the discovered transfer functions and symbolic values.
the repository stores all the inferred results for reuse.
iii.
p artitioning programs ondemand the challenges we addressed in the static component are to determine when and how to partition a program for constructing a meaningful test to reason static unknowns.
a. demand driven symbolic analysis our explanations on symbolic analysis are based on the following language model.
the language consists of data types integer boolean string float double poin ter and aggregate types composed of the above data types statements assignments arithmetic operations on integer float and double read interface to get input data and library calls and3 control structures if then andelsestatements reducible loops and procedural calls.
symbolic analysis also called symbolic execution the term here refers to pure static symbolic analysis take s symbolic inputs obtained at read statements.
during analysis symbolic values of variables are collected at each statemen t. at the conditional branch ifstatement symbolic analysis performs a fork and symbolic conditions at true andfalse branches are collected respectively along each path.
at the end of the pat hs the symbolic conditions are sent to the constraint solver.
t he instances if found are the program inputs that can exercis e the paths.
if the error conditions are added the instances a re the inputs that can exercise the path and trigger the bug.
a typical symbolic analysis is exhaustive in that it visits t he entire execution path explores as many paths as the resourc e allows and collects all symbolic values at the program poin ts.
in helium we develop a demand driven symbolic analysis .
the symbolic conditions e.g.
regarding buffe r safety or branch correlations are only constructed at the selected program points of interest.
the analysis starts fr om these conditions and performs a backward traversal of progr am paths to determine whether there exist inputs that can make the conditions to be true orfalse .
our analysis is basic in that it does not apply heuristics or manually constructed specifications.
its capabilities are summarized as follows .
data types .
we construct symbolic conditions for integers booleans floats and doubles.
we model string length and buffer size.
for pointers and aggregate types we apply an ex ternal intraprocedural field sensitive pointer analysi s .
we usemust aliasing and heuristically select may aliasing when constructing symbolic conditions.
statements .
we integrate the semantics of assignment for all data types arithmetic on integer boolean float and double and the read function.
control structures .
we apply a demand driven interprocedural path sensitive context sensitive analysis for propagating symbolic conditions across the contro l structures if then and else and procedures.
the symbolic analysis traverses each loop once for each path in the loop.b.
partitioning programs based on static unknowns code partitioning is performed when the symbolic analysis encounters a statement or a control structure that it cannot analyze.
in helium we consider two sources of static unknowns .
we report an unknown at the library call if the variable under tracking is a global an actual parameter of a pointer type o r the return of a library call.
we report a loop unknown if we traverse a loop once and discover that the loop can have an impact on the symbolic conditions.
since statically we cannot derive more information for such library calls and loops we aim to run the code to infer their behaviors.
specifically our goal is to determine the transf er functions i.e.
the relations of output and input variable s for the unknown code segments.
ideally we would run the entire program and perform dynamic inference based on the inputs and outputs observed at the entry and exit of the code segments.
however it is very hard to develop test inputs tha t can exercise any code segment of interest with high code coverage.
therefore in helium we construct unit tests on the unknown code segments partitioned from the program.
although we do not run an entire program we initialize program variables at the entry of unknown code using the test inputs that are equivalent or at least similar to the val ues we potentially obtain in a system testing.
in this way the un it tests simulate feasible program behaviors and we can gener ate valid semantics for the unknown code.
to determine how to assign initial values for program variables in the test program we first identify a set of varia bles used in the code segment but defined outside the segment.
we perform a def use analysis on the original program to decide where those variables are declared and defined.
if a variable is initialized with some constant before entering the code segment we include such initialization in the test program .
for example in figure we add int i when constructing a unit test for reasoning about the loop.
in many cases the variables used in the code segment are not constant.
we apply a range analysis to determine the potential ranges of these variables in the orignal program based on which we automatically generate test inputs to initialize the varia bles.
iv.
m ixing static and dynamic analyses different from techniques where static and dynamic components are run separately our hybrid approach unifies the two types of analyses through online requests andresponses .
besides efficiency this approach makes a better use of dynamic analysis as the dynamic analysis may not be able to reason symbolic values for every program variable but can answer a specific request from the static analysis.
a. from static to dynamic analysis initializing requests requests express the demand of static analysis and provide guidance for generating unit tests needed by dynamic analys is.
shown in figure a request is a tuple angbracketleftv c e angbracketright where vlists variables for which dynamic analysis should infer symbolic values.
it defines the output variables for unittests.
the requests are expressed using attributes e.g.
value v for the value of variable v len v for the length of string vandsize v for the size of buffer v. cincludes the code segment identified for constructing a unit test see section iii b .
egives the types as well as the constraints of initial values if any for all the uninitialized variables used in the given code segment.
it specifies the requirement for generating test inputs.
fig.
.
interaction protocol request and response b. from dynamic to static analysis consuming responses aresponse encapsulates any semantic information found by dynamic analysis on the code segment crelated to v. in helium we currently support five types of models for representing the relevant behavior of a code segment namel y constant simple linear multiple linear polynomial linear andpiecewise linear shown in table ii .
dependent on whether the output variable acan be predicted using only one or multiple input variables a linear relation can be simple or multiple.
in a polynomial linear relation the powers of input variables e.g.
b2 or interactions of input variables e.g.
c d are used to represent the output variable a. there is also the piecewise linear model where the linear relations can vary based on the ranges of the input variable s .
given a request vfrom the static analysis our dynamic inference component will automatically select a model that fits the dat a. the generated models will be supplied to static analysis for continuing symbolic analysis.
table ii explanatory models for representing code semantics supposea output var b c d input vars models examples constant a simple linear a b multiple linear a b c polynomial linear a b2 c d piece wise linear ifb 0a b elsea v. i nference on demand in this section we show how we construct a unit test from a given code segment and how we apply regression analysis to discover symbolic relations of program variables.a.
test synthesizer a test synthesizer accomplishes two tasks.
it constructs a test program from the code segment cwith designated input and output variables and it automatically generates a set o f test inputs that satisfy e see section iv for definition .
shown in figure we take four steps to construct a test program.
first we complete the code segment by including the function calls invoked and the libraries used.
second w e prune the code segments from which we are unlikely to infer precise transfer functions.
in the current version of heliu m we use code size as heuristics to exclude such code segments.
specifically we will exclude the code segments whose branch numbers or variable numbers exceed the thresholds.
our assumptions are that if the code segment contains a small number of branches we potentially can achieve a high test coverage even with randomly generated test inputs the transfer function for a smaller code segment is more likely t o be linear and we are more likely to make a smaller code segment runnable.
in our future work we plan to iteratively decompose the code segment and perform segmented symbolic analysis within a segment until the confident linear relatio ns are learned.
in the final steps we identify vin the code segment as test output variables and the variables whose ini tial values are not given as test input variables.
we instrument t he code for enabling such input and output in the test program.
fig.
.
construct unit tests in helium we support test input generation for both integer and string data types.
currently we implement a random test input generator taking the constraints identified for the t est input variables into consideration.
to determine the size o f test inputs there are two effective approaches.
one approach is to stop generating and running test inputs when the desired cod e coverage is achieved for inferring confident symbolic relat ions.
another related approach is to stop testing when the transfe r functions are learned and stabilized.
further research has to be done to determine such stopping criteria.
in the current ver sion of helium the test input size is not automatically determin ed but configured by the users.
b. regression based inference after running the constructed tests we obtain a set of value s from test input and output.
based on these values regressio n analysis is able to determine the relations between the inpu t and output variables if any.
applying regression analysis to discover transfer functions in statistics linear regression models the relationship between a scalar response variable yand one or more explanatory variables x angbracketleftx1 x2 ... xn angbracketrightby fitting a linear equation to the observed data.
the linear equation is called thelinear predictor function denoted y 0 1x1 ... nxn where 0 1 ...and nare the coefficients indicating the relative effect of a particular explanatory variable on the outcome .
applying regression analysis to infer transfer functions each program variable in request vis mapped to a dependent variableyand the input variables in the test program are mapped to the explanatory variables.
for example in figure to infer the impact of the library call for filename we define the response variable len filename the length of the string after the call and the explanatory variable len filename the length of the string before the call .
the regression analys is makes inferences on the test inputs and outputs from multipl e runs and determines len filename len filename .
steps of regression analysis since we consider all the program variables alive at the entry of unknown code as explanatory variables for regression analysis we may end u p including too many explanatory variables in a linear model a nd cause an over fitting problem the model describes a random error rather than the underlying relationships .
to ad dress this challenge we apply model selection to determine for a specific response variable which explanatory variables a re valid.
we then infer the relations for the response variable and the selected explanatory variables.
to reason polynomial linear relations that potentially exi st among program variables we perform a data transformation for the selected explanatory variables.
for example if we h ave two explanatory variables x1andx2 we would construct the datax1 x2 x2 1andx2 2for deriving potential polynomial relations y 0 1x1 2x2 3x1 x2 4x2 5x2 .
if regression analysis reports that 1 5are the linear model is constant.
similarly if 2 5are or 1and 3 5are the model is simple linear if 3 5 are the relation is multiple linear.
otherwise we obtain a polynomial model.
if the above linear relations are not foun d we resort to a piecewise regression model to fit the data.
fig.
.
inference via regressionvi.
i mplementation and experimental results the goals of our experiments are to determine the capabilities of segmented symbolic analysis in handling lo ops and library calls and detecting bugs and infeasible paths the capabilities of regression based dynamic inference i n discovering correct transfer functions and the scalabi lity of concurrent on demand hybrid analysis.
a. implementation and experimental setup we developed the helium framework for detecting infeasible paths and buffer overflows for c c programs.
we apply a branch correlation algorithm for infeasible path de tection and demand driven analysis for buffer overflow detection .
the demand driven symbolic analysis is implemented using the microsoft phoenix compiler infrastruc ture and the disolver constraint solver .
regressi on analysis is performed using the r statistical package .
our experimental data are collected using the configurations of test inputs per unit test and maximumly input variables fo r constraining the test program size.
we collected programs to evaluate our framework.
the real world programs such as snort containing k lines of code are used to examine the scalability of the tool wu ftpd andsendmail from the buffer overflow benchmark and polymorph andgzip from bugbench containing known buffer overflows are used for estimating false negatives.
in our experiments we ran a basic symbolic analysis see section iii for description as well as a segmented symbolic analysis for detecting both buffer overflows and infeasible paths.
the comparison metrics include the number of bugs and infeasible paths detected the number of static unknown s reported and the time overhead.
we also evaluated the capabilities of regression based dynamic inference by reportin g the percentage of loops and library calls analyzed and the numbe r of transfer functions generated.
b. experimental results comparing the basic and segmented symbolic analyses in table iii we compare the capabilities of the two symbolic analyses.
on the left we give the results for buffer overflow detection and on the right we show the results for infeasibl e path detection.
under sain the table we list the data collected from the basic symbolic analysis and under s sa we display the results from the segmented symbolic analysis.
under pvs we show the total number of potential buffer overflow statements reported for each program.
the demanddriven analysis raised queries from these statements.
comparing columns saand s sa under overflow we find that the segmented symbolic analysis found a total of buffer overflows for all the benchmark programs while the basic symbolic analysis reported only .
we inspected the buffe r overflows and found that there are no false positives related to our dynamic analyses.
there are false positives among the overflows reported for snort .
our inspection shows that these false positives are all related to the same infeasible path t hat we failed to detect due to the complex pointers.
the basicsymbolic analysis is blocked by a library call and does not encounter this infeasible path.
among a total of known buffer overflows located in wu ftpd sendmail polymorph andgzip we detected and missed .
take polymorph as an example.
we found a total of of known buffer overflows and we missed one overflow because our dynamic inference does not yet handle the librar y callstrrchr .
we have further discussions on the capabilities of segmented symbolic analysis in section vi c. under determined we list the number of statements that contain statically determined paths.
under unknown we show the number of statements that contain static unknown paths.
for all benchmarks segmented symbolic analysis reports better detection capabilities and less unknowns.
to show that segmented symbolic analysis can be generally applied for determining different properties we also comp are the results for infeasible path detection.
under cond we list the number of conditional branches we analyzed for determining infeasible paths.
under infeasible we show that segmented symbolic analysis detects more infeasible paths tha n basic symbolic analysis for most benchmarks.
for sendmail pointer complexity blocks both of the symbolic analyses fro m further determining path feasibility and thus the advanta ges of segmented symbolic analysis for handling loops and library calls are not applicable here.
the results from this table also indicate that segmented symbolic analysis can handle both small and large programs.
for the largest benchmark program snort we determined infeasible paths for more conditional branches and reported less unknowns than the basic symbolic analysis.
feasibility and capabilities of dynamic inference table iv summarizes the results from our dynamic inference on the left for buffer overflow detection and on the right for infeasible path detection.
under segments we list the number of code segments we partitioned from a program.
under runnable we display the number of code segments that are successfully compiled and run.
under analyzable we give the number of unit tests from which the semantic informatio n is discovered.
finally under inferred items we list the total number of transfer functions discovered.
the results indicate that we inferred a total of models from all the benchmark programs.
take both buffer overflow and infeasible path detection into consideration.
segment ed symbolic analysis successfully analyzed loops for out of programs and reasoned library calls for all the programs.
comparing the data under runnable andsegments we show that we successfully generated unit tests for .
of the lo ops encountered.
comparing segments andanalyzable we show that .
of the encountered loops are successfully analyz ed.
we also managed to build unit tests for .
and proccessed .
of the library calls that block static analysis.
in our experiments we found that symbolic equivalence shown in the second row in table ii is useful for modeling transfer functions for code segments that have no impact on the variables of interest.
on the other hand multiple and polynomial linear models shown in the third and fourth rowstable iii segmented symbolic analysis for detecting buffer overflows and infeasible paths program pvsoverflow determined unknown sa s sa sa s sa sa s sa wu ftpd sendmail polymorph .
.
gzip .
.
grep tightvnc .
.
putty .
snort .
.
45program condinfeasible determined unknown sa s sa sa s sa sa s sa wu ftpd sendmail polymorph .
.
gzip .
.
grep tightvnc .
.
putty .
snort .
.
table iv dynamic inference for buffer overflow and infeasible paths detection programsegments runnable analyzableinferred itemsloop lib loop lib loop lib wu ftpd sendmail polymorph .
.
gzip .
.
grep tightvnc .
.
putty .
snort .
.
148programsegments runnable analyzableinferred itemsloop lib loop lib loop lib wu ftpd sendmail polymorph .
.
gzip .
.
grep tightvnc .
.
putty .
snort .
.
in table ii are useful in modeling loop impact as well as the behaviors of some string library calls such as strcat .
a piecewise linear model shown in the fifth row in table ii is a natural fit for reasoning the semantics of if then andelse statements or library calls such as strncpy andstrncat .
integrating dynamic information potentially leads to unde rapproximation and summarizing such information may lead to over approximation.
we manually inspected the transfer functions discovered by our dynamic inference and we did not find imprecise relations.
this precision is achieved by runn ing tests on small code segments for coverage constraining tes t inputs based on the context of code segments in the orignial programs and using regression analysis for summarization .
scalability our experiments are run on a windows machine with duo intel core i7 cpu and .
gb memory.
each benchmark program is finished within .
g memory.
the time used for the two types of symbolic analyses are given in table v. under size we display the sizes of the benchmark programs using lines of code.
we show the time used for the basic symbolic analysis infeasible path detection under t inf and buffer overflow detection under t buf .
the results indicate that the time used for analysis is not linear to the program size.
since the analysis terminates when static unknowns ar e discovered a larger program with more complex code may take a shorter time to analyze than a smaller program with simpler code.
we list the total time used for the segmented symbolic analysis under segmented symbolic analysis t inf and t buf .
we also give the total time used for the dynamic analyses inclu ding constructing and running tests and performing regressi on analysis under i inf and i buf .
since helium concurrently runs symbolic and dynamic analyses the accumulated timefrom multiple dynamic analyses could be more than the total time used by the segmented symbolic analysis.
we display the number of threads invoked during the analysis under threadinfandthread buf .
our experimental results show that segmented symbolic analysis generally takes longer to analyze a program compar ed to basic symbolic analysis as it performs dynamic analyses .
also when a static unknown is unblocked more code is potentially analyzed.
although slower segmented symboli c analysis is still reasonably scalable.
for the most expensi ve benchmark snort we finished infeasible path detection and buffer overflow detection both within an hour.
c. the capabilities of segmented symbolic analysis in table vi we provide a summary of the types of loops and library calls helium can and cannot handle.
the first tabl e on the left displays a set of libraries that we successfully analyzed.
these are the library calls that manipulate strin gs file systems and i o. in the table labeled libno we list types of library calls helium currently does not handle.
these lib rary calls are the general challenges faced by any dynamic analys is.
to infer the semantic information for calls such as strrchr andgetenv we need specially crafted test inputs to supply the string contents required to reason their behaviors.
for cal ls such as malloc we are not able to obtain the buffer size since the c language does not support a managed heap.
for calls that access networking resources such as sockets we need to model client server behaviors in testing.
for similar reas ons calls related to user interactions such as getchar are not yet handled in our testing.
on the right in table vi we display a set of challenges for analyzing loops.
the first row of the table indicates that we do not yet handle nested loops.
similar to library calls we cannot handle loops that access network resources or involv etable v scalability of segmented symbolic analysis benchmarksize symbolic analysis segmented symbolic analysis kloc t inf t buf t inf i inf thread inf t buf i buf thread buf wu ftpd .
.
s .
s .
s .
s .
s .
s sendmail .
.
s .
s .
s .
s .
s .
s polymorph .
.
.
.
s .
s .
s .
s .
s .
s gzip .
.
.
.
s .
s .
s .
s .
s .
s grep .
.
s .
s .
s .
s .
s .
s tightvnc .
.
.
.
s .
s .
s .
s .
s .
s putty .
.
.
s .
s .
s .
s .
s .
s snort .
.
.
.
s .
s .
s .
s .
s .
s table vi thecapabilities of segmented symbolic analysis libyes type example string strcpy strcat strlen strncpy strdup file system chdir getcwd rename unlink stat i o printf fgets fgetc read misc perror utime inet addr atoilibno type example string content strrchr getenv compiler unknown malloc network resource recv gethostbyname interactive input getcharloopno type example complex loops nested loops network resource recv interactive input getchar invalid context figure user interactions.
there are also loops that only can be run w ith a specially constructed test input.
as an example in figure we display a code snippet discovered in tightvnc .
the code is used to render a window.
the index of array rcolors in the loop is computed through a bit operation.
our randomly generated inputs are not always able to produce a valid index and thus the unit test for this loop crashes from time to time.
non a n a l y z a b l e loop due t o t h e i n v a l i d c o n t e x t f o r n n pfburh r .w n r c s o u r c e r c o l o r s n fig.
.
a loop that cannot be handled by segmented symbolic anal ysis segmented symbolic analysis is able to analyze loops that contain pointers conditional branches and library calls which static analysis is not capable to determine.
in figure we show an example discovered in the sendmail benchmark.
this loop contains the library calls isascii isupper and tolower anifconditional branch and some pointer operations.
basic symbolic analysis only can determine that the string is pote ntially modified in the loop.
our dynamic analysis successful ly reasons that the loop does not have an impact on len p and thus we can safely use the unchanged symbolic value forlen p at the loop exit.
loop h a n d l e d by segment s y m b o l i c a n a l y s i s f o r p name p !
p i f i s a s c i i i n t p i s u p p e r i n t p p t o l o w e r p t r y a g a i n true fig.
.
the power of segmented symbolic analysis in reasoning l oopsvii.
r elated work symbolic analysis has a variety of applications in software engineering.
examples include infeasible path detection test input generation bug detection and debugging .
due to its importance a set of symbolic analysis tools has been developed .
most of these tools are motivated by software testing with the goal of exploring as many paths as possible.
for example s2e starts with a concrete execution and initiates symbo lic execution at places where detailed checks are needed.
our work is motivated by precise static analysis in that we use dynamic analysis to generate a summary for code segments of interest and our goal is to produce symbolic conditions for the code that static analysis is not able to automatically analy ze.
in table vii we compare four representative hybrid symbolic tools.
under order we show that check n crash and dsd run static and dynamic analyses sequentially while concolic testing and segmented symbolic analysis run them concurrently.
the difference between our tool and concolic testing is that segmented symbolic analys is can flexibly select code segments on demand for dynamic analysis but concolic testing always runs tests for the entire p rogram.
under size of test program we see that check n crash and dsd run tests for procedures and only report invariants a t the entry or exit of a procedure.
we also compare the four tool s on where static and dynamic analysis exchange information under interaction location and what information to exchange under exchange information .
compared to other tools our analysis requires no executables or test inputs the intera ctions of static and dynamic analyses are based on demand and thus more efficient and the dynamic information is aggregated from multiple runs and thus is more confident.
loops and library calls are challenges for all symbolic tool s. research has been done on refined local analysis to reason loops and library calls .
sankaranarayanan ettable vii compare four types of hybrid symbolic tools hybrid symbolic analysis order size of test program interaction location exchange information check n crash first static then dynamic procedure likely buggy locations safety constraints dsd first dynamic then static procedure entry of the procedure program invariants concolic testing concurrent same code entire program static unknowns some concrete value segmented symbolic analysis concurrent different code code segment on demand static unknowns symbolic values transfer functions al.
applied inductive logic programming and decision tree learning to infer specifications of libraries.
the focus is t o understand how the exceptions are handled in the library.
gopa n et al.
performed binary analysis to determine summaries for library calls.
our work provided linear models to approxima te the behaviors of any small segments of code.
our work is also related to discoveries of program invariants.
diakon instruments the programs and based on the values at program points it determines whether a predefined invariant potentially holds at a program point .
compar ed to diakon we infer transfer functions rather than program invariants and we apply regression analysis to determine t he symbolic relations between variables.
viii.
c onclusions and future work this paper presents segmented symbolic analysis a novel hybrid technique that flexibly weaves static and dynamic ana lyses on demand for their maximum capabilities of discoverin g program semantic information.
the two key challenges we addressed here are partitioning a program to construct val id unit tests for dynamic analysis and mapping the problems of discovering symbolic relations between program variabl es to regression analysis.
our experimental results show that segmented symbolic analysis can address the loops and library calls that cannot be analyzed by traditional symbolic analysis.
it is fully automatic and can be generally applied for determining different program properties and for diffe rent programs.
our future work includes extending the technique s to handle pointers and recursive calls and to further improv e the code partition strategies.