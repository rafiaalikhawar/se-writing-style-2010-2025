improving automated documentation to code traceability by combining retrieval techniques xiaofan chen department of computer science university of auckland auckland new zealand xche044 aucklanduni.ac.nz john grundy centre for computing engineering software systems swinburne university of technology melbourne australia jgrundy swin.edu.au abstract d o c u m e n t a t i o n w r i t t e n i n n a t u r a l l a n g u a g e a n d source code are two of the major artifacts of a software system.
tracking a variety of traceability links between software documentation and source code assists software developers in comprehension efficient development a n d effective management of a system.
automated traceability systems to date have been faced with a major open r e s e a r c h c h a l l e n g e how to e x tract these links w i t h b o t h h i g h p r e c i s i o n a n d h i g h recall.
in this paper we introduce an approach that combines three supporting techniques regular expression key phrases and clustering with a vector space model vsm to improve the performance of automated traceability between documents and source code.
this combination approach takes advantage of strengths of the three techniques to ameliorate limitations of vsm.
four case studies have been used to evaluate our combined technique approach.
experimental results indicate that our approach improves the performance of vsm increases the precision of retrieved links and recovers more true links than vsm alone.
keywords component traceability vector space model regular expression key phrases clustering i. introduction source code alone is not sufficient to capture all information about a software system.
software requirements architectural decisions detailed design tutorials and user documentation and various types of technical system documentation e.g.
deployment configuration are important artifacts p r o d u c e d w h i l e e n g i n e e r i n g s o f t w a r e s y s t e m s .
tracing and maintaining interrelationships between these various forms of software documentation and source code enables software engineers to better understand systems undertake improved maintenance of systems and ultimately to produce higher quality systems .
however this relies on retrieving high quality c a n d i d a t e l i n k s b e t w e e n elements in one artifact e.g.
code constructs and elements in another e .
g .
r e q u i r e m e n t s a n d d e t a i l e d d e s i g n documentation .
a set of high quality candidate links represents a link set between these artifacts that contains as many correct links as possible and as few fault links as possible.
moreover a high quality candidate link set should connect elements of different artifacts at a fine grained level of detail e.g.
part of a design document description and its related source code elements.
however it is very challenging to automatically extract high quality candidate links between the w i d e v a r i e t y o f a r t i f a c t s c r e a t e d d u r i n g the software development life cycle .
many traceability recovery techniques have b e e n invented to retrieve traceability links between artifacts .
some need human intervention others can automatically generate traceability links .
unfortunately no recovery approaches have the capability of recovering all possible links between artifacts automatically and accurately.
this is due both to the inherent imprecision when expressing things in natural language and inherent information loss or addition when moving between software artifacts at differing levels of abstraction.
s o m e p o t e n t i a l l y useful and important links are missed by existing techniques.
similarly some incorrect or unuseful links are extracted and may confuse developers.
most existing automated traceability techniques adopt a single approach to trace link retrieval.
however different link retrieval approaches have different strengths and weaknesses.
to try and improve the performance of automated traceability l i n k r e t r i e v a l we have developed an approach that combines a vector space model vsm ir approach with three supporting techniques regular expression re key phrases kp and clustering.
these particular t e c h n i q u e s h a v e q u i t e d i f f e r e n t s t r e n g t h s a n d weaknesses and recover different sets of links due to their vastly different retrieval approaches.
our approach attempts to t ake advantage of strengths of these techniques to automatically recover links between artefacts a t b o t h h i g h precision and high recall.
o u r p a r t i c u l a r f o c u s i s o n retrieving links between class entities and sections in documents written in natural language e .
g .
tutorials handbooks developer or user s guides api documentation architecture d o c u m e n t a t i o n design rationale emails and so on.
the objective of this research is to demonstrate whether our new composite traceability link recovery approach can improve the automatic recovery of traceability links with high precision and recall.
we have conducted a detailed experiment with four case studies to evaluate the strengths and weaknesses of our approach.
analysis of experimental results demonstrates that our approach improves the performance of vsm increases the precision of retrieved links and recovers more true links than vsm alone.
this paper is organized as follows.
related work is discussed in section .
section describes our traceability link recovery approach and each technique we have applied.
a description of the implementation of our tool is described in section followed by the experimental results in section .
section analyzes these results.
finally we draw conclusions in section .
ii.
related work due to the importance of traceability link recovery extensive effort in the software engineering research community has been put into improving the precision and recall of recovered traceability links between documents and code through various traceability recovery techniques.
these approaches can be classified into two main groups semi automatic recovery and automatic recovery.
a. semi automatic techniques semi automatic recovery techniques are those that need human intervention during the traceability link extraction process such as rule based scenario driven and value based approaches.
rule based approaches use traceability rules to define traceability relations between tracing documents.
since these approaches are dependent on grammatical structures present in the natural language sentences traceability rules have to be expanded to allow generation of relations that consider all possible grammatical structures.
moreover building rules is time consuming.
the scenario driven t e c h n i q u e combines the hypothesized traces and test scenarios that are executed on a running software system to generate traceability relations.
it requires test and usage scenarios to be linked to classes in the source code and it does not support tracing links to program variables and other types other than classes.
in addition the correctness and completeness of the hypothesized traces largely affects the quality of recovered links.
the value based a p p r o a c h does not treat every artifact as equally important so not all trace relationships are equally important in the context of traceability.
the value based approach p r o d u c e s h i g h q u a l i t y t r a c e relationships among high value artifacts on a finer grained level of detail but the quality of relationships among low value artifacts is undesirable because they are based on a coarser grained level of detail.
although this approach can save cost due to its focus on artifacts with high value the determination of the value of every artifact is complex and time consuming.
b. automatic techniques automatic recovery techniques include l i g h t w e i g h t a n d heavyweight techniques.
lightweight techniques d o n o t require pre computation of the input and c a n b e d i r e c t l y executed at run time.
bacchelli et al build regular expressions to match class names to words in emails.
their experimental results show that the regular expression re approach achieves good accuracy.
the drawback is that this approach fails to retrieve links between classes and emails where class names don t explicitly appear but are mentioned implicitly such as an email that describes tasks that a class should fulfill but does not directly mention its name.
heavyweight techniques by c o n t r a s t require pre processing of their input.
these t e c h n i q u e s i n c lude information retrieval ir and text mining tm .
many traceability recovery techniques to date make use of a variety of information retrieval ir approaches to automatically recover traceability links.
however the accuracy rate of link recovery by using ir heavily relies on a cut point only links that have a similarity value greater than or equal to the cut point are shown to users .
the same cut point m a y o r m a y n o t b e s u i t e d to d i f f e r e n t software systems.
using a low cut point retrieves a larger number of accurate true links than using a high cut point but more incorrect fault links are captured at the same time.
antoniol et al.
apply two different ir models probabilistic model pm and vector space model vsm to extract links between code and documentation.
the results show that ir provides a practical solution for automated traceability recovery.
the two ir models have similar performances when terms in artifacts perform a preliminary morphological stemming.
a traceability recovery tool based on pm was developed to explore how the retrieval performance can be improved by learning from user feedback .
the results show that significant improvements are achieved both with and without preliminary stemming .
cleland huang et al.
propose an approach to improve the performance of dynamic requirements traceability by incorporating three different strategies into pm namely hierarchical modeling logical clustering of artifacts and semi automated pruning of the probabilistic network.
the results indicate that the three strategies effectively improve trace retrieval performance.
settimi et al.
investigate the effectiveness of vsm and vsm with a general thesaurus for generating links between requirements code and uml design models.
the comparison results show that precision and recall are not improved by the use of the general thesaurus.
hayes et al.
use vsm but with a context specific thesaurus that is established based on technical terms in requirement documents to recover links between requirements.
the results show that improvements in recall and sometimes in precision are achieved.
marcus and maletic introduce latent semantic indexing lsi an extension of the vsm to recover links between documentation and source code.
the results show that lsi achieves very good performance without the need for stemming as required for pm and vsm.
wang et al.
present four enhanced strategies to improve lsi namely source code clustering identifier classifying similarity thesaurus and hierarchical structure enhancement.
the comparison results indicate that this approach has higher precision than lsi and pm but has lower recall.
a l t h o u g h various strategies have been applied to enhance the performance of ir t e c h n i q u es no approaches to date can largely decrease fault links at low cut points and significantly increase true links at high cut points .
the tm technique organizes related texts in documents to extract domain specific information from texts .
witte et al employ information extraction a subfield of tm to capture traceability links through extracting entities e.g.
methods classes packages etc.
from software documents.
its limitation is that it can only extract from documents salient facts about pre specified types of events entities or relationships though it generates relationships with high accuracy .
types of entities have to be pre defined and grammar rules have to be built for detecting complex named entities.
to varying degrees none of the traceability recovery techniques developed so far is able to produce sufficiently consistent and high enough quality results to meet developer s needs.
semi automatic techniques are unable to generate traceability links automatically without human intervention.
it is difficult to employ these techniques to retrieve traceability links between artifacts in a system f o r people who are unfamiliar with t h e s y s t e m .
a l t h o u g h automatic techniques improve this issue their limitations impede them from capturing all potential true links and few fault links.
iii.
our approach in order to recover traceability links at a high level of precision and recall w e h a v e e x p l o r e d an approach incorporating three supporting techniques regular expression re key phrases kp and clustering into a vector space model vsm to recover links between sections in documents and class entities.
our approach i s intended to overcome the limitations of vsm by taking advantage of strengths of re kp and clustering.
we use an ir model vsm as the fundamental basis of our approach as v s m c a n r e t r i e v e a l l p o t e n t i a l l i n k s w i t h appropriate queries.
however vsm has three main limitations .
first very few true links are retrieved at high cut points.
second many fault links are captured at low cut points.
the third limitation is that vsm misses links in the following two situations class names that do not follow a c o m m o n n a m i n g c o n v e n t i o n strategy and documents that use different words to describe related classes.
combining the first supporting technique regular expression re with vsm allows extraction of more true links at high cut points.
as long as class names are retrieved correctly and refined regular expressions are built re c a n retrieve all possible links that are related to these class names and return few fault links as well.
we added the second technique key phrases kp to our approach to recover links missed by vsm.
we extend the vsm queries to include key phrases of comments in the source code.
if code is well commented kp can extract key phrases from code comments closely related to classes.
clustering the third t e c h n i q u e incorporated aims to eliminate fault links at low cut points by refining existing retrieved traceability links.
as the aim of our approach is to trace u s e f u l links between class entities and sections in documents we take advantage of the inherent hierarchical structure of documents to cluster links retrieved by vsm re and kp.
therefore our combination approach increases the precision at any cut point and retrieves links with a high recall.
the following section describes the four techniques used in detail.
a. the basic retrieval approach information retrieval ir is widely used in searching fields s u c h a s w e b s e a r c h e n g i n e s a n d l i b r a r y d o c u m e n t search.
we decided to employ a n i r t e c h n i q u e as t h e foundation of our traceability links retrieval approach as its query based approach has potential to recover all types of link if appropriate queries are constructed.
the ir engine we employed is apache lucene which is a full featured text search engine written in java .
we chose this as it is broadly used for ir experimentation and practice.
lucene uses vsm to index text and determine how relevant a section is to a query .
as many papers h a v e extensively discussed vsm we only briefly describe how queries are built and similarity scores of links are calculated.
a class name or identifier composed of two or more words is split into separate words.
a query string for vsm is established by using the or operator to combine the name and the separated words.
for example dragsource is split into the words drag and source then the query string is dragsource or drag source or drag or source .
the query is case insensitive.
the output of the indexing process is a term by document matrix where term r e p r e s e n t s a l l w o r d s t h a t o c c u r i n documents and document i n d i c a t e s a l l d o c u m e n t s i n t he vsm corpus.
each entry ai j of this matrix denotes a weight for the frequency of the ith t e r m i n t h e jth d o c u m e n t .
e a c h matrix column is considered as a vector that describes a document.
queries are represented in a similar way by a matrix where each vector indicates a query.
the similarity between a document and a query is measured by the cosine of the angle between the corresponding vectors.
in other words a matching document may have one or more query terms and is ranked based on the frequency of term occurrence and number of query terms present in the document .
in the end traceability links between documents and classes are retrieved.
each link has a similarity score to display how much the related document and class is matched.
there are three main drawbacks w i t h u s i n g v s m .
t h e method calculating link similarity values results in some true links with a very low similarity score and t h e m a j o r i t y o f retrieved links have low similarity values.
therefore the lower the cut point that is used the more possible links are retrieved but also the more fault links are captured as well.
this leads to the first limitation that very few true links are captured at high cut points.
the second limitation i s t h a t many fault links are extracted at low cut p o i n t s .
t h e t h i r d limitation is that links are missed in the following two situations class names not following a n a m i n g c o n v e n t i o n strategy and documents using d i f f e r e n t words to describe related classes.
we have found that these are both common occurrences in many software documentation artifacts.
b. regular expression re in order for us to augment the number of retrieved links at high cut points a re technique is used.
a regular expression which is a pattern of characters that describes a set of strings is constructed and used to find all of the occurrences of this p a t t e r n i n a n i n p u t s e q u e n c e .
h e r e w e use res to find class names in documents.
it i s c a s e sensitive.
class names can be placed into two groups.
one group is class names containing o n l y o ne word such as control main graphics etc.
another is class names formed by compound words such as namingexceptionevent dragsource etc.
for the second group class names are most likely not part of common words that can be found in a dictionary.
therefore once they appear in documents most likely they represent class names.
for the first group class names probably belong to common words.
then we need to make sure the same words found in documents indicate class names and not other names.
for the s e cond group simply matching class names against their occurrence in documents s u f f i c e s. from inspection of typical documents we observe that class names can be surrounded by a wide variety of non word characters but must exclude the hyphen .
a hyphen attached before or after a class name can be part of another class name.
for example the string dragsource matches a class named dragsource but also a class name is written as dragsource listener in documents when a class name is separated over t w o lines and is connected by a hyphen dragsource is at the end of a line listener is at the beginning of the following line.
it raises another issue that hyphens may exist inside class names e.g.
dragsource listener .
therefore we extend the regular expressions developed by bacchelli et al to the following regular expression code take the class named control for the example .
a za z0 c ?o ?n ?t ?r ?o ?l a za z0 .
in order to identify class names in the first group we can additionally match different parts of the package name of a class in documents.
for example a p a c k a g e n a m ed javax.naming.event has three parts javax naming event.
it is not feasible to require the package name to be presented before the class name because it is very rare that a package name is cited before the class name in documents.
if the class name the last part of the package name and at least one of other parts o f the package name are found then the single word in documents denote a class name.
t h i s m e t h o d a l s o can apply to identify classes sharing the same name b u t belonging to two different packages.
the regular expression code for matching each part of package names is .
a za z0 each part of package name a za z0 .
these two regular expressions can correctly capture all documents directly containing class names and return few unrelated documents.
therefore links recovered by re a r e considered as true links they are assigned with the highest similarity value.
this largely expands the retrieved link sets at high cut points but does not change the fault links recovered by vsm.
this approach still fails to retrieve links that are missed by vsm.
both tm discussed in section and re can fulfill class name entity recognition.
we found through experimentation that the results obtained from both approaches are the same.
however t m s p e n d s m u c h m o r e t i m e t h a n r e a n d combining tm into our traceability recovery system made the whole system much slower than re.
therefore we chose to use re rather than more sophisticated tm techniques in our current tool.
c. key phrases kp key phrases provide a brief summary of a document s content .
we wanted to use the kp technique to extract key words or key phrases from comments of code to provide a brief summary of each class s d e s c r i p t i o n comment and use these to augment our vsm t e c h n i q u e s link recovery.
there are two situations where vsm is unable to retrieve correct links.
firstly when class names do not follow a naming convention strategy vsm s t r u g g l e s t o r e t r i e v e documents that do not explicitly mention the class name.
for example for a class named refaddr its vsm q u e r y i s refaddr or ref addr or ref or addr vsm is unable to retrieve documents n o t c o n t a i n i n g refaddr a s ref and addr a r e n o t c o m m o n w o r d s .
s e c o n d l y d o c u m e n t s implicitly mentioning a class but not explicitly using the same word as the class name or separated w o r d s o f t h e compounded class name are also problematic.
for example a class named media but where documents m a y u s e medium t o i n d i c a t e t h i s c l a s s .
w e h a v e f o u n d that these two issues can be addressed by taking the comments in source c o d e i n t o c o n s i d e r a t i o n .
g e n e r a l l y s o f t w a r e developers provide comments to describe the purpose of the class or what tasks the class fulfills.
extracting key phrases from comments can help find alternative words to the class name or words indicating what tasks the class fulfills.
for example medium indicates the class media reference address r e f e r s t o t h e p u r p o s e of the class refaddr .
as long as comments in each classes are well documented kp can extract all possible key phrases that summarize the purpose of each class.
we found that adding these extracted key phrases to the vsm q u e r i e s e n a b l e s our approach t o work in the above two contexts.
however many fault links at low cut points are also recovered.
d. clustering in general every document has an inherent hierarchical structure.
documents are usually divided into sections with headings.
each section has a direct p a r e n t o r s o m e d i r e c t children or some siblings.
there exist tangled relationships between these sections.
for example in this paper section .a t h e b a s i c r e t r i e v a l a p p r o a c h h a s a d i r e c t p a r e n t section our approach and three siblings sections .b .c and .d .
it has no children.
section .a .b .c and .d cross reference each other to some extent.
we take advantage of these tangled relationships to reduce the number of fault links retrieved by using clustering.
clustering is a division of a set of objects into groups of similar objects c l u s t e r s .
w e m o d i f y t h e k mean clustering algorithm to meet our needs.
there are three main steps i n t h i s initialization assignment and removal.
we take links between the class java.awt.dnd.dragsource and sections in a document as an example to illustrate our clustering algorithm.
table shows an example where sections are related to dragsource .
each line represents a link and lines colored blue and italicized refer to true links.
before starting the initialization step all retrieved links are grouped based on classes namely links related to the same class are grouped together.
clustering is performed on each group that represents sections related to the same class.
then the algorithm s e l e c ts k c l u s t e r s according to the number of links with similarity values !
s. each cluster contains one of these related sections.
when the group contains links with a similarity value that equals to then the algorithm uses s .
otherwise the algorithm uses s .
to create clusters.
from empirical observation we found four reasons to use this latter value when none of the links similarity value in the group is equal to .
firstly a majority of the fault links have a similarity score .
.
secondly links with similarity !
.
are more likely to be true.
t h i r d l y i f w e u s e s .
our approach retrieves many f a u l t l i n k s a n d only slightly more true links.
fourthly if s !
.
our approach slightly decreases the number of fault links but does not obtain more true links.
empirically therefore we found the .
threshold to be t h e b e s t c h o i c e f o r t h e t a r g e t s y s t e ms u s e d i n o u r experiment.
we need to conduct more experiments however to validate its s u i t a b i l i t y f o r o t h e r s y s t e m s .
in table links have a similarity score .
the algorithm thus creates clusters each one containing one of these sections.
table i. sections related to java.awt.dnd.dragsource next the algorithm assigns the direct parent all direct children and all siblings of the initial section to the cluster but only new sections that aren t already in other clusters and are in the retrieved link set.
take the cluster for section .
in table for example sections .
.
.
.
.
.
.
.
and .
are not assigned to this cluster as they belong to other clusters and section .
is not assigned as i t i s n o t i n t h e retrieved link set.
lines colored by red bold and blue italics indicate links included in clusters.
finally links not in clusters are discarded.
thus in this case links out of are discarded in the group for dragsource .
we have found that our clustering approach e l i m i n a t e s many f a u l t l i n k s a t low cut points.
iv.
implementation figure illustrates the traceability recovery process of our approach.
first if a document contains sections it is partitioned into small sub documents according to sections or headings .
for example if a pdf document contains headings i n c l u d i n g a l l s u b headings it is split into sub documents the contents of each are the text b e t w e e n i t s heading and the following one.
these sub documents are then preprocessed.
next source code is analyzed by the code dependency analysis system in order to extract source code identifiers every class method package name and comments inside code .
code dependency analysis is based on eclipse s jdt java parser .
these extracted class names are passed to the regular expression r e p r o c e s s o r t o f i n d s e c t i o n s that directly mention class names .
links retrieved by the re processor are assigned the highest similarity score and form the re link set.
figure .
traceability recovery process of our approach at the same time extracted comments inside code are passed t o t h e k e y p h r a s e s e x t r a c t i o n s y s t e m .
t h i s i s based on kea a keyphrase extraction algorithm developed by witten et al.
.
this extracts key phrases from comments.
these extracted key phrases are combined with extracted class names to form ir queries .
a query string for ir is established by using or operators to combine the class name the separated words if the class name is formed by compound words and key phrases extracted from comments in the class code.
before using the apache lucene ir engine to capture links between sections and class entities sections in documents are p r e p r o c e s s e d .
l u c e n c e p r e p r o c e s s i n g starts by generating tokens from consecutive letters in the text stream according to token boundaries that are defined at non letter characters.
next non textual tokens i .
e .
s p e c i a l symbols numbers etc.
are dropped.
a lower case filter source code code dependency analysis comments class names key phrases extraction key phrases queries builder ir engine regular expression documents preprocessing corpus links integrator clustering traceability links .
dnd1.pdf .
overview .
dnd1.pdf .
.
draggesturerecognizer .
dnd1.pdf .
drag source .
dnd1.pdf .
.
the dragsource definition .
dnd1.pdf .
.
the dragsourcecontext definition .
dnd1.pdf .
.
the dragsourcedragevent definition .
dnd1.pdf .
.
the dragsourcedropevent definition .
dnd1.pdf .
.
the droptargetcontext definition .
dnd1.pdf .
.
the droptargetlistener definition .
dnd1.pdf .
.
the droptargetdragevent and ... .
dnd1.pdf .
data transfer phase .
dnd1.pdf .
.
flavormap and systemflavormap .
dnd1.pdf .
.
transferring data across the jvm ... .
dnd1.pdf .
.
what are the implications of the ... .
dnd1.pdf .
.
lifetime of the transferable s ?
.
dnd1.pdf .
.
implications of action ... .
dnd1.pdf .
.
the dragsourcelistener definition .
dnd1.pdf .
.
transferring lists of files across... .
dnd1.pdf .
.
the dragsourceevent definition .
dnd1.pdf .
.
inter intra vm transfers?
.
dnd1.pdf .
.
semantics of action ... .
dnd1.pdf .
.
java.awt.component additions... .
dnd1.pdf .
.
transferring java.rmi.remote ... .
dnd1.pdf .
issues .
dnd1.pdf .
api .
dnd1.pdf .
.
the droptarget definition .
dnd1.pdf .
provision of a platform independent .
dnd1.pdf .
drag gesture recognition .
dnd1.pdf .
integration with platform ... .
dnd1.pdf appendix a droptargetpeer definition .
dnd1.pdf .
requirements .
dnd1.pdf .
.
autoscrolling support .
dnd1.pdf appendix b dragsourcecontextpeer definition .
dnd1.pdf appendix c droptargetcontextpeer definition transforms all capital letters into lower case letters and a stop words filter removes common words i.e.
articles adverbs etc.
.
finally an ir corpus is generated containing all documents and words or tokens in the documents.
the ir engine r e t r i e v es t r a c e a b i l i t y l i n k s a c c o r d i n g t o q u e ries and computes similarity scores s i m i l a r i t y s c o r e based on the frequency and distribution of the key words or phrases .
recovered links forms the ir link set.
the re link set and the ir link set are then merged together .
if a link can be found in both sets then the one in the ir set is removed and we leave the link in the re set i.e.
with higher rank .
finally the merged link set passes through the clustering system to refine the link set to produce the final candidate traceability links .
to make the extracted traceability links useful for maintainers our final s t e p is to visualize r e c o v e r e d l i n k s allowing u s e r s t o b r o w s e a n d m a i n t a i n t h e s e l i n k s i n a natural and intuitive way.
we use a hierarchical graphical traceability link v i s u a l i z a t i o n t h a t c a n b e e x p a n d e d a n d contracted to enable users to interact with large numbers of extracted relationships.
a screen dump of a prototype version showing links visualization i s s h o w n i n f i g u r e .
here a software engineer has selected a source file printjob.java and its related sections retrieved by our link recovery technique in the file jps pdf.pdf are highlighted.
figure .
a screen dump from our eclipse based prototype tool in use.
v. evaluation a. case studies to validate the effectiveness of our approach we have set up four case studies based on four unrelated software systems.
the first system we used is jdk .
a free software system for java developers.
table describes the packages in jdk .
and their corresponding pdf documents used in this study as well as the number of java c l a s s e s a n d t h e number of sections in them.
we divided these pdf files into sections based on their headings.
this case study contains true links.
we describe how w e b u i l t t h e o r a c l e traceability link set for jdk .
in section .c.
the systems used for the other three case studies are argouml freenet and jmeter.
alberto bacchelli kindly provided the three systems their email archives and their oracle traceability link sets.
these emails were extracted from active development mailing lists of each project.
table provides details of these three case studies.
table ii.
jdk1.
packages and documents jdk .
classes sections java packages java.awt javax.naming and javax.print packages jps pdf.pdf javatm print service api user guide dnd1.pdf drag and drop subsystem for the java foundation classes jndispi.pdf java naming and directory interfacetm service provider interface jndi spi pdf files total sections table iii.
class entities emails and total true links per system classes emails total true links argouml freenet jmeter b. evaluation metrics precision recall and f measure are common metrics used in the evaluation of ir systems.
the three metrics depend on three figures correct or true links retrieved fault links retrieved and missing links.
correct links retrieved are those that are correctly captured by the system.
fault links are those that are wrongly detected by the system.
total links retrieved combine these two kinds of link.
relationships that are not found by the system are called missing links.
total correct links are the sum of correct links retrieved and missing links.
precision can be defined as the ratio of the number of correct retrieved links over the total number of retrieved links.
if precision equals it means that all the recovered links are correct though there could be correct links that were not recovered.
precision correct links retrieved total links retrieved recall is the ratio of the number of correct retrieved links over the total number of correct links.
recall indicates that all correct links are recovered but there may be incorrect recovered links.
recall correct links retrieved total correct links the f measure combines precision and recall based on their weighted harmonic mean to measure the effectiveness of retrieval.
is an adjustable weight to favor precision over recall.
we take to weight precision and recall equally.
f measure precision recall 2recall precision two sets of traceability links between sections in documents and class entities are prepared in order to compute precision recall and f measure.
one set is produced by a system under evaluation the other is an oracle traceability link set carefully prepared manually section .
describes how the link set for jdk1.
is established the oracle link sets of argouml freenet and jmeter area as provided by alberto bacchelli .
the latter is critical as it is a crucial factor in determining the number of missing links.
comparison of the two sets is then conducted to determine whether a link is correct faulty or missing.
c. building the oracle traceability link set in order to build the oracle traceability link set for jdk1.
we employed a method of manually verifying trace links by a group as used in to build the oracle traceability link set for our case study jdk1.
.
we recruited analysts a n a l y s t s h ad a t l e a s t y e a r s o f j a v a programming experience and participants had more than years of java programming experience.
we set up two rules to assist participants in finding and verifying a link.
first if a section directly mentions a class identifier name then this section is related to this class.
the second rule is t h a t if a section describes tasks that a class should fulfill then they are related.
at the first stage the classes were divided into sets.
participants then manually retrieved links between sections in documents and classes by following the above two rules.
after they completed their task we asked another participant to verify these links.
at the second stage conflict links produced at the first stage were randomly divided into overlapping sets.
three other participants verified t h e s e conflict links by carefully studying the text of documents and the comments inside code.
after the three finished we asked a senior participant to verify those links still having conflicts.
this participant carefully studied the text of documents and the comments in code.
this participant also consulted with another senior participant.
each conflict l i n k was t h u s analyzed by at least participants.
when three reviewers agreed that the conflict link was a fault we considered this link to be a fault link and discarded it.
the final oracle link set c o m p r i s e d t r u e l i n k s .
o u r r i g o r o u s m a n u a l verification of the true links remedied any potential bias of adding incorrect links to the oracle link set .
d. evaluation results to evaluate whether the three supporting techniques re kp and clustering ameliorate limitations of vsm we compared the performances of four different combinations of techniques vsm the combination of vsm a n d re the combination of vsm re a n d kp and our final approach vsm re kp a n d c l u s t e r i n g .
t h e f o l l o w i n g s e c t i o n s describe the results produced by the four different combination techniques.
every approach recovers links with a similarity score !
the cut point.
for example the cut point is .
which denotes that all links having a similarity score !
.
a r e e x t r a c t e d b y o u r a p p r o a c h .
a cut point .
is considered as a low cut point in the following discussion.
otherwise we consider it to be a high cut point.
in figure we summarize the precision results of all approaches for the four case studies.
recall results of all approaches are in figure .
the basic retrieval approach first we used vsm to recover links between d o c u m e n ts and class entities t o discover vsm s p e r f o r m a n c e a t d i f f e r e n t c u t p o i n t s .
i t i s obvious from precision results in figure and recall results in figure that the lower the cut point used the lower the precision value but the higher the recall value vsm obtains.
although vsm retrieves a majority of true links at low cut points from to .
many f a u l t l i n k s a r e e x t r a c t e d especially at and .
cut points.
vsm g e t s t h e h i g h e s t precision value at .
cut point for jdk1.
and argouml and at .
cut point for freenet and jmeter but only recovers very few true links.
vsm and regular expressions re we t h e n evaluated the combination of vsm a n d re t o v e r i f y whether re c a n i n c r e a s e t h e n u m b e r o f r e t r i e v e d l i n k s a t high cut points.
figure shows t h a t a d d i n g re t o vsm improves precision at all cut points except for jmeter s .
and .
cut points.
in figure we observe that recall is largely increased at all cut points especially for high cut points.
this indicates that adding re to vsm retrieves more true links than vsm alone.
vsm re and key phrases kp to recover links missed by vsm we added a n a d d i t i o n a l t e c h n i q u e kp.
from figures and compared with the combination of vsm and re we see that after adding kp to vsm and re precision a t a l l c u t p o i n t s i s i n c reased f o r j d k .
a n d argouml but recall has a slight decrease.
however there is no significant improvement in freenet and jmeter.
compared with vsm adding kp still increases recall at all cut points except for the slight decrease at cut points from .
to .
for jdk1.
.
this shows that this combination retrieved more true links and less fault links than vsm.
vsm re kp and clustering incorporating clustering i nto the last combination aims to reduce the number of fault links but not deteriorate recall too much.
figures a n d show that our approach o f i n t e g r a t i n g t h e three supporting techniques with vsm fulfills the above two objectives.
precision is largely increased at all cut points especially at low cut points.
the majority of fault links are discarded at low cut points.
although our approach retrieves less true links than vsm alone at low cut points for jdk1.
and argouml at to .
cut points for freent and at to .
cut points for jmeter recall is only slightly reduced and still reaches a value !
f o r j d k .
f r e e n e t a n d jmeter and for argouml.
this shows that our approach largely reduces the number of fault links without suffering from low recall at low cut points.
e. performance of our approach we ran our approach on an imac with a .
ghz intel core duo processor and 3gb of ram.
figure shows that our approach took up to minutes to execute on each case.
for all cases this is times more than vsm times more than vsm re and up to s e c o n ds m o r e t h a n vsm re kp.
of time for jdk1.
and at least of time for other cases are spent on kp extraction.
it is because kea the key phrases processor in our approach uses an expensive machine learning algorithm for training and key phrase extraction .
our approach thus produces a much better result than the other combination techniques but is slower.
it is vastly faster than manually extracting links.
when building the oracle link set every participant spent one hour on average to identify related sections of classes.
figure .
execution times for different combinations vi.
discussion according to our experimental results precision i s gradually improved through incrementally adding techniques into the combination approach and is greatest when incorporating all three techniques with vsm.
adding re to vsm increases precision at high cut points from .
to .
and recall at all cut points.
analysis of the four case studies shows that documents contain many class names that enable re to match classes to documents.
further adding kp increases precision at all cut points for jdk1.
and argouml but slightly decreases recall.
freenet and jmeter are unresponsive to the kp technique.
analysis of source code reveals a low number of comments in their source code.
in addition the key phrases extracted from comments contain many key words unrelated to the purpose of classes.
finally precision at low cut points from to .
is greatly increased b y a d d i n g c l u s t e r i n g .
analysis of the four cases shows that documents h a v e i n h e r e n t h i e r a r c h i c a l s t r u c t u r e that provides useful hierarchical information for clustering to refine retrieved links.
our approach is able to obtain good precision at all cut points.
moreover recall for our approach is much higher than for vsm at high cut points but slightly less than for vsm at low cut points for jdk1.
and argouml at to .
cut points for freenet and at to .
cut points for jmeter.
therefore we conclude that our approach improves t h e precision of retrieved links and achieves high recall by utilizing the strengths of re kp and clustering to mitigate limitations of vsm.
vsm has three main drawbacks it recovers very few links at high cut points has low precision at low cut points and misses l i n k s i f class names do not follow the naming convention strategy and if documents use different words to describe the related classes.
combining re with vsm eliminates the first drawback of vsm.
adding kp to this combination ameliorates the third drawback of vsm.
finally integrating clustering ameliorates the drawback of many fault links produced by vsm.
furthermore the f measure results of all approaches in figure s h o w t h a t o u r a p p r o a c h i s t h e m o s t e f f e c t i v e among all approaches we evaluated if precision and recall are considered equally important.
the main limitation of our approach is that some true links are discarded after adding clustering.
this is because the group containing links related to a same class is totally removed when no links in the group have a similarity value larger than the threshold s value this leads to no clusters for this group being created.
true links in such groups are cut.
a jdk1.
b argouml c freenet d jmeter figure .
precision results for a jdk1.
b argouml c freenet and d jmeter a jdk1.
b argouml c freenet d jmeter figure .
recall results for a jdk1.
b argouml c freenet and d jmeter a jdk1.
b argouml c freenet d jmeter figure .
f measure results for a jdk1.
b argouml c freenet and d jmeter in future work we will experiment with allowing users to configure thresholds and select some or all techniques to apply to the extracted link set.
furthermore we will explore the impact of other techniques to refine the extracted links such as our visual ide s user creation and editing of links and both user and automated ranking of relationship quality.
in addition we will carry out a usability evaluation of our traceability relationship recovery approach and our trace link visualization tool to determine how effective they are in assisting users navigate b e t w e e n s o u r c e c o d e e l e m e n t s a n d associated documentation elements.
vii.
threats to validity first we relied on human judgment to build the oracle link set and thus this set might not correct.
to alleviate this we applied a very rigorous manual verification strategy to analyze every true link which were verified by at least analysts.
second our traceability recovery technique may show different results when applied to other software systems with other types of documents.
to alleviate this we chose unrelated open source systems.
these systems are varied in the sizes of the systems the types of documents the structures of documents and the availability of comments in source code.
however we cannot confirm that our results are similar in closed source systems.
viii.
summary it is a major challenge for traceability recovery techniques t o extract r e l a t i o n s h i p s b e t we e n d i v e r s e a r t i f a c t s of a software system at high levels of precision and recall.
many recovery techniques exist but none so far produces sufficiently consistent and high enough quality of results that software developers require.
our traceability system incorporates three supporting techniques re kp a n d clustering with vsm to extract links between documents and class entities.
the three techniques a m e l i o r a t e t h e k e y limitations of vsm by taking advantage of the respective strengths of each of the three supporting techniques.
our experimental r e s u l t s f r o m f o u r d i f f e r e n t c o m b i n a t i o n recovery approaches provide a demonstration t h a t our combination recovery approach can eliminate s o m e limitations of vsm.
our approach improves precision at all cut points reduces fault links at low cut points and increases the number of true links at high cut points.
acknowledgement the authors gratefully acknowledge alberto bacchelli for agreeing to share his exemplar test sets and oracles and the financial support of the foundation for research science and technology and university of auckland.