characterizing and predicting which bugs get fixed an empirical study of microsoft windows philip j. guo thomas zimmermann nachiappan nagappan brendan murphy stanford university microsoft research pg cs.stanford.edu tzimmer nachin bmurphy microsoft.com abstract we performed an empirical study to characterize factors that affect which bugs get fixed in windows vista and windows focusing on factors related to bug report edits and relationships between people involved in handling the bug.
we found that bugs reported by people with better reputations were more likely to get fixed as were bugs handled by people on the same team and working in geographical proximity.
we reinforce these quantitative results with survey feedback from microsoft employees who were involved in windows bugs.
survey respondents also mentioned additional qualitative influences on bug fixing such as the importance of seniority and interpersonal skills of the bug reporter.
informed by these findings we built a statistical model to predict the probability that a new bug will be fixed the first known one to the best of our knowledge .
we trained it on windows vista bugs and got a precision of and recall of when predicting windows bug fixes.
engineers could use such a model to prioritize bugs during triage to estimate developer workloads and to decide which bugs should be closed or migrated to future product versions.
categories and subject descriptors d. .
testing and debugging d. .
distribution maintenance and enhancement general terms human factors management measurement .
introduction validation often accounts for the majority of software development costs .
it encompasses activities such as debugging testing verification and bug tracking.
in both commercial and open source software large projects have to keep track of hundreds of thousands of bug reports.
as of august the mozilla bug database contains over and the eclipse bug database over bug reports.
on average mozilla received and eclipse new bug reports on each day from january to july .
bug triaging is the process of deciding which bugs should get fixed a decision that typically depends on several factors how bad is the bug s impact severity ?
how often does this bug occur permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
icse may cape town south africa copyright acm ... .
.
frequency ?
how much effort would be required to implement a fix?
what is the riskof attempting to fix this bug?
bug triaging is a pervasive process that extends far beyond developers and testers.
for example at microsoft employees regularly use and report bugs on versions of microsoft software that are under active development a practice known as dogfooding .
thus managers business staff customer service representatives and contractors also report and edit bugs.
people in office buildings in countries were involved in either opening handling commenting on or resolving windows vista bugs.
that is an order of magnitude greater than the developers who wrote code for vista .
some bugs are purposely left unfixed for some of the following reasons the bug occurs rarely and affects only a few users.
changes required to fix it could be large and expensive.
fixing it could introduce new bugs code changes that fix bugs are up to twice as likely to introduce new bugs as other kinds of changes .
users might be relying on existing behaviour and thus fixing the bug could break their systems.
ideally developer time should be focused on bugs that will actually get fixed.
however this is not always the case.
for example in the eclipse bug database unfixed bugs receive almost the same amount of attention as fixed bugs as measured by numbers of developer comments in the bug database .
comments on average vs. .
comments .
a better understanding of what bugs are fixed could inform the design of improved triage tools and policies that allow developers to more efficiently spend their time on bugs.
for this paper we analyzed windows vista and windows bug reports to characterize and predict which bugs get fixed with respect to the involved people bug reporter and assignees and their activities in the bug database e.g.
report edits reassignments and reopenings .
existing studies of bug triaging focus on assigning bugs to developers and detecting duplicates but to our knowledge there is no prior published academic study that characterizes which bugs get fixed.
our study contributes to the empirical body of validated research in bug fixing and informs the design of new bug tracking tools and policies.
.
contributions after surveying related work section and describing our experimental methodology section we devote the bulk of this paper to three main contributions characterization of which bugs get fixed in a quantitative study of windows vista and windows bugs we describe how people s reputations bug report edit activities and geographical and organizational relationships affect the chances of a bug getting fixed section .
we summarize the findings in a logistic regression model section .
qualitative validation of quantitative findings we conducted a survey of microsoft employees to obtain feedback on our characterizations of which responded.
these responses corroborated our quantitative findings and enriched them with qualitative insights section .
they also revealed additional influences on whether a bug gets fixed such as report quality perceived customer and business impact and seniority and interpersonal skills of the bug opener section .
statistical model to predict which bugs get fixed we developed the first model in the research literature to the best of our knowledge that can predict whether a bug gets fixed section .
such predictions help to prioritize bug reports and to decide which bugs to carry over to the next release of a product.
to ensure that this model can generalize we developed it and evaluated its performance on separate datasets windows vista and windows respectively .
we achieved a precision of and a recall of when predicting windows bug fixes.
we conclude by addressing threats to validity section and providing some recommendations for tool and policy design section .
.
related work several studies modeled the lifetimes of bugs investigating properties like time to resolve how long it takes a bug report to be marked as resolved where the resolution can be of any outcome e.g.
fixed wontfix duplicate worksforme .
hooimeijer and weimer built a descriptive model for the lifetime of a bug report based on self reported severity readability daily load reputation and changes over time.
panjer used information known at the beginning of a bug s lifetime such as severity component platform and comments to predict its time to resolve.
bettenburg et al.
observed that bug reports are fixed sooner when they contain stack traces or are easy to read.
anbalagan and vouk found that the more people are involved in a bug report the higher its time to resolve.
mockus et al.
found that in apache and mozilla bugs with higher priority are fixed faster than bugs with lower priority.
herbsleb and mockus observed that distributed work items e.g.
bug reports take about .
times as long to resolve as co located work items.
cataldo et al.
found that when coordination patterns are congruent with their coordination needs the resolution time of modification requests similar to bug reports was significantly reduced.
in contrast to these time to resolve studies we analyze and predict the probability that a bug is successfully resolved i.e its resolution outcome is marked as fixed .
several groups of researchers developed techniques to prioritize static analysis warnings by building models to predict which warnings are likely to get triaged and fixed kim and ernst using static analysis tools for open source java projects ruthruff et al.
for commercial java projects and guo and engler for open source c projects.
in contrast to these works we predict the likelihood of fix for bug reports in general and not just for static analysis warnings.
in addition we consider in our models bug report edit activities as well as people related factors like reputation and geographic and organizational relationships.
several studies characterized properties of bug reports and their edit activities bettenburg et al.
characterized what makes a good bug report.
by contrast this paper analyzes which bug reports get fixed.
while the quality of a bug report certainly influences the chances of getting the bug fixed there are additional factorsdiscussed in this paper such as edit activities developer relationships and severity.
aranda and venolia examined communication between developers about bug reports at microsoft to identify common bug fixing coordination patterns.
breu et al.
categorized questions asked in open source bug reports and analyzed response rates and times by category.
bettenburg et al.
quantified the amount of additional information in bug duplicates.
jeong et al.
analyzed the reassignment of bug reports called bug tossing and developed tossing graphs to support bug triaging activities.
ko et al.
conducted a linguistic analysis of bug report titles and observed a large degree of regularity.
however none of these studies characterized and predicted which bugs get fixed.
to improve bug triaging previous research proposed techniques to semi automatically assign developers to bug reports assign locations to bug reports recognize bug duplicates assess the severity of bugs and predict effort for bug reports .
with this paper we provide support for another triaging activity deciding which bugs should get fixed.
independently from us diederik van liere explored factors that affected which bugs were fixed in mozilla firefox he published his findings on his blog .
in another study he investigated how the information provided by open source community members influences the repair time of software defects .
empirical studies allow us to build a validated body of knowledge in software engineering and are crucial for informing the design of new bug tracking tools.
this paper adds a characterization of what makes bug reports successful to that body of knowledge.
.
methodology for this study we performed a quantitative analysis of bug datasets section built logistic regression models using features extracted from them sections and and analyzed results from a survey consisting of both multiple choice and free response questions sections and .
here are our data sources windows vista bug database our primary data source was the set of bug reports for windows vista containing all pre and postrelease bugs collected in july .
years after vista s release date .
we consider our dataset to be fairly complete for the factors we want to investigate since very few new vista bugs are being opened compared to when it was under active development.
for confidentiality reasons we cannot reveal the exact number of reports but it is at least an order of magnitude larger than datasets used in related work .
for each bug report we extracted a list of edit events that occurred throughout its lifetime.
each event alters one or more of these fields in the bug report editor who made this edit?
state opened resolved or c losed bug source how was the bug found?
see table for details.
bug type what kind of bug is it?
e.g.
bug in code specification documentation or test suite component path which component is the bug in?
e.g.
desktop shell navigation start menu severity an indicator of the bug s potential impact on customers.
crashes hangs and security exploits have the highest severity level minor ui blemishes typos or trivial cosmetic bugs have the lowest severity level .
opener who opened this bug?
assignee who is now assigned to handle this bug?bug source description human review code design spec security reviews code analysis tool automated program analysis tools ad hoc testing exploratory and ad hoc testing component testing unit tests model based tests system testing integration build stress tests customer reported by non microsoft user internal user reported by microsoft user table sources of windows vista bugs resolution status how was this bug resolved?
for this study we only care whether a bug was resolved as fixed or not.
other statuses include duplicate and won t fix .
null if state is not r esolved we excluded fields that were edited infrequently or unreliably.
most notably we excluded the priority field which represents a subjective rating of bug importance since there was too much inconsistency in how different teams within microsoft used it there are similar inconsistencies in open source projects .
here is a typical bug s life cycle when it is first opened all of its fields except for resolution status are set.
then the bug might be edited a few times e.g.
to upgrade its severity .
a special type of edit called a reassignment occurs when the assignee field is edited.
when somebody thinks he she has resolved the bug its resolution status field is set.
after the resolution attempt is approved usually by the opener the bug is closed.
however it might be reopened if the problem has not actually been properly resolved.
the main goal of our study is to characterize what factors lead a bug to be successfully resolved as fixed as opposed to related studies like hooimeijer and weimer that investigate whether a bug is resolved in any manner within a set period of time .
when a bug has been resolved more than once i.e.
it was reopened we use its final resolution status to determine whether it has been successfully resolved.
geographical data to correlate location related factors with bug fixes we obtained from people management software the building andcountry where each employee worked when vista was being developed.
sometimes people switch locations but in general microsoft tries to keep employees in the same location during a product cycle .
like bird et al.
we also considered campus e.g.
redmond silicon valley and continent as factors but our findings using those were so similar to simply using country that we omitted them for brevity.
organizational data nagappan et al.
found that organizational factors are correlated with bugs.
motivated by that study we obtained the name of each employee s manager which allows us to build an organizational tree and determine whether two employees are part of the same team i.e.
share the same manager .
microsoft employee survey to get feedback about the fidelity of our quantitative results we sent out an online survey to microsoft employees.
since we wanted to get the opinions of people well versed in handling windows bugs we chose as our survey participants the top of people who have opened been assigned to and resolved vista bugs.
the main question in our survey was in your experience how do each of these factors affect the chances of whether a bug will get successfully resolved as fixed ?we chose the factors based on bug opener reputation fixedfirst bug .
.
.
.
.
.
.
.
.
figure percent of fixed vista bugs vs. bug opener reputation rounded up to nearest .
.
first bug represents all bugs whose opener had never opened a bug before the current one.
the y axis is unlabeled for confidentiality.
our quantitative findings and asked respondents to rate the effect of each on bug fixes on a point likert scale ranging from significantly increase chances of fix to significantly decrease chances of fix we also included a no opinion option .
we concluded the survey with free response questions what are reasons why a bug might be reassigned multiple times why a bug might be closed then reopened multiple times and any other comments about what factors influence whether a bug gets fixed.
we received responses response rate .
most respondents were either developers or testers .
most were fairly experienced with a median of .
years of work experience in the software industry and years at microsoft.
we integrate our survey results into the findings of section and focus on the free response answers in section .
replicated study on windows after completing our study on windows vista we extracted bug reports from its successor project windows and replicated our study on it.
we used the entire bug database for the development period of windows years .
.
influences on bug fix likelihood in this section we present factors related to people and bug report edit activity that affect the likelihood of a bug being fixed.
our findings are consistent across both windows vista and windows but here we only present the vista results for space reasons section .
summarizes some differences with windows .
.
reputations of bug opener and 1st assignee we found that a bug opened by someone who has been successful in getting his her bugs fixed in the past has a better reputation with respect to bug reporting is more likely to be fixed.
we quantify reputation using the same metric as hooimeijer and weimer bug opener reputation openedtfixed opened for each bug we calculate its opener s reputation by dividing the number of previous bugs that he she has opened and gotten fixed by the total number of previous bugs he she has opened .
adding to the denominator prevents divide by zero for people who have never previously opened any bugs and more importantly prevents 1we copied their reputation metric verbatim to facilitate comparisons with related work.
building a robust meaningful and fair reputation metric is difficult and beyond the scope of this project.
editors fixed assignees fixed figure percent of fixed vista bugs vs. numbers of unique bug report editors and assignees.
vertical bars are confidence intervals for binomial probabilities most are invisible .
the y axes are unlabeled for confidentiality.
people who have opened very few bugs from earning high reputations without the extra 1term someone who has opened bug and gotten it fixed will have the same reputation as someone who has opened bugs and gotten all fixed intuitively the latter person should have a higher reputation which our metric ensures .
in figure we grouped windows vista bugs by ranges of opener reputations and plotted the percentage of bugs in each group that were fixed.
the leftmost two points were specially calculated the first bug point considers all bugs where the opener had not opened any bugs before this one.
the point considers all bugs where the opener had opened some bugs but had gotten none fixed.
the rest of the points consider all bugs with opener reputations within a .
point range.
for instance the rightmost point represents all bugs with opener reputations between .
and .
there is a consistent monotonic increase in bug fix likelihood as the opener reputation increases with the exception of those with zero reputation.
interestingly bugs opened by first timers first bug point had a higher likelihood of fix than bugs opened by people with low reputations.
all differences between points are statistically significant since their confidence intervals for binomial probabilities never overlap.
in fact all confidence intervals are negligible so they are invisible in figure .
employee intuitions corroborated our data.
for the final freeresponse survey question on what factors influence bug fixes one respondent who was not aware of our quantitative findings wrote a big influence is the reputation of the person opening the bug.
i often see nonsense bugs get opened indicating opener had done zero work.
contrast this with some very high quality bugs i see from some folk who have done a bunch of background work and often target the exact underlying problem.
if submitter has a history of submitting high quality bugs then new bugs from that person get better attention when we repeated these calculations for the reputations of the first person who was assigned to each bug the trends were nearly identical.
this result shows that certain people are more effective at either fixing bugs or reassigning bugs to others who can fix them.
summary people who have been more successful in getting their bugs fixed in the past perhaps because they wrote better bug reports will be more likely to get their bugs fixed in the future.
.
bug report edits and editors each act of editing a bug report field especially by a new editor provides evidence that somebody is taking an interest in it and improves its likelihood of being fixed.
it doesn t take much effort to figure likert scores for survey questions about the perceived impact of bug report edits on bug fixes averaged over all respondents.
3means significantly decrease chances of fix and 3means significantly increase chances of fix .
edit a bug report field e.g.
to upgrade its severity since an editor isn t necessarily the person assigned to handle the bug.
bugs with at least edit are more likely to be fixed as those with no edits all two group ratio differences reported in this paper are statistically significant at p .001according to a chi square test .
however too many edits might indicate a dispute over how to handle the bug so it might not be fixed bugs with over edits are less likely to be fixed than those with fewer than edits.
there is a similar positive correlation between the number of unique people who have edited a bug report and its likelihood of being fixed.
the left half of figure shows that if a bug report has more editors up to around its likelihood of being fixed steadily increases.
the differences are all statistically significant since the confidence intervals never overlap most are invisible .
the percent of fixed bugs seems to flatten out at around editors but the sample sizes grow too small to provide statistical power.
contrary to our data our survey respondents thought that the number of editors had only a weak effect on the likelihood that a bug would be fixed figure .
this perception could exist because developers aren t usually aware of how many people have edited their bug reports.
however one specific type of edit a change in severity level elicited stronger responses.
respondents thought that a severity upgrade greatly increased chances of fix mean likert score of .
which our data corroborates vista bugs whose severity had been upgraded were more likely to get fixed.
respondents also thought that a severity downgrade would decrease chances of fix mean likert score of .
but our data actually showed almost no difference from the control population of bugs whose severity level never changed.
summary the more people who take an interest in a bug report the more likely it is to be fixed.
.
bug report reassignments and assignees a reassignment is a major type of bug report edit since it shifts responsibility to a new person.
the right half of figure shows that reassigning a bug report to up to people increases its likelihood of being fixed but the likelihood decreases with more assignees.
most confidence intervals are invisible but as the number of assignees approaches they become visible.
calculations for number of reassignments rather than unique assignees show similar trends bugs that are reassigned at least once are more likely to be fixed than those that are never reassigned but bugs thatare assigned more than times are less likely to be fixed than those assigned fewer than times.
one explanation for this phenomenon is that people often need to reassign a bug several times possibly across teams or locations to find the optimal developer who can best address it.
a survey respondent cited the following reason for reassignments bugs many times are exposed in the ui but are not caused by the team writing the ui code.
these bugs can pass down several layers of components before landing on a lower level component owner.
however too many reassignments means that no one person or team is taking responsibility for handling the bug so it might never get fixed .
according to figure survey respondents concurred that having too many reassignments is detrimental to the chances of a bug being fixed.
however they also thought that even having a few reassignments would be detrimental which is contradictory with our data.
this perception could exist because developers associate reassignments with inefficiencies in the bug triaging process as indicated by some other free response answers .
summary reassignments are not always detrimental to bug fix likelihood several might be needed to find the optimal bug fixer.
.
bug report reopenings sometimes a bug is reopened after someone has already resolved and closed it.
our data shows that bugs that are reopened up to times are not any less likely to eventually be fixed.
however if a bug is reopened too many times then it probably will not be fixed bugs with more than reopenings are less likely to be fixed than those with fewer than and those with more than are less likely to be fixed too few bugs had more than reopenings for the differences to be statistically significant .
consistent with our data survey respondents felt that reopenings only had a slightly negative effect on bug fix likelihood figure .
in a free response question on why people felt that certain bugs might need to be reopened several times before being successfully fixed respondents cited reasons like the following the bugs might be difficult to reproduce so they were first closed as not repro and later reopened when someone improved report quality.
the initial fix might trigger regression test failures so the bug must be reopened to attempt another fix.
summary reopenings are not always detrimental to bug fix likelihood bugs reopened up to times are just as likely to get fixed.
.
organizational and geographical distance we found that bugs assigned to someone in a different team or geographical location as the bug opener were less likely to be fixed.
we quantified these effects by partitioning bugs into groups based on organizational and geographical profiles of their openers and assignees.
then we calculated the percent of bugs in each group that were successfully fixed.
in table we report ratios relative to the anonymized baseline percentages x y andz.
for instance bugs opened by and initially assigned to people with different managers are0.85times as likely to be fixed as those opened and initially assigned to the same person shown in bold near the top of table .
at one extreme bugs opened by and assigned to the same person are the most likely to get fixed the xandybaselines since the opener is probably a developer who wants to and is able to fix his her own bug.
bugs assigned to someone in the same team ororganizational factors opened by and initially assigned to .
.
.
.
.
.
the same person x .
.
.
someone with the same manager .
x .
.
.
someone with a different manager .
x assigned to opener at some point in time y never assigned to opener but assigned to someone with the same manager as opener .
y never assigned to anyone with same manager .
y opened by a permanent employee z opened by a temporary employee .
z initially assigned to temp.
employee .
z assigned to temp.
employee at any point .
z geographical factors opened by and initially assigned to .
.
.
.
.
.
the same person x .
.
.
someone in the same building .
x .
.
.
someone in a different building but in the same country .
x .
.
.
someone in a different country .
x assigned to opener at some point in time y never assigned to opener but assigned to someone in the same building .
y never assigned to anyone in same building but assigned to someone in the same country .
y never assigned to anyone in the same country .
y table effect of organizational and geographical factors on percentage of vista bugs that get fixed.
exact percentages for each group are anonymized only ratios are shown.
building are almost as likely to get fixed .97and0.94times respectively .
these colleagues can easily talk face to face to resolve ambiguities in bug reports and to hold each other accountable.
however if bugs are assigned to people who work in different buildings or countries then there is greater overhead in communication.
in a free response question about what factors affect bug fixes one survey respondent cites poor communication language barrier problems with other countries as hindrances.
bugs that were never assigned to anyone in the same country as their opener were only .33times as likely to be fixed as those assigned to the opener at some point in time shown in bold at the bottom of table .
survey results in figure corroborate these findings.
herbsleb and grinter found that cultural and language barriers existed at lucent software development sites just within western europe microsoft employees in countries across continents were involved in windows vista bugs so the potential barriers are even greater.
also microsoft tries to organize teams so that all members are located in the same building.
thus when bugs are assigned across buildings chances are that the participants do not personally know one another.
another survey respondent pointed out that there is less implicit trust between people in different teams or locations personal relations between the bug opener and members of the team it is assigned to .
whenever i open bugs assigned to people i know they are investigated thoroughly as there is a trust in the report i write.
often when reporting afigure likert scores for survey questions about the perceived impact of people factors on bug fixes averaged over all respondents.
3means significantly decrease chances of fix and 3means significantly increase chances of fix .
bug within areas where i don t know the owners there is inherent distrust in the bug report.
at another extreme temporary employees e.g.
contractors or interns have lower reputation and fewer relationships with windows developers so their bug reports might not be taken as seriously as those from core employees.
figure shows that survey respondents felt that bugs opened by and assigned to temporary employees were less likely to get fixed.
the section of table with thezbaseline corroborate these hunches.
it s more detrimental for a bug to be opened by a temp than to be assigned to a temp though since the burden is on the opener to find someone to fix the bug.
as a bug is reassigned across several buildings its likelihood of being fixed drops monotonically.
there is a drop in bug fix likelihood when going from to buildings and another drop when going from to the drops get smaller as the number of buildings increases .
recall from figure that more assignees up to actually improves likelihood of fix but that is not true for assignee buildings.
herbsleb and mockus found that modification requests mrs which include bug reports took longer to resolve when development was globally distributed .
our findings supplement theirs by showing that bug reports assigned across teams buildings and countries are less likely to be successfully resolved.
herbsleb and mockus attributed these delays in part to the fact that more people were usually involved in mrs distributed across sites.
in our data bug reports distributed across sites did not involve significantly more people usually only one extra editor and assignee but we still observed noticeable drops in bug fix likelihood.
summary bugs assigned across teams or locations are less likely to get fixed due to less communication and lowered trust.
.
replicated study on windows although the exact numbers and graphs for windows data are slightly different than those for vista the overall trends are the same.
here are some notable differences figure shows the same plots on windows data as figure does for vista.
there is a sharper upward progression and sudden flattening in percent fixed at editors and a larger spike at assignees.
also there is a much sharper drop off in percent of fixed bugs as the number of assignee buildings increases not pictured for space .
for example windows bugs whose assignees were distributed across buildings editors fixed assignees fixed figure percent of fixed windows bugs vs. numbers of unique bug report editors and assignees analogous to figure for vista bugs .
vertical bars are confidence intervals for binomial probabilities most are invisible .
were less likely to get fixed than those that remained within building versus only a decrease for vista.
.
descriptive statistical model a problem that often arises when presenting a series of singlevariable correlations as we ve done in section with factors that correlate with whether a bug is fixed is that their effects might be cross correlated thereby diminishing their validity.
to show that the factors we picked have independent effects that do not confound we built a logistic regression model and ran an analysis of deviance test on all factors .
.
model building a logistic regression model aims to predict the probability of an event occurring e.g.
will this bug be fixed?
using a combination of factors that can be numerical e.g.
bug opener reputation boolean e.g.
was severity upgraded?
or categorical e.g.
bug source .
we built a model to predict the probability that a windows vista bug will be fixed using our entire bug dataset as training data .
we chose our factors explanatory variables from those described in section .
we also built a model for windows using the same factors we obtained almost identical results so we do not show them here due to space constraints.
we determined that all factors had independent effects by incrementally adding each one to an empty model and observing that the model s deviance error decreases by a statistically significant amount for all added factors a standard technique called analysis of deviance .
we found that all factors were statistically significant at p lessmuch0.001according to an analysis of deviance chi square test.
we also checked for interactions between the factors in table .
in particular we were worried about interactions between opener and assignee having the same manager and being in the same building since people on the same team often work in the same building.
we found no interactions between any pairs of factors though.
the purpose of this model is to describe the various independent effects on bug fixes.
note that this model cannot actually be used to predict the probability that a newly opened bug report will be fixed since it uses factors that are not available at bug opening time e.g.
number of reopens .
.
meaning of logistic regression coefficients one main benefit of using logistic regression over other types of statistical models e.g.
support vector machines is that its parameters e.g.
the coefficients in table have intuitive meanings.factor coefficient bug source categories human review .
code analysis tool .
component testing .
ad hoc testing system testing .
customer .
internal user .
relatively fewer bugs from sources marked as were fixed due to numerous duplicate bug reports and the difficulty of reproducing bugs reported by users in the field.
reputation of bug opener .
reputation of 1st assignee .
opened by temporary employee?
.
initial severity level .
opener any assignee same manager?
.
opener any assignee same building?
.
severity upgraded?
.
num.
editors .
num.
assignee buildings .
num.
re opens .
num.
component path changes .
table descriptive logistic regression model for bug fix probability trained on all vista bugs.
the factor labeled folds into the intercept term which is omitted for confidentiality.
numerical and boolean factors the sign of each coefficient is its direction of correlation with the probability of a bug being fixed.
for example bug opener reputation is positively correlated with bug fixes so its coefficient is positive .
.
the magnitude of each coefficient roughly indicates how much a particular factor affects bug fix probability.
see hosmer and lemeshow for details on how to transform these coefficients into exact probabilities.
in general it s hard to compare coefficient magnitudes across factors since their units of measurement might differ.
however it s possible to compare coefficients for say two boolean factors like opener any assignee same manager and opener any assignee same building .
the coefficient of the former .
is larger than that of the latter .
which means that having the same manager has a larger positive effect on bug fix probability than working in the same building.
categorical factors if a factor has ncategories levels then n 1of them get their own coefficient and the remaining one gets its coefficient folded into the intercept term the r statistics package chooses the alphabetically earliest category to fold so that s why ad hoc testing has no coefficient in table .
what matters isn t the value of each coefficient but rather their ordering across categories.
for example for the categorical factor bug source the coefficient for human review is higher than that for code analysis tool which means that bugs in the former category are more likely to be fixed than bugs in the latter.
.
interpreting our descriptive model the following factors already discussed in section are positively correlated with bug fix probability so their corresponding coefficients are positive reputations of the bug opener and 1st as signee whether the opener and any assignee had the same manager or worked in the same building whether severity was upgraded and number of bug report editors.
these factors are negatively correlated with bug fix probability so their coefficients are negative whether the bug was opened by a temporary employee and numbers of reopens and assignee buildings.
we also included in our model three additional factors that we did not have space to discuss in depth in section bug source bugs from different sources vary in how often they are fixed.
we have sorted the bug source categories in table in decreasing order of coefficient values which ranks them by how many percent of bugs in each category were fixed.
in general bugs that are easier to triage reproduce and confirm are fixed more frequently.
on the high end human review and code analysis bugs are easy to triage and require no separate reproduction steps.
on the low end bugs reported by users can be difficult to reproduce users are not trained to write methodical bug reports like testers are and are often resolved as duplicate and not as fixed many users might encounter different symptoms of the same underlying bug .
initial severity level bugs opened with a higher severity value in the range of are more likely to be fixed as reflected by its .
coefficient.
our windows vista data shows that a severity bug is more likely to be fixed than a severity or bug and more likely to be fixed than a severity bug.
num.
component path changes bugs with more component path changes are less likely to be fixed as reflected by its .23coefficient.
if people edit a bug report to change its component path then that s a sign that they are unsure of the bug s root cause and or where a fix should be applied.
our windows vista data shows that a bug with its path changed at least once is less likely to be fixed than one with no path changes.
.
excluded factors we excluded several factors in section from our model because they had similar yet weaker effects than factors we already included.
trying to add these factors did not further decrease our model s deviance by statistically significant amounts so we excluded them in order to form the simplest possible model.
we used num.
assignee buildings rather than num.
assignees because the former had a monotonic effect while the latter did not.
similarly the effect of num.
reassigns was not monotonic.
we used num.
editors rather than num.
edits since the former had a stronger and more consistent effect.
we used buildings rather than countries since the former had a stronger effect.
.
predictive statistical model engineers cannot directly use the descriptive model of section to predict the probability that a newly opened bug will be fixed since it contains factors that are not available at open time e.g.
num.
reassignments .
to remedy this limitation we created a simple predictive model and evaluated its performance.
.
model building we built a predictive model using only factors that are available at the time a bug report is opened .
to do so we modified our descriptive model of table by removing the last factors changing opener any assignee .
.
.
to opener 1st assignee .
.
.
and re training on our entire windows vista dataset to obtain 2at the time a bug is opened it must be assigned to someone.factor coefficient bug source categories human review .
code analysis tool .
component testing .
ad hoc testing system testing .
customer .
internal user .
relatively fewer bugs from sources marked as were fixed due to numerous duplicate bug reports and the difficulty of reproducing bugs reported by users in the field.
reputation of bug opener .
reputation of 1st assignee .
opened by temporary employee?
.
initial severity level .
opener 1st assignee same manager?
.
opener 1st assignee same building?
.
table predictive logistic regression model for bug fix probability trained on all vista bugs.
the factor labeled folds into the intercept term which is omitted for confidentiality.
new coefficients.
the two models are quite similar although the exact values of the coefficients are different their signs and magnitudes relative to one another remain unchanged.
.
model performance we evaluated the predictive power of our model using crossvalidation and by predicting bug fixes on an entirely new dataset.
for cross validation we randomly picked of our data to train the model and the other to test its accuracy.
we predict a bug as being fixed only when the model gives a probability exceeding .
.
we performed rounds of randomized cross validation and obtained an average precision of .
and recall of .
.
we also did fold cross validation and found identical results.
we also ran cross validation on our descriptive model and its precision and recall were only .
greater than that achieved by our predictive model.
this provides encouragement that factors available at the time a bug is first opened are almost as effective as factors from the entire bug lifetime.
the ideal way to evaluate model performance is to train on one dataset and test on an entirely new dataset that we didn t have access to when we were creating the model cross validation is an approximation to this ideal when only one dataset is available .
after developing and running our analyses on the windows vista dataset we extracted bug reports from windows the successor of vista.
we then trained our model on the entire windows vista dataset and used it to predict which bugs will be fixed in windows .
we obtained a precision of .
and recall of .
.
these values are comparable to those obtained with cross validation on the vista dataset alone so we are confident that this model has predictive powers that generalize beyond the dataset on which it was developed.
for the proof of concept model presented here we didn t focus on optimizing performance we chose logistic regression because its parameters are relatively easy to interpret.
using more sophisticated classifiers e.g.
support vector machines or ensemble learning methods e.g.
boosting could improve precision and recall.
are these precision and recall values good enough ?
unfortu nately we cannot directly compare to related work since we know of no prior work that provides such performance numbers for models that predict bug fix probability.
we feel that our model performs well enough to consider deploying it to help triage bugs within microsoft.
only by collecting user feedback and understanding the role which a predictive model plays in a specific triage process can we figure out what performance numbers are adequate and how to best improve our model.
.
applications of predictive model in practice such a model can improve bug triaging as follows prioritizing bug reports during triage during software development resources are often spent on bugs that are never fixed.
our prediction model helps to prioritize bug reports and to focus resources on the bugs that are most likely to be fixed.
thus wasted effort can be reduced.
deciding which bugs to prematurely close in the mozilla project bug reports are automatically closed after an inactivity period of days .
even though the auto close feature is not very popular among users it is necessary to control the number of open bugs.
our prediction model could improve this situation by closing bugs more selectively preferring bugs that are predicted not to be fixed.
knowing which bugs will get fixed also helps to monitor and track the progress of software projects.
for example our prediction model can be used to provide an estimate of how many of the open bugs have yet to be fixed.
similarly the model helps to estimate the number of fixed bugs by developers rather than just counting assigned bug reports we can additionally estimate how many of each developer s bug reports will be fixed.
such estimates can improve automatic triaging techniques such as the one introduced by anvik and murphy who should fix this bug?
because in practice every developer can fix only a limited number of bugs.
.
additional insights from survey our final survey question was free response please write any other comments about what factors influence whether a bug gets successfully fixed.
out of the respondents answered this question.
when we examined their responses we found that many of them mentioned the following qualitative factors textual quality of bug report precise well written reports are more likely to gain the triager s attention especially if there are clear steps for reproducing the bug confirming the findings of bettenburg et al.
just to re emphasize the quality of the bug description is very important.
not necessarily filling in the dozens of fields in the bug database with all sorts of crap build numbers dates classifications etc but just the plain text description of the problem the implication and maybe even the potential solution.
perceived customer business impact bugs that are likely to hurt the company financially or in terms of reputation amongst customers will get more attention customer impact can be a very big impact on a bug if evidence exists to show the cost of not fixing the bug for one or more customers.
the biggest factor is the impact on end users.
if the impact on end users is high the bug will always be fixed.
seniority of bug opener bugs reported by and affecting higherranked employees often get preferential treatment a bug opened because something went wrong on a vps vice president s laptop has better chance than a bug opened because the same thing happened to an intern.
interpersonal skills of bug opener with limited resources available to fix bugs people who are more persuasive champions for their bugs are more successful in getting them addressed and fixed one other soft factor is the speaking skill persuasiveness of the developer or other representative when arguing for the bug.
how hard someone fights for the bug to be fixed may be the opener customer or feature owner .
whether there is someone on the team particularly passionate about the issue or somebody very senior or influential in the company .
.
threats to validity construct validity antoniol et al.
pointed out that not all bug reports are related to software problems in some case bug reports correspond to feature requests.
for our study we used the bug type field to distinguish between different kinds of bug reports such as code bug spec bug test bug and feature request.
however since this factor had little influence on the accuracy of our models we excluded it from the discussion in this paper.
internal validity in a qualitative study of bugs aranda and venolia found that many details are discussed even before a bug report is created and that not all information is recorded in bug tracking systems.
for our study this is only a minor threat because most of the events we analyzed must be recorded in the bug database e.g.
reassignments and reopenings .
moreover people make triage decisions based on data available in the bug database.
we also validated our quantitative results with qualitative feedback from microsoft employees involved in handling these bugs.
bird et al.
raised the issue of bias in bug datasets for defect prediction in open source projects.
however the likelihood of bias in our dataset is low since we analyzed the entire population of windows vista and windows bug reports.
external validity drawing general conclusions from empirical studies in software engineering is difficult because any process depends on a potentially large number of relevant context variables .
for this reason we cannot assume a priori that the results of our study generalize beyond the specific environment in which it was conducted.
however we feel that our results can potentially generalize at least to other large scale systems software projects because they were consistent when we replicated the initial windows vista study on windows .
replication studies on projects outside of microsoft are essential for strengthening external validity.
concurrently with our work diederik van liere applied logistic regression to predict which bugs were fixed in the mozilla firefox project using some factors similar to those in our models e.g.
bug opener reputation .
although his findings were only published as a short blog post they still help improve the generality of our own findings and motivate us to replicate our study in more detail on open source projects.
common misinterpretation lastly a common misinterpretation of empirical studies is that nothing new is learned e.g.
i already knew this result .
however such wisdom has rarely been shown to be true and is often quoted without scientific evidence.
this paper provides such evidence most common wisdom is confirmed e.g.
distributed bug reports are less likely to be fixed while others are challenged e.g.
bug reassignments are always bad .
.
conclusions fixing bugs is a crucial software maintenance activity.
it is very important for software developers and managers to know how and what types of bugs get fixed.
our study investigated factors related to people and report edit activities that affect the bug triage process.
quantitatively our findings characterized which bug reports get successfully fixed.
to highlight we found that at least one reassignment increases but too many reassignments decrease the likelihood of a bug getting fixed.
we also observed that the higher reputation a bug opener has the more likely his her bugs are to get fixed and that bugs handled by multiple teams and across multiple locations are less likely to get fixed.
qualitatively our survey results provide insights into difficultto measure social factors that affect the bug triaging process.
for example survey respondents pointed out the influence of seniority reputation personal relations and trust.
informing tool and policy design based on our findings we can make the following recommendations to improve bug triaging tools and processes use prediction models to rank and filter bugs during triage.
improve collective awareness of each developer s areas of expertise to minimize the number of reassignments required to find the optimal person to fix a particular bug.
minimize the number of times a bug must be reopened before being fixed perhaps by improving regression testing.
train employees to write high quality bug reports highlighting the importance of reputation which can reduce both unnecessary reassignments and reopenings.
reorganize teams to reduce the number of cross team and cross building reassignments.
improve communication and trust amongst people working in different teams and locations to improve the likelihood of distributed bugs being fixed.
encourage more fairness and objectivity in prioritizing bugs so that seniority and personal connections are less influential.
future work looking forward we plan to replicate this study on other projects within microsoft and also on open source projects taking into account the ways that open source project developer dynamics differ from those in commercial projects.
more broadly we plan to build a social network of developers in windows based on their personal interactions and also a developer network of people who worked together to write code and fix bugs using these two networks we can assess the importance of social connections in software development and bug fixing.
in the end people are the core of any software development process so it is crucial to understand how they work in aggregate using quantitative methods like data analysis as well as their perceptions of inefficiencies in their workflow using qualitative methods like surveys .
this study is one step in that direction we hope it can inform future work on people related factors that affect bug triaging.