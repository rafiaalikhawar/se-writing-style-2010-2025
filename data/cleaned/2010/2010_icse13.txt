reran timing and touch sensitive record and replay for android lorenzo gomez university of california los angeles usa lorenzo cs.ucla.eduiulian neamtiu university of california riverside usa neamtiu cs.ucr.edutanzirul azim university of california riverside usa mazim002 cs.ucr.edutodd millstein university of california los angeles usa todd cs.ucla.edu abstract touchscreen based devices such as smartphones and tablets are gaining popularity but their rich input capabilities pose new development and testing complications.
to alleviate this problem we present an approach and tool named reran that permits record and replay for the android smartphone platform.
existing gui level record and replay approaches are inadequate due to the expressiveness of the smartphone domain in which applications support sophisticated gui gestures depend on inputs from a variety of sensors on the device and have precise timing requirements among the various input events.
we address these challenges by directly capturing the low level event stream on the phone which includes both gui events and sensor events and replaying it with microsecond accuracy.
moreover reran does not require access to app source code perform any app rewriting or perform any modifications to the virtual machine or android platform.
we demonstrate reran s applicability in a variety of scenarios including a replaying out of the top android apps on google play b reproducing bugs in popular apps e.g.
firefox facebook quickoffice and c fast forwarding executions.
we believe that our versatile approach can help both android developers and researchers.
index terms record and replay google android.
i. i ntroduction smartphones and tablets have become powerful and increasingly popular platforms for a host of software applications apps ranging from office suites to games to social networking tools.
the appeal of these new platforms stems in part from the rich capabilities for user interaction via touchscreens as well as the diverse set of sensors e.g.
accelerometer compass gps that can be leveraged to drive app behavior.
however these new features also pose important challenges for software development testing and maintenance.
in this paper we focus on the challenge of accurately recording an app s execution in order to support automatic replay.
record and replay systems can be valuable tools for many software engineering tasks including program debugging testing and understanding.
unfortunately past approaches to record and replay for gui based applications are not adequate on smartphones.
these tools capture user activity in terms of discrete high level actions which cannot easily express complex gestures and do not support capture and replay for events from other sensors.
for illustration consider the task of recording and replaying the popular game angry birds a fully graphical app with no standard gui elements and very timing sensitive.
ourapproach has no trouble carrying out this task the reader is invited to watch our youtube videos showing r eran a record and replay of angry birds.
in fact our approach can successfully replay out of the top free android apps on google play.
however existing gui level approaches have multiple difficulties achieving record and replay for such apps as explained next.
first gui level tools e.g.
android guitar abbot hp winrunner ibm rational robot and gui crawler typically employ the keyword action paradigm in order to replay user interface events.
in this paradigm input events are abstracted from the concrete gui level to a higher level representation that uses a gui object s handle or name within the system to interact with it e.g.
click textbox1 ortype test123 .
angry birds however has a single activity screen so there are no gui elements such as multiple screens frames menus and input boxes that a keyword action tool can hook into.
second while the aforementioned tools can work well for discrete desktop point and click guis touchscreen platforms use a much richer gui paradigm based on continuous gestures such as swipe zoom and pinch.
even assuming an app has multiple screens and menus that a gui recorder can hook into touchscreen gestures are difficult to capture and represent as keyword actions since they can occur at arbitrary parts of the gui e.g.
to zoom in on a map and or can require low level precision in order to accurately replay e.g.
to slingshot a bird in angry birds .
this precision is required during record and replay both spatially input coordinates and temporally event timing .
for example it would be difficult to capture represent and replay a complicated non discrete gesture such as circular bird swipe with increasing slingshot tension in angry birds.
the problem is even more acute in the presence of multi touch gestures.
to quantify the importance of replaying gestures in figure we show the distribution of the number of touchscreen gestures used during a minute run for the apps r eran can replay note that out of replayable apps contain gestures and hence would not be fully replayable with prior approaches.
third it is insufficient to capture only the user interface events.
rather accurate replay requires capturing the multitude of external events that arise from sensors on the device.
for example inputs from the accelerometer and compass are used978 c ieee icse san francisco ca usa accepted for publication by ieee.
c ieee.
personal use of this material is permitted.
permission from ieee must be obtained for all other uses in any current or future media including reprinting republishing this material for advertising or promotional purposes creating new collective works for resale or redistribution to servers or lists or reuse of any copyrighted component of this work in other works.72to drive many games and navigation apps but these sensors are not exposed at the gui level.
one such app is google maps street view which uses the compass sensor to detect phone orientation with respect to magnetic north in order to orient the on screen map correctly.
finally the accuracy of event timing during both capture and replay is crucial.
for example a swipe that is captured too slowly will replay as a sequence of button presses and the timing between external events and user interface actions can be similarly crucial.
indeed we found that delays as short as milliseconds can adversely impact the replay process.
in this paper we present r eran record and r eplay for an droid a record and replay tool that addresses these challenges in the context of android applications.
r eran directly captures and replays the low level events that are triggered on the device.
this approach allows r eran to capture and playback gui events i.e.
touchscreen gestures e.g.
tap swipe pinch zoom as well as those from other sensor input devices e.g.
accelerometer light sensor compass .
in contrast prior replay tools for android which are based on the keyword action paradigm only replay touchscreen presses and cannot handle touchscreen gestures or other sensor inputs.
reran works in a natural 1non intrusive and low effort way during record a capture component reads the events with no noticeable impact on execution.
this contrasts with many keyword action based approaches which require manual scripting of test cases rather than direct trace collection .
during replay a phone based replay agent feeds the events to the phone and the phone acts as it would if the sensor input came from user or environment interaction.
r eran is carefully designed to manage the large number of low level events that occur during execution and to record and replay them with precise timings.
reran is currently unable to replay sensors whose events are made available to applications through system services rather than through the low level event interface e.g.
camera and gps .
r eran also does not capture other sources of nondeterminism in applications for example use of randomnumber generators and access to the file system.
providing fully deterministic replay would require a significantly more heavyweight solution for example involving modifications to the virtual machine and or complete interposition between the app and the underlying platform.
despite these limitations we demonstrate that r eran is useful in several ways.
first we were able to record and successfully replay execution traces for out of the top100 free android apps on google play the main android app distribution channel .
moreover r eran replays in nearly real time with an overhead of just over compared to the original execution.
second r eran is a powerful debugging aid because it can capture and replay event sequences that lead to crashes in 1reran requires the device to be rooted in order to execute the replay agent which we believe is a reasonable assumption for the intended users of reran researchers and developers.
number of gesturesnumber of replayable appsfig.
.
distribution of gestures in the apps replayable with r eran .
apps which helps developers inspect system state around a crash point.
in particular we demonstrate how using r eran we were able to reproduce and replay bugs in widely used apps including firefox facebook k mail and quickoffice.
third r eran has support for time warping which allows the execution of certain apps to be fast forwarded in order to reach a specific app state faster than in the original execution and without any additional manual input.
we found that the replay time for time warpable apps can be reduced by to percent compared to the original execution.
the remainder of this paper is organized as follows.
section ii introduces the android input events and sensor classes as well as event generation delivery and processing.
section iii provides an overview of our approach and the challenges that accurate record and replay pose for touchscreenbased smartphones.
in section iv we discuss the experimental methodology we followed the implementation of r eran results of running it on top google play apps and performance overhead.
section v presents three applications of using r eran for research and development tasks repeatability reproducing bugs and time warping.
in section vi we discuss limitations of our approach and record and replay on android in general.
section vii discusses related work and in section viii we present our conclusions.
ii.
a ndroid inputs in this section we describe the diverse kinds of inputs that android apps can accept as well as how these inputs are represented internally as events .
a. touchscreen user actions smartphone apps are distinguished in part by the expressive variety of user actions possible through touchscreens.
we briefly describe the most common ones press and release the primary input action is the simple press in which the user taps an area on the screen and releases quickly e.g.
clicking a button or typing text with the on screen keyboard.
press and hold the press and hold consists of the user tapping an area on the screen and releasing after holding in the same position past some threshold amount of time.
this action can be used to access secondary menus or hidden options.73swipe swiping on the touchscreen occurs when a user presses down on the screen from position x1 y1 and while continuing to hold down on the screen moves to a new position x2 y2 and releases.
swiping is used in many apps e.g.
to scroll through text in a web browser or slingshot a bird in angry birds.
zoom and pinch multi touch gestures involve pressing the touchscreen through more than one contact point e.g.
using two or more fingers.
the most common multi touch usages are zooming and pinching when apps support such gestures they usually correspond to changing the magnification level of the content being viewed e.g.
in google maps zooming and pinching change the level of detail.
of the four user actions listed above three are considered gestures press and hold swipes and zoom and pinch.
gestures require a large group of underlying touchscreen events to provide their perceived functionality as explained shortly.
the press and release user action requires a much smaller grouping of events and as described in section vii has been successfully replayed using other methods.
as shown in figure touchscreen gestures in apps are very frequent we collected these results based on a minute run of the app from a single user.
note that the majority of apps out of had anywhere from to gestures during the session whereas only apps did not contain any gestures uno free and brightest flashlight free .
aside from the touchscreen users can provide input through physical buttons on the phone.
our test devices did not have a physical keyboard but they have several buttons with various usages e.g.
lock the screen turn off the device increase or decrease the speaker volume.
b. physical sensors android devices typically have several sensors that generate inputs asynchronously.
sensor data is generated by hardware components that measure changes in the physical properties of the phone.
we describe the most common sensors and their uses in android apps.
note that gps location is attained from an android service rather than directly from a physical sensor so we cannot currently replay its events.
the accelerometer allows an application to detect whether the phone has changed its speed and can also be used to detect phone tilting and rotation .
this is the mechanism used to change the screen layout from portrait to landscape mode and some games use the accelerometer as a primary means of user input e.g.
to roll a ball through a maze or shake a magic eight ball.
the proximity light sensor allows applications to detect how close the user is from the phone .
this sensor is primarily used to dim the screen as well as protect the user from accidental button presses when the phone is close to the user s ear during a phone call.
the compass reports the phone s orientation relative to the magnetic north.
the compass is frequently used in mapping and navigation apps to provide a direction perspective.c.
android events the android software stack consists of a custom linux kernel and libraries the dalvik virtual machine vm and apps running on top of the vm.
when users interact with an android app the android device s sensors generate and send events to the kernel via the dev input event device files.
events have a standard five field format timestamp device type code value where timestamp represents the time elapsed from the last system restart device names the input device that has created the event and the remaining fields depend on the specific event type.
touchscreen gestures are encoded as a stream of touchscreen events in the above format with no labeling as to which gesture was performed.
for example one such event could look as follows dev input event4 0000011f here the timestamp indicates the event was generated seconds and microseconds since system restart and the input device is event4 which corresponds to the touchscreen for our device .
the next three columns provide position information corresponds to the xposition of the event and 0000011f hex corresponds to coordinate decimal of the screen.
however this single event alone is not enough information for reconstituting the high level gesture for instance a single press usually involves roughly touchscreen events while a swipe usually involves roughly touchscreen events.
in figure we show a subset of events involved in a single typical gesture a swipe.
the left side of the figure shows the raw stream of events while the right side shows the high level semantics of event clusters press move release.
the sample event explained previously is actually event in the stream.
note how the timing information reveals that in order to successfully replay the swipe the events have to be replayed accurately within milliseconds between timestamps and40 .
to provide an illustration of the event flux in a real world app that uses multiple sensors in figure we show the stream of events in the gasbuddy app the app displays gas prices on a map over the first seconds of a normal run.
the x axis shows the time in seconds and the y axis shows the number of events.
the graphs show the number of events at second granularity the top curve in red shows the touchscreen events while the bottom curve in light blue shows events coming from the compass.
the text on top indicates the distinct phases in the execution.
first the user inputs the geographical location los angeles using the touchpad seconds notice how the compass is not used in this phase.
next the app loads the gas station maps in the vicinity of los angeles and uses the compass to orient the map notice how the user waits at this point as indicated by the absence of user events seconds .
in the third phase the map has been loaded and the user navigates on the map using pinch and zoom indicated by the high number of touchscreen events seconds the compass is still used to keep the correct map740 number of events time seconds compass events touchscreen events enter location !los angeles!map loaded navigate via pinch zoom!browse individual gas station via scroll!navigate through stations map via pinch zoom!app loads station map!fig.
.
time series of events in gas buddy.
.
dev input event4 0000001e .
dev input event4 .
dev input event4 0000011f .
dev input event4 000001d9 .
dev input event4 .
dev input event4 .
dev input event4 0000001e .
dev input event4 .
dev input event4 0000016e .
dev input event4 000001d2 .
dev input event4 .
dev input event4 ... .
dev input event4 .
dev input event4 .
dev input event4 .
dev input event4 000001d2 .
dev input event4 .
dev input event4 xi yi press xm ym move xf yf release sec s device sensor values swipe fig.
.
series of events representing a swipe xi yiare the initial starting coordinates xm ymare the coordinates during moving still holding down andxf yfare the final coordinates.
orientation.
in the fourth phase the user browses gas prices for an individual station seconds which requires scrolling and no compass.
finally seconds the user navigates again through the stations map using pinch and zoom which generates both touchscreen and compass events.
the time series reveals several key requirements for successful replay events from all sensors not only the touchscreen must be captured and delivered as they influence app behavior and events must be captured and delivered at high throughput .
we provide a broader quantitative assessment of typical event volume in table i. the table shows the total number of events received from three input devices captured during a minute run of the app listed.
touchscreen events dominate table i number of input events per input device during a minute run .
app name touchscreen proximity sensor accelerometer facebook angry birds gasbuddy amazon however there are also a significant number of events from sensors.
for all apps the phone was kept flat on a table during execution which accounts for the small number of reported accelerometer events.
iii.
a pproach overview we now present an overview of our approach its technical challenges and its advantages over prior record and replay approaches.
google provides the android software development kit sdk which contains various tools to aid app developers in implementation testing and debugging.
several of these tools were used in the development of r eran .
the high level view is presented in figure .
record or replay can be started from either the phone using the android terminal emulator app available for free on google play or from a computer connected to the phone via a usb cable.
the android debug bridge adb accessible through the adb command in the android sdk and android terminal emulator act as the interface between r eran and the smartphone.
commands can be issued to the smartphone s os via these shells.
we used this ability both to record events and to replay them.
a. record we use the android sdk s getevent tool which reads the dev input event files in order to provide a live log trace of the input events on the phone as shown on the top of figure .
the performance of the app is unaffected during logging.
once logging has ended r eran s record phase translates the captured trace and creates the event trace file that is ready to be replayed.
during translation all the75 dev input event replay agent dev input event eventtrace eventtracerecordreplayrecord input events inject eventsfig.
.
overview of r eran .
captured event information is converted to a concise form and time delays are calculated.
for implementation reasons we currently perform translation offline on a computer but we plan to perform it directly on the phone in future work.
b. replay the android sdk also provides a sendevent tool which allows developers to send a single input event to the phone.
unfortunately we found that sendevent has a small lag when used in series which makes it unable to faithfully replay recorded event streams.
there are several negative consequences if accurate timing is not preserved during replay.
for example delays in the middle of a swipe will make the swipe appear to be a series of presses delaying the release that marks the end of press will make the press act as a pressand hold etc.
therefore delivering events with exact timings was a key technical challenge.
as mentioned earlier recreating a swipe usually requires or more events to be replayed.
further each swipe is usually less than a second and the time between individual events in the swipe is typically less than microseconds.
because of the sensitive time dependency between events we had to refine our approach to replay.
rather than employ sendevent we implemented our own replay agent that runs on the phone and directly injects events into the phone s event stream as shown on the bottom of figure .
this approach also allowed us to inject multiple events at the same time thereby seamlessly handling events that occurred simultaneously during recording.
during replay the replay agent on the phone appears as an external user generating events through the phone s input devices.
while in theory there is potential for conflicts with other events occurring during a replay session in practice we did not find this to be a problem because of our testing setup see section iv b the phone gracefully accepts and processes events from all sources and there was no noticeable difference in behavior for the apps in our test suite.
c. comparison with keyword action approaches by performing record and replay at the level of individual events our tool can replay sophisticated touchscreen gestures while being unaware of their high level action meaning.
furthermore our approach naturally generalizes to handle new touchscreen gestures that are available in the future as well as new kinds of sensors.
all that is necessary is that these actions can be represented as low level events.
in contrast approaches based on the keyword action paradigm represent high level actions directly.
this can be useful in conveying more semantic information to users.
however it requires that the high level taxonomy be updated each time a new kind of gesture or sensor becomes available.
furthermore this approach requires a method for inferring the high level actions from the individual low level events which may not always be straightforward.
finally the many degrees of freedom involved in touchscreen gestures make the keyword action style relatively unnatural.
for instance a swipe s behavior may depend not only on the start and end positions but also by the time taken the trajectory followed between the two positions the amount of pressure used etc.
iv.
i mplementation details and performance this section provides further details of r eran s implementation and experimental setup and evaluate the tool s performance.
a. physical devices the android devices used to develop the replay tool were motorola droid bionic phones which have dual core arm cortex a9 processors running at 1ghz.
the phones were released on released september and run android version .
.
with linux kernel version .
.
.
b. testing environment our phones did not have cellular service we did not use them for related tasks such as sending sms messages and making phone calls.
in order to minimize the impact of poor wireless link quality on apps we used wifi in strong signal conditions.
if tested apps did not require the device to be physically moved the phone was placed on a flat surface when collecting traces this reduces the flux of always on sensor events e.g.
the accelerometer and light sensor without affecting app behavior.
c. replay agent we wrote the replay agent in c and compiled it with arm elf gcc .
we used the source code of android s sendevent tool as a guide to determine how to interact with the device directly i.e.
write to dev input event .
in the early stages of this research the replay agent was running on the computer as a java program that used the android shell command sendevent to send a series of input events into76table ii the86out of top apps in the u.s. view of google play as of may6 that reran can replay .
app name adobe air craigslist mobile feed your dino free imdb running fred visual anatomy adobe flash player crime city gas buddy instagram sincerely ink cards weather bug adobe reader daily horoscope google drive kindle sky map weather channel amazon mobile dance legend google earth maps skype whatsapp messenger angry birds rio death rally free google maps street view motoprint slacker radio where s my water angry birds seasons dictionary google play books movies by flixster slot city machines word search angry birds space documents togo google play music mp3 ringtone maker stick man bmx stunts yellow pages background hd wallpapers drag racing google play movies myxer talking tom yelp baseball superstars drag racing bike racing google plus netflix ted youtube bbc news draw something google search nba gametime textgram zedge bible easy battery saver google translate one touch drawing touchnote postcards zinio bmx boy ebay groupon picsart tunewiki brightest flashlight espn score center heartradio pool master pro twitter bubble shoot evernote how to read thoughts pulsenews unblock me free color note facebook ifunny recipe search unicorn dash table iii the performance and space overhead of reran on 4popular apps averaged over 5user sessions .
app name run time overhead trace size original replay overhead seconds seconds kb facebook .
.
.
.
angry birds .
.
.
.
dictionary .
.
.
.
gas buddy .
.
.
.
the phone via adb.
however as described earlier that solution did not achieve the microsecond accuracy needed for gestures.
reran supports selective replay whereby the user can suppress entire classes of events.
this can be especially helpful when the user is trying to isolate the root cause of a bug.
it can also reduce overhead when replaying an app that never uses a particular sensor input such as the accelerometer.
the compiled replay agent is uploaded to the phone via adb and takes a trace file event set and their timing as argument.
in order to execute on the phone system permissions must be changed which requires the phone to be rooted.
the replay agent runs in a separate process from the replayed app.
d. achievements of the top apps on google play we were able to successfully replay we list the names of these apps in table ii.
note that these apps span a variety of categories from social media to productivity to games demonstrating the wide scope of r eran s practical utility.
in section vi we discuss the reasons why replay is not possible for the remaining apps in top .
e. time and space overhead we measured time and space overheads for sample apps using traces from different users.
we present the results in table iii.
first we compared the completion time of original executions with the completion time of replayed executions.
columns and show the average run time across the executions of the original run and of the replayed run column shows the time overhead near in all cases.
we believe the replay overhead is largely due to the fact that event injection isnot instantaneous.
during capture sometimes an input device reports events as occuring simultaneously i.e.
with the same timestamp.
we were able to mimic this by writing multiple events into the stream at once.
however because the events are being injected programatically rather than being generated by the physical device captured simultaneous events are only replayed within microseconds of each other.
despite the lag it caused no noticeable differences in app behavior.
the last column shows the average log size of the events captured.
as expected for the more interactive apps that use many gestures e.g.
angry birds the log size is higher than less interactive apps e.g.
dictionary.
all tests were conducted on the physical devices described in section iv a. v. r eplay uses the ability to replay a recorded execution has myriad applications.
in this section we illustrate several scenarios of how r eran s record and replay capabilities can be beneficial to developers and researchers.
a. repeatability through trace replay reran is able to play back a set of input events of a specific session exactly in the same way as it was originally recorded.
this includes touchscreen events user proximity events as well as changes in phone orientation sensed by the accelerometer and compass.
in contrast if a user were to manually repeat a session trying to replicate the same actions as the previous run there could be inconsistencies and abnormalities when compared to the original run due to human error and inconsistent timing this could in turn lead to unfaithful results or an undesired outcome.
replay can greatly help developers and researchers who wish to eliminate inaccurate and time consuming app testing when repetition of a sequence is needed.
in fact in our prior research we used a preliminary version of r eran to eliminate the need for constant interaction with testers to profile network traffic and other app characteristics we examined functionally identical executions of the same app by recording a user s interaction execution and replaying it times executions through .77table iv reproducible app bugs that are replayable .
category app name file format ankidroid .7b3 apv pdf viewer .
.
quickoffice .
.
soundcloud .
.
invalid input k mail .
.
.
stress npr news .1b scripts plugins firefox .
app logic home switcher .
facebook .
.
varying environments trace replay can also be used to test the effect of various environmental conditions on app behavior.
for example in prior work on network profiling we replayed the same app trace at different times of day to obtain a wider range of app behaviors .
similarly developers can choose to vary conditions such as network connectivity or phone position during a replayed execution and observe the impact of these variations on app behavior.
b. reproducing bugs reproducibility is key to bug fixing.
r eran provides significant help for reproducing bugs by recording executions until a bug is encountered and then replaying the trace.
we tested r eran s bug reproducing capabilities using actual bugs in popular android apps.
we first gathered sample bugs2from a variety of sources google code mozilla s bugzilla bug tracker and the web.
we manually tried to reproduce the bug by following the provided steps to reproduce it while recording our input actions with r eran .
when we were able to reproduce the bug in a manual run we replayed the collected trace using r eran .
all bugs that we were able to reproduce manually could be replayed in that during the replayed execution the bug manifested itself.
to ensure the consistency of our results we replayed the bug trace additional times and each time the bug was reproduced.
the bug category along with the names and version of each app is provided in table iv.
video demos of r eran replaying bugs are available on youtube .
we now provide a detailed characterization of the bugs.
bugs stemming from incorrect file formats e.g.
corrupted files inappropriate file extension unsupported files etc.
.
for example apv pdf viewer version .
.
and quickoffice version .
.
crash if a corrupt pdf file is loaded while the soundcloud .
.
app crashes if an unsupported file format e.g.
.ogg is uploaded.
the ankidroid flash card app version .7b3 crashed when it opened a specific custom card template.
bugs that are created by entering invalid or wrong input.
for example in the k mail .
.
.
app when ip 2we searched the google code and mozilla bugzilla bug repositories with the keywords steps to reproduce stack trace observed behavior test cases error report error message code sample .
of the returned results that were not device specific and did not require phone service we installed the version of the app that contained the bug.addresses are inserted in place of the corresponding domain name and the preferences are saved the application crashes.
bugs in browser applications which can be due to unresponsive scripts erroneous plug ins and malformed html pages.
one example is version .
of the popular browser mozilla firefox it crashes while handling certain xml files and external scripts.
bugs caused by stress testing i.e.
the same thing or generating the same sequence of events over and over.
for example the npr news reader app version .1b crashes if the hourly news update feature is exercised repeatedly.
bugs caused by transitioning among app states.
the home switcher app allows the user to change the system wide theme of the user interface.
sometimes transitioning from a particular third party theme to another theme causes the app version .
to crash.
facebook version .
.
crashed after removing the internet connection and attempting to log in.
note that r eran enables reproducing bugs that contain gestures whereas other android testing tools cannot handle gestures.
for example androidguitar which we compare with extensively in section vii could reach the point of the crash in those apps that did not contain input gestures such as swipes.
however for apps that did contain gestures e.g.
ankidroid quickoffice apv pdf viewer and soundcloud androidguitar is unable to reproduce the bugs.
debugging reran can be used in combination with debuggers to drives the app to a certain state and then using a breakpoint the debugger helps examine that state to facilitate bug finding and fixing.
for example we used r eran in conjunction with the eclipse integrated debugger which communicates with the vm on the smartphone via the java debugger jdb to inspect app state during execution and just before a crash.
c. time warping with r eran we can time warp the gui events of an event trace to alter timing during replay while still going through the same execution states.
time warping is accomplished by increasing or decreasing the time delays td for short between consecutive events of a trace without changing the original path captured.
we have focused on fast forwarding but we imagine that a similar approach could be used to slow down execution which could be used as another debugging tool in a testing suite.
for example the tds could be increased to give the developer more time to examine the state of the app before the next interaction occurs.
we do not attempt to manipulate the speed of touchscreen presses or gestures.
as we have discussed such time warping can easily modify the gesture s effect or convert it to a different action or set of actions.
however we have identified two cases when significant tds occur that can be targeted for fastforwarding during data entry and when the user is processing content.
data entry refers to the user typing on the78virtual or physical keypad and clicking buttons.
these events occur on human timescales and thus have significant room for speed ups.
processing content refers to the user examining content on the screen and deciding which action to perform next e.g.
press a button.
processing content can also take place after accessing data on external servers via the internet e.g.
the cnn and facebook apps .
these situations can be fast forwarded because there is a lag between the time that the content has loaded and the time the user performs the next input action.
we fast forward using three rules that we have derived empirically for our phones and test apps but we expect the general principle to hold for other setups.
the rules are as follows a if the td is less than .
seconds then we compress the delay to .
seconds b if the delay is greater than .
seconds we compress the delay to .
seconds and c any delay between .
and .
seconds is unchanged.
rule a tries to identify and fast forward data entry from the user.
this rule for example allows data entry to be greatly sped up in apps requiring heavy text input such as dictionary and google translate.
rule b accounts for the long tds during execution that can occur when a user is viewing content on the screen or deciding where to navigate to next.
for example this optimization can be seen in the gas station finder gas buddy in which the user views a map of gas prices before selecting one creating long periods of delay.
rule c preserves the speed of the execution in all other situations.
despite the simplicity of these rules we were able to use them successfully to time warp many apps.
video demos of reran fast forwarding are available on youtube .
we present the results of fast forwarding in table v. for each app in column we present the original run time in column we present the run time when fast forwarding while column shows the run time reduction as a percentage.
note that in general apps can be sped up anywhere from to .
certain apps however quickoffice npr news home switcher could not be fast forwarded due to reasons that we will explain next.
uses of fast forwarding fast forwarding can shorten the time to reach a certain point in the app without requiring manual input.
for example while testing a feature added to one of the app s screens a developer could use fast forwarding to greatly reduce the time required to get to that screen.
fastforwarding can also be used in combination with r eran s ability to reproduce bugs in order to speed up debugging time.
by fast forwarding the replay the amount of time to reproduce the crash i.e.
replay the steps to reproduce will be reduced thus saving the developer time.
as shown in table v we also fast forwarded the apps that had reproducible bug crashes.
in each we ran our time warped replay and found that apps had reduced running time.
the remaining apps saw no reduction and kept their previous running time.
this is due to the apps not having data entry or long delays so we could not applytable v app run time in the original execution and replayed using fast forwarding .
bugs reproduced are shown in gray .
app name run time reduction original fast forwarded seconds seconds facebook .
.
.
.
dictionary .
.
.
gas buddy .
.
.
bbc news .
.
.
craigslist .
.
.
espn score .
.
.
amazon .
.
.
movies .
.
.
google translate .
.
.
ankidroid .
.
.
apv pdf viewer .
.
.
firefox .
.
.
soundcloud .
.
.
k mail .
.
.
facebook .
.
.
.
.
quickoffice .
.
.
npr news .
.
.
home switcher .
.
.
table vi the14out of top apps that reran cannot replay .
non replayable reason app name requires android sensor service barcode scanner tango video calls e.g.
camera microphone v oice search v oxer walkie talkie dynamic or random elements pandora boxing game fruit ninja i.e.
nondeterminism jewels star shoot bubble deluxe solitare temple run tetris uno free words with friends rules a or b and instead the tds stayed in the range of our do not alter rule rule c which kept the original td.
vi.
l imitations as mentioned in section iv d r eran could replay of the top apps on google play.
however there were apps we could not replay.
these apps fell into two main categories apps which required an android sensor service and apps that contain dynamic or random elements as shown in table vi.
we now discuss the main reasons why these apps cannot be replayed.
requires android sensor service some apps require sensor input that r eran does not record.
for example we cannot replay the barcode scanner app properly without capturing the identical barcode image that is fed as input from the camera.
similarily we cannot replay v oxer walkie talkie because the app requires capturing audio data from the microphone.
in android these types of input come from sensors that are not instrumented in the same way as the touchscreen and accelerometer that use dev input event .
instead due to privacy and security issues these sensors are not openly accessible for capturing and are protected by system permissions e.g.
the device s camera microphone and gps location.
currently we do not capture such sensors as tapping into such sources would require a non trivial extension to our system a task we leave to future work.79dynamic or random similarly we do not capture sources of nondeterminism for example arising through dynamic layouts or popup windows network connectivity changes or internal nondeterminism such as the use of a random number generator.
as can be seen in table vi the majority of these dynamic or random apps are games e.g.
the popular game temple run randomly generates levels each time a user plays making replay with r eran impossible.
in general handling these sources of nondeterminism requires capturing the results of system calls as well as calls to nondeterministic apis and providing customized versions of these apis for replay which requires instrumenting apps and or the vm.
r eran s simple design loses this expressiveness but can still replay the vast majority of apps in the top .
vii.
r elated work record and replay techniques have been explored by a rich body of prior work on a range of platforms including android.
most closely related to our line of work are approaches that implement record and replay at the gui level they usually do so using two methods a keyword action approach in which the gui components are accessed and changed via scripts and an event driven approach in which input device events are captured and replayed.
we first survey general purpose gui testing tools and then android specific approaches.
a. gui testing for desktop applications some junit based capture and replay tools e.g.
jacareto or pounder are event driven and capture coordinates in a manner similar to r eran .
they record the x y coordinates of mouse clicks and keyboard strokes and during replay create new mouse and keyboard events with the captured information.
these tools even though they are at a higher level of abstraction than r eran are also susceptible to errors when changes in the gui occur e.g.
button1 changes position between application versions.
some of these tools also offer support for mouse drags .
however mouse drags differ from swipes in that the individual events being sent by other platforms are usually being detected as mouse presses which already contain positioning information .
in contrast in android as shown in figure a down press corresponds to a group of single precisely timed events.
therefore timing accuracy for mouse drags on other platforms is not as critical as in android.
marathon hp winrunner abbot and rational robot offer support for record and replay for desktop or server applications but in a different manner.
instead of capturing raw position coordinates they use a keyword action technique that works at a higher level of abstraction by capturing gui objects.
by capturing the gui components themselves they are able to refer to objects by name in their traces however they rely on the existence of a gui layout in the first place an assumption which might not hold e.g.
in the angry birds case.
finding appropriate object handles to use can be alleviated with techniques such as guimapping or creating unique identifiers based on the thread creating the gui object .
once a script has been created the gui interaction is replayed by accessing the gui objects and updating their properties.
tools following the keyword action technique often require users to manually write test scripts rather than capturing user interaction directly as in r eran because their focus is creating test cases rather than replay.
this type of testing is not as fragile as coordinate based testing when changing gui components however modifications made to the gui api e.g.
changes additions or deletions of gui classes might also require the scripts to be changed .
all the aforementioned approaches were built targeting traditional desktop interfaces and none of them offer support for touchscreens.
attempts for touch based replay outside of mobile devices e.g.
dart and microsoft surface sdk for tabletop applications are usually built to function solely with the hardware and api s of the targeted platform.
recent work has moved towards creating a universal interface for multi touch devices .
b. android gui testing the android sdk provides the monkey tool which can generate random touchscreen presses and gestures and other system level events and feed them into an application.
monkey also supports event sequence scripts to be fed into an application however it is not supported by google which lists its purpose solely as a stress tester.
monkey scripts can contain android motionevents allowing it to handle presses.
however based on our initial attempts when developing reran scripting presses is very labor intensive e.g.
besides the x y position each press requires additional parameters to be specified including pressure precision and size.
in addition monkey scripting does not support touchscreen gestures.
r eran alleviates the need for such complex and time consuming scripting via recording that allows the user to interact naturally with an app.
google also provides a similar tool monkeyrunner which brings the keyword action technique to android by providing an api for replaying scripts that drive the android device or emulator.
the tool allows users to view the ending state as a screenshot.
robotium a framework based on junit provides a similar approach as monkeyrunner but also allows for automatic black box testing of android applications by invoking gui elements e.g.
button names and menus to navigate the application.
both tools heavily depend on the app layout being structured in a way that allows them to easily retrieve gui components.
however deciding how to structure a layout is very much at the discretion of the individual android app developers who can either a provide an xml layout file or b create layout elements at run time .
reran s testing is independent of layouts and limitations of user defined gui elements.
this enables r eran to be able to record and replay applications no matter how the layout is structured.80guitar is a gui testing framework for java and windows applications.
guitar generates event sequencebased test cases for gui applications.
their technique can generate test cases automatically using a structural event generation graph.
while guitar primarily targets java desktop applications it has recently been ported to android by extending android sdk s monkeyrunner tool to allow users to create their own test cases with a point and click interface that captures press events.
however guitar does not support touchscreen gestures e.g.
swipe and zoom or other input devices e.g.
accelerometer and compass.
in the past navigating through a program by pointing and clicking was sufficient and useful outside of the mobile world the primary input devices captured have been mouse movement and keyboard keystrokes.
however as smartphones become more advanced offering greater features and interactivity through added device sensors and their uses we argue that in order to faithfully replay user interaction allthese sensors must be accounted for not only a subset of one device i.e.
touchscreen presses.
c. deterministic replay a substantial body of work has focused on deterministic replay by capturing and replaying events at the hardware operating system or virtual machine levels.
these approaches log events that might introduce non determinism i o thread scheduling memory accesses etc.
and deliver the events in the right order during replay to ensure that the replayed execution is quasi identical to the original run.
logging overhead varies depending on the nature of the benchmark and adding record and replay capabilities to an existing system might be quite intrusive.
we explore a different point in the design space we do not aim to achieve deterministic replay but instead focus on an effective approach and tool that uses standard software hardware and is minimally intrusive yet nevertheless can replay out of the top popular apps.
viii.
c onclusions we have presented r eran an approach to record andreplay for the android platform.
our research was motivated by the novelty and popularity of touchscreen based platforms and apps the unique challenges associated with replaying these apps and the broad applicability of recordand replay techniques when tackling research and practical tasks on android.
by directly capturing the low level event stream on the phone and replaying it with precise timing reran can easily reproduce complex gui gestures as well as other sensor inputs.
the result is a noninvasive yet very effective record and replay approach that works for the vast majority of popular real world apps in google play s top100.
moreover we have demonstrated that the approach can be applied successfully for repeatability bug reproducibility and execution time warping.