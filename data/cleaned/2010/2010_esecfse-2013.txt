second order constraints in dynamic invariant inference kaituo li computer science dept.
university of massachusetts amherst ma usachristoph reichenbach institut f r informatik goethe university frankfurt frankfurt am main germanyy annis smaragdakis dept.
of informatics university of athens athens greece michal y oung computer science dept.
university of oregon eugene or usa abstract the current generation of dynamic invariant detectors often produce invariants that are inconsistent with program semantics or programmer knowledge.
we improve the consistency of dynamically discovered invariants by taking into account higher level constraints.
these constraints encode knowledge about invariants even when the invariants themselves are unknown.
for instance even though the invariants describing the behavior of two functions f1andf2may be unknown we may know that any valid input for f1is also valid for f2 i.e.
the precondition of f1implies that of f2.
we explore techniques for expressing and employing such consistency constraints to improve the quality of produced invariants.
we further introduce techniques for dynamically discovering potential second order constraints that the programmer can subsequently approve or reject.
our implementation builds on the daikon tool with a vocabulary of constraints that the programmer can use to enhance and constrain daikon s inference.
we show that dynamic inference of second order constraints together with minimal human effort can significantly influence the produced first order invariants even in systems of substantial size such as the apache commons collections and the aspectj compiler.
we also find that of the dynamically inferred second order constraints we sampled are true.
categories and subject descriptors d. .
software program verification class invariants d. .
testing and debugging testing tools general terms reliability verification keywords daikon dynamic invariant inference second order constraints permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
esec fse august saint petersburg russia copyright acm ... .
.
.
introduction and motiv ation systematically understanding program properties is a task at the core of many software engineering activities.
software testing software documentation and software maintenance benefit directly from any significant advance in automatically inferring program behavior.
dynamic invariant detection is an intriguing behavior inference approach that has received considerable attention in the recent research literature.
tools such as daikon diduce and dysy monitor a large number of program executions and heuristically infer abstract logical properties of the program expressed as invariants.
dynamic invariant inference is fundamentally a search in the space of propositions over program variables for the tiny subset of propositions that are both true on all executions and relevant to the programmer or to some client analysis such as a theorem prover or test data generator .
any such search requires a way of generating candidate propositions and a way of evaluating them.
even limiting consideration to propositions of fixed length over a particular vocabulary of operations and relations among variables the space is enormous and for a long time it seemed folly to even attempt such a search based on dynamic program execution.
daikon was the first demonstration that a generate and test tactic could be feasible generating a moderately large set of candidate propositions from syntactic templates and quickly pruning the vast majority as they were refuted by program execution.
in this work we enhance the dynamic invariant detection approach by including second order constraints.
the invariants inferred should be consistent with these constraints.
more specifically we identify a vocabulary of constraints on inferred invariants.
we call these constraints second order because they are constraints over constraints they relate classes of invariants firstorder constraints .
such second order constraints can be known even though the invariants are unknown.
to avoid confusion we try to consistently use the term constraints for second order constraints as opposed to the first order invariants although the term second order invariants would have been equally applicable.
our vocabulary includes concepts such as subdomain one method s precondition implies that of another subrange one method s postcondition implies that of another canfollow one method s postcondition implies the precondition of another concord two methods satisfy a common property for the common part of their domains although some inputs for one may be invalid for the other and more.
such constraints arise fairly naturally.
two methods may be applicable at exactly the same state of an input.
for instance the top andpopmethods of a stack data structure will have constraints subdomain top pop subdomain pop top this signifies that their preconditions are equivalent.
as another example a method may be a specialized implementation of another e.g.
a matrix multiplication with a faster algorithm applicable to upper triangular matrices only relative to a general matrix multiplier .
this induces a subdomain triangmatmul matmul constraint.
similarly a method may be preparing an object s state for other operations as in the common case of open andread canfollow open read .
the purpose served by second order constraints is dual first when the constraints are discovered dynamically without any human effort expended they can serve as a concise and deeper documentation of program behavior e.g.
a single second order constraint can distill the meaning of many daikon invariants.
this can be seen as an effort to generalize the observations that the daikon system already makes via sophisticated post processing.
for instance state machine behavior e.g.
calls to method foo can follow calls to method bar can be documented in the vocabulary of second order constraints.
second when the second order constraints are either supplied by the programmer or vetted by the programmer among candidate constraints suggested automatically they can help enhance dynamically inferred first order invariants by effectively crosschecking invariants against others.
in this way the noisy inferences caused by having a limited number of dynamic observations are reduced the second order constraint links the invariant at a certain program point with a larger set of observed values from different program points.
in exchange for modest specification effort second order constraints can eliminate inconsistencies and produce more relevant and more likely correct invariants.
in more detail the main contributions of our paper are as follows we identify and describe the idea of second order constraints that help improve the consistency and relevance of dynamically inferred invariants.
we define a vocabulary of common second order constraints.
we present a generalization of daikon s dynamic inference approach to second order constraints by appropriately defining the daikon confidence metric for second order properties.
we discuss how second order constraints can be implemented how their enforcement is affected by properties of the dynamic invariant inference system we identify monotonicity as a particularly important property .
we provide an implementation of the constraints in our vocabulary in the context of the daikon system.
we provide experimental evidence for the value of second order constraints and their dynamic inference.
we evaluate our approach both in controlled micro benchmarks and in realistic evaluations with the apache commons collections and the aspectj compiler.
a low cost effort to write constraints e.g.
a few hours spent to produce constraints results in significant differences in the dynamically inferred invariants.
furthermore the vast majority of a random sample among our dynamically inferred second order constraints are found to be true.
.
inv ariants and constraints we begin with a brief background on dynamic invariant inference and subsequently present our vocabulary of second order constraints.
for illustration purposes our discussion is in the context of java and the daikon invariant inference tool.
this is themost mainstream combination of programming language and dynamic invariant inference tool but similar observations apply to different contexts and tools.
.
daikon and dynamic invariant inference daikon tracks a program s variables during execution and generalizes their observed behavior to invariants.
daikon instruments the program executes it for example on an existing test suite or during production use and analyzes the produced execution traces.
at each method entry and exit daikon instantiates some three dozen invariant templates including unary binary and ternary relations over scalars and relations over arrays relations include linear equations orderings implication and disjunction .
for each invariant template daikon tries several combinations of method parameters method results and object state.
for example it might propose that some method mnever returns null.
it later discards those invariants that are refuted by an execution trace for example it might process a situation where mreturned null and it would therefore discard the above invariant.
daikon summarizes the behavior observed in the execution traces as invariants and generalizes it by proposing that the invariants hold in all other executions as well.
daikon can annotate the program s source code with the inferred invariants as preconditions postconditions and class invariants in the jml specification language for java.
.
a vocabulary of constraints to express rich constraints on invariants we use a vocabulary including constraints such as subdomain andsubrange .
these constraints are specified explicitly by the user of the invariant inference system by employing an annotation language.
furthermore we give the user an opportunity to express one more useful kind of information regarding inferred constraints a set of care about program variables and fields that are allowed in inferred invariants.
our vocabulary includes the following concepts onlycareaboutvariable hvari and onlycareaboutfield hfldi these annotations instruct the invariant inference system that the derived invariants of a method should only contain the listed method formal argument variables or class fields.
this prevents the system from deriving facts irrelevant to the property under examination which would also be more likely to be erroneous.
additionally it allows restricting invariants so that complex constraints can be expressed.
the onlycareabout... constraints are not consistency constraints on invariants but they are essential background for use together with the consistency constraints that follow.
subdomain m1 m2 the precondition of method m1implies the precondition of method m2.
for instance the author of a matrix library may specify the constraint subdomain processdiagonal processuppertriangular this means that method processdiagonal which works on diagonal matrices has a precondition that implies that of method processuppertriangular which works on upper triangular matrices the latter method is applicable wherever the former is.
matrix libraries often have a large number of related operations in terms of interface and applicability but with different implementations for performance reasons .
in this section we draw several examples from this domain for illustration purposes.
preconditions are not only expressible on method parameters but also on member fields of an object.
e.g.
one may specify that the preconditions of method append imply those of method write if the object is in an appendable state it can also be written to.in order to specify useful subdomain constraints one may need to limit the inferred invariants by employing the onlycareaboutvariable andonlycareaboutfield annotations presented earlier.
this also holds for many of the later constraints.
for instance methods m1andm2may be on separate objects.
thus their invariants would normally include distinct sets of variables.
yet if we specify their common variables with onlycareaboutvariable then the subdomain constraint can be applicable.
subrange m1 m2 this constraint is analogous to subdomain but for postconditions.
it means that the postcondition of method m1 is stronger than i.e.
implies that of m2.
again the condition may apply to parameter or return values e.g.
a method with postcondition isdiagonal return is related with subrange to one with postcondition isuppertriangular return .
where return stands for the return value of the method.
yet the condition can also be on object state.
for instance we may have constraints such as subrange listtail listrange this means that the state of the return value and overall object after execution of the method listtail is also a valid state after listrange the former method produces a subset of the possible results and effects of the latter.
canfollow m1 m2 this constraint means that the postcondition of method m1implies the precondition of method m2.
execution of method m2is enabled by execution of m1in this sense and it is a natural way to capture temporal sequencing rules e.g.
canfollow open write such specifications are common and are often expressed in the form of state machines.
note that the above constraint means that anopen can be followed by a write not a write has to be preceded by an open .
the latter is inexpressible since our vocabulary is only concerned with the relationship between conditions at two program points but there is nothing to prohibit other program points from establishing the same conditions.
follows m1 m2 this constraint means that the precondition of method m2implies the postcondition of method m1.
informally this means that the only states that m2can start from are states thatm1 may result in.
m1does not guarantee such a state though m1 s postcondition is necessary but not sufficient for preparing to execute m2.
in practice this constraint prevents the postcondition ofm1from being more specific than necessary.
for instance we may have follows add remove this does not signify that addneeds to execute before remove a different method may be reaching the same states as add .
but it means that if we are in a state where the last operation cannot have been an add e.g.
an empty structure then we cannot remove .
concord m1 m2 concord means that the postcondition of method m1implies that of method m2but only for the values that satisfy the preconditions of both m1andm2 or put another way 1our implementation provides some default restrictions on which variables are considered when second order constraints are used so that common cases are covered without explicit onlycareabout... annotations.
namely when two methods are linked by a secondorder constraint their invariants are defined over matching arguments and fields.
roughly argument variables match if they are in the same position and the methods have the same arity and class fields match if they have the same name and type.only for the values for which the precondition of m1implies that ofm2 .
this is a valuable constraint for methods that specialize other methods.
for instance there can be a fully general matrix multiply routine a more efficient one for when the first argument is an upper triangular matrix one for when the first argument is a diagonal matrix etc.
the operations invariants are linked with a concord constraint concord triangularmultiply matrixmultiply thus the postcondition of the specialized operation triangularmultiply should imply that of the more general operation indeed in this case the conditions should be equivalent for all their common inputs.
nevertheless the general operation matrixmultiply is applicable in more cases and thus has a weaker precondition than the specialized one.
for inputs valid for matrixmultiply but not triangularmultiply the concord constraint imposes no restriction.
.
meaning and completeness of secondorder constraints we intend for second order constraints to be devices for expressing relationships between program elements at a high level.
this means that the precise interpretation of the constraints will depend on the specifics of the invariant inference system we use and on its capabilities.
as a guideline we present the intended meaning of five of our constraints in figure column pre post .
we omit the onlycareabout predicates as they are straightforward.
in that column we summarize the meanings of each constraint as logical relations over the preconditions premand postconditions postmof all involved methods.
we assume in this presentation that all preconditions use the same names for parameters in the same position and all postconditions use the same names for their return value.
in other words prem1 prem2means that any constraints that prem1places on the first second third .
.
.
parameter of m1 prem2also places on the first second third .
.
.
parameter of m2.
as we can see the first four predicates capture all possible straightforward implications between the preconditions and postconditions of two methods.
predicate concord meanwhile captures a more complex but practically important second order constraint.
we will return to this figure later when we describe our implementation.
.
discussion second order constraints can serve as documentation of program behavior in much the same way that first order invariants can i.e.
for program understanding purposes .
furthermore second order constraints can offer external knowledge that helps steer invariant inference in the right direction.
certainly one reason to do this is to avoid erroneous invariants second order constraints serve to crosscheck invariants and thus enhance the dynamic opportunities to invalidate them even with a limited number of observations.
another important use of constraints however is in deriving more relevant invariants.
clearly a simple use of onlycareabout... can prevent some irrelevant invariants.
greater benefit can be obtained by more abstract constraints however.
consider for example a constraint on the constructor of a class cand on one of c s methods m. if we have the constraint follows c m then we have a hint that the constructor establishes part of the precondition for m. without the constraint we may observe the constructor s execution and derive for a certain field fld of the class the postcondition this.fld .
this inference would certainly be reasonable if whenever the constructor is executed fldis assigned the value .
yetconstraint pre post dataflow subdomain m1 m2 prem1 prem2 int m1 int m2 subrange m1 m2 postm1 postm2 outt m1 outt m2 canfollow m1 m2 postm1 prem2 outt m1 int m2 follows m1 m2 prem2 postm1 int m2 outt m1 concord m1 m2 prem1 prem2 postm1 postm2 prem1 t prem2 t outt m1 outt m2 figure meanings of second order constraints.
the invariant could be overly specific.
given that we know that the constructor s postcondition is implied by m s precondition we can observe all the different circumstances when mis called not necessarily right after construction .
this may yield the broader precondition this.fld for m. because of the follows constraint the constructor needs to also register all the same values and hence changes its postcondition to this.fld instead of the more specific this.fld .
the generality can mean that the new postcondition is more meaningful from a program understanding standpoint.
the specific value may be just an artifact of the specific test cases used i.e.
the postcondition this.fld may be erroneously over specific but even if it is correct it may be the result of an arbitrary technicality or a detail likely to change in the next version of the program.
certainly the follows constraint steers the invariant inference to the kind of invariant the user wants to see in this case the condition that partly enables m to run.
it is worth noting that the principle of behavioral subtyping can be viewed as a combination of constraints from our vocabulary.
informally behavioral subtyping is the requirement that an overriding method should be usable everywhere the method it overrides can be used.
this is a common concept employed also in program analyzers e.g.
esc java2 and design methodologies e.g.
subcontracting in design by contract .
when a method c.moverrides another s.m the behavioral subtyping constraints consist of a combination of subdomain s.m c.m and concord c.m s.m .
implicitly there are also onlycareaboutvariable andonlycareaboutfield constraints that restrict both the preconditions and postconditions to be over parameters of method mand member variables of the superclass s. in past work we discussed how consistent behavioral subtyping can be supported in the context of dynamic invariant inference systems and similar ideas have informed the present work.
.
design and implementation we next discuss the crucial design questions regarding a secondorder constraints facility as well as our own implementation decisions.
before this however we introduce the concept of monotonicity for a dynamic invariant inference system.
this concept plays a central role in our discussion and understanding.
.
background monotonicity an important consideration for our later implementation arguments is whether our invariant inference system is mostly monotonic if supplied more values to observe the conditions it will output will be logically weaker i.e.
broader .
note that monotonicity applies to the logical predicates and not to the number of invariants.
there may be fewer invariants produced when more values are observed but these will be implied by the invariants produced for any subset of the values.
most dynamic invariant inference tools are in principle monotonic.
tools like dysy and krystal use a combination of dynamic and symbolic execution.
the invariants are computedfrom the boolean conditions that occur inside the program text when these are symbolically evaluated.
the more executions are observed the more the invariants of a program point are weakened by the addition of extra symbolic predicates in a disjunction .
similarly tools like daikon or diduce have invariant templates that are multiply instantiated to produce concrete candidate invariants.
the candidate invariants are conceptually organized in hierarchies from more to less specific.
values observed during execution are used to falsify invariants and remove them from the candidate set.
themost specific non falsified candidate invariant of each hierarchy is a reported invariant.
for instance if two candidate invariants x and x are satisfied by all observed values of x then the former will be reported as it is more specific.
this is a monotonic approach it means that as candidate invariants are falsified they are replaced by more general conditions.
nevertheless invariant detection tools often include nonmonotonicities in their inference logic.
for instance daikon uses a confidence threshold for invariants an invariant is not output even when consistent with all observations if the number of pertinent observations is small.
similarly daikon treats some boundary values and invariant forms specially.
for instance if the maximum value for a variable is daikon will not output an invariant of the form x but if it additionally observes the value for the variable it will output x an invariant that would have been true even without observing the value but would not have been reported .
furthermore daikon produces the weakest predicate true when no invariants can be inferred.
these features entail non monotonicity observing more inputs will produce a stricter invariant.
in general some non monotonicity is unavoidable in practically useful dynamic invariant inference tools even if just in corner cases.
for instance if a tool is strictly monotonic then it has to infer a precondition and postcondition of false for every method that happens to not be exercised by the test suite.
this is the only logical condition that is guaranteed to be weakened as monotonicity prescribes when we add an execution that does exercise the method.
computing invariants of false is a sound approach accurately captures observations but largely useless.
any further use of the produced invariants cannot employ the method in any way as it can never establish the preconditions for calling it or know anything about its results.
effectively monotonic invariant inference would have to report that a method is forever unusable if it was not observed to be used in the test run.
this and other similar examples in practically significant cases preclude the use of strictly monotonic dynamic invariant inference.
.
implementation we implemented second order constraints in the daikon system.
daikon is not only the mainstream option for dynamic invariant inference but also convenient for engineering purposes.
the dysy tool on which we have worked in the past was another interesting prospect but requires c .net and a specialized closedsource dynamic symbolic execution infrastructure.
there are two aspects to the implementation.
first we infer second order auto matically through dynamic observations of program behavior.
second we allow treating second order constraints as ground truth and use them to influence regular invariant inference.
dynamically inferring second order constraints the key construct in most of our second order constraint is an implication between pre post conditions pandqat two different program points with each one being either the entry or the exit of a program procedure .
our strategy for proving the second order constraint p qis to first use daikon rev.
2eded4baf181 to produce pandqand then employ the simplify theorem prover to check whether pcan imply q. the full implication check may fail even if the implication holds in principle.
one reason for this is that an inadequate test suite may lead daikon to produce a slightly inaccurate porq.
furthermore the theorem prover may be unable to decide whether an implication is satisfiable or not.
therefore a more realistic check since pandqare expressed as conjunctions of invariants is to see if a particularly large number of invariants inqare subsumed by invariants of p i.e.
implied by the full conjunction p .
in order to find whether a sufficiently large number of implications between pand the constituent invariants of qare true we define the success rate sa of the implication as sa n m where nrepresents the number of invariants in qthat can be implied by pandmdenotes the number of invariants of q. the success rate on its own is often not enough for comparing the likelihood of a second order constraint being true.
in our definition of success rate all invariants are treated equally so in a case with lots of junk invariants in pbut not in qthat ratio may get overwhelmed by the junk.
daikon uses a confidence metric to approximate the probability that an invariant cannot hold by chance alone.
if we sum up the confidence values for all invariant implications between pand each constituent invariant of q then the weight of the junk invariants in the ratio will decrease.
thus we extend the definition of confidence to second order constraints in order to approximately measure the probability that a second order constraint could not hold by chance alone.
for regular invariants daikon defines the confidence of an implication relation inv1 inv2 to be the product of the confidence of the guard inv1 and the confidence of the consequent inv2 .
similarly the second order constraint confidence of p qcan be defined as the mean of the confidences of the implication relations between pand each invariant of qthat is implied according to simplify .
representing the confidences of invariants in pbypc1 pc2 ... pcz and denoting the confidences of invariants of qthat can be implied by pbyqc1 qc2 ... qcn we calculate the second order constraint confidence ma asma pc1 pc2 pcz qc1 qc2 qcn n. we filter out second order constraints whose success rate is below a threshold by default and rank the unfiltered secondorder constraints according to confidence.
it is meaningful for the user to change the success rate threshold possibly based on the accuracy of invariants produced by daikon for the program at hand.
the fewer redundant and irrelevant invariants a program has the higher the program s success rate filter can be.
the time complexity of our algorithm is quadratic over the number of methods.
we consider all combinations of program points inside a class as candidate second order constraints.
if there are n methods in a class there are 2nprogram points i.e.
2n 2n potential second order constraints.
to verify a candidate second order constraint we invoke the simplify prover on implications between invariants.
removing irrelevant and redundant invariants before applying our tool can help reduce theorem proving time.
standard avenues for so with daikon include using more represen tative test suites and employing the dyncomp tool for more accurate invariants.
we use a few heuristics to improve the accuracy of derived second order constraints.
one heuristic is to normalize parameters a parameter s name is based on its position in the parameter list.
for example if we examine the second order constraint subdomain foo int i int j bar int x int y then we do not use the names iandjwhen we compare to bar int x int y .
instead we substitute arg1 foriandx and arg2 forjandy.
we implement this normalization via regular expression transformation on the data trace file generated by chicory the java instrumenter inside daikon .
in addition if a variable only exists in the consequent side program point of a second order constraint it often gets in the way of verification for the second order constraint.
we ignore invariants that contain such variables in the consequentside program point.
another heuristic is that invariants over variables that are likely to be meaningless for cross method comparisons are ignored.
for instance in the case of follows bar foo andsubrange foo bar we ignore invariants over the orig x variable which refers to the value of variable xupon entry to a procedure at the exit of bar for subrange foo bar and canfollow foo bar we ignore procedure parameters at both the entry and exit point of bar for follows bar foo we ignore the return variable at the exit of bar.
using second order constraints for better invariants we extended daikon with an annotation mechanism for second order constraints.
users can pass a separate configuration file with second order constraints to daikon.
this changes the daikon processing of the low level observations and allows refining the inferred invariants without having to re run any test suites.
the main element of our approach is that when the precondition or postcondition of a method m1is constrained to imply the precondition resp.
postcondition of another method m2 as shown in our earlier figure column dataflow we propagate the values observed at entry resp.
exit of m1tom2.
this ensures that producing m2 s invariants takes into account all the behavior observed for m1.
note that m2need not be executed during invariant inference the conditions observed established for m1are simply registered as if m2had also observed established them.
these observations are suitably adapted to be over common variables as dictated by onlycareabout... constraints including implicit assumptions as mentioned in footnote .
for the first four second order constraints of figure the implementation of the above value propagation is straightforward as it can leverage existing daikon facilities.
specifically the implementation extensively hijacks the daikon dataflow hierarchy mechanism.
this daikon internal facility propagates primitive invariants between different program points a program point is a line of code or the entry or exit from a method .
the machinery is therefore quite suitable with some minor adjustment to suppress filtering in some cases for implementing our value propagation.
however the concord second order constraint is more complex we only want to flow primitive invariants from outt m1 to outt m2 if at execution point tthe preconditions of both m1and m2hold.
however at this point in daikon s execution we do not yet know what the preconditions of m1andm2should be since we have not even seen all primitive invariants yet.
we thus evaluateconcord constraints in two passes.
the first pass stores all data from int m1 int m2 and outt m1 .
at the end of this pass we ask daikon to compute the preconditions ptom1andm2using daikon s usual heuristics and any other second order constraints .
in the second pass we now use these preconditions on the data from int m1 andint m2 p mi t holds iff int mi satisfiesthe precondition to miat pointt.
we thus iterate over tone more time to copy all primitive invariants from outt m1 tooutt m2 and update daikon s results as needed.
for example assume that we are examining two methods int m1 int x andint m2 int y .
we make the following observations about m1 m1 t int m1 outt m1 t1 arg1 3return t2 arg1 return t3 arg1 return t4 arg1 return that is the method is invoked at time t1with its first and only parameter xbound to and returns etc.
from the table above daikon might plausibly infer the precondition pre m1 true and postcondition post m1 return arg1 .
now assume that we make the following observations about m2 m1 tint m2 outt m2 t5 arg1 return t6 arg1 return t7 arg1 return here daikon sees no negative inputs and a constant output so it might infer precondition pre m2 arg1 0and postcondition post m2 return .
if the user intended m2to be a specialized version of m1for nonnegative integers the precondition for m2would be correct but the postcondition would be wrong.
the user can address this by adding the constraint concord m1 m2 .
this constraint will make our system first compute preconditions and postconditions as above then compute all the times tat which pre m1 t agrees with pre m2 t .pre m1is always true so we will only filter out t1via pre m2.
consequently daikon will get to see all inputs and outputs fromt2 t3andt4in addition to the ones it was already considering for method m2.
with this additional data daikon can no longer infer post m2 return but might instead conclude post m2 return arg1 return which matches the user s intention.
.
discussion it is evident from the previous section that our two mechanisms that of dynamically inferring second order constraints and that of taking them into account when inferring invariants operate differently.
the former follows a static approach for checking invariant implication the simplify system is used as a symbolic prover.
however the mechanism of enforcing invariant implications to produce different invariants by taking second order constraints into account eschews symbolic reasoning in favor of propagating more dynamic observations.
why do we not just take the conjunction of the produced invariants and declared second order constraints simplify it symbolically and report it as the new produced invariants?
the reason is that there is noise introduced when generalizing from observed executions to invariants e.g.
because the invariant patterns are uneven and this carries over to the combined invariants.
it is better to generalize i.e.
compute invariants from more observations than to generalize from fewer ones and then combine the generalizations symbolically.
the above insight is evident in the case of non monotonic invariant inferences which are virtually unavoidable as mentioned in section .
.
for instance consider a subdomain m1 m2 constraint.
ifpis the precondition of m1andqis the precondition ofm2 then we can statically satisfy the constraint by considering the real precondition of m2to bep q so that it is always implied byp.
if however method m1is never called in our test suite daikon will infer trueas its precondition.
this will make truealsobe the precondition of m2 even though we have actual observations for that method!
this result is counter intuitive and so common in practice as to significantly reduce the value of produced invariants.
in contrast in our chosen approach a second order constraint just causes more observations to register.
these observations are then generalized using the same approach as the base inference process i.e.
just as if the system had really registered these observations.
this is particularly beneficial in cases of nonmonotonicity.
consider again our example of an m1and m2 with preconditions pandq respectively and a constraint subdomain m1 m2 .
if m2observes the exact values that led to the inference of p then these values combined with the ones that led to the inference of q may induce higher confidence for an invariant more specific than either porq which will now be reported because of crossing a confidence threshold .
caveats note that our approach of propagating observations from one program point to another does not strictly guarantee that the dynamically inferred invariants satisfy the second order constraints.
interestingly if the inference process is monotonic correctness is guaranteed under monotonic invariant inference taking into account the union of two sets of observations should produce a condition that is weaker than either individual condition.
this observation argues for why our approach is expected to be correct as long as there are enough observations dynamic invariant inference is typically monotonic as discussed in section .
.
additionally any implementation of dynamic invariant inference under second order constraints suffers from the possibility of a disconnect between observed executions and values reflected in an invariant.
the source of the problem is that we are allowing an invariant to be influenced by values not really seen at that program point during execution.
these values will be reflected in a reported invariant but will not be reflected in other dependent invariants.
for instance using second order constraints we may infer a more general precondition but not the corresponding postcondition.
thus readers who consider the two invariants together may misinterpret their meaning even when the invariants are individually correct.
.
ev aluation there are two questions that our evaluation seeks to answer do second order constraints aid the inference of better first order invariants?
can correct second order constraints be inferred dynamically?
the next two sections address these questions in order.
.
impact of second order constraints we explored the utility of second order constraints in three case studies one of a manageable small example application with a relatively thorough test suite and two of large unfamiliar programs with their actual test suites.
in all studies we first took existing classes and examined their apis.
we then added second order constraints to manifest implicit relationships between api methods in the same class or in different classes.
we ran a series of experiments to determine the effects that adding these constraints had on the observed pre and postconditions reported by daikon.
in these three case studies second order constraints were written by hand and their correctness was verified by inspection.
this is a feasible approach in several settings since second order constraints are much sparser coarse grained than first order invariants one needs to write few second order constraints to affect a large number of first order invariants.p u b l i c c l a s s stackar p u b l i c boolean isempty p u b l i c boolean i s f u l l p u b l i c void makeempty p u b l i c void push o b j e c t p u b l i c void pop p u b l i c o b j e c t t o p p u b l i c o b j e c t topandpop figure the array based stack stackar shipped with daikon .
.
stackar our first case study is stackar an array based fixed size stack implementation that ships with daikon and is perhaps the most common daikon benchmark and demonstration example.
stackar is interesting because it is the most controlled of our case studies due to test suite coverage and small size .
figure lists the class and its methods.
methods isempty andisfull are straightforward.
makeempty clears the stack.
push o pushes element oto the top of the stack.
pop removes the top stack entry but does not return a value.
instead top peeks at the top of the stack and returns the most recently pushed value while topandpop returns the top of the stack before removing it.
operations top andpop raise an exception if the stack is empty while topandpop returns null in that case.
to explore our invariants we examined this api and determined second order constraints that we considered to be meaningful for this class.
the process took one of the authors negligible time less than a minute although there was previous discussion of interesting invariants hence the exact effort cost is unclear .
we split these constraints into separate experiments and explored the effect they had on daikon s invariant detection mechanism experiment ex1 subdomain ontopandpop top and pop.
the operations top pop and topandpop all require a nonempty stack so we instructed the system to treat all of them as having identical subdomains.
experiment ex2 any push sets up the stack for a top pop or topandpop .
we experimented with setting up canfollow relations between push and the three top pop operations.
to ensure the highest quality invariants we ran these experiments with the dyncomp tool enabled.
experiment we instructed the system to treat all of top pop andtopandpop as having the same subdomains using specifications such as subdomain stackar.topandpop stackar.pop subdomain stackar.pop stackar.top subdomain stackar.top stackar.topandpop the above specification captures a circular subrange dependence and hence equality it specifies that all three operations should have effectively the same preconditions.
there are other ways to express this equality we experimented with reversing the circular dependencies and with establishing mutual subdomain constraints between all three interesting pairs of the three operations for a total of six constraints .
we found these approaches to be equivalent.
the experiment results in the elimination of five spurious invariants from pop this has only one value this.thearray has only one value size this.thearray this.thearray !
null this.topofstack size this.thearray also this.topofstack size this.thearray is replaced by the weaker and correct this.topofstack size this.thearray .
our constraints further helped infer two new correct preconditions one establishing an inequality between a stack s default capacity and the size of this.thearray and one establishing that the top of the stack does not exceed the size of the internal array.
as a result the preconditions between the three methods were identical.
experiment for this experiment we specified that the push operation sets up a stack for using topand similar operations canfollow stackar.push object stackar.top canfollow stackar.push object stackar.pop canfollow stackar.push object stackar.topandpop this specification improved the inferred invariants removing four incorrect preconditions the same as for experiment except for this has only one value and adding three invariants one states that topofstack cannot exceed the internal array size as in experiment .
one establishes an inequality between stack default capacity and array size as in experiment .
one establishes that the topofstack is nonnegative.
again the changes affected method pop while top and topandpop remained unaffected as they already had high test coverage.
in summary the impact of second order constraints on stackar under the standard test suite was overwhelmingly positive.
all of the additional invariants were correct and most were insightful while spurious invariants were eliminated.
.
.
apache commons collections our second case study is the apache commons collections library 2version .
.
.
this library contains classes of which we used a total of explicitly3for our experiments.
for our experiments one of the authors unfamiliar with the library examined the above classes and constructed a specification while consulting the api documentation with a total of second order constraints comprising experiments.
this process took approximately .5h.
the author spent another 2h doublechecking and fixing the invariants after specification.
this amount of effort is in the noise level compared to the development effort for a library of this size.
we then examined the utility of our specifications by running daikon first with and then without our constraints.
since running the entire test suite with daikon s instrumentation tool would have consumed harddisk space in excess of gb compressed we instructed daikon s instrumentation tool to only report invariants for the methods we were interested in.
we only ran these experiments with dyncomp disabled as using the dyncomp instrumented jdk caused errors during execution.
we recorded the invariants of all affected methods and analyzed the generated differences.
figure summarizes our results.
we first list the affected class or classes then the concrete secondorder constraints we introduced slightly compressed for space .
3some classes may use other classes from the library internally.
classes second order constraints first order invariants pre post pre post arraystack canfollow push peek arraystack subrange peek get listutils subdomain removeall retainall listutils subdomain sum subtract collectionutils subdomain subtract disjunction collectionutils subdomain subtract intersection treebidimap subdomain containskey get treebidimap subdomain nextkey previouskey unmodifiablesortedbidimap subrange tailmap submap treebidimapsubdomain remove get 7subdomain get remove treebidimapsubdomain getkey removevalue 7subdomain removevalue getkey dualtreebidimap subrange tailmap submap unboundedfifobuffer follows add remove setuniquelist follows addall remove abstractbidimapdecorator subrange getkey removevalue reverselistiteratorsubrange previousindex nextindex 1subrange nextindex previousindex cursorablelinkedlist canfollow addnode removenode cursorablelinkedlist canfollow addnode updatenode linkedmapsubdomain get remove 1subrange get remove listorderedmap subrange put remove compositemap canfollow addcomposited removecomposited compositecollection concord addcomposited collection addcomposited collection collection figure summary of our experiments on the apache commons collections.
next we considered the invariants inferred by daikon restricted to invariants of the particular methods occurring in our constraints.
for example in experiment we considered methods push and peek in class arraystack only.
the final four columns summarize these invariants first we give the number of invariants in the absence of any second order annotations separated into pre and postconditions preandpost .
finally we give the differences over any preconditions pre and postconditions we observed post .
we use the notation x yto indicate that we added xnew invariants and removed yexisting ones.
qualitatively the use of second order constraints on the apache commons collections was a clear win.
all invariants removed were false to the best of our understanding.
we added invariants of which our manual inspection found to be true i.e.
expected to hold for all executions not just the ones observed and to be false.
the added invariants arise due to non monotonicity.
in experiment for example the augmented observations in the presence of secondorder constraints enable two additional true invariants i.e.
a stronger inference in the precondition of method nextindex this.list !
null and this.iterator !
null .
the invariant orig value !
null was incorrectly added to abstractbidimapdecorator.removevalue object in experiment where parameter value does not have to be non null.
furthermore we replaced invariants with more general invariants.
consider for example experiment with second order constraint follows add remove .
the postcondition of method unboundedfifobuffer.add object originally contained invariants such as this.head one of .
such false invariants are replaced with a more insightful this.head .
.
.
aspectj compiler our third case study is the aspectj compiler.
we followed the same approach as for the apache commons collections collectinginvariants from unit tests and integration tests.
since aspectj lacks detailed api documentation one of the authors unfamiliar with the library directly inspected the source code of aspectj and derived a total of second order constraints.
the combined process of understanding the foreign code base and writing invariants cost the author approximately 10h.
again dyncomp s instrumented jdk caused problems during execution so we only tested with dyncomp disabled.
we summarize our results in figure .
we removed invariants.
all of the invariants were false.
for instance most variable has only one value and variable is one of f g invariants largely due to limitations in the test suite were removed or replaced by more accurate invariants.
we also added false invariant in experiment again due to non monotonicity by assuming a variable is always less than a constant.
meanwhile we added true invariants and replaced invariants with more general ones.
for instance without the secondorder constraint subrange getajtype getdeclaringtype in experiment daikon reports no invariants for the exit of the getdeclaringtype method.
our subrange constraint yields two new postconditions return !
null and return.getclass ajtypeimpl.class due to observations on getajtype .
.
inferring second order constraints we next evaluate the success of our dynamic process of inferring second order constraints.
note that dynamically inferred secondorder constraints are useful for many reasons as documentation of program behavior on their own i.e.
as deeper invariants than typical daikon invariants.
for finding bugs in manually stated second order constraints.
for offering the programmer a set of mostly correct second order constraints to choose from.
classes second order constraints first order invariants pre post pre post ajtypesystem adviceimpl subrange getajtype getdeclaringtype programelement subdomain tosignaturestring boolean tolabelstring boolean programelement subdomain tolabelstring boolean tosignaturestring boolean programelement subrange tolabelstring tolabelstring boolean programelement subdomain getparent getchildren programelement subrange genmodifiers getmodifiers int programelement subdomain tolabelstring tosignaturestring programelement subdomain tosignaturestring tolabelstring programelement subdomain getchildren getparent fieldsignatureimpl subdomain getdeclaringtypename getdeclaringtype fieldsignatureimpl subdomain getdeclaringtype getdeclaringtypename methodsignatureimpl subdomain getfield getfieldtype methodsignatureimpl subdomain toshortstring tolongstring methodsignatureimpl subdomain getdeclaringtype getdeclaringtypename signatureimpl subdomain getdeclaringtypename getdeclaringtype signatureimpl subdomain getdeclaringtype getdeclaringtypename signatureimpl subdomain tolongstring toshortstring signatureimpl subdomain toshortstring tolongstring bcelweaver canfollow prepareforweave weave unwovenclassfile bcelobjecttype bcelweaver canfollow prepareforweave weave unwovenclassfile bcelobjecttype bool.
bcelweaver canfollow prepareforweave weaveandnotify bcelweaver canfollow prepareforweave weavenormaltypemungers bcelweaver canfollow prepareforweave weaveparenttypemungers bcelweaver canfollow prepareforweave weave iclassfileprovider bcelweaver canfollow prepareforweave weaveparentsfor bcelweaver canfollow prepareforweave weavewithoutdump figure summary of our experiments on the aspectj compiler.
although the first benefit is very important it is hard to quantify experimentally.
therefore we focus on the second and third benefits and specifically on evaluating the correctness of automatically inferred second order constraints.
correctness of inferred constraints we inspected the results of our automatic mechanism for inferring second order constraints section .
on four randomly selected classes from acc and aspectj two each .
one of the authors manually verified all of the generated second order constraints.
for this experiment we considered a second order constraint to be correct whenever it did not disagree with the implementation of the given class.
figure lists our precision results.
we note that overall precision exceeds suggesting that our confidence metric is highly effective at identifying low quality constraint candidates.
our five losses in lstbuildconfigmanager were three follows and two subrange constraints involving methods with lowquality invariants.
for example four of the five constraints involved anaddlistener method for which daikon had failed to observe the method s effect on the internal object state.
although these constraints are true they are not necessarily all interesting.
many of them just reflect implementation artifacts and would not arise if the methods in question had interesting invariants to begin with.
for instance for two methods that have a very small number of invariants in their preconditions it is easy to find meaningless agreement e.g.
on the fact that their argument is never null .
forsingletonmap we observed more than proposed highconfidence constraints that claimed that most methods were in some relationship to each other.
we found that singletonmap is an immutable class meaning that methods do not influence each other on subsequent calls therefore many invariants remained the same across methods resulting in second order constraints being derived.
these include the two second order constraints we manually wrote for singletonmap but also many others of muchless value.
this suggests the existence of other useful higherorder constraints beyond the catalog we have proposed herein for singletonmap a meta constraint immutable would be the most concise way to express the properties that we observed.
in summary we found that dynamic second order constraint inference is highly effective at identifying high quality sets of second order constraints even though we allow some margin of error over already erroneous or imprecise axioms.
inferred vs. manual constraints our manually derived second order constraints of the previous section were never intended as a full or ideal set but as a set of constraints that take low effort to produce and have significant effect over first order invariants.
still it is instructive to compare them with automatically inferred constraints.
for this purpose we ran our inference mechanism on all classes that we had manually written second order constraints for.
indeed our manual effort to produce constraints for acc and the aspectj compiler originally yielded 64constraints and not just the52shown in figures and .
12manually derived second order invariants were removed exactly because their absence from the set of automatically inferred constraints caused us to re inspect them and discover they were erroneous!
this pattern is likely to also occur in practice when dealing with unfamiliar code in fact 8of the12were in aspectj which lacks documentation .
note that in a scenario in which software authors write their own second order constraints such disagreements between hand written and inferred second order constraints would point to more serious issues likely to poor test suites or to implementation bugs.
of the 52constraints in figures and our automatic inference mechanism produced 37and missed .
on closer inspection we found that 6of those missing hand written second order constraints are rejected although true due to low success rate.
this is caused by noise invariants participating in the corresponding preconditions and postconditions due to very few actual observa second order constraints library class methods program points daikon invariants total correct incorrect acc abstractmapbag acc singletonmap aspectj reflection aspectj lstbuildconfigmanager figure results of inferring second order constraints.
in the above program points lists only program points that our inference considers i.e.
enter and exit program points.
tions for the relevant methods.
7more second order constraints are missing due to having no data samples at all for the methods.
the last2second order constraints are missing since our current implementation does not support detecting the concord constraint or constraints relating methods in two different classes.
thus overall the automatic inference facility produces quite high quality results on its own and is found to be a strong complement for manual derivation of second order constraints.
.
related work there is a wealth of other work on invariant inference.
we next selectively focus on some recent approaches that were not covered in the body of the paper typically because they focus on static invariant inference techniques .
for reverse engineering gannod and cheng proposed to infer detailed specifications statically by computing the strongest postconditions.
nevertheless pre postconditions obtained from analyzing the implementation are usually too detailed to understand and too specific to support program evolution.
gannod and cheng addressed this deficiency by generalizing the inferred specification for instance by deleting conjuncts or adding disjuncts or implications.
their approach requires loop bounds and invariants both of which must be added manually.
there has been some recent progress in inferring invariants using abstract interpretation.
logozzo infers loop invariants while inferring class invariants.
the limitation of his approach are the available abstract domains numerical domains are best studied.
resulting specifications are expressed in terms of fields of classes.
flanagan and leino propose a lightweight verification based tool named houdini to statically infer esc java annotations from unannotated java programs.
based on pre set property patterns houdini conjectures a large number of possible annotations and then uses esc java to verify or refute each of them.
the ability of this approach is limited by the patterns used.
in fact only simple patterns are feasible otherwise too many candidate annotations will be generated and consequently it will take a long time for esc java to verify complicated properties.
taghdiri uses a counterexample guided refinement process to infer over approximate specifications for procedures called in the function being verified.
in contrast to our approach taghdiri aims to approximate the behaviors for the procedures within the caller s context instead of inferring specifications of the procedure.
henkel and diwan have built a tool to dynamically discover algebraic specifications for interfaces of java classes.
their specifications relate sequences of method invocations.
the tool generates many terms as test cases from the class signature.
the results of these tests are generalized to algebraic specifications.
they use a second tool to dynamically compare their specifications against implementations by executing both simultaneously and comparing their behavior .
much of the work on specification mining is targeted at inferring api protocols dynamically.
whaley et al.
create a finitestate machine into which a transition from method a to method b is added if the post condition of method a is not mutually exclusive with the pre condition of method b. meghani and ernst build upon whaley s work by using daikon to determine the likely pre post condition of each method.
other approaches use data mining techniques.
for instance ammons et al.
use a learner to infer nondeterministic state machines from traces similarly yang and evans built terracotta a tool to generate regular patterns of method invocations from observed runs of the program.
li and zhou apply data mining in the source code to infer programming rules i.e.
usage of related methods and variables and then detect potential bugs by locating the violation of these rules.
gabel and su dynamically infer and verify method call ordering constraints and report the constraints only if they are violated.
beschastnikh et al.
use mined temporal invariants from logs to derive a refined finite state machine.
although not explicitly our goal some of our second order constraints can be thought of as a way to express temporal api protocols.
for example we can find the general has next type specification by checking if canfollow has return true next or that the postcondition of has when has returns true implies the precondition of next .
it is interesting future work to see how to integrate existing techniques on specification mining with our approach to derive automata that describe correct behavior.
.
conclusions second order constraints can steer dynamic invariant inference to avoid erroneous invariants and to derive more relevant invariants while reducing noise.
we have defined a vocabulary of secondorder constraints and described how each of them encodes information that is typically known by programmers and useful to a dynamic invariant detector.
we have taken an approach in which the second order constraints control the propagation of the observations on which invariant detection is based.
we have also extended the daikon system so as to infer second order constraints.
overall we consider second order constraints to be a particularly promising idea not just as a meaningful documentation concept but also for improving the consistency and quality of dynamically inferred invariants a major challenge in this area.
.