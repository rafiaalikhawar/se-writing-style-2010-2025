generating obstacle conditions for requirements completeness dalal alrajeh jeff kramer axel van lamsweerde alessandra russo and sebastian uchitel department of computing imperial college london uk da04 jk ar3 su2 doc.ic.ac.uk icteam universit e catholique de louvain belgium avl info.ucl.ac.be abstract missing requirements are known to be among the major causes of software failure.
they often result from a natural inclination to conceive over ideal systems where the software to be and its environment always behave as expected.
obstacle analysis is a goal anchored form of risk analysis whereby exceptional conditions that may obstruct system goals are identified assessed and resolved to produce complete requirements.
various techniques have been proposed for identifying obstacle conditions systematically.
among these the formal ones have limited applicability or are costly to automate.
this paper describes a tool supported technique for generating a set of obstacle conditions guaranteed to be complete and consistent with respect to the known domain properties.
the approach relies on a novel combination of model checking and learning technologies.
obstacles are iteratively learned from counterexample and witness traces produced by model checking against a goal and converted into positive and negative examples respectively.
a comparative evaluation is provided with respect to published results on the manual derivation of obstacles in a real safety critical system for which failures have been reported.
keywords requirements completeness risk identification obstacle model synthesis model checking inductive learning goal oriented requirements engineering i. i ntroduction completeness is among the most critical and difficult challenges facing requirements engineers.
missing requirements and assumptions are reported as one of the major causes of software failure .
incompleteness often arises from the lack of anticipation of exceptional conditions.
the natural inclination is rather to conceive idealised systems this prevents adverse events or conditions from being properly identified and as a result specifications of suitable countermeasures in such circumstances are missing.
risk analysis is therefore at the heart of the requirements engineering process .
a riskis commonly defined as an uncertain factor whose occurrence may result in some loss of satisfaction of some corresponding objective.
in goal oriented system modelling frameworks obstacles are introduced as a natural abstraction for risk analysis when using goal models .
an obstacle to a goal is a precondition for the non satisfaction of this goal.
depending on the category of goal being obstructed obstacles may correspond to safety hazards security threats inaccuracyconditions on software input output variables with respect to their environment counterpart etc.
obstacle analysis roughly consists of three steps a identify as many obstacles as possible to every leaf goal in the systems goal refinement graph b assess the likelihood and severity of each obstacle and c resolve likely and severe obstacles by systematic transformations to the goal model using appropriate countermeasures.
the obstacle identification step is obviously crucial.
in a formal technique is described for generating obstacles by regressing goal negations through available domain properties.
although quite systematic this technique appears costly to implement for goals formalised in a first order real time linear temporal logic.
no tool support is available.
this paper presents an alternative tool supported technique for obstacle generation.
a complete set of obstacles relative to what is known about the domain is computed by iterating the following cycle a a behaviour model is synthesised from the available background properties b this model is verified against the goal and against a negated form of it in order to generate a negative trace counterexample and a positive trace witness respectively c the negative trace is taken as positive example whereas the positive trace is taken as negative example input for a learning engine d the learning tool generates a set of candidate obstacles that cover the positive example and exclude the negative one e the user can then select from the generated obstacles those considered likely and severe and suggest further domain properties f a new cycle is applied to the background properties augmented with such properties and the negated obstacles generated at the previous cycle.
the process terminates when a domaincomplete set of obstacles is generated.
the synergistic use of model checking and learning technologies was already explored successfully in for the generation of specifications of software operations from goals.
our contributions in this paper include the following.
a new combination of model checking and learning for supporting the significant challenging task of riskdriven elaboration of more complete requirements.
automation is increased with respect to the earlier combined use of model checking and learning in positive traces have to be elaborated manually .moreover the goal specification language is much more expressive allowing us to capture the full range of achieve andmaintain goals only immediate achieve goals are considered in .
tool support is provided for formal obstacle generation which was unavailable to date.
moreover with respect to earlier techniques the one here generates obstacles that are domain consistent by construction domainconsistency checks have to be performed separately in .
the technique is also guaranteed here to converge to a domain complete set of obstacles.
the paper is organised as follows.
section ii briefly provides some background on goal modelling obstacle analysis labelled transition systems for behaviour model analysis and synthesis fluent linear temporal logic for goal specification and inductive logic programming for learning obstacles.
section iii introduces a motivating example.
the approach is detailed in section iv.
section v discusses our experience in using our technique and tool for generating a variety of obstacles in a real safety critical system for which failures have been reported .
some related work is discussed in vi.
section vii concludes the paper.
ii.
b ackground a. goal oriented modelling and obstacle analysis agoal is a prescriptive statement of intent to be satisfied by the agents forming the system.
the latter include the software to be developed pre existing software devices such as sensors and actuators people etc.
the word system thus refers to the software to be together with its environment.
unlike goals domain properties are descriptive statements about the problem world such as natural laws .
a goal model is an and or graph showing how goals contribute positively or negatively to each other .
parent goals are obtained by abstraction whereas child goals are obtained by refinement.
in a goal model each leaf goal is assigned to a single system agent as a requirement orassumption depending on whether it is assigned to the software to be or an environment agent respectively.
a goal may be behavioural orsoftdepending on whether it can be satisfied in a clear cut sense or not.
this paper focusses on behavioural goals.
a behavioural goal captures intended behaviour declaratively and implicitly.
it can be of type achieve ormaintain avoid .
the specification pattern for an achieve goal is ifcthen sooner or later t where c denotes a current condition and tatarget condition with obvious particularisations to immediate achieve bounded achieve and unbounded achieve goals.
the pattern for a maintain resp.
avoid goal is always g resp.
if cthen never b where gandbdenote a good andbad condition respectively.
an obstacle to a goal is a domain satisfiable precondition for the non satisfaction of this goal.
the following definition makes this more precise .definition .
let dom be a set of known domain properties and g a goal assertion.
an assertion o is said to be an obstacle to g in dom iff the following conditions hold o dom g obstruction o dom ne ationslash false domain consistency obstacles can be and or refined into sub obstacles resulting in a goal anchored form of risk tree.
in such tree the root obstacle is the negation of the associated leaf goal in the goal model an and refinement captures a combination of sub obstacles entailing the parent obstacle an orrefinement captures alternative ways of entailing the parent obstacle and recursively of obstructing the corresponding leaf goal the leaf sub obstacles are single fine grained obstacles whose likelihood can be easily estimated.
definition .
let dom be a set of known domain properties and g a goal assertion.
a set of obstacles o1 o2 ... o n togis said to be domain complete for gin dom if the following condition holds o1 o2 ... on dom g domain completeness note that completeness while highly desirable is bounded by what we know about the domain.
obstacle generation techniques should therefore support the incremental elicitation of relevant domain properties as well.
patternbased heuristics can be used for more focussed elicitation .
in particular for the above patterns defining achieve and maintain avoid goals domain properties of the form iftthen norifgthen nare worth eliciting where n denotes a necessary condition for the target condition tor good condition g they result in obstacles of form never nor sooner or later not n respectively.
b. model checking model checking is an automated technique for verifying that a model msatisfies property writtenm .
in this paper we are interested in declarative models and properties both expressed in a temporal logic called fluent linear temporal logic fltl with labelled transition systems as the semantic structure.
in fltl a fluent is a propositional atom defined by a set ifof initiating events a set tfof terminating events and an initial truth value either true orfalse .
given a set of event labels act we write f an bracketle tif tf init an bracketri htas a shorthand for a fluent definition where if act tf actandif tf and init true false .
fltl assertions use standard operators for temporal referencing such as circlecopyrt at the next time point at the previous time point some time in the future always in the future u always in the future until w always in the future unless and always implies .
we will also use real time operators x x andu xwhere andxdenotes a number of time points .
the semantics of fltl assertions is defined in terms of behaviour models called labeled transition systems ltss .
an lts is an automaton defined by a structure q act q0 whereqis a finite set of states actis a set of event labels q act q is a labeled transition relation andq0is an initial state.
the global system behaviour is captured by the parallel composition denoted as bardbl of ltss one for each component by interleaving their behaviour but forcing synchronisation on shared events .
a trace in an lts is a sequence of events from the initial state.
given a trace trover actand fluent definitions d a fluent is said to be true resp.
false in a trace trat position i denoted tr i f iffeither of the following conditions hold a the fluent is initially true and no terminating event has occurred since or b some initiating event has occurred with no terminating event occurring since then.
an lts can be synthesised from a safety assertion p written in fltl using the algorithm in .
the resulting lts denoted l p is an lts that captures all infinite traces over the alphabet actthat satisfy p. also an fltl property can be verified against an lts l p using the model checking algorithm described in and implemented in the ltsa tool .
this procedure involves constructing an automaton b uchi that recognises all infinite traces over the alphabet act violating and checking that the synchronous product l p bardblb uchi is empty.
any trace leading to the error state in this product is a counterexample to the property while any trace not leading to the error state is a witness to the property .
c. inductive logic programming inductive logic programming ilp is a machine learning technique for generating a generalisation hthat together with a given knowledge base b covers a given set of positive examples e and excludes a set of negative examples e where b h e ande are expressed as logic programs .
a mode declaration md is a form of language bias that defines the space of plausible generalisations solutions for a given ilp task by specifying the syntactic form of the generalisations that can be learned.
we uses md to denote the set of all plausible generalisations rules that can be constructed from md.
for the rest of this paper we define an inductive task to be a tuple an bracketle tb e e md an bracketri htand an inductive solution as follows.
definition .
let an bracketle tb e e md an bracketri htbe an inductive task.
the logic program h whereh s md is an inductive solution iff e .b h e and e .b h ne ationslash e where is entailment under stable model semantics .
we consider here logic programs that use the following predicates from fluent f to assert that fis a fluent event e for an event e timepoint i for time point i trace s for traces holdsat f i s to express that the fluent fholds at time point iin traces happens e i s to express that eventehappens at time point iin traces and initiates e f resp.
terminates e f to capture fluents that are initiated resp.
terminated by event e. the knowledge base alsocomprises a set of frame axioms for determining fluents truth values and semantic constraints e.g.
events cannot happen concurrently denoted ax.
iii.
m otivating example in this section we give an overview of the approach and introduce our running example.
we use a simplified version of the train control system introduced in .
the example is propositional rather than first order for simplicity it comprises a train a signal and a driver.
a train may start or stop moving on the track.
the signal may be set to stop or go.
the view of the signal may be clear orobstructed .
the driver may respond to or ignore the stop signal.
we define the fluents for the train control system as follows.
trainstopped an bracketle tstop train start train false an bracketri ht stopsignal an bracketle tsettostop settogo false an bracketri ht signalvisible an bracketle tclear signal obstruct signal true an bracketri ht driverresponsive an bracketle tdriver responds driver ignores true an bracketri ht consider the goal stating that the train shall stop when the signal is set to stop goal achieve stopsignal circlecop rt trainstopped suppose the domain properties include the following necessary conditions for the train to stop circlecop rttrainstopped driverresponsive which states that if a train stops the train driver was responsive to the stop command and circlecop rttrainstopped signalvisible meaning that if a train stops the stop signal was visible.
consider a system that satisfies the domain properties and .
a simple goal violation scenario of such a system is one in which the signal is set to stop and then although the stop signal is visible initially the driver ignores the signal and the train does not stop.
similarly another scenario possible in the domain is when the signal is set to stop and the signal is visible initially the signal is then obstructed e.g.
because of foggy weather and consequently the train does not stop.
such scenarios represent situations where the goal satisfaction is at risk.
the problem is that the goal achieve is too ideal it presupposes that nothing in the environment will prevent the goal from being achieved.
the goal can only be achieved if it is assumed that the driver is always responsive and the stop signal is always visible among others these two assumptions are likely to be violated from time to time.
in both scenarios we can see that some exceptional circumstance has prevented the goal from being satisfied.
in the first case the driver not being responsive is an obstacle preventing the goal trainstoppedatblocksignalifstopsignal from being achieved this obstacle can be formally expressed as stopsignal circlecopyrt driverresponsive .
in the second case the signal being not visible stopsignal circlecopyrt signalvisible is another obstacle to the goal.
detecting obstacle conditions under which goals may be violated is essential for not missing requirements that would prescribe what the software should do in order to properly handle such unexpected situations.
in this simple example detecting obstacles is straightforward however for complex systems performing such a task manually is likely to be error prone and miss important obstacles.
the technique in this paper can automatically detect all obstacles to a goal for a set of known domain properties.
iv.
g enerating obstacles to goal satisfaction the approach proposed here considers a set of goals and background properties as input and iteratively computes obstacles to the goals.
each iteration can be subdivided into three main phases see figure elicit new dom bp dom selectsynthesise lts l bp bp bp o dom model check l bp c t model check l bp c t learntr tr e e dom oi oanti target c t goal c t bp bp bp figure .
overview of the proposed obstacle generation approach.
the first phase generates domain consistent counterexample and witness traces for a goal.
this is achieved by synthesising a behaviour model l bp from the background properties bpcurrently available and performing two model checks.
to obtain a counterexample trace tr to a goal taking the form c twhere is a temporal operator the model is checked against it.
to obtain a witness tr to the goal the model is checked against a perturbation of the property that asserts that the goal target is violated c t. the second phase is concerned with learning obstacles.
a learning system is given the background properties and the goal in addition to the counterexample and witness traces generated in the first phase.
critically it is the counterexample trace to the goal that is provided to the learning system as a positive example e i.e.
an example in which an obstacle is satisfied.
the witness trace to the goal is provided as a negative example e to the learning system i.e.
an example in which the obstacle is not satisfied.
the learning system generates a set of candidate obstacles oi that cover the positive example while excluding the negative one.
the third phase contrary to the others requires human intervention.
an engineer makes a selection ofrom the set of proposed obstacles based on those consideredlikely and severe.
the selected obstacles are negated and added to the background properties.
this is to allow for further identification of obstacles in the next iteration.
in this phase the engineer can also suggest further domain properties based on the learned obstacles and provided they are consistent with the existing background properties to which they are added to allow for identification of further obstacles or finer grained sub obstacles.
the process terminates when a domain complete set of obstacles is generated see definition .
in what follows we structure the presentation according to these phases.
a. generating goal counterexamples and witnesses consider the lts shown in figure which is synthesised from the background properties including and of section iii.
notice that some of the traces the lts exhibits satisfy the system goal achieve while others do not.
traces which satisfy the goal are examples in which no obstacles are present e.g.
the signal is set to stop and the train stops .
on the other hand traces which violate the goal are examples of obstacles that are present e.g.
the view of the stop signal is not clear .
to automatically find such examples we perform two model checks which are explained below.
starttrain settogo settostop clearsignal driverrespondsobstruct signaldriverignore stop trainclearsignaldriverresponds starttrain settogo signalstop obstruct signal driverignoreobstruct signaldriverignore starttrain settogo settostop clearsignaldriverrespondsclearsignaldriverignores starttrain settogo settostop obstruct signaldriverrespondsstart traindriverresponds stoptrain settogo settostop clearsignal figure .
the lts l bp for the train control system.
goal counterexamples for a given set of background properties bp the computation of a counterexample trace to a goalgis done in a straightforward manner by checking the ltsl bp againstg.
if the model checker finds that l bp contains a trace that violates g it is produced automatically.
for example model checking the lts in figure against the goal achieve using the ltsa model checker gives the following violation.
violation in trainstoppedatblocksignalifstopsignal set to stop stopsignal driver ignores stopsignal the left column represents a sequence of events in which the goal is violated.
the column on the right indicates the fluents that are true immediately after the occurrence of the event to their left.
this trace fragment exemplifies a case in which the train does not stop after the signal is set to stop.
this behaviour thus satisfies an obstacle which prevents the goal from being achieved.if checking the lts l bp againstgdoes not yield a counterexample this means that l bp satisfiesgand hence there are no more obstacles to be generated the three phase cycle then comes to an end.
goals witnesses conceptually a witness trace to a goal is obtained by checking the lts l bp against a property stating that the goal is violated.
however this might lead to traces that vacuously satisfy the goal.
if for example the goal is of the form c tthe property asserting that the goal is violated is c t that is c t .
checking l bp against the latter property could generate a counterexample that never satisfies c. such counterexample is a witness that vacuously satisfies the goal c tas the antecedent is never true.
we are interested in obtaining witnesses where both cand thold.
hence we need to checkl bp against a variant property c t. we refer to this property as the anti target for the goal c t. table i shows the corresponding anti target assertions for goals expressed in achieve andmaintain modes.
antitarget assertions for goals expressed in avoid modes can be constructed by simply removing the negation preceding the target condition in the anti target assertion of the corresponding maintain assertions in table i. if checking l bp againstg s anti target yields no counterexamples this means that l bp satisfies the anti target i.e.
there are no traces that satisfy the goal non vacuously.
this is an indication of problem in the formulation of the goal itself which needs to be weakened or in the background properties which need to be revised.
this situation is beyond the scope of this paper.
table i goals and their corresponding anti target patterns mode goal pattern anti target pattern c circlecop rttc circlecop rt t achieve c xtc x t c t c t c t c t c t c t maintain c gwtc tu g c t c t c xtc x t returning to the example of the previous section to generate a witness to the goal achieve the lts in figure is checked against the anti target assertion stopsignal circlecop rt trainstopped this results in the violation trace below where the signal is set to stop and the train stops immediately afterwards.
violation in nottrainstoppedatblocksignalifstopsignal signal stop stopsignal stop train stopsignal trainstopped b. learning obstacles from traces the next step involves the generation of obstacles from the produced counterexample and witness traces to the goal.
to perform this computation ilp is deployed.
the applicationof ilp to the obstacle generation task comprises three main steps definition of an ilp task through appropriate encoding of background properties goals counterexample and witness computation of an inductive solution and decoding of the inductive solutions into obstacles.
these steps are done automatically and are hidden from users who are only shown the final set of possible obstacles.
ilp task for learning obstacles as explained in section ii c ilp computes generalised rules from given examples and knowledge base expressed as logic programs.
hence to learn obstacles the background properties goals and counterexample and witness traces have to be mapped into a logic program as in any learning task a suitable language bias has also to be chosen.
the encoding uses in addition to the predicates described in section ii a collection loof anti target predicates specific to the anti target patterns in table ii and a collection ltof target predicates specific to the target patterns in table iii.
the correspondence illustrated in these tables considers the target condition to be a conjunction or disjunction of fluents and that the predicates are introduced for each fluent in t. examples of anti target predicates include obstructed next f i s which means that a fluentfis prevented from being true at the next timepoint from iin traces and obstructed always by f i x s which states that a fluent fis obstructed from being true for xtime points after time point iin traces.
examples of target predicates include holdsat eventually f i s meaning that fluentfis true sometime in the future after time point i. table ii ilp encoding of anti target anti target pattern corresponding obstacle predicates circlecopyrt t obstructed next t i s .
x t obstructed always by t i x s .
t obstructed always t i s .
t obstructed t i s .
t obstructed eventually t i s .
tu gobstructed always until t i1 i2 s .
obstructed eventually g i1 s .
t obstructed before t i s .
x t obstructed eventually by t i x s .
table iii ilp encoding of target target pattern corresponding goal predicates circlecopyrtt holdsat next t i s .
xt holdsat eventually by t i x s .
t holdsat eventually t i s .
t holdsat t i s .
t holdsat always t i s .
gwtholdsat always until g i1 i2 s holdsat always g i1 s .
t holdsat before t i s .
xt holdsat always by t i x s .
the knowledge base bof the ilp task includes an encoding of the background properties fluent definitions and domain properties the goals and a set of frame axioms axthat specify conditions under which an initiating or terminating changes the truth value of fluents.fluent definitions are expressed as initiates andterminates rules.
for example the fluent definition for trainstopped is expressed as initiates stop train trainstopped and terminates start train trainstopped .
domain properties are encoded as integrity constraints which force the learning tool to compute only obstacles that are consistent with the domain.
intuitively every domain property is of the form t n wherenis either a conjunction of literals or a weak until formula defining a necessary condition for t. in the former case a domain property is translated into a set of rules of the form false holdsat t i s ... lit n j i s one for each conjunct literal njinn where litis anholdsat literal if njis negated in n and anot holdsat literal otherwise.
for example the domain property circlecopyrttrainstopped driverresponsive in is represented as false holdsat next trainstopped i s not holdsat driverresponsive i s .
this means that in any stable model of bwhere holdsat next trainstopped i s is true holdsat driverresponsive i s must also be true.
domain properties of the form t nwpare encoded into rules of the form false holdsat t i1 s holdsat eventually p i1 i2 s not holdsat always until n i1 i2 s .
false holdsat t i1 s not holdsat eventually p i1 i2 s not holdsat always n i1 s .
goals on the other hand are encoded as rules of the formholdat target i s current i s not o .
in this rule o is a predicate in lo.
the general interpretation of such a rule is that the goal s target condition holds if its current condition holds and no obstacles exist.
for instance theachieve goal expressed as stopsignal circlecopyrt trainstopped is encoded as holdsat next trainstopped i s holdsat stopsignal i s not obstructed next trainstopped i s .
this rule informally states that if a signal is set to stop and no obstacles to stopping the train at the next time point are satisfied then the train stops.
this encoding as shown later plays a key role in the computation of obstacles.
the encoding is proven to be sound in terms of preservation of the fltl model consequences in the encoded logic program.
theorem .
let bp be a set of background properties expressed in fltl let l bp be the lts synthesised from bp and tr a trace in l bp .
let be a property expressed in fltl.
let be the encoding of bp and tr into a corresponding knowledge base bunder stable model semantics.
then the following condition holds tr if and only if b inferring obstacle positive and negative examples need to be provided to the ilp task.
in the problem at hand the counterexample trace tr to a goal is taken as a positive example for learning obstacles to the goal while the witness trace tr to the goal is taken as a negative example.each event occurrence in the counterexample resp.
witness trace is represented as a happens fact and added to the positive resp.
negative examples every fluent valuation in the counterexample resp.
witness trace is represented as a holdsat literal and also added to the positive resp.
negative examples.
for instance the goal counterexample trace for our toy train system shown in section iv a can be systematically expressed as the following positive examples happens set to stop c .
holdsat stopsignal c .
happens driver ignores c .
holdsat stopsignal c .
and the witness trace as the following negative examples.
happens set to stop w .
holdsat stopsignal w .
happens stop train w .
holdsat stopsignal w .
holdsat trainstopped w .
onceb e ande are generated with b bp g ax e tr ande tr they are given to a non monotonic ilp system to compute a generalisation h that covers e and excludes e .
the encoding of the goal and traces plays a crucial role in the computation of the obstacles.
since the consequent of g is true in the stable model of bwhen no obstacles are present whilst the positive examples indicate the contrary the ilp task is concerned with finding rules that would prevent the derivation of the goal s target.
to define the solution space we define the mode declaration to include rules with lopredicates in the head and holdsat andltpredicates in the body.
in our running example the tool generates the following rule stating that an obstacle to stopping the train at the next timepoint is the driver not being responsive.
obstructed next trainstopped i s holdsat stopsignal i s not holdsat next driverresponsive i s .
the computed explanation is then mapped back into fltl and presented to the engineer stopsignal circlecop rt driverresponsive in many situations the learning tool may find several solutions as obstacles to a goal.
when this is the case these alternatives are presented to the engineer to select the obstacles considered likely and severe.
theorem below states that any computed solution is an obstacle to a goal.
theorem .
let bp and gbe a set of background properties and a goal respectively expressed in fltl.
let tr and tr be a counterexample and witness traces to g inl bp .
let ax be a set of frame axioms expressed in the logic programming formalism.
given the inductive task an bracketle t bp g ax tr tr md an bracketri ht a set of rules h s md is an inductive solution under stable model semantics iff the fltl expression ogiven by h o is an obstacle to gsatisfied by tr and not by tr .
c. completing the obstacles once the analyst selects those obstacles their negation is added to the background properties.
as the lts synthesisedfrom the extended background properties may contain other violation traces to the considered goal the process of model checking and learning is repeated again.
to generate a domain complete set of obstacles in every new iteration i we look for obstacles different from those already generated and selected.
the negation of each one is added to the background properties bpand the verification process is repeated again.
if a counterexample trace is found then the steps in sections iv a and iv b are repeated until no further counterexamples to the goal are found.
in some cases the computed obstacles oi may highlight some domain properties that are missing from the current background properties typically properties of the formt n other necessary condition for the goal s target or s o sufficient condition for the obstacle under consideration .
when this is the case the engineer may add such properties to bpbefore the start of the new iteration.
returning to our running example the analysis is performed on the lts synthesised from the background properties including the domain properties and fluent definitions and the negation of the obstacle i.e.
stopsignal circlecopyrt driverresponsive .
the counterexample trace settostop obstruct signal is generated.
this trace along with the witness settostop stop train are given to the learner tool which in turn computes the obstacle stopsignal circlecop rt visiblesignal once this is added to the current set of obstacles a new cycle results in no further violations to the goal.
hence the set comprising the obstacles and is the domaincomplete set of obstacles for the goal achieve .
if sufficient conditions for the learned obstacles are added to the background properties as additional domain properties the process will go on to generate finer grained sub obstacles.
theorem states that for a given set of background properties bpand goal gthat is consistent with bp the proposed approach will converge to a domain complete set of obstacles to goal g. theorem .
let bp be a set of background properties andga goal expressed in fltl consistent with bp.
let tr be the set of shortest finite counterexample traces in the composition l bp bardblbuchi g .
let tr be a set of finite witness traces to the goal gin the composition l bp bardbll g .
let ax be a set of frame axioms expressed in the logic programming formalism.
given the inductive task an bracketle t bp g ax tr tr md an bracketri ht there exists a set hi of inductive solutions under stable model semantics such that bp o1 .... on g wherehi oi for1 i n .
v. v alidation we show here an application of the proposed approach to the london ambulance service las .
we reporton our findings and illustrate the various steps in our approach with respect to two goal patterns bounded andunbounded achieve .
the application to goals under maintain andavoid modes was similar.
for the purpose of validating our approach we considered a set of obstacles which were formally derived manually in .
the las specification as presented in is formalised in a synchronous form of first order linear temporal logic ltl where the goals are expected to hold at fixed time points but maybe violated in between and several events may occur between two consecutive timepoints.
ltss on the other hand assume an asynchronous interpretation of ltl expressions.
therefore to preserve these semantics when applying model checking the available synchronous specification was systematically translated into asynchronous fltl using the algorithm described in .
this translation makes use of a special event tick which is introduced in the alphabet of the lts to mark the time points at which goals are expected to hold.
similarly the language of our logic programs is extended with this notion by defining auxiliary predicates such as holdsat tick and holdsat eventually tick.
fluent definitions were also extracted from the specification using the technique in .
a. experimental results our experiments generated all the obstacles which were manually obtained described in as well as other obstacles that were not found there.
the outcomes also confirmed that our approach provides support for eliciting new domain properties.
for instance when checking the background properties against one of the las goals reported later in this section the model checker produced the counterexample tick a1.assign a1.inc1.allocate inc1.resolve ... where an incident is stated to be resolved before the ambulance has been mobilised and has intervened in the incident.
such traces help engineers in detecting goals or domain properties that are too weak e.g.
the domain property inc incident inc.resolved a ambulance intervention a inc .
furthermore our approach produced finer sub obstacles depending on the granularity of the provided domain properties.
this case is exemplified in section v c where the learning tool produced the obstacle resourcenotusedonpatient which is a refinement of the obstacle patientnottreatedatincidentlocation .
we tested our approach using two ilp systems xhail and tal .
these mainly differ in directions in which they explore the generalisation search space and in the degree of control they provide to users in defining further syntactic constraints over acceptable generalisations.
in our experience we observed that the approach may compute obstacles that appear too general e.g.
an obstacle totrainstopped being that the driver is not responsive even when the signal is not set to stop.
however further experiments suggest that producing several witnesses to agoal including traces in which the target of goals is true with the condition being false results in weaker obstacles.
in what follows we illustrate these findings where applicable.
b. obstacles to bounded achieve goals consider the goal achieve stating that a mobilised ambulance shall intervene at the incident within minutes.
goal achieve available a.mobilised 11intervention a inc the background properties capture the following necessary conditions for the target condition of the above goal to hold.
a ambulance inc incident a.available a.mobilised intervention a inc circlecop rt a.mobilised w a.mobilised intervention a inc a ambulance inc incident a.available a.mobilised intervention a inc circlecop rt a.inservice w a.inservice intervention a inc these properties state that if an available ambulance is mobilised and eventually intervenes in an incident then it must remain mobilised and in service respectively until it intervenes.
the definitions of the fluents appearing in the goal and background properties are given below.
resolved angbracketleft .resolve .happens false angbracketright intervention angbracketleft .intervene .stop intervention false angbracketright allocated .
angbracketleft .allocate .deallocate false angbracketright mobilised angbracketleft .mobilise .demobilise false angbracketright available angbracketleft .assign .free true angbracketright inservice angbracketleft .oncall .offcall true angbracketright model checking an lts synthesised from those background properties against the goal achieve results in the following counterexample.
tick available.a1 a1.inc1.allocate available.a1 a1.assign available.a1 tick available.a1 a1.mobilise mobilised.a1 tick mobilised.a1 a1.offcall a1.demobilise tick a1.inc1.deallocate ... tick cycle in terminal set tick tick the events appearing in the terminal set are the only ones that can occur thereafter.
in the above violation trace the goal antecedent is satisfied by the third tick after which the ambulance does not intervene i.e.
the goal s target is not satisfied.
a witness is generated by checking the synthesised lts against the anti target assertion a.available a.mobilised intervention a inc .
in this case the model checker produces the following witness.
tick available.a1 a1.inc1.allocate available.a1 a1.assigntick a1.mobilise mobilised.a1 tick mobilised.a1 ... a1.inc1.intervene mobilised.a1 intervention.a1.inc1 tick mobilised.a1 intervention.a1.inc1 cycle in terminal set tick tick the ambulance a1intervenes by the fourth tick.
please note that the goal achieve the background properties including assertions and and the counterexample and witness traces are automatically encoded as a logic program.
for instance the goal achieve is encoded as the rule holdsat eventually by tick intervention a inc i2 s holdsat tick available a i1 s next tick at i1 i2 s holdsat tick mobilised a i2 s not obstructed always by tick intervention a inc i2 s .
the learning task aims to generate conditions explaining why holdsat eventually by tick intervention a1 inc1 c does not hold in the positive example but is true in the negative one.
the learning outcome is guided by the mode declaration provided to the learning system.
in this example the mode declaration is restricted to learn rules with the predicate obstructed always by tick in the head.
the ilp tool produces a number of possible obstacles for the goal achieve which include obstacle mobilisedambulancestopsservice a ambulance inc incident a.available a.mobilised a.inservice obstacle mobilisedambulancedeallocated a ambulance inc incident a.available a.mobilised allocated a inc obstacle ambulancemobilisationretracted a ambulance inc incident a.available a.mobilised circlecop rt a.mobilised a comparison of the above outcome with the obstacles generated manually in revealed that our method is capable of computing obstacles produced in by instantiation of the non persistence pattern e.g.
the first and last obstacles above cover the obstacles mobilizedambulancestopsservicebeforeintervention and ambulancemobilizationretracted respectively.
it also showed that we were able to generate obstacles not obtained through pattern instantiations but related to real obstacles reported in the inquiry report where ambulances did not intervene in incidents because of incorrect allocation of ambulances.
c. obstacles to unbounded achieve goals we now consider the goal achieve specified as follows.
goal achieve a ambulance inc incident intervention a inc inc.resolved among the background properties bp the following provide necessary conditions for the target inc.resolved and for treating a patient at an incident location.
p patient inc incident inc.resolved injured p inc treatedatlocation p inc p patient inc incident inc.resolved injured p inc p.admittedtohospital p patients inc incident.treatedatlocation p inc r resource criticallyneeds p r usedon r p bpalso includes the fluent definitions admittedtohospital angbracketleft .admit .discharge false angbracketright injured angbracketleft .isinjured .isrecovered false angbracketright treatedatlocation angbracketleft .istreated .finishtreatment false angbracketright criticallyneeds angbracketleft .needs .use false angbracketright usedon angbracketleft .use .not use false angbracketright model checking l bp against the goal results in the following counterexample trace.
tick p1.inc1.isinjured a1.inc1.allocate a1.assign tick a1.mobilise tick a1.inc1.intervene intervention.a1.inc1 tick intervention.a1.inc1 a1.inc1.stop intervention a1.inc1.deallocate a1.free tick cycle in terminal set tick tick in this violation trace an ambulance intervenes but the incident is never resolved.the background properties are then verified against the anti target assertion intervention a inc inc.resolved which yields the following witness trace.
tick p1.inc1.isinjured p1.r1.needs a1.inc1.allocate assign.a1 tick a1.mobilise tick a1.inc1.intervene intervention.a1.inc1 tick intervention.a1.inc1 r1.p1.use p1.inc1.istreated tick intervention.a1.inc1 admit.p1 inc1.resolve resolved.inc1 tick resolved.inc1 cycle in terminal set tick resolved.inc1 tick resolved.inc1 this witness illustrates an incident resolved eventually after an ambulance s intervention.
the background properties including domain properties and the goal achieve and the counterexample and witness traces are automatically encoded as a logic program.
for example the goal is represented by the following rule.holdsat eventually tick resolved inc i s holdsat tick intervention a inc i s not obstructed always tick resolved inc i s .
the predicate holdsat eventually tick f i s means that fluent fis true at some tick in the future after timepointiin tracesunless an obstacle that always prevents it from being true holds.
the ilp tool suggests the following possible obstacles.
obstacle incidentnotresolvedbyintervention a ambulance inc incident intervention a inc resolved inc obstacle patientnotadmittedtohospital a ambulance inc incident intervention a inc p patient injured p inc p.admittedtohospital obstacle patientnottreatedatincidentlocation a ambulance inc incident intervention a inc p patient injured p inc treatedatlocation p inc obstacle criticalcarenotgiventopatient a ambulance inc incident intervention a inc p patient r resource injured p inc criticallyneeds p r obstacle resourcenotusedonpatient a ambulance inc incident intervention a inc p patient r resource injured p inc usedon r p obstacle ambulancenotavailableafterintervention a ambulance inc incident intervention a inc a.available by comparing the output of the learning system with those identified in we find that the first obstacle corresponds to the high level obstacle incidentnotresolvedbyintervention obtained through manual regression in .
the obstacles and are sub obstacles for incidentnotresolvedbyintervention obtained from the domain properties.
the tool also produced obstacles at a finer level such as resourcenotusedonpatient .
note that this obstacle suggests that resources may be used on patients who do not need it.
this may trigger the addition of a missing domain property that states that a necessary condition for using a resource on a patient is that the patient critically needs it.
vi.
d iscussion and related work our applications to medium sized case studies indicate that the techniques used are scalable.
in general the scalability of the approach is determined by the scalability of the model checker and learning tool used.
the scalability of model checker is affected by the number of goals and composed ltss one for each domain property per iteration.
since the approach is incremental it takes one goal at a time and finds all its obstacles.
hence we do not discuss an upper bound on the number of goals handled.
the number of domain properties provided per iteration is dependent on the necessary conditions for the goal s target condition to besatisfied and is assumed to be small.
as for the ilp system it uses an answer set programming solver which grounds the logic programs before searching for solutions.
it scales for finite domains and is comparable to sat solvers.
the complexity of translating each assertion to an automata or a logic program is exponential in the size of the fltl formula.
as these correspond to individual goals or domain properties for goals target conditions they remain small enough to be handled by the tool.
obstacles were originally introduced as informal goal obstruction scenarios in used in for requirements elaboration.
heuristics for informally identifying possible exceptions and errors in such scenarios are proposed in .
obstacles as goal obstruction preconditions were introduced in where various techniques for obstacle analysis are outlined.
lutz and colleagues discuss a convincing application of obstacle analysis to identify anomaly handling requirements for a nasa unmanned aerial vehicle .
the ddp approach to risk analysis also integrates a lightweight form of obstacle analysis .
the integration of hazard analysis in the early stages of the re process is advocated in .
iterative approaches for defect driven modification of requirements specifications in the context of system faults and human errors are proposed in .
fault trees and threat trees are discussed as special types of risk trees in and respectively.
the approach presented here is much related to that described in where techniques are proposed for identifying and resolving obstacles to goals.
in obstacles are generated from goal negations and domain properties by applying a formal regression calculus or by using obstruction patterns.
though their techniques are sound the processes are manual the pattern based technique is restricted to patterns available in the catalogues.
our approach complements the obstacle identification process by a providing automated support for generating obstacles from given goals and domain properties and b computing a wider class of obstacles that cannot be identified through pattern based techniques.
however our approach does not address the various obstacle resolution options studied there.
our approach builds upon the work presented in where model checking and ilp are used for the elaboration of specifications operationalising goals and the derivation of non zeno behaviour models respectively.
however the technique here involves several challenges that were not addressed in .
the witnesses are here generated without human intervention.
the role of counterexamples and witnesses is inverted as counterexamples are considered to be positive examples for learning obstacles while witnesses are considered as negative examples.
the goal language is much more expressive as it covers any achieve ormaintain avoid goal which were not covered in .
the approach presented here is also somewhat related to the technique described in .
the authors in use areasoning technique called abduction by refutation to detect a complete set of counterexamples for invariants expected to hold for a given system description.
the output of the approach is a set of transition relations that show where an invariant does not hold.
such transitions however are not guaranteed to be reachable from the initial state of the description and hence it is assumed that reachability checks are performed separately.
also the invariant structure is limited to the form c t .
our approach has several advantages a it guarantees that any detected obstacle is indeed reachable from the initial state b the obstacles are produced in the goal language and c this language is richer and more expressive than the one applicable in .
our mechanism for encoding goals to learn obstacles is related to the formalisation of abnormality relations in logic programming .
in the latter abnormality relations are used to revise an agent s default assumptions.
similarly our use of obstruction predicates in the body of goal rules provides the means for revising the engineer s default assumption about when the goal s target holds in the domain.
vii.
c onclusion and future work the framework described in this paper is a formal toolsupported approach for incrementally generating obstacles that may prevent goals from being achieved within a given domain.
it uses model checking for generating traces that violate and satisfy the goals from a given system description and an inductive learning tool for computing obstacles from these traces.
this iterative process ends once a domaincomplete set of obstacles is generated.
we applied the proposed approach to a real safety critical system the london ambulance service where a domain complete set of obstacles was computed.
our application has shown an improvement over existing methods through automation and detection of a wider class of obstacles.
we envision a number of extensions to the work presented here.
first we will investigate enriching the framework with incremental techniques for resolving the detected obstacles.
for this purpose we plan to revisit the learning phase of the approach and apply ilp algorithms for theory revision.
we further plan to extend the framework to handle goals and obstacles which are associated with probabilities.
to do so the use of tools such as probabilistic model checking and probabilistic ilp will be explored.
as part of our future work we intend to adapt our approach to detect conflicts among goals.
one way we envision this being possible is by learning boundary conditions for goal conflict from traces generated through deadlock checks.
acknowledgment we are grateful to bernard lambeau and the reviewers for their careful inspection and feedback on an earlier version of the paper.
this work is financially supported by erc project pbm fimbse no.
.