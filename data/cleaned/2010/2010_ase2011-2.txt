generalizing evolutionary coupling with stochastic dependencies sunny wong siemens healthcare malvern pa usa sunny.wong siemens.comyuanfang cai dept.
of computer science drexel university philadelphia pa usa yfcai cs.drexel.edu abstract researchers have leveraged evolutionary coupling derived from revision history to conduct various software a nalyses such as software change impact analysis ia .
the probl em is that the validity of historical data depends on the recenc y of changes and varies withdifferentevolution paths thus in fluencing the accuracy of analysis results.
in this paper we forma lize evolutionary coupling as a stochastic process using a marko v chainmodel.byvaryingtheparameters of thismodel we defin ea family of stochastic dependencies that accounts for different types of evolution paths.
each member of this family weighs histor ical data differently according to their recency and frequency.
to assess the utility of this model we conduct ia on releases of five open source systems using stochastic dependency typ es and compare with the results of several existing approaches .
the results show that our stochastic based ia technique can pro vide more accurate results than these existing techniques.
index terms impact analysis stochastic dependency evolutionary coupling markov chain i. introduction researchers have leveraged revision history to identify evolutionary coupling between components by checking how components historically change together .
the effe ctiveness of conducting various software analyses based on evolutionary coupling has been demonstrated.
for example cataldo et al.
s empirical studies suggest that evoluti onary dependencies provide more accurate estimates of coordination requirements than structural dependencies.
soft ware change impact analysis1 ia exemplifies another analysis technique where evolutionary dependencies often outperfo rm structural dependencies.
different from traditional chan ge impact analysis techniques that are often performed based on static dependency structure evolutionary coupling b ased ia captures semantically coupled components that may not structurally depend on each other.
although historical data has been shown to be a useful resource for various analyses the validity of historical d ata depends on the recency of changes and varies with different evolution paths.
for example the amount of history needed to accurately estimate change impact would be different for a 1change impact analysis also called change propagation ana lysis and change scope analysis is the method of determining what sof tware elements components files etc.
are likely to change called the ch ange scope or the impact scope when or after a certain set of elements call ed the starting impact set changes .relatively new system that is frequently refactored than fo r a long established system with a stable architecture.
to improve the accuracy of history based analysis techniques we present a formalized generalization of evolutio nary dependencies based on probability theory which we call stochastic dependencies .
this formalization defines a family of dependency types.
to account for different evolution pat hs each member of the family weighs historical data differentl y according to their recency and frequency.
our stochastic dependencyfamily can be used to augment prevailing history based analysis techniquesby selecting a member of the famil y that fits the project in consideration.
our stochastic dependency framework is based on the markov chain model a probabilistic model often used in artificial intelligence for determining the expected resul t of a randomvariable event.ourassumptionisthat each transac tion i.e.
atomic commit in revision history can be modeled as a random variable.
to address the temporal issue of changing dependencies that invalidate historical data our approac h first limits the length of historical data used for analysis.
this limited sequence of transactions create a sliding window that resembles a markov chain discrete k th order markov process in which each state of the chain is a transaction fro m revision history.
fromthemarkovchain wecancomputetheprobabilitythat two components are coupled i.e.
they will both be changed in the next transaction .
this probability value can be used to reason about whether a componentwill be in the impact scope of a change.
to account for the importance of recent history over distant history our model for computing this dependen cy probability uses a smoothing function to control how much each transaction contributes to the predicted probability .
the two parameters to our framework i.e.
the length of history to useandthetypeofsmoothingfunction allowforthedefiniti on of a family of stochastic dependency types.
to evaluate our approach we conduct change impact analysis on releases of five open source systems by varying the values of the two stochastic dependency parameters.
our results show that the stochastic based change impact analysis can provide more accurate results than two traditional structure based ia approaches and an existing history bas ed ia approach for all five systems.
.
c ieee ase lawrence ks usa293the rest of this paper is organized as follows section ii presentsrelated work.
section iii uses an example to overvi ew the stochastic dependency computation for change impact analysis.
section iv formally defines the family of stochast ic dependencies.
section v presents our evaluation method and empirical results.
section vi discusses threats to validit y and future work.
section vii concludes.
ii.
relatedwork in this section we review related work and differentiate ou r stochastic based technique from existing approaches.
a. impact analysis numerous ia techniques have been proposed.
below we discuss several representative categories of ia approache s. structure based impact analysis various ia techniques have been developed using software dependency structures.
for example briand et al.
and elish and rine proposed ia techniques based on the metrics of chidamber and kemerer .robillard andrajlich presentedalgori thms based on dependency graph structures.
to capture impact tha t cannot be easily identified throughsyntactic analysis som e ia approaches e.g.apiwattanaponget al.
use dynamic i .e.
instance based rather than class based analysis to measu re coupling.
history based impact analysis ying et al.
and zimmermann et al.
leverage revision histories to perfor m ia based on association rules that identify evolutionary o r logical coupling between software elements.
an associ ation rule of the form a b states that if ais changed then b will likely also be changed.
these rules are prioritized bas ed on the heuristics of supportandconfidence .supportis defined as the number of transactions that aandboccur together in revision history.
confidence is defined as supportdivided by the number of times that aoccurs with or without b .
with minimum support and confidence thresholds association rul es are selected to predict the impact scope of a change starting from a. evolutionary dependency approaches often consider the transactions in the overall revision history to be a multise t and disregard the temporal sequence i.e.
ordering of the tra nsactions.
two approaches that include temporal information in ia include the work of bouktif et al.
and ceccarelli et al.
.
different from our approach of using markov chains their purpose is to infer cause effect relationships from t he temporal data rather than to filter out obsolete history dat a. the evolution radar is another approach that considers the temporal sequence of transactions.
it allows for the tracking of evolutionary dependencies over time by dividing revision history into time intervals.
however its g oal is different from our approach in that it is meant for the interactive visualization of dependency changes to aid the detection architecture decay.
while these existing history based techniques are effective at identifying semantic dependencies between softwar e elements refactorings that remove these dependencies maycause the approaches to overestimate the impact scope.
sinc e the support heuristic never decreases once support passes the minimum threshold a dependency between two elements continues to exist.
although the confidence heuristic can be usedinconjunctionwithsupport asthenumberoftransacti ons becomes large confidence only minimally changes with each transaction.
our stochastic dependency framework address es this issue by limiting the length of historical information analyzed and uses a smoothing function to emphasize more recent history over distant history.
cataldo explored the question of how many months of revisionhistoryareenoughtoaccuratelycomputeevolutio nary dependencies and coordination requirements.
he construct ed task dependency matrices on monthly increments to find when a matrix no longer significantly differs from a previous matrix.
although he found a fix point months when the dependencies stabilized the result is hard to generalize t o other software systems.
recent architectural refactoring s can significantly alter the structure of dependencies invalid ating previous revision history.
probabilistic impact analysis recently several impact analysis techniques have been proposed that are based on probability theory.
for example tsantalis et al.
defin e probabilities of impact based on structural relations betw een software elements in object oriented designs.
abdi et al.
use a bayesian network a probabilistic model with structu ral coupling metrics to construct the inference model.
mirarab et al.
also use a bayesian network and combine structural coupling with historical data in constructing the network.
while our approach also uses a probabilistic model markov chain stochastic dependencies use the temporal sequence of transactions in revision history to account for changes to t he dependency structure over time.
b. markov processes markov processes of which markov chains are a specific type are probabilistic models that are widely used in artifi cial intelligence e.g.
reinforcement learning and vario us other computing fields e.g.
web search engine algorithm .
markov processes have also been applied to software engineering e.g.
generate test inputs classify softwa re behavior predict component reliability .
to the best ofourknowledge markovprocesseshavenotyetbeenapplied to computing evolutionary coupling.
iii.
framework overview in this section we present a high level overview of our stochastic dependency framework using concrete but hypo thetical examples to demonstrate how to compute stochasti c dependencies and how to conduct ia using them.
the next section provides more rigorous formal definitions and expl anationsfortheconceptsdiscussedhere.foralltheexample sin this section we consider that we have the following sequenc e of transactions in our revision history a b a c d a b a a b c b d a a d c a c a where a is the most recent transaction.294intuitively a stochastic dependency is theprobability that if the next transaction includes it will include .
to compute this probability we look at the previous transacti ons thatinclude .eachoneofthesetransactionsthatalsoincludes gives us evidence that a dependency exists i.e.
depends on .
to account for different evolution paths and changing design structures we use two parameters in computing the stochastic dependency value a limit on history length and a smoothingfunction.thehistorylengthparameter kdefinesthe number of transactions to look at thereby ignoring transa ctions that occurred in the distant past.
the smoothing funct ion allows us to give more weight to transactions that occurred recently over those from the distant past.
we first consider an example of limiting to the last five transactions k and using a linear smoothing function i.e.
theusefulnessofhistoricaldatadecayslinearlywi thtime as shown in table i .
to compute the stochastic dependencies onc we first find the last five transactions that involve c a c a b c c a c .
since chas only been involved in four transactions so far we only use the four available transactions.
then we compute the stochastic dependencies as shown below a c c a b c a c pr a 1 1 2 3 4 .
b 1 0 2 3 4 .
d 1 0 2 3 4 from these stochastic dependency values we can perform ia and estimate the impact of changing c. there are various methods to use these values for ia.
the simplest way is to use a threshold base rounding scheme.
if we use .
as the minimumthreshold thenwe wouldpredictthatonly aislikely to be in the impact scope of c. as another example we consider analyzing the impact of changing a. the last five transactions that involve aare a b c a a d a c a .
again we use the same linear smoothing function a a c a d a a b c pr b 1 0 2 0 3 0 4 5 .
c 1 0 2 1 3 0 4 5 .
d 1 0 2 0 3 1 4 5 .
using the same minimum threshold of .
we would expect that changing awill not impact any other elements.
iv.
formalization in this section we first present the definitions and mathematicalnotationsto formallydefinethe stochasticdependency .
after that we describe a method for computing the dependency value.a.
definitions and background lete ei n i 1be the set of software elements in the system where nis the total number of elements.2let t ti m i 1be the sequence of revision history transactions each involving a subset of software elements i.e.
ti t ti e where mis the length of t. we can view tas a stochastic process where each tiis a discrete random variable with domain 2e.
for any element e e lett e braceleftbig t e i t e t e i bracerightbig be the subsequence oftinvolving e. without loss of generality we use separate indexing sequences for tandt e in other words t e 1is not necessarily the first element of t t e 2is not necessary the second element of t etc.
then let m e be the length of t e .
giventwo elements a b e letc a b braceleftbig x a b i bracerightbigm a i 1be astochasticprocessthatmodelswhether bisinthetransactions that involve a x a b i braceleftbigg 1ifb t a i 0otherwise we define the stochastic dependency b a at time as pr parenleftbig x a b parenrightbig .
the method for computing this probability varies among the different types of stochastic dependencie s. unlike some existing dependency definitions in which a dependencyeitherexistsordoesnot wedefinethatanelemen t is stochastically dependent upon another with a continuous probability.
given a starting impact set a we compute its stochastic dependents from all other elements b e a to determine if bwill be in the impact scope of a. in this paper we use the terms change scope and impact scope interchangeably.
with the probability values of stochastic dependencies we can reason about which elements are expected to be in an impact scope.
while we can simply sort the software elements by decreasing probability values and present the list to a maintainer this continuous range also allows for varioustechniquesto reducethe numberofelementspresent ed to a maintainer.
for example we can define a minimum probability threshold and consider all elements above that threshold to be in the impact scope.
alternatively we can use randomized rounding to select the likely impacted elements.
for simplicity we use a minimumthresholdstrate gy for our evaluation in section v. next we formally define our method of computing stochastic dependencies.
b. computing stochastic dependencies given a sequence of 1transactions in revision history involving an element a we have defined the probability that another element bwill be involved in the next transaction involving aas thestochastic dependency from btoaat time .
for each of the 1transactions involving a letxibe the value of x a b i i.e.
xiindicates whether bandaoccurred together in the i th transaction involving a .
then we 2although software elements may be added and deleted over tim e we use eto refer to the set of elements in the software at the time of in terest.295definetheprobabilitythat bisstochasticallydependon awhen the th transaction involving aoccurs as follows pr parenleftbig x a b parenrightbig pr parenleftbig x a b x a b x1 x a b x parenrightbig as a first step in accounting for different evolution paths of software we consideronlythelatest ktransactionsinvolving a foranalysis.weemphasizethatthesearethelast ktransactions that software element ais involved in but not necessarily the latest ktransactions in the revision history.
selecting an appropriate value for kcan affect the accuracy of impact analysis.
if kis too large then dependencies may have been removedduringevolution.on the other hand if kis two small then semantic dependencies between components may not be detected.
we investigate the effects of various kvalues in our evaluation reported in section v. only considering the latest ktransactions creates a sliding window that resembles a discrete k th order markov process markov chain which leads to our method of computing the stochastic dependency probability.
a markov chain is a stochastic process with a property that the next state depen ds onlyonthe currentstate and a finite numberof previousstate s but not the entire history of states.
a k th order markov chain depends on the current state and the k 1previous states or formally pr yi yi .
.
.
y pr yi yi .
.
.
y i k .
a prevailing model for high order markov chains defines the probability for a next state to be based on a linear combination from the previous states.
based on this prevailing model we derive a method to compute stochastic dependencies that is also based on a linear combination of previous states pr parenleftbig x a b parenrightbig k summationdisplay i 1 ix a b i where i andk summationdisplay i 1 i based on this model every time bchanges with ain a transaction we gain evidence that bdepends on aand this evidence contributes to the computed probability.
intuiti vely ifboften changes with arecently then it is more likely that it will changewith ain the nearfuture.on the contrary if bonly changes with ain the distant past but not recently it is more likelythatthisdependencyhasbeenremovedduringevoluti on.
to capturethis temporalphenomenon we use a monotonically decreasing smoothing function 3 to account for software evolution and weigh more recent transactions more heavily than older transactions.
table i shows several functions th at can be used as the smoothing function .
3technically i k i 1is a sequence of kvalues but it can be intuitively understood as a function that maps to the approp riate sequence value.
hence we interchangeably refer to it as either a sequ ence or a function.the first column shows a constant function in which all the transactions are weighed the same regardless of how long ago they occurs as with the traditional evolutionary depen dency definition.
the second column shows a linear function indicating that the usefulness of a transaction in terms of determining stochastic dependency decreases linearly ove r time.thethirdcolumnshowsasinusoidalfunctionthatweig hs the most recent transactions similarly and older transact ions lessandless.thelastcolumnshowsanexponentiallydecayi ng function which models a rapid decreasing of the usefulness of a transaction over time.
these last three functions weigh past transactions less heavily than recent transactions.
by using a limited history kand a decreasing sequence our stochastic dependencies potentially can recover more quickly from refactorings which may significantly alter th e dependencystructure of a design than traditional evoluti onary dependencies that only use confidence to detect such changes .
our stochastic dependency definition is a generalization of traditional evolutionarydependenciesbecause they repre sent a specific kvalue and sequence for stochastic dependencies.
for example to use a minimum support value of and minimum confidence of in determining traditionally defined evolutionary dependency we can compute the evolutionary dependency b a at the time when th transaction involving aoccurs using our stochastic dependency model by letting k considering all the existing transactions involving a and k k i treating these transactions equally .
then aevolutionarydependency b a issaidtoexist attime ifthe probabilityexceedsboththeminimumsupportandconfidence pr parenleftbig x a b parenrightbig max braceleftbig bracerightbig v. evaluation to evaluate the effectiveness of our stochastic model we conductchangeimpactanalysisusingthestochasticdepend encies defined in the previous section.
we compare the accuracy of ia using members of the stochastic dependency family with different combinations of k length of history and smoothing function .
we also compare the results with two traditional structure based ia techniques and the prevail ing evolutionary coupling based ia techniques aiming to ans wer the following questions q1 are stochastic based ia approaches more accurate than traditional structure based ia techniques?
for each subject system we compare the accuracy of each stochasticdependency basedia with structure basedia techniques.
q2 are stochastic based ia approaches more accurate than prevailinghistory basedia techniques which do nottake different types of evolution into consideration?
as we mentioned before the prevailing evolutionary coupling definition is a special case of our stochastic dependency family.
q3 how does the selection of kaffect the accuracyof impact analysis?
we investigate the hypothesis that the ia will achieve peak performance with a particular choice of k and that the length history can impact ia performance.296table i example lambdasequences constant linear sinusoidal exponential k2 k i k2 kcos parenleftbig k i parenrightbig k i k2k q4 how does the selection of a sequence affect the accuracy of impact analysis?
we investigate the hypothesis that in general the usefulness of a transaction decreases over time.
we consider that the hypothesis is true if we observe increasing ia performance with a decreasing .
we also hypothesize that the best function for each subject system will be different because as independent projects their evolution paths should be different.
in this section we first describe the five software systems to whichwe applyourapproach.thenwedescribetheevaluation procedure and present the results.
a. subjects table ii shows some basic information of the following five open source systems that we chose as the subjects of our evaluation.
these projects were chosen because they hav e different sizes and are from different domains.
log4j 4a popularlogging framework for the java programming language.
hadoop common 5a java based distributed computing framework hadoopcommonprovidesthe shared components and functionality used by other hadoop sub projects.
jedit 6a text editor that supports syntax highlighting of source code and the ability to write macros.
apache ant 7an automated software build tool for java applications.
jboss 8oneofthemostwidelyusedjavaapplicationservers in the world.
it providesa platform for runningenterprise j ava applications based on the java ee standards.
b. evaluation procedure for each subject system we extract transaction informatio n from its subversion svn repository.
for each transaction we randomly select a file that is involved in the transaction a s ii subjectsysteminformation subject vers history ksloc trans log4j hadoop common jedit apache ant jboss the starting impact set and performed impact analysis on it .
assuming each transaction is a single change task an ideal i a approachwouldbeabletoidentifyallfilesinthetransactio nas being in the impact scope.
we perform ia on each transaction up to five times fewer if the transaction has fewer than five files with a different random starting impact file each time .
thesame startingimpact files foreach transactionare used f or all the approaches for unbiased comparison.
consistent wit h theworkofzimmermannet al.
we ignoretransactionswith morethan30files astheyare unlikelyto be meaningful.these large blanket operations on the code base are often changes t o licensing information that need to be updated in the comment section of all files or other trivial housekeeping activiti es on the code base.
we usethe standardinformationretrievalmeasuresof precision recall and f1for assessing the accuracyof ia.
precision measures how much of the predicted impact scope is correct while recall measures how much of the actual impact scope was predicted.
the f1measure score combines precision and recall into a single number for ease of comparison.
next we introduce the existing ia techniques against which we compare our stochastic based ia technique.
precision correct predicted recall correct transaction size f1 precision recall precision recall2971 structure based impact analysis to answer the first evaluation question we compare our stochastic ia accuracy with that of two traditional structure basedia techniques .
the first is from the work of briand et al.
.
they proposed a structural coupling measure that combines whether classe s fromdifferentinheritancehierarchiesinteract cbo w hether aclass directlyorindirectly aggregatesanotherclass inag and the number of method calls between classes pim .
to ease analysis we normalize their coupling measure into the range of by dividingby the largest measure value.
in this section we refer to this technique as the staticdependency approach.
the other structure based approach we compare against is the work of robillard .
robillard defines an algorithm that given a starting impact set assigns a weigh t in the range to other software elements based on analyzing the structure topology of the dependency graph.
in t his section we refer to this technique as the topology dependency approach.
to perform ia using these measures we first compute the dependency values of the files based on the software structur e in the most recent release.
given a minimum threshold value we select all files whose dependency value is at least the threshold value to be included in the impact scope.
prior to performing ia on a given software release we first identify the minimum threshold value that maximizes the f1measure.
essentially we compare against the best accuracy of these structure based ia.
history based impact analysis to answer the second evaluation question we compare the ia accuracy using stochastic dependency against traditional evolutionary d ependency .
we perform traditional history based ia on a transaction by analyzing all transactions from the beginni ng of the revision history to the most recent release in order t o be fair to the structural dependency experiments .
similar ly to the structural dependency experiments we determine the be st minimum support and confidence values that maximize f1 prior to processing the transactions for each software rele ase.
stochastic based impact analysis we use the four sequences presented in table i as the smoothing function of each stochastic dependency family member.
for each sequence we use the values of and for k maximum number of transactions to consider .
as a result we consider members of the stochastic dependency family in total.
like with evolutionary dependencies we consider the transaction for the most recent software release to be the la test transaction available for analysis.
although various roun ding techniques are possible for our stochastic dependency valu e to determine whether a file is in the impact scope we follow the same strategy as with the structural dependencies give n a minimum threshold a file is considered in the impact scope if its stochastic dependency value is at least as large as the threshold.
also similar to the other two types of ia approaches we find the best minimum threshold for each software release.c.
results table iii shows the results from our evaluation.
for each subject system and ia technique we show the average f1 score in the column labeled f1.
the average f1score is computed over the ia predictions for all transactions.
for example with apache ant we ran a total of impact analyses on transactions with each dependency type.
we compute the average f1score for each dependency type by adding the f1score for each of the ia analysis results and dividing the total by .
due to space constraints we onlyshow the f1valuesforthe stochastic dependencieswhere k .f1values for other kvalues are discussed below.
a q1.
comparing with structure based ia table iii shows that the accuracy by f1measure of both structurebased ia for all the subjects are lower than any member of the stochastic based ia approaches and are also lower than traditional history based impact analysis.
take hado op common for example the topology approach achieved an average f1score of .
and the static approach achieved an average f1score of .
.
in contrast all the stochastic dependencies had average f1scores of above .
.
to confirm our intuition based on the average f1measures we apply the wilcoxon signed rank test to compare each of the stochastic dependency types against static dependen cy types.thenullhypothesis h0foreachstatistical testisthatthe f1value per impact analysis on each transaction achieved by the existing approach is the same as the f1value achieved by the stochastic dependency.the alternativehypothesis h1is that the stochastic dependency achieved greater f1value than the existing approach.
the resulting w scores and p values from performing the statistical tests with a confidence interval are also shown in table iii.
the results of the wilcoxon signed rank test corroborate our intuition that the stochastic dependencies outperform ed the structure based ia approaches.
all the p values from the statistic testswere .
thesmallest p valuepossible in our statistics software r9 .
these p values which are statistically quite significant indicate that the null hyp othesis should be rejected and the alternative hypothesisshould be accepted i.e.
the stochastic dependenciesprovidemoreacc urate predictions than the static dependencies .
from these resu lts we can affirmatively answer the first evaluation question tha t stochastic dependencies are more accurate than traditiona l structural dependencies at ia.
b q2.
comparing with traditional history based ia lookingat theresultsfromtable iii we see thatforanyofth e fivesubjectsystem threeoutofthe fourtypesofthestochas tic dependencies yield a higher average f1score than traditional evolutionary dependencies and that the differences are st atistically significant.
take log4j as an example we observe that the average f1for the constant stochastic dependency is .
which is lower than that of evolutionarydependenci es .
.
the statistical test results w score of .
and pvalue of .
confirm that the stochastic dependency does iii wilcoxon signedranktestresults for f1scores k subjectstochastic evolutionary topology static f1 f1 w p f1 w p f1 w p log4jconst .
.
.
.
.
.
.2e .
.2e line .
.
.133e .
.2e .
.2e sine0.
.
.57e .2e .
.2e expon .
.
.552e .2e .2e hadoopconst .
.
.
.
.
.2e .
.
.2e line .
.654e .2e .2e sine0.
.406e .2e .2e expon .
.2e .2e .2e jeditconst .
.
.043e .
.2e .
.2e line .
.054e .2e .2e sine0.
.
.2e .2e expon .
.
.2e .2e antconst .
.
.
.
.
.2e .
.
.2e line .
.2e .2e .2e sine0.
.2e .2e .2e expon .
.2e .2e .2e jbossconst .
.
.
.
.
.2e .
.
.2e line .
.339e .2e .2e sine0.
.895e .2e .2e expon .
.2e .2e .2e not outperformthe evolutionary dependenciesin this scena rio.
we highlight the cells of table iii where the statistical test results indicate that our stochastic dependencies did not outperform the existing dependency type.
although the stochastic dependenciesdo not always outperform the evolutionary dependencies we affirmatively answe r our second evaluation question because for each subject system most stochastic dependency types can provide more accurate ia results than traditional evolutionary depende ncies.
due to the differencein the evolutionpathsof subjectsyste ms it is not surprising that some stochastic dependency types c an provide more accurate ia results.
below we further explore how the parameters that define stochastic dependencies kand influence analysis accuracy.
c q3.
effects of k in determining the effects of k length of history on the accuracy of analysis we again app ly the wilcoxon signed rank test.
given a fixed smoothing function we vary the value of kand compare the f1values.
table iv shows the average f1scores for hadoop common as a representative example.
table iv average f1scores for an bracketle t k an bracketri htpairs hadoopcommon hhhh k5 const .
.
.
.
line .
.
.
.
sine .
.
.
.
expon .
.
.
.60302from table iv we see that increasing the value of k generally decreases the accuracy of analysis except in the case of the exponential smoothing function where increasin g kfrom to improves the accuracy .
to corroborate these observations we apply the wilcoxon signed rank test with a nullhypothesisthattwodifferent kvaluesareequallyaccurate.
the alternative hypothesis is that one of the kvalues is more accurate than the other.
for example comparing k 5and k 10for the linear smoothing function of hadoop we obtain a w score of .
and p value of .
which confirms that k 5is statistically more accurate than k .
comparing k 10andk 20for the same smoothing function yields a w score of and a p value of9.
which indicatesthat k 10ismoreaccurate thank .
we applied this statistical test to all pairs of kvalues in each subject system and found consistently that changing thekvalue does affect the accuracy of analysis.
due to space restrictions we do not elaborate on the statistical t est results for the other subject systems.
these results allow u s to affirmatively answer our third evaluation question that the value of kdoes influence the accuracy of analysis and that both too long and too short of a history will negatively impac t the ia results.
d q4.
effects of to evaluate the effects of different sequences we compare the accuracy of applying the four sequences for each given subject system.
for example table v shows the average f1valuesfor jboss underdifferent combination of andk.
for example when k the constant smoothing function yields lower accuracy than the299other functions and the exponentialsmoothingfunction yi elds highest accuracy.
to conduct the wilcoxon signed rank test we define null and alternative hypotheses to compare differe nt pairs under the same k. as an example we define a null hypothesis as the linear and constant smoothing functions are equally accurate and t he alternative hypothesis as the linear function is more accur ate.
for jboss with k we obtain a w score of and a p value of .
.
this statistically significant resultconfirmsthatthelinear performsbetterthanconstant function.comparingthe exponentialandsinusoidalsmooth ing functions we obtain a w score of and a p value of1.
confirming that the exponential function is more accurate than the sinusoidal function.
on the other han d comparing the linear and sinusoidal smoothing functionsyi eld aw score of .
and a p value of .
indicating no significant difference in accuracy.
these results sugges t that jboss follows an evolution path with high refactoring activity since the historical data quickly becomes inaccu rate in performing ia.
table v average f1scores for an bracketle t k an bracketri htpairs jboss hhhh k5 const .
.
.
.
line .
.
.
.
sine .
.
.
.
expon .
.
.
.
we obtain similar results with other subjects different provides different ia accuracy in different projects the exponential smoothing function is best for hadoop and jboss with log4j sinusoidal smoothing slightly outperformsoth ers forapache ant the linearand sinusoidalfunctionsare equa lly best for jedit the linear and constant functions are equal ly best.
so we can positively answer the last evaluation questi on in most cases a decreasing sequence increases accuracy and the best for a project differs due to different evolution paths where the speeds at which historical data becomes irrelevan t can vary.
d. assessing precision and recall while the f1score provides a simple single quantity measure the respective importance of precision and recall measures varies with applications.
for the purpose of impac t analysis the recall measure is considered more important t han precision because developers do not want to miss important files that need to be changed.
in this subsection we provide further elaboration on the precision and recall values usi ng jboss the largest subject systems as a representative exam ple.
in table vi we present the quartile values of precision and recall scores of each type of ia analysis on jboss.
table vi shows that the static and topology dependencies have very high precision but low recall compared to stochastic dependencies.
the high precision is not surpris ingbecause these techniques identify components that are high ly structurally coupled and hence they are most likely to be impacted by changes.
the low recall is also not surprising many semantically coupled componentsdo not have structura l dependencies.
by leveraging historical data the evolutio nary and stochastic dependencies can detect semantic coupling a nd improve the recall scores but at the cost of slightly decrea sed precision values.
the large increase in recall compensates for the small lost in precision and improves the overall f1 accuracy.
similarly table vi shows that the exponential smoothing functionachievesthesameprecisionquartilevaluesasthe evolutionary dependencies even though the average arithmet ic mean precision is slightly lower not shown .
the table als o shows that comparing with traditional evolutionary depend encies exponential stochastic dependency achieves signific ant improvement in the recall in the first quartile q1 the rec all increases from .
to .
and the median q2 recall increas e from .
to .
this means that more than half the impact analysesconductedbythe exponentialstochasticdependen cies had perfect recall.
table vi quartile values of ia accuracy on jboss k approach measure min q1 q2 q3 max staticprecision recall .
.
topologyprecision recall .
.
evolutionaryprecision recall .
.
const stochasticprecision recall .
.
line stochasticprecision .
recall .
sine stochasticprecision .
recall .
expon stochasticprecision recall .
we make similar observations from the other subject systems comparing with traditional evolutionary dependenci es our stochastic dependencies consistently have slightly lo wer precision values but have significantly better recall valu es and thus significantly higher f1values.
table iii shows that thef1values for the other subject systems are lower than those for jboss but this precision recall tradeoff occurs with all the subjects.
vi.
discussion in this section we discuss the evaluation results threats to validity and possible future work.
although stochastic dependency is a generalization of evolutionary dependency not all stochastic dependencies wit h constant sequences are evolutionary dependencies due to thekparameter.
in order to identify the same impact scope as evolutionary dependencies we need to have a constant300 sequence andkmust be the number of allthe transactions involving the starting impact set.
that is why in our evaluation the stochastic dependency types with a constan t sequence did not perform the same as traditional historybasedia.
to achievethesame resultsas existinghistory ba sed ia we would have needed to vary the value of kfor each transaction.
the low ia accuracy for some of the evaluation subject systems may seem alarming at first the average f1measure dips down to1 3for some systems .
however the accuracy in actual usage may be significantly higher.
this low accuracy i n the evaluation is due to two factors the directional nature of impact analysis and the selection of a random starting impac t set.
for example consider a transaction that contains a bas e classaand its two subclasses bandc and assume that it is only possible for changesto ato affectbandc but changes to borcneveraffect a. sincewedonotknowthat ais thecorrect starting impact set our evaluationapproachconsiderseac h file to be a starting impact set.
hence even a perfect ia approach would only achieve a .
average f1score f1 1withaas starting impact set f1 0withborcas starting impact set .
identifying the actual starting impact set of a transaction or modificationrequestisanactiveareaofresearch e.g.anto niol et al.
that is orthogonal to our stochastic approach an d can be used to improve ia accuracy in the future.
in our evaluation we found the optimal minimum threshold values to compare each ia approach at its best accuracy.
however in practice the best value is not known a priori.
one strategy to address this problem is to use the optimal threshold from the previous release s transactions.
after each software release the minimum threshold can be recomputed and used for estimating during the next release.
e threats to validity since we only applied our approach to five java based object oriented systems we cann ot conclude that the effectiveness of stochastic dependencie s generalizes to all software systems however we did choose projects of various sizes and domains to begin addressing th is issue.
similarly we only applied the stochastic model to ia but not other analysis techniques where historical data can be leveraged such as bug triage prediction.
thus we cannot claim that the same improvement can be generalized to other history based analysis techniques.
as with any technique that derives dependencies from transactions in revision history our approach assumes tha t the transactionsrepresent cohesivework units.
in other words if a developer only commits to the revision control system a batc h of files once in a while the files committed together may have no semantic relationship and are only coincidentally occur ring in the same transaction.
the accuracy of ia produced by stochastic dependencies and evolutionary dependencies in dicate that transactions often are cohesive work units and generally do indicate semantic coupling of software elemen ts.
our framework assumes that the transactions of a revision control history form a stochastic process where the dependencies between software elements control the probability distributionoftherandomvariablesinthisprocess.weuse thisassumption as the basis for building the markov chain model.
inreality theprobabilitydistributionoftheserandomva riables software elements that occur together in a transaction ca n also be influenced by external factors and our assumption may not always be true.
however our evaluation shows that modeling the revision history as a stochastic process is a suffic ient approximation for the actual behavior of development to yie ld more accurate ia results.
f future work the parameters of stochastic dependency allow for a large number of specific dependency types to be defined.
in the study reported in this paper we only used several kand values.
identifying additional successful sequences is an ongoing work.
for example a possible sequence could be based on the how long ago i.e.
in terms of days months etc.
a transaction was committed.
th e bestkvalue for different systems may also vary.
exploring techniques to automatically construct optimal andkvalues for a given software system is also a possible future work.
exploring methods to improve the accuracy of stochasticbased software analysis in general is an ongoing work.
in particular we are exploring the use of more complex probabilisticmodels e.g.hiddenmarkovmodels dynamicbayesi an networks in place of the markov chain model.
incorporating structural dependency information into these model s to improve ia accuracy is also of interest.
vii.
c onclusion using history based evolutionary coupling to conduct various software analyses in software maintenance has gained popularity recently.
however differences in the speed of evolution of different software systems affect the validit y of historical data used for analysis and thereby the accuracy of the analysis results.
our stochastic dependency framewo rk generalizes evolutionary coupling using a length of histo ryk and a smoothing function parameter to account for different typesofevolutionpaths.by varyingthese two parameters o ne can select the combination that best fits the system.
our experimentshowsthat performingia using stochastic depende ncies consistently outperforms structure based ia techniq ues.
comparing with prevailing history based ia techniques ou r stochastic based approach can provide better ia accuracy in particular significant improvementin recall for all five su bject systems.