managing non functional uncertainty via model driven adaptivity carlo ghezzi leandro sales pinto paola spoletiniy and giordano tamburrelli deepse politecnico di milano italy.
fghezzijpintojtamburrellig elet.polimi.it yuniversit a dell insubria italy.
paola.spoletini uninsubria.it abstract modern software systems are often characterized by uncertainty and changes in the environment in which they are embedded.
hence they must be designed as adaptive systems.
we propose a framework that supports adaptation to non functional manifestations of uncertainty.
our framework allows engineers to derive from an initial model of the system a finite state automaton augmented with probabilities.
the system is then executed by an interpreter that navigates the automaton and invokes the component implementations associated to the states it traverses.
the interpreter adapts the execution by choosing among alternative possible paths of the automaton in order to maximize the system s ability to meet its non functional requirements.
to demonstrate the adaptation capabilities of the proposed approach we implemented an adaptive application inspired by an existing worldwide distributed mobile application and we discussed several adaptation scenarios.
i. i ntroduction modern software systems are characterized by an increased complexity for example in terms of size as well as geographical distribution.
moreover engineers increasingly design systems by relying on components operated by third party organizations.
all these factors introduce many sources of uncertainty in designing software that should guarantee certain quality requirements.
for example a component operated by a third party organization has an uncertain execution time and failure rate.
this means that at design time engineers can make certain assumptions but these may be invalidated at run time.
indeed uncertainty may subvert design time assumptions jeopardizing the system s ability to meet its requirements.
the execution time of a remote component may increase unexpectedly affecting the response time of the overall system or similarly a component failure may affect the system s reliability.
both cases may lead to potential violations of non functional requirements that cannot be tolerated.
to cope with uncertainty software can be designed as an adaptive system .
in practice engineers typically design systems by explicitly programming alternative behaviors and by heavily using exception handling techniques to adapt the execution to detected changes in the environment that reify the sources of uncertainty.
this is quite hard per se and cannot be done by inexperienced developers.
in addition using this approach such alternative behaviors cannot be kept separated from each other and from the exception handling code.
as a result the architecture and the code are hard to understand and maintain.to overcome this limitation we present adam 1a modeldriven framework conceived to support the development and execution of software that tolerates manifestations of uncertainty by self adapting to changes in the environment trying to do its best to satisfy certain non functional requirements.
in particular we support adaptation aimed at mitigating the non functional uncertainty concerning response time and faulty behavior of components integrated in a composite application.
the proposed solution models the system as a workflow of abstract functionalities.
for each of them one or more implementations are provided.
the approach derives then a finite state automaton augmented with probabilities in which each state of the automaton represents an implementation of an abstract functionality of the system while paths represent all the possible execution flows of the system.
the system execution is performed by an ad hoc interpreter that navigates the automaton state by state and invokes the implementations associated with the states it traverses.
the interpreter is responsible for driving and adapting the execution by choosing among alternative paths of the automaton in order to maximize the system s ability to meet its non functional requirements.
with this paper we contribute to research in self adaptive systems in two distinct ways we lay the foundations of a model driven methodology that supports the design of systems in terms of abstract functionalities and delegates the execution to an optimizing interpreter which self adapts to changes by selecting the implementation variants to bind to abstract functionalities in order to satisfy non functional requirements we present a novel technique to support non functional adaptation that exploits probability theory and probabilistic model checking .
the proposed technique computes and assigns a probability to each possible execution flow of the system indicating their likelihood to meet the desired non functional requirements.
in our approach the interpreter relies on such values to drive the execution the remainder of the paper is organized as follows.
section ii introduces a reference example we use throughout the paper.
section iii describes the adam approach in its essential steps presenting it also applied to the example 1adaptive m odel driven execution978 .
c ieee icse san francisco ca usa33 highlighting several relevant scenarios.
section iv discusses its advantages w.r.t.
the state of the art.
section v evaluates the performance of adam in several scenarios of growing complexity.
finally section vi discusses related work while section vii draws some concluding remarks.
ii.
t heshopreview application shopreview hereafter referred to as sr has been selected as the adaptive application used throughout the paper to explain our approach.
sr is a mobile application for smartphones inspired by shopsavvy 2an existing worldwide distributed application which allows users to share data concerning a commercial product or query for data shared by others.
users may use sr to publish the price of a product they have found in a certain shop and in response the application provides the users with more convenient prices offered by i nearby places i.e.
localsearch or ii on line stores i.e.
websearch .
the unique mapping between the price signaled by the user and the product is obtained by exploiting the product s barcode.
the application starts by asking the user to scan a barcode with the smartphone camera and to type the price of the product whose barcode has been scanned.
in response to these inputs the applications recognizes the barcode number in the scanned image looks up online the product associated to the barcode number retrieves the user location performs the websearch as well as the localsearch displays the obtained results and allows the user to publish the price of the product to be used by searches issued by other users.
furthermore we decide to implement the code for recognizing the barcode from a picture acquired through the camera which runs an ad hoc developed component that encapsulates an image recognition algorithm.
since such component executes correctly only on devices with an autofocus camera and does not work properly on other devices this choice would limit the usability of our application.
for this reason sr as for the original shopsavvy app is designed to provide also an alternative recognition algorithm.
indeed it detects if the camera on the current device has autofocus and if not it invokes an external service to process the acquired image with an ad hoc blurry decoder algorithm.
in both cases if the barcode cannot be recognized e.g.
the image is blurred the application asks the user to take the picture again.
in addition let us assume that sr must satisfy the nonfunctional requirements listed in table i. r1 for example is a performance requirement typically imposed by several marketplaces of mobile applications.3notice that in our application several features contribute at large to usability r2 .
for example to retrieve the user location the gps is preferable over the nps4because of its increased precision.
similarly presenting a sorted list by price and distance of the results of websearch and localsearch respectively also increases the app s usability.
3the windows phone marketplace requires that applications unresponsive for more than three seconds must display a visual progress or busy indicator msdn.microsoft.com en us library hh184840 v vs. 4network positioning system.table i shopreview non functional requirements .
description metric class r1 after an input the application response threshold shall respond in at most 3s.
time rt based r2 maximize application usability usability u max r3 minimize battery consumption energy consumption e min adam supports two classes of non functional requirements threshold based and max min.
the former comprise requirements in the form m thorm th where mis a non functional metric e.g.
response time energy etc.
andthis a threshold see r1 .
the latter requires to minimize maximize a non functional metric see r2 r3 .
sr is subject to several sources of uncertainty and as a consequence run time conditions may jeopardize the application s ability to meet its non functional requirements.
for example engineers may design sr to be compliant with r1 by estimating or experimentally measuring the response time of the component implementing the websearch functionality which invokes a remote back end.
however such response time may increase unexpectedly during operation because of the network latency or other external factors causing the system to violate r1.
such unexpected behavior if left unmanaged may cause an unsatisfactory user experience or in the worst case the rejection from the marketplace.
thus even with such a simple example uncertainty management is fundamental for a successful system design.
it is important to notice that the concepts illustrated through this paper apply seamlessly to larger and more complex systems where the benefits of our approach are even more relevant.
iii.
t headam a pproach adam is a model driven framework conceived to support the development and run time operation of self adaptive systems which can react to unexpectedly higher response time or unexpected faults of the parts they rely upon.
let us start by giving an overview of the approach as illustrated in figure .
first developers provide a model of the system in terms of abstract functionalities organized in a workflow.
in particular we support systems modeled by activity diagrams .
for each abstract functionality developers also provide one or more target implementations annotated with a description of their non functional behaviors.
annotations may concern for example the expected execution time cost or the impact on energy consumption or on the application s usability.
the supplied target implementations display different non functional qualities.
the goal is to be able to develop dynamic composition of target implementations that best match the overall application s requirements.
we assume target implementations to be stateless components.
given these inputs and a set of non functional requirements the system has to meet the approach relies on two distinct tools the generator and the interpreter .
the generator analyzes the activity diagram and the corresponding annotated target implementations and generates a finite state34developer uml activity diagrams implementations generates invokes executes uses annotates designs uses embedded model ...... ............interpreter prism uses generator fig.
.
the adam approach.
automaton called embedded model em .
in the em each state represents an implementation of an abstract functionality of the system while paths represent all the possible execution flows.
the interpreter is instead in charge of executing the system by navigating the automaton state by state and by invoking the chosen target implementations associated to the states it traverses.
in particular it is responsible for driving and adapting the execution by choosing among alternative paths of the automaton in order to maximize the system s ability to meet its non functional requirements.
by this we mean that the interpreter first measures the effects of non functional uncertainty e.g.
the response time of invoked functionalities and consequently chooses the most convenient path in the em to maximize the likelihood of meeting all the system s requirements.
this way if the interpreter detects that the current execution is slower w.r.t.
a certain performance requirement it may autonomously decide to drive the execution by choosing a specific fast path in the em that guarantees the compliance with the performance requirement.
the approach comprises the following steps modeling transformation model manipulation and execution .
hereafter we describe each of them in detail.
for each step we also illustrate it referring to the sr example.
a. modeling as previously introduced the system is initially conceived in terms of abstract functionalities and modeled by one or more uml activity diagrams which organize them in workflows.
for each abstract functionality engineers also provide one or more corresponding alternative target implementations .
the design methodology to derive the set of target concrete functionalities for each abstract one given the overall requirements and an uncertainty mitigation policy is out of scope of the present paper.
we observe however that designing systems in terms of alternative implementations corresponds to an approach already used for complex software systems even if informally.
for example in mobile applications the user location is typically obtained by relying on two alternatives the gps sensor or the nps.
clearly every abstract functionality needs at least one corresponding implementation.
in addition while modeling engineers are allowed to annotate a subset of the abstract functionalities as optional .
usually optional functionalities are not essential for the correctness of .
photo acquisition input price product lookup web search local search publish price optional result ordering local recognition remote recognition optional secondary web search .
.
true false location .
true false showmap nps location nps alternative fig.
.
shopreview uml activity diagram.
the final result but may however affect usability.
if necessary they are sacrificed to accomplish more important goals.
as illustrated in the example each non functional requirement predicates over a certain non functional metric.
as a consequence each implementation is annotated with the impact it has w.r.t.
these metrics.
for example an implementation of an abstract functionality with an expected response time of 2seconds is annotated with responsetime 2s .
concrete implementations that require user interaction cannot be annotated with an impact on response time since they depend on the user s think time.
they are therefore annotated with ui whose meaning will become clear later on.
notice that the annotation process occurs for each requirement metric on all the implementations.
finally adam requires engineers to annotate each branch of decision nodes in the uml activity diagram with the expected probability that an execution of the system may take that branch.
when not specified branches are considered to have the same probability.
modeling the sr application.
the modeling step applied to the sr example may produce the activity diagram illustrated in figure .
for each abstract functionality one or more concrete implementations are provided.
for instance concerning productlookup which translates a barcode into a product name sr relies on a remote service e.g.
searchupc.com as one of the possible implementations.
alternatively the application may ask the user to directly provide the product s name.
as for searching the web for more convenient prices sr relies on a primary remote service e.g.
shopzilla.com and on complementary services represented by the abstract functionalities websearch andsecondarywebsearch respectively.
note that the secondarywebsearch is annotated as an optional functionality to represent the fact that it may be omitted at runtime if necessary.
similarly the resultordering functionality which sorts the results of websearch andlocalsearch by price and distance respectively has been annotated as optional.
concrete implementations are provided by java methods using the ad hoc annotation implementation to refer to the abstract functionality they implement.
moreover the annotation impact is used to specify the impact the implemen implementation name productlookup impact metrics f responsetime energy u s a b i l i t y g values f1 g public s t r i n g automaticproductlookup s t r i n g barcode f invoke h t t p searchupc .
com g implementation name productlookup impact metrics f energy u s a b i l i t y g values f1 0g ui public s t r i n g manualproductlookup s t r i n g barcode f ask the user to i n s e r t the product name g listing .
implementations for the productlookup functionality.
tation has w.r.t.
the requirements metrics.
listing illustrates two methods implementing the productlookup functionality as described earlier.
note that impacts may be objective values as for the response time or subjective measures as for the usability or energy consumption.
for example we annotate with 2the expected energy consumption of the automaticproductlookup implementation to indicate that it requires more energy i.e.
battery usage w.r.t.
the second alternative which is annotated with an impact equal to .
indeed the first alternative includes the invocation to a remote service which implies a higher energy consumption.
alternatively the implementations may be annotated with the real energy consumption they have.
however such values are difficult to measure and are also device dependent.
by relying on the proposed qualitative annotations we do not need to necessarily know the real power consumption of the two alternative implementations but only their relative difference .
furthermore being these impacts estimates and or experimental results they may be also automatically updated and refined at run time as discussed for example in our previous work .
similarly concerning usability we annotate the two implementations with different impacts to indicate that the automatic alternative is preferable over the alternative which asks the user with an explicit input.
activities in the diagram may also map to sub diagrams as for the location that maps to a concrete implementation concerning the gps alternative and another activity diagram as reported in a dashed box in figure .
according to the second option the user s location is obtained by first invoking the nps and then showing a map i.e.
showmap centered in the obtained location for a manual refinement.
this way we allow for a hierarchical composition of diagrams.
the last step in the modeling phase concerns the probability annotations of decision nodes.
decision nodes guarded by the conditions hasautofocus andrecognized have been annotated with the probabilities reported in figure .
they express respectively the fact that of mobile devices do not have an autofocus camera and on average of barcodes contained in acquired pictures are correctly recognized.
b. transformation activity diagrams are translated into a formal representation the embedded model em which is a markov decision process mdp .
mdps are finite state machines augmented with probabilities and non deterministic transitions.
the formal concepts concerning mdps needed to understand the rest of the paper are summarized in the appendix.the translation of activity diagrams into an mdp is performed by the generator tool.
it first translates each abstract functionality into a simple mdp with an initial state a final state and as many intermediate states as the number of implementations associated with the abstract functionality.
in addition it adds a non deterministic transition from the initial state to each intermediate state that are in turn connected to the final state.
the resulting mpds are then merged in a single mdp which represents the translation of the overall activity diagram.
moreover annotations attached to implementations are also propagated into the em by annotating each state in the model with the same impact numbers as its corresponding implementation.
notice that connections which participate in decision nodes i.e.
connections labeled with probabilities are translated in the mdp as probabilistic transitions labeled with the same probabilities as the originating connections.
transforming the sr activity diagram.
as we said above we first translate each abstract functionality into a simple mdp with an initial state a final state and as many intermediate states as the number of implementations associated to the abstract functionality.
for example the productlookup functionality which has two corresponding implementations results in the mpd in figure a .
a functionality annotated as optional also requires the introduction of a direct transition from the initial state to the final one.
for example if we have two alternative implementations of the secondarywebsearch which differ in the remote service they invoke we obtain the mdp in figure b .
the resulting mdps are then composed together as follows.
two mdps corresponding respectively to two subsequent nodes in the activity diagram are composed by merging the final state of the first one with the initial state of the second one.
by merging such states we generate a symbolic state .
this process is exemplified in figure c where symbolic states are highlighted in grey and labeled with a letter.
decision nodes are translated similarly.
the mdp corresponding to a functionality that precedes a decision node has its final state merged to the initial state of all the mdps corresponding to the functionalities subsequent to the decision node.
the merging process generates a symbolic state as aforementioned.
concerning nodes that also map to other diagrams as for thelocation node we first translate the node as explained so far considering only its implementations e.g.
the gps alternative .
subsequently we add as an alternative path from the initial to the final state the mpd obtained by translating the other diagrams e.g.
the nps sub diagram .
the translation process applied to the activity diagram of the sr application results in the em reported in figure d .
for intance the functionality location is represented in the mdp by state 6a i.e.
the gps alternative and states f i.e.
the translation of the nps nested diagram .
at this stage we propagate the annotations attached to the implementations into the em.
in figure d we indicate them withrt e andufor response time energy consumption and usability respectively.
for example state 5b which cor product lookup 5a5b ..... ..... activity mdp a alternative implementations.
optional secondary websearch 9a9b ..... ..... activity mdp b optional functionality.
8activity mdp websearch ..... i ..... optional secondary web search 9a9b c composition of mdps.
rt .3s e u c g hrt .6s e u rt .5s e u rt .3s e u rt .6s e u rt .8s e u rt 2s e u i rt .6s e u 9a 9bj rt .6s e u rt .5s e u .
.
6a e b f rt 0s e u a0.
.
5a 5brt 0s e u d rt 0s e u rt 0s e u k rt 0s e u d shopreview embedded model.
fig.
.
translation process.
responds to the automaticproductlookup implementation see listing is annotated with its impact in terms of response time i.e.
5s energy consumption i.e.
and usability i.e.
.
since symbolic state are artificially generated by the translation process they are annotated with neutral values rt e u .
notice that by construction the obtained em represents all the possible execution flows of the system in terms of target implementations.
indeed starting from its initial state the mdp has multiple alternative paths towards the final state.
the translation process performed by the generator hides the complexity of mdps to developers.
a formal description of the automatic translation algorithm is not given here for space reasons.
it is based on the automatic translation of an annotated activity diagram into a markov process that was presented in our previous work i.e.
.
c. model manipulation the annotations attached to the states of the em represent the impact of the corresponding implementation on quality metrics.
formally this information corresponds to rewards in the mdp formalisms see the appendix .
it can be used to compute the minimum and maximum cumulative rewards indicated as minr s andmaxr s from each state sto the final state in the model and for each quality metric.
the computation of such cumulative rewards may be arbitrarily complex because of three characteristics of the model loops probabilities attached to transitions a large number of alternative paths.
we rely on a probabilistic model checker such as prism to compute them.
given these premises we manipulate the model by replacing impact numbers attached to each state swith an intervalhminr s maxr s i for every requirement metric of the system.
it is important to notice that such intervals represent forecasts of the impacts necessary to complete the execution i.e.
reach the final state starting from a specific state sof the model.
at execution time such values are used by the interpreter to select the most appropriate path towards the final state as illustrated in section iii d. figure illustrates the cumulative rewards obtained by exploiting prism for some states of the em.
notice that when cumulative rewards are computed for response time all the states characterized by user interaction i.e.
whose corresponding implementations are annotated with ui are considered as final states of the em together with the original final states.
indeed the requirements concerning response time e.g.
r1 predicate over the portions of the system in which the computation occurs autonomously i.e.
without user input.
9a 9bi... rt .
.
e u rt .
.
e u jrt .
e u ... fig.
.
model execution example.
manipulating the sr model.
at this stage we manipulate each statesof the model in figure d by replacing impact numbers with intervals in the form hminr s maxr s i for every requirement metric obtained by running the probabilistic model checker as explained above.
for example let us focus on state 6aand usability.
in this case the model checker yields the following values h4 6i.
these values indicate that an execution reaching state 6awill have an additional usability impact value in the interval h4 6ito reach the final state.
similarly for the response time and energy consumption we obtainh2 1iandh8 11i respectively.37d.
execution at run time given the annotated em the interpreter is in charge of executing the application by navigating through the state space.
it invokes the corresponding implementation and performs two additional tasks.
first it keeps track of the cumulated impact of all the quality metrics.
for example assuming that the interpreter invoked two implementations that executed in 1sand0 5s its aggregated response time is 5s.
the run time data structure that contains all these aggregated values is called the execution context .
second it selects one of the alternative paths in the model.
the choice among alternative paths occurs if the current state has many outgoing non deterministic transitions i.e.
the next functionality to be executed has many corresponding implementations and or is optional.5the choice is performed by the interpreter as described next.
given a system with a set of non functional requirements r fr1 r ngand an execution that reached state sc characterized by a set t ft1 t kgof non deterministic outgoing transitions the interpreter computes a probability of success for each alternative transition ti.
such probability pti represents the likelihood that the system may complete the execution meeting all the requirements by taking transition ti.
letsibe the destination state of each outgoing transition tiand let us focus initially on a threshold based requirement req that predicates on response time i.e.
rt th.
we know from the interval associated to each state sithat an execution through that state has an expected response time included in the intervalhai bii as computed in the model manipulation step of the approach.
in addition we know from the execution context that to reach state w the execution already cumulated a response time crt i.e.
the execution spent crtseconds to reach statesc .
given these premises we model the response time associated with the execution from state sito the final state as a random variable xsiuniformly distributed over the intervalhai bii i.e.
xsi u ai bi .
in this setting the ability of the system to meet req boils down to choosing a transition towards a state sisuch that the response time from that state to the final one is less than the requirement threshold decreased by the time already consumed to reach the current state xsi th crt.
in particular the probability that this may occur i.e.
p xsi th crt corresponds to the area in the uniform distribution comprised among aiandth crt pti rt p xsi th crt th crt ai bi ai such value corresponds to the probability of success for transitionticoncerning only response time.
in particular three cases may occur that yield to a probability of success as illustrated in figure .
intuitively if the threshold decreased by crt is greater than the interval that contains the expected values of response time probability of success is one.
conversely if 5states with multiple outgoing transitions labeled with probabilities do not represent a decision point among alternative paths since they correspond to decision nodes in the activity diagram and the next state in the execution is selected by evaluating run time conditions e.g.
hasautofocus for sr .
th c rt0 p rt th a bp rt th th c rt a b a b rtth c rt p rt th p rt th rtrtp rt th p rt th b a 1b a b a 1fig.
.
probability of success.
the threshold decreased by crtis smaller than the interval the probability is zero.
in all the other cases the probability is in accordingly to the relative position of the interval and the quantity th crt.
notice that requirements in the form ofrt thare processed similarly by inverting the area considered in computing the probability of success.
we repeat this procedure for all requirements in r. in particular if we havenrequirements and kpossible outgoing transitions the interpreter builds a n kmatrix in which each element i j represents the probability that choosing transition tiwould yield to an execution compliant with requirement rj i.e.
probabilities of success pti rj .
the interpreter is parametrized with a vector w w1 w nof weights.
such vector is used to aggregate the probabilities of success by computing a weighted average of the values in each column of the matrix.
the result is a single value for each outgoing transition which represents the probability of satisfying all the requirements according to the weight pti p j n wj pti rj .
the interpreter proceeds the execution by choosing the transition tiwith the highest pti.
notice that weights are used by the designer to prioritize requirements.
executing the sr application.
let us consider requirement r1and let us assume that the interpreter reached state i see figure .
in this scenario it has to choose among three outgoing transitions i.e.
9a 9bandj .
the probability of success of the transition towards state 9acorresponds to the probability that the execution terminates within 3s r1 .
we know from the interval associated to state 9athat the execution through that state will terminate with a response time in the intervalh0 5s 1si.
at this stage we model the response time of the execution through state 9aas a random variable x9auniformly distributed over the interval i.e.
x9a u .
furthermore let us assume that the execution context contains a cumulated value for the response time equal to crt 95s.
the interpreter computes the probability that the response time will be lower than the requirement threshold decreased by the value in the execution context i.e.
3s 95s 05s as the area in the uniform distribution in the interval h0 5s 05si p x9a 3s .
similarly for the outgoing transitions to state 9bwe havep x9b 3s .
finally for the outgoing transitions to state jwe havep xj 3s i.e.
the third case of figure .38let us consider now requirement r2 which is a maximization requirements and thus needs a slightly different process.
in this case the probability of success concerning usability associated with the transition toward state 9a i.e.
p9a u corresponds to the probability that the usability value obtained by choosing it is greater than the usability value obtained with the transitions to state 9band to state j. we know that by choosing the transition to state 9ausability would be in the interval in h2 3i while choosing the transitions to state 9bandjwe obtain a usability value in the intervals h2 3iandh1 2i respectively.
by modeling the usability of the execution through state 9aas a random variable y9auniformly distributed over the discrete interval i.e.
y9a u and the usability of the execution through states 9bandj with random variables y9b yjuniformly distributed over their intervals i.e.
y9b u andyj u we obtain that the probability of success associated with the transition toward state 9a w.r.t.r2 is p9a u p y9a y9b y9a yj x i k l 2ap y9a i y9b k yj l where a f i k l ji2h2 3i k2h2 3i l2h1 2i i k i lg.
considering y9a y9bandyjare independent variables we obtain p9a u .
similarly we obtain p9b u 75andpj u .
finally for requirement r3 i.e.
a minimization requirement we can apply a similar approach with obvious changes obtaining p9a e p9b e andpj e .
let us configure the interpreter with the following weight vectorw f0 2g which corresponds to requirements r1 r2 andr3respectively.
this choice prioritizes r1 overr3.
given these weights the probabilities of success are p9a p9b andpj .
in this setting the interpreter proceeds in the execution towards state 9a.
notice that the approach as described so far uses only uniform distributions.
however the concepts illustrated in the paper apply seamlessly to other distributions that may adopted in specific scenarios if needed.
in addition it is important to notice that the proposed approach applies identically to continuous e.g.
r1 as well discrete non functional requirement e.g.
r2 .
the only difference is the mathematical computation of probabilities.
iv.
a dvantages of the adam a pproach the inability to manage at run time the consequences of design time uncertainty leads to system that may violate their requirements.
a non adaptive implementation for sr when execution reaches a certain state say i would proceed by selecting the same transition say the transition towards state 9a irrespective of the time spent by the computation to reach state i. the adaptive execution supported by adam would instead select the transition towards state 9ain a scenario where state iis reached in 95s i.e.
crt 95s and select transition jin the case which state iis reachedin2s i.e.
crt 2s .
in the latter case with crt 2s the probability of success associated with outgoing transitions from state ichanges.
in particular by repeating the calculations illustrated in the previous section we obtain the following values p9a p9b andpj .
as a consequence the interpreter proceeds the execution by selecting transition j i.e.
the highest probability .
this choice is reasonable since the new context i.e.
2s indicates a slower execution.
in this situation the probability of success of the outgoing transitions 9aand9bdecreases making the option that skips the secondarywebsearch functionality i.e.
transition towards j preferable.
indeed skipping this functionality speeds up such slower executions minimizing the risk of violating r1.
conversely in faster executions transition jhas a lower probability of success because of its smaller contribution to usability w.r.t.
9aand9b.
the same adaptation mechanisms apply to all of the em non deterministic choices for example the choice between the gps and nps which require different execution times and offer different degrees of usability and energy consumption.
a traditional strategy to manage uncertainty consists of designing systems by explicitly programming alternative behaviors and by heavily using exception handling techniques to adapt the execution to the manifestations of uncertainty.
let us consider the case of the alternative implementations of the location functionality.
a traditional adaptive implementation would require engineers to write an ad hoc adaptation logic e.g.
cascaded if else s to choose between the two implementations and exception handling constructs aimed at managing the potential failures of both the alternatives.
such logic not only results in convoluted solutions but is also intertwined with the application logic yielding to code that is hard to read and maintain.
conversely adam applications do not require such adaptation logic see listing and delegate the adaptation management to the framework tools.
as a consequence of this simplification the implementations in the form of distinct annotated methods result in code that is easy to read write maintain and evolve.
furthermore adam also increases reusability since the same functionality implementations can be reused across different applications.
adam also offers another source of adaptation against uncertainty.
in section i we stated that adam not only manages non functional uncertainty in terms of higher response time but also handles unexpected faults.
indeed the system execution managed by the interpreter introduces a useful self healing feature in adam applications.
as soon as the interpreter catches a run time exception while invoking a functionality implementation it redirects the execution if possible towards another em path that allows the system to complete successfully.
for example if invoking the functionality associated with state 9athe interpreter catches an exception indicating that the underlying web service is unavailable it may backtrack the execution to the previous state i.e.
i and redirect the execution through an alternative path e.g.
9b .
even if this is a simple self healing mechanism it is useful to maximize the system reliability in many scenarios.
for39example in the mobile domain the gps may fail unexpectedly and the nps may be executed alternatively and transparently.
finally adam also achieves a clear separation among the different aspects of the application from the more abstract ones captured by activity diagrams to those closer to the technical domain captured by the implementations.
by relying on such sharp separation of concerns developers may first model the features they want to introduce in the system ignoring how they will be implemented later on.
let us consider again the location functionality of the sr application.
in the inception phase developers only focus on the fact the system needs such feature and connect it to the other features by relying on the activity diagram.
later on they can implement a first prototype that leverages nps and the manual input of the user realizing that this solution needs to be improved in terms of usability.
the applications may gradually evolve by adding other implementations for this feature e.g.
the gps .
this process in which the system design is decoupled from the implementation as enforced by the proposed approach is a widely recognized best practice in software engineering.
it is important to notice that the advantages provided by the adam approach are obtained transparently w.r.t.
to engineers who only have to produce one or more activity diagrams and their corresponding implementations.
even the complexity concerning the em and mdps is managed behind the scenes by the adam tools.
v. v alidating the approach adam is implemented a publicly available open source tool.6although our approach is general and applies with limited technological modifications to other languages we focused on the java language for our prototype.
in this section we discuss the validation of the adam approach focusing on its run time overhead and scalability.
the validation has been carried out by performing a large simulation campaign.
hereafter we report the most significant results and we refer the reader to our prototype implementation for the replicability of the presented data.
since adam requires additional runtime computation we start by discussing the overhead imposed to navigate and execute the model.
this includes the computation of the probabilities of success for each alternative.
we developed an application that automatically generates different models and we used the adam prototype to execute them.
to test its performance under different situations we varied the number of abstract functionalities that are part of the model and the number of alternative implementations bound to them.
finally we also varied the number of nonfunctional requirements present in the model to be satisfied during execution.
our evaluation was carried out on the following hardware setting i5 540m processor 4gb of ram ubuntu linux .
and oracle java runtime environment version .
.
.
moreover each of the experiments was repeated at least 30times.
the first experiment investigates the overhead imposed by adam to execute a simple model each abstract functionality is associated with a single implementation.
to calculate the overhead we compared an adam execution with an equivalent hard coded sequence of method calls to the same implementations.7we have varied the number of used abstract functionalities and consequently the number of method calls from 10to1000 .
the measured results are reported in figure a .
these results show that the way adam models are navigated and executed introduces a negligible overhead around .
for instance for a large model with abstract components the execution takes in average 65s while the java execution with the same number of method calls requires 06s.
to further investigate the overhead imposed by adam we extended the previous experiment as follows.
let us consider a base scenario with the following parameters 500abstract functionalities each with alternative implementations annotated with different impacts 6non functional requirements 3of which are threshold based and the remaining 3aremin max requirements.
figure b shows how the size of the model affects the overall execution time.
in this experiment we consider the base scenario increasing the size of the model from 10to .
note that these results differ from figure a because they include also the time to compute and choose the best alternative.
in general the experiments show an overhead of approximately which we still claim to be reasonable.
for instance for a large model of 500abstract functionalities the execution time increases from 06sto26 .
figure c shows the time required to execute an adam model in our base scenario with an increasing number of alternatives bound to each abstract functionality from 1to5.
note that we plotted with an horizontal black line the average time for the java execution.
even in the worst scenario in which we have 5alternatives for each abstract functionalities the overhead compared to the java execution reaches an acceptable value of .
consider that this testbed included a very large number of alternatives in total which is far from what we expect from a realistic application.
if we consider that we typically have two alternatives the average execution takes 83sinstead of 06s.
finally figure d shows instead how the execution time is affected in our base scenario by increasing in the number of requirements which we varied from 2to10.
note that the adam interpreter scales very smoothly allowing applications to add multiple requirements without decreasing the adam performance.
in general from the above assessment we may conclude that the adam approach is feasible and its use introduces an acceptable often negligible overhead in the execution time of the overall application especially when compared to the advantages as discussed in the section iv.
vi.
r elated works many existing works address the problem of uncertainty management and investigate adaptive software systems.
the requirements engineering community has been particularly 7all the methods have a default implementation which sleeps for 50ms.
a execution overhead.
b execution overhead increasing model size.
c execution overhead increasing number of alternatives.
d execution overhead increasing number of requirements.
fig.
.
adam overhead.
active w.r.t.
this research challenge .
for example relax a requirements language for adaptive systems explicitly addresses uncertainty by enabling engineers to capture uncertainty in the requirements definition.
differently from our approach relax achieves adaptation by relaxing non critical requirements instead of relying on alternative or optional functionalities as in the adam approach.
souza et al.
instead enable adaptation by conceiving systems in control loop in which a set of system parameters i.e.
variability points is tuned at run time to satisfy the system requirements.
finally wang et al.
describe a framework that exploits software variability and goal models to allow selfrepair in cases of failure.
from a model driven perspective we can mention and .
the former focuses on functional adaptations and investigates the adoption of aspect oriented programming to weave new system configurations together with run time models used to validate them.
the latter also exploits aspect oriented programming but focuses on nonfunctional properties of systems.
it describes a middleware for run time adaptation that chooses between alternative application variants.
in addition concerning the concept of embedded model we can mention the work by balz et al.
that describes an approach to embed full model semantics into source code.
in this case the ultimate goal of the authors is to support the synchronization between the model and the implementation.
this approach may be considered as an alternative solution to implement the adam concepts.
from an architectural viewpoint we may mention the foundational work on a three layer architecture for software adaptation described in which focuses mainly on functional adaptation.
cheng et al.
in investigate instead architecturebased adaptation through resource prediction that is similar to the non functional forecasts obtained via probabilistic modelchecking in adam even if at architecture level.
in addition concerning monitoring it is important to mention the work by ehlers et al.
that propose an approach to localize performance anomalies and enable adaptations through a rulebased expert system even if they focus only on response time.
in addition fleurey et al.
define the impact of features i.e.
functionalities as well as high level adaptation rules to choose among them according to the context and achieve an adaptive behavior.
in the same way floch et al.
adopt utility functions to determine which component implementation should be selected according to the context.
the work by ramirez et al.
represents instead an approach that may used to complement the adam solution.
indeed it allows the automatic discovery of combinations of environmental conditions that produce requirements violations and latent behaviors in an adaptive system.
such approach may be used in adam to support engineers in designing the alternative implementations needed to face the discovered environmental conditions.
all the mentioned approaches differ from adam in many aspects.
some of them for example do not consider non functional aspects.
others even if they focus on non functional adaptation do not offer the same degree of flexibility provided in adam that for example not only optimizes the non functional behavior of the system but also maximizes its reliability as described in section iv.
vii.
c onclusions and future work in this paper we presented adam a novel approach that supports the effective development and operation of adaptive systems.
to demonstrate its advantages we used the proposed approach to implement a realistic mobile application and we assessed the overhead introduced by the approach and its scalability by performing a simulation campaign.
in addition to41encourage the adoption of the proposed approach and to allow the replication of experiments the adam implementation has been released as an open source tool.
finally adam currently supports parallelism only in the implementation methods and not at the activity diagram level.
we plan to overcome this limitation in our future work.