code patterns for automatically validating requirements to code traces achraf ghabi johannes kepler university linz austria achraf.ghabi jku.atalexander egyed johannes kepler university linz austria alexander.egyed jku.at abstract traces between requirements and code reveal where requirements are implemented.
such traces are essential for code understanding and change management.
unfortunately trac es are known to be error prone.
this paper introduces a novel approach for validating requirements to code traces thro ugh calling relationships within the code.
as input the approa ch requires an executable system the corresponding requirements and the requirements to code traces that need validating.
as output the approach identifies likely incorrect or missing traces by investigating patterns of traces with cal ling relationships.
the empirical evaluation of four case study systems covering kloc and requirements demonstrates that the approach detects most errors with precision and recall and is able to handle traces of varying levels of correctness and completeness.
the approach is fully automated tool supported and scalable.
categories and subject descriptors d. .
software program verification statistical methods validation general terms algorithms measurement reliability verification keywords requirements traceability feature location validatio n .
introduction requirements to code traces reveal where a requirement is implemented in the code.
this is important for program comprehension and understanding change impact.
traces are most useful in cases where developers are not familiar with the source code a situation that likely occurs during maintenance.
it has been shown in several experiments that lack of understanding where a requirement is implemented leads to higher effort and more errors.
this is not permission to make digital or hard copies of all or part of thi s work for personal or classroom use is granted without fee provided th at copies are not made or distributed for profit or commercial advantage an d that copies bear this notice and the full citation on the first page.
to cop y otherwise to republish to post on servers or to redistribute to lists re quires prior specific permission and or a fee.
ase september essen germany copyright acm ... .
.surprising because in such a case a developer is more likely to perform changes at inappropriate places in the code accelerating code degradation.
capturing and main taining requirements to code traces is therefore mandate d by many standards such as cmmi level and software engineering techniques .
unfortunately capturing and maintaining traces is an erro rprone activity.
some automation exists but many approaches are not applicable to informal unstructured requirements which are common in practice.
the few techniques that do apply vary widely in quality and often require elaborate descriptions of requirements requirements depende ncies and or the code to deliver good results.
even if traces are captured by the original developers and are thus expected to be of good quality these traces may deteriorate over time as the system evolves.
trace maintenance counters this problem but as kong et al.
have shown manual trace maintenance is highly error prone and often made the quality of traces worse.
this paper introduces an automated tool supported approach for identifying errors among requirements to code traces by exploring patterns of traces and calling relation ships within the code i.e.
method or function .
for example a given method is likely implementing a given requirement if it is called or calls other methods that also implemen t the given requirement.
our approach thus computes a trace expectation for a given method by investigating the known traceability of neighboring methods callers and callees .
an error is reported if this expectation differs from the known trace of the given method.
as input our approach requires existing requirementsto code traces that need validation and a call graph reflec ting method function calls in the code.
the approach does not require special requirements descriptions nor knowled ge about requirement dependencies.
however the approach does assume the code to be of good quality i.e.
executable and testable for the given requirements though it is largel y immune to isolated code errors.
this assumption is realisti c because traceability is typically needed during maintenan ce where the code has stabilized.
to calibrate our approach we empirically evaluated it on four open source case study systems totaling over kloc and selected requirements.
we chose these systems because we had high quality requirement to code trace links provided by their develo pers.
the requirements were mostly functional and were often inter dependent cross cutting as is typical in pract ice.
the empirical validation of the calibration showed that our approach applies to about of the requirements to permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
ase september essen germany copyright acm ... .
code traces coverage and most of these traces are validated with correctness.
good performance on calibration data however does not necessarily imply our approach s ability to cope with traces of decreasing quality.
we thus performed an empirical study to understand the impact of input trace quality on the validation quality by organizing an elaborate experiment involving subjects who manually generated about requirements to code traces discussed the experiment in detail .
since the subjects were predominantly inexperienced students it ca n be assumed that this study led to traces of a wide range of qualities quite possibly the worst quality which is a desired property here because the evaluation showed that our approach was able to validate even these traces with high precision and recall.
while the quality of our approach does decrease with decreasing trace input quality and completeness this decrease is small correctness even if of the traces of a given requirement were incorrect .
the approach thus vastly outperforms the ability of humans which peaked around correctness .
also contrary to manual validation our approach s validation feedback become s increasingly better with increasing input trace input qual ity.
this paper is based on a short paper which appeared in ase using a similar data set.
the short paper demonstrated that code implementing a given requirement typically forms connected regions.
this paper builds on thi s foundation and provides an algorithm for trace validation and an empirical study testing the algorithm s ability to co pe with traces of varying levels of correctness and completene ss.
the goal of this paper is to describe an algorithm for validating requirements to code traces.
as input the algorit hm takes calling relationships in the code and a requirementsto code trace matrix rtm were the matrix cells represent the individual relationships between code methods functions and requirements.
as a result the algorithm produce s feedback on traces which are presumed incorrect or missing.
since the algorithm proposed in this work is not immune to varying input quality the goal of this paper is also to demonstrate that the quality of its feedback remains high with diminishing quality completeness of input rtms.
.
related work in last two decades multiple traceability techniques have been presented where different approaches are applied to retrieve and or maintain trace links between code and other software artifacts.
these approaches exploit either textu al characteristics static structures or dyna mic information of software artifacts.
each techniq ue analysed this information in order to provide a certain understanding to the implementation of different requirement s in the system.
there are also hybrid approaches that combine multiple technique types in one approach e.g.
cerberus .
usually these approaches deliver a ranked list of potential traces among the input software artifacts wher e higher ranked traces are presumed to be more correct traces .
calling relationships in particular have been used to impro ve the reported ranking of traces in information retrieval approaches .
multiple researchers investigated also the usefulness of traceability during software engineering.
traceability p rovides an important support for software engineering activities such as impact analysis reverse engineering and re gression testing.
but most proposed methods are relatedtable information on the four study systems vod chess gantt jhd language java java java java kloc .
.
executed methods sample reqs.
size of gold standard toautomatic trace generation atg .
they mainly aim to create or recover trace links from scratch.
different softwa re artifacts as well as derivatives thereof are expected as i nput.
the output would be a set of possible recognized trace links.
although the proposed methods are fully automated and tool supported a manual check must be performed in order to verify the quality of each technique.
the results of those methods are validated against a benchmark trace link knowledge base e.g.
gold standard rtm which was initially created manually.
if an atg method would be performed on a system without such a benchmark knowledge base we would never know how good the produced trace links are.
indeed the strongest motivation for our work comes from a study by kong et al.
who conducted an experiment about manual trace link maintenance.
as could be expected the effectiveness of trace maintenance is the quality of the fi nal rtm is influenced by the initial rtm.
they made a very interesting observation participants who validated rtms of poor quality tended to improve the rtm.
participants validating good quality rtms however made more errors than correct decisions during the maintenance of rtms making the accuracy of the input rtm worse.
based on that study we conclude that manually validating traces does not necessarily guarantee a better accuracy in the final rtm.
while the relationships between traces and calling relationships in the code have been explored in the past they have never been exploited together with potential ly erroneous traces for validation.
it is also noteworthy that our approach investigates each requirement s relationshi p to the source code independently of other requirements i.e.
unlike feature interactions technologies which are based o n cross cutting concerns concern graphs or concep t lattices .
.
case studies to validate our approach we investigated four software systems between kloc in size and randomly chosen requirements covering functional non functional and cr osscutting requirements .
the systems were videoondemand vod chess ganttproject and jhotdraw jhd and their basic characteristics are depicted in table .
we chose them because of the availability of high quality requirements tocode traces a gold standard provided by original developer s in case of the larger systems ganttproject and jhd or developers familiar with the code in case of the smaller systems vod and chess .
we used the gold standard to gain confidence that the patterns we identified were indeed likely or unlikely important for confirming or rejecting traces as will be discussed later .
we also used the gold standard for evaluating the quality of the reported errors generated whi le validating subject rtms to assess our approach s ability to cope with decreasing quality of the input rtm.
as is common we represent traces in form of requirements trace matrices rtm .
each rtm contains m n201table excerpt of rtm from chess system method requirement r1 play move r2 show score addplay x x afterplay doplay x droppiece getpiece getindex x x initpiece initpos setcolor setpiece x cells where mis the number of requirements and nis the number of code elements methods in this case .
table depicts an excerpt of such a rtm for the chess system.
a cell is either a trace x or a no trace blank .
a trace in a cell implies that the given code element row implements the given requirement column .
a no trace in a cell implies that the code element is not implementing the requirement.
we refer to a trace also by the abbreviation t and to a notrace by the abbreviation n .
note that a rtm may also be incomplete if rows code or columns requirements are missing.
as was mentioned in the introduction our approach uses calling relationships among code elements to help validate the correctness of the given requirements to code traces.
there are standard tools available for recording execution logs d uring program execution.
for example the java jdk provides an easy and reliable interface for recording method calls at runtime.
we used this interface to record the calling relationships while each system was being tested.
each system was tested according to use case descriptions of the gold standards.
but the testing was not limited to the sample requirements nor was it attempted to test the requirements individually to avoid any bias towards particular requirements.
the use of the java jdk ensures that there are no false calling relationships however incomplete testing may result in missing calling relationships.
the implications of this will be discussed later in more detail.
the nodes in the resulting call graph represent individual classes methods or functions depending on the level o f granularity chosen.
in this work we focus on methods only but our approach should be applicable to non oo languages e.g.
functions in c as well as coarser granularity class es or packages .
figure depicts a small excerpt of the call graph for the chess system.
the nodes are labeled with method names and for brevity the figure depicts those listed in the rtm in table only.
the edges in the call graph represent the method calls.
these edges are directed arrows to distinguish the caller and the callee .
for example since method getpiece calls method initpiece the node corresponding togetpiece has a directed arrow to the node corresponding toinitpiece .
we say that getpiece is a caller of initpiece and in reverse that initpiece is a callee of getpiece .
note that there is exactly one node for every method.
we thus use the terms node and method synonymously in the paper.
.
patterns and algorithms we found that methods implementing a given requirement are very likely to call one another forming regions of connected methods.
these regions may vary in size and may also overlap if their corresponding requirements ar egetindex afterplay doplay getpiece initpiece initpos setpiece addplay setcolor ......... ... ...droppiece figure modified excerpt of call graph from the chess system r1 region highlighted in gray implemented in close proximity or depend on one another.
our approach to trace validation exploits these regions.
.
principles figure shows an example of a region gray area .
the region identifies all methods nodes that trace to requiremen t r1 of the illustrative chess system note that the methods inside the gray area are defined to trace to r1 in the rtm in table .
the surrounding area represents the methods that do not trace to that requirement.
we see that the nodes in the region are generally connected directly or indirectl y though it is not uncommon to have multiple regions also.
to understand the principles of trace validation let us now assume the existence of an incorrect trace.
obviously an incorrect trace false t may only exist in an area outside the region all methods inside the region are correct t s .
if that false t exists far off the region then it is ful ly surrounded by methods that all do not trace to the given requirement.
a method that is labeled as tracing to a given requirement in the input rtm but is being surrounded by methods that do not trace to that requirement thus indicates an erroneous trace with a high likelihood of correctne ss.
take for example the method droppiece .
this method does not trace to r1.
however if it were falsely labeled as tracing to r1 in the input rtm then it would form its own mini region and be surrounded by methods that do not trace to r1.
our approach would identify this method as an erroneous trace because it would be disconnected from a larger requirements region which is counter to the observation in .
let us next assume the existence a missing trace a false n .
a missing trace is a method that is currently marked as not tracing to a given requirement but should be tracing.
a false n may only exist inside the region all methods outsi de the region are correct n s .
if that false n is surrounded by methods that trace to the given requirement then this indicates a missing trace with a high likelihood of correctness.
listing trace validation v a l i d a t e c e l l rtmcell c expect getexpectation c .
method c .
req i f c .
value expect .
value return correct else return error algorithm depicts the simple principle behind trace validation.
each cell of the rtm is investigated separately where each cell represents the traceability between exactl y one method and one requirement.
the algorithm then computes an expected trace for that cell which is based on the202caller method any callee methodrequirement no trace calls callsno tracecaller method any callee methodrequirement trace calls callstrace where caller callee any figure t any t and n any n patterns traceability of the neighboring methods.
while the neighbo ring methods are the same for all cells in a row their expectations may differ because they are investigated in context of different requirements.
the complexity of trace validation is thus in computing an expectation which is discussed next.
.
t and n surrounding patterns the notion of surroundedness forms the basis for understanding expectation.
there are two primary patterns the t any t pattern depicted in figure top applies to any method that has at least one caller method the anymethod is called by the caller method and at least one callee method the anymethod calls this callee method where both the caller and callee trace t to a same given requirement.
not e that the anymethod represents an arbitrary method.
the n any n pattern depicted in figure bottom is simply the negation in terms of traceability.
it applies to a ny method that has at least one caller method and at least one callee method that both do not trace to a given requirement.
figure depicts an excerpt of the chess system introduced earlier that combines the call graph with the input rtm.
for example we know from the call graph that afterplay calls doplay and we know from the input rtm that afterplay does not implement requirement r1 while doplay does.
this is depicted in the graph where thick arrows denote calling re lationships thin solid arrows denote trace relationship s and thin dashed arrows denote no trace relationships.
we can identify a t any t pattern for method setpiece validated on requirement r1 because it is called by doplay and calls getindex which both trace to requirement r1.
similarly we can identify a n any n pattern for method doplay validated on requirement r2 because afterplay andsetpiece do not trace to r2.
we thus expect that setpiece traces to requirement r1 and we expect that doplay does not trace to requirement r2.
for trace validation we simply compare these expected values with the their corresponding cell values in the input rtm.
consulting table we find that our expectations are consistent with the actual cell values in both cases and thu s our approach would confirm the correctness of these two input rtm cells.
note that neither the t any t pattern nor the n any n pattern used the trace information of the any method.
the patterns merely used the trace information of the surrounding methods.
the expected value computed through these patterns is thus derived without knowledge of the traceability of the cell being validated.
the t any t pattern expects a likely trace whereas the n any n pattern expects an unlikely trace or a likely notrace .
this is useful for trace validation to confirm or reject a trace.
however as is common in traceability research there are exceptions to their validity and below we will discuss some of these cases.
it should be noted that we investigated more elaborate patterns such as the anymethodafterplay doplay setpiece getindex r1 play move r2 show scoretrace no trace calls calls calls figure surrounding patterns in chess caller anyt trace calls callstrace anyt no trace calls callsno trace where s caller caller any figure t t any and n n any patterns having at least two callers and callees and such patterns improve the quality.
however we also found that more elaborate patterns are much less likely to be applicable there are comparatively few methods that have two callers and callees with the same trace than compared to single callers and callees .
more elaborate patterns are thus little helpful in improving the overall quality.
we will see later that a far greater effect can be achieved by combining the simple t any t and n any n patterns into more elaborate structures.
.
inner leaf and root methods the t any t and n any n patterns are useful only for methods that have both caller s and callee s .
we refer to such methods as inner methods inner nodes in the call graph .
unfortunately many methods do not call other methods so called leaf methods which are leaf nodes in the call graph.
in figure an example of such a leaf method is setcolor .
in context of the four case study systems roughly half the methods are leaf methods.
in the absence of a callee method we define two additional patterns depicted in figure .
the t t any pattern implies a likely trace if the given method has a caller that traces to a given requirement and this caller has in turn a caller that also traces to the given requirement.
the n n any pattern is the opposite and implies an unlikely trace or a likely no trace .
a call graph usually has root methods also but they are rare.
indeed all four case studies had few root methods each the java main method is always one of them often it is the only one.
other roots are typically methods startin g separate threads e.g.
thread.start .
root patterns and their treatment are analogous to leaf patterns.
since root methods are rare they are of little significance and will be ignored in the remainder of this work.
.
boundary patterns the inner method and leaf method patterns t any t n any n t t any and n n any are not applicable to all methods.
as was discussed earlier requirement regions have boundaries where a method not implementing a given requirement calls a method implementing it or vice versa.
we find such boundary cases in figure where for example method doplay implements requirement r1 and calls setpiece which implements the same requirement but it is203r1 play move r2 show scoretraceno trace figure mixed and pure patterns in chess called by method afterplay which does not implement r1.
we can think of such methods as entry and or exit points to from regions.
we speak of a boundary pattern for inner methods having a caller that traces to a given requirement while none of the callees do t any n or in reverse having a callee that traces to a given requirements while none of the callers do n any t .
leaf methods having a caller that traces to a given requirement while none of the caller s caller trace to the given requirement n t any or as having no caller that trace to the given requirement while at least one caller s caller does t n any .
the expected values of t and n surrounding patterns t any t and n any n are intuitive to understand the anymethod in a t surrounding is expected to have a trace t link the anymethod in a n surrounding is expected to have a no trace n link.
but this simple intuition does not work for boundary patterns.
indeed empirical observation s discussed later show that the likelihoods of anyboundary method tracing to the requirements vs. not tracing to that requirement is roughly or random.
since it is not useful to make random guesses it may appear that boundary methods are failure scenarios where our approach fails to compute a useful expected value.
but even here our approach does not necessarily fail as will be discussed next .
.
combinations pure and mixed patterns thus far we discussed patterns in isolation.
however these patterns often occur together.
figure illustrates s uch cases in context of the chess system.
this figure is analogous to figure but involves more methods.
in context of requirement r1 the n any n pattern can be found through a pattern involving the afterplay doplay any and getpiece methods.
this pattern expects that the doplay method does not trace to requirement r1.
additionally the n any t boundary pattern can be found through a pattern involvingafterplay doplay any and setpiece methods.
this boundary pattern suggests that it is not decidable whether doplay traces to requirement r1.
the method doplay is thus involved in a n surrounding pattern and a border pattern at the same time.
if multiple patterns can be matched on the given method any then one of two situations applies pure patterns all patterns are of the same kind.
for example in context of requirement r2 the doplay method is involved with two n surrounding patterns one is found with afterplay andsetpiece and another with afterplay and getpiece .
mixed patterns the patterns are of different kinds.
for example method doplay is involved in a mixed pattern with r1 as was discussed above.
the combined meaning of pure patterns are simple to decide multiple t any t patterns re confirm a likely trace multiple n any n re confirm an unlikely trace.
pure patterns are quite advantageous because in combination their likelihoods increase making them more reliable patterns f or trace validation.
e.g.
the empirical validation discusse d latter confirmed that if any method has two or more t any t patterns applying than the method is more likely to trace than compared to a method with a single t any t pattern.
mixed patterns however require further elaboration.
.
trace no trace over boundary dominance a boundary pattern implies that it is not possible to decide on a likely or unlikely trace.
therefore if a boundary pattern is found in combination with a likely pattern t any t or t t any or an unlikely pattern n any n or n n any then the likely unlikely patterns dominate and we ignore the existence of the boundary pattern.
we define dominate as meaning that say in case the t any t pattern applies to the same method any and requirement this method is likely to trace to r ignoring the boundary pattern.
this was confirmed through the empirical evaluation of the four case study systems and their gold standards as will be discussed later.
most boundary patterns are ignored in this manner.
only if all patterns applying to a method are boundary patterns a pure boundary pattern so to speak then we truly cannot decide whether the method is expected to trace or expected to not trace to the given requirement.
we will see later that our approach fails in a small percentage of rtm cells only.
.
trace over no trace dominance but what if a likely trace pattern t any t occurs together with an unlikely trace pattern n any n ?
it is common for the t any t and n any n patterns to occur together.
this happens when on each side caller and callee of a method there are at least one method that traces to a given requirement and another that does not.
figure depicts such an example for setpiece .
the t any t pattern involving doplay and getindex suggests that setpiece traces to requirement r1.
the n any n pattern involving initpos and setcolor clearly suggests the opposite.
this apparent conflict is the result of cross cutting requir ements and or feature interactions.
in such cases the code serves a purpose that supports a trace and another purpose that does not.
indeed trace no trace conflicts of this kind are common in all four study systems and upon empirically evaluating this issue on their respective gold standards w e observed that in such cases the t any t pattern dominates the n any n pattern.
the rationale for this empirical observation has to be seen in the context of granularity.
it is said that if some code traces to a given requirement then this code implements the requirement either in part or full.
traceability is rarely e xclusive and it is implicitly understood that the code may als o implement other requirements.
for example in the context of java class even if only few methods of a class implement a given requirement then we say nonetheless that the class implements that requirement.
hence trace dominates notrace.
.
algorithm for computing expectation considering above discussion a concise mechanism emerges that helps us decide whether anymethod is expected to trace or expected not to trace to a given requirement or cannot be decided upon fail .
algorithm depicts the mechanism for computing the expected values of inner methods.
we use a counting scheme because it is very efficient to execute compared to pattern matching algorithms.
four variables are used callert identifies the number of callers of the input method that trace to the given requirement r callern identifies the callers that do not trace to r calleet identifies the number of callees that trace to r and calleen identifies the number of callees that do not trace to r. since this algorithm is called only for inner classes we know that there must be callers and callees.
listing get expectation for a given inner method and requirement getinnerexpectation method m requirement r cal l er t m. c a l l e r tr aci ng to r cal l er n m. c a l l e r not tr aci ng to r cal l eet m. c a l l e e tr aci ng to r calleen m. c a l l e e not tr aci ng to r i f cal l er t cal l eet i f cal l er n calleen return trace pure return trace mixed else i f cal l er n calleen i f cal l er t cal l eet return notrace pure return notrace mixed return fail boundary the algorithm shows that a given method is expected to trace to a given requirement if at least one caller method traces to the requirement callert and at least one callee method traces to the given requirement calleet .
if the trace is a pure trace then there also should be no caller and no callee methods that do not trace to the given requirement callern calleen .
the algorithm thus returns either pure or mixed trace depending on the outcome.
similarly the algorithm shows that a method is expected to not trace to a given requirement if both callern and calleen are greater than zero i.e.. n surrounding .
the t over n dominance is implied in the order of the ifs trace checking before no trace checking .
note that at the time of no trace checking it is no longer possible that both caller s and callees trace to the given requirement.
however it is still possible that either caller or callee traces to a requi rement.
this allows us to distinguish a pure no trace from a mixed no trace note that the mixed no trace is essentially the n over boundary dominance .
all other situations are failure scenarios i.e.
pure boundary patterns .
as mentioned earlier the algorithm distinguishes pure from mixe d patterns and leaf from inner methods because the likelihood s of correctness are different.
this is discussed below.
not de picted is the algorithm for computing the expected values fo r leaf methods because it is essentially identical if we assum e the variable calleet to stand for callers callers that tra ce to the given requirement and calleen to stand for callers callers that do not trace.
.
expectations for incomplete rtms the rtm in table is complete because it identifies for every cell whether it traces or does not trace to a givenrequirement.
however we believe that it is useful to distinguish defined traces no traces from undefined traces in completeness .
since to date very little work is available f or maintaining traces it is not a common practice to provide partially complete rtms.
however we believe that developers may want to start validating rtms even at times where the rtms are not yet fully captured.
thus trace maintenance ought to apply to incomplete rtms also.
our approach allows for arbitrary cells to be left undefined u .
undefined cells cannot be validated because the expected value cannot contradict or confirm an undefined cell.
at best the expected value could be used for auto completion.
however undefined cells obstruct the validation of other cells.
the following defines what happens if a pattern encounters an undefined cell.
listing get expectation for a given inner method and requirement with incompleteness getinnerexpectation method m requirement r .
.
.
cal l er u m. c a l l e r with undefined tr aces to r calleeu m. c a l l e e with undefined tr aces to r i f cal l er t cal l eet i f cal l er n calleen cal l er u calleeu return trace pure return trace mixed else i f cal l er n calleen i f cal l er t cal l eet cal l er u calleeu return notrace pure i f cal l er u calleeu return fail incomplete return notrace mixed else i f cal l er u calleeu return fail incomplete return fail boundary algorithm expands on algorithm .
for brevity we again restrict this discussion to inner methods.
as was discussed above the leaf methods are handled analogously.
the algorithm introduces two more variables to reflect the number of undefined callers and callees calleru identifies the number of calling methods that have undefined traces and calleeu identifies the number of callee methods with undefined traces.
to understand algorithm we must understand that an undefined cell is a placeholder for either a trac e or a no trace we just do not know yet.
the implication of an undefined trace is thus explored by considering both possible interpretations.
for example algorithm has an a lternative fail scenario at the end.
the last else if statem ent is reached only when all caller methods and all callee methods have undefined traces to a given requirement pure and mixed scenarios are addressed by earlier statements .
the method may thus trace to the requirement if the undefined traces are eventually changed to traces the method may not trace if the undefined traces are eventually changed to no traces or we may even fail to compute an expectation for the undefined traces if the traces resolve to a boundary pattern .
anything is possible.
our approach reports this problem as failure to compute an expectation due to incompleteness.
note that this failure is a factor of the com pleteness of the input and not a limitation of the approach as in boundary patterns and thus we distinguish boundary from incompleteness failure.
a more complete input would fix this failure.205the existence of undefined traces does not always lead to failure to compute an expectation.
let us assume that the rtm cell for getpiece and requirement r2 is undefined in table .
the cell getpiece cannot be validated however the cell for its neighboring method doplay can recall figure but assume that there exists no no trace edge between getpiece and r2 .
during the validation of method doplay on requirement r2 we find a n any n pattern involving methods afterplay doplay and setpiece .
however no patterns apply to the methods afterplay doplay and getpiece because the trace for getpiece is undefined.
method getpiece may either trace to requirement r2 or it may not.
if it were to trace then methods afterplay doplay and getpiece would form a n any t boundary pattern.
we know that the n any n pattern above would dominate this boundary pattern and hence we would expect that doplay does not trace to r2.
if method getpiece were not to trace to r2 then methods afterplay doplay andgetpiece would form another n any n pattern which would reconfirm the other one and we would also expect that doplay does not trace to r2.
therefore no matter how the undefined trace is eventually resolved we expect that doplay does not trace to r2.
knowing about the undefined trace would only influence our certainty about the expectation but not the expectation itself.
reasoning in the presence of incomplete input rtms is thus possible.
algorithm in listing thus also expands on the pure mixed trace no trace computation.
for example we see that a no trace expectation may lead to an incompleteness failure only if both calleru and calleeu are greater than zero.
in the case ofdoplay calleeu is not zero and hence the algorithm returns a mixed no trace.
pure trace no trace patterns are found only if calleru and calleeu are zero.
.
algorithm for validation based on the mechanism for computing an expectation for a given method and requirement trace validation is quite trivial.
algorithm expands on algorithm we introduced earlier.
it iterates over every rtm cell and the validation algorithm is composed of two parts to compute an expectation via getexpectation and to compare the expectation with the actual rtm value via validatecell .
the getexpectation algorithm distinguishes between inner nodes and leaf nodes.
note that the algorithm for computing expectations of incomplete rtm cells algorithm subsumes the earlier algorithm .
the expectation returned by it is a tuple containing the value trace no trace fail and the category missing boundary incomplete pure mixed .
the value of the expectation is then compared to the value of the rtm cell.
if the expected value matches the current value then the cell is presumed correct.
otherwise it is tagged as erroneous.
if the computation of the expectation fails then this is reported as a warning.
a warning implies that the rtm cell could not be validated automatically and requires manual checking.
since we can establish the category of a cell pure or mixed trace no trace it is possible to order the error fee dback based on the different likelihoods associated with the categories discussed next.
it is noteworthy that the algorithm is also able to detect missing calls or dead code if the code has neither callers nor callees see fail missing ingetexpectation .
cells that are not called or do not call cannot be validated by our approach.
however this fail sce nario is a factor of the input and not a characteristic of the approach.
in the most extreme case no call graph is given as input in which case no method can be validated.
we will discuss in threats to validity why smaller numbers of missin g calls are unlikely to strongly influence our algorithm.
listing validation algorithm v a l i d a t e c e l l rtmcell c expect getexpectation c .
method c .
req i f expect .
value fail or c .
value undefinded return warning expect .
category else i f c .
value expect .
value return correct expect .
category else return error expect .
category getexpectation method m requirement r i f isinnermethod m return getinnerexpectation m r else i f isleafmethod m return getleafexpectation m r return fail missing .
likelihoods on gold standard section .
claimed in several places that our understanding of the adequacy of the introduced patterns is based on empirical data on four case study systems.
we can think of this as a calibration step to understand the performance of our approach under ideal circumstances ideal because the gold standards are of good quality .
this performance is expected to decrease as the quality of the rtm decreases.
this is explored in the evaluation section later.
we investigated each category fail mixed and pure for trace and no trace in terms of correctness and coverage.
table depicts our findings.
the coverage represents the percentage of the cells that fall into a given category.
the percentages for coverage add up to for the entire rtm.
the correctness refers to the likelihood of our algorithm va lidating a cell of its respective category correctly e.g.
i dentifying an incorrect no trace or trace in the rtm .
this data is based on the gold standards of the four cases study systems.
as was already suggested earlier the likelihoods diff er depending on category and system.
by considering combinations of patterns and dominance we see that many cells are validated with high likelihoods of correctness.
for exa mple line n pure in table depicts the correctness and coverage for pure no trace cells which are cells where on ly n any n patterns are found.
we see that our approach is likely to correctly validate such cells and of all rtm cells fall into this category.
pure trace cells are also validated with high correctness line .
the correctness is a bit lower for mixed traces and mixed no traces however do note that these kinds of cells are encountered less often only of all cells are mixed traces .
the lower likelihoods of correctness thus do not affect the overa ll performance strongly however the qualities are still hig h compared to manual trace validation.
as was discussed the approach fails for pure boundary methods and only of inner methods and of leaf methods fall into this category.
this is a low percentage and implies that our algorithm is able to validate most rtm cells.
to summarize this figure table provides overall precision and recall number s 206table coverage cov.
correctness cor.
cor.
cov.
cor.
cov.
cor.
cov.
cor.
cov.
fail n.a n.a n.a n.a n mixed t mixed n pure t pure fail n.a n.a n.a n.a n mixed t mixed n pure t pure chess gantt jhotdraw vod leafinner table precision recall on gold standard vod chess gantt jhotdraw precision .
.
.
.
recall .
.
.
.
p recision correctly v alidated cells v alidated cells correctly incorrectly recall correctly v alidated cells correctly v alidated cells f ailed cells precision reflects the ratio of correctly validated cells of totally validated cells including wrong validation .
rec all reflects the number of cells that our approach failed to validate compared to the ones it correctly validated i.e.
miss ing validations .
we see that both precision and recall are very high mainly because pure trace no trace situations are ve ry common.
.
evaluation in this section we demonstrate the ability of our approach to validate rtms of arbitrary quality.
.
precision and recall on erroneous rtms considering the nature of our patterns a random error in the rtm is easily identifiable because our algorithm fails only in case of a coordinated set of errors i.e.
to change a likely trace to an unlikely trace for a given method and requirement requires all caller and callee t s to be chang ed to n s an unlikely scenario.
however are rtm errors random or are these errors concentrated in certain areas of the code which increases the chances of a coordinated error?
we thus conducted an experiment where subjects were asked to identify the traceability for the larger two system s in our study gantt and jhotdraw.
the subjects had to inspect the code and then provide traces.
due to the effort involved each subject typically investigated a part of the original rtm.
we then obtained a wide spread of rtm qualities by seeding the gold standard with a variable number of subject traces.
the worst rtm we validated included the errors from all subjects combined.
this process reflects industrial practice where traces are often captured by multip le developers and are thus expected to have mixed qualities.
we validated the combined rtms using our algorithm.
the validation results were compared to the gold standards to test the level of correctness of the feedback computed by the algorithm.
we measured this feedback in terms of precision and recall introduced above and figure depicts the precision and recall in relationship to the percentage o f80 s ubject e r rors seeded jhotdraw precision jhotdraw recall gantt precision gantt recall figure precision and recall decreasing slightly with increasing erroneous rtms errors introduced by the subjects relative to the gold stan dard .
since the traceability literature usually attribut es errors relative to the correct number of traces the x axis o f the figure reflects erroneous and missing traces relative t o the total number of traces.
for example if a requirement traces to methods then error implies that the traces of of these methods were either missing a no trace instead of a trace or wrong a trace instead of a no trace .
the figure combines all cells of a rtm and hence combines all requirements tested.
there were some variations among the requirements but all requirements we tested behaved similarly.
our observation on both gantt and jhotdraw is that precision and recall were slightly affected by subject errors.
t he quality fell by less than in the worst case.
note that this data is based on the validation of over cells with human generated tracing errors among the nearly subject traces which also explains the difference between the maximum number of errors seeded for jhotdraw about and the maximum number of errors seeded for gantt about .
the seeded erroneous traces are arbitrary distributed over both systems.
this demonstrates that our approach remains useful in rtms of varying qualities.
.
precision and recall on incomplete rtm traditionally rtms are presumed to be complete because most applications of traceability require this.
yet we see trace validation as an ongoing process that must not necessarily start with a complete rtm but could also start at a time where traceability knowledge is only partially avail able.
our approach works for both complete and incomplete rtms as was discussed earlier.
this section investigates th e impact of incompleteness onto trace validation quality.
figure depicts precision and recall with increasing incompleteness of the input rtm.
the incompleteness of the rtm designates commonly the number of cells which are not yet traced.
these cells could be randomly distributed in the rtm aligned in a row when a method has not been traced or aligned in a column when a requirement has not been traced.
since there are no studies available on how and why traces are incomplete and since the subjects chose not to leave cells incomplete either we resorted to random seeding to evaluate incompleteness i.e.
removing random cells from gold standard .
for example at incompleteness half the input rtm cells are undefined i.e.
u and the other half is validated.
the algorithm generating expectations for incomplete input see listing isolates the cells which are affected by in completeness under the category fail incomplete .
the increasing number of undefined cells will thus increase the total number of cells for which our validation algorithm se e listing would report a warning and can not validate207figure precision is unaffected by incompleteness.
recall falls linearly only with level of incompleteness them.
considering the precision and recall formulas presented in section .
we deduce that the increasing fail cells due to incompleteness will only decrease the recall b ut do not affect the precision which is clearly visible in figur e where only the recall is falling linearly but the precision is largely unaffected by the increasing incompleteness.
thi s implies that the correctness of the approach remains high even in the presence of incompleteness.
.
scalability our approach is fully automated and tool supported.
the computational overhead is linear with the size of the rtm with the largest rtm requiring less than minutes validation time.
most of the runtime was required for parsing the execution log to build the call graph which is usually performed only once when the data is loaded the first time.
the actual validation algorithm needed less than ms in all cases studies since the validation algorithm is based on a rather simple but effective counting scheme for computing expectations out of the surrounding traces.
recall sectio n .
.
further details about the tool used in this study may be found under .
.
threats to validity we used four systems of different domains see table with rtms of different sizes.
each cell in a rtm was validated separately and this large number of cells makes our findings statistically representative.
to assess precisio n and recall we relied on a gold standard provided by the original developers of the study systems.
the gold standard was probably not perfect.
however given that it requires a coordinated set of errors to fool our patterns and given that so many patterns were validated the patterns exhibited the roughly same effects on all four study systems and the study systems were independently developed by different people who did not know each other leaves us to conclude that the studies are representative.
however we can see two situations where our algorithm would fail a requirement being implemented in very few methods only or the methods implementing a requirement being not connected no calling relationships .
as to point a requirement that is implemented in a single method only would appear like an erroneous trace because it would be surrounded by methods that do not trace n surrounding .
however it is possible to detect such situations in advance by investigating the input rtm.
our algorithm should not be used on such requirements but we believe such cases to be rare.
as to point if the methods implementing a requirement were not connected then they would also be detected as erroneous traces because each method would be n surrounded.
however connectedness was confirmed on all requirements we investigated covering four diverse cas estudy systems.
most of these requirements were functional however the jhotdraw system also had non functional requirements.
although we are not claiming that these requirements are of all possible types we believe that they are representative as they were selected and traced by independent developers of each system.
while the issue of connectedness warrants further investigation at present it appears to be a reasonable assumption for most situations.
like point a problem with the connectedness could be detected by investigating the input rtm.
this work presumed that the input call graph was reasonably correct and complete.
unfortunately both assumptions might be unsatisfied under certain circumstances.
on the one hand incorrect calling relationships could be caused b y undetected bugs in the code.
our assumption is that the code is of reasonably good quality since trace validation is most relevant during software maintenance where typicall y a mature code base exists.
still isolated bugs may exist.
but in order to affect our reasoning two surrounding calling relationships should be reverted to the wrong kind of traces i.e.
t surrounding pattern to n surrounding patte rn or vice versa .
in other words the very nature of our patterns makes it unlikely that isolated code errors significan tly influence the quality of the approach.
on the other hand incompleteness in the call graph relationship is more likel y when using dynamic call graphs as in our case.
yet the level of completeness is measurable through metrics that as sess the test coverage e.g.
branch coverage tests .
even if the call graph is incomplete certain patterns would be unaffected.
for example a t surrounding pattern can never become an n surrounding pattern with more calling relation ships.
static call graph may be an alternative that does not require a running system but with a down side that we would have to deal with both incomplete e.g.
polymorphism and incorrect e.g.
dead code code relationships.
finally our work used homogeneous levels of granularity methods in call graphs and rtms.
we presume that our approach would perform similarly on other homogeneous levels of granularity e.g.
statements or classes though the likelihoods would presumably be different.
this assumption will be assessed in future work.
in summary we believe that there is no significant threat to the internal validity and the data experiments were diverse enough to imply more general applicability hence we see no major threat to the external validity either.
the only uncertainty was our evaluation on incompleteness where we used random seeding.
this may not have been appropriate however we were unable to find any literature that characterized incompleteness and believe this to be mostly an organizational issue that from an outsider s perspective appears random.
.
conclusion this paper represents an important step towards improving traceability automation because state of the art pre dominantly focused on recovering requirement to code trace l inks but not maintaining them.
since automated trace recovery or recovery done by subjects not familiar with the code rarely exceeds correctness we believe that traces shou ld be captured early on by subjects familiar with the system.
however these traces then need to be maintained like other development artifacts with the system.
this paper demonstrates a novel approach to maintaining requirements to 208code traces by validating them in context of code calling relationships.
we introduced an algorithm that computes trace expectations based on likely and unlikely patterns an d then compares them with the given traces.
errors are detected whenever the given traces differ from the expected traces.
empirical evaluation on over of rtm cells have shown that the error feedback produced by our approach is of high precision and recall and the quality of the feedback being lightly affected by the quality of the given traces only.
the approach scales is fully automated and tool support is provided.
the approach applies to functiona l and non functional requirements whether they be independent or cross cutting.
.