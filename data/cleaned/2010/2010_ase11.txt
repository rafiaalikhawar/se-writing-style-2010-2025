prioritizing tests for fault localization through ambiguity group reduction alberto gonzalez sanchez1rui abreu2hans gerhard gross1arjan j.c. van gemund1 1delft university of technology software technology department mekelweg cd delft the netherlands email fa.gonzalezsanchez h.g.gross a.j.c.vangemund g tudelft.nl 2university of porto departament of informatics engineering rua dr. roberto frias porto portugal email rui computer.org abstract in practically all development processes regression tests are used to detect the presence of faults after a modification.
if faults are detected a fault localization algorithm can be used to reduce the manual inspection cost.
however while using test case prioritization to enhance the rate of fault detection of the test suite e.g.
statement coverage the diagnostic information gain per test is not optimal which results in needless inspection cost during diagnosis.
we present r aptor a test prioritization algorithm for fault localization based on reducing the similarity between statement execution patterns as the testing progresses.
unlike previous diagnostic prioritization algorithms r aptor does not require false negative information and is much less complex.
experimental results from the software infrastructure repository s benchmarks show that r aptor is the best technique under realistic conditions with average cost reductions of with respect to the next best technique with negligible impact on fault detection capability.
i. i ntroduction regression testing is a time consuming but rather important task for improving software reliability after a software change.
literature shows how source code changes are bound to introduce regressions in up to a of cases .
given the significant cost associated with regression tests test prioritizationhas emerged as a predominant technique to reduce testing cost.
prioritized regression test suites aim at detecting failures as soon as possible in order to reduce testing effort ct .
the sooner failures are found the sooner debugging can commence.
automatic fault localization techniques use the information obtained during regression testing e.g.
test coverage and failure information to produce a ranking of source code statements likely to be the root cause of the observed failures.
this ranking is used to minimize the diagnostic work the developer has to perform when inspecting the program to find the faults inspection cost cd .
previous work in the combination of test prioritization and diagnosis has shown that while traditionalprioritization techniques minimize ctby merely reducing the delay between testing and debugging they do not maximize diagnostic information and therefore increase inspection effort cd.
the reason is that traditional test prioritization aims at high code coverage whereas obtaining a refined diagnosis requires partially revisiting already covered code to further exonerate or indict suspect statements.
in order to minimize overall cost one must consider a test prioritization strategy that takes into account the combined cost of testing and debugging ct cd1.
recently a diagnostic test prioritization technique i.e.
test prioritization technique that maximizes the diagnostic information gain per test has been proposed to solve this problem.
the current approach to diagnostic test prioritization is based on the information gain heuristic ig .
although in theory its diagnostic effectiveness is optimal it does have a number of drawbacks that restrict its applicability in practice.
first its performance depends heavily on the precise estimation of a number of parameters fault density and false negative test rate that are very expensive to obtain as well as very error prone.
this has been shown to severely impact on the quality of the ig heuristic .
second the algorithmic complexity of ig is exponential due to the fact that more than one fault may be present in the system.
finally unlike traditional test prioritization techniques in ig based diagnostic test prioritization the tests are selected on line based on the actual pass fail results of previously executed tests which varies per regression cycle .
on line calculations impose a large overhead in the test process if test cases are relatively short.
in this paper we introduce a novel off line diagnostic test prioritization algorithm that solves the above problems.
in particular our paper makes the following contributions we present r aptor greedy diagnostic prioritization by ambiguity group reduction a low complexity diagnostic test prioritization algorithm that can be used 1the addition is not necessarily arithmetic as inspection cost typically involves labor by the diagnosticianoff line which does not require any additional input parameters and can consider variance in test costs.
we evaluate the performance of r aptor for the siemens set as well as for larger programs available from the software infrastructure repository sir .
all programs are extended to accommodate multiple faults.
in the above experiments we compare the performance of raptor to the contemporary test prioritization algorithms addst fep art the ig based diagnostic test prioritization algorithm s equoia and to random prioritization rnd our baseline.
to the best of our knowledge a diagnostic approach to off line test prioritization has not been described before.
our results show that r aptor can deliver a performance in terms of inspection cost reduction per unit of test cost superior to addst fep art and rnd and in some cases even to the theoretical optimum s equoia .
improvements are on average better with respect to the next best technique and better than the baseline rnd .
the paper is organized as follows.
in the next section we present the basic idea behind diagnostic prioritization.
in section iii we present related prioritization and diagnosis techniques.
in section iv r aptor is presented.
in section v we present experimental performance results.
section vi discusses these results and the threats to their validity.
related work is discussed in section vii.
in section viii we conclude and discuss future work.
ii.
d iagnostic prioritization before going into the specific details of our diagnostic prioritization algorithm we first explain why traditional test prioritization conflicts with the goal of fault localization.
let us consider the faulty program in table i. we provide a test suite with tests that provide full statement coverage.
the following inputs are needed for test prioritization and diagnosis a finite setc fc1 c j c mgofmcomponents typically source code statements of which mf m can be faulty.
a finite sett ft1 t i t ngofntests with binary outcomes oi whereoi if testtifailed and oi otherwise.
each test has a cost ct i .
an mcoverage matrix a whereaij if testtiinvolves component cj and otherwise.
each row is called spectrum and each column is called signature .
these inputs are represented in the example program of table i. for the sake of code readability the coverage matrix is shown transposed.
for exposition clarity we use a simplified way of diagnosis.
we assume that if a test fails the statements that were covered become suspects and if it passes the covered statements are exonerated.
diagnostic performance is expressed in terms of a cost metriccdthat measures the excess effort incurred in finding all statements at fault inspection effort .
cdmeasures wasted effort independent of the number of faults mfin the program t cprogram character counter t1t2t3t4t5t6t7t8 function count char s int let dig other i a transposed c1while c s c2 if a c z c c3 let fault c4 elsif a c z c c5 let c6 elsif c c c7 dig c8 elsif isprint c c9 other c10printf d d d n let dig other test case outcomes f f f f f f p p table i example program and inputs for test prioritization and diagnosis to enable an unbiased evaluation of the effect of mfoncd.
thus regardless of mf cd represents an ideal diagnosis technique all mffaulty statements on top of the ranking no effort wasted on inspecting other statements to find they are not faulty while cd m mfrepresents the worst case inspecting all m mfhealthy statements until arriving at themffaulty ones .
a. example a traditional prioritization heuristic such as the additional statement coverage heuristic addst tries to maximize covered code in as few tests as possible.
once all the code is covered the algorithm restarts with the remaining tests.
such algorithm would start by selecting t1 which fails.
if we tried to apply diagnosis after this test a large number of source code statements would have to be inspected since all but statement c7are covered.
assuming random inspection cd statements in average.
if we would execute one more test addst would select t2.
since it also fails c8andc9are no longer suspects and inspection effort would drop to cd on average.
after t3 c5 is also exonerated and cd 5on average.
executing the next two addst tests t4andt5 would not provide any new diagnostic information since they cover all the current suspects.
executing t8as the last test pass would finally enable a perfect diagnosis since the only non covered suspect isc3.
on the other hand r aptor the diagnostic prioritization algorithm presented in this paper would initially select t5since it provides a better balance between covered and non covered statements.
as it fails only the covered statements become suspects.
this means that after just one test cd already equal to addst after tests.
r aptor tries to increase the difference between the current suspects and chooses t8as second test which passes.
the set of suspects is reduced to onlyc3andc5 andcd .
testt6is selected next to differentiate between those and fails indicating that the fault must bec3.
the remaining tests do not change the result.
.
.
.
.
.
7cd m mf ctaddst raptrfig.
.
advantage of diagnostic prioritization b. measurement whereas both algorithms detect the presence of a fault after the first test r aptor produces much more diagnostic information per test and the overall cost combination ct cd is significantly reduced.
to measure how good a specific prioritization algorithm is for fault localization we need to measure the evolution of cdper test case choice.
previous work measured the relative difference between cd at fixed percentages of the test suite and the cdafter applying of the test suite following the formula relativeexpense n cd n cd cd in the first sample is taken after a of the test cases have been executed which corresponds to approximately tests in their experimental setting.
however previous experiments have shown that the most gains in inspection cost happen in the first 20tests.
therefore we use a continuous measure instead of discrete samples to evaluate this continuous process without running the risk of missing important details or biasing the results.
our effectiveness measure can be seen as a continuous variant ofrelativeexpense and uses the area difference betweencd n i.e.
cdas a function of the number of applied tests andcd according to s nx n cd n cd n m mf ct n wherect n corresponds to the cost of the n th test.
a similar measurement is used in .
figure illustrates the evolution of inspection cost cdper unit of test cost ctfor both scenarios and the area s shaded .
the effectiveness of addst in our example corresponds tos whereas the effectiveness of r aptor corresponds to s a cost reduction.
iii.
r elated techniques in general terms testers will apply one of the prioritization algorithms to obtain an ordered test suite.
the tests in this ordered suite will be executed one by one recording the test outcomes until e.g.
the available testing time is exhausted.
if failures have occurred a diagnosis algorithm is used to locate the faults causing the failures producing a diagnosis.since we cannot directly measure the diagnostic quality of the information provided by the ordered test suite we will use two well known diagnostic techniques and infer conclusions based on the quality of the two different diagnoses they produce.
in the following we introduce basic concepts on test prioritization algorithms as well as on the diagnosis techniques considered.
a. test prioritization traditionally test cases have been prioritized with the goal of enhancing their fault detection ability i.e.
the rate at which failures are produced.
diagnostic test prioritization a recent development proposes to prioritize tests with the goal of fault localization i.e.
the rate at which diagnostic quality improves.
random this is the most straightforward prioritization criterion which orders test cases according to random permutations of the original test suite.
it is used as baseline in many prioritization experiments .
add statement in additional statement coverage prioritization addst test cases are selected iteratively in terms of the additional coverage they yield taking into account all the test cases that were already executed.
the algorithmic complexity time and space of addst prioritization is o n m per selected test.
fault exposing potential fep is a coverage based prioritization algorithm that assigns each statement a confidence value .
as high confidence is assigned to a statement that has been exercised by a number of passing tests those statements need less coverage in subsequent tests.
fep has o m n time complexity.
adaptive random testing art is a hybrid random coverage based algorithm .
art selects its next test case in two steps.
first it samples tests randomly until one of the samples does not add additional coverage.
second it selects the test which maximizes a distance function with the already selected test cases.
the best case time complexity is o n2 per selected test while the worst case time complexity is o n2 m .
information gain unlike all the previous techniques information gain ig is a diagnostic prioritization technique.
ig orders test cases dynamically on line based on the improvement of diagnostic quality based on an informationtheoretical measurement of the quality of the current diagnosis d the probability of the test passing or failing and the quality of the diagnosis if the test passes or fails.
ig is based on information theory in terms of entropy .
the complexity of ig iso n 2m for multiple faults.
an approximate solution with near optimal performance dubbed s equoia can perform ig test selections in o m n time .
b. fault localization although there is a large number of different fault localization techniques see section vii in our work we will consider two well known coverage based techniques bayesian diagnosis well known from model based diagnosis an area within ai and statistical approaches such as tarantula and ochiai .statistical fault diagnosis in statistical fault diagnosis the likelihood a component is at fault is quantified in terms ofsimilarity coefficients scs .
a sc measures the statistical similarity between statement cj s test coverage a1j a nj and the observed test outcomes o1 o n .
similarity is computed by means of four counters npq j that count the timesaijan the combinations respectively i.e.
npq j jfijaij p oi qgjp q2f0 1g for instance n10 j andn11 j are the number of tests in whichcjis executed and which passed or failed respectively.
the four counters sum up to the number of tests n. in this paper we will consider the ochiai sc given by ochiai lj n11 j p n11 j n01 j n11 j n10 j a great advantage of scs is their ultra low computational complexity compared to probabilistic approaches.
despite their lower diagnostic accuracy scs have therefore gained much interest.
in our example system after executing all the tests in the test suite the counters for c3aren11 n10 n01 n00 .
its likelihood being the faulty one according to ochiai is l3 .
the remaining statements all have lower likelihoods as they all have n10 j 0or n01 j .
for example for c2 n11 n10 n01 n00 and its ochiai similarity is l2 .
bayesian diagnosis bayesian diagnosis is an alternative diagnostic technique founded on probability theory aimed at obtaining a set of fault candidates d hd1 d ki.
each candidate dkis a subset of the statements which when simultaneously at fault explain the observed failures.
for instance d fc1 c3 c4gindicates that c1andc3andc4 are faulty and no other statement.
many algorithms exist to computed .
the candidates returned by bayesian fault diagnosis are ordered according to their probability of being the true diagnosis pr dk .
initially the probability of each candidate depends on the estimated probability of each of its statements being faulty pj prior fault probability .
after test case tiis executed the probability of each candidate is updated depending on the outcomeoiof the test following bayes rule pr dkjoi pr oijdk pr oi pr dk in this equation pr dk represents the prior probability of candidatedkbefore the test is executed.
pr oi is a normalization value that represents the residual probability of the observed outcome and pr oijdk represents the probability of the observed outcome oiproduced by a test ti if that candidatedkwas the actual diagnosis.
this depends on the false negative rate fnr of the statements in dk.
in software fault localization fnr is related to the concepts of testability and coincidental correctness .
a more detailed description of bayesian diagnosis can be found in .to diagnose the example system in table i for simplicity we will assume here that all statements have equal prior probability pj software has a much lower prior probability this is just an example and we assume fnr i.e.
faults will always cause a failure.
the initial probability ford3 fc3g ispr d3 .
a more complex candidate such as d3 fc3 c5ghas an initial probability equal to pr d3 .
after all tests are executed the diagnosis is composed by candidates pr d3jo1 o2 pr d3 5jo1 o2 pr d3 7jo1 o2 and pr d3 7jo1 o2 .
hence cd .
iv.
r aptor the ig heuristic for diagnostic prioritization requires very precise estimations of the false negative rate of test cases to be able to predict their failure probability.
estimating fnr is a costly and error prone calculation.
experiments with real programs showed that errors in the fnr estimations can have disastrous results .
the enormous investment in parameter estimation and the overhead incurred in the testing process totally outweighs the benefits of ig diagnostic prioritization.
furthermore since ig requires knowing the outcome of the previous test case ig test sequences cannot be pre calculated off line introducing an overhead in the testing process.
for these reasons we present an alternative off line diagnostic prioritization algorithm r aptor greedy diagnostic prioritization by ambiguity group reduction that while not being theoretically optimal produces competitive results.
furthermore since it is not affected by fnr estimation errors its results are in many cases better than ig.
a. ambiguity since the basic working principle of any coverage based diagnostic algorithm is analyzing the differences and similarities between the signatures of each of the statements of the system under test each of the columns in the test coverage matrix a and the failure pattern of the system the test outcomes oi we can use the maximization of these differences to devise a new simpler diagnostic test prioritization heuristic.
any individual statement belonging to a group of statements with identical columns signatures cannot be uniquely identified as faulty.
such a group is termed an ambiguity group .
the example system in table i has two ambiguity groups f1 10gandf8 9g.
letag fg1 g2 g lgbe the ambiguity groups generated by the matrix a or a subset of it.
the residual diagnostic effort should a fault occur in a given group gicorresponds to the expected diagnostic effort if the developer would randomly pick statements in gifor inspection e jgij .
to keep the heuristic simple we assume faults are distributed uniformly through the program s code.
therefore the probability of groupgioccurring is pr gi jgij m. the value of the diagnostic ambiguity heuristic can be defined by averaging the effort in each group gi by theprobability of the system containing a fault belonging to each of the ambiguity groups.
g ag lx i 1jgij m jgij wheremis the total number of statements in the system.
the complete matrix in table i produces the set ag ff1 10g f8 9ggwhose ambiguity is g ag .
b. ambiguity reduction since g ag estimates the residual diagnostic effort cd it can be seen as an estimation of diagnosis quality and its value can be used to construct an alternative heuristic to ig.
each test that is executed breaks each ambiguity group into two smaller ambiguity groups one corresponding to the statements in the ambiguity group that are covered by the test and one corresponding to the statements that are not covered.
groups of size are discarded.
using g ag has the advantage that it does not require knowing the test outcomes i.e.
can be performed off line nor requires estimation of failure probabilities unlike ig nor does it need additional input parameters e.g.
fnr.
the ambiguity reduction heuristic is defined as the difference in ambiguity caused by appending one more test to the test matrix according to ar a ti g ag a g ag ajjti where the function agreturns the set of ambiguity groups of a test matrix and the jjoperator appends test titoa.
c. algorithm algorithm details the implementation of the r aptor algorithm which computes a sequence that optimizes the evolution of ambiguity in a greedy incremental way.
algorithm raptor function raptor t a while t6 do ti arg maxi2tar a ti ct i ifar a ti 0then .any improvement?
a ajjti t tnfig else a0 raptor t return ajja0 return a the algorithm receives the set of test cases and their coverage as input together with the test cost.
at every iteration a testtiis selected such that it maximizes the reduction of ambiguity per unit of test cost.
the test that produces the highest improvement is appended to the result operator jj and removed from the set of free tests.
since the algorithm may reach a point where no test can produce any improvement the algorithm checks for this case and if detected starts recursively with the remaining tests and appends the resulting a0toa.
this policy is also used in .
an alternative policy also proposed in would be to simply randomly order the remaining tests.
g ag can be computed in at most o m time and the set of ambiguity groups can be computed incrementally in o m time from the previous set.
since these two functions have to be repeatedly used for each of the remaining free tests the complexity per text choice i.e.
for the loop of r aptor equals o mn a complexity similar to addst prioritization.
execution time measurements confirm our complexity analysis.
on an core .
ghz.
xeon machine with 32gb of memory test selection for m n test matrices takes less than second.
example raptor would prioritize the tests in our example test suite as follows.
initially there is no distinction between statements they all belong to the same ambiguity group ff1 10gg and g ag .
if we executed test t1 the ambiguity group will be broken toff1 10g f7gg f7gis discarded as it is a single statement with ambiguity g ag 6on the other hand if we execute t5 we obtain ff1 10g f6 9ggand ambiguity g ag 1which represents a larger reduction of ambiguity t6also provides the same reduction .
the second test chosen by r aptor ist8.
the set f1 10gis split into two ambiguity groups one for the covered statements f1 10g and one for the not covered f3 5g.
the same applies to the f6 9ggroup split inf6 9gandf7g.
this new state has a total ambiguity g ag table ii shows the sequence of tests chosen by r aptor together with the evolution of the ambiguity groups and the value of diagnostic ambiguity.
the r symbol indicates when the set of ambiguity groups is reset to ff1 10gg because no test can further reduce the ambiguity.
v. e mpirical evaluation in this section we compare the performance of r aptor to rnd art addst fep and s equoia .
the prioritization performance of each algorithm is assessed by the effectiveness formula in equation .
finally we also study the trade off between fault detection and fault localization made by raptor .
a. subject programs we perform our experiments using the well known siemens benchmark set as well as the flex grep gzip sed and space programs obtained from sir .
every program has a correct version and a set of test inputs is also provided which were created with the intention of providing full test coverage.
table iii provides more information about the programs used in the experiments where mcorresponds to the number of lines of code.testoi ambiguity groups g ag d cd f1 10g .
hfg f1g f2g f3g f4g f5g f6g f1 2g f1 3g f1 3g i4.
t51 f1 10g f6 9g .
hf1g f2g f3g f4g f5g f10g f1 2g f1 3g f3 5g f1 3g i2.
t80 f1 10g f3 5g f6 9g f7g .
hf3g f5g f3 5g f3 7g f5 7g f3 7gi .
t61 f1 10g f3g f4g f5g f6 9g f7g .
hf3g f3 5g f3 7g f3 7gi .
t70 f1 10g f2g f3g f4g f5g f6 9g f7g .
hf3g f3 5g f3 7g f3 7gi .
t21f1 10g f2g f3g f4g f5g f6g f7g f8 9g0.
r hf3g f3 5g f3 7g f3 7gi .
t41 f1 10g f5 9g .
hf3g f3 5g f3 7g f3 7gi .
t31 f1 10g f7g f5g f8 9g .
r hf3g f3 5g f3 7g f3 7gi .
t11 f1 10g f7g .
hf3g f3 5g f3 7g f3 7gi .
table ii evolution of ambiguity groups and dfor the raptor heuristic for our example system program name mutants loc m n program type ptprint tokens lexical analyzer p2print tokens2 lexical analyzer re replace pattern recognition sc schedule priority scheduler s2 schedule2 priority scheduler tc tcas altitude separation ti tot info information measure sp space adl parser gz gzip compressor se sed stream editor gr grep string matching fl flex lexer generator table iii programs used for evaluation to obtain a realistic fault sample size we have extended the subject programs with versions mutants for which we seeded random combinations of multiple faults similar to the ones in siemens.
these additional faults are obtained by applying mutation techniques to the reference implementation of each program.
the mutants were generated by a modified version of zoltar a spectrum based fault localization tool set .
as each program includes a correct version we use the output of the correct version as oracle.
for each program faulty versions seeded with and random mutation faults were created.
for each of the faulty versions repetitions were made to a total of prioritized test suites per program.
b. input parameters for our study coverage matrices awere obtained by instrumenting each of the programs at statement level with zoltar .
it must be taken into account that the coverage of a test input can vary between regression cycles.
this will not affect diagnostic accuracy as diagnosis is performed a posteriori when the updated coverage is already available.
however it can affect the accuracy of prioritization heuristics such as fep art ig or r aptor because the coverage of a test case is needed a priori .
if using the coverage information from a previous test run the coverage can deviate usually slightly .
this deviation should be taken into account by using techniques for estimating the updated coverage of a test input .
this situation is generally overlooked in test prioritization literature .
regarding the input parameters of bayesian diagnosis.
it is safe to assume equal valued priors pj defects kloc since priors have been shown not to be very critical todiagnostic performance .
on the other hand the accuracy of the diagnosis itself depends on accurate fnr estimations .
in our experiments we will derive fnr information from testability by using a simplified propagation infection execution pie technique used also in .
c. fault localization effectiveness we compare diagnostic prioritization effectiveness in terms of diagnostic effectiveness s according to equation .
statistical diagnosis ochiai sc table iv presents the numerical results in terms of the sscore and relative percentage with respect to rnd.
the best techniques with statistical confidence in the bonferroni mean separation test are highlighted in boldface.
the s equoia column is obtained by using the test order produced by s equoia discarding its internal bayesian diagnosis and performing a new diagnosis using the similarity coefficient.
it can be seen how s equoia s effectiveness appears to be extremely poor in contrast with its performance when using bayesian diagnosis as shown in the following section.
this is caused by the fact that similarity coefficients do not exploit all the information available.
it can also be seen how r aptor consistently provides an improvement in the efficiency for all programs with only one fault and is the best in all cases but one tcas .
on average raptor provides reduction in terms of swith respect to rnd s baseline performance in the single fault case and in the multiple fault case.
when compared to the next best technique art r aptor provides reduction in the single fault case on average and reduction in the multiple fault case.
for multiple faults r aptor s superiority is still clear although there are some cases where the performance of r aptor is severely affected because the distribution of the faults is very biased as will be explained in section vi.
for the siemens programs addst and fep perform extremely poorly even when compared to rnd.
however for the sir programs the trend reverses producing much better results.
the root causes for the low effectiveness of r aptor fortcas and the striking difference between the effectiveness of addst for siemens and sir programs will be analyzed in section vi.
bayesian diagnosis we now evaluate the effectiveness of r aptor and other techniques in terms of bayesian fault diagnosis.
table v presents the numerical results in terms of thesscore.
again we present the reduction percentage withochiai mf rnd art addst fep raptor sequoia pt .
.
.
.
.
.
p2 .
.
.
.
.
.
re .
.
.
.
.
.
sc .
.
.
.
.
.
s2 .
.
.
.
.
.
tc .
.
.
.
.
.
ti .
.
.
.
.
.
sp13.
.
.
.
.
.
gz12.
.
.
.
.
.
se10.
.
.
.
.
.
gr12.
.
.
.
.
.
fl .
.
.
.
.
.
ochiai mf rnd art addst fep raptor sequoia pt .
.
.
.
.
.
p2 .
.
.
.
.
.
re .
.
.
.
.
.
sc .
.
.
.
.
.
s2 .
.
.
.
.
.
tc .
.
.
.
.
.
ti .
.
.
.
.
.
sp12.
.
.
.
.
.
gz .
.
.
.
.
.
se .
.
.
.
.
.
gr10.
.
.
.
.
.
fl .
.
.
.
.
.
table iv effectiveness s in terms of statistical diagnosis ochiai respect to rnd and the scores in boldface correspond to the top techniques with confidence following the bonferroni mean separation test.
combined with bayesian diagnosis s equoia is no longer among the worst performing algorithms but among the best showing the perfect match between the heuristic and the diagnosis algorithm.
however it can be seen how r aptor s effectiveness is on par and even surpasses s equoia the theoretical optimum both in the single fault and multiplefault case.
this is due to the fact that the ig heuristic used in sequoia is largely affected by errors in the fnr estimations whereas r aptor is not.
on average r aptor provides a reduction of sin the single fault case with respect to the baseline set by rnd.
in the multiple fault case the reduction with respect to rnd is .
when compared to the next best technique art r aptor achieves a reduction of for single faults and for multiple faults.
identical to what happened in the similarity coefficient case there is a noticeable difference in the effectiveness of fep and addst between the siemens and sir programs which will be explained in section vi.
d. fault detection apfd c we evaluate the techniques in terms of their fault detection performance by using the apfd cmetric .
this information is useful to understand the modest trade off between the test prioritization goals of fault detection and fault localization.
consistently with previous literature we will use only single fault data.bayes mf rnd art addst fep raptor sequoia pt .
.
.
.
.
.
p2 .
.
.
.
.
.
re .
.
.
.
.
.
sc .
.
.
.
.
.
s2 .
.
.
.
.
.
tc .
.
.
.
.
.
ti .
.
.
.
.
.
sp .
.
.
.
.
.
gz .
.
.
.
.
.
se .
.
.
.
.
.
gr .
.
.
.
.
.
fl .
.
.
.
.
.
bayes mf rnd art addst fep raptor sequoia pt .
.
.
.
.
.
p2 .
.
.
.
.
.
re10.
.
.
.
.
.
sc13.
.
.
.
.
.
s211.
.
.
.
.
.
tc .
.
.
.
.
.
ti .
.
.
.
.
.
sp12.
.
.
.
.
.
gz14.
.
.
.
.
.
se10.
.
.
.
.
.
gr10.
.
.
.
.
.
fl .
.
.
.
.
.
table v effectiveness s in terms of bayesian diagnosis table vi shows the results in terms of the improvement percentage of the apfd cmetric with respect to rnd.
the values in boldface represent the best technique with confidence using the bonferroni mean separation test.
consistent with previous literature it can be seen how addst and fep are the best performing techniques especially in the siemens programs.
for the larger sir programs however r aptor has the best performance tied with addst.
both observations are consistent with our previous findings indicating that prioritizing for fault localization independently of the specific heuristic tends to lower failure rates in some test suites.
this reduced performance is not a very serious problem in practice given the difference between addst and r aptor .
only schedule2 presents a significant reduction of for r aptor with respect to addst.
however the increased test effort is completely outweighed by the large savings in inspection cost.
rnd art addst fep raptor sequoia pt .
.
.
.
.
.
p2 .
.
.
.
.
.
re .
.
.
.
.
.
sc .
.
.
.
.
.
s2 .
.
.
.
.
.
tc .
.
.
.
.
.
ti .
.
.
.
.
.
sp .
.
.
.
.
.
gz .
.
.
.
.
.
se .
.
.
.
.
.
gr .
.
.
.
.
.
fl .
.
.
.
.
.
table vi fault detection performance apfd c vi.
d iscussion in this section we discuss the threats to the validity of our results analyze the reasons for the behavior of the techniques and introduce some criteria aimed at choosing the right technique under varying circumstances.
a. threats to validity the external validity of the results obtained with the siemens programs can be questioned given their small sizes.
in order to strengthen the validity of our results we provided validation experiments with larger programs such as the sir tools showing that indeed for larger matrices the behavior of techniques is different.
the fact that we seeded artificial faults into our programs is a second threat to the external validity of our results.
from the point of view of the representativeness of mutation faults they have become usual in test prioritization and fault diagnosis literature since it is almost impossible to obtain a sample of real faults that is representative.
from the fault density point of view we restricted the experiment to simultaneous faults to keep fault density to a realistic level.
a number of other threats to the validity of our experiments have been discussed throughout the paper.
the motivation and construct validity of the smetric was discussed in section ii.
using two different diagnosis techniques to measure efficiency was motivated in section v. the threats to validity derived from how we determine the algorithm input parameters especially the usage of up to date coverage information the prior fault probabilities and false negative rates all were covered in section v. b. technique analysis it can be seen in our results that there are significant differences in the effectiveness of each technique depending on the program.
there is also a noticeable difference between the siemens programs and the sir programs that influences the behavior of addst transforming it from the worst of all techniques to a very competitive one.
to explain the difference in the effectiveness of addst and fep between siemens and sir programs it is necessary to explain the relationship between coverage and information gain.
for simplicity of exposition let us assume that there is only one fault in the system and that the fault will produce a failure whenever covered fnr .
let us also assume that the coverage of a test case is uniformly distributed throughout the program.
in this situation the fault will always be at the top of the suspect ranking possibly tied to other candidates.
in this simplified case the information gain that a test provides is determined by the reduction of the size of the top ranked suspect set.
assuming there are jdjtop ranked suspects a test of coverage density will reduce the top ranked set to jdj statements if it fails and jdj if it passes.
under these conditions it is shown in that diagnostic information gain can be modeled by ig log2 log2 .
.
.
.
.
.
.
.
100cd m mf testing costschedule mf rnd art addst fep rap seq .
.
.
.
.
.
.
100cd m mf testing costspace mf rnd art addst fep rap seq .
.
.
.
.
.
.
.
1rel.
frequency row wise schedule ig .
.
.
.
.
.
.
.
1rel.
frequency row wise space ig fig.
.
impact of coverage density distribution which is optimal for coverage probability which also corresponds to failure probability in this case .
in real test matrices coverage density is not uniform but varies for each test.
the plot in figure depicts the evolution ofcdand coverage density histogram of two programs from our evaluation.
the ig curve is added as reference.
techniques like addst and fep designed to maximize coverage will tend to select test cases with a very high thus a high failure probability if they are available which will fall past the ig maximum .
.
this is the case for the schedule program.
this affects their effectiveness greatly as can be seen in our results.
however when there are no tests past the ig maximum very sparse matrices as is the case for space and the other sir programs addst and fep are indirectly choosing tests that are close to the optimum by maximizing coverage.
this coverage distribution also explains the difference in the apfd cscore between siemens and the sir programs.
for the siemens set r aptor and s equoia lower the coverage whereas for the sir programs they both maximize it as addst does hence the similar scores.
the bad results of r aptor for the tcas program are due to the program s nature and some subtle assumptions underlying raptor .
first tcas has lines of code but only ambiguity groups which severely impacts the performance of any similarity coefficient and makes any improvement in effectiveness very small.
second our sample of seeded faults intcas andtot info are not uniformly distributed in the code making r aptor less optimal.
s equoia being a dynamic technique can adapt to this non uniformity but the errors in the fnr estimation which affect the ig heuristic neutralize the gain.
c. choice of technique we now analyze the factors that influence the decision to test for failures or faults from the first test and to use either raptor sequoia or an alternative.
wait for the first failure?
we have seen in our evaluation that the fault detection cost i.e.
the test effort it takes to detectinspection cost testing cost c a b 1st failurediagn addstfig.
.
prioritization techniques and usage scenarios the first failure can be slightly increased when using diagnostic test prioritization.
the first question is whether to perform diagnostic test prioritization from test or only after the first failure since r aptor and s equoia have a moderately decreased fault detection capability.
the most conservative solution especially if the introduction of a fault is unlikely is to initially use addst or fep and switch to diagnostic test prioritization if a failure occurs.
this corresponds to scenario a in figure .
however if the probability of introducing a fault during development is high some projects can have up to probability it is better to start directly with diagnostic test prioritization since the tests executed until the first failure is found provide the most valuable diagnostic information.
the increased test cost the first failure occurs slightly later is greatly outweighed by the much more substantial gains in terms of diagnostic performance per unit of test effort.
therefore even if it takes slightly longer to detect a fault the reduction in the inspection effort required to precisely locate the fault greatly compensates for this.
this corresponds to scenario b .
furthermore if coverage density is very low diagnostic prioritization and fep or addst will provide similar fault detection and localization capabilities to sequoia or r aptor .
this corresponds to scenario c .
raptor or s equoia ?if using low cost similarity coefficients r aptor is the clear choice.
however since s equoia can potentially provide better results than r aptor combined with bayesian diagnosis it is necessary to consider the advantages and disadvantages of each technique.
computational cost even though r aptor and s equoia have a similar order of complexity r aptor is based on fast bit wise operators whereas s equoia is based on expensive floating point operations and requires expensive prior parameter determination.
furthermore it must be taken into account that s equoia must perform on line prioritization as the tests are executed potentially introducing a significant overhead.
fnr estimation quality the ig heuristic used in sequoia can be severely affected by poor fnr estimations.
if the variance of the samples used to estimate eachhjis high as is the case for tcas one should not consider s equoia .
ambiguity and non uniformity a test matrix with very few and very large ambiguity groups or a system with extremely biased fault distribution can cause problems to a static algorithm like r aptor .
if the fnr estimation quality is good enough one could opt for s equoia .otherwise the best would be to opt for a random approach such as art or rnd.
vii.
r elated work the influence of test suite extension reduction modification and prioritization on fault detection and diagnosis has received considerable attention .
all the works cited study the effect of prioritization and reduction techniques that were designed for fault detection on fault localization.
raptor on the other hand is designed with fault localization effectiveness in mind to optimize the improvement of diagnostic accuracy per unit of test effort.
baudry et al.
propose test for diagnosis tfd to evaluate the quality of a test suite for diagnosis.
their measurement is based also on ambiguity groups dynamic basic blocks dbb in their work .
however their heuristic is focused exclusively on the number of ambiguity groups not on their size.
this may lead to needlessly sparse matrices e.g.
a diagonal matrix in their terms has ideal tfd fitness but at excessive test cost .
our algorithm recursively dissects ambiguity groups using a much more sophisticated goal function.
as a result tests are selected that offer higher diagnostic performance per test optimizing the coverage overlap in tests which allows deducing the defect locations in less tests.
finally our algorithm handles multiple defects while only considers single faults a highly unrealistic assumption in large systems.
test case prioritization s most common goal is to increase failure detection rate .
multiple coverage based prioritization techniques have been proposed and studied including techniques that take testing cost variance into account .
r aptor fundamentally differs from the above prioritization techniques in that its main goal is not to optimize the rate of failure detection but to also minimize debugging effort.
automated fault localization techniques aim at minimizing residual diagnostic effort when failures occur during the testing phase.
statistical approaches include .
a recent probabilistic approach of acceptable complexity is .
other approaches to fault localization include .
all the above approaches do not address test sequencing to optimize diagnostic accuracy and are essentially similar to rnd.
sequential diagnosis aims at finding the test sequence that optimizes diagnostic performance based on the current test outcomes applied to hardware systems .
if the system can have multiple faults sequential diagnosis complexity becomes exponential and can only be approximated .
the intelligent probing mechanism by brodie et al.
uses a similar measurement of ambiguity as r aptor for test matrix reduction minimal set of probes applied to computer networks.
viii.
c onclusions f uture work in this paper we presented a diagnostic test prioritization algorithm r aptor that selects test cases by their ability toproduce a refined diagnosis fault localization rather than to produce a failure as early as possible fault detection .
our results show that r aptor s test prioritization can significantly improve the reduction of inspection cost per unit of test cost when compared to random rnd adaptive random art statement coverage addst fep and ig based s equoia prioritization.
when using similarity coefficients r aptor provides a and average reduction in swith respect to the next best art for single and multiple faults respectively.
in the case of bayesian diagnosis r aptor achieves a and average reduction of swith respect to the next best art for single and multiple faults respectively.
given its negligible sacrifice in fault detection capability raptor can be used as the sole test prioritization strategy during regression testing in many cases especially when the probability of introducing defects is high.
future work focuses on modeling the influence of program and test suite characteristics on diagnosability.
an understanding of these factors will allow us to define new criteria for the creation of new diagnostic test suites or to improve existing ones.