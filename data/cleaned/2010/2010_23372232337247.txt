bug prediction based on fine grained module histories hideaki hata osamu mizuno and tohru kikuno osaka university osaka japan h hata kikuno ist.osaka u.ac.jp kyoto institute of technology kyoto japan o mizuno kit.ac.jp abstract there have been many bug prediction models built with historical metrics which are mined from version histories of software modules.
many studies have reported t he effectiveness of these historical metrics.
for prediction levels most studies have targeted package and file levels.
predicti on on a fine grained level which represents the method level i s required because there may be interesting results compared to coarse grained package and file levels prediction.
the se results include good performance when considering quality assurance efforts and new findings about the correlations between bugs and histories.
however fine grained predicti on has been a challenge because obtaining method histories fro m existing version control systems is a difficult problem.
to tackle this problem we have developed a fine grained versio n control system for java historage.
with this system we tar get java software and conduct fine grained prediction with well known historical metrics.
the results indicate that fine gr ained method level prediction outperforms coarse grained p ackage and file levels prediction when taking the efforts necessar y to find bugs into account.
using a correlation analysis we show that past bug information does not contribute to method lev el bug prediction.
keywords bug prediction fine grained prediction finegrained histories historical metrics effort based eval uation i. i ntroduction bug prediction has been widely studied and has been one of many hot topics among researchers.
recent findings show the usefulness of collecting historical metrics from software repositories for bug prediction models.
many studies measure software development histories such as changes on source code events of development or maintenance processes developer related histories and so on.
it is reported that historical metrics are more effect ive than code complexity metrics .
in industry there are reports of bug prediction in practice .
microsoft corporation built a system crane and reported its experiences with this system .
historical metrics including code churn regression histories and details of fixes are collected to build failure prediction models in crane.
there is also a report of bug prediction in practice at google1.
based on research papers a prediction model was built using bug fix information.
in both industry and the academy bug prediction with historical metrics has 1bug prediction at google ot.com bug prediction at google.htmlbecome the focus of attention because of its effectiveness and understandability.
in the research area of bug prediction fine grained prediction is one of the next challenges.
in the esec fse conference phd working groups created a forum to conduct short surveys on software engineering topics by interviewi ng conference participants and researching the field2.
the forum group who discussed bug prediction models concentrated on the main open challenges in building bug prediction models.
from subjects including five from industry and from academia fine grained prediction was selected as one of the future directions.
studies of fine grained predictio n are necessary because desirable results may be obtained when compared to coarse grained prediction.
recently studies take into account the effort of quality assurance activitie s for evaluating bug prediction results .
effort b ased evaluation considers the effort required to find bugs but does not evaluate the prediction results only with predicti on accuracy.
previous studies considered the lines of code loc of modules as efforts.
if we can find the most bugs while investigating the small percentages of loc in the entire software such prediction models would be desirable.
recent studies reported that file level predict ion models are more effective than package level prediction which has more coarse grained modules than file level on java software .
from these results we can hypothesize that method level prediction is more effectiv e than package level and file level prediction which means we can find more bugs during quality assurance activities with method level prediction while investigating the same amount of loc.
actually there are studies predicting fine grained buggy modules.
kim et al.
targeted buggy java methods by a cachebased approach .
mizuno and kikuno predicted buggy java methods using a spam filtering based approach .
however there have been few studies of fine grained prediction using well known historical metrics.
this is becau se of the difficulty of collecting method level historical met rics since version control systems do not control method histories.
to collect detailed histories we have proposed a finegrained version control system historage .
historage is c ieee icse zurich switzerland constructed on top of git and can control method histories of java.
with this system we collect historical metrics for methods to build prediction models and compare such models with package level and file level prediction models based on effort based evaluation.
we empirically evaluate the prediction models with eight open source projects writt en in java.
the contributions of this paper can be summarized as follows survey and classification of recent historical metrics proposed in bug prediction studies.
study of the effectiveness of method level prediction compared with package level and file level prediction based on effort based evaluation and a report of its effectiveness.
analysis of the correlations between bugs and histories of packages files and methods.
the reminder of this paper is structured as follows.
section ii summarizes the proposed historical metrics from our survey.
section iii discusses the problem of obtaining finegrained module histories and introduces our fine grained version control system.
in section iv we describe our study design including effort based evaluation research ques tions information of study projects collected historical metri cs in our study and how we collect buggy modules and the prediction model we used.
section v reports the results and lessons we learned and section vi discusses the overheads of fine grained prediction and threats to the validity of thi s study.
finally we conclude in section vii.
ii.
h istorical metrics in this section we classify historical metrics based on the target of measurement.
we prepare four categories each of code related metrics process related metrics organiza tional metrics and geographical metrics.
a. code related metrics nagappan and ball proposed code churn metrics which measures the changes made to a module over a development history .
they measured churned loc total loc and deleted loc total loc for example.
churned loc is the sum of added and changed lines of code between a baseline version and a new version of a module.
based on code churn metrics the authors built statistical regression models a nd reported that code churn metrics are highly predictive of defect density performed on windows server .
these code related metrics have been basic historical metrics an d have been used in many studies .
b. process related metrics there are many studies of historical metrics related to development processes.
changes fixes past bugs etc.
graves et al.
measured the number of changes the number of past bugs and the averageage of modules for predicting bugs .
they reported the usefulness of such process related metrics compared with traditional complexity metrics from a telephone switching system study.
these process related metrics have been used in many studies for example the number of changes the number of past bugs the number of bug fix changes and module age s .
cache based approach.
several cache based bug prediction studies exist .
hassan and holt for example proposed a top ten list which dynamically updated the list of the ten most likely subsystems to have bugs .
the list is updated based on heuristics including the most recently changed most frequently bug fixed and the most recently bug fixed as the development progresses.
kim et al.
and rahman et al.
discusses bugcache andfixcache cache operations.
the four heuristics used as cache update policies in their work are as follows changed locality recently changed modules tend to be buggy.
new locality recently created modules tend to be buggy.
temporal locality recently bug fixed modules tend to be buggy.
spatial locality a module recently co changed with bug introduced modules tends to be buggy.
the number of co changes with buggy modules logical coupling with bug introducing modules are also measured in other studies .
process complexity metrics.
hassan proposed complexity metrics of code changes .
these metrics are designed to measure the complexity of change processes based on the conjecture that a chaotic change process is a good indicator of many project problems.
the key idea is that the modules that are modified during periods of high change complexity will have a higher tendency to contain bugs.
to measure the change complexity of a certain period hassan proposed to use shannon s entropy.
to measure how much a module is modified in complex change periods different parameters are prepared and four history complexity metrics hcm are proposed.
it is reported from a study with open source projects that history complexity metrics are better predic tors than process related metrics i.e.
prior modifications an d prior bugs .
c. organizational metrics historical metrics related to organization are newer metrics and have been well studied recently.
number of developers.
graves et al.
measured the number of developers .
from a case study of a telephone switching system the authors reported that the number of developers did not help in predicting the number of bugs.201weyuker et al.
also reported that the number of developers is not a major influence on bug prediction models .
structure of organization.
to investigate a corollary of conway s law structure of software system closely matches its organization s communication structure nagappan et al.
designed organizational metrics which include the number of engineers the number of ex engineers the number of changes the depth of master ownership the percentage of organizational contribution the level o f organizational ownership overall organizational owners hip and the organization s intersection factor .
they repor ted that these organizational metrics based failure prone mo dule prediction models achieved higher precision and recall val ues compared with models with churn complexity coverage dependencies and pre release bug measures from a case study of windows vista.
mockus investigated the relationship between developercentric metrics of organizational volatility and the proba bility of customer reported defects .
from a case study of a switching software project mockus reported that the numbe r of developers leaving and the size of the organization have an effect on software quality but the number of newcomers to the organization is not statistically significant.
network metrics.
networks between developers and modules are analyzed for predicting failures .
human factors such as the contributions of developers coord ination and communications are examined based on network metrics such as centrality connectivity and structural holes.
ownership.
the relationship between ownership and quality is also investigated.
bird et al.
examined the effec ts of ownership on windows vista and windows .
they measured the number of minor contributors the number of major contributors the total number of contributors and the proportion of ownership for the contributor with the highest proportion of ownership.
they found a high ratio of ownership and many major contributors and a few minor contributors are associated with less defects.
rahman and devanbu examined the effects of ownership and experience on quality .
they conducted a finegrained study about authorship and ownership of code fragments.
they measured the number of lines contributed by an author divided by the number of lines changed to fix a bug as an authorship metric and defined the authorship of the highest contributor as ownership.
from a study of open source projects they reported that a high ownership value by a single author is associated with lines changed or deleted to fix bugs and that lack of specialized experience on a particular file is associated with such lines.
d. geographical metrics geographical metrics are measured for assessing the risks of distributed development.
bird et al.
investigated the locations of engineers who developed binaries .
bird et al.
classified distribution levels into buildings cafet erias campuses localities and continents.
from a case study of windows vista they clarified how distributed development has little to no effect on post release failures.
in a study of organizational volatility and its effects on software defects mockus measured the number of sites that modified the file and investigated the distribution of mentor s and developers .
he also reported on a case study of large switching software to show that geographic distribution ha s a negative impact on software quality.
iii.
f ine grained histories in section ii we discussed various historical metrics.
to measure these historical metrics we need to obtain version histories of each module.
for packages and files it is easy to collect historical metrics by using builtin commands of ordinary version control systems.
however there is no command to investigate the histories of methods in java files .
to analyze fine grained module histories some tools have been proposed and used in research.
hassan and holt for example proposed c rex which is an evolutionary extractor .
it records fine grained entity changes over the development period.
although c rex stores entire versions it cannot track module histories if there is renaming or moving.
beagle is a research platform .
using origin analysis it can identify rename move split and merge.
however the beagle targets selected release revisions to apply origin analysis .
bevan et al.
proposed kenyon which is designed to facilitate software evolution researc h .
although kenyon records entire versions rename and move are not identified.
zimmermann proposed apfel which collects fine grained changes in relational database s .
although versions are stored entirely apfel does not identify rename or move.
for fine grained module histories clarifying existing methods in particular revisions is not difficult because all versions of the files are stored entirely.
matching every sequential version is required to obtain entire method histor ies but matching is difficult when renaming and moving exist.
because of this limitation obtaining entire histories of j ava methods has been difficult.
to address this problem we proposed a fine grained version control system historage .
we make use of the rename move detection mechanism of git a version control system.
when renaming and moving exists git identifies matches based on the similarities of file contents .
historage stores all java methods independently and contr ol their histories3.
since historage is created on top of a git version control system every git command can be used.
from empirical evaluation with some open source projects we found that historage can identify matches practically 3a tool to create historage is available from .com hdrky git2historage202percent of linespercent of bugs found 100loc figure .
cost effectiveness curve when renaming and moving exist4.
with this system we can obtain the entire histories of java methods and collect method level historical metrics.
iv.
s tudy design a. effort based evaluation recent studies take into account the effort of quality assurance activities such as inspecting and testing predi cted modules for evaluating prediction models .
these effort based evaluations should be desirable for practica l use of the prediction results.
the key idea of effort based evaluation is that it discriminates the cost of inspecting a nd testing for each module.
arisholm et al.
pointed out that the cost of such quality assurance activities on a module is roughly proportional to the size of the module .
figure illustrates an example of a cost effectiveness curve.
this curve shows that as the quality assurance cost increases the percentage of found bugs increases.
the quality assurance cost is represented as the percentage of investigated loc of software.
when we inspect or test modules the modules are ordered by bug proneness.
if we find most bugs when we investigate the small percentage of the entire loc it should be effective.
to compare different bug prediction results the percentage values of bugs found on the same value of the percentage of loc should be easy to understand.
for this cutoff value of loc is used in some studies .
we also choose as this cutoff value because it is more realistic than investigating the entire loc.
inspecting of the entire loc may be an enormous effort for large software or little for small software.
so deciding cutoff w ith absolute value of cumulative loc is another possible way and one of future works is to discuss the results with such effort based evaluation.
in figure a dotted line represents this cutoff of loc at20 .
if cost effectiveness curves cross the upper part of 4git detects rename move while outputting logs with m optio n if the content is similar enough.
the default value of this similar ity threshold is .
historage makes use of this mechanism for tracking methods and we found that it detected more than correct matches in candidates with this default threshold value.this cutoff line it is better for the cost of inspection and testing.
in this example when we inspect top bug prone modules until of the entire loc it is revealed that we can investigate of buggy modules.
b. research questions to investigate the effectiveness of fine grained predictio n we compare prediction models on different levels that is packages files and methods of java software.
prediction models are built with well known historical metrics proposed and used in previous studies and are compared with effort based evaluation.
compared with package level and file level prediction there is a difference in method level prediction.
since pac kages consist of files the total loc are equal in both levels.
however this does not hold in package level vs. methodlevel and file level vs. method level because a file does not consist of methods only.
for fair comparison with levels of package file and method we ignore code except for methods.
this means that bugs only in methods are targeted and only the loc of methods are considered as efforts.
with these settings we investigate the following three research questions rq1 are method level prediction models more effective than package level and file level prediction models with effort based evaluation?
rq2 when method level prediction models are more effective.
why are method level prediction models more effective than package level and file level prediction models?
rq3 are there differences in different module levels regarding the correlations between bugs and module histories?
c. target projects we selected eight open source projects for our study eclipse communication framework ecf wtp incubator and xpand were chosen from the eclipse projects.
ant cassandra lucene solr openjpa and wicket were chosen from the apache software foundation.
all projects are written in java and have relatively long development histories.
we chose these projects because they span varied application domains a building tool a distributed databa se management system a text search platform an objectrelational mapping tool a web application framework and development platform plugins related to the communication framework web tools and a template engine.
we obtained each git repository5.
for package level and file level prediction we mine ordinary git repositories.
f or method level prediction we convert ordinary git reposito ries to historage repositories and mine them.
this conversion 5eclipse projects from and apache software foundation from i summary of studied projects name initial date last date of commits of developers last l oc of files on last date ecf wtp incubator xpand ant cassandra lucene solr openjpa wicket can be done automatically.
table i summarizes information for each target project.
the development period ranges from months to years and the loc on the last date of the studied period ranges from 15k to 370k.
table i also presents the number of commits from 1k to 15k the number of developers from to and the number of files on the last date from to 4k .
the average locs per one file varies from .4to140.
.
d. metrics collection we collected the major metrics discussed in section ii.
historical metrics for packages can be measured by the cumulating values of files in the packages in most cases.
method level historical metrics can be collected from historage repositories similar to collecting file level histo rical metrics from git repositories.
table ii presents all histor ical metrics collected in this study.
code related metrics.
for code related metrics we measure loc and code churn metrics added loc and deleted loc .
as stated in section ii a these metrics are used in many studies.
code churn metrics for files are easily collected from version control repositories.
process related metrics.
for process related metrics we collect the basic metrics stated in section ii b such as the number of changes the number of past bugs the number of bug fix changes and the existing period age of modules.
some metrics are collected inspired by cache based approaches .
we collect two types of logical coupling metrics the number of logical couplings with bugintroduced modules and the number of logical couplings with modules that have been buggy.
to investigate the frequency of changes we measured average maximum and minimum intervals.
in addition we also collected one of the history complexity metrics .
as stated in section ii b there are four types of historical complexity metrics.
in this paper we select hcm3sbecause it performed well.
this metric is designed under the assumption that modules are equally affected by the complexity of a period.
for other parameters we follow the paper .organizational metrics.
organizational metrics and geographical metrics are relatively difficult to collect from o pensource projects although it may be possible to measure by integrating information from several software repositori es.
hence we measure ownership related metrics designed in although there are lots of metrics especially for orga nizational metrics as stated in section ii c. organization al metrics in can be collected only from version control repositories.
to measure ownership related metrics we follow the definition of proportion of ownership in .
the proportion o f ownership of a developer for a particular module is the ratio of the number of changes by the developer to the number of total changes for that module.
if ownership of an developer is below a threshold the developer is considered a minor developer otherwise a major developer.
in values ranging from to10 are suggested as the threshold based on a sensitivity analysis.
bird et al.
targeted compil ed binaries as modules for study which tend to be developed by many developers .
on the contrary files and methods which are our modules for study are a relatively small size and are developed by relatively only a few developers.
to take into account this difference we set the threshold valu e at20 .
e. bug information buggy modules are collected based on the szz algorithm proposed by sliwerski zimmermann and zeller which is designed to identify bug introducing commits by mining version control repositories and bug report repositories .
buggy modules can be identified by choosing modified modules between bug introducing commits and bug fixing commits.
with the szz algorithm bug introducing and bugfixing commits can be linked with each bug id in bug reports6.
first we need bug reports from bug report repositories such as bugzilla and jira.
in these bug report repositories 6bug reports are available from bugs eclipse projects ant and apache.org jira the other projects in the apache softwar e foundation 204table ii collected historical metrics name description code loc lines of code addloc added lines of code from the initial version delloc deleted lines of code from the initial version process chgnum number of changes fixchgnum number of bug fix changes pastbugnum number of fixed bug ids period existing period in days bugintronum number of logical coupling commits that introd uce more than one bug in other modules logcoupnum number of logical coupling commits that change o ther modules that have been buggy avginterval period comnum maxinterval maximum weeks between two sequential changes mininterval minimum weeks between two sequential changes hcm history complexity metric hcm3s organization devtotal total number of developers devminor number of minor developers devmajor number of major developers ownership the highest proportion of ownership table iii summary of prediction modules of packages of files of methods project tag date method loc buggy all percent buggy all per cent buggy all percent ecf root release .
.
.
wtp incubator v20090510 .
.
.
xpand galileo rc1 .
.
.
ant ant rc1 .
.
.
cassandra casandra .
.
rc1 .
.
.
lucene solr lucene solr .
.
.
openjpa .
.
.
.
.
wicket wicket .
.
.
.
.
there are also reports for requesting new features or enhanc ement.
to ignore such reports it is necessary to filter report s. from bugzilla repositories we exclude enhancement severity reports and from jira repositories we collect on ly bug issue type reports.
from a bug report of bug bi where irepresents bug id we obtain open date od bi and commit date cd bi .
with collected bug reports we then identify bug fixing commits.
bug fixing commits and bug biare linked based on matching bug ids in commit messages stored in version control repositories.
while linking commits and bug bi we investigated whether commit dates are before cd bi or not to remove improper identification of bug fixing commits.
from each bug fixing commit we perform the following procedure to identify buggy modules perform the diff command on the same module between the bug fixing version and a preceding revision to locate modified regions on the bug fixing commit.
examine the initially inserted date of the modified regions using line tracking commands such as git blame or cvs annotate .
if the regions are inserted before od fi commits creating those regions are identified as bug introducing commits.
identify a module as buggy if the module contains regions that are created in the bug introducing commits and are modified in the bug fixing commits.
as reported in naive differencing analysis on step of the procedure should yield incorrect bug introducing commits such as non behavior change commits and just format change commits.
to remove such false positives we ignore changes on blank lines comment changes and format changes.
in addition we ignore changes not on methods to identify bugs on methods as stated in section iv b. this procedure can be performed automatically.
if there is more than or equal to one buggy file in a package we consider it as a buggy package.
buggy methods are identified by205mining historage repositories.
this identification can als o be performed automatically.
we identify buggy packages files and methods in one revision for each project.
for this particular revision we select tagged revisions or revisions that are nearby tagged revisions.
table iii shows the data of the prediction study and the result of buggy module identification.
we obtained bug reports from the first report to the last one until june .
with these reports and entire versions in obtained version repositories we identify bug informatio n. the percentages of buggy packages ranges from .
to .
the percentages of buggy files ranges from .
to .
and the percentage of buggy methods ranges from .
to6.
.
since we target only the code of methods each total loc is accumulated with the entire method loc method loc .
f .
prediction model bug prediction models are built with the historical metrics shown in section iv d. these historical metrics are measured in the period from the initial date to the tagged date shown in table iii for each module.
we adopt the randomforest algorithm as a bug prediction model.
randomforest is a classifier with many decision trees that outputs the class that is the mode of the classes output by individual trees.
lessmann et al.
confirme d its good performance in bug prediction .
there are several other studies using the randomforest algorithm for bug prediction .
we use a statistical computing and graphics tool r and a randomforest package for our study.
as shown in table iii the percentages of buggy methods are small in total methods.
in such cases predictio n models tend to predict all methods as non buggy because there are only a small number of false positives.
in our pilot study with other prediction models like logistic regressio n we found such results.
however with randomforest models not all methods are predicted as non buggy in every project.
using prepared modules in table iii we conduct a fold cross validation analysis.
entire modules in one predictio n level in one project are randomly divided into groups.
of the groups a single group is used for testing a model and the other groups are used for training the model.
the cross validation process is repeated times with each of the groups used once as test data.
the results are combined into a single validation result.
v. r esults we present our results following research questions stated in section iv b. plots of the results are shown from eclipse communication framework ecf and ant only and other results are discussed in text.percent of linespercent of bugs found percent of linespercent of bugs found percent of linespercent of bugs found 100packagefilemethod a ecfpercent of linespercent of bugs found percent of linespercent of bugs found percent of linespercent of bugs found 100packagefilemethod b ant figure .
cost effectiveness curves of package level file level and methodlevel prediction package file methodpercent of bugs found a ecfpackage file methodpercent of bugs found b ant figure .
boxplots of package level file level and method level prediction.
percentages of bugs found in loc on a times run a. effort based evaluation package file vs. method rq1 are method level prediction models more effective than package level and file level prediction models with effort based evaluation?
figure shows two plots of cost effectiveness curves.
a package level curve dotted file level curve dashed and a method level curve solid are plotted.
we can see that the method level curves rise larger than the packagelevel and file level curves in a small loc.
as a result more bugs can be found by method level prediction when investigating of the loc represented by the cutoff lines.
in all projects method level prediction outperfor med package level and file level prediction.
as arcuri and briand insisted we should collect data from a large enough number of runs to assess the results of randomized algorithms because we obtain different results on every run when applied to the same problem instance .
randomforest is a randomized algorithm.
figure shows the result on one run.
following the suggested value of1 000as a very large sample we conducted a times run for all projects.
figure shows the results of the run.
in each project boxplots of the value of percentages of bugs found i n loc for package level file level and method level are shown.
in all projects we observed the small distributions206table iv median values of the percentage of bugs found in loc on1 times run project package file method ecf .
.
.
wtp incubator .
.
.
xpand .
.
.
ant .
.
.
cassandra .
.
.
lucene solr .
.
.
openjpa .
.
.
wicket .
.
.
of the values and method level prediction achieved higher values than package level and file level prediction.
in table iv we summarize the median values of the percentages of found bugs when investigating of loc in all modules.
the second to fourth column shows the values of package level file level and method level resu lts.
to detect statistical differences the mann whitney u tes t was used between package level vs. method level and filelevel vs. method level.
in both pairs in all projects the differences are statistically significant p .
.
the values of the percentages of found bugs are shown in bold if the value is more than .
in all projects method level prediction achieved more than and outperformed package level and file level prediction.
based o n these results from eight open source projects we can answe r research question rq1.
the answer is clear method level prediction is more effective than both package level and fil elevel prediction.
when comparing package level and file level file level prediction outperformed package level prediction in five projects as shown in table iv.
these results are consistent with the reports of previous studies .
however there are opposite results in the xpand cassandra an d openjpa projects.
our study is different from the previous studies in counting loc and targeting bugs we limit the loc of methods and target buggy methods.
these settings lead to an ignorance of files that have no method and may improve the package level prediction.
however these resu lts depend on project specific data.
therefore analyzing thes e project specific features is remained as a future work.
b. why is method level prediction effective?
rq2 why are method level prediction models more effective than package level and file level prediction model s?
intuitively fine grained prediction may more effective than coarse grained prediction because finding bugs in larg e modules is difficult.
figure shows boxplots of loc for packages files and methods.
with the mann whitney utest in all pairwise comparisons packages vs. files packag espackage file method0 800loc a ecfpackage file method0 1500loc b ant figure .
size of modules package level file level and met hod level.
all buggy0 60number of methods a ecfall buggy0 100number of methods b ant figure .
number of all and buggy methods in buggy files.
vs. methods and files vs. methods we found that the differences in loc are statistically significant p .
.
comparing the median value of the loc methods are nearly ten times smaller than files and are from thirty to threehundreds times smaller than packages.
next we investigated buggy files by considering how many methods exist in one file and how many buggy methods exist in the file.
the boxplots of figure present the results.
in both projects most of the buggy files contain nearly or more than 10methods but there are only a few buggy methods.
from all of the projects the median values of the number of entire methods range from 8to22 and the median values of the number of buggy methods range from 1to2.
although there are many methods in one buggy file there are only a few actual buggy methods.
this indicates that we need to investigate most of the non buggy methods in a file if the file is predicted to be buggy.
similarly we also investigated buggy packages.
from all of the projects the median values of the number of entire methods range from 27to579.
and the median values of the number of buggy methods range from 1to5.
.
because of these non buggy methods method level prediction is more effective than package level and file level predictio n.207table v spearman correlation between the post bugs and collected met rics .
marked by if statistically significant p .
ecf xpand ant wicket metric package file method package file method package file method package file method loc .
.
.
.
.
.
.
.
.
.
.
.
addloc .
.
.
.
.
.
.
.
.
.
.
.
delloc .
.
.
.
.
.
.
.
.
.
.
.
chgnum .
.
.
.
.
.
.
.
.
.
.
.
fixchgnum .
.
.
.
.
.
.
.
.
.
.
.
pastbugnum .
.
.
.
.
.
.
.
.
.
.
.
period .
.
.
.
.
.
.
.
.
.
.
.
bugintronum .
.
.
.
.
.
.
.
.
.
.
.
logcoupnum .
.
.
.
.
.
.
.
.
.
.
.
avginterval .
.
.
.
.
.
.
.
.
.
.
.
maxinterval .
.
.
.
.
.
.
.
.
.
.
.
mininterval .
.
.
.
.
.
.
.
.
.
.
.
hcm .
.
.
.
.
.
.
.
.
.
.
.
devtotal .
.
.
.
.
.
.
.
.
.
.
.
devminor .
.
.
.
.
.
.
.
.
.
.
.
devmajor .
.
.
.
.
.
.
.
.
.
.
.
ownership .
.
.
.
.
.
.
.
.
.
.
.
c. correlation analysis rq3 are there differences in different module levels regarding the correlations between bugs and module histories?
the spearman correlation values between historical metrics and the number of post bugs for package level file leve l and method level of four projects are shown in tablev.
the number of post bugs is the number of bug ids that have not been fixed.
correlations that are statistically signific ant p .
are marked by .
as shown in table iii the percentages of buggy methods is smaller than the percentages of buggy packages and files.
thus the correlation values are lower in method level.
we can make the following observations code related metrics have relatively higher correlations that is changes in code are related to bugs.
although this holds in most projects there are exceptional projects like the wicket project.
in this project java files and methods do not change repeatedly.
the usefulness of code related metrics depends on how the software has evolved.
past bug information fixchgnum and pastbugnum does not correlate with post bugs for method level prediction.
this indicates that methods do not have bugs repeatedly.
metrics about intervals have negative correlations.
in other words short intervals between changes are related to bugs in most projects.
organizational metrics may not contribute to methodlevel prediction.
this is because many developers have not changed the methods in the studied projects.
vi.
d iscussion a. overheads for method level prediction we need additional costs for package level and file level prediction.
required overhea ds can be summarized as follows preparing historage converting git repositories to historage repositories is needed only for method level prediction.
although it takes several hours a one night run there is no need for manual efforts.
mining historage running the szz algorithm to identify buggy modules and collecting historical metrics require mining repositories of version control systems.
the essential differences between git repositories and historage repositories is the number of storing modules.
to calculate the loc of one module there is no difference in processing time.
when we extract a single entire module s history rename move identification requires an o n2 processing time where nis the number of candidates.
as a result to mine a single log to collect simple historical metrics such as the number of changes fixes and developers historage requires more processing time than git.
to collect the process complexity metrics historage requires more processing time because it needs to analyze multiple logs.
building models and prediction the processing time of training and testing models highly depends208on the number of modules.
actually the most timeconsuming task in this study is the times run of fold cross validation analysis for method level prediction it requires one to two days .
although there are such overheads we do not need additional manual procedures for method level prediction compared with package level and file level prediction.
so we do not consider them as critical limitations.
b. threats to validity target projects are limited to open source software written in java.
for external validity there is a threat of generalization of our result.
projects we targeted are only open source projects written in java.
one of the good points of targeting only open source software projects in java is that there is no opposite result regarding the effectivenes s of method level prediction compared with package level an d file level prediction.
as described in section iv c the eight targeted projects varied in sizes domains and development periods.
for example the lucene solr project has less than two periods and prediction is conducted with only a one year history and yields a good result.
this result may promote the adoption of historical metrics based prediction for young projects.
for future work we intend to widen our study to other projects written in other programming languages and work on industrial projects.
collection of bug information has problems.
for construct validity the main threat is in the phase of collectin g bug information.
although we adopted a well known szz algorithm discussed in section iv e it has been reported th at there is a linking bias in identifying bugs with revision log s and bug reports .
recently a new algorithm of linking bugs and changes has been proposed .
this algorithm may mitigate this threat.
effort based evaluation may not reflect actual efforts.
in our evaluation there are also threats to construct validity.
to compare package level file level and methodlevel prediction we adopted an effort based evaluation wi th cost effectiveness curves which has been previously stud ied .
this effort based evaluation considers the cos t of quality assurance activities to be roughly proportional to the size of the modules that is to the lines of code.
for coarse grained modules such as packages and files it seems acceptable to consider the sizes of the modules as effort.
however for methods it may not be acceptable.
for example although methods are small they might require much more effort than big methods because of the context of the methods such as complex call relations or other deep dependencies.
discussing these threats is also important for further finegrained prediction.
when we consider only the sizes of the modules as efforts we can hypothesize that blocklevel or line level prediction is more effective than metho d level prediction for finding bugs.
however this hypothesiz e should not be acceptable.
because of this threat we need empirical studies of the actual effort such as times needed and cumulative loc of the code we need to inspect by conducting actual quality assurance activities with diffe rent prediction levels.
vii.
c onclusion this paper conducted fine grained bug prediction which is a method level prediction on java software based on recently proposed historical metrics.
using eight open sou rce projects package level file level and method level pre diction models were compared based on effort based evaluation .
the findings from our study are as follows.
method level prediction is more effective than package level and filelevel prediction when considering efforts.
this is because predicted buggy packages and files contain many non buggy packages and files.
from the correlation analysis we found that past bug information on methods does not correlate with post bugs in methods and organizational metrics may not contribute to method level prediction.
code related metr ics have positive correlations and interval related metrics h ave negative correlations.
effort based evaluation may not reflect actual efforts.
therefore in the future we will also use well designed effort calculation or an empirical study of the actual effor ts should be required.
correlation analysis is also needed for further study.
to discuss the correlations between post bug s and historical metrics we need more various type projects to study.
in addition we want to compare fine grained historical metrics with complexity metrics on methods.
acknowledgment this research is supported by a grant in aid for jsps fellows no.
and a grant in aid for scientific research c japan.