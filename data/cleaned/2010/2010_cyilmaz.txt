combining hardware and software instrumentation to classify program executions cemal yilmaz sabanci university faculty of engineering and natural sciences istanbul turkey cyilmaz sabanciuniv.eduadam porter university of maryland college park md aporter cs.umd.edu abstract several research e orts have studied ways to infer properties of software systems from program spectra gathered from the running systems usually with software level instrumentation.
while these e orts appear to produce accurate classi cations detailed understanding of their costs and potential cost bene t tradeo s is lacking.
in this work we present a hybrid instrumentation approach which uses hardware performance counters to gather program spectra at very low cost.
this underlying data is further augmented with data captured by minimal amounts of software level instrumentation.
we also evaluate this hybrid approach by comparing it to other existing approaches.
we conclude that these hybrid spectra can reliably distinguish failed executions from successful executions at a fraction of the runtime overhead cost of using software based execution data.
categories and subject descriptors d. .
debugging aids general terms reliability measurement experimentation keywords hardware performance counters failure detection software quality assurance.
.
introduction in recent years numerous researchers have proposed datadriven techniques to improve the quality of deployed software.
at a high level these techniques typically follow the general approach of lightly instrumenting the software system monitoring its execution analyzing the resulting data and then acting on the analysis results.
some example applications of this general approach include identifying likely permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
fse copyright 200x acm x xxxxx xx x xx xx ... .
.fault locations anticipating resource exhaustion and categorizing crash reports as instances of previously reported bugs .
another speci c application which is the focus of this paper is determining whether execution data taken from a deployed system comes from a failed or a successful execution.
following the approach described above existing solutions to this problem typically add instrumentation to the system source code or binaries that collect speci c types of execution information called program spectra whenever the system runs.
this data is periodically collected and analyzed.
these analysis techniques attempt to identify patterns in the returned program spectra that are highly correlated with failed executions.
the resulting models can later be applied to new executions taken from deployed software instances whose failure status is unknown as a way of classifying whether the original execution failed.
such information can then be used for instance to determine whether the deployed software system is experiencing an already reported bug.
one fundamental assumption these and similar approaches is that there are identi able and repeatable patterns in the behavior of successful and failed executions and that similarities and deviations from these patterns are highly correlated with the presence or absence of failures.
previous e orts in fact appear to support this assumption successfully applying a variety of program spectra to classify failed program executions .
another less well understood issue however is how best to limit the total costs of implementing these approaches and whether and how tradeo s can be made between cost and classi cation accuracy.
this issue is important because these approaches have been targeted at deployed software systems excessive runtime overhead is generally undesirable.
therefore it is important to limit instrumentation overhead as much as possible while still supporting the highest levels of classi cation accuracy.
in general previous e orts have tended to either ignore this problem or have appealed to various sampling strategies see section for a solution.
one potential drawback of sampling however is that aggressive sampling schemes greatly increase the numbers of observations that must be made in order to have con dence in the data.
while we believe that sampling can be a powerful tool we also conjecture that large cost reductions may derive from reducing the cost of the measurement instruments themselves.
to evaluate this conjecture we have designed and evaluated an improved approach in which most of the datacollection work is performed by fast hardware performance counters.
the data is augmented with further data collected by a minimal amount of software instrumentation that is added to the system s software.
we contrast this approach with other approaches implemented purely in hardware or purely in software.
our empirical evaluation conducted on four open source projects suggests that for the systems used our hybrid hardware and software instrumentation approach was as good or better than other approaches in distinguishing failed executions from successful executions and it did so at a fraction of the cost of using purely software based instrumentation.
.
related work classifying program executions.
several researchers have studied how to predict program execution behaviors from program spectra.
to our knowledge all of these e orts used software spectra program spectra collected purely by software instrumentation as their execution data.
podgurski and colleagues present a set of techniques for clustering program executions.
for example in one e ort they used cluster analysis to group program executions in deployed instances.
they showed that the individual clusters tended to include execution pro les stemming from the same failures.
bowring rehg and harrold used markov models to classify program spectra as coming from either successful or failed executions.
their approach uses software instrumentation and requires probes at every branch in a system.
brun and ernst used two machine learning approaches to identify observed likely program invariants that tended to be present during faulty program runs.
this approach computes very detailed abstractions at many program points and is thus quite expensive.
jones and harrold and staska use statement coverage information to identify likely causes of failures.
chen et al.
track the software components used in computations and leverage that data for problem determination.
we provide a comparison of the proposed approach to similar types of program spectra used by jones and chen in the experiments section.
reducing data collection overhead.
other research has extended earlier work with some consideration for limiting instrumentation overhead.
liblit and colleagues transform the source of software systems to e ciently sample execution data collected from users and use this data to perform fault localization.
the rewriting process however signi cantly increases the size of the system code and imposes a signi cant memory overhead.
in addition the noise created by sampling must be balanced by instrumenting very large numbers of deployed instances which may not be possible for some applications.
haran et al.
developed several techniques for classifying execution data as belonging to one of several classes.
each technique works by instrumenting a set of deployed instances.
each instance in this set however captures only a small subset of the program spectra and that subset is di erent from that captured by all other instances.
the goal is to create a combined data set that captures enough information to allow accurate classi cations.
yilmaz et al.
present a related approach called time will tell twt .
in this work they used minimal amounts of software instrumentation to capture time spectra i.e.
traces of method execution times .
their empirical evaluations suggested that coarse grained execution data could e ectively capture patterns in executions.hardware based pro ling.
another way to cut instrumentation overhead is to do all data collection at the hardware level.
anderson et al.
present a lightweight pro ling technique done entirely with hardware performance counters.
while the program is running they randomly interrupt it and capture the value of the program counter.
using this information they statistically estimate the percentage of time each instruction is executed.
assuming the program runs long enough they can generate a reasonably accurate model with overheads of less than .
an open question with this work is whether it can be extended to other types of data spectra and analysis purposes.
one reason for the uncertainty is that their approach has no way to associate execution data back to program entities.
in general it is almost always possible to collect quite detailed data from program executions which is the case with some of the existing approaches discussed above to distinguish failed executions from successful executions.
however the runtime overhead required to collect such data often makes it impractical.
in this work we aim at nding a sweet spot between the accuracy of classi cations and runtime overheads.
.
combining hardware and software instrumentation in this article we design and evaluate an improved approach to classifying program executions that is both e ective and inexpensive.
speci cally we use hardware counters to collect raw data but we also use lightweight software instrumentation to associate subsets of the hardware collected data with speci c program entities.
hardware performance counters are hardware resident counters that record various events occurring on a processor.
today s general purpose cpus include a fair number of such counters which are capable of recording events such as the number of instructions executed the number of branches taken the number of cache hits and misses experienced etc.
to activate these counters programs issue instructions indicating the type of event to be counted and the physical counter to be used.
once activated hardware counters count events of interest and store the counts in a set of special purpose registers.
these registers can also be read and reset programmatically at runtime.
one challenge we encountered when rst using hardware performance counters to collect program execution data was that the counters do not distinguish between the instructions issued by di erent processes.
to deal with this we used a kernel driver called perfctr linux.softpedia.com which implements virtual hardware counters that can track hardware events on a per process basis.
a second challenge was that hardware performance counters have limited visibility into the programs being executed e.g.
by themselves they do not know for example to which program function the current instruction belongs.
as described in more detail in section .
raw hardware spectra are generally too coarse to be useful in classifying executions.
to improve this situation we chose to associate hardware spectra with function invocations.
that is we use traditional software instrumentation to indicate which function is currently executing so that di erent subsets of the hardware spectra are properly associated with that function.
while we opted to track program execution data atthe function level the techniques are equally applicable to other granularity levels.
thus at a high level our approach in its simplest form works as follows a hardware counter of interest is activated at the beginning of a program execution the value of the counter is read before and after each function invocation and the di erence is attributed to the invocation and the counter is deactivated at the end of the execution.
note that hardware counters are always active during executions.
early experimentation with a prototype implementation uncovered further issues.
first one key cost driver is the use of software instrumentation that causes very expensive context switching.
in this work we mainly use one instruction called rdmpc which enables us to read the values of physical counters from user space without causing an os context switch.
for example to compute the value of a virtual counter we record two values sumand start at each instrumentation site for later processing in addition to the current value of the physical counter now .
the sum variable stores the total number of events observed in the current process from the start up to the last process switch involving the process.
the start variable records the value of the physical counter at the time of the last process switch.
once these values are known the value of a virtual counter is computed as now start sum.
the perfctr driver used in this work augments the os level context switch code to store the start andsumvalues at suspends and restore them at resumes.
furthermore this driver provides a view of these values in user space.
consequently reading the value of a virtual counter can be done fast without requiring any further expensive os context switching.
to give an example based on performing a million counter read operations we observe that it takes clock cycles on average to read the value of a virtual counter on our test platforms.
even if the cost of reading counters is low another cost driver is the raw number of times the counter values need to be read.
therefore to further reduce overhead we in this work chose not to pro le functions that are invoked more than 50times nor those that invoke more than 50other functions.
note that the hardware counters are still active during the execution of unpro led functions the hardwarespectra is just associated with function that calls these unpro led functions.
the cuto value was chosen so that functions that account for the vast majority of invocations were ltered.
the information required for this purpose was obtained by analyzing the histograms of function invocation counts observed in our experiments.
furthermore we chose to ignore functions that handle already detected failures e.g.
error ... and fatal ... .
we do this because these function invocations are the effect of failures and thus not useful in understanding failure causes which is often the scenario for which failure classi cation is done .
in the rest of the paper these ltering steps are referred to as global function ltering.
.
a simple feasibility study combining hardware and software instrumentation clearly adds some additional context to hardware spectra.
nevertheless the underlying hardware spectra which are based on commonly available hardware performance counters are inherently less exible than programmable software spectra.
as a result it is unclear whether combined spectra provide data that can be used to accurately classify executions.
8000pass fail info.
vs. instruction count number of machine instructions executedpass fail info data fail passfigure classi cation of the number of instructions executed in the socket function.
as a simple test we therefore conducted a rudimentary feasibility study using the socket system call as our subject.
the socket function creates an endpoint i.e.
socket for communication.
we experimented with two parameters that this function takes as input domain and type.
the domain parameter speci es a communication domain e.g.
inet and inet6 and the type parameter speci es the communication semantics e.g.
connection based and connectionless .
these parameters take a value from a set of eleven and six discrete settings respectively.
for this system we created test cases that exhaustively exercised all combinations of the parameters settings.
for each input combination we measured the number of machine instructions executed during the invocation of the function.
since not all input combinations were supported on our test platform of the test cases failed.
figure depicts a simple hardware spectra we obtained.
the horizontal axis depicts the number of machine instructions executed and the vertical axis denotes the entire data as well as the data obtained from the failed and successful executions.
using this data we asked whether this simple hardware spectra could be used to classify executions in which the requested socket failed to be created?
as can be seen from the gure even using only one simple hardware counter the di erence between the successful and failed invocations is immediately apparent failed invocations execute either many fewer or many more machine instructions compared to those of successful invocations.
training a classi cation model for our observations using the weka s j48 algorithm and testing it on previously unseen executions provided an f measure of 98in predicting the failed invocations.
with manual analysis we determined that the failed invocations that executed few instructions did so because of a simple check at the very top of the function that immediately returns an error code if the parameters provided are not within the supported range.
the failed invocations that executed more instructions on the other hand did so because theirsubject number of number of number of total passing failing application loc functions versions defects tests tests tests grep ex sed gcc unknown table subject applications used in the experiments.
failures caused the kernel to immediately release all previously allocated resources.
successful executions in contrast hold on to resources until the socket is explicitly closed.
although this simple demonstration is by no means conclusive it encouraged our belief that program spectra gathered from hardware performance counters can capture useful data that can be used to reliably detect failures.
.
experiments to evaluate the accuracy and e ectiveness of hardwarebased spectra in distinguishing failed executions from successful executions we conducted a set of experiments using four open source real life applications as our subject applications.
this section reports on our experiments.
.
independent variables we manipulated two independent variables in our experiments.
program spectrum type.
this variable has six different levels.
the rst three program spectra are collected using hardware performance counters 2tot ins counts the number of machine instructions executed 2brn tkn counts the number of branches taken 2lst ins counts the number of load and store memory instructions executed the three remaining spectra are gathered using traditional software pro ling 2call swt records the functions invoked 2stmt freq counts the number of times the source code statements are executed 2time measures execution times of functions at the level of nanoseconds although numerous types of software based spectra have been proposed in the literature we chose to use these four types for several reasons.
first each has been successfully used in the literature for related purposes .
second each is representative of a variety of related spectra in terms of the runtime overhead they impose.
for example the overheads of collecting the call swt and stmt freq spectra can be viewed as lower bounds on collecting simple function level and detailed statement level execution data respectively.
similarly the overhead of collecting the time spectra can be viewed as a lower bound on collecting simple execution data that requires os context switches we used system calls to compute the execution times in this work.dynamic call tree depth to be pro led.
we used six di erent dynamic call tree depths and all as a cuto point for our instrumentation.
for a depth d only the function calls that happen when the call stack depth is less than or equal to dare pro led.
when d only the main function is pro led and when d all all the function invocations of interests are pro led.
note that hardware counters are always active during an execution.
hardware spectra data for function invocations occurring at depth d are simply associated with the function invocation at depth d. .
subject applications we used four open source subject applications in our experiments grep flex sed and gcc.
these widely used applications print lines matching a pattern generate fast lexical analyzers lter and transform text as a stream editor and compile c programs respectively.
table provides some descriptive statistics for the subject applications.
the rst three subject applications were taken from the software artifact infrastructure repository sir .
the sir repository provided us with several versions of these subject applications with known defects.
the gccapplication used in the experiments was the o cial release of the gnu compiler collection version .
each subject application came with its own test suites and oracles which we used in the experiments.
.
operational model to conduct our studies we executed the test suites of our subject applications collected the spectra from these executions.
for each run we measured the overhead incurred by our data collection instrumentation.
next we determined whether each execution was successful or failed using the test oracles that came with the suites.
after that we created classi cation models for each combination of subject program version spectrum type and depth of dynamic call tree being pro led.
once the data was collected we created and evaluated the classi cation models by using the weka s j48 classi cation algorithm with ve fold strati ed cross validation .
that is the evaluation of the models was performed on previously unseen executions.
to evaluate the runtime overhead induced by collecting various types of spectra we compare the execution times of programs with and without pro ling and compute the overhead as follows overhead exec time w prof exec time w o prof exec time w o prof to evaluate the accuracy of classi cation models we use several standard metrics.
precision p and recall r aretwo widely used metrics to assess the performance of classi cation models.
for a given testing table t we de ne them as follows recall of correctly predicted failed executions in t total of failed executions in t precision of correctly predicted failed executions in t total of predicted failed executions in t since neither measure predominates our evaluation we combine these measures using the f measure.
this is de ned as f measure b2 pr b2p r here bcontrols the weight of importance to be given to precision and recall f pwhen b 0andf rwhen b .
throughout the paper we compute f measure with b which gives precision and recall equal importance and use it to evaluate the classi cation models.
.
experimental setup the software instrumentation used in associating hardware spectra with function invocations was implemented via binary instrumentation using gnu s c extension framework for instrumentation i.e.
gcc s finstrument functions option .
the same approach was also used to collect the time and call swt spectra.
the stmt freq spectra on the other hand were collected using gnu s gcov test coverage tool.
we modi ed the implementation of this tool to support selective instrumentation so that coverage information was computed only for the functions of interests.
to compute runtime overheads we dedicated one cpu of a dual cpu system to execute the test cases using sched setaffinity and other related system calls .
no other user level programs were allowed to run on the dedicated cpu.
we furthermore measured execution times at the level of nanoseconds in terms of the cpu allocation time using the k best measurement scheme .
all the experiments were performed on a dual intel processor machine with 2gb of ram running the centos .
operating system.
all told our data set is comprised of 922total test cases run across defective versions of our subject applications .
these defective versions were culled from an set of defective versions using the criteria that the ratio of failed to successful executions was between 05and .
we did this because classi cation techniques themselves either perform poorly or need special enhancement when one class is much more common than the other.
since our goal is not to evaluate classi cation techniques themselves we ignore these cases for our analysis.
for our evaluations we created a total of 850classi cation models versions x6 spectra types x5 call tree depths x5 fold cross validation .
.
data and analysis the following sections present and discuss some of our results.
f measure vs. spectrum typef measure spectrum type0 .
.
.
.
.
.
.
.
.
.48call swt stmt freq time tot ins br tkn lst insfigure f measure vs. spectrum type hardware and software spectra .
.
hardware and software spectra our rst study examined the accuracies and overheads provided by hardware and software spectra.
to collect the hardware spectra we activated one hardware counter of interest read the value of the counter at the beginning and at the end of an execution and associated the di erence with the execution.
note that hardware counters were read only twice for each program execution in this study.
this scenario corresponds to pro ling with d .
to collect the software spectra we rst enabled our global function lters section and then pro led all the remaining functions to collect one type of program spectra.
since this process ignores the depth of the call stack it corresponds to pro ling with d all.
for these subject programs and test cases global function ltering prevented of the invocations on average from being pro led.
the last three columns of table present the runtime overheads incurred by each of the hardware spectra used in our experiments.
for this study the rows marked as d are relevant.
as the table indicates the overheads ranged from to about .
that is the runtime overheads attributable solely to hardware performance counters were under .
the rst three columns of table present the overheads incurred by each of the software spectra used in the experiments.
the relevant data are in the rows where d all.
the call swt spectrum which simply records the list of called functions incurred overheads of about to .
the two remaining software counters incurred higher overheads ranging from about .
to about .
figure plots f measures of classi cation accuracy we obtained for this study.
each box in this plot illustrates the distribution of f measures obtained from a spectrum type.
the lower and the upper end of a box represents the rst and the third quartiles and the horizontal bar inside represents the median value.
numbers given below the boxes indicate the mean values and are visualized as lled circles.sut call swt stmt freq time tot ins br tkn lst ins d overhead d overhead d overhead d overhead d overhead d overhead grep0 n a n a n a .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
all .
all .
all .
all .
all .
all .
ex0 n a n a n a .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
all .
all .
all .
all .
all .
all .
sed0 n a n a n a .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
all .
all .
all .
all .
all .
all .
table runtime overheads.
f measure vs. spectrum type depth dall f measure spectrum type0 .
.
.
.
.
.
.
.
.
.86call swt stmt freq time tot ins br tkn lst ins figure f measure vs. spectrum type depth all .
the figure shows that even though hardware spectra were inexpensive they were not very e ective in classifying executions.
in fact the classi cation models created using the hardware spectra collected in this study predicted failed executions with an average f measure of only .
note the expected value of the f measure varies depending on the ration of successful to failing executions but for our studies random assignment would give f measures between about .
and about .
.
the figure also shows that the fmeasures for software spectra were generally higher ranging from .
for call swt to .
stmt freq and .
time .
overall we see that the hardware spectra were very inexpensive but inaccurate.
for the software spectra one f measure vs. overhead overheadf measure .
.
.
.
.
.
.
.
.
.
.
.85call swt software stmt freq software time software tot ins hardware br tkn hardware lst ins hardware tot ins hybrid br tkn hybrid lst ins hybrid figure f measure vs. overhead.
call swt was also very inexpensive and had moderate accuracy.
the remaining software spectra were more accurate but incurred substantially more overhead.
.
associating data with function invocations to improve classi cation accuracy while limiting instrumentation overhead we decided to combine hardware and software instrumentation.
the general idea is to collect most of the data using hardware counters but to use software instrumentation to assign that data to speci c program entities.
to evaluate this idea we made several changes to our procedures and then repeated the previous study the rst change was that we used software instrumentation to asso ciate hardware collected data with individual function invocations.
speci cally we inserted code into the programs that read the value of the appropriate hardware counter at the beginning and at the end of each invocation.
we then attributed the di erence to that invocation.
since this process ignores the depth of the call stack it corresponds to pro ling with d all.
table presents the runtime overhead incurred by each type of performance counter.
the data relevant for this study appear in rows marked depth all.
here we see that the overhead incurred by our combined hardware and software approach ranged from about .
for grep to about .
for sed.
these levels of overhead indicate that even minimal software instrumentation increased overhead by a factor of but that the total overhead was nonetheless substantially smaller than that incurred with more sophisticated software instrumentation approaches.
figure depicts the f measures of classi cation accuracy we obtained for this study.
our rst observation is that associating hardware counters with function invocations significantly boosted classi cation accuracy over plain hardware spectra.
here the average f measure increased from 46to .
figure provides an integrated view of the costs and bene ts of using hardware software and hybrid spectra.
one observation is that for comparable overhead levels the hybrid spectra were signi cantly better at detecting the failures than the hardware or software spectra used in the study.
for example compared to the call swt spectrum where the average overheads were almost the same hybrid spectra provided signi cantly better f measures an average f measure of 85vs respectively.
alternatively for comparable accuracy levels the hybrid spectra induced signi cantly less overhead see also the rows where d allin table .
for example the hardware spectra and the stmt freq spectra have similar f measures 85vs 83on average respectively.
however the hybrid spectra incurred a fraction of the overhead incurred by the stmt freq spectrum.
the runtime overhead was 015on average for the hybrid spectra and 159for the stmt freq spectrum.
this corresponds to about fold reduction in the runtime overhead.
.
using structural sampling as discussed in section several previous research e orts have use sampling strategies to further reduce pro ling overhead.
many of these strategies are implemented by pro ling only a carefully chosen small subset of all the potential measurement locations.
we call this technique structural sampling to distinguish it from statistical sampling where logically all measurement locations are instrumented but the instruments are enabled with certain probabilities.
note however that even statistical approaches are sometimes implemented via structural sampling.
speci cally code sections are duplicated and copied into both instrumented and uninstrumented paths .
while sampling certainly reduces overhead it may have a negative e ect on classi cation accuracy especially when the number of instrumented systems is low and or when failure frequencies are low.
in this study we evaluated the overhead and accuracy of classifying executions when execution data is acquired via a structural sampling approach.
to carry out the study we used the following simple sampling approach.
we onlypro le function invocations when they occur at or below depth din the dynamic call stack where d .
note however that our hardware counters were always activate during executions.
if a function invocation occurs at depth greater than d the resulting data is not associated with the current invocation but is associated with the calling function at depth din the dynamic call stack.
furthermore to focus on areas in which the loss of precision might cause a resulting loss of classi cation accuracy we considered only those faults that were exercised at a depth greater than d. these defects were identi ed by manually marking the depths at which the underlying faults were executed and then choosing those that satis ed the condition.
all other faults were ignored.
in this study we did not observe signi cant overhead reduction by employing our structural sampling approach .
this was because after enabling our global function lters the number of functions pro led at di erent depths were close to each others.
figure depicts the classi cation accuracies observed in this study.
as the gure indicates the hybrid spectra were indistinguishable from software spectra when dwas low d 1andd .
as depth increased the hybrid spectra generally displayed greater accuracy.
referring back to figure however we note that when d all software spectra were as accurate as hybrid spectra.
referring to table we also note that hybrid spectra incurred a fraction of the overhead cost compared to that of the software spectra.
for example when d the average f measure is 72with an overhead of0 015for the combined spectra and 29with an overhead of0 154for the stmt freq spectrum.
to better understand these results we manually analyzed the resulting classi cation models.
one reason for which the classi cation models created from hybrid spectra outperform those created from software spectra is that the hybrid spectra summarize rather than ignore unpro led functions.
that is when using hardware performance counters we associate the execution data for functions that are called at a level greater than dwith the parent function at depth d. in a sense hardware counters were able to collect some information from the uninstrumented parts of the programs.
visual inspection of the classi cation models con rmed that the calling functions at level dbecome the key indicators of failures.
on the other hand the software spectra such as the stmt freq spectra su ered greatly because they completely ignore uninstrumented parts of the code.
.
different defect types while studying the classi cation models obtained in the previous study we observed several cases in which software spectra outperformed our hybrid spectra and vice versa.
for example the stmt freq spectra when d 1performed better than the hybrid spectra.
we discovered that our subject applications often perform certain types of error checking at depth one and two such as checking to see if the return values of function calls indicate an internal failure.
of course if one of these checks fails it is a perfect indicator of a failure.
in these cases stmt freq spectra were faultless in predicting failures.
however many failures are not internally detected by our subject applications.
in these cases software spectra tended to perform poorly e.g.
when d .
to further investigate potential relationships between ac f measure vs. spectrum type depth d1 f measure spectrum type0 .
.
.
.
.
.
.
.
.
.20call swt stmt freq time tot ins br tkn lst ins a f measure vs. spectrum type d .
f measure vs. spectrum type depth d2 f measure spectrum type0 .
.
.
.
.
.
.
.
.
.55call swt stmt freq time tot ins br tkn lst ins b f measure vs. spectrum type d .
f measure vs. spectrum type depth d3 f measure spectrum type0 .
.
.
.
.
.
.
.
.
.75call swt stmt freq time tot ins br tkn lst ins c f measure vs. spectrum type d .
f measure vs. spectrum type depth d4 f measure spectrum type0 .
.
.
.
.
.
.
.
.
.69call swt stmt freq time tot ins br tkn lst ins d f measure vs. spectrum type d .
figure failure prediction f measure vs. spectrum type depth f1 g .
curacy and failure characteristics we performed the following additional study.
working with three graduate students at sabanci university we asked them to examine each known defect in our subject programs and categorize them into of categories.
these categories are laid out by the sir repository that categorizes each defect into one of the three broad defect types type type and type .
type defects cover the defects that stem from the errors made on variable assignments such as using erroneous values for variables and passing incorrect parameters to functions.
type defects represent the errors made on the control ow of programs such as missing a function call and using incorrect branching conditions.
type defects on the other hand depict the errors made on memory operations such as pointers related errors.
we then used a voting scheme to resolve con icting categorizations.
further inconsistencies were handled on a case spectrum type type call swt .
.
stmt freq .
.
time .
.
tot ins .
.
brtkn .
.
lst ins .
.
table average f measures obtained on di erent types of defects.
by case basis.
out of defects used in the experiments defects were categorized into type another into type and only defect into type .
since we happened to have only one type defect we leave it out of discussion in this section.depth call swt stmt freq time tot ins f measure overhead f measure overhead f measure overhead f measure overhead .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
all .
.
.
.
.
.
.
.
table results obtained from the gccexperiments.
table depicts the average f measures obtained for different types of defects.
note that the f measures used in this table are adopted from section .
.
we observed that the hybrid spectra were generally more accurate than the software spectra across both defect types.
that is di erent types of defects did not cause any noticeable di erences between the relative accuracies of the hybrid and software spectra.
furthermore each spectrum type was better at classifying type failures than type failures.
we observed that type defects by directly changing the control ow of programs often caused pronounced di erences in the paths taken by the failed and successful executions.
these di erences re ected on the stmt freq spectrum for example as a set of suspicious source code statements executed and on the combined spectra as a set of suspicious amount of computational activities performed.
it turned out that it was much easier for the spectrum types used in the experiments except for call swt to detect such di erences compared to the ones caused by type defects.
.
replication with gcc the studies discussed so far involved medium sized applications.
in this study we evaluated our approach on larger gnu compiler collection gcc version .
for this study we collected the call swt stmt freq time and tot ins spectra at various levels of granularity.
we then used this data to classify failing and successful executions.
as we do not know the actual causes of the failures for gcc we could not manually verify the speci cs of the resulting classi cation models as we did in our previous studies.
in these experiments we only pro led the cc1component of the compiler.
this is the core component of the gcc compiler and is responsible for compiling source code into assembly language.
we executed a total of test cases out of which of them failed and of them passed.
as with the rest of the experiments we rst applied our global function lters section .
this prevented pro ling around of the total function invocations.
as with our previous studies we also did not pro le functions that are called only after an internal failure has been detected.
table depicts the overheads and f measures observed in this study.
in general these results are consistent with those obtained on the smaller scale applications used in our previous studies.
looking at the overhead data we observe that while the cost of pro ling for the tot ins spectrum in this study was similar to the ones obtained in other studies the stmt freq spectrum imposed signi cantly higher costs.
a manual investigation revealed that one reason for the variation was that the gccapplication often executed more statements per function invocation compared to the rest of the subject applications.compared to the stmt freq spectrum when d all the tot ins spectrum provided similar f measures at a fraction of the cost an average f measure of 81with an overhead cost of 014for the tot ins spectrum and an average f measure of 82with an overhead cost of for the stmt freq spectrum.
alternatively compared to the call swt spectrum where the overhead costs are similar the tot ins spectrum provided signi cantly better f measures an f measure of 81vs.
.
furthermore the tot ins spectrum was better at predicting the failures at almost all granularity levels of pro ling compared to the software spectra.
.
concluding discussion several research e orts have studied how to infer properties of executing software systems from program spectra.
these e orts appear to produce accurate results but the issue of costs is less well understood.
in this article we examined a novel approach for instrumenting software systems to support execution classi cation.
this approach combines low overhead but coarsegrained hardware spectra with minimal amounts of higher overhead software instrumentation to create a hybrid spectra.
we also evaluated this approach and compared it against other representative approaches.
in the experiments we used three di erent types of hybrid spectra and three di erent types of software spectra.
we compared the cost and accuracy of the hybrid spectra to those of the software spectra.
before discussing the results of these evaluations we remind the reader that all empirical studies su er from threats to their internal and external validity.
for this work we are primarily concerned with threats to external validity since they limit our ability to generalize our results.
one threat concerns the representativeness of the subject applications used in the experiments.
although they are all real life applications they only represent four data points.
a related threat concerns the representativeness of the defects used in the experiments.
although the grep flex and sedapplications were taken from an independent defect repository which has been leveraged by many related studies in the literature and the gccapplication was an o cial release of a frequently used compiler they only represent a subset of defects.
keeping these limitations in mind we believe that our study supports our basic hypothesis that our hybrid spectra approach incurs low overhead but still produces data that generates accurate classi cation models.
we arrived at this conclusion by applying our approach to several medium sized subject systems.
based on this we rst observed that for our subject systems test cases and choices of program spectra hardware only spectra had lowoverhead but led to inaccurate classi cation models while software only spectra had high overhead but led to accurate classi cation models.
next we compared the hybrid spectra to hardware only and to software only spectra.
compared to hardware only spectra our hybrid spectra however added little additional overhead while greatly increasing classi cation accuracy.
compared to software spectra our hybrid approach had equivalent accuracy but greatly reduced overhead.
we also observed that limiting pro ling according to depth of the call stack did not greatly a ect the runtime overhead of collecting the various program spectra.
this was primarily due to the fact that we had already applied global function ltering which already reduced the number of function invocations pro led by around .
the accuracy of the hybrid spectra appeared to degrade more slowly than did that of the other spectra but more studies are needed.
after this we observed that all the program spectra based approaches we studied were better at classifying failed executions stemming from failures that changed control ow rather than those that caused by incorrect data usage.
from this perspective the hybrid spectra was no di erent from the hardware only or software only spectra.
finally we replicated most of our initial studies on a larger system gcc.
this study was consistent with our previous ndings.
this further supports our hypothesis that hybrid spectra can be both lightweight and yield accurate execution classi cations.
we believe that this line of research is novel and interesting.
we are therefore continuing to investigate how hybrid hardware and software based instrumentation can serve as abstraction mechanisms for program executions in various software quality assurance approaches such as fault localization failure prediction security assurance and in the eld quality assurance approaches.
.