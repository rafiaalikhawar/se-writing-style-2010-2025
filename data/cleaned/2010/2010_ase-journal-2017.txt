automated software engineering manuscript no.
will be inserted by the editor lightweight control flow instrumentation and postmortem analysis in support of debugging peter ohmann ben liblit february abstract debugging is difficult and costly.
as a programmer looks for a bug it would be helpful to see a complete trace of events leading to the point of failure.
unfortunately full tracing is simply too slow to use after deployment and may even be impractical during testing.
we aid post deployment debugging by giving programmers additional information about program activity shortly before failure.
we use latent information in postfailure memory dumps augmented by low overhead tunable run time tracing.
our results with a realistically tuned tracing scheme show low enough overhead to be used in production runs.
we demonstrate several potential uses of this enhanced information including a novel postmortem static slice restriction technique and a reduced view of potentially executed code.
experimental evaluation shows our approach to be very effective.
for example our analyses shrink stack sensitive interprocedural static slices by in larger applications.
keywords postmortem program analysis debugging core dumps static program slicing path tracing coverage introduction debugging is a difficult time consuming and expensive part of software development and maintenance.
debugging testing and verification account for of a software project s cost hailpern and santhanam these costs grow even higher in some cases gauf and dustin tassey .
yet post deployment p. ohmann university of wisconsin madison e mail ohmann cs.wisc.edu b. liblit university of wisconsin madison e mail liblit cs.wisc.edu2 peter ohmann ben liblit failures are inevitable in complex software.
when failures occur in production detailed postmortem information is invaluable but difficult to obtain.
developers would benefit greatly from seeing concrete traces of events leading to failures failure focused views of the program or program state or suggestions of potentially faulty statements.
sadly full execution tracing is usually impractical for complex programs.
even for simple code full tracing overhead may only be acceptable during in house testing.
one common and very useful artifact of a failed program execution is a core memory dump.
coupled with a symbol table a core dump reveals the program stack of each execution thread at the moment of program termination the location of the crash the identities of all in progress functions and program locations from which they were called the values of local variables in these in progress functions and the values of global variables.
prior work with symbolic execution has shown that this information can help in deriving inputs and or thread schedules that match a failed execution r ler et al weeratunge et al zamfir and candea .
our goal is to support debugging using latent information in postmortem core dumps augmented by lightweight tunable instrumentation1.
this paper explores four such enhancements a variant of ball larus path profiling function coverage statement coverage and call site coverage.
we evaluate the trade offs among these tracing methods and conclude that pairing our path profiling variant with callsite coverage yields a complementary realistic and valuable choice for deployed applications.
our results for this pairing with a realistically tuned tracing scheme show low overheads execution time dynamic memory suitable for production use.
we also demonstrate a number of potential preprocessing debugging uses of this enhanced information including a unique hybrid program slicing restriction and a reduction of potentially executed control flow graph nodes and edges.
these postmortem analyses can take advantage of all of our core dump enhancement tracing mechanisms.
for example one of our evaluated applications space crashes within a loop in a complex function containing many branches and a large switch statement.
the bug is a missing exitstatement within one switch case.
our analysis is able to provide the complete branch trace within the crashing function reducing the possible set of executed statements by over .
this benefit comes at a tracing time overhead of just .
relative to uninstrumented code.
this is a simple intraprocedural example section indicates that our approach often performs even better on larger more complex interprocedural cases.
this paper expands upon our previous conference paper ohmann and liblit in several ways.
first we provide discussion and experimental results for varying granularities of program coverage tracing at functions call sites and statements whereas ohmann and liblit only discussed call site coverage.
section .
.
details this change and provides examples.
second and partly due to these extended tracing options in this paper we more strongly emphasize the difference between our instrumentation which is static and our run time tracing which is customizable .
we introduce the notion of a scheme to describe a possible tracing configuration 1source code is available at .lightweight control flow instrumentation and postmortem analysis in support of debugging linker codesurfer coverage info executable path info sdg crash fix graph unused core file paths combined graphsource source instrumentor instrumentor object metadata object metadata per frame line sequences correspondence per frame node sequencesglobal unused stmts per frame unused stmts intra analysis inter analysis fig.
overview of data collection and analysis stages.
sharp cornered rectangles represent inputs and outputs rounded rectangles represent computations.
and provide a more in depth discussion of this topic.
see section for details.
third with more instrumentation choices due to the added forms of program coverage we provide some discussion of and a new approach to customization of tracing post deployment see section .
.
further changes involve our analyses and evaluation.
first we provide a more detailed discussion of our control flow node and edge reduction analysis see section .
.
second we evaluate our techniques in much greater detail.
specifically we evaluate each tracing mechanism including all coverage types independently along with tracing schemes combining multiple mechanisms including the realistic scheme from ohmann and liblit .
we also assess the effect of post deployment customization support on our tracing overhead.
see sections .
and .
for details.
third we provide an in depth discussion of sources of ambiguity that we encounter in our analysis framework.
note that ambiguity in our results is expected we intentionally sacrifice full trace detail to reduce run time overhead.
however the fact that we use two independent pieces of software for pre instrumentation and post crash analysis results in additional ambiguity for matching trace data to analysis program representations .
section .
.
contains full details.
finally we set further context for our work we discuss threats to the validity of our experiments section and provide a more extensive discussion of our future work plans section .
peter ohmann ben liblit void add action char new text intlen strlen new text while len index size intnew size size if new size size size else size new size array realloc char arr array size strcpy array new text index len a code examplea b c d e f g b control flow graph fig.
example code figure shows the relationships between our instrumentation and analyses each feature of this diagram is described in the sections that follow.
we begin with a motivating example in section then review key background material in section .
section describes the kinds of data we collect and our instrumentation strategies for so.
section gives a detailed description of the analyses we perform on collected data.
we assess instrumentation overhead and usefulness of analysis results in section .
section discusses possible threats to the validity of our results.
sections and discuss related work and opportunities for future research.
section concludes.
example figure shows an example we will refer to throughout the paper.
the source code in figure 2a is taken from flex one of the applications used for evaluation in section .
most often we will make use of the function s intraprocedural control flow graph cfg representation shown in figure 2b.
background we begin by describing core dumps and their benefits for postmortem debugging.
we then review a well studied path profiling approach by ball and larus the present work develops a variant of this approach.
finally we briefly outline program slicing which serves as the basis of one of our analyses.lightweight control flow instrumentation and postmortem analysis in support of debugging .
core memory dumps all widely used modern operating systems can produce a core dump file containing a snapshot of a program s memory.
a dump may be saved after abnormal program termination due to an illegal operation such as using an invalid pointer or on demand such as by raising a fatal signal or failing an assertion .
this can be useful if the core dump is to be used for postmortem analysis.
typically a core dump includes the full program stack at termination.
for our purposes the key elements are the point of failure the exact location of the program crash as well as the final call location in each other still active frame on the stack i.e.
each stack frame s return address .
conveniently core dumps are only produced in the case of program failure.
thus collecting them imposes zero run time overhead.
this is a key advantage to using core dumps for postmortem analysis.
.
path profiling path profiling is traditionally used to compute path coverage during program testing.
the approach we adopt from ball and larus is designed to efficiently profile all acyclic intraprocedural paths.
the algorithm first removes back edges to transform the control flow graph cfg of a procedure into a directed acyclic graph dag .
we represent the transformed cfg as a single entry single exit dag g v e s x where vis the set of nodes in the graph and e v vis the set of edges with no directed cycles.
every node in vis reachable by crossing zero or more edges starting at the unique entry node s2v.
conversely the unique exit node x2vis reachable by crossing zero or more edges starting from any node.
a path pthrough gis represented as an ordered sequence of nodes hp1 pjpjisuch that pi pi 2efor all i jpj.
we define a complete path as a path whose initial and final nodes are sandxrespectively.
let crepresent the set of all complete paths note that this set is finite since gis a dag.
loops are handled specially and are discussed later in this subsection.
the overall goal of the ball larus algorithm is to assign a value increment e to each edge e2esuch that .
each complete path in chas a unique path sum produced by summing over the edges in the path .
the assignment is minimal meaning that all path sums lie within the right open interval jcj and .
the assignment is optimal meaning that each path requires the minimal number of non zero additions.
the first step assigns a value to each edge such that all complete path sums are unique and the assignment is minimal.
to do so the algorithm traverses the graph in reverse topological order.
for each n2vwe compute numpaths the number of paths from ntox.
if we number the outgoing edges of nase1 ekwith respective successor nodes v1 vk then the weight weight ek assigned to each outgoing edge ofnis k j 1numpaths .
after this step complete path sums using weight values are unique and the assignment is minimal.
peter ohmann ben liblit a s b c d e f g x pathsum pathcount pathsum 1pathsum 2pathcount pathsum a extra instrumentation code added for path profilingpathsum path abcef abcdf abg bcef bcdf bg b path numbers fig.
path profiling example the next step optimizes the value assignment.
this uses a maximum cost spanning tree mcst of g. a mcst is an undirected graph with the same nodes as g but with an undirected subset of g s edges forming a tree and for which the total edge weighting is maximized.
algorithms to compute maximum cost spanning trees are well known.
remaining non tree edges are chord edges and all edge weights must be pushed to these edges.
the unique cycle of spanning tree edges containing a chord edge determines its increment .
instrumentation is then straightforward.
track the path sum in a register or local variable pathsum initialized to 0ats.
along each chord edge e update the path sum pathsum increment e .
when execution reaches x increment a global counter corresponding to the path just traversed pathcount .
cycles in the original cfg create an unbounded number of paths.
control flow across back edges requires creating extra paths from stoxby adding dummy edges from sto the back edge target corresponding to initialization of the path sum when following the back edge and from the back edge source to x corresponding to a counter increment when taking the back edge .
the algorithm then proceeds as before.
because of the dummy edges to xand from s counter increments and reinitialization of the path sum occur on back edges.
we expand our definition of a complete path to include paths that begin at back edge targets or that end at back edge sources.
figure shows possible instrumentation to profile paths in the example function from figure .
figure 3a shows the function s cfg annotated with pathsum and pathcount increments.
each acyclic path completes at either function exit or the loop back edge and the counter for the path s value is incremented at that point.
as shown in figure 3b each acyclic path is uniquely numbered.
note that the assignment is clearly minimal as each acyclic path contains at most one pathsum initialization and one pathsum increment.
the preceding overview of path profiling focuses on details relevant to the present work see ball and larus for the complete authoritative treatment.
there has been a great deal of follow on work since the original paper ammons et al lightweight control flow instrumentation and postmortem analysis in support of debugging melski and reps sumner et al vaswani et al some of which provides opportunities for potential future work described in section .
.
program slicing program slicing with respect to program p program point n and variables vdetermines all other program points and branches in pwhich may have affected the values ofvatn.
the original formulation by weiser proposed the executable static slice a reduction of pthat when executed on any input preserves the values of v atn.
in this work we are concerned with non executable or closure slices which are the set of statements that might transitively affect the values of v. ottenstein and ottenstein first proposed the program dependence graph pdg a useful program representation for slicing.
the nodes of a pdg are the same as those in the cfg and edges represent possible transfer of control or data.
a control dependence edge is labeled either true orfalse and always has a control predicate or function entry as its source.
an edge n1!n2means that the result of the conditional at n1directly controls whether n2executes.
a node may have multiple control dependence parents in the case of irregular control flow such as goto break orcontinue statements.
a data dependence edge is labeled with a variable vand has a variable definition at its source and a variable use at its target.
our definition of the system dependence graph sdg an interprocedural dependence graph is drawn from horwitz et al .
the sdg combines all pdgs and adds a number of new nodes and edges.
each call is now broken out into three types of nodes a call site actual in and actual out nodes.
we treat globals as additional parameters following horwitz et al .
a special actual out node is created for the return value.
each pdg is also augmented with formal in and formal out nodes corresponding to formal parameters and the return value as well as global variables used or defined in the procedure.
interprocedural control dependence edges are added from each call site to the called procedure s entry node.
interprocedural data dependence edges are added for all appropriate actual in formal in and formal out actual out pairs including the return value.
finally summary edges from actual in to actual out nodes are computed these represent transitive data dependence summarizing the effects of each procedure call.
details on the computation of these edges can be found in horwitz et al .
a static slice considers all possible program inputs and execution flows.
while debugging one prefers a slice that is constrained to a particular execution.
korel and laski first proposed dynamic slicing as a solution to dataflow equations over an execution history.
we are interested in closure dynamic slices similar to those proposed by agrawal and horgan .
the authors propose four variants of dynamic slicing.
the first simply marks all executed nodes and performs a static slice over that subset of the graph.
the second recognizes that each executed node has exactly one control dependence parent and one reaching definition for each variable used in the statement.
therefore this variant slices using only dependence edges actually observed as active during the execution.
the third approach recognizes that different instances of each node may have different dependence histories.
therefore this8 peter ohmann ben liblit approach replicates each statement each time it occurs in the execution trace attaching only the active dependence edges for that instance of the statement.
agrawal and horgan s final approach only replicates nodes with unique transitive dependencies.
dynamic slicing can be very expensive potentially requiring data equivalent to a full execution trace.
to make matters worse one must trace all memory accesses due to pointer variables arrays and structures to have a completely accurate dynamic slice in the general case agrawal et al korel and laski .
kamkar et al and zhang and gupta are able to reduce the cost of dynamic slicing but the cost of fully accurate slicing remains too high for production use.
venkatesh and binkley et al formalize the semantics of program slicing and discuss the distinctions and orderings among the different types of program slices.
data collection when considering which data to collect and how several desirable properties guide our choices.
instrumentation must be efficient in time and space and therefore suitable for production use.
data must be held in memory until failure adding no i o or other system calls during normal execution.
data size must scale with aspects of execution state such as stack depth or number of program locations.
results must be mappable back to source code and contain as little ambiguity as possible.
lastly instrumentation must be tunable for overhead or to change focus without recompilation or redeployment.
any core dump already records the return address of each active function at the time of failure.
while this has all the above qualities it may be insufficient on its own.
therefore we augment core dumps with two novel techniques path tracing and various forms of program coverage.
some of these techniques can be combined.
throughout the remainder of the paper we will refer to a possibly empty or singleton set of tracing mechanisms as a tracing scheme .
the distinction between instrumentation and tracing is key to our technique.
first during compilation the program must be instrumented to support each possible desired tracing scheme.
section .
describes the four tracing mechanisms we consider in this paper.
second tracing must be customizable post deployment.
we discuss the preliminary method we adopted in section .
.
section .
touches on thread safety.
.
tracing mechanisms this paper considers four tracing mechanisms path tracing statement coverage callsite coverage and function coverage which we group into two different high level methods of tracing.
our path tracing mechanism is an extension of work by ball and larus .
coverage mechanisms are all traced similarly while only the traced program points differ.
for each instrumented function we produce a metadata file used to interpret traced data for reconstruction and postmortem analysis we describe this metadata individually for each tracing mechanism.lightweight control flow instrumentation and postmortem analysis in support of debugging .
.
ball larus inspired path tracing path tracing records the last nacyclic paths taken through each function on the stack at the time of failure.
like any stack bound data this is discarded whenever a function returns.
we achieve this using a variant of ball larus path profiling.
rather than counting acyclic path executions we instead record each completed acyclic path in a stack allocated circular buffer.
however completed paths alone do not yield an execution suffix.
we also need the final incomplete path leading up to the failure.
fortunately given a cfg g failing node v and a partial path sum w we can recover the unique acyclic path that accumulates the value wupon reaching v. this is a natural consequence of the ball larus approach vandware the only state maintained while determining acyclic paths and therefore must constitute the system s entire memory of the partial path covered so far.
formally for any node v2v every pathsum v pair either encodes a unique subpath in gor is infeasible.
conversely every unique subpath in gis represented by a unique pathsum v pair.
the proof that these uniqueness properties hold is straightforward by contradiction.
ghas a unique exit node x that is reachable from vvia some sequence of edges e. this sequence of edges need not be unique.
each of those edges has been assigned an increment and therefore we can compute the sum of the suffix sequence of edges to be w e2eincrement e .
suppose two distinct subpaths pandqboth begin at s end at v and share the same value of pathsum .
we can complete the path for both of them by connecting each subpath to eand getting a total path sum of wfinal w pathsum .
however we know that two acyclic paths do not share the same path sum by the proof from ball and larus .
it is trivially the case that no subpath can give rise to more than one possible pair as edge increments are fixed.
we must merely guarantee that an accurate partial path sum is available at every point during execution since failure can occur at any time.
figure shows appropriate instrumentation for the example from section .
note that the pathsum increments and pathtrace stores correspond to the path profiling instrumentation scheme shown in figure .
our implementation of path tracing includes a number of changes relative to standard ball larus path profiling.
we move array allocation into the stack giving one trace pathtrace per active call.
the size of this array determines how many acyclic paths are retained.
this is fixed at build time defaulting to .
we performed preliminary experiments on small applications varying the buffer size over several orders of magnitude up to .
we find that overhead initially increases anywhere from per order of magnitude.
overhead eventually stabilizes once the array is so large that most of it is unused and therefore never mapped into memory.
note that since space for path traces is stackallocated it naturally scales directly with the stack depth.
its allocation is also free as no explicit allocation is required and depending on the choice of trace size it has minimal impact on the size of a stack frame.
the stack allocated array serves as a circular buffer.
a local variable pathindex tracks the current buffer position.
at each back edge and function exit we append the path sum pathsum for the just completed path to this buffer.
on back edges the path sum is reinitialized pathsum to uniquely identify paths beginning10 peter ohmann ben liblit void add action char new text volatile int pathsum volatile int pathtrace volatile int pathindex intlen strlen new text while len index size intnew size size if new size size size pathsum else size new size array realloc char arr array size pathtrace pathsum pathindex pathindex n pathsum pathsum pathtrace pathsum strcpy array new text index len fig.
path tracing instrumentation example.
highlighted code implements path tracing .
at the loop head.
obviously we cannot instrument functions with more paths than can be counted in a machine integer.
this rarely affects bit platforms though section .
notes one exception seen in our experimental evaluation.
instrumentation skips affected functions for which we simply collect no trace data.
we must be able to access the current path sum at any point not just at the very ends of complete paths.
for safety we forbid the compiler from keeping this value in a register.
rather both the path sum and the trace array are declared volatile .
instrumentation produces a metadata file necessary for future analyses.
for each function we record a full representation of the control flow graph with edges labeled with path sum increments and a mapping from basic blocks to line numbers.
the linker aggregates this metadata into a single record for the entire executable path info in figure .
.
.
program coverage path traces provide very detailed information close to the point of failure in each active stack frame.
however path traces have two major blind spots old paths that have already rotated out of the circular trace buffer and interprocedural paths through calls that have already returned.
program coverage data can easily provide coarser grained global information allowing tracing to scale gracefully as the debugging task departs from the active crashlightweight control flow instrumentation and postmortem analysis in support of debugging stack.
coverage instrumentation uses one global array per instrumented function and one local array of the same size for each stack frame.
for a function f we select a set of statements which we call trace points .
these trace points are numbered n these serve as indices into f s local and global coverage arrays.
coverage that we gather is binarized meaning that we record whether each trace point was ever executed locally in each particular invocation of fcorresponding to a stack frame and globally for any invocation of facross the entire program s execution.
thus each trace point corresponds to one local coverage bit per active f stack frame plus one global coverage bit.
taken together the local and global coverage bits have several desirable properties.
the local bits offer up to date information for trace points in each still active function.
space for this is stack allocated so like path traces it naturally scales with the stack depth.
conversely the global coverage bits summarize data from completed calls which have already left the stack.
our prior work ohmann and liblit considered only one set of trace points call sites.
in this work we place that choice in better context by also considering two alternatives.
first one may elect to gather full statement coverage.
na vely one trace point could be used for each statement in f. however one trace point per basic block in fis sufficient.
second if one is interested in function coverage one need only select one trace point per function.
any statement guaranteed to execute on any execution of fwill do we use function entry as selecting function exit may require either multiple trace points or adding a shared exit block.
note that function coverage is unique in that it has no stack local variant all functions currently in the active stack are clearly executing.
call site coverage is the final coverage form we consider.
this mechanism is taken directly from our prior work ohmann and liblit .
here we have one trace point for each call site in f. our use of call sites as the program points for which to gather coverage information is somewhat arbitrary.
however the choice is well matched to its purpose.
call sites mark departures from the visible call stack these are places where stack based tracing such as path tracing cannot help us.
intuitively coverage at call sites complements dense stack local mechanisms where that help is most likely to be useful.
we find that call site coverage works extremely well in practice see section .
.
figure shows appropriate instrumentation for the example from section .
the three variants correspond to our three sets of trace points.
this example also shows some of the subsumption relationships that hold among the three types of program coverage.
call site coverage is more precise than function coverage for this particular function it is able to determine whether the loop was ever taken via tracing the call torealloc char array .
the subsumption relationship however does not hold in general as a function may be a leaf function i.e.
contain no calls or not be guaranteed to execute a call instruction on every path through the function.
however statement coverage always subsumes both function and call site coverage.
in the examples of figure only statement coverage distinguishes the direction of the ifstatement within the loop.
local coverage data is stored in a stack allocated n element array cov zeroinitialized at function entry.
a per function global n element array add actioncov initialized at program start holds global coverage information.
immediately follow peter ohmann ben liblit volatile bool add actioncov false void add action char new text add actioncov true intlen strlen new text while len index size intnew size size if new size size size else size new size array realloc char arr array size strcpy array new text index len a function coveragevolatile bool add actioncov false false false void add action char new text volatile bool cov false false false intlen strlen new text cov add actioncov true while len index size intnew size size if new size size size else size new size array realloc char arr array size cov add actioncov true strcpy array new text cov add actioncov true index len b call site coverage volatile bool add actioncov false false false false false false void add action char new text volatile bool cov false false false false false false intlen strlen new text cov add actioncov true while len index size intnew size size cov add actioncov true if new size size size cov add actioncov true else size new size cov add actioncov true array realloc char arr array size cov add actioncov true strcpy array new text index len cov add actioncov true c statement coverage fig.
program coverage instrumentation example.
highlighted code implements coverage .lightweight control flow instrumentation and postmortem analysis in support of debugging ing each trace point i we store true into slot iof both the local and global coverage arrays.
to preserve ordering the arrays are declared volatile .
for each trace point we record a small amount of static metadata used to identify the trace point during analysis.
in practice our setup requires that this data differ slightly depending on the type of trace point used.
function coverage need only record the name or mangled name of the function.
call site coverage records the name of the called function if known and the line number of the call site.
statement coverage records the sequence of line numbers occurring in the basic block and for reasons discussed further in section .
.
any calls that occur within the basic block.
the linker aggregates this metadata into a single record for the entire executable coverage info in figure .
.
tracing customization in production code it can be difficult to specify instrumentation overhead requirements beforehand as these requirements may change over time or vary for each program instance.
furthermore while focusing on failure related code could substantially reduce tracing cost it is impossible to predict where or when post deployment failures will occur before release.
therefore if the cost of full program tracing is too high for production use customizable tracing is necessary.
our approach statically replicates each function instruments each replica with one possible tracing scheme and dynamically decides which replica to execute.
our original implementation from ohmann and liblit used internal replication .
that is we replicated each function body inside the function and added a branch at function entry to select between tracing schemes.
however that work considered only two alternatives call site coverage with and without path tracing.
in this extended work we allow substantially more freedom in tracing schemes and add two new coverage alternatives.
note that the number of possible tracing schemes grows exponentially with the number of possible tracing mechanisms.
of course some schemes are unnecessary for example statement coverage subsumes both call site coverage and function coverage.
nevertheless the number of possible schemes can quickly become unwieldy there are possibilities for our mechanisms proposed in section .
.
this explosion prompted us to instead use external replication that is we replicate each function f into multiple functions one for each of f s possible tracing schemes.
the original body of fis changed to a springboard that calls the correct variant.
this significantly reduces the sizes of individual functions and makes selected tracing schemes easier to identify as each now constitutes its own function .
however many alternatives and optimizations are possible here.
for example one could use a switch statement or a jump table inline functions or use tail calls use a binding method to change later indirect calls to direct calls etc.
our current approach is very straightforward using standard switch statements and function calls.
we rely 2each of no coverage function coverage call site coverage statement coverage and for some functions function coverage call site coverage possibly paired with path tracing.
peter ohmann ben liblit enum inst none inst cc inst cc pt add actioninst void add action char new text switch add actioninst default add action none new text return case inst cc add action cc new text return case inst cc pt add action cc pt new text return fig.
tracing customization example on compiler optimizations to make appropriate choices regarding inlining or conversion to jump tables.
for each function a global variable encodes which function variant to use on that particular run.
these variables are stored in a special section of the data segment where they can easily be changed by direct editing of the program binary.
applications can initially ship with all instrumentation turned off.
over time instrumentation can be activated for selected functions based on previously observed failures.
figure shows an example for the function from section .
the new global variable add actioninst determines which tracing to use for this particular run.
here there are three possibilities no tracing call site coverage tracing or call site coverage plus path tracing.
note that our simple approach introduces an extra indirection into each function call.
this example is reasonably small however as mentioned previously the number of possible tracing schemes can grow rapidly in more extreme cases.
in section we investigate both the memory and run time costs of this customization.
.
additional consideration thread safety our experimental evaluation uses only single threaded applications but our instrumentation remains valid with threads.
path tracing only accesses stack allocated variables and each thread independently maintains its own path traces.
program coverage writes to globals but never reads from globals.
we store each coverage bit as a full byte for atomicity.
thus even updates to the global coverage arrays have no malign race conditions.lightweight control flow instrumentation and postmortem analysis in support of debugging analyses here we describe two analyses we developed to demonstrate the utility of the new information embedded in core dumps.
first we describe a simple algorithm that restricts the feasible execution set of control flow graph nodes and edges based on dynamic information from a failing run.
second we describe a novel static program dependence graph restriction algorithm which can be used without knowledge of slicing criteria to allow future restricted static program slicing.
both analyses are defined with respect to data collected as per section .
we assume that this data has been extracted from the core file and is named and organized as follows path one execution suffix for each frame on the stack at program termination.
each suffix contains at least one entry either the final crash location for the innermost frame on the stack or the location of the still in progress call to the next inner frame for all other frames .
localcoverage one array for each coverage mechanism stack frame at program termination.
array elements are booleans with one element per static trace point in the frame s function.
if a particular form of coverage is not used all its elements are true.
from this we extract unusedpoints the set of unexecuted trace points in each frame.
note that this description is equally valid for either call site coverage or statement coverage.
specifically if we only trace call site coverage for some frame the localcoveragestmt array contains all trueelements.
globalcoverage one boolean array for each coverage mechanism function in the program regardless of the state of the stack with one element per static trace point in the corresponding function.
if the corresponding coverage is traced each element denotes whether or not the corresponding trace point was ever executed.
otherwise all elements are true.
from this we extract globalunusedpoints the set of unexecuted trace points across the entire run.
again this description applies to all three forms of program coverage function coverage has only a single entry per function .
unused tracing mechanisms result in wholly trueentries.
.
restriction of execution paths our first analysis determines the set of cfg nodes and edges which could not have executed given the crashing program stack and tracing data collected.
this analysis involves only computing static control flow graph reachability based on the path and coverage data.
as the analysis is very light weight it could be used before debugging to filter portions of the program structure shown to a programmer.
letpbe a program with control flow graph g. while the statements and edges ingrepresent all possible control flows on any execution of p they are a static overapproximation of those active in any possible run of p. a full execution trace for a specific run rcan precisely yield the set of executed statements and edges in g. with this information one might reasonably restrict gto a subgraph grcontaining only the cfg nodes and edges active during r and use the restricted subgraph during debugging or subsequent r specific analyses.
peter ohmann ben liblit procedure intra active nodes gf path unusedpoints input a single function combined graph gf input a vector of nodes path hpath1 pathjpathjirepresenting a path in gf input a set unusedpoints of unexecuted trace points in gf output a set of nodes retain coverage reduce gf unusedpoints pathjpathj retain path.nodes cfg backward reachable gf path1 fig.
intraprocedural active node analysis procedure coverage reduce gf unusedpoints last input a single function combined graph gf input a set unusedpoints of unexecuted trace points in gf input a node lastrepresenting the last executed node in f gf.nodes unusedpoints gf.nodes cfg forward reachable gf f.entry cfg backward reachable gf last fig.
coverage reduction if the complete execution trace is unavailable but possible execution flows can be safely over approximated then the graph grcan likewise be approximated giving a subgraph that is larger than ideal but still smaller than g. in our case we have path traces and program coverage data as described in section .
this trace data is incomplete and ambiguous many runs can produce the same data.
our goal is to use this trace data to determine the set of possibly active nodes and the set of possiblyactive edges onanyrun that is consistent with the trace data.
figure shows the algorithm for intraprocedural active nodes analysis.
we first run the procedure coverage reduce shown in figure .
this procedure eliminates all trace points in the function that were not executed in a particular activation record as well as any other program points which could not have executed given that the trace points did not execute.
the procedure has two phases.
first it determines the set of nodes forward reachable from function entry then it finds the set of nodes backwardreachable from the function s end in this case the crash point .
any node not in the intersection of these two sets either only executes if an eliminated trace point executes or only occurs after the crash point.
then continuing with figure all nodes in the path trace must be kept along with any nodes backward reachable from the first path entry path1 .
all other nodes can be eliminated.
though not shown determination of active edges is identical the only difference is that we track edges crossed rather than nodes visited for each stage.
the interprocedural algorithm in figure is largely an extension of the intraprocedural algorithm with some complexities to deal with stack data.
we apply the logic from figure to every procedure in the entire application now using globalunusedpoints .
after this for each frame on the stack we execute the intraprocedural algorithm over a mutable copy of the procedure s cfg g0.
this is necessary because the analysis will remove nodes from g0via a call to coverage reduce and the result must respect the retain sets of all invocations of each procedure on the stack in the case of recursion and all possible invocations through transitive calls.
to incorporatelightweight control flow instrumentation and postmortem analysis in support of debugging input a whole program combined graph g input a vector of frames stack each composed of a vector of nodes path hpath1 pathjpathji representing a path in g and a set unusedpoints of unexecuted trace points in g input a mapping globalunusedpoints from functions to a set of their unexecuted trace points output a set of nodes retain forall f unusedpoints inglobalunusedpoints do gf fragment of grepresenting function f coverage reduce gf unusedpoints f .exit retain foreach frame inhstackjstackj stack 1ido g0 temporary copy of grestricted to frame .function retain0 intra active nodes g0 frame .path frame .unusedpoints retain retain0 end call call node located at frame .pathjframe .pathj calls fn2retain0jnis a callg ifend call62cfg backward reachable g0 path1 fpath1 pathjpathj 1gthen calls end call foreach callincalls do retain edges interprocedurally forward reachable from call.target without crossing any return edges fig.
interprocedural active node analysis possible execution flows outside the visible stack we collect the set of possiblyexecuted calls excluding the final call end call corresponding to the crash location for the relevant stack frame and determine the set of cfg nodes that may have executed during those calls.
this set is determined as all forward reachable cfg nodes from the entry of each called function.
this reachability analysis crosses call edges to get full interprocedural information but not return edges to preserve contextsensitivity .
instead we assume the intraprocedural cfg contains an intraprocedural edge corresponding to the call and return for each call site.
as with the intraprocedural variant gathering active edge information is nearly identical.
here an additional requirement is that we also maintain a set of possible return edges which for this simple analysis can be derived directly from the set of possible call edges .
after all frames have completed we can eliminate nodes and or edges which were eliminated for all frames.
.
static slice restriction our second analysis is a novel technique for program dependence graph pdg restriction based on an early dynamic program slicing algorithm originally proposed by agrawal and horgan .
note however that we are not actually computing a dynamic slice during analysis the slicing criteria program point and variables of interest may not yet be known.
rather we restrict the static pdg to respect the failing execution data.
this can be a preparatory step for multiple future slice queries for any given slicing criteria.
peter ohmann ben liblit input a single function combined graph gf input a vector of nodes path hpath1 pathjpathjirepresenting a path in gf input a set unusedpoints of unexecuted trace points in gf output a restricted version of gfwith respect to path andunusedpoints coverage reduce gf unusedpoints pathjpathj retain intra control retain gf path intra data retain gf path gf.pdg edges retain fig.
intraprocedural dependence graph reduction letpbe a program with dependence graph g. as with the cfg in section .
dependence edges in gare a static over approximation of those active in any possible run of p. suppose in this case that one knew exactly which control and data dependence edges were actually used during a specific run r. one might reasonably restrict gto a dependence subgraph grcontaining only the dependence edges active during r and use the restricted subgraph during subsequent r specific analyses.
for example a backward static slice over grwould yield an r restricted dynamic slice for any program point of interest.
this corresponds to approach in agrawal and horgan .
as in the cfg case our path traces and program coverage data from section allow us to over approximate the exact set of dependence edges active in r yielding a safe over approximation of the ideal gr.
specifically we wish to compute a tracerestricted dependence graph that retains every dependence edge that could possibly have been active in anyrun that is consistent with the trace data.
for this formulation we assume that gis also overlaid with the control flow edges in each procedure as the pdg contains all nodes from the cfg by our definition .
in the remainder of the paper we refer to a graph with both cfg and pdg edges as acombined graph .
in figures to !
always refers to a control dependence not control flow edge while !v refers to a data dependence edge defining v. for the high level descriptions of the algorithms given here we collapse all actual in and actual out nodes into their associated call nodes for ease of presentation.
.
.
intraprocedural restriction figure shows the overall process of computing intraprocedural pdg restrictions which proceeds in several phases.
this algorithm resembles that in figure for active cfg nodes but determining active dependence edges is somewhat more complex.
to begin coverage information is used to prune the reachable nodes in the combined graph per figure described earlier.
next we identify the control and data dependence edges that must be retained.
this process is more complex than simple reachability required for cfg nodes and edges details for each of control dependence and data dependence edges appear in figures and respectively.
lastly we remove all dependence edges not selected for retention.
figure shows the process for determining the retained set of control dependence edges.
the goal is to identify the immediate control dependence parent of each node in path and each node potentially executed prior to path.
the vector unattributedlightweight control flow instrumentation and postmortem analysis in support of debugging function intra control retain gf path input a single function combined graph gf input a vector of nodes path hpath1 pathjpathjirepresenting a path in gf output a set of nodes retain unattributed path retain foreach n i in pathjpathj jpathj path1 do foreach pinpathi path1do ifp!nis a control dependence edge in gfthen retain fp!ng remove slot ifrom unattributed break reachable cfg backward reachable gf path1 retain f !njn2reachableg retain fq!njq2reachable n2unattributedg fig.
intraprocedural control dependence retention holds path entries for which the algorithm has yet to determine the most direct controlling node.
the outer foreach loop walks backward beginning from the crash point through the entries in path.
the inner loop begins with the entry immediately prior to the current node again walking backward through path.
during this inner loop search if a node is encountered that controls the execution of the outerloop node then the control dependence edge between those nodes was active in the traced execution and thus must be retained.
once such a node is found the outer loop node has found its directly controlling conditional it is removed from unattributed and the search for that node ends.
after attributing control dependence parents to as many path entries as possible the algorithm determines the set of nodes backwardreachable from the first entry in the trace.
these nodes have no additional dynamic information any control dependence edge from a reachable node could have been active in some run producing this trace.
finally all remaining unattributed nodes from path must retain all incoming control dependence edges from reachable nodes.
determining the retained set of data dependence edges detailed in figure follows a similar process albeit with some additions.
here each node must determine active data dependence parents for each variable used at that node.
the algorithm first determines which variables must be defined and may be used by each node in the combined graph.
for brevity in presentation mustdef andmayuse are computed as sets of node variable pairs but will also be interpreted as mappings from nodes to sets of variables.
each entry of the unattributed vector again corresponds to a node from the path trace but instead tracks all unattributed variable uses at that entry.
thecalleeexclusions parameter is unused by the intraprocedural analysis.
the nested loops step backward through path as in control dependence retention.
in this case the outer loop finishes with a path entry only once it has attributed each variable used or potentially used in the case of pointers at that node.
otherwise at each inner loop step data dependence edges are retained for any variables not yet attributed.
summary data dependence edges from the appropriate actual in to actual out nodes should be added to retain whenever a call node is encountered.
the path trace does20 peter ohmann ben liblit function intra data retain gf path calleeexclusions input a single function combined graph gf input a vector of nodes path hpath1 pathjpathjirepresenting a path in gf input a set of variables calleeexclusions unused at call site pathjpathj output a set of nodes retain mustdef f n v jn2gf.nodes nmust define vg mayuse f n v jn2gf.nodes nmay use vg unattributed hmayuse foriin jpathji unattributedjpathj calleeexclusions retain foreach n i in pathjpathj jpathj path1 do foreach pinpathi path1do ifunattributed i 0then break ifp!vnis a data dependence edge in gffor some v2unattributed ithen retain fp!vng ifv2mustde f then unattributed i fvg reachable cfg backward reachable gf path1 retain f !vnjn2reachableg forall n i in path1 pathjpathj jpathj do retain fq!vnjq2reachable v2unattributed ig fig.
intraprocedural data dependence retention not contain data flow information.
thus in the case of pointers with multiple possible variable targets the analysis cannot be certain which dependence for vwas active.
therefore the algorithm considers a used variable vattributed only if the source must always define v. lastly we conservatively add all possible data dependence edges to unattributed variable uses much as figure did for control dependence edges leading to unattributed nodes.
.
.
interprocedural restriction figure gives the steps for interprocedural restriction.
the formulation closely mirrors the interprocedural slicing method given in horwitz et al which is also later used to slice over the restricted dependence graph.
first we use global unusedpoints information to remove unexecuted trace points from each function as well as any other nodes execution dependent on those program points.
next we process each stack frame beginning with the crashing function.
this phase identifies active dependence edges within and between stack procedures transitive dependencies from called and returned procedures are captured with summary edges.
for each frame we create g0 a temporary subgraph of gcontaining only nodes from the frame s function.
as with the active nodes analysis from figure interprocedural restriction must respect the retain sets of all possible invocations of each procedure.
we then remove unused trace points.
at this point we need to connect this frame to the previous frame by retaining data dependence edges from formal in nodes to actual variables from the call.
for the innermost frame this haslightweight control flow instrumentation and postmortem analysis in support of debugging input a whole program combined graph g input a vector of frames stack each composed of a vector of nodes path hpath1 pathjpathji representing a path in g and a set unusedpoints of unexecuted trace points in g input a mapping globalunusedpoints from functions to a set of their unexecuted trace points output a restricted version of gwith respect to stack andglobalunusedpoints forall f unusedpoints inglobalunusedpoints do gf fragment of grepresenting function f coverage reduce gf unusedpoints f .exit retain formals foreach frame inhstackjstackj stack 1ido g0 temporary copy of grestricted to frame .function call call node located at frame .pathjframe .pathj coverage reduce g0 frame .unusedpoints call actuals variables for actual arguments for call connected fcall!vfjv2actuals f2formalsg unconnected fv2actualsj call!v 2connectedg retain connected retain0 intra control retain g0 frame .path intra data retain g0 frame .path unconnected retain retain0 formals fformaljformal!
2retain0g worklist all call nodes nsuch that retain contains any intraprocedural dependence edge from n retain edges interprocedurally backward reachable from worklist without crossing any edges from calls to formal ins g.pdg edges retain fig.
interprocedural dependence graph reduction no effect.
for other frames connected will contain those edges to formal in nodes that correspond to transitively potentially used formals in the previous stack frame these must be retained.
unconnected contains any actuals not connected to a useful formal.
note that here the intraprocedural restriction algorithms are used as subroutines.
we now use the third parameter to intra data retain the algorithm does not consider unused actuals to be unattributed as incoming data dependence edges for these variables were unused.
the final step of the algorithm retains dependence edges from transitive calls beginning from the stack frames.
a worklist is populated with all calls not corresponding to the crash point in this frame.
all dependence edges backward reachable in the sdg from the worklist nodes including edges corresponding to function returns but excluding those corresponding to function calls must be retained.
these edges correspond to transitive interprocedural dependencies for previously returned calls.
the algorithm does not need to re ascend to calling procedures because summary edges are included in both phases.
.
.
additional considerations and relationship to dynamic slicing slices over a restricted graph like those of agrawal and horgan and horwitz et al are closure slices .
these over approximate the set of statements that may22 peter ohmann ben liblit have affected the variable values at the chosen slice point but are not necessarily executable or equivalent to the original program.
unlike agrawal and horgan our dependence graph restriction algorithms are not actually computing dynamic slices they are not slicing from any particular program point.
in fact one way to define the analyses is as partial trace dynamic slicing from every point along our execution suffix.
the choice of static slice start node is orthogonal to this restriction.
every static slice taken over the restricted graph should be consistent with the trace data modulo the loss of accuracy as in agrawal and horgan s approach when a node is executed multiple times with different incoming dependence edges.
our dependence graph is static so these dynamically distinct nodes are necessarily collapsed into one static node.
it would be possible to unroll all traced paths into the dependence graph and track individual dependencies.
this approach for a full execution trace produces what is known as a dynamic dependence graph and is equivalent to agrawal and horgan s approach our approach would produce a partial dynamic dependence graph.
while it can yield smaller dynamic slices this approach also makes the pdg significantly larger and more complex to understand.
despite advances in compressing dynamic dependence graphs e.g.
zhang and gupta and the final approach by agrawal and horgan graph sizes remain quite large increasing the time and mental effort for a developer to sift through graph data to find a reasonable slice point.
thus we do not work with dynamic dependence graphs for our analysis results future work could consider this possibility.
our primary goal is extremely lightweight data collection.
therefore we do not track updates to memory locations as would be necessary for fully accurate interprocedural dynamic slicing agrawal et al .
we accept a potential loss of accuracy that comes with static alias analysis for globals and pointer variables when crossing procedure boundaries.
experimental evaluation we conducted experiments to assess the efficiency of our data collection strategies and the utility of the information we collect.
we use clang llvm .
lattner and adve to compile and instrument programs.
instrumentation operates directly on llvm bitcode.
we selected a range of applications varying in functionality and size.
table gives additional details about our test subjects.
the siemens applications flex grep gzip sed and space were obtained from the software artifact infrastructure repository do et al rothermel et al .
space contains real faults sed contains both seeded and real faults and the remaining sir provided test subjects contain only seeded faults.
ccrypt and gcc are real released versions with real faults.
some application versions have multiple faults which can be enabled separately the variants column of table counts unique builds across all versions and all available faults.
all of these applications are written in c. however there are no practical reasons our approach could not be applied to object oriented programming languages and both ourlightweight control flow instrumentation and postmortem analysis in support of debugging table evaluated applications application type variants mean loc print tokens siemens print tokens2 siemens schedule siemens schedule2 siemens tcas siemens ccrypt linux utility flex linux utility grep linux utility gzip linux utility sed linux utility space adl interpreter gcc c compiler analysis back end and compiler front end support compilation and analysis of c code.
results presented in this section are aggregates across all versions bugs and test suites of each application.
in general results vary little among builds of a given application we note any exceptions below.
we also aggregate results for all applications from the siemens test suite to simplify presentation.
these are very small simple applications and results indicate that they have similar results for both tracing overhead and analysis effectiveness.
again we note exceptions below.
.
overhead our first evaluations assess the efficiency of our tracing mechanisms and customization methodology from section .
all experiments used a quad core intel core i53450 cpu .
ghz with gb of ram running red hat enterprise linux .
.
.
.
run time overhead overhead is the ratio of execution times for instrumented and uninstrumented code.
for each version of each application we ran the test suite over the non faulty build at least three times and took the geometric mean of the overheads for each test case.
results appear in figure .
smaller values are better with .
conveying no instrumentation overhead.
we built each application version using our instrumentor with all non library functions instrumented with various instrumentation configurations.
we first evaluate each tracing mechanism individually.
the first four bars function coverage call coverage statement coverage and path tracing indicate instrumentation that does not require any customization that is all functions have only one variant the particular tracing mechanism listed .
function coverage causes no measurable overhead for our test subjects.
call site coverage is far cheaper than statement coverage gathered as basic block coverage .
the maximum overhead for call site coverage among our test subjects was .
for gcc while statement coverage has24 peter ohmann ben liblit .
.
.
.
.
.
siemens ccrypt flex grep gzip sed space gccexecution time relative to uninstrumentedfunction coverage call coverage statement coverage path tracing realistic realistic fixed fig.
run time overhead overheads as high as .
for sed .
gcc has thirteen functions with more than acyclic paths these cannot be instrumented for path tracing.
even so the cost of full path tracing is surprisingly low varying across applications from negligible to .
for gzip .
this suggests that our adaptation of the classic path profiling approach is very efficient substantially reducing our overhead over full path profiling which according to initial results by ball and larus has approximately average run time overhead due to large storage requirements and the use of hashing .
taking into account measured overheads and expected orthogonality of benefits we then considered instrumentation based on a realistic set of tracing schemes for customization none call coverage call coverage path tracing .
we then activated call site coverage tracing for all non library functions and path tracing for any function appearing in the crash stack of any failing test case for each application version.
this is a realistic configuration if latent instrumentation can be enabled post deployment in response to observed failures and appears as realistic in figure .
our results indicate that limiting path tracing to functions involved in failures can significantly reduce overhead especially for gzip and sed .
the overhead of a particular application appears to depend on non trivial factors.
for example larger applications do not necessarily have more overhead.
most applications have comparable overheads for all versions with realistic instrumentation.
one version of gzip has significantly lower overhead about on average while the other versions are around .
overheads between sed versions also vary somewhat ranging from negligible to .
.
averaged across all larger non siemens applications the realistic configuration shows a mere .
overhead.
we next evaluated what portion of the overhead for the realistic configuration was due to tracing customization i.e.
the springboard function discussed in section .
.
the realistic fixed bar in figure shows the run time cost of the realistic lightweight control flow instrumentation and postmortem analysis in support of debugging configuration had we disallowed customization that is had we re instrumented each function based on observed failures to obtain the same tracing data as realistic but with each function deciding at compile time rather than run time which tracing scheme to use .
clearly customization adds a substantial portion of the run time overhead for some applications especially gzip .
overall though the realistic configuration has extremely low run time overhead in all cases and would be suitable for deployed applications.
all of the preceding results used non optimized builds as this is most conducive to debugging.
we also gathered results not shown in figure using each of our previous instrumentation schemes but with clang o3 optimization enabled.
analysis still works correctly on optimized code due in part to our use of volatile declarations as discussed in section .
results for optimized code are very similar to unoptimized results and suggest that our instrumentation does not seriously hinder program optimization.
in fact for the realistic configuration with optimization overhead averages just .
across all larger applications with a maximum overhead of .
for gzip .
however debugging optimized code is always tricky.
for example statement reordering can make the execution paths we recover difficult to understand.
prior work on debugging optimized code jaramillo et al tice is directly applicable here.
.
.
memory overhead we next measured the ratio of the maximum resident memory size of the running program for instrumented and uninstrumented code.
again for each version of each application we ran the test suite over the non faulty build at least three times and took the geometric mean of the overheads for each test case.
results appear in figure .
smaller values are better with .
conveying no instrumentation overhead.
again the first four bars indicate memory overhead for each tracing mechanism individually without customization .
our results indicate that function coverage and call site coverage have very small memory footprints.
for statement coverage and path tracing however extra memory usage is somewhat larger for sed overheads reach .
for path tracing and .
for statement coverage.
the next two bars realistic and realistic fixed again correspond to the scheme proposed in section .
.
optional tracing of call site coverage and path tracing with coverage enabled everywhere and path tracing enabled in functions appearing in failing stack traces.
beginning with the realistic fixed scheme it is again clear that specializing tracing to observed failures can significantly reduce overhead.
in the most extreme case sed the memory overheads for call site coverage and path tracing are .
and .
respectively totaling .
but the uncustomized realistic configuration causes only .
overhead.
however the realistic results indicate that tracing customization appears to take a large toll on static memory usage.
exploring this further the final bar all options shows memory overhead for the pathological case where we instrument for all logical tracing possibilities as mentioned in section .
but perform no tracing at execution time i.e.
we select the none variant for all functions .
perhaps as one might expect the memory cost of customization is quite high.
since we create26 peter ohmann ben liblit .
.
.
.
.
siemens ccrypt flex grep gzip sed space gccresident memory size relative to uninstrumentedfunction coverage call coverage statement coverage path tracing realistic realistic fixed all options fig.
memory overhead a new copy of every instrumented version of each function we can potentially cause an exponential blow up in code size.
for the larger applications the results of all options instrumentation indicate that this is a potential issue.
this scheme does not enable any tracing at run time so the observed memory overheads are pure code bloat.
nevertheless it is important to keep this result in perspective.
first our instrumentation makes rather na ve choices in a real world scenario it may be possible to make more informed decisions about which functions are likely to ever require customization or tracing in the future.
second and most importantly the increased memory usage for customization is a one time cost it does not scale throughout program execution.
thus the dynamic memory cost of tracing is more closely related to the realistic fixed results.
the uncustomized realistic configuration shows just .
memory overhead averaged across all larger non siemens applications.
as with time overhead we also gathered memory overhead numbers for our tracing configurations with standard o3 compiler optimizations enabled.
for the most part the results are again similar to their unoptimized counterparts.
overhead numbers are slightly higher in optimized code.
the differences are most pronounced for coverage mechanisms statement coverage sees its maximum overhead value for flex increase from .
to .
.
the uncustomized realistic scheme similarly sees its maximum overhead increase from .
to .
.
nevertheless the average overhead for this realistic scheme with compiler optimizations for the larger applications is only .
.
thus our tracing has a very small memory footprint even for optimized builds.lightweight control flow instrumentation and postmortem analysis in support of debugging if code !
reg !exp equiv p p exp p exp if elt elt elt first same value a multiple expressions on a single line if get code op const int width host bits per wide int width p lookup arg1 safe hash arg1 get mode arg1 nbuckets get mode arg1 b single statements across multiple lines fig.
examples of matching ambiguity .
analysis implementation this section describes details related to our implementation and evaluation of the analyses described in section .
.
.
implementation details codesurfer .2p0 anderson et al produces our combined graphs.
these match the sdg description given in section .
and are overlaid with cfg edges.
all cfg nodes i.e.
all nodes except for those representing hidden formal and actual parameters such as global variables have associated source code location information.
our analysis implementation follows that given in section .
however there we simplified presentation by collapsing both global and local formals and actuals into their associated call node.
formals and actuals are separate nodes in codesurfer sdgs and our analysis treats them separately thus retention can distinguish between used and unused formal and actual parameters the unconnected set figure is composed of nodes rather than variables and summary edges exist from actual in nodes to actual out nodes which are relevant for intraprocedural analysis .
.
.
sources of ambiguity because we use two different pieces of software clang and codesurfer to determine statement locations for path trace entries and coverage trace points minor disagreements are inevitable.
much of the ambiguity in matching program locations stems from the fact that line numbers are the smallest granularity at which we can reliably match clang ast nodes to codesurfer graph nodes.
we also find disagreements in the selection of line numbers to assign to particular program points.
naturally our matching approach must always be conservative with respect to our analyses in order to ensure that our results safely under approximate but never over approximate the optimal reduction we can achieve.
we are generally unable to individually match different expressions occupying the same source line as clang and codesurfer may break or order the expressions differently.
this means that the start end and size of expressions can differ as well28 peter ohmann ben liblit as the number of nodes or operations involved.
consider the two code lines shown in figure 16a.
in the first line the llvm bitcode contains significantly more instructions than the number of expressions given as cfg nodes produced by codesurfer dereferences the unary !
operation etc.
.
the ordering of the actual parameters in the call to exp equiv p and evaluation of their expressions need not correspond so we also cannot count on an ordered many to one relationship.
this in line ambiguity is particularly problematic for path traces and statement coverage data but also has a small impact on call site coverage matching.
for path traces we handle the ambiguity by matching each path trace entry with a set of nodes matching the given line number rather than a single node .
this set can be restricted based existing cfg edges to previous or from following entries in the trace nevertheless significant ambiguity is common.
specifically we are never able to distinguish paths through a single line such as the ifstatement given on the second line of figure 16a.
our analyses from section suffer further from this problem because we often miss out on opportunities to remove a node from the unattributed sets figures and due to not knowing if an assignment definitely executes on a particular line.
ambiguity due to the matching of llvm line numbers to codesurfer nodes reduces the precision of our analysis in the correspondence stage of figure .
statement coverage similarly cannot always distinguish between multiple basic blocks which occur in the same line.
however as mentioned in section .
.
the set of called functions is also recorded for each basic block this can often help to distinguish blocks occurring purely within the same line.
call site coverage is unable to distinguish between calls to the same function on the same line.
our tools must also grapple with statements that span multiple lines.
this is because clang and codesurfer builds do not necessarily agree about whether to assign the line number s for a statement or expression to the first line last line or in codesurfer s case all relevant lines.
figure 16b shows two examples of statements demonstrating this issue.
this issue arises most frequently with conditional expressions ternary expressions and calls.
actual parameters unless they contain other expressions which will necessitate their own line number such as another call tend to be assigned the line number of the call statement which is usually either the first or last line of the entire statement .
because of the great uncertainty in matching multi line expressions we intentionally introduce ambiguity into the combined graph to safely match clang s output.
we collapse all line numbers within each set of nodes corresponding to a multi line expression into a single set which we assign to all nodes of the expression.
this impacts path traces statement coverage and call site coverage.
for path traces this further increases the ambiguity as to which expression each path trace entry refers to on a particular line.
for statement coverage it necessitates that we only remove nodes for which all trace points corresponding to that line have false as their coverage bit.
for call site coverage we similarly must ensure that call nodes are only removed if they are either the only call site on the line for indirect calls or the only call to the specified function for direct calls .
other intricate issues also necessitate some further minor introduction of ambiguity into the combined graph.
for example llvm .
assigns the line number of the close of the statement block i.e.
the closing brace to the conditional of a do while statement.
naturally this character has no semantic value so it will notlightweight control flow instrumentation and postmortem analysis in support of debugging appear in the codesurfer graph.
thus we must include all line numbers up to the most recent statement within the loop in the set of line numbers for the loop guard conditional.
these changes as well as changes necessary for multi line expressions are referred to as the fix graph stage in figure .
finally in flex gcc and one version of grep we had to modify one source code line by eliminating a line break at the start of an ifstatement that otherwise caused irreconcilable disagreement between clang and codesurfer line numbers.
unfortunately this ambiguity is quite common in the applications we examined.
in fact all four code lines from figure are taken from one single function of gcc.
nevertheless our analysis results show that we can significantly reduce ambiguity in the failing execution despite this ambiguity in our analysis framework.
.
analysis effectiveness we evaluated the benefit of our analyses described in section .
for test cases where core dumps were already produced we used the generated core file.
if a test case produced bad output without crashing we used the output tracing tool of horwitz et al to identify the first character of incorrect output and forced the application to abort at that point.
we aggregated results by taking arithmetic means across all failing tests of each faulty build then across all faulty builds of each version.
this avoids over representing builds that simply have many failing test cases.
for intraprocedural results we ran each analysis over every function on the stack that has at least one ambiguous branch on a path from function entry to the crash point.
we ran analysis experiments by varying which tracing mechanisms were enabled.
in all cases the tracing mechanisms specified were enabled for all functions in each application.
path traces are purely intraprocedural tracing therefore restricting tracing to functions appearing in crashing stacks the realistic configuration from section .
does not result in any loss of information.
as mentioned previously gcc has thirteen functions with more than 263acyclic paths that cannot be instrumented for path tracing however all program coverage remains available for these functions.
due to memory constraints we were unable to gather complete analysis results for gcc.
specifically we excluded six gcc functions that we could not analyze with our memory based analysis assign parms expand expr fold fold truthop rest of compilation and yyparse .
gcc s large size also prevented us from constructing the whole program combined graph.
therefore we omit interprocedural analysis results for gcc.
.
.
restriction of execution paths the restriction algorithms in section .
can eliminate cfg nodes and edges that could not possibly have been active during a given run.
figures and show results intraprocedural and interprocedural respectively for active edges as a percentage of all cfg edges.
we show only results for edges here as active nodes show very similar patterns.
these numbers are relative to context sensitive stack constrained backward reachability.
for the intraprocedural analysis we count backward reachable30 peter ohmann ben liblit siemens ccrypt flex grep gzip sed space gccactive edges as of entire functionnone function coverage call coverage statement coverage path tracing realistic fig.
intraprocedural active edges nodes and edges from the frame s crash point.
for the interprocedural analysis we work back from the crash point of the innermost stack frame.
smaller numbers here are better values close to the none result indicate little reduction while values closer to mean that our analysis eliminated many inactive edges.
figure shows intraprocedural results.
here we measured the set of possiblyactive cfg edges as a percentage of all cfg edges in each stack frame s function.
we ran our analysis over every function on the stack that has at least one ambiguous branch on a path from function entry to the crash point.
we first measured the reductions for each tracing mechanism individually.
reductions for the smaller siemens applications are modest across all tracing mechanisms.
execution ambiguity is generally very low for these applications due to the small size of most functions.
results for larger applications however are much more impressive.
note that by our analysis formulation from section .
function coverage does not contribute to intraprocedural analysis as all functions in the crashing stack are clearly already executing .
our other three tracing mechanisms all perform well though complete statement coverage obtains the best results for all applications except sed which achieves a better reduction with path tracing .
the high cost of full statement coverage however motivates consideration of the realistic scheme from section .
the combination of path traces and call site coverage.
results indicate that the two mechanisms are indeed complementary.
for example gcc sees an additional reduction due to the combination.
the realistic configuration is the optimal choice for all but two of the applications ccrypt and gcc and averages reduction with a maximum reduction of sed across the larger applications.
it achieves these reductions at significantly less tracing cost than full statement coverage.
figure shows interprocedural results for active edges.
here the plot shows the set of possibly active cfg edges as a percentage of all edges in the entire programlightweight control flow instrumentation and postmortem analysis in support of debugging siemens ccrypt flex grep gzip sed spaceactive edges as of entire programnone function coverage call coverage statement coverage path tracing realistic fig.
interprocedural active edges excluding external libraries .
again reductions for smaller applications are modest.
there are however some exceptions one version of print tokens sees an average interprocedural reduction in active edges.
however in general as with intraprocedural analysis execution ambiguity is very low often with only one stack frame besides main .
considering the larger applications however results are again much more impressive.
some patterns are clear.
coverage data is the dominating factor for interprocedural analysis.
this is not surprising coverage maintains global scope information not available to path tracing.
however path traces do still contribute to the reduction for our realistic result in all larger applications except space which generally has very little ambiguity within the failing stack .
comparing our coverage mechanisms it is clear that the coarse grained global information provided by function coverage often still leaves a great deal of execution ambiguity that can be rectified by the finer grained coverage mechanisms.
full statement coverage provides a clear benefit for some applications e.g.
flex grep and sed but for others the reductions obtained for the inexpensive realistic configuration are comparable.
overall results for the combination of path tracing and call site coverage are quite impressive with average reductions as high as ccrypt interprocedural .
most applications are uniform across versions but versions of sed have active edge reductions ranging from in the intraprocedural case and in the interprocedural case.
space versions vary from intraprocedurally and interprocedurally.
in general for complex applications we find that a stack trace alone leaves great ambiguity as to which code was active.
our feedback data and analyses can significantly reduce this ambiguity with negligible impact on performance.
peter ohmann ben liblit siemens ccrypt flex grep gzip sed space gccslice as of entire functionnone function coverage call coverage statement coverage path tracing realistic fig.
intraprocedural slicing .
.
static slice reduction our pdg restriction algorithms from section .
can compute a restriction of the static pdg based on traced data.
per section .
.
the computed restriction is independent of and can be computed prior to selecting the slicing criteria.
for our evaluation we compute interprocedural static slices backward from the crash point in the innermost stack frame intraprocedural slices work backward from the crash point in each function in the crash stack.
all interprocedural slices are callstacksensitive binkley et al horwitz et al krinke .
results show to a large extent very similar patterns to those for active edges.
intraprocedural slicing results are shown in figure where bars indicate the slice size for each stack frame s function as a percentage of all pdg nodes that have a source code representation i.e.
that map to a line number .
note that a line can have more than one node.
for example for a call with multiple parameters we count each actual parameter separately as some may be included in the slice while others are not.
the none bar represents the slice size for a backward static slice from the crashing location in each active stack frame without the benefit of our dependence graph restriction.
smaller numbers are again better values close to none indicate little reduction in slice size while values closer to mean that slices were much smaller with our restriction analysis than without.
smaller applications again see less benefit.
however larger applications again show much better results.
considering each tracing mechanism individually full statement coverage again has the strongest results.
however the combination of path tracing and call site coverage again performs extremely well with the best results for all applications except grep for which it lags behind full statement coverage by a mere .
reduction .
intraprocedurallightweight control flow instrumentation and postmortem analysis in support of debugging siemens ccrypt flex grep gzip sed spaceslice as of entire programnone function coverage call coverage statement coverage path tracing realistic fig.
interprocedural slicing slice reductions average across all larger applications with a maximum reduction of for gcc the largest application in our experiments.
figure shows interprocedural slicing results.
here bars indicate the slice size as a percentage of all sdg nodes in the entire program excluding external libraries .
the none bar represents the slice size for a callstack sensitive backward slice from the crashing location without the benefit of our dependence graph restriction.
as in all previous cases the siemens applications see only a small benefit though there are some exceptions one version of schedule has an average interprocedural slice reduction of but the absolute slice sizes in this particular case are small so the absolute ambiguity is not large.
results improve substantially for larger applications with interprocedural slice reduction showing better results reduction realistic trace data than the intraprocedural variant.
coverage data is again the dominating factor in interprocedural analysis.
here however the benefit of full statement coverage over the combination of call site coverage and path traces is much less pronounced.
even for grep the application with the largest discrepancy full statement coverage further reduces slice size by only beyond the realistic tracing scheme.
overall the realistic scheme obtains the majority of the benefit of full statement coverage at a much lower cost.
space is the only larger application with highly varied results ranging from intraprocedurally and interprocedurally.
overall the results for path traces and call site coverage are again very impressive especially interprocedurally.
even for flex the worst among the large applications our approach cuts interprocedural slice sizes in half.
the best results for ccrypt show a reduction the cost of which is a mere half percent of execution time overhead realistic in figure .
peter ohmann ben liblit .
discussion our results indicate that enhancing core dumps from failing applications with lightweight tunable tracing can yield significant postmortem analysis benefits.
the combination of path traces and call site coverage proved an inexpensive complementary and effective pairing to enhance postmortem analyses.
path traces have the additional benefit of providing a detailed though incomplete partial trace leading up to the point of failure.
this would likely be very valuable to a developer in a real world scenario but we could not assess this benefit in our present experimental setting.
future work could consider performing a live debugging study with real developers to gauge the complete benefit of path traces and the reductions from our coverage mechanisms.
there are clearly substantial trade offs regarding coverage in our domain.
while function coverage has unmeasurably small overhead its postmortem analysis benefit is often significantly smaller than other options.
full statement coverage comes at a high overhead cost but is useful where its cost can be tolerated.
call site coverage provides most of the benefit of full statement coverage at significantly less cost thus it is likely the best choice in many real world deployed scenarios.
overall our goal was to show that a large benefit can be drawn from very little cost via targeted core dump enhancement we have succeeded in this regard.
a particular real world application may benefit in both overhead cost and analysis performance from a more customized tracing scheme than the rather simple schemes we consider here.
while our realistic scheme proved widely applicable different scenarios will allow different choices.
if higher execution overheads can be tolerated statement coverage proved helpful for many applications.
if execution constraints are tightened simple function coverage can still yield significant benefit in many scenarios.
to this end our approach is intentionally customizable.
threats to validity we attempted to gather fair and generalizable results but have not formally proven the correctness of our approaches or implementation.
here we discuss threats to the validity of our results and measures taken to mitigate these risks.
.
threats to internal validity we began with a claim that nearly all deployed software will have bugs throughout its lifetime.
our software is no exception.
bugs in our algorithm design or software implementation could impact the correctness of analysis results or the accuracy of overhead results.
we made significant attempts to control other factors outside of our tracing mechanisms which could have impacted overhead results.
we used a single machine and ran our tests under minimal load.
nevertheless our instrumentation does impact code size stack frame size and in rare cases where we need to place instrumentation along edges the control flow graph of the programs.
thus it is possible that other factors not directly related to instrumentation may impact our results.lightweight control flow instrumentation and postmortem analysis in support of debugging section .
.
notes changes we required in order to match static information between the two tools we used for our analysis experiments.
the intentional addition of this ambiguity into our combined graphs makes our results a safe over approximation of the optimal result but could impact the relationship between the results of different tracing methods.
in particular it may have a larger effect on some tracing methods when compared with others.
from a subjective and cursory inspection this seems to impact our path traces most significantly.
.
threats to external validity while we attempted to select applications with a wide variety of size and functionality it is obviously impossible for us to test our approach on all possible programs.
thus our results may not generalize to all deployed software.
in particular we evaluate only applications written in the c programming language in this work so the applicability of our approaches to modern object oriented languages cannot be guaranteed.
many applications had seeded faults raising typical concerns as to whether such faults are realistic.
all applications include test suites with both failing and successful runs we distinguished these by comparing the result with that produced by a nonbuggy reference version of the same application.
in real deployed applications it may be more difficult to identify failures or to obtain failing core dumps either due to not recognizing failures until later in execution or due to security concerns .
while this does not directly impact the utility of our traced information it could make it more difficult for a developer to select appropriate functions for instrumentation tracing or impact the distance between the failure and the fault.
longer fault propagation distances likely increase the benefit of traced information but the overall impact is not clear from our lab experimental setting.
related work several prior efforts use symbolic execution in conjunction with dynamic feedback data to reproduce failing executions cao et al crameri et al jin and orso r ler et al zamfir and candea .
we intentionally sacrifice perfect replay in favor of low overhead and tunable instrumentation.
as symbolic execution can be very expensive and is undecidable in the general case we see related work on symbolic execution based on core dumps as possible beneficiaries of the restriction analyses we perform.
yuan et al use static analysis with logs from failing runs to identify paths that must may or cannot have executed between logging points.
clause and orso track environment interactions for replay and minimization of failing executions.
while we do not require run time logging or tracing of environment interactions these approaches may provide additional valuable sources of information that could be used in conjunction with the analyses described here.
failure reconstruction is one possible postmortem analysis task worthy of study we propose other inexpensive pre debugging analyses in this work and demonstrate36 peter ohmann ben liblit their effectiveness in reducing failing execution ambiguity.
manevich et al use backward dataflow analysis to reproduce failing executions based on only a failure location and typestate information regarding the failure.
while very efficient this approach is geared toward solving specific typestate problems with very simple types e.g.
tracking null values for null pointer dereferences .
our approach uses denser information but targets a wider range of unknown failures anything that can be made to dump core.
adaptive bug isolation arumuga nainar and liblit and the gamma project bowring et al orso et al emphasize adaptive post deployment instrumentation with data collection aggregated across large user communities.
such approaches are complementary to our own we focus on gathering very valuable information at very low cost while these related efforts focus on how best to deploy information gathering instances.
gupta et al compute slices within a debugger ordered break points and call return traces restrict the possible paths taken.
while gupta et al focus on interactive debugging our approach is intended for deployed applications.
this imposes different requirements leading to different solutions.
our overheads must remain small relative to a completely uninstrumented application not merely relative to an application running in an interactive debugger.
gupta et al use complete break point and call return traces while we have only bounded buffers for each morsel of dynamic data.
takada et al offer near dynamic slicing by tracking each variable s most recent writer.
our work focuses more on control than data in the presence of pointers and arrays lightweight dynamic data dependence tracing in the style of takada et al could be a useful addition.
call mark slicing nishimatsu et al marks calls that execute during a given run then uses this to prune possible execution paths thereby shrinking static slices.
the first phase of our interprocedural slice restriction algorithm uses a similar strategy.
however our information is more detailed we have both global coverage information as well as segregated information for each stack frame.
future work our results indicate that the core dump enhancement approach has great potential to aid in postmortem debugging.
in this section we consider some of the most promising future directions for continued research.
.
unused information the astute reader will note that while our analyses can significantly reduce execution ambiguity we cannot claim to make full use of the information we gather.
first we only make use of false coverage bits to eliminate unused code.
it is clear that true coverage bits can also provide important execution information for example ifstatement branches not contained within a loop will always have only one branch covered for local execution.
second our present analysis does not make use of function coverage bits for intraprocedural analysis but it is possible to do so.
all direct calls tolightweight control flow instrumentation and postmortem analysis in support of debugging any unexecuted function could also be removed as part of our coverage restriction procedure from figure .
finally our traced information holds great promise for more heavyweight analyses.
particularly our data could be used as additional constraints to reconstruct failing executions via symbolic execution.
recent work has shown great strides in this area jin and orso r ler et al zamfir and candea .
future work could also consider aggregation of data from multiple failing runs in for example slice based fault localization e.g.
lei et al or some form of union slicing e.g.
mulhern and liblit .
.
customization customization currently makes up a large portion of both the run time and memory overheads of the realistic instrumentation configuration we propose.
future work could take at least two possible routes to mitigate this.
first instrumentation could eliminate tracing options for some functions by user customization based on a more limited set of expected future tracing needs or by making more intelligent static decisions if it can be determined that certain functions are better or worse candidates for specific tracing mechanisms .
second as we note in section .
we use a very simple switch based customization method for our current implementation.
future work could consider other indirection techniques such as function multi versioning for scenario based optimization mars and hundt .
.
tracing extensions our results indicate that specializing path tracing to functions involved in previous failures can substantially reduce overhead.
however when path tracing is deployed more widely our preliminary inspection indicates that a large portion of its overhead comes from functions with a very large number of acyclic paths.
in addition we were unable to make use of path tracing instrumentation for a non trivial number of functions from one of our test subjects due to very large path counts.
one might simply leave these uninstrumented unfortunately these complex functions may be exactly what the programmer needs help understanding.
one could also trace just some paths perhaps adapting work by apiwattanapong and harrold or vaswani et al on focused path profiling variants.
the resulting trace suffix would be ambiguous but potentially still useful.
our global program coverage mechanisms work well as described here but are both coarse grained and inflexible.
we are interested in approaches that can encode calling context with low overhead bond and mckinley sumner et al rather than explicitly and blindly logging all trace points.
we are also interested in leveraging aspects of data flow as well as control flow analyses by yuan et al to identify most useful variables may be a good start.
our current instrumentation and analysis techniques should be able to analyze c applications we are interested in exploring whether our techniques translate well to larger object oriented software with many dynamically bound calls.
peter ohmann ben liblit conclusion our primary design goal was to provide valuable extended core dump information for debugging with low enough overhead to be used in a production setting.
our adaptations of path tracing and program coverage are complementary strategies that realize this goal.
experimental evaluation finds interprocedural slice reductions as high as and active node and edge reductions as high as .
average run time overheads are merely .
in a realistic debugging configuration with a maximum overhead of less than .
thus we provide significant debugging support for negligible cost.