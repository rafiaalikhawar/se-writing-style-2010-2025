on demand feature recommendations derived from mining public product descriptions horatiu dumitru marek gibiec negar hariri jane cleland huang bamshad mobasher carlos castro herrera mehdi mirakhorli depaul university s. wabash ave chicago il dumitru.horatiu mgibiec negar.hariri gmail.com jhuang mobasher ccastroh cs.depaul.edu m.mirakhorli acm.org abstract we present a recommender system that models and recommends product features for a given domain.
our approach mines product descriptions from publicly available online specifications utilizes text mining and a novel incremental diffusive clustering algorithm to discover domain specific features generates a probabilistic feature model that represents commonalities variants and cross category features and then uses association rule mining and the k nearestneighbor machine learning strategy to generate product specific feature recommendations.
our recommender system supports the relatively labor intensive task of domain analysis potentially increasing opportunities for re use reducing time to market and delivering more competitive software products.
the approach is empirically validated against different product categories using thousands of product descriptions mined from a repository of free software applications.
categories and subject descriptors d. .
domain engineering h. .
retrieval models clustering query formulation general terms algorithms documentation keywords domain analysis recommender systems clustering .
introduction domain analysis is the process of analyzing related software systems to identify organize and represent features common to systems within a domain .
although domain analysis is typically performed as part of the product permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
icse may waikiki honolulu hi usa copyright acm ... .
.line development process its use can also be beneficial in single application projects.
for example an analyst eliciting requirements for a new anti virus software system might evaluate the features provided by competing products or a developer might analyze an existing health care administration system to extract a set of re usable assets for use in a new product.
in both of these cases the identification and timely reuse of domain assets could potentially reduce development costs shorten time to market improve quality and increase product competitiveness.
although several domain analysis techniques such as feature oriented domain analysis foda and the domain analysis and reuse environment dare have been developed these approaches generally assume that analysts utilize existing requirements documentation and then manually or semi manually evaluate the documentation to extract features.
they provide little upfront support for automating the task of identifying features or for understanding their composition rules.
as a result domain analysis tends to be quite labor intensive dependent upon the expertise of available analysts or subject matter experts and constrained by the availability of requirements specifications from previous related projects.
to address these problems researchers have applied datamining and natural language processing nlp techniques to automate the process of mining features from requirements specifications or project repositories .
however these techniques are only useful when an organization has an available repository of requirements specifications or other related assets.
furthermore the automated analysis of existing documents is constrained to the features described in those documents.
this approach therefore fails to explore the full range of features that might be offered by competitors and does not help analysts to explore ideas beyond the confines of their own existing products.
in this paper we address these limitations through presenting a novel approach for automating the feature analysis process.
in contrast to previous methods that extract features from proprietary project repositories our approach mines raw feature descriptions referred to from now on as descriptors from thousands of product specifications found on internet sites which host or market software packages.
it then uses a novel clustering algorithm especially suited for this task to automatically discover and characterize product features.
it draws inferences about the relationships between features that are not possible when features are extracted from only a handful of requirements specifications.permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
icse may waikiki honolulu hi usa copyright acm ... .
product descriptionsraw feature descriptionsincremental diffusive clustering product feature matrix domain analystinitial product description recommendations feedbackproduct ideafeature namingfeatures featuresfeature names recommender system based on association rules and content based knn recommender.association rulesneighborhoods of products frequent item set graph fig accepted recommendationsscreen scraper feature mining modeling phase recommendation phasefigure feature extraction and recommendations specifically we use association rule mining to identify affinities among product features and we employ knn k nearest neighbor machine learning strategy to identify similar products and make predictions about the existence of features not previously identified.
as a result our approach not only generates a feature model for a given product category but also introduces a sophisticated recommender system capable of recommending features and combinations of features which can provide useful insights during the domain analysis process.
.
overview our feature recommender system includes several different components as illustrated in figure .
the first component is the screen scraper responsible for mining descriptors from online product specifications.
the second component is the incremental diffusive clustering algorithm which clusters descriptors into features .
this clustering algorithm which is capable of identifying both dominant and latent themes from descriptors has been shown in our prior work to perform well for the task of clustering requirements .
the third component is a productby feature matrix which is generated as a by product of the clustering process and is then used to construct a frequent itemset graph fig from which feature association rules can be generated.
the final component is the recommender system itself.
this system utilizes both the product by feature matrix and the fig to generate ondemand feature recommendations.
the feature recommendation process is initiated when a user provides a preliminary product description.
this description is automatically parsed and analyzed to create a partial product profile .
this profile may be relatively sparse representing the case where a user is quite unfamiliar with the domain or it may be relatively rich representing the case where a user understands the core features of the domain but is searching for additional feature ideas that might competitively differentiate the targeted product.
recommendations are made in two different ways.
first the feature recommender utilizes a content based recommender based on the standard knn algorithm to generate feature recommendations.
secondly it utilizes assostep enter initial product description the product will protect the computer from viruses and email spam.
it will maintain a database of known viruses and will retrieve updated descriptions from a server.
it will scan the computer on demand for viruses.
step confirm features we have identified the following features from your initial product description.
please confirm email spam detection virus definition update and automatic update supported disk scan for finding malware internal database to detect known viruses step recommend features based on the features you have already selected we recommend the following three features.
please confirm network intrusion detection why?
real time file monitoring why?
web history and cookies management why?
click here for more recommendationswe notice that you appear to be developing an anti virus software system.
would you like to browse the feature model ?
view feature model figure example of feature recommendations ciation rules which are often able to identify hidden affinities between features across products.
recommendations based on association rules can differ from and thus be complementary to the recommendations made by the knn approach.
furthermore association rules can sometimes be used to generate recommendations from relatively sparse product profiles which can be useful if a user provides only limited information for an initial product description.
figure illustrates a feature recommendation scenario for an anti virus product.
an initial product description is mapped to four features in the recommender s knowledge base related to spam detection disk scans virus definitions and virus databases which serve as seeds for generating feature recommendations.
user feedback is used to drive and refine future recommendations.
the remainder of this paper is structured as follows.
table product categories product product feature category count count antivirus audio players bookmark managers browsers coding languages compilers compression tools debuggers decompilers dissasemblers digital photo tools download managers ftp servers file sharing file managers multimedia ipod tools office suites password managers generators popup ad spyware blockers search engine tools submitting text editors video recording webcam 40182table a small sample of features for a selection of softpedia antivirus products a squared free acronis av ahnlab platinum ahnlab anti trojan elite appranger ashampoo a.m. auslogics av avast!
pro av avast!
int.
sec avg av pro.
avgav firewall avira antivir premium avira smallbusiness suite bkav2008 bitdefender total sec.
bitdefender int.
sec.
corbitek antimw cyberdefender int.
sec.
comodo cloud scanner dr.web g data av fix it utilities pro.
gucup av gsa delphi induc cleaner hazard shield ggreat owl usbav jiangmin av kv k7 av immunet protect mw destroyer kaspersky ultra portables mx one av multicore av antispyware mcafee virusscan microworld av toolkit util.
norton int.
sec.
novashield anti mw novirusthanks mw rem.
norman virus control norton av gaminged.
norton av norman sec.
suite network mw cleaner pc tools int.
sec.
outpost sec.
suite pro nprotect gameguard pers.
quick heal int.
sec.
quick heal total sec.
steganos int.
sec.
steganos av spydllrem.
tizer rootkit razor the shield deluxe the cleaner systemsuite pro.
sysintegrity am vipre av premium virit explorer lite trustport pc sec.
twister anti trojanvirus zonealarm sec.
suite wlording antispyware your free antispyware webroot int.
sec.
windows av mate prof. wimp virusfighter virusbuster pro.
virusbuster personal active detection of downloaded files active detection of instant messenging active detection of removable media active detection of search results anti root kit scan automatic scan automatic scan of all files on startup automatic updates behavioral detection command line scan contain viruses in specific quarantine customized firewall settings data encryption detection of suspcious injected dlls disc scan for finding malware email detection file backup ... ... note this table was manually compiled by researchers at depaul university through inspecting anti virus product listings at it therefore only includes features listed on softpedia.
sections and describe the process for mining and discovering features using the incremental diffusive clustering method.
sections and describe knn and association rule recommendation algorithms.
section describes empirical experiments that were conducted to evaluate the recommender system while section provides an anecdotal example.
section describes related work and section summarizes the contributions of this paper and discusses future work.
.
mining ra w product data all of the feature descriptors used in this paper were mined from softpedia.com .
however our approach is easily adapted for use with product descriptions from other online sources.
softpedia provides descriptions for a wide variety of software products including windows linux mac and mobile applications.
as of august it included over different software applications with over .
billion downloads categorized under primary groupings sub categories and product types.
most products include a section of feature descriptors formatted in a bullet point list format.
as formatting is fairly consistent we utilized the screen scraperc circlecopyrtutility to automate the extraction of the raw product features.
as softpedia and other similar repositories describe products for marketing purposes and do not provide full technical specifications the feature lists for each individual product cannot be expected to be complete.
this is an important observation that impacts the feature mining process.
whereas previous approaches have used a small number of relatively complete specifications our approach which analyzes thousands of individually incomplete specifications is able to automatically infer associations due to the sheer quantity of the analyzed data.
for experimental purposes descriptors were mined from the softpedia product categories shown in table .
table illustrates a small subset of the features manually identified for the softpedia anti virus software products.
it shows that most of the analyzed anti virus systemsinclude core features such as automatic updates ormalware scan as well as variants such as file backup and data encryption which are found in only a small subset of products.
furthermore certain features such as antiroot kit scan are found primarily in anti virus software applications while others such as password manager are common across many different product categories.
various associations can be observed between features.
for example of products containing parental controls also track web history while conversely of anti virus products that provide integration with 3rd party software do not support protected files .
understanding such association and disassociation rules can help improve the organization of feature recommendations.
.
feature discovery our approach utilizes an incremental diffusive clustering idc algorithm that we had previously developed to detect recurring problems in flight anomaly reports .
in this case it was used to construct a domain model of common and variant features.
following a preprocessing phase the algorithm incrementally identifies features by repeatedly executing the following steps i clustering the descriptors into candidate features ii selecting and retaining the best feature iii identifying dominant terms and removing them from all descriptors to produce new reduced descriptors and then iv repeating steps i iii using the increasingly reduced descriptors until the targeted number of features have been generated.
the concept behind the clustering algorithm is to progressively remove terms representing dominant topics around which features have already formed thereby allowing latent topics to emerge.
.
incremental diffusive clustering feature descriptors are first preprocessed by removing commonly occurring words and then by stemming the remaining words to their root form i.e.
terms .
given the dictionary of all such terms t t1 t2 ... t w each raw feature fiis represented as a vector of terms vi fi fi ... f i w wherefi jis a term weight representing the number of occurrences of term tjin the raw feature description fi.
these term weights are then transformed using a standard term frequency inverse document frequency tf idf approach such that tf idf fi j fi j log2 d df j wheredrepresents the total number of raw feature descriptions and dfjrepresents the number of raw feature descriptions containing term tj.
finally the transformed vector with tf idf weights is normalized to a unit vector resulting in the vector vi fi fi ... f i w .
the following steps are then executed to identify features.
step granularity determination to determine how many features to generate for a given product category we adopted a modified version of can s metric which considers the degree to which each raw feature description differentiates itself from other raw features.
the ideal number of clusters kis computed as follows k summationdisplay vi fw summationdisplay j 1fi j vi fi j nj summationdisplay vi f1 vi w summationdisplay j 1f2 i j nj wherenjrepresents the total number of occurrences of term tj.
through observing the results of preliminary clustering experiments we modified the algorithm to exclude terms for whichnjfell below a threshold determined empirically to be .0075d.
introducing this threshold improved cluster quality by removing low frequency terms that had little effect in representing potential features.
step clustering feature descriptors our incremental diffusive clustering idc method uses a consensus clustering approach in which a predefined number of candidate clusterings in this case are generated and then integrated into a final clustering through use of a voting scheme .
although not reported in this paper we previously conducted an extensive comparison of different approaches for clustering requirements and features .
techniques included latent semantic analysis lsa latent dirichlet allocation lda agglomerative hierarchical methods and different variants of k means clustering methods.
our experiments showed that consensus clustering methods used in conjunction with spk outperformed other methods on the tested datasets.
based on these findings we therefore adopted a consensus based approach for the feature recommender system in which each candidate clustering is generated by selecting of the original descriptors clustering them using the standard spk algorithm and then classifying the remaining into their most similar clusters.
multiple candidate clusterings are then reconciled to generate a final set of clusters.
although the consensus clustering algorithm has a relatively long running time it produces results that are consistently of higher quality than the average spk clustering and invariably close to the optimal quality achievable by an individual spk clustering .
step selecting the best cluster in each iteration idc selects and promotes the best cluster to the status of a feature.
based on initial observations the best cluster from a set l c1 c2 ... c k is one that has high levels of cohesion with broad coverage of the topic.
to measure cohesion for a cluster ci vi vi ... v i r with centroid ci the similarity between the features and their associated centroids is computed and averaged as summationtextr j 1sim vi j ci r. while topic coverage is computed as summationtextr j 1sim vi j ci .
cohesion and topic cov erage scores are added together and the cluster with the highest combined score is selected as the best cluster and promoted to the status of a feature.
step removing dominant terms to remove dominant terms all terms exhibiting weights above a predefined threshold .
in the vector representing the centroid of the best cluster are selected.
since the centroids are also normalized this threshold is held constant.
these terms are then removed from all descriptors in the dataset.
for example if dominant terms are identified as instant messag and encrypt shown in stemmed form then a descriptor originally specified as encrypt email messages before transmission is reduced to messages before transmission with the word before also removed as a stop word .
future rounds of clustering are then performed on the reduced version of descriptors.
steps are repeated until the targeted number of features determined previously in step have been identified.
step post processing a post processing step is executed to optimize the identified features.
this step involves the four tasks of i removing misfits ii recomputing centroids iii checking for missing members and finally iv merging similar features.
misfits are removed by computing the similarity score between each centroid and its associated descriptors and then removing any feature descriptions which fall below a given threshold value set to .
based on empirical observations .
centroids are then repositioned according to the remaining descriptors using the same spk algorithm adopted in the initial clustering step.
missing descriptors are identified through recomputing the cosine similarity between every raw feature descriptor not currently assigned to a feature and the centroid of that feature.
any feature exhibiting a similarity score higher than a given threshold set to .
is added to that feature.
finally similar features are merged by computing the cosine similarity between each pair of centroids.
any pair of features exhibiting a score above a given threshold set to .
is merged into a single feature.
step feature naming each feature is named through identifying the me defined as the descriptor that is most representative of the feature s theme.
the me is identified by first computing the cosine similarity between each descriptor and the centroid of the cluster and then summing up the different weighted values in the descriptor s term vector for all values above a certain threshold .
.
both scores are normalized and then added together for each descriptor.
the descriptor scoring the highest value is selected as the feature name.
this approach produces quite meaningful names.
as an example a feature based on the theme of updat databas automat viru was subsequently named virus definition update and automatic update supported .
.
merging category clusters our approach involves processing each product category separately and then merging them into a single productby feature matrix.
this directly mitigates scalability issues of dealing with large numbers of features and has the additional extensibility benefit of allowing new product categories to be added incrementally.
merging is accomplished through computing the cosine similarity between each pair of features and then merging features exhibiting scores of .
or higher.
the end result is illustrated by the three features184table feature analysis easy to use and rotating save friendly user cropping and compressed feature interface resizing images files of categories containing that feature most common file photo video category mcc sharing tools recording of products with that feature .
.
.
in mcc depicted in table .
the first feature easy to use and friendly user interface is an example of a merged feature that cuts across of the analyzed product categories.
in contrast the other two features are specific to one or two product categories only.
.
evaluating feature quality the quality and completeness of features generated for anti virus software multi media ipod applications and photography applications were independently evaluated by three graduate level researchers at depaul and compared against feature models that had been manually developed as answer sets by independent analysts.
each assessor judged whether each automatically generated feature represented i a clearly defined feature that matched a feature in the answer set ii a meaningful feature that was not included in the answer set iii a non unique feature that overlapped with a previously generated feature or iv an ill formed feature that was non cohesive or otherwise did not make sense.
they were also asked to rate the feature name as i excellent ii good iii poor or iv completely inadequate where an excellent feature was described as having a realistic and professional sounding feature name and an inadequate feature name exhibited significant problems such as being too lengthy or grammatically significantly incomplete.
finally each evaluator was asked to either match each feature in the manually created answer set with a similar feature generated by idc or to mark it as missing.
results from the evaluation are shown in table and show that while our approach discovered only about of the features in the answer set it also discovered an equivalent number of unique features that were missed in the manually constructed answer set.
this occurred despite the fact that analysts spent from hours constructing each answer set.
our initial observations suggest that additional features could have been detected by expanding the scope of the screen scraper to mine broader product descriptions beyond items listed as features.
it is also worth noting that our naming algorithm performed very well delivering almost of features there were categorized as good or excellent.
only of names were deemed inadequate.
.
feature recommendations using standard knn once features have been identified a product by feature matrix is generated m mi j p f whereprepresents the number of products and fthe number of identified features.
in a typical domain analysis features are modeled using a specific notation that depicts commonalities vari table user evaluation of feature quality and completeness virus ipod photo overall total features in answer set in both auto gen. and answer set answer set only auto generated only redundant features ill formed features excellent name .
.
.
.
good name .
.
.
.
poor name .
.
.
.
inadequate name .
.
.
.
abilities mandatory and optional features.
in our approach this knowledge is represented in the product by feature matrix and the frequent item set graph.
from these data structures it is possible to infer some of the information that is typically captured as part of a more traditional feature diagram namely commonalities variants and crosscutting features.
for this reason our approach does not explicitly construct a feature diagram.
several steps are needed to generate a feature recommendation.
these include seeding the recommendation request creating an initial product profile using association rule mining to make initial recommendations and then to augment the product profile and finally recommending additional features using a content based recommendation algorithm based on standard knn.
.
creating a new product profile an initial description or list of features is provided for the new product which is then automatically parsed to break the text into segments sentences or phrases remove unimportant terms i.e.
stopwords and stem words to root forms.
the cosine similarity metric is used to match individual segments to previously mined features.
if insufficient matches are found no recommendations are generated and the user is notified that either the targeted product is outside the knowledge of the recommender system or that the initial product description contains insufficient detail to launch a recommendation.
for purposes of this paper we established a threshold score of .
for the cosine similarity and then required at least product specific features to be matched to known features.
the new product profile is appended as a row in the product by feature matrix.
in many cases the initial product profiles may be rather sparse and unable to provide sufficient information to generate high quality recommendations using more traditional techniques such as content or collaborative recommenders.
the association based recommender system described in section can be used to identify additional features from high confidence association rules.
these recommended features can also allow a user to explore the possible feature space for the product.
the user can be asked to provide feedback on these recommendations and then accepted features can be used to augment the product profile in preparation for additional feature recommendations.
.
content based recommendation we adopted a standard k nearest neighbor knn learning strategy to design a content based recommender algorithm.
this approach has been shown to perform well in185our previous work in forum recommendations .
in this context the knn algorithm computes a feature based similarity measure between a new product and each existing product.
the top kmost similar products are considered neighbors of the new product.
it then uses information from these neighbors to infer other potentially interesting features and to make recommendations.
in the first step the product similarity productsim p n between a new product pand each existing product nis computed using the binary equivalent of the cosine similarity as follows productsim p n fp fn radicalbig fp fn wherefpdenotes the set of features of product p .
this metric generates numbers between and where products with identical features score and products with no common features score .
productsim p n is computed between the new product and all previously mined products.
a neighborhood is then computed for the new product p by selecting the top kmost similar products.
based on an initial series of experiments we set the value of kto .
the second key computation of the algorithm predicts the likelihood that stakeholders for product pwill be interested in including a new feature f. for this a variation of the standard prediction formula is used pred p f summationtext n nbr p productsim p n mn f summationtext n nbr p productsim p n wheren nbr p depicts that nis a neighbor of p and mn fis an entry in the matrix mindicating whether product ncontains feature f. in general prediction scores will be computed for each candidate feature and the features with highest predictions will be recommended.
.
feature recommendations using association rules features within product categories exhibit various kinds of associations or disassociations which can be leveraged to improve the accuracy of feature recommendations.
association rule discovery techniques such as the apriori algorithm were initially developed to discover groups of products that buyers typically purchase together.
association rules identify groups of items based on patterns of cooccurrence across transactions.
our approach applies association rule mining to discover latent relationships between features within products.
in this context each product is viewed as a transaction and association rules are generated among sets of features that commonly occur together among a significant number of products.
given a set of product profiles pand a set of features f f1 f2 fk and a feature set fs f letpfs pbe the set of products that have all the features in fs.
the support of the feature set fsis defined as fs pfs p .
feature sets that satisfy a predefined support threshold are referred to as frequent item sets in the following we will refer to these as frequent feature sets .
an association rule ris expressed in the form x y r r wherex pandy pare feature sets r is the support of the feature set x y and ris the confidence for the rule rgiven by x y x .
the discovery of association rules from a transaction database involves two main parts the discovery of frequent feature sets root np rs sp ed ds sq ad np ds np sp np ed np sq np df np ds sq np ds df np ds ed np ds sp np ds df sq np ds ed df np ds sq df0.
.
.
.
.
.
.
.
.
.
.
.
.
ad active detection of search query results ds disc scan for finding malware ed email detectionsp spyware protection sq search queriesfigure a subset of a frequent itemset graph for thenetwork intrusion protection augmented with confidence scores i.e.
itemsets which satisfy a minimum support threshold and the discovery of association rules from these frequent feature sets which satisfy a minimum confidence threshold.
note that association rules are only generated from frequent features sets so features that do not appear in at least one frequent itemsets are filtered out and will not appear in any rules.
the strength of a discovered rule is measured based on the support of the underlying feature set as well as the confidence of the rule.
among other types of analysis association rules have been used as the basis for a class of recommender systems especially in e commerce and intelligent web applications.
the basic approach is to match a partial profile comprised of a set of items against the antecedent xof each discovered rule and then sort the items on the right hand side of the matching rules according to the confidence values.
the top ranked items from this list form the recommendation set.
in our case we start with an initial product profile a set of features and use the association based algorithm to recommend new features.
the new features in turn can be used either as stand alone recommendations or as a way to enrich the initial product profile.
it should be noted that.
if there is not enough support for a particular feature that feature will never appear in any frequent feature set and will therefore never be recommended based on association rules.
in our approach we retain a relatively high support threshold value in order to guarantee that only relatively strong associations are used in the initial recommendations.
to facilitate the search for matching association rules the frequent feature sets are stored in a directed acyclic graph called a frequent itemset graph fig .
the graph is organized into levels from to k wherekis the maximum size among all discovered frequent feature sets.
each node at depth din the graph corresponds to a feature setiof sizedand is linked to features sets of size d that contain iat the next level.
the root node at level 0186corresponds to the empty features set.
each node also stores the support value of the corresponding frequent feature set.
the fig represents the aggregate model learned in the first phase of association rule discovery performed offline.
the recommendations are however generated at query time by performing depth first searches of the fig.
given an initial product profile comprised of a feature set f the algorithm performs a depth first search of the graph to level f .
each candidate recommendation ris a feature contained in a frequent feature set f r at level f .
for each such child node of f the feature ris added to the recommendation set if the support ratio f r f which is the confidence of the association rule f r is greater than or equal to a pre specified minimum confidence threshold.
this process is repeated for each subset of the initial feature set f and conflicting candidate recommendations are resolved by retaining the highest confidence values.
figure shows a small subset of frequent feature sets mined from the anti virus software features.
the displayed itemset graph shows features associated with network intrusion detection .
for example one rule emanating from this graph states that if network intrusion detection np and disk scan for finding malware ds features are found in a product then we have a confidence of .
that the product will also contain an email detection feature.
.
ev aluation evaluating a recommender system is a non trivial task.
the ideal approach would involve conducting a study of several software projects to observe whether any of the recommended features were ultimately included in the final product.
however this type of evaluation would need to be conducted over a long period of time and would require multiple software projects.
fortunately there are several commonly used statistical methods for evaluating recommender systems .
one such method is a leave one out cross validation approach which if applied to the feature recommendation problem would involve systematically removing a random feature from each product profile executing the recommender system to generate a recommendation feature set of size n ranked according to prediction values and determining if the removed feature is part of the recommendation set.
results for leave one out cross validation recommendation experiments are typically evaluated by computing the hit ratio which computes the probability that a given feature is recommended as part of the top nrecommendations produced by the system.
specifically for each product pin the test set a feature fpis randomly removed from the product profile and a recommendation set rn p comprised of the top ranked nrecommended features is produced using the remaining features of p. iffp rn p that is considered ahitfor that product.
suppose pis the set of products used for evaluation.
the hit ratio of the recommendation algorithm relative to a recommendation set size of n is computed as hr n p p fp rn p p .
typically hit ratio values are plotted against different values of n. a hit ratio value of .
indicates that the algorithm was able to always recommend the hidden feature whereas a hit ratio of .
indicates that the algorithm was not able to recommend any of the hidden features.
note that hit ratio increases as the recommendation set size n increases.
in particular ifnis the total number of possible features the hit ratiowill be .
therefore ideally a recommender system should be able to achieve relatively high hit ratios even when the recommendation set is small.
.
experimental design a series of three different experiments were designed to evaluate a realistic use of the feature recommender system in which a domain analyst might provide a partial description of a product and then request recommendations for additional features.
these three experiments evaluate i the use ofknn with various sized product profiles ii the use of association rule mining with incomplete product profiles and finally iii a hybrid approach that utilizes association rule mining to augment incomplete profiles and then uses knn to make additional recommendations.
all experiments described in this paper share a common experimental design so that results can be compared across experiments.
.
experiments were set up as five fold cross validations in which of products from each category were assigned to each set.
in each of five runs one of the sets served as the testing set while the remaining four were combined into a training set.
after five runs each set had served as the test set one time.
it should be noted that this five fold approach was only necessary for the two experiments involving association rule mining however it was applied across all of the experiments so that results could be more easily compared.
.
for each product in the test set lfeatures were randomly selected and retained as the starting product profile.
one of the remaining features was then randomly selected as a target item and removed from the initial profile.
in each case the recommender system was evaluated with respect to whether it was able to recommend back this targeted item.
all other known features were removed from the product profile and not used in the current experiment.
.
to support experiments that included and features in the initial profile plus one target item only products with or more features were included in the experiment.
this resulted in product profiles in the product by feature matrix.
.
.
experiment varying profile size for the first experiment the previously described experimental design was adopted in order to evaluate the use of the knn algorithm.
the experiment was repeated three times with profile sizes of l and .
results are reported in the hit ratio graph shown in figure .
as expected the recommender performed better given larger initial profiles.
it is worth noting that for all three experiments of features were presented in the top features.
for the largest training set l5f1 over features were returned within the top recommendations.
.
.
experiment association rules the second experiment evaluated the use of association rules for making feature recommendations.
again the previously defined five fold experiment was adopted.
in each of the five runs of the experiment a frequent item set graph was constructed from the product profiles in the training set.187figure hit ratio for knn recommendations with initial profile of size and with profiles augmented by association rules knn initial profile sizes were set at l for all products in the test set.
association rules were then generated with respect to these initial profile and used to create recommendations at confidence values of .
or higher.
as recommendations based on association rules tend to be fairly precise but also incomplete the results of this experiment were evaluated by measuring precision and coverage of the recommendations where precision is computed as the fraction of recommended features that were marked as target features and coverage is computed as the fraction of product profiles which received recommendations.
we also measured recall which as expected was relatively low.
results are depicted in figure and show that recommendation precision increases as the confidence threshold is raised until a point of diminishing return is reached.
at lower levels of precision approximately of product profiles received recommendations however this number dropped to only as confidence scores and precision values increased.
these results suggest that although association rule mining can be used to generate a small yet relatively precise set of feature recommendations it would not be effective on its own for finding a more complete set of features.
figure precision and coverage achieved using association rules .
.
experiment augmented profile one of the problems frequently experienced with typical recommender systems is the cold start problem that occurswhen recommendations must be made for a user for whom no profile exists.
in the case of the feature recommender although an initial profile can be extracted from a visionary description of the product the profile may still be relatively terse resulting in a sparse profile.
to address this problem we investigated a novel hybrid approach in which association rules are first used to augment an initially sparse matrix and then the standard knn algorithm is applied to the augmented profile.
the following experiment was conducted to evaluate whether this approach might lead to improved feature recommendations.
the first part of the experiment followed all of the steps described in experiment .
however once the association rules had been used to generate recommendations these recommendations were all automatically accepted and used to augment the initial product profile of size l .
the knn leave one out experiment described in experiment was then conducted against the augmented profiles.
results are also reported in figure as knn .
these results should be compared to l3f1 as both cases had initial profile sizes of l .
using the association rules to augment the originally sparse product profile led to significant improvements.
for example knn showed improvements of approximately in the top recommendations in the top ten and greater than in the top recommendations.
.
analysis of results results from these experiments have shown that the knn recommender system has the ability to recommend useful features to users.
it performs better as the size of the product profile increases.
furthermore when the product profile is sparse association rules can be used quite effectively to enrich the profile and improve the performance of the knn recommender.
there are a number of threats to validity for our study.
first all of the feature descriptors are mined from a single repository.
however this repository is very large containing many hundreds of thousands of product descriptions.
we anticipate that our approach will generalize to other sources of product descriptions simply by customizing the screen scraping and feature extraction process.
a threat to the generalization of our approach is that the software applications on softpedia represent small to medium sized applications each of which tends to perform a very specific task.
we therefore cannot yet claim that our approach would apply for large software systems in which numerous modules must interact in carefully defined ways.
nevertheless the feature recommender system could still prove useful for proposing features for various components of such larger software systems.
our approach is also limited by the scope of the products described in online repositories.
however we leave it to future work to explore broadening the descriptor mining process to discover and incorporate a much larger set of product features.
.
an anecdotal example to illustrate the use of the feature recommender in a more anecdotal way table provides a simple example of recommendations made as a result of seeding a product profile with four initial features.
three of these features were related to managing music while one was a general usability feature.
the association rules identified one additional fea 188ture related to dragging and dropping of files into the play list with a high level of confidence.
this feature was added to the product profile.
the knn recommender then proposed several additional recommendations most of which appear to be very viable suggestions.
the one exception is create photo albums which appears unrelated but introduces the serendipitous idea of creating music albums.
in general this example demonstrates that the feature recommender took a relatively sparse initial product profile and made a series of viable and useful feature recommendations.
table anecdotal example easy to use and friendly user interface initial profile listen to internet radio streams supported audio file formats mp3 wma ogg flac mp4 m4a features recommended drag and drop files into the playlist by association rules customize the program with user interface skins audio formats supported wav ogg mp1 mp2 mp3 mod xm it s3m mtm umx mo3 band equalizer with presets features recommended play media video files mp3 by knn wav wma mpg mpeg avi create photo albums export albums to burn to cd dvd support winamp2 x and sonique visualizations and plugins easy to use only click .
related work this work bridges the gap between automated feature detection and recommender systems.
we therefore provide a brief background survey on each of these areas.
several researchers have previously investigated the use of information retrieval methods for constructing feature models.
for example the domain analysis and reuse environment dare uses semi automated tools to extract domain vocabulary from text sources and then identifies common domain entities functions and objects by clustering around related words and phrases.
chen et al.
manually construct requirements relationship graphs rrg from several different requirements specifications and then use clustering techniques to merge them into a single domain tree.
vander alves et.al.
utilized the vector space model vsm and latent semantic analysis lsa to determine the similarity between requirements and generate an association matrix which is then clustered.
a merging step is then executed to create the entire domain feature model.
noppen et al.
extended this work by including fuzzy sets in the framework to allow individual requirements to be associated into multiple features.
niu and easterbrook developed an on demand clustering framework that provided semi automatic support for analyzing functional requirements in a product line .
weston et al.
introduced a tool named arborcraft which creates feature models from requirements specifications by utilizing clustering methods to identify initial features and then a vocabulary lexicon and grammatical pattern matching to identify feature variants.
the primary limitations of these approaches are their reliance upon existing requirements specifications and the constraints associated with miningfeatures from only a small handful of specifications.
on the other hand such requirements specifications provide a deeper perspective of the product than our approach has to infer through analyzing hundreds of different product specifications.
the field of recommender systems has also been studied extensively but mostly within the context of e commerce systems where numerous algorithms have been developed to model user preferences and create predictions.
these algorithms vary greatly depending on the type of data they use as an input to create the recommendations.
for example some use content information about the items or collaborative data of other users ratings or knowledge rules of the domain or hybrid approaches .
substantial amounts of work have been done in the area of evaluating recommender systems and on newer highly efficient algorithms such as those based on matrix factorization .
despite the proliferation of both of these fields there has been very little work combining recommender systems and requirements engineering.
work in this area has focused on recommending topics of interest in large scale online requirements forums and a high level overview of possible usages and applications of recommender systems in this domain .
the use of recommender systems in this paper builds on the substantial background of research in this area.
.
conclusions this paper has presented a novel approach for mining and recommending product specific features and therefore providing support for the critical software engineering task of domain analysis.
it differs significantly from prior work in the area of feature mining which relies upon the availability of detailed requirements specifications or documentation.
in contrast our approach discovers features and their associations through mining publicly available repositories of product descriptions.
to achieve this we have introduced a novel incremental diffusive clustering algorithm which is well suited to discovering features.
another novelty of this work is the hybrid approach which uses association rule mining to augment an initial profile and then uses the standardknn approach to make additional recommendations.
finally to the best of our knowledge prior work in the area of feature mining has focused on automating the discovery of features from requirements specifications but has not developed a corresponding recommending system.
in our case the statistical engine behind the recommender system is enabled because of the large amount of supporting product data.
the findings reported in this paper introduce numerous additional questions and areas of future work.
in the area of feature mining we plan to extend the work to mine feature descriptions from general product descriptions instead of limiting them to the bulleted lists found in softpedia.
we believe this will enrich the profiles of each individual product.
furthermore future work will also include using both positive as well as negative associations among features to enhance knn recommendations.
.