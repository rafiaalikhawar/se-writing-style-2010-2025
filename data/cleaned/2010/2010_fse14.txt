mining preconditions of apis in large scale code corpus hoan anh nguyen hoan iastate.edurobert dyer rdyer iastate.edutien n. nguyen tien iastate.eduhridesh rajan hridesh iastate.edu iowa state university ames ia usa abstract modern software relies on existing application programming interfaces apis from libraries.
formal specifications for the apis enable many software engineering tasks as well as help developers correctly use them.
in this work we mine large scale repositories of existing open source software to derive potential preconditions for api methods.
our key idea is that apis preconditions would appear frequently in an ultra large code corpus with a large number of api usages while project specific conditions will occur less frequently.
first we find all client methods invoking apis.
we then compute a control dependence relation from each call site and mine the potential conditions used to reach those call sites.
we use these guard conditions as a starting point to automatically infer the preconditions for each api.
we analyzed almost million lines of code from sourceforge and apache projects to infer preconditions for the standard java development kit jdk library.
the results show that our technique can achieve high accuracy with recall from and precision from .
we also found preconditions missing from human written specifications.
they were all confirmed by a specification expert.
in a user study participants found of the mined preconditions as a good starting point for writing specifications.
using our mining result we also built a benchmark of more than precondition related bugs.
categories and subject descriptors f. .
specifying and verifying and reasoning about programs keywords specification mining jml preconditions big code mining .
introduction software in our modern world is developed using frameworks and libraries which provide application programming interfaces apis via classes and their methods.
to be able to correctly use these apis programmers must conform to their specifications.
for example in the standard java development kit jdk a call to permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
fse november hong kong china copyright acm ... .
.next in alinkedlist needs to be preceded by a call to hasnext to ensure the list still has elements.
for each api method there are conditions that must hold whenever it is invoked.
these are called thepreconditions of the api.
for example in the jdk string class the condition beginindex endindex must hold when the method substring beginindex endindex is called.
these conditions as part of the api s specification have been shown to be useful for many automated software engineering tasks including the formal verification of program correctness generation of test cases building test oracles bug detection design by contract etc.
popular formal specification toolsets include esc java bandera java path finder jmlc kiasan code contracts etc.
manually defining specifications for libraries is time consuming.
one must read the documentation of the apis and even the source code and convert the conditions to the formats suitable for verification tools.
to ease defining specifications several approaches have been proposed to automatically derive the specifications.
generally there are two types of approaches that complement each other program analysis based anddata mining based approaches.
among program analysis approaches dynamic approaches could detect data and temporal invariants and recover program behaviors.
however they require a large number of test cases and their results might be incomplete due to the incompleteness of the test suites.
on the other hand static analysis approaches do not require dynamic instrumentation but have high false positive specifications .
importantly those static techniques focus their analyses only on an individual project which has the call sites for only a small number of apis .
in contrast to program analysis based approaches other techniques in the mining software repositories msr area have applied mainly data mining to derive api specifications from existing code repositories .
the key difference of these mining approaches from the traditional program analysis based approaches is that they consider the usages of the apis at the call sites in the client programs of the apis to derive the conditions regarding only the usage orders or temporal orders among the api calls.
while some approaches detect such orders as pairs of method calls e.g.
pmust be called before q other approaches mine the sequences of calls or even a graph or finite state diagram of method calls .
other mining approaches focus on associations of api entities .
unfortunately those mining approaches do not aim to recover pre and post conditions as part of specifications.
moreover except a few methods they mainly rely on mining techniques without in depth analyzing the data and control properties in the mined code.
this paper introduces an approach that puts forth the idea of mining api specifications that combines both static analysis and sourcepermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
fse november hong kong china copyright acm ... .
166code mining from a very large code corpus in open source repositories to derive the preconditions of apis in libraries and frameworks.
we expect that the apis preconditions would appear frequently in an ultra large corpus of open source repositories that contain a very large number of the usages of those apis while projectspecific conditions will occur less frequently .
importantly we combine the strength of both static analysis approaches via control dependency analysis and msr approaches via mining to make it scale to large corpus.
moreover we can derive preconditions for a large number of apis or entire library at the same time.
specifically we used a very large scale data set from sourceforge consisting of java projects with source files methods and slocs and from apache consisting of projects with source files methods and slocs.
to analyze the apis client code in such large data set we did not choose the dynamic analysis approach since it would require the generation of a very large number of test cases and a great deal of execution time.
instead we develop a light weight intra procedural static analysis technique to collect all predicates for every api method in the data set.
our technique first builds the control dependence relation for each method.
it then analyzes different paths and conditions that lead to each method to recover all primitive predicates for all api methods in the data set.
after that it will start mining on the preconditions by performing normalization merging filtering and ranking on them.
in our empirical evaluation we compared the mined preconditions with the real world jml specifications for several jdk apis that are created and maintained by the jml team .
the results show that our precondition mining technique can achieve high accuracy with recall from and precision from for the top ranked results.
we also found new preconditions for two jdk classes that were not listed by the jml team.
we reported to the team and got their confirmation on those preconditions.
moreover we filed to the jml team the preconditions for previously unspecified methods in jdk classes and they accepted all proposals.
importantly our method is light weight and scales to such large amount of code allowing us to derive preconditions for entire jdk library.
we also conducted a user study on human subjects who have experience with specifications on the usefulness and correctness of our mined preconditions.
of the participants found that our result is a good starting point for writing specifications for apis under study.
in addition to supporting specification writing we show the usefulness of our mined preconditions by using them to build a benchmark of more than api call sites that might be buggy due to missing precondition checking.
it is useful for tools to detect neglected conditions .
our key contributions include .
a novel approach that combines the strength from both code mining in a ultra large code corpus and program analysis to derive the preconditions of apis in libraries and frameworks .
an empirical evaluation on a very large scale data set to mine preconditions of jdk apis.
section will explain an example that motivates our approach.
our key program analysis and mining technique is presented in section .
section is for our empirical evaluation.
related work is described in section .
conclusions appear last.
.
motiv ating example we first present an example of an api in java development kit jdk and then discuss the observations motivating our approach.
an example.
let us consider an example of a commonly used api from the java development kit jdk string.substring int int in the java.lang package.
the method takes as input two integer1public boolean setpathfragmentation int servletpathstart int extrapathstart 2if servletpathstart extrapathstart servletpathstart completepath .length extrapathstart completepath .length servletpathstart extrapathstart return false 7if servletpathstart completepath .length ... return true if completepath .charat servletpathstart !
return false if extrapathstart completepath .length ... return true if completepath .charat extrapathstart !
return false contextpath completepath .substring servletpathstart servletpath completepath .substring servletpathstart extrapathstart ... return true figure client code of api string.substring int int in project semoa at revision .
values beginindex the index of the starting character inclusive and endindex the index of the the ending character exclusive .
the method returns a new string that is the substring of the original string using the two indices.
examining this api we could learn that there are three preconditions that must hold before it is called .beginindex .endindex this.length and .beginindex endindex .
a precondition for an api to be used could involve the receiver object of the api and or one or multiple of its arguments .
identifying the complete set of preconditions for an api is a difficult and time consuming task.
however this particular api is extremely popular one of the most frequently used apis from the jdk and there is another way to learn these preconditions without having to even look at the documentation or source code for the method.
consider one example usage of this api as shown in figure .
the method request.setpathfragmentation ... in the semoa project uses this api lines and .
examining the source we can see several conditions that must be false in order for the controlflow to reach the api calls.
for example the ifstatement on line must be false meaning that both indices servletpathstart andextrapathstart must be non negative the indices must not be greater than the length of the string completepath and servletpathstart must not be greater than extrapathstart .
these are the same conditions we saw in the documentation.
this gives us our first observation observation .preconditions can be inferred by looking at the conditions that must be satisfied before calling the apis i.e.
the guard conditions of the api call sites.
let us consider line of figure .
it contains another call to the api.
the only difference is that at this call site instead of a variable constant value 0is passed as the first argument.
thus the conditions on an argument of an api can be derived from the properties of such value passed to the api.
this gives the observation observation .the mining tool should take into account the properties of the arguments passed as the apis parameters.
this client code however contains other conditions checked before the api call.
some of these conditions are specific to the logic of the client lines and .
this gives our next observation 1671private string getcommand int pc boolean allthisline boolean addsemi 2if pc lineindices.length return 4if allthisline ... return ... 8int ichbegin lineindices 9int ichend lineindices ... string s if ichbegin ichend ichbegin ichend script.length return try s script.substring ichbegin ichend ... figure client code of api string.substring int int in project jmol at revision .
observation .call sites might contain client specific conditions which could cause noise when inferring preconditions.
thus an approach that mines preconditions from call sites should attempt to minimize such noise.
this has been a challenge for the existing static program analysis based approaches when they examine the call sites of the apis only within the code of the apis programs.
one way to minimize noise is to mine preconditions from a large number of projects .
the valid preconditions should appear more frequently while client specific conditions should appear infrequently.
figure shows another client jmol that uses the same api line in the method scriptevaluator.getcommand ... .
the ifstatement on line checks the three required preconditions.
note that in this case the checked condition is stronger than the required one the beginning index ichbegin isstrictly less than the ending index ichend .
this gives our next observation observation .the relationship between conditions should be considered when mining preconditions.
for example a stronger condition should be counted as an instance of a weaker one.
a mining tool must consider the relations among conditions to derive a precondition.
similar to the previous client code this method also contains client specific conditions lines and .
again these conditions are project specific and not actual preconditions for the api in question.
however these conditions do not appear in the first client code and thus we start to see evidence that such noise would appear less frequently.
motivation.
this example motivates us to use an approach to mine the preconditions via the guard conditions of the call sites of the apis under study in a very large number of projects in a large scale corpus.
that would help to minimize the project specific conditions as noises because they will appear less frequently in the large corpus.
the true preconditions would occur more frequently.
in this paper we introduce such an approach that mines the preconditions of the apis.
in fact after running our mining tool on a very large data set from sourceforge consisting of java projects with source files classes methods and slocs we are able to derive the preconditions for the string.substring method in jdk.
the columns in table show the preconditions with highest frequencies in the corpus that we mined for the receiver string object and the arguments beginindex andendindex respectively.
as seen the aforementioned true preconditions have among the highest frequencies.
projectspecific conditions did not make the top of the list.table mined preconditions for string.substring int int receiver object rcv beginindex endindex rcv.length rcv.length beginindex endindex rcv.length endindex beginindex endindex endindex !
rcv.length beginindex beginindex rcv.length endindex .
mining with large code corpus let us outline our approach for mining the preconditions for api methods.
figure gives an overview which can be summarized as .
the input is the set of all api methods under analysis and client projects to mine.
.
for each method in the corpus that calls an api we build the control dependence relation between each method call and the predicates in the method from the control flow graph and identify all preconditions of api calls.
section .
.
next we normalize the preconditions to identify and combine the equivalent ones.
section .
.
we then analyze the preconditions to infer additional ones which are not directly present in the client code.
section .
.
finally we filter out non frequent preconditions section .
and rank the remaining ones in our final result.
section .
.
control dependence and preconditions in order to identify the preconditions of api calls we need to identify all predicates that guard the evaluation of each method call in the program.
this can be done by building the control dependence relation based on the control flow graph cfg .
in a cfg each predicate node has exactly two outgoing edges labeled true andfalse representing the two corresponding branches.
definition .a method call ciscontrol dependent on a predicate expression pif and only if on the corresponding cfg all directed paths from ptocgo out ofpon the same edge either true orfalse .
this means that cis control dependent on pifcis executed in only one branch of p. ifccould be called in both branches of p thenc s execution does not depend on p. for example in figure string.substring on line is called only in the false branch of the predicate on line thus it is control dependent on that predicate.
our definition is stricter than the traditional definition by ferrante et al.
which requires calways be called in one branch ofpand not called in at least one path in the other branch.
according to that a method could be called in both true andfalse branches of the predicate on which it is control dependent thus the value of the predicate does not control the execution of the method call.
this is the reason we give an adaptation in definition .
definition .an api method miscontrol dependent on a predicate expression pin a client method if and only if all call sites ofmin the client method are control dependent on exactly one branch ofp true orfalse .
whenmis control dependent on the false branch ofp the predicate that guards mwill be the negation of the predicate expression inp.
we now define what we consider to be a precondition for calling a method.
definition .aprecondition of a method call is a single clause in the conjunctive normal form cnf of a predicate on which the method call is control dependent.168ifentry a1 a2 cfg m n ranking filtering inference normalization 1p1 2p2 .. .. npnapis projects conf p conf pr p conf m p normalize p p a b q a b t a b p q p q mined preconditions p for each p mined preconditions calling methods m1 .. m n for each m i find methods that call apis ifentry a1 a2 cfg .. m1 api p .. .. m2 api p .. .. .... mn api p .. .. control dependence relation ifentry a1 a2 cfg m 1figure approach overview we first find all methods that call each api and compute the control flow graph for each.
then we generate the control dependence graph to identify conditions leading to an api call.
from that we create an inverted index then normalize each condition.
we infer and merge conditions and then filter some out.
the final list is ranked giving us our result.
in figure the api call on line is control dependent on the false branch of the ifstatement on line so the predicate is negated and gives us !
ichbegin ichend ichbegin ichend script.length .
this predicate is represented in cnf as !
ichbegin !
ichend ichbegin !
ichend script.length .
moving the negations inside we have a set of three preconditions ichbegin ichend ichbegin andichend script.length .
for the goal of deriving general specifications the contextspecific names expressions must be abstracted away from the individual method call sites.
since each call contains a receiver object and list of arguments we are interested in the preconditions on each of these components.
we use rcvandargi as the symbolic names for the receiver object and the i th argument in the list of arguments respectively.
first we match the expression of the receiver and that of each parameter of the method call against the expression of the precondition.
then we try all possible substitutions of occurrences of the receiver and parameters with their corresponding symbolic names.
if the condition contains a variable field its latest value will be used in the precondition.
its latest value is the expression in the right hand side of its most recent assignment if any .
in the above example processing the three preconditions ichbegin ichend ichbegin and ichend script.length of the method call script.substring ichbegin ichend will result in the following abstracted preconditions arg0 arg1 arg0 andarg1 rcv.length .
a condition that does not involve any component of the call i.e.
having no symbolic names will be discarded.
finally to follow observation for each expression epassed as argument argito a method call we create a precondition in three cases.
first if eis a constant of a primitive type we create a precondition argi c .
second if eis an expression that can be recognized via its syntax as returning a non null object e.g.
object instantiation or array initialization expression we create a precondition argi !
null .
third ifeinvolves any component of the call i.e.
having some symbolic names we create a precondition argi e wheree0is obtained from eby replacing identifiers with the corresponding symbolic names e.g.
arg1 rcv.length .
these equality preconditions are used to support the inference of the non strict inequality preconditions such as arg1 orarg1 rcv.length .
table shows the resulting preconditions mined from our example api using this process.
for each api the preconditions aretable extracting preconditions for string.substring int int from the usages in figures and .
figure line figure line figure line arg0 arg0 arg0 rcv.charat arg0 arg0 rcv.length arg1 arg0 arg1 arg0 !
rcv.length arg1 rcv.length arg1 !
rcv.length rcv.charat arg0 rcv.charat arg1 arg0 arg1 arg1 arg1 rcv.length arg1 !
rcv.length rcv.charat arg1 stored in a map in which p returns the set of calling methods containing precondition pbefore calling the api.
.
precondition normalization since we collect preconditions from call sites in different methods and projects there are conditions that are equivalent but expressed in different forms.
for example the following arg1 arg0 arg0 arg1 arg0 arg1 arg1 arg0 and arg0 arg1 express the same conditions.
thus we need to normalize the preconditions.
the first step is to ensure every unary binary expression is enclosed by exactly one pair of opening and closing parentheses.
the next step is to order the operands in the binary operation s such as etc.
of the preconditions so that they are comparable between call sites.
whenever two operands of a binary operation are re ordered the operator is reversed correspondingly.
for any comparison expression e elder where dis a comparison operator we transform it into e0 e0 lde0 r where e0 rcontains only literals and e0 lcontains all symbolic and other identifier names.
if e0 rcontains all numeric literals it will be evaluated.
the terms in e0 lare ordered in the ascending order of its symbolic names.
for example all conditions above will be normalized into the same condition arg0 arg1 .
finally the map is updated with the normalized preconditions for each api.
.
precondition inference inferring non strict inequality preconditions.
in the client code a non strict inequality precondition a b ora b might be split into strict inequality a b ora b and equality a b condi 1691for each precondition p a b 2for each precondition q a b orq a b ifq a b then t a b else t a b ifj p j j q jthen t t p q else ifj p j j q jthen t t q else t t p figure inferring non strict inequality preconditions.
tions and checked at different call sites.
figure shows our algorithm for inferring the non strict inequality precondition.
when the two preconditions pandqare used equally all call sites for both of them are counted toward the inferred condition line .
otherwise only the call sites of the less frequently used precondition are added lines and .
this helps us avoid counting the occurrence frequencies of incorrect conditions toward the inferred one.
merging strong and weak conditions.
among the preconditions some imply others observation .
if a stronger condition holds the weaker condition holds too.
this means that all call sites of the stronger condition could be merged to counted toward those of the weaker.
however merging can lead to inferring wrong preconditions if the weaker one is in buggy code or specific to a particular client observation .
we avoid this noise by using the assumption that the more frequently a precondition is checked the more likely it is correct.
thus if the stronger condition is less frequently checked than the weaker one its call sites will be merged to those of the weaker and it will be removed from the set of preconditions.
1for each pair of preconditions p q 2ifp!q j p j j q jthen q q p remove pfrom figure merging preconditions with implication.
the procedure is shown in figure .
note that this merging will remove all equality and or strict inequality preconditions composing the non strict ones.
for example if two conditions p arg andq arg infer the condition t arg andpis stronger and less frequently checked than t as at line in figure its call sites containing pwill be added to those of t. then pis removed.
dealing with dynamic dispatch.
since the data types cannot be precisely resolved at static time some actual api calls could be missed in our static analysis thus all their preconditions at those call sites could be missed too.
for example method obj.add which is resolved at static time as list.add because objis declared as list could actually be arraylist.add at runtime.
we address this with a conservative solution that whenever a set of preconditions is extracted for a call of api m that set is also considered as the preconditions of all apis that override or implement min the library.
the rationale behind this is the assumption of behavioral subtyping in which preconditions cannot be strengthened in a subtype .
thus this heuristic will enrich the set of extracted preconditions for a sub type with those from the super type which are the same or stronger than the actual ones.
those preconditions could be merged to the actual ones and increase the confidence of the actual ones.
.
precondition filtering since we mine preconditions from many projects methods in a large scale code corpus there are conditions which are contextspecific or might even be incorrect.
these conditions are not useful for building the api specifications and should be filtered out.
first we remove all conditions which are checked only once in the whole code corpus.
then for each api we remove all conditions which have low confidence in being checked before calling the api.
the confidence of a precondition for an api is measured as the ratio between the number of code locations checking the condition before calling the api over the total number of locations calling the api.
we compute two values for confidence corresponding to two types of locations one over client projects conf pr and another over client methods conf m conf pr p j p j s q q conf m p j p j s q q where p is the set of projects with condition pbefore the api call.
for each api we keep only the preconditions that have both confidence values higher than or equal to a certain threshold .
we use 5in our experiment.
.
precondition ranking for each api we rank the preconditions based on their total confidence which is computed as conf p conf pr p conf m p .
using onlyconf m p might favor the conditions used a lot but only in a small number of projects.
in contrast using only conf pr p might favor the conditions which are accidentally repeated in many projects but not used frequently.
thus our approach combines both confidence values to rank the preconditions.
different from the traditional ranking scheme that puts all items in one list our approach uses different ranked lists for the receiver object the arguments of an api and any combinations of them.
only the top precondition in each ranked list is kept in the final result.
.
ev aluation in this section we aim to answer two research questions rq1.
how accurate are the preconditions mined by our approach?
the answer to this question would tell whether our approach works in identifying the preconditions from usages in a large code corpus.
rq2.
how useful are the mined preconditions as a starting point in writing api specifications?
.
data collection we collected a large code corpus from two sources sourceforge.net sf and apache software foundation asf .
sf is a free source code hosting service for managing open source software projects.
asf is an american non profit corporation who manages the development of apache open source projects.
for sf we downloaded project metadata in json format from its website and collected information about all projects that are selfclassified to be written in java.
to get higher quality code for mining the preconditions we filtered out the projects that might be experimental or toy programs based on the number of revisions in the history.
we only kept projects with at least revisions.
we downloaded the last snapshots of each project.
we eliminated from the snapshot of a project the duplicated code from different branches versions of the project.
for asf we checked the list of all apache projects and downloaded the source code of the latest stable releases of all projects written in java.
table shows the statistics on our datasets.
sf has projects satisfying the above criteria and asf has projects.
they both have hundreds of thousand of source files.
the total amount of code is almost million lines of code slocs where sf contributes about four times more than asf.
the projects are written by thousands of developers and cover a variety of domains and topics.170table collected projects and api usages.
sourceforge.net apache projects total source files total classes total methods total slocs total jdk public classes total jdk public methods total used jdk classes total used jdk methods total method calls total jdk method calls public normal behavior requires beginindex beginindex endindex endindex length ensures result !
null result.stringseq.equals this.stringseq.
subsequence beginindex endindex also public exceptional behavior requires beginindex beginindex endindex endindex length signals only stringindexoutofboundsexception 13public string substring int beginindex int endindex figure jml specification for string.substring int int in this experiment we focus on the apis in the jdk library.
analyzing all apis from the java packages we found that there are public classes and public methods in the library.
we also observed that many apis have not been used at all in the studied projects.
only and of the accessible jdk classes have been used in sf and apache respectively.
the corresponding numbers of jdk methods used are and respectively.
in both sf and asf about one fourth of the number of all method calls are the calls to jdk methods.
this number shows that those open source projects are heavily based on the jdk library.
.
ground truth java modeling language jml preconditions in order to evaluate the accuracy of our mined preconditions we used a ground truth of known correct preconditions.
the java modeling language jml is a language for specifying the behavior of java classes and methods.
specifications are defined using a custom syntax inside of special comments that start with .
figure shows part of the specification in jml for the substring int int method discussed in section .
the specification defines both normal behavior lines and exceptional behavior lines and signals certain exception when certain preconditions hold line .
the normal behavior for this method requires three conditions to hold prior to calling the method.
these conditions are declared using requires statements and boolean expressions lines .
the specification also ensures that after finishing normal execution two conditions hold.
these are declared using ensures statements and boolean expressions line .
a precondition is a clause in the conjunctive normal form of the boolean expression following a requires keyword in a normal behavior or a clause in the conjunctive normal form of the negation of the boolean expression follow table specifications for jdk classes from jml website package number of classes full spec some spec no spec total java.io java.lang java.net java.sql java.util java.util.regex all table jml preconditions of jdk methods in classes with full specifications number of preconditions methods number of methods .
number of preconditions .
ing a requires orsignals keyword in an exceptional behavior .
if a specification has multiple normal and or exceptional behaviors we combine them by taking the union set of the preconditions.
for example if preconditions i and i appear in two normal behaviors they will be combined into a precondition i .
the preconditions are then abstracted using the symbolic names.
the authors and maintainers of jml have written specifications for several popular java packages from the jdk and published them on their website .
we downloaded and analyzed these specifications.
as shown in table there are specification files for classes from jdk packages.
after analyzing we learned that in class files there are no specifications for any method column no spec and in other files there are specifications for some methods but not all column some spec .
we read the remaining files which contain specifications for all methods column full spec and extracted all preconditions for all of their methods.
table summarizes the number of extracted preconditions of the methods in those classes.
we group the methods based on the numbers of extracted predicates in the preconditions.
in total there are preconditions for methods in which of them have no preconditions of them have one precondition and so on.
as seen most of them have from to preconditions.
a much smaller percentage of methods has more than preconditions.
.
rq1 accuracy .
.
result we ran our tool on the two datasets and compared the mined preconditions with those in the jml ground truth.
we used two metrics precision and recall.
precision is measured as the ratio between the number of correctly mined preconditions and the total number of mined preconditions.
recall is measured as the ratio between the number of correctly mined preconditions and the total number of preconditions.
a mined condition is considered correct if it is exactly matched with one precondition of the same method in the ground truth using syntactic checking.
if a mined condition is not in the ground truth we manually verified it.
if it is a not yet defined one or semantically equivalent with a precondition e.g.
!rcv.isempty andrcv.size or implied by the preconditions of that method in the ground truth e.g.
b is implied by a and a b it is counted as correct.171table mining accuracy over preconditions mined precision recall time sourceforge 17h35m apache 34m both 18h03m table mining accuracy over methods dataset fully covered total.inc.
total perfect extra extra sf .
apache .
both .
table shows the accuracy for all mined preconditions.
in both datasets the tool achieved high accuracy with recall from and precision from .
the accuracy for two sources is comparable.
the accuracy for sourceforge is a bit higher than that for apache.
when both datasets are combined precision lies between those for two datasets.
however recall is slightly improved since a few more api methods which were not seen in either dataset have been included in the result for the combined dataset.
table shows more detailed numbers on the mining accuracy for all the api methods.
as seen with the sourceforge dataset our tool can cover all of the preconditions for out of jdk methods in the ground truth.
that is in of given methods under investigation specification writers would just have to verify and remove some incorrect ones.
among those we can derive perfectly the preconditions for methods.
that is in of methods specification writers would use the set of preconditions as is.
there are and .
methods having and more than extra incorrect preconditions respectively.
our tool cannot produce any correct preconditions for only of the methods.
the numbers are comparable for apache and the combined dataset.
thanks to our light weight analysis the running time for apache which has more than 25m slocs and .2m jdk api calls is just minutes.
the time for sourceforge and for both is much longer mainly due to accessing the local svn repositories.
.
.
analysis incorrect cases.
we first analyzed the incorrect cases .
since the jml specifications were manually built by the jml team it is possible that some preconditions are still missing from the current version of their specifications.
thus for the mined preconditions that are not in the ground truth from the jml team we manually verified them to see if they are truly incorrect cases.
we found correctly mined preconditions that were missing in the ground truth .
we sent them to the main author of jml.
he kindly confirmed all five cases.
this is evidence that our tool could help specification writers reduce their effort and mistakes.
table shows the summary of the incorrectly mined preconditions which are classified into types.
for majority of the incorrect cases the mined preconditions are stronger than the actual ones.
the reason is that our tool cannot distinguish between the precondition as part of an api usage and the one as part of the api specification.
for example the api java.util.list.add object accepts a nullargument.
however in many usages of that api in the client code developers often perform nullchecking for the argument before calling it.
thus our tool reported the incorrect condition arg0 !
null .
another example is the api file.mkdir which does nottable newly found preconditions in jml specifications class method precondition string getchars int int char int arg3 stringbuffer append char arg0 !
null bitset flip int int arg0 arg1 set int int arg0 arg1 set int int boolean arg0 arg1 table different types of incorrectly mined preconditions dataset total stronger irrelevant analysis.err.
sourceforge apache both require any preconditions in its specification.
if the operation fails for some reason it will return null.
however to avoid unnecessary operations to the file system and control the reason of the failure developers often check file existence with !exists before calling mkdir .
another example is the method valueof object obj .
our tool detects the null checking on the argument arg0 !
null from several client projects but it is not part of its specification.
these examples show an interesting gap between the actual api usages from client code and the intended usages from the api designers.
this suggests a further investigation for api designers on how to adjust to support developers better in the apis client code.
in the second type of incorrect cases the conditions along the path to an api call are irrelevant to the preconditions of the api.
for example it is frequent that developers check if both arguments are positive before calling math.min .
those checks might make sense in term of the logic of the program however they are not relevant as the preconditions.
for the third type a few incorrect cases are caused by the imprecision in our light weight static program analysis .
an example is incorrectly mined precondition arg0 ofstringbuffer.
ensurecapacity int .
in the code the call to this api belongs to the branch satisfying arg0 however the sign of arg0 is reversed before the call.
our analysis did not keep track of the value change in the code leading to the call thus extracted incorrect condition.
to track value changes we can use dynamic symbolic execution.
missing cases.
to better understand the missing cases we examined all the preconditions which are in the ground truth but were not mined by our tool.
we classified the missing cases into four categories as shown in table .
each cell of the table shows the ratio between the number of missing cases in the corresponding category over the total number of preconditions in the ground truth.
the first category column no call consists of the preconditions of the api methods that have their jml specifications in the ground truth but have never been called in the client code in our datasets.
for sourceforge there are such methods with preconditions.
for apache the corresponding numbers are and .
for those methods and preconditions which contribute about and of the total numbers of preconditions respectively our tool can not mine the preconditions.
thesecond category column private contains the preconditions involving the apis private and internal fields or methods which are inaccessible from client code.
examples of this category are .
precondition !changed ofobservable.notifyobservers changed is a private field of the observable class to represent the172table four types of missing preconditions no call private no occur low freq.
sf apache both internal state of the object.
the method notifyobservers is called only if the object s state was changed.
.
precondition parseable s ofinteger.parseint string s this condition requires the string argument of parseint to be parseable.
.
precondition capacityincrement ofstack.push object the stack can only be pushed if its internal capacity is larger than .
the first two categories are due to the inherent limitation of mining approaches on client code however their percentages are small.
the last two categories contain the preconditions which could occur in the client code but are not in our result due to the limitations of our static analysis that cannot detect the occurrences of the conditions no occur.
or due to the cut off thresholds low freq.
.
.
.
accuracy by data size when computing accuracy we also analyzed the impact of the size of dataset in our algorithm.
we ran our tool on various data sizes.
from each full dataset sourceforge and apache we created the datasets of size bby randomly selecting the projects of the full dataset into bins having the same number of bprojects.
using each bin as input we ran our tool on it and recorded the accuracy precision andrecall for that bin.
then we computed the average accuracy over all bins and used that accuracy for that size.
in this experiment we chose b 2i meaning that we kept increasing the data sizes by a power of until reaching the full dataset.
to consider both precision and recall we used fscore .fscore is the harmonic mean of precision and recall which is computed as fscore precision recall precision recall .
figure shows the result.
the values on the lines at b shows the accuracy for the dataset containing individual projects and those at b full shows the accuracy for the full dataset as input.
as the data size increases precision decreases and recall increases.
the gain in recall is much higher than the loss in precision making their harmonic mean fscore increases significantly to for sourceforge and to for apache.
.
.
accuracy sensitivity analysis in this experiment we studied the impact of different components in our method on the accuracy.
in figure the baseline group base is the solution that extracts the preconditions by looking at only the guard conditions e.g.
the ones in ifstatement s on the path leading to the api calls.
this baseline does not consider the properties of the passed arguments normalization and merging nor deal with dynamic dispatch.
then we successively add other components one by one to the baseline solution to see changes in accuracy.
the second solution arg adds the preconditions that are obtained from the properties of the passed arguments e.g.
arg0 arg1 !
null .
the third one includes normalization of preconditions and the fourth one includes merging.
the last one covers all components in our approach by adding the subtyping information in which the preconditions of a method are also collected from the call sites of its overridden methods to deal with dynamic dispatch.
as more components are added recall increases significantly from to in sourceforge and from to in apache while precision is maintained.
among the components adding properties of arguments passed to apis improves the recall insourceforge and in apache.
the respective improvements from adding merging conditions are and .
adding subtyping contributes and .
normalization contributes for both.
.
rq2 usefulness we also studied how useful our automatically mined preconditions are for writing specifications via two experiments.
.
.
suggesting preconditions in specifications our first experiment looks at the mined preconditions for api methods that currently do not have a jml specification provided.
we run our tool to automatically mine preconditions for the apis and then manually transformed them into jml syntax.
we then sent these jml styled specifications to one of the original authors of jml.
if he agreed these specifications are correct it lends evidence that our approach is useful as a tool for suggesting preconditions when writing the initial specification for apis.
our results are summarized in table .
in total we prepared specifications for api methods from jdk classes which previously had no jml specifications.
our tool generated a total of mined preconditions column m .
for our approach one author transformed the automatically generated preconditions into jml specifications.
a second author who has extensive experience with jml s syntax including designing and implementing the jml research compiler jajml then performed a manual validation of the results and removed preconditions column rm which are incorrect for the corresponding apis.
five preconditions are deemed close column fix but require modifications of the comparison operator from strictly greater than to greater than or equal to .
the remaining were accepted exactly as the tool mined them.
after this step the specifications containing preconditions including the modified were sent to the jml team member.
table suggesting preconditions class method m rm fix accept stringbuffer delete int int y replace int int string y setlength int y subsequence int int y substring int int y linkedlist add int object y addall int collection y get int y listiterator int y remove int y set int object y as seen the jml team member agreed on out of methods s specifications such that the set of suggested preconditions is complete and precise yin column accept .
for only one method stringbuffer.replace y in column accept the preconditions are correct however two other ones are missing.
.
.
web based survey in the second experiment we created a web based survey and asked human subjects who have experience with using jdk library and or formal specification languages such as jml to evaluate the resulting preconditions.
we had a total of 15respondents.
participants were asked to rate their experience with java jml reading specifications and writing specifications.
two thirds self indicated1730 full data size projects full data size b projects precision recall fscore a sourceforge full data size projects full data size b projects precision recall fscore b apache figure mining accuracy as the size of dataset varies base arg norm merge subtype precision recall a sourceforge base arg norm merge subtype precision recall b apache figure mining accuracy as technical components are successively added having more than months experience writing specifications and many with experience in jml specifically.
participants were shown an example method e.g.
the substring method from section along with the set of proposed preconditions we mined for that method.
we then pre selected the correct answers based on the jml ground truth for each condition and explained why it was correct a good starting point or incorrect .
correct means that this precondition can be used as is in the specification.
good starting point means that it might need small modifications to be used in a specification such as changing a comparison operator from strict to non strict.
incorrect means that the condition is irrelevant in building the specification.
next users were shown methods one at a time and the mined preconditions for them.
they were asked to rate each individual precondition as mentioned.
we also asked them to give an overall more subjective rating for the entire method on whether our mined preconditions are useful.
after methods they were given an opportunity to write general feedback.
they also had an opportunity to continue rating more preconditions for other methods.
on average each participant graded preconditions.
when randomly choosing methods for a user we enforced that the first two were apis that existed in the ground truth and the last three were apis that did not.
using the responses from the first two we were able to grade the users on their expertise by calculating the answers that matched the ground truth out of the total number of ground truth answers.
for this study we only keep responses from users who scored on this grading.
in total there were 9users grading 75methods with 104preconditions.
the following table shows the correctness of the preconditions as rated by participants.
excluding the not sure responses theparticipants rated as correct.
what the results in section .
could not show however was the amount of almost correct preconditions which the participants rated as almost .
correct good starting point incorrect not sure overall participants found that of the mined preconditions are useful as the starting point for writing the specification.
the following table shows the responses for rating the tool s usefulness agree agree no opinion disagree disagree again excluding the no opinion responses the participants rated the tool as useful for of the methods shown!
.
.
a benchmark of precondition related bugs in this section we show an application of our mined preconditions in building a benchmark of bugs caused by missing precondition checking.
an example of this type of bug is that a developer does not check the condition beginindex endindex before callingstring.substring int int when the logic of the program does not ensure it.
this type of benchmark is very useful for bug detection tools that look for neglected condition checking such as chang et al.
s tool and alattin .
it was reported that neglected conditions are an important but difficult to find class of defects .
to build the benchmark we processed all revisions with changed java files for all java projects in sourceforge174dataset.
for a project p we first identified the fixing revisions by the popular method that uses the heuristic of searching in commit logs for the phrases indicating fixing activities.
for each fixing revisionri we used our prior origin analysis tool to compare it with the previous one ri .
we detected the mapped methods and api calls between two revisions.
for each pair of mapped api calls in a method we computed two sets of guard conditions.
we compared each set with the mined preconditions of the api to find the set of preconditions that are implied by a guard condition.
if there exists such a precondition in ribut not inri we add the api call sites and ri ri to our benchmark.
in total there are fixing revisions.
among them .
in931projects are detected as related to missing preconditions.
the total number of call sites related to those fixes is .
to check its quality we manually checked a sample of call sites in the benchmark and found that of them are related to preconditions.
we will manually check all and make our benchmark available.
we found that null pointer and index out of bounds exceptions are the two most common sub types in those bugs.
our result confirms this type of bug and calls for detection tools.
this shows the usefulness of our mined preconditions in building the benchmark.
our mined preconditions can also be used in such detection tools.
threats to validity.
the two chosen datasets might not be representative.
the criteria of revisions might not have filtered out all experimental and toy projects.
we conducted experiments only on jdk.
the ground truth was built by us.
thus human errors could occur.
the two chosen classes in the usefulness study might not be representative.
our human study suffers from selection bias as not all participants have the same level of expertise on formal specifications.
there is possible construct bias as we chose the apis in jdk.
we did not compare our tool to a related one in .
similar to ours their tool is also based on both mining and program analysis.
however their tool is for c code and re implementing it for java code is infeasible due to their algorithm s complexity as well as the differences between two languages.
moreover their approach operates on a single project while we rely on large number of projects.
thus the two approaches require inputs with different nature.
other mining based approaches do not work for preconditions while other static and dynamic analysis methods for specification inference do not have a mining component section .
.
related work the condition mining work that is closest to our approach is from ramanathan grama and jagannathan rgj .
similar to ours the rgj approach tightly integrates program analysis with data mining techniques .
they proposed a static inference mechanism to identify the preconditions that must hold when a method is called.
they first analyze the call sites of the method in its containing program and then use a path sensitive inter procedural static analysis to collect the predicates at each program point.
to compute preconditions rgj collects a predicate set along each distinct path to each call site.
the intersection of predicate sets is then constructed at the join points where distinct paths merge.
predicates computed within a procedure are memorized and used to compute preconditions that capture inter procedural control and data flow information.
rgj then runs frequent itemset mining on data flow predicate sets and sub sequence mining for control flow conditions to derive preconditions.
they reported a precision level of .
.
our approach has several key differences.
first it operates on a very large scale corpus of client programs of the libraries that contain the call sites of apis.
in contrast rgj is designed to perform its inter procedural analysis on only an individual client programcontaining the apis call sites.
thus rgj can be used to improve our analysis technique when running on each project.
second their mining algorithm works on the data flow predicate sets in an individual program while our mining technique operates on the comparable preconditions across an ultra large number of projects.
in contrast they find conditions using sophisticated data and controlflow analyses on a single program.
their mining algorithm does not consider the predicates across projects.
our work is also related to static approaches for mining specifications.
those static approaches rely more on data mining while using more light weight static analyses than our approach and rgj.
gruska et al.
introduce the idea of wisdom of the crowds similar to our approach on linux projects about 200mlocs .
however their technique mines only temporal properties in term of pairs of method calls.
they used million mined temporal properties to check the anomalies in a new project.
our prior work grouminer performs frequent subgraph mining to find api programming patterns.
jadet dynamine williams and hollingsworth codeweb mine pairs of calls as patterns.
mapo expresses api patterns in term of partial orders of api calls.
tikanga mines temporal specification in term of computation tree logic formulas.
shoham et al.
use interprocedural analysis to mine api specification in term of fsas.
other static approaches to mine api specifications and then leverage them to detect bugs .
findbugs looks for specified bug patterns.
tools suggest code examples related to specific apis and types .
all above static approaches do not recover apis preconditions .
there are several dynamic approaches in mining specifications .
daikon automatically detects invariants in a program via running test cases.
wei et al.
infer complex post conditions from simple programmerwritten contracts in the code.
weimer et al.
mine method pairs from exception control paths and identify temporal safety rules.
in brief our approach can complement well to dynamic approaches .
there are other approaches that require annotations on partial specifications on desired invariants and then verify program properties and detect violations .
our approach is automatic .
our work is also related to research to derive the behavior model of a program or software component for verification .
these approaches aim to recover the formal model for a program with pre post conditions of the states transitions.
in contrast our approach focuses at a more fine grained level of individual apis .
.
conclusions in this paper we propose a novel approach to mine the preconditions of api methods using a large code corpus.
our key idea is that the true api preconditions appear frequently in their usages from a large code corpus with large number of api usages while projectspecific conditions occur less frequently.
we mined the preconditions for jdk methods on almost million slocs on sourceforge and apache projects.
comparing to the human written preconditions in jml our approach achieves high accuracy with recall from and precision from for the top ranked results.
in our user study participants found of the mined preconditions as a good starting point for writing specifications.
.