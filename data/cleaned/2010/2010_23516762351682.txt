diversity maximization speedup for fault localization liang gong1 david lo2 lingxiao jiang2 and hongyu zhang1 1school of software tsinghua university beijing china tsinghua national laboratory for information science and technology tnlist 1gongliang10 mails.tsinghua.edu.cn hongyu tsinghua.edu.cn 2school of information systems singapore management university singapore 2davidlo smu.edu.sg lxjiang smu.edu.sg abstract fault localization is useful for reducing debugging effort.
however many fault localization techniques require nontrivial number of test cases with oracles which can determine whether a program behaves correctly for every test input.
test oracle creation is expensive because it can take much manual labeling effort.
given a number of test cases to be executed it is challenging to minimize the number of test cases requiring manual labeling and in the meantime achieve good fault localization accuracy.
to address this challenge this paper presents a novel test case selection strategy based on diversity maximization speedup dms .dms orders a set of unlabeled test cases in a way that maximizes the effectiveness of a fault localization technique.
developers are only expected to label a much smaller number of test cases along this ordering to achieve good fault localization results.
our experiments with more than bugs from the software artifact infrastructure repository show that dms can help existing fault localization techniques to achieve comparable accuracy with on average fewer labeled test cases than previously best test case prioritization techniques and that given a labeling budget i.e.
a fixed number of labeled test cases dms can help existing fault localization techniques reduce their debugging cost in terms of the amount of code needed to be inspected to locate faults .
we conduct hypothesis test and show that the saving of the debugging cost we achieve for the real cprograms are statistically significant.
categories and subject descriptors d. .
testing and debugging general terms algorithms experimentation reliability the work was done while the author was visiting singapore management university.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
ase september essen germany copyright acm ... .
.keywords test case prioritization fault localization .
introduction software testing and debugging activities are often laborintensive accounting for to of labor spent for a project .
establishing sufficient testing and debugging infrastructure can help reduce software errors that cost the us economy .
billion dollars .
of s gdp .
many automated testing and debugging techniques have been proposed to reduce the high cost in such activities.
spectrum based fault localization e.g.
is an automated debugging techniques that can narrow down the possible locations of software faults and help save developers debugging time.
many spectrum based fault localization techniques take a set of executions and labels as input compare between failed and passed executions and statistically locate faulty program entities.
such techniques require each execution to be labeled as a failure or a success which often needs human interpretation of an execution result and may not be easy to determine when a failure is not as obvious as a program crash or invalid output formats.
labeling all executions or test cases for a program can require much manual effort and is often tedious and thus the effectiveness of existing spectrum based fault localization techniques may be potentially hampered due to the unavailability of labeled test cases.
with test case generation techniques we may be less concerned with lacking test cases.
however we still face the same problem of lacking test oracles that can determine whether a program behaves correctly for an input.
note that many software failures do not have obvious symptoms such as crashes or violation of predefined specifications they may simply produce a wrong number or display a widget in an inappropriate place and they still need human to decide whether the results are good or not which could be a laborious and error prone activity.
recently artzi et al.
propose a directed test case generation approach for fault localization .
they however only handle two kinds of errors in web applications that automated test oracles can be constructed program crashes and invalid html documents.
in general programs constructing automated test oracles is much more complicated and still requires much manual effort.
the key research question for this paper is as follows how can we minimize the number of test cases requiring human labeling while achieving comparable fault localization effectiveness as when all test cases are labeled?permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
ase september essen germany copyright acm ... .
t1t2t3t4t5t6t7t8t9t10t11t12nefnepnnfnnp ochiai tarantula jaccard main s1 int let dig c s2 let dig s3 while c getchar s4 if a c z c s5 .
.
.
let s6 .
.
.
else if a c z c fault s7 .
.
.
let s8 .
.
.
else if c c s9 .
.
.
dig s10 .
.
.
printf d d n let dig s11 .
.
.
pass fail pfpfppppfpppstatementtest case suspiciousness metrics .
.
.
a fault localization with all test cases s1s2s3s4s5s6s7s8s9s10s11p f s1 s2 s3 s4 s5 s6 s7 s8 s9 s10 s11 s1 s2 s3 s4 s5 s6 s7 s8 s9 s10 s11 t2 11111111111f0.
.
.
.
.
.
.
.
.
.
.
s5 s6 s7 s8 s9 s10 s1 s2 s3 s4 s11 t8 11110000001p0.
.
.
.
.
.
.
.
.
.
.
s7 s8 s9 s10 s5 s6 s1 s2 s3 s4 s11 t6 11111100001p0.
.
.
.
.
.
.
.
.
.
.
s7 s8 s5 s6 s1 s2 s3 s4 s9 s10 s11 t4 11111111001f0.
.
.
.
.
.
.
.
.
.
.
s7 s5 s8 s9 s10 s1 s2 s3 s4 s11 s6 t9 11111010111f0.
.
.
.
.
.
.
.
.
.
.0875suspicious group the groups are ordered according to their suspiciousness selected test caseprogram spectra normalized ochiai score b evolution of suspiciousness scores with test cases selected by our approach figure running example in this paper we propose the concept of diversity maximization speedup dms and an associated test case prioritization strategy to minimize the human effort needed to label test cases while maintaining the effectiveness of existing spectrum based fault localization techniques.
the concept is based on our observation that when given sufficient test cases an effective fault localization technique would assign a unique suspiciousness score to most program elements e.g.
a function a statement a branch or a predicate and high scores to faulty elements and low scores to non faulty ones.
we thus design dms tospeedup the changing process of the suspiciousness scores generated by a fault localization technique by using as few test cases as possible .
.
running example figure a and b illustrate how our concept helps reduce the number of test cases for effective fault localization.
there are statements s1...s11in the program in figure a adapted from previous papers where s7is faulty.
suppose the program has test cases t1...t12.
a dot for a statement under a test case means the corresponding statement is executed or hit in the corresponding test case.
the collection of such dots or represented as sequences of 1and0as shown in figure b are called program spectra .
with the spectra for all of the test cases and their pass fail information fault localization techniques may calculate various suspiciousness scores for each of the statements and rank them differently.
in this case three well known techniques ochiai tarantula andjaccard all rank s7as the most suspicious statement the last three columns in the highlighted row for s7in figure a .
however the fault localization techniques can in fact achieve the same effectiveness i.e.
ranking s7as the top suspicious one with much fewer test cases when our concept is applied.
use ochiai as an example.
first we select an initial small number of test cases t2in the example .
after a programmer labels the execution result of t2 ochiaican already assign suspiciousness scores to each statement although the ranks are not accurate as in the last columns of the row for t2in figure b .
then our approach calculates the potential rank changes that may be caused if a new test case is used by ochiai and selects the next test case with the maximal change potential t8in our case for manual labeling.
with a label for t8 ochiai updates the suspiciousness scores for the statements as in the last columns of the row for t8 .
repeating such a process three more times test cases t6 t4andt9are added and ochiai can already rank s7as the most suspicious statement.
thus our approach helps ochiai to effectively locate the fault in this case with only five test cases instead of .
section and present more details about our approach.
.
contributions we have evaluated our approach on five real cprograms and seven siemens test programs from the software artifact infrastructure repository sir .
in total we analyze faults and demonstrate that our approach significantly outperforms existing test case selection methods for fault localization.
.
given a target fault localization accuracy our approach can significantly reduce the number of test cases needed to achieve it.
in particular we compare with several state of the art test case prioritization strategies including coverage based e.g.
stmttotal art fault exposing potential based and diagnostic prioritization and our approach achieves on average test case reduction rates from to .
.
given a maximum number of test cases that a programmer can manually label i.e.
given a fixed number of test cases to be used for fault localization dms can improve the accuracy of fault localization and thus helps reduce the amount of code programmers need to investigate to locate faults and reduce debugging31cost.
in comparison with other test case selection techniques we show with wilcoxon signed rank test at confidence level that the cost saving achieved bydms is statistically significant on real life programs.
.
paper outline the rest of this paper is organized as follows section describes fault localization and test case prioritization techniques that we use in our study.
section formally introduces the problem we address.
section presents our approach in detail.
section presents our empirical evaluation.
section describes more related works.
finally section concludes with future work.
.
preliminaries .
fault localization spectrum based fault localization aims to locate faults by analyzing program spectra of passed and failed executions.
a program spectra often consists of information about whether a program element e.g.
a function a statement or a predicate is hit in an execution.
program spectra between passed and failed executions are used to compute the suspiciousness score for every element.
all elements are then sorted in descending order according to their suspiciousness for developers to investigate.
empirical studies e.g.
show that such techniques can be effective in guiding developers to locate faults.
parnin et al.
conduct a user study and show that by using a fault localization tool developers can complete a task significantly faster than without the tool on simpler code.
however fault localization may be much less useful for inexperienced developers.
the key for a spectrum based fault localization technique is the formula used to calculate suspiciousness.
table lists the formulae of three well known techniques tarantula ochiai and jaccard .
given a program element s nef s is the number of failed executions that executes nnp s numerates passed executions that do nothits by the same token nnf s counts failed executions that do not hitsandnep s counts passed executions that executes.
table spectrum based fault localization name formula tarantulanef s nef s nnf s nef s nef s nnf s nep s nep s nnp s ochiainef s radicalbig nef s nnf s nef s nep s jaccardnef s nef s nnf s nep s example.
each column for tiin figure a is a spectrum.
the columns nef nep nnf andnnpcan thus be calculated from the spectra.
the suspiciousness scores of tarantula ochiai and jaccard for each statement are then calculated based on the formulae in table .
.
test case prioritization in rothermel et al.
define the problem of test case prioritization as follows definition .
test case prioritization .given t a set of test cases pt the set of permutationsoft and f a function mapping pt to real numbers the problem is to find a permutation p pt such that p prime pt.f p f p prime .
in this definition ptrepresents the set of all possible orderings of t fis an award function indicating the value for each ordering.
the higher the value the better it is.
for easier implementation award functions in the literature are often defined as a priority function mapping test cases to real numbers and then the optimal permutation is simply to sort the test cases in descending order according to their values.
the key for a test case prioritization technique to be effective is to design a priority function that assigns appropriate priority to the test cases under given situations.
the following subsections highlight some test case prioritization techniques that we compare with our approach.
.
.
coverage based prioritization stmt total is a test case prioritization strategy that assigns higher priorities to a test case that executes more statements in a program.
stmt addtl extends stmt total by selecting next test case that covers more statements that have not been covered by previously selected test cases.
adaptive random test prioritization art starts by randomly selecting a set of test cases that achieves maximal coverage and then sort the unlabeled test cases based on their jaccard distances to previous selected test cases.
among its several variants art minwas shown to be the best test case prioritization strategy .
however recent study shows that art may not be effective when the failure rate is low and the high distance calculations cost might overshadow the reduction on test execution times.
.
.
fault exposing potential based prioritization fep addtl aims to sort test cases so that the rate of failure detection of the prioritized test cases can be maximized.
to reduce the need for test oracles the rate of failure detection is approximated by the fault exposing potential fep of a test case which is in turn estimated based on program mutation analysis each program elementsjis mutated many times and the test case tiis executed on each mutant the fep oftiforsj fepij is calculated as the ratio of mutants of sjdetected by tiover the total number of mutants of sj then the fepofti fepi is the sum of the fep of tifor all elements summationtext jfepij .
.
.
diagnostic prioritization jiang et al.
investigate the effects of previous test case prioritization techniques on fault localization and find that coverage based techniques may be insufficient since the prioritized test cases may not be useful in supporting effective fault localization.
gonz alez sanchez et al.
use the concept of diagnostic distribution that represents the probability of a program element to be faulty which is then estimated by bayesian inference based on previous selected test cases and in their tool named sequoia sort test cases so that the information entropy of the diagnostic distribution can be minimized.
soon after gonz alezsanchez et al.
propose another strategy called ambiguity group reduction to sort test cases.
in their tool named raptor program elements having the same spectrum record are considered to be in the same ambiguity group ag and raptor aims to select next test case that would maximize the number of ambiguity groups while trying to minimize the deviation on the sizes of the ambiguity groups.
.
problem definition in this section we show a motivating example and formally introduce our approach diversity maximization speedup dms .dms employs trend analysis to give priorities to test cases that can quickly increase the diversity of suspiciousness scores generated by fault localization techniques for various program elements.
in the subsections we illustrate its intuition and formally define it as a variant of test case prioritization.
.
running example revisited we use the running example figure a to explain the intuitions for dms.
no.
of statements to be examined iterations s1 s2 s3 s4 s5 s6 s8 s10 others s9 s7 faulty figure motivating example with sufficient test cases an effective fault localization technique is more likely to assign high suspiciousness scores to faulty program elements while assigning low scores to non faulty elements and each element should be assigned a unique rank according to their suspiciousness scores to facilitate further investigation such as the scores shown in the last three columns in figure a .
with fewer test cases a fault localization technique may not be able to achieve an effective ranking.
figure shows the evolution trend of the ranks of the running example s program statements based on their ochiai scores as test cases are added one by one.
the test cases are added byraptor which is the existing best approach in the literature for selecting test cases for fault localization.
in this figure the horizontal axis represents the number of iterations to select test cases.
in each iteration one test case is picked from the unlabeled test case pool tu.
the vertical axis is the rank1of a statement sorted based on suspiciousness.
each line in the figure depicts the evolution of the suspiciousness rank for one specific statement.
for example s7 the faulty statement is ranked 11thin the first iteration and 6thin the second iteration.
this figure shows that the ranks of different statements may evolve in different ways as more test cases are added.
specifically some statements keep rising in general e.g.
s7 some others oscillate back and forth e.g.
s9 .
ideally we should only use test cases that could enable a fault localization technique to assign elements the scores close to the final score when all test cases are used.
comparing to the changes of s7 the oscillation of s9is less important as its final rank is the same as its initial rank.
thus when we add test cases we should look for test cases that could offer 1program elements with the same suspiciousness score are assigned the same lowrank since developers are expected to investigate all of the elements having the same score if they are ever going to investigate one.
for example if statements s1 s2 s3have the highest suspiciousness score then the ranks of the statements are all .more changing opportunities to promising elements like s7 with clear trend instead of s9so that the ranks for both s7ands9 may quickly approach their final position.
the following questions prompted us to define dms .
can we analyze the change trend of every program element and identify promising elements with high change potentials i.e.
elements whose ranks are likely to change much in a stable way ?
.
for program elements having high change potentials can we select appropriate test cases to speed up their rank changing process so that these elements can reach their final ranks faster i.e.
with fewer test cases ?
.
formal definition of dms definition .
diversity maximization speedup .
given t a set of test cases pt the set of permutations of t and k a positive integer we use pkto represent a permutation p pttruncated at length k andptkto represent all such truncated permutations i.e.
ptk pk p pt .
then with f a function mapping ptkto real numbers the problem of dms is to find a permutation p ptsuch that pk i ptk.
f pk f pk i for the given k. in definition .
fis an award function indicating the value of an ordering in ptk which in our case would be the effectiveness of a fault localization technique based on k labeled test cases.
the number kcan be used as a labeling budget indicating the number of test cases developers are willing to label for fault localization.
thus the goal for dms is to quickly maximize the effectiveness of fault localization techniques with at most klabeled test cases.
.
approach details in this section we answer the two questions raised in the previous section which conceptualize dms.
.
identify high change potential elements in order to evaluate the change potential of program elements we first represent program element s rank changes as time series data points.
we then fit the points to a linear model using regression analysis.
the regression coefficient of the model and the error i.e.
discrepancy between the model and the real points are used as proxy to identify program elements with high change potentials.
more details are described as follows.
representative time series construction.
we capture changes in the ranks of a program element as a series of trend units .
when the rank of the program element decreases its current trend unit is .
.
when the rank of the program element increases its current trend unit is .
.
if the element s rank stays the same its current trend unit is .
for example the ranks of statement s8in different iterations and its corresponding trend units are listed in table .
this series of trend units is further converted to a series of points xi yi wherexirepresents the iteration33number and yirepresents cumulated changes in program ranks at iteration i. we sety0as .
when the trend in iterationiis yi yi .
if the i th trend is yi yi otherwise if the trend does not change thenyi yi .
we refer to this series of points as the evolution trend of the corresponding program element.
table evolution trend of s8.
iteration xi ... rank ... trend t ... yi ... linear model construction.
then we use linear regression analysis to model the trend of each program element.
each trend is modeled as a linear equation yi 1 xi 0 epsilon1i change potential computation.
here we define the changepotential of a program element with trend tas wt vextendsingle vextendsingle vextendsingle 1 vextendsingle vextendsingle vextendsingle 1 1is estimated by least squares and 1is the error of estimating 1 .
in this metric the numerator is the absolute value of the trend slope and the denominator considers the fitness of the regression model which represents the deviation of the actual value from the regression model.
using this metric our method isolates trends that evolve in a monotonous and stable way.
table shows a few example trends and their change potentials according to equation .
table trend examples and their potentials t 1 1wt .
.
.
.
.
speed up the rank change process after evaluating the program elements according to their change potentials dms will try to speed up the evolution trend of the program elements based on the changepotential wt .
first program elements with the same suspiciousness scores are grouped together they are termed assuspicious group in this paper.
these suspicious groups are then assigned change potential scores based on the change potentials of their constituent program elements.
when new test cases are added based on the actual program elements that get executed some groups can be broken into two.
when this happens the diversity of the suspiciousness scores increases in most cases.
the goal of dms is to select a new test case that breaks a group into two sub groups where the overall change potentials are maximized.
we calculate the potential of a group gby summing up the potential of all program elements dthat belongs to g. wg summationdisplay d gwtd wheretdis the change potential of the program element dbased on the labeled execution trace profiles.
the overall change potential score of all suspicious groups g are calculated as follows hg summationdisplay gi gw2 gi to evaluate an unlabeled trace t dms calculates the difference between the overall change potential score of the current groups g hg and the overall change potential score of all groups when tis added to the pool of labeled test cases g t and chooses the test case that can maximize the difference as the next one for labeling.
arg max t tu braceleftbig hg h g t bracerightbig the new groups g t and their change potential h g t can be estimated based on t s spectrum i.e.
the set of program elements hit by t even when the pass fail label fortis unknown.
given an existing suspicious group if a newly added test case tonly covers a subset of the group elements this group may be broken into two one contains the elements hit by t and the other contains the elements uncovered by t. then each subgroup inherits a portion of the original group s change potential proportional to its size.
for example suppose a group ginhgcontains elements whose potentials are .
and .
respectively and a new test casetbreaksgintog1andg2 each of which contains element then the change potentials wg1andwg2are both .
.
.
.
note that dms does not intentionally increase suspiciousness scores of promising statements which could lead to confirmation bias .
more specifically dms might make an initially promising statement become less suspicious if the statement is covered in the next selected trace and the trace is labeled pass or it is not covered in the next selected trace and the trace is labeled fail.
.
overall approach before prioritization all test cases will be executed on instrumented program versions and the corresponding traces would be collected.
our approach pseudocode in figure takes in a set of unlabeled traces tuand the labeling budget k i.e.
the maximum number of traces to be manually labeled and outputs kselected traces for manual analysis.
one failed trace t0in line is also used as an input because a developer usually starts debugging only when at least one test fails and fault localization techniques rarely produce meaningful results if all spectra consists of only passed executions.
to collect indicative trends for analyzing and speedup at lines we first collect wtraces by one generic prioritization techniquepand record evolution trend tdfor each program elementd.
this step is desirable since it helps bootstrap the trend analysis in our solution.
at lines we perform the second stage which speeds up the change process based on existing trends.
note that after selecting each test case t in this stage we will update the trend for all elements.
ft represents a fault localization technique e.g.
ochiai built based on the set of test cases t.ft d returns the suspicious score for the program element d. in the pseudocode manual label t asks a user to check the correctness of the outcome from the test case t. proce 34table evolution of suspiciousness scores for the running example in table a using raptor .
s1s2s3s4s5s6s7s8s9s10s11p f s1 s2 s3 s4 s5 s6 s7 s8 s9 s10 s11 s1 s2 s3 s4 s5 s6 s7 s8 s9 s10 s11 t2 11111111111f0.
.
.
.
.
.
.
.
.
.
.
s5 s6 s7 s8 s9 s10 s1 s2 s3 s4 s11 t8 11110000001p0.
.
.
.
.
.
.
.
.
.
.
s7 s8 s9 s10 s6 s5 s1 s2 s3 s4 s11 t6 11111100001p0.
.
.
.
.
.
.
.
.
.
.
s7 s8 s5 s6 s1 s2 s3 s4 s11 s9 s10 t4 11111111001f0.
.
.
.
.
.
.
.
.
.
.
s7 s8 s6 s5 s10 s1 s2 s3 s4 s11 s9 t7 11111011101p0.
.
.
.
.
.
.
.
.
.
.
s7 s10 s5 s1 s2 s3 s4 s11 s6 s8 s9 t9 11111010111f0.
.
.
.
.
.
.
.
.
.
.0885ambiguity group the groups are ordered according to their suspiciousness selected test caseprogram spectra normalized ochiai score procedure diversitymaximizationspeedup input k maximum number of traces to be selected w switching threshold tu unlabeled trace set where tu k t0 initial failed trace output kselected test cases prioritized method ttmp t0 fail bootstraping with prioritization technique p while ttmp kand ttmp wdo selecttbyp c manual label t ttmp ttmp t c tu tu t d d calculate suspicious score fttmp d d d update trendtdbased onfttmp d end while ts ttmp speedup while ts kdo d d calculatewtdby equation selecttby equation c manual label t ttmp ttmp t c tu tu t d d calculate suspicious score fttmp d d d updatetdbased onfttmp d ts ts ttmp ifdiv ttmp cease growing then ttmp t0 fail d d cleartd end if end while returnts figure diversity maximization speedup dure div t counts the number of unique suspicious scores diversity generated by ft which is defined as follows div t vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle uniondisplay d d ft d vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle the diversity of small programs may reach the maximum after selecting a small number of test cases.
to avoid random selection after that happens the pseudocode at lines resets the set ttmpbased on which the suspiciousness scores of all program elements are calculated.
with this step dms can continually choose test cases from tuthat maximally diversify suspicious scores calculated based on ttmp.
repeating the diversity selection process also helps to confirm the previously selected test cases and make the final result more robust.
example we describe step by step how dms minimizes the number of test cases needed by ochiai to locate the fault in the running example in figure a and figure b .
since the example code snippet is quite small there is noneed to use a large number of initial test cases to bootstrap our trend analysis.
we set w and only use one test case in addition to t0 for bootstrapping.
in this example and our evaluation in section we use raptor one of the previously best techniques in the bootstrapping process for better comparison.
initially users execute the program and expose a failure t2in this example in which all statements are covered.
thus all statements get equal non zero suspiciousness and constitute a suspicious group g. all non zero suspicious groups compose a group set g g .raptor would then chooset8and ask developer to label pass orfail .
after the bootstrapping stage ochiai updates the suspiciousness score for each statement based on the selected traces and the existing suspicious group set are broken into s1 s2 s3 s4 s11 and s5 s6 s7 s8 s9 s10 they are called g1 andg2respectively.
at this time the trend for the statements ing1is because the ranks of these statements change from to while the trend for the statements in g2is because their ranks are still .
the corresponding time series of the statements in g2are y0 andy1 .
applying equation we obtain the change potential of the trend of the program elements in g2as .
we now calculate hgfor the current suspicious group set g g1 g2 according to equation hg w2 g1 w2 g2 summationtext d g10 summationtext d g21 .
now there are candidate traces ti i i to be evaluated.
we will use each candidate trace ti to break ties in g g ti .
then we calculate the score that evaluates the breaking effect h g ti .
for example when evaluating t6 t6coverss1 s2 s3 s4 s5 s6 ands11 thus breaks suspicious g2into s5 s6 and s7 s8 s9 s10 let us call them g21andg22respectively.
now the score wg21 wg wg22 .
so if choosing t6 the score for gish g t6 w2 g21 w2 g22 .
and the reduction ishg h g t6 .
in the same way we evaluate all candidate traces and find that the reduction of t6is maximal so we select t6 as the next trace and ask developer to manually label t6.
the developer then labels it as pass .
after adding newly labeled trace t6into the selected trace set ts we recalculate the suspicious score of all program elements according to the current selected trace set.
after calculation the normalized suspicious score of the elements in s5 s6 reduced from .
to .
and their ranks remains the same.
the suspicious scores of the elements in s7 s8 s9 s10 increase from .
to .
and thus their ranks rises from to .
after that the trends of program elements are updated.
for example the trend of elements in s1 s2 s3 s4 s13 becomes the trend of the statements in s5 s6 becomes and those in s7 s8 s9 s10 corresponds to .
note that right now s7 s8 s9 s10 gets the highest change 35potential score and thus can get more chances to be broken up.
as shown in table b after three iterations dms selects t8 t6 t4 .
in the next iteration dms choosest9 and breaks s7 s8 and s5 s6 which have greater changepotentials and consequently ranks s7the highest.
overall dms only requires user to manually label four additional traces t8 t6 t4 t9 .
as a comparison raptor always chooses the test case that maximally reduces the overall sizes of groups of statements that have the spectrum records i.e.
ambiguity group reduction c.f.
section .
.
.
as shown in table raptor effectively selects the same test cases as dms in the first four iterations however it chooses t7in the next iteration to break s1 s2 s3 s4 s9 s10 s11 and s5 s6 and it takes one more iteration to rank s7the highest.
it thus requires users to label five additional test cases besides t2 t8 t6 t4 t7 t9 .
.
empirical ev aluation in this section we present empirical evaluation that analyzes the impact of dms on manual effort needed for test case labeling and compares our approach with multiple previous test case prioritization methods.
section .
gives details about experimental setup.
in section .
we introduce the subject programs in our study.
section .
shows the results followed by section .
discussing the threats to validity.
.
experimental setup in our experiment every test case prioritization technique starts from an arbitrary labeled failed trace because developers start debugging only when test cases fail.
we compare the effectiveness of different prioritization methods based on the diagnostic cost when the same number of test cases are selected.
the diagnostic cost is defined as follows cost j fts dj fts d d wheredconsists of all program elements appearing in the program.
we calculate the average cost as the percentage of elements that developers have to examine until locating the root cause d of failure.
since multiple program elements can be assigned with the same suspicious score the numerator is considered as the number of program elements djthat have bigger or the same suspicious score to d .
in this paper we use raptor as the bootstrapping technique pin figure .
during the bootstrapping process wis set to to facilitate trend analysis.
following for each faulty version we repeat each prioritization technique times to obtain its average cost.
for each time a randomly chosen failed trace is used as the starting point to alleviate the sensitivity of the technique to the choice of starting traces.
on the other hand to fairly compare our approach with other prioritization methods the same randomly chosen failed traces are used as the starting traces for all methods.
.
subject programs we use five real cprograms and seven siemens test programs from the software artifact infrastructure repository sir .
we refer to the five real programs sed flex grep gzip and space asunix programs.
table shows the descriptive statistics of each subject includingthe number of faults available test cases and code size.
following we exclude faults not directly observable by the profiling tool2 e.g.
some faults lead to a crash before gcov dumps profiling information and some faults do not cause any test case to fail and in total we study faults.
table subject programs program description loc tests faults tcas aircraft control schedule2 priority scheduler schedule priority scheduler replace pattern matcher totinfo info measure print tokens2 lexical analyzer print tokens lexical analyzer space adl compiler flex lexical parser sed text processor grep text processor gzip data compressor .
experimental results in this subsection we conduct several controlled experiments to show the effectiveness of dms.
.
.
effectiveness on reducing the number of test cases needed for a target cost we compare dms with previous test case prioritization techniques in terms of labeling effort when given an expected fault localization accuracy.
if labeling all test cases and performing fault localization on all program spectra results in an average diagnostic cost c we call it the base line cost.
then we define x base line effectiveness cx as follows cx x c table shows how many labels are needed on average to achieve base line effectiveness i.e.
within accuracy lost for each approach.
e.g.
raptor requires labels on average for each faulty version from the unix programs while dms only needs .
overall dms requires the minimal amount of labeling effort by achieving .
labeling reduction on unix programs and reduction on siemens programs in comparison with the existing best approach raptor .
table labeling effort on subject programs subject rap seq stmt stmt fep artprograms dms tor uoia addtl total addtl min siemens unix .
.
effectiveness on reducing cost for a given number of labeled test cases we select test cases which we believe are not too many to manually label.
we also find that in our experiments the average debugging cost of using dms will not reduce noticeably even if more labeled test cases are added further see figure .
during the bootstrapping process the first test cases are picked by raptor .
we use different prioritization techniques and apply ochiai to evaluate program elements the selected program spectra.
a prioritization technique that obtains a lower cost is better.
debugging cost no.
of test cases selected figure average cost of dms when selecting different numbers of test cases.
following and the cost metric equation we compare the effectiveness of two prioritization methods pa andpbby using one of the methods for example pb as reference measure.
when selecting equal number of traces k the cost difference cost pb cost pa is considered as the improvement of paoverpb.
a positive value means that paperforms better than pb since lower cost is better .
the difference corresponds to the magnitude of improvement.
for example if the cost of test cases from pa is and the cost of pbis then the improvement ofpaoverpbis which means that developers would examine fewer statements if pais deployed.
summary table and summarize the comparison between our method and the existing prioritizing techniques the results show that our method outperforms all of them.
table comparison of prioritization methods.
test pri.
tech.
positive negative neutral dms vsraptor .
.
.
dms vssequoia .
.
.
dms vsstmt addtl .
.
.
dms vsstmt total .
.
.
dms vsfep addtl .
.
.
dms vsart min .
.
.
as illustrated in table dms performs better than raptor on .
of the faulty versions worse on .
of the faulty versions and shows no improvement on .
of the faulty versions.
the first row of table characterizes the degree of positive improvement of dms overraptor .
as the table indicates half of the .
faulty versions with positive improvement values have improvements between .
and .
and the other half have improvements between .
and .
.
the average positive improvement of dms overraptor is .
.
we conduct paired wilcoxon signed rank test to confirm the difference in performance between dms and six existing prioritization techniques.
the statistical test result rejects the null hypothesis and suggests that dms is statistically significantly better than the existing best approach on unix programs at confidence interval.
detailed comparison table shows that raptor fepaddtl andart min achieve base line effectiveness with less than test cases on subject programs.
due totable distribution of positive improvements.
test pri.
tech.
max mean median min dms vsraptor .
.
.
.
dms vssequoia .
.
.
.
dms vsstmt addtl .
.
.
.
dms vsstmt total .
.
.
.
dms vsfep addtl .
.
.
.
dms vsart min .
.
.
.
limited space we only show the comparison between dms and these methods in detail.
figure and show the comparison between different prioritization techniques based on fault localization cost.
the horizontal axes represent the number of versions that show differences in the cost of fault localization.
the vertical axes represent the percentage difference in costs.
ifdms is better than the reference method the area above zero level line will be larger.
dmsvs f ep addtl previous studies show that fep addtl is the most promising prioritizing method for fault detection.
without test oracles fep can be estimated by false negative rate fnr 3which is also used in our study.
improvement no.
of versions figure improvement of d msover f ep addtl .
figure presents the comparison between dms andfepaddtl over all faulty versions.
fep addtl is used as the reference prioritization technique.
the baseline represents the fault localization cost on program spectra prioritized byfep addtl .
each program version is a bar in this graph and we remove versions from the graph that have no cost differences due to the limited space.
in the figure the vertical axis represents the magnitude of improvement of dms overfep addtl .
if the bar of a faulty version is above the horizontal axis that means on this version dms performs better than fep addtl positive improvement and the bars below the horizontal axis represent faulty versions for which dms performs worse than fep addtl .
the comparison shows that dms is better than fepaddtl .
out of versions that show differences in costs our prioritization method performs better than fep addtl on versions but performs worse than the fep addtl on 3fnr is the program passing rate when program element is the real fault and executed in test case.
usually when fnr is high the fault is difficult to be detected by spectrum based fault localization techniques.
versions.
the positive improvement ranges from .
to .
with an average of .
.
improvement no.
of versions improvement no.
of versions improvement no.
of versions improvement no.
of versions improvement no.
of versions figure improvement of d msover a rt min.
dmsvs a rt minin this study we compare the effectiveness of dms toadaptive random test prioritization art .
there are various strategies for art in this experiment we only compare with the best one artmin .
figure shows the results of the study in which art min is used as the baseline method.
the comparison shows that dms is better than art min .
out of versions that show differences in costs our prioritization method performs better than art min on versions but performs worse than the art min on versions.
dmsvs r aptor figure shows the comparison between dms andraptor onunix programs.
here we use raptor as the reference metric.
the comparison shows that dms is better than raptor .
on unix programs dms outperforms raptor on versions by at least cost and only versions worse than raptor over cost.
.
.
.
.
.
.
.
2e .
.
.
.74e .
.
.
.
.
.
.
.7e .
.
.
.3e .
.
.
.
.
.8e .
.12e improvement no.
of versions figure improvement of d msover r aptor on unixprograms.
there is also improvement on siemens programs .
versions show differences and the average debugging cost improvement is .
which is not so significant as comparison on unix programs.
this is probably due to the small software size.
on siemens programs the existing best approach can reach of the base line effectiveness by only selecting less than test cases on average see table .
by selecting such few test cases raptor already obtains the maximal ambiguity group reduction due to very limited different coverage profiles.
for example all test cases of tcas only have less than ambiguity groups in all faultyversions.
in this case the speedup by our method is trivial.
in real scenario programs to be diagnosed would be more similar to unix programs.
.
threats to validity the threats to our studies include the issue of how representative the subjects of our studies are.
since the siemens programs are small and larger programs may be subject to different testing and debugging traits.
to strengthen the external validity we include unix programs which are real life programs.
these subjects have been adopted for evaluation in many works .
another possible threat is that although our method outperforms existing method in .
to .
program versions and gets equivalent cost in around versions there are still a certain percent of versions that our method does not perform very well.
but as we can see in the studies most of the negative improvements of those versions are relatively small or even trivial comparing to the positive improvements.
we also conduct statistical test to further confirm the superiority of dms.
.
related work in this section we describe related work on fault localization defect prediction test case prioritization diagnostic prioritization and automated oracle construction.
the survey here is by no means a complete list.
fault localization over the past decade many automatic fault localization and debugging methods have been proposed.
the ways of calculating suspiciousness for program elements are various including state of arts e.g.
tarantula and ochiai .
renieris and reiss propose a nearest neighbor fault localization tool called whither that compares the failed execution to the correct execution and reports the most suspicious locations in the program.
zeller applies delta debugging to search for the minimum state differences between a failed execution and a successful execution that may cause the failure .
liblit et al.
consider predicates whose true evaluation correlates with failures are more likely to be the root cause.
test case prioritization test case prioritization techniques are initially proposed for early fault detection in regression testing.
rothermel et al.
show the coveragebased and fault exposing potential based approaches can improve the rate of fault detection of test suites.
elbaum et al.
further investigate version specific prioritization on different profile granularities.
in li et al.
show that additional greedy algorithm is among the best approaches for regression test case prioritization.
baudry et al.
propose dynamic basic block dbb for test suite reduction.
their method focuses on the number of dbbs.
gonz alezsanchez et al.
further consider group size.
oracle construction although in recent years many studies aim to automatically generate test oracles they are often heavy weight based on certain assumption and thus applicable to specific scenarios.
eclat can generate assertions based on a learning model but they assume correct executions.
xie proposes a method called orstra for oracle checking.
bowring et al.
propose argo which selects test cases inducing unknown behaviors to actively construct test oracles for improving test quality.
the approach is more suitable for regression testing.38our approach complements these studies by reducing the effort needed for the purpose of fault localization.
.
conclusion and future work this paper proposes a new technique aiming to minimize the amount of effort in manual oracle construction while still permitting effective fault localization.
in comparison with existing prioritization techniques on cprograms we have shown that our method only requires on average a small number of test cases to accomplish the target average cost within accuracy lost and outperform existing methods in terms of reducing debugging cost for the subject programs.
we have also shown that the differences on reallife programs are statistically significant.
in future we will evaluate the proposed approach on more subject programs.
we will also explore the possibility of adopting more sophisticated trend analysis methods.
.
acknowledgement this work is partially supported by nsfc grant and tsinghua university project 2010thz0.
we thank researchers at university of nebraska lincoln georgia tech and siemens corporate research for the software artifact infrastructure repository.
we would also like to thank the anonymous reviewers for providing us with constructive comments and suggestions.
.