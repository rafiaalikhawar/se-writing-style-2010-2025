automatic input rectification fan long vijay ganesh michael carbin stelios sidiroglou and martin rinard mit csail fanl vganesh mcarbin stelios rinard csail.mit.edu abstract we present a novel technique automatic input rectification and a prototype implementation soap.
soap learns a set of constraints characterizing typical inputs that an application is highly likely to process correctly.
when given anatypical input that does not satisfy these constraints soap automatically rectifies the input i.e.
changes the input so that it satisfies the learned constraints .
the goal is to automatically convert potentially dangerous inputs into typical inputs that the program is highly likely to process correctly.
our experimental results show that for a set of benchmark applications google picasa imagemagick vlc swfdec and dillo this approach effectively converts malicious inputs which successfully exploit vulnerabilities in the application into benign inputs that the application processes correctly.
moreover a manual code analysis shows that if an input does satisfy the learned constraints it is incapable of exploiting these vulnerabilities.
we also present the results of a user study designed to evaluate the subjective perceptual quality of outputs from benign but atypical inputs that have been automatically rectified by soap to conform to the learned constraints.
specifically we obtained benign inputs that violate learned constraints used our input rectifier to obtain rectified inputs then paid amazon mechanical turk users to provide their subjective qualitative perception of the difference between the outputs from the original and rectified inputs.
the results indicate that rectification can often preserve much and in many cases all of the desirable data in the original input.
i. i ntroduction errors and security vulnerabilities in software often occur in infrequently executed program paths triggered by atypical inputs.
a standard way to ameliorate this problem is to use an anomaly detector that filters out such atypical inputs.
the goal is to ensure that the program is only presented with typical inputs that it is highly likely to process without errors.
a drawback of this technique is that it can filter out desirable benign but atypical inputs along with the malicious atypical inputs thereby denying the user access to desirable inputs.
a. input rectification we propose a new technique automatic input rectification .
instead of rejecting atypical inputs the input rectifier modifies the input so that it is typical then presents the input to the application which then processes the input.
we have three goals a present typical inputs which the application is highly likely to process correctly to the application unchanged b render any malicious inputs harmless by eliminating any atypical input features that may trigger errors or securityvulnerabilities while c preserving most if not all of the desirable behavior for atypical benign inputs.
a key empirical observation that motivates our technique is the following production software is usually tested on a large number of inputs.
standard testing processes ensure that the software performs acceptably on such inputs.
we refer to such inputs astypical inputs and the space of such typical inputs as the comfort zone of the application.
on the other hand inputs designed to exploit security vulnerabilities i.e.
malicious inputs often lie outside the comfort zone.
if the rectifier is able to automatically detect inputs that lie outside the comfort zone and map these inputs to corresponding meaningfully close inputs within the comfort zone then it is possible to a prevent attackers from exploiting the vulnerability in the software while at the same time b preserving desirable data in atypical inputs either benign or malicious for the user.
we present soap sanitization of anomalous inputs an automatic input rectification system designed to prevent overflow vulnerabilities .
soap first learns a set of constraints over typical inputs that characterize a comfort zone for the application that processes those inputs.
it then takes the constraints and automatically generates a rectifier that when provided with an input automatically produces another input that satisfies the constraints.
inputs that already satisfy the constraints are passed through unchanged inputs that do not satisfy the constraints are modified so that they do.
b. potential advantages of automatic input rectification input rectification has several potential advantages over simply rejecting malicious or atypical inputs that lie outside the comfort zone desirable data in atypical benign inputs anomaly detectors filter out atypical inputs even if they are benign.
the result is that the user is completely denied access to data in atypical inputs.
rectification on the other hand passes the rectified input to the application for presentation to the user.
rectification may therefore deliver much or even all of the desirable data present in the original atypical input to the user.
desirable data in malicious inputs even a malicious input may contain data that is desirable to the user.
common examples include web pages with embedded malicious content.
rectification may eliminate the exploits while preserving most desirable input from the978 .
c ieee icse zurich switzerland a the original image b the rectified image figure .
a jpeg image truncated by the rectification.
original input.
in this case the rectifier enables the user to safely access the desirable data in the malicious input.
error nullification even if they are not malicious atypical inputs may expose errors that prevent the application from processing them successfully.
in this case rectification may nullify the errors so that the application can deliver most if not all of the desirable data in the atypical input to the user.
c. the input rectification technique soap operates on the parse tree of an input which divides the input into a collection of potentially nested fields .
the hierarchical structure of the parse tree reflects nesting relationships between input fields.
each field may contain an integer value a string or unparsed raw data bytes.
soap infers and enforces upper bound constraints on the values of integer fields sign constraints that capture whether or not an integer field must be non negative upper bound constraints on the lengths of string or raw data byte fields and correlated constraints that capture relationships between the values of integer fields and the lengths of potentially nested string or raw data fields.
the taint analysis engine of soap first identifies input fields that are related to critical operations during the execution of the application i.e.
memory allocations and memory writes .
the learning engine of soap then automatically infers constraints on these fields based on a set of training inputs.
when presented with an atypical input that violates these constraints the soap rectifier automatically modifies input fields iteratively until all constraints are satisfied.
d. nested fields in input files one of the key challenges in input rectification is the need to deal with nested fields.
in general input formats may contain arbitrarily nested fields which make inferring correlated constraints hard.
our algorithm must consider relationships between multiple fields at different levels in the tree.
nested input fields also complicate the rectification.
changing one field may cause the file to violate constraints associated with enclosing fields.
to produce a consistent rectified input the rectifier must therefore apply a cascading sequence of modifications to correlated fields as its constraint enforcement actions propagate up or down the tree of nested fields.e.
key questions we identify several key questions that are critical to the success of the input rectification technique learning is it possible to automatically learn an effective set of constraints from a set of typical benign inputs?
rectification percentage given a set of learned constraints what percentage of previously unseen benign inputs fail to satisfy the constraints and will therefore be modified by the rectifier?
rectification quality what is the overall quality of the outputs that the application produces when given benign inputs that soap has modified to enforce the constraints?
security does soap effectively protect the application against inputs that exploit errors and vulnerabilities?
we investigate these questions by applying soap to rectify inputs for five large software applications.
the input formats of these applications include three image types png tiff jpeg wave sound wa v and shockwave flash video swf .
we evaluate the effectiveness of our rectifier by performing the following experiments benign input acquisition for each application we acquire a set of inputs from the internet.
we run each application on each input in its set and filter out any inputs that cause the application to crash.
the resulting set of inputs is the benign inputs .
because all of our applications are able to process all of the inputs without errors the set of benign inputs is the same as the original set.
training and test inputs we next randomly divide the collected benign inputs into two sets the training set and thetest set .
potentially malicious inputs we search the cve security database and previous security papers to obtain malicious inputs designed to trigger errors and or exploit vulnerabilities in the applications.
learning we use the training set to automatically learn the set of constraints that characterize the comfort zone.
atypical benign inputs for each application we next compute the percentage of the benign inputs that violate at least one of the learned constraints.
we call such inputs atypical benign inputs .
in our experiments the percentage of atypical benign inputs is less than .
.
a the original image b the rectified image figure .
a jpeg image twisted by the rectification a the original image b the rectified image figure .
a tiff image whose color is changed by the rectification.
quality of rectified atypical inputs we evaluate the quality of the rectified atypical inputs by paying people on amazon mechanical turk to evaluate their perception of the difference between the output that the application produces when given the original input and the output that the application produces when given the rectified version of the original input.
specifically we paid people to rank the difference on a scale from to with indicating completely different outputs and indicating no perceived difference.
the mean scores for over of the atypical inputs are greater than .
indicating that mechanical turk workers perceive the outputs for the original and rectified inputs to be very close.
security evaluation we verified that the rectified versions of malicious inputs for each of these applications were processed correctly by the application.
manual code analysis for each of the malicious inputs we identified the root cause of the vulnerability that the input exploited.
we examined the learned constraints and verified that if an input satisfies the constraints then it will not be able to exploit the vulnerabilities.
f .
understanding rectification effects we examined the original and rectified images or videos for all test inputs that soap rectified.
these files are available at rectification for the majority of rectified inputs out of inputs the original and rectified images or videos appear identical.
the mean mechanical turk scores for such images or videos was between .
and .
.
we attribute this to the fact that the rectifier often modifies fields such as the name of the author of the file that are not relevant to the core functionality of the application and therefore do not visibly change the image or video presented to the user.
the application must neverthelessparse and process these fields to obtain the desirable data in the input file.
furthermore since these fields are often viewed as tangential to the primary purpose of the application the code that handles them may be less extensively tested and therefore more likely to contain errors.
figures and present examples of images that are visibly changed by rectification.
for some of the rectified images of inputs the rectifier truncates part of the image leaving a strip along the bottom of the picture see figure .
for the remaining inputs of the rectifier changes fields that control various aspects of core application functionality for example the alignment between pixels and the image size see figure the image color see figure or interactive aspects of videos.
the mean mechanical turk scores for such images or videos vary depending on the severity of the effect.
in all cases the application was able to process the rectified inputs without error to present the remaining data to the user.
g. contributions we make the following contributions basic concept we propose a novel technique for dealing with atypical or malicious inputs automatic input rectification and a prototype implementation soap which demonstrates the effectiveness of the technique.
constraint inference we show how to use dynamic taint analysis and a constraint inference algorithm to automatically infer safety constraints.
this inference algorithm operates correctly to infer correlated constraints for hierarchically structured input files with nested fields.
rectification algorithm we present an input rectification algorithm that systematically enforces safety constraints on inputs while preserving as much of the benign part of the input as possible.
because it is capable of enforcing correlated constraints associated with nested input fields this algorithm is capable of rectifying hierarchically structured input files.
experimental methodology we present a new experimental methodology for evaluating the significance of changes to program inputs and or outputs.
specifically we use amazon mechanical turk to evaluate the subjective perceptual quality of the outputs for rectified inputs.
we present effective mechanisms to ensure the quality of the collected responses which is a primary challenge of utilizing such crowdsourcing workforce.
experimental results our results indicate that for our set of benchmark applications and inputs mechanical82turk workers perceive rectified images and videos to be in most cases close or even identical to the original images and videos section v .
these results are consistent with our own quantitative section iv and qualitative section v evaluation of the differences between the original and rectified images and videos.
explanation we explain sections i f and v why rectification often preserves much or even all of the desirable data in rectified files.
we organize the rest of the paper as follows.
section ii presents an example that illustrates how soap works.
we describe the technical design of soap in section iii.
we present a quantitative evaluation of soap in section iv and a subjective human evaluation of soap in section v. section vi discusses related work.
we conclude in section vii.
ii.
m otivating example figure presents source code from dillo .
a lightweight open source web browser.
dillo uses libpng to process png files.
when dillo starts to load a png file it calls the libpng callback function png datainfo callback shown in figure .
the function contains an integer overflow vulnerability at line where the multiplication calculates the size of the image buffer allocated for future callbacks.
because png rowbytes is proportional to the image width arithmetic integer overflow will occur when opening a png image with maliciously large width and height values.
this error causes dillo to allocate a significantly smaller buffer than required.
dillo eventually writes beyond the end of the buffer.
dillo developers are well aware of the potential for overflow errors.
in fact the code contains a check of the image size at lines to block large images.
unfortunately the bounds check has a similar integer overflow problem.
specific large width and height values can also cause an overflow at line and thus bypass the check.
soap can nullify this error without prior knowledge of the vulnerability itself.
to use soap an application developer or system administrator first provides soap with a set of typical benign inputs to the application.
to nullify the above dillo error soap performs following steps understand input format soap provides a declarative input specification interface that enables users to specify the input format.
soap then uses this specification to automatically generate a parser which transforms each png input into a collection of potentially nested input fields.
along with the other fields of a typical png file the parser will identify the locations specifically the byte offsets of the image width and height fields.
identify critical fields soap monitors the execution of dillo on training png inputs and determines that values in the image width and height fields influence a critical operation the memory allocation at line .
thus soap marks width and height in png images as critical fields which may cause dangerous overflow.
dillo s libpng callback static void png datainfo callback png structp png ptr ... dillopng png ... png png getprogressive ptr png ptr ... check max image size if abs png width png height image max w image max h ... png error handling png ptr aborting... ... ... png rowbytes png getrowbytes png ptr info ptr ... png image data uchar t dmalloc png rowbytes png height ... figure .
the code snippet of dillo libpng callback png.c .
the boldfaced code is the root cause of the overflow vulnerability.
infer constraints soap next infers constraints over the critical fields including the height and width fields.
specifically for each of these fields soap infers an upper bound constraint by recording the largest value that appears in that field for all png training inputs.
rectify atypical inputs soap performs the above three steps offline.
once soap generates constraints for the png format it can be deployed to parse and rectify new png inputs.
when soap encounters an atypical png input whose width or height fields are larger than the inferred bound it enforces the bound by changing the field to the bound.
note that such changes may in turn cause other correlated constraints such as the length of another field involved in a correlated relation with the modified field to be violated.
soap therefore rectifies violated constraints iteratively until all of the learned constraints are satisfied.
iii.
d esign soap has four components the input parser theexecution monitor the learning engine and the input rectifier .
the components work together cooperatively to enable automatic input rectification see figure .
the execution monitor and the learning engine together generate safety constraints offline before the input rectifier is deployed input parser the input parser understands input formats .
it transforms raw input files into syntactic parse trees for the remaining components to process.
execution monitor the execution monitor uses taint tracing to analyze the execution of an application.
it identifies critical input fields that influence critical operations i.e.
memory allocations and memory writes .
learning engine the learning engine starts with a set of benign training inputs and the list of identified critical fields.
it infers safety constraints based on the field83input parser training parse trees execu2on monitor applica2on input parse trees security constraints training inputs incoming input cri2cal fields learning engine input rec2fier rec2fied inputs offline training figure .
the architecture of the soap automatic input rectification system.
values in these training inputs.
safety constraints define the comfort zone of the application.
input rectifier the input rectifier rectifies atypical inputsto enforce safety constraints.
the algorithm modifies the input iteratively until it satisfies all of the constraints.
a. input parser as shown in figure the input parser transforms an arbitrary input into a general syntactic parse tree that can be easily consumed by the remaining components.
in the syntactic parse tree only leaf fields are directly associated with input data.
the hierarchical tree structure reflects nesting relationships between input fields.
each leaf field has a type which can be integer string or raw bytes while each nonleaf field is a composite field with several child fields nested inside it.
the parse tree also contains low level specification information e.g.
endianness .
the input rectifier uses this low level information when modifying input fields.
b. execution monitor the execution monitor identifies the critical input fields that should be involved in the learned constraints.
because large data fields may trigger memory buffer overflows the execution monitor treats all variable length data fields as critical.
integer fields present a more complicated scenario.
integer fields that influence the addresses of memory writes or the values used at memory allocation sites e.g.
calls to malloc andcalloc are relevant for our target set of errors.
other integer fields for example control bits or checksums may not affect relevant program actions.
the execution monitor uses dynamic taint analysis to compute the set of critical integer fields.
specifically soap considers an integer field to be critical if the dynamic taint analysis indicates that the value of the field may influence the address of memory writes or values used at memory allocation sites.
the execution monitor uses an automated greedy algorithm to select a subset of the training inputs for the runs that determine the critical integer fields.
the goal is to select a small set of inputs that minimize the execution time required to find the integer fields and together cover all of the integer fields that may appear in the input files.
the execution monitor currently tracks data dependences only.
this approach works well for our set of benchmark applications eliminating .
.
of integer fields from1 header width header width 3sizebits text text text size sizebits text keyword sizebits text text figure .
a subset of constraints generated by soap for png image files.
consideration.
it would be possible to use a taint system that tracks control dependences as well.
c. learning engine the learning engine works with the parse trees of the training inputs and the list of critical fields as identified by the execution monitor.
it infers safety constraints over critical fields see offline training box in figure .
safety constraints overflow vulnerabilities are typically exploited by large data fields extreme values negative entries or inconsistencies involving multiple fields.
figure presents several examples of constraints that soap infers for png image files.
specifically soap infers upper bound constraints of integer fields line in figure sign constraints of integer fields line upper bound constraints of data field lengths line and correlated constraints between values and lengths of parse tree fields lines .
these kinds of constraints enable the rectification system to eliminate extreme values in integer fields overly long data fields and inconsistencies between the specified and actual lengths of data fields in the input.
when properly inferred and enforced these constraints enable the rectifier to nullify the target set of errors and vulnerabilities in our benchmark.
note that once soap infers a set of safety constraints for one input format it may use these constraints to rectify inputs for any application that reads inputs in that format.
this is useful when different applications are vulnerable to the same exploit.
for example both picasa and imagemagick are vulnerable to the same overflow exploit see section iv .
a single set of inferred constraints enables soap to nullify the vulnerability for both applications.
inferring bound constraints soap infers three kinds of bound constraints upper bound constraints of integer fields sign constraints of integer fields and upper bound constraints of data field lengths.
soap learns the maximum value of an integer field in training inputs as the upper bound of its value.
soap learns an integer field to be non negative if it is never negative in all training inputs.
soap also learns the maximum length of a data field that appeared in training inputs as the84upper bound of its length.
soap infers all these constraints with a single pass over all the parse trees of the training inputs.
inferring correlated constraints soap infers correlated constraints in which an integer field findicates the total length of consecutive children of the parent field of f. lines in figure present an example.
the constraint states that the value of the field text size is the total length in bytes of the field text keyword and the field text text which are two consecutive nested fields inside the field text .
the soap learning algorithm first enumerates all possible field combinations for correlated constraints initially assuming that all of these constraints are true.
when processing each training input the algorithm eliminates constraints that do not hold in the input.
our technical report contains more details and peudo code for our learning algorithm.
d. input rectifier given safety constraints generated by the learning engine and a new input the input rectifier rectifies the input if it violates the safety constraints see figure .
the main challenge in designing the input rectifier is enforcing safety constraints while preserving as much desirable data as possible.
our algorithm is designed around two principles it enforces constraints only by modifying integer fields or truncating data fields it does not change the parse tree structure of the input.
at each step it attempts to minimize the value difference of the modified integer field or the amount of truncated data.
it finds a single violated constraint and applies a minimum modification or truncation to enforce the constraint.
nested input fields further complicate rectification because changing one field may cause the file to violate correlated constraints associated with enclosing or enclosed fields at other levels.
our algorithm therefore iteratively continues the rectification process until there are no more violated constraints.
in our experiments soap enforces as many as correlated constraints on some rectified input files.
our algorithm has a main loop that iteratively checks the input against learned constraints.
the loop exits when the input no longer violates any constraint.
at each iteration it applies a rectification action depending on the violated constraint upper bounds of integer fields if the input violates the upper bound constraint of an integer field our algorithm changes the value of the field to the learned upper bound.
sign constraints of integer fields if the input violates the sign constraint of an integer field our algorithm changes the value of the field to zero.
upper bounds of data field lengths if the input violates the upper bound constraint of the length of a data field our algorithm truncates the data field to its length upper bound.
correlated constraints if the value of a length indicator field is greater than the actual length of corresponding data fields our algorithm changes the value to the actual length.
if the total length of a set of data fields is longerthan the length indicated by a corresponding integer field our algorithm truncates one or more data fields to ensure that the input satisfies the constraint.
note that correlated constraints may be violated due to previous enforcements of other constraints.
to avoid violating previously enforced constraints our algorithm does not increase the value of the length indicator field or increase the field length which may roll back previous changes.
note that because the absolute values of integer fields and the lengths of data fields always decrease at each iteration this algorithm will always terminate.
our technical report contains more details and pseudo code for the algorithm.
checksum soap appropriately updates checksums after the rectification.
soap currently relies on the input parser to identify the fields that store checksums and the method used to compute checksums.
after the rectification algorithm terminates soap calculates the new checksums and appropriately updates checksum fields.
soap could use the checksum repair technique in taintscope to further automate this step.
e. implementation the soap learning engine and input rectifier are implemented in python.
the execution monitor is implemented in c based on valgrind a dynamic binary instrumentation framework.
the input parser is implemented with hachoir a manually maintained python library for parsing binary streams in various formats.
soap is able to process any file format that hachoir supports.
because soap implements an extensible framework it can work with additional parser components implemented in the declarative specification interface of hachoir to support other input formats.
iv.
q uantitative evaluation we next present a quantitative evaluation of soap using five popular media applications.
specifically the following questions drive our evaluation is soap effective in nullifying errors?
how much desirable data does rectification preserve?
how does the amount of training data affect soap s ability to preserve desirable data?
applications and errors we use soap to rectify inputs for five applications swfdec .
.
a shockwave player dillo .
a browser imagemagick .
.
an image processing toolbox google picasa .
a photo managing application and vlc .
.6h a media player .
figure presents a description of each error in each application.
these applications consume inputs that if crafted may cause the applications to incorrectly allocate memory or perform an invalid memory access.
the input formats for these errors are the swf shockwave flash format the png jpeg and tif image formats and the wa v sound format.
malicious inputs we obtained six malicious input files from the cve database the buzzfuzz project and the85application source fault format position related constraints swfdec buzzfuzz x11 crash swf xcreatepixmap rect xmax rect ymax swfdec buzzfuzz overflow crash swf jpeg.c sub jpeg ... width sub jpeg ... height dillo cve overflow crash png png.c header width png.c header height imagemagick cve overflow crash jpeg tiff xwindow.c ifd img width value ifd img height value picasa taintscope overflow crash jpeg tiff n a start frame content width start frame content height vlc cve overflow crash wa v wav.c format size figure .
the six errors used in our experiments.
soap successfully nullifies all of these errors see section iv a .
source presents the source where we collected this vulnerability.
fault and format present the fault type and the format of malicious inputs that can trigger this error.
position presents the source code file and or line positions that are related to the root cause.
related constraints presents constraints generated by soap that nullify the vulnerability.
rectification statistics running time input application train test field distinct rectified enforced ploss mean parse rect.
per field swf swfdec .
.
.
.
n a 531ms 443ms 88ms .096ms png dillo .
.
23ms 19ms 4ms .075ms jpeg imk picasa .
.
.
.
.
24ms 21ms 3ms .080ms tiff imk picasa .
.
.
.
.
31ms 26ms 5ms .093ms wa v vlc .
.
.
.
.5ms .3ms .2ms .088ms figure .
benchmarks and numerical results for our experiments.
the input column presents the input file format.
the application column presents the application name here imk is an abbreviation of imagemagick .
the train column presents the number of training inputs.
the test column presents the number of test inputs.
the field distinct column has entries of the form x y where x is the mean number of fields in each test input of each format and y is the mean number of semantically distinct fields i.e.
fields that have different names in each test input.
the rectified column has entries of the form x y where x is the number of test inputs that the rectifier modified and y is the corresponding percentage of modified test inputs.
the enforced column has entries of the form x y where x is the mean number of constraints that soap enforced for each rectified test input and y is the maximum number of constraints that soap enforced over all rectified test inputs of that format.
the ploss column presents the mean data loss percentage over all test inputs of each format see section iv b .
the mean column presents the mean running time for each test input including both parsing and rectification.
the parse column presents the mean parsing time for each input.
the rect.
column presents the mean rectification time for each input.
the per field column presents the mean running time divided by the number of input fields.
taintscope project .
each input targets a distinct error see figure in at least one of the examined applications.
benign inputs we implemented a web crawler to collect input files for each format see figure for the number of collected inputs for each input format .
our web crawler uses google s search interface to acquire a list of pages that contain at least one link to a file of a specified format e.g.
swf jpeg or wa v .
the crawler then downloads each file linked within each page.
we verified that all of these inputs are benign i.e.
the corresponding applications successfully process these inputs.
for each format we randomly partitioned these inputs into two sets the training set and the test set see figure .
a. nullifying vulnerabilities we next evaluate the effectiveness of soap in nullifying six vulnerabilities in our benchmark see figure .
we applied the rectifier to the obtained malicious inputs.
the rectifier detected that all of these inputs violated at least one constraint.
it enforced all constraints to produce six corresponding rectified inputs.
we verified that the applications processed the rectified inputs without error and that none of the rectified inputs exploited the vulnerabilities.
we next discuss the interactions between the inputs and the root cause of each vulnerability.flash video the root cause of the x11 crash error in swfdec is a failure to check for large swfdec viewing window sizes as specified in the input file.
if this window size is very large the x11 library will allocate an extremely large buffer for the window and swfdec will eventually crash.
soap nullifies this error by enforcing the constraints rect xmax and rect ymax which limit the window to a size that swfdec can handle.
in this way soap ensures that no rectified input will be able to exploit this error in swfdec.
the integer overflow vulnerabilities in swfdec occurs when swfdec calculates the required size of the memory buffer for jpeg images embedded within the swf file.
if the swf input file contains a jpeg image with abnormally large specified width and height values this calculation will overflow and swfdec will allocate a buffer significantly smaller than the required size.
when soap enforces the learned constraints it nullifies the error by limiting the size of the embedded image.
no rectified input will be able to exploit this error.
image errors in dillo imagemagick and picasa have similar root causes.
a large png image with crafted width and height can exploit the integer overflow vulnerability in dillo see section ii .
the same malicious jpeg and tiff images can exploit vulnerabilities in both imagemagick running on86linux and picasa photo viewer running on windows .
imagemagick does not check the size of images when allocating an image buffer for display at magick xwindow.c in function xmakeimage .
picasa photo viewer also mishandles large image files .
by enforcing the safety constraints soap limits the size of input images and nullifies these vulnerabilities across applications and operating systems .
sound vlc has an overflow vulnerability when processing the format chunk of a wa v file.
the integer field format size specifies the size of the format chunk which is less than in typical wa v files .
vlc allocates a memory buffer to hold the format chunk with the size of the buffer equal to the value of the field format size plus two.
a malicious input with a large value such as 0xfffffffe in this field can exploit this overflow vulnerability.
by enforcing the constraint format size soap limits the size of the format chunk in wa v files and nullifies this vulnerability.
these results indicate that soap effectively nullifies all six vulnerabilities.
our code inspection proves that the learned constraints nullify the root causes of all of the vulnerabilities so that no input after rectification can exploit the vulnerabilities.
b. data loss we next compute a quantitative measure of the rectification effect on data loss.
for each format we first apply the rectifier to the test inputs.
we report the mean data loss percentage of all test inputs for each format.
we use the following formula to compute the data loss percentage of a rectified input i pi loss di loss di tot di totmeasures the amount of desirable data before rectification anddi lossmeasures the amount of desirable data lost in the rectification process.
for jpeg tiff and png files di totis the number of pixels in the image and di lossis the number of pixels that change after rectification.
for wa v files di totis the number of frames in the sound file and di lossis the number of frames that change after rectification.
because swf files typically contain interactive content such as animations and dynamic objects that respond to user inputs we did not attempt to develop a corresponding metric.
we instead rely solely on our human evaluation in section v for swf files.
result interpretation figure presents rectification results from the test inputs of each input format.
first note that more than of the test inputs satisfy all constraints and are therefore left unchanged by the rectifier.
note also that both png and wa v have zero desirable data loss png because the rectifier did not modify any test inputs wa v because the modifications did not affect the desirable data.
for jpeg and tiff the mean desirable data loss is less than .
.
one of the reasons that the desirable data loss numbers are so small is that rectifications often change fields such as the name of the author of the data file or the software package that created the data file that do not affect the output presented to .
.
.
.
mean data loss percentage the number of training inputs jpeg tif png wav figure .
the mean data loss percentage curves under different sizes of training input sets for jpeg tiff wa v and png see section iv c .
x axis indicates the size of training input sets.
y axis indicates the mean data loss percentage.
the user.
the application must nevertheless parse and process these fields to obtain the desirable data in the input file.
c. size of training input set we next investigate how the size of the training input set affects the rectification result.
intuitively we expect that using fewer training inputs will produce more restrictive constraints which in turn will cause more data loss in the rectification.
for each format we incrementally increase the size of the training input set and record the data loss percentage on the test inputs.
at each step we increase the number of training inputs by .
figure presents curves which plot the mean data loss percentage of the different input formats as a function of the size of the training input set.
as expected the curves initially drop rapidly then approach a limit as the training set sizes become large.
note that the png and wa v curves converge more rapidly than the tiff and jpeg curves.
we attribute this to the fact that the png and wa v formats are simpler than the tiff and jpeg formats see figure for the number of semantically distinct fields .
d. overhead we next evaluate the rectification overhead that soap introduces.
figure presents the mean running time of the soap rectifier for processing the test inputs of each file format.
all times are measured on an intel .33ghz core machine with soap running on only one core.
the results show that the majority of the execution time is incurred in the hachoir parsing library with the execution time per field roughly constant across the input formats so swf files take longer to parse because they have more fields than other kinds of files .
we expect that users will find these rectification overheads negligible during interactive use.
v. m echanical turk based evaluation amazon mechanical turk is a web based crowdsourcing labor market.
requesters post human intelligence tasks hits workers solve those hits in return for a small payment.
we organized the experiment as follows input files we collected all of the tiff jpeg and swf test input files that the rectifier modified we exclude png87and wa v files because the original and rectified files have no differences that are visible to the user .
hit organization together the tiff and jpeg files comprise the image files.
the swf files comprise a separate pool of video files.
we partition the image files into groups with four files per group.
there is one hit for each group the hit presents the original and rectified versions of the files in the group to the worker for rating.
the hit also contains a control pair.
with probability .
the control pair consists of identical images with probability .
the control pair consists of two completely different images.
we similarly create hits for the videos.
hit copies we post copies of each hit on mechanical turk.
each mechanical turk worker rates each pair in the hit on a scale from to .
a score of indicates no visible difference between the images or videos indicates only minor visible differences indicates a substantial visible difference and indicates that the two images or videos appear completely different.
as with all marketplaces that involve the exchange of currency amazon s mechanical turk contains misbehaving users.
for example some workers attempt to game the system by using automated bots to perform the hits or simply by providing arbitrary answers to hits without attempting to perform the evaluation .
we used three mechanisms to recognize and discard results from such workers approval rating amazon rates each mechanical turk worker and provides this information to hit requestors.
this rating indicates what percentage of that worker s previously performed hits were accepted by other requestors as valid.
we required that prospective mechanical turk workers have an acceptance rate of at least .
using an approval rating filter provides an initial quality filter but cannot guarantee future worker performance.
control pairs each hit contains five pairs one of which was a control pair.
half of the control pairs contained identical images or videos while the other half contained completely different images or videos one of the images or videos was simply null .
if a worker did not correctly evaluate the control pair we discarded the results from that worker.
this technique can effectively detect bots and misbehaving workers but requires control pairs that are difficult to misinterpret.
descriptions for each hit we require workers to provide a short description of the perceived differences if any between image or video pairs.
by forcing users to provide a textual description we help users transition from performing motor control actions e.g.
clicking on images to cognitive executive functions.
this technique helps improve the performance of legitimate workers and enables the detection of misbehaving users by monitoring for empty or nonsensical descriptions.format undetectable minor substantial complete swf .
.
.
jpeg .
.
.
.
tiff .
.
.
.
figure .
results of mechanical turk experiment.
undetectable minor substantial and complete correspond respectively to rectified files whose mean scores are in .
.
.
.
and .
.
whenever we discarded a result from a worker we reposted a copy of the hit to ensure that we obtained results for all copies of each hit.
results for each hit h we computed the mean scores over all the scores given by the workers assigned to h. we then used the mean scores to classify the files in hinto four categories undetectable difference score in minor difference score in .
.
substantial difference score in .
.
and complete difference score in .
.
figure presents for each combination of input file format and classification an entry of the form x y where x is the number of files in that classification and y is the corresponding percentage out of all test inputs.
note that out of rectified inputs only two exhibit a complete difference after rectification.
only exhibit more than a minor difference.
to compare the mechanical turk results with the quantitative data loss percentage results on image files see section iv b we compute the correlation coefficient between these two sets of data.
the correlation coefficient is .
which indicates that they are significantly correlated p .
.
for complex rectification effects we find that mechanical turk workers can provide a more intuitive evaluation than the than quantitative data loss percentage provides.
for example only the image color in figure changes mechanical turk score .
but the quantitative data loss percentage reports simply that all pixels change.
causes of rectification effects when we compare the original and rectified jpeg files we observe essentially three outcomes the rectification changes fields that do not affect the image presented to the user the original and rectified images appear identical out of inputs with turk scores in .
the rectification truncates part of the picture removing a strip along the bottom of the picture out of inputs with turk scores in see figure .
the rectification changes the metadata fields of the picture the pixels wrap around and the rectified image may have similar colors as the original but with the detail destroyed by the pixel wrap out of inputs with turk scores in see figure .
for tiff files we observed essentially four outcomes the rectification changes fields that do not affect the image presented to the user the original and rectified images appear identical out of inputs with turk scores in .
the rectification truncates the image removing a strip along the bottom of the picture out of inputs with turk scores in .
the rectification changes the color palette fields88so that only the image color changes out of inputs with turk scores in see figure .
the rectification changes metadata fields and all data is lost out of inputs with turk score .
.
for swf files we observed essentially three outcomes the rectification changes fields that do not affect the video out of inputs with turk scores in .
the rectification changes fields that only affect a single visual object in the flash video such as an embedded image or the background sound leaving the swf functionality largely or partially intact out of inputs with turk scores in .
the rectification changes fields that affect the program logic of the flash video so that the rectified flash fails to respond to interactive events from users out of inputs with turk scores in depending on how important the affected events are to the users .
vi.
r elated work input rectification applying input rectification to improve software reliability and availability was first introduced by rinard who presented the implementation of a manually crafted input rectifier for the pine email client.
soap improves upon the basic concept by automating the fundamental components of the approach learning and rectification.
data diversity ammann and knight propose to improve software reliability using data diversity.
given an input that triggers an error the goal is to retry with a reexpressed input that avoids the error but generates an equivalent result.
input rectification in contrast may change the input and therefore change the output .
the freedom to change the input semantics enables input rectification to nullify a broader class of errors in a broader class of applications specifically applications for which equivalent inputs may not be available .
anomaly detection anomaly detection research has produced a variety of techniques for detecting malicious inputs .
web based anomaly detection uses input features e.g.
request length and character distributions from attack free http traffic to model normal behaviors.
http requests that contain features that violate the model are flagged as anomalous and dropped.
similarly valeur et al propose a learning based approach for detecting sql injection attacks.
wang et al propose a technique that detects network based intrusions by examining the character distribution in payloads.
perdisci et al propose a clustering based anomaly detection technique that learns features from malicious traces as opposed to benign traces .
soap differs from anomaly detection techniques in its aim to rectify inputs and to preserve desirable data in inputs while anomaly detection techniques simply recognize and drop potentially malicious inputs.
signature generation vigilante bouncer packetvaccine vsef and shieldgen generate vulnerability signatures from known exploits.
soap differs from such systems in its ability to nullify unknown vulnerabilitiesand to enable users to access desirable data in potentially malicious inputs rather than discarding such inputs .
critical input code and data inference snap can automatically learn which input fields code and program data are critical to the acceptability of the output that a given application produces.
other fields code and data can sustain significant perturbations without changing the acceptability of the output.
soap could use this criticality information to minimize or even eliminate changes to critical input fields in the rectification process.
directed fuzzing soap uses taint analysis to track input fields that may trigger overflow errors.
buzzfuzz also uses taint tracing to track disparate input bytes that simultaneously reach security critical operations .
buzzfuzz uses this information to perform directed fuzzing on inputs that have complex structures.
like buzzfuzz soap learns which bytes reach security critical operations.
unlike buzzfuzz soap also learns and enforces safety constraints over these bytes.
automatic patch like soap clearview enforces learned invariants to eliminate errors and vulnerabilities.
specifically clearview learns invariants over registers and memory locations detects critical invariants that are violated when an adversary attempts to exploit a security vulnerability then generates and installs patches that eliminate the vulnerability by modifying the program state to enforce the invariants.
rectification algorithm the soap rectification algorithm is inspired by automated data structure repair which iteratively modifies a data structure to enforce data consistency defined in an abstract model.
it is also possible to use data structure repair to enforce learned data structure consistency properties .
evaluation with mechanical turk by enabling a largescale low cost human workforce mechanical turk has become a viable option for a variety of experimental tasks such as training data annotation computation result evaluation and behavior research .
vii.
c onclusion our results indicate that input rectification can effectively nullify errors in applications while preserving much and in many cases all of the desirable data in complex input files.