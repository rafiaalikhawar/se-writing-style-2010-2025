inferring method specifications from natural language api descriptions rahul pandita xusheng xiao hao zhongy tao xie stephen oneyz and amit paradkarx department of computer science north carolina state university raleigh usaylaboratory for internet software technologies institute of software chinese academy of sciences beijing chinazhuman computer interaction institute carnegie mellon university pittsburgh usaxi.b.m.
t. j. watson research center hawthorne ny usa frpandit xxiao2 txie g ncsu.edu zhonghao itechs.iscas.ac.cn soney cs.cmu.edu paradkar us.ibm.com abstract application programming interface api documents are a typical way of describing legal usage of reusable software libraries thus facilitating software reuse.
however even with such documents developers often overlook some documents and build software systems that are inconsistent with the legal usage of those libraries.
existing software verification tools require formal specifications such as code contracts and therefore cannot directly verify the legal usage described in natural language text in api documents against code using that library.
however in practice most libraries do not come with formal specifications thus hindering toolbased verification.
to address this issue we propose a novel approach to infer formal specifications from natural language text of api documents.
our evaluation results show that our approach achieves an average of precision and recall in identifying sentences that describe code contracts from more than sentences of api documents.
furthermore our results show that our approach has an average accuracy in inferring specifications from over sentences describing code contracts.
i. i ntroduction software reuse is commonly practised since the advent of software development .
software reuse facilitates development of larger more complex and timely delivered software systems .
to determine what and how to reuse specifications of reusable software libraries play an important role.
in the absence of specifications developers may write code that is inconsistent with the expectations of libraries.
as a result not only such code is of inferior quality and contains faults the added cost of debugging and correcting such faulty code could also defeat the purpose of reusing software.
code contracts have emerged as a popular way of formalizing method specifications close to the implementation level.
code contracts unambiguously capture the expectations of a method in terms of what is required preconditions and what to expect after method execution postconditions .
furthermore code contracts can be subjected to formal verification by existing state of the art verification tools such as spec jml1 and code contracts for .net2.
additionally code contracts can be used for formal proofs and automated code correction .
despite being highly desirable code contracts do not exist in a formalized form in most existing software systems in practice .
in contrast library developers commonly describe legal usage in natural language text in application leavens jml interface api documents.
typically such documents are provided to client code developers through online access or are shipped with the api code.
for example j2ee s api documentation3is one of the most popular api documents.
even with such documents client code developers often overlook some api documents and use methods in api libraries incorrectly .
since these documents are written in natural language existing tools cannot verify legal usage described in a library s api documents against the client code of that library.
one possible solution is to manually write code contracts based on the specifications described in api documents.
however due to a large number of sentences in api documents manually hunting for contract sentences and writing code contracts for the api library is prohibitively time consuming and labor intensive.
for instance the file class of the c .net framework has around sentences.
moreover not all of these sentences describe code contracts requiring extra effort to first locate the sentences describing code contracts and then translate them.
to address the preceding problem we propose a novel approach to facilitate verification of legal usage described in natural language text of api documents against client code of those libraries.
we propose new techniques that apply natural language processing nlp on method descriptions in api documents to automatically infer specifications.
in particular our techniques address the following challenges to infer specifications automatically.
ambiguity .
existing linguistic analysis techniques focus on well written documents such as news articles .
in contrast method descriptions are often not well written.
for instance consider the sentence from the file class in the c .net framework true if path is an absolute path otherwise false .
this sentence does not have the main subject and the verb.
to address this challenge we use meta data such as position information of description as well as method signatures.
in particular in this example the sentence is placed under the return descriptions and the method signature describes the return type as boolean.
we use this information to infer that words true and false describe the return value of the method.
keywords .
method descriptions often contain programming keywords e.g.
true null buffer which have a different meaning in the context of programs in contrast to general linguistics.
for instance consider this sentence from the path class in the c .net framework this method also returns false if path is null .
in this sentence words false and null are nouns in the context of object oriented languages such as java and c whereas in general linguistics these words are adjectives.
thus these keywords need to be handled differently.
for those keywords we propose a new technique called noun boosting to distinguish keywords from the other words.
semantic equivalence .
a legal usage in natural language can be described in different words and semantic structures.
for instance consider the following two fragments that describe the same specification name can contain numbers underscores... and name consists of numbers and or underscores... .
thus there is a need to identify the semantic equivalence of legal usage described in different ways.
to address this challenge we propose a new technique called equivalence analysis based on identified grammatical structures main nouns and verbs of a sentence.
in summary our approach infers specifications from existing api documents thus facilitating verification of client code of an api library against the natural language descriptions of the library.
as our approach analyzes api documents in natural language it can be reused independent of the programming language of the library.
additionally our approach complements existing approaches that infer code contracts from source code or binaries.
to the best of our knowledge ours is the first approach that analyzes api documents to extract specifications targeted towards generating code contracts.
our paper makes the following major contributions a technique that effectively identifies natural language sentences in the api documents for a library that describe code contracts hereby referred to as contract sentences and a technique to infer specifications from the identified contract sentences.
a prototype implementation of our approach based on extending the stanford parser which is a natural language parser to derive the grammatical structure of sentences.
an open source implementation of our prototype can be found at our website4.
an evaluation of our approach on sentences for methods in five different classes from the .net framework and facebook api for c .
our evaluation results show that our approach effectively identifies contract sentences with an average of precision and recall.
additionally our approach infers spec4 from around contract sentences with an average accuracy of .
ii.
b ackground a. code contracts code contracts based on the design by contracts dbc methodology are typically in the form of method pre conditions post conditions and class invariants.
they are used to specify what a method accomplishes without giving details of how the method is implemented.
preconditions for a method describe what is expected by the method in terms of inputs.
post conditions for a method describe what to expect when the method has finished execution in terms of output.
class invariants describe what conditions on receiver objects of the class are true before and after the execution of each method in the interface of the class.
furthermore code contracts are useful for software reuse software testing formal proofs and automated correction of code .
b. nlp preliminaries due to the inherent ambiguous nature of natural language it is very difficult to understand and convert the natural language text into precise and unambiguous specifications that can be processed by computers.
in contrast existing nlp techniques have been shown to be fairly accurate in highlighting the grammatical structure of a natural language sentence .
we next present two of the nlp techniques that have been used in this work.
word tagging parts of speech pos tagging aims to identify the part of speech such as nouns and verbs that a particular word within a sentence belongs to.
the most commonly known technique is to train a classification parser over a manually labelled dataset .
current state of theart approaches can achieve around accuracy over well written news articles .
phrase and clause parsing chunking divides a sentence into a set of words that are logically related such as a noun phrase andverb phrase .
chunking thus further brings forth the syntax of a sentence after pos tagging has been done.
current state of the art approaches can achieve around accuracy in classifying phrases and clauses over well written news articles.
iii.
m otivating examples we next present two examples where developers wrote faulty code because they overlooked legal usage in method descriptions.
we collected these examples from online developer forums.
these examples highlight the importance of our approach since the defects shown in them could have been easy to fix with our inferred code contracts.
nullpointerexception .
as shown in figure a developer asked a question on in one of the java forums5regarding java.lang.nullpointerexception .
download file nullpointerexception.htmlfigure .
description of a question posed in a java forum figure shows the code snippet.
after going through the suggestions from the contributing forum members the author of this question was finally able to resolve the problem to a path issue occurring in the underlined line a month after he initially posted the question.
the associated api documents reveal that there are many ways to throw java.lang.nullpointerexception thus making the task of debugging non trivial.
the problem caused due to invoking the read method on a null object of inputstream .
the method description for the getresourceasstream method in the servletcontext interface states that this method returns null if no resource exists at the specified path.
.
the sentence once translated into a formal specification can be verified statically or at runtime to pinpoint the problem.
for instance given the specification that the method can return null advanced integrated development environments ides can raise a warning after the developer attempts to perform an operation on the return value of the getresourceasstream method thus asking the developer to put the necessary checks in place.
path format not supported .
another developer posted a line code snippet in a forum6.
the developer reported that he she was noticing exceptions while moving a file.
after a brief exchange of messages the issue was traced to the moveto method in the fileinfo class in c .net.
further exchanges revealed that the developer was attempting to move and rename the file to .txt .
the method description for the moveto method in fileinfo states that the method throws an argumentexception if the new file name consists of invalid characters defined in path.getinvalidcharacters including character .
after our approach infers a code contract from the description the problem can be identified and reported by static checkers that are usually built into ides.
elusive error while renaming file figure .
overview of our approach iv.
a pproach we next present our approach for inferring code contracts from method descriptions.
figure gives an overview of our approach.
our approach uses a parser a pre processor a text analysis engine a post processor and a code contract generator.
the parser accepts the api documents and extracts intermediate contents from the method descriptions.
the preprocessor augments the sentences in an intermediate representation with meta data.
the text analysis engine accepts the intermediate representation of the sentences and then based on our semantic templates generates specifications in the form of first order logic fol expressions.
the postprocessor refines the fol expressions.
the code contract generator accepts the fol expressions and generates code contracts by using a mapping relation to the constructs of the target programming language.
a. parser our parser accepts api documents and extracts intermediate contents from the method descriptions.
in particular from the method descriptions our parser extracts the following contents summary description the summary of the method argument description the descriptions of the method s arguments return description the descriptions of the method s return value exception description the descriptions of exceptions explicitly thrown by the method remark description additional descriptions about the functionality of the method.
b. pre processor our pre processor accepts extracted contents of the method descriptions and performs three major tasks.
meta data augmentation .
for each identified method our pre processor collects the following meta data information and associates it with respective sentences the names and data types of method arguments the types of the return value and exceptions the names of the classes namespaces and methods.
for example for the method description shown in figure the meta data information associated with the sentences in line is as follows sentence type argument description argument name prop name argument type string .
this information is used in code contract generation by substituting the name of the variable with its place holder and matching a template for code contracts using the datatype of the variable.
in particular the pre processor uses method signatures and their associated tags for meta data augmentation.
from the method signatures our approach extracts the name of the method arguments the data types of the method arguments and the exceptions thrown by the method.
noun boosting .
since our text analysis engine uses the parts of speech pos tags provided by a pos tagger the accuracy of the inferred specifications is dependent on the accuracy of the pos tagger.
however there are specific words that represent nouns in the context of programs in contrast to adjectives or verbs in the context of general linguistics.
for example consider the statement this method also returns false if path is null .
in this sentence false and null should be treated as nouns since they are constructs of programming languages but a typical pos tagger would incorrectly classify them as adjectives.
our pre processor identifies these words from the sentences based on a domain specific dictionary and thus forces the underlying pos tagger to identify them as nouns.
in particular our pre processor uses a predefined list of words for noun boosting.
we manually collected these words by looking into the method descriptions in the data class of the facebook api and the path class of the .net framework api.
a list of these words is available on our project website.
programming constructs and jargon handling .
in english grammar the .
character represents the end of a sentence.
however in programming languages the .
character is used as a separator character as well.
for example in the facebook.data namespace the .
character represents that the facebook.data namespace exists within the facebook namespace.
our pre processor identifies these separators and replaces .
with .
for example facebook.data is replaced with facebook data .
additionally developers tend to use abbreviations for specific words e.g.
max.
for maximum and min.
for minimum .
our pre processor identifies these words and replaces abbreviations with their full names.
for example max.
is replaced with maximum .
these techniques increase the accuracy of the underlying pos tagger and thus increase the accuracy of our text analysis engine.
furthermore our pre processor maintains mapping relations of the place holder words from the programming language constructs to the original words and locations and these relations are used by our post processor later to infer specifications.
methods and namespaces have a well defined lexical structure in a programming language.
our pre processor uses this structural information and builds regular expressions to identify these words.
for handling jargons and abbreviations such as max.
we manually built a list of such words.
in future work we plan to adapt hill et al.
s technique to generate the list automatically.although a pos tagger can be retrained to achieve these pre processing steps we prefer annotations to make our approach independent of any specific nlp infrastructure thus ensuring interoperability with various pos taggers.
c. text analysis engine our text analysis engine parses pre processed sentences and builds specifications in the form of fol expressions.
we chose fol since previous research shows that fol is an adequate representation for natural language analysis.
we first use a pos tagger to annotate pos tags in a sentence.
we then use an nlp technique called shallow parsing .
a shallow parser accepts the lexical tokens generated by the pos tagger and attempts to classify sentences based on pre defined semantic templates.
shallow parsing is implemented as a sequence of cascading finite state machines.
research has shown the effectiveness of using finite state machines in different areas of linguistic analysis such as morphological lookup pos tagging phrase parsing and lexical lookup.
table i shows frequently used semantic templates for identification of specifications.
column description describes what is inferred from the sentence if a semantic pattern holds.
for example for the template described in the first row in table i the fol expression is constructed ascan not be path null where path and null are terms to the predicate can not be .
the specification is interpreted as can not be predicate should be evaluated to be true over terms path and null .
as another example our text analysis engine uses the semantic pattern transitive predicate described in the fourth row in table i to analyze the sentence in line of figure .
figure shows the graphical fol expression.
each internal node shaded grey represents a predicate and the children of these nodes represent the terms to that predicate.
we implemented a configurable infrastructure to accept a pos tagger to annotate a sentence with pos tags.
in particular for our evaluation we used the stanford parser which is a natural language parser to work out the grammatical structure of sentences.
the stanford parser parses a natural language sentence and determines pos tags associated with different words phrases.
we also implemented a generic and extensible framework that accepts semantic patterns based on the functions of pos tags and converts them into a series of cascading fsms.
once pos tags have been determined by a pos tagger the sentences along with tags are passed as an input to the shallow parser which generate fol expressions based on the fsms.
d. post processor our post processor accepts the fol expressions produced by the previous component and performs three types of semantic analysis removing irrelevant modifiers in predicates classifying predicates into a semantic class based on domain dictionaries and augmenting expressions.table i categories of shallow parsing semantic templates .
name example description .
predicate name the path subject can not be verb the subject and object form the terms of the nullobject predicate represented by verb.
.
conditional followed or if path does not have extension conditional the subject verb object forms specification preceded nominal getextension subject returns verb as described in row which is true when the predicate system.string.empty object condition highlighted by conditional is true.
the condition is further resolved using one of the templates.
.
prepositional predicate path subject is verb not null the verb forms the partial predicate and the subject or empty string preposition forms one of the terms.
the second term and the remaining of the predicate are extracted by resolving the preposition.
.
transitive predicate name subject is verb a valid the sentence is broken down into two sentences.
identifier object subject which is no the first sentence ends with the phrase labeled longer than characters clause object subject and the second sentence begins with the phrase labeled object subject .
each sentence is further resolved and the resulting specifications are joined using the logical and operator.
figure .
specifications in format of fol expressions extracted by our nlp parser for defineobjectproperty method in facebook api summary ..... param name prop name this name needs to be a valid identifier which is no longer than characters starting with a letter a z and consisting of only small letters a z numbers and or underscores.
param ..... public void defineobjectproperty string obj type string prop name int prop type figure .
the method description of the defineobjectproperty method in facebook api equivalence analysis .
consider the predicate needs to be in fol representation shown in figure .
the words needs to are modal modifiers to the verb be .
such modal modifiers are identified and eliminated.
furthermore our post processor classifies predicates into pre defined semantic classes based on domain dictionaries.
this classification addresses the challenge of inferring semantic equivalence.
for instance the predicate starting with in figure can also be represented as begins with .
our post processor identifies and classifies all semantically equivalent predicates into a single category and thus reduces the effort to individually write mappings for every predicate in inferred fol expressions even when they represent same the semantic function.
we have identified the following seven major semantic categories for predicates greater lesser begin end consist equal and action with respect to expressions dealing with code contracts.the negative semantic categories are represented using a negation operator preceding the identified semantic class.
in the preceding semantic analysis our post processor uses an nlp technique called lemmatization .
lemmatization involves full morphological analysis to accurately identify the lemma for each word.
extracting lemmas reduces the various operational forms of a word to its root.
for example am are and is are all reduced to be .
once the lemma of a word is identified our postprocessor uses the lemma to query a synonym from the wordnet database for a suitable replacement.
from the implementation perspective we maintain a list of modifier words to identify and discard them.
we have also collected synonyms from wordnet to classify a predicate in one of the semantic classes.
if a match is not found our post processor places the predicate in the unknown category.
intermediate term elimination .
the intermediate term elimination attempts to remove intermediate terms if they are found in the extracted expressions.
for example consider the statement in line of figure .
here valid identifier is used as the intermediate term to establish the no longer relationship between name and characters .
since a shallow parser is independent of the semantics of the words used in a sentence our text analysis engine picks up these intermediate terms as valid arguments to the predicate using them as shown in figure .
these terms are of no inherent importance in code contract generation.
our post processor identifies such terms and eliminates them by replacing their usage with their definition.
in particular our post processor eliminates intermediate terms by parsing fol expressions.
we specifically watch out for terms that are involved in an equality operator with a variable name followed by the same term being used as an input to another predicate in the representation.
expression augmentation .
the sentences in return descriptions and exception descriptions in an api document arefigure .
fol expression after synonym analysis and compaction for the defineobjectproperty method in facebook api algorithm expression augmentation generator input expre meta data d output expre0 expr e0 e if d description return then if e0 root !
e0 right is variable then term t e0 right iffindtype t d returntype then predicate p new predicate returns p term t e0 right p end if end if end if if d description exception then if e0 root !
e0 right is empty then term t d exception name predicate p new predicate throw p term t e0 right p end if if e0 root!
!
then term t d exception name predicate p new predicate throw p term t expr e00 new expr !
e00 left e0 e00 right p e0 e00 end if end if return e0 often not well written.
for example consider the following sentences true if path is an absolute path otherwise false.
the return descriptions for the ispathrooted method in the path class in the c .net framework.
the main subject and verb are missing as in what is true and false.
if path is null.
one of the exception descriptions repeated in many methods in the file class in the c .net framework.
the action is missing as in what happens if the path is null.
io error occurs while accessing specified directory.
one of the exception descriptions repeated in many methods in the directory class in the c .net framework.
while the sentence describes a code contract the sentence omits important information in terms under what specific condition the exception is thrown.our expression augmentation attempts to augment these expressions.
in particular for each method we use meta data collected in the pre processor augment to complete the fol expressions involving return and exception descriptions.
here we propose algorithm to achieve our expression augmentation.
the algorithm accepts an fol expression and the meta data of a sentence.
the algorithm returns an augmented expression if successful and otherwise returns the original expression.
the algorithm first checks whether the expression corresponds to a return description statement line .
if the expression is a conditional expression and the right hand side of the expression is a variable term the algorithm checks whether the type of the variable matches the return type described in the meta data.
literals true and false are identified as boolean numeric values are identified as numeric that matches integer float and double.
if a match is found we construct the right hand side of the original predicate as returns .
for the descriptions of exceptions our expression augmentation does a similar check except that there is no need to match the type of a variable term.
we construct the predicate asthrows .
additionally for the expressions in exception descriptions where no conditional expression is identified we explicitly construct a conditional fol expression line and associate the expression to the left hand side and the throws predicate to the right hand side.
e. code contract generator our code contract generator generates code contracts from the extracted fol expressions.
the generator uses the predefined mapping of semantic classes of the predicates to the programming constructs to produce valid code contracts.
our current implementation supports the mapping relations for the string class integer class null checks return andthrows constructs.
with more mapping relations our generator can easily produce code contracts involving complex objects.
for example consider the fol expression in figure .
the greater predicate is mapped to the length method of the string class.
thus the resulting code contract isrequires !
name.length .
in contrast begins is mapped to the startswith andsubstring methods of the string class.
our generator resolves which methods to choose by taking into account the argument for the method.
if the argument is a character characterized by a single character in quotes or string characterized by a string in quotes our generator uses the startswith method and if the argument is a range characterized by expression a z our generator uses the substring method by converting the range to a regular expression.
thus the final contract is requires name.substring .matches .
requires !prop name.length requires prop name.substring .
matches requires prop name.matches figure .
the inferred specifications for the prop name variable of thedefineobjectproperty method in facebook api v. e valuation we conducted an evaluation to assess the effectiveness of our approach.
in our evaluation we address three main research questions rq1 what are the precision and recall of our approach in identifying contract sentences i.e.
sentences that describe code contracts ?
rq2 what is the accuracy of our approach in inferring specifications from contract sentences in the api documents?
rq3 how do the specifications inferred by our approach compare with the human written code contracts?
a. subjects we used the api documents of the following two libraries as subjects for our evaluation.
c file system api documents .
these documents describe correct usage of methods for manipulating files in the .net environment.
however developers still post a lot of questions regarding their usage.
because of the importance of the file api we chose these api documents as the first set of subject documents for inferring specifications.
in particular we use three key classes file path and directory in our evaluations.
facebook api documents .
facebook is a popular social networking site which allows developers to write their own third party applications.
according to facebook statistics people on facebook install million applications everyday7.
due to the sheer popularity of facebook and a huge number of developers developing third party applications we chose the facebook api8for c as another set of subject documents for our evaluation.
in particular we use four key classes data friends events and comments within the facebook api for our evaluations.
table ii shows the statistics of the subject documents used in our evaluations.
column class lists the name of classes and their corresponding libraries.
column m lists the number of methods in each class.
column s lists the number of natural language sentences in method descriptions of each class.
b. evaluation results rq1 precision and recall in identifying contract sentences in this section we quantify the effectiveness of our approach in identifying contract sentences by answering rq1.
we first manually measured the number of contract sentences in the api documents.
we considered a sentence as a contract sentence if it contains a clause that is either a pre condition or post condition.
two authors independently sentences as contract sentences by discussing iteratively until they reached a consensus.
we then applied our approach on the api documents and manually measured the number of true positives tp false positives fp and false negatives fn produced by our approach as follows tp.
a sentence that is a contract sentence and is identified by our approach as a contract sentence.
fp.
a sentence that is not a contract sentence and is identified by our approach as a contract sentence.
fn.
a sentence that is a contract sentence and is identified by our approach as not a contract sentence.
in statistical classification precision is defined as the ratio of the number of true positives to the total number of items reported to be true and recall is defined as the ratio of the number of true positives to the total number of items that are true.
f score is defined as the weighted harmonic mean of precision and recall.
higher values of precision recall and f score indicate higher quality of the contract statements inferred using our approach.
based on the total number of tp fp and fn we calculated the precision recall and f score of our approach in identifying contract sentences as follows precision tp tp fp recall tp tp fn f score 2x precision x recall precision recall table ii shows the effectiveness of our approach in identifying contract sentences.
column class lists the names of the classes.
column s lists the number of sentences in each class and column sc lists the number of sentences manually identified as contract sentences.
columns tp fp and fn represent the number of true positives false positives and false negatives respectively.
columns p r and fs list values of precision recall and f scores respectively.
our results show that out of sentences our approach effectively identifies contract sentences based on average precision recall and f score of .
and .
respectively.
we next present an illustrative example of how our approach incorrectly identifies a sentence as a contract sentence.
consider the sentence from the getlastwritetime method description in the directory api for c the file or directory for which to obtain write date and time information.
the sentence describes the input parameter path .
ideally a pos tagger should parse the statement as a noun phrase statement i.e.
a sentence including just a noun phrase.
however the pos tagger incorrectly annotates this sentence as including a subject object and predicate where the predicate is write .
since our shallow parser is dependent on the pos tagger to correctly annotate pos tags our approach incorrectly identifies this sentence as a contract sentence.
the fp produced by our approach are primarily due to the incorrect pos tags annotated by the pos tagger.table ii statistics of subject classes and evaluation results class m s sc tp fp fn p r fs si acc sd c q data .
.
.
.
.
friends .
.
.
.
.
events .
.
.
.
.
comments .
.
.
.
.
file .
.
.
.
na na na path .
.
.
.
na na na directory .
.
.
.
na na na total .
.
.
.
.
column average the fn in our approach are also primarily due to incorrect pos tags annotated by the pos tagger.
overall a significant number of fp and fn can be further reduced by improving the existing underlying nlp infrastructure.
rq2 accuracy in inferring specifications from contract sentences to address rq2 we apply our approach on sentences that were manually identified as contract sentences to infer fol expressions.
we then manually verify the correctness of the inferred specifications.
we define the accuracy of our approach as the ratio of the contract sentences with correctly inferred expressions to the total number of contract sentences.
table ii shows the effectiveness of our approach in inferring specifications fol expressions from contract sentences.
column class lists the name of the classes.
column sc lists the number of sentences manually identified as contract sentences.
column si lists the number of specifications that were correctly inferred from contract sentences.
column acc lists the accuracy of our approach in inferring specifications from the contract sentences.
our results show that out of contract sentences our approach correctly inferred specifications from contract sentences with the accuracy of .
.
we next present an illustrative example of how our approach infers an incorrect specification from a contract sentence.
consider the sentence from the friends class in the facebook api for .net the first array specifies one half of each pair the second array the other half therefore they must be of equal size.
.
the sentence describes the two input parameters.
our approach successfully identifies the sentence as a contract sentence.
however while inferring the specification our approach faces difficulty in accurately inferring the semantic relations.
in particular the complexity of the sentence involving both code contracts and generic descriptions makes it difficult for the pos tagger to correctly annotate pos tags thus causing a semantic pattern to be incorrectly applied to the sentence.
this sentence appears times across different method descriptions in the friends class where our approach performed the worst.
if our approach would have correctly inferred specifications from the sentence the accuracy of our approach for the friends api would have been .
instead of .
.
rq3 comparison with human written contracts to answer rq3 we compared the specifications inferred from contract sentences by our approach with the human written code contracts.
the facebook api for c is equipped with code contracts that were written by rubinger et al.
as a part of their experience report on applying the microsoft code contract system for the .net framework.
we first manually calculated sias the number of specifications correctly inferred by our approach for a class.
we then calculated sdas the number of code contracts written by rubinger et al.
for that class and cas the number of specifications in common.
table ii shows the comparison of the specifications inferred by our approach to the human written contracts.
column class lists the name of the classes.
column si lists the number of specifications correctly inferred by our approach.
column sd lists the number of human written code contracts.
column c lists the number of the specifications that are common between si and s0 d .
our results show that out of inferred specifications and human written contracts only are in common.
we next discuss some of the implications of the results.
before carrying out this evaluation we had hoped that the specifications inferred by our approach would largely be a superset of the human written contracts as rubinger et al.
claimed to have written these contracts as a direct translation of the method descriptions and some as their own interpretation of the api .
however the results suggest that not to be the case.
we were intrigued by the outcome and manually investigated the nature of the human written contracts and the specifications inferred by our approach.
interestingly we found that all of the human written code contracts are assertions categorized as follows null checks range checks and size checks.
furthermore around of these are simplistic not null andlength checks.
for instance for the example method description in figure the human written code contracts are contract.requires name!
null name.length although the contract holds true it is a simplistic not null andlength check since it fails to capture limitations of the first character and size restrictions .
in contrast our approach is capable of inferring detailed specifications as shown in figure .
furthermore there is no direct text in the method description that corresponds to some of human written contracts.
since our approach infers specifications from only method descriptions we do not produce such specifications for these contracts.
additionally of the instances of the same description as shown in figure for input parameter name across the methods in thedata class for the facebook api we found only instances where the specifications inferred by our approach completely matched the code contracts written by rubinger et al.
the remaining instances were translated as described earlier.
logically specifications produced by our approach imply the corresponding human written code contracts.
in future work we plan to explore techniques to infer these implied contracts.
on manual examination of other human written contracts we concluded that despite valid several contracts are deemed to be implied and hence there is no corresponding textual description in the api method descriptions including all the contracts in the friends comments and events classes and more than of the contracts in the data class of the facebook api.
these contracts are the ones that rubinger et al.
claimed to have written as their own understanding of the api.
in addition none of the human written contracts capture post conditions.
in contrast our approach is able to infer both pre and postconditions from the method descriptions.
from our evaluation we conclude that our approach systematically infers specifications from the method descriptions in api documents.
however there are cases where method descriptions do not completely describe specifications.
in such cases our approach can work in conjunction with either human written contracts or approaches that statically or dynamically infer code contracts from api implementation .
summary in summary our evaluation shows that our approach effectively identifies contract sentences from the method descriptions in api documents demonstrated by the high values in columns precision recall and fscore in table ii from over sentences.
our evaluation also shows that our approach infers specifications from the contract sentences with high accuracy averagely .
as shown by the values in column accu in table ii from over contract sentences.
furthermore our evaluation results show that our approach can infer detailed specifications than human written contracts.
c. threats to validity threats to external validity primarily include the degree to which the subject documents used in our evaluations are representative of true practice.
to minimize the threat we used api documents of two representative projects one commercial and the other open source.
the c file system api documents describe one of the most commonly used and mature apis.
we also used the facebook api for c which is relatively new introduced in .
furthermore the difference in the functionalities provided by the two projects also address the issue of over fitting our approach to a particular type of api.
the threat can be further reduced by evaluating our approach on more subjects.
additionally to represent human written code contracts we used the human written code contracts for the facebook api for c and did not use any code contracts written by ourselves.
threats to internal validity include the correctness of our implementation in extracting code contracts and labelling a statement as a contract statement.
to reduce the threat we manually inspected all the specifications inferred against the api method descriptions in our evaluation.
furthermore we ensured that the results were individually verified and agreed upon by two authors.
vi.
d iscussion and future work our approach serves as a way to formalize the description of specifications in the natural language texts of api documents targeted towards generating code contracts thus facilitating existing tools to process these specifications.
we next discuss the benefits of our approach in other areas of software engineering followed by a description of the limitations of the current implementation and our approach.
code searching .
code searching for reuse is a classic problem in software engineering.
among previous approaches a recent approach by riess provides promising results by using semantics such as code contracts as input output relationships for code searching.
our approach can be used for generating specifications from api documents in a code repository and thus assisting such approaches in producing better results.
program synthesis .
automated program synthesis holds potential for easing the task of a developer by taking care of program generation and allowing the developer to concentrate on design tasks.
recent work by srivastava et al.
addresses the problem by leveraging specifications in the form of pre post conditions and invariants to achieve synthesis.
our approach can work in conjunction with such approaches to extract specifications from natural language text to achieve better synthesis.
we next present some of the limitations of our approach.
information flow analysis .
our approach currently takes into account the specifications described in a single sentence.
however there are instances when a specification is distributed across several sentences.
consider the sentences below parameter values id value pairs of preferences to set.
each id is an integer between and inclusively.
each value is a string with maximum length of characters.
the first sentence describes the data structure used for the variable values.
the sentences following the first sentence describe the specification on each item in the data structure.
since currently our approach works on individual sentences it is not possible to establish the relationship between the specifications described in later sentences to the first sentence.
in future work we plan to investigate techniques to facilitate information flow analysis to handle such situations.
contextual information .
some api documents are not comprehensive.
method descriptions omit certain specifications that have already been described in another closely related method.
currently our approach does not deal with such scenarios as we do not consider contextual information.
in future work we plan to explore techniques to infer specifications in such scenarios.
validation of method descriptions .
api documents can sometimes be misleading thus causing developers to write faulty client code.
in future work we plan to extend our approach to find documentation implementation inconsistencies.
elimination of predefined lists .
the current implementation of our approach uses predefined lists for domain dictionaries.
there are approaches that facilitate building domain dictionaries from source code.
we plan to extend our implementation to use these approaches.
furthermore we rely on pre defined templates for code contract generation.
while such a strategy serves our purpose of prototyping advanced techniques such as keyword programming have shown promising results in building programming statements using keywords.
we plan to explore such techniques and evaluate the overall effectiveness of our approach after augmenting it with such techniques.
vii.
r elated work design by contracts has been an influential concept in the area of software engineering in the past decade.
a significant amount of work has been done in automated inference of code contracts.
there are existing approaches that statically or dynamically extract code contracts .
however a combination of developer written and automatically inferred contracts seems to be the most effective approach .
since developers describe the specifications in the method descriptions we believe that our approach can work in conjunction with existing approaches towards extracting a comprehensive set of code contracts for a method.
furthermore wei et al.
demonstrated that dynamic contract inference performed better when provided with an initial set of seed contracts.
there are existing approaches that infer code contract like specifications such as behavioral model algebraic specifications and exception specifications either dynamically or statically from source code and binaries.
in contrast our approach infers specifications from the natural language text in api documents thus complementingthese existing approaches when the source code or binaries of the api library is not available.
nlp techniques are increasingly applied in the software engineering domain.
nlp techniques have been shown to be useful in requirements engineering usability of api documents and other areas .
we next describe most relevant approaches.
xiao et al.
use shallow parsing techniques to infer access control policy acp rules from natural language text in use cases.
the use of shallow parsing techniques works well on natural language texts in use cases owing to well formed nature of sentences in use case descriptions.
in contrast often the sentences in api documents are not well formed.
additionally their approach does not deal with programming keywords or identifiers which are often mixed within the method descriptions in api documents.
zhong et al.
employ nlp and ml techniques to infer resource specifications from api documents.
their approach uses machine learning to automatically classify such rules.
in contrast we attempt to parse sentences based on semantic templates and demonstrate that such an approach preforms reasonably well.
tan et al.
applied an nlp and machine learning ml based approach to test javadoc comments against implementations.
however their approach specifically focuses on null values and related exceptions thus limiting the application scope.
in contrast our approach infers generic specifications from api documents.
in particular our approach already produces fol representation of the specifications that can be used to test implementations.
furthermore the performance of the preceding ml based approaches is dependent on the quality of the training sets used for ml.
in contrast our approach is independent of such training set and thus can be easily extended to target respective problems addressed by these approaches.
viii.
c onclusion specifications described in natural language in api documents are not amenable to formal verification by existing verification tools.
in this paper we have presented a novel approach for inferring formal specifications from api documents targeted towards code contract generation.
our evaluation results show that our approach has an average of precision and recall in identifying sentences describing code contracts from over sentences.
furthermore our results also show that our approach has an average of .
accuracy in inferring specifications from sentences describing code contracts out of over sentences.