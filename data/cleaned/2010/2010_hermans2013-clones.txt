data clone detection and visualization in spreadsheets felienne hermans ben sedee martin pinzger and arie van deursen software engineering research group delft university of technology infotron netherlands f.f.j.hermans tudelft.nl b.m.w.sedee student.tudelft.nl m.pinzger tudelft.nl arie.vandeursen tudelft.nl abstract spreadsheets are widely used in industry it is estimated that end user programmers outnumber programmers by a factor .
however spreadsheets are error prone numerous companies have lost money because of spreadsheet errors.
one of the causes for spreadsheet problems is the prevalence of copypasting.
in this paper we study this cloning in spreadsheets.
based on existing text based clone detection algorithms we have developed an algorithm to detect data clones in spreadsheets formulas whose values are copied as plain text in a different location.
to evaluate the usefulness of the proposed approach we conducted two evaluations.
a quantitative evaluation in which we analyzed the euses corpus and a qualitative evaluation consisting of two case studies.
the results of the evaluation clearly indicate that data clones are common data clones pose threats to spreadsheet quality and our approach supports users in finding and resolving data clones.
index terms spreadsheets clone detection spreadsheet smells code smells i. i ntroduction spreadsheets are heavily used within companies in many domains ranging from financial to medical and from educational to logistics.
it is estimated that of desktops have excel installed and that the number of spreadsheet programmers is bigger than that of software programmers .
because of their widespread use they have been the topic of research since the nineties .
however most papers focus on analyzing and testing the formulas in a spreadsheet.
the impact of data on spreadsheet calculations has been somewhat overshadowed by this interest in formulas.
however problems with data can pose threats to a spreadsheet s integrity too.
a paper by ballou et al.
phrases the problem as follows ...errors in the operational data can influence the determination of the most appropriate forecasting model and the manager is unlikely however to study the implications of errors in the data that are being projected.
clearly such errors have an impact but it is not necessarily obvious which are potentially serious and which less .
although this paper is years old the problem statement is still very valid.
in transalta lost us million because of a copy paste error in a spreadsheet1.
more recently the federal reserve made a copy paste error in their consumer credit statement which although they did not make an official statement about the could have led to a difference of us billion2.
these stories although anecdotal underline the fact that copy paste errors in spreadsheets can greatly impact spreadsheet quality.
in this paper we focus on the occurrence of copy pasting in spreadsheets by analyzing how the detection of data clones can help spreadsheet users in finding errors and improving the quality of their calculations.
to that end we study related work in the field of clone detection in source code and come up with an approach to detect data clones in spreadsheets.
in addition to exact clones we also detect near miss clones those where minor to extensive modifications have been made to the copied fragments .
our approach is based on existing text based clone detection techniques we use cell values as fingerprints and remove values that do not occur as formula and plain text.
subsequently we group values that occur in multiple places into clone clusters to detect groups of cells that are possibly copied.
detected clones are visualized in two ways.
firstly we generate a dataflow diagram that indicates how data is cloned between two worksheets by drawing an arrow between boxes that represent those worksheets.
this way users can see how data is copied through worksheets and files.
secondly we add pop up boxes within the spreadsheet to show where data is copied and in the case of near miss clones what cells differ.
this approach is subsequently validated both quantitatively and qualitatively.
firstly we analyze the euses corpus to calculate the precision and performance of our algorithm and to understand how often clones occur.
secondly we perform two case studies one with a large budget spreadsheet from our own university and a second one for a large dutch nonprofit organization for which we analyzed business critical spreadsheets.
from these three evaluations we conclude that data clones in spreadsheets are common data clones in spreadsheets often indicate problems and weaknesses in spreadsheets and our algorithm is capable of detecting data clones quickly with precision and supports spreadsheet users in finding errors and possibilities for improving a spreadsheet.
c ieee icse san francisco ca usa292ii.
r elated work as stated in the introduction ballou et al.
described the problem of data quality in spreadsheets.
more recently o beirne states that ...much present use of spreadsheets is as data manipulation and reporting tools used to bypass the controls around it development.
and that this ad hoc integration transformation or simple cobbling together is done by the user to get what they need when they need it.
this gives rise to many extracted copies of corporate data as imports or query links in spreadsheet files.
these personal data stores are often referred to as data shadows or silos or spreadmarts giving rise to multiple versions of the truth .
he furthermore cites evidence that errors in the transfer of data from the field officer forms through to the defra spreadsheet equating to an error rate of percent over the year.
clone detection in source code has been researched extensively and resulted in numerous clone detection techniques and tools.
bruntink et al.
give the following overview text based techniques perform little or no transformation to the raw source code before attempting to detect identical or similar sequences of lines of code.
typically white space and comments are ignored .
token based techniques apply a lexical analysis tokenization to the source code and subsequently use the tokens as a basis for clone detection .
ast based techniques use parsers to obtain a syntactical representation of the source code typically an abstract syntax tree ast .
the clone detection algorithms then search for similar subtrees in this ast .
pdg based approaches go one step further in obtaining a source code representation of high abstraction.
program dependence graphs pdgs contain information of a semantical nature such as control and data flow of the program.
kommondoor and horwitz look for similar subgraphs in pdgs in order to detect similar code.
krinke first augments a pdg with additional details on expressions and dependencies and similarly applies an algorithm to look for similar subgraphs .
other related efforts are roy who created nicad a parser based and language specific tool that detects both exact and near miss clones with high precision and recall.
roy and cordy compared several open source systems and study among other properties the occurrence of nearmiss clones versus exact clones.
they detected significantly higher numbers of near miss clones than exact clones in the systems under evaluation.
for more information on existing code clone detection techniques and tools we refer the reader to the comprehensive survey by roy et al.
.
our approach is text based and is most similar to that of johnson where we use cell values as fingerprints.
recently there have been other efforts to apply clone detection to artifacts other than source code alalfi et al.
have successfully applied clone detection to simulink models.
for this purpose they adapted nicad and were able to efficientlyfind exact renamed and near miss clones in simulink models.
to the best of our knowledge no approach to detect data clones in spreadsheets exists.
most related are the efforst of burnett et al.
that also compute similarity between cells albeit in a quite different way and for the purpose of supporting the testing of spreadsheets.
also relevant is the work of gold et al.
that describe an approach to detect clones in dataflow languages .
finally there is our own work on spreadsheet analysis.
previously we have worked on an algorithm to visualize spreadsheets as dataflow diagrams and subsequently on detecting inter worksheet smells in those diagrams .
recently we have also worked on detecting smells in spreadsheet formulas .
this paper is a continuation of our research on smells in spreadsheets however we shift our focus to detecting and visualizing clones in spreadsheet data.
a tweetsized paper on clones in spreadsheets was recently accepted in tiny transactions on computer science .
iii.
m otivation in our work with spreadsheet users we often see that they copy and paste data from one spreadsheet to the other from to worksheet to the other and even within worksheets.
when data is copy pasted or cloned the spreadsheet might become more prone to errors similar to the effect clones have on a software system.
research in the field of source code analysis has analyzed the negative effect of clones on quality and maintenance.
mayrand et al.
showed that duplicated code fragments can increase maintenance effort.
furthermore a study by jurgens et al.
that analyzes industrial code shows that inconsistent changes to code duplicates are frequent and lead to severe unexpected behavior .
however not all clones are harmful kapser en godfrey show that clones can also have a positive impact on maintainability.
strictly copy pasting data in spreadsheets is not necessary most spreadsheet systems have a feature where data can be linked from one worksheet to another and even from one file to another.
in excel this can be done by either typing the location of the file in a formula followed by the name of the worksheet and the cell s or by opening both worksheets or spreadsheets and creating the link by clicking just as one would do with any formula.
so why would spreadsheet users resort to copy pasting data from one spreadsheet file to the other if most spreadsheet systems have a better way to do this?
in our experience this practice can have several reasons.
firstly sometimes users are not aware of a way to link spreadsheets they do not know how to use the link formulas.
secondly users are often unaware of the risks of copy pasting data and it seems the easiest way.
we do not aim at changing the spreadsheet users s behavior since that would most likely involve changing the process around a spreadsheet and that would be hard to implement in a company.
we rather follow an approach that allows users to proceed as they normally would but mitigate the risks by detecting and visualizing the copy paste relationships.
this293fig.
.
cells b10 and d25 form a clone.
since all their non empty neighboring cells are also clones we detect two clone clusters in this example.
enables users to take the appropriate measures in a similarly pragmatic way.
therefore the aim of this paper is to both understand the impact of copy pasting and to develop a strategy to automatically detect data clones in spreadsheets .
we refine this goal into three research questions.
r1 how often do data clones occur in spreadsheets?
r2 what is the impact of data clones on spreadsheet quality?
r3 does our approach to detect and visualize data clones in spreadsheets support users in finding and understanding data clones?
iv.
d ata clones the type of clones we are interested in are formula results that are copied as data for other parts of the spreadsheet.
this type of copying is easy in excel with paste special a user can copy values only.
we hypothesize that this type of cloning is risky when formulas or their input is updated and their values change this results in an extra maintenance task updating the copies of the formulas too.
if this is forgotten errors could occur.
we therefore look for tuples of a formula cell and a constant cell a cell with a fixed value in it that contain the same value.
we call such a tuple of cells a clone and corresponds to what is called a clone pair in the clone detection literature.
it can of course happen by coincidence that a formula and a cell contain the same value.
however if a group of neighboring cells are all copies or are all copied we are probably dealing with data that has been copied by the user.
we call such a group a clone cluster .
in more detail a clone cluster consists of cells that are all either formula cells or constant cells and all of them are contained in a clone.
we call two clone clusters matching if they contain the same values.
figure shows an example of a clone in the small green rectangle and two matching clone clusters in the gray rectangles.finally we distinguish between clones clusters of which all values match and near miss clone clusters which contain cloned cells but also cells that differ from each other.
nearmiss clone clusters can occur when by a user updates a copied cell but not does not update the original cell.
v. d ata clone detection in this section we describe the algorithm with which we detect clone clusters.
this algorithm consists of steps as shown in the overview in figure .
a. algorithm in the first step cell classification we divide the cells into data cells formula cells and empty cells.
for data cells we only consider cells containing a number.
although strings can be the result of a formula such as string concatenation or a lookup function we do not take them into consideration since strings are usually used for labels and descriptions in spreadsheets.
in figure formula cells are colored pink and data cells containing a number are colored green.
note that this classification differs slightly from the cell classification algorithms we have used in previous papers .
in our current version all cells containing a number are considered data cells and not only cells that are used as input for formulas.
since we are looking for clones the data cells do not necessarily have to be used in calculations.
in the second step lookup creation a lookup table of all cells is created with the cell value as key and a list of locations as the value.
shown in figure the value .
occurs only in eff4!b28 and .
occurs in problem data!b10 and eff4!d25.
this step is similar to the creation of fingerprints in johnson s clone detection approach .
the third step pruning removes all values from the lookup table that do not occur both in a formula and a constant cell since these cells can never be part of a clone conform our definition.
in the example shown in figure .
is removed since it only occurs in a formula and not in a constant cell.
in the subsequent fourth step called cluster finding the algorithm looks for clusters of neighboring cells that are all contained in a clone and that are all either formula cells or constant cells.
the clusters are found by starting with a cell that is still contained in a value of the lookup table.
in figure we start with cell problem data!b10 that contains .
.
subsequently this cell s neighbors are inspected.
if these neighbors are contained in the lookup table too the cluster is expanded and their neighbors are inspected.
the fourth step of the algorithm results in a list of formula clusters and a list of constant clusters.
in the fifth and final step cluster matching each formula cluster is matched with each constant cluster.
for two clusters to match they have to contain the same values i.e.
all values in one cluster also have to occur in the second cluster.
if one cluster is bigger than the other all values of the smaller cluster have to be found in the second cluster.
furthermore there may not be a formula link between the formula cells and the cloned294fig.
.
overview of the approach consisting of the five different steps cell classification lookup creation pruning cluster finding and cluster matching.value cells since we do not consider a link i.e.
sheet2!b1 to be a clone.
in figure the two gray clusters match since all values of the left cluster match with values on the right.
b. parameters the algorithm takes four parameters as input stepsize is used in the fourth step of the algorithm and indicates the search radius in terms of numbers of cells.
setting it to means we are only looking for direct neighbors with step size a gap of cells is allowed in a cluster.
matchpercentage is used in the final step when clusters are matched.
this percentage indicates what percentage of the cells has to match.
setting it to means the values have to match exactly lower percentages allow for the detection of near miss clones.
minimalclustersize sets the minimal number of cells that a cluster has to consist of.
very small clusters might not be very interesting hence we allow for a minimal threshold.
minimaldifferentvalues represents the minimal number of different values that have to occur in a clone cluster.
similar to small clusters those clusters consisting of a few different values will be of less interest.
furthermore a user of the algorithm can indicate whether clones are found within worksheets between worksheets between spreadsheets or a combination of those.
vi.
c lone visualization we visualize the detected clones in two ways.
firstly we generate a dataflow diagram that shows the relationship between worksheets that contains clones.
secondly we add a pop up to both parts of a clone indicating the source and the copied side of a clone.
the two visualizations serve a different purpose.
the dataflow diagram is aimed at understanding the relationship between worksheets and show how data is copied between worksheets in a spreadsheet or between multiple spreadsheets.
the pop ups within the spreadsheet on the other hand are meant for support when maintaining a spreadsheet.
whether it is updating the copied side of a clone or refactoring the copy into a link the pop ups support the spreadsheet user in selecting the right cells.
a. dataflow diagrams in previous work we have developed a tool to generate a dataflow diagram from a spreadsheet to represent dependencies between worksheets.
in this visualization worksheets are visualized as rectangles while arrows are used to indicate a formula dependency between two worksheets.
we consider the copying of data from one worksheet to another as a dependency between worksheets and hence we decided to show this dependency in our original dataflow diagrams too.
we show data clone dependencies with a dashed arrow to show the difference with formula dependencies which are shown with solid arrows.
figure shows the dataflow diagram corresponding to the spreadsheet hw4a.xls shown in figure .
in this spreadsheet295fig.
.
screenshot of the clone detection dataflow diagram corresponding to our running example hw4a.xls data is copied from formulas in the worksheet eff4 to the worksheet problem data this is shown in the diagram with a dashed arrow.
b. pop ups as described above we add pop ups to the spreadsheets to both the source and the copied side of the clone.
this warns the user that data has been copied so he can update the copy in case of a change to the formulas.
furthermore provides an easy way for the user to improve the design of the spreadsheet by changing the copy paste relationship into a link.
by creating a link the dependencies are made explicit and future changes will automatically be propagated.
figure shows an example of a pop up indicating a detected clone cluster.
on the formula side we show where the data is copied and on the data side we indicate the source.
vii.
i mplementation our current approach for the detection of data clones in spreadsheets is implemented into our existing spreadsheet analysis tool breviz .
breviz is implemented in c .
using visual studio .
it utilizes the gembox component to read excel files.3breviz reads an excel file and executes the above described clone detection algorithm either within a spreadsheet or among multiple files and subsequently generates the dataflow diagram and a copy of the spreadsheet with pop ups.
breviz including the data clone analysis is available as aservice by uploading a spreadsheet to infotron s website.
fig.
.
screenshot of the clone detection pop up showing the copy paste dependency for our running example hw4a.xls viii.
e valuation overview to evaluate our approach we performed both a quantitative and a qualitative analysis.
first we analyzed a subset of the euses corpus to determine how well our algorithm performs and to learn how often data clones exist in this corpus.
the corpus consists of more than spreadsheets from different domains collected from practice.
secondly we studied two different real life cases.
the first case study was conducted at the south dutch foodbank where employees keep track of all logistics using spreadsheets.
for the second case study we evaluated a spreadsheet used by our university to calculate the budget for a large e25 million research proposal.
with the qualitative analyses we aim to determine whether detected data clones actually pose a threat to spreadsheet quality.
ix.
q uantitative evaluation a. goal the aim of the first evaluation is to answer research question how often do data clones occur in spreadsheets?
and to preliminarily evaluate the performance of our algorithm both in terms of execution time as in terms of the precision of the algorithm.
b. background in this evaluation we used spreadsheets from the euses corpus .
this corpus contains real life spreadsheets from different domains ranging from educational to financial and from inventory to biology.
it was created in and has since then been used by several researchers to evaluate spreadsheet algorithms among which and .
of the spreadsheets in the corpus spreadsheets contain formulas.296c.
setup to reach our goal we ran our data clone detection algorithm on those spreadsheets for different values of the minimalclustersize and minimaldifferentvalues parameter.
since we do not have a validated benchmark we focus on matching exact clones.
evaluating the correctness of near miss clones without the owners of the spreadsheets would leave too much room for speculation.
hence we set matchpercentage to for the quantitative study.
in the qualitative studies we will take near miss clones into consideration.
furthermore we do not search for clones between the files of the euses corpus.
since the spreadsheets are unrelated matches between spreadsheets would always be false positives.
for each detected clone we manually determine whether this is a real clone or a false positive.
we do this by inspecting clones and determining whether the detected clone clusters indeed share the same data values one of the detected clone clusters consists of formulas and the other of constant cells and headers of the found clones match to decide whether the clones indeed concern the same conceptual data.
this way we calculate the precision of our approach.
we calculate this precision as the percentage of spreadsheets in which we verified a clone divided by the total number of spreadsheets in which a clone is detected by the algorithm rather than measuring it as the number of verified clones divided by the number of detected clones.
we do this because we found that some spreadsheets contain as many as clones all of which are very similar and this could skew the results.
since we do not know what spreadsheets in the corpus contain clones we cannot not analyze the recall of our algorithm at this point.
it would be both time consuming and speculative to inspect all spreadsheets in the corpus by hand to check whether they contain data clones.
we plan to analyze recall in a future study on a smaller set of spreadsheets of which we can contact the creators.
the results of our analysis are all available online in the figshare corpus5 to enable other researchers to replicate our results.
d. findings precision using minimalclustersize and minimaldifferentvalues which we consider the lowest meaningful values our algorithm detects spreadsheet files in the euses corpus that contain clones.
manual inspection showed that of these detected files contain verified clones.
this is highlighted in table ii.
files out of detected files with clones leads to a precision of .
as highlighted in table i. in this table one can find the precision for different values of minimalclustersize and minimaldifferentvalues.
combinations where minimaldifferentvalues is bigger than minimalclustersize are not allowed since there cannot be more different values in a clone cluster than cells.
illustrated by table i the precision rises for higher values of the two parameters especially the parameter minimaldifferentvalues is of influence as we suspected.
highest precision .
is obtained with both parameters set to this value is also highlighted in table i. in that case we still detect clone files which amounts to of all spreadsheets that contain verified clones in the euses test set highlighted in table ii .
false positives the biggest category of false positives is a group of data that happen to occur at multiple places in a spreadsheet.
for instance in a spreadsheet used for grades we detect several groups of the numbers to .
if some are calculations and others are input data this is detected as a clone.
especially for low values of minimalclustersize and minimaldifferentvalues both below this occurs frequently since chances that small groups of values are found in multiple places are higher.
a second category of false positives is a clone that is actually a header spreadsheet users use formulas to describe their data such as a department code or a year.
if in one case they use a formula and in another case they use a constant value this is detected as a clone.
another type of false positives are clones consisting of array formulas that have the same value as other formulas in the worksheet.
gembox the third party library we use to read spreadsheets is not able to recognize array formulas so they are read as being values.
performance running the clone detection algorithm over the spreadsheet files in the euses corpus which contain formulas total took hours minutes and seconds seconds in total .
this means analyzing one file takes an average of .
seconds.
clone occurrence in total there are spreadsheets in the euses corpus that contain formulas which means around of all spreadsheets with formulas contain verified clones.
although not directly comparable papers on clone analysis on source code estimate that to of lines of code are duplicated.
for instance baker reported that around of large code bases can be clones.
lague et al.
found that when considering function clones only between .
.
of code is cloned.
baxter et al.
have reported .
cloning and mayrand et al.
have estimated that industrial source code contains between and duplication.
observations while we cannot yet conclude something about the impact of data clones on spreadsheet quality we noted several interesting similarities in this evaluation.
firstly we saw that a common pattern for cloning is the use in overviews and reports.
in this scenario spreadsheet users use one worksheet to calculate values and copy them to a second worksheet to create a summary a graph or a report sheet.
since many of these spreadsheets did contain links between worksheets we do not think this use is due to the fact that the user did not know how to create links.
secondly we saw that copies are used to sort.
in this scenario a whole column is copied sometimes directly next to the column with values but the copy is sorted.
this use might be due the way sorting in combination with links is297table i results of the euses evaluation showing the percentage of spreadsheets containing a clone minimal different values minimal size .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
table ii the number of spreadsheets in euses containing a data clone for varying values of minimal different values and minimal size minimal different values minimal size implemented in excel.
when one sorts a column that has links the formulas get sorted too.
users might prefer to make a copy to keep their formulas intact.
finally an unexpected observation was that in some cases the format of the cells that were clones did not match.
for instance the original formulas were typed currency while the copied cells were typed as a percentage.
even without knowing the context of this spreadsheet we can conclude that one of the cell formats must be wrong.
this practice is error prone especially in the case of dates.
when a date is typed as a number excel will show a the number of days this day is removed from january since excel uses the date system.
this way a user can easily overlook the fact that this value represents a date.
in future work we plan to work on the detection of these mismatching clones.
x. t hecase studies after we performed the quantitative evaluation and we were convinced of both the applicability of our approach and the frequency with which clones occur in practice we conducted two case studies to investigate the implications of data clones in spreadsheets.
a. goal the goal of the two case studies is to answer research questions and to learn more about the impact of data clones and to evaluate our data clone detection and visualization approach.
b. setup to reach this goal we have analyzed real life spreadsheets in both case studies we ran the data clone detection algorithmand subsequently we presented the results to the spreadsheet owners.
next we went over all detected clones with them and asked them the following questions is this a real clone in other words did you copy this data?
did this clone lead to errors or problems?
could this clone be replaced by a formula link?
furthermore we asked them the following questions about clones and about our approach do you know why no direct links were used initially?
how did the pop ups help you in understanding the found data clones?
how did the dataflow diagrams help you in understanding the found data clones?
c. background the following describes the background of the two case studies.
foodbank a foodbank is a non profit organization that distributes food to those who have difficulty purchasing it.
we ran our case study at the distribution center of the foodbank that supplies local foodbanks.
in the distribution center processed an average of .
kilograms of food per month.
to keep track of this process they use a set of spreadsheets.
the figures of incoming food from sponsor and food sent out to local foodbanks should balance since no food is supposed to remain in the distribution center.
in january the distribution center of the foodbank approached us and asked whether we could help them improve their spreadsheet administration since they observed that the298total result did not balance and food remained in the center or went missing.
initially we did not know what caused their problems but when we learned about the copy pasting practice that was used we suspected that clone detection might help to locate the errors.
we asked the foodbank whether they would be interested in participating in a study of a new feature we were developing with which they agreed.
subsequently we received spreadsheet files from the foodbank to check whether clones might be the source of problems.
one of those spreadsheets was the distribution list while the other were lists of a specific region.
delft university in april of delft university of technology participated in a grant proposal for which a budget spreadsheet had to be created.
one of the authors of this paper was involved in this proposal and got this spreadsheet from a financial employee of the university.
this particular spreadsheet calculates among other things the salary cost of different types of employees.
these salaries are raised every year because of inflation and the creator of this spreadsheet calculated the salaries once and copied them to different places in the spreadsheet.
the author involved in this proposal noticed this duplication and asked this employee whether he would want to participate in a study on cloning in spreadsheets and this employee agreed.
d. findings in this subsection we describe the results of both case studies.
foodbank in the first study we searched for data clones in the test set of the foodbank by running the prototype tool over the spreadsheets.
we used parameters for minimalclustersize and minimaldifferentvalues since they were the optimal choice in the quantitative analysis.
furthermore we set matchingpercentage to and stepsize to to enable the detection of near miss clones.
running the algorithm took hours minutes and seconds which amounts to minutes per file.
performance was worse than in the euses case since in this analysis all clones of all files had to be compared with each other since we were searching for clones between files too.
with these settings we detected clones of which were near miss clones in other words they had a matching percentage of less than .
furthermore in this case we only searched for clones between spreadsheets since we knew that there would only be clones between files.
we discussed the found clones one by one with three employees of the foodbank and checked whether the found clones were actual clones.
only one of the found clones was identified as a false positive in that case by coincidence two files contained similar values.
subsequently we studied the near miss clones in more detail were they really errors that had been made in copypasting?
we found that all cases were wrong in the sense that the values should match.
the employee that we discussed the results with stated these should always match i don tunderstand why they do not.
however in many cases the updates made to the copies were the right values but in of the detected near miss clones were actual errors that the employees were not aware of before our analysis.
in the other cases the copies were not mistaken.
for instance in some cases only half of the column was copied because for the other items the amounts from the previous month remained in the distribution center.
while checking the near miss clones we also found that one of the exact clones was actually an error here the data had been copied into the wrong column.
the foodbank employees stated that all found clones could in theory be replaced by direct links.
no direct links were used initially since the employee who created the spreadsheets was not very proficient in spreadsheets at that time.
she started with a few spreadsheets and copying the values would not be much of a problem.
when the collection of spreadsheets got bigger it became increasingly more difficult to make the change.
later on another employee was put in charge of handling the spreadsheets.
she stated since i did not build all the sheets i am always a bit afraid to adapt formulas.
since i can see the links in the pop ups that you created i feel more safe since i know it will do the right things.
this sentiment is shared even by the original creator of the spreadsheets saying the problem with managing multiple sheets is that you never know if changing one cell will mess up other sheets or files.
especially for the current maintainer of the spreadsheets seeing files that were not linked was insightful.
i assumed this region was already copied into the total sheet but in the diagram i see it is not.
i should fix that right away.
after the employees fixed the clones that we found the overall results balanced as they should meaning less food is wasted on a monthly basis which we consider a very good result and strong evidence that data clones can indeed be the cause of errors.
delft university in the case study for the delft university we studied the budget spreadsheet consisting of worksheets.
we again used minimalclustersize and minimaldifferentvalues and set the matchingpercentage to and stepsize to .
in this case study we searched for clones between worksheets since there was just one spreadsheet.
running the algorithm took seconds.
we found exact clones which all turned out to be real clones i.e.
they were copied by the spreadsheet creator.
when we asked him why he used the clones instead of links he stated that the spreadsheet was a draft version and that it seemed easier to simply copy the values.
although these clones did not lead to problems in this case the spreadsheet owner did state that if he had to share the spreadsheet with others he thought he should replace the clones with links.
he stated that our analysis would be very useful in improving the spreadsheet and removing the clones this scan is very useful.
you can just copy paste and the system indicates where you should make links .
in this case study the visualization was interesting since there were two worksheets that were both connected by a solid arrow indicating formula dependencies and a dashed arrow which shows a clone dependency.
we consider this as299extra risky because the spreadsheet s user might think all values are linked upon seeing one of the formula dependencies.
xi.
t he research questions revisited in this section we revisit the research questions.
r1 how often do data clones occur in spreadsheets?
we learned from the both euses case and the case studies that clones occur often in spreadsheets.
around of all spreadsheets in the euses corpus contain clones.
r2 what is the impact of data clones on spreadsheet quality?
from the two case studies we learned that clones can have two different types of risks.
we learned that clones matching mainly impact the users perspective of spreadsheets i did not know these values were copied from that source while near miss clones really causes trouble this value should have been updated months ago .
r3 does our approach to detect and visualize data clones in spreadsheets support users in finding and understanding data clones?
in both studies we saw that employees were not always aware of what values were copied from what sheets to what others.
even creators of the spreadsheets did not know all relations by heart.
the dataflow visualizations aided users in quickly getting an overview of the otherwise very hidden copy dependencies the system indicates where you should make links .
xii.
d iscussion our current approach to finding clones helps spreadsheet users to understand how data is copied throughout worksheets and spreadsheets and furthermore supports them in improving erroneous relations.
in this section we discuss a variety of issues that affect the applicability and suitability of the proposed approach.
a. relative settings for parameters in the current evaluations we have used fixed settings for the parameters we set minimaldifferentvalues and minimalclustersize both to irrespective of the spreadsheet.
however it could improve performance of the algorithm if these parameters were calibrated using properties of the spreadsheets.
for instance in a spreadsheet with only rows no clones will ever be found.
although the evaluations showed that using fixed settings leads to useful results taking spreadsheet properties into account might improve the algorithm even further.
b. headers in previous work we have worked on the extraction of meta data from spreadsheets .
other authors have worked on this as well .
we could use extracted header information such as column or row names to gain more confidence in detected clones.
if clones are found below column headers with the same name chances are bigger that clones are are real clones and concern the same conceptual data.c.
copied data in addition to copying the results of formulas a spreadsheet user can also copy data to different places of the spreadsheet.
this is a different type of cloning in spreadsheets that we have not yet considered for this paper.
we hypothesize that copypasting of data might also be error prone however this calls for more research.
furthermore there is be the challenge of detecting the origin of the clone similar to origin analysis in source code .
we see this as an interesting avenue for future research.
d. clone genealogy the current approach analyzes cloning as it occurs in a spreadsheet at a given point in time.
however it would also be very interesting to understand how clones are created and adapted.
when spreadsheets are be placed under version control such as provided by microsoft s sharepoint for example it will be possible to also track the history of a set of clones similar to clone genealogy work in source code analysis .
e. spreadsheet maintenance support we learned from the case study at the foodbank that when spreadsheets become larger and more complex their users become more anxious to make structural changes.
although this does not relate to cloning directly updating a clone into a formula link is one of those changes that users fear might mess up the entire sheet.
this means that spreadsheets need better support for previewing a change such as some refactoring tools offer or the option to calculate what cells will be affected by a certain change.
f .
threats to validity a treat to the internal validity of our quantitative evaluation is the fact that we validated the precision of the algorithm manually.
we have however described our approach and made our results publicly available so our results can be replicated.
a threat to the external validity of our quantitative evaluation concerns the representativeness of the euses corpus.
however the euses corpus is a large set that is collected from practice and has been used for numerous spreadsheet papers.
the external validity of the qualitative evaluation might suffer from this threat however these spreadsheets too are collected from practice and available online to enable other researchers to replicate our results.
xiii.
c oncluding remarks the goal of this paper is to investigate the risks that data clones pose to spreadsheets.
to that end we have defined data clones and described a way to detect and visualize them.
we have subsequently evaluated data clones in two ways with a quantitative evaluation on the euses corpus and two real life case studies in which we found that data clones are common and can lead to real errors.
the key contributions of this paper are as follows the definition of data clones in spreadsheets section iv .
an approach for the automatic detection section v and visualization section vi .
an implementation of that approach into our existing spreadsheet analysis toolkit breviz section vii .
a quantitative evaluation of the proposed clone detection algorithm on the euses corpus section x .
a real life evaluation with spreadsheet from a dutch non profit organization and from academia section ix .
the results of our evaluations show that around of spreadsheets contain data clones and that these clones lead to actual errors such as in the case of the foodbank.
the current research gives rise to several directions for future work.
firstly the algorithm could be improved to get a better precision.
also in a new study we will analyze the recall of the algorithm and on detecting clone that do not match in their number format since these might be even more errorprone than the data clones we detect currently.
furthermore the case study learned us that impact analysis of changes in spreadsheets could help to increase a spreadsheet user s confidence either before the change or directly after.
this is a very interesting avenue for further research.
finally taking the meta data into account might strengthen the clone detection algorithm.