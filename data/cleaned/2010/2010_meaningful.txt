specifying and detecting meaningful changes in programs yijun yu thein than tun and bashar nuseibeh the open university milton keynes uk lero irish software engineering research centre limerick ireland abstract software developers are often interested in particular changes in programs that are relevant to their current tasks not all changes to evolving software are equally important.
however most existing differencing tools such as diff notify developers of more changes than they wish to see.
in this paper we propose a technique to specify and automatically detect only those changes in programs deemed meaningful or relevant to a particular development task.
using four elementary annotations on the grammar of any programming language namely ignore order prefer andscope developers can specify with limited effort the type of change they wish to detect.
our algorithms use these annotations to transform the input programs into a normalised form and to remove clones across different normalised programs in order to detect non trivial and relevant differences.
we evaluate our tool on a benchmark of programs to demonstrate its improved precision compared to other differencing approaches.
i. i ntroduction nothing endures but change.
heraclitus c. bc bc this philosophy is true in many software development projects.
however not all changes are equally relevant to developers engaged in different development tasks.
for example changing the indentation of statements in a java program does not necessarily alter its execution semantics.
nonetheless most revision control systems typically using text based differencing tools such as the diff utility in unix do not discard changes to the indentation of such programs.
although indentation is not meaningful to the execution semantics of java programs it can be very important for the execution of python programs.
furthermore for those who are concerned with pretty prints of java programs indentation is important.
another example is api evolution users of object oriented programming libraries are encouraged to use the api instead of its implementation to adhere to the information hiding principle .
as a result some developers may wish to identify only those changes made to the api whilst others may want to determine changes in the api implementation only.
a change considered meaningful for one purpose may be irrelevant for another.
for a given purpose how can one specify the types of changes that are relevant to a specific development task?
how can such a specification be used for automatic detection?
most change detection tools are effective either at reporting all changes through general purpose differencing algorithmson programs represented as line separated text and structured models or at finding out certain or all changes that are specific to one particular language such as uml class diagrams dependency graphs or verilog specifications .
few techniques aim to provide a generic solution that can also be customised to the specific language and the specific needs of the developers.
in this paper we propose a new way to specify meaningful changes as the composition of elementary changes that are defined on a normalising transformation of source programs.
two programs that are not different due to orderings abstractions and preferences are normalised into the same program using three basic normalising transformations order ignore andprefer respectively.
we show that such normalisations can be specified as simple annotations on the original production rules while specific needs of further normalisation can be accommodated by user defined functions.
each type of elementary normalisation corresponds to an elementary type of transformation to a term in the production rules of the source language.
once such annotations are specified a fully automated meta transformation can turn them into a composed transformation that operates directly on the source programs separating meaningful changes from the irrelevant ones.
the meta transformation is written as a generic modification to the meta grammar of the txltransformation system that is the grammar of all txl grammars.
therefore it is applicable to any source language specifiable by txl which currently supports several general purpose programming languages such as c java c and python as well as several modelling languages such as xml xmi gxl.
an evaluation of our meaningful change tool hereafter mct on the cvs repositories of two medium sized software projects and one small hardware project shows that i few annotations are needed to specify typical meaningful changes such as changes made to the api and ii the tool is scalable.
the remainder of the paper is organised as follows section ii introduces a running example illustrating the need for detecting meaningful change.
section iii explains our approach to generate from meta grammar specifications those normalisation transformations needed to detect meaningful changes.
section iv presents the results of a number of experiments in using the tool and compares the performance with existing differencing tools.
section v compares existing approaches with ours highlighting some of our limitations.
section vi concludes the paper.fig.
.
the differences found by emfcompare on the two emf models ii.
a m otivating example the essence of meaningful change can be illustrated using a simple java program in listing .
after some changes the execution semantics in listing remain the same.
the unix diff utility reports these changes ignoring white spaces as one deletion and one modification shown in listing .
a more advanced algorithm ldiff reports these changes again ignoring white spaces as two insertions one deletion and two modifications shown in listing .
listing .
cat n helloworld.java 1public class helloworld 3static private string hello hello 4private static string world world 5static public void main string args system .out.println hello world !
listing .
cat n helloworld .java 1public class helloworld 3private static string world world 5static private string hello hello 6public static void main string args system .out.println hello world !
listing .
diff w helloworld.java helloworld .java 3d2 static private string hello hello 6c4 static public void main string args system .out.println hello world !
static private string hello hello public static void main string args system .out.println hello world !
listing .
ldiff.pl w o diff helloworld.java helloworld .java 3d2 static private string hello hello 4a4 static private string hello hello 5c6 static public void main string args public static void main string args 6c7 system .out.println hello world !
system .out.println hello 6a8 world !
the emfcompare tool is applied to the corresponding emf models of the two java examples parsed by the jamopp java parser reporting three changes one concerns the renamed compilation units one concerns the class helloworld for the order of the reference members and the final one concerns the method main for the order of reference annotationsandmodifiers values .
if only the differences in the execution semantics are meaningful to a programmer none of the changes identified in this example are relevant just as adding a newline or some white spaces would not change the syntax of the program swapping the keywords public andstatic in the declaration of the main method makes no semantic difference.
iii.
t hemctsystem our approach to finding meaningful change between two versions of a program has two steps shown in figure step .
specification a developer specifies annotations onto the grammar terms of programs see dotted arrows in figure step .
detection the mct tool generates a refined parsing grammar and two sets of transformations normalisations and clone removals from the specification in step and applies these transformations to a pair of two source programs reporting any meaningful change to the developer.
see solid arrows in figure .
in a typical work flow the specification step is done manually by the developer whilst the detection step is done automatically by the mctsystem to find meaningful changes of programs in revisions stored in the repository.
bootstrap txl developer grammar parser txl programs v1 v2... cvs normalisations txl clone removals txl meaningful changes v1 v2 v2 v3 ... refinedgrammarignore order preferscopeannotations ignore order prefer scope .
.
.
fig.
.
specifying and detecting meaningful changes using mcttable i basic annotations to the terms in a txl grammar transformation application scope txl annotations example ignore repeat list optional order repeat list prefer alternative scope any non terminal term fig.
.
the outline view of the eclipse ide helps programmers to select meaningful information interactively while reviewing a java class.
typically they care about the ordering e.g.
the a z button and may ignore certain details e.g.
the hide fields hide non public members hide static members buttons and express a preference e.g.
java or debug perspective .
other filtering options can be expressed by user defined dialogues.
a. specifying meaningful changes we first define a few requirements for specifying meaningful changes through the concept of normalisation transformations.
definition equivalence classes by normalisation .a program pis said to be meaningfully equivalent to program p0if and only if p0 p n p0 n p where n p is the normalisation transformation of p. in other words p0 introduces no meaningful changes to p. typically n p is a many to one transformation.
the exact meaning for meaningful equivalent in the definition is intentionally left open to the user who defines the normalisation function appropriate to the tasks at hand.
this definition only provides the general criteria for determining whether a transformation is a suitable normalisation once it is clear what is meaningfully equivalent to the users any trivial or irrelevant changes should be normalised to the same program.
after the normalisation transformation is defined the detection of the meaningful changes becomes a comparison of two normalised programs.
according to definition however a normalisation transformation can be a recursive function that does not terminate when applied.
for example adding white spaces can be regarded as a normalisation transformation but it would lead to infinite results when the transformation is applied recursively.
therefore a useful normalisation transformation needs to be terminable so that no further transformation is necessary when a fixed point is reached.
definition fixed points of terminable normalisation.
a fixed point of normalisation nis a program psuchthat n p n0 p p. a normalisation transformation terminates upon its fixed point.
the normalisation is terminable if any input program pcan converge to a fixed point ni p ni p where i 0is a finite number.
every fixed point in fp n is the representative element for a class of meaningfully equivalent programs according to the normalisation n. by this definition the identity transformation is trivially terminable.
there are non trivial terminable normalisations.
for example ordering the modifiers i.e.
private static of all class members is a terminable transformation because the number of inverse order of the modifiers is finite so is the number of class members.
the following property guarantees that a composition of any two terminable normalisation transformations is still terminable for a subset of fixed points.
property composability of terminable normalisations if two normalisations n1and n2are terminable according to definitions and then the functional composition n1 n2 p n2 n1 p pis also a terminable normalisation and fp n1 n2 fp n1 fp n2 .
for example ignoring the method bodies in all classes is a terminable normalisation composable with reordering the method modifiers.
a program with method bodies ignored may not have the modifiers sorted and vice versa.
only fewer programs with both the method bodies ignored and the modifiers ordered are the fixed points that terminate the composed normalisation transformation.
in general the more normalisation transformations are composed the fewer fixed points can be distinguished.
in order to support most programming languages at the level of the meta grammar we aim to generate normalisation transformations by composing three elementary terminable normalisations derived from the production rules of grammars ignore order and prefer .
for every term of a production rule one can check whether any one of these basic types of terminable normalisations is applicable to provide what programmers like to compare.
for example traditionally java programmers get help from an ide such as eclipse to obtain meaningful information in an outline view as shown in figure .
the abstraction presented in the outline view can be further customised by clicking at the right buttons by the programmer.
our elementary normalisation operations already cover all the most commonly used meaningful selection buttons of the eclipse ide.
definition elementary normalisations ignore order andprefer .let a production rule be n ...t i ... ... where nis a non terminal and tiis the i th term which could be either terminal or non terminal and optionally the rule could contain more than one alternative sequence pattern.
every optional denoted by ?
term can be ignored if with or without the value it makes no difference to the developer elements of a repeated denoted by term can be ordered if the ordering of the values is not important to the developer and the whole element nmatches a mandatory alternative can be preferred to another alternative denoted by if thedifference between these two alternatives are not significant to the developer.
table i gives an example of each of these elementary transformations by ignoring the members when they are private by sorting the member declarations in ascending order and by preferring the semicolon over the detailed method bodies.
these elementary normalisations can be used to preserve the conformance to the syntax of the source programming language if one does not apply ignore to mandatory terms.
since different programming languages have different semantics users may wish to preserve the semantics by avoiding certain normalisations.
for example one would not reorder the statements in normalisation to avoid breaking the execution semantics of java.
whether these syntax or semanticspreserving transformations are desirable really depends on the developer s task.
property syntax conformance.
the normalised programs generated by the three elementary transformations in table i are valid programs in the source programming language.
of course syntax conformance of the normalised programs is not an issue when the purpose of checking meaningful changes is not to obtain a compilable program.
one may choose to define the target grammar to be incompatible with the source language.
the elementary normalisations can also be further customised.
the unconditional ignored rule for an optional term ?
can be associated with a conditional check in the api extraction example one would remove a declaration if and only if it does not have public or protected modifiers.
similarly the ordered rule for repeating terms can be customised to ascending or descending orders and the ordering criteria can be associated with certain foreign keys.
b. detecting meaningful changes after each program revision is normalised the next task is to detect the non trivial changes.
a simple method is to apply an existing diff algorithm on the normalised results.
however this may not detect the exact and subtle differences smaller than one line of code.
the method we adopted is to apply clone detection in order to take advantage of knowing the meaningful structures independent of the line boundaries.
as long as the normalised entities are the same a clone detector could locate them.
on the other hand if the two entities are similar but not exactly the same a meaningful context of the difference may need to be shown.
after removing the clones across a pair of programs their differences become evident.
note that we do not check intra program clones as our purpose is not to detect clones but only to reuse existing clone detection techniques for the sake of differencing.
in principle any parametrised ast based clone detector could be used for this purpose.
to illustrate this in this paper we use the simplest exact clone detection.
not all language constructs at all levels of granularity should be considered as clones either.
for example index variables of a for loop are not apparently so meaningful to detect as aclone because it makes little sense to scope the comparison at this level of abstraction.
to be able to specify the scope of language construct that needs to be considered as clones to remove another kind of annotation is introduced to nonterminals.
property scoping the clone detection.
any optional or repeat term in the production rule can be marked as a possible scope for clone detection such that removing the inter program clones at this level does not change the conformance of the source programming language.
instances of any mandatory term in the grammar can be marked as possible clones if required whilst the target programming language may violate the syntax rules of the source programming language.
the last row of table i summarises the scoping annotation for clone removals.
c. running example specifying normalisations for the java api to illustrate the features of our method we use the example of the java grammar provided by the txl website containing lines of code.
txl is a functional programming language in which a transformation is defined by either a non recursive function or a recursive rule .
instead of using pseudo code to illustrate the algorithms in this paper some of the exact declarative rules are used in order that the work can be easily reproduced.
listing .
cat n java.annotated.grm 1include java .grm 2annotate package declaration 3annotate package declaration repeat import declaration ignored 4annotate package declaration repeat type declaration scoped ordered 5annotate class or interface body repeat class body declaration scoped ordered ignored when private 6annotate method declaration repeat modifier ordered by descending 7annotate method declaration method body preferred with ... 9function private a match b class or interface body construct m construct publicmodifiers public protected where not m 14end function 15rule descending b 16match a 17construct sa 18construct sb 19where sa 20end rule line includes the original java grammar.
the annotate rules in table i are used or composed in some of the term extensions.
here we explain the rationale behind these extensions.
the annotations scoped are appended to the terms such as package header line type declaration line class body declaration line .
these instruct a clone detector to compare these three types of entities for possible clones.
although the technique is similar to generalpurpose clone detection the purpose of the cross programclone removal is exactly the opposite those non clones are the differences to be detected.
however the ordering of elements or appearance of ignorable details can get in the way of meaningful change detections.
therefore several normalisation transformations are required to be applied before the change detection step.
since one does not care about whether a modifier is before another one or not e.g.
private static is the same as static private the ordering of the elements in the array of repeat modifier is unimportant to the java semantics.
however the default behaviour of a txl parser preserves the ordering of the modifiers in the parsing tree as they occur in the source program.
to specify the order normalisation one only needs to insert ordered at the end of the term.
furthermore if one would like to normalise the elements in descending order a user defined rule descending lines is added in listing .
this is just to illustrate how easy it is to customise the comparison function in case one would like to define a different key or ordering for the structure to be normalised.
for the sake of identifying meaningful changes in this particular case ordering these members in ascending order is the same as ordering them in descending order.
the ignore annotations ignored on the other hand will replace the optional or repeated terms with .
the terms import declaration at line and class body declaration at line are examples.
in particular the ignore annotation to class body declaration is conditional it uses a user defined function from lines to check when the term has not used the public orprotected modifiers.
as a result it will achieve the effect of extracting api methods from all members.
without specifying such user defined functions the default behaviour of ignore extension would simply ignore the term just as what the annotated term import declaration ignored does.
since such terms are unconditionally ignored it is unnecessary to compose them with the scope annotation as other siblings do.
as a result this will ignore the import statements in the api regardless so any difference in such statements will not be considered as meaningful.
finally the prefer annotations preferred are appended to the terms that have more than one alternative expansion.
the user is free to choose a sequence of literals to make a constant instance of the terms in any one of its alternative production rules.
for example when the method body at line is annotated by preferred this will lead to a transformation to turn any block into a semicolon.
d. brief implementation of the mct the meaningful change detection tool mct is implemented completely as a txl program.
the first part of the implementation is an extension to the txl s meta grammar given in the file txl.grm .
listing shows the extension to the existing typespec rule and the addition of four annotation rules orderedby ignoredwhen preferred andscoped corresponding respectively to the three elementary normalisations and the scoping rules.
listing .
cat n norm.grm 1include txl.grm the extension ofthe txl grammar 3keys ... scoped ordered by ignored when preferred with annotate 5end keys 6define typespec ... opt preferredwith 8end define 9define scoped scoped end define 10define orderedby ordered end define 11define byfunction by end define 12define ignoredwhen ignored end define 13define whenfunction when end define 14define preferred preferred with end define 15redefine statement ... end define 16define mct annotate annotate end define the second part of the implementation is a specification of the normalisation transformations.
for brevity we only discuss the extension for the order transformation shown in listing .
the transformation generates the rules for eliminating ordered annotations so that it is recognisable by txl at runtime and for producing the rules for ordering the parsed terms.
lines specify how to generate the transformation rules denoted by the variable rules on the fly by checking every definestatement in the txl grammar such as those in listings .
for each occurrence of the transformation in lines is invoked to generate a rule such as those instantiated in lines .
these rules have unique names constructed from the names of the definestatement and the term x. by the end of the main transformation the rule in lines are applied to eliminate the order annotations from the extended grammar.
listing .
cat n norm.txl 1include norm .grm 2rule typespec eliminateorderedby 3replace t 4deconstruct tm i r opt typerepeater o 5deconstruct o ordered b 6construct t1 m i r 7byt1 8end rule 9function typespec repeat byfield ds t 10import rules 11import ruleids 12replace 13deconstruct ds redefine tid type literalortype rest end define 14deconstruct t repeat i r o 15deconstruct o ordered b 16deconstruct b byf 17construct strid 18deconstruct i typeid 19construct id normalise list 20construct ruleid id 21construct s rule ruleid replace n1 n2 rest where n1 by n2 n1 rest27 end rule 28export rules rules 29export ruleids ruleids 30bys 31end function 32function ds replace ds 33replace s0 34construct t 35construct s2 typespec repeat byfield ds each t 36construct s s0 37bys 38end function 39function id to type id 40replace l 41construct t 42byl 43end function 44function main 45replace p 46export rules 47export ruleids 48construct ds 49construct s 50import rules 51import ruleids 52deconstruct p s0 53construct id ruleids 54construct pl prg 55construct pl2 id to type each ruleids 56construct l 57construct replace l 58construct main function main replace prg byreplace end function 62construct p1 s0 63byp1 64end function e. generated normalisation transformation the above generic implementation is done on the metagrammar of txl.
when it is applied to a concrete txl grammar such as the one specified in listing a concrete normalisation transformation is produced in the original syntax of txl as shown in listing .
lines are generated from the annotations from the line of listing using the user defined comparison function descending which was listed in lines in listing .
listing .
cat n java.txl 1include java .grm 2rule normalise list method declaration modifier replace n1 n2 rest repeat modifier where n1 by n2 n1 rest 9end rule 10function main replace prg by prg normalise list method declaration modifier 15end function f .
the normalised programs and relevant changes we have implemented the processor of all the four types of elementary annotations using txl which generates a few transformation rules per annotated term.
applying thecomposed normalisation transformation to the two java programs in listings and produces the normalised results that are identical as shown in listing .
both hello and world members are removed because they are not public nor protected members of the class.
the main method has the modifiers ordered in ascending order as public static whilst its method body is replaced by the preferred simplification semicolon alternative.
to display the differences of two compared programs a generated transformation is applied to remove all inter program cloned instances of the annotated terms.
this transformation only applies to those scoped annotated terms because one usually would not remove duplication of low level term such as identifiers.
listing .
mct helloworld.java helloworld .java 1public class helloworld public static void main string args 5public class helloworld public static void main string args as a result there is no longer anything left leaving the output empty as shown in listing .
listing .
mct diff helloworld.java helloworld .java iv .
e xperimental results themcttool has been applied to three benchmark evolving programs in the public domain i gmf is a model driven code generator for eclipse graph editors ii jhotdraw is a gui framework for technical and structured graphics and iii opencores uart16650 is a specification of fifo queue for hardware which was used for the study of verilog diff .
a. specifying meaningful changes on java and verilog the meaningful changes we want to detect are differences in the apis of these programs in different programming languages.
table ii lists the sizes of the meta grammar txl.grm java grammar java5.txl and the verilog grammars v.txl .
the sign before the numbers is used for counting those incremental grammars that include the original one.
the mcttool is implemented as mct.txl which consists of additional rules that transform the extended terms.
the java api normalisation tool is implemented by redefining terms using scope order ignore and prefer annotations and user defined rule in additional to the original grammar.
as a result new transformation rules are generated which also define new refined terms.
the verilog annotations include scope order and ignore which generates additional transformation rules.
on a server running redhat enterprise linux .
with a .
ghz intel xeon x5464 cpu 6mb cache 24gb memory the automated generation of these normalisation rules takes no more than .
seconds.
the programming language grammars in txl l and the generated normalisation transformation rules in txl m were then used in the remaining experiments.fig.
.
contrast the effectiveness of change detection at the file level as the percentage of reduced changed files table ii size of the fully extended grammars and time to generate the normalisation rules grammar description loc terms rules txl.grm meta grammar mct.txl implementation java5.txl l java grammar java.norm annotation java.txl m result v.txl l verilog grammar verilog2.norm annotation verilog2.txl m result table iii change of source programs with comments white spaces j w ow h i t es p a c e s comments l or after normalisations m program file loc j loc l loc m diff commit loc j loc l loc m uart16650 mct diff ldiff jhotdraw mct diff ldiff gmf mct diff ldiff b. detecting meaningful changes on three projects we accessed the history of gmfandjhotdraw by analysing all commits from their public cvs repositories whilst we were using the same set of selected revisions of uart16650 provided by duley et al .
let j stand for the original code l stand for the comment less code and m stand for the normalised code.
the java parsers obtained from the txl website are already designed to remove all the comments and white spaces in the java programs.
thus it is perhaps better to compare the normalised results m with the unparsed ones l rather than with the original code j .table iii lists the size metrics of these programs.
the metric loc is the number of accumulated lines of code of all the revisions loc is the number of accumulated lines of changes detected by the diff ldiff utilities.
all the size metrics show that uart16650 jhotdraw gmf roughly by a magnitude of .
the gmf cvs repository of accumulated lines of code has close to million lines of code.
taking out white spaces comments does help reduce the size by almost half indicating that the three opensource programs were all well commented.
the performance table iv comparing file level changes program pairs diff txl diff mct uart16650 .
.
.
jhotdraw .
.
.
gmf .
.
.
ofldiff in terms of detecting file level changes is the same as that of diff .
however ldiff generally reduces the amount of information presented to developers when changes did occur.
the absolute size of the normalised code loc m is almost times smaller than loc l and the change loc m is also much smaller than the counterparts.
as a result in all the three examples fewer file level changes are found by diff ldiff .
table iv highlights the ratio of reduction of the file level changes after diff txl diff andmctare applied where mcthas the most effective result.
the ratios are compared in figure .
the time in seconds it took for the experiment is shown in table v. t x is the time it took to generate the programs and to measure the differences using diff orldiff between pairs of consequent revisions.
for the original x j program no computation is needed for the diff ldiff measurements in generating the program.
the generation of the pretty printed x l is done by the default txl parser and generation of the normalised x m programs is done by the mctgenerated transformations.
amongst the three evolving programs diff is the fastest on average only as little as .
.
.
.
.
seconds per revision pair whilst using txl then ldiff is the slowest on average .
.
seconds per revision.
on average the normalisations and clone removals in one step mcttakes about .
.
seconds per revision.
finally table vi lists the time performance relative to the input size in seconds per million lines of code.
the columns are ordered by the last row from the slowest on the left to the fastest on the right.
we only compare the scalability of five configurations for detecting changes using a combination of tools diff ldiff txlandmct.
figure plots the data in this table.
c. threats to validity although some of our experiments were large scale we should not over generalise our findings.
the gmf projecttable v absolute time performance in seconds program tool txl mct commits t j t l t m uart16650 codegen .
.
.
diff .
.
ldiff .
.
jhotdraw codegen .
.
.
diff .
.
ldiff .
.
gmf codegen .
.
.
diff .
.
ldiff .
.
table vi scalability time relative to the input size sec mloc txl mct txl loc j ldiff ldiff diff diff .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
is model driven and an unknown portion of cvs commits attributes to the code generations thus it is less relevant to the api evolution compared to those manual changes in the jhotdraw project.
in these experiments however we did not separate generated code from the cvs repository.
the verilog normalisation applies fewer annotated transformations than that of the java api which could explain why the average time mloc performance of verilog is better than jhotdraw.
the performance of ldiff in terms of file level change detection is not better than that of diff however the quality of diff chunks in ldiff may be finer than that ofdiff .
therefore we included experiments of both to indicate how mct compares with the scalable ldiff tool.
to avoid any skewing of the running environment we took the timing measurement times and the minimal elapsed time.
however a different hardware configuration may lead to slightly different measurements.
finally we did not compare the interactive supervised diff results as some of the related .
.
.
.
.
.
.
uart16650 jhotdraw gmf txl ldiff l ldiff j mct txl diff l diff j fig.
.
contrast the scalability of the experimented command line tools work does because such supervisions require a large amount of time on the code base and truthful interpretation from thedevelopers that is intrusive to the development projects.
as a trade off our command line tool mctcould substitute the underlying diff algorithms for the interactive use cases.
v. r elated work general problem.
brunet et at define the challenges of model managements in terms of merge match diff split and slice operations and the properties that should be preserved by those operations.
their operations and properties are independent of models and modelling languages.
our normalisation steps are similar to slice operations because they are a series of transformations performed from model to model based on slicing criteria.
and the clone removal step is similar to the diffoperation that transforms two models to a set of changes.
model matching and merging are also related to our work in the sense that they merge the detected changes.
our emphasis is on ensuring the transformed programs or models remain valid according to the original language syntax so that it is easier to compare the differences with the original programs.
structural diff.
xing and stroulia propose an approach to recover uml design models such as class diagrams from java code then compare their structural changes.
the approach is specific to uml which uses similarity metrics for names and structures to determine the types of changes made.
schmidt and gloetzner describe an approach that integrates the sidiff tool to detect semantic changes on diagram structures.
it then visualises the changes on uml diagrams and simulink models.
these diagrams in principle can be specified in domain specific languages such as umlassketch1.
thus it is possible to apply our tool to detect changes on the textual models.
the main difference with our work is that our approach allows the tool user to specify selective changes to be detected.
apiwattanapong et al present a graph based algorithm for differencing api of java programs.
since their approach and the tool jdiff is geared towards java there is explicit support of java specific features such as the exception hierarchies.
their tool is therefore not as language independent as ours.
in addition we can also specify the meaningful changes to extract uml models and to isolate user specified generated not elements from model driven software development with only a few additional semantic rules in txl.
these are beyond the scope of jdiff .
beyer et al present an efficient relational calculator crocopat that can perform diff calculation on two sets of tuples very efficiently and thus has been widely used invisualisation reverse engineered facts such as call graphs or inheritance aggregation relationships.
however crocopat treats all differences in sets rather than ordered lists.
therefore it is not suitable for checking the differences among ordered structures such as statements or parameter lists.
fluri et al describe an approach to find differences on abstract syntax trees.
the criterion for measuring the com bliki umlassketch.htmlsize of differences is the length of minimal number of editing operations such as insert delete move update as well as refactoring based operations such as condition expression change method renaming parameter delete ordering change type change statement insertion parent changes etc.
most of their basic editing operations can be expressed using a composition of the four basic annotations rules used in this paper.
on the other hand the refactoring changes on semantic behaviour preserving require more advanced transformations that depends much on the specific java semantics.
our design considers that specificity with the generalisable principle so that a substantially different programming language such as verilog can also be supported.
in principle refactoring type of transformations can be supported by specifying those changes as user defined equivalence functions.
semantic diff.
several differencing tools work at the semantic level which may be complementary to ours.
jackson and ladd use dependency between input and output variables of a procedure as a way to detect certain changes.
the dependency is represented as a graph and any difference in two graphs is taken as a change to the semantics of the procedure.
there are of course changes that affect other kinds of semantics but not the dependency graph such as changes in constants.
working at the level of program grammar our tool presents all the choices for the user to decide whether a change in constant should be ignored or not.
kawaguchi et al present a static semantic diff tool called symdiff which uses the notion of partial conditional equivalence where two versions of a program are equivalent for a subset of inputs.
the tool can infer certain conditions of equivalence and therefore behavioural differences can be lazily computed.
our tool does not work at the level of program semantics.
duley et al present vdiff for differencing nonsequential position independent verilog programs.
their algorithm extracts the abstract syntax trees of the programs and matches the sub trees in the ast s whilst traversing them top down.
furthermore boolean expressions are checked using a sat solver and the results of differencing are presented as verilog specific change types.
in this work we used their datasets to demonstrate that our work can be applied to this language too.
although we do not classify the changes into types as they did we can also classify the changes according to annotated terms.
applications.
wenzel et al present a view that the evolution history of models can be traced into modelling elements and visualise the change metrics.
when large amounts of data are being processed again it is important to be able to extract the relevant information to compare with each other.
our work has shown that it is not only possible to trace the history of evolution but also possible to specify such views based on the relevance to programming tasks.
on the other hand adding some visualisation capability to our commandline tools should be possible especially since we have obtained the exact structures in the comparisons.
dagenais and robillard present a promising way to use change detection for recommendation systems especiallyfor the framework evolution.
recently kawrykow and robillard demonstrate the diffcat tool to classify both cvs and svn change sets of java programs for non essential changes such that those induced by cosmetic refactoring operations can be ignored.
diffcat aims to classify the changes as input data that might be non essential for automated techniques instead of defining for java programmers which changes are essential or meaningful.
on the other hand our approach can be used to define a suitable normalisation for each of these classified change types.
for example a local variable renaming could be normalised by renaming any local variable to the surrounding context of its declaration.
therefore it is possible to combine the two approaches further for classifying the different types of meaningful changes.
kim and notkin present the lsdiff tool to automatically identify structural changes.
similar to us there are no predefined change types in lsdiff though the abstraction oflsdiff is at the level of code element and structural dependencies.
while both lsdiff andmctshare a common goal of helping programmers to understand changes at a high level instead of focusing on identifying and summarizing systematic structural differences right now our tool focuses on programmer provided annotations on the production rules to filter out meaningless changes.
godfrey and zou introduce the notion of origin analysis for detecting structural changes made to program entities in order to find out reasons for merging and splitting of code.
with more precise changes identified on the structure it is possible to increase the chance of identifying such origins.
refactoring transformations improve program structures without introducing behavioural changes see mens and tourw e .
the four basic annotations may already express simple forms of refactorings that normalise the structures in order to remove irrelevant changes when evolving programs are compared.
to detect an advanced refactoring especially those happened to the api s see dig et al a userdefined function works on a term of appropriate scope e.g.
class declaration or method body depending on the nature of the refactoring.
implementation.
although our implementation is based ontxl the implementation of the concepts could be replaced using other generic transformation systems language engineering tools such as grammarware .
vi.
c onclusions and future work in this paper we have presented a declarative approach to specify changes in programs that are relevant to different programming tasks.
in particular we have demonstrated its use in extracting the changes at the api levels for evolving java programs and hardware specifications.
we have shown that four elementary annotations can account for all light weight syntactical normalisations by default and can be customised for more advanced semantic changes through user defined functions.
our declarative specification approach already works on several programming and domain specificlanguages.
our automated tool has been implemented on top of a generic transformation system txl and the results of detecting relevant differences in the three programs were evaluated and compared to other diff utilities such as linebased diff showing more precise detection and acceptable scalability and time performance.
the tool and results can be downloaded from the tool currently supports a substantial list of programming languages inherited from as well as several requirements modelling languages including i problem frames and argumentation .
our implementation of the clone removal is currently limited to exact clones.
we are planning to integrate a nearmiss clones detector such as nicad by roy and cordy to ignore more structural changes.
recently kim et al proposed the mecc tool to detect semantic clones i.e.
types according to roy et al by statically analysing the equivalent classes of memory footprints upon the exit of every c c procedure.
their approach adopts a specific technique to guarantee a fixed point can be reached by the normalisations implicitly defined by the checked equivalence classes.
without an explicit user defined function our approach cannot be applied to these cases.
therefore we plan to specify such normalisations explicitly.
recent work on requirements monitoring indicates that it is important to detect meaningful changes at run time.
in a generic graph based approach high level meaningful changes are expressed declaratively as change patterns .
we are investigating how to extend our metaannotation approach to generate such change patterns for detecting dynamic meaningful changes at the runtime.
acknowledgement the work is partly supported by the eu fp7 security engineering of lifelong evolvable systems securechange project the microsoft software engineering innovative foundation seif award and the sfi cset2 programme at lero.
the authors would like to thank charles b. haley and michael a. jackson for useful discussions.