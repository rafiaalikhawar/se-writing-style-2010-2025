scalable and incremental software bug detection scott mcpeak coverity inc. san francisco usa smcpeak coverity.comcharles henri gros coverity inc. san francisco usa chgros coverity.commurali krishna ramanathan indian institute of science bangalore india muralikrishna csa.iisc.ernet.in abstract an important but often neglected goal of static analysis fo r detecting bugs is the ability to show defects to the programmer quickly.
unfortunately existing static analysis tools scale very poorly or are shallow and cannot find complex interprocedural defects.
previous attempts at reducing the analysis time by adding more resources cpu memory or by splitting the analysis into multiple sub analyses based on defect detection capabilities resulted in limited negl igible improvements.
we present a technique for parallel and incremental static analysis using top down bottom up and global specification inference based around the concept of a work unit a self contained atom of analysis input that deterministica lly maps to its output.
a work unit contains both abstract and concrete syntax to analyze a supporting fragment of the class hierarchy summarized interprocedural behavior and defect reporting information factored to ensure a high lev el of reuse when analyzing successive versions incrementally.
work units are created and consumed by an analysis masterprocess that coordinates the multiple analysis passes the flow of information among them and incrementalizes the computation.
meanwhile multiple analysis worker processes use abstract interpretation to compute work unit results.
process management and interprocess communication is done by a general purpose computation distributor layer.
we have implemented our approach and our experimental resultsshowthatusingeightprocessorcores wecanperfor m complete analysis of code bases with millions of lines of code in a few hours and even faster after incremental changes to that code.
the analysis is thorough and accurate it usually reports about one crash causing defect per thousand lines o f code with a false positive rate of .
the author performed the work as an employee of coverity inc. permission to make digital or hard copies of all or part of this w ork for personal or classroom use is granted without fee provided th at copies are not made or distributed for profit or commercial advantage and th at copies bear this notice and the full citation on the first page.
to cop y otherwise to republish to post on servers or to redistribute to lists re quires prior specific permission and or a fee.
esec fse august saint petersburg russia copyright acm ... .
.categories andsubjectdescriptors d. .
testing and debugging debugging aids f. .
semantics of programming languages program analysis generalterms reliability performance design keywords static analysis bug detection parallel incremental .
introduction static analysis for automated bug detection has been a well studied problem and its usefulness well documented in .
a variety of bugs are detected by these techniques including null pointer dereferences re source leaks concurrency violations and buffer overflows.
detecting these bugs before deployment is important because it is quite expensive to fix a bug found in the field.
there are also a number of dynamic analysis approaches for detecting bugs .
however many of the dynamic analysis approaches are time consuming and are critically dependent on the quality of the tests generated.
motivated by the high cost of software bugs and the difficulties of thorough testing we seek to build a static analysi s that can accurately find bugs in large code bases and successfully integrate with real world development processe s. intra procedural analysis techniques for bug detection are usually faster but cannot be used for detecting complex inter procedural defects because of high false positive ra te.
on the other hand accurately finding a compelling fraction of bugs requires interprocedural analysis in particula r bottom up propagation of behavior summaries topdown computation of calling context and global specification inference .
most industrial code bases are large typically between one and ten million lines of non blank non comment code loc .
however applying inter procedural analysis on large codebases takes too long sometimes running into weeks .
integrating static analysis with the development process requires at least two important properties.
the first is it must be fast.
the reason is that in order to be adopted into regular usage static analysis must fit into one of the development cycles and a natural fit is the nightly build cycle.
a typical nightly build and test cycle takes hours so static analysis must complete within that time window otherwise organizations would have to create a new cycle justpermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse august saint petersburg russia copyright acm ... .
554for static analysis and experience has shown that most are unlikely to do so.
moreover staticanalysisresultsquicklybecomestale.
static analysis identifies root causes not bug symptoms which is a big advantage if results are delivered quickly.
if not developers are often reluctant to make changes to code that has cooled on the basis of defect reports sometimes perceived merely as theoretical .
new code usually goes through automated tests and or a quality assurance cycle fairly soon after being checked in.
additionally in many organizations a significant component of the testing effort for a given piece of code happens implicitly as the product is exercised for other reasons.
the longer a piece of code has been deployed either internally or externally the greater the sunk testing cost.
that cost must be incurred again when the code is changed for any reason even to address a static analysis defect.
delays also increase the cost of the developer learning or re learning the relevant code.
therefore timely delivery of defect reports is an importan t requirement for those reports to be useful.
the second important property is that defect results must bedeterministic because this is critical to verifying a fix.
non determinism means defects might disappear for reasons other than being fixed even if the code is unmodified.
therefore the results of analyzing a particular code base do not depend on how the analysis was run for example how many concurrent tasks were involved or how much incrementality was involved.
we argue that determinism is necessary to build confidence in the tool if users developers see results flicker they have a hard time learning what to expect from it and may assume it is generally unreliable.
moreover unpredictability makes it very difficul t to put processes in place to manage the set of defects both when dealing with the backlog when static analysis is first deployed and handling the stream of new defects as development proceeds it is critical that defects only disappear when they are truly fixed and that they only appear when truly introduced.
otherwise it is impossible to answer the questions of how much work has been done and how much remains which are central to the management task.
additionally the code being analyzed is mostly the same between any two consequent versions of a code base.
so it is natural to do incremental analysis by reusing results effectively.
small differences in the codebase should not trigger a full analysis and only relevant parts of the code need to be reanalyzed.
more pointedly for example the addition of whitespace at the beginning of a file should not cause all of the functions and their interprocedural dependencies to be re analyzed.
furthermore the results of an incremental analysis must also be equivalent to the results from a full analysis otherwise user confidence quickly erodes.
we address the above discussed three objectives in this paper.
we provide a design of a parallel analysis technique for interprocedural static analysis.
we define a work unit as a serializable collection of self contained analysis input data that can be analyzed independently and quickly .
the specific type of output from a work unit differs for each type of work unit but is typically a set of defects or a function summary.
the only inputs to the analysis of a work unit are the work unit itself and the analysis binary i.e.
the output is deterministic in those inputs with the exception of possible diagnostic timing information included in the output .
furthermore the output is platform independent in thatanalyzing the work unit on all platforms yields the same output the analysis times can be different .
the overall analysis is split between a single master process and a set of worker processes with workers potentially on machines other than where the master is running.
the master divides the analysis task up into work units that are sent to the workers which then return results when each work unit is complete for subsequent integration by the master.
when the computation is finished the master presents the finished results to the originating client and terminates the worker s. the design of a work unit has inherent challenges.
as it is desirable for work units to be self contained there is design pressure to keep their size small and avoid reliance on shared state which adds complexity and compromises independence.
identifying the appropriate scope of a work unit so that the overhead of communicating and processing the work units and results back and forth between processes does not exceed the benefits accrued of distributing the work across multiple processes is important.
furthermore the analysis of the work units must be deterministic underdifferentresourceconditions orondifferentplatfor ms. addressing these challenges yields a number of important benefits.
the determinism of the work unit results enables the use of incremental static analysis.
our design of the work unit ensures that only a practically feasible minimum fraction of the entire code base is analyzed.
obviously reducing the amount of code to be analyzed lessens the overall time taken for the analysis.
the design of the work unit also yields a powerful advantage of failure isolation when the analysis crashes or otherwise misbehaves all that is require d to reproduce the problem is the work unit and the appropriate analysis binary.
we have implemented our design in the coverity static analysis to analyze large codebases.
the tool takes as input abstract syntax trees and performs a combination of bottom up and top down processing to detect various types of defects including null pointer dereferences concurren cy violations resource leaks and buffer overflows.
applying our analysis on a number of large open source benchmarks mloc shows a substantial reduction in the analysis time.
our results show that the analysis time is reduced by upto a factor of five to seven on an eight core machine on many c benchmarks while still being able to detect critical defects with high precision less than false positives .
we make the following key technical contributions in this paper .
a design of a self contained analysis work unit that can be analyzed independently quickly and deterministically.
.
a design and implementation for a scalable static analysis by leveraging the design of work units to find critical defects precisely.
.
an empirical evaluation of the proposed approach displayingits scalabilityon very largecodebaseswith millions of lines of code.
the rest of the paper is organized as follows.
we discuss the design challenges for building a scalable static analysi s tool for bug detection and present the design and implementation of our approach in section .
in section we presents the results of our analysis on large codebases.
the challenges posed in scaling the analysis for object oriente d555programs is discussed in section .
we compare our work withotherapproachesis section5andconcludein section6.
.
design .
architecture the overall architecture which includes the proposed design is given in figure .
analysis frameworkinterproceduralincremental analysisprogram asts defectsworker1 worker2work units results ........units results true positivesfalse positivesworkanalysis options user interfaceparser figure system architecture.
first we provide an overview of the interprocedural analysiscomputationtoperform independentofhowitisspread across time and space.
we informally use chronological metaphors but that is just to convey data dependence.
to begin with the program source code is parsed into an abstractsyntaxtree ast forest onetreeperfunction.
in thispaper weusetheterm function forfunctions method s and initializer blocks.
once the analysis phase begins a virtual linker pass resolves named symbol