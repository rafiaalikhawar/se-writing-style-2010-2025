trademaker automated dynamic analysis of synthesized tradespaces hamid bagheri x hb2j virginia.educhong tangx ctang virginia.edukevin sullivanx sullivan virginia.edu computer science dept.xcomputer science dept.
george mason university university of virginia fairfax va usa charlottesville va usa abstract system designers today are focusing less on point solutions for complex systems and more on design spaces often with a focus on understanding tradeo s among non functional properties across such spaces.
this shift places a premium on the e cient comparative evaluation of non functional properties of designs in such spaces.
while static analysis of designs will sometimes su ce often one must rundesigns dynamically under comparable loads to determine properties and tradeo s. yet variant designs often present variant interfaces requiring that common loads be specialized to many interfaces.
the main contributions of this paper are a mathematical framework architecture and tool for speci cation driven synthesis of design spaces and common loads specialized to individual designs for dynamic tradeo analysis of non functional properties in large design spaces.
to test our approach we used it to run an experiment to test the validity of static metrics for object relational database mappings requiring design space and load synthesis for and dynamic analysis of hundreds of database designs.
categories and subject descriptors d. .
design tools and techniques general terms design experimentation performance keywords speci cation driven synthesis tradeo space orm static analysis dynamic analysis .
introduction producing systems that achieve acceptable tradeo s among non functional properties remains a major engineering problem.
to address it engineers are now focusing less on point permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
icse may june hyderabad india copyright acm ... .
.solutions and more on specifying populating and analyzing points and regions in design spaces.
the contribution of this work is an approach to speci cation driven synthesis of both design spaces and common loads for fair comparative dynamic analysis of non functional properties of variant designs across such spaces.
a key challenge is to synthesize test loads for fair comparative analysis because so generally requires specialization of common loads to the variant interfaces of variant designs.
our goal is to synthesize both design spaces and such loads automatically from common formal design space speci cations to enable speci cation driven automated dynamic analysis of tradeo s among non functional properties across large design spaces.
this paper provides one solution to this problem particularly for design space models expressible within a relational logic .
section presents object relational mapping orm as a concrete driving problem.
section presents a mathematical and solution framework.
section details an implementation architecture using a relational constraint language alloy and solver alloy analyzer for expression and synthesis of design spaces and loads.
section presents an experiment using our dynamic analysis approach to test the validity of static predictors of non functional properties of database applications.
the rest of the paper presents our evaluation of this work related work and conclusions and thoughts about future work.
.
driving problem while our long term aim is to improve engineering productivity and quality through advances in design space science and technology our short term research strategy is to use the analysis of spaces of object relation mappings orm as a tractable and useful driving problem .
in this domain one starts with an object model as in figure and eventually selects one of many possible strategies for mapping such a model to a relational database with tradeo s in response time space usage and evolvability.
figure illustrates two such strategies and listing a database set up script derived from one of these solutions.
simple orm solutions many in everyday use lock one into either point solutions or highly constrained solution spaces.
to address this problem our earlier work presented a capability to synthesize comprehensive orm design spaces from formal object model speci cations.
given such a space the challenge is to develop validate and apply non functional property prediction analysis functions to designs in the space to predict properties of designs in and tradeo s across the space.permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
copyright is held by the author owner s .
publication rights licensed to acm.
icse may june hyderabad india acm figure a simple object model with three classes order customer and preferredcustomer a one to many association between customer and order and with preferredcustomer inheriting from customer .
figure two mapping strategies.
white boxes represent classes gray titles corresponding tables and black and white arrows mapping and inheritance relationships.
foreign keys are marked as fkeys .
ideally one has a vector of easily computed well validated analysis functions.
in that case mapping this vector of functions or equivalently this vector valued function across the points in the space yields a multi dimensional non functional property image of the design space.
tradeo s pareto optimal solutions and other critical information can then be read from the results.
static analysis functions predict properties from the structures of design representations.
such functions are often efcient but might not be available validated or predictive.
this point is clear in our earlier work.
cognizant of the issues we applied published but not well validated static metrics to our synthesized orm spaces.
the results were interesting and promising and allowed us to make progress in our research but it was clear that questions remained.
can design decision makers believe such metrics?
what are the actual properties and tradeo s?
1c r e a t e table order orderid int n o t null ordervalue int customerid int 5k e y fk customerid idx customerid 6p r i m a r y k e y orderid 9c r e a t e table customer dtype varchar discount int customerid int n o t null customername varchar 14p r i m a r y k e y customerid listing synthesized mysql database creation script elided for space and readability.
figure a view of our tool to provide decision makers with pareto optimal or mapping solutions based on static analysis results columns and rows represent metrics and solution alternatives respectively.
these questions took on added urgency with our production reported here for the rst time of a web accessible tool that implements our orm synthesis and analysis approach.
we call it trademaker orm1 t orm .
it supports automated speci cation driven synthesis of orm design spaces and static analysis using the aforementioned metrics.
it provides a web interface user account and job management job submission asynchronous execution status reporting persistence computation and presentation of pareto optimal subsets of synthesized designs under the given metrics and synthesis of sql databases for selected designs.
figure presents a screen shot of a t orm run.
rows present pareto optimal designs and columns analysis results.
listing presents an sql database creation script obtained by selecting a design from the table.
to test the validity of the results that t orm reports we turned to dynamic analysis.
the combination of ample computing capacity and our ability to synthesize many running databases for given object models suggested that we measure properties and tradeo s of actual running systems in the spirit of what cadar et al.
call multiplicity computing .
so could at least validate the static metrics through statistical analysis of the power of these metrics to predict dynamically measured results.
if we could validate the static metrics we could use them for e cient analysis.
if not we could fall back on less e cient but more trustworthy dynamic analysis.
the problem was now to gure out how to automate fair comparative dynamic analysis of diverse database designs.
there are of course many commercial tools for generating database testing loads from schemas.
in our case however many variant schemas implement a common object model.
an application that operates against an object model will create what we will call an abstract load that any implementations would have to handle.
the translation from abstract load to concrete operations on a database would be implemented by an application based on a single choice of mapping strategy.
we faced the need to synthesize hundreds or thousands of such load specialization functions.
.
algebraic model the insight that enabled such synthesis was that we could recover from synthesized database designs abstraction functions relating designs back to the object model speci cations from which they were derived and that from these abstraction functions we could derive functions for concretizing abstract loads synthesized from the same object models.
the commutative diagram in figure presents the resulting structure.
design abstis a set of formal design space speci cations in a particular domain inductively dened by the grammar and semantics of the language in which the models are speci ed.
in work to date we represent design space speci cations as expressions in a domain speci c language embedded in a relational logic.
design abst load abst design conc load concl t clcompute ac figure algebraic structure of the trademaker approach.
to an abstract model m2design abst we apply a design space synthesis concretization function c to compute c m design conc the space of concrete design variants from which we want to choose a design to achieve desirable tradeo s. relation ccan be seen as mapping abstract intensional models of design spaces to extensional representations namely sets of concrete design variants.
we represent the design space synthesis function c as a semantic mapping predicate in our relational logic taking expressions in the abstract modeling language to corresponding concrete design spaces.
relation a an abstraction relation explains how any given concrete design d2c m instantiates i.e.
is a logical model of its abstract model m. function cis speci ed once for any given abstract modeling language as a semantic mapping predicate in our relational logic.
relation l an abstract load generation relation similarly maps an abstract model m2design abst to a set of abstract loads l m load abst.
to dynamically analyze a concrete design d2c m an abstract load ld2l m has to be specialized for the particular design.
the function t a load concretization function serves this purpose.
we compute tfrom a as long as c m preserves a representation of ain its output then from any single design space model m we can synthesize a concrete design space and both abstract and concretized loads.
the derivation of tfrom ainduces a mapping cl from concrete designs to concrete loads parameterized by a choice of abstract load.
this function completes the commutative diagram.
we do not actually implement this mapping.
the next section describes instantiation of our approach for the particular domain of object oriented relational database persistence mappings.
.
model implementation this section presents an implementation architecture for our approach for orm .
figure gives a high level overview.
boxes represent processing modules and ovals module inputs and outputs.
abstract models are given as expressions in alloy om a domain speci c language embedded in alloy s relational logic language.
roughly speaking we specify figure high level overview of the trademaker implementation for the particular domain of orm.
candlas predicates in alloy.
conjoining these predicates to an alloy om model yields a speci cation of the desired output space.
the alloy analyzer computes the results encoded as alloy models which we then unparse into useful forms.
from concrete design models we extract sql database creation scripts.
from abstract load models combined with choices of concrete databases we derive concrete loads represented as sequences of sql insert and select queries.
the rest of this section details how we implement the main components of the approach corresponding to functions c l andt subsection .
explains how we implement c for synthesizing concrete models from abstract design space specications .
how we implement l for synthesizing abstract loads from the same speci cations and .
how we implement t for concretization abstract loads.
.
design space synthesis mapping abstract object models to concrete designs was the subject of earlier work .
novel results since that work include substantial re nement and validation of mapping rules and the production of functions that unparse concrete designs representations encoded as alloy objects into sql database creation scripts.
this translation is important for tool users as a key to automating dynamic analysis.
to make this paper self contained this subsection brie y reviews the approach.
we then brie y describe relevant new work.
inspired by a bottom up model driven approach we start by expressing object models in a domain speci c language embedded in alloy called alloy om.
we then use alloy s constraint solver to synthesize concrete or mapping strategies realizing the function c. the synthesizer uses our alloy encoded formalizations of best practices for object relational mapping described informally in the literature .
alloy om supports three main constructs class attribute andassociation .
each class in an e.g.
uml object model appears as a class signature in alloy om.
each attribute of a given class appears as an alloy om attribute in the attribute set of the corresponding alloy om class signature.
each association in the object model appears as an alloyomassociation signature.
listing presents a fragment of an alloy om model for our customer order example.
the order class has two attributes orderid and ordervalue assigned to the attrset eld of the order class.
the id eld speci es the orderid as the identi er of this class.
the last two lines of the order signature speci cation denote that order is not1081one sig order extends class fgf attrset orderid ordervalue id orderid isabstract no noparent 6g 7one sig customerorderassociation extends association fgf src customer dst order s r c m u l t i p l i c i t y one d s t m u l t i p l i c i t y m a n y g listing order class in alloy om.
an abstract class and has no parent.
lines then specify the customerorderassociation along with the number of object instances that can be at each end of the association denoted as srcand dstmultiplicity .
alloy om is not a sophisticated modeling language.
the salient point is that embedding it in alloy allows us to use alloy relations to encode and the alloy analyzer to compute formally specied semantic mapping rules to other domains here concrete database designs and abstract loads for those designs.
figure or mapping for customer order example figure presents a graphical depiction of an alloy object encoding a synthesized or mapping solution.
this solution is one of ve pareto optimal solutions in the design space for our customer order object model.
the diagram is accurate but edited to omit some details for readability.
in this diagram table1 is associated to customer and preferredcustomer classes and table0 is associated to both order and customerorderassociation.
from this alloy solution our tools generate the sql script of listing .
the script sets up a database with the two tables order with attributes orderid customerid and ordervalue and customer with attributes customerid customername discount and dtype .
both customer andpreferredcustomer objects are stored in this table under this particular mapping strategy with the dtype eld distinguishing the type of record stored.
.
abstract load synthesis our approach to synthesizing abstract loads starts with the automated transformation of a given alloy om model into a related alloy speci cation that we call a load model.
we then use the alloy analyzer to synthesize abstract loads1fact f all o1 o2 customerorderassociation jo1 .
orderid o2 .
orderid and o1 .
customerid o2 .
customerid o1 o2 3g 5fact f all o customerorderassociation jone c order jo .
orderid c .
orderid all o customerorderassociation jone c customer j o .
customerid c .
customerid 8g listing part of the load model speci cation generated for customer order association.
from this load model.
alloy solutions to the load model encode abstract object model data instances om instances which are what we take as synthesized loads with which to test synthesized designs.
this section describes this functionality in more detail.
for each instance of class andassociation in the alloyom model our model transformer synthesizes a signature de nition.
when the class under consideration inherits from another class the synthesized signature de nition extends its parent signature de nition.
given the speci cation of order represented in listing the following code snippet represents its counterpart in a synthesized load model.
sig order f ordervalue one int orderid one int g the onemultiplicity constraints used in the declaration of elements signatures within the alloy om model listing specify them as singleton signatures.
while these constraints are required by the tradeo space generator e.g.
to not generate multiple tables for a class in the model they are unneeded for load generation and thus omitted in the load model.
the element attributes in the object model are also declared as elds of the corresponding load signature de nition representing relations from the signature to the attribute type.
finally two sets of constraints are synthesized as fact paragraphs in the load model to guarantee both referential integrity of generated data as well as uniqueness of element identi ers with reference to the set of element instances to be generated.
referential constraints require every value of a particular attribute of an element instance to exist as a value of another attribute in a di erent element.
consider the association relationship between customer and order classes from our running example figure .
the code snippet of listing represents synthesized constraints in the load model for the customer order association.
the expression of lines states that if any two elements of type customerorderassociation have the same orderid andcustomerid the elements are identical.
this constraint rules out duplicate elements.
the fact constraint of lines states that for any orderid and customerid elds of acustomerorderassociation there are order andcustomer instances with the same orderid and customerid .
applying the alloy analyzer to the derived load model yields the desired load in the form of object model data instances om instances .
figure depicts a generated ominstance an alloy solution object.
this solution represents two customers with customerid of and the latter a preferred customer with percent discount along with109figure an example of om instance.
their orders.
from many such solutions we derive an abstract application object model level rather than concretedatabase schema level load with which to test the performance of many database instances.
improving the e ciency of the load generator.
one of the challenges we faced involved the scalability of this approach to load synthesis.
a large number of solutions generated by the alloy analyzer were symmetric to previously generated instances and thus did not contribute usefully to the load being generated.
we explored a number of ways to improve e ciency of the load generator.
the one that we found worked best is the iterative re nement of the load model by adding constraints that eliminate permutations of the already generated om instances.
without this improvement it took hours for trademaker orm to generate test loads for one of our experiments.
given this approach the time was reduced to about hours an order of magnitude speed up in the synthesis of test loads.
.
abstract load concretization the next challenge we discuss is to convert abstract load om instance objects into concrete sql queries on a perdatabase basis.
this is the task of specializing abstract load elements to the variant schemas presented by di erent solutions in the design space.
our alloy to sql transformer handles this task.
to create sql statements for a given database alloy to sql transformer requires an or mapping the abstraction function describing how that concrete database schema implements the abstract object model.
algorithm outlines this transformation.
for brevity and because it su ces to make our point this section focuses oninsert queries.
the approach supports the generation of select and update queries as well which are important of course for comprehensive dynamic analysis.
the logic of the algorithm is as follows.
iterate over all elements in a given om instance e.g.
classes and associations whose values can be populated into databases through insert statements.
looks up the mapping to determine the table in which the element values should be stored.
for each relational eld in the associated table if the om instance contains a value corresponding to that eld insert the value into the eld.
otherwise in the case that the eld is a dtype insert the name of element into the eld.
finally if the eld is a foreignkey nd the associated attribute from a relevant association in the given om instance and insert its value into the eld.
consider the database alternative for our running example in which we store the customer order association data into the order table figure 2b .
in that case the eld ofcustomerid in the order table is a foreignkey and its values come from the associated customerorderassociation element.algorithm generate sql insert statements input omi om instance map or mapping output a set of sql insert statements 1forelement in omi do t map.tableassociat element f t. elds for eld in f do value getvaluefromomi eld ifvalue !
null then add eld value into statements end else if eld dtype then value element.name end ifisforeignkey eld then attr ndattributefromassociation eld value getvaluefromomi attr end add eld value into statements end end 20end 1insert into customer customerid dtype values customer 2insert into customer customerid dtype values preferredcustomer 3insert into order orderid ordervalue customerid values 4insert into order orderid ordervalue customerid values listing generated sql insert statements from ominstance of figure for implementation mapping of figure .
listings represents the set of sql insert statements generated from the om instance of figure according to the mapping of figure .
the rst two generated statements de ne insert queries to store instances of customer and preferredcustomer into the customer table along with appropriate dtype values for each one.
the next two statements then store instances of order and customerorderassociation into the order table.
.
dynamic analysis experiment as an experimental test of our approach to speci cationdriven automated dynamic analysis of non functional property tradeo s across design spaces we apply the approach to test the validity of the static predictors of database performance.
we formulate test and provide experimental data in support of three driving hypotheses h1 the ordering of alternatives predicted by the static metrics predicts that of the dynamic analysis results110 h2 the relative magnitudes of static measures of alternatives predict those of the dynamic analysis results h3 dynamic analysis using scale limited synthesized loads predicts performance under much larger loads this section summarizes the design and execution of our experiment the data we collected its interpretation and our results which include novel ndings regarding these metrics.
.
static metrics suite the choice of mapping strategy impacts key non functional system properties.
response time performance storage space and maintainability are among the set of quality attributes de ned by the iso iec standard that are in uenced by the choice of or mappings.
to statically measure these attributes in an orm design space we use a set of metrics suggested by holder et al.
and baroni et al.
.
the metrics are called table access for type identi cation tati number of corresponding table nct number of corresponding relational fields ncrf additional null value anv number of involved classes nic and referential integrity metric rim .
in this work we focus on three of these metrics for time and space performance.
maintainability is out of scope as we cannot measure it using dynamic analysis technique.
.
.
table accesses for type identification tati table accesses for type identi cation tati is a performance metric for polymorphic queries .
according to the de nition given a class c tati c de nes the number of di erent tables that correspond to c and all its subclasses.
our tools total up tati values for each class as the overall tati measure for each solution alternative.
.
.
number of corresponding tables nct number of corresponding tables nct is a performance metric for insert and update queries.
this metric speci es the number of tables that contain data necessary to assemble objects of a given class .
according to the de nition given a class c nct c equals to nct of its direct super class if c is mapped to the same table as its super class.
otherwise if c is mapped to its own table nct c equals to nct of its direct super class plus one.
finally if c is a root class nct c equals to .
our tool computes totaled nct values over classes as the nct measure for each solution alternative.
.
.
additional null value anv the additional null value anv metric speci es the storage space for null values when di erent classes are stored in a common table .
according to the de nition given a class c anv c equals to the number of non inherited attributes of c multiplied by the number of other classes that are being mapped to the particular table to which c is mapped.
our tools present totals for anv values over all classes as the anv measures for each solution alternative.
.
static analysis of synthesized designs to apply these metrics to synthesized solutions we designed speci c alloy queries.
here we describe one for measuring the tati metric.
the others are evaluated similarly.
tati c c. parent .
tassociate figure multi dimensional quality measures for paretooptimal solutions.
here the dot operator denotes a relational join.
the alloy operator represents the transpose operation over a binary relation which reverses the order of atoms within the relation.
given the tassociate abstraction relation that maps tables to their associated elements i.e.
class or association within the object model its transpose is the relation that maps each element to its associated table within the relational structure.
the alloy operator represents the re exive transitive closure operation of a relation.
accordingly the expression of c. parent states a set of classes that have the class c as their ancestor in their inheritance hierarchy.
the query expressions then by using the alloy set cardinality operator computes the tati metric.
our static metrics suite comprises six such static measures.
the vector of these functions de nes a dimensional static analysis function applicable to alloy synthesized concrete designs e.g.
figure .
our tools map this function over all elements of a synthesized design space to produce a tradeo surface.
the spider diagram shown in figure illustrates one pareto optimal point on that surface for our example customer order system.
to display quality measures in one diagram we normalized the values.
such diagrams can assist in conducting tradeo analyses by making it easier to visualize and compare alternatives.
according to the diagram if the designer opts for performance she may decide to use sol.
instead of sol.
as the latter has worse values for the tati and nct performance metrics.
of course none of this theory or machinery is very useful if the metrics themselves are not predictive of the actual non functional performance properties of candidate designs.
the rest of this section presents our experiment in automated dynamic analysis the goal of which was to help us answer this question.
.
four subject systems we synthesized design spaces and compared static predictions with dynamic results for four subject systems.
the rst is the object model of an e commerce system adopted from lau and czarnecki .
it represents a common architecture for open source and commercial e commerce systems.
it has classes connected by associations with inheritance relationships.
the second and third object models are for systems we are developing in our lab.
decider is another system to support design space exploration.
its object model has classes associations and inheritance relationships.
the third object model is for a system csos 111a kind of cyber social operating system meant to help coordinate people and tasks.
in scale it has classes associations and inheritance relationships.
we also analyzed an extended version of our customer order example.
.
planning and execution our experimental procedure involved the synthesis of both design spaces of database alternatives and several abstract loads in a variety of sizes for each subject system.
given the synthesized schemas we created a database for each alternative.
we then populated generated data into databases and ran concrete queries over those databases.
we measured and collected the numbers of concrete queries generated from abstract loads for each database alternative query execution time as well as the size of each database.
we used an ordinary pc with an intel core i7 .
ghz processor and gb of main memory with sat4j as our sat solver.
database queries were performed on a mysql database management system dbms installed on a machine equipped with an amd opteron mhz processor and 64gb memory.
data and statistical information are available at table design space sizes for subject systems.
subj.
sys.
solutions eq.classes pareto sols.
decider e commerce csos cust order ext table summarizes generated solution space for each subject system.
there is one row for each system.
the columns indicate the total number of solutions the number of static equivalence classes where equivalence is determined by equality of static analysis results and the number of paretooptimal solutions under the given static metrics.
we investigated and compared two di erent methods for generation of data sets.
the rst method generated data using our formal synthesis methods.
for the second we hand developed a load generator for generating large loads that nevertheless respect the constraints in our object models e.g.
referential constraints between elements .
three data sets were developed for each subject system to support the task of evaluating the static metrics.
dataset .
this data set is generated using the alloybased data generator where the maximum bit width for integers is restricted to .
this leads to the generation of small data set for our experiments.
dataset .
this data set is generated using our alloybased data generator.
the maximum bit width for integers is restricted to which leads to the generation a larger data set compared with the former data set.
dataset .
as with many formal techniques the complexity of constraint satisfaction restricts the size of models that can practically be analyzed and synthesized .
for experimental purposes we hand implemented a more scalable data generator.
it does not generate queries directly but rather replaces the constraint solver for synthesis of abstract loads.
having synthesized larger abstract loads in the form of om instances using the mechanisms already used in the alloy based data generator cf.
.
the generatorthen transforms abstract loads into sets of concrete queries targeting diverse implementation alternatives.
table part of the generated data sets for the ecommerce experiment the rst row shows abstract loads generated for the e commerce system within each data set each cell in the other rows corresponds to the size of generated concrete load for the database alternative and data set given on the axes.
e commerce dataset dataset dataset abstract load sol.
conc.
load sol.
conc.
load sol.
conc.
load sol.
conc.
load table presents the sizes of generated data sets for some of the solution alternatives for the e commerce system.
the number of concrete queries re ned from a common abstract load is di erent in various solution alternatives depending on the way that each implementation mapping alternative re nes the abstract object model into the concrete representation in relational structure cf.
.
.
.
results for hypothesis h1 order to test the predictive power of our static metrics we compared its predictions against the results of our dynamic analysis.
to evaluate our rst hypothesis whether the relative order of implementation alternatives is predicted by static metrics we compute spearman correlation coe cients an appropriate correlation statistic for order based consistency analysis.
it measures the degree of consistency between two ordinal variables .
a correlation of indicates perfect correlation while indicates no meaningful correlation.
negative numbers indicate negative correlations.
table correlation coe cients between the relative order of solution alternatives predicted by static metrics and those observed from actual runtime measures.
tati nct anv deciderdataset1 .
.
.
dataset2 .
.
.
dataset3 .
.
.
e commercedataset1 .
.
.
dataset2 .
.
.
dataset3 .
.
.
csosdataset1 .
.
.
dataset2 .
.
.
dataset3 .
.
.
cust order ext dataset1 .
.
.
dataset2 .
.
.
dataset3 .
.
.
table summarizes correlation coe cients between static metrics and dynamic measures.
the data show reasonably strong but somewhat inconsistent positive correlations between statically predicted and actual run time performance for tati average correlation of .
and nct average correlation of .
.
these metrics appear moderately to strongly predictive of the relative ordering databases runtime performance at least for the kinds of loads employed in our experiments.112the performance of the anv predictor varies across the subject systems.
anv predicts well in the e commerce and decider experiments and moderately in the csos data but weakly in the customer order extended set.
moreover the results show negative correlation between the anv metric and database size.
as number of null values increases size decreases.
this observation for the anv metric is in direct contrast to what is predicted.
one possible reason is that when the anv metric increases the number of tables for the database solution under consideration decreases.
assuming that the database system e ciently stores null values the database size would reduce.
to further evaluate predictiveness of static metrics we consider the case in which designers use each static metric as a two class classi er.
we thus measure precision recall and f measure as follows precision is the percentage of those alternatives predicted by a given metric as more preferable in terms of a given quality attribute that were also classi ed as more preferable by the actual analysis tp tp fp recall is the percentage of alternatives classi ed more preferable by the actual analysis that were also predicted as more preferable by the a given metric tp tp fn f measure is the harmonic mean of precision and recall precision recall precision recall where tp true positive fp false positive and fn false negative represent the number of solution alternatives that are truly predicted as preferable falsely predicted as preferable and missed respectively.
while static metrics output predictions of quality characteristics as natural numbers actual analysis of query execution performance and required storage space are in terms of seconds and bytes respectively.
to classify an alternative aspreferable we thus use median for each set of result values as a threshold.
we measure evaluation metrics for each subject system with respect to three data sets.
table experimental results of evaluating or metrics as two class classi ers.
tati nct anvprecision recall f measure precision recall f measure precision recall f measure deciderds1 .
.
.
.
.
ds2 .
.
.
.
.
.
ds3 .
.
.
.
.
.
e commerceds1 ds2 ds3 .
.
.
csosds1 .
.
.
.
.
.
.
.
.
ds2 .
.
.
.
.
.
.
.
ds3 .
.
.
.
.
.
.
cust orderds1 .
.
.
ext ds2 .
.
.
.
.
.
.
.
ds3 .
.
.
.
.
.
.
table summarizes the results of our experiments to evaluate the accuracy of static metric predictors as two class classi ers.
the average precision recall and f measure are depicted in figure .
the results show the accuracy of the tati and nct metrics in classifying implementation alternatives in terms of their run time performance.
the average precision and recall for all four experiments are about showing a low rate of both false positives and false negatives.
the anv metric however achieves the average under in all evaluation metrics.
the experimental data thus suggests that under the generated abstract loads the relative order of implementation alternatives predicted by static metrics of tati and nct is figure bar plot of the average precision recall and fmeasure for considering static metrics as two class classi ers.
indicative of their comparative preference in actual runtime performance but this is not the case for anv as a static predictor of storage space.
.
results for hypothesis h2 magnitudes to address the second hypothesis relative magnitude of static predictions matter we employ a coe cient of determination denoted r2 as a metric for how well actual outcomes are predicted by the static metrics.
figure plots the results.
for brevity only results from dataset are presented other data sets give similar results.
the performance of the predictors varies widely across systems and predictors.
tati and nct are predictive of performance for the e commerce and decider systems but relatively poor predictors for csos.
tati performs poorly in the customer order extended data.
anv predicts size in the e commerce experiment and moderately in the decider data but inconsistently and weakly in the csos data and not at all in the customer order extended set.
we interpret this data as suggesting that the relative magnitudes of static metrics for various solution alternatives are not reliably indicative of the relative magnitudes of actual performance and that anv is a poor indicator of the storage space.
one is advised to use such static metrics with caution.
while tati and nct metrics predict the relative order of solution alternatives with high con dence the difference in predicted values of two alternatives is not a good indicator of their actual run time di erence.
.
results for h3 small vs. large loads to address the third hypothesis that small formally synthesized loads predict the outcomes of much larger loads we employ the pearson product moment correlation statistic.
pearson measures the degree of linear dependence between two variables not necessarily ordinal as opposed to the spearman test.
a correlation of represents perfect correlation and no meaningful correlation.
we summarize correlation coe cients between experimental results obtained from smaller data sets of and and that of the large dataset in figure .
the average pearson correlation coe cient between dataset and the rst and second data sets are and respectively.
these data lend support to the proposition that smaller scale test sets produced by speci cation driven synthesis can provide valid predictions of performance under larger more realistic loads.113figure correlation between static metrics and actual run time measure rows represent scatter plots of observed values versus predicted values by tati nct and anv metrics from top to bottom respectively r2correlation coe cient is shown at the bottom of each plot.
figure summary of pearson correlation coe cients between experimental results obtained from smaller data sets and that of the large dataset .
.
our evaluation of this work the overarching problem this work addresses is interesting and important the need for improved science to support decision making in complex and poorly understood tradeo spaces particularly involving tradeo s among nonfunctional properties also sometimes called ilities .
we need languages in which to specify design spaces techniques for synthesizing and analyzing design spaces mechanisms for mapping static and dynamic analysis functions across design spaces techniques for validating such metrics and tools that enable engineers use the science to improve real engineering practice .
we also need measures for ilities that are important but hard to measure today for evolvability some dependability properties a ordability of construction and more.this paper contributes some new results to the science and engineering of tradeo analysis of non functional properties.
it suggests the possibility of useful formal languages for specifying design spaces in support of formal synthesis of both designs and comparative analysis loads.
we showed that specialization of common loads is enabled by access to abstraction functions from concrete to abstract designs which can be embedded in the results of design synthesis.
concretization functions proved useful not only for scalelimited formally synthesized loads but for concretizing abstract loads produced by other means.
we also presented an experiment using our tool to test the validity of static predictors of database performance based on published but not validated metrics.
two of the metrics appear to produce meaningful signals while the third appears not useful.
the data also indicate a need for caution in relying on the static metrics.
their predictive power even in the good cases varied across application models.
that said we can now provide automated dynamic analysis as a fall back.
we are integrating support for invoking such automated analysis into our trademaker orm tool.
trademaker orm itself has real potential utility for object relational mapping and partial application synthesis but its greater signi cance is as a demonstration of our research results and a testbed for further research on formal tradespace modeling and analysis.
there are of course limitations in our approach and in this work.
we mention those most relevant to a proper evaluation of this e ort.
first the static metrics we evaluated sum the values of published metrics over the elements of each design alternative.
we thus extended the original met 114rics and our statistical results should technically be read as pertaining to these extensions of the original measures.
second while our synthesis mechanisms are implemented and working our infrastructure for running synthesized concrete loads against synthesized designs still relies on some manual processing.
our statistical data were thus derived by dynamic analyses of certain subsets of our synthesized designs.
we selected the subsets deemed pareto optimal by the static metrics.
as our infrastructure matures we will conduct whole space dynamic analyses which we expect to produce results consistent the basic result presented here.
we are on a path to support automated whole space dynamic analysis through trademaker orm.
the work reported in this paper did nevertheless involve the synthesis and dynamic analysis of over database alternatives.
third our experiments to date tested our hypotheses for random loads of varying sizes.
real applications will generally produce non random loads.
whether the static metrics we tested are predictive for large real applications remains unclear.
on the other hand we o er dynamic analysis at scale as an alternative.
we envision a future in which some systems run many design variants in parallel perhaps with small but representative loads abstracted from real loads on live systems to detect conditions in which dynamic switching to new implementation strategies should be considered.
finally there is the issue of scalability.
using alloy as a constraint solver entails scalability constraints.
we can handle object models with tens of classes.
industrial databases often involve thousands of classes.
it is unlikely that our current implementation technology will work at that scale.
for now it does have real potential as an aid to smallerscale system development.
that we can present an object model for a realistic web service synthesize a broad space of orm strategies select one based on tradeo analysis automatically obtain an sql database setup script provide it java ee and have much of an enterprise type application up and running with little e ort is exciting even if it does not address yet the most demanding needs of industry.
.
related work much work is related to this research.
numerous techniques have been developed for database test generation including the generation of realistic loads for tpc benchmarks .
while some use constraint solvers none generate common loads over spaces of alternative schemas.
this requires enforcement of abstract design constraints as well as constraints implied by concretization mappings for each alternative.
trademaker to our knowledge is the rst tool with this capability.
others have derived databases from speci cations.
krishnamurthi et al.
mapped alloy speci cations into scheme implementations with a focus on databases.
cunha and pacheco translated a subset of alloy into corresponding relational operations.
these research e orts share with ours the emphasis on using formal methods.
our work di ers fundamentally in its emphasis on the generation of spaces of implementation alternatives not just point solutions.
much work has focused on object relational mapping approaches to the object relational impedance mismatch problem .
philippi categorized the mapping strategies in a set of pre de ned quality trade o levels which are used to develop a model driven approach for the generation of or mappings.
cabibbo and carosi dis cussed more complex mapping strategies for inheritance hierarchies in which various strategies can be applied independently to parts of a multi level hierarchy.
our approach is novel in having formalized orm strategies previously informally described in some of these research e orts thereby enabling automatic generation of or mappings for each application object model.
drago et al.
considered or mapping strategies as a variation points in their work on feedback provisioning.
they extended the qvt relations language with annotations for describing design variation points and provided a feedback driven backtracking capability to enable engineers to explore the design space.
while this work is concerned with the performance implications of choices of perinheritance hierarchy or mapping strategies it does not attack the problem that we address the automation of dynamic analysis through synthesis of design spaces and fair loads for comparative dynamic analysis.
the other relevant thrust of research has focused on mapping uml models enriched with ocl invariants into relational structures and constraints.
heidenreich et al.
developed a model driven framework to map object models represented in uml ocl into declarative query languages such as sql and xquery.
badawy and richta provided some rules guiding derivation of declarative constraints and triggers from ocl speci cations.
extending the same line al jumaily et al.
developed a model driven tool transforming the ocl constraints into sql triggers.
demuth et al.
also discussed a number of di erent approaches to implement ocl to sql mapping and developed a tool that transforms each ocl invariant into a separate sql view de nition.
di erent from these research e orts transforming an object model to a single counterpart in relational structures trademaker generates tradeo spaces of objectrelational mappings with focus on structural mapping alternatives rather than transformation of integrity constraints.
.
conclusion this paper makes several contributions to the science and engineering of software intensive systems a mathematical and implementation architecture for formal automated dynamic analysis of tradeo spaces a principled approach to load concretization for specializing common loads to large numbers of variant implementations experimental validation of simple derivatives of published orm metrics to our knowledge the rst experimental evaluation of orm metrics and trademaker orm an accessible and functional tool enabling tradeo analysis in large design spaces for the particular domain of object relational mapping and a testbed for ongoing research of the kind reported in this paper.
this paper also contributes to our broader research program which is increasingly focused on specifying validating realizing and certifying acceptable tradeo s among non functional properties which remains a research challenge of the rst order.
.