balancing trade offs in test suite reduction august shi alex gyori milos gligoric andrey zaytsev and darko marinov department of computer science university of illinois at urbana champaign awshi2 gyori gliga zaytsev2 marinov illinois.edu abstract regression testing is an important activity but can get expensive for large test suites.
test suite reduction speeds up regression testing by identifying and removing redundant tests based on a given set of requirements.
traditional research on test suite reduction is rather diverse but most commonly shares three properties requirements are defined by a coverage criterion such as statement coverage the reduced test suite has to satisfy all the requirement s as the original test suite and the quality of the reduced test suites is measured on the software version on which the reduction is performed.
these properties make it hard for test engineers to decide how to use reduced test suites.
we address all three properties of traditional test suite reduction we evaluate test suite reduction with requi rements defined by killed mutants we evaluate inadequate reduction that does not require reduced test suites to satisfy all the requirements and we propose evolution awa re metrics that evaluate the quality of the reduced test suites across multiple software versions.
our evaluations allow a more thorough exploration of trade offs in test suite reduc tion and our evolution aware metrics show how the quality of reduced test suites can change after the version where the reduction is performed.
we compare the trade offs among various reductions on projects with a total of tests over commits and a cumulative history spanning years of development.
our results help test engineers make a more informed decision about balancing size coverage and fault detection loss of reduced test suites.
categories and subject descriptors d. .
software engineering testing and debugging general terms experimentation measurement keywords test suite reduction software evolution .
introduction developers often build regression test suites that are automatically run as the software evolves.
modern software permission to make digital or hard copies of all or part of thi s work for personal or classroom use is granted without fee provided th at copies are not made or distributed for profit or commercial advantage an d that copies bear this notice and thefull citation on the firstpage.
tocop y otherwise to republish topostonserversortoredistribute tolists re quires priorspecific permission and or afee.
fse november hong kong china copyright acm ... .
.evolves fairly quickly with changes pushed to repositorie s even several times per minute .
meanwhile regres sion test suites also grow and even older reports mention real world regression test suites that could take weeks to finish .
as a result regression testing is becoming more important but also more expensive.
test suite reduction is an approach to make regression testing faster.
the goal is to identify te sts that can be removed from a test suite without substantially reducing its fault detection capability.
most test suite reduction techniques identify such tests based on satisfying redundant test requirements .
each test satisfies certain requirements e.g.
covers certain statements or branches fo r the statement or branch coverage criteria.
a test tfrom a test suite tisredundant if tsatisfies only the requirements satisfied by the other t t tests from the test suite.
researchers have proposed many algorithms to identify redundant tests .
yoo and harman present an extensive survey of regression testing including test suite reduction .
removing redundant tests from an original test suite produces a reduced test suite.
prior research measured the quality of reduced test suites in comparison to the original test suites mostly by two metrics.
the reduction in test suite size is most commonly measured as the ratio of the number of tests removed from the original test suite to the number of tests in the original test suite.
the loss in fault detection capability is most commonly measured as the ratio of the number of faults missed by the reduced test suite to the number of faults detected by the original test suite the faults are ei ther automatically generated mutants or manually seeded faults .
some prior w ork also used other metrics e.g.
test execution cost or cover age of fault history as discussed in section .
despite a variety of techniques most traditional test sui te reduction research shares three properties.
first redund ant tests are determined with respect to some structural or dataflow coverage criteria e.g.
statement coverage block coverage branch coverage or def us e coverage .
second test suite reduction produces a reduced test suite that covers exactly the same requirements as the original test suite we call this adequate test suite reduction .
third evaluation of the effectiveness of test suite reduction was conducted only on the same software version on which reduction was performed .
these three properties of traditional test suite reductio n research limit the insight into the trade offs of reduced tes t suites.
consider a test engineer who needs to decide whetherto use the original test suite or a reduced test suite.
we can distinguish two scenarios.
one scenario is to permanently remove redundant tests from the original test suite and keep only the reduced test suite.
such reduced test suites run faster but the removed tests could detect faults that the remaining tests in the reduced test suite would not detect as software evolves.
the other scenario is to keep both the reduced test suite and the original test suite but run the reduced test suite more often e.g.
run it for all software changes during day and then run the original test suite only during night.
in both scenarios the test engineer needs to balance the reduction in the test suite size with the risk th at the fault detection capability of the reduced test suite do es not degrade substantially compared to the original test sui te as the project evolves1.
in this paper we address the three properties of traditional test suite reduction.
first we evaluate test suite reduction based on killed mutants rather than traditional coverage i.e.
the reduced test suite has to kill the same mutants killed by the original test suite this reduction was proposed by offutt et al.
almost years ago but not widely evaluated.
we also propose an even stronger reduction that requires the reduced test suite to preserve both statement coverage and killed mutants of the original test suite.
second we evaluate inadequate test suite reduction where the reduced test suite need not cover all the requirements as the origina l test suite .
such inadequate reduction leads to higher reductions in test suite size at the expense of higher losse s in fault detection capability.
third we introduce novel reduction metrics based on software evolution .
our metrics evaluate the code coverage and fault detection capability of reduced test suites on multiple software versions .
we make the following contributions test suite reduction based on killed mutants we evaluate using killed mutants as requirements for test sui te reduction potentially combined with the more traditional test suite reduction based on statement coverage to achie ve lower loss in fault detection capability at the expense of lower reduction in test suite size .
inadequate reduction we evaluate inadequate reduction that relaxes the constraint of covering all requirements wh en performing test suite reduction to achieve higher reducti on in test suite size at the expense of higher loss in faultdetection capability .
evolution aware metrics we propose novel evolutionaware metrics to evaluate the impact of software evolution on reduced test suites.
extensive evaluation we explore the trade offs of testsuite reduction based on killed mutants and inadequate reduction with both traditional and our proposed evolutionaware metrics on projects with a total of tests over commits and spanning years of cumulative evolution history.
to the best of our knowledge this is the largest dataset used for evaluating test suite reduction.
the results show that traditional reduction based on statement coverage can reduce test suite size on average .
but loses up to .
in killed mutants.
in contrast the reduction based on killed mutants achieves no loss in killed mutants with .9pp2increase in size over test suites re1note that test suite reduction does notexplicitly consider software changes from software evolution unlike regressi on test selection that chooses tests based on software changes .
2here pp stands for percentage points which are used toduced using statement coverage.
the reduction based on both statement coverage and killed mutants has no losses in those requirements but has .7pp increase in test suite siz e compared to the reduction based on killed mutants.
hence a test engineer who plans to permanently remove redundant tests may prefer to use one of the reductions based on killed mutants instead of the traditional reduction based on covered statements.
further by allowing the reduced test suite to satisfy instead of of the original test suites requirements t he median reduction in test suite size increases by .14pp.
w e show how relaxing the coverage further results in even highe r reductions in test suite size.
hence a test engineer who plans to use both the reduced test suite and the original test suite may prefer to use some inadequate reduction instead of the traditional adequate reduction.
finally we evaluate for all kinds of reductions how the killed mutants of reduced test suites change as software evolves.
we find the numbers to remain fairly stable dropping on median by at most .76pp even after many software versions.
hence a test engineer deciding whether how to use the reduced test suite can be relatively confident that making the decision based on the current software version is likely to reflect what happens in the future software version s. .
background we first describe the traditional test suite reduction and commonly used reduction algorithms.
we then revisit the three properties frequently shared in traditional test su ite reduction research requirements are defined by code coverage criteria reduction algorithms perform adequ ate test suite reduction and evaluations of reduction alg orithms use only one software version.
definition .traditionally a test suite reduction algorithm algotakes two inputs a function that returns the set of satisfied requirements for a given test suite and the original test suite oto be reduced.
it returns a reduced test suite r o that satisfies the same requirements as the original test suite algo o r such that o r .
requirements code coverage is widely used for measuring the quality of test suites.
a coverage criterion defines a set of requiremen ts and measures which requirements a given test suite satisfies .
for example statement coverage measures which statements are covered during a test suite run.
previous research on test suite reduction has often used statement coverage to detect redundant tests i.e.
the first argument of algowas the stmtfunction that returns the set of covered statements for a given test suite.
other criteria were also used for test suite reducti on e.g.
block coverage branch coverage and def use coverage .
in the remaining text we use the termtechnique to refer to an algorithm instantiated with a function that returns the satisfied requirements.
describe differences between values expressed in percentag es to avoid the following example ambiguity if a value is and increases .
does it become .
or .
?
the increase of .9pp means that it becomes .
.
.
reduction algorithms the most popular traditional reduction algorithms create reduced test suites that satisfy the same requirements as the original test suite i.e.
o r .
we thus call themadequate test suite reduction algorithms.
specifically when a traditional test suite reduction algorithm is insta ntiated with statement coverage we call it statement adequate reduction sar technique.
the most widely used algorithm is greedy which iteratively selects the test that satisfies the most requirement s not previously satisfied.
more precisely starting with an empty set of tests r and an empty set of satisfied requirements r the greedy algorithm selects at each step a testt othat satisfies the highest number of requirements not in r and adds the selected test to r. this process continues until o r .
when two or more tests satisfy the same number of requirements various strategies ca n be used to break ties to determine the next test to add to r. we currently break ties randomly as commonly done in prior work .
the other commonly used algorithms for test suite reduction are ge gre hgs and ilp their details are available elsewhere e.g.
in the regression testing survey .
.
evaluating reduction algorithms studies that evaluated test suite reduction algorithms used mainly two metrics reduction in test suite size andloss in fault detection capability to measure the quality of the reduced test suites on the one software version on which the reduction is performed.
the size reduction was measured as the ratio of tests removed from the original test suite over the number of tests in the original test suite sizred o r o the loss in fault detection capability was measured as the ratio of the number of faults missed by the reduced test suite over the number of faults detected by the original test suite mutloss mut o mut r mut o where mutis the function that returns the set of detected faults for the given test suite.
due to the challenges in collecting a large number of known real faults per project researchers most commonly evaluated reduction algorithms using mutation testing or manually seeded faults.
mutation testing systematically i nserts syntactic changes called mutants in code and measures how many of these mutants are killed by a given test suite a mutant is considered killed if at least one of the tests fails and the same test passes in the non mutated run .
the quality of a test suite is measured as the ratio of the number of killed mutants over the total number of systematically inserted mutants this ratio is called the mutation score.
previous research on test suite reduction measured the effectiveness of reduction algorithms by comparing the mutation score of the reduced test suite to the mutation score of the original test suite .
we also use mutatio n score to evaluate a test suite s fault detection capabilit y. interestingly previous studies reported conflicting findings in terms of the loss of fault detection capability reduced test suites sometimes had low loss and sometimes had high loss .additionally yoo and harman used multi objective optimizations to consider multiple metrics at once includ ing execution cost approximated by the number of instructions to obtain a machine independent metric .
while they applied these optimizations to perform test selection and prioritization one could apply them also to test suite reduction.
however in this study we use only the size of the test suite as a proxy for execution cost.
limited evaluation to summarize we are concerned with three properties of test suite reduction research.
requirements based on code coverage may result in relatively small reduced test suites that do not preserve well the fault detection capability of the original test suites.
adequ ate test suite reduction may result in relatively large reduce d test suites and if more size reduction is acceptable the lo ss in the fault detection capability may not be high.
all previous studies evaluated each reduced test suite only on a single software version on which the suite is reduced which may not give enough insight into the quality of reduced test suites through evolution.
.
new evaluation methodology we next describe our evaluation that extends the traditional research on test suite reduction.
specifically we e valuate requirements for test suite reduction based on kil led mutants inadequate reduction that achieves higher reductions in test suite size by relaxing the requirements th at a test suite reduction algorithm has to satisfy and nov el metrics to evaluate test suite reduction algorithms by mea suring the impact of software evolution on the reduced test suites produced by each algorithm.
.
requirements considering the importance of preserving the high mutation score after test suite reduction we evaluate requi rements defined by killed mutants and requirements defined by a combination of statement coverage and killed mutants.
.
.
mutantadequatereduction mutant adequate reduction mar technique reduces a test suite based on killed mutants .
instead of finding a reduced test suite that covers the same statements as the original test suite as done by sar mar finds a reduced test suite that kills the same mutants and thus achieves the same mutation score as the original test suite.
in other words the first argument in the reduction algorithm i.e.
inalgo definition is the mutfunction that returns the set of mutants killed by a given test suite.
all testsuite reduction algorithms we evaluate can then use killed mutants instead of covered statements as requirements.
.
.
statement mutantadequatereduction statement mutant adequate reduction smar technique reduces a test suite based on bothstatement coverage and killed mutants.
it creates one joint set of requirements of allstatements covered and allmutants killed by the original test suite.
although smar by definition preserves both statement coverage and killed mutants it is important to explore the reduction in test suite size that smar provides .
.
reduction algorithms most traditional test suite reduction algorithms aim to find a reduced test suite that satisfies allrequirements sat 0 0 o0 0 r0 1 o0 1 r0 2 o0 2 r0 1 o1 1 r1 2 o1 2 r1 2 o2 2 r2 ... figure visualized collected data used to calculate novel metrics where stmt mut isfied by the original test suite be the requirements all sta tements covered sar or all killed mutants mar or both smar .
however if the goal is to greatly reduce the testsuite size it may be acceptable to have some loss in both statement coverage and killed mutants .
we evaluate inadequate reduction instead of producing a reduced test suite that satisfies of the requirements of the original test suite the reduced test suite can satisfy l ess than of the requirements e.g.
of the statements covered by the original test suite .
definition .an inadequate reduction algorithm takes three inputs a function that returns the set of satisfied requirements for a given test suite the original test su ite o and the percentage l 100of requirements that must be satisfied.
it returns a reduced test suite r o that satisfies at least l of the requirements satisfied by o inalgo o l r such that r l o note that inalgo is a more general form of algo i.e.
inalgo withl is equivalent to algo.
while inalgo can be applied to any set of requirements we particularly identify statement inadequate reduction sir which achieves less than statement coverage of the original test suite inalgo is evaluated with the stmtfunction and l and mutant inadequate reduction mir which achieves less than killed mutants of the original test suite inalgo is evaluated with the mutfunction and l .
both sir and mir can be instantiated to any lbetween and which we call inadequacy level .
we adjust the greedy algorithm to select tests for the given inadequacy level.
note that the actual percentage of satisfied requirements may be higher than the given lif no set of tests can achieve the exact value.
.
evaluating reduction algorithms previous research measured the size reduction sizred and the loss in fault detection capability mutloss of each reduced test suite on only one single version .
we propose an approach for evaluating reduction techniques by measuring how the quality of each reduced test suite varies over multiple project versions .
furthermore we propose several other metrics besides killed mutants to better characterize th e quality of the test suite over multiple versions.
we believe that our metrics by accounting for software evolution giv e a better insight into the effectiveness of test suite reduct ion techniques than the previously used metrics give.
as our evaluation introduces a temporal dimension along software versions we extend our previous notation to include this new dimension.
we denote the original test suite at version iasoiand the reduced test suite obtained by a reduction technique on oi at version iasri.
we use ti to refer to any test suite at version i. the function j ti returns the set of requirements satisfied at version jby the test suite ti o j. as earlier stmt mut i.e.
it either returns the set of covered statements or the set of killed mutants.
note that j ti accounts for the tests that were removed between versions iandj ti oj .
in our experiments the tests are considered removed if they are either deleted altogether or renamed moved.
j ti ignores newly added tests i.e.
oj ti because our goal is to evaluate how the quality of the reduced test suite compares relative to the original test suite as software evolves.
in other words if a test engineer needs to decide whether to use the original test suite or the reduced suite what matters is the comparison among those two and not the fact that both of them can be further extended with more tests as software evolves.
finally we introduce a function dist i j that calculates the distance between versions iandj i.e.
j iifiandjare integer version numbers and i j. figure visualizes the computation of values at each version.
columns and rows correspond to the sequence of project versions used to evaluate a reduction algorithm.
fo r each row version i we evaluate j oi and j ri for each column version j. namely we measure the number of statements covered and the number of mutants killed for the original test suite at version i and reduced test suite at version i on version j with version jlater than version iin history.
.
.
impactofevolutiononstatementcoverage we measure how the evolution impacts statement coverage of the reduced test suite with respect to the coverage of the original test suite.
to measure this impact we define statement coverage loss between two project versions.
definition .statement coverage loss between versions iandjis stmtlossj i stmtj oi stmtj ri stmtj oi namely the statement coverage loss measures the ratio of statement coverage missed by the reduced test suite over the statement coverage achieved by the original test suite at the same version or subsequent versions.
in the traditional evaluation approach the statement coverage loss would always be because the original test suite and the reduced test suite achieve the same statement coverage by construction on the current version i and no other versions would be considered.
in other words the traditional approach only considers the diagonal elements from figure .
in contrast our approach measures the statement coverage loss for all versions iandjsuch that dist i j .
we measure the statement coverage loss for the following reasons.
first the statement coverage of the reduced test suite can vary as software evolves.
it is important to quantify the variation and evaluate if the reduced test suit e remains equally good compared to the original test suite a s on version ion which the reduction was performed.
second if test suite reduction is performed using algorithms para meterized with our requirements it is important to evaluate the impact of such reduction on statement coverage and contrast the loss in statement coverage with the loss in killed mutants which we discuss next.
.
.
impactofevolutiononkilled mutants we measure how the killed mutants vary between versions for the original and reduced test suites.
previous researchonly evaluated the effectiveness of the reduced test suite on the version on which the reduction was performed the elements on the diagonal in figure .
the effectiveness was often measured using mutloss .
we introduce the mutants killed loss which measures the impact of evolution on the effectiveness of the original and reduced test suites.
definition .mutants killed loss between two versions i andjis mutlossj i mutj oi mutj ri mutj oi namely the mutants killed loss measures the ratio of mutants not killed by the reduced test suite over mutants kille d by the original test suite at the same version or subsequent versions.
note that by setting i j we get the formula commonly used in the traditional approaches for evaluating test suite reduction techniques.
.
.
relativeevolutionchange to further compare the changes in both statement coverage and killed mutants across different software versions between different projects we introduce relative evolution change rec .
definition .given a test suite reduced at version i the relative evolution change at version jis recj i lossj i lossi i where loss stmtloss mutloss i.e.
rec can be calculated for either statement coverage loss or mutants kille d loss.
rec is defined to be the loss in evolution metrics some number of versions after reduction.
the higher the rec the more loss and therefore the worse the reduced test suite performs compared to the original test suite as the software evolves across versions.
the metric reported for every project is a relation between the reduced test suit e and the original test suite so the rec can be compared across projects.
therefore we can define recd recj i for all iandjsuch that d dist i j i.e.
rec is parameterized only by the distance from the initial reduction.
thi s allows us to compare recdfor various distances across various projects.
our goal is to evaluate the impact of distance on the reduced test suites.
note that recdcan have a positive value or a negative value.
a positive value would indicate that changes had negative impact on the reduced test suite more loss compared to original test suite in a later version .
on the other hand a negative value would indicate a positive impact on the reduced test suite i.e.
the changes cause the reduced test suite to be closer in quality to the original test suite.
we define rec stability as the difference between min and max rec values across all versions considered.
.
evaluation this section describes our evaluation of test suite reduction on a set of medium sized open source projects from github.
we first describe the projects used in our study.
we then describe the results obtained on a single software version as often done in the traditional test suite reduction.
we next describe the results obtained by analyzing reduced test suites as software evolves as proposed in thispaper overall our experiments consider the evolution of t he projects over a total number of commits.
we finally describe the results for inadequate reduction.
we ran all our experiments on a .66ghz intel xeon x5650 machine with 16gb of ram running scientific linux .
and java openjdk bit server version .
.
.
the total machine time to run all our experiments is approximately eight days.
.
implementation we use the pit mutation tool to collect the statement coverage and killed mutants for each test suite.
pit uses mutation operators including these replace numerical co nstant negate conditional replace arithmetic operator a nd remove method calls.
we chose pit because it is somewhat robust and has been recently deployed in industry but we still had to make two modifications to pit to collect all the data required for our experiments.
first we extended pit to collect the full coverage and kill matrices that record fo r each test in the test suite the statements it covers and the mutants it kills.
out of the box pit stops running tests o n a mutant as soon as one test kills the mutant.
however to evaluate test suite reduction we wanted to collect for eac h mutant the set of all the tests that kill the mutant.
that way we can determine which mutants would be killed by various reduced test suites directly from the matrices wit hout rerunning pit on those reduced test suites.
we define a mutant to be killed if a test fails or errors when running on the mutated code pit ignores the cases where the test times out on the mutated code.
second we modified pit to ignore tests that fail on the original not mutated code due to pit instrumentation.
by default pit stops execution when a test fails on the original code.
however to collect data for more projects we changed pit to ignore such tests and to continue execution.
following the traditional literature sources we implemented the greedy ge gre hgs and ilp reduction algorithms that can operate on the collected matrices.
to implement the ilp algorithm we used ibm s cplex optimizer solver version .
.
for baseline comparison we also implemented random reduction that given a test suite and a desired size selects a random subset of the given size from the given test suite.
we create random test suites of the same size as the reduced test suites created by the other reduction algorithms givi ng a random test suite corresponding to each reduced test suite .
.
projects as subjects of our evaluation we select java projects from github that are built through maven .
we focus on maven projects to simplify the automation of running mutation testing using pit as pit integrates well with maven.
initially we downloaded the most popular java projects on github and selected the projects that satisfy these four conditions the project uses maven out of the software history of the project has more than commits out of pit can successfully run tests on the latest version of the project3 out of i.e.
without crashing or reporting an internal error and after running pit over several commits from the project and eliminating runs for which pit failed the project should have at least four data points out of .
3in git the version we used is head of the master branch.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
loc tests mutants mut score project ver min med max min med max min med max min med max commons lang .
.
.
assertj core .
.
.
square wire .
.
.
jasmine .
.
.
dropwizard .
.
.
gs collections .
.
.
scribe java .
.
.
cloudera ml .
.
.
caelum v raptor .
.
.
cloudfoundry .
.
.
la4j .
.
.
jodatime .
.
.
messagepack .
.
.
slf4j .
.
.
jopt simple .
.
.
java apns .
.
.
caelum stella .
.
.
sql parser .
.
.
mean over ver .
figure statistics of projects used in our experimentsrand sar rand mar rand smar sar mar smar sirmar mir sarsizredmin .
.
.
.
.
.
.
.
med .
.
.
.
.
.
.
.
max .
.
.
.
.
.
.
.8stmtlossmin .
.
.
.
.
.
.
.
med .
.
.
.
.
.
.
.
max .
.
.
.
.
.
.
.5mutlossmin .
.
.
.
.
.
.
.
med .
.
.
.
.
.
.
.
max .
.
.
.
.
.
.
.
figure sizred stmtloss and mutloss for different requirements using greedy algorithm in the end we obtained projects and we refer to their commits for which we collected data as versions .
overall we collected data for a total of versions from all projects.
we select each version by counting backwards commits at a time from the head commit of each project4up to versions per project.
a project may have fewer than versions if either it did not use maven in the past or pit starts failing at an earlier commit.
if the project does not build or work with pit at some commit we go back one commit at a time until we obtain a version that works.
note that we regenerate new mutants for every software version.
we do not sample mutants but rather use all mutation operators available in pit.
after collecting data for all versions for a project we automatically remove from each version the tests that were manually renamed moved in subsequent versions.
figure shows for each project the number of versions used in our experiments along with some statistics about them.
columns show the min median and max lines of 4we consider only commits on the master branch to properly track the main linear software evolution.code for the project across the versions used in the experiments obtained using sloccount .
columns show min median and max number of tests across the versions used in the experiments.
columns show min median and max number of mutants generated by pit.
the last three columns show min median and max mutation score as reported by pit.
the last row in figure shows mean values across all versions.
.
singleversionevaluation in this section we report the quality of the reduced test suites by sizred stmtloss and mutloss for a single software version at a time i.e.
diagonal elements in figure .
figure summarizes the results.
the values are calculated across all projects.
sar mar and smar columns show the values obtained by the greedy algorithm using covered statements killed mutants or both as requirements respectively.
the values for other algorithms differ only marginally we further discuss difference between algorith ms in section .
we compare the greedy algorithm instances for various requirements among each other and with our baseline random reduction.
we consider three randomly reduced test suites with the same sizes as the sizes of test suit es reduced through the greedy algorithm with the various requirements.
we denote the algorithm on which the size is based in the subscript e.g.
rand maris random selection with the same size as greedy with mar requirements .
random reduction the rand columns in figure show that random reduction performs worse than greedy regardless of the requirements.
with the substantial loss in state ment coverage and killed mutants of up to .
and .
respectively we use random reduction only for research com parison and do not suggest its use in practice.
adequate reduction as anticipated sar and smar achieve the same statement coverage as the original test suite while mar and smar achieve the same killed mutants as the original test suite.
statement coverage for mar can be less than the original ranging from .
to .
median of .
loss in statement coverage.
for sar the original loss in killed mutants ranges from .
to .
version distance 2024rec of stmtloss version distance 202rec of mutloss mirsarsirmarsmarmarsar figure rec for stmtloss left and mutloss right for suites reduced randomly at the same size of their corresponding greedy reduced test suites version distance 2024rec of stmtloss version distance 1012rec of mutloss mirsarsirmarsmarmarsar figure rec for stmtloss left and mutloss right for suites reduced using greedy median of .
.
based on these metrics smar achieves the best for both requirements having no initial loss in statement coverage or killed mutants.
the size of the test suites shows that sar gives the largest reductions in testsuite size ranging from .
to .
median of .
.
smar gives the smallest reductions in test suite size rang ing from .
to .
median of .
.
mar reductions in test suite size fall between the other two ranging from .
to .
median of .
.
considering that the most widely used traditional metric to evaluate the qual ity of reduced test suites is killed mutants we believe that using mar is preferred over sar mar achieves high killed mutants with good size reduction.
however considering that smar has only a median of .7pp loss in reduction of test suite size compared to mar while smar achieves maximum in both requirements we believe smar could be the best approach to test suite reduction if sufficient resources are available to run the reduced test suites.
in summary the loss in killed mutants for the traditional sar does not rise above .
.
in comparison with someprior studies that found significant losses around in most cases in fault detection capability on the version of reduction our results show that testsuite reduction has less significant losses on killed mutant s similar as reported by some other studies .
.
evolution aware evaluation following the methodology described in section we evaluate how different test suite reduction techniques perform over versions of all projects.
similar to the previous section we compare the greedy algorithm instantiated for various requirements with our baseline random reduction.
we compare the rec trends for all these techniques by comparing the stability of rec values.
to show the distribution of recs we use boxplots.
each boxplot figures and shows a distribution of recs for all projects for one of the distance values the i th boxplot shows distribution of all rec i. we use redts bluets and orangetsto illustrate how the number of killed mutants of the reduced test suite varies as software evolves for sar mar and smar respectively.figure pairwise value comparison for statement coverage left and mutants right over versions for greedy reduced test suites the light blue tsand yellow tsboxplots are for mir and sir as described later.
random reduction figure shows the rec trends for the randomly reduced test suites.
the left and right plots in figure show trends for statement loss recs and mutant loss recs respectively.
we cut the boxplots to only show over the whiskers for better visualization.
first we can observe that random reduction variants i.e.
various targeted size achieve similar stability.
second rec of statement coverage is less stable than rec of killed mutants for all three sizes considered.
while statement cover age can be more significantly affected 8pp to 4pp rec of killed mutants changes less as software evolves 6pp to 2pp .
this surprising result higher stability illustrates tha t the killed mutants of reduced test suites are not influenced even after a large number of commits.
adequate reduction figure shows the rec trends for sar mar and smar that use the greedy algorithm the left and right plots in figure show trends for statement loss and mutant loss recs respectively.
we noticed similar to random reduction that rec for statement loss ranging from 4pp to 4pp is less stable than rec for mutant loss 3pp to 2pp .
for all requirements used for reduction the overall trend is a slight increase in loss over versions.
surprisingly although sar starts at a lower leve l of killed mutants it is on average slightly more stable than mar and smar.
for all of sar mar or smar the loss in killed mutants is at most .76pp from the initial loss in killed mutants due to reduction regardless of which type of reduction is performed.
figure additionally summarizes the comparison of all techniques across multiple versions of all projects.
for ea ch evolution point i.e.
each element in the matrix in figure we do a pairwise comparison of sar mar and smar and measure how many times each is better dominant equal or worse than the other.
similar to our previous conclusions we conclude that in terms of killed mutants mar and smar are the best techniques to use.
.
inadequate reduction finally we compare inadequate reduction section .
with random and adequate reduction.
we perform two inadequate reductions sir maris coverage based reduction targeting the same statement coverage as achieved by mar and mir saris mutant based reduction targeting the same percentage of killed mutants as achieved by sar.
fig figure reduction in size for inadequate test suites ure includes values for sir marand mir sarat a single software version last two columns .
further figures and include stability for inadequate reduction.
we use light bl uetsand yellowtsfor sir and mir respectively.
although the test suites produced by inadequate reduction are similarly stable as test suites produced by other reduction algorithm s figures and these test suites lead to higher initial los s in killed mutants and statement coverage figure .
to further explore the trade offs of inadequate reduction we evaluated how it targets a range of values for sizes of reduced test suites.
figure shows how the size of a reduced test suite changes based on the amount of loss in requirements we set for inadequate reduction.
the horizontal axis shows the inadequacy level for the requirements we set for the reduction algorithm and the vertical axis shows the reduction in the test suite size compared to the original tes t suite .
the boxplots are drawn from data gathered from reducing on all projects and versions.
we find that for adequate reduction the size of the reduced test suite is media n of .
of the original test suite size first boxplot by dropping down to of the requirements the reduction in size of the reduced test suite can increase .14pp third boxplot .
further decreases in the inadequacy level reduce s the size of the reduced test suite even more eventually reducing .25pp from the median reduction in test suite size of the adequately reduced test suite when only of the requirements are satisfied.
at an extreme of the median of reduction in test suite size goes up to .
which is .90pp more reduction in size than the adequately reduced test suite.
these trends are seen in both statement coverage and killed mutants requirements.
additional results due to space constraints we only report detailed results for greedy algorithm.
additional results for other algorithms along with details about the projects and versions that we used can be found at .
discussion reduction algorithms while the previous section reported and visualized values obtained by running greedy algorithm we also evaluated other algorithms mentioned in section i.e.
ge gre hgs and ilp .
we found that they produce very similar results to greedy.
across all algorithms we found the difference in size reduction to be at most .26pp for all types of requirements.
furthermore the difference in stmtloss for algorithms that use mar is atfigure correlation between code change and rec of mutation score loss for greedy mar most .15pp and the difference in mutloss for algorithms that use sar is at most .15pp.
for stability we found that the median rec i at every distance i varied by at most .33pp for mutloss and .67pp for stmtloss across all algorithms.
sir and mir we instantiate and evaluate sir and mir with inadequacy levels based on the statement coverage and killed mutants results of mar and sar respectively.
we choose to set the inadequacy to these levels to compare how the inadequately reduced test suites compare to the adequately reduced test suites i.e.
comparing the killed mutants of a test suite with the same statement coverage as a mar test suite that has no loss in killed mutants.
code change vs. loss we quantify how the amount of code change correlates with loss in requirements satisfied by the reduced test suite.
definition .we quantify code change between two versions iandjby using normalized change ccj i removedj i addedj i sloc i where i j where removedj iandaddedj irepresent the number of removed and added lines respectively between versions iand j. we obtained these values by using git s diff command.
sloc irepresents the total number of source lines of code at version i. figure plots the correlation between the amount of code change and the rec for killed mutants.
the x axis shows thecc and the y axis shows the rec for mutloss .
we use different colors for each distance e.g.
for all ccj i recj i for which dist i j is i.e.
subsequent versions we use green.
we also measure the correlation between the amount of change and rec for stmtloss andmutloss .
we computed coefficient of determination r2 spearman s and pearson s coefficients for all algorithms.
the data shows a weak correlation between change and recs.
across all algorithms and reduction criterion r2varies between .
and .
spearman s coefficient varies between .
and .
and pearson s coefficient varies between .
and .
.
statement loss for mar we find that mar may not achieve the same statement coverage as the original test suite.
this can happen for several reasons.
first there might be statements that cannot be mutated by any mutation operator.
second although reached some mutants might not be killed by the original test suite e.g.
a mutant is equivalent or there is no test oracle that fails .
in eithe r of the two cases it can happen that some statements arenot covered by a test suite produced by mar although the original test suite covers them.
.
threats to validity external projects and tools our results may not generalize to projects beyond the scope of those used in our evaluation.
to mitigate this threat we considered actively developed projects with real evolution from github.
although we excluded some projects due to the fact that pit could not run their tests we used projects that vary in size number of developers number of tests and mutation score .
.
.
several of the projects used in our study are larger and include more tests than any project used in previous studies on test suite reduction .
we used pit to collect statement coverage and perform mutation testing.
the results might not be generalizable to other tools that perform similar functionality e.g.
javalanche or major .
we used pit because it scales to large projects and major was not available at the time of our study.
in addition pit has been used in research and in industry most notably in the apache lucene project .
internal correctness of our implementation to the best of our knowledge no implementations of the testsuite reduction algorithms mentioned in section .
are pub licly available.
therefore we implemented those algorith ms ourselves following the usual literature .
to ensure the correctness of our implementation we inspected the results of several small runs wrote unit tests and peer reviewed our code.
construct metrics and versions we measure the fault detection capability of test suites using mutation s core.
although mutants are not real software faults previous research has shown that a test suite s ability to kill mutants can highly correlate with its ability to reveal actual software faults .
another threat is that we do not identify and remove equivalent mutants generated by pit.
note however that the users of a mutation testing tool would likely not identify equivalent mutants either and would bas e their evaluation of the test suites on all generated mutants .
measuring statement coverage loss for sar and mutants killed loss for mar may bias the results.
to mitigate this threat we measure reduction in size statement coverage loss and mutants killed loss regardless of the reduction te chnique used.
in addition we measure these values at multiple versions that are far apart .
we assume mutants approximate real faults on a single version .
therefore as we regenerate mutants on future versions we expect the stabil ity of the real faults detected loss to mirror the stability of the mutants killed loss.
previous research on test suite reduction has used different kinds of code coverage to perform reduction.
we compare with the traditional approach to test suite reduction using only statement coverage.
however statement coverage is the most commonly used criterion in practice and it is widely used in research on test suite reduction .
we define a version for a project to be commits which covers a significant portion of software evolution history f or the projects we used in our evaluation.
regardless of the difference in scale of changes for versions between different projects our conclusions remained the same.
.
related work elbaum et al.
investigated the effect of software evolution on coverage.
while we also measure how coverage is impacted by software evolution we do this for reduced test suites.
our findings on reduced test suites seemingly contradict theirs on original test suites we find that covera ge of reduced test suites relative to the original test suite is not greatly impacted by the changes note that this can hold even if the absolute values of both reduced and original test suites are greatly impacted by the changes.
previous studies on test suite reduction find conflicting re sults on the fault detection capability of reduced test sui tes.
wong et al.
reported insignificant losses in faultdetection capability when performing test suite reductio n on small programs.
zhang et al.
also found small losses in test suite reduction evaluated on java programs from the software infrastructure repository .
in contrast rothermel et al.
found significant losses in faultdetection capability in their evaluation on the same programs that wong et al.
used.
our results show that testsuite reduction does not significantly impact killed mutant s for the projects we studied.
we find the loss in killed mutants does not vary due to software evolution either.
our evaluation was conducted on a large number of actively developed real java projects downloaded from github as opposed to curated projects from the software infrastructure repository.
our choice of using mutants and projects could explain some differences between our results and the results of previous research.
previous research also looked into improving the faultdetection capability of reduced test suites by adding in extra tests beyond those necessary to preserve code coverage requirements.
jeffrey and gupta suggested adding in extra tests which cover a secondary set of requirements e.g .
reducing first based on requirements defined by block coverage but then adding in tests that satisfy a set of requirement s defined by def use coverage.
lin and huang proposed adding tests based on a secondary set of requirements only when breaking ties in traditional reduction algorithms.
ou r smar technique is similar to these previously proposed algorithms in that we use a secondary set of requirements to gain higher quality reduced test suites.
however we use killed mutants as another set of requirements as opposed to some other type of structural code coverage.
previous research also considered fault detection capabi lity to some degree when performing test suite reduction.
black et al.
proposed a bi criteria ilp solution to test suite reduction.
while the ilp formulation they proposed would find a minimal set of tests that cover all statements it could be configured to take seeded faults into account.
their ilp algorithm can be used to add tests known to detect at least one fault.
at the extreme all tests which are known to detect faults would be added to the reduced test suite.
hao et al.
proposed a reduction algorithm that seeks to reduce the loss in killed mutants.
they collect statistics abo ut killed mutants on the individual statement level of various programs and apply those statistics to perform reduction using an ilp formulation.
we differ from both these algorithms in that we directly reduce based on killed mutants as requirements we remove redundant tests based on mutants unlike the bi criteria ilp algorithm which keeps redundant tests and we directly apply killed mutants instead of using statistics about them.yoo and harman proposed and evaluated paretooptimal multi objective algorithms for regression testin g that explored the pareto frontier where a specified requirement could be set to an inadequate level.
while they mainly focused on test suite selection and prioritization their wo rk can be applied to inadequate reduction as well.
moreover they considered multiple metrics code coverage executio n cost and fault history while we use only statement coverage and killed mutants as our requirements.
more generally inadequate reduction is similar to test prioritization or u nsafe test selection that execute only a subset of tests from t he original test suite.
for example elbaum et al.
evaluat ed a number of prioritization techniques including two that u se fault exposing potential based on mutants.
our evaluatio ns based on sar and smar are larger than any previous evaluation and we are the first to consider evolution effects on inadequate reduction.
offutt et al.
described a test suite reduction algorith m called ping pong which relied on mutation testing.
the algorithm orders the tests in the test suite based on heuristic s and runs the tests in those orders until all mutants are kille d. their work uses mutants as requirements for test suite reduction but the ping pong algorithm does not compute all the mutants killed by each test rather it computes only the additional previously non killed mutants that are kille d by each test when run.
in contrast sar and smar use the full test to mutants killed matrix to compute the reduced test suites.
although computing the full matrix is more expensive the reduced test suites that sar and smar compute cannot be larger than the ones computed by ping pong.
.
conclusions we evaluated several trade offs in test suite reduction algorithms that balance the goals of high reductions in size and small losses in code coverage and fault detection capability.
specifically we evaluated adequate test suite red uction with requirements defined by killed mutants evaluated inadequate reduction that conducts reduction without satisfying all the requirements as the original test suite and introduced novel evaluation metrics based on software evolution.
we performed an extensive evaluation on projects with tests commits and representing year s of total development time.
we find that the reduction based on killed mutants is more attractive because it produces reduced test suites with the same stable killed mutants as the original test suite but it does have slightly larger reduce d test suites compared to the reduction based on statement coverage.
in addition inadequate reduction can achieve si gnificantly higher reductions in test suite size.
finally w e find test suite reduction algorithms to be robust to softwar e evolution regardless of requirements used.
.