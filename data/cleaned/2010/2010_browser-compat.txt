automated cross browser compatibility testing ali mesbah electrical and computer engineering university of british columbia vancouver bc canada amesbah ece.ubc.camukul r. prasad trusted systems innovation group fujitsu laboratories of america sunnyvale ca usa mukul.prasad us.fujitsu.com abstract with the advent of web .
applications and new browsers the cross browser compatibility issue is becoming increasingly important.
although the problem is widely recognized among web developers no systematic approach to tackle it exists today.
none of the current tools which provide screenshots or emulation environments speci es any notion of cross browser compatibility much less check it automatically.
in this paper we pose the problem of cross browser compatibility testing of modern web applications as a functional consistency check of web application behavior across di erent web browsers and present an automated solution for it.
our approach consists of automatically analyzing the given web application under di erent browser environments and capturing the behavior as a nite state machine formally comparing the generated models for equivalence on a pairwise basis and exposing any observed discrepancies.
we validate our approach on several open source and industrial case studies to demonstrate its e ectiveness and real world relevance.
categories and subject descriptors d. .
testing and debugging general terms reliability veri cation keywords dynamic analysis web testing cross browser compatibility .
introduction web applications pervade all aspects of human activity today.
the web browser continues to be the primary gateway channeling the end user s interaction with the web application.
it has been well known for some time that di erent this author was a visiting researcher at fujitsu laboratories of america when this work was done.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
icse may waikiki honolulu hi usa copyright acm ... .
.web browsers render web content somewhat di erently .
however the scope and impact of this problem has been rapidly growing due to two fairly recent trends.
first modern rich content web applications have a heavy client side behavioral footprint i.e.
they are designed to execute signi cant elements of their behavior exclusively on the client side typically within the web browser.
further technologies such as ajax flash and event handling for dynamic html which support this thick client behavior are the very aspects in which web browsers di er.
second recent years have seen an explosion in the number of available web browsers.
there are nearly di erent web browsers available today .
coupled with the di erent kinds and versions of operating systems in which these operate this yields several hundred di erent client side environments in which a web application can be used each with a slightly di erent client side rendering of the application .
in the context of the above problem the key contributions of this paper are we de ne the cross browser compatibility problem and present an in depth discussion of the issues surrounding possible solutions to it.
we present a systematic fully automated solution for cross browser compatibility testing that can expose a substantial fraction of the cross browser issues in modern dynamic web applications.
we validate our approach on several open source as well as industrial case studies to demonstrate its e cacy and real world relevance.
the rest of the paper is organized as follows.
in the next section we discuss the genesis of the cross browser compatibility problem and how it plays out in modern web applications.
we present a formal characterization of the problem and put the solutions o ered by this paper in that context.
section reviews related work on cross browser testing.
in section we present our proposed approach for performing cross browser compatibility testing followed by a description of the salient implementation aspects of that approach in section .
section presents an empirical evaluation of our approach on some open source as well as industrial case studies.
in section we discuss the strengths and weaknesses of our solution and lessons learnt from our experience.
we conclude the paper in section .
.
cross browser compatibility problem genesis.
the cross browser compatibility cbc problem is almost as old as the web browser itself.
there are several reasons for its genesis and growth in recent years.
the earliest instances of this problem had a rendering in ie .
.
b rendering in firefox .
.
figure cbc issues in an industrial web .
application missing widgets in firefox.
its roots in the parallel evolution of di erent browsers and the lack of standards for web content.
currently standards do exist for basic web content e.g.
html .
and for scripting languages such as javascript jscript and actionscript e.g.
ecma .
however in their bid to be inclusive and render websites that do not adhere to these standards e.g.
legacy websites web browsers typically implement their own extensions to the web standards and in so di er in their behavior.
the explosive growth in the number of browsers and client side environments has only exacerbated this issue.
in addition modern dynamic web applications execute an increasingly bigger fraction of their functionality in the client tier i.e.
within the end user s web browser thus further amplifying di erences in observed behavior.
cross browser compatibility is widely recognized as an important issue among web developers but hardly ever addressed directly during the software development process.
typically web applications are developed with a single target client side con guration in view and manually tested for a few more as an after thought.
look and feel versus functionality.
the common perception is that the cbc problem is con ned to purely look and feel di erences on individual screens.
while that was indeed the case for the previous generation of web applications the problem plays out in a more systemic functional way in modern web .
applications.
thus we believe that the issue should be addressed as a generalized problem of checking functional consistency of web application behavior across web browsers rather than purely a look and feel issue.
this view is also held by several web developers .
the following scenario illustrates how the problem plays out in modern web applications.
the human end user interacts with the web application through the browser by viewing dynamically served content and responding with userevents e.g.
clicks mouse overs drag and drop actions and user data e.g.
form data or user authentication data .
the client side machine in turn interacts with the serverside tiers of the web application by sending requests to it based on the user input and the web application workow.
the server side responds with new web content which is served by the client machine to the user through the browser.
di erences in the serving of a particular screen on the web browser can in uence the set and nature of actionable elements available on that screen which can in uence what actions the user can and does take on the current screen.
this can have a cascading e ect by altering requests sent b browser level observable differencesa dom and or trace level differences differences differences d differences detected by proposed methodc ideal set of differences to detect yppfigure browser incompatibility landscape.
from the client tier to the server tiers the response received and subsequent content served on the client thus in uencing the overall evolution of the web application on the client side.
figure shows screen shots taken from a real enterprise proprietary web .
application illustrating this scenario.
while the application renders correctly in internet explorer the firefox rendering of it is missing the new user anddelete user widgets marked with a red eclipse in ie.
thus the human user would be unable to exercise these features from this screen thereby completely removing a very important set of behaviors namely the application administrator being able to add and remove users from the evolution of the web application under firefox.
problem de nition.
our working de nition of the cbc problem for the purposes of this paper is based on the venn diagram of figure .
the set bdepicts those crossbrowser di erences that can be observed by the human user on the web browser while the set arepresents those crossbrowser di erences that are re ected as di erences in the client side state of one or more screens e.g.
di erences in the dom representation or css properties of various dom elements or di erences in the set of possible traces i.e.
alternating sequences of screens and user actions on the client side.
further there is the set of di erences b a which can be visually observed by the user but is not reected as a di erence in the client side state or in the evolution of that state.
these di erences are typically though not necessarily stylistic and stem from di erent browsers rendering of identical web content e.g.
css les .
although such di erences are important in their own right they are not the focus of this paper.
there is also the set a b of di erences which exist in the dom representation but do not result in any user observable di erences in behavior.
we argue that these di erences are not relevant since the nal metric of incompatibility is that which can be observed by the end user.
the set c a b which comprises the di erences re ected in both the user observable behavior as well as the underlying client side state represents the most interesting target for our technique.
however as explained below in section typically the set of di erences detected by our technique is a set d wherec d a. .
related work currently there are several tools and services both opensource and commercial that claim to address the problem of cross browser compatibility checking.
they fall under two broad categories namely tools capturing screenshots.
these web services can capture and provide screen shots of how a particular 1we veri ed that this was an issue of dom level di erences not simply one of screen resolution or the size of the browser window.url speci ed by the user would be rendered under various client side platform combinations of speci c browsers operating system and screen resolutions.
typical o erings include ie netrenderer and iecapture which focus on internet explorer as well as others like browsershots browsercam browser photo and litmus which include a broader set of browser os combinations.
tools providing emulation environments.
these tools and web services o er a slightly more advanced functionality than the previous category in that they allow the user to interact with a particular web application as if it were being served on a particular client platform browseros combination .
representatives in this category include adobe browserlab and crossbrowsertesting.com which span a wide variety of client side platforms as well as more speci c ones like browsercamp targeted for mac os x browsers xenocode browser sandbox for windowsbased environments ietester which is speci c to ie and iphoney which is an emulator for the iphone platform.
the o erings in both of the above categories su er in varying degrees from the following fundamental limitations .compatibility checking none of the above tools speci es any notion of cross browser behavioral compatibility much less check it automatically.
it is left to the human user to de ne their own notion of compatibility and validate it on observed behavior usually manually.
this makes the whole process very ad hoc and hence the quality of the check itself very suspect.
.behavioral coverage modern dynamic web applications display rich stateful behavior which cannot be adequately covered with a few screenshots or manual examination of a few traces.
the above solutions do not provide any automatic method of systematically and comprehensively exploring web application behavior.
such an exploration is typically needed to expose bugs embedded deep in the web application workow.
.scalability since the process of actually browsing the web application under di erent environments and comparing observed behavior is completely manual it is di cult to apply the tools to several browser os platforms in a consistent repeatable manner.
the acid tests developed under the web standards project present a complementary approach towards achieving cross browser compatibility.
the acid tests are a battery of tests that check a given browser for enforcement of various w3c and ecma standards.
however the fact that almost all common browsers fail some and sometimes most of these tests2is another indication that crossbrowser compatibility issues will continue to exist in the foreseeable future.
a related e ort in this category is the sputniktests project which provides a conformance test suite to check javascript engines for ecmascript compliance.
these approaches are complementary to ours since they check web browsers or their component engines for standards compliance rather checking the real time behavior of a speci c web application of interest.
another related body of work is that of gui testing .
indeed web applications can be seen as a special class of general gui based applications.
however the speci c architecture execution environment the web browser implementation technologies javascript ajax and api standards w3c html css dom of web applications allow us to employ a simple nite state machine model and develop very e cient equivalence checking algorithms around 2ie8 scores on the acid3 test .it whereas use gui forests eventow graphs and integration trees.
eaton and memon presented one of the rst techniques for automated identi cation of cross browser issues on speci c web pages.
their technique identi es potentially problematic html tags on a page using a user supplied manually generated classi cation of good and faulty pages.
concurrent to our work choudhary et al.
have proposed thewebdiff tool which analyzes the dom as well as screen shots of pairs of screens to automatically locate crossbrowser issues.
in both these papers the focus is on identifying cross browser di erences in individual screens.
in contrast our approach also identi es more systemic crossbrowser issues that manifest in the overall trace level behavior of the web application.
thus these techniques are somewhat complementary to our work.
.
our approach our overall approach consists of a two step process.
the rst step is to automatically crawl the given web application under di erent browser environments and capture and store the observed behavior under each browser as a nitestate machine navigation model .
the crawling is done in an identical fashion under each browser to simulate exactly the same set of user interaction sequences with the web application under each environment.
the second step consists of formally comparing the generated models for equivalence on a pairwise basis and exposing any observed discrepancies.
the crawling technology i.e.
model generation process the generated model and the equivalence check are discussed in more detail in the following sections.
.
state space exploration our approach for automatically exploring the web application s state space is based on the crawljax work.
crawljax is a crawler capable of exercising client side code detecting and executing doorways clickables to various dynamic states of modern ajax based web applications.
by ring events on the user interface elements and analyzing the e ects on the dynamic dom tree in a real browser before and after the event the crawler incrementally builds a state machine capturing the states of the user interface and the possible event based transitions between them.
crawljax is fully con gurable in terms of the type of elements that should be examined or ignored during the crawling process.
for more details about the architecture algorithms or capabilities of crawljax the interested reader is referred to .
we have extended crawljax in several ways to apply it to the cbc problem.
this is discussed in section .
.
the navigation model the navigation model produced by crawling the web application is a nite state machine.
the states represent the screens observed by the end user on the web browser and the transitions represent user actions e.g.
a button click that cause the web application to transition from one screen to another.
each transition is labeled with the user action that caused it.
each state screen is represented by its underlying programmatic representation as viewed by the web browser.
for the purpose of meaningfully and e ciently comparing multiple navigation models we found it useful to view and analyze the navigational model hierarchically.
the top level is a graph representation of the nite state machine with the states screens represented merely as unnamed vertices.
we refer to this as the state graph .
at the second level is the full programmatic representation ofeach screen state which we refer to as the screen model of the state.
these are formally de ned below.
conceptually the state graph captures the set of traces i.e.
alternating sequences of user actions and screen transitions without referring to the details of each screen whereas the screen model of each screen captures precisely this detail but without any knowledge of transitions leading up to or out of the screen.
de nition state graph a state graph gis a labeled directed graph with a special designed start vertex.
it is denoted by a tuple g v e o l wherevis the set of vertices ethe set of directed edges othe special designated start vertex an alphabet of labels and l e!
is a labelling function that assigns a label from to each edge.
further ghas the following speci c characteristics .
each label from can appear on at most one outgoing edge from a given vertex i.e.
no vertex can have two or more outgoing edges with the same label although the same label can appear on multiple edges in the overall graph.
.gcan have multi edges i.e.
9e1 e22e s e1 s e2 andd e1 d e2 .
.
each node in vis reachable from the root r i.e.
gis composed of a single connected component.
.gcan be cyclic.
the special node otypically denotes the start or index screen state of the web application.
for an edge e u v we refer to its source vertex ubys e and destination vertex vbyd e .
we useout v andin v to denote respectively the set of outgoing and incoming edges of vertex v. de nition screen model a screen model tis a rooted directed labeled tree.
it is denoted by a tuple t q d r whereqis the set of vertices dis the set of directed edges r2qis the root vertex is a nite set of labels and q!
is a labelling function that assigns a label from to each vertex in q. in our current implementation the screen model is essentially an abstracted version of the dom tree of a given screen displayed on the web browser.
note that this model could easily be generalized to include and compare other aspects of the client side state such as javascript variable values or css properties.
q d andrhave obvious meanings in terms of the dom tree.
the label of a particular node is a combination of the html tag name of the dom node as well as a set of name value pairs representing the attributes of the dom node.
we use a single label as a convenient abstraction for these multiple pieces of data in order to formalize the model and the equivalence check performed on it section .
.
details of the actual implementation are discussed in section .
.
equivalence checking the equivalence check of the navigation models mirrors our hierarchical view of them.
we rst extract the state graph models from the respective navigation models and compare them at a trace level.
this provides a set of tracelevel di erences between the two navigation models i.e.
a set of traces that exist in one model and not in the other and vice versa.
it also pairs up each screen in the rst model with its most likely counter part in the second model.
next candidate matching pairs of screens produced by the rst step are compared in terms of their underlying dom representations.
this unearths detailed screen level di erencesalgorithm .
modelequivcheck m1 m2 g1 stategraph m1 g2 stategraph m2 if traceequivcheck g1 g2 false then outtracediff g1 g2 v1 vertices g1 for each v12v1 do8 if v1 match6 null then8 v2 v1 match t1 getscreen m1 v1 t2 getscreen m2 v2 if scrnequivcheck t1 t2 false then outscrdiff t1 t2 whose e ects may be con ned to the individual screen or may play into trace level di erences.
our proposed method attempts to prune out some of the provably benign di erences discussed in section .
note that providing a detailed diagnosis for the cause of each observed di erence is beyond the scope of this work at its current state.
algorithm .
is the overall algorithm for matching a pair of navigation models m1andm2 generated through the crawling.
the function stategraph returns the underlying state graph which is an input to the traceequivcheck algorithm .
.
traceequivcheck checks and annotates the two graphs.
it returns false if g16 g2.outtracediff extracts trace level di erences from the annotated graphs.
v1is the set of vertices from g1.
the function getscreen extracts and returns the detailed screen representation of a vertex vof a state graph from its corresponding navigation model.
this is used for the equivalence check scrnequivcheck done by the screen matching algorithm explained later.
the function outscrdiff extracts and presents these screen level di erences to the user.
trace equivalence check.
the notion of trace equivalence on state graphs and the precise algorithm to perform such a comparison are discussed in the following.
de nition trace equivalence given state graphs g1 v1 e1 o1 l1 andg2 v2 e2 o2 l2 g1andg2 are said to be trace equivalent denoted as g1 g2 if and only there exists a bijective mapping function m v1!v2 such that the following are true .8u v2v1 u v 2e1 m u m v 2v2 .8e1 u1 v1 2e1 e2 u2 v2 2e2such thatm u1 u2andm v1 v2 l e1 l2 e1 .m o1 o2 algorithm .
implements the trace level equivalence check on the state graphs g1andg2as an isomorphism check.
the function out v returns the set of outgoing edges of vertexv label e returns the label of edge eand the functionlookup l edgeset returns an edge having the label l from the set of edges edgeset ornullif none exists.
dest e returns the destination vertex of edge e. it is assumed that thematch eld of each edge and the visited eld of each vertex is initialized to false and the match eld of each vertex in is initialized to null ing1andg2 .
the above algorithm is a simple variant of depth rst search and linear time in the sizes of g1 g2i.e.
o jv1j jv2j je1j je2j .
it is important to note here that we have chosen to use the same alphabet of labels for bothg1andg2 in order to develop and present the theoretical under pinnings of our approach.
however in practice edge labels representing otherwise identical transitions also have cross browser differences.
our tool implementation described in section algorithm .
traceequivcheck g1 g2 procedure match u1 u2 u1 visited true u2 visited true u1 match u2 u2 match u1 for each e12out u1 do8 e2 lookup label e1 out u2 if e26 null then8 v1 dest e1 v2 dest e2 if v1 visited false v2 visited false then8 e1 match true e2 match true edgect match v1 v2 else if v1 match v2 v1 visited true v2 visited true then e1 match true e2 match true edgect main global edgect edgect o1 startvertex g1 o2 startvertex g2 match o1 o2 if edgect je1j je2j then return true comment g1 g2 else return false comment g16 g2 uses a set of abstractions and transformations to reconcile these di erences and establish edge label equivalence.
theorem algorithm .
returns g1 g2 if and only if they are trace equivalent according to de nition .
we have not included the formal proof of the above theorem and others below in the paper due to space constraints.
however the interested reader can nd them at this link.
in the case where algorithm .
nds that g16 g2 consider the sub graphs implied by the partial match produced by the algorithm i.e.
the sub graph implied by all nodes and edges that were matched to a counter part in the other graph.
speci cally consider subgraph g0 v0 e0 o1 l0 ofg1 wheree0 fe2e1 e match trueg v0 fv2 v1 v match6 nullg l0 e0 !
andl0 e l1 e 8e2 e0 .
the implied sub graph g0 2ofg2 v0 e0 o2 l0 can be similarly de ned.
as the following theorem states subgraphsg0 1andg0 2are indeed valid state graphs themselves and trace equivalent as per de nition .
theorem when algorithm .
certi es g16 g2the subgraphsg0 1andg0 2induced by the partial match computed by it are valid state graphs and trace equivalent as per the criteria of de nition .
further it can be shown that when algorithm .
returns g16 g2 it not only produces a trace equivalent partial match but actually a maximal partial match i.e.
there do not exist a pair of edges e1ande2 wheree12e1bute162e0 ande22e2bute262e0 2which can be added to g0 1andg0 respectively along with their source and sink nodes such that the resulting graphs would also be trace equivalent.
theorem ifg16 g2 the trace equivalent partial matches g0 1andg0 2computed by algorithm .
are maximal matches.
3url for proofs of the above theorems fujitsulabs.com mprasad 2b5b385a6d proofs.pdfnote that although the algorithm computes maximal matches it is easy to show by a simple example that the match need not be the maximum match possible.
it is possible to have a variant of algorithm .
that back tracks on matching decisions made in order to compute the absolute maximum match.
in our experience the maximal match computed by the linear time algorithm above is su cient for most practical purposes.
screen equivalence check.
since the screen model is represented as a rooted directed labeled tree de nition it is natural to compare two given screen models t1andt2 based on the isomorphism of the respective trees.
thus screen models t1 q1 d1 r1 andt2 q2 d2 r2 are said to be equivalent denoted t1 t2 if and only if there exists a bijective mapping n q1!q2such that .n r1 r2 .8q2q1 q n q .8u v2q1 u v 2d1 n u n v 2d2 since screen models are rooted labeled trees screen matching the function call scrnequivcheck t1 t2 in algorithm .
can be performed in linear time by a simple variant of the tree isomorphism algorithm originally due to aho hopcroft and ullman .
however our implementation is built upon a more contemporary solution to this problem that respects the special syntax and structure of dom trees.
further details of this check are presented in section .
.
tool implementation we have implemented our cbc testing approach in a tool called crosst which comprises two components.
for the state exploration component we have used and extended on the open source ajax crawler crawljax .4the input consists of the url of the web application under examination a list of supported browsers ie firefox and chrome and a list of user interface elements for inclusion and exclusion during the crawling execution.
using the given settings the web application is crawled in each of the browsers and the inferred navigation model is serialized and saved into the le system.
the implementation of the navigation model itself is based on the jgrapht5library.
the nodes are state abstractions in terms of the browser s dom tree and the edges are comprised of the dom elements and event types that cause state transitions.
in the second component the saved navigation models are used to automatically conduct a pair wise comparison of the web application s behavior in the given browsers which itself has two parts namely tracelevel and screen level comparison.
trace level comparison.
for detecting trace level differences we have implemented algorithm .
in java which produces as output a list of edges and nodes that are mismatched in either of the two compared graphs.
in order to compare the labels of two edges as de ned in de nition our method retrieves the dom element and the corresponding event type from each edge and tries to reconcile the two labels.
two edges are considered a match if the edit distance between the two based on a combination of event types tag names attributes and their values as well as the xpath positions of the two elements on the corresponding dom trees is lower than a similarity threshold.
the edge comparison method is fully recon gurable for instance if persistent id attributes are used for elements in a given web application the method can be easily con gured to use the ids instead of the combination sketched above.
examples of browser dom di erences.
description ff ie ch uppercase lowercase style display style display style display semicolon whitespace style display none style display none style display none colgroup col width colgroup col width col width middle center valign middle valign center valign middle attribute value style visibility inherit style width 256px style visibility inherit order width 256px visibility inherit width 256px attribute addition input name reason value input name reason input name reason element addition body body iframe id yui hist iframe body screen level comparison.
each node on the state graph represents an abstraction of the dom tree instance of a particular screen of the web application as viewed in the browser.
as discussed in section not all screen level di erences should be agged as candidate cbc issues.
for instance table shows some of the internal dom level differences e.g.
elements attributes their values and order of appearance in firefox ff internet explorer ie and chrome ch that typically do not cause any observable functional di erences in the way a web application is presented to the end user the set a bin figure .
based on our case studies we have started to document such differences between browsers and develop suitable abstractions that allows our screen matching algorithm to ignore them and present the user with only the true cbc issues.
our implementation for detecting dom level mismatches is built as an extension of the differencing engine in xmlunit6.
to minimize the number of false positives i.e.
irrelevant di erences we have written a differencelistener to ignore case sensitivity node level white space attribute order node text values attribute value order and whitespace between the values.
in addition our tool takes as input a list of patterns that can be excluded such as the ones shown in table .
a custom elementqualifier is used to recursively compare nodes and their children to allow for node permutations in the graphs.
additionally as a realization of the outscrdiff in algorithm .
we have implemented a visualization plugin for our tool which while crawling makes a snapshot of each screen change in the browser at hand.
later when a mismatch is found between two screens the corresponding snapshots are used to create a visualization report of the di erences.
more importantly the report also contains the transition paths that lead to the mismatched screens along with the two corresponding dom trees having the di erences highlighted see figure .
.
empirical evaluation to assess the e cacy and utility of our approach and the corresponding implemented tool we have conducted a number of case studies following guidelines from .
our evaluation addresses the following research questions rq1 what is the e ectiveness of our approach in revealing observable trace level and screen level di erences in di erent browsers?
rq2 how e ective is our dom level comparison in minimizing the number of false positives?
rq3 what is the tool s performance and automation level?
.
subject systems the organizer.
our rst experimental case is an open source ajax web application called the organizer developed by zammetti in his book practical ajax projects experimental data.exp.
subject browser pair detected states detected transitions crawled paths avg.
dom nodes crawling min comparison sec manual e ort min organizer ff ch ind v1 ff ch ind v2 ff ie tmms ie ch cnn ff ie with java technology and available for download.7it is a java ee personal information manager using webwork hsqldb spring jdbc and the prototype ajax library.
ind v1 and v2.
our second experimental subject consists of two di erent versions ind v1 andind v2 of a large industrial enterprise web .
application.
ind is a business process manager composed of approximately loc in client side javascript les loc in jsp les and loc in java les.
yui8 is the ajax library used in ind.
a complete user interface redesign forms the main di erence between the two versions.
tm management system.
tmms is a live formbased enterprise web application for submission approval distribution and archiving of technical memoranda.
it is a very typical example of the many relatively small but important legacy web applications that are common place in enterprise settings and usually very poorly compliant with modern web browsers.
it is written in javascript and php.
public domain sites.
we have experimented with a number of public domain sites taken from the list of mozilla s bug reports on browser incompatibility issues.
here we discuss the cnn us presidential elections page referred to as cnn .
.
experimental setup for each experimental subject we con gured our tool by providing the url elements to be included e.g.
crawler.click div and excluded e.g.
crawler.dontclick div .withattribute class logout in the crawling session as well as the browser 10retrieved mar results president table case study results.exp.
subject trace level mismatches trace level false pos.
screen level mismatches of pair of screens screen level false pos.
avg.
dom level mismatches per trace level matched screen pair method organizer crosst xdiff ind v1 crosst xdiff ind v2 crosst xdiff tmms crosst xdiff cnn crosst xdiff to be used.
the browser speci cations used in our case studies are as follows firefox version .
chrome version .
and internet explorer version .
.
to constrain the state space for this experiment so that we can manually assess the correctness of the output we set the crawl depth to for all the subjects.
as shown in table for each subject we measure the number of automatically detected states transitions and crawled paths.
to give an indication of the size of the screens we calculate the average number of dom nodes per screen.
for three of the subjects marked with a we speci cally set a maximum number of detected states e.g.
or to constrain the experimental data.
to address rq3 we report the time taken for the crawling and state exploration phase in minutes for the graph equivalence checking in seconds and manual e ort required to con gure and use crosst in minutes .
in the second phase of the experiment the saved navigation models are checked for equivalence at a trace and screen level.
we measure the number of trace level and screen level mismatches pair of nodes reported by crosst as well as the number of dom level di erences per pair of screens output as potential matches by the trace level comparison.
to form a baseline for comparison we manually inspect each subject in the given browsers to document the observable trace level and screen level di erences.
in addition we use the default settings of xmlunit s diff method further referenced as xdiff as a baseline to evaluate the performance of our approach for detecting cross browser domlevel di erences.
to measure the e ectiveness we analyze the observed false positives and where possible false negatives.
a false positive is a reported mismatch that is not observable in the browsers and as such not relevant for cross browser testing i.e.
the setd cin figure .
a false negative is an observable mismatch that is undetected set c d .
.
results table shows the results of our case studies.
the tracelevel mismatches column presents the sum of unmatched edges in both state graphs i.e.
edges in one state graph that have no counterpart in the other.
the next column displays the number of false positives for the reported un matched edges.
the screen level mismatches column shows the percentage of the screen pairs from the two models that were reported to be potentially matched at the trace level but have di erence at the screen level i.e.
dom level.
the next column reports the percentage of false positives.
for such mismatched screen pairs the table also shows the average number of dom level di erences that are detected by our tool and xdiff .
note that the number is representing all the di erences e.g.
at the node attribute children level that need to be resolved before the two dom trees and hence the screen pair could be seen as a match.
trace level mismatches.
the trace level comparison produced no false negatives and only false positives on ind v2 .
the false positives are due to the fact that the edge labels could not be matched deterministically no persistent id attributes were present and the combination of the attribute names values and xpath expressions did not su ce.
the mismatches correctly reported for ind v2 are caused by a screen level failure which is discussed below under screen level mismatches .
as an example of correctly detected trace level mismatches figure depicts the state graphs produced for the organizer in chrome and firefox.
as it can be seen there are state transitions shown in bold with label imgid logo that lead to state shown in red that are present in the chrome version but are missing from the graph in firefox.
all these transitions are caused by a click on the logoff tab in the application.
the reason for this di erence is that the logoff javascript function associated with the onclick attribute of the corresponding dom element is not executed in firefox.
thus after clicking on the element there is no state change and hence no transition detected.
thecnn case is interesting as well since the missing traces are caused by a bug in the firefox instance 11which results in many of the main content panes never nishing loading.
the trace level mismatches are mainly due to the transitions originating from content loaded into the pane which are present in the ie graph but are missing in the firefox one.
the mismatches in the tmms web application are due to the functionality being totally broken in chrome since many of the clickable elements do not cause any state changes.
in fact after lling in the form clicking on the submit button merely clears all the lled input elds instead of submitting the form.
screen level mismatches.
screen level mismatches are typically more di cult to assess than trace level di erences.
the reason is that a screen level mismatch could be caused by a series of dom level di erences and since the number of dom level di erences could be large despite our abstraction mechanisms more e ort is required to check whether a reported mismatch is a relevant observable one.
the rst observation is that our tool outperforms xdiff which represents the current industrial practice in constraining the number of dom level di erences to be examined reductions of up to times in ind v2 and reducing the number of screen level di erences and false positives reductions of up to .
times in cnn .
figure shows one instance of the detected dom level mismatches in ind v1 taken from our output visualization plugin.
in this case the class attribute which is on the anchor tag in firefox has been moved into a newly added tag element namely a label in chrome.
this detected domlevel di erence is observable in the two browsers as depicted in figure i.e.
the menu icons are missing in chrome.
this type of behavior is the root cause of many dom level di er11 !
!
!
!
!
!
!
!
!
!
!
!
figure generated organizer graphs in chrome top and firefox bottom with the detected di erences.
the organizer s dom in chrome form class cssmain id contactcreateshow ... table class cssmain input id contactcreateshow createddt ... the organizer s dom in firefox form class cssmain id contactcreateshow ... input id contactcreateshow createddt ... table class cssmain figure example of the organizer s dom di erences in chrome top and firefox bottom .
ences we witness in ind v1 propagated to all the instances of the screen level mismatches.
as far as ind v2 is concerned an interesting instance of screen level mismatch is manifested in the way some of the iframes used as content panes internal content simply disappears after a series of clicks in firefox.
this is caused by the way the style attributes are dynamically added and removed through javascript to the corresponding parent element div on the dom tree.
a typical example of false positives and the di culty of resolving them is shown in figure which presents domlevel di erences for the same form element in chrome and firefox.
here the input element resides outside the table in firefox and is pulled in the table in chrome.
although in this case there is no clear observable di erence it is very di cult to discard such di erences automatically without adversely a ecting the false negative rate.
.
discussion scope.
cross browser compatibility spans a wide range of issues from purely visual look and feel di erences to lack of functionality and availability in di erent browsers.
lack of functionality is believed to be a much more severe problemsince it can easily result in loss of revenue.
ideally each web application should behave exactly in the same manner regardless of the rendering browser.
our premise in this work is that cross browser di erences that in uence the functionality and usability of a web application do exist in practice.
further many of these di erences manifest themselves as di erences in the client side state of the application under di erent browsers.
these di erences can be captured in an automated way by using one browser s behavior as an oracle to test another browser s output and vice versa to detect mismatched transitions and screens.
the results of our case studies validate these claims.
note that the present implementation only uses the dom portion of the client state for analysis but could easily be extended to extract di erences based on css properties or even javascript variable values.
our current approach does not target cbc issues caused by di erences that result from di erent browsers di erent rendering of identical web content i.e.
issues that never result in any di erences in the programmatic client side state or traces thereof.
this would be an interesting area for future work.
automation level.
manual crawling or the recordand replay approach embodied by tools such as selenium12 are other alternatives to the model capture phase of our approach.
however we believe that crawljax represents a more automated scalable and robust solution to behavior exploration and integrates very well with the subsequent equivalence checking.
as far as the manual e ort is concerned the main task of the tester consists of providing the url of the deployed web application setting the crawling speci cations and choosing the desired web browser types for compatibility testing which usually takes a few minutes.
the state exploration and comparison steps are fully automatic.
detected ind v1 dom level di erences in chrome left and firefox right .
figure observable di erences of ind v1 s menu in chrome left and firefox right .
note that it is possible for the tester to tune the screen level comparison metrics manually if desired.
this optional step includes for instance specifying which dom level di erences can be ignored to reduce false positives.
the time needed for the actual crawling and generation is fully dependent on the required state space and the crawling settings.
in our experiments the longest model generation case was for ind v2 which took around minutes for two browsers to explore and generate states.
the graph comparison phase is quite fast e.g.
it took less than seconds for indv2.
it requires no manual e ort if the default settings are used.
in case custom dom elements or attributes need to be ignored by the comparison method they obviously have to be provided which in our case studies was not needed.
in short the actual model generation and comparison requires very limited manual e ort.
although we do provide some degree of visualization of the detected mismatches to make it easier assessing the correctness of the output is of course still a manual task.
completeness.
while our proposed technique can expose several interesting and important cross browser issues in a given web application it cannot expose all of them.
this is limited on the one hand by the scope of the algorithm itself discussed above and on the other hand by the fraction of application behaviors covered during the crawling.
obviously the number of cross browser issues exposed co relates to the number of behaviors covered by the crawling.
for the purposes of this investigation we used simple resource bounds to limit the crawling.
this served us well since typically the same cross browser issues appear repeatedly on di erent states and under di erent application behaviors.
thus a complete or comprehensive crawl of the application may not even be necessary to expose key cross browser issues.
in any case optimizing guiding or bounding the crawling to speci cally target cross browser issues are inter esting avenues of future research in their own right but are beyond the scope of this paper.
correctness.
the most conclusive outcome from the evaluation is that within the automatically explored state space our technique is capable of detecting trace level mismatches with a high level of certainty.
as per theorem algorithm .
guarantees a zero false positive and false negative error rate at the trace level provided edge labels in the state graphs have been matched see our formal proof .
our label matching algorithm section is quite successful in achieving this in practice no false negatives and merely false positives .
detected screen level mismatches are also reasonably accurate with the false positive rate ranging from for cnn lowest to for ind v2 highest .
as far as screen level false negatives are concerned for the organizer andtmms we can claim that there were no false negatives.
for the other subjects because of the large state space we are not able to present any concrete numbers i.e.
it is di cult to claim that we have detected all the possible cbc issues since that requires manually examining and comparing a couple of hundred states in di erent browsers.
catalog of browser dom di erences.
ideally we would have a comprehensive list of all dom level di erences that are merely bound to di erent browser rendering and do not have any observable side e ects.
the more complete this list the more accurate our approach will be in terms of reducing the number of false positives.
unfortunately no o the shelf catalog exists today.
this is a learning process which requires examining the web applications at hand and documenting the noticeable di erences.
our catalog is indeed growing with every new case study we conduct.
non deterministic and dynamic behavior.
comparing tree structured data such as html is known to be a di cult problem in web based regression testing even within the same browser because of the dynamic and non deterministic behavior in modern web applications .
some of the false positives in our results are due to precisely this reason.
in this work we have presented the extra challenges involved in dealing with the di erent ways browsers handle and render dom changes from the initial html page through subsequent dom updates via javascript .
recent solutions proposed for instance in could help resolve some of the false positives we currently report.
browser sni ng.
browser sni ng is a technique used to determine the web browser of the visitor in order to serve content in a browser speci c manner.
an interesting pattern we have witnessed in our case studies is when a javascript library treats one browser as the default and uses if else statements for other speci c browsers to account for cbc issues.
the problem starts when a user is employing a browser not tested for and the default content is generated by the library.
the cbc problem depicted in figures and isan example of this type of failure.
our technique is capable of correctly spotting all instances of such di erences.
threats to validity.
some of the issues in uencing the external validity of our results have been addressed in the above discussion.
although the number of web applications chosen in our evaluation is limited we believe they are representative of modern web applications present in open source and industrial environments.
as far as the internal validity is concerned since we use external libraries that act as wrappers around native browsers our evaluation results could be a ected by implementation di erences.
we have tried to mitigate this threat by extensively testing the browsers and their crawling behavior for the model generation part.
.
concluding remarks in this paper we have proposed an automated method for cross browser compatibility testing of modern web applications.
the results of our evaluation on several open source and industrial web applications clearly point to the ubiquity of the problem.
they also demonstrate the e cacy of our approach in automatically exposing relevant cross browser issues at a trace level as well as at a screen level.
our current approach can be enhanced in several ways.
it can immediately bene t from a larger catalog of known dom level cross browser di erences that are merely bound to di erent browser rendering and have no observable side e ects.
this would directly reduce the screen level false positive rate and improve the precision of our approach.
another useful direction would be some automated method of detecting observable cross browser di erences not re ected at dom level.
in concert with our tool such a method could provide a very potent cross browser compatibility tester for the end user.
.