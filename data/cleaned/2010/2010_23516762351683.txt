improving the effectiveness of spectra based fault localization using specifications divya gopinath razieh nokhbeh zaeem and sarfraz khurshid the university of texas at austin austin tx usa divyagopinath nokhbeh utexas.edu khurshid ece.utexas.edu abstract fault localization i.e.
locating faulty lines of code is a key step in removing bugs and often requires substantial manual effort.
recent years have seen many automated localization techniques specifically using the program s passing and failing test runs i.e.
test spectra .
however the effectiveness of these approaches is sensitive to factors such as the type and number of faults and the quality of the test suite.
this paper presents a novel technique that applies spectra based localization in synergy with specification based analysis to more accurately locate faults.
our insight is that unsatisfiability analysis of violated specifications enabled by sat technology could be used to compute unsatisfiable cores that contain likely faulty statements and generate tests that help spectrabased localization.
our technique is iterative and driven by a feedback loop that enables more precise fault localization.
our framework sat tar embodies our technique for java programs including those with multiple faults.
an experimental evaluation using a suite of widely studied data structure programs including the antlr and jtopas parser applications shows that our technique localizes faults more accurately than state of the art approaches.
categories and subject descriptors d. .
testing and debugging debugging aids general terms verification keywords automated debugging fault localization alloy kodkod tarantula minimal unsat cores .
introduction fault localization locating faulty lines of code in a buggy program is a fundamental step in removing the bugs.
in practice fault localization is largely manual and often costly.
however there permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
ase september essen germany copyright acm ... .
.has been much research progress in recent years to automate it .
a particularly effective approach is spectrumbased localization which utilizes the coverage of multiple program runs successful and failing to identify faulty locations.
most of these techniques produce a suspect list which ranks program entities based on a heuristic metric of suspiciousness which measures the likelihood of them being faulty .
the effectiveness of these localization techniques however is heavily dependent on the test suite quality.
the number and coverage of the tests can adversely impact the localization.
for instance many failing tests with similar code coverage or passing tests having coverage very different from the failing tests can result in too many statements being marked suspicious of being faulty.
the type and number of faults also affect the accuracy of the results.
moreover failing tests covering different faults may interfere with each other leading to a decrease in the suspiciousness values assigned to the faulty statements.
also certain faulty statements may get covered by both failing and passing tests resulting in them being ranked less suspicious than an actually correct statement being covered by the failing tests alone.
such faults are more common in programs dealing with data structures where some statements may lead to errors only on certain heap configurations.
these programs are important as they form the backbone of many applications today such as xml parsers compilers relational engines and so on.
a recently proposed approach uses directed test generation to more effectively localize faults.
given a failing test it executes the program using concolic execution to record a path condition comprising of the control flow predicates along the failure trace.
a set of new path conditions is generated by negating each of the predicates systematically and solving them using a constraint solver to generate inputs that would trace new control flow paths.
the input whose trace covers maximum number of path conditions having the same truth value as that of the initial failure trace is considered to be the one most similar to the failing test and is chosen as the next test case to be added to the suite.
the algorithm is repeated with the new test case to generate additional test inputs.
the rationale behind this selection is that a passing test case most similar to the failing test yields the maximum benefit in terms of localizing faults.
while the results of test spectra based localization approaches can improve using a test suite thus generated certain situations would impede the effectiveness of this approach.
for instance when the failure trace is long including a number of path conditions the technique may end up choosing a number of similar failing runs before hitting upon a passing test case.
a key characteristic of most spectrum based approaches is that they depend solely on runtime execution information and are not guided by reasons for failure.
however advances in enabling the user to annotate programs with correctness specifications canpermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
ase september essen germany copyright acm ... .
be leveraged to guide the search for faulty statements.
a recent work leverages sat solvers in analyzing correctness constraints to identify suspicious statements.
however complete reliance on user defined contracts is also problematic since the completeness and complexity of the constraints can adversely impact the effectiveness of the localization.
moreover repetitive static analysis to improve localization accuracy impacts the scalability of these approaches to bigger applications.
we present a technique sat tar that combines specificationbased analysis with dynamic test execution information to produce effective localization consistently across varying fault and specification complexity.
our insight is that unsatisfiability analysis of violated specifications enabled by sat technology could be used to augment the ratings produced by test coverage based localization tools such as tarantula which are more scalable and widely used.
our technique employs a feedback loop to employ sat based analysis and spectrum based localization in synergy.
sat based localization given a program annotated with correctness specifications and the trace of a single run violating these constraints our approach investigates the violated constraints to determine the list of statements responsible for the specification violation.
we leverage minimal unsatisfiable cores muc returned by sat solvers for this purpose.
however complex or incomplete user defined specifications can yield long suspect lists.
we perform spectra based localization to utilize the coverage of different tests to refine the results of localization.
spectra based localization we employ spectra based localization to obtain suspiciousness ratings for the statements.
we utilize the information obtained from the unsat core analysis as follows i we increase the suspiciousness ratings of those statements that appear in the muc ii we generate the test cases for spectra based localization using a variant of the directed test generation approach .
specifically after the generation of a set of test inputs we select the test input whose trace is most similar to the failure trace in terms of its coverage of only those statements that appear in the muc and hence contribute to the violation.
this enables the generation of test cases that would be most effective in localizing faults earlier in the process thereby allowing more accurate ratings to be generated using fewer test cases.
instead of using the test suite as a whole we enable incremental processing of each additional test.
heuristic analysis of the ratings after every round is used to refine the localization.
feedback based on this analysis is used to improve the sat based test generation strategy on the fly.
our technique provides effective localization even in multiple fault scenarios.
we perform root cause analysis of specification violation and support user control on addition of tests to prevent different faults from interfering with each other s localization.
test selection strategies face the challenge to balance between choosing sufficient number and type of tests to provide good error detection and localization capabilities and keeping the test suite size manageable under time constraints.
sat tar generates test suites containing minimal number of test cases required to produce high quality localization.
this paper makes the following contributions unsat cores for fault localization.
application of unsatisfiability analysis of specifications enabled by alloy and sat to short list suspicious statements which aids in augmenting the effectiveness of spectra based localization.
combination of specification based analysis and execution spectra.
feedback driven approach combining specification based analysis and spectra of tests to produce better localization than the stand alone application of each technique for different types of faults and user provided contracts.
minimal test suite generation.
generation of a minimal test suite for effective fault localization.
multiple faults.
specification based approach to partition failing tests covering different faults.
experimental evaluation.
our evaluation highlights some specific issues with localizing faults using purely spectrumbased techniques in the implementations of recursive data structures.
we demonstrate that sat tar localizes faults more accurately than existing state of the art spectra based and sat based localization techniques.
.
background thetarantula tool localizes faults in a program based on the coverage of a given test suite.
it associates with each statement a metric of suspiciousness which represents the likelihood of the statement being faulty and a metric of confidence in the calculated suspiciousness.
in the following definitions failed s and passed s show the number of failing and passing tests covering statementsrespectively while totalfailed andtotalpassed represent the total number of failing and passing tests.
susp tar s failed s totalfailed failed s totalfailed passed s totalpassed conf tar s max failed s totalfailed passed s totalpassed statements with a suspiciousness value of .
are considered to be the most suspicious.
among the statements with the same suspiciousness values those having a higher value for confidence are more likely to be faulty since more number of tests lend evidence to them being suspicious.
each statement is assigned a rank which indicates the maximum number of statements that would need to be examined to reach that statement inclusive of the statement if they were to be arranged in the descending order of suspiciousness and confidence values.
alloy is a specification language based on first order relational logic.
its set based syntax allows modeling the heap of object oriented programs.
classes are represented as sets and fields as relations between the sets.
sat tar supports alloy for writing the specifications including class invariants also known as repok .
theforge tool set enables verification of java code against correctness specifications written in jfsl or jml .
it translates the code and the specifications to alloy by encoding the data and control flow of the procedure in relational logic.
the loops are unrolled a finite number of times.
the flow from one statement to the next is viewed as a relational implication at branch statements the two branch edges are viewed as relational disjunctions.
the conjunction of the pre condition the formula representing the code and the negation of the post condition specification of the procedure is fed into the relational back end engine kodkod .
a solution represents a counter example to the specification showing the presence of a valid input tracing a valid path through the code and producing an output that does not satisfy the post condition.
kodkod the back end of forge is an efficient model finder for relational logic problems specified in alloy.
given a finite bound on the scope it translates the problem into boolean satisfiability and uses off the shelf sat solvers to find solutions.
minimal unsatisfiable cores of declarative specifications considerable work has been done in recent years to find minimal unsatisfiable cores of unsatisfiable constraints written as propositional satisfiability sat formulas .
given an unsatisfiable cnf formula x a minimal unsatisfiable sub formula mus is a subset of x s clauses that is both unsatisfiable and minimal which means41any subset of an mus is satisfiable.
there could be many independent reasons for a formula s unsatisfiability and hence more than one minimal core.
however extracting all of them is computationally expensive.
torlak et al.
propose an efficient algorithm for the extraction of a single muc of declarative specifications based on the resolution refutation proofs generated by sat solvers and theorem provers.
the recycling core extractor algorithm rce returns an unsatisfiable core of specifications written in the alloy language that is guaranteed to be sound constraints not included in the unsat core are definitely irrelevant to the unsatisfiability proof and irreducible removal of any constraint from the set would make the remaining formula satisfiable .
muc has been shown to be useful in the identification of over constrained models weak theorems and insufficient scopes while checking models.
in this paper we use muc in localizing faults in imperative code.
.
illustrative overview c l a s s l i n k e d l i s t node h e a d e r i n t s i z e number ofnodes i nt h i s l i s t s t a t i c c l a s s node node n e x t i n t key boolean d e l e t e i n t k removes t h e node with key v a l u e k node prev n u l l node l s t h e a d e r while l s t !
n u l l i f l s t .
key k i f prev !
n u l l prev .
n e x t l s t .
n e x t c o r r e c t prev .
n e x t l s t removeerr e l s e h e a d e r h e a d e r .
n e x t c o r r e c t h e a d e r h e a d e r headerr s i z e c o r r e c t s i z e s i z e e r r r e t u r n t r u e prev l s t l s t l s t .
n e x t r e t u r n f a l s e listing linkedlist and its delete method with faults.
we consider the localization of typical faults in a simple data structure method and illustrate the benefits of our technique by comparing the results of sat tar with existing state of the art localization techniques pure spectra based localization tar tarantula on a test suite generated using the most recent directed test generation technique for effective fault localization dt andpure sat based analysis of specifications sat .
example program with faults listing shows the delete method of a singly linked list data structure class.
the delete method takes in an integer argument k and attempts to remove the list node with the matching key value.
figure displays a model for the class and its correctness specifications in alloy section .
the class invariant repok consists of the acyclicity constraint which checks that the list does not contain any cycles the unique elements constraint which checks that each list node has a unique key and size invariant which ensures that the size field has a value equal to the number of nodes reachable from the header through the next pointer.
we consider two possible versions for the user defined post condition specification for the delete method.
in deletepostcond1 the user includes constraints to specifically check the functionality of the method alone only the node with the matching key value has been removed from the list remove ok and the size of the list has been decremented on a successful delete size ok .
on the other hand indeletepostcond2 the user ensures that all the class invariantspred repok this linkedlist class invariant all n this.header.
next n !
inn.
next acyclicity this.header.
next int this.size size invariant all n m this.header.
next int m.key int n.key n m unique elements pred deletepostcond1 this linkedlist k int remove ok this.header.
next.key k this.header .
next .key k in this.header.
next.key this.size this.size size ok pred deletepostcond2 this linkedlist k int repok figure linkedlist class invariant post conditions for delete in alloy.
table spectra based localization using tarantula.
stmts fault tech.
tests rating sizeerr tardt2f 2p susp .
.
.
.
.
.
.
.
.
.
.
.
tar conf .
.
.
.
.
.
.
.
.
.
.
.
tar rank headerr tardt2f 2p susp .
.
.
.
.
.
.
.
.
.
.
.
tar conf .
.
.
.
.
.
.
.
.
.
.
.
tar rank are preserved after deletion without including a specific check to ensure the removal of the input value.
the syntactic sugar of adding back tick is used to represent the relations in their post state after the execution of a method.
we use these two versions to show how our technique is intended to work with varying levels of complexity and completeness in user defined specifications.
let us consider two faulty versions of the delete method one comprising of just sizeerr on statement and the other comprising of just headerr on statement .
the first fault wrongly sets thesize field to instead of decrementing it whenever a match is found.
the second fault incorrectly updates the header field.
applying tarantula tar we first apply tarantula on a minimal suite and then consider the use of a suite generated using the approach for effective fault localization tardt .
consider the use of just two tests a failing test case with a two node input list and the value kmatching the keyof the first node and a passing test case with an empty input list to localize sizeerr .
the traces of the two runs are very dissimilar so most of the statements are assigned the same suspiciousness and confidence ratings of .
.
hence in the worst case actually correct statements should be examined before hitting the faulty statement giving it a rank section of .
the results improve on using a test suite with tests generated specifically for effective fault localization tardtin table susp andconf stand for suspiciousness and confidence and fandpare for failing and passing tests respectively .
while headerr is welllocalized ranking the faulty statement first in the list the ratings are not accurate for sizeerr .
statement rank is rated lower than the actually correct statement .
this is because the suite includes a test that removes from an input list with just one node for which setting size to after deletion is valid.
hence statement has one passing test covering it whereas all tests covering statement are failing runs.
applying pure sat based analysis of specifications sat let us now consider the application of a technique which solely uses static analysis of the code and violated specifications to localize42table pure sat and sat tar localizations for sizeerr .
stmt sat spectra t armuc postcond 1f 1f 2f 1p 2f 2p susp rank susp 1conf 1susp 2conf 2susp conf rank sat sat sattar sattar sattar .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
table pure sat and sat tar localizations for headerr .
stmt sat spectra t armuc postcond 1f 1p 2f 1p 2f 2p susp rank susp 1conf 1susp 2conf 2susp conf rank sat sat sattar sattar sattar .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
the same faults.
given a program annotated with correctness specifications and an input exposing a fault in the code that violates the specifications kodkod is leveraged to detect a minimal unsat core section .
the constraints in the core are mapped to source code statements to determine the list of suspicious statements each of them being assigned the same suspiciousness value of .
.
an input exposing only sizeerr with deletepostcond1 would violate the size ok constraint.
the suspect list produced includes the faulty statement updating size while eliminating statements updating other fields such as statement .
faulty statement sat in table is ranked fourth using just a single failing test.
however complex specifications made up of a number of dependent constraints result in multiple violated constraints involving many data structure fields.
such is the case with headerr using deletepostcond2 sat in table .
a list with one node whose key value matches the input kexposes this fault.
the violated constraint is size invariant which includes almost all fields of the linked list.
hence the unsat core does not help much in filtering out the correct statements.
faulty statement is ranked seventh.
applying sat tar the above results lend motivation to our intuition that instead of dwelling just in the realm of spectra based localization or pure sat based approaches it would be helpful to combine the two techniques in order to achieve effective localization consistently across different fault scenarios.
starting in the sat domain our framework takes in a faultrevealing input.
we employ the forge framework with kodkod at its backend to determine a minimal unsatisfiable core.
the muc consists of the core constraints responsible for the violation and is mapped back to an initial suspect list of potentially faulty source code statements.
this list is exactly the same as that produced bytable multi fault localization.
faulty tardtsat tar postcond1 stmt test suite shows both faults initial trace shows headerr initial trace shows sizeerr 3f 3p 1f 2p 1f 2p susp conf rank susp conf rank susp conf rank tar tar tar sattar sattar sattar sattar sattar sattar .
.
.
.
.
.
.
.
.
.
.
.
the pure sat based technique for the respective faults sat in tables and .
instead of performing further analysis in the satdomain which may impact efficiency sat tar utilizes spectrabased localization for further refinement based on the coverage of other tests.
sat tar uses the information gained from muc analysis to generate tests which would prove most useful in refining the precision of localization.
specifically we generate an input whose trace is most similar to the initial run in terms of its coverage of the statements in the suspect list.
this algorithm aids in producing effective localization using minimal number of test cases.
the benefit of our technique over directed test generation gets highlighted on bigger and more complex programs section .
the test inputs along with the initial suspect list are passed onto the spectra based analysis domain.
we execute the faulty code on the test inputs using the user provided post condition specification as the correctness oracle to determine failing and passing tests.
we use the same suspiciousness and confidence metrics as used by tarantula to rate the statements based on the coverage of the tests but a value of .
is added to the suspiciousness of statements in the suspect list built using the muc analysis tarmucin tables and .
this is done to factor in the knowledge gained from the analysis of the specifications.
the tables show the tests incrementally added to the test suite and the corresponding ratings.
for headerr the test case added in the first round is a passing run wherein the inputkmatches the key of the second node of the list.
this test has its code coverage most similar to the failing run hence the suspiciousness of all statements in common between the two traces gets reduced contributing to significant refinement in the ratings susp and conf 1in table .
the control passes back to the sat domain to generate additional test inputs for subsequent rounds.
such a passing test case is generated after the second round for sizeerr susp 2and conf 2in table .
this process continues until no more tests with unique coverage of the code can be generated.
incremental processing of test cases facilitates the availability of intermediate localization results which is beneficial as elaborated in section .
particularly it enables support for user control wherein the user is presented with the results after every round and he could choose to stop the addition of tests and further processing when appropriate.
in both the fault cases the best possible localization of the faulty statements is achieved using the first few tests.
hence ideally the user could stop further processing after the second round for sizeerr and the first for headerr .
observe that faulty statements and are both assigned suspiciousness of .
and confidence of .
susp sattar and conf sattar in tables and respectively which are higher than the ratings for the correct statements.
hence they rank first in a descending ordering of the statements based on their suspiciousness and confidence.
compared to the counterpart techniques tar sat we provide high quality localization consistently for both the fault scenarios.
multiple faults in multi fault cases tests covering different faults interfere with each other impacting the effectiveness of pure spectrabased localization.
we applied tarantula on a code containing both the faults sizeerr andheaderr with a suite generated using dt having failing tests covering both of them.
the localization tardt is not very effective as the faulty statements and43fault revealing input program specsat spectra muc analysis forge test input generationinitial suspect listtest execution spectra localization tarantula heuristic analysisfinal ratingstest suite updated suspect listupdate ratings test generation strategy changefigure sat tar framework rank third and fourth respectively.
our approach localizes the faults exposed by the initial failing trace and performs violatedspecification based partitioning of failing tests covering different faults.
the smallest fault revealing input for the two fault example would be a run removing a node from a list with only one node.
this run violates the remove ok constraint alone caused due to headerr on statement .
failing runs covering sizeerr and violating size ok constraint are not included in the test suite thus preventing decrease in the ratings headerr in table .
the suspect list built using muc analysis also aids in augmenting the suspiciousness of statement ranking it second in the list.
similarly when starting with an input violating size ok alone our approach eliminates the failing runs violating the remove ok constraint thus localizing statement with high precision with a rank of sizeerr in table .
.
framework details in this section we elaborate on the algorithm and implementation details of the modules of our framework.
figure presents an overview.
the input to the framework is a fault revealing test which can be produced by any testing or static verification technique .
the two main constituents of our framework are sat based analysis section .
and spectra based analysis section .
.
sat based analysis short lists an initial suspect list using muc analysis and generates suitable test cases which are passed onto the spectra domain.
the ratings of the spectra based localization using these tests is heuristically analyzed and updated based on the suspect list.
feedback from the spectra back to the sat domain aids in refining the test generation strategy.
.
sat muc analysis the forge framework section uses symbolic execution to translate the code of a procedure into a set of formulas in relational logic f code f ... fn .
given a fault revealing input i fr and the correctness specification we attempt to find a valid path through the code for the given input yielding an output satisfying the post condition specification.
kodkod is invoked with the following alloy formula f code .
the pre state relations are bound to the values in the fault revealing input i fr and the scope is fixed to the size of the input.
due to the fault in the code the formula is unsatisfiable and kodkod returns a proof of unsatisfiability unsat .
the rce strategy of kodkod is used to produce the muc section a reduced form which consists of the core constraints responsible for the violation.
muc fmuc ... f muc m muc ... muc m which is some subset of f1 ... fn .
figure shows the main formulas that appear in the muc extracted for the sizeerr .
the first formula represents the violated k in this .header.
next.key this .size this .size !
no this .header this .header.key val this .size size this figure muc for sizeerr .
specification constraint size ok .
the second formula represents the constraints that appear on the path that updates the size field.
the first two constraints represent conditionals on the pre state relations evaluated by branches and listing .
the last constraint represents the faulty statement as an override of the size relation wherein the list instance this is mapped to a value .
note that only those branches that are relevant to the violation branches on which the update statement is control dependent on are included in the muc.
for instance branch statement is not included in the muc for sizeerr .
the forge framework calculates a coverage metric in the event that the formula used to invoke kodkod is unsatisfiable which determines the set of source code statements covered during the analysis.
during the translation from imperative code to logic a formula slice map is maintained mapping each formula inserted into the path constraint f i to the set of statements or slice of code from which the formula was generated constraint strategy of forge employed for translation .
this is utilized to determine the set of statements mapping to the formulas in the muc f muc i which can be considered responsible for the unsatisfiability.
this forms the initial list of suspicious statements.
for the sizeerr statements are short listed using this analysis from the list of all statements in the trace .
the suspiciousness of statement s is susp sat s .
if statement s is in the initial suspect list otherwise it is .
.
kodkod returns only a single muc for a violation which is not sufficient when the trace covers multiple faults violating more than one constraints.
hence after processing an muc we remove the corresponding violated constraints from the specifications and invoke the unsatisfiability analysis again to extract other mucs.
we thus form a consolidated list of suspicious statements covering all faults in the code.
test input generation this module aims to generate test inputs that would provide the most benefit in localizing the fault exposed by the initial failure trace.
the algorithm involves two main steps pseudo code in listing i using the conditionals on the failure trace to generate a set of additional inputs covering new portions of the code and ii selecting the input which is the most similar to the failure trace as the next test input similartrace .
the heuristic behind this technique is that if the input with a trace most similar to the failure trace happens to be a passing run then it would provide the most benefit in improving the precision of the localization since a considerable number of statements in common between the two traces could be considered non faulty.
the first step is accomplished by systematically negating each of the path constraints on the failure trace f pc ... f pc n obtained by solving for f codebinding the pre state to i fr.
the following new path constraints get generated f pc f pc ... f pcn f pc fpc2 ... f pcn 1so on until f pc .
for every new path constraint newpc sat is employed to look for a valid input whose trace includes that constraint.
given a failure trace and its unsatisfiability core we define the similarity score of another trace with respect to the former as the number of source code statements it covers that map to the former s muc.
the trace with the highest similarity score is considered most similar.
the selected trace needs to cover at least one statement from the suspect list.
our similarity criterion ensures that when there are more than one traces having the same number of statements in common with the failure trace 44the one that covers more number of suspicious statements is chosen thus providing maximum benefit in refining the localization if it happens to be a passing run.
from the generated inputs the one that is most similar to the initial failure trace is chosen as the test input to be added to the suite which already contains the initial fault revealing input.
trace t e s t g e n e r a t i o n l i s t stmnt s u s p e c t l i s t trace ce l i s t trace s e l t r a c e s t e s t g e n s t r a t e g y s t c o n s t r a i n t pathconds p a t h c o n d c o n s t r a i n t s ce f o r i n t i i pathconds .
l e n g t h i c o n s t r a i n t newpc c o n j u n c t i o n pathconds .
.
.
pathconds n e g a t i o n pathconds trace newtrace kodkod .
s o l v e c o n j u n c t i o n precond newpc i f newtrace .
s a t i s f i a b l e i f s t .
e q u a l s new strategy boolean uniquecov uniquecoverage newtrace s e l t r a c e s s u s p e c t l i s t e l s e uniquecov uniquecoverage newtrace s e l t r a c e s i f uniquecov l i s t trace newtraces .
add newtrace i n t max trace s i m i l a r t r a c e n u l l f o r trace t newtraces l i s t stmnt stmtnums srccodestmts t f o r stmnt s t m t s u s p e c t l i s t i f stmtnums .
c o n t a i n s s t m t s c o r e i f max s c o r e max s c o r e s i m i l a r t r a c e t s e l t r a c e s .
add s i m i l a r t r a c e r e t u r n s i m i l a r t r a c e listing test input generation algorithm.
.
spectra the tests generated in the sat domain are executed followed by spectra based localization using the formulas of tarantula.
the suspiciousness and confidence metrics are calculated as follows susp sattar s suspmuc tar s susp sat s conf sattar s confmuc tar s .
the superscriptmucrepresents muc based test generation.
tar indicates tarantula s spectra based localization metrics.
sat represents the metric obtained from sat based analysis.
violated specification based filtering of tests for failing tests the violated constraints are analyzed to confirm that they match the constraints violated by the initial failing run.
tests that violate distinctly different constraints are not considered since they pass through different code faults and would wrongly reduce the ratings of the faulty statements in the initial failure trace.
note that we could potentially use sat to statically look for inputs that would violate the specifications failing or not passing and also perform the filtering out of distinctly different failing tests.
however we defer these steps until the actual method execution for efficiency and scalability purposes.
heuristic analysis of ratings the test inputs are generated and used for localization one at a time.
such incremental addition and processing of tests facilitates application of heuristics to refine the precision of the ratings and to provide feedback to improve the effectiveness of test generation.
refinement of ratings localization using the test added in every round updates the ratings.
if the test added in a round happens to be a failing run the statements whose suspiciousness and confidence values decrease from the previous round are not faulty in most probability.
this is under the assumption that the new failing test also covers the same code faults as the initial run.
hence the ratings of these statements are not augmented i.e.
susp sattar s susp tar s .
when the added test violates a subset of the constraints violated by the initial failing run it probably covers a subsetof the faults exposed by the initial run.
in such a case the above heuristic is not applied since it may reduce the suspiciousness of the faulty statements present in the initial failure trace and not covered by the new test.
feedback to customize test generation strategy analysis of the ratings also helps improve the test input generation strategy onthe fly.
statements heuristically determined to be non faulty could be removed from the suspect list.
the feedback of this updated suspect list to the test input generation module improves the effectiveness of the similarity criterion.
we also asses the performance of the tests heuristically to identify redundant tests.
big fault revealing inputs such as long lists lead to the generation of a series of failing runs with very similar code coverage providing little benefit in refining the ratings.
hence the results are observed periodically to detect such series of tests causing no change in the ratings of the statements in the suspect list.
subsequently the test input generation strategy switches to generating tests which differ from the previous tests not only in their total code coverage but specifically in their coverage of the suspicious statements new strategy in listing2 .
user control optional the incremental generation and processing of tests is continued until no more test cases with unique coverage can be generated.
the user can optionally be presented with the output after a specified number of rounds and if he is satisfied with the precision he can choose to stop further refinement.
this helps in cases when additional tests could reduce the localization accuracy such as passing runs covering the faulty statement.
since we generate test cases that are as close to the initial failing run as possible the first few tests could be assumed to cover the same code faults in most probability in multi fault scenarios .
but as the rounds increase the chance of hitting new faults increases and user control could aid in stopping the process before the generation of these tests.
.
discussion of correctness the correctness of our approach relies on the accuracy of the specification.
however lack of completeness in the specification leading to the inclusion of statements in the muc that may not be responsible for the violations can be refined by spectra based localization.
for single fault cases the muc is guaranteed to map to all statements responsible for the violation.
the faulty statements are also localized with lower ranks than the correct ones in most cases.
multi fault cases require special handling.
when multiple faults occur simultaneously in a single failure trace we require each of the faults to violate a distinct specification constraint.
our iterative processing of mucs aids in exploring the mucs covering different faulty statements.
violated specifications analysis helps eliminate failing tests that cover different faults and violate constraints other than those violated by the initial run.
this prevents interference which causes decrease in the ratings of the faulty statements.
further generation of tests similar in coverage to the failing run and user input based stopping of refinement aid in preventing the generation of failing tests covering other faults.
.
evaluation we address the following research questions in the evaluation.
rq1 does sat tar perform better than existing pure spectrabased localization and pure sat based analysis of specifications for different types and number of faults and varying complexity of specifications?
rq2 how much do the individual components of our localization algorithm a test generation using unsat core and b augmentation of ratings using unsat core contribute to its effectiveness?45boolean add int k node y null node x this.root while x !
null y x if k x.key x x.left bsttraverseerr x x.right else if k x.key x x.right else return false x new node x.key k if y null this.root x bstrooterr this.root null else if k y.key bstbrancherr if k y.key y.left x else y.right x bstrighterr y.right y x.parent y bstparenterr x.parent x this.size bstsizeerr1 this.size return true void addchild tree t if t null return basetree childtree basetree t if childtree.isnil if this.children !
null this.children childtree.children throw new runtimeexception if childtree.children !
null int n childtree.
children.size if children !
null for int i i n i tree c childtree.
children.get i this.children.add c c.setparent this antchildparerr1 c.setparent c else children childtree.children int i while i n tree c childtree.
children.get i c.setparent this antchilderr c.setparent c i antlooperr i i else if children null children newlist children.add t childtree.
setparent this antparenterr1 childtree.
setparent childtree a b figure code snippets of a bst.add b antlr basetree.addchild with error numbers.
candidates bst.add integer k binary search tree bst is a data structure with complex structural properties commonly used in applications requiring efficient search.
the data structure invariants include uniqueness of each element acyclicity with respect toleft right andparent pointers size correctness and search constraints.
the add integer k method figure 4a inserts a node at an appropriate position in the tree based on the input value.
basetree.addchild tree t another tool for language recognition antlr is a commonly used open source tool to build recognizers interpreters and compilers from grammars dacapo benchmarks .
it is an excellent candidate because it uses various kinds of data structures specially trees as its backbone.
basetree class implements a generic tree structure customized to parse input grammars.
each instance maintains its children as a list each child is in turn a tree and has a pointer to its parent .
every tree node may also contain a token field which represents the payload.
the addchild tree t is the main method used to build all tree structures figure 4b .
based on the comments and the program logic we derived the following specifications acyclicity of the children list accurate parent child relationships and addition of child without any unwarranted modifications to the tree structure.
fault scenarios we seeded different types of faults in both these methods including incorrect updates to data structure fields local variables which impact the traversal of the tree bst table single fault results.
sat pure muc based localization tarrand tarantula with a randomly generated suite tardt tarantula with tests generated by and sat tar user sat tar with user control .
fault sat tarrandtardtsat tar sat tar tests tests tests rank tests rank rank user bst sizeerr1 .
.
bst sizeerr2 .
.
bst parenterr .
.
bst righterr .
bst traverseerr .
.
bst brancherr .
.
ant parenterr1 .
ant parenterr2 .
.
ant childparerr1 .
.
.
ant childparerr2 .
.
.
ant childerr .
.
ant looperr table results of restricted variants of sat tar.
fault tardt sat sat tar tarmuctardt rank bst sizeerr1 .
.
bst sizeerr2 .
bst parenterr .
.
bst righterr bst traverseerr .
bst brancherr .
.
traverseerr branch conditions bst brancherr and loop indices ant looperr .
some faults lead to the violation of just one constraint such as bst parenterr which only violates the constraint n n. left .parent while others such as bst righterr violate many constraints involving almost all fields of the data structure.
error names ending with labels and represent the same code fault but with different post condition specifications impacting the unsat core.
for instance bst sizeerr1 violates only size size while bst sizeerr2 violates size this.root .
right left producing a bigger core and suspect list.
similarly for ant parenterr2 the post condition only checks if for every node the parent pointers have been set correctly for all its children while err1 also checks if the input tree has been added correctly as a child.
we also seeded more than one faults simultaneously to simulate multi fault scenarios .
localization techniques the spectra based localization approaches tarrand tardt use the same suspiciousness and confidence formulas for localization as tarantula.
for tarrand we used the stateof the art test input generation technique for data structures korat to generate tests exhaustively up to a size such that there was a failing run for every fault.
for each fault we used a code version containing only that fault and selected tests randomly ensuring the inclusion of at least one failing run .
for tardt the test suite was generated using the directed test generation algorithm .
we implemented the algorithm using forge with sat as the back end technology instead of concolic execution as done previously.
this enables an efficient application of the technique on data structure programs with complex invariants.
we employed a prototype implementation of our algorithm built on top of the forge framework to obtain results for sat tar .
in both sat tar and tardt tests table multiple faults localization.
multi fault tarrandsat tar sat tests rank tests rank rank tests r1 ... rn loc1 loc2 r1 ... rn r1 ... rn bstrootparerr .
.
bstrootsizrghterr .
.
.
anttwoerrs .
.
sllsizremerr 946are incrementally added to the suite.
in order to compare the testsuite effectiveness we used the same number of tests for tardtas that produced by sat tar to localize a particular fault.
sat is the pure unsat core analysis based technique which assigns the same suspiciousness value of .
to all statements in a suspect list obtained by mapping from the muc.
metrics the effectiveness of localization was measured by assigning a rank to the faulty statement section based on its position in the descending order of the suspiciousness and confidence ratings of all the statements.
the lower the rank of the faulty statement the better the localization.
for instance a faulty statement with suspiciousness .
confidence .
is ranked fifth in a list with two statements having suspiciousness .
confidence .
and two others with suspiciousness .
confidence .
.
kodkod with minisat as the backend sat solver was employed to obtain the minimal unsatisfiable cores.
all the experiments were run on a system with .50ghz core duo processor and .00gb ram running windows .
the results are an average of runs.
all the localization approaches except tarrand start with a single failing run.
hence for every run we used bounded verification forge to generate a fault revealing input of random size.
result discussion table shows the ranks assigned to the faulty statements for each fault under each technique.
the tests for tardtand sat tar is the minimum number of tests amongst the runs for the run with the fault revealing input of smallest size .
rq1 sat tar vs tar for all types of faults our approach consistently produces lower ranks using less number of tests than tarrand.
for most of the faults the best possible ranking is obtained using the first few tests and the algorithm could ideally be stopped at that point under user control mode user in table .
the precision is better than tardtas well despite the latter approach using a test suite produced specifically for effective localization.
the use of unsat core helps filter out statements not related to the specification violation.
for instance in bst sizeerr1 muc analysis helps narrow down to statements responsible for the violation from a total of statements.
even in faults not directly updating fields appearing in the specifications such as ant looperr and bst brancherr around of statements are eliminated based on muc analysis.
bst sizeerr2 is one of the many cases where our heuristic refinement of ratings proves beneficial.
on processing two failing test cases one adding a right child to the tree and the other a left child statements updating the right andleft fields are rightfully eliminated from being faulty.
the test suites for both random selection tarrand and directed test generation tardt include many redundant tests with the same code coverage.
our approach on the other hand specifically generates test cases with unique statement coverage which are most similar to the initial failing test in their coverage of the suspicious statements.
ant parenterr1 is an instance wherein a passing test most similar to the initial failing run is produced in the second round resulting in the faulty statement being ranked first.
the randomly selected tests tarrand and the tests generated by dt tardt both comprise of many failing tests with similar coverage which assign the same ratings to almost all statements.
multiple faults table shows the results for multi fault scenarios r ... rnrepresent ranks of faulty statements to n loc loc2 indicate the separate localizations runs for each failure trace .
the test suite used by tarrandcontains failing tests exposing different faults simultaneously which decreases the quality of localization due to interference.
our approach works on a single failure trace and builds a suitable suite to localize the faults exposed by that trace.
for sllsizeremerr the initial failure trace covers both removeerr and sizeerr simultaneously listing hence iterativeprocessing of mucs is performed to obtain the complete list of possibly suspicious statements.
consider bstrootparerr containing two faults simultaneously inbst.add bstrooterr and bstparenterr figure 4a .
two distinct failing tests cover each of these faults and violate two distinct constraints one this.root andall n n.left .parent nrespectively.
our approach processes each of these failing tests separately and eliminates each of these tests from the other fault s localization.
the faulty statements are thus assigned lower ranks in their respective localizations as compared to the ranks assigned to them by tarrandusing a test suite containing both the failing tests.
consider anttwoerrs containing antparenterr and antchildparerr simultaneously in basetree.addchild .
failing tests covering each of these faults violate the same parent child relationship constraint.
the first similar test case is a passing run ranking the faulty statement at while subsequently the failing test exposing the fault on statement gets included pushing the rank higher.
in the user control mode the user could ideally stop refinement in the first round to prevent interference from the other failing run.
sat tar vs sat the high ranks of faulty statements sat in tables and highlight the poor precision of the localization based on pure sat based analysis of specifications.
specifically bstsizeerr2 ant parenterr2 and ant childparerr2 have exactly the same faults as their counterpart error cases ending with .
however muc analysis returns longer suspect lists for these cases either due to the increase in the complexity or decrease in the completeness of the post condition specifications.
on the other hand sat tar employs the coverage of additional tests to refine the ratings in the initial suspect list and hence the precision does not suffer much.
rq2 to address rq2 we compare sat tar with two restricted variants each including one specific component of the technique but not the other i tardt sat this represents a mere aggregation of the ratings obtained from the stand alone application of pure spectra based localization and sat based analysis susp suspdt tar susp sat ii tarmuc this represents the use of muc analysis only for test generation susp suspmuc tar .
sattar includes both the components susp suspmuc tar susp sat.
comparing the results of tardt sat with sat tar shows that in most cases our technique performs better than a technique that merely aggregates the ratings from pure spectrabased and sat based localizations.
this indicates that our test generation strategy does provide benefits as highlighted in the comparisontarmucvs tardt.
in bst brancherr a test case inserting a node into an empty list is the passing test case that is most effective in refining the precision of localization.
the similarity score assigned to this test using our metric which is based on the coverage of the suspicious statements section is higher than the score assigned to it using the counterpart technique which is solely based on the truth values of the path conditions covered section .
hence this test case is not included in the suite for tardt.
two passing test cases having the same code coverage passing through significantly different portions of code than the initial failing run get used which do not help much.
even for fault revealing inputs of fairly small size such as a tree with nodes tardtstarts generating series of similar failing tests all the tests for bst parenterr are failing .
these tests have smaller structures exposing the same fault which help reduce the suspiciousness of some statements used in tree traversal but do not contribute to the refinement as much as a similar passing test case.
for bsttraverseerr the suite for tardthas failing runs and passing run while sat tar generates passing runs similar to the initial failing run.
the accuracy of the suspect list used by our similarity metric also gets updated dynamically based on the feed 47table localization times.
fault tardtsat sat tar time in secs bst sizeerr1 .
.
.
bst sizeerr2 .
.
.
bst parenterr .
.
.
bst righterr .
.
.
bst traverseerr .
.
.
bst brancherr .
.
.
ant parenterr1 .
.
.
ant parenterr2 .
.
.
ant childparerr1 .
.
.
ant childparerr2 .
.
.
ant childerr .
.
.
ant looperr .
.
.
time in mins jtopas err1 .
.
.
jtopas err2 .
.
.
back from the heuristic analysis which aids generation of effective tests sooner.
the results of sat tar are better than tarmuc indicating the benefit of unsat core based augmentation of suspiciousness ratings.
specifically in cases such as bst sizeerr where the tests produced by our algorithm and dt are almost the same muc analysis based filtering helps lower the ranks significantly.
jtopas case study jtopas is a java library used for parsing arbitrary text data such as html xml programming language source code and so on.
we used sat tar to localize a fairly complex fault from version .
of the application in sir and another fault seeded by us.
we tested the tokenizer class by asserting that the parsed output satisfies the following two properties i the sign is followed by a keyword inside a javadoc comment ii the number of open and closed braces are the same.
when the input file input1 in listing is parsed the assertion on the first property fails despite the fact that the token author following the sign is a keyword.
assuming that the test code was error free we performed modular analysis of the nexttoken method which parses the input at the next position into an appropriate token.
we annotated the method with a post condition specification checking that an sign is always followed by a token that is a keyword.
the code of this method with the called helper methods inlined was encoded in the forge intermediate language with a total loc of .
the first set of test inputs generated comprised of different types of tokens separator space etc.
substituted before and after author leading to a series of similar failing runs.
on detecting that even after processing failing tests the suspiciousness of the statements in the suspect list did not change the test generation strategy switched to producing a run differing from the previous runs in its coverage of the suspicious statements.
a passing test case was produced shooting up the precision of localization.
the faulty statement in the test4normal helper method which wrongly sets the type of the author token as normal instead of keyword is assigned a rank of .
tardt on the other hand ends up generating series of similar failing tests shooting up the rank to .
input in listing violates the property on balanced braces due to the seeded fault in test4specialsequence method.
this is localized by our approach to a rank of using just the first few tests.
i n p u t i n p u t author listing fault revealing inputs for the two faults in jtopas.
performance table shows the average times taken by tardt pure sat based analysis and sat tar for localizing each of the errors.
sat tar consumes on an average about twice as much time as pure spectra based localization.
more than of this time is spent in the extraction of the unsatisfiable core.
hence thedifference in times is more pronounced for applications with large specifications such as antlr wherein every node of the tree has multiple children.
the large size of the source code impacts the performance of all three techniques for the jtopas application.
threats to validity use of our implementations of the sat technique and the directed test generation algorithm dt used in tardt may impact the construct and conclusion validity of our experiments.
however comparing the test suite generated by sat tar with the sat based implementation of dt aids in rightly attributing the differences in the results to purely algorithmic differences without being impacted by the back end technology.
the number of test cases used for techniques tarrandand sat differ from sattar.
however they represent typical applications of these existing approaches in practise.
representatives of the candidate programs may impact the external validity of the results.
.
related work directed test generation for effective fault localization recent work presents a test generation strategy specifically directed at localizing faults.
given an arbitrary failure trace this algorithm incrementally adds test cases based on their similarity score with the initial failing run section .
this technique employs concolic execution to keep track of path constraints and generate input configurations covering new portions of code.
the scalability of this approach has not been evaluated on data structure methods wherein a repok method would have to be symbolically executed before every method invocation to generate valid inputs.
in our approach specifying correctness constraints declaratively and relational modeling of java programs aid in efficient representation of the problem in boolean satisfiability wherein sat technology could be leveraged for efficient generation of inputs.
our evaluation section shows that sat tar produces more effective tests than dt earlier in the generation process.
correctness oracle based augmentation of tarantula s ratings artzi et al.
present an effective localization approach for web applications that is related to ours in terms of augmenting the ratings of tarantula based on an oracle for correctness.
however this technique is very specific to errors in php applications generating html pages.
also only statements for which tarantula assigns a rating greater than .
are augmented which is not very effective for typical errors in data structure methods wherein both passing and failing runs cover the erroneous statements.
it is not explicitly shown if multiple error cases are handled effectively by the technique.
the paper presents a novel condition modeling approach to catch omitted branch statements.
we envisage the use of muc based analysis for the same purpose.
for instance if the update to size were omitted in the list example the violated size ok constraint would indicate that the size field was possibly wrongly updated or not updated at all.
analyzing the code statements that the muc contains would likely show the omission error.
localization using unsatisfiability analysis of sat the recently developed bugassist tool models programs and their correctness specifications in boolean satisfiability and employs sat solvers to localize faulty statements.
while we use the muc returned by kodkod this technique uses the maximum satisfiability core returned by sat solvers to deduce minimum unsatisfiable subsets.
it further makes clauses hard to iteratively determine all possible suspicious locations in the program.
however the technique has not been applied to typical data structure programs.
our evaluation of pure sat based localization section on data structure methods shows that the precision of such techniques is poor when used with complex specification constraints.
our approach combats these issues by combining sat based and spectra based analysis.48localization based on analysis of code state and contracts program slicing based techniques are the earliest works in the field of employing static analysis to isolate a subset of instructions as suspicious.
however these suffer from very low precision and efficiency.
an extension to these techniques discusses the idea of generating program slices that satisfy specific constraints on the inputs.
griesmayer et al.
and ball et al.
explore the use of model checking technology for fault localization.
the former attempts to identify faulty locations by introducing non deterministic variables at program components marked suspicious by the user while the latter compares the counter examples returned by the model checker with successful traces to identify faulty transitions.
others such as zhang et al.
and huang et al.
perform analysis of program states rather than locations to identify infected states leading to more precise localization.
delta debugging is also a popular approach that analyzes state differences between failing and passing test cases to identify suspicious values of variables and their corresponding locations.
the autofix e project uses contracts to synthesize fix schemas for program repair.
spectrum based and instrumentation based techniques spectrabased techniques utilize dynamic test information such as code coverage for localization.
set union and set intersection are popular techniques that compute suspect lists by marking statements exclusively executed by failing runs as suspicious.
nearest neighbor technique is an extension wherein the difference in the profile of the passing run most similar to the failing run is considered instead of including all passing test cases.
instrumentationbased techniques e.g.
statistical debugging collect and analyze runtime data about the instrumented predicates to find the location of the bugs.
both spectrum based and instrumentationbased techniques typically rank the lines of code based on some suspiciousness measure.
tarantula marks a statement possibly faulty if it is primarily executed by failing runs rather than being exclusively covered by them.
our approach utilizes these metrics for spectra based localization however incremental addition and processing of test cases along with the input from the unsat core analysis generates results with higher precision.
.
conclusion sat tar combines unsatisfiability analysis of correctness specifications and test spectra based localization in a novel feedback driven manner to iteratively refine localization results.
the technique shows benefit in multi fault cases as well.
case studies on typical data structure programs indicate that sat tar can produce more accurate localization than existing approaches.
.