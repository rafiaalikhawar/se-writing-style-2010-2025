checking app behavior against app descriptions alessandra gorla ilaria tavecchia florian gross andreas zeller saarland university saarbr cken germany gorla tavecchia fgross zeller cs.uni saarland.de abstract how do we know a program does what it claims to do?
after clustering android apps by their description topics we identify outliers in each cluster with respect to their api usage.
a weather app that sends messages thus becomes an anomaly likewise a messaging app would typically not be expected to access the current location.
applied on a set of android applications our chabada prototype identified several anomalies additionally it flagged of novel malware as such without requiring any known malware patterns.
categories and subject descriptors d. .
invasive software general terms security keywords android malware detection description analysis clustering .
introduction checking whether a program does what it claims to do is a longstanding problem for developers.
unfortunately it now has become a problem for computer users too.
whenever we install a new app we run the risk of the app being malware that is to act against the interests of its users.
research and industry so far have focused on detecting malware by checking static code and dynamic behavior against predefined patterns of malicious behavior.
however this will not help against new attacks as it is hard to define in advance whether some program behavior will be beneficial or malicious.
the problem is that any specification on what makes behavior beneficial or malicious very much depends on the current context.
in the mobile world for instance a behavior considered malicious in one app may well be a feature of another app ilaria tavecchia is now with swift brussels belgium.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
icse may june hyderabad india copyright acm ... .
.
.
app collection .
topics weather map ... travel map ... theme .
clusters weather travelthemes access locationinternet access locationinternetsend sms .
used apis5.
outliersweather travelfigure detecting applications with unadvertised behavior.
starting from a collection of good apps we identify their description topics to form clusters of related apps .
for each cluster we identify the sentitive apis used and can then identify outliers that use apis that are uncommon for that cluster .
an app that sends a text message to a premium number to raise money is suspicious?
maybe but on android this is a legitimate payment method for unlocking game features.
an app that tracks your current position is malicious?
not if it is a navigation app a trail tracker or a map application.
an application that takes all of your contacts and sends them to some server is malicious?
this is what whatsapp does upon initialization one of the world s most popular mobile messaging applications.
the question thus is not whether the behavior of an app matches a specific pattern or not it is whether the program behaves as advertised.
in all the examples above the user would be informed and asked for authorization before any questionable behavior.
it is thecovert behavior that is questionable or downright malicious.
in this paper we attempt to check implemented app behavior against advertised app behavior.
our domain is android apps so chosen because of its market share and history of attacks and frauds.
as a proxy for the advertised behavior of an app we use its natural language description from the google play store.
as a proxy for its implemented behavior we use the set of android application programming interfaces apis that are used from withinpermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may june hyderabad india copyright acm ... .
figure words in app descriptions of the navigation and travel cluster.
the bigger a word the more app descriptions it appears in.
figure words in personalize apps the app binary.
the key idea is to associate descriptions and api usage to detect anomalies this weather application accesses the messaging api which is unusual for this category.
specifically our chabada approach1takes five steps illustrated in figure and detailed later in the paper .chabada starts with a collection of good android applications downloaded from the google play store.
.using latent dirichlet allocation lda on the app descriptions chabada identifies the main topics theme map weather download for each application.
.chabada then clusters applications by related topics.
for instance apps related to navigation and travel share several topics in their description so they form one cluster.
figure shows the word cloud for the descriptions of the apps in the navigation and travel cluster.
clusters very much differ by their word clouds compare for instance the word cloud for the personalization cluster figure .
.in each cluster chabada identifies the apis each app statically accesses.
we only consider sensitive apis which are governed by a user permission.
for instance apis related to internet access are controlled by an internet permission.
figure shows the sensitive apis used by navigation and travel applications grouped by the governing permission.
obviously the normal behavior for these apps is to access the current location and access the internet typically a map 1chabada stands for checking app behavior against descriptions of apps.
chabada is a french word for the base ternary rhythm pattern in jazz.
figure apis grouped by associated permission used within the navigation and travel cluster.
standard behavior is to access the location access fine location and access the internet access network state internet .
figure apis for the personalize cluster.
in contrast to figure these apps frequently access the sd card write external storage enable and disable new features change component enabled state but rarely if ever access the device location.
server .
internet access is also used by personalize apps figure however they would access external storage and components rather than the current location.
.using unsupervised one class svm anomaly classification chabada identifies outliers with respect to apiusage.
it produces a ranked list of applications for each cluster where the top apps are most abnormal with respect to their api usage indicating possible mismatches between description and implementation.
likewise yet unknown applications would first be assigned to the cluster implied by their description and then be classified as being normal or abnormal.
in the navigation and travel cluster the usage of any api that changes the configuration of the phone or its components would be unusual this however is common for personalize apps which in turn rarely access the current location.
in both clusters any app that would read or write contacts calendar entries pictures text messages the browser history network settings etc.
would immediately be flagged as an outlier and thus be subject to further scrutiny.
by flagging anomalous apiusage within each cluster chabada is set up to detect any kind of mismatch between advertised and implemented behavior.
how does this work in practice?
figure shows london restaurants pubs available from the google play store.
its description clearly puts it into the navigation and travel cluster.
besides expected apicalls to access the current location and the internet however it also uses three apicalls to retrieve the list of user accounts on the device getaccountsbytype getdeviceid and getline1number all governed by the getaccounts permission.
these calls which retrieve sensitive information such as the device identifier and mobile phone number make london restaurants an outlier within navigation and travel .
indeed london restaurants covertly sends this information including additional information such as the current location to its advertisement service which is not mentioned at all in the description.
id com.alarisstudio.maps.restaurants.london1026looking for a restaurant a bar a pub or just to have fun in london?
search no more!
this application has all the information you need you can search for every type of food you want french british chinese indian etc.
you can use it if you are in a car on a bicycle or walking you can view all objectives on the map you can search objectives you can view objectives near you you can view directions visual route distance and duration you can use it with street view you can use it with navigationkeywords london restaurants bars pubs food breakfast lunch dinner meal eat supper street view navigationfigure the app london restaurants bars pubs together with complete description and apigroups accessed is this malware?
possibly.
is this unexpected behavior?
certainly.
iflondon restaurants had been explicit about what it does it would have fallen in an advertisements cluster instead where it would no longer be an outlier.
in our research we found several more examples of false advertising plain fraud masquerading and other questionable behavior.
as a side effect our approach is also effective as a malware detector training per cluster svm classifiers on benign applications chabada flagged of known malware as such without requiring any training on malware patterns.
the remainder of this paper is organized as follows.
we first detail how to cluster applications by description topics in section .
section describes how in each cluster we detect outliers with respect to their apiusage.
section evaluates our approach manually and automatically quantitatively and qualitatively.
after discussing the related work section section closes with conclusion and consequences.
.
clustering apps by description the intuition behind chabada is simple applications that are similar in terms of their descriptions should also behave similarly.
for this we must first establish what makes two descriptions similar .
we start with our collection method for android apps section .
.
after initial processing section .
chabada identifies topics of app descriptions section .
and then clusters the apps based on common topics section .
to section .
.
.
collecting applications our approach is based on detecting anomalies from normal hopefully benign applications.
as a base for such normal behavior we collected a large set of applications from the google play store the central resource for android apps.
our automated collection script ran at regular intervals during the winter and spring of and for each of the categories in the google play store downloaded the top free4applications in each category.
a 3when installing london restaurants the user must explicitly acknowledge its set of permissions but why would the user find something like account access unusual or suspicious?
4section .
discusses possible induced bias.single complete run of our script thus returned apps as the top apps shifted during our collection we obtained a total of apps across all categories.
in addition to the actual app coming as an apk file we also collected the store metadata such as name description release date user ratings or screenshots.
as chabada is set to identify outliers before they get released to the public it only uses name and description.
.
preprocessing descriptions with nlp before subjecting our descriptions to topic analysis we applied standard techniques of natural language processing nlp for filtering and stemming.
app descriptions in the google play store frequently contain paragraphs in multiple languages for instance the main description is in english while at the end of the description developers add a short sentence in different languages to briefly describe the application.
to be able to cluster similar descriptions we had to choose one single language and because of its predominance we chose english.
to remove all paragraphs of text that were not in english we ran google s compact language detector5to detect their most likely language non english paragraphs were removed.
after multi language filtering we removed stop words common words such as the is at which on .
.
.
and applied stemming on all descriptions.
stemming is a common nlptechnique to identify the word s root and it is essential to make words such as playing player and play all match to the single common root plai .
stemming can improve the results of later nlp processes since it reduces the number of words.
we also removed non text items such as numerals html tags links and email addresses.
as an example consider the description of london restaurants in figure after stop word removal and stemming it appears as look restaur bar pub just fun london search applic inform need can search everi type food want french british chines indian etc can us car bicycl walk can view object map can search object can view object near can view direct visual rout distanc durat can us street view can us navig keyword london restaur bar pub food breakfast lunch dinner meal eat supper street view navig with that we eliminated those applications from our set whose description would have less than words after the above nlp preprocessing.
also we eliminated all applications without any sensitive apis see section for details .
this resulted in a final set of apps which form the base for our approach.
.
identifying topics with lda to identify sets of topics for the apps under analysis we resort to topic modeling using latent dirichlet allocation lda .
lda relies on statistical models to discover the topics that occur in a collection of unlabeled text.
a topic consists of a cluster of words that frequently occur together.
by analyzing a set of app descriptions on navigation and travels for instance lda would group words such as map traffic route and position into one cluster and city attraction tour and visit into another cluster.
applications whose description is mainly about navigation would thus be assigned to the first topic since most of the words occurring in the description belong to the first cluster.
applications such as london restaurants however would be assigned to both topics as the words in the description appear in both clusters.
our implementation feeds output of nlp pre processing i.e.
the english text without stop words and after stemming into the mallet framework .
we could freely choose the number of topics to topics mined from android apps id assigned name most representative words stemmed personalize galaxi nexu device screen effect instal customis game and cheat sheets game video page cheat link tip trick money slot machine money poker currenc market trade stock casino coin finance tv tv channel countri live watch germani nation bbc newspap music music song radio play player listen holidays and religionchristmas halloween santa year holiday islam god navigation and travel map inform track gps navig travel language language word english learn german translat share email ad support facebook share twitter rate suggest weather and stars weather forecast locate temperatur map city light files and video file download video media support manage share view search photo and social photo friend facebook share love twitter pictur chat messag galleri hot send social cars car race speed drive vehicl bike track design and art life peopl natur form feel learn art design uniqu effect modern food and recipes recip cake chicken cook food personalize theme launcher download install icon menu health weight bodi exercise diet workout medic travel citi guid map travel flag countri attract kids and bodies kid anim color girl babi pictur fun draw design learn ringtones and sound sound rington alarm notif music game game plai graphic fun jump level ball 3d score search and browse search icon delet bookmark link homepag shortcut browser battle games story game monster zombi war battle settings and utils screen set widget phone batteri sports team football leagu player sport basketbal wallpapers wallpap live home screen background menu connection device connect network wifi blootooth internet remot server policies and ads live ad home applovin notif data polici privacy share airpush advertis popular media seri video film album movi music award star fan show gangnam top bieber puzzle and card games game plai level puzzl player score challeng card be identified by lda and we chose the number of categories covered by our apps in the google play store.
furthermore we set up the lda such that an app would belong to at most topics and we consider an app related to a topic only if its probability for that topic is at least .
table shows the resulting list of topics for the descriptions that we analyzed the assigned name is the abstract concept we assigned to that topic.
our example application london restaurants is assigned to three of these topics topic navigation and travel with a probability of .
topic food and recipes with a probability of .
and topic travel with a probability of .
.
.
clustering apps with k means topic modeling assigns an application description to each topic with a certain probability.
in other words each application is characterized by a vector of affinity values probabilities for each topic.however what we want is to identify groups of applications with similar descriptions and we do that using the k means algorithm one of the most common clustering algorithms .
given a set of elements in a metric space and the number k of desired clusters k means selects one centroid for each cluster and then associates each element of the data set with the nearest centroid thus identifying clusters.
in this context the elements to be clustered are the applications as identified by their vector of affinities to topics.
table shows four applications app1 app4 with the corresponding probabilities of belonging to four topics.
when applied to this set of applications with k 2clusters k means returns one cluster with app1andapp3 and another cluster with app2andapp4.
table four applications and their likelihoods of belonging to specific topics application topic1topic2topic3topic4 app1 .
.
app2 .
.
app3 .
.
.
app4 .
.
.
finding the best number of clusters one of the challenges with k means is to estimate the number of clusters that should be created.
the algorithm needs to be given either some initial potential centroids or the number kof clusters to identify.
there exist several approaches to identify the best solution among a set of possible solutions.
therefore we run k means several times each time with a different knumber to obtain a set of clusterings we would then be able to evaluate.
the range for k covers solutions among two extremes having a small number of clusters even just with a large variety of apps or having many clusters potentially even one per app and thus being very specific.
we fixed num topics 4as an upper bound since in our settings an application can belong to up to topics.
to identify the best solution i.e.
the best number of clusters we used the elements silhouette as discussed in .
the silhouette of an element is the measure of how closely the element is matched to the other elements within its cluster and how loosely it is matched to other elements of the neighboring clusters.
when the value of the silhouette of an element is close to it means that the element is in the appropriate cluster.
if the value is close to instead it means that the element is in the wrong cluster.
thus to identify the best solution we compute the average of the elements silhouette for each solution using kas the number of clusters and we select the solution whose silhouette was closest to .
.
resulting app clusters table shows the list of clusters that were identified for the apps that we analyzed.
each of these clusters contains apps whose descriptions contain similar topics listed under most important topics .
the percentages reported in the last column represent the weight of specific topics within each cluster.
the clusters we identified are quite different from the categories one would find in an app store such as the google play store.
cluster advertisements for instance is filled with applications that do nothing but display ads in one way or another these apps typically promise or provide some user benefit in return.
cluster connection represents all application that deal with bluetooth wi fi etc.
there is no such category in the google play store.
the several wallpaper clusters from adult themes to religion simply represent the fact that several apps offer very little functionality.1028table clusters of applications.
size is the number of applications in the respective cluster.
most important topics list the three most prevalent topics most important shown in bold.
topics less than not listed.
id assigned name size most important topics sharing share settings and utils navigation and travel puzzle and card games puzzle and card games share game memory puzzles puzzle and card games game share music music share settings and utils music videos popular media holidays and religion share religious wallpapers holidays and religion design and art wallpapers language language share settings and utils cheat sheets game and cheat sheets share popular media utils settings and utils share connection sports game game battle games puzzle and card games battle games battle games game design and art navigation and travel navigation and travel share travel money money puzzle and card games settings and utils kids kids and bodies share puzzle and card games personalize personalize wallpapers settings and utils connection connection settings and utils share health health design and art share weather weather and stars settings and utils navigation and travel sports sports share popular media files and videos files and videos share settings and utils search and browse search and browse game puzzle and card games advertisements policies and ads design and art design and art share game car games cars game puzzle and card games tv live tv share navigation and travel adult photo photo and social share settings and utils adult wallpapers wallpapers share kids and bodies ad wallpapers policies and ads wallpapers settings and utils ringtones and sound ringtones and sound share settings and utils theme wallpapers wallpapers holidays and religion share personalize personalize share settings and utils settings and wallpapers settings and utils wallpapers personalize the london restaurants app ended up in cluster together with other applications that are mostly about navigation and travels.
these are the clusters of apps related by their descriptions in which we now can search for outliers with respect to their behavior.
.
alternative clustering approaches as with most scientific work the approach presented in this paper only came to be through several detours dead ends andrefinements.
we briefly list the most important ones here as to have future researchers avoid some of the problems we encountered.
usage of topics.
one might wonder if it is really necessary to cluster based on topics instead of clustering plain descriptions directly.
the reason is that k means as well as any other clustering algorithm works better when few features are involved.
hence abstracting descriptions into topics was crucial to obtain better clustering results.
usage of clusters.
having just one dominant topic for applications did not yield better results since several applications may incorporate multiple topics at once.
this also excluded the usage of the given google play store categories as a clustering strategy.
despite one might argue that clustering does not produce different results than just clustering on the predominant topics the number of topics and cluster is almost the same one should also notice that clusters have quite different features than topics.
for instance cluster advertisements groups applications whose main topic is about wallpapers and mention in the description that the application is using advertisements.
this contrasts to cluster settings and wallpapers for instance which also groups applications that are about wallpapers but do notmention advertisements in the description.
one cluster per app.
as it is now each application belongs to one cluster which may incorporate multiple topics.
this leads to a good clustering of similar apps.
a yet unexplored alternative is to allow an app to be a member of multiple clusters.
this might potentially provide better clustering results.
choice of clustering method.
before using k means we experimented with formal concept analysis to detect related concepts of topics and features without successful results the analysis was overwhelmed by the number of apps and features.
k means has known limitations and we believe that other clustering algorithms could improve the clustering.
low quality apps.
app stores like the google play store contain several free applications of questionable value.
restricting our approach to a minimum number of downloads or user ratings may yield very different results.
however the goal of our approach is to identify outliers before users see them and consequently we should consider all apps.
.
identifying outliers by apis now that we have clustered apps based on similarity of their description topics we can search for outliers regarding their actual behavior.
section .
shows how we extract apifeatures from android binaries.
section .
focuses on apis controlled by permissions.
section .
describes how chabada detects apioutliers.
.
extracting api usage as discussed in the introduction we use static apiusage as a proxy for behavior.
going for apiusage is straightforward while android bytecode can also be subject to advanced static analysis such as information flow analysis and standard obfuscation techniques that easily thwart any static analysis apiusage has to be explicitly declared in android binaries as in most binaries on other platforms static apiusage is easy to extract.
for each android application we extracted the binary apk file with apktool6 and with asmali disassembler we extracted all apiinvocations including the number of call sites for each api.
sensitive apis used in london restaurants .
the bold apis make this app an outlier in its cluster.
android.net.connectivitymanager.getactivenetworkinfo android.webkit.webview java.net.httpurlconnection.connect android.app.notificationmanager.notify java.net.url.openconnection android.telephony.telephonymanager.getdeviceid org.apache.http.impl.client.defaulthttpclient org.apache.http.impl.client.defaulthttpclient.execute android.location.locationmanager.getbestprovider android.telephony.telephonymanager.getline1number android.net.wifi.wifimanager.iswifienabled android.accounts.accountmanager.getaccountsbytype android.net.wifi.wifimanager.getconnectioninfo android.location.locationmanager.getlastknownlocation android.location.locationmanager.isproviderenabled android.location.locationmanager.requestlocationupdates android.net.networkinfo.isconnectedorconnecting android.net.connectivitymanager.getallnetworkinfo .
sensitive apis using allapicalls as features would induce overfitting in later stages.
therefore we select a subset of apis namely the sensitive apis that are governed by an android permission setting.
these apis access sensitive information such as the user s picture library the camera or the microphone or perform sensitive tasks altering system settings sending messages etc.
when installing an app the user must explicitly permit usage of these apis.
for this purpose each android app includes a manifest file which lists the permissions that the application requires for its execution.
to obtain the set of sensitive apis we relied on the work of felt et al.
who identified and used the mapping between permissions and android methods we considered a sensitive apito be used by the app if and only if it is declared in the binary and if its corresponding permission is requested in the manifest file.
this allowed us to eliminate api calls that are used within third party libraries and not used by the application directly.
as an example for such sensitive apis consider table .
these are the apis used by the london restaurants app that would be governed by a specific permission.
through these apis the app accesses the current network provider the last known location as well as updates and the internet via an http connection.
these apis also reveal that the app accesses the device identifier the user s account info as well as the mobile phone line1 number.
these latter apis shown in bold would be governed by the getaccounts permission.
as each permission governs several apis using permissions alone would give us too few features to learn from.
instead the sensitive apis allow for a much more fine grained characterization of the application behavior.
.
identifying api outliers with oc svms now that we have all apifeatures for all apps the next step is to identify outliers that is those applications whose apiusage would be abnormal within their respective topic cluster.
to identify these outliers we use one class support vector machine learning oc svm which is a machine learning technique to learn the features of one class of elements.
the resulting svm model can later be used for anomaly novelty detection within this class.
note how this is in contrast to the more common usage of support vector machines as classifiers where each app additionally has to be labeled as belonging to a specific class say benign vs. malicious during training.
oc svm has been successfully applied in various contexts that span from document classification to automatic detection ofanomalous windows registry accesses .
in our context the interesting feature of oc svm is that one can provide only samples of one class say of regular benign applications and the classifier will be able to identify samples belonging to the same class tagging the others as anomalies.
oc svm s therefore are mainly used in those cases in which there exist many samples of one class of elements e.g.
benign applications and not many samples of other classes e.g.
malicious applications .
with the sensitive apis as binary features chabada trains an oc svm within each cluster with a subset of the applications in order to model which apis are commonly used by the applications in that cluster.
the resulting cluster specific models are then used to identify the outlier applications i.e.
applications whose used apis differ from the common use of the apiwithin the same cluster.
to represent the distance of an element from the common behavior we use the actual distance of the element from the hyperplane that the oc svm builds.
the bigger this distance the further an element is from the commonly observed behavior.
thus by ranking the elements i.e.
apps by their distance to the oc svm hyperplane we can identify which ones have behaviors that differ the most from what has been commonly observed.
as an example consider again our london restaurants app.
after training the oc svm on the apps in cluster it classifies london restaurant as an outlier.
the reason is the apis shown in bold in table indeed accessing the device identifier the user s account info or his mobile phone number is uncommon for the apps in the navigation and travel cluster.
in our evaluation in section we discuss trends that make an app an outlier.
.
alternative approaches to detect anomalies we have identified several alternative settings some of which we already experimented with.
again we briefly list them here.
class and package names as abstraction.
before going for sensitive apis with felt et al.
s mapping we considered abstracting theapimethod invocations by considering only the class name or the package name instead of the whole method signature.
although this helped reducing the number of features it also caused a loss of relevant information.
invocations to sensitive methods such as getline1number which returns the user s phone number would be indistinguishable from relatively harmless methods such as getnetworktype which returns the current data connection since they are both declared in class telephonymanager .
number of call sites.
for each apiwe considered a binary value i.e.
there exists at least one call site for that apiin the app or not .
we could have considered the normalized number of call sites for each apias a feature.
we expect similar results although we only experimented with binary values.
tf idf forapis.since some apis are commonly used across all clusters for instance apis for internet access we could have considered only the most relevant and representative methods for the cluster instead of all the methods.
term frequencyinverse document frequency tf idf could filter out some of the non discriminant features thus providing even greater support for the oc svm algorithm.
we have not tried this path yet although we plan to investigate it in the near future.
insensitive apis.to avoid overfitting limiting the number of features is crucial.
hence we focused on apis that would be1030 sensitive that is impacted by android permissions.
expanding this set to other relevant apis might yield even better results.
permissions instead of apis.instead of apis we could have used the list of permissions in the manifest file as features.
however studies showed that almost of android applications request more permissions than they actually use .
we chose apis since they provide a more fine grained view into what apps do and do not.
avoiding apis as predictors alone.
when training a classifier on descriptions and apis of known malware the specific apis being used in the malware set typically sending text messages will dominate the descriptions.
by first clustering by descriptions and then classifying we obtain better results.
.
ev aluation to evaluate the effectiveness of our technique we investigated the following main research questions rq1 can our technique effectively identify anomalies i.e.
mismatches between description and behavior in android applications?
for this purpose we manually inspected the top outliers as produced by our technique and classified them with respect to covert behavior section .
.
rq2 can our technique be used to identify malicious android applications?
for this purpose we included in our set of applications a set of known malware and we ran oc svm as a classifier section .
.
.
outlier detection let us start with rq1 can our technique effectively identify anomalies i.e.
mismatches between description and behavior in android applications?
for this purpose we ran chabada on all clusters as described in section .
following k fold validation we partitioned the entire set of applications in subsets and we used subsets for training the model and for testing.
we ran this times each time considering a different subset for testing.
out of the whole list of outliers identified in each run we identified the top outliers from the ranked list for each cluster.
these outliers would now have to be assessed whether they would really exhibit suspicious behavior.
.
.
manual assessment in the end only a human can interpret properly what is in an app description.
therefore for these applications we would manually examine their description the list of apis used as manually inspect the code.
we would classify each of the apps into one of three categories malicious the app shows unadvertised covert behavior using sensitive apis that acts against the interest of its users.
dubious the app shows unadvertised covert behavior using sensitive apis but would notnecessarily act against the user s interests.
benign all sensitive behavior is properly described.
this includes apps which clearly list the sensitive data they collect and also applications placed in the wrong cluster due to inadequate descriptions.we applied an innocent unless proven guilty principle on average each such assessment would take minutes for benign applications and up to minutes for dubious or malicious applications.
table summarizes our assessment.
overall we clearly identified outliers as malware which is of our sample.
given that these apps stem from an app store that is supposed to maintain quality this is a worrying result.7even more worrying is that there are clusters of apps in which the majority of outliers are all malicious.
in clusters kids connection ad wallpapers theme wallpapers the majority of outliers are malicious.
the good news in all of this is that the outliers as reported by chabada are worth looking into of the top outliers require additional scrutiny by app store managers or end users who may just as well run chabada for their protection.
top outliers as produced by chabada contain malware additional apps show dubious behavior.
.
.
what makes an outlier?
during our investigation we identified a number of repeating trends that determined whether an app would be an outlier or not.
these trends can be characterized as follows spyware ad frameworks.
a large portion of the malicious apps we found are spyware.
we identified multiple applications in different clusters that get sensitive information such as the user s phone number the device id the user s current location and the list of emails used in different accounts such as the google and facebook accounts.
apps do not use this information for themselves but they retrieve these data only because they include third party libraries for advertisements and advertisement companies such as apploving andairpush pay application developers for users sensitive information.
some apps clearly state that they include such frameworks and most of them ended up in the advertisements cluster where such behavior is normal.
apps that do not mention the usage of such frameworks and their impact on privacy however are spyware.
just to mention a few examples we found mosquito killer apps such as mosquito repellent no ads anti mosquitoes mosquito repellent plus wedding apps such as wedding ideas gallery and apps with collections of wallpapers such as christmas girl live wallpaper andtwilight live wallpaper .
since they all include the same ad frameworks they all get the sensitive data mentioned above and send it to ad servers.
dubious behavior.
in dubious applications whose description does not completely justify the behavior.
for instance the uno free game application accesses the user s location without explanation and wicked the official application for a broadway show can record audio but it does not say for which purposes.
runtastic a widely used training application can also record audio but it does not mention it in the description.
finally y ahoo!
mail which is the official application to browse and compose emails with yahoo can send smss.
from the description it is not clear why the application should do that.
misclassified apps.
some benign applications were misclassified on the basis of their descriptions and consequently were assigned to clusters popu7note though that between the time of download and the time of writing many of these applications had already been identified as malicious by users and since been removed.1031table manual assessment of the top outliers per cluster and total.
behavior total malicious dubious benign lated by applications that cover substantially different topics.
for instance slideit free keyboard which is a popular tool to insert text by sliding the finger along the keyboard letters ended up in the language cluster since more than half of the description is about the language support.
romanian racing which is a racing game also ended up in the same cluster mainly because its brief description mentions multi language support.
we also had some rare cases of applications that were associated to completely unexpected clusters.
hamster life a pet training game ended up in the religious wallpapers cluster.
uncommon behavior.
some apps were tagged as outliers because their behavior although benign and clearly described is just very uncommon for the clusters these applications belong to.
for instance soundcloud music audio was tagged as an anomaly mainly because it records audio.
this is expected behavior since the application connects to a platform for finding and sharing new music and it allows to record music that users produce.
however recording audio is not one of the common features of cluster and consequently soundcloud was tagged as an anomaly.
similarly llama location profiles which allows to change the ringtones depending on the context and location was tagged as an anomaly because it is not common for personalization applications to access the user s location and calendar.
this application though uses this information to automatically switch between vibrate and ringtones when the user for instance is at home in office or has a meeting.
benign outliers.
in some clusters chabada identified the uncommon behavior as thelack of malicious behavior .
for instance cluster money contains several applications that use libraries for advertisements and thus access sensitive information.
as a consequence mr. will s stud poker andmr.
will s draw poker were tagged as anomalies because they do notaccess sensitive information despite them being poker games.
chabada is behavior agnostic it cannot determine whether an application is good or bad only if it is common or not.
.
malware detection let us now turn to rq2 can our technique be used to identify malicious android applications?
for this purpose we used the dataset of zhou et al.
containing more than known malicious apps for android.
in their raw form these apps lack metadata such as title or description.
as many of these apps are repackaged versions of an original app we were able to collect the appropriate description from the google play store.
we used the title of the application and the package identifier to search for the right match in the store.
for cases we could find exactly the same package identifier and for applications we found applications whose package identifier was very similar.
we manually checked that the match was correct.
as with our original set of benign apps section .
we only kept those applications with an english description in the set reducing it to apps.as a malware detector we again used the oc svm model but this time we would use it as a classifier that is we used the svm model for a binary decision on whether an element would be part of the same distribution or not.
.
.
classification using topic clusters we ran the classification on the benign set of apps used in the previous study and we included the malware samples for which we could find the corresponding description.
we trained the ocsvm only on benign applications as before and we excluded the applications manually classified as malicious during the previous experiment section .
we then trained within each cluster the oc svm on the apis of of these apps and then used the ocsvm as a classifier on a testing set composed of the known malicious apps in that cluster as well as the remaining benign apps.
what we thus simulated is a situation in which the malware attack is entirely novel chabada must correctly identify the malware as such without knowing previous malware patterns.
as for the previous experiment we would do this times each time considering a different test set.
the number of malicious applications would notbe equally distributed across clusters as malicious applications are assigned to clusters depending on their descriptions.
in our evaluation setting with our data set the number of malicious applications per cluster spans from to .
the results of our classification are shown in table .
we report the average results of the different runs.
chabada correctly identifies of the malicious apps as such while only of benign apps are misclassified.
if our approach would be used to guard against yet unknown malicious behavior it would detect the majority of malware as such.
table checking apis and descriptions within topic clusters our approach predicted as malicious predicted as benign malicious apps .
.
benign apps .
.
compared against standard malware detectors these results of course leave room for improvement but that is because existing malware detectors compare against known malware whose signatures and behavior are already known.
for instance accessing all user accounts on the device as the london restaurants app does is a known pattern of malicious behavior.
in practice our approach would thus be used to complement such detectors and be specifically targeted towards novel attacks which would be different from existing malware but whose apiusage is sufficiently abnormal to be flagged as an outlier.
in our sample even without knowing existing malware patterns chabada detects the majority of malware as such.
.
.
classification without clustering we further evaluate the effectiveness of our approach by comparing it against alternatives.
to show the impact of topic clustering we compare our classification results against a setting in which the1032oc svm would be trained on sensitive apis and nlp preprocessed words from the description alone that is all applications form one big cluster.
as table shows the malware detection rate decreases dramatically.
this shows the benefits of our clustering approach.
table checking apis and descriptions in one single cluster predicted as malicious predicted as benign malicious apps benign apps .
.
classifying without clustering yields more false negatives.
.
.
classification using given categories finally one may ask why our specific approach for clustering based on description topics would be needed as one could also easily use the given store categories.
to this end we clustered the applications based on their categories in the google play store and repeated the experiment with the resulting clusters.
the results demonstrate the general benefits of clustering however topic clustering as in our approach is still clearly superior.
additionally one may argue that a category is something that some librarian would assign thus requiring more work and more data.
table checking apis and descriptions within google play store categories predicted as malicious predicted as benign malicious apps .
.
benign apps .
.
clustering by description topics is superior to clustering by given categories.
.
limitations and threats to validity like any empirical study our evaluation is subject to threats to validity many of which are induced by limitations of our approach.
the most important threats and limitations are listed below.
external validity.
chabada relies on establishing a relationship between description topics and program features from existing assumed mostly benign applications.
we cannot claim that said relationships could be applied in other app ecosystems or be transferable to these.
we have documented our steps to allow easy replication of our approach.
free apps only.
our sample of apps is based on free applications only i.e.
applications that need to generate income through ads purchases or donations.
not considering paid applications makes our dataset biased.
however the bias would shift normality more towards apps supported by ads and other income methods which are closer to undesired behavior exposed by malware.
our results thus are conservative and would rather be improved through a greater fraction of paid applications which can be expected to be benign.
app and malware bias.
our sample also only reflects the top downloads from each category in the google play store.
this sample is biased towards frequently used applications and towards lesser used categories likewise our selection of malware section may or may not be representative for current threats.
not knowing which actual apps are being used and how by android users these samples may be biased.
again we allow for easy reproduction of our approach.researcher bias.
our evaluation of outliers is based on the classification by a single person who is a co author of this paper.
this poses the risk of researcher bias i.e.
the desire of an author to come up with best possible results.
to counter this threat we are making our dataset publicly available section .
native code and obfuscation.
we limit our analyses to the dalvik bytecode.
we do not analyze native code.
hence an application might rely on native code or use obfuscation to perform covert behavior but then such features may again characterize outliers also neither of these would change the set of apis that must be called.
static analysis.
as we rely on static apiusage we suffer from limitations that are typical for static analysis.
in particular we may miss behavior induced through reflection i.e.
code generated at runtime.
although there exist techniques to statically analyze java code using reflection such techniques are not directly applicable with android apps in the long run dynamic analysis paired with test generation may be a better option.
static api declarations.
since we extract apicalls statically we may consider apicalls that are never executed by the app.
checking statically whether an apiis reached is an instance of the undecidable halting problem.
as a workaround we decided to consider an apionly if the corresponding permission is also declared in the manifest.
sensitive apis.our detection of sensitive apis section .
relies on the mapping by felt et al.
which now two years later may be partially outdated.
incorrect or missing entries in the mapping would make chabada miss or misclassify relevant behavior of the app.
.
related work while this work may be the first to generally check app descriptions against app behavior it builds on a history of previous work combining natural language processing and software development.
.
mining app descriptions most related to our work is the whyper framework of pandita et al.
.
just like our approach whyper attempts to automate the risk assessment of android apps and applies natural language processing to app descriptions.
the aim of whyper is to tell whether the need for sensitive permissions such as accesses to contacts or calendar is motivated in the application description.
in contrast to chabada which fully automatically learns which topics are associated with which apis and by extension which permissions whyper requires manual annotation of sentences describing the need for permissions.
also chabada goes beyond permissions in two ways first it focuses on apis which provide a more detailed view and it aims for general mismatches between expectations and implementations.
the very idea of app store mining was introduced one year earlier when harman et al.
mined the blackberry app store .
they focused on app meta data to find patterns such as a correlation consumer rating and the rank of app downloads but would not download or analyze the apps themselves.
our characterization of normal behavior comes from mining related applications in general we assume what most applications in a well maintained store do is also what most users would expect to be legitimate.
in contrast recent work by lin et al.
suggests1033crowdsourcing to infer what users expect from specific privacy settings just like we found lin et al.
also highlight that privacy expectations vary between app categories.
such information from users can well complement what we infer from app descriptions.
.
behavior description mismatches our approach is also related to techniques that apply natural language processing to infer specifications from comments and documentation.
lin tan et al.
extract implicit program rules from program corpora and use these rules to automatically detect inconsistencies between comments and source code indicating either bugs or bad comments.
rules apply to ordering and nesting of calls and resource accesses famust not be called from fb .
h st and stvold learn from program corpora which verbs and phrases would normally be associated with specific method calls and used these to identify misnamed methods.
pandita et al.
identify sentences that describe code contracts from more than sentences of apidocuments these contracts can be checked either through tests or static analysis.
all these approaches compare program code against formal program documentation whose semi formal nature makes it easier to extract requirements.
in contrast chabada works on end user documentation which is decoupled from the program structure.
.
detecting malicious apps there is a large body of industrial products and research prototypes that focus on identifying known malicious behavior.
most influential for our work was the paper by zhou and jiang who use the permissions requested by applications as a filter to identify potentially malicious applications the actual detection uses static analysis to compare sequences of apicalls against those of known malware.
in contrast to all these approaches chabada identifies outliers even without knowing what makes malicious behavior.
the taintdroid system tracks dynamic information flow within android apps and thus can detect usages of sensitive information.
using such dynamic flow information would yield far more precise behavior insights than static apiusage similarly profilers such as profiledroid would provide better information however both taintdroid and profiledroid require a representative set of executions.
integrating such techniques in chabada combined with automated test generation would allow to learn normal and abnormal patterns of information flow this is part of our future work section .
.
conclusion and consequences by clustering apps by description topics and identifying outliers byapiusage within each cluster our chabada approach effectively identifies applications whose behavior would be unexpected given their description.
we have identified several examples of false and misleading advertising and as a side effect obtained a novel effective detector for yet unknown malware.
just like mining software archives has opened new opportunities for empirical software engineering we see that mining apps and their descriptions opens several new opportunities for automated checking of natural language requirements.
during our work we have gained a number of insights into the android app ecosystem that call for action.
first and foremost application vendors must be much more explicit about what their apps do to earn their income.
app store suppliers such as google should introduce better standards to avoid deceiving or incomplete advertising.
second the way android asks its users for permissions is broken.
regular users will not understand what allow access to the device identifier means nor would they have means to checkwhat is actually being done with their sensitive data nor would they understand the consequences.
users understand though what regular apps do and chabada is set to point out and highlight differences which should be way easier to grasp.
although our present approach came to be by exploring and refining several alternatives we are well aware that it is by no means perfect or complete.
our future work will focus on the following topics detailed behavior patterns.
static apiusage is a rather broad abstraction for characterizing what an app does and what not.
more advanced methods could focus on the interaction of apis notably information flow between apis.
dynamic behavior.
exploring actual executions would give a far more detailed view of what an app actually does in particular concrete values for all apis accessing remote resources.
we are working on guitest generators for android apps that aim for coverage of specific apis or dynamic information flow.
natural language processing.
the state of the art in natural language processing can retrieve much more than just topics.
looking at dependencies between words such as conjunctions subject verb verb object could retrieve much more detailed patterns.
likewise leveraging known ontologies would help in identifying synonyms.
a rosetta stone for topics and behavior.
by mining thousands of applications we can associate natural language descriptions with specific program behavior.
the resulting mapping between natural language and program fragments help in program understanding as well as synthesis of programs and tests.
to allow easy reproduction and verification of our work we have packaged all data used within this work for download.
in particular we have prepared a mb dataset with the exact data that goes into chabada including app names descriptions other metadata permissions and apiusage.
all of this can be found on thechabada web site .