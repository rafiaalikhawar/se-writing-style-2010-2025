symbolic state validation through r untime data yueqi li shing chi cheung department of computer science and engineering hong kong university of science and technology hong kong department of computer science and engineering hong kong university of science and technology hong kong yueqili cse.ust.hk scc cse.ust.hk abstract real world programs are typically built on top of many library functions.
symbolic analysis of these programs generally requires precise models of these functions application programming interfaces apis which are mostly unavailable because these models are costly to construct.
a variant approach of symbolic analysis is to over approximate the return values of those apis that have not been modeled.
however such approximation can induce many unreachable symbolic states which are expensive to validate manually.
in this paper we propose a static approach to automatically validating the reported anomalous symbolic states.
the validation makes use of the available runtime data of the unmodeled apis collected from previous program executions.
we show that the symbolic state validation problem can be cast as a max sat problem and solved by existing constraint solvers.
our approach is motivated by two observations.
we may bind the symbolic parameters in un modeled apis based on observations made in former executions by other programs.
the binding enables us to use the corresponding observed concrete return values of apis to validate the symbolic states arising from the over approximated return values of the un modeled apis.
second some symbolic constraints can be accurately evaluated despite the imprecision of the over approximated symbolic values.
our technique found unreported bugs when it was applied to popular programs with a total of .
million lines of code.
all of them can be confirmed by test cases.
our technique presents a promising way to apply the big data paradigm to software engineering.
it provides a mechanism to validate the symbolic states of a project by leveraging the many concrete input output values of apis collected from other projects.
categories and subject descriptors f. .
program analysis keywords symbolic analysis api modeling dynamic analysis warning validation .
introduction existing symbolic analysis tools have shown promising results in checking program behavior .
we observe that real world programs often make heavy use of external library methods which can be invoked through their provided apis.
for example linux kernel .
.
invokes system library methods and glibc .
invokes library methods .
to apply symbolic analysis to reason about these programs the behavior associated with the library methods invoked needs to be considered .
the state of the art symbolic analysis engines like klee require explicit modeling of each library method s application programming interface api .
it is non trivial and rarely adopted by developers in practice due to the multitude of library methods involved.
for example jdk .
has over 5k native library methods with more than 500k slocs native code.
since modeling such scale of apis is expensive existing tools provide only the models of a small set of library apis.
besides the source code of many libraries is often not available .
even for symbolic execution engines that can handle binaries such as s2e the implementations of library calls are difficult to handle as they are often highly optimized extensively using caching hashing and bit level operations .
these difficulties hinder the wide adoption of symbolic analysis .
a variant approach is not to model all library apis but to overapproximate the return values of those un modeled apis .
recent study shows that symbolic analysis can scale up to large programs like hadoop by exploiting over approximated variables returned by un modeled apis.
however this approach requires developers to validate the feasibility of reported warnings because over approximation of return values often introduces infeasible behaviors in the analysis and hence generates false warnings .
the amount of false warnings can be numerous as reported by a recent study .
unfortunately the false warnings caused by over approximated return values can hardly be ruled out by constraint solvers because these warnings rarely give rise to constraint contradictions .
take the code snippet below for instance.
if error statement symbolic analysis of the snippet requires solving the constraint which is satisfiable if the return value of the un modeled api is over approximated to be any value.
this reported warning requires users to validate if can return a positive value greater than three in the program concerned.
real world programs typically comprise many different api calls.
for example a single execution path analyzed by symbolic analysis can make a few thousand different external api invocations in our subjects like hadoop or tomcat.
the accumulated effects arising from the over approximation of these apis generate numerous false warnings.
validating these warnings is expensive and a waste of effort .
our work is motivated by two questions.
first can the validation of warnings be performed mechanically by leveraging the runtime data of un modeled apis collected from a subject program s previous test runs?
second can the valida tion leverage the runtime data collected from other programs test runs that involve the apis used by a subject program?
the second question is permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permiss ion and or a fee.
copyright acm ... .
.
187ase septem ber vasteras sweden.
particularly applicable to the apis in jdk libraries which are commonly used by many java programs.
as such the feasibility of a constraint like due to the program in figure can be validated if we can find a test run of another program that has invoked with a return value larger than .
this feature greatly improves the applicability of symbolic analysis tools.
for instance it enables developers to perform bug detection on a partially completed program which is not runnable by using the runtime data of other programs.
in this paper we propose an effective approach to answering the two preceding questions .
our solution meets three requirements in order for it to be practically used on industrial scale programs.
first our approach is scalable that it can complement the scalable symbolic analysis approach to validate mechanically reported warnings.
second our approach does not require extra modeling effort of apis.
third our approach is static in the sense that it does not require new test runs.
it is particularly useful to the analysis of complex systems e.g.
hadoop whose runtime environments may not be easily reconfigured for running additional tests to validate warnings.
we build a database for java programs with about gb runtime data collected from published test runs of open source projects.
experiments on large real world programs show that our approach is able to distinguish true warnings from many false warnings.
to our best knowledge our tool is the first tool that is able to perform this kind of symbolic analysis on large subjects like tomcat and hadoop.
we found more than unknown real bugs based on our validated warnings.
all of these bugs are confirmed by test cases.
validating a reported warning is essentially checking the feasibility of its symbolic state.
imprecision of the symbolic analysis is introduced by over approximating the return values of un modeled api invocations .
the imprecision leads to uncertainties on whether such symbolic states are feasible.
our approach addresses the validation problem based on two insights.
first we observe that the actual parameters of an un modeled api invocation are often evaluated to symbolic values during symbolic analysis .
these symbolic values can be bound to some concrete values so that the api invocation can be validated by following an earlier observed execution of the api.
for example an api invocation receives a symbolic value as its actual parameter where may be evaluated to a symbolic expression like .
in order to leverage the information collected from dynamic analysis to validate this invocation we can bind symbolic actual parameter to a concrete value say observed in an earlier concrete execution of apicall .
this leads to an additional constraint the api invocation can now be validated if the conjunction of this additional constraint and the existing path condition is satisfiable.
second although over approximated api return values can induce imprecision to some symbolic variables the satisfiability of the constraints arising from the se variables can sometimes be accurately determined despite such imprecision.
for example let us consider a constraint where denotes an overapproximated variable derived from the return of an un modeled api and denotes a program input that is not confined to a particular concrete value .
the constraint is satisfiable regardless of s imprecise value because there always exists an input value that differs from x s bound value.
this insight enables us to attest the feasibility of some constraints in symbolic states even if we have inadequate runtime data to validate these constraints.
section .
shows that symbolic state validation problem can be reduced to max sat or sat problem that can be solved by existing efficient constraint solvers.
our previous work improves the scalability of symbolic analysis using a special type of symbolic state equivalence induced by api approximation.
like other similar techniques our previous work can result in false positive warnings.
we make three contributions in this paper.
first we develop a static and scalable approach to validating the warnings given by those symbolic analysis techniques that do not precisely model all apis.
second we implemented our technique as a tool.
third we applied our technique to large real world subjects with totally .
million lines of code and found over unreported bugs.
.
illustrative example we use a simple example in figure to illustrate the intuition of our approach.
suppose there is a previous test run of the example program with concrete bindings of and the return value of as and respectively .
the test run does not reach the error statement in line .
symbolic analysis of the program based on over approximation of the two un modeled apis return values finds an execution path with lines and reaching the error statement and reports a warning.
this execution path generates a path condition where and denote the return values of and respectively.
since the path condition does not have any contradiction constraint solvers cannot disprove the warning.
neither can constraint solvers prove the feasibility of the path condition due to the over approximated return values from the two un modeled apis.
our goal is to validate whether the error statement in line is truly reachable.
in our approach we distinguish the symbolic variables introduced by inputs from those introduced to denote over approximated return values of un modeled apis.
we can manipulate input symbolic variables without introducing imprecision in the sense that the se can be freely bound to arbitrary values .
as a result the warning validation problem is reduced to the checking of whether the two constraints and are feasible in some dynamic execution.
the checking can be performed as follows.
first can be validated by leveraging the previous dynamic test run.
we can bind to so that the parameter of is identical to the observed concrete actual parameter value in the test run.
12main intx input1 inty input2 intz input3 if external1 x external1 is an un modeled api if x y if external2 y x z external2 is an un modeled api errorstatement runtime data there was a test run with bindings of x y z and the return value of external1 as and .
the test run covers lines figure .
illustrative example 188as such we know that can bind to and is feasible.
this corresponds to our first insight.
there is no uncertainty in because we can manipulate to assume a value so that is satisfiable.
now we encounter difficulties in validating because we do not have sufficient runtime data about .
however the satisfiability of is independent of s binding because we can manipulate input3 to assume a value so that always holds regardless of s value.
this corresponds to our second insight which asserts the satisfiability of some constraints even without sufficient runtime data of the un modeled apis.
as a result we conclude that the warning reported by symbolic analysis is true.
in this example we may derive the path feasibility from the test runs of other programs that share the same apis.
for instance we can validate is feasible if we find that can return in an execution of another program with an actual parameter of .
as a result our solution can be static when we have pre built a runtime data database of the un model ed apis.
our approach differs from concolic testing.
assume that we apply concolic testing technique on this example.
without the source code of the un modeled apis concolic testing tools need to randomly try out some value of so that can be satisfied.
in practice concolic testing tools often fail to find appropriate values after large number of executions making it difficult for such tools to achieve high coverage on large programs .
for example xiao et al.
reported that it is hard for concolic testing tools to find a valid path string so that a system api like path .getfullpath can proceed withou t throwing exception.
higher order test generation approach is a complementary approach to concolic testing.
it requires validity proof showing that is satisfiable for arbitrary specifications of .
this approach has not yet been implemented due to the lack of efficient constraint solvers for the required logic.
.
approach we describe our approach in two subsections.
we first describe our refined symbolic analysis rules that record the contexts of unmodel ed api s invocation s. then we introduce how we model the state validation problem as a max sat problem which can be efficiently solved by existing constraint solvers .
.
simple language and semantics to facilitate our discussion w e describe symbolic analysis rules for a simple imperative language in figure .
our implementation supports the semantics of full fledged languages like java.
a program comprises a sequence of statements with expressions involving boolean and integer types.
the simple language supports conditional sequential and assignment statements.
there are three types of assignment statements which are and .
the first assignment statement updates variable x with value of the expression e. the only special elements in this language are and .
the element denotes reading an input.
the element denotes a returned value by an unmodeled api invocation.
we explicitly distinguish un modeled api invocation s i.e.
and inputs i.e.
in this simple language.
for example a statement reading an input from a file can be modeled by while a statement invoking an un modeled math library to get resulting data can be modeled by .
we distinguish them in order to address the imprecision issue caused by un modeled api invocations i.e.
.
the idea is that we can arbitrarily manipulate a set of input values returned from without introducing imprecision while arbitrarily manipulating return values from would introduce imprecision because of the ignorance of the internal logic of in the simple language each un modeled api invocation accepts only one input and one return value.
in section we show how to extend our simple language capture the effects of un modeled apis involving multiple inputs heap modifications and internal states that are invisible to symbolic execution engines.
this language does not have function declarations because it is not relevant to our discussion.
our implementation supports inter procedural analysis.
we define the semantic rules of symbolic analysis on our simple language in figure .
except for rule s unknown these rules are standard.
they describe the semantic s of existing symbolic execution engines like klee .
there are two types of rules.
expression rules evaluate an expression to a symbolic value.
statement rules evaluate a symbolic state to a set of symbolic states describing its possible continuations.
each symbolic state is a tuple where is the statement that represents the remaining code to be executed is a state constraint denoting the current path conditions is a symbolic store that maps variables to symbolic expressions and is a vector of tuples introduced in this work to record potential imprecision in process of symbolic analysis.
for example the symbolic state is program p s constant c ... ... true false expression e x c e1ope2 statement s x e x input x unknown e s1 s2 if e then s1else s2 operators op ... ... figure .
a simple language the operator turns astore toalogical conjunction .expression rule e const e v ar e op sta tement rules s assign s if t s if both s unknown s input figure .
semantic rules after executing line of figure and taking the true branch.
we ignore the details of and we will describe it in the next paragraph.
the assignment evaluation is standard.
a flattening operator is used to flatten the mapping in the symbolic store to the corresponding constraints for feasibility testing.
rule s if t states that if the path feasibility test determines that only the true branch is taken the continuation is the statement in the true branch with the path condition updated.
figure omits the rule for the case when only the false branch is taken.
rule s if both evaluates a conditional statement to two continuations when both branches are feasible.
both of them will be added to the set that tracks the states to explore and evaluated independently later.
rule s input specifies that when an input statement is encountered a fresh symbolic variable is introduced to represent the input value.
the semantic rules describe standard symbolic analysis with additional provision to record the potential imprecision caused by un modeled api invocations using the vector .
we call each component in a tuple of unknown .
each tuple of unknown captures the potential imprecision induced by an unmodeled api invocation.
it consists of the input parameter of the un modeled api invocation and the symbolic value denoting the over approximated return value of the un modeled api invocation.
we call u an unknown variable which overapproximates the return values of an un modeled api invocation .
the two components in of an un modeled api invocation record its symbolic input parameter and its return value respectively.
rule s unknown specifies that when an unmodeled function is encountered we introduce a fresh symbolic variable to represent its return value and append to a new tuple of unknown to record the potential imprecision and its context .
for example the tuple of unknown derived after invoking the un modeled api in line of figure is where is the symbolic parameter of the invocation and is a fresh symbolic variable introduced to over approximate the return value of external api invocation.
due to the approximation of some apis return values the symbolic analysis can introduce unrea chable execution states if a program contains unknown variables and hence generate false warnings.
our goal is to validate whether a symbolic state with unknown variables is feasible in some dynamic execution.
.
feasible symbolic states in this section we first introduce a few notations and definitions related to feasible symbolic states.
then we show how to reduce the state validation problem to a max sat problem which can be efficiently solved by existing constraint solvers.
in order to perform symbolic state validation we need to validate that the path conditions involving over approximated symbolic values are feasible.
we introduce a function that maps a conc rete parameter of an un modeled api to the corresponding concrete return value i.e.
.
this function denotes the computation of un modeled apis.
we use to denote a set defined by which is the set of feasible parameter return bindings for a given function.
since one execution may involve multiple invocations of different apis we use to denote the set of feasible parameter return bindings for the api that is invoked by the ith function call in an execution trace under analysis.
we define validate as follows.
definition a vector of sets of binary tuples validates a vector if .
we denote it as .. our approach binds the symbolic parameters and return values of un modeled api calls to some concrete values that have been observed in some dynamic execution .
we need to address a challenge.
some of these bindings can introduce contradictions in the existing path conditions of a given symbolic state.
for example the binding of s parameter to can cause a contradiction in the code snippet below because implies which contradicts the path condition .
int x input1 if x external1 x ... definition defines feasible symbolic states by binding some variables to observed concrete values while avoiding causing contradictions in the symbolic states concerned.
definition a symbolic state is feasible if where is a vector of concrete binding of parameter return pairs of un modeled apis in the invocation order is the corresponding vector of the sets of feasible parameter return bindings is the ith unknown variable recorded by and is the ith symbolic parameter recorded by .
intuitively a symbolic state is feasible if there exists a vector of concrete parameter return pairs such that parameterreturn pairs are confined to some real execution of un modeled apis i.e.
and the symbolic state in the conjunction form with unknown variables concretized is satisfiable.
let us illustrate the idea using an example of the resulting symbolic state after executing line and taking the true branch in figure .
we can check if this state is feasible using the runtime data in figure .
we can bind to and validate using the runtime data collected from an earlier test run.
the constraint is satisfiable.
thus we can conclude that state is feasible.
in fact this validation problem can be reduced to a max sat problem as follows.
we use .
to denote the number of validated parameter return pairs.
maximize .
subject to intuitively the max sat problem tries to find concrete bindings for so that the tuples of unknown can be validated while the bindings do not introduce contradictions .
definition requires each un modeled api invocation to be validated.
however this is not always necessary as shown in the 190motivating example.
recall that the constraint generated by the example code in figure can be validated without the runtime data about .
definition is thus given to relax the requirement of definition by excluding those parameter return pairs that do not need to be validated.
definition a symbolic state is feasible if where and are two disjoint vectors partitioned from in definition is a vector of the sets of feasible parameter return bindings is the ith unknown variable recorded by and is the ith symbolic parameter recorded by .
definition differs from definition in that we partition into and and we only need to validate while can bind to any value.
we use the universal quantifier to denote that can bind to any value.
however this definition causes some difficulties in solving the max sat problem because what belongs to partitions and is unknown and constraint solvers cannot efficiently solve constraints with both universal and existential quantifiers in arbitrary domains like integer domain .
our approach therefore eliminates the universal quantifiers before passing the max sat problem with quantifier eliminated to constraint solvers .
our existing implementation uses a simple approach to eliminating universal quantifiers .
it scans the constraints to identify expressions that use operators like etc.
and involve a single occurrence variable denoting input plus another variable denoting the return value of an un modeled api invocation.
it then marks the se identified expressions as validated.
for example in the example of figure can be identified as validated without using runtime data because is only used in this constraint and operator allows to control the outcome of this expression to be always true regardless of the return value of .
we leave the study of other more sophisticated quantifier elimination approaches to our future work.
we assume that inputs can bind to arbitrary values because a sound analysis of software applications should include the scenarios arising from malicious or malformed inputs.
after quantifier elimination the max sat becomes maximize subject to where is the part of that still requires to be validated using runtime data.
to apply our approach we need to have the vector .
ideally the set can be complete if we have formal specifications of all un modeled apis.
in our approach we obtain from the runtime data collected from earlier test runs.
in some situations some tuples of unknown may not be successfully validated using the collected runtime data.
under these situations one may prioritize the warnings based on the amount or proportion of the validated tuples of unknown.
we leave the study of such prioritization to our future work.
in this paper we focus only on the warnings whose associated symbolic states can be fully validated.
in this setting the problem is equivalent to sat problem.
it is easy to show that a symbolic state is feasible based on definition if the symbolic state is validated using the approach above.
the proof is done by binding all symbolic values to the concrete values given by the constraint solver and show that there is no contradiction in the constraint.
our approach handles the computation of un modeled apis based on the program states obtained from earlier executions.
in practice some apis may be subject to side effects such as thread creation and subscribing call back functions.
our implementation explained in section adapts existing techniques to handle such apis.
the remaining apis are assumed to have no side effects.
section and table show that our approach allows analysis with many un modeled apis and the manual efforts of api modeling is significantly reduced.
we empirically show that combining modeling and runtime data provides precise results in practice no false warnings are found in our empirical study in section .
.
.
implementation we have implement ed a symbolic analysis tool called sym jvm to analyze java programs.
sym jvm uses choco .
as its constraint solver and follows the design of klee .
for example both tools use copy on write technique to improve state forking efficiency and reduce memory consumption.
unlike klee sym jvm allows approximating the return values of the un modeled apis and leverages these approximated variables to perform state reduction.
like existing static analysis tools sym jvm includes the models of a small set of basic apis including thread creating apis string apis array copy apis and container apis.
on top of these apis we manually model a few apis where over approximation obviously does not make sense number of warnings reported by concolic testing using inputs from system test cases is marked with .
table .
subject programs subjects source lines of code un modeled apis shared apis struts .
.
.
apache tomcat .
.
apache fop apache lucene .
.
findbugs .
.
amce web server .
antlr hadoop .
.
alpha pmd .
.
proguard .
table .
of w arnings comparison subjects raa save concolic1 struts .
.
.
apache tomcat .
.
apache fop apache lucene .
.
findbugs .
.
amce web server .
antlr hadoop .
.
alpha pmd .
.
proguard .
191including the apis for creating threads and apis that involve call back functions.
totally we modeled apis.
other apis are un modeled.
as a result more than of the apis are unmodeled on average.
in our study we consider command line arguments file input and network input as program inputs.
although our discussion in this paper focuses on single parameter and return value for simplicity sym jvm supports multiple parameters and return values.
it allows variables reachable in a method call to be treated as its input and output.
for example if a method invocation may modify a field is also treated as a return value or output .
for dynamic data collection sym jvm uses javassist to instrument subject programs to collect object states before and after un modeled api invocations.
we also use jvm s instrumentation framework which can perform loading time instrumentation.
the object states are stored using json format.
we use go programming language to build a server with around slocs to manage these json objects which are indexed and stored in sqlite database.
let us explain the handling of object returns which often involve complex data structures from un modeled apis.
hence simply introducing a fresh symbolic variable is insufficient.
to address this issue sym jvm deploys lazy initialization techniques to handle returned objects from un modeled apis.
for instance a program invokes an un modeled api that returns an object o. sym jvm first marks the object to be an unknown object.
when the subsequent code accesses a field f in o sym jvm initializes field f to point to a new object x and mark x to be an unknown object.
when sym jvm performs symbolic state validation it checks whether the lazily initialized object can be validated by some runtime instance.
for example suppose there is an object o with three fields a b and c. also suppose that sym jvm has lazily initialized a b to be some non null objects while c remains uninitialized in the execution path under analysis.
this only the bindings of a and b are needed for the analysis.
if there exists a runtime instance r returned from the same api invocation with consistent precondition such that is not null and is not null this object can be validated.
since field c remains unknown in symbolic analysis.
sym jvm does not need to validate it.
.
evaluation we conducted evaluation to study whether overapproximating the return values of un modeled apis cause many false warnings in real applications and whether our approach is able to effectively distinguish real warnings from false warnings caused by such over approximated return values.
we choose ten real world open source java programs as our subjects.
the information about these subjects is listed in table .
these subjects have altogether around .
million lines of code.
we made two efforts for realistic evaluation.
first we chose popular industrial scale subjects instead of other benchmarks like dacapo which contains relatively small size subjects relying on few external apis.
second we applied sym jvm to the entire subjects without excluding those components that make heavy use of apis.
table shows the number of unique un modeled api functions used by the chosen subjects.
each individual subject is built on top of a few hundred to more than one thousand unique un modeled apis.
the ten subjects altogether rely on unique un modeled apis.
modeling these apis is hard because it requires domain knowledge of graphics jvm execution and operation systems etc.
fortunately these apis are commonly used by the subjects.
table gives the percentage of the shared un modeled apis2 for each subject.
this indicates the runtime data of a subject s un modeled apis can be mostly reused for the analysis of another subject.
to our knowledge symbolic analysis has not been applied to these subjects because of the huge api modeling effort.
the evaluation assesses the usefulness of our approach in extending static symbolic analysis to large real world programs.
we collected the api runtime data by running the documented test cases of the first five subjects in table .
these five subjects were selected to collect api runtime data because they are accompanied by ample test cases.
the database of runtime data is available online .
it currently stores about gb runtime data with more than five million unique concrete pairs of input parameters and returns.
to perform warning validation we need a set of warnings generated for our chosen subjects.
we configured our sym jvm to use random strategy and a pi approximation raa to perform path exploration from main methods to detect runtime exceptions for each subject with maximum time budget of six hours3.
random path exploration strategy is commonly used by many symbolic analysis studies .
the warnings generated by raa are available online .
the experiment was conducted on a linux server with cores of .10ghz cpus running centos .
bit.
we used the jdk .
from oracle and we set the maximum heap size for sym jvm to 22gb.
the runtime exceptions detected by sym jvm include null pointer exceptions array out of bound exceptions assertion violations and tho se uncaught exceptions thrown by the programs or apis.
the second column of table lists the number of warnings generated for each subject.
for some large subjects like hadoop the number of generated warnings is about 15k.
validating these warnings manually can take non trivial human efforts.
.
warning validation we applied our symbolic state validation technique save over sym jvm to automatically validate true warnings from the warnings generated by raa.
the number of warnings validated by save is listed in the third column of table .
all of these warnings have been confirmed explicitly by test cases .
note that we did not collect any runtime data of subjects we consider an api is shared if the api is used by more than one subjects.
the validation time is also included in the analysis time.
the test cases were generated in a semi automated way.
we checked the constraints and the hints provided by sym jvm and then constructed the environments to trigger the bug.
generating complex environments for large subjects automatically is beyond the capability of our tool.
a the number of un modeled api before reaching warning.
b the number of constraints before reaching warnings.
c the number of constraints involving over approximated symbolic values before reaching warnings.
figure .
some statistical information about warnings 192from their test cases.
the experimental results show that our approach is useful for the subjects with few or no documented test cases like most android apps.
raa reports more warnings in antlr and hadoop than the other subjects.
this is because antlr involves many recursive method invocations such that one buggy statement can be reached by many different stack traces while hadoop has many entry methods.
we also study the warnings that have not been validated by save to check whether they are true warnings.
since we cannot afford to study all the warnings we randomly using random generator to select warnings sample about .7k warnings of un validated warnings to investigate and we only found one true warning that was not validated by our approach.
we spent two months on th is manual checking .
the missed true warning is related to missing information of an exceptional case.
the warning requires an api to throw an exception to trigger.
however there is no such information for this api used by the subject in our current database.
we can enrich the database with such information by using more system test cases in the future.
in our investigation we classify a warning as a false warning by checking the un validated apis against the jdk documentation.
if an error symbolic state requires some impossible behavior of apis to reach the warning is classified as a false warning.
our empirical result shows that many warnings generated by static symbolic execution with api approximation are indeed false.
it could take huge effort to manually confirm true warnings among the numerous generated warnings.
our approach is able to automate this tedious task so that developers can prioritize their limited resources on the true warnings.
in the process of analysis we also record ed the number of unmodeled api invocations before the sym jvm reaches the reported error states.
the result is plotted in figure a .
on average sym jvm observes un modeled api invocations before reaching an error state.
these api invocations generate large numbers of over approximated symbolic values.
we also plot the number of constraints before sym jvm reaches the error states in figure b and the number of constraints with overapproximated symbolic values before sym jvm reaches the error states in figure c .
on average there are constraints governing each error state.
the average value is reduced to if we confine the constraints to those with overapproximated symbolic values.
such an amount of constraints can be handled by existing constraint solvers effectively.
our approach can be practically used to validate the warnings reported by symbolic analysis saving developers efforts.
.
bug details to evaluate the applicability of our approach in identifying real world bugs we applied our approach directly to the selected subjects without artificially seeding additional bugs.
our evaluation focus on those bugs that cause exceptions such as null pointer exceptions array out of bounds exceptions and exceptions thrown out of main functions.
all validated warnings have been confirmed explicitly by test cases .
a large portion private keepclassspecification extractkeepspecifications list keepspecifications boolean allowshrinking boolean allowobfuscation list matches new arraylist for intindex index keepspecifications.
size index bug ... private void loadboilerplateconfiguration try configurationparser parser new configurationparser this.
getclass .getresource boilerplate configuration system.getproperties configuration configuration new configuration try parser.
parse configuration we re interested in the keep options.
boilerplatekeep extractkeepspecifications configuration.keep false false ... public static void invokeandwait runnable runnable try if !swingutilities.
iseventdispatchthread swingutilities.
invokeandwait runnable ... public static void main swingutil.
invokeandwait new runnable public void run try transitively invoke loadboilerplateconfiguration1 input configuration snippet injars bin classes injars libs outjars bin classes processed.jar dontpreverify repackageclasses allowaccessmodification figure .
a validated example from proguard public static void main string args if checkdependencies startfop args input arguments java org.apache.fop.cli.main dump config xml input.xml private intparsexslinputoption string args inti throws fopexception setinputformat xslt input if i args.length isoption args throw new fopexception you must specify the stylesheet else xsltfile new file args return private intparsexmlinputoption string args inti throws fopexception setinputformat xslt input if i args.length isoption args throw new fopexception you must specify the input file else string filename args if issysteminoutfile filename this.usestdin true else xmlfile new file filename private boolean parseoptions string args throws fopexception else if args .equals xsl i i parsexslinputoption args i else if args .equals xml i i parsexmlinputoption args i private void dumpconfiguration case xslt input log.info xsltstylesheet xsltfile.
tostring bug1 figure .
a validated example from apache fop 193of these warnings are induced by unexpected values in the options specified by users.
we selected warnings that are apparently caused by logic errors and filed subsequent bug reports to developers.
the summary of bug reports can be found in table .
by the time of writing six of them have been confirmed.
four of these six have already been fixed.
the url of bug reports and details of bugs can be found in .
one was marked as duplicated.
one aroused discussion but no good solution was found.
for severity of these responded bugs five are marked as major two are normal and one is low.
although this work focuses on automatic identification of true warnings it would be interesting to extend the technique to categorize warnings into possible failure causes in future work.
.
warning examples this section discusses some examples of validated and unvalidated warnings .
in figure a null pointer exception can occur in line of extractkeepspecifications .
the sym jvm finds that it is possible to generate an input that is shown at the bottom of figure so that configuration .keep is not initialized when the input is parsed by parse in line of loadboilerplateconfiguration .
the field configuration .keep is passed to extractkeepspecifications which dereferences the field without checking whether it is a null pointer.
to check if this warning is true sym jvm leverages runtime data to show that predicate !swingutilities.
iseventdispatchthread in line of invokeandwait is feasible.
the feasibility of this predicate is a necessary condition to show that the reported anomalous symbolic state is reachable because the runnable object that transitively invokes loadboilerplateconfiguration is passed to invokeandwait in line of main .
before reaching extractkeepspecifications un modeled apis have been invoked in the symbolic analysis.
this makes it difficult for developers to validate such warnings manually.
in this example our technique is able to conclude that the error statement is indeed reachable even we do not have the models of all apis.
figure shows another example from apache fop project.
the bug is in the line of dumpconfiguration where an uninitialized field variable xsltfile is dereferenced.
the problem occurs when xml option is specified in the command line .
in parsexmlinputoption the input format is set to xslt input in line of parsexmlinputoption .
in this case variable xmlfile is initialized instead of xsltfile .
the reason why the developer made this mistake is that there is a method called parsexslinputoption that s ets the same type of input format xslt input and initializes xsltfile .
as such the developer thought that xsltfile is always initialized when xslt input is set.
to check if the symbolic state is feasible our technique validates that checkdependencies in line of main can return true and all the path conditions between startfop and dumpconfiguration are feasible.
at the bottom of figure we put the command line input that can trigger the bug.
while it is possible to extend static symbolic analysis to realworld programs by approximating the un modeled apis we can see from the above two examples that validating the warnings thus reported is non trivial because they often involve multiple procedures and invocations of large numbers of complex external apis.
our approach is valuable to help developers to concentrate on the true warnings i.e.
real bugs when developers want to deploy static symbolic analysis but cannot afford to model all external apis.
according to our random sampling un validated ones are likely false warnings.
figure shows an example in which a false warning is un validated by our approach.
sym jvm reports a warning in line of loadcorepackage .
it is suspected that loader in line of loadcorepackage may be a null pointer.
the variable loader is catalinaloader which is passed from securityclassload.
securityclassload in line of init to loadcorepackage in line of securityclassload .
sym jvm finds that catalinaloader in some execution path is an alias of commonloader that is created in line of initclassloaders .
it is because that parent can be returned in line of createclassloader where variable parent is commonloader .
in the code there is nothing preventing commonloader from being a null pointer.
we cannot even use heuristics like private static final void loadcorepackage classloader loader throws exception ... loader.
loadclass basepackage accesslogadapter false warning ... public void init ... initclassloaders ... securityclassload.
securityclassload catalinaloader public static classloader createclassloader2 list repository repositories final classloader parent ... return accesscontroller.
doprivileged new privilegedaction standardclassloader override public standardclassloader run if parent null .....public static void securityclassload classloader loader throws exception ... loadcorepackage loader ... private void initclassloaders ... commonloader this.
getclass .getclassloader ... catalinaloader createclassloader server commonloader sharedloader createclassloader shared commonloader private classloader createclassloader string name classloader parent throws exception ... if somecondition return parent ... return classloaderfactory.
createclassloader repositories parent figure .
an un validated false warning from apache tomcat table bug report statistics rpt affected subject confirmed fixed severity proguard no no not classified amce web server yes no low tomcat yes yes normal tomcat yes yes normal fop no duplicated no major fop pending discussion no major fop pending no not classified fop pending no not classified hadoop yes no major pmd yes yes major struts yes yes major 194consistency checking to avoid generating this warning.
in this example variable parent is passed to createclassloader2 in which parent is checked against to null in line of createclassloader2 .
the consistency checking heuristic would report that parent is likely to be null because the programmer explicitly checks it against null .
however according to jdk specification getclassloader would never return null for non bootstrap boot loaders .
in the case of permission denial getclassloader would throw a securityexception instead of returning a null pointer.
the false warning is un validated and our technique reduces the efforts of developers to check these kinds of false warnings.
.
discussion we have present ed an automated and effective approach to identifying true warnings amongst large numbers of warnings generated by symbolic analysis when some apis models are unavailable .
although our approach does not guarantee to identify all true warnings the experimental results on real industrial scale subjects show that our approach is useful to identify real bugs.
we made several observations which account for the effectiveness of our approach in our experiments.
first many un modeled api invocations are irrelevant to the reachability of error symbolic states.
our observation is that many symbolic values introduced by un modeled apis are not used in the constraints of path conditions and they are not required to be validated.
the data in figure show that the number of constraints with over approximated symbolic values is much smaller than the number of over approximated variables generated by un modeled api invocations before sym jvm reaches the error symbolic state.
second there is a large set of concrete values that can be used to establish the feasibility of a constraint.
for example there are many possible values of to make satisfiable.
collecting such values from the dynamic execution of documented test cases is highly possible.
third we found that the symbolic analysis often finds multiple paths leading to the same warning as shown in figure .
the mean is and median is for the number of paths leading to the same warning.
we consider a warning is validated as long as one of the paths can be validated.
this also greatly increases the chance of validating a warning.
our approach complements other warning prioritization techniques and semi automated validation techniques .
for example our technique can be first applied to identifying true warnings.
after fixing these warnings developers may apply existing prioritization and semi automated validation techniques on the remaining un validated warnings.
although existing tools dsc and jcute provide a prototype implementation of concolic testing we were not able to apply them successfully to the real world subjects enlisted in table due to the various limitations of the tools.
for example the dsc provides inadequate support of jdk libraries while jcute has limited support for string input s. as such we adapt sym jvm to implement concolic testing for comparison with our proposed approach.
we conducted two further experiments.
concolic testing is applied to each subject using the same time budget of six hours as our previous experiment.
the time budget is comparable to that adopted in existing studies .
besides the number of detected warnings we compare the effectiveness using statement and branch coverages because few statements and branches in real subjects are unreachable .
we do not make comparison using path coverage because concolic testing is a dynamic approach while our technique save is a static approach.
in the first experiment we applied concolic testing to each subject with randomly generated test inputs as the seed test case.
we found that concolic testing approach failed to achieve more than of statement coverage for all of our large real world subjects and report no warnings.
in the second experiment we applied concolic testing to subjects and with test inputs derived from their system test runs.
we are not able to find documented system test runs for the remaining seven subjects.
note that our technique save can leverage runtime data collected from unit test cases which are much more widely available than system test cases .
the use of inputs derived from system test cases improves the statement coverage of concolic testing to around for the three subjects .
figure shows the branch coverage achieved by concolic testing and our save technique.
the branch coverage of concolic testing for subjects and is based on inputs from system test cases while the branch coverage of the remaining subjects is based on random test cases.
we find three reasons that explain the low coverage of concolic testing it cannot often find appropriate input values to survive initialization phases if test inputs are generated randomly it exhausts resources before finding appropriate function parameter values to achieve adequate branch coverage even it is able to survive initialization phases with inputs from system test cases and it fails to automatically setup environments for distributed program like hadoop.
the first and second reasons have been discussed in section and our result confirms a similar finding made by an earlier study .
real world large subjects typically have complex initialization module and function parameters.
they also require non trivial setup to work correctly.
the two experiments show that our approach is able to achieve higher test coverage than concolic testing for the real world subjects and successfully detects more warnings with the same time budget as shown in table .
our approach requires instrumented program execution in order to collect runtime data .
the instrumented test cases can run for a few hours in the collecting process.
the execution time is acceptable for our application because we only need to collect the runtime data once.
although reducing instrumentation overhead is not a focus of our work we plan to reduce the overhead using more sophisticated instrumentation techniques .
besides our runtime data collection is performed before the analysis time and the initial cost is amortized by many executions of symbolic figure .
number of paths leading to the same warning .
.
.
.
10c o v e r a g e subjects sym jvm concolic figure branch coverage comparison 195analysis.
currently we have not optimized our instrumentation code and the instrumented test runs may incur times overhead.
we also studied the usefulness of utilizing the runtime data collected from other subjects test cases in validating true warnings of a subject.
the study was conducted on subjects because each of them is accompanied by a set of well documented test cases.
eight true warnings are successfully validated by using only the runtime data derived from each subject s own test cases.
four more true warnings are validated by using also the runtime data derived from the other four subjects test cases.
the reason accounting for the difference is that other subjects runtime data can sometimes trigger the corner cases of the subject under test.
in other words the runtime data of other subjects can include those variable bindings that infrequently occur to the subject under test in its normal executions.
these bindings are useful to trigger infrequent buggy execution paths of the subject under test.
this shows the merit of cross fertilization using the runtime data from different subjects.
.
related work promising results of symbolic analysis have been reported in the areas like test case generation static bug detection regression testing security analysis etc.
to ensure its precision it is often necessary to consider the apis used by the programs under analysis.
concolic testing is a dynamic approach to the symbolic analysis.
it does not require prior modeling of such methods api behaviors.
however concolic testing approach can only handle the apis that are reachable by dynamic execution and it often fails to figure out appropriate parameters for external apis to guide execution .
godefroid proposed to leverage parameters and return values of apis to improve symbolic execution.
however there is no efficient constraint solver to solve the generated constraints that involve first order logic formula of functions .
therefore the technique has not been implemented.
in contrast our approach generates constraints that only involve formula in terms of variables and those operators supported by existing efficient constraint solvers as shown in section .
.
our approach does not requires concretization of over approximated variables until validating a symbolic state and therefore it is applicable to scalable static symbolic analysis approach that exploits over approximated variables .
our evaluation in section shows that our approach scales better on large subjects.
besides it is difficult to perform concolic testing on those real world programs whose execution requires complex environment setup consumes expensive resources or incur costly side effects upon failures.
for example the execution of hadoop or railway control systems often require non trivial setup of distributed environments.
due to these limitations concolic testing has not been widely adopted in system testing.
unlike concolic testing our approach does not require further execution of the subject programs and this feature makes it applicable these programs whose execution environments are non trivial to setup and manipulate.
concolic testing is also used to generate mock object for unit testing .
due to scalability issue of concolic testing existing approaches can only be applied to unit test of small modules.
our approach is able to perform whole program analysis.
approaches have been proposed to use runtime data collected from executions to automatically construct approximated api models or related constraints for symbolic analysis.
each constructed model is an approximation because the behavior covered by dynamic execution is incomplete.
in contrast our approach works differently by binding symbolic values to concrete values in the validation process.
our approach avoids the imprecision due to model construction.
besides these approaches are limited in terms of constructed models expressiveness.
for example they can only construct models for those apis based on their predefined data structures or predefined linear constraints .
our approach requires no prior knowledge of data structures or linear computation in the unmodeled apis.
there are two categories of api specification mining.
one focuses on temporal relation mining of specifications on temporal relations like and .
these specifications aim to detect program bugs instead of validating warnings because confining api invo cations temporal order does not imply that a warning is true.
another category focuses on arithmetic specifications .
for example the parameter of must be a positive number.
although simple arithmetic specifications can describe simple program properties they cannot precisely describe the complex behaviors of apis.
these approaches also suffer from imprecision issues when mining specifications from finite number of test cases.
since the models of external apis are often unavailable recent static symbolic analysis approach es assume these apis can return arbitrary values .
such approximation however can generate many false warnings.
since manual inspection of such warnings is tedious and time consuming researchers proposed different approaches to validating warnings.
for example dillig et al.
proposed a semi automated approach to diagnosing warnings.
semantic consistency checking is a technique to obtain semantic information from the usage of variables.
for example a check var null in source code would indicate that variable var is likely to be null.
blackshear et al.
proposed a more general warning prioritization approach inspired by the idea of program semantic consistency checking.
these techniques reply on heuristics and still require developers to manually confirm warnings.
our example in figure shows that these techniques can prioritize false warnings.
in contrast our approach is precise for identifying true warnings as shown in our evaluation.
our approach complements existing techniques in that it can be first applied to identify true warnings followed by further diagnosis or prioritization of the remaining warnings using existing techniques after these true warnings have been dealt with.
.
conclusion in this work we have presented an approach to validating warnings generated by the symbolic analysis.
our approach provides a practical solution to distinguish true warnings from false warnings when developers want to apply static symbolic analysis to large program but cannot afford to model all the apis involved.
our approach successfully extends the application of static symbolic analysis to ten large real programs that rely on external or native apis and automatically detects true warnings of these programs.
we plan to apply our approach to other platforms such as android whose applications typically rely on external apis and gpu render scripts.