expositor scriptable time travel debugging with first class traces technical report cs tr khoo yit phang jeffrey s. foster and michael hicks computer science department university of maryland college park md usa fkhooyp jfoster mwh g cs.umd.edu abstract we present e xpositor a new debugging environment that combines scripting and time travel debugging to allow programmers to automate complex debugging tasks.
the fundamental abstraction provided by e xpositor is the execution trace which is a time indexed sequence of program state snapshots or projections thereof.
programmers can manipulate traces as if they were simple lists with operations such as map and filter.
under the hood e xpositor efficiently implements traces as lazy sparse interval trees whose contents are materialized on demand.
e xpositor also provides a novel data structure the edit hash array mapped trie which is a lazy implementation of sets maps multisets and multimaps that enables programmers to maximize the efficiency of their debugging scripts.
in our microbenchmarks e xpositor scripts are faster than the equivalent non lazy scripts for common debugging scenarios.
we have also used e xpositor to debug a stack overflow and to unravel a subtle data race in firefox.
we believe that e xpositor represents an important step forward in improving the technology for diagnosing complex hard to understand bugs.
i. i ntroduction ...we talk a lot about finding bugs but really bottleneck is not finding bugs but fixing ... robert o callahan understanding how the failure came to be...requires by far the most time and other resources andreas zeller debugging program failures is an inescapable task for software programmers.
understanding a failure involves repeated application of the scientific method the programmer makes some observations proposes a hypothesis as to the cause of the failure uses this hypothesis to make predictions about the program s behavior tests those predictions using experiments and finally either declares victory or repeats the process with a new or refined hypothesis.
there are certain kinds of bugs that can truly test the mettle of programmers.
large software systems often have complex subtle hard to understand mandelbugs1whose untangling can require hours or even days of tedious hard to reuse seemingly sisyphean effort.
debugging mandelbugs often requires testing many hypotheses with lots of backtracking and retrials when mandelbug from the mandelbrot set a bug whose underlying causes are so complex and obscure as to make its behavior appear chaotic or even nondeterministic.
from the new hacker s dictionary 3d ed.
raymond e.s.
editor .those hypotheses fail.
standard debuggers make it hard to efficiently reuse the manual effort that goes into hypothesis testing in particular it can be hard to juggle the breakpoints single stepping and state inspection available in standard debuggers to find the point at which the fault actually happened.
scriptable debugging is a powerful technique for hypothesis testing in which programmers write scripts to perform complex debugging tasks.
for example suppose we observe a bug involving a cleverly implemented set data structure.
we can try to debug the problem by writing a script that maintains ashadow data structure that implements the set more simply e.g.
as a list .
we run the buggy program and the script tracks the program s calls to insert andremove stopping execution when the contents of the shadow data structure fail to match those of the buggy one helping pinpoint the underlying fault.
while we could have employed the same debugging strategy by altering the program itself e.g.
by inserting print statements and assertions so would require recompilation and that can take considerable time for large programs e.g.
firefox thus greatly slowing the rate of hypothesis testing.
modifying a program can also change its behavior we have all experienced the frustration of inserting a debugging print statement only to make the problem disappear!
scripts also have the benefit that they can invoke libraries not used by the program itself.
and general purpose scripts may be reused.
a. background prior scriptable debuggers there has been considerable prior work on scriptable debugging.
gdb s python interface makes gdb s interactive commands stepping setting breakpoints etc.
available in a general purpose programming language.
however this interface employs a callback oriented programming style which as pointed out by marceau et al.
reduces composability and reusability as well as complicates checking temporal properties.
marceau et al.
propose treating the program as an event generator each function call memory reference etc.
can be thought of as an event and scripts are written in the style of functional reactive programming frp .
while frp style debugging solves the problems of callback based programming it has a key limitation time always marches forward so we cannot ask questions about prior states.
for example if while debugging a program we find a doubly freed address we cannot jump backward in time to find the 1corresponding malloc .
instead we would need to rerun the program from scratch to find that call which may be problematic if there is any nondeterminism e.g.
if the addresses returned by malloc differ from run to run.
alternatively we could prospectively gather the addresses returned by malloc as the program runs but then we would need to record all such calls up to the erroneous free.
time travel debuggers like undodb and systems for capturing entire program executions like amber allow a single nondeterministic execution to be examined at multiple points in time.
unfortunately scriptable time travel debuggers typically use callback style programming with all its problems.
sec.
vii discusses prior work in detail.
b.expositor scriptable time travel debugging in this paper we present e xpositor a new scriptable debugging system inspired by frp style scripting but with the advantages of time travel debugging.
e xpositor scripts treat a program s execution trace as a potentially infinite immutable list of time annotated program state snapshots or projections thereof.
scripts can create or combine traces using common list operations traces can be filtered mapped sliced folded and merged to create lightweight projections of the entire program execution.
as such e xpositor is particularly well suited for checking temporal properties of an execution and for writing new scripts that analyze traces computed by prior scripts.
furthermore since e xpositor extends gdb s python environment and uses the undodb time travel backend for gdb users can seamlessly switch between running scripts and interacting directly with an execution via gdb.
sec.
ii overviews e xpositor s scripting interface.
the key idea for making e xpositor efficient is to employ laziness in its implementation of traces invoking the timetravel debugger is expensive and laziness helps minimize the number of calls to it.
e xpositor represents traces as sparse time indexed interval trees and fills in their contents on demand.
for example suppose we use e xpositor sbreakpoints combinator to create a trace trcontaining just the program execution s malloc calls.
if we ask for the first element of tr before time perhaps because there is a suspicious program output then e xpositor will direct the time travel debugger to time and run it backward until hitting the call capturing the resulting state in the trace data structure.
the remainder of the trace after time and before the malloc call is not computed.
sec.
iii discusses the implementation of traces.
in addition to traces e xpositor scripts typically employ various internal data structures to record information e.g.
the set sof arguments to malloc calls.
these data structures must also be lazy so as not to compromise trace laziness if we eagerly computed the set sjust mentioned to answer a membership query at time t we would have to run the time travel debugger from the start up until t considering all malloc calls even if only the most recent call is sufficient to satisfy the query.
thus e xpositor provides script writers with a novel data structure the edit hash array mapped trie edithamt which provides lazy construction and queriesfor sets maps multisets and multimaps.
as far as we are aware the edithamt is the first data structure to provide these capabilities.
sec.
iv describes the edithamt.
we have used e xpositor to write a number of simple scripts as well as to debug two more significant problems.
sec.
ii describes how we used e xpositor to find an exploitable buffer overflow.
sec.
vi explains how we used expositor to track down a deep subtle bug in firefox that was never directly fixed though it was papered over with a subsequent bug fix the fix resolved the symptom but did not remove the underlying fault .
in the process we developed several reusable analyses including a simple race detector.
in summary we believe that e xpositor represents an important step forward in improving the technology for diagnosing complex hard to understand bugs.
ii.
t hedesign of expositor we designed e xpositor to provide programmers with a high level declarative api to write analyses over the program execution as opposed to the low level imperative callbackbased api commonly found in other scriptable debuggers.
in particular the design of e xpositor is based on two key principles.
first the e xpositor api is purely functional all objects are immutable and methods manipulate objects by returning new objects.
the purely functional api facilitates composition by reducing the risk of scripts interfering with each other via shared mutable object as well as reuse since immutable objects can easily be memoized or cached upon construction.
it also enables e xpositor to employ lazy programming techniques to improve efficiency.
second the trace abstraction provided by e xpositor is based around familiar list processing apis found in many languages such as the built in list manipulating functions in python the array methods in javascript the listmodule in ocaml and the data.list module in haskell.
these apis are also declarative programmers manipulate lists using combinators such as filter map and merge that operate over entire lists instead of manipulating individual list elements.
these list combinators allow e xpositor to compute individual list elements on demand in any order minimizing the number of calls to the time travel debugger.
furthermore they shield programmers from the low level details of controlling the program execution and handling callbacks.
a. api overview fig.
lists the key classes and methods of e xpositor s scripting interface which is provided as a library inside undodb gdb s python environment.
a the execution class and the theexecution object the entire execution of the program being debugged is represented by the execution class of which there is a singleton instance named theexecution .
this class provides several methods for querying the execution.
the getat t 2method returns a snapshot object representing the program state at time tin the 2we use the convention of naming time variables as t and trace variables astr.
21class execution get snapshots 3getat t snapshot at time t derive traces 6breakpoints fn snapshot trace of breakpoints at func fn 7syscalls fn snapshot trace of breakpoints at syscall fn 8watchpoints x rw snapshot trace of read write watchpoints at var x allcalls snapshot trace of all function entries allreturns snapshot trace of all function exits interactive control cont manually continue the execution gettime latest time of the execution 17class trace count get items len called by len trace iter called by for item in trace getat t item at exactly time t getafter t next item after time t getbefore t previous item before time t create a new trace by filtering mapping a trace filter p subtrace of items for which preturns true map f new trace with fapplied to all items slice t0 t1 subtrace from time t0to time t1 create a new trace by merging two traces merge f tr see fig.
2a trailing merge f tr see fig.
2b revtrailing merge f tr see fig.
2c create a new trace by computing over prefixes suffixes scan f acc see fig.
2d revscan f acc see fig.
2e tscan f acc see fig.
3a revtscan f acc see fig.
3b 41class item time item s execution time value item s contents 45class snapshot read var x gdb value of variable xin current stack frame read retaddrs gdb values of return addresses on the stack backtrace print the stack backtrace .
.
.
and other methods to access program state .
.
.
53class gdb value getitem x called by gdb value to access field index x deref dereference gdb value if it is a pointer addrof address of gdb value if it is an l value .
.
.
and other methods to query properties of gdb value .
.
.
fig.
.
e xpositor s python based scripting api.
the getxand len methods of execution andtrace are eager and the remaining methods of those classes return lazy values.
lazy values include trace snapshot and gdb value objects whose contents are computed only on demand and cached.execution we will describe snapshot s in more detail later .
several methods create immutable sparse projections of the execution or trace s consisting of program state snapshots at points of interest the breakpoints fn andsyscalls fn methods return trace s ofsnapshot s at functions and system calls named fn respectively the watchpoints x rw method returns a trace ofsnapshot when the memory location xis read or written and theallcalls andallreturns methods return trace s ofsnapshot s at all function entries and exits respectively.
for debugging interactive programs the execution class provides two useful methods cont resumes the execution of the program from when it was last stopped e.g.
immediately after e xpositor is started or when the program is interrupted by pressing c and gettime gets the latest time of the execution.
if a program requires user input to trigger a bug we often find it helpful to first interrupt the program and call gettime to get a reference time before resuming the execution using cont and providing the input trigger.
b the trace class and the item class as mentioned above the trace class represents sparse projections of the execution at points of interest.
these trace s contain snapshot s or other values indexed by the relevant time in the execution.
initially trace s are created using the execution methods described above and trace s may be further derived from other trace s. the first five trace methods query items in trace s. the tr .len method is called by the python built in function len tr and returns the total number of items in the tr.
the tr.iter method is called by python s for x in tr loop and returns a sequential python iterator over all items in tr.
the getat t method returns the item at time tin the trace or none if there is no item at that time.
since trace s are often very sparse it can be difficult to find items using getat so thetrace class also provides two methods getbefore t and getafter t that return the first item found before or after time t respectively or none if no item can be found.
the getat getbefore and getafter methods return values that are wrapped in the item class which associates values with a particular point in the execution.
the remaining methods create new traces from existing traces.
the tr.filter p method creates a new trace consisting only of items from trthat match predicate p. the tr.map f method creates a new trace of items computed by calling function fon each item from tr and is useful for extracting particular values of interest from snapshots.
the tr.slice t0 t1 method creates a new trace that includes only items from tr between times t0andt1.
thetrace class also provides several more complex methods to derive new traces.
three methods create new traces by merging traces.
first tr0.merge f tr1 creates a new trace containing the items from both tr0and tr1 calling function fto combine any items from tr0andtr1that occur at the same time .
none can be passed for fiftr0andtr1contain items that can never coincide e.g.
if tr0contains calls to foo andtr1contains calls to bar since fwill never be called in this case.
next tr0.trailing merge f tr1 creates a new trace by 3calling fto merge each item from tr0with the immediately preceding item from tr1 ornone if there is no preceding item .
lastly revtrailing merge is similar to trailing merge except that it merges with future items rather than past items .
the remaining four methods create new traces by computing over prefixes or suffixes of an input trace.
the scan method performs a fold or reduce like operation for every prefix of an input trace .
it is called as tr.scan f acc where fis a binary function that takes an accumulator and an item as arguments and accis the initial accumulator.
it returns a new trace containing the same number of items at the same times as in the input trace tr where the nth output item outn is recursively computed as outn innfoutn 1ifn innfacc ifn where fis written infix as f. the revscan method is similar but deriving a trace based on future items rather than past items .
revscan computes the output item outnas follows outn innfoutn if0 n length innfacc ifn length lastly tscan andrevtscan are variants of scan andrevscan respectively that take an associative binary function but no accumulator and can sometimes be more efficient.
these two methods are described in sec.
iii b. c the snapshot class and the gdb value class the snapshot class represents a program state at a particular point in time and provides methods for accessing that state e.g.
read var x returns the value of a variable named xin the current stack frame read retaddrs returns the list of return addresses on the stack backtrace prints the stack backtrace and so on.
thegdb value class represents values in the program being debugged at a particular point in time and provides methods for querying those values.
for example v.getitem x is called by the python indexing operator v to access struct fields or array elements deref dereferences pointer values addrof returns the address of an l value and so forth.
these gdb value objects are automatically coerced to the appropriate python types when they are compared against built in python values such as ints for example it is also sometimes useful to manually coerce gdb value objects to specific python types e.g.
to treat a pointer value as a python int.
both the snapshot andgdb value classes are thin wrappers around gdb s python api and undodb.
when a method of a snapshot orgdb value object is called it first directs undodb to jump to the point in time in the program execution that is associated with the object.
then it calls the corresponding gdb api wrapping the return value in snapshot and gdb value as necessary.
in general the semantics of snapshot and gdb value follows gdb e.g.
the e xpositor s notion of stack frames is based on gdb s notion of stack frames.we also provide several methods such as read retaddrs that return the result of several gdb api calls in a more convenient form.
additionally all of gdb s python api is available and may be used from within e xpositor .
given a debugging hypothesis we use the e xpositor interface to apply the following recipe.
first we call methods ontheexecution to derive one or more trace s that contain events relevant to the hypothesis such events could be function calls breakpoints system calls etc.
next we combine these traces as appropriate applying trace methods such as filter map merge and scan to derive traces of properties predicted by our hypothesis.
finally we query the traces using methods such as getbefore andgetafter to find evidence of properties that would confirm or refute our hypothesis.
b. warm up example examining foocalls in expositor to begin with a simple example let us consider the task of counting the number of calls to a function foo to test a hypothesis that an algorithm is running for an incorrect number of iterations for example.
counting foocalls takes just two lines of code in e xpositor .
we first use the breakpoints method of theexecution to create the footrace 59foo the execution.breakpoints foo this gives us a trace containing all calls to foo.
we can then count the calls to foousing the python lenfunction and print it 60print len foo later we may want to count only calls to foo x where x perhaps because we suspect that only these calls are buggy.
we can achieve this using the filter method on the foo trace created above 61foo0 foo.filter lambda snap snap.read var x here we call filter with a predicate function that takes a snapshot object at calls to foo reads the variable named x and returns whether x .
the resulting trace contains only calls to foo which we assign to foo0.
we can then count foo0as before 62print len foo 0g after more investigation we may decide to examine calls to both foo and foo e.g.
to understand the interaction between them.
we can create a new trace of foo calls and merge it with foo 63foo1 foo.filter lambda snap snap.read var x 64foo01 foo .merge none foo we define foo1just like foo0but with a different predicate.
then we use the merge method to merge foo0and foo1 into a single trace foo01containing calls to both foo and foo passing none for the merging function as foo and foo can never coincide.
note that we are able to reuse the fooandfoo0traces in a straightforward manner under the hood e xpositor will also have cached the computation of fooandfoo0from the earlier and reuse them here.
4tr0tr1tr0.merge f tr1 f a nonetr0tr1tr0.trailing merge f tr1 ffff b nonetr0tr1tr0.rev trailing merge f tr1 ffff c trtr.scan f acc accfff d trtr.rev scan f acc accfff e fig.
.
illustration of complex trace operations.
finally we may want to take a closer look at the very first call to either foo orfoo which we can do using thegetafter method 65first foo01 foo .get after we call getafter onfoo01to find the first item after time i.e.
the beginning of the execution that contains the snapshot of a foo orfoo call.
in this example observe how we began with a simple debugging task that counts all calls to fooin a trace to answer our initial hypothesis then gradually create more traces or combined existing ones and queried them as our hypothesis evolves.
e xpositor is particularly suited for such incremental interactive style of debugging.
comparison to gdb s python api in contrast to e xpositor it takes lines of code to count foocalls using gdb s standard python api as shown below 66count more true 67foo gdb.breakpoint foo 68def stop handler evt if isinstance evt gdb.breakpointevent n and foo in evt.breakpoints global count count 72def exit handler evt global more more false 74gdb.events.stop.connect stop handler 75gdb.events.exited.connect exit handler 76gdb.execute start 77while more gdb.execute continue 79gdb.events.exited.disconnect exit handler 80gdb.events.stop.disconnect stop handler 81foo.delete on line we first initialize two variables count andmore that will be used to track of the number of calls to fooand to track if the execution has ended respectively.
then on line we create a breakpoint at the call to foo.
next we create a callback function named stop handler on lines to handle breakpoint events.
in this function we first check on lines to see if the breakpoint triggered is the one that we have set and if so we increment count on line .
we also create a callback function named exit handler on lines to handle stop events which are fired when the program execution ends.
this function simply resets the more flag when called.
after that we register stop handler andexit handler with gdb on lines and start the program execution on line .
gdb will run the program until it hits a breakpointor the end of the execution is reached calling stop handler in the former case or exit handler in the latter case.
then we enter a loop on lines that causes gdb to continue running the program until more isfalse i.e.
the program has exited.
once that happens we deregister the event handlers from gdb and delete the breakpoint on lines cleaning up after ourselves to ensure that the callbacks and breakpoint will not be unintentionally triggered by other scripts.
it also takes more work to refine this gdb script to answer other questions about foo compared to e xpositor traces.
for example to count calls to foo we would have to modify the gdb script to add the x predicate and rerun it instead of simply calling filter on the footrace.
as another example if we were given two different scripts one that counts foo and another that counts foo if would be difficult to combine those scripts as they each contain their own driver loops and shared variables it would be easier to just modify one of those script than to attempt to reuse both.
in contrast it took us one line to use the merge method to combine the foo0and foo1traces.
finally note that e xpositor caches and reuses trace computation automatically whereas we would need some foresight to add caching to the gdb script in a way that can be reused by other scripts.
c. example reverse engineering a stack smashing attack we now illustrate the use of e xpositor with a more sophisticated example reverse engineering a stack smashing attack in which malware overflows a stack buffer in the target program to overwrite a return address on the stack thereby gaining control of the program counter .
we develop a reusable script that can detect when the stack has been smashed in any program which will help pinpoint the attack vector.
our script maintains a shadow stack of return addresses and uses it to check that only the top of the stack is modified between function calls or returns any violation of this property indicates the stack has been smashed.
we begin by using the allcalls andallreturns methods on theexecution to create traces of just the snapshots at function calls and returns respectively 82calls the execution.all calls 83rets the execution.all returns next we use merge to combine these into a single trace passing none for the merging function as function calls and returns can never coincide.
we will use this new trace to compare consecutive calls or returns 584calls rets calls.merge none rets now we map over callreturns to apply the read retaddrs method returning the list of return addresses on the call stack.
this creates a trace of shadow stacks at every call and return 85shadow stacks calls rets.map lambda s map int s.read retaddrs we also use map to coerce the return addresses to python ints.
then we need to check that between function calls and returns the actual call stack matches the shadow stack except for the topmost frame one return address may be added or removed .
we use the following function 87def find corrupted ss opt shadow if opt shadow.force is not none for x y in zip ss.read retaddrs opt shadow.force if int x !
y return x l value of return address on stack return none here find corrupted takes as arguments a snapshot ssand its immediately preceding shadow stack optshadow the opt prefix indicates that there may not be a prior shadow stack ifssis at the first function call and we need to call the force method on optshadow to retrieve its value we will explain the significance of this in sec.
iii .
if there is a prior shadow stack we compare every return address in ssagainst the shadow stack and return the first location that differs or none if there are no corrupted addresses.
the zipfunction creates a list of pairs of the respective elements of the two input lists up to the length of the shorter list.
finally we generate a trace of corrupted memory locations using the trailing merge method calling find corrupted to merge each function call and return from callrets with the immediately preceding shadow stack in shadow stacks .
we filter none out of the result 93corrupted addrs calls rets n .trailing merge find corrupted shadow stacks n .filter lambda x x is not none the resulting trace contains exactly the locations of corrupted return addresses at the point they are first evident in the trace.
d. mini case study running expositor ontinyhttpd we used the script just developed on a version of tinyhttpd that we had previously modified to include a buffer overflow bug.
we created this version of tinyhttpd as an exercise for a security class in which students develop exploits of the vulnerability.
as malware we deployed an exploit that uses a return tolibc attack against tinyhttpd .
the attack causes tinyhttpd to print now i pwn your computer to the terminal and then resume normal operation.
finding buffer overflows using standard techniques can be challenging since there can be a delay from the exploit overflowing the buffer to the payload taking effect during which the exploited call stack may be erased by normal program execution.
the payload may also erase evidence of itself from the stack before producing a symptom.to use e xpositor we call the expositor launcher with tinyhttpd as its argument which will start a gdb session with e xpositor s library loaded and then enter the python interactive prompt from gdb expositor tinyhttpd expositor python interactive then we start running tinyhttpd theexecution.cont start running 99httpd running on port when tinyhttpd launches it prints out the port number on which it accepts client connections.
on a different terminal we run the exploit with this port number .
exploit.py 101trying port 102pwning... at this point tinyhttpd prints the exploit message so we interrupt the debugger and use e xpositor to find the stack corruption starting from the time when we interrupted it 103now i pwn your computer 104 c 105program received signal sigint interrupt corrupted addrs stack corruption function containing sec.
ii ccode time the execution.get time last corrupt corrupted addrs.get before time items in a trace are indexed by time so the getbefore method call above tells e xpositor to start computing corrupted addrs from the interrupted time backward and find the first function call or return when the stack corruption is detected.
we can print the results print time .
print last corrupt 113item .
address this shows that the interrupt occurred at time and the corrupted stack was first detected at a function call or return at time .
we can then find and print the snapshot that corrupted the return address with bad writes the execution n .watchpoints last corrupt.value rw write last bad write bad writes.get before last corrupt.time print last bad write 118item .
snapshot we find that the first write that corrupted the return address occurred at time .
we can then inspect the snapshot vialast bad write.value .
in this case the backtrace of the very first snapshot identifies the exact line of code in tinyhttpd that causes the stack corruption a socket recv with an outof bounds pointer.
notice that to find the bug e xpositor only inspected from time 8to time .
moreover had last corrupt not explained the bug we would then call 3gdb contains an existing python command that is not interactive pythoninteractive is a new command that we have submitted to gdb and is available as of gdb .
.
6corrupted addrs.get before last corrupt.time to find the prior corruption event inspecting only as much of the execution as needed to track down the bug.
this mini case study also demonstrates that for some debugging tasks it can be much faster to search backward in time.
it takes only second for corrupted addrs .get before time to return whereas if we had instead searched forward from the beginning e.g.
simulating a debugger without time travel 119first corrupted corrupted addrs.get after it takes seconds for the answer to be computed.
using expositor users can write scripts that search forward or backward in time as optimal for the task.
iii.
l azy traces in expositor as just discussed e xpositor allows users to treat traces as if they were lists of snapshots.
however for many applications it would be impractical to eagerly record and analyze full program snapshots at every program point.
instead e xpos itor uses the underlying time travel debugger undodb to construct snapshots on demand and to discard them when they are no longer used since it is expensive to keep too many snapshots in memory at once .
thus the major challenge is to minimize the demand for snapshots which e xpositor accomplishes by constructing and manipulating traces lazily .
more precisely all of the trace generators and combinators including execution.all calls trace.map trace.merge etc.
return immediately without invoking undodb.
it is only when final values are demanded with execution.get at trace.get at trace.get after or trace.get before that e xpositor queries the actual program execution and it does so only as much as is needed to acquire the result.
for example the construction ofcorrupted addrs in sec.
ii d line induces notime travel on the underlying program it is not until the call to corrupted addrs.get before time in sec.
ii d line that expositor uses the debugger to acquire the final result.
to achieve this design e xpositor uses a lazy intervaltree like data structure to implement traces.
more precisely a trace is a binary tree whose nodes are annotated with the closed lower bound and open upper bound of the time intervals they span and leaf nodes either contain a value or are empty.
the initial tree for a trace contains no elements only its definition and e xpositor materializes tree nodes as needed.
as a concrete example the following trace constructs the tree shown on the right with a single lazy root node spanning the interval which we draw as a dotted box and arrow.
120foo the execution.breakpoints foo now suppose we call foo.get before .
expositor sees that the query is looking for the last call to foobefore time so it will ask undodb to jump to time and then run backward until hitting such a call.
let us suppose the call is at time50 and the next instruction after that call is at time .then e xpositor will expand the root node shown above to the following tree .
.
.1foo50.
here the trace has been subdivided into four intervals the intervals and are lazy nodes with no further information as e xpositor did not look at those portions of the execution.
the interval contains the discovered call and the interval is fully resolved and contains no calls to foo.
notice that if we ask the same query again expositor can traverse the interval tree above to respond without needing to query undodb.
likewise calling getat t orgetafter t either returns immediately if the result has already been computed or causes undodb to jump to time t and for getafter t to then execute forward .
these methods may return none e.g.
if a call to foodid not occur before after at time t. as our micro benchmarks in sec.
v will show if we request about of the items in a trace computing traces lazily takes less time than computing eagerly depending on the query pattern as well as the kind of computations done.
this makes lazy traces ideal for debugging tasks where we expect programmers to begin with some clues about the location of the bug.
for example we start looking for stack corruption from the end of the execution in sec.
ii d line because stack corruptions typically occur near the end of the execution.
a. lazy trace operations we implement filter andmap lazily on top of the interval tree data structure.
for a call tr1 tr0.map f we initially construct an empty interval tree and when values are demanded in tr1 bygetxcalls e xpositor conceptually calls tr0.get x applies fto the result and caches the result for future use.
calls to tr0.filter p are handled similarly constructing a lazy tree that when demanded repeatedly gets values from tr0until pis satisfied.
note that for efficiency e xpositor s does not actually call getxon the root node of tr0 instead it directly traverses the subtree of tr0corresponding to the uninitialized subtree of the derived trace.
the implementation of tr0.merge f tr1 also calls getxon tr1as required.
for a call tr.slice t0 t1 expositor creates an interval tree that delegates getxcalls to tr asking for items from time t0to time t1 and returns none for items that fall outside that interval.
for the last four operations trailing merge and scan expositor employs additional laziness in the helper function argument f. to illustrate consider a call to tr.scan f acc .
here e xpositor passes the accumulator to f wrapped in an instance of class lazy defined as follows 121class lazy force return the actual value isforced return whether force has been called the force method when first called will compute the actual value and cache it the cached value is returned in subsequent calls.
thus fcanforce the accumulator as needed and if it is not forced it will not be computed.
to see the benefit consider the following example which uses scan to derive a new trace in which each item is a count of the number of consecutive calls to foowith nonzero arguments resetting the count when foois called with zero 124foo execution.breakpoints foo void foo int x 125def count nonzero foo lazy acc snapshot if snapshot.read var x !
return lazy acc.force else return 130nonzero foo foo.scan count nonzero foo notice that if lazy accwere not lazy e xpositor would have to compute its value before calling count nonzero foo.
by the definition of scan this means that it must recursively call count nonzero footo compute all prior output items before computing the current item even if it is unnecessary to do so e.g.
if we had called nonzero foo.get before t and the call to foojust before time thad argument x .
thus a lazy accumulator avoids this unnecessary work.
e xpositor uses a lazy accumulator in revscan for the same reason.
likewise observe that in tr0.trailing merge f tr1 for a particular item in tr0the function fmay not need to look in tr1to determine its result thus e xpositor wraps the tr1 argument to fin an instance of class lazy.
the implementation ofrevtrailing merge similarly passes lazy items from tr1to f. note that there is no such laziness in the regular merge operation.
the reason is that in tr0.merge f tr1 the items from tr0andtr1that are combined with foccur at the same time.
thus making f s arguments lazy would not reduce demands on the underlying time travel debugger.
b. tree scan finally e xpositor provides another list combinator treescan which is a lazier variant of scan that is sometimes more efficient.
the tscan method computes an output for every prefix of an input trace by applying an associative binary function in a tree like fashion .
it is invoked with tr.tscan f where fmust be an associative function that is lazy and optional in its left argument and lazy in its right argument.
thetscan method generates an output trace of the same length as the input trace where the nth output outnis defined as outn in0fin1f finn where fis written infix as f. notice that there is no accumulator and e xpositor can apply fin any order since it is associative.
when a value at time tis demanded from the output trace e xpositor first demands the item innat that time in the input trace if no such item exists then there is no item at that time in the output trace .
then e xpositor walks down the interval tree structure of the input trace calling f only if demanded on each internal tree node s children to trtr.tscan f ffff a tr.rev tscan f trffff b fig.
.
illustration of tree scan operations.
compute outn.
since the interval tree for the input trace is computed lazily fmay sometimes be called with none as a left argument for the case when fforces an interval that turns out to contain no values thus for correctness we also require that ftreats none as a left identity.
the right argument corresponds to innand so will never be none .
because both arguments of fare lazy e xpositor avoids computing either argument unnecessarily.
the isforced method of the lazy class is particularly useful for tscan as it allows us to determine if either argument has been forced and if so evaluate the forced argument first.
for example we can check if a trace contains a true value as follows 131def has true lazyleft lazyright return lazyleft.is forced and lazyleft.force n or lazyright.is forced and lazyright.force n or lazyleft.force or lazyright.force 135has true trace some trace.tscan has true 136last has true has true trace.get before inf the best case for this example occurs if either lazyleft or lazyright have been forced by a prior query in which case either the first clause line or second clause line will be true and the unforced argument need not be computed due to short circuiting.
expositor srevtscan derives a new trace based on future items instead of past items computing output item outnas outn innfinn 1f finlength here the right argument to fis optional rather than the left.
iv.
t heedithash array mapped trie many of the e xpositor scripts we have written use sets or maps to record information about the program execution.
for example in sec.
i we suggested the use of a shadow set to debug the implementation of a custom set data structure.
unfortunately a typical eager implementation of sets or maps could demand all items in the traces defeating the intention of e xpositor s lazy trace data structure.
to demonstrate this issue consider the following code which uses python s standard non lazy setclass to collect all arguments in calls to a function foo 137foos the execution.breakpoints foo void foo int arg 138def collect fooargs lazy acc snap return lazy acc.force .union n set 141fooargs foos.scan collect fooargs set 8142class edithamt lookup methods contains k return if key kexists find k return the latest value for kornone if not found find multi k return an iterator of all values bound to k static factory methods to create new edithamts empty create an empty edithamt add lazy eh k add binding of kto itself to lazy eh addkeyvalue lazy eh k v add binding of ktovtolazy eh remove lazy eh k remove all bindings of kfrom lazy eh removeone lazy eh k remove the latest binding of kto any value from lazy eh removekeyvalue lazy eh k v remove the latest binding of ktovfrom lazy eh concat lazy eh1 lazy eh2 concatenate lazy eh2edit history to lazy eh1 fig.
.
the edithamt api.
notice that we must force lazy accto call the union method which will create a deep copy of the updated set lines .
unfortunately forcing lazy acc causes the immediately preceding set to be computed by recursively calling collect fooargs.
as a result we must compute all preceding sets in the trace even if a particular query could be answered without so.
to address these problems we developed the edit hash array mapped trie edithamt a new set map multiset and multimap data structure that supports lazy construction and queries.
the edithamt complements the trace data structure as we will explain and our micro benchmark in sec.
v d will show the edithamt can be used in traces without compromising trace laziness unlike eager sets or maps.
a. edithamt api from the user s perspective the edithamt is an immutable data structure that maintains the entire history of edit operations for each edithamt.
fig.
shows the edithamt api.
the edithamt class includes contains k to determine if key kexists and find k to look up the latest value mapped to key k. it also includes the find multi k method to look up all values mapped to key k returned as a python iterator that incrementally looks up each mapped value.
edithamt operations are implemented as static factory methods that create new edithamts.
calling edithamt.empty creates a new empty edithamt.
calling edithamt.add lazy eh k creates a new edithamt by adding to lazy eh the prior edithamt a binding from key kto itself treating the edithamt as a set or multiset .
similarly edithamt.addkeyvalue lazy eh k v creates a new edithamt by adding to lazy eha binding from keykvalue v treating the edithamt as a map or multimap .conversely calling edithamt.remove lazy eh k creates a new edithamt by removing all bindings of key kfrom lazy eh.
lastly calling edithamt.removeone lazy eh k oredithamt .removekeyvalue lazy eh k v creates new edithamts by removing from lazy ehthe most recent binding of key kto any value or to a specific value v. the lazy ehargument to these static factory methods is lazy so that we need not force it until a call to contains findorfind multi demands a result.
for convenience the lazy ehargument can also be none which is treated as an empty edithamt.
the last static factory method edithamt.concat lazy eh1 lazy eh2 concatenates the edit histories of its arguments.
for example 166ehrem edithamt.remove none x 167ehadd edithamt.addkeyvalue none x 168eh edithamt.concat eh add eh rem here ehis the empty edithamt since it contains the additions in ehadd followed by the removals in ehrem.
a common e xpositor script pattern is to map a trace to a sequence of edithamt additions and removals and then use edithamt.concat with scan ortscan to concatenate those edits.
b. example edithamt to track reads and writes to a variable as an example of using the edithamt we present one piece of the race detector used in our firefox case study sec.
vi .
the detector compares each memory access against prior accesses to the same location from any thread.
since undodb serializes thread schedules each read need only be compared against the immediately preceding write and each write against the immediately preceding write as well as reads between the two writes.
we use the edithamt as a multimap in the following function to track the access history of a given variable v 169def access events v reads the execution.watchpoints v rw read n .map lambda s edithamt.addkeyvalue n none v read s.get thread id writes the execution.watchpoints v rw write n .map lambda s edithamt.addkeyvalue n edithamt.remove none v n v write s.get thread id return reads.merge none writes inaccess events we create the trace reads by finding all reads to vusing the watchpoints method line and then mapping each snapshot to a singleton edithamt that binds v to a tuple of read and the running thread id lines .
similarly we create the trace writes for writes to v line but instead map each write snapshot to an edithamt that first removes all prior bindings for v line then binds vto a tuple of write and the thread id lines .
finally we merge reads andwrites and return the result line .
we are not done yet since the edithamts in the trace returned by access events contain only edit operations corresponding to individual accesses to v. we can get an edithamt trace that records all accesses to vfrom the beginning of the 9readvar1t0thread 1readvar2t1thread 2writevar1addvar1read 1access events var1 .merge access events var2 removevar1addvar1write 1writevar2readvar1addvar2read 2removevar2addvar2write 1addvar1read 2t2t3t4fig.
.
example execution with two threads accessing var1 gray and var2 and the corresponding edithamt operations returned by access events .
execution by using scan with edithamt.concat to concatenate the individual edithamts.
for example we can record the access history of var1 as follows 178var1 history access events var1 .scan edithamt.concat we can also track multiple variables by calling access events on each variable merging the traces then concatenating the merged trace e.g.
to track var1 andvar2 179access history n access events var1 .merge access events var2 n .scan edithamt.concat since trace methods are lazy this code completes immediately the edithamt operations will only be applied and the underlying traces forced when we request a particular access e.g.
at the end of the execution time inf 182last access history.get before inf to see laziness in action consider applying the above analysis to an execution depicted in fig.
which shows two threads at the top and the corresponding edithamt operations at the bottom.
suppose we print the latest access to var1 at timet4using the findmethod print last.find var1 read because var1 was just added at time t4 answering this query will only force the edithamt and query the time travel debugger at time t4 and not before.
as another example suppose we want to find all accesses tovar1 from the last access backward using find multi for mem access in last.find multi var1 print mem access read write here since all var1 bindings added prior to time t2were removed at time t2 the results are computed without forcing any edithamts or querying the debugger before time t2.
c. implementation the edithamt is inspired by the hash array mapped trie hamt .
like the hamt the edithamt is a hybrid data structure combining the fast lookup of a hash table and the memory efficiency of a trie.
the hamt is a hash baseddata structure built in a manner analogous to a hash table.
whereas a hash table uses a bucket array to map keys to values the hamt uses an array mapped trie amt a trie that maps fixed width integer keys to values for the same purpose.
when a hash collision occurs the hamt resolves the collision by replacing the colliding entry with a nested hamt rehashing the colliding keys and inserting those keys in the nested hamt using the new hash values.
we developed the edithamt by making two changes to the traditional hamt.
first we replaced the amt with thelazyamt which supports lazy rather than eager updates.
second we resolve hash collisions as well as support remove and multiset multimap operations using editlist s which are lazy linked lists of nodes tallying edit operations on the edithamt the tails are lazily retrieved from the prior edithamt.
lazyamt lazy array mapped tries the first piece of the edithamt is the lazyamt which is a lazy immutable variant of the amt that maps fixed width integer keys of sizekbits to values.
we implement the lazyamt using lazy sparse arrays of size 2was internal nodes where wis the bit width of the array index such that w k and store keyvalue bindings as leaf nodes.
we will divide the key into w bit words where each w bit word is used to index an internal node during a lookup the key can be padded as necessary if kis not a multiple of w. lazy sparse arrays combine the properties of lazy values and sparse arrays each element of a lazy sparse array is computed and cached when first indexed akin to forcing a lazy value and null elements are stored compactly like sparse arrays.
we implement lazy sparse arrays using two bitmaps to track which elements are initialized and non null 4respectively and an array to store initialized non null elements.
to build the edithamt we need to support two operations on the lazyamt adding a key value binding to a lazyamt and merging two lazyamts into a single lazyamt.
we will explain how the lazyamt works by example using an internal node index bit width of w bits and a key size of k bits.
a adding a key value binding when we add a binding such as bto a lazyamt we first create a new lazy sparse array representing the root node bprior lazyamt initially all elements of the root node are uninitialized which we depict as four narrow dotted boxes we will use the convention of numbering the boxes from left to right i.e.
in binary the leftmost box is element and the rightmost box is element .
in addition we also maintain a lazy reference 4it is more efficient to track non null elements as many modern processors provide a popcnt instruction which counts the number of 1bits in a word that can be used to compute the index of a non null element in the storage array.
10to the prior lazyamt we do not yet need to know what the prior lazyamt contains which we indicate with a dotted arrow.
in fact the lazy reference allows us to further defer the construction of the root node of the prior lazyamt i.e.
the prior lazyamt may not exist yet when we add the binding b we indicate this with a dotted trapezoid.
for example in e xpositor we may query undodb to determine what binding should be added only when the lazy reference to the prior lazyamt is first forced.
we also need to store the binding b to be added when the lazyamt is sufficiently initialized.
the actual construction of the lazyamt occurs only when we look up a binding.
the lookup is a standard trie lookup however since internal nodes are lazy sparse arrays the elements of those arrays will be initialized as necessary when we access those elements during the lookup.
we initialize an element in one of three ways depending on whether that element is along the lookup path of the binding we previously set aside to be added and whether we have reached the end of the lookup path.
if the element is along the lookup path the binding and we have not reached the end of the lookup path we create the next internal node and initialize the element to that node.
if the element is along the lookup path of the binding and we have reached the end of the lookup path we initialize the element to a leaf node containing that binding.
otherwise if the element is not along the lookup path of the binding we initialize it to point to the same subtrie as the corresponding element at the same partial lookup path in the prior lazyamt or to be null if the corresponding element does not exist.
note that in the last case prior lazyamts will be recursively initialized as necessary.
for example suppose that we look up the binding for key .
first we split up the key into w bit words here in binary this is the lookup path for key .
then we use the first word to index the root node.
we need to initialize the element at 00as this is the first time we accessed it.
since this particular lazyamt was created by adding band the 00element of the root node is along the lookup path for key we initialize that element to a new uninitialized internal node below the root node bprior lazyamt here we depict the initialized element of the root node as a square unbroken box and a non lazy reference to the just created internal node as an unbroken arrow.
we continue the lookup by using the next word to index the just created internal node.
since 11is again along the lookup path we initialize the corresponding element to another internal node.
we repeat the process again with the last word but now that we have exhausted all bits in the lookup key we initialize the element for 10to point to a leaf node containing the binding bthat we previously set aside.
this results in a partially initialized lazyamt prior lazyamt14 bwe finish the lookup for key 14and return b. the example so far illustrates how the lookup process drives the initialization process in an interleaved manner.
also since we are looking up a key that was just inserted into the lazyamt we did not need to refer to the prior lazyamt at all.
these properties allow lazyamts to be constructed lazily by initializing only as much as necessary to answer lookup queries.
we continue the example by considering the case of looking up a key that was not added by the most recent lazyamt.
suppose that the immediately prior lazyamt when computed will add binding a prior lazyamt14 badd a if we then look up key or00 in binary from the rightmost lazyamt we would first index 00of the root node.
we have already initialized this element from looking up key 14before so we simply walk to the next internal node and index .
the element at 01is uninitialized but it is not along the lookup path of key the key added to the rightmost lazyamt.
to continue the lookup of key we retrieve the prior lazyamt by forcing our lazy reference to it causing it to be partially constructed aprior lazyamt14 b then we initialize the element at 01to point to the subtrie under the element at the partial key in the prior lazyamt initializing the middle lazyamt a bit more along the way aprior lazyamt14 bwe finish the lookup for key 5as before initializing the lazyamts a bit more b5 aprior lazyamt note that we have simultaneously initialized parts of the rightmost lazyamt and the middle lazyamt because they share a common subtrie subsequent lookups of key 5on either lazyamt will become faster as a result.
b merging two lazyamts the merge operation takes two lazyamts as input which we call left and right as well as a function mergefn lazy opt leftval rightval that is called to merge values for the same key in both lazyamts.
as the name of the arguments suggests mergefn is called in an unusual asymmetric manner in that it is called for all keys in the right lazyamt but not necessarily for all keys in the leftlazyamt.
for each key in the right lazyamt mergefn is called with a lazy optional value representing the value for that key in the leftlazyamt as the lazy opt leftval argument and the value for the same key in the right lazyamt as the rightval argument.
this approach maximizes laziness in that we can compute a lazy value as soon as we determine a key exists in the one lazyamt without immediately looking up the value for the same key in the other lazyamt.
for example mergefn can be used to create a lazy linked list by returning lazy opt leftval and rightval in a tuple.
when we merge two lazyamts we first create a new root node of a new lazyamt with two lazy