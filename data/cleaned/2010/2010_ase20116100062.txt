a topic based approach for narrowing the search space of buggy files from a bug report anh tuan nguyen tung thanh nguyen jafar al kofahi hung viet nguyen tien n. nguyen electrical and computer engineering department iowa state university anhnt tung jafar hungnv tien iastate.edu abstract locating buggy code is a time consuming task in software development.
given a new bug report developers must search through a large number of files in a project to locate buggy code.
we propose bugscout an automated approach to help developers reduce such efforts by narrowing the search space of buggy files when they are assigned to address a bug report.
bugscout assumes that the textual contents of a bug report and that of its corresponding source code share some technical aspects of the system which can be used for locating buggy source files given a new bug report.
we develop a specialized topic model that represents those technical aspects as topics in the textual contents of bug reports and source files and correlates bug reports and corresponding buggy files via their shared topics.
our evaluation shows that bugscout can recommend buggy files correctly up to of the cases with a recommended ranked list of files.
index terms defect localization topic modeling.
i. i ntroduction to ensure software integrity and quality developers always spend a large amount of time on debugging and fixing software defects.
a software defect which is informally called a bug is found and often reported in a bug report.
a bug report is a document that is submitted by a developer tester or end user of a system.
it describes the defect s under reporting.
such documents generally describe the situations in which the software does not behave as it is expected i.e.
fails to follow the technical requirements of the system.
being assigned to fix a bug report a developer will analyze the bug s search through the program s code to locate the potential defective buggy files.
let us call this process bug file localization .
this process is crucial for the later bug fixing process.
however in a large system this process could be overwhelming due to the large number of its source files.
at the same time a developer has to leverage much information from the descriptive contents of the bug report itself from his domain knowledge of the system and source code from the connections between such textual descriptions in a report and different modules in the system and from the knowledge on prior resolved bugs in the past etc.
therefore to help developers target their efforts on the right files and raise their effectiveness and efficiency in finding and fixing bugs an automated tool is desirable to help developers to narrow the search space of buggy files for a given bug report.
in this paper we propose bugscout a topic based approach to locate the candidates of buggy files for a given bug report.
the key ideas of our approach are as follows there are several technical functionality aspects in a software system.
some functionality aspects might be buggy i.e.
incorrectly implemented.
as a consequence a bug report is filed.
the textual contents of the bug report and those of the corresponding buggy source files comments and identifiers tend to describe some common technical aspects topics among other different technical topics .
thus if we could identify the technical topics that are described in the bug reports and source files we could recommend the files that describe the common technical topics with a given bug report.
some source files in the system might be more buggy than the others e.g.
they are more defect prone .
similar bugs might be related to similar fixed files thus if a given bug report xhas some similar topic s with a previously resolved bug report yin the history the fixed files associated with ycould be the candidate buggy files for x. in this paper we extend latent dirichlet allocation lda to model the relation among a bug report and its corresponding buggy source files.
lda is a generative machine learning model that is used to model the topics in a collection of textual documents.
in lda a document is considered to be generated by a machine which is driven via parameters by the hidden factors called topics and its words are taken from some vocabulary .
one can train the model with historical data to derive its parameters.
terms in the documents in the project s history are the observed data.
lda considers that all documents are generated by that machine with its parameters.
when lda is applied to a new document it uses its process to generate that document thus it can tell the topics that are described in the document s contents and the corresponding terms for those topics.
in bugscout the technical aspects in the system including in bug reports and source code are modeled by topics.
bugscout model has two components representing two sets of documents source files and bug reports.
the s component for a source file is a lda model in which a source file is modeled as a document influenced by the topic distribution parameter and other parameters of the lda model.
for some buggy source files some of their technical topics might be incorrectly implemented.
as a consequence a bug report is filed to report on the buggy topic s .
the second component b component is designed to model bug reports.
b component is an extended lda model in which a bug report is modeled as a document that are influenced not only by its own topic distribution978 .
c ieee ase lawrence ks usa263 parameter but also by the topic distribution parameters of the buggy source files corresponding to that bug report.
the rationale behind this design is that the contents of a bug report are written by the tester reporter and describe about the occurrence of the bug s .
thus the technical topics of the buggy files must be mentioned in the bug report.
at the same time a bug report is also a relatively independent document and can discuss about other topics.
for example a bug report on memory leaking could also mention about the related topics on file loading when the memory leaking was observed.
the scomponent models the source files from the developers point of view while the b component models the bug reports written from the point of view of the reporters.
two components are connected to form bugscout.
we also developed the algorithms for training and predicting buggy files for a given bug report.
parameters in bugscout are the parameters combined from two components.
they can be derived by our training algorithm with the historical data of the previous bug reports and corresponding buggy files.
when a new bug report is filed bugscout is applied to find its topics.
then the topics of that report are compared with the topics of all source files.
the source files that have had more defects in the past and have shared topics with the new bug report will be ranked higher and recommended to developers.
we have conducted an empirical evaluation of bugscout on several large scale real world systems.
bugscout can recommend candidate buggy files correctly up to of the cases with one single file and up to of the cases with a ranked list of files.
that is in almost half of the cases the top files in the recommended ranked list contain the actual buggy file s .
the key contributions of this paper include .
bugscout a topic model that accurately recommends a short list of candidate buggy files for a given bug report .
associated algorithms for model training and predicting of buggy files for a new bug report and .
an empirical evaluation on the usefulness of bugscout.
section presents the motivating examples.
section provides the details of our model bugscout.
section describes the associated algorithms for training and inferring candidate buggy files.
section is for our empirical evaluation.
section discusses the related work and conclusions appear last.
ii.
m otivating examples let us discuss some real world examples that motivate our approach.
we collected the bug reports and their corresponding fixed files from an industrial project of a large corporation.
the year development data from that project includes source files documentation test cases defects and bug reports change data and communication data among developers.
in that project for a work item a general notion of a development task the data contains a summary a description a tag and relevant software artifacts.
there are work items of which are marked as bug reports.
as a developer fixed a bug in response to a bug report s he was required to record the fixing changes made to the fixed files.
we wrote a simple tool to extract the data and observed the following examples.bug report summary error saving state returned from update of external object incoming sync will not be triggered.
description this showed up in the server log.
it s not clear which interop component this belongs to so i just picked one of them.
seems like the code run in this scheduled task should be able to properly handle a stale data by refetching retrying.
fig.
bug report interopservice.java implementation of the interop service interface.
fetch the latest state of the proxy fetch the latest state of the sync rule only return data from last synchronized state if there is a project area associated with the sync rule get an advisable operation for the incoming sync schedule sync of an item with the state of an external object the result of incoming synchronization of one item state .
use sync rule to convert an item state to new external state.
get any process area associated with a linked target item.... for permissions checking get any process area associated with the target item.
if none get the process area of the sync rule.
return an instance of the process server service... do incoming synchronization of one state of an item.
public iexternalproxy processincoming iexternalproxyhandle ... ... ... fig.
source file interopservice.java example .
figures and display bug report and the corresponding fixed buggy file interopservice.java for brevity only comments are shown in figure .
the report is about a software defect in which incoming synchronization tasks were not triggered properly in a server.
we found that the developers fixed the bug at a single file interopservice.java by adding code into two methods processincoming and processincomingonestate to handle a stale data by refetching.
as shown both bug report and the buggy file interopservice.java describe the same problematic functionality of the system the synchronization of incoming data in the interop service.
this faulty technical aspect was described and could be recognized via the relevant terms such as sync synchronization incoming interop state schedule etc.
considering the bug report and the source file as textual documents we could consider this technical aspect as one of their topics .
this example suggests that the bug report and the corresponding buggy source files share the common buggy technical topic s .
thus detecting the common technical topic s between a bug report and a source file could help in bug file localization.
example .
we also found another report figure that was also fixed at the single file interopservice.java but at two different methods processoutgoing and processoutgoingonestate .
it reported a different technical topic the permission issue with background outgoing tasks in interop service.
examining those two methods we saw that the bug report and the source file also share that common topic which is expressed via the relevant terms such as outgoing synchronize permissions process state interop service etc.
this example also shows that a source file e.g.
interopservice.java could have multiple buggy technical aspects and thus could be traced linked from multiple bug reports.264bug report summary do not require synchronize permissions for background outgoing sync task.
description the background outgoing sync task in interop component which runs as admin is currently invoking a process enabled operation to save external state returned from some external connection.
it causes a problem because admin needs to be granted process permissions.
a periodic server task should be trusted however so it shouldn t invoke process enabled operations.
fig.
bug report bug report summary mutiple cq records are being created description there are records in cq db which seem to have identical information.
they all have the same headline cq connector use case for rtc instance with multiple project areas.
on the client side there is only item corresponding to all these.
fig.
bug report example .
we also examined bug report figure .
analyzing it carefully we found that it reported on three technical aspects including an issue with the interop service connection an issue with the connection to cq database and an issue with the instance of rtc framework.
for this bug report developers made several fixing changes to nine different files including interopservice.java .
this example shows that a bug report could also describe multiple technical aspects and could be linked mapped to multiple files.
moreover despite having multiple topics this bug report and the corresponding fixed file interopservice.java share the common buggy topic on interop service connection .
that common buggy topic was described in parts of the report and in parts of interopservice.java .
observations and implications.
the motivating examples give us the following observations .
a system has several technical aspects with respect to multiple functionality.
some aspects functionality might be incorrectly implemented.
.
a software artifact such as a bug report or a source file might contain one or multiple technical aspects.
those technical aspects can be viewed as the topics of those documents.
each topic is expressed via a collection of relevant terms.
.
a bug report and the corresponding buggy source files often share some common buggy technical topics.
.
some source files in the system might be more buggy than the others.
those observations suggest that while finding the source files relevant to a bug report developers could explore the similarity sharing of topics between them and the bug profile of the source files.
that is if a source file shares some common topic s with a bug report and is known to be buggy in the history it is likely to be relevant to the reported bug s .
iii.
m odel in bugscout each software system is considered to have k technical aspects topics.
among other types of artifacts in a system bugscout concerns two types of artifacts source files and bug reports.
source file is a kind of software artifacts summary do not require synchronize permissions for background outgoing description the background outgoing sync task in the interop component which runs as admin is currently invoking a process enabled operation to save external state ...bug report b with n words b topic... ktopic proportion bfor b...topic vector z of size nb bsync task topic interop .
synchronize .
outgoing .
state .
process .
permission .10topic connection .
rtc .
database .
cq .
priority .
view .02topic k file .
repository .
content .
editor .
open .
view .
... ... ... ...vocabulary of v words sync interop incoming state ... 1 2 kper topic word distribution brfig.
illustration of lda written in a programming language.
each source file implements one or multiple technical aspects of a software system.
some of them might be incorrectly implemented and cause bugs.
a bug report is a kind of software artifacts that describe buggy technical aspect s .
our model has two components for those two types of artifacts s component for source files and b component for bug reports.
the s component models the source files from the developers point of view while the bcomponent models the bug reports written from the point of view of bug reporters.
two components are connected to form bugscout.
let us describe them in details.
a. s component s component in bugscout is adopted from lda .
in general source code always includes program elements and are written in some specific programming language.
in bugscout a source file is considered as a text document s. texts from the comments and identifiers in a source file are extracted to form the words of the document s. topic vector.
a source document shasnswords .
in scomponent each of the nspositions in document sis considered to describe one specific technical topic.
therefore for each source document s we have a topic vector zswith the length of nsin which each element of the vector is an index to one topic i.e.
k .
topic proportion.
each position in sdescribes one topic thus the entire source document scan describe multiple topics.
to represent the existence and importance of multiple topics in a document s lda introduces the topic proportion s. sfor each document sis represented by a vector with kelements.
each element corresponds to a topic.
the value of each265element of that vector is a number in which represents the proportion of the corresponding topic in s. the higher the value s is the more important topic kcontributes to the document s. for example in the file interopservice.java if s of words are about outgoing sync other are about incoming sync etc.
vocabulary and word selection.
each position in source code document sis about one topic.
however to describe that topic one might use different words which are drawn from a vocabulary of all the words in the project and other regular words in any dictionary of a natural language .
let us call the combined vocabulary v oc with the size of v. each word inv oc has a different usage frequency for describing a topic k and a topic can be described by one or multiple words.
lda uses a word selection vector kfor the topic k. that vector has the size of vin which each element represents the usage frequency of the corresponding word at that element s position in v oc to describe the topic k. each element vin kcan have a value from to .
for example for a topic k k .
that is in of the cases the first word in v oc is used to describe the topic k of the cases the second word is used to describe k and so on.
for a software system each topic khas its own vector k thenktopics can be represented by a k vmatrix src which is called per topic word distribution .
note that src is applicable for all source files rather than for sindividually.
lda is a machine learning model and from its generative point of view a source file sin the system is considered as an instance generated by a machine with three aforementioned variables zs s src.
given a source code document s of size ns based on topic proportion sof the document the machine generates the vector zsdescribing the topic of every position in the document s. for each position it then generates a word wsbased on the topic assigned to that position and the per topic word distribution srccorresponding to that topic.
this is called a generative process .
the terms in the source files in the project s history are the observed data.
one can train the lda model with historical data to derive those three parameters to fit the best with the observed data.
as a new document s comes lda uses the learned parameters to derive the topics of the document and the proportion of those topics.
b. b component let us describe the b component in our bugscout model which is extended from lda .
as a consequence of an incorrect implementation of some technical aspects in the system a bug report is filed.
thus a bug report describes the buggy technical topic s in a system.
similar to s component b component also considers each bug report bas a document with three variables zb b br figure .
a bug report b hasnbwords.
the topic at each position in bis described by a topic vector zb.
the selection for the word at each position is modeled by the per topic word distribution br.
note that brapplies to all bug reports and it is different from src.
the bug report bhas its own topic proportion b. however that report is influenced not only by its own topic distribution sm 1 sm s1... b zsm 1sm s1...bz z z sm 1sm s1 bw ...w w w br src src src ...fig.
bugscout model but also by the topic distribution parameters of the buggy source files corresponding to that bug report.
the rationale behind this design is that in addition to its own topics the contents of a bug report must also describe about the occurrence of the bug s .
that is the technical topics of the corresponding buggy files must be mentioned in the bug report.
at the same time a bug report might describe about other relevant technical aspects in the system from the point of view of the bug reporter.
let us use s1 s2 ... s mto denote the buggy source files that are relevant to a bug report b. the topic distribution of bis a combination of its own topic distribution b from the writing view of a bug reporter and topic distributions of s1 s2 ... s m. in bugscout we have b s1.
s2..... sm.
b. the equation represents the sharing of buggy topics in a bug report and corresponding source files.
if a topic khas a high proportion in all sand b i.e.kis a shared buggy topic it also has a high proportion in b. the generative process in b component is similar to s component except that it takes into account the combined topic proportion b s1.
s2..... sm.
b. c. bugscout model to model the relation between a bug report and corresponding buggy source files we combine the s component and bcomponent into bugscout figure .
for a bug report b in the b component side there are variables that control b zb b and br.
however if the source files s1 s2 ... s mare determined to cause a bug reported in bug report b the topic vector zbwill be influenced by the topic distributions of those source files.
that is there are links from s1 s2 ... smtozb.
for each source document there are variables that control s zs s and src figure .
there are two hyper parameters and whose conditional distributions are assumed as in lda.
is the parameter of the uniform dirichlet prior on topic distributions sand b. is the parameter of the uniform dirichlet prior on the per topic word distributions srcand br.266for training the model will be trained from historical data including source files bug reports and the links between bug reports and corresponding fixed source files.
the variables of bugscout will be trained to derive its parameters and to make the model fit most with both the document data and the links between bug reports and corresponding buggy source files.
for predicting the model will be applied to a new bug report bnew.
bugscout uses its trained parameters to generate that bug report and estimate its topic proportion bnew.
that topic proportion will be used to find corresponding source files that share most topics.
cosine distance is used to determine the topic proportion similarity.
we use sim s b to denote the topic proportion similarity between a source file sand a bug report b. the topics of that bug report are compared with the topics of all source files.
finally the files that have shared the buggy topics with the new bug report will be ranked and recommended to the developers.
because bugscout has two components and the dependencies among variables in the internal model become much different from lda we developed our own algorithms for training bugscout with historical data and predicting for a new bug report.
we will present them in section iv.
integrating with defect proneness of source files in a software system some files might be more buggy than the others.
we integrate this characteristic into bugscout to improve its accuracy in buggy file prediction.
we use the following equation to formulate the idea p s b p s sim s b in the equation p s b is the total relevance measure of a source file to a given bug report b.sim s b is the similarity of the topics of the source file and those of the bug report.
p s is the bug profile of source file s. in bugscout s current implementation p s is determined by the number of bugs in the file sin the history and by its size.
other strategies for computing defect proness of a source file can be used for p s .
the equation implies the inclusion of both defect proneness and the buggy topics of a source file.
given a new bug report if a source file is determined as having higher buggy potential and it also contains shared buggy topics with the bug report it will be ranked higher in the list of possible buggy files.
next section will describe our training and predicting algorithms.
iv.
a lgorithms a. training algorithm the goal of this algorithm is to estimate bugscout s parameters given the training data from a software system.
the collection of source files s that of bug reports b and the set of links ls b between a bug report and corresponding source file s will be used to train bugscout and estimate its parameters zs s src and zb b br .
algorithm overview.
our algorithm is based on gibbs sampling method .
the idea of gibbs sampling is to estimate the parameters based on the distribution calculated from other sampled values.
the estimation is made iteratively between the1 training 2function trainmodel sourcefiles s bugreports b links ls b 3zs zb src br random 4repeat 5z s zs z b zb update the variables forsource documents for sourcefile s s for i 1tons zs estimatezs s i estimate topic assignment at position i end s ns ns estimate topic distribution end src k nk n estimate per topic word distribution update the variables forbug reports for bugreports b b for i 1tonb zb estimatezb1 wb ls b i end b nb nb end br k nk n until z z return zs zb s b src br 24end estimate topic assignment fors 26function estimatezs sourcefile ws inti for k 1tok p zs k ns ns k nsrc k nsrc k v end 30zs sample p zs 31end estimate topic assignment forb 33function estimatezb1 bugreport wb inti links lws wb for k 1tok p zb k nb s ls b ns nb s ls b ns k nbr k nbr k v end 37zb sample p zb 38end fig.
model training algorithm values until the estimated parameters reach their convergent state i.e.
the new estimated value of a parameter do not change in comparison with its previous estimated value .
figure shows the pseudo code of our training algorithm.
function trainmodel is used to train bugscout by using the collections of source files s bug reports b and the set of links ls b between the bug reports and the corresponding buggy source files.
line describes the initial step where the parameters zs zb src brare assigned with randomly values.
lines describe the iterative steps in estimating the parameters using gibbs sampling.
the iterative process terminates when the values of parameters are convergent.
the convergent condition is determined by checking whether the difference between the current estimated values and previous estimated ones is smaller than a threshold.
in our implementation the process is stopped after a number of iterations which is large enough to ensure a small error.
in each iteration the parameters are estimated for all source code documents sin s lines and all bug reports binb lines .
detailed description.
let us explain in details all the steps.
step estimating the topic assignment for source documents ins lines .
with each document sins bugscout estimates the topic assignment zs for position i line .267function estimatezs lines provides the detailed computation.
for each topic kinktopics bugscout estimates the probability that topic kwill be assigned for position iin document s. then it samples a topic based on the probabilities ofks line .
the equation follows the topic assignment estimation by gibbs sampling in lda p zi k zs ws ns ns k nsrc k nsrc k v where ns is the number of words in s except for the current position i that are assigned to topic k nsis the total number of words in s nsrc k is the number of words wiin all source documents s except for the current position that are assigned to topic k and nsrc k is the number of all words in sthat are assigned to topic k. the intuition behind this equation is that given a word ws at position iof document s the probability a topic k that is assigned to that position can be estimated based on both the proportion of the terms in s excluding the current one that describe topic k i.e.
ns ns and the probability that the current term ws appears if topic kis assigned i.e.
nsrc k nsrc k .
moreover the current position value can be estimated by prior knowledge of surrounding positions.
step estimating topic proportion sfor a source file line .
line shows the estimation for the topic proportion of source file s. once topic assignments for all positions in sare estimated the topic proportion s of topic kin that document can be approximated by simply calculating the ratio between the number of words describing the topic kand the length of the document.
step estimating word distribution src line .
line shows the estimation for the per topic word distribution for each word wifrom v oc sizev and topic k. src k is a vector of size v representing how often each word in vocabulary v oc can be used to describe topic kin the source file collection s. element at index iin kdetermines how often the word with index iinv oc can be used to describe k. thus k can be approximated by the ratio between the number of times that the word index iinv oc is used to describe topic kand the total number of times that any word that is used to describe k. step estimating the topic assignment for bug reports in b lines .
for each bug report binb bugscout estimates the topic assignment zb for position i line .
function estimatezb1 lines provides the detail.
for each topic kink bugscout estimates the probability that topic kwill be assigned for position i. it then samples a topic based on the probabilities of ks line .
the estimate equation is similar to that for a source file document p zb k zb wb n b n b k nbr k nbr k v where nbr k is the number of words wiin all bug reports in b except the current position that are assigned to topic k and nbr k is the number of words in sdescribing k.the crucial difference between and is that because a bug report describes the buggy topic s in the corresponding source documents the proportion of a topic kdescribed in the bug report includes its own topic proportion band the topic proportions of corresponding source files s1 s2 ... sm where s1 s2 ... s m ls b i.e.
the set of buggy source files linking to bug report b .
that leads to n b nb s ls b ns and n b nb s ls b ns in which nb is the number of words in b except for the current position i that are assigned to topic k.nbis the total number of words in b. for each buggy source document slinked to b ns is the number of words in s except for the current position i that are assigned to topic k.nsis the total number of words in s. step estimating topic proportion bfor a bug report band estimate word distribution br line and line .
those estimation steps are similar to the steps for sand src.
b. predicting and recommending algorithm the goal of this algorithm is to estimate the topic proportion of a newly arrived bug report bnew and derive a candidate list of potential buggy source files that cause the reported bug s .
the algorithm uses the trained model from the previous algorithm to estimate the topic proportion of bnew then it uses a similarity measure to compute the topic similarity between bnewand each source file sins.
the similarity in combination with p s will be used to estimate how likely scan cause the bug reported in b. the output of the algorithm will be a list of potential buggy source files corresponding to the given bug report.
our algorithm is also based on gibbs sampling.
figure describes the steps of our algorithm.
lines show the estimation step for parameters zbnewand bnewfor new bug report bnew we do not need to recalculate br because they are fixed after the training phase .
because we do not know the buggy links between source files and bnew we use lda gibbs sampling formula to estimate topic assignment and topic proportion for bnew.
the function for estimating zbnewis described in estimatezb2 lines .
in the equation nbnew is the number of words in bnew except the current position i that are assigned to topic k.nbnewis the total number of words in bnew.nbr k is the number of words wiin all source files s except the current position that are assigned to topic k.nbr k is the number of all words in s that are assigned to topic k. bugscout calculates s bnew i.e.
the probability that source file scauses the bug reported inbnew lines .
s bnew is calculated by multiplying the buggy profile p s ofsand the topic similarity measure sim ... between sandbnew lines .
finally it returns a ranked list of potential buggy files corresponding to bnew.
v. e valuation this section describes our empirical evaluation on buggy files recommendation accuracy of bugscout for given bug reports in comparison with the state of the art approaches.
all2681 predict and return relevant list 2function predict zs zb s b src br bugreport bnew prior p s estimate topic proportion of new bug report bnew 4repeat 5z bnew zbnew for i 1tonb zbnew estimatezb2 bnew i estimate topic assignment at position i end 9 bnew nbnew nbnew estimate topic proportion until zbnew z bnew calculate relevance ofsource files toa bug report for sourcefile s s s bnew p s sim s bnew calculate prob ofscausing the bug end return rankedlist s bnew 16end estimate topic assignment forb 18function estimatezb2 bugreport bnew inti for k 1tok p zbnew k nbnew nbnew k nbr k nbr k v end 22zbnew sample p zbnew 23end calculate topic similarity between a source file and a bug report 25function sim sourcefile s bugreport bnew 26 k ..k s bnew calculate dot product 27sim exp 28end fig.
predicting and recommending algorithm experiments were carried out on a computer with cpu amd phenom ii x4 .
ghz 8gb ram and windows .
a. data sets we collected several datasets in different software projects including jazz a development framework from ibm eclipse an integrated development environment aspectj a compiler for aspect oriented programming and argouml a graphical editor for uml .
eclipse argouml and aspectj datasets are publicly available and have been used as the benchmarks in prior bug file localization research .
all projects are developed in java with a long history.
each data set contains three parts.
the first part is the set of bug reports .
each bug report has a summary a description comments and other meta data such as the levels of severity and priority the reporter the creation date the platform and version.
the second part is the source code files .
we collected all source files including the buggy versions and the fixed files for all fixed bug reports.
the third part is the mapping from bug reports to the corresponding fixed files.
for jazz project the developers were required to record the fixed files for bug reports.
for other projects the mappings were mined from both version archives and bug databases according to the method in .
generally the change logs were mined to detect special terms signifying the fixing changes.
details are in .
table i shows the information on all subject systems.
b. feature extraction our first step was to extract the features from bug reports and source files for our model.
for the bug reports files grammatical words and stopwords were removed to reduce noises and other words were stemmed for normalization astable i subject systems system jazz eclipse aspectj argouml mapped bug reports source code files words in corpus in previous work .
tf idf was then run to determine and remove the common words that appear in most of the bug reports.
the remaining words in the bug reports were collected into a common vocabulary v oc.
a word was indexed by its position in the vocabulary.
only fixed bug reports were considered because those reports have the information on corresponding fixed source files.
we used the summary and description in a bug report as a bug report document in bugscout.
for a fixed source document we used the comments names and identifiers.
identifiers were split into words which were then stemmed.
next a feature vector was extracted from each document.
a vector has the form wi wi0 wi1 .
.
.
w in where wikis an index of the word at position kinv oc and nis the length of the source or bug report document.
the vectors were used for training and predicting.
for prediction bugscout outputs a ranked list of relevant files to a given bug report.
c. evaluation metrics and setup to measure the prediction performance of bugscout we use thetop rank evaluation approach.
our prediction tool provides a ranked list of n potential fix files for each bug report in a test set.
ncould be seen as the number of candidate files to which developers should pay attention.
the prediction accuracy is measured by the intersection set of the predicted and the actually fixed files.
we consider a hitin prediction if bugscout predicts at least one correct fixed buggy file in the ranked list.
if one correct buggy file is detected a developer can start from that file and search for other related buggy files.
prediction accuracy is measured by the ratio of the number of hits over the total number of prediction cases in a test set.
accuracy was reported for all top rank levels n. in our experiment we used the longitudinal setup as in to increase the internal validity and to compare with prior results.
the longitudinal setup allows data in the past history to be used for training to predict for the more recent bug reports.
first all bug reports in a subject system were sorted according to their filing dates and then distributed into ten equally sized sets called folds fold is the oldest and fold is the newest in the chronological order.
bugscout was executed several times in which older folds were used for training and the last fold was used for prediction.
specifically at the first run fold was used for training to predict the result for fold fold was not used for prediction because there is no prior data .
for each bug report in fold we measured the accuracy result for that report by comparing the predicted fixing files with the actual fixed files.
an average accuracy was recorded for fold .
we continued for fold using both folds and as the training set.
we repeated until269fig.
accuracy and the number of topics without p s fold using all first nine folds as the training set.
for each top rank level n we also measured the average accuracy across all nine test sets from folds .
by using this setup we could have a realistic simulation of real world usage of our tool in helping bug fixing as a new bug report comes.
if data is randomly selected into folds there might be the cases where some newer data would be used for training to predict the buggy files corresponding to the older bug reports.
d. parameter sensitivity analysis our first experiment was to evaluate bugscout s accuracy with respect to the number of chosen topics k. we chose argouml for this experiment.
two hyper parameters and were set to .
.
we compared the results when the defectproneness information of source files p s was used and was not used section iii .
we varied the values of k ifkis from the step is and if kis from the step is .
the accuracy values were measured for each top rank level n .
figure shows the top to top accuracy results.
as shown for this dataset in argouml the accuracy achieves its highest point in the range of around topics.
that is this particular data set might actually contain around that number of topics.
as kis small accuracy was low because there are many documents classified into the same topic group even though they contain other technical topics.
when kis around the accuracy reaches its peak.
that is because those topics still reflect well those reports and files.
however as kis large then the nuanced topics may appear and topics may begin to overlap semantically with each other.
it causes one document having many topics with similar proportions.
this overfitting problem degrades accuracy.
this phenomenon is consistent for all top rank levels.
we repeated the same experiment however in this case we used bugscout with the defect proneness information p s of the files i.e.
the number of bugs of the files in the past history and the sizes of the files section iii .
figure shows the result.
as seen with this information about the source files at k bugscout can improve from for top to topfig.
accuracy and the number of topics with p s accuracy.
importantly for this dataset accuracy is generally very good.
with top accuracy of when bugscout recommends a ranked list of files one in four cases that list contains a correct buggy file for the bug report.
with the ranked list of files the accuracy is about that is one of three cases a buggy file for the bug report is actually in that recommended list.
this result also shows that bugscout can potentially be combined with other defect proness prediction algorithms to improve accuracy.
e. accuracy comparison our next experiment was to evaluate bugscout s accuracy in comparison with that of the state of the art approaches the support vector machine svm based approach by premraj et al.
and the approach by lukins et al.
that combines lda and vector space model vsm .
for the former approach we re implemented their approach by using the same machine learning tool libsvm as in their work.
for the latter one we re implemented their lda vsm approach with our own code.
for our tool we performed the tuning process to pick the right number of topics as described earlier.
figure shows the accuracy result on jazz dataset.
the xaxis shows the size nof the top ranked list.
as seen bugscout outperforms both svm and lda vsm.
for top accuracy it achieved about when bugscout recommended one single file for each bug report in a test set it correctly predicted the buggy file on average.
that is in one of three cases the single recommended file was actually the buggy file for the given bug report.
the corresponding top accuracy levels for svm and lda vsm are only and respectively.
thus in top accuracy bugscout outperformed those two approaches by and respectively.
with the ranked list of files the top accuracy is around .
that is in four out of ten cases bugscout was able to recommend at least one correct buggy file among its recommended files.
the corresponding numbers for svm and lda vsm are only and .
at top accuracy bugscout also outperformed the other two approaches by and respectively.270fig.
accuracy comparison on jazz dataset fig.
accuracy comparison on aspectj dataset interesting examples.
examining those results we found that bugscout could detect within the top ranked list all buggy files of bug reports in section ii and several similar cases.
bugscout also correctly detected the buggy files that have never been defective in the past .
for example for bug report in jazz bugscout correctly detected with its single recommendation the buggy file com.ibm.team.scm.service.internal.iscmdatamediator which was not in the training set i.e.
not found buggy before .
figure shows the comparison result on eclipse dataset.
figure and figure display the comparison results on aspectj and argouml datasets respectively.
as seen bugscout consistently achieved higher accuracy from than the other two approaches for top to top ranked lists.
for top accuracy the corresponding number is from .
time efficiency.
table ii displays running time of our tool.
both average training time and prediction time for one bug report is reasonably fast .3s .3s and .8s 25s respectively.
generally bugscout is scalable for systems with large numbers of bug reports thus is well suited for daily practical use.
threats to validity.
our experiment was only on systems.
we also re implemented the existing approaches since their fig.
accuracy comparison on eclipse dataset fig.
accuracy comparison on argouml dataset tools are not available.
however we used the same library as used in their tools for our re implementation.
table ii time efficiency system jazz eclipse aspectj argouml average training time per br s .
.
.
.
average prediction time per br s .
.
.
vi.
r elated work a related work to bugscout is from lukins et al.
.
they directly applied lda analysis on bug reports and files to localize the buggy files.
they perform indexing on all source files with the detected topics from lda.
then for a new bug report a textual query is formed from its description and a search via vector space model vsm is performed among such indexed source files.
in contrast bugscout correlates the topics in both source files and bug reports and uses topics as a random variable in our model.
moreover their approach does not work well if the code contains few common terms with a new bug report.
as shown in section v bugscout outperformed their approach of lda vsm.271trase combines lda with prospective traceability i.e.
capturing developers activities during development for tracing between architecture based documents and source code.
instead of directly using lda bugscout correlates bug reports and buggy files via shared topics.
prospective tracing links are also incorporated in bugscout via the links from bug reports and corresponding fixed files recorded during bug fixing.
bugtalks from premraj et al.
addresses the bug localization using bug reports information.
they combine a machine learning approach using support vector machine svm on textual features in documents with a usual suspect list i.e.
the list of frequently buggy locations with the philosophy that bugs tend to concentrate in selected code components.
to train the svm model bug reports are paired with their fixed files in the usual suspect list to form positive examples.
however their approach faces unbalanced data with a huge number of negative examples which are the incorrect pairs of bug reports and files.
thus their accuracy depends much on the randomly selected set of such negative examples.
moreover their approach assumes that a bug report contains similar terms as the identifiers in the fixed files.
bugscout does not need negative examples and it correlates the reports and fixed files via common topics.
evaluation results also show that bugscout achieves higher top accuracy from .
ostrand et al.
and bell et al.
developed negative binomial regression models to predict the expected number of faults in each file of the next release.
despite using information from modification requests mrs release ids abstract category their model is mainly based on the code bugs and the modification histories of the files.
insoftware traceability andconcept feature location research several information retrieval ir approaches have been proposed to trace the relations of high level concepts in code.
the followings and their combined approaches are popular formal concept analysis latent semantic indexing probabilistic topic models and lda name based model and a combination of ir and execution traces .
comparing to ir approaches bugscout is able to learn the correlation of the topics in two different types of documents bug reports and corresponding buggy code.
our approach complements well to bug prediction approaches .
some relies on code churns and code changes .
they focus on code properties and changes rather than on textual information in bug reports as in bugscout.
they can provide excellent a priori information on defect proneness of source files for bugscout.
moser et al.
built machine learners with logistic regression na ve bayes and decision trees with metrics on code changes .
nagappan et al.
s model uses the metrics based on change bursts .
canfora and cerulo store textual descriptions of fixed change requests use them to index the source files for searching from a new change request.
other prediction approaches rely on code and change complexity metrics .
others also show that files depending on buggy modules are likely to be error prone .
bugcache maintains a cache of locations that are likely to have faults.vii.
c onclusions we propose bugscout an automated approach to localize the buggy files given a bug report.
it assumes that the textual contents of a bug report and those of its corresponding source code share some technical aspects of the system.
we develop a specialized topic model that represents the technical aspects in the textual contents of bug reports and source files as topics and correlates bug reports and buggy files via the shared topics.
empirical results show that bugscout is accurate in localizing buggy files and outperforms existing approaches.
we plan to explore convergence measures for gibb sampling as in .