towards automatically generating summary comments for java methods giriprasad sridhara emily hill divya muppaneni lori pollock and k. vijay shanker department of computer and information sciences university of delaware newark de usa gsridhar hill muppanen pollock vijay cis.udel.edu abstract studies have shown that good comments can help programmers quickly understand what a method does aiding pro gram comprehension and software maintenance.
unfortunately few software projects adequately comment the code.
one way to overcome the lack of human written summarycomments and guard against obsolete comments is to au tomatically generate them.
in this paper we present a noveltechnique to automatically generate descriptive summary comments for java methods.
given the signature and body of a method our automatic comment generator identifiesthe content for the summary and generates natural languagetext that summarizes the method s overall actions.
according to programmers who judged our generated comments the summaries are accurate do not miss important content and are reasonably concise.
categories and subject descriptors d. .
distribution maintenance and enhancement documentation general terms algorithms documentation .
introduction software maintenance demands as much as of software engineering resources and much of this time is spent understanding the maintenance task and any related software or documentation .
in spite of numerous stud ies demonstrating the utility of comments for understanding software few software projects adequately document the code to reduce future maintenance costs .
there are a number of ways to overcome insufficient comments.
one approach is to obviate comments by using extremely descriptive identifier names .
unfortunately precise identifiers that accurately describe an entity lead to very this material is based upon work supported by the national science foundation grant no.
ccf and ccf .
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.ase september antwerp belgium.
copyright acm ... .
.long identifier names .
longer names can actually reducecode readability rather than increase it .
another way is to encourage the developer to write comments by automatically prompting the developer to enter them or by using a top down design paradigm and generating comments directly from the specification or by using a documentation first approach to develop ment .
although these solutions can be used to comment newly created systems they are not suitable for existing legacy systems.
an alternative to developer written comments is to automatically generate comments directly from the source code.in addition to providing comments for existing code generated comments encourage developers to comment newly written code .
in recent work buse and weimer au tomatically generate comments about the exceptions thrownby a given java method.
specifically they use symbolic execution to identify under what conditions the exception is thrown and then use a set of templates to generate the tex tual comment for these conditions.
however the templatesthey developed are specific to exception handling and areinadequate for generating comments in general.
we are unaware of any system that is capable of automatically generating comments in general for arbitrary methods.
this paper describes a novel technique to automatically generate descriptive summary comments for java methods.
the system takes a method signature and body as input and outputs a natural language summary comment for themethod.
our key insight into automatic summary commentgeneration is to model the process after natural languagegeneration dividing the problem into subproblems of content selection and text generation .
in our context content selection involves choosing the important or central code statements to be included in the summary comment.
for a selected code statement text generation determines how to express the content in natural language phrases and how tosmooth between the phrases to mitigate redundancy.
comments can be used to communicate a variety of information.
in this work we focus on comments that describe amethod s intent which we call descriptive comments .
specifically we are interested in descriptive comments that sum marize the major algorithmic actions of the method.
similarto how an abstract provides a summary for a natural lan guage document a descriptive summary comment for a method can help programmers quickly understand what a method does aiding program comprehension and softwaremaintenance.
we target leading summary comments occurring before a method in contrast to other places comments may occur.
leading summary comments are not only useful for a developer while modifying code but also useful forskimming a set of methods to decide which methods need tobe examined in more detail.
our automatic summary comment generation involves analysis of source code requiring no execution information and thus can be applied to incorrect incomplete and unexecutable legacy programs.
the comment generation process currently implemented for java requires less than minutesfor kloc.
the main contributions of this paper are an algorithm to automatically extract important codestatements for a method s summary comment a text generation technique that takes a java code statement as input and outputs a natural language phrase which represents the code and a human evaluation of the accuracy content adequacy and conciseness of the automatically generated leadingdescriptive summary comments.
our results show that the generated summary and individ ual phrases are accurate do not miss important summary information and are reasonably concise.
.
problem generating comments automatically users prefer documentation that is at an appropriate level of detail complete and correct .
from this high level goal we derive our problem statement given a method signature and body statements for a method m generate natural language text that summarizes the overall actions of maccurately adequately and concisely.
the most important goal is to generate comments whichare accurate and contain adequate content.
that is a sum mary comment should not miss important information forunderstanding should be specific enough to be practicallyuseful to the developer and not overly general.
a concise comment contains little to no redundancy and has no extraneous information thereby not wasting the developer s valuable reading time.
there are a number of challenges in developing a system to automatically generate comments.
first a system will behindered if the source code does not include at least somemeaningful variable method and type names.
we believethis requirement is reasonable given that developers tendto choose long and descriptive names for highly visible program entities such as methods and types .
assuming the developer used meaningful identifier names the problemof automatically generating descriptive summary commentsfrom the source code has three main challenges method names are inadequate summaries.
in prior work hill et al.
presented a technique capable of generating natural language phrases for arbitrary java method signatures.
one way to generate a comment would be tosimply generate a phrase for the method based on its signa ture.
at first glance this might seem an adequate summary of a method s actions.
for the method compareto object object in the class playlistfile the phrase compare play list file to object is an accurate summary of the method s actions.
unfortunately there are many well named methods for which this summarization technique will fall short.when using the method signature to summarize a method s actions we are making the assumption that the method s name accurately captures the method s main action.
in compareto the method name contains the main action compare .
however some methods are not named based on theaction being executed but under what conditions the action takes place.
for example consider the methods mousepressed actionperformed and aftersave .
we call these methods reactive since their names are based on the events the methods are reacting to rather than the actions being per formed.
reactive naming is very common for methods con forming to an api or overriding existing methods.
because it is impossible to rely solely on a method s name for an accurate summary comment a general purpose comment generation technique must use information from themethod s body.
that leads us to our next two challenges not all method body statements belong in a summary.
another way to generate a leading descriptive comment would be to simply generate a phrase for every statement in the method.
however such a comment would cease to provide a summary of the method s actions and instead uselessly repeat the entire method body.
for a comment to qualify as a summary it must contain less information and be faster and easier to read than the method s sourcecode.
although every statement in a method is necessary forproper execution just a few statements may be importantfor the summary.
consider the method processsource in the popular opensource project rhino which contains statements.
inaddition to the main actions which read each input file compile the file and write the results to an output file the other statements in the method handle exceptions resource cleanup and object creation.
although all statements arenecessary for execution just are needed for the summary.thus one of the major challenges in summary comment gen eration is to precisely identify these necessary statements.
using names in the summary loses contextual information from the source code.
assuming we can automatically select the important statements containing content that should be included in the summary the next chal lenge is how to present that content.
the simplest approach would be to generate a phrase based only on the statement.
for example consider the statement print current from which one could generate the phrase print current .the problem with this approach is that the name of thevariable current alone is insufficient we are left with no concept of what is being printed.
the missing contextual in formation is current s type which is document .
however for any given statement there may be a wealth of contex tual information the types of variables the return type or declaring classes of methods or the names and types of the formal and actual parameters and including all of thiscontextual information would lead to a verbose or redundant comment.
thus when generating a summary from a method s body statements we must carefully select additional contextual information for the summary that the developer would have had when reading the code directly.
.
automatic summary generation there are three main components to our approach to automatically generating leading summary comments selecting the content or sunits to be included in the sum44figure the summary comment generation process mary comment lexicalizing and generating the natural language text to express the content and combining andsmoothing the generated text.
our design is driven by ourgoals to accurately represent the method s main actions to include precise contextual information needed for understanding and to be concise and avoid unnecessary words.
figure illustrates our summary comment generation process.
the input to the generator is a set of structural and linguistic program representations for a method.
we use information from programming semantics naming conventions and linguistic knowledge gained from observations ofthousands of java programs.
in this section we describeour approach to preprocess the source code convert code statements into a meaningful semantic representation select content and generate text for a summary comment.
.
preprocessing before any names can be analyzed for text generation identifiers must be split into component words.
we use camel case splitting which splits words based on capitalletters underscores and numbers e.g.
xyline3drenderer would be split into xy lin e d renderer .
we will adopt more advanced splitting techniques after they are refined .
abbreviations in variable and type names can reduce the readability of generated comments and accuracy of our analysis e.g.
button butselectall mouseevent evt .
we use techniques from prior work to automatically identify andexpand abbreviations in code before generating text.
during summary content selection we use information from the control flow graph data and control dependences along with textual clues which we obtain from the software word usage model swum of the program.
.
software word usage model swum automatically generating comments requires the ability to identify linguistic elements of an arbitrary method.
specifically it is critical to identify the action theme and any secondary arguments for a given method.
consider the example method signature list.add item i which can be captured by the phrase add item to list.
in this example the action is add the theme is item and the secondary argument is to list .
the action theme and optional secondary arguments can be used to generate intelligible text for thesummary and in conjunction with program structure canbe used to select what content to summarize.
to capture the action theme and secondary arguments for a given method along with its program structure we usea novel software word usage model swum .
based on the prior work of hill et al.
we are developing swumto capture the conceptual knowledge of the programmer as expressed in both linguistic information and programminglanguage structure and semantics .
thus swum not only captures the occurrences of words in code but also their linguistic and structural relationships.
although a formal definition of swum and its construction is outside the scope of this work we can provide someintuition behind swum s extraction rules which are used to construct the model.
based on common java naming conventions we assume that most method namesstart with a verb.
swum assigns this verb as the actionand looks for the theme in the rest of the name the formal parameters and then the class.
however some methods do not begin with a verb such as str.length and obj.tostring .
in these situations swum infers an action for the method such as get or convert respectively.
in general the po sition of a word within a name e.g.
beginning end or its structural location e.g.
formal name formal type class provide clues as to the word s semantics.
for example theaction in the method void saveimage is save whereas in image savedimage the action is get and in void imagesaved the action is handling or reacting to the event of the image being saved.
for content selection we exploit the structural relationships based on the linguistic information of the theme and secondary arguments.
for text generation we use the semantics captured by action theme relationships in conjunction with the actual words to generate intelligible phrasesthat accurately represent the code.
.
s unit selection we focus on the content that would be in the first few sentences of a descriptive summary comment which provides the reader with the overall gist of a method s actions.
ourprimary goal in s unit selection is to choose the important or central lines of code to be included in the summary.
because a java statement can span multiple lines we define an sunitto select individual lines.
an suniti saj a v a statement except when the statement is a control flow statement then the s unit is the control flow expression with one of the if while for orswitch keywords.
our heuristics for selecting s units for a summary comment are based on a wealth of observations.
specifically we have identified characteristics similar to beacons for summary comments where a beacon is a surface feature whichfacilitates comprehension.
we have studied comments from popular open source java programs investigated the summary needs of methods with a variety of structural characteristics and surveyed experienced java programmers as to which statements they personally felt were necessary forsummary comments.
we analyzed this information and clas sified statements by their importance to a summary comment.
we then looked for patterns of characteristics such as location within the method body data and control depen45dences relation to other statements in the summary and role in programming.
.
.
identifying major s unit candidates program comprehension studies have shown that each line does not make an equal contribution to comprehension for expert programmers .
this section describes a set of characteristics or clues that suggest when an s unit is a good candidate for a method s summary comment.
ending s units.
an ending s unit lies at the control exit of a method.
to identify the ending s units of a method m we build a single entry single exit control flow graph cfg for m w i t ha l l return nodes leading to the exit.a n ending s unit is a predecessor of the cfg s exitnode.
in the voidreturn example below the s unit on line is an ending s unit.
note that the reactive method name returnpressed does not provide a summary of the method s actions and hence we need to use additional heuristics to select s units for the summary.
void returnpressed shel l s getshell string input s.getenteredtext history.addelement input string result evaluate input s.append result we observed that methods often perform a set of actions to accomplish a final action which is the main purpose of themethod.
this observation across many methods led to theselection of ending s units for the summary.
void return s units.
an sunit which has a method call that does not return a value or whose return value is not assigned to a variable is a void return s unit.i n returnpressed l i n e4i sa void return s unit.
we have observed that method calls that do not return a value often supply useful content for a summary.
the intuition is that when a method call does not return a value it must be invoked purely forside effects.
in contrast method calls returning a value will likely serve as facilitators to a major action by their returnvalue being used to build toward the main action.
we use a method s ast to identify void return s units.
same action s units.
in a method m i fa ns unit has a method call csuch that mand chave the same action then the s unit is called a same action sunit.
on line below consider the compilere method call which is neither anending sunit nor a void return sunit.
scriptable compile object args string s scriptruntime.tostring args string glob scriptruntime.tostring args re recompiled compilere s glob false lastindex return this intuitively the call on line is very important towards achieving the intended functionality of compile .
thus in a summary of a method m we include the same action s units.
we use swum to identify such same action s units.
in the compile method the call on line compilere has the same action as the method compile .
data facilitating s units.
data facilitating s units assign data to variables used in s units identified by the previous three heuristics.
for example consider the s units.append result on line in returnpressed .
although this sunit is selected by the ending s unit heuristic little information is known about the theme variable result.t h u s we select its data facilitator on line string result evaluate input .
although an s unit may contain many variables because our text generation technique only uses variables that represent the theme or secondary arguments in a method call we only identify data facilitating s units for these variables.
for s units without a method call we currently find data facilitators for all variables used.
we use swum to identify the variables corresponding to the themeand secondary argument and then we find data facilitatings units for these variables using the def use chains for the method.
we go back one level from the usealong the def use chain.
controlling s units.
a controlling s unit i.e.
an s unit with one of the if while for orswitch keywords controls the execution of an s unit previously selected by one of the earlier heuristics.
for example consider the method actionperformed below.
line contains an ending sunit that is control dependent on line making line a controlling sunit.
void actionperformed actionevent e string cmd e.getactioncommand if cmd !
null if cmd.equals interrupt exportfile.delete the summary content would be inadequate without the controlling s unit.
contrast the following two plausible summaries for this method delete export file and if command equals interrupt delete export file.
the latter summary conveys more information specifically about when the major action occurs.
once a controlling s unit is included in a summary we recursively include its controlling s unit if any so the reader is given the conditions under which a major action is performed.
.
.
filtering out ubiquitous operations some operations are less specific to a method s computational intent than to the overall program behavior.
such sunits would add unnecessary information to a summary comment.
for instance exception handling statements are typically not needed for a summary.
similarly programmers would not expect information describing a method s resourcecleanup operations logging or other diagnostic operations in a method s summary comment.
the exception to this rule is when a method s sole intent is exception handling resource cleanup or logging.
we identify such s units by using the ast and checking if an s unit is within the catch or finally block of a method.
we also check the action and theme identified by swum for the words log error debug trace exception or close .
similarly a code pattern of the formif x null with only a return null statement in its body represents an exception handling block that is typically used to check for null input parameters.
some ending s units can also be omitted from a summary.
many methods return a boolean value to indicate success or failure.
for example a method named savedata might return false if it fails to save the data.
we believe these failure paths to be unnecessary and thus do not add return falsesunits in such methods to the summary.
46in addition certain void return and data facilitating sunits can be elided from a summary.
specifically get set and object creation operations are ubiquitous in an object oriented system and do not provide important distinguishing information for a method summary s actions.
hence we exclude sunits in which a get set object creation method is the outermost call.
the exception is when the computational intent of a method is to get set a value or create an object.
similarly a statement that initializes a variable to a value 0or nullis too trivial to include in a summary comment.
also not all controlling s units are needed for a summary.
anifexpression of the form if x !
null without an accompanying elseis often used to guard against null pointer exceptions.
these sanity checks are not important enoughfor a concise summary comment.
.
.
s unit selection process we have a three phase process to select the summary sunits for a method m. in the first phase we identify the same action ending and void return sunits and add them to the summary set .
for each s unit in the summary set we add its data facilitating sunits to the summary set.
we then augment the summary set with any controlling s units.
in each phase we apply the filter to exclude ubiquitous operations along with s unit identification.
finally the summary setis sorted in ascending order based on the line number within the method.
in the previously shown returnpressed example the s units on lines and are selected in the first phase.
the s unit on line is added during the second phase.
no s units are added during the third phase.
.
text generation after identifying the set of s units for the content of the summary comment the next challenge is to convert each sunit into a natural language phrase that can be understood independent of the s unit s context within the method body.
given f.getcontentpane .add view.getcomponent center we generate add component of drawing view to content pane of frame the text generator first constructs subphrases for the arguments in an s unit and then concatenates subphrases for the entire s unit.
in generating phrases for the arguments e.g.
component of view to pane of frame our system strives to produce more descriptive phrases than containedwithin individual s units.
for instance in the above example we generate drawing view rather than view .
this addition of the modifier drawing to produce the more specific drawing view is accomplished via variable lexicalization .
note that we did not include the parameter center in the generated text as it does not correspond to the theme or secondary argument ofadd.
we do not claim that center is an unimportant parameter of add but it is not necessary to include in a summary.
although the example shown has method calls with associated verbs the generated text includes only one verb.
the text generator combines phrases when possible and removes words that are not needed for the summary.
forexample we dropped the get in the generated text for getcontentpane and getcomponent .
although not shown in our example s units that are conditional or loop expressions also have templates for generation.the basic s unit is one with a single method call.
the text generation strategy for a single method call is then used innested method calls composed method calls assignments returns conditional and loop expressions .
before describing our approach to generate text for these s units we first describe how we lexicalize the variables used in those s units.
lexicalization of variables.
one challenge in text generation is to construct noun phrases that represent variables.
in english noun phrases more specific noun modifiers ap pear on the left.
since a variable s type name typically pro vides general information about the variable while the nameprovides specific information when converting a variable into an english noun phrase we generally place the variable name to the left of the type name.
for example considerthe variables document current and callframe parentframe which would be lexicalized as current document and parent call frame respectively.
notice that the phrase for the latter example does not repeat the word frame .
however when the type name is an adjective e.g.
selectable item we place the variable name to the right selectable item .
single method call.
consider a method call m ... .i n java a method implements an operation and typically begins with a verb phrase .
thus we generate a verb phrase form.
the template for the verb phrase is action theme secondary argsand get return type where action theme and secondary arguments ofmare identified by swum and correspond to the verb noun phraseand prepositional phrases of the verb phrase.
example s unit os.print msg we generate print message to output stream text generation can be improved by identifying theme equivalences which occur when the theme in a method name overlaps some of its parameters.
consider the call removewall oldwall for which we can generate the phrases remove wall remove wall given old wall remove old wall .
the last phrase is the most concise and descriptive.
wegenerate this phrase by determining theme equivalence between the theme wall in the method name and parameter name.
however not all overlap leads to theme equivalence.consider the call additem itemurl which adds an item after retrieving the item from its url.
although the theme item overlaps the parameter item url these phrases do not have equivalent meanings.
thus when the overlap onlybegins the lexicalized parameter name and does not occur at the end we distinctly incorporate both the theme from the method name as well as the lexicalized parameter name.
table shows some examples of theme equivalence.
method signature and call generated text sig removewall wall w remove old wall call removewall oldwall sig addimage thumbimage ti add new thumb call addimage newthumbimg image sig additem item itemurl add item given item call additem itemurl url table theme equivalence for text generation 47return.
areturn sunit is a pseudo method call where the action is return and the theme is the method s return type .
nested and composed method calls.
an sunit may contain nested calls like m m1 ... ... or composed calls such as m .m2 .
.. .
when swum detects that theme return type the template for text generation in general is action 1theme 1secondary args and get return type action 2theme 2secondary args and get return type example s unit print sendrequest we generate send request and get response print response when theme return type we can drop the second phrase from our general template and get return type without losing information.
example s unit menu.add makemenuitem we generate make menu item add menu item to menu when theme return type 1and action get we drop the first two phrases from our general template without loss of information.
we use the theme and secondary arguments of m 1as the theme of m .
the add component of drawing view .. .
example at the beginning of this section illustratesthis case.
the same example also illustrates composition along with combination of nesting and composition.
assignment.
consider the general form of an assignment s unit l h s m .
.
.
.
the general template is action theme secondary args and get return type assign to lhs since assignment involves assigning the return type to the lhs we can avoid redundancy by combining the second and third phrases in our template as get lhs .
example s unit filename showfiledialog .
.
.
we generate show file dialog and get file name when lhs overlaps the theme we generate a more concise phrase by dropping the redundant get lhs and use either thelhsortheme in the text whichever is more specific.
example s unit boldfont derivefont we generate derive bold font we are still developing templates for assignments where the right hand side is not a method call or variable but aninfix expression e.g.
value y x width .
conditional expressions.
for an ifs unit we generate text for the boolean expression of the ifwhich controls execution of another identified s unit.
when an ifexpression is composed of multiple boolean expressions combined viaoperators we generate text for the individual expressionsand combine them.
in contrast to method calls which are typically realized as verb phrases boolean expressions are realized as sentences since sentences can convey a true or false value.
we devel oped swum rules for methods returning a boolean value and boolean fields to obtain the subject of a sentence.
when the expression is a boolean variable we simply use the variable name in the generated text.
in the case when the variable is a field and an adjective swum provides theclass name as the noun example s unit if visible we generate if window is visible when the boolean expression is a method call we identify the subject and place the verb after the subject as in an english sentence.
when the method name begins with a third person singular verb e.g.
equals we identify the subjectas the receiving object of the method call first parameter in case of static methods .
example s unit if amb.getstyles .contains t.getstyle we generate if styles of ambience contains style of track when the method call begins with an auxiliary verb e.g.
is the subject is in the method name or is a receiver object or parameter of the method call.
example s unit if abstractdoc.hasonlyspaces prefix we generate if prefix has only spaces when the call begins with a base verb the return value indicates success or failure of the operation.
thus we transformthe verb phrase into a propositional sentence by appending succeeds to the end of the phrase.
example s unit if saveauctions we generate if save auctions succeeds when the expression involves a comparison of two operands using an equality or a relational operator the operator provides the verb while the arguments of the verb are given by the phrases for the operands.
loop expressions.
for while sunits in general text for the boolean loop expression is generated like an ifsunit.
however while loops frequently iterate over a collection using the well known iterator pattern iterator it homefolder.iterator while it.hasnext file f file it.next ... although we can generate while iterator has next for the selected s unit on line we recognize the iterator pattern and generate the phrase for each file in home folder by using information from lines and .
we identify iterators by checking if the method call in the loop condition expression has a receiver object with a type name that contains either iterator or enumeration .
weuse the template for each itemincollection .
to get item we use def use chains and look for a use of the iterator as the receiver object of a call that returns a value within the body of the loop.
this return value is used as the item.t o get collection we again use def use chains to look for the 48receiver object of a method call that provides a definition for the iterator.
another frequently occurring loop expression iterates with an index value to access all elements of a collection for int i i tree.getfunctioncount i functionnode fn tree.getfunctionnode i ... rather than generating for i function count of tree for the s unit on line we produce for each function node in tree by using information from lines and .
as with iterators we use def use chains and linguistic clues theme contains count length or size in the call on line to identify the itemand collection for the generation template.
prototype implementation.
our prototype gensumm is implemented as an eclipse plug in.
it implements the sunit selection process and the text generation templates.
gensumm utilizes swum also an eclipse plug in.
.
ev aluation our primary goal for this first automatic summary comment generator is to generate comments that are highly accurate tolerating some unnecessary information in the summary and allowing some content to be missed as long as the missing information does not hinder understanding themethod.
to examine how well we attain these goals we de signed a study to examine the following research questions accuracy how accurately does our generated text represent the code s actions?
content adequacy and conciseness how effectively can we automatically identify the s units for the summary?
with no existing automatic comment generators for comparison we asked humans to judge the generated comments targeted at evaluating accuracy content adequacy and con ciseness.
the study included graduate students and post docs in computer science with advanced to intermediate javaprogramming experience.
six have experience in the software development industry.
table presents the multiple choice questions that we asked the human evaluators and the possible answers.
to account for variation in human opinion we obtained and analyzed three separate judgements for each generated text.
although the measures of conciseness and content adequacy appear similar to precision and recall respectively they are difficult to measure for this study.
measuring precision and recall requires mapping the evaluators summaries to exact s units and the summaries may seamlessly merge information across different s units.
we selected the methods in our study from four opensource programs that span different domains megamek an unofficial online version of the classic battletech board game with methods and kloc sweethome3d an interior design application with methods and 73kloc jhotdraw a java gui framework for technical and structured graphics with methods and kloc and jajuk an application that organizes and plays music with methods and kloc.
since a summary comment consists of text generated for selected individual s units we first evaluate text generated for individual s units and then for whole summaries.
we did not evaluate s unit selection in isolation from commentgeneration because we have found it very difficult for humans to judge s unit selection independent of the generated text and to map their summaries back to specific s units.
.
evaluating s unit text generation procedure.
our goal was to gain feedback on text generation templates for as many of the different types of s units as possible without demanding a lot of time from our human subjects.
thus we randomly selected s units such that each newly selected method covered a new s unit type until we selected a total of s units.
each of human evaluators examined a total of s units from two of the four programs leaving us with judgements of s unit text.
we provided each evaluator with the body of the method in which each s unit occurred and the entire program source.
we instructed the subjects to read and understand what themethod does and then write their own summarizing text for the s unit.
since a summarizing text for an s unit is very subjective we did not want to bias the evaluators anddeliberately did not provide exact instructions on what text to write.
once the subjects wrote text for an s unit they examined the text automatically generated by our system and answered the three questions similar to those in table .
results and discussion.
figure reports the majority opinions where evaluators agreed and the number of individual responses in each category of responses for accuracy content adequacy and conciseness of sunit phrases.
the overall results are quite positive and suggest that in general we have met our stated goals of generating accuratetext including all the information relevant to understanding the method and avoiding unnecessary text.
accuracy .of the accuracy judgements over all s units rated the generated comment accurate with only judgement giving a rating of very inaccurate .
furthermore no generated comments were ranked very inaccurate by majority opinion and in fact when majority opinion is taken into account only out of generated comments were ranked as even slightly inaccurate .
we analyzed the few comments judged as slightly to very inaccurate based on thetext written by the evaluator.
two cases require swum to more precisely identify the action and theme one requires domain knowledge and in the final case the generated textwas so specific that it created the illusion of inaccuracy.
forthe s unit parent.addchild createpolyline we generated create polyline and get xml element.
add child given child xml element to parent xml element .
evaluators who did not consider the return type of createpolyline said the generated text was slightly inaccurate.
response category s rresponse category s rresponse category s r accurate adequate concise slightly inaccurate 16misses some 728slightly verbose very inaccurate 1misses important 6very verbose 1accuracy content adequacy conciseness figure human judgements of individual phrases.
s majority opinion s units .
r responses.
49criteria question answer choices accuracyindependent of content adequacy and conciseness do you think that the comment is accurate a little inaccurate very inaccurate content adequacylooking at only the content of the generated comment and not the actual text or the way thetext is presented do you think that the comment is missing some very important information that can hinder the understanding of the method is missing some information but the missing information is not necessary to understand the method is not missing any information concisenesslooking at only the content of the generated comment and not the actual text or the way the text is presented do you think that the summary has a lot of unnecessary information has some unnecessary information has no unnecessary information table questions and answer choices designed to elicit human judgements.
content adequacy .for of judgements the comments were not missing any important information for understanding with of those indicating no missing information.
more significantly there were no comments for which there was a majority opinion that important infor mation was missing for understanding.
further of the48 comments had a majority opinion of no missing information.
in the comments where a majority said there was some information missing but not needed for understand ing the missing information was due primarily to how wegenerated text for nested method calls and loop conditions.
evaluators wanted more information about parameters beyond the theme and secondary arguments particularly liter als and constants in the nested method calls.
for the loops the evaluators wanted more information from the loop bodyand the collection on which the loop iterates.
conciseness .there was no s unit where a majority of evaluators said the comment had too much unnecessary information.
instead of the comments were ranked by majorityopinion as having no unnecessary information with only 2of the comments with the majority of evaluators saying it had some unnecessary information.
when we examined the comments where there were individual judgements of slightly verbose we found that we could further avoidredundant information in assignments and nested calls by recognizing additional opportunities for simplification.
.
evaluating whole summary comments procedure.
judging a summary comment adequately to carefully answer our questions takes considerable time because the humans need to read and understand each method sbody.
thus we provided six of our human evaluators with four methods each one from each of the four programs.
a total of eight summary comments two per program werejudged independently by human evaluators.
to controlfor learning effects the humans did not see the methods in the same order.
to select methods for evaluation we first eliminated methods with characteristics that make them quickly understandable without a summary comment or contain features thatwe do not yet attempt to address such as methods with a switch statement where each case has a similar action.
thus for this study we chose methods that have between to s units about of the methods in our subject programs had s units .
we did not select constructors or methods beginning with getorsetsince the method name itself can serve as a summary comment.
from the remainingresponse category m rresponse category m rresponse category m r accurate adequate concise slightly inaccurate 6misses some 26slightly verbose very inaccurate 0misses important 27very verbose 5accuracy content adequacy conciseness figure human judgements of method summaries.
m majority opinion methods .
r responses.
methods we randomly selected two methods from each of the four programs.
as with the previous evaluation we asked the evaluators to read understand and write their own summary of each of the four methods assigned to them.
to avoid biasing the evaluators we did not give an explicit definition of a sum mary but only mentioned that the goal of a summary is toprovide a gist of what the method does.
once the evaluators wrote a summary they examined the summary generated by our system and answered the questions in table .
results and discussion.
figure reports the majority opinions and the number of individual responses in each category for accuracy content adequacy and conciseness .i n general we believe the results are positive especially when considering that our stated goal is to generate accurate summary text while tolerating slight verbosity and missing someinformation as long as it does not hinder understanding ofthe method.
figure shows an example generated summary evaluators summaries and the existing summary written by thedeveloper for the method exporttosvg .
observe that the method name does not suffice as a summary.
the majorityopinion about the generated summary was accurate adequate and concise .
we believe that the similarity of the generated summary with three of the four human written summaries attests to the accuracy of our text generation italso testifies to the success of our s unit selection strategy in selecting only the one relevant s unit among s units.
accuracy .of the methods had accurate summaries according to the majority of evaluators per method.
not one among the individual responses suggested that we generated very inaccurate text.
only in of the methods did a majority believe the summary text was a little inaccurate.
further analysis of the evaluators summaries 50writer summar y comments developer exports the plan objects to a given svg file our system export plan component to svg evaluator export plan component to svg file evaluator sets up plan component and calls exporttosvg on it evaluator get the actual planview.
if planview is an instance of plan component planview is copied to plan component.
else plancomponent is a new instance of plan component.
try to get a new instance of bufferedoutputstream associated to the svgfile and attempt to export it to svg using the plancomponent.
if not possible address the potential cases for exceptions 1publicvvoidexporttosvg string svgfile t throws... view planview controller.getplancontroller ... plancomponent plancomponent 4iif planview i instanceofplancomponent plancomponent plancomponent planview eelse plancomponent n newplancomponent this.home ... outputstream outputstream null boolean exportinterrupted false ttry outputstream n newbufferedoutputstream new... plancomponent.exporttosvg outputstream ccatch interruptedioexception ex exportinterrupted true tthrownewinterruptedrecorderexception expor... ccatch ioexception ex tthrownewrecorderexception couldn t export ... ffinally iif outputstream !
null t try outputstream.close delete the file if exporting is... i if exportinterrupted n newfile svgfile .delete c catch ioexception ex t thrownewrecorderexception couldn t... ... figure contrasting generated summary with the developer s and evaluators summaries.
suggests that for the s unit beginedit textholder we generated begin edit whereas the evaluators wrote edit text holder.
more precise theme and action identification wouldaddress this problem.
content adequacy .
of the summaries were judged to not have missed important information by the majority.
in fact of the individual responses suggest that the generated summaries did not miss important information.
inthe two methods where a majority felt that some important information was missing we failed to identify important s units for three reasons.
we missed an s unit because we do not use semantic similarity word relations between a method s action and a callee s action.
automatically detecting such semantic similarity in programs is not a trivial task .
we missed an s unit because we do not include the data facilitating s units for method parameters that are not a theme or secondary argument.
another s unit was missed because the negation operator !
was used to implement the concept of flipping .
conciseness .there was only methods for which a majority of the evaluators felt that the generated summary was very verbose.
of the individual responses suggest thatthe generated summary was concise.
in the only method where a majority said that the generated summary was very verbose the void return and same action s unit selectionrules were applied once too often.
in the methods where the summaries were slightly verbose we included too manyifblocks for special cases and error handling return paths.
.
threats to validity considering our stated problem is the lack of developer written comments we unsurprisingly found few comments in application code with which to compare our automati cally generated comments.
our results may not generalizeto other java programs or other languages.
to mitigate this threat we chose four large open source programs across different domains representative of typical java programs.
.
summary of results the results of our evaluation suggest that our summary comment generation technique has met its stated goals of accurate text while tolerating some extra and missing rel atively unimportant information.
the summary generation would benefit from improved action and theme identification along with usage of other parameter information.
based on evaluator feedback as seen in the evaluators summaries in figure summary generation should be tailored to the developers experience novice versus expert and their personal preferences.
even among experts thegranularity of required detail varies.
for example eval uators included exception handling logic in their summary.thus we plan to allow the developer to control the amount of detail in a summary.
.
related work there has been some limited work on comment generation.
semi automated approaches either automatically determine uncommented code segments and prompt developers to enter comments or automatically generate com ments from high level abstractions which the programmer provides during development .
although useful for newly created systems none of the semi automatic techniques apply to existing legacy systems.
in contrast we are aware ofsome techniques that could be used towards generating com ments for legacy code .
however these approaches are limited to inferring documentation for exceptions and generating api function cross