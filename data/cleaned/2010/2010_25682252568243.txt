reviser efficiently updating ide ifds based data flow analyses in response to incremental program changes steven arzt1and eric bodden1 secure software engineering group european center for security and privacy by design ec spride 1technische universit t darmstadt 2fraunhofer sit darmstadt germany firstname.lastname ec spride.de abstract most application code evolves incrementally and especially so when being maintained after the applications have been deployed.
yet most dataow analyses do not take advantage of this fact.
instead they require clients to recompute the entire analysis even if little code has changed a time consuming undertaking especially with large libraries or when running static analyses often e.g.
on a continuous integration server.
in this work we present reviser a novel approach for automatically and e ciently updating inter procedural dataow analysis results in response to incremental program changes.
reviser follows a clear and propagate philosophy aiming at clearing and recomputing analysis information only where required thereby greatly reducing the required computational e ort.
the reviser algorithm is formulated as an extension to the ide framework for inter procedural finite distributed environment problems and automatically updates arbitrary ide based analyses.
we have implemented reviser as an open source extension to the heros ifds ide solver and the soot program analysis framework.
an evaluation of reviser on various client analyses and target programs shows performance gains of up to in comparison to a full recomputation.
the experiments also show reviser to compute the same results as a full recomputation on all instances tested.
categories and subject descriptors f. .
semantics of programming languages program analysis general terms design languages performance keywords inter procedural static analysis ow sensitive analysis ifds ide incremental analysis permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may june hyderabad india copyright acm ... .
.
introduction within minutes to hours static dataow analysis can often produce results that would take weeks or even months to derive through manual code inspection.
code analyses are used for a variety of tasks including program understanding compiler optimization and security analysis.
on the downside though highly precise static analyses on large code bases are often still quite expensive to compute.
as others have argued before a large margin of this ine ciency is due to the fact that current dataow analyses lack a way to respond to incremental program changes.
once an expensive analysis run of some program phas completed whenever pchanges the analysis will typically need to be re computed entirely once again a costly undertaking.
this is especially problematic with large libraries that change rarely but contribute much to the overall size of the program.
in this work we present reviser an approach for automatically and e ciently updating static analysis results for a broad class of inter procedural ow sensitive contextsensitive dataow analyses.
reviser assumes that analyses are implemented in sagiv reps and horwitz s framework for inter procedural distributive environment transformers ide or within the ifds framework for interprocedural finite distributive subset problems an often used specialization of ide.
both frameworks require that ow functions are distributive over the merge operator.
although this is a limitation in some cases ifds and ide have been used for a large variety of practical analysis problems such as secure information ow typestate alias sets speci cation inference and shape analysis .
the ifds ide frameworks allow dataow analyses to be expressed in a template driven style.
this means that users simply de ne a set of ow functions.
a generic ide solver then uses those ow functions to compute analysis results for the entire program.
reviser replaces the standard ide solver with a solver that automatically copes with incremental program changes at the same time allowing users to reuse the original ow functions with only minor modi cations and without restricting the expressiveness of the ide framework.
reviser works by rst applying the usual ide algorithm once to the application s entire code base.
then on receiving a modi ed version of the code it determines the changes in terms of the application s control ow graph.
afterwards reviser invokes a specialized revision algorithm that updates analysis results only where necessary.
this algorithm is the core contribution of this paper.permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may june hyderabad india copyright acm ... .
id s s s fag s ifa2s s fbg else s fbg a a b b a a b b a a b b figure function representation in ifds reproduced from a tool such as reviser is useful if it produces correct and precise results saves analysis time and does not impose too large a burden on the static analysis programmer.
we have thus evaluated reviser on a number of client analyses and target programs including revision histories of junit as well as the abc and soot frameworks showing that reviser produces the same results as a full recomputation can save up to of the time required for a full recomputation.
at the same time client analyses only require simple changes to be made compatible with reviser .
to summarize this paper presents the following original contributions an algorithm for e ciently updating ide results based on a structural comparison of two program versions an open source implementation of the approach and a set of experiments showing that the implementation computes correct and precise results and saves on average about of analysis time in comparison to a full recomputation.
the implementation of reviser is available as an opensource extension to the language independent heros ide solver and the soot program analysis framework for java along with all benchmarks documentation and scripts necessary to reproduce our experimental results http sseblog.ec spride.de tools reviser this paper is accompanied by a technical report containing additional details on reviser that we could not include in this paper due to space restrictions.
the remainder of this paper is structured as follows.
section gives background information about the ifds and ide frameworks.
in section we present the core of this paper reviser s algorithm for incremental recomputation.
section presents important details about the implementation and particularly discusses design decisions and how client analyses need to be adapted for use with reviser .
section presents our experimental results.
we discuss related work in section and conclude in section .
.
background on ifds ide reviser applies to analyses formulated as inter procedural distributive environment transformers.
for such analyses the ide framework de nes a very e cient tabulationbased solution strategy based on computing summary functions for each method.
to achieve e ciency these summaries are only computed once to achieve context sensitivity though they are re applied anew at every calling context.
while many ideas of reviser may apply to updating interprocedural analysis results in general our current formulation ofreviser exploits certain properties of the ide framework that may not easily carry over to a more general setting.ide is a generalization of ifds a solution framework for inter procedural finite distributive subset problems.
since ifds is easier to understand than ide we will present ifds rst and also focus the remaining presentation in this paper on ifds explaining elements important to treating full ide only where necessary.
.
overview of the ifds framework the major idea of the ifds framework is to reduce any program analysis problem formulated in this framework to a pure graph reachability problem.
based on the program s inter procedural controlow graph the ifds algorithm builds a so called exploded super graph .
the exploded graph contains a node for every combination of a statement a node in the original control ow graph and a statically decidable factd2dabout the program.
in an informationow analysis for instance the node s x could denote that variable xholds con dential data at statement s. the domain of factsdmust be nite.
edges between nodes in the exploded supergraph model data ow functions.
figure gives three di erent examples on how simple ow functions can be represented as graph segments in ifds.
the nodes at the top represent facts before the given statement s the nodes at the bottom represent facts after s. at the very left the identity function idmaps each dataow fact before a statement onto itself.
the special fact 0is associated with every node in the exploded supergraph and denotes a tautology a fact that always holds.
as can be seen in the middle ow function this fact can be used to unconditionally generate the dataow fact a by connecting it to the fact becomes unconditionally reachable in the graph.
at the same time kills the dataow fact bby making it no longer reachable.
function at the right side is a typical function modeling dataow through an assignment statement b a. here ahas the same value as before the assignment modeled by the arrow from atoa and bobtains a s value modeled by the arrow from atob.
the previous value associated with bis killed in the process there is no edge from btob.
it is important to note that dataow facts are by no means limited to simple values such as the local variables in our example.
much more sophisticated abstractions exist in which facts can for instance model aliasing through sets of access paths or even the abstract typestate of combinations of multiple objects .
the ifds framework itself however is oblivious to the concrete abstraction being used the abstraction is a free parameter to the framework.
ifds is e cient because its graph based dataow functions can easily be composed to so called path edges .
a path edge always starts at a method s header and ends at some statement within the same method.
the edge summarizes the data ows along all paths from the method s entry to this statement.
path edges that end at one of the method s exit points are called summary edges.
see figure on page for an example.
crucially the ifds solution algorithm computes such summaries only once for each method.
reviser must take care to update these summaries where required.
.
the ide framework as in ifds the ide framework models data ow through edges in an exploded super graph.
in addition to ifds however ide allows for the computation of distributive functions along those edges.
a fact is no longer a simple value but an environment mapping facts d2dto val 289uesvfrom a separate value domain v. the ow functions thus transform environments fd7!vgto other environments fd07!v0g.
in comparison to ifds this widens the class of problems that can be expressed in the framework.
in general ide computes and maintains the following types of functions flow functions are used to compute environment transformers between nodes s d and s0 d0 .
flow functions themselves are never stored they are just used to compute longer functions.
jump functions correspond to path edges in ifds.
they encode summaries of ow functions i.e.
compositions of environment transformers.
they e ectively store the composition of ow functions computed from the method s start point to the current statement n. we write them ashd1 n d 2iwithd1being the transformer at the start point and d2being the transformer at n. after the entire method was processed jump functions are turned into summary functions.
summary functions encode the summarized e ects of a method.
they are jump functions to the exit statements return throw of the respective method.
summaries save the solver from having to recompute a callee s information anew for every call site.
if a statement is changed its ow function may also change.
as a consequence the jump functions of all transitive successors may change as well since they encode information computed involving the changed statement s ow function.
the same holds for the summary functions of the method containing the changed statement.
section describes in detail the revisions that reviser needs to perform to bring jump and summary functions back to a correct state after an incremental program update.
one important di erence between ifds and ide is that the ide algorithm does not just compute graph reachability.
instead it comprises a second phase in which the computed environment transformers are actually applied along all edges in the graph to yield individual values for every program statement.
reviser incrementally updates both phases of the ide algorithm.
.
incremental updates reviser assumes a scenario in which the user rst triggers a complete analysis computation within the ifds ide framework and then submits an incremental program update for instance by committing a new version of the code to a version control system or by triggering an incremental build in the user s integrated development environment.
reviser rst compares both code versions generating a structural di .
this di gives information about which nodes and edges in the program s inter procedural controlow graph icfg were added or removed.
in the following we will call all nodes that were added or removed changed nodes.
one of the guiding principles ofreviser is to infer from all changed nodes the set of so called a ected nodes i.e nodes whose information was outdated by the change and needs to be updated.
reviser treats as a ected all nodes reachable from changed nodes when following edges in the novel updated icfg.
this is an over approximation.
reviser then follows a clear andpropagate strategy for each a ected node it rst clears theanalysis information computed and then re propagates the information from all the node s predecessors.
note that by this design it is always safe to over approximate the set of a ected nodes.
assuming some un a ected nodes as a ected will lead to super uous re computation but it can never lead to incorrect analysis results.
determining the set of a ected nodes precisely can sometimes be more time consuming than re computing additional analysis information.
for this reason reviser does not necessarily seek to determine a maximally precise set of a ected nodes but rather an e ciently computable approximation that is good enough in practice.
as our experiments show the set of a ected nodes is usually just a small fraction of all icfg nodes yielding a high potential for approaches such as reviser .
the remainder of this section explains reviser sclear andpropagate algorithm in detail.
section .
focuses on how to identify a ected nodes.
section .
then introduces the notion ofsafe and start nodes and explains how re propagations are triggered.
section .
discusses how reviser handles method calls.
section .
explains how to incrementally update the actual result values that ide opposed to ifds computes for each statement while section .
presents some important optimizations.
.
computing changesets we assume a structural di erencing algorithm which models all code alterations through added and deleted statements represented by added and deleted nodes and edges in the inter procedural controlow graph.
in particular modied statements are represented through combinations of added and deleted statements.
our technical report provides details about two di erencing algorithms that we implemented and evaluated together with reviser .
s1s2s3 given the structural di one can express the di erences between two program versions using two sets e ande containing all edges added respectively removed from the original icfg.
in the example shown to the right the original edges s1!s2ands2!s3 are removed and a new edge s1!s3is added.
for simplicity we also de ne the sets n for the added nodes in the example and n for the removed nodes fs2gin the example .
reviser uses this program change information to nd a ected nodes.
in general reviser considers as a ected all nodes that are transitively reachable from changed nodes via the new icfg s successor relation.
reviser does implement some optimizations however to further restrict this set.
we will discuss those optimizations in section .
.
note that while reviser itself is language independent the icfg is always language speci c. for our instantiation for java reviser adds all nodes of added methods and removes all nodes of removed methods along with the respective call edges.
for modi ed methods reviser uses a lightweight graph di erencing algorithm which computes a superset of the added and deleted controlow graph edges.
for performance reasons reviser approximates the computed superset and is thus not always maximally precise.
as our experiments show however the computed sets are typically small enough to yield a short re analysis time.
algorithm presents reviser s update algorithm as an initialization phase followed by two outer loops phases a and b and a value computation phase that is required for290algorithm incremental ide initialization outer loop procedure incrementalanalysis cold cnew get the edges we must update he e n n i computecfgchanges cold cnew purge the edges e e n n m n2n e e n n m n2n e callers of modi ed methods see sec.
.
delete all facts for all deleted statements for alln2n d1 d22d v2vdo pathedge pathedgenhd1 n d 2i val valnhn d1 vi endsum ife e then return changednodes chgendsums worklist allchangedns oldes endsummaries phase a update jump functions for allhn1 n2i2 e e e do ifispartofloop n1 then ls getloopstart n1 n getpredsof ls else n fn1g for alln2n d d2 d1 n d 2pathedge do worklist worklist fhd1 n d 2ig forwardtabulateslrps update cnew return node or end summary changed?
if9ep2eproc d2 ep2 n n 9d12d sp2sproc d2 oldes endsummaries then for allc2callsite proc d2 d2succs c do e e hc di allchangedns allchangedns changednodes changednodes phase b recompute information at merge points for alln2allchangedns do check for merge point both straight line and interprocedural preds fm m!n2cnewg ifjpredsj 2then for allm2preds do for alld1 d2 d1 m d 2pathedge do worklist worklist fhd1 m d 2ig forwardtabulateslrps compute cfg incremental phase ii from for alln12allchangedns do for allni 9n1 n i2n 8i ni!ni 12cfgdo for alld2d val n d do val n d for alln12allchangedns do run original phase ii for n d see ide problems only not for ifds .
phases phases a and b call the function forwardtabulateslrps which is described in algorithm .
but let us consider the initialization phase rst.
the computation of change sets is shown in line .
here the algorithm populates the four sets e e n and n using the di erencing algorithm.
it then purges e and e removing edges starting at changed nodes.
since the remaining algorithm will consider such edges automatically this avoids super uous re computations.
line clears the outdated analysis information i.e.
path edges at deleted nodes.
for e ciency reviser clears the outdated analysis information for all other a ected nodes on1void test a while a a a print a listing safe and non safe nodes the y. section .
will give further details.
next we discuss howreviser initializes its repropagation in phase a. .
safe repropagations after deleting outdated analysis information at a changed nodec reviser must compute the updated analysis information.
computing this updated information is easy assuming thatc s predecessor nodes are una ected i.e.
their ide results are unchanged.
we call such predecessors safe.
it is important to note that not all statements unchanged by the incremental code update are automatically safe.
listing gives an example.
assume that the incremental update removes line in order to x the in nite loop.
further assume that the analysis is computing constant propagation.
both lines and are unchanged but while line is safe line is not.
the reason is that it is reachable from line and its abstract value even depends on the one computed at line .
generally problematic are thus recursive dataow dependencies introduced by loops.
to nd nodes guaranteed to be safe reviser thus walks up the control ow graph.
for every changed node it follows the sequence of predecessors until it nds a node which is not itself transitively preceded by any changed nodes.
this node is then necessarily safe.
if the changed node is not part of a loop the candidate for the safe node is always the set of direct predecessor s of the rst changed node in the statement sequence.
if the changed node is part of a loop reviser selects the predecessor of the head of the outermost loop.
then if still at an a ected node reviser walks up the statement sequence until it reaches the predecessor of the rst a ected node and regards that node as a safe node.
this is sound because nodes that are neither changed nor have any a ected predecessors are safe.
in algorithm this is done in lines to for all changed nodes.
note that predecessors of safe nodes are always safe as well if they are not changed nodes on their own.
this directly follows from the de nition of a safe node.
therefore one simple selection of safe nodes would be all of the program s entry points.
this choice will often be sub optimal however as it could cause the unnecessary re computation also at safe nodes.
reviser therefore determines start nodes as follows.
for a given a ected node aand a path ptoa a safe node s on this path is considered a start node if there is no other safe node closer to sonp.
one observation following from this de nition is that if an a ected node has multiple transitive predecessors they all are start nodes.
.
iterative propagation once start nodes are known a trivial approach would be to just pass over the changed program twice one would rst clear all ide results at all a ected nodes the transitive successors of the start nodes as described in section .
and then start a new propagation from each of the start nodes as described in section .
.
for e ciency however 291algorithm incremental ide iterations procedure forwardtabulateslrps mode cfg while worklist6 do pop an edgehsp d1i!hn d2ifrom worklist switchndo casen2callp ifd2 then maybeclearandpropagate hd1 retsite n i continue for alld32passargs hn d2i do propagate hd3 scalledproc n d3i incoming hn d2i for allhep d4i2endsum do for alld52retval hep d4i hn d2i do maybeclearandpropagate hd1 retsite n d5i ifretval hep d4i hn d2i mode update then maybeclearandpropagate hd1 retsite n i casen2ep clear all potentially outdated end summaries ifmode update then ifhsp d1i 2chgendsums then chgendsums chgendsums hsp d1i endsum add new end summary ifd26 then endsum endsum hep d2i optimization no automatic caller update ifmode compute then for allhc d4i2incoming do ifd2 then propagate hd1 retsite c i continue returnvals returnval hep d2i hc d4i for alld52returnvals d3 hsprocof c d3i!hc d4i2pathedge do propagate hd3 retsite n d5i casen2 npncallpnfepg ifd2 then for allm n!m2cnewdo maybeclearandpropagate hd1 m i continue succs fhm d 3i n!m2cfg d32 ow hn d2i g for allhm d 3i2succs do maybeclearandpropagate hd1 m d 3i ifjsuccsj mode update then maybeclearandpropagate hd1 m i algorithm incremental ide clear and propagate procedure maybeclearandpropagate e hd1 n d 2i ifmode update then only clear if we haven t changed this node yet ifn62changednodes then changednodes changednodes fng for alld32d d1 n d 2pathedge do pathedge pathedgen d1 n d ifd26 then propagate e reviser follows a more advanced approach by combining both passes into a single clear and propagate step which we show in algorithm .
when reviser processes a node it rst clears the ide results associated with this node to then compute the new analysis information through a propagation from the node s already re computed predecessors.
reviser commences at the start nodes clearing and repropagating the analysis information for each node reachable ifs2s4s3figure example with controlow branch from there.
after this step all a ected nodes are associated with the correct analysis information for the new version of the target application.
for our example from listing line is the only safe node and thus also the only start node.
by keeping a record of nodes already visited and never clearing a node twice this procedure is guaranteed to reach a xed point in all cases in which the forward propagation as de ned in the original ide algorithm reaches such a xed point.
while e cient this clear and propagate approach requires some precaution if a node can be reached on more than one path reviser must make sure to clear it only once.
the example in figure contains a simple conditional.
assume theif statement to be a start node.
in this case statement s4will be reached along two di erent paths.
without loss of generality assume the propagation via the left branch to occur rst.
reviser would rst clear the information at s4 to then add the information computed along this branch.
afterwards when processing the right branch reviser would clear the information at s4once again thus resulting in nal analysis information for s4 which only contains results from the right branch.
the jump functions previously computed along the left branch would be lost.
to circumvent this problem reviser remembers all nodes for which the analysis information has been cleared already preventing them from being cleared a second time see line .
additionally reviser must make sure to actually start a repropagation on all paths reaching an a ected node n even for paths to nwhich themselves contain no change.
in our example from figure assume a statement in the right branch to be changed and the start node to also reside within the right branch as well.
in this case s4would be cleared and the analysis information computed along the right branch would be added but the one from the left branch would be lost since no propagation is ever performed along this path.
the algorithm therefore performs in a second phase phase b after all clear and propagate cycles have completed a single forward only propagation step for all controlow merge points whose analysis information was updated see line .
in other words reviser starts an arti cial propagation from all non unique predecessors of nodes that have been cleared at some point during phase a. this is correct since after the clear and propagate phase has completed no outdated analysis information is left in the graph.
thus a forward propagation cannot possibly re introduce spurious analysis information.
the iterative steps of the incremental update see algorithm are very similar to those of the original ide algorithm.
generally reviser needs to perform a clear andpropagate step whenever the original algorithm performs a propagate step see for instance line .
for performance reasons however reviser deviates from this rule in the case of method calls see section .
.
finally reviser must make sure to clear the analysis information at a successor node even if no new analysis in 292x password y x foo x y foo a b c b 0xyxababcnotdeletedcontrol flowpath edge jump functionflow functionfigure update to method call arguments formation is to be propagated because otherwise outdated analysis information would be retained.
in such cases reviser needs to clear without having anything to propagate .
reviser thus uses the pseudo value as a marker to denote the obligation to clear lines and .
values are transparently repropagated to transitive successors just like new jump functions would be so that all a ected nodes are actually assured to be cleared lines and .
.
method calls ide is a framework for solving inter procedural analysis problems.
when the ide algorithm processes a call site it uses the so called call ow function to propagate the current analysis information i.e.
jump functions to the start nodes of all possible callees.
it would be sound for reviser to replace this propagate step with a clear and propagate step see line .
this however would in some cases require the analysis to recompute the information for all methods in the analyzed program for instance if the program s main method has changed even if neither those methods code nor their call parameters have changed.
this would severely impair performance.
as described in section .
reviser thus treats call edges separately and for those edges only performs a regular forward propagation without clearing potentially outdated analysis information see line .
in result a method is only entered if it is reached by new analysis information via the call edge.
in case an update to a caller deletes analysis information this approach might lead to situations where jump functions associated with the callee become unreachable as shown in figure .
assume a taint analysis tracking the return value ofpassword .
after the code update removing the second assignment reviser deletes the caller side jump function as indicated but retains the callee side jump function from btoc leaving this jump function unreachable in the super graph.
this has the additional advantage of having the jump function still available should it become reachable again later but at the same time wastes some memory in the meantime.
while our reviser prototype does not clean up this memory an implementation in an industrial setting would probably implement idle time garbage collection to collect unreachable functions at selected times.
in any case such leftovers get disconnected from the graph and thus cannot impair the precision of the analysis.
recall that the result is de ned through the reachable tails of the supergraph.note that reviser recomputes the callgraph from scratch and therefore does not need to deal with changing callee sets during the incremental analysis.
.
value computation in the above we have explained how reviser updates analysis information .
in ide this information actually itself resembles environment transformers i.e.
functions which in a second step are applied to some initial values taken from a pre de ned value domain.
values are computed intra procedurally using jump functions.
a value can thus only become outdated through a change to a jump function or through a change to values at the jump function s start node.
the latter however can only change through a change to a jump function in the caller.
thus the transitive closure of all nodes with changed jump functions safely overapproximates the set of expired values.
reviser deletes all values at these nodes see lines to in algorithm .
afterwards to obtain all updated values reviser starts a regular value propagation task from the start nodes of all changed methods line .
since the new jump functions are complete and correct and since the ide value propagation algorithm which we use without changes is sound the incremental computation is sound as well.
note that there is no risk of repropagating old values since all values not guaranteed to still be valid have been removed.
.
optimizations reviser applies a couple of sound optimizations to the clear and propagate principle.
firstly when the iteration reaches a node that itself serves as a start node for a clearand propagate cycle it can safely abort the propagation.
this can happen when the incremental update comprises changes to multiple parts of the code.
secondly if there are two changes in the same method only the rst one needs to be propagated if the clear and propagate cycles will reach the start node of the second change anyway.
note that the second optimization does not include the rst one in the case of interprocedural loops.
finally when processing return edges reviser does not need to clear and propagate back into the caller if the return site is a start node since in this case this node will trigger a recomputation on its own.
to avoid cluttering the presentation these optimizations are not shown in algorithm .
reviser also implements another less obvious optimization instead of performing clear and propagate steps over return edges reviser stops at the end of each method see line .
after all updates in the current method have completed reviser checks whether either one of the return statements is in the set of changed nodes or whether an end summary entry has been changed see line .
only if this is the case reviser adds the caller to the set of changed nodes arti cial changed edge set e see line and schedules it to be updated.
this is sound since the return edge is computed locally on the return statement and the jump functions reaching it in the callee.
the latter however are equal to the end summaries for that function.
when we say thatreviser issound then we mean that it yields the same analysis information as a full re computation.
in essence the return statement serves as a checkpoint during which reviser checks whether additional propagations are required.
such checkpoint could also be de ned at other statements.
initially we even experimented with293an implementation that would rst compute allanalysis information for an entire statement to then discontinue the propagation if the analysis information obtained that way was found to be equal to the original information at this statement.
we found however that this design was causing drastic slowdowns in our implementation.
this is because our ide solver heros gains much e ciency by computing individual data ows concurrently.
an eager equality check at each statement requires synchronizing the computations for each statement however which we found to cause too much thread contention to pay o in practice.
.
implementation we have implemented reviser on top of the open source solver heros .
heros provides an open interface for icfgs which allows it to be used in combination with programanalysis frameworks for various target languages.
we have extended this interface for changeset computation and provide a reference implementation which integrates with soot for analyzing java programs.
this raised some technical challenges as soot normally does not support parts of the ast and intermediate program representation to be exchanged while soot is running.
we thus decided to decorate all relevant soot objects with wrappers that support dynamic replacement.
reviser s modi ed ide solver then accesses these wrappers only.
naturally the indirection introduced through the wrappers incurs some overhead.
as our evaluation shows though in practice the overhead is quite acceptable in comparison to the savings achieved through incremental evaluation.
additionally the client analysis developer is required to adapt his code using a simple template.
instead of directly accessing ast objects he must request the corresponding wrapper from reviser .
for space reasons we refer the interested reader to our technical report .
.
experiments our evaluation addresses both the correctness and performance of reviser .
in our accompanying technical report we further assess the usability of reviser .
to assess correctness we compare the results of a full recomputation on the target code with the results of an incremental update.
to evaluate performance we measure both the time required to initially run reviser on the original code and the time required for the incremental update and compare it to the time a full recomputation of the changed code would have taken in the original unchanged heros solver.
for all our tests we use the following target applications and test cases junit special tests these test cases were hand written by ourselves they comprise important corner cases such as changes in methods close to the entry point loops in callees etc.
the tests all consist of code changes to junit .
.
they are especially useful to assess the correctness of reviser .
junit update junit is upgraded from version .
to version .
changing a large amount of code.
this test case evaluates a typical worst case scenario to see whether the algorithm degenerates for large changes.
junit soot and abc revisions performs incremental updates for check ins from the junit and soot git repositories as well as the abc svn repository to evaluatereviser on changes submitted to real world versioncontrol systems.
we envision this to be the main scenario for reviser frequent updates of smaller scale on a continuous integration server or even inside a development environment to ensure software quality.
all benchmarks are available on our project website.
firstly we ran every target application with an interprocedural reaching de nitions analysis.
the results of this ifds client analysis change at a rather large scale every modi ed de nition statement changes at least one result and is thus a good candidate for evaluating the lower performance bounds of an incremental algorithm.
secondly we ran an uninitializedvariable analysis on all target programs to evaluate reviser with a more lightweight client analysis.
for maximum analysis precision the full jdk was included with the target program for all junit test cases.
for the soot and abc test cases memory constraints required us to exclude the jdk.
.
implementation correctness to validate the correctness of our implementation we applied reviser to all test cases mentioned above i.e.
both the set of arti cial test cases on junit as well as all real world change sets.
for two subsequent versions v1 andv2 of any target program we rst ran all analyses using the unmodi ed heros solver on version v2and recorded the results.
afterwards we ran reviser onv1 incrementally updated the results to version v2 and compared the results with the ones from the unchanged heros solver.
our experiments con rm that reviser computes the same results as a full recomputation in all cases.
.
performance all results reported in this section are averaged over runs.
every run was allotted a maximum heap size of gb on a computation server with amd opteron cores running debian linux .
with oracle s java hotspot bit server vm version .
.
.
we allotted a large amount of memory since some client analyses require it.
this is not a requirement introduced by reviser .
all times are measured for the client analysis only excluding aspects like loading the target program into memory or constructing a callgraph.
.
.
reaching definitions analysis we rst show how reviser performs with an interprocedural reaching de nitions analysis.
the results of the junit special tests cases and the junit version upgrade are shown in figure .
the left side shows the timings the right side the number of processed edges the latter on a logarithmic scale.
though reviser introduces some overhead on the initial computation it requires only few edges to be recomputed making incremental updates fast.
therefore the initial overhead which only occurs once quickly pays o when performing multiple incremental updates.
with the junit special tests the rst update already makes up for initial overhead reviser saves about of the time required for a full recomputation using the original solver.
in the worst case scenario of large changes to the code base as in the junit update case shown as the rightmost data point in figure the time required for an incremental update seconds is approximately equal to the time of a complete recomputation in reviser seconds .
in this scenario classes and methods in existing classes were added methods were removed and methods were294base case new variable overwrite variableremove statementremove assignmentadd call statementadd call result remove from loopoverwrite returntwo junit versions50100150200time s base case new variable overwrite variableremove statementremove assignmentadd call statementadd call result remove from loopoverwrite returntwo junit versions101104107edgesoriginal algorithm reviser initial computation reviser incremental update figure junit special tests reaching de nitions revisionsindividual time s revisionsaccumulated time s figure junit git commits reaching de nitions changed.
the changed methods included hashcode and equals methods requiring the changed return de nitions to be propagated through all callers including those in the jdk.
in result in this case one really cannot expect much time to be saved by an incremental update.
on the most recent check ins to the junit git repository reviser greatly outperforms a recomputation.
figure shows the results which are very similar to our hand crafted test cases.
reviser saves about of the full recomputation time with the original solver and about of its own initial computation time.
in concrete numbers incremental updates on the junit git commit set take seconds on average about seconds of which are due to changeset computation.
the right side of figure shows how the savings accumulate over time to more than seconds.
for the updates to the soot repository of both the initial computation time and the full recomputation time with an unchanged heros solver are saved for the reaching de nitions analysis see figure .
an update takes seconds on average seconds are were spent on changeset computation.
the overhead of the initial computation is about seconds on average .
on the most recent commits to the svn repository of the aspectbench compiler abc reviser saves about of the original computation time as shown in figure .
the initial overhead was below the standard deviation of the original computation time and thus negligible.
even in the worst case scenario in which a commit modularized and restructured the project reviser performed an update in about of the original computation time.
.
.
uninitialized variable analysis on the specialized test cases reviser saves about of the original time and about of the initial computationbase case new variable overwrite variableremove statementremove assignmentadd call statementadd call result remove from loopoverwrite returntwo junit versions50100150200time in secondsoriginal algorithm reviser initial computation reviser incremental update figure junit special tests uninitialized variables time when performing incremental updates.
the initial overhead is about .
as shown in figure the savings are smaller than for the reaching de nitions analysis because the analysis as such is much faster.
still reviser saves time in all cases except the version upgrade.
here the huge number of changed edges severely a ects performance.
on the most recent commits to the junit repository figure reviser saves about of is initial computation time seconds on average and about of the original solver s time seconds on average .
the initial overhead is negligible since it was well inside the standard deviation of the original computation time about seconds .
for an uninitialized variables analysis on the most recent soot commits reviser saves about of both the initial and the original computation time see figure .
an update takes about seconds on average seconds if only counting updates that changed code seconds thereof are spent on the changeset computation.
the initial overhead is negligible for this experiment the unchanged solver took seconds295204060 revisionsindividual time s revisionsaccumulated time s original algorithm reviser initial computation reviser incremental update figure soot git commits reaching de nitions revisionsindividual time s revisionsaccumulated time s figure abc git commits reaching de nitions revisionsindividual time s revisionsaccumulated time s figure junit git commits uninitialized variables revisionsindividual time s revisionsaccumulated time s figure soot git commits uninitialized variables revisionsindividual time s revisionsaccumulated time s figure abc git commits uninitialized variables296on average with a standard deviation of .
seconds while reviser took seconds on average.
on the most recent commits to the abc repository reviser saves about of the original computation time on average as shown in figure with an initial overhead of less than .
there is a single case in which reviser s incremental update takes longer than the initial computation.
this commit contained major code restructuring which is rare.
.
discussion the performance advantage of reviser in comparison to full recomputations is visible best when applied repeatedly.
when we assume that the static analysis is performed on a continuous integration server for every check in into a version control system savings are accumulated over time as depicted on the right sides of figures .
for instance over the most recent soot revisions the savings introduced by reviser accumulate to over seconds hours .
in general the performance of reviser depends on the number of jump functions that need to be recomputed.
the larger the impact of the code change is the more edges are a ected.
clearing and repropagating over an edge takes generally longer than the initial computation for that edge.
performance gains are thus achieved by recomputing only a su ciently precise overapproximation of the a ected nodes which is usually a small subset of all nodes in the program graph.
in the worst case all edges must be recomputed and the algorithm degenerates to a recomputation with some overhead caused by changeset computation and wrapper lookups as described in section .
this for instance happens for the junit update from version .
to version .
.
furthermore reviser is not applicable in cases in which the time required for changeset computation already exceeds the time a full recomputation would take or in other words a recomputation is extremely fast which erases the need for incrementalization anyway.
if such a situation is detected during the rst incremental update further revisions should rather be recomputed than incrementally updated.
in the situations we consider primary use cases for reviser changes to the source code are frequent but reasonably small e.g.
a single bug x or new feature checked into a version control system.
in these cases reviser can save up to of the computation time across di erent client programs and analyses as we have shown in our evaluation.
furthermore if reviser is integrated into a development environment like eclipse which provides changesets as part of the infrastructure the respective computation time can be saved in reviser making it even faster.
.
related work a method for constructing incremental versions of kill gen problems has been proposed by pollock and so a .
ryder has shown an incremental solver based on linear equations for partitionable problems.
these approaches however do not easily translate to arbitrary ide problems.
carroll and ryder incrementalize arbitrary elimination based data ow algorithms by reducing them to the domintator tree problem and applying a variant of reps optimal attribute parse tree update algorithm.
in general ryder and burke have surveyed many older approaches which are limited to lowering lattice values in ide problems leading to results that di er from a complete recomputation.
reviser always produces the same results as a full recomputation.ismail and souter et al.
have presented methods for incrementally updating call graphs.
this work is orthogonal toreviser which focuses on the ide results alone.
at the moment reviser re computes the complete call graph.
sharp has presented an approach for pre computing summaries for type and dependence analysis in library functions which change rarely.
our approach is orthogonal as it focuses on identifying changes and propagating their effects across the code under analysis.
rountev et al.
discuss how to compute more concise summaries of libraries for generic ide problems.
integrating these results into our incremental solver is subject to future work.
we envision using summaries when calls into libraries are changed but not the libraries themselves so as not to repropagate the changes through the complete library.
tripp et al.
e ciently update dataow results by replacing the whole program controlow graph and pointer analysis with local information computed on demand during the taint propagation.
this removes the need of recomputing these data structures when the target changes.
for the dataow facts as such their tool andromeda computes the transitive closure of all facts in uenced by the code change removes them and then starts a recomputation.
while the latter is quite close to reviser s clear and propagate approach reviser only deletes jump functions on demand and thus can abort earlier if it detects that a jump function would be recreated in exactly the same way i.e.
it does not delete functions that might not change at all just because they are in the change s transitive dependence set.
eichberg et al.
use incremental tabled evaluation to update analysis results deduced in a logic language.
this approach comes with the cost of having to translate the program graph to prolog facts and depends on the performance of the underlying general purpose reasoning engine.
.
conclusion we have presented reviser a novel approach for e ciently and incrementally updating analysis results to re ect changes to the analyzed code.
reviser s update algorithm is based on the clear and propagate principle.
it detects the origin of a change then clears the information of its successors and propagates the new results from there on.
we have implemented reviser on top of heros and soot.
using this implementation we have shown that on the initial computation reviser only introduces a small overhead under in most cases sometimes even within the standard deviation but greatly outperforms recomputation saving up to of the time when performing incremental updates.
therefore the initial overhead quickly pays o when updating ide results on a regular basis e.g.
at every check in on a continuous integration server.
over the most recent commits to the soot git repository the savings achieved withreviser accumulated to over seconds hours .
.