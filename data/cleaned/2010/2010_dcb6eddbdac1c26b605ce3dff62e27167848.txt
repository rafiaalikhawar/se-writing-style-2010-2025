on the value of user preferences in search based software engineering a case study in software product lines abdel salam sayyad tim menzies hany ammar lane department of computer science and electrical engineering west virginia university morgantown wv usa asayyad mix.wvu.edu tim menzies.us hany.amma r mail.wvu.edu abstract software design is a process of trading off competing objectives.
if the user objective space is rich then we should use optimizers that can fully exploit that richness.
for example this study configures software product lines expressed as feature maps using various search based software engineering methods.
as we increase the number of optimization objectives we find that methods in widespread use e.g.
n sga ii spea2 perform much worse than ibea indicator based evolutionary algorithm .
ibea works b est since it makes most use of user preference knowledge.
hence it does better on the standard measures hypervolume and spread but it also generates far more products with violations of domain constraints.
our conclusion is that we need to change our methods for search based software engineering particularly when studying complex decision spaces .
index terms software product lines feature models optimal feature selection multiobjective optimization indicator based evolutionary algorithm search based software engineering .
i. introduction as software changes from product based to app based this changes the nature of software engineering.
previously in product based methods vendors tried to retain their user base via some complete solution t o all their anticipated needs e.g.
microsoft office .
such large software platforms are very complex and hence very slow to change.
with smart phones and tablet based software users can choose from large numbers of small apps from different vendors ea ch performing a specific small task.
in app based software engineering vendors must quickly and continually reconfigure their apps in order to retain and extend their customer base.
this new style of software engineering demands a new style of feature based analysis.
for example feature maps are a lightweight method for defin ing a space of options as well as assessing the value of a particular subset of those options .
feature models allow visualization reasoning and configuration of large and complex software product lines spls .
common spls now consist of hundreds even thousands of features with complex dependencies and constraints that govern which features can or cannot live and interact with other features.
for instance according to the linux model has features of which declare constraints of some sort and most features refer to other features.
such level of complexity surely requires automated reasonin g and configuration techniques especially if the intricacies of the feature model are combined with further user preferences and priorities such as those related to cost and reliability.
in that case the job of offering product variants with guaranteed conformance to the feature model and efficiency according to user preferences becomes monumental requiring tool assistance.
the automation of optimal feature selection in spls has been attempted before but never with multiobjective evolutionary optimizat ion algorithms meoas .
previous approaches will be highlighted in section ii .
the logical structure of feature models poses a challenge to evolutionary techniques since those techniques depend on random crossover and mutation which invariably destroy feature dependencies and constraints.
in this hurdle is overcome by introducing a repair operator to surgically make each candidate solution fully compatible with the feature model after each round of crossover and mutation.
in our opinion this approach fails to take advantage of the automatic correction afforded by the metaheuristic algor ithms via survival of the fittest .
as we show in this paper conformance with the feature model can be achieved by the evolutionary algorithms especially ibea without resorting to a repair operator or special crossover and mutation operators .
we demons trate how logical correctness can be obtained by generating a range of solutions i.e.
a pareto front which include fully correct and marginally incorrect solutions solutions with a very small number of rule violations as well as totally intolerable on es.
we believe that by shedding light on marginally incorrect solutions we provide wider configuration options to product managers and might inspire software developers to rethink the feature model and the relationships defined therein.
more important ly the main contribution of this paper is true high dimensional multiobjective search which puts each user preference in focus without aggregation and then incorporates the user preferences in the pareto dominance criteria using the indicator bases evolut ionary algorithm ibea .
we show remarkable results obtained with ibea compared to six other multiobjective evolutionary optimization algorithms meoas .
up to optimization objectives are used namely to maximize logical syntactic correctness maximize richness of feature offering minimize cost maximize code c ieee icse san francisco ca usa accepted for publication by ieee.
c ieee.
personal use of this material is permitted.
permission from ieee must be obtained for all other uses in any current or future media including reprinting republishing this material for advertising or promotional purposes creating new collective works for resale or redistribution to servers or lists or reuse of any copyrighted component of this work in other works.492reuse and minimize known defects.
we demonstrate how popular algorithms such as nsga ii and spea2 become useless as we increase the n umber of objectives a result that was shown in other domains but never before in software engineering.
the uniqueness of ibea comes from the way it calculates dominance as a value which incorporates the user preferences i.e.
optimization objectives thus providing an amount of dominance .
all other algorithms rank solutions in the objective space according to absolute dominance with second preference given to diversity of solutions.
the glaring superiority of ibea at higher dimensions shown in this work gives software engineers this take home message if your user preference space is rich then use an meoa that can exploit that richness .
the rest of the paper is organized as follow s section ii reviews related work in automated software product configuration as well as the use of multiobjective evolutionary optimization algorithms meoas in software engineering .
section iii provides background material on software product lines and meoas .
sections iv and v describe the experimental setup and the results of the experiments .
in section s vi we discuss the findings and their implications.
section v ii presents the threats to validity.
and in the final section we present our conclusions and future work.
ii.
related work a. automated software product configuration first we discuss related work in the area of automated product configuration and feature selection.
in our previous work we analyzed feature models using a data mining technique which runs over thousands of randomly generated product variants and identifies the most critical feature choices that amount to the most constraint violations.
based on that we offered rec ommendations as to where the configuration task sh ould begin in order to avoid related errors.
in the present work we augment the feature models with quality attributes and seek to find the optimal product variants based on the desired preferences.
the ide a of extending or augmenting feature models with quality attributes was proposed by many among them zhang et al.
.
the following papers used a similar approach and synthetic data to experiment wi th optimizing feature selection in spls.
benavides et al.
provide d automated reasoning on extended feature models.
they assign ed extra functionality such as price range or time range to features.
they modeled the problem as a constraint satisfaction problem and solved it using csp solvers to return a set of features which satisfy the stakeholders criteria.
white et al.
mapped the feature selection problem to a multidimensional multi choice knapsack problem mmkp .
they apply filtered cartesian f lattening to provide partially optimal feature configuration.
also whi te et al.
introduced the muscle tool which provided a formal model for multistep configuration and mapped it to constraint satisfaction problems csps .
hence csp solvers were used to determine the path from the start of the configuration to the desired final configuration.
non functional requirements were considered such as cost constraints between two configurations.
a sequence of minimal feature adaptations is calculated to reach from the initial to the desired feature model configurations.
the limitations of these methods are obvious given the small models that they experimented with.
as spls become larger the problem grows more intractable.
more recently a genetic algorithm was used to tack le this problem .
although the problem is obviously multiobjective the various objectives where aggregated into one and a simple ga was used.
the result is to provide the product manager with only one optimal configuration which is only optimal according to the weights chosen in the objective formula.
also t hey used a repair operator to keep all candidate solutions in line with the feature model all thro ughout the evolutionary process.
we contend with this as discussed in the introduction.
b. use of meoas in software engineering we now review broadly related work in the area of multiobjective optimization applied to various problems in software engineering.
historically the field of search based software engineering sbse has seen a slow adoption of meoas.
back in when harman and jones coined the term sbse all surveyed and suggested techniques were based on single valued fitne ss functions.
in harman commented on the current state and future of sbse and in the road map for future work section he suggested using multiobjective optimization.
then in harman et al.
were able to cite several works in which multiobjective evolutionary optimization techniques were deployed.
sti ll most of the work reviewed therein as well as work done thereafter optimized two objectives only while higher numbers appeared only occasionally.
also the typical tendency was to use algorithms that are popular in other domains such as nsga ii and spea2.
to support these two assertions table lists examples of papers that used meoas in variou s software engineering problems along with number of objectives and the algorithms used.
among the paper s in table t he paper by bowman et al.
is noted for using objectives and achieving good results with spea2.
we attribute that to the moderate size of the model and lack of complexity within.
in our experiment spea2 does not perform well with objectives when applied to the relatively large e shop feature model.
a literature survey of pareto optimal search based software engineering confirms these tendencies after studying related papers.
for example of the papers only applied a single multiobjective algorithm to their problems.
most researchers chose their algorithms based on popularity especially nsga ii often time not s tating any reasons for their choice.
it also shows that most papers tackled two or three optimization objectives.
very few examples were found where the researchers analyzed the suitability of certain algorithms for the problems at hand.
consequently the field of sbse is ripe for much reconsideration of algorithms reformulation of problems and performance comparisons.
493table examples of use of meoa s in software engineering reference application number of objectives meoa used zhang et al.
next release p roblem nsga ii pareto ga lakhotia et al.
test data generation nsga ii yoo and harman test case selection nsga ii vnsga ii gueorguiev et al.
software p roject planning for robustness and completion time spea2 bowman et al.
class responsibility assignment problem spea2 colanzi et al.
generating integration test orders for aspect oriented software nsga ii spea2 heaven and letier optimizing design d ecisions in quantitative goal models nsga ii iii.
background a. software product line engineering sple increasingly software engineers spend their time creating software families consisting of similar systems with many variations .
many researchers in industry and academia started using a feature oriented approach to commonality and variability analysis after the software engineering institute introduced feature oriented domain analysis foda in .
software product li ne engineering is a paradigm to develop software applications using platforms and mass customization .
benefits of sple include reduction of development costs enhancement of quality reduction of time to market reduction of maintenance effort coping with evolution and complexity and identifying opportunities for automating the creation of family members .
b. feature models and the sxfm format a feature is an end user visible behavior of a software product that is of interest to some stakeholder.
a feature model represents the information of all possible products of a software product line in terms of features and relationships among them.
feature models are a special type of information model widely used in software product line engineering.
a feature model is represented as a hierarchically arranged set of features composed by .
relationships between a parent feature and its child features or subfeatures .
.
cross tree constraints that are typically inclusion or exclusion statements in the form if feature f is included then features a and b must also be included or excluded .
figure adapted from depicts a simplified feature model inspired by the mobile phone industry.
the simple xml feature model sxfm format was defined by t he splot website which was launched in may .
splot is host to a feature model repository which adheres to the sxfm format .
figure shows the sxfm format for the mobile phone feature model from figure .
it shows the root feature marked with r the mandatory features marked with m the optional features marked with o and the group features marked with g .
the cross tree constraints are listed at the bottom in conjunctive normal form cnf .
the full set of rules in a feature model can be captured in a boolean expression such as the one in figure which shows the expression for the mobile phone feature model.
from it we can conclude that the total number of rules in this feature model is including the following the root feature i s mandatory.
every child requires its own parent.
figure feature model for mobile phone product line figure mobile phone feature model in sxfm format figure mobile phone feature model as a boolean expression feature model name mobile phone meta data name description mobile phone data ... meta feature tree r mobile phone root m calls calls o gps gps m screen screen g g 1 basic basic color color high resolution hi res o media media g g 2 camera camera mp3 mp3 feature tree constraints constraint 1 gps or basic constraint 2 camera or hi res constraints feature model fm mobile phone calls mobile phone screen gps mobile phone media mobile phone screen xor basic color high resolution media camera mp3 camera high resolution gps basic if the child is mandatory the parent requires the child.
every group adds a rule about how many members can be chosen.
every cross tree constraint ctc is a rule.
the total number of rules will be used as the full correctness score in this experiment thus making correctness one of the optimization objectives.
the feature models used in this study were downloaded from splot and were further augmented with properties pertaining to cost and reliability to allow for multiobjective optimizati on as will be explained in section iv.
c. multiobjective evolutionary optimization algorithms meoas many real world problems involve simultaneous optimization of several incommensurable and often competing objectives.
often there is no single optimal solution but rather a set of alternative solutions.
these solutions are optimal in the wider sense that no other solutions in the search space are superior to them whe n all objectives are considered .
formally we define two types of pareto dominance boolean dominance is defined as follows a vector is said to dominate a vector if and only if u is partially less than v i.e.
whereas continuous dominance is measured with a continuous function such as equation in figure .
the pareto f ront is defined as the set of all points in the objective space that are not domin ated by any other points.
many algorithms have been suggested over the past two decades for multiobjective optimization based on evolutionary algorithms that were designed primarily for single objective optimization such as genetic algorithms evolutionary strategies particle swarm optimization and differential evolution .
the algorithms we used in this study were already implemented in the jmetal framework .
they are ibea indicator based evolutionary algorithm .
nsga ii nondominated sorting genetic algorithm version .
ssnsga ii a st eady state version of nsga ii .
spea2 strength pareto evolutionary algorithm version .
fastpga fast pareto genetic algorithm .
mocell a cellular genetic algorithm for multiobjective optimization .
mochc a multiobjective version of chc which stands for cross generational elitist selection heterogeneous recombination cataclysmic mutation .
table provides a brief comparison among the algorithms highlighting their major properties.
d. indicator based evolutionary algorithm of th e algorithms listed above ibea is unique in terms of its dominance criteria.
all other algorithms followed a ranking approach according to boolean dominance equation while favoring diversity in the pareto optimal set of solutions.
they only gave each solution a place in the ranking.
ibea on the other hand makes more use of the preference criteria.
equation in figure shows ibea s continuous dominance criteria where each solution is given a weight based on quality indicators thus factoring in more of the optimization objectives of the user.
the authors of ibea zitzler and kunzli designed the algorithm such that preference information of the decision maker can be integrated into multiobjective search.
in figure we provide an outline of the ibea algori thm.
the details can be found in .
figure outline of ibea input population size n maximum number of generations fitness scaling factor output a pareto set approximation step initialization generate an initial population p of size and an initial mating pool p of size append p to p set the generation counter m to .
step fitness assignment calculate fitness values of individuals in p i.e.
for all x1 p set where i .
is a dominance preserving binary indicator.
step environmental selection iterate the following three steps until the size of population p does not exceed .
choose an individual x p with the smallest fitness value i.e.
f x f x for all x p. .
remove x from the population.
.
update the fitness values of the remaining individuals i.e.
f x f x for all x p. step termination if m n or another stopping criterion is satisfied then set a to the set of decision vectors represented by the nondominated individuals in p. stop.
step mating selection perform binary tournament selection with replacement on p in order to fill the temporary mating pool p .
step variation apply recombination and mutation operators to the mating pool p and add the resulting offspring to p. increment the generation counter m m and go to step .
495table comparison of multiobjective evolutionary optimization algorithms algorithm population operators domination criteria goal of domination criteria ibea main archive crossover mutation environmental selection calculates domination value i.e.
amount of dominance based on indicator e.g.
hypervolume .
favors those dominating by far.
favor objectives i.e.
user preferences nsga ii one crossover mutation tournament selection calculates distance to closest point for each objective.
fitness is product of these distances.
favors higher fitness i.e.
more isolated points.
favor absolute domination and more spread out solutions.
ssnsga ii one crossover mutation tournament selection same as nsga ii.
but only one new individual inserted into population at a time.
favor absolute domination and more spread out solutions.
spea2 external internal crossover mutation tournament selection strength of an external point is number of points dominated by it or equal to it.
strength of an internal point is sum of strengths of points dominating or equal.
minimize strength to minimize crowding.
favor absolute domination and more spread out solutio ns.
fastpga one crossover mutation tournament selection dynamic population sizing the fitness of the nondominated solutions is calculated using the crowding distance as in nsga ii.
the fitness of dominated solution is the number of solutions it dominates similar to spea2.
ranking by both domination and fitness.
favor absolute domination and more spread out solutions.
mocell main archive crossover mutation tournament selection random feedback the solutions are ordered using a ranking and a crowding distance estimator similar to nsga ii.
bigger distance values are favored.
favor absolute domination and more spread out solutions.
mochc one crossover cataclysmic mutation ranking crowding selection the solutions are ordered using a ranking and a crowding distance estimator similar to nsga ii.
bigger distance values are favored.
favor absolute domination and more spread out solutions.
e. quality of pareto front quality indicators can be calculated to assess the performance of multi objective metaheuristics .
in this study we used two indicators hypervolume defined in as a measure of the s ize of the space covered as follows let x1 x2 ... x k be a set o f decision vectors.
the hypervolume is the volume enclosed by the union of the polytopes p1 p2 ... p k where each pi is formed by the intersections of the following hyperplanes arising out of xi along with the axes for each axis in the objective space there exists a hyperplane perpendicular to the axis and passing through the point f1 xi f2 xi ... fn xi .
in the two dimensional d case each pi represents a rectangle defined by the points and f1 xi f2 xi .
in jmetal all objective s are minimized but the pareto front is inverted before calculating hypervolume thus the preferred pareto front would be that with the most hypervolume.
spread defined in measures the extent of spread in the obtained solutions.
it is found with the formula where n is the n umber of points in the pareto front di is euclidean distance s between con secutive points is average of di s and df and dl are the euclidean distances between the extreme solutions and the boundary solutions of the pareto front.
other quality indicators are used elsewhere namely generational distance inverted generational distance epsilon and g eneralized sp eed.
these indicators weren t used here since they compare the calculated pareto front to a previously known true pareto front which we do not have in this case.
an indicator that is particular to this problem is the percentage of correct solutions since correctness is an optimization objective that allows product configurations to evolve into full conformance with the feature model.
we are interested in points wi thin the pareto front that have zero violations and thus a full correctness score.
the importance of this indicator will become very clear in this experiment.
iv.
setup a. setting up feature models the two feature models used in this study belong to the feature model repository at splot website a popular repository used by many researchers .
we chose web portal a moderate size feature model and e shop the largest feature model in that repository.
table shows the feature model s along with size information and the