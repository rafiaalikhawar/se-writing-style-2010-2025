mit open access articles partial replay of long running applications the mit faculty has made this article openly available.
please share how this access benefits you.
your story matters.
citation alvin cheung armando solar lezama and samuel madden.
.
partial replay of long running applications.
in proceedings of the 19th acm sigsoft symposium and the 13th european conference on foundations of software engineering esec fse .
acm new york ny usa .
as published publisher association for computing machinery acm persistent url version author s final manuscript final author s manuscript post peer review without publisher s formatting or copy editing terms of use creative commons attribution noncommercial share alike .
partial replay of long running applications alvin cheung armando solar lezama and samuel madden mit csail akcheung asolar madden csail.mit.edu abstract bugs in deployed software can be extremely difficult to track down.
invasive logging techniques such as logging all nondeterministic inputs can incur substantial runtime overheads.
this paper shows how symbolic analysis can be used to re create path equivalent executions for very long running programs such as databases and web servers.
the goal is to help developers debug such long running programs by allowing them to walk through an execution of the last few requests or transactions leading up to an error.
the challenge is to provide this functionality without the high runtime overheads associated with traditional replay techniques based on input logging or memory snapshots.
our approach achieves this by recording a small amount of information about program execution such as the direction of branches taken and then using symbolic analysis to reconstruct the execution of the last few inputs processed by the application as well as the state of memory before these inputs were executed.
we implemented our technique in a new tool called bbr.
in this paper we show that it can be used to replay bugs in long running single threaded programs starting from the middle of an execution.
we show that bbr incurs low recording overhead avg.
of during program execution which is much less than existing replay schemes.
we also show that it can reproduce real bugs from web servers database systems and other common utilities.
categories and subject descriptors d. .
testing and debugging general terms reliability performance .
introduction a large amount of research effort has been devoted to the problem of identifying bugs and helping programmers pinpoint their root causes.
however not all bugs are equal.
most development organizations already have more bug reports than resources to fix them.
as such a bug from an important customer is much more critical than a bug dispermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
esec fse september szeged hungary.
copyright acm ... .
.covered by an automated test generator.
unfortunately pinpointing and fixing such critical bugs in the field can be very challenging.
stack traces and core dumps can be helpful when dealing with some errors and statistical bug isolation can be used when a bug affects large numbers of users.
however for bugs only manifest as a result of a specific input these techniques are not useful.
the gold standard for pinpointing such bugs is program replay.
if users could provide a log of the entire execution of their system or all of its inputs then identifying and fixing such bugs would be simple when the bug is observed you would have a complete trace of the execution that could be used to reproduce and fix the bug.
in fact replay tools exist that able to reconstruct an execution by either taking periodic snapshots of the system state or by logging all non deterministic inputs to the target program such as the return values from non deterministic functions e.g.
random system calls and user inputs .
the problem with these tools however is that while they can reproduce the exact scenario that leads to the buggy behavior modulo hardware failures they can significantly slow down the normal execution of the program and produce very large data logs that may grow without bound as long as the program keeps executing.
this makes them impractical for debugging systems like databases and web servers that may run for months at a time.
to mitigate this runtime overhead problem there has been work done on performing software replay using symbolic execution .
the idea is to capture a subset of the program state during runtime thus incurring less overhead and then use symbolic execution to reconstruct the missing information.
even though the reconstructed state might not be exactly the same as the one that the user experienced it is nonetheless useful for debugging purposes since it is usually the case that the same bug can be triggered by multiple execution traces.
thus as long as the reconstructed trace can still trigger the bug then it is good enough.
unfortunately all the previous work focuses on replaying programs from the beginning of the execution and today s symbolic execution engines which rely on smt solvers are not able to replay programs that have been running for days or months.
in this paper we explore the idea of using symbolic execution to perform partial replay from the middle of executions rather than replaying long running programs from the very beginning.
by this we avoid having to store and transmit very large logs as required by deterministic replayers and mitigate the very long replay times that can result from symbolic execution.
our tool called bbr is the firstsuch partial symbolic replay tool.
to use bbr the developer annotates the code with checkpoints for instance at places in the program that mark the transition from processing one request or phase to the next such as at each invocation of the query parser in a database server.
bbr collects a log during program execution and when a checkpoint is reached discards all logged data that was previously collected limiting the size of the logs that need to be maintained.
when the program terminates the developer gives the partial log to bbr to replay starting from the last checkpoint.
bbr symbolically executes the program generating constraints when the program uses values that were not recorded.
at the end of the symbolic execution the constraints are solved to find the program state at the beginning of the replay.
the solved state might not be exactly the same as the one in the original execution but it is one guaranteed to take the same control flow path when executed with the logged data.
we refer to this as a branch deterministic replay and we show that such a replay is as useful as a fully deterministic replay in debugging a number of real world bugs while avoiding the expensive cost of the data logging approaches.
unlike the data logging based schemes bbr works by recording control flow one bit per branch and accessed array indices into a log during program execution as well the current stack and file offset information for the currently opened files.
when a checkpoint is taken.
this amounts to much less data than in the data log based approaches which can accumulate large logs even in partial replay scenarios .
in summary this paper makes the following contributions we introduce the idea of partial symbolic replay at an arbitrary program point in the target application which lets users replay long running programs without the burden of maintaining large logs.
furthermore we develop an algorithm to handle pointer aliases that arise during partial replay without using the theory of bit vector arrays which as our results show gives poor performance.
we propose the concept of branch deterministic replay by recording control flow and non constant array indices and demonstrate its applicability to dataintensive applications showing low runtime overhead and small log sizes as compared to other existing replayers.
we identify several techniques that enable replaying of real world applications in our bbr prototype including a new memory model separating constraints into independent subgroups during solving and building a parallel solver implementation.
we show that our technique can scale to replay real programs including sqlite running on a gb tpc c database and two different web servers.
our runtime overheads range from to with reasonable replay and solving times.
we also show that we can reproduce several real bugs in these systems.
the rest of this paper is organized as follows.
in section we overview the architecture of bbr and provide a sample usage scenario.
in section we discuss in detail the design of the different components of bbr.
section describes our experimental evaluation of bbr on a number of different realworld applications.
finally section surveys related work followed by conclusions in section .
native runtimeannotated source code bbr inst.
librarybbr compiler instrumented bytecode bbr log smt constraints bbr parallel solver solved inputsmem modelfs network model constraint splittersymbolic executor user site developer siteexternal fn models bbr replayerassembler linkerinstrumented assemblynative app bbr debugger1.
prepare source code for replay .
runtime monitoring and log collection3.
symbolic replay to generate constraints .
constraint solving and debuggingfigure bbr system overview highlighting steps in the replay process .
overview bbr consists of five components a bytecode compiler a library for the instrumentation routines a bytecode replayer a parallel solver and a debugger.
fig.
shows the steps involved in using bbr for replay.
we illustrate the operation of these components through a real world bug in memcached.
in version .
.
a bug was found in decrementing an existing value in the cache .
the slightly abridged code is as follows char do add delta item it const int64 t delta int64 t value item data it ... if incr ... else value delta if value value memcached command decr item key it value the function first obtains the existing value for a key from the cache at line before performing the decrement.
then if the resulting value is negative the code simply sets the new value to be .
this is a bug since value is treated as a signed entity contrary to memcached s specifications.
if the existing value is a large number with the most significant bit set then decrementing it will result in .
in the following we describe how a developer can use bbr to replay and debug this problem.
.
preparing for replay to use bbr the developer first prepares the source code by inserting the bbr checkpoint annotations.
the annotation can be inserted in two ways at a program point for which the developer would like to start replay from e.g.
at the point that processes each incoming requests or configured as a timing parameter e.g.
take a checkpoint every five minutes .
in our example the developer can put the annotation at the program point that calls different functions e.g.
do add delta based on the incoming request type.the developer then uses the bbr compiler to compile the code into llvm bytecode.
the bbr compiler links the user code with a modified version of the uclibc library which we use because it can be easily compiled into llvm bytecode .
during compilation the compiler inserts instrumentation routines to record two types of data.
first bbr records the values of conditional branches in the example the branch conditions at lines and .
next bbr records the values of non constant indices into arrays none in this case .
the instrumented code is then compiled to native assembly and linked with the bbr instrumentation library to produce the final native memcached distribution.
.
runtime monitoring the user starts using the instrumented memcached server in her application.
as the application issues operations against the memcached server the bbr library embedded in the server intercepts the branch outcomes and array indices from the running program and stores them in an inmemory buffer which is periodically flushed to disk when it becomes full.
when the checkpoint annotation is hit the library takes a lightweight snapshot of the running program.
it also discards any logs that are previously written to disk.
in our example the user has been running her application normally until one day she observes that memcached returns for a decrement and causes her application to return an incorrect result.
believing that it is a problem in the server she files a report to the memcached developer along with the log generated by bbr.
.
symbolic replay the developer would like to find out why was returned in the decrement operation which is not obvious by just looking at the code.
with the collected log and the instrumented bytecode the developer uses the bbr replayer to replay.
the replayer symbolically executes the bytecode from the last checkpoint.
in our example at line item data loads the data from the heap pointed to by it whose contents are unknown since it was stored prior to the checkpoint.
when that happens the replayer creates a fresh symbolic variable vto represent the contents at the memory pointed to by itand assign that to value .
at the branch point in line the replayer reads the branch log and finds that the branch was not taken and jumps to line .
at line value is assigned to be v d where the symbolic variable drepresents the value of the program variable delta .
finally at line from the branch log the replayer learns that the branch was taken and because the branching condition involves symbolic variables it generates the constraint v d and continues execution.
.
solving and debugging the replayer saves the generated constraints to a file at the end of the replay which are then given to the bbr parallel solver to solve.
in our example the solver solves for possible values of vanddin order to produce a branch deterministic execution from the last checkpoint.
suppose the solver returns for v and for d. to map these results back to the program bbr comes with a debugger .
the debugger allows the developer to specify the values to be printed when an instruction is reached during symbolic execution.
a sample session is as follows italic text represents user inputs bbr db print delta at print value at bbr db run at delta at value with the output above and by following the program logic the developer realizes the cause of the bug and fixes her code accordingly.
even though the solved values might not be exactly the same as those that the user originally saw in fact the insertion of the key into the cache could have happened a long time ago with a different value in the original execution the developer is still able to use bbr to diagnose the problem by finding an execution that leads to the behavior observed by the user.
the debugger also allows the developer to request a new feasible variable assignment if she isn t satisfied with a given assignment by appending extra constraints.
in the example above perhaps the developer knows that the value of delta was not and thus the solution does not represent a feasible program state.
in that case she can tell the debugger that delta does not equal to and ask the debugger to generate another set of values for delta and value .
in contrast in order to use existing tools to replay the bug the developer would either have to rely on the user to provide a detailed use case that illustrates the bug or to collect data logs that have recorded the values of all nondeterministic data since memcached started which could have been a long time ago or to write assertions and rely on test generators to hit upon the bug all of which are costly and error prone.
in the next section we discuss the details of the design of the bbr replayer.
.
bbr design we begin by explaining the implementation of the recording mechanism followed by that of the replayer and parallel constraint solver.
.
instrumentation for recording as discussed in section calls to the instrumentation functions are added to the user code during compilation with the bbr compiler to collect the necessary data for replay.
these functions are implemented in a separate library that is linked with the instrumented assembly when producing the native executable.
each conditional branch generates bit of data and other types of data such as array indices are bytes each.
to reduce disk overhead we use a doublebuffering mechanism where we log data in one buffer in memory.
when the buffer fills or the program terminates we flush it to disk in the background and start recording into the other buffer.
section .
reports the overhead of data collection.
when a checkpoint annotation is reached bbr records the current stack and the state of open files see section .
.
for details so that replay can start at the appropriate program point.
the contents of registers and heap memory are not saved making the operation very fast.
.
replayer design once data logs are collected the developer feeds them to the replayer which uses them to generate the constraints used to solve for inputs and program state consistent with the log.
using the branch log the stream of bytecode instructions in the original execution is reconstructed pexpr ep n r unop ep ep1binop ep2 b?ep1 ep2 cexpr ec ep bitvector l n cond b true false b ep1comp ep2 b1 b2 b1 b2 stmt s r malloc n r ep r ep r ep assert b program p s p n n r program variables l n memory locations unop !
binop mod band bor xor shl lshr ashr comp negationslash we denote a memory location as l n where lrepresents an allocation and nis the offset from the base of allocation.
figure language of bytecode instructions and instructions are emulated to generate constraints.
the constraint generation process mirrors the symbolic execution done in concolic analysis e.g.
the main difference is that instead of getting our concrete data from the execution itself we get it from the log.
this subtle difference requires tradeoffs in terms of how much we can rely on symbolic vs. concrete reasoning and has implications for the design of the symbolic state and constraint generation.
.
.
modeling state the most interesting aspect of the state maintained by the replayer is memory representation.
traditionally the easiest way to model memory has been by using the theory of arrays modeling memory as a giant array that gets updated with every write operation.
this approach is very general but puts too much strain on the smt solver .
at the other extreme if we know the concrete address of every load and store we can model the heap as a map that gets modified by read and write operations .
this is very efficient because the solver doesn t have to reason about aliasing but it also requires a lot of concrete knowledge about the execution.
in our system we know the addresses for all memory accesses except those involving memory allocated before the start of replay and the key to our approach is to leverage the concrete information we have rather than relying on the theory of arrays to discover it.
the first important element of our representation is that it models the heap as a collection of independent buffers produced by malloc rather than as a flat array.
in this view a pointer is a pair l n where lis the base address of a buffer assigned by malloc and nis an offset into the buffer.
the benefit of this is that during runtime we only need to record nand only when it is statically unknown in llvm array element access instructions.1the main downside of this approach is that we assume pointer arithmetic to be able to change only nbut not l which prevents the system from reproducing errors caused by unsafe memory operations.
in exchange for this we are able to scale to large long running programs and to reproduce real bugs that are often much harder to discover than memory errors see section .
.
in addition to the heap h l n ec the replayer maintains an environment r ecthat maps variables to the symbolic values currently assigned to them as well as an alias map a l l0 .
.
.
l k that stores may alias locations 1field in records are accessed in the same way however nis always statically known in such cases.
h b a h b a where lis a fresh memory location h b a h b a h b a h b b1 a figure semantics for non memory instructions for a given allocation l. finally brepresents the set of constraints accumulated so far in the execution.
together the four entities h b a make up the state of the replayer.
.
.
symbolic execution of memory operations our treatment of non memory operations is similar to standard symbolic execution as illustrated by fig.
.
however memory operations present new challenges.
first of all a read or a write to an address l n is easy to handle if we know the concrete values of landn since we can just read or update the corresponding entry in our model of the heap.
the challenge comes when we lack information about an address as a consequence of partial replay.
the reason partial replay makes this difficult is because when we read a location that was written to before the start of the log we know nothing about its contents and if it contains an address we have no information about either lorn or about its aliasing relationship with other addresses.
because of this our system does not know the invariants the non replayed execution enforced on memory contents.
for the replayed portion of the program bbr ensures that for every location l n and all its potentially aliased locations li n the following invariant is maintained solvervalue l n solvervalue li n solvervalue h solvervalue h in other words if the solver decides that liis actually aliased tol then the symbolic expression in h should evaluate to the same value as the symbolic expression in h .
in the following we show this invariant is preserved in memory operations and describe how we handle memory locations initialized before the start of partial replay.
address initialization consider reading from or writing to memory whose address is stored in variable variable r. if maps to some location l n then the operation proceeds as described below.
otherwise rholds a value that was written before the start of partial replay i.e.
.
when this happens the system assigns a fresh symbolic variable bvto represent r. furthermore it assigns bva brand new base address lrthat is different from all the l s currently in use by the program updates and generates the constraint bv lr .
to account for the possibility of aliases the system updates the alias map ato keep track of all the other l s that may be aliased with lr.
our current implementation assumes that two memory locations can be aliased to each other only if the program variables for which they were originally allocated for have the same static type and that a memory location cannot be aliased to some offset within another location e.g.
array variables aandbcan be aliased to each other but acannot be aliased to the addresses of b b etc and vice versa .
notice that this is just one possible mechanism for computing alias information which we chose as it proved sufficient for replaying avariety of programs.
users can supply more precise alias information obtained elsewhere e.g.
from the output of an alias algorithm or by logging all memory addresses in load and store instructions.
memory writes memory writes are processed according to the following rule h prime h li c bi?ec h lj a li c b i getloc angbracketleft r ec h b a angbracketright h prime b a this rule conditionally updates every address that is potentially aliased with the address stored in r. the rule uses the function getloc to account for the fact that the address in r might itself have been the result of some conditional updates so instead of a single address getloc returns a guarded list of the possible addresses stored in .
if is a simple address lr c getloc returns lr c true but in general can be a complicated expression evaluating to different li ci under different conditions bi.
however since we logged the value of the offsets the rule can assume that those are fixed for all choices.
for each memory location li c that is returned by getloc we store a conditional expression that evaluates to econly if rdoes indeed evaluate to li c i.e.
if biis true.
for each memory location ljthat is aliased with each li we update h to a conditional that reduces to ecifljis indeed aliased to li.
an important assumption in the rule above is that since we always know the offsets for memory accesses we only have to track aliases among the base addresses.
in the special case that an address is allocated with a call to malloc after the start of replay there is no ambiguity as to what address is contained in a memory location getloc simply returns one possible location for r and that location has no aliases so the rule simply reduces to standard heap update li ci true getloc h prime h angbracketleft r ec h b a angbracketright h prime b a memory reads loading from memory presents similar complications and is processed using the following rule li ci bi getloc ec h negationslash prime angbracketleftr ec h b a angbracketright prime h b a the notation ibi eiabove should be read as a switch statement that produces eiifbiis true.
note that we do not load from any of the may alias locations of ecsince the store rule above ensures that their values will be equivalent if the alias turns out to be real.
in summary in the case where we have the log from the start of execution our strategy for memory operations reduces to the very efficient modeling of memory as a map.
conversely when we have no information about aliasing and all our locations are unknown our strategy is just an inefficient implementation of the theory of arrays.
for our purposes however this is ideal because it exploits all the concrete information available with the system and allows us to deal with aliasing uncertainty while still exploiting any aliasing information that we can provide.
.
.
external function calls a common issue in the symbolic execution of real world programs is handling external functions such as libc and system calls.
the typical solution and the one we follow is to provide a model of those functions.
bbr follows the approach used in klee by linking a modified version of the uclibc library with the target program which greatly reduces the number of libc functions that we need to model.
we model a subset of system calls using bit vector values.
for instance we use a byte bit vector to model the user id of the calling process.
thus calls to getuid will return that bit vector.
we currently model over linux system calls but do not model the state of devices or the kernel.
.
.
file descriptors and network sockets bbr implements a simple symbolic file system where each file is modeled as follows an array of symbolic expressions where each entry in the array represents one byte in the file.
a byte integer for the current file offset.
a byte integer representing the file flags read write both and append overwrite mode .
a byte integer representing the file permissions.
a byte integer representing the file size.
the file descriptor itself is modeled as a byte bit vector variable and the file system is a map from the file descriptors to the structure listed above.
bbr currently supports typical file system calls and network sockets are modeled similarly except that they are append only and do not support seek.
because the file metadata are modeled as real integers rather than bit vectors bbr records values from file system operations as mentioned in section2 in order to maintain each file s internal state during symbolic execution.
for instance the return values from read calls are recorded so that the current file offset can be correctly updated.
we experimented with using bit vectors and the theory of arrays to represent the file contents but this did not scale while the approach above did.
this is because the programs we experimented with operate on large files but do not necessarily process each byte within those files e.g.
databases may only read a few tuples from a loaded page .
modeling these files with the theory of arrays caused a large number of bit vector variables to be created for indices that are not referenced.
our approach which records additional information during runtime bytes per each invocation of read write lseek etc allows us to implement our own file model that generates less complicated constraints which saves a substantial amount of constraint solving time while adding relatively little additional recording state.
.
soundness and completeness for partial replay we define soundness as the fact that all program executions i.e.
the starting heap state and execution path solved by the replayer are indeed feasible traces of the target program although not necessarily the same as the original execution and completeness as the ability to solve for program executions given the input logs provided that the inputs were from an actual execution.
bbr is unsound since the initial state of the heap generated at the beginning of the partial trace might not correspond to a feasible heap from the original program.
this is because the system might miss some of the invariants that the non recorded portion of the program enforces onthe heap so it might generate a heap that violates these unstated invariants.
on the other hand bbr is incomplete since we might not be able to replay executions that violate our assumptions namely the independent allocation and non overlapping assumption the memory alias assumptions and the fact that we do not model the hardware or the kernel state.
in practice that means we cannot determine the memory locations that are overwritten in a buffer overflow attack although we can still detect writing out of allocated boundaries errors or replay an execution that is caused by malfunctioning hardware.
.
parallel constraint solver symbolic execution produces a set of constraints.
the bit vector variables in the constraints correspond to heap contents before the start of replay the non deterministic inputs that were read as well as return values any external function invocations during the execution.
the constraints need to be solved in order to re create the values that would cause the execution to take the same control flow path as in the original run.
a straight forward implementation would send all the generated constraints to a constraint solver to solve in one bundle.
we found however that this is quite slow as the constraint sets can be very large.
instead we subdivide the constraints into independent portions that can be solved separately.
specifically we found that although there are a large number of symbolic variables it is frequently the case that each variable is only related to a handful of other variables.
for instance in replaying a web server each byte that is read from the incoming socket is modeled as a bit vector variable as mentioned in section .
.
.
while it is likely that there will be constraints that bind the variables generated from reading the same socket e.g.
a constraint that the first three bytes read from the socket must be the characters get it is unlikely that there will be constraints that bind variables from one socket read to those from reads from different sockets where each socket corresponds to a unique http request.
thus bbr includes a constraints analyzer that separates the constraints into independent groups.
formally the constraints form a graph g v e where each vertex v v represents a bit vector variable and each edge e ebetween two vertices v1andv2represents a constraint binding the variables represented by v1and v2.
given g the constraint analyzer processes eand splits ginto its independent components.
at the end of the analysis each of the independent components are written to a file.
the parallel solver in bbr then solves the components individually.
because most solvers are single threaded this also allows us to parallelize solving by running each component in a separate instance of the solver with a separate thread.
in addition to reducing solving time splitting constraints into independent components can help identify components that may not need to be solved.
for example the constraints generated from replaying the thttpd web server see section separate nicely into independent components as expected with each component corresponding to an http request.
most components take a relatively short time to solve but one component takes substantially longer.
examining constraints involved in that component reveals that they involve not the bytes that are read from the request sockets but instead bind the return values from multiple invocations of gettimeofday together.
looking at the code forthe server we found that it implements a number of timers for house keeping tasks such as clearing lingering connections.
the timer structure maintains a field time that stores the next time that the timer should be fired.
after processing each incoming connection the server iterates through all timers to check if any of them should be run by passing in the current time by calling gettimeofday .
the check routine then compares the current time with the time field in the timers and either fires the timer or reschedules creating dependencies between each invocation of the check and thereby gettimeofday routine.
this routine runs many times per minute and the solver is quite slow at solving it.
in this case however these constraints represent a small portion of the program which is unlikely to contain bugs and not solving them reduces solving time substantially.
in general it is possible to use the outputs of any subset of the constraints to attempt to reconstruct a bug thanks to our parallel solver.
if one portion of the constraints is taking a long time to solve the programmer can run the program on the values from the constraints that have been solved so far with the debugger to see if the bug is reproduced.
in the case of the gettimeofday constraints described above they don t impact the results of interest namely the contents of the incoming http requests so we do not need to wait for the solver to finish solving them.
.
using the output of the solver the output of the solver is an assignment to each variable involved in the constraints.
bbr provides a debugger that takes in the instrumented bytecode and the solved outputs.
similar to the replayer the debugger performs symbolic execution from the replay starting point.
when an instruction that generates symbolic data is encountered instead of creating symbolic variables the debugger substitutes values from the solved outputs.
like gdb the user can specify a list of values to be printed on the screen when they are executed.
for files and sockets that were used during execution bbr further provides a utility that assembles the contents that were read from the solved output.
bbr is able to do that due to the naming conventions of symbolic variables when they are created.
thus if the developer is interested in viewing what values were read from a specific socket she can first use the bbr debugger to identify the file descriptor number that the socket was assigned during replay and then use the utility to assemble all the contents that were read from that descriptor number rather than printing out the values of the descriptor number and the contents of the read buffer after each recv call.
as discussed in section if the user is not satisfied with the solved outputs say because she has extra information about the original program state she can provide that to the debugger in terms of extra constraints e.g.
some variable must have a certain value .
the debugger then appends those constraints with the existing ones and solves for another plausible program state if one exists.
.
experiments in this section we describe our evaluation of the three central claims of this paper first we compare the runtime overhead of bbr to other replay schemes.
we measure both the overhead in terms of slowdown to the running program and the size of the logs generated.sqlite we ran 20k tpc c transactions on top of a 10g database representing warehouses and measured the time to complete all transactions.
checkpoints are taken every transactions.
memcached we inserted or updated 10k keys into the cache with values of size 800k each and measured the time to complete all operations.
checkpoints are taken every operations on the server.
tcpdump we asked tcpdump to print the details from a packet dump of 1g in size and measured the time to process all the packets.
checkpoints are taken every packets that are processed.
betaftpd we fetched files from the server each of size 1g and measured the time to complete all operations.
checkpoints are taken every fetches.
thttpd same as betaftpd ghttpd same as betaftpd figure description of benchmarks next we chose different types of bugs from real world applications and examine bbr s ability to replay them.
finally we measure the effectiveness of the alias aware memory model and constraint partitioning in bbr in replaying programs.
bbr is implemented with 11k loc of c using llvm version .
.
we experimented with several different smt solver implementations but we only report numbers from those using z3 as that was the solver that we found to scale the best.
for these experiments replay was run on a bit ubuntu machine with 2gb of ram while the constraint solving was done on a bit core machine running z3 version .
on windows server with 24gb of ram.
.
overhead experiments in the first experiment we measured the time and space overhead that different programs incur while collecting logs with periodic checkpoints.
the programs we replayed are listed in fig.
.
fig.
shows the results of the time overhead experiment in terms of slowdown relative to an uninstrumented binary while fig.
and fig.
show the log sizes that were generated by the different recording schemes.2all data collections were done using the bbr instrumentation library.
we report the results from running five different versions of each application namely native uninstrumented version.
bbr instrumented version with periodic checkpoints at frequencies shown in fig.
.
instrumented version that collects all nondeterministic data from the beginning of program execution.
this models the overhead of a whole program fully deterministic replayer.
same as non det except that every time a checkpoint annotation is reached we fork a process to create a core dump and all previously collected data are deleted.
this models the overhead of a partial replayer that takes periodic snapshots of memory and logs non deterministic inputs that were received between snapshots.
instrumented version that records the values of all memory loads.
to reduce the amount of logging 2the checkpoints were placed at sensible program points such as where the web server starts to process a new http request.
we tried placing the annotation at different but semantically similar locations and did not notice much difference in replay and solving times.we use the technique from idna where we only record loads whose values are not predictable at runtime i.e.
the store to a location was not an explicit instruction in the application but rather a side effect of a system call such as storing to the buffer in read .
.
.
.
sqlite 5m34s memcached 12m tcpdump 7m betaftpd 77m thttpd 86m ghttpd 77m overhead normalized to native executionbbr .
.
.
.
.
.04non det3.
.
.
.
.
.56snapshot .
.
.
.
.
.62loads .
.
.
.
.
.
figure normalized execution time relative to uninstrumented binary for different applications with uninstrumented times shown at bottom.
benchmark bbr non det snapshot loads sqlite 7k 20g 1g 250m memcached 16k 8g 600m 569m tcpdump 3k .6g 150m 200m betaftpd 72m 50g .1g 550m thttpd 100m 50g .1g 300m ghttpd 99m 50g .2g .2g figure log size experiment results the timing overhead experiment shows that bbr incurs the least overhead as compared to the other replay modes varying from for thttpd to for memcached with an overall average of which is significantly faster than the other schemes.
this is due to the smaller amount of data that bbr needs to write as compared to the data logging schemes.
the more computationally intensive applications e.g.
sqlite incur more overhead since they are more likely to hit branch instructions during their executions.
in terms of log sizes bbr outperforms the other schemes by a significant amount.
this is expected because for applications such as betaftpd the majority of non deterministic data comes from the contents of the files that are read and sent back to the user.
so in the case of non det the size of the log is roughly equal to the size of files that were read.
the core dump snapshots help somewhat since all previously recorded non deterministic data are discarded when a snapshot is taken.
as the size of the core dump is directly proportional to the amount of memory that is currently being used by the program for a computationally intensive application such as sqlite the log in the snapshot case is dominated by the size of the core dump whereas in dataintensive applications such as web servers the log size is dominated by the non deterministic data log.
finally loads reduces log sizes by only recording the load values that are affected by system calls and subsequently read by the application.
however the log sizes are still larger than thosebenchmark bbr non det snapshot loads sqlite .4k op 1m op .2g op .5k op memcached .6k op .8m op 60m op .9k op tcpdump .6k op .3m op 30m op 20k op betaftpd .4m op 1g op 1g op 55m op thttpd 20m op 1g op 1g op 6m op ghttpd .8m op 1g op 1g op 44m op figure log growth rates in overhead experiment requests bbr non det snapshot loads 46m 10g .1g 47m 46m 30g .3g 150m 46m 50g .6g 300m figure log sizes with varying of requests from bbr since for some applications such as sqlite and tcpdump most of the values that are affected by system calls are indeed loaded by the application afterwards for instance the read buffers in read and recv calls.
since the number of operations stored in the various logs are not the same e.g.
bbr takes periodic checkpoints to reduce log sizes whereas non det keeps the entire log from the beginning of execution fig.
presents the same results by showing the log growth rates instead.
the results show that the bbr logs grow much slower as compared to others.
thus even if the user decides to keep around all the bbr log files rather than having the system truncate them at each checkpoint perhaps due to uncertainty as to which checkpoint the replay should start bbr will still have the smallest log file sizes as compared to other schemes.
next we reran the experiment for betaftpd varying the number of requests issued in order to characterize the size of the data logs as the running time of the application increases the results show that the execution overhead is relatively insensitive to the number of requests .
the results are shown in fig.
.
observe that the log sizes for the non det and loads schemes grow proportionally with execution time due to the lack of log truncation.
and while the log sizes are roughly the same for bbr and snapshot bbr incurs much less runtime overhead because it writes less data to disk as shown in fig.
.
to understand how these numbers compare to other replay tools we compared our time overheads to those reported for other replay tools on similar data intensive programs.
pres reports an overhead of when recording all basic blocks while running mysql and when recording pbzip2.
r2 reports an overhead of when logging all data from win32 system calls while running mysql.
itarget reports a slowdown of when performing whole program replay on berkeleydb.
odr reports a slowdown of nearly on mysql.
other tools designed to collect data during normal execution on different benchmarks report similar or larger overheads.
for example program shepherding reports up to and idna reports an average of .
in summary the overheads of bbr are generally low enough with an average of to be deployed as an online tool during normal program execution.
.
reproducing bugs in our next experiment we used bbr to replay different types of bugs from real world programs.
fig.
shows the list of bugs that we tried to replay.
we describe a few representative bugs in detail in section .
.
below.
we set up the applications in a similar way as in the overhead experiment except that we input a request that would expose or trigger the bug.
we then terminated the appli cation if it had not already terminated due to errors and collected the logs.
given the log we asked bbr to reproduce a plausible execution of the program from the last checkpoint.
fig.
shows some statistics about the bbr executions specifically number of llvm instructions emulated.
number of conditional branch values recorded.
time taken for bbr s symbolic execution.
time taken to split the generated constraints into independent components.
total number of smt constraints generated.
note that constraints that reduce to true are not included thus the number of constraints can be smaller than number of conditional branches.
number of independent groups created.
of bit vector variables in the constraints.
time taken for parallel solving.
whether the solved inputs can be used to identify the original bug.
these experiments show that bbr is able to symbolically execute a wide range of real world data intensive applications and generate constraints that can be solved within a reasonable amount of time.
most of the replay time was spent in symbolic execution.
note that the number of conditional branch values recorded is typically much fewer than the number of constraints generated.
that is because of peephole optimizations on the constraint expressions that bbr performs to eliminate constraints that reduces to true and also because some of the conditional branches are not based on non deterministic values in the program so no constraints were generated.
.
.
bug walkthrough here we discuss a few bugs in detail.
as discussed in section the decrement bug in memcached was caused by the incorrect treatment of the stored values as signed entities.
using bbr we were able to solve for inputs and state of the value store that would trigger the problem.
notice that even though bbr did not record the contents of the request from the user it was nonetheless able to reconstruct it given the branching decisions recorded during parsing of the request.
for the sqlite bugs rather than a complete database file the output of the solver is a combination of heap values and a partial database file that was read while processing the transactions since the last checkpoint.
as described in section .
these outputs cannot be used directly to run sqlite and reproduce the bug since the solved input file is incomplete.
however these solved values can still help developers debug.
for instance the collation bug was caused by an error in the implementation of the comparison operator between two expression trees causing it to return the wrong cached value rather than performing the actual comparison.
using the solved values from the partial replay and the branch log we were able to observe the error by tracking the solved values that were used as inputs to the comparison function thanks to the bbr debugger.
when invoked with those values the function returns the incorrect value that triggers the bug.
for the bugs in tcpdump bbr solved for the contents of the incoming packets that cause the infinite loops.
while the contents were not exactly identical to the original ones we have verified that they cause the same problems when fed into tcpdump.sqlite cast error in the processing of queries with multiple selection predicates when one of the predicates involves a cast.
the code mistakenly reuses the results from the predicate without the cast for those with the cast .
sqlite join error in processing natural self joins.
mistake in identifying the table to join leads to returning extra rows .
sqlite collate in the processing of aggregates the code mistakenly treats aggregates with collation and without collation as equivalent.
as a result instead of executing each aggregate the cached results are returned .
memcached decr error in treating unsigned entities as signed leads to the wrong value being returned as a result of decrement .
memcache cas when a part of an existing value is updated the code forgets to updates its cas a unique identifier for the value leading to the same cas being returned both before and after the update violating the specification .
tcpdump bgp the code for displaying bgp packets contains an error in the checking of the loop condition that always returns true.
as a result the loop never terminates .
tcpdump isis in printing isis packets the code does not update how many bytes have been processed.
because of that the printing code goes into an infinite loop.
this is a different bug than the one above .
tcpdump rsvp the code for displaying rsvp packets does not check if the end of packet has been reached.
as a result the printing code goes into an infinite loop.
this is a different bug than those above .
betaftpd char betaftpd does not properly handle non latin characters such as a .
as a result it returns not found when a user requests a file with such characters as filename even though the file exists.
thttpd defang when returning an error message to a http request the code expands and characters into their html equivalents.
however it forgets to check if it has already reached the end of the buffer allocated to hold the escaped error message thus leading to a write out of bounds error .
ghttpd cgi when generating the pathname for a cgi the code simply concats the names of the cgi directory and the cgi executable together without checking whether the length of the result exceeds the preallocated buffer .
ghttpd log the request logging code in ghttpd does not check the length of the filename in the get request.
as a result it can write into memory that is beyond the size of the buffer preallocated to hold the log message .
figure description of bugs replayed bug loc br replay split constr groups vars solve debug?
sqlite cast 1225s 2s 5hr y sqlite join 1011s 4s 4hr y sqlite collate 820s 2s 3hr y memcached decr 286s .67s 13s y memcached cas 1955s .74s 158s y tcpdump bgp 31s .08s 1s y tcpdump isis 370s .65s 5s y tcpdump rsvp .8s .03s 1s y betaftpd char 7s .01s 1s n thttpd defang 542s .06s 2s y ghttpd cgi 40s .01s 2s y ghttpd log 40s .01s 1s y figure replay experiment results in general for all of the bugs that bbr was able to replay even though the solved instances of the database contents network packets http requests etc are not necessarily the exact same one as in the original input they still exhibit the errors.
this illustrates the power of our approach recording branches and a few extra pieces of data is enough for developers to debug the problem in hand.
also observe that without using bbr s partial replay ability in order to replay these bugs it would be necessary to record all non deterministic data from the beginning or take periodic snapshots of the heap which would be very costly as demonstrated.
in both cases there is a a huge overhead in both time and data log sizes.
furthermore as our experiment shows the longer the program runs the worse the problem becomes.
bbr failed to replay the betaftpd non latin character bug.
this is because the bug was caused by the lack of checking the characters that are read from the incoming socket before passing them to open.
the constraints generated from symbolic execution simply bound the length of the file requested since the code checks for but not the contents that were read this is precisely the reason why the bug exists .
as a result the solver returned a random filename that does not trigger the bug when re executed.
while the developer can use the bbr debugger to request another plausible value for the filename it is unlikely that she will be able to hit upon one that causes the problem within a reasonable amount of time given the unconstrained nature of the bug.
this illustrates a limitation of bbr the ability to recon struct a trace that leads to the problem relies on the fact that the buggy execution is sufficiently bound by the bbr logs.
otherwise the solver might return a trace that does not trigger the error even though it is branch deterministic.
finally we note that for a few of these bugs e.g.
those from ghttpd it is possible to replay them by just recording the incoming requests after the last checkpoint since they do not involve the internal state of the program.
however it would be very difficult for a developer to know a priori whether the bugs that her program exhibits will involve the internal state of the application or not unless the application keeps no internal state whatsoever which is highly unlikely.
for instance the sqlite and memcached bugs are related to the internal state of the program in particular the cached values in memory .
thus it would not be possible to replay such bugs simply by recording incoming requests.
.
constraint splitting next we look at the effectiveness of splitting constraints into independent groups using ghttpd and betaftpd as examples.
we replayed different number of requests coming into the two servers and measured the solving time.
we chose these two applications since they have relatively simple internal states and each incoming request should be independent from each other in terms of the constraints that are generated.
we compared the time taken to solve the generated constraints all at once from a single file single and the total time needed to solve the split constraints using threads for the parallel solver on a core machine split .
reqs const.
vars groups single split ghttpd web server 8s 1s 20s 5s 32m 6m betaftpd ftp server 2s 1s 40s 10s 40m 13m figure constraint splitting experiment results the results are of the experiment are shown in fig.
.
the results show a huge difference between parallel and single threaded solving.
we believe that one possible reason for the substantial slowdown in the single threaded case is because of cache misses when the input problem size becomes large.
we have also noticed that the solver frequently suffers from memory thrashing in the single threaded case on a machine with 24gb of physical ram which further contributes to the slowdown.
while one might argue that this is a relatively obvious way to speed up solving we have compared our results with different solver implementations z3 yices stp and none of them seem to have this feature in place possibly because constraint solvers are traditionally targeted to solving instances where most variables are related but not instances with a large number of independent components.
given that the time needed to do constraint splitting is relatively small as compared to the replay time as shown in fig.
it appears worthwhile to use parallel solving for replay.
.
memory model implementation lastly we looked at the performance differences between different memory models in our replay engine.
as discussed in section .
bbr models memory as a conceptual mapping from program variables to constraint expressions.
internally this is implemented using two maps one that maps program variables to memory locations and one that maps memory locations to contents in memory.
there are different ways to implement the second map.
we experimented with several different implementations for a bit memory i.e.
addresses are bit each and compared the time it took to symbolically execute three different small programs .
word count on an empty file 37k llvm loc .
.
a simple application that connects to a sqlite database 66k llvm loc .
.
application that connects and issues a select query to a sqlite database 341k llvm loc .
debug printouts were turned on so they took longer to run.
the different memory model implementations include .a single z3 bit vector array z3 bit vector z3 bit vector .
this is the most general representation based on the theory of arrays.
.for an allocation site of nbytes create a z3 bit vector of length n with the entire memory modeled as a std map .
.a single std map .
.a z3 bit vector array for each allocation site with the entire memory modeled as a single std map uint z3 bit vector array .
.for an allocation site of nbytes create a std vector of size n with each entry being an bit z3 bit vector to model a byte and the entire memory is modeled as a single std map .impl.
wc db connect db query 13m 52m 1hr 1hr crashed crashed 8m 15m 1hr 15m 35m 1hr 47s .9m 17m 10s 42s 2m figure memory modeling experiment results .we built our own data structure to represent a bit vector and implemented a number of peephole optimizations.
a single std map is then used to model memory.
this is the implementation we used for the operations described in section .
.
.
fig.
reports different memory model implementations and their replay times.
crashed means the experiment exhausted the address space on a bit machine and crashed.
as the experiment shows using the z3 theory of arrays incurs a substantial replay overhead in real programs since each read write to the array potentially creates a new array data structure.
using z3 bit vectors still incurs some overhead in the solver possibly due to housekeeping routines such as structural hashing.
note that the programs above were replayed from the entry point and no memory aliases were involved.
we anticipate that the performance of the first implementations to perform much worse in partial replay with memory aliases and thus built our own representation of expressions at the end.
.
related work a number of bug replay tools based on symbolic execution have been proposed recently.
however to our knowledge no tools support partial symbolic replay for long running programs which fundamentally distinguishes our approach.
in the authors proposed to record input traces during execution and perform symbolic execution to generate bug cases for the developer.
however they used a trace logger with high overhead and it is not clear if their approach is scalable to long running programs.
esd uses a path searching approach similar to model checking to reproduce bugs.
it has no runtime overhead but requires a coredump makes no guarantee regarding how long it would take to regenerate the bug and is tricky to use for replaying noncrash or hang bugs.
odr targets multicore bugs and collects data traces during normal execution.
they report a substantial runtime overhead because of data collection and also a long solving time.
pres is similar to odr but reproduces bugs iteratively with significant slowdowns.
replaying executions deterministically from data logs has been a topic in systems research for many years with the emphasis on using different mechanisms to reduce the runtime overhead and log sizes and recording at the operating systems level rather than application level .
recent tools such as r2 and itarget allow users to decide what data to be logged in order to reduce recording overhead but at the expense of not being able to reproduce all executions.
these tools generally have higher runtime overheads for data intensive programs than bbr.
at the other end are techniques that automatically find bugs without any inputs.
these range from static analysis tools to dynamic tools such as model checkers .
advances in smt solvers and symbolic execution have enabled new test generation tools such as concolic testing and other test generators based on symbolic ex ecution .
these tools focus on finding all sorts of bugs rather than reproducing a specific bug in hand.
our memory model is inspired by the work done in test generation for languages that include pointer operations.
in the authors proposed a memory model that maintains heaps for different types of objects and introduces constraints to enforce the disjointness among the different object heaps.
bbr imposes similar assumptions on object types and their alias properties.
in the authors proposed a region based approach with each address represented by a memory location object similar to that in bbr and each location can point to different concrete addresses depending on alias resolution.
in a hybrid memory model was proposed with a concrete store and a symbolic store implemented using theory of arrays which led to our initial memory model implementation.
there is similar work in languages without explicit pointer constructs such as .
.
conclusions we presented bbr a branch deterministic replayer that performs low overhead replay by logging only a small amount of data at runtime.
we also proposed the notion of partial replay which allows users to replay long running dataintensive programs with bounded log sizes.
to make our approach scale we introduced several new techniques including a new memory model for handling aliased addresses and a partitioning approach for parallel solving.
we showed that these techniques allow bbr to efficiently replay a number of data intensive programs and can reproduce real bugs in long running programs including sqlite and several web servers.
.