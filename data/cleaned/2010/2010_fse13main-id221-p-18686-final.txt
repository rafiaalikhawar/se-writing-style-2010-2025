hal id hal submitted on sep hal is a multi disciplinary open access archive for the deposit and dissemination of scientific research documents whether they are published or not.
the documents may come from teaching and research institutions in f rance or abroad or from public or private research centers.l archive ouverte pluridisciplinaire hal est destin e au d p t et la diffusion de documents scientifiques de niveau recherche publi s ou non manant des tablissements d enseignement et de recherche fran ais ou trangers des laboratoires publics ou priv s. f eature model extraction from large collections of informal product descriptions jean marc davril edouard delfosse negar hariri mathieu acher jane clelang huang patrick heymans t o cite this version jean marc davril edouard delfosse negar hariri mathieu acher jane clelang huang et al.. f eature model extraction from large collections of informal product descriptions.
european software engineering conference and the acm sigsoft symposium on the f oundations of software engineering esec fse sep saint petersburg russia.
pp.
.
.
.
hal feature model extraction from large collections of informal product descriptions jean marc davril1 edouard delfosse1 negar hariri2 mathieu acher3 jane cleland huang2 patrick heymans1 1faculty of computer science university of namur belgium 2school of computing depaul university chicago usa 3inria irisa unviersity of rennes france jmdavril delfosse student.fundp.ac.be nhariri cs.depaul.edu jhuang cs.depaul.edu macher irisa.fr patrick.heymans fundp.ac.be abstract feature models fms are used extensively in software product line engineering to help generate and validate individual product configurations and to provide support for domain analysis.
as fm construction can be tedious and time consuming researchershavepreviouslydevelopedtechniques for extracting fms from sets of formally specified individual configurations or from software requirements specifications for families of existing products.
however such artifacts are often not available.
in this paper we present a novel automated approach for constructing fms from publicly available product descriptions found in online product repositories and marketing websites such as softpedia and cnet.
while each individual product description provides only a partial view of features in the domain a large set of descriptions can provide fairly comprehensive coverage.
our approach utilizes hundreds of partial product descriptions to construct an fm and is described and evaluated against antivirus product descriptions mined from softpedia.
categories and subject descriptors d. .
requirements specifications methodologies general terms algorithms management keywords product lines feature models domain analysis .
introduction the use of software product line spl engineering is becoming increasingly prevalent as a means to deliver high quality products with a shorter time to market at reducedcosts .
according to the software engineering institute spls epitomize strategic planned reuse and represent a way of business that results in order of magnitude im provements in cost time to market and productivity .
an spl is a set of software intensive systems that share a common managed set of features developed from a common set of core assets in a prescribed way .
spl engineering aims to support the structured reuse of a wide range of software artifacts including requirements design code and test cases .
feature models fms are one of the most popular formalisms for modeling and reasoning about commonality and variability of an spl .
depending on the level of abstraction and artifacts described features may refer to a prominent or distinctive user visible characteristic of a product or to an increment in a software code base .
a recent survey of variability modeling showed that fms are by far the most frequently reported notation in industry .
several academic or industrial tools have been developed to specify them graphically or textually and automate their analysis configuration or transformation .
fms hierarchically organize a potentially large number of concepts features into multiple levels of increasing detail typically using a tree.
variability is expressed in terms of mandatory optional and exclusive features as well as logical constraints over the features.
the conjunction of constraints expressed in an fm defines the set of all legal configurations of an spl .
this is illustrated in table which lists all valid configurations for the fm shown in figure .
spl engineering includes two phases of domain engineeringandapplication engineering .
domain engineering involves analyzing a specific domain discovering commonalities and variabilities and then constructing core assets which will be used across the entire spl .
in contrast application engineering is concerned with building a specific product based upon the core assets of the product line.
in this paper we focus on the process of constructing an fm as part of the domain engineering process.
this process can be exceedingly time consuming yet can provide support during the domain engineering phase to help configure products design a new family of products expand an existing product line or simply provide inputs into the requirements elicitation phase of a single application process.
given the arduous nature of manually constructing fms the spl research community has shown significant interest in the ability to automatically generate fms from exist permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
copyright is held by the author owner s .
publication rights licensed to acm.
esec fse august saint petersburg russia acm 290phone camera connectivity bluetooth wi fiimplies figure fm example camera connectivity bluetooth wi fi x x x x x x x x x x x x x x table configurations for the fm above ing data.
there are several examples of prior work in the area.
czarnecki et al.
introduced probabilistic fms and provided an extraction procedure that mined propositional formulas and soft constraints from a set of multiple configurations.
however their approach assumed that products were already formally described as sets of features.
similarly acher et al.
described a way of extracting fms from product descriptions but their approach assumed the availability of formal and complete descriptions of products as configurations of features.
chen et al.
and weston et al.
described techniques for extracting an fm from informal specifications .
this approach is particularly useful in cases where an organization has an existing set of individual products and wishes to move towards an spl approach.
however it also has certain limitations because the constructed fm is constrained to the set of features described in the srs for the existing set of products.
in this paper we focus on the scenario in which an organization has no existing product descriptions and must rely upon publicly available data from websites such as softpedia1 cnet2 and majorgeeks3 which provide feature lists for hundreds of thousands of products .
however such product descriptions are generally incomplete and features are described informally using natural language.
the task of extracting fms from informal data sources involves mining feature descriptions from sets of informal product descriptions naming the features in a way that is understandable to human users and then discovering relationships between features in order to organize them hierarchically into a comprehensive model.
in this paper we base the feature extraction technique on our previously developed approach and then introduce a novel technique for generating an fm from the set of extracted features.
we describe and validate our approach using product descriptions for antivirus products mined from softpedia.
the remainder of the paper is structured as follows.
section provides a general overview of our approach while describes feature modeling in general.
sections and describe the two main phases of our approach namely feature mining and subsequent construction of the fm.
section describes results from the evaluation process while section discusses possible threats to validity.
finally section describes related work and section provides an analysis of our results and proposes ideas for future work.
.
overview our approach is summarized in figure and consists of two primary phases.
in the first phase software features are discovered from a set of informal product descriptions while in the second phase the fm is constructed.
.
mining features in step product specifications are mined from online software repositories.
we used the screen scraper utility to scrape raw product descriptions for antivirus products fromsoftpedia .
in step these product specifications are processed in order to identify a set of features and to generate a product by feature matrix p fin which the rows of the matrix correspond to products and the columns correspond to features.
the i j thentry of this matrix can take a value of or to represent whether the ithproduct is known to include the jthfeature or not.
given the informal and incomplete nature of the product descriptions we cannot differentiate between the case in which a feature is not included in the product versus the case in which the feature is present in the product but not listed in the description.
one of the challenges of our approach is therefore to construct an fm from relatively large quantities of incomplete information.
in step meaningful names are selected for the mined features.
.
building feature model in the second phase the product by feature matrix is used to infer feature associations and to create the fm.
this process requires creating some intermediate structures.
in step a set of association rules are mined for the features.
in step these association rules are used to generate an implication graph ig which captures binary configuration constraints between features.
in this context the ig is a directed graph in which nodes represent features and an edge exists between two features f1andf2if the presence of f1 in a configuration implies the presence of f2.
in step the tree hierarchy and then the feature diagram fd are generated given the ig and the content of the features.
finally step identifies cross tree constraints ctcs and or groups of features.
these two elements in addition to the fd generated in step form the fm.
.
background before describing our approach in greater detail we illustrate different types of syntactical constructions used in fms and we present the underlying formalism.
an fm is a hierarchical organization of features that aims to represent the constraints under which features occur together in products configurations.
returning to the example of figure the fm is depicted using the standard visual notation and aims to represent a family of mobile phones.
each combination of features a.k.a.
configuration that does not violate the constraints of the fm corresponds to a specific product for instance a mobile phone that exhibits the features 6f 6f 6e 8c 6e 4e 6d 6e 6f d7 4d 4d 6e 6e 6f 6f 6e 4d 6e 6e 6d 6c 6f 6e 6d 6e 6d 6c 6f 6e 6e 6e 6e 4f 2d 6f 4d 6f 6c 4d 6e 6e 6c 6e 4d 6f 6c 4e 6d 7a 7b figure fully automated two step process mining features and building fm connectivity bluetooth and camera see also table is a valid product.
figure shows some of the constructions every mobile phone has a connectivity feature the presence of a camera is optional a mobile phone supports at least bluetooth or wi fi and possibly both of them .
finally the presence of a camera implies the presence of bluetooth.
importantly the hierarchy imposes some constraints the presence of a childfeature in a configuration logically implies the presence of its parent e.g.
the selection of bluetooth implies the selection of connectivity .
the hierarchy also helps to conceptually organize the features into different levelsofincreasingdetail.
specifically relationshipsbetween a parent and its child features can be as follows .mandatory the presence of the parent feature in a configuration implies the presence of the child feature.
.optional the child feature may or may not be present in a configuration which contains its parent feature.
.orif the parent is selected then at least one of its child features must be selected.
.xorif the parent is selected exactly one of the child features should be selected.
formally an fm is composed of an fd and a set of crosstree constraints ctcs seedefinitionhereafter .
thefd of an fm is a tree representing the hierarchical structure among features as well as variability information exposed above.
ctcs are additional configuration constraints that cut through the tree structure of the fd.
in line with we define these concepts as follows definition .
an fd is a tuple fd f e e m go gx where i fis a finite set of features and e f frepresents the set of edges from child features to their parents so that f e forms a tree ii em eis a set of mandatory edges iii goandgxrepresent the sets of or groups and xor groups respectively.
these are sets of non overlapping subsets of eso that all the edges from the same subset of eshare a common parent feature.
there exists two kinds of ctcs.
i impliesconstraints are binary implications between two features a b .
figure gives an example of an implies ctc between the features camera and bluetooth.
ii excludes constraints ex table features from an antivirus product safepay keeps hackers at bay by automatically opening online banking pages in a separate secure browser.
dashboard see all the status and licensing information about your software and services in your own mybitdefender dashboard.
now accessible from anywhere anytime from any internet connected device.
security widget enables you to keep track of all of your security related tasks plus lets you quickly and easily drag and drop files for quick scanning for viruses right from your desktop!
parental blocks inappropriate content restricts web control access between certain hours and helps you remotely monitor your children s online activity even on facebook!
usb immunizer immunizes any flash drive from viruses when they are connected to your computer so that you never worry again about usbs infecting you.
active proactive dynamic detection technology which virus control monitors processes behavior in real time as they are running and tags suspicious activities.
press that the presence of a feature in a configuration implies the absence of another feature a b .
.
feature mining to mine features from a database of software specifications we adopted an approach used in our previous work in which we constructed a feature recommender system based on features described using natural language and mined from softpedia.
however our prior work made no attempt to construct a more formal fm which is the focus of this current paper.
furthermore we replace the previous feature naming algorithm to generate names more suited to appearing in an fm.
in this section we summarize the process used to mine features from product descriptions.
.
mining raw feature descriptors raw feature descriptors are retrieved from a repository of software products.
for purposes of this paper the screenscraperutility was used to scrape the raw software descriptions of antivirus products from softpedia.com .
softpedia products tend to include a general product description followed by a list of bulleted items describing specific features.
the set of feature descriptors for each product was extracted by parsing the software description into sentences and adding the items in the bulleted list of features.
there were a total of descriptors mined from the antivirus category.
table provides examples from one particular product.
it is important to note that similar features are described using very different terms and furthermore that the list of descriptors for each product is incomplete.
.
preprocessing in preparation for feature extraction all of the feature descriptors were preprocessed by stemming each word to its morphological root removing stop words i.e.
extremely common words such as thisandprovides .
the remaining descriptor was then modeled as a vector of terms in which each dimension of the vector corresponds to one of the terms in the vocabulary.
we use the tf idf term frequency inverse document frequency scheme to assign a weighting to termtin descriptor das follows wt d tft d log n dft 292table features published on softpedia for a selection of typical a ntivirus productsa squared freeacronis avahnlab platinumahnlabanti trojan eliteapprangerashampoo a.m.auslogics avavast!
pro avavast!
int.
secavg av pro.avgav firewallavira antivir premiumavira smallbusiness suitebkav2008bitdefender total sec.
10bitdefender int.
sec.
10corbitek antimwcyberdefender int.
sec.comodo cloud scannerdr.webg data av 10fix it utilities pro.gucup avgsa delphi induc cleanerhazard shieldggreat owl usbavjiangmin av kv 10k7 avimmunet protectmw destroyerkaspersky ultra portablesmx one avmulticore av antispywaremcafee virusscanmicroworld av toolkit util.norton int.
sec.novashield anti mwnovirusthanks mw rem.norman virus controlnorton av gaminged.norton avnorman sec.
suitenetwork mw cleanerpc tools int.
sec.
10outpost sec.
suite pronprotect gameguard pers.quick heal int.
sec.
10quick heal total sec.
10steganos int.
sec.
2009steganos av 2009spydllrem.tizer rootkit razorthe shield deluxe 10the cleaner 2011systemsuite pro.sysintegrity amvipre av premiumvirit explorer litetrustport pc sec.
10twister anti trojanviruszonealarm sec.
suitewlording antispywareyour free antispywarewebroot int.
sec.windows av mate prof.wimpvirusfightervirusbuster pro.virusbuster personalactive detection of downloaded files active detection of instant messenging active detection of removable media active detection of search results anti root kit scan automatic scan automatic scan of all files on startup automatic updates behavioral detection command line scan contain viruses in specific quarantine customized firewall settings data encryption .... note this table was manually compiled by researchers at depaul universit y through inspecting antivirus product listings at om.
it therefore only includes features listed on softpedia ref original source icse where tft drepresents the number of times that term t occurs in d dftis the number of descriptors that contain termt andnis the total number of descriptors.
.
feature formation to identify coherent features we first determined the similarity of each pair of descriptors through computing the inner product of their corresponding vectors.
the resulting similarity scores were then used to cluster descriptors into similar groups in which each group represents a feature.
we adopted a two stage spherical k means spk means clustering algorithm which has previously been shown to perform well for clustering features .
the first stage is similar to the k means clustering algorithm which starts by randomly selecting kcentroids where kis the desired number of clusters.
in each iteration of k means clustering each of the instances is assigned to the nearest cluster and at the end of the iteration each centroid is recomputed based upon its assigned set of descriptors.
this iterative process continues until the centroids stabilize.
the second stage of the spk means clustering involves the incremental optimization of the objective function through an iterative process.
at each iteration one of the instances is randomly selected and moved to another cluster to maximize the gain of the objective function.
the centroids are then updated and this process continues until convergence.
.
naming the feature for purposes of constructing an fm the clusters represent features which will be presented to human users and must therefore be assigned meaningful names.
based on informal experimentation we developed a cluster naming process that involved selecting the most frequently occurring phrase from among all of the feature descriptors in the cluster.
this approach is similar to the method presented in for summarizing customer reviews.
to identify the most frequently occurring phrase we use the stanford part of speech pos tagger4to tag each term in the descriptors with its pos.
the descriptors are then pruned to retain only nouns adjectives and verbs as the other terms were found not to add useful information for describing a feature.
itemsets are then discovered for each of the clusters.
in this context frequent itemsets are sets of terms that frequently co occur together in the descriptors assigned to the same cluster.
more formally the support of an itemset iis the number of descriptors in the cluster that contain all the terms in i. given a pre determined itemset support threshold s iis considered frequent if its support is equal or larger than s. we set this threshold to be of the total number of descriptors in each cluster.
various algorithms exist for mining frequent itemsets including the apriori and fpgrowth algorithms.
we chose to use fpgrowth as it is shown to be memory efficient and hence suitable for the size of our data set.
to select the name for a cluster all of its frequent itemsetsofmaximumsize fismaxareselected.
next allfeature descriptors in the cluster are examined.
in each feature descriptor the shortest sequence of terms which contains all the words in fismaxis selected as a candidate name.
for example let fismax prevents intrusion hacker .
for a given feature descriptor such as prevents possible intrusions or attacks by hackers trying to enter your computer the selected candidate name is prevents possible intrusions or attacks by hackers .
finally the shortest candidate name is selected as this reduces the verbosity of the feature name.
.
building the feature model thissectiondescribesthealgorithmusedtoautomatically construct the fm see algorithm .
it takes as input the product by feature matrix created during the feature mining phase and the set of feature descriptors assigned to each feature cluster.
the complete process was derived incrementally through a series of informal design and evaluation iterations.
we present only our final algorithm here although two variants are compared in section of this paper.
thelogicalconstraintshavelargelyinfluencedouradopted process.
we first utilize binary implication rules between features to construct a so called implication graph more details are given hereafter then add disjunctive rules to complete the implication graph and finally perform additional processing to transform it into a complete fm including the synthesis of or groups and ctcs .
the main steps of the algorithm are now briefly explained.
mining feature associations the first step of the pro293cess involves mining association rules between features lines in algorithm .
two types of association rules are mined binary implications anddisjunctive rules .
implication graph the binary implications are used to build an implication graph line defined as a directed graph in which nodes are features and edges represent logical implications between features.
because the implication graph is a directed graph it does not present the look andfeel of an fm in which features are grouped and arranged in a hierarchical fashion.
in fact every possible hierarchy represents a spanning tree of the implication graph.
extraction of feature hierarchy the next step is to find subgroups of features.
to accomplish this task we utilized the spk means clustering algorithm to group features intonclusters such that features in the same cluster are similar in textual content line .
the implication graph is then split into nsubgraphs representing the nidentified clusters line .
this is accomplished through removing the edges that connect features across different clusters and adding them to a set of ctcs.
we then utilized the agape5 library of graph algorithms to look for the strongly connected components sccs in each of the subgraphs using tarjan s algorithm line .
next fds are built for each of the subgraphs line .
the final fd is then built by merging these individual fds.
associations between the different fds are identified through mining an additional set of association rules at the cluster level line .
we substitute each feature by the cluster it belongs to in the product by feature matrix before re executing the association rule mining algorithm.
these associations are then used to aggregate the fms lines .
recovery of ctcs and or groups .
in the final step or groups and ctcs are recovered line .
these steps are explained in greater detail below.
.
mining feature associations there are various kinds of associations between software features in a domain.
having a dataset of valid configurations association rule mining methods can be exploited to identify these associations.
these algorithms were originally proposed for market basket analysis in order to identify the relations between shopping items.
for example a rule in the form of flour eggindicates that customers who buy flour are likely to buy eggs as well.
the rules are discovered based on a database of customers shopping transactions.
to discover the association rules for features the productby feature matrix p f is used as the training data to discover the relationships between the features.
each row of this matrix corresponds to a product and therefore represents a potentially incomplete yet otherwise valid configuration of features.
mining association rules is a two step process.
the first step is to discover the frequent itemsets as explained in section .
while in the second step association rules are generated for the set of frequent itemsets.
given an association rule in the form of a b aandb are both frequent itemsets and a b .
thesupportof this rule indicates the proportion of transactions that contain both itemsets aandb support a b s a b s feature model extraction association rules mining function assocrules p mis f cfp growth p mis frequent itemsets a agrawal f minsup returna implication graph g v e ig assocrules configurations mis clustering the features c spk means features building fds for the clusters fori tondo number of clusters gi subgraph g ci cluster i scci stronglyconnectedcomponents gi fdi featurediagram gi scc i aggregating the fds a assocrules configsclusters misclusters g merge fd1 ... fd n a scc stronglyconnectedcomponents g fd featurediagram g scc fd primeimplicates fd recovery of ctcs and or groups ctc g mg cross tree constraints wheresis the multiset of all transactions and s a b is the multiset of transactions that contain both aandb.
given a predefined threshold value rules which have support are accepted.
theconfidence of this rule indicates the proportion of transactions that contain itemset bamong the transactions that contain the itemset a. confidence a b support a b support a the fm is constructed based on binary implications and disjunctive rules.
.
.
binary implications abinary implication f1 f2 expresses an implication between two single literals and is discovered through mining frequent itemsets.
standard approaches for mining frequent itemsets utilize a single minimum support threshold however this can be problematic.
setting the threshold too low produces false positives i.e.
frequent itemsets that are not representative of actual co occurrence patterns of features.
on the other hand setting the threshold too high results in false negatives i.e.
patterns of feature co occurrence which are not captured as frequent itemsets.
this situation is particularly common when the distribution of features over the dataset is not normal and some of the features occur frequently while others appear rarely in transactions.
to deal with this problem we use the cfp growth algorithm which allows multiple minimum support values to be used to mine frequent items sets.
we tweaked the different minimum support values of the features until they all appeared in the association rules.
294files scanning mail attachement analysis mail content scanning behavior based detection anti spyware antispam removes trojan removes keylogger anti rootkit0.
.
.
.
.
.
.
.
.
.
figure implication graph anti spyware removes keylogger removes trojan anti rootkit antispammail content scanningmail attachement analysis behavior based detectionfiles scanning .
.
.
.9cluster cluster cluster figure implication graph divided in subgraphs after clusteri ng agrawal s apriori algorithm was then applied to discover theassociationrulesinordertodiscoverbinaryimplications.
.
.
disjunctive rules adisjunctive rule f1 f2 f3 ... fn representsanimplication from a single literal to a clause i.e.
a disjunction of literals .
the disjunctive rules are found by identifying prime implicates among features.
a clause cis animplicate of the logical expression e iffcis not a tautology and e c is a tautology.
an implicate cof expression eis said to be primeiff there is no clause c obtained by removing any literal from csuch that c is an implicate of e. by observing whether disjunctions of features are prime implicates we identify or groups of minimal size among features.
disjunctive rules for which the features in the prime implicate share a common parent in the hierarchy are represented as or groups.
in case of an incomplete dataset a threshold can be tuned so that the disjunctive rules involved in the computation of the prime implicates are the rules with a support higher than this given threshold.
.
.
exclusion clauses while fms generally include exclusion clauses in the form f1 f2 the nature of the informal product descriptions used in our approach makes this infeasible.
this is because as previously explained the absence of a feature in theproduct by featurematrixdoesnotdifferentiatebetween the case that the feature is not present versus the case in which the feature is not described in the product description.
therefore our procedure does not include the mining of exclusion clauses.
.
mining the implication graph the set of binary implications can be represented as an implication graph in which nodes represent features and a directed edge connects f1tof2for each implication f1 f2.
figure shows an example of an implication graph which was automatically generated for a subset of features for theantivirus category of products in our dataset.
however in this example feature names were assigned manually.
later we provide examples of automated feature naming.
association rules are a form of partial implication between features.
deterministic association rules are implications with confidence while non deterministic rules have confidence of less than .
this is reflected in the weights assigned to the directed edges connecting any two given features f1andf2in the implication graph.
each weight represents the confidence of the rule f1 f2.
given the incomplete product data mined from softpedia and the sparsity of the resulting product by feature matrix it is necessary to consider association rules with confidence lower than .
our product by feature matrix contains products for features with an average of .
features per product.
certain features appear in as few as five products andnopairoffeaturesoccurtogetherwithaconfidence of .
therefore in order to build a dependency structure it was necessary to reduce the confidence threshold to a value below .
and groups.
in the implication graph there exists sets of features that are mutually implied and have a common parent.
they form a so called and group.
all these groups can be determined by identifying strongly connected components scc in the implication graph.
a scc in a graph gisasubgraphof ginwhichapathexistsinbothdirections between each pair of nodes in the subgraph.
and groups can be synthesized as mandatory features in an fd whenever the parent child relationships between them have been determined see next section .
we reduce the implication graph by merging all the nodes in the same scc.
these merged nodes represent conjunctions of features and form and groups.
for example in figure anti spyware removes keylogger andremoves trojanform a scc and can be merged together.
the andgroups are then included in the new resulting implication graph see figure .
.
extraction of feature hierarchy given an implication graph there are many potential feature hierarchies and thus fds which could be extracted.
the challenge is to identify the diagram that will ultimately produce the best hierarchy.
it is well known that different groups of people will organize features in different ways and therefore produce a variety of hierarchies from the same set of features.
the problem is not only identifying a single correct hierarchy i.e.
a spanning tree but also finding a good one which organizes features in a meaningful way.
one viable approach is to treat the extraction process as a spanning tree optimization problem.
our approach selects the final feature hierarchy using a combination of text mining and co occurrences between features.
first the spk means clustering algorithm clusters features into nclusters according to terms used in their associated feature descriptors.
we used the same approach as in our prior work to set the number of clusters n .
this clustering step is conducted because in many cases human created fms include subtrees of related features.
for each cluster we then extract the subgraph of the implication graph that contains all the features belonging to this cluster and only those.
therefore we can reduce the scope of possible fds to a selection of nfds from nsubgraphs of the implication graph.
for example the implication graph showninfigure4showsthedivisionoftheimplicationgraph in figure into three subgraphs.
each one of the three fds selections is realized by applying edmonds optimum branching algorithm to the subgraph which can be seen as a minimum spanning tree algorithm for a directed graph.
in our case the weights of the edges are conditional probabilities between feature occurrences and the algorithm is used to compute maximal trees.
for each subgraph an artificial root node is added and elements under the root form an or group.
each node in the subgraphs represent features except for these artificial roots which are abstract nodes that are similar to those created by expertswhentheywritefmsmanually.
graphically werepresent these artificial roots as boxes containing the themes of the clusters i.e.
the words that were attributed the greater tf idf weights in the vector space representation of the clusters .
figure shows three examples of these automatically generated abstract nodes scan detection files spyware protection andmail spam .
finally all the resulting fds need to be connected together into a single systemwide fd.
this is accomplished by mining association rules between clusters from the product by feature matrix.
this additional association rule mining phase requires the features in the dataset to be replaced by the clusters they belongto.
theminedassociationrulesindicatehowtoconnect the artificial roots of the fd together with directed edges.
edmonds algorithm is applied again to the overall graph in order to reduce it to a tree.
in other words connecting different fds can be seen as the construction of a tree structure between the abstraction nodes first the tree structure is formed between the abstract nodes by mining association rules and by applying edmonds algorithm.
next for each abstract node the fd containing its successors is added to the tree.
finally nodes that were previously merged as conjunctions of features thus forming and groups can now be unfolded.
to accomplish this one of the conjunctions must be chosen as the parent of the group.
given an and group we define the parent feature as the feature that maximizes the minimal co occurrence with other features of the group in the dataset.
formally the parent feature fmaximizes the number of configurations involving fand any other feature of the and groups.
for example as shown in figures and anti spyware is selected as parent of the group.
our clustering approach aims to ensure that features covering similar aspects of the domain are close to each other in the fd.
furthermore our initial informal observations of several variants of these algorithms suggested that the automatic creation of abstraction nodes reduces the cognitive complexity of the final model.
.
recovery of ctcs and or groups at this point a tree structure showing the relationships betweenfeaturesandabstractionnodeshasbeenconstructed.
in addition mandatory relationships have been synthesized and an fd without feature groups has been created.
some of the disjunctive rules that have previously been mined can be represented as or groups in the fd.
these are the disjunctive rules for which the antecedent feature is the parent of all its consequent features in the fd f1 f2 f3 ... fn wheref1is the parent of f2 f3 ... fn.
unfortunately for a large dataset computing prime implicates can become infeasible in practice.
however if we are primarily interested in finding or groups in the fd instead of looking for all disjunctive rules from the dataset then performance can be increased by reducing the task to consider only features sharing a common parent in the hierarchy .
algorithm shows the computation of prime implicates after elicitation of the feature hierarchy at line .
when the scope of orgroups mining is reduced it becomes feasible to compute prime implicates in a brute force manner i.e.
by counting co occurrences between the parent feature and disjunctions of its children in the dataset in order to find or groups of minimal size.
furthermore once the implication graphs and the fd are known the cross tree constraints can be easily deduced.
the fd coupled to the conjunction of cross tree constraints form a fm as defined in section .
.
ev aluation to evaluate the quality of the generated fms we first explored the possibility of creating a golden answer set and then comparing our fm against this standard.
for this approach to be viable it would be necessary for multiple users to manually construct similar fms given an initial group of features.
as an initial feasibility study we asked two distinct pairs of users to construct an fm for the antivirus domain.
each pair was given a brief introduction to feature modeling so that they had a solid understanding of the expected hierarchy optional and mandatory relationships as well as or groups.
in separate sessions each pair was given the same list of features taken from our product by feature matrix and was asked to organize these features into an fm using a whiteboard.
the participants were not required to create cross tree constraints.
each pair of users took approximately four hours to complete their task.
while we did not ask the users to to follow any specific process bothpairsapproachedtheproblembycreatingclusters of features related to similar topics and then creating a hierarchy that connected these clusters.
while there were several similarities in the way the two pairs created clusters the final hierarchical organization of the two fms was quite 296antivirus scan detection files mail spam behavior based detection files scanning spyware protection anti spyware removes keylogger removes trojan anti rootkitmail content scanning mail attachement analysis antispam antispam mail attachement analysis mail attachement analysis files scanning anti spyware files scanning removes trojan behavior based detection figure resulting fm cluster6 scan engin optim perform file scanning technology skips safe files for better scan speed and lower systemoption to suspend real time monitoring activities and updates to reduce pc and network resource usagescanning technology skips safe files for better scan speed and lower systemmalware detection via innovative scanning technology scan engineprevents unauthorized software from changing your critical applications without impacting your pc performancesensing monitor scans only the modified portions of the file system avoiding repeat scans of files that have not changed since the last scan the fast and intelligent anti malware engine has no impact on overall system performance and can operate figure group of features shown in the evaluation different.
as a result of these observations we decided that it would not be appropriate to compare our approach against a single golden standard.
we therefore adopted a more direct evaluation technique in which we asked several graduate students familiar with feature modeling to critically evaluate parts of four different fms.
these fms included one fm automatically generated using only association rules and the computation of a maximal tree based on the conditional probabilities between features occurrences which we refer to as the probabilisticapproach the two manually constructed ones and the one generated by our algorithm which we refer to as the clustered approach.
we created four surveys and two participants were assigned to each one.
each survey included questions taken from each of the fms however the participants were notinformedofthe source ofeachquestion.
each question was asked in the context of a specific parent child relation or the grouping of features such as the automatically generated features depicted in figure .
the study included questions and was completed by users at an average completion time of approximately one hour.
the first group of questions in the survey were designed to evaluate the quality of groups of features and read on a scale of with being the highest please provide an overall rating for the group as a whole.
a score of means that the group is cohesive i.e.
all features belong together in this group while a score of means that the group is not very meaningful at all .
results from this question for the three types of fm are reported in figure a and show that the evaluators assigned an average rating of .
to groupings in the manually constructed fms .
to the clustered fms our approach and only .
to the probabilistic fms.
the second group of questions were designed to evaluate the quality of the parents for each feature group.
the question read on a scale of with being the highest please provide an overall rating for the parent of the group.a score of means that the parent captures the essence of the features in the group and a score of means that there is no obvious relationship between the parent and its child nodes .
results are reported in figure b and show that the evaluators assigned an average rating of .
to the manually constructed fms .
to the clustered fms and only .
to the probabilistic fms.
the third group of questions were designed to individually evaluate parent child relationships.
for each presented feature group all parent child associations were listed and evaluators were asked to mark the correct associations.
results are reported in figure c and show that the average percentage of correct associations is .
in the manually constructed fms .
in the clustered fms and only .
in the probabilistic fms.
these results show that while the feature groupings in the clustered fm generated by our approach do not reach the same level of quality achieved in manually constructed fms they outperform the groupings of the probabilistic fms.
a careful comparison of the fm generated by the two automated techniques showed that in several cases the clustered approach identified key abstractions which were not identified by the probabilistic approach.
for example figure6showsagroupoffeaturesthattheclusteredfmgrouped together under an abstraction node cluster6 whereas in the fm obtained by the probabilistic approach these six features were scattered across five unrelated groupings.
.
threats to v alidity there are several threats to validity for our study.
the primary threat is our assumption that extracting feature information from large numbers of partially complete product descriptions yields a representative set of features from the entire domain.
we do not fully explore this assumption in thispaper apartfromensuringthat thedomainwechose a user evaluation of the quality of groups of features b user evaluation of the quality of the parent for each group of features c user evaluation of the quality of the individual parent child relationships figure a comparison of our approach clusteredversus manually created versus probabilistic approach for fm construction for experimental purposes contained a large and varied representation of products and clarifying that it is clearly a constraint of our method and that of most machine learning techniques that we can only learn from available data.
applyingourapproachtoadomainwithamoreconstrainedset of product descriptions is highly unlikely to produce good coverage of features in the domain.
a second threat to validity lies in the scope of our study which focused on only the single domain of antivirus software.
the primary reason for this is that evaluating the quality of the generated fm is time consuming and involves manuallycreatingoneormorefmsforthedomain andthen asking human users to evaluate the quality of the product lines in a blind study.
we leave the evaluation of our approach across a broader set of domains with a larger group of evaluators to a future study.
a third threat is the computation of sccs to identify and groups for a set of partially complete product descriptions.
as explained in section .
andersen et al.
compute strongly connected components in implication graphs to detect and groups.
the mapping from sccs to andgroups is motivated by the fact that the implications between the features in the implication graph are transitive.because there is a path between any two features in a scc each presence of a feature of a scc in a configuration implies the presence of every other feature of the scc in this configuration.
however the implication graph described in section .
is not made of implications but probabilistic association rules which are not transitive.
it follows that features that do not occur often together in configurations may be considered as parts of the same and group.
so in case of an implication graph using probabilistic association rules and groups can be computed from sccs to offer the user an approximation of potential and groups but these groups must be manually reviewed.
the final threats we discuss here relate to the evaluation process.
it was impossible to entirely separate out the task of evaluating the quality of each feature s name with the quality of the associations established in the fm.
for example if we asked a user to evaluate whether p was a correct parent of child c then the study participant might be influenced by both the essence of the feature i.e.
what it truly represented as well as the name of the feature.
nevertheless feature naming was essential for human cognition purposes.
to mitigate this problem our study presented both the generated feature name and the bag of words representing the primarytheme s oftheunderlyingfeaturedescriptorstothe user.
while our evaluation was conducted by only graduate students we deliberately chose the domain of antivirus products as our evaluators were knowledgeable about this domain and therefore served as valid stakeholders.
finally while we did perform an initial analysis of the generated fm to determine that it modeled valid and sensible product configurations we did not evaluate this in a formal way.
we leave this for future work.
.
related work synthesizing fms.
several techniques for synthesising an fm from a set of configurations or constraints e.g.
encoded as a propositional formula have been proposed .
these techniques cannot be applied in our context since we cannot assume the availability of formal and complete descriptions of configurations or constraints.
therefore we develop new extraction and synthesis techniques to deal with the informal and textual nature of product descriptions.
an important limitation of prior work is the identification of the feature hierarchy.
in the authors calculate a diagrammatic representation of all possible fms.
however they did not address the problem of selecting a unique fm with a meaningful hierarchy.
similarly the algorithm proposed in does not control the way the feature hierarchy is synthesized in the resulting fm.
in she et al.
proposed heuristics for identifying the likely parent candidates for a given feature in order to assist users in selecting a hierarchy.
however the heuristics are specific to the targeted systems linux freebsd ecos both from the domain of operating system and therefore hardly apply to our case.
furthermore she et al.
reported that their attempts to use clustering techniques did not produce a single and desirable hierarchy.
they gave a possible reason arguing that there is simply not enough information in the input descriptions and dependencie for the kinds of artefacts they considered.
acher et al.
proposed a procedure that processes userspecified knowledge for organizing the hierarchy of features.
compared to our approach does not require user 298intervention.
another key difference is that we integrate feature mining and clustering techniques for building and exploiting the implication graph.
extraction of fms.
acher et al.
proposed a semiautomatedproceduretosupportthetransitionfromproduct descriptions expressed in a tabular format to fms.
ryssel et al.
developed methods based on formal concept analysis and analyzed incidence matrices containing matching relations .
a common assumption is the availability of formal and complete descriptions of products which is not the case in our context.
the two works also assume a certain structure in the product description or other knowledge that is exploited to hierarchically organize the features.
probabilistic fms pfms .
in czarnecki et al.
introduced pfms.
soft constraints are formally described and indicate the conditional probabilities between the presence of features in configurations which enable reasoning aboutpreferencesbetweenconfigurationchoices.
whilehard constraints express configuration rules that must be obeyed byalltheconfigurations softconstraintsshouldberespected by most configurations but can be violated by some of them.
the authors extended their prior work by proposing an extraction procedure that relies on association rule mining.
the prior work used association rules with a confidence of to build the hierarchy and association rules with confidence less than but above a predefined threshold to add extra information to the fm.
in our approach the product by feature matrices are built from natural language text and can be very disparate.
therefore all the mined soft constraints above a defined confidence threshold are used to build the hierarchy.
our approach also integrates clustering techniques to derive a desirable hierarchy.
clustering techniques.
alves et.al.
conducted an exploratory study based on the use of the vector space model vsm and latent semantic analysis lsa to determine the similarity between requirements.
the variability information is out of the scope of their study though.
weston et al.
proposed an extension to the framework proposed by alves et al.
and developed a tool which creates fms from natural language requirements specifications.
first they divided the specifications in fragments and then used clustering techniques to identify features.
the size of thesegmentscanbeparameterizedbytheuser.
theyparsed the specifications to identify variabilities by detecting grammatical pattern based structures and words from a vocabulary lexicon.
in our approach we build fms by both using the information about co occurrence of the features in the products and the content of features without assuming the presence of specific grammatical patterns or the presence of words from a lexicon.
chen et al.
proposed an approach to build fms from applications specifications.
the authors introduce a classification of relationships between requirements.
for each application the procedure first elicited a set of functional requirements and modeled the relationships between them in an undirected graph.
features were then identified by clustering the functional requirements.
finally the resulting fms were merged as one.
instead of merging as many models as there are configurations we directly mine an fm from the set of all the configurations.
the determination of the feature hierarchy is fully automated and basedonfeaturesco occurrencesinthedataset withoutpredefining any type of relationship.
niu and easterbrook provided semi automatic support for analyzing functionalrequirements denoted frps in a product line.
the frps and their attributes were extracted manually thus increasing the user effort.
itshouldbenotedthatseveralothertechniques assume existing requirements specifications that provide a deep and rather complete description of the products.
in our context we have to infer fms through analyzing hundreds of informal product specifications.
.
conclusion and future work in this paper we have presented a novel algorithm for automating the generation of an fm from a set of informal and incomplete product descriptions.
the results from the reported evaluation show that in the case of the antivirus software utilizing clustering techniques to augment association rule mining led to marked improvements in the quality of the generated fm.
as such the findings reported in this paper make a significant contribution to the ongoing research goal to automate the generation of fms.
furthermore one ofthe major advantages of our approach is that product descriptions are publicly available for many different kinds of products which means that our approach can be used in practice even if an organization has not previously developed software for the targeted domain.
a quick perusal of softpedia shows products such as authoring tools desktop enhancements file managers ipod tools networking tools and office tools to name a few.
future work will involve applying and then evaluating our approach on a far broader set of products and also exploring other sources of informal product descriptions.
given the probabilistic nature of our approach the generated fm must either be further refined by a human analyst into a more formal fm or else used informally during domain analysis to provide ideas for features to implement in a product.
in future work we plan to explore the utility of the generated fm for supporting specific tasks related to domain analysis and the design of a software product line.
.