mining behavior models from user intensive web applications carlo ghezzi politecnico di milano italy deepse group at deib carlo.ghezzi polimi.itmauro pezz university of lugano switzerland mauro.pezz usi.ch michele sama head of cloud and data touchtype ltd uk michele swiftkey.netgiordano tamburrelli university of lugano switzerland giordano.tamburrelli usi.ch abstract many modern user intensive applications such as web applications must satisfy the interaction requirements of thousands if not millions of users which can be hardly fully understood at design time.
designing applications that meet user behaviors by e ciently supporting the prevalent navigation patterns and evolving with them requires new approaches that go beyond classic software engineering solutions.
we present a novel approach that automates the acquisition of user interaction requirements in an incremental and re ective way.
our solution builds upon inferring a set of probabilistic markov models of the users navigational behaviors dynamically extracted from the interaction history given in the form of a log le.
we annotate and analyze the inferred models to verify quantitative properties by means of probabilistic model checking.
the paper investigates the advantages of the approach referring to a web application currently in use.
categories and subject descriptors d. .
software program veri cation model checking h. .
information storage and retrieval systems and software user pro les general terms design measurement veri cation keywords web application log analysis user pro les markov chains probabilistic model checking this research has been funded by the eu programme ideas erc prj.
smscom and by a marie curie ief within the 7theuropean community framework programme prj.
runmore permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
icse may june hyderabad india copyright acm ... .
.
.
introduction a key distinguishing feature of user intensive software and in particular web applications is the heavy dependence on the interactions with many users who approach the applications with di erent and evolving needs attitudes navigation pro les preferences and even idiosyncrasies1 which generate di erent navigation pro les.
knowing and predicting the di erent user behaviors are crucial factors that may directly a ect the success of the application.
underestimating the importance of these factors may lead to technical as well as non technical failures that may involve substantial economic losses.
for example an inadequate or distorted knowledge of users navigation preferences may lead to web applications characterized by an unsatisfactory user experience with consequent loss of customers and revenues.
unfortunately the presence of a huge number of users with di erent and evolving behaviors make it almost impossible to accurately predict and model all of them and to design applications that can answer all possible needs.
moreover the population of users is seldom homogenous and typically several classes of users with distinct user behaviors coexist at the same time.
in addition no matter how well they are initially captured user behaviors change over time.
this leads to the need for learning and re ning our understanding of how users interact with the system and to the need for speculating on the inferred knowledge to drive the progressive system maintenance adaptation and customization.
the mainstream approach towards capturing the user behaviors consists of monitoring the usage of the system and subsequently mining possible interaction patterns .
some existing solutions instrument web pages to track users navigation actions for instance google analytics while others analyze log les as discussed by facca and lanzi .
current solutions su er from several limitations.
some approaches lack generality for example they need to infer users navigational pro les to support speci c actions such as run time link prediction or data caching .
being tailored to speci c tasks these solutions provide little support from a general software engineering perspective.
on the other hand the general frameworks simply return a set of statistics or patterns that are useful to understand the preferences of system s users but cannot be directly used to 1we collectively identify these factors under the term user behavior or simply behavior when the context is clear.permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may june hyderabad india copyright acm ... .
evaluate software engineering decisions.
this paper describes a framework called bear2 that overcomes these limitations supporting software engineers in maintaining and adapting existing user intensive web applications.
the proposed approach focuses on rest3architectures and analyses the log le of the server in which the application under analysis has been deployed.
by analyzing the log le bear infers a set of markov models that cluster similar users in classes and capture their behaviors probabilistically.
developers can decorate the inferred models with rewards that represent the causal connection among user navigation actions and technical as well as non technical aspects of the application under analysis.
an ad hoc analysis engine mines the models to gather valuable insights about the users behaviors and the relation among users and the entities modeled by the rewards.
the analysis engine relies onprobabilistic model checking to formally verify quantitative properties of the behavior of the users captured by the models.
for instance the analysis engine may compute the probability that a user who enters the web application from a certain link navigates across one or more speci c paths and reaches a given target page.
the analyses supported by our approach may focus on the whole population of users on a speci c class of users in isolation or may compare di erent classes.
bear can be viewed as an approach to facilitate and automate the acquisition of user interaction requirements in an incremental and re ective way that supports many aspects of the application maintenance and evolution.
the proposed solution brings some key advantages with respect to existing competing alternatives.
the inferred models together with rewards represent a general abstraction that can be used to analyze technical as well as non technical and domain speci c aspects of the application.
probabilistic model checking and the incremental inference process allow the progressive and automatic analysis of large and complex models as soon as new data become available in the log le.
to the best of our knowledge this paper contributes to current research in requirements and design of user intensive software in three distinct ways .
it is the rst approach that investigates the use of probabilistic model checking to formally verify quantitative properties of users behaviors in web applications.
.
it investigates a novel approach to capture user behaviors with an inference algorithm and a model based technique speci cally conceived for rest architectures.
.
by introducing rewards it provides a new way to reason about the relationships between the interaction of users and several aspects of the application under analysis.
the remainder of the paper is organized as follows.
section overviews the bear approach.
section introduces the running case study we use throughout the paper to exemplify and validate the approach.
section provides a detailed description of the approach while section illustrates some relevant scenarios of our case study that exemplify the potential applications of bear.
section discusses performance and scalability of the approach.
section discusses related work.
section summarizes the main contributions of the paper and illustrates the ongoing research work.
2behavioral analysis of rest applications.
3representational state transfer .
bear inference engine engineer analysis results specifies uses uses generates rewards uses generates log file uses propositions user classes properties specifies bear analysis engine markov models figure the bear approach .
the bear approach in this section we present the bear approach.
although the approach is applicable to di erent kinds of systems and logs in this paper we refer to user interactions with remote services implemented according to a rest architectural style .
rest is an increasingly popular architectural style in which requests and responses ow through thestateless transfer of resources via urls that uniquely identify the state of the conversation between clients and servers.
bear infers the user behaviors by deriving markov models from log les and quantitatively veri es properties of the interaction patterns by analyzing the inferred models using probabilistic model checking.
the veri cation provides the core information to refactor or customize the application according to emerging user behaviors.
bear is articulated in six main steps that we introduce below referring to the diagram in figure and discuss in detail in section .identifying the atomic propositions the designers give semantics to the urls occurring in the log le by means of a set of atomic propositions that denote the relevant user actions.
this is a necessary setup phase through which the designer identi es the actions relevant for the analysis of the application.
bear automatically clusters the entries of the log that represent urls into groups univocally identi ed by sets of propositions.
.identifying user classes the designers characterize the population of users by identifying a set of relevant features to cluster them into distinct classes.
for instance they may use the feature user agent to discriminate users depending on the browser they rely on or depending on the device they use mobile vs. desktop users .
.inferring the models the bear inference engine analyses the log le of the application and infers a set of discrete time markov chains dtmcs .
dtmcs are nite state automata augmented with probabilities each state is characterized by a discrete probability distribution that regulates the outgoing transitions.
the inference engine generates an independent dtmc for each user class.
.annotating the models with rewards the designers may provide information by annotating the states of the models with numerical values that represent rewards .
rewards indicate the impact of the state on some metrics of interest.
the annotations are optional and refer to the set of atomic propositions introduced in the second step.
.specifying the properties of the interaction patterns the designers formally specify the properties of interest for the user intensive system.
the properties may predicate on the probability that users may follow a certain navigational pattern or may predicate on the rewards.
.analyzing the models the bear analysis engine quantitatively evaluates the formal properties against the markov models and produces either numerical or boolean results depending on the nature of the properties.
the obtained results provide insights on the behaviors of the users and on the impact of such behaviors on the rewards in the models.
these insights guide designers in refactoring or customizing the application under analysis.
.
the real estate example we introduce the real world rest application we use throughout the paper to illustrate and validate the bear approach.
the running example has been provided by an it consultancy company and is currently in use.
we chose it because it balances generality and simplicity the application is general enough to include the main aspects that characterize the requirements in the user intensive rest domain and simple enough to illustrate the approach.
during our study we had full access to both the application and the log les and we conducted our experiments on the data collected during the normal operation of the application.
for condentiality reasons we anonymize the application selected as a case study by using the pseudonym ndyourhouse.com .
through the ndyourhouse.com website users may either browse the housing announcements divided by category or search for the available o ers with a proprietary search engine accessible from every page of the website.
if users nd an announcement of interest they can contact a sales agent for additional details and schedule a visit to the property of interest.
the website is composed of several pages and resources identi ed by the urls summarized in table the meaning of the third column will be discussed later and can be ignored at this stage .
the table contains samples of the relevant urls and provides a summary of the urls through a pre x. it ignores urls that are not relevant for the experiments for example the url pointing to the robots.txt le used by web spiders.
some of the urls are simple for example home while others are parametrized for example anncs sales ?page n or have a parametric structure for example anncs sales id .
even for a relatively simple rest application like the one illustrated in this section information about the behavior of the nal users is crucial for engineering an application that meets users di erent and evolving browsing requirements and tries to increase the economic value of the service.
.
the details of the approach bear is grounded on a simple basic assumption discussed here before presenting the six steps of the approach in details.
the input to bear is a log le structured as a list ofrows that record the interactions between the users and the web server of the application under analysis.
each row represents a request of a web resource issued by a client.
hereafter we use the terms rowandrequest interchangeably.
we assume that the rows contain the following common data the ip address of the user who issued the request to the server a timestamp that represents the time of the request the user agent and the requested url.
these assumptions correspond to the information provided by the log les compliant to the common log format clf adopted by many popular web servers such as the apache web server4.
.
identifying the atomic propositions in the rst step of the approach bear associates semantics to the rows of the log le by means of a set of atomic propositions ap that indicate what can be assumed as valid when a certain entry in the log le is found.
for example the proposition homepage is associated to a row in the log le to indicate that the request corresponding to that row has led the application to the home page.
the atomic propositions to be associated to the log entries are encoded as code fragments called lters .
the application designers declare the lters as methods decorated with the annotation bearfilter .
a lter may be parameterized with a regular expressions to restrict its application to the urls that match the expression.
the bear engine scans the log le invokes the lters with matching parameters on each row it analyses and associates the propositions returned by the lters to the log le entries.
the third column in table shows some atomic propositions associated to urls of the ndyourhouse.com application.
listing shows some examples of lters.
the rst lter associates the proposition homepage to the homepage url.
the second lter associates the proposition sales anncs to the urls that matches the regular expression in its annotation and indicates that the urls are related to sales announcements.
the third lter associates the propositions login success and login failto urls that correspond to login attempts depending on the http status code of the request.
the fourth lter associates the propositions controlpanel to the pages of the control panel.
the bear inference engine associates propositions only to relevant urls which match some regular expressions in the lters.
rows that correspond to urls associated to secondary resources that are not crucial to capturing relevant aspects of the users behavior are not labeled with any proposition.
for example usually lters do not match urls that represent css or javascript resources that are not relevant to user navigation actions since they are automatically requested by browsers and thus are not labeled with propositions.
filters may generate propositions dynamically according to information available in the url or the application database.
for example a lter may use the announcement id extracted from the url to retrieve the location of the sales announcement from the application database and may use the location to build a proposition dynamically.
filters propositions and regular expressions are exible tools that application designers use to characterize the rows in the log le exploiting both application and domain speci c knowledge.
the relevant urls of ndyourhouse.com url description atomic propositions home homepage of ndyourhouse.com homepage anncs sales the rst page that shows the sales announcements.
sales page page anncs sales ?page n the nthpage that shows sales announcements n is an integer index.
sales page page n anncs sales id detailed view of the sales announcement identi ed by the string id .
sales anncs anncs renting the rst page that shows the renting announcements.
renting page anncs renting ?page n the nthpage that shows renting announcements n is an integer index.
renting page page n anncs renting id detailed view of the renting announcement identi ed by the string id .
renting anncs search page containing the results of a search submitted through the search engine.
search admin ... website s control panel that allows to publish edit or delete announcements.
control panel admin login login page that allows to access the control panel.
login success orlogin fail contacts url with the form to contact a sales agent.
contacts contacts submit url that indicates that the form used to contact the agency has been submitted.
contacts requested contacts tou page that describes the website terms of use.
tou media ... urls with this pre x refer to images css and javascript resources.
bearfilter regex home public static proposition void f i l t e r r e n t i n g logline l i n e f return new proposition homepage g bearfilter regex anncs s a l e s nw public static proposition void f i l t e r s a l e s logline l i n e f return new proposition s a l e s a n n c s g bearfilter regex admin l o g i n public static proposition void f i l t e r l o g i n logline l i n e f i f logline .
gethttpstatuscode return new proposition l o g i n s u c c e s s else return new proposition l o g i n f a i l g bearfilter regex admin e d i t public static proposition void filteradmin logline l i n e f return new proposition c o n t r o l p a n e l g listing some examples of lters .
identifying the user classes in this step of the approach the designer may de ne a set of user classes relevant for the application under analysis.
a string in the format name value de nes each user class.
the bear inference engine uses code fragments called classi ers decorated with the annotation bearclassi er to specify classes of users.
the bear engine scans the log le invokes the classi ers on each row and associates the user classes returned by the classi ers to the log le entries.
by default bear comes with two classi ers that extract the user agent and the user s location obtained geolocating the ip address.
for instance a row may by associated with the following user classes f useragent mozilla location boston g classi ers represent a exible and extensible tool to map rows in the log into classes.
notice that as shown in the example above each user may belong to multiple classes.
by adding classi ers the designers can classify the users into application or domain speci c classes exploiting additional information that may be stored in customized log les.
for example designers may classify users predicating on their operating system the http referrer the user s time zone etc.
for the sake of readability in this paper we refer only to the default classi ers even if all the concepts and examples we discuss here apply seamlessly to more complex and application speci c classi ers.
.
inferring the model given the set of atomic propositions apand the user classes de ned through lters and classi ers respectively the bear inference engine infers a set of discrete time markov chains dtmcs that represent the users behaviors.
the inference process works sequentially and incrementally on the log le as a data stream.
once a log entry is processed it may be discarded.
thus the process works efciently both on line and o line and works both for legacy applications for which log data have been collected and for newly deployed applications.
the inference engine generates an independent dtmc for each user class de ned by the classi ers.
for the sake of readability we rst de ne the inference of a single generic dtmc model and then extend the inference algorithm to multiple dtmcs later in this section.
in this paper we derive dtmcs augmented with rewards de ned as follows.
a dtmc is a tuple hs p l iwhere s is a non empty nite set of states and s02sis the initial state p s s!
is a stochastic matrix that represents the probabilistic edges that connect the states in s. an elementp si sj represents the probability that the next state will be sjgiven that the current state is si l s !
2apis a labeling function that associates each state with a set of atomic propositions ap.
s!r 0is a state reward function that assigns a non negative number to each state.
rewards are nonnegative values that quantify the bene t or disadvantage of being in a speci c state.
as for the dtmcs we infer the set apconsists of the propositions identi ed by lters as described in section .
.
in addition no two di erent states can be associated with the same set of atomic propositions i.e.
the set of atomic propositions associated with a state univocally identify it.
the inference process starts from an initial dtmc characterized by a set of statessthat contains the initial state s0and a sink state ethat models users who leave the system a stochastic matrix pwith only one non zero element p e e a labeling function lde ned as follows 280ip timestamp url .
.
.
home .
.
.
admin l o g i n .
.
.
anncs s a l e s .
.
.
admin e d i t listing log le excerpt the listing does not report the user agents l s fstartgifs s0 fendgifs e otherwise a reward function that assigns to all the states ins.
non null rewards can be added as discussed in section .
.
this initial dtmc is shown in figure a .
the inference engine builds the dtmc incrementally by processing the rows of the log le and inferring transitions between states ins.
the engine processes each row in four steps .extracting the destination state the inference engine examines the propositions associated by the lters with the current row r. the engine ignores the rows associated with an empty set of propositions since they represent transitions irrelevant in our context.
the engine associates rwith a destination state d2s such thatl d l wherelis the set of propositions associated with r. ifddoes not belong tosyet the inference engine adds the new state dtosand updates the labeling function laccordingly.
.extracting the user identi er the engine assumes that distinct ip addresses correspond to di erent users thus assigns a unique identi er to each new ip address extracted from the rows in the log le.
in normal operational conditions ip addresses may not be uniquely associated to users and it may happen that di erent users that browse the system in di erent occasions may have the same ip address.
to cope with this scenario the inference engine refers to the timestamps of the transitions and assumes that requests issued from the same ip address with signi cantly di erent timestamps are issued by di erent users i.e.
they are given distinct user identi ers .
the minimum temporal distance between timestamps to consider two requests with the same ip address as issued by distinct users is a parameter called userwindow .
.extracting the source state if the previous step assigned a new user identi er to r the engine assumes that ris the rst interaction of the user with the system and associates the initial state s0as the source state.
if the interaction rcomes from an existing user a known ip address the inference engine retrieves the destination state of the most recently processed row characterized by the same ip address and assigns such state as the source state of r. .computing the probabilities the engine uses the transitions extracted from the log le to update two sets of counters that are initially set to zero a set of counters ci jfor each pair of states si sj 2s s and a set of counters tifor each statesi2s.
the engine increments both the counter ci jfor each transition from state sitosjand the counter ti for each transition whose source state is si independent of its destination state.
the counter tirepresents the numberof times the users exited state si while counter ci jrepresents the number of times the users moved from state sito statesj.
the inference engine updates the counters for each row in the log le that corresponds to a transition in the model and uses these counters to compute the i j entry of the stochastic matrix pthat represents the probability of traversing the edge from state sito statesj by computing the following frequency p si sj ci j ti for all pairs of states siandsj.
the probability p si sj is computed as the ratio between the number of traversals of the transitions from state sitosjand the total number of traversals of the transitions exiting state si and corresponds to the maximum likelihood estimator forp si sj .
the probabilities can be recomputed incrementally after adding any number of transitions or states to the dtmc.
figure illustrates the inference process described so far referring to the log le in listing and the lters shown in listing .
the log entries in listing have been excerpted from the interactions of two users with the ndyourhouse.com application.
the bear engine starts from the initial dtmc shown in figure a and proceeds incrementally through the log le.
bear associates the rst row with the proposition homepage .
sincesdoes not contains any state ssuch thatl s fhomepageg the engine adds a new state s1tos and extends the labeling function withl s1 fhomepageg.
being this the rst transition in the log the ip address has not been already encountered thus the engine considers state s0as the source state for the inferred transition hs0 s1i .
the engine increments the counterst0andc0 and consequently sets p s0 s1 to .
figure b shows the resulting dtmc.
the second row corresponds to a successful login and bear associates it with the set of propositions flogin success control panelg.
the engine associates this row with the new destination state s2and updates the labeling function l s2 flogin success control panelg.
the ip address is new and thus the engine creates a new user identi er and associates the transition with the initial state s0yielding to a transitionhs0 s2i.
the engine increments the counters related to the new transition t0 andc0 and sets p s0 s2 andp s0 s1 to .
figure c shows the resulting dtmc.
the engine processes the third and fourth row in a similar way.
it associates the third row with a new destination state s3such thatl s3 fsales anncsg.
since the row is associated with the same ip address of the rst one the source state corresponds to the destination state of the last transition generated by this user s1 and results in the transition hs1 s3i.
the engine increments the counters t1andc1 and consequently sets p s1 s3 .
when processing the fourth row bear generates a transition from s2 the destination state of the second transition that corresponds to the same ip address to s4with l s4 fcontrol panelg.
the engine increments the counterst2andc2 and setsp s2 s4 .
figure d shows the resulting dtmc.
when the userwindow timeout for a certain ip address expires the engine assumes that the user associated with that address left the system.
as a consequence a later request from the same address is considered as issued by a new user and the source state is s0.
as soon as2811 e end starts0 a e end starts0s1homepage b .
1e end start s0s1homepage .
s2 login success control panel c .
e end start s0s1homepage .
s2 login success control panel s3sales anncs 1s4 control panel d .
.
e end start s0s1homepage .
s2 login success control panel s3sales anncs 1s4 control panel e figure dtmc inference process .
.
s1 s6 sales anncs s3 sales page page 1 s2renting page page 1 s4renting anncs s7 tou homepage .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
s50.
.
.
.
.
starts00.
.
.
.
.
.
.
.
.
.
.
contacts figure partial dtmc of ndyourhouse.com a the timeout expires the engine generates a new transition that leads from the destination state of the last transition issued by the expired ip address towards the nal state e. if for example we assume that the userwindow timeout expires for both the considered users the engine generates the transitionshs4 eiandhs3 ei and updates the corresponding counters.
a new interaction occurring after the timeout that leads to state s3and involves the ip address of one of previous requests generates a new user and a transition hs0 s3i.
figure e shows the resulting dtmc.
by processing the log le of the ndyourhouse.com application with a set of lters that match the propositions shown in the third column of table the bear engine produces a dtmc with states and transitions.
figure shows a subset of the generated model.
being the model a subset of the complete dtmc the probability of the transitions exiting a state may not sum to one.
the obtained dtmc captures the behaviors of all users regardless of the class they belong to.
in general the bear inference engine infers a dtmc for each class of users.
for instance if a log le contains entries characterized by ve di erent user agents and ten di erent locations the inference engine infers fteen dtmcs one for each class of useragents and one for each class of user locations.
each log entry processed by the engine contributes uniquely to the inference of the dtmcs associated to its user classes.
for instance a row associated with the user classes exempli ed in section .
contributes to infer a dtmc associated to the class useragent mozilla and a dtmcassociated to the class location boston .
in this setting each inferred dtmc captures the behavior of a speci c class of users.
the classi ers identi ed by the application designer directly a ect the number of inferred dtmcs and their level of abstraction.
.
annotating the models rewards are non negative values the designer can associate with propositions to model bene ts or losses.
the bear engine uses the rewards associated with propositions in the setup phase to automatically annotate the states of all inferred dtmcs.
in the absence of rewards bear returns a set of models with default value zero for the reward function of the states.
in the presence of rewards the bear inference engine computes the reward of the states as the sum of the rewards of the propositions associated with the states.
let us consider the dtmc in figure and let us assume that the designer assigns rewards and to the propositions salespage andpage respectively then the bear engine assigns to s3 .
rewards are a general purpose and abstract tool to augment the inferred dtmcs with domain speci c metrics of interests.
designers can use rewards to capture both technical and non technical metrics of interest.
they assign rewards to propositions in the setup phase and do not need to know the structure and the number of the inferred models which are inferred only later while monitoring the application behavior.
here we illustrate the use of rewards with an example related to a refactoring of the ndyourhouse.com application which aims at increasing the number of announcements displayed to the customers and thus gives special recognition to the states that display a large number of announcements.
this can be easily achieved by annotating the propositions with rewards that depend on the number of announcements they are related with.
they associate reward with the proposition homepage because homepage displays six announcements.
likewise they associate reward with both the propositions page 1and page n because they contain nine announcements and so on.
the bear engine computes the reward functions of the states of the inferred dtmcs accordingly.
for instance in the dtmc in figure s1 since s1is associated only to proposition homepage s2 and s3 .
.
specifying the properties in this step the application designers de ne the properties of interest using probabilistic computation tree logic pctl augmented with rewards .
pctl with rewards is282a probabilistic branching time temporal logic based on the classic ctl logic that predicates on a state of a markov process.
hereafter we provide a formal de nition of this logic through the following recursive grammatical rules truejaj j jp.
p jr. r x j u t i kjc kj3 wherep2 .
2f g t2n f1g r2r andk2z andarepresents an atomic proposition.
the operatorr.
r supports the speci cation of properties that predicate over rewards.
let us rst discuss the semantics of basic pctl ignoring the reward operator.
formulae originated by the axiom are called state formulae those originated by are instead called path formulae .
the semantics of a state formula is de ned as follows sj true sj a i a2l s sj i s2 sj 2i sj 1and sj sj p. p i pr j j s .
p where pr j j s is the probability that a path originating in ssatis es .
a path originating in ssatis es a path formula according to the following rules j x i j j 1u t 2i j t j k j j let us now discuss intuitively the reward operator r. r r .
r i k is true in state sif the expected state reward to be gained in the state entered at step kalong the paths originating in smeets the bound .
r. r .
r c k is true in state sif froms the expected reward cumulated afterksteps meets the bound .
r. r .
r is true in state sif froms the expected reward cumulated before reaching a state where holds meets the bound .
r. the bear analysis engine processes pctl properties relying on the prism probabilistic model checker5.
more precisely a bear property is composed of a preamble in curly brackets and a pctl expression.
the preamble denes the scope of the property while the pctl expression speci es the formula to be veri ed with the model checker.
the scope of the property is expressed as a string in the fromname regex that identi es the user classes the pctl formula refers to.
more precisely the rst part of the scope i.e.
name is the name of a user class as speci ed with the classi ers for instance a useragent while the second part i.e.
regex corresponds to a regular expression.
the property veri cation is restricted to the users that belong to the speci ed class and that matches the regular expression in the scope of the property.
as an example the designers of ndyourhouse.com who are interested in the probability that users with a certain browser for instance mozilla will eventually contact a sales 5we present the ptcl properties in the prism syntax.agent can use the following property fuseragent mozilla gp ?
as another example the application owners who are interested in the number of announcements displayed to mobile users for example android or ios users through all the states up to the nal state can use the following property fuseragent androidjios gr ?
that refers to the reward function that associates the number of displayed announcements to each state as exempli ed in the previous paragraph.
the pctl properties depend only on the propositions and designers can specify them without knowing the structure of the inferred models in terms of states or transitions.
designers can also express properties in structured english that can be automatically translated into pctl properties .
indeed designers can be completely agnostic of the complexity of the formal tools such as the probabilistic model checking engine and pctl used by the bear analysis engine.
.
analyzing the models the process is completed with the analysis of the properties speci ed by the application designer.
the bear engine exploits the scope in the preamble of the properties to identify the set of relevant dtmcs among the inferred models.
as discussed in section .
the bear inference engine generates a distinct dtmc for each user class.
for each property to be processed the analysis engine selects the dtmcs associated with the user classes that match the regular expression indicated in its scope.
for example when analyzing property the analysis engine selects the dtmcs associated to the mozilla user agents.
the bear analysis engine selects one or more dtmcs depending on the user agents contained in the log entries processed during the inference process.
for instance it may select the dtmc associated to the user agents of mozilla .
as well as the dtmcs associated to user agents of di erent versions of mozilla since they all match the regular expression in the property s scope.
if the scope of the property selects multiple dtmcs the bear analysis engine merges them and synthesizes a single dtmc as described hereafter.
let fd1 d2 dngbe the set of dtmcs selected according to the scope of a propertyp wheredk hsk pk lk ki for each k n and letukbe the user class associated to dk for each k n the merging procedure produces a new dtmc t hst pt lt tiwhere the set of states is the union of the sets of states of the input dtmcs st k nsk states of di erent input dtmcs may correspond to the same state of the merged dtmc since by construction two states are equal if and only if they are characterized by the same propositions see section .
.
the transition probabilities are computed according to the law of total probability pt si sj x k npk si sj pi uk wherepi uk corresponds to the probability for a user associated to the selected user classes that exited statesito belong to the speci c user class uk.
the labeling function is computed as lt s lk s ifs2sk the readers should notice that if a state belongs to more than one dtmc the labeling function of all the dtmcs returns the same value by construction.
the reward function is computed as t s k s ifs2sk the readers should notice that if a state belongs to more than one dtmc the reward function of all the dtmcs returns the same value by construction.
in addition the distribution of rewards is independent from the merging process since as explained in section .
they are de ned for propositions.
the synthesized dtmc captures the behaviors of several user classes.
for example the dtmc synthesized for property captures the behavior of all mozilla users independently of the speci c version they use while each original dtmc captures the behavior of users with a speci c version of the mozilla browser.
similarly the dtmc synthesized for property captures the probabilistic behavior of all mobile users independently of the speci c type of device.
the bear analysis engine evaluates the property for the synthesized dtmc using a model checker prism in our experiments .
the approach does not depend on the model checker and works with other engines such as mrmc as well as with ad hoc mechanisms for e cient runtime analyses like the approach described by filieri et al.
.
the bear analysis engine processed property resulting in a probability of that mozilla users will contact a sale agent and the property resulting in announcements displayed on average by mobile users.
.
bear models at work bear captures information about user interactions with web applications.
in this section we illustrate how this information can be used to enrich or modify the initial requirements and to keep them current as user behaviors evolve over time.
bear can thus be used to support the evolution of web applications.
indeed many web applications are initially designed with little or no knowledge of how its nal users will behave.
resorting to the experience collected for similar applications if any only provides rough data.
in addition user behaviors may change with their familiarity with the application and for many other reasons.
the analysis of the dtmcs by means of probabilistic model checking produces information about navigation anomalies emerging behaviours and new attitudes of users that wellcomplements the initial incomplete requirements.
we show how this can be done by illustrating the use of bear in different maintenance actions for the ndyourhouse.com case study introduced in section .
the results discussed here refer to a log le composed of .
entries that correspond to ten months of users interactions.
we ran the bear inference engine on the log le relying on the lters listed in the third column of table and we obtained dtmcs.
we rst illustrate the use of bear for detecting navigation anomalies and then for inferring emerging behaviours and new attitudes of users.
.
detecting navigational anomalies a navigational anomaly is a di erence between the actual and the expected user navigation actions.
the expected navigation is what has been implemented in the application and is represented by the application s site map .
the actual navigation is instead represented by a path on the dtmcs inferred by bear which corresponds to actual navigations performed by users in reality.
navigational anomalies can be detected by comparing the dtmcs with the site map.
by detecting navigation anomalies we can nd suggestions to improve the application.
we can for example identify frequent users workarounds that may witness the lack of some navigational features.
as an example of navigational anomaly detection let us compare the model produced by bear with the ndyourhouse.com site map by running the bear analysis engine with queries of this kind6 fgp ?
fsjg for every state si sjin the model.
this query speci es the request for the probability of a user to move from state sj to statesi.
because of the empty scope in the properties the analysis engine selected all the inferred dtmcs and synthesized a unique model that represents the behaviour of the whole population of users.
the synthesized model is composed of states and transitions and is partially reported in figure .
the bear analysis engine identi ed several navigational anomalies despite the fact that the application has been in use for more than two years and has been carefully maintained and corrected.
here we illustrate one of them that corresponds to the two transitions exiting states7of figure that occur with non negligible probability in the dtmc but do not correspond to transitions in the application site map.
thus they represent frequent actions performed by users which do not correspond to navigation features of the application.
state s7corresponds to theterms of use page proposition tou that can be reached only from the contacts page state s5 .
the terms of use page does not o er a way to go back to the contacts page.
the anomalous transitions that exit state s7correspond to the users trying to go back to the contacts page state s5 likely using the back button of the browser and ending up in one of the states proceedings s5 statess4ands6 because of the ajax implementation of the application.
the readers should notice that there is no transition from s7to s1that also precedes s5.
this indicates that the log le does not record any attempt of users to go back from s7to s5having reached s5directly from s1.
this is because s1 correspond to the home page and no users felt the need to check the terms of use s7 before consulting renting or sales 6prism not only can evauate the truth or falsity of a property but can also compute probability values.284announcements states s4ands6 .
this anomaly has been corrected by adding a back button to the terms of use page.
although navigational anomaly detection is presently done by manually inspecting and comparing the analysis results with a site map the comparison can be easily automated by using available xml sitemap descriptions.
.
inferring behaviours and attitudes bear can analyze properties that correspond both to emerging behaviors and behaviors that may derive from new requirements.
application designers can use properties to describe the expected behaviors of either all or speci c classes of users as well as the impact of changes in the navigation attitude of users.
here we present the results of the analysis of the ndyourhouse.com log le for properties that represent the di erent type of analyses.
the ndyourhouse.com owners were interested in improving the access to the application in terms of renting versus buying inquires.
to do so one needed to understand what is the probability of a user to browse sales and not renting announcements and vice versa the probability of users to browse renting announcements only.
the former can be found with the query fgp ?
the bear analysis engine indicated that of users are interested in sales announcements only and users are interested in renting announcements only.
the remaining percentage of users look both for sales and renting announcements.
with these data the designers decided to change the homepage that initially displayed a random set of announcements and now displays renting and sales announcement proportionally to the measured users behaviors.
the ndyourhouse.com owners were further interested in possible di erences between mobile versus desktop users.
they simply re ned the above query by adding an ad hoc scope to restrict the analysis to mobile users see property at page .
the analysis engine selected dtmcs out of the initial set of inferred dtmcs and synthesized a single model that captures the behavior of mobile users only which indicated that of the mobile users are interested in sales announcements only.
with this additional information the developers decided to properly customize the mobile home page.
as a nal example the ndyourhouse.com owners were planning a marketing campaign targeting desktop users with a banner published on social networks advertising the website and linked to the sales anncs page.
in this scenario it is crucial to accurately predict the number of database queries generated by the marketing campaign to suitably adapt the website infrastructure to prevent a potential denial of service.
similarly to the example illustrated in section .
developers associated the rewards that represent the number of data base queries needed to display each page of the application to the atomic propositions dened by lters to weight each state of the inferred dtmcs with a reward indicating the impact of that state in terms of queries to the database and formulated the query f ?
!
androidjios gr ?
the query whose scope excludes android and ios users to just focus on desktop users asks for the resource usage r ?
after hitting the sales anncs page.
since the resource usage is measured in terms of database queries the analysis of the property gives the estimate of database queries ofdesktop users after accessing that page.
the analysis engine selected models out of the initial inferred models that capture the behaviors of desktop user and synthesized an appropriate unique model against which to verify the property.
the product between the obtained result and the expected click through rate per hour estimated from previous marketing campaigns or with ad hoc techniques like the one de ned by richardson et al.
represents a reasonable prediction of the database queries generated by the marketing campaign.
similarly we augmented the model with rewards that indicate the average amount of storage consumed by each page request to predict the storage requirements implied by the additional tra c of the marketing campaign.
in general rewards can model every resource that directly depends on users actions and can be represented numerically to support capacity planning and forecasting analyses.
.
performance and scalability we evaluated the performance and scalability of both the bear inference and analysis engine on a ghz intel core i7 8gb ram with java tm1.
.
.
each experiment has been repeated one hundred of times collecting the average result and the standard deviation.
the execution time of the bear inference engine depends on two factors the number of states in the inferred model and the length of the log le.
we generated synthetic log les composed of lines generated ad hoc to produce dtmcs with an increasing number of states.
figure a shows that the bear inference engine can produce a dtmc of states analyzing a log les of lines in few seconds.
figure b illustrates instead the execution time of processing log les of increasing length.
the gure reports the execution time for log les that produce a dtmc of states.
bear processes a log le of lines in around seconds.
inference engine.
the execution time of the bear analysis engine depends on two factors the number of synthesised models and the number of states of synthesised models.
in the experiments discussed below we shows the execution of the synthesis algorithm.
we refer to for the performance of evaluating pctl properties on dtmcs.
we randomly generated fully connected dtmcs composed by states and we measured the execution time needed to synthesise a single model selecting an increasing number of input dtmcs.
figure a shows that the bear analysis engine can synthesise a dtmc from input dtmcs in few seconds.
figure b illustrates instead the execution time of synthesising models with an increasing number of states.
the gure reports the execution time to synthesise input dtmcs.
also in this case bear shows a reasonable execution time.
the gure shows that models composed of states are synthesised in around seconds.
it is important to notice that synthesised modes are not necessarily generated from scratch each time because of an internal caching mechanism.
the log le of the case study is composed of over entries and we conducted all the experiments within few minutes thus con rming the scalability of the approach.
our implementation has been released as an open source artifact7that includes an anonymized excerpt of the ndyourhouse.com log le.
!
!
number of states execution time ms a increasing number of states.
!
!
!!!
!
!!!
!
!!!
!
!!!
!
!!!
!
!!!
!
!!!
!
!!!
!
!!!
!
!!!
!
!!!
!
!!!
!
!!!
!
!!!
!
!!!
!
!
!
!
!
!!!!
number of log lines execution time ms b log of increasing length.
figure inference engine performance evaluation !
!
!
!
!!
!
!
!
!!
!
!
!
!!
!
!
!
!!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!!
number of dtmcs execution time ms a increasing number of dtmcs.
!
!
!!
!
!!!
!
!!
!
!!!
!
!!
!
!!!
!
!
!
!
!
!
!
!
!
!
!
number of states execution time ms b increasing number of states.
figure analysis engine performance evaluation .
related work many existing works address the problem of model inference from execution traces tackling a wide range of research problems that range from mining api patterns inferring speci cations inferring behavioral models for web services and software processes testing web applications and detecting faults .
worth to mention is also perracotta an approach to mine and visualize temporal properties of event traces used to study program evolution and the work by krka et al.
that consists of an approach to mine invariants and improve precision of inferred models.
finally it important to mention the work by beschastnikh et al.
that illustrates synoptic a tool that helps developers by inferring from log les a concise and accurate system model focusing on generating invariant constrained models.
beschastnikh et al.
also discuss in an approach to specify inference algorithms declaratively.
complementary to these approaches there is the work by tonella et al.
that discusses how to nd the optimal approximation in the inference process.
all these solutions represent fundamental tools for developing complex and dependable software systems even if di erently from bear they do not focus on user behaviours that actually represent a crucial factor in applications domains such as user intensive web applications.
the problem of capturing and analysing the user behaviours in web applications through the analysis of log les has been address by many approaches as reported in the survey of facca et al.
.
many of these approaches focus on mining speci c information to perform peculiar tasks.
for example liu and v. ke selj combine the analysis of web server logs with the contents of the requested web pages to predict users future requests .
they capture the content of web pages by extracting character n grams that are combinedwith the data extracted from the log les.
schechter et al.
in use instead a tree based data structure to represent the collection of paths inferred from the log le to predict the next page access.
similarly sarukkai relies on markov chains for link prediction and path analysis.
alternatively yang et al.
focus on predicting accesses for e cient data caching.
these approaches even if extremely helpful for the speci c tasks they have been conceived for lack of general applicability.
di erently the bear approach produces a navigational model that can be used to verify a plethora of di erent properties that span from simple navigational probabilities that may be used for link prediction to more complex properties that may be used for capacity planning analysis as exempli ed in the paper.
indeed the exibility of the proposed approach relies on the expressiveness of the pctl formal logic that allows engineers to encode the properties to be veri ed including domain speci c aspects of the application.
finally it is worth to mention the work by komuravelli et al that illustrates the inference of a probabilistic system given nite set of positive and negative samples and the work by chierichetti et al.
that discusses the approximation of web users with markov models.
.
conclusions and future work we presented a novel inference mechanism conceived adhoc for probabilistic model checking to elicit requirements about emerging users behaviours.
the approach extracts dtmcs that represent the users behaviours from application logs and analyses them by means of probabilistic model checking to identify navigation anomalies and emerging users behaviours.
we are extending the approach with probabilistic timed automata to capture other user behaviors.
.