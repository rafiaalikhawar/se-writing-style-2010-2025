mining configuration constraints static analyses and empirical results sarah nadi university of waterloo canadathorsten berger it university of copenhagen denmarkchristian k stner carnegie mellon university usakrzysztof czarnecki university of waterloo canada abstract highly configurable systems allow users to tailor the software to their specific needs.
not all combinations of configuration options are valid though and constraints arise for technical or non technical reasons.
explicitly describing these constraints in a variability model allows reasoning about the supported configurations.
to automate creating variability models we need to identify the origin of such configuration constraints.
we propose an approach which uses buildtime errors and a novel feature effect heuristic to automatically extract configuration constraints from c code.
we conduct an empirical study on four highly configurable open source systems with existing variability models having three objectives in mind evaluate the accuracy of our approach determine the recoverability of existing variability model constraints using our analysis and classify the sources of variability model constraints.
we find that both our extraction heuristics are highly accurate and respectively and that we can recover of the existing variability models using our approach.
however we find that many of the remaining constraints require expert knowledge or more expensive analyses.
we argue that our approach tooling and experimental results support researchers and practitioners working on variability model re engineering evolution and consistency checking techniques.
categories and subject descriptors d. .
distribution maintenance and enhancement restructuring reverse engineering and reengineering d. .
reusable software general terms design measurement experimentation keywords variability models feature models software product lines reverse engineering static analysis empirical software engineering .
introduction developing highly configurable software that can be tailored to specific needs has been receiving increasing attention by practitioners and researchers.
configuration options or features allow customizing functionality to user needs.
for example providing permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
icse may june hyderabad india copyright acm ... .
.
figure overview of proposed approach and empirical study options to reduce energy consumption and memory footprint when building for embedded systems.
features can range from those tweaking small functional and non functional aspects to those enabling whole subsystems of the software.
large configurable systems can easily have thousands of features with complex constraints that restrict valid combinations and values.
examples of such systems range from large industrial software product lines to prominent open source systems software such as the linux kernel with currently more than features .
such configurable systems are usually divided into a problem space and a solution space as shown in figure explained shortly .
the problem space describes the supported features and their dependencies while the solution space is the technical realization of the system and the functionalities specified by the features i.e.
code and build files .
thus features cross both spaces they are described in the problem space and mapped to code artifacts in the solution space.
ideally configurable systems have a formal documented variability model describing the problem space.
automated and interactive configurators use such models to support users in navigating a complex configuration space .
however many systems have no documented variability model or rely on informal textual descriptions of constraints e.g.
the freebsd kernel .
as thepermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may june hyderabad india copyright acm ... .
number of features and their dependencies increases configuration becomes more challenging and introducing an explicit variability model is often the way out to conquer complexity and have one central human and machine readable place for documentation.
manual extraction of constraints and construction of such models for existing systems is a daunting task though which calls for automation.
identifying the sources of configuration constraints is essential to support automatically creating variability models.
we expect a broad spectrum of constraints in a variability model ranging from purely low level technical constraints which reflect code dependencies e.g.
multi threaded i o locking depends on threading support in an operating system kernel to purely non technical constraints which reflect domain specific knowledge e.g.
marketing requirements placed by a project manager or a sales department .
the former can be discovered by just analyzing the code while the latter can be found through talking to experts or looking at requirements documents for example.
however additional sources of constraints may lie between these two ends.
for example there may be technical constraints not discoverable except through specific tests on particular platforms.
we are not aware of any study that empirically investigates how prevalent different sources of constraints are in existing variability models.
such knowledge provides valuable insights into the practicability of automatically constructing a variability model.
in this work we investigate the different sources of configuration constraints and to what extent we can automatically andaccurately extract constraints from existing implementations using static analysis techniques.
figure shows an overview of the approach we follow as well as our empirical evaluation.
our work has both a significant engineering contribution extracting constraints from c code and an empirical contribution assessing recoverability and classifying constraints in existing variability models .
extracting constraints.
our work focuses on c based systems with build time variability using the build system and c preprocessor.
since many features are directly used in implementation files we assume that many of the configuration constraints are reflected in the code.
we design and implement a scalable approach to extract constraints statically.
we use two specifications all valid configurations should build correctly and they should all yield different products.
for both specifications we propose novel scalable extraction strategies based on the structural use of ifdef directives on parser and type errors and on linker checks.
whereas prior work approximated constraints from preprocessor directives we design an infrastructure that accurately represents c code based on our previous research on variability aware parsing and type checking .
in a nutshell we statically analyze build time variability effectively without examining an exponential number of configurations.
we demonstrate scalability by extracting constraints from four large open source systems uclibc busybox ecos and the linux kernel and evaluate accuracy by comparing the constraints to existing developer created models.
our results show that our extraction is and accurate respectively for the two specifications we use and can scale to the size of the linux kernel in which we extract over unique constraints.
assessing recoverability.
we use our described infrastructure to automatically measure how many of the constraints in the existing variability models correspond to technical statically discoverable code dependencies.
our results show that on average of variability model constraints reflect technical dependencies statically recoverable from code with our techniques.
while around prevent build time errors of these model constraints correspond to simple nesting relationships in the code.classifying constraints.
to classify the sources of configuration constraints we qualitatively inspect a sample of the variabilitymodel constraints our analysis could not recover.
we find five cases where the source of the constraint is beyond our analysis.
for example we find that of these constraints stem from domainknowledge.
this includes knowing which features are related and should thus appear in the same configurator menu or knowing which functionalities only work on certain hardware.
to the best of our knowledge our work is the first to quantify the recoverability of variability model constraints from code using an automated approach and to qualitatively analyze non recovered ones.
contributions and perspectives.
to summarize our contributions are i an extension and combination of existing analyses e.g.
linker analysis and type checking to extract configuration constraints ii a novel constraint extraction technique based on feature use and code structure iii a quantitative study of the effectiveness of such techniques to recover constraints and iv a qualitative study of sources of constraints in existing models.
our results can be used in various ways.
for re engineering approaches our analyses extract constraints that can be used to re construct variability models.
for the evolution of systems our techniques provide the basis for detecting inconsistencies and proposing fixes.
our empirical data in particular identifying which types of code analysis recover most variability model constraints can help to design effective and optimized analysis techniques.
finally information about which constraints appear in the code and where they stem from e.g.
preventing a type error may be useful for developers in understanding intricate dependencies when configuring these systems .
.
configuration constraints variability support in configurable systems is usually divided into aproblem space and a solution space as shown in figure .
this separation allows users to make configuration decisions without knowledge about low level implementation details.
therefore both spaces need to be consistent such that any feature dependencies in the solution space are enforced in the problem space and no conflicts occur.
we are interested in understanding the different types of configuration constraints defined in the problem space and how much of these are technically reflected in the solution space.
this can be done by extracting configuration constraints from both the problem and solution spaces and then comparing and classifying them as shown in figure .
.
problem space features and constraints are described in the problem space with varying degrees of formality either informally in plain text such as in the freebsd kernel or using a formal variability model expressed in a dedicated language e.g.
kconfig as in our subject systems.
given such a model configurator tools can support users in selecting valid configurations and avoiding invalid ones.
figure shows the configurator of busybox one of our subject systems.
the configurator displays features in a hierarchy which can then be selected by users while enforcing configuration constraints such as propagating choices or graying out features that would lead to invalid configurations.
constraints reside in the feature hierarchy a child implies its parent and in additional specifications of crosstree constraints .
specifically the feature hierarchy is one of the major benefits of a variability model as it helps users to configure a system and developers to organize features.
enforced configuration constraints can stem from technical restrictions present in the solution space such as dependencies between141figure configurator of the busybox system two code artifacts.
additionally they can stem from outside the solution space such as external hardware restrictions.
constraints can also be non technical stemming from either domain knowledge outside of the software implementation such as marketing restrictions or from configurator related restrictions such as to organize features in the configurator or to offer advanced choice propagation.
we illustrate these kinds of constraints with examples from two of our subject systems.
in the linux kernel a technical constraint which is reflected in the code is that multi threaded i o locking depends on threading support due to low level code dependencies.
a technical constraint which cannot be detected from the code is that 64gb memory support excludes and cpus which stems from the domain knowledge that these processors cannot handle more than 4gb of physical memory.
in busybox see figure a technical constraint is that enable iso date format requires date since the code of the former feature would just not be compiled without the latter.
a non technical configurator related constraint is that feature date itself appears under the menu feature coreutils in the configurator hierarchy.
there has been much research to extract constraints from existing variability models within the problem space .
such extractors can interpret the semantics of different variability modeling languages to extract both hierarchy and cross tree constraints as shown in figure .
.
solution space the solution space consists of build and code files.
our focus is on c based systems that realize configurability with their build system and the c preprocessor.
the build system decides the source files and the preprocessor the code fragments to be compiled.
the latter is realized using conditional compilation preprocessor directives such as ifdef s. to compare constraints in the variability model to those in the code we must find ways to extract global configuration constraints from the code as opposed to localized code block constraints .
we assume that there is a solution space code level constraint if any configuration violating this constraint is ill defined by some specification.
there may be several sources of constraints that fit such a description.
however in this work we identify two tractable sources of constraints i those resulting from build time errors and ii those resulting from the effect of features in build files and in the structure of the code e.g.
ifdef usage .
we now explain the justification behind these two specifications.
.
.
build time errors every valid configuration needs to build correctly.
in c projects various types of errors can occur during the build preprocessor errors parsing errors type errors and linker errors.
our goal is to detect configuration constraints that prevent such build errors.
we derive configuration constraints from the following specification ifndef y 2void foo ... endif ifdef x 6void bar foo endif a type error1 ifdefined z defined x ... ifdef w ... endif ... endif b feature effect listing examples of constraint sources specification .
every valid configuration of the system must not contain build time errors such that it can be successfully preprocessed parsed type checked and linked.
a naive but not scalable approach to extract these constraints would be to build and analyze every single configuration in isolation.
if every configuration with feature x compiles except when feature yis selected we could infer a constraint x!
y. for instance in listing 1a the code will not compile in some configurations due to a type error in line the function foo is called under condition x while it is only defined under condition y thus the constraint x!
ymust always hold.
the problem space needs to enforce this constraint to prevent invalid configurations that break the compilation.
however already in a medium sized system such as busybox with boolean features this results in more than 2881configurations to analyze which is more than the number of atoms in the universe.
we show how this can be avoided in section .
.
.
feature effect ideally variability models should also prevent meaningless configurations such as redundant feature selections that do not change the solution space.
that is if a feature ais selected in a configuration then we expect that aadds or changes some code functionality that was not previously present.
if a feature has no effect unless other features are selected or deselected a configurator may hide or disable it simplifying the configuration process for users.
determining if two variants of a program are equivalent is difficult even undecidable .
we approximate this by comparing whether the programs differ in their source code at all.
if two different configurations yield the same code this suggests some anomaly as opposed to errors described in section .
.
in the model.
we extract constraints that prevent such anomalies.
we use the following specification as a simplified conservative approximation of our second source of constraints specification .
every valid configuration of the system should yield a lexically different program.
the use of features within the build system and the preprocessor directives for conditional compilation provides information about the context under which selecting a feature makes a difference in the final product.
in the code fragment in listing 1b selecting w without selecting zandxwill not break the system.
however only selecting wwill not affect the compiled code since the surrounding block will not be compiled without zandxalso being selected.
thus w!z xis a feature effect constraint that should likely be in the model even though violating it will not break the compilation.
.
problem statement we can summarize that variability model constraints arise from different sources.
we discussed two such sources above where the constraints exist for technical reasons discoverable from the code.
our work strives to automatically extract such constraints.
however 142figure variability aware approach to extract configuration constraints from code it is not clear if other sources of constraints exist beyond implementation artifacts and how prevalent they are.
we therefore also strive to identify the sources of any non recovered constraints.
improving empirical understanding of constraints in real systems is crucial especially since several studies emphasize configuration and implementation challenges for developers and users due to complex constraints .
such knowledge not only allows us to understand which parts of a variability model can be reverse engineered and consistency checked from code and to what extent but also how much manual effort such as interviewing developers or domain experts would be necessary to achieve a full model.
for example a main challenge when reverse engineering a variability model from constraints is to disambiguate the hierarchy .
thus this process could be supplemented by knowing which sources of constraints relate to hierarchy information in the model.
we focus on the sources of constraints described in both specifications above since such constraints can be extracted using decidable andscalable static analysis techniques.
there are of course also other possible kinds of constraints in the code resulting from errors or other specifications e.g.
buffer overflows or null pointer dereference .
however many of these require looking at multiple runs of a program which does not scale well or requires imprecise sampling or produce imprecise or unsound results when extracted statically.
.
extracting code constraints one of our main goals is to extract configuration constraints from the solution space in order to compare them to the variability model constraints cf.
figure .
to do so we use the two specifications described in section to extract code constraints from preprocessor errors parser errors type errors linker errors and feature effect .
figure shows an overview of the approach we use and which we explain in details in this section.
as shown in figure before analyzing the code in a specific c file we first need to know under which condition the build system includes this file to be able to accurately derive constraints.
we use the term presence condition pc to refer to a propositional expression over features that determines when a certain code artifact is compiled.
for example a file with pc hush ash is compiled and linked iff the features hush orash are selected.
to avoid an intractable brute force approach of analyzing every possible configuration and to avoid incompleteness from sampling strategies we build on our recent research infrastructure typechef to analyze the entire configuration space of c code with build time variability at once .
our overall strategy for extracting code constraints is based on parsing c code without evaluating conditional compilation directives.
we extend and instrument typechef to accomplish this.
typechef only partially preprocesses a sourcefile it resolves all include s and expands all macros but preserves conditional compilation directives.
on alternative macro definitions or include s it explores all possibilities similar to symbolic execution.
as shown in figure partial preprocessing produces a token stream in which each token is guarded by a corresponding pc including the file pc which is subsequently parsed into a conditional abstract syntax tree which can be subsequently type checked.
this variability aware analysis is conceptually sound and complete with regard to a brute force approach of analyzing all configurations separately.
however it is much faster since it does the analysis in a single step and exploits similarities among implementations of different configurations see for more details.
in previous research with typechef it was typically called with a given variability model such that it only emits error messages for parser or type problems that can occur in valid configurations discarding all implementation problems that are already excluded by the variability model.
this is the classic approach to find consistency errors which a user can subsequently fix in the implementation or in the variability model .
since we need to extract all constraints without knowledge of valid configurations we use typechef in a different context where we run it without a variability model and process all reported problems in all configurations.
we extend and instrument typechef and implement a new framework farce feature constraint extractor which analyzes the output of typechef and the structure of the codebase with respect to preprocessor directive nesting derives constraints according to our low level specifications and provides an infrastructure to compare extracted constraints between a variability model and code.
we now explain our design decisions and methodology using the c code in listing adapted from busybox as a running example.
.
preprocessor parser and type constraints preprocessor errors parser errors and type errors are detected at different stages of analyzing a file.
however the post processing used to extract constraints from them is similar thus we discuss them together.
in contrast linker errors require a global analysis over multiple files which we discuss separately.
preprocessor errors.
a normal c preprocessor stops on error directives which are usually intentionally introduced by developers to avoid invalid feature combinations.
we extend the partial preprocessor to log error directives with their corresponding presence condition and to continue with the rest of the file instead of stopping on the error message.
in listing line shows a error directive that occurs under the condition ash nommu .
parser errors.
similarly a normal c parser stops on syntax errors such as mismatched parentheses.
our typechef parser reports1430 ifdef ash represents the file presence condition ifdef nommu error ... ash will not run on nommu machine endif ifdef editing 7static line input t line input state 9void init initediting intmaxlength ifdef max len endif endif editing 20intmain ifdef editing vi ifdef max len line input state flags endif endif endif ash listing running example of c code with compile time errors adapted from ash.c in busybox an error message together with a corresponding presence condition but continues parsing for other configurations.
in listing a parser error occurs on line because of a missing semicolon if max len is not selected.
in this case our analysis reports a parser error under condition ash editing max len .
type errors.
where a normal type checker reports type errors in a single configuration typechef s variability aware type checker reports each type error together with a corresponding pc.
in listing we detect a type error in line if editing is not selected since line input state is only defined under condition ash editing on line .
typechef would thus report a type error under condition ash editing vi max len editing .
constraints.
following specification we expect that each file should compile without errors.
every error message with a corresponding condition indicates a part of the configuration space that does not compile and should hence be excluded in the variability model.
for each condition fof an error we extract a configuration constraint f. in our running example we extract the following constraints rewritten to equivalent implications ash!
nommu from the preprocessor ash!
editing!max len from the parser and ash!
editing vi max len !editing from the type system.
.
linker constraints to detect linker errors in configurable systems we build a conditional symbol table for each file during type checking.
the symbol table describes all non static functions as exported symbols and all called but not defined functions as imports.
all imports and exports are again guarded by corresponding pcs.
we check only linkage within the application and discard all symbols defined in libraries with additional analysis though we could also model library symbols with corresponding presence conditions .
we show the conditional symbol table without type information of our running example in table assuming that symbol initediting is defined under pc init in some other file not shown .
for more details on conditional symbol tables see .table example of two conditional symbol tables file symbol kind presence condition listing init export ash editing main export ash initediting import ash editing other file initediting export init in contrast to the file local preprocessor parser and type analyses linker analysis is global across all files.
from all conditional symbol tables we derive linker errors and corresponding constraints.
a linker error arises when a module imports a symbol that is not exported def use or when two modules export the same symbol conflict .
we derive constraints for each symbol sas follows def use s f f 2imp s f !
f y 2exp s y conflict s f1 y1 2exp s f2 y2 2exp s f16 f2 y1 y2 where imp s andexp s look up all imports and exports of symbol sin all conditional symbol tables and return a set of tuples f y each determining the file fin which sis imported exported and pc y. the def use constraints ensure that the pc of an import implies at least one pc of a corresponding export while the conflict constraints ensure mutual exclusion of the pcs of exports with the same function name.
an overall linker constraint can be derived by conjoining all def use andconflict constraints for each symbol in the set of all symbols s v s2sdef use s conflict s .
if the two files shown in table were the only files in the system we would extract the constraint ash editing!init for symbol initediting .
.
feature effect to ensure specification of lexically different programs in all valid configurations we detect the configurations under which a feature has no effect on the compiled code and create a constraint to disable the feature in those configurations.
the general idea is to detect nesting among ifdef s when a feature occurs only nested inside an ifdef of another feature such as editing that occurs only nested inside ifdef ash in our running example the nested feature does not have any effect when the outer feature is not selected.
hence we would create a constraint that the nested feature should not be selected without the outer feature because it would not have any effect editing!ash in our example.
unfortunately extraction is not that easy.
extracting constraints directly from nesting among ifdef directives produces inaccurate results because features may occur in multiple locations inside multiple files and ifdirectives allow complex conditions including disjunctions and negations.
hence we develop the following novel and principled approach deriving a constraint for each feature s effect from pcs throughout the system.
first we collect all unique pcs of all code fragments occurring in the entire system in all files including the corresponding file pc as usual .
technically we inspect the conditional token stream produced by typechef s partial preprocessor and collect all unique pcs note that this covers all conditional compilation directives if ifdef else elif etc.
including dynamic reconfigurations with define and undef .
to compute a feature s effect we use the following insights given a set of pcs pfound for code blocks anywhere in the project and the set of features of interest f then we say a feature f2fhas an no effect in a pc f2piff is equivalent to f where x means substituting every occurrence of finxbyy.144in other words if enabling or disabling a feature does not affect the value of the pc then the feature does not have an effect on selecting the corresponding code fragments.
furthermore we can identify the exact condition when a feature fhas an effect on a pc f. in all configurations in which the result of substituting fis different using xor f f .
this method is also known as unique existential quantification.
putting the pieces together to find the overall effect of a feature on the entire code in a project we take the disjunction of all its effects on all pcs.
we then assume that the feature should only selected if it has an effect resulting in the following constraint f!
f2pf f this means that we choose to disable a feaure by default when it does not have an effect on the build.
alternatively we could enable a feature by default and forbid disabling it when disabling has no effect we just need to negate fon the right side of the above formula.
however we assume the more natural setting where most features are disabled by default and so we look for the effect of enabling a feature.
in our running example we can identify five unique pcs excluding tokens for spaces and line breaks ash ash nommu ash editing ash editing max len and ash editing vi max len .
to determine the effect of max len we would substitute it with true andfalse in each of these conditions and create the the following constraint assuming that max len does not occur anywhere else in the code max len!
ash ash ash nommu ash nommu ash editing ash editing ash editing true ash editing false ash editing vi true ash editing vi false max len!ash editing editing vi this confirms that max len only has an effect iff ash and eitherediting orediting vi are selected.
in all other cases the constraint enforces that max len remains deselected.
additionally to determine how many constraints the build system alone provides we do the same analysis for file pcs instead of pcs of code blocks.
note that the feature effect analysis on the build system alone is incomplete and provides only a rough approximation.
.
empirical study we now study four real world systems with existing variability models.
as shown in figure our objectives are o1to evaluate accuracy andscalability of our extraction approach.
this is done by checking if the configuration constraints we extract from implementation are enforced in existing variability models.
o2to study the recoverability of variability model constraints using our approach.
specifically we are interested in how many of the existing model constraints reflect implementation specifics that can be automatically extracted.
o3toclassify variability model constraints.
in other words we want to understand which constraints are technically enforced and which constraints go beyond the code artifacts.
this allows us to understand what reverse engineering approaches to choose in practice.
for all three objectives we report the key results in this paper.
refer to our online appendix for full datasets additional statistics and detailed qualitative results .
.
study setup .
.
subject systems we choose four highly configurable open source projects from the systems domain.
all are large industrial strength projects that realize variability with the build system and the c preprocessor.
our selection reflects a broad range of variability model and codebase sizes in the reported range of large commercial systems.
our subjects comprise the following systems and variability model sizes.
the first three use the kconfig and the last one uses the cdl language and configurator infrastructure in the problem space.
we choose systems with exsiting variability models to have a basis for comparison.
uclibc is an alternative resource optimized c library for embedded systems.
we analyze the x86 64 architecture in uclibc v0.
.
.
which has c source files and features described in a kconfig model.
busybox is an implementation of gnu shell tools ls cp rm mkdir etc.
within one binary executable.
we study busybox v1.
.
with c source files and documented features described in a kconfig model.
the linux kernel is a general purpose operating system kernel.
we analyze the x86 architecture of v2.
.
.
which has c files and features documented in a kconfig model.
ecos is a highly configurable realtime operating system intended for deeply embedded applications.
we study the i386pc architecture of ecos v3.
which has c source files and features described in a cdl model.
in all systems the variability models have been created maintained and evolved by the original developers of the systems over periods of up to years.
using them reduces experimenter bias in our study.
prior studies of the linux kernel and busybox have also shown that their variability models while not perfect are reasonably well maintained .
in particular ecos and linux have two of the largest publicly available variability models today.
.
.
methodology and tool infrastructure we follow the methodology shown in figure .
we first extract hierarchy and cross tree constraints from the variability models of our subject systems problem space .
we rely on our previous analysis infrastructures lv at and cdltools which can interpret the semantics of kconfig and cdl respectively to extract such constraints and additionally produce a single propositional formula representing all enforced constraints see for details .
we then run typechef on each system and use our developed infrastructure farce to derive solution space constraints from its error output specification cf.
section .
.
and the conditional token stream specification cf.
section .
.
.
as a prerequisite we extract file pcs from build systems by reusing our build system analysis tool kbuildminer for systems using kbuild busybox and linux and a semi manual approach for the others.
.
.
evaluation technique after problem and solution space constraints are extracted we compare them according to our three objectives.
to address o1 evaluate accuracy and scalability we verify whether extracted solution space constraints hold in the propositional formula representing the variability model problem space of each system.
we also measure the execution time of the involved analysis steps.
for this objective we assume the existing variability model as the ground truth since it reflects the system s configuration knowledge which developers have specified.
to address o2 recoverability of model constraints we determine whether each existing variability model constraint holds in the solution space constraint formulas we extract.
we use the term145table constraints extracted with each specification per system and percentage holding in the variability model vm code analysisuclibc busybox ecos linux extracted found in vm extracted found in vm extracted found in vm extracted found in vm specification preprocessor constr.
parser constr.
type checking constr.
linker constr.
total specification feature effect constr.
feature effect build constr.
n a n a total recoverability instead of recall because we do not have a ground truth in terms of which constraints can be extracted from the code.
since no previous study has classified the kinds of constraints in variability models we cannot expect that of them are enforced in the code and can be automatically extracted.
to address this gap ando3 classification of variability model constraints we show the types of constraints we could automatically recover and manually investigate randomly sampled non recovered model constraints to characterize constraints that are not found by our analysis.
note that averages and numbers across subjects are geometric means.
.
o1 accuracy and scalability we expect that all constraints extracted according to specification hold in the problem space variability model as these prevent any failure in building a system.
constraints that do not hold either indicate a false positive due to an inaccuracy of our implementation or an error in the variability model or implementation cases we analyze separately.
such checks have been the standard approach in previous work on finding bugs in configurable systems where inconsistencies between the model and implementation are identified as errors.
in contrast specification prevents meaningless configurations that lead to duplicate systems.
thus we expect a large number of corresponding constraints but not all to occur in the variability model.
measurement strategy.
we measure accuracy as follows.
we keep constraints extracted in the individual steps of our analysis separate.
that is for each build error specification and each feature effect specification we create a separate constraint fi.
for each extracted constraint fi we check whether it holds in the formula yrepresenting all the problem space constraints from the variability model with a sat solver by determining whether y fi is a tautology i.e.
whether its negation is not satisfiable .
we record execution time of each analysis step separately to measure the scalability of our approach.
for all analysis steps performed by typechef and kbuildminer which can be parallelized we report the average and the standard deviation of processing each file.
in addition we provide the total processing time for the whole systems assuming sequential execution of file analyses.
for the derivation of constraints which can not be parallelized we report the total computation time per system.
results.
table shows the number of unique constraints extracted from each subject system in each analysis step and the percentage of those constraints found in the existing variability model.
on average across all systems constraints extracted with specification and specification are and accurate respectively.
both results show that we achieve a very high accuracy across all four systems.
specification is a reliable source of constraints where our tooling produces only few false positives extracted constraintstable duration in seconds unless otherwise noted of each analysis step.
average time per file and standard deviation shown for analysis using typechef.
global analysis time shown for post processing using farce uclibc busybox ecos linux file pc extraction manual n a 20typecheflexing parsing .
.
type checking symbol table creation .
.
.
sum for all files sequential 13hr 5hr 7hr 376hrfarcefeature effect build constr.
n a feature effect constr.
.7hr preprocessor constr.
.
.
1hr parsing constr.
39min type checking constr.
.3hr linker constr.
5hr total farce time 3min .4min 34min 10hr that do not hold in the model .
interestingly a accuracy rate for specification suggests that variability models in fact prevent meaningless configurations to a high degree.
table shows execution times of our tools which were executed on a server with two amd opteron processors cores each and 128gb ram.
significant time is taken to parse files which often explode after expanding all macros and include preprocessor directives.
our results show that our analysis scales reasonably where a system as large as linux can be analyzed in parallel within twelve hours on our hardware.
accuracy discussion.
our approach is highly accurate given the complexity of our real world subjects.
while further increasing accuracy is conceptually possible improving our prototypes into mature tools would require significant industrial scale engineering effort though beyond the scope of a research project.
regarding false positives we identify the following reasons.
first the variability model and the implementation have bugs.
in fact we earlier found several errors in busybox and reported them to the developers .
we also found one and reported it in uclibc.
second all steps involved in our analysis are nontrivial.
for example we reimplemented large parts of a type system for gnu c and reverse engineered details of the kconfig and cdl languages as well as the kbuild build system.
little inaccuracies or incorrect abstractions are possible.
after investigating false positives in uclibc linker constraints we found that many of these occur due to incorrectly manually extracted file pcs.
in general intricate details in makefiles such as shell calls complicate their analysis .
third our subjects implement their own mechanisms for providing and generating header files at build time according to the configuration.
we implemented emulations of these project specific mechanisms to statically mimic their behavior but such emulations are likely incomplete.
we are currently investigating using symbolic146table number and percentage of variability model hierarchy constraints recovered from each code analysis uclibc busybox ecos linux of vm hierarchy constraints count recovered from code specification preprocessor constr.
parser constr.
type checking constr.
linker constr.
total unique specification feature effect constr.
feature effect build constr.
total unique total unique constraints recovered execution of build systems in order to accurately identify which header files need to be included under different configurations.
scalability discussion.
our evaluation shows that our approach scales in particular to systems sharing the size and complexity of the linux kernel.
however we face many scalability issues when combining complex constraint expressions into one formula mainly in linux and ecos.
feature effect constraints were particularly problematic due to the unique existential quantification see section .
which causes an explosion in the number of disjunctions in many expressions thus adding complexity to the sat solver.
to overcome this we omit expressions including more than ten features when aggregating the feature effect formula.
this resulted in using only and of the feature effect constraints in linux and ecos respectively.
the threshold was chosen due to the intuition that larger constraints are too complex and likely not modeled by developers.
we faced similar problems in deriving other formulas such as the type formula in linux but mainly due to the huge number of constraints and not their individual complexity.
this required several workarounds and required high memory consumption in the conversion of the formula into conjunctive normal form required by our sat solver.
thus we conclude that extracting constraints according to our specifications scales but can require workarounds or filtering expressions to deal with the explosion of constraint formulas.
refer to our online appendix for more details.
.
o2 recoverability we now investigate how many variability model constraints can be automatically extracted from the code.
measurement strategy.
while the extraction approach directly gives us individual constraints to count and compare the situation is more challenging when measuring constraints from the variability model.
variability models in practice use different specification languages.
semantics of a variability model are typically expressed uniformly as a single large boolean function expressed as a propositional formula describing the valid configurations.
after experimenting with several slicing techniques for comparing these propositional formulas we decide to exploit structural characteristics of variability models that are commonly found.
in all analyzed models we can identify child parent relationships hierarchy constraints as well as inter feature constraints cross tree constraints .
this way we count individual constraints as the developer modeled them which is intuitive to interpret and allows us to investigate the different types of model constraints.
note that we only account for binary constraints as they are most frequent whereas accounting for n ary constraints is an inherently hard combinatorial problem.
technically we perform the inverse comparison to that in section .
we compare whether each individual problem space constraint ycholds intable number and percentage of variability model crosstree constraints recovered from each code analysis uclibc busybox ecos linux of vm cross tree constraints count recovered from code specification preprocessor constr.
parser constr.
type checking constr.
linker constr.
total unique specification feature effect constr.
feature effect build constr.
total unique total unique constraints recovered the conjunction of all extracted solution space constraints fiin each code analysis category i.e.
whether v ifi ycis a tautology.
results.
in tables and we show how many of the variability models hierarchy and cross tree constraints can be recovered automatically from code.
since the same constraint can be recovered by different analyses we also show the total number of unique constraints for each specification and for each system.
across the four systems we recover of hierarchy constraints and of cross tree constraints.
to compare the two specifications we use to extract solution space constraints we show the overlap between the total number of recovered variability model constraints both hierarchy and cross tree aggregated across both specifications in the venn diagrams in figure .
these illustrate that in all systems a higher percentage of the variability model constraints reflects feature effect constraints in the code specification .
overall we can recover of variabilitymodel constraints using both specifications across the four systems.
recoverability discussion.
we can see a pattern in terms of where variability model hierarchy and cross tree constraints are reflected in the code.
as can be seen in table the structure of the variability model hierarchy constraints often mirrors the structure of the code.
specification alone can extract an average of the hierarchy constraints.
an interesting case is linux where already of the hierarchy constraints are mirrored in the nested directory structure in the build system i.e.
file pcs .
we conjecture that this results from the highly nested code structure where most individual directories and files are controlled by a hierarchy of makefiles almost mimicking the variability model hierarchy .
on the other hand although harder to recover cross tree constraints seem to be scattered across different places in the code e.g.
linker and type information and seem more related to preventing build errors than hierarchy constraints are.
interestingly figure shows that there is no overlap with the exception of one constraint in uclibc between the two specifications we use to recover constraints.
this aligns with the different reasoning behind them one is based on avoiding build errors while the other ensures that product variants are different .
the fact that our static analysis of the code could only recover of the variability model constraints suggests that many of the remaining constraints require different types of analysis or stem from sources other than the implementation.
we look at this in more details in our final objective.
.
o3 classification of variability model constraints to investigate which parts of a variability model can be automatically extracted our aim is to understand the kinds of constraints that147exist in variability models and the analyses and knowledge needed to identify them.
measurement strategy.
to automate parts of the investigation we use the recoverability results from section .
to automatically classify a large number of constraints as technical and statically discoverable which reduces manual investigation to the remaining ones.
to manually investigate the remaining constraints we randomly sample non recovered constraints hierarchy and cross tree constraints from each subject systems .
we then divide these constraints among the authors for manual investigation.
results.
from our manual investigation of non recovered constraints we classify five cases in which constraints could not be statically detected from the code with our approach.
in figure we summarize the overall classification of the sources of constraints including those automatically found through our static analysis.
case .
additional analyses required we find constraints where the relationship might have been recovered by using more expensive analysis such as data flow analysis or testing more advanced build system analysis system specific analysis such as the use of applets in busybox or the kernel module system in linux or assembly analysis .
case .
more relaxed code constraints for constraints we recover constraints that relate the two features but not directly as they appear in the variability model.
for example our analysis would recover the following constraint in busybox blkid type!volumeid fat blkid while the variability model constraint is blkid type!blkid .
this suggests that devlopers may use configuration features differently in the code than what they enforce in the model.
case .
domain knowledge for at least one of the features is not used in implementation.
we find two cases where this occurs.
the first is that the constraint is configurator related where that feature is used only internally in the variability model to support its menu structure and constraint propagation in the configurator.
for example has network support in uclibc is amenuconfig which helps organizing networking features in the configurator into a menu format.
this happens in constraints.
from their domain knowledge developers usually know which features are related and are thus grouped together in the same menu.
for the remaining constraints we find that this unused feature represents some form of platform or hardware knowledge.
for example in linux serio ct82c710 !x86 64 where the first feature controls the port connection in that particular chip but which seems to only work with an x86 64 architecture.
such hardware dependencies are not statically detectable in the code and can only be found through testing the software on the different platforms.
we believe that developers use their domain expertise usually gained from previous testing experiences to enforce such dependencies.
case .
limitation in extraction in constraints our analyses could not recover the constraint because it indirectly depends on some non boolean comparison which we do not handle or because it depends on c code which we do not analyze.
case .
unknown.
we could not determine the rationale behind the remaining constraints.
first this indicates that finding constraints manually is a very difficult and time consuming process which enforces the need for automatic extraction techniques such as those we present here.
second the fact that we could not manually extract the constraints that were not automatically recovered by our analysis gives us confidence in our results.
it might be that such constraints also require additional analyses which we could not easily determine or that they rely on external developer knowledge.
a uclibc b busybox c ecos d linux figure overlap between specifications and in recovering variability model constraints.
an overlap means that the same model constraint can be recovered by both specifications classification discussion.
our classification shows that many of the variability model constraints can be statically extracted with our approach.
this seems motivating for automated extraction tools.
we have especially seen that of constraints are reflected in the nesting structure and can be easily extracted using specification since it only depends on extracting the file pcs and lexing the files which are cheaper steps in the analysis see table .
however our manual analysis of the remaining constraints also shows that many of the constraints can only be found through more expensive analysis such as testing.
additionally it seems that several constraints in the model are non technical and are simply responsible for organizing the structure of the model for configuration purposes.
we have also come across constraints that could only stem from domain knowledge.
both these facts suggest that additional developer and expert input may always be needed to create a complete model.
finally the constraints we find in case of our manual analysis explain why an analysis may produce accurate constraints and yet recover no variability model constraints.
for example the type analysis in linux extracts over .
million constraints which are accurate and yet only recovers cross tree constraints in table .
we plan to investigate the feasibility of comparing nonbinary constraints to overcome this.
.
threats to v alidity internal validity.
our analysis extracts solution space constraints by statically finding configurations that produce build time errors.
conceptually our tools are sound and complete with regard to the underlying analyses i.e.
they should produce the same results achievable with a brute force approach compiling all configurations separately .
practically however instead of well designed academic prototypes we deal with complex real world artifacts written in several different decades old languages.
our tools support most language features but do not cover all corner cases e.g.
some gnu c extensions some unusual build system patterns leading to minor inaccuracies which can have rippling effects on other constraints.
we manually sample extracted constraints to confirm that inaccuracies reflect only a few corner cases that can be solved with additional engineering effort which however exceeds the possibilities of a research prototype .
we argue that the achieved accuracy while not perfect is sufficient to demonstrate feasibility and support our quantitative analysis.
our static analysis techniques currently exploit all possible sources of constraints addressing build time errors.
we are not aware of other classes of build time errors checked by the gcc clang infrastructure.
we could also check for warnings lint errors but those are often ignored and would lead to many false positives.
other extensions could include looking for annotations or comments inside the code which may provide variability information.
however even in the best case this is a semi automatic process.
furthermore dynamic analysis techniques test cases or more expensive static techniques such as data flow analysis may also extract additional148information.
however the benefit gained from performing such expensive analyses still needs investigation.
the percentage of recovered variability model constraints in linux and ecos may effectively be higher since we limit the number of constraints we use in the comparison due to scalability issues.
therefore we can safely use the reported numbers as the worst performance of our tools in these settings.
additionally we cannot analyze non c codebases which also decreases our ability to recover technical constraints in systems such as ecos where of the codebase comprises c and assembler code which we excluded.
construct validity.
different transformations or interpretations of the variability model may lead to different comparison results than the ones achieved e.g.
additionally looking at ternary relationships in the model .
properly comparing constraints is a difficult problem and we believe the comparison methods we choose provide meaningful results that can also be qualitatively analyzed.
additionally this strategy allowed us to use the same interpretation of constraints in all subject systems.
external validity.
due to the significant engineering effort for our extraction infrastructure we limit our study to boolean features and to one language c code with preprocessor based variability.
we apply our analysis to four different systems that include the largest publicly available systems with explicit variability models.
although our systems vary in size and cover two different notations of variability models all systems are open source developed in c and from the systems domain.
thus our results may not generalize beyond that setting.
.
related work this work builds upon but significantly extends our prior work.
we reuse the existing typechef analysis infrastructure for analyzing ifdef based variability in c code with build time variability .
however we use it for a different purpose and extract constraints from various intermediate results in a novel way including an entirely novel approach to extract constraints from a feature effect heuristic.
furthermore we double the number of subject systems in contrast to prior work.
the work is complementary to our prior reverse engineering approach for feature models an academic variability modeling notation where we showed how to get from constraints to a feature model suitable for end users and tools.
now we focus on deriving constraints in the first place.
techniques to extract features and their constraints have been developed before mainly to support the re engineering maintenance and evolution of highly configurable systems.
from a process and business perspective researchers have developed approaches to re engineer existing systems into an integrated configurable system .
these approaches include strategies to make decisions when to mine which assets to mine and whom to involve.
others have developed re engineering approaches by analyzing non code artifacts such as product comparisons .
in contrast to techniques using non code and domain information we extract technical constraints from code.
from a technical perspective previous work has attempted to extract constraints from code with ifdef variability .
most attempts focus on the preprocessor code exclusively looking for patterns in preprocessor use but do not parse or even type check the underlying c code.
that is they are at most roughly equivalent to our partial preprocessor stage.
prior attempts to parse unpreprocessed code typically relied on heuristics unsound or could only process specific usage patterns incomplete .
for instance our previous work used an inexact parser to approximate parts of our specification and .
our new infrastructureis sound and complete allowing accurate subsequent syntax type and linker analyses.
complementary to analyzing build time ifdef variability some researchers have focused on load time variations through program parameters.
rabkin and katz design an approach to identify loadtime options from java code but not constraints among them .
reisner et al.
use symbolic execution to identify interactions and constraints among configuration parameters by symbolically executing a system s test cases .
such dynamic analysis can identify additional constraints as discussed in section .
.
however scalability of symbolic execution is limited to medium size systems up to 14k lines of code with up to options in whereas our build time analysis scales to systems as the linux kernel.
we also avoid using techniques such as data flow analysis due to scalability issues.
in future work although challenging to scale we plan to investigate additional analysis approaches that track load time and runtime variability e.g.
from command line parameters .
data flow analysis symbolic execution and testing tailored to variability are interesting starting points.
finally researchers have investigated the maintenance and evolution of highly configurable systems.
there has been a lot of research directed at studying and ensuring the consistency of the problem and solution spaces .
however most of this work has analyzed features in isolation either in the problem space or in the solution space to identify modeling practices and feature usage.
some work has also looked at both sides to study coevolution or to detect bugs due to inconsistencies between models and code .
while our results can enhance these consistency checking mechanisms our goal is to clarify where constraints arise from and to demonstrate to what extent we can extract model constraints from the code.
.
conclusions we have engineered static analyses to extract configuration constraints and performed a large scale study of constraints in four real world systems.
our results raise four main conclusions.
automatically extracting accurate configuration constraints from large codebases is feasible to some degree.
our analyses scale.
we can recover constraints that in almost all cases assure a correct build process.
in addition our new feature effect heuristic is surprisingly effective accurate .
however variability models contain much more information than we can extract from code.
our scalable static analysis can only recover of the model constraints.
qualitative analysis shows additional types of constraints resulting from runtime or external dependencies often already known by experts or used for model structuring and configurator support.
while cross tree constraints in variability models mainly prevent build time errors major parts of the feature hierarchy can be found using our feature effect heuristic.
the feature hierarchy is one of the major benefits of using variability models.
it helps users to configure and developers to organize features.
with our results reverse engineering a feature hierarchy can be substantially supported.
manually extracting technical constraints is very hard for non experts of the systems even when they are experienced developers.
we experienced this first hand giving a strong motivation for automating the task.
.