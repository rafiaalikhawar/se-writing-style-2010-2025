automated software architecture security risk analysis using formalized signatures mohamed almorsy john grundy and amani s. ibrahim centre for computing and engineering software systems swinburne university of technology melbourne australia swin.edu.au abstract reviewing software system architecture to pinpoint potential s ecurity flaws before proceeding with system development is a critical milestone in secure software development lifecycles .
this includes identifying po ssible attack s or threat s cenarios that target the system and may result in breaching of system security.
additionally we may also assess the strength of the system and its security architecture using well known security metrics such as system attack surfa ce compartmentalization least privilege etc.
however existing efforts are limited to specific predefined security properties or scenarios that are checked either manually or using limited toolsets.
we introduce a new approach to support architecture security analysis using security scenarios and metrics.
our approach is based on formal izing attack scenario s and security metrics signature specification using the object constraint language ocl .
using formal signatures we analyse a target system to loca te signature matches for attack scenarios or to take measurements for security metrics .
new scenarios and metrics can be incorporated and calculated provided that a formal signature can be specified .
our approach supports defining security metrics and scenarios at architecture design and code levels.
we have developed a prototype software system architecture security analysis tool .
to the best of our knowledge this is the first extensible architecture security risk analysis tool that supports both me tric based and scenario based architecture security analysis.
we have validated our approach by using it to capture and evaluate signatures from the nist security principals and attack scenarios defined in the capec database.
index terms software security architecture security risk analysis formal attack patterns specification common attack patterns enumeration and classification capec i. introduction software architecture plays a vital role in the soundness and flexibility of complex software systems .
while software architecture is usually expensive to change after system development it is potentially cheaper to analyze early during system development .
this both helps in assuring that stakeholders requirements have been met and aids in discovering flaws while modification is still a fraction of time and cost compared w ith later updates .
architecture analysis has different goals.
this includes assessing system maintainability usability sustainability and security and resilience against attacks.
existing efforts to assess and evaluate software architecture against these quality attributes are classified into two main techniques i scenario based architectural analysis focusing on generating sometimes using b rainstorming workshops a set of evaluation scenarios based on the evaluation requirements and ii metrics based approaches focusing on developing metrics that can be used in assessing software architecture.
evaluating the security properties of software at early development stages helps in identify ing security risks potential security related weaknesses in the software architecture and areas that violate security requirements of stakeholders.
these architecture and design flaws represent of total reported vulnerabilities .
many of these flaws cannot yet be discovered using existing security analysis tools.
the s ecurity analysis task is usually conducted at different phases of the software develop ment lifecycle under different names and using different artifacts .
architecture security risk analysis is usually conducted at design phase using system architecture and design models.
it targets identifying architecture and design security flaws .
vulnerability a nalysis is usually applied during development and testing using source code or after system development using system binaries.
these efforts ta rget identifying existing security bugs in the system under test .
in this paper we focus on a rchitecture securi ty risk analysis .
most existing architecture security risk analysis efforts depend on a set of predefined metrics that have been hardcoded or implemented in the analysis tools .
scenario based efforts usually use security requirements and objectives as a source to develop the required security sc enarios to be validated in a given software architecture .
key problems are the lack of automated tool support for analyzing system architectures lack of flexible and familiar architecture evaluation criteria specification language limited consideration of the software operational enviro nment capabilities details .
to address these issues we introduce a new comprehensive architecture security analysis schema .
this schema captures details of a given system attack scenario including categories preconditions consequences signatures etc .
a key entry is the attack signature .
this signature specifies a set of in variants that when matched indicate that the given architecture vulnerable to the specified attack.
we adopt the declarative and formal object constraint language ocl to capture such signatures.
this makes it eas ier for a development team usually familiar with ocl to develop their own scenarios for assessing their software systems architectures.
we also use ocl to specify architectural securit y metrics used in assessing c ieee icse san francisco ca usa accepted for publication by ieee.
c ieee.
personal use of this material is permitted.
permission from ieee must be obtained for all other uses in any current or future media including reprinting republishing this material for advertising or promotional purposes creating new collective works for resale or redistribution to servers or lists or reuse of any copyrighted component of this work in other works.662system and security architecture soundness .
our approach supports extensible security metrics specification where new user defined architectural security metrics can be introduced and evaluated without tool customization or development of new plug ins.
we have developed a system security meta model that helps in validating the ocl based scenarios and metrics signatures .
this meta model is extensible enab ling users to capture other perspectives relevant to their architecture analysis task.
each attack or metric can be assigned a specific weight.
this helps in performing automated architectural trade off analysis between system potential architectur es or be tween different systems.
we capture system description and security in two dif ferent models to help in assessing security and architecture both separately and combined.
the details of the system to be analyzed are captured in a system description model sd m using uml with a uml profile that helps capturing interrelations between different system structure elements.
security details are captured in a separate security specification model ssm .
this captures security objectives refined security requiremen ts security architecture security zones mechanisms and services and the security controls patterns and functions used to realize the specified security.
section ii introduces a set of security scenarios and metrics we have identified from existing architecture security analysis efforts and we discuss possible signature s for these.
section iii discusses our approach covering the attack scenario schema signature specification and our ocl based analysis tool.
section iv discusses implementation detai ls of our approach and section v summarizes our evaluation results .
section vi discusses key strengths and weaknesses and areas for further research .
section vii reviews the key related efforts .
ii.
architectural security scenarios and metrics we discuss some of the security attack scenarios and metrics commonly used in assessing software architecture during the security risk analysis task.
this is neither a comprehensive nor a complete list of possible scenarios or metrics.
however we try and cover most well known scenarios and metrics frequently used.
the example s ignatures used here are not meant to be complete or sound.
security experts have to develop detailed signatures that can be reused by other software engineers in assessing different systems.
a. archi tecture security analysis scenarios developing security scenarios to be used in assessing software architecture is a key task in scenario based architecture analysis approaches.
however it is a very complicated task because it requires deep knowledge of t he security domain which is usually not feasible for all software engineers.
the stride model and eop card game give guidance in identifying such security scenarios.
however they still depend h eavily on engineers experience to analyze the architecture of the software under test.
recently a new community effort introduced the common attack pattern enumeration and classification capec as a reference tha t can be used in assessing systems security.
it provides a comprehensive list of possible attack patterns that are frequently used to breach systems security.
however capec is not yet formalized enough for use in automated architecture security analysis tools.
we discuss below a few of the key patterns in this repository.
we note that these attacks may have other signatures and specifications when it comes to source code level analysis bugs i.e.
for vulnerability analysis.
man in the middle attack this attack intercepts communications between two components.
the attacker makes independent connections with the victims and relays messages between them making them believe that they are talking directly to each other.
the signature of such attack is to have an unsecure connection between two components or if the components communicate in an untrusted zone.
denial of service dos attack this attack aims to make a system or one of its key resources unavailable for legitimate users.
dos attacks have diff erent formats with different signatures.
some use invalid inputs in terms of type format.
or size .
others overwhelm a system with requests.
possible signatures of such attack include i a publicly accessible component that does not use input validatio n control or firewall to validate incoming requests or ii a public interface that does not implement appropriate authentication control to filter requests.
data tampering attack an attacker can tamper with data at rest storage in transmission or during processing if data is manipulated as plaintext.
possible signatures of these attacks include i a system component that operates in an untrusted host malicious insider ii sending data between components or to a client in plaintext or iii absence of appropriate security authorization control.
injection attack this attack exploits the lack of input validation controls to pass in malicious inputs that can be used to gain higher privileges modify data or crash a system.
different types of i njection attacks include sql i njection os command injection and xml injection.
the signature is that system components do not apply suitable input filtration on user inputs or on inputs from other untrusted components.
b. architecture security metrics devel oping security metrics to be used in assessing software architecture is also a very complicated task.
different security metrics exist with different scope of applicability.
these include static vulnerability analysis metrics dynamic vulnerability analys is metrics static architecture security metrics and runtime security metrics.
we discuss some well known metrics used in assessing architecture security .
system architecture security metrics these metrics help assess ing the soundness of the software arc hitecture security .
examples include attack surface metric total public classified attributes and methods critical super classes proportion least privilege and least common mechanisms .
these metrics can be used to assess the exposure exploitability and attack ability of the software system given its architecture design and may be code details.
new architectural patterns such as m ulti tenancy require new 663security metrics that can assess tenants data isolation security elasticity etc.
below we discuss examples of such metrics.
attack surface metric this metric measures the proportion of the system that an attacker can use to attack the system.
this can be measured as the number of system methods th at receive data from the software environment number of methods that return data to the software environment number of communication channels and number of untrusted data items.
the larger the attack surface value the more potentially insecure or vulne rable is the system.
compartmentalization metric compartmentalization means that systems and their components run in different compartments isolated from each other.
thus a compromise of any of them does not impact the others.
this metric can be measured as the number of independent components that do not trust each other performs authentication and authorization for requests calls coming from other system components that the system is based on to deliver its function.
the higher the compartmentalizatio n value the more secure the system.
least privilege metric this metric states that each component and user should be granted the minimal privileges required to complete their tasks.
this metric can be assessed from two perspectives from the security co ntrols perspective we can review users granted privileges.
from the architectural analysis perspective this can be assessed as how the system is broken down to minimal possible actions i.e.
the number of components that can access critical data.
the small er the value the more secure the system.
fail securely metric the system does not disclose any data that should not be disclosed ordinarily at system failure.
this includes system data as well as data about the system in case of exceptions.
this metric c an be evaluated from the security control responses i.e.
how the control behaves in case it failed to operate.
from the system architecture perspective we can assess it as the number of critical attributes and methods that can be accessed in a given component.
the smaller the metric value the likely more secure the system in case of failure.
security architecture metrics these metrics help assess ing the soundness of the system security architecture and mechanisms including security functions and compon ents security patterns and security controls.
nist introduces a set of design principles that should be adopted in developing secure systems.
these include use layered security simplicity of the security design protect information while it is being processed in transit and in storage and never trust external inputs.
we discuss a few examples that can be used to judge such characteristics.
defense in depth layered security metric this metric verifies that security controls are used at different points in the system chain including network security host security and application security.
components that have critical data should employ security controls in the network host and component layer s. to assess this metric we need to capture system architecture and deployment models as well as the security architecture model.
then we can calculate the ratio of components with critical data that apply the layered security principle compared to number of critical components.
isola tion metric this assesses the level of security isolation between system components.
this means getting privileges to a component does not imply accessibility of other co located components.
this metric can be assessed using system architecture and deploy ment models.
components marked as confidential should not be hosted with non confidential public components.
methods that are not marked as confidential should not have access to confidential attributes or methods.
weakness language platformdescription categorynameid target resources likelihoodconsequencespreconditions signature mitigation actionsprevention actions fig.
.
weaknesses definition schema iii.
our approach in our previous work we introduced an ocl based static vulnerability analysis approach supported with a toolset.
this was based on capturing software vulnerability signatu res as ocl invariants.
these expressions are used in conducting program analysis of program source code or binar ies to identify matches to ocl specified vulnerability signatures.
our approach succeeded in locating static vulnerabilities with high precision and accuracy rates.
we now extend this approach here with a step up in the abstraction level.
instead of looking for signatures in source code we look for signatures captured from security scenarios and metrics like those described above in system arch itecture and design models.
we integrate this with our original code vulnerability analysis approach.
our architectural security risk analysis approach is based on i a comprehensive security attack scenarios schema shown in fig that capture s details of a given scenario including relevant platform likelihood preconditions consequences etc.
ii a formal signature specification approach that can capture security scenarios and metrics signatures .
signatures are part of the attac k scenarios schema and iii an architecture security analysis tool that perform s signature based models analysis.
below we focus on the most interesting signature attribute.
a. security scenarios and metrics signature specification existing software securi ty attack signatures in the common attack patterns enumeration and classification capec help understand ing the nature of attack s. the same applies on existing security design principles and metrics.
however these are usually quite informally expressed a nd thus cannot be used in automatically locating potential s for such attacks in target systems.
applying them by hand is error prone and time consuming.
formalizing these descriptions allows architecture analysis tools to semi automate th e analysis proces s. ideally 664the formalization approach used should be extensible enough to support capturing new attacks and metrics signatures for different domains and requirements.
we use ocl as a well known extensible and formal language to specify semantic signa tures of security weaknesses and metrics.
to support specifying and validating ocl based signatures we have developed a system description meta model described in detail in which captures system and security details from the high level objectives down to the source code entities and realization security controls.
this model captures the main entities in an object oriented system including compo nents deployment package hosting services web serve r storage communication channels classes instances inputs input sources output output targets methods new objects objects interactions etc.
moreover it captures security concepts such as security objectives requirements architecture zones mechanisms authentication authorization audit controls etc.
each entity has a set of attributes such as component name provider platform used class name accessibility method name accessibility variable name variable type method call name e tc.
this enables specifying of ocl based scenarios and metrics signatures on different system entities with different abstraction levels.
table i shows some attack scenarios and simplified metrics signatures specified in ocl using our system descriptio n model.
these signatures can be further improved to incorporate system design details and even source code details if available.
these signatures should initially be developed by security experts and captured in a knowledge base while software developer s can further extend such signatures using custom ized and user defined scenario and metric signatures.
b. ocl based system architecture analyzer after formalizing security scenarios and metrics signatures in ocl an ocl based analyzer component conducts stati c analysis of the system and security description details.
this includes system source code represented in abstract syntax tee optional system design architecture and security models to locate and evaluate the specified security scenarios and metrics.
fig.
.
shows the architecture of our analysis component .
to simplify the discussion of the analysis component architecture we use example models from our test bed galactic erp multi tenant cloud application a web based erp sys tem .
below we discuss the main inputs outputs and components of our architecture security analysis tool.
system description model instead of using only the system architecture model to capture and apply security metrics we use a detaile d system description model sdm.
fig.
shows the system description model of our exemplar galactic erp system .
the sdm is developed by system engineers using uml to describe details of the software .
it describe s system features architecture classes behaviour and deployment.
these models cover most of the perspectives that may be required in analysing system architecture security soundness.
not all of these models are needed it depends on system engineers a nd attack scenarios and metrics that they need to evaluate .
some system description details such as class diagrams can be reverse engineere d from source code.
table i. examples of architectural security scenarios and metrics signatures i n ocl id metric signature context system inv man in the middle attack self.components select c1 c1.deploymentzonetype untrusted and self.components.exists c2 c2.channels exists ch ch.targetcomponent c1 and ch.encryptioncontroldeployed false and c1.encryptioncontroldeployed false and c2.encryptioncontroldeployed false any two components that communicate through an unencrypted channel and one or both of them operate in an untrusted zone or do not apply cryptography controls on their communicated messages.
context system inv denial of service attack self.components select c1 c1.deploymentzonetype untrusted and c1.authenticationcontroldeployed false and c1.inputsan itizationcontroldeployed false or c1.host.network.firewal lcontroldeployed false any publicly accessible component that does not operate input sanitization control or application firewall and does not have authentication control.
context system inv datatampering self.components select c1 c1.deploymentzonetype untrusted and self.components.
exists c2 c2.channels exists ch ch.targetcomponent c1 and ch.encryptioncontroldeployed false and c1.encryptioncontroldeployed false and c2.encryptioncontroldeployed false any component that is deployed on an untrusted host malicious insider or zone sends data in plain text or does not operate authorization contro l. context system inv attacksurface self.components select c1 c1.
deploymentzonetype untrusted collect c2 c2.functions size number of functions defined in the provided interfaces of the public system components and number of functions defined in the required interfaces of the system public components that are used by other components.
context system inv compartmentalization self.components select c c.authenticationcontroldeployed true and c.authorizationcontroldeploy ed true size number of architecture components that apply authn.
and authz.
controls on incoming calls work independent and do not trust other components .
context system inv failsecurely self.components collect c c.functions select f f.iscritical true size sum self.components collect c c.functions select f f.iscritical true size siz the average of critical methods and attributes in each system component.
context system inv defense in depth self.select c c.iscritical true and c.authentication controldeployed true and c.authorizationcontroldeployed true and c.cryptographycontroldeployed true and c.host.authenticationcontroldeployed true and c. host.authorizationcontroldeployed true and c. host.cryptographycontrol true size self.select c c.iscritical true size the ratio of critical components that have layered security compared to the total number of critical components in th e system.
system description model source codesecurity specification model...flaws bugs measuresattack scenarios metrics trade off analyzer decision rationalesignature evaluator ocl user defined functions fig.
.
ocl based static security scenarios and metrics analysis tool 665bc ... metaclass operation metaclass class metaclass connection metaclass component metaclass usecase stereotype securityconcept securityobjectives string securityrequirements string securitycontrols string metaclass node metaclass channel de a fig.
.
example of galactic system description model fig.
.
example of galactic security specification model to support mapping security specifications to system entities we developed a new uml profile shown in fig.
a. this extends uml models with attributes that help in i capturing relation ships between different system entities in different models e.g.
a feature entity in a feature model with its related components in the component model and a component entity with its related classes in the class diagram and ii capturing security entities objectives requirements controls mapped on to a system entity.
it captures system features fig.
b including customer employee and order managemen t features system architecture including presentation business and data acce ss layers fig.
c system classes including customerbll orderbll employeebll fig.
d and system deployment including web serve r application server and database server fig.
e .
security specification model security engineers capture security det ails in a separate security specification model ssm .
this enables evaluating both system architecture details and security architecture details both separately and combined.
we have developed a new comprehensive security domain specific visual language secdsvl .
secdsvl covers most of the details required during the security engineering process including security goals and objectives security risks and threats security requirements security architecture for the operational environment and security controls patterns to be enforced.
here we just focus on objectives requirements architecture and controls.
not all these models are mandatory.
engineers decide which models they need to check or incorporate in their security analysis.
fig.
shows an exam ple of the security specification model for the galactic erp system.
this captures security objectives that should be satisfied fig.
a part of the security requirements fig.
b high level security architecture with security services and security mec hanisms to be used in securing galactic fig.
c and security controls and real implementations fig.
d .
the solid black lines between security entities reflect relation ships between security entities e.g.
objectives and requirements and requirement s and realization controls patterns.
system security mappings engineers map security entities objectives requirements controls on system e ntities features components classes .
we support m any to many mappings between security and system entities i.e.
many security entities c ould be mapped on many system entit ies.
mapping of security entities onto hig h level system entities e.g.
a system feature means that the same secur ity entities are mapped to low level system entities e.g.
components and classes.
moreover mapping security objective o to a system entity e implies that all security requirements and controls that are linked to o are also mapped on e .
the dashed red lines between figures and show security to system mappings such as placement of deployment nodes within security zones security objectives that should be met on different components and security solutions mapped to deployment node or system entities etc.
source code abstract program representation to avoid being speci fic to programs written in a specific programming language or with a specific coding style we transform the given system code into an abstract syntax tree ast representation.
the program ast abstracts most of the source code details away from specific l anguage constructs.
we perform further abstraction of this ast using our system description model.
this enabl es evaluati ng the conformance of source code with system and security models.
signature evaluator this is the main component in our analysis tool.
it receives the system and security details and security scenarios vulnerabilities and metrics to be evaluated and generates a list of potential flaws vulnerabilities security holes and security measures.
during analysis the signature evaluator loa ds the defined weaknesses and metrics in the signatures database specified in ocl and compiles these signatures into small analysis programs using ocl 2 c transformation that generate s c code from the se signatures .
these generated analysis programs a nalyze the fed in models to locate entities that match the specified signatures and calculate measure ments specified.
the user defined ocl functions represent a repository of user defined functions that can be used in developing complex scenarios and metri cs signatures.
this includes control flow analysis data flow analysis string analysis taint analysis et c. trade off analysis the previous step produce s a security analysis report with a list of security flaws and measurements .
this report can be used to conduct trade off analysis between different potential software architectures.
the trade off analysis component compares different architectures metric s taking into account metrics weights.
the output of is a recommendation on selected software archit ecture with rationale presented as a radar chart summarizing number of flaws and measurements between different systems or different system architectures as shown in fig.
.
iv.
implementation we briefly describe key implementation details of our formalized a ttack scenarios and metrics specification approach and supporting architectural risk analysis tool.
we used microsoft visual studio2010 uml modeler to capture system description models as an sdm .
we used microsoft visual studio modeling sdk to develop our secdsvl used in capturing security details and our uml profile used in mapping security details onto the target system sdm.
we developed a ui component using visual studio to assist system and security engineers in capturing security scenarios and me trics signatures specified in ocl.
this ui is based on our system description meta model discussed in section iii.
this checks the validity of ocl statements and tests specifications on simple target application models and source code.
we use an existing ocl parser to parse and validate signatures against our system description model.
once validated the signature is compiled into c code that traverses system and security models to find matched flaws or to calculate security metrics values.
to parse the given program source code and generate a system abstract model we use an existing .n et parser nrefactory which supports vb.n et and c .
moreover we have used a c parser written in python 667called pycparser .
we currently support locating attack patterns in c vb.n et c c .
we are working on parsers for php and java.
for a system without source code i.e.
only binaries are available we use an existing de compilation tool ilspy to gene rate source code from binaries using .net languages .
v. evaluation we perfo rmed a detailed evaluation to assess the capabilities of our approach in capturing signatures of software systems architecture security evaluation criteria either as security scenarios or security metrics.
then we assess ed its capabilities in identifying architecture flaws that match weakness scenarios and measur e security metrics.
table ii.
benchmark applications summary benchmark downloads kloc files comps classes method blogengine .
bugtracer galactic .
kooboo nopcommerce rel.
splendidcrm a. benchmark applications we could not find a repository or benchmark set of software architectures to evaluate our approac h and so we decided to use existing open source applications on which to conduct our experiments.
we used reverse engineering to retrieve systems architecture and performed manual analysis to identify security details from applications source code.
we have selected a set of six open sour ce applications developed in .net as our benchmark to evaluate our approach.
table ii summarizes the se applications including known number of downloads size in lines of code number of files number of components number of classes number of methods.
these cover a wide spectrum including galactic erp system developed for internal testing purposes splendidcrm open source crm kooboo open source enterprise cms for websites blogengine open source asp.net .
bloggi ng engine bugtracer open source web based bug tracking and nopcommerce open source ecommerce solution .
b. evaluation experiments setup to evaluate our benchmark applications architecture security we selected a set of four security attack scenarios man in the middle denial of service data tampering and injection attacks and four security metrics attack surface compartmentalization fail securely and defense in depth some exemplar signatures and metrics are presented earlier.
we use d a set of evaluation metrics to measure the soundness and completeness of our analysis technique.
these metrics are precision rate recall rate and f measure.
the precision metric is used to assess the soundness of the approach.
a high precision means that the approach returns more valid results true positive tp than invalid results false positive fp .
thus the maximum precision is achieved when no false positives equation below .
the recall metric is used to assess the completeness.
a high recall mean s the approach returns more valid results true positive tp than misses valid results false negative fn see equation .
the f measure metric combines both precision and recall.
we use it to measure the overall effectiveness weighted harmonic mean .
this metric depends on the importance of the recall rate and the precision rate e.g.
if we are interested in high precision more valid results then we will give precision factor high weight and vice versa.
in our evaluation we assume that the importa nce of precision and recall is equal see equation .
equation equation equation these evaluation metrics can be applied directly on attack scenario based approaches where we can count how many missed or i nvalid scenarios retrieved by our approach.
however most security metrics return values like average min max etc.
this means that we cannot apply our evaluation metrics directly on these security values i.e.
we cannot count how many system security i nstances were missed or incorrectly selected.
to overcome this we have rewritten the metrics expressions expand metrics expression into separate factors that we can examine in terms of fps fns .
c. experimental results except for galactic we did not ha ve experience with the se benchmark applications and their architecture design and security details.
we used reverse engineering to retrieve parts of the system description models mainly class diagram sequence diagram and component diagram from their s ource code repositories using altova umodel.
these benchmark applications were already developed with built in security functions.
we performed manual analysis to identify security controls used in such systems we use these details to develop systems security specification models and where they are currently applied these details represent mappings between the security entities and system entities .
table iii summarizes the results of our experiments from our security scenarios and metrics analysis evaluation .
table iii is divided into two parts security scenarios and security metrics.
columns represent ids of the benchmark applications blogengine bugtracer galactic kooboo nopecommerce splendidcrm.
rows represent flaws and metrics.
we summarize for each application and each attack scenario or security metric analyzed the number of discovered flaws or the metric measured value number of false positive s reported as flaw but the manual analysis showed it is not a flaw and number of false negative s a flaw but missed by our tool .
from our experiments we found that our approach achieves on a verage precision over both security scenarios and security metri cs and on average recall rate on both.
this means that in every reported scenario instances our tool report s valid scenarios and around scenarios are missed.
these values depend on the soundness of the scenarios and metrics signatures.
668table iii.
experimental results of applying our ocl based architectural securi ty risk analysis t ool on benchmark applications .
d discovered flaws m metric measured value fp false positives and fn false negatives scenario metric total security scenarios man in themiddle d fp fn denial of service d fp fn data tampering d fp fn injection attack d fp fn total d fp fn average precision recall and f measure security metrics attack surface m fp fn compartmental ization m fp fn fail securely m .
.
.
.
.
.
fp fn defence indepth m .
.
.
.
.
.
fp fn average precision recall and f measure 531119man in the middle denial of service data tampering injection attack attack surfacecompartmentalizationfail securelydefence in depth fig .
example of the radar chart for applications and 6defense in depth isolation least privilege compartmental ization attack surface metric system criticality fig .
performance of the analysis component table iii also shows i ndicators associated with security metrics.
if the indicator is it means that the higher the metric value the more secure the architecture.
the indicator means that the lower the metric value the more secure the architecture.
totaling the security metrics has no sensible meaning as many have different units some count others use average or ratio .
table iii shows that the man inthe middle attack is the most frequent vulnerability.
we also have injection attack vulnerabilities including sql injection os command injection xpath injection.
denial of service was the least frequent injection attack vulnberability.
when we compare these results with owsap top10 vulnerabilities we found that they reflect relatively the same ranking where injection attacks are ranked number .
although security metrics are helpf ul in comparing two different architectures for the same system trade off analysis they are misleading as they depend on the application scale.
furthermore in the security domain having just one flaw may result in breach of the whole system.
fig.
sho ws a radar chart of the attack scenarios and metrics reported for the applications in our benchmark.
this chart assists in conducting trade off analysis between different applications or different system architectures because it visualizes the different metrics values for different application.
thus users can easily compare and select the best architecture from the security perspective.
from this figure one may decide to use application instead of assuming both are in the same business domain as it is more secure.
d. performance evaluation fig.
shows the time in sec required to analyze the benchmark applications architectures to assessing specified security attack scenarios and metrics using the given set of scenarios and signatures shown in table i. it is clear that the defense in depth metric takes much more time to identify than other metrics.
the system criticality takes the lowest time.
the time required to estimate a given security metric expression depends on the complexity of the specified o cl signature transformed into c code and system size .
vi.
discussion to the best of our knowledge our approach is the first extensible architecture security risk analysis approach that supports both metric based and scenario based architecture security ana lysis.
using ocl provides a flexible formal familiar and extensible specification approach that can capture both metrics and scenarios signatures .
these can be generic applied on different systems and provide a knowledgebase or application specific a pply only to a specific application .
a static scenario and metric analyser was developed based on our vulnerability signatures specification approach to perform analysis on system models at architecture design and code levels .
the scenarios and metrics d atabase can be the responsibility of system engineers or even a community of security organization s to build up this repository.
we have developed an architecture security analysis tool that can be extended without a need for new algorithms modules or 669patches.
our current static analyzer achieves a precision rate of and recall rate .
these can be further improved using additional and more detailed signatures and more accurate description of a target system and its security details.
from our ex periments we conclude that in assessing application security we cannot use measurements in percentages or ratios as they give misleading indicator s as raw value s. this is because results depend on system size.
moreover we cannot use percentage metrics t o assess different systems for the same reason.
although the number of found flaws is an important indicator having one weak point as an attack surface means that the system can be attacked from this point.
some attack points are also much more vulnerable and likely to be exploited than others.
these points can be measured using specialized metrics.
we might then use an overall security metric for a target system using weighted sum of the used measurements .
a key problem with our approach is that the results returned by the analysis tool depend on the soundness of th e scenario and metric specification s i.e.
the ocl expressions .
this can be mitigated by i supporting a knowledge base with a set of covering metrics allowing engineers to select metrics of interest and ii developing a model based security scenario and metrics builder tool where engineers can build complex scenarios and metrics from existing small constructs e.g.
predefined scenarios and base measures.
our security analysis tool works on xml representation of the software description model.
this x ml representation may be extracted from system architecture developed using uml sysml or user defined domain specific language.
moreov er we plan to try and automate the security attacks scenarios and metrics signatures from the existing attack repos itory e.g.
capec that violate customer security objectives.
vii.
related work existing efforts in architecture analysis can be categorized into two main groups scenario based approaches and metrics based approaches.
both have limitations related to approach formality in describing metrics or scenarios extensibility to capture new metrics or scenarios to be assessed and in automation of the architecture analysis process.
a key notice from the existing efforts is that they focus mostly on scenario based analys is.
a possible justification of this tendency is that developing security metrics is a hard problem.
moreover it limits capabilities of the approach compared to user defined or tool supported scenarios.
scenario based analysis kazman et al.
dobrica et al.
and babar et al introduce comprehensive software architecture analysis method s for different milestones.
kazman et al.
introduce a set of criteria that can be used in developing or evaluating an architecture analysis method including identification of the goals properties under examination analysis support and analysis outcomes.
babar et al.
compare and contrast eight different existing architecture analysis approaches.
a key weakness of all these approaches is a lack of tool support.
kazman et al.
introduce atam to identify trade offs between quality attributes of a given system and report sensitivity points in its architecture.
the approach is based on coll aboration of stakeholders to define scenarios to evaluate architecture against.
the analysis is expected to be manually.
faniyi et al.
extend the atam approach to support architecture analysis in unpredictable environments such as cloud computing platforms.
they improve the scenario elicitation process using security testing with implied scenarios unanticipated scenarios of components interactions .
this generates potential scenarios that may lead to security attacks.
although this improved the scenario elicitation proc ess it still requires manual analysis.
a further extension to our approach could be to integrate this approach as the source of our attack and metrics signatures.
halkidis et al.
introduce an architectural risk analysis approach based on locating the existing security patterns in the given system architecture using architecture annotation.
then they use the stride model to generate the set of possible attacks along with their likelihood.
these security attacks can be mitigated using security patterns.
thus the lack of specific security patterns will cause violation of certain security obje ctives in the underlying system architecture.
however their approach does not support developing custom security scenarios to be analyzed in the target system.
admodisastro et al .
introduce a scenario driven architectural analysis approach for black box component based systems.
their analysis framework is extensible to support different pluggable analyzers that perform structure checking quality checking and conformance checking.
however their proposed framework is high level and lacks details of its components.
alkussayer et al .
introduce a scenario based security evaluation framework of software architecture.
they use mapping of security goals requirements security patterns and security threats to identify security scenarios used in evaluating and improving the given system architecture.
metrics based analysis antonino et al.
introduce an indicator based approach to evaluate architecture level security in soa.
they use reverse engineering to extract securit y relevant facts.
they then use system independent indicators and a knowledge base which maintains list of security goals and indicators relevant for every goal.
although the approach is extensible it does not support automated analysis.
sant anna et al.
describe a concern driven quantitative framework for assessing architecture modul arity.
they introduce a set of modularity metrics that are used to assess a given system architecture.
alshammari et al.
introduce a hierarchical security assessment model for object oriented programs.
they define a set of dependent metrics that capture security attributes of the given system.
the proposed metrics are well organized.
however they are not extensible i.e.
are predefined metrics .
moreover they do not consider security architecture details analysis.
heyman et al .
introduce an approach to identify security metrics to measure assess based on mapping user security requirements on security objectives.
for each security objective they define security patterns that are expected to satisfy s uch objectives.
each security pattern has a set of security metrics that are satisfied by the pattern.
the metrics specification approach is 670informal so it does not enable automating the analysis phase.
sohr et al .
describe an architecture centric security analysis approach.
they reverse engineer system architecture from sourc e code using the bauhaus tool.
they conduct manual analysis to identify security flaws existing in the given system architecture.
liu introduce a service oriented framework to analyze attack ability of given software.
they develop a new language to capture system architecture and security deta ils.
using this model they defined a set of built in security metrics to be assesses in a given system architecture.
viii.
summary we introduced a new architecture security analysis approach based on formalizing system architectural security attack scenarios and security metrics using ocl.
target s ystem architecture and security details are captured using uml and our secdsvl respectively.
we have developed a prototype architecture security analysis tool that succeeds in analyzing different systems against differ ent sets of security scenarios and metrics .
we are able to apply these at source code design and architecture levels.
our experiments show that security metrics should not be specified as ratio or percentage metrics as this gives misleading figures of a s ystem s actual security.