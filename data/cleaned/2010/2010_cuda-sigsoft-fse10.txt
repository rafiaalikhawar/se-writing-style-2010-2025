scalable smt based verification of gpu kernel functions guodong li school of computing university of utah ut usa ligd cs.utah.eduganesh gopalakrishnan school of computing university of utah ut usa ganesh cs.utah.edu abstract interest in graphical processing units gpus is skyrocketing due to their potential to yield spectacular performance on many important computing applications.
unfortunately writing such efficient gpu kernels requires painstaking man ual optimization effort which is very error prone.
we contribute the first comprehensive symbolic verifier for kernels written in cuda c. called the prover of user gpu pro grams pug our tool efficiently and automatically analyzes real world kernels using satisfiability modulo theories smt tools detecting bugs such as data races in correctly synchronized barriers bank conflicts and wrong results.
pug s innovative ideas include a novel approach to symbolically encode thread interleavings exact analysisfor correct barrier placement special methods for avoidinginterleaving generation dividing up the analysis over barrier intervals and handling loops through three approaches loop normalization overapproximation and invariant find ing.
pug has analyzed over a hundred cuda kernels from public distributions and in house projects finding bugs as well as subtle undocumented assumptions.
categories and subject descriptors d. .
software engineering software program verification formal methods general terms reliability verification keywords cuda gpu formal verification concurrency satisfiability modulo theories decision procedures .
introduction there is an explosive growth of interest in graphical processing units gpu for speeding up computations occurring at all application scales .
gpus are used iniphones for video processing and on desktop computers for extracting features from medical images.
all future supercomputers will employ gpus.
the main attraction of supported in part by microsoft src tj .
and nsf ccf .
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies arenot made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specificpermission and or a fee.fse november santa fe new mexico usa.
copyright acm ... .
.gpus is that when properly programmed they can yield anywhere from to times more performance compared to standard cpu based multi cores.
unfortunately obtaining this performance requires heroic acts of programming toname a few i one must keep all the fine grained gpu threads busy ii one must ensure coalesced data movements from the global memory that is accessed commonly by cpus and gpus to the shared memory that is accessed commonly by the gpu threads and iii one must minimize bank conflicts when the gpu threads step through the shared memory.
data races and incorrect barrier placementsare frequently introduced during cuda programming.
few tools are available to verify cuda programs.
the emulator that comes with gpus assumes concrete inputs andexecutes only a miniscule fraction of all possible schedules.
bugs often escape either crashing or deadlocking the gpu hardware often requiring a hardware reboot.
gpu kernels are comprised of light weight threads.
their single instruction multiple data simd organization bears little resemblance to thread programs written in c javawith their heterogeneous and heavy weight threads and use of synchronization primitives such as locks monitors.
this requires a fundamentally new approach for analyzing cudakernels.
this paper s main result is that while satisfiabil ity modulo theories smt techniques are a natural choice for analyzing cuda kernels many innovations are essential before such analysis can scale.
efficient techniquesfor encoding concurrent interleavings and analyzing barrier placement must be developed.
one must try to exploit the mostly deterministic style of programming and avoiding interleaving generation.
it is efficient to divide up the analysis over barrier intervals.
finally techniques for efficiently handling loops rather than simply unrolling them must bedeveloped.
we now begin with a few cuda examples and elaborate our innovations.
illustration of cuda.
a cuda kernel is launched as an 1d or 2d gridofthread blocks .
the total size of a 2d grid isgriddim.x griddim.y .
the coordinates of a thread block are angbracketleftblockidx.x blockidx.y angbracketright.
the dimensions of each thread block are blockdim.x and blockdim.y assuming 1d or 2d blocks in this paper .
each block contains blockdim.x blockdim.y threads each with coordinates angbracketleftthreadidx.x threadidx.y angbracketright.
these threads can share information via shared memory and synchronize via barriers syncthreads .
threads belonging to distinct blocks must use the much slower global memory to communicate.
this paper focuses on shared memory races .
consider a sim ple example of a cuda kernel to add bto all the elements of a shared array aof size n void global kernel int a int b int idx blockidx.x blockdim.x threadidx.x if idx n a a b basically each thread accesses a different array location and adds bto it in parallel there are no data races .n o w imagine the programmer wanting to update each array location with badded to the previous array location.
the programmer may not simply change the last line to a a b because there will be data races between adjacent threads.
the programmer may however change thecode to the following void global kernel1 int a int b shared int temp int idx blockidx.x blockdim.x threadidx.x if idx n temp a b syncthreads a barrier if idx n a temp what if the barrier is removed from this code?
obviously the accesses of a a n d a by different threads may cause a race.
this can be detected by examining the symbolic models of two threads as following where privatevariables in a thread are superscripted by the thread id bid andbdim are the short hands for blockidx and blockdim respectively.
threads t 1andt2are assumed to be in the same block.
formally a race occurs if predicate t1.x negationslash t2.x idt1 n idt2 n idxt1 idxt2holds.
as all variables have symbolic values we can consult with a constraint solverto determine whether this predicate is satisfiable.
if so thenthe solver would return a concrete counter example.
if the barrier is present then we only need to check whether the writes to a idx t1 a n d a conflict.
since t1.x negationslash t2.x implies idxt1 negationslash idxt2fort1.
x b d i m .
x andt2.
x b d i m .
x these two writes will not result in a race.
thread t1 thread t2 idxt1 bid.x bdim.x t1.x idxt2 bid.x bdim.x t2.x if idxt1 n r e a d a if idxt2 n r e a d a if idxt1 n write a if idxt2 n write a as another example the scalarprodgpu figure kernel computes the scalar product of vnpairs of vectors with en elements in each vector both sequential and cuda parallelversions are shown .
this kernel coalesces global memory accesses minimizes bank conflicts avoids redundant barriers and reduces serial penalties through tree summation.without such hand crafting steps kernels such as this will perform poorly.
in this paper we present our tool pug that helps detect bugs introduced during kernel design.
internal architecture of pug.
p u gt a k e sak e r n e lp r o gram written in c called kernel c as input.
it first uses the rose compiler to parse the kernel and generates an immediate format then produces an smt expression accordingto the configuration information supplied e.g.the properties to be checked or the number of threads .
we consider only two threads with symbolic identifiers ids for race andsynchronization checking.
users must specify the number of threads for assertion user defined property checking.
the pug generated smt expressions are processed by an smtsolver currently yices for satisfiability checking.
ifthe expression is satisfiable the solver will return a concrete counter example otherwise the kernel is deemed free of thebugs targeted by our analysis.
organization.
we now list some of our novel contributions each of which is later elaborated in its own section.
pug employs a c front end based on the llnl rose framework with customized extensions .
it handles manycuda c features including i arrays and records ii loops conditional statements and function calls iii variable aliases due to pointer expressions and iv lexical scopes.
manyfeatures such as heap allocation and recursive calls are not allowed in cuda simplifying our translation.
we contribute a novel approach to capture all possible interleavings between cuda threads as compact smt for mulae.
in practice working with this smt representation is far more efficient than explicitly enumerating all schedules.
we propose a way to model the semantics of barriers exactly.
we generate smt formulae that help verify that despite the presence of branches and loops all barriers are wellsynchronized.
while we have the ability to model all possible concurrent interleavings it is preferable to avoid resorting to this approach whenever possible .
our observation that enables this optimization is based on the fact that in many cases the existence of races between a given pair of variables is pred icated on the existence of conflicts on other variables.
theexistence of conflicts can be checked over just one canonical interleaving say the one that simply runs one thread till it blocks and then switching over to another.
this helps dra matically improves the overall efficiency.
we propose a way to further scale up this approach by analyzing one barrier interval the portion before and after syncthreads a t a time.
this divide and conquer approach also helps boost efficiency.
.
the translation of loops can become extremely involved especially if the loops are nested and they employ nonlinear strides.
our multi pronged attack is as follows i we normalize loops through program transformation into a unit stride loop ii we over approximate loop computations and iii we can automatically discover compensating invariants that compensate for non linear loop strides frequently found in practice.
.
for many kernels an smt tool may generate a false alarm false bug report when it cannot determine how the kernel formal parameters are constrained by the main program caller .
for example pug assures that the matrix multiplication kernel in the cuda programming guide works only when the size of matrix b is greater or equal to theblock size.
pug is able to reveal such undocumented assumptions.
we have obtained very encouraging results using pug on real examples.
as one example of its multiple uses withrespect to scalarprodgpu we could obtain many valuable analysis results using pug i one may not remove thevoid scalarprodseq sequential version float d c float d a float d b int vn int en for int vec vec vn vec int vbase en vec int vend vbase en double sum for int pos vbase pos vend pos sum d a d b d c float sum parallel version nvidia cudazone site global void scalarprodgpu float d c float d a float d b int vn int en shared float acc for int vec blockidx.x vec vn vec griddim.x int vbase en vec int vend vbase en for int i threadidx.x i acc n i blockdim.x float sum for int pos vbase i pos vend pos acc n sum d a d b acc sum for int stride acc n stride stride syncthreads for int i threadidx.x i stride i blockdim.x acc acc if threadidx.x d c acc figure scalar product sequential and cuda parallel versions barrier on line it will result in a data race but this single barrier suffices to remove all races with respect to the variables da db dcandacc.
ii it is formally guaranteed that no bank conflicts by different threads occur inthis example for all possible values of vn enandacc n iii analysis by pug helped us confirm the assumption that acc nmust be a power of two iv we could establish the equivalence of this kernel to scalarprodseq for small instances of the problem parameters.
we have also encountered examples where some kernels have benign races i.e.
they are still functionally correct.
pug has caught some serious but non obvious bugs in beginner examples.
it has also handled many large examplesfrom the cuda sdk site.
all these examples and pug itself are freely downloadable .
.
encoding serial constructs prog angbracketleftvardecl fundecl angbracketright program vardecl ty id v v a r i a b l e fundecl ty id f angbracketleftty id v angbracketright block function block angbracketleftstmt angbracketright basic block stmt ifexp block conditional for exp exp exp block loop block vardecl exp expression idf angbracketleftexp angbracketright function call ty int ty ty type mdv shared global modifier figure summary syntax of kernel cthis section describes the encoding of serial constructs it gives the formal semantics of a kernel assuming no concur rency.
concurrency is handled in the next section.
the main syntax of kernel c is given in figure and are illustrated by the kernel examples given so far.
the notation angbracketleftterm angbracketright separator used in fundecl block etc.
denotes a sequence of term s separated by separator .
expression exp represents usual c expressions including assignments.
identifiers idfandidvrepresent names of functions and variables respectively.
shared and global variables reside in the gpu and the cpu respectively.
a variable declared without modifier is local to each thread.
we now present the encodingof sequential program structures.
basic statements.
our encoding assigns ssa indexes to variables.
specifically the following translation function constructs a logical formula from single statements and ex pressions where nextand curreturn the next and the current ssa indices of a variable respectively and v unionmulti mapsto x denotes the update of array vby setting the element at ito x. we also give below a simple example of applying .
e 1ope2 .
e1 op e2 v e .
vnext v e v e2 .
vnext v vcur v mapsto e2 v .
vcur v int k int a int i a k a i k i k1 i1 a0 k1 a1 a0 mapsto i1 k1 i2 i1 branches.
the ssa indices of the variables updated in the two clauses of a conditional statement ifcb l k 1elseblk should be synchronized so that subsequent statements have a consistent view of their values.
the following example gives an illustration i1 i0is added into the first clause so that later on i0is invisible and only variable i1will be referred.
here notation itestands for if then else .
ifi j i k j i else i j k ite i0 j1 i0 k1 j1 i0 i1 i0 i1 j0 k0 j1 j0 k1 k0 such synchronization is done at the join node by inserting the following formula into blk and similarly to blk where cur blk v returns v s last ssa index in blk.
vj vifori cur blk v j cur blk v such that i j variable aliasing.
variables may be aliased due to the use of pointers or