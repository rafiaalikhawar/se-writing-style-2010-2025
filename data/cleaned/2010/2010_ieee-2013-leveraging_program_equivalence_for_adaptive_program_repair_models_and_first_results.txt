leveraging program equivalence for adaptive program repair models and first results westley weimer computer science department university of virginia charlottesville v a usa weimer cs.virginia.eduzachary p. fry computer science department university of virginia charlottesville v a usa zpf5a cs.virginia.edustephanie forrest computer science department university of new mexico albuquerque nm usa forrest cs.unm.edu abstract software bugs remain a compelling problem.
automated program repair is a promising approach for reducing cost and many methods have recently demonstrated positive results.
however success on any particular bug is variable as is the cost to find a repair.
this paper focuses on generate and validate repair methods that enumerate candidate repairs and use test cases to define correct behavior.
we formalize repair cost in terms of test executions which dominate most test based repair algorithms.
insights from this model lead to a novel deterministic repair algorithm that computes a patch quotient space with respect to an approximate semantic equivalence relation.
this allows syntactic and dataflow analysis techniques to dramatically reduce the repair search space.
generate and validate program repair is shown to be a dual of mutation testing suggesting several possible cross fertilizations.
evaluating on real world bugs in programs totaling 5mloc and involving tests our new algorithm requires an order of magnitude fewer test evaluations than the previous state of the art and is over three times more efficient monetarily.
index terms automated program repair mutation testing program equivalence search based software engineering i. i ntroduction both the cost of program defects and the cost of repairing and maintaining programs remain high.
for example a cambridge university study places the global cost of general debugging at us billion annually and finds that software developers spend of their programming time fixing bugs or making code work .
in the security domain a symantec study estimates the global cost of cybercrime as us billion annually with a further us billion in lost time and a consumer reports study found that one third of households had experienced a malicious software infection within the last year .
human developers take days on average to address security critical defects and new general defects are reported faster than developers can handle them .
this has driven bug finding and repair tools to take advantage of cheap on demand cloud computing to reduce costs and the burden on developers.
since when automated program repair was demonstrated on real world problems clearview genprog interest in the field has grown steadily with multiple novel techniques proposed autofix e afix debroy and wong etc.
and an entire session at the international conference on software engineering semfix armor par coker and hafiz .
we categorize program repair methods into two broad groups.
some methods use stochastic search or otherwise produce multiple candidate repairs and then validate them using test cases e.g.
genprog par autofix e clearview debroy and wong etc.
.
others use techniques such as synthesis e.g.
semfix or constraint solving to produce a single patch that is correct by construction e.g.
afix etc.
.
we use the term generateand validate program repair to refer to any technique often based on search based software engineering that generates multiple candidate patches and validates them through testing.
although generate and validate repair techniques have scaled to significant problems e.g.
millions of lines of code or mozilla firefox many have only been examined experimentally with few or no explanations about how difficult a defect or program will be to repair.
a recent example is genprog which takes as input a program a test suite that encodes required behavior and evidence of a bug e.g.
an additional test case that is currently failing .
genprog uses genetic programming gp heuristics to search for repairs evaluating them using test suites.
a repair is a patch edit or mutation that when applied to the original program allows it to pass all test cases a candidate repair is under consideration but not yet fully tested.
the dominant cost of such generate and validate algorithms is validating candidate patches by running test cases .
in this paper we provide a grounding of generate andvalidate automated repair and use its insights to improve performance and consistency of the repair process.
we first present a formal cost model motivated in part by our categorization broadly the key costs relate to how many candidates are generated and how expensive each one is to validate.
this model suggests an improved algorithm for defining and searching the space of patches and the order in which tests are considered.
intuitively our new algorithm avoids testing program variants that differ syntactically but are semantically equivalent.
we define the set of candidate repairs as a quotient space i.e.
as equivalence classes with respect to an approximate program equivalence relation such as one based on syntactic or dataflow notions.
further optimizations are achieved by eliminating redundant or unnecessary testing.
by recognizing that a single failed test rules out a candidate978 .
c ieee ase palo alto usa356 authorized licensed use limited to university of michigan library.
downloaded on november at utc from ieee xplore.
restrictions apply.
repair our algorithm prioritizes the test most likely to fail and the patch most likely to succeed based on previous observations.
the result is a deterministic adaptive algorithm for automated program repair backed by a concrete cost model.
we also highlight a duality between generate and validate program repair and mutation testing explicitly phrasing program repair as a search for a mutant that passes all tests.
examining the hypotheses associated with mutation testing sheds light on current issues and challenges in program repair and it suggests which advances from the established field of mutation testing might be profitably applied to program repair.
based on these insights we describe a new algorithm and evaluate it empirically using a large dataset of real world programs and bugs.
we compare to genprog as a baseline for program repair finding that our approach reduces testing costs by an order of magnitude.
the main contributions of this paper are as follows a detailed cost model for generate and validate program repair.
the model accounts for the size of the fault space size of the fix space section iii the order in which edits are considered repair strategy and the testing strategy.
a technique for reducing the size of the fix space by computing the quotient space with respect to an approximate program equivalence relation.
this approach uses syntactic and dataflow analysis approaches to reduce the search space and has not previously been applied to program repair.
a novel adaptive and parallelizable algorithm for automated program repair.
unlike earlier stochastic repair methods our algorithm is deterministic updates its decision algorithm dynamically and is easier to reason about.
an empirical evaluation of the repair algorithm on defects in programs totaling over five million lines of code and guarded by over ten thousand test cases.
we compare directly to genprog finding order of magnitude improvements in terms of test suite evaluations and over three times better dollar cost.
a discussion of the duality between generate and validate program repair and mutation testing formalizing the similarities and differences between these two problems.
this provides a lens through which mutation testing advances can be viewed for use in program repair.
ii.
m otivation generate and validate repair algorithms have been dominated historically by the time spent executing test cases.
consider genprog which uses genetic programming gp to maintain a population of candidate repairs iteratively mutating and recombining them in a manner focused by fault localization information until one was found that passed all tests .
the iterative population based gp search heuristic makes it difficult to predict the cost number of test cases evaluated in advance but early empirical estimates placed the percentage of effort devoted to running tests at roughly and laterexperiments with test suite sampling to reduce the number of test case evaluations improved performance by .
an early and simplistic cost model for genprog related the number of complete test suite evaluations to the size of the parts of the program implicated by fault localization fig.
.
this is intuitive but incomplete because it ignores the test suite sampling discussed earlier and it ignores the order in which candidate repairs are evaluated e.g.
if a high probability candidate were validated early the search could terminate immediately reducing the incurred cost and the number of possible repair operations edits that can be considered.
however genprog demonstrates high variability both across individual trials and among programs and defects.
for example in one large study genprog s measured ability to repair a defect varied from with no clear explanation .
in light of such results a more powerful explanatory framework is desired.
a second cost arises from syntactically distinct but semantically equivalent program variants.
this overhead is real but completely ignored by cost models that consider only test case evaluations.
in a generate and validate repair framework equivalent programs necessarily have equivalent behavior on test cases so the size of this effect can be estimated by considering the number of candidate repairs that have exactly the same test case behavior.
to this end we examined the test output of over program variants produced by genprog in a bug repair experiment .
for a given bug if we group variants based on their test output of them are redundant with respect to tested program behavior on average.
although not all programs that test equally are semantically equivalent this suggests the possibility of optimizing the search by recognizing and avoiding redundant evaluations.
we thus desire a more descriptive cost model as well as a search based repair algorithm that explicitly considers program equivalence and the order in which tests and edits are explored.
iii.
c ost model this section outlines a cost model for generate and validate repair to guide the algorithmic improvements outlined in section iv.
we assume a repair algorithm that generates and validates candidate repairs using test cases and tests are the dominant cost.
we acknowledge many differences between approaches but believe the description in this section is sufficiently general to encompass techniques such as genprog clearview debroy and wong and par .
broadly the costs in a generate and validate algorithm depend on generation how many candidates are created and validation how each one is tested .
without optimization the number of tests executed equals the number of candidate repairs considered by the algorithm times the size of the test suite.
fault localization identifies a region of code that is likely associated with the bug.
fault localization size refers to the number of statements lines of code or other representational unit manipulated by the repair algorithm.
a candidate repair i.e.
a patch typically modifies only the code identified by fault localization but it can also include code imported from another357 authorized licensed use limited to university of michigan library.
downloaded on november at utc from ieee xplore.
restrictions apply.
part of the program synthesized or instantiated from a template .
the number of first order candidate repairs is the product of the fault localization size and the size of thefix space where fix space refers to the atomic modifications that the algorithm can choose from.
in addition the repair algorithm could terminate when it finds and validates a repair so the enumeration strategy the order in which candidate repairs are considered can have significant impact.
similarly a non repair may be ruled out the first time it fails a test case and thus the testing strategy also has a significant impact.
equation shows our cost model.
fault localization size is denoted by fault .
the number of possible edits mutations is denoted by fix.
note that the model structure has each component depending on the previous components.
for example fixdepends on fault e.g.
some templates or edit actions might not apply depending on the variables in scope control flow etc.
.
the size of the test suite is denoted by suite .
the order in which the algorithm considers candidate repairs is repairstrat and repairstratcost denotes the number of tests evaluated by repairstrat which ranges from fault fix an optimal strategy that selects the correct repair on the first try to a pessimal strategy that considers every candidate .
finally given a candidate repair the order in which test cases are presented is given by teststrat and the number of tests evaluated by teststrat is given by teststratcost which ranges from suite optimal to worst case .
cost fault fix fault suite fault fix repairstratcost fault fix suite teststratcost fault fix suite repairstratcost by contrast earlier algorithms defined the search space as the product of fault andfixfor a given mutation type sec.
.
.
genprog s policy of copying existing program code instead of inventing new text corresponds to setting fixequal tofault leveraging existing developer expertise and assuming that the program contains the seeds of its own repair for o n2 edits while other techniques craft repairs from lists of templates .
although fault localization is wellestablished fix localization identifying code or templates to be used in a repair is just beginning to receive attention .
in our model fixdepends on fault capturing the possibility that operations can be avoided that produce ill typed programs or the insertion of dead code .suite depends on suite so the model can account for techniques such as impact analysis .
the repairstrat term expresses the fact that the search heuristic ultimately considers candidate repairs in a particular order and it suggests one way to measure optimality.
it also exposes the inefficiencies of algorithms that re evaluate semantically equivalent candidates.
the teststrat term depends on the repair strategy allowing us to account for savings achieved by explicit reasoning about test suite sampling .
note that suite optimizations remove a test from consideration entirely while teststrat optimizations choose remaining tests in an advantageous order.in the next section we use the structure of the cost model with a particular emphasis on the repair and test strategy terms to outline a new search based repair algorithm.
iv.
r epair algorithm we introduce a novel automated program repair algorithm motivated by the cost model described in section iii.
based on the observation that running test cases on candidate repairs is time consuming the algorithm reduces this cost using several approaches.
first it uses an approximate program equivalence relation to identify candidate repairs that are semantically equivalent but syntactically distinct.
next it controls the order in which candidate repairs are considered through an adaptive search strategy.
a second adaptive search strategy presents test cases to candidate repairs intelligently e.g.
presenting test cases early that are most likely to fail.
although each of these components adds an upfront cost our experimental results show that we achieve net gains in overall time performance through these optimizations.
to highlight its use of adaptive search strategies and program equivalence we refer to this algorithm as ae in this paper.
we first describe the algorithm and then provide details on its most important features the approximate program equivalence relation and two adaptive search strategies.
a. high level description the high level pseudocode for ae is given in figure .
it takes as input a program p a test suite suite that encodes all program requirements and impact analyses a conservative approximate program equivalence relation an edit degree parameter k an edit operator edits that returns all programs resulting from the application of kth order edits and the two adaptive search strategies repairstrat andteststrat .
the algorithm is shown enumerating all kth order edits of pon line .
in practice this is infeasible for k and operations involving candidaterepairs should be performed using lazy evaluation and calculated on demand.
on line the repairstrat picks the candidate repair deemed most likely to pass all tests based on model the observations thus far.
on line and the quotient space is computed lazily a set of equivalence classes encountered thus far is maintained and each new candidate repair is checked for equivalence against a representative of each class.
if the new candidate is equivalent to a previous one it is skipped.
otherwise it is added to the set of equivalence classes line .
candidates are evaluated on the relevant test cases line in an order determined by teststrat line which uses information observed thus far to select the test deemed most likely to fail.
since successful repairs are run on all relevant tests regardless teststrat affects performance opting out after the first failure rather than functionality and is thus chosen to short circuit the loop lines as quickly as possibly for non repairs.
if all tests pass that candidate is returned as the repair.
if all semantically distinct candidates have been tested unsuccessfully there is no k degree repair given that program approximate equivalence relation test suite and set of mutation operators.
authorized licensed use limited to university of michigan library.
downloaded on november at utc from ieee xplore.
restrictions apply.
input program p prog input test suite suite prog!p test input equivalence relation prog prog!b input edit degree parameter k n input edit operator edits prog n!p prog input repair strategy repairstrat p prog model!prog input test strategy teststrat p test model!test output program p0.8t2suite p0 p0 t true letmodel letequivclasses letcandidaterepairs edits p k repeat letp0 repairstrat candidaterepairs model candidaterepairs candidaterepairs nfp0g is any previously tried repair equivalent to p0?
if 9previous2equivclasses p0 previous then equivclasses equivclasses fp0g lettestsremaining suite p0 lettestresult true repeat lett teststrat testsremaining model testsremaining testsremainingnftg testresult p0 t model model fhp0 t testresultig until testsremaining testresult iftestresult then return p0 end if end if until candidaterepairs return nok degree repair fig.
.
pseudocode for adaptive equivalence ae generate and validate program repair algorithm.
candidate repairs p0are considered in an order determined by repairstrat which depend on a model of observations model may be updated while the algorithm is running and returns the edit mutation deemed most likely to pass all tests.
candidate repairs are compared to previous candidates and evaluated only if they differ with respect to an approximate program equivalence relation .teststrat determines the order in which tests are presented to p0 returning the test on which p0is deemed most likely to fail.
the first p0to pass all tests is returned.
the cost model identifies five important components fault fix suite repairstrat and teststrat .
we leave fault localization fault as an orthogonal concern although there is some recent interest in fault localization targeting automated program repair rather than human developers .
in this paper we use the same fault localization scheme as genprog to control for that factor in our experiments.
similarly while we consider impact analysis to be the primary suite reduction we do not perform any such analysis in this paper to admit a controlled comparison to genprog which also does not use any.
finally one cost associated with testing is compiling candidate repairs compilation costs are amortized by bundling multiple candidates into one executable each selected by an environment variable .
in the rest of this section we discuss the other three components.
b. determining semantic equivalence to admit a direct controlled comparison we form edits as a quotient space of edits produced by the genprog mutation operators delete a potentially faulty statement and insert after a potentially faulty statement a statement from elsewherein the program.
this means that any changes to the search space of edits are attributable to our equivalence strategies not to different atomic edits or templates.
genprog also includes a replace operator that we view as a second degree edit delete followed by insert in this paper we use edit degree k unless otherwise noted see section v for a further examination of degree .
if two deterministic programs are semantically equivalent they will necessarily have the same test case behavior.1thus when we can determine that two different edits applied at the same fault location would yield equivalent programs the algorithm considers only one.
since general program equivalence is undecideable we use a sound approximation a bimplies that aandbare semantically equivalent but our algorithm is not guaranteed to find all such equivalences.
we can hope to approximate this difficult problem because we are not dealing with arbitrary programs aandb but instead a anda0 where we constructed a0fromavia a finite sequence of edits applied to certain locations.
although our algorithm is written so that the quotient space is computed lazily for small values of kit can be more efficient to compute the quotient space eagerly i.e.
on line of figure .
in this domain the cost of an imprecise approximation is simply the additional cost of considering redundant candidate repairs.
this is in contrast with mutation testing where the equivalent mutant problem can influence the quality of the result via its influence on the mutation score see section vi .
drawing inspiration from such work we determine semantic equivalence in three ways syntactic equality dead code elimination and instruction scheduling.
a syntactic equality programs often contain duplicated variable names or statements.
in techniques like genprog that use the existing program as the source of insertions duplicate statements in the existing program yield duplicate insertions.
for example if the statement x 0appears ktimes in the program genprog might consider kseparate edits inserting each instance of x after every implicated fault location.
template based approaches are similarly influenced ifptris both a local and a global variable and a null check template is available the template can be instantiated with either variable leading to syntactically identical programs.
programs that are syntactically equal are also semantically equal so a textb a b. b dead code elimination iflval is not live at a proposed point of insertion then a write to it will have no effect on program execution assuming rval has no sideeffects .
ifkeditse1 e kapplied to the program ayield a candidate repair a andeiinserts dead code then a a .
as a special common case if e1inserts dead code then a a. dataflow analysis allows us to determine liveness in polynomial time thus ruling out insertions that will have no semantic effect.
1excluding non functional requirements such as execution time or memory use.
we view such non functional program properties as a separate issue i.e.
compiler optimization .
authorized licensed use limited to university of michigan library.
downloaded on november at utc from ieee xplore.
restrictions apply.
c instruction scheduling consider the program fragment l1 x l2 y l3 z and the fixmutation insert a .
genprog might consider three possible insertions one at l1 one at l2and one at l3.
in practice all three insertions are equivalent a 0does not share any read write or write write dependencies with any of those three statements.
more generally if s1 s2 and s2 s1 are semantically equivalent only one of them need be validated.
one type of instruction scheduling compiler optimization moves or bubbles independent instructions past each other to mask latencies or otherwise improve performance.
we use a similar approach to identify this class of equivalences quickly.
first we calculate effect sets for the inserted code and the target code statements e.g.
reads and writes to variables memory system calls etc.
.
if two adjacent instructions reference no common resources or if both