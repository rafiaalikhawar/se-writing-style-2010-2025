verifying self adaptive applications suffering uncertainty wenhua y ang chang xu y epang liu chun cao xiaoxing ma jian lu state key lab for novel soft.
tech.
nanjing university nanjing china dept.
of comp.
sci.
and tech.
nanjing university nanjing china ihope1024 gmail.com changxu caochun xxm lj nju.edu.cn dept.
of comp.
sci.
and engr.
the hong kong univ.
of sci.
and tech.
hong kong china andrewust cse.ust.hk abstract self adaptive applications address environmental dynamics systematically.
they can be faulty and exhibit runtime errors when environmental dynamics are not considered adequately.
it becomes more severe when uncertainty exists in their sensing and adaptation to environments.
existing work verifies self adaptive applications but does not explicitly consider environmental constraints or uncertainty.
this gives rise to inaccurate verification results.
in this paper we address this problem by proposing a novel approach to verifying self adaptive applications suffering uncertainty in their environmental interactions.
it builds i nteracti ve state machine ism models for such applications and verifies them with explicit consideration of environmental constraints and uncertainty.
it then refines verification results by prioritizing counterexamples according to their probabilities.
we experimentally evaluated our approach with real life self adaptive applications and the experimental results confirmed its effectiveness.
our approach reported more counterexamples than not considering uncertainty and eliminated all false counterexamples caused by ignoring environmental constraints.
categories and subject descriptors d. .
software program verification d. .
testing and debugging general terms verification reliability experimentation keywords self adaptive application verification uncertainty .
introduction self adaptive applications are gaining increasing popularity e.g.
locale phone adapter and navia .
these applications continually sense their environments and make adaptation corresponding author permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
ase september vasteras sweden.
copyright acm ... .
.
.according to their predefined logics .
this forms a reaction loop and an application s adaptation upon certain environmental changes can then affect environmental sensing afterwards.
thus self adaptive applications and their environments are together creating complex and correlated interactions.
this causes challenges to building dependable self adaptive applications since developers have to consider every detail of such interactions in a predictive way.
real world self adaptive applications are thus error prone .
to assure the quality of self adaptive applications many research efforts focus on sophisticated testing or debugging techniques.
some techniques use fault patterns to dynamically detect and analyze faults in these applications.
others work on test case generation or test adequacy criteria to support effective fault detection.
however one outstanding challenge in fault detection for self adaptive applications is that these applications keep interacting with dynamic environments.
it is generally infeasible to predict and enumerate all possible environmental conditions that an application can encounter at runtime .
this makes existing techniques unable to test self adaptive applications adequately and precisely.
for example ramirez et al.
used simulation to explore environmental conditions that may cause requirement or behavior violation to an application but only limited simulation environments can be tested due to its complexity and cost.
on the other hand formal methods such as model checking and theorem proving rigorously verify an application s behavior .
given an application these techniques exhaustively explore its state space to detect potential errors e.g.
dead state or abnormal behavior .
recent studies have also reported promising results in applying these techniques to verifying properties of self adaptive applications e.g.
safety reliability liveness and reachability consistency and stability .
however when it comes to verifying self adaptive applications under real world environments these pieces of existing work have two major limitations lack of modeling environmental constraints.
first an application s running environment can be subject to implicit constraints enforced by this environment s physical laws or assumed by the application s prior knowledge.
consider an example robot car application that aims to explore an unknown area without bumping into any obstacle.
the car can sense its four directional distances front back left and right to nearby obstacles using its built in ultrasonic sensors.
based on these sensed distances it decides its next movement to avoid obstacles.
suppose that the car keeps walking forward with an obstacle detected ahead.
its sensed distance to this obstacle would keep decreasing.
one can derive a constraint for this situation the last sensed distance should be equal to the summation of the new sensed distance and how far the car has walked since its last sensing.
such constraints relate environmental sensing e.g.
distance sensing to application adaptation e.g.
car walking .
we name them environmental constraints.
overlooking them can lead to inaccurate verification results.
for example sama et al.
used model checking to detect faults for self adaptive applications.
the work does not model or use environmental constraints in verification and thus many reported faults are false positives .
lack of modeling uncertainty.
second an application s environmental sensing and adaptation can be affected by uncertainty which is inevitably caused by unreliable environmental sensing and flawed physical actions .
for environmental sensing an application may only be able to obtain an estimate of its environmental conditions but never know its real state.
for example the car s distance sensing always contains unpredictable noise and sensed values may not faithfully reflect real distances from the car to its nearby obstacles.
similarly for adaptation an application can only interact with its environment as designed but may not know whether the interaction indeed proceeds as expected.
for example the car can make left or right turns but with unpredictable error.
in practice a left turn can actually be and the car may not be able to know this error.
such sensing and adaptation uncertainty can cause inconsistency between an application s understanding to its environment and its actual environmental conditions thus affecting the application s functionalities .
similar to environmental constraints overlooking such uncertainty can also lead to inaccurate verification results.
however to the best of our knowledge none of existing work has explicitly modeled and considered such uncertainty in verifying self adaptive applications.
in this paper we address these two limitations by proposing a novel approach to verifying self adaptive applications under uncertain environmental dynamics.
our approach works in three phases phase modeling adaptation logic and environmental constraints.
we model the reaction loop of a self adaptive application with i nteracti ve state machine ism and explicitly specify environmental constraints for the application.
phase verifying the model with uncertainty considered.
we consider the uncertainty in this application s sensing and adaptation to its environment by specifying the error range and distribution of each related variable.
we then verify the application through its ism model taking all error ranges into account.
phase prioritizing counterexamples.
from the verification we obtain counterexamples that lead to the application s potential runtime errors .
we refine verification results by ranking generated counterexamples according to their occurrence probabilities.
we show that by modeling and exploiting such environmental constraints and uncertainty verifying self adaptive applications can receive results with greatly increased accuracy.
our approach reported more counterexamples than not considering uncertainty and eliminated all false counterexamples caused by ignoring environmental constraints.
the experimental results consistently showed that our verification approach is more accurate and achieves good performance as well as scalability.
we summarize our contributions in this paper below we propose a novel ism model to explicitly consider environmental constraints and uncertainty in verifying self adaptive applications.
this greatly increases verification accuracy.
we propose a prioritization technique to rank counterexamples generated from verification according to their occurrence probabilities.
this enables developers to focus on most likely faults.
we evaluate our verification approach with self adaptive applications by both real and simulation experiments and validate its usefulness in practice.
the remainder of this paper is organized as follows.
section introduces our modeling of self adaptive applications.
section uses a motivating example to explain the inadequacy of existing work and motivate our work.
section presents our verification approach in detail.
section validates our approach with self adaptive applications.
section discusses related work and finally section concludes this paper.
.
modeling self adaptive applications as mentioned earlier self adaptive applications continually sense their environments and make adaptation upon perceived environmental changes.
their functionalities are realized by the collaboration of three parts environmental sensing decision making and application adaptation.
thus a self adaptive application s running can be described by a reaction loop as illustrated in figure .
first the application senses its environment to capture interesting environmental changes.
then according to its predefined logics the application makes a decision by selecting appropriate adaptation to such environmental changes.
the adaptation can change the environment and affect the application s environmental sensing afterwards.
thus the environmental sensing is related to the adaptation by environmental constraints as explained earlier.
as figure shows the sensing and adaptation can also be affected by uncertainty which is caused by imperfect sensing technologies and flawed physical actions nowadays.
since existing modeling approaches for self adaptive applications such as a fsm do not explicitly consider how an application s adaptation affects its environmental sensing afterwards we propose a new model named interacti ve state machine ism to meet this requirement.
given a self adaptive application we define its ism as a tuple m s v r s0 in which symbols are explained below sis a set of this application s all states and s02sis its initial state with which the application starts.
vis a set containing this application s all variables.
v vs vn in which vsandvnrepresent two disjointed categories.
vscontains all sensing variables which store values of environmental attributes interesting to this application updated by relevant sensing devices .
vncontains other normal variables i.e.
non sensing variables.
ris a set containing this application s all adaptation rules or rules for short .
for each rule r2r ris associated with a state s2s which is r s source state.
rule rtakes a form ofr condition actions .condition is a logical formula built on v and its satisfaction would trigger the execution of this rule.
actions specifies what should be done when executing this rule.
actions can include internal actions and interactive actions .
the former takes internal adaptation by updating values of non sensing variables e.g.
updating the application s current state and in this case the application transits to a new state.
the latter takes interactive adaptation by interacting with the application s environment directly e.g.
making a robot car move forward.
interactive actions can also specify the extents of their effects on the environment by updating certain non sensing variables e.g.
recording the distance that the car has moved forward.
interactive 200ac tions would also update values of sensing variables implicitly through environment constraints the updates are explicitly performed upon next environmental sensing .
ism is executable.
starting from its initial state s0 an ism m s v r s0 repeatedly reads values of its sensing variables automatically updated by environmental sensing then evaluates and decides which rule to execute and finally conducts the executed rule s associated actions.
when a state s2sis set as m s current state rules having this state as source state are enabled while other rules are disabled.
only enabled rules participate in rule evaluation upon each environmental sensing.
when an enabled rule r s condition r condition is satisfied the rule is triggered for execution.
if multiple rules are triggered only one of them is selected to execute.
this tie can be resolved by some priority or random mechanisms which are not our focus in this paper and therefore omitted.
when a rule ris selected to execute its actions r actions are conducted in a sequential way.
conducting actions concurrently might be possible for certain scenarios but this also is not our focus in this paper and therefore omitted.
thus an ism m s execution can be conceptually modeled by a path which is a sequence of states and rules s s0r1s1 rnsn.
similar to traditional programming we define path condition of execution sas pc s n i 1ri condition to be representative we adopt a quantifier free first order logic based language for specifying a rule s condition.
with this language a rule s condition can be specified by a logical formula that is recursively constructed using the following syntax f f and f j f or f j f implies f jnot f j bfunc v v note that the above and or implies and not logical connectives follow their traditional interpretations i.e.
representing conjunction disjunction implication and negation operations respectively.
terminal bfunc refers to any user defined or domainspecific function that returns either true or false.
when a bfunc is easy to understand one may also use its corresponding operator to simplify its representation e.g.
largert han v can also be represented by v .
.
motivating example in this section we present a motivating example using our aforementioned self adaptive robot car application.
the application controls a robot car to explore an unknown area and avoid bumping into any obstacle.
if the car bumps into an obstacle we say that the application fails.
we first use our ism model to specify this application s adaptation logics.
we illustrate it partially in figure due to page limit but this suffices for explaining our problem.
the ism model for this application is m s v r s0 where s fa b e g r fr0 r1 r14 g vis the set of variables used in this application in particular by r and the application s initial state s0 a. we in the following take state aand its associated rules for example and other states and rules can be explained similarly.
there are four rules associated with state a i.e.
having aas their source states r0 r1 r2andr3 multiple actions are sequentially separated by semicolon r0 disf walkf .
r1 disf and disl turnl walkf environmentunreliable flawedenvironmental constraintsdecision making adaptationsensingself adaptiveappfigur e reaction loop between a self adaptive application and its environment.
turnl updatestate b .
r2 disf and disl and disr turnr walkf turnr updatestate d .
r3 disf and disl and disr walkb updatestate e .
these rules reference four variables disf disb disl anddisr.
they are all sensing variables representing sensed distances between the car and its four directional obstacles front back left and right respectively.
if a sensed distance is no less than cm we consider this distance safe.
these rules also involve some actions.
for example actions walkf and walkb mean driving the car to walk forward and backward by a unit distance say 10cm respectively.
actions turnl and turnr represent turning the car left and right by respectively.
at state a the car keeps walking forward if its sensed distance ahead is safe rule r0 .
if this distance is no longer safe but the car s left distance is still safe the car would turn left walk forward for a unit distance and then turn left again rule r1 .
after these interactive actions the application also conducts a state transition internal action updatestate b which transits the application to a new state b .
at state b new rules associated with this state r4 r8 r9 are enabled while the previous rules r r1 r2 r3 are all disabled.
rule r2works similarly as rule r1except that it turns the car to right and transits the application to state d. if the car s sensed distances at three directions front left and right are all not safe the application would drive the car to walk backward for a unit distance and then transit to state e rule r3 .
consider our earlier failure definition.
the car should not bump into any obstacle.
since the car can walk only forward or backward if its last action is walkf the failure condition is disf or otherwise i.e.
walkb the failure condition is disb the failure condition would be different with uncertainty and environment constraints which will be discussed later .
now we verify this ism model to check whether it contains any problem.
we note that if one does not model and consider environmental constraints and uncertainty the verification results can be inaccurate.
for example consider an execution a r0a r1b.
its path condition is disf 20anddisf 20anddisl since removing parentheses from a conjunction formula does not change its value all parentheses are omitted for simplicity .
here different subscripts represent sensed values at different time points.
suppose that after executing action walkf in rule r0 the car bumps into an obstacle i.e.
the failure condition disf is satisfied.
without considering uncertainty caused by unreliable sensing disf would equal to disf which is the sensed value of disf after executing action walkf in rule r0.
we concatenate this failure condition to the earlier path condition and try to solve the whole constraint.
if we can successfully solve this constraint we would ob201a de cb r1 r3 r2r4 r5r6 r7r9r10 r13r14 r0 r12 r11 disf walkf disf and disl and disr walkb updatestate e disf and disl turnl walkf turnl updatestate b disf and disl and disr turnr walkf turnr updatestate d r8figur e a partial ism model for our example self adaptive robot car application ellipses represent states and arcs represent rules .
tain a concrete answer on why this execution fails.
this execution with the answer is also known as a counterexample .
regarding the above constraint disf 20anddisf 20and disl 20anddisf one possible counterexample for solving this constraint is disf disf and disl .
this counterexample seems feasible but it violates an environmental constraint connecting disf 0anddisf which is established by action walkf in rule r0.
we observe that the distance between disf 0anddisf 1is too large cm such that it cannot be accomplished by walkf 10cm .
this makes the counterexample unreal and thus useless i.e.
a false positive .
on the other hand real counterexamples i.e.
true positives may also be missed if one does not consider uncertainty in verifying this application.
for instance consider the same execution in the above example a r0a r1b.
by using the approach of modeling environmental constraints which will be introduced later we can have a constraint disf disf unit since disf s value becomes disf s value due to the effect of action walkf which moves the car forward by a unit distance.
suppose that one wants to know whether after executing action walkf in the first r0 the application can fail i.e.
disf is satisfied.
concatenating the path condition and the failure condition together and trying to solve the whole constraint would return no result since unit and thus disf which equals to disf unit must be larger than based on the fact disf .
however both environmental sensing and application adaptation can contain uncertainty as explained earlier.
suppose that disf s value is subject to an error range of and the car s walked unit distance falls in an error range of .
then there still exists possibility that the car bumps into an obstacle in this situation.
therefore this calls for new effort to model such uncertainty to enhance our constraints so that one can discover such potential problems in a self adaptive application in a more accurate way.
.
verifying self adaptive applications in this section we present our approach to verifying self adaptive applications with environmental constraints and uncertainty.
we begin with an overview of the approach followed by detailed explanations.
.
approach overview given a self adaptive application we build its ism model.
as discussed in the motivating example the failure condition of ouralgorithm 1verification algorithm.
input ism m s r v s0 failure condition f c and bound k. output setcof counterexamples with probabilities.
c path s0 i repeat s the last state of path ifi k shas unexplored rules then r an unexplored rule of s s the state that rleads to append rands topath i i extract the path s path condition pc augment pcwith environmental constraints modify pcby introducing uncertainty check pc f cwith a constraint solver ifpc f cis satisfied then estimate the probability of the counterexample add the counterexample with probability to c end if else remove s andrfrom path i i end if until path return c robot car application is that the car bumps into any obstacle.
this is verified by checking each path in the ism to see whether the concatenation of its path condition and the failure condition can be satisfied.
if so a counterexample is found which corresponds to an application failure.
the overview of our verification approach is shown in algorithm .
.
the algorithm takes an ism m a failure condition f c and a bound kas its inputs.
the main data structure used in the algorithm is a list path which records the path that is currently being explored.
the algorithm traverses the ism in a depth first manner to find new paths lines lines .
since the number of optional paths could be infinitely many for practical considerations our approach bounds the length of a path being explored with a configurable integer during the traversal line i k .
our approach also supports setting a time budget to prevent endless traversal.
the traversal ends when there is no unexplored path within the bound line .
for each selected path the algorithm extracts its path condition pc.
the ism explicitly specifies the adaptation logics of an application but does not include its environmental constraints and uncertainty.
so we augment the path condition with environmental constraints and uncertainty for realistic verification.
then the path condition is passed to z3 an efficient smt solver to check whether it can be satisfied.
if so a counterexample is found.
it is possible that many counterexamples can be reported.
to make the verification results more actionable to users our approach prioritizes the reported counterexamples according to their occurrence probabilities.
in the following three subsections we present our ideas of modeling environmental constraints dealing with uncertainty and prioritizing counterexamples in detail.
.
modeling environmental constraints a self adaptive application s execution can be described by a reaction loop.
each environmental sensing provides information for 202disfi disli disbidisri disfi disli disbi 1disri 1unit disfi disli disbidisri disri disfi disli 1disbi 1disfi disfi unit disbi disbi unit disli 1isirrelevantto disli disri 1isirrelevantto disri disfi disli disbi disri disli disbi disri disfibeforeactionturnlbeforeactionwalkf afteractionturnlafteractionwalkffigur e environmental constraints for actions.
the application to select an appropriate adaptation which can further change the environment and affect the application s next environmental sensing.
since the new environment is the result of the adaptation s effects on the previous environment it cannot be arbitrary.
this is because inherent constraints in the environment such as physical laws or the constraints predefined by the application domain could be violated.
for example for the robot car application suppose that the car keeps walking forward with an obstacle detected ahead.
if each sensed environment of the application is treated independently and can be arbitrary we can have that the application s sensed distance to its front obstacle in one environmental sensing is larger than that in the previous sensing.
this clearly contradicts physical laws and makes thus reported counterexample useless.
the constraints related each environmental sensing to its previous sensing and adaptation are named environmental constraints as explained before.
for a self adaptive application we build its ism m s v r s0 .
suppose a rule r2rhas been just triggered and interactive actions ofr actions has affected the environment.
then an environmental constraint is a formula conenv v v e where v andv are the set of sensing variables before and after the interac tive actions respectively and eis a set of non sensing variables representing the effects of interactive actions.
the semantics of conenvcan be derived from inherent constraints of the environment.
take the robot car application as an example again.
suppose that the car takes action walkf which makes the car walk forward for a distance unit.
then from physical laws we can derive an environmental constraint conenv fdisf ig fdisf i 1g funitg meaning that the last sensed distance disf ishould be equal to the summation of the new sensed distance disf i 1and the distance unitthat the car has walked since its last sensing i.e.
conenv fdisf ig fdisf i 1g funitg disf i disf i unit.
the environmental constraint conenv v v e requires that when values of the sensing variables in v are explicitly updated upon an environmental sensing these updated values should satisfy conenv v v e .
thus through environmental constraints we provide a means to enable interactive actions to update sensing variables implicitly.
for conenv fdisf ig fdisf i 1g funitg in the above example it requires that the update ofdisf i 1should satisfy disf i disf i unit as illustrated in figure top .
however for action walkf there are no constraints about disl i 1anddisl i ordisr i 1anddisr i. this is because after the robot car walks forward for a distance unit the distances between the car and its left and right obstacles can be arbitrary and thus no environmental constraints are specified.figure also shows another example in the bottom about action turnl which is a turning left action.
similar environmental constraints exist for actions walkb and turnr which are the walkingbackward and turning right action respectively.
they are omitted due to page limit.
now we can augment the path condition of a selected path with such environmental constraints as mentioned in the overview.
for each rule in the path if there are environmental constraints for taking the rule s interactive actions we concatenate the environmental constraints to the path condition.
after it is done we get a new formula of constraints for the path which is called the ideal condition.
for example for path s a r0ain the robot car example its path condition is disf .
for rule r0 it has an interactive action walkf.
let disf 1be the distance between the car and its front obstacle after taking the action walkf.
then as mentioned before there is an environmental constraint disf disf unit .
after concatenating the environmental constraint to the path condition we get the ideal condition of path s which is disf 20and disf disf unit .
for each of the selected paths we process the path condition in the same manner to get the ideal condition which will be further processed to include uncertainty as described in the next subsection.
.
dealing with uncertainty self adaptive applications environmental sensing and adaptation can be affected by uncertainty which is naturally caused by unreliable sensing and flawed adaptation .
the uncertainty can cause inconsistent understandings for an application between its sensed environment and actual environment .
as suggested by the motivating example the application may fall into failure due to its inaccurate understanding to the environment caused by uncertainty.
thus we should consider uncertainty in verifying selfadaptive applications.
otherwise the accuracy of verification results cannot be guaranteed.
however it is difficult to specify uncertainty precisely in the modeling and verification process because uncertainty comes from various sources and appears in different forms.
we studied uncertainty in many real cases and observed that uncertainty caused by unreliable sensing or flawed adaptation demonstrates regular patterns.
the sensed value of unreliable sensing or the effects of flawed adaptation often fall into an error range with a distribution determined by the physical characteristics of sensing technologies and actions.
in this section we explain how to model this kind of uncertainty in the verification of self adaptive applications.
uncertainty affects self adaptive applications sensing and adaptation and thus affects values of sensing variables and non sensing variables that represent the effects of adaptation.
given an ism to model uncertainty we first need to identify the variables in an ideal condition that would be affected by uncertainty.
then for each of these variables we give an error range and a distribution for its potential value i.e.
for a variable vaffected by uncertainty let a b be the error range of v. then the lower bound and upper bound of variable varev aandv brespectively.
meanwhile we set a distribution pof the variable s value between its lower and upper bounds.
the lower bound upper bound and the distribution of a variable can be obtained from field studies or experiments with statistical analysis.
in the robot car application the distance disf between the car and its front obstacle is affected by uncertainty.
we found that the ultrasonic sensor used in the robot car has an error in sensing.
field studies show that its error range is cm and its error distribution is a gaussian one.
so for variable disf we give an error range of .
then the lower bound and upper bound aredisf and disf respectively.
the distribution of disf s 203v alue between its lower and upper bounds is a gaussian distribution.
similarly from field studies we learned that the distance unit of the car s walking action falls into an error range cm and the distribution of its value is also a gaussian distribution.
now we can show how to augment an ideal condition with uncertainty.
in an ideal condition for all its variables there is no uncertainty considered.
therefore for each variable v which is affected by uncertainty in the ideal condition since vdoes not include uncertainty we use a new variable v to represent vwith uncertainty.
v satisfies the constraint v a v v b where is the error range of v. this means that the value of v can range from v ato v b. clearly for environmental sensing the value of v is a sensed value of the application and the value of vis the actual value about the environment.
for adaptation the value of v records its actual effects on the environment and the value of vrecords its ideal effects assumed by the application.
we also set a distribution p v forv that will be used to prioritize later reported counterexamples which is explained in the next subsection.
then we replace vwith v in the ideal condition and join the constraint v a v v b with the ideal condition.
this forms a new condition named the actual condition .
take path s a r0ain the robot car application mentioned earlier for illustration.
the ideal condition of the path is disf anddisf disf unit in which variables disf disf and unit are affected by uncertainty.
the error ranges for disf 0anddisf are and the error range of unitis .
we use new variables disf disf 1andunit to replace the counterparts in the ideal condition respectively.
the constraint between disf 0anddisf 0is disf disf disf .
other variables constraints between themselves and the new variables are similar.
then we combine all these new constraints into the ideal condition and get the actual condition of s i.e.
disf 20anddisf disf unit anddisf disf disf 6anddisf disf disf 6andunit unit unit .
.
prioritizing counterexamples to check whether an execution can lead to application failure we concatenate a failure condition to the actual path condition associated with this execution to get a new constraint which is then passed to z3 to check whether there is a satisfying solution.
if yes the execution can fall into failure.
in the solution for each variable z3 will provide it with a value.
the values of all sensing variables represent an application s understanding to the environment.
based on these values we can construct a partial environment in which the application fails.
the reason why the environment may be partial is that the application may not sense all environmental attributes.
a path scontains a sequence of actions that the application takes which would lead to the application s failure if a solution exists.
the path sand the solution together indicate an application failure and that is why we name them a counterexample.
a counterexample is a tuple t s l where lis a mapping l v!a where vis a set fv0 v1 vngcontaining all variables in the actual condition of sandais a set of values fa0 a1 ang where l vi ai i n in the solution.
a counterexample represents a failed application execution in a certain environment.
for example for the robot car application we already know the actual condition of path s a r0a cf.
the previous subsection .
the failure condition of this path sisdisf .
then by solving the concatenation of the actual condition and the failure condition we can obtain a solution of disf disf disf disf unit unit .
this solution corresponds to the following failure scenario.
the distance between the robot car and its front obstacle is initially disf but due to uncertainty the applica tion s sensed distance is disf .
based on the sensed distance the application makes the car walk forward for a unit distance that is assumed to be 10cm unit .
however the actually walked distance is 14cm unit .
as a result although the new sensed distance of the application is 6cm disf in reality the car has already bumped into the obstacle disf .
this counterexample would not have been reported if we do not consider uncertainty in environmental sensing and application adaptation.
self adaptive applications are more likely to fall into failures in an environment with uncertainty .
as a result many counterexamples could be reported by solving concatenation of actual conditions and failure conditions.
however for a certain counterexample t s l an application may not fail by exactly following the actions specified in sunder the environment constructed from the values of variables in l. this is because each time the application runs due to uncertainty the application s sensed environment can be different from its actual environment and its adaptation s effects can be different from its assumption.
the likelihood for application making the same actions as the ones in sthat lead to failure in the environment corresponding to the variables values inlis called the probability of counterexample t s l .
we propose to prioritize reported counterexamples to save the effort for fault inspection and fixing.
we believe that the more likely a counterexample is to occur the more attention it needs.
therefore we rank counterexamples according to their probabilities from high to low.
for a counterexample t s l to occur in the environment constructed from l it requires that the application should make the same sequence of actions as specified in the rules of s. this means that for each rule rins r condition should be satisfied so that r actions can be taken.
thus we first estimate the probability of satisfaction of r condition.
suppose that r condition involves one variable vaffected by uncertainty and the variable replacing vto model uncertainty is v .
let the error range of vbe and the value of vinlbed.
so the lower bound and upper bound of the value of v ared aandd b respectively.
then the probability of r condition being true true can be calculated according to the following equation .
function p v is the probability density function of v .
function r v is defined as equation .
for a given value of v r v returns if r condition istrue and returns otherwise.
for other possible variables involved in r condition their values are fixed using those values in l. prob d b d ap v r v dv r v ifr condition true ifr condition false for example we assume that rule r0is the first rule in a counterexample s path.
the rule s condition disf involves one variable disf affected by uncertainty and we replace disf with disf .
the error range of disf is and the value of disf solved in the counterexample is .
it means that disf s value can range from to due to uncertainty.
the distribution of disf s value complies with the gaussian distribution n .
so the probability of disf being true is calculated according to equation as 11p disf r disf ddisf .
since r disf when disf the above equation is equivalent to 20p disf ddisf which results in 2p 2pe disf 8dd if 204note that there can be more than one variable affected by uncertainty in a rule s condition and there can be more than one rule in a path.
variables in one rule s condition may affect each other and variables across rules may have effects on each other as well.
in theory if we want to calculate the probability of satisfaction of all rules conditions we need to treat all the conditions in a path as a whole and perform a multiple integral on all variables that are affected by uncertainty.
as we know the multiple integral can be very inefficient when its condition is complex and there are many variables in the condition.
thus we give an approximated solution by treating each variable independently.
first for each rule in a counterexample we calculate the probability of satisfaction of the rule s condition according to equation .
if there are more than one variable affected by uncertainty in the rule s condition a multiple integral is used.
then we multiply the probabilities of satisfaction of each rule s condition to get an estimated probability of whole counterexample.
.
validating our approach in this section we validate the effectiveness of our approach.
we implemented our approach as a prototype and the validation was carried out in the context of our robot car application case study.
in this study we are going to answer the following three research questions rq1 how does our modeling of environmental constraints and uncertainty improve the accuracy of verification of selfadaptive applications?
rq2 can our approach give an accurate estimate of occurrence probabilities for its reported counterexamples?
rq3 how does the bound of path length configured during verification affect the scalability and effectiveness of our approach?
.
experimental setup and design self adaptive applications are different from conventional applications.
they interact with their running environments and adapt their behavior based on their sensed environmental changes.
to conduct our evaluation we need to carefully select our experimental application subjects.
specifically both the selected applications and their running environments need to be manageable as otherwise it is hard for us to deploy the applications for experiments.
guided by this requirement we selected different robot car applications with various sizes as our experimental subjects.
these applications were independently developed by different researchers and students in our university during the past four years.
they adopt different strategies to control a robot car to explore unknown areas based on collected sensory data.
these applications have up to different states and rules.
to answer our research question rq1 we conducted two experiments.
the first experiment studies whether modeling environmental constraints can improve the verification results by eliminating false counterexamples.
for comparison purposes we implemented another approach naive which ignores environmental constraints and uncertainty.
we applied both our approach and the naive approach to the robot car applications and checked the reported counterexamples to see how many of them are false counterexamples.
our second experiment studies whether modeling uncertainty can help improve the verification results.
similar to the first experiment we implemented an approach ideal which considers environmental constraints but ignores uncertainty for comparison.
we applied both our approach and the ideal approach to the robot cartable experimental results without considering environmental constraints a pplicationcounter examplef alse positivef alse positive rate a pp1 .
a pp2 .
a pp3 .
a pp4 .
a pp5 .
a pp6 .
a pp7 .
a pp8 .
a pp9 .
a pp10 .
a pp11 .
a pp12 .
applications and recorded their reported counterexamples.
then we ran the robot car applications in both real deployments i.e.
real field study and simulation to validate these counterexamples.
we then compared true counterexamples reported by the two approaches to see whether there is any counterexample reported by actual i.e.
our approach but not by ideal and vice versa.
in other words our goal is to study whether actual can report more counterexamples than ideal.
to answer research question rq2 for each counterexample we need to know its likelihood of occurrence in its corresponding environment in real cases.
the likelihood here serves as a ground truth to assess our predicted occurrence probability for each counterexample.
so we let an application run in the corresponding environment of every counterexample and counted the number of failures encountered by this application with respect to its corresponding counterexample.
the experiment was conducted for top reported counterexamples of each application in both field study and simulation.
as we know to get an accurate probability one has to collect a fairly large number of samples.
the simulation is thus used to refine our experimental results by providing more sampling data.
then we checked calculated probabilities of counterexamples against their observed likelihoods of occurrences to see how close they are.
the bound of path length is a parameter in our approach which can affect the approach s performance and the number of reported counterexamples.
besides since our approach takes one path for verification at a time the maximum bound of the path instead of the whole size of the ism affects the scalability of the approach virtually.
therefore we need to investigate how the bound impacts our approach.
in particular we want to know how our approach scales and how the number of counterexamples grows as the bound increases.
so to answer our research question rq3 we applied our approach to the robot car applications to measure the performance of our approach and recorded the number of reported counterexamples as the bound increased.
the results of all these experiments are discussed in the next section.
.
experimental results in this section we present experimental results to answer our earlier raised three research questions.
rq1.
first we examined the effects of modeling environmental constraints.
we implemented the naive approach and verified the robot car applications with naive.
the bound of path length was set to .
table gives the verification results.
column shows 205table comparison of experimental results reported counterexamples between actual and ideal a pplicationactual ideal mor eimpr ovement a pp1 .
a pp2 .
a pp3 .
a pp4 .
a pp5 .
a pp6 .
a pp7 .
a pp8 .
a pp9 .
a pp10 .
a pp11 .
a pp12 .
the number of reported counterexamples.
we examined these counterexamples one by one manually and found that many of them violated environmental constraints.
for example in one counterexample after the car moved forward for a unit distance the distance between the car and its front obstacle was bigger than that before the car took the move.
these counterexamples will not happen in real deployments and thus are false counterexamples false positives .
column shows the number of reported counterexamples which are false.
as we can see from column the false positive rate can vary from to over which indicates the necessity and importance of considering environmental constraints in the verification process.
then we examined the effects of modeling uncertainty by comparing the verification results of approach ideal and our approach actual .
we verified the robot car applications with both approaches with the bound of path length set to .
the results are shown in table .
column is the number of reported counterexamples of actual and column is the number of reported counterexamples of ideal.
our approach actual reported clearly more counterexamples than ideal.
furthermore by careful examination we found that all the counterexamples reported by ideal are also reported by actual .
in the meantime we confirmed that all counterexamples reported by actual can happen in real environments.
most confirmations were acquired by field study more than .
the others less than were acquired by simulation because these counterexamples have a fairly low probability to occur and therefore were difficult to be witnessed in the field study.
the robotcar and the simulation used to do the field study and simulation are shown in figure .
the experimental results show that our approach actual reported more counterexamples than approach ideal which demonstrates that our approach has a better accuracy more complete .
based on the above discussed experimental results we derive our answer to research question rq1 modeling environmental constraints and uncertainty can greatly improve the accuracy of verification of self adaptive applications .
rq2.
we also ranked the counterexamples reported by our approach from the above experiment with their predicted probabilities.
to assess the accuracy of these probabilities we selected the top counterexamples from each of the robot car application i.e.
counterexamples in total for further study.
specifically for each selected counterexample we let the concerned application to run in the environment constructed from this counterexample in field study for times and also in simulation for times figur e the robot car and the simulation used in experiments.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
experimental likelihood predicted probablity field study simulation field study simulati on figur e comparison of predicted probabilities and experimental probabilities.
i.e.
totally runs for each counterexample .
for each counterexample we counted the number of its corresponding failures and obtained a likelihood value for the failure s occurrence.
figure illustrates the results.
the horizontal axis represents predicted probability from our approach and the vertical axis represents the likelihood of occurrence observed from experiments.
each counterexample corresponds to two points in the figure blue points solid circle are for the field study and red points solid triangle are for the simulation.
it is clear that for a counterexample if its predicted probability from our approach is close to its likelihood of occurrence from experiments its corresponding point in the figure would be close to the diagonal line.
as we can observe from figure most of the points are scattered near the diagonal line.
from these results we derive our answer to research question rq2 our approach can accurately estimate occurrence probabilities for its reported counterexamples.
rq3.
we ran our approach to verify the robot car applications with different bounds of path length.
the experimental platform is a dell desktop pc with an intel core cpu .53ghz and 2gb ram running windows .
we recorded the spent time and memory in each run which are shown in table .
as we can observe from the table when the bound is set to our approach spent about minutes and consumed around mb memory on average.
clearly given enough time our approach is able to handle larger bounds.
however if we focus on counterexamples with relatively high probabilities a bound of is already sufficient for the robot car applications.
this is because we observed that when the bound was set to the increase of the number of counterexamples with a probability higher than which is a very small likelihood for a counterexample to occur tends towards 206t able time and memory costs for verification with different bounds a pplication5 a pp14.0s 40mb6.8s 48mb10.5s 61mb19.8s 72mb38.5s 84mb72.3s 97mb109.3s 118mb196.3s 129mb310.8s 153mb500.3s 178mb a pp22.3s 55mb3.8s 70mb7.0s 87mb12.8s 102mb22.5s 116mb41.3s 134mb75.5s 153mb147s 168mb243.8s 186mb491.3s 204mb a pp35.0s 31mb9.3s 44mb16.5s 52mb28.8s 63mb54.0s 75mb92.8s 81mb164.3s 89mb323.5s 97mb480.8s 108mb886.3s 124mb a pp45.8s 44mb9.5s 51mb17.5s 59mb33.0s 68mb60.8s 81mb105.3s 103mb198.8s 117mb344.8s 132mb508.0s 155mb976.3s 196mb a pp53.8s 58mb7.0s 65mb11.5s 83mb19.5s 94mb38.5s 112mb71.5s 137mb137.0s 162mb243.8s 194mb419.5s 205mb529.3s 217mb a pp62.3s 38mb3.5s 45mb6.8s 53mb13.0s 59mb24.3s 64mb47.0s 71mb90.8s 78mb177.0s 84mb331.0s 96mb633.3s 113mb a pp75.3s 41mb9.0s 53mb15.3s 64mb27.5s 71mb51.5s 79mb96.3s 94mb177.5s 124mb314.3s 167mb528.8s 195mb971.8s 211mb a pp84.3s 47mb7.5s 55mb14.5s 67mb26.0s 84mb47.3s 95mb94.8s 110mb178.0s 135mb302.3s 157mb528.3s 198mb1000.5s 245mb a pp95.5s 39mb9.5s 47mb18.8s 55mb37.3s 63mb60.3s 79mb116.0s 90mb203.0s 99mb385.0s 110mb742.0s 157mb1012.5s 203mb a pp103.3s 29mb6.3s 43mb11.3s 60mb22.0s 75mb39.0s 91mb69.5s 105mb130.5s 119mb248.5s 168mb472.5s 211mb810.0s 264mb a pp114.5s 45mb8.0s 53mb15.0s 60mb24.8s 76mb45.0s 91mb92.5s 105mb180.3s 129mb313.8s 154mb525.3s 212mb998.5s 231mb a pp125.0s 35mb8.8s 46mb17.3s 60mb33.5s 68mb59.0s 81mb113.8s 90mb208.5s 107mb382.3s 113mb692.0s 163mb1026.5s 217mb number of counterexamples bound of path length app app2 app3 app4 app5 app6 figur e the growing trend of the number of counterexamples with the increase of the bound of path length.
stability.
figure illustrates the number of counterexamples with a probability higher than 5when the bound was set from to for app to app .
from these discussions we can derive our answer to research question rq3 our approach can scale well to large bounds of path length and it can detect more counterexamples when the bound increases.
.
threats to validity we analyze threats to the validity of our conclusions below.
threats to construct validity.
the main threat to construct validity for our study is that we may not have run our robot car applications adequate times in the field study in order to obtain accurate likelihoods of occurrence of the counterexamples.
to reduce this threat we ran each application in simulation for times to get the simulated probabilities as complementary evidence.
another potential threat to construct validity is the threshold of probability used to filter out low probability counterexamples when evaluating the impact of the bound of path length.
nevertheless we set the probability threshold to which is an extremely small likelihood for a counterexample to occur in real cases.
in fact we believe developers should focus mainly on counterexamples with much higher probabilities in a realistic setting.threats to internal validity.
there are mainly two threats to internal validity.
one is that the given ranges and distributions of variables for modeling uncertainty may not be realistic.
to reduce this threat we have conducted a lot of field studies and performed careful statistical analysis.
the other threat to internal validity is the selected bound of path length.
it is possible to find more counterexamples with a larger bound.
nevertheless according to our experiments the number of counterexamples will tend to be stable as the bound increases.
so we selected a proper value for the bound in experiments.
threats to external validity.
the main threat to external validity is that our conclusions may not generalize to other self adaptive applications.
to reduce this threat we selected different robotcar self adaptive applications with various sizes as our experimental subjects.
meanwhile we made our best efforts in selecting them being independently developed by different developers and validated by both simulation and field study.
the results consistently support our conclusions.
although we try to make our approach applicable to other self adaptive applications there still is a strong need for validating our approach with more realistic applications.
.
related work in this section we discuss selected related work on self adaptive applications.
cheng et al.
and lemos et al.
presented a comprehensive and in depth analysis of the current research status including methods and challenges to which interested readers can refer.
here we focus on modeling testing and verifying selfadaptive applications.
modeling self adaptive applications.
to model a self adaptive application there are several optional methodologies such as goaloriented or rule based methodologies.
goal based modeling offers a means to identify and visualize different alternatives for satisfying the overall objectives of a system .
the goals here capture the intentions of a stakeholder on a self adaptive application and its execution environment and can be used to model the requirements of self adaptive applications .
rule based modeling uses rules explicitly or implicitly to model an application s expected reactions to monitored events such as the a fsm approach .
there are also other pieces of work related to modeling self adaptive applications.
andersson et al.
defined four categories of dimensions for modeling self adaptive applications selfadaptive goals causes or triggers of self adaptation mechanisms used to adapt and effects of those mechanisms on applications.
dobson et al.
identified four aspects of self adaptive applications around which decisions can be organized collection analysis decision and action.
brun et al.
discussed the importance of making the adaptation control loops explicit during an application s development process and outlined several types of control loops that can lead to adaptation.
verifying and testing self adaptive applications.
designing and deploying certifiable verification and validation methods for self adaptive applications is one of the major research challenges for the software engineering community in general and the selfadaptive applications community in particular .
concerned properties for self adaptive applications include safety liveness and reachability reliability and stability .
in recent years different methods have been used in to verify self adaptive applications.
zhang and cheng introduced an approach to creating formal models for the behavior of self adaptive applications.
they also presented a process to construct verify and validate these models.
bartels et al.
used the process algebra csp for the specification verification and implementation of self adaptive applications .
camara et al.
proposed an approach for the verification of self adaptive applications based on stimulation and probabilistic model checking.
it stimulates the environment and collects data about how an application reacts environmental changes to evaluate whether important properties are satisfied within certain confidence levels.
model checking is also widely used to detect some well known fault patterns in self adaptive applications .
there are also many studies focusing on testing self adaptive applications.
xu et al.
used error patterns to dynamically detect and analyze responsible faults.
tse et al.
used isotropic properties of contexts as metamorphic relations for testing contextsensitive software and presented techniques for generating effective test cases.
wang et al.
proposed to augment existing test cases to expose faults by focusing on context switching points that can affect application adaptations.
besides test case generation and augmentation there are also efforts spent on test adequacy criteria research.
for instance lu et al.
proposed a new set of coverage criteria to test data flows caused by context uses in self adaptive applications.
these pieces of work detect faults in self adaptive applications and contribute to their dependability at design and development phases.
some other studies also tried to improve self adaptive applications dependability but from different perspectives.
for example related studies detected and resolved inconsistency in contexts fed to a self adaptive application.
consistent context data is an important prerequisite for dependable adaptations.
our previous work focused on improving the dependability of self adaptive applications by monitoring application executions and checking consistency constraints at runtime.
kulkarni et al.
also introduced a runtime errorhandling framework for programming robust self adaptive applications by adopting forward recovery strategies.
last but not least ramirez et al.
introduced a technique for automatically discovering combinations of environmental conditions that produce requirement violations and latent behaviors in a self adaptive application.
managing uncertainty.
uncertainty poses a big threat to correct and reliable self adaptations.
this problem is gaining increasing attention in recent years.
ramirez et al.
reported a tax onomy of uncertain factors that can affect self adaptive applications.
their work called for a spectrum of research efforts from requirement specification application design to runtime support.
there are some studies focusing on how to handle uncertainty at design time for self adaptive applications .
esfahani et al.
described an approach to tackling the challenge of uncertainty by assessing both positive and negative consequences of uncertainty and proposed a framework for managing uncertainty in selfadaptive applications .
cheng et al.
proposed a requirement language relax to explicitly address uncertainty by enabling engineers to specify uncertainty in application requirements.
in their work adaptation is achieved by relaxing non critical requirements.
ghezzi et al.
proposed a framework that supports adaptation to non functional manifestations of uncertainty relying on alternative or optional functionalities.
the framework allows engineers to derive a finite state automaton augmented with probabilities from an initial model of a self adaptive application.
famelis et al.
specified uncertainty using annotations with well defined semantics that transforms an application model into a partial model and presented an approach to reasoning with such models.
our work differs from the existing work in three aspects.
first we explicitly model environmental constraints and uncertainty caused by unreliable sensing and adaptation for self adaptive applications.
second we present a novel approach which exploits the power of smt solvers to verifying the correctness of self adaptive applications affected by uncertainty.
third we propose to rank counterexamples according to their probabilities which has not yet been considered in the above literature.
.
conclusion in this paper we propose a novel approach to verifying selfadaptive applications.
by explicitly considering the environmental constraints the approach avoids reporting false counterexamples that will not happen in real environments.
at the same time by taking error ranges of the environment related variables into account the approach can find lots of potential counterexamples faults that would otherwise be overlooked by methods not considering uncertainty in environmental interactions.
our approach also prioritizes its reported counterexamples according to their occurrence probabilities whose accuracy has been well validated by both simulated experiments and field study.
this work can still be improved.
for example we need to validate this work with more real world applications.
in addition to environmental interactions we also plan to extend our consideration of uncertainty to those from other sources such as requirements and adaptation decisions.
.