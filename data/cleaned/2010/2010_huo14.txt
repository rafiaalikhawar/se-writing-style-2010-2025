improving oracle quality by detecting brittle assertions and unused inputs in tests chen huo computer information sciences department university of delaware de usa huoc udel.edujames clause computer information sciences department university of delaware de usa clause udel.edu abstract writing oracles is challenging.
as a result developers often create oracles that check too little resulting in tests that are unable to detect failures or check too much resulting in tests that are brittle and di cult to maintain.
in this paper we present a new technique for automatically analyzing test oracles.
the technique is based on dynamic tainting and detects both brittle assertions assertions that depend on values that are derived from uncontrolled inputs and unused inputs inputs provided by the test that are not checked by an assertion.
we also presented oraclepolish an implementation of the technique that can analyze tests that are written in java and use the junit testing framework.
using oraclepolish we conducted an empirical evaluation of more than real test cases.
the results of the evaluation show that oraclepolish is e ective it detected tests that contain brittle assertions and tests that have unused inputs.
in addition the results also demonstrate that the costs associated with using the technique are reasonable.
categories and subject descriptors d. .
testing and debugging general terms experimentation measurement keywords unit testing improving oracles brittleness unused inputs dynamic tainting mutation .
introduction although software tests are conceptually simple they are composed of two parts inputs that are used to execute the program under test and an oracle that is used to verify that the execution induced by the inputs produces the expected results they are often di cult to write in practice.
this permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
fse november hong kong china copyright acm ... .
.is especially true for modern software which is typically large and complex.
together these characteristics produce a situation where test writers have an imperfect understanding of not only what inputs a program may receive but also how the program should behave and what outputs it should produce.
in short when writing tests selecting neither inputs nor oracles is straightforward.
fortunately the software engineering research community has provided many techniques that can help developers write test cases e.g.
.
in general these techniques focus primarily on test data selection or generation i.e.
choosing inputs .
while such techniques can be successful in helping developers write tests they only address part of the overall problem.
in order to provide more e ective help it is necessary to not only provide developers with help choosing inputs but also with help creating oracles.
in many testing frameworks an oracle is encoded as a set of assertions that check whether a subset of a program s state variables have particular values.
considered in this way choosing an oracle is analogous to choosing a point on the continuum from checking nothing to checking the entire state of the program.
while neither extreme is appropriate oracles that check nothing will never nd bugs and oracles that check everything will likely be di cult to maintain and enormous there is a point somewhere between that represents the ideal oracle.
unfortunately identifying this point is challenging.
in practice the oracles written by testers often miss the mark by either checking too little by failing to include assertions for relevant variables which can result in tests that are unable to reveal failures i.e.
missed warnings or checking too much by including assertions about irrelevant variables which can lead to brittle tests that fail when they should not i.e.
false warnings .
existing work on assessing the quality of test oracles addresses only the rst of these possibilites by detecting tests that are likely missing assertions e.g.
.
in this paper we present a novel dynamic analysis technique that addresses both possibilites.
the technique is based on dynamic tainting and works by tracking the ow of controlled and uncontrolled inputs along data and controldependencies at runtime.
intuitively controlled inputs are inputs explicitly provided by the test itself e.g.
constants that appear in the test method and all other inputs are considered uncontrolled.
when a test nishes execution the technique uses the tracked information to generate reports that identify brittle assertions assertions that check values that are derived from inputs that are not controlled by the test and unused inputs inputs that are controlled by the test public class employeetest extends testcase string firstname lastname ssn double basesalary commissionrate .
grosssales employee e new employee firstname lastname ssn basesalary commissionrate grosssales public void testtostring e.setfirstname john e.setgrosssales e.setbasesalary string expected employee null n social security number null n total salary .
assertequals e.tostring expected public void testabbreviatelastname e.setlastname moore towers string expected moore assertequals e.abbreviatedlastname expected figure an example of a brittle test case.
but are not checked by an assertion.
these reports are then ltered to remove false positives and presented to testers.
to evaluate our technique we created a prototype implementation that analyzes java applications and tests written using the junit testing framework.1we used the prototype tool to analyze over 000tests from real open source software projects and to answer several research questions about the feasibility and e ectiveness of the technique and the quality of existing test oracles.
this work makes the following contributions the de nition of a new technique that can automatically analyze tests to detect both brittle assertions and unused inputs.
a prototype implementation of the technique that implements the technique for java applications with test cases written using junit.
an extensive empirical study that demonstrates our tool s feasibility accuracy and usefulness.
.
motivating example in this section we provide an example that will be used in the remainder of the paper to illustrate our technique.
figure shows the example which consists of several tests derived from the test suite for commissionemployee a small application that is used to perform various computations necessary to calculate payroll information for sales employees.
consider testtostring which is checking whether employee stostring method produces the expected output.
while this test ful lls its goal it has several problems.
first testtostring is brittle because it makes assertions about values derived from inputs that it does not control.
more speci cally the test assumes that the values of the employee s last name social security number and commission rate are not changed between the time when the employee is created and the time when the result of tostring is checked.
note that no such assumption is made about the employee s rst name gross sales or base salary as these values are controlled by the test i.e.
they are explicitly set to john and respectively during the execution of the test .
int x y z int a input int b input x a y b z x y a int x y int a input if a x else6 x y b figure code examples that illustrate information ow through data and control dependencies.
in practice there are many ways that testtostring s assumption that the employee s last name social security number and commission rate are not changed could be violated.
for example if testabbreviatelastname was added to the test suite testtostring would fail intermittently depending on the order in which the test cases are executed.
iftesttostring is executed rst the assumption holds and both tests will pass.
however if testabbreviatelastname is executed rst the assumption is violated and testtostring will fail because the value of the employee s last name will no longer be null.
to prevent the possibility of failures due to brittleness a test should not check values derived from inputs that it does not control.
for testtostring this can be accomplished by explicitly controlling the values of the employee s last name social security number and commission rate as is done for rst name gross sales and base salary.
this can also be accomplished by creating a new instance ofemployee with known values or by explicitly setting the employee s last name social security number and commission rate.
both of these options x the test s brittleness by ensuring that the values checked by the its oracle are derived from controlled inputs.
the second problem with testtostring is that one of the test s controlled inputs is unused.
although the test speci cally sets the employee s rst name to john none of its assertions check values derived from this input.
unused inputs suggest that the test s author is unsure about the behavior of the application under test possibly because modi cations made to the application have not been re ected in the test or simply because the tester was unfamiliar with the code when the test was written.
in the worst case an unused input indicates that a test is missing an assertion which could lead to missed warnings situations where the test should fail but does not.
even if it they do not lead to missed warnings unused inputs increase the costs of test maintenance by increasing the cognitive burden on the tester.
to eliminate unused inputs additional assertions could be added to the test e.g.
adding assertequals e.getfirstname john totesttostring or the unused inputs could be removed e.g.
deleting line in testtostring .
.
background in this section we provide background information on dynamic tainting.
note that the material in this section is paraphrased from our previous work on dynamic tainting .
intuitively dynamic tainting consists of marking some data values in a program with a piece of metadata called a taint mark and propagating taint marks according to how data ows in the program at runtime.
in this way dynamic tainting can track and check the ow of information through a program while it executes.information ows through a program in two ways through data dependences and through control dependences.
we illustrate these two kinds of ows using the code examples in figure .
first consider the code in figure 2a.
assume that variable ais tainted with taint mark taat line and variable bis tainted with taint mark tbat line .
given this assignment of taint marks variables x y and zwould be tainted at the end of the execution with sets of taint marks ftag ftbg andfta tbg respectively.
taint mark tawould be associated with xbecause the value of ais used to calculate the value of x x a that is xis data dependent on a. analogously ywould be tainted with tbbecause the value ofbis used to calculate the value of y y b .
finally zwould be tainted with both taandtbbecause the values of both xandyare used to compute the value of z z x y that is zis indirectly data dependent on both aandb.
consider now the code in figure 2b and assume that variableais tainted with taint mark taat line .
although a s value is not directly involved in the computation of xin this case it nevertheless a ects x s value the outcome of the predicate at line decides whether line or line will be executed that is the statements at lines and are control dependent on the statement at line .
therefore the value ofxat the end of the execution would be associated with taint mark ta.
in general the propagation of taint marks along data dependences is called dataow propagation and the propagation along control dependences is called controlow propagation .
.
detecting brittle assertions and unused inputs this section presents our technique for helping testers improve the quality of their test oracles.
we rst provide an intuitive description of the technique and then discuss its main characteristics in the following steps.
.
overview the overall goal of the technique is to reduce the costs of testing by automatically identifying and helping testers x both brittle assertions and unused inputs.
the basic intuition behind the approach is that dynamic tainting due to its ability to mark and track inputs at runtime can be successfully used to accomplish this goal.
in this spirit our approach works by assigning taint marks to two types of inputs inputs that are controlled by the test and inputs that are not controlled by the test tracking both types of inputs by suitably propagating the taint marks as a test executes and identifying when an assertion is executed which taint marks are associated with the values checked by the assertion.
the taint marks discovered in the third step allow for identifying situations where a test checks too much i.e.
is brittle and situations where a test checks too little i.e.
has unused inputs .
before presenting the details of the approach we discuss how it works on testtostring from figure .
this test is brittle because it contains assertions about values derived from uncontrolled inputs and also has unused inputs because some controlled inputs or values derived from them are not checked by an assertion.
figure provides an intuitive view of how our technique can detect both problems.
the top of figure shows testtostring s inputs.
note that the inputs are divided into two categories controlled testtostring ssn nulltotal salary .00uncontrolledinputsnullssn0.5commission ratenulllast name john first name200gross sales100base salarycontrolledinputs assertionslast name null figure intuitive view of the application of our technique to testtostring from figure .
inputs and uncontrolled inputs.
intuitively controlled inputs are values that are provided as part of the test itself in this case john 200and100 and uncontrolled inputs are inputs that are not explicitly set during the execution of the test in this case null used to initialize lastname and ssn and used to initialize commissionrate .
section .
provides a detailed discussion of how the technique identi es controlled and uncontrolled inputs.
to make the example more clear each input shows both the value top and a brief description of what the value represents bottom .
for example the value john represents the rst name of the employee the value represents the employee s gross sales value etc.
the bottom of figure shows conceptually the test s oracle.
the call to assertequals at line implicitly checks whether the employee s rst name is equal to john whether the employee s social security number is equal to null and whether the employee s total salary is equal to .
the lines that traverse testtostring illustrate intuitively how our technique assigns a unique taint mark to each input.
in the gure each input is the source of a unique line.
in addition the color and style of the lines indicate the type of input green dashed lines indicate taint marks assigned to controlled inputs and solid red lines indicate taint marks assigned to uncontrolled inputs.
in the remainder of the paper we refer to taint marks assigned to controlled inputs asc marks and taint marks assigned to uncontrolled inputs asu marks.
the lines in the gure also illustrate how our technique tracks inputs at runtime by propagating the taint marks as the test executes.
for example the line connecting the input null to the assertion last name null indicates that the value checked by the assertion the employee s last name is derived from the value null.
similarly the lines that connect the inputs and 5to the assertion total salary .
indicate that the value checked by the assertion the employee s total salary is derived from the values and .
the technique uses this information to detect brittle assertions and unused inputs.
in figure both types of errors are shown using a bug icon.
brittle assertions are detected by identifying when an assertion occurs the set of taint marks associated with the values checked by the assertion and checking whether the set of taint marks contains a u mark.
if the set does contain aumark the assertion is considered to be brittle.
for example as figure shows there are three taint marks associated with the value checked by the assertion total salary the taint marks for and .
because the taint mark for 5is au mark the technique identi es this assertion as brittle.
similarly the other two assertions are also identi ed as brittle because the values that they check are tainted with a u mark.
unused inputs are detected by computing the union of all taint marks associated with every value checked by an assertion and checking whether the union contains every c mark assigned during the execution of the test.
if a c mark is not present in the union its corresponding input is unused.
for example in figure the union of all taint marks associated with values checked by the assertions does not contain the c marks for john .
consequently john is identi ed as an unused input.
in addition to detecting brittle assertions and unused inputs the information provided by propagating taint marks is used to give testers additional data about the identi ed errors.
intuitively the technique tracks backwards to identify the origins of the problems and outputs the source of each input i.e.
the locations where the controlled and uncontrolled inputs were assigned a taint mark .
these locations can serve as a starting point to help testers x the identi ed problems with their assertions.
.
input tainting input tainting is responsible for associating taint marks with a test s inputs.
the technique intercepts the execution of the test at speci c points and assigns either an c mark for controlled inputs or a u mark for uncontrolled inputs.
.
.
tainting controlled inputs currently our technique considers two types of values to be controlled inputs.
first the technique considers values constants that are used during the execution of the test method itself and not passed to an assertion method to be controlled inputs.
for example in figure the constant john used at line is a controlled input but the constant moore at line is not because it is used as an argument toassertequals on line .
the decision to only include constants in the test method itself is based on our experience domain knowledge and intuition about how testers write tests.
initially the technique also considered constant values from the test s setup code to be controlled inputs.
however we found that many tests use the same setup code to construct a complex state.
while when considered individually the tests appear to have unused inputs i.e.
parts of the common state that are not checked when they are considered collectively they check the entire state.
in future work we plan to extend the technique to consider entire test suites rather than individual tests when identifying missing assertions see section .
second the technique considers the return values of noargument methods called in the test method itself and also implemented in the test class to be controlled inputs.
we found that no argument methods are frequently used to separate long sequences of initialization code from a test.
moving such initialization code to a separate method decreases the size of the test which can improve its readability and understandability.
because such methods are conceptually part of the test we consider their results to be controlled inputs.to taint constants that are used as part of the test method the technique simply intercepts the loading of the constants and applies a unique c mark to the loaded constant.
similarly to taint the return value of no argument methods implemented in test suite the technique intercepts the test s execution immediately after the method returns and applies a unique c mark to the return value.
note that if either type of controlled input is used repeatedly as would be the case inside of a loop the technique reuses the same c mark for each iteration.
based on the results of our experiments see section we found that this approach produces the most understandable reports.
from the point of view of a tester regardless of the number of times an input is used it is still conceptually the same input.
as a concrete example of how our technique assigns c marks to controlled inputs consider testtostring in figure .
the technique identi es three controlled inputs in this test the literal value john used at line the literal value 200used at line and the literal value 100used at line .
when each of these constants is loaded the technique assigns a unique c mark to each value e.g.
c1is assigned to john c2is assigned to and c3is assigned to .
.
.
tainting uncontrolled inputs currently our technique considers two types of values to be uncontrolled inputs.
first the values of global variables static mutable elds are considered to be uncontrolled inputs.
the intuition behind this choice is that reading the value of a global variable is the most likely way for a test to unintentionally depend on a value that it does not control.
because globals variables maintain their state and can be written to at any time a test has no way of knowing what values they contain.
similarly tests can also unintentionally depend on the contents of the les databases network connections etc.
we chose not to consider values read from such sources as uncontrolled inputs because unit tests typically use mock objects instead of the real resources.
second the values of all non nal elds in the test s containing class are considered as uncontrolled inputs.
we choose to consider such values because the elds of the test s class s are essentially global variables within the context of the test class.
their values can be changed by any test method inside the class.
to assign u marks to global variables the technique iterates over all of the classes that are loaded at the start of the test.
for each loaded class the technique assigns a unique u mark to each non nal static eld.
to assign u marks to the values of the test s class s elds it is necessary to understand how elds are initialized by the java virtual machine jvm .
when an object is initialized each of its elds is assigned the initial value for its type.2then if the eld has an variable initializer e.g.
public int i code added by the compiler to the object s constructors evaluates the variable initializer and assigns the result to the eld.
this means that in order to assign taint marks to the test s class s elds the technique must intercept object initialization as well as the execution of variable initializers.
if only object initialization was intercepted the taint marks associated with the elds would be overwritten when the result of the variable initializer was assigned to the eld see section .
for additional information on how taint marks propagated .
if only the execution of variable initializers was intercepted elds without a variable initializer would not be assigned a taint mark.
to assign taint marks to the initial values of the test s class s elds the technique assigns a unique u mark to each eld at the end of object initialization.
to assign taint marks to the results of variable initializers the technique identies the code added by the compiler by checking the debug information.
compiler added code will have a source line location that is outside the bounds of the constructor.
after identifying the compiler added code the technique intercepts the execution immediately after the variable initializer is evaluated and applies a unique u mark to the result.
note that taint marks assigned to the results of variable initializers will overwrite the taint marks assigned during object initialization.
while this does not impact the performance of the technique the only consequence is that unnecessary taint marks are created a simple static analysis could be used to identify elds with variable initializers.
such elds could then be skipped when taint marks are assigned during the initialization process.
as a concrete example of how our technique assigns umarks to uncontrolled inputs consider testtostring in figure .
employeetest has six elds only one of which has a variable initializer commissionrate .
when an instance of employeetest is initialized all six of its elds are assigned a unique u mark e.g.
firstname is assigned u1 lastname is assigned u2 ssnis assigned u3 basesalary is assigned u4 commissionrate is assigned u5 and grosssales is assigned u6 .
during the execution of employeetest s constructor when commissionrate is assigned the value the taint mark assigned during object initialization is overwritten with a fresh taint mark e.g.
u5is overwritten by u7 .
later when testtostring is executed the technique would assign a unique u mark to each static mutable eld of every currently loaded class.
.
.
recording supplemental information regardless of the type of taint mark our technique performs an additional action when assigning a taint mark tto an input i. to help testers debug the problems identi ed by the technique additional information is recorded.
more speci cally the technique logs a tuple ht loc valuei where locis the location in the execution where the taint mark was associated with the input and value is the initial value of the input.
the location is expressed di erently depending on the type of taint mark.
for c marks the location is the le name and line number corresponding to where the constant or return value was used.
for u marks the location is the fully quali ed name eld name and declaring class name of the eld that contains the input.
this information is used by our technique when generating reports as described in section .
.
.
taint mark propagation a taint propagation policy speci es how taint marks are propagated during execution.
typically it is de ned along two dimensions how to combine taint marks and which types of dependences to consider.
our technique s policy for combining taint marks is fairly intuitive.
in general the technique taints all values written by a statement with the union of all taint marks associated with the values read by that statement.
for instance afterthe execution of statement x y z where yand zare tainted with taint marks t1andt2 respectively xwould be associated with the set of taint marks ft1 t2g.
the only type of statement where the techniques deviates from this general policy is the execution of native methods.
because native methods are executed by the jvm it s is often unclear which values are read by the native method.
rather than require a precise model of every native method the technique conservatively assigns the union of all taint marks associated with the native method s arguments to its return value.
when choosing which dependences to consider our technique considers both dataow and controlow dependencies.
identifying dataow dependencies is trivial as they are encoded as the semantics of the language.
identifying controlow dependencies is more challenging.
a controlow dependence arises when a conditional branch bdecides whether a statement sis executed.
in this case the values that a ect b s outcome indirectly a ect the values of any data written by s. therefore to be conservative the taint marks associated with the values read by bmust be combined and associated with the values written by s. to achieve this our technique uses an approach that we proposed in prior work .
in brief the technique keeps track of relevant taint marks at runtime by leveraging statically computed post dominance information.
when an execution reaches a conditional branch b the technique computes t the union of the taint marks associated with the values read by b and adds a pair hb titocf the set of active control ow marks.
when execution reaches the immediate postdominator of a conditional branch b it removes from cf all pairshx yisuch that xis equal to b. note that cfwill contain multiple pairs with xequal to bwhen bis executed as part of a loop.
each iteration will add a new pair hb ti tocf all of which must be removed when the immediate post dominator is executed.
when a statement sis executed andcfis not empty the technique computes the union of all active control ow marks i.e.
the union of y for each pairhx yiincf and adds this set to the set of taint marks associated with the values written by s. .
checking taint marks this third part of our technique checking is responsible for two tasks identifying brittle assertions and unused inputs and generating the error reports that will be presented to testers.
to identify brittle assertions the technique intercepts the execution of comparison operations e.g.
greater than less than equals etc.
that occur inside the execution of an assertion method e.g.
assertequals .
intercepting the execution of comparison operations rather than simply examining the actual argument of the assertion method allows for a more precise identi cation of brittle assertions.
for example if the actual parameter of the assertion method is an object examining the taint marks associated with all of the object s elds is likely to be incorrect as not all of the elds are necessarily involved in checking whether the actual and expected arguments are equal.
rather than attempting to identify a priori which values are used to check for equality the technique can simply monitor the comparison operations to achieve the same e ect.
in addition testers often inadvertently swap the order of the actual and expected arguments which means that the actual parameter may not in the correct location which would result in incorrect reports.testtostring appears to be brittle.
the assertions at the following lines check values that are derived from uncontrolled inputs assertequals at line depends on employeetest.lastname being null object initialization employeetest.ssn being null object initialization employeetest.commissionrate being .
object initialization a report for brittle assertions.
testtostring appears to be missing one more assertions.
the following values are provided as input but are not checked by an assertion john employeetest.java line b report for unused inputs.
figure example reports output by our technique when run on testtostring from figure .
for each comparison operation inside of an assertion method the technique identi es the taint marks associated with the values involved in the comparison and checks whether the set of identi ed taint marks contains a u mark.
if a u mark is found the technique detects a brittle assertion.
to identify unused inputs the technique calculates the union of all c marks that were encountered when checking for brittle assertions.
the technique then subtracts this set from the set of all c marks that were assigned to controlled inputs.
if the resulting set is not empty the inputs initially assigned with the remaining c marks are marked as unused.
as a concrete example of how the checking part of the technique operates consider again testtostring from figure .
for this test the technique would intercept the comparison operations that occur inside the call to assertequals .
because the actual value is a string the string class s equals method is used to perform the check.
the equals method uses a series of equality comparisons i.e.
to check whether the same characters make up each string.
each time this equality is executed the technique determines whether either character is tainted with a u mark.
because the actual value is derived from three uncontrolled inputs three u marks are found and a brittle assertion is detected.
at the end of the test s execution the technique calculates the union of all encountered c marks.
because only values tainted with only two of three total c marks were checked by the assertion an unused input report for the remaining mark the one initially assigned to john is created.
figure shows the error reports generated by the technique when run on testtostring .
as the gure shows both the brittleness report top and the unused input report bottom include all of the information necessary to help testers x the identi ed issues.
the brittleness report includes the name and location of the brittle assertion assertequals on line the uncontrolled values that were used to compute the values checked by the assertion null null and .
the names of the elds where the uncontrolled values were stored employeetest.
rstname employeetest.ssn and employeetest.commissionrate and the locations where the uncontrolled values were stored into the elds during object initialization .
note that to collect the location information the technique traverses the test s call stack to nd the name of the outermost enclosing assertion method invocation and the location where the assertion method was invoked.
the unused input report includes the controlled inputs that were not checked by an assertion and the line number where the value was loaded.
.
removing false positives the purpose of the fourth part of the technique is to lter false positive error reports.
taint mark propagation is known to be imprecise especially in the case of native methods.
as a result error reports generated by the third part of the technique may be false positives.
more speci cally the technique may generate false positive reports if it underpropagates c marks or over propagates u marks.
as a result controlled inputs may appear to be unused when in fact they are used and uncontrolled inputs may appear to be checked by an assertion when in fact they are not.
to eliminate such false positives the technique uses an approach inspired by mutation testing .
essentially the technique preemptively makes changes that may happen in the future and checks to see whether such changes alter the outcome of the test.
more speci cally for each input that is identi ed as the cause of a brittle assertion or as an unused input the technique re executes the test.
as the test is being re executed at the point when the taint mark was assigned to the input in the original execution the technique mutates the value of the input to a randomly chosen value of the same type.
note that data and controlow analysis is not needed to accomplish this.
the technique then compares the outcomes of the re executed and original executions.
in the case of uncontrolled inputs that cause brittle assertions we would expect that changing the input s value would alter the outcome of the test.
if a test checks values derived from an input changing the value of the input should change the outcome of the test.
if the outcome of the test does change the report is a true positive i.e.
if the change were to be made the test would fail and is presented to the user.
conversely if the outcome of the test does not change the report is a false positive i.e.
the u mark should have been over written but was not and is discarded.
in the case of unused inputs we would expect that changing the value of the input would not alter the outcome of the test.
if an input is really unused its value doesn t matter.
if the outcome of the test does not change the unused input report is a true positive and is presented to the user.
conversely if the outcome of the test does change the error report is a false positive i.e.
the c mark should have propagated to an assertion but did not and is discarded.
note that this ltering strategy is precise reports that are identi ed as true positives have an associated witness a concrete change that will cause the test to fail but not safe reports that are identi ed as false positives may actually be true positives.
true positives can be identi ed as false positives from the point of view of the test when the randomly chosen value is indistinguishable from the original value.
for example consider an assertion that checks whether a value is positive.
if the original value checked by the assertion is 1and the randomly chosen replacement is the outcome of the assertion will be the same for both values.
to reduce the possibility of this occurring multiple re executions each with a unique value can be run or additional analysis could be performed to identify values that are more likely to cause the outcome of the test to change.
in the case of testtostring both of the error reports generated by the third part of the technique are true positives.
changing the value of commissionrate causes the test to fail and changing the value of the employee s rst name does not cause the test to fail.
.
evaluation to evaluate our technique we created a prototype implementation called oraclepolish and analyzed over 000tests for real java applications.
using the output of the tool we investigated the following research questions rq e ectiveness.
can the technique detect both brittle assertions and unused inputs in real test suites?
rq cost.
what are the costs associated with using the technique and are they reasonable?
note that rq1 provides a quantitative assessment of the technique it does not make any assumptions about whether the reported errors are likely to cause problems in the future.
conversely rq2 is a qualitative assessment that does take into account the users perspective.
the remainder of this section describes oraclepolish the prototype implementation of our technique the experimental subjects we chose the experimental protocol we used and the data we generated the results of evaluation and threats to the validity of our results.
the prototype implementation of our technique as well as the subjects we chose and the experimental data we generated are available from .
.
prototype tool oraclepolish is a prototype implementation of our technique for applications written in the java language using the junit testing framework.
it consists of three separate components the analyzer the runtime system and the mutator .
the primary task of the analyzer is to statically compute the information needed by the runtime system.
more speci cally the analyzer computes the post dominance information needed to perform controlow propagation.
the current implementation of the analyzer uses the t.j. watson libraries for analysis wala to perform the necessary analyses.
we choose wala because it analyzes java bytecode which means that we do not need to obtain the source code for all parts of the application provides built in dominator analyses and is extensible enough to allow us to easily implement the other necessary analyses.
the runtime system implements the input tainting taint mark propagation and checking parts of the technique described in section .
section .
section .
respectively.
the current implementation of the runtime system is an extension to java pathfinder jpf an explicit state software model checker for java software.3to assign taint marks to inputs oraclepolish uses jpf s listener callbacks to intercept class and object initialization and to intercept the execution of instructions that load constants.
to implement taint mark propagation oraclepolish uses jpf s bytecode overloading facilities to replace each java bytecode with a modi ed version that replicates the instruction s original semantics while also propagating taint marks.
finally to implement checking oraclepolish again uses jpf s listener callbacks to intercept the execution of comparisons instructions that occur inside of assertion methods.
the mutator implements the part of the technique that lters false positives see section .
.
it is also implemented as a plugin to jpf.
similarly to the runtime system the mutator uses jpf s listener callbacks to intercept class and initialization and to intercept the execution of instructions that load constants.
however instead of assigning taint marks the mutator randomly changes the values of the inputs.
currently the mutator re executes the test three times.
as we demonstrate in section .
this number is su cient to eliminate many false positives.
.
subjects the goal of the technique is to improve oracle quality by detecting brittle assertions and unused inputs.
to suitably evaluate the technique with respect to this goal we selected the test suites of 20applications as our subjects.
table describes the applications.
in the table the rst column subject shows the name and version of each application if available.
the rst eight applications commissionemployee through sudoku are taken from the proteja test suite executor and coverage monitor repository.4the remaining subjects were obtained from various repositories including the software artifact infrastructure repository sir which provides a variety of open source projects for empirical software engineering sourceforge 6a popular repository for open source projects and apache commons 7a collection of reusable components.
the second column loc shows the number of non blank non comment lines of code that comprise the application and the third column tests shows the number of tests in each application s test suite.
we chose the test suites of these applications as subjects for several reasons.
first the applications cover a variety of subject domains.
for example commons cli is a library for processing command line options commons io is a library for performing various input output operations joda time is a library for handling dates and times etc.
second the applications vary in size.
for example commons math has over 000lines of code while sudoku only has 376lines of code.
finally the test suites also vary in size.
the test suites for some of the application contain more than 000tests while others contain fewer than .
selecting test suites and applications of various sizes and subject domains improves the generalizability of our results.
after selecting our subjects we performed an initial sanity check and removed any tests that can not be run using jpf.
the number of remaining tests is shown in the fourth column executable .
for example although commons beanutils1.
.
s test suite contains 810tests 73of which are executable using jpf.
after ltering we were left with tests.
.
experimental protocol and data to generate the experimental data necessary for answering our research questions we ran oraclepolish on each of our 718tests and recorded its output.
the experiments were all conducted on the same computer a machine running ubuntu .
lts bit edition with a ghz intel core i7 processor and gb of memory.
java version .
.
was used and was con gured with gb of heap space default .
table shows the experimental data that we generated.
the last four columns in the table show the number of reports generated by the technique reports and the number of reports that are true positives tp for both brittle assertions and unused inputs .
the number of reports is the experimental subjects and data.
test suite brittle assertions unused inputs subject loc tests executable reports tp reports tp commissionemployee datastructures employee loopfinder point reductionandpriority sudoku commons beanutils .
.
commons cli .
commons collections .
.
commons io .
commons lang .
commons math .
jdepend .
.
jfreechart .
.
joda convert .
joda time .
jtopas .
pmd .
.
total total number of reports generated by the checking part of the technique see section .
and the number of true positives is the number of reports that remain after being ltered by the fourth part of the technique see section .
.
.
rq1 effectiveness the purpose of our rst research question is to determine the e ectiveness of the technique at detecting brittle assertions and unused inputs in real tests.
to answer this question we rst judged e ectiveness quantitatively by examining the number of true positive reports generated by oraclepolish.
as table shows for the subjects we considered oraclepolish was able to detect both brittle assertions and unused inputs.
in total it detected 164tests that contain at least one brittle assertion and 618tests that contain unused inputs.
these results are encouraging and also a bit surprising.
because most of the tests that we considered are from the test suites of mature applications we expected them to contain few errors.
it is interesting to note that oraclepolish detects far more unused inputs than brittle assertions.
intuitively this makes sense as unused inputs are unlikely to cause any observable problems.
while missing assertions may cause a test to pass when it should fail there is no way to detect this occurrence.
similarly there is not an easy way to measure the amount of additional e ort needed to comprehend and maintain tests with unused inputs.
as a result unused inputs are more likely go undetected and un xed than brittle assertions.
the second way we judged e ectiveness was by qualitatively assessing the reports generated by oraclepolish.
in the remainder of the section we provide a more detailed discussion of two randomly chosen brittle tests and two randomly chosen tests with unused inputs.
figure shows an excerpt of test13666 that is part of the test suite for commons cli.
oraclepolish detects that the assertion at line is brittle because it depends on several public class bugstest extends testcase public void test13666 throws exception options options new options option dir optionbuilder.withdescription dir .hasarg .create d options.addoption dir final printstream oldsystemout system.out try outputstream bytes new bytearrayoutputstream system.setout new printstream bytes helpformatter formatter new helpformatter formatter.printhelp dir options assertequals usage dir eol d arg dir eol bytes.tostring finally system.setout oldsystemout figure brittle assertions in test13666 ofoptionbuilder s static elds.
because optionbuilder is a singleton it is possible for other users of the class to leave it in an indeterminate state by starting to build an option but never calling create .
internally create resets the state of the optionbuilder so that it is safe to reuse.
to prevent the possibility that optionbuilder has already been partially con gured the test should call optionbuilder s reset method before using starting to build an option at line .
figure shows an excerpt of testput that is part of test suite for commons beanutils.
oraclepolish detects that the assertion at line is brittle because it checks the value of stringval .
as the code shows stringval is a static eld of the dynabeanmapdecoratortestcase .
because testput does not control the value of stringval it is assuming that public class dynabeanmapdecoratortestcase extends testcase private static final dynaproperty properties new dynaproperty ... private static string stringval somevalue private object values new object stringval ... private basicdynabean dynabean public void setup throws exception dynabean new basicdynabean dynaclass for int i i properties.length i dynabean.set properties .getname values modifiablemap new dynabeanmapdecorator dynabean false public void testput string newvalue abc assertequals stringval modifiablemap.put stringprop.getname newvalue assertequals newvalue dynabean.get stringprop.getname assertequals newvalue modifiablemap.get stringprop.getname figure brittle assertions in testput public class defaultkeyedvalues2dtests extends testcase public void testgetrowkey defaultkeyedvalues2d d new defaultkeyedvalues2d d.addvalue new double .
r1 c1 d.addvalue new double .
r2 c1 assertequals r1 d.getrowkey assertequals r2 d.getrowkey figure unused inputs in testgetrowkey stringval will not be modi ed between the time when the eld is initialized and the time when the assertion is executed.
to x this error the reference to the static eld could be replaced with the expected constant.
alternatively if the eld were to be made nal it would be guaranteed to have the expected value.
because the majority of dynabeanmapdecoratortestcase s other elds are nal this later option is likely to be the correct x. figure shows an excerpt of testgetrowkey from jfreechart s test suite.
oraclepolish detected two unused inputs in this test the value c1 at line and the value c1 at line .
although these values are used as arguments to the calls to addvalue at line and line they are not checked by an assertion.
adding additional assertions i.e.
assertequals c1 d.getcolumnkey and assertequals c1 d.getcolumnkey would ensure that not only are the correct row keys returned but also that the column keys are not modi ed.
figure shows an excerpt of test13 from employee s test suite.
oraclepolish detected three unused inputs in this test fn at line sn at line and ssn at line .
although these values are used to construct s2 a new instance ofsalariedemployee they are never checked by an assertion.
note that s1is used to construct the actual value passed toassertequals at line not s2.
in this case it is not clear how to best x the test.
the unused inputs could be deleted or the actual value could be constructed using s2 instead of s1.
public class employeetest extends testcase private string fn ln ssn private double s salariedemployee s1 new salariedemployee fn ln ssn s public void test13 s1.setweeklysalary fn fn ln sn ssn ssn salariedemployee s2 new salariedemployee fn ln ssn s string actual s1.tostring string expected salaried employee null null n ssn null n weekly salary .
assertequals actual expected figure unused inputs in test13 .
rq2 cost the purpose of our second research question is to investigate the costs of using oraclepolish and to determine if such costs are reasonable.
because our technique is fully automated the primary cost is its runtime overhead.
to investigate the runtime overhead that oraclepolish imposes we executed our subject tests twice once using thejvm and once using oraclepolish with the preceding static analysis and compared the execution times of these runs.
based on these measurements we found that running the tests using oraclepolish takes between 5and30times longer than running the tests using the jvm .
although this cost is signi cant we believe that it is reasonable.
in our experience developers will accept high overheads for tools that produce accurate results.
this is especially true when as is the case for oraclepolish the tools do not require any developer interaction and can be run overnight possibly as part of an automated build system whose results are inspected the next day.
in addition oraclepolish is an unoptimized prototype.
we chose to implement it as a jpf plugin because jpf is a general platform that already implements many of the capabilities we needed e.g.
the ability to associate metadata with runtime values .
however jpf s generality comes at a cost.
based on our experience with taint based techniques we believe that a custom implementation of oraclepolish could reduce its overhead to less than levels that are comparable to other recent tainting based approaches e.g.
by taking advantage of several optimizations e.g.
.
.
threats to validity there are several threats to the validity of our evaluation.
first we considered a limited number of tests all of which were written in java and used the junit testing framework.
in addition we ltered out tests that could not be run using jpf.
consequently our results may not generalize beyond the considered domains.
however the tests that we considered represent a wide range of application domains sizes and maturity levels.
therefore we believe that our results are promising and motivate further research.
second we qualitatively assessed the usefulness of the error reports generated by the technique ourselves which may introduce bias.
while we are planning to conduct a human study with developers to eliminate this threat in the future we did not believe that such a study was justi ed at this stage of the research.
.
related work to the best of our knowledge our technique is the rst technique that is able to detect both brittle assertions and unused inputs.
schuler and zeller propose checked coverage as an approach for assessing oracle quality .
the checked coverage of a test or test suite is the ratio of executed statements that compute values that are checked by the test to the total number of executed statements.
a low checked coverage score suggests that a test is likely to be missing assertions.
unlike our technique which uses dynamic tainting checked coverage uses backward dynamic slicing to compute the set of statements that contribute to values checked by the test.
while dynamic tainting and dynamic slicing are similar dynamic tainting due its focus on values rather than statements provides several bene ts.
for example our technique precisely identi es unused inputs while checked coverage only identi es sets of statements.
fixing the identi ed issues starting from sets of statements rather of inputs increases the amount of manual work that testers must perform.
in addition checked coverage shares the common limitation of all coverage based techniques deciding how much coverage is su cient.
obviously a checked coverage score of is bad but what about a score of ?
state coverage originally proposed by koster and kao and extended by vanoverberghe et al.
is similar to checked coverage.
the primary di erence is that state coverage is the ratio of executed output de ning statements ods statements that de ne a variable that can be checked by the test suite to the total number of odss.
unfortunately there have only been small case studies on the technique s e ectiveness so it is not clear how it compares to checked coverage.
however because state coverage is also a coverage metric it shares the same limitations as state coverage as compared to our technique.
the brittle assertion problem is closely related to the test dependency problem.
a recent study proposed an approach for detecting test dependencies in existing test suites.
the authors decribed a k bounded dependence aware algorithm which trims the search space for re ordering the test methods which otherwise requires a full permutation over the test methods.
the remaining sequences will be executed and checked to see if this certain ordering will alter the outcomes of some tests in the sequence.
however the search space is still so large that the authors had to limit the length of the sequence up to .
moreover the detection on dependencies are limited to the ones which will unveil their presence by altering the test outcome in a certain order.
our technique presents a more precise data ow analysis that will further narrow down the search space and also be aware of the dependencies which not only cause changes of outcomes in a certain order but also lie deep in the test suite and application code such that failing the tests in the future.
in addition to techniques that attempt to improve the quality of existing oracles there are also several techniques that attempt to automatically create oracles.
some of these techniques use mutation testing to discover how successful an oracle is at detecting mutants.
for example staats et al.
use mutation testing to support the creation or oracles by identifying the program variables are most successful at detecting mutants and therefore should be checked by an assertion .
conversely fraser and zeller use mutation testing to generate complete test cases including oracles .another recent work by loyola et al.
presents an approach that supports the generation of test oracles .
their technique rstly assumes that the test inputs have already been determined by the testers and then ranks variables based on the interactions and dependencies observed between them during program execution.
the authors conducted an empirical study by comparing the e ectiveness de ned by how many mutants killed of the oracle data sets selected by their technique and the original oracle data sets by the testers which shows improvement in nding faults.
other techniques create oracles from observed invariants e.g.
or generate oracles for speci c domains e.g.
guis web pages .
finally the large number of existing approaches for generating test inputs are also related to our work e.g.
.
however such approaches are not alternatives to our technique.
instead they are complementary.
as we discuss in section we plan on investigating how our technique can be combined with these approaches to improve the tests that they generate.
.
conclusions and future work in this paper we presented a new technique for automatically analyzing test oracles.
the technique is based on dynamic tainting and can detect both brittle assertions assertions that depends on values that are derived from uncontrolled inputs and unused inputs inputs provided by the test that are not checked by an assertion.
we also presented oraclepolish an implementation of the technique that can analyze tests that are written in java and use the junit testing framework.
using oraclepolish we conducted an empirical evaluation of the tool s performance on more than 000tests from real applications.
the results of the evaluation demonstrate that oraclepolish is able to detect both brittle assertions and unused inputs in real tests at a reasonable cost.
in future work we will implement the automated generation of recomendations to x the reported oracle problems.
the possible xes follow very regular and speci c patterns so that templates will be provided for the developers.
we will investigate the possibility of extending the technique to analyze entire test suites rather than individual tests.
this will allow the technique to more precisely handle certain situations such as when logically connected assertions are split among multiple test cases e.g.
the one assertion per test style .
we are also planning on conducting additional evaluations of the technique.
in particular we are interested in conducting human studies with testers to qualitatively assess the technique more fully such as the importance that developers would give to such reported issues and increasing the number and type of subjects that we consider.
finally we will investigate how our technique could be integrated with existing test generation approaches to improve the quality of the generated tests.
.