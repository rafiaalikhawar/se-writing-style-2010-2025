witchdoctor ide support for real time auto completion of refactorings stephen r. foster uc san diego la jolla ca srfoster cs.ucsd.eduwilliam g. griswold uc san diego la jolla ca wgg cs.ucsd.edusorin lerner uc san diego la jolla ca lerner cs.ucsd.edu abstract integrated development environments ides have come to perform a wide variety of tasks on behalf of the programmer refactoring being a classic example.
these operations have undeniable benefits yet their large and growing number poses a cognitive scalability problem.
our main contribution is witchdoctor a system that can detect on the fly when a programmer is hand coding a refactoring.
the system can then complete the refactoring in the background and propose it to the user long before the user can complete it.
this implies a number of technical challenges.
the algorithm must be highly efficient handle unparseable programs tolerate the variety of ways programmers may perform a given refactoring use the ide s proven and familiar refactoring engine to perform the refactoring even though the the refactoring has already begun and support the wide range of refactorings present in modern ides.
our techniques for overcoming these challenges are the technical contributions of this paper.
we evaluate witchdoctor s design and implementation by simulating over refactoring operations across three opensource projects.
the simulated user is faster and more efficient than an average human user yet witchdoctor can detect more than of refactoring operations as they are being performed and can complete over a third of refactorings before the simulated user does.
all the while witchdoctor remains robust in the face of non parseable programs and unpredictable refactoring scenarios.
we also show that witchdoctor is efficient enough to perform computation on a keystroke by keystroke basis adding an average overhead of only milliseconds per keystroke.
keywords refactoring ide change detection repository mining i. i ntroduction refactoring is a common activity yet the automated refactoring support provided by ides remains significantly under used in the wild .
this is problematic considering the tedium of refactoring the time it can consume and the considerable possibility of introducing errors.
reasons for the disuse of refactoring have been investigated in depth .
assuming that a programmer has reached a point during development in which a refactoring r is appropriate there exist several cognitive preconditions that must be met before r will be used the programmer must realize that she is performing a refactoring.
she must know that support for r exists.
she must know the name of r. she must know that r is applicable.
she must believe that invoking idesupport for r is faster than performing r by hand.
she must trust that the support for r will not transform her code in unexpected ways.
she must be willing to perform a mental and physical context switch from writing code at the keyboard to navigating a menu and gui wizard via mouse.
moreover these are merely the cognitive preconditions for onerefactoring r as it pertains to an isolated moment during development.
the problem can only become worse with the addition of new ide supported refactorings.
we present witchdoctor a system that solves the cognitive scalability problem by relieving the programmer of the need to meet the aforementioned cognitive preconditions.
witchdoctor observes the programmer s programming activity detects when a particular refactoring is in progress and completes it before the programmer does.
in this scenario the programmer is relieved even of the burden of knowing that a particular refactoring exists let alone its name menu location hotkey etc.
witchdoctor s automated recognition can benefit novices and experts alike.
novices are simultaneously struggling with the concepts e.g.
the idea of refactoring and the environment eclipse s refactoring operations .
a novice using witchdoctor can be taught in context by having witchdoctor suggest completions for the novice s stuttering progress.
experts on the other hand seek efficiency and their work can be accelerated if they don t have to interrupt their typing to use the refactoring drop down menus and its pop up dialogs.
although the teaching interface and the expert interface would be quite different the same underlying technology of witchdoctor would be required.
automatically recognizing and completing a refactoring in progress at the speed of typing poses a number of technical and human computer interaction challenges.
in this paper we present our solution to five technical challenges that arise when performing real time refactoring detection.
in order to be interactive witchdoctor must do change detection very quickly in order to be useful witchdoctor must detect and complete the refactoring before the programmer has finished it.
these requirements lead to novel technical challenges where the traditional techniques of change detection cannot be applied straightforwardly interactive speed we assume that every keystroke that goes unchecked is a missed opportunity to save theprogrammer time.
hence witchdoctor examines the programmer s document after every keystroke and mouse click.
this requires witchdoctor to be very efficient in order to avoid noticeable delays while the programmer types.
specifically it must be much faster than the speed at which programmers can type individual keys while programming.
and it must maintain this runtime guarantee even with large files and large projects.
tolerance for non parseable program states analyzing the document on every keystroke induces another challenge.
in most cases the document will not be parseable after every keystroke.
the programmer will not have terminated the line with a semicolon.
the parentheses may not match.
there may be statements dangling outside of any method bodies.
indeed because witchdoctor must analyze the document after cut and paste commands too non trivial and sudden changes to the program s structure may mangle the abstract syntax tree.
thus witchdoctor is obliged to treat unparseable programs as first class citizens.
tolerance for programmer variance the goal of witchdoctor is to enable a programmer to interface with the ide s refactoring support regardless of whether she knows it s there.
thus witchdoctor must detect refactorings regardless of how they are being performed.
different programmers may carry out the same refactoring in different ways.
take the example of extracting a method.
this refactoring is comprised of a number of sub operations remove a code block create a new method declaration place the removed code block in the method and introduce a new call to the method.
any permutation of these suboperations would constitute a method extraction.
taking this a step further a programmer may even interleave edits not related to the refactoring.
witchdoctor attempts to detect refactorings irrespective of the ordering imposed on its suboperations by the programmer as well as allow for unrelated edits in the sequence of edits that includes the refactoring.
reuse of trusted ide components our fourth challenge is that we would like to reuse the automated refactoring operations provided by the ide.
refactoring operations are highly non trivial to implement.
moreover experienced programmers are familiar with the native operations and have well justified expectations for the result of performing a given refactoring.
achieving reuse is non trivial because by the time witchdoctor detects that a refactoring is in progress the programmer may have already performed multiple sub operations of the refactoring.
the program may or may not be parseable.
and even if it is the state of the program has by definition advanced beyond the point where the ide s built in refactoring operation ought to have been invoked.
the naive solution is to roll the document back to a previous state and then trigger the ide s refactoring operation.
however this strategy would discard undo any unrelated edits that the programmer made between the sub operations of the refactoring.
a smarter roll back strategy is required.
extensibility the final challenge is to handle the wide variety of the refactorings supported by an environment like eclipse as well as new ones that may be added in the future.
witchdoctor can detect and complete several idesupported refactorings rename variable local and global rename class rename method extract local variable and extract method.
it can also detect and complete one idesupported operation which is not a refactoring surround with try catch.
further refactorings and even real time completion support can be added to witchdoctor with relative ease.
our techniques for solving these five technical challenges constitute our paper s technical contributions we employ a three stage strategy of detecting changes recognizing subsets of changes as the prefix of a refactoring and rolling back the document to invoke the refactoring tool to create a text view that suggests the refactoring to the programmer.
to achieve both interactive speed and tolerate unparseable programs witchdoctor performs change detection primarily at the text level using myers s differencing algorithm rather than the ast a substep maps detected changes to the eclipse ast.
to tolerate programmer variance witchdoctor matches refactoring specifications against the change history using the rete pattern matching algorithm .
to enable reusing eclipse s refactoring operations witchdoctor rolls back just the matched changes not all the changes since the inception of the refactoring .
to achieve extensibility witchdoctor employs a declarative specification language for describing refactoring operations akin to kim s language .
in section ii we examine related work as it informs our solutions to the five challenges above.
in section iii we give a detailed overview of witchdoctor.
in section iv we evaluate our techniques for solving the above challenges.
in particular we simulate a highly variant programmer performing more than randomized refactoring operations on three java code bases finding that witchdoctor is fast and robust even under these pessimal conditions.
ii.
r elated work a. improved refactoring tools there exists a long history of research on tools for performing refactoring while maintaining program semantics exemplified by the early work of opdyke and griswold .
refactoring support has since been incorporated into numerous modern ides eclipse netbeans and visual studios for example.
after refactoring became a staple in the toolkit of the modern ide the work of murphy hill called into questionthe efficacy of refactoring tool interfaces .
to our knowledge the earliest observations pertaining to the cognitive preconditions required by refactorings tools were first made by murphy hill although he did not use the term cognitive precondition per se .
additionally much of the empirical research about refactoring practices in the wild were performed by murphy hill leading to the conclusion that the ide s refactoring support is underused and that programmers often prefer to refactor by hand.
the same body of work suggests numerous improved interfaces for refactoring tools all of which reduce the cognitive load of the programmer in some way for example by assisting in the selection of statements to refactor by providing more effective context menu support or by annotating the relevant control flow and dataflow affected by refactorings.
the goal is to make safe automated refactoring more appealing to programmers who for whatever reason often elect to refactor by hand.
our work draws its motivation from these aforementioned improvements and seeks to further reduce the cognitive preconditions for refactorings.
witchdoctor observes the programmer and attempts to guess whether the user is refactoring by hand.
if so it completes the refactoring.
this predictive on line refactoring support is a novel way of eliminating the cognitive preconditions even after the user has embarked on the path of refactoring by hand.
b. predictive tools observing the user and guessing her intent is an oftemployed ui paradigm within ides word processors and web browsers.
it is commonly known as completion e.g.
tab completion or code completion.
word processors such as openoffice will complete a word that the user is typing drawing from a history of words the user has already typed.
many web browsers such as chrome do the same thing with urls typed in the search bar drawing from the user s browsing history or from a list of popular web sites.
ides such as eclipse are equipped to complete method names drawing from the method names in available apis.
in all of these cases the list of characters already typed by the user becomes a prompt for the environment to provide a completion or list of completions to the user.
witchdoctor is similar at the metaphorical level.
however instead of observing the sequence of characters typed by the user it observes the sequence of refactoring sub operations.
and whereas the sequence of characters in say a web url cannot be permuted without altering the url being typed the sequence of sub operations in a refactoring may be permuted without implying a change of intent on the part of the user.
furthermore whereas the completion of a word in a word processor requires observing a sequence of localized changes to the user s document the completion of a refactoring in an ide requires observing a sequence of non localized changes across the user s code base.c.
refactoring opportunity detection the notion of code smells goes hand in hand with refactoring many smells being placed in correspondence with refactorings that mitigate them .
the long method smell can be ameliorated by extract method.
the large class can be mitigated by extract class.
many tools have been proposed to detect code smells and hence to detect opportunities for refactoring .
code smell detection is more analogous to spell checking than to auto completion.
code smell detection does not attempt to recognize and extend the user s intent but rather attempts to direct and modify the user s intent.
in particular such tools draw attention to locations in code for which the user had not formed an intent.
d. mining software repositories there exists another body of research that attempts to detect refactorings after they have happened.
this is motivated by the desire to determine how a software framework has evolved in hopes for example of being able to make corresponding evolutions in clients of the framework.
mining software repositories is a process that makes use of high level differencing techniques to augment the low level textual differencing techniques of traditional diff tools accumulating a list of transformations that have affected a software repository .
because these tools have the feature of computing the difference between two consecutive checkins to a version control system their bar for efficiency is low compared to witchdoctor.
the techniques can also depend on parseable code without much loss of generality.
to summarize prior work has observed and studied the disuse of refactoring tools in ides due to a range of cognitive factors.
whereas code smell detection and framework change analysis attempt to detect refactorings before orafter they happen witchdoctor addresses the cognitive factors of disuse by taking the middle ground of attempting to detect and finish refactorings while they are happening and in real time on unparseable programs.
we believe this in between space constitutes an untapped research domain with novel benefits challenges and techniques in the field of real time tool support.
iii.
d esign and implementation a. design overview witchdoctor is comprised of three components each designed to address one or more of the challenges laid out in the introduction.
figure is a graphical overview of witchdoctor s components.
there are three components change detection specification matching and refactoring execution .
the architecture can be viewed as a pipeline that successively refines programmer edits into refactorings.
during change detection programmer edits are analyzedas changes to the program s abstract syntax tree ast .
during specification matching the these ast changes are analyzed to determine if a refactoring is in progress.
if so during refactoring execution the refactoring is completed and proposed to the programmer.
change detection employs a technique that initially bypasses the ast.
this is important to achieve interactive speed .
but it is also necessary for the purpose of tolerating non parseable program states .
changes are handled first at the textual level and only later at the syntactical level ensuring that we do not miss changes due to bad syntax.
specification matching involves pattern matching the programmer s change history against a suite of declarative refactoring specifications.
we use an efficient pattern matching algorithm to avoid re matching each pattern specification every time a new change is added to the history.
the goal ofspecification matching is to determine when enough information exists to perform a refactoring on behalf of the programmer.
the refactoring specifications are written in a declarative rule based syntax that decomposes a refactoring operation into its required sub operations.
this helps meet the challenge of having an extensible suite of supported refactorings making it simpler to define new refactoring specifications.
but it also provides a solution to the programmer variance problem the specification matching process can match a single specification regardless of the order of sub operations in the programmer s change history and regardless of interleaved changes that do not apply to the refactoring.
refactoring execution1happens when the specification matching process has gathered enough information to complete the refactoring.
here witchdoctor reuses trusted ide components for the appropriate refactoring.
in order to do so however the document must be transformed into a state in which the ide would expect to find it prior to a refactoring.
the rollback must also avoid obliterating changes that the programmer interleaved between the suboperations of a refactoring.
refactoring execution is the slowest step because witchdoctor relinquishes control flow to the ide s refactoring engine which although fast is not designed for interactive speed .
thus it is all the more important that change detection specification matching and the rollback operation of refactoring execution be as efficient as possible offsetting the cost of the refactoring engine s invocation.
we now dive into a detailed exposition of these components with the help of a motivating example.
suppose a programmer wishes to extract a code block from one method into a different method that does not yet exist 1our implementation executes the refactoring in the background.
a viable alternative would be to prompt the user to trigger the refactoring execution.
in this case refactoring proposal might precede refactoring execution .
figure .
graphical representation of witchdoctor s workflow figure .
a typical delete operation in progress.
the user highlights a code block.
deleting the code block triggers the change detection phase replacing the code block with a call to the new method.
this refactoring is known as extract method .
let s say that the programmer s first sub operation is to highlight the code block and delete it or cut it to the clipboard the result is the same either way .
this operation is visualized in figure .
b. detailed descripion change detection with the deletion of the statement sequence as shown in figure the tool begins the change detection phase.
a tempting strategy for detecting changes to the programmer s program and one we used in an early version of witchdoctor is to parse the document before the change parse the document after the change and to use a tool that can compute the difference between the two parsed programs i.e.
umldiff or changedistiller .
however this fails to tolerate non parseable programs and complicates achieving interactive speed due to the parsing overhead.
the earlier version of the document call it a or the later version call it b or both versions could contain syntax errors.
a syntax error within a method body can cause the entire method body to be missing from the abstract syntax tree.
our technique is to difference the document at the textual level and then map the delta to an ast subtree or forest.
for text differencing we use myers s algorithm the same algorithm used in the well known unix diff tool because its runtime in practice is very quick when the differences between a and b are small.
because witchdoctor examines every keystroke and mouse click a and b often differby a single character making the average runtime of the algorithm proportional to the file size.
in section iv we show that this scales to the largest files seen in practice.
when running myers s algorithm newline characters are treated as a delimiter allowing witchdoctor to determine line by line differences between a and b. witchdoctor considers contiguous changes to be a single delta e.g.
the deletion of several consecutive lines is considered to be a single deletion operation one that may involve more than one ast node.
after running myers s algorithm witchdoctor then attempts to produce the original and revised asts ast a and ast b and map the textual differences to relevant ast nodes.
to do so witchdoctor attempts to find the set of ast nodes that the textual change covers fnjoffset n offset change length n length change n2astfor change g where offset n is the textual offset of entity nfrom the beginning of the document and length n is the textual length.
the function astfor change is shorthand for the table below.
for a given textual difference we have various editing possibilities it could be an insertion a deletion or an update effectively an atomic delete insert at the same textual offset .
the type of the change determines which ast is used by witchdoctor when mapping the change.
the following table summarizes which ast is used in each case ast a ast b insert yes delete yes update yes yes the special case is update for which both the before from file a and after from file b asts are mapped.
returning to our example we observe that the removal of several lines from a method will register as a delete operation after running myers s algorithm.
according to the table we select file a to look for the ast nodes that map to the textual change.
from file a s ast we find the set of statement nodes that are covered by the textual changes using equation .
our approach is tolerant of unparseable programs through a multi step strategy.
first in the case of insertions any syntax errors in file a are irrelevant.
likewise in the case of deletions any syntax errors in file b are irrelevant.
thus 2witchdoctor does some optimization here in service of interactive speed .
because the change detection phase occurs after any change to the document witchdoctor keeps the computed ast b in memory using it as ast a in the next change detection phase.the document may move from a parseable state to a nonparseable state or vice versa and witchdoctor can often still find the ast nodes it is looking for.
even when a file is not parseable all hope is not lost.
eclipse s built in ast parser is quite forgiving and will parse as deeply along each ast branch as possible.
a syntax error in a method mmay cause m s branch to be nonparseable.
but if the relevant textual change pertains to a different method then witchdoctor can still find a mapping using the textual change s character offset according to equation .
the remaining difficult case is when the textual change cannot be mapped to an ast node due to syntax errors in the relevant file and in the same branch affected by the textual change.
the first strategy is to attempt to construct an ast out of the textual change itself.
often programmers cut andpaste blocks of code that can be parsed as a sequence of statements.
even when the ast of the document is mangled beyond repair sometimes the textual delta itself can be used to construct a smaller ast.
in the case of the deleted statements in our example even if the rest of the document was not parseable the removed statements themselves would be parseable.
the second strategy is to find a relevant ancestor ast node an ast node whose associated character offset and length indicate that the textual change is covered by the ast node.
of the covering nodes fnjoffset n offset change length n length change n2astfor change g we select the one whose length is the smallest.
the upshot is that even if witchdoctor cannot figure out an exact mapping to an ast node it can often find a parent ast node that was affected by the change.
this can be useful for example if the programmer pastes a block of statements into the space between methods of a class a sub operation that can signal that the programmer is performing extract method and plans to immediately wrap the statements inside a method body.
the covering node in this case is the class.
although the pasted statements will cause the document to become largely non parseable the affected class can still be obtained allowing witchdoctor to determine the target class for the extract method operation.
the goal of change detection is after all to detect as many relevant changes as possible giving the specification matching phase enough information to detect refactorings in progress.
performing the textual differencing algorithm first followed by a mapping to ast nodes allows information to be gathered even when the program is highly non parseable.continuing with our example the deletion of statements from a method has during change detection been detected by myers s algorithm and mapped to an appropriate ast node and by indirection its subtree .
we structure the result as a tuple delta type ast nodes where astnodes is the set of ast nodes to which the textual delta was mapped during change detection and delta type2 f insert delete update g fcovers coveredby g the tuple is then passed to the specification matching component.
because all but the most exceptional of our ast mapping techniques outlined above produces an ast node that the textual change covers most tuples encountered in witchdoctor s pipeline will have a delta type2 finsert delete update g f coversg.
to simplify the following exposition then we will assume that the textual change covers the ast node unless stated otherwise writing it asdelta type2finsert delete update g. specification matching in this phase the sequence tuples created by the change detection phase one for every edit are pattern matched to detect evidence of refactorings.
a naive slow approach would be to keep the tuples in an edit history and to search for patterns within the entire history each time a new tuple is added.
instead witchdoctor employs the rete algorithm an algorithm for efficient pattern matching in production rule systems.
we keep a list of refactoring specifications patterns that represent refactorings that may be in progress.
each new tuple is checked against the list of specifications.
the specifications can be thought of as state machines if the new tuple is evidence of a refactoring that the specification is designed to recognize the specification s internal state advances.
as a result each new tuple can be evaluated just once obviating the need to sift through an ever growing history of changes looking for matches.
the specifications are designed using a declarative rulebased model derived from kim s body of research on detecting refactorings in software repositories .
each refactoring is described by one or more specifications .
for example here is a simplified specification to detect a subset of the ways in which extract method may be performed delete code block insert method call insert new method each constituent of the conjunction describes a change tuple giving the change type and a descriptor for the ast node set.
the descriptor can be arbitrarily complex and isimplemented as an ast node visitor which can traverse asts both upward and downward scouring the tree for various properties.
however in practice we have found it sufficient to implement these ast node set descriptors as simple checks against the types of the ast nodes.
for example the code block descriptor checks for a sequence of statements and the method call descriptor checks for a method call ast node.
this is too simple however.
one can imagine scenarios in which a programmer deletes a code block and adds a method but is not performing a refactoring.
the heavylifting in witchdoctor is done by the constraints attached to each specification.
for example we could flesh out the above specification with constraints as follows delete code block insert method call insert new method where position code block position method call name method call name new method of course this is an over simplification because the position function must take into account the deleted position of code block versus the added position of method call.
furthermore the asts for code block and method call may look very different so a simple calculation of the offset is not usually an adequate way to determine the position.
instead properties of the asts must be used to determine whether the positions are equal.
although this high level presentation obscures some of the implementation details it illustrates the distinction between the components of a specification requirements and constraints .
the requirements can be thought of as patterns that must be matched.
the constraints relate the requirements to each other preventing some requirements from matching.
each requirement that is matched can be thought of as the advancement of the specification s state machine.
continuing with our example the deleted code block will be matched by the requirement delete code block .
the first constraint is not applied because position method call is undefined another subtlety but easily implemented the second constraint is ignored because it does not pertain to the code block.
when the matching occurs the delete code block requirement establishes a binding with the tuple generated during change detection .
a specification begins with no bindings and gradually acquires bindings until they carry enough information to execute the refactoring i.e.
supplyall the required parameters to the eclipse refactoring .
thus in our example the specification shown above has now established one binding.
whenever a specification is updated the original is always retained unchanged.
in our example the specification for extract method now has a binding for code block .
however the original extract method specification remains in the list of specifications.
the point is that if the programmer deletes another code bock the specification whose code block is bound will ignore the change but the specification whose code block is unbound will acquire a binding.
this allows witchdoctor to detect the advent of a newly begun refactoring regardless of which refactorings it believes to be in progress.
indeed many refactorings are permitted to be in progress at once.
for example a programmer may begin extracting one method proceed to extract a completely different method and return to complete the original refactoring.
this is one form of programmer variance that witchdoctor permits.
the challenge of supporting a broad and extensible suite of refactorings is partially accomplished through the use of these specifications which cleanly model the requirements for a refactoring.
requirements and constraints once implemented as java classes may be reused between specifications.
the challenge of tolerating programmer variance is accomplished in several ways using these specifications.
for one the requirements for a specifications may be matched in any order permitting the programmer to permute the suboperations defined by the requirements.
furthermore the programmer may interleave edits between the sub operations of a specification.
they will not affect the state of any specifications unless they are relevant to a refactoring.
however for the sake of efficiency the list of in progresss specifications cannot be allowed to grow indefinitely.
for the sake of efficiency witchdoctor removes specifications whose states have not progressed recently.
consequently if the programmer interleaves enough edits between relevant sub operations the refactoring may be missed due to the excessive noise.
continuing our example suppose the programmer now places a method call into the method where the code block was deleted.
figure visualizes this insertion.
the change detection process will run creating the relevant change tuple.
the inserted method call matches the second requirement in our specification insert method call and the constraint is satisfied.
so the binding takes place advancing the state of the specification.
with two requirements bound the specification has enough information to trigger witchdoctor s next phase.
witchdoctor now knows the 3in some cases a binding can be supplied automatically by witchdoctor rather than supplied through programmer edits such as providing a default legal name for a method.
this name can be changed later by the programmer.
figure .
an insert operation triggering the change detection and specification matching phases for the second time also providing enough information to trigger the refactoring execution phase.
contents of the code block being extracted and the name of the method into which the block will be extracted.
this is enough information to execute the refactoring.
refactoring execution the goal of this phase is to complete the refactoring that has been detected.
once completed the refactoring can be proposed to the programmer.
the challenge is that on the one hand we would like toreuse well tested components in the ide yet on the other hand the refactoring has already been initiated by the programmer.
thus the document will not be in the state that the well tested components expect it to be in.
some of the programmer s changes need to be reverted in order to return the document to a state in which the refactoring has not yet begun.
unfortunately a general approach cannot work such as restoring the document to its state before the first suboperation of the refactoring.
the edits interleaved between sub operations would be lost.
instead the edits matching the specification must be rolled back while preserving the interleaved edits.
in the case of our example the rollback strategy is to inline the code block replacing the method call.
in essence we run the refactoring backward independent of the interleaved edits.
then we call refactoring engine in the background to perform extract method feeding it the code block and the name in the method call.
during this phase witchdoctor must relinquish control flow to the ide s refactoring engine.
the refactoring engine s operations are tuned for correctness not speed.
so this is the one phase of witchdoctor in which the programmer might detect a noticeable delay in typing although the refactoring is happening in the background minimizing distractions to the programmer.
in our evaluation we assess how long this delay is in practice.
continuing with our example the document has been rolled back and the refactoring has been performed in the background yielding a version of the programmer s document in which the refactoring has been fully performed.
there are a variety of ways to present the results of thefigure .
the tool s proposal displaying proposed changes in gray.
refactoring which is not a consideration for this paper.
an informal poll of our colleagues has turned up a myriad of strategies for proposing the completed refactoring to the programmer.
these various user interface options and their relative merits are beyond the scope of this paper and will be compared and tested in future work.
regardless of the presentation efficiency is still a prime consideration.
for now we describe the interface that we currently use for testing witchdoctor.
in our running example the execution of the refactoring engine yields a document in which the inserted method call which was inlined during the roll back has now been reinserted by the refactoring engine and the code block the programmer deleted is now wrapped in a method declaration.
our interface proposes this change by displaying the new method declaration in gray to indicate that it is a suggestion.
the rest of the code everything typed by the programmer so far is rendered in normal colors see figure .
at this point the behavior mimics tab completion.
if the programmer presses enter or tab the changes are finalized.
if the user continues typing in such a way that doesn t contradict the suggested change the suggestion remains in effect.
otherwise the suggested changes are removed.
iv.
e valuation a. experimental methodology key experimental questions revolve around the speed of our approach its ability to handle unparseable programs and its ability to handle variance in the way programmers can perform refactorings by hand.
to gain insight on these performing a large number of complex refactorings in a great variety of ways on a variety of software projects is appropriate.
refactoring type we chose to focus on extract method because it is amongst the most complex available in eclipse and the most complex that we implemented.
it comprises multiple steps and has elements that are related to other simpler refactorings such as rename and extractbinding.
also there are numerous ways to perform extract method many of which create non parseable states.
simulated user ideally we would assess witchdoctor s design and implementation against thousands of byhand refactorings based on the techniques styles of real programmers with a validated distribution of the application of those techniques.
to our knowledge these don t exist.
instead we chose to simulate the broad spectrum of possible extract method refactorings in a randomized unbiased distribution.
although not externally valid a random distribution still allows examining selected subpopulations of the refactoring pool and discussing their likely relation to practice.
to this end we built a simulated user that can make scripted changes to a document.
we programmed the user to randomly select construct a script for and perform correct extract method refactorings.
each editing operation in each script is executed by the simulated user by mimicking human behaviors such as keystrokes mouse clicks selections cut operations and paste operations.
the simulated user ran at a rate of milliseconds per keystroke much faster than the average human typist.
as part of the simulated user s random behavior it often forgets to close curly braces or to add semi colons.
it also inserts lines character by character causing the line to be non parseable until the final semi colon.
when deleting a sequence of lines it deletes them in a random order which often results in non parseability e.g.
when curly braces or control constructs are deleted.
additionally to incorporate the notion of user variance into our simulated programmer it randomized the order of the sub operations used to perform each extract method refactoring.
sometimes the new method declaration would be added first followed by the deletion of the code block and addition of the method call.
at other times the order was permuted.
the order was randomly chosen for each script yielding a uniform distribution across the various permutations.
pseudo code for simulating a single refactoring might look like let ops the refactoring sub operations scramble order of ops for each op in ops switch rand case do keystrokes op case do cut and paste op case do keystrokes but no curly op case ... endfiles refactorings performed eclipse compare plugin eclipse jface plugin apache struts figure .
projects tested with the total number of files in the project and the number of random refactorings run by our simulated programmer.
projects we chose three open source java projects eclipse compare plugin eclipse jface plugin and apache struts.
these projects are somewhat dissimilar they perform rather different tasks and were implemented by different teams.
figure gives a profile of the three projects.
although these projects are not especially large project size did not turn out to influence performance.
execution environment finally our experiments were run on a macbook pro with 4g ram and .
ghz intel core duo processor.
such a machine while contemporary is modest in its clock rate and number of cores.
the operating system is macos .
.
.
all refactorings ran in eclipse .
.
helios .
b. results tolerance of non parseable program states and user variance witchdoctor was able to detect the refactoring performed by the simulated user to of the time.
witchdoctor was also able to complete the simulated user s intended refactoring before the user could complete it to of the time see figure .
extreme user variability was the primary cause of whichdoctor s failure to complete a refactoring in particular order of the suboperations.
one such order involves first adding the new method declaration complete with the body before adding the method call or deleting the code block.
in these cases witchdoctor detects the new method declaration but does not complete a refactoring because it cannot determine the code bock to extract.
if the programmer then adds a call to the new method witchdoctor still does not know the code block to extract.
by the time the code block has been removed all of the work of the refactoring has already been performed leaving no time to complete the refactoring on behalf of the user.
a similar failure can occur when the method call is added first followed by the method declaration with body and the removal of the code block.
half of witchdoctor s failures to complete the refactoring can be attributed to these late detections after which there is no work to perform.
yet it seems unlikely for programmers in the wild to construct a method declaration complete with its final body as the first step of extract method.
this technique requires significantly more work than utilizing cut and paste e.g.
cut the code block paste it into a new method add a method call.
omitting just these figure .
witchdoctor s percent of refactorings detected and percent of refactorings completed on each of the three experiments.
figure .
witchdoctor s average overhead in keystrokes scaling linearly with the size of the file.
the chart summarizes the experment run on the eclipse compare plugin.
twp obviously anomalous cases would raise the completion rate to about .
interactive speed the typical typist is said to type at characters per minute perminute .
this equates to milliseconds between each keystroke.
in figure each data point represents the average computation per keystroke within a particular refactoring performed by the simulated user during the experiment run on the eclipse compare plugin.
witchdoctor performed even better on the jface and struts experiments.
the chart show that the computation performed by witchdoctor after each keystroke is on average an order of magnitude less than .
the time to process a keystroke was never more than .
milliseconds this includes rollbacks .
we do note however that processing time increases linearly with respect to file with a slope of .
reuse of trusted ide components in all cases the completion of the refactoring was performed by invoking eclipse s refactoring tools which requires the selective rollback process described previously.
surrendering control flow to the well tested eclipse refactoring engine constitutes the most significant impact to witchdoctor s performance.the following table summarizes the averages across the three experiments.
witchdoctor eclipse refactoring compare ms ms jface ms ms struts ms ms the witchdoctor column is the average time witchdoctor spends computing per keystroke across the three experiments a short summary of the data presented in .
the eclipse refactoring column is the average time taken for eclipse to complete refactorings detected by witchdoctor.
in all cases the refactoring takes significantly more time than the amount of time spent within witchdoctor.
although this delay is significant we feel that using the trusted components of the ide are justified for three reasons not just for robustness and familiarity but also because the noticeable delay cause by the refactoring engine is not the normal case for witchdoctor which still performs its normal computations in less than milliseconds on average and the delay caused by the refactoring engine is a prelude to a completed refactoring which saves the user significantly more time in the long run.
we would like to add that eclipse s refactoring implementation cannot be blamed for being slow.
it is only in the context of real time support tools like witchdoctor that the notion of interactive speed becomes an issue for the ide s refactoring engine.
if real time interactive refactoring becomes common optimizations for refactoring engines will follow.
extensibility we have specified implemented refactorings in witchdoctor rename variable local and gobal rename type rename method extract local variable extract method and surround with try catch a nonrefactoring operation supported by eclipse .
in all cases the specification technique we used to define refactorings allowed us to incorporate these new refactorings with relative ease giving us confidence that the suite of refactoring operations in eclipse can be supported by witchdoctor as well as new refactoring operations that may be added to eclipse in the future.
for example it was fairly trivial to implement the specification for rename variable after having implemented extract method.
in the following sample implementation the classes delete insert notequal and sameplace are all reused from extract method specification rename new specification rename method rename.addrequirement new delete old name rename.addrequirement new insert old name rename.addconstraint new noteq old name new name rename.addconstraint new placeeq old name new name v. f uture work having models of how programmers refactor by hand can inform the development of tools like witchdoctor and may have other applications to informing software engineering practice.
we plan to deploy witchdoctor in an observation mode that will record all the ways that users refactor by hand.
this approach will permit gathering a very large and detailed in the wild dataset.
a key question in this line of research is the efficacy of real time refactoring suggestions.
given that the performance and robustness of witchdoctor is high the main outstanding design question is interface design.
an informal poll of our colleagues suggests a potential need for a wide variety of different interfaces for proposing refactoring completions to human programmers from actually transforming the document under the nose of the programmer to various kinds of pop up context menus to code annotations to a full fledged video tutorial for novices on the best practices and merits of the refactoring being performed.
we plan to prototype interfaces for novices and experts ultimately performing lab and field studies of the use of witchdoctor and the practices that arise around it.
vi.
c onclusion refactoring tools are underutilized due to the numerous cognitive preconditions that must be satisfied before a refactoring operation is invoked.
witchdoctor represents a first step toward eliminating these preconditions.
a programmer can simply write code as she normally would and witchdoctor makes refactoring suggestions.
we have shown that the techniques applied in witchdoctor achieve very complete extremely fast recognition of refactorings.
making assumptions about how real programmers refactor the suggestion rate is high as well.
key future work is to investigate how programmers refactor by hand in the wild and to design and investigate user interface designs for realtime refactoring suggestions.
several techniques were required to achieve fast robust and extensible refactoring suggestions.
textual differencing can be combined with delayed ast node mapping to handle non parseable program states.
a declarative specification language and associated pattern matching algorithm can be used to recognize a broad and extensible array of refactorings as they unfold regardless of user variance.
selective rollback permits invoking the ide s refactoring engine while tolerating interleaved edits.