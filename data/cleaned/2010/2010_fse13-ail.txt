server interface descriptions for automated testing of javascript web applications casper s. jensen aarhus university denmark semadk cs.au.dkanders m ller aarhus university denmark amoeller cs.au.dkzhendong su university of california davis usa su cs.ucdavis.edu abstract automated testing of javascript web applications is compli cated by the communication with servers.
specifically it is difficul t to test the javascript code in isolation from the server code and dat abase contents.
we present a practical solution to this problem.
f irst we demonstrate that formal server interface descriptions are useful in automated testing of javascript web applications for separ ating the concerns of the client and the server.
second to support the construction of server interface descriptions for existing ap plications we introduce an effective inference technique that learns c ommunication patterns from sample data.
by incorporating interface descriptions into the testing t ool artemis our experimental results show that we increase the level of automation for high coverage testing on a collection of jav ascript web applications that exchange json data between the client s and servers.
moreover we demonstrate that the inference techn ique can quickly and accurately learn useful server interface descr iptions.
categories and subject descriptors d. .
testing and debugging general terms algorithms languages keywords web applications automated testing interface descripti ons .
introduction many modern web applications run in browsers as htmlembedded javascript programs that communicate with a serve r. the javascript code reacts to user events and asynchronously se nds http requests to the server for updating or retrieving data.
the response from the server is used for example to dynamically m odify the html page.
with this so called ajax style of structur ing web applications the server mostly acts as a central databa se seen from the client s point of view.
the server interface compri ses a collection of operations identified by urls that accept in put and produce output typically in xml or json data formats.
some web service providers have public apis such as google twitter and facebook that are well documented and used by m any permission to make digital or hard copies of all or part of thi s work for personal or classroom use is granted without fee provided th at copies are not made or distributed for profit or commercial advantage and th at copies bear this notice and the full citation on the first page.
copyright s for components of this work owned by others than the authors must be honored.
abstracting with credit is permitted.
to copy otherwise or republish t o post on servers or to redistribute to lists requires prior specific permiss ion and or a fee.
esec fse august saint petersburg russia copyright is held by the authors.
publication rights licens ed to acm.
acm ... .
.1functiongoto page id q 2jquery.ajax get page url ?page id query q datatype json success function result 6populate table result 10functionpopulate table attendees 11vartable attendees 12table.html 13for i i attendees.length i 14vara attendees 15varstyle 16if a.checkedin 17style style background color b6edb8 19ahtml tr id row a.id style td b a.name b 21a.email br 22a.department td td a href onclick info a.id a a href onclick checkin a.id a a href onclick del a.id a tr 30table.append ahtml figure a typical example of ajax in javascript.
client applications for example in mashups that each use sm all parts of different apis.
in contrast in many other web appli cations the server side and the client side are developed in conjunction within the same organization.
in such web applications the programming interface of the server is often not described i n a formal way if documented at all.
this can make it difficult to modify or extend the code even for small web applications.
m ore concretely we have observed that it limits the possibility of applying automated testing on the javascript code in isolation fr om the server code and database contents.
it is well known that precisely specified interfaces can act a s contracts between the server code and the client code thus supp orting a clean separation of concerns and providing useful documen tation for the developers.
in this work we show that having formal d escriptions of the programming interfaces of the server code in ajax web applications is instrumental when conducting automate d testing of the javascript code in such applications.
in addition we present a technique for automatically learning server inte rface descriptions from sample data for pre existing web applicati ons.
as an example consider the javascript code in figure whic h is part of a web application that manages attendance lists fo r meetings.
when the function goto page is called an ajax request is id name fred email fred cs.au.dk department cs checkedin true id name joe email joe imf.au.dk department imf checkedin false figure example json response for the ajax interaction from figure .
sent to the server via the jquery library.1this request takes the form of an http get request with a specific url and the parameterspage andquery .
thedatatype value json on line indicates that the response data is expected to be formatted usin g json a widely used format because it integrates well with javascr ipt.
when the response data arrives the function populate table is called via line .
by inspecting that function lines we see that the json data is expected to consist of an array of objects with specific properties id name email department and checkedin .
moreover their values cannot be arbitrary.
for example thecheckedin property is used in a branch condition so it probably holds a boolean value and the other properties app ear to hold strings that should not contain special html character s such as or since that could lead to malformed html when inserted into the page on line .
figure shows an example of an actual json response that may appear.
in this example as in many javascript web applications in general the interface between the server and the client is n ot made explicit.
as a consequence the server code and the client co de become tightly coupled so it becomes difficult to change eithe r part without carefully checking the consequences to the other pa rt.
for instance the server code could safely omit the checkedin property when the value is false without breaking the client code sincea.checkedin on line would then evaluate to undefined which is coerced to false however the necessity for such subtle reasoning makes the application fragile to modifications.
a lso the client code implicitly assumes that escaping of special htm l characters has been performed on the server but this may not have been communicated to the server programmer.
one aim of our work is to advocate the use of formal interface d escriptions as contracts between the client code and the serv er code.
in the example above an interface description could specif y what are valid request parameters and the details of the response data format such that the server code and the client code to a larger e xtent can be developed separately.
interface descriptions are th e key to solve a substantial practical problem that we have observed in our work related to the tool artemis that performs automated tes ting of javascript web applications it can be difficult to set up servers and populate databases to be able to test the client side jav ascript code.
moreover an automated tester that focuses on testin g the javascript code and has a black box view on the server is oft en not able to produce high coverage tests within a given time bu dget.
with interface descriptions we can automatically constru ct mock servers that can be integrated into such an automated tester in place of the real servers.
to illustrate this idea consider again the example from fig ure .
if we wish to apply automated testing to the javascript code two approaches could be considered at first we could ignore t he server and simply assume that any response is possible to any ajax request.
automated testing could then reveal that the javas cript code will throw a runtime exception if the response data is no t an array or if the array contains a null value on line and line respectively and malformed html would be generated if the ob ject properties contain special html characters.
however this does not imply that there are errors in the javascript code impli citly it be the server s responsibility to ensure that the ajax re sponse does not contain such values.
alternatively we could us e a live server with realistic database content.
this would elimina te the problem with false positives in the first approach.
however two drawbacks arise first it requires deep insight into the app lication to be able to provide realistic database content second the testing capabilities become fixed to that particular database co ntent which may limit the coverage of the client code.
interface de scriptions give us another alternative with a description of what requests the server accepts and the responses it may produce an automated testing tool such as artemis becomes able to focus on testing the javascript code on meaningful inputs.
to alleviate the burden of writing interface descriptions f or preexisting applications we additionally propose an automat ed learning technique.
our hypothesis is that practically useful in terface descriptions can be created using only sample request and re sponse data.
the sample data can be obtained by users exercising the functionality of the application without requiring detailed kn owledge of the server code.
this makes the learning technique indepe ndent of the specific programming languages and frameworks php j sf asp.net ruby etc.
that may be used on the server and thereb y be more generally applicable.
the idea of using interface description languages idls to specify the interfaces of software components has proven succes sful in many other contexts.
prominent examples in related domains include web idl for the interface between browsers and javascr ipt application code wsdl for web service communication and omg idl for interprocess communication with corba .
nevertheless idls are still not widely used in the context o f clientserver interactions in ajax web applications despite the e xistence of languages such as wadl .
we suspect that one reason is that writing the interface descriptions is a laborious task .
to this end our work is the first to propose an automatic technique to learn interface descriptions for ajax web applications.
in summary our contributions are as follows we first introduce a simple ajax server interface descriptio n language named ail inspired by wadl section .
this language can describe http operations involving json and xml data as commonly seen in ajax web applications.
we demonstrate how the interface descriptions can be incorp orated into automated testing of javascript web application s to be able to test client code without involving live servers.
spe cifically we extend the automated testing tool artemis with sup port for ail section by introducing a generic mock server component that is configured using ail descriptions.
we provide an algorithm for learning ail descriptions of aja x web applications through dynamic analysis of network traffi c between clients and servers section .
we experimentally evaluate our approach by investigating h ow ail descriptions affect the code coverage obtained by artem is with our extensions and by comparing the inferred ail descri ptions with manually crafted ones section .
our results sh ow that by using the descriptions artemis can obtain as goo d coverage with the mock server as with real servers and manual ly populated databases and the learning algorithm is capab le of producing useful ail descriptions.
testing ajax applications is recognized as a difficult probl em and interface descriptions have proven useful for testi ng classical web applications but no previous work has combined interface descriptions and testing of ajax applicati ons.
related work on interface description languages learning al gorithms and automated testing is discussed in section .url get news read items.json get author name author.json get users login user pwd token.json post news send token token.json items item.json void post users create token token.json user pwd vo id figure an example ail description.
in this paper we use the term ajax in a broad sense cover ing different technologies for client server communicati on in javascript based web applications.
in current web applica tions this typically involves the xmlhttprequest3api but our general approach in principle also encompasses the more recent websoc ket4 api.
the data being transmitted may involve different forma ts including xml and json that are supported by ail although our current learning algorithm and experiments focus on json.
.
an interface description language for ajax our first step is to design a formal language ail ajax server interface description language for describing the inter faces of servers in ajax style web applications.
the communication in such web applications consists of http client server interacti ons where the javascript code running on an html page in a browser sends requests and receives responses.
an http request contains a method typically get or post a url path and a number of name value parameter pairs.
for simplicity we abstract aw ay the other information in the http requests such as the protocol and headers.
we design ail as a simple language that concisely ca ptures the essence of wadl and integrates with json.
an ail description consists of a base url and a collection of operation descriptors each of the form request response where request is a pattern that describes a set of possible http requests and response describes the possible responses that may be generated by the server for those requests.
within an ail d escription the request patterns must be disjoint in the sens e that every possible http request can match at most one of the pattern s which ensures a deterministic behavior.
an ail description establishes a contract between the clien ts and the server the clients are responsible for ensuring tha t each request matches one of the request patterns and it is the ser ver s responsibility that the response matches the corresponding r esponse schema.
below we describe the syntax and matching semantics of request patterns and response schemas.
figure shows an ail description without json schema files for a simple json news server that makes five operations avail able for javascript applications.
the first three operations pro vide access to news items author information and authentication .
the last two operations can be used for submitting news items to t he server and for registering new users.
all operations use htt p and json.
the description refers to external json schema files th at specify the data formats involved in the operations.
such an ail description evidently characterizes the structure of the o perations that are supported by the server while abstracting away from the actual data being transmitted at runtime.
the initial version of ail supports two kinds of data formats json and xml.
ail simply relies on json schema5and relax ng6for describing the structure of data.
comment delete comment id delete.json post project id issues issue id set title value value set title.json post project id scrum add task for story story id mode issue task name add task.json figure parts of the ail description of the bug genie .
a request pattern consists of an http method get post etc.
apath and a comma separated list of parameters method path parameters a path consists of path fragments separated by each being a string or a parameter.
each parameter has the form name cardinality datatype where cardinality is either absent meaning precisely one occurrence ?
optional or zero or more .
adatatype is written as a constant string e.g.
start the wildcard the keywordvoid a reference to an external json schema file e.g.
token.json a reference to a relax ng schema file e.g.
person.rng or a type defined in such a file e.g.
types.rng person or a list of datatypes separated by .
the datatypes of parameters that occur in paths are restrict ed to simple string types such as numerals or string enumeration s and the special datatype void is never used in request patterns.
a datatype matches strings in the obvious way a constant str ing matches that string and no others matches any value void is used for describing the empty response a reference to a sche ma type matches according to the semantics of json schema and re lax ng respectively and represents union.
an http request matches a request pattern if each constituent matches.
a res ponse pattern is simply a datatype with matching defined according ly.
we omit the precise semantics of pattern matching due to the lim ited space but the intuition should be clear from this brief desc ription.
the example shown in figure is a part of an ail description of the application the bug genie .7this application uses rest style naming where some parameters appear in the path not in the ht tp request body or the query string.
the responses use json in bo th application we omit the details of the associated json sche mas.
the ail language as presented above is capable of expressing the basic properties of server interfaces.
one straightfor ward extension is to support other data formats such as html plai n text or jsonp json with padding credentials for http basic authentication and request content types i.e.
mime ty pes .
in some situations it can also be useful both for documentation and testing purposes to describe error responses that is non ok http response codes and http content negotiation.
for now ail cannot describe temporal properties for example that o perationamust be invoked before operation b simply because such properties have not been significant in any of the web applica tions we have studied.
another possible extension is support for w ebsockets which unlike http involves connection oriented c ommunication and thereby does not fit directly into the simple req uestresponse model.
.
using server interface descriptions in automated testing server interface descriptions are not only useful for docum enting the server interface for the client programmer they also ma ke it possible to test the client code in isolation from the server code which provides new opportunities for practical automated t esting.
in section .
we give a brief overview of the artemis tool fro m earlier work by artzi et al.
with a focus on the complicat ions caused by ajax communication.
in section .
we show how a new server component can exploit ail descriptions to impro ve the level of automation.
.
automated testing with artemis a javascript web application is driven by events such as the initial page load event mouse clicks keyboard presses and ti meouts.
event handlers are executed single threaded and non preemp tively.
a test input to an application is thus given by a sequence of pa rameterized events.
of particular relevance here are the event s that are triggered by ajax response where the event parameter contai ns the http response data from the server.
figure shows a use of the xmlhttprequest api8 which provides low level ajax functionality in contrast to the exam ple in figure that uses the jquery library .
the call to x.send on line initiates the request to the server in this case an http get r equest to the relative url news read which matches the ail description in figure .
an event handler for receiving the response is set up on line .
when the response content has finished loading x.readystate will have the value and the event handler function is called.
if the response status code is the res ponse content is then available as a text string in x.responsetext .
for this example the challenge for an automated tester is how to produce meaningful server response data that will thoroughly e xercise the response event handler including the showitems function being called on line .
the artemis tool uses feedback directed random testing of javascript web applications to produce high coverage test inputs.
that is it executes the application on a test input and monit ors the execution to collect interesting information that can be us ed to generate new test inputs to improve coverage.
the heuristics us ed for collecting information producing new test inputs and pri oritizing the work list of test inputs are described by artzi et al.
and we here focus on the interactions with the server.
although our goal is to test the javascript code not the serv er we face the problem that the javascript code in ajax style ap plications closely depends on the server.
as discussed in secti on it is often difficult to populate the server database with use ful data that is required to ensure high coverage of the javascript co de.
a simple example is line in figure where both branches can only be covered if the server database contains a nonempty li st of attendees whereof at least one is marked as checkedin and another is not no matter how other events such as mouse clicks are being triggered in the browser.
on top of this even a well pop ulated database may not suffice.
reaching one part of the javas cript code may require certain values in the database where anothe r part may require different values so multiple database snapshots may be necessary to enable high coverage of the javascript code which makes the burden even higher.
yet another problem for automated testing appears when impo rtant server responses can only be triggered by request value s that are practically impossible to guess by the testing tool.
con sider for example the operation users login for the server described in figure .
a successful response requires the client to pro vide a valid user name and password which is hopefully impossib le to guess so a considerable part of the client code will remain u nexplored.
a common workaround is to ask the user for help in such situations .
the consequence of these problems is that a utomated testing may require a considerable manual effort.
we observe that when testing client code many execution pat hs require data from the server that is structurally well form ed but not necessarily semantically valid.
as an example for test ing the populate table response handler function in figure we do not 34varx newxmlhttprequest 35x.open get news read 36x.onreadystatechange function 37if x.readystate 38if x.status 39showitems x.responsetext else 41alert an error occurred 45x.send null figure a simple use of xmlhttprequest to perform an ajax call to get news items from the server from figure .
need server response data that contains actual attendee nam es and email addresses but we do need json data with a certain struc ture.
this observation allows us to use ail descriptions instead o f actual servers and live data for testing client code.
.
extending artemis with an ail mock server to alleviate the problems described above we have extended the artemis tool with a mock server component that is configured b y an ail description.
whenever the javascript program under tes t initiates ajax communication the mock server intercepts the r equest such that the actual server is never contacted during the tes ting.
given an http request the mock server performs the following steps it searches through the ail description to find an operation descriptor with a request pattern that matches th e http request.
if one is found a random response that matches the c orresponding response datatype is prepared otherwise the res ponse to the client is a generic not found .
the response data is then sent to the test input generator component in artemis w hich will subsequently produce new test inputs that include an aj ax response event containing the response data.
as result we obtain a nondeterministic model of how the serv er may behave according to the ail description and the javascr ipt code can be explored without the need of a real server and data base.
now several observations can be made.
first using the mock server solves the problem of populating databases since it a utomatically returns a wide range of possible responses as specifi ed by the ail description.
this means that the client code is effec tively tested on a variety of structurally meaningful inputs.
the r esponse data generated by the mock server may of course not be semanti cally valid but as argued above structurally correct resp onse data will suffice for testing many properties of client code.
this approach also elegantly handles the issue with the users login operation mentioned above the mock server component will ski p the actual password check and automatically produce a meaningf ul response representing successful login.
second our approach makes it easy to model the asynchronous nature of ajax which is a source of intricate race errors even though the ail mock server component only produces a sin gle response for each request in step the artemis test inpu t generator component may create multiple new inputs in step to t est different event orders.
third the construction of responses in step may not be entirely random.
we can exploit the existing feedback mechani sm in artemis such that information that has been collected by art emis in previous executions of the javascript code with different t est inputs can guide the selection of the new ajax response data.
specifi cally artemis dynamically collects constants that are used in eac h event handler and these constants are often good candidates f or values in new event parameters such as the ajax response data.
.
automatic learning of ail descriptions we have shown that ail offers a simple formal mechanism for documenting client server communications in ajax style w eb applications and that ail descriptions are useful in automate d testing of the client code.
however despite the many advantages of h aving server interface descriptions constructing such descrip tions for preexisting applications can be a nontrivial task.
to support t he construction of ail descriptions we show how to automatically learn descriptions from samples of client server communication traffic through a black box dynamic approach.
this approach has be en chosen for generality and independence of particular serve r technologies used.
we imagine that such a learning algorithm can be used when a development team realizes that their web applica tions have grown from being small and manageable to become larger and more difficult to maintain without proper separation of c oncerns and without the ability to apply automated testing tec hniques.
automated learning makes it easier to retrofit server interf ace descriptions to existing applications thereby supporting a utomated testing for the further development of the applications.
we assume that the ail descriptions being used in automated testing as described in section have been written manually or with support from the learning algorithm.
the automatically gen erated descriptions may naturally require some manual adjustment s since they are generated on the basis of sample data.
we first introduce our learning problem.
the inputidenotes a finite set of concrete http request and response pairs a bracketle tr s a bracketri ht.
the outputddenotes an ail description that expresses a possibly infinite relation llbracketd rrbracketof request and response pairs.
since we perform black box learning we assume that sufficient samples are av ailable for learning.
given a set of input samples there are many valid ail descrip tions that generalize it.
thus it is important to define wh ich ail descriptions are the most desired.
at the high level we want a learned ail description to closely match the server program mer s view of the interface a set of independent operations each w ith its own meaning and purpose.
the central challenge is to iden tify these operations from the given observations without any wh ite box knowledge of the server and client.
to guide our learning algorithm we specify the following de sirable properties that a learned description should have completeness the input iis covered by the learned ail descriptiond i.e.i llbracketd rrbracket.
disjointness the request patterns of dmust be disjoint.
precision dshould be as close to ias possible i.e.
llbracketd rrbracket ishould be small.
we say that d1ismore precise thand2iff llbracketd1 rrbracket i llbracketd2 rrbracket i. conciseness dshould be small.
we say that d1ismore concise thand2iff d1 d2 where d denotes some appropriate notion of the size of an ail description d. with these properties in mind we devise an algorithm to lear n ail descriptions from input samples.
our algorithm has two p hases data clustering andpattern generation .
the data clustering phase is the key step organizing the input samples into distinct clu sters such that each cluster corresponds to a likely operation descr iptor and these together form an ail description with the aforementio ned properties.
once the appropriate clustering has been deter mined the pattern generation phase transforms the clusters into a ctual ail descriptions and json schemas.
this last step is straightfo rward and will not be described in this paper due to space constrain ts.
for the clustering phase we make two observations.
first id entifying responses that are structurally similar can be a good s tarting point.
for example two json values that have the same objectstructure but contain different strings or numbers can be co nsidered similar and hence likely belong to the same operation .
second we can infer important information for clustering from the path fragments and parameters that occur in the request data .
as an example consider requests to the first operation from figur e post comment delete comment id delete.json a request consists of path fragments and get post parameter s which we will denote features.
the features for this operati on are three path fragments i.e.
the constant strings comment anddelete and a comment id value.
these can be divided into key features which are characterized by having relatively few possible v alues that together identify the operation for the request and non key features with a higher number of possible values which do not identify operations.
for this particular operation the key fea tures are the first two i.e.comment anddelete and we can expect that our sample data will contain a higher number of comment id values than the number of distinct operations.
these observations motivate us to further divide the cluste ring phase into two steps construct an initial clustering by considering only the response data and grouping the responses into distinct clusters with respect to their response types sectio n .
and restructure the clustering using request data by identi fying the likely key features section .
.
after the clustering pha se we construct ail descriptions that satisfy the completeness p roperty by ensuring that each sample is associated with a cluster and giving the cluster a request pattern and a response pattern that match all samples in the cluster.
.
response data clustering we first cluster the input set iusing http response data.
although ail can describe both xml and json data we describe our algorithm for json which is the most widely used data int erchange format for ajax web applications.
a json response is a javascript data structure containing primitive values st rings numbers booleans and null objects and arrays.
for each request and response pair a bracketle tr s a bracketri ht i the response s contains json data.
we map sto its type abstraction aprimitive value is mapped to its respective primitive type e.g.
string number boolean ornull anobject value p1 v1 ... pk vk is mapped to a record type p1 t1 ... p k tk by replacing each object property value with its type where tidenotes the type of the value vi and anarray is mapped to a union type k i 1ti where tidenotes the type of vi.
we now cluster all sample pairs from iaccording to structural equivalence of the response type abstractions.
for example the five sample responses shown in figure will be clustered togethe r into three clusters.
the first two samples have the same type abstr action id number name string stories number and are thus grouped together while the next two contains an additi onal property resulting in the type abstraction id number name string email string stories number and their own cluster.
similarly the type abstraction of the last respon se id number title string does not match the first or the second cluster so it will be placed in a third cluster.
.
request data clustering using the distinction between key and non key features we w ant our learning algorithm to construct request patterns in whi ch key features are represented using constant strings and non k ey features are represented using wildcards.
however deciding o n the division between key and non key features may require restr ucture of the clustering to ensure that the disjointness property i s satisfied.
angbracketleftget author?name alice id name alice stories angbracketright angbracketleftget author?name bob id name bob stories angbracketright angbracketleftget author?name charlie id name charlie email charlie example.org stories angbracketright angbracketleftget author?name eve id name eve email eve example.org stories angbracketright angbracketleftpost news read id title news id title news angbracketright figure example request and json response pairs a bracketle tr s a bracketri ht for two different operations.
in the example shown in figure the first four responses are i nitially put into two clusters.
if the name parameter is classified as a key feature then we need to split the two clusters into four one for each sample.
on the other hand if it is classified as a non key feature then we need to merge the two clusters into one to ens ure disjointness.
to generate the desired request patterns usi ng constant strings and wildcards this example shows that we may n eed tomerge clusters together using a wildcard or split them into separate clusters using constant strings.
to describe in more detail how we merge and split clusters we first introduce some additional terminology.
as stated eac h path fragment and parameter of a request is a feature .
the set of features in a request forms its signature denoted by s. as an example a request with url foo bar and a parameterbaz has the signature baz where path fragments are identified by their positions in the url and parameters are identified by th eir names.
since we wish to construct one request pattern for eac h cluster we first split clusters that contain requests with d ifferent signatures.
request patterns that are constructed from clu sters with different signatures are trivially disjoint.
next we need to decide on a suitable partition of sinto key and non key features corresponding to constant strings and wildcards respectively.
there are two obvious extremes when selecting the partition assign wildcards to all features thereby merging all clust ers with the same signature into a single one which is likely to be hig hly imprecise and assign constant strings to all features th ereby splitting all clusters into singletons i.e.
simply the input set i which is neither concise nor very useful.
these two extremes relat e to operation descriptions being concise and precise respective ly which are conflicting requirements that we must reconcile.
our algorithm is given in figure .
let dbe initial response data clustering dfrom section .
.
for each signature sind the algorithm iterates over all clusters d that match s. it then iterates over all possible partitions that divide sinto key and non key features selecting the partition with the minimal cost with respect to a cost function c. this partition is used to restructure the clusters d. the end result after iterating over all signatures is drestructured in accordance with its request data.
what rema ins is to define the cost function c d where is a partition of s into key and non key features and d is a set of clusters with the same signature.
recall our observation that clustering based on response ty pes typically yields a good baseline clustering.
thus we favor partitions that result in the smallest number of splits and merges compared to the baseline clustering.
this strategy is further s upported by the other observation that key features have few unique va lues so our goal is to find a partition that leads to the smallest num ber of splits and merges.function request dataclustering d for allsinsignatures d do d find clusters withsignature d s cmin min null for all inpartitions s do c c d ifc cminthen cmin c min end if end for restructure d min end for end function figure the request data clustering algorithm.
we define the cost c d as the total number of splits and merges necessary to get from d to the restructured clustering.
intuitively a least cost partition helps avoid merging too mu ch for precision and avoid splitting too much for conciseness.
i n case of a tie we choose a partition that minimizes the number of wild cards.
to illustrate the cost calculation consider the two initia l clusters that were created from the first four sample responses in figu re .
those two clusters are a result of different response struct ures however we cannot ensure disjointness of the request patterns without a reorganization.
both clusters have the signatures s name corresponding to the author url path fragment and the name parameter.
the cost function is applied to all possible partit ions of s in this example the following four partitions .
neither 0nor name is considered a key feature causing the two clusters to be merged at a cost of into a cluster with request pattern ?name .
.
only 0is a key feature which also causes a single merge operation hence the cost is but the resulting cluster now has request pattern author?name .
.
only name is a key feature which means that the two clusters are split into four singleton clusters at a total cost of resulting in the four request patterns ?name alice ?name bob ?name charlie and ?name eve .
.
both 0and name are key features which also results in four singleton clusters at a total cost of but the request patterns are nowauthor?name alice author?name bob author?name charlie andauthor?name eve .
we choose the second partition since it has minimal cost and m inimal number of wildcards.
finally we have constructed clusters with the desired prop erties.
each cluster can be turned into an ail operation descriptor as hinted earlier.
its request pattern is generated from the em ployed partition and json schemas for the response patterns are generated from the type abstractions of the response samples in the cluster.
the close connection between json schemas and the t ype abstraction we uses for response data leads to a straightfor ward construction.
.
ev aluation we have argued that server interface descriptions can provi de separation of concerns which enables testing of javascrip t code in isolation from the server code.
when conducting automated t esting of the javascript code the use of ail and a mock server remove s the burden of setting up actual servers with appropriate dat abase contents.
to find out how this may influence other aspects of au tomated testing we first consider the following research ques tions client server benchmark loc framework language simpleajax jquery python django resume flapjax python globetrotter jquery java jwig impresspages jquery php buggenie prototype php elfinder jquery php tomatocart prototype php eyeos jquery php figure benchmark applications.
q1.
how is the running time of automated testing affected whe n replacing the real server by the mock server for a fixed number of test inputs?
q2.
does the use of ail in place of live servers affect the code coverage obtained by automated testing?
to evaluate how our learning algorithm from section can be u seful when creating ail descriptions for existing applicatio ns we consider two additional research questions q3.
to what extent is the learning algorithm capable of produ cing ail descriptions that correctly describe the servers in act ual javascript web applications?
q4.
how much effort is required for producing request and response data for the learning algorithm and how fast is the learning algorithm?
to answer these questions we have implemented three tools a web proxy for recording the http communication between clients and servers the learning algorithm from sectio n which reads the data recorded by the web proxy and outputs ail descr iptions and json schemas and the ail mock server for artemi s. we have collected benchmark applications that use javascr ipt for their client side logic and ajax for communicating betw een the client and the server and where the source code for the entir e application has been available including the server code simpleajax is a small home built test application for event registration s resume10 is an application management system globetrotter11is a travel application system impresspages12is a cms system elfinder13is an online file explorer buggenie8is a project management tool that we also used as example in section tomatocart14is an ecommerce platform and eyeos15is an online desktop environment.
figure contains a list of the applications together with th e number of lines of javascript code excluding frameworks the framework they use for javascript if any and the language or frame work used on the server side.
our experiments are performed on a .1ghz i5 machine with 4gb of memory.
.
using ail in automated testing to be able to answer q1 and q2 we run artemis on our benchmark applications using various configurations emptydb with real servers but with empty databases fulldb with real servers where the databases are populated with realistic data random with a fully generic mock server that accepts all requests and produces r andom json responses and ailwith the mock server using the ail description.
9our tools are available at 10old version of ail fulldb init emptydb fulldb random ail simpleajax 25s 26s resume 67s 77s globetrotter 102s 94s buggenie 104s 180s elfinder 162s 152s figure execution time for artemis with a budget of test input executions and code coverage obtained by artemis wit h a budget of test inputs.
the database contents used in the fulldb configuration are se lected as snapshots obtained when we exercised the applicat ions to collect sample request and response pairs.
for the ail con figuration we use manually constructed ail descriptions or e quivalently descriptions that were produced by the automated le arning and subsequently manually adjusted to properly model the se rvers.
three of the larger benchmark applications are unfortunate ly beyond the capabilities of the latest version of artemis for re asons that are unrelated to ail and ajax communication so our expe riments are conducted on the remaining five applications.
the execution time of artemis depends on a number of factors one of course being the time budget which is expressed as a ma ximum number of test input executions.
other factors are the s pecific data that the javascript application receives from the server in ajax interactions and the response time of the server.
rep lacing the live server with a mock server affects the two latter f actors.
responses that are randomly generated from the ail response patterns may trigger long running loops in the javascript code however the work performed by the mock server is presumably sim pler than that of the real server in most cases.
the first columns in figure show the total running time of artemis with the two configurations ail and fulldb using a bud get of test input executions for each application.
this g ives an answer to q1 for these applications the running time is n ot affected notably by the ail mock server.
the remaining columns show the code coverage measured as number of lines of javascript code for test input execut ions of each application using all four configurations.
the extra column init shows the coverage obtained by loading the applic ation without triggering any events which can be viewed as a basel ine for the coverage comparisons.
the globetrotter andbuggenie applications have not been tested with empty databases since t his did not make sense for those cases.
please note that the loc colu mn in figure should not be compared with the coverage numbers i n figure since the latter only include lines with executabl e code.
we observe that the use of the ail mock server yields similar coverage results as when using the real servers populated wi th realistic data which partially answers q2.
forglobetrotter elfinder and resume coverage is slightly improved when using ail.
in each case the increased coverage i s caused by conditions in the javascript code that are only tri ggered with specific ajax response data for example an empty array o r a certain boolean value somewhere in a json structure.
these a re examples of application behavior that depend on the precise co ntents of the server database as discussed in section .
in globetrotter for example the program state describes a travel applicati on that can be at different workflow stages.
the mock server quickly g enerates json responses that cover all the workflow stages whi le the fulldb configuration only manages to cover a single one.
the lower code coverage for buggenie is caused by an animation not being triggered in the ail configuration due to the heuris tics used internally by artemis.
for elfinder a few lines are reached with fulldb but not with the ail configuration.
the data in thi s application contains a tree like structure of files and dire ctories that are linked through hash and parent hash values that refer to e achother.
this invariant cannot be expressed with the current d esign of ail so the mock server is not able to produce the right respon se.
several additional observations can be made from the covera ge numbers.
the emptydb fulldb and ail measurements show higher coverage than init demonstrating that we actually t est additional functionality besides simply loading the page.
inte restingly the random measurements for resume globetrotter and elfinder show considerably less coverage which demonstrates that m eaningful response data is important.
in all cases this is caus ed by the initialization of the web applications depending on correc tly structured ajax responses.
as expected populating the database i.e.
fulldb results in higher or equal coverage than using the em pty database i.e.
emptydb .
although we did not expect to find bugs in the benchmark applications the use of the ail mock server revealed one in resume that was not found with any of the other configurations.
the bu g is triggered by a sequence of events that involve sending an e mpty array to the server and back to the client ending up in obj.values at the following snippet of code where it leads to a runtime er ror varln a href javascript undefined obj.values obj.values this example illustrates how unclear assumptions between c lient and server developers can end up creating errors in the appli cations.
in other situations similar unclear assumptions do not cau se errors but lead to fragile code that may break in future revisio ns made by programmers who are not aware of subtle invariants that mu st be satisfied.
the use of ail in artemis also revealed such a sit uation.
the elfinder application contains the following snippet of code wheredirandfiles originate from an ajax response while dir dir.phash dir files the purpose of this code is to traverse a directory structure where files are represented in an array indexed by file hash values.
r unning artemis with the ail configuration discovered that if th is data structure contains loops then the while loop never terminates.
the required invariant that the data structure sent in the ajax response never contains such loops is not documented in the applicat ion source code.
ail is not expressive enough to capture such inv ariants but one could argue anyway that the application would b e more robust if its correctness did not depend on such intrica te invariants involving the server state.
concluding these experiments our answer to q2 is that the us e of ail leads to good coverage compared to using a server with an empty database a server with a populated database or a mo ck server that generates random responses.
the experiments al so pointed us to examples where correctness of the application s depends on subtle undocumented invariants.
.
automated learning of ail descriptions to obtain the training data for the learning algorithm we in stall and exercise each application by manually clicking on visua l elements and entering data into forms for a few minutes while th e web proxy monitors all ajax communication.
this is done with out detailed knowledge of each application and entirely withou t looking at the server code.
this gives us between and sample request and response pairs depending on the amount of infor mation exchanged.
we now run the learning algorithm on the data obtained for eac h application which in each case takes less than a second.
the request data clustering process described in section .
perf orms al benchmark samples sampling learning match n n simpleajax 3m 74ms resume 9m 111ms globetrotter 8m 84ms impresspages 6m 224ms buggenie 6m 118ms elfinder 6m 124ms tomatocart 8m 153ms eyeos 6m 213ms total figure number of sample request and response pairs used for ail learning time used for collecting sample data and learning ail descriptions and results from comparing the learned ail descriptions with the manually written ones.
together splits and merges when searching for the parti tions with the minimal cost.
this results in a total of ail opera tion descriptors and lines of json schema all generated au tomatically.
figure shows the amount of sample data the time used for collecting the sample data and the time used by the ail learn ing algorithm for each application.
from these numbers we ca n give a rough answer to q4 the effort required for using autom ated ail learning is clearly manageable compared to the time oth erwise spent developing the web applications.
producing ail descriptions is of course not enough they als o need to capture the actual patterns of the ajax communicatio n. recall from section that the constructed ail description is c omplete by construction relative to the training data.
however th e training data may not cover the entire application which might resul t in incomplete ail descriptions where some operations support ed by the server are missing in its ail description.
another poten tial source of mismatches between automatically constructed ai l descriptions and manually written ones is that the learning al gorithm may not be sufficiently precise or concise using the termino logy from section .
furthermore as there is no canonical best ail description for a given ajax server we must settle for a subj ective baseline for comparison which we decide to construct a s follows for each benchmark application we manually write an a il description based on an inspection of the source code for the server part of the application.
this process can take hours but thi s work is of course only required to be able to measure the quality of the learning algorithm in our experiments.
next we need a measure of the difference between the automat ically constructed ail descriptions and the manually const ructed ones.
the first aspect of this measure is how the individual op eration descriptions match between the two.
figure also show s the results of this comparison.
the match column counts the numb er of learned operations that map directly to the actual server operations while nandn count the number of server operations that map to multiple learned operations and vice versa whic h indicate mismatches between the two descriptions.
a second aspe cts is to what extent the individual datatypes of parameters and re sponse patterns differ between the two descriptions.
we get a total of matches occurrences of n and a singlen .
the high number of matches is already encouraging but a closer inspection of the other cases reveal that they ar e relatively benign.
in all the ncases a simple manual merging of the relevant operation descriptors suffices to resolve th e discrepancy.
this is acceptable since the learned ail description i s only intended as a starting point for the programmer as an altern ative to writing the ail description from scratch.
an example is delete operation in resume which can be called both with and without an idparameter resulting in different responses causing the le arning algorithm to produce two separate ail operation descriptor s. an other example of a ncase appears in buggenie .
in this case a specific server operation runissuerevertfield performs multiple tasks and dispatches internally based on a parameter field in a way where one may argue that the ail description produced by the learning algorithm where these sub operations are d ivided into separate descriptors is in fact just as good as the manu ally constructed one.
the single n case appears in tomatocart and is caused by our merging heuristic being slightly too aggressive.
two opera tions for deleting images and setting default images respectively both take anidparameter and return a trivial response and the operations are only distinguished by the value of an action parameter.
the similarity of the data causes the two operations to be merged by our current heuristic.
regarding the quality of the inferred datatypes in request a nd response patterns we notice that many of our benchmarks use js on in responses but not in requests.
for request patterns the m ain question then is whether wildcards are introduced appropriatel y. the learning algorithm needs at least two distinct values of a pa th fragment or parameter to conclude that it is not constant.
for exa mple resume represents session ids in parameters so the training data must involve multiple sessions.
incompleteness of our samp le data in some cases results in missing wildcards however this is easy to adjust manually after the learning phase.
most json response data in the benchmark applications is bui lt using arrays and simple objects with fixed collections of pro perties.
for these common cases the learning algorithm is able t o generate json schemas correctly.
differences between the j son schemas constructed by the learning algorithm and the manua lly constructed ones are mostly due to incomplete sample data.
h owever we observed two interesting cases in impresspages andglobetrotter respectively that could be improved.
some responses in impresspages have a recursive structure of objects and arrays.
more specifically the data represents a list of page and director y objects where each directory object itself contains a list of page an d directory objects.
our current learning algorithm is not able to p roduce the desired concise json schema.
in globetrotter a specific json structure contains information about a list of countries.
e ach country is represented by an object where the country name appear s as a property name not as a property value which causes the lea rning algorithm to view each country object as being distinct.
based on these experiments our answer to q3 is that the learn ing algorithm is able to produce ail descriptions that are reaso nably close to manually constructed ones.
this suggests that auto mated learning can be a good starting point for creating ail descri ptions for pre existing applications and that sufficient sample d ata can be obtained by someone who is familiar with the functionality o f the applications but does not have knowledge of the server code.
.
threats to validity a possible threat to validity of our experimental results is that the manually constructed ail descriptions that we use as bas eline for the comparisons have been made by ourselves without expe rt knowledge of most of the benchmark applications.
more solid results could perhaps be obtained by performing user studies w ith the developers of the applications.
also our benchmark applic ations do not reflect all possible uses of ajax and json and they may n ot be representative of typical usage patterns although we hav e striven toward including a wide variety of applications.
.
related work our work touches on several areas of work on interface descri ptions automated testing of web applications and learning algorithms.
.
interface descriptions for separation of concerns the idea of design by contract is a fundamental principle i n modern software engineering for separating the concerns of ind ividual software components.
even in web programming which often involves dynamic scripting languages both on the client and the server interface description languages play an important role similar to ail wsdl allows description of operations and th eir argument and return types however wsdl is tailored to xmlbased web services and has no support for json and we are not aware of uses of wsdl for describing server interfaces in aja xstyle javascript web applications.
as mentioned in section ail is by design conceptually closer to the language wadl a lthough ail has a compact non xml syntax and supports json.
the web idl language is used for describing the api that web browsers provide to javascript programs for accessing the html dom and other parts of the browser state however unlik e ail each web idl description is common to all javascript web applications and cannot describe the interfaces of individ ual ajax servers.
web idl has its roots in the omg idl interface definit ion language for corba .
interface descriptions have also been proposed for html for mbased web applications without javascript.
the webappsleu th methodology by fisher et al.
works by submitting reques ts to a server and analyzing the responses to infer parts of its int erface.
the resulting interface descriptions are related to ail des criptions but tailored to html forms not json or xml.
each form is described by its set of mandatory and optional fields together w ith simple value constraints and dependencies between the field s. the extensive survey by alalfi et al.
covers many modeling methods used in web site verification and testing but wit hout javascript and ajax.
to our knowledge the only existing wor k involving interface descriptions for ajax communication is t hat by hall et al.
.
they propose a contract language based on i nterface grammars linear temporal logic and xpath express ions for specifying the order of http interactions that exchange xml data in long running sessions.
we believe the data formats of req uests and responses are more important in typical ajax applicatio ns than restrictions on the order of operations so we have chosen to ignore the temporal aspect in our first version of ail.
their paper di scusses how the contracts can be used for runtime monitoring.
they also ask the important question who should write the contracts?
to this end we take the approach of using machine learning on sample execution traces as explained in section .
a range of well documented web services that fit into the desi gn of ail can be found at google s apis explorer website.16the interface descriptions for those web services are only made av ailable as online documentation for programmers not using any inte rface description language which makes them less accessible to for example automated testing tools.
.
automated testing of web applications besides the artemis tool that we discussed in section .
we are aware of a few other tools for automatically testing java script web applications.
the kudzu tool by saxena et al.
perfor ms automated testing by a combination of symbolic execution wi th a string constraint solver for value space exploration and ra ndom exploration of the event space whereas artemis uses a more lig htweight feedback directed approach.
the state based testi ng technique by marchetto et al.
builds finite state machin es that model ajax web pages from concrete execution traces.
as in ou r approach a subsequent manual validation or refinement step is to ensure that the extracted model is correct befor e the model can be used for automated testing.
the key difference t o our approach is that the models in state based testing descr ibe the dom states of the javascript execution not the interaction s with the server.
a closely related tool is crawljax by mesbah et al .
that also aims to derive models of the user interface stat es of ajax applications and use these models as a foundation for te sting.
ajax crawl by duda et al.
similarly performs dynamic exploration of ajax applications but for the purpose of cra wling the applications by search engines not aiming at testing.
a common limitation of kudzu crawljax and ajax crawl is that the exploration of the javascript applications is do ne with little focus on the client server communication simply us ing live servers which leads to the problems discussed in section .
about how to properly populate the server databases.
on top of this most tools with artemis as an exception do not restore the s erver database state after each test input execution which affec ts testing reproducibility.
the jscontest tool by heidegger and thiemann performs random testing for javascript programs that are annotated with type contracts .
these function annotations play a similar r ole as ail descriptions but at the level of function calls rather t han ajax client server interactions.
due to the javascript orient ed design of json schema that we use in ail it is natural that the basic contract language in jscontest has similar expressiveness .
however jscontest also supports function types which are not relevant for client server exchange of json or xml data.
another difference is that jscontest permits user defined contract s written in javascript which might be useful to consider for a future version of ail to address the limitations identified in section .
several tools have been developed for automatically testin g serverbased web applications.
the apollo tool by artzi et al.
an d the tool by wasserman et al.
perform directed automated ran dom testing for php code but javascript is not considered.
with our proposal of using a server interface description language f or separating the concerns of server code and client code we have so far focused on testing the client code but an interesting direc tion of future work is to develop testing or analysis techniques that c an also check whether the servers fulfill their part of the contracts .
elbaum et al.
have proposed the use of user session data f or black box testing of web applications.
they record concret e user sessions and replay the sessions in various ways to test the s erver code not aiming for testing client code and not involving ex plicit server interface descriptions.
the wam tool by halfond and orso automatically discovers interfaces of web applications using static analysi s or symbolic execution of the server code.
the interfaces are subse quently used in automated testing similar to our approach althoug h wam considers classical web applications without ajax and json .
the notion of interfaces used by wam is similar to that in webappsleuth.
wam is restricted to java servlets unlike our appro ach which is in principle independent of the languages and frame works used on the server.
.
learning algorithms the learning algorithm presented in section has been devel oped specifically for ail but related algorithms exist for o ther domains.
webappsleuth which we also mentioned in section .
uses learning techniques to identify interfaces of server based web applications that receive html forms.
that approach does no t involve learning the structure of server response data and a s ingle server operation is considered at a time while our learning algorithm needs to work for multiple operations.the latest version of wam likewise uses a learning algorithm to produce interface descriptions.
the wam algorithm operates on path constraints constructed through symbolic ex ecution of the server code which differs from our learning algorith m that is based on sample request and response data and has a black b ox view on the server.
furthermore wam does not consider respo nse types unlike our learning algorithm.
the clustering problem that we face in section is related to the work by broder et al.
on clustering web pages that are synt actically similar .
their approach is to define a distance me asure between two web pages using a distance threshold to cluster similar pages.
this approach could be transferred to json respo nses and our learning algorithm but we found the results from ini tially clustering only entirely equal structures to be sufficient f or our purposes.
we are not aware of existing work on json schema inference.
the closest related work has been centered around dtd and xml schema inference.
this problem is described by chidlovskii as being reducible to grammar inference .
others improve on this line of work however the differences between xml and js on make their algorithms unsuitable for json schema.
.
conclusion server interface descriptions for ajax style web applicat ions enable separation of concerns of the server code and the client code.
the ail language has been designed to capture the essence of t he existing proposals wadl and allow concise description of th e basic properties of server operations in particular involvi ng json data.
our experimental validation suggests that the expres siveness of ail suffices for typical ajax communication patterns but also that it might be useful in future work to add support for user defined contracts to specify more fine grained invariants.
one key contribution is that we demonstrate that server inte rface descriptions are useful in automated testing.
no previous w ork has combined server interface descriptions with testing of aja x applications.
our experimental results show that this approach c an improve the level of automation by eliminating the need for car efully populated databases on the servers while maintaining the q uality of the testing of the client code.
another key contribution o f our work is the automated learning algorithm that can produce se rver interface descriptions from sample request and response da ta.
the experiments show that ail learning can be performed with a mo dest effort and that the resulting descriptions are a good st arting point when programmers wish to construct ail descriptions f or pre existing web applications.
in addition to the suggestions about possible extensions of ail several directions of future work appear.
as an alternative or supplement to our ail learning approach that has a black box vie w on the server it would be interesting to infer or validate ai l descriptions by static or dynamic analysis of the server code f or the most widely used server web frameworks.
additionally ail m ay also be useful for static analysis of javascript applicatio ns to enable more precise reasoning of ajax interactions than currently possible.
specifically we wish to incorporate ail into the javascript analysis tool tajs .