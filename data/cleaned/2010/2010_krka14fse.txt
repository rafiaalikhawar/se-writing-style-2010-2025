automatic mining of specifications from invocation traces and method invariants ivo krka yuriy brun nenad medvidovic google inc. university of massachusetts university of southern california zurich switzerland amherst ma usa los angeles ca usa krka google.com brun cs.umass.edu neno usc.edu abstract software library documentation often describes individual methods apis but not the intended protocols and method interactions.
this can lead to library misuse and restrict runtime detection of protocol violations and automated verification of software that uses the library.
specification mining if accurate can help mitigate these issues which has led to significant research into new modelinference techniques that produce fsm based models from program invariants and execution traces.
however there is currently a lack of empirical studies that in a principled way measure the impact of the inference strategies on model quality.
to this end we identify four such strategies and systematically study the quality of the models they produce for nine off the shelf libraries.
we find that using invariants to infer an initial model significantly improves model quality increasing precision by and recall by on average effective invariant filtering is crucial for quality and scalability of strategies that use invariants and using traces in combination with invariants greatly improves robustness to input noise.
we present our empirical evaluation implement new and extend existing model inference techniques and make public our implementations ground truth models and experimental data.
our work can lead to higher quality model inference and directly improve the techniques and tools that rely on model inference.
categories and subject descriptors d. .
debugging aids tracing general terms algorithms design modeling keywords model inference execution traces log analysis .
introduction developers frequently use existing software libraries.
unfortunately many libraries are poorly documented hindering reuse and forcing developers to re engineer existing solutions .
even heavily used well documented libraries contain documentation inaccuracies as updates to the documentation lag or fail to follow this work was completed while ivo krka was a phd student at the university of southern california.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
copyright held by the owner author s .
publication rights licensed to acm.
fse november hong kong china acm updates .
further natural language documentation can be ambiguous and misunderstood by developers causing library misuses that lead to subtle latent and costly faults.
a promising way to ease library use is to automatically mine accurate specifications from existing uses of those libraries .
numerous specification mining techniques have been proposed and used for test case generation debugging validation and fault localization .
the quality of the inferred specifications is critical to their successful use.
in fact most research on specification inference focuses on improving the quality of the inferred specifications.
yet the relationship between the principles employed by inference techniques and the quality of the models they produce is not well understood and existing studies have not pursued to improve this understanding in the context of real world software.
the goal of this paper is to systematically evaluate the principles behind existing inference techniques particularly with respect to the input data used by the techniques to understand the effects of these principles on the inferred models quality and on the scalability of the inference.
the main contributions of this work are an enhanced understanding of how to best design and improve inference techniques and a novel technique that implements these improvements.
existing mining techniques either infer finite state machine fsm models that support the observed invocation sequences also referred to as execution traces or identify high level properties declarative class and method invariants by observing how a library s state its internal variables changes at runtime .
hence the utility of the dynamic inference techniques in general and fsm inference techniques in particular critically depends on how rich the inferred models are and how close they are to the true model of the system s behavior.
the primary focus of fsm inference research has been to improve the inferred models precision e.g.
.
recent research suggests that the inferred models quality can be improved by extending the fsm inference that relies solely on execution traces by also using internal state information available during execution .
in the limit the contractor algorithm demonstrates that fsm inference can rely exclusively on internal state information .
while existing evaluations of model inference research have made substantial contributions they also have had significant limitations our work addresses.
most importantly to properly compare inference techniques it is necessary to understand how well they perform on real software and how their underlying principles e.g.
reliance on inferred state invariants vs. reliance on execution traces affect model quality.
many existing studies of model quality rely on simulated execution traces as opposed to traces from actual software systems .
as simulations are typically more controlled than real software this runs the risk of inaccurately esti178mating how the techniques perform in the wild.
meanwhile those studies performed on real software typically estimate the quality of the inferred models via proxies.
for example the quality is sometimes measured via test coverage the number of automatically detected faults or case study analysis of manually discovered faults instead of the more generalizable information retrieval metrics of precision and recall .
further there are no studies to date that thoroughly measure the effects of the types of input information used by inference techniques on the quality of the resulting models.
in particular there are four possible strategies to dynamic fsm inference .traces only infer models from execution traces only.
.invariants only infer models from invariants.
.invariant enhanced traces infer models from execution traces and then enhance them with invariants.
.trace enhanced invariants infer models from invariants and then enhance them with execution traces.
in this context the research questions how do these strategies impact the quality of the inferred models?
and under what circumstances are they effective?
remain unanswered.
notably the empirical study conducted by lo et al.
provides an initial comparison of the first and the third strategies above.
to answer these questions this paper provides an empirical study that compares the quality of models inferred by four techniques that respectively implement the above four strategies.
the ktail inference algorithm representing the traces only strategy is employed and enhanced by many model inference techniques e.g.
.
we select k tail because k tail models turn out to already be highly precise in our evaluations and further precision improvements would not affect our findings.
contractor representing the invariants only strategy is our own extension of the contractor technique that creates models based solely on the inferred state invariants.
contractor addresses the limitations of contractor when applied to dynamically inferred as opposed to manually specified state invariants.
sekt representing the invariants enhanced traces strategy is our own extension of k tail that uses state invariants to restrict the way k tail merges execution traces.
sekt expands on lorenzoli et al.
s gk tail algorithm by relaxing restrictions on how and which invariants are inferred for small subsets of the execution traces.
finally temi representing the trace enhanced invariants strategy is a novel technique we have developed as part of this research that first infers a model based on the state invariants and then refines that model with the information from the execution traces.
a systematic careful evaluation of the four strategies has two critical requirements.
first the findings must be generalizable.
second they must be applicable to real world systems.
our evaluation relies on nine widely used open source libraries selected from a range of domains.
further our evaluation derives the execution traces by running eight real world publicly available applications that use the selected libraries.
by so our evaluation reflects more closely than most existing studies the scenario of an engineer encountering a poorly documented library and trying to infer a usage model from other open source software uses of that library.
we compare the quality represented by precision and recall of the models produced by the four strategies.
we also assess two important and often overlooked aspects of model inference the scalability of the strategies and their robustness to noise in the inputs.
we make four evidence supported conclusions .invariants only and trace enhanced invariants strategies produce significantly higher recall than the traces only and invariantenhanced traces strategies while maintaining or in rare cases minimally reducing the already high precision.
.in the general case invariant enhanced traces and trace enhancedinvariants strategies that combine the two types of execution information slightly improve the precision of the inferred models while maintaining the recall.
.invariant filtering that keeps only a limited set of relevant invariant types is crucial to enhancing the scalability of techniques that implement invariants only and trace enhanced invariants strategies.
.while the quality of models inferred by invariants only and trace enhanced invariants strategies is similar in most cases combining an fsm inferred from invariants with execution traces circumvents the risks associated with noisy invariants.
such noise significantly reduces the quality of invariants only strategy models making it also perform worse than the traces only and invariant enhanced traces strategies.
the remainder of the paper is organized as follows.
section overviews the background.
section details the techniques representing the four strategies.
section evaluates those techniques while section discusses the impact of the results.
section places our work in the context of related research.
finally section summarizes the paper s contributions.
.
background this section provides the background necessary for the discussions in this paper.
section .
introduces stackar our running example data structure.
section .
defines the mts formalism used by three of the model inference techniques in section and discusses how execution traces map to an mts.
finally section .
defines program state and discusses state invariants.
.
example library stackar stackar is a java implementation of a stack distributed with daikon .
initialized with an integer capacity stackar has six public methods push x top topandpop makeempty isempty and isfull .
internally stackar represents its stack as an array thearray and has a pointer to the top of the stack topofstack .
apush on a full stack generates an exception.
a top ortopandpop on an empty stack returns null .
.
modal transition system mts an mts is an fsm based model with labeled transitions between states.
a state represents a specific point in the execution of a system or module a transition represents the system s change from one state to another caused by some invocation.
in an mts there are two explicit kinds of transitions required which are transitions that are certain to occur and are common to all fsms and maybe which are uncertain transitions unique to mtss.
we use the notation sl !
rs0andsl !
ms0 respectively to denote required and maybe l labeled transitions between states sands0.
the most common input to a model inference algorithm is a set of observed execution traces.
an execution trace a runtime recording of public method invocations and internal data values between those invocations can be represented by an mts with states corresponding to variable values and transition labels composed of the method name input values and return value.
.
program state and state invariants a program s concrete state is represented by the values of the program s variables at a given snapshot in the program s execution.
however for non trivial programs there exist intractably many concrete states.
for example for stackar there are an infinite 179datastructures.stackar class this.topofstack this.topofstack size this.thearray datastructures.stackar.push java.lang.object enter this.topofstack size this.thearray this.topofstack datastructures.stackar.push java.lang.object exit103 orig this.topofstack size this.thearray this.topofstack this.topofstack orig this.topofstack size this.thearray orig size this.thearray figure a subset of daikon s program invariants on stackar .
number of concrete states represented by the contents of thearray .
therefore it is common to consider and reason about abstract program states defined with first order predicates over program variable values different program states correspond to different combinations of predicate evaluations.
for stackar one reasonable predicate that can be used to define abstract state is is the stack not full?
topofstack size thearray .
program state invariants can be used to automatically extract relevant predicates.
invariants hold true at certain program execution points.
for example an object level invariant such as size holds at all program points.
while developers can manually specify program invariants in the code or in other documentation static and dynamic analyses can automatically infer invariants.
a commonly used tool for automatic invariant inference is daikon which observes data values of program executions and infers invariants that hold over all observed executions.
the inferred invariants consist of method pre and postconditions and object invariants.
figure shows eight invariants daikon infers forstackar two object level invariants and two preconditions and four postconditions for push .
as preconditions and object invariants help determine which methods can execute in a particular state the predicates that appear in daikon inferred preconditions and object invariants are good candidates for defining abstract program state.
for stackar daikon reports four predicates p1 topofstack p2 topofstack p3 topofstack size thearray and p4 topofstack size thearray .
four boolean predicates can define 16abstract program states.
however many of these states can be automatically eliminated because of predicate interdependencies.
for example stackar sp2 cannot be true when p1is false.ktail trace set traces intk mts t ptal traces 2for each pairt s1 t s2int s iftail t s1 k t ail t s1 k m erge t s1 t s1 5return t figure the k tail algorithm.
.
inference algorithms this section details the four algorithms that respectively implement each the four model inference strategies recall section .
k tail section .
implements the traces only strategy by reasoning exclusively about the invocation sequences observed in the execution traces.
contractor section .
builds a model by reasoning about the potentially allowed invocation sequences based on manually specified state invariants.
to apply contractor on dynamically inferred invariants we have developed contractor via a set of non trivial extensions of contractor.
sekt section .
is our extension of k tail inference that implements the invariantenhanced traces strategy by considering the program states extracted from invariants as a k tail merging criterion.
finally temi section .
implements the trace enhanced invariants strategy by first building an mts that adheres to the invariants and then refining it according to the execution traces.
.
traces only traditional k tail the existing k tail algorithm concisely captures a library s api protocol as an mts with required only transitions by merging the states from the execution traces.
the algorithm merges every pair of states with identical sequences of the next kinvocations hence k tail .
figure details the algorithm.
in the first step line k tail builds a prefix tree acceptor pta .
the pta is an mts obtained by merging the initial states of each trace into a single initial state and from that state merging all those states that are reached by the same invocation sequence e.g.
states s1through s4of trace are merged with states s1through s4of trace respectively .
subsequently lines analyzes each pair of states in the pta for tail equivalence line merges the equivalent states.
the k tail algorithm relies on selecting an appropriate k. this choice typically involves a tradeoff between precision smaller kimplies more spurious merges due to the limited scope and completeness recall larger kimplies fewer merges and less generalization of the generated model.
because of that the existing k tail based techniques e.g.
have aimed to improve the algorithm s precision with smaller k. despite some improvements the existing k tail based algorithms still suffer from limitations described next.
s0stackars1 s2 s3 s4 s5 s6 s7 s8 s9 s10trace capacity s0 s4 s5pushs6 s7 s8 s9 s10trace capacity s11 s12 s13 s14 s0 s1 s2 s3trace capacity s4 s8stackar stackars1 s2 s3et tpn emp tpn tpn et ff ft ef tv ff et tpn tn tpv tn emp push pushtn ft et tn fttn toppop null tv top null tpn topandpop null tpv topandpop null emp makeempty legend et isempty true ef isempty false ft isfull true ff isfull false s15pushs16emps17push s5 s6tpv pushs7emp pushs9pushs10pushs11tpvs12pushs13tpvs14tpvs15pushs16pushs17tpvs18emp s0stackars1 s2 s3 s4 s5 s6 s7 s8 s9 s10trace capacity et tpn emp tpn tn ff et tn ff s0 s1 s2 s3 s4 s8stackar emp push pushs5 s6tpv pushs7emp pushs9pushs10pushs11tpvs12pushs13tpvs14tpvs15pushs16pushs17tpvs18emptrace capacity figure five example stackar invocation traces.
180contractor inv set invariants mts t t s 2for each tuple enabled2invariants methods clause statepred for each method2enabled statepred statepred method precond for each method 2enabled statepred statepred method precond ifsmt isconsistent statepred addt senabled tot s 10for each pairt s1 t s2int sandmethod ininv methods ifsmt isconsistent t s1 method precond and smt isconsistent t s2 method postcond addt s1method !
rt s2tot transitions 14return t figure the contractor algorithm.
to illustrate k tail and its shortcomings we use five stackar invocation traces corresponding to creating and using stacks of different capacities figure .
let us consider how tail that considers the method return values as part of its merging criterion works on these traces.
the algorithm correctly merges states s1and s6in trace 1because the two following invocations from each state areisempty true andtop null .
the algorithm also merges states s1in trace 1ands11in trace .
however this merge is imprecise as it allows a non zero capacity stack to change capacity to zero after an invocation of isfull from s10tos11in trace .
the k tail models are also incomplete for those traces in which pairs of methods happen to be but are not actually required to be invoked in a specific order e.g.
top is always invoked after isempty in figure .
the existing k tail based techniques e.g.
all suffer from these limitations.
.
invariants only c ontractor as mentioned earlier contractor comprises two parts the core algorithm contractor a recent algorithm that creates mts models exclusively based on program invariants and our enhancements to contractor take enable it to work on inferred as opposed to manually specified program invariants.
figure lists the contractor algorithm.
contractor uniquely characterizes the model s states by the combination of methods enabled in each state lines build the state set t s .
this abstraction is thus referred to as enabledness .
a state i.e.
a combination of enabled methods is legal if the preconditions of the enabled methods are consistent with one another.
the algorithm checks for consistency of the preconditions in lines with the help of an off the shelf satisfiability modulo theories smt solver such as yices .
lines create a transition on a method between two states if that method s precondition is satisfied in the source state and the postcondition is satisfied in the target state.
to use contractor in our evaluation we had to enhance its inputs in two significant ways without which both the accuracy and scalability of the algorithm would be notably lower.
we refer to these enhancements as contractor and use contractor as the implementation of the invariants only inference strategy.
we refer to the first enhancement as method distinction since contractor does not consider predicates of the methods output values in contractor we represent each method returnvalue combination as a distinct method with its own invariants.
otherwise for example the model inferred for stackar would have only two states the first one with all methods enabled and the second one with push prohibited and all other methods allowed.
such a model is imprecise as it allows for example pushing on a stack of capacity or popping non null values from an empty stack.advanced merge stt1 s stt2 p intk setpred 1iftail t1 s k tail t2 p k return false 3ifevalglobal t1 s pred evalglobal t2 p pred return false 5return true figure the sekt algorithm uses a dvanced merge to determine if two states should be merged.
we refer to the second enhancement as invariant filtering instead of using manually specified invariants contractor uses daikon inferred invariants filtered to avoid less meaningful invariants and to make the algorithm scale since dynamically inferred invariants typically have higher complexity than the manually specified ones .
we consider the relational invariants on boolean and integer variables e.g.
intequal intgreaterthan and the isnull invariant on objects.
further we consider internal variables up to a depth of one i.e.
we consider an object s fields but not those fields fields .
for collections we consider their sizes but not their elements.
without these enhancements the original contractor algorithm s models are of significantly lower quality than reported below for contractor .
note that the same set of filters are employed in and were in fact originally developed for temi.
.
invariant enhanced traces sekt while k tail has been used extensively in prior work recall section .
our state enhanced k tail sekt is the first algorithm that extends k tail using program state information inferred from the full set of observed executions.
the most closely related algorithm proposed by lorenzoli et al.
infers invariants only for the limited set of states that are merged during pta construction recall figure .
due to this limited scope for learning relevant invariants lorenzoli et al.
s algorithm may err both in allowing and rejecting merges which may decrease both the precision and the recall of the resulting model .
for example this approach merges the states in stackar s trace 1and trace 4from figure because they follow the same invocation sequence despite the different method parameter and return values.
consequently the resulting merged trace erroneously implies that a stack of size is the same as one of size even though isfull returns different values.
in contrast to lorenzoli et al.
s algorithm sekt modifies the k tail algorithm by adding a new global merge requirement the merging states must correspond to the same abstract program state.
method advanced merge in figure details this merging criterion and is incorporated into k tail by replacing the original condition specified in line of figure .
the pred parameter of advanced merge is the set of predicates that define the program states and t1 sandt2 pare the two potential to be merged states.
lines of advanced merge test the tail similarity lines check for matching program states.
the state matching compares whether the two concrete variable evaluations correspond to the same abstract program state e valglobal .
the new merging condition can prevent erroneous merges.
for example sekt avoids the spurious merge of s1in trace 1ands11in trace 2in the stackar traces from figure recall section .
the condition in line of advanced merge is satisfied thus rejecting the merge since only predicates p1andp4 from section .
are true in s1 but only p1andp3are true in s11.
.
trace enhanced invariants temi trace enhanced mts inference temi infers an mts that includes but differentiates the behavior asserted legal by the in181generate invariant mts set pred inv set invariants mts invariantmts settoprocess isprocessed set predcombinations c ombine pred 3for each combination2predcombinations ifsmt isconsistent combination addcombination toinvariantmts states 6addinvariantmts initst totoprocess 7while toprocess6 currentst toprocess pop addcurrentst toisprocessed for each methodinv2invariants ifsmt isconsistent methodinv pre currentst for each targetst2invariantmts states ifsmt isconsistent methodinv post targetst iftargetst 2isprocessed addtargetstate totoprocess addcurrentstmethodinv name !
m targetst toinvariantmts transitions 16return invariantmts figure constructing of an invariant based mts.
variants and the behavior observed in the traces.
temi consists of two phases.
the first phase conceptually similar to contrac tor constructs an mts with only maybe transitions capturing all invocation sequences of an object s interface allowed by the invariants.
we call this model an invariant based mts.
the second phase promotes transitions observed in the traces from maybe to required.
the remaining maybe transitions stem from generalizations performed during invariant inference.
as we demonstrate later in the paper these generalizations are error prone when working with a partial limited set of execution traces.
temi is loosely inspired by our earlier work on refining requirements level use case scenarios .
we have previously outlined an early version of temi but the algorithmic details and evaluation in this paper are new.
phase i synthesis of the invariant based mts the method generate initial mts figure synthesizes an invariant based mts.
it first constructs the prospective state space invariantmts states lines based on the set pred of predicates from method preconditions.
for each possible combination of the predicate evaluations line generate invariant mts uses yices to check if that combination in conjunction with object invariants is satisfiable line .
for stackar daikon inferred predicates recall section .
yices rejects as unsatisfiable every predicate combination with p1 false and p2 true.
after determining the valid states generate invariant mts creates transitions between those states the loop in lines .
each transition added in line has a source state that satisfies the appropriate method preconditions and a destination state that satisfies the postconditions similarly to contractor .
the resulting invariant based mts contains a state for every reachable program state and a transition for every invocation sequence that is legal according to the invariants .
figure depicts the invariant based mts for stackar .
although the largest theoretical state space for stackar is24 16states with an additional initial state the generated invariant based mts has only 5states including the initial state .
there are several selftransitions that capture methods that do not change the program state.
by contrast the k tail based algorithms implicitly consider every method to be state changing.
temi s construction of the invariant based mts is conceptually similar to contractor as it uses a predicate based abstraction of the program state.
in contrast to contractor whose predicates are the full method preconditions temi uses the individual clauses that appear in the invariants.
the reason we choose this finer grain abstraction is that the automatically inferred postcondis0s4 s3 s2 s1push?et?
ft?
emp?
tn?
tpn?
et?
ff?
emp?
tn?
tpn?push?
ef?
ff?
tv?
tpv?ef?
ft?
tv?
tpv ?
emp?
tpv?push?
stackar?stackar?
push?emp?
tpv?figure the invariant based stackar mts.
refine invariant mts mts invmts settraces 1currentst invmts initialstate 2for each currentev2traces for each nextst2invmts states ifsmt isconsistent nextst currentev post currentstcurrentev !
mnextst r efine state currentst nextst currentev invmts currentst nextst0 7for each st12invmts refinedst for each st1l !
mst22invmts transitions if9st1l !
rst3remove st1l !
mst2 10for each state state 22invmts refinedst 11where state programst state programst ifst1 outtrans st2 outtrans merge st1 st2 13return invmt s refine state state currentst state nextst event currentev mts invmts 1ifcurrentst nextst require currentstcurrentev !
rnextst 2else addnextst0toinvmts states rename nextst tonextst00 replace currentstcurrentev !
gnextst00with currentstcurrentev !
rnextst0 for each nextst00l !
gotherst ininvmts transitions ifnextst006 otherst addnextst0l !
gotherst toinvmts transitions else add nextst0l !
gnextst0toinvmts transitions figure refining the invariant based mts according to the traces.
tions tend to be more complex than the manually written ones .
for example consider a method postcondition that consists of a set of implication clauses that relate the program state before and after a method invocation .
the states in the temi s invariantbased mts would correspond to the different states prestate prestate n and each state would have a transition to its appropriate next state poststate poststate n. on the other hand contractor s model would have a single state corresponding to all the pre states with nondeterministic transitions to the post states thus resulting in a less precise model.
phase ii refining the invariant based mts temi uses observed trace information to refine the invariant based mts by promoting to required those maybe transitions that correspond to observed invocations.
refine invariant mts in figure describes this refinement algorithm.
in we summarize additional optimizations introduced to improve the scalability of temi as well as extensions that add further information to the inferred models.
we omit their discussion for brevity as they are not part of the core algorithm.
182s0s4 s3 s1 pushet ft tn tpn emp et ff emp tn tpnef ft tv stackarstackars1 et ff emp?
tn tpn tpv emppush s1 s2 push ef?
ff?
tv?
tpvpushet?
ff?
emp?
tn?
tpn?
s3 tpvpush ef?
ft?
tv?tpv emppush empfigure the stackar mts refined with invocation traces.
a direct approach to incorporating trace information into the invariant based mts is to simulate the traces on the mts and promote each traversed maybe transition denoted with ?
on the label to a required transition without ?
.
however this approach can result in imprecisions because states may be visited multiple times and the produced model would not distinguish between the different visits.
this can stitch together a required transition from one trace to a required transition from another trace resulting in an invocation ordering that never occurred.
for example consider the direct refinement of the invariant based mts from figure based on the stackar traces from figure .
the resulting mts allows a spurious sequence in which based on trace push x from an empty stack state s1 to a full stack s3 is followed based on trace by topandpop to a partially full stack s2 .
to avoid such issues refine invariant mts enhances the direct refinement strategy by also refining the visited states the refinement process is captured in lines .
when refine invari antmts visits a state in the invariant based mts it first splits it into two states line where refine state shown in the bottom portion of figure is called .
the first refined state nextst0inrefine state has only one incoming transition which corresponds to the currently processed trace invocation currentev .
the second refined state nextst00 keeps the remaining incoming transitions of the original state.
each state keeps all of the original outgoing transitions and self transitions lines in refine state .
the state splitting enables each state to express different behavior according to the incoming transitions.
for example stackar s mts depicted in figure is obtained by refining the invariant based mts from figure with the traces from figure .
the push x invocation from s5tos6in trace figure splits stackar s invariant based state s3 figure into two new states s0 3ands00 figure .
s0 3is reachable from empty stack states while s00 3is reachable from a partially full stack.
furthermore the transition s0 1push !
rs0 3is promoted to required since it has been observed in the traces.
once the mts is refined according to the traces refine invari antmts uses the newly incorporated required transitions to further improve the model.
first r efine invariant mts removes spurious nondeterministic transitions for each method using a heuristic that if a state has non deterministic transitions on a method and some of those transitions are observed required while others are unobserved maybe then the unobserved transitions can be removed lines because they are likely a product of overly general invariants.
for example stackar s refined mts in figure does not have a maybe transition from s0 3ontopandpop to a partially full stack state s2.
this is because such behavior was never observed.
by contrast a direct transition to an empty stack s0 3topandpop !
rs00 was observed in trace .
this distinction between the refined statesapplication type exec.
libraries stackartester unit test unit test stackar jedit text editor end user stringtokenizer jlgui media player end user stringtokenizer columba e mail client end usersignature socket smtpprotocol jftp file transfer end usersignature sftpconnection jarinstaller packaging end user zipoutputstream dacapo xalan benchmarkperfor numberformatstrmance ingtokenizer test tohtmlstream v oldemort distributedunit tests socketdatabase figure eight applications that exercise the evaluated libraries.
s0 3ands00 3was not present in the original invariant based mts due totopandpop s incomplete postcondition.
.
ev aluation to evaluate the four model inference strategies we used the four respective algorithms to infer models of nine open source libraries.
to generate the execution information necessary for our analysis we exercised the libraries using other readily available open source applications we found on the web.
we then compared the quality of the models inferred by each of the four algorithms.
section .
describes the applications and the libraries our evaluation uses.
section .
explains the setup and goals of our evaluation.
sections .
.
and .
present the evaluation results.
finally section .
addresses the threats to the validity of our findings.
.
subject libraries and applications our nine evaluation libraries span five categories .
data structures datastructures.stackar .
data processing org.apache.xalan.templates.elemnumber.numberformatstringtokenizer to which we will refer as nfst and java.util.stringtokenizer .
authentication and data integrity verification java.security.signature .
data streaming java.util.zip.zipoutputstream and org.apache.xml.serializer.tohtmlstream .
distributed communication and message exchange org.columba.ristretto.smtp.smtpprotocol net.sf.jftp.net.wrappers.sftpconnection and java.net.socket to collect invocation traces for these libraries we used eight opensource applications.
figure describes the applications and the way we ran them to exercise the libraries.
for example we exercised stringtokenizer s functionality by running jedit as an end user who edits and saves text and socket s functionality by running v oldemort s unit tests that involve socket based communication.
we provided all techniques with the same set of traces and inferred invariants as inputs.
the collected traces contained all invocations of the selected classes.
.
evaluation setup this section describes our quality metrics the process for assessing a model s quality based on ground truth models our hypotheses 183s0zipoutput streams1s2 s3putnextentry write closeentry closeclosefigure zipoutputstream s ground truth model.
and our experiments.
.
.
metrics to measure the quality of a model we compare it to a groundtruth model see section .
.
.
we perform this comparison in terms of precision and recall .
precision measures the fraction of one thousand traces generated by the inferred model that are allowed by the ground truth.
recall measures the fraction of one thousand ground truth traces that are allowed by the inferred model suggesting how complete the model is.
since the evaluated models can have infinite traces we restricted the length of the traces to twice the number of transitions in the ground truth model.
.
.
ground truth models evaluating the quality of the inferred models requires a set of ground truth models that represent the libraries legal behavior.
to this end we used the ground truth models that were manually extracted as a part of related work .
we modified those models when we discovered imprecisions that we were able to validate by inspecting the source code and when the models included non public methods.
we removed from the ground truth models all transitions on methods that were never invoked in the collected traces.
this simplification equally impacts the recall of our techniques and of the existing techniques and thus does not affect our conclusions.
meanwhile the precision of the techniques is unaffected as the removed methods are not present in the inferred models.
for libraries without an existing ground truth nfst tohtmlstream andsftpconnection two doctoral students inspected the source code and api documentation and manually constructed the models.
as an example figure depicts the ground truth models for zipoutputstream .
.
.
hypotheses our evaluation tests the following hypotheses hypothesis models inferred using invariants only and trace enhanced invariants strategies are of significantly higher quality as compared to models inferred using traces only and invariant enhanced traces strategies.
hypothesis execution traces can circumvent imprecisions stemming from invariant inference that may be incomplete.
hypothesis invariant filtering is a necessary aspect of invariantsbased dynamic model inference techniques.
.
.
experimental design for each library we inferred seven models traditional k tail and sekt with k2f1 2g optimistic and pessimistic temi and contractor .
the pessimistic temi model removes maybe transitions thus treating unobserved invocations as illegal while the optimistic model retains all transitions.
we do not report results of k tail for k 2because those kvalues led to fewer merges which lowered the recall without notable precision improvement.in the experiments for each library we performed three steps execute applications that use the library to generate traces run the seven inference algorithms on those traces and measure the precision and recall of the inferred models.
the implementation observed traces inferred models and ground truth models are publicly available php?id inference start .
.
inferred model precision and recall this section assesses the quality of the inferred models as compared to the ground truth.
figure shows the precision p and recall r of each algorithm s models.
figure distinguishes the algorithms along two dimensions the algorithms developed fully as part of our research placed in the central portion of the table are separated from the existing algorithms by the two vertical lines the different shadings distinguish implementations of traces only and invariant enhanced traces strategies from the algorithms that implement invariants only and trace enhanced invariants strategies.
next we compare the models precision and recall analyze the reasons for better recall of models inferred via the invariantsonly and trace enhanced invariants strategies and explain the differences between models inferred using those two strategies.
for all libraries except stringtokenizer contractor and temi produce models of superior recall and comparable or better precision than the traditional k tail and sekt algorithms.
for example the k tail models of smtpprotocol allow only a single message to be sent before terminating the connection.
the temi model correctly generalizes the observed behavior and allows multiple messages which improves the recall.
compared with sekt for example the precision of the optimistic temi is lower in the cases where temi either included an erroneous transition or inferred erroneous states due to incomplete invariants.
pessimistic temi does resolve the imprecisions due to erroneous transitions by considering only required transitions.
figure indicates that temi and contractor have significantly higher recall than the k tail based algorithms.
this is because the invariants help to distinguish between those invocations that change program state in turn restricting future invocations and those that do not.
for example tohtmlstream s invariants indicate no restrictions on its method invocations and the contractor model has a single state with a self transition for every method.
in contrast the k tail models capture irrelevant invocation restrictions inferred from the traces.
furthermore the results confirm that while the traces only strategy has high precision on average its complete dependence on execution traces can result in precision lowering spurious merges e.g.
this happened for models of stackar and sftpconnection .
our evaluation results also suggest that temi is slightly to moderately more precise than contractor while having nearlyidentical recall.
the differences in precision stem from the ways these two approaches construct model states and the way temi incorporates the observed invocations.
as discussed in section .
multiple temi states may be logically mapped to a single contractor state the contractor state may have additional precision lowering transitions that do not exist in the temi states.
the difference in precision is especially pronounced for stringtokenizer andsmtpprotocol whose recall contractor improved by up to but at a precision cost of as compared to optimistic temi.
contractor s model of stringtokenizer allowed illegal invocation sequences in which a first invocation ofhasmoretokens returned false but a subsequent invocation returned true.
this occurred because contractor is not always able to precisely capture postconditions that relate post state 184librarytraditional traditional sekt sekt optimistic pessimisticcontractor tail tail tail tail temi temi p r p r p r p r p r p r p r stackar nfst stringtokenizer signature tohtmlstream zipoutputstream smtpprotocol socket sftpconnection na na average figure precision p and recall r comparison of k tail sekt temi and the c ontractor enhanced contractor algorithms.
the average row excludes results for sftpconnection because c ontractor ran out of memory during model generation.
values to pre state values.
for smtpprotocol temi removed unobserved transitions on getstate which remained in the contractor model due to incomplete invariants.
in general the causes behind contractor s imprecision were more varied than those that impacted the recall of temi while temi s recall may deteriorate because of overly restrictive invariants abstracted by contractor contractor s precision may be hampered by incomplete invariants intricate relationships between invariants and invocation dependencies that invariants cannot capture.
we note that while issues such as overly restrictive or incomplete invariants can be mitigated by collecting additional executions invariant complexity and implied invocation dependencies cannot be mitigated in such a way.
our results strongly support hypothesis from section .
utilizing program state information from invariants to create an initial model before potentially augmenting it with information about invocation sequences from the execution traces significantly improves the quality of dynamically inferred models.
our results also suggest that combining program state information with information about invocation sequences from execution traces results in near perfectly precise models as was the case for our invariant enhanced traces sekt and trace enhancedinvariants temi algorithms.
.
sensitivity to invariant quality in the real world the collected execution data may be partial and the results of invariant inference noisy.
model inference s aim is to maintain high precision under noise even a moderate drop in precision could render the produced model useless .
to evaluate the impact of invariant noise we removed random subsets of invariant clauses and measured the resulting precision and recall of the temi and contractor models.
for each library we generated models for each of the cases when and of the invariant clauses are removed.
the results in figure suggest that the precision of pessimistic temi is robust to variations in invariant quality optimistic temi models outperform contractor by yielding higher precision and recall noisy environments require enhancing invariants with trace information and decreased invariant quality negatively affects contractor s performance.
we elaborate on each point next.
.
invariant incompleteness did not affect the near perfectly precise pessimistic temi models.
this confirms that the mts refinement procedure recall section .
appropriately introduces the trace information even when the initial model is imperfect.
in particular pessimistic temi models have higher precisionthan optimistic temi and contractor models while also having higher recall than comparably precise k tail models which are not affected by noisy invariants see figure .
.
when faced with noisy invariants the optimistic temi models outperform c ontractor in the average case by in both precision and recall.
the reasons were twofold incomplete invariants add erroneous nondeterministic transitions the degree of nondeterminism is higher in contractor models leading to lower precision.
incomplete invariants cause temi s refinement procedure to correctly split states and subsequently remove the undesired maybe transitions only from the appropriate state.
.
in the average case noisy invariants caused the temi models precision to drop from figure to figure the precision dropped by and in the two extreme cases stackar andsocket .
a reason for the extremes is that the states in temi s socket model can have a number of incorrect nondeterministic transitions that confirm the connection isconnected true before it has been established.
this highlights the crucial role of augmenting invariants only models with trace information isconnected never returns this result in the actual traces and the erroneous transitions do not exist in the pessimistic temi models.
.
incomplete invariants affect performance making contrac tor less efficient due to a higher number of allowed program states.
this in turn results in a higher number of smt queries that cause the scalability problems further discussed in section .
.
we conclude that invocation trace information is necessary to circumvent potential imprecisions in the invariants only models.
hypothesis holds for trace enhanced invariants models as less reliable inferred program invariant information is augmented with information about invocation sequences from the execution traces.
while lower quality invariants reduce the precision of the maybe transitions the pessimistic temi models remained almost perfectly precise with unchanged recall which makes pessimistic temi the most appropriate choice when an engineer is running an unfamiliar system to infer a model of a poorly documented library.
.
impact of invariant filtering as noted earlier the high quality of invariants only models is critically dependent on having meaningful and manageable invariants as inputs.
this is best described using the differences between the original contractor algorithm and contractor our enhancement of contractor with invariant filters recall section .
.
figure outlines the model quality when the enhancements are notapplied.
compared to contractor when the input invari185libraryoptimistic optimistic pessimisticcontractor optimistic pessimisticcontractor temi temi temi temi temi full invariant set invariants removed invariants removed p r p r p r p r p r p r p r stackar nfst stringtokenizer signature tohtmlstream zipoutputstream smtpprotocol socket na na na na average figure precision p and recall r comparison of temi and the c ontractor algorithms in a noisy environment when some of the invariants are removed .
temi is more robust to the noise with almost perfectly precise pessimistic temi while delivering slightly higher recall on average.
the average excludes results for socket because c ontractor ran out of memory during model generation.
ants are not filtered no invariant filtering in figure a modest average increase in precision comes at the expense of a sizable drop in recall up to in the case of smtpprotocol .
when the different method return points are not handled separately no method distinction the resulting models are less precise on average although the average recall increases by .
omitting our enhancements also accentuated contractor s scalability problems denoted as navalues discussed next.
each contractor smt query includes the invariants of all methods and such a query is generated for every possible combination of methods invariant evaluations recall section .
.
hence contractor queries are longer and more resource consuming than temi s queries.
in the case of sftpconnection which has methods with invariant clauses the smt solver runs out of memory figure this happens in five additional cases when our enhancements are not applied figure as well as the one case with noisy invariants figure .
since contractor is built using the combination of python and c the memory is allocated by the operating system which kills the smt solver s process once the memory consumption makes the system unstable.
overall our evaluation results confirm hypothesis as invariant filters that keep only a limited set of relevant invariant types have shown to be crucial to enhancing the scalability as well as the quality of techniques that implement invariants only and trace enhanced invariants strategies.
.
threats to validity we now outline the threats to our evaluation s validity and discuss our mitigation strategies.
librarycontractor no invariant no method filtering distinction p r p r p r stackar nfst stringtokenizer signature na na tohtmlstream na na zipoutputstream na na na na smtpprotocol na na socket figure precision p and recall r of contractor models with and without sekt and temi specific invariant filters.ground truth bias.
the ground truth models were in part manually constructed.
this may make them biased to the specifier s expertise.
to mitigate this threat we used the publicly available ground truths from other researchers and modified them only if we were able to validate the modifications by inspecting the source code.
we also made multiple iterations over the resulting models with two specifiers.
subject libraries and applications.
the selection of libraries and applications that invoke them may bias the evaluation results.
for instance models of a well known library may not be representative of dynamically inferred models in general.
similarly mature applications may be more careful in using a library s functionality.
to this end we selected libraries of different types and popularity e.g.
well documented java libraries vs. less widely known nfst .
we also used applications from several different domains and of different maturities popularities and sizes e.g.
widely used v oldemort vs. less popular jarinstaller .
finally we had to address the bias stemming from inferring models based on traces obtained from unit and integration tests.
hence we collected some of the utilized traces by executing open source applications in ways that an end user would use them to explore the available features.
metrics.
there are multiple ways of comparing the generated models with the corresponding ground truth models e.g.
recall and precision of the simulated traces vs. graph comparison which could potentially yield different results.
our mitigation strategy used metrics that have been proposed and adopted by the research community and are consistent with our goal of comparing model behavior not structural similarity.
.
our findings impact while studying inferred model quality is an interesting exercise on its own our findings which confirm the high quality and robustness of trace enhanced invariants models should motivate further application of model inference in practice.
below we briefly elaborate on the utility of having the different types of generated models and discuss the potential impact of our higher quality trace enhancedinvariants models on several development activities.
model quality.
the high overall quality of the inferred models can aid a variety of software development tasks including api understanding debugging test generation and runtime fault detection .
for example during debugging a programmer can analyze if a given library is invoked as expected.
similarly an inferred trace enhanced invariants model that exhibits high recall i.e.
that is complete can help to detect invocations that violate the library s protocol while avoiding spurious warnings.
186required vs. maybe transitions.
the temi models contain observed required transitions and unobserved maybe transitions.
this dichotomy is useful for several reasons.
for example as discussed in section .
when the available executions are not comprehensive the resulting invariants can be noisy.
in such cases a developer can rely on temi models due to almost perfect precision of the required transitions.
in addition the required mts transitions can be augmented with frequencies of method invocations.
this can benefit recommender systems in prioritizing examples by selecting those that commonly occur in actual executions.
program state information.
while our evaluation focused on the invocation sequences our models also relate the model states to the internal program states.
hence instead of having to gain a comprehensive understanding of a library s source code or to strictly rely on the available api level documentation a programmer can use the state information to peek inside the library s implementation.
similarly tools that detect protocol violations e.g.
may provide more informative warnings by referring to program state.
trace oriented models.
the invariant enhanced traces models can be more appropriate for development tasks that require tracespecific information despite their significantly lower recall than that of the temi models.
for example detailed analysis of how an unfamiliar program communicates with a library requires compact yet accurate representation of the traces themselves as opposed to a representation of the library s full api protocol.
the sekt algorithm produces such models while the k tail algorithm is less reliable due to its sole dependence on execution traces.
.
related work program invariants have been used to directly synthesize fsm models and to augment the k tail algorithm with transition invariants .
as noted in sections .
and .
temi is more appropriate than contractor for dynamic specification mining because it has higher precision it is more resilient to invariant noise and unlike contractor it distinguishes between observed and unobserved invocations.
by contrast starting from the observed executions and using daikon to infer transition invariants results in other imprecisions as discussed in section .
.
the k tail algorithm serves as a basis for many fsm inference techniques from invocation traces .
these algorithms extend k tail to improve its precision or recall build larger frameworks with k tail as the inference algorithm and enhance the models with information about invocation probabilities and program state and method parameters .
additional merges can make the models more compact while stricter merging conditions based on pairwise sequencing invariants can improve precision .
in general these approaches recall is only as good as the traditional tail and for our evaluation libraries their precision cannot surpass the precision of sekt.
synoptic csight and perfume use the cegar approach to create a coarse initial model and then refine it using counterexamples that falsify temporal invariants.
invarimint presents a declarative specification language for expressing model inference algorithms and improves the efficiency of algorithms but neither their precision nor recall.
there are other ways to aid development tasks than inferring models such as detecting method invocation patterns and inter object sequence charts .
these patterns can detect code anomalies .
scenario based views of a system s behavior such as parametrized and symbolic sequence charts facilitate understanding of a system s runtime interactions.
while we used both contractor and temi in combination with invariants inferred by daikon invariants only and trace enhanced invariants techniques can be adapted to work with other invariant inference techniques.
examples of such techniques include techniques that combine inference with symbolic program execution and enhance it by using simple manually written initial invariants or manually written relations between methods .
static and hybrid techniques provide two alternatives to specification mining based strictly on invocation traces.
shoham et al.
infer from client side code fsm models that over approximate the actual invocation sequences.
by contrast our algorithms work on traces generated from multiple parts of the code and potentially from multiple applications.
de caso et al.
statically analyze c programs for invariants and use contractor to create models that allow more behavior than the ground truth.
adabu infers the concrete program state by statically finding side effect free invocations and combines that information with test case executions.
while the concrete program state is also abstracted using predicates these predicates are predetermined and do not relate multiple variables e.g.
adabu abstracts integers only as negative zero or positive .
together with test case generation adabu can improve model quality enabling code verification .
however this requires tailored unit test executions.
compared to temi adabu uses limited invariants and infers one model per runtime object which hampers its applicability to rich classes and executions that involve many objects of the same type.
whaley et al.
create a separate submodel for each field of a class analyzing if a method modifies a given field and creating a tail model that combines static and dynamic information about method invocations with respect to that field.
unlike temi this approach requires static analysis creates multiple submodels and considers only one step history tail limiting its applicability.
.
conclusions using a software library is a non trivial task hampered by a lack of appropriate documentation for describing the required but oftenimplicit invocation protocols.
this paper studied how different model inference strategies perform when applied to libraries whose behavior is exercised using real software.
the recent scalability improvements of the dynamic inference techniques have resolved many of the obstacles to their application in the real world these techniques are now able to handle large sets of execution traces and large sets of runtime data values .
however there are still noticeable gaps in understanding the quality of the models produced by model inference techniques.
as part of this research we enhanced one existing technique and presented two novel algorithms sekt and temi that combine execution traces with automatically inferred program state invariants.
our evaluation demonstrates that invariants only and trace enhanced invariants significantly outperform the traces only and invariant enhanced traces strategies.
trace enhanced invariants models produced by temi also exhibit superior recall while being robust to noisy inputs.
our results highlight the significant impact of using program state information to infer high quality models.
in addition our research highlights the benefits of combining different types of runtime information to enhance inferred models and in turn to effectively support development tasks.
in our future work we plan to study whether this combination can enhance model inference for concurrent libraries and multi object protocols .
.