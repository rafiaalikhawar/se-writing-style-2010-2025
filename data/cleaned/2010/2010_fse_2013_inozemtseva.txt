using fault history to improve mutation reduction laura inozemtseva university of waterloo waterloo on canada lminozem uwaterloo.cahadi hemmati university of manitoba winnipeg mb canada hemmati cs.umanitoba.careid holmes university of waterloo waterloo on canada rtholmes uwaterloo.ca abstract mutation testing can be used to measure test suite quality in two ways by treating the kill score as a quality metric or by treating each surviving non equivalent mutant as an indicator of an inadequacy in the test suite.
the first technique relies on the assumption that the mutation score is highly correlated with the suite s real fault detection rate which is not well supported by the literature.
the second technique relies only on the weaker assumption that the interesting mutants i.e.
the ones that indicate an inadequacy in the suite are in the set of surviving mutants.
using the second technique also makes improving the suite straightforward.
unfortunately mutation testing has a performance problem.
at least part of the test suite must be run on every mutant meaning mutation testing can be too slow for practical use.
previous work has addressed this by reducing the number of mutants to evaluate in various ways including selecting a random subset of them.
however reducing the set ofmutantsbyrandomreductionissuboptimalfordevelopers using the second technique described above since random reduction will eliminate many of the interesting mutants.
we propose a new reduction method that supports the use of the second technique by reducing the set of mutants to those generated by altering files that have contained many faults in the past.
we performed a pilot study that suggests that this reduction method preferentially chooses mutants that will survive mutation testing that is it preserves a greater number of interesting mutants than random reduction does.
categories and subject descriptors d. .
testing and debugging general terms experimentation measurement performance keywords mutation testing mutant reduction fault history test suite quality permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
esec fse august saint petersburg russia copyright acm ... .
.
.
introduction mutation testing offers software developers a way to evaluate the quality of their test suite.
in mutation testing mutants are created by making small syntactic changes to a program which we will refer to as the system under test sut .
for example a mutant could be created by modifying a constant negating a branch condition or removing a method call.
the resulting mutant may produce the same output as the original sut in which case it is called an equivalent mutant .
as or after the mutants are generated the program s test suite is run on each one.
if the suite fails it is said to have killedthe mutant.
the number of mutants the suite kills divided by the total number of non equivalen t mutants is the suite s kill score .
equivalent mutants are excluded because they cannot by definition be detected by an automated test.
there are two ways a developer can use the output of mutation testing technique .the developer treats the kill score as a quality metric where higher is better.
this technique assumes that the mutant kill score is correlated with the suite s actual fault detection ability.
technique .the developer ignores the kill score and focuses on the set of surviving mutants.
each non equivalen t surviving mutant indicates an inadequacy in the test suite that the developer may want to address.
the downside of technique is the built in assumption that the mutation score is highly correlated with the suite s real fault detection rate.
this assumption has only been tested in two studies both of which used a single small subject program.
it is therefore not clear that it holds in general.
this technique also does not help the developer write new tests there is no obvious way to use the mutation score to guide improvements to the suite.
technique by contrast is less reliant on the assumption that the mutation score is highly correlated with the suite s real fault detection rate.
treating a surviving nonequivalent mutant as an indicator of an inadequacy in the test suite does assume that the mutant is at least somewhat representative of a real fault.
however it does not require making any assumptions about the killed mutants we merely assume that the interesting mutants will be found in the set of surviving mutants.
trivial mutants which are one of the worries of mutation testing will be killed easily and the developer will not need to consider them.
moreover the extra context the developer gets from manually investigating the mutants makes this technique much less reliant on there being a strong correlation between the killscore and the fault detection ability of the suite.
this technique also makes improving the suite straightforward the developer simply writes tests that can kill the interesting mutants.
these advantages make technique the preferable approach.
unfortunately mutation testing has a drawback that applies to both techniques.
since it requires generating tens of thousands of mutants for a typical sut and at least part of the test suite must be executed for each mutant to determine if it can be killed mutation testing can be too slow for practical use.
it is possible to speed up mutation testing with techniques like changing the definition of killing a mutant evaluating mutants1in parallel or computing the results incrementally as the program evolves.
however as long as the same number of mutants are being evaluated there is a limit to how much speedup can be achieved.
in particular even though mutation testing is embarrassingly parallel parallelization is insufficient on its own because of the large number of mutants.
as we will describe in section previous studies have explored improving the performance of mutation testing through mutant reduction methods.
these studies either used fewer mutation operators and thus generated fewer mutants or selected a random subset of the generated mutants to evaluate.
while these approaches may be acceptable for a developer using technique they are suboptimal for a developer using technique because they will eliminate many mutants that would survive if they were evaluated.
each of these mutants indicates an inadequacy in the test suite so eliminating them prevents the developer from identifying those inadequacies.
it would be preferable to reduce the mutant set in a way that preserves as many interesting mutants as possible.
we propose a novel reduction method that supports the use of technique .
more precisely we propose evaluating only the faulty file mutants or mutants that are generated by altering a file that has contained many faults in the past.
this reduction method has three desirable characteristics .improves performance since previous work has shown that a small number of classes in an objectoriented program contain most of the faults and java programs typically have one class per file this methodwillgreatlyreducethenumberofmutantsthat need to be evaluated improving performance.
.focuses developer effort since the number of faults that have been found in a file in the past is a good predictor of the number of faults that will be found in the file in the future focusing the developer s effort on the faulty files and the interesting mutants that are generated from them is likely to be a good use of the developer s time.
.supports the use of technique sincefaultyfiles by definition are associated with many of the faults that were found in the program we hypothesized that faulty file mutants would be more likely to survive mutation testing.
this means that our reduction method would eliminate fewer interesting mutants than random reduction supporting the use of technique .
1we use the phrase evaluate a mutant to refer to running the program s test suite on the mutant version of the program to determine if the suite can kill the mutant.
2note that the reduction is done before the mutants are evaluated there would be no performance benefit otherwise.we explored the validity of the third reason in a pilot study that we will describe in section .
our results suggest that our reduction method supports the use of technique by preferentially choosing mutants that will survive mutation testing.
section describes the full study we plan to perform to confirm and extend these results.
section indicates our desired feedback and section concludes the paper.
.
related work previous attempts to speed up mutation testing have used the following four approaches .
weakening the definition of killing a mutant .
accelerating the testing process by for instance evaluating mutants in parallel or adding compiler support for mutation testing e.g.
.
computing the mutation testing results incrementally and .
selecting a subset of the mutants to evaluate .
our approach is complementary to the first three.
for example a developer could reduce the set of mutants using our method and then evaluate the remaining mutants in parallel.
the fourth approach is the one we use so we describe these studies in more detail.
in wong and mathur proposed reducing the set of mutants by randomly selecting a subset of them to evaluate.
they found that the number of mutants could be reduced significantly with little impact on the results.
later work focused on selective mutation or reducing the number of mutants by reducing the number of mutation operators used to generate the mutants.
specifically in offutt et al.
reduced the set of operators used by mothra a mutation tool for fortran programs to operators and showed that there was little change in the results.
in barbosa et al.
developed guidelines for the determination of a sufficient set of mutation operators.
in namin et al.
used variable reduction to identify key mutation operators for the c language.
finally in zhang et al.
compared random reduction and selective mutation.
they found that operator based mutation selection is not superior to random selection.
.
novelty of the idea the single most related paper by the same authors is which uses mutation testing to explore the relationship between a test suite s size its coverage and its fault detectio n effectiveness.
it does not study the practical aspects of mutation testing including efficiency at all.
thesinglemostrelatedpaperbyotherresearchersiswong and mathur s work since they also reduce the set of mutants by selecting a subset to evaluate.
unlike them we do not select the subset randomly.
while random selection is simple it is suboptimal for developers using technique .
the other studies we described used operator based reduction.
while useful this technique has limits modern mutation tools such as pit3use a small number of operatorstobeginwith 10inpit scase soitisunlikelythatthe operator sets can be reduced much further.
moreover eliminating whole classes of mutants may eliminate the mutants that would have survived mutation testing.
number of bugs associated with a filecount of files figure a histogram of the number of bug ids associated with java files from apache poi.
the x axis gives the number of bug ids while the yaxis gives the number of files that are associated with a specific number of bug ids.
.
.
.
.
.
.
.
.
.
.
percentage of random mutants survivingpercentage of faulty mutants surviving suite size figure the relationship between the fraction of randomly selected mutants that survive pr and the fraction of faulty mutants that survive pf for test suites of various size.
to the best of our knowledge this study is the first attempt to reduce the number of mutants in a non random way without changing the mutation operators making it a novel approach to improving the performance of mutation testing.
we summarize the new idea as follows not all mutants are equal.
evaluating only faultyfile mutants will improve the performance of mutation testing as random mutant selection does but will preserve a greater proportion of interesting mutants.
.
pilot study the goal of the pilot study was to determine if the faultyfile reduction method preferentially selects mutants that will survive mutation testing.
we began by choosing a subject program apache poi4 the percentage of suites that preferentially choose mutants that would survive i.e.
the percentage above the line pf pr grouped by suite size.
size of points above line .
.
.
.
.
.
all sizes .
an open source api for microsoft office documents that contains approximately source lines of java code.
using standard techniques we combined information from poi s version control repository and its bug tracker to identify historically faulty files.
as figure shows the majority of the java files in the program of are associated with zero or one bug ids.
six files are associated with more than bug ids these are not shown in the figure for space reasons.
two of the six files are part of the regression test suite so it is not surprising that they are associated with a large number of past faults.
we ignored these two files since test files are not mutated and considered only the remaining four faulty files.
once we had identified the faulty files we used the mutation tool pit to perform standard mutation testing on apache poi.
pit generated mutants for poi of these or were made by mutating one of the four faulty files that we identified.
this verifies that our reduction technique greatly decreases the number of mutants that need to be evaluated.
next we compared our reduction method to random reduction as follows.
for s we made test suites of size sby randomly selecting test methods without replacement from apache poi s full suite.
inotherwords wecreatedatotalof6 000randomtestsuites ofvaryingsize.
foreachsuite t weranthesuiteonthesetof faulty file mutants to determine the percentage of mutants that survived pf.
note that we include equivalent mutants in the set of surviving mutants.
we then selected mutants randomly from the that pit generated and ran ton the random mutants to determine the percentage of mutants that survived pr.
figure shows the results.
each point in the figure represents pfandprfor one test suite.
if our reduction method did not preferentially choose mutants that would survive we would expect the points to be equally distributed above and below the line pf pr.
instead we see that the points tend to lie above this line.
specifically of the test suites or have pf pr.
this meansthatfor74 ofthesuites moremutantssurvivewhen we use the faulty file reduction method than when we use the random reduction method.
we break down this result by suite size in table .
as the table shows the percentage of suites above the pf prline initially drops as suite size increases but rises to for the method suites.
5the threshold of bug ids was set arbitrarily based on manualinspectionofthehistogram wewillevaluatealternative automated methods of choosing an appropriate threshold in our full study.finding our current results suggest that our reduction method preferentially chooses mutants that will survive mutation testing.
.
planned full study our full study will do the following confirm the findings of our pilot study by extending it to more test subjects confirm the performance improvement by measuring runtime for both standard and faulty file mutation testing explore alternate methods of predicting which mutants will survive since fault data may not always be available and explore other ways of choosing a threshold for faulty files.
in addition to extending the pilot study we are interested in exploring how this reduction method can be used in higher order mutation testing where the performance issue becomes even more pressing.
.
desired feedback though our pilot study found that pfwas greater than pr for of suites we had hoped for a more substantial difference since we can expect approximately of suites to havepf prby chance.
we are considering other reduction methods that may produce a greater difference and welcome anysuggestionsregardingalternatereductionstrategies.
we also want to explore why the percentage varied with suite size and invite discussion of this topic.
.
conclusion mutation testing can be too slow for practical use.
one way to improve performance is to reduce the number of mutants to be evaluated.
we proposed a new non random mutant reduction method evaluating only the faulty file mutants or mutants generated by altering files that are known to have contained many faults in the past.
our pilot study suggests that this method preferentially chooses mutants that will survive mutation testing.
these mutants are interesting to developers because they indicate possible inadequacies in the test suite.
the reduction technique also greatly decreases the amount of time required to evaluate the mutants making mutation testing more practical.
we plan to do a full study that confirms and extends these results.
.