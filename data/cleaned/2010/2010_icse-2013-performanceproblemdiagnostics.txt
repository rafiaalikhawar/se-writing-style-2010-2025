see discussions st ats and author pr ofiles f or this public ation at .researchgate.ne t public ation supporting swift reaction automatically uncovering performance problems by systematic experiments conf erence paper in proceedings int ernational conf erence on softw are engineering may .
ic se.
.
citations 55reads author s alexander wert novatec consulting gmbh publica tions citations see profile jens happe chrono24 publica tions citations see profile lucia happe karlsruhe instit ute of t echnolog y publica tions citations see profile all c ontent f ollo wing this p age was uplo aded b y jens happe on may .
the user has r equest ed enhanc ement of the do wnlo aded file.supporting swift reaction automatically uncovering performance problems by systematic experiments alexander wert karlsruhe institute of technology am fasanengarten karlsruhe germany alexander.wert kit.edujens happe sap research vincenz priessnitz str.
karlsruhe germany jens.happe sap.comlucia happe karlsruhe institute of technology am fasanengarten karlsruhe germany lucia.kapova kit.edu abstract performance problems pose a significant risk to software vendors.
if left undetected they can lead to lost customers increased operational costs and damaged reputation.
despite all efforts software engineers cannot fully prevent performance problems being introduced into an application.
detecting and resolving such problems as early as possible with minimal effort is still an open challenge in software performance engineering.
in this paper we present a novel approach for performance problem diagnostics ppd that systematically searches for well known performance problems also called performance antipatterns within an application.
ppd automatically isolates the problem s root cause hence facilitating problem solving.
we applied ppd to a well established transactional web e commerce benchmark tpc w in two deployment scenarios.
ppd automatically identified four performance problems in the benchmark implementation and its deployment environment.
by fixing the problems we increased the maximum throughput of the benchmark from requests per second to more than .
index terms performance problem detection measurement i. i ntroduction the performance of an application is highly visible to end users and thus crucial for its success.
response times throughput and resource consumption affect conversion rates1 user satisfaction and operational costs.
however performance problems are usually difficult to detect and even harder to reproduce.
applying systematic approaches e.g.
software performance engineering spe requires specific knowledge and significant expertise.
as a consequence most performance and scalability questions are postponed to the end of the development process fix it later approach .
problems introduced early in the development process are identified late and thus expensive to fix as they can be disproportionally disruptive to an application s implementation and architecture.
as examined by boehm costs escalate as problems are discovered in later development phases.
an example of cost escalation has been given by nasa fixing a requirements phase error during design increases repair costs three to eight times.
during integration fault removal becomes 1conversion rate is the fraction of visitors of a website who become customers.to times more expensive.
costs explode by to times for errors found during operation.
even though these numbers may be different in other contexts the tendency can be expected to be the same.
therefore it s vital to identify performance problems as early as possible.
however slow performance low throughput high response times or high resource consumption can have various causes in an application architecture implementation or deployment environment.
without sufficient expertise it is hard to identify the actual cause of a problem.
software engineers need to know typical performance problems that can occur in their application.
for each problem they must know where and how to measure in order to get the necessary data without distorting measurements.
in many cases the necessary performance metrics cannot be collected.
these will lead to incomplete and noisy measurement data which in turn make it even harder to draw the right conclusions.
existing approaches try to identify performance problems based on software architectures load tests or runtime data .
while analyzing the architecture can identify potential problems early it is limited to a very high level of abstraction.
many causes of performance problems are not reflected in an early architecture and thus will be missed in such an analysis.
load tests take into account all effects of the implementation but are focused on specific scenarios like identification of resource bottlenecks.
they do not provide a goal driven search for performance problems in the application s implementation logic.
approaches using runtime data to detect and diagnose performance problems can operate with real data but should only be a last resort.
problems are detected way too late to be solved efficiently.
in this paper we introduce a novel performance problem diagnostics ppd that automatically identifies performance problems in an application and diagnoses their root causes.
once software engineers specified a usage profile for their application and setup a test system ppd can automatically search for known performance problems.
since ppd encapsulates knowledge about typical performance problems for example performance antipatterns only little per formance engineering expertise is required for its usage.
ppd combines search techniques that narrow down the scope of the problem based on a decision tree with systematic experiments.
the combination of both allows efficiently uncovering performance problems and their root causes that are otherwise hard to tackle.
in its current state ppd is tailored for the diagnosis of performance problems in java based three tier enterprise applications.
for this purpose ppd requires a representative usage profile of the system i.e.
a load driver and test system that resembles the actual setup.
to validate ppd we applied it to an established implementation of the tpc w industry benchmark a javabased three tier enterprise application.
we deployed the benchmark in two different test environments.
ppd identified four performance problems in the benchmark implementation the web server the database and the infrastructure.
solving these problems increased the maximal throughput of the benchmark from requests per second to more than .
overall we make the following contributions we introduce a novel approach for performance problem detection and root cause analysis called performance problem diagnostics .
ppd systematically searches for known performance problems cf.
in three tier enterprise applications.
once a problem has been found ppd isolates its root causes as far as possible.
we structure a large set of known performance problems in a novel performance problem hierarchy .
to guide ppd s search the hierarchy starts from very general problems or symptoms .
each further level refines the problems down to root causes.
the hierarchy allows systematically excluding classes of problems and focusing on the most relevant ones.
we define detection strategies for twelve performance problems in the hierarchy.
the strategies are based on goal oriented experiments tailored to trigger a specific problem.
based on the results heuristics can decide if a problem is assumed to be present and refine the search.
for each performance problem we investigated and compared different heuristics for detecting the problems see section iii .
we chose those heuristics that minimize false positives and false negatives.
we evaluated our approach in two steps.
first we determined the detection strategies that are most likely to find a performance problem see section iii .
for this purpose we evaluated the accuracy of each detection strategy based on ten reference scenarios .
each scenario contains different performance problems which have been injected into a test application.
second we evaluated if ppd can detect performance problems in real enterprise applications see section iv .
ppd successfully identified four performance problems in the tpc w benchmark which significantly limited the maximal throughput.
in the following section we introduce the main concepts of our approach.ii.
a utomatic performance problem diagnostics the core idea of our performance problem diagnostics ppd is based on the observations that i particular performance problems share common symptoms and ii many performance problems described in the literature are defined by a particular set of root causes.
based on these observations we create a hierarchical structure of performance problems their symptoms and their root causes that simplifies the detection and diagnostics significantly section ii a .
the hierarchy is based on performance antipatterns known in the literature .
to detect performance problems and diagnose their root cause we execute a series of systematic experiments that first test for symptoms and then search for more specific performance problems and their root cause section ii b .
in the following we introduce the idea of both concepts.
a detailed description follows in section iii.
a. performance problem hierarchy figure shows an excerpt of the hierarchical structure of performance problems.
an extended performance problem hierarchy for a large set of the performance problems known in literature can be found on our website .
the hierarchy is structured in categories symptoms performance problems and root causes.
the category occurrences of high response times in figure a groups common symptoms for the performance problems high overhead varying response times unbalanced processing and dispensable computations .
symptoms represent the starting point for the performance problem diagnostics.
they combine common characteristics of a set of performance problems.
each symptom is refined by more specific performance problems that further limit the set of possible root causes.
occurrences of high response times high overhead varying response times unbalanced processing dispensable computations a symptoms of known performance problems.
varying response times the ramp dormant