does adding manpower also affect quality?
an empirical longitudinal analysisandrew meneely north carolina state university oval drive eb2 box raleigh north carolina usa apmeneel ncsu.edu pete rotella cisco systems inc. kit creek rd.
bldg.
research triangle park nc protella cisco.com laurie williams north carolina state university oval drive eb2 box raleigh north carolina usa lawilli3 ncsu.edu abstract with each new developer to a software development team comes a greater challenge to manage the communication coordination and knowledge transfer amongst teammates.
fred brooks discusses this challenge in the mythical man month b y a r g u i n g that rapid team expansion can lead to a complex team organization structure.
while brooks focuses on productivity loss as the negative outcome poor product quality is also a substantial concern.
but if team expansion is unavoidable can any quality impacts be mitigated?
our objective is to guide software engineering managers by empirically analyzing the effects of team size expansion and structure on product quality.
we performed an empirical longitudinal case study of a large cisco networking product over a five year history.
over that time the team underwent periods of no expansion steady expansion and accelerated expansion.
using team level metrics we quantified characteristics of team expansion including team size expansion rate expansion acceleration and modularity with respect to department designations.
we examined statistical correlations between our monthly team level metrics and monthly product level metrics.
our results indicate that increased team size and linear growth are correlated with later periods of better p r o d u c t quality.
however periods of accelerated team expansion are correlated with later periods of reduced s o f t w a r e q u a l i t y .
furthermore our linear regression prediction model based on team metrics was able to predict the product s post release failure rate within a prediction interval for out of months.
our analysis provides insight f o r p r o j e c t m a n a g e r s i n t o h o w t h e expansion of development teams can impact product quality.
categories and subject descriptors d. .
metrics process metrics product metrics.
general terms measurement human factors keywords longitudinal analysis team expansion metric modularity brooks law developer linear regression .
introduction with each new developer to a software development team comes a greater challenge to manage the c o m m u n i c a t i o n c o o r d i n a t i o n and knowledge transfer amongst teammates.
lack of team cohesion miscommunications and misguided effort can a l l l e a d to problems in the software product.
following a similar line of reasoning fred brooks discusses the challenge of team expansion directly in his widely known book the mythical man month ...training cannot be partitioned so this part of the added effort varies linearly with the number of workers.
the added effort of communicating may fully counteract the division of the original task.
adding manpower to a late project makes it later.
the latter quote is known as brooks law.
while brooks was specifically discussing effort estimation and productivity one could apply a similar argument to software quality.
too many new developers in a short period of time can potentially lead to problems such as inconsistent implementation or poor system integration.
but is team expansion an unavoidably high risk?
or can successful development teams undergo healthy growth as the product progresses?
risk management practices often account for new teammates so teams can plan ahead for some developer turnover and handle it gracefully.
furthermore the structure of the team as it expands can also affect software quality.
brooks describes software development as an exercise in complex interrelationships and describes the development team as a socio technical network of communication and coordination a structure since defined as a developer network .
when the team organization becomes too complex collaboration suffers.
for instance developers may choose to only collaborate on code within their own department and avoid developing across departments despite the advantage of having the added perspective from other departments.
therefore if team expansion is a high risk what are the elements of team expansion that can be mitigated?
an analysis of software quality inspired by brooks law must take into account team size how fast the team expands and team structure over time.
our research objective is to guide software engineering managers during periods of team expansion by empirically analyzing the effects of team size expansion and structure on product quality.
we examined statistical correlations between periods of team expansion and the observed effects on product quality in a large cisco networking product over a five year period.
we measured permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
fse september szeged hungary.
copyright acm xxx x xxxx xxxx ... .
team size expansion rate expansion acceleration and modularity of the team with respect to departments.
our data came from the version control logs the defect tracking system historical records from the human resources department and the failure tracking database.
the contributions of this paper are statistically significant associations that help researchers and practitioners better understand the risks of expanding a team and a predictive model that can help the practitioners of our case study to accurately predict upcoming product quality measurements.
the rest of this paper i s o r g a n i z e d a s f o l l o w s .
s e c t i o n s a n d cover background and related work on analyzing large software development teams and software quality.
section describes our study design and the metrics we used to analyze team expansion and structure.
sections and present the case study and the results of the empirical analysis and its limitations.
section discusses how our study applies to brooks law and product quality.
lastly sections and discuss future work and a summary of the study.
.
background in this section we define various terms relating to software quality and network analysis.
.
quality and metric terminology in software reliability a failure i s t h e i n a b i l i t y o f a s o f t w a r e system or component to perform its required functions within specified performance requirements .
a fault is an incorrect step process or data definition in a computer program.
note a fault if encountered may cause a failure .
we use the term team level metric to indicate that the metric is collected as one measurement f o r t h e e n t i r e t e a m f o r a g i v e n period of time.
also we use the term product level m e t r i c t o indicate that the metric is collected as one measurement of the product s overall quality for a given period of time.
.
network analysis our analysis involves quantifying measures of networks.
in this section we provide background with regard to network analysis.
network analysis is the study of characterizing and quantifying network structures represented by graphs .
in network analysis vertices of a graph are called nodes and edges are the names for connections between exactly two nodes.
the degree of a node is defined as the number of neighboring nodes that a node has.
to analyze the structure of a team in terms of company organization we use the modularity metric .
modularity is a measure of how the network is spread with respect to organization.
modularity requires a method of logically grouping nodes together called partitioning .
by definition each node is placed in exactly one partition.
the modularity value is computed based on edges where both nodes are in the same partition and the number of edges that cross partitions.
modularity is computed using the following pseudo code in figure .
figure .
pseudo code for computing modularity.
the terms involving the nodes degrees are designed to account for a random re wiring of network as a way to mitigate potentially missing or mistaken edges in the network .
the output of the modularity measure is a decimal value between .
and .
.
a value near .
highly modular indicates that most of the edges are within the partitions a value near .
anti modular indicates that most of the edges cross boundaries and are not within partitions a value near zero not modular indicates that edges are crossing partitions as often as staying within partitions.
.
related work the topic of measuring the structure of development teams have been examined in several recent empirical studies.
all of the studies however examine file level metrics that reflect the overall team.
none of the studies use team level metrics nor examined the relationship between team level metrics and product level metrics.
many of the studies make use of the developer network which we formally define in section .
.
the closest study to ours was a file level analysis on an at t product performed by weyuker et al.
.
the researchers began their project with a predictive model that could identify of the system s faults in of the source code files.
using the version control logs the researchers counted the number of committers to a source code file.
in their case study adding the number of developers metric to their predictive model only provided a modest improvement over previous predictive results finding and of the faults on average.
however they found that files changed by additional developers were more likely to have faults.
they concluded that too many cooks can spoil the broth although which is consistent with the argument brooks presents.
meneely et al.
examined the relationship between developer activity metrics and reliability.
the empirical case study examined three major releases of a large proprietary networking product.
the authors used developer centrality metrics from a developer network to examine whether source code files are more likely to have failures if they were changed by developers who are peripheral to the network.
the authors formed a model that included metrics of developer centrality recent code churn the degree to which a file was changed recently and lines of code to predict failures from one release to the next.
their model s input graph g with nodes in set v and with e edges partitions p1 p2 ... pn contain nodes in v algorithm modularity .
for each partition pi for each node v1 v2 in pi where v1!
v2 if an edge between v1 and v2 exists modularity degree v1 degree v2 e else modularity degree v1 degree v2 e endif endfor endfor modularity modularity e prioritization found of the system s test failures in of the files where a perfect prioritization would have found .
since their analysis used only file level metrics they did not examine team expansion or organization.
bird et al.
examined social structures in open source projects.
discussing connections and contradictions between some of brooks ideas and the bazaar like development of open source projects the authors empirically examine how open source developers self organize.
the authors use similar network structures as our developer network to find the presence of sub communities within open source projects.
in addition to examining version control change logs the authors mined email logs and other artifacts of several open source projects to find a community structure.
the authors conclude that sub communities do exist in open source projects as evidenced by the project artifacts exhibiting a social network structure that resembles collaboration networks in other disciplines.
the authors did not examine team expansion or structure in terms of modularity.
shin et al.
e v a l u a t e d t h e s t a t i s t i c a l c o n n e c t i o n b e t w e e n vulnerabilities and metrics of complexity code churn and developer activity.
the study denotes two case studies of large open source projects multiple releases of mozilla firefox and the rhel4 kernel.
among the findings include a statistically significant correlation between metrics of all three categories and security vulnerabilities.
also in the mozilla project a model containing all three types of metrics was able to find .
of the known vulnerabilities by selecting only .
of the project s files.
pinzger et al.
proposed a variation on the developer network called a contribution network.
the contribution network i s designed to use version control data to quantify the direct and indirect contribution of developers on specific resources of the project.
the researchers were able to predict reliability failures in binaries of microsoft windows vista by applying centrality metrics to the contribution network.
files that were contributed to by many developers especially by developers who were making many different contributions themselves were found to be more failure prone than files developed in relative isolation.
the authors did not examine team expansion or organization.
nagappan et al.
c r e a t e d a l o g i s t i c r e g r e s s i o n m o d e l f o r failures in the windows vista operating system.
the model was based on what they called overall organizational ownership oow .
the metrics for oow included concepts like organizational cohesiveness and diverse contributions.
among the findings is that more edits made by many non cohesive developers leads to more problems post release.
the oow model was able to predict with average precision and average recall.
the oow model bears a resemblance to the contribution network in that both models attempt to differentiate healthy changes in software from the problematic changes.
in addition to the prediction and validity studies other studies have provided additional insight into team development using social network analysis in general.
sarma et al.
have developed a tool that visualizes many different aspects of development artifacts including the developer network .
also begel et al.
have developed a tool at microsoft that utilizes development artifacts to aid in finding people with specific expertise in a project .
treude and storey approached the problem of awareness in large development teams by examining current tools.
they performed a qualitative and quantitative case study of ibm s jazz development platform to examine how developers use highly configurable features like dashboards and feeds.
according to the researchers some developers reported that dashboards provide an increased peripheral awareness and overview of the project s status.
feeds were reported to help developers track the lower level tasks of the project such as updates to fault reports or upcoming deadlines.
the results indicate that an integrated development platform like jazz can provide valuable team level and task level awareness to software developers.
.
methodology in this section we describe how we conducted our longitudinal case study including the metrics we used.
.
study design our empirical analysis is a statistical correlation study between team metrics and product quality.
we set up this study as a longitudinal analysis of a single development team at cisco that underwent expansion over time.
to incorporate time into our analysis we used a shifting time window for the team metrics.
the time window is the period of time in which we collected the team metrics representing a data point in our analysis.
the quality of the product as experienced by the customer however does not change at the same time as the team changes.
a lag exists between changes in the team and changes in the experienced product quality.
during this lag period developers can be stabilizing the product testers are performing their final system tests and the product is delivered to customers production environments.
thus in our study we take this delay into account between the team changing in the time window under study and a snapshot of the product s overall quality.
figure depicts how the time window fits on the production development timeline.
figure .
study timeline in regard to how to set up the time lag we must answer the following question time lag what is the time lag between changes in the team and corresponding changes in product quality?
the results of the time lag analysis can be found in section .
.
next we focus our analysis on three main research questions.
the first q u e s t i o n i s r e l a t e d t o a s s o c i a t i o n w h i c h a n s w e r s f o r u s specific questions about the relationship between our team metrics and product quality on the individual level.
association are team expansion and organization metrics statistically associated with s o f t w a r e q u a l i t y ?
s p e c i f i c a l l y w i t h respect to qsize qrate qacceleration and qmodularity.
qsize.
does an expanded team result in reduced product quality?
qrate.
does a team with a high expansion r a t e result in reduced product quality?
qacceleration.
does a team with an accelerated expansion rate result in reduced product quality?
qmodularity.
does a t e a m t h a t d o e s n o t c o l l a b o r a t e a c r o s s departments result in reduced product quality?
for each of the four sub questions we formulate a metric in this study.
the metrics for the first three questions are defined in section .
the metric for the fourth question is defined in section .
and the metric for product quality is defined in section .
.
the results of this analysis can be found in section .
.
next we use predictability to estimate the strength of the correlation between all of the team metrics and the product quality metric.
practically speaking prediction also has a direct use to the managers in our case study project because each month team leads set an expected quality goal i.e.
an expected failures per hour goal for the product.
cisco upper management uses the failures per hour metric and its goal as a guide for process improvement.
managers at cisco can use the predictive model we used in this analysis to better inform the goal setting process.
predictability can we use team metrics to predict months where product quality will be reduced?
the results of the predictability analysis can be found in section .
.
lastly our prediction results could be sensitive to slight variations in the time lag parameters.
thus we examine what our prediction results would have been if with differing time lag parameters.
sensitivity would using d i f f e r e n t t i m e l a g p a r a m e t e r s y i e l d different prediction results?
the results of the sensitivity analysis can be found in section .
.
.
team size and expansion metrics to estimate the size of the development team for a given time period we counted the number of distinct developers who made version control changes to source code files on the product.
we call this metric numcommitters.
s i n c e t h e n u m c o m m i t t e r s metric is based on version control logs it only includes teammates who made changes to the code and does not include counts of management and other non coding employees.
to measure how quickly the team expands we use two measures numnewcommitters a n d expansionacceleration.
we define numnewcommitters as the number of committers who had never previously made a commit to the product in its history.
we define expansionacceleration as the slope of the change in the number of monthly new committers over a given period of time.
the two metrics represent velocity of the team size and acceleration of the team size respectively.
for example suppose we examine the version control logs for a three month period of time and we find that committers made changes to the code.
during that three month period suppose that the team had ten new developers for the first month then developers the next month then developers in the third month.
in total the team had new developers in this three month period.
furthermore the team s growth increased by five developers per month.
thus in this example numcommitters is numnewcommitters is and expansionacceleration is .
.
team structure metric to measure the overall structure of the team we first need to define how we quantify structure .
we used a developer network to examine the structure of our development team.
developer networks have been used for analyzing teams predicting failures and predicting vulnerabilities .
the purpose of a developer network is to represent the complex system of socio technical1 r e l a t i o n s h i p s b e t w e e n developers in a software development project.
we define our developer network as a graph where the nodes represent a developer on the team.
edges exist where two developers made a version control commit to the same source code file on the same version control branch within the time window under study.
edges represent places where two developers were likely working on the same code which in most cases means the developers are collaborating with each other .
following results in a previous study we do not apply numeric weights to the edges .
while the version control logs provide records of which developers are working on the different parts of the code the logs and resulting developer network do not provide any information on the formal organization of the team.
teammates could be collaborating on code only within departments or not working with other developers within the same department.
to measure how much code is being changed by developers of the same department we used a modularity metric called departmentmodularity.
using historical data from the human resources department at cisco we obtained the department identifiers for all the developers.
we then applied the modularity metric defined in section to the developer network using departments as partitions.
we chose departments as our partitioning boundary in this case study because each department has its own budget.
as a result developers in a given department are focused on producing departmental components while simultaneously focusing on integrating departmental components with other departments components.
a highly modular team modularity near .
indicates that the code changed by two developers on the same version control branch was mostly within departments.
likewise a team can also be highly anti modular modularity near .
or not modular at all modularity near .
.
for example suppose the version control logs and human resources data contained the following records in table .
the resulting developer network with department partitions can be found in figure .
from a visual inspection of the network most of the edges are within department boundaries making the team modular.
for this example the modularity metric value is .
indicating that the team is highly modular with respect to departments.
table .
departmentmodularity example data developer department files changed andy depta file1 file2 laurie depta file2 file3 file4 pete depta file1 file3 file7 aaron deptb file4 file5 w e u s e s o c i o technical to describe the connection between two people in the context of work related collaboration .
mei deptb file5 file6 john deptc file7 file8 jerrod deptc file6 file9 ben deptc file9 raza deptc file8 file9 figure .
example developer network with department partitions .
product quality metric we used failures per hour as our product quality metric.
we define failures per hour as the number of customer reported software failures that were eventually traced to a software fault per hour of usage of the product.
the failures per hour metric is intended to evaluate product quality from the point of view of the customer.
since failures per hour is based on failures not faults the metric is sensitive to situations when multiple customers encountered the same fault making the failure per hour metric more representative of the customer experience.
however using failures as a quality metric alone would also be dependent on the number of customers and the amount of product usage in addition to the quality of the product.
if the product s usage remained constant then f a i l u r e s would be an adequate product quality metric alone.
however to be safe we use an hours of usage term to normalize failures against the possibility of expanding or contracting market for the product.
.
case study we performed our analysis on a large cisco networking product that uses this goal setting process.
the product has over source code files and is being changed by hundreds of developers at any given time.
at cisco managers track the progress of a project using a goal setting practice.
managers dialog with team leads and decide on goals for various metrics including software quality metrics like failures per hour.
thus the failures per hour metric is a standard vetted quality metric used on hundreds of cisco products and is followed closely by the managers of our case study.
as a part of the goal setting dialog managers and team leads discuss upcoming quality concerns based on the team s progress.
from collective experience a t c i s c o using the time window as shown in figure of s e c t i o n to g u i d e s c o p i n g of the goal setting discussions has shown to be an accurate way of viewing the team s status.
specifically cisco managers have found that using a time window for goal setting is more advantageous than tracking failures by individual features and branches b e c a u s e a time window accounts for the entire team s activity e.g.
feature enhancement maintenance and is more accurate in practice.
to observe the activity of the development team we analyzed the version control logs and the failure tracking system.
nearly every change to the source code required a defect or feature recorded.
in this project both developers and testers commit changes to the code so the numcommitters metric includes some testers in addition to developers.
for modularity we also investigated several ways of partitioning developers other than departments but did not find the measures to be truly representative of logical partitions in this particular case study i.e.
they are not internally valid .
we examined same supervisor as a way to partition developers but some departments were more formally hierarchical than others confounding the partitions.
we also examined same business unit but found that the partition boundaries were too coarse to truly represent how the team is organized.
figure is a graph of the failures per hour metric over time with the y axis units hidden to protect proprietary information.
generally speaking the failures per hour for this project has decreased over time indicating that the overall quality of the product has generally improved.
the largest spikes in reduced quality correspond to new major feature releases of the product.
figure .
failures per hour over time lastly we only considered changes to source code files which for this project are files who names have the following extensions .java .jsp .jspf .tld .js .script .sql .c .h .cpp .hpp .py .sh .bat .pl .bas .asp .xsl and .wsdl.
.
analysis results in this section we examine the answers to our research questions in section .
.
we used the r statistics package2 v2.
.
for our statistical analysis.
.
time lag research question what is the time lag between changes in the team and corresponding changes in product quality?
in our case study when the team introduced problems to the code the customer did not experience the drop in quality immediately.
our team would release a new version of the product every three to six m o n t h s o f t e n m a i n t a i n i n g m u l t i p l e r e l e a s e s a t a t i m e a n d porting fixes across different releases.
all changes to the system underwent system testing prior to release as well.
if a customer were experiencing poor product quality today then the development that caused or missed the problem would have happened several months ago which we will refer to as the time lag.
we are looking to find appropriate values of two time lag parameters minimum time lag and m a x i m u m t i m e l a g to define the time window.
the minimum time lag represents the minimum amount of time between changing code and the customer being exposed to that change.
the maximum time lag represents the furthest amount of time prior to release such that changes are still in the same release that the customer experiences.
for example the minimum and maximum time lags for an average one year release cycle with a stabilization period of two months would be and months respectively.
to determine an appropriate time lag we used the average window of time between introducing new later to be found faulty files and the customer finding a bug.
in those specific cases the new source code would have gone through the normal testing and stabilization as part of the team s development process and was wrongly deemed to be correct before release.
any faults found in these source code files after release had to be injected into that new source code file during our time window.
note that we are not assuming that the faults in the new code were caused by team expansion rather we are using the injection to customer time as an indicator of the typical time lag between development and customer experience.
we performed a manual investigation of the defect tracking system and version control logs to find new later to be found faulty source code files.
we looked for examples of source code files that were both introduced as part of new development and later had to be fixed for a fault found by a customer after the product s release.
to ensure that the example files were representative we directed our search to find source code files in various components of the system committed and tested by different groups of developers and introduced at different times over the project history.
in the course of manual investigation we were specifically identifying source code that represented new development.
for example code was considered new development if its initial introduction was explicitly recorded as a new feature.
sometimes new code would be introduced as a result of a defect report that required major re implementation and thus n e w s o u r c e c o d e files .
we discarded any examples where the new source code was reported to be imported from another system a refactoring or the result of any other minor improvement activity that did not represent new development.
such source code files were rare yet highly informative.
our search surfaced source code files in different components.
no two source code files were involved in the same external defect.
the minimum amount of time between the new code being introduced and the first customer found defect was months.
we used months for our minimum time lag.
to determine the maximum time lag we had some large outliers that could be the result of the customer not finding the defects.
we used the upper bound of the confidence interval of the time lag which was .
months mean was .
months .
thus for a given failure per hour measurement we examine what happened in the team in the prior months.
to examine the sensitivity of these parameters on our prediction results we report our prediction results based on varying time lag parameters in section .
.
figure depicts the timeline with our time lag parameters.
since the failures per hour metric is captured monthly we shift our time window monthly.
therefore each team metric data point in our analysis comes from a different time window.
figure .
time window with lag parameters determined in section .
a summary of the team metrics based on our time lag parameters for this project can be found in table .
table .
summary of the case study project metric minimum maximum numcommitters numnewcommitters expansionacceleration .
committers per month .
committers per month departmentmodularity .
.
as table shows the size of the team in committers changed from to over from its smallest size to its largest size during that five year period.
every month window had at least new committers to the project meaning that the team was consistently under some form of expansion over a long period of time.
some windows had as much as new committers which was of all the committers at that time.
while the team was consistently under growth the acceleration of growth sometimes increased and decreased per month.
lastly the team s modularity was always positive meaning that the team was always modular with respect to departments.
.
association are team metrics associated with product quality metrics?
to test for association we used simple linear regression.
simple linear r e g r e s s i o n m e a s u r e s t h e l i n e a r r e l a t i o n s h i p b e t w e e n a n independent variable and a dependent variable.
our independent variables were our team metrics and our dependent variable was the failures per hour metric.
the outcome of the analysis is a p value comparing to .
that indicates whether or not the team metric is associated with software quality.
the pearson r2 m e a s u r e d e s c r i b e s t h e percentage of the variance explained by the metric alone giving evidence of the strength of the correlation.
lastly we indicate whether the metric was positively or inversely correlated with a high failure rate i.e.
reduced software quality .
the results can be found in table .
table .
team metrics association with reduced quality metric p value .
?
r2 correlation w reduced quality numcommitters yes .
inverse numnewcommitters yes .
inverse expansionacceleration yes .
positive departmentmodularity yes .
positive with regard to numcommitters the inverse correlation indicates that when the team was large the product quality was better.
this result does not surprise us given that we already knew that the team generally expanded over time and the product generally improved over time as shown in figure .
with numnewcommitters times of having many new developers were also inversely correlated with reduced quality.
that is when new developers were on the team the team later had better product quality.
however expansionacceleration was positively correlated with a reduced failures per hour.
this positive correlation indicates that periods of accelerating expansion are correlated with periods of relatively poor software quality.
therefore periods of large team size and linear team growth are correlated with better quality but periods of accelerated growth are correlated with periods of relatively poor quality.
for modularity we see that periods of high team modularity are correlated with periods of relatively poor product quality.
however we do not conclude that having a modular team is universally a bad characteristic.
as shown in table of section .
the team s modularity was never negative so the potential sweet spot of modularity may still be a positive number but should not be exceedingly high i.e.
close to .
.
we examined potential correlations i.e.
collinearity amongst our team metrics to see if the team metrics are similar to each other.
we tested our metrics again by performing multiple regression analysis against the failure per hour metric with combinations of two and three variables at a time and tested if all of the variables were still statistically significant.
we found that all of the variables were still statistically significant in this analysis with one exception.
when we combined numcommitters numnewcommitters and expansionacceleration into one model the numcommitters metric became statistically insignificant at a p .
level.
that is the variation in the failures per hour metric can be explained by the team s rate of growth without the need for accounting for i t s a c t u a l s i z e .
t h i s e v i d e n c e s u g g e s t s t h a t t h e velocity and acceleration of growth o f a d e v e l o p m e n t t e a m h a s more to do with quality than its overall size.
we also provide the pearson correlation coefficients between each of the variables in table .
the one metric that was strongly correlated with the other variables was numcommitters.
that is when the team was large the team also had many new developers and was more modular.
interestingly times of having many new developers were not found to be statistically correlated with having high expansion acceleration most likely stemming from the fact that in many of the time periods the team underwent a linear non accelerated growth.
therefore with respect to qsize we conclude that an expanded team does not necessarily result in reduced q u a l i t y b e c a u s e t h e rate and acceleration of expansion statistically explain the large team size and its observed effects on reduced q u a l i t y .
f o r qrate our results indicate that that linear growth in the team was not associated with reduced product quality.
however for qacceleration we conclude that accelerated team expansion is associated with reduced p r o d u c t q u a l i t y .
l a s t l y for qmodularity we conclude that when collaboration between departments is low the product quality also reduces.
.
predictability how often are we right?
our first step in predictability was to create a model.
we selected our variables based upon our association results described in section .
and internal correlation analysis where we found that combining our metrics together rendered the numcommitters variable statistically insignificant.
therefore the multiple linear regression model uses the following three metrics numnewcommitters expansionacceleration and departmentmodularity.
a key element of prediction is the supervised model.
a supervised model is a method of combining multiple metrics into a regression equation that predicts values of the failures per hour metric.
in our study we use multiple linear regression analysis as our predictive model.
supervised models require a training set and a validation set of data which are taken from the method validation.
we used a time based v a l i d a t i o n t e c h n i q u e t o p r o v i d e a simulation of how the model could have performed at specific times in history.
instead of randomly partitioning the data points into folds as is widely used in cross validation we iterated over each month in history and trained our model on only data available prior to the month in question then tested against the current month.
for the prediction analysis we analyzed a month history with a month delay from the beginning of the time window to the failures per hour metric.
for training a multiple regression model we required at least months of training data to properly train the model.
therefore our time validation prediction results are from months in total.
table .
pearson correlation coefficients between the team metrics.
numcommitters numnewcommitters expansionacceleration departmentmodularity numcommittters .
.
.
.
numnewcommitters .
.
.
expansionacceleration .
.
deptartmentmodularity .
coefficient not statistically different from at a p .
level to evaluate our model we report the adjusted pearson r2 value for the model on the training set and examine how often the model was able to predict within a prediction interval in our validation phase.
our prediction model on its own training set had an r2 of .
and was able to predict out of time periods over time.
figure show the prediction intervals and the actual failures per hour rate the y axis have no unit labels are hidden to protect proprietary information .
our predictions results indicate that three metrics based solely upon team growth and structure have a linear relationship that explains of the variation in the product s quality.
.
prediction sensitivity while we performed our analysis with a time lag of to months we also are interested in how sensitive our results are to adjusting those time lag parameters.
we present our prediction results with several different time lag parameters in table with highlighted top row being our best estimation for time lag according to the analysis in section .
.
we did not choose our time lag parameters based on this analysis we performed this investigation after choosing our month time lag parameters.
table .
prediction sensitivity to varying time lag parameters min.
time lag max.
time lag months in prediction interval adj.
r2 months months .
month months .
months months .
month months .
the sensitivity analysis shows that the predictions are in fact somewhat sensitive to varying time windows.
the prediction intervals however do still provide strong prediction results meaning that even if our choice of time lag parameters is slightly off the prediction results would have been strong.
interestingly the parameters we chose based on our own manual investigations of source code yielded the strongest prediction results.
.
limitations the results of this study are in the form of statistical correlations which means that our study does not unequivocally prove that accelerated team expansion affects quality.
furthermore our study has only been applied to one case study and further studies can reveal if these results are consistent across teams.
the longitudinal structure of the analysis assumes that the time lag from changes in the team to changes in the product quality is a constant factor over time.
in reality the actual lag may vary as a result of many different factors.
sometimes a product is rushed to customers or possibly delayed for more testing.
our sensitivity analysis in section .
mitigates this limitation by showing that our predictions are somewhat sensitive to the time lag but not sensitive to the point that strong prediction is not possible with parameters that are off by a few months.
as we apply our models to c i s c o s g o a l setting process we will examine the validity of our month time lag parameters according our case study and adjust them as necessary.
.
brooks law product quality the results of this study show that expanding a team does not have a high r i s k o f reduced q u a l i t y b u t t h a t a c c e l e r a t i n g t h e expansion of a team can be high risk to product quality.
we do not believe that this result contradicts the spirit of brooks law at all.
rather we submit that these results serve as a clarification of what brooks was discussing regarding his law.
adding developers to a team requires significant overhead such as training increased communication and increased coordination.
even in situations where the new teammates are veteran developers software projects are filled with project specific and domain specific knowledge that new teammates would need to be briefed on .
teams can plan for new developer overhead but when the project is already late as brooks law states the team may not have the time to adequately plan ahead.
like project lateness accelerating the expansion of a team can also undermine the development team s planning.
for example if a team is used to adding three new developers per month they figure .
prediction intervals for time based prediction will have likely have experience in allocating time with coworkers to train in the new developers.
as time passes planning for the training effort required of three developers per month becomes easier with experience as long as that rate remains constant.
planning for accelerated expansion however means the team will have to plan for more new developers each month.
the acceleration introduces an increase in the time and the number of coworkers allocated to train people in.
each month would have worse and worse training overhead than the month before which is difficult to plan for and introduces the risk of negative outcomes like lateness or poor quality.
fortunately expansion acceleration can be mitigated.
for example suppose a manager decides to expand the team by new developers over the course of three months.
an option involving acceleration would be to add two new developers in the first month then four the second month then six in the third month.
instead the same expansion of adding developers in three months can be accomplished without acceleration with a steady rate of four new developers per month.
based upon the findings of this case study we would recommend the steady growth option over the accelerated option.
.
future work we will be applying our metrics and study methodology to other case studies within cisco.
the data sources we used for this case study are available for many other different projects with different domains and varying team sizes.
we plan to investigate if our results replicate across teams particularly in situations where teams remained a constant size or reduced in size.
one additional case study has a team size of over a thousand committers which could provide added insight for teams that are an order of magnitude larger than the case study of this paper.
beyond cross project analysis we will be continuing to investigate other ways of using metrics to aid the goal setting practice at cisco.
one metric to examine is turnover or losing developers while also gaining new developers.
the case study in this paper had minimal turnover so we did not include it in this study.
additionally we are considering ways of quantifying developer expertise and experience so that we can separate out situations where the new committers are inexperienced or not.
lastly we are also examining other team level network analysis measures that quantify the structure of a team in different ways.
developer centrality is one file level measure used in other studies that could be aggregated on a team level.
.
summary our research objective is to guide software engineering managers during periods of team expansion by empirically analyzing the effects of team size growth and structure on product quality.
we performed an empirical longitudinal case study on a large networking product that grew from to committers.
we presented several team level metrics that can be used to assess and track the growth and modularity of software development teams.
in our case study we found that the team expanded in size over time and was also able to improve quality over time.
however periods o f a c c e l e r a t e d e x p a n s i o n a n d h i g h l y m o d u l a r t e a m organization were correlated with relatively poor software quality from the point of view of the customer.
i n f a c t r a t e a n d acceleration of team expansion together are enough to explain the team size association with product quality.
our results a help researchers and practitioners better understand how team expansion can be a high risk and b help practitioners including the subjects of our case study predict upcoming failures per hour measurements by monitoring team expansion and organization metrics.
we believe that the results of this case study warrant further investigation into the specific ways that adding manpower to a team can help or hurt the products quality.
.