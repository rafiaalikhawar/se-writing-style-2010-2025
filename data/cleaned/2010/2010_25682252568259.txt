detecting performance anti patterns for applications developed using object relational mapping tse hsun chen1 weiyi shang1 zhen ming jiang2 ahmed e. hassan1 mohamed nasser3 parminder flora3 queen s university1 york university2 blackberry3 ontario canada ftsehsun swy ahmed g cs.queensu.ca1 zmjiang cse.yorku.ca2 abstract object relational mapping orm provides developers a conceptual abstraction for mapping the application code to the underlying databases.
orm is widely used in industry due to its convenience permitting developers to focus on developing the business logic without worrying too much about the database access details.
however developers often write orm code without considering the impact of such code on database performance leading to cause transactions with timeouts or hangs in large scale systems.
unfortunately there is little support to help developers automatically detect suboptimal database accesses.
in this paper we propose an automated framework to detect orm performance anti patterns.
our framework automatically ags performance anti patterns in the source code.
furthermore as there could be hundreds or even thousands of instances of anti patterns our framework provides support to prioritize performance bug xes based on a statistically rigorous performance assessment.
we have successfully evaluated our framework on two open source and one large scale industrial systems.
our case studies show that our framework can detect new and known real world performance bugs and that xing the detected performance antipatterns can improve the system response time by up to .
categories and subject descriptors d. .
testing and debugging c. general terms performance keywords performance performance anti pattern static dynamic analysis performance evaluation permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
icse may june hyderabad india copyright acm ... .
.
.
introduction object relational mapping orm provides developers a conceptual abstraction for mapping database records to objects in object oriented languages.
through such mapped objects developers can access database records without worrying about the database access and query details.
for example developers can call user.setname peter to update a user s name in a database table.
as a result orm gives developers a clean and conceptual abstraction for mapping the application code to the database.
such abstraction signi cantly reduces the amount of code that developers need to write .
orm is widely used in practice as it signi cantly reduces the overhead of bridging business logic and database .
since java java has included a standard persistence api called jpa that supports orm.
there are many di erent implementations of jpa available such as hibernate and apache openjpa .
orm s popularity is not only limited to java but also other programming languages such as c ruby and vb.net provide orm abstraction .
despite orm s advantages it may introduce potential performance problems.
developers may not be aware which source code snippets would result in a database access nor whether such access is ine cient.
thus developers would not proactively optimize the database access performance.
for example code that is e cient in memory e.g.
loops may cause database performance problems when using orm due to data retrieval overheads.
in addition developers usually only test their code on a small scale e.g.
unit tests while performance problems would often surface at larger scales and may result in transaction timeouts or even hangs.
therefore detecting and understanding the impact of such potential performance overhead is important for developers .
in this paper we propose an automated framework which detects the orm performance anti patterns.
our framework can detect hundreds of instances of orm performance anti patterns based on static code analysis.
furthermore to cope with the sheer number of the detected anti patterns our framework provides suggestions to prioritize bug xes based on a statistically rigorous performance assessment improvement in response time if the detected anti patterns are addressed .
the main contributions of this paper are this is the rst work that proposes a systematic and automated framework to detect and assess performance anti patterns for applications developed using orm.permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may june hyderabad india copyright acm ... .
!
!
!!
!
!
!
!
!!
!
!!
!
!
!
!
!!
!
!
!!
!
!!
!
!
!
!
figure a motivating example.
shows the original class les and the orm con gurations shows the modi ed company.java the excessive data application code and the resulting sqls and shows the modi ed company.java the one by one processing application code and the resulting sqls.
our framework provides a practical and statistically rigorous approach to prioritize the detected performance anti patterns based on the expected performance gains i.e.
improvement in response time .
the prioritization of detected anti patterns is novel relative to prior anti pattern detection e orts .
through case studies on two open source systems petclinic and broafleaf commence and one largescale enterprise system ea we show that our framework can nd existing and new performance bugs.
our framework which has received positive feedbacks from the ea developers is currently being integrated into the software development process to regularly scan the ea code base.
paper organization the rest of this paper is organized as follows.
section provides motivating examples of the performance impact of anti patterns.
section describes our framework for detecting and prioritizing performance antipatterns.
section discusses the results of our case study.
section provides some discussions on the detected antipatterns and presents some future work.
section describes the threats to validity.
section surveys the related work.
finally section concludes the paper.
.
motivating examples in this section we present realistic examples to show how such orm performance anti patterns may a ect the performance of a system.
we develop a simple java program as an illustration figure .
the program manages a relationship between two classes company and department and provides a set of getter and setter functions to access and change the corresponding db columns e.g setcompanyname .
in this example there is a one to many relationship between company anddepartment i.e.
one company can havemultiple departments.
this relationship is represented using annotation onetomany on the instance variable department incompany.java and manytoone on the instance variable company indepartment.java details not shown in figure but very similar to company.java .
column shows which database column the instance variable is mapped to e.g.
companyid maps to column company id and entity shows that the class is a database entity class which maps to the database table speci ed in table e.g.
company class maps to company table .
fetch type in orm which can be either lazy oreager determines how the data of a java object is retrieved from the database.
using company.java in figure as an example a fetch type of eager means that department objects are always fetched from the database when a company object is initialized i.e.
calling new company even when department objects might never be needed.
on the other hand a fetch type of lazy means that department objects are retrieved only when their information is used e.g.
when calling department .getdepartmentname .
in the following subsections we discuss how the performance anti patterns may a ect system performance and show the performance di erence before and after xing the anti patterns.
we focus on the following two performance anti patterns that are commonly seen in real world code and that can possibly cause serious performance problems excessive data which retrieves unused unnecessary data from the database and one by one processing which repeatedly performs similar database operations in loops .
in this paper we focus our study on jpa which is a very popular orm standard api for java.
.
excessive data developers may set the relationship between two database entity classes to eager if the two classes are always associated together e.g.
accessing class company will always lead to an access to class department .
in such cases set annotated global call graph and data graph ranked performance anti patternsfigure overview of our orm performance anti pattern detection and prioritization framework.
ting the relationship to eager may improve performance by retrieving two database entity objects from the database in one sql statement using a join.
however such an eager fetch is not optimal if the eagerly retrieved data is never used.
figure shows an example of the excessive data antipattern.
excessive.java shows an application program that accesses the name of all the companies.
if we execute excessive.java using the orm con gurations in company.java excessive it would generate sql statements to retrieve both company objects as well as department objects from the database due to the eager setting on the department instance variable in company.java even though we do not access department objects in excessive.java .
one way to x this performance anti pattern is to change the fetch type from eager tolazy the original setting incompany.java .
to demonstrate the performance impact of excessive data we run the program shown in figure .
we populate the database with records in the company table and records of department for each record in the company table.
the response time before xing excessive.java is seconds xing the performance anti pattern reduces the response time to seconds a improvement .
.
one by one processing figure shows an example of the one by one processing anti pattern.
the one by one processing anti pattern is a special case of the empty semi trucks anti pattern which occurs when a large number of requests is needed to perform a task.
in this paper we study the e ect of such anti pattern in the orm context.
onebyone.java shows an application program that iterates through all the companies companylist and nds the names of all the departments in each company.
if we execute onebyone.java using the same orm con gurations in company.java it would generate one select department statement for each company object.
one way to solve this particular issue is to change the orm con guration for retrieving department objects to the con guration in company.java onebyone .
after adding a batch size e.g.
batchsize size to the instance variable department orm will select department objects in each batch.
the x reduces the number of sql statements signi cantly and could help improve the database performance.
note that the x for one by one processing may vary in di erent situations e.g.
database updates in loops and can be sometimes di cult.
section has more discussions regarding this issue.
to demonstrate the performance impact of one by one processing we run the program shown in figure with the same populated database as in section .
.
the response time before xing the anti pattern is seconds and the response time after the x is seconds a improvement .
our motivating examples show that there is a signi cant performance improvement even in simple sequential database read operations after xing both performance anti patterns.
.
our framework this section describes our framework for detecting and prioritizing orm performance anti patterns.
as shown in figure our framework consists of three phases data extraction phase performance anti pattern detection phase and performance assessment phase.
we rst extract all the code paths which involve database accesses.
then we detect the performance anti patterns among these databaseaccessing code paths.
finally we perform a statistically rigorous performance assessment so that developers can prioritize the performance bug xes among hundreds of antipatterns.
in the rest of this section we explain these three phases in detail.
we use the example in section to illustrate our approach.
.
data extraction in this phase we identify all the code paths which involve database accesses.
for each source code le we extract the local call graphs database accessing functions and orm con gurations section .
.
.
then we combine the information from all the les and identify code paths i.e.
scenarios which involve database accesses section .
.
.
.
.
extracting database accessing functions local call graphs and orm configurations we rst extract the call graphs and data ows in each le then we identify all orm related information such as annotations and con gurations.
as shown in section orm uses annotations to annotate a java class as a database entity class or to setup di erent data retrieving strategies and con gurations.
we store the information about the orm con guration of each database entity class and database instance variable and identify functions that could result in database accesses.
using figure as an example we store the relationship between company and department as oneto many.
we also mark the getter and setter functions e.g.
setdepartmentname which access or modify database instance variables as database accessing functions.
.
.
identifying database accessing code paths we identify the code paths which involve database accesses.
we accomplish this by constructing global call and data flow graphs we build a global call graph for all the functions and we keep track of each object s data usage during its lifetime.
since functions in object oriented languages are usually invoked through polymorphism we connect the function call graphs using the corresponding functions in the subclasses for abstract classes or the implemented class for interfaces.
marking database accessing code paths and data flows using taint analysis we use taint analysis commonly used in computer security to identify code paths and data ows which involve database accesses.
taint analysis keeps track of a possibly malicious variable e.g.
variable v and if vis used in an expression to manipulate another variable m mis also considered suspicious.
similarly if a function in a call path contains a database accessing1003function that is determined by the rst step we mark all the functions in the code path as database accessing functions.
for example in a call path function a calls function b and function b calls function c. if function c is a database accessing function we consider the code path of a !b!c as a database accessing code path.
we perform taint analysis statically by computing the node reachability across functions in the global function call graph.
.
performance anti pattern detection with identi ed database accessing code paths and data ows we use a rule based approach to detect orm performance anti patterns.
di erent anti patterns are encoded using di erent rules.
in this paper we focus on detecting two of the most pervasive orm anti patterns but new antipatterns can be integrated to the framework by adding new detection rules.
section has more discussions about extending our framework.
detecting excessive data anti patterns when a database entity object is initialized a database call is invoked to retrieve the required information.
therefore we use pointto analysis to rst identify the variables that point to the database entity object.
then we analyze the data ow of the object to detect excessive data.
if a database entity object does not use any of the eagerly retrieved information during its lifetime identi ed by traversing the data ow graph we report the object usage as an instance of performance anti pattern.
detecting one by one processing anti patterns to detect one by one processing anti patterns the framework rst identi es the functions that are directly called within both single and nested loops we consider all kinds of loops such as for while foreach and do while .
if a directly called function is a database accessing function the framework simply reports it as an one by one processing anti pattern.
the framework also traverses all the child nodes in the function call graphs of the functions that are called in loops.
we analyze the child nodes across multiple functions and determine whether there is a node in the call graph that may access the database.
if so the framework reports the call path that contains the node as an instance of one by one processing anti pattern.
due to orm con gurations some database accessing functions may not always access the database.
in such cases we do not report them as anti patterns.
for example if department is eagerly retrieved by company retrieving company will automatically retrieve department .
therefore accessingdepartment through company in a loop will not result in additional database accesses and will not be reported by our framework.
if a database accessing function in a loop is already being optimized using some orm con gurations i.e.
fetch plan is either batch subselect orjoin we do not identify it as a performance anti pattern.
.
performance assessment previous performance anti pattern detection studies generally treat all the detected anti patterns the same and do not provide methodologies for prioritizing the anti patterns .
however as shown in the case studies section there could be hundreds or thousands of performance anti pattern instances.
hence it is not feasible for developers to address them all in a timely manner.
moreover some instances of anti patterns may not be worth xing due tothe high cost of the x and the small performance improvement.
for example if a one by one processing anti pattern always processes a table with just one row of data there is little improvement in xing this particular anti pattern.
in this phase we assess the performance impact of the detected anti patterns through statistically rigorous performance evaluations.
the assessment result may not be the actual performance improvement after xing the anti patterns but may be used to prioritization the xing e orts.
we repeatedly measure and compare the system performance before and after xing the anti patterns by exercising the readily available test suites.
anti patterns which are expected to have big performance improvements e.g.
performance improvement after the xes will result in higher priorities.
the rest of this subsection explains the three internal parts in performance assessment phase exercising performance anti patterns and calculating test coverage assessing the performance improvement after xing the antipatterns and statistically rigorous performance evaluations.
part exercising performance anti patterns and calculating test coverage one way to measure the impact of performance anti patterns is to evaluate each anti pattern individually.
however since system performance is highly associated with run time context and input workloads we need to assess the impact of performance anti patterns using realistic scenarios and workloads.
since performance anti patterns are detected in various software components it is di cult to generate work ows to exercise all the performance anti patterns manually.
therefore we use the readily available performance test suites to exercise the performance anti patterns.
for the systems that do not have performance test suites we use integration test suites as an alternate choice.
although integration test suites may not be designed for testing performance critical parts of a system they are designed to test various features in a system i.e.
use case tests which may give a better test coverage.
in short performance and integration test suites group source code les that have been unit tested into larger units as suites e.g.
features or business logic which better simulate system work ows and user behaviours .
since we do not have control over which instances of performance anti patterns are exercised by executing the test suites it is important to know how many performance antipatterns are covered by the tests.
we use a pro ler to pro le the code execution paths of all the tests and use the execution path to calculate how many instances of performance anti patterns are covered in the tests.
part assessing performance improvement after xing anti patterns in this part we describe our methodology to assess the performance improvement of xing the excessive data and one by one processing anti patterns.
assessing the excessive data anti patterns the eager fetch setting may be necessary in some situations to improve performance but may cause performance degradation when the retrieved data is not used.
we x excessive data antipatterns by xing the source code i.e.
change the fetch type from eager to lazy where appropriate .
finally we measure and compare the system performance before and after xing the excessive data anti patterns.1004assessing the one by one processing anti patterns fixing one by one processing can be much more complicated than what we have shown in section .
one common x to oneby one processing is using batches.
however for example performing a batch insert to the department table in orm may require writing speci c orm sql queries such as insert into department name values department1 department2 ... to replace ordinary orm code.
as a result manually xing the anti patterns of one by one processing requires a deep knowledge about a system s structure design and apis.
due to the complexity it is very di cult to x all the detected one by one processing anti patterns automatically.
therefore we follow a similar methodology by jovic et al to assess the anticipated system performance after xing the one by one processing anti patterns.
as shown in section the slow performance in the oneby one processing anti patterns is mainly attributed to the ine ciency in the generated sql statements.
the oneby one processing anti patterns in orm generate repetitive sql statements with minor di erences.
the repetitive sql statements can be optimized using batches which reduce a large amount of query preparation and transmission overheads.
therefore the performance measure for executing the optimized sql statements could be a good estimate for the anticipated system performance after xing the one by one processing anti patterns.
to obtain the generated sql statements we use a sql logging library called log4jdbc to log the sql statements and sql parameter values.
log4jdbc simply acts as an intermediate layer between jdbc to the database which relays the sql statements to the database and outputs the sql statements to log les.
we detect the repetitive sql statements generated by orm and execute the sql statements in batches using java database connectivity jdbc which assess the performance impact after xing the performance anti pattern.
note that since jdbc does not support batch operations for select we exclude select in our assessment.
we execute the original non optimized and optimized sql statements separately and compare the performance di erences in terms of response time.
part statistically rigorous performance evaluation performance measurements su er from instability and may lead to incorrect results if not handled correctly .
thus a rigorous study is required when performance measurements .
therefore our framework does repeated measurement and computes e ect sizes of the performance improvement i.e.
quanti es the increase in response time statistically to overcome the instability problem.
repeated measurements georges et al recommend computing a con dence interval for repeated performance measurements when performance evaluation since performance measurements without providing measures of variation may be misleading and incorrect .
we repeat the performance tests times as suggested by georges et al and record the response time before and after xes.
we use student s t test to examine if the improvement is statistically signi cant di erent i.e.
p value .
a p value means that the di erence between two distributions is likely not by chance.
then we compute the mean response time and report the con dence interval.
at test assumes that the population distribution is normally distributed.
according to the central limit theoremour performance measures will be approximately normally distributed if the sample size is large enough .
e ect size for measuring the performance impact we conduct a rigorous performance improvement experiment by using e ect sizes .
unlike t test which only tells us if the di erences of the mean between two populations are statistically signi cant e ect sizes quantify the di erence between two populations.
researchers have shown that reporting only the statistical signi cance may lead to erroneous results i.e.
if the sample size is very large p value can be small even if the di erence is trivial .
we use cohen s d to quantify the e ects .
cohen s d measures the e ect size statistically and has been used in prior engineering studies .
cohen s d is de ned as cohen s d x1 x2 s where x1and x2are the mean of two populations and sis the pooled standard deviation .
the strength of the e ects and the corresponding range ofcohen s d values are e ect size trivial if cohen s d .
small if .
cohen s d .
medium if .
cohen s d .
large if .
cohen s d we output the performance anti patterns ranked by their e ect sizes in an html report.
this report has two parts the database entity objects that have excessive data the database assessing functions and the code path of the detected one by one processing anti patterns.
.
case study in this section we apply our framework on two open source systems petclinic and broafleaf commence and one large scale closed source enterprise system ea .
we seek to answer the following two research questions rq1 what is the performance impact of the detected antipatterns?
rq2 how do performance anti patterns a ect system performance at di erent input scales?
each research question is organized into three sections motivation approach and the results.
table shows the statistics of the studied systems.
all of our studied systems use jpa for orm and follow the model view controller design pattern .
pet clinic is a sample open source system developed by the spring framework which aims to provide a simple yet realistic design of a web application.
broadleaf is a large open source e commerce system that is used in many commercial companies worldwide for building online transaction platforms.
ea supports a large number of users concurrently and is used by millions of users worldwide on a daily basis.
we sought to use open source systems in addition to the commercial system so others can verify our ndings and replicate our experiments on the open source systems as we are not able to provide access to the ea.
rq1 what is the performance impact of the detected anti patterns?
motivation system performance is highly associated with run time context and input workloads .
rarely1005table performance assessment result for excessive data and one by one processing.
tests with p value .
have statistically signi cant performance improvement marked in bold .
numbers in the parentheses are the percentage reduction in response time.
a excessive data system test case no.
excessive before sec after sec statistical signi cance e ect size description data covered p value pet clinic browsing .
.
.
.
.
.
large broadleafcustomer phone .
.
.
.
.
.
trivial o er service .
.
.
.
.
.
small shopping cart .
.
.
.
.
.
medium checkout .
.
.
.
.
.
large customer addr.
.
.
.
.
.
.
small customer .
.
.
.
.
.
trivial order .
.
.
.
.
.
large o er .
.
.
.
.
.
small payment info .
.
.
.
.
.
trivial ea multiple features improved by .
.
medium b one by one processing system test case no.
one by one before sec after sec statistical signi cance e ect size description processing p value covered broadleafcustomer phone .
.
.
.
.
.
.
trivial o er service .
.
.
.
.
.
trivial shopping cart .
.
.
.
.
.
large checkout .
.
.
.
.
.
large customer addr.
.
.
.
.
.
.
medium customer .
.
.
.
.
.
trivial order .
.
.
.
.
.
large o er .
.
.
.
.
.
small payment info .
.
.
.
.
.
trivial ea multiple features improved by .
.
large table statistics of the studied systems and number of detected anti pattern instances.
total lines no.
of no.
of by no.
of of code k les processing excessive data pet clinic .3k broadleaf .
206k ea 300k or never executed anti patterns would have less performance impact compared to frequently executed ones.
therefore we use test suites to assess the performance impact instead of executing the anti patterns individually.
in this research question we want to detect and prioritize performance antipatterns by exercising di erent features of a system using our proposed framework section .
approach since performance problems are usually revealed under large data sizes we manually increase the data sizes in these test suites and write a data loader for loading data into the database.
our framework repeatedly exercises the test suites and computes the e ect sizes of the performance impact.
moreover we measure the performance impact before and after xing all the anti patterns in each test suite separately.
we use the percentage reduction in response time statistical signi cance of such reduction and e ect size to measure performance impact i.e.
whether there is an actual di erence and how large the e ect is .
results anti pattern detection results table shows the anti pattern detection result.
for pet clinic our framework does not nd any one by one processing anti patterns.
however our framework does nd instances of excessive data antipattern.
in particular one of these instances is also discussed online by developers and it is shown to cause seriousperformance degradation .
by using our framework this performance problem can be detected in the early stages of testing.
in broadleaf our framework detected a total of instances of one by one processing anti pattern and instances of excessive data anti pattern.
since a large number of anti pattern instances is detected we only emailed the top instances of high impact performance anti patterns to the developers.
we are currently waiting for their reply.
due to non disclosure agreement nda we cannot present the exact numbers of detected anti patterns in ea.
however we can con rm that our framework is able to detect many of the existing and new performance problems in ea.
performance bene ts of removing excessive data table 2a shows the performance impact of excessive data in each test suite.
each test suite may cover multiple and overlapping test cases.
overall excessive data anti patterns have a statistically signi cant performance impact and the e ects are at least from medium to large in out of test suites.
the only test suite in pet clinic which covers two instances of excessive data anti pattern is related to browsing information about di erent pet owners pets and pets visits to the clinic.
the performance impact of the excessive data anti patterns is very large cohen s d is and xing the anti patterns can improve the response time by .
we execute all broadleaf test suites that contain instances of excessive data anti pattern.
the anti patterns cause a signi cant performance impact in of the test suites.
excessive data in three test suites has a medium to large statistical signi cant performance impact e ect sizes is .
.
and response time is improved by after xing the anti patterns .
however the impact of excessive data anti patterns in six test suites are trivial and are not statis 1006tical signi cant.
it is interesting to see that these test suites have a small seconds and similar response time before and after xing the performance anti patterns which implies that these anti pattern instances have a very low performance impact.
we nd that xing excessive data anti patterns in ea gives a statistically signi cant improvement and can improve the response time by a medium e ect size of .
we manually investigate how excessive data anti patterns a ect the performance in all three systems because the performance improvements vary considerably among the studied systems.
we nd that the di erences in database schema may introduce a signi cant performance impact on excessive data anti pattern.
in pet clinic we discover that when viewing the names of each owner s pet i.e.
retrieve petobjects from the database the system eagerly retrieves every single visit of a pet i.e.
one to many relationship .
as a result many selects are executed to retrieve information about all pet s visits which is not needed for displaying owner and pets name.
on the other hand most instances of the excessive data anti pattern in broadleaf are one to one e.g.
one product has only one stack keeping unit or many to one e.g.
multiple payments are done by one customer which have a lower performance impact.
performance bene ts of removing one by one processing.
table 2b shows the performance impact of one by one processing in each test suite and the assessed performance impact.
table 2b does not show pet clinic since our framework does not detect any instance of one by one processing.
in broadleaf one by one processing anti patterns have a statistically signi cant performance impact in out of the test suites and the e ect sizes are at least medium .
.
.
the assessed response time reduction is from .
one by one processing anti patterns have a non statistical signi cant impact in other test suites.
similar to our ndings in excessive data anti patterns these test suites have one common behaviour very short response time.
the results indicate that when the response time of a program is small adding batches will not give much improvement.
this also shows that not all anti patterns are worth xing.
although we cannot show the mean response time and con dence interval in ea the assessed response time reduction is high and the e ect size is large .
.
by using batch operations the performance of ea was improved signi cantly.
our performance assessment results show that performance anti patterns have a statistically signi cant performance impact in excessive data and one by one processing test suites with e ect sizes varying from medium to large.
we nd that xing the performance anti patterns may improve the response time by up to and on average by .
rq2 how do performance anti patterns affect system performance at different input scales?
motivation in rq1 we manually change the data sizes to large to study the impact of performance anti patterns.
however populating large volumes of data into the database requires a long time and a database expert is needed to ensure that the generated data satis es all the database schema requirements .
in this research question wetable performance assessment result for di erent scales of data sizes.
we do not show the e ect size for the tests where the performance improvements are not statistically signi cant i.e.
p value .
.
a excessive data system test case e ect sizes for di erent input sizes description small medium large pet clinic browsing .
.
.
broadleafshopping cart .
.
checkout .
.
.
order .
.
.
ea multiple features .
.
b one by one processing system test case e ect sizes for di erent input sizes description small medium large broadleafshopping cart .
.
.
checkout .
.
customer addr.
.
.
order .
.
ea multiple features .
.
.
study whether we still have the same prioritization ranking of the performance anti patterns using smaller data sizes.
approach we focus only on the test suites which yield anti patterns with statistical signi cant performance impact in rq1.
we manually modify the test suites to change the data sizes to medium and small as opposed to big data sizes in rq1.
we reduce the data sizes by a factor of at each scale e.g.
medium data size is of large data size and small data size is of the medium data size .
finally we re run the performance tests to study how the performance impact and e ect size change at smaller scales.
results excessive data.
table 3a shows the performance impact assessment result of excessive data at di erent scales.
in pet clinic the performance impact is statistically signi cant and the e ect is large at all di erent scales.
when the data size is small the e ect size is the smallest .
among the three di erent data sizes.
when the data size is medium the e ect size becomes .
which is signi cantly smaller than the e ect size calculated using the large data size .
.
in addition the e ect size increases along with the input size which implies that identi ed performance anti patterns in pet clinic may cause scalability problems.
in broadleaf excessive data anti patterns in almost all test suites have a statistically signi cant performance impact in all three scales e ect size .
.
.
the result implies that these anti patterns can still be revealed using a smaller scale of input data.
the excessive data anti pattern in ea has a statistically signi cant impact when the data sizes are medium and small the e ect sizes are medium .
however we nd hat the e ect size is slightly smaller from the large data size compared to that of the medium data size.
the reason for having a smaller e ect size in larger data size is that some excessively retrieved objects have a many to one relations e.g.
multiple departments may belong to the same company which only need to be retrieved once and cached.
many to one excessive data anti pattern may cause large performance impact if the eagerly retrieved data is large large transmission overheads .
our framework reports all the detected anti pattern instances and annotates the relationship e.g.
many to one orone to many so developers can determine the necessary action to them.1007one by one processing.
table 3b shows the performance impact assessment of one by one processing at di erent scales.
in general one by one processing anti patterns in broadleaf have a higher performance impact i.e.
larger e ect sizes when the data sizes increase because the data sizes directly a ect the number of iterations in loops.
however in most test suites these one by one processing anti patterns still have a statistically signi cant impact at smaller scales.
we nd that only three test suites do not have a signi cant performance impact when the data size is small but all test suites have a signi cant performance impact when the data size is medium e ect size .
.
.
we nd a similar trend in ea where the e ect size increases as data size increases.
we can still identify performance problems in these test suites using small to medium data sizes.
we nd that the priority of the performance anti patterns at di erent scales is consistent i.e.
the rank of the e ect sizes in di erent test suites is consistent across di erent input data scales.
for example the rank of the e ect sizes for test suites using medium and large data sizes is the same except for the ranks of the shopping cart test and the order test which are swapped.
as a result if the generation of large dataset takes too long or takes too much e ort we are still very likely to reproduce the same set of severe performance problems using a smaller dataset.
we nd that the prioritization of performance antipatterns when exercised on medium scale data size is very similar to the large data size.
this results show that developers may not need to deal with all the di culties of populating large data into the database to reveal these performance problems.
.
discussion in this section we discuss the accuracy of our performance assessment the distribution of our performance antipatterns across the studied systems extensions of our framework and initial developer feedbacks.
the accuracy of our one by one processing performance assessment methodology.
in our performance assessment methodology for one by one processing we measure the response time of the original non optimized and optimized sql statements instead of directly xing the code.
to study the accuracy of this methodology we develop a simple program with a known one by one processing antipattern example in section for evaluation.
we create a database with department names in all companies and verify using the example in figure .
we x the one by one processing pattern in the code by writing sql statements using jpa speci c query language.
the original code takes about seconds.
fixing the code results in a mean response time of seconds and the assessment shows a mean response time of seconds.
the experiment shows that our assessment methodology may be an over estimate but can achieve a comparable performance improvement v.s.
to assess the impact of the anti patterns.
in the future we plan to investigate automated performance refactoring approach for xing the one by one processing anti patterns.
distribution of the detected performance anti pattern instances.
in section we studied how the impact of the performance anti patterns changes with di erent scales oftable skewness of performance anti pattern instances found in the studied systems.
system excessive one by one all data processing anti patterns pet clinic .
.
broadleaf .
.
.
ea .
.
.
input data.
however we are not sure how these instances of anti patterns are distributed across di erent software packages.
the distribution of the anti pattern instances may a ect the allocation of qa resources.
it would be challenging to manually review and verify these performance antipattern instances if they were found evenly in all software packages since more general knowledge about the whole system would be needed.
on the other hand if the anti pattern instances are mostly found within a few packages database experts can put more qa resources on verifying them in these packages.
we analyze the anti pattern detection results that we obtained from the case study and count the number of antipattern instances in each software package.
we plot the cumulative density function cdf of number of total performance anti pattern instances both excessive data and one by one processing in all the software packages.
cdf can be used to explore the distribution of data and provide observation such as of the packages have at most one performance anti pattern .
more formally cdf shows the probability that the value of a random variable will be less than or equal to a given value in a probability distribution.
we also compute the skewness on the number of antipattern instances in all packages.
if the skewness is larger than the distribution is highly skewed if the skewness value is between .
and the distribution is moderately skewed and if the skewness value is less than .
the distribution approximately symmetric .
table shows the skewness of the performance anti pattern instances.
we nd that the anti patterns are highly skewed in all studied systems .
.
.
the skewness for excessive data anti patterns is larger than .
in pet clinic and larger than in the other systems implying that excessive data anti patterns are found mostly in a few packages and so are one by one processing anti patterns skewness .
in broadleaf and ea .
the skewness of the total number of anti pattern instances combining excessive data and oneby one processing is also high .
.
.
since we want to compare the distribution of the number of anti pattern instances in packages we normalize the anti pattern instance counts in figure .
figure ea is excluded due to nda shows that most software packages do not have instances of performance anti patterns e.g.
more than of the packages in broadleaf have almost zero performance antipattern instance and only about of the packages in broadleaf have anti pattern instances.
as a result developers and database experts can focus on reviewing the code and verifying the anti pattern instances in a small number of packages without needing whole system knowledge.
we want to understand which packages tend to have more performance anti pattern instances.
we rank the packages by the number of performance anti pattern instances both excessive data and one by one processing together contained in each package and list the names in table .
we exclude ea in this study due to nda.
we nd that packages related to handling events e.g.
the service and ser .
.
.
.
.
.
.
.
.
.
.
.
normalized anti pattern countcumulative density pet clinic broadleaffigure cumulative density function cdf plots of number of performance anti pattern instances found in packages.
the x axis shows the normalized number of performance anti patterns in a package and the y axis shows the cumulative density.
table names of the top packages containing most performance anti patterns.
system package no.
exces no.
name sive data one by one pet clinicservice web model broadleafcore.order.domain core.order.service core.o er.service.processor vice.processor packages data model e.g.
the model and domain packages and gui the web package contain more performance anti pattern instances in these systems.
in the future we plan to study the root cause of the performance anti patterns in these packages and how to avoid them.
framework extension.
in this paper we proposed a rulebased approach which detects and prioritizes two of the most pervasive orm performance anti patterns.
similar as any other pattern detection work our framework cannot detect unseen performance anti patterns.
however our framework could easily be extended by encoding other performance anti patterns.
in the future we can plan to add new detection rules and apply the rules on the global call and data ow graphs to nd new performance anti patterns.
initial developer feedback.
we have received positive feedback from developers and performance testers in ea.
the framework is able to help them narrow down the performance problems and nd potential bottlenecks.
we are currently working closely with the developers in ea for integrating the framework in their daily development processes.
.
threats to validity in this section we discuss the threats to validity.
.
external validity we have only evaluated our framework on three systems.
some of the ndings e.g.
which system components may have more performance anti patterns might not be generalizable to other systems.
although the studied systems vary in sizes and domains other similar systems may have completely di erent results.
future work should apply our framework to more systems and even di erent programming languages e.g.
c .
.
construct validity detection approach.
we use static analysis for detecting performance anti patterns.
however static analyses generally su er from the problem of false positives and our framework is no exception.
for example a detected performance anti pattern may be seldom or never executed due to reasons like unrealistic scenarios or small input sizes.
therefore we provide a performance assessment methodology to verify the impact and prioritize the xing of the detected performance anti patterns.
experimental setup.
we exercise the performance antipatterns using either performance or integration test suites so we do not have control over which performance antipatterns will be exercised.
as a result our performance impact assessment study only applies to the exercised performance anti patterns.
however our performance impact assessment methodology is general and can be used to discover the impact of performance anti patterns in di erent software components and to prioritize qa e ort.
we manually change the data sizes to study how the impact of performance anti patterns changes in di erent scales.
changing the data loader in the code and loading data in the database require a deep understanding of the system s structure and design of each test suite.
although we studied the code in each test suite and database schemas carefully it is still likely that we did not change the inputs that are directly associated with the performance anti patterns or that the data does not generate representative workloads.
however case studies show that we can still ag a similar set of high impacting performance anti patterns using different sizes of database.
fixing performance anti patterns and performance assessment.
fixing some performance anti patterns may require api breaks and redesign of the system.
therefore xing them may not be an easy task.
for example to achieve maximal performance improvement sometimes it is necessary to write sql statements in orm .
if the antipattern is generating many small database messages which cause transmitting overheads and ine cient bandwidth usage the solution is to apply batching .
in addition di erent implementations of orm support di erent ways to optimize performance.
as a result we provide a performance assessment methodology for assessing the performance impact.
we use a similar methodology as jovic et al to measure the performance impact of one by one processing and we manually x the excessive data anti patterns in the code.
although our performance assessment methodology may not give the exact performance improvement and there may be other ways to x the performance anti patterns we can still use the assessment result to prioritize the manual veri cation and performance optimization e ort.
we can further reduce the overheads of running the performance assessment approach using the result of our static analysis and focus only on the parts of the system that are prone to performance anti patterns.
it is possible that the performance xes may have contradicting result in di erent use cases.
for example in some cases using a fetch type of eager may yield a better performance but may yield performance degradation in other cases.
however since orm provides a programming interface to change the con guration and fetch plans dynamically the problem can be solved by developers easily.
.
related work in this section we discuss the following two areas of related research design level performance anti patterns and detecting performance bugs.
design level performance anti patterns.
most prior studies focus on discussing and detecting design level performance anti patterns.
smith and williams discuss design level anti patterns that may cause performance impacts and provide solutions on how to refactor the design to eliminate the performance problem.
in their followup work smith and williams document the problem and possible solution of another three performance anti patterns.
one of the anti patterns discussed in their paper called empty semi trucks is related to the one by one processing antipattern discussed in this paper.
empty semi trucks occurs when a large number of excessive requests is performed for a given task such as retrieving information from the database.
our paper on the other hand focuses on detecting a variant of empty semi trucks using static analysis and we propose a framework that can automatically assess the performance impact of the detected anti patterns.
nijjaret al extract a formal data models from the orm speci cation of system and develop heuristics to discover anti patterns in the data model.
their framework can then automatically propose solutions to correct the data models.
cortellessa et al discuss various approaches of detecting design level performance anti patterns using software modelling and design change rules.
most prior studies on performance anti patterns aim to improve the architecture and class design where our work focuses on how developers write orm code.
to the best of our knowledge our paper is the rst work that aims to detect software performance anti patterns using static analysis and provide a performance assessment automatically for systems that are developed using orm.
performance bug detection.
prior studies propose various approaches to detect di erent performance bugs through run time indicators of such bugs.
parsons et al present an approach for automatically detecting performance issues in enterprise applications built using component based frameworks.
parsons et al detect performance issues by reconstructing the run time design of the system using monitoring and data mining approaches.
chis et al provide a tool to detect memory anti patterns in java heap dumps using a catalogue.
nistor et al propose a performance bug detection tool which detects performance problems by nding similar memory access patterns during system execution.
nistor et al report code loops with repetitive computation and partially similar memory access patterns.
tamayo et al construct the program dependency graph using dynamic information ow and combine the information with the corresponding database operations to identify performance bottlenecks.
their tool may also be used to identify problems related to batching sql synchronization repetitive sql queries and extra operations.
xuet al introduce copy pro ling an approach that summarizes runtime activity in terms of chains of data copies which are indicators of java runtime bloat i.e.
many temporary objects executing relatively simple operations .
xu et al introduce a run time analysis to identify lowutility data structures where the involve costs that are out of line with the gained bene ts.
xiao et al use di erentworkloads to identify and predict workload dependent performance bottlenecks i.e.
performance bugs in gui applications.
grechanik et al develop an approach for detecting database deadlocks with high degrees of automation.
in another work grechanik et al combine dynamic analysis and static code analysis to prevent database deadlocks.
most of the aforementioned studies typically detect performance bugs during the execution of the software which may not cover all the code paths depending on the input workow.
in addition generating work ows that exercise di erent components of a system requires good domain knowledge and can be very time consuming.
in this paper we provide a framework to statically identify performance anti patterns by analyzing the source code of the system.
the advantage of using static code analysis is that we can identify parts of the code that are not executed by the input work ow but may still contain performance bugs.
in addition we focus on orm performance anti patterns which may not be captured by detecting performance anti pattern using memory access e.g.
.
moreover we provide a statistical rigorous performance assessment approach that can be used to evaluate the impact of the detected performance anti patterns which is generally missing in prior studies.
.
conclusion object relational mapping orm provides a conceptual abstraction between the application code and the database.
orm signi cantly simpli es the software development by automatically translating object accesses and manipulations to database queries.
developers can focus on business logic instead of worrying about non trivial database access details.
however such mappings might lead to performance anti patterns causing transactions timeout or hangs in largescale software systems.
in this paper we propose a framework which can detect and prioritize instances of orm performance anti patterns.
we applied our framework on three software systems two open source and one large enterprise systems.
case studies show that our framework can detect hundreds or thousands instances of performance anti patterns while also e ectively prioritizing the xing of these anti pattern instances using a statistically rigorous approach.
our static analysis result can further be used to guide dynamic performance assessment of these performance anti patterns and reduce the overheads of pro ling and analyzing the entire system.
we nd that xing these instances of performance anti patterns can improve the systems response time by up to and on average by .