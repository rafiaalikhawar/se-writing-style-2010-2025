using psycho physiological measures to assess task difficulty in software development thomas fritz andrew begel born sebastian c. m ller serap yigit elliott manuela z ger university of zurich bornmicrosoft research exponent zurich switzerland redmond wa usa bellevue wa usa abstract software developers make programming mistakes that cause serious bugs for their customers.
existing work to detect problematic software focuses mainly on post hoc identification of correlations between bug fixes and code.
we propose a new approach to address this problem detect when software developers are experiencing difficulty while they work on their programming tasks and stop them before they can introduce bugs into the code.
in this paper we investigate a novel approach to classify the difficulty of code comprehension tasks using data from psycho physiological sensors.
we present the results of a study we conducted with professional programmers to see how well an eye tracker an electrodermal activity sensor and an electroencephalography sensor could be used to predict whether developers would find a task to be difficult.
we can predict nominal task difficulty easy difficult for a new developer with .
precision and .
recall and for a new task with .
precision and .
recall.
we can improve the naive bayes classifier s performance if we trained it on just the eye tracking data over the entire dataset or by using a sliding window data collection schema with a second time window.
our work brings the community closer to a viable and reliable measure of task difficulty that could power the next generation of programming support tools.
categories and subject descriptors h. .
user machine systems human factors software psychology general terms human factors experimentation measurement keywords psycho physiological task difficulty study permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
icse may june hyderabad india copyright acm ... .
.
.
introduction knowing how hard a task is as it is being performed can help in many dimensions.
for instance the estimate for completing a task might be revised or the likelihood of a bug occurring in the source code changes for the task might be predicted.
existing work to determine task difficulty has mainly focused on already existing artifacts such as task descriptions and the similarity of artifacts using machine learning classifiers.
in our research we are investigating a novel approach to determine task difficulty that uses psycho physiological data gathered from the developer while he is working such as electroencephalographic eeg activity along the forehead or electrodermal activity eda .
by using psycho physiological sensors and collecting data while a developer is performing a task we present the first approach that can support an instantaneous measure of task difficulty that does not rely on already produced artifacts or even whether the developer is writing any code at all.
there has been extensive research in psycho physiology investigating how various measures can be linked to psychological states and processes e.g.
but only little work has investigated the use of such measures in software development.
predominantly this work used eye tracking technology to retrospectively determine the effect on visual effort for different representations such as differences in identifier styles or the visual representation of requirements e.g.
.
none of this work has used psychophysiological features of software developers to measure task difficulty.
onepreliminarypilotstudybyparnin hasexplored the use of electromyography to measure sub vocal utterances and investigate them as an additional measure for task difficulty.
while parnin found a correlation between utterances and a developer editing code his work looks at only a single psycho physiological feature ignoring the potential to look for instantaneous or more general measures of psycho physiological features corresponding to task difficulty.
in this paper we investigate whether we can use psychophysiological measurements to determine whether a code comprehension task is perceived as easy or difficult.
in particular we ask the following questions rq1 can we acquire psycho physiological measures from eye tracking eda and eeg sensors to accurately predict whether a task is difficult or easy?
rq2 which combination of psycho physiological sensors and associated features best predict task difficulty?
rq3 can we use psycho physiological measures to predict task difficulty as the developer is working?permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
copyright is held by the author owner s .
publication rights licensed to acm.
icse may june hyderabad india acm with such a code and quality independent indicator for a developer s difficulty with a task it may be possible to designasetofinterventionsthatcouldpreventthedeveloper from introducing bugs caused by cognitive difficulties and also provide timely support for the remainder of his task.
to answer our research questions we conducted an exploratory study in which professional software developers monitored with psycho physiological sensors performed six to eight tasks.
we gave the developers code comprehension tasks that were small but large enough to challenge the subjects for a few minutes at a time.
using all of the sensor data we were able to train a classifier to predict whether a developer on which the classifier was not trained on would perceive the task to be easy or difficult with .
precision and .
recall.
using just the eye tracking data resulted in even greater predictive power.
to create a classifier that can operate while the developer does his work we explored how well a sliding time window data collection approach adjusting the size of the time window from second to60seconds slidingit5secondseachtime couldmakepredictions of the developer s final assessment of task difficulty after finishing his task.
we found that combining subsets of sensors with particular time windows could improve classifier performance when predicting a new developer s task difficulty and a developer task task difficulty pair.
our contributions are an exploratory study on the viability of using psychophysiologicalsensorstodeterminecodecomprehension task difficulty an approach to classify tasks by difficulty using time intervals suitable for on the fly classification and an investigation of which combination of psychophysiological sensors and measurements are most effective at predicting task difficulty.
overall our work provides the software engineering research field with a new perspective on using psycho physiological measures to understand and support the software developer in his activities.
in the future advances in sensor technology and data analysis techniques should make it possible to employ simpler cheaper and more accurate metrics and develop them into programming support tools.
.
related work related work can be categorized into two areas the general use of psycho physiological measures to study psychologicalstatesandprocessesandresearchrelatedtoaspectsof software development using psycho physiological measures.
.
using psycho physiological measures there is a broad range of psycho physiological measures that have been explored and linked to psychological and specifically cognitive processes and states.
all of these measures have different strengths and weaknesses with respect to aspects such as invasiveness sensitivity generalizability interpretability and ease of collecting .
some of the most commonly used measures can roughly be categorized into eye related brain related or skin related measures.
eye.there is a variety of eye related measures such as the pupil size fixation duration or number of saccades.
early on beatty found that task evoked pupillary response in particular the peak amplitude of the pupil diameter is an indicator for memory load or also processing load and that it varies with task difficulty .
further research on pupilsize found similar correlations e.g.
to mental workload of subtasks and cognitive load and even used pupil dilation as a measure for workload at task boundaries .
others used measures of fixation and saccades e.g.
goldberg et al.found that a higher number of saccades is an indicator for a poorer interface and in their overview on eye tracking research in hci and usability jacob et al.
state that the mean fixation duration is believed to be an indicator of a participant s difficulty in extracting information from a display .
recent approaches have also used eyerelated measures to train machine learning classifiers and predict a person s cognitive state e.g.
.
while measures on pupil size fixations and saccades are commonly captured using an eye tracking sensor eye blink rateisbettermeasuredthroughelectrodesplacedaroundthe eye i.e.electrooculography eog or by filtering certain frequencies within electroencephalography eeg .
studies on eye blink rate have shown that it is inversely correlated with attention or mental load i.e.the lower the blink rate the higher the mental load or attention e.g.
.
brain.withbrain relatedmeasureswerefertotherecording of electrical activity inside the brain or close to the surface of the scalp i.e.electroencephalography eeg .
studies have shown that specific frequency bands often referred to as alpha beta gamma delta and theta within the eeg data can be connected to different mental states .
for instance several studies found that a decrease of alpha eeg activity and often an increase in theta eeg activity was accompanied with an increase in attentional demand and working memory load e.g.
.
other studies examined an eeg task engagement index defined as beta alpha theta e.g.
based on evidence that with increases in task engagement theta is suppressed alpha is blocked and beta increases in relative power or they found that the theta and delta band are sensitive to task difficulty manipulations e.g.
.
as with eye tracking measures researchershavealsoinvestigatedusingeegdata andmachinelearningtopredictaspects suchastheworking memory load or the cognitive task e.g.
.
skin.electrodermal activity eda also known as skin conductance sc or galvanic skin response gsr has been closelylinkedwitharousal attention emotionalstates stress and anxiety .
frequently features of electrodermal activity have been used in combination with measures such asblood volumepressureandrespirationtoclassifythedata into classes or states of emotion e.g.
.
in addition studies have shown that eda measures can be used to indicate cognitive load levels task difficulty level and distinguish cognitive load at the workplace from stress e.g.
.
for instance nourbakhsh et al.have shown that normalizedfrequencydomainsofelectrodermalactivitywere significanttoindicatetaskdifficultylevelsforarithmeticand reading tasks .
researchers have also investigated eda as a real time measure e.g.
to adapt the workload of an operator and avoid it to become too high or to detect emotions and improve the gaming experience .
finally researchers have combined various of these measures.
wilson for instance measured brain activity eye blinks electrodermal activity and heart rate and found that electrodermal activity measures as well as alpha and delta bandsofbrainactivityshowedsignificantchangestovarying mentalworkloaddemandsinflyingscenarios whiletheheart rate was less sensitive .
similarly ryu et al.combined403multiple sensors and found that a combination worked well for distinguishing between the difficulty levels of tasks .
more recently haapalainen et al.collected data using multiple sensors including a neurosky mindset for eeg eyetracking and a gsr armband and compared their ability to assess cognitive load using six elementary cognitive tasks with varying difficulty levels each.
their results show that electrocardiogram median absolute deviation and median heat flux measurements were most accurate to classify between low and high cognitive load .
similar to the aforementioned research we also want to takeadvantageofthepsycho physiologicalmeasuresanddifferentiate between difficult and easy tasks.
in particular we are looking into a combination of sensors similar to the ones by haapalainen .
however we are looking at aspects of softwaredevelopmentandthusdifferinthetasksandparticipants we are studying.
in particular the tasks in our study are more closely related to software development tasks and the participants are professional software developers.
since early research on reading algorithms has found differences to reading prose our study provides insights on how these psycho physiological measures could be used in the software development domain.
.
psycho physiology in sd a few studies have investigated the use of psycho physiological measures in software development mainly using eyetracking.
anearlystudyoncodecomprehensionbycrosby et al.used eye tracking to study the scan patterns and strategies of high and low experience developers.
in their study they used eye fixation as a measure of attention classified codeinto5categoriesfromeasytohardandfoundthathighexperienced developers use less time on comments and more time on complex statements than low experienced developers .
more recent studies by bednarik et al.also analyzed differences in strategies for less and more experienced developers in program comprehension and debugging .
using eye tracking technology researchers have also studiedtheeffectofdifferentrepresentationsinsoftwaredevelopment on the visual effort.
for instance sharif et al.looked at the effect of identifier naming conventions camelcase and under score in code comprehension and found that the accuracy in answers stays the same but time and visual effort decreases .
while sharafi et al.also looked at memorability of identifier styles they examined the impact of gender on source code reading and found different comprehension strategies in male and female subjects using eye tracking .
studies have also looked at differences in other representations such as graphical and textual representations of code variables requirements as well as the representation and layout of design patterns .
to study the link between code reviews and defect detection researchers have also examined the time developers spend scanning code by summarizing fixation durations over specific areas of interest and counting the number of fixations.
thereby theyfoundthatalongerscantimecorrelates significantly with a better defect detection .
all of these approaches examine software engineering aspects however theyarelimitedtoeye relatedfeatures.
khan et al.have looked into another psycho physiological aspect and its link to performance by investigating how the mood of developers affects debugging and programming .
in these studies different moods were induced by showingdevelopers video clips and then the developers performance was measured.
none of this research has investigated the use of psycho physiological measures for determining task difficulty.
closest to our work is a preliminary pilot study by parnin who has explored the use of electromyography to measure sub vocal utterances .
from early results he found that such a measure might be used to determine the difficulty of a programming task.
while these initial results indicate the potential of these measures this paper goes further in investigating multiple psycho physiological measures and their relation to task difficulty in a study with fifteen professional software developers.
.
experiment we conducted a lab experiment with professional software developers.
each subject performed eight code comprehensiontasksaswerecordedvariouspsycho physiological and subjective measurements1.
.
subjects subjects were recruited from a pool of professional software developers who lived in the greater seattle wa area and had registered their interest in participating in user studies at microsoft.
a screening questionnaire selected of these candidates who had at least years of software development experience knew how to program in c and had done so in the last year did not need to wear bifocal or trifocal glasses they interfere with the eye tracker and were available to come to our lab.
five of the selected subjects did not show up.
those that completed the .
hour experiment were remunerated with a single license for their choice of microsoft consumer software a standard payment for microsoft user study participants .
fourteen of the subjects were male and one was female.
subjects ranged in age from to years of age mean .
stdev .
.
.
data capture we recorded study data using three psycho physiological sensors eye tracking eda and eeg.
we also recorded the subject s think aloud narrative recorded a video of the experiment and recorded a screen capture.
the subjects filled out a pre questionnaire a written nasa tlx survey aftercompletingeachexperimentaltask andapostquestionnaire after the entire experiment that asked them to rank each of the tasks by relative perceived difficulty.
the experiment administrator also took hand written notes.
eye tracking has been used to assess task difficulty and cognitive and mental load .
we used a tobii tx300 eye tracker using a hz tracking frequency to collect gaze location information fixation and saccade count and duration and pupil diameter.
the eye tracker has an accuracy of .
of visual angle which is equivalent to pixels on its built in dpi x inch monitor.
we applied tobii studio s built in i vt fixation filter with default parameters in order to classify eye movements based onthevelocityofshiftsintheeyes directions.
toavoidgaze inaccuracy we directed the tool and our subsequent analysis to record and analyze data only from the subject s dominant eye determined as part of our experimental procedure .
1a replication package of the experiment is available via activity eda is an oft used sensor to detect arousal particularly cognitively determined arousal .
to measure eda we used an affectiva q sensor .
worn on the wrist of the subject s non dominant and non mouse holding hand.
the q sensor samples at a rate of hz simultaneously measuring skin temperature along with three axis acceleration data.
data is stored on the device itself and streamed via bluetooth to a recording computer.
electroencephalography eeg referstothemeasurement of the brain s electrical activity that arises from neuronal firing .
it is used in a variety of fields such as neurology and brain computer interface bci research.
there are a variety of devices that record multi channel eeg signals using sensors attached with gel to various points on a subject s head.
to make our experiment less invasive and minimize cleanup we decided to use an off the shelf neurosky mindband eeg sensor.
it is a one channel noise canceling dry sensor that records the eeg signal at hz from a single location on the subject s forehead reading signals mainly from the pre frontal cortex .
the mindband produces a single pre filtered time varying voltage signal as well as two computed signals attention and meditation corresponding to paying attention and feeling calm and centered .
while these are both produced by proprietary read trade secret algorithms the signals are always available from the entire family of neurosky sensors.
audio video capture of the experiment was done with two fps cameras one pointed straight at the subject from the screen like a webcam and the other above the subject aimed at the screen and keyboard.
the tobii studio v3.
software that was used to run the eye tracker also recorded the full resolution screen at hz and added a follow thebouncing ball visualization on top of the recording to visualize the subject s gaze location.
we attempted to use all of the psycho physiological sensors to record psycho physiological data for all of our tasks.
afterrefiningourprocedureswithatwopersonpre pilot we were able to successfully capture the complete set of sensor signals for of our participants.
we got eye tracking data for everyone eeg data for out of participants and eda data for out of participants.
two participants failed to produce a valid eeg signal coincidentally they failed to produce a measurable eda signal as well.
another participant s eeg data was lost during capture.
.
experimental tasks subjects were asked to perform short several minutes code comprehension tasks.
in two pre pilots we had asked subjectstoperformmorecomplex15 30minutetasksinvolving code comprehension and mental code execution but we found it difficult to scale our characterization of our subject s activities to a granularity of tens of milliseconds for such a long period of time.
we eventually designed smaller shorter tasks though still limited to code comprehension and mental execution.
while these are much simpler than the tasks of many software professionals we believe that this starting point helps us identify the big picture answers to our research questions and leaves more details to future experiments.
each subject was asked to work on ten tasks two practice questions and eight which were measured.
during each task they were asked to read a short passage of c codepresented on a single screen in the visual studio ide.
syntax highlighting was enabled there were no code comments and they never executed the code.
there were two kinds of programs.
the first created two rectangle objects assigned the coordinates of the corners and drew them on the screen.
a printed question underneath the program asked the subjects whether the two rectangles overlapped yes or no .
the second program created four shape objects choosing among circles squares rectangles and triangles and then drew them in some order on the screen.
a printed multiple choice question underneath the program asked subjects to tell us which three shapes were drawn on the screen last and the order they were drawn in from five possible answers.
we used three instances of the first program in the experiment.
the practice version of this program was used solely to familiarize the subject with the task.
one experimental instance was identical to the practice version except for the use of local variables of non mnemonic single letters.
in contrast the other experimental instance randomized and interleaved assignments of the corner coordinates for both rectangles.
this program was designed to stress the subjects abilities in spatial relations deciding whether the two rectangles overlapped and visual object grouping interleaving the rectangle initialization statements and working memory randomizing the order of the assignments prevents chunking each rectangle s assignment sequence together and fills up working memory to a greater amount .
there were seven instances of the second program.
they differed in a the order between initialization and drawing each shape e.g.
creating a shape and then drawing it or creating all shapes and then drawing them in randomized order b the variable names mnemonic vs generic to impact subjects working memory by interfering with their ability to remember the mapping between variable name and its shape c using an array to group the shapes and then looping over the array d making the loop construct mathematically more complex to stress the working memory for remembering the order of shapes and their mathematical skills e calling a separate function to swap the order f including a double nested question mark colon conditional operator to engage the subject s mathematical and working memory abilities comparing variables to constants .
each of the tasks was designed to take subjects between and minutes to finish.
subjects could see both the code and the question on screen at the same time and never needed to scroll.
in fact we directed the subjects to keep their hands still on the table to avoid affecting the eda sensor through wrist motion.
.
experimental procedure 1when each subject first entered the lab he was asked to fill out a consent form and a pre questionnaire requesting demographic information.
2we synced the internal clock of the eda sensor to the time on the eye tracking computer and then placed it on the wrist of the subject s nondominant hand the hand that does not use the mouse .
3we then connected the eda sensor via bluetooth to405the data recording computer and checked the live display to verify that a signal was being received.
since the eda sensor works by detecting the electrical conductivity across the wrist it sometimes fails to work if the subject has no sweat.
for those few subjects who did not register any signal we asked them to do a mild physical exertion jumping jacks and walking up and down a flight of stairs to cause them to sweat a little.
this sufficed for all but three subjects so we were unable to record their eda signal.
during our pilot study we had noticed that the subjects eda signal kept rising monotonically as they completed each subsequent task.
this would cause an intense learning effect on the eda signal so we changed our protocol.
4prior to the first task and in between each one subjects were asked to watch two minutes of one of four different calming full screen youtube videos of fish swimming in a fish tank and were requested to relax their minds.
this relaxation caused the subjects eda measurements to return to baseline after about a minute.
we were then able to use the eda signal in the second minute of the video as a baseline for the eda signal in the next task.
5next we determined the dominant eye of the subject so we could be sure that our subsequent analysis of the eyetracking gaze location data would point to the actual word that the subject was reading.
6each subject was asked to sit on non wheeled chair in front of the eye tracking computer and shift the seat around until their head stayed in an imaginary box about 75cm in front of the center of the screen.
no chin rest or mouth guard was required.
a peripheral display on a second computer enabled the experimenter to notice if the subject moved too far out of range cm side to side and or cm up and down and ask him to move back into range before continuing.
the subjects were then shown the practice tasks in visual studio and the font size was adjusted if requested by the subject.
we asked them to think aloud while the task and to tell us the answer out loud rather than typing it into the computer.
we turned on the audio and video recording and helped them put the mindband eeg sensor on their head.
we then verified the mindband s bluetooth connection to the recording computer.
two of the subjects whose eda signals were undetectable also exhibited problems with the mindband thus we were not able to record their mindband either.
we then calibrated the subjects eye gaze using tobii studio s point calibration program.
we recalibrated any points that showed too much error.
finally we began the experiment.
7the subjects were asked to watch the first fish tank video and 8start their first task.
9after each task the subjectsweregivenapaper basednasatlxsurveyinstrument to fill out that asked them to first rate the task from along six dimensions mental demand physical demand temporal demand performance effort and frustration and then compare each dimension with one another to determine the rank order of their importance.
10afterward they watched the next two minute fish tank video and continued to the next task.
11once the subjects finished their last task and nasa tlx survey we removed all of the psycho physiological sensors and turned off the recordings.
12finally we had them fill out a post test questionnaire where they ranked the tasks they did according to the their own hind sight perception of the tasks difficulty.
subjectswere able to go back and refamiliarize themselves with the task codes before ranking them.
.
experimental conditions every subject was expected to complete all ten tasks first the two practice problems and then the eight experimental tasks.
to combat any kind of learning effects caused by experience with the tasks we counter balanced the task order so that each subject took them in a different order.
on average it took the subjects minutes sd minutes to complete a task.
the fastest subject completed one task of the second kind in seconds.
the slowest subject completed one task in minutes also of the second kind.
overall each subject took about .
hours to complete the entire experiment.
some subjects failed to complete all the tasks before they had to leave.
two missed the final task and one missed the last two tasks.
fortunately we had no measurement difficulties with these three subjects.
.
data analysis we collected psycho physiological measurements for a total of tasks.
we present an overview of each sensor s measurements along with their related cognitive effects in table .
a detailed list of every measurement we used from the sensors is in table .
for each subject s tasks we also collected the completion time the nasa tlx score whether their answer was correct and the difficulty rank they gave that task at the end of the study.
we used the video recordings and the thinkaloud protocols to fix any inadvertent mistakes we made during data analysis which we describe next.
.
data cleaning and transformation biometric data is notoriously noisy and contains large amounts of invalid data that must be cleaned before it can be analyzed.
eye tracker.
first for each data point produced by the eye tracker an indication of the validity of the pupil size measurement enabled us to remove the invalid ones.
second we noticed that the first pupil size measurement of each fixation occurring after a blink was suspiciously larger than the subsequent one measured just .
ms later .
we learned that when your eyes close even for a short time the darkness causes your pupils to open just a little bit.
to eliminate this artifact we ended up eliding each of the first pupil size measurements after a blink.
next we compared the distribution of pupil sizes between subjects.
we discovered that while each subject s pupil size distribution was gaussian the range of pupil sizes was very different.
consequently to make subjects easier to compare we standardized the pupil size measurement within participants by subtracting the mean from each value and dividing the difference by the standard deviation.
pupil size tends to increase up to .
mm under cognitive load especially when reading difficult material.
to find these events we use a matlab based peak finding algorithm to count the number of peaks in the pupil size signal where the pupil size increased at least .
.
and .
mm above its baseline.
the baseline is calculated from the minimum and maximum pupil sizes gathered during each task as well as the prior one minute during the fish tank video.406table overview of psycho physiological measurements and the effects related to them in literature.
measure previously found effect eyetracking pupil size cognitive load memory load mental workload saccades mental workload while air traffic control tasks evaluation of user interfaces fixations cognitive load while solving arithmetical tasks performance during a code review effort to identify variable identifiers eeg eye blinks visual attention stress and anxiety level classification of visual demanding tasks during flight mental workload while air traffic control tasks mental workload during arithmetic and visual tracking tasks frequency bandsmental workload during air traffic control tasks mental workload during arithmetic and visual tracking task cognitive task classification auditory awareness alpha beta gamma delta theta ratios of frequency bands memory load during cognitive task task engagement index car driver status in various conditions attention and meditation cognitive load eda tonic anger and fear mood states of bipolar patients mental workload arousal and engagement phasic anger and fear distinguish stress from cognitive load arousal and engagement table psycho physiological measurements used from each of three sensors abbreviated represents the difference to the baseline .
eyetracking numsaccades min sumsaccadeduration min mean median stdev saccadeduration numfixations min sumfixationduration min mean median stdev fixationduration minpupilsize maxpupilsize mean median stdev pupilsize numpupilsizejumps .1mm .2mm .4mm eeg min max attention min max meditation mean stdev attention mean stdev meditation eyeblinks min eda min max peakampl numphasicpeaks min meanphasicpeakampl sumphasicpeakampl min meanscl aucphasic people s eyes move in small jerky movements called saccades which each take under ms. someone can only read text when their eye fixates on a location between saccades.
we extract the number and duration of a subject s eye saccades and fixations to gain insight into how their eye motion is impacted when reading material with various cognitive demands.
since every subject works at their own pace we normalize many of our measurements by time to make them comparable between subjects.
eda.eda signals consist of two parts a low frequency tonicsignal which changes over a period of minutes and a higher frequency phasicsignal which takes seconds to rise and seconds to fall.
the tonic component of the eda signal or skin conductance level scl is commonly used as a measure of arousal.
the phasic component reflects reactions based on external stimuli .
to clean our eda signal we first subtracted the signal s dc component to base it at 0 s. we found a lot of noise in the signal from 2hz to 4hz so we applied an exponential smoothing filter x t x t .
.
next we used a 5th order low pass butterworth filter set to .05hz to extract the tonic signal.
since the maximum frequency of a phasic response is .33hz the inverse of seconds we must extract the phasic signal at .66hz the nyquist sampling rate is twice the maximum frequency to ensure we see the entire phasic response.
fortunately the exponential smoothing we applied already eliminated the signal above0.66hz so we were able to use a high pass version of the same butterworth filter to extract the phasic signal.
thetonicsclvaluemustbemeasuredrelativetoarecent baseline value.
we calculate it by subtracting the mean scl of the eda signal while the subject watched the fish tank videofromtheonemeasuredwhilethesubjectdideachtask.
the literature distinguishes between spontaneous changes intheedasignal callednon specificskinconductanceresponses ns scrs andchangesthatoccurafteraspecific stimuli called event related skin conductance responses er scrs .
these changes are visible as peaks in the phasic signal which we found with a matlab based peak finder set to identify peaks with a minimum amplitude of 2ns .
while ns scrs occur all the time the only external stimuli the subjects could have experienced must have come from what they read during their program comprehension tasks.
thus we can compute the likely number of er scrs by subtracting the number of peaks experienced during the experimental task from the preceding one minute time period while they watched the fish tank video.
we also use the peak finder to extract additional features from the signal including the peak amplitude frequency and area under the curve auc and normalize these by time.
eeg.the eeg sensor produces a raw signal sampled at 512hz.
we first use a matlab based 60hz notch filter to remove signal noise caused by the overhead lights.
to identify various mental states we use matlab s pwelch function407to compute the power spectrum distribution for each of the five familiar brain wave frequency bands alpha hz beta hz gamma hz delta 4hz and theta 8hz .
sinceeverypersonhas a unique power spectrum distribution we compute the ratio ofeachbandwithoneanotherinordertocomparethevalues between individuals.
in addition inspired by kramer and lee we compute beta alpha theta andtheta alpha beta as additional measures of task difficulty.
we found an additional use for the eeg sensor.
due to itsplacementontheforehead thesensor isexquisitelysensitive to the motor signals of the face such as brow furrowing eyebrow motion and blinking.
each of these motor activities produces a high amplitude low frequency signal which is easy to distinguish from neuronal activity.
brookings et al.showed that a person s blink rate decreases significantly when tasks become more difficult .
taking advantage of a technique illustrated by manoilov we use a band pass butterworth filter to filter our eeg signal from .5hz to 3hz and apply our matlab based peak finding algorithm to find peaks that are over 100x stronger than the waveform s average amplitude.
these peaks correspond to eye blinks.
we calculate the number of blinks per minute and then subtract out the baseline number of blinks during the subject s prior viewing of the fish tank video.
finally we extract the pre computed 1hz attention and meditation signals from the neurosky eeg sensor and compute the mean median standard deviation minimum and maximum values for our analysis.
.
outcome measures we used two outcome measures in our tasks the nasa task load index tlx filled out on paper after each task andasubjectiverankingoftasksbasedonthesubject s post hocperceptionoftheirdifficultyattheendoftheexperimental session.
the nasa tlx is a commonly used subjective measure for assessing cognitive load .
after each task the subject rates its difficulty on six point scales performance good poor mentaldemand low high physicaldemand low high temporaldemand low high effort low high andfrustration low high .
eachscaleisdefined for the subject using hart and staveland s instructions along with a discussion of their meaning with the experiment administrator.
after marking the six ratings the subject then considers every possible pair of scale names and is instructed to circle the scale name in each pair which is more important to his experience of workload than the other.
we compute the overall nasa tlx score to be the sum of the products of each rating and the tally of the number of times it was chosen as more important and then divided by .
three of the authors computed these scores at different times during analysis to ensure we transcribed and calculated them properly.
while the nasa tlx score gives us insight into the subject s mental workload for each question we were interested in a measure of the subject s summative assessment of task difficulty.
to this end we asked each subject to rank the ten tasks he did from easy to hard ties were acceptable .
a few subjects wrote down additional comments to clarify how they thought about the difficulty e.g.
the rectangle tasks were difficult because i am terrible at spatial relations in my head.
.to make prediction simpler for our machine learning algorithm we nominalized the task difficulty ranking as easy or difficult.
low ranks were changed to easy and high ranks were labeled difficult.
for scores in the middle we looked at each subject s additional comments and found that in all but two cases out of subjects clearly expressed where there was an easy difficult gap in their perception of the tasks difficulty.
for the other two cases we were able to use the nasa tlx score to disambiguate in favor of correlation because there the nasa tlx score was clearly unambiguous.
after nominalizing the task difficulty ranking our dataset consisted of difficult and easy tasks.
to validate the task difficulty ranking we confirmed that therewasahighcorrelationbetweenthetaskdifficultyranking and the nasa tlx scores.
a spearman correlation shows that the nasa tlx score is correlated with the subjects taskdifficultyrankings r .
p .
.
the nasa tlx easy difficult boolean was also similar to the task difficulty easy difficult boolean 2 .
p .
with an accuracy of .
as a final step in validating the task difficulty ranking we looked at the correlation between the ranking and task completion time since time on task is also a proxy for difficulty .
a spearman correlation of r .
p .
supports this correlation and thus our choice of task difficulty ranking for our outcome measure.
.
machine learning machine learning has been shown to be a promising approachtofindlinksbetweenlow leveldatacaptureandhighlevel phenomena of interest .
we used weka a popular java based machine learning classification toolkit to develop a set of classifiers that can connect our psychophysiological measures with task difficulty.
there were a number of parameters that could affect the design of the classifier we wished to develop.
first and foremost was a choice between three types of predictions by participant by task and by participant task pair.
the byparticipant classifier would be the most useful in practice trained on a small set of people program comprehension tasks it could be applied to any new person new tasks and still accurately assess task difficulty.
next in utility is the by task classifier when trained on people a set of tasks it would work well when applied to one of those people any new task.
finally the by participant task pair classifier shows the proof of concept trained on a set of people programming tasks it can predict the difficulty of the task as perceived by one of those people a task that the rest already did.
these three predictions were used to stratify the datasets into test and training sets.
second was the choice of classification algorithm.
we considered naive bayes a j48 decision tree using weka s implementation of c4.
and a support vector model.
for our goal of an instantaneous classifier naive bayes was the best choice because of the ease in which its training can be updated on the fly improving its performance as it adjusts to its user.
third we can train the classifier on the entire set of data from each participant and task or divide up the data collection into sliding time windows.
this would enable us to create a classifier usable before a developer finished his task that would adjust to his changing psycho physiological conditions.
we divided up our data using sliding time win 4085s10s15s20s25s30st10s10s10s10s10sfigure sliding windows of size seconds with second offsets.
dows of sizes from seconds to seconds sliding seconds between intervals.
a demonstration of this is shown in figure .
finally the last parameter to the machine learning algorithm is to identify the best set of measurements features that will be used to train the model .
we chose to experiment with measurements extracted from every combination of our three sensors possible sets of features .
to ensurecorrect performance fornaive bayes weremovedfive measurements that correlated almost perfectly with measurements we left in.
.
results this section reports the results of our use of machine learning to define classifiers to predict task difficulty.
.
task difficulty classification to evaluate whether we can use psycho physiological measures to predict if a task is easy or difficult rq1 we perform a post hoc analysis that applies machine learning to the data gathered over the whole task period.
we used a leave one out strategy to create an exhaustive set of test and training folds to train classifiers using all of the sensors for each stratification by participant by task by participanttask .
the average precision recall and f measure for the three classifiers we trained is shown on the last row of each sectionintable3.
thebestoverallperformancecomeswhen predicting a new task with .
precision and .
recall.
.
evaluating sensors next we wished to find out how well each of the three sensors eye tracking eda and eeg could be used to predict task difficulty rq2 .
we trained classifiers on each combination of sensors creating training and test sets for all three predictions by participant by task by participanttask over the entire dataset.
the results are shown in table .
considering each sensor by itself the eye tracker has the best predictive power for new participants .
fmeasure .
whenpredictinganewtask eeghasthehighest precision .
but the eye tracker has the best recall .
.
when predicting a participant task pair the eyetracker comes out on top .
f measure .
combinations of sensors performed better when predicting new tasks all sensors and participant task pairs eye tracker eda .
we investigated whether eliminating features from each sensor could help improve the accuracy of our classifiers.
we used weka s cfssubseteval algorithm to analyze the features for each sensor combination and keep those that correlated highly with the outcome variable and poorly with other features.
in some cases this yielded better performance on our data e.g.
eda eeg f measure rose fromtable performance characteristics of classifiers trained on the entire dataset over data from all possible combinations of three sensors to predict a participant a task and a participant task pair.
the best measurements for a prediction are bold.
prediction sensors precision recall f measure by participanteye .
.
.
eda .
.
.
eeg .
.
.
eye eda .
.
.
eye eeg .
.
.
eda eeg .
.
.
eye eda eeg .
.
.
by taskeye .
.
.
eda .
.
.
eeg .
.
.
eye eda .
.
.
eye eeg .
.
.
eda eeg .
.
.
eye eda eeg .
.
.
by participant taskeye .
.
.
eda .
.
.
eeg .
.
.
eye eda .
.
.
eye eeg .
.
.
eda eeg .
.
.
eye eda eeg .
.
.
.
to .
however running anova tests on the weka output failed to show any significant differences between the original and shrunken sets of features.
thus the improvement we saw may be an artifact of our dataset capturing additional input data would help establish whether feature elimination will truly improve performance.
.
evaluating time windows finally to see if we could build a classifier that would be accurate if receiving streaming data from the sensors as the developer worked we built a set of classifiers trained on sliding time windows rq3 .
however we needed to find out which time window sizes would work the best.
in some cases the window size was longer than the task data so we just included the time windows that were available.
figure2presentstheprecisionforeachclassifiertrainedona particulartimewindowsizeusingalloftheavailablesensors.
there appears to be no major differences in the performance of that classifier over the various time windows.
however we calculated the effects of combining a subset of sensors along with the use of sliding time windows.
we found the best classifier for predicting new participants to usejusttheeye trackerandtheedasensorwithatimewindow size of seconds.
this performed at .
precision and .
recall which is just a tiny bit better than using allthreesensorsorjusttheeye tracker.
forpredictingtasks the best classifier used just the eda sensor with a second time window and got a precision of .
and a recall of .
.
this performs better than using all three sensors on sliding time window data but not better than when trained on the entire dataset.
when predicting a participant task the best classifier used the eda and eeg sensors with a time window of seconds.
this achieved a precision of .
and a recall of .
which is better than both using all of the sensors and the entire dataset.
.
discussion the results of our machine learning experiments answer rq1 demonstrating that it is possible to very accurately predict whether a task is easy or difficult using psycho 409by participant by task by participant task figure precision and recall using all sensors over time windows of seconds.
physiological measures.
using all of the task data a classifier trained on the three sensors achieves .
precision and .
recall when predicting our nominalized task difficulty measure for new participants.
the performance increases to .
precision and .
recall when predicting new tasks likely because the classifier has had a chance to see the participant in action on other tasks.
for predicting participant task pairs the precision and recall both settle at .
.
answering rq2 when we checked which combinations of sensors had the best predictive power we found that for predicting a new participant the eye tracker did the best .
precisionand65.
recall whenpredictinganew task the combination of all three sensors was best .
precision and .
recall and if predicting a participanttask pair the pair of eye tracking and eda sensors was best .
precision and .
recall .
thus for predicting new participants and new participant task pairs it may be better to use a subset of the sensors available to achieve better performance and save money!
.
when we measured the predictive power of classifiers that use sliding time windows we found that for predicting new participants the best classifier using all three sensors uses a time window of seconds and reaches .
precision and .
recall.
the best classifier for predicting a new task uses a second time window and reaches a precision of .
and a recall of .
.
finally for predicting a participant task pair the best classifier uses a time window of seconds and achieves a precision of .
and a recall of .
.
compared with using the entire dataset dividing the data into sliding time windows is beneficial for predicting new participants and participant tasks but not for predicting new tasks.
when we combined the use of sliding time windows with subsets of sensors we found it possible to improve the precision and recall slightly compared with using the entire dataset and all of the sensors.
the big improvement came for predicting a participant task pair with just the eda and eeg sensors our two lowest cost sensors and a time window of seconds.
our work provides an existence proof that answers rq3.
itispossibletouselow cost off the shelfpsycho physiological sensors to develop accurate classifiers.
the existence of such anindicatorshouldprovidemanyopportunitiesfornewsoftware engineering tools.
for instance it could be used to detect the places in the code that developers have difficultieswith while working and mark them for review or for future refactoring.
as pointed out by bailey and iqbal it could also help prevent interruptions during particularly difficult tasks which might require a longer task resumption time .
.
threats to v alidity we describe several threats to the validity of our study in this section.
external validity.
while we feel these results should be generalizable to other kinds of short code comprehension tasks more work remains to be done to validate our classifier against tasks that are longer contain more code and involvecodecreationandmaintenance.
wemitigatedthisrisk somewhat by carefully constructing the tasks to vary their difficulty and effects on various brain functions according to pastempiricalresults onprogrammers .
wedonotclaim that these results are generalizable to students novice software developers or other broader populations but feel that our use of professional developers situates this work within a population that creates most of the software in the world.
internal validity.
during the study the participants were required to complete a series of small tasks of varying difficulty.
we counter balanced the task order to combat learning effects but did not have a large enough population to explore every possible order.
thus some learning effects may have gone unnoticed.
our study took place in a lab setting thus our subjects may have performed differently than in their own work environments.
since the typical effect of lab studies on subjects is to increase their performance due to their desire to please the experimenter they may have experienced less task difficulty than normal.
while the tasks in our study were not very long only several minutes we believe the subjects behavioral responses interpreted with their think aloud narrative to be fairly typical of software developers working on their own longerterm tasks.
as noted in section .
even short lab based experimental tasks like ours can be designed to provoke cognitive difficulties in many of the different functional brain regions that comprise software development skills.
more experiments will be required to establish whether the trends we have seen in our data apply to different programming tasks.
while there is great individual variability in the performance of software developers which we also observed in ourexperimentalsubjects thereapparentlywasnotenough in the sensor data to impede accurate classification.
a study410with a larger and more diverse sample of developers should be able to tell us whether the classifiers will be confounded or confirm their generalizability.
even if the classifiers fail to generalize due to individual participant variation our use of the naive bayes algorithm will support performance improvement through additional classifier training by the participant while he works.
given the great number of hours that developers spend in front of their computers and the potential utility of such an instantaneous classifier of task difficulty training classifiers for each individual programmer to improve accuracy should be a palatable tradeoff.
construct validity .
the goal of this study was to investigate the predictive power of multiple psycho physiological measures for task difficulty.
a threat to the study is that there are other factors that might either influence the perceived task difficulty or psycho physiological measurements unrelated to task difficulty itself.
these include personality traits private and professional stress or even the time of day.
we tried to mitigate the risk by providing the same quiet environment for every subject but we may need to investigate these effects in the future.
second to make predictions simple for our machine learning approach we categorized the task difficulty ranking into easy or difficult.
this binary classification might have lead to better results than if we had used the original interval scale.
third our tasks were constructed to be varying shades of difficult but this is really subjective.
we triangulated this difficulty using not just a retrospective ranking of tasks by difficulty but also through the commonly used nasa tlx score.
these measures correlated together quite well especially when both were converted to nominal form.
thus we do believe that our task difficulty construct is quite valid.
.
conclusion softwaredevelopersregularlyexperiencedifficultiesintheir work that waste their time and may cause them to introduce bugs into their software.
previous research focused on identifying bug risk using correlations between defects and various software process metrics.
our research however is the first to investigate an automated approach using psycho physiological sensor data to detect both post hocand as the developer works whether a developer perceives that his program comprehension task is difficult.
our experimental results show that we can train a naive bayes classifier on short or long time windows with a variety of sensor data to predict whether a new participant will perceive his tasks to be difficult with a precision of over and a recall over .
our results also demonstrate that it is possible to use fewersensorsandstillretaintheabilitytoaccuratelyclassify task difficulty.
now that we have shown that these classifiers can be built researchers can leverage them to develop novel programming support tools allowing them to potentially intervene in time to stop bugs from entering the code.
.