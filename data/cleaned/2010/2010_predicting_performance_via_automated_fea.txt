predicting performance via automated feature interaction detection norbert siegmund sergiy s. kolesnikov christian k astner sven apel don batory marko rosenm uller and gunter saake university of magdeburg germany university of passau germany philipps university marburg germany university of texas at austin usa abstract customizable programs and program families provide user selectable features to allow users to tailor a program to an application scenario.
knowing in advance which feature selection yields the best performance is difficult because a direct measurement of all possible feature combinations is infeasible.
our work aims at predicting program performance based on selected features.
however when features interact accurate predictions are challenging.
an interaction occurs when a particular feature combination has an unexpected influence on performance.
we present a method that automatically detects performance relevant feature interactions to improve prediction accuracy.
to this end we propose three heuristics to reduce the number of measurements required to detect interactions.
our evaluation consists of six real world case studies from varying domains e.g.
databases encoding libraries and web servers using different configuration techniques e.g.
configuration files and preprocessor flags .
results show an average prediction accuracy of .
i. i ntroduction there are many ways to customize a program.
commonly a program uses command line parameters configuration files etc.
.
another way is to derive tailor made programs at compile time using product line technology.
in product line engineering stakeholders derive tailored programs by means of a program generator to satisfy their requirements .
the generation process is based on features where a feature is a stakeholder visible behavior or characteristic of a program .
by mapping features to implementation units a generator produces a program based on a user s feature selection.
in this paper we use product line terminology and call any customization option that stakeholders can select at compiletime or load time a feature of a program.
stakeholders are also interested in non functional properties of a program.
for example a database management system is usually customized to achieve maximum performance when used on a server but is customized differently for low energy consumption when deployed on a batterysupplied system e.g.
on a smartphone or sensor node .
besides the target platform other factors influence nonfunctional properties of a program.
database performance depends on the workload cache size page size disk speed reliability and security features and so forth.
non functional properties can be customized by selecting a specific set offeatures called a configuration that yields a valid program.
however finding the best configuration efficiently is a hard task.
there can be hundreds of features resulting in myriads of configurations optional and independent features yields a configuration for each human on the planet and optional features yields more configurations than there are estimated atoms in the universe.
to find the configuration with the best performance for a specific workload requires an intelligent search brute force is infeasible.
we aim at predicting a configuration s non functional properties for a specific workload based on the user selected features .
that is we aggregate the influence of each selected feature on a non functional property to compute the properties of a specific configuration.
here we concentrate on performance predictions only.
unfortunately the accuracy of performance predictions may be low because many factors influence performance.
usually a property such as performance is program wide it emerges from the presence and interplay of multiple features.
for example database performance depends on whether a search index or encryption is used and how both features operate together.
if we knew how the combined presence of two features influences performance we could predict a configuration s performance more accurately.
two features interact if their simultaneous presence in a configuration leads to an unexpected behavior whereas their individual presences do not .
today developers detect feature interactions by analyzing the program e.g.
source code or control flow or specification of features .
these and similar approaches require substantial domain knowledge exhaustive analysis capacities or availability of source code to achieve the task.
furthermore each implementation technique e.g.
configuration options ifdef statements generators components and aspects requires a specialized solution.
to the best of our knowledge there is no generally applicable approach that treats a customizable program as a black box and detects performance feature interactions automatically.
we improve the accuracy of predictions in two steps i we detect which features interact and ii we measure to what extent they interact.
in our approach we aim at finding the sweet spot between prediction accuracy generality in terms of a black box approach and measurement effort.
acm .
this is the author s version of the work.
it is posted here by permission of acm for your personal use.
not for redistribution.the distinguishing property of our approach is that we neither require domain knowledge source code nor complex program analysis methods and we are not restricted to special implementation techniques programming languages or domains.
overall we make the following contributions an approach for efficient in terms of measurement complexity automated detection and quantification of performance feature interactions to enable an accurate prediction of a configuration s performance.
an improved tool called spl conqueror to measure performance detect feature interactions and predict performance in an automated manner.
a demonstration of practicality and generality of our approach with six customizable programs and product lines from different domains programming languages and customization mechanism.
a percent prediction accuracy when feature interactions are included which is a percent improvement over an approach that takes no interactions into account.
in contrast to our previous work we do not rely on domain knowledge reduce the effort for pairwise measurement measure and predict performance instead of footprint size incorporate higher order feature interactions and evaluate our approach with additional industrial product lines.
ii.
a m odel of feature interactions our work relies on a recent model of feature composition .
if program pconsists of features a b andc w e write p a b cwhere denotes the associative and commutative composition of features.
evaluating a b c generates p. features interact features that perform one way in isolation may behave differently when other features are present interactions may affect semantics as well as in our case performance of the overall system.
a classic example is a flood control fc sensor working with a fire alarm fa sensor .
if only one of fcorfais present the behavior is unambiguous water is turned on when fire is detected and turned off when a flood is detected.
when fcandfaare both present there is an interaction fc fathat turns water off after the fire sensor turned water on to prevent a fire.
in code we make this interaction explicit such that we can control this interaction with an appropriate behavior.
nevertheless the interaction is present whether we handle it or not.
more generally if a program pcontains features aandb it should also include the interaction a b. basic mathematics encodes these ideas.
when a stakeholder wants features a andb s he also wants their interaction a b because a b says how aandbare to work correctly together e.g.
keeping water on when fire and flood are detected .
the associative 1henceforth capital letters denote compositions of one or more terms lowercase letters aare terms features or feature interactions .and commutative operation expands a given configuration to all feature terms and all feature interaction terms a b a b a b that is a program does not only contain the behavior of each individual feature but also the interaction behaviors among all features.
many of these feature interactions have no observable effect only some of them are relevant.
in this paper we propose heuristics to detect only the relevant performance feature interactions.
to relate the above abstract model to performance prediction we state that performance of a feature composition a b be the sum of their individual performance values a b a b from and we estimate p s performance as follows p a b c a b c a b a c b c a b c a b c a b a c b c a b c to improve prediction accuracy we need to determine the influence of an interaction on performance.
we use a basic result that follows from and .
if we can measure a performance value for a and b we certainly can measure the value of a b .
we therefore know the value of a b a b a b a b here is the challenge a product of nfeatures yields o 2n terms.
we cannot compute a value for each term as this is infeasible for anything beyond programs with few features.
furthermore assumes that we can measure the performance influence of each feature in isolation.
this is not always possible.
we avoid both problems by composing multiple terms that cannot be separately measured as a single term called a delta .
given a base configuration c we compute the impact of a feature aonc s performance as the performance delta induced by feature a ac a c c from and an equivalent definition of acis ac a c c a c a c c a c a that is acis the performance contribution of aby itself plus the performance contributions of a s interaction with all 2commutativity and other axioms of sequential interaction and product composition are spelled out in details beyond what is presented here are non essential to this paper.
3as a limitation of this approach we require additivity of performance measurements.terms in c. ifcis the empty set then ac a .
if cis a product of ifeatures acis a sum of o 2i terms.
as we demonstrate in subsequent sections knowing ac for some cis often sufficient to accurately predict the performance of programs that include a. we do not need to assign values to each of ac s terms we measure only two variants of instead of 2iterms.
herein lies the key to the efficiency and practicality of our approach.
iii.
p redicting performance we predict performance and other non functional properties by measuring the influence of each feature its delta and summing the deltas for all relevant features.
with few measurements linear complexity in the number of features we can predict performance of all configurations exponential in the number of features .
although the approach is simple it yields surprisingly good results.
the general concept of quantifying the influence of each feature on performance is as follows for each feature a we find a configuration min a that is minimal in the number of features such that min a does not contain aand bothmin a anda min a are valid configurations.4we determine each feature s delta as amin a min a min a consider the feature model in figure which has five features.
the minimal configuration for each feature is feature min b i b t b e b db e we need only five measurements to determine the influence of each feature all values in our example are measured in transactions per second bmin b imin b i b tmin b t b emin b e b dmin b e d b e 4features may not be independent such that we cannot measure arbitrary configurations.
we explored calculating deltas in the presence of complex domain dependencies previously .
it is outside the scope of this paper.
with constraints between features in principle there can be multiple minimal configurations for example in the presence of mutually exclusive features .
in this case we use any minimal configuration.
furthermore we admit the empty or null program as a minimal configuration when determining the performance of a root feature.
5a feature model a standard idea in product line engineering defines features and their relationships.
features are decomposed into a hierarchical structure and are marked as mandatory optional or mutually exclusive.
to select a child feature the parent feature must be selected.
a configuration is valid if its feature selection fulfills all constraints i.e.
arbitrary propositional formulas of the feature model.i t e b bt tb i index t transactions e encryption d decryption b base measured values are transactions per second.ib eb i tb i ttb idbmsmandatory optionalfeature be ibit bitb tbd i t e bdbms dimplies implies i t e bdbms d impliesdb ebed b be ib figure .
measuring deltas for features and interactions.
to predict the performance of a configuration we simply add the deltas of all relevant features.
for example for configuration b t i we predict bmin tmin imin .
unfortunately this prediction scheme is inaccurate.
as mentioned earlier when measuring feature deltas we might obtain very different results when using different configurations.
consider figure 1b which computes the delta for feature tfor a different configuration.
our first value computed above was tmin whereas the newly computed value is tb i .
consequently predictions for the same configuration b t iwill differ when using tmin or tb i .
the difference is due to feature interactions.
detecting and quantifying the influence of interactions allows us to overcome the differences among different deltas leading to consistent predictions.
the question is which features interact that cause this discrepancy?
if we know that two features interact we can improve our prediction by measuring the delta for their interaction.
suppose configuration chas both features aandb.
the contribution of the interaction of aandbtocis a b c a b c c a b c a b c c a b a b c similar to the delta of a feature the delta of interaction a b includes the interaction a band all interaction terms of a b with terms in c. in figure 1c we illustrate such a measurement forinteraction i t. knowing the interaction s delta improves our predictions in our example it patches the value of tmin.
if more than two features interact a.k.a.
higherorder interactions we proceed in a similar way.
the challenge is how to find interactions that actually contribute to performance out of an exponential number of potential interactions.
iv .
a utomated detection of feature interactions our goal is to identify feature interactions automatically using a small number of measurements.
our approach consists of two steps identifying features that participate in some interactions called interacting features and finding minimal combinations of features that actually cause a feature interaction.
we use the setting from figure as our running example.
a. detecting interacting features our first step is to identify features that interact.
the rationale is to reduce our search space.
for example suppose a program has features in which features interact the rest do not.
we have to look only at instead of configurations to detect interactions.
in the presence of interacting features the delta for a featureadiffers depending on which base configurations it was measured with.
we say aisnot an interacting feature if acis the same for all possible base configurations c within some measurement accuracy .
conversely if ac changes with different configurations of c we know that a is interacting.
we express this as ainteracts c d c negationslash d ac negationslash ad to avoid measuring acfor a potentially exponential number of configurations of c we use a heuristic.
we determine the deltas of athat are most likely to differ because it is affected by the largest number of feature interactions we compare amin the delta for the minimal configuration with amax a delta for a configuration with most features selected.
let max a anda max a be two valid configurations such that max a does not contain a and is a maximal set of features that could be composed witha.
we call max a amaximal configuration .
amax is their performance difference amax a max a max a the rationale of determining max a is that it maximizes the number of features that could interact with a. consequently if amin and amax are similar then adoes not interact with the features that are present in max a but not inmin a .
otherwise ainteracts with those features we do not know yet with which features and to what extent .
thus with at most four measurements per feature two for 6we allow the empty set as a valid configuration.
this is necessary to create a maximal configuration for mandatory features.
aminusing a min and min and two for amax using a max and max we discover interacting features.
in our running example we determine the following maximal configurations and assume the following corresponding measurements feature max max ib t e d tb i e d eb i t db i t e notemax e does not include d a sdrequires efor a valid configuration figure .
with these additional measurements we compute the additional deltas as follows with six measurements imax i max i max i tmax t max t max t emax e max e max e dmax d max d max d we conclude that features iandtare interacting imin negationslash imaxsince negationslash tmin negationslash tmaxsince negationslash emin emaxsince dmin dmaxsince we know that feature iinteracts with a feature in the set max i min i .
from these candidate features we can exclude features b e andd because their deltas do not change.
feature tremains the only candidate for interaction.
the same conclusion is reached had we analyzed feature t concluding feature iis the only possible interaction candidate .
in this way we found the feature combination that causes an interaction.
note that if we find more than two interacting features we have no information which feature combination causes an interaction.
this is the goal of the next step.
b. identifying feature combinations causing interactions after detecting all interacting features we have to find the specific valid combinations that actually have an influence on performance.
suppose we know that features a b andc are interacting.
we have to identify which of the following interactions have an influence on performance a b a c b c o ra b c. again we do not want to measure all combinations whose number is exponential in the number of interacting features .
7of course there is an obvious situation that we can not detect when two interactions cancel each other e.g.
one has influence 4and another one we will not detect them.
we have no evidence that this situation is common but we are aware of its existence.
8surprisingly max b is an empty configuration because feature bis mandatory the only valid configuration without feature bis the empty set.we use three heuristics.
each makes an assumption under which it can detect interactions thus improving performance prediction with a few additional measurements.
some heuristics are based on the experience we gained during the manual analysis of feature interactions i.e searching the source code for nested ifdef statements using domain knowledge etc.
for the prediction of a program s binary footprint .
other heuristics are based on assumptions we make due to analyses of source code feature interactions and on related work see section vi .
we explore in our evaluation whether our heuristics actually reduce measurement effort and improve accuracy of our predictions.
auxiliary implication graph in all three heuristics we reason about feature chains in an implication graph.
animplication graph is a graph in which nodes represent features and directed edges denote implications between features.
using implications we conclude that aminalways includes the influence of all interactions with features implied by a i.e.
all features in a s implication chain .
for example if feature aalways requires the presence of featureb then we have implicitly quantified the influence of interaction a bwhen computing amin.
this mechanism reduces computation effort in all heuristics especially for hierarchically deep feature models and for feature models with many constraints.
heuristic pair wise interactions pw we assume that pair wise or first order interactions are the most common form of performance feature interactions.
we justify this assumption as follows related research often uses a similar approach the software test community often uses pair wise testing to verify the correctness of programs .
pair wise testing was also applied successfully to test feature interactions in the communication domain and to find bugs in product line configurations .
furthermore analysis of variability in largescale programs showed that structural interactions are mostly between two features although structural interactions do not necessarily cause performance feature interactions we assume that this distribution also holds for performance because the additional code may have some affect on performance.
within the set of interacting features we use this heuristic to locate pair wise interactions first as they are the most common .
we search for higher order interactions with the remaining heuristics.
heuristic composition of higher order interactions ho we assume that second order feature interactions i.e.
interactions among three features can be predicted by analyzing already detected pair wise interactions.
the rationale is if three features interact pair wise in any combination they likely also participate in a triple wise interaction.
that is if we know that two of these three interactions a b b c a c are non zero then and only then will we check whether a b chas an influence onperformance.
for example if both a bandb callocate gb ram then it is likely that there is an interaction a b cthat results in a lower performance because gb ram was allocated .
we experienced this phenomenon in previous work on measuring and predicting footprint .
a different footprint may also indicate a possible impact on performance because either functionality is added increased footprint or is removed decreased footprint .
this added or removed functionality can cause performance deviations.
we do not consider other higher order interactions to save a huge number of measurements.
thus we might miss some interactions in attempt to balance measurement effort and accuracy.
heuristic hot spot features hs finally we assume the existence of hot spot features.
we experienced that there are usually a few features that interact with many features and there are many features that interact only with few features.
high coupling between features or many dependencies can impact the performance of the whole system because both features strongly interact with each other at the implementation level.
these observations are analogous to previous work on coupling in feature oriented and object oriented software and footprint feature interaction .
we anticipate the same distribution for performance feature interactions following a power law .
using this heuristic we perform additional measurements to locate interactions of hot spot features with other interacting features.
specifically we attempt to locate secondorder interactions for hot spot features because they seem to represent a performance critical functionality in a program.
we do not identify interactions with an order higher than three because this increases measurement effort substantially.
c. realization so far we described a general approach to detect interacting features and to find feature combinations that cause interactions.
next we detail how we implemented these techniques and heuristics in our tool spl conqueror as an underlying data structure we use an implication graph as described earlier.
we can easily generate this graph from a feature model using a sat solver .
to locate pair wise interactions pw heuristic we consider only pair wise interactions between interacting features of different implication chains.
we do not need to determine interactions of features belonging to the same implication chain because the interaction is already included in amin.
furthermore the order of the measurements is crucial.
our algorithm starts from the top of one implication chain and determines the influence of interacting features with the interacting features of another chain also starting from the top.
afterwards we continue with the next chain.
for example in figure the order we use to detect pair wisef2 f3 f4f1 f5 f7 f8f6f9 f11 f12f10fbase implication chainsinteracts implies f1interacting feature f2non interacting feature figure .
implication chains with interacting features.
interactions is f1 f6 f1 f7 f4 f6 f4 f7 f6 f11 f7 f11 f1 f11 f4 f11.
to identify whether two features aandbinteract we compare the measured performance a b with the performance prediction of the same configuration that includes all known feature interactions up to this time.
if the result of a bcexceeds a threshold e.g.
we use the standard deviation of measurement bias as a threshold we record it.
next we search for second order interactions among features that interact in a pair wise fashion ho heuristic .
again we perform additional measurements and compare them to the predicted results.
for example if we noticed that f1interacts with f7andf7interacts with f14 we would examine whether interaction f1 f7 f14has an influence on performance.
finally we search for further second order interactions involving hot spot features hs heuristic .
we count the number of interactions per feature identified so far.
next we compute the average number of interactions per feature.
we classify all features that interact above the arithmetic mean as hot spot features other thresholds are possible too .
with hot spot features we search with the usual mechanism additional measurements comparing deltas for interactions involving a hot spot feature a feature that already interacts with this hot spot feature and an interacting feature that does not interact pair wise with the hot spot feature.
v. e v aluation our approach to performance prediction is simple.
but it is the simplicity that makes it practical.
we demonstrate this with six real world case studies.
the goal of our evaluation is to judge prediction accuracy and the utility of our heuristics.
that is we analyze how we detect performance feature interactions with additional measurements and how detected interactions improve prediction accuracy.
to that end we compare predictions with actual performance measurements.
a. experimental setting we selected six existing real world programs i.e.
three customizable programs and three product lines with differentproject domain lang.
loc features configs berkeley db ce database c berkeley db je database java apache web server c sqlite database c llvm compiler c x264 video enc.
c table i overview of sample programs used in the ev aluation characteristics to cover a broad spectrum of scenarios see table i .
they are of different sizes thousand to thousand lines of code to millions of configurations implemented in different languages c c and java and configurable with varying mechanisms such as conditional compilation configuration files and command line options .
the programs we selected have usually under configurations.
the reason is that this way we can actually measure allconfigurations of these programs in a reasonable time.
hence even though it required over days of measurement with multiple computers we could actually perform the brute force approach and determine accuracy of our prediction over allconfigurations.
setup we measure allconfigurations of all programs that affect performance i.e.
that are invoked by a benchmark .
the exception is sqlite in which we measure only the configurations needed to detect interactions and additionally random configurations to evaluate the accuracy of predictions.
we identified features in each case study and created a feature model describing their dependencies.
all feature models and measurement results are available online at the tool s website.
we automated the process of generating programs according to specific configurations and running the benchmark.
since berkeley db c and java and sqlite use compiletime configuration we compiled a new program for each configuration that includes only the relevant features.
for apache llvm and x264 we mapped the configuration to command line parameters.
we used five standard desktop computers for the measurements.
we repeated each measurement between to times depending on the measurement bias.
it is known that measurement bias can cause false interpretations and are difficult to control especially for performance .
the width of the confidence interval is smaller than of the according means.
we used a range between to to specify the threshold for detecting performance feature interactions.
we use the mean of all measurements of a single configuration cas c .
benchmarks we use standard benchmarks either delivered by the vendor or used in the community of the respective 9intel core quad cpu .
ghz 4gb ram vista 64bit amd athlon64 .2ghz 2gb ram debian gnu linux amd athlon64 dual core .0ghz 2gb ram debian gnu linux intel core2 quad .4ghz 8gb ram debian gnu linux .
each program was benchmarked on an individual systems.application.
we did not develop our own benchmark to avoid bias and uncommon performance behavior caused by flaws in benchmark designs.
since performance predictions are especially important in the database domain we list three database product lines berkeley db s java and c version which differ significantly in their implementation and provided functionality and sqlite.
for each program we use the benchmark delivered by the vendor.
for example we use oracle s standard benchmark to measure the performance of berkeley db.
the workload produced by the benchmarks is a typical sequence of database operations.
furthermore we selected the apache web server to measure its performance in different configurations.
we used the tools autobench andhttperf to produce the following workload for each server configuration we send requests per second to a static html page kb provided by the server.
after seconds we increase the request rate by until requests per seconds are reached.
after this process we analyzed at which request rate the web server could no longer respond or produced connection errors.
llvm is a modular compiler infrastructure.
for our benchmarks we use the opt tool that provides different compile time optimizations.
we measure the time llvm needs to compile its standard test suite i.e.
with different optimizations such as inline functions and combine redundant instructions enabled .
in this case the workload is the program code from the llvm test suite that has to be compiled with the enabled optimizations.
x264 is a command line tool to encode video streams into h. and mpeg a vc format.
the tool provides several options such as parallel encoding on multiple processors.
we measured the time needed to encode the video trailer sintel mb .
this trailer is used by different video encoding projects as a standard benchmark for encoders.
b. results we compute a fault rate of our prediction as the relative difference between predicted and actual performance actual predicted actualand accuracy as fault rate in percent.
as said we measure each program several times.
from these measurements we compute the average performance i.e.
arithmetic mean and the standard deviation.
we use the average performance to compute the delta of a feature.
we use the standard deviation to set the threshold at which we identify a feature interaction because we consider every unexpected performance behavior above the measurement error as an interaction.
accuracy and effort in table ii we show the results of our six case studies for each approach we depict the required number of measurements the time needed for these measurements and the number of identified interactions.
furthermore we show the distribution of the fault rate of our predictions with box plots.
finally we show for eachapproach the mean fault rate of all predictions including the standard deviation.
note that when adding a new heuristic we keep the previous heuristic working because they are successively applied to a program.
the feature wise fw approach does not use a heuristic and does not account for feature interactions.
we achieve good predictions for programs in which interactions have no substantial influence on performance.
for example our predictions have an average error rate of less than for all llvm configurations.
in contrast we usually have a high fault rate e.g.
over for berkeleydb c version when no interactions are considerd.
the average accuracy of performance prediction is .
.
using the pair wise heuristic pw usually improves predictions significantly on average because the majority of interactions are pair wise.
the benefit of implication chains compared to the common pair wise measurement is that it reduces the number of measurements.
for example we require measurements to detect first order interactions for x264 see table ii which is less than which would be needed to measure all pairs of features.
with the higher order ho heuristic we achieve an average accuracy of .
for all case studies.
interestingly for llvm we could not find a feature combination that satisfies our preconditions to search for higher order interactions.
it is important to note that this heuristic usually doubles the number of measurements.
for apache the fault rate increases because measurement bias over the determined threshold lead to a false detection of interactions.
we detected these false positives when we search for third order feature interactions as we do with the hot spot heuristic.
finally the hot spot heuristic hs including the other two heuristics improves accuracy again to .
on average.
considering that the measurement bias for a single measurement of the case studies apache llvm and x264 is for sqlite it is and for berkeley c and java version it is our predictions are as accurate as the bias of a single measurement.
influence of heuristics since all our heuristics are consecutively applied we can visualize the trade off between additional measurements and error rate of predictions as in figure .
dashed lines represent the average error rate of our predictions and straight lines depict the percentage of measurements compared to the maximum number of measurements.
as expected with an increasing number of measurements the fault rate decreases.
the results show that the relative number of measurements strongly differ to achieve the same accuracy for different programs.
further note that we have to measure approximately .
of all variants of sqlite which demonstrates the scalability of our approach.
pair wise vs. higher order interactions look at the apache case study which is similar to others a higher order interaction usually improves predictions.
we detected first effort fault rate in program appr.
measurements time in h interactions distribution mean std berkeley ce fw .
.
.
pw .
.
.
ho .
.
.
hs .
.
.
bf berkeley je fw .
.
.
pw .
.
ho .
.
hs .
.
.
bf apache fw .
.
.
pw .
.
.
ho .
.
.
hs .
.
.
bf sqlite fw .
.
.
pw .
.
ho .
.
hs .
bf llvm fw .
.
pw .
.
.
ho .
.
.
hs .
.
bf x264 fw .
pw .
.
ho .
.
.
hs .
.
.
bf table ii ev aluation results for six case studies approaches appr.
feature wise fw pair wise pw higher order ho hot spot hs brute force bf .
m ean mean fault rate of predictions std standard deviation of predictions .
order interactions and higher order interactions.
using the pw heuristic we have some features that interact with many other features e.g.
keepalive and other features that interact only with one or two features e.g.
extendedstatus .
although without using the hot spot heuristic we observe that some features are more likely to interact.
additionally we found two features base and inmemory that do not interact which substantially decreases the search space.c.
threats to validity internal validity regarding sqlite we cannot measure all possible configurations in reasonable time.
hence we sampled only configurations to compare prediction and actual performance values.
we are aware that this evaluation leaves room for outliers.
also we are aware that measurement bias can cause false interpretations .
since we aim at predicting performance for a special workload we do not have to vary benchmarks.
additionally we determined the width of a confidence40 00in percentberkeley db c berkeley db java apache sqlite llvm h264error rate of measurements feature wise pair wise higher order hot spot applied heuristics figure .
comparing percentage of measurements straight lines with average error rates of predictions dashed lines for each heuristic.
interval of our measurements smaller than of the according means.
external validity we aimed at increasing external validity by choosing programs from different domains with different configuration mechanisms and implemented with different programming languages.
furthermore we used programs that are deployed and used in the real world.
nevertheless we are aware that the results of our evaluations are not automatically transferable to all configurable programs.
in addition to our sample program selection the strong and exhaustive evaluation over days of measurement with computers indicate that our heuristics hold for many practical application scenarios.
d. discussion although we use a simplistic performance model we demonstrated that the approach is feasible.
with an average accuracy of we achieve predictions that even stay in the range of the observed measurement bias for the case studies.
it is important to note that we experienced large differences in accuracy when we changed the threshold at which a performance feature interaction is detected.
having a too small threshold causes many false detections of interactions.
the fault rate increases because we sum the influence of measurement bias instead of the influence of interactions.
we observed that we need a relatively large number of measurements when many alternative features exist compared to independent features because having many alternative features limits the number of valid configurations substantially.
for example we can only generate configurations in berkeley db java though it has features.
this number is below quadratic.
hence already the detection of interacting features require a relatively large number of measurements.
however having programs with a small number of valid configurations make a brute force approach feasible which is not our intended application scenario.furthermore we do not consider performance behavior of a program independently of the workload.
we can make accurate statements for any configuration given a specific workload.
that is we address end users that have a certain application scenario in mind but do not know which configuration performs best.
measurements can be performed on a live system in a real environment which produces more suitable performance predictions than standard benchmark results in a synthetic environment.
for a new customer or a new workload we have to repeat the measurements.
we believe that many interactions still exist though the values of the interactions will change.
this however means that we may save additional measurements for new customers since we already know which features interact.
we believe that our approach is not limited to the detection of non functional feature interactions for the property performance but also for other quantifiable and additive non functional properties such as binary footprint memory footprint and bandwidth.
vi.
r elated work a. performance prediction there are several approaches that aim at predicting performance of a customizable program or a product line.
abdelaziz et al.
provide an overview of component based prediction approaches .
typically the approaches belong to one of three categories model based measurement based as we use in this paper and mixed.
model based model based predictions are common .
for example linear and multiple regression explore relationships between input parameters features and measurements.
based on such a regression model different estimation methods e.g.
ordinary least squares can be used to predict the performance for specific input parameters.
bayesian or belief networks are used to model dependencies between variables in the network .
they are often used to learn causal relationships and hence may be applicable to detect feature interactions.
furthermore machine learning approaches can be used to find the correlation between a configuration and a measurement e.g.
canonical correlation analysis which uses dataset pairs to identify those linear combinations of variables with the best correlation.
principal component analysis finds dimensions of maximal variance in a dataset that can also be used to detect interactions.
ganapathi et al.
provides an analysis for different machine learning approaches in the context of performance prediction of database queries .
the feasibility of model based approaches depends on the application scenario and program to be analyzed.
our work differs in that it offers a general way to produce accurate predictions independent of the application scenario and it uses heuristics to significantly reduce measurement effort.krogmann et al.
combine monitoring data genetic programming and reverse engineering to reduce the number of measurements to create a platform independent behavioral model of components.
for a platform specific prediction they use bytecode benchmark results of concrete systems to parameterize the behavior model.
we predict the performance independently of the used programming language and availability of bytecode.
happe et al.
present a compositional reasoning approach based on the palladio component model .
the idea is that each component specifies its resource demands and predicted execution time in a global repository.
the approach is applicable only to component based programs whereas we use a single approach for all customizable programs.
also in this vein mde based work uses feature models to customize or synthesize performance models e.g.
.
this line of research requires up front and detailed knowledge of domain specific performance modeling where tuning predictions for accuracy can be difficult.
our approach avoids these problems by directly measuring performance.
measurement based sincero et al.
predict a configurations s non functional properties based on a knowledge base consisting of measurements of already produced and measured configurations.
they aim at finding a correlation between feature selection and measurement.
this way they can provide qualitative information about how a feature influences a non functional property during configuration.
in contrast to our approach they do not actually predict a value quantitatively and they do not provide means to detect feature interactions.
chen et al.
use a combined benchmarking and profiling approach to predict the performance of componentbased applications.
based on a benchmark and a java profiling tool a performance prediction model is constructed for application server components.
in contrast we correlate the measurements to the configuration and measure only those configurations from which we expect to detect performance feature interactions.
abdelaziz et al.
argue that most measurement approaches lack generality as they are applicable only to specific application scenarios or infrastructures .
our work can be used for a broad range of applications of different domains implementation techniques etc.
b. feature interaction detection there is a large body of research on automated detection of feature interactions e.g.
see nhlabatsi et al.
and calder et al.
for surveys .
many approaches aim at detecting feature interactions at the specification level.
for example calder and miller use a pair wise measurement approach based on linear temporal logic to detect feature interactions .
they specify the behavior of a product line in promela a modeling language .
using a model checker they generate for each pair wise combination a model checkingrun to verify whether the defined properties are still valid.
other approaches use state charts to model and detect feature interactions .
for example in feature specifications are translated to a reachability graph.
the authors use state transitions to detect whether a certain state is not exclusively reachable in isolation i.e.
a feature interaction occurs .
there are approaches that provide means to detect semantic feature interactions i.e.
feature interactions that change the functional behavior of a program.
some use model checking techniques to find semantic feature interactions .
apel s work uses model checking techniques to verify whether semantic constraints still hold in a particular feature combination .
other approaches aim at investigating the code base to detect structural feature interactions.
for example liu et al.
propose to model feature interactions explicitly using algebraic theory.
in contrast to these approaches we focus on performance feature interactions in a black box fashion.
vii.
c onclusion we presented a method that allows stakeholders to accurately predict the performance of customized and generated programs.
it detects interactions among configuration options or features and evaluates their influence on performance.
we detect feature interactions in a step wise manner.
first we find features that interact.
second we detect the combinations of these features that cause a measurable interaction and quantify their impact on the performance of a configuration.
the common weak spot of such an approach is the exhaustive number of measurements required to detect interactions.
we solved this problem by means of three heuristics that reduce the number of measurements without sacrificing precision in predictions.
our evaluations demonstrate that an accuracy of is possible on average when using our heuristics.
we demonstrated generality by using applications of varying domains implemented with different programming languages and techniques and configured via configuration files or compilation options.