does organizing security patterns focus architectural choices?
koen yskout ibbt distrinet ku leuven heverlee belgiumriccardo scandariato ibbt distrinet ku leuven heverlee belgiumwouter joosen ibbt distrinet ku leuven heverlee belgium abstract security patterns can be a valuable vehicle to design secure software.
several proposals have been advanced to improve the usability of security patterns.
they often describe extra annotations to be included in the pattern documentation.
this paper presents an empirical study that validates whether those proposals provide any real benefit for software architects.
a controlled experiment has been executed with master students who have performed several design tasks involving the hardening of a software architecture via security patterns.
the results show that annotations produce benefits in terms of a reduced number of alternatives that need to be considered during the selection of a suitable pattern.
however they do not reduce the time spent in the selection process.
keywords secure software engineering experiment security patterns software architecture i. i ntroduction a security pattern describes a particular recurring security problem that arises in specific contexts and presents a generic scheme for its solution .
the description of a pattern follows the familiar template of for instance the gang of four patterns including sections on the problem the forces the solution the known uses and so on.
security patterns can be a valuable vehicle to design secure software as they provide sound time proven solutions.
an inventory done in counted over security patterns that had been documented over the previous ten years .
while there is clearly no shortage of security patterns in the literature they are not nearly as popular as the software design patterns e.g.
gang of four .
an investigation by laverdiere et al.
has discovered that security patterns are plagued by a number of issues including over and underspecification lack of generality and consensus as well as misrepresentation.
the mass of security patterns has also led to overlaps as reported by hafiz et al.
.
these are all potential setbacks for a wider adoption.
the secure software engineering community is trying to mitigate the present situation by focusing on the rationalization of the patterns landscape in order to make the offering more accessible structured and effective.
in this stream most activities have focused on classifying patterns e.g.
via taxonomies and provide support for navigation among patterns that are related e.g.
via pattern languages.
these proposals result into extra tags and annotations to be included in the pattern documentation in order to improveusability .
however to date no evidence has been collected that any of these annotations do provide an advantage to the end users i.e.
architects and software designers.
this paper contributes with a pioneering empirical study in the domain of security patterns.
in particular this work focuses on security patterns for software architecture design as well as detailed design.
the key research question is whether security patterns annotations increase the performance of an architect when making architectural choices .
in the context of this work an architectural choice amounts to the evaluation and selection of a solution in the form of a security pattern.
for the study we use a specific proposal of annotation types that has been developed at ku leuven for teaching purposes and has been applied to a catalog of security patterns .
the annotations provide extra information about the applicability of each pattern its relationships with highlevel security goals and other patterns and its impact on other software qualities.
in summary the study divided teams of master students in two treatment groups.
the students had to perform design tasks involving the hardening of a software architecture via security patterns.
one treatment group had access to a version of the catalog that is augmented with the abovementioned annotations.
the other group had access to the plain pattern documentation only.
we have measured the performance of the teams in terms of the time it takes to carry out each task as an approximation of effort and efficiency i.e.
the number of patterns that are browsed in order to come to a solution.
the results suggest that there is no significant difference between the two groups in terms of time.
however the group using the annotated catalog is more efficient.
at the end of the experiment a questionnaire was also administered in order to validate the experimental assumptions and gather feedback from the participants.
the rest of this paper is structured as follows.
the annotation scheme used in the experiment is described in section ii and positioned with respect to the related work in section iii.
the design of the experiment is described in section iv while the results are presented in section v. the data obtained via the follow up questionnaire are explained in section vi.
finally section vii discusses the threats to validity and section viii gives the concluding remarks.ii.
a nnotations while pattern descriptions are expected to contain sufficient contextual information to assist with selecting a suitable pattern this is not always the case with security patterns.
as mentioned before annotations have been proposed to provide this information.
the study takes the perspective of the software architect and aims at measuring the effect of such annotations on the architect s performance.
for the experiment the annotations described in are used.
this choice was subject to two criteria.
firstly the annotations used in this study have to be representative of what has been suggested in the state of the art.
the selected set is a combination of existing proposals as illustrated in the related work section.
therefore it is expected that the annotations of other proposals would yield to similar results although this should be verified in a separate experiment.
secondly a catalog needs to be available in which the annotations have been applied to actual patterns.
the catalog used in this study already existed including the annotations and has been tested for over three years in courses with students.
in the past the students have used the catalog to build realistically sized systems and have provided positive feedback it covers the solution space well and is manageable in a lab setup.
the annotations in the catalog cover four dimensions thesecurity objective s for which the pattern provides a solution for example confidential data transmission data storage integrity accountability and so on theapplicability of the pattern to either the high level architecture of a system or its detailed design.
this annotation also indicates whether the pattern is to be applied in the core of the system or rather in its deployment environment thetrade off labels which indicate the positive or negative impact of the pattern on other software qualities such as performance or maintainability therelationships among patterns e.g.
functional dependency mutually exclusive conflict alternative and so on.
for example the annotations for the s ecure logger pattern determine that it is linked to the auditability objective is applicable to the core of a system architecture impacts positively on maintainability and negatively on performance and is related to the s ecure pipeand a udit intercep tor patterns which are advised to be used as supporting solutions .
iii.
r elated work an extensive survey on security patterns has been published by yoshioka et al.
and two referential books are available .
to the best of the authors knowledge there are no empirical studies concerning security patterns.
over the last decade various proposals have appeared for organizing and classifying the security patterns.
in thissection we illustrate how the proposal used in this study and summarized in section ii is indeed connected to and representative of the state of the art.
security objectives.
hafiz et al.
survey the taxonomies that have been presented so far and propose a new schema based on the following dimensions the addressed security issues i.e.
cia confidentiality integrity availability the application context i.e.
core security perimeter security and exterior security the zachman framework stakeholders vs. concerns and the microsoft stride threat categories .
the proposal used in this study uses the security objectives as one of the classification dimensions.
the security objectives are in fact a refinement of the cia.
security objectives are meant to provide a connect between the solution space and the problem domain.
in this perspective rosado et al.
map out the relationships between security requirements and security patterns.
mazhelis and naumenko suggest a similar approach.
applicability.
the proposal used in this study includes the applicability of a pattern which is similar to the application context e.g.
core security vs perimeter security in the work of hafiz et al .
the applicability also marks a distinction between high level architectural design and detailed design.
this is in line with the work of rosado et al.
proposing the same differentiation and similar to the works of yoshioka et al.
and vanhilst et al.
classifying security patterns according to the software life cycle phases such as requirements architecture and design implementation .
relationships.
hafiz et al.
acknowledge that classification is only one side of organization.
as important as classification is navigation that is the ability of guiding the reader toward the selection of a pattern.
those authors point out that the relationships among patterns represent a key ingredient to successful navigation.
the relationships used in this study are similar to the dependencies among security problem patterns suggested by hatebur et al.
.
an interesting work by fernandez et al.
outlines a methodology to automatically elicit the dependencies via the analysis of the textual description of the patterns.
trade offs labels.
concerning the trade off labels they are similar to the work of weiss which traces the contribution either positive or negative of security patterns to qualities like availability performance cost maintainability usability and the cia itself.
iv.
e xperiment design the experiment has been performed with master students as part of the lab project for a course on software architecture.
the experiment ran over a period of two weeks and was mainly executed during two supervised lab sessions hours in total although the students were given the option of continuing working on the project at home while still being monitored by means of the tool support as described later .
the students worked in teams of two people and wehave measured the performance of each team as a whole as described later on.
the teams have performed five design tasks each of which consisted of hardening an existing software architecture with respect to a number of security requirements.
to assist the teams in accomplishing these tasks the tool they used provided access to a catalog of security patterns.
the catalog contains security patterns mostly coming from a referential book .
two versions of the same catalog have been used.
one version called plain contains the pattern documentation as it is presented in the literature.
in the other version called annotated the patterns are enriched with the annotations mentioned in section ii.
accordingly the teams have been divided in two balanced groups called the plain and annotated group from now on depending on the version of the catalog they were provided with.
per design task the average performance of the two groups has been compared.
we are interested in determining if the presence of annotations improved the performance of the teams regarding the selection of a suitable solution from the security pattern catalog and if so to what extent.
for this we interpret performance in two ways.
first we look at the selection time i.e.
the time that each team spent on selecting one or more patterns from the catalog.
the expected outcome is that the teams in the annotated group will arrive at their selection more rapidly because they can use the annotations to quickly discard irrelevant patterns and thus work faster.
second we investigate the selection efficiency or efficiency for short of each team namely whether the teams actually discarded the irrelevant patterns and only looked at the patterns they eventually used for solving the task.
again it is expected that the presence of the annotations makes the annotated group more efficient.
the rest of this section further describes the context preparation and setup of the experiment and the precise measurements and research hypotheses.
for more details about the experiment s material and setup we refer to this paper s accompanying website .
a. experimental object the system that was used for the experiment comes from the domain of electronic health care.
it allows a cardiologist to remotely monitor patients with cardiovascular diseases.
the system consists of a central patient monitoring system pms with which various external entities communicate.
the data about a patient is obtained from sensors for example a wearable unit that continuously measures the heart rate and blood pressure of the patient.
these sensor readings are collected and sent to the pms by a gateway device e.g.
a smartphone .
the system stores the received data in a sensor reading database analyzes it and alerts the patient s cardiologist if further action needs to be taken.
also when the readings indicate an emergency e.g.
an imminent heart attack the emergency services are notified.table i background of the participants program specializations plain annotated total computer science distributed systems secure software software engineering other informatics applied informatics other total further the system is also accessible by people from the patient s close environment e.g.
friends the patient s general practitioner or home caretakers .
they can review the patient s status and provide additional information by filling out questionnaires.
the initial setup and configuration of the system for a patient is done by a nurse that has been trained for this purpose.
finally the system should interact with the hospital information system his of the hospital for exchanging data and or requesting emergency assistance.
b. participants and teams the experiment has been executed with students in their first year of a two year master in computer science at the ku leuven.
the students have different backgrounds for example secure software artificial intelligence or humancomputer interaction.
they were enrolled in an obligatory course on software architecture and the work done by the students in the context of the experiment was integral part of the course syllabus.
as mentioned before the participants worked in pairs and have been allowed to choose their own teammate.
this is a standard practice at ku leuven and the experimenters could not control that e.g.
via random team assignment .
the teams have been randomly assigned to the two treatment groups leading to teams in the plain group and teams in the annotated group.
by using stratified randomization an attempt has been made to balance the assignment of teams to groups with respect to the background of the students.
in table i the distribution of the participating students across the different study programs specializations and groups are given.
note that sometimes within a single team each member had a different background.
this has hindered a perfectly balanced group assignment.
however participants with a security background are evenly distributed across the two treatment groups.
the students were made aware of their participation to an experiment and of the fact that their work was monitored although the goals hypotheses of the experiment were not communicated to them.
it has been made clear to the participants that the experimenters would not look at the raw measurements until after their grades for the course were made official.
this pledge is important because the coursewas taught by the experimenters themselves and we wanted to avoid any perception of coercion from the participants.
the message has been reinforced several times during the duration of the course.
furthermore the participants were given a ten days grace period to opt out from the experiment after the course s grades were made official and before the experimenters started analyzing the measurements.
no participant decided to opt out.
c. course and lab material the experiment was part of the hands on project for a onesemester course on software architecture which consisted of two parts.
in the first part weeks the students were taught to build a software architecture following the attribute driven design method .
in the accompanying lab project the students created and documented in uml the architecture for the pms system outlined before.
this part of the project was not part of the experiment.
during the second part of the course the students have received four lectures on various security related topics such as understanding eliciting and documenting security requirements documenting security architectures and using security patterns.
the students were also given a tutorial about the security patterns contained in the catalog.
the students in the annotated group received an additional very short lecture explaining the annotations that were available to them in the catalog.
in the accompanying lab project an initial architecture of the pms system the same for all teams needed to be hardened by instantiating security patterns.
the architecture was created by the experiment designers and explained to the participants beforehand.
the documentation of the pms architecture is not detailed here due to space limitations and is provided to the interested reader on the website .
during the first part of the course the students were free to choose the tools to work with e.g.
for drawing uml diagrams.
to facilitate the collection of the measurements for the experiment during the second part the students have been obliged to use a custom tool that we provided and that was unavailable during the first part .
before the experiment started the participants have received a tutorial and a demonstration on how to use the tool.
all lab material including the initial architecture the catalog and the tasks to be performed were digitally provided to the participants by means of the tool.
copies of the lab material are available on the website.
more details about the tool are given later in section iv f. d. tasks each task consists of elaborating the software architecture in order to support a security requirement.
the requirement is documented via a description of the threats to protect against in the form of two misuse cases and a description of how the system is expected to react in theform of a quality attribute scenario .
table ii contains a high level description of the five tasks that were given to the teams.
the table also contains the expected impact of the task on the architecture and the patterns from the catalog that could possibly be used for completing the task.
clearly this additional information was not provided to the students.
note also that in tasks a and b the correct solution requires the selection of a system of collaborating patterns while in tasks c e a single pattern can be found that solves the problem entirely.
further task e is expected to be the easiest one to solve.
e. process all teams were given a process to follow when hardening the architecture.
this provides the students with the necessary guidance so that they do not get stuck with the tasks as they never used security patterns before.
the process is lightweight and very intuitive as it resembles any problem solving approach a list of potential solutions is scouted first and then the most adequate is chosen.
for each task the teams follow the steps below study the requirement that should be implemented and assess which parts of the architecture are impacted and how.
if the requirement is already sufficiently supported by the current architecture skip all remaining steps and go to the next task.
quickly skim through the security pattern catalog and create a shortlist of possibly interesting patterns for the current task.
study the patterns from the shortlist more thoroughly evaluate the real effectiveness of each candidate make trade offs with other qualities that are important for the architecture detect conflicts with already implemented patterns and make a final selection of patterns to instantiate.
instantiate the solution in the architecture by injecting the pattern in the design.
this step is not used in the context of this experiment.
the observations on this step are part of a follow up study.
note that participants were not requested to build a secure architecture from the ground up.
therefore there was no need for them to follow a more articulated architecture creation process like the attribute driven design .
for the teams in the annotated group the process steps are the same but the activities are augmented so that the students can take advantage of the annotations in the catalog they are using.
in particular in step the team must assign a security objective to the requirement.
in step the security objective is to be used to quickly select the relevant patterns for the shortlist.
further the annotations about the relationships with other patterns can be used to extend the shortlist.table ii task descriptions and impact task scenario to prevent security objective and expected impactpossible pattern s task a warm up a malicious person attempts to bring down the sensor reading database.
this leads to the loss of received readings and results in the unavailability of up to date information for the cardiologist.availability .
the sensor reading database is replicated possibly using different database technologies.
the sensor reading database host is shielded from the external network.
difficulty hardfirewall load balancer replicated system task ba user of the system tries to avoid responsibility for his action by tampering with the log files.accountability .
only authenticated users can perform actions and they are logged in a tamper proof appendonly audit log.
difficulty hardauthentication enforcer audit interceptor secure logger task cunauthorized entities attempt to access sensor data about a patient which is sensitive medical data .confidential data transmission .
data in transit between the patient s gateway and the pms system is encrypted for example using ssl.
difficulty averagesecure pipe task da member of a patient s personal health community tries to use the web interface to access information about a patient to which she is not related.confidentiality .
all actions that are performed by members of the community are checked against a policy.
all necessary information to make an authorization decision is available to the component that makes the decision.
difficulty averageauthorization enforcer task ethe web interface of the personal health community is targeted by a malicious entity by providing malicious input in order to cause system malfunctioning or unauthorized access to patient information.data integrity .
the system is designed so that external input is validated before it is used.
difficulty easyinput guard in step the annotations about the conflicts with other patterns and the trade offs with performance availability and modifiability are to be used to facilitate the final selection.
f .
experiment execution the process is enforced by a tool in order to ensure that it was followed closely by each team.
the use of tool is important to counter a common threat to internal validity i.e.
when the participants do not follow the planned lab procedures.
the tool is a customized eclipse environment consisting of the topcased uml editor topcased.org a viewer to display the description of the tasks to be performed a browser to navigate the security pattern catalog and a wizard to enforce the process described above.
the first task task a in table ii is a warm up task in order for the team to become familiar with the system the tool and the pattern catalog.
each team performs this task first.
the other four tasks b c d and e have to be completed sequentially i.e.
postponing a task is not allowed and incrementally i.e.
each task is executed in the context of the architecture resulting from the previous tasks .
in order to weed out the learning effect the order of execution of tasks b e is randomized across the teams.
the tasks are provided to the teams via the tool i.e.
not on paper or online to make it harder to pass the task descriptions around.
similarly the security patterns catalog is only available through the tool and could not be printed.
each team receives a unique code which is entered when first starting the tool.
the tool then configures itself for that specific team for example by loading the correct order of the tasks and enabling or disabling the display of the annotationsin the catalog browser depending on the team s assignment to the treatment groups.
for the plain group the browser to navigate the catalog is a simple html viewer with an index of all available patterns.
for the annotated group the browser allows the filtering of the index according to a specific security objective the applicability of the pattern the trade off labels of interest or a combination of the above.
as mentioned before a wizard enforces the strictly sequential execution of the tasks and of the process steps within each task.
for instance during step study of the requirement the team has to use the wizard to enter its considerations about the impact of the requirement and for the annotated group the security objective that has been assigned to the requirement.
in steps shortlisting and selection the wizard must be used to enter the shortlist and the final selection.
during steps the diagrams of the architecture are accessible in read only mode via the uml editor.
the uml tab is enabled for editing during step only instantiation of the pattern .
during the lab sessions one or more supervisors were always present to answer questions about the functionality of the tool the meaning of the tasks and so on.
the tool is instrumented to monitor the team s actions in the background.
in particular the tool collects the following information for each task the time spent in each step of the process study shortlist select and instantiate the patterns that are browsed in the catalog the patterns that are shortlisted and finally selected the total time each pattern is looked at.
the tool is also equipped with a pause button which the teams were instructed to use when they were taking a break.figure .
design of the experiment pressing this button stops the time measurements and at the same time hides all information that is visible in the tool until work is resumed.
the supervisors in the lab sessions reminded the teams of this functionality whenever necessary.
the collected measurements are stored in an encrypted log file and are automatically transmitted to a web server after the completion of every task.
the teams were made aware of this beforehand so they knew they had to be connected to the internet when completing a task.
however they did not know precisely which measures were collected.
to summarize the design of the experiment is presented in figure .
both the plain and annotated groups have followed the same process except for the augmentations described in section iv e have used the same tool and performed the same set of tasks.
the only difference between the groups were the features of the security pattern catalog.
the annotated group teams had access to an annotated catalog together with filtering functionality based on these annotations.
the plain group had access to the same catalog but without annotations and filtering options.
the design has been validated and calibrated in a small tryout before being used with the participants.
after the experiment the teams have been asked to fill out an online questionnaire see section vi .
g. measures and experimental hypotheses first we measure the selection time t as the time in seconds that is necessary for a team to arrive at their final pattern selection for each task.
this measure includes the first three activities of the process that is studying the requirement creating a shortlist of patterns and making the final selection.
for each task we test the effective null hypothesis that the mean selection time for both groups is equal ht a t p t where a tand p tare the average selection time of the annotated and plain group respectively.table iii number of data points for time tand efficiency e task invalidoutliers remaining t et e plain annot plain annot b c d e all second we measure the selection efficiency e as follows.nviewis the total number of patterns that the team looked at i.e.
opened in the catalog browser when performing a task ignoring whether or not the pattern was retained or discarded for instantiation.
nselectis the number of patterns that the team finally selected for instantiation in the architecture for that task.
the selection efficiency then ise nselect nview.
as every selected pattern must have been viewed nview nselectand thus e .
note thate means that every viewed pattern was selected maximizing efficiency.
again for each task we test the effective null hypothesis that the mean efficiency for both groups is equal he a e p e where a eand p eare the average selection efficiency of the annotated and plain group respectively.
v. d ata analysis in the analysis we ignore the warm up task a as it is heavily influenced by other factors such as the teams becoming familiar with the tool the system and the process.
a. data validation and outlier removal before starting with the analysis of the data we observed that in nine cases we did not obtain measurements for some tasks.
eight of these cases correspond to teams that decided that a task was already covered by the architecture.
hence they skipped that task and no measurements about the execution of the rest of the process are available.
also for one team all data from task b was missing due to an occasional crash of the otherwise very reliable tool.
these cases have been discarded.
additionally some of the obtained data points have been labeled as outliers and excluded from further analysis.
data points are discarded when they are more than .
times the inter quartile range above below the upper lower quartile.
the boxplots showing the outliers for both the time and the efficiency measures can be found in figures and respectively.
concerning the time measure across all tasks 11data points were labeled as outliers from the set of 171available data points resulting in a reduction of .
concerning the efficiency measure across all tasks 8data points were removed resulting in a reduction of .
theannot plain0 8000bselection time t sec annot plain0 8000c annot plain0 8000d annot plain0 8000e 1figure .
boxplots of selection time tper task annot plain0.
.
.
.
.
.0befficiency e28 annot plain0.
.
.
.
.
.0c annot plain0.
.
.
.
.
.0d annot plain0.
.
.
.
.
.0e3 figure .
boxplots of efficiency eper task number of remaining data points per task and treatment group is shown in table iii.
b. summary of the results the descriptive statistics of the time tcan be found in the left hand side of table iv.
the results see the mean column indicate that on average the annotated group has spent more time in most of the cases.
this is a surprising result that goes against the expectations.
mind that tasks c e are of medium to low difficulty.
task b is the most difficult one according to the experiment designers and here the difference between the two groups is negligible.
the descriptive statistics of the efficiency ecan be found in the left hand side of table v. the results show that on average the annotated group is largely more efficient intable iv analysis for the selection time t taskplain annotated mean p valuemean sec stdev mean sec stdev b c d e table v analysis for the efficiency e taskplain annotated mean p valuemean stdev mean stdev b c d e tasks b and c. the difference is much smaller in task d. these tasks are of medium to high difficulty.
task e is considered to be the easiest as confirmed by the participants see section vi .
in this case the selection of the right pattern could have been done very efficiently by simply looking at the names of the patterns.
hence using the annotations is likely to be an unnecessary complication.
this could explain why the annotated teams underperformed in task e. c. statistical analysis in order to select a suitable statistical test we use the shapiro wilk normality test to determine whether the data follows a normal distribution.
this is the case in task c fortand task d for e. in both cases the two sample populations also have equal variance.
when the data is normally distributed we test the hypothesis by means of the two tailed t test which is a parametric test.
otherwise we use the the non parametric wilcoxon rank sum test also known as mann whitney u test .
we always use as the significance level.
the resulting p values of the statistical tests for time t and efficiency e are given in the right hand side of tables iv and v respectively.
concerning the time none of the measured differences are statistically significant and as such we cannot reject the null hypothesisht .
based on these results we cannot conclude that the annotations had any effect on the mean selection time of the two groups.
concerning the efficiency the results are statistically significant for tasks b and c. this allows us to confidently reject the null hypothesis he 0and conclude that for these two tasks an improvement in efficiency was obtained by providing annotations in a pattern catalog.
finally we remark that we have also re analyzed the data without removing the outliers as discarding outliers is sometimes regarded as a controversial practice.
however table vi number of viewed and selected patterns per group and task taskviewed patterns selected patterns plain annotated plain annotated min med max min med max min med max min med max a b c d e we report that we have obtained the same conclusions.
concerning t the annotated group is slower in tasks b e. however the differences are not statistically significant.
concerning e the same trends are observed an advantage for the annotated group in tasks b and c a tie in task d and a disadvantage in task e. the differences in tasks b and c are still statistically significant.
d. interpretation of the results the experimenters expectation namely that the anno tated group would be faster in selecting patterns because they can more easily focus on the relevant ones thanks to the guidance provided by the annotations does not appear to hold.
nevertheless for tasks b and c there is a significant increase in efficiency which shows that fewer irrelevant patterns are indeed browsed by the annotated group.
to explain this effect nviewandnselect the contributors to the efficiency should be investigated separately.
therefore table vi shows the number of patterns that was viewed and eventually selected by each group per task.
the data show that for tasks b and c the annotated group viewed less patterns than the plain group nviewdecreases but retained more in their final selection nselectincreases .
by applying the wilcoxon test these differences are found to be statistically significant for the selected patterns during task b p value and c and for the viewed patterns during task b .
for the viewed patterns during task c the decrease is close to being significant p value .
the decrease in nviewindicates that the annotated group was more focused when choosing a suitable pattern as they invested their time in gaining a deeper insight into a subset of the patterns.
this could be the result of filtering the catalog based on the security objective annotations.
also it is plausible that the relationship information led the annotated group to select additional complementary patterns thereby increasing nselect.
e. discussion with time it is natural that a team becomes more familiar with the solutions in the catalog.
this effect is irrelevant in the previous discussion due to the randomized order of the task execution.
when the team uses the catalog for the first time however it is intuitively expected that the impact of theannotations would be larger.
to assess this effect table vi also contains the warm up task a first task for every team .
it is clear that the number of viewed patterns for task a is much higher for the plain group than for the annotated group.
every team in the plain group at least looked at patterns when completing the first task and half of the teams in that group looked at every pattern in the catalog.
for the annotated group the minimum and median are much lower and no team looked at the entire catalog during task a. the difference between the two groups is statistically significant wilcoxon p .
this demonstrates that annotations can have a beneficial impact when an architect is confronted with a pattern catalog for the first time e.g.
because she is dealing with a software quality she is less acquainted with.
the annotations make it unnecessary to familiarize yourself with the whole catalog beforehand.
a legitimate question is how the correctness of a team s solution was determined.
the teams had to hand in a lab report for this part of the course which was graded independently from the rest of the course itself.
it is important to note that the grades have been assigned by six teaching assistants.
as the graders were no stakeholders of the experiment or its outcome they can be assumed to be unbiased.
also the graders performed an up front calibration of their grading criteria on two reports in order to guarantee homogeneity in their scores.
reports have been graded on a scale from to which is familiar to the tas.
overall the average score obtained by all teams is .
with the first quartile equal to .
.
hence the bulk of the grades distribution is above the threshold and it can be concluded that the teams did a fair job.
the plain group did slightly better than the annotated group by .
points on average but this difference is not statistically significant.
we have performed an analysis considering only the teams about that passed the threshold in their grades.
these are the teams that produced higher quality artifacts.
we report that the same conclusions of sections v b and v c can be drawn.
the only difference concerns t in task d the annotated group was faster .
considering the threshold about teams the same trends are observed.
however the differences are more polarized.
additionally we performed an initial attempt at assessing the pattern selections made by the subjects which is hard as there is no single correct baseline to compare against.
we restrict ourselves to the most popular pattern selected by each group.
the data show that for each task the most often selected pattern is the same in both groups.
hence the annotations did not cause major differences with respect to the chosen pattern but they might have influenced the completeness of the final solution.
further experiments are necessary in order to corroborate or refute this claim.table vii questionnaire question answer .
the tutorial and warm up task were sufficient to become familiar with strongly disagree disagree neutral agree strongly agree q1.
.
the tool agree q1.
.
the architecture of the pms system agree q1.
.
the process agree q1.
.
the security patterns catalog agree .
rate your understanding of the task s description very unclear unclear average clear very clear q2.
.
task b e clear .
were all the tasks of similar difficulty?
yes no no .
rate the difficulty of each task very hard hard average easy very easy q4.
.
task b average q4.
.
task c average q4.
.
task d average q4.
.
task e easy .
indicate your agreement with these statements strongly disagree disagree neutral agree strongly agree q5.
.
the pattern based process is intuitive agree q5.
.
the process puts too many constraints neutral q5.
.
the catalog does not contain enough patterns disagree q5.
.
the description of the patterns is clear neutral q5.
.
the process wizard is user friendly agree q5.
.
the uml editor is user friendly disagree q5.
.
the catalog browser is user friendly disagree q5.
.
overall the pattern based process is useful agree .
i am satisfied with the selected patterns.
strongly disagree disagree neutral agree strongly agree q6.
.
task b e agree .
how difficult was it to find a suitable pattern?
very hard hard average easy very easy q7.
.
task b e easy vi.
q uestionnaire at the end of the experiment the teams were asked to fill in an online questionnaire.
the purpose of the questionnaire is to validate the experimental assumptions and to gather feedback from the participants.
a. validation of the experimental assumptions a number of assumptions have been made while designing the experiment.
for instance we assume that the process is rather intuitive and hence natural to follow or that the tool is easy to use.
these assumptions guarantee that the measures are not altered by the experimental conditions.
if not verified the above assumptions are to be considered as threats to the validity of the results.
tables vii and viii present the questions asked to the participants and the median of the answers or the mode for yes no questions .
the full set of questions and answers is available online .
note that the order of the questions have been rearranged in this paper for presentation purposes.
a first assumption of the study is that the participants were adequately prepared when entering the experiment.
the answers to q1.
indicate that this was indeed the case.
we also assume that the participants understood the tasksthey were assigned.
this is very important for the sound construction of the experiment.
the assumption is confirmed by the answer to q2.
.
concerning the complexity of the individual tasks questions q3 and q4 the participants report that tasks b d are considered of equal difficulty.
it looks like the higher difficulty anticipated by the experiment designers for task b due to the fact that a system of patterns needs to be selected is not particularly worrisome for the participants.
task e appears to be easier than the others as expected .
tasks b and c lead to a statistically significant difference concerning the selection efficiency.
since they are of comparable nature according to the participants the results obtained in the two tasks may reinforce each other.
we also assume that the process described in section iv e did not force the participants to adhere to a counterproductive workflow.
from the answers to questions q5.
q5.
and q5.
we can conclude that the participants felt that the process was intuitive and useful.
a third assumption was that the security patterns catalog was sufficiently large to execute all the assigned tasks.
this is confirmed by the answers to question q5.
.
however the description of the patterns which comes from the state ofthe art is reported to be less than ideal in question q5.
.
this confirms the concerns about the usability of the existing patterns as mentioned in the introduction of this paper.
a further assumption tested in questions q5.
is that the tool has no impact on the performance of the participants by being hard or counterintuitive to use.
the answers to the questionnaire show that the tool was well absorbed by the participants especially concerning the process wizard q5.
.
they did complain about the limited usability of the topcased uml editor q5.
which is used to instantiate the selected patterns.
according to the feedback browsing uml diagrams was not an issue.
modifying the diagrams during step was more tedious.
note however that this step is not used for the measurements.
hence this issue has no effect on the outcome of the study.
the participants of both groups were also slightly annoyed by one specific monitoring feature of the catalog browser.
pattern descriptions are organized into sections e.g.
problem forces solution and so on.
the tool records which section is accessed the most over each step this data was not used in this paper .
to this aim the sections must be opened via a mouse click and they close automatically after seconds.
b. additional feedback per task we asked the teams to rate their level of satisfaction with respect to the solution they selected q6 .
we also asked about the level of perceived difficulty related to the selection q7 .
the teams agree that they found a satisfactory pattern for each task median is in a satisfaction scale of .
they also considered the selection process as easy median is in a difficulty scale of .table viii questionnaire cont d annotated group only question answer .
to what degree was the following information helpful to shortlist a pattern in step ?
not helpful at all not helpful neutral helpful very helpful q8.
.
trade off labels neutral q8.
.
relationships among patterns helpful q8.
.
security objectives very helpful q8.
.
applicability neutral .
to what degree was the following information helpful to select a pattern in step ?
not helpful at all not helpful neutral helpful very helpful q9.
.
trade off labels helpful q9.
.
relationships among patterns helpful q9.
.
security objectives helpful q9.
.
applicability neutral for the annotated group only we also gathered some feedback about the perceived usefulness of the annotations questions and .
overall the participants see less value in the applicability annotation.
on the contrary the connection between requirements and solutions via the security objectives is very much appreciated especially in step .
vii.
t hreats to validity a. internal validity the familiarity of the participants with the concepts used in the experiment patterns misuse cases quality scenarios uml and so on might have an impact on the participants performance.
we tried to mitigate this threat by providing extensive training on all the matters during the class hours.
however we cannot guarantee that all participants attended all the necessary classes.
also the annotated group has received about half an hour of additional lecture to make them familiar with the annotations.
however as the lecture only explained the nature of the annotations and how to use them and not the pattern catalog nor the case study we believe that the impact on the results is negligible.
the participants were not supervised at all times as they were allowed to work at home.
further the experiment spanned over two labs sessions.
these are opportunities for treatment diffusion as the teams might have interacted.
furthermore the number and type of patterns in the catalog might have influenced the results.
e.g.
organization and navigation might become more helpful for larger catalogs resulting in a bigger difference between the groups.
b. external validity the main issue threatening the generalization of the results concerns the use of master students instead of professionals.
however it is generally advised to test new theories starting with students via exploratory studies .
further runeson observes that differences can be small between graduate students our case and professionals .the results might also be specific for the selected set of annotations.
although in section iii we have shown that the set is representative of the related work replica studies are likely to be needed in order to establish whether alternative annotations would lead to similar conclusions.
the tasks are of a small size with respect to real world design endeavors.
larger tasks also require longer time for the experiment execution to the further detriment of the control on the experiment itself.
given the time frame of the experiment lab sessions the used tasks represent the best compromise.
however we acknowledge that the study should be replicated with larger tasks.
the results might be influenced by the objects used in this study.
for instance the pms system is a realistic application but one of moderate size.
also the experiment was performed only using this architecture.
this represents a drawback in terms of the realism of the experiment.
on the other hand some interfering issues such as getting to know the system are reduced thanks to the limited size.
finally the tool that was used to browse the patterns had a few counterintuitive constraints to make it possible to monitor the subjects actions.
as reported in the questionnaire this has hindered the subjects with possibly a negative impact on their performance or motivation.
viii.
c onclusions we have performed a controlled experiment with participants to determine the impact of annotations for security patterns on the performance of a software architect.
surprisingly the results do not show an advantage in terms of the time that is necessary to complete a design task.
on the other hand the use of annotations noticeably reduced the number of irrelevant patterns that were considered in two out of the four cases we investigated.
this result is statistically significant and applies to a master student population and for tasks of average difficulty.
the study presented in this paper did not single out one specific annotation.
rather a representative set has been studied jointly.
the main lesson learned is that it is not self evident that annotations provide an edge.
therefore we recommend that new proposals are carefully evaluated.
starting from the additional data collected in this experiment but not used in this paper we are also in the process of analyzing the quality of the design artifacts produced by the teams.
we expect to gather useful insight on the effect of the annotations on the architectural choices as well as the overall soundness of the adopted security solutions.
acknowledgement this research is partially funded by the eu fp7 project nessos the interuniversity attraction poles programme belgian state belgian science policy and by the research fund ku leuven.