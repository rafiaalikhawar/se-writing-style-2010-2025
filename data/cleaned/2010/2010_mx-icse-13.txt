safe software updates via multi version execution petr hosek cristian cadar department of computing imperial college london fp.hosek c.cadarg imperial.ac.uk abstract software systems are constantly evolving with new versions and patches being released on a continuous basis.
unfortunately software updates present a high risk with many releases introducing new bugs and security vulnerabilities.
we tackle this problem using a simple but effective multiversion based approach.
whenever a new update becomes available instead of upgrading the software to the new version we run the new version in parallel with the old one by carefully coordinating their executions and selecting the behaviour of the more reliable version when they diverge we create a more secure and dependable multi version application.
we implemented this technique in m x a system targeting linux applications running on multi core processors and show that it can be applied successfully to several real applications such as coreutils a set of user level unix applications lighttpd a popular web server used by several high traffic websites such as wikipedia and youtube and redis an advanced key value data structure server used by many well known services such as github and flickr.
index terms multi version execution software updates surviving software crashes.
i. i ntroduction in this paper we propose a novel technique for improving the reliability and security of software updates which takes advantage of the idle resources made available by multi core platforms.
software updates are an integral part of the software life cycle but present a high failure rate with many users and administrators refusing to upgrade their software and relying instead on outdated versions which often leaves them exposed to critical bugs and security vulnerabilities.
for example a recent survey of system administrators has reported that of respondents refrain from performing a software upgrade regardless of their experience level .
one of the main reasons for which users hesitate to install updates is that a significant number of them result in failures.
it is only too easy to find examples of updates that fix a bug or a security vulnerability only to introduce another problem in the code.
for example a recent study of software updates in commercial and open source operating systems has shown that at least .
to of fixes are incorrect and have affected end users .
our goal is to improve the software update process in such a way as to encourage users to upgrade to the latest software version without sacrificing the stability of the older version.
our proposed solution is simple but effective whenever a new update becomes available instead of upgrading the software to the newest version we run the new version in parallel with the old one.
then by selecting the output of the more reliable version when their executions diverge we canincrease the overall reliability of the software in effect our goal is to have the multi version software system be at least as reliable and secure as each individual version by itself.
we implemented this approach in a prototype system called mx which targets crash bugs in linux applications running on multi core processors.
mxallows a new and an old version of an application to run concurrently without requiring any modifications to the application itself or the operating system nor any input from the user.
the synchronisation of the two versions is performed at the system call level using system call interposition and synchronisation.
when one of the versions crashes mxtransparently restarts it via a lightweight checkpointing mechanism and often allows it to survive the bug by using the code of the other version.
we evaluate mxby showing that it can successfully survive crashes in several real applications specifically several coreutils utilities and two popular servers lighttpd andredis .
in summary the main contributions of this paper are a novel software update approach based on multi version execution which allows applications to survive crash errors introduced by incorrect software updates a study of the evolution of application external behaviour confirming the feasibility of our approach a prototype system for multi core x86 and x86 linux systems which implements this approach without requiring any changes to the application binaries nor the operating system kernel an evaluation of our prototype on several real applications coreutils a set of user level unix utilities lighttpd a popular web server used by several high traffic websites such as wikipedia and youtube and redis an advanced key value data structure server used by many well known services such as github and flickr.
the rest of this paper is organised as follows.
ii introduces our approach through a real update scenario in lighttpd .
then iii presents a study analysing the feasibility of our approach iv describes our mxprototype targeting linux applications running on multi core processors and v presents our experience applying mxto several real applications.
finally vi discusses the different trade offs involved in our approach vii presents related work and viii concludes.
ii.
m otivating example to motivate our approach we present a real scenario involvinglighttpd which is representative of one type of applications which could benefit from our approach namely server applications with stringent security and availability requirements.
c ieee icse san francisco ca usa accepted for publication by ieee.
c ieee.
personal use of this material is permitted.
permission from ieee must be obtained for all other uses in any current or future media including reprinting republishing this material for advertising or promotional purposes creating new collective works for resale or redistribution to servers or lists or reuse of any copyrighted component of this work in other works.612lighttpd1is a popular open source web server used by several high traffic websites such as wikipedia and youtube.
despite its popularity crash bugs are still a common occurrence inlighttpd as evident from its bug tracking database.
below we discuss one such bug which our approach could successfully eliminate.
in april a patch was applied3tolighttpd s code related to the http etag functionality.
an etag is a unique string assigned by a web server to a specific version of a web resource which can be used to quickly determine if the resource has changed.
the patch was a one line change which discarded the terminating zero when computing a hash representing the etag.
more exactly line in etag.c for h i i etag used i h h h etag ptr was changed to for h i i etag used i h h h etag ptr this correctly changed the way etags are computed but unfortunately it broke the support for compression whose implementation depended on the previous computation.
more precisely lighttpd s support for http compression uses caching to avoid re compressing files which have not changed since the last access.
to determine whether the cached file is still valid lighttpd internally uses etags.
unfortunately the code implementing http compression did not consider the case when etags are disabled.
in this case etags used is0 and when the line above is executed etag used underflows to a very large value and the code crashes while accessing etag ptr .
interestingly enough the original code was still buggy it always returns zero as the hash value and thus it would never re compress the files but it was not vulnerable to a crash.
the segfault was diagnosed and reported in march 20104and fixed at the end of april 5more than one year after it was introduced.
the bottom line is that for about one year users affected by this buggy patch essentially had to decide between incorporating the new features and bug fixes added to the code but being vulnerable to this crash bug and giving up on these new features and bug fixes and using an old version oflighttpd which is not vulnerable to this bug.
our approach provides users with a third choice when a new version arrives instead of replacing the old version we run both versions in parallel.
in our example consider that we are using mxto run a version of lighttpd from march .
when the buggy april version is released mxruns it in parallel with the old one.
as the two versions execute as long as the two versions have the same external behaviour e.g.
they write the same values into the same files or send the same data over the network they are run side by side and mxensures that they act as one to the outside world see iv a one of the versions crashes e.g.
the new version executes the buggy patch mxwill patch the crashing version at runtime using the behaviour of the non crashing version see iv b .
in this way mxcan successfully survive crash bugs in both the old and the new version increasing the reliability and availability of the overall application when a non crashing divergence is detected mxwill discard one of the versions by default the old one but other heuristics can be used .
the other version can be later restarted at a convenient synchronisation point e.g.
at the beginning of the dispatch loop of a network server .
from the user s point of view this process is completely transparent and does not cause any interruption in service.
in our example this effectively eliminates the bug in lighttpd while still allowing users to use the latest features and bug fixes of the recent versions.
iii.
f easibility study our approach is based largely on the assumption that during software evolution the changes to the external behaviour of an application are relatively small.
in the context of linux applications the external behaviour of an application consists of its sequence of system calls which are the primary mechanism for an application to change the state of its environment.
note that the key insight here is that we are only concerned with externally observable behaviour and are oblivious to the way the external behaviour is generated.
as a trivial example given two versions of a routine that outputs the smallest element of an array our approach considers them equivalent even if the first version scans the array from the first to the last element while the other scans it in reverse order.
to verify this assumption we compared successive revisions of the lighttpd web server namely revisions in the range of branch lighttpd .
.x which were developed and released over a span of approximately ten months from january to october .
to understand the amount of code changes in these versions we computed the number of lines of code loc that have changed from one version to the next.
during this period code patches in lighttpd varied between and loc with a median value of loc.
to compare the external behaviour of each version we traced the system calls made by these versions using the strace6 tool while running all the tests from the lighttpd regression suite targeting the core functionality a total of seven tests but each test contains a large number of test cases issuing http requests .
all tests were executed on a machine running a linux .
.
.
x86 kernel and the gnu c library .
.
the system call traces were further normalised and postprocessed.
we first split the original trace on a per process basis and normalised all differences caused by timing which would not affect mx s operation e.g.
we collapsed all sequences of accept poll system calls which represent repeated polling operations.
trace files were then post processed by eliminating individual system call arguments and return values.
this postprocessing step might reduce the precision of our comparison .
.
.
.
2612differences normalized revisions traces source codefig.
.
correlation of differences in post processed system call traces with differences in source code across revisions of lighttpd .
the seven named revisions are the only ones introducing external behaviour changes.
but we performed it because many system calls accept as arguments addresses of data structures residing in the virtual address space and these addresses may differ across versions but mxhandles this while mediating the effect of system calls as described in iv a .
finally for each test case we compared the traces of consecutive lighttpd versions using the edit distance.
our results are shown in figure which correlates the differences in post processed system call traces with the source code changes.
the graph shows that changes in externally observable behaviour occur only sporadically.
in fact versions which account for around of all the versions considered introduce no changes in external behaviour.
in particular the revision which introduced the bug described in ii is one of the versions that introduces no changes yet this revision is responsible for a critical crash bug.
iv.
m xprototype system we have implemented our approach in a prototype system called mx targeted at multi core processors running linux.
currently mxworks with only two application versions but we are adding support for arbitrarily many versions.
the system works directly on application binaries making it easy to deploy it and possibly integrate it with existing software package managers such as apt oryum.
on a platform using mx conventional i.e.
unmodified applications and multi version mv applications run side by side.
the key property that must hold on such a platform is that without purposely trying to do so applications should not be able to distinguish between conventional and mv applications running on the platform.
in particular the multiple versions of an mv application should appear as one to any other entity interacting with them e.g.
user operating system other machines .
furthermore mv applications should be more reliable and secure than their component versions and their performance should not be significantly degraded.
to achieve these goals our prototype mxemploys several different components as shown in the architectural overview of figure .
the input to mxconsists of the binaries of two fig.
.
m xsystem architecture.
versions of an application which we will refer to as the old version the one already running on the system and the new version the one newly released.
these two binaries are first statically analysed by the sea static executable analyser component which constructs a mapping from the control flow graph cfg of the old version to the cfg of the new version iv c .
the two versions are then passed to mxm multi execution monitor whose job is to run the two versions in parallel synchronise their execution virtualise their interaction with the outside environment and detect any divergences in their external behaviour iv a .
once a divergence is detected it is resolved by rem runtime execution manipulator which selects between the available behaviours and resynchronises the two versions after the divergence iv b .
the rest of this section describes the main mxsystem components and their implementation in more detail and discusses how they work together to support safe software updates.
a.mxm multi execution monitor one of the main components of our multi version execution environment is the mxmmonitor.
mxm s main jobs are to run the two versions concurrently mediate their interaction with the outside world synchronise their executions and detect any divergences in their external behaviour.
mxmworks by intercepting all system calls issued by each application version and manipulating them to ensure that the two versions are executed in a synchronised fashion and act as one to the outside world.
mxmis implemented using the ptrace interface provided by the linux kernel.
this interface often used for application debugging allows simple deployment without any need for compile time instrumentation and makes the monitor itself lightweight since it is running as a regular unprivileged process.
mxmis similar in operation to previous monitors whose goal is to synchronise applications at the level of system calls .
mxmruns each version in a separate child process intercepting all their system calls.
when a system call is intercepted in one version mxmwaits until the other version also performs a system call.
with a pair of system calls in hand one executed by the old version and one by the new version mxmcompares614their types and arguments.
if they differ mxmhas detected a divergence and invokes the remcomponent to resolve it iv b .
otherwise if the two versions perform the same system call with the same arguments mxmvirtualises their interaction with the environment.
if the operation performed by the system call has no side effects and does not involve virtualised state e.g.
sysinfo mxmallows both processes to execute it independently.
otherwise it executes the system call on their behalf and copies its results into the address spaces of both versions.
mxm must also enforce deterministic execution across versions.
this consists mainly of intercepting instructions that may produce non deterministic results and returning the same result in both versions.
examples of such nondeterministic operations include random number generators e.g.
read calls to dev random date and time e.g.
read calls to etc localtime and access to files and network e.g.
file descriptor consistency .
note that non deterministic effects resulting from allocating memory objects at different addresses in memory or randomly arranging memory areas via address space layout randomisation aslr do not pose any problems mxmunderstand the semantics of individual system calls and rather than directly comparing memory addresses which might be different in each executed version it compares the actual values stored at those memory locations.
there are several challenges that we encountered while implementing mxm.
first mxm must partly understand the semantics of system calls.
for example many system call parameters use complex often nested structures with complicated semantics to pass values to the operating system kernel as in the case of ioctl orfutex .
to be able to compare the parameters of these system calls and copy back their results mxmneeds to understand the semantics of these structures.
however there are only a relatively small number of system calls in linux and once the support for handling them is implemented it can be reused across applications.
mxmcurrently implements system calls out of the provided by linux x86 .
.
which was enough to allow us to run m xon our benchmarks v .
second the arguments of a system call are often passed through pointers which are only valid in the application address space which is not directly available to mxm.
therefore mxmneeds to copy the contents pointed to by these structures to its own address space in order to perform their comparison.
the ptrace interface on x86 only allows to copy one quadword per system call which is very expensive.
previous approaches either used various ad hoc optimisations such as named pipes or shared memory with custom shellcode or a modified kernel to overcome this limitation.
instead mxmuses cross memory attach a new mechanism for fast interprocess communication which has been recently added to the linux kernel .
finally a particular challenge arises in the context of multiprocess and multithreaded applications.
using a single monitor instance to intercept both versions and their child processes or threads would eliminate any advantage that these applications derive from using concurrency.
therefore mxmuses a new monitor thread for each set of child processes or threads spawned by the application.
for instance if the old and new versions each have a parent and a child process then mxm will use two threads one to monitor the parent processes and one to monitor the child processes in each version.
mxm does not enforce deterministic execution across multiple versions of multithreaded programs which may diverge if race conditions can lead to different external behaviour across executions although we could overcome this limitation by combining it with recently proposed deterministic multithreading systems such as d threads .
b.rem runtime execution manipulator at the core of our system lies the remcomponent which is invoked by mxmwhenever a divergence is detected.
remhas two main jobs to decide whether to resolve the divergence in favour of the old or the new version and to allow the other version to execute through the divergence and resynchronise the execution of the two versions after the divergence.
as discussed before in this paper we focus our attention on surviving crash errors so the key challenge is to allow the crashing version to survive the crash.
this is essential to the success of our approach which relies on having both versions alive at all times so that the overall application can survive any crash bugs that happen in either the old or the new version although of course not in both at the same time .
we emphasise that we apply our approach only to crash errors those raising a sigsegv signal and not to other types of program termination such as abort .
this is important from a security perspective because when a vulnerability is discovered but a proper solution is not yet known developers often fail stop the program rather than letting it continue and allowing the attacker to compromise the system.
suppose that one of the versions has crashed between the execution of system call s1and the execution of system call s2.
then in many common scenarios the code executed between the two system calls is responsible for the crash e.g.
the old version crashes because it doesn t incorporate a bug fix present in the new version or the new version crashes because its code was patched incorrectly .
therefore our strategy is to do a form of runtime code patching in which we use the code of the non crashing version to execute over the buggy code in the crashing version.
our exact recovery mechanism is illustrated in figure .
at each system call mxcreates a lightweight checkpoint of each version.
this is implemented using the clone system call in linux which internally uses a copy on write strategy.
as shown in figure suppose that the crash happens in version v2 between system calls s1ands2.
then remfirst restores v2at point s1 copies v1 s code into v2 s code segment executes over the buggy code using v1 s code but note that we are still using v2 s memory state and then restore v2 s code at point s2.
there are several challenges in implementing this functionality.
first remneeds the ability to read and write the application code segment.
in the current implementation we bypass this by linking together the two application versions after renaming all the symbols in one of the versions using a modified version615fig.
.
rem s recovery mechanism uses the code of the non crashing version to run through the buggy code.
of the objcopy tool.7however in the future we plan to implement this transparently by using the cross memory attach mechanism used by m xm.
second remneeds to modify the contents of the stack inv2.
this is necessary because the return addresses on the stack frames of v2still point to v2 s original code which was now replaced by v1 s code.
without also modifying v2 s stack any function return instruction executed between s1ands2 would most likely veer execution to an incorrect location since function addresses are likely to be different across different versions.
thus after remreplaces v2 s code it also updates the return addresses on v2 s stack with the corresponding return addresses in v1 which are obtained via static analysis iv c .
because system calls are invoked via wrapper functions in libc this ensures that when v2resumes execution it will immediately return to the code in v1.
to implement this functionality remmakes use of the libunwind library which provides a portable interface for accessing the program stack for both x86 and x86 architectures.
to actually modify the execution stack of v2 remuses again the ptrace interface.
unfortunately updating the stack return addresses is not sufficient to ensure that v2usesv1 s code between s1ands2 asv2may also use function pointers to make function calls.
to handle such cases reminserts breakpoints to the first instruction of every function in v2 s original code.
then when a breakpoint is encountered remis notified via a sigtrap signal and redirects execution to the equivalent function in v1 s code which is obtained from the seacomponent by simply changing the instruction pointer.
finally after executing through the buggy code rem performs the same operations in reverse it redirects execution tov2 s original code changes the return addresses on the stack to point to v2 s functions and disables all breakpoints inserted inv2 s code.
the one additional operation that is done at this point is to copy all the global data modified by v1 s code into the corresponding locations referenced by v2 s code.
note that mxcannot currently handle major modifications to the layout of the data structures used by the code including stack frames.
while this still allows us to support several common software update scenarios in future work we plan to improve the system with the ability to perform full stack reconstruction and automatically infer basic data structure changes at the binary level .
our approach of using the code of the non crashing version to survive failures in the crashing one may potentially leave the recovered version in an inconsistent state.
however mxis able to discover most internal state inconsistencies by comparing whether the two versions have the same external behaviour.
when the behaviour of the recovered version starts to differ mxwill immediately discard it and continue with only one version to ensure correctness.
the discarded version can be later restarted at a convenient synchronisation point.
this restarting functionality is not currently implemented in mx but we plan to add it as a future extension.
c.sea static executable analyser the seacomponent statically analyses the binaries of the two versions to obtain information needed at runtime by the mxmandremcomponents.
seais invoked only once when the multi version application is assembled from its component versions.
the main goal of seais to create several mappings from the code of one version to the code of the other.
first sea extracts the addresses of all functions in one version and maps them to the addresses of the corresponding functions in the other version.
this mapping is used by remto handle calls performed via function pointers iv b .
second seacomputes a mapping from all possible return addresses in one version to the corresponding return addresses in the other version.
in order to allow for code changes this mapping is done by computing an ordered list of all possible return addresses in each function.
for example if function foo inv1performs call instructions at addresses 0xabcd0000 and 0xabcd0100 and function foo inv2performs call instructions at addresses 0xdcba0000 and0xdcba0400 then sea will compute the mapping f0xabcd0005 !0xdcba0005 0xabcd0105 !0xdcba0405 g assuming each call instruction takes bytes .
this mapping is then used by remto rewrite return addresses on the stack.
to construct these tables seafirst needs to extract the addresses of all function symbols and then disassemble the code for each individual function in order to locate the call instructions within them.
the implementation is based on the libbfd andlibopcodes libraries part of the gnu binutils suite.
to obtain the addresses of all function symbols defined by the program seauses libbfd to extract the static and dynamic symbol tables and relocation tables.
to disassemble functions seauses the libbf library 10built on top of libopcodes .
v. e valuation to evaluate our approach we show that mxcan survive crash bugs in several real applications gnu coreutils v a redis v b and lighttpd v c .
we then examine the question i utilities from gnu coreutils the crash bugs used and the versions in which these bugs were introduced and fixed .
w e group together utilities affected by the same or similar bugs .
utility bug description bug span md5sumbuffer underflow v5.
v6.11sha1sum mkdirnull pointer dereference v5.
v6.11mkfifo mknod cut buffer overflow v5.
v8.
of how far apart can be the versions run by mx v d and discuss m x s performance overhead v e .
a. coreutils as an initial evaluation of mx s ability to survive crashes we have used applications from the gnu coreutils utility suite which provides the core user level environment on most unix systems.
we have selected a number of bugs reported on the coreutils mailing list all of which trigger segmentation faults.
the bugs are described in table i together with the utilities affected by each bug and the versions in which they were introduced and fixed.
for all these bugs we configured mxto run the version that fixed the bug together with the one just before.
mx successfully intercepted the crash and recovered the execution by using the strategy described in iv b. b. redis redis is an advanced key value data structure server used by many well known services such as github and flickr.
because the whole dataset is held in memory reliability is critically important as a crash could result in total data loss.
however like any other large software system redis is often subject to crash bugs.
issue 34413is one such example.
this issue causes redis to crash when the hmget command is used with the wrong type.
the bug was introduced during a code refactoring applied in revision 7fb16bac .
the original code of the problematic hmgetcommand function is shown in listing while the buggy refactored version is shown in listing .
in the original code if the lookup on line is successful but the type is not redis hash line the function returns after reporting an incorrect type lines .
however in the refactored version listing the return statement is missing and after reporting an incorrect type line the function continues execution and crashes inside the hashget function invoked on line .
this is a critical bug which may result in losing some or even all of the stored data.
the bug was introduced in april diagnosed and reported only half a year later in october and then fixed after fifteen days.
below we describe how mxcan survive this bug while running in parallel the redis revision a71f072f the old version just before the bug was introduced with revision 7fb16bac the new version just after the bug .
mxfirst seato perform a static analysis of the two binaries and construct the mappings described in iv c .
then mx invokes the mxmmonitor which executes both versions as child processes and intercepts their system calls.
when the new version crashes after issuing the problematic hmget command mxmintercepts the sigsegv signal which is sent to the application by the operating system.
at this point remstarts the recovery procedure.
first remsends a sigkill signal to the new version to terminate it.
it then takes the last checkpoint of the new version which was taken at the point of the last invoked system call which in this case is an epoll ctl system call.
then remuses the information provided by seato rewrite the stack of the new version as detailed in iv b .
in particular remreplaces the return addresses of all functions in the new version with the corresponding addresses from the old version.
remalso adds breakpoints at the beginning of all the functions in the code of the new version to intercept indirect calls via function pointers and then finally restores the original processor registers of the checkpointed process and restarts the execution of the modified new version.
since the checkpoint was performed right after the execution of the system call epoll ctl the first thing that the code does is to return from the libc wrapper that performed this system call.
this in turn will return to the corresponding code in the old version that invoked the wrapper since all return addresses on the stack have been rewritten.
from then on the code of the old version is executed but in the state of the new version until the first system call is intercepted.
in our example the old and the new versions perform the same system call and with the same arguments so remconcludes that the two processes have re converged and thus restores back the code of the new version by performing the steps above in reverse plus the additional step of synchronising their global state see iv b .
finally the control is handed back to the mxmmonitor which continues to monitor the execution of the two versions.
c. lighttpd to evaluate mxonlighttpd we have used two different crash bugs.
the first bug is the one described in detail in ii related to the etag and compression functionalities.
as previously discussed the crash is triggered by a very small change which decrements the upper bound of a for loop by one.
mxsuccessfully protects the application against this crash and allows the new version to survive it by using the code of the old version.
the other crash bug we reproduced affects the url rewrite functionality.14this is also caused by an incorrect bound in a for loop.
more precisely the loop for k k pattern len k should have been for k k pattern len k the bug seems to have been present since the very first version added to the repository.
it was reported in december and fixed one month later.
as a result we are running mxusing the last version containing the bug together with the o lookupkeyread c db c argv 2if o null 3addreplysds c sdscatprintf sdsempty 4for i i c argc i addreply c shared.nullbulk 7return else 9if o type !
redis hash addreply c shared.wrongtypeerr return 14addreplysds c sdscatprintf sdsempty listing .
original correct version of the hmgetcommand function inredis .1robj o value 2o lookupkeyread c db c argv 3if o !
null o type !
redis hash 4addreply c shared.wrongtypeerr 6addreplysds c sdscatprintf sdsempty 7for i i c argc i 8if o !
null value hashget o c argv !
null addreplybulk c value decrrefcount value else addreply c shared.nullbulk listing .
refactored buggy version of the hmgetcommand function inredis .
one that fixed it.
while this bug does not fit within the pattern targeted by mx where a newer revision introduces the bug from a technical perspective it is equally challenging.
mxis able to successfully run the two versions in parallel and help the old version survive the crash bug.
d. ability to run distant versions in the previous sections we have shown how mxcan help software survive crash bugs by running two consecutive versions of an application one which suffers from the bug and one which does not.
one important question is how far apart can be the versions run by mx.
to answer this question we determined for each of the bugs discussed above the most distant revisions that can be run together to survive the bug.
for the coreutils benchmarks we are able to run versions which are hundreds of revisions apart revisions corresponding to over one year and seven months of development time for the md5sum sha1sum bug revisions over four years of development time for the mkdir mkfifo mknod bug and revisions over two years and three months of development time for the cut bug.
the most distant versions for the first lighttpd bug are approximately two months apart and have revisions inbetween while the most distant versions for the second lighttpd bug are also approximately two months apart but have only revisions in between.
finally the most distant versions for theredis bug are revisions and days apart.
of course it is difficult to draw any general conclusions from only this small number of data points.
instead we focus on understanding the reasons why mxcouldn t run farther apart versions for the bugs in lighttpd andredis we ignore coreutils for which we can run very distant versions .
for lighttpd issue the lower bound is defined by a revision in which a pair ofgeteuid andgetegid calls are replaced with a single call to issetugid to allow lighttpd to start for a non root user with gid .
mxcurrently does not support changes to the order of system calls but we believe this limitation could be overcome by using peephole style optimisations which would allow mxto recognise that the pair geteuid and getegid could be matched with the call to issetugid .
the upper bound for lighttpd issue adds a read call to dev random in order to provide a better entropysource for generating http cookies.
this additional read call changed the sequence of system calls which mxcannot handle.
forlighttpd issue both the lower and the upper bounds are caused by a change in a sequence of read system calls.
we believe this could be optimised by allowing mxto recognise when two sequences of read system calls are used to perform the same overall read.
for the redis bug the lower bound is given by the revision in which the hmget command was first implemented.
the upper bound is defined by a revision which changes the way error responses are being constructed and reported which results in a very different sequence of system calls.
e. performance overhead we ran our experiments on a four core server with .
ghz intel xeon e3 and gb of ram running bit linux v3.
.
.
spec cpu2006 .to measure the performance overhead of our prototype we first used the standard spec cpu200615 benchmark suite.
figure shows the performance of mx running two instances of the same application in parallel compared to a native system.
the execution time overhead of mxvaries from .
to .
compared to executing just a single version with the geometric mean at .
.
coreutils .the six coreutils applications discussed in v a are mostly used in an interactive fashion via the command line interface cli .
for such applications a high performance overhead is acceptable as long as it is not perceptible to the user prior studies have shown that response times of less than 100ms typically feel instantaneous .
in many common use cases e.g.
creating a directory or using cut on a small text file the overhead of mxwas imperceptible e.g.
creating a directory takes around 1ms natively and 4ms with mx.
for the three utilities that process files we calculated the maximum file size for which the response time with mxstays under the 100ms threshold.
for cut the maximum file size is 10mb with an overhead of for md5sum 25mb overhead and for sha1sum 22mb overhead .
redis andlighttpd .to measure the performance overhead forredis we used the redis benchmark16utility which is part of the standard redis distribution and simulates get set .
.
.perlbench .bzip2 .gcc .mcf .gobmk .hmmer .sjeng .libquantum .h264ref .omnetpp .astar .xalancbmk .bwaves .gamess .milc .zeusmp .gromacs .cactusadm .leslie3d .namd .dealii .soplex .povray .calculix .gemsfdtd .tonto .lbm .wrf .sphinx3execution time normalized native0.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.04mx0.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.43fig.
.
normalised execution times for the spec cpu2006 benchmark suite running under m x. operations done by nclients concurrently with default workload.
for lighttpd we used the http load17multiprocessing test client that is also used by the lighttpd developers.
both of these standard benchmarks measure the end to end time as perceived by users.
as a result we performed two sets of experiments with the client and server located on the same machine which represents the worst case performance wise formx and with the client and server located on different continents one in england and the other in california which represents the best case.
the overhead for redis varies depending on the operation being performed from to1 in the remote scenario and from to16 in the local scenario.
the overhead forlighttpd varies from to1 in the remote scenario and from to3 in the local scenario.
despite the relatively large overhead in the local experiments the remote overhead is negligible because times are dominated by the network latency which in our case is over 150ms .
as a result we believe mxis most suitable for scenarios for which its execution overhead does not degrade the performance of the end to end task such as the remote redis andlighttpd scenarios discussed above or interactive tasks such as those performed using command line utilities where users would not notice the overhead as long as the response time stays within a certain range.
finally we would like to emphasise that our current prototype has not been optimised for performance and we believe its overhead can still be significantly reduced.
for example we could synchronise versions at a coarser granularity by using an epoch based approach or we could improve our checkpointing mechanism by implementing it as a loadable kernel module that only stores the part of the state needed for recovery .
vi.
d iscussion this section discusses in more detail the scope of our approach with regard to the type of software updates suitable to multi version execution and the different trade offs involved.
load types of code changes.
in order for mxto be successful the external behaviour of the versions that are run in parallel has to be similar enough to allow us to synchronise their execution.
our empirical study in iii shows that changes to the external behaviour of an application are often minimal so our approach should work well with versions that are not too distant from one another.
similarly our system relies on the assumption that versions re converge to the same behaviour after a divergence.
as a result we believe mxwould be a good fit for applications that perform a series of mostly independent requests such as network servers.
these applications are usually structured around a main dispatch loop which provides a useful re convergence point.
our approach is also suitable to local code changes which have small propagation distances thus ensuring that the different versions will eventually re converge to the same behaviour.
trade offs involved.
our approach is targeted toward scenarios where the availability reliability and security of a software system is more important than strict correctness high performance and low energy consumption.
in terms of correctness guarantees mxis similar to previous approaches such as failure oblivious computing which may sacrifice strict correctness for increased availability and security see iv b for details regarding possible problems caused by mx .
however mxalleviates this problem by using a previously correct piece of code to execute through the crash and by discovering most potential problems by regularly checking if the two versions have the same external behaviour.
finally note that mxalways reverts to running a single version when a non resolvable divergence is detected.
mxincurs a performance overhead as discussed in v e .
in our experience mxis readily deployable to interactive applications such as command line utilities text editors and other office tools where the performance degradation is not noticeable to the user.
we believe it is also applicable to server applications where availability is more important than high performance.
mxis not applicable to patches that fix performance bugs as the system runs no faster than the slowest version.
our approach of using idle cpu time to run additional versions also increases energy consumption.
however it is619interesting to note that idle cpus are not free either even without considering the initial cost of purchasing the cores left idle an energy efficient server consumes half its full power when virtually no work and for other servers this ratio is usually much worse .
vii.
r elated work we have introduced the idea of multi version software updates in a hotswup workshop position paper .
n version programming paradigm.
the original idea of concurrently running multiple versions of the same application was first explored in the context of n version programming a software development approach introduced in the 1970s in which multiple teams of programmers independently develop functionally equivalent versions of the same program in order to minimise the risk of having the same bugs in all versions .
during runtime these versions are executed in parallel and majority voting is used to continue in the best possible way when a divergence occurs.
cook and dage proposed a multi version framework for upgrading components.
users formally specify the specific input subdomain that each component version should handle after which versions are run in parallel and the output of the version whose domain includes the current input is selected as the overall output of the computation.
the system was implemented at the level of leaf procedures in the tcl language.
the key difference with mxis that this framework requires a formal description of what input domain should be handled by each version in comparison mxtargets crash bugs and is fully automatic.
moreover mx s goal is to have all versions alive at all times so crash recovery plays a key role.
finally mxhas to carefully synchronise access to shared state which is not an issue at the level of tcl leaf procedures.
more recently researchers have proposed additional techniques that fit within the n version programming paradigm e.g.
by using heap over provisioning and full randomisation of object placement and memory reuse to run multiple replicas and reduce the likelihood that a memory error will have any effect employing complementary thread schedules to survive concurrency errors or using genetic programming to automatically generate a large number of application variants that can be combined to reduce the probability of failure or improve various non functional requirements .
we have also argued that automatically generated software variants are a good way for exploiting the highly parallel nature of modern hardware platforms .
cox et al.
propose a general framework for increasing application security by running in parallel several automaticallygenerated diversified variants of the same program.
the technique was implemented in two prototypes one in which variants are run on different machines and one in which they are run on the same machine and synchronised at the system call level using a modified linux kernel.
within this paradigm the orchestra framework uses a modified compiler to produce two versions of the same application with stacks growing in opposite directions runs them in parallel on top of an unprivileged user space monitor and raises an alarm ifany divergence is detected to protect against stack based buffer overflow attacks.
there are two key differences between our approach and the work discussed in the last two paragraphs.
first we do not rely on automatically generated variants but instead run in parallel existing software versions which raises a number of different technical challenges.
second this body of work has mostly focused on detecting divergences while our main concern is to survive them keeping all versions alive in order to increase both the security and availability of the overall application.
an approach closer to the original n version programming paradigm is cocktail which proposes the idea of running different web browsers in parallel under the assumption that any two of them are unlikely to be vulnerable to the same attacks.
compared to mxand other techniques inspired by the nversion programming paradigm cocktail s task is simplified by exclusively targeting web browsers which implement common web standards.
online and offline testing.
back to back testing where the same input is sent to different variants or versions of an application and their outputs compared for equivalence has been used since the 1970s.
more recently delta execution proposes to run two different versions of a single application splitting the execution at points where the two versions differ and comparing their behaviour to test the patch for errors and validate its functionality.
band aid patching proposes an online patch testing system that also splits execution before a patch and then retroactively selects one code version based on certain criteria.
similarly tachyon is an online patch testing system in which the old and the new version of an application are run concurrently when a divergence is detected the options are to either halt the program or to create a manual rewrite rule specifying how to handle the divergence.
the idea of running multiple executions concurrently has also been used in an offline testing context.
for instance d amorin et al.
optimise the state space exploration of object oriented code by running the same program on multiple inputs simultaneously while kim et al.
improve the testing of software product lines by sharing executions across a program family.
by comparison with this body of work our focus is on managing divergences across software versions at runtime in order to keep the application running and therefore runtime deployment and automatic crash recovery play a central role in mx.
software updating.
dynamic software updating dsu systems such as ginseng upstare or kitsune are concerned with the problem of updating programs while they are running.
as opposed to mx the two versions co exist only for the duration of the software update but dsu and the remcomponent of mxface similar challenges when switching execution from one version to another.
we hope that some of the technique developed in dsu research will also benefit the recovery mechanism of m xand vice versa.
other prior work on improving software updating has looked at different aspects related to managing and deploying new software versions.
for example beattie et al.
have considered the issue of timing the application of security updates while crameri et al.
proposed a framework for staged620deployment in which user machines are clustered according to their environment and software updates are tested across clusters using several different strategies.
in relation to this work mxtries to encourage users to always apply a software update but it would still benefit from effective strategies to decide what versions to keep when resources are limited.
surviving software failures.
mx s main focus is on surviving errors.
prior work in this area has employed several techniques to accomplish this goal.
for example rx helps applications recover from software failures by rolling back the program to a recent checkpoint upon a software failure and then re executing it in a modified environment.
mxsimilarly rolls back execution to a recent checkpoint but instead of modifying the environment it uses the code of a different version to survive the bug.
the two approaches are complementary and could be easily combined to support a larger number of errors and application types.
failure oblivious computing helps software survive memory errors by simply discarding invalid writes and fabricating values to return for invalid reads enabling applications to continue their normal execution path.
similar to failureoblivious computing execution transactions help survive software bugs by terminating the function in which the bug has occurred and continuing to execute the code immediately following the corresponding function call.
our approach shares some of the philosophy of these two techniques as we cannot always guarantee that the crashing version will correctly execute through the divergence when using the other version s code.
however by using a previously correct piece of code to execute through the crash and regularly checking for divergences in the external behaviour our approach provides stronger guarantees than those obtained by fabricating read values or terminating the function in which the bug occurred.
viii.
c onclusion software updates are an important part of the software development and maintenance process.
unfortunately they also present a high failure risk and many users refuse to upgrade their software relying instead on outdated versions which often leave them exposed to known software bugs and security vulnerabilities.
in this paper we have proposed a novel multi version execution approach for improving the software update process.
whenever a new program update becomes available instead of upgrading the software to the newest version we run the new version in parallel with the old one and carefully synchronise their execution to create a more secure and reliable multiversion application.
our ultimate goal is to enable users to benefit from the additional features and bug fixes provided by recent versions without sacrificing the stability and security of older versions.