reducing confounding bias in predicate level statistical debugging metrics ross gore and paul f. reynolds jr. dept.
of computer science university of virginia charlottesville va usa rjg7v reynolds virginia.edu abstract statistical debuggers use data collected during test case execution to automatically identify the location of faults within software.
recent work has applied causal inference to eliminate or reduce control and data flow dependence confounding bias in statement level statistical debuggers.
the result is improved effectiveness.
this is encouraging but motivates two novel questions how can causal inference be applied in predicate level statistical debuggers and what other biases can be eliminated or reduced.
here we address both questions by providing a model that eliminates or reduces control flow dependence and failure flow confounding bias within predicate level statistical debuggers.
we present empirical results demonstrating that our model significantly improves the effectiveness of a variety of predicate level statistical debuggers including those that eliminate or reduce only a single source of confounding bias.
keywords automated debugging fault localization i. i ntroduction recently there has been considerable research on using statistical approaches for fault localization .
these approaches referred to as statistical debuggers require test inputs corresponding execution profiles and a labeling of the test executions as either succeeding or failing.
the execution profiles reflect coverage of individual statements the truth values of branches or other inserted predicates conditional propositions .
in the canonical predicate level statistical debugger cooperative bug isolation cbi three predicates are inserted and tested for each assignment statement to or return of a variablek k k and k .
within the predicate level statistical debugger exploratory software predictor esp these three predicates are complemented with elastic predicates.
elastic predicates use profiling to compute the mean k and standard deviation k of the values assigned to or returned from a variable k. using these profiled statistics the cbi predicates are complemented with elastic predicates such as k k k k k and k k k .
once formed the predicates in esp and cbi are scored for suspiciousness.
then developers examine the predicates in decreasing order of suspiciousness until the fault is discovered.
one metric used to score predicate suspiciousness is the probability of a program qfailing given that a predicate pis true.
this probability pr qfails p true indicatesif the condition specified by predicate pwas true during an execution of q. given the execution of a test suite pr qfails p true is typically estimated by the specificity metric fp fp sp wherefpis the number of tests for which pis true and the program fails and where spis the number of tests for which pis true and the program succeeds.
approaches that estimate the probability pr qfails p true use statistical techniques on observational data to determine the effect of individual predicates on program failures.
however the suspiciousness metrics used in these approaches can be susceptible to biases.
recently baah et.
al.
showed that control flow dependence confounding bias exists within statement level suspiciousness metrics .
confounding bias occurs when an apparent causal effect of an event on an outcome may actually be due to an unknown confounding variable which causes both the event and the outcome .
baah et al.
showed that coverage of the immediately preceding dependent statement in the control flow the forward control flow predecessor can cause dependent statements to contribute to a program s failure and that existing metrics do not account for this control flow confounding bias .
by accounting for control flow confounding bias bias at the statement level baah et al.
improved the effectiveness for a variety of established statement level statistical debugging suspiciousness metrics.
more recently baah et al.
improved their statement level approach by also controlling for confounding bias caused by data flow dependences between statements .
here we look to adapt baah et al.
s work for predicatelevel statistical debuggers.
the adaptation has challenges requiring innovation.
one of the contributions of our work is a robust method to efficiently track the forward control flow predecessor predicate and employ it in a causal inference model that eliminates control flow confounding bias in different predicate level statistical debugging metrics.
within predicate level statistical debugging approaches the issue of bias has been previously explored.
liblit et al.
showed that the estimatefp fp sp of pr qfails p true is biased .
the estimate is biased because once the fault in a program has been triggered the probability of the program failing is .
thus the observations collected from .
c ieee icse zurich switzerland authorized licensed use limited to old dominion university.
downloaded on november at utc from ieee xplore.
restrictions apply.
subsequent predicates are more susceptible to failure.
this reflects failure flow confounding bias .
liblit et al.
proposed the suspiciousness metric importance as a correction for failure flow confounding bias .
importance measures the suspiciousness of a predicate p not by the chance that it implies failure but by how much difference it makes that the predicate pis observed to be true versus simply reaching the line where the predicate p is evaluated .
within importance pr qfails p true is estimated by the difference fp fp sp fp obs fp obs sp obs .
here fp obs andsp obs are the number of respective failing and succeeding test runs for which pis reached and evaluated true or false .
this correction attempts to factor out predicates that are more susceptible to failure because of the program flow once the fault is triggered.
while this heuristic can be effective it is not a proven solution.
the second contribution of our work is a causal inference model which accounts for failure flow confounding bias at the predicate level.
the combination of our two contributions yields a predicate level statistical debugging metric that is significantly more effective than existing metrics because thecontrol flow and failure flow confounding biases are reduced and or eliminated.
these contributions are needed.
while control flow and data flow dependence biases are evident at the statementlevel and the predicate level failure flow is only distinguishable at the predicate level .
we present an empirical evaluation showing that our model significantly improves the effectiveness of a variety of predicate level statistical debugging metrics in two different predicate level statistical debuggers.
ii.
m otivating example an example helps elucidate how confounding bias occurs in predicate level suspiciousness metrics.
consider the proceduredistance in figure which has a fault in statement .
the procedure should print the one dimensional euclidean distance between two points xandy.
however for some test cases distance returns a negative number.
the observational data collected for the truth of the predicates for statements and is shown in table i. the first two columns in table i identify the statement number and condition tested in each of the predicates.
the third through the seventh columns identify the inputs for five test cases.
the entires within these columns indicate if the corresponding predicate was true in each test case.
an entry of means that the predicate was true and an entry of means that the predicate was not true.
the bottom row of table i shows the boolean outcome of executing each test case.
a failing test case execution is denoted by f and a successful or passing test case execution is denoted by s .
the two rightmost columns sr and cr in table i indicate the rank of each predicate based on two different 13int distance int x int y int diff x y if !
diff off by one int dist dist y x print dist int dist dist x y return dist figure .
faulty function that calculates euclidean distance between two one dimensional points.
table i testcases and predicate data for figure .
loc predicate sr cr 5diff 5diff 5diff 6dist 6dist 6dist 7dist 7dist 7dist 8dist 8dist 8dist s f s f s s f suspiciousness metrics.
the first metric is the specificity metric described in the introduction.
the second metric found in the rightmost column of table i is derived from a causal model which controls for the effects of other predicates on the suspiciousness of the predicate being estimated and on the occurrence of program failure.
table i shows that the specificity metric identifies three predicates which rank as the most suspicious predicates in the procedure distance shown in figure .
these predicates are diff dist 7and dist .
a predicate xspecifying a condition corresponding to program statement yis abbreviated as xy.
the first predicate diff reflects the location of the fault in the proceduredistance .
however the two other predicates have the same suspiciousness rank as diff 5and correspond to innocent statements.
these two predicates have the same rank as the fault localizing predicate despite their ties to innocent statements because their truth is dependent on the condition diff 0in statement .
this dependence causes the predicates dist 7and dist 8to be true in every failing execution.
since thespecificity metric does not control for dependence among authorized licensed use limited to old dominion university.
downloaded on november at utc from ieee xplore.
restrictions apply.
predicates confounding bias exists and the two dependent predicates dist 7and dist 8receive the same rank as the fault localizing predicate diff .
this dependency related confounding bias is referred to as control flow confounding bias .
however another type of confounding bias exists in the specificity metric used to rank the predicates in the procedure distance .
additional confounding bias exists because the fault in statement is triggered before the predicates corresponding to statements and are evaluated.
this bias is evident in the specificity suspiciousness rank calculated for the predicate dist which corresponds to the innocent declaration of the variable dist .
while the condition dist in statement is uncorrelated with failure it is always true immediately following the execution of statement and thus is true in every failing test case.
as a result the specificity metric finds the predicate dist 6to be suspicious.
however it is important to note that the chance of a test case failing given that dist 6is true is the same as the chance of a test case failing given that statement is executed.
the inability to control for the difference between the chance of a test case failing given that a predicate is true and the chance of a test case failing given that the predicate is evaluated true or false results in a second type of confounding bias failure flow confounding bias .
the factors that create control flow and failure flow confounding bias can be controlled for in a causal model.
the causal model produces a suspiciousness metric with reduced bias that more effectively ranks predicates for fault localization.
in this example the causal model predicate rankings clearly identify one suspicious predicate that localizes the fault in the procedure distance in figure .
this is shown in the right hand column of table i. in section iii the factors that create control flow and failure flow confounding bias are identified and causal models which produce suspiciousness metrics with reduced bias are presented.
iii.
c ontrolling for confounding bias within the motivating example in section ii two different types of confounding bias are evident control flow and failure flow .
while controlling for both of these confounding biases through a causal model to estimate suspiciousness for predicate level statistical debuggers is our novel work each of the biases has been previously explored separately in other research.
at the statement level baah et al.
have shown that in a subject program control flow confounding bias is manifested on a given statement stmt through the execution of the statement immediately preceding stmt in the control flow graph.
this statement is the forward control flow predecessor ofstmt.
by employing a causal model to control for the forward control flow predecessor baah et al.
improved theeffectiveness of suspiciousness metrics for statement level statistical debuggers .
in section iii c we adapt baah et al.
s statement level work on reducing control flow confounding bias to the predicate level.
while control flow confounding bias had not been perviously explored at the predicate level failure flow confounding bias has.
liblit et al.
have shown that failure flow confounding bias exists in the specificity metric and proposed the importance measure to address it.
recall the importance measure estimates pr qfails p true with the difference fp fp sp fp obs fpobs spobs .
the terms fpobs andsp obs are the number of respective failing and succeeding test cases for which pis evaluated.
liblit et al.
s estimate of pr qfails p true measures not the chance that a predicate pimplies failure but how much difference it makes that the predicate pis observed to be true versus simply reaching the line where the predicate pis evaluated .
this correction is a heuristic to factor out the program flow once the fault is triggered within a subject program.
while liblit et al.
s heuristic can be effective it does not employ a methodology such as causal inference that is a proven solution for addressing confounding bias.
in section iii d our causal model which reduces control flow and failure flow confounding bias is presented.
the evaluation in section iv shows that employing this causal model to control for both confounding biases results in significantly more effective suspiciousness metrics for predicate level statistical debuggers than any existing suspiciousness metrics including liblit et al.
s importance estimate.
however before any of our models for reducing confounding bias are presented section iii a and section iii b review background information related to suspiciousness metrics observational studies confounding bias and causal inference which is required to understand our approach.
a. existing suspiciousness metrics the extent to which a predicate preflects subject program failure is measured through a suspiciousness metric .
the following terms are used in existing predicate level metrics to estimate suspiciousness sis the total number of tests that succeed pass fis the total number of tests that fail sp is the number of tests that succeed where pis true and fp is the number of tests that fail where pis true.
different suspiciousness metrics use these terms differently.
here several established suspiciousness metrics are reviewed.
tarantula the tarantula suspiciousness metric shown in eq.
is closely related to the specificity metric tarantula fp f fp f sp s. tarantula differs from specificity because it includes the number of failed test cases f in the numerator and denominator and it includes the number of successful test cases s authorized licensed use limited to old dominion university.
downloaded on november at utc from ieee xplore.
restrictions apply.
in the denominator.
however when s fas shown in eq.
tarantula reduces to the specificity metric tarantula fp f fp f sp s fp f fp f sp f fp fp sp.
f1 f1balances an estimate of pr qfails p true with an estimate of the probability that predicate pis true given that the subject program qfailed pr p true q fails .
the sensitivity metric fp f is used in the f1measure to estimate pr p true qfails .
the inclusion of sensitivity within a suspiciousness metric addresses issues that occur when a predicate pis true in very few failing test cases.
without sensitivity if there are many successful passing test cases where pis true the overall sample of test cases where pis true will be unbalanced and thespecificity will be low even if there are very few failed test cases.
conversely if there are few successful passing test cases where pis true the overall sample of test cases wherepis true will be small and the specificity could be high even if there are many failed test cases where predicate pis not true f1 fp f fp fp sp.
importance liblit s importance measure is closely related to the f1metric .
however the specificity metric used in the f1metric is replaced with the difference fp fp sp fp obs fpobs spobs .
this difference is referred to as the increase .
the first term in increase is identical to the specificity metric.
however the second term inincrease is meant to ensure that predicate pis scored not by the chance that pimplies failure but by how much difference it makes that pis true versus simply reaching the statement where pis evaluated true or false .
formally the importance measure shown in eq.
is importance fp f increase.
ochiai other statistics besides the harmonic mean can be employed to balance the metrics specificity and sensitivity .
the ochiai metric shown in eq.
balances specificity andsensitivity with the geometric mean ochiai s fp f fp fp sp.
b. observational studies and confounding bias reducing or eliminating confounding bias within observational studies is a well studied research topic.
in this section we view predicate level statistical debugging as an observational study and a novel approach to reduce confounding bias is summarized.
casting predicate level statistical debugging as an observational study yields two groups of test case executions.these two execution groups are those where predicate p is true the treatment group and those where predicate p is not true the control group .
for a predicate p the membership of a test case in either the treatment or the control group is denoted by the treatment variable tp.
for those test cases where predicate pis true tp .
for those test cases where predicate pis not true tp .
independent of the presence of a given predicate test case executions can also be classified with an outcome variable y. a successful test case execution is denoted by y and a failing test case execution is denoted by y .
in the context of an observational study estimating the average treatment effect of a predicate on a test case corresponds to estimating the probability of program qfailing given that a specific predicate pis true pr qfails p true .
the average treatment effect of a predicate p is estimated by a regression model.
the most basic estimate for the average treatment effect of a predicate is computed using the regression model in eq.
.
the model is linear and is solved with least squares regression pis an intercept and pis a random error term that is uncorrelated with tp .
the estimate of pr qfails p true yields the same ranks as the specificity metric.
for each predicate pin a faulty subject program qfit a separate model mpaccording to the following a the outcome variableyis for a test case if it fails and is otherwise.
b the treatment indicator tpis for a test case if pis true and is otherwise.
rank the predicates in descending order of ls p. ls p is the least squares estimate for each predicate of the coefficient of the treatment variable tpin the model mp.
y p ptp p the model shown in eq.
shows the symmetry between the specificity metric and the estimate of the average treatment effect of a predicate on subject program test case outcomes.
however the model in eq.
ignores any dependencies between the treatment variable tpand the outcome variable y. this relationship reflects treatment selection .
ignoring treatment selection is equivalent to assuming the treatment variable tpand the outcome variable yare independent.
the metrics in section iii a make this assumption.
as a result they suffer from confounding bias.
it is often possible to characterize the process of treatment selection in terms of one or more important variables.
if a set of covariates accounts well for which units in an observational study receive treatment and which do not then it is possible to reduce or eliminate confounding bias when estimating the average treatment effect.
in the context of statistical debugging if a set xof covariates accounts well for those test cases where a given predicate pis true authorized licensed use limited to old dominion university.
downloaded on november at utc from ieee xplore.
restrictions apply.
t and those test cases where pis not true t then it is possible to reduce or eliminate confounding bias in the suspiciousness estimate for a predicate.
this is accomplished by controlling for or conditioning on xin a model that estimates the average treatment effect of a predicate .
in the next sections models which employ this approach to control for different covariates are presented.
c. control flow dependency confounding bias our predicate level adaptation of baah et al.
s statementlevel work for controlling for control flow confounding bias begins with defining and identifying the forward control flow predecessor statement for a given predicate.
this requires a review of control flow graphs and statement dependency.
a program s control flow graph is a directed graph whose nodes correspond to program statements and whose edges represent control dependences between statements .
node yiscontrol dependent on node xifxhas two outgoing edges and the traversal of one edge always leads to the execution of ywhile the traversal of the other edge does not necessarily execute y. nodexdominates nodeyin a control flow graph if every path from the entry node to ycontains x. nodeyisforward control dependent on nodexifyis control dependent on xandy does not dominate x .
forward control dependences are control dependences that can be realized during execution without necessarily executing the dependent node more than once.
node xis a forward control flow predecessor of nodeyifyisforward control dependent onxandx immediately precedes yin the control flow graph.
the statement corresponding to node xis the forward control flow predecessor statement of the statement corresponding to nodeythat is defined by baah et al.
.
we identify the forward control flow predecessor predicate using an approach that is similar to baah et al.
s algortihm to find the forward control flow predecessor statement .
for a given predicate p corresponding to statement stmt both approaches extract the control dependence graph of a subject program and identify the control flow statement in the graph immediately preceding stmt.
this is the forward control flow predecessor forstmt.
however identifying the forward control flow predecessor forprequires an additional step.
recall a statement reflects a line of source code while predicates represent conditions that are true about variables within the line of source code.
thus given a forward control flow statement the forward control flow predecessor predicate is located by instrumenting the forward control flow predecessor statement with two branch predicates.
the first of the two predicates asserts that the branch is false.
the second of the two predicates asserts that the branch is true.
when the branch is reached exactly one of the two predicates will be true.
the predicate that is true is the forward control flow predecessor predicate .this approach is applicable to all two way branches in subject programs.
two way branching statements include ifstatements branches governing for andwhile loops branches implied by the logical and0 0operators and implicit branches.
however multiple way switch statements are rarely two way branches.
as a result each branch of a switch statement is instrumented with a predicate which asserts that the branch is true.
when the switch statement is reached exactly one of the branches and one of the predicates will be true.
the predicate that is true is the forward control flow predecessor predicate .
branch predicate instrumentation is not a contribution of our work however innovatively employing branch predicates to capture forward control flow predecessor predicates is our contribution.
the ability to capture the forward control flow predecessor predicate for a given predicate enables our model which controls for control flow dependency confounding bias to be defined.
given an instrumented subject program and the feedback reports from executing a set of test cases with a predicate level statistical debugger such as cbi or esp the following model reduces or eliminates control flow confounding bias for each predicate pin a faulty model qfit a separate linear model mpaccording to the following a the outcome variableyis for a test case if it fails and is otherwise.
b the treatment variabletpis for a test if pis true and is otherwise.
c ifphas a forward control flow predecessor predicate cfp p thenmphas a single binary covariate cp which is for a test case if cfp p is true and is otherwise.
if pdoes not have a forward control flow predecessor predicate then mphas no covariates.
rank the predicates in descending order of c ls p the least squares estimate for each predicate of the coefficient of tpinmp.
the resulting linear model for a predicate pis y c p c ptp c pcp c p the coefficient c ls pis the average treatment effect of predicate pon subject test case outcomes.
this estimate is a reduced bias version of the specificity metric.
the role of covariate cpis to control for confounding bias of the suspiciousness estimate for predicate p due to the truth of other subject program predicates.
intuitively conditioning on cpreduces confounding bias because cfp p is the most immediate cause of pbeing evaluated or pnot being evaluated in a particular test case.
pearls back door criterion for causal graphs provides a formal causal inference justification for the model in eq.
.
for any subject program where failure is determined authorized licensed use limited to old dominion university.
downloaded on november at utc from ieee xplore.
restrictions apply.
with a single output statement and control dependences carry all the causal influences of failure any back door paths from a predicate to the output statement must begin with the forward control flow predecessor predicate cfp p .
thus cfp p is a suitable covariate of tpbecause it satisfies pearl s back door criterion.
it blocks all back door paths in the dynamic control flow graph from the predicate corresponding to the treatment variable tpto output statement corresponding to the outcome variable y. as a result the control flow dependency confounding bias in c ls p the model s estimate of the average treatment effect is reduced.
d. failure flow confounding bias recall liblit et al.
s importance measure employs the difference fp fp sp fp obs fpobs spobs as a heuristic to reduce failure flow confounding bias .
the term measures not the chance that a predicate pimplies failure but how much difference it makes that the predicate pis observed to be true versus simply reaching the line where the predicate pis evaluated .
while this can be an effective means of reducing failure flow confounding bias it is a heuristic not a proven solution.
formally reducing or eliminating failure flow confounding bias requires a causal model where the set of covariates within the model satisfy the causal inference back door criterion .
the difference fp fp sp fp obs fpobs spobs does not meet these requirements.
in this subsection our model which controls for predicate evaluation true or false satisfies pearl s backdoor criterion and reduces failure flow confounding bias is presented.
given the outcomes and predicate coverage vectors from executing a set of test cases with a predicate level statistical debugger such as cbi or esp the following approach reduces or eliminates both control flow and failure flow confounding biases for each predicate pin a faulty model qfit a separate linear model mpaccording to the following a the outcome variableyis for a test case if it fails and is otherwise.
b the treatment variabletpis for a test if pis true and is otherwise.
c ifphas a forward control flow predecessor predicate cfp p thenmphas a single binary covariate cp which is for a test case if cfp p is true and is otherwise.
if pdoes not have a forward control flow predecessor predicate then mpdoes not have this covariate.
d the covariate dpis for a test case if pis evaluated true or false and is otherwise.
rank predicates in descending order of c f ls p the leastsquares estimate for each predicate of the coefficient oftpinmp.the resulting linear model for a predicate pis y p c f ptp c f pcp !c f pdp p here the coefficient c f ls pis the least squares estimate of the average treatment effect of a predicate pon the subject program test case outcomes.
the notable difference between eq.
and the causal model shown in eq.
is the inclusion of the covarite dp which reflects whether or not predicate pis evaluated.
intuitively dpfurther reduces confounding bias because it enables the model to determine how much difference it makes that the predicate pis observed to be true versus simply reaching the line where the predicate p is evaluated.
once again inclusion of the covariate cpblocks all backdoor paths from the predicate corresponding to the treatment variabletpto the output statement corresponding to the outcome variable y. this enables the additional source of bias controlled for by dpto be reduced without introducing other sources of bias into c f ls p. this is significant.
without the inclusion of covariate cpin the model to block all backdoor paths dpwould not be a suitable covariate.
e. improving existing suspiciousness estimates the reduced bias metrics derived in sections iii c and iii d can be integrated into the suspiciousness metrics presented in section iii a. recall that tarantula and the reduced bias metrics c ls pand c f ls pare similar to specificity .
thus integrating either c ls pand c f ls pinto the tarantula metric is a straightforward substitution.
it is slightly more difficult to integrate c ls pand c f ls p into the ochiai f1andimportance metrics because these measures also employ sensitivity .
as a result both c ls pand c f ls pmust be converted into a probability value before either can replace the specificity measure in the ochiai f1or importance metrics.
the inverse logit function exp x exp x is used to convert c ls pand c f ls pinto a probability value.
the function constrains the value of the reduced bias estimates to the range .
.
and ensures the combination with the sensitivity measure is meaningful.
once converted c ls pand c f ls pcan be substituted into the ochiai f1andimportance metrics in place of the biased specificity estimate.
performing this substitution in the f1 metric and the importance measure renders the two metrics indistinguishable because the only term in which they differ is replaced with c ls por c f ls p. iv.
e vaulation a. experimental setup the utility of a statistical debugging approach is determined through empirical evaluation using established benchmarks.
characteristics of the benchmarks included in our evaluation are listed in table ii.
each was obtained from except bc which was obtained from .
authorized licensed use limited to old dominion university.
downloaded on november at utc from ieee xplore.
restrictions apply.
table ii evaluation benchmarks name loc vers.
tests description tcas altitude seperation totinfo information measure schedule priority queue schedule2 priority queue print tokens lexical analyzer print tokens2 lexical analyzer replace pattern recognition sed stream editing utility space adl interpreter bc basic calculator gzip compression utility the siemens suite consists of seven benchmarks and faulty versions.
in our evaluation we omitted four versions version of replace version of schedule2 and versions and of print tokens.
we omitted these versions because either there were no syntactic differences between the correct version and the faulty versions of the program or none of the test cases failed when executed on the faulty version of the program.
the space program has faulty versions and several different coverage based test suites.
we used of the faulty versions.
for these versions we found a test suite that achieved branch coverage and resulted in a combination of passing and failing tests cases.
we had difficulty finding such a test suite for the remaining three versions.
there are seven versions of the sed program with multiple faults per version that can be activated separately.
we activated one fault for each of the seven versions.
bc is a calculator program with a reported buffer overflow fault .
our bc test suite is comprised of valid randomly generated programs with various sizes and complexities.
gzip is a well known compression utility with an established test suite .
in total we evaluated faulty versions.
for each test case using the cil framework we computed feedback reports to communicate test case success or failure predicate truth and predicate evaluation .
also using cil we computed the dynamic control flow graph for each function in each version.
our approach uses the feedback reports and control flow graphs as inputs.
the regression models and the existing suspiciousness metrics are implemented in the statistical language r .
b. ranking effectiveness to measure the effectiveness of the suspiciousness metrics we use an established cost measuring function cost .
cost measures the percentage of predicates a developer must examine before the faulty statement is found assuming the predicates are presented in descending order of suspiciousness.
to compare two metrics a and b0102030405060708090 0510152025absolute improvement faulty versionabsolute improvement faulty version a standard tarantula as the reference metric.
10absolute improvement faulty versionabsolute improvement faulty version b c ls pas the reference metric.
figure .
tarantula evaluation.
for effectiveness we choose one metric b as the reference metric and subtract the cost value for a from the cost value for b. if a performs better than b then the cost is positive and if b performs better than a the cost is negative.
for example for a given program if the cost of a is and thecost of b is then the absolute improvement of a over b is because developers would examine fewer predicates using a instead of b. we integrate the reduced bias metrics c ls pand c f ls p into thetarantula f1and ochiai metrics.
we evaluate each reduced bias metric in cbi red and esp white .
for each program version the absolute improvement of each reduced bias metric within each predicate level debugger is represented with a bi colored bar.
the height of the colored portion of the bar closest to the x axis reflects the authorized licensed use limited to old dominion university.
downloaded on november at utc from ieee xplore.
restrictions apply.
200204060absolute improvement faulty versionabsolute improvement faulty version a standard f1as the reference metric.
051015absolute improvement faulty versionabsolute improvement faulty version b f1integrated with c ls pas the reference metric.
figure .
f1evaluation.
improvement for the matching debugger.
the total height of both portions reflects the improvement for the debugger matching the colored portion furthest from the x axis.
predicate level tarantula suspiciousness metric here we evaluate the effectiveness of the two reduced bias metrics c ls pand c f ls pcompared to the standard tarantula suspiciousness metric in the predicate level statistical debuggers cbi and esp.
c ls pand c f ls pare obtained from the models presented in eq.
and eq.
respectively.
fig.
a shows that the reduced control flow confounding bias estimate c ls p performs better than the standard tarantula metric on program versions within cbi and esp but it performs worse on two versions.
c ls pperforms the same as the standard tarantula metric on versions.
fig.
b compares c ls pand c f ls p. it uses c ls pas the reference metricand measures the cost of c ls psubtracted from the cost of c f ls p. c f ls pperforms better than c ls pfor of the versions and it never performs worse.
predicate level f1suspiciousness metric here we evaluate the effectiveness of c ls pand c f ls pwithin the f1 metric in cbi and esp.
fig.
a shows that the f1metric employing c ls pperforms better than the f1metric using the standard specificity measure on versions within cbi and esp but performs worse on seven versions.
the metrics perform the same on versions.
fig.
b compares f1 metric employing c ls pto the version c f ls p. once again the metric employing c f ls poutperforms the metric using c ls p. thef1metric employing c f ls pperforms better than the f1 metric employing c ls pfor of the programs and it never performs worse.
predicate level ochiai suspiciousness metric here we evaluate the effectiveness of c ls pand c f ls pwithin the ochiai metric in cbi and esp.
fig.
a shows that the ochiai metric employing c ls p performs better than the ochiai metric using the standard specificity measure on versions within cbi and esp but performs worse on two versions.
the metrics perform the same on versions.
fig.
b compares ochiai metric employing c ls pto the version using c f ls p. again the metric employing c f ls poutperforms the metric using c ls p. the ochiai metric employing c f ls p performs better than the ochiai metric employing c ls pfor of the programs and it never performs worse.
discussion throughout the evaluation the suspiciousness metric employing c f ls pis the most effective metric within both cbi and esp.
these results show that control flow andfailure flow confounding bias exist in established predicate level suspiciousness metrics and that our metric c f ls p reduces or eliminates these confounding biases.
space precludes a graphical comparison of c f ls pwith theimportance measure.
however we evaluated importance against the reduced bias versions of the tarantula f1and ochiai metrics employing c f ls p. table iii shows that in the preponderance of the program versions the metric employing c f ls poutperforms the importance metric.
furthermore in section iv d the f1metric employing c f ls pis evaluated favorably against the importance metric at different predicate sampling rates.
thus for cbi and esp and the evaluated programs the suspiciousness metrics employing c f ls pare superior to the importance measure.
although the metrics c ls pand c f ls pperformed well in our evaluation each was not as effective as the standard metric for some program versions.
the faults in these versions violate the coverage trigger assumption which assumes that the coverage of a statement corresponding to the predicate pwill necessarily trigger a failure if the statement is faulty .
however covering a faulty statement corresponding to predicate pmay not be sufficient to trigger a failure because the statement does not cause an invalid internal state or authorized licensed use limited to old dominion university.
downloaded on november at utc from ieee xplore.
restrictions apply.
table iii metrics employing importance vs .
c f ls p. metric better than same as worse than importance importance importance tarantula f1 ochiai table iv cbi and esp r elative efficiency .
metric standard c ls p c f ls p cbi esp cbi esp cbi esp tarantula .
.
.
.
.
.
f1 .
.
.
.
.
.
ochiai .
.
.
.
.
.
the invalid state does not propagate to the programs output.
often these faults correspond to missing statements where the predicates corresponding to statements adjacent to the missing code qualify as the fault.
the effectiveness of c ls pand c f ls prelative to cbi and esp is also important to discuss.
for the preponderance of the program versions cbi offers more improvement than esp.
however for most of the program versions esp incurs less overall cost for developers.
this paradox can be explained.
esp has been shown to be more effective than cbi when standard biased suspiciousness metrics are employed .
while c ls pand c f ls pimprove the effectiveness of each predicate level debugger esp appears to improve less by absolute measure because of its superior effectiveness.
similarly for most of the versions where negative improvement is observed the effectiveness of esp degrades less than cbi.
c. efficiency we measured the relative computation time for each of the different versions of the suspiciousness metrics used in our evaluation for each program version.
table iv shows the mean relative efficiency for the reduced bias metrics c ls p and c f ls pwhen integrated into the tarantula f1andochiai suspiciousness metrics.
as table iv shows the algorithms to compute the reduced bias metrics are not inefficient relative to the algorithms that compute the standard suspiciousness metrics.
esp is relatively more efficient than cbi because esp requires more computation time which absorbs a portion of the additional computational cost required to solve the regression models for c ls pand c f ls p. while esp incurs .5x slowdown compared to cbi it is more effective .
d. sampling predicate level statistical debuggers such as esp and cbi use instrumentation to collect predicate data.
the collection adds overhead to program execution.
the overhead is limited by employing sparse random sampling rather than complete data collection.
the sampling collects an unbiased representative set of program behavior across test cases.
here we0102030405060 0510152025absolute improvement faulty versionabsolute improvement faulty version a standard ochiai as the reference metric.
5absolute improvement faulty versionabsolute improvement faulty version b ochiai integrated with c ls pas the reference metric.
figure .
ochiai evaluation.
evaluate c f ls punder sparse sampling to determine the extent to which the introduced uncertainty reduces its effectiveness.
fig.
shows the cost incurred by using the f1metric integrated with the reduced bias metric c f ls p shaded blocks within esp and cbi compared to using the importance metric within esp and cbi non shaded blocks .
the effectiveness of esp and cbi remains stable under sampling rates of and .
for each of these rates the version of the predicate level statistical debuggers using the f1metric employing c f ls poutperforms its counterpart employing the importance metric.
for less frequent rates the variance of thecost increases.
this is expected given the introduction of random sampling.
at a sampling of the f1 metric employing c f ls pstill outperforms the importance metric but the relative difference in effectiveness narrows.
authorized licensed use limited to old dominion university.
downloaded on november at utc from ieee xplore.
restrictions apply.
allall 10k1 10k 1k1 1k0102030405060708090100 cost sampling ratecost sampling rate figure .
cbi red and esp white employing the importance suspiciousness metric non shaded and the f1integrated with c f ls p shaded .
the performance of both metrics at a sampling rate of reveals a trend sufficiently infrequent rates will reduce the effectiveness of esp and cbi regardless of the suspiciousness metric used.
however the performance of esp and cbi under the more frequent rates shows that c f ls p can improve effectiveness of esp and cbi up to a sampling rate of .
this is significant research has shown that sampling rates significantly reduce overhead in predicate level statistical debuggers .
e. validity internal external and construct validity threats affect our evaluation.
internal validity threats arise when factors affect the dependent variables without evaluators knowledge.
it is possible that some implementation flaws could have affected the evaluation results.
however our results for the evaluated benchmarks are similar in magnitude to improvements offered by baah et al.
s statement level work .
threats to external validity occur when the results of our evaluation cannot be generalized.
although we performed our evaluations on nine programs with a total of versions and two different predicate level statistical debuggers cbi and esp we cannot claim that the effectiveness observed in our evaluation can be generalized to other faults in other programs for other predicate level statistical debuggers.
threats to construct validity concern the appropriateness of the metrics used in our evaluation.
more studies into how useful developers find predicate ranking metrics needto be performed .
however the more accurate faultlocalization methods are the more meaningful such studies will become.
v. r elated work many debugging approaches use statistical analysis and program coverage data to rank the suspiciousness of program elements .
however none of these approaches use causal inference to account for control flow andfailure flow confounding biases at the predicate level.
a related approach is the probabilistic program dependence graph ppdg .
the ppdg is a probabilistic model of an entire program which augments each node of a program dependence graph with a conditional probability table cpt characterizing the conditional probability distribution of the nodes states given the states of its parent nodes.
although the technique has been shown to be effective a node may have an anomalous state without being a cause of a failure.
in our approach we estimate the causal effect of a given predicate being true using a regression model involving only the predicate and its forward control flow predecessor predicate cpts are not needed.
state altering approaches such as delta debugging and ivmp attempt to find the cause of program failure by altering program states and re executing the program .
our approach is more lightweight than these types of approaches.
performing experiments on altered programs can be time consuming and requires an oracle to determine the success or failure of each altered program.
also previous evaluations suggest that stochastic distributions within subject programs can degrade state altering analysis .
other debugging approaches use slicing to compute the set of statements that potentially affect the values of a given program point .
these techniques do not provide rankings to the developer to facilitate localization.
thus it is difficult to compare our approach with these approaches.
vi.
c onclusion recent work has applied causal inference to reduce or eliminate control and data flow dependence confounding bias in statement level statistical debuggers.
here we further these efforts by applying and extending causal inference to the predicate level.
first we adapted baah et al.
s statementlevel definition of the forward control flow predecessor to the predicate level.
using the definition we provided a linear regression model which accounts for control flow confounding bias and estimates the effect of a given predicate on a program failure.
next we extended the model to account forfailure flow confounding bias .
finally we presented an evaluation which showed that the reduced bias metric c f ls p from our extended model significantly improved the effectiveness of existing metrics.
authorized licensed use limited to old dominion university.
downloaded on november at utc from ieee xplore.
restrictions apply.