automated analysis of css rules to support style maintenance ali mesbah university of british columbia canada amesbah ece.ubc.cashabnam mirshokraie university of british columbia canada shabnamm ece.ubc.ca abstract css is a widely used language for describing the presentation semantics of html elements on the web.
the language has a number of characteristics such as inheritance and cascading order which makes maintaining css code a challenging task for web developers.
as a result it is common for unused rules to be accumulated over time.
despite these challenges css analysis has not received much attention from the research community.
we propose an automated technique to support styling code maintenance which analyzes the runtime relationship between the css rules and dom elements of a given web application detects unmatched and ineffective selectors overridden declaration properties and undefined class values.
our technique implemented in an open source tool called c illa has a high precision and recall rate.
the results of our case study conducted on fifteen open source and industrial web based systems show an average of unused css selectors in deployed applications which points to the ubiquity of the problem.
keywords cascading style sheets css dynamic analysis software maintenance web applications i. i ntroduction one of the fundamental w3c standards for developing web applications is cascading style sheets css .
css is a language for defining the presentation semantics of html elements including their positioning layout colour and fonts.
the main driving force behind adopting css has been the separation of structure from presentation.
although this separation of concerns helps a web application s evolution as far as the structure and content is concerned the css code itself is not easily maintainable .
writing css code is not trivial .
it requires human computer interaction graphic design as well as web programming skills .
in addition the language has a number of characteristics such as inheritance cascading and selector specificity which makes understanding how css properties are applied to document object model dom 1elements at runtime a daunting endeavour for web developers.
therefore developers are continuously faced with challenging questions during web development and maintenance tasks is my web application using all of the defined css rules?
which ones are obsolete?
what will happen if this css rule is removed?
will it break the layout in some 1dom is a standard object model representing html at runtime.
it is used for dynamically accessing traversing and updating the content structure and style of html documents.pages?
is this selector really effective or is it overridden by another rule at runtime?
which dom elements does this rule affect?
are there any undefined classes in the html code?
consequently as a web application evolves unused rules or ineffective ones with properties that are always overridden start to accumulate over time.
this accumulation of unused code has a number of negative consequences all client side code including any unused css code needs to be downloaded and parsed by the browser to load a web application the larger the code the higher the load on the network server and browser.
the web browser is a cpu intensive program .
benchmarks of popular browsers such as internet explorer safari and firefox reveal that visual layout consumes of the average processing time.
on every new page the browser tries to match the parsed css rules against the dom tree.
matching unused selectors is an unnecessary overhead which can significantly increase the loading time of a web page and decrease the level of responsiveness unused code adversely influences program comprehension maintainability and ultimately code quality by increasing the probability of introducing errors.
in addition to financial costs web applications that contain errors such as pages that display incorrectly result in loss of revenue and credibility .
despite these challenges css analysis has not received much attention from the research community and there is currently a lack of solid tools and techniques to support its comprehension and maintenance.
to the best of our knowledge analyzing css code from a maintenance perspective has not been addressed in the literature.
in this paper we propose a technique that automatically checks css code against different dom states and their elements to infer an understanding of the runtime relationship between the two detects unmatched andineffective rules overridden declaration properties and undefined class values.
we have implemented the technique in an open source tool called c illa .
the results of our evaluation show that c illa has a high precision and recall rate of retrieving unused css code.
our empirical study conducted on fifteen web based systems indicates that on average of css selectors is unused in deployed web applications.
news background color silver font italic color black .s p o r t s color blue text decoration underline h3 h4 font family sans serif .latest color green news span color red p.select font size medium figure .
motivating css example example.css .
the css properties that are used at runtime are shown in bold.
the key contributions of this paper are a discussion of challenges surrounding css rule comprehension and maintenance a fully automated technique and algorithms for inferring knowledge about actual style code coverage and selector effectivity an open source tool implementing the analysis technique and algorithms an empirical study to validate the proposed technique demonstrating its efficacy and real world relevance.
ii.
b ackground a css rule is composed of two parts selector and declaration .
figure presents a simple example of css rules and how they are linked to the elements of two dom states in figure .
we will refer to these two figures as the motivating example in the rest of this paper.
in the first defined css rule news is the selector part.
as the name suggests a selector selects one or more elements from the dom tree.
the declaration part is code between curly brackets which defines the styling properties to be applied to the selected element s .
in this case for instance color is a declaration property and black is the value of that property.
the language provides three mechanisms for selecting dom elements element selectors are defined by using dom element types e.g.
p color blue selects any p element with or without attributes.
id selectors are defined by using the prefix and are matched based on the value of the idattribute of dom elements e.g.
news background color silver selects p id news ... .
class selectors are defined by using the .
prefix and are matched based on the value of the class attribute of dom elements e.g.
.sports color blue selects span class sports .
both id and class selectors can also be defined with an associated element type.
for instance p.select font size medium selects p elements with a class attribute value equal to select .
if no element type is defined the rules apply to all matched element types.
complex selectors can be written by combining multiple simple selectors separated by white space e.g.
newsdom html head link href example .css rel stylesheet type text css head body pid n e w s style font n o r m a l world span class sports sports news span p div class sport football div body html dom html head link href example .css rel stylesheet type text css head body pid n e w s style font n o r m a l world span class latest latest news span p body html figure .
two dom states of our motivating example.
the visual effects of the css code from example.css are presented under each state.
span selects a dom span element that is the child of an element with an id attribute equal to news .
if the same declaration should be applied to different selectors selectors can also be grouped together.
grouping happens by separating the selectors with a comma e.g.
h3 h4 font family sans serif .
css also has the notion of pseudo elements e.g.
p first line and pseudo classes e.g.
a visited to allow style formatting based on information that lies outside the dom tree .
inheritance.
inheritance in css allows a styling property value to be propagated from the parent to the descendent elements.
our motivating example shows a simple case of inheritance in working.
the span element inherits the background color property silver from its parent element p through the css rule news .
an inherited property can also be overridden in css.
for instance the same span element has a parent with a font color of black but since there is a more specific color property defined for the element through news span the value of the inherited property is overridden by red.
cascading and specificity.
the cascading notion in css ultimately determines which properties will be applied to a selectable dom element.
the cascading order is based on two main concepts specificity andlocation .
when there is a competition on an element from two or more css rules for the same property e.g.
color the language applies these methods to determine which rule takes precedence.
specificity as we have seen css provides different selector types to target dom elements and each of these types carries a different weight of importance.
the specificity weight of a selector is the sum of all its selector type s weights.
the more specific a selector points to a dom element the higher its specificity weight.
in our motivating example both news span and .latest selectors compete for the span class latest element s color property.
news span wins because it is more specific about the element i.e.
it specifies both the tag name and the parent s id and thus the dom element receives a red color.
in case an element is targeted by multiple selectors carrying the same specificity weight the selectors location becomes the determining factor.
location location is determined by the source of a css rule and its position.
css rules can be defined in three different sources inline declarations are defined on specific html elements using the style attribute embedded rules are defined inside a style element within an html document s header external style sheets are separate files usually with a .css extension referenced from html documents.
when multiple rules from various sources select the same element the rule closest to the dom element has the highest priority.
based on this definition the priority scheme becomes from highest to least inline embedded and external style rules.
the language also allows authors to use the !important declaration on the property level.
a property designated as important receives the highest priority over competing rules.
challenges and motivation.
our motivating example is a very simple example of the kind of css code that is present on the web.
the code snippet is showing the properties that are applied on the elements of the two dom states at runtime in bold.
this clear indication is however not readily available when developers write or maintain css code.
even in this simple example with only two dom states and a few lines of css code it is not trivial to understand how the rules are applied to the dom elements.
having to work on a web project with thousands of lines of css code and hundreds of dom states can thus be very challenging.
our aim in this work is to provide a technique that can automatically provide the developer with information on css rule usage.
iii.
r elated work we categorize related work into two groups namely css analysis andunused code detection .
css analysis.
despite its widespread adoption and maintenance challenges css code has not received much attention from the research community.
lie presents an in depth discussion of style sheet languages and some of the design decisions behind css.
keller and nussbaumer compare user authored css code to generated css code andpropose an abstractness factor for measuring code quality.
they argue that manual css code has a higher abstractness factor than generated code.
quint and vatton provide an overview of techniques and tools for editing style sheets.
they identify challenges css developers face and argue that robust css debuggers and rule analyzers are a necessity for web developers.
meyerovich and bodik propose algorithms for css selector matching layout solving and font rendering to improve page loading performance in browser layout engines.
extending css to account for some of the limitations of the language has gained more attention.
for instance badros et al.
propose a constraint based style sheet model on top of css2 called ccss which allows a more flexible specification of the layout.
a more recent language extension is sass which supports variables nested rules mixins inline imports and selector inheritance.
the code written in sass can be automatically translated into valid css code.
current industrial tools for analyzing css code are mainly static analyzers concerned with either standard conformity such as w3c css validator or code formatting and optimizations such as csstidy cssclean and css lint .
a few industrial tools exist such as dust me selectors dms and css ess which target css rule analysis.
all such tools are however still immature.
in particular they produce a high rate of false positives and false negatives as shown and discussed in sections vi vii .
unused code detection.
detecting unused code in conventional programming languages e.g.
java c has been explored in a number of different contexts.
dead code and unreachable code elimination is addressed in compiler optimization techniques .
the main focus in these techniques is optimizing code generation.
tip et al.
use program transformation and extraction techniques to detect and remove unreachable methods and redundant fields in java.
their goal is to reduce the size of distributed applications deployed via the internet.
tempero presents an empirical study on unused design decisions in java applications.
the study indicates a high degree of unused code in open source software.
industrial tools such as pmd and ucdetector aim at spotting unused local variables parameters and methods in java.
another related topic is clone detection and removal to improve program comprehension and maintenance.
roy et al.
provide an overview of clone detection tools and techniques.
to the best of our knowledge analyzing css rule usage and effectivity has not been addressed in the literature.
iv .
o urapproach our overall approach is based on dynamic analysis in which we automatically drive a given web application and infer the runtime relationship between the css rules and dom elements of the navigated states.
we use this inferred relational knowledge to spot unused css selectors.
the venn diagram of figure depicts the total landscape of css selector coverage and what our approach targets.
setasrepresents all the css selectors present in a webas all selectors us unmatched selectorsis matched and ineffective selectorsme matched and effective figure .
css selector coverage landscape.
application.
usis the set of unmatched selectors i.e.
selectors with no dom element counterparts.
the set as uscontains all the matched selectors from which the set isencompasses all the ineffective ones i.e.
the selectors that are matched but have no effect on the dom elements.
meis the set of all matched and effective selectors.
ideally after each development and maintenance cycle the css code should only contain the set of selectors in me.
our technique operates in three steps to detect unused selectors and undefined class values.
in the first step we execute each selector against all dom states to differentiate unmatched selectors us .
in the second step the matched selectors as us and dom elements are analyzed to detect the set of ineffective selectors is .
the output of our technique as far as the total unused selectors is concerned is the set us is.
there is also the set of class values uc present on dom elements that are not defined in css code not shown on the diagram .
in the last step we use the matched selectors to spot these undefined class values.
each of these steps is further described in the following subsections.
a. relation between css and dom the first step in our analysis is to determine the relation between css rules and their counterpart dom elements.
definition matched selector let denote the set of dom states then a css selector sis said to be matched if and only if there exists at least one dom element e2 so that it is selectable by s. based on this definition a selectable element is a dom element matched by a selector.
algorithm shows our algorithm for analyzing css selectors and their counterpart dom elements.
for each detected dom state line the algorithm extracts all the new css rules and adds them to the overall set of css rules line .
the utility function e xtract newcssrules scans each new dom tree looking for unexamined embedded rules and external css files.
using the url of each external css resource the content is retrieved through a http request.
then the extracted css code is parsed and transformed into an object model containing all the information about the rules and declarations as well as their resource e.g.
url of the css file and location e.g.
line number .
since a css rule can have grouped selectors we iterate over the set of selectors of the current rule lines .
then algorithm analyzing selectors and dom elements input set of visited dom states output set of annotated css rules r unmatched selectors us selectable dom nodes 1begin set r set set us foreach dom do r extract newcssrules dom foreach rule 2rdo s rule.
getselectors foreach selector 2sdo xpathexpr transform toxpath selector nodes dom.
ev aluate xpath xpathexpr ifnodes then selector.matched true selector.matchednodes nodes nodes foreach rule 2rdo foreach selector 2rule do ifselector.matched false then us selector to check whether a selector matches any dom elements we transform the selector into a corresponding xpath expression line that can be evaluated on the current dom tree line .
we have defined a mapping of the css selector syntax to the xpath language.
for instance the selector news span is translated to .
descendant id news descendant span .
in case the xpath expression retrieves elements from the dom line we annotate the selector as matched lines and add the retrieved elements to the overall set of selectable elements line .
after all the dom states are covered and having annotated all the matched selectors and selectable elements the algorithm iterates over all the rules to find the set of unmatched selectors lines .
going back to our motivating example this algorithm returns p.select h3 andh4as the detected unmatched selectors since these do not touch any of the elements in the two given dom states.
in addition through this algorithm we know exactly which elements in the two dom states are selectable by which css selectors.
we use this information in the following step of our analysis.
b. effective selectors and declaration properties not all matched selectors are used at runtime per se.
for instance although the .latest selector in figure matches span class latest in state of figure the selector is actually not effective due to its low specificity weight.
thus to understand a selector s effect on dom elements a more specific definition is required.algorithm analyzing declaration properties input set of selectable dom nodes r set of annotated css rules output set of ineffective selectors is and properties 1begin foreach node do overridden getrandom int s getmatching selectors node r os order specificity location s fori!1to os.
size do selector osi p selector .getproperties foreach property 2pdo ifproperty.status overridden then property.status effectiv e forj!i 1to os.
size do selectorc osj pc selectorc.
getproperties foreach propertyc 2pcdo ifproperty.name propertyc.name then propertyc.status overridden 18procedure ineffective selectors r begin set is foreach rule 2rdo foreach selector 2rule do counter p selector.
getproperties foreach property 2pdo ifproperty.status effectiv e then counter ifcounter p.size then is selector definition effective selector a matched css selector sis said be effective if and only if shas at least one declaration property that is applied to a selectable dom element e2 .
algorithm shows our overall algorithm for analyzing the effectivity of selectors and declaration properties.
the input to this algorithm consists of the set of annotated css rules as well as the set of selectable dom elements from algorithm .
for each selectable dom element the algorithm starts by retrieving all the corresponding css selectors that matched that particular element line .
then it sorts the list of matched selectors line according to their calculated specificity weight in decreasing order.
based on the css specification we calculate the overall specificity weight sw of a selector scomposed of different selector types as follows sw s concatenate a b c d where a b c and dare calculated as follows a if the declaration is inline otherwise b number of id types in s c number of class types in s d number of element types in s going back to our motivating example news span and .latest selectors have specificity weights of id attribute and element type and class type respectively.
in this case news span has a higher specificity.
if two selectors have the same specificity weight then their cascading order in terms of their location is used for ordering see section ii .
we know by definition that the declaration property of a selector that has a higher cascading order and specificity weight wins over all the competing selectors.
thus once the selectors for an element are ordered based on their specificity and location the algorithm starts annotating the properties in that exact order.
for each property in a selector the algorithm first checks whether the property has already been overridden by a higher order property line .
if that is not the case the property is marked as effective line .
when an effective property has been identified all the properties of the competing selectors that have the same property name are marked as overridden lines .
at the end of this step we can distinguish between effective and ineffective properties.
once all the properties are annotated we can retrieve the set of ineffective or effective selectors.
the i neffec tive selectors procedure iterates over all the annotated rules and selectors lines .
if none of the properties of a selector is marked as effective lines then that selector is added to the set of ineffective selectors line .
by applying this algorithm to our motivating example news .sports and news span are identified to be effective since they all have at least one effective property.
this leaves .latest as ineffective.
note that the total set of unused selectors that our approach returns is a union of unmatched selectors and ineffective selectors e.g.
p.select h3 h4 .latest .
using the same principle we can retrieve the total set of unused css properties i.e.
all the properties that are not marked effective plus the properties of unmatched selectors .
c. detecting undefined classes we reverse the process and analyze the dom elements to examine whether all the class attribute values are defined as css rules.
definition defined class values a class attribute value cattached to a dom element is said be defined if and only if there exists at least one css selector that matches c. there are at least four scenarios imaginable for a css class to be undefined the developer forgets to definealgorithm analyzing class attribute values input set of visited dom states r set of annotated css rules.
output set of undefined class values uc 1begin se c set defc set uc foreach dom do n dom.getelements bytagname foreach node 2ndo attr node.
getattribute 0class0 cv attr.getvalues foreach value 2cvdo c value foreach rule 2rdo s rule.getselectors ifvalue 2sthen defc value break uc c defc the css rule for the class value the css rule definition is removed making the class obsolete a mistake e.g.
typo is made in attaching a defined class value to the dom element the class value is used for purposes other than styling such as querying the dom through j avascript .
the first three scenarios require close inspection by the developers to either fix the error or clean up the unused code.
algorithm presents our method for detecting undefined css class values.
this algorithm takes as input the set of visited dom states along with the set of annotated css rules.
for each dom state it first extracts all the nodes from the tree line .
then the values of each node s class attribute are retrieved line .
each class value is then subsequently checked against all the selectors lines .
if a selector matches the class value the algorithm adds the class to the set of defined classes line and continues with the next class value.
at the end the algorithm returns the set of undefined classes line .
when applied to our motivating example the class attribute value sport from div class sport is returned as undefined.
v. t ool implementation we have implemented our css analysis technique in an open source tool called c illa .2we use cssp arser to parse css source code and transform the rules into a dom style tree .
for automating the dom state exploration phase we use c rawljax a dynamic web crawler capable of detecting dom state changes of ajax based web applications.
when the initial index page of a web application is loaded cilla extracts all external and embedded css sources.
then it retrieves and parses the css code to create a map all the css rules selectors and property declarations associated with each source.
each rule s relation to the elements of the current dom tree is examined and the map is annotated with the findings algorithms .
then the class attributes of all the elements on the dom tree are analyzed algorithm .
our tool currently excludes pseudo elements classes from the analysis process because inherently their relation cannot be deduced from the dom tree .
for each consecutive new dom state c illa first examines all the css sources defined in that particular state.
any new css code that is identified is parsed and added to the map before the analysis is carried out for that particular state.
when the state exploration phase is done the tool iterates over the entire css rule entries in the map and reports about the findings.
the first entry in the report consists of the total number of examined css resources rules selectors and properties detected matched and unmatched selectors detected effective and ineffective selectors detected used and unused properties and detected undefined class values.
in addition details of the detected ineffective and unmatched selectors including their location and line number and undefined class values are reported.
the report also includes all effective and matched rules along with the list of corresponding dom elements for each selector.
vi.
e mpirical eva l uat i o n to assess the effectiveness and real world relevance of our approach we have conducted a case study following guidelines from runeson and h ost .
our evaluation addresses the following research questions rq1 what is the overall accuracy of c illa in detecting unused css code?
rq2 how does c illa s detection rate compare to existing approaches?
rq3 what percentage of css code is typically unused in online web based systems?
a. experimental objects during the implementation and testing phases of c illa we used two web applications with unused rule sets that were well known to us.
however in the evaluation phase our goal is to assess the effectiveness of the approach on real world web applications.
our study includes fifteen web based systems in total.
two are open source namely phormer which is a photo gallery written in php and igloo a simple company website taken from the book pro css for high traffic websites .
seven of the systems are randomly selected using the random link generator provided by yahoo!
which has also been used in other studies .
the randomly selected web systems include becker equus pte vanities lcn employeesolutions and sync.
we further include six online web applications in our list of experimental objects namely those of the icse 2012table i experimental objects .
id exp.
object resource igloo phormer becker equus pte vanities lcn icse12 employeesolutions sync globaltvbc lenovo mountainequip staples msnweather conference globaltvbc news mountain equipment coop staples technology and electronics and msn weather forecasts.
table i shows each system s id name and resource.
the characteristics of these systems in terms of their size and complexity is shown in table ii.
b. experimental setup our study is composed of two parts.
the first part rq12 focuses on the accuracy of c illa and compares it to tools currently available to web developers for analyzing css selectors.
the second part rq3 empirically explores how omnipresent unused css code is in web applications.
the experimental data produced by c illa is available for download.
to run the experiment we provide the url of each experimental object to c illa and choose the default crawling settings for event generation and dom state comparison.
then we run the tool and save the generated output.
to evaluate the accuracy of reported unused css selectors rq1 we measure precision recall and f measure as follows precision is the rate of detected unused selectors found by the tool that are correct tp tp fprecall is the rate of correct unused selectors that the tool finds tp tp fnf measure is the harmonic mean of precision and recall precision recall precision recall where tp true positives fp false positives and fn false negatives respectively represent the number of unused css selectors that are correctly detected falsely reported and missed.
to document tp fp and fn in a timely fashion while preserving accuracy we randomly select of the css rules from the first ten systems in table i as follows d0.
ne ifn otherwise where is the number of randomly selected css rules and nis the total number of css rules.
we manually examine the samples against the reported output.
it is worth mentioningtable ii characteristics of the experimental objects .id css files loc css css rules css selectors ignored selectors css properties ignored properties dom states that manual checking of css rules is a labour intensive task.
in this study examining the ten samples took approximately hours in days .
to answer rq2 we compare the results produced by cilla to the results generated by two industrial open source tools namely dust me selectors dms and css ess .
similar to c illa both these tools aim at spotting unused css rules.
since dms is a firefox plugin we use firefox for the state exploration phase in all our experiments to make comparisons possible c illa supports ie and chrome as well .
note that the same set of randomly selected samples are used to conduct the comparisons through precision recall and f measure as defined above.
since cilla dms and css essare not able to analyze pseudo classes elements we ignore pseudo items in the evaluation of all the three tools see table ii ignored selectors .
to address rq3 we run c illa on all fifteen experimental objects and calculate the percentage of the css code that is found to be unused.
c. results table ii presents the examined properties of each system produced by c illa .
the table shows the number of examined css files total lines of embedded and external css code number of css rules number of css selectors number of ignored selectors pseudo elements classes number of css declaration properties number of ignored properties belonging to a pseudo selector and the number of dom states examined.
table iii shows the results of our evaluation produced by c illa .
for each experimental object the table shows the detected number of undefined classes uc unmatched selectors us ineffective selectors is unused selectors us is unused declaration properties up the percentage of unused selectors and the percentage of unused properties.table iii eva l uat i o n r e s u lt s p ro d u c e d b y cilla .
id uc us is us is up us is up table iv descriptive statistics of unused selectors and properties .
min.
1st qu.
median mean 3rd qu.
max.
is .
.
.
.
.
.
us is .
.
.
.
.
.
up .
.
.
.
.
.
red.
.
.
.
.
.
.
we calculate the percentage of unused selectors us is and unused properties up as follows us is us is cssselectors ignoredcssselectors up up cssp roperties ignoredcssp roperties table iv shows descriptive statistics of the percentages of detected ineffective selectors is unused selectors us is unused properties up and reduction in css code size if the unused code were to be removed red.
.
d. findings accuracy the precision and recall rates measured for cilla dms and css ess are presented in figure .
the f measure is shown in figure .
as far as rq1 is concerned our results show that c illa is highly accurate in detecting unused css selectors.
the recall is meaning that our approach can successfully spot all unused selectors of type class id and element present in a web application.
the precision oscillates between which is caused by a low rate of false positives discussed in section vii under limitations .
the f measure varies between .
the comparisons in figure and emphasize that the accuracy of c illa is higher than that of dms and css essin recall precision and f measure rq2 .
dms performs better than css essbut it still suffers from a high rate of false positive and negative.
unused css code figure depicts a bar plot of the percentages of unused css selector and declaration properties for all the fifteen systems.
the numbers on each bar represent the number of unused entities.
in order to obtain the results shown in figure in a reliable manner we varied the number of dom states from to c illa had to analyze from each system.
by increasing the number of dom states covered we find out when the number of detected unused selectors as well as the percentage stabilize0.
.
.
.
.
.
.
.
.
.
recallprecisioncilladmscssess figure .
plot of precision and recall for c illa dms and css ess.
.
.
.
.
.
.
.
.
experimental objectsf measure 12345678910cilladmscssessfigure .
f measure of c illa dms and css ess obtained for each object.
i.e.
remain unchanged .
we depict the results in figure obtained from six systems with high numbers of dom states.
the percentage of unused selectors oscillates when we increase the number of explored dom states from to .
after the graph stabilizes indicating that the process of detecting unused selectors has reached a steady state.
the numbers in figure represent the percentages of unused selectors taken after stabilization.
going back to rq3 the high percentages reported in figure clearly indicate that there is a huge amount of unused css code in online web applications.
as shown in table iv on average there are .
unused css selectors and .
unused declaration properties.
staples has the highest unused percentages selectors and declaration properties.
our results show that ineffective selectors are present in web applications and they can form up to .
of the total50100150200405060708090100 dom statesunused selectors stapleslenovomsnweathermountainequipglobaltvbclcnfigure .
percentage of unused selectors versus the number of dom states.
number of unused selectors.
unmatched selectors however constitute the largest portion of unused code.
there are also a number of undefined class values in html code.
the highest number reported in our study is for lenovo.
as shown in table iv css file size can be reduced by up to merely by eliminating unused selectors and properties.
vii.
d iscussion correlations.
to examine the relationship between the number of unused selectors and the independent variables in table ii we used r to calculate the non parametric spearman correlation coefficients r as well as the p values p and plotted the graphs.
we present the combinations that indicate a possible correlation.
figure depicts the scatter plot of the total number of selectors versus the number of detected unused selectors with the line of best fit.
clearly there is a high linear correlation r .
p between the two the higher the number of css selectors the more unused selectors are present in a web application.
more interesting is figure which shows the scatter plot of the percentage of unused selectors versus the average dom size.
the correlation coefficient r .
p .
suggests that the variables are positively corelated.
one reason might be that when there are more dom elements present it becomes more difficult for developers to have a clear understanding of their css code usage and effectivity.
another reason could be that when there are more dom elements and selectors developers become more reluctant to remove unused selectors in fear of breaking the style since they do not know exactly if or where a certain selector is used.
limitations.
similar to other tools one of the limitations of our technique is that pseudo elements classes are currently not supported.
table ii presents the number of ignored pseudo selectors and properties.
as mentioned earlier we ignore pseudo items in the evaluation of all the three tools.experimental objectsunused 123456789101112131415selectorsproperties figure .
bar plot of the percentage of unused selectors and declaration properties.
the numbers on each bar represent the number of unused entities.
therefore any unused pseudo item that is ignored could be regarded as a false negative.
as shown in figure unlike dms and css ess cilla achieves a recall rate.
this implies that in c illa false negatives could potentially be caused only by unused pseudo classes elements.
since our approach is based on dynamic analysis the explored state space is only a subset of the entire state space.
this limitation is in part inherent to all dynamic analysis techniques.
thus if a css selector is used in a certain dom state not present in the explored set then that selector is mistakenly marked as unused .
a low rate of false positives produced by c illa is caused by these css rules.
the conclusive outcome from our evaluation apart from the fact that unused css code is omnipresent on the web is that within the automatically explored state space our technique is capable of detecting unused selectors with a high level of accuracy.
applications.
the first direct application of our technique is in css code maintenance.
c illa can be incorporated into web development cycles through automated nightly runs.
the reported unused code can for instance be deleted to maintain a clean code base and decrease the processing load on the browser.
specifically mobile web applications could greatly benefit by avoiding the download of unnecessary css code to decrease bandwidth usage and user perceived latency.
what we witness in the evaluation is that some unused rules are a result of reusing the entire css rule set of a parent website while perhaps only a small subset is needed.
others are a result of copy paste from other resources.
c illa can tell web developers exactly what the used subset is so that the remaining obsolete rules can be avoided.
in addition our technique can assist in understanding the relationship between css rules and dom elements at runtime.
for instance c illa provides all dom elements affected by 020004000600080000100020003000400050006000r .
p css selectors unused css selectors figure .
scatter plot of the total number of css selectors versus the number of detected unused css selectors.
r represents the spearman correlation coefficient and p is the p value.
each selector as well as all selectors affecting each element.
this relational information can be valuable during program comprehension and refactoring tasks.
another interesting area where c illa could support web developers in is crossbrowser compatibility by providing an overview of how dom elements are linked to css rules in different browsers.
scalability and performance.
the results in table ii show that our approach is scalable to deployed industrial web applications consisting of tens of thousands of css loc and hundreds of dom states.
on average it took cilla minutes in total including state exploration and css analysis to analyze 7k lines of css code and dom states.
the results indicate that both scalability and performance of c illa are acceptable.
threats to validity.
to minimize selection bias seven of our fifteen experimental objects were chosen randomly.
we acknowledge the fact that more studies are required to draw more general conclusions.
however we believe the systems are representative of css code present in deployed web applications.
for measuring the rate of false positives and false negatives we randomly select a sample of the entire rule set from the css code and check them manually against the output.
manual checking of css rules is a time intensive task done by the authors of the paper.
therefore we acknowledge that it could be error prone and biased towards our judgment although we made every effort to mitigate these threats.
the main reason behind selecting samples instead of the entire sets has been constraining the effort and time needed to manually form a baseline since there are thousands of selectors and declaration properties along with hundreds of dom states in the systems as shown in table ii.
increasing the sample size or selecting other samples could change the assessment positively or negatively.
as a remedy for this threat we created a script that randomly selects the samples.
2000040000600008000030405060708090r .
p .
dom size byte unused selectors figure .
scatter plot of the percentage of detected unused selectors versus the average dom size.
r represents the spearman correlation coefficient and p is the p value.
with respect to reliability of our results c illa and all the fifteen web based systems are publicly available making the case study replicable.
one threat with using online web applications in empirical studies is that they might change over time making exact replications challenging.
that is why we have also included two open source systems in the study.
viii.
c oncluding remarks this paper presents an automated approach for analyzing the relation between css rules and dom elements of web applications.
our technique implemented in a tool called cilla is capable of detecting unmatched and ineffective selectors and properties as well as undefined class values.
the results of our empirical evaluation on several opensource and industrial web applications clearly point to the ubiquity of the problem on average we found unused selectors and unused properties.
our results also demonstrate the efficacy of the approach in automatically detecting unused css code recall and precision .
our work can be enhanced and extended in several ways.
improving the algorithms and implementation to further reduce the number of false positives and conducting larger case studies to obtain more empirical data form part of our future work.
other directions we will pursue are exploration of suitable techniques for analyzing pseudo classes and elements.
further we will investigate how the analysis results can be used for detecting antipatterns and smells in css code and suggesting refactoring steps for improving code quality and maintainability.
acknowledgment this research was supported in part by an nserc discovery grant and the institute for computing information and cognitive systems icics at ubc.