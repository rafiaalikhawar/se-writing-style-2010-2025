an empiricalstudyof reported bugs in server software withimplicationsforautomated bug diagnosis swarup kumar sahoo universityofillinois 201n.goodwin ave. urbana il ssahoo2 illinois.edujohncriswell university ofillinois 201n.goodwin ave. urbana il61801 criswell illinois.eduvikram adve universityof illinois n.goodwin ave. urbana il61801 vadve illinois.edu abstract reproducing bug symptoms is a prerequisite for performing automatic bug diagnosis.
do bugs have characteristics that ease or hinder automatic bug diagnosis?
in this paper we conduct a thorough empirical study of several key characteristics of bugs that affect reproducibility at the p roduction site.
we examine randomly selected bug reports of six server applications and consider their implications on automatic bug diagnosis tools.
our results are promising.
from the study we find that nearly of bug symptoms can be reproduced deterministically by re running with the same set of inputs at the production site.
we further find that very few input requests are needed to reproduce most failures in fact just one input request after session esta blishment suffices to reproduce the failure in nearly of the cases.
we describe the implications of the results on reproducing software failures and designing automated diagnosi s tools for production runs.
categories andsubject descriptors d. .
testing and debugging d. .
fault tolerance general terms reliability testing verification fault tolerance keywords bug characteristics network servers bug reports bug dia gnosis checkpointing this work has been supported by nsf contracts cns cns cns and ccf and by the gigascale systems research center funded under fcrp an src program .
permission to make digital or hard copies of all or part of thi s work for personal or classroom use is granted without fee provided th at copies are not made or distributed for profit or commercial advantage an d that copies bear this notice and thefull citation on the firstpage.
tocop y otherwise to republish topostonserversortoredistribute tolists re quires priorspecific permission and or afee.
reproduced with permission.
copyright acm ... .
.
.
introduction .
motivation in field software failures are becoming increasingly common with the increasing complexity of software.
in addition to causing severe inconvenience to customers such faults result in billions of dollars of lost revenue to servi ce providers .
to this end increasing the reliability of s ystems is becoming critically important.
in spite of tremendous improvements in software engineering testing and sof tware reliability many software bugs still escape testing and enter production.
as others have noted performing off site analysis of production run failures at d evelopment sites has several limitations it is difficult to reproduce failures at the development site due to difference s in the environment customers have privacy concerns over what information can be released for off site diagnosis and the same bug may generate a different failure at multiple production sites it is cumbersome for the development team to investigate every failure that occurs without any automated feedback regarding the root cause of the failure.
the use of automatic software bug diagnosis techniques is a promising solution for fixing bugs found in production code.
automatic bug diagnosis has the potential to identify root causes of failure both during development and production runs create reduced test cases for filing bug reports and automatically repair the software while it is in production.
as an example triage uses techniques based on checkpointing rollback and re execution to perform in production bug diagnosis.
one challenge for automated diagnosis tools is that they generally require mechanisms to roll back and replay program inputs repeatedly in order to evaluate different root causes.
unfortunately using checkpointing for such roll back limits the practical usefulness of such tools.
first checkpointing that is lightweight enough to be used for soft ware diagnosis or debugging requires operating system support which means that such tools cannot work on commodity operating systems that lack such support.
multithreaded processes also complicate the checkpointing procedure.
in addition diagnosis cannot be done if the fault happens before the checkpoint is taken.
it would be very useful if diagnosis tools could simply restart the target program and replay a small subset of the inputs to reproduce and diagnose the failures.
exploring this question require s an understanding of real world bug behavior.
one perhaps surprising implication of the present study is that such asimple approach is likely to work for most bugs in real world server programs as described in section .
there also exist techniques like delta debugging to generate a minimal set of test inputs from some failing test case.
in general such tools are too slow to be deployed in a production environment.
again the knowledge of what types of inputs and how many inputs are commonly needed to produce failures can help us to build automated tools which use heuristics to efficiently select a minimal test case .
however in order to be widely deployable in production run environments bug diagnosis tools must be able to quickly isolate the inputs that trigger a fault reduce the inputs to just those that trigger the fault and be able to reproduce the fault with reasonable reliability.
server applications make these challenges more difficult as they run for long periods of time handle large amounts of data over that time and perform concurrent processing of input.
do the failures in server applications lend themselv es to being automatically reproduced?
are there characteristics of server applications that ease or frustrate attempts to perform automatic bug diagnosis?
are there characteristic s of inputs that ease the procedure to find a minimal test case?
our study an empirical examination of real world bugs in server applications aims to answer these questions.
.
goalsofthe study the main goal of this study is to answer and analyze the following questions focusing on server software .
how many inputs are needed to trigger the symptoms of a software bug?
.
how long does it take for the symptom to occur after the first faulty input is used by the application?
.
what kinds of symptoms appear as a manifestation of bugs?
are these symptoms sufficient for creating automatic bug diagnosis tools?
.
what fraction of failures are deterministic with respect to the inputs?
the answers to these questions will have implications for designing automated diagnosis tools for server applicatio ns.
server applications have several qualities that make them ideal for such a study.
they are widely used and mission critical for many businesses.
they process a large amount of input data over extended periods of time making it important to understand how many server inputs are needed to trigger failures and how reliably they do so.
they are also extremely concurrent making it important to understand whether bug behavior both normal errors and concurrent programming errors is deterministic with respect to the in puts.
while these qualities make them challenging a silver lining is that their inputs are well structured due to the na ture of the protocols they use to communicate with clients.
we studied the above questions using public bug databases and committed bug fixes patches for six large open source server infrastructure programs that are widely used to build servers and web server applications squid apache subversion svn mysql the openssh secure shell server sshd and the tomcat application server.
among the several servers we considered for this study we attempted to include all the stateful servers.
we randomly selected and manually analyzed a total of randomly selected bugsand specifically selected concurrency bugs in these six programs to answer these questions1.
.
findings and contributions the main findings of our study are as follows.
here we define an input as a logical request from the client to the server that needs to be buffered to be able to reproduce a failure see section .
nearly of the failures due to software bugs can be reproduced with just one input request excluding session establishment inputs like loginandselect database requests .
among the remaining bugs with clear information only of the failures need more than inputs to trigger a symptom.
.
among the cases that require more than one input request to trigger a fault in a majority of them cases all the necessary inputs are likely to occur within a short duration of time.
.
for most of the failures the time duration between the first faulty input and the symptom is small.
.
for the majority of overall bugs nearly the failure symptom is an incorrect output.
in two of the applications squid and tomcat we find many fewer incorrect output symptoms compared to other applications our analysis leads us to believe that this is because squid and tomcat use many more assertions and exceptions respectively.
.
nearly of all the faults we analyzed were reported to have deterministic behavior.
this is true even though apache mysql and tomcat are extensively multi threaded and even for stateful applications.
.
concurrency bugs e.g.
data races or deadlocks form a small fraction of all bugs even in highly concurrent applications but they have very different more complex characteristics nearly all are non deterministic they usually require more inputs to trigger they have more hangs crashes and fewer incorrect output symptoms but about of them show different failure symptoms in different executions for the same inputs.
our results have several implications for automated bug diagnosis tools .
most bug failures can be automatically reproduced by replaying just the last input.
furthermore most failures including both single and multi input failures are triggered within a short time after receiving the first faulty input.
therefore tools can optimize their search for inputs that reproduce the failure by first trying a small number of the most recent inputs received before the failure was detected.
systems can buffer only a small suffix of the inputs for each server instance.
.
in cases where multiple inputs are needed to trigger a fault the symptoms are not only triggered quickly but the required inputs are also likely to be clustered together in the input stream allowing an automated tool to optimize the search for the inputs.
1a detailed spreadsheet with all these bugs can be found at statistics.xls3.
new techniques are needed to detect the internal data corruptions that cause incorrect outputs as they are the most common symptom.
inserting more assertions or exceptions manually or automatically appears to be a promising approach.
.
isolating fault triggering inputs for concurrency bugs and reproducing failures of such bugs reliably is significantly harder than for other bugs but tools can exploit the fact that there are fewer incorrect output errors and many more hangs crashes i.e.
failure detection is somewhat easier .
based on these results we also propose a new low cost technique to reproduce failures during production and deve lopment.
automated bug diagnosis tools can buffer a suffix of the input requests to the server and upon failure restart the server and replay the suffix of inputs to attempt to reproduce the failure.
a few preliminary experiments suggest thi s approach may be able to reproduce server failures without checkpointing the server state.
the rest of the paper is organized as follows.
section describes our methodology for choosing server application s and the bugs to study and the key limitations of the work.
section presents our terminology.
section details our primary analysis and classification of the bugs.
section further analyzes the bugs which require multiple inputs to trigger them.
section focuses on the characteristics of concurrency bugs.
section describes the implications our results have on automated bug diagnosis tools.
we describe related work in section .
we conclude and describe future work in section .
.
methodology in this section we describe our methodology for selecting the applications and the bugs we study in this paper we also discuss the limitations of our study.
a summary of the applications and software bugs is in table .
.
applicationselection our study focuses on widely used large server applications.
we aimed our study at open source applications that provide both a publicly accessible bug database and access to the server s source code.
when possible we opted to study servers implementing stateful protocols i.e.
prot ocols requiring the server to maintain application specific prot ocol state during an application defined session as these serve rs are the most likely to require more inputs for failure reproduction.
finally we needed applications with a sufficient number of production bugs to study.
we considered many widely used linux servers e.g.
those implementing the imap smtp ftp dns ldap and nis protocols and selected six server applications.
we found that only a few maintain significant state and we deliberately included the stateful servers in our study.
three out of six servers in our study squid mysql tomcat or the applications run on top of tomcat maintain significant stat e that affects reported server bugs.
all six servers use tcp as the transport level protocol for client communication.
apache web server the apache web server communicates with clients via the stateless http protocol and via http over ssl for authenticated and encrypted communication.
while http is stateless apache does maintain some information on the threads and processes it usesto handle requests.
apache can also maintain in memory and on disk state for caching recently served web pages.
squid http proxy server the squid web proxy server also communicates with clients via http and http over ssl.
like apache squid can cache recently accessed web pages in memory and on disk.
squid s rate throttling features must also maintain some global state.
mysql database server mysql uses a custom protocol for client communication .
for each session the server must maintain state about the authentication status and credentials of the client temporary tables prepar ed statements and various parameters like query cache size an d sql modes.
mysql also supports clustering and replication which can maintain a lot of global state.
tomcat servlet container tomcat uses the http protocol optionally over ssl for client communication.
it maintains internal state about which web applications are loaded and provides facilities with which web applications can maintain session state across individual http requests .
tomcat bug reports are often generated by developers of applications running on tomcat.
such applications can maintain arbitrary amounts of state e.g.
for e commerce.
this state will affect the behavior and reproducibility of failures due to tomcat bugs.
tomcat also supports clustering and session replication which maintains a lot of global state.
openssh secure shell server the openssh server communicates via the stateful ssh protocol .
this protocol provides sessions which maintain one or more virtual channels over which programs on the client can communicate with programs on the server .
for each client connection the server must maintain a small amount of state information about each ssh session as well as the state of each virtual channel maintained by the session.
subversion version control server svn can use http or a custom stateful svn protocol tunneled through ssh.
for this study we restricted ourselves to the standalone server using the svn protocol.
the svn server maintains a small amount of per session state .
.
bug selection we selected bugs to analyze for each server as follows.
first for each application we selected a recent major version of the software that had been in development and production use for at least a year.
we expect these versions to have a more diverse bug sample.
in a few cases a single version of the software did not provide a sufficiently sized sample so we used multiple versions of the software.
second we then selected the set of repaired bugs by using filters provided by the program s bugzilla database.
for all programs except mysql we searched for bug reports with a status field of either resolved verified or closed a resolution field of fixed and whose severity was anything other than trivial or enhancement.
since the filters for mysql are non standard we had to adapt our selection criteria to search for bug reports marke d fixed or patch approved queued and with any severity other than feature request.
fixed bugs will have the most complete and accurate information but may be biased towards easier to fix bugs see section .
.
third we randomly selected a subset of bugs from the bug list generated in the previous step for each server using a seeded rand function.
we skipped this step for sshdandapplication description loc years in total bugs bugs production after sampling selected squid .
.x caching web proxy 93k apache .
.x web server 283k .
openssh sshd .
.x .x secure shell server 27k .
svn .
.
.
.
version control server 587k mysql .x database server 028k .
tomcat servlet container and web server 274k total 292k table set of server applications and software bugs.
svn since they had fewer bugs.
the detailed information about the number of random bugs selected after this step is shown in the fifth column of table .
finally we removed the bugs in development versions of code from the randomly selected bug list.
since our main goal was in production bug diagnosis we only focused on bugs in the externally released versions of code.
squid had many development bugs so we had to select a much larger random sample compared to other servers.
then we manually removed trivial bugs like build errors documentatio n errors and feature requests.
after this final manual filtering we were left with bugs from bugs in the earlier step.
the last column of table shows the details for each server.
after creating the list of bugs we analyzed each bug report and its test cases available patches and any other external information associated with it.
we classified each bug s characteristics by first examining the information in the bug report and then by inspecting the patches and other external information if more information was needed to make a decision.
we also used available patches to confirm our analysis of the bug reports.
based on the analysis we classified each bug based upon the observable failure symptoms the bug caused the reproducibility of the observable symptoms and the maximal number of inputs needed to trigger the observable symptoms.
for some bugs we could not classify the bug for some characteristics due to limited informa tion in the bug report.
we report for each characteristic the number of such unclassifiable bugs by placing them in a separate classification as described in section .
.
limitations our methodology s limitations should be considered when using or interpreting our results.
like other empirical stu dies our results are limited by the kinds of applications and software bugs we used.
our study examines a subset of server applications.
our results may not apply to other types of software or to network servers with different architectures e.g.
peer to pe er software.
also all the servers except one are written in c and or c tomcat is written in java results may differ for similar servers written in other programming languages .
there is also some potential bug selection bias in our study.
first some samples omit bugs that cause security flaws because their projects e.g.
apache and sshd do not record such bugs in their public bug databases.
second our study omits unfixed bugs from the samples as their bug reports may contain inaccurate information.
since it is pos sible that unfixed bugs have different properties it has the potential to introduce bias.
third the bug samples in our study exclude unreported bugs.
we believe this is acceptabl e because unreported bugs in a mature server are likely to be much less frequent than reported bugs.
nevertheless it is possible that bugs whose failures are difficult to reproduc e which may include non deterministic bugs and multi input bugs are less likely to be reported.
our results are there fore only representative of reported bugs .
on the positive side our study does not exhibit the bug feature and commit feature biases as described by bird et.
al.
as we sampled allfixed bugs in the bug database instead of sampling the subset of fixed bugs which are linked with the source code bug fixes or other bug fix information.
finally our study relies upon the accuracy and completeness of the bug reports and the materials connected to them.
also as we have analyzed a large number of bug reports manually there may be some human error in the results.
.
definitionsandterminology here we define several terms as they are used in the context of our work.
first an input request to a server is a logical input from the client to the server we identify logi cal inputs at the application level as reported in the bug reports examples include a login authentication request f or establishing a session in ssh mysql any command from an ssh or svn client an http request or a mysql query.
each request may internally involve more than one communication between the client and server and may span several network packets.
we chose logical inputs because bug reports describe test cases as a set of application level inputs.
translating inp uts from bug reports into low level network protocol messages would have made the study too tedious and error prone.
messages coming from sources other than the client e.g.
the file system back end databases dns queries are not considered to be input requests.
these inputs are responses to requests that the server made on behalf of a client i.e.
client input is driving these other inputs.
since there is a causal relationship between client inputs and these other inputs replaying the client inputs will cause the server to perform the same requests.
we also exclude inputs that do not trigger the fault per se but are used instead to recreate a persistent environment in which the failure can be reproduced.
examples of such inputs are svn checkout and sql table creation commands unless they are part of the faulty input set .
in production systems the environment is almost always present before the fault is triggered these inputs are only in the bug repor t so that a similar environment can be manufactured at the developer s site for off line diagnosis.
we define symptoms of bugs as any incorrect program behavior which is externally visible or detectable.
for examp le an incorrect output segmentation fault program crash pr ogram hang or assertion violation is a symptom.
we use the termincorrect output to describe a symptom in which the server completes an operation but the external output of the program differs from the correct behavior.
in our analysis we say that an incorrect output symptom is detected when incorrect output is externally visible to the user or client .
though detecting incorrect outputs can be challenging the internal data corruption that causes them can be detected through manually or automatically inserted assertions application memory error crash other crash assertion violation hang incorrect output unclear squid .
.
.
.
.
.
apache .
.
.
.
.
.
sshd .
.
.
.
.
.
svn .
.
.
.
.
.
mysql .
.
.
.
.
.
tomcat .
.
.
.
.
.
total .
.
.
.
.
.
table classification of bug symptoms.
.
detecting bugs is not a subject of this study we simply treat incorrect outputs as a symptom.
a failure due to a software bug is observed to be deterministic if the fault triggers the same symptom each time the application is run with the same set of input requests in the same order on a fixed architecture os platform and a fixed server configuration.
otherwise the failure due to a bug is non deterministic .
the architecture os platform and server configuration are the user controllable parts of the environment.
this definition is reasonable because our goal is reproducibility at the end user s site where these parts o f the environment and software configuration are fixed.
a failure due to a bug is timing dependent if the timing of the input requests in addition to their order determines whethe r a symptom is triggered and if so which symptom.
this is a special case of a non deterministic software bug that is input timing dependent.
as an example of our terminology one of the failures in squid an assertion violation occurr ed when a client sent an input request to the server and then disconnected from the server before the response for the request was written back.
this is a timing dependent bug as the symptom s occurrence depends upon when the disconnect request is sent to the server.
the timing of the inputs matters and is under the client s control.
in contrast for a concurrency bug like a data race the occurrence of the symptom depends upon timing issues that are beyond the client s control e.g.
thread scheduling we classify su ch failures as non deterministic not as timing dependent .
note that our study is conservative with respect to the definition of non determinism.
we classify a bug as nondeterministic if according to the bug report the symptom s could not be reproduced consistently for any reason e.g.
the same inputs may not be available or parts of the environment might have changed .
it is possible that such bugs are deterministic but we conservatively assume that they are not.
also our definition of determinism is overly restrictive.
we believe that many of the deterministic bugs in our study are actually deterministic across different env ironments and configurations as in many cases failures are reproduced by developers on different systems from the one where the bugs are first detected.
but because bug reports often lack sufficient information about the bug s behavior across different environments we chose to define deterministic to mean reproducibility in a fixed environment.
.
classificationofsoftwarebugs we now present the results of our analysis of the selected server application bugs.
we classify the software bu gs based on three characteristics observed symptoms section .
reproducibility section .
and the number of inputs needed to trigger the symptom section .
.
finally we analyze the characteristics of a few important subclasse s of bugs in section .
.
.
bug symptoms we analyzed the bug reports in detail to determine the symptoms observed for each bug when the failure triggering input requests are sent to the server.
for a small number of bugs two symptoms were possible depending upon which inputs were used to trigger it for these bugs we chose to analyze the symptom that was given in the original bug report.
the observed symptoms are memory error segmentation fault null pointer exception and memory leak program crash assertion violation program hang and incorre ct output.
a program crash in this context is an abnormal server termination that is either not caused by a segmentation fault null pointer exception or memory leak or for which no cause is given in the bug report.
we made this distinction because segmentation faults java null pointer exceptions and memory leaks all have a memory error as the root cause while other termination errors may have other root causes.
assertion violation symptoms include explicit c c checks and java exceptions other than null pointer exceptions.
table shows the results.
each column shows the number of bugs that result in the corresponding symptom for each application.
the last column shows the number of cases in which the bug report did not clearly identify the symptom there were only such cases out of bugs.
the number in parentheses shows the fraction of the cases resulting in the symptom as a percentage of the total number of bugs.
the results in table indicate that most of the bugs nearly result in incorrect output.
incorrect outputs can be caused by memory errors e.g.
buffer overflows dangling pointers integer overflow errors off by one errors in loops logical errors etc.
the results also show that squid and tomcat have many more assertion violations and respectively but a lower percentage of incorrect out put errors compared to the other servers.
we suspect this is because squid has many more assertions in its code than the other servers and because tomcat uses java exceptions.
implications these results lead to two important conclusions .
new techniques are needed to efficiently detect the data corruption that causes incorrect output errors at run time so that future diagnosis tools will be able to detect and diagnose the majority of software errors.
.
the results from squid and tomcat suggest that adding assertions or automatically generated program invariants may help detect incorrect output errors.
.
bug reproducibility we did a similar analysis to determine the reproducibility of failures due to server bugs table summarizes our results.
we classified bugs as either deterministic timing dependent or non deterministic.
this property is useful asapplication deterministic timing dependent non deterministic unclear from bug report squid .
.
.
.
apache .
.
.
.
sshd .
.
.
.
svn .
.
.
.
mysql .
.
.
.
tomcat .
.
.
.
total .
.
.
.
table symptom reproducibility characteristics.
application input input input input input unclear max inputs squid .
.
.
.
.
.
apache .
.
.
.
.
.
sshd .
.
.
.
.
.
svn .
.
.
.
.
.
mysql .
.
.
.
.
.
tomcat .
.
.
.
.
.
total .
.
.
.
.
.
max table maximal number of inputs needed to trigger a symptom.
it will determine whether diagnosis tools can reliably repr oduce the failure symptoms.
in some bug reports the failure could not be reproduced or was very difficult to reproduce as it occurred infrequently .
we conservatively classifie d such bugs as non deterministic.
some bug reports contained no information at all about reproducing the failure these are counted separately in the last column of table .
the numbers in parentheses in table are the corresponding fractions as a percentage of the total number of bugs.
the results are encouraging.
more than of the bugs demonstrate deterministic behavior these results agree w ith chandra and chen s results that nearly of bugs are actually environment independent .
a few bugs nearly exhibit timing dependence.
only of the bugs exhibit other non deterministic behavior.
it should be noted that in practice automatic diagnosis tools will normally replay a subset of inputs.
while deterministic bugs trigger the same symptom each time when run with the same input sequence they may also depend upon global state such as memory layout.
if using a subset of inputs creates a different global state then the bug may not trigger the symptom again even though the same root cause is triggered.
section discusses this issue more .
implications the above results indicate that .
because most bugs are deterministic bug diagnosis tools should be able to reproduce them by replaying inputs.
.
a small percentage of bugs are either timing dependent or non deterministic.
bug diagnosis tools will need to incorporate new techniques such as time stamping inputs or controlling thread scheduling in order to reproduce failures due to these bugs via input replaying.
.
number offailuretriggering inputs we now analyze and classify the software bugs based on the number of inputs needed to trigger the failure symptom.
as mentioned in section we count each logical input as one input request.
we determined the maximal set of inputs needed to trigger the symptom by examining each bug report and the other related external web resources linked to it.
when more than one set of inputs could trigger aappl input input unclear max ips squid .
.
.
apache .
.
.
sshd .
.
.
svn .
.
.
mysql .
.
.
tomcat .
.
.
total .
.
.
max table maximal number of inputs needed to trigger a symptom excluding session setup inputs.
symptom we used the largest set to compute the maximal number of inputs.
we did not count changes to server configuration files or command line options as inputs.
table shows the results of this analysis.
the second third fourt h fifth and sixth columns in table show the number of cases in which and more than inputs are needed to trigger the corresponding symptom.
the zero input column includes cases such as when the server experiences a failure after start up but before it processes client input request s. there were a few bugs for which it was clear from the bug report that more than one input was needed to trigger the failure but the exact number of inputs could not be determined as they were difficult to reproduce.
we have counted them as requiring more than inputs and included them in the sixth column.
the seventh column as in the previous section shows the number of bugs for which the bug report contained too little information to determine whether one or more inputs are needed to reproduce the symptom.
the last column shows the maximum number of inputs needed to trigger a failure due to any of the bugs we studied for that application.
we used only the bugs for which we know the exact number of inputs to trigger a failure to compute the maximum number of inputs.
as before the numbers in parentheses in the table are the corresponding fractions as a percentage of the total number of bugs.
our results show that most failures can be triggered using a very small number of inputs.
some symptoms can be triggered with zero inputs.
squid had a few such cases nearly .
for example when run with a certain combination of options or with a particular configuration squid failed aft er starting execution but before processing any client inputs .
the majority of failures in squid apache and tomcat can be triggered with just a single input request in the case ofsshdand svn using just two input requests for mysql usingthree input requests .
all of the input request failures insshdand svn require one input for authentication and session establishment and another final input to trigger the symptom.
all of the input request failures in mysql require two inputs for authentication and database selection providing a session and execution context in which the final input could trigger the symptom.
table lists the number of failures that can be triggered with no more than one input request excluding session establishment inputs.
if we exclude the session setup inputs then nearly of the bugs in all applications need just a single input request to trigger the symptom in all such cases we have observed that it is always the last input in the corresponding session connection which triggers the symptom.
among the remaining cases nearly of the bugs needed more than one input to trigger the symptom and the remaining of bugs do not have any clear information about the number of inputs in their bug reports.
furthermore considering all the bugs for which we could determine the exact number of inputs all of the failures for apache squid svn and tomcat can be reproduced using at most and input requests excluding session establishment inputs respectively only two failures in sshd and one in mysql required more than non login input requests.
in fact very few bug failures bugs across all server bugs excluding the unclear cases needed more than three non login input requests to reproduce the symptom.
another result not listed in the tables is that for most of the bug reports we studied the symptom occurs immediately after the last faulty input is processed.
in fact the o nly exceptions were hangs and time outs for these the time between the last faulty input and when the symptom can be observed is time dependent but usually small.
this suggest s that the error propagation chain for these bugs is usually short and that a symptom can usually be detected immediately after the server processes the faulty inputs.
these results agree with previous work that found that error propagation chains in the linux kernel are short in practice .
implications these results have several implications for automatic bug diagnosis tools .
virtually all failures can be triggered by replaying a small number of inputs.
.
most of the failures can be simply reproduced by first connecting to the server creating a session if necessary through authentication and or a database select request and replaying a single input.
.
for most of the bugs the last input request from the session connection which triggers the fault can be used to reproduce the symptom.
.
except for bugs which cause a hang or time out the failure symptom for a set of faulty inputs will occur immediately after the last faulty input is processed.
.
analysis interestingly when we consider only the subset of nondeterministic or multi input bugs many characteristics a re very different from the overall bug characteristics.
for example among the non deterministic bugs a majority ofthem are multi input bugs and only were single input bugs remaining cases were unclear .
also only of the non deterministic bugs result in incorrect output most of the failures result in catastrophic failures like cr ash segmentation fault assertion violation and hangs.
this im plies that majority of non deterministic bugs need multipl e inputs to trigger a failure and many fewer of them result in incorrect outputs as compared to the overall bugs.
of the multi input bugs only are deterministic are timing dependent and are non deterministic.
this implies that many fewer multi input bugs show deterministic behavior compared to the overall bugs.
.
multiple inputbug analysis bugs that require multiple inputs to trigger a symptom are harder to reproduce and diagnose because the faulty inputs may be interspersed with non faulty inputs and the combination of inputs to explore can be large.
we did a more detailed study of multi input bugs to see if there are patter ns that can be exploited to reduce the input stream to just the faulty inputs.
specifically we wanted to see whether the set of inputs for triggering a multi input failure were likely t o be clustered together within an input stream or occur within a short time duration which can help automatic tools to detect the symptom triggering inputs more easily.
otherwise automatic tools will need to use more complex algorithms to track down the faulty inputs.
there were multi input bugs from squid from apache from sshd from svn from mysql and from tomcat .
for servers like apache squid and tomcat any bug in table with more than one input is considered a multi input bug.
for sshd svn and mysql we considered a multi input bug to be any bug requiring more than two two and three inputs respectively to trigger the symptom.
our rationale is that all of these two and three input bugs require one and two inputs respectively for establishing a session e.g.
authentication and or database selection a nd a final single input for triggering the failure.
these bugs ar e in essence single input bugs with additional session esta blishment inputs that occur in a known location within the input stream and can be easily buffered for each session.
we classified each bug into one of three categories clustered likely clustered andarbitrary .
a bug is classified as clustered if the input requests must occur within some bound this bound is often short.
for this category the faulty inputs are always going to be clustered within the input stream within a short period of time less than a few minutes .
we classify a bug as likely clustered when we know that the faulty input requests are likely to occur within a short duration for most real world inputs but there is no bound.
for these cases there are reasonable cases in which the inputs may not be clustered.
inputs are classified as arbitrary if there is nothing to indicate that they must be or usually will be clustered withi n an input stream in real world usage.
this does not mean that the inputs will not be clustered it simply means that there is no reason to expect that they are likely to be clustered for a single given input stream.
table shows our detailed analysis results.
the second column shows the bug s id from the bug database the third column reports the number of inputs needed to trigger the symptom and the fourth column succinctly describes the steps needed to trigger the symptom.
the fifth column ex appl bugid ip steps to trigger the bug conclusion class squid send a post request with an incomplete body kill the origin server and send the remaining body of the request.all the events will happen within the time a complete request is processed hence will most likely occur within a short time duration.clustered squid send many ntlm authenticator requests.
the requests can be far apart.
arbitrary squid start downloading a file.
then start downloading the same file concurrently.
abort downloading the first file.as the requests happen concurrently they will occur within the duration of first download.clustered squid send a first request to a web page.
then send a second request to same webpage at nearly the same time.both the inputs will occur within a very short duration before the completion of first request.clustered squid send a lot of requests for a long time.
no mention of any particular inputs causing the crash.the requests can be far apart spread over a long period of time.arbitrary apache first try to authenticate with ldap server with wrong login password.
then try to authenticate again with same login.incorrect and correct logins will most likely happen within a short duration.likely clustered apache need a random number of inputs to cause the crash.the requests can be spread over a long period of time.arbitrary apache send requests which open a connection to ldap server.
first two requests work but the third may crash server.
sometimes more such connections are needed for crash.when many requests are needed they may not occur within a short duration.arbitrary sshd first login to a shell.
run any command e.g.
sleep then ctrl c while the command is running.last two commands can happen within a short duration for short running commands.likely clustered sshd execute commands through a library function cmd which internally opens a new channel and closes it after executing the command.all the commands will be sent consecutively and will most likely occur within a short duration.likely clustered sshd three successive failed login attempt.
all the three requests can occur consecutively e.g.
when someone doesn t remember the password .likely clustered sshd the bug is triggered by a denied ssh connection blocked by tcp wrappers.
the bug occurs after 5th blocked connection.five blocked connections can happen over a long period of time.arbitrary svn first login to server.
run any svn command e.g.svn commit then ctrl c while the command is running.last two commands will occur within a short duration before the svn command completes.clustered svn first login to server.
then run svn lock test.txt followed by svn commit test.txt when there is no write access on root.as in many cases users commits after small changes the last two commands will be within a short duration in such cases.likely clustered svn first login to server.
then run svn lock test.txt followed by svn commit test.txt .as in many cases users commits after small changes the last two commands will be within a short duration in such cases.likely clustered mysql execute a series of insert queries in main thread execute some select update and delete queries on the same table in background thread.according to the report error occurs always after some queries execute concurrently likely to be close together.likely clustered mysql 5prepare stmt1 from select into arg15 execute stmt1 execute stmt1 .the execute stmt can occur far apart.
arbitrary mysql 4set sql mode only full group by then select round sum a count from foo group by a .in cases when sql mode is not set in the config file it can be set long before running group by based queries.arbitrary mysql create innodb table immediately create myisam table containing a point column insert into the table with the point column.in most cases insert queries will be immediate after table creation.likely clustered mysql 5prepare stmt1 from explain complex select execute stmt1 execute stmt1 .the execute stmt can occur far apart.
arbitrary mysql in first thread load data infile file into mytable in second thread insert into mytable2 values .as both requests are processed concurrently they should occur within a short duration.clustered mysql 4load data from master execute any command.
as the requests are executed consecutively they should occur within a short duration.clustered mysql in master create temporary table t a int reset master in slave stop slave reset slave start slave .reset master can occur after a long time of create.
arbitrary tomcat when there is more than simultaneous connection run a long request like big dir listing.as the requests are processed concurrently with other connections they should occur within a short duration.likely clustered tomcat few inputs with clustering and session replication needed to trigger exception.the inputs can occur independently.
arbitrary tomcat when requests are being processed kill one of the replication servers all the web servers will fill up the max threads.all the inputs will occur within socket timeout period after which the threads will be unblocked.clustered tomcat start session through webpage restart webapp reload webpage in that session.the two requests can occur far apart.
arbitrary tomcat request a static file get a response with etag.
request the same file again getting a response without etag.the two requests can occur far apart.
arbitrary tomcat authenticate two users simultaneously with http digest.the two requests will occur within a short duration.clustered tomcat send requests to make jdbcrealm cache preparedstatement and preparedroles.
run two requests allowing two threads to call getroles simultaneously.first set of requests can occur far apart.
arbitrary table analysis of multiple input software bugs.plains why we classified the bug as we did and the last column shows the classification we assigned to the bug.
we classified of the bugs as clustered and bugs as likely clustered.
we deemed of the bugs as arbitrary.
the faulty inputs for the first two categories can be isolated relatively easily.
even for arbitrary cases it should be noted that server applications normally run on multiple installations.
to perform a successful diagnosis we do not need to reproduce the failure at every possible instal lation it is sufficient to reproduce it on a single installati on.
thus it is enough for the automated tools to work if the faulty inputs will cluster in at least one instance.
for designing bug diagnosis tools that replay input the important factor is the time between the firstfaulty input and the symptom this delay determines the minimum amount of information a replay tool must record in order to be able to catch all of the faulty inputs.
since we have determined that most faulty inputs are clustered together within an input stream we know that the time between the first faulty input and the last faulty input is small and since the symptom will occur shortly after the last faulty input as de scribed in section .
we can conclude that the time period between the first faulty input and the symptom is also small.
implications there are two important implications of our results .
most multi input bugs except for those in which the symptom is a hang or time out will trigger the symptom shortly after the first input.
this means that a replay tool only needs to record a small suffix of the input stream to reproduce the failure.
.
the locality of multiple faulty inputs within an input stream makes it easier to create a reduced test case.
.
study of concurrencybugs surprisingly we found only three concurrency bugs out of bugs in the multi threaded servers apache mysql and tomcat we studied in section .
this strongly indicates that there are relatively few concurrency bugs in servers relative to the totalnumber of reported bugs similar observations can be drawn from the data in .
one possible reason is that servers generally process each requ est relatively independently producing fewer inter thread i nteractions than other multi threaded programs with more intricate sharing behavior.
nevertheless concurrency bugs do occur and may have different characteristics from other bugs as they usually in volve multiple threads and may be difficult to reproduce.
we therefore manually selected and analyzed a set of concurrency bugs to determine if they show behavior similar to that of the bugs in section .
we now present the results of our analysis of these bugs.
as before we classified the concurrency bugs based on three characteristics observed symptoms reproducibility and the number of inputs needed to trigger the symptom.
we selected concurrency bugs from apache mysql and tomcat by searching the bug databases based on a set of keywords like race s atomic concurrency dea dlock lock s and mutex s in a manner similar to lu et al.
.
the other servers have few concurrency bugs.
out of these were data race bugs and were deadlock bugs it was not clearly reported for two of the bugs .appl.
deterministic timingdependentnondeterministic apache .
.
.
mysql .
.
.
tomcat .
.
.
total .
.
.
table symptom reproducibility characteristics of concurrency bugs.
table shows the results of classification based on symptoms.
each column shows the number of bugs for the corresponding symptom or combination of symptoms.
we include combinations of symptoms because some of these concurrency bugs were reported to produce different yet specific symptoms in different executions for the same input e.g.
a segmentation fault in some executions and an incorrect output in others .
there are some interesting differences between concurrency and non concurrency bugs.
first as expected a much higher fraction of bugs produce hangs most of them are due to deadlocks.
second five of the concurrency bugs produced different yet specific symptoms in different executions as noted above.
third there are much fewer incorrect outputs with concurrency bugs overall but in mysql .
it appears that a higher fraction of concurrency bugs produce catastrophic symptoms like crashes or hangs which can cause service interruption.
this observation is similar to that reported by lu et.
al.
.
table shows our results from classifying bugs as deterministic timing dependent or non deterministic.
most o f the bugs overall and in apache and tomcat show non deterministic behavior.
this underscores the dif ficulty of reproducing the symptoms of concurrency bugs.
table shows the results of classifying bugs based on the number of inputs required to reproduce the bug note that the columns differ from table .
for some cases it was not clear from the bug reports exactly how many inputs were needed for example bug reports mention that they need to run some test cases in stress mode with multiple threads repeatedly for a few minutes to trigger a symptom .
we have conservatively classified these cases as requiring more than eight inputs.
the fifth and sixth columns are identical in purpose to those of table .
we used only the bugs for which we know the exact number of inputs to trigger them to compute the maximum number of inputs.
as before the numbers in brackets in the table are the corresponding fractions as a percentage of the total number of bugs.
there are several differences with our earlier results for non concurrency bugs.
first all the studied concurrency bugs need multiple non login inputs to trigger a symptom as a comparison very few non concurrency bugs needed multiple non login inputs for reproduction .
some cases need significantly more inputs but none of the bugs in apache and mysql for which bug report mentions exact number of fault triggering inputs needed more than inputs.
second many bugs needed executions with multiple threads and multiple client connections for some time to reliably trigger the symptoms.
for most of the bugs though the bug reports mention that the symptoms can possibly be triggered using or threads and client connections.
application seg fault crash assert.
hang incorrect seg fault seg fault crash crash violation output incorrect assert.
incorrect hang output violation output apache .
.
.
.
.
.
.
.
.
mysql .
.
.
.
.
.
.
.
.
tomcat .
.
.
.
.
.
.
.
.
total .
.
.
.
.
.
.
.
.
table classification of bug symptoms of concurrency bugs.
application input input input unclear max inputs apache .
.
.
.
mysql .
.
.
.
tomcat .
.
.
.
total .
.
.
.
max table maximal number of inputs needed to trigger a symptom for conc urrency bugs.
.
implications these results have several implications for automatic bug diagnosis tools for concurrency bugs.
.
as most of the concurrency bugs are non deterministic and produce different symptoms bug diagnosis tools will need to develop new techniques to reliably reproduce the symptoms.
.
a somewhat larger suffix of inputs will be needed to trigger the symptoms compared to non concurrency bugs.
.
for most of the concurrency bugs we will also need to use inputs from multiple different client connections.
this can significantly complicate the process of reproducing the symptom and minimizing test cases.
finally note that our methodology successfully identified both non deterministic behavior and also the need for multiple inputs in these bugs.
the same methodology found a very low occurrence of both these behaviors among overall reported bugs as described in the previous section.
this is an important validation of those perhaps surprising resu lts for overall reported server bugs in section .
.
implications for designing automatedbug diagnosistools bug diagnosis often involves one or more of the following steps recording inputs that may lead up to a fault reducing a small triggering input from the recorded inputs when a fault does occur and using the inputs to somehow determine the cause of the bug.
new bug diagnosis tools may be able to exploit the bug characteristics we have found to improve their efficiency.
we provide potential ways of using our results below.
.
recording server input tools that automatically create reduced test cases for bugs need an recorded input that triggers the bug.
however recording all of the inputs to a server program is infeasible .
servers process vast amounts of inputs over long periods of time a way to prioritize which inputs to save and which inputs to discard are needed.
our results indicate that most bugs can be triggered with a single input that some protocols require an authentication step before playing that single input and that the inputs needed for reproducing a multiple input bug are oftenclustered close together within the input stream.
addition ally we observed like previous work that the symptom is often triggered immediately after the faulty inputs have been processed.
also as discussed in section we found that the time duration from first faulty input to symptom is usually short for most bugs.
the implication is that an automatic bug diagnosis tool should be able to catch most bugs without recording the entire input stream.
rather it should suffice to record a prefix of the per session input to replay session establishment a nd authentication if necessary and a suffix of the input which will most likely contain all of the inputs needed to trigger the symptom .
however bug reports often try to reproduce a failure using a subset of the inputs containing all the failure trigge ring inputs instead of the complete input stream.
one concern is that the ability for a set of inputs to trigger a symptom may depend upon global state in the server that was affected by processing earlier inputs.
for example one set of inputs may cause the server to allocate memory in such a way that a buffer overflow triggers a segmentation fault while a subset of those inputs generate an incorrect output symptom due to a different heap layout.
while a simple test case exists how do we know that it can be reduced from a larger test case?
in other words can a suffix of inputs which contains all the failure triggering inputs reliably trigger the same sympt om that was triggered by the original input stream?
we hypothesize that most deterministic bugs will generate identical symptoms even when earlier non faulty inputs are removed from the input stream.
such bugs have a small number of failure triggering inputs and appear to have small error pro pagation chains.
moreover servers generally process each r equest relatively independently.
given this we believe fai lure behavior of these server bugs is less likely to be affected by differences in global state.
we did a preliminary experiment to see if the global state of the server often affects whether a set of faulty inputs triggers a symptom.
we selected four real bugs from four server applications a stack buffer overflow bug due to an integer overflow sshd a null pointer dereference bug apache and two heap buffer overflow bugs squid and nullhttpd .
for each bug we created an input stream of good inputs and appended to it the faulty input.
we then proceeded to feed the input stream into the server recorded whether the same symptom as reported in the bug report occurred removed good inputs from the input stream and re ran the experiment.
we repeated this process until we had reduced the input stream to just faulty inputs.for all of the bugs we tested the same symptom occurred after the faulty input was received regardless of the number of good inputs that preceded it.
this suggests that the ability to reproduce a bug by replaying a suffix of the inputs to the server does not greatly depend upon global server state.
.
automated test casereduction our results may also help develop heuristics for guiding automatic test case reduction.
for example the ddmin minimizing delta debugging algorithm by zeller and hildebrandt considers all test inputs as equally likely to tr igger a symptom.
however our results indicate that most server bugs are single input bugs or require a small number of inputs that are clustered close together.
as stated in sec tion for most of the bugs we find the time duration from first faulty input to symptom is usually short.
therefore it may be possible to improve the efficiency of test case reduction algorithms by first systematically testing each sma ll suffix of the recorded input stream to see if any of those inputs trigger the symptom before applying a more general algorithm like ddmin.
for most of the bugs this procedure is likely to be faster than ddmin.
also some of the tools can possibly take benefit of the fact that very few inputs usuall y are needed to trigger the symptom by first searching small subsets before trying more complex algorithms.
.
automated bug diagnosistools the results of our study may also help improve tools such as triage that use checkpointing and replay to automatically diagnose bugs during production runs.
triage period ically checkpoints a program during normal execution .
when it detects an error triage instruments the code with additional detectors that help determine the bug s root cau se and re executes the program from the last checkpoint .
our results have several implications for tools like triage .
first a system like triage can reduce the input stream to a much smaller set of inputs as described previously speed ing up the bug diagnosis process by not replaying irrelevant inputs.
second our results indicate that symptoms can be triggered by restarting the server and replaying a small num ber of inputs i.e.
without checkpointing server state.
this alleviates the need for checkpointing however technique s like checkpointing may not be practical due to various reasons.
first complexity of taking checkpoints which needs specialized support from application and or operating sys tem is a major issue.
second multi threaded process also complicates the checkpointing procedure further .
second they can impose additional overhead on normal program executions.
in addition diagnosis cannot be done if the fault happens before the checkpoint is taken.
using a restart replay mechanism will enable us to build a much simpler and much powerful automatic bug diagnosis tool.
.
related work several previous bug characteristic studies have examined the bug reports of both open source and proprietary software.
gray studied the maintenance reports of customer systems to study trends in system outages his results show that software is the dominant factor in system outages.
lee and iyer studied the root causes and error propagation behavior of bugs in the tandem guardian90 system and concluded that consistency checks detected slightly more than half of the bugs in software and prevented error propa gation for of the bugs .
sullivan and chillarege studied the root causes and triggers for bugs and determined that most bugs were caused by memory errors.
more recent work by li et.
al.
aimed to update the results of sullivan and chillarege by studying the mozilla web browser and the apache web server they found that memory errors were not the dominate cause of errors in these applications.
furthermore they found that incorrect program behavior was the most common bug symptom our study confirms this result.
lu et.
al.
studied many characteristics of concurrency bugs in open source software they foun d among other things that most concurrency bugs can be reliably triggered by controlling the schedule of four or fewe r memory accesses.
chandra and chen studied the bug reports of several versions of apache gnome and mysql to determine whether application agnostic recovery techniq ues could recover from the majority of bugs detected in production runs.
our study confirms their finding that most bugs are deterministic .
as far as we know no other bug study has examined the number of inputs needed to reproduce bugs or aimed to answer questions about the feasibility of creating automatic diagnosis tools that replay inputs.
.
conclusionsandfuturework in this paper we reported the results of an empirical study of bugs found in open source servers.
our results show that most server bugs are deterministic and that failures due to most bugs can be reproduced by replaying a single input request after session establishment if needed .
even f or the remaining multi input bugs the set of inputs needed for reproducing failures is usually small and are often cluster ed together within the input stream.
for most of the bugs the time duration between first faulty input and the symptom is small.
our results also showed that many bugs produce incorrect outputs indicating that better detectors are need ed to flag errors in production runs.
most of the concurrency bugs though need multiple inputs to reproduce a symptom.
finally we discuss how the results can be used by automated tools for in production bug diagnosis.
one of the key implications of the study is that most of the failures may be reproduced without checkpointing server state.
in future work we intend to investigate ways of creating light weight error detectors that can reduce the number of bugs that trigger incorrect outputs.
based on the results of this study we also plan to build a tool capable of reproducing failures during in production runs reducing test c ase inputs and automatically diagnosing root causes of failure s using a repeated restart replay mechanism.
.