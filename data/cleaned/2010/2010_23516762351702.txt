predicting recurring crash stacks hyunmin seo and sunghun kim department of computer science and engineering the hong kong university of science and technology hong kong china hmseo hunkim cse.ust.hk abstract software crash is one of the most severe bug manifestations and developers want to fix crash bugs quickly and efficiently.
the crash reporting system crs is widely deployed for this purpose.
even with the help of crs fixes are largely by manual effort which is error prone and results in recurring crashes even after the fixes.
our empirical study reveals that of fixed crashes in firefox crs are recurring mostly due to incomplete or missing fixes.
it is desirable to automatically check if a crash fix misses some reported crash traces at the time of the first fix.
this paper proposes an automatic technique to predict recurring crash traces.
we first extract stack traces and then compare them with bug fix locations to predict recurring crash traces.
evaluation using the real firefox crash data shows that the approach yields reasonable accuracy in prediction of recurring crashes.
had our technique been deployed earlier more than crashes in firefox .
could have been avoided.
categories and subject descriptors d. .
testing and debugging debugging aids tracing general terms management reliability verification keywords crash crash reporting system bug .
introduction software crash is one of the most obvious and severe bug manifestations.
crashes immediately stop software execution and often cause data loss.
if a crash happens in a critical part of the operating system kernel the entire computer may stop working and require rebooting.
researchers and developers have put in significant efforts to fix crash bugs permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
ase september essen germany copyright acm ... .
.quickly and efficiently.
the crash reporting system crs is an outcome of efforts made in this context.
many crss such as windows error reporting mozilla crash reporting system and apple crash reporter have been widely deployed and are actively used in practice.
when a crash is detected on the client side crs generates acrash report by collecting crash related data and sends it to a server maintaining all crash reports.
the report typically includes crash point and stack traces .
since often too many crashes are reported similar crash traces are grouped together and put into a crash bucket .
then developers focus on top crash buckets which contain the most frequent crashes .
a bug report is filed for top crashes and is linked to the corresponding crash bucket.
crash traces in the same bucket are investigated to localize and fix the crash.
even with the help of crs fixing crashes largely relies on manual effort and this process is error prone.
gu et al.
found that bad fixes account for as much as of all bugs .
yin et al.
investigated post release bug fixes in three large operating systems and found that at least .
.
of them were incomplete .
in addition our empirical study revealed that of fixed crashes in firefox .
are recurring and many of them are due to incomplete or missing fixes.
figure shows an example of a recurring crash.
two crash traces are collected from one crash bucket in firefox .6b1.
a developer made a patch to fix this crash in firefox .6b2 by changing the code in function nstexttosuburi unescapeandconvert shown in trace a. however the developer missed a crash bug in trace b. as a result the same crash recurred following trace b. unfortunately this crash became one of the top crashes in the official release of firefox .
.
it was re fixed in .
.
by changing function nscacheentrydescriptor getdeviceid in trace b. after the second fix the crash disappeared.
to avoid recurring crashes it is desirable to automatically check if all reported crash traces in a bucket are covered by a crash fix.
if any crash traces are not covered by the proposed fix the crash may recur due to the missed traces as shown in figure .
in this paper we propose a technique to predict recurring crash traces.
from crash traces in a crash bucket and a proposed fix for the bucket we automatically check if the fix covers all crash traces in the bucket.
we first extract unique stack traces from the bucket and expand the traces based on program call relations.
then we compare the original and expanded traces with crash fix locations to identify missing traces.permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
ase september essen germany copyright acm ... .
xpcwrappednative callmethod ns invokebyindex p nstexttosuburi unescapeandconvert ns strdup strlen nscacheentrydescriptor getdeviceid crash point trace a trace b first fix in .6b2 second fix in .
.
figure two crash traces from the the same crash point.
a developer fixed this crash bug report by modifying function nstexttosuburi unescapeandconvert shown in trace a. our approach correctly predicted that trace b will reappear.
actually this crash trace became one of the top crashes in firefox .
.
.
the developer filed a new bug report bug report and fixed function nscacheentrydescriptor getdeviceid .
finally the crash disappeared in firefox .
.
.
we evaluate our approach by using actual firefox crash data crash fixes and corresponding crash reports in releases of firefox .
.
we apply our technique to each crash bucket and predict if any traces will recur.
the evaluation is based on the actual recurring crash data of firefox.
our technique predicts recurring stack traces with reasonable accuracy .
precision and .
recall.
had the proposed technique been deployed in advance it could have prevented occurrence of more than crashes.
we asked for feedback from firefox developers who were involved in fixing the crashes used in our experiment.
in general they considered our approach interesting and useful for fixing crash bugs.
overall our paper makes the following contributions empirical study on recurring crashes we present an empirical study on crashes recurring due to incomplete and or missing fixes.
our study reveals that of fixed crashes are recurring and are non neglectable they become top crashes in subsequent releases.
an automatic technique to predict recurring crash traces for a given crash fix our technique can automatically predict if any crash traces in the crash bucket will recur.
evaluation on actual crash fixes in firefox .
we present experimental evaluation of our approach and firefox developer s feedback.
the remainder of the paper is organized as follows.
we present empirical study results and statistics for recurring crashes in section .
section introduces our approach.
section presents our experimental setup.
after reporting our experimental results in section we discuss limitations of our approach in section .
related work is surveyed in section and the paper is concluded in section with directions for future research.
.
recurring crashes this section reports the results of our empirical study on recurring crashes.
we first introduce crs and explain crs bug crash bucket stack traces crash point bug report crash fix figure a crash bucket and a linked bug report related terminologies.
we use mozilla s crash reporting system mcrs as a typical crs example.
then we present statistics of recurring crashes and discuss the reasons for recurring crashes.
.
mozilla crash reporting system when a crash occurs on the client side the crs generates a crash report and sends it to a server.
for example mcrs generates a crash report including crash point crash time product version operating system and its version hardware information optional user comments and all thread stack traces from the crash.
the crash report is sent to the mcrs server.
on the server side crash reports having similar crashes are grouped together and put in the same crash bucket figure .
mcrs s grouping is based on the crash point.
that is crash reports having the same crash point are grouped together and put into the same crash bucket.
then developers investigate the crash buckets to fix them.
developers usually focus on top crash buckets first .
each crash bucket is linked to a bug report to monitor and track the progress of crash fixes figure .
table explains the terminologies used in this paper.
.
many recurring crashes to observe crashes that recur after fixes we explored the crash reporting system and the bug reporting system of mozilla firefox described in section .
.
for a twotable terminologies used in the paper name explanation crash report when a crash occurs on the client side a crash report will be generated and sent to a crs server.
a crash report includes crash related information such as stack traces and a crash point.
crash point the crashed location.
it consists of file name function name and line number.
stack traces a list of stack frames captured at the crash moment.
each stack frame corresponds to information of a function including the function name source file name and line number.
a stack trace shows the function call sequence at the moment of crash.
crash bucket a group of crash traces.
similar traces are put in the same bucket.
mozilla crash traces are grouped according to their crash point.
bug report bug reports fixing crash bugs are linked to the crash buckets.
developers communicate via comments in bug reports.
the status of a fix can be checked via the comments and the history of bug report resolutions.
crash fix when a bug is fixed a patch file is usually attached to the bug report.
once reviewers accept the patch it is reflected to the source code and the next release contains the patch.181table number of crash reports in three different versions for three crash fixes.
gray color cells represent bug fixed versions.
bug id crash point ver ver ver 538722nshtml5elementname .
.
.
.
.
.
initializestatics nstextframe reflow3.
.
.
.
.
.
528311nsxultreeaccessible .6b3 .6b4 .6b5 gettreeitemaccessible week period in march we identified crash reports and crash buckets from nineteen versions of firefox .
including five beta versions.
then from the bug reporting system we identified the corresponding bug reports linked to these crash buckets.
among the identified bug reports we used only the reports in fixed status for our study.
in total we collected bug reports.
these reports were corresponding to bugs in crash buckets that had been fixed1.
then we checked whether crashes in the crash buckets had disappeared after the fixes.
for crashes we identified the number of crashes reported in each version.
we also identified the version where the crash was fixed.
by looking at the number of crash reports in different versions before and after the fixes we manually checked if the crashes had disappeared.
table lists three example cases.
the first column shows bug report ids and the second column shows crash points.
the next columns show the number of crash reports at different versions.
gray color cells represent the version where the crashes were fixed.
bug report fixed a crash nshtml5elementname initializestatics .
there were crash reports in version .
.
.
after the fix was made in .
.
the crash had disappeared completely.
however bug is an example of an incomplete fix.
even though a fix was applied to .
.
and crashes were reported in .
.
and .
.
respectively.
bug is also an incomplete fix.
developers fixed the crash twice after realizing it had not disappeared after the first fix in .6b4.
after the second fix in .6b5 the crash disappeared.
surprisingly we found that almost one half out of of fixed crashes were recurring after their corresponding first crash fixes .
table recurring crashes among fixed ones name value of fixed crash point of recurring crash point .
.
reasons for recurring crashes this section reports the outcome of further investigation of potential reasons of recurring crashes.
crash reports in the same bucket have the same crash point but their detailed stack frames may differ.
for example figure shows two different stack traces in the same crash bucket.
the functions at the third stack frame are different.
we sub grouped crash reports in the same bucket according to their respective crash stack traces.
then we counted the number of crash reports in each sub group.
figure a is 1some bug reports fix more than one crash bucket.
group group group group group of crash reports trace sub groups a before fix group group group group group of crash reports trace sub groups b after fix figure number of crash reports in trace sub groups before and after a fix bug fix .
the fix missed sub group .
an example of crash nsxultreeaccessible gettreeitemaccessible .
it shows the number of crash reports for five different sub groups in the same crash bucket in .6b3 before fix is released.
we excluded three sub groups having only one crash report.
we counted the number of crash reports after a fix in .6b4 in each sub group in figure a to check if they had disappeared.
figure b shows the result.
interestingly all other sub groups have disappeared but crashes in subgroup recurred.
in fact crashes in sub group account for of all crash reports in the corresponding bucket in firefox .6b4.
when developers fix a crash bucket sometimes the fix misses certain crash traces in the bucket.
as a result of such incomplete fixes some of the crash traces in the fixed crash bucket may recur as shown in figure b .
this is one of the main reasons of recurring crashes.
bug report confirms that the first fix was indeed incomplete.
a developer modified function nsxultreeaccessible getchildat in the first fix.
all stack traces which include this function disappeared while traces not including this function recurred in the next release.
another developer mentioned in the bug report that the crash had not disappeared in .6b4 and the first developer fixed a function in the recurring stack trace.
after the second fix the crash disappeared.
with thousands of crash reports in a bucket it is easy to miss some and end up with incomplete fixes as shown in figure b .
a comment in another bug report clearly shows another example of a crash recurring due to an incomplete fix.
after observing that crash imgframe draw is recurring after the first fix the developer re fixed it and left a comment i don t know how this bit crash trace got lost from the patch i ended up checking in but it s pretty essential.
.
.
to check if these missing stack traces can be recognized by developers immediately we measured the time lag between the first incomplete fixes and the corresponding follow up fixes.
unfortunately we found the average time was days.
this indicates that these missing stack traces are not something developers catch immediately after the first incomplete fixes.
thus this issue is non neglectable.
to assist developers and prevent such incomplete crash fixes we propose an automatic technique to predict recurring crash traces.182sub grouping identifying verifying fix locations foo bar ... ... covered stack traces missing stack traces stack expansion classification bug bug extracting call relations figure overview of our approach.
.
approach since developers may miss some stack traces in the fixes our approach tries to identify them when a fix is made to prevent potential recurring crashes.
we present the overview of our approach first and explain each component in detail.
.
overview figure shows the overview of our approach.
first crash traces in the same crash bucket are sub grouped according to their traces.
from a given crash fix the fix locations are identified.
then we compare sub grouped crash traces with bug fix locations.
during this comparison traces are expanded using their call relations acquired from static analysis of source code.
if we find crash fix locations in original or expanded stack traces we classify these traces as covered by the fix.
if we cannot find fix locations in original or expanded stack traces they are classified as missing .
missing crash traces are predicted to recur which requires developers attention.
.
grouping crash traces the example cases in figure and figure show that developers miss some stack traces in the same crash bucket.
to find such traces we sub group crash traces in a crash bucket.
two traces are grouped together when all stack frames of the traces are matched.
we consider function name source file and line number of each frame for matching.
this matching is quite strict but other heuristics for grouping crash traces can be applied in this process.
firefox is a multi threaded program having separate stack traces for each thread.
we consider only the thread containing the crash point and use the stack trace of that thread for sub grouping.
after the sub grouping we check if a fix for the bucket covers all sub groups in the bucket.
.
identifying crash fixes and locations we use bug fix locations to check if there are any missing traces in the crash bucket.
fix locations can be extracted from patch files attached to bug reports or developers can specify them.
we use the links between crash buckets and bug reports to identify the corresponding crash fixes.
as explained in section .
each crash bucket has links to the corresponding bug reports.
fix location hidden function calls crash point b c d e a original stack b expanded stack f g h i j a fix location l l l figure two crash stacks with bug fix locations.
each circle is a function corresponding to a stack frame.
the crash point is at the bottom.
stack a shows an unexpanded stack trace.
since bug fix location is one of the stack functions the trace is classified as covered.
stack b shows level and stack expansions from functiona.
iffis not included in the stack after expansion the stack is classified as missing.
from the linked bug reports we extract patch files attached to the bug reports.
we verify whether the fix code in the patch files had actually been released.
we downloaded the source code of firefox release versions and manually compared them with code in patch files to check if the changed code was really included in the releases.
after identifying and verifying fixes linked to crash buckets we extract fix locations in functional levels.
patch files include the changed code with file names and line numbers.
by looking at the source code corresponding to file names and line numbers we acquire the function names.
.
predicting missing traces finally we compare each sub group in a bucket described in section .
with fix locations identified in section .
.
figure sketches the comparison algorithm.
figure a shows an original stack trace with explicit call sequences.
each circle is a function corresponding to a stack frame and the arrows represent call sequences shown in the stack trace.
the bug fix location is marked .
the crash point is drawn at the bottom.
since the fix location is in the stack trace in figure a the fix modifies a function in the stack trace we assume the fix covers the stack trace and classify it as covered.
however it is not always the case that fix locations are in original stack traces.
a stack trace is not a complete execution trace it only shows function call sequences at the moment of crash.
functions once called and successfully returned are not shown in the stack trace.
these functions may include crash bugs and fixes may be located in these functions.
to handle this case we expand stack traces according to call relations and control flow graphs cfg .
we acquired call relations and cfg from firefox source code.
firefox supports multiple platforms and uses different files and implementations depending on the target platform.
to acquire call relations we built firefox on the windows platform and identified the files and declaration directives.
then we used understand to get call relations with cfg.
we also identified class hierarchy information using understand to resolve virtual function calls.
from the cfg we perform path analysis to recover hidden function calls.
for example figure shows the cfg of183entry exit if y g b x path path block1 block2 figure the cfg of function a function ain figure b .
from the cfg and stack trace we know that path2 of the ifbranch is taken because the next function in the trace is b and bis inside block2 .
then ymust not have been called.
also we know gmust have been called and returned since it is located before calling b. on the other hand we know xhas not been called since the stack trace shows the execution has not returned from b. then we expand the stack by including gsince we know gwas called and returned.
figure b shows the expanded trace.
we call this level expansion.
in the same manner we can expand the stack further by considering call relations from the newly added function g. in this example gcalls h so his included in the expanded stack in level expansion.
the figure shows that iand jcan be included in level expansion.
note that figure b only shows stack expansion from function a. other functions are expanded simultaneously in our approach.
in figure b the fix location function f locates outside the original stack trace.
we check if fis included in the expanded stack trace.
if it does we classify this stack trace as covered.
in this example fis not located in the expanded stack trace so this trace is not covered.
it is possible that our approach can not find fix locations from any of the original and expanded stack traces in a crash bucket.
for example a crash fix can be related to configuration files or meta files rather than fixing problems in functions.
in such cases we do not have any clue to distinguish missing traces from covered traces.
we do not predict stack traces in such crash buckets.
algorithm describes the missing trace prediction approach formally.
given a set of stack traces sfrom a crash bucket a set of pairs of function names rfor call information and bug fix functions fix the algorithm classifies sintocover and miss .
from line to we expand each stack trace for the given level .
expanded traces are compared with bug fix locations at line .
each trace is classified into cover if fix locations are found otherwise classified into miss .
note that expandstack function in the algorithm is simplified.
for the following reasons irrelevant functions may be included during the current stack expansion process and affect prediction accuracy.
branches in the actual program execution only one path of a branch is taken.
however sometimes it is not obvious to figure out which path is taken statically.
we use a conservative approach by considering all possible execution paths.
virtual functions virtual functions in c are dynamically dispatched.
the actual function called from a virtual function call site is determined dynamically based on the type of the object in run time.
we use class hierarchy analysis to statically resolve virtual function calls.algorithm predicting missing traces input s a set of stack traces for a crash bucket r a set of function call information fix changed functions in the bug fix level expansion level output cover covered stack traces miss missing stack traces 1cover 2miss 3foreach s sdo l es s while l level do es es expandstack es increase lby end ifes fix negationslash then addstocover else addstomiss end 15end 16function expandstack s 17es 18foreach f sdo if f f prime rthen addf primetoes end 22end 23return es leveraging more precise stack expansion techniques such as and including data flow analysis and alias analysis is our future work.
our prediction results may depend on the expansion level.
if stack traces are not expanded enough we may not find bug fix locations.
too much expansion introduces irrelevant functions and makes our predictions inaccurate.
we present and discuss the effect of different expansion levels on prediction results in section .
.
experimental setup this section presents our experimental setup including research questions subjects and evaluation measures.
.
research questions we design our experiments to address the following research questions rq1.
how accurately can our approach predict recurring crash traces?
for each crash trace and given fix we predict whether the trace may recur or not.
we compare our prediction results with actual recurring crash traces in the mozilla crash reporting system.
to measure the accuracy of our prediction we calculate precision recall and f measure.
rq2.
how can this prediction help developers?
our approach identifies missing crash traces for a given fix.
we want to evaluate if this information could be helpful for developers to catch and fix missing crash traces.
we present case studies and developers feedback for this evaluation.184table characteristics of our subject name description subject releases of firefox .
release date oct. mar.
programming language c c loc .2m .4m .
subjects we chose crash fixes in firefox .
on the microsoft windows platform as our experiment subject for two reasons.
firstly its crash information including a large number of crash reports and crash bug fixes is publicly available.
secondly firefox .
has five beta releases and several minor releases.
minor releases usually contain security updates and bug fixes rather than major updates to add new features.
when software has major changes it is not clear if recurring crashes are due to incomplete fixes or bugs newly introduced by the major changes.
by choosing minor releases we could clearly observe and evaluate recurring crashes caused by incomplete crash fixes.
table shows our subjects in detail.
we used versions of firefox .
which were released between october and march .
firefox is written in c and c and has 3m 4m loc.
table shows the number of crash buckets and stack traces used in our evaluation.
from crash buckets identified in section we used buckets in the microsoft windows platform in the experiment.
we excluded five crash buckets in other operating systems since we had acquired call relations and cfgs for firefox compiled in the windows platform.
for the crash buckets we collected crash reports from the firefox version right before the corresponding crashes were fixed.
when a crash bucket included too many crash reports we randomly chose reports.
we identified unique stack traces sub group out of crash reports we collected.
to evaluate our prediction results by checking which subgroup traces were recurring we collected crash reports in the next releases after the fixes had been applied.
this recurring crash data is used as an oracle set to evaluate our prediction results.
from the traces we identified traces that had actually recurred.
table the number of crash buckets and stack traces used in the experiment.
name value of crash buckets of recurring stack traces sub groups of total stack traces sub groups .
prediction accuracy measures we classify each stack trace as missing or covered and predict missing traces to recur and covered traces to disappear.
our prediction results can have four outcomes predicting a recurring stack as recurring r r predicting a recurring stack as to disappear r d predicting a disappeared stack as recurring d r predicting a disappeared stack as to disappear d d .
we calculate commonly used performance measures including precision recall and f measure from the above outcomes to evaluate the accuracy of our approach.
precision number of stack traces correctly classified as recurring nr r over the number of all stack traces classified as recurring.
precision p r nr r nr r nd r recall number of stack traces correctly classified as recurring nr r over the total number of actual recurring stack traces.
recall r r nr r nr r nr d f measure a composite measure of precision p r and recall r r for recurring stack traces.
f measure f r p r r r p r r r in addition we calculate feedback percentage of crash buckets that our approach makes predictions about among all crash buckets used in the experiment.
as discussed in section .
when our approach can not identify actual bug fix locations in any of the expanded stacks from a crash bucket we do not make a prediction for that bucket.
feedback the number of crash buckets for which we make predictions over the number of total crash buckets used in the experiment.
feedback of predicted crash buckets of total crash buckets .
results in this section we present the experimental results by addressing the research questions.
.
prediction performance to address rq1 in section .
we present prediction accuracy in terms of precision recall f measure and feedback.
we applied our approach to stack traces described in section .
and predicted traces likely to result in recurring crashes.
predicting recurring crashes for traces took less than minutes at each expansion level.
all experiments were conducted in a machine with core duo .66ghz cpu and 8gb ram.
table shows our prediction results when the expansion level is .
overall the prediction accuracy is reasonable precision and recall are .
and .
respectively and fmeasure is .
.
table prediction results when the expansion level is name value precision .
recall .
f measure .
feedback .
precision shows the percentage of recurring stack traces correctly predicted by our approach.
at l expansion we predicted stack traces as recurring traces.
among them are actually recurring traces precision .
.
in our dataset percentage of recurring stack traces among all stack traces is .
so the random guesser can only achieve .
precision.
our precision is much higher than that.185the recall value represents the ratio of identified recurring traces among all actual recurring traces.
our approach found almost of all recurring stack traces.
the feedback is .
.
we did not make any prediction for traces in four crash buckets since we could not find bug fix locations in any of the expanded stack traces from these buckets as discussed in section .
.
we hypothetically calculated how many recurring crashes could have been avoided if missing stack traces were detected by our technique and fixed by the developers in the first place.
we counted the number of recurring crash reports after fixes for correctly predicted stack traces in l expansion.
by examining stack traces more than recurring crash reports in our subject could have been avoided.
note that our dataset only covers crash reports over a period of two weeks.
the total number of crashes that could have been avoided can be much higher over a longer period.
as we explained in section .
our prediction accuracy may depend on the expansion level.
to observe accuracy at different expansion levels we measured precision recall and feedback with various expansion levels and .
in l expansion unexpanded original stack traces were used.
l expansion means stack traces are expanded until no more expansion is possible.
figure shows prediction accuracy at different expansion levels.
the y axis shows values of precision recall fmeasure and feedback.
the maximum value for precision and recall is .
and .
respectively.
f measure values are between .
and .
.
after expanding the stack for more than two levels the feedback ratio reaches its maximum value and does not increase any further.
precision and recall differ according to expansion levels.
precision increases from l onwards while recall continuously decreases as stacks are expanded further.
feedback value at l .
indicates that more than of crash buckets did not include any stack traces having fix locations in their original unexpanded stacks.
this result implies that stack expansion is necessary to find fix locations and predict recurring crashes.
however higher levels of stack expansion may include more irrelevant functions during the expansion.
as a result accuracy is affected as we expand the traces more.
.
.
.
.
.
.
.
.
.
l l l l l l l l l value expansion level feedback precision f measure recall figure prediction accuracy according to various stack expansion levels.
the graph shows precision recall and f measure with feedback at each expansion level.
if nsnull text set empty string instead of returning due to compatibility.. text ... char unescaped ns strdup text a bug const char deviceid mcacheentry getdeviceid if !deviceid adeviceid nsnull return ns ok adeviceid ns strdup deviceid b bug figure two fixes for the crash in figure .
both fixes check null before calling ns strdup .
the overall prediction results show that our approach is effective at predicting recurring stack traces.
it is possible to predict with either high precision or high recall based on the stack trace expansion level.
developers may apply our approach with high expansion levels first to get higher precision.
traces so predicted are more likely to recur.
after checking predicted missing traces in high expansion levels developers can reduce the expansion level to find more traces.
.
case studies this section provides case studies to address rq2 the usefulness of our approach.
figure shows two crash fixes for the crash in figure .
both fixes added code to check for the argument of ns strdup .
since their root cause is similar non null value for the ns strdup argument and the fixes are simple bug could have been fixed earlier had the developer noticed that there is a trace not covered by the first fix.
figure a shows another example.
two stack traces from a crash bucket are shown.
each circle is a function in the trace with function names on the side.
the bottom circle is the crash point.
the arrows show two different execution traces.
the crash was first fixed in .6b4 bug by changing function nsxultreeaccessible getchildat in trace a. however trace b was not covered by the fix and the crash trace recurred.
the same bug report was re opened and function nsxultreeaccessible gettreeitemaccessible was fixed and then finally the crash disappeared in .6b5.
our approach correctly predicts trace b as recurring.
figure b and figure c show the first and second fixes.
since the fixes are almost identical adding isdefunct checker the bug could have been fixed in the first place had the developer noticed that crash trace b was not covered by the first fix.
one more example is shown in figure .
in this case the fix location is not in the original stack trace.
our approach finds the fix location in the expanded trace from trace a. however we could not locate the fix in the expanded trace from trace b. firefox .
included the fix but stack trace b recurred.
the above examples show that our approach can help developers.
by knowing the existence of non covered traces developers can easily fix the missed crash traces.
.
developers feedback we presented our approach and some recurring crash prediction examples briefly and asked firefox developers for feedback about the usefulness of our approach.
we sent emails to individual developers who are related to crashes186ienumconnectionpoints remotenext thunk ienumoleundounits next stub nsaccessiblewrap next nsxultreeaccessible getchildat nsxultreeaccessible gettreeitemaccessible nsrootaccessible handleevent crash point trace a trace b first fix in .6b4 nsrootaccessible handleeventwithtarget second fix in .6b5 a two stack traces from a crash bucket ns ensure arg pointer achild achild nsnull if isdefunct return ns error failure print32 childcount b first fix545 aaccessible nsnull if arow if arow isdefunct return print32 rowcount c second fix figure two crash stack trace examples from a crash bucket.
a developer fixed this crash bug report by modifying function nsxultreeaccessible getchildat shown in trace a. the fix was included in .6b4.
however trace b appeared again in .6b4 and the developer reopened bug and fixed function nsxultreeaccessible gettreeitemaccessible .
finally the crash disappeared in .6b5.
our approach correctly predicted that trace b will reappear.
and bug reports we used in our experiments.
in addition we sent our survey to the firefox developer and mozilla static analysis mailing lists.
among responses developers said our approach is very useful said it is useful and developers requested more information to evaluate our approach.
overall developers were very interested in our approach and considered it useful.
in addition we have received promising and encouraging comments from firefox developers it should be an interesting feature and useful like any automation tool.
it should make the engineering work easier and keep users less annoyed.
we have been trying to get some stack searching techniques going for quite some time to help us analyze similar frames found across many different stacks.
definitely interested in any ideas that you have for static analysis of stacks to find additional problems.
the first patch fixed the known steps but missed the fact that other routes led to the same state inconsistency.
.
.
.
if you have a system that automates that process it would indeed be helpful.
.
discussion this section discusses the limitations of our approach and threats to validity.
nsobjectframe instantiate nsobjectframe instantiateplugin nspluginhost instantiate embeddedplugin nspluginnativewindow win callsetwindow nspluginnativewindow callsetwindow nsobjectframe callsetwindow crash point trace a trace b nsobjectloadingcontent instantiate nsobjectframe instantiate bug fix in .
figure two crash stack examples from the same crash point.
a developer fixed this crash bug report in firefox .
by modifying two functions nspluginhost getplugin and nsnpapiplugin createplugin which are not in the stacks.
in l stack expansion our approach found one of the fix locations from trace a but not from trace b and predicted it will recur.
in .
trace b actually recurred but trace a did not.
.
incorrect crash fixes our approach is based on crash fix locations assuming fixes are correct.
therefore we predict stack traces covered by fixes will disappear.
however sometimes fixes are incorrect .
we also found incorrect crash fixes in our dataset.
in fact many of our false negative cases are due to such incorrect fixes.
figure shows a stack trace with a bug fix bug as an example.
firefox crashed at line and the fix added code to check the value of bufinside function nsziparchive buildfilelist which is in the original stack trace.
our approach assumed the fix was correct and predicted the trace will disappear.
however the fix was incorrect.
firefox crashed at line again.
later the developer added more code for verifying the value of bufto finally fix this crash.
gu et al.
proposed an approach to find incorrect fixes.
from a concrete bug triggering input the approach generates more inputs that can still trigger the bug.
then they used the generated inputs to verify a fix.
we could not apply their approach directly to crash fixes because we could not obtain a crash triggering input from crs.
in fact finding a crash triggering input is challenging.
developing a comprehensive fix verification technique to identify incorrect fixes remains as our future work.
.
threats to validity we find the following threats to validity of our experiment the subject is open source software .
we use only firefox as the subject in the experiment since it is publicly available.
in addition it has a large number of crash reports and bug fixes.
unfortunately we could not find any other open source projects having a large number of publicly available crash reports.
for this reason we used only firefox as our subject.
our approach may yield different results for other software projects and their crash data.
collected crash data might be biased.
we chose sub releases of firefox .
to minimize the effect of major code changes on collection of recurring crashes due187nsziparchive buildfilelist crash point nsziparchive openarchive nsjar open nszipreadercache getzip nsjarinputthunk ensurejarstream a a crash trace read the central directory headers buf startp centraloffset if endp buf sizeof pruint32 return ns error file corrupted pruint32 sig xtolong buf crash point while sig centralsig b bug figure a developer added code to check the value of bufbefore using it.
since the fix was in function nsziparchive buildfilelist we predicted this trace will disappear.
however the fix was incorrect and the same trace recurred.
later the developer added more code to check buf.
to incomplete fixes.
in addition we collected crash reports of sub releases over a two week period due to an overwhelmingly large number of crash reports.
our recurring trace prediction may be more less accurate when the approach is applied to different sub releases or crash reports collected over different periods.
oracle data set is incomplete.
the actual recurred stack traces serve as the oracle to evaluate our prediction results.
there is a large possibility of the oracle being incomplete.
for example some crashes may not have manifested in the period we collected crash data.
it is also possible that users did not send crash reports.
when more crash reports are used to evaluate our prediction the prediction results could be different.
.
related work we briefly review related work in this section.
.
managing crashes after crss were deployed many researchers proposed techniques to analyze crash reports.
one research area is about failure clustering or bucketing.
glerum et al.
presented ten years of debugging experience using windows error reporting system wer including new bucketing algorithms.
wer uses more than heuristics to put similar crash reports into the same bucket.
podgurski et al.
introduced a technique applying feature selection clustering and multi variate visualization to group failures triggered by similar causes.
brodie et al.
and modani et al.
treated stack traces as strings and applied several string matching techniques to identify similar stack traces.
bartz et al.
proposed a machine learning technique to identify similar stack traces by identifying key similarity features.
for example the call stack edit distance is a key feature in their approach.
dang et al.
introduced the rebucket technique to cluster duplicated crash reports.
rebucket measures the similarity between two call stacks based on the number of functions on two call stacks the distance of thosefunctions from the top frame and the offset distance between the matched functions.
these approaches focus on finding similar traces.
our approach is different in that we focus on finding non covered stack traces from already grouped similar traces.
another area concerns about how to fix the reported crashes.
manevich et al.
proposed the pse postmortem symbolic evaluation technique to diagnose software failure.
they adopted dataflow and alias analysis to track the flow of a single value from the failure point back to the points where the value may have originated.
kim et al.
introduced crash graphs combining multiple crash traces together to provide aggregate view of crashes.
liblit et al.
introduced a technique to reconstruct the execution path from a crash in several environments.
artzi et al.
introduced the recrash technique to reproduce software failure.
instead of using crash reports recrash stores partial copies of method arguments in memory to reproduce the crash.
recently kim et al.
introduced a technique to predict top crashes early.
they extracted features of top crashes by a machine learner and predicted if a crash will be a top crash when only a small number of crash reports are submitted.
all these techniques are applied before crashes are fixed to help developers.
however our approach checks if the fixes are incomplete and predicts crash traces not covered by the fixes.
.
bug fix verification gu et al.
tried to identify incorrect fixes.
they generated test cases from distance bounded weakest precondition and used generated inputs to verify the fixes.
similarly recent test case generation techniques using dynamic symbolic execution can be used to verify bug fixes.
snugglebug also computes weakest precondition .
starting from the bug location with a given buggy condition snugglebug traces back the program path to the entry point of the program and calculates the weakest precondition.
if the acquired precondition can not be satisfied it is verified that the buggy condition can not happen and the bug is fixed.
our work also verifies bug fixes.
especially it can find incomplete fixes in terms of fix locations.
yin et al.
investigated incorrect bug fixes from large operating system code bases.
they found at least .
.
of sampled fixes for post release bugs incorrect.
among several bug types concurrency bugs were the most difficult to fix.
our work investigated crash bug fixes in firefox and found of crashes were recurring after bug fixes.
.
conclusions we found of fixed crashes in firefox were recurring.
with the overwhelming number of crash reports it is challenging to identify missed crash traces manually.
we proposed an approach to automatically predict recurring crashes by comparing stack traces with crash fix locations.
our experimental evaluation on actual firefox .
crashes showed that our approach yielded reasonable prediction accuracy .
precision and .
recall.
we believe that developers can use recurring crash prediction information to check if their crash fix covers all the reported crash traces.
had our approach been deployed earlier more than recurring firefox .
crashes could have been avoided.
feedback from firefox developers involved in crash fixes shows our approach is useful.188we plan to improve our approach by removing irrelevant functions included in the stack trace expansion phase to achieve better accuracy.
in addition reducing false negatives of our approach by identifying incorrect fixes remains as future work.
.