distilling privacy requirements for mobile applications keerthi thomas1 arosha k. bandara1 blaine a. price1 bashar nuseibeh1 centre for research in computing the open university milton keynes uk lero university of limerick ireland keerthi.
thomas arosha.bandara blaine.price bashar.nuseibeh open.ac.uk abstract as mobile computing applications have become commonplace it is increasingly important for them to address end users privacy requirements.
privacy requirements depend on a nu mber of contextual socio cultural factors to which mobility adds another level of contextual variation.
however traditional requirements elicitation methods do not sufficiently account for contextual factors and therefore cannot be used effectively to rep resent and analyse the privacy requirements of mobile end users.
on the other hand methods that do investigate contextual factors tend to produce data that does not lend itself to the process of requirements extraction.
to address this problem we have developed a privacy requirements distillation approach that employs a problem analysis framework to extract and refine privacy requirements for mobile applications from raw data gathered through empirical studies involving end users .
our approach introduces p rivacy facets that capture patterns of privacy concerns which are matched against the raw data.
we demonstrate and evaluate our approach using qualitative data from an empirical study of a mobile social networking application .
categories and subject descr iptors d. .
methodologies h1.
human factors .
general terms design security human factors.
keywords privacy mobile requirements engineering .
introduction the age of ubiquitous computing particu larly the rapid increase in the use of smart phones has created a mass market for software applications that are being used in every context of users dai ly lives.
previous research has highlighted how system designers policy makers and organisations can easily become isolated from end users perceptions of privacy in different contexts.
for mobile applications end users context changes frequently and unpredictably and observations of such users suggest that changes in context result in changes in users privacy requirements.
omitting these privacy requirements can affect users privacy and consequently may have an impact on how well a system is adopted or utilised .
while knowledge acq uisition techniques such as the use of personas have proven successful at dealing with the challenges of gathering and analysing the requirements of a large user base the highly dynamic and hard to predict usage scenarios associated with mobile applications still pose a challenge for existing requirements engineering approaches.
this is particularly true for privacy requirements which are known to be highly context dependent and are only likely to arise as users gain experience wi th an application .
this makes eliciting end user privacy requirements for mobile applications both sensitive and difficult.
questionnaires do not elicit rich enough information about users decisions and how these are influenced by the emerging context in a particular situat ion.
to overcome such limitations goguen and linde propose d the use of ethnographic analysis techniques such as conversation discourse and interaction analyses to obtain tacit knowledge of what users actually do in different work situations.
they also show ed how the discourse analysis of users stories can be used to explore the value systems of organisations and how the disco urse analysis of users explanations can be use d for situated task analysis .
while rubenstein and beyer and holzblatt have shown that shadowing of users is useful for capturing contextual requirements to design and build new systems when it comes to privacy this direct approach is problematic since the experience of being under constant observation is likely to change the behaviour of the users in ways tha t invalidate any observed behaviours with respect to privacy.
this prior work suggests that for mobile applications privacy requirements are emergent requirements that need to be elicited and analysed from qualitative reports of the users experience of the application.
while there have been ethnographic studies conducted by the hci community to study end user privacy including our own user studies user experience data from such studies do es not readily translate into requirements.
often this qualitative data in the form of interview transcripts or user written reports may contain pri vacy requirements that are embedded and tightly entwined with user s contextual experiences.
the technical challenge in extract ing these requirements systematically from the qualitative data relate to a structur ing and separat ing privacy relevant inform ation from the qualitative data b identify ing and extract ing mobile privacy requirements from this data and c modelling and represent ing the extracted mobile privacy requirements .
since privacy is a broad topic we focus on personal privacy which refers to how people manage their privacy with respect to other individuals as opposed to large organisations .
this paper makes two contribution s first a novel framework is proposed for structuring problem analysis called privacy facets .
the framework supports the identification of privacy requirements from different contextual perspectives namely those of actors information information flows and places.
it also uncovers privacy determinants and threats that a system mus t take into permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for p rofit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee .
icse may june hyderabad india copyright acm ... .
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may june hyderabad india copyright acm ... .
account in order to support the end user s privacy.
the second contribution is a technique called requirements distillation a systematic method for qualitative data analysis that employs analysis models and patterns to extract and refine emer gent software requirements such as those relating to privacy for mobile applications .
distillation is a synthesis of thematic an alysis from social sciences and problem frames from softwar e engineering.
p rivacy requirements do not exist in a vacuum rather they refer to other information requirements.
therefore our approach to distilling privacy requirements makes the related information requirements manifest through the use of information problem patterns.
distillation makes use of both information problem patterns and privacy facets to derive privacy requirements.
for the purpose of evaluation we choose a pragmati c approach because it is more aligned t o our objective of engineer ing practical solutions to real world problems.
since distillation borrows techniques from both social sciences and software engineering its evaluation is a mix of qualitative research methods and case study design .
specifically distillation is assessed for qualities such as a employing a transparent and systematic process b providing traceability by linking outputs to qualitative data and c demonstrating applicability or usefulness of results by informing system design.
in we discuss some of the related research relevant to privacy requirements for mobile applications.
describe s the overall process of requirements distillation and present s our privacy facets prif framework which we use to enabl e a structured analysis of the privacy problems experienced by users.
in we describe a case study of mobile facebook application and in we discuss the results and limitations of the distillation process.
presents the available tool support.
finall y concludes with ideas for future work .
.
related work privacy management is a fine balancing act between what information is monitored and the protections that are available against its search.
as an enabler of both monitoring and searching the archit ecture of mobile technology plays a key role in privacy .
in particular mobile application architectures incorporate numerous sensors gps camera accelerometer etc.
that enable monitoring together with ubiquitous netwo rk connectivity that enable continuous search and disclosure of monitored information.
further the large screen displays of modern mobile devices facilitate proximal disclosures in public places .
this leads us to view privacy as a constraint on the capabi lities of the mobile application and we adapt the concept of privacy described in nissenbaum s contextual integrity framework to define mobile privacy requirements as a set of constraints on a mobile computing applicatio n that enables appropriate flow of information depending on the user s context.
here the flow of information is the information sharing practices relevant to a user s context and norms that regulate it contribute to its appropriateness from end users perspective .
while there has been significant work to understand privacy requirements based on laws and regulations e.g.
health care information regulations hipaa and oecd guidelines organisation privacy policy this research does not specifically address privacy violations experienced by mobile users .
one of the ways to capture behaviou r requirements for a software system is through the use of use cases.
seyff et al.
developed a software environment called art scene later extended to mobile applications to discover and document stakeholder requirements by walking through scenarios that are automatically generated from use case specifications.
however this approach is unlikely to work for studying mobile privacy because it is not practical to ask users to type their privacy requirements into a mobile d evice as they may be in transit or have limited input capabilities .
sutcliffe et al proposed a requirements elicitat ion framework called pc re to describe functions that meet people s goals characteristics of the users and how users would like computer systems to achieve their personal goals .
however this work does not focus on privacy goals of end users.
the pris method uses eight categories of security and privacy principles to deriv e privacy requirements but these high level principles are organisation centric and do not cover fine grain ed personal privacy threats end users face.
in a similar approach deng et al.
have produced a threat taxonomy obta ined by negating the main security properties.
in their top down linduun approach it may be difficult to a priori identify all potential privacy threats that are applicable to a software system.
in semantic parameterization privacy requirements were extracted from legal documents to produce a set of privacy requirements however these requirements are organisation centric and do not specifically focus on personal privacy .
some propose the modelling of users negative inte nt and behaviour as misuse cases others have used these t o elicit security requirements and privacy requir ements for mobile applications .
although thes e approaches can potentially highlight deficiencies in a software system it is difficult to anticipate all possible misuses of a mobile software system.
a number of researchers have investigated the uses of different types of qualitative data for requirem ents elicitation and design of mobile applications .
for example the user centred contextual design method gathered a variety of data to develop a mobile application for baseball fans .
however eliciting mobile privacy usi ng this method will be problematic because shadowing of mobile end users causes them to change their behaviour thus invalidating any requirements that were observed.
in addition to this privacy is a sensitive issue and often user s are not be able articul ate their choices and decisions in an emerging context .
a number of other studies have used an enthnomethodological approach to elicit privacy requireme nts for mobile applications.
although these studies provided rich datasets that contained mobile privacy requirements they did not provide mechanisms to structure and represent them such that they could be understood and implemented by software engineers and designers .
the privacy requirements distillation technique described in this paper addresses this problem.
.
distillation process as already discussed mobile privacy has been studied by ethnomethodologists with the specific aim of producing new theories and high level design guidelines .
however not all of these theories and guidelines have translated into concrete system requirements or design artefacts.
the primary aim of distillation is to not only equip and assist software engineers with analytical tools and techniques but also provide process guidance on the extraction of privacy requirements from qualitative data which can be used in the design of privacy aware software systems.
figure .
privacy requirements distillation process as a starting point the distillation process relies on a software system that implements the initial requirements.
this is the same software system for which qualitative data has been gathered and its user experiences are captured in the intervie w transcripts.
the qualitative data and the initial systems requirements of the mobile application being studied form the two inputs to the distillation process fig ure .
the distillation process consists of three main phases namely structuring of qualitative data information flow modelling and privacy problem analysis.
using an inductive approach inspired by thematic analysis from social sciences in the first phase the qualitative data is structured using the privacy facets prif fram ework which provides pre defined codes tailored for the identification of privacy sensitive contexts .
once the privacy sensitive contexts are isolated additional codes from each facet of the prif framework help in identifying the relevant privacy determi nants and deriving the relevant privacy threats and concerns .
the output of this phase is a set of privacy concerns experienced by users of the mobile application.
in the second phase using initial systems requirements problem models of information flows are developed based on the information flow problem patterns provided in the prif framework.
these problem models not only capture how the information is created but also how it is disseminated to other users.
the privacy problem analysis phase is the thi rd phase where the privacy sensitive context along with its privacy threats and concerns is analysed in conjunction with the information flow problem models to identify the gaps in the current system leading to the discovery of privacy requirements.
the d istillation approach is designed to be a sequential process where the structuring of qualitative data precedes information flow modelling and privacy problem analysis .
in order to demonstrate our approach we use data gathered from an empirical study of us ers of the mobile facebook application1 conducted in .
although data from this study was analysed from an hci perspective it hadn t been previously analysed specifically for the purpose of requirements extraction as done in this paper.
in this study users were electronically shadowed in an unobtrusive manner and their responses to privacy issues were captured through an in depth post hoc interview.
while the data we have analysed covers a range of functionality suppo rted by the application due to space limitations in this paper concentrate on the participants use of the update status message feature .
table .
example data from mobile facebook study if i am out with friends i don t take my phone out i don t do facebook ...yes ok if i am with my sister i keep to read emails but no i don t use facebook and i tend not to use the mobile...because i am busy with other stuff talking with them socialising...facebook tends to fill the gaps...if i a m with a person i concentrate with that person.
...things like buses and trains i don t feel so comfortable... because i don t know...lots of people i don t know...if they for example read some of the posts i have done...they don t know the peop le that they are aimed at or the back story...they d probably come across quite differently and they would not understand them it would look a little weird.. the wrong sort of almost the wrong first impression.
anything i feel is private to myself i keep it to myself.
i have a lot of good friends so if i want to share it i am happy to share it with all my friends.
if there was something private that is more close to me like a girl that i liked and i wanted to share it with a fri end i would do that in person rather than on facebook in the subsequent sections we will demonstrate how the above data can be analysed using the requirements distillation method in order to derive privacy requirements for the mobile facebook applicatio n. .
privacy facets framework the main challenge of analysing qualitative data to derive privacy requirements is that the requirements will have to be systematically extracted from things that are not relevant but are tightly entwined with the users experie nce for example the noise emanating from the operating context .
to address this challenge we propose a novel analytical framework called privacy facets prif whose objectives are to provide a analytical tools such as thematic codes heuristics fa cet questions and extraction rules to structure qualitative data and b information flow problem patterns and privacy arguments language to model privacy requirements .
.
privacy sensitive context s thematic analysis is a method for identifying analysing a nd reporting patterns or themes within qualitative data .
a theme is said to capture something important about the data or having meaning within the dataset.
when t hemes emerge within the mobile facebook app has significantly changed since .
873the data they are encoded using appr opriate codes or labels in a process called coding or thematic coding .
similarly distillation employs coding and makes use of specialised codes provided by the prif framework to str ucture privacy related segments within the qualitative data.
qualitative data may contain not only the users experience but also their social interactions with other mobile users and actors in environment that may or may not be relevant to privacy.
theref ore the challenge of structuring this data would relate to isolating those aspects that are relevant to the extracti on of privacy requirements.
for this the prif framework provides a set of user centric heuristics called negative behaviour patterns nbps and negative emotional indicators neis to identify situations or settings involving privacy threats .
we refer to the segments of qualitative data identified using these heuristics as a privacy sensitive context or ps context .
this notion is adaption of context from where it is stated as any information that can be used to characterise the situation of entities i.e.
whether a person place or object that are considered relevant to the interaction between a user and an application including the user and the application themselves .
therefore ps context refers to the location identity and state of people groups and computational and physical objects that affect end users privacy.
nbps are used to identify situatio ns where users choose to not use or ignore an application due to privacy concerns e.g.
switching off all location services on their mobile device or situations where the user completes a task that is supported by the application by some alternative m eans e.g.
communicating their location through a voice phone call rather than a location based social network .
this is based on the approach waving the red flag and looking for the negative case used by .
neis are a set of key words that indicate the negative emotional state of the user in response to an event or action in the environment.
for example some of the key words are concerned unhappy worried scared dislike etc.
and include synonyms and semantically eq uivalent phrases .
the presence of these neis in the qualitative data can indicate the presence of a privacy threat or concern.
this is an adaptation of looking at emotions that are expressed and the situations that aroused them used by .
considering the example data from the mobile facebook study table i excerpt would be coded as a nbp based on the phrase i don t take my phone out i don t do facebook .
likewise excerpt which includes an indication of a workaround i would do that in person rather than on facebook .
excerpt on the other hand includes i don t feel so comfortable indicating that is should be coded as a nei.
.
facet questions and privacy determinants after extracting a ps context from the data the social aspects of the user s interaction have to be understood for example the actors involved their roles and relationships with the user and the type of interactions that take place between them.
to this end the prif framewor k proposes the use of facets a notion very similar to that of viewpoints where each facet is considered to hold partial domain knowledge of the system.
since the knowledge is very specific to privacy the facets are ca lled privacy facets each having unique properties and functions that must be analysed and addressed separately while at the same time be considered together to ensure completeness and consistency.
there are four privacy facets namely information informa tion flow actor and place .
each facet can be used to gather specific domain knowledge that affect s the privacy of mobile application user s. the information facet elicits knowledge regarding what information is created by the software system while the act or facet focuses on who the information is transmitted to the information flow facet identifies why the information was transmitted and the place facet captures where the information was created or transmitted.
in the remainder of this section we describ e the questions privacy determinants and threats associated with each facet.
for each privacy determinant we also indicate the code used to annotate the qualitative data e.g.
.
information facet software systems produce data either by themselves e.g.
log transactions or when the users interact with their functionality e.g.
take a digital photo .
in order to be clear about how we relate data to information we adopt tenopir s definitio n of data and information in which states data are facts that are the result of observation or measurement and information is meaningful data or data arranged or interpreted in a way to provide meaning.
when considering the privacy of information we identify four questions that can be used to elicit the key privacy determinants relevant to this facet is the information personal or sensitive?
personal information relates to a living individual who can be identified from that information.
sensitive information refers to information pertaining to an individual that can be used to characterise them in some way e.g.
religion ethnicity sexual orientation etc.
.
code i type personal sensitive is the information collected automatically by computer automation or manually input by end users ?
these two modes of information creation impact the types of privacy threats that can be discovered in the software system.
for example if the software system sampled certain information at a high frequency it can cause a surveillance effect.
code what is the purpose of the information or its context of use?
knowing for what purpose the information is being collected is important as it will help in later checking if the purpose was fulfilled or i f it was used in a way detrimental to a user s privacy.
code what are the information attributes?
quality attributes can influence how the information is used within the system and perceived by its users.
for example some quality attribute s could relate to accuracy precision of data completeness all required data fields are filled freshness data is not expired and has become irrelavent timeliness data received at expected time frame i.e.
within accepted latency etc.
code i attr accurate complete fresh ontime actors facet the actors facet pertains to the roles that a user can play in a given context and their relationships with other users.
in the context of a software system the roles of actors has a significant impa ct on the information flows thus understanding the roles of the actors sender subject and receiver their relationships and responsibilities are critical to protecting privacy .
for example in a hospital context the readings of patient s body temper ature may be required by physician s to treat a health 874problem .
the roles of both the patient and the physician with their roles relationship and responsibilities should be understood and clearly defined.
privacy violations occur when these are ambiguous .
we identify the following questions for eliciting the key privacy determinants relating to the actors facet what are the role relationships between the information sender receiver and subject?
a role is the abstract characteri sation of the behavio ur of an active entity or agent within some context .
a relationship refers the relations between agents and corresponds to the social aspect of a role .
toge ther they determine the level of trust which influences the sharing of sensitive information.
code what are the responsibilities associated with each role?
responsibility is when one agent is responsible to another agent for someth ing and that this something can be described as a possible mismatch or non conformance relation between an actual state of affairs and a desired expected or feasible state of affairs adapted from p. .
responsibilities can affect the power relationships between actors which in turn influences the information flows in a given context.
code information flow facet in order to understand the privacy requirements all possible flows of information between the interacting users must be examined.
each o f these information flows are governed by what nissenbaum calls transmission principles informally established terms and conditions that guide the flow of information between different actors .
in other words transmissio n principles are constraints placed on the flow of information and breaching these constraints leads to a privacy violation .
the following questions can be used to help elicit the key privacy determinants associated with th is facet what goals and purpos es hold for information about a subject flowing between the sender and receiver?
these transmission principles determine the privacy expectations of the subject for example if the subject needs to consent before the information is sent.
code what goals and purposes hold for information flows between the sender and receiver?
these transmission principles determine the privacy expectations of the sender and receiver for example the sender would expect only certain receivers and not others.
code are there any 3rd party recipients of the information?
this determines the flow of information to 3rd parties who can misuse the information.
code place facet the place refers to a unique geog raphic location with a material form meaning and value .
when mobile users move through different places they interact with the objects that are present.
lessig points out that the archit ecture at a given place influences privacy in other words the way in which the physical objects such as human agents and technologies are arranged in a place can have a direct impact on users privacy this was also shown by user studies from mancini et al.
.
places can have their own set of rules or norms regulating social behaviours and interactions within them.
users are subjected to these rules which may protect the privacy of others .
the questions to be used to elici t the privacy determinants associated with the place facet are as follows what are the places associated with the subject sender and receiver?
used to identify the places that can be associated with a privacy sensitive context for the different actor s. code what norms apply to a place?
used to identify the expected behaviours associated with a given place .
deviations from the expected behaviour can result in privacy threats being realised.
code by asking the above questions of the example data from the mobile facebook study we can apply the relevant codes for identifying the privacy concerns experienced by the user .
the resulting coding is shown in table where for each example statement we have used di fferent formatting to highlight the elements of the text that identify a ps context as well as the applicable privacy facets .
for instance in statement a privacy related context associated with a negative behaviour pattern nbp is identified due to the user saying i would do that in person rather than on facebook .
additionally data elements relating to the information facet are identified in those portions of statement containing the text private and like a girl that i liked indicating that there is sensitive information being described in th is context.
table .
structured data from mobile facebook study if i am out with friends i don t take my phone out i don t do facebook ...yes ok if i am with my sister i keep to read emai ls but no i don t use facebook and i tend not to use the mobile ...because i am busy with other stuff talking with them socialising...facebook tends to fill the gaps...if i am with a person i concentrate with that person.
... things like buses and trains i don t feel so comfortable ... because i don t know...lots of people i don t know...if they for example read some of the posts i have done...they don t know the people that they are aimed at or the back story...they d probably come across quite differently and they would not understand them it would look a little weird.. the wrong sort of almost the wrong first impression.
nei place location anything i feel is private to myself i keep it to myself .
i have a lot of good friends so if i want to share it i am happy to share it with all my friends .
if there was something private that is more close to me like a girl that i liked and i wanted to share it with a friend i would do that in person rather t han on facebook.
nbp i type sensitive role relationship flow sender receiver key to coded text privacy sensitive context information facet actor facet information flow facet place facet in the next section we demonstrate how these codes can be used in the formulation of extraction rules for retrieving the qualitative data associated with different privacy threats .
the data associated with each threat can then be used to identify gaps between the current software system and the users expe ctation leading to the discovery of privacy requirements.
.
privacy threats and concerns parameters that influence privacy within a facet are likely to contribute to privacy threats these are privacy violations that are likely to happen.
when privacy threa ts are analysed in conjunction with the existing software system its failings can be captured as privacy concerns which will have to be addressed in in a future version of the system.
the prif framework lists the possible threats and concerns that can be identified from the qualitative data.
as mentioned earlier we define mobile privacy requirements as a set of constraints on a mobile computing application that enables appropriate flow of information depending on the user s context.
this notion of privac y is particularly suited for mobile applications because it takes context into consideration.
using the definitions used by nissenbaum s contextual integrity framework information flow is described as a user sender tran smitting information or information attributes about a subject to a user receiver while complying with a specific set of transmission principles .
for simplicity in this paper we consider examples where the sender and subject are the same individual but this need not always be the case .
in general transmission principles refer to the goals and purposes that govern the flow of information encompassing the means and ends for which the information is being transmitted.
madsen et al.
discuss several types of information flows in a software system that are relevant to addressing privacy but this work concentrates only on those that are critical to addressing privacy in mobile applications which support peer to peer use r interactions e.g.
mobile social networking applications .
the majority of these applications are designed to make use of an intermediate application service provider s to facilitate information sharing among its users.
figure .
information flows handled by the prif framework figure shows a generic architecture containing three information flows information is created and sent to a service provider f1 stored information is requested and is sent to a receiver f2 and i nformation sent to unintended receivers by either the service provider or the receiver f3 .
the unintended receivers can also refer to actors who are co located and in close proximity to the sender or receiver and is able to access the information without making a request to the software system.
a privacy violation is said to occur when an information flow causes harm to the user because of its faulty composition or because it is inappropriate.
the components in an information table .
privacy threats associated harms and data extraction rules id privacy threat faulty information flows example harms data extraction rule t1 identificatio n subject s personal information is revealed.
identity theft h1 financial loss h2 i type personal and t2 exposure personal sensitive information received by unintended recipients discrimination h5 loss of anonymity h7 relationship b reakdown h8 embarrassment h9 physical danger h10 i type senstive and t3 surveillance receiver makes frequent requests for information about the subject.
emotional harm h4 loss of freedom h6 physical danger h10 i mode auto and t4 aggregation receiver combines datasets to produce a new type of information without the subject s consent.
discrimination h5 i purpose and t5 misinformation inaccurate or insufficient level of information about the subjec t is transmitted.
loss of reputation h3 emotional harm h4 discrimination h5 i attr and t6 breach of trust receiver forwards the information to others contravening the subject s terms and conditions.
loss of reputation h3 emotional harm h4 role relationship and t7 power imbalance receiver uses information to control the subject.
loss of freedom h6 relationship breakdown h8 role responsibility and t8 cross contextual information flow information from one context may be used in another context loss of reputation h3 discrimination h5 flow and t9 proximal access unintended receivers can access information due to close physical proximity to the sender or receiver.
loss of reputati on h3 loss of freedom h6 loss of anonymity h7 embarrassment h9 place location and t10 intrusion information flow disturbs receiver s tranquility.
emotional harm h4 loss of freedom h6 place norm and 876flow that influence privacy are called privacy determinants e.g.
sensitivity of information or role of the receiver .
privacy threats map information flows in a software system to the harms a user can suffer and privacy threats when realised cause privacy violations.
privacy concer ns describe the gap between the requirements model or its implementation and the identified privacy threats.
privacy requirements address these privacy concerns by providing suitable feedback and control facilities such that the user has better control o ver the information flows which are linked with specific privacy threats .
the privacy taxonomy proposed by solove has sixteen types of privacy violations that are broadly applicable to software systems however they do n ot necessarily focus on privacy violations that are possible when using mobile applications.
one of our previous empirical studies involving mobile users identified privacy violations related to the use of mobile applicati ons.
combining both these contributions we refine and present the privacy threats applicable for mobile software systems together with the potential harm associated with each threat .
this taxonomy of privacy threats and harms that we have deve loped links the privacy threats that can arise due an inappropriate information flow to the potential harm that can result to the end user .
for example a mobile application that allows sensitive information to flow to an unintended recipient will create a n exposure threat t2 that might result in discrimination h5 loss of anonymity h7 relationship breakdown h8 embarrassment h9 or physical danger h10 to the end user.
table also shows the data extraction rule associated with each threat whic h can be used to retrieve the qualitative data that matches the combination of codes given in each rule .
for instance executing the extraction rule for the exposure threat t2 will return the excerpt from table which is coded with both i typ e senstive and nbp.
this indicates that the mobile facebook application causes the user to report a negative behaviour when sensitive data is associated with a data flow.
this privacy threat arises because the application is unable to detect the informati on type or limit its flow to a subset of the user s friends .
.
information flow problem patterns since privacy requirements are related to information flows in a software system these must be modelled as part of the requirements distillation process .
the prif framework uses information flow problem patterns for this purpose.
the first part of the information flow relates to how information is created.
the prif framework captures this aspect as an information creation problem pattern while the second aspect i s captured as an information dissemination problem pattern both of which are based on the problem frames method .
we have chosen problem frames for our analytical framework because it supports a notion of context where real world domains i.e.
physical domains are explicitly modelled which are critical to understanding privacy in mobile applications .
information flow in its simplest form consists of a sender receiver and the information that is transmitted between them.
as privacy relates to flow of personal sensitive information the subject of the information should also be considered.
in addition information flows have goals and purpose s to achieve which play an important role in the flow of personal information from the sender to the receiver .
putting all these together we define a privacy problem in an information system as that of building a machine that will allow appropriate flow of personal information and or avoid inappropriat e flow of personal information i.e.
avoid privacy violations where the appropriate or inappropriate flow of personal information is a function of the information type roles of actors and transmission principle .
a composite model of the information flow problem frame for the status update feature of the mobile facebook application is shown in figure .
it is composed of two smaller sub problems information creation ic problem and information dissemination id problem.
in the information creation p roblem the mobile phone acts as connection domain between the user and the machine.
in the problem frame diagram figure the user is a biddable domain representing the human operator.
to create the status message the user issues a create command creat e sm at interface a which is executed by the machine sending equivalent commands to the model domain status message where it is stored.
the user issues commands update sm and delete sm respectively to perform further updates and deletions to the statu s messages.
in the second part of the problem the emphasis is on how the information reaches the recipients therefore modelling of information dissemination deals with the viewing or receiving of the information.
normally users are able to view informat ion when they make queries to the software system however the mobile facebook application is designed to display a user s status message to their friends as soon as the application is launched .
therefore the friends of the user are able to view the stat us message when they log into the software system because the system automatically makes a request the command request sm at interface g and the message answering machine responds to the query by reading the information from the model domain status messa ge at interface e and updates the mobile display accordingly.
with the basic information flows of the update status feature modelled we can now analyse the control variant of this information flow model where the emphasis is on the controlling of inform ation and the rules that govern its dissemination .
figure .
information flow problem frame for status update figure .
control variant problem frame for status update therefore in the control va riant problem frame figure the central feature is a privacy rules model domain which contains rules for information creation and editing and also rules for answering queries for information.
the message creating controller checks the privacy rules t o determine if the user is allowed to issue the commands to create modify delete or forward status messages.
similarly when the friends make request for the status message the message answering controller checks the privacy rules to determine if the request should be answered or not setting the mobile screen display accordingly.
while the above problem frames modelled the information flow within the software system its control variants help in constraining how the information is created and disseminat ed thus addressing privacy.
out of the five basic problem frames found in the problem frames method the information creation problem is a modification of the basic workpiece problem frame while the information disseminat ion is fitted to an operator variant of an information problem frame.
in the problem frames method each problem has a frame concern which highlights a certain aspect of the problem demanding the attention of the analyst developer.
similarly in the prif framework the privacy concern is simply a special type of frame concern relating to privacy which the analyst must take into account and address in the software system to make it privacy aware.
therefore the privacy concerns extracted from the qualitati ve data through the use of facets should be addressed in order to support the privacy of end users.
.
privacy arguments in previous work we developed a notation for mobile application privacy requirements called privacy arguments that could be used to reas on about privacy requirements be integrated into a mobile application to enable users to fine tune the requirements at run time and provide run time diagnostics about the satisfaction of privacy requirements .
however th ere was no process to support the formulation of privacy argument classes .
we have integrated privacy arguments into the prif f ramework extending it to link the requirements derived through the distillation process to the original qualitative data.
from a developer s perspective a privacy argument justifies to an audience such as users of mobile applications that the user s privacy claim has been respected by the software system .
the general structure of privacy arguments is warrant ground claim .
privacy requirements described as the claim of an argument that needs to be justified.
the ground is the collection of facts that can be observed from the world domains which supports the claim.
the warrant is the collection of domain specific rules that links the ground to the claim of the argument .
the developer can formulate privacy arguments as argument classes which are instantiated by the user with specific parameter values that are appropriate to their particular context.
.
case study m obile facebook in section .
we explained how the qualitative data was used to highlight a privacy concern relating to the threat of sensitive data being exposed.
this concern arose because the software system is unable to distinguish between sensitive a nd non sensitive information resulting in sensitive information being visible to all friends.
using the ps context that was extracted to derive this concern we can express this as shown in listing .
here the argument class mfb closefriends norm captures the user s intended behaviour as described by the qualitative data whereas the argument mfb exposure concern specifies the behaviour of the system that causes the user to exhibit a negative behaviour pattern.
to address this concern we could bui ld a machine that would automatically check if the information is sensitive or not otherwise the machine could prompt to the user to make the decision .
by being able to determine information sensitivity the software system will be able to ensure that se nsitive information is not visible to any unintended recipients e.g.
in this case if the user selects a group of friends recipients who should not be viewing the sensitive information then the software system can immediately alert the user of the poten tial threat .
in this way we can mitigate the effect of exposure where sensitive information cannot be leaked to a wider unintended audience.
listing .
privacy norm and exposure concern argument argument mfb closefriends norm pn1 user can only share status messages with close friends supported by f1 user has close friends f2 user creates sensitive msg f3 user wants sensitive msg to be seen by close friends only f4 close friends want to see sensitive msg warranted by r1 user inputs sensitive msg r2 when a close friend taps the fb icon on his mobile device the application opens with sensitive msg displayed argument mfb exposure concern pc2 status messages are considered as non sensitive by the system rebuts pn1 supported by f6 user is unable to classify a status message as being sensitiv e or nonsensitive f7 the system is unab le to differentiate between sensitive and non sensitive status message 878in order to mitigate the expos ure concern the requirement for checking of information sensitivity is captured in the following argument construct listing .
listing .
privacy argument to check information sensitivity detecting the creation of informatio n sensitivity is just one part the other part relates to information receivers.
from the problem context it is evident that the user wished to share sensitive status messages only with close friends but the software system did not facilitate the creation of such groups.
therefore the next privacy requirement is about allowing the user to create a recipient group called close friends listing .
listing .
privacy argument to create close friend group on its own the privacy requirements pr1 and pr2 may not be sufficient to mitigate privacy concern pc2 because it does not take into consideration the recipients who will receive the sensitive information.
another requirement regarding query answering must be defined such that only those who are members of the close friends group may be allowed to see status messages marked as being sensitive.
this is done by an additional requirement in pr3 as shown in listing .
listing .
privacy argume nt for information dissemination we use the depends on clause to indicate that pr3 has a dependency on other requirements such as pr1 the system s ability to determine if the status message was sensitive or not and pr2 the user s ability to create a gr oup list of close friends.
as shown a privacy requirement can mitigate one or more privacy concerns and similarly a privacy concern can rebut one or more information flow norms in a software system .
this third phase of distillation showed the derivation of privacy requirements for mobile applications in the form of privacy arguments for a single privacy concern associated with the threat of exposure t2 .
a similar analysis process can be carried out to yield requirements relating to other concerns derived from the qualitative data.
.
discussion distillation not only follows a systematic approach but also its output in the form of privacy arguments can be traced back to its source in the qualitative data.
further the information flow problem models with their associated privacy arguments aimed to address the gaps in the software system studied and therefore protect the privacy of end users.
however in this section we discuss some of the factors that influence t he validity and limitations of our approach.
the first limitation of our approach is scalability.
distillation uses a number of different analysis techniques.
for example in order to apply privacy requirements distillation software engineers need to be familiar with qualitative data analysis techn iques which is not the norm .
whilst acquiring the necessary data coding skills is not difficult it takes practice to get it right with the analysts level of expertise influencing the quality of output.
this can be managed through the use of software too ls and templates which can reduce the complexity and improve the outcome of the analysis .
one way to encourage the use of distillation would be to provide software tools to assist the analyst.
in the next section we describe some of the tooling options we have explored in order to support the distillation process .
the second factor relates to reliability.
similar to other inductive approaches thematic coding in the distillation approach is subjective and depends on the software engineer s interpretation of raw data.
this implies that identification of ps contexts privacy threats and concerns can be biased.
inductive approaches prescribe the use of an assessment process where an initial coder produces a set of codes and additional analysts may be asked to apply these codes to the same raw data.
the variations between the initial coder and subsequent ones are statistically measured to prove the reliability of codes a similar assessment needs to be carried out on distillation although i t may not be difficult to train a group of software engineers to use our approach to overcome any initial inter coder disagreements software engineers can be encouraged to discuss and agree with each other s interpretations of the raw data similar to code cross checking .
while we acknowledge such inter coder assessments can improve the confidence and reliability of our approach this is considered to be future work.
the thir d factor relates to distillation s generalisability.
the qualitative data from the mobile facebook study had two dimensions namely a mobility of users b personal privacy .
although distillation and more specifically the prif framework had been designed to analyse these two dimensions we believe the approach can cover scenarios where the dimension of mobility is not included in the input for example qualitative data from studies involving facebook users with no reference to their mobility.
in such cas es the place facet in the prif framework may not be fully utilised .
but for the approach to be successful the underlying privacy norms that produce negative behaviour patterns nbps and emotions neis in users should be captured in the qualitative data.
this leads us to conclude that distillation critica lly relies on neis and npbs within the qualitative data to analyse privacy requirements and without these markers it will be difficult to apply this approach on other datasets .
therefore distillation can not be generalised for qualitative data that does not have a strong focus on privacy.
argument mfb close friends group pr2 user can create group of close friends mitigates pc2 supported by f1 warranted by cr3 user issues command creategroup closefriends fr2 user assigns friends to group assigngroupmember f closefriends argument mfb close friends viewing pr3 only close friends of user can see sensitive status messages mitigates pc2 depends on pr1 pr2 warranted by cr5 senstive status msg only visible to close friends if sensitivemessage m closefriends cf user then statusmessageview m cf argument mfb inf sensitivity detect pr1 status message sensitivity can be detected mitigates pc2 supported by f2 warranted by cr1 system detects s ensitivity of msg ?
sensitivemessage statusmsg fr2 if cr1 is indeterminate ask user to select sensitivity label 879the last factor relates to completeness.
the application of distillation demonstrate d how the approach can help software engineers derive privacy requirements that addres s end users privacy concerns.
while the derived requirements could be used to improve the design of privacy functionality of the software system that was studied it was not possible to validate this by modifying the software and testing it with the users again.
using distillation in an iterative software development project where the effectiveness of the derived requirements can be evaluated empirically remains an area for future work .
.
tool support there were two main requirements for automated tool supp ort of our privacy requirements distillation process.
first it should support the extraction of privacy concerns from qualitative data and second it should support the modelling of information flows of the current software system and later help in the p rivacy problem analysis.
both of these activities are based on two well known and proven methods qualitative data analysis and the problem frames method respectively .
as a first step towards supporting software engineers in distilling privacy requirements we decided to customise existing tools from each of these areas.
figure .
nvivo codes for prif framework from the qualitative data analysis domain we chose to use nvivo because of its prevalence and wide use in qualitative research .
one of the main advantages of using nvivo is that the codes from the prif framework can be pre defined and stored to be re used by other projects analysts.
the pre defined codes in nvivo serve as a template for the structuring of qualitative data making it easier for the analyst to readily apply the codes on the transcribed texts.
in nvivo each node represents a code or concept.
therefore all the codes used in coding phase of distillation neis nbps and privacy facets sec tion iv are defined as a hierarchy of nodes in nvivo fig ure .
the tool also supports the specification of extraction rules thus automating identification of the privacy related contexts associated with different threats.
for privacy problem analysis we chose to use openargue an eclipse plug in that supports both problem frames modelling and incremental arguments written in propositional logic.
the tool can perform syntax checking visualizing formalizing and reason ing over these incremental arguments.
openargue integrates a decreasoner which is an off the shelf reasoning tool that translates propositional formulae into problems for sat solvers.
the integrated tool supports logical deduction to check whether an ar gument is valid and model finding to obtain counterexamples to the argument.
on the basis of these results rebuttals and mitigations are generated and visualized .
while the use of the off the shelf tools was adequate to testing the concepts behind the p rivacy requirements distillation method the lack of integration between the tools was a drawback .
additionally to be useful in real world mobile applications development projects it will be necessary to develop tools that integrate directly into standard development environments such as eclipse.
since the source code for openargue is freely available and it is already integrated into eclipse our strategy is to extend this tool to support the qualitative data analysis needs of the requirements distillati on approach .
development of this tool remains an area of future work.
.
conclusions eliciting mobile privacy requirements is challenging largely due to the fact that mobile privacy issues are so dependent on the physical and socio cultural context of the us ers.
this means that only data that captures the nuances of these contextual factors and variations can adequately inform the development of privacy requirements for privacy aware mobile applications.
the distillation approach we proposed in this paper all ows requirements analysts to take advantage of the richness of qualitative empirical data while refining this data systematically into a form that enables it to be used for the design of mobile applications that reflect users real privacy concerns and nee ds.
our distillation process uses a novel privacy facets framework to structure raw data and to derive privacy concerns.
to support the privacy distillation we have adapted off the shelf tools such as nvivo and openargue .
further automated tools can help t he software engineer integrate different phases of the distillation process into standard software development environments such as eclipse .
in addition to undertaking work to address the limitations discussed above we intend to conduct further evaluation s of our approach by using other sources of empirical data such as our stud ies of location tracking .
.
acknowledgment this research was partially funded by a microsoft software engineering innovation foundation seif award science foundation ireland grant ce i1855 and by the european research council advanced grant asap .
.