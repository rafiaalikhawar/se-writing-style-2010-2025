determin inferring likely deterministic specifications of multithreaded programs jacob burnim eecs department uc berkeley usa jburnim cs.berkeley.edukoushik sen eecs department uc berkeley usa ksen cs.berkeley.edu abstract the trend towards multicore processors and graphic processing units is increasing the need for software that can take advantage of parallelism.
writing correct parallel programs using threads however has proven to be quite challenging due to nondeterminism .
the threads of a parallel application may be interleaved nondeterministically during execution which can lead to nondeterministic results some interleavings may produce the correct result while others may not.
we have previously proposed an assertion framework for specifying that regions of a parallel program behave deterministically despite nondeterministic thread interleaving.
the framework allows programmers to write assertions involving pairs of program states arising from different parallel schedules.
we propose an algorithm to dynamically infer likely deterministic specifications for parallel programs given a set of inputs and schedules.
we have implemented our specification inference algorithm for java and have applied it to a number of previously examined java benchmarks.
we were able to automatically infer specifications largely equivalent to or stronger than our manual assertions from our previous work.
we believe that the inference of deterministic specifications can aid in understanding and documenting the deterministic behavior of parallel programs.
moreover an unexpected deterministic specification can indicate to a programmer the presence of erroneous or unintended behavior.
categories and subject descriptors d. .
software program verification d. .
testing and debugging f. .
specifying and verifying and reasoning about programs general terms reliability verification documentation keywords determinism specification inference parallel programs permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
icse may cape town south africa copyright acm ... .
.
.
introduction with the growing prevalence of multicore microprocessors and graphic processing units gpus software engineers are increasingly required to write parallel programs.
unfortunately parallel programs have proven to be much more difficult to write and debug than sequential software.
a key culprit in this difficulty is that parallel programs can show different behaviors depending on how the executions of their parallel threads interleave.
the fact that executions of parallel threads can arbitrarily interleave with each other is called internal nondeterminism orscheduler nondeterminism .
internal nondeterminism enables multiple threads to run simultaneously which is essential to harness the power of multicore chips.
however internal nondeterminism in parallel programs could also result in nondeterministic outputs.
most of the sequential programs that we write are deterministic they produce the same output on the same input.
therefore in order to make parallel programs easy to write test and debug we need to make them behave like sequential programs i.e.
we need to make parallel programs deterministic.
the most widespread method for writing parallel programs threads requires programmers to ensure determinism.
ensuring deterministic behavior in such programs is generally very challenging.
thus a variety of tools and techniques have been proposed to help ensure that multithreaded programs exhibit their intended determinism.
these tools attempt to automatically find sources of nondeterminism likely to be harmful i.e.
to lead to nondeterministic output such as data races and high level race conditions.
however the absence of data races does not always guarantee deterministic behavior .
on the other hand the presence of data races may not lead to unintended nondeterministic behavior and may aid in achieving high performance .
we have argued previously that programmers should have a way to directly and easily specify that a parallel software application behaves deterministically.
we proposed a scheme for asserting that a block of parallel code exhibits the intended userspecified semantic determinism .
formally our framework allowed a programmer to give a specification for a block cof parallel code as deterministic assume pre s0 s0 c assert post s s0 this specification asserts the following suppose cis executed twice with potentially different schedules once from initial state s0and once from s0 0and yielding final states sands0 respectively.
then if the user specified precondition pre holds overs0ands0 thensands0must satisfy the user specified postcondition post .
we argued that such assertions allow a programmer to specify the correctness of the use of parallelism in an application independently of the functional correctness.
that is one can specify thatdifferent executions of a parallel program on the same input cannot erroneously produce non equivalent outputs due to scheduling nondeterminism.
this can be accomplished without having to specify anything about the correctness of individual outputs in terms of their corresponding inputs.
our experiments showed that if the deterministic specification of a parallel program is provided we can distinguish true races from benign ones in the program and find bugs in parallel programs that arise due to internal nondeterminism.
in this paper we propose to automatically infer likely deterministic specifications for parallel programs.
specifically given a set of test inputs and thread schedules for each procedure pof a parallel program we infer a deterministic specification for the body of a procedurep voidp deterministic assume pre s0 s0 ... body of p... assert post s s0 a key challenge in inferring likely deterministic specification of a parallel program is that there could be several specifications for the program however not all of the specifications are interesting.
for example the following deterministic specification holds for any parallel program where pre is any predicate.
voidp deterministic assume pre s0 s0 ... body of p... assert true to address the problem of inferring interesting deterministic specifications we argue that a pre post pair is interesting if the following two conditions hold.
.pre is a weakest liberal precondition for post andpost is a strongest liberal postcondition for pre and .post is the strongest liberal postcondition for any possible pre which we show to be unique.
we give an algorithm d etermin to compute one such interesting deterministic specification from a set of executions observed on a given set of inputs and schedules.
we formally prove that if the set of given inputs and schedules is the set of all inputs and schedules then we infer an actual interesting deterministic specification of the program.
we have implemented d etermin for java and have applied it to a number of previously examined java benchmarks.
we were able to infer specifications largely equivalent to or stronger than our manual assertions from .
we believe that the inference of deterministic specifications can aid in program understanding and documentation of deterministic behavior of parallel programs.
specifically a correct inferred specification documents for programmers the deterministic aspect of the parallel behavior of an application.
moreover an unexpected deterministic specification can indicate to a programmer the presence of buggy or otherwise unintended behavior.
for example consider a specification indicating a critical component of the program output is notdeterministic or consider a specification indicating that a program s determinism hinges on some believed to be insignificant portion of the input.
related work there is a rich literature on invariant generation .
daikon automatically infers likely programinvariants using statistical inference from a program s execution traces.
csallner et al.
propose an approach called dysy that combines symbolic execution with dynamic testing to infer preconditions and postconditions for program methods.
hangal and lam propose diduce which uses online analysis to discover simple invariants over the values of program variables.
deryaft is a tool that specializes in generating constraints of complex data structures.
logozzo proposed a static approach that derives invariants for a class as a solution of a set of equations derived from the program source.
houdini is an annotation assistant for esc java .
it generates a large number of candidate invariants and repeatedly invokes the esc java checker to remove unprovable annotations until no more annotations are refuted.
the problem of program invariant generation is related to the problem of automatic mining of temporal specifications of programs.
previous work have approached this problem using both dynamic and static analysis techniques.
the above mentioned techniques mostly focuses on generation of traditional specifications.
our approach is the first one to infer likely deterministic specifications of parallel programs.
unlike traditional specifications our inferred specifications relate two program states coming from different executions.
a number of ongoing research efforts aim to make parallel programs deterministic by construction .
but such efforts face two key challenges.
first new languages see slow adoption and often remain specific to limited domains.
second new paradigms often include restrictions such as hard to use type systems that can hinder general purpose programming.
sadowski et al.
propose a strict notion of determinism where they require the final output to be bitwise equal therefore their notion could not support semantic determinism.
kendo proposes deterministic thread scheduling for race free programs.
dmp proposes hardware support for deterministic parallel execution.
.
background in this section we review the key features of our previously proposed deterministic specifications quoting liberally from .
a block of parallel code is said to be deterministic if given any particular initial state all executions of the code from the initial state produce the exact same final state.
in our proposed specification framework the programmer can specify that they expect a block of parallel code say p to be deterministic with the following construct deterministic p semantic determinism.
we observed that the above deterministic specification is often too conservative.
for example consider the following example where a b andcare floating point matrices deterministic c parallel matrix multiply float a b floating point addition and multiplication being non associative due to rounding error it may be unavoidable that the entries of matrix cwill differ slightly depending on the thread schedule.
in order to tolerate such differences we relaxed the deterministic specification deterministic c parallel matrix multiply float a b assert c c this assertion specifies that for any two matrices candc resulting from the execution of the matrix multiply from same initial state the entries of candc must differ by only a small quantity i.e.
.
note that the above specification contains a predicate over two states each from a different parallel execution of deterministic block.
we call such a predicate a bridge predicate and an assertion using a bridge predicate a bridge assertion .
bridge assertions are different from traditional assertions in that they allow one to write a property over two program states coming from different executions whereas traditional assertions only allow us to write a property over a single program state.
this relaxed notion of determinism is useful in many contexts.
consider the following example which adds in parallel two items to a synchronized set represented internally as a red black tree set set new synchronizedtreeset deterministic cobegin set.add set.add coend assert set.equals set here a strict deterministic assertion would be too conservative.
the structure of the resulting tree and its layout in memory will likely differ depending on which element is inserted first and thus the different executions can yield different program states.
but we can use a bridge predicate to assert that no matter what schedule is taken the resulting set is semantically equal.
that is for objects setandset computed by two different schedules the equals method must return true because the sets must logically contain the same elements.
we call this semantic determinism .
preconditions for determinism.
so far we have described the following construct deterministic p assert post where post is a predicate over two program states in different executions resulting from different thread schedules.
that is if s ands0are two states resulting from any two executions of pfrom the same initial state then post s s0 holds.
the above construct could be rewritten in the following way deterministic assume s0 s0 p assert post that is if any two executions of pstart from initial states s0and s0 respectively and if sands0are the resultant final states then s0 s0 0implies that post s s0 holds.
the above rewritten specification suggests that we can further relax the requirement of s0 s0 0by replacing it with a bridge predicate pre s0 s0 .
for example deterministic assume set.equals set cobegin set.add set.add coend assert set.equals set the above specification states that if any two executions start from sets containing the same elements then after the execution of the code the resulting sets after the two executions must still contain exactly the same elements.
definition of deterministic specification.
in summary we previously proposed the following construct for the specification of deterministic behavior.deterministic assume pre p assert post it states that for any two program states s0ands0 if pre s0 s0 holds an execution of pfroms0terminates and results in state s an execution of pfroms0 0terminates and results in state s0 thenpost s s0 must hold.
more formally let p s0 denote the resulting program state if we run procedure pon initial state s0and with thread schedule .
then the above deterministic specification states that 8s0 s0 pre s0 s0 post p s0 p s0 we abbreviate this condition by pre ppost note that technically only certain thread schedules are possible for each initial program state.
that is schedules should not be universally quantified but must come from the set s0 of thread schedules for procedure prealizable from program state s0.
and functionp s0 is defined only for s0 .
for simplicity however we omit any further