stride search based deterministic replay in polynomial time via bounded linkage jinguo zhou xiao xiao charles zhang the prism research group department of computer science and engineering the hong kong university of science and technology andyzhou richardxx charlesz cse.ust.hk abstract deterministic replay remains as one of the most effective ways to comprehend concurrent bugs.
existing approaches either maintain the exact shared read write linkages with a large runtime overhead or use exponential off line algorithms to search for a feasible interleaved execution.
in this paper we propose stride a hybrid solution that records thebounded shared memory access linkages at runtime and infers an equivalent interleaving in polynomial time under the sequential consistency assumption.
the recording scheme eliminates the need for synchronizing the shared read operations which results in a significant overhead reduction.
comparing to the previous state of the art approach of deterministic replay stride reduces on average .
times of runtime overhead and produces on average .
times smaller logs.
keywords concurrency replaying debugging i. i ntroduction deterministically replaying a concurrent multicore execution remains as one of the most effective ways to comprehend concurrency bugs .
a typical deterministic replayer must tame two sources of non determinism the input non determinism observing the randomness in the program input such as the user input interrupts signals and the scheduling non determinism concerned with races to the shared memory locations caused by a random scheduler.
while the input non determinism can be effectively recorded with a low overhead the scheduling nondeterminism still poses tough challenges to making a record and replay technique attractive for the practical use.
existing replay schemes that address memory races fall into two categories order based andsearch based .
for the order based ones we have come to know in both theory and practice that tracking which write a read follows the exact linkage with respect to a particular shared memory location can be used to efficiently reconstruct an equivalent interleaving under the sequential consistency criterion .
a key drawback is that tracking the exact linkages requires adding additional locks to the program to ensure the recording operation and the observed read write operations of the program happen together atomically as illustrated in figure a .
consequently recent deterministic replay techniques such as leap and order essentially eliminate all low level data races in a program including many benign ones and incur a significant runtime overhead.
for java programs onmulti processors synchronization can significantly degrade the program performance for causing the chip wide cache validation operations across all processors .
recognizing this drawback the search based replaying techniques do not record the exact rwlinkage and instead rely on the post recording search to construct a feasible interleaving.
the search based replay techniques can incur a very low recording overhead1at the cost of losing the replay determinism.
gibbons et al.
proved that computing a feasible schedule with the value trace is np complete even with the help of local write order that defines a total order for the write operations to the same memory location.
in practice none of the existing searchbased techniques guarantees to reproduce a concurrent multicore execution essentially because the search space without the exact linkage information is exponential and cannot scale to large real systems.
it seems that we are faced with an unfortunate choice between losing the replay determinism and paying a severe performance cost for using synchronization.
towards alleviating this difficulty we present a novel search based deterministic replay technique that does not record the exact rw linkages and yet still reconstructs the schedule in polynomial time .
the non exactness is a crucial relaxation that for read operations on shared memory locations the recording operation and the read events are not required to happen atomically .
hence no synchronization is needed.
as illustrated in figure b for the read operation ri instead of observing its exact corresponding write wi our recorder observes a write operation wj that happens sometime later than the matching write wi.
if we version all the write operations the observed version of wjcan be used as a linkage bound in guiding the post recording search to only focus on the writes of older versions when reconstructing the original execution.
compared to the pure order based approaches our technique dramatically reduces the need of synchronization.
since no atomic execution is required for reads we essentially permit the concurrent read exclusive write crew semantic where the read operations issued by one processor 1e.g.
presented by lee et al.
and weeratunge et al.
present a totally search based method with nothing recorded at all978 .
c ieee icse zurich switzerland figure .
difference between recording exact linkage and bounded linkage can happen in parallel with the writes from other processors.
in most of the real world programs the number of read operations is much larger than that of the writes.
our versioning of the writes does require adding locks to unprotected writes.
we find that in well engineered concurrent programs most of the writes to shared locations are locked by the programmer already which significantly limits the performance penalty of our technique.
since only a limited number of context switches get into the execution window between the read operation and the recording operation the distance between the bounded linkage and the exact linkage is small.
in fact our evaluation of real programs shows that for most of the cases the two operations are not interleaved by other operations at all and hence the search can be done in almosto time in practice.
to the best of our knowledge the only related approach that deterministically reproduces the interleaving without synchronizing the read operations is proposed as a theoretical possibility by cantin et al.
.
their proposal requires the serialization of all the writes in the program by a global lock to establish the global write order .
serializing writes across cores incurs a significant slowdown for concurrent programs running many threads.
comparatively our technique only requires locking writes locally for each shared memory location and incurs a limited penalty to the degree of concurrency.
to evaluate our technique we have implemented a tool called stride and used it to replay many large java programs.
our experiment evaluates many widely cited programs including the dacapo suite the derby database server the ice ipc middleware and the specjbb2005 benchmark.
the average recording slowdown incurred by stride is times for all subject programs and time if we exclude special computationally intensive cases such as avrora and lusearch .
we compare stride against both our previous order based replayer leap and an implementation of cantin et al.
s approach using the global write order.
we show that on average stride is faster than leap by .
times excluding our best cases for which the gap can be up to times.
stride is also faster than cantin et al.
s global order approach by .
times on average.
for all our subjects the search time for the interleaving regeneration is negligiblefor all the subject programs.
also compared to leap the log size of stride is on average .
times smaller excluding our best cases which are up to times smaller.
in summary our contributions are the follows .
we present stride abound infer replay technique to deterministically replay concurrent programs on multi cores.
stride is the first to record partial runtime information and to infer the deterministic execution in polynomial time.
.stride only concerns with the write write race a more relaxed race condition that favours a lot of well engineered concurrent programs.
.
we extensively evaluate our algorithm and show that our new algorithm works well in practice with the overhead orders of magnitude smaller than the state of the art techniques.
the rest of the paper is organized as follows.
section ii provides an exemplified overview of stride .
the formal description and analysis of stride is given in section iii and iv.
in section v we discuss how to efficiently implement stride .
the evaluation result is given in section vi.
finally we discuss the related work in section vii and conclude our work in section viii.
ii.
o verview of ourreplaying scheme we first illustrate our technique with an example shown in figure .
this program has four threads with lines numbered following a total order.
we are interested in replaying a special program state where both output statements line and line are executed.
the interleaving order indicated by arrows is one of the possible schedules to reach this program state.
recall that the order based technique can replay the program to this state by recording the exact rwlinkages which in the given schedule include the following r6 squigglerightw5 r9 squigglerightw4 r7 squigglerightw3 andr8 squigglerightw2.
here randwstand for read or write operations and rx stands for reading at line x. we want to show that stride does not record this information and instead computes these linkages to replay this program state.
stride logs the information separately for the read operations the write operations and the lock operations.
to simplify the example let us consider only the read and write operations.
for the read operations stride records a twotuple representing the value returned by the read operation and the latest version of write that read can possibly link to the bounded linkage .
for example the tuple represents a read of value from a write of version at most for that variable.
the read operations are logged separately for each thread.
for the write operations stride records the thread access order on each variable.
in the example in figure we embed what stride logs at each statement where rlog and wlog denote the logs for read and write operations respectively.
figure presents how the stride replayer uses the two logs to compute the exact linkages listed above.
with no893figure .
example program loss of generality we assume the replayer uses a roundrobin scheduler that executes the next statement selected from the four threads in a rotating fashion starting from the threadt2.
we denote the statement in line kassk.
the replayer first tries to execute s4of threadt2 a write to the variable y. since the wlog ofyindicates that the first write to yis by thread t1 t2is suspended.
when the scheduler continues to execute s6oft3 since it is a read the replayer consults the rlog and obtains the tuple .
this tuple means the value read from variable yis of which the write version is not larger than .
since the third version is not yet computed it is not t3 s turn to execute and t3 is also suspended.
similarly t4is suspended.
the replayer then executes s1 writes value to variable yand updates its version as denoted as y1 0in figure .
at this point s4as well ass2ands5can be executed which produce the second version of y the first version of x and the third version of y respectively.
consequently the execution ofs6oft3 which is previously suspended can finally be executed as follow.
since s6oft3reads value of yof version smaller than we need to search all writes of yof older versions that writes the value .
in our example the match iss5oft2.
an exact linkage r6 squigglerightw5is computed as shown by the arrow in figure .
linkages r7 squigglerightw3and r8 squigglerightw2can be reasoned in the same way.
the execution of the last statement s9particularly shows the strength of linkage bounding.
the rlog indicates that we are reading ofyno later than version .
this means that we only look for writes that produce with the associated versions not larger than .
through a simple linear scan we can easily compute the last linkage r9 squigglerightw4.
from this example we can observe that for the orderbased replay technique we need to insert nine synchronization operations in this short piece of code to protect nine shared variable accesses whereas stride only needs five.
figure .
replaying the example program using bounded linkage execution log lwxlaltri lwx x sv i ofwi x v lal l l i ofli l tri i v ofri x v bli x bli x figure .
formalism of the concurrent program execution log.
more importantly since stride allows the crew semantic the execution of threads t3andt4can be completely in parallel leading to the more efficient recording run.
in the following sections we will describe how stride works why it is correct as well as the engineering challenges that we have encountered.
iii.
p reliminaries in this section we formalize the essential concepts as well as the problem addressed in this paper.
a. execution log of concurrent program we adopt the notations of a previous work to define the concurrent program as a set of threads t t1 t2 .
.
.
tk communicating through a set of shared variables sv residing in a single shared memory protected by a set of locksl.
the thread t1is the main thread that forks other threads at runtime.
all the operations executed by thread ti can be numbered in order and we use pci ato denote the execution number of an operation a. formally figure gives the definition of our execution log for a concurrent program.
the symbols e.g.ri x define the following operations ri x v read value vof variablexby threadti.
wi x v write value vto variablexby threadti.
li l acquire lock lby threadti.
ui l release lock lby threadti2.
fi j fork a new thread tjby threadti.
ji j join the thread tjto threadti.
2ui l fi j and ji jis not used in the execution log.
we define them here to describe all the operations concerned by stride894 program order 1 a b tei pci a pci b a scb weak total order 2 a b ops a negationslash b a scb b sca asymmetric order 3 a b ops a negationslash b a scb b sca exact read write linkage 4 a opsr b opsw var a var b b sca c opsw var c var b b scc sca figure .
sequential consistency specification.
opsrandopswdenote all the reads and writes respectively and ops denotes all the concerned operations.
var a is the variable of the operation aaccessed.
an execution log is divided into three disjoint parts.
lw x stands for the local total order of the writes to a shared variablex.
specially we say the kthwrite in lw xis of versionk.
la lis the lock acquisition log recording the lock unlock order for the lock lfor reproducing dead locks.
triis the read log of threadti.
each item in a read log is a two tuple representing the value returned by the read operation and the latest version of write that read can possibly link to the bounded linkage .
the read value can be used to faithfully replay the thread local execution trace for each thread see section iv a while the bounded linkages are used to guide the search for the exact read write linkages see section iv b .
b. memory model and legal schedule amemory model defines the set of values committed by writes that are allowed to be returned by a read .
the most strict memory model for concurrent programs issequential consistency sc .
lamport defines sequential consistency as the result of any concurrent execution is the same as that the operations on all the processors are executed in some sequential order and the operations of each individual thread appear in the program order .
axiomatically we define a legal schedule under sc to be a total order sc of the read write operations that conform to the memory behaviour rules given in figure .
among the rules 1reflects the program order 2and 3restrict the shared memory operations to be executed sequentially and 4mandates the read can only return the most recent value written to the same memory location.
if more than one legal schedule can be found we say they are equivalent to each other.
c. problem definition given an execution log the task of replay or of the execution composition is to generate a total order of all operations such that the reads and writes conform to the lock and unlock matching 5 a li1 l1 b li2 l2 l1 l2 a scb c ui3 l3 l3 l1 i3 i1 a scc scb 6 a ui1 l1 b li1 l1 b sca c ui1 l1 b scc sc a fork and join constraints 7 a fi j b tj a scb 8 a ji j b tj b sca figure .
thread control axioms for lock unlock and fork join.
sequential consistency memory model and meanwhile the lock unlock as well as the fork join operations conform to the thread control axioms described in figure .
rules 5and 6define a lock that can only be held by one thread at a time.
rules 7and 8guarantee a thread must be executed after the fork operation and before the join operation.
similar to the previous work we synthesize a valid execution by sorting the happens before graph topologically see section iv .
our core research question is how to rediscover the exact rw linkages via the read logs tr i and the write sequences lw x .
the bounded linkages in the read log is a number describing a bounded write version for a read ri x. the bounded write version is used as an upper bound to search for the matched write for any read.
if for example a read ri xhas a bounded linkage it means the matched write wj xof this read is placed before or equal to the position starting from in lw x. in the next section we will show how to instrument the program how to infer the exact rw linkage as well as the proof of why this algorithm can compute an execution equivalent to the original execution.
iv.
a t heory of execution composition by bounded linkages a. program instrumentation we first perform a thread escape analysis to identify all the shared variables sv .
next we normalize the program so that the result of reading a shared variable is first stored in a local variable and use that local variable in the subsequent computation.
for example if a statement x y z involves three shared variables x y andz we change the code into three statements a y b z x a b. after the transformation each statement can access at most one shared variable.
to collect the execution log we instrument the program as shown in table iv b. for each shared variable x we maintain a version value vx.
the statements labelled with wc version update and rc version snapshot in the instrumented code for the shared write and read guarantee any bounded linkage is a searching upper bound.
this is895because since wcmust execute before the write to x and rcmust execute after the read from x the matched write ofrj xis always positioned before or equal to its bounding writewi x. the full details of the thread execution as well as the unlock operations can be reconstructed during replay.
when replaying since the only way for one thread to be affected by another thread is by reading a value3 the values in the read log can help faithfully reproduce a thread s local behaviour.
for reproducing the orders of write and lock operations logging the execution as a sequence of thread ids is also sufficient since the program order is available in the replaying run.
since a lock operation must be followed by a corresponding unlock operation the sequence of unlock information is also available.
thus in the rest of this section we assume the full details of each thread s execution and the lock unlock sequence are already obtained in the replay run.
b. inferring exact read write linkage composing a feasible execution requires a happens before graph that encodes the legal schedule constraints which in turn needs the exact read write linkages.
fortunately turning our bounded linkages to exact linkages can be achieved by a simple linear scan which is given in algorithm .
the core of algorithm is the searchformatch procedure.
for each read operation we suppose it reads variable x we search from the upper bound blbackward to index in the local write log lwx and stop at the first write that writes the value returned by this read.
the time complexity of algorithm is o kn wheren is the total length of the execution log and kis the number of threads.
this is because although the lower bound for the search in line is the jthread in thread ticannot match a write of an older version than the bounded linkage of the j thread.
therefore the loop from the line to line in the worst case examines o n operations.
since we only queryo n times for the exact linkages the average execution time of searchformatch iso kn n o k which is extremely fast if only a small number of exact rw linkages are to be recovered.
the last question is why the first matched write guarantees the legal schedule.
recall that a legal schedule is obtained by sorting the happens before graph topologically.
hence it is essential to prove that graph has no cycle.
formally a happens before graph is constructed as follows definition .
a happens before graph has all the executed statements as its nodes.
the edges are built by a .
ifri xreads the value written by wj x we add edges wj x ri xandri x wcwherewcis the version update statement for the next write wj xinlwx b .
for any two adjacent writes wi1 xandwi2 xinlwx we 3none memory access operations cannot affect the execution path of a thread thus will not affect a thread s local behaviourtable i program instrumentation illustration .
all code is executed in thread ti and the underlined statements are our instrumented code .
write read lock unlock synchronized lx wc vx x a lwx.add i a x rc v vx bli.add v tei.add a l.lock lal.add i code l.unlock algorithm infer the exact linkages for all reads procedure linkage infer for all threadti i do for allrx i v intiwith bounded linkage bldo search formatch rx i v bl end for end for end procedure procedure search formatch rx i v bl for k bl k k do ifwrite value of lwx vthen returnlwx found the exact linkage exit for end if end for end procedure addwi1 x wc wherewcis the version update statement forwi2 x c .
if statements aandbare both executed in tiand pci a scpci b we adda b d .
for an unlock operation ui l we add an edge to the next lock operation lj lfor the same lock l e .
for any fork operation fi j we add an edge from fi jto the first operation of thread tj f .
for any join operation ji j we add an edge from the last operation of thread tjtoji j. it is straightforward to validate that the happens before graph constructed by definition .
satisfies all the axioms in figure and figure .
therefore a topological sort on this graph gives a legal execution.
since the original execution is a legal execution by the definition of equivalent execution stated in section iii b the computed result is equivalent to the original execution if and only if there exists a topological sort in the happens before graph or in other words the happens before graph has no cycle.
since only rule a uses the inferred result we only need to prove that rule a does not incur any cycle.
theorem .
the exact read write linkages computed by algorithm leads to an acyclic happens before graph.896figure .
happens before graphs with different rw linkages.
proof suppose the bounded linkage for a read ri xist1 and the matched write found by algorithm is positioned at t2 t2 t1 .
we first prove that if there is another match t3 t3 t2 that forms a happens before graph with no cycle so does the match t2.
we use figure a to show the part of the happensbefore graph around the rw linkage wt3 ri x.wcandwc2 are the version update statements corresponding to wt1 andwt2.wc3andwc4are the version update statements corresponding to the write operations next to wt2andwt3 inlwx respectively.
the graph on the right figure b is a modified version of figure a in which the edges wt3 ri xandri x wc4are replaced by wt2 ri xand ri x wc3.
our aim is to show if figure a has no cycle figure b is also acyclic.
because we only add two edges in figure b there are only two chances to form a cycle i the circle formed by the edge ri x wc3and the path wc3 squigglerightri x.the pathwc3 squigglerightri xdoes not exist because otherwise there is a path wc4 squigglerightri xand figure a has a cycle which contradicts our assumption.
ii the circle formed by the edge wt2 ri xand the pathri x squigglerightwt2.becauseri xhas only two outgoing edges the pathri x squigglerightwt2must start with one of them.
ri x wc3 cannot be picked because otherwise there is a path wc3 squiggleright wt2.
sincewt2must be executed before wc3according to our local write order constraint there is a path wt2 squigglerightwc3 in figure a .
therefore together with the path wc3 squiggleright wt2 we have a cycle in figure a which is a contradiction.
if we pickri x rcas the first edge it implies that there is a pathrc squigglerightwt2.
also since there is only one incoming edge ofwt2fromwc2 there should be a path from rc towc2.
since there is a path wc2 squigglerightwc4and an edge wc rc there must be a cycle in figure a which again contradicts our assumption.
4particularly if t1 t2 wc2is essentially the wc.now we have proved figure b also has no cycle.
since we knowri xmust read from some write wreal andwrealis eitherwt2or the one that is placed preceding wt2inlwx it immediately follows that the exact rw linkage wt2 ri x cannot form a cycle.
since ri xis chosen arbitrarily we can conclude that the happens before graph has no cycle.
v. f rom theory to engineering in the previous section we have discussed our core contribution of inferring a legal execution with bounded linkages.
a few engineering challenges still remain.
a. execution log compression for the read logs tr i we compress the read values and the bounded linkages separately.
the common way of compressing the read values is using the last one value predictor which is also adopted by the tracing tool idna .
specially for each shared variable x we maintain a shadow memory in each thread tito record its last accessed value and a counter to record the prediction hits rate.
when ri x v is executed we compare the value vto its current shadowed value v prime.
if they are equal we increment the corresponding counter by one.
otherwise we output an entry value counter to the log and update the shadow memory usingvand reset the counter to .
for a write wi x v we only update the corresponding shadow memory to vand reset the counter to .
the memory footprint can be very large if we create a shadow memory for every shared variable at runtime.
to limit the memory usage we use a hash function so that two different variables can share a shadow memory if they have the same hash value.
according to our experiment a 10mb shadow memory for each thread is very effective for log compression.
we compress the bounded linkages in the read logs the local write logs lw x and the lock acquisition logs la l by replacing the consecutive nelements with the same value twith an tuple t n a form of run length encoding .
for example we merge the sequence into .
b. variable grouping maintaining the order and the version for each variable is costly due to the large amount of memory used in the execution of the original program.
stride uses the context insensitive and the field based model to abstract the program and map the runtime shared variables to the symbolic variables also adopted by leap .
supposing aand bare two runtime instances of class c the runtime variables a.fandb.fare treated as the same variable fthat share the same local write log lw fand the same version value.
when a program has strong locality and a small number of context switches a group of variables may be accessed by the same thread for a period of time.
such property results in a lot of adjacent log entries having the same value in both897the read and the write logs.
this can be used to improve the compression rate of the run length encoding.
the last one value predictor for logging the read values however cannot benefit from the grouping of the variables since the value in each memory unit is supposed to be different.
for example thread t1updatesx1 x2...xnand then thread t2readsx1 x2...xn.
if we group x1 x2...xntogether as variablex recording n 5for the write order log and n n for the bounded linkages is enough.
however we have to record all the values of x1 x2...xn since the value of x1 x2...xnare supposed to be different from each other.
we have designed a novel compression technique to deal with this problem.
if we can confirm the version value is the exact linkage but not merely a bounded linkage the read value need not be logged.
this is because the read value can be recovered by loading the write value of its exact linkage write in the replaying run.
to implement our idea we update the version value twice for each write operation instead of once in the original algorithm.
one is put before the write and the other is put after the write.
if a version value is even and it is the same as the last version recorded the version recorded is actually an exact linkage since under this condition no new value is written.
thus the read value need not be recorded.
by this means we can achieve similar compression rate as other logs for the read values in programs with strong locality and infrequent context switches.
c. optimization for race free programs if the read and the write operations to a variable are all protected by a lock logging the acquisition order of the lock can regenerate the shared access orders for the variable and thus deterministically reproduce the execution .
more precisely if a variable is protected by a lock for both read and write operations we insert no instrumentation for this variable.
if a variable is protected by a lock for all the write operations we only record the read logs for the variable since under this condition the write order can be deduced from the lock order.
this treatment leads to a great runtime overhead reduction.
the experimental details are given in section vi e. d. objects correlation in different executions in java the address of an object is represented by a hash code.
as the hash code is dynamically assigned to an object two executions of the same program of the same allocation statement may return different hash codes.
to correlate the same objects created in different executions we assign a birthday to every object and maintain a hashcode birthday map.
more precisely for each thread we maintain a counter cbirth.
when an object is created we map the hash code of that object to cbirth and increment the counter by one.
after n stands for the next nwrites are issued by thread t1.
n n stands for the next nread operations reads version n.the execution ends we dump the map between the hash code and birthday counter.
during the replay run we assign the birthday to every object in the same way as above.
but this time we maintain a birthday object map.
if the logged value of a pointer variable is t we immediately translate tto the birthday using the hashcode birthday map obtained in the recording run to lookup the referred object.
in this way the object correlation is easily achieved with low performance penalty.
since the execution control flow for each thread is guaranteed to be same in two runs the birthday method is sound.
vi.
e valuation we assess the quality of stride by quantifying its recording overhead its log size and the inference cost.
we have implemented stride for java using the soot framework7.
we compare our approach to our earlier work leap a representative approach8in using the exact linkage to deterministically replay concurrent java programs.
to conduct a fair comparison we group the variables for stride in the same granularity as leap .
we have also implemented the work of cantin et al.
referred to as global in the rest of the paper that maintains a global write order in order to deterministically replay.
for global there is no need of grouping since we must maintain the global order of all the write operations accessing each shared variable.
we do not compare stride to the search based techniques because unlike stride the search based techniques are not deterministic.
all experiments are conducted on a core .00ghz intel xeon machine with 16gb memory and linux version .
.
.
we selected a wide range of benchmarks to evaluate our approach.
avrora batik h2 lusearch sunflow tomcat andxalan are from the dacapo suite9.moldyn is a scientific computation program from the java grande benchmark suite.
tsp is a parallel algorithm solving the travelling salesman problem.
we also include derby a widely used database engine specjbb2005 a benchmark for parallel business transactions and ice a high performance implementation of the protocol buffer10ipc specification.
a. the study of recording overhead table ii presents the experimental results for the selected benchmarks.
the column read percentage presents the percentage of read operations among all concerned operations described in section iii a during the execution.
the third column reports the average comparison time during the infer stage.
the 4thto6thcolumns report the runtime overhead 8a more recent work successfully applies our technique in the jvm.
9the reflections in dacapo suite are solved using tamiflex ii performance for real applications infer efficiency overhead x log size s benchmark read percentage avg compare time stride leap global stride leap global avrora .
.
.
.
.
.4mb .5mb .1mb batik .
.
.
.
.
.5kb .3kb .7kb h2 .
.
.
.
.
.569mb .382mb .353mb lusearch .
.
.
.
.
.8mb .7mb .0mb sunflow .
.
.
.
.
.2kb .6kb 52758kb tomcat .
.
.
.
.
.6kb .7kb .1kb xalan .
.
.
.
.
.8mb .1mb .9mb tsp .
.
.
.
.
.8mb .7mb .6mb moldyn .
.
.
.
.
.3mb 3834mb .2mb derby .
.
.
.
.
.1kb .2kb .1kb specjbb .
.
.
.
.
.9kb .1kb .5kb ice .
.
.
.
.
.57mb .21mb .14mb which is the gap of the execution time between instrumented code and the original code normalized based on the original execution time.
the last three columns report the log size for one second of execution.
our first study looks at the most important characteristic of a replay technique the recording overhead.
compared to the original programs the overhead of stride is below 1x in of the subjects and below 2x for the two evaluated scientific computation benchmarks tsp andmoldyn that intensively access shared variables.
for tomcat derby and batik the overhead is less than which is attractive even for the production usage.
compared to leap our measurements show that stride incurs on average of .5x smaller runtime slowdown if we consider the subjects moldyn andtsp as special cases where stride is 11x and 75x better respectively.
stride only incurs a slowdown on derby because derby rarely accesses shared variables.
although the write operations on the same variable cannot execute in parallel the number of such operations is small and most of them have already been protected by locks.
therefore there is no need for stride to insert locks.
for moldyn despite that the program accesses shared memory very frequently .
of the operations are read operations.
under this condition tracking the exact read write linkages is very expensive due to the large amount of additional locks.
stride also performs better than global for out of the subjects.
global requires a global lock for all of the write operations to shared variables such that any two write operations whether they access the same memory location or not can not execute in parallel.
this increases the lock contention drastically if the thread number gets large.
for ice the performance of global is slightly better because ice frequently accesses the same shared variable.
stride andglobal incur a similar degree of lock contention in this case.
since global does not maintain the write version it performs better than stride .
however this caseshows that maintaining and logging the write versions incur very small overhead because the performance gap between global .93x and stride .06x is small.
an interesting finding is that global which is assumed not practical performs better than leap for out of the subjects due to the removal of the lock contention for read operations.
since the read operation contributes to of the total amount of operations on the shared variables global has the comparable performance with respect to leap .
b. the study of log size for the log size table ii shows that stride performs better than leap for all of the subjects.
leap produces on average .88x of the log size of stride without counting our best cases tsp andmoldyn .
compared to leap stride only tracks the write operations which is fewer in number and easier to compress.
in addition the read operations usually read a value written by the same thread which need not be recorded.
in the subjects derby andspecjbb the gap on log size between leap andstride is less than 2x due to the fact that the interleaving is not very frequent making the compression algorithm of leap very effective.
however for moldyn which intensively accesses shared memory the log size of stride is only .3mb per second which is more than 140x smaller than that of leap .
one reason is that of the operations in moldyn are reads for which leap needs to insert locks for recording the thread access order.
besides in moldyn the value updated by write operations are very frequently checked by most of the threads making it very easy for stride to reduce the log size but quite hard forleap .
the log size of global is even smaller than stride in of the benchmarks.
this is because in these four subjects the write operations rarely update new values and the reads mostly return the same value.
the entropy of the log files is low which favours compression algorithms a lot.
on the contrary for sunflow h2andbatik global899figure .
overhead vs thread number x coordinate specifies the amount of thread y coordinate specifies the overhead normalized based on the original execution time incurs very large log sizes because of the opposite reasons the writes often update the values of shared variables and these updates are checked by other reading threads causing a lot of recording of read values.
stride encounters similar problems.
but our double versioning technique can provide an optimization see section v b to solve this problem.
therefore the log size of stride is also small under such conditions.
c. the thread scalability study we are also interested in investigating how the recording overhead and the log size scale with respect to the increasing number of threads used.
since dacapo has self configured thread numbers we select two benchmarks moldyn where almost all the operations accessing shared memory are read operations and tsp a subject that has the normal percentage of reads and writes to the shared memory.
the observed overhead is shown in figure and the log sizes are shown in figure .
we can see that for stride the overhead increases from .5x to .81x for moldyn and from .54x to .27x fortsp when the number of threads increases from to .
when the number of threads increases from to the log size for stride also increases from .3mb s to .4mb s for moldyn and from .8mb s to .3mb s fortsp .
also we find that when thread number increases the recording overhead of global increases 5x faster than stride formoldyn and 2x faster for tsp .
this is consistent figure .
log size vs thread number x coordinate specifies the amount of thread y coordinate specifies the exact log size with the theoretical conclusion that global does not fit for highly parallelized executions.
d. the cost of inferring the exact linkage in this study we quantify the inference cost of stride since we only record a bound for the exact linkage in the log.
for each read operation in the log we need to linearly scan all the write operations that have smaller version numbers than the bound.
given the huge amount of read operations it is crucial that the scan needs to be very fast.
the avg compare time column of table ii shows the average number of lookups during the scan is very close to for all of the subjects.
this shows that the number of preemption between the read operation and the following read of the bound is very small in practice.
for avrora where interleaving frequently happens there are .
million out of .
million read operations to shared memory can be solved in the first comparison .
million in the second in the third.
only read operations requires or more comparison.
we have similar findings for the other subjects.
in the subject xalan we detected two cases that the scan requires more than lookups.
overall we conclude that although the complexity of inferring an exact linkage is on average o k in theory the average complexity in practice is almost o .
e. race free condition our final study explores the optimal recording overhead ofstride assuming that in well engineered programs the900table iii race free optimization overhead x protectedrw protectedw avrora .
.
.
batik .
.
.
h2 .
.
.
lusearch .
.
.
sunflow .
.
.
tomcat .
.
.
xalan .
.
.
tsp .
.
.
moldyn .
.
.
derby .
.
.
specjbb .
.
.
ice .
.
.
unprotected writes are intentional i.e.
the write write race is benign.
in this case stride does not need to add any additional locks to the program and is still able to deterministically replay it.
table iii reports the overhead normalized against the original execution time.
we find that the overhead is on average only 1x and even less than 4x for avrora where there are lots of hot loops accessing the shared memory.
this result is significant because all of the order based techniques such as leap order and recplay requires the program to be both read write and write write race free if no locks are to be added.
also as reported in table iii the percentage of variables that both reads and writes are protected protectedrw is much smaller than those to which writes are protected protectedw .stride is much more efficient if this assumption holds in practice.
vii.
r elated work pres and odr are two recent search based projects.
pres uses a feedback replayer to explore the thread interleaving space.
it reduces the overhead by adding more replay attempts.
odr focuses on reproducing the same output and reason a possible execution with the offline inference in order to alleviate the online recording overhead.
weeratunge et al.
presents a way to guide the offline inference based on the core dump without any online overhead.
these approaches provide no guarantee of reproducing a feasible execution trace and they all report the cases that they fail to reproduce a run in several hours.
leap and order are two state of the art order based techniques that directly record the order of shared memory accesses.
they carefully adjust the granularity of how the shared memory cells are grouped to avoid the contentions caused by additional synchronizations.
netzer presents a method on minimizing the amount of logged exact rw linkages in recovering the same execution trace which make the further reduction of the runtime cost hard for the order based techniques.
doubleplay breaks this bound by executing the program twice using two different parallel strategies and comparing the effect of the executions.
instead of maintaining the exact linkage doubleplay link the read and write operations by value.
doubleplay canachieve a lower recording overhead.
but the change of the parallel strategy requires the low level control permission and the hardware support.
our work however provides a general theory on how to perform the read write mapping in polynomial time.
to avoid the overhead of recording memory races recplay and kendo replay race free multithread programs by logging lock sequences.
both the approaches use a data race detector during replay to ensure the replay determinism until the first race.
however they suffer from the limitation that they cannot replay past the data race.
unfortunately most real world concurrent applications contain low level data races.
our work relaxes the the race free requirement to be the write write race free which favours many well engineered concurrent programs.
bhansali et al.
presents idna an instruction level tracing framework.
their work records all the values read from or written to a memory cell.
they use a memory predictor to compress the value trace.
idna incurs on average 11x runtime overhead and the trace size of tens of mega bytes per second by recording all the values from memory access operations.
unlike tracing techniques our replay technique requires logging only the memory access to the shared memory for which only the read value written by a different thread is required to be recorded.
thus the recording overhead and the log size for stride can be much smaller than that of idna .
viii.
c onclusion we have presented stride a deterministic replay technique for multi thread programs by recording thebounded linkages of read and write operations and then inferring an equivalent execution in almost linear time.
our method achieves a low runtime overhead by removing the additional synchronizations on read operations and allows the concurrent read exclusive write semantics.
our experiments show that compared to the state of the art stride incurs .
times smaller runtime slowdown excluding our best cases for which the gap can be up to times.
the log size is also on average .
times smaller excluding our best cases for which our log size is times smaller.
besides our work makes more space for further optimization by leveraging the restriction of being low level race free to write write race free.
since our technique focuses on the problem of what to record but not how to record it can also be directly applied for many order based techniques as an optimization.
acknowledgement we thank the anonymous reviewers for their constructive comments.
this research is supported by rgc grf grants and .901references s. t. king g. w. dunlap and p. m. chen debugging operating systems with time traveling virtual machines ser.
atec .
s. m. srinivasan s. kandula c. r. andrews and y .
zhou flashback a lightweight extension for rollback and deterministic replay for software debugging ser.
atec .
j. tucek s. lu c. huang s. xanthos and y .
zhou triage diagnosing production run failures at the user s site ser.
sosp .
t. c. bressoud and f. b. schneider hypervisor based fault tolerance acm trans.
comput.
syst.
vol.
february .
s. medini p. galinier m. d. penta y .
g. gueheneuc and g. antoniol a fast algorithm to locate concepts in execution traces in search based software engineering ser.
lecture notes in computer science vol.
pp.
.
s. narayanasamy g. pokam and b. calder bugnet continuously recording program execution for deterministic replay debugging ser.
isca .
d. lee m. said s. narayanasamy z. yang and c. pereira offline symbolic analysis for multi processor execution replay ser.
micro .
p. b. gibbons and e. korach testing shared memories siam j. comput.
vol.
august .
j. huang p. liu and c. zhang leap lightweight deterministic multi processor replay of concurrent java programs ser.
fse .
d. r. hower and m. d. hill rerun exploiting episodes for lightweight memory race recording ser.
isca .
p. montesinos l. ceze and j. torrellas delorean recording and deterministically replaying shared memory multiprocessor execution efficiently ser.
isca .
s. narayanasamy c. pereira and b. calder recording shared memory dependencies using strata ser.
asplos xii .
m. xu r. bodik and m. d. hill a flight data recorder for enabling full system multiprocessor deterministic replay inproceedings of the 30th annual international symposium on computer architecture ser.
isca .
d. lee b. wester k. veeraraghavan s. narayanasamy p. m. chen and j. flinn respec efficient online multiprocessor replayvia speculation and external determinism ser.
asplos .
z. yang m. yang l. xu h. chen and b. zang order object centric deterministic replay for java ser.
usenixatc .
l. lamport how to make a multiprocessor computer that correctly executes multiprocess programs ieee trans.
comput.
vol.
september .
s. narayanasamy z. wang j. tigani a. edwards and b. calder automatically classifying benign and harmful data races using replay analysis ser.
pldi .
m. aldinucci m. meneghin and m. torquati efficient smith waterman on multi core with fastflow parallel distributed and network based processing euromicro conference on vol.
.
d. weeratunge x. zhang and s. jagannathan analyzing multicore dumps to facilitate concurrency bug reproduction ser.
asplos .
c. zamfir and g. candea execution synthesis a technique for automated software debugging ser.
eurosys .
g. altekar and i. stoica odr output deterministic replay for multicore debugging ser.
sosp .
n. sinha and c. wang on interference abstractions ser.
popl .
s. park y .
zhou w. xiong z. yin r. kaushik k. h. lee and s. lu pres probabilistic replay with execution sketching on multiprocessors ser.
sosp .
j. f. cantin m. h. lipasti and j. e. smith the complexity of verifying memory coherence and consistency ieee trans.
parallel distrib.
syst.
vol.
july .
c. flanagan and s. n. freund adversarial memory for detecting destructive races ser.
pldi .
s. v .
adve and h. j. boehm memory models a case for rethinking parallel languages and hardware commun.
acm vol.
august .
r. l. halpert static lock allocation master s thesis mcgill university april .
m. burtscher and b. g. zorn exploring last n value prediction in ieee pact .
s. bhansali w. k. chen s. de jong a. edwards r. murray m. drini c d. miho cka and j. chau framework for instruction level tracing and analysis of program executions ser.
vee .
o. lhot ak and l. hendren scaling java points to analysis using spark ser.
cc .
m. ronsse and k. de bosschere recplay a fully integrated practical record replay system acm trans.
comput.
syst.
vol.
may .
r. h. b. netzer optimal tracing and replay for debugging shared memory parallel programs ser.
padd .
k. veeraraghavan d. lee b. wester j. ouyang p. m. chen j. flinn and s. narayanasamy doubleplay parallelizing sequential logging and replay ser.
asplos .
m. olszewski j. ansel and s. amarasinghe kendo efficient deterministic multithreading in software ser.
asplos .