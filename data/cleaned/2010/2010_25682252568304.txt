patch verification via multiversion interprocedural control flow graphs wei le shannon d. pattison rochester institute of technology one lomb memorial drive rochester ny usa wei.le sdp1929 rit.edu abstract software development is inherently incremental however it is challenging to correctly introduce changes on top of existing code.
recent studies show that of the bug fixes are incorrect and the most important yet hard to acquire information for programming changes is whether this change breaks any code elsewhere.
this paper presents a framework called hydrogen for patch verification.
hydrogen aims to automatically determine whether a patch correctly fixes a bug a new bug is introduced in the change a bug can impact multiple software releases and the patch is applicable for all the impacted releases.
hydrogen consists of a novel program representation namely multiversion interprocedural control flow graph mvicfg that integrates and compares control flow of multiple versions of programs and a demand driven pathsensitive symbolic analysis that traverses the mvicfg for detecting bugs related to software changes and versions.
in this paper we present the definition construction and applications of mvicfgs.
our experimental results show that hydrogen correctly builds desired mvicfgs and is scalable to real life programs such as libpng tightvnc andputty .
we experimentally demonstrate that mvicfgs can enable efficient patch verification.
using the results generated by hydrogen we have found a few documentation errors related to patches for a set of open source programs.
categories and subject descriptors d. .
reliability general terms algorithms experimentation reliability verification keywords multiversion software changes patch verification .
introduction as software becomes an essential part of our daily life it is very important to be able to deliver new features critical patches refactorings or performance optimizations in a trustworthy way and in permission to make digital or hard copies of all or part of this w ork for personal or classroom use is granted without fee provided th at copies are not made or distributed for profit or commercial advantage and th at copies bear this notice and the full citation on the first page.
to cop y otherwise to republish to post on servers or to redistribute to lists re quires prior specific permission and or a fee.
icse may june hyderabad india copyright acm ... .
.a timely fashion.
nowadays many software companies adopt an agile process and deliver incremental changes via short release cycles e.g.
google chrome and firefox release new versions every weeks .
fast releases increase the communications between software companies and users but not the users tolerance of bugs.
a recent study shows that only of smartphone users are willing to try a failing app more than twice .
system administrators are typically very careful about updating software because unstable new releases can lead to unrecoverable consequences.
importantly if we do not assure release quality an overwhelming number of failures can be returned after software deployment diagnosing which can stall new releases .
although important it is challenging to ensure the correctness of software changes especially in a fast release setting.
to introduce a change developers need to understand existing code which may be written by other people and the documentation can be missing or out of date.
a recent study shows that the most important yet hard to acquire information for software changes is whether this change breaks any code elsewhere .
in fact a gmail bug that deleted emails for millions of users was caused by an incorrect code refactoring .
studies on important open source software found that .
.
of bug fixes are erroneous .
frequ ent releases typically imply multiple versions exist in the field as users may have different habits to update software or the old versions need to exist to be compatible with system dependencies thus we need to ensure that common changes such as bug fixes are not only effective for a program but also for all the versions maintained.
traditional software assurance tools targeting single versions of programs are not scalable and flexible for verifying changes as such analysis can take days to terminate for large software .
even worse many warnings can be generated for the new version but it is hard to determine which warnings are relevant to the changes.
program analysis targeting software changes include impact analysis and its goal is to determine which statements in a program can be affected by a change.
yang et al.
used impact analysis to isolate the code potentially affected by the changes and performed model checking only on the impacted code .
although targeting changes this approach is still exhaustive in that it explores all the paths impacted by the change for verification.
sometimes the impact of a change can be large leading to state explosion problems .
person et al.
generate and compare symbolic signatures from function calls to determine whether the semantics of programs have been changed between versions .
the comparison is done offline in that it first analyzes each program version respectively and then compares their analysis results.
the problems of such an offline comparison are twofold.
first it redundantly detects information as the two versions share the majority of code.
second the information used to compare program properties suchpermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may june hyderabad india copyright acm ... .
as line numbers and variable names can be changed between versions and hard to match.
the goal of our work is to design program analyses targeting program changes as well as multiple versions for patch verification in this paper we use the terms patch andsoftware changes interchangeably .
specifically we aim to automatically determine whether a patch fixes a bug and whether a software change breaks existing code and introduces new bugs.
importantly we not only verify the bug fix for a program but also determine whether the fix is applicable for all the buggy releases.
we design a framework called hydrogen consisting of a program representation namely multiversion interprocedural control flow graph mvicfg that specifies the commonalities and differences of control flow for multiple program versions and a demand driven path sensitive symbolic analysis on the mvicfg for detecting bugs in program changes and multiple versions.
intuitively an mvicfg is a union of a set of interprocedural control flow graphs icfgs for program versions.
depending on applications the program versions in an mvicfg can be revisions from code repositories or software releases.
in an mvicfg a node is a program statement and we specify one node for multiple versions if the statement is not changed across the versions.
an edge specifies the control flow between the statements.
both the nodes and edges are annotated with which versions they belong to.
to build an mvicfg we first construct an icfg for a program version and then incrementally integrate control flow changes for successive versions.
using an mvicfg to verify a patch we apply an interprocedural demand driven path sensitive symbolic analysis on the mvicfg.
the analysis takes versions marked on the edges into consideration and performs either incrementally on the program changes for detecting bugs in changes or simultaneously on multiple program versions for determining bug impact and verifying patches for multiple software releases.
the novelty and importance of an mvicfg are as follows.
.representing program semantic differences mvicfgs are control flow based representations and we can easily obtain the changed program paths and thus program behaviors from the graphs for visualization and analysis.
.enabling efficient precise program verification precisely identifying bugs requires a prediction of program runtime behaviors.
we apply an interprocedural path sensitive symbolic analysis on the mvicfg for precision.
we achieve efficiency by only directing analyses along the changed program paths caching and reusing intermediate results from analyzing older versions for a new version and applying a demand driven algorithm to traverse the changed paths only relevant to the bugs.
the three approaches improve the scalability of analyses without compromising the precision and have a great potential to be useful in practice.
.correlating multiple program versions using mvicfgs the analysis not only can traverse along program execution paths but also longitudinally across program versions for comparing and sharing analysis results.
therefore we not only can compare programs at code level but also can determine the commonalities differences or changes of program properties e.g.
bugs or invariants across program versions.
.facilitating online comparisons in an mvicfg program versions are matched based on their statements.
we thus can determine the commonalities of program properties by analyzing the shared code.
meanwhile using the matched state ments we can easily report the differences between program versions.
as we mentioned before in an offline comparison we may repeatedly analyze the same code existing in many versions and have difficulties to match the generated results from different versions.
we implemented hydrogen using the microsoft phoenix infrastructure .
we experimentally demonstrate that our algorithm is scalable to build mvicfgs for real life programs such as libpng tightvnc and putty .
we randomly selected functions from the benchmark programs and manually validated the correctness of the mvicfg.
our experiments show that the integration of demanddriven path sensitive symbolic analysis and the mvicfg is feasible and efficient for detecting bugs in changes and we are able to perform patch verification for multiple versions of software releases.
before such information has to be identified manually.
in fact our experimental results show that such documentation can be buggy or incomplete.
note that in this paper we mainly focus on applying static analyses on mvicfgs for bugs such as integer overflows buffer overflows and null pointer dereferences h owever the mvicfg is a representation that may be generally applicable for a variety of program analyses e.g.
concolic testing for other types of bugs.
in summary the contributions of the paper include definition of an mvicfg the algorithm for constructing an mvicfg applications of an mvicfg for patch verification and implementation and experimental results to demonstrate the scalability and correctness of building mvicfgs and the effectiveness of applying mvicfgs to solve a set of important problems in patch verification.
the rest of the paper is organized as follows.
in section we provide an overview of the mvicfg using an example.
in sections and we present the definition and the construction of an mvicfg respectively.
in section we present the integration of a demand driven path sensitive symbolic analysis on the mvicfg for a set of important applications.
in section we describe our implementation and experimental results followed by the related work in section and conclusions in section .
.
an overview in figure we use a simple example to intuitively explain the mvicfg and how to construct and use it for patch verification.
as shown in figure a versions describe a bug fix scenario in the freebsd code repository .
in version a buffer overflow exists at line .
version introduces a fix by replacing the stack buffer with dynamically allocated heap memory however this patch does not correctly fix the bug.
version enhances the code by checking an exceptional condition but the code fails to drop the privilege along the exceptional path leading to a privilege elevation vulnerability .
this bug is fixed in version by adding a call drop privilege at line .
version also finally fixes the buffer overflow originated from version .
in figure b we show the mvicfg constructed for the versions of programs.
in the graph the statements common across versions e.g.
nodes and are only specified once.
nodes and in solid indicate the beginning of the differences.
as an example node leads the differences between version and versions .
edges are labeled with versions in figure b we1048 a versions of programs b mvicfg for the versions c constructing an mvicfg figure four versions of programs and their mvicfg only mark the edges connected to the beginning of the differences for clarity .
the edges such as angbracketleft1 angbracketright that connect changes to the new versions are specified in the dotted line in the graph.
from the graph we can obtain the changed program paths for a new version.
for example in figure b starting at node and following the versions marked on the edges we derive that path angbracketleft1 angbracketright is newly added in version .
to build an mvicfg shown in figure b we first construct an icfg for version and then incrementally add the control flow differences for the next versions.
figure c displays the process to construct an mvicfg consisting of versions and .
in the first step we identify which statements are different between the two versions shown on the top.
based on the statement differences we find the corresponding nodes and on the graphs representing the entries and exits of the differences.
in the next step we connect node in version to node in version and node in version to node in version and update the versions on the edges shown at the bottom in figure b .
we develop a demand driven path sensitive symbolic analysis on the mvicfg to verify bug fixes and detect bugs introduced by a change.
in this example to determine if the patch in version correctly fixes the buffer overflow we raise query at node in figure b .
the query is propagated backwards along path angbracketleft3 angbracketrightin version and resolved as at node indicating an off by one buffer overflow exists along path angbracketleft1 angbracketright.
thus the bug is not fixed correctly.
to detect bugs in the change added in version we first apply a reachability analysis from nodes introduced in version and determine that path angbracketleft1 angbracketrightis new to this version.
the demand driven analysis starts at get privilege at node inquiring a liveness property regarding whether a drop privilege will be called after get privilege .at node we discover drop privilege is never called along the new path angbracketleft1 angbracketright leading to a privilege elevation.
the mvicfg also can be used to determine whether a bug can impact multiple software releases and whether a patch developed based on a version can fix the bug for all the impacted releases.
to explain the use of mvicfgs in this scenario we assume versions in figure a are the three deployed software releases and the buffer overflow in version is reported by the user.
to determine which other versions the bug may impact our analysis raises query at node in figure b aiming to check for all the paths of versions reachable from node whether the buffer overflow exists.
the query is resolved at node along path angbracketleft3 angbracketrightin version and also at node along paths angbracketleft3 angbracketrightin version and angbracketleft3 angbracketrightin version indicating the bug can impact versions .
to patch the bug a common practice is to diagnose and introduce the fix based on one impacted version.
suppose in this case we develop a patch based on version where the bug is firstly discovered and the patch removes node and adds node shown in figure b .
our analysis aims to determine whether the patch developed for version can also fix the buffer overflow in versions .
from the graph we see that version does not contain node and thus the patch cannot be directly applied.
similarly we found that the patch can be applied to version without leading to a syntax error however further semantic analysis needs to be applied to confirm whether the buffer overflow in version is removed with this patch.
to do so we propagate query at node along all the paths of versions .
at node we arrive at the patch location we advance the query to node instead of node to integrate the patch.
the query is resolved at node as indicating the buffer access is safe that is the patch correctly fixed versions and .1049figure mvicfg the union of icfgs .
defining an mvicfg we aim to design the mvicfg that can satisfy the following requirements it integrates control flows of nversions of programs of interest and the differences and commonalities of the control flow between any versions are available on the graph from the mvicfg we are able to get a subgraph of the mvicfg that represents any desired m m n versions of programs and from the mvicfg we are still able to obtain the control data and value flow as well as variable dependencies that originally belong to each individual version of a program.
with the above goals we present our definition for mvicfgs.
definition anmultiversion interprocedural control flow graph mvicfg g angbracketleftn e angbracketrightis a union of g1 ...gk such that gi angbracketleftni ei angbracketrightis an icfg representing the ithversion of programpi.n niis a statement in pi.
angbracketleftn m angbracketright eiis an edge inpi.
n ni n n. angbracketleftn m angbracketright ei angbracketleftn m angbracketright e. forn matched across versions we label vn n to denote the set of program versions to which nbelongs.
similarly we label edge angbracketleftn m angbracketright withve angbracketleftn m angbracketright to denote the set of program versions to which the edge belongs.
example in figure we show that the mvicfg in figure b is a union of the icfgs of the program versions given in figure a .
in each icfg the nodes newly introduced in the current version are specified in solid and the nodes matched to previous versions are shown in grey.
the match is determined by the programmers beliefs on whether the statement is changed from the previous version to the current version.
for example in figure node is matched across versions as from the scenario in figure a we believe that the statement at line has not been changed for the versions.
using this way we only specify once for the nodes and edges commonly shared across versions.
since we annotate nodes and edges with the version numbers the control flow information is not lost in the mvicfg when we perform a union for a set of icfgs .
.
constructing an mvicfg here we present our approach for constructing an mvicfg.
.
an overall approach to construct an mvicfg we identify what are the common nodes between versions and we then incrementally add the control flow changes from new versions on top of the in progress mvicfg.
shown in figure we take steps to integrate a new version to an mvicfg.
in the first step we identify the differences between the nthversion the version we aim to integrate and then 1thversion the last version integrated on the in progress mvicfg.
to do so we first determine whether in a new version a function is added removed or updated.
for an updated function we report which statements are added and or removed.
we choose to compare the functions of the two versions statement by statement rather than line by line directly from the source code because in a cfg each node is a statement and the added and or removed statements identified from this step will be used in the next step to construct control flow that can be integrated to the mvicfg.
in the second step we identify the change of control flow between the two versions.
our approach is to first build cfgs for the newly added code as well as the code after deletion.
next we find where on the mvicfg the new statements should be added and we connect the mvicfg nodes to the corresponding entries and exits of the new code.
similarly we identify on the mvicfg which nodes are deleted.
we then compare the cfg of the new version to adjust the corresponding mvicfg edges.
our final step is to update the version information for all the edges and nodes in the updated functions.
.
the algorithm we provide further details on how to construct an mvicfg in algorithm .
the input of the algorithm is nversions of source code and the output is an mvicfg.
at line we first build an icfg for the first version.
lines handle a version a time and1050figure building mvicfgs algorithm construct an mvicfg for nprogram versions input nversions of source code v1 v2 ... vn output the mvicfg that integrates v1 v2 ... vn 1mvicfg buildicfg v1 2foreach new version vido d generatediffs vi vi foreach diff ddo ifadd or update a function then cfg buildcfg diff.func ifadd statements then addtomvicfg cfg mvicfg diff ifdelete statements then deletefrommvicfg cfg mvicfg diff end 11end 12procedure addtomvicfg cfg cfg cfg mvicfg diff d 13n identifyaddednodes cfg d 14foreach n ndo t pred n cfg succ n cfg foreach t t and t ndo t findmatchednode t d mvicfg addedge t n end updateversion n 20end 21procedure deletefrommvicfg cfg cfg cfg mvicfg diff d 22n identifydeletednodes mvicfg d 23foreach n n and n mvicfg do ifn has a successor or predecessor in n then n findmatchednode n d cfg foreach m pred n cfg succ n cfg do m findmatchednode m d mvicfg ifno edge between m n on mvicfg then addedge n m end end updateversion n 32end incrementally integrate the differences from the next versions.
generatediffs at line accomplishes two tasks.
first it determines whether in a new version a function is added removed or updated by comparing function signatures from the two versions.
a function is added if the function signature only appears in the new version similarly a function is deleted if the function signature only exists in the old version.
if the function signature has not been changed but the statements in the function body are different we consider the function is updated.
for an updated function we further identify which statements are added and or deleted in the new version.
to obtain statement differences we use a parser to generate a text file for each function where each line contains a statement.
we then use a unix diff tool to compare the two textual files to determine which statements are added and or removed in the function in version n. buildcfg at line constructs control flow graphs for the updated code in the new version.
theoretically we just need to constructcontrol flow for the code involved in the change.
in practice we have not found a tool that can build a cfg for any selected section of statements.
thus in our implementation we build a cfg for the complete updated function and mark the added and removed nodes on the cfg.
addtomvicfg at lines takes cfg the control flow graph built for the updated function mvicfg the in progress mvicfg built for the previous versions and d the statement differences including both added and removed statements in a new version of the function.
the goal is to identify the control flow for newly added code from cfgbased on dand append it to mvicfg .
at line we first identify on cfgthe set of nodes that are newly added these nodes should be linked in to mvicfg .
to find their successors and predecessors on mvicfg our approach is to first find their successors and predecessors on cfg see lines .
we then map these entries and exits of the differences to mvicfg see line and connect them to the new statements in cfg.
at line we update the version information for the nodes and edges related to the change.
updateversion at line records in which version a node in the mvicfg is introduced and removed that is which versions the nodes and edges belong to.
to handle deletion we do not need to add or remove nodes from the in progress mvicfg.
instead we just need to update the edges and versions that can reflect the control flow change.
details are given in deletefrommvicfg at lines .
at line we first detect n the set of deleted nodes on mvicfg .
at lines we find the predecessors and successors of the deleted nodes on mvicfg and determine if any edge needed to be adjusted regarding these nodes for representing the new version.
to do so we map these predecessors and successors on mvicfg tocfgat line and find their corresponding edges on cfg if any at line .
if we find such edges at line we add them on mvicfg .
at line we traverse the deleted nodes and edges to update the versions.
we believe that algorithm builds an mvicfg that can satisfy the requirements and definition shown in section .
first in our approach we classify software changes into adding removing and updating a function and for the updated function we further classify whether the update is an addition and or removal of the statements.
if a function is added or removed in a new version and it is not dead code the caller s of this function is surely updated by adding or removing a callsite of this function.
thus after building cfgs for the newly added function see line algorithm the case of adding or removing a function can be reduced to how to integrate an updated function in the mvicfg.
for the two types of changes adding and removing statements we handle addition at line and deletion at line in algorithm .
second the mvicfg is defined by the nodes and edges as well as the versions marked on these nodes and edges.
although in the implementation we built cfgs for the complete updated functions rather than only for the changed code only the nodes and edges labeled with version information are linked into the mvicfg.
third we use statement differences to determine control flow differences between versions.
although statements might have an ambiguous definition and may mean differently in different languages the key is that the statements we used to report the differences are the same as the statements constructed in our cfg nodes.
finally to determine the match between the nodes in program versions we use a unix diff tool to detect the differences between statement sequences.
the tool implements a longest common subsequence algorithm .
our assumption is that the differences detected by such algorithm are consistent with the programmers intention on which statement is changed.
.
applications of an mvicfg the mvicfg is a control flow based program representation for specifying software changes and comparing program versions.
the goal is to extend program analysis applicable on icfgs to mvicfgs and determine program properties related to program changes and versions.
here we present an integration of a demanddriven path sensitive symbolic analysis with the mvicfg for a set of important tasks in patch verification.
.
demand driven path sensitive analysis demand driven analysis formulates a demand into queries about program facts.
we thus can determine program properties by performing a traversal of a program that is only relevant to resolving the query for efficiency.
demand driven analysis is a natural fit for the patch verification problem because not only bugs but also program changes are likely to be sparsely distributed in the code.
not every execution path in a program or every statement along the path is relevant to the bugs or changes.
therefore a search from the program points of interest of bugs and changes in a demand driven fashion on the parts of the paths that are relevant may greatly improve the scalability of the analysis.
with the efficiency achieved we then potentially afford more precise expensive analysis such as interprocedural context sensitive path sensitive symbolic analysis to reduce false positives and false negatives of bug detection.
demand driven analysis formulates bug detection to queries at potentially faulty statements pfs where a faulty condition e.g.
a buffer overflow can be perceived .
we have identified for a set of common bugs the types of pfss and the queries that can be raised at these statements .
for instance to detect buffer overflow we raise a query at the buffer access inquiring whether the buffer safety constraints can be violated.
to detect the bug we traverse all the paths to this buffer access to resolve the queries.
applying to detect bugs in changes we only need to find pfss along the changed program paths identified on the mvicfg.
path sensitive analysis tracks program facts along actual program paths.
path sensitive analysis is potentially precise to predict runtime program behavior because it does not merge queries from different paths and it excludes any statically detectable infeasible paths.
unlike on icfgs where any path in the graph represents a program path on an mvicfg the edges along a path may belong to different versions of programs.
thus the challenge of applying path sensitive analysis on the mvicfg is to ensure the propagation of program facts is always along the edges of the same program versions.
demand driven path sensitive symbolic analyses have been successfully applied for detecting bugs for single versions of programs .
we thus take the design decisions of handling loops procedures and infeasible paths shown to be scalable and effective for analyzing single versions of programs to design analyses on mvcifgs.
specifically to handle loops we first traverse a loop once to determine if the loop has an impact on the query and if so what is the symbolic change for the query through one iteration.
meanwhile we identify the symbolic loop iterations if possible.
if both the loop impact and iterations are successfully identified we then determine the symbolic update of a query in the loop.
driven by the demand we only need to reason the loops that can have an impact on the query.
for handling procedural calls our approach is an interprocedural context sensitive analysis.
in a backward demand driven analysis we propagate the query to its original caller at the entry of the procedural call.
our interprocedural analysis is also demand driven in that we only propagate a query into a procedure from the callsite if it is determined to have an impact on the query.
to reduce the false positives caused by in feasible paths we first identify infeasible paths based on a branch correlation algorithm and mark them on the mvicfg .
we only propagate the query along feasible paths during bug detection.
.
automatic patch verification we apply demand driven path sensitive analyses on mvicfgs for a set of patch verification tasks.
first we develop incremental analysis targeting differences between any specified versions for verifying bug fixes and detecting bugs in changes.
second we develop multiversion analysis that can simultaneously analyze a set of program versions to determine which software releases a bug may impact and whether a bug fix introduced for a version can potentially correct other impacted versions.
.
.
mvicfgs for incremental analysis incremental analysis is designed for the following two tasks.
detecting bugs in changes we need to quickly verify program changes in two scenarios.
in one scenario developers finish some changes and want to know if their code introduces new bugs and breaks the existing program.
in this case the code server can maintain the most up to date mvicfg for previous revisions.
when the code is checked in we incrementally integrate the new code on the mvicfg and invoke the analysis to detect bugs along the changed program paths.
in another case developers are merging a set of changes to a branch or mainline in the code repository.
the analysis aims to detect semantic merge conflicts that a compiler is not able to report e.g.
the merge can cause a memory leak.
we will construct an mvicfg consisting of revisions before and after the changes.
developers have flexibility in choosing how much change to be verified by selecting appropriate revisions from the code repository.
in this paper we focus to design static analysis on mvicfgs for detecting bugs such as null pointer dereferences buffer overflows integer overflows and memory leaks.
these bugs can cause programs to crash and thus are very important to be found at the early stage of the software development.
verifying bug fixes.
a certain type of code changes focuses to correct a bug.
typically it is urgent to release such bug fixes and thus we need to quickly verify whether the patch actually fixes the bug.
as opposed to detecting bugs in changes in this case we know where in the code the bug is located.
the goal of our analysis is to show that integrating the patch the bug no longer exists.
instead of analyzing the changed paths for bugs we start at the pfs where the bug is given and verify if the safety constraints for the bug can be satisfied.
note that sometimes the patch ships the bug fixes with other functionality enhancement.
using this approach we still can quickly verify if the patch correctly fixes the bug.
a key step for incremental analysis is to raise a query at a pfs and determine its resolutions along the changed paths for bugs that is on the mvicfg the analysis needs to propagate a query along a particular version.
in figure a we select nodes from figure b as an example to explain how we perform incremental analysis to verify whether version fixes the buffer overflow in version .
shown in figure a we raise a query at node and as a part of the query we include which versions the query aims to propagate.
at node the query can be advanced to nodes and .
to determine which edge is legitimate we compare the versions marked on the edges angbracketleft3 angbracketright angbracketleft3 angbracketrightand angbracketleft3 angbracketrightwith the version s stored in the query.
specifically we perform an intersection for the set of versions from the edges and the one tracked in the query if the intersection is not an empty set we propagate the query onto the edge.
using this approach the path angbracketleft3 angbracketrightis selected for verifying the bug fix for version .
a verify fixes detect bugs in change b determine bug impact for multiple releases c verify patch for multiple releases figure select paths on an mvicfg based on versions on an mvicfg we can use three approaches to determine the bug for the change change based exhaustive analysis similar to the one implemented in the yang et al.
s incremental model checking change based demand driven analysis the basic demand driven algorithm we explained above and cache based demand driven analysis a further optimized approach we develop for the hydrogen framework.
in figure we provide more details for the three approaches using an example in figure .
suppose our goal is to verify if the patch in version can correct the buffer overflow in version .
in a change based exhaustive analysis shown in figure a we would first identify paths angbracketleft1 angbracketright and angbracketleft1 angbracketrightas being impacted by the change introduced at node .
we then start the analysis at node and exhaustively collect information at each node along the two paths until node is reached.
in the worst case we may have visited nodes and shown in figure a and even in the best case we need to visit nodes and .
the change based demand driven analysis shown in figure b would identify that path angbracketleft1 angbracketrightis impacted by the change and contains the pfs for a potential buffer overflow.
the analysis starts at node and collects information in a demanddriven fashion along angbracketleft3 angbracketright.
at node the query resolution is determined and thus the analysis is terminated.
note that to detect bugs in changes we would raise queries for all the pfss along the impacted paths.
since the query may be resolved by only propagating along the old code of the path the change based analysis is not most economical for only focusing on changes.
the most efficient analysis is the cache based demand driven analysis shown in figure c .
here we cache and reuse all the intermediate results obtained from analyzing previous versions on an mvicfg.
when analyzing a new version we raise queries at pfss located in the new code.
meanwhile we advance the cached queries previously computed at the interface of the old and new code for new resolutions.
for example in figure c query has been propagated to node when analyzing version .
to verify the bug fix in version we can directly advance this intermediate result to node to determine the correctness of the buffer access at node rather than restarting the analysis from node .
as a result we only visit node for verifying the bug fix in version .
.
.
mvicfgs for multiversion analysis here we explain multiversion analysis for patch verification tasks related to multiple software releases.
determining bug impact for multiple releases.
we will re port bug impact as to which releases a bug can affect.
knowing which versions are impacted we can determine how to develop the fixes and also notify the affected users to patch the bugs on time.
our approach is to first construct an mvicfg consisting of a set of software releases.
on the mvicfg we find the pfs where the bug is located from which we simultaneously analyze the paths of all versions reachable to this pfs to determine the bug impact.
in figure b suppose the bug is reported in version at node .
our interest is to determine which other versions this bug may impact.
we start the analysis at node and propagate the query along paths of all versions.
during the query propagation we compare the versions stored in the query with the versions marked on the edges and only advance the query if the intersection of the two sets is not empty shown in figure b .
by so we make sure the query is propagated along legitimate paths of the same versions.
verifying patches for multiple releases.
different projects may have different conventions to patch their programs dependent on their branch structures.
a typical practice is as follows.
a reported failure is first dispatched to the owner of the code.
the developer diagnoses the failure and develops the patch based on the program version where a failure occurred.
the patches are then merged to the mainline or the relevant branches where a bug is affected.
determining whether a patch can fix a bug for all the affected versions is challenging because a semantic bug such as buffer overflow is not a local property.
even though a local function is never changed across versions and the patch is merged to all the versions without a syntax error it does not mean the bug fix is generally applicable for all the impacted versions.
we need an interprocuedural semantic analysis for further confirmation.
to verify a patch for multiple releases we first integrate the patch to the mvicfg that consists of a set of releases.
we then determine for each release whether the bug is successfully fixed after integrating the patch.
in figure c versions contain a buffer overflow at node .
suppose a patch is developed based on version which removes node and adds node .
first from the graph we find that the patch is not reachable from any paths of version and thus it is not directly applicable to version .
in the next step we determine whether the bug in versions and can be fixed by this patch.
we raise the query at node and propagate it along paths of versions .
at node where the patch is encountered we continue advancing the query to the patched code node rather than node the old code that belongs to versions .
notations and in the figure mean at node we use the patched code in version to replace node for determining the bug.
at node we resolve the query and determine the buffer overflow is fixed.
a change based exhaustive analysis b change based demand driven analysis c cache based demand driven analysis figure efficiency via caching intermediate results on the mvicfg comparing nodes visited in three types of analyses .
experimental results the general goals of our experiments are to demonstrate that an mvicfg can be correctly built and the algorithm is scalable for real life programs and also to show the mvicfg is practically useful for a set of important tasks of patch verification.
.
implementation and experiment setup hydrogen consists of two components the construction and the analysis of an mvicfg.
we implemented both of the components using the microsoft phoenix infrastructure and we used the microsoft disolver as a constraint solver for bug detection.
thus hydrogen can handle c c c programs.
to generate the differences between versions we first preprocessed the sourc e code.
we then used srcml to parse the programs for functions and applied the unix diff on the functions to determine the added and removed statements in a new version.
we collect a set of benchmarks each of which contains multiple versions of programs.
tcas schedule gzip andprinttokens are obtained from the sir benchmark and programs for libpng tightvnc andputty are revisions and releases selected from the realworld code repositories.
we designed three experiments.
in the first experiment we measured the time and memory used to build an mvicfg to determine the scalability of the mvicfg construction.
in the second experiment we found a set of known bugs and their patches from the common vulnerability exposure cve bugzilla as well as the projects revision histories.
we ran hydrogen to determine whether these patches correctly fixed the bugs.
furthermore we randomly selected a set of releases and determine whether the bugs can impact these versions and if so whether the patch can also be applied to correct these impacted versions.
in both of the cases we compare our results with the documentation.
in the third experiment we demonstrate our capabilities in detecting bugs in the changes and we compare change based and cache based deman ddriven analyses to demonstrate the efficiency of our approach.
in the following we provide detailed results for the three experiments.table scalability of building mvicfgs benchmark v loc churn icfgs mvicfg t s m mb tcas .
.
k .
.
schedule .
k .
.
printtokens .
k .
.
gzip .
k .
k .
k .
.
tightvnc .
k .
.
k .
k .
.
libpng .
k .
k .
k .
k .
.
putty .
k .
k .
k .
k .
.
.
experimental results .
.
building mvicfgs table presents the data collected from constructing mvicfgs.
under vand loc we show the number of program versions used and the size of the first version in the benchmarks.
under churn we report the average number of added and removed statements between any two consecutive versions.
comparing columns icfgs the total number of nodes on the icfgs for all the versions andmvicfg the number of nodes in the mvicfg we show an mvicfg is able to identify the commonalities across the versions and thus largely reduce the redundancies in representing control flow for a set of programs.
we report the time and memory overhead under tin terms of seconds and min terms of megabytes.
the results are collected from dual intel xeon e5520 cpu processors running at .
ghz with .
gb of ram.
we show that building mvicfgs is scalable for real life programs.
for example it only takes .
minutes to build the mvicfg for versions of libpng .
it takes about half an hour to handle putty .
we found much time has been spent on reading pre build cfgs of different versions from files as phoenix cannot build cfgs for multiple versions in a single run.
to determine the correctness of the mvicfg we have performed manual validation on the selected parts of mvicfgs.
.
.
determining bug impact and verifying fixes in table we demonstrate the usefulness of the mvicfg in determining bug impact and the correctness of the bug fixes.
we1054table determining bug impact and verifying fixes documented incremental analysis multiversion analysis buggy version detected bugs t s fixed t s releases doc impacted t s fixed t s gzip .
.
buffer overflow .
yes .
.
.
libpng .
.
integer overflow .
no .
.
.
libpng .
.
integer overflow .
yes .
.
.
tightvnc .
.
integer signedness .
yes .
putty .
null pointer deref .
yes .
.
.
construct an mvicfg consisting of the buggy version shown underdocumented buggy version its corresponding patched version and a set of releases.
the documentation provides the location of the bug in the source code and also the types of the bug.
under detected bugs we list a set of documented bugs confirmed by hydrogen.
under fixed we show whether the patches correctly fixed the bugs.
under t s we report the time in seconds used to detect the bugs and verify the fixes.
our results show that using incremental analysis hydrogen can quickly verify the fixes for a set of real life bugs including buffer overflows integer overflows integer signedness conversion problems and null pointer dereferences .
the integer overflows in libpng shown in the 2ndand3rdrows in the table are the same bug located in different revisions reported from libpng .
.
.
we correctly identified that this integer overflow is not correctly fixed by the first patch see row and then correctly fixed by the second patch see row .
we report our analysis results for multiple versions of programs under multiversion analysis .
under total v we list the number of releases integrated on the mvicfg.
under doc andimpacted we compare the documented results with the results hydrogen reports regarding how many of such releases are impacted by the bug.
our data show that hydrogen detected more releases impacted by the bug than the documentation says.
after manually inspecting the results we find that hydrogen correctly reported all the impacted versions and the documentation is incomplete.
the manual inspection finds that the second patch for the integer overflow of libpng successfully fixed all the versions and we reported shown in the 3rd row.
the imprecision is caused by the fact that phoenix does not provide the information for a structure member needed for correctness.
we run this experiments on a windows machine with duo intel core i7 cpu and .
gb memory.
columns t s show that our analysis is very efficient and reports the results in seconds for large programs and for multiple versions.
an interesting case we found in our experiments is that libpng .
.
was released after the patch for libpng .
.
was developed.
we would have assumed that the libpng .
.
was already patched however hydrogen reports that the bug still exists inlibpng .
.
.
we found in the code comments developers have written todo fix the potential overflow .
this indicates that manual patch management can be error prone and we need tools such as hydrogen to provide automatic support for tasks of determining the bug impact and propagating the patches across branches.
.
.
detecting bugs in changes in this experiment we randomly selected two versions of the benchmark programs shown under benchmark versions and performed change based and cache based analyses on detecting bugs for the changes between the two versions.
we focused on the three types of bugs buffer overflows integer overflows and null pointer dereferences.
in table under total pfs we list the number of pfss reported for the three types for analyzing the entire version of the program.
compared to the pfss detected in the cache basedanalysis and change based analysis shown under pfs the data suggest that we can significantly benefit from program analysis targeting changes for verifying a new version.
in addition to pfs we identified the other three metrics for comparing efficiency.
under v bandv p we report the number of blocks and procedures visited during the analysis and under t s we give the time used to run the analysis.
under w we list the number of warnings reported.
our experimental results show that we can detect bugs in changes in seconds for most of the benchmarks using both of the analyses.
the efficiency of the analysis provides promising evidences that we can potentially deploy such analysis at the code check in time to verify changes and provide developers immediate feedback.
the results further show that cache based analysis is more efficient than change based analysis.
for putty the changebased analysis runs out of memory and we thus are not able to obtain the bug detection results.
however in the cache based analysis we still verified all the pfss in changes for bugs although our analysis for computing the cached queries is terminated before traversing all the paths and we may miss bugs related to changes.
the experimental results also demonstrate that the cache based analysis reports fewer warnings and provides more focuses on confirming and diagnosing the bugs.
we manually confirmed the warnings generated from the cache based analysis.
we found that the warnings we identified for libpng are all real integer overflows.
in fact are related to a vulnerability reported we did not know the bug before detecting it and one are related to the memory allocation size that potentially can cause a buffer overflow.
the buffer overflow reported for putty are false positives due to the lack of precise pointer analysis.
.
summary and discussions in this section we provided experimental evidences to show that the construction of an mvicfg is scalable correct and useful tables and .
we have used a set of real life programs bugs and patches to demonstrate that we are able to automatically perform patch verification and identify the information that is missing in the documentation.
we are also able to efficiently find bugs in the changes compared to other approaches.
intuitively an mvicfg is a compact representation that specifies the control flow differences and commonalities for a set of programs.
when the programs integrated on the mvicfg share the majority of code the analysis can benefit most by reusing the intermediate analysis results across versions.
the mvicfg represents fine grain semantic comparisons such as control flow differences within a function thus it effectively characterizes the behavioral differences for program versions that contain many small changes in between.
meanwhile the coarse grain changes such as adding or removing functions are also available on the mvicfg and we can perform analysis to determine properties for such changes as well e.g.
which calls can be impacted by the newly added function.
through the experimentation we have also found a set of potential improvements we can make for the mvicfg.
first in our1055table detecting bugs in changes benchmark versionstotal cache based demand driven analysis change based demand driven analysis pfs pfs v b v p t s w pfs v b v p t s w tcas .
.
schedule .
.
printtokens .
.
gzip .
.
.
.
.
.
k .
tightvnc .
.
.
.
.
.
libpng .
.
.
.
.
k .
k .
.
k .
k .
putty .
.
.
k .
current approach of building an mvicfg we integrate one version a time and compare the statements between versions to determine the changes.
although the mvicfg built can satisfy the requirements see section and correctly perform the patch verification shown above the change specified on the mvicfg may not always reflect programmers intention on what is the change.
consider in version we delete a statement and then we add the statement back in version .
on the current mvicfg we would integrate a deletion between versions and and then an addition between versions and .
the match between any non consecutive versions is not directly shown on the graph unless we compare the program with all the other versions rather than just with its previous version.
in addition analyzing the mvicfg we can further improve the precision by performing an alias analysis on the mvicfg.
.
related work in the keynote at the paste workshop in notkin proposed the concept of longitudinal program analysis and the need for reuse and learning information retained from earlier analysis to a new version of software .
the mvicfg is a program representation to enable such analyses.
the mvicfg is related to techniques on representing program differences analyzing program changes an d software history and also detecting bugs in the programs.
in the following we present the comparisons of these areas and our work.
program differencing.
previous techniques on comparing programs mainly focus on two versions .
the mvicfgs enable the comparisons for multiple versions and characterize behavioral differences.
we highlight three representative solutions closely related to the mvicfg.
horwitz et al.
performed code differencing on dependency graphs to determine noninterference changes .
dependency graphs are adequate to determine whether a change impact exists but not able to provide further reasoning on the changes of program properties as we have done.
raghavan et al.
applied graph differencing algorithms on abstract semantic graphs asg .
the asg is an abstract syntax tree annotated with semantic information.
the differences available via asgs do not include the comparisons on important semantics such as program paths.
apiwattanapong et al.
performed the comparisons on control flow graphs using hammock based approaches .
the differences are marked on the individual control flow graphs rather than displaying in a union representation like mvicfgs that can enable program analyses.
program analysis and testing on changes.
a foundation of change based program analysis is impact analysis a type of dependency analysis that determines the propagation of change effects for solving problems such as regression testing .
here we compare the two most relevant change based program analyses.
person et al.
conducted program differencing on symbolic execution trees and applied it for selecting regressiontest cases .
the comparison exhaustively collects symbolic signatures and has not shown scalability on interprocedural analysis.
yang et al.
used impact analysis to isolate the code potentially affected by the changes and performed model checking only on the impacted code .
on the mvicfgs the changed paths can be identified via a reachability analysis and we can easily cache and reuse the analysis results from previous versions.
based on a demand driven algorithm our incremental analysis is believed to be more scalable and flexible than the two above approaches.
multiple versions and software history.
research interests on program languages and analysis for multiple versions and software history are mostly recent .
erwig et al.
developed choice calculus a language for manually specifying software variants with the goal of better developing changes.
our approach does not involve manual effort for specifying the differences.
servant et al.
proposed history slicing showing how the same code locations evolve in terms of definition and use of the variables.
we are able to identify such information with hydrogen and expect to be more precise with the path sensitive demand driven symbolic analysis on mvicfgs.
static bug detection.
due to its importance there has been much work on bug detection and diagnosis .
among the techniques demand driven has shown scalability and path sensitive analysis has the advantages of being precise and able to provide rich information .
.
conclusions this paper presents a program representation the mvicfg that specifies software changes and compares program versions using program control flow and a demand driven path sensitive symbolic analysis on the mvicfg that determines the commonalities and differences of program properties for a set of program versions.
the key impact of an mvicfg is twofold.
first it enables reuse of the program analysis results from previous versions for scalable yet still precise program verification to solve software assurance problems related to incremental software development process.
second it makes possible not only analyze programs along their execution paths but also longitudinally across program versions for efficient online comparisons of advanced pro gram properties.
we demonstrate the usefulness and practicability of the framework for a set of important problems related to patch verification.
in the future we will further explore other types of program analyses on mvicfgs to determine program properties related to software changes and program versions.
.