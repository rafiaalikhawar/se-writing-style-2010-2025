brownout building more robust cloud applications cristian klein ume university sweden cristian.klein cs.umu.semartina maggio lund university sweden martina control.lth.se karl erik rz n lund university sweden karlerik control.lth.sefrancisco hern ndez rodriguez ume university sweden francisco cs.umu.se abstract self adaptation is a first class concern for cloud applications which should be able to withstand diverse runtime changes.
variations are simultaneously happening both at the cloud infrastructure level for example hardware failures and at the user workload level flash crowds.
however robustly withstanding extreme variability requires costly hardware over provisioning.
in this paper we introduce a self adaptation programming paradigm called brownout .
using this paradigm applications can be designed to robustly withstand unpredictable runtime variations without over provisioning.
the paradigm is based on optional code that can be dynamically deactivated through decisions based on control theory.
we modified two popular web application prototypes rubis and rubbos with less than lines of code to make them brownout compliant.
experiments show that brownout selfadaptation dramatically improves the ability to withstand flashcrowds and hardware failures.
categories and subject descriptors d. .
programming techniques distributed programming d. .
design methodologies general terms design experimentation theory performance keywords adaptive software control theory brownout cloud .
introduction many modern software applications are developed for the cloud .
in fact cloud computing is expected to be one of the first technologies that will drive the future economy .
in addition to traditional requirements cloud applications have dynamic loads and variable number of users therefore dynamic resource capacity requirements .
moreover they also need to be designed to robustly handle unexpected events unexpected peaks also called flash crowds may increase the volume of requests by up to permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
icse may june hyderabad india copyright acm ... .
.
times .
similarly unexpected hardware failures in data centers are the norm rather than an exception .
also unexpected performance degradations may arise due to workload consolidation and the resulting interference among co located applications .
these phenomena are well known therefore software is readily designed and deployed to cope with them.
for example techniques such as elasticity replication dynamic binding and dynamic load balancing allow to overcome unexpected events as long as resource capacity is sufficient .
however given the large magnitude and the relatively short duration of such unexpected events it is often economically unfeasible or too costly to provision enough capacity.
as a result the application can saturate i.e.
it can become unable to serve users in a timely manner.
some users may experience high latencies while others may not receive any service at all.
hence the application owner may lose customers and profits.
we argue that it is more profitable to downgrade user experience thus serving a larger amount of clients.
to allow applications to more robustly handle unexpected events and avoid saturation we propose a new programming paradigm called brownout .
our work borrows on the concept of brownout in electrical grids.
brownouts are intentional voltage drops often used to prevent blackouts through load reduction in case of emergency.
in such a situation incandescent light bulbs dim emitting less light and consuming less power hence originating the term.
we define a cloud application as brownout compliant if it can gradually downgrade user experience to avoid saturation.
for example online shops usually offer end users recommendations of similar products they might be interested in.
no doubt recommender engines greatly increase the user experience which translates to higher owner revenue.
in fact a study found an increase of on song sales when a group of users where exposed to recommendations .
however due to their sophistication such engines are highly demanding on computing resources .
the developer can specify that the execution of the recommender engine is optional.
by selectively activating or deactivating optional components the application s capacity requirements can be controlled at the expense of end user experience without compromising the functional requirements.
to lower the maintenance effort brownouts should be automatically triggered.
this would enable cloud applications to rapidly and robustly avoid saturation due to unexpected environmental changes lowering the burden on human operators.
in other words the application should be self adaptive .
designing brownout compliant applications brings the design of the runtime behavior of the application itself into the software design .
contributions in this article we introduce a paradigm to design and develop cloud applications based on the concept of brownouts.
brownout compliant applications can change their resource capac permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may june hyderabad india copyright acm ... .
ity requirements and automatically adjust to changing conditions of its environment.
hence we add a new mechanism to enable design and development of self adaptive applications.
first we discuss a model that captures the behavior of a typical cloud application with optional computation that can be activated or deactivated at runtime.
second we synthesize a control theoretical solution to automatically decide when to activate those optional features.
control theory allows us to provide specific guarantees on desirable properties such as user perceived latency.
this directly translates into withstanding unexpected events more robustly.
our paper offers the following contributions.
it proposes a model for cloud applications with optional components.
applications are extended with a dynamic parameter the dimmer q that monotonically affects both the enduser experience and the computing capacity required by the application section .
it synthesizes a controller to automatically adapt the dimmer to cope with the incoming workload and the available resources with formal convergence proof section .
it shows the applicability of the brownout paradigm extending two popular cloud benchmarks rubis and rubbos with few non intrusive changes section .
it presents experimental results showing the behavior of the self adaptive applications in comparison to their nonadaptive counterpart as suggested in .
brownoutcompliant applications more robustly withstand unexpected events like peak loads and resource shortages section .
the results show that using the brownout paradigm applications can support more users or run on less resources while maximizing user experience.
hence our proposition enables cloud infrastructures to more robustly deal with unexpected peaks or unexpected failures requiring less spare capacity.
to foster further research on application brownouts and to make our results reproducible we released all source code1.
.
application model in this section we define the theoretical foundations of the brownout paradigm discussing the methodology of making applications brownout compliant.
cloud applications serve multiple users through the internet.
their computations are generally separated into independent and stateless user requests that after being processed provide responses .
an essential requirement of these applications is that responses should be produced in a time sensitive way otherwise unsatisfied users would abandon the service.
indeed a study on web user behavior found a tolerable waiting time between and seconds .
with this model in mind brownout can be added to applications in three steps.
step .
the application designer needs to identify which part of the response can be considered optional.
in fact it is good engineering practice to decompose the act of serving a request into different software components each dealing with a different part of the response.
some of these components produce data that are necessary to satisfy the user s request while other provide accessory information that merely improve user experience.
in a brownout compliant application software components are isolated to make it possible to activate or deactivate the optional computation per request.
being able to run optional computations is desirable as they would improve end user experience.
however in case of an unexpected event it is preferable to deactivate computations instead of saturating the application due to insufficient hardware resources and providing a response after the tolerable waiting time of the user has expired.
deciding activation of optional components for each request allows us to make more fine grained trade offs.
for example instead of completely deactivating optional components the application may serve every second user with the optional part thus avoiding saturations but still improving the experience of some users.
step .
the designer needs to provide a knob to control how often the optional computations are executed.
applications export a dynamically changeable runtime parameter a dimmer q which monotonically affects both the average quality of the user experience and the amount of resources that the application requires.
this allows a specialized component called the controller to monitor the application and adjust the application s behavior as needed see step .
more formally the number of times that these optional computations are executed between time kandk and thus the amount of resources required by the application is proportional to qk the dimmer s value during that time interval2.
to adhere to the stateless request model for each request the optional component can be activated depending on the outcome of a single bernoulli trial with success probability qk.
to clarify the concepts just introduced we sketch an e commerce website as an example of a brownout compliant application.
in the e commerce website we consider the visualization of a page containing one specific product as one request.
the optional part of the response consists in displaying recommendations of similar products.
for each request besides retrieving the product information the application runs the recommender engine with a probability q. increasing qincreases the number of times recommendations are displayed thus improving end user experience but also the resource requirements of the application.
in the end the resource requirements will be roughly proportional to q. we propose another example to show that the brownout paradigm can handle different performance measures and different application engineering concepts.
a music streaming service such as spotify serves two types of audio files songs that the user chooses to listen to and ads.
since they are simultaneously requested by a large number of users songs can often be served in a peer to peer fashion without consuming the service owner s bandwidth.
in contrast ads are personalized for each user and premium users do not have to listen to them at all.
ads therefore need to be served from the servers operated by the owner.
in this case we consider the streaming of a song as a single request which may be preceded by an ad.
since it is the heart of the business model the service owner would like to serve as many ads as possible.
however it might be better to make serving ads optional and stop serving them in case of insufficient bandwidth than to damage the service s reputation due to interrupted song streaming.
thus the associated performance is the delivered streaming bandwidth directly affecting user satisfaction while the dimmer qis the probability of serving an ad before streaming a song affecting the service s profit.
step .
for reduced burden on the human operator the application should be self adaptive.
a new component called the controller is added to achieve this.
its goal is to adjust the dimmer exported during the second step as a function of the current performance e.g.
response time to avoid saturation.
let us illustrate the interest of self adaptation through numerical examples obtained with our extended version of the rubis ecommerce website.
let us assume that a constant number of users is accessing the cloud application.
due to various unexpected phe2in the entire paper we use superscripts to indicate time indexes.
0510resources latency .51rec 010203040throughout triangle a with all recommendations 0510resources latency .51rec 010203040throughout triangle b with no recommendations 0510resources latency .51rec 010203040throughout triangle c self adaptive figure stress testing rubis extended with our recommender engine.
the number of users is kept constant and the amount of cpu allocated is reduced.
throughput reduction and response time increase show the point where the application is saturated.
nomena such as cooling failure hardware failure performance interference etc.
the amount of resources allocated to the application may be arbitrarily reduced.
since a usual application serves recommendations to all users it would become saturated when the allocated cpu is lower than i.e.
cores .
effectively the application cannot respond to user requests as quickly as they are issued therefore some users experience high latencies while others perceive the applications as unavailable .
the applicationless robustly withstands unexpected capacity reductions.
to deal with the lack of capacity and restore the application s responsiveness a system administrator could decide to completely disable recommendations .
this way the application would be responsive as long as it has at least cpu.
effectively by disabling recommendations the application can withstand a further capacity reduction of times i.e.
from to .
nevertheless adopting such a manual solution has several deficiencies.
first it requires an administrator to constantly monitor the application and react.
second no users would receive recommendations even if there would be extra capacity to serve for example every second user with recommendations.
therefore manually deactivating or activating optional code is not a viable solution.
avoiding manual intervention a self adaptive application would dynamically adjust the dimmer as available capacity allows .
effectively as the amount of cpu allocated to the application is reduced the application would transition from serving recommendations to all users to serving recommendations to some users to serving no recommendations at all.
the application more robustly withstands unexpected resource capacity reductions.
selfadaptation would require some headroom in our case the amount of cpu needs to be above instead of without recommendations.
however we believe the headroom is small when compared to the self adaptation benefits.
we obtained similar figures with an increase in the number of users and constant resources as happens with flash crowds sudden increases of popularity of the application when linked from a high profile website.
with no recommendations rubis saturates with times more users than if recommendations are always enabled whereas a self adaptive approach allows a fold increase in users.
hence the brownout paradigm enables cloud applications to better withstand unexpected events either load increase or hardware capacity reductions by gradually reducing user experience.
from an engineering point of view the brownout paradigm also encourages modularity and separation of concerns.
existing applications only need to be augmented with the choice of which code is optional and how to deactivate it while a separate controller cantake care of when to execute the optional components.
in the next section we discuss how to build a controller that automatically selects the dimmer for a vast class of applications providing formal guarantees on its behavior.
.
controller design cloud applications usually run in virtualized environments where a hypervisor multiplexes hardware resources among multiple virtual machines vms .
this makes avoiding saturation more challenging due to the inherent performance unreliability of the underlying vm.
moreover cpu utilization cannot reliably measure used capacity at low utilization the vm is given the impression that it runs isolated without being informed of the amount of cpu that is allocated to a different vm.
this only becomes noticeable at higher utilizations reported as steal time i.e.
the time that the vm would have had something to execute but the hypervisor decided to run a different vm instead .
this unreliability introduces the need for a different indicator to detect saturation conditions such as response time.
however the relationship between response time and saturation is non linear since many applications behave like queues .
therefore off the shelf controllers like pids should be carefully tuned and coupled with online corrections.
in this section we present the synthesis of a controller for maximum latency and formally prove its limits.
we employ terminology and notations used in control theory .
the controller keeps the maximum response time around a given setpoint for better user experience as opposed to average response time control .
using a very primitive yet useful model we assume that the maximum response time of the web application measured at regular time intervals follows the equation tk ak qk dtk i.e.
the maximum response time tk 1of all the requests that are served between time index kand time instant k depends on a time varying unknown parameter akand can have some disturbance dtkthat is a priori unmeasurable.
aktakes into account how the dimmer qselection affects the response time while dtkis an additive correction term that models variations that do not depend on the dimmer choice for example variation in retrieval time of data due to cache hit or miss.
notice that the used model ignores the time needed to compute the mandatory part of the response but it captures the application behavior enough for the control action to be useful.
our controller design should aim for canceling the disturbance dtkand selecting the value of qkso that the maximum response time would be equal to our setpoint value.702as a first step of the design we assume that we know akand its value is constant and equal to a. we will later substitute an estimation of its current value in the controller equation to make sure that the behavior of the closed loop system is the desired one.
to study the convergence of the system the time based quantities can be converted to their frequency domain counterparts using the z transform .
for the system we want to control before the feedback loop is closed called the plant the z transform is z t z a q z dt z where z 1is the unit delay operator t z is the z transform of the time series tk q z relates to qkanddt z transforms dtk.
we cannot control the disturbance dt z therefore we are only interested in the transfer function from the input the dimmer to the output the measured maximum response time which is p z t z q z a z every closed loop system composed by one controller and a plant has the generic transfer function g z c z p z c z p z y z r z where c z is the transfer function from the error to the control signal.
in this case the error is the difference between the setpoint and the measured value and the control signal is the dimmer value in the next time interval.
p z is the plant transfer function in our case eq.
.
y z andr z are respectively the output and the input of the closed loop system in our case the measured and the desired maximum response time.
the function g z represents the response of the controlled system with the feedback loop closed.
the next step in controller design consists in deriving an equation for c z .
one possible strategy is to choose c z so that some properties on g z the response of the controlled system are satisfied in control terms to select the shape of the response.
for example we want the steady state gain of g z in eq.
to be one since we want the output to be equal to the setpoint.
also we want to introduce a stable pole in the closed loop system to control the speed of the response in order for the system to be stable the pole should lay within the unit circle in order to also avoid oscillations its value should be between zero and one.
assuming that we want to introduce the stable pole in p1 our desired closed loop transfer function looks like g z c z p z c z p z p1 z p1 and substituting the plant transfer function of eq.
into eq.
we can derive the expression c z p1 z a z for the controller which turns to be a pi controller with specific constant values.
by applying the inverse z transform on c z we obtain qk qk p1 a ek where ek 1is the difference measured at time k between the setpoint for the response time and its measured value.
this equation can be used to implement a controller that selects the dimmer parameter.
we also add anti windup to the controller.
the choice of the pole p1depends on the type of behavior that we want to enforce for the closed loop system as explained later in this section.
during the control synthesis phase we assumed ato be constant.
however we know that its value changes over time due to performance interference and we should take into account thosevariations.
we should therefore provide an estimation of its current value akas akto be used in the controller.
we can use many methods to estimate it online while the application is running.
the most simple is to take past measurements compute the maximum response time tk pretend the disturbance dtkis negligible and compute akbased on eq.
.
once a first estimation is available it is also possible to assign a weight to new data points and choose ak m ak m tk qk where mis a discount factor that defines how trustworthy the new observations are.
control theoretical guarantees control theory allows us to provide some formal guarantees on the system.
our main aim is to close a loop around a cloud application constraining the application to have a behavior that is as predictable as possible.
without any feedback strategy the application can have transient behaviors depending on the input that it receives.
for example when the number of users suddenly increases latencies can raise due to saturation.
we would like to enforce robustness on the application behavior no matter how much environmental variations the application is subject to.
in control terms the uncontrolled variations that the system is exposed to are disturbances and our aim is to follow the setpoint rejecting them.
the controller will not be able to reject all types of disturbances.
for example when even setting the dimmer to zero results in a too high latency it means that the control system cannot achieve the desired value.
however if the goal is feasible i.e.
if the controller can set a dimmer value whose operating conditions fulfill the requirements it will find it due to its stability property.
to enforce stability since the closed loop system has the form given by eq.
we should simply make sure that the pole p1belongs to the open interval .
to avoid oscillations the pole should also be positive .
we now analyze how the pole position can compensate the undesired effects of introducing an estimator for akin the control algorithm.
the controller acts based on an estimation of the effect of its action akin eq.
.
if this estimation is incorrect the controller acts based on some false assumption.
however the presence of the feedback loop helps in detecting those errors and reacting to them in a satisfactory way.
the value given to the pole p1can be use to trade off responsiveness how fast the controller reacts to disturbances maybe not correctly estimated and safety how sure the controller is that the action taken will not damage the system .
the closer p1is to one the slower the system responds but the better it rejects measurement noise or other disturbances.
effectively the controller will only make small corrections at every iteration.
in contrast values of p1close to zero will make the system respond quickly but also be more sensitive to disturbances making large corrections that risk being based on transient disturbances instead of long term trends.
some values for p1can be suggested depending on the reliability of the measurements and the variability of the incoming requests.
however selecting a value for p1is best done based on empirical testing as shown in section .
.
to complete the trade off analysis we show the entity of incorrect estimation that each possible value given to p1is able to withstand.
assume we estimate akas akbut the real values is ak dak.
this multiplicative perturbation is often used to quantify how wrong an estimation can be.
if the system tolerates a daequal to it means that although the estimated value might be times smaller or larger than the real one the system will converge anyway due to the presence of the feedback loop.
.
.
.
.
.
.
.
.
.
p1tolerance kfigure multiplicative tolerance on the estimation error.
we test what is the maximum perturbation that our system is able to cope with.
in other words we want to find the values of dakfor which our plant is still stable.
the plant transfer function p z isa z therefore it becomes pmod z a da z. the controller transfer function is c z p1 z a z .
the closed loop transfer function gmod z of eq.
becomes therefore gmod c z pmod z c z pmod z p1 da z da p1 which is stable only if the two denominator poles are inside the unit circle.
since the gain is one it still hold that if the system is stable the setpoint will be reached.
the stability conditions derived by setting the denominator roots within is dak p1 which means exactly that choosing the value of the pole p1defines how safely the controller acts with respect to model perturbations.
fig.
plots the allowed perturbation.
the highlighted region is the safety zone.
setting the pole to means that the estimation can be times wrong while setting the pole to means that the tolerated estimation error is only twice or half of the real value.
in conclusion there is a fundamental trade off between the controller reactivity and the safety with respect to perturbations that the controller can withstand.
this trade off can be exploited carefully choosing the pole p1.
in our experimental results we demonstrate what this means in practice with statistical analysis exploring the range of possible choices for p1and their effects.
.
implementation to demonstrate the easiness of applying the brownout paradigm to existing cloud applications we extended two well known cloud benchmarks rubis and rubbos .
rubis is an extensively used benchmark that implements an auction website similar to ebay.
it has been widely used in cloud research e.g.
in .
we built a brownoutcompliant rubis version extending the php implementation and in particular the viewitem.php page.
we show how we applied the three steps presented in section selecting an optional component adding the dimmer closing the feedback loop.
with respect to selecting an optional component the existing rubis implementation seems a fairly minimalistic auction website.
therefore to make our evaluation more realistic instead of selecting an optional component from the existing code we decided to extend rubis with a simple recommender engine that works as follows when the user views an item j the engine retrieves the set of users ujthat bid on the same item in the past.
then the engine composes the set of recommended items rj retrieving other items that the users in ujhave bid on.
the items in rj are ordered by popularity i.e.
the number of bids on them and the top are returned.
while the described engine is not sophisticated it does serve as a reasonable example of an optional component that a cloud application may enable or disable at runtime.
clearly suchtable effort in logical source lines of code sloc to apply brownout to two popular cloud applications.
modification rubis rubbos recommender dimmer reporting response time to controller controller total a recommender engine adds a great value to the user experience thus increasing the owner s revenue.
however it is also resource hungry as already discussed in section and fig.
.
nevertheless in our extension the recommender engine is well isolated which allows us to easily enable and disable it per request.
having selected the recommender engine as the optional component we can proceed by adding an externally modifiable parameter to control its activation the dimmer.
since php scripts are executed independently for each request adding a central coordinator to decide which requests are to be served with recommendations and which not may lead to contention thus reduced scalability.
therefore we chose the dimmer qto represent the per request probability that the recommender engine is activated.
by working with a probabilistic instead of deterministic behavior we enable each invocation to take an independent decision.
each invocation of a script reads the dimmer value from a file called the dimmer file then a single bernoulli trial is performed to decide whether recommendations are served or not the script generates a random number r2 and if r q recommendations are displayed otherwise not.
the operating system caches this small dimmer file therefore exporting the dimmer using this procedure is done with low overhead and is minimally intrusive for the codebase .
finally we need to close the feedback loop to avoid overload.
we chose as performance criterion the user perceived latency as it seems to have a great influence on web user satisfaction and is highly suitable to predict saturation .
to this end the beginning and the end time of each view item request are recorded and by subtracting the two the response time can be measured.
while this quantity is slightly different than the user perceived latency due to network latencies context switches and other external factors it should be reasonably close.
each invocation of the viewitem page sends the measured response time to a well known local udp port on which the controller listens and stores these measurements.
the controller s algorithm is periodically activated to decide on a new value of the dimmer based on eq.
.
this value is atomically written to the dimmer file using the rename system call and is then used by the php scripts during the next control interval.
adding latency reporting and implementing the controller takes little effort as can be seen in table .
rubbos is a bulletin board prototype website modeled after slashdot and has also been used as a benchmark in cloud computing research .
adding brownout compliance to rubbos can be done similarly to rubis described above focusing on the view story page.
however concerning the first step of our methodology optional code choice rubbos offers more flexibility.
indeed we have identified two parts that can be considered optional.
first the existing code features a comment section that can easily be disabled.
while the comments section is an essential part of a bulletin board users are better served without it than not at all in case of overload.
second we extended rubbos with a recommender engine 704that suggests other stories that might be related or interesting for the reader based on common commentators.
the activation of the two optional components the comment section and the recommender engine can be linked to the value of the dimmer qin several ways.
in our implementation for each invocation the view story script stochastically decides how to serve the page using a cascade scheme as follows.
a first bernoulli trial is performed with probability qfor success.
in case of a successful outcome comments are served and a second bernoulli trial is performed with the same probability.
in case the second trail succeeds then recommendations are also served alongside the comments.
as a result the probability of serving a page with comments isq while for serving a page both with comments and recommendations the probability is q2.
the feedback loop is identical to the rubis one.
we reused the controller written for rubis and implemented the same response time reporting mechanism through local udp.
as with rubis the code changes were minimal as shown in table .
experience with two popular cloud applications showed that brownout can in general be added to existing applications with minimal intrusion and little effort.
the only required effort is to identify the optional computations in as many request types as possible.
as with most self adaptation techniques brownout is a cross cutting concern .
therefore large projects would benefit from using aspect oriented programming to clearly separate brownout compliance code from core concerns.
in the next section we do extensive experimentation to further show the benefits of our paradigm and to provide an in depth evaluation of the behavior of the resulting self adaptive applications.
.
ev aluation in this section we report results obtained using real life experiments to show the potential of the brownout paradigm in comparison to a non adaptive approach and to test the behavior of the selfadaptive application under different conditions.
in what follows we first describe the experimental setup then we do fine grained analysis on the time series results of a limited number of runs and finally we test the system statistically under a variety of conditions.
experimental setup experiments were conducted on a single physical machine equipped with two amd opterontm6272 processors3and 56gb of memory.
to simulate a typical cloud environment and also to dynamically change the resource allocation we decided to deploy each application with all its tiers inside its own vm as is commonly done in practice e.g.
using a lamp stack .
we use xen as hypervisor to get finegrained resource allocations to vms .
initial experiments revealed that cpu is the major bottleneck both for rubis and rubbos.
therefore each vm was configured with a static amount of memory 4gb and a variable number of virtual cpus depending on the experiment.
allocating cpu means that the application had exclusive access to cores of the physical machine while signifies accessing to a single core of the physical machine for half of the time.
combined multiplexing of the physical cores both in space and in time is common in today s virtualized datacenters .
to emulate the users behavior we have found the clients provided by rubis and rubbos insufficient for our needs.
specifically they do not allow to change the number of concurrent users and their behavior at run time.
moreover they report statistics for the whole experiment and do not export the time series data pre32100mhz cores per processor no hyper threading.venting us from observing the application s behavior during transient phases.
last these tools cannot measure the number of requests that have been served with recommendations or comments which represents the quality of the user experience.
we therefore developed a custom tool httpmon to emulate web users.
its behavior is similar both to the tools provided by rubis and rubbos and to the tpc w benchmark specification .
among others it allows to dynamically select a think time and a number of users and maintains a number of client threads equal to the number of users.
each client thread runs an infinite loop which waits for a random time and then issues a request for an item or a story.
the random waiting time is chosen from an exponential distribution whose rate parameter is given by the reciprocal of the think time.
a master thread collects information from the client threads and periodically prints statistics for the previously elapsed second of execution.
in particular it records the maximum user perceived latency which is the time elapsed from sending the first byte of the http request to receiving the last byte of the http response and the ratio of recommendations orcomments the number of requests that have been served executing the optional code for recommendations or comments divided by the total number of requests.
note that due to the stochastic nature of our implementation see section this may be slightly different from the dimmer q which is the output of the controller.
during all our experiments httpmon was executed on a dedicated core to reduce its influence on the application under test.
.
time series analysis thoroughly testing a system should be done under a variety of conditions applying statistical analysis on the result.
however statistical testing alone may hide details about the behavior of the system in transient phases.
therefore we first show a few selected experiments in the form of time series.
we report three sets of experiments each focusing on a different time varying aspect.
first we vary the resources that the application can use.
second we vary the application load the number of connected users.
as a third experiment we vary both these quantities together to emulate a real execution environment.
since previous research suggests that unexpected peaks vary considerably in nature we manually chose values for load and resources that exposed the application to extreme conditions.
the following figures presenting each a single experiment are structured as follows.
the bottom x axis represents the time elapsed since the beginning of the experiment.
every experiment consists of intervals each of them lasting seconds.
the experimental parameter that is changed for every interval and its value are reported on the top x axis.
three different metrics are plotted.
first the maximum user perceived latency is shown in continuous blue lines and its y axis is depicted on the left side of the plot.
second the right y axis hosts two different curves related to the user experience.
the first one the dimmer is the output of the controller and is shown in dotted red lines.
the second one the comments or recommendation ratio depicted in dashed black lines is the average ratio of pages served with optional content number of pages served with optional content over total number of pages served .
to improve the readability of the graphs the values are aggregated over second intervals.
ideally the controller should maximize the dimmer while keeping the latency close to the setpoint.
also the recommendation ratio should closely follow the dimmer.
constant load and variable resources in this set of experiments we keep the load constant concurrent users with a think time of 3seconds and vary the amount of resources allo time user perceived latency .
.
.
.81resources a non adaptive q time .
.
.
.81resources b self adaptive p1 time .
.
.
.81resources dimmer .
.
.
.81resources recommender ratio c self adaptive p1 figure rubis behavior in a non adaptive configuration and two self adaptive configurations varying the resource allocation.
time user perceived latency .
.
.
.81number of users a non adaptive q time .
.
.
.81number of users b self adaptive p1 time .
.
.
.81number of users dimmer .
.
.
.
recommendations ratio c self adaptive p1 figure rubis behavior in a non adaptive configuration and two self adaptive configurations varying the number of users.
cated to rubis.
in a cloud data center this situation arises when a physical machine is over subscribed and co located vms suddenly requires more resources.
in fact when multiple vms share the same machine performance interference may occur .
this is either cause by the hypervisor s decision to time share a cpu core also called steal time or due to the congestion of a hardware resource such as memory bandwidth or cpu cache.
also cpu throttling due to cooling failures or load redistribution due to the failure of a different physical machine may cause similar vm capacity reductions.
the controller was configured with a control period of 1second to allow a quick reaction a target latency of 1second to allow a safety distance to the tolerable waiting time of 2seconds recommended in a discount factor m and a sliding measure window of 5seconds.
this means that the controller s input is the error between the desired value of 1second and the maximum latency measured over the last 5seconds.
first we test the behavior of the non adaptive system when no controller is present.
emulating the non brownout compliant version of the application can simply be done by forcing the output of the controller to maximum.
however we found that the resulting system behaves poorly therefore for fairer comparison we set the dimmer to which means that requests are served with recommendations only half of the time.
second we compare these results to the case of brownout compliant application when the controller s pole p1is set to and .
figure plots the results of our test.
figure 3a shows that the non adaptive application performs quite well in the first interval up to seconds when resources are abundant as the cpu allocation is set to .
indeed the latency is below 2seconds and the recommendation ratio is closely following the dimmer .
however during the next interval when resources are slightly insufficient as the amount of allocated cpu is halved the latency starts increasing because the application is unable to serve requests fast enough and saturates.
in the next time interval when even fewer resourcesare available the system becomes unresponsive and some users experience huge latencies up to 10seconds4.
the ratio of recommendations is very low as requests that would potentially receive recommendations are abandoned by the client due to timeouts.
in the next interval more resources are allocated to the web application as its cpu is increased to .
the application catches up with serving previous requests and the latency decreases.
however this process takes 60seconds during which the application seems unresponsive.
in the last interval resources are insufficient and the application becomes again unresponsive.
the results show that if resource capacity fluctuates and temporarily becomes insufficient a non adaptive approach may result in users experiencing unpredictable latencies.
figure 3b plots the results of the self adaptive application with the controller configured with the pole p1 .
in contrast to the non adaptive system the self adaptive application is perceived as more predictable from the user s perspective.
effectively it managed to maintain the latency below 2seconds whenever possible despite a factor reduction of resources from a cpu of to one of .
this is due to the dimmer adjustment that follows the available resource capacity.
furthermore the ratio of recommendations closely follows the dimmer.
we discuss here the few deviations from the desired behavior where the latency increases above the tolerable waiting time.
the highest deviations occur as a result of an overload condition when the cpu allocation is reduced around time instant and .
this is in accordance with theory since the controller needs some time to measure the new latencies and correspondingly select the new dimmer value.
nevertheless the system quickly recovers from such conditions in less than 20seconds.
around time instant and the controller seems to be too aggressive.
it tends to increase the dimmer quickly violating therefore the 2seconds tolerable latency.
4we limit plots to 4seconds to ease comparison among scenarios.706let us now study how the self adaptive application behaves when the controller is tuned for more stability.
figure 3c plots the results with the same controller configured with p1 .
as predicted by theory it reacts at a slower pace with small adjustments at every iteration.
its output seems more steady and it generally does a better job at keeping the latency around the setpoint of 1second.
by using this controller the likelihood of having latencies above the tolerable waiting time is decreased.
however this configuration also takes more time to recover from overload conditions.
compared to the previous configuration it required twice as much time to react to the resource reduction at time instant .
also during recovery the recommendation ratio differs slightly from the dimmer s value.
this happens because the responses arriving at the client have a high latency and were actually started at a time when the dimmer was higher.
however considering that the resources were reduced instantaneously by a factor of the slower recovery is unlikely to be a problem in a production environment.
summarizing adding brownout self adaptivity to a cloud application may considerably improve its flexibility with respect to resource allocation.
effectively the application behaves more robustly and can withstand large reduction in resource allocation proportional to the resource requirements of the optional components.
constant resources and variable load in this second set of experiments we keep the resources constant setting the cpu allocation to and vary the number of users accessing brownoutcompliant rubis.
in a real data center this situation may happen due to flash crowds sudden increase in popularity when the page is linked from another high profile website.
however it can also be the result of load redistribution due to a failing replica or denialof service attacks.
the controller is configured identically to the previous set of experiments.
let us now discuss the results.
figure 4a shows the results of the non adaptive version of rubis when the system cannot keep up with the load increase.
even after the number of users is significantly decreased such as at seconds the application requires a significant time to recover up to 62seconds.
in contrast figure 4b and figure 4c shows the results with the self adaptive version of rubis.
despite an fold increase in the number of users from to the application is more responsive adjusting the dimmer to adapt to the load increase.
regarding the adaptation time in the worst interval when the number of users was spontaneously increased by a factor of at time the controllers required respectively 22seconds and 66seconds when p1 and .
as in the previous experiment the controller with a pole of is more aggressive quickly increasing the dimmer and risking latencies above the tolerable level.
in contrast setting the pole to produces a more conservative controller which does smaller adjustments of the dimmer s value.
in any case the brownout compliant cloud application is more robust and avoids saturation when the number of users increases.
variable load and resources to reproduce a realistic setup we studied how a brownout compliant application behaves when both the available resource capacity and the number of users are varying.
we present the results of an experiment conducted with rubbos incidentally showing another brownout compliant application with two optional components comments and recommendations.
however to improve graph readability we only present the ratio of requests served with comments.
concerning controller configuration we present results with the pole p1 and to further show that the controller behaves as theoretically designed we chose to reduce the target latency setpoint to 5seconds.
time user perceived latency .
.
.
.81resources number of users dimmer .
.
.
.
comments ratio figure rubbos brownout compliant p1 setpoint .
seconds behavior varying both resources and users.
figure shows the results of the experiment.
as can be observed except for the fourth interval the controller successfully manages to keep the maximum latency around 5seconds.
in the fourth interval the dimmer is kept as close as possible to zero to serve the maximum number of requests in a reasonable time.
in general the dimmer is increased when the conditions allow for it such as during the second and fifth interval and decreased when resource capacity is insufficient or the load is too high during the remaining intervals.
the time series results show that the self adaptive applications behaves as intended.
the controller adapts the dimmer both to the available capacity and number of users as expected and keeps the perceived latencies close to the setpoint.
moreover the advantages that the brownout paradigm brings to a previously non adaptive applications can clearly be observed from the results.
the experiments opened up two questions.
first we have shown that the pole allows to choose between a more aggressive and a more conservative controller.
which one is better i.e.
which one serves more requests of any kind and which one serves more requests with optional components enabled?
second we have chosen to compare the self adaptive approach with a non adaptive one with the dimmer q .
is it possible that other static dimmer values compare more favorably?
in what follows we show experimental results that answer these two questions.
.
statistical analysis in this section we present statistical results to show that our controller is able to tackle a variety of scenarios with invariant benefits in the cloud application behavior.
we focus our experiments here on unreliable resource capacity.
our intuition is that flash crowds are somewhat avoidable for example by gradually rolling out an application to an increasing number of users as google did when launching gmail or facebook when launching graph search.
in contrast for the foreseeable future hardware is increasingly unreliable as its scale and complexity is constantly increasing therefore any cloud provider eventually has to deal with unreliable resource capacity.
moreover performance of the cloud applications may be degraded due to colocation .
since both the stress test and time series results figs.
and suggest that the system behaves similarly in responding to an increasing number of users as to a reduction in resources we believe these results are representative also for the flash crowd scenario.
the experimental setup is as follows.
each particular application configuration whether non adaptive or self adaptive is subjected to distinct test cases.
each test case consist of time intervals each having a duration of 100seconds but a different amount of cpu allocated to the application.
the first four test cases allocated cpu with small uniform random deviation of around .
latency cumulative fraction a p1 .
.
latency cumulative fraction b p1 .
.
latency cumulative fraction c p1 .
.
latency cumulative fraction d p1 .
.
latency cumulative fraction e p1 .
.
latency cumulative fraction f p1 .
.
.
.
.
.
.
.
.
.910k20k30k configuration value of pole p1avg.
request count38k39k40k avg.
revenue g summary over all self adaptive configurations.
figure statistical results for self adaptive system.
figs.
6a to 6f show empirical cumulative distribution of latencies for each configuration.
each line represents the results of a test case.
fig.
6g shows for each configuration over all test cases average served requests in total bar with no fill and with recommendations solid blue bar and average revenue red patterned bar .
and .
the next four test cases allocate cpu uniform randomly between and .
the final two testcases validate the system in extreme cases in which the amount of available resources alternates between and cpu starting with the lower and higher amount respectively.
we present results with rubis with the controller configured similarly as in the previous section except for a setpoint of 5seconds.
for any particular configuration of the application we are interested in the following metrics the user perceived latency represented as an empirical cumulative distribution function the total number of requests served and the total number of requests served with optional content such as recommendations.
to provide a single metric and ease comparison we compute the revenue of the application owner.
each served request values monetary unit and each served recommendation adds monetary units.
this revenue model is based on a study that found that recommendations increased sales by .
let us first focus on testing the various self adaptive configurations.
fig.
show the results for various pole configurations ranging from more aggressive to less aggressive .
the first take away point is that every configuration does a reasonable job in keeping the latencies below the setpoint therefore we gain confidence that our controllers are adjusting their output correctly.
analyzing the results more in detail more aggressive controllers serve slightly more requests than conservative ones however they serve fewer recommendations and perform poorer in maintaining low latencies figs.
6a to 6f .
when combining the two dimensions by looking at revenue values for p1between and maximize application owner income.
in the end we determine that the pole p1 is our best configuration since it maximizes average revenue over the test cases while at the same time keeping low latencies.
having found the best configurations for the self adaptive application let us compare it to the non adaptive version.
fig.
shows the results for various statically chosen dimmer values with the same resource availability patterns.
the results of the best brownout compliant configuration is replotted for the reader s convenience in figs.
7f and 7g.
as expected low dimmer values main tain low latencies but deliver no recommendations.
high dimmer values risk saturating the application which leads to timeouts and as a result reduces the number of requests served.
in contrast the self adaptive approach serves recommendations when capacity allows and disables them otherwise.
as a result when it comes to owner revenues self adaptation manages to outperform all static configurations .
to sum up the results show that adding brownout compliance to cloud applications increases their robustness in case of flashcrowds unexpected hardware failures or unexpected performance interference.
this directly translates into increased revenue for the application owner and hence increased profits.
.
related work self adaptation is playing a key role in the development of software systems and control theory has proved to be a useful tool to introduce adaptation in such systems .
although many attempts have been made to apply control theory to computing systems the research is still in a preliminary stage and the achievable benefits are yet to be clearly defined .
we were inspired by the idea that there might be multiple code alternatives for the same functionality and not all the code that a software application is executing is necessary and some of its code might be skipped when necessary .
a similar concept has been proposed in the web context.
degrading the static content of a website was first proposed in and has been subsequently extended to dynamic content .
however this work tend to propose controllers that keep cpu usage below a certain threshold that should be determined through guesswork or prior knowledge of the platform.
this solution works for web servers running on bare metal hardware but it is unsatisfactory in cloud environments.
on one hand resources may be inefficiently utilized due to the fact that the threshold needs to be set low enough to leave headroom in case of performance interference from co located vms.
on the other hand cpu usage is not a reliable measure for spare capacity in virtualized environments due to hypervisor preemption of virtual machines also called steal time .
we use measured7080 .
latency cumulative fraction a q .
.
latency cumulative fraction b q .
.
latency cumulative fraction c q .
.
latency cumulative fraction d q .
.
latency cumulative fraction e q .
.
latency cumulative fraction f self adaptive p1 .
.
.
.
.
.
.
.
p1 .8010k20k30k40k configuration static value for or self adaptiveavg.
request count 20k25k30k35k40k avg.
revenue g summary non adaptive and best self adaptive configurations.
figure statistical results for non adaptive system.
figs.
7a to 7e show latency distribution for each non adaptive configuration while fig.
7f shows our selected self adaptive behavior.
each line represents a test case.
fig.
6g shows for each configuration over all test cases served requests in total bar with no fill and with recommendations solid bar and revenue red patterned bar .
latency which requires a carefully designed controller in order to avoid this limitation.
other proposals exploit partial execution of computation to avoid overload or soft resource abuse detection to counteract denial of service attacks.
in the first case response generation is interrupted after a certain time budged has been exhausted .
in the second case the application code is annotated to precisely track soft resource usage and react in case of malicious behavior .
these strategies however are only applicable to a narrow class of applications or require exhaustive annotation of the applications source code.
our aim is to provide a widely applicable programming paradigm that can tackle the variety of fluctuations happening in a cloud environment.
therefore we propose a general solution that can be applied both to existing and new cloud applications with minimal impact on their design.
an approach complementary to ours is elasticity .
in cloud computing elasticity means deciding the right amount of resources each application needs avoiding underor over provisioning.
for example sharma et al.
propose a system that tries to minimize the cloud tenant s deployment cost while reacting to workload changes.
the system takes into account the cost of each instance the possibility of horizontal and vertical scaling and the transition time between configurations.
however elasticity offers no solution if the underlying infrastructure s capacity is exhausted taking only the application s point of view.
although some work deal with performance differentiation for multiple classes of clients to our knowledge the closest cloud application to a brownout compliant one is harmony .
harmony adjust the consistency level of a distributed database as a function of the incoming end user requests so as to minimize resource consumption.
in this case the motivation to introduce the adaptation mechanism lies in limiting the amount of money that the user is charged for.
this is a specific example of how a cloud application can be compliant with our paradigm while we propose a general technique and build a sufficiently broad control strategy to realize adaptivity for a vast class of applications.
related to methodology cloud research in general relies either on analytical models or on running actual ex periments and building empirical traffic profiles and signatures .
our system uses an analytical model to infer performance from measurements taken from the actual system.
zheng et al.
argue that running actual experiments is cheaper than building accurate models to validate research proposals.
we build on this assumption validating our technique on a small scale testbed.
.
conclusion in this paper we introduced the brownout paradigm for cloud applications.
we discussed a model for applications with optional code i.e.
computations that can be activated or deactivated per client request.
we described our experience with two widely used cloud benchmark applications rubis and rubbos to show the ease of applying our approach to existing cloud applications.
we synthesized a controller for a wide range of applications which selects the dimmer parameter based on incoming load and available capacity.
we proved the correctness of the resulting system using control theoretical tools.
we implemented the framework and tested it with real life experiments.
the results show that self adaptation through brownout can allow applications to support more users or run on fewer resources than their non adaptive counterparts.
hence our proposition enables cloud applications to more robustly deal with unexpected peaks or unexpected failures without requiring spare capacity.
future work include extending the contribution to applications spanning multiple machines and combining brownout compliance with other mechanism like horizontal vertical elasticity and migration.
we believe that brownouts open up a new level of flexibility in cloud platforms.
.