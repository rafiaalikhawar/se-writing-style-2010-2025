solving complex path conditions through heuristic search on induced polytopes peter dinges university of illinois urbana champaign usa pdinges acm.orggul agha university of illinois urbana champaign usa agha illinois.edu abstract test input generators using symbolic and concolic execution must solve path conditions to systematically explore a program and generate high coverage tests.
however path conditions may contain complicated arithmetic constraints that are infeasible to solve a solver may be unavailable solving may be computationally intractable or the constraints may be undecidable.
existing test generators either simplify such constraints with concrete values to make them decidable or rely on strong but incomplete constraint solvers.
unfortunately simpli cation yields coarse approximations whose solutions rarely satisfy the original constraint.
moreover constraint solvers cannot handle calls to native library methods.
we show how a simple combination of linear constraint solving and heuristic search can overcome these limitations.
we call this technique concolic walk .
on a corpus of programs an instance of our concolic walk algorithm using tabu search generates tests with two to three times higher coverage than simpli cation based tools while being up to ve times as e cient.
furthermore our algorithm improves the coverage of two state of the art test generators by and .
other concolic and symbolic testing tools could integrate our algorithm to solve complex path conditions without having to sacri ce any of their own capabilities leading to higher overall coverage.
categories and subject descriptors d. .
testing and debugging symbolic execution general terms algorithms keywords concolic testing local search non linear constraints c peter dinges and gul agha .
this is the authors version of the work.
it is posted here for your personal use.
not for redistribution.
the definitive version was published in the proceedings of the 22nd acm sigsoft international symposium on foundations of software engineering sigsoft fse november hong kong china.
introduction thorough testing of programs is crucial but time consuming and expensive .
automatic test input generators can simplify testing by supplying values that trigger di erent behaviors in the program including hidden corner cases.
we are interested in generating inputs for programs whose controlow depends on complex arithmetic operations such as non linear and trigonometric functions for example the tsafe1program used to prevent airplane collisions.
such programs which are common in the domain of cyber physical systems pose major challenges for test input generators based on symbolic and concolic execution.
symbolic and concolic test generators attain their strength high coverage by picking a distinct path in the program for each round of input generation.
they do this by characterizing a fresh path s branch conditions as a set of symbolic constraints and solving this path condition to obtain concrete inputs that drive the program down the path.
a central problem in this approach as exempli ed in tsafe is translating the arithmetic constraints of the path condition into the theory of the underlying solver.
the di culties in translating are non linear integer constraints often make it infeasible to solve the path condition.
such constraints are even undecidable in general .
path conditions can contain calls to uninterpreted library methods such as trigonometric functions about which the solver cannot reason .
classic concolic testing mitigates these problems by replacing troublesome symbolic terms with their concrete values .
this reduction of symbolic reasoning to simple evaluation allows concolic testing to explore paths whose branch conditions lie outside the solver s theory.
however such simpli cation restricts the search space rather arbitrarily.
the result is that it can nd a solution only in a few cases see section .
another mitigation strategy for symbolic testing is relying on a domain speci c solver that can interpret all occurring arithmetic operations and library methods .
while performing well within the target domain the approach requires a solver extension for every new operation.
existing solvers based on heuristic search furthermore ignore the symbolic structure of the path condition.
the concolic walk algorithm introduced in this paper solves path conditions through a novel blend of symbolic 1tactical separation assisted flight environmentreasoning concrete evaluation and heuristic search which overcomes the limitations of previous approaches.
the algorithm is based on a geometric interpretation of the problem we regard assignments of values to the variables appearing in a path condition as points in a valuation space .
intuitively thinking of the valuation space as rn we nd a solution point to a path condition by combining the following ideas the solutions of the linear constraints in the path condition de ne a contiguous convex region in the space a polytope .2all solutions to the whole path condition must lie within this polytope.
all terms appearing in the constraints that comprise the path condition including library methods can be evaluated.
hence we can assign each constraint an evaluation based tness function that measures how close a valuation point is to satisfying the constraint.
this allows us to nd solutions through heuristic search.
many non linear terms are at least piece wise continuous.
numerical optimization techniques akin to newton s method can thus accelerate the solution search.
in particular our algorithm splits the path condition into linear and non linear constraints nds a point in the polytope induced by the linear constraints with an o the shelf solver and then starting from this point uses adaptive search within the polytope guided by the constraint tness functions to nd a solution to the whole path condition.
this paper contains the following research contributions we introduce the concolic walk cw algorithm a novel combination of symbolic reasoning and heuristic search for solving complex arithmetic path conditions section .
the algorithm is sound and complete for linear constraints and supports non linear constraints and calls to native library methods.
we evaluate an implementation section of the cw algorithm on a corpus of programs whose path conditions include mostly non linear constraints.
we show section that the algorithm generates tests with two to three times higher coverage than simpli cationbased tools while being up to ve times as e cient and considerably improves the coverage of state of theart test generators such as pex .
in its current form the cw algorithm is limited to solving arithmetic constraints in path conditions.
however it can be combined with approaches for solving pointer constraints or heuristic concolic object generation to ll this gap.
for purpose of exposition we limit the discussion to test input generation but the cw algorithm also applies to other uses of concolic execution such as regression testing speci cation mining and property checking .
.
motiv ation a common goal for test input generators is producing inputs that cover as many di erent execution paths as possible.
while random inputs are fast to generate they mostly cover 2we ignore not equal constraints to convey the essential idea of our algorithm.1static void example1 intx inty f 2intz x y non linear operation 3if x z if x assert false found error 6g 8static void example2 double u f work with the binary representation of u long v double.doubletorawlongbits u native method long w v 0x if w assert false found error 14g figure example java methods with complex path conditions.
in method example1 the path to the error line has the non linear path condition x x y x .
neither jcute nor mixed concrete symbolic solving discover input values that satisfy this path condition.
in method example2 the path condition for the error line contains a call to an uninterpreted library method.
neither spf coral nor pex for the c version discover input values that satisfy the path condition.
thecommon paths in a program.
narrow branch conditions such asx x y are unlikely to be met by random values forxandy.
instead most generated inputs will execute the same pathx6 x y resulting in repeated tests of the same program behavior.
to cover narrow branches and avoid repetition symbolic and concrete symb olic concolic input generation take a more systematic approach.
they rst collect all branch conditions along a target path picking a single clause from disjunctive conditions and represent them as conjunction of symbolic constraints.
then they solve this path condition to obtain concrete inputs.
the path condition characterizes the set of all concrete inputs that lead the program down this path.
a solution thus satis es all branch conditions including narrow ones.
furthermore solving a di erent path condition every time prevents repetitions that may occur with random inputs.
for example assume we want to nd an input for the example1 method in figure that covers the path along the statements in the lines and .
to drive the execution down this path xand ymust satisfy the path condition x x y x .
given a suitable decision procedure we can solve the path condition to obtain for instance the concrete inputs x 3and y .
solver limitations and mitigation strategies unfortunately a complete symbolic decision procedure for general non linear integer constraints cannot exist .
furthermore a decision procedure can typically only nd solutions if it has an interpretation for all appearing operations.
if a path condition contains arbitrary integer arithmetic or importantly calls to opaque library methods like the native cosmethod in java then nding a solution is hard .
a common approach to work around the solver limitations is to simplify under approximate the path condition parts of the path condition that the solver cannot handle are rst executed on concrete inputs and then replaced withfigure solutions of the non linear equation x x y circles and its linearization x y squares .
no solution for x y satis es the path condition x x y x which shows the danger of blindly simplifying path conditions.
the concrete results.
simpli cation has been applied while constructing the path condition and while solving it.
classic concolic test generators such as jcute and pex simplify at construction time.
for example jcute relies on a linear constraint solver.
when building the path condition for the path in figure it replaces the non linear expression x ywith yifx 2when the expression is added.
this yields the path condition x y x x if we include the constraint x 2that is required to make the simpli cation sound .
in contrast mixed concrete symbolic solving simpli es at solution time.
to solve a path condition mixed solving splits it into resolvable and complex constraints solves the resolvable ones directly and uses the solution to simplify and concretely execute the complex constraints.
the execution results in turn serve to simplify the complex constraints.
figure shows how simpli cation produces bad approximations.
the simpli ed path condition of above example is unsatis able because of a bad approximation due to a random choice ofx.
likewise mixed solving fails to cover the path because the only feedback from the concrete execution to the constraint solver is ruling out non working values which is often insu cient to nd a solution section .
observe that both simpli cation techniques are problematic because ofblind commitment to concrete values regardless of other constraints on the variables.
stronger solvers the number of such bad approximations decreases as the strength of the solver increases.
the pex concolic test generator for example relies on the z3 smt3solver to nd inputs that satisfy a path condition.
z3 supports some non linear integer operations in its constraints and hence pex discovers the error in line of figure .
likewise spfcoral a combination of the symbolic pathfinder spf symbolic execution tool and a constraint solver based on heuristic search coral discovers the error.
while this extends the domain of programs that can be handled and enables coverage of more paths than before it does not fully x the interpretation problem.
speci cally 3satis ability modulo theoriesprograms may call hitherto unknown library methods.
for example an implementation of trigonometric functions converts oating point numbers to bit vectors as exempli ed in figure .
such methods would require a solver extension arguably a maintenance nightmare.
other interactions such as database queries are even harder to integrate.
.
algorithm the concolic walk cw algorithm for solving path conditions addresses the aforementioned challenges of relying on decision procedures section .
speci cally it treats linear and non linear constraints di erently to solve the linear constraints it uses an o the shelf solver to solve the nonlinear constraints it uses heuristic search based on concrete execution evaluation .
using concrete execution allows the algorithm to handle opaque library methods without further extension.
at the same time the algorithm never simplies or approximates the path condition this avoids blind commitment to concrete values.
.
synopsis the algorithm distinguishes between linear and non linear constraints because linear constraint systems are decidable and e cient solvers exist.
furthermore linear constraints have a useful geometric interpretation assume that we relax the domain of each variable in the path condition to r. then we can regard an assignment of values to each variable as point in a valuation space which corresponds to rn.
in the valuation space the solutions of a linear constraint form a half space a conjunction of linear constraints therefore describes an intersection of half spaces which is a convex hence contiguous region a convex polytope.4in figure the polytope is the region right of the line x .
all variable assignments that are global solutions to the whole path condition must lie within the polytope because the points outside violate the linear constraints.
to nd a global solution the cw algorithm thus picks points in the polytope and evaluates the non linear constraints on them to check whether these are satis ed too.
an e cient way to pick random points in the polytope is a random walk.
however if global solutions are sparse within the polytope a random walk has slim chances of discovering one.
the algorithm therefore combines the random walk with a search heuristic that guides the walk towards promising regions.
for this each non linear constraint is assigned a tness function based on evaluating the terms in the constraint that measures how close the current point is to a solution of the constraint.
from the many meta heuristics simulated annealing genetic algorithms etc.
we chose the adaptive search variant of tabu search for its ease of adding a nonrandom neighbor picking strategy see below .
in each iteration adaptive search picks the variable that appears in the most violated constraints and examines neighbor points that di er only in this variable.
a variable becomes tabu for several iterations if changing its value failed to yield a better neighbor.
the search moves towards the ttest neighbor like hill climbing but escapes local minima with the help of the tabu mechanism.
4recall that each clause of an orbranch condition is treated as a separate path.
the path condition is therefore a pure conjunction of constraints.
our interpretation ignores not equal constraints these cut slices out of the polytope.hexpi hvarijhlitijhcallijhexpi hexpij hexpi hcalli hfuni jhfuni hvari hvari ?
hcondi hvari h vari hstmti hvari hexpi jif hcondi hstmtielsehstmti jwhile hcondi hstmti jfhstmti hstmti ?g hprogi hstmti hstmti ?
figure syntax of the example language with variables var literals lit function symbols fun binary operations f modg and relations 2f g. in addition to picking random neighbors the cw algorithm furthermore tries to exploit piece wise continuity of non linear terms.
given the values of the tness function at the current point and a neighbor it estimates a third point where the constraint would be satis ed were it linear.
such estimation equals a single step of the bisection method for numerical zero nding and can accelerate the search.
example consider the partial plot of the valuation space for the variablesxandyin figure .
the path condition x x y x consists of the linear constraint x 2and the non linear constraintx x y. the linear constraint x 2describes an unbounded convex polytope the half plane right of the line x .
all feasible solutions must be contained within this polytope.
to discover a solution to the non linear constraint we start a random walk at an arbitrary point in the polytope for instance x y .
modifying x we randomly generate the neighbors and choosing because it is closer to satisfying the equation x x y. modifyingxagain does not yield a better neighbor all of these lie outside the polytope.
thus xis marked as tabu and the next iteration modi es y. aside from a random neighbor we estimate a zero for the linear parameterization of x x y on the line which yields the solution .
.
terms and definitions before formalizing the cw algorithm in the next section we brie y de ne the terms used.
to simplify the exposition we describe the algorithm for a small imperative programming language whose java like syntax is shown in figure .
the algorithm itself is independent of the target language and applies to any language for which the ceval andseval functions can be de ned accordingly.
the example language supports the basic imperative statements.
it lacks support for function de nitions to keep matters simple but expressions may contain calls to opaque library functions that have been de ned elsewhere.
the only data types are integers and real numbers because of our focus on solving arithmetic constraints.
concrete execution an evaluation function ceval models the concrete operational small step semantics of the language.
in practice ceval could take the shape of an interpreter or virtualmachine.
formally ceval returns the successor con guration for a given program prog and a concrete environment var!r f?g ceval prog prog0 where prog0is the program derived from prog by executing one step and 0is derived from by applying the e ects of this step.
using record notation hz cifor the environment with cand ?fory6 z we thus have ceval y x hx 23i ?
hy x 23i .
as shorthand for expression evaluation we write ceval e for where ?
ceval z e with a fresh variable z. when a program runs it follows an execution path which is a sequence of steps i !jfrom statement number iin the program to one of its successors j. symbolic execution symbolic execution of the language is encapsulated by the function seval .
for an execution step i !j seval builds a symbolic description of the step s e ects.
the description consists of two parts a symbolic environment and a set of controlow constraints p. in symbols seval prog i !j p p0 the symbolic environment 0captures updates to the program state as expressions.
it assigns each variable x an expression ethat when evaluated in a concrete environment yields the same value that xwould have after executing the step concretely.
thus emust be precise and cannot approximate the e ects through simpli cation.
however there are no structural transparency requirements on e seval may encapsulate the e ects as opaque function calls.
using the expression evaluation notation from above we have ceval e for ?
ceval progi where progiis thei th statement in prog.
for example seval y x !
hx xi hy x x xi so that evaluating the expression assigned to yyields as above.
we assume that seval performs the variable renaming necessary to support reassignments.
the second half of the description built by seval the setp0 collects the symbolic constraints of traversed conditionals.
if the execution step i !jfollows the true branch of an if or while statement with the condition x y then seval derives p0by adding the constraint x y top if the step follows the false branch seval adds x y top otherwise it copies p. a concrete execution of the program thus follows the path given to seval only if the values in the concrete environment satisfy all constraints inp0.
hence p0is the path condition .
constraints formally the constraints in the path condition are triples r 2exp f g exp written as r. a constraint is satis ed in an environment if the relation denoted by holds between the values ceval and ceval r .
we say that the path condition pis satis ed in if each of its constraints is satis ed in .
in this case we write j p.algorithm the concolic walk algorithm for solving the path condition p. notation p f i irijigis a set of constraints x y2varare variables and var!rare environments whose elements are by default.
operations between environments apply point wise.
the vars function returns the set of variables appearing in an expression constraint or path condition.
procedure solvewithconcolicwalk p l fc2pjcis linearg .polytope n pnl .non linear constraints solvelinear l .starting point if ?then return?
i .iteration step counter while 6j ndo .
is not a solution ifi i jnjthen return?
i i if8y2vars p 0then.all vars tabu randomstep vars p l hy 0jy2vars p i end if e .error at hy 0jy2vars p i.error per variable forc2ndo w computeerror c e e w hy wjy2vars c i end for x varwithmaxvalue hy 1j 0i e findbestneighbor x l n ife e then .found better neighbor e e hy 1j 0i else t .
x is tabu fortsteps end if end while return end procedure as motivated in subsection .
we distinguish linear from non linear constraints to exploit their decidability and geometric interpretation.
a constraint ris linear if it can be transformed into a normal form nx i 1aixi b with variables xiand constants ai b2r.
.
concolic walk algorithm algorithm formalizes the cw algorithm.
the algorithm accepts a path condition pas input and returns a concrete environment that satis es p or?if it could not nd such environment.
in preparation for the random walk the algorithm extracts the polytope description from p and generates a starting point within the polytope lines .
the polytope description denoted l simply consists of all linear constraints in p. the starting point is the solution for lreturned by a linear constraint solving function solvelinear .
in dimensions un algorithm error score for the constraint rin the environment that captures how badly the constraint is violated.
the procedure computes the score by executing the symbolic expressions ron the concrete inputs in .
procedure computeerror r d ceval ceval r if is then returnjdj else if is6 then ifd6 0then return 0else return else ifd 0then return 0else returnjdj end if end procedure procedure computeerror f i irijig returnp icomputeerror i iri end procedure constrained by l the point has arbitrary entries.
assuming thatsolvelinear is sound and complete pis unsatis able if no solution for lexists and the algorithm hence returns ?.
otherwise the random walk starts and continues until either a solution was found line or the iteration budget was exhausted line .
in each iteration the algorithm tries to nd an environment with a lower error score than the current environment .
to do so it nds the variable xwith the highest error score lines generates neighbor environments for by modifying this variable s value picks the neighbor with the lowest error score both line and makes the current environment if is better than lines .
algorithm shows the function for computing the error scores the function resembles korel s branch functions .
the algorithm maintains a tabu counter for each variable to escape local error score minima.
if modifying a variable x failed to yield a better neighbor it is marked as tabu for t iterations line .
variables marked as tabu cannot be selected for modi cation they are assigned an error score of before choosing the maximal one line .
consequently the algorithm explores other directions if one seems to lead nowhere.
every iteration a better neighbor was found all tabu counters are decremented line .
however some constraints like x y require changing multiple variables at the same time and cause the algorithm to declare each variable tabu one after another.
thus if all variables are tabu the algorithm modi es the values of all variables and resets the tabu counters lines .
neighbor selection generating neighbors and picking the best one has been extracted to the findbestneighbor function algorithm .
rtimes the function generates two neighbor environments and for its input remembering the overall best one.
the environment is the result of taking a random step in the polytope lalong the axis of the given variable x see algorithm .
the function randomstep guarantees that the returned environment lies within the polytope.
the environment is the result of linear approximation for a random unsatis ed constraint r2nthat contains x thebisectionstep function estimates the environment that would satisfy the constraint if both andrwere linearalgorithm choosing the best among environments that di er from in theirx entry and lie inside the polytope l satisfy l .
procedure findbestneighbor x l n e .error at forriterations do randomstep x l .in the polytope c oneof fc2nj 6j candx2vars c g bisectionstep c .may be outside e computeerror n e computeerror n ife e then e e end if if j lande e then e e end if end for returne end procedure algorithm taking a random step from in theyidirections within the polytope l. the algorithm uses rejection sampling with at most msamples.
parameter sa ects the step radius.
the function adjusttosatisfy restores linear equalities that were violated during randomization by re computing a ected values from .
procedure randomstep fyijig l e f r2lg .linear equations formiterations do hyi normalrandom s jii adjusttosatisfy e if j lthen return end for return end procedure functions.
this can be seen as performing one step of the bisection method in the hope of jumping to a region where a solution is close.
setting v ceval r andv ceval r the slope of the linear approximation is t v v v and is the zero of t .
if v v a random slope is used.
.
discussion the cw algorithm uses a sound and complete o theshelf solver for linear constraints.
hence it is sound and complete for path conditions that contain only linear constraints.
for non linear path conditions the algorithm uses heuristic search.
the search ends with a negative result when it has exhausted its iteration budget.
thus it is not complete.
however it is sound because a returned environment must satisfy the non linear path condition nto escape the main loop and all generated neighbors lie within the polytope l. consequently satis es the original path condition p l n. .
implementation we have implemented the algorithm described in subsection .
as an extension of symbolic pathfinder spf .
spf is a symbolic execution engine built on top of the jpf veri cation framework.
our extension works with existing spf test drivers the only change required is enabling the extension by setting a con guration ag.
the implementation as well as the evaluation harness and the raw data are available for download on our website.
.
ev aluation this section evaluates how e ective and e cient the concolic walk cw algorithm is in solving path conditions with non linear arithmetic constraints.
to make the results comparable and link them to a practical application of the algorithm we measure e ectiveness as the coverage of generated test cases on a focused program corpus.
the corpus consists of programs whose path conditions contain mostly non linear constraints.
in subsection .
we evaluate the performance of the cw algorithm.
in subsection .
we investigate how the parameters of the algorithm in uence the coverage.
program corpus table lists the programs used in the evaluation together with the type of non linear operations appearing in their path conditions.
due to our focus on non linear arithmetic constraints the programs are samples from a population of programs that use such constraints they do not represent common programs.
to avoid a bias towards speci c strengths of our approach and to foster comparability we use mostly examples from works presenting other approaches to concrete symbolic and randomized solving of path conditions the coral program6is a collection of benchmark functions used to evaluate the coral constraint solver .
the functions consist of a single if statement whose condition includes a mixture of complex mathematical operations like calls to trigonometric functions.
opti contains the six non linear benchmark functions that were part of evaluating the flopsy oating point constraint solver .
the dart power sine stat and tsafe programs are part of the symbolic pathfinder distribution.
statcomputes the mean and standard deviation of a list of numbers and tsafe is an aviation safety program that predicts and resolves the loss of separation between airplanes.
blind is an implementation of figure and hash tries to provoke ve collision variants in a common hash function .
tcasfeatures involved but linear controlow.
it demonstrates how the evaluated algorithm behaves on classical testing problems.
finally the rayapplication7is a simple ray tracing renderer.
method we generate test cases for each program in the corpus and record the coverage of the generated tests with jacoco.8to account for randomness we repeat this process seven times and verify the statistical signi cance of observed di erences in f98 lecture20 raytrace.java programs used to evaluate the cw algorithm.
the loc column lists the number of source code lines in the program excluding comments and empty lines.
the operations column describes the type of operations appearing in the path condition.
program operations loc coral trigonometric functions polynomials blind multinomial hash polynomial shift bit wise xor opti exponentials square roots dart polynomials required over ow power exponential function ray polynomials dot product sine float to bit vector conversion stat mean and std.
dev.
computation tcas constant equality checks tsafe trigonometric functions the coverage and generation time distributions through nonparametric mann whitney u tests.9to account for varying di culty we perform one test per program between the seven measurements of the two compared algorithms.
unless stated otherwise the test is two tailed and the signi cance level is .
to prevent small programs from dominating the mean coverage of the algorithms we weight each program s contribution by the program s lines of code when computing the arithmetic mean.
the kind of coverage reported depends on the type of the program.
we distinguish between benchmarks and other programs.
benchmarks encode a single constraint that must be solved as a conditional in an if statement.
for these we report whether one of the generated test cases covers the target statement which indicates that the encoded constraint was solved.
branch coverage is a bad measure in this case because short circuit logic operators manifest as branches in the control ow meaning that despite solving the constraint some false branches may remain uncovered.
the other programs contain a more diverse range of execution paths that should be explored.
for these we report the total branch coverage of the generated test cases.
to avoid adverse e ects on a tool s performance from handling object creation each test invokes a single driver method with just numerical parameters.
thus the challenge of creating objects as test inputs is absent in our setup.
.
effectiveness and efficiency this section discusses the performance of the concolic walk algorithm.
rq1 is the cwalgorithm more effective than simplification for solving complex arithmetic path conditions?
we consider the null hypothesis that simpli cation isas effective as the cw algorithm in solving path conditions with non linear arithmetic constraints.
to test this hypothesis we compare the coverage achieved by our algorithm implementation against that of two other tools that use solvers for linear constraints but otherwise rely on simpli cation 9scipy.stats.mannwhitneyu in scipy v0.
.3table coverage and generation wall clock time of the test cases generated for each program.
the med.
columns show the median of seven runs the var.
columns show the respective variance.
for benchmarks the coverage is the percentage of covered target statements for other programs it is the branch coverage.
dots denote zeros.
the locweighted avg.
row lists the arithmetic mean over all programs using the loc as weights to prevent small programs from dominating the numbers.
coverage time sec.
program med.
var.
med.
var.
coral .
.
min.
.
blind .
hash .
.
opti .
.
dart .
power .
ray min.
.
sine .
.
.
stat .
tcas .
.
tsafe .
.
loc weighted avg.
.
.
min.
.
spf mixed is a variant of symbolic pathfinder that attempts to solve a non linear arithmetic path condition by solving the decidable simple part using the solution to concretely execute the complex part and then further simplifying all constraints using the results .
as suggested in the paper we enable the randomization heuristic of spf mixed.
in addition we increase the maximum number of solving tries to three per path condition instead of the default of one.
jcute is a classic concolic testing tool.
during the construction of a path condition it substitutes parts of non linear terms with their concrete run time value to ensure that all constraints remain linear.
in our setup jcute randomizes the initial concrete values and explores paths in random order.
both simpli cation based tools achieve a much lower coverage the weighted average of the median coverages is for jcute and for spf mixed the respective standard deviations are .
and .
.
this is far from the coverage achieved by our algorithm s.d.
.
see table .
on each program our algorithm achieves a higher coverage than jcute.
except for statand tcas the same is true for spf mixed.
all di erences are signi cant.
furthermore the inputs generated by our algorithm subsume the inputs of the other tools except for a small fraction of rayand statinputs which shows that the di erences are true improvements.
the draw between our algorithm and spf mixed on tcas which lacks non linear operations indicates that the di erences originate in the management of non linear constraints.
consequently we reject the null hypothesis the results suggest that the cw algorithm is more e ective than the simpli cation used in both tools.rq2 can the algorithm improve the effectiveness of concolic test generators that use strong solvers?
as discussed in section strong constraint solvers allow test generators to solve more path conditions directly thereby reducing the need to resort to approximations like simplication.
for such tools the cw algorithm can serve as a fallback strategy whenever the solver cannot handle the path condition.
however such cases might be rare with state ofthe art solvers.
we therefore investigate the null hypothesis that combining state of the art concolic test generators with the cw algorithm does notimprove the achieved coverage.
to test the hypothesis we consider combinations of our algorithm with two tools spf coral a symbolic execution tool that relies on the coral solver .
coral targets non linear arithmetic constraints and uses the particle swarm optimization search heuristic to nd solutions.
we use spf coral in the default con guration set in the spf repository.
pex10 a concolic test generator that employs tness guided exploration and a strong smt solver z3 .
because our experiment focuses on coverage rather than user responsiveness we increase pex s solver timeout to ve seconds and allow it to run up to iterations without generating new tests.
to avoid the cost of implementing the tool combinations we simulate them by unifying the generated tests.
for each run and each program we take the union of the inputs generated by spf coral and the cw algorithm and likewise for pex.
this allows us to measure the increase in coverage that our algorithm contributes inputs that lead to duplicated execution of already covered program paths have no e ect on the coverage.
the combination with the cw algorithm raises the averaged median coverage of spf coral from to s.d.
.
and .
and that of pex from to s.d.
.
and .
.
both tools achieve higher coverage on the coral opti ray and sine programs.
spf coral furthermore improves on hash dart and tcas while pex improves on tsafe.
in the case of sine this is not surprising the problematic example2 method in figure is a snippet of this program.
in the case of coral the tools and our algorithm complement each other the union of test inputs achieves higher coverage than each set of inputs alone.
aone tailed mann whitney u test on the coverages of each program between spf coral or pex and its combination with our algorithm indicates that all improvements are signi cant.
we therefore reject the null hypothesis and conclude that our algorithm can improve the e ectiveness of test generators that use strong constraint solvers.
rq3 how efficient is the cwalgorithm?
e ciency that is test coverage achieved per unit of generation time depends on implementation choices.
to reduce the impact of unrelated details such as the depth rst path exploration strategy that leads to min.
timeouts in ray 10pex is a c tool.
for the evaluation we translated the whole program corpus to c generated inputs with pex and made the inputs into java unit tests.
the coverage for pex is thus measured like that of other tools and directly comparable.we compare our spf based implementation against the two spf based test generators spf mixed and spf coral.
averaged over all programs our cw implementation .
coverage second is about .
times as e cient as spfcoral .
s and .
times as e cient as spf mixed .
s in generating test inputs.
one reason for the higher e ciency is the inability of spf mixed and spf coral to generate inputs for the hash and sine programs which contain bit operations and library calls.
however even on the coral benchmarks which lack such problems our algorithm is only slightly slower than spf mixed .
min.
vs. .
min but delivers considerably more solutions vs. it is .
times as fast as spf coral while achieving of the coverage vs. .
the coverage di erences of all programs are signi cant as are the time di erences for spf coral.
for spf mixed only of times di er signi cantly .
in summary these numbers suggest that the cw algorithm is more e cient than its two competitors.
.
influence of algorithm parameters this section discusses how the parameters of the cw algorithm in uence its e ectiveness.
in our experiments we vary a single parameter at a time and compare the variation s coverage with the baseline coverage shown in table .
rq4 how much does the tabu mechanism improve the effectiveness of the algorithm?
without the marking of variables as tabu the overall coverage drops to s.d.
.
which is .
times the baseline coverage.
thus the tabu mechanism contributes a relative performance increase of to the algorithm.
this performance change appears consistently over all runs of the algorithm the di erence is signi cant for all programs except sine whose hard oating point to bit vector conversion emphasizes the random walk aspect of our algorithm.
once tabu marking is enabled however the chosen number of tabu iterations seems to have little in uence on the algorithm s performance increasing it from the defaultt min jvars n j tot min jvars n j for example lacks any e ect on the coverage.
rq5 how much does the bisection step improve the effectiveness of the algorithm?
disabling the estimation of solutions through linear approximation the bisection step explained in subsection .
reduces the overall coverage to .
times the baseline.
thus the bisection step improves the overall coverage from s.d.
.
to a relative increase of about .
without bisection the algorithm consistently achieves lower coverage on the coral hash and opti benchmarks signi cant for .
it therefore seems that the bisection step steers the random walk towards promising areas resulting in more found solutions.
rq6 what influence do the number of neighbors and number of steps have on the performance?
for the majority of programs in the corpus granting the algorithm more steps to nd a solution or choosing among more neighbors has little e ect on the coverage.
the average coverage for just steps per constraint is .
times the baseline coverage.
likewise allowing more than the baseline steps per constraint leads to the same overall coverage.table fraction of the baseline coverage that the algorithm variations achieve.
values below .
mean less coverage than the baseline algorithm values above .
mean more coverage.
dots denote the value .
and indicate no change.
each variation changes a single parameter of the baseline algorithm which uses the following settings see algorithm i steps per constraint r neighbors t min jvars n j tabu iterations and bisection enabled.
each fraction is that of the median of seven runs.
benchmarks other algorithm variation w.avg.
coral blind hash opti dart power ray sine stat tcas tsafe tabu disabled t .
.
.
.
.
.
.
tabu extended t bisection disabled .
.
.
.
.
steps i .
.
.
.
.
steps i .
.
.
steps i .
.
neighbors r .
neighbors r .
.
neighbors r .
.
it appears that for most programs the constraints are simple enough that few steps su ce to nd a solution.
however for the complex constraints of coral more steps increase the coverage but only for steps per constraint is the di erence to the baseline signi cant .
the price for the relative coverage improvement from steps to steps per constraint is a relative slowdown of the test generation time grows from .
minutes s.d.
.3s for steps to .
minutes s.d.
.2s for steps per constraint.
the number of neighbors generated per step seems to have little in uence on the overall coverage.
the coverage di erences are statistically signi cant only for and for neighbors.
the slowdown from generating more neighbors is similar to that of increasing the number of steps.
.
limitations and future work evaluation threats to validity we try to ensure conclusion validity of our evaluation by checking the statistical signi cance of measured di erences with a robust non parametric test at a high level .
one threat to the construct validity of our experiments is the use of coverage as e ectiveness metric.
while branch coverage is a good predictor for the bug detection capability of test suites it does not measure how useful the generated inputs are for the user.
lacking a user study we are unfortunately limited to this common surrogate metric.
another threat in particular for rq1 is the aggregate nature of coverage two test suites with similar coverage may complement each other making them incomparable.
we mitigate this risk in by checking whether the test suite with higher coverage subsumes the one with lower coverage.
the internal validity of our experiments is threatened by our comparison of di erent tools.
many implementation details not just constraint solving in uence the performance.
we try to lessen this problem by a including a program in the corpus tcas that lacks non linear operations and ensuring that the compared tools have similar e ectiveness rq1 and b limiting the e ciency comparison to tools sharing the same spf based infrastructure rq3 .finally the external validity of our evaluation is threatened by our focused corpus.
despite over one third of programs being excerpts of realistic programs the corpus does not constitute a random sample of programs with non linear path conditions.
consequently our results may generalize poorly.
a larger study would mitigate this risk but is unfortunately too expensive at this time as the used tools spf jcute pex require signi cant manual setup.
algorithm the cw algorithm currently cannot create objects as test inputs.
while it could employ among others feedbackdirected randomization or heuristic search to ll this gap we plan to investigate in future work how exactly object randomization relates to the notions of continuity and neighborhood used by its local search strategy.
for arithmetic constraints the algorithm assumes an at least piece wise continuity of the constraint error score functions to identify the most promising neighbor.
while the assumption seems to work well in practice other modes of nding solutions may be more e ective for highly noncontinuous operations like hash functions.
the algorithm currently makes no provisions for disjunctive constraints for which the linear constraints can describe non contiguous regions.
while disjunctions cannot occur if boolean connectives are encoded in the program s controlow as assumed in this paper tools that work under di erent assumptions may have to spawn multiple instances of the algorithm.
support for non contiguous regions within a subset of dimensions would improve the algorithm s applicability in such scenarios.
implementation the cw implementation described in section assumes that the native methods occurring in constraints are pure that is lack side e ects.
a more general implementation could purge this assumptions by integrating setup and tear down methods as in unit tests that are executed before and after each constraint evaluation and by maintaining the program s execution order for native methods.
furthermore a better implementation could accelerate the algorithm a byexecuting constraint expressions directly in the jvm instead of interpreting them b by caching the error scores of constraints whose inputs remained unchanged during a step and c by using memoized solutions to seed the starting point.
.
related work the concolic walk algorithm cw presented in this paper uses a mix of heuristic search and symbolic reasoning to generate inputs that satisfy a path condition.
search based software testing combinations of heuristic search and symbolic reasoning have been explored in the context of search based software testing sbst .
like our approach sbst searches for test inputs that meet a coverage criterion by iteratively selecting inputs that according to a tness function seem closer to a solution.
however inputs can vary in granularity ranging from primitive values to method sequences for constructing objects.
common heuristics for nding better inputs are genetic algorithms ga as well as the alternating variable method avm which is similar to the adaptive search used by us.
heuristic search can be slow in discovering the speci c solutions of narrow branch conditions.
a number of approaches thus suggests to accelerate the search through symbolic reasoning the evacon framework constructs high coverage tests for object oriented programs by alternating between generating method sequences for object creation via ga and generating primitive method arguments via concolic execution.
other techniques introduce a mutation operator in the ga that yields new test individuals by concolically executing an existing test and ipping a branch condition .
symbolic execution has also been applied to derive tness functions that represent the search landscape more accurately thereby improving the e ciency of the search heuristic.
these approaches di er from ours in that they use symbolic reasoning as part of heuristic search steps.
in contrast the cw algorithm uses heuristic search to solve a symbolic path condition.
the robustness and strength that symbolic solving gains from the cw algorithm would thus bene t the hybrid sbst approaches without any further modi cation.
symbolic and concolic execution search heuristics have been applied to concolic testing.
the fitnex approach improves the coverage of concolic testing by picking the ttest path for exploration in each iteration.
however fitnex is independent of the path condition solver.
in particular it does not in uence how classic concolic execution replaces unsolvable constraints with concrete values see section .
instead of simplifying such constraints our algorithm evaluates them to avoid the coarse approximations from blind commitment to concrete values.
this notion of using concrete execution to solve undecidable arithmetic constraints during symbolic execution has been explored as mixed concrete symbolic solving see section .
like our approach mixed solving seeks to avoid blind commitment and therefore does not eagerly simplify the path condition with run time values.
however simpli cation remains a central strategy.
another di erence is that mixed solving makes no assumptions about the type of directly solvable constraints.
henceit must rely on the solver to provide all concrete inputs for executing the complex constraints.
yet no mechanism guides the solver towards potential solutions for the complex constraints when re solving the simple constraints.
a similar disconnect between simple and complex constraints limits the performance of solvers based purely on randomization and substitution based simpli cation .
search based constraint solving search heuristics similar to the adaptive search used in our approach have been used for solving complex arithmetic constraints.
in contrast to the cw algorithm the resulting solvers are domain speci c and lack callback interfaces to include previously unknown functions in the constraints.
the coral solver uses particle swarm optimization and avm to solve constraints that include rich mathematical operations like exponentiation and trigonometric functions.
a recent extension improves coral s e ciency by seeding the initial solution population through interval solving.
flopsy is a plugin for pex that solves oating point constraints with heuristic search methods including avm.
random testing to facilitate random testing of speci c program parts gotlieb and petit show how to construct a domain for uniformly sampling inputs that satisfy a path condition.
the approach is based on constraint propagation and refutation.
unlike our approach it cannot handle uninterpreted functions or bit wise operations in the path condition.
.
conclusions the path conditions of programs may contain calls to library methods and complicated arithmetic constraints that are infeasible to solve.
yet test input generators based on symbolic and concolic execution must solve such path conditions to systematically explore the program paths and produce high coverage tests.
existing approaches either simplify complicated constraints or rely on specialized constraint solvers.
however simpli cation yields few solutions and specialized constraint solvers lack support for native library methods.
to address both limitations this paper introduces the cw algorithm for solving path conditions.
an evaluation on a corpus of small to medium sized programs shows that the algorithm generates tests with higher coverage than simpli cation based tools and moreover improves the coverage of state of the art concolic test generators.
.