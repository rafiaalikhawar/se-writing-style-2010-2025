a scalable approach for malware detection through bounded feature space behavior modeling mahinthan chandramohan hee beng kuan tan lionel c. briand lwin khin shar and bindu madhavi padmanabhuni school of electrical and electronic engineering nanyang technological university singapore.
mahintha001 padm0010 e.ntu.edu.sg ibktan lkshar ntu.edu.sg snt centre university of luxembourg luxembourg.
lionel.briand uni.lu abstract in recent years malware malicious software has greatly evolved and has become very sophisticated.
the evolution of malware makes it difficult to detect using traditional signature based malware detectors.
thus researchers have proposed various behavior based malware detection techniques to mitigate this problem.
however there are still serious shortcomings related to scalability and computational complexity in existing malware behavior modeling techniques .
this raise s questions about the practical appl icability of these techniques.
this paper proposes and evaluates a b ounded feature space behavior m odeling bofm framework for scalable malware detection.
bofm models the interactions between software which can be malware or benign and security critica l os resources in a scalable manner.
information collected at run time according to this model is then used by machine learning algorithms to learn how to accurately classify software as malware or benign.
one of the key problems with simple malware behavi or modeling e.g.
n gram model is that the number of malware features i.e.
signatures grows proportional to the size of execution trace s with a resulting malware feature space that is so large that it makes the detection process very challenging.
on the other hand in bofm the malware feature space is bounded by an upper limit n a constant and the results of our experiments show that its computation time and memory usage are vastly lower than in currently reported malware detection techniques whi le preserving or even improving their high detection accuracy.
index terms malware detection malware behavior modeling i. introduction exponential growth of malware malicious software is a major threat in the software industry.
symantec an anti malware vendor reported that more than million new malware variants were created in a increase over .
at the same time targeted attacks such as stuxnet and duqu and advanced persistent threats apt also showed a steady increase in recent years .
despite the widespread use and availability of various anti malware commonly known as anti virus tools the growth of m alware is phenomenal.
it is observed that malware has greatly evolved where new malware has become very sophisticated and is designed to avoid traditional anti virus signatures using various obfuscation techniques .
given the alarming growth of malwar e a significant amount of research has focused on proposing various malware detection techniques to mitigate this problem.
we can divide these techniques into two broad categories static or signature based and dynamic or behavior based malware detect ion.
signature based malware detection has an advantage over behavior based analysis since it examines the static content of the malicious binary and thus is able to achieve full code coverage.
in addition using signatures it is even possible to detect malicious applications before they are executed.
however the major limitation of signature based malware detection is that it can be easily evaded by basic obfuscation techniques.
further malware authors can change the syntactic characteristics i.e.
st ructure of a malicious program without changing its semantics i.e.
behavior .
unfortunately signature based malware detection is still the predominant detection method today .
to overcome the limitations of signature based malware detection security researchers have proposed various behavior based malware detection techniques that focus on the semantic s of the malicious application.
in particular these techniques examine the run time behavior of the malicious binary and analyze the system calls e.g.
win32 and native api functions invoked during execution in order to model its malicious behavior.
the key behavior based malware modeling techniques include bags of system call s sequence of system calls such as n gram model individual system call analysis behavioral graphs and system call dependency graphs .
however one of the key issues in existing behavior based malware modeling techniques is that the scalability of these approaches is highly problematic.
here scalability refers to the size of malware features or signatures extracted from an execution tr ace.
for example even a simple model such as bags of system calls generates a number of malware features that grows proportional ly to the size of execution trace s .
this makes the detection process impractical as huge feature space s make the learning process computationally intensive and detection might be negatively affected if most of the se features are irrelevant.
in addition to the scalability of feature spaces unacceptably high computational complexity and memory consumption are also expected to impact the practicality and efficiency of a malware detector.
as a result practical applications of complex malware behavior modeling technique s such as system call dependency graph and behavioral graph are very limited in practice .
for example in it is reported that it took hours to extract malware specification s from a network worm using a graph mining algorithm.
in this paper we propose and evaluate a simple yet efficient malware behavior modeling technique called bofm that system atically captures the interactions between malware and security critical system resources in a scalable manner at an adequate level of abstraction .
in bofm scalability is achieved through constructing an upper bounded malware feature space with a predete rmined value n discussed in section iv .
in other words bofm can extract malware features that do not grow in proportion with the number of program samples under examination.
in addition bofm is resilient against basic obfuscation techniques .
as bofm is both accurate and efficient it can be used to complement traditional anti virus tools by leverag ing on bofm features to accurately detect malware at the end host.
indeed our results show that when combined with machine learning techniques bofm is not only at least as accurate as existing malware detection techniques but its computation times e.g.
for matching signatures and memory consumption are vastl y lower as well thus making it a much more practical and scalable approach.
in summary this paper makes the following contributions we propose a malware behaviour modelling technique called bofm that captures malicious interactions b etween malware an d security critical os resources in a scalable manner.
this is in turn combined with machine learning techniques for automated malware detection.
we conducted and report an experiment involving malware and benign samples collected from various sources.
our experimental results show that bofm when combined with appropriate machine learning classifiers can achieve .
malware detection rate with no false positives the latter being important in our co ntext.
we show that the feature space generated by bofm is of fixed dimension does not grow with the number of ma lware samples under examination and is three orders of magnitude smaller than with the best reported techniques for malware behaviour modelling.
as a result comput ation times and memory usage for extracting program fe atures and malware detection are vastly decreased.
the paper is organized as follows.
section ii summarizes the related wo rk and our motivation.
section iii gives an overview of our behavior modeling technique.
section iv defines our bounded feature space behavior modeling technique .
section v describes the featu re vector construction .
section vi presents the detection method.
section vii describes the experimental design .
section viii summarizes and discusses the experimental results .
finally section ix concludes the paper.
ii.
related work and motivations past research includes several useful techniques for malware detection.
in this section we shall present related research works and discuss the pros and cons of these approaches.
the recent st udy on behavior based malware detection reported by canali et al.
is most relevant to our current work.
in the authors have done a comprehensive study on analyzing the efficiency of various malware behavior modeling techniques.
they organized the behavior models based on three dimensions the granularity of bas ic model elements i.e.
system calls at various levels of abstraction such as with and without parameters the relationship among basic model elements such as n gram m bag and ktuple1 and cardinality of each specification i.e.
values of n m and k .
a series of more than experiments were conducted on a large set of malware and benign samples to systematically identify the optimal behavior model for malware detection.
t heir experiment results revealed th at the optimal behavior model bags of tuples of action with arguments achieved a detection rate with only a .
false positive rate.
though the above results are very encouraging there are several shortcomings associated with this approach.
the most important issue is that the scalability of this approach is highly problematic.
the behavior modeling techniques such as ngram m bag and k tuple can easily generate huge feature spaces.
for example from an executi on trace with unique system calls more than million features are constructed using m bag model with a bag cardinality of m .
this problem is even worse in tuple based behavior models.
in it is also reported that the memory consumption is one of the major threat to practical implementation of this approach where on a standard machine intel dual core .
ghz with 4gb of ram the prototype malware detector consu med 1gb of ram for million malware signatures.
further it is also reporte d that feature extraction from malware samples is itself a computationally intensive task where almost days of computation are required for tuples of syste m calls with arguments model .
in addition the approach in requires several parameter tunings for optimal performance that makes it less practical .
moreover i t is observed that intensive parameter tuning is often associated with overfitting problems.
for example to manage the huge feature space authors have proposed a feature pruning mechanism.
a malware feature is discarded if it is not general enough i.e.
doesn t detect at least five malwares or too redundant i.e.
not represented by other signatures where the values and are arbitrarily selected.
further there is a trade off in selecting the cardinality of a specification e.g.
number of basic model elements in a bag where increasing the cardinality may result in a high detection rate but also l ead to overfitting.
for example in it is reported that detection rates achieved by tuple based behavior models are highly sensitive to please refer to for definitions of n gram m bag and k tuple models cardinality.
finally the alert threshold the number of malware signatures that need to be matched to flag an unkn own program as malware significantly influences the detection rate and false positive rate.
in it is shown that small alert threshold results in high detection and false positive rate and vice versa.
thus choosing the appropriate values for these parameters is crucial but complex in practice .
apart from there are several other behavior based malware modeling techniques proposed in the literature.
lanzi et al.
proposed accessminer a malware detection technique based on system centric malwar e models where the interaction between benign sample and the os resources is modeled in a system centric manner.
this addresses the limitation of program centric approaches.
further authors empirically proved the inefficiencies of n gram based malware behavior modeling .
in addition to generic malware detection system call and library call based behavior modeling is also proposed to detect more specific class of malware such as spyware kirda et al.
and botnets stinson et al.
detect ion.
kolbitsch et al.
proposed an efficient and effective malware detection approach at the end host where it models the malware behavior as a graph and detection is done at the end host using graph matching.
similarly fredrikson et al.
proposed malware specification mining using dependency graphs.
they managed to achieve a higher detection rate than two commercial behavior based malware detectors.
however graph mining still remains very computationally intensive where it is reported that it to ok around hours to extract malware specification from certain network worms.
in addition the dataset used in most of these approaches are very limited.
for example kolbitsch et al.
used only malware samples and benign samples similarly christodorescu et al.
used malware and benign samples stinson et al.
used malware and benign samples and martignoni et al.
used only malware and benign samples for evaluation.
we derive the following key observations based on the abovementioned behavior based malware detection approaches the p racticality and efficiency of malware detection techniques are characterized on four dimensions the size of feature space computational complexity ove rhead in terms of additional pre processing activities and detection accuracy.
simple malware behaviour models such as n gram mbag and k tuple generate huge feature spaces and r equire various pruning and parameter tuning mech anisms to alleviate the pr oblem.
more complex malware behaviour models such as d ependency and behavioural graphs are generally highly computationally and data intensive.
in the n ext two sections we explain our proposed approach bounded feature space behavior modeling bofm which aims at making malware detection scalable efficient and practical while retaining or improving the high accuracy reported thus far in the literature.
iii.
overview malwares usually achieve their objectives through performing malicious actions on secu rity critical operating system resources.
an action corresponds to a high level operation e.g.
reading a file that is comp osed of a set of related system calls to achieve an externally meaningful objective .
for example reading a file may requir e two system calls ntopenfile to open the file and ntreadfile to read the file content.
the main advanta ge of using actions over system calls is that different versions of the same operating system e.g.
windows and windows xp may use different names for system calls that are in fact serving the same purpose and as a result analyzing system calls directly may result in dealing with unnecessarily large amounts of data.
for example in windows os the system calls ntcreateproce ss and ntcreateprocessex are both used to create a new process.
thus these two system calls can be mapped to a single action called create process .
system call sequences can be mapped to actions using a mapping algorithm .
there are a number of differen t mapping algorithms used in the malware research community.
depending on the algorithm used the system call sequence ntopenfile ntreadfile can be mapped to two distinct actions openf ile and readf ile respectively or both system calls can be combined to represent a single action readf ile.
in the remainder of this section we first discuss the various types of os resources and t hen we introduce and illustrate our behavior modeling technique by using an example.
a. operating system resource types the a nalysis of malicious behavior is usually carried out through examining the actions it performs on security critical system resources.
in the literature researchers usually model malware behavior based on its interaction with certain types of os resources such as file system registry p rocess and network.
for example kolbitsch et al.
considered security relevant system calls associated with file system registry network process and system services for malware detection whereas in our previous work we considered the actions performed on four security critical os resource types such as file system registry process and network for malware clustering.
based on the broad classification of system calls reported in and windows os internals we have considered the following os resource ty pes in our study file system registry process thread section network and synchronization.
next we shall briefly describe each of these os resource types.
file system.
operating system and the prog rams that run on it are made up of individual files.
a file is an i nstance of any opened file or i o device.
registry.
registry is a system defined database in which applications and system components store and retrieve configuration data .
process a nd thread .
process is the virtual address space and control information necessary for the ex e cution of a set of thread s one or more threads run in the context of such process .
network.
this corresponds to the network related activ ities of the program being executed.
synchronization .
this aims to protect shared resources from simultaneous access by multiple threads or pro cesses .
section.
section represents a portion of memory that can be shared where a process can use section to sha re parts of its memory addre ss space with other processes .
we model malicious behavior based on the sets of actions that malware performs on individual os resource instances .
an os resource instance corresponds to an identifier or instance of a n os resource type.
for example for f ile system file names e.g.
c foo.exe and c windows abc .dll are identifiers and the actions perform ed on each of these file instance s include openfile readfile and deletefile .
a comprehensive list of actions that a malware can perform on each os resource type is given in table .
table os resources and corresponding actions os resource types of actions list of a ctions file system createdirectory querydirectory createfile setfileinformation unlockfile lockfile openfile writefile queryfileattributes queryfilevolume deletefile read file devicecontrol queryfileinformation registry createkey deletekey deletevalue setvalue openkey notifychangekey queryvalue process thread setinformationprocesses create process createthread openprocess killprocess queryinformationprocess synchronization createmutex opensemaphore createsemaphore openmutex releasemutex releasesemaphore network networkconnection section opensection createsection querysection mapviewofsectoin next we shall present an example to illustrate our behavior modeling technique.
this example is used as a running example in this paper.
b. example a sample malware execution trace is given in figure where system calls are already mapped to high level actions.
in a real world scenario a single malware execution trace can contain several thousands of actions .
however t o keep it simple we have only considered few file and registry related actions in this example.
the behavior of our pseudo malware is given below creates a malicious executable along with three other dummy files.
reads two system files and a dummy file several times .
creates a registry key and sets its value.
deletes all the dummy files .
createfile c windows malicious.exe createfile c windows ... dummy1.txt readfile c windows ... dummy1.txt createfile c windows dummy2.dll readfile c windows ... sysfile1.ini readfile c windows ... sysfile2.dll createkey hklm software ... ... key setvalue hklm software ... ... key value readfile c windows ... dummy1.txt readfile c windows ... dummy1.txt deletefile c windows ... dummy1.txt createfile d personel dummy3.exe deletefile d personel dummy3.exe deletefile c windows dummy2.dll readfile c windows ... sysfile2.dll fig.
.
sample malware execution trace table extracted malware fea tures id features action set os resource i nstances createkey setvalue hklm software ... ... key createfile c windows malicious.exe createfile readfile deletefile c windows ... dummy1.
txt readfile c windows ... sysfile1.ini c windows ... sysfile2.dll createfile deletefile c windows dummy2.
dll d personel dummy3.exe table shows in column the five extracted features from the sample malware execution trace shown in figure .
as we will see in the next section features are actio n sets that is features are constructed by grouping related actions performed by malware on individual os resource instance s where related actions refers to actions belonging to the same os resource type.
column in table shows the os resource instances on which features are performed.
for example the action set createfile readfile deletefile is performed on a file r esource c windows ... dummy1.
txt id and action set readfile is performed on two different os resource instan ces c windows ... sysfile .ini and c windows ... sysfile2 .
dll id .
in table id represent malware features corr esponding to file system and id represent s a feature corr esponding to r egistry.
it is important to note that os resource instances column in table are only used to identify rela ted action s and are not included in the feature vector s used to support malware detection section v .
this is due to the fact that malware tend to use random file names mutex values and registry key values each time they execute and therefore there is no agreed upon mechanism to generali ze these highly volatile artifacts .
next we shall precisely define our malware behavior modeling technique bofm and explain its properties.
iv.
bounded feature space behaviour modelling bofm a malware perform various actions on one or more os resour ce instances.
in the proposed bofm for each type of os resources the set of related actions performed by malware on an individual resource instance constitutes a feature of the malware.
that is in our example see section iii.b the set of related actions createkey setvalue performed by malware on a registry instance hklm software ... ... key constitutes a feature id .
in total five features are extracted see column in table from the malware executio n trace shown in figure .
due to our modeling preference bofm features hold the following three key properties property regardless of the number of times an action is performed if the same set of actions is performed on os resource instance s of the same type this leads to identical malware fe atures.
for instance in our example readfile action is performed only once on file instance c windows ... sysfile .ini and twice on file instance c windows ... sysfile2.dll however these two behaviors are considered to be identical and are represented by a single malware feature readfile id .
property the sequence in which the actions are performed by malware is ignored in feature construction .
that is in our example malware read the contents of system file c windows ... sysfile1.ini way ahead of creating file d personel dummy3.exe however this information i.e.
sequence is not captured by bofm features.
in addition ordering of actions in an action set is also ignored.
that is feature s readfile queryfile infor mat ion and queryfile information readfile are considered ident ical.
property identical action sets which are performed on two different os resource instances of same type are modeled as a single feature.
in our example action set createfile deletefile is modeled as a single malware feature even though it is performed on two different file resource instances c windows dummy2.dll and d personel dummy3.exe id .
next we shall formally derive the upper bound for malware feature s constructed using bofm .
upper bound .
let us assume there are types of os resources and for each os resource type the possible actions that a program can perform are always predefined and fixed.
the list actions considered for each os resource type in table is a representative example .
thus the total number of possible actions that a malware may perform on a resource instance of type is a constant.
conse quently the maximum number of possible features or action sets with regard to os resource type is also a constant and can be computed as follows ... where therefore as a result of applying bofm the total number of possible features extracted from all resource types is always the following constant from equation it can be seen that the total number of features of a malware depends only on the total number of os resource types and the number of possible actions performed on each os resource type .
based on the number of actions considered for file system using equation the maximum possible number of malware features that can be extracted is .
similarly the maximum possible number of malware features extrac ted for various resources are r egistry network process t hread synchronization and section .
finally using equation the total number of malware features n that can be extracted from these six os resource types sums up to .
it s worth noting that t he value of n calculated above is specific to this study.
in practice it will vary based on the number of os resource types and list of action s considered in a given context.
hence in contrast to existing approaches in which the feature space grows in direct proportion to number of malware instances under examination the total number of possible features for malware detection under our approac h has an upper bound n .
that is our approach has a bounded feature space and this is expected to improve the scalability of malware behavior modeling.
further we observed that malware s often perform a combination of actions that are not normally performed by benign applications.
this behavior is captured by the hypothesis below.
hypothesis action set c haracterization .
to achieve malicious objectives malware tend to perform sets of actions on a number of os resou rce types that are significantly different from benign applications.
rationale.
obfuscation techniques such as dead code injection subroutine reordering instruction substitution and code transposition are widely used to evade tradition al signature based malware detection .
it is observed that malware authors often reorder independent actions2 and repeat certain actions many times e.g.
perform readfile action in a loop to break the byte sequence or code pattern without affecting the semantics of the program to fool byte or action sequen ce based malware detection techniques .
therefore accounting for the sequence of actions in behavior modeling may have the adverse ef fect of failing to capture identical high level behavior with different action sequence.
in addition as opposed to sets sequence s of actions similar to these actions are independent from others and any permutation of these a ctions will lead to the same end behavior n gram w ould result in a huge feature space and thus w ould be much less scalable.
thus we modeled the malware behavior as a set of actions in contrast to sequences to overcome the above mentioned obfuscation techniques .
the advantage of using set in malware behavior modeling is twofold repeated actions are ignored property and agnostic to reordering of independent action s property .
though it is noted that there is a trade off in using sets as the ordering of actions may constitute valuable information in practice malware authors often use obfuscation techniques that render this information useless .
further os resource instances column in table are not considered for malware detection as they are highly volatile i.e.
involve random ness and there is no agreed upon mecha nism to generalize these highly volatile artifacts such as file names mutex values and ip address es property .
v. construction of feature vectors in this section we explain how we extract malware features from execution traces and embed them in feature vectors .
a. collecting execution traces the run time behavior of malware instances are monitored using a sandbox which is a dynamic malware analysis tool such as cwsandbox anubis and cuckoo sandbox .
these systems execute programs in a controlled environment monitor their behavior and generate behavior reports.
these reports generally contain high level action based malware behavioral characteristics such as newly created modified deleted file details registry keys and network traffic details.
few sandboxes such as cuckoo sandbox also provide low level behavioral characteristics i.e.
win32 and native api functions based .
in such cases system calls can be mapped to relevant high level actions using an appropriate mapping algorithm .
it is also noted that system calls can be used to model malware behavior but as mentioned earlier one mu st be aware of different system calls serving the same purpose e.g.
ntcreateprocess and ntcreate process ex .
b. extraction of features feature extraction from an execution trace involves three steps .
they are as follows step os resource instances present in the execution trace are identified .
step related actions3 corresponding to an os resource instance are grouped forming action sets.
step repeat step until all the os re source instances identified in s tep are covered.
each unique action set constructed in step constitute a feature see section iii.b .
similar to other approaches we use feature vector to embed the extracted malware features.
next we shall explain feature vector con struction.
related actions refer to actions belonging to the same os r esource type.
... malware fig.
.
feature v ector c. n dimensional feature vector for each malware once the malware features ar e extracted column in table from the execution traces we embed them in an n component or n dimensional feature vector where n is the total number of possible feature s equation .
each component in a feature vector is designated to represent a possible malware feature.
we re emphasize that os resource identifiers are only used to identify related action s and are not part of feature vector s. figure depicts a feature vector constructed using malware f eatures column in table extracted from execution traces shown i n figure .
in a feature vector the nth component represent s feature n denoted by fn and each feature is assigned a value or to denote the presence i.e.
active or absence of that feature respectively.
active features4 refer to thos e features present in a malware or benign program .
it is also noted that extracting features from benign programs exactly follows the same process as explained above except that it is executed on a real world machine instead of a sandbox to collect representative execution trace s. in addition the length of benign feature vectors is also upper bounde d by a constant n equation .
to summarize each malware and benign application is converted into an ndimensional binary feature vector in our case n .
vi.
detection method based on our analysis of related work section ii we find that not many behavior based malware detection frameworks adopt machine learning classification techniques to build detection engines.
this is may be due to the fact that when the feature space is extremely large the learning process will be computationally intensive and negatively affected if most of the features are irrelevant.
in contrast due to its limited feature space bofm is amenable to the use of machine learning ml cl assification techniques for buil ding malware detection models.
in our approach machine learning classifiers are used to classify unknown software as either malware or benign .
we tried and compared a number of ml classification techniques and report here o n the results with logistic regression lr and support vector machine svm .
the latter is reported as it is a recent technique that has shown to work well in a number of applications is based on a non probabilistic theory about learning struc tures in data and yields the best results in our particular case.
the former is a standard probabilistic technique that yields regression models in the following sections of the paper when we refer to features extracted by bofm we implicitly refer to active features unless otherwise stated.
the number of active features is always less than or equal to n. createkey setvalue createfile createfile readfile deletefile readfile createfile deletefile features samples f16 which are easy to interpret in particular to assess what features are statistically significant predictors of malware.
the m alware detection process includes two phases model building and model evaluation.
during the model building phase a training set of benign and malware feature vectors is used by the ml algorithm to build a classifier.
the model evaluation phase aims at assessing the classifier accuracy in a realistic fashion.
by analyzing the actual classification benign or malware of feature vectors present in the training set an ml algorithm generates a trained classifier e.g.
a logistic regression equation with estimated parameter values.
next during the model evaluation phase a test set of benign and malware feature vectors is classified by the trained classifier.
based on classification results the performance of the classifier is evaluated b y computing standard accuracy evaluation criteria.
note that computing such criteria require s the actual class labels of feature vectors in the test set in order to compare the actual class with the class predicted by the trained c lassifier .
vii.
experimental design to evaluate the effectiveness of bofm in distinguishing between malicious and benign behaviors we performed a large set of experiments.
in the following sub sections we describe the dataset s used in our experiments and describe the evaluation criteria used to evaluate our malware predictions.
a. experimental dataset we used three different datasets in our experiments.
the first dataset called malware train is a collection of execution traces of malware samples obtained from the a nubis database.
similarly the second dataset called malware test contains execution traces of malware samples that are collected on a machine that is not used to run anubis .
it is noted that these two datasets malware test and malware train are obtained from canali et al.
.
the final dataset called benign contains the execution traces of benign samples collected from five different real world machines pcs where each machine ran benign programs .
obtaining execution traces from various machines for both benign and malware programs helps lower the chances that machine specific artifacts influence the final outcome .
the benign dataset consists of applications that are commonly used by a standard user e.g.
ms word firefox and that are mostly interactive applications.
thus following the approach in we obtained representative execution trace s by simulating the user interaction with the application for around minutes.
for example for a word processor applicati on i.e.
ms word we created a new document including text images and diagrams and saved it to disk used several ms word plug ins such as endnote and opened few already existing documents.
similarly for a web browser e.g.
firefox we connected t o our university webpage and downloaded few documents from the site uploaded few files the server sent an e mail using gmail and used several browser plug ins such as adblock and pdf viewer.
likewise for all interactive benign applicat ions we performed a set of required operations to get representative execution trace s. it is important to note that to be consistent with malware execution traces obtained using anubis we selected the same subset of system calls as used in anubis from the benign execution traces.
in addition to ascertain whether and explain why a minute simulated user interaction with a benign application is good enough to represent real world user behavior in terms of bofm features we conducted a simple experiment.
we compared a representative execution trace of ms word application monitored for eight hours obtained from a real world machine with an execution trace of same application but with simulated user interaction.
the f indings are summarized in table .
from table it can be seen that the execution trace obtained using real world user interactions trace a is larger in size and has a larger number of system calls than the execution trace with simulate d user interaction trace b .
however the number of features extracted using bofm is larger for trace b than for trace a. this shows that in real world people often tend to use a small fraction of operations e.g.
intuitive operations and thus generate large execution traces with limited number of useful features.
hence in order to get real and representative execution traces for an application and thus build accurate malware predictors one should simulate the user interaction to explore as many features as possible.
table comparison of executi on trace for simulat ed user and real world user interacti ons real world user interaction a simulated user interaction b application ms word ms word execution environment real world pc real world pc execution time hours minutes size of execution trace kb kb of system calls obtained extracted bofm features of c ommon features .
further when selecting the benign application s for evaluation we made sure that they were from one of the following functionally diverse categories word processors e.g.
ms word text editors e.g.
ms wordpad command line shell e.g.
cmd.exe web browser e.g.
firefox file transfer e.g.
filezilla ftp server remote access e.g.
putty ssh client e mail e.g.
ms outlook ide e.g.
ms visual studio media e.g.
vlc player game e.g.
chess titans anti visus tool e.g.
avg antivirus voip e.g.
skype cloud storage e.g.
dropbox reader e.g.
adobe pdf reader and other utility tools e.g.
google desktop .
we observed that execution traces of benign applications in the same category looked similar.
for example using bofm we managed to extract features fr om notepad and features from wordpad execution traces out of which features were common to both applications.
that is .
of notepad features and .
of wordpad features are identical.
this indicates that as long as we include a few benign applications from each category it is sufficient to cover a wide range of benign applications in terms of functionality.
thus we can confidently say that our benign dataset of applications at least three from each category is sufficien tly representative to build classifiers to accurately predict malware as it will be confirmed by our experimental results.
it is also worth noting that in the literature researchers have used very small benign dataset in the range of applications and that our experiment is much more extensive with that respect.
finally as mentioned in section vi malware detection consists of two phases model building and evaluation.
to build the models we used a training set consisting of malware train and execution traces of benign samples obtain ed from out of machines.
to evaluate the classifier models we used a test set consisting of malware test and benign execution traces from the machine that was not used for training.
this process is repeated five times where on each iteration the t est set consists of benign execution traces selected from a different machine.
due to space constraints only averages across the five experiments are presented in the paper.
table presents an overview of the benign and malware datasets used in our experiments.
table overview of malware and benign datasets malware d ataset benign d ataset total number of samples execution environment sandbox real world pc s max.
size of an execution trace kb kb min.
size of an execution trace kb kb avg.
size of an execution trace kb kb total no.
of system calls avg.
of system calls sample b. evaluation measures we employ standard evaluation measures including true positive rate tpr false positive rate fpr and total accuracy to evaluate the malware detection accuracy.
we refer to definitions in for further details but for the sake of completeness we briefly explain them here.
we can use the following contingency table to define the four possible outcomes i.e.
tp fp fn and tn from a binary classifier.
predicted outcome actual value malware benign malware true positive tp false positive fp benign false negative fn true negative tn true positive rate tpr is in our context the proportion of malware samples correctly classified as malware.
similarly false positive rate fpr is the proportion of benign samples misclassified as malware.
finally total accuracy or detection accuracy measures the overall proportion of correctly classified instances either malware or benign.
these measures are formally defined as follows table summary of malware detection accuracy achieved by lr and svm classifier true positive rate counts false positive rate counts total accuracy counts lr .
.
.
svm .
.
.
c. experimental setup all the experiments were executed using a core xeon r with gb ram machine installed with ubuntu .
.
in addition a well known machine learning t ool weka was used to build the malware detection classifiers.
next we shall present and discuss the malware detection accuracy obtained by our framework.
viii.
experimental results to assess the accuracy of our classifiers in detecting malicious code we measured the true positive rate false positive rate and total accuracy achieved by bofm for both logistic regression lr and support vector machine svm .
as explained in section vii.a we used a training set of malware and benign samples and a test set of malware and benign samples.
the experiment is repeated five times with different set s of benign samples in the test set refer section vii.a for explanation following a standard fold cross validation process.
the average results for lr and svm across all five expe riments are presented in table in the form of both rates and counts .
from table it can be seen that both lr and svm achieved similar detection accuracy.
for lr the slightly better detection accuracy of .
compared to .
for svm comes at the cost of a false positive rate.
in malware detection a lower or zero false positive rate is desired since the consequences of flagging a benign application as malware can be disastrous .
for example if a benign system file is flagged as malicious and deleted from the system in the worst case it may prevent the syste m from booting .
thus we can conclude that svm is a preferable solution to lr in our context.
since our original test set contained a much higher proportion of malware we needed to check this imbalance did not bias our results and ran the experiment agai n with a randomly selected balanced subset test set .
test set consists of randomly selected from a pool of samples malware samples and the benign samples used in the original test set.
again we repeated the experiment five times following the same procedure as on the original data set and the averages a cross the five experiments were analyzed.
svm yielded a perfect accuracy of thus not misclassifying a number of malware features0150300450600 10002000300040005000bofm0150000300000450000600000 gramnumber of malware featuresnumber of malware samples a number of malware samples b single program.
however lr achieved .
detection accuracy with false positive rate.
thus based on these two experimental results we can con firm that svm performs relatively better than lr for malware detection.
further the results also suggest that the accuracy of our overall approach based on bofm is very encouraging.
in addition we also performed sensitivity analysis to investi gate how individual os resource types influence malware detection rates.
that is we repeated the above experiment six times using test set where on each instance we considered features corresponding to an individual os resource type.
for sensitivity analysis we used svm as our classifier and table summar izes the outcomes.
from table it can be seen that for each os resource type the false positive rate is unacceptably high.
however two os resource types file system and process thread managed to achieve a detection accuracy of or greater with a false positive rate of and respectively.
thus we can conclude that features corresponding to individual os resource type s alone not sufficient for malware detection as they generate unacceptably high false positive r ates.
a. feature space analysis in this section we compare the features extracted from malware samples using bofm and n gram n or bigram model a simple behavior modeling technique .
for this analysis we considered malware samples that is used to train our classifier .
one of the key aspects of bofm is the bounded feature space where the number of active features doesn t grow in proportion with the number of samples or size of execution trace under evaluation.
to visualize this characteristic of bofm in figure b we have plotted the feature space or active features growth against malware sample sizes .
from figure b it can be seen that for bofm the curve flattens as the number of malware samples increases.
however for bigram model figure a the number of features grows proportionally with the number of malware samples under examination.
it is also noted that a similar feature space growth trend is observed in other behavior modeling techniques such as n bag and k tuple.
this illustr ates the scalability of bofm against simple malware behavior models in terms of feature space.
in addition in order to investigate whether our original hypothesis holds we analyzed how benign and malware program behavio rs differ in general.
in table we summarized the number of common features as well as the unique features corresponding to malware a nd benign datasets.
from table it can be seen that around and of the features appear to be common in benign and malware samples respectively.
having of unique malware features strongly support s our hypothesis and suggest s that behavior based malware analysis is a promising approach to detect malicious software.
next we shall briefly analyze some of the interesting malware and benign features b. a brief analysis of interesting features through our analysis we fi nd that certain actions drove malware predictions to a large extent.
to be more specific table summary of sensitivity analysis os resource type total accuracy fp rate file system .
.
section .
.
network .
.
synchronization .
.
process thread .
.
registry .
.
table summary o f feature spaces malware dataset benign dataset common features .
.
unique features .
.
total features fig.
.
feature space growth of malware samples a using bigram n model and b using bofm notifychangekey action i.e.
action that allows the running application to request notification for a registry key change is very widely used by malware samples when compared to benign samples.
that is around of malware applications performed notifychangekey action on registry resource whereas only of benign appli cations performed it.
further deletekey and delete value action s i.e.
action s that delete key s and value s from the registry respectively also played a significant role in distinguishing malware from benign applications.
this behavior is expected as registry contains the system configuration settings and malware often create or modify registry keys and values to maintain persistence on t he infected system allowing the malware to survive reboots .
for example modification to the registry key hklm software microsoft windows currentversion run allows the malware to automatically run every time when the windows is started.
in addition with regard s to file resource we find that there are several features such as createfile setfileinformation devicecontrol readfile writefile that widely appear ed in malware samples.
s imilarly several feature s corresponding to process thread resource predominantly appeared in malware samples .
for example createthread queryinformation proce ss setinformationprocess feature appeared in .
of malware samples and only of benign applications .
however several other features such as openfile queryattributesfile and createmutex release mutex seemed to be too common where they appeared in almost all the malware and benign applications .
c. comparison with canali et al.
as discussed in section ii canali et al.
in their recent study proposed several malware behavior modeling techniques for malware detection.
their experiment results revealed th at the optimal behavior model bags of tuples of action with arguments achieved a detection rate with a false positive rate of .
.
using svm to build a classifier bofm achieved .
detection accuracy with no false positives and therefore improves the already accurate results of canali et al.
.
since our benign sample is different from theirs due to privacy reasons this result should be interpreted with care but is nevertheless encouraging.
more importantly such improvement is obtained despite a dramatic size reduction in the malware feature space as discussed next.
canali et al.
on average generated more than one million malware features i.e.
signatures for each one of these models whereas bofm generated only features i.e.
active features .
as listed in section ii the feature space size or number of signatures is one of the key characteristics determining the practicality and scalability of a malware detector.
in bofm we achieve this by limiting our total number of features to be a constant number n whereas in the feature space is not constant and grows proportional ly to the size of execution traces.
to get a better insight into the feature space problem in canali et al.
let us assume an execution trac e with just unique actions with arguments for example there are unique actions with arguments in the malware execution trace shown in figure .
the simplest malware behavior model 4bags of actions with arguments generates a feature space of size .
this is very large and the number of features heavily depends on the unique actions present in every single execution trace.
this problem is even more acute for other models such as tuples of actions with arguments and bags of tuples of actions with arguments presented in .
in addition approaches in have high memory requirements and long execution times to perform signature matching whereas we were able to run standard machine learning algorithms on a standard pc in less than a minute.
to be more specific in it took almost hours to extract malware features using tuples of system calls with arguments whereas using bofm we were able to extract features in .
hours from the same set of malware samples.
note that our experiments were conducted using a single core xeon r machine with 4gb of ram in contrast to where the authors used two clusters one with eight core xeon r machines with 16gb of ram and a second one with eight core authentic amd machines with gb of ram.
further we were able to train the svm classifier using our training set in second s averaged over executions consuming only mb of physical memory average memory space .
in contrast canali et al.
reported that their prototype malware detector was unable to run on a standard machine due to the huge feature space as it cons umed 1gb of ram to perform matching on million signatures.
this suggests that bofm beyond improvements in accuracy is also much more efficient and scalable.
further our approach does not require any complex parameter tuning or preprocessing.
from all the above we can therefore conclude that bofm when combined with machine learning algorithms is indeed a more practical solution than the behavior modeling approaches reported in and other related works as discussed in section ii.
ix.
conclusion this paper proposes a novel malware detection solution that combines a new malware behavior modeling technique bofm and machine learning in order to distinguish malware f rom benign programs.
our goal is to be sufficiently efficient scalable and accurate to complement traditional anti virus software on end host machines.
our detection models cannot be easily evaded by simple obfuscation techniques as we characterize the b ehavior of malware as a set of high level actions that models the interaction between malware and the operating system resources in a systematic manner.
further the feature space generated by bofm is of fixed dimension and does not grow in proportion with the number of malware samples under examination.
this makes bofm more efficient and scalable in practice.
in addition in spite of all these practical advantages when combining bofm and support vector machines a well known machine learning approach we obtain a better detection accuracy including no false positives than reported malware detection techniques .
but more importantly given the usual difficulties in comparing accurac y across studies such results are obtained with vastly lower computation ti mes and memory usage thus demonstrating the improved scalability and efficiency of our approach.