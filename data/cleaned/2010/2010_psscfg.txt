a path sensitively sliced control flow graph joxan jaffar national university of singapore singapore joxan comp.nus.edu.sgvijayaraghavan murali national university of singapore singapore m.vijay comp.nus.edu.sg abstract we present a new graph representation of programs with specified target variables.
these programs are intended to be processed by third party applications querying target variables such as testers and verifiers.
the representation embodies two concepts.
first it is path sensitive in the sense that multiple nodes representing one program point may exist so that infeasible paths can be excluded.
second and more importantly it is sliced with respect to the target variables.
this key step is founded on a novel idea introduced in this paper called tree slicing and on the fact that slicing is more effective when there is path sensitivity.
compared to the traditional control flow graph cfg the new graph may be bigger due to path sensitivity or smaller due to slicing .
we show that it is not much bigger in practice if at all.
the main result however concerns its quality third party testers and verifiers perform substantially better on the new graph compared to the original cfg.
categories and subject descriptors d. .
testing and debugging symbolic execution general terms algorithms reliability verification keywords symbolic execution program slicing program transformation .
introduction we present a new intermediate graph representation for c programs with specified target variables.
these programs are intended to be processed by third party applications such as verifiers and testers.
the representation embodies two concepts.
first it is pathsensitive in the sense that there may be multiple nodes representing one program point so that infeasible symbolic execution paths can be excluded.
second and more importantly the graph is sliced with respect to the target variables.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
fse november hong kong china copyright acm ... .
.we begin with a promotional example consider the c program if c p else p x if p x if x z target z note that no static slicing is effective on this program because each statement and variable affects the target zalong at least one path.
however we can transform this program into an equivalent one if !c z which produces on any given input the same values for zas the original program.
clearly this transformed program would be more efficient when input to a verifier or tester which seeks properties of z. we arrived at this transformation as follows.
let s denote the program fragment comprising of all but the first if statement of the original program.
now consider slicing s in the contextp the then body of the first if statement .
clearly s would not modify the variable zbecause only the statements x andx would be executed in this context.
next consider the alternative context p the else body .
now s would execute the statements x andz from which the former can be sliced away.
hence we get the transformed program.
in other words we arrived at this new program by first considering path sensitivity and more specifically the original program s symbolic execution se tree .
the general idea is that slicing of a program fragment can be much more effective when it is done with a given context.
the se tree in fact displays the context of a program fragment as it unfolds through the various paths that bring execution to this fragment.
now consider the example if c p else p s target z where s now represents a program fragment which cannot be sliced by restricting consideration of the values of zat the end of the program.
that is all symbolic execution paths in s produce some different output value in zat the end regardless of the initial values of corp. here by being path sensitive we would produce a cfg that corresponds to the program if c p s else p s this new program is effectively twice the size of the original program due to the duplication of s and yet there is no benefit from using this enlarged representation.
it is folklore that a fully path sensitive representation of symbolic execution is simply intractable for the representation doublesin size for each branch statement encountered.
the only alternative is to have some form of merging where at some stages in the construction of the graph certain paths in the graph transition into the same node.
if the merging is performed at every opportunity the original cfg would be obtained.
if not performed at all the full possibly intractable se tree would be obtained.
the big question is therefore how much merging is needed?
in this paper we present a method for producing a path sensitive cfg by constructing a se tree but merging nodes exactly when the merge does not hide any information that affects slicing.
that is when our algorithm merges a node in the tree with another it guarantees that had the node been symbolically executed instead one would obtain precisely the same slicing information as that of the node it s being merged with.
a key step involved in the construction of our cfg which we call the path sensitively sliced cfg orpss cfg is tree slicing a powerful technique to merge and slice arbitrarily different se sub trees under certain conditions.
our main result is that the pss cfg when decompiled or transformed into regular programs that can be directly used by applications which query target variables e.g.
a concolic tester that targets the program s outputs or a verifier with a safety property produces significant improvement in terms of time usage as compared to using the original program.
the strength of the pss cfg is that it can be used out of the box by a wide number of thirdparty software engineering applications.
we consider two main applications program testing and verification and show in section how they can benefit from the pss cfg to gain in performance.
.
related work with regards to performing an offline program transformation for general use our closest related work is performing a path sensitive transformation with an aim to improve the pathinsensitive analysis used inside the f s oft tool to obtain the effects of path sensitive analysis .
the main difference is that their transformation only removes infeasible paths from the cfg without performing slicing.
as a result it is not clear how the performance of a verifier or tester could be improved because they are themselves path sensitive and would not consider the infeasible paths anyway.
hence their target application is a path insensitive analyser within f s oftthat can benefit from the removal of infeasible paths as it would spuriously consider them otherwise.
nevertheless we share with them the high level goal of performing an offline program transformation that helps an external application.
since program transformation is a specific area we also discuss related work that do not perform transformation but still provide benefits of path sensitivity for external consumption.
in this regard another related work is that discards irrelevant tests in concolic testing by tracking values read and written by executed program statements.
then when two states differing only in program valuesnot subsequently read are visited the exploration of the second state can be pruned.
the main difference is that they use live range information of variables to make the decision about pruning paths which results in lesser pruning compared to our method that uses slicing specifically dependency information .
moreover they do not perform program transformation themselves but work with the concolic tester to discard certain tests during execution.
thus they are dependent on the external application whereas we perform an offline transformation that is independent of the application.
another related work is that performs slicing of paths but their goal is to reduce the size of the counterexample path generated by cegar based verifiers during their process.
as a result they do not work with the entire program s cfg and hence they are not concerned with splits and merges in the cfg.
however a programtransformation algorithm like ours needs to work with the whole cfg to decide where to split or merge.
slicing as a precursor to model checking has also been shown to be effective in .
the recent work performs dynamic state merging during symbolic execution in order to combine paths.
while reducing the number of paths the formulas corresponding to merged states are more complicated.
they showed that their chosen heuristic for deciding which states are merged produced significant speedups.
a similarity to our paper here is that we also perform state merging but we do so by learning when different states need not be explored.
also does not consider slicing but our algorithm merges only when it can guarantee lossless ness of slicing dependency information.
state merging in the context of dynamic symbolic execution has also been studied in a more recent work .
we will see in section that our method uses interpolation to perform state merging.
interpolation has been used in program testing and verification to reduce state space and contain path explosion .
however the similarity with our paper is only in the use of interpolation for state merging.
our method has to additionally guarantee that the merging is lossless something that is inapplicable to these works.
also in section we experimentally evaluate the pss cfg using applications of testing and verification which may be another source of confusion with these works.
the fundamental difference is that these works involve directly performing the testing or verification process on the program.
we simply evaluate the pss cfg on third party testing and verification tools to show that they benefit in performance in fact is one of the verifiers we use .
but the pss cfg is a much more generic object not limited to just testing and verification.
we finally mention the work which performed static slicing.
the technical approach there was to first generate a path sensitive symbolic execution tree which then was used to determine which primitive program statements could be sliced.
it performed slicing on the program using the symbolic tree to slice a statement that does not affect the target anywhere in the tree.
in contrast here we perform slicing on the tree itself to transform it into a new tree using the transformation rules.
our method allows the same program statement to be sliced form one part of the tree but not another a scenario in which simply cannot slice the statement from the program at all.
this fundamental difference will be exposed in the example in section .
moreover a key technical slicing step of our method called tree slicing involves slicing a compound statement from a tree a problem not relevant to in general the symbolic execution subtrees rooted at what corresponds to the end of a compound statement may not be identical.
a main theoretical result of this paper concerning the correctness of the transformation theorem is that under certain conditions formalised in theorem we can correctly slice away the entire compound statement and merge the following subtrees even though they are different while still retaining the necessary equivalent behavior of the original program on the target variables.
.
basic idea consider the program in fig.
where a read call signals a concolic tester to generate an input and the target of interest is the variable zin the end.
the program has two inputs canddwhich decide the control flow and paths to traverse.
at the outset note that no static slicers even path sensitive ones like or the wellknown frama c are effective on this program because each statement along some path affects the target.
our algorithm has two steps first it performs symbolic execution to generate the se tree annotated with dependency information at each node fig.
b .
the goal here is to be as path sensitiveif read c flag elseflag x if read d y elsey if flag z y x elsez x target z c flag x d y flag z y x!d y !flag!c flag y x flag d x flag x d !d y y flag !flag z x flag x flag x true z true z false c x d y z y x!d y !c x z x 1if read c x if read d y else y z y x else x z x figure a a program b its symbolic execution tree c its psscfg and d the corresponding decompiled program as possible since it makes dependency information more precise.
however since path sensitivity also makes the se tree exponential in the number of branches we try to keep its size in check by mergingwhile ensuring this does not cause imprecision of dependencies.
in the second step transformation rules are applied on the se tree to get the final pss cfg fig.
c .
these rules take advantage of the precise dependency information obtained in the first step.
in fig.
a our algorithm first encounter a branch on c. to be path sensitive it splits symbolic execution into two one with context cand the other with context !c.
in a dfs fashion it first explores the context c symbolically executing the statements flag andx and as usual carrying these path constraints in a logic formula.
upon reaching the next branch it again splits into two with context dand!d.
continuing along the context dit executes y and reaches the final branch.
again it splits into two with context flag and!flag following the former and finally executing z y x before reaching the terminal point.
at this point the path formula is represented by the constraints c flag x d y flag z y x1which is satisfiable meaning the path is feasible.
our algorithm now generates the backwards dependency information for this feasible path resulting in the dependency set fzg the target at the terminal point.
this is then propagated back to the branch point on flag by applying weiser s formulas resulting in the set fy xg.
in addition to the dependency set our algorithm also computes the witness path for each variable in the set.
a witness path for a variable at a particular node in the se tree is a path from that node along which the variable affects the target in the end i.e.
it is a witness for the variable affecting the target.
the witness path for the set fy xgis the path executing flag andz y x corresponding to the formula flag z y x. to avoid cluttering we do not show the witness paths in fig b .
witness paths are needed to ensure there is no loss of dependency information when we merge two nodes later.
next our algorithm backtracks and explores the other context from the last split point !flag .
the path formula c flag x d y flag is unsatisfiable hence the path is infeasible.
now it computes an interpolant a formula that captures the essence of infeasibility of the path at the branch point.
the purpose of the interpolant is to exclude irrelevant information pertaining to the infeasibility so that merging of another node with the 1we omitted the read calls which only the tester understands.current one is more likely to happen in future.
for the above path one possible interpolant at the branch point is flag which is enough to capture the inconsistency with flag .
there are numerous methods to compute interpolants e.g.
weakest preconditions and the quality of the interpolant will affect the amount of merging performed by our algorithm.
the interpolant at a terminal node is true and the interpolant at an infeasible node is false as shown.
in summary our method computes at each node in the se tree a the dependency sets b witness paths from feasible paths c interpolants from infeasible paths.
at the branch point on flag these arefy xg flag z y xandflag respectively.
the astute reader might have noticed that our algorithm did not include the variable flag in the dependency set whereas a traditional slicer such as would have included it due to control dependency.
the reason is that along this particular path only one branch the one where flag is true non zero is feasible and the other is infeasible.
that is flag is always true at this point along this path.
hence the value of flag does not affect the execution of the statement z y x therefore it is not control dependent on flag .
however flag being true is needed to preserve the infeasibility of that branch and this is captured in the interpolant.
next our algorithm backtracks again to the previous split point to explore the other branch !d.
it executes the statement y and reaches the branch on flag this time under the different context !d.
now the most important step of checking whether the current context of the branch can be merged with the previously explored context is performed.
first our algorithm makes sure the merging iscorrect by checking if current path formula c flag x d y implies the interpolant flag .
this check succeeds meaning that this context can be merged soundly with the previous one2.
next it makes sure the merging will incur no loss of precision by checking if the witness path from the previous context flag z y xis feasible in the current context.
indeed it is as the current path formula is consistent with the witness formula.
therefore the current context of the branch on flag is merged with the previous context without any loss of precision.
this is formalised in theorem that says if both checks succeed then by exploring the current context of the node one would obtain exactly the same dependency information as the node it s being merged with.
the merging is denoted by the green dashed arrow in fig b .
2the concept of soundness is formalised later in lemma .our algorithm now propagates backwards the dependency sets interpolants and witness paths to the previous branch on d resulting in the setfd xg interpolant flag and witness path d y flag z y x. note that this time it considered the control dependence of yondas both paths from the d branch were feasible thus adding dto the dependency set.
it then backtracks to the first split point on cand explores the other branch !c.
upon reaching the branch on dagain it tries to merge with the previous context of the branch by checking if the current path formula c flag x 2implies the interpolant flag .
it does not so the merging cannot be performed and so it proceeds to explore the rest of the tree under the node resulting in the final se tree as shown in fig.
b .
we do not explain the process again as it is very similar to the left half of the se tree.
however there are a few important things to note in the final tree.
the branch on dis duplicated due to the split at the previous branch onc.
however under the context !c the dependency set at the branch point on flag is onlyfxgas opposed tofy xgunder the context c because here there is no data dependency of zony.
this is the advantage of path sensitivity we have obtained a more precise dependency information at a different context of the same program point by considering the contexts separately although at the price of duplication of the dbranch.
however we will see soon that because of the more precise information the duplication can be controlled by slicing.
in phase two of our algorithm we apply three transformation rules that will process the se tree annotated with dependency information to transform it into the final pss cfg.
we give an informal description of each rule here as they are formalised in section .
.
rule the traditional slicing rule states if the lhs of an assignment statement does not occur in the dependency set after it the statement can be removed.
rule states that if a branch point has only one feasible path arising from it the branch point can be removed.
the reasoning is that if a branch point has only one feasible path from it then in that particular context the branch condition can be deterministically evaluated to true or false .
thus it can simply be replaced with the then or else body.
rule called tree slicing which is more powerful in reducing the pss cfg s size states that an entire branch is irrelevant to the target and can be removed if both the then and else bodies contain no statement that is included in the slice.
this rule is more complicated than it seems at first because working with trees a problem arises when we remove a branch point conceptually there could be twosubtrees whose parent the branch point is about to be removed.
the two sub trees could be arbitrarily different because of the different contexts leading into them.
which one should be linked to the branch point s parent?
the rule guarantees that regardless of which sub tree is picked the transformation is still sound provided that our algorithm declared the sub trees to be merged.
this important non trivial result is formalised in section .
and is one of the many fundamental differences between our transformation method and static slicing methods that slice on the program not the tree.
note that in general the rules are not limited to the above three and one can indeed formulate more sophisticated rules.
for instance amorphous slicing can be applied to further elide statements from the se tree where it is more likely to be useful compared to applying on the original cfg as the se tree exposes differentsymbolic paths leading to a program point.
for our benchmarks however the above three rules were sufficient to provide benefit.
these rules are applied on the se tree until none of them can be applied any more and the resultant graph is the pss cfg.
in our example applying rule on the se tree removes the statements flag andflag .
applying rule removes the two branches on flag that have an infeasible path.
more interesting is the application of rule .
it cannot be applied on the dbranch under the context cbecause in that context y andy are included in the slice the dependency set after the branch is fy xg .
however it can indeed be applied on the dbranch under the context!cbecause neither y nory is included in the slice the dependency set after the branch in this context is only fxg and our algorithm had merged the symbolic state after its then and else body.
thus rule removes the dbranch under the context !cbut not in the context c to get the final pss cfg in fig.
c .
this reduction of the graph due to slicing complements the blow up due to path sensitivity and is critical to maintaining the pss cfg s size.
finally note that rule cannot be applied on the top level cbranch because the two subtrees after its then and else body have not been merged.
this means the split due to the cbranch is causing some differences in the two subtrees related to the target and so removing the branch could make the pss cfg incorrect.
indeed the cbranch assigns different values to flag which ultimately causes different values to be assigned to the target z. thus the branch must be kept to preserve the original program s semantics.
finally as a third step of our algorithm we produce an equivalent c program from the pss cfg by decompiling it.
the decompilation process is quite straightforward so we do not detail it here.
it is done primarily so that external off the shelf applications can be executed on the pss cfg.
the decompiled program for our example is shown in fig.
d .
at the outset one can notice that the decompiled program has only paths compared to paths in the original program.
moreover information that cannot be captured from the original program can be captured by the decompiled program.
for instance a concolic tester on the original program will always generate a value for dregardless of the value generated for c. however in the decompiled program if the value of cwas generated to be the tester would not generate the value of dbecause it will not affect the target z. it can also be seen that the variable flag which was mainly used for control flow between different parts of the code is not even present in the decompiled program.
this information cannot be captured by static slicers like which cannot statically remove the assignments to flag or the branch on flag from the program without becoming unsound.
remark.
one might wonder if our complete algorithm to produce the pss cfg is equivalent to simply expanding the paths of the original program producing a semantically equivalent program deleting the infeasible paths and applying standard slicing wrt the target.
even though conceptually it may be similar there are many practical differences with our method.
without the merging performed by our algorithm one would run into exponential blowup of paths during symbolic execution before even producing the semantically equivalent program.
even if a merging mechanism is used to contain the blowup without the guarantee of lossless merging provided by our algorithm one could obtain imprecise dependency information thereby keeping irrelevant statements in the new program.
however our algorithm provides the right balance between precision and performance of such a target based transformation.
thus the process of constructing the se tree and the process of dependency computation are closely intertwined and cannot be separated and outsourced to an external slicer.
.
background syntax .
we restrict our presentation to a simple imperative programming language where all basic operations are either assignments or assume operations and the domain of all variables are integers.
the set of all program variables is denoted by vars.
an assignment x e corresponds to assign the evaluation of the expression eto the variable x. in the assume operator assume c if the boolean expression cevaluates to true then the program continues otherwise it halts.
the set of operations is denoted by ops.
we then model a program by a transition system .
a transition system is a quadrupleh i !
oiwhere is the set of states and i is the set of initial states.
!
ops is the transition relation that relates a state to its possible successors executing operations.
this transition relation models the operations that are executed when control flows from one program location to another.
we shall use op !
0to denote a transition relation from to executing the operation op2ops.
we shall also use a similar notation op !
0to denote a transition from the symbolic state to 0corresponding to their program locations.
finally o is the set of final states.
symbolic execution .
asymbolic state is a tripleh s i. the symbol corresponds to the current program location.
we use special symbols for initial location start2i and final location end2o.
the symbolic store sis a function from program variables to terms over input symbolic variables.
the evaluation jcksof a constraint expression cin a storesis defined as jvks s v ifvis a variable jnks n ifnis an integer jeope0ks jeksopje0ks wheree e0are expressions and opis a relational or arithmetic operator .
finally is called path condition a first order formula over the symbolic inputs that accumulates constraints which the inputs must satisfy in order to follow the corresponding path.
the set of first order formulas and symbolic states are denoted by fol and symstates respectively.
given a transition system h i !
oi and a state h s i2symstates the symbolic execution of op !
0returns another symbolic state 0defined as h s jcksi ifop assume c and jcksis satisfiable h s iifop x e note that equation queries a constraint solver for satisfiability checking on the path condition.
we assume the solver is sound but not necessarily complete.
that is the solver must say a formula is unsatisfiable only if it is indeed so.
abusing notation given a symbolic state h s iwe define j k symstates!fol as the formula v v2varsjvks where vars is the set of program variables.
asymbolic path nis a sequence of symbolic states such that8i i nthe state iis asuccessor of i .
a symbolic state h iis a successor of another h iif there exists a transition relation op !
.
a path n isfeasible if n h s isuch that j ksis satisfiable.
if 2o and nis feasible then nis called terminal state.
otherwise if j ksis unsatisfiable the path is called infeasible and nis called aninfeasible state.
if there exists a feasible path n then we say k k n isreachable from 0ink steps .
we also define a partial function mergepoint symstates!
symstates symstates that given a symbolic state h iif there is an assume statement at i.e.
corresponds to a branch point returns a tuple h h i h iisuch 1and 2are reachable from and 0is the nearest post dominator of .
in other words 1and 2are the symbolic states at the merge point reached through the then and else body respectively.
asymbolic execution tree contains all the execution paths explored during the symbolic execution of a transition system by triggering equation .
the nodes represent symbolic states and the arcs represent transitions between states.
dependency computation via abstract interpretation .
the backward dependency computation process starts from endwith a set of target variables v vars for which the program transformation is being performed.
to compute the dependencies we follow the dataflow approach described by weiser reformulated as an abstract domaind f?g p vars wherep vars is the powerset of program variables with a lattice structure hv ?
t u i such thatv t andu are conveniently lifted to consider the element?.
we say 2d is the approximate set of variables at the symbolic state that may affect variables in v.backward data dependencies can then be formulated as follows.
given a transition relation op !
0we define def op and use op as the sets of variables written to and read during the execution of op respectively.
then 0ndef op use op if def op otherwise where vif h end i. in the first case of eqn.
we say that op !
0is included in the slice .
backward control dependencies can also affect variables in v. a transition relation op !
0where op assume c is included in the slice if any transition relation from to its nearest post dominator is included in the slice3.
then use op finally a function dpre op that returns the pre state after executing backwards the operation opwith the post state 0is defined using eqs.
.
tree transformation rules .
the se tree produced by our algorithm together with the dependency information of each symbolic state is represented using the set soffacts of the following types edge op !
denoting a feasible edge from to inf edge op !
denoting an infeasible edge from to merged denoting that has been merged with will be formalised later in slice op !
denoting that the transition from to is included in the slice due to eqs.
.
note that we do not explicitly store the dependency information at each state but rather just the fact whether a transition from the state is included in the slice or not denoted by the in slice fact .
in section .
the transformation of the se tree into the final psscfg will be modelled using certain rules that act upon these facts.
3we assume a function infl that returns the set of transitions from to its nearest post dominator the set of transitions influenced by .
.
algorithm we describe our algorithm in two phases in phase one section .
we explore symbolic paths in the program to generate the symbolic execution se tree annotated with dependencies.
in phase two section .
we transform this tree by removing edges and sub trees to finally produce the pss cfg.
at a high level our algorithm performs forward symbolic execution in a depth first manner interleaved with backward dependency computation.
symbolic execution avoids the exploration of infeasible paths thus increasing the precision of the computed dependencies.
however it allows multiple copies of the same program point to exist as different symbolic states along different symbolic paths.
thus an important challenge to overcome is to avoid this inherent exponential blowup of symbolic execution.
our solution is to merge different symbolic states provided certain conditions are met.
these merging conditions guarantee that the merge does not incur any loss of slicing information.
to formalise these conditions we define two key concepts definition i nterpolant .given a pair of first order logic formulas aandbsuch thata bisfalse aninterpolant is another formula such that a aj b bis false and c is formed using common variables of aandb.
interpolation has been prominently used to reduce state space blowup in program verification and testing .
here we use it for a similar purpose to merge states and thereby avoid redundant exploration.
however in addition to merging states we must also guarantee lossless merging .
thus we define definition w itness paths f ormulas .given a symbolic state h iannotated with the set of dependency variables awitness path for a variable v2 is a feasible symbolic path endsuch that end h end iand there exists v 12v such that v 1is control or data dependent on v along the path .
we call j endkthewitness formula of v denoted !v.
intuitively a witness path for a dependency variable at a symbolic state is a path arising from it along which the dependency variable affects the target variables at the end.
the witness formula is the path condition of its witness path.
to accommodate witness formulas in our abstract domain dwe redefine it as follows d f?g p vars fol i.e.
set of pairs of the formhx !xiwherexis a variable and !xis its witness formula.
the abstract operations tandvstill stand for and but the pre operator dpreis slightly modified to propagate back witness formulas the dependency variable xis still computed using eqs.
as before while the pre state witness formula for xis the computed as the conjunction of the post state witness formula for xwith the logical constraint from the transition operation op.
we now formalise our merging conditions definition m erging conditions .given a current symbolic state h s iand an already annotated symbolic state h s0 0isuch that 0is the interpolant generated for and 0are the dependencies at we say ismerged with 0if the following conditions hold a j kj b 8hx i2 9hx !xi2 0s t j k !xis satisfiable note importantly that both and 0must correspond to the same program point in order to be merged.
the condition a affectssoundness and it ensures that the set of feasible symbolic paths reachable from is a subset of those from .
this is a necessary condition for two states to be merged.
lemma .given states h s iand h s0 0i let 0be the interpolant for .
if j kj the set of feasible paths from is a subset of those from .
proof .
by contradiction .
assume there exists a feasible path with path condition from but is infeasible from .
if is infeasible from 0then j 0k is unsatisfiable and by definition of interpolant is unsatisfiable.
since j kj it follows that j k is unsatisfiable.
however since is feasible from j k cannot be unsatisfiable.
the intuition is that the interpolant 0represents the reason of infeasibility of all infeasible paths arising from .
if j kj any infeasible path under 0is also infeasible under .
in other words any feasible path under is also feasible under .
the condition b is the witness check which essentially states that for each variable xin the dependency set at there must be at least one witness path with formula !xthat is feasible from .
this affects accuracy and ensures that the merging of two states does not incur any loss of precision.
this is formalised as follows.
theorem .given states h s iand h s0 0i let 0be the dependencies and witness formulas associated with .
if can be merged with 0then by exploring there cannot be produced a set of dependencies such that .
proof .assume that although can be merged with i.e.
both conditions of eqn.
are satisfied it is instead symbolically explored and a dependency set is obtained.
proof that since can be merged with by condition b of eqn.
8hx i2 there is a witness path say x with formula !xsuch that j k !xis satisfiable.
that is xis feasible from .
by the definition of a witness path definition 9v12v s.tv1is control or data dependent on xalong the path x which is feasible from .
thereforexmust be in .
proof that by contradiction assume 9x2 s.t x .
then the witness path for x xwith formula !xmust be such that j k !xis satisfiable but j 0k !xis unsatisfiable otherwise from the definition of a witness path xwould have been included in .
that is xis feasible from but infeasible from .
from eqn.
condition a and lemma this is impossible.
.
generating the se tree structure with dependencies the purpose of our main algorithm g enpsscfg is to generate a finite symbolic execution tree annotated with dependency information at each symbolic state.
as mentioned in section the tree is represented using a set of facts that are added to the sets which is assumed to be a global variable to the algorithm.
g enpsscfg requires the program to have been translated to a transition system h i !
oiin ssa form and accepts a symbolic state as argument.
it is initiated with the state h start truei.
genpsscfg implements a mutually recursive algorithm with a few other procedures.
first the most important decision of whether to merge a symbolic state with another is taken by g enpsscfg at line .
it attempts to find another symbolic state 0such that and 0satisfy the two merging conditions in equation .
if yes it merges with 0by calling the procedure m erge at line .
if such a 0does not exist g enpsscfg decides whether to split the symbolic execution of or not by checking if corresponds to a branchinggenpsscfg h s i if9 h s0 0is.t.
and 0satisfy eqn.
then merge else if is at a branch point then s plit else s ymexec merge s s merged split h s i true foreach transition assume c !
0do if is a loop header then h invariant jcksi else h s jcksi if 0is infeasible state then s s inf edge assume c !
false else s s edge assume c !
g enpsscfg dwlp assume c tdpre assume c s if assume c !
0satisfies eqn.
then s s in slice assume c !
symexec h s i if transition relation x e !
0then true v else h s i s s edge x e !
if 0is not a loop header g enpsscfg dwlp x e dpre x e if x e !
0satisfies eqn.
then s s in slice x e !
figure symbolic execution interleaved with dependency computation to produce the se tree point in the program line .
if yes it calls the procedure s plit at line which as we will see forks the symbolic execution of different branches from .
if both the above cases do not match genpsscfg simply continues the symbolic execution by calling the procedure s ymexec with .
g enpsscfg is in essence the high level backbone of our method.
the procedure m erge given a current symbolic state and an already explored state merges the former with the latter by setting the interpolant and dependency set of to those of .
recall that theorem guaranteed such a merge to have no loss of precision.
that is had been explored instead of being merged with the resulting dependency set at would be exactly .
finally the procedure adds the fact merged tosto record the merge between the two states.
the procedure s plit is used to fork the symbolic execution of a state from which multiple transitions are possible typically a branch point .
given a symbolic state with program point and path condition it first initialises its interpolant to true at line .
at line it iterates its main body over each transition possible from .
now there is an issue if the current state is a loop header line then symbolically executing the loop could result in an unbounded tree which we want to avoid.
therefore we need to execute the loop with a loop invariant to make the tree finite.
our method to compute a loop invariant is simple but effective from the loop header s symbolic state we only keep the constraints that are unchanged through the loop and delete the rest.
for instance if x 5holds at the loop header and xis only incremented in the loop then x 5is unchanged through the loop.
this widened state at ultimately forms a loop invariant.
this technique provides a balance between getting the strongest invariant whichis needed to maximise path sensitivity and efficiency.
we found experimentally that this technique preserves most of the important information through the loop.
nevertheless we remind the reader that no matter what the invariant is it does not affect the guarantee of lossless ness of dependency information during our merging and the correctness of our transformation as stated by theorem .
we assume a function invariant that given a symbolic state returns a fol formula representing the loop invariant.
with this invariant the next state is constructed by augmenting it with jcks where cis the branching condition of the assume statement line .
if not 0is constructed line by augmenting the path condition with jcks.
at line an important check is performed if 0is an infeasible state i.e.
the augmented path condition is unsatisfiable it means symbolic execution has encountered an infeasible path.
therefore it adds to sthe fact that the transition from to 0is infeasible line and sets the interpolant and dependency set of 0to false and respectively line to signify that the state is unreachable.
otherwise it adds a normal edge to sat line and mutually recursively calls g enpsscfg with .
in either case 0would have been annotated with an interpolant 0and dependency set .
now it computes the same information for at lines .
the interpolant is supposed to generalise the se tree below while preserving its infeasible paths.
for this the procedure dwlp fol ops!fol is called that ideally computes the weakest liberal precondition the weakest formula on the initial state ensuring the execution of assume c results in the state .
in practice we approximate wlpby making a linear number of calls to a theorem prover following techniques described in usually resulting in a formula stronger than the weakest liberal precondition.
the dependency set is computedrule s traight line slicing e1 edge 0op !
2se2 edge 1x e !
2s in slice 1x e !
2s s snfe1 e2g f edge 0op !
g rule i nfeasible path removal e1 edge 0op !
2se2 edge 1assume c !
2se3 inf edge 1assume c !
2s s snfe1 e2 e3g f edge 0op !
g rule t ree slicing edge 0op !
2s edge 1assume c !
2s edge 1assume c !
2s in slice 1assume c !
2s in slice 1assume c !
2s h k ki mergepoint merged k k 2s s snf edge 0op !
j 0op !
002infl 1assume c1 !
0op !
002infl 1assume c2 !
g f edge 0op !
k g figure transformation rules to produce the final pss cfg by applying the pre operation dpreon 0and joining with any existing set across different iterations of the main loop .
finally in lines of s plit it checks if any transition from to its nearest postdominator is included in the slice eqn.
.
if yes it adds an in slice fact toswith the transition from to .
the final procedure s ymexec is called by g enpsscfg when the current symbolic state corresponding to program point cannot split typically an assignment statement .
initially at line it checks if there exists a program transition from to any other .
if not symbolic execution has reached the end of a feasible path whose final state is .
in other words it has reached a terminal node.
hence it sets the interpolant to true and its dependency set tov recall that the target variables are specified at end at line .
if there exists a transition from to say 0with the assignment x e it constructs the next symbolic state line 0by setting in the storesthe value of xtojeksand adds tosthe appropriate edge fact line .
then if 0is not a loop header it recursively calls g enpsscfg with line .
if 0is a loop header then there is no need to explore it again since it would have already been explored with the loop invariant at s plit line .
our algorithm thus makes the symbolic execution finite.
in s ymexec line and it sets the interpolant and dependency set of by callingdwlp anddpre on the interpolant and dependency set of .
finally at lines if xcontains a variable in eqn.
it adds tosthe fact that the transition from to 0is included in the slice.
to perform the fixpoint computation at the highest level we keep making calls to g enpsscfg until there is no change in s. this is the simplest way to describe the fixpoint computation but in practice we can optimise it by calling g enpsscfg with the symbolic state of the loop header in which the change was detected.
.
transformation of the annotated se tree the algorithm described so far produces a symbolic execution tree represented as a set of facts s. now we present certain rules in fig.
that act upon sto modify it in essence modelling the transformation of the se tree into the final pss cfg.
the rules are presented in a declarative fashion and can be implemented conveniently in a rule based programming language e.g.
constraint handling rules .
straight line slicing states that if there is a transition or edge from state 0to 1and an assignment transition from to 2such that the latter is not included in the slice then both tran sitions can be removed and replaced with one linking 0directly to .
this is the typical rule for slicing assignment statements using dependencies.
infeasible path removal states that if there is a transition from state 0to and 1is abranch point such that there is branching edge edge from 1to 2and an infeasible branching edge inf edge from 1to another then all three edges can be removed and 0can be directly linked to the feasible state .
tree slicing is more complicated and the most powerful in terms of reducing the symbolic state space of the pss cfg.
it states that if there is a transition from 0to and 1is a branching point with branching transitions to with condition assume c and with condition assume c such that neither transition is included in the slice then we can remove all transitions 0op !
that occur either in the dynamic range of influence given by infl of !
2or !
.
in other words we can remove all transitions that occur in the then or else body of the branch at .
but there is a problem since we are working on a symbolic tree removing the branch point 1would conceptually leave two different subtrees hanging without a parent.
the question arises as to which subtree should we link to the node .
t ree slic ingguarantees that if the symbolic states at the end of the branch h k ki as returned by mergepoint are merged by our algorithm i.e.
merged k k exists the differences in the trees do not affect the target variables.
hence it simply adds a transition directly linking 0to one of the symbolic states k. we explain the reasoning behind the above rules by defining our correctness statement for the transformation of the se tree into the pss cfg and providing a proof outline for it.
first let two cfgs be defined equivalent wrt target variables vif for any input the programs corresponding to both cfgs produce the same values for all variables inv.
theorem .
correctness of transformation an application ofrule rule 2orrule 3to a cfggproduces a transformed cfgg0such thatg0is equivalent to gwrt target variables v. proof outline .
the correctness of s traight line slicing follows directly from the correctness of slicing assignment statements using dependency information formalised in eqn.
.
as for infeasible path removal for any input that executes a path ingleading to the state the condition c1will evaluate to truebenchmark lines of code blow pss rule triggers orig st.slice pss up time rul1 rul2 rul3 cdaudio .
24s diskperf .
18s floppy .
7s floppy2 .
16s kbfiltr .
1s kbfiltr2 .
1s tcas .
2s 47testing time speed solver calls st.slice pss up st.slice pss 1m30s 43s .
16k 7k 900m 34m .
26mil 1mil 9m6s 24s .
260k 4k 525m 429m .
613k 479k 2s 1s 22s 6s .
7k 2k 4s 1s .5k 23h56m 7h44m .
.9mil .5mil a b table a statistics about the pss cfg b experiments on the pss cfg for concolic testing andc2will evaluate to false.
moreover an assume statement does not modify any variable in the program state.
thus both checks assume c andassume c are useless because we deterministically know their outcomes and hence can be replaced with a transition linking 0to the next feasible state 2to produceg0.
the correctness proof of t ree slicing is as follows.
assume that some input executes a path in gstarting from startto 0and then reaches .
w.l.o.g assume that the condition c1holds at therefore it chooses to follow reaches the merged point kand continues to eventually reach the terminal state end.
let us call this executed path g. ing0 obtained by applying t ree slicing on g thereby removing the entire branch at the same input would follow a path say g0 such that g0is the exact same path as g starting from starttill thus having the same symbolic state at .
at this point g0differs from gby implicitly skipping the execution of the branch at 1and instead directly reaches k. since kand kwere merged the dependency sets at both points are the same.
now since the transition 1assume c1 !
2ingwas not included in the slice it means that no statement skipped by g0affected the dependency information at k. this implies that the symbolic state of the path g0at kis the same as the symbolic state of the path gat kas far as the dependency variables at kare concerned .
to be precise the values of the dependency variables at kare the same in both gand g0.
since these are the only variables affecting the target variables vat end it is sufficient to preserve their values to ensure that g0will produce the same values forvas g. of course g0may produce different values than gfor variables notinv but we are not interested in those variables.
the three rules are applied until fixpoint is reached i.e.
none of them can be applied anymore .
termination of rule applications is guaranteed from the initial finiteness of the set sand the fact that all three rules remove more edges from sthan they add.
soundness of individual rule applications is guaranteed from theorem .
transitiveness of the rules is also guaranteed by theorem since each new cfg is equivalent to the previous cfg.
once fixpoint is reached the final pss cfg structure can be extracted from s. thus theorem guarantees that the pss cfg is equivalent to the original program wrt the target variables v. therefore any analysis of the original program concerned only with vcan be applied on the pss cfg instead to take advantage of its benefits.
we will see two such applications program testing and verification.
.
experimental ev aluation we evaluate the pss cfg using applications of program testing and verification to show considerable increase in their performance.we implemented the algorithm on the tracer framework for symbolic execution.
our proof of concept implementation models the heap as an array.
a flow insensitive pointer analysis provided by crystal is used to partition updates and reads into alias classes where each class is modelled by a different array.
given the statement p q the set defcontains everything that might be pointed to by pand the set useincludes everything that might be pointed to by q. this coarse modelling of heaps does introduce imprecision in the analysis but it is orthogonal to our main contribution.
functions are inlined during symbolic execution and external functions are modelled as having no side effects and returning an unknown value.
we used device drivers from the ntdrivers simplified category of sv comp and a traffic collision avoidance program called tcas as benchmarks and chose the target variables from the safety properties of the programs.
all programs had multiple target safety properties on several variables all of which were included in our slicing criteria.
for practically applying external tools on the pss cfg structure we used its equivalent decompiled program.
since both the original and decompiled programs are in c we can easily measure how external tools benefit from our transformation.
for all our experiments we compare the pss cfg4with a static slice of the benchmark program on the target variables.
comparing with a static slice is more challenging as some statements would have already been sliced away from the original program.
we obtained the static slice through the well known state of the art slicer frama c .
frama c is a path sensitive static slicer that can detect infeasible paths through techniques such as constant propagation constant folding and abstract interpretation.
also before the target variables are provided and our algorithm is initiated we process the program and store an intermediate representation ir .
this processing involves computing information about infeasible paths in the program and is completely independent of the target variables.
then when the target variables are provided our algorithm is invoked and it uses information from this ir.
all experiments were run on an intel .
ghz system with 2gb memory.
now we provide statistics about the pss cfg and its construction in table a .
the lines of code column shows the number of non commented lines of code in the original orig program its static slice st.slice and its decompiled program pss respectively.
in the column blowup we show the ratio of the loc of pss cfg compared to the static slice.
the blowup is a result of the balance between the splits introduced by path sensitivity and the merges and slicing from our algorithm.
it is clear that the blowup is manageable sometimes even smaller than the program being on average around .
in the column pss time we show the time 4we use decompiled program and pss cfg interchangeably.impact armc cpa checker benchmark cdaudio diskperf floppy floppy2 kbfiltr kbfiltr2 tcas totalverification time speed st.slice pss up 95s 14s .
146s 18s .
34s 8s .
39s 13s .
4s 1s .
8s 2s .
3s 1s .
329s 57s .8verification time speed st.slice pss up t o 21s n a t o 6s n a 259s 6s .
t o 17s n a 3s 1s .
13s 2s .
3s 1s .
t o 54s n averification time speed st.slice pss up 26s 14s .
7s 6s .
6s 5s .
10s 8s .
3s 2s .
4s 2s .
2s 1s .
58s 38s .
a b c table experiments on the quality of pss cfg for verification times of different verifiers taken in seconds for our algorithm to produce the pss cfg given the target variables which is modest.
in the final column rule triggers we show the number of times each transformation rule was triggered during pss cfg construction.
although r ule is shown to be triggered fewer number of times than r ule or rule it is the most powerful rule in reducing the search space of the pss cfg.
in tcas we see r ule triggering more frequently than r ule1 due to its large number of infeasible paths.
note that the pss cfg construction is only performed once for a given set of target variables.
the resulting program can however be subjected to an innumerable number of properties to be verified or tested.
for example using the same pss cfg one can verify different bounds on a target variable depending on different preconditions to the program.
.
testing white box we consider software testing an important application for the pss cfg to be used.
for this we consider the typical dart methodology that performs concolic testing i.e.
executing the program with both concrete and symbolic inputs and symbolically negating branches to explore new paths.
we chose the publicly available concolic tester crest an implementation of dart for c programs.
since the statically sliced and decompiled programs are in c the experiment was simply to run the concolic testing process on both programs and measure the time taken to complete i.e.
time taken to test all feasible paths in the program.
in table b we show the measures of the experiment.
the second and third columns st.slice andpss show the time taken to complete the concolic testing process on the statically sliced and decompiled programs respectively.
the third column shows the speedup obtained by using the pss cfg i.e.
the ratio of the columns st.slice andpss .
it is immediately apparent that the psscfg provides speedup in all benchmarks.
in programs diskperf andfloppy the speedup is exceptionally high around reducing the concolic testing time from for instance minutes hours to just minutes.
on the other hand in floppy2 the speedup of .
is not that high but still the absolute benefit in time can be seen around minutes or .
hours.
ultimately the total time taken for concolic testing to run on all our statically sliced programs was almost hours whereas it took less than hours to run on the decompiled programs providing a net benefit in time of a magnitude of .
.
although it is understood that in practice concolic testing may not terminate by exploring all paths we gave a huge timeout hours for the process to terminate simply to see how much benefit the pss cfg can provide in timing.
from the table it is clear that the pss cfg can make the difference between termination and timing out of the concolic testing process.in addition to time we also measured the number of calls made bycrest to its underlying solver.
this measure shown in the column solver calls gives an idea of how the pss cfg would still benefit the concolic tester even if a different faster solver was used.
again we see several magnitudes of less solver calls for all benchmarks when crest was run on the pss cfg.
the maximum benefit is in diskperf where million calls were made for the statically sliced program compared to only million for the decompiled program.
this is in line with the speedup in time for diskperf around .
this indicates that even if a faster solver is used the relative speedup in time for this benchmark would still be around although the absolute timings may be faster.
ultimately this table shows that concolic testing would definitely benefit by using the pss cfg instead of the statically sliced program.
.
verification another important application for the pss cfg is program verification.
in table we compare the verification times of the benchmarks across three different state of the art verifiers impact armc and cpa checker .
we chose this set of verifiers because they come from different approaches to verification interpolant based cegar based and smt based.
since impact is not publicly available we use cpa checker s implementation of theimpact algorithm.
in each table the second and third columns show the verification time in seconds of the statically sliced program st.slice and the pss cfg pss respectively.
in the third column speedup we show the ratio of st.slice topss .
for all three verifiers it can be clearly seen that the pss cfg is verified in a much faster time than the static slice.
for impact verifying all statically sliced programs in our suite took seconds whereas verifying the respective pss cfgs took only seconds.
thus the speedup across all programs on aggregate is .
.
as for armc it was unable to terminate its verification of the statically sliced programs for cdaudio diskperf andfloppy2 with a timeout of minutes whereas it was able to verify each of their respective pss cfgs in less than seconds thus providing a huge benefit to armc .
for cpa checker the benefit was relatively smaller providing on average a speedup of .
.
the reason is because cpa checker is a more sophisticated verifier than the other two but still the fact that the pss cfg provides a speedup for cpachecker is to be considered noteworthy.
thus we believe that the pss cfg is quite a useful object in general for verification.
.
acknowledgement we would like to thank jorge navas for his contributions to this work while at nus.
.