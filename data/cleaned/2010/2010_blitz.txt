blitz compositional bounded model checking for real world programs chia yuan choyxvijay d silvaxdawn songx xuniversity of california berkeley usa ydso national laboratories singapore fchiayuan vijayd dawnsong g cs.berkeley.edu abstract bounded model checking bmc for software is a precise bug finding technique that builds upon the efficiency of modern sat and smt solvers.
bmc currently does not scale to large programs because the size of the generated formulae exceeds the capacity of existing solvers.
we present a new compositional and property sensitive algorithm that enables bmc to automatically find bugs in large programs.
a novel feature of our technique is to decompose the behaviour of a program into a sequence of bmc instances and use a combination of satisfying assignments and unsatisfiability proofs to propagate information across instances.
a second novelty is to use the control and data flow of the program as well as information from proofs to prune the set of variables and procedures considered and hence generate smaller instances.
our tool b litz outperforms existing tools and scales to programs with over lines of code.
b litz automatically and efficiently discovers bugs in widely deployed software including new vulnerabilities in internet infrastructure software.
i. i ntroduction software bounded model checking bmc is a powerful technique for finding bugs in bounded program executions.
the technique constructs a formula called a bmc instance that encodes the behaviour of a program up to a user specified bound.
bmc instances can capture bit level operations and the memory model and so generate precise information about bugs.
however existing bmc tools exhaust memory or time on programs containing a few thousand lines of code .
in this paper we ask is it possible solve a large instance by only solving instances that fit in memory .
specifically we seek to design a compositional bmc algorithm.
an analysis technique is compositional if it can decompose a large problem into smaller problems and solve only a small problem at a time.
for example hoare logic is compositional because it allows for proving a statement about a program by proving statements about its parts.
several static analysis techniques are compositional because they propagate information through a program one block at a time.
decomposing bmc instances is challenging because dependencies between constraints are lost if the formula is decomposed.
imagine a procedure bar which calls a procedure foo int x with argument .
if the assertion is never violated no formula that includes the behaviour of both foo andbar will be satisfiable.
if we decompose the problem and reason about bar andfoo int x separately the assertion may be violated because there is no constraint on the input variable x. more generally decomposing a bmc instancemay render an unsatisfiable formula satisfiable because the context in which the code executes is not taken into account.
we do not wish to report that an assertion may be violated because we lose the appealing property that bmc reports precise information about bugs.
compositional bounded model checking we use two ideas to address the problems sketched above.
first we consider preconditions for violation which are conditions under which a program is guaranteed to violate an assertion.
computing such preconditions precisely would involve the expensive step of quantifier elimination while overapproximating preconditions leads to spurious bug reports.
we compute the underapproximate preconditions for a violation and weaken them iteratively.
we use information from proofs generated by satsolvers to expand the set of error states that must lead to a violation.
as a result we can decompose a bmc instance consider multiple inputs to a piece of code and preserve the accuracy of bmc with respect to bugs.
our second idea is to incrementally generate bmc instances using information from proofs generated by sat solvers.
solvers reason about semantic relationships between variables when they construct proofs so proofs provide relevance heuristics for tuning program analyses.
by constructing bmc instances relevant to variables and operations appearing in a proof we dramatically reduce the number of instances that must be considered.
our approach is closely related to the use of craig interpolants in verification and the formulae we construct also satisfy the interpolation criteria.
consequently our technique is not only compositional but like interpolation techniques is property driven.
our tool b litz implements a compositional bmc technique that combines underapproximate preconditions with incremental construction of bmc instances.
both steps are guided by unsatisfiability proofs generated by satsolvers.
we have evaluated b litz on vulnerability benchmarks containing unmodified real world programs and found that b litz faces no capacity problems and can find bugs in programs of approximately 100kloc.
in addition we applied b litz to check critical internet infrastructure software from the internet systems consortium and found multiple new vulnerabilities.
content and contributions we present an algorithm and tool for compositional bmc that boosts the capacity of bmc and can discover bugs in real world programs with about 100kloc.
we make the following contributions.
we present a new bmc algorithm that achieves compositionality by computing underapproximate preconditions and improves scalability by proof guided incremental instance construction.
we demonstrate that the technique extends the state of the art of bmc by applying our tool b litz to real world benchmarks containing up to about 100kloc.
we deploy b litz on critical internet infrastructure software and find multiple new vulnerabilities.
the paper is organised as follows we revisit the terminology ofbmc in section iii where we also recall notions from program analysis.
our compositional bmc algorithm is presented in section iv and evaluated in section v. we discuss related work in section vi and conclude in section vii.
ii.
t echnique overview we present a run of b litz on a simple program.
the example is intentionally simple to facilitate presentation.
goal.
the program in figure begins execution in main and contains calls to four procedures foo baz bar andqux.
the procedures baz andqux have no side effects and are not shown.
the goal is to determine if the assertion at line 18of baris violated.
the standard bmc procedure will take as input a parameter kand construct an instance mkin which loops and recursive procedures are unwound ktimes and procedure calls are inlined.
this approach leads to large formulae.
formula construction the first novelty of b litz is that we only generate formulae for small code fragments rather than the entire program.
b litz begins by generating a formula for the behaviour of baras shown in figure .
observe that the variables have been labelled with subscripts so that a variable has different indices as its value changes in the lifetime of the program.
technically the formula corresponds to single static assignment ssa form.
the values of bandc being inputs are unknown and denoted as is the value of f because the body of qux is not considered.
underapproximate preconditions the formula for bar is satisfiable so a sat solver can generate a satisfying assignment.
this satisfying assignment may not correspond to a feasible execution because the calling context for bar does not appear in the formula.
the second novelty of b litz is to use a satisfying assignment to first generate an unsatisfiable formula and then use a proof of unsatisfiability to obtain aprecondition for assertion violation .
in this case b litz generates the precondition b1 b where b denotes the ascii value of the character b. this means that the assertion is violated if the value of the variable b1is strictly less than the ascii value of the character b. there are two differences between the precondition computed by b litz and that of standard techniques.
it is common to compute weakest preconditions with respect to a correctness property.
instead we compute preconditions with respect to an assertion violation.
the second difference is that we do not necessarily compute weakest preconditions.
the dijkstraweakest precondition with respect to the assertion violation condition d d is the formula c1 c1 d c16 b1 d which simplifies to c1 c1 d c16 b1 b the precondition generated by b litz is an underapproximation of the weakest precondition.
the practical benefit of our formula is that it is smaller and contains fewer boolean operations hence is easier for a solver to manipulate.
this simplicity translates to significant performance benefits for larger formulae.
the trade off of this performance benefit is that b litz may miss bugs produce false negatives because it uses underapproximation.
false negatives are mitigated by using a refinement strategy that weakens preconditions.
incremental instance construction next b litz has to determine if bar can be called in a context satisfying b1 b .
standard bmc and recent techniques like c orral and a lter consider the callers and callees surrounding a procedure to generate such constraints.
this approach would result in qux andbaz being added to the instance.
blitz uses data flow information in the program and only considers contexts that affect the underapproximate precondition.
in the example we can skip qux andbaz and consider the call to foo at line .
solving an instance with the body offoo generates the precondition a0 a which is a sufficient precondition for the assertion violation.
solving this formula provides an input value to trigger the assertion violation.
we have found that incrementally generating bmc instances by combining data flow with underapproximate preconditions significantly reduces the number and size of instances we consider.
fine grained decomposition in the example above we have argued at the level of procedures.
sometimes a procedure or its unwinding is too large to fit in memory.
b litz supports decomposing bmc instances at different levels of granularity up to single statements.
at the finest level we start with a single statement directly preceding an assertion violation and incrementally compute necessary preconditions for single statements.
we only work at this level of granularity when required or when configured by the user.
to complete the overview figure b illustrates the formula constructed if we inline bar inmain .
suppose b litz is run with a statement level granularity it will generate an underapproximate precondition for individual statements.
since data flow is taken into account statements not affecting the approximate preconditions are ignored.
iii.
t erminology and preliminaries we introduce background and notation about bmc and program analysis.
the details of bmc included here are required later for correctness proofs and to clarify the differences between our technique and existing ones.
void main unsigned char a void bar unsigned char b c f f char b foo a char d b char c baz b some function char e c bar b c char f qux d e some function g if e char foo unsigned char a d c f assert d d return a g g fig.
an example program.
b1 c1 d1 b1 e1 c1 f1 d2 e1 ?c1 d1 d2 d a b1 a0 a0 a c1 baz b1 d1 b1 b1 b e1 c1 d1 d f1 qux d1 e1 d2 e1 ?c1 d1 d1 d e1 c1 d d2 d d2 d b fig.
formulae generated by b litz a the bmc formula generated for bar.
b the left column shows the formula generated for the program and the right column shows the preconditions computed if b litz is run at the granularity of statements.
statements that are bypassed are indicated by .
a. syntax and semantics of programs for simplicity of presentation the formalisation here focuses on a small subset of c. our technique and tool both apply to full ansi c and are not subject to these restrictions.
syntax letvar be a set of variables.
we use the symbol to denote a non deterministic value.
let exp be a set containing expressions in c and the symbol.
similarly bexp is a set containing boolean expressions in c and the symbol.
a statement is an assignment assumption assertion sequential composition of statements or a procedure call.
the set of statements stmt is defined inductively below.
st x tjassume b jassert b jcall p jst stjif b st else stjwhile b st semantics the semantics of programs is given by states and state transitions.
a program state consists of the values of the program counter global variables and contents of the stack and the heap.
let state be the set of states.
the semantics of a program is given by a relation.
a statement stdefines a transition relation tst state state that contains a pair r s if executing stin the staterresults in the states.
an assignment changes the value of a variable in a state and leaves all other states unchanged.
the semantics of assume bexp is a relation that contains s s ifssatisfies bexp .
the semantics of assert bexp is similar except that ifsdoes not satisfy bexp there is a transition s e to an error statee.
the semantics of sequential composition p q is the relational composition tp tq.
we writetpto be the transition relation of a program p. error reachability program properties such as assertion violations can be formulated as reachability of states in atransition system.
a state sisreachable in a program if there is an execution whose last state is s. the error reachability problem is to determine if an error state is reachable.
an error reachability technique is sound if whenever the technique reports an error the error is reachable.
an error reachability technique is complete if whenever the technique reports that the error is not reachable the error is indeed not reachable.
our definitions of soundness and completeness are given with respect to reachability and differ from the notions used in the correctness literature.
b. bounded model checking bounded model checking bmc is a technique for finding bugs in bounded program executions.
it operates by unwinding a program translating the unwinding into a logical formula and solving the formula.
unwinding this material is based on .
a kunwinding of a program pfor a non negative kis a program unwind p k defined inductively below.
unwind x t k x t unwind assume b k assume b unwind if b p else q k if b unwind p k else unwind q k unwind while b p if b assume false unwind while b p k if b p unwind while b p k the definition of the unwinding for other c constructs is similar.
recursive procedures are handled by inlining.
an input variable in a bmc unwinding is one that is neverassigned.
input variables are the source of non determinism in an unwound program.
translation to logic statements in an unwinding are translated to formulae.
an assignment x x where is assignment cannot be written as a formula x x where represents mathematical equality because xmust have the same value on both sides of the equality in the formula.
the statement x x is rewritten to x1 x0 to make explicit that xmay have different values before and after the assignment.
this statement is then translated to a formula x1 x0 .
more generally a program is in single static assignment ssa form if every variable is assigned exactly once in the program.
unwindings are translated to ssa form.
ak unwinding of pinssa form is translated into two logical formulaeb p ande p .
the behavioural constraint b p encodes program executions.
the error constrainte p encodes error conditions such as out of bounds array accesses double frees and assertion violations.
if bimplies e no execution of a k unwinding leads to an error.
conversely a k unwinding contains an error if b e is satisfiable.
the satisfiability condition can be checked using a sat solver.
the behaviour formula b st and error condition e st for a statement stas defined in are recalled below.
we write form t for the logical expression corresponding to a c expression t. stb st e st x t x form t true assume b form b true assert b true form b p qb p b q e p e q all statements except assertions modify the behaviour constraint.
the property is only modified by assertions.
a bmc instance is satisfiable ifb e is satisfiable.
a bmc instance is generated by traversing the control flow graph cfg of unwind p k in topological order starting from the initial vertex init.
ifxis an input variable of unwind p k we say that form x is ainput variable of of the bmc instance.
we illustrate the construction of a bmc instance below.
example .
a programpis given on the left below with an unwinding on the right.
while x y x x assert x y !if x y x x if x y x x if x y assume false assert x y the unwinding is translated into the formulae below.
b x1 x0 y ?
x0 x0 x2 x0 y x1 y ?
x1 x1 x0 y x1 y x2 y e x2 y 0if the arithmetic and comparison operations and the memory model respect the semantics of c the unwinding contains an assertion violation exactly if b e is satisfiable.
bit vector logic is typically used to model numeric variables in c. let var be the set of variables in a formula .
let bbe the set of values that variables can take.
an assignment to a formula is a function var !b.
c. backward reachability computation a classic approach to reasoning about programs is to approximate the set of reachable states.
we recall reachability analysis because b litz combines bmc with ideas from reachability analysis.
asymbolic encoding is a representation of sets of states by data structures such as logical formulae.
let pbe a program with a transition relation t a set init of initial states and a seterr of error states.
we write xfor a sequence of variables.
the initial and error states are represented symbolically by the formulae init x anderr x .
the transition relation generates a formulat x y in which xand yare of equal length.
the precondition transformer defined below maps a formula s x to a formula called a precondition representing the predecessors of states represented by s x .
pre form!form pre s x x t y x s x the set of backward reachable states breach s x contains those that lead to a state in s x .
below we use the notation f0for the identity function and fi 1for the function mapping xtof fi x .
the backward reachable states have the well known characterisation below.
breach err x i2nprei err x the equivalence suggests a na ve approach to computing states that lead to an error.
the iterative computation terminates when a predicate that is a fixed point is reached.
a fixed point ofreach is a predicate f x satisfying the condition reach f x f x a formula q x is an underapproximate precondition if q x pre s x .
the notions for overapproximations are similarly defined.
iv.
c ompositional bounded model checking in this section we present an approach for finding deep bugs by combining bmc with approximate preconditions.
an obstacle to scalability of bmc is that the size of a bmc instance grows beyond the capacity of solvers as the unwinding depth is increased.
reachability analysis with quantifier elimination faces similar computational obstacles.
we combine bmc instances with underapproximate preconditions to scale bmc without producing false alarms about bugs.a.
underapproximating precondition computation we describe the use of sat solvers to underapproximate preconditions with respect to a bmc instance and an error condition.
suppose we have a procedure pand a condition that should hold after pexecutes.
the formula represents a set of states from which an error state can be reached.
the set of predecessors pre represents all states that lead to a state in through p. computing this set is expensive so we compute an approximation.
program analysers typically overapproximate postconditions and may produce spurious results about bugs.
we compute underapproximate preconditions to avoid spurious outcomes.
our first observation is that the values of input variables in a satisfying assignment to a bmc instance dictate the value of other variables in the formula.
suppose a bmc instance b p e p has four variables w x y z with the input variables being xandy.
a satisfying assignment of the form below can be viewed as a formula and this formula implies the sub formula that ranges only over input variables abbreviating true andfalse astand frespectively .
w t x f y f z f w x y z x y even though the sub formula over input variables is weaker than the assignment it is sufficient to constrain the values of all other variables and hence is a precondition for an error .
for the example above the formula x y b p e p has only one satisfying assignment because the values of x andyconstraint the values of all other variables.
the lemma below states this observation formally.
we treat an assignment also as a formula and write inp for the sub formula of that contains only input variables.
lemma .
ifb p e p is satisfied by an assignment the formula inp b p e p has a unique satisfying assignment.
consequently the formula inp b p e p is unsatisfiable.
proof.
consider the satisfying assignment and the formula b p .
the semantics of inp b p is equivalent to replacing every input variable in b p by its truth value in .
after such a replacement only non input variables remain which by definition occur on the left hand sides of assignment statements.
since the formula is generated by a program in ssa form each non input variable is assigned only once and hence has a unique value for the whole formula.
it follows thatinp b p e p has a unique satisfying assignment.
for the second part observe that satisfiese p and so does not satisfy e p .
the constraints on input variables are determined by b p soinp b p must be uniquely satisfied by so the conjunction inp b p e p is unsatisfiable.
the practical value of lemma is that we can derive an unsatisfiable formula from a satisfiable formula.
a proofgenerating sat solver can generate a resolution refutation foralgorithm underapproximate precondition approx pre f a code fragment a postcondition for f a satisfying assignment to b f e f w a weakening parameter i inp b f repeat res solve b f e f generalise i i until ori w return solve a formula if is satisfiable then let be a satisfying assignment return sat else let be a proof of unsatisfiability return unsat a formula that is unsatisfiable.
the refutation makes explicit what properties of the program are used to prove unsatisfiability and this information has numerous applications.
specifically if an input variable does not appear in a refutation the value of that variable does not affect the satisfiability of the restricted formula.
we can use information from proofs to derive an underapproximation of a precondition that is more general than restricting an assignment to input variables.
to return to the example suppose the constraint over input variables is x yand the variable xdoes not occur in the refutation with or without negation .
we know that xis not required to prove unsatisfiability of x y b p e p so we can conclude that y b p e p is also unsatisfiable.
recall that if a bis unsatisfiable then aimplies b. in this example y b p impliese p meaning that the set of states represented by yonly leads to states that contain the error.
since x yimplies y we have generalised the precondition for the error.
the idea above is used to underapproximate preconditions.
the reasoning we have sketched above does not require us to start with an assignment.
it can be used to take a set of states that lead to an error and derive a larger set that only contains paths to an error.
the restriction to states leading to an error is important to avoid spurious results about bugs.
the algorithm for underapproximate precondition computation is shown in algorithm .
we encapsulate interaction with the sat solver by the method solve which takes as input a formula and returns a pair res where resis the result of the satisfiability check.
if is satisfiable res satand is a satisfying assignment.
otherwise res unsat and is a proof of unsatisfiability.
the procedure approx pre takes as input a program fragment f a postcondition that fmust satisfy in order to reach an error a satisfying assignment to the formulab f e f and a parameterw.
an underapproximate precondition is a formulaalgorithm adjustable incremental bmc instance construction next inst f a code fragment a condition for error d a decomposition parameter frag prev code f d nobj repeat foreach fragment ginfrag do remove gfrom frag ifgdefines variables in then addgtonobj else frag frag prev code g d until frag return nobj prev code f a code fragment d a decomposition parameter frag ifd proc then add callers of fin the call graph to frag else ifd stmt then add statements before fin the cfg tofrag return frag satisfying the condition b f e f every execution through fthat starts in a state in leads to a state in .
the procedure approx pre returns an underapproximate precondition.
the condition is approximate because it may not be the weakest such .
since is a condition for reaching an error the formula is a precondition for reaching an error.
the parameter wis used to weaken an underapproximate precondition.
if wis0 the underapproximate precondition isinp .
ifwis1 the formula inp is weakened using information from an unsatisfiability proof.
we have considered two variants for the procedure generalise .
one variant is to weaken by removing all variables that do not occur in the proof .
to do this we first walk the proof backwards to eliminate unnecessary deductions.
further techniques for computing minimal unsatisfiable cores of unsatisfiable formulae can also be used .
lemma .
the formula approx pre p w is an underapproximate precondition of pwith respect to .
proof.
the invariant of the loop in the algorithm is that b f e f is unsatisfiable.
this is because the generalisation step only reduces an unsatisfiable formula to a smaller unsatisfiable formula and projects out the portion of in this smaller formula.
it follows that b f e f implies so is a precondition of .
b. incremental data flow based instance construction if a bmc instance is satisfiable we use approx pre to construct an underapproximate precondition.
to determine if there is indeed a bug we need to propagate the preconditionto the entry point of the program.
the standard approach to propagate facts through a program is to use the control flow graph cfg .
propagation is wasteful if information is propagated through code not relevant for reaching an error.
we use the term fragment for a piece of code that is either a procedure or a configurable number of sequential statements.
bmc instances are generated incrementally using a granularity specified by the user.
a code fragment fdefines a variable x ifxoccurs on the left hand side of an assignment in fand uses the variable if the variable occurs in an expression.
in program analysis a use def graph makes data flow explicit.
we combine both data and control flow information to prune the number of instances that are generated.
given a condition for an error we only use fragments that define variables in that condition to generate bmc instances.
we show in the experiments section that this seemingly simple optimisation has significant impact on the number of instances generated and consequently on the size of programs that can be analysed.
instances are incrementally constructed using algorithm .
the procedure prev code takes as input a fragment fand a parameter dwhich specifies the granularity of fragment.
it returns a set of fragments that execute before f. at the granularity of procedures we return the nodes before fin the call graph of the program.
at the granularity of statements we return statements preceding fin the cfg.
the procedure next inst takes as input a fragment fthat has already been analysed a formula which is a precondition forfto reach an error and a decomposition parameter d which specifies the granularity of fragments.
it returns a set of fragments that precede fand which define variables in .
it is implemented by iteratively calling prev code until only fragments manipulating variables in are obtained.
c. the blitz algorithm blitz combines underapproximate precondition computation with incremental construction of bmc instances to decompose the problem of finding a bug in a large instance to that of solving a sequence of smaller bmc instances.
the advantage is that every instance fits in memory and that a smaller number of instances is considered than generating instances based on control flow.
the algorithm is parameterised so that the user may fine tune the settings used for decomposition and precondition computation using domain specific knowledge or data from benchmarks.
the procedure blitz in algorithm takes as input a program pwhich contains assertions an unwinding bound kfor loops and recursive procedures a weakening parameter wfor precondition approximation and a decomposition granularity d. the algorithm returns an input vector vif there exists an execution of pwith values specified by vthat leads to an assertion violation.
if no violation is found it may be because no error exists in kunwindings or because relevant states were missed by the underapproximation.
the main data structure in blitz is a set of obligations obj.
an obligation contains a fragment fand a formula algorithm the blitz algorithm blitz p a program k a bound for bmc w a weakening parameter d a decomposition granularity obj b m c obligations foreach fragment fcontaining an assertion do add f e f toobj repeat remove f from obj res solve b f e f iffis the program entry point then return violation triggered by input inp else if res satthen approx pre f w obj obj next inst f d until obj is empty representing a condition for an error.
the initial value of is the set of assertion violations possible in a program.
blitz proceeds by solving the instance generated by each fragment inobj.
in addition to the behaviour and error constraint we also use the precondition as an error constraint.
if a bmc instance is unsatisfiable it is eliminated from obj because its behaviour is no longer relevant for finding a bug.
otherwise the instance could be satisfiable either because the error is reachable or because the context in which the fragment fexecutes is not taken into account.
we first underapproximate the error precondition of fusing the method given earlier and then propagate this precondition to other fragments in the program.
the subsequent fragments are determined by following the control and data flow of the program.
there are two outcomes which make blitz terminate.
if the entry point of the program is reached and the precondition obtained is satisfiable a satisfying assignment defines an input vector inp which can be used to trigger an error.
the other outcome is an empty set of obligations.
this can occur either if no assertion is violated or if the underapproximations have lost information about states leading to an error.
in the latter case there is nothing conclusive to report.
the precondition weakening approach proposed in algorithm can be viewed as an eager weakening approach that eagerly weakens each precondition up to a pre determined boundw.
we extend b litz with a lazy approach that avoids having to guess the appropriate weakening bound.
the lazy approach starts by weakening each precondition once.
if the entry of the program is reached with inconclusive results blitz increments wand backtracks to further weaken a previously computed precondition.
the weakening sites are chosen based on data flow and only applied if a precondition is not the weakest precondition.
theorem .
ifblitz p k w d returns an input vector an assertion violation is reachable in p.v.
i mplementation and evaluation a. implementation and comparison to other tools we implemented b litz within the cprover framework which is the basis of the bounded model checker c bmc which targets ansi c .
to extract proofs of unsatisfiability we use a proof logging version of the sat solver m inisat .
our implementation uses several practical optimisations to improve upon the compositional bmc algorithm we presented.
for one we interleave unwinding and formula generation to avoid storing large structures in memory.
this optimisation influences the architecture of implementation.
we try to avoid recomputing information about procedures whenever possible.
when a procedure has different callees we also try to reuse preconditions that were computed earlier if relevant.
this optimisation is a rather weak form of procedure summarisation used in program analysis.
we compare b litz to other tools at a conceptual level.
tools with the similar goal of bug finding and which we compare with are c bmc esbmc and c orral .
architecturally c bmc and e sbmc are similar both tools inline all procedures into a single bmc instance.
like b litz corral combines bounded model checking with nondeterminism to bound the scope of analysis and is competitive with the stateof the art .
unlike b litz corral inlines procedures on demand instead of propagating preconditions.
for solvers corral and e sbmc use z3 an efficient smt solver cbmc and b litz use the c prover framework which directly reduces a bmc instance to sat and solves it with a sat solver.
section vi contains a more detailed discussion of the algorithmic content of these tools.
b. benchmarks we evaluate b litz on the bugbench data set to measure its performance in detecting known vulnerabilities.
bugbench is an independent benchmark suite for systematic evaluation of bug detection tools .
it aims to be a representative collection of real world c programs with known bugs.
in our evaluation we used the vulnerability subset of the suite that focuses on memory safety violations the most critical type of bugs.
our results are in section v c. we also applied b litz to production software from the internet systems consortium to search for unknown vulnerabilities.
the isc develops and distributes critical internet infrastructure software to internet providers worldwide1.
we found new vulnerabilities in multiple production releases of isc programs currently deployed in the internet.
we discuss these results in section v d. in section v e we evaluate b litz under configurations regarding propagation control vs data flow and precondition weakening.
we find that data flow based propagation is key to b litz s scalability.
we also find that the lazy approach to weakening preconditions works better than the eager approach.
all experiments were performed on intel xeon .
ghz machines with 32gb ram.
1isc software is deployed by over of internet providers worldwide evaluation on the bugbench vulnerability benchmarks the vulnerability benchmarks in bugbench consist of programs polymorph ncompress man gzip bc squid andcvs.
all benchmarks are labelled with the location and type of vulnerability stack overflow global overflow heap overflow and double free.
we list these programs in table i with the labels b1 and indicate their sizes and type of vulnerability they contain.
into each program we inserted an assertion that if violated would trigger the vulnerability.
we also statically determined the minimum unwinding krequired to reach the vulnerability.
this value is shown in the table and the same value was used with all tools.
we then used c bmc esbmc corral and blitz to check for assertion violations.
c bmc and e sbmc support slicing which reduces the size of bmc instances.
we ran these tools with slicing turned on.
all tools terminate once an assertion violation is found or report no violation on termination.
we used a timeout of hours 86400s .
as listed in the table an unwinding bound of 3was sufficient to find most vulnerabilities.
the only exception was b2 where an unwinding of k was required to reach a buffer overflow.
this was the number of iterations to traverse a buffer of that size.
we ran b litz with data flow driven propagation and lazy weakening of preconditions.
we also fixed the granularity of each analyzed code fragment in b litz at the level of a procedure in all our experiments.
thus each analyzed bmc instance corresponds to a single procedure.
the evaluation results are in rows b1 of table i. c bmc and e sbmc produced similar results so we omit e sbmc from table i to conserve space.
all tools find a vulnerability in benchmarks b1 b3 b4 and b5 with b litz requiring the least amount of time.
b litz is the only tool that does not time out and finds vulnerabilities in b2 b6 b7 and b8.
the maximum time required by b litz was .
minutes to find a double free vulnerability in cvs.
the time and memory required by b litz increases with the size of the benchmark and unwinding bound but we did not observe a timeout or memory exhaustion.
the experiments demonstrate the utility of underapproximate preconditions for bug finding.
the underapproximate preconditions did not usually require more than one weakening with the exception of b6 where b litz backtracked to weaken the precondition times.
the results suggest that our compositional bmc approach is effective for finding violations on real world programs of significant sizes.
cbmc and b litz have similar performance on the smallest benchmark b1 .
both tools also found the bug in b3.
on benchmarks b2 b4 b5 and b6 c bmc runs out of memory memory and on benchmarks b7 and b8 c bmc exceeded the hr timeout.
corral has performance similar to b litz on benchmarks b1 b3 b4 and b5 and outperforms c bmc on benchmark b3.
however c orral exceeded the hr timeout on benchmarks b2 b6 and b7 and terminated prematurely without finding the vulnerability on the largest benchmark b8.d.
evaluation on isc programs we now evaluate b litz on open source production software from the internet systems consortium isc .
we use the current production release of aftr v1.
and sntp v4.
.6p5 .
the address family translation router aftr plays a central role in transitioning the global internet from ipv4 to ipv6 it provides backwards compatibility to transport ipv4 traffic over ipv6 carrier infrastructure.
the transitioning process was launched on june 20122and is currently ongoing using the version of aftr in this evaluation.
the program sntp is a reference implementation of the simple network time protocol that provides clock synchronisation over the internet.
we focus on finding null pointer dereference vulnerabilities which are not represented in bugbench.
to check for null pointer dereferences we use the default null pointer dereference assertions inserted by c prover .
since we have no knowledge of any vulnerability in the isc programs we used an unwinding depth of k for all the tools.
the results are rows i1 of table i. again e sbmc produces similar results to c bmc .
cbmc quickly ran out of memory on these programs.
c orral and b litz separately found the same vulnerabilities within minutes.
we manually verified the results and have confirmed these vulnerabilities with the isc who will be patching their software for redistribution to affected internet providers worldwide.
we briefly describe the two vulnerabilities in the following paragraphs.
aftr .a pointer ss1 is dereferenced after a function call ss1 stdio open .
the function stdio open calls fileno stdin in its body and returns null if fileno stdin returns on stream failure.
an attacker with control over the program s environment stdin will be able to exploit the null pointer dereference.
sntp .a pointer bcastaddr is dereferenced after being allocated a buffer through a call to realloc .
however realloc could return null when memory allocation fails.
an attacker who is able induce memory allocation failure will be able to exploit the null pointer dereference.
e. evaluation of b litz features we now evaluate b litz using different configurations for propagation and precondition weakening.
first we compare the effect of using data flow for propagating preconditions to that using control flow on performance.
second we compare the performance of an eager and a lazy weakening strategy.
in eager weakening preconditions are weakened several times before propagation while in lazy weakening all propagation is performed first and preconditions are weakened only if an inconclusive result is obtained at the entry of the program.
the timeout for the experiments was hours 86400s .
data vs control flow propagation fig.
compares the running time between using precondition guided data flow propagation and control flow based propagation.
in of 2the internet society declared june the world ipv6 launch day.l.
program kloc vulnerability cbmc corral blitz k time mem.
bug time mem.
bug w r time mem.
bug s mb s mb s mb known vulnerabilities bugbench benchmark b1 poly .
stack overflow 21x 10x 18x b2 poly .
global overflow x b3 ncomp .
stack overflow 258x 32x 506x b4 man .
global overflow 119x 156x b5 gzip .
global overflow 384x 67x b6 bc .
heap overflow x b7 squid .
heap overflow 9024x b8 cvs .
double free x discovered new vulnerabilities isc programs i1 aftr .
null ptr deref.
482x 959x i2 sntp .
null ptr deref.
136x 227x table i comparison of c bmc corral and b litz on benchmarks.
rows b1 contain the evaluation results on known vulnerabilities in the bugbench benchmark while rows i1 contain the evaluation results on programs from the internet systems consortium isc where blitz and c orral discovered new vulnerabilities.
the l. column lists the benchmark labels.
the kloc column indicates the size of each benchmark program in thousands of lines of code.
the k column lists the statically determined minimum number of loop and recursion unwindings required to trigger the violation condition in each benchmark.
the time s column indicates the length of time for which the tool ran with indicating that the tool exceeded the hour timeout.
the mem.
mb column shows the maximum amount of memory used by the tool in mb.
we write to indicate that the tool exceeded 32gb of memory.
the bug column indicates whether the vulnerability was found by the tool on termination.
the w column indicates the number of precondition weakening passes used in b litz detected automatically using the lazy approach.
the r column shows the number of procedure refinements in the propagation chain that found the bug.
benchmarks control flow based propagation leads to a timeout.
barring one benchmark on which the two techniques perform equally data flow based propagation is always superior.
the results suggest data flow based propagation is key to scalability of b litz .
existing tools such as c orral and a lter follow control flow and inline procedures on demand.
using information in preconditions to construct instances allows b litz to sidestep code that is irrelevant for detecting a violation.
for example in one of the largest programs squid a single call to the procedure comm close would have required the analysis of up to million unique procedure instances if control flow based inlining was used.
blitz however did not analyze the comm close procedure.
lazy vs eager weakening we compare lazy and eager weakening of underapproximate preconditions.
a lazy approach starts the analysis using a weakening bound .
when blitz terminates with an inconclusive result the weakening bound is incremented and b litz backtracks to the first computed precondition on the data flow path that is not equivalent to the weakest precondition.
we configured the eager approach to use passes since this was the upper bound detected by the lazy approach see table i .
fig.
compares the effect of lazy and eager weakening on running time.
the lazy approach leads to shorter running times because weakening a precondition twice suffices to discover a bug in most benchmarks.
vi.
r elated work this paper lies at the intersection of model checking and program analysis.
of several techniques to automatically compute information about a program slam is notable for its success as a software model checker .
slam requires repeated calls to a theorem prover to construct abstractions and refines the abstraction using counterexamples.
one refinement100101102103104105100101102103104105 control flow propagation running time s data flow propagation running time s comparison of running times fig.
a comparison of b litz running times with data flow against control flow propagation with hr timeout.
strategy uses weakest preconditions but these are computed over single paths unlike program fragments as in our case.
the compositional approach to system analysis is key for overcoming the complexity of any real world system.
we focused on composition defined with respect to sequential composition and procedure calls as in hoare logic .
compositionality is exploited in program analysis and symbolic execution but we are not aware of it being used in bmc to date.
the b litz algorithm is composition in the same sense but differs from these above approaches because it uses dataflow to further reduce the decomposition of the program.
eager weakening running time s lazy weakening running time s comparison of running times fig.
a comparison of b litz running times with lazy against eager weakening of preconditions with hr timeout.
a key technique for relevance driven program analysis is craig interpolation which has numerous applications in formal verification.
interpolation was applied to over approximate reachable states in hardware model checking in to infer preconditions in and to learn annotations from failed explorations to improve backtracking efficiency .
we do not use standard techniques for computing interpolants from proofs because these lead to large formulae and consume more memory.
the preconditions we generate do satisfy the interpolation condition and can be viewed as a restricted type of interpolants that have compact representations in addition to satisfying the usual vocabulary and implication conditions.
our approach of generalising satisfying instances is in the same spirit as ic3.
ic3 is a technique for incremental construction of inductive proofs for modular analysis .
unlike ic3 b litz only seeks to discover assertion violations and does not attempt proofs of correctness.
there are two main strategies to apply scope bounded analysis.
one strategy partitions a program into multiple subprograms at the outset each with a subset of paths and solve all of them in parallel .
though amendable to a parallel architecture it may generate a prohibitively large number of subprograms.
another strategy is to overapproximate behaviour outside the scope of bounded analysis and iteratively refine it.
called structural abstraction in c alysto it also used in corral and a lter .
dc2 further uses a lightweight static analysis to infer pre and post conditions to model the behavior of procedures outside the scope of analysis but its scope expansion is not automatic.
c orral automates forward callee scope expansion with stratified inlining of procedures and selective variable abstraction.
a lter alternates between eager forward callee and lazy backward caller expansion and uses interpolation to learn procedure preconditions that lead to failed scope expansions to prevent re exploration onbacktracking.
b litz recasts satisfying assignments to obtain unsatisfiable formulae and then derives intermediate preconditions from unsatisfiability proofs.
unlike existing approaches where the size of a bmc instance grows as more procedures areinlined blitz can bound the size of instances.
slicing is commonly used to reduce the size of bmc instances by removing variables that are syntactically irrelevant to a property e.g.
.
it is also known as cone of influence reduction where the set of relevant variables expands with the size of the slice diminishing its effectiveness e.g.
despite slicing c bmc and e sbmc frequently run out of time memory .
beyond syntactic relevance b litz also uses proofs of unsatisfiability to reason about semantic relevance on small code fragments at a time producing an overall cone with much smaller base.
vii.
c onclusions and future work we presented b litz a new compositional bounded model checking algorithm for software and showed that it scales bmc to real world programs.
b litz is capable of finding all known vulnerabilities in a known data set and has also discovered new vulnerabilities in widely deployed software.
the new discoveries have led to bug fixes which will soon be deployed.
blitz works by constructing a series of bmc instances that when composed lead to a violation.
a novel feature of our algorithm is the use of underapproximate preconditions in the context of bmc .
the underapproximations are computed using information from resolution refutations generated by a sat solver.
the underapproximation guarantees that the tool does not generate false alarms about the existence of bugs and the proofs guarantee that the approximation is not too restricted by considering only facts relevant for the violation.
our procedure is parametric allowing for the preconditions to be iteratively weakened to eventually derive dijkstra s weakest precondition if resources permit.
the size of code fragments analysed is configurable and can range from a single statement to an entire procedure depending on code size and memory available.
there are several directions to explore.
we did not use craig interpolation over proofs because the formulae were large.
an interesting question is whether proofs can be manipulated to yield interpolants that have compact representations and whether this improves performance.
a second question is how one may guess the optimal configuration of the algorithm unwinding weakening granularity by a preliminary analysis of the code.
third concrete and symbolic representations have been combined in symbolic execution with great success but such an approach has not been applied to bmc .
we anticipate that combining concrete values with bmc may provide new opportunities for decomposition.