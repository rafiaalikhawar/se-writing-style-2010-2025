carfast achieving higher statement coverage faster sangmin park georgia institute of technology atlanta georgia usa sangminp cc.gatech.eduishtiaque hussain christoph csallner university of texas at arlington arlington tx usa ishtiaque.hussain mavs.uta.edu csallner uta.edukunal taneja accenture technology labs and north carolina state university raleigh nc usa ktaneja ncsu.edu b. m. mainul hossain university of illinois at chicago chicago il usa bhossa2 uic.edumark grechanik university of illinois and accenture technology lab chicago il usa drmark uic.educhen fu qing xie accenture technology labs san jose ca usa chen.fu qing.xie accenture.com abstract testcoverageisanimportantmetricofsoftwarequality si nceitindicates thoroughness of testing.
in industry test coverag e is often measured as statement coverage.
a fundamental problem of so ftware testing is how to achieve higherstatement coverage faster and it is a difficult problem since it requires testers to clev erly find input data that cansteer execution sooner toward sections o f application code that contain more statements.
wecreatedanovelfullyautomaticapproachfor achievinghigher statementcoveragefaster carfast whichweimplementedand evaluated on twelve generated java applications whose size s range from loc to one million loc.
we compared carfast with severalpopulartestcasegenerationtechniques includin gpurerandom adaptive random and directed automated random testin g dart .
our results indicate with strong statistical signi ficance that when execution time is measured in terms of the number of runs of the application on different input test data carfas t outperforms the evaluated competitive approaches onmost subject applications.
categories andsubject descriptors d. .
testinganddebugging symbolic execution testingtools keywords testing statementcoverage experimentation .
introduction test coverage is an important metric of software quality since it indicates thoroughness of testing.
statement coverage which measures the percentage of the executed statements to the permission to make digital or hard copies of all or part of thi s work for personal or classroom use is granted without fee provided th at copies are not made or distributed for profit or commercial advantage an d that copies bear this notice and thefull citation on the firstpage.
tocop y otherwise to republish topostonserversortoredistribute tolists re quires priorspecific permission and or afee.
sigsoft fse november11 cary northcarolina usa.
copyright acm ... .
.total number of statements in the application under test is viewed as an important kind of test coverage.
achieving high er statement coverage is correlated with the probability of de tecting more defects and increasing reliabilityof s oftware .
even though it is agreed that statement coverage al one may not always be a strong indicator of software quality page itisageneral consensus thatachieving higher statem entcoverage is desirable for gaining confidence insoftware qualit y and it serves as an indicator for test completeness and effectiven ess .
statement coverage is widely used in industry as a common cri terion for thoroughness of software testing.
different sta ndards require achieving high levels of statement coverage for exam ple avionics industry standard do demands that close to statement coverage be achieved and avionics industry stan dard do 178b and automotive industry standard iec detail differentrequirements onachievingstatement coverage.
m anydifferent organizations use statement coverage as the major cr iterion for measuring the quality of software testing .
given the importance of statement coverage how common it is and how widely it is used to evaluate the thoroughness of test ing it is not surprising that statement coverage is the one c overage metric that is supported by almost all coverage based testi ng tools whereas other coverage measures e.g.
branch coverage me thod coverage or class coverage are supported byfewer tools .
.
higherstatement coveragefaster achieving higher statement coverage means that testers hav e to select test input data with which they can execute larger por tions ofapplicationcode.
higherstatementcoverage isalways be tterfor increasingtheconfidenceofstakeholdersinthequalityofs oftware however statement coverage is rarely achieved espec ially when testinglarge scale applications .
the fas ter these testersachievehighercoverage theloweristhecostoftes ting sincetesterscanconcentratesooneronotheraspectsoftes tingwith the selected input data for example performance and funct ional testingwithoracles.
we measure the speed with which a certain level of statement coverage isachievedbothin thenumber oftestruns oftheapplication under test aut with different test input data i.e.
i terations of executing the same application with different input data and in the elapsed time of running the aut.
whilethe elapsed time givestheabsolutevalueofthetimeittakestoreachacertainleve lofcoverage measuringthenumberofiterations whichessential lymeans number of test cases to achieve the coverage goal is importa nt for many reasons e.g.
using fewer test cases requires less man ual effort for creatingtest oracles for these testcases.
moreover measuring the number of iterations provides an in sight into the potential of a given approach.
the elapsed tim e includes time for generating or selecting input data and time to run the aut using these data.
in many systematic test case genera tion or selection approaches the time spent on generating or sel ecting input data is significant.
thus if an approach achieves a hig her test coverage using fewer iterations but spends more time o n each iteration this time can eventually be reduced by improving the efficiencyof the particular approach.
a big and important challenge is to get higher statement cove rage fasterfornontrivialapplications thathaveaverylarg espace of input parameter values.
many nontrivial applications have complex logic that programmers express by using different cont rolflow statements which are often deeply nested.
in addition these control flowstatementshavebranchconditionsthatcontai nexpressions that use different variables whose values are compute d using some input parameters.
in general it is difficult to choose s pecific values of input parameters to direct the execution of these a pplications tocover specificstatements.
the maximum test coverage is achieved if an application is ru n with all allowed combinations of values for its inputs.
unfo rtunately this is often infeasible because of the enormous num ber of combinations for example integer inputs whose values o nly range from zero to nine already leave us with 1020combinations.
knowingwhatcombinationsoftestinputdatatoselectfordi fferent input parameters to drive the aut towards the statements nes ted insidevariousbranchesisverydifficult.
thus afundament alproblemofsoftwaretestingishowtoachievehigherstatementco verage fasterby selecting specific values of input parameters that lead th e executions of applications to cover more statements in a sho rter time period.
.
a novel approach we created a novel approach for achieving higher statement coverage faster carfast using the intuition that higher statement coverage can be achieved faster if input data are select ed to drive the execution of the aut toward branches that contain m ore statements.
that is if the condition of a control flow state ment is evaluatedto true somecodeisexecutedinthescopeofthisstatement.
the statements that are contained in the executed code are saidtobecontrolledbyorcontainedinthecorrespondingbr anchof this control flow statement.
in program analysis these sta tements aresaidtobe controldependent onthecontrol flowstatement.
in carfast static analysis is used to estimate how many stat ementsarecontainedineachbranch.
onceitisknownwhatbran ches contain more statements carfastuses a constraint based s election approach to select input data that will guide the execut ions of the aut towards these branches.
in carfast input data are no t generated but they rather come from external databases as w e describe it in section .
.
comparing to carfast many automat ic testdatagenerationtechniquesusecomputationallyexpen siveconstraint solvers to generate test data for achieving higher test coverage.
using these solvers negatively af fects the scalabilityofthesetechniques.
byreplacingconstraints olverswith selectors notonlydoes carfastachieve highercoverage fa ster but alsoit achieves betterscalability section5 .
carfastoffersmultiplebenefits itisfullyautomaticsinc eitdoes not require any intervention by testers it is directed sinc e it ex plores branches inthe control flow graph cfg oftheautrather than an enormous space of the combinations of the values for t he inputtestdata anditisscalableonlarge scaleapplicati onswithup to500kloc as demonstrated by our experiments withtwelve ja va applications with up to one million loc.
even though we built carfasttoworkwithjavaprograms therearenofundamental limitationstogeneralizing ittootherlanguages andplatform s suchas c or c .
this approach may be generalized for other coverag es that can be statically approximated and dynamicall y computed.
to the best of our knowledge carfast is the first appro ach that defines and uses static program analysis based coverag e gain prediction to achieve higher coverage faster and this work is the firstthatevaluated thisidea withstrongstatisticalsigni ficance ona large number of subject applications of varying sizes.
.
ourcontributions thispaper makes the followingcontributions we developed a novel algorithm for achieving higher statement coverage faster and we implemented it as part of carfast.
we applied carfast to twelve java applications whose sizes range from loc to one million loc that we generated using stochastic parse trees .
carfast subject jav a applications and the stochastic application benchmark ge nerator are available for public use1.
we conducted large scale experiments using amazon ec2 to evaluate carfast and competitive approaches against one another specifically pure random and adaptive random test ing and directed automated random testing dart using a rigorous experimental evaluation methodology .
the results show that when execution time is measured in terms of iterations carfast outperforms evaluated compet itiveapproaches formostsubjectautswithstrongstatistic al significance.
finally we compared pure random testing to adaptive random testing to address an open issue in determining which approach is better .
adaptive random performs statis tically as good as pure random testing when lower coverage istargetedandtimeismeasuredintermsofiterations.
when higher coverage is targeted pure random beats adaptive ran dom testingwithstrongstatisticalsignificance.
.
the carfastapproach in this section we give an illustrative example of how our ap proach works we formulate our hypothesis upon which we designed our approach and we give analgorithm ofcarfast.
.
anillustrativeexample an illustrative example is shown in figure using java like pseudo code.
linenumbers tothe right should be thought of a s labels as much code is omitted for space reasons.
this example has if else statementsthatcontrol threebranches wherebranchlabels are shown in comments along withthe numbers of statemen ts that these branches control.
these numbers are given purely for an illustrativepurpose.
consider executing this code with randomly selected input v aluesi1 andi2 which leads to the elsebranch3in lines .
the number of distinct uncovered statements that are reach able from this branch is which is significantly less than the 1all tools and subject applications are available for downlo ad at if i1 .. branch statements else if i2 .. branch statements else .. branch statements if .. if .. .. .. figure1 anillustrative example.
numbersofstatementscontainedinthetwootherbranches.
w esay that a previously uncovered statement sis contained in a branch b if there exists a concrete input that triggers an execution that evaluates the condition of the branch bandcovers s. besides the lower number of statements reachable from branc h the control flow within branch is also more complex than th e control flow in branch or branch as denoted by a few example nestedif else statements .
clearly this is one of the worst test inputs since it covers only of this code at best.
to achiev e higher coverage faster we would like to learn from this exec ution to select a test input that satisfies i1 ne ationslash i2 to steer the next run toward branch since it contains the biggest number of distinct reachable uncovered statements i.e.
thus increasing test coverage upto70 .
however none of the existing approaches can systematicall y steer the execution towards branch since it is the nature of randomization to select data points independently from one ano ther fromtheinputspace.
dartdynamicallyanalyzesprogrambeh avior using random testing and generates new test inputs autom atically to direct the execution systematically along alterna tive program paths .
a problem is that the original dart algorith m will keep exploring all nested branches in branch 3using adepthfirst search algorithm.
that is dart keeps exploring the branch for a while even though the gain in coverage will rather be min uscule.
.
our observation preliminary study and hypothesis weobservethatmanyapplicationshaveafewbranchesthatco ntain large bodies of statements and many more branches that c ontain only few statements.
this observation is supported by a preliminary study we did on three nontrivial and widely used ope nsource apache applications log4j2 ant3 andjmeter4.
for each application we counted the number of statements ineac h basic block.
our results indicate that the number of statement s per basic block approximates the power law i.e.
approxim ately of the statements are in20 of the basic blocks.
specifica lly ofthebasicblockscontain73 ofthestatementsin ant injmeter and in log4j.
assuming that this observation holdsformanyapplications ourintuitionisthatwecanexp loitthis skewed size distribution of the basic blocks in test case sel ection.
i.e.
we want to systematically steer aut execution towards these large basic blocks toachieve higher statement coverage fa ster.
wehypothesizethatwecansignificantlyacceleratetestsel ection techniques by guiding the selection to test input data that c overs those branches that contain more uncovered statements by e stimatingthenumberofdistinctstatements.
thishypothesisi srooted in the essence of systematic testing which is a counterpart to ran2version1.
.
3version1.
.
4version1.
testing where test data inputs are selected without any p rior knowledge .
to test our hypothesis we combine systemat ic and random testing approaches in a novel way using the insigh t that higher coverage can be achieved faster if it is known whi ch distinct branches that are still uncovered contain more sta tements.
knowingtheconstraints frombranch conditions mayenable s election of test input data that leads to execute the statements w ithin those branches.
.
carfastby example we review how our approach works using our illustrative example of figure .
once branch 3of this code is executed using input values i1 andi2 constraints c1 i1 ne ationslash and c2 i2 ne ationslash can be learned automatically.
since branch 2contains the biggest number of statements i.e.
the statem ents of line4 constraint c2can be negated and the resulting constraint formula will be c1 c2ori1 ne ationslash i2 .
in the next step test input data is obtained that fits this constraint that is the value ofi1 ne ationslash andi2 .
this process can be repeated as often as necessary toachieve higher coverage.
inthe worstcase this approach may resultintestinput data that leadsexecutiontowardsalreadyexecutedbranchesorbranc hesthat have fewer statements.
for example if the first input data is selectedi1 and branch 1is executed no additional useful constraintexceptfor i1 ne ationslash 10willbelearnedduringthissteptohelpour approachtosteerexecutiontowardbranch .
however random selection allows testers to select completely different data which in turnwillleadtodifferentexecutionprofilesandlearningm oreconstraints .
our hypothesis is that by learning more of these constraints with each execution of the aut it is possi ble to converge to higher coverage faster.
verifying this hypothe sis is a goal of this paper.
.
ranking branches by statements tounderstandwhichbranchesaffectstatementcoveragethe most we rank each branch if loop etc.
by the number of statemen ts it contains the number of statements that are transitively controldependent on that branch .
executing higher ranked branche s enablesachievinghigherstatementcoveragefaster.
torankb ranches we construct and traverse a cfg of the aut then we count the inter procedural statements that are control dependen t on each branch condition.
i.e.
if in method c branchbtransitively controls a call to method m then the statements of mare treated as if they were in lined into the calling method c and some statements ofm and possibly statements of methods called by m may be included inthe count of statements thatare control dependen t onb.
specifically if the method mis virtual we perform virtual call resolution using static class hierarchy analysis and coun t all the statements in all the target methods but use the one with the maximum statementstodetermine thenumber ofstatements contr olled bybranchb.
.
selecting existing testinput data we assume that the test input data come from existing reposit ories or databases.
this is a common practice in industry we c onfirmed it after interviewing professionals at ibm accentur e two large health insurance companies a biopharmaceutical com pany twolargesupermarket chains andthreemajorbanks.
forins tance therentersinsuranceprogram designedandbuiltbyamajorinsurance company has a database that contains approximately m illioncustomer profiles whichare used as the testinput data.
as part of carfast we translate constraints into sql querie s against such existing databases .
for example to find va luesfor input variables i1 andi2 that satisfy the constraint i1 ne ationslash i2 the following sql query is executed select from inputtbl where i1 !
and i2 .
someofthesesql queries include millions of conditions in the whereclause which caused runtime problems in some commercial strength databa se management system such as microsoft sql server.
to scale car fast we developed a lightweight and efficient sql based con straint evaluator that wedescribe insection3.
.
.
the algorithm the algorithm carfast is shown in algorithm .
this algorithm takes as its input the set of the input parameter values t the autp and the set of accounted aut branches b. the total coverage score totalcov is computed and returned in line 31of the algorithm.
in step2 the algorithm initializes the values for total coverage totalcov to zero the set of covered branches bcovwhose statements are covered and the set of constraints to the empty set .
in step3 the procedure computebranchfun is called that computes the function brankthat maps each branch of the aut p to the approximate number of statements that are reachable fro m this branch.
next instep theprocedure sortsortselementsofinput setbinthedescendingorderaccordingtothenumberofstatement s using the function brank producing the sorted set bs.
in step5 the procedure getrandomtestinput randomly selects a data object tfrom the set of the input parameter values that is input testdata t andthisdataobjectisremovedfromthesetinstep .
thisalgorithmrunstheloopbetweensteps whichterminates on thecondition of the reached timelimitor desiredcoverag e i.e.
thepredefinedvalue covceiling .
instep8 theaut pisexecuted using the input data t resulting in the updated value of totalcov added branches that were covered during this execution to th e set of covered branches bcov and added constraints that are learned during this execution.
then in the forloop insteps each member branch in the set bsis examined to check whether it was coveredinthepreviousrunoftheaut.ifsomebranch bkwascovered it is removed from the set bsin line23 otherwise the first occurrenceofthecorrespondingconstraint ckisinverted ignoring the following constraints inthe pathcondition inline .
bytreatingaconstraintasaquerytoobtaininputdatathats atisfy the conditional whereclause the subsets of test input data tc is obtained in line 13that satisfy this clause that is the flipped constraint.
if tc is empty then no test input data from our input database can lead to the desired branch and this message is i ssued inline20.
otherwise oneinput tisrandomlyselectedfromtheset tc inline15andthecontrolisreturnedtoline 25andeventually to line8 where the aut is run with this input thereby repeating the loop.
in some cases it may not be possible to know the exact constraints toreach certain statements since the set of const raints that is collected by the concolic engine corresponds to reaching different nodes of the cfg and subsequently different statements .
flippingtheseconstraintsandsolvingtheseflippedconstraint s mayresult in input data that will lead the aut toward other uncover ed statements but not necessarily the desired statements.
ho wever as more constraints are collected with newly obtained test i nput data these constraints eventually enable carfast to narro w down the scope of the executed statements tothe ones thatare desi rable.
this works only if the input test data set contains an input th at can reach such statements.
if the application contains a sta tement thatisnotreachablewiththeinputsfrominputtestdata th encarfast will never cover that statement.
however as the result s of thealgorithm the carfastalgorithm.
carfast testinputdata t autp autbranches b totalcov bcov c initialize values of the total statement coverage the set of covered branches and the set of constraints.
computebranchfun p mapsto brank b b rank sort b brank mapsto bs sort elements of the set in the descendingorder bytheir rankusing the function brank getrandomtestinput t mapsto t t t mapsto t t repeat runaut p t mapsto totalcov mapsto totalcov cov bcov mapsto bcov b c mapsto c c1 ... cn foundtest4branch false for allbk bsdo ifbk bcovandck cthen flipconstraint c mapsto c mapsto c1 ... ck gettestinput c mapsto tc t if tc ne ationslash 0then getrandomtestinput tc mapsto t t mapsto t t foundtest4branch true break the forloop else printgivenconstraint ccannot be satisfied endif else bs mapsto bs bk endif endfor iffoundtest4branch false then getrandomtestinput t mapsto t t mapsto t t endif untiltime limitisnot reached or totalcov covceiling returntotalcov experimental evaluation show in section carfast outperf orms other competitive approaches under different conditions.
.
implementationanddeployment in this section we describe main challenges and the salient featuresofourimplementationanddeploymentincludingtheco ncolic engine.
.
mainchallenges our implementation goal is to demonstrate that carfast is vi able by applying it to large scale auts.
there are two main ch allenges it is memory intensive and itcontains cpu intensi ve components.
extracting constraints by executing auts takes ti me and most importantly significant amounts of memory.
typically concolicenginesincurmorethananorderofmagnitudeoverhead from normal program execution.
memory footprint of concolic eng ines increases quickly as the engines must keep track of symbolic representations of all aspects of the current program executio n e.g.
symbolic representations of the static fields of all loaded c lasses as execution traces get longer.
in our experiments one extr acted constraintfroma50klocautisoverfivemegabytesanditssiz e growsto50gbforonemillionlocaut!moreover solvingsuch constraints can take a long period of time since it involves performing queries onlarge sets of input test data.
.
concolicexecution engine we used dsc a java dynamic symbolic execution engine i.e.
a concolic engine for java auts in carfast.
below we d escribe its main features and how we adapted it to scale to larg e auts.
.
.
overviewofdsc dsc instruments the bytecode of auts automatically by inser ting method calls i.e.
callbacks after each instruction i nthe code.
during aut execution the callbacks enable dsc to maintain t he symbolic state by mirroring the effects of each user program instruction including the effects of reading and writing hea p i.e.
array and object field locations performing integer and flo ating point arithmetic following the local and inter procedura l controlflows andhandling exceptions.
dsc integrates well with the existing java execution enviro nments itdoes not require anymodifications ofthe user appli cation code or the virtual machine.
dsc uses the instrumentation f acilities provided by the jvm of java 5to instrument the user progr am at load time using the open source bytecode instrumen tation framework asm .
by manipulating programs at the bytecode level dsc extends its analysis from the user code into all li braries called by these programs.
in addition dsc allows users to se lectivelyexclude classes from instrumentation.
.
.
thedumpermodeofdsc dsc in its normal mode represents every concrete computatio n by a corresponding symbolic expression caches it in memory and utilizes it later when the same computation is repeated or is used in a subexpression.
however nontrivial applications cont ain large number of computation steps and caching symbolic expressio ns quickly exhaust the available heap memory.
moreover often computations are done in loops or recursive call chains and when concolicengines process theseloops orrecursivecallchains theyproduce long symbolic expressions which are in turn used in sub sequent computations adding quickly to the total length of the resulting symbolic expression.
as a result even for moderate size programs concolic executions quickly exhaust all memory.
toscale tolargeapplications we introduced a dumper mode f or dsc to minimize the memory consumption for the symbolic stat e representation.
instead of caching symbolic expressions i n heap memory this dumper mode introduces local variables symbo ls for each expression and dumpsor writes these expressions to the disk.
later a dynamic lookup and replacement technique is u sed onthedumpfiletobuildtheconstraintsorpathconditioninvolving input parameters.
.
constraint based selector toimprovethescalabilityofcarfast wedevelopedaconstr aintbased selector rather than using off the shelf constraint solvers.
our motivation is twofold improving the speed of computati on and better utilizing resources.
specifically our concolic engine dsc is a bit tool meaning that it can only use less than fou r gigabytes of ramata time.
addinga constraint solver tothe p rocessspace ofdscwouldsignificantlyreduceavailablememor y. to address this problem we implemented the constraint based selector as a separate server process that can serve many dsc clien ts simultaneously through socket interfaces.
fortheimplementationoftheconstraintsolver atthebegi nning we kept all the data in a relational database.
then by runnin g a query wetriedtoselectthe data thatsatisfythe constrain t given as the where clause of the query.
but the traditional rdbmssfailed to process a query with such a big constraint part in th e whereclause.
as a different approach we wrote a set of production rules to define a formal grammar so that every possible constraint can be recognized by that grammar.
we used the antlr tool5for processing the grammar and its languages.
with the help of antlr we were able toparse and process much larger constraints.
when the server process constraint solver receives a quer y fromaclient theserverbuildstheabstractsyntaxtreefor theconditionpart whereclause ofthe query.
then itevaluates the tree inabottom upfashion againstallpossibleinputdatainth erepository.
finally astestinputdata theserverprocessreturn svaluesfor the parameters that satisfy all the conditions in the condit ion part of the query.
.
miscellaneous we implemented branch ranking using java static analysis an d transformation engine called soot .
all conditional br anch statements in the auts are ranked using the approach describ ed in section .
.
at runtime we used emma6to compute and report statement coverages.
also we modified callback functi ons in dsctokeeptrackofthecoveredbranches duringthetestexec ution to reset rankings of the already executed branches to zero to avoid repeatedly executing already coveredstatements.
.
experiments to determine how effective carfast is in achieving higher st atement coverage faster we conducted an experiment with compe titive approaches such as random testing adaptive random tes ting and dart on twelve java applications i.e.
auts whose size s rangefrom300loctoonemillionloc.inthissection webrie fly describethesecompetitiveapproaches providethemethod ologyof our experimental design explain our choice of subject auts and discuss threats tovalidity.
.
variables main independent variables are the subject auts the value o f testcoveragethatshouldbeachievedforautsineachexperi ment and approaches with which we experiment i.e.
random adap tive random testing dart and carfast .
a dependent variable is the execution time that it takes to achieve a given test coverage .
we measure the execution time both in terms of elapsed time eand as a number of iterations of aut executions with different in put values i. the effects of other variables the structure of aut and the types and semantics of input parameters are minimized b y the design of thisexperiment.
.
.
randomtesting random testing approach as the name suggests involves ran dom selection of test input data for input parameter values and in that it showed remarkably effective and efficient for expl oratory testing and bug finding .
a seemingly stupid idea of r andom testing proved often more effective than systematic sop histicatedtestingapproaches .
toproveourclaimsinthi spaper ourgoalistoshowunderwhatconditionscarfastoutperform srandom testingwithstrong statisticalsignificance.
.
.
adaptiverandomtesting adaptive random testing art is a controversial refinement of the baseline random testing where randomly selected data ar e dis5 evenly across the input data space .
in that ar t introduces a certain level of control over how input data is sel ected when compared with the baseline random testing.
a recent imp lementationof artforobject oriented languages isartoo wh ich we use as a competitive approach to carfast in our experiment s .
prior to our experiment artoo was evaluated on eight classes from the eiffelbase library and the sizes of these c lasses ranged from 779loc to 980loc.
recently arcuri and briand presented statistically significant results of experiment s that question the effectiveness of artoo with respect to bug detectio n for programs withseededfaults .
meyerpointedout inhisres ponse that the programs with seeded faults behave much differ ently from programs withrealfaults.
moreover arcuri andbriand measured the time to find the first fault as a testing metric which may not be a rigorous metric .
therefore we performed an exp eriment comparing random testing and artoo with a set of small to large programs with statement coverage as a testing metri c. in this paper we also address a research question of how effect ive artoo is in achieving higher coverage faster against compet itive approaches including random testing.
.
.
dart directed automated random testing dart is an approach that uses a concolic engine to generate test inputs that expl ore differentexecution pathsofaprogram .
intheoriginaldar talgorithm pathexplorationisconductedin depth first order dfo orbreath first order bfo of navigating the cfg of the aut.
we faithfully re implemented dart using dsc so that we can evaluate it in an unbiased fashion against carfast.
in the or iginal paper dart was previously evaluated only on three c applications whose sizes range from a dozen loc to 30kloc.
even though there are many implemented variations of dart e.g.
jcute klee pex dart has never been evaluated with strong statisticalsignificance on benchmark auts.
.
methodology our goal is to determine which approach achieves higher stat ement coverage faster.
given the complexity of the subject au ts it is not clear what is the highest coverage that can be achiev ed for these auts and given a largespace of input data itis not fea sible toruntheautsonallinputstoobtainthehigheststatementc overage.
theselimitationsdictatethemethodologyofourexper imental design specifically for choosing the threshold for the desi red test coverage whichis aut specific and ingeneral less than100 for a number of reasons not the least of which is the presence of u nreachable code in auts.
before conducting experiments we r un each benchmark aut against pairwise test input data and use the resulting achieved coverage as the coverage threshold for i t. each experiment run ishalted wheneither it hits the coverage thr eshold or the execution time limit hours is reached.
the time li mit is determined experimentally.
see section5.2for details.
we aligned our methodology with the guidelines for statisti cal tests to assess randomized algorithms in software engineer ing .
our goal is to collect highly representative samples of data when applying different approaches perform statistical tests on these samples and draw conclusions from these tests.
since our ex periments involve random selection of input data it is impo rtant to conduct the experiments multiple times to pick the averag e to avoid skewed results.
for each subject application we ran e ach experiment times with each approach on the same aut to consider collected data a good representative sample.
it means that for a total of auts we ran experiments for each of the fourapproaches resulting in a total of experiment runs.
to evaluate our hypotheses we ran statistical tests based o n the assumption that the population is normally distributed.
th e law of large numbers states that if the population sample is suffi ciently large between to samples then the central limit theo rem applies even if the population is not normally distributed page .
since we have sample runs for each aut for each configuration the central limit theorem applies and the ab ovementioned tests have statisticalsignificance.
experiments are carried out in amazon ec27virtual machine largeinstances with the following configuration .
gb ram ec2 compute units virtual cores with ec2 compute units each 35gbinstancestorage.
weseta24 hourtimelimitfor each experiment run.
so the estimated total runtime is hours.
with the cost of usd .
per large instance per hour as of september the estimated cost of this experi ment was around usd .
however we underestimated the cost of building testing and fixing the experiment environment i tself whichresulted ina total cost of around usd30 .
.
hypotheses we introduce the following null and alternative hypotheses to evaluate how close the means are for the es andis for control and treatment groups.
unless we specify otherwise carfast is a pplied to auts in the treatment group and other competitive approa ches are applied to auts in the control group.
we seek to evaluate t he followinghypotheses ata .
level of significance.
h0theprimarynullhypothesis isthatthereisnodifferencein the valuesoftestcoveragethatautscanachieveinagiventime interval.
h1analternative hypothesis to h0is that there is statisticallysignificant difference in the values of test coverage that auts canachieve ina given timeinterval.
once we test the null hypothesis h0 we are interested in the directionality of means of the results of control and treatment groups where sis eitheriore.
in particular the studies are designed toexamine the following null hypotheses h1 carfast versus random.
the effective null hypothesis is tha t carfast s rand s whilethe true null hypothesis is that carfast s rand s. conversely the alternative hypothesis is carfast s rand s. h2 carfast versus artoo.
the effective null hypothesis is that carfast s artoo s whilethe true null hypothesis is that carfast s artoo s. conversely the alternative hypothesis is carfast s artoo s. h3 carfast versus dart.
the effective null hypothesis is that carfast s dart s whilethe true null hypothesis is that carfast s dart s. conversely the alternative hypothesis is carfast s dart s. h4 artooversus random.
theeffective null hypothesis is that artoo s rand s while the truenull hypothesis is that artoo s rand s. conversely the alternative hypothesis is artoo s rand s. as of march10 2012the rationale behind the alternative hypotheses to h1 h2 and h3is that carfast achieves certain test coverage faster than o ther approaches.
the rationale behind the alternative hypothes is toh4 is that the random approach outperforms artoo as suggested b y arcuri and briand .
.
input test datarepository recall that instead of generating test data carfast select s test input data from existing repositories.
most nontrivial app lications haveenormousspacesoftestinputdataobjectsthatarecons tructed by combining values of different input parameters.
even tho ugh it is infeasible to create a test data repository that contains the entire input space itispossible tocreatecombinations ofvalues that will result in a smaller space of input data objects using combina torial design algorithms which are frequently used by testing pra ctitioners .
most prominent are algorithms for t wise combinatorial testing which requires every possible combinati on of interestingvaluesof tparametersbeincludedinsometestcaseinthe test suite .
pairwise testing is when t and every unique pair of values for each pair of input parameters is included i n at least one test case in the test suite.
to construct a test data repository for evaluating carfast we used the acts8tool previously known asfireeye togenerate data forourexperiments using pairwise testingfromthe range of input data that waschosen experimentally.
since pairwise selection significantly re duces the numberoftestinputdata weaddeduptoonemillioncombinat ions of test input data values usingan unbiased random selection .
.
subject auts given that we claim significant improvements in carfast when comparedwithcompetitiveapproaches itisimportanttose lectapplication benchmarks that are not biased nontrivial ande nable reproducibility of results among other things.
in general a b enchmarkisapointofreferencefromwhichmeasurementscanbema de in order to evaluate and predict the performance of hardware or software or both .
benchmarks are very important for eva luating program analysis and testing algorithms and tools .
.
.
challengeswith benchmarkapplications different benchmarks exist to evaluate different aspects s uch as how scalable program analysis and testing tools are how f ast they can reach high test coverage and how effective these to ols are in executing applications symbolically or concolicall y. currently a strong preference is towards selecting benchmark s that have much richer code complexity e.g.
nested if then else statements class structures and class hierarchies .
unfortunately complex benchmark applications are very costly t o develop and it is equally difficult to find real wor ld applications of wide variety of sizes and software metrics tha t can serve as unbiased benchmarks for evaluating program analys is and testingapproaches.
consider our situation where different test input data sele ction and generation approaches are evaluated to determine which approach enables users to achieve higher statement coverage f aster.
on one extreme real world applications of low complexit y with very few control flow statements are poor candidate benchma rks since most test input data generation approaches willperfo rm very well especially if auts take as input parameters only primi tive types.
on the other extreme it may take significant effort to adjust these approaches to work with a real world distributed application whose components are written in different languages and cl meth nbd mcc wmc .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
table1 subjectaut a characteristics.
cl classes noc meth methods nom nbd nested block depth mcc mccabe cyclomatic complexity wmc weighted methods per class.
the last three columns show average and maximum values as avg max.
run on different platforms.
in addition current limitatio ns of concolic engines e.g.
manipulating arrays different types make it very difficult to select nontrivial application benchmarks to satisfy these limitations.
ideally a large number of different ben chmark applications are required with different levels of code com plexity toappropriately evaluate testinput data generation tools .
one way to address the problem is to write benchmark applications that satisfy the requirements.
however writing benc hmark application from scratch is laborious not to mention that a significant bias and human error can be introduced .
in addition selecting commercial applications as benchmarks negatively affects reproducibility of results which is a cornerstone of the sc ientific method since commercial benchmarks cannot be easi ly shared among organizations and companies for legal reasons and trade secret protection.
for example accenture human res ource policy item states that source code constitutes confident ial information and other companies have similar policies.
fina lly in addition more than one benchmark is often required to deter mine thesensitivityofprogramanalysisandtestingapproaches basedon the variabilityofresults forapplications thathave diffe rent properties making ita verylaborious exercise.
ideally users should be able to easily generate benchmark a pplications withdesired properties that are similar to real world applications.
this idea has been already successfully used in testing relationaldatabase engines where complex structured querylanguage sql statements are generated using a random sql statement generator .
suppose that a claim is made that a relat ional databaseengineperformsbetteratcertainaspectsofsqlop timizationthan some other engine.
the best way toevaluate this cla im is to create complex sql statements as benchmarks for this eval uationinawaythatthesestatementsstresspropertiesthatar especific to these aspects of sql optimization.
since the meaning of sq l statementsdoesnotmatterforperformanceevaluation thi sgenerator creates semantically meaningless but syntactically co rrect sql statements thereby enabling users to automatically create low cost benchmarkswithreducedbias.
inaddition syntheticprogr amsand data have been usedwidelyincomputer visionandimage proce ssing .
.
.
randombenchmarkapplications we define a random program by construction.
everyprogram is an instance of the grammar of the language in which this progr am is written.
we use the grammar to generate branches of a parse tree for different production rules where each rule is assi gned theprobabilitywithwhichitisinstantiatedinaprogram.
star tingwith thetopproductionrulesofthegrammar eachnonterminal is recursively replaced with its corresponding production rule.
te rminals are replaced with randomly generated identifiers and values and they are used in expression with certain probability distri butions leadingtoasyntacticallycorrectprogram.
thisapproach i swidely used in natural language processing speech recognition i nformationretrieval andalsoingeneratingsqlstatementsf ortesting database engines .
.
.
subjectautsforexperimentation we generated twelve subject auts whose sizes range from loc to over one million loc using our program generator .
tominimizetheeffectofusingdifferentlibrariesanddata typeson our experimental design we allowed only integer data types and standard java language constructs.
each aut takes input p arameters this number is chosen experimentally.
table con tains characteristicsofthesubjectprograms withthefirstcolu mnshowing the names followed by other columns with different chara cteristics of these auts as specified in the caption.
we used th e generated programs without any tweak and they are availabl e at the website given infootnote .
.
threats to validity the main threat for our experimental design is the selection of subject auts and their characteristics.
due to limitations of concolicengines whichrequiresfinitenumberofvaluesforeac hinput we had tosynthesize the subject auts and these auts have hig h cyclomatic complexity which makes it difficult to choose va lues for input parameters to achieve high coverage faster.
the re sults may vary for auts that have very simple logic or different sou rce code structures.
the other threat to validity comes from evaluating approach es basedonstatementcoverage ratherthanusingsome faultdet ection metric.
in general even though a connection exists between statement coverage and fault detection capability the latter is a more robust metricsince itgoes intothe heartof amaingoal oftes ting bugdetection.
however existingapproaches for applying f aultdetection metric use generated mutants which are not always e quivalenttoapplications withbugsthatareintroducedbyprogr ammers .
finally statement coverage is also an important metr ic for stakeholders toobtainconfidencefromtestingapplication s andwe evaluate this important testingmetric.
finally a threat to validity is our method for selecting ran ges of input data.
sinceour autsaregenerated itisunclear whatr anges of input values should be chosen and how the number of combina tions of input values can be minimized effectively.
in our ex perimental design we used standard practices used by test engine ers at different fortune companies specifically to apply comb inatorial pairwise testing to create sufficiently diverse sets of input test data.
.
results in this section we provide and explain results of experimen ts and statisticalteststoaddress our hypotheses.
.
testing thenull hypothesis weusedanovatoevaluatethenullhypothesis h0thatthevariation in an experiment is no greater than that due to normal va riation of individuals characteristics and error in their mea surement.
the results of anova confirm that there are large differences between the approaches for coverage for both measures of execu tion time.
astheresultshows allp valuesarelessthan0.
.
he nce wereject the null hypothesis h0and accept the alternative hypothesis h1.
statisticalresultsforexecutiontimesareshownintable2 .
dart ranoutofmemoryforautsa6 a12andcarfastranoutofmemoryforauta12 over1milloc .basedont testsforpairedtw o sample for means for two tail distribution we reject hypot heses h1 h2for time measured as iterations and we reject hypotheses h3 h4for both measures of time i.e.
iterations and elapsed time .
we cansummarize these resultsas following.
when only iterations are counted carfast achieves higher statement coverage faster when compared with the random and artoo approaches for all auts with strong statistical significance.
carfast also outperforms dart for all auts but a5 since both approaches reach the desired coverage in one iterationfor a5.
whenonlyelapsedexecutiontimesarecounted random and artooachievehigherstatementcoveragefasterwhencompared with carfast for all auts with strong statistical sig nificance.
however when comparing carfast with dart carfastoutperformsdartforallautsbuta5forthesame reason mentioned above.
whenonlyiterationsarecounted therandomapproachachie ves higher statement coverage faster when compared with the artooapproach forallautswithstrongstatisticalsignificance.
when only elapsed execution times are counted the random approach achieves higher statement coverage faster when comparedwiththeartooapproachforallautswithstrong statisticalsignificance.
butwhenlowercoverageisspecifi ed forsmallprograms e.g.
a1 a2 a4anda5 therandomapproach does not outperform artoo.
.
investigationofcornercases we investigated the corner cases.
first we found that in a5 the maximum coverage is achieved inone iterationusin g all approaches.
since the obtained test coverage withdart is si gnificantlylowerwhencomparedwithotherapproaches werunst atistical tests with results for dart excluded so that we verify that the results of testinghypotheses still hold.
we chose i .e.
the minimum coverage of all approaches but dart as the coverage level for which we extracted execution times for these appro aches.
the results are consistent with our previous conclusion.
we had similar treatment for a1 a4 i.e.
we excluded the results t hat we obtainedfromdartfromdataanalysis andgotconsistentre sults.
second wefoundthattheexecutiontimeofcarfastincrease sat a much faster rate when compared to that of random and artoo approaches as program size increases.
we analyzed the execu tion timeofcarfastforeachbenchmarkaut andwefoundoutthatt he dumper mode of dsc takes the most of time for large applicatio ns when compared with other components of carfast.
for a11 it takes .
minutes on average per one iteration of an execution and it takes of entire carfast execution time.
for a12 ds c ran out of memory.
that is the dumper mode of dsc should be improved tomake carfastscalable tolargeprograms.
finally we found that the accumulated test coverage for car fast after running for hours is comparable with that of ran dom and artooapproaches for a1 a8.
as mentioned above it takes much longer for carfast to run on larger applications a9 a1 which results in much fewer iterations or out of memory wit hin 24hours and inachieving less testcoverage.acovappimedimeaniminimaxsdiemedemeaneminemaxsdecmincmaxcmed rand .
.
.
.
art .
.
.
.
dart .
.
cf1413.
.
.
.
rand11871299.
.
.
art17301903.
.
.
.
cf254314.
.
.
.
rand .
.
.
.
art .
.
.
.
dart .
.
.
.
cf .
.
.
.
.
rand14281607.
.
.
art17481963.
.
.
.
cf877906.
.
.
.
rand16.
.
.
.
.
art17.
.
.
.
.
dart .
.
.
cf .
.
.
rand .
.
.
art432438.
.
.
.
cf124133.
.
.
rand .
.
.
.
art .
.
.
.
dart .
.
.
.
cf .
.
.
.
.
rand14981636.
.
.
.
art22302629.
.
.
cf259266.
.
.
.
rand .
.
art .
.
dart .
.
cf .
.
rand .
.
.
.
art15561615.
.
.
.
cf459463.
.
.
.
rand .
.
.
art12091220.
.
.
cf405405.
.
.
rand .
.
.
.
art671684.
.
.
.
cf370380.
.
rand .
.
.
.
art105107.
.
.
.
.
cf100100.
.
.
.
rand .
.
.
.
art406398.
.
.
.
cf206210.
.
.
.
rand .
.
.
.
art466464.
.
.
.
cf241241.
.
.
.
rand .
.
.
.
art .
.
.
.
cf2626.
.
.
.
rand16211620.
.
.
art21062114.
.
.
.
rand10601067.
.
.
.
art15041488.
.
.
.
table results of experiments on subject applications und er test auts a1 a12 with approaches app carfast cf random rand artoo art and dart.
columns cmin cmax andcmedgive the minimum maximum and median values of statement coverage afterrunningtheautsfor24hours.
wedefinethemin imumvalueof cminasthetargetcoverage cov .
wethendetermine howlongeachapproachtakestoreachthistarget.
execution timesaremeasuredinthenumberofiterations i andelapsedtime e inseconds .
for each we reportthemedian mean min max.
a ndthestandarddeviation sd .
autsa1 a5reportmeasurements with and without including the dart approach but auts a6 a1 do not include the dart approach.
for details please see sections .2and .
.
.
our interpretation ofresults we can summarize and interpret the results of our experiment s as follows.
.
westronglysuggestthatcarfasthashighpotentialinach ieving higher statement coverage faster and becoming practica l especially if its execution overhead per iteration can be fu rther reduced.
we expect toreduce the overhead inthe future since we found the bottlenecks of carfast from our experiments.
.
whenitcomes tocomparing therandom approach withartoo the random approach is still better when higher statement coverage is targeted.
artoo performs as good as the randomapproachonlywhenlowerstatementcoverageistargeted.
we suggest that itis likelythat results depend on cer taincharacteristicsoftheauts findingwhichisasubjecto f future work.
.
related work our approach isa testcase prioritizationtechnique choos ing an ordering of some existing test suite in order to increase the likelihood of revealing faults earlier.
elbaum et.
al.
surv eyed several approaches that effectively prioritize test cases in regression testing.
these techniques use greedy algorithm to comp ute anorderthatachieveshighercoveragesoonerorhigherfaul tdetectionrate.
thus testcoverageorfaultdetectionrateofeac htestcase mustbeknown.
inthecontextofregressiontesting eachtes tcase s coverage or fault detection rate on previous versions of the aut is used to predict their future performance.
our approach does not require prior knowledge of test cases and thus it is not restr icted in the context of regressiontesting.
dynamic symbolic or concolic execution engines such as dart generate test inputs that explore different execu tion paths of a program.
in early work the exploration strategy i s usuallydepth first or breath first whichis the basis for many t estcase generation techniques including ours.
majumdar et.
al.
interleave random testing and concoli c exploration to improve test coverage.
their approach start s with random testing changes toconcolicexplorationwhenrando mtestingfailstoincrease coverage andchanges backtorandom as soon assomecoverage is gained.
in contrast carfast uses a systematic approach based on a static program analysis based branch co veragegainpredictor andweevaluatedcarfastwithstatistic alsignificance ona large number of subject applications.
concolic tools use different search strategies to decide ho w to pick branches where constrains are negated.
xie et.
al.
use a branch s distance to the target path as the fitness function i n their work.
here distance means the number of conditional control flow transfers between a branch and the target path.
branches nea r the target path are more likely to be picked for negation.
simila rly burnimandsenpickabranchwhenitsdistancetosomeuncover ed path is small .
to increase coverage sage by godefr oid et al.
tries to negate not one but as many constraints in a pa th condition as possible.
our approach differs from search based approaches in the fit ness function to the best of our knowledge carfast is the fir st tool that defines and uses a static program analysis based cov erage gain predictor to guide path exploration.
however genetic based approaches are not shown to be scalable and they usually wor k on generating test data for expressions with less than bo olean variables.
oursisthefirstapproachthatworksforlarge sc aleapplications itis scalable andit does not require any machine learningalgorithms whichare usuallycomputationally intensive.
inthe future once scalablegenetic algorithmsaredeveloped forge nerating test input data for achieving higher coverage faster we wil l compare carfastwiththese algorithms.
.
conclusion andfuture work wecreatedanovelfullyautomaticapproachfor achievinghigher statementcoverage faster carfast bycombining random testingwithstaticprogramanalysis concolicexecution andc onstraintbased input data selection.
we implemented carfast and appl ied it to twelve java applications whose sizes range from loc to one million loc.
we compared carfast pure random adaptive random anddirectedautomatedrandomtesting dart again st one another.
the results show with strong statistical signi ficance that when execution time is measured in terms of the number of runs of the application on different input test data carfas t largely outperforms the evaluated competitive approaches with mos t subject applications.
ourexperimental resultsare promising and thereare sever al areas that will improve our work.
first we plan to adapt carfas t to other test coverage metrics such as branch coverage and b asic blockcoverage tostudyifcarfastcangeneralize toother m etrics.
next weplantoinvestigatetherelationshipbetweenhighc overage and fault detection abilities with carfast.
since there is a body of researchthatshows astrongcorrelation we expect that using carfast increases the probability of finding faul ts.
finally we plan toimprove the implementation of carfast to re duce the total elapsed time.
we identified several bottlenecks fr om our experiments i.e.
in dsc s current dumper mode.
with more e ngineering on the bottlenecks we expect carfast to run faste r and outperform random techniques with respect to both iteratio n and elapsed time.
.