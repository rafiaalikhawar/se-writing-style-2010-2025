preffinder getting the right preference in configurable software systems dongpu jin dept.
of comp.
sci.
eng.
university of nebraska lincoln lincoln ne usa djin cse.unl.edumyra b. cohen dept.
of comp.
sci.
eng.
university of nebraska lincoln lincoln ne usa myra cse.unl.eduxiao qu industrial software systems abb corporate research raleigh nc usa xiao.qu us.abb.com brian robinson abb inc. raleigh nc usa brian.p.robinson us.abb.com abstract highly con gurable software such as web browsers databases or o ce applications have a large number of preferences that the user can customize but documentation of them may be scarce or distributed.
a user tester or service technician may have to search through hundreds or thousands of choices in multiple documents when trying to identify which preference will modify a particular system behavior.
in this paper we present preffinder a natural language framework that nds and changes user preferences.
it is tied into an application s preference system and static documentation.
we have instantiated preffinder as a plugin on two open source applications and as a stand alone gui for an industrial application.
preffinder nds the correct answer between of the time on more than queries.
when compared to asking questions on a help forum or through the company s service center we can potentially save days or even weeks of time.
categories and subject descriptors d. .
testing and debugging general terms veri cation keywords con gurable systems testing debugging .
introduction many software systems today are highly con gurable.
users can customize the program s behavior by choosing settings for a large number of preferences.
preferences control which permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
ase september vasteras sweden.
copyright acm ... .
.
are used or excluded during the program execution and most systems support the selection of these at both compile time and runtime.
during development testing maintenance and when providing end user technical support engineers need to manipulate a system s preferences to mimic user behavior and ensure that correct execution occurs under a wide range of user pro les.
most large real systems provide multiple ways to access and modify preferences .
on the user interface there may be a preference menu that is easily accessible containing a core set of preferences.
for advanced users who want to manipulate the less common options or who need to automate the con guration process changing preferences can be achieved by modifying values in preference les or through interaction with a runtime api which connects to the active preference database .
despite the exibility and availability of con guring and manipulating how a program runs it is often non trivial to determine which preference is tied to a speci c behavior or to a speci c element of code .
for instance if a developer knows that a preference in the firefox browser found on a menu is called always show the tab bar he or she may not be able to quickly determine what the real preference name is in the preference database or les i.e.
browser.tabs.autohide .
and if a user wants to change the tab bar behavior they may spend a long time searching through menus to nd out where such an option can be modi ed.
in recent work wiklund et al.
reported that the majority of the impediments for novice testers were in con guring the testing tools to use the correct parameters and environment .
rabkin and katz highlight the lack of documentation that exists for preferences including knowing the valid value domains for each of the preference options .
making this worse we have observed in recent work that the locations for manipulating con gurations within a system are often distributed and only a limited number can be manipulated by the menu e.g.
only of firefox preferences are accessible from the menu .
we see similar trends in industrial systems such as those studied at abb.
to address this issue rabkin and katz developed a static analysis technique that reverse engineers the con guration options from code either for con guring systems or for diagnosing errors .
zhang and ernst have developed another analysis to identify which con guration option causes a fail151 ure or has caused the system behavior to change in an undesirable way due to evolution but this is limited to situations where the di ering behaviors are known and can be demonstrated.
both of these approaches identify preferences at the source code level but it is non trivial to map them back to the preference database names and or to the menu items .
furthermore the use of static analysis means that these techniques are programming language dependent and many of the highly con gurable systems like firefox are written in multiple programming languages with preference code distributed throughout .
some programs provide built in search utilities tied into their documentation as in an abb system or to the runtime preference database as in firefox but these primarily use keyword searches forcing the user to know exactly what they are looking for.
consider a preference found in firefox browser.download.downloaddir .
it determines the default download directory when users save a le.
there is no menu setting for this option but firefox provides a utility about config to look for this.
if the user happens to search using the keyword download they will nd this option and can then modify its settings.
if instead they search for directory they will not because the keyword is dir .
browsing through all preferences in about config is not useful with over in the current versions.
and if the user is working on a system like libreo ce they have a hierarchical directory to search that has over choices .
instead there is the need for a more natural way to interact and nd preferences in highly con gurable systems.
in this paper we present a natural language processing nlp based framework called preffinder .
in preffinder a query is an input in natural language.
preffinder rst parses both the preferences and the user query informed by dictionaries and lexical databases.
the queries and preferences are then matched ranked and returned to the user.
we can tie this into the runtime apis of the applications to provide descriptions of the returned preferences and to allow directly modi cation of the chosen preference.
preffinder has been instantiated on two open source and one industrial application.
in a case study on more than real queries from users and developers across these three systems we show that preffinder is e ective and has potential to save time over existing techniques.
the contributions of this work are .
preffinder an extensible framework to provide natural language interactive querying of preferences .
an implementation for three di erent applications .
a case study on more than queries demonstrating its potential usefulness the rest of this paper is laid out as follows.
in the next section we provide a motivating example.
we then present preffinder in section .
in sections and we evaluate and show the results of our case study.
in section we describe related work.
we end with our conclusions and discuss future work in section .
.
motivation we motivate our research with two open source applications firefox and libreo ce using data from .
firefox is a web browser that contains approximately million linesof code.
like many modern applications it is developed using various programming languages including c c javascript java .
and assembly .
.
in addition it uses xul a markup language for interface functionality and this is where some preference options are manipulated.
it is highly con gurable with preferences in the cited version ubuntu firefox version .0a1 .
in addition the browser can be extended by installing third party extensions which can introduce an arbitrary number of additional preferences.
libreo ce is an o ce productivity suite of tools that includes a word processing spreadsheet and presentation module.
it is written in c java and uses additional scripting languages such as python.
the number of preferences associated just with the writer application is .
there are similar numbers of preference for each of the other applications in addition to ones common to all applications .
since both of these applications are written in multiple languages this presents challenges for analyses targeted at one language such as java i.e.
.
in systems like these there are two common approaches for customizing preferences.
one is to make changes via an option or preference menu by clicking buttons selecting check boxes and checking radio buttons etc.
this approach is intuitive to use for novice users but as mentioned the option menu only contains the most commonly used set of preferences and it is only a small subset.
in firefox if one wants the tabs to appear above the url bar rather than below there is an option browser.tabs.ontop which can be set to true.
but this option is not available in the preferences menu.
in fact the removal of this from the user menu is the subject of a post and user complaint on the firefox forum.
the second approach is to modify preferences directly via the preference les and or a preference utility.
firefox maintains its preferences for persistence via a set of preference les at various locations and during runtime via a hash table in memory .
at startup it reads these les and stores the contents in memory.
firefox has by default such les .
libreo ce maintains a directory of preferences for external storage that it reads at startup as well over of them .
in libreo ce for instance there are many directories such as so ce.cfg with les such as menubar.xml that can be modi ed to determine which buttons appear on which toolbar.
both applications provide runtime apis which can examine the internal available preferences .
firefox s about config utility uses a regular expression keyword search but this requires an exact match.
for instance if the user types tabs ortabfor the previous preference they will nd this option.
however if they type browsers ortabbing they will not nd it.
libreo ce does not have an about con g utility.
it has a le called registrymodi cations.xcu which is di cult to parse and understand.
most users of libreo ce will probably use menu options to change their preferences which may not scale for larger maintenance tasks.
in each of these scenarios the preferences are represented as mid level variable names i.e.
they are neither code nor natural language and there is no direct traceability between the options menu and these names or down to the code.
in the work of rabkin and katz and zhang and ernst preferences names are found and returned 152nlp algorithms lexical db synonyms antonyms relations topics ... abbreviations acronyms spelling prefixes suffixes stop words dictionaries default abbreviations acronyms spelling stop words ...... dynamic preferences api application interface static documentation command line gui domain knowledge !
!!!!!!!!!!
!
user preference system figure preffinder framework architecture from the source code.
but these may or may not match the names found in the intermediate preference les where the users manipulate preferences directly .
therefore while useful and a possible complement to our system they will not provide the information we seek.
before one can automate any sort of con guration manipulation or allow technical support to help users change a con guration they must rst translate from the intended behavior to these preference names and then nd a way to modify them.
finally con guration spaces are rapidly changing.
we need to be able to easily re evaluate questions when a version is updated.
for instance the example discussed in the introduction and the work of zhang and ernst highlight the changing con guration space and the need to nd options over and over again.
in the next section we present preffinder which will overcome most of these challenges.
.
preffinder figure shows an overview of the preffinder framework.
on the left of this gure we see a customizable application interface where interaction with the user and the application itself takes place.
on the right we see domain knowledge that allows information to be added to our databases.
in the center lies the core component of preffinder.
this contains natural language processing algorithms dictionaries and lexical databases.
it can be used on its own or packaged into a plugin or gui application or run at the command line which permits automation of multiple queries at a time.
in preffinder the users enter a short description or question in english about what features or functionality of the system they want to lookup customize .
they also specify a number of results to display and preffinder will return a list of ranked preferences with a value showing the score and a description of each result if available.
users may enter arbitrary english sentences with di erent punctuation numbers mixed case letters and may use di erent forms of the language such as present participle e.g.
closing and plural e.g.
tabs .
to instantiate the framework preference extraction is rst performed to build the preference system.
next the core component runs several steps to identify the correct preferences that best match the query splitting parsing matching and ranking.
finally the documentation step connects preference descriptions to corresponding preferences returned in the results.
optionally for instantiations that use a dy namic api to extract the preference system preffinder is able to also update the preference via its gui.
let us take firefox as a running example.
suppose the user types a query firefox .
doesn t warn me when closing multiple tabs any more.
.
as reported online there are four di erent preferences that a user can set to modify this browser.tabs.warnoncloseothertabs browser.tabs.warnon close browser.showquitwarning and browser.warnonquit.
preffinder is expected to nd at least one of them.
.
preference extraction the rst step is preference extraction from the application.
to extract preferences preffinder can utilize di erent types of information such as a static analysis like that of rabkin and katz or it can also use static artifacts such as a user manual.
we can also use apis to extract the preferences dynamically.
in our prior work we used the runtime apis to automatically extract preferences from two running applications databases .
for one of the systems there are apis that directly return a set of all the preferences.
for the other system we traversed the hierarchical structure in a depth rst search fashion.
we can also combine static and dynamic methods to get a more complete view of the preferences.
in the running example we would extract the preferences from firefox using the dynamic api and obtain approximately preferences in our list.
.
splitting once we have the preferences we normalize them into bags of words.
preffinder begins by taking in the the system preferences and parsing splitting them into sets of keywords see for more details of the parsing algorithms we used .
our identi er splitting algorithms are based on the work of enslen et al.
.
preference names are usually represented as arbitrary strings such as our running example from firefox browser.tabs.warnoncloseothertabs ororg.eclipse.jdt.core.
compiler.codegen.targetplatform as in eclipse and org.openo ce.o ce.recovery recoverylist as in libreo ce.
as in a program variable a preference name must be a sequence of characters without any white space.
soft words individual dictionary words within a preference name are separated byword markers such as a period .
underscore dash backslash or camel case letters .
after splitting the words the remaining identi ers are called hard words .
once the initial separation via word markers is complete we next use a camel case splitting algorithm.
we found that this 153often does not provide an accurate split i.e.
some words are still joined or are split too much so we use an additional same case splitting algorithm and a backward greedy algorithm based on the work of enslen et al.
.
.
parsing to incorporate meaningful code related words during parsing we compiled a dictionary based on the one used by hill et al.
which is derived from ispell .
it is a list of computer science abbreviations and acronyms such as sys and url .
we also adopt a pre x list and a su x list from the work of enslen et al.
to identify commonly used pre xes and su xes such as uni and ibility .
our dictionaries are available online see section .
once the preferences are split we can parse them along with the user queries to extract a set of relevant keywords .
since the queries are to be run against identi er like names we have adopted a set of rules that limit what keywords are extracted.
the parser removes words with leading numbers special symbols and punctuation and converts all of the letters to lowercase.
after this step the user query in our example becomes refox doesnt warn me when closing multiple tabs any more .
some words such as doesnt me when any more do not provide domain relevant information in our context.
these words are commonly referred to as stop words .
the parser lters stop words prior to further processing using a stop words list.
at this step as shown on the back end of figure a domain speci c dictionary can be plugged in.
in our example several words are added to the stop word list such as refox libreo ce openo ce org and o ce which are tied to speci c applications and carry little discriminating power when it comes to con gurations.
after this the above query becomes warn closing multiple tabs which only contains the keywords that carry the core information.
the user query has been shortened without losing the core information however the query may still fail to match if the user expresses the same concept using words in di erent forms or uses a di erent word with similar meaning.
preference names are often made up of root words for example close rather than closing .
in another example a user may useshutdown to mean close something that an exact match will not nd.
to alleviate these issues preffinder integrates wordnet a lexical database for english that converts user query and preference words to root forms and expands the keywords in a user query with their synonyms as shown in the core component of figure .
in our running example wordnet converts the word closing in the query to its root form close and expands it with synonyms such as shutdown shutting closedown closing closure completion .
as before a domain speci c database can be added.
figure shows additional lexical information in grey i.e.
antonyms relations and topics that are available in wordnet which we will incorporate into preffinder in future work.
.
matching and ranking once we have parsed both the preferences and the query the next step is to suggest preferences that are most relevant to the user query.
to compute the similarity for each query preference pair we adopt a fast tf idf algorithm a variant of the classic information retrieval weighting scheme term frequency inverse document frequency tf idf .a user query q contains a bag of words and each word in qis aterm t .
each preference name is considered a small document d that also contains a bag of words.
a preference system that consists of npreferences forms a collection c of size n.term frequency tft d is de ned as the number of occurrences of a term tin the document d. the value of tft dequals zero if tis not in d.document frequency d ft is de ned as the number of documents in the collection that contains the term t. the value of d ftequals zero if tdoes not exist in any of the documents in the collection.
the inverse document frequency id ft is de ned by the equation id ft logn d ft where d ftis the document frequency of term tand nis the number of documents in the collection.
note that if a term exists in many documents it often carries less discriminating power d ftis large and thus makes id ftsmall .
hence id ft can be used to reduce the e ect of terms that appear in too many documents.
the weight or tf idf for a term in dis de ned by the equation tf id ft d tft d id ft which is the product of the term frequency and the inverse document frequency for that item the weight equals zero if the item only occurs in dbut not q .
as can be seen a term indwould have a heavier weight if it occurs many times in a few documents both tft dandid ftare large .
on top of the tf idf weight we impose an additional scale factor which reduces the the e ect of synonyms by scaling down their weight.
our matching favors the term that has an exact match in the original user query.
we experimented with a series of scale factors on the firefox preference set and found that .
works best for a synonym match .
thus the overall similarity score for a query document pair is computed as the sum of tf idf weights for all the items that occur in both the query qand the document dby the following equation score q d x t2qtf id ft d scale where scale equals to .
for synonyms and otherwise.
table ranking terms in the correct preference for the example query item in qtf df idf tf idf scale weight warn .
.
.
closing .
.
.
multiple tabs .
.
.
in the fast tf idf variant we rst build a posting list for each term tin the query qby collecting relevant preferences from the entire preference space.
a posting list is a list of preferences that match t either an exact match or a synonym match .
posting lists directly associate relevant preferences to query terms which avoids repeated examination of the entire preference space.
the length of a posting list is the number of preferences that contains t d ft .
we then calculate scores for each preference as shown in algorithm .
each query term calculates its own weight outer loop which is added to the score of every preference in its 154algorithm pseudocode of core algorithm that calculates preference scores using fast tf idf input user query q posting lists output a collection c0of preferences with score for each tinqdo calculate id ft for each dint s posting list do d.score id ft tft d scale end for end for c0 preferences in posting lists return c0 posting list inner loop .
the algorithm returns a collection of preferences with a score.
consider the running example where the bag of words after parsing without the synonyms are fwarn closing multiple tabsg for the query qandfbrowser tabs warn on close othergis the corresponding preference d browser.tabs.
warnoncloseothertabs .
there are total preferences relevant to q n .
table shows the statistics of each term in q the query .
the overall score is the sum of the weights of all the terms .
note that the term close indis a root form of term closing inq and thus is considered as an exact match with a scaling factor of .
the term multiple fails to match any word in dand contributes zero weight.
after assigning each preference a similarity score for a given query all preferences are ranked in decreasing order with respect to the score.
the top npreferences nis a parameter speci ed by the user via preffinder front end ui are sent to the front end and displayed.
.
documentation and update this part of preffinder is optional.
we can use external documentation such as that found on the firefox user website and connect this to our found preferences providing potentially useful information for the user.
in our example we would get a brief description if available for each found preference from the documentation written by the user community .
in the running example there is no documentation for the rst solution so this will be null but the second solution browser.tabs.warnonclose has the following partially eluded text which we append in the preffinder result list warn when closing window if more than one tab open true default the browser will prompt for con rmation when closing the browser ..... this can be changed via tools !
options !tabs!warn ... .
if we are connected to the preference database we can now change the value directly in memory which will modify the external system and the preference les and be re ected in the current state of the application.
this works in the same way the about config works and we have implemented this in our firefox and libreo ce versions of preffinder.
.
case study we perform a case study aimed at evaluating preffinder that asks three research questions.
supporting data on the queries used and the associated results can be found on our website.
rq1 what e ort customization is required to instantiate preffinder for di erent systems ?
rq2 how e ective and e cient is preffinder at nding the correct preference?
rq3 how does preffinder compare with existing approaches?
the rst question is used to qualitatively evaluate the generality and applicability of our framework across di erent types of con gurable systems.
the second question evaluates the quality of preffinder s search mechanism using both accuracy match success and e ciency time .
the last question examines the current state of the art for two of our systems and evaluate these against the preffinder queries.
.
preffinder versions we built preffinder versions using two open source applications from di erent domains firefox and libreo ce and selected an industrial application developed at abb to avoid open source bias.
all systems are large highly con gurable and have a dedicated user base.
in addition we have shown that they all have complex con guration mechanisms .
basic information about each application version number and number of preferences extracted for use in preffinder is shown in table .
table application version and preferences application version no.
of preferences firefox .
.
libreo ce .
abb s all three applications manage their preference database slightly di erently and provide di erent con guration interfaces for the users.
we describe each system next as well as the the use case of how we expect someone will interact with the given system.
firefox web browser .
for this study we chose firefox version v18.
.
running on ubuntu .
.
.
we note that preffinder itself is not operating system or version speci c and we have installed it on di erent versions and platforms of firefox but all of the results we present are from the speci ed version.
firefox has a large preference system that is available dynamically via an api.
although it is not the complete set of preferences this is the same set of preferences that would appear in the about config utility.
we use the mozilla xpcom api to extract the existing preferences at runtime.
we also included additional descriptive information gathered by merging our results to the documentation written by the user community and allow the user to change the found preference value directly from within preffinder.
the use case for this query is similar to the use of about config .
libreo ce application .
we used libreo ce version v4.
for this study.
libreo ce has over preferences in total contained in a hierarchical database based on a speci c xml schema .
we expect a di erent use case in this type of system given the complexity of the preference database and assume that the preference modi cation will be done via the user interface.
for this version we model a person who is trying to change the system behavior using the menu.
to extract the preferences we used the api which 155connects to the dynamic database as detailed in the online user guide .
abb sindustrial application .
our last application is an industrial software system developed at abb abb s .
all of its important user preferences can be accessed and modi ed in preference les.
the de nition and description of these preferences are available in two online documents denoted as abb d1andabb d2.
in the documentation real preference names are used as they appear in the preference les.
there are preferences de ned in abb d1 and in abb d2.
the system provides a help keyword match utility but only for preferences in abb d1 similar toabout config except that the user can type in multiple keywords at a time.
in fact they can type in the entire query.
the keyword match will do an exact match on all entered keywords therefore any extraneous or incorrect words will result in a failed search.
for this use case we assume that the person the search is a technical support engineer who is trying to help customers who have called in on the help line.
it can be time consuming to determine what the user has done or is trying to do to the system preference les therefore we build this version of preffinder to see if it will help in this scenario.
.
obtaining and running user queries for each of our systems we obtained real user queries.
for firefox and libreo ce we went to online user forums see .
we searched the forums using the keywords preference andcon guration and selected the rst for firefox and rst for libreo ce that had a solution or solutions to serve as an oracle.
for the queries obtained from the firefox forums the oracle is simple to check since in most cases the actual preference name is returned.
in the libreo ce forum this is not as straight forward.
therefore we restricted our queries to ones in which a series of menu steps are provided which matches our intended use case .
we then performed the example steps identi ed which preference changed in the preference database and then veri ed this by ensuring that when we change that preference directly in the system that particular menu item changes as well.
this preference then serves as our oracle.
for abb swe were unable to access the internal support log so we asked several independent system engineers to write queries that they thought a user would ask based on their experience.
we only brie y described preffinder to them without explaining the search mechanisms used in the tool.
we obtained queries of which queries are from the preferences in abb d1and queries are from preferences in abb d2.
for each query they also provided answers which serve as our evaluation oracles.
we then used preffinder to run each of the queries on each system.
we utilize command line versions and run the queries times each to get timing information.
we also compared a sample of results from the command line and gui versions to validate that we are reporting the correct results.
table shows a few example queries from the firefox and libreo ce forums.
we provide the full set of open source queries on our website.
.
metrics to answer rq1 we qualitatively assess if it is feasible to build multiple versions of the system and ask what is involved in customizing each system.
to answer rq2 werun all queries and evaluate whether the correct answer is found and at which rank for e ectiveness .
we also report the preffinder execution time averaged over executions and a break even be time for our open source systems for e ciency described below.
the execution time is the time that a query takes to run.
the evaluation time for the returned result however is harder to measure.
once a person has the preference result list they must determine which one is correct.
since we cannot accurately predict without bias the time it would take someone to evaluate each preference returned by preffinder we report a metric called the break even time.
this metric tells us how long one would need to spend per answer in preffinder to make the tool no better than an existing approach in this case a user forum .
we use the oracle pages from the user forums and make the assumption that this is the rst time this question was asked i.e.
the question cannot be obtained by a simple web query .
since we obtained our queries from the forums we can examine the time stamps from when the question was initially asked and when it was rst answered correctly.
we then use this time as the time it takes to answer this as a new question on the forum.
to then calculate the break even time we ignore the execution runtime but report it since it is less than a minute in all cases.
we then calculate it as be forumtime rank.
if for instance an answer is found in the 3rd rank position and the forum takes minutes it means that as long as a user can evaluate each result returned by preffinder in less than minutes on average it will perform better.
to answer rq3 we compared the firefox queries with theabout config utility and the abb d1queries with its search utility.
for this we had to split our queries into its constituent keywords and try each one individually.
for the abb d1system since its utility can search on multiple keywords at once we try the original query and then we try all keywords together key all followed by each one individually.
the success rate and ranking of these results are the metrics that we compare with preffinder.
.
threats to validity the rst threat to validity is that of generalization.
we have built preffinder on three di erent systems with di erent preference mechanisms and one is industrial so we believe that this is representative of many real systems.
we had to select the queries from the forums but we used a systematic approach and did not try the queries on preffinder before selecting them.
the queries obtained from abb may have some bias since the engineers unlike in tech support in the real use case are familiar with the system and the types of questions users ask.
but we believe they are still representative and may in fact bias the results towards the existing approach.
finally we may have mistakes in our data but we have cross validated our questions using both a manual and the command line version.
we are also making our open source data available on line.
.
results in this section we describe our results for each question.
.
rq1 different instances of preffinder figure shows a screenshot for one of our versions of preffinder a plugin for firefox.
on the screen you can see the query the result for the rst answers including 156table sample queries from the user forums query preference answer firefox how to change permanently the search engine?
keyword.url is there an about con g entry to toggle search example.com for selected text automatically switching to the tab it opens?
browser.search.context.loadinbackground libreo ce do you have a way to accept or translate excel macros?
org.openo ce.o ce.common security scripting macrosecuritylevel default font color on button in calc org.openo ce.o ce.ui colorscheme colorschemes org.openo ce.o ce.ui colorscheme fontcolor color how do i disable paste via middle mouse button?
org.openo ce.o ce.common view dialog middlemousebutton figure preffinder prototype user interface the ranking score the current value of that preference and a description when it is available.
in this case our query is the example query used in section .
both the rst and second answers match our oracle there were solutions .
although we have no description for the rst preference we do for the second which will make the user s choice easier.
if the user wants to change the value for this option they can simply click on that row and it will directly modify the running application preference database or les.
for firefox we were able to create a working version that can interface with the dynamic con gurations to match our use case and provide both documentation and an update facility.
since this was our rst instantiation and the easiest use case we did not encounter any problems.
to customize this for firefox i.e.
interfacing with the dynamic api and documentation took about a day of programming time.
for libreo ce we also implemented a plugin.
we did not change the core system but only rewrote the interface to the application.
we used the dynamic api to access and modify preferences.
this took us a bit longer approximately two days since the documentation on the api was not as detailed.
we re used the entire nlp core of preffinder without modi cation.
in our initial version we used the entire preference dump for libreo ce but the runtime was a bit slower than firefox.
we also found that the returned preferences were hard to understand.
since many of the preferences are not available via the menu our expected use case we restricted our preferences to only thosethat are managed by the menu system which is a subset of the full preference space.
to nd the proper subset without introducing bias we rst tried all of the menu options in the preferences menu of libreo ce.
we observed which groups of preferences were being modi ed in the resulting database and then tagged these groups.
from this we were able to limit our preferences to a set of categories with preferences the list of these preferences can be found on our website .
this reduced the search space and helped us to manage our oracle evaluation since that required manual steps as well.
for abb swe did not have a way to attach to the runtime database because this is a production system.
instead we provided a standalone version with a simple gui.
the only customization of the preffinder framework was the gui which took on the order of a few hours to create.
since we had to use the static preferences we obtained from the online documentation system these had to be translated into a database that preffinder could understand.
we did this manually and it took about hours to organize and translate.
when we started to run queries on the system we found that there were some common words that the system domain uses as abbreviations which were not in our default general dictionaries.
although our searches were successful adding these abb speci c abbreviations increased our accuracy therefore we compiled a list and added this custom set of abbreviations to the database.
this iteration added about another hour of development time.
summary for rq1.
we are able to successfully instantiate and run preffinder using the same core for all three systems albeit with some modi cations and programming effort.
the primary customization involved programming the connection to the con guration apis or modeling the con gurations from a static location.
other minor customizations were required to re ne the quality of the results such as using only the required subset of preferences for libreo ce and adding custom database entries for abb.
.
rq2 effectiveness of preffinder the e ectiveness of preffinder is measured by the search success rate i.e.
accuracy and the execution time.
accuracy .
the accuracy is shown in table .
in this table we see the number of queries run the number of queries that found the correct answer and the success rate as a percentage.
in the last column we see the range of the ranks where the answer is returned.
if the correct answer is returned as the rst row of the result we mark it as a .
if it is the 10th row it is a etc.
when there are multiple preferences 157speci ed as an evaluation oracle we only consider the rst one that preffinder can nd.
for success rate we see a range between systems with abb having the highest and libreo ce the lowest success rate.
to investigate the ranking distribution of all results excluding the queries that fail data is presented in figure and table .
in both the table and the graph we break out our results showing those in the top those found in position etc.
as we can see of the queries that return correct results appear in the top rows of the returned results and are returned within the top .
we believe that using additional lexical information may help to improve these results.
number of queries ranking of results firefox libreoffice abbs figure ranking distribution for firefox libreofce and abb s execution time .
execution time is the clock time to run preffinder once a query is input.
we run and user queries for firefox libreo ce and abb srespectively.
we run this times to obtain averages.
the running time is shown in table .
we report the total time to run all questions and the standard deviation std .
since we see little variance we only show a single run for the time in our next study.
for firefox it takes on average less than a second to return a result.
for libreo ce it takes about seconds and in abb sit takes about one half of a second per query.
we next gathered the time that it took to get answers to individual queries on the user forum and calculated the break even time.
table shows the rst queries for firefox the rest are on our website and table shows all the queries for libreo ce.
when a result was not found we left the query in the table shown as fail and put a dash for break even.
a few of the firefox queries were answered by a faq which does not have a time stamp so we also use dashes for these cases.
in firefox the forum response time ranges from minutes to over months and its average is nearly days we only show of them in the table but the results reported are based on all queries excluding failed ones or the ones that do not have time stamp information .
if we suppose it takes about minute on average for a user to browse each result returned by preffinder until he or she nds the correct preference then an estimated time that the user spends to get the right answer from typing in a query will be a sum of preffinder execution time and the ranking position times minute.
for example if a preference ranked at the 10th place the lookup time would be about seconds the execution time is negligible .
based on this assumption theaverage lookup time for preffinder is only about half an hour which is less than of the average forum response time.
and the forum response time is as high as times large as the preffinder lookup time.
the break even times for per answer evaluation are from a couple of seconds in of the questions to about .
months and the average time is almost days.
more than of the break even time exceeds minutes.
we believe that this is arti cially high for the real time it would take a user to do this work.
in libreo ce the forum response time ranges from .
hours to a couple of days and the average response time is more than hours.
with the same minute browsing time assumption the average lookup time for preffinder is about hours which is about of the online forum response time.
the break even times for per answer evaluation are from a second only one case to over hours and the average time is about .
hours.
almost of the break even time exceeds minutes.
table ranking results for firefox libreo ce and abb suser queries application no.
no.
success rank queries found rate range firefox .
libreo ce .
abb s .
table ranking distribution for firefox libreofce and abb s rank range firefox libreo ce abb s table preffinder execution time in seconds for runs on an ubuntu .
.
machine with an intel core i7 2760qm cpu and .8g memory no.
of avg.
tot.
std avg.
per queries time query firefox .
.
.
libreo .
.
.
.
abb s .
.
.
summary for rq2.
preffinder is e ective at nding user preferences and runs in less than a minute on our queries.
when compared with the time it takes to get a new response on a user forum as long as the user can evaluate what has been returned within minutes per result on average it is as fast or in many cases faster than waiting for a response.
.
rq3 comparison existing techniques for our last research question we evaluated firefox and abb swith their existing keyword match mechanisms.
two sample comparison results are shown in table .
for each query we see the individual keywords in bold and their results a fail means that the correct preference was not found .
we collate this and show overall results in table .
the rst row shows the average result ranking for both tools excluding failed queries.
as we see firefox nds the result 158table break even timing results for firefox rst queries query rank exec forum break even query rank exec forum break even sec min min sec min min fail .
fail .
.
.
.
.
fail .
.
.
fail .
fail .
.
.
fail .
.
.
.
.
.
.
.
.
.
.
.
.
fail .
.
.
.
.
.
.
.
.
.
fail .
.
.
.
.
fail .
.
.
.
.
.
.
.
.
.
.
fail .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
table break even timing results for libreo ce query rank exec time forum break even sec min min .
.
fail .
.
.
.
.
.
.
fail .
fail .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
fail .
fail .
fail .
.
.
.
.
.
.
.
.
on average at the .1th postion while about con g nds it a the .9th position.
the second row shows the success rate for either the full preffinder query or when at least one keyword is found for that query.
for example we would say that both of the example queries in table pass since at least one keyword nd the results.
preffinder returns the correct answer of the time while about config does so only of the time.we aslo report in parentheses the number of times an individual keyword nds the correct answer.
using the example queries in table this would be out of or of the time.
we see that using about config with each individual extracted keyword returns the correct answer only of the time.
this tells us that more than two thirds of the time a keyword failed to nd the answer con rming what we know that it is sensitive to keyword selection .
the last row of this table shows the number of successful searches for each tool where the other tool failed.
there are queries where preffinder succeeded and about config failed while only where about config found an answer and preffinder did not.
we next compare to the keyword match utility in abb d1.
the comparison results are shown in table .
we rst show results for the exact query query next we show a combination of allkeywords extracted from the query and then each individual keyword.
the rst row shows the average ranks with failed queries excluded.
when all keywords are used together we get the best average rank .
.
the next best rank is for the individual keyword searches followed by preffinder .
and nally by the full query .
.
if we next look at success rate we see that when we use individual keywords we nd the correct answer for at least one keyword in a query .
of the time.
the individual rate of success for keywords is lower .
and the full set of keywords only has a .
success rate both of which are lower than preffinder .
.
the worst scenario is when we type in the full query for only a .
success rate.
finally we show two rows that tells us how many queries pass in preffinder but fail in the other techniques i.e.
of the full query of the all keywords and none of the individual ones as well as the reverse how many queries succeed in the other technique but fail in preffinder a total of across all techniques .
we conclude from this that the keyword match utilities nd the answer at a lower rank when 159table sample results preffinder vs. firefox about con g up to keywords query preffinder rank about con g rank when closing firefox windows i would like a warning before the last window closes.8windows warning closes fail fail how do i prevent the warning for closing multiple tabs at once from displaying?1warning closing tabs fail fail successful but overall they are more sensitive to failure.
we believe that the high success rate of abb d1has to do with the way that the queries were written and keywords hence extracted .
the writers of these queries are expect engineers and they will tend to use forms of the words and terminology consistent with the preference system.
in addition the keyword match utility in abb can also search the full document instead of just preferences .
this might lead to better success but also has the potential for more noise.
table preffinder vs. about config preffinder about config avg.
rank .
.
success rate succeeded other failed table preffinder vs. abb d1keyword match pfkeyword match query all indiv.
avg.
rank .
.
.
.
success rate .
.
.
.
.
pref succeed other failed other succeed pref failed summary for rq3.
preffinder is competitive against existing keyword search utilities.
the success rate is as good or higher than these systems and allows for more noise although the accuracy when successful is slightly lower.
.
related work there has been a lot of research related to sampling and reducing the large con guration space for testing and maintenance of software for prioritizing these samples and for change impact analysis .
at the code level symbolic execution has been used to identify dependencies and viable interactions of preferences for testing or to perform analysis that is con guration aware .
from a reverse engineering perspective rabkin and katz extract source code level preference names .
other work aims to x or diagnose problems when con gurations fail .
this thread of work requires that some unwanted behavior has been observed a miscon guration and can be recreated.
the aim is not to search for individual con guration options but to return the system to a non faulty state.
confsuggester by zhang and ernst is the most similar work to ours in that is searches for a single con guration option from the source code to return to the user.
however confsuggester still requires the user to demonstrate the di erent behavior it only works for regressions where some default behavior has changed and is limited to java.
furthermore it requires instrumentation at the byte code level which means it is language dependent.preffinder can be used to search for con gurations without demonstration of altered behavior and does not depend on the underlying programming language .
there has been considerable work on using natural language to improve code documentation and understanding and to create code traceability links .
in addition recent work on nding relevant code uses search to nd code snippets that satisfy a given purpose .
while this work is related to our problem the techniques assume that there is a large code base to explore and leverage this in their similarity techniques we want to associate behavior with identi er names with little or no context.
preffinder is unique in that searches highly con gurable multi lingual software systems without access to the code and uses only natural language.
the return result is the preference name that is used within the main preference database a higher level of abstraction than a variable name .
it can also connect with an application s preference system and documentation at runtime.
.
conclusions and future work in this paper we have presented preffinder a natural language framework for nding preferences in highly congurable software.
preffinder uses a core nlp engine but is customizable at both the application and database end.
we instantiated three versions of this framework and performed a case study on two large open source and one industrial application.
we nd that preffinder is able to nd the right preferences for as many as of the queries but no less than using only seconds of time.
when we compared the time taken to nd the same answers when newly asked on a user forum and calculated a break even point we found that it would require a user on average more than minutes per answer evaluation time to make preffinder the slower alternative.
and when we estimate a time of one minute per answer we see as much as an improvement in time.
when compared with existing keyword match utilities we nd that preffinder is more robust albeit the rank of the returned result may be lower.
in future work we will extend preffinder to handle additional use cases.
first we will consider constraints between options and multiple options for a single query.
we will continue to work on the accuracy of our results by adding additional lexical information and will develop traceability links between the menu preference names and code.
we will also include additional artifacts such as code and documentation to enrich the knowledge returned back to the user.
finally we plan to evaluate preffinder in user studies.