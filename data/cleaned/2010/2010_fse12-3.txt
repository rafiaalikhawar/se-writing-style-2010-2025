predicting null pointer dereferences in concurrent programs azadeh farzanyp.
madhusudanzniloofar razaviyfrancesco sorrentinoz abstract we propose null pointer dereferences as a target for finding bugs in concurrent programs using testing.
a null pointer dereference prediction engine observes an execution of a concurrent program under test and predicts alternate interleavings that are likely to cause null pointer dereferences.
though accurate scalable prediction is intractable we provide a carefully chosen novel set of techniques to achieve reasonably accurate and scalable prediction.
we use an abstraction to the shared communication level take advantage of a static lock set based pruning and finally employ precise and relaxed constraint solving techniques that use an smt solver to predict schedules.
we realize our techniques in a tool exceptionull and evaluate it over benchmark programs and find scores of nullpointer dereferences by using only a single test run as the prediction seed for each benchmark.
categories and subject descriptors d. .
software program verification d. .
testing and debugging keywords testing concurrency smt null pointers data races .
introduction errors in concurrent programs often occur under subtle interleaving patterns that the programmer had not foreseen.
there are too many interleavings to explore even on a single test input for a concurrent program making concurrency testing a hard problem.
with the rise of multicore hardware platforms finding solutions to this problem is very important as testing is still the most effective way of finding bugs today.
current testing technologies such as stress testing have proved largely inadequate in exposing such subtle interleavings.
prediction based testing has emerged as a promising approach to testing concurrent programs.
it involves taking one arbitrary concurrent execution of the program under test and from that predict alternate interleavings that are more likely to contain bugs interleavings that lead to data races interleavings that violate atomicity etc.
.
prediction replaces systematic search with a search for interleavings that are close to observed executions only and hence is more tractable and at the same time explores interesting interleavings that are likely to lead to errors .
in this paper we explore a new target for predictive testing of concurrent programs that is fundamentally very different from data races or atomicity errors we propose to target executions this work was funded partly by the nserc discovery grant at university of toronto and by the illinois intel parallelism center at the university of illinois at urbana champaign and by nsf career award .
yuniversity of toronto.
zuniversity of illinois.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
sigsoft fse november cary north carolina usa.
copyright c acm .
.
.
.00that lead to null pointer dereferences .
given an arbitrary execution of a concurrent program under test we investigate fundamental techniques to accurately and scalably predict executions that are likely to lead to null pointer dereferences.
null pointer dereferences can occur in a thread when dereferencing local variables.
consequently an accurate prediction of null pointer dereferences requires by definition handling local variables and the computation of threads.
this is in sharp contrast to errors like data races and atomicity violations which depend only onaccesses to shared variables .
the prediction algorithm aims to find some interleaving of the events in the observed run that will result in a null pointer dereference.
the naive approach to this problem is to reduce it to a constraint satisfaction problem the set of constraints capture the semantics of local computations as well as the interaction of threads using reads and writes concurrency control like locks etc.
a constraint solver could then solve these constraints and hence synthesize an interleaving that causes a null pointer dereference to occur this is similar to logic based bounded model checking for concurrent programs .
however this simply does not scale in realistic dynamic testing setting where the number of events that model reads writes and computation can span millions of events.
consequently accurate null pointer dereference prediction seems intractable.
the main goal of this paper is to achieve useful and scalable prediction for finding runs that cause null pointer dereferences.
we propose a combination of four carefully chosen techniques to achieve this .
approximation an approximation of the prediction problem that ignores local computation entirely and recasts the problem involving only the events that observe shared reads writes and concurrency control events which we call the shared communication level to achieve scalability.
the prediction at the shared communication level can be more efficiently solved using a combination of a lock set based static analysis that identifies null read write pairs and a constraint satisfaction problem to predict executions that force these null reads.
predicted runs in this model will be feasible but may not actually cause a nullpointer dereference though they are likely to do so.
.
static pruning an aggressive pruning of executions using static analysis based on vector clocks that identifies a small segment of the observed run on which the the prediction effort can be focused.
this greatly improves the scalability of using sophisticated logic solvers.
pruning of executions does not affect feasibility of the runs but may reduce the number of runs predicted.
however we show that in practice no additional errors were found without pruning.
.
relaxed prediction a formulation of the prediction at the shared communication level that allows some leeway so that the prediction algorithm can predict runs with mild deviations from the observed run which could be interesting runs this makes the class of predicted runs larger at the expense of possibly making them infeasible though in practice we found the majority of the predicted runs to be feasible.
.
re execution the runs predicted using the techniques may be infeasible or may be feasible and yet not cause any null pointer dereference.
we mitigate this by a re execution engine that executes predicted schedules accurately to check if a null pointer dereference actually occurs.
errors reported hence are always real i.e.
they cause an uncaught exception or result in failing the test harness and hence we incur no false positives.
we explain these techniques below and motivate their choice and their impact.
approximation to the shared communication level though null pointer dereferences could occur on local variables and shared variables unlike data races and atomicity which are defined only at the level of shared variables a prediction that takes into account local variables and local computation simply does not scale we have tried many experiments on such a model that validate this claim .
we propose an approximation to null pointer dereference prediction that works at the shared communication level.
consider a threadtthat in some interleaving reads a shared variable xand subsequently does some computation locally using its value and consider the task of predicting whether this could result in a nullpointer dereference.
our approximation of the prediction problem at the shared communication level asks for a run that forces the threadtto read a value of null.
note that this approximation is neither sound nor complete thread tmay read null forxbut may not dereference the pointer e.g.
it could check if xis null and there may be runs where the value read is not nulland yet the local computation causes a null pointer dereference.
however such an approximation is absolutely necessary to scale to large runs as it is imperative that local computation is not modeled.
as our experiments demonstrate this approximation does not inhibit us from finding interesting executions with null pointer dereferences.
the above approximation poses the problem as a prediction problem at the shared communication level which is a well studied problem.
in particular there is a known maximal causal model that allows prediction at this level and is the most precise prediction one can achieve at the shared communication level.
moreover this prediction can be achieved using automatic constraint solvers that solve a constraint that demands a sequentially consistent interleaving that respects the semantics of read write of shared variables and the concurrency control mechanisms locks barriers threads creation etc.
.
maximal causality prediction using constraint solvers has been done in the past for data races atomicity etc.
as they are properties already defined at the shared communication level and we utilize a similar technique with additional optimizations to approximately predict null pointer dereferences.
static pruning of executions prediction at the shared communication level though more scalable than when modeling local computation still has scalability issues in practice as there can be in the order of hundreds of thousands of events involving shared variables.
we propose pruning the execution using a simple scalable lock set and vector clock based analysis that determines a large prefix of the observed run that can be cut out soundly .
the prediction algorithm hence is only applied to the remnant segment which is smaller by an order of magnitude.
if the prediction of the smaller segment succeeds we are guaranteed that there is a way to stitch back the removed prefix to predict a full execution.
furthermore the relaxed prediction technique discussed below being only applied to the smaller segment introduces inaccuracies solely within that segment.
relaxed prediction the above two techniques of approximate prediction at the shared communication level and static pruning address scalability issues and ensure that predicted runs are always feasible.
however they do not always work well in practice be cause sometimes no solution to the constraints exist.
demanding that the predicted run be absolutely guaranteed to be feasible using the maximal causal model seems too stringent a requirement as it rules out runs that even mildly deviate from the requirements.
for instance if there is a read of ywith value 23in the original run the predicted run is required to make the same read event read the value while in reality reading a different value say may not cause the program to completely deviate from the current path.
we propose a novel relaxed prediction algorithm that models the constraints to allow bounded wiggle room .
we propose to explore for an increasing threshold k whether there is a predictable run that violates at most kconstraints that specify the values of shared reads.
according to our experiments even setting kto a small number e.g.
is often sufficient to predict runs causing nullpointer dereferences.
these predicted runs are not guaranteed to be feasible but we show empirically that most of them actually are.
this technique as well as the approximation to the shared communication level causes unsoundness predicted runs may be feasible or not cause a null pointer dereference which is handled by using an accurate re execution tool that checks whether the predicted runs are indeed feasible and cause a null pointer dereference.
the main technical contributions of this paper is the mechanism of targeting null pointer dereference prediction using the approximation to the shared communication level the static pruning for scalability and the prediction by relaxing constraints so as to make the prediction useful.
evaluation the final contribution of this paper is a full fledged implementation realizing the new prediction based testing tool that targets null pointer dereferences called e xceptio null .
e xceptio null monitors and reschedules interleavings for java programs using java bytecode rewriting building over the p enelope infrastructure and implements the identification of null wr pairs the pruning and the logic based procedures for both precise and relaxed prediction using the smt solver z3 from microsoft research .
we show that e xceptio null is effective in predicting a large number of feasible runs in a suite of concurrent benchmarks.
evaluated over a suite of benchmarks we show the discovery of a slew of about null pointer dereference errors just be predicting from single test executions and with no false positives.
we know of no current technique that can find anywhere close to these many null pointer dereferences on these benchmarks.
we believe that the techniques proposed here hence make a significant leap forward in testing concurrent programs.
we also study some of the effects of techniques we have introduced and estimate the inaccuracies caused and the scalability gained.
we show that the pruning technique provides significant scalability benefits while at the same time does not prohibit the prediction from finding any of the errors.
we also show experimentally that the relaxation technique allows us to predict many more runs than the maximal causal model that result in errors of the errors were found due to relaxation .
we also show the efficacy of the relaxation technique by adapting our relaxed prediction to find data races .
note that data races are already defined at the shared communication level and hence the approximation technique is not relevant.
however even in this setting the static pruning allows us to scale more and the relaxation technique allows us to predict a lot more runs that have data races than the strict prediction on the maximal causal model can the latter is the current state of the art in predicting data races .
our tool discovers data races over our benchmarks of which are found using relaxed prediction showing that relaxed prediction is a very effective for other types of errors as well.
related work the closest work related to ours in the realm of logic based methods are those that stem from bounded model checking for finding executions of bounded length in concurrent programs that have bugs.
typically a program s loops are unrolled a few times to get a bounded program and using a logical encoding of the runs in this bounded program a constraint solver is used to check if there is an error.
we refer the reader to the papers from the nec labs group gives a clean encoding as well as work from microsoft research where the programs are converted first to a sequential program from which bounded run constraints are generated.
the crucial difference in our work is that we use logic in the testing setting to predict alternate interleavings.
another closely related work is c onmem see also where the authors target a variety of memory errors in testing concurrent programs including null pointer dereferences but the prediction algorithms are much weaker and quite inaccurate compared to our robust prediction techniques.
furthermore there is no accurate rescheduling engine which leads the tool to have many false positives.
there are two promising approaches that have emerged in testing concurrent programs selective interleavings andpredictionbased testing and combinations of these .
the selective interleaving approach is to focus in testing a small but carefully chosen subset of interleavings.
there are several tools and techniques that follow this philosophy for instance the chess tool from microsoft tests all interleavings that use a bounded number preemptions unforced context switches pursuing the belief that most errors can be made to manifest this way.
several tools concentrate on testing atomicity violating patterns for varying notions of what atomicity means with the philosophy that they are much more likely to contain bugs .
however systematically testing even smaller classes of interleavings is often impossible in practice as there are often too many of them.
there are several work on prediction based testing that do not use logical methods.
these algorithms may focus on predicting runs violating atomicity or containing data races those by sorrentino et al.
those by wang and stoller and by huang and zhang.
a more liberal notion of generalized dynamic analysis of a single run has also been studied in a series of papers by chen et al.
.
jp redictor offers a predictive runtime analysis that uses sliced causality to exclude the irrelevant causal dependencies from an observed run and then exhaustively investigates all of the interleavings consistent with the sliced causality to detect potential errors.
the main drawback of non logical prediction approaches is that the predicted runs may not be feasible.
in fact they ignore data which makes them less effective in finding bugs that are data dependent such as null pointer dereferences.
logic based prediction approaches target precise prediction.
given an execution of the program several work model the whole computation local as well as global logically to guarantee feasibility.
the research presented in the above related work has too big an overhead to scale to large executions.
maximal causality model mcm on the other hand allows prediction at the level of shared communication and is the most precise prediction one can achieve at this level.
mcm has been used by said et al.
for finding data race witnesses.
we also use this model to predict runs leading to null pointer dereferences.
.
motivating example consider a code extract from the pool .
library in the apache commons collection presented in figure .
the object pool s state open orclosed is tested outside the synchronized block in method returnobject by checking whether the flag variable isclosed is true.
if so then some local computation occurs followed by a synchronized block that dereferences the shared object pool .
a second method close closes the pool and setsisclosed to true to signal that the pool has been closed.an error in this code and such errors are very typical stems from the fact that the check of isclosed in the method returnobject is not within the synchronized block hence if a thread executes the check at line and then a concurrent thread executes the method close before the synchronized block begins then the access to the pool object at line 0will raise an uncaught nullpointer dereference exception .
in a dynamic testing setting consider the scenario where we observe an execution with two threads where texecutes the method returnobject first and then t0executes the method close aftertfinishes executing returnobject .
there is no null pointer dereference in .
our goal is to predict an alternate scheduling of events of that causes a null pointer dereference.
our prediction for null pointer dereferences works as follows.
in the run a read of the shared variable pool at 0occurs int and the read value is not null.
also a write to pool occurs int0 at 00which writes the value null .
we ask whether there exists an alternative run 0in which the read at int can read the value null written by the write at location int0 as illustrated by the arrow in figure .
our prediction algorithm observes the shared events such as shared reads writes but suppresses the semantics of local computations entirely and does not even observe them they have been replaced by ... in the figure as they play no role in our analysis.
prediction of runs that force the read at 0to read the null value written at 00must meet several requirements.
even if the predicted run respects the synchronization semantics for locks thread creation etc.
the run may diverge from the observed run due to reading a different set of values for shared variables which will result in a different local computation path e.g.
the condition check at will stop the computation of the function right away if the value of isclosed is true .
therefore we also demand that all other shared variable reads read the same value as they did in the original observed run in order to guarantee that unobserved local computations will unfold in the same way as they did in the original run.
this ensures the feasibility of the predicted runs.
relaxed prediction the requirement for all shared variable reads to read the same values however can be too strict in some cases.
for instance in our example the variable modcount is a global counter keeping track of the number of modifications made to the pool data structure and does not play any role in the local control flow reaching the point of null pointer dereference at .
in the real execution leading to this null pointer dereference which is the one where block b1 fromt is executed first followed by b3 fromt0 and thenb2 fromt the read of modcount will read a different value than the corresponding value read in .
however this does not affect the feasibility of the run in contrast to the value read for isclosed which plays an important role in reaching the nullpointer dereference .
our relaxed prediction model gives a slack threshold k allowing predicted runs to have at most kreads that do not have to read the same values as in .
by increasing the threshold kiteratively our technique will find an execution that violates the read condition on modcount but yet finds a feasible run that causes the null pointer dereference in this example.
.
preliminaries here we present an overall overview of our prediction based approach and set up a formal notation to describe the predicted runs.
.
overview of proposed approach given a concurrent program pand an input i we perform the following steps monitoring we execute pon the input iand observe an arbitrarily interleaved run .publicvoidclose synchronized this ...modcount ......pool null isclosed true publicvoidreturnobject objectobj ...if isclosed thrownewpoolclosedex ...synchronized this numactive ...... modcount ...pool.push obj lscript lscript prime lscript prime prime t prime t canthenullvaluebeobservedhere?
b1 b2 b3figure .
code snippet of the buggy implementation of pool.
run prediction we analyze the run to find a set of pair of events e f in such that i eis a write to shared variablexthat writes a null value ii fis a read from the same shared variable xthat reads a non null value in another thread and iii static analysis on the run determines that there is a runb ofp obtained from reshuffling of events in that respects locks and in which freads the null value written by e. we call such pair of events e f anull wr pair.
for each null wr pair we logically encode the set of runs and use smt solvers to predict concrete runs b that force null reads.
rescheduling for each b generated by the run prediction phase we re execute the program on the same input i forcing it to follow b .
if it succeeds then the null value read at f may later result in an error such as a null pointer dereference exception we report all such confirmed errors.
we now set up the formal notation to describe the run prediction phase.
in particular the prediction algorithm will ignore computation of threads and interleave at the level of blocks of local computations that happen between two reads writes to global variables.
.
modeling program runs suppressing local computation we model the runs of a concurrent program as a word where each letter describes the action done by a thread in the system.
the word will capture the essentials of the run shared variable accesses synchronizations thread creating events etc.
however we will suppress the local computation of each thread i.e.
actions a thread does by manipulating local variables etc.
that are not yet visible to other threads and model the local computation as a single event lc.
in the formal treatment we will ignore other concurrency constructs such as barriers etc.
these can be accommodated easily into our framework.
we fix an infinite countable set of thread identifiers t ft1 t2 g and define an infinite countable set of shared variable names sv that the threads manipulate.
without loss of generality we assume that each thread tihas a single local variable lvithat reflects its entire local state.
let v svs iflvigrepresent the set of all variables.
let val x represent the set of possible values that variable x2svcan get and define init x as the initial value of x. we also fix a countable infinite set of locks l. the actions that a thread tican perform on a set of shared variablessvand global locks lis defined as ti fti readx val ti writex valjx2sv val2val x g fti lcg fti acquire l ti release l jl2lg fti tctjjtj2tg actionsti readx val andti writex val correspond to the thread tireading the value valfrom and writing the value valto the shared variable x respectively.
action ti lccorresponds to a local computation of thread tithat accesses and changes the local state lvi.
actionti acquire l represents acquiring the lock land theactionti release l represents releasing of the lock l by thread ti.
finally the action ti tctjdenotes the thread ticreating the threadtj.
we define s ti2t tias the set of actions of all threads.
a wordwin in order to represent a run must satisfy several obvious syntactic restrictions which are defined below.
lock validity data validity and creation validity there are certain semantic restrictions that a run must follow.
in particular it should respect the semantics of locks and semantics of reads i.e.
whenever a read of a value from a variable occurs the last write to the same variable must have written the same value and the semantics of thread creation.
these are captured by the following definitions jadenotes the word projected to the letters in a .
definition .
lock validity .
a run islock valid if it respects the semantics of the locking mechanism.
formally let l fti acquire l ti release l jti2tgdenote the set of locking actions on lock l. then is lock valid if for every l2l j lis a prefix ofhs ti2t ti acquire l ti release l i definition .
data validity .
a run over a set of threadst shared variables sv and locksl isdata valid if it respects the read write constraints.
formally for each nsuch that ti readx val one of the following holds i the last write action to xwrites the value val.
i.e.
there is a m n such that tj writex valand there is no m k n such that tq writex val for anyval0and any thread tq or ii there is no write action to variable xbefore the read and valis the initial value of x. i.e.
there is no m n such that tj writex val for anyval0and any thread tj and val init x .
definition .
creation validity .
a run over a set of threadstiscreation valid if every thread is created at most once and its events happen after this creation i.e.
for every ti2t there is at most one occurrence of the form tj tctiinw and if there is such an occurrence then all occurrences of letters of ti happen after this occurrence.
program order let a1 anbe a run of a program p. the occurrence of actions in runs are referred to as events in this paper.
formally the set of events of the run is e fe1 eng and there is a labeling function that maps every event to an action given by eu au.
while the run defines a total order on the set of events in it e there is an induced total order between the events of each thread.
we formally define this as vifor each thread ti as follows for anyes et2e ifasandatbelong to thread tiands tthen esviet.
the partial order that is the union of all the program orders isv ti2tvi.
the maximal causal model for prediction given a run corresponding to an actual execution of a program p we would like our prediction algorithms to synthesize new runs that interleave the events of to cause reading of null values.
however we want to predict accurately in other words we want the predicted runs to be feasible in the actual program.
we now give a sufficient condition for a partial run predicted from an observed run to be always feasible.
this model of prediction was defined by s erb anut a et al.
and is called the maximal causal model it is in fact the most liberal prediction model that ensures that the predicted runs are always feasible in the program that work purely dynamically i.e.
no other information about the program is known other than the fact that it executed this set of observable events which in turn do not observe computation .we generalize the model slightly by taking into account thread creation.
definition .
maximal causal model of prediction .
let be a run over a set of threads t shared variables sv and locks l. a run 0isprecisely predictable from if i for each ti2t 0jtiis a prefix of jti ii 0is lock valid iii data valid and iv creation valid.
let prpred denote the set of all runs that are precisely predictable from the run .
the first condition above ensures that the events of tiexecuted in 0is a prefix of the events of tiexecuted in .
this property is crucial as it ensures that the local state of tican evolve correctly.
note that we are forcing the thread tito read the same values of global variables as it did in the original run.
along with datavalidity this ensures that the thread tireads precisely the same global variable values and updates the local state in the same way as in the original run.
lock validity and creation validity are of course required for feasibility.
we will refer to runs predicted according to the maximal causal model i.e.
runs in prpred as the precisely predicted runs from .
the following soundness of the prediction that assures all predicted runs are feasible follows theorem .
.
letpbe a program and be a run corresponding to an execution of p. then every precisely predictable run 02prpred is feasible in p. the above theorem is independent from the class of programs.
we will assume however that the program is locally deterministic non determinism caused by threads interleaving is of course allowed .
the above theorem in fact even holds when local computations of parenon deterministic i.e.
the predicted runs will still be feasible in the program p. however in order to be able to execute the predicted runs we need to assume determinism of local actions.
in this case we can schedule the run 0precisely and examine the outcomes of the tests on these runs.
.
the prediction problem for null reads we are now ready to formally define the precise prediction problem for forcing null reads.
definition .
precisely predictable null reads .
let be a run of a program p. we say that 0is a precisely predictable run that forces null reads if there is a thread tiand a variable x such that the following are satisfied i fwherefis of the formti readx null ii 00is a precisely predictable run from using the maximal causal model and iii there is some val null such that 00j i ti readx valis a prefix of j i. intuitively the above says that the run 0must be a precisely predictable run from followed by a read of null by a thread ti on variablex and further in the observed run threadtimust be executing a non null read of variable xafter executing its events in .
the above captures the fact that we want a precisely predictable run followed by a single null read that corresponded to a nonnull read in the original observed run.
note that 0itself is not in prpred but is always feasible in the program p and results in a null read by thread tion variablexthat had not happened in the original run.
the precisely predictable runs that force null reads are hence excellent candidates to re execute and test if the local computation after the read does not check the null ness of xbefore dereferencing a field ofx then this will result in an exception or error.
.
identifying null wr pairs using lock sets the first phase of our prediction is to identify null wr pairs e f whereeis a write of null to a variable and fis a read ofthe same variable but where the read in the original run reads a non null value.
moreover we would like to identify pairs that are feasible at least according to the hard constraints of thread creation and locking in the program.
for instance if a thread writes to a shared variable xand reads from it in the same lock protected region of code then clearly the read cannot match a write protected by the same lock in another thread.
similarly if a thread initializes a variablexto a non null and then creates another thread that reads x clearly the read cannot read an uninitialized x. we use a lock set based static analysis of the run without using a constraint solver to filter out such impossible read write pairs.
the ones that remain are then subject to a more intensive analysis using a constraint solver.
using a static analysis on the observed run we first collect all null wr pairs e f .
then we prune away null wr pairs for which there is no lock valid run in which fis reading the null value written bye.
then for each null wr pair e f left we use our precise logical prediction algorithm to obtain a lock valid datavalid and creation valid run in which fis reading the null value written bye.
however instead of using run for the purposes of the prediction we slice a relevant segment of it and use the segment instead.
the reason for this is twofold these run segments are often orders of magnitude smaller than the complete run and this increases the scalability of our technique and when a precisely predictable run does not exist we use a more relaxed version of the constraints to generate a new run limiting the improvisation to a smaller part of run increases our chances of obtaining a feasible execution.
we formally define this relevant run segment and how it is computed in section .
in this static analysis the idea is to check if the null wr pair e f can be realized in a run that respects lock validity and creation validity constraints only and not data validity .
creation validity is captured by computing a vector clock associated with each event where the vector clock captures only the hard causality constraints of thread creation.
if foccurs before eaccording to this relation then clearly it cannot occur after eand the pair is infeasible.
lock validity is captured by reducing the problem of realizing the pair e f topairwise reachability under nested locking which is then solved by computing lock sets and acquisition histories for each event.
we describe only the lock validity checking below.
similar techniques have been exploited for finding atomicity violations in the tool p enelope .
checking lock valid reachability consider a null wr pair e f and a run in whichf a read in thread tj occurs first and later the write event eis performed by ti.
let us assume that e00is the next write event to the same variable accessed in eandf intiaftere.
if there exists a lockvalid run obtained by permuting the events in in which freads the null value provided by e then in fshould be scheduled after e but before e00 iffis scheduled also after e00 then the write in e00overwrites the null value written by ebefore it reachesf.
this means that there should exist an event e0of threadti occurring between events eande00 that is executed right before or after f in in other words e0andfare co reachable.
e e prime prime f ti tj .
.
.
.
.
.
.
.
.
.
.
e prime .
.
.
ah1 ah2 ls2 ls1 ls1 ls2 ah1compatiblewithah2 writex null readx null writex .
we use a simple technique to check if there is an evente0intibetweeneande00such thate0andfare coreachable in a lockvalid run.
the coreachability check is done by examining the lock sets and ac po cv dv lvpo vni 1poi cinitcinit vni tseinit t sei poi vmi 1j tsei j t sei j dv vxvval2val x vr2rx val ww02wx valcoupledr w0 coupledr w tsw t sr e002wx w tse00 t sw tsr t se00 lv lv1 lv2lv1 i6 j2 .. n lockl 2li l 2lj l tserel tse0ac tse0rel tseac lv2 i6 j2 .. n lockl eac2noreli l 2lj l tse0rel tseac figure .
constraints capturing the maximal causal model.
quisition histories at e0andf the lock sets at e0andfmust be disjoint and the acquisition histories at e0andfmust be compatible.
note that the above condition is necessary for the existence of the lock valid run but not sufficient hence filtering out pairs that do not meet this condition is sound.
.
precise prediction by logical constraint solving we now describe how we solve the problem of precisely predicting a run that realizes a null wr pair e f .
this problem is to predict whether there is an alternate schedule in the maximal causal model that forces the read at fto read the null value written by e. we solve this using a logic constraint solver an smt solver the logic of the constraints is in a fragment that is efficiently decidable.
prediction according to the maximal causal model is basically an encoding of the creation validity data validity and lock validity constraints using logic where quantification is removed by expanding over the finite set of events under consideration.
modeling this using constraint solvers has been done before in the context of finding data races.
we reformulate this encoding briefly here for several reasons.
first this makes the exposition self contained and there are a few adaptations to the null read problem that need explanation.
second we perform a wide set of carefully chosen optimizations on this encoding whose description needs this exposition.
and finally the relaxation technique which is one of the main contributions of this paper is best explained by referring directly to the constraints.
capturing the maximal causal model using logic given a run we first encode the constraints on all runs predicted from it using the maximal causal model independent of the specification that we want runs that match a given null wr pair .
a predicted run can be seen as a total ordering of the set of events e of the run .
we use an integer variable tseto encode the timestamp of evente2ewheneoccurs in the predicted run.
using these timestamps we logically model the constraints required for precisely predictable runs see definition .
namely that the run respect the program order of that it be lock valid data valid and creation valid.
figure illustrates the various constraints.
the constraints are a conjunction of program order constraints po creation validity constraints cv data validity constraints dv and lock validity constraints lv .the program order constraint po captures the condition that the predicted run respect the program order of the original observed run.
suppose that the given run consists ofnthreads and let jti ei ei ... ei m ibe the sequence of events in that relates to thread ti.
then the constraint poidemands that the time stamps of the predicted run obey the order of events in threadti andpo demands that all threads meet their program order.
we also consider an initial event einitwhich corresponds to the initialization of variables.
this event should happen before any thread starts the execution in any feasible permutation and is encoded as the constraint cinit.
turning to creation validity suppose that etc i is the event that creates thread ti.
then the constraint cv demands that the first event oftican only happen after etc i .
combined with program order constraint this means that all events before the creation of ti in the thread that created timust also occur before the first event ofti.
the data validity constraints dv see definition .
capture the fact that reads must be coupled with appropriate writes more precisely that every read of a value from a variable must have a write before it writing that value to that variable and moreover there is no other intermediate write to that variable.
let rx val represent the set of all read events that read value valfrom variable xin wxrepresent the set of all write events to variable x and wx val represent the set of all write events that specifically write valuevalto variablex.
for each read event r readx val and write eventw2wx val the formula coupledr wrepresents the requirement that wis the most recent write to variable xbeforer and henceris coupled with w. the constraint dv demands that all reads be coupled with writes that write the same value as the read reads.
lock validity is captured by the formula lv.
we assume that each lock acquire event acof locklin the run is matched by precisely one lock release event relof locklin the same thread unless the lock is not released by the thread in the run.
we call the set of events in thread tibetweenacandrela lock block corresponding to lock lrepresented by .
letli lbe the set of lock blocks in thread tiregarding lock l. thenlv1asserts that no two threads can be simultaneously inside a pair of lock blocks and e0 ac e0 rel corresponding to the same lock l. turning to locks that never get released the constraint lv2handles asserts that the acquire of lock lby a thread that never releases it must always occur after the releases of lock lin every other thread.
in this formula noreli lstands for lock acquire events in tiwith no corresponding later lock release event.
optimizations the constraints when written out as above can be large.
we do several optimization to control the formula bloat while preserving the same logical constraint .
the data validity constraint above is expensive to express as it is in the worst case cubic in the maximum number of accesses to any variable.
there are several optimizations that reduce the number of constraints in the encoding.
suppose that r readx val is performed by thread ti.
each write event w0toxthat occurs after rinti i.e.rviw0 can be excluded in the constraints related to coupling rwith a write in constraint dv above.
suppose that wis the most recent write to xbeforerinti.
then each write event w0beforewinti i.e.w0viw can be excluded in the constraints related to coupling rwith a write in constraint dv above.
whenris being coupled with w2wx val in threadtj each write eventw0beforewintj i.e.w0vjw can be excluded as candidates for e00in the formula coupledr w. suppose that ris being coupled with w2wx val in thread tjandw0is the next write event to xafterwin threadtj.
then each write event w00afterw0intj i.e.w0vjw00 can be excluded as candidates for e00in the formula coupledr w. eventrcan be coupled with einitonly when there is no other write event to xbeforerinti i.e.
w wvir w2wx .
furthermore it is enough to check that the first write event to x in each thread if it exists is performed after r. the lock validity formula above which is quadratic in the number of lock blocks is quite expensive in practice.
we can optimize the constraints.
if a read event rin threadtican be coupled with only onewrite eventwwhich is in thread tjthen in all precisely predictable runs wshould happen before r. therefore the lock blocks according to lock lthat are intjbeforewand the lock blocks according to lock lthat are intiafterrare already ordered.
hence there is no need to consider constraints preventing tiand tjto be simultaneously in such lock blocks.
in practice this greatly reduces the number of constraints.
furthermore when considering lock acquire events with no corresponding release events in lv2 above it is sufficient to only consider the lastcorresponding lock blocks in each thread and exclude the earlier ones from the constraint.
predicting runs for a null wr pair we adapt the above constraints for predicting in the maximal causal model to predict whether a null wr pair e f is realizable.
suppose that and e f are a run and a null wr pair passed to the prediction phase respectively.
notice that in the original run freads a non null value while we will force it to read null in the predicted run by coupling it with write event e. indeed this is the whole point of predicting runs we would like to diverge from the original run at fby forcingfto read a null value.
note that once freads a different value we no longer have any predictive power on what the program will do as we do not examine the code of the program but only its runs .
consequently we cannot predict any events causally later than f. the prediction problem is hence formulated as follows given a run and a null wr pair e f in algorithmically find a precisely predictable run from that forces null reads according to i.e.fis the last event and reads the null value written bye.
the prediction problem is to find precisely predicted runs that executeefollowed by f while avoiding any other write to the corresponding variable between eandf.
the constraints that force the readfbe coupled with the write eisnc coupledf e. furthermore recall that the feasibility of the run that we are predicting needs to be ensured only up to the readf.
consequently we drop from the data validity formula that the value read at f in the original run match the last write it should instead match eas above .
a further complication is scheduling events that happen after ein the same thread.
note that some of these events may need to occur in order to satisfy the requirements of events before f for instance a read before fmay require a write after eto occur .
however we may not want to predict some events after e as we are really only concerned with foccurring after e. our strategy here is to let the solver figure out the precise set of events to schedule after e and before the next write to the same variable as eis writing to in the same thread.
for events after einti we enforce lock validity and datavalidity constraints only if they are scheduled beforef.
more precisely we replace w0coupledri w0in the formula dv to tsr tsf w0coupledri w0 .
similarly we drop the lock constraints on events occurring after f this relaxation is more involved but straightforward .in summary we have reduced the problem of predicting a run according to the maximal causal model that causes the null writeread pair to be realizable to a satisfiability of a formula in logic.
the constraints generated fall within the class of quantifier free difference logic constraints which smt solvers efficiently solve in practice.
.
relaxed prediction the encoding proposed in the previous section is sound in the sense that it guarantees feasibility of the predicted runs.
however as demonstrated by the example in section sound prediction under the maximal causal model can be too restrictive and result in predicting no runs.
slightly diverging from the original can sometimes lead to prediction of runs that are feasible in the original program.
we hence have a tension between two choices we would like to maintain the same values read for as many shared variable reads as possible to increase the probability of getting a feasible run but at the same time allow a few reads to read different values to make it possible to predict some runs.
our proposal which is one of the main contributions of this paper is an iterative algorithm for finding theminimum number of reads that can be exempt from data validity constraints that will allow the prediction algorithm to find at least one run.
we define a suitable relaxed logical constraint system to predict such a run.
our experiments show that exempting a few reads from data validity constraints greatly improves the flexibility of the constraints and increases the possibility of predicting a run and at the same time the predicted runs are often feasible.
the iterative algorithm works as follows.
let s assume there arenshared variable reads that are required to be coupled with specific write by the full set of data validity constraints.
the datavalidity constraints are expressed so that we specifically ask for n shared reads to be coupled correctly.
if we fail to find a solution satisfying constraints for all nreads then we repeatedly decrement n and attempt to find a solution that couples n 1reads in the next round and so on.
the procedure stops whenever a run solution is found.
the change required in the encoding to make this possible is described below.
for every read event ri2r we introduce a new boolean variable bi that is true if the data validity constraint for riis satisfied and false otherwise.
in addition we consider an integer variablebintiwhich is initially and set to 1only whenbi is true.
this is done through a set of constraints one for each ri2r .
also for eachri2r we change the sub term w0coupledri w0to tsr tsf bi w0coupledri w0 indv forcing the data validity constraint for read rito hold when biis true.
note that with these changes we require a different theory that is linear arithmetic in the smt solver to solve the constraints compared to the difference logic which was used for our original set of constraints.
initially we set a threshold to bejrj the number of all read events.
in each iteration we assert the constraintp i jrjbinti which specifies the number of data validity constraints that should hold in that iteration.
if no run can be predicted with the current threshold i.e.
the constraint solver reports unsatisfiability then is decremented in each iteration until the formula is satisfiable.
this way when a satisfying assignment is found it is guaranteed to have the maximum number of reads that respect data validity possible for predictable run.
note that once jrj the predicted run is not theoretically guaranteed to be a feasible run.
however in practice when is close tojrjand a run is predicted this run is usually feasible in the program.instrumenter observed javaclasses jvm bug runs passedthe extractor schedule instrumenter instrumented classes null wrpair constraintgenerator z3 constraints run extractor run nosolution segment generator instrumented classes jvm prefix null wr pair segment monitor monitor scheduler runpredictor run predicted testharnessfigure .
exceptio null.
.
pruning executions for scalability identifying null wr pairs using the lock set based analysis and then subjecting them to constraint checking is a precise method to force null reads.
however in our experiments we discovered that the constraint solving approach does not scale well when runs get larger.
in this section we propose a pruning technique for the runs that removes a large prefix of them while maintaining the property that any run predicted from the suffix will still be feasible.
while this limits the number of predictable runs in theory we show that in practice it does not prevent us from finding errors in particular no error was missed due to pruning in our experiments .
furthermore we show that in practice pruning improves the scalability of our technique in some cases by an order of magnitude.
consider an execution and a null wr pair e f .
the idea behind pruning is to first construct the causal partial order of events of and then remove two sets of events from it.
the first set consists of events that are causally after eandf except for some events as described in detail below .
the second set is a causally prefix closed set of events a configuration that are causally before eandf and where all the locks are free at the end of execution of this configuration.
the intuition behind this is that such a configuration can be replayed in the newly predicted execution precisely in the same way as it occurred in the original run and then stitched to a run predicted from the suffix since the suffix will start executing in a state where no locks are held.
in order to precisely define this run segment we define a notion of partial order on the set of events ethat captures the causal order.
letddenote the dependency relation between actions that relates two actions of the same thread reads and writes on the same variable by different threads and lock acquisition and release actions of the same lock in different threads.
we define the partial order e eon the set of program events as the least partial order relation that satisfies the condition that ei ej whenever ai aj i j and a a0 2dwhereaiandajare actions performed by events eiandej respectively.
let us define as the smallest subset of events of that satisfies the following properties contains events eandf for any event e0in all events e00 e0are in and for every event corresponding to a lock acquire in its corresponding release event is also in .
the intuition is that events that are not in are not relevant for the scheduling of the null wr pair they are either far enough in the future or are not dependent on any of the events in .
the figure below presents a run of a program with threads that is projected into individual threads.
here ebelongs to thread t1andfbelongs to threadt2.
the cut labeled marks the boundary after which all events are not causally before eandf and hence need not be considered for the generation of the new run.
next we identify a causally prefix closed set of events before e andfto remove.
for the null wr pair define as the largestsubset of events of that has the following properties it does not containeorf for any event e0in all eventse00 e0 are in and for any event e0intisuch thate0is the last event oftiin with respect tovi the lockset associated to e0 intiis empty.
in the above figure the curve labeled marks the boundary of and eventst1 t 4have empty lock sets.
t1 t2 t3 t4 f e t1 t2 t3 t4 the run segment relevant to a nullwr pair is then defined as the set of events in n scheduled according to the total order in .
one can use a simple worklist algorithm to compute both and and consequently .
this run segment is passed to the run prediction phase in the place of the whole run .
.
implementation we have implemented our approach in a tool named e xcep tionull .
figure demonstrates the architecture of e xcep tionull .
it consists of three main components a monitor a run predictor and a scheduler.
the monitor and scheduler are built on top of the p enelope tool framework with considerable enhancements and optimizations including the extension of the monitoring to observe values of shared variables at reads and writes.
in the following we will explain each of these components in more details.
monitor the monitor component has an instrumenter which uses the bytecode engineering library bcel to automatically instrument every class file in bytecode so that a callto an event recorder is made after each relevant action is performed.
these relevant actions include field and array accesses acquisition and releases of locks thread creations and thread joins etc.
but exclude accesses to local variables.
the instrumented classes are then used in the java virtual machine jvm to execute the program and get an observed run.
for the purpose of generating the datavalidity constraints the values read written by shared variable accesses are also recorded.
for variables with primitive types e.g.
boolean integer double etc we just use the values read written.
objects and arrays are treated differently the object hash code by system.identityhashcode is used as the value every time an object or an array is accessed.
run predictor the run predictor consists of several components null wr pair extractor segment generator constraint generator z3 smt solver and run extractor.
the null wr pair extractor generates a set of null wr pairs from the observed run by the static lock analysis described in section .
the segment generator component for each null wr pair e f isolates a part of .
raytracer pool .
pool .
pool .
sbuckermap vector stack hashset stringbuffer ftpserver hedc weblechtime seconds prediction time w o pruning prediction time w pruning figure .
prediction times with without pruning in log scale.
run that is relevant to as described in section and passes it to the constraint generator.
given a null wr pair and the relevant segment the constraint generator produces a set of constraints based on the algorithm presented in section and passes it to the z3.
any model found by z3 corresponds to a concurrent schedule.
the run extractor component generates a run based on the model returned by z3.
when z3 cannot find a solution the constraint generator iteratively weakens the constraints see section and calls z3 until a solution is found.
scheduler the scheduler is implemented using bcel as well we instrument the scheduling algorithm into the java classes using bytecode transformations so that the program interacts with the scheduler when it is executing the same set of events that were monitored.
the scheduler at each point looks at the predicted run and directs the appropriate thread to perform a sequence of nsteps.
the threads wait for a signal from the scheduler to proceed and only then do they execute the number of observable events they are instructed to execute.
afterwards the threads communicate back to the scheduler relinquishing the processor and await further instructions.
the communication between the scheduler and the threads is implemented using wait notify synchronization which allows us to have a finely orchestrated scheduling process.
data race prediction our proposed monitoring logic based precise and relaxed prediction on statically pruned runs and the rescheduling is a general framework and can be adapted to errors other than null pointer dereferences as well.
in order to study the effects of relaxed prediction and static pruning we implemented a data race prediction unit as well to our tool as data races are a more well studied class of errors for which precise prediction has been studied.
due to lack of space we do not discuss the details of the data race detection unit here.
.
evaluation we subjected e xceptio null to a benchmark suite of concurrent programs against several test cases and input parameters.
experiments were performed on an apple macbook with ghz intel core duo processors and 2gb of memory running os x .
.
and sun s java hotspot bit client vm .
.
.
benchmarks.
the benchmarks are all concurrent java programs that use synchronized blocks and methods as means of synchronization.
they include raytracer from the java grande multi threaded benchmarks elevator from eth vector stack hashset andstringbuffer from java libraries pool three different releases and staticbucketmap from the apache commons project apache ftpserver from hedc from and weblech from .
elevator simulates multiple lifts in a building raytracer renders a frame of an arrangement of spheres from a given view point pool is an object pooling api in the apache commons suite staticbucketmap is a thread safe implementation of the java map interface apache ftpserver is a ftp server by apache and vector stack hashset andstringbuffer are java libraries that respectively implement the concurrent vector the concurrent stack the hashset and the stringbuffer data structures.
hedc is a web crawler application and weblech is a websites download tool.
experimental results.
table illustrates the experimental results for null pointer dereference prediction information is provided about all the three phases of monitoring run prediction and scheduling.
in the monitoring phase the number of threads shared variables locks the number of potential interleaving points i.e.
number of global events and the time taken for monitoring are reported.
for the prediction phase we report the number of nullwrpairs in the observed run the number of precisely predicted runs and the additional number of predicted runs after relaxing the data validity constraints when there is no precisely predicted run for a null read write pair .
in the scheduling phase we report the total number of schedulable predictions among the predicted ones.
finally we report the average time for prediction and rescheduling of each run the total time taken to complete the tests for on all phases on all predicted executions and also the number of errors found using the precise and relaxed predicted runs.
errors found.
in almost all the cases the errors manifested in the form of raised exceptions during the execution.
in weblech in addition to a null pointer dereference an unwanted behavior occurred the user is asked to push a stop button even after the website is downloaded completely resulting in non termination!
.
raytracer has a built in validation test which was failed in some of the predicted runs.
for some of the test cases of vector and stack the output produced was not the one expected.
we report the errors found in two categories those that were found through the precise prediction algorithm and those that were found after weakening data validity constraints relaxation .
the effect of pruning figure illustrates the substantial impact of our pruning algorithm in reducing prediction time.
we present prediction times with and without using the pruning algorithm.
note that the histogram is on a logarithmic scale.
for example in the case of weblech the prediction algorithm is about times faster with pruning.
furthermore all errors found without the pruning were found on the pruned runs showing that the pruning did not affect the quality of error finding on our benchmarks.
data race detection.
table presents the results of data race prediction on our benchmarks using the same observed runs as in the null reads prediction.
for each benchmark we report the total number of data races found these are all distinct races identified by the code location of the racy access.
we also report the number of distinct variables involved in data races.
for brevity information about different test cases is aggregated for each benchmark see for more details .
observations exceptio null performs remarkably well predicting a large number of feasible program runs on which there are null pointer dereferences and data races.
in total it finds about executions with null pointer dereferences and races which to our knowledge is the most successful attempt at finding errors on application elevator raytracer pool .
pool .
pool .
sbucketmap vector stack hashset stringbuffer ftpserver hedc weblechtotal num.
of data races by precise prediction additional data races by relaxation number of distinct involved variables table .
experimental results for data race prediction.monitoring prediction scheduling application loc input base num.
of threads num.
of shared variables num.
of locks num.
of potential interleaving points time to monitor num.
of null wr pairs num.
of precisely predicted runs additional predicted runs by relaxation num.
of schedulable predictions average time per predicted run total time null pointer deref.
by precise prediction additional null pointer deref.
by relaxation elevator data .3s 814k .4s .9s data2 .3s 830k .4s .9s data3 .2s 50150k .0s .5s raytracer .5k a .0s .0s .6s .5s a .6s .7k .4s .7s 2m15s b .4s .5s .7s 6m24s pool .
.8k pt1 1s 1s 1s .6s pt2 1s 1s .8s pt3 1s 1s .2s .0s pt4 1s 1s .5s .8s pool .
7k pt1 1s 1s 1s .6s pt2 1s 1s .8s pt3 1s 1s .4s .9s pt4 1s 1s .2s 1m49s pool .
.2k pt1 1s 1s .5s .5s pt2 1s 1s .5s .5s pt3 1s 1s .1s pt4 1s 1s .4s .4s sbucketmap smt 1s 1s 1s .3s vector .3k vt1 1s 1s 1s .3s vt2 1s 1s .1s .0s vt3 1s 1s 1s .1s vt4 1s 1s 2s .4s vt5 1s 1s 2s 2m57s stack .4k st1 1s 1s 1s .5s st2 1s 1s 1s .9s st3 1s 1s 1s .3s st4 1s 1s .8s .2s st5 1s 1s .0s 2m51s hashset .3k ht1 1s 1s 1s .2s ht2 1s 1s 1s stringbuffer .4k sbt 1s 1s 1s .3s apache ftpserver 22k lgn 1m2s 60s 1m13s 2h14m46s hedc 30k std .7s .74s .7s 1m57s weblech v. .
.
35k std .9s .6k .92s .26s 10m34s total number of errors table .
experimental results for predicting null reads.
errors tagged with represent test harness failures.
errors tagged with represent array out of bound exceptions.
errors tagged with represent unexpected behaviors.
all other errors are null pointer dereference exceptions.
these benchmarks in the literature.
furthermore all the errors are completely reproducible deterministically using the scheduler.
we count exceptions raised in different parts of the code as separate errors.
more precisely each error reported in table consists of a unique read write pair in the code that were forced to perform a null read and that resulted in an error.
for example the exceptions in ftpserver are raised in different functions and at different locations inside the functions and involve nullpointer dereferences on different variables.
the prediction algorithm works extremely well while there were several runs that were predicted in the precise model the re laxed prediction gives a lot more predictions and a large fraction of these were schedulable.
the time taken for prediction and scheduling are very reasonable for the kind of targeted analysis that we perform despite the use of fairly sophisticated static analysis and logic solvers.
the number of data races found using relaxed prediction further shows the efficacy of relaxed prediction.
a further dataraces were found using relaxed prediction showing that predicting beyond the maximal causal model can be effective even in finding errors other than null pointer dereferences.