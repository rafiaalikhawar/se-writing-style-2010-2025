identifying execution points for dynamic analyses william n. sumner school of computing science simon fraser university wsumner sfu.caxiangyu zhang department of computer science purdue university xyzhang cs.purdue.edu abstract dynamic analyses rely on the ability to identify points within or across executions.
in spite of this being a core task for dynamic analyses new solutions are frequently developed without an awareness of existing solutions their strengths their weaknesses or their caveats.
this paper surveys the existing approaches for identifying execution points and examines their analytical and empirical properties that researchers and developers should be aware of when using them within an analysis.
in addition based on limitations in precision correctness and e fficiency for techniques that identify corresponding execution points across multiple executions we designed and implemented a new technique precise execution point ids.
this technique avoids correctness and precision issues in prior solutions enabling analyses that use our approach to also produce more correct results.
empirical comparison with the surveyed techniques shows that our approach has overhead on average several times less than existing solutions.
i. introduction dynamic analyses help developers identify interesting pro gram behaviors at runtime.
as a result these analyses can simplify or speed up common tasks like debugging and verification .
because these problems are core developme nt tasks improving them can lead to lower software developmen t costs and this in turn has led to great interest and gro wth within the field of dynamic analysis as a whole.
one fundamental task in dynamic analyses is identifying a point within an execution of a program.
such execution points are sometimes used to provide feedback to developers .
for example when a tool like memcheck within valgrind identifies an invalid memory access it can provide an execution point showing developers where in the execution this invalid access occurred.
developers can use this infor mation to help fix the bug.
execution points also serve as input to additional analyses.
for instance dual slicing uses execution points to identify commonly executed instructio ns across multiple executions .
it uses these common behavi ors to prune out irrelevant dependences from specialized slice s that concisely explain concurrency bugs.
in spite of this pervasiveness dynamic analyses are incons istent and imprecise in how they identify and compute executio n points.
analyses create their own formulations of execution point ids epids without understanding existing approaches and even among existing techniques di fferent types of epids have unexplored properties.
their strengths and weaknesse s are poorly understood and can lead to unexpected limitation s of precision or scalability.
in addition one definition of e xecution point may be preferable in one context but undesirable i n1defaction x 2print x 4defmain 5foriin range x input ifx action x fori x if false fori x if false fori x if true action print sic sic sic 1fori x if true action print fori x if false fori x if true action print sic sic sic sic a b c fig.
.
a program that prints odd numbers and two executions of the program.
another yet these trade o ffs between the different techniques are presently not well understood.
consider the program in fig.
1a.
this program reads in three numbers from the user.
if a number is odd as checked on line then the program calls action to print the number out.
notice that line can execute many times because it is called from within the loop.
as a result simply using the line numbe r to identify the execution point is ambiguous because the same id may appear multiple times within the same execution.
this is undesirable for many dynamic analyses as it yields imprecise or incorrect results .
one approach commonly used in the context of record and replay techniques is the software instruction counter sic .
an sic uses a single integer counter that increments a t function calls and loop backedges during the execution of a program.
combining the current counter with the current lin e number yields a pair counter line that can uniquely identify an execution point within one execution.
for example the instances of the ifstatement on line of execution b are identified by and because of the counter increments on back edges as shown in fig.
1b.
however these identifiers only work within a single execution .
the sics used for execution b do not work for the instructions of execution c .
this is because the executio ns behave differently.
the sic is incremented at the call to action in the first iteration of execution c so the identifiers for the ifstatements are and .
because the sic was incremented at the first call in c but not in b the sics of the two executions diverge and cannot be compared after this point.
this is a problem for analyses that compare informati on across multiple executions because sics can only precisely identify points within one execution.
to address this problem and enable comparison across978 .
c ieee ase palo alto usa81 executions other epid techniques exploit program structu re .
using this information they are often able to align the corresponding instructions across multiple exec utions.
unfortunately these techniques also have limitations tha t create ambiguous or meaningless relationships when identifyi ng the instructions that align across executions.
they also ha ve substantial limitations in usability.
in particular stru ctural execution indexing has di fficulties scaling to longer executions while stat requires a program core dump at each point that requires an epid.
in addition sei can fail to identify useful relationships between epids.
in this paper we survey five existing approaches used to compute epids for dynamic analyses.
the surveyed techniques range in their precision and purpose from only being able to imprecisely identify points even in one execution to uniquely identifying points across multiple executions ev en in the presence of concurrency and nondeterminism.
they range in runtime overhead from none using only postmortem analysis to several times the cost of the original executio n. based on the limitations of the existing techniques for cros sexecution epids we observed a need for a new technique that provides meaningful and unambiguous relationships in execution alignment and without the usability and scalabil ity limitations of existing approaches.
we introduce a new tech nique for precise execution point ids pepids that addresses these goals and has a runtime overhead only slightly higher than using calling contexts .
we have implemented all of these techniques those surveyed along with pepid.
we evaluated them empirically on spec cint2006 to illustrate their performance.
we also provide the first analytical comparison of these di fferent approaches weighing their costs their benefits and the scen arios where one may be more desirable than another.
using this information a dynamic analysis designer can know in advanc e which techniques are most appropriate for his or her purpose s and avoid inventing or reinventing an approach with known problems.
in summary the contributions of this paper are we surveyed and implemented existing techniques for computing epids for dynamic analyses.
we analytically examine all of the di fferent techniques and compare them along several spectra in order to weigh their relative costs merits and limitations.
we observed problems with producing meaningful unambiguous relationships between epids as well as with usability and scalability in existing techniques for cross execution epids.
to address these problems we introduce a new cross execution technique pepid and show that it avoids the limitations of existing work while also having lower runtime overhead.
we empirically compare the runtime and space overheads introduced by the di fferent techniques those surveyed as well as pepid and we show that for cross execution epids pepid is the most e fficient with average overhead.
for intra execution techniques sics are the most efficient with overhead.
we illustrate how missing meaningful relationships be tween inter execution epids can result in undesirable or incorrect results for dynamic analyses.
ii.
existing epid techniques in this section we review the di fferent approaches for computing epids that have appeared historically in the cont ext of dynamic analyses.
we consider the intended use cases design and requirements of each technique.
a. calling contexts one of the traditional representations of epids is the calling context at a point within an execution.
the calling context consists of the list of active functions currently on the cal l stack.
note similar to using the line number or program counter as an epid in fig.
the calling context is an ambiguous representation.
the same calling context may appea r multiple times even within one execution.
as a result calli ng contexts are potentially ambiguous epids but they provide a more detailed representation of the static program behavi or than just a line number.
in spite of this calling contexts ar e already familiar to developers and can be easily collected b y walking over the call stack .
as a result many dynam ic analysis tools use calling contexts during analysis or whil e generating reports for developers .
in spite of their familiarity calling contexts were tradit ionally costly to collect.
walking over the call stack at every point of interest can be costly which has forced some dynami c analyses to resort to sampling techniques that only analyze portions of an execution .
more recently e fforts have focused on efficient means of encoding calling contexts.
these include approaches that can probabilistically encode cont exts in constant space as well as approaches that can precisely encode calling contexts but can require a flexible encoding size and a slightly higher runtime overhead .
in the context of dynamic analysis more precise informatio n is usually preferred so in this paper we only consider the la tter work precise calling context encoding pcce .
pcce works on the principle that calling contexts are equivalent to paths through the call graph of a program.
the technique examines the call graph during compilation and numbers all o f the acyclic paths present in the graph.
it then annotates eve ry edge or call site with an arithmetic operation that comput es the numerical id of the current path in the call graph at runtime similar to ball larus path profiling .
combine d with the current instruction these comprise a calling cont ext.
pcce handles recursion by pushing and popping the acyclic path ids onto a calling context stack as necessary.
main a b c 1defb ... contextid c contextid ... a b fig.
.
a an annotated call graph that encodes all calling c ontexts into unique integers.
b example instrumentation of the function b .
for example consider the call graph presented in fig.
2a.
the circle annotations on the call edges denote the amount82added to the context id before each call and subtracted from the id upon return.
fig.
2a illustrates this instrumentatio n for the function b .
using this example the calling context main b cis captured by the pair c .
this reflects the currently executing function c and the numerical id representing the path in the call graph .
computing these ids using pcce requires that a program be instrumented at compile time which requires forethough t and time not applicable for all dynamic analyses.
for instan ce if a developer wishes to analyze an already compiled program with a tool that uses pcce they have to compile the program again to have the necessary instrumentation added.
in addit ion the efficiency results achieved by pcce .
runtime overhead exploit profile guided instrumentation and addit ional optimizations for compressing repetitive and recursive ca lling contexts.
both of these requirements can be avoided by using stack walking to extract the calling context but as mentio ned before they induce a high overhead .
b. software instruction counters mellor crummey and leblanc introduced software instruction counters sics to provide a more precise notion of execution point for profiling and debugging .
sics have since been used in a variety of dynamic analyses especially in the context of nondeterministic recording and replay .
sics provided the first representation of execut ion points that was able to uniquely and scalably identify every instruction within a single execution of a program.
they wor k by maintaining a monotonic counter that indicates the progr ess through an execution.
this gives sics the advantage of only adding a single counter and sparse increment operations to an execution thus yielding low overhead.
while the epids defined by sics are unambiguous within a single execution the sic for a point may change across di fferent executions and the same sic may even represent di fferent execution points in two different executions as seen in fig.
and section i. computing sics involves incrementing a counter at every function call and back edge in the control flow graph cfg of a program.
fig.
1b c show the executions of fig.
1a with instrumentation for computing sics where print range and input are built in commands .
for any point within an execution of a program the sic instrumentation creates a pa ir counter current line such that the pair uniquely identifies that execution point.
the counter maintains a notion of forward progress within the execution and it is only incremented at those features within an execution that may cause an instruction to execute multiple times loops and function c alls .
accurately placing instrumentation on back edges requires static analysis or some additional dynamic analysis to dete ct loops within individual functions.
this mandates either fo rethought for the static analysis just like pcce or addition al runtime space and complexity overhead for dynamic loop de tection.
instead of instrumenting back edges in the cfg man y analyses alternatively instrument the branch points withi n a program .
for executions that terminate or have side effects these are equivalent and have the advantage that1defaction x 2print x 4defmain 5foriin range push x input ifx push push action x pop pop pop possible calls to action an bracketle t an bracketri ht an bracketle t an bracketri ht an bracketle t an bracketri ht a b fig.
.
a the program from fig.
instrumented for computing s eis.
the consecutive pushes at and are discussed in the text below .
b epids for potential calls to action .
branch instructions can be easily identified and instrument ed by dynamic instrumentation or virtualization tools .
c. structural execution indexing while the epids provided by sic su ffice for intra execution analyses we saw in section i that an epid defined by sic might correspond to the first iteration of a loop in one execution and the last iteration of a loop in another execution.
indeed the alignment that sics create between t he instructions of two di fferent executions can match instructions at the beginning of one execution with instructions at the end of a second.
for dynamic analyses that perform interexecution analysis e.g.
execution comparison this can lead to meaningless results.
intuitively when there is no relatio nship between instructions with the same epids across the two executions comparing them is uninformative.
this provided the motivation for structural execution indexing sei from xin et al .
they observed that some dynamic analyses compare execution points across executio ns but the way that analyses identified execution points led to meaningless correspondences like those established by si c in section i .
they instead sought to use the semantic structure of underlying programs to determine which progra m points corresponded.
they observed that the control struct ures of a program along with the dynamic control dependence at runtime established a semantic identity for execution po ints even across different executions so they used these to uniquely identify instructions at runtime.
the technique maintains a stack that keeps track of the currently active control struc tures while a program executes.
this stack then acts as the epid.
the process of computing an sei based id for an execution point is similar to manually maintaining a call stack at runt ime except that dynamic control dependence information is also included in the stack.
at every branch or call instruction the instruction id is pushed onto an indexing stack along with the id of its postdominator or return instruction .
th is id postdominator pair identifies the region of code that is control dependent upon the branch or call instruction.
up on encountering a postdominator or return all entries in th e stack postdominated by that instruction are popped from sta ck.
applying this process to the code from fig.
yields the new831ifa b 2action ifa ifb action exitcalls to action an bracketle t 1a exit exit an bracketri ht an bracketle t 1a exit 1b exit exit an bracketri ht a b c fig.
.
a a simple program where structural execution index ing is dependent upon the execution path.
b the cfg with two paths to action .
c epids for the call to action .
program in fig.
3a.
note for each dynamic iteration of the loop an id postdominator token is pushed on the stack at line .
as seen in fig.
3b showing the epids for each call toaction these tokens track the monotonic progress of an execution through a loop until the loop finishes and all itera tion tokens are popped at line .
the pop x operation removes all tokens with the postdominator x. the push and pop on lines and bound a region of code control dependent upon line while those on lines and identify the call on line .
uniquely identifying function calls is crucial because the same function may be called multiple times and not di fferentiating the call sites would lead to ambiguous epids.
the complete algorithm also contains additional operation s for optimizing simple loops using counters and for eliminat ing pushes onto the stack that can be inferred based purely on where an instruction lies within the cfg.
for example the push for each loop iteration on line can be replaced by a counter increment since the loop has a single conditional guard.
also executing the body of the ifstatement in fig.
automatically implies that the ifstatement on line was executed and the truebranch taken.
thus the pushes and pops on lines and can be safely elided.
the intuition that control dependence creates a semantic relationship across executions had previously been used fo r trace similarity metrics and has proven e ffective enough that sei has gained traction in analyses that examine inter execution relationships.
it has since been used for tasks ra nging from automated debugging to concurrent profiling to identifying causes of vulnerabilities .
in spite of t his tracking control dependence can require o n space where nis the length of an execution which does not scale for some programs.
the aforementioned optimization heuristic s can mitigate this problem in practice but they do not elimin ate it.
we explore the space and runtime overheads in section v. in addition sei requires that a program be instrumented at compile time to accurately identify postdominators.
as previously noted sei was designed to guarantee epids across executions could only be equal for execution points that correspond across the executions.
in some cases it is too aggressive in achieving this goal and can create di fferent epids even when execution points meaningfully correspond across executions .
consider the code in fig.
4a.
a shortcircuiting oroperation creates the cfg in fig.
4b with two branches and two paths to action on line .
note that the paths through the program split based on the values of aand b but the paths that call action merge together again before this call.
intuitively the calls to action occur at the same execution point even in different executions so their epids should be the same.
in spite of this because sei bases epid constructionon the control dependence of the execution point different paths to the same point can have di fferent epids .
in this case as fig.
4c shows one epid encodes a path where aistrue and the call is control dependent on a. the other encodes the path where just bistrue and the call is depends first on bwhich transitively depends on a .
we show later in section v c that this counterintuitive relationship lea ds to undesirable results for dynamic analyses.
d. stat ordering the techniques presented thus far all required either stati c or dynamic program instrumentation.
in some cases such as when analyzing a deployed program or a program whose behavior changes when it is instrumented it is necessary to avoid any instrumentation whatsoever.
this motivated th e epid technique presented by ahn et al.
as a part of their stack trace analysis tool stat .
stat was designed for debugging high performance computing applications wit h multiple processes.
in order to better classify and group equivalent processes that represented failures they deve loped a technique for analyzing core dumps of programs in order to extract the execution point where a program failed.
these core dumps are essentially snapshots of program memory and contain not only the call stack of the execution at the point of failure but also the values of all variables on the stack or heap at that point.
in addition to producing an epid from the core dumps stat produced a partial ordering of execution points across di fferent executions.
this partial order was particularly important in the context of analyzing para llel code that involved multiprocess communication.
stat was the first epid technique we are aware of that observed how a partial ordering of epids could be useful for analyses.
epids produced by stat are also stack based similar to those produced by sei.
however stat does not have the control dependence or postdominance information used by se i. instead stat infers as much as possible about an execution point from the core dump.
in particular epids from stat inte rleave the call stack of the execution point and values of certain local variables that show the monotonic progress of an execution through loops.
the call stack of an execution point can be extracted from the core dump using stack walking methods mentioned in section ii a but finding variables tha t show loop progress is more di fficult.
such variables do not even always exist so stat makes no guarantee that epids it produces are unambiguous.
pragmatically stat defines loop order variable s lovs that can easily be recognized and extracted as indicators of loop progress when present.
lovs must be defined at least once each iteration be given strictly increasing or decreasing values over a loop s life time and be given an identical value each particular iteratio n across all possible executions.
informally these variabl es are given a strictly ordered and predefined sequence of values.
stat also defines a static analysis for identifying when thes e variables are available.
consider the simple program in fig.
5a.
this program contains two loops one that iterates over a fixed range of841foriin range 2process int i 3fornode inlinkedlist 4process node node possible calls to process int and process node an bracketle t i mapsto process int an bracketri ht an bracketle t i mapsto process int an bracketri ht an bracketle t i mapsto process int an bracketri ht an bracketle t process node an bracketri ht an bracketle t process node an bracketri ht a b fig.
.
example of using stat to identify epids at the calls to process int andprocess node .1while a .
.
.
3ifb break .
.
.
d fig.
.
a loop with linear sei growth.
integers on lines and another that iterates over a linked list on lines .
suppose that the linked list contains two elements.
the epids computed by stat for each call toprocess int orprocess node are shown in fig.
5b.
for the first loop stat is able to identify that iis a lov so its value inside the loop is extracted and included in the epid of each function call.
this makes the epid for each call to process int unique.
however for the second loop there is no lov as the loop iterates over a linked list.
as a result the epid contai ns only the call to process node and the epids are ambiguous.
in contrast to previous techniques stat does not require program instrumentation and thus does not induce additiona l overhead on an analyzed application.
however it can only extract an epid at a location where the program produced a core dump e.g.
a crashing failure.
in practice this meant that stat was strictly a post mortem technique it could not produce epids on the fly as a program was executing.
while this limitation can be worked around by explicitly producin g core dumps both the runtime and space overhead of producing core dumps can be prohibitive.
also note that stat makes use of static analysis for identifying the lovs whose values it captures.
performing this analysis precisely requires a ccess to the cfg and variable information available at compile tim e but it can also be approximated through binary static analys is thus avoiding the need for any compile time information.
e. lightweight execution indexing while sei offers an approach for computing epids online at runtime the potential overhead can cause scalability prob lems and interfere with the program being analyzed.
this occurs when loops have multiple guarded exits.
consider the loop in fig.
.
sei pushes a token onto the stack every time lines or execute because they branch the control flow but those tokens will not be popped o ffthe stack until the loop finishes because the branches are postdominated by a statement outside the loop.
in order to avoid the overhead of sei some analyses instead use information about the number of times an instruction has been seen within a particular cal ling context a particular function invocation or invocations at a certain depth of the call stack .
a canonical examp le of this is lightweight execution indexing lei which was used to identify allocated objects in order to help expose potential deadlocks in concurrent java programs .the approach of lei is to maintain a counter for each depth of the call stack.
this counter keeps track of how many times a particular method has been called at that depth.
for instan ce the first time that the method foo is called at a depth of on the stack its hit counter for the depth is .
the next time it is called at the depth of on the stack its hit counter for that depth is .
the counter for each method at each depth is maintained independently.
the lei for a given execution poi nt then comprises the current calling context along with the hi t counts of every call site within the context as well as the hit count and identity of the currently executing statement.
this approach bounds the size of the an epid to twice the size of the calling context.
in addition it maintains a noti on of forward progress through depth counters and this notion of progress is structured by the call stack.
as a result each ep id is unique and unambiguous within one particular execution.
unfortunately exactly as with sic the values of counters seen in one execution have no guaranteed relationship with the counters seen in other executions.
as a result lightwei ght execution indexing can provide epids within one execution but it cannot provide meaningful epids across executions.
also similar to sic lei does not inherently require that a program be analyzed or rewritten at compile time.
the counters associated with each function and statement of interes t at every depth of the call stack can be entirely constructed usi ng dynamic instrumentation without a need for prior planning.
iii.
precise execution point ids dynamic analyses comparing multiple executions are increasingly common so having a robust e fficient epid technique that works across executions is important.
such inter execution techniques create epids that are only equal when their corresponding execution points are equiva lent.
prior work has called this the execution correspondence criterion .
in spite of this problem s importance we se e that there are only two existing techniques that can provide epids across executions sei and stat.
both techniques have limitations that can prevent them from being practical or us eful for particular dynamic analyses.
in particular we desire a n inter execution epid technique that is online an analysis should be able to construct the epid for the current point in the execution and as often over the lifetime of an execution as necessary.
low overhead an execution running with an epid technique should require as little additional runtime and memory as possible.
scalable neither the duration of an execution nor the size of its workload should significantly a ffect the runtime or space requirements of the epid technique.
unambiguous every instruction or statement within an execution should have a unique epid.
comprehensive as a dual to satisfying the execution correspondence criterion equivalent execution poin ts should also yield equal epids.
neither sei nor stat is able to satisfy all of these requirements.
sei is not low overhead scalable or comprehensive 851defaction x 2print x 4defmain 5while notdone ... action x 8action x defmain while notdone ... action x action x print x print x ifnotdone ... action x ifnotdone ... action x ifnotdone ...print x ifnotdone ... action x ifnotdone ...print x ifnotdone ...defmain action x print x a b c fig.
.
a a small program.
b the program with calls logicall y inlined.
c the program with calls inlined and loops unrolled.
and stat is not online unambiguous or comprehensive.
in this section we introduce a new epid technique precise execution point id s pepid that targets all of these criteria.
we start by building an intuition about which points should correspond across executions in order to provide unambiguity a nd comprehensiveness.
we then devise a technique for computin g epids that produces this correspondence e fficiently online.
a. which points correspond?
because we desire an inter execution epid technique we must first decide which execution points should correspond or align across executions.
the intuition used by sei was that the path taken by an execution helped to determine which execution points were equivalent and sei used contro l dependence to codify this relationship.
stat in contrast used the intuition that loop control variables captured a notion of forward progress through the loop iterations of an executio n. but as we saw before control dependence prevents comprehensiveness and focusing on loop control variables lea ds to ambiguity.
in contrast we base pepid on the idea that execution points at the same position in a su fficiently inlined and unrolled cfg are equivalent .
consider a simple program with an acyclic cfg and no function calls.
each instruction inside the program can be executed at most once so an instruction s position within the cfg can unambiguously identify the instruction within an execution.
in addition the same instruction will trivia lly have the same epid across all possible executions thus guaranteeing comprehensiveness.
unfortunately this mod el is unrealistic in general real programs have both function ca lls and back edges in their cfgs both of which can cause instructions to execute more than once and thus introduce ambiguity.
however we can extend the intuition of equivale nt points in the cfg to handle those cases as well.
first consider programs that also include function calls.
a function may be called from multiple locations thus execut ing its body multiple times and making the cfg location an ambiguous epid.
a simple solution to this in most cases would be to inline every function call.
if every call were inlined then function bodies would be duplicated at every call site once again ensuring uniqueness.
thus the positi onof an instruction within this fully inlined cfg serves as an unambiguous epid ignoring loops .
this can be seen in fig.
7a b. this simple program makes calls to action both inside and outside of the loop.
using the position in the cfg alone would make these calls to print on line ambiguous however once action is inlined the calls from inside the loop are clearly distinguished from those outside of the loop.
of course this cannot be done in practice because recursiv e calls would require an undecidable degree of inlining and inlining every function call would simply increase a progra m s size too much to be pragmatic.
however we only need to perform this operation logically for now.
we shall later show that the same correspondence can be computed without actually inlining any functions at all.
next we must handle back edges in the cfgs of a program s functions.
back edges create loops or general cycles in a cfg and can thus cause instructions to execute multiple times again making an instruction s position in the cfg ambiguous as an epid.
one approach used by bounded model checkers is to unroll the loops of a program .
each iteration of a loop is peeled of into the guarded body of an ifstatement and each successive iteration is nested within the body of the preceding iteration.
fig.
7c illustrates thi s unrolling in combination with the inlining of function call s. again unrolling a loop su fficiently for all executions is not possible in practice but we shall show that this limitation is irrelevant in the next section.
using this combination of unrolling and inlining we are able to define how execution points relate across executions definition alignment given two execution points p1 and p2from executions e1ande2of program prespectively letgbe cfg of psufficiently unrolled and inlined to contain both execution points.
points e1ande2align iffthey occur at the same instruction in g. this alignment of execution points determines exactly which points are equivalent and must have equal epids even across different executions.
observe in this transformed program g execution points p1and p2can each be performed at most once in any execution as guaranteed by the acyclic structure of the unrolled and inlined cfg.
thus the transformed program guarantees that the position in the control flow graph of the program provides an unambiguous epid and the control flow graph correspondence maintains comprehensiveness as before.
this means that pepid avoids the problems with sei presented in fig.
and fig.
.
b. efficiently computing pepids as discussed in the last section inlining all function call s and unrolling all loops is impractical and even undecidable in general so we must compute this equivalence another way.
instead of actually performing these program transformati ons pepid executes the original program without any extra inlin ing or unrolling but at the same time keeps track of the inlini ng and unrolling operations that would have occurred in order to identify the current execution point.
we keep track of these86instrument p input a program p for each loop linpdo insert pushloopcounter before the loop header of l insert incrementloopcounter before loop latches of l insert poploopcounter on loop exits of l. for each callcinpdo insert pushcallsiteid before c insert popcallsiteid after c fig.
.
instrument takes in a program pand modifies it to maintain a pepid online.
this is the unoptimized instrumentation.
operations on an id stack similar to those used in sei and stat.
this stack is then what pepid uses to produce epids.
in particular we push an entry onto the stack to identify the call site of every function invocation popping it as the fun ction returns or unwinds for exceptional control flow .
this trac ks the inlining operations for all function invocations.
we al so need to track all unrolling operations for backedges.
we firs t consider only natural loops loops with a single entry node o r loop header but we extend this to irreducible loops in the next section.
we compactly record the unrolling of natural loops by pushing a counter for the loop upon loop entry and popping the counter upon loop exit.
we increment the counter upon every iteration of the loop by instrumenting the loop latche s or the edges in the cfg that lead back to the loop header.
the stack also naturally handles nested loops.
fig.
shows a na ve instrumentation algorithm for pepid.
it does not cover exceptional control flow but we handle exceptions by saving the id stack height before a call that might throw an exception and pruning the stack to that height if an exception was thrown.
note that the entries in the stack related to inlining and the entries related to unrolling may be maintained independently because they can be unambiguousl y recombined.
this stems from the fact that given an instruct ion i the number of static loops containing imay be readily identified.
as a result a pepid can be broken down into the inlining id stack the unrolling id stack and the current instruction id.
observe though the inlining id st ack is precisely equal to the calling context!
pcce already provid es a means of encoding the calling context that is more e fficient than explicitly pushing and popping at each call site so we can exploit this to make pepid computation more e fficient.
at any point during the execution a dynamic analysis can callgetcurrent pepid to yield an epid of the form an bracketle tpcce context unrolling id stack current instruction an bracketri ht this tuple comprises an epid that provides comprehensiveness and uniqueness based on the prior construction.
like sei and stat pepid requires compile time knowledge about a program.
e fficiently computing pcce calling contexts requires the call graph and the unrolling stack requires loops to be identified.
for programs with only natur al loops pepids are compact.
the pcce context is bounded in size by the calling context depth and the loop unrolling sta ck is bounded by the number of nested loops that may be active at one time.
we show in section v that this instrumentation scheme allows pepid to scale with low overhead.a b cd ea b cd ea bc d e a b c fig.
.
a a natural loop.
b c irreducible loops.
c. handling irreducible loops counting iterations is e ffective for natural loops which have a unique headers or entry nodes.
in that context unrolling loops is well defined and corresponds to actions upon the unrolling id stack.
programs can also have unnatural or irreducible loops which have multiple entry points.
indeed half the spec cint2006 benchmarks have such loops.
fig.
shows some natural and unnatural loops.
with multiple headers distinguishing a loop body from a nested loop is di fficult.
we use steensgaard s generalized loop forest recognition t o identify irreducible loops and their bodies .
both b and c are individual irreducible loops under this approach with headers b and d for b and b c and d for c .
sometimes using an iteration counter can still work for irreducible loops.
given a loop if there exists a header hof the loop such that every path from each header h through the loop body back to h must pass through h then we say that the header h naturalizes the loop.
this is because there exists a traversal of the cfg such that every backedge in the loop hashas its destination.
thus we can use a counter as before and simply increment it on every loop edge that targets h. an alternative intuition is that breaking only edges to hwould destroy all cycles in the loop so a counter incremented on hwill uniquely identify instances of this acyclic subregion .
node b in loop b is one such naturalizing header.
note that this is just a generalization of natural loops where th e unique header always naturalizes the loop body.
we identify naturalizing headers using simple static analysis.
without a naturalizing header edges to multiple headers must increment the counter to avoid ambiguity.
conservativ ely allheaders may need to increment.
this can yield unintuitive results.
for example the path abdcdcdc in loop c would have the epid an bracketle tentry c an bracketri htif edges to header nodes increment the loop counter but so would the path abcbcbdc.
here entry is the calling context and is the unrolling i d stack.
technically there exists an unrolling of c that pr oduces these ids but it is unclear how meaningful this is in practic e. alternatively we can use the same approach as sei for only this small portion of the program.
we push the ids of predicates in the loop that the headers are control dependent upon and pop them upon their postdominators.
this produces the epids an bracketle tentry b e d e c e d e c e d e c an bracketri htand an bracketle tentry b e c e c e c e b e d e c an bracketri ht which show the different paths.
both approaches produce unambiguous inter execution epids.
they merely use di fferent approaches for unrolling degenerate irreducible loops.
in fact an ana lysis can correctly select either.
if overhead is more important 1steensgaard s approach is preferable to other loop extract ion techniques in that it produces consistent results regardless of how a cfg i s traversed .87incrementing on edges to all headers is preferable.
if disam biguating paths through these loops is important then usin g the localized pushing and popping from sei is preferable.
iv .
analytical comparison in this section we examine some of the analytical propertie s of the different techniques surveyed and how they impact which techniques are preferable in di fferent situations.
fig.
i summarizes the results and we discuss them in detail below.
availability many dynamic analyses require that epids be available online e.g.
for identifying events like allocat ion or synchronization during an execution.
most of the technique s provide epids online although stat does not.
however for analyses that are interested in execution points at the poin t a program crashes stat can still be a useful choice because it alone avoids the need for any program instrumentation.
requirements instrumentation the requirements and time of instrumentation for the techniques can sometimes create more work for analyses or developers that depend on epids.
for example stat places the lowest instrumentation burden on users and client analyses because it does not modif y the underlying program.
as a result it is easy for stat to be used with an already compiled program.
because it imposes no overhead it could even be used on deployed software.
techniques like sic and lei that use local counters can be implemented using runtime instrumentation alone so they a lso impose little burden on users but they may not be appropriat e for deployed software.
finally the remaining techniques a ll require that programs are recompiled with additional stati c instrumentation.
this requires the most work and planning o n the part of the developer or client analysis.
independent of instrumentation the techniques can also re quire additional source level information to be precise.
pc ce sei and pepid all require additional compilation informat ion which is expected since they also require static instrument ation.
however stat also requires some compile time information in order to identify lovs.
this requirement holds in spite of the fact that stat performs no instrumentation.
ambiguousness inter execution ids ambiguous epids do not necessarily confer much information about where an execution point occurs temporally.
thus ambiguous techniques may be useful for attaching a lightweight notion of local execution context to an execution point but they cann ot be used for more fine grained execution comparison based techniques .
note though that while both pcce and stat are listed as ambiguous stat is unambiguous for programs in which all loops have identifiable lovs hence the in the table .
the major differentiating feature of inter execution techniques is that they are able to align loop iterations across different executions.
as a result techniques that do not track the progress through each loop independently are unable to provide inter execution ids.
this e ffectively leaves only sei and pepid as viable techniques for analyses requiring such epids.
note however that stat can also provide this under the same assumptions of lovs as before .comprehensiveness one of the large limitations of sei was that it was not comprehensive.
while its epids always established a correspondence across executions it also cr eated different epids for execution points that did correspond see fig.
.
note for programs with lovs stat actually is comprehensive.
however in contrast to both pepid provide s comprehensive inter execution epids in general making it a preferable choice when instrumentation is possible.
ordering some analyses require that epids be ordered.
for example record and replay techniques require that epid s be ordered within one execution intra .
some analyses require stricter orders where epids are partially ordered even across executions inter .
most of the techniques are able to provide intra execution ordering am ong epids except for calling contexts with pcce.
sei stat and pepid provide stronger inter execution ordering as wel l through happens before relationships among their epids .
space overhead the size of epids is also an important concern.
the required space ranges from none or a constant word stat and sic respectively to proportional to the leng th of an execution in the worst case for sei.
all other technique s however have epids that grow roughly proportional to the size of the call stack.
we examine later how the sizes of the epids produced by these techniques compare in practice.
v .
empirical evaluation in order to compare these di fferent epid techniques in practice we implemented all of them using llvm .
as a program instrumentation platform and compared them on the spec cint2006 benchmarks.
the implementations cover all basic program behavior covered by these benchmarks including exceptional control flow.
in this section we look closely at the compile time properties as well as the runtime and space overheads induced by these techniques.
we conclud e by looking at a particular case study that illustrates why comprehensiveness is important in practice.
note that neither the runtime nor space overhead comparisons include stat.
this is because stat performs no instrumentation and thus has no overhead.
however the effectiveness of stat depends heavily on the ability to produc e core dumps and identify lovs.
to gauge whether or not these variables can be found in practice we compiled the spec benchmarks and counted the total number of static loops as well as the number of static loops for which a lov could be identified.
fig.
ii contains the results.
overall a median of of loops had identifiable lovs across the different benchmarks and of all loops had such variables.
this indicates that relying on lovs may not be practical in general.
however stat was originally designed for analyzing high performance computing program s. for programs in that domain the structure of the programs may make relying on lovs practical .
a. runtime efficiency for each of the techniques except stat we ran the spec cint2006 benchmarks using reference workloads times88table i analyticalpropertiesofthedifferent epidtechniques .
properties pcce sic sei stat lei pepid availability online online online offline online online requirements call graph nonecontrol dependence loopsloop order variablesnonecall graph loops instrumentation static dynamic static none dynamic static ambiguous yes no no yes no no inter execution no no yes no no yes comprehensive no no no no no yes ordering none intra inter inter intra inter space overhead o call stack o o path length none o call stack o call stack unrolling stack table ii lovidentificationfor spec cint2006.
program loops lovs with lovs .perlbench .bzip2 .gcc .mcf .gobmk .hmmer .sjeng .libquantum .h264ref .omnetpp .astar .xalancbmk total and computed the median and confidence interval for the mean.
we ran all experiments on a bit intel i5 machine with 8gb ram running ubuntu .
.
fig.
presents the normalized median of each technique compared to uninstrumented trials of the benchmark suite.
we also present the geometric means of the normalized results for each technique.
error ba rs indicate the confidence intervals of the means.
pcce and sic usually have the lowest overhead on average and respectively.
the next closest is pepid with then lei with and sei with .
we immediately see that in comparison to the other inter execution technique sei pepid consistently produces lower overhead.
the original sei paper produced overhead near on average which differs the results we find.
while we used clang sei used diablo fit with link time optimization yielding optimization differences.
the original evaluation of sei also used spec cpu95 and cpu2000 benchmarks with smaller workloads than those present in the benchmarks.
when we used the test workload the smallest that spec provides sei improved to overhead.
this illustrates that scalabi lity was indeed a problem for sei.
one of the benchmarks .omnetpp would not even run using sei on the reference workload because the stack used for epids consumed all memory and crashed the program before completion.
in contrast pepid s overhead was always closer to sic and pcce in spite of the fact that it provides a more informative form of epid.
we also note that the original pcce paper reports overhead closer to .
the work used profile guided instrumentation to achieve low runtime overhead but we did not use profile guided instrumentation in our llvm based implementation.
also while we used clang to compile programs pcce used gcc which optimizes programs di fferently.
this does nottable iii worstcasememoryoverheadof epidtechniques .
program pcce sic sei stat lei pepid .perlbench 197kib 8b .8mib 110kib 262kib .bzip2 8b 8b 238mib 5kib 112b .gcc 165kib 8b 885mib .1mib 496kib .mcf 232b 8b 626mib .3kib 488b .gobmk .7kib 8b .3mib 126kib .4kib .hmmer 32b 8b 255kib .1kib 96b .sjeng 368b 8b .3kib .4kib 856b .libquantum 8b 8b 40mib .2kib 48b .h264ref 24b 8b 121kib .7kib 168b .omnetpp .9kib 8b 7gib .4kib .9kib .astar 8b 8b .3mib .6kib 64b .xalancbmk 246kib 8b .86gib .6mib 431kib mean .1kib 8b 436mib .2mib .9kib affect our comparison because alltechniques in this paper were compiled using clang .
in addition using profile guided optimizations for pcce would just strengthen the results of pepid since pepid relies on pcce as a subtask.
b. space overhead maintaining the current epid consumes memory for each technique except stat.
table iii lists the maximum memory overhead for each benchmark and technique as well as the mean across all benchmarks.
sic and stat require a single word or no overhead respectively which may be preferable if memory must be conserved.
even though pcce compactly encodes the calling context it still takes .1kib on avera ge because some benchmarks have deeply nested calls.
for instance .gcc has a maximum depth of calls.
profile guided instrumentation can help reduce this.
however even the worst case overhead of pepid which uses pcce is relatively low around kib on average.
it is almost always smaller than lei and is orders of magnitude smaller than sei in spite of its precision.
this makes pepid a preferable technique fo r analyses needing inter execution epids.
c. client impact we now show how a comprehensive technique like pepid is preferred over a non comprehensive technique like sei fo r a particular dynamic analysis.
we consider an analysis know n as dual slicing.
dual slicing is a backward slicing techniqu e that contrasts two executions .
instead of including all backward dependences for a slice criterion it includes onl y those dependences that either exist in only one of the executions or exist in both executions but define di fferent values.
in this way dual slicing produces explanations for why two executions di ffer which can be useful for debugging89400.perlbench401.bzip2403.gcc .mcf .gobmk .hmmer458.sjeng .libquantum464.h264ref .omnetp473.astar .xalancbmkgeomean1.
.
.
.
.
.0normalized overheadbase pcce sic sei lei pepid fig.
.
normalized runtime median overhead of the di fferent epid techniques on spec cint2006 benchmarks.
error bar s show the confidence intervals for the mean of each technique.
1x input ... 3ifa b 4print x x ... if true ... print x ... if false true print a b c 3a 3b .
.
.
.
.
.
.
.
.
3a 3b d e fig.
.
a a program that can lead to bad dual slices using se i. b a trace where aistrue .
c a trace where bistrue .
d a dual slice using sei.
e a dual slice using pepid.
or for security analysis .
backward slicing techniq ues traditionally include too many dependences to be practical so dual slicing is particularly useful because it prun es away irrelevant dependences as it contrasts two executions .
epid techniques like sei form the foundation of dual slicing.
epids determine whether a dependence in one execution exists in another.
unfortunately when noncomprehens ive epids are used they can include unnecessary dependences in the slice defeating one of the main goals of the technique.
consider the program in fig.
11a.
this program reads an integer xfrom the user and prints it if either aorbistrue.
suppose there are two di fferent executions of the program one where the program prints and the other prints as shown in fig.
11b c. note that aistrue in one execution but only bis true in the other.
this matches the case we considered earlier in section ii c meaning that the print statements in the two executions have different epids under sei.
because the epids differ dual slicing considers them di fferent statements and also includes their control dependences.
the dual slice include s the different values of aand bvia control dependence even though they do not actually a ffect the output differences.
these irrelevant dependences get in the way and impede the user s ability to understand why the executions printed di fferent numbers as shown in fig.
11d.
here the arrows denote dependences in the dual slice.
in contrast a comprehensive technique li ke pepid is able to identify that the print statements occur at the same execution point and identify that the di ffering userinput for xcaused the different output.
fig.
11e shows the dual slice when using pepid and clearly identifies how the input difference directly caused the output di fference.
vi.
related work we examined several approaches from literature that compute epids for dynamic analyses .
each of these techniques has been used to solve real problems in dynamic analysis ranging from informing replay techniques to fine grained execution comparison .
the compariso n of these techniques along with our new epid computation technique pepid is one of the core contributions of this wo rk.
in developing pepid we based our system around the notion that the position within an unwound and unrolled cfg provides a notion of identity for execution points.
this was inspired in part by bounded model checking but model checkers do not need to consider the alternative high level semantics for unrolling degenerate irreducible loops.
sim ilar notions of identifying execution points also exist within s tatic analysis where k cfa provides a statically bounded approx imation of execution points using a similar intuition .
vii.
conclusion in this paper we examined several techniques for computing execution point ids epids and considered their strengths weaknesses and limitations.
to address limitations of int erexecution epids we introduced a new technique pepid that is able to comprehensively compute inter execution epids with significantly less space and runtime overhead than existing techniques.
pepid also produces more meaningful relationships between epids in di fferent executions.
finally we show that establishing these meaningful relationships i s useful in the context of real world dynamic analyses.