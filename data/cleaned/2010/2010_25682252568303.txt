data guided repair of selection statements divya gopinath sarfraz khurshid diptikalyan saha satish chandra university of texas at austin usa ibm research india samsung electronics usa divyagopinath khurshid utexas.edu diptsaha in.ibm.com schandra schandra.org abstract database centric programs form the backbone of many enterprise systems.
fixing defects in such programs takes much human effort due to the interplay between imperative code and database centric logic.
this paper presents a novel data driven approach for automated fixing of bugs in the selection condition of database statements e.g.
where clause of select statements a common form of bugs in such programs.
our key observation is that in real world data there is information latent in the distribution of data that can be useful to repair selection conditions efficiently.
given a faulty database program and input data only a part of which induces the defect our novelty is in determining the correct behavior for the defect inducing data by taking advantage of the information revealed by the rest of the data.
we accomplish this by employing semi supervised learning to predict the correct behavior for defect inducing data and by patching up any inaccuracies in the prediction by a sat based combinatorial search.
next we learn a compact decision tree for the correct behavior including the correct behavior on the defect inducing data.
this tree suggests a plausible fix to the selection condition.
we demonstrate the feasibility of our approach on seven realworld examples.
categories and subject descriptors d. .
reliability d. .
testing and debugging debugging aids general terms reliability algorithms languages keywords machine learning program repair databases data centric programs abap support vector machines sat .
introduction a majority of enterprise software systems are database centric programs.
defects in such programs specifically in database manipulating statements are expensive to fix and can require much permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
icse may june hyderabad india copyright acm ... .
.1select cstid price year from ordertab into itab 3sort itab by cstid 4del from itab where year and price 5loop at itab into wa at new cstid amount endat amount amount wa.price at end cstid write wa .cstid amount endat 13endloop figure a sample abap code segment.
human effort in understanding the interplay between traditional imperative code and database centric logic.
automated tools to help diagnose these defects and furthermore to assist with fixing them can make a substantial reduction in the cost of developing and maintaining database centric programs.
.
problem context our specific focus is on sap erp systems in which databasecentric programming is carried out in a proprietary language called abap.
abap contains sql like commands but it mixes imperative code and sql s declarative syntax.
we introduce the essential constructs of abap that are relevant for this paper using a small example figure .
the meaning of this abap code segment is straightforward.
at line it reads all rows from a database called ordertab into an internal table called itab.
the sort statement sorts this internal table by cstid which is the key.
the delstatement at line removes from itab those rows that match the condition described in the statement.
the loop at line iterates over itab.
when it encounters a new cstid that is when at new at line is true it resets an accumulator called amount and it prints the accumulated amount when the last record of that cstid has been visited this is done when at end on line is true.
at new andat end help with key wise aggregation akin to the sql group by construct.
table a sample input to program in figure .
the last column with is not a part of the input table.
cstid price year continued on right .
.
.cstid price year permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may june hyderabad india copyright acm ... .
suppose the program in figure is run on the database in table .
the rows marked are retained in itab after the delstatement.
the output of the program is which unfortunately differs from the expect output also shown id amount expected amount the bug arises from an error in the condition of the delstatement which causes the first row for cstid to be incorrectly deleted shown by a bold .
we can think of the delstatement as a equivalent select statement select from itab where year or price .
we call such a defect a selection bug because the bug is due to an incorrect where condition in a select statement.
the problem is to find an alternate where condition for the faulty select statement whose location is assumed to be known so that the entire output corresponding to each of the keys is correct.
selection bugs are common in abap programs.
in fact many database statements in abap programs allow a selection condition and therefore are vulnerable to a selection bug.
for example the abap read and delete adjacent statements can be modeled as selection statements.
based on our experience working with practitioners in ibm global business services about of the abap code level defects have to do with selection.
such bugs typically do not reveal themselves while testing with limited set of data that is available in the test environment.
the production environment has a lot more data and therefore exposes the corner cases that do not show up while testing.
moreover the lack of an automated testcase generation tool for this framework is another reason why such bugs are not discovered while testing.
therefore techniques that can help in fixing defective selection statements are of much value.
note that in our setting of debugging abap programs the process starts with the end user of this software filing a bug report citing a deviation of the actual output from the expected output on given input data.
thus the expected output of the program is already known to the programmer or the maintainer .
as we shall see the challenge here is in determining the correct behavior of the defective select statement from the expected output of the entire program and in determining an alternate where condition for the selection that would match the correct behavior .
an obvious technique to generate a correct selection condition would be to explore the space of syntactic mutations of the buggy condition.
because of the possible presence of data values in the clauses that constitute the conditions the search space for a mutationbased technique is immense.
the size of the mutation search space for our suite of benchmarks is reported in section .
this makes the technique very inefficient for real use.
in comparison our approach presented next sidesteps the drawbacks of a mutationbased approach.
.
a data driven approach an overview our key observation is that in real world data there is information latent in the distribution of data that can be useful to repair the where condition efficiently.
syntactic search completely ignores this latent information.
in this work we show that it is possible to find a good repair suggestion efficiently if we took advantage of this information.
in our approach we first discover the correct behavior of the selection statement on the failure causing input data and then find an alternate selection statement that exhibits the correct behavior.
our approach leverages the distribution of input data in both of these phases.
price year distribu.on of posi.vely and nega.vely labeled data pos neg tbd figure distribution of data in table a defective selection statement assigns incorrect or labels to some of the rows of the input for example some of the rows forcstid do not have the correct labels.
to discover the correct behavior of the defective selection statement we need to search through all possible assignments of labels to rows that have possible incorrect labels.
our technique carries out this search efficiently by taking advantage of the distribution of data.
since part of the output is correct we can assume that the rows that contributed to that part are labeled correctly the remaining rows are possibly mislabeled.
our premise is that a possibly mislabeled row that is geometrically close to a correctly labeled row is likely to require the same label.
obviously this notion of proximity is not guaranteed to produce the correct labels but they can serve as a very good starting point from which to carry out the search for the right labeling.
this is exactly what we do use a labeling computed on the basis of geometric proximity but fix it up based on local search around that labeling.
in figure data of passing keys in table is shown with diamonds for positively labeled data and squares for negatively labeled data.
for rows belonging to cstid whose labels as generated by the where condition are suspect data is shown with a triangle unlabeled .
assuming that points that are spatially close are likely to be labeled similarly an assignment of a positive label to the two unlabeled points on the right can be done with relatively high confidence.
the two unlabeled data points in the middle of the chart could go either way so an assignment of a negative label to the two points in the middle can be done only with low confidence.
table shows a sample assignment of predicted labels to the failing rows.
we generated these predications using an implementation of support vector machines svm .
informally svm creates separating lines a b and their center c as its best effort on how to separate positively and negatively labeled data.
in this particular example the line d would have be the perfect separator so the two points that are close to separator c are predicted incorrectly.
the incorrect lower confidence predictions can be fixed up by a combinatorial search for labels until we obtain correct labels for all the rows correctness validated by the final output matching the expected output .
we carry out this search iteratively starting with the table predicted label assignment for the failing rows cstid price year predicted label correct label confidence .
.
.
.
a split on year b split on price year price year price figure splitting the data points on the basis of alternative conditions row with the least confident prediction.
in realistic problem sizes this strategy which takes advantage of data distribution is significantly more efficient than combinatorial search on all the rows.
once we have the correct labels for all the rows the problem reduces to that of finding a function a classifier that attaches correct or labels to rows depending on the contents of the row.
as mentioned before it is difficult to find such a function by looking for syntactic variations on the existing where condition.
in general a vast number of different functions could produce the correct labels for a given set of rows.
not all of these would be close to the one intended by the programmer because they may be overfitted to the data in the sense that those functions may not label as yet unseen data correctly.
a common heuristic is to look for a compact function because it is more likely to be generalizable and therefore presumably correct.
we use the distribution of data to guide the search for a compact function using a well known technique known as decision tree learning.
this technique performs a greedy search over a space of functions being guided by the distribution of data and the label for each row of data.
the way this greedy search works is to first identify a predicate that classifies most of the data correctly and then iteratively identify additional predicates as required to classify the residual data.
in the running example first it would realize that partitioning the rows of the table on the basis of year gives the maximum though not perfect efficacy in terms of clubbing the and labeled rows in distinct partitions.
see figure a which shows the result of splitting on the basis of year again squares are negatively labeled points and diamonds are positively labeled points and the data is for the correct labels on all rows of table .
an alternate split say on the basis of price shown in fig b is less effective in clubbing the and labeled data in distinct partitions.
the id3 decision tree learning algorithm captures this intuition using the concept of information entropy and automatically chooses the most advantageous splitting predicate.
in the partition for which year the maximum efficacy is obtained by further partitioning on the basis of price at which point all positives are perfectly separated from the negatives.
in the partition for which year all rows are positive regardless of the price.
this decision tree is written as conjunctions of clauses on paths from root to ve leaf nodes and disjunction over such paths year 2008 year price .
by demorgan s laws this simplifies to the following condition year 2008 price 8comparing this to the previous incorrect where condition we see that while the learned where clause for year is slightly but gratuitously different for price it is crucially different.
our technique manages to find natural conditions that a programmer would have written and therefore ends up offering useful repair suggestions.
we attribute this desirable property to our data guided approach.
a where condition that a programmer1repair s out correctout key fields trace initialize 4find fkeys pkeys sfkeys spkeys step predict labels for failing keys input of s 7projprediction inputprediction map prodtbl predict sfkeys spkeys sin sout s step correct label computation 11scorrectoutset label s trace sfkeys projprediction step where condition generation 15generate conditions scorrectoutset prodtbl map inputprediction figure algorithm generating repair suggestions for selection statement writes is intended to classify regions of data uniformly as opposed to cherry picking points in the data space and classifying them individually by some complex conditional logic.
this is the reason that predictions based on spatial proximity work well and also the reason that the heuristic of finding a compact decision tree works.
.
contributions our contributions are the following .
we describe a new approach for repairing faulty selection conditions in database statements.
our approach tries to extract information from the way the incumbent selection condition treats the part of the data that exhibits correct behavior and from the relative distribution of passing and defect inducing data.
.
we give a new way of combining machine learning and combinatorial search in determining the correct labels for the failing keys.
the learning part takes advantage of the known behavior for the passing keys whereas the combinatorial part makes up for cases in which the knowledge from passing keys does not extend perfectly to the failing keys.
.
we present an evaluation of the proposed approach on a suite of programs drawn from an industrial setting.
these programs are excerpts of real programs 1and the data sets we use come from real data this is crucial because the effectiveness of our approach cannot be gauged based on synthetic data which may not be representative of distributions found in real data.
the evaluation indicates promise in the approach.
.
repair algorithm in this section we describe the repair algorithm in detail.
as shown in figure the algorithm has three major steps exploit the distribution of data to predict the selection result for the input rows of the faulty selection statement verify the predictions and if required determine the selection result using combinatorial search for the parts where the predictions are incorrect and generate correct conditions using decision tree learning algorithm.
we illustrate the steps of the algorithm using an example shown in figure .
the example is a slight variation of the example presented in section to illustrate some salient features of the algorithm.
the select statement shown in lines is the faulty statement.
below are the entities used in the algorithm 1the excerpts of real programs the buggy selection conditions and their fixes are available at 2451select cstid price year 2from order material into itab 3where item itemid 4and year 5loop at itab into wa 6at new cstid amount 8endat 9amount amount wa.price 10at end cstid write wa .cstid amount 12end at 13endloopprogram output out cstid total correct program output correctout cstid total select statement input sin order cstid item i1 i2 i3 i4 i5 i6 i7 i8 i9 i10 i11material itemid year price i1 i2 i3 i4 i5 i6 i7 i8 i9 i10 i11 10stmt.
output sout cstid price year correct stmt.
output scorrectout cstid price year figure an abap program and data s is the select statement trace the execution trace which produces incorrect output.
s the trace occurrence of the faulty statement sin sout the set of input tables and current output of s out incorrect program output correctout expected correct program output scorrectout a correct output of swhich can produce correctout key fields a set of fields which uniquely identifies each row of out the out correctout sin sout scorrectout for the example are shown in figure .
in the domain of data centric programs each row in the output is identified by a set of field value pairs called key.
the algorithm compares the current program output out and the expected output correctout to determine a set of failing keys fkeys and passing keys pkeys for the program output.
a passing key is a set of key field value pairs which identifies identical rows in outand correctout .
a failing key is a set of key field value pairs which identifies a row which exists in outbut not in correctout or vice versa or identifies a row in outand a row in correctout which differ in at least one non key field value.
in the example cstid is the passing key whereas cstid andcstid are the failing keys.
note that cstid corresponds to a missing row in the output.
all the input rows in s obtained using the cartesian product of all tables in sin that directly or indirectly affect the failing rows incorrect missing unwanted in the program output are considered asfailing input rows and the rest are considered as passing input rows .
such classification is performed based on a key based dependency analysis between the passing and failing keys in the output of the program and the input rows in s. the set of passing and failing keys for sare denoted as spkeys and sfkeys .
in the example rows corresponding to hcstid 1iandhcstid 2iaresfkey rows and those corresponding to hcstid 3iarespkey rows.
as described in section the prediction algorithm predicts the selection result for the rows corresponding to sfkeys using the selection result for the spkey rows.1predict sfkeys spkeys sin sout s svm in empty prodtbl empty for each t2sin prodtbl prodtbl x t creating classification for prediction 7for each r2prodtbl r class if r .key2sfkeys r class if r .key2spkeys selection r s r class 1if r .key2spkeys !selection r s svm in.add r r class label input rows set r r predict in prediction svm svm in where r predict is a real number label projected rows for joined table in input for each r2prodtbl st .r.key2sfkeys projected row projection r s map projected row .add r for each projectedrow p in map .keyset predict p max in prediction r r2map p return predict in prediction map prodtbl figure algorithm prediction 1label s trace sfkeys prediction 2model code 2model trace s 3scorrectoutset empty 4for each sfkey 2sfkeys threshold while true label empty for each p2prediction .keyset s .t.p.key sfkey predvalue prediction .get p if predvalue threshold label p true if predvalue label p false if predvalue keycorrectoutset sat label model correctout if keycorrectoutset is empty threshold threshold paramthresholdincrement if threshold maximum confidence value return failure else continue else break scorrectoutset scorrectoutset x keycorrectoutset add passing key data to each selection in scorrectoutset return scorrectoutset figure algorithm labeling for failing keys prediction of correct output of s.the function predict in figure first creates the input prodtbl by performing the cartesian product of all input tables in the example material andorder then assigns label signifying rows whose values are to be predicted to the input rows corresponding to sfkeys .
the existing selection clause behaves either selects or deselects correctly for thespkey rows.
each passing row in the input is thus classified as if the row has been selected and if the row has not been selected denoting known and correct classification lines .
this forms the input to an svm which assigns to each input row with label a signed value called prediction line .
the sign called label indicates whether the input row has been predicted to be selected positive value or not selected negative value .
the unsigned prediction value denotes the confidence associated with the prediction.
in the example the prodtbl contains rows of them are for cstid and rows are for cstid which are marked .
the remaining rows for cstid are labeled rows or rows .246note that a select statement first performs a selection of the rows in prodtbl followed by a projection to generate the output ofs projected rows .
the set of input rows which correspond to a projected row is called the block of the projected row.
a projected row is in the output of s if at least one input row from its block is selected.
svm is employed to predict the outcome of the selection of the input rows.
our algorithm uses this to determine the prediction for the projected rows lines .
the likelihood of a projected row being present in the output of s is determined by the maximum likelihood of selection of the input rows in its block.
the algorithm determines the prediction of the projected row as the maximum prediction signed value of all the rows in its block.
in the example there are rows in the prodtbl which project to rows rows per key.
the predictions for the projected rows ofcstid andcstid are shown below.
cstid projected rows cstid price year pred.
.
.
1cstid projected rows cstid price year pred.
.
.
.
the salient features of this step are summarized here determining passing and failing input rows and exploiting the data distribution to predict selection results of the failing input rows.
mapping prediction values from input rows to the projected rows based on the maximum likelihood of selection.
determining correct output of s.the next step is to use these signed values to determine the part of scorrectout corresponding to the failing keys.
the algorithm described in figure tries to determine this per failing key line for a reason described later.
first the output of sis created strictly as per the predicted labeling.
the label is determined by the sign of prediction which if positive denotes that the row is to be selected to the output and not selected label false if negative.
if this does not yield the correctout then the projected rows corresponding to thesfkeys are gradually unlabeled.
the decision whether a row would be unlabeled is done based the confidence of its prediction.
a parameter threshold is used to gradually un label low confidence projected rows.
a projected row having confidence value above this threshold is labeled.
note that the algorithm starts with threshold value zero to make all the projected rows labeled.
in the running example for cstid the prediction selects only one row with price corresponding to item i1 whereas for cstid it selects rows with price values i3 i5 and i6 .
next we discuss how we verify whether the labeling based on predictions yields scorrectout and if not how we use combinatorial search to label the rows whose predictions are relaxed based on the threshold adjustment.
ifscontains a selection bug then there exists a subset of its projected rows that can produce the expected program output.
there can be combinatorial number of ways to create subsets of the projected rows.
we employ a sat solver to efficiently search for subset s that lead to the final program output matching correctout .
the scalability of the search depends on the input table size which is usually large.
to reduce space we perform this search separately for every failing key.
further as described earlier we1generate conditions scorrectoutset prodtbl map inputpred 3conditionset empty 4for each scorrectout 2scorrectoutset weight scorrectout average prediction value of sfkey rows in answer 7rankedset sort scorrectoutset based on weights 8for each scorrectout 2rankedset in order c getcondition prodtbl scorrectout map prediction conditionset .add c if no more results required return conditionset 15getcondition prodtbl scorrectout map predictedlabels for each projectedrow p 2map .keyset if p2scorrectout max pred maximum prediction of rows in map .get p for each r2map .get p r pred predictedlabels .get r class r if r pred max pred or r pred threshold r pred if r pred threshold r pred else for each r2map .get p class r return id class figure algorithm selection condition generation rely on the predicted labelings for rows whose confidence is greater than threshold and perform combinatorial search only on the remaining unlabeled rows.
the algorithm creates a model of the code which can execute aftersas a first order formula using alloy line .
the details of the translation is not provided in this paper but is available at .
a sat solver line is used to validate if the predicted labeling yields the correct output for the respective sfkey and if not perform combinatorial search to find such a labeling.
it either returns no solution or returns a set of correct selections per failing key.
the sat solver may not yield any satisfying truth assignments to the unlabeled projected rows for a failing key.
this can be attributed to incorrect labels for rows marked based on the predictions.
in this case the algorithm increases the threshold to un label some more low confident projected rows.
iteration based on adjusting threshold increases the domain size for combinatorial search.
however in our experiments we have seen that many iterations are seldom needed.
in the running example sat solver validates the prediction for cstid but fails for cstid yields total expected .
the low confidence projected rows for cstid corresponding to itemid i4 i5 i6 are unlabeled.
combinatorial search in the second iteration yields two satisfactory combinations for cstid i3 i4 i5 and i3 i6 .
both of them yield total price value as in correctout .
combining all solutions for failing keys line and adding the passing key selection line the algorithm generates the following two scorrectout s. cstid price year 2012cstid price year 2012247note that considering each failing key separately has another advantage apart from reducing the search space.
it avoids unnecessary un labeling of rows corresponding to keys for which the current labeling yields the correct output for the respective keys.
the salient features of this step are summarized below an iterative algorithm to label fewer projected rows based on predictions if the current labeling does not yield scorrectout .
performing sat based combinatorial search on a per failing key basis to determine the set of correct outputs for s. selection condition generation.
the algorithm for selection condition generation is presented in figure .
the generation of selection condition is performed using a home grown implementation of the id3 decision tree learning algorithm which learns a classifier that provides accurate classification for the training data.
the function id3takes the selection result for the input rows to derive a compact condition satisfying the selection.
the algorithm first ranks the set of correct outputs of sobtained in the previous step and calls the function getcondition corresponding to each scorrectout in order of the ranking.
lines .
the function getcondition classifies each input row of swith or based on the correct labeling for the projected rows.
this is a reverse label mapping of what is done in function predict .
if the projected row is not present in the scorrectout then all the input rows in its corresponding block should not be selected line .
if a projected row is in output then one or more corresponding input rows can be selected.
we mark the input row with the maximum prediction value as the one to be selected.
line .
for each of the other rows in the block we use the predicted label if its confidence is higher than the running threshold lines .
lesser confidence rows are not fed to the decision tree learner.
finally id3 is called with the classified input.
the conditions generated using this method are shown below item itemid and year item itemid and year or price note that the first condition is more preferable over the second as it is more compact and not overfitted to a specific value hence it has more chances of being valid for unseen inputs.
in general there can be many solutions given by combinatorial search.
since generating all possible repair suggestions is time consuming our approach selects as input to the decision tree learner the solution which has the potential to generate a good selection condition.
the algorithm first ranks the solutions figure line based on the average prediction value of the projected rows present in the respective scorrectout s. in our example for cstid the weight of the first solution consisting of items i3 i6is .
.
whereas it is .
.
.
for the second solution corresponding to the selection i3 i4 i5.
based on our heuristics the first solution is preferred over the second as the first solution has i4 which is predicted to not be selected.
the basis of labeling input rows and ranking solutions is the same it is possible to generate better quality condition by following the svm prediction.
there could be multiple outputs to theselect statement that yield the expected output of the program however the where condition generated based on the labelings predicted by svm is the most natural condition or closest to the ideal manual repair refer section for experimental validation the salient features of the final step are summarized below ranking multiple solutions returned by combinatorial search.
labeling input rows based on the correct labels for the projected rows.
using id3 to generate compact selection conditions.
more subtle variations of the algorithm such as handling of multiple occurrences of the faulty statement and variations in threshold adjustment are available in .
pragmatics.
the application of svms to the problem at hand requires several steps of data conditioning.
the main issue is that svms prefer to view data as numerical values for the purpose of distance computation.
relational database tables seldom contain data in this form.
we discuss the problems and our solutions.
nominal attributes the table could contain nominal attributes which are compared for equality but not for order.
for example state letter state abbreviation is a nominal attribute.
for such data we introduce fresh columns one for each distinct value of the nominal attribute that appears in tables.
for state we might introduce boolean attributes such as state ak tostate wy and hide the original state attribute.
at other times data that looks like non numeric data might need to be treated numerically.
for example dates have to be mapped to a numeric interval.
key attributes keys are usually nominal data in that value based proximity of two keys is not meaningful.
table joins created by cartesian cross product of two tables contain distinct key attributes coming from each of the tables in the join.
since it would require too many additional attributes to de nominalize these key attributes we instead include an additional boolean attribute that denotes the equality of these two keys as it is common to have key equality comparison in select statements for a natural join.
scaling it is typical in the use of svms to scale data to a normalized range for each attribute.
in case the range of data for a certain attribute is very large due to a few outliers care is needed to prevent lower values being scaled down to too close to zero.
selecting relevant attributes for id3.
the input tables of the buggy query typically have large number of attributes many of which are irrelevant.
we heuristically perform the following selection of potentially relevant attributes all attributes projected by the query attributes that have been frequently used whenever this table has been used earlier in the code such as key attributes .
attributes having the same data type and overlapping values with the state variables at that execution point.
seeding synthetic attributes in id3.
decision tree based algorithms are only equipped to learn clauses that compare attribute values with constants.
however where conditions can contain comparison of two attributes.
we seed binary valued equality predicates between attributes as extra attributes into the learning algorithm.
these predicates are seeded based on domain knowledge for instance attributes of the same data type and having same range of values may be compared to select records.
in the current state of our tool each of the three modules of the algorithm are automated except as follows predict requires dataconditioning as described above label works based on a manual translation of the abap code fragment to forge intermediate language following the pseudo code in and generate conditions requires heuristic selection and seeding of attributes.
.
case studies this section first presents a summary of the experimental results which is subsequently explained using case studies of a select set of subject programs.
finally it discusses relevant research questions and limitations of our approach.248table summary of results.
time in minutes.
subjects passing failing prediction accuracy correct label computation decision tree learning input rows input rows correct labels time search space iterations soln.
time useful repair suggestion?
ex1 .
yes ex2 .
yes ex3 .
yes ex4 .
.
no ex5 .
.
yes ex6 .
yes ex7 yes we selected seven subject programs which are fragments of abap code from industrial applications running on real data sets.
the criteria employed to select these subjects were cover different types of selection bugs commonly found in bug reports highlight the different characteristics and design decisions of the repair algorithm.
our evaluation covers different types of statements such as select statements on single tables and joins of tables with buggy where clauses and delete statements with buggy comparing clauses.
the repair is applied on different types of faults such as missing field checks incorrect data value used in the conditions incorrect missing join conditions and also incorrect missing range checks equivalent to two missing conditions .
the subjects fit into different scenarios section .
highlighting the different features of our approach.
the excerpts of real programs the buggy selection conditions and their fixes are available at .
the bugs in these programs are actual bugs that occurred in the past.
in all cases we know the manual fix to the bug.
our implementation uses the alloy .
tool set specifically forge kodkod and minisat svm light in transductive learning mode and a home grown implementation of the id3 decision tree learning algorithm.
all experiments were conducted in a .53ghz cpu 4gb ram laptop running ubuntu linux.
the summary of our experimental results is shown in table .
for every candidate we recorded the number of rows in the input table corresponding to the passing and failing keys shown as passing input rows and failing input rows respectively in table .
column highlights the prediction accuracy i.e.
the of failing rows for which the labels were predicted correctly.
we also tabulate the total time for correct label computation dominated by sat solving times the combinatorial search space the total number of threshold relaxation iterations and the number of scorrectout s generated.
we also present the time to learn the where condition.
finally we state whether the repair suggestion was useful or not by comparing how close it was with the manual fix for the bug.
.
example scenarios we describe details of applying our approach to four subjects to highlight some of its key characteristics and how it handles different types of faults.
scenario accurate predications.
we start with a simple case where a straightforward application of our approach produces a repair very quickly.
consider the following buggy select statement in ex3 select from ekbe into table tab ekbe where vgabe eq or vgabe eq and ebeln in ebeln range .needed in the correct query the where clause is essentially missing two predicates in the form of a missing range check predicate for the field ebeln .
this error results in unexpected rows in the output of the program.correct label computation .
the incorrect rows in the program output correspond to failing rows in the input ekbe table.
each row corresponds to a unique key value so there are sfkeys .
the number of passing key rows are much higher spkeys .
the predictions were accurate.
all the sfkey input rows were given negative prediction values by svm.
our algorithm assigns all the rows with negative labels in the first iteration.
this labeling was verified by sat to produce the correct output within a minute.
decision tree learning.
the decision tree learning module was invoked with the passing rows labeled as per the existing output of the statement and the failing rows marked with negative labels.
the condition learned was as given below and was correct in not selecting exactly the failing rows.
vgabe and ebeln 4500000229the generation of a comparison on ebeln conveys to the programmer that a bound check is missing.
indeed the source code defines the constant ebeln range as ebeln low ebeln high but the buggy query fails to use it.
because of the data distribution in this test case the generated repair condition does not contain the the lower bound on ebeln nor could it generate the additional condition on vgabe .
however the generated condition presents a useful hint to the user to add the missing bound check on ebeln .
scenario .
select with table joins.
this scenario illustrates a case where highly accurate prediction helps to significantly reduce the combinatorial search space for labeling.
the program ex1 creates a sales order report by calculating order amount and unbilled amount for each sales order.
it first creates a table called p i vbrp using the following query select vbeln posnr aubel aupos matnr netwr from vbrp p i vbap into table p i vbrp where aubel p i vbap vbeln and aupos p i vbap posnr and netwr .needed in the correct query however the missing netwr predicate from the where condition causes incorrect p i vbrp formation shown below for the key aubel .
computed aubel aupos netwr .
.
.
.00expected aubel aupos netwr .
.
the program logic after the select statement reads the rows and corresponding to two posnr values20and30 instead of and which it would have read from the correct version of the table.
this leads to the incorrect output for the failing key .
altogether there are failing keys in this example.249correct label computation .
there were passing input rows that were labeled as per their outcome in the existing execution.
failing input rows were unlabeled.
svm attached a positive prediction to unlabeled rows and a negative prediction to the remaining.
as noted in table in this case the prediction is highly accurate .
leaving only input rows incorrectly predicted.
each of these rows corresponds to a distinct failing key.
and happens to be the one with the maximum prediction value in the block of the respective projected row.
thus for each of the failing keys the projected row was incorrectly labeled.
for each key the iterative threshold adjustment process was invoked until a correct solution was found.
for example for key initially both rows were marked negative as shown below leading to unsatisfiability.
aubel aupos netwr pred .
.39996994with a threshold of .
the second row with confidence less than .
was assigned an unknown label to be determined by sat while the first row was given negative label.
the same was done with the other two failing key records.
sat assigned positive labels to these rows leading to satisfiable solutions.
in all this process completed in minutes.
utilizing predictions produces a total search space of for the sat solver.
we also give an estimate of the combinatorial search space if predictions had not been used at all.
for each of the failing keys on average there are projected rows where each projected row maps to a block size of input rows.
for each failing key the state space for choosing the set of projected rows that yield the correct output is .
each solution comprising of projected rows needs to be mapped to input rows of the joined table before being fed to the id3.
the state space for this would be 2273in worst case when the solution contains all three projected rows.
thus the total search space in worst case to generate correct condition without using any predictions would .
as explained earlier use of predictions helps reduce this space to just .
decision tree learning .
decision tree learning discovered the correct where condition aubel p i vbap vbeln and aupos p i vbap posnr and netwr 6note that our approach was able to learn the join condition.
for each projected row the input row that is selected from the corresponding block is critical in determining the correct join condition.
we would like to highlight that for the given data the only input row in every block that satisfied the join condition was the one with maximum prediction value in that block.
hence the selection of any other row from the block would have not lead to the discovery of the join condition.
this adds evidence to the fact that our design decision of selecting the row with maximum prediction value would result in producing high quality conditions close to the ideal.
the constant discovered is rather than due to the distribution of the data.
but it is a good repair suggestion since it points out an important missing clause.
scenario .
use of predictions to rank candidate solutions.
this scenario highlights that our repair algorithm is not restricted only to select statements and further illustrates a case where predictions aid in reducing the space of candidate solutions on which decision tree learning has to be performed.
the buggy statement in this example ex2 is a delete statement shown below.
delete adjacent duplicates from db tab comparing kunnr matnr arktx needed in the correct querythe delete adjacent duplicates statement deletes a row from the table that has same values in its immediately previous row for the fields specified in comparing clause.
this could be modeled as an equivalent select statement as shown below.
select from db tab rc as db tab db tab rc as db tab2 where db tab .rc db tab .rc 1and db tab .kunnr db tab .kunnr and db tab .matnr db tab .matnr and db tab1.arktx db tab2.arktx needed in correct query where db tab rc has an extra column rcin addition to all the columns of db tab .
it contains the same records as db tab with therccolumn populated with the row number.
this statement selects rows that would need to be deleted by the original statement.
the code after the delete statement in a nutshell aggregates the netwr amounts corresponding to every unique value in monat field on db tab .
the output report has incorrect amounts displayed for two monat values sep2008 andoct2008 failing keys .
correct label computation.
the db tab has records with monat assep2008 and records with oct2008 .
note that although the select is over a join and every row of db tab rc maps to a block of rows in the joined table we know upfront the exact record that needs to be considered from every block.
to comply with the semantics of delete adjacent duplicates the only record that can be selected in the block corresponding to every failing row of db tab is the one where db tab1.rc db tab2.rc is satisfied.
hence the search space remains and respectively for the two failing keys.
label predictions.
there are only positively labeled passing key records compare to negatively labeled records in the joined table.
hence the accuracy of predicting positive labels is low.
all rows are assigned prediction values .
and .
.
the first iteration assigning all failing key rows with negative labels was unsatisfiable.
however with a threshold of .
rows with prediction values .
were marked negative while the remaining were assigned labels based on sat based search.
for sep2008 there was exactly one correct solution while for oct2008 there were possible correct solutions.
the reason for the large space of possibilities in the latter case was that there were records with netwr amounts of .
the presence or absence of each of these records yields the same final output.
hence sat produces different solutions yielding the expected output.
it would be inefficient to generate possible where clauses.
this is where predictions aid in heuristically selecting the solution that is most likely to yield the ideal where clause.
label predictions based solution ranking.
the solutions were ranked based on their average prediction values.
the solution with the highest average prediction value is the one whose constituent rows have the highest likelihood of being assigned positive labels.
in practice the decision tree learning would be invoked on the highest ranked solution first the condition would be presented to the user and conditions for the remaining solutions would be generated only if the user is not satisfied with the first condition.
however for our experiment we invoked the decision tree learning on all the solutions to evaluate the efficacy of our selection heuristic.
decision tree learning .
the where clause of the select statement learnt for the highest ranked solution was db tab1.rc db tab2.rc and db tab1.kunnr db tab2.kunnr and db tab1.arktx db tab2.arktxas can be observed the condition on arktx that was missing in the incorrect version is correctly discovered.
however the condition onmatnr is missing from the learned clause.
this is because the250matnr values are equal for all adjacent records in which the other two conditions are also satisfied.
this makes the learned where clause correct for the given input set.
the conditions learnt for the other solutions with lower ranks were of poorer quality.
as can be seen from the numbers shown below the number of clauses present in the conditions generated from the other solutions were very high.
these conditions were overfitted and very different from the intended fix.
of clauses of solutions 2scenario .
impact of incorrect selection on passing keys .ex4 displays an interesting scenario which violates our assumption about the correctness of erroneous select statement for the passing keys.
the final output corresponding to passing keys is still correct but the select acts incorrectly on some of them.
the erroneous select statement given below leads to the inclusion of extra records for the failing keys in the actual output of the program compared to the expected correct output.
select ebeln ebelp belnr buzei bewtp budat matnr werks ernam from ekbe into table it ekbe where budat in s crdate and vgabe needed in the correct query in this example for the passing keys too the erroneous select statement selected some extra rows but subsequently they got deleted by a delete statement in the program.
consequently these passing keys yielded the correct final output anyway.
correct label computation .
the incorrect labeling for passing key records where vgabe impacts the accuracy of predictions as seen from table .
hence the approach of using predictions to label records performs poorly.
the algorithm passes through iterations of threshold adjustment and produces correct solution only when all records are labeled based on sat based search.
decision tree learning .
the incorrect labeling of the passing key records impacts the where clause condition learned.
belnr or budat or budat and ebeln the condition is quite different from the one in the correct version of the code.
it leads to the expected final output on this data set but this is not a useful repair suggestion.
.
discussion based on our experimental evaluation we address the following key research questions.
rq1.
do the predictions based on the data distribution aid in finding the correct output for the failing keys efficiently?
in all cases prediction based labeling of rows helps in determining a correct output state to the faulty statement within minutes in the worst case.
the efficiency of our algorithm is attributed to high prediction accuracy which effectively reduces the combinatorial search space and further design decisions such as an iterative threshold relaxation strategy which judiciously un labels incorrect predictions.
the low number of iterations in most cases suggest that there were only few incorrect predictions that needed to be labeled by sat ranking of solutions based on predictions which saves the effort of generating conditions corresponding to all the solutions.as noted in scenario ex1 in the absence of predictions in the worst case a combinatorial search based strategy has to explore huge search space to arrive at useful solution.
even for subjects that do not involve joins predictions based labeling brings about significant reduction in search spaces reduction from a total of 220forex2 and almost reduction from a total of forex5.
rq2.
how useful are the repair suggestions?
the usefulness of the generated repair suggestions is summarized in the last column of table .
except for ex4 the repair suggestions were close to manual ideal fixes for the bugs.
the reason for high quality of our repair suggestions can be attributed to the labeling of failing key data based on its proximity to passing key data which generates the conditions that classify regions of data uniformly which is typical of where clauses.
even though theoretically it is possible to generate many scorrectout s which generate the expected correct output of the program our approach only generates few of them based on the prediction.
this in turn generates few good conditions which are close to the ideal fix.
forex6 we show below the manual fix and the condition generated by our approach using a solution that respects the predicted labels.
in this case p p werks is a parameter to the program which had a value gbs1.
as can be seen this condition is very close the ideal fix.
ideal fix for ex6 vbeln p i vbak vbeln and werks p p werkscondition learned from a solution based on predictions vbeln p i vbak vbeln and werks gbs1 we also show few conditions generated from other solutions that yield correctout but do not use the predicted labels.
clearly such solutions are far away from the ideal fix.
conditions learned from other solutions vbeln p i vbak vbeln and werks gbs1 and vbeln .
and waer eur or waer usd and posnr .
or vbeln .
vbeln p i vbak vbeln and werks gbs1 and vbeln .
and netwr .
or netwr .
or vbeln .
rq3.
is syntactic mutation technique feasible for real data?
to check the feasibility of mutation based repair we consider a repair strategy which checks if the where condition could be corrected by either adding one clause removing one existing clause or replacing an existing clause with a new one.
clauses of the form field operator field field operator constant and field operator variable are considered as mutants.
subjects mutation based repair time min space ex1 .
ex2 ex3 .
ex4 .
ex5 .
ex6 .
ex7 147350in almost all the cases the search space of the number of mutants is very huge in the order of leading to a blow up in the worst case exploration time in the order of hours assuming an average of seconds to execute mutant .
the main reason being the large number of distinct values that could be compared in the clauses of the form field operator constant .
an algorithm that does not consider clauses that involve constants would work much faster however it would be unsuccessful in discovering the correct where condition for bugs such as in ex1 ex3 and ex7.251limitations.
.
our technique assumes that the incorrect selection criteria works correctly for keys that satisfy the final output correctness criteria.
violation of this assumption ex4 impacts the quality of the predictions and the where condition learned.
.
sufficient amount of diverse passing data is required to make the learning effective.
for example in ex7 the failing rows were all erroneously predicted to be negatively labeled.
this is because majority of the rows corresponding to the passing keys were negatively labeled very few rows were positively labeled.
.
attention must be paid to data conditioning which currently uses heuristics based tuning described in pragmatics in section to arrive at good label prediction.
.
id3 algorithm is designed to correctly label all training data.
however if the data in the current execution is not representative enough then the where condition created may be overfitted to the data ex4 .
techniques to avoid overfitting compromise the accurate labeling of training data.
finding the right balance for our application is the subject of future work.
.
our algorithm strives to generate the most compact classifier for the given data.
in some cases this could exclude clauses that would be in general necessary but do not impact the outcome for the given data.
to reiterate our technique generates useful repair suggestions and not necessarily plug and play repairs.
.
related work recent years have seen much progress in techniques for automated debugging both for fault localization i.e.
finding the locations of likely faulty lines of code as well as program repair i.e.
correcting the faulty lines of code to fix the fault s which is the focus of this paper.
fault localization.
the application of machine learning to debugging is largely confined to fault localization.
decision tree generation algorithms including c4.
have been used in conjunction with the fault localization tool tarantula to cluster failing tests in order to help developers manually fix bugs in their code more effectively .
statistical debugging techniques employ statistical analysis on the data collected from passing and failing program runs to determine likely faulty statements.
program repair.
the problem of program repair has been the focus of a number of recent techniques including those based on evolutionary algorithms specifications program code transformations as well as program state mutations .
the key novelty of our technique with respect to previous work is two fold previous work has not considered repair of sql statements in general and abap programs in particular and machine learning and systematic search have not been integrated before for program repair.
jobstmann et al.
employed a technique to replace faulty program expressions with unknowns and formed a model checking problem in order to repair a faulty program with respect to its linear time logic specification.
griesmayer et al.
map the problem or repairing boolean programs to finding a memoryless stackless strategy in a game and explore the game graph to find a repair for the boolean program and show how it can be used to repair a class of c programs.
malik et al.
use a search based technique for data structure repair as a basis of program repair.
specifically they use mutations done on program state to fix corrupt data structures as a basis of synthesizing program statements that abstract those fixes using program variables.
gopinath et al.
introduce nondeterminism in the program s operations and use sat solvers to generate valid program states with respect to given specifications which are then abstracted into program expressions that evaluate tothose states and provide the fixes.
chandra et al.
use changes to program states in a faulty program to approximate the behavior of a correct program with respect to a given set of passing and failing tests and use these state mutations to guide syntactic changes to code in order to repair it.
weimer et al.
introduced the idea of program repair using genetic programming where existing parts of code are used to patch faults in other parts of code and patching is restricted to those parts that are relevant to the fault.
ackling et al.
simplifies the repair problem by evolving patches to fix the faulty program rather than evolving the program itself.
debroy et al.
used syntactic mutations to repair faults.
the technique is in the context of tarantula and uses passing and failing tests to focus mutations.
however the approach fails to scale to real world applications.
wei et al.
represent class contracts and execution profiles of tests in terms of boolean queries methods of the class.
a comparison between failing and passing profiles is performed for fault localization and a subsequent program synthesis effort generates the repaired statements.
program synthesis.
a closely related area to program repair is program synthesis where the goal is to generate parts of a program independently of a given incorrect version.
a number of program synthesis techniques are based on specifications .
programming by sketching employs sat solvers to generate missing parts of a given skeletal program with respect to another reference program that serves as a specification.
a sat solver completes the implementation details by generating expressions to fill the holes of the skeletal program by exploring several of its variants.
kuncak et al.
generalize decision procedures into synthesis procedures to synthesize code snippets from specifications.
some recent techniques support synthesis based on given concrete input output examples.
gulwani presents such a technique for synthesizing string processing code for spreadsheets using examples of how a user processes sample strings.
more recently singh et al.
integrate scenarios which illustrate steps of modifying specific data structure instances with given code skeletons and inductive definitions to facilitate program synthesis.
at present techniques for synthesis have largely been developed independently of techniques for repair.
.
conclusion and future work we presented a novel approach to generate repair suggestions for defective database programs with faults in the selection condition of database statements.
our key novelty is to determine the correct behavior of the defect inducing data using a combination of satbased search and prediction generated by support vector machines.
we learn a decision tree from the behavior shown on the defectfree data as well as the correct behavior determined for the defectinducing data.
the decision tree provides useful repair suggestions.
experiments using a prototype of our approach on a suite of real programs show the promise it holds in automated debugging.
while our current work focuses on repairing database statements we envisage an extension of our idea of data driven repair to more general imperative programs.
a direct application would be to correct faulty branch conditions that are covered by both passing and failing tests.
the outcomes of the condition on faulty runs could be predicted based on passing runs which in turn could be used to learn a condition that works correctly for all the tests.
.