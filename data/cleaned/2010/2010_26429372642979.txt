automated analysis of multithreaded programs for p erformance modeling alexander tarvo brown university providence ri usa alexta cs.brown.edusteven p .
reiss brown university providence ri usa spr cs.brown.edu abstract the behavior of multithreaded programs is often difficult to understand and predict.
synchronization operations and limited computational resources combine to produce complex non linear dependencies between a program s configuration parameters and its performance.
performance models are used to understand these dependencies.
such models are complex and constructing them requires a solid understanding of the program s behavior.
as a result building models of complex applications manually is extremely timeconsuming and error prone.
in this paper we demonstrate that such models can be built automatically.
this paper presents our approach for automatically modeling multithreaded programs.
our framework uses a combination of static and dynamic analyses of a single representative run of a system to build a model that can then be explored under a variety of configurations.
we show how the models are constructedandshow theyaccurately predict the performance of various multithreaded programs including complex industrial applications.
categories and subject descriptors f. .
logics and meaning of programs program analysis c. performance of systems modeling techniques keywords program analysis performance modeling .
introduction multithreaded programs demonstrate complex non linear dependencybetweentheconfigurationandperformance.
configurations may reflect variations in the workload program options such as the number of threads and characteristics of the hardware.
to better understand this dependency a performance prediction model is used.
sucha model predicts performance of a program in different configurations.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
ase september vasteras sweden.
copyright acm ... .
.
.performance models are essential for various applications .
for example a model may help finding a good configuration for deploying the tomcat web server.
for each combination of configuration parameters including the number of cpu cores the number of tomcat working threads or the rate of incoming connections the model will predict response time throughput and resource utilization for tomcat.
a configuration that utilizes resources efficiently and satisfies the service agreement can be used for deployment.
performance models canbe also used todetectperformance anomalies and discover bottlenecks in the program.
modern multithreaded applications can be large and complex and are updated regularly.
building their models manually is extremely time consuming and error prone.
to be practical building such models should be automated.
building performance models of such applications is hard.
first it requires discovering queues threads and locks in theprogram details oftheir behavior andsemantics oftheir interaction.
this automatically requires complex program analysis.
second it requires measuring demand for hardware resources such as the cpu disk and the network.
this is a complex problem that requires collecting and combining information from multiple sources.
third the performance of a parallel system is dependent on its contention for computation resources and locks.
accurate modeling requires simulating these resources and locks in detail.
this paper presents an approach towards automated performance modeling of multithreaded programs.
its main contribution is a combination of a model that accurately simulates complex thread interactions in a program and a methodology to build such models automatically.
the paper makes the following technical contributions a combination of static and dynamic analyses for understanding the structure and semantics of multithreaded programs automatically an approach for collecting parameters of performance models from user and kernel mode traces verification of our approach by constructing models of various multithreaded programs while working on the automatic model building we made importantfindings.
first theanalysisofaprogramisgreatly simplified if that program relies on well defined implementation of high level locks semaphores barriers blocking queues etc.
.
second in order to be fast and easy to understand the resulting model must be simple and compact.
building compact models requires identifying program constructs that do not have significant impact on performance and excluding these constructs from the model.
third acc urate prediction requires precise measures of resource demands for the elements of the program.
in certain cases small errors in measuring resource demands can lead to large prediction errors.
.
scope and challenges weanalyzeperformanceofmultithreadedapplicationssuch as servers multimedia programs and scientific computing applications.
such programs split their workload into separatetaskssuch as an incoming http request in a web server a part of a scene in a 3d renderer or an object in a scientific application.
we do not model the performance of individual tasks or requests instead we predict the aggregate performance of the system for a given workload .
processing tasks is parallelized across thread pools.
a thread pool is a set of threads that have same functionality and can process tasks in parallel.
multiple threads rely on synchronization to ensure semantic correctness e.g.
the thread may start executing only after a barrier is lifted and to protect shared data.
this results in the parallel execution of some computations and the sequential execution of others.
threads also use shared hardware resources such as the cpu disks andthenetworksimultaneously whichmaylead to their saturation.
this combination of locking and simultaneous resource usage leads to complex non linear dependencies between configuration parameters of the program and its performance.
as a result even an expert may not understand such dependencies on a quantitative level.
the best approach is to build a performance prediction model.
we focus on following aspects of performance modeling automatic generation of performance models.
we minimize the need for human participation in building the model.
ourprogramanalysis andmodelgeneration aredone automatically.
the analyst need only inspect the generated model and specify configurations in which performance shouldbepredictedandthemetricsthatshouldbecollected.
generating models from a running a program in a single configuration.
building the model should not require running the program many times in many configurations.
such experimentation is time consuming and may not be feasible in a production environment.
instead we want to generate the model by running a program in a singlerepresentative configuration in which the behavior and resource demandsof the program approach the behaviorand resource demands of a larger set of configurations.
accurate performance prediction for a range of configurations.
this lets our model to answer what if questions about the program s performance detect performance anomalies in the running program and be used as a decision making element of a self configuring data center.
wemodelprogramsrunningoncommodityhardware.
predicting performance of programs runningon cluster and grid systems would require developing an additional set of hardware models and potentially different approach for program analysis which is beyond the scope of this paper.
building performance models of complex multithreaded systems is challenging.
the primary challenges are discovering the semantics of thread interaction.
building the performance model requires knowledge of the queues buffers and the locks in the program their semantics e.g.
is this particular lock a semaphore a mutex or a barrier and interactions e.g.
which thread reads or writesto a particular queue or accesses a particular lock .
there are numerous ways to implement locks and queues and to expose their functionality to threads.
discovering this information automatically requires complex program analysis.
discovering parameters of the program s components.performance of the program depends on parameters of its locks and queues and on the resource demands of its threads.
for example the amount of time the thread has to wait on a semaphore depends on the number of available semaphore permits.
the amount of time the program spends on the disk i o depends on the amount of data it has to transfer.
however the retrieving parameters of locks and queues may require further program analysis and obtaining resource demands may require instrumenting the os kernel.
.
model definition below we briefly describe the model we build automatically.
we use discrete event simulation models that consist of three tiers.
the high leveltier simulates the flowoftasks processed by the program.
it is a queuing network model whose queues correspond to program s queues and buffers as well as to some os queues.
the service nodes correspond to the program s threads and thread pools.
the mid level tier simulates the delaysthat occur in the program s threads as they process tasks.
thread models are probabilistic call graphs pcgs where each vertex si s corresponds to a piece of the thread s code a code fragment cf .
edges representpossible transitions of control flowbetweenthecfsandarelabeledwiththeirprobability.
transition probabilities are defined by the mapping s p s .
we distinguish three major sources of delays in processing tasks which correspond to three classes of code fragments i o code fragments denoted as cio represent i o operations synchronization csync cfsrepresentsynchronization operations computation ccpu cfs represent computations and memory operations.
in addition cinandcoutcfs communicate with the high level queuing model.
cincfs fetch tasks from the queues of the queuing model while coutcfs send tasks to the queuing model.
the lower tier model simulates the system s shared resources the cpu and the os thread scheduler the disk i o subsystem and the set l l1 ... lm of locks in the program.
these models are part of q t the state of the whole simulation at each moment of time t. as an example a model of a simple web server is shown in figure .
the accept threadlistens for incoming connections the cf s1in its thread model .
once the connection has been accepted the accept thread creates a task object s2 s4 and sends s5 it into the task queue.
once one of the working threads becomes available it fetches s6 the task from the queue and processes it s7 s8 .
the working thread verifies that the requested page exists reads if from the disk and sends it to the client.
finally the thread closes the connection and fetches the next task from the queue.
execution of each cf results in the delay .
while the call graph structure an bracketle ts an bracketri htdoesnotgenerally change between different configurations execution times for code fragments can be affected by resource contention .
to accurately simulate the time delays we rely on the lower tier models.
for each code fragment we define a set of parameters see table .
the parameter of a computation cf cpu an bracketle t cpu an bracketri htis thecpu time for that fragment.
the parame8figure a model for a web server t ers of a disk i o cf is a sequence disk an bracketle tdio1 ... dio k an bracketri ht of low level disk i o operations initiated by that cf.
the number kof i o requests allows to implicitly simulate the os page cache.
it was shown that after serving a sufficient numberof requests 104to 105in our experiments the cache enters a steady state where the probability of cache hit converges to a constant.
in terms of our model kfollows a stationary distribution where k indicates a cache hit.
values of cpuand diskvary across different executions of cfs so we representthem as distributions p cpuandp disk.
the parameters sync an bracketle tlid optype out an bracketri htof a synchronization cf are the id of the lock being called the type of synchronization operation e.g.
barrier.await mutex.enter or mutex.exit and the timeout.
when the thread model needs to compute the ifor the cfsi it retrieves the parameters iand calls the corresponding low tier resource model ccpucfs call the model of the cpu and os scheduler ciocfs call the model of disk i o subsystem and csynccfs call the model of a corresponding lock lj l which simulates that lock semantically.
the resource model computes as a function f q t .
once the delay is over the resource model notifies the thread model which resumes its execution.
low level resource models have parameters too.
in particular the parameter of the cpu is the number of cores.
the parameters an bracketle tlid ltype lparam an bracketri htof the lock lj lare the lock id lock type e.g.
semaphore barrier or mutex and the additional parameters specific to the type of the lock.
for example the parameter of the barrier is the barrier capacity and the parameter of the semaphore is its count.
low level models are implemented as a combination of queuing and statistical models.
their detailed description is beyond the scope of this paper.
information on modeling hardware and locks and can be found in .
.
automatic model generation constructing the performance model requires collecting the following information about the program automatically table model components and their parameters entity description s s1.
..s n the set of all nodes code fragments in the pcg s p s transition probabilities for pcg nodes i delay caused by executing cf si s disk i o cf parameters a sequence of an bracketle td io1 ... dio k an bracketri ht low level i o operations cpu an bracketle t cpu an bracketri ht computation cf parameters the amount of cpu time sync synchronization cf parameters an id an bracketle tl id optype out an bracketri htof the lock called operation type timeout l l1.
..l m the set of all locks in a program lock lock parameters an id of the lock an bracketle tl id ltype lparam an bracketri htlock type type specific parameters t heset ofqueues threads correspondtoservice nodes in the upper tier model and knowledge of their interactions correspond to cin coutcfs in the middle tier model the set of thread pools.
the sizes of thread pools are configuration parameters that impact performance the computations i o and locking operations corresponding to the set sof cfs and the sequence of their execution corresponding to transition probabilities the parameters of cfs required to model delays the setlof locks their types and parameters lock.
we collect the required data in four stages see figure using a combination of static and dynamic analysis.
each stage saves intermediate results into files that are used as input to subsequent stages.
first the program is executed and its call stack is sampled.
the stack samples are used to detect thread groups and libraries in the program.
second a static analysis of the programisperformed.
duringthisstagewedetect csync cin cout andciocfs.
third the program is instrumented and executedagain with the same configuration.
the instrumentation log is used to detect program wide locks and queues properties of code fragments and to build the probabilistic call graphs an bracketle ts an bracketri htof the program s threads.
finally the collected information is used to build a performance model.
all these operations are performed automatically.
below we describe these stages in more details.
.
collecting stack samples duringthestacksamplingstageourframework findsthread pools frequently called functions and methods in the program and frequently called library functions.
identifying libraries is essential for generating correct probabilistic call graphs see section .
.
.
as the program is being executed the framework periodically takes snapshots of the call stack of the running program which are merged to build a call trie of the program.
in a call trie each leaf node contains the code location being executed which includes the name of a function or a method being executed and a line number.
the non leaf nodes provide a call stack for that code location.
for each leaf the framework maintains the list of pairs an bracketle tt1 c1 an bracketri ht ... an bracketle ttn cn an bracketri ht where the ciis the number of executions of that code location by the thread ti.
thread groups are detected in two stages.
first a map t is created.
its keysare threadtuplesdiscoveredbysampling 9figure model creation stages and intermediate results a nd its values are execution counts.
for each leaf in the trie the framework gets a tuple ti an bracketle tt1 ...tk an bracketri htof threads that executed the node along with the total numberof executions ci summationtext c1 ... c k .
iftdoes not contains the tuple ti the pair an bracketle tti ci an bracketri htis inserted into t. otherwise the number of executions for the existing tuple is increased by ci.
second threadtuplesin tare merged.
thetuple an bracketle tt1 c1 an bracketri ht is merged with an bracketle tt2 c2 an bracketri htif and only if all threads in t2 also present in t1 andc1 c2.
the resulting tuple is formed as an bracketle tt1 c1 c2 an bracketri ht.
after merging the tuples t1...tm t represent the thread pools detected in the program.
stacksamples are also usedto identifyprogram s libraries.
for everyfunction ftheframework generatestheset offunctions an bracketle tf1 ... fn an bracketri htthatcalled f. ifthenumberofcallees n fis added to the set of library functions .
although the stack sampling may not detect some rarely executed library functions this does not affect correctness of our models.
.
static analysis during static analysis our framework scans the code of the program and detects csync cio cinandcoutcfs.
it also detects the creation points of locks and queues in the program as a prerequisite for the dynamic analysis.
the static analyzer represents the program as a dependency graph.
the vertices of this graph correspond to functions and methods in the program both called function herein .
the edges are code dependencies e.g.
the function a calls the function b and data dependencies e.g.
the function a refers the class b or creates the instance of b between these functions.
the transitive closure of all the vertices in the dependencygraph represents all thecode that may be executed by the program.
the static analyzer traverses the dependencygraph starting from the functions discovered during the stack sampling.
it scans the code of the functions searching for the specific constructs that represent cfs.
in the process the analyzer searches for