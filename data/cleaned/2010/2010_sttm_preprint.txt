to be presented at icse .
hazeline u. asuncion arthur u. asuncion ri chard n. taylor.
software traceability with topic modeling.
acm ieee nd international conference on software engineering.
may to appear .
softwaretraceabilitywithtopic modeling hazelineu.
asuncion instituteforsoftware research university of california irvine hasuncio ics.uci.eduarthur u.asuncion center formachine learning and intelligent systems university of california irvine asuncion ics.uci.edurichard n.taylor institutefor software research university of california irvine taylor ics.uci.edu abstract software traceability is a fundamentally important task in software engineering.
the need for automated traceability increases as projects become more complex and as the number of artifacts increases.
we propose an automated technique that combines traceability with a machine learning technique known as topic modeling.
our approach automatically records traceability links during the software development process and learns a probabilistic topic model over artifacts.
the learned model allows for the semantic categorization of artifacts and the topical visualization of the software system.
to test our approach we have implemented several tools an artifact search tool combining keyword based search and topic modeling a recording tool that performs prospective traceability and a visualization tool that allows one to navigate the software architecture and view semantic topics associated with relevant artifacts and architectural components.
we apply our approach to several data sets and discuss how topic modeling enhances software traceability and vice versa.
categories andsubjectdescriptors d. .
distribution maintenance and enhancement documentation d. .
management g. probability and statistics probabilistic algorithms h. .
information storage and retrieval information search and retrieval generalterms documentation management keywords software traceability topic model latent dirichlet allocation software architecture permission to make digital or hard copies of all or part of this w ork for personal or classroom use is granted without fee provided th at copies are not made or distributed for profit or commercial advantage and th at copies bearthisnoticeandthefullcitationonthefirstpage.
tocop yotherwise to republish topostonserversortoredistributetolists re quirespriorspecific permission and orafee.
icse may2 capetown southafrica copyright2010acm ... .
.
.
introduction large scale industrial projects are often comprised of thousands of software development artifacts such as requirements documents design documents code bug reports and test cases.
the goal of software traceability is to discover relationships between these artifacts to facilitate the efficient retrieval of relevant information which is necessary for many software engineering tasks .
while fully manual traceability approaches are typically only feasible for small projects automated techniques also encounter difficulties in practice due to the lack of accuracy and the high level of false positive trace links generated .
in this paper our main contribution is a scalable approach to traceability based on a combination of automated link capture and topic modeling.
the traceability problem can be tackled both retrospectively and prospectively.
in retrospective traceability artifact relationships are inferred ex post facto from a static set of artifacts.
automated approaches such as information retrieval techniques generally perform traceability retrospectively.
in contrast prospective traceability generates trace linksin situ as artifacts are being created and modified during the development process.
prospective capture is the creation of putative links between artifacts based upon directly observed actions of the user on those artifacts.
while we discuss the application of topic modeling in the retrospective setting we mainly focus on the combination of prospective traceability and topic modeling in this paper.
there are several key benefits of the prospective approach.
prospective traceability allows for links to be captured in an online fashion incrementally improving the system s traceability and allowing developers to immediately benefit from the trace links created .
another benefit of prospective traceability is the presence of additional captured information such as the temporal sequence of user actions in the design environment which can be used to automatically generate trace links to heterogeneous artifacts.
machine learning and information retrieval techniques have been used in the past to automatically generate traceability links .
in particular latent semantic indexing lsi has made significant inroads into the area of automated traceability .
more recently probabilistic topic models such as latent dirichlet allocation lda have been used for source code analysis .
lda is an unsupervised machine learning technique that facilitates the automatic learning of semantic topics from the set of artifacts without requiring previous training data with training labels.
usually these approaches have exclusively focused on retrospective traceability.
in contrast we proposeincorporating the lda model into the task of prospective traceability.
another difference from previous lda based work is that we do not focus solely on source code analysis but rather investigate an architecture centric approach which creates trace links for all types of artifacts produced in the software development life cycle.
we argue that a positive symbiosis exists between prospective capture and topic modeling.
prospective link capture helps to identify a larger amount of potentially related artifacts through observation of user actions which gives rise to a more diverse and semantically coherent set of learned topics.
meanwhile these learned topics enhance the process of prospective capture through the visualization of the topical content of the software architecture and the efficient retrieval of semantically similar artifacts.
furthermore while topic modeling cannot be applied to certain types of artifacts like sound or video files prospective link capture can still trace to these artifacts by taking advantage of recorded temporal user actions.
conversely prospective link capture is inadequate at determining the semantic nature of artifacts a task at which topic modeling excels.
thus these two techniques tightly complement each other.
note that existing retrospective machine learning techniques can also complement our prospective approach.
in the next section we discuss the current state of software traceability research and discuss strategies for effective traceability.
we then provide a brief overview of topic modeling techniques.
we detail our approach of combining prospective traceability with topic modeling.
then we describe several tools that demonstrate the feasibility of our approach and show results on several data sets.
we then conclude with future research directions.
.
softwaretraceability the practical realization of software traceability is known to incur high overhead and thus there has been a concerted effort to automate the generation of trace links.
we highlight the current state of the art in both retrospective and prospective traceability and we also discuss insights into effective traceability which guide our approach.
.
retrospective traceability most automated traceability techniques fall under the category of retrospective traceability.
information retrieval techniques such as the vector space model and latent semantic indexing have been used to automatically generate candidate links based on textual similarity between artifacts .
other machine learning techniques have also been combined with program analysis and run time monitoring to automatically link source code to use cases .
probabilistic topic models like latent dirichlet allocation have been used to mine semantic topics from source code.
in particular lda has been used to automatically categorize code and lda topics have been interpreted to be analogous to cross cutting concerns in aspect oriented programming .
we discuss lda in depth in section .
visualization techniques have been proposed to support the efficient identification of correct links.
duan and clelandhuang use cluster based techniques to group candidate trace results that are presented to the user .
other visualization techniques include tag clouds to graphically display term frequencies and a tree structure to represent the hierarchical structure in a requirements document .
visualiza tion is an important aspect of traceability as it allows users to verify the quality of trace links.
as we will see later in the paper topic modeling provides useful semantic information that can be used to visualize the semantic relationships between the traced artifacts and software architecture.
.
prospectivetraceability prospective traceability approaches have largely been manual or minimally automated until recently.
such techniques include embedding related artifact ids into source code and only automating peripheral traceability tasks such as maintaining consistency between artifacts .
tools like pro art and toors support the online recording of links based on pre specified user information.
pro art requires a process model to be manually specified prior to the recording of traces between artifacts .
toors requires training in formal specifications in order to mathematically express the relations between classes of artifacts .
once these relations have been specified in the database automated tracing between artifacts is possible.
other research communities have also developed methods for prospectively capturing relations between artifacts.
in the aspect oriented research community code is automatically related to concerns by requiring users to specify a concern prior to making code changes .
model driven approaches use transformation techniques to automatically create links between source and target models .
these approaches may require the specification of the meta model and the transformation program or the specification of the transformation rule prior to the link capture.
more recently lightweight approaches to tracing between artifacts have been proposed in the program comprehension research community.
online recording of user interaction has been used to associate source code to tasks as well as source code to team collaboration .
prospectively capturing links between artifacts during an experiment lifecycle has also been used extensively in e science .
in previous work we investigated an approach for automated prospective capture that utilizes open hypermedia techniques and rules.
tool specific adapters record user actions over heterogeneous platforms while users generate or access artifacts during software development.
rules are used to associate links with a relationship type.
developing these adapters and custom rules requires only a one time overhead setup.
the overhead of using this approach involves turning the record mode on or off optionally applying rules for each recording session and deleting extraneously recorded links which were not caught by the filters.
the approach however suffers from the fact that prospective capture lacks insight into the semantic nature of the artifacts being linked.
for instance if a developer is multi tasking and working on two different projects at once prospective capture based on the recorded temporal sequence of actions may generate irrelevant trace links.
semantically sifting through artifacts is important for this task and thus we explore the use of topic modeling in prospective traceability.
.
insightsfor effective traceability based on our experience with implementing a successful software traceability framework in an industrial setting and our observations of traceability techniques within escience our approach is guided by the following general insights.source code consistent architecture structural view class foo ... class bar ... module b module c module a req.
specs wiki pages bug reports use cases sequence charts figure architecture centric traceability where software artifacts are linked to specific modules.
understand the limits of automation.
as we have observed in previous work it is important to distinguish between automatable traceability tasks and tasks that require human intervention.
thus we aim to use automation techniques that minimize the manual tasks of artifact search and trace link post analysis.
as we detail later in the paper our technique generates links prospectively as users perform development tasks.
the generated links are then automatically categorized by semantic topics and visually represented to the user to facilitate link analysis.
in addition users can navigate to the artifacts in the context of their native editors to aid users in determining the correctness of the links.
traceability must support user work practices.
both our previous work and literature suggest that performing traceability tasks should be a side effect to the users development tasks in order to gain wide adoption.
in addition the traced information should provide direct benefits to the users.
our prospective capture approach seeks to capture links in the background while users perform their development tasks.
the online improvements to the system s traceability and the visual representation of trace links can provide immediate benefits to users.
the traceability approach must be scalable.
the literature reports that one of the difficulties with transferring traceability techniques to industry is that the examples are too small .
thus it is important that approaches for both capturing links and presenting the linked information to users be scalable.
in the prospective setting scalability is achievable due to the incremental capture and maintenance of trace links.
furthermore advances in probabilistic inference algorithms have made topic modeling very scalable as we will show later in the paper.
traceability must be bounded.
literature suggests that it is infeasible to create links to every single artifact.
with n artifacts there are n possible pairwise links between these artifacts making it generally infeasible to evaluate and manage each of these potential links.
the trace for a purpose strategy states that trace links should only be captured if there is a direct usage of the traced information .
in addition creating direct links between line level source code and high level concepts can produce an unmanageable amount of links that make it difficult to analyze and use the links.
we posit that centering links at the system s architecture level bounds the scope of traceability links to be captured.
figure depicts architecture centric traceability.
artifacts are linked to particular architectural components and there is the assumption that source code is generally consistent with the architectural description.
many design factors such as domain constraints user requirements and governmental regulations are addressed at the architectural level.
nd znd xt d t dnd figure graphical model for latent dirichlet allocation.
unshaded shaded circles denote hidden observed variables boxes denote parameters and plates denote replication over indices.
since architecture forms the nexus between artifacts in the problem space e.g.
requirements and artifacts in the solution space e.g.
code tests the conceptual gap between the architecture and the other artifacts is smaller than for example the conceptual gap from source code to requirements.
finally the fact that architecture is a high level abstraction of the source code supports impact analysis software evolution and system comprehension and these are tasks that software traceability aims to support as well.
.
topicmodeling topic modeling is a widely used machine learning technique for automatically inferring semantic topics from a text corpus.
in order to provide a foundation for our topicenhanced traceability approach we briefly introduce latent dirichlet allocation and discuss applications and limitations of topic modeling.
.
latentdirichlet allocation automatically discovering the underlying structure of the data is an important problem in machine learning which has spurred the development of dimensionality reduction techniques.
latent semantic indexing lsi also known in the literature as latent semantic analysis is one such technique that attempts to address this problem.
lsi has been utilized extensively in software engineering since it can be easily applied to text corpora.
in lsi each document in the corpus is represented as a word count vector of length w where wis the number of words in the corpus vocabulary.
when the vectors of all ddocuments are placed side by side one obtains a w dmatrix of counts which lsi decomposes by singular value decomposition in order to map the documents to a lower dimensional latent space.
hofmann proposed probabilistic latent semantic indexing plsi a probabilistic version of lsi which is able to achieve better results .
improving upon plsi a fully generative bayesian model known as latent dirichlet allocation lda was introduced by blei et al.
lda deals with overfitting issues associated with plsi and can achieve better results than plsi.
in this paper the topic model that we use is lda.
the graphical model of lda is displayed in figure .
each topic tis defined to be a probability distribution t over w words drawn from a dirichlet distribution with parameter .
furthermore each document dis associated with a probability distribution d over ttopics drawn from a dirichlet with parameter .
note that a sample obtained from a dirichlet distribution is precisely a discrete distribution itself.
a topic assignment variable zndis associated to each individual word token nin each document dand is sampledfrom d. the actual word token xndis sampled from its respective topic twhere t znd.
since these word tokens are observed data which can be represented as a w dmatrix of counts we can use bayesian probability calculus to invert the generative model given observed data and automatically learn the hidden variables tfor each topic t and dfor each document d. it is important to note that lda is an unsupervised machine learning framework which means that no previous training data with training labels is required.
the only required input to lda is the set of documents converted to a sparse w dmatrix after removing stopwords and performing stemming and the desired number of topics tto be learned.
recent advances in bayesian inference for topic models have made it possible to learn an lda model in near realtime on a moderately sized set of documents.
we use an efficient zeroth order collapsed variational bayesian inference algorithm cvb0 in which an underlying variational distribution q znd over ttopics is associated with each topic assignment znd.
the algorithm consists of iteratively performing the following variational updates in a systematic scan over tokens q znd t n nd wt n nd t w n nd td where n nd wk n nd k and n nd kdare expected counts derived fromq z .
for more details see asuncion et al.
.
while other algorithms such as fast collapsed gibbs sampling can also be used cvb0 is very fast later in the paper we will show timing results when applying cvb0 to software artifacts.
furthermore topic modeling can easily scale to hundreds of thousands of artifacts especially when combined with distributed computing .
we take advantage of the efficiency of cvb0 inference in our traceability tools.
.
applications of lda once an lda model is learned on a corpus one can use the learned probability distribution over words tto display a list of wwords sorted by decreasing probability for each topic t. for instance if topic has high probability words school teach student book one can assume this topic to be about academics.
thus the semantic content of the entire corpus can be summarized by displaying these topics1.
one can also use document d s distribution dover topics to determine the topical content of the document.
for instance if there are topics and if d then one can infer that document dis mainly comprised of a combination of topics and .
note that dcan also be compared against other d using a similarity measure such as kullback leibler divergence or cosine distance in order to obtain a ranked list of topically similar documents.
thus lda is useful for finding related documents as well as visualizing the topical content of each document.
we incorporate these abilities into our traceability tools.
lda has been applied to a variety of problems including information retrieval and entity resolution .
as mentioned earlier lda has also been used to find topics in source code .
the main differences between our approach and previous lda based work are we mainly 1for a brief demo of topic modeling on news articles see on prospective traceability we do not perform topic modeling on code but rather on text based artifacts such as requirements design documents generated during the software lifecycle.
thus our approach is complementary with other lda based work on source code analysis.
.
limitations oflda while lda is very useful for analyzing text data it is important to note the limitations of lda.
the first limitation is that the number of topics t needs to be pre defined by the user.
if tis small then the topics are more general in nature and are more distinguishable from each other.
if tis large then nuanced topics may appear and topics may begin to overlap semantically.
one way to address this problem is to learn multiple models using various tand visually inspect the topics.
alternatively a non parametric model known as hierarchical dirichlet processes extends lda and seeks to learn the optimal tautomatically.
another limitation is that the visualization of lda topics is limited to displaying the high probability words and so the interpretation of the actual semantic nature of the topic is left to the user e.g.
for the topic school teach student book there is no automatic label denoting that this is an academic topic .
note that there has been some recent work that seeks to provide topic labels automatically .
.
our combinedapproach we have reviewed the problem of traceability and the benefits that topic modeling brings.
we believe that traceability can benefit from the application of topic modeling to software development artifacts.
we outline how topic modeling can be effectively applied to prospective traceability.
topic modeling enhances prospective capture by providing semantic information about the artifacts.
recall that our prospective traceability approach is centered on the architecture .
while a developer is working on a particular architectural component our technique captures the developer s actions such as opening a requirements specification visiting a wiki page or modifying a bug report.
the artifacts that the developer visits are then automatically linked to the architectural component on which the developer is working.
once these artifact links are recorded the list of artifacts related to a component can be visualized by the developer by simply navigating to the particular component in the architectural graph.
topic modeling enhances the prospective capture by providing a learned set of topics that can help the developer to find artifacts or other relevant online documentation.
for instance if the developer needs to search through the project s entire set of artifacts the developer can use the learned semantic topics to filter the artifact search.
furthermore the developer can easily find similar artifacts by comparing dand finding the closest matches.
prospective traceability topic modeling semantic categorization and visualization expansion of artifact base figure symbiosis between prospective traceability and topic modeling.acts architecture centric traceability for stakeholders trase topically rich artifact search engine team topic enhanced architecture mashup user interaction with trase 2captured links with semantic information figure tool support for our combined approach.
topic modeling can also enhance the visualization of the system.
artifacts that have been gathered via prospective capture are now connected to the corresponding architectural component.
when the developer views the component the developer can view the artifacts along with a graphical depiction of the topic distributions d .
furthermore the components themselves are now associated with the topics of their artifacts.
we can define each component c s topic distribution cto be an average of the topic distributions of artifacts associated with the component c nd cp d c d. thus we have a topic enhanced bird s eye view of the entire system and one can find which artifacts and components are related to particular semantic topics.
this feature is important for system comprehension.
not only is prospective capture enhanced by topic modeling but the quality of the topics is enhanced by the prospective capture of new artifacts.
as more artifacts and other online documentation are prospectively linked to the architecture the quality of the topic model improves as we will see later in the paper.
the topics become more semantically coherent and interpretable since the collection of underlying artifacts becomes larger and more diverse.
as depicted in figure there appears to be a beneficial symbiosis between prospective capture and topic modeling.
there are other potential benefits to applying topic modeling to prospective traceability.
false positives in automatic link generation can be minimized by comparing the ddistributions if the difference is greater than a threshold then that candidate traceability link can be treated as noise and be discarded.
furthermore artifacts can be clustered together in groups based on semantic topic similarity and displayed to the developer which aids in artifact retrieval and allows for automated recommendation of similar artifacts.
finally extensions to the lda topic model such as the author topic model and the dynamic topic model can give an indication of which topics developers are working on as well as the temporal evolution of topics both of which are of interest to project management.
.
tool support we implemented several different tools that can be used to collectively perform prospective traceability with topic modeling.
figure shows the high level interplay between our topic based artifact search engine trase our prospective capture tool acts and our topic enhanced architecture visualization tool team .
the user s interaction with trase can be prospectively recorded with acts which produces trace links.
these trace links are then augmented with topical information and are visualized within team.
we provide details for each tool and discuss the application of our approach on archstudio a mature software project at uc irvine.
figure trase tool which performs lda in realtime on the results of artifact search.
.
trasetool to investigate our idea of improving prospective capture with topic modeling we created the topically rich artifact search engine trase .
trase is a search engine over the artifacts of the project which dynamically learns an lda topic model on the search results in real time.
we implemented trase using a combination of perl ajax and lucene technologies.
lucene provides keywordbased search results over the set of artifacts.
since our topic model inference algorithm cvb0 is very fast on the order of a few seconds trase dynamically learns a new topic model over the artifacts returned by lucene and displays the high probability words of the learned topics as well as the distribution over topics d for each artifact dreturned by lucene.
as shown in figure each topic is represented by a different color and the distribution dis depicted as a color bar underneath each search result.
thus it is easy to visually determine the topical composition of each artifact.
trase also includes functionality for ordering the results by topic as well as by similarity to another document.
thus the developer can filter by desired topic or find artifacts with the most similar topic proportions.
for instance if the developer wants artifacts similar to result clicking on similar pages would order the results by similarity to where the similarity measure used is kl divergence.
as long as the prospective capture of acts is activated each artifact that the developer visits via the trase tool is recorded as a trace link to the specific component on which the developer is working.
note that this lda based search technique can also be applied to general web pages on the internet.
trase is a topic enhanced way to search for artifacts that enables prospective traceability to be more efficient and accurate.
.
acts tool to capture links we use our previously built acts traceability tool on top of archstudio .
acts prospectively captures links by recording the user interaction with the architecture and other artifacts.
we center our links to the architecture and our first class n ary links are stored in an xml architecture description language xadl file .
acts combines prospective capture with the use of rules and open hypermedia adapters.
the tool specific recording adapters capture all the user actions on the artifacts and have been implemented for applications such as the mozilla firefox browser ms word ms excel ms powerpoint and adobe acrobat.
rules are then applied to these recorded actions to determine traceability links filter extraneous links and assign link semantics.
for instance if a user visits urls from the trase search results or any other web site the firefox recorder would capture links to these urls.
figure shows the end of a recording session which lists the artifacts visited during that session.
after performing some rule based filtering these artifacts are then associated with a particular component.
note that acts can capture links to artifacts of varying media types such as images like .png files.
this ability to capture links to non text artifacts is an advantage to performing prospective traceability.
.
teamtool to visualize our architecture with traceability links we built the topic enhanced architecture mashup team tool.
this tool aggregates the linked information from acts and overlays this information on top of the software architecture.
team also takes the results of the topic model and graphically renders the topical information of both the architectural components and the artifacts.
as shown in figure team allows one to view the entire system and identify which components are related to a particular topic.
in order to semantically classify component c we use the component s topic distribution cwhich was defined in section .
if the component s probability for topic t is greater than a threshold i.e.
ct .
a threshold we set arbitrarily we associate the component with that topic.
note that team displays the high probability words of each topic on the left pane.
when a topic is clicked the components associated with that topic are highlighted in the topic s color.
thus it is easy to determine the topical makeup of various sections of the architecture.
one can also zoom in on an individual component and view the topic distributions d of the component s related artifacts as shown in figure .
this visual information allows the user to quickly locate an artifact of interest and once the user clicks on an artifact the artifact is displayed in its native editor.
thus at both the system level view and the component level view users can identify at a glance both the trace and topic information and navigate to desired artifacts.
.
evaluation to evaluate our traceability approach we apply our techniques to the archstudio software project and we perform a feature comparison between our traceability tools and other tools in the literature.
we also report timing and accuracy results when applying latent dirichlet allocation to archstudio artifacts and we compare the precision recall scores of lda and lsi on the easyclinic data set .
figure team tool which provides a mashup of topical information over the software architecture.
.
case studyon archstudio we conducted a case study on the archstudio system .
the latest version of archstudio consists of components and connectors which corresponds to more than 85kloc.
the system comes with a heterogeneous set of artifacts tutorials in pdf presentations in powerpoint project specifications in word archived emails in an online mailing list wiki pages and bug reports in trac archstudio web pages research publications in pdf and developer notes in various file formats.
we followed the scenario of understanding the unfamiliar parts of the archstudio system.
in the process of understanding each component we navigated to various archstudio artifacts and web sites while prospective capture was enabled in acts thus links were being captured as we investigated each component.
since the architecture already has a consistent mapping with the underlying code i.e.
the system will not run if an inconsistency exists it was not necessary to create links to the source code.
to make our set of artifacts amenable to topic modeling we converted our artifacts to plain text files.
a few documents were very long and thus we broke these documents by section into separate files.
all the other preprocessing steps such as removing stop words and stemming are automated within our topic modeling algorithm.
we tested the capability of our trase tool on our set of archstudio artifacts by querying various component names.
we find that the tool performs very efficiently returning re sults in a few seconds and that the displayed semantic information is accurate.
figure displays the results of querying archedit which is a tool within the archstudio framework.
we see that various archstudio related topics are found an xml schema topic t1 a uci email topic t2 a bna tree topic t3 a java eclipse topic t4 a component connector topic t5 a similar myx framework topic t6 and an archlight test topic t7 .
in each of the returned results the yellow topic appears since archedit and archlight terms are collocated in these documents.
we also see the presence of the email topic in olive green in results and because these specific results are precisely the artifacts from email archives.
also note that result is an email about the myx framework with relationships to archlight which confirms the accuracy of the learned topic distribution that is displayed.
once we captured our links through the acts prospective capture tool we performed topic modeling on our set of artifacts generating topic proportions for both the artifacts and related architectural components.
we then rendered this information within the team mashup tool.
as depicted in figure we clicked on the first topic about change sets and the resulting highlighted components in red were all related to this topic changeset relationship manager changeset id view changeset status view changeset id relationships and changeset status relationships.
figure displays the artifacts related to the archipelago component which is the visual editor within archstudio.
most of the linked artifacts are related to topic t6 which is about archipelago or its visual elements.
topic t2 the olive green topic is found among the email artifacts.
this result makes sense because the high probability words within topic t2 are typically found in emails.
as with the trase tool the width of the color in the color bar indicates the strength of its relation to the topic.
the artifact in the fourth row is largely comprised of topic t5 which is the myx topic.
when we examined the artifact we found that it is indeed largely about the myx architectural style.
the topic with the second highest probability for this artifact is topic t4 about xadl and when we examined the artifact we found that it also discusses xadl elements.
through these examples we see how team allows one to quickly identify the topics of a component s related artifacts.
when we presented our team tool to the archstudio developers the response was largely positive.
one developer stated that topics aid in system comprehension.
this developer recounted his previous experience of having to manually go through source code when he was initially learning archstudio and he stated that this topic based tool would have saved him time and effort in understanding archstudio provides me a central access to all the available materials so that i don t have to go to different places searching for the same topic and possibly get overwhelmed by lots of unrelated materials.
at this point i believe the mashup tool not only saves users time but also improves the usability of existing technical materials.
in addition the topic visualization also aided the developers in analyzing the correctness of the related artifacts.
the visualization enabled the developers to quickly identify whether the captured links were correct and whether we were missing some links.
the developers generally thought that the captured links were accurate.
the developers also gave several suggestions for improve table feature comparison between tools feature our combined approachretro.
trace.
prosp.
trace.
generates candidate links based on textual similarityx x generates links based on user interactionx x generates links across heterogeneous artifacts i.e.
non text based x uses fully probabilistic interpretation of semantic topicsx adds links in an online incremental fashionx x x detects topics from artifacts automaticallyx x visualizes semantic topics on architectural mashupx ment.
one suggestion is to provide topics at finer levels of granularity to minimize the number of components to examine.
another suggestion is to make the representation of topics more clear since there were similar high probability words that appeared in more than one topic.
.
featurecomparison table shows a feature comparison between our approach and the existing retrospective and prospective traceability techniques in the literature.
the table shows that our approach provides capabilities that are not currently supported in other tools such as generating traceability links across a wider range of artifacts including graphic and media files using a fully probabilistic interpretation of semantic topics and visualizing topics on top of the architecture graph through the use of mashups.
.
accuracyand timingresultsfor lda in this section we briefly discuss accuracy and timing results when applying latent dirichlet allocation to software artifacts.
in figure we see that the test perplexity of the model decreases as the number of artifacts increases.
perplexity is a widely used metric for topic models that indicates the quality of the model and a lower perplexity indicates a better model .
this unsurprising result suggests that it is beneficial to expand the artifact base for topic modeling suggesting that the prospective capture of artifacts can benefit topic modeling just as topic modeling benefits prospective traceability.
in figure we show the amount of time it takes to learn a topic model for different settings of the number of topics t as a function of the number of artifacts to model.
we see that there is only a linear increase in computation time0 artifacts modeled perplexity lda t lda t lda t figure as the number of archstudio artifacts increases a higher quality topic model is learned.
artifacts modeledtime in seconds lda t lda t lda t figure timing results for lda on archstudio artifacts.
as the number of artifacts increases.
note that the timing results are measured seconds and that we used a single core .6ghz machine to run these experiments.
with a multi core processor one can perform topic modeling on a moderatelysized data set in near real time suggesting the scalability of our approach.
we also note that the other facets of our approach are also scalable acts is scalable since it performs link capture incrementally and team is scalable since mashup visualizations can be done on large scale data with the appropriate tools e.g.
google maps api .
in figure we compare the precision recall scores of lda vs. lsi on the easyclinic data which was used in the tefse traceability challenge .
note that the precisions are generally low since we clumped the four different artifact types in the challenge into one global set of artifacts.
for this data set we see that lda performs better than lsi perhaps due to the fact that lda is fully probabilistic and includes priors on and which can act as regularization.
this result is somewhat expected since hofmann discovered that plsi generally outperforms lsi and since lda is a fully bayesian version of plsi.
nonetheless it is reassuring to know that in the realm of software artifacts lda performs as well or better than lsi on this data.
.
discussion our archstudio case study suggests that combining topic modeling with prospective traceability provides useful results.
our task of learning the unfamiliar parts of the arch .
.
.
.
.
.
.
.
.
.
.
.
.
.
recallprecisionlda t lsi t figure lda perform better than lsi on the easyclinic data set in terms of precision recall.
studio system was supported by our traceability tools.
we found that the learned semantic topics corresponded well with the actual content within the artifacts and these topics allowed us to efficiently find and evaluate artifacts.
the archstudio developers were also able to easily verify the traceability links by using the semantic information visualized by the team tool.
our empirical results also suggest that lda is competitive or superior to lsi and that our approach can scale to handle larger numbers of artifacts.
there are limitations to our approach.
first we assume the existence of an architecture since we center our traceability links to the architecture.
this is not an unrealistic assumption since we believe that every system has an underlying architecture whether or not it is explicitly documented.
in the event that the architecture is not explicitly documented or incomplete we can create virtual components to correspond to the source code.
secondly we perform our topic analysis on text based artifacts.
the non text artifacts were ignored by the topic model algorithm.
in the future we plan to use text metadata associated to non text artifacts in order to include them in the topic model.
.
conclusions automated approaches for generating traceability links have largely focused on recovering trace links retrospectively.
this paper builds upon our previous work of capturing links prospectively while the artifacts are generated or accessed in the context of a development task.
in this work we employ topic modeling in order to aid users in analyzing the semantic nature of artifacts as well as the entire software architecture.
our approach is scalable since the trace links are incrementally captured the problem space is bounded by tracing to the architecture and the topic model algorithm is very efficient.
this paper marks the initial investigation into combining prospective link capture with machine learning techniques and there are many open research questions can prospective link capture be successfully combined with retrospective ir techniques?
is it possible to relate the automatically generated topics to high level concepts such as features non functional properties or concerns?
is it possible to successfully perform topic modeling on long artifacts by section?
our results suggest that the combination of prospective traceability with topic modeling is a promising area of research that can be useful in practice.
.