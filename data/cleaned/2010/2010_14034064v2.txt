arxiv .4064v2 sep 2014feedback generation forperformance problemsin introductory programming assignments sumit gulwani microsoftresearch usa sumitg microsoft.comivanradi cek tuwien austria radicek forsyte.atflorian zuleger tuwien austria zuleger forsyte.at abstract providing feedback on programming assignments manually is a tedious error prone and time consuming task.
in this paper we motivate and address the problem of generating feedback on performance aspects in introductory programming assignments.
we studied a large number of functionally correct student solutions to introductory programmin g assignments and observed there are different algorithmic strategies with varying levels of efficiency for solvin g a given problem.
these different strategies merit different feedback.
the same algorithmic strategy can be implemented in countless different ways which are not relevant for reporting feedback on the student program.
we propose a light weight programming language extension that allows a teacher to define an algorithmic strategy by specifying certain key values that should occur during the execution of an implementation.
we describe a dynamic analysis based approach totest whether a student sprogram matches a teacher s specification.
our experimental result s illustrate the effectiveness of both our specification langu age and our dynamic analysis.
on one of our benchmarks consisting of functionally correct implementations to3 p rogramming problems we identified strategies that we were able to describe using our specification language in minutes after inspecting i.e.
around implementations .
our dynamic analysis correctly matched each implementation with its corresponding specification thereby automat ically producing the intended feedback.
categories andsubject descriptors d. .
testing and debugging i. .
automatic programming automatic analysis of algorithms the second and third author were supportedby the vienna science and technology fund wwtf grant ict12 .
permission to make digital or hard copies of all or part of thi s work for personal or classroom use is granted without fee provided that copies ar e not made or distributed forprofit orcommercialadvantageandthatcopiesbearthisn oticeandthefull citation on the first page.
copyrights for components of this work owne d by others than the author s mustbehonored.
abstractingwithcreditispermi tted.
tocopyotherwise or republish topostonserversortoredistributetolists re quirespriorspecificpermission and or a fee.
requestpermissionsfrom permissions acm.or g. sigsoft fse november hongkong china copyright isheld by theowner author s .
publication righ ts licensedtoacm.
acm978 ... .
.
terms algorithms languages performance.
keywords education moocs performance analysis trace specification dynamic analysis.
.
introduction providing feedback on programming assignments is a very tedious error prone and time consuming task for a human teacher even in a standard classroom setting.
with the rise of massive open online courses moocs which have a much larger number of students this challenge is even more pressing.
hence there is a need to introduce automation around this task.
immediate feedback generation through automation can also enable new pedagogical benefits such as allowing resubmission opportunity to students who submit imperfect solutions and providing immediate diagnosis on class performance to a teacher who can then adapt her instruction accordingly .
recent research around automation of feedback generation for programming problems has focused on guiding students to functionally correct programs either by providing counterexamples generated using test input generati on tools or generating repairs .
however non functiona l aspects ofaprogram especially performance are also impo rtant.
we studied several programming sessions of students who submitted solutions to introductory c programming problems on the pex4fun platform.
in such a programming session a student submits a solution to a specified programming problem and receives a counterexample based feedback upon submitting a functionally incorrect attempt generated using pex .
the student may then inspect the counterexample and submit a revised attempt.
this process is repeated until the student submits a functionall y correct attempt or gives up.
we studied different problems and observed that of the different programming sessions led to functionally correct solutions.
howe ver unfortunately on average around of these functionally correct solutions had different kinds of performance prob lems.
in this paper we present a methodology for semiautomatically generating appropriate performance relate d feedback for such functionally correct solutions.
from our study we made two observations that form the basis of our semi automatic feedback generation methodology.
i there are different algorithmic strategies with varying levels of efficiency for solving a given problem.
algo rithmic strategies capture the global high level insight o f a solution to a programming problem while also defining key performance characteristics of the solution.
different strategies merit different feedback.
ii the same algorith mic strategy can be implemented in countless different ways.
these differences originate from local low level implement ation choices and are not relevant for reporting feedback on the student program.
in order to provide meaningful feedback to a student it is important to identify what algorithmic strategy was employed by the student program.
a profiling based approach that measures running time of a program or use of static bound analysis techniques is not sufficient for our purpose because different algorithmic strategies that nec essitate different feedback may have the same computational complexity.
also asimple patternmatchingbasedapproach is not sufficient because the same algorithmic strategy can have syntactically different implementations.
our key insight is that the algorithmic strategy employed by a program can be identified by observing the values computed during the execution of the program.
we allow the teacher tospecify an algorithmic strategy bysimplyannota ting at the source code level certain key values computed by a sample program that implements the corresponding algorithm strategy using a new language construct called observe.
fortunately the number of different algorithmic strategies for introductory programming problems is often small at most per problem in our experiments .
these can be easily enumerated by the teacher in an iterative process by examining any student program that does not match any existing algorithmic strategy we refer to each such ste p in this iterative process as an inspection step.
wepropose anoveldynamicanalysis thatdecides whether the student program also referred to as an implementation matchesanalgorithm strategy specifiedbytheteacherinthe form of an annotated program also referred toas a specification .
our dynamic analysis executes a student s implementation and the teacher s specification to check whether the key values computed by the specification also occur in the corresponding traces generated from the implementation.
we have implemented the proposed framework in c and evaluated our approach on 3pre existingprogramming problems on pex4fun attempted by several hundreds of students and on new problems that we hosted on pex4fun as part of a programming course attempted by students in the course .
experimental results show that i the manual teacher effort required to specify various algorithmic strategies is a small fraction of the overall task that our system automates.
in particular on our mooc style benchmark of functionally correct implementations to pre existingprogramming problems we specified strate gies in minutes after inspecting implementations.
on our standard classroom style benchmark of functionally correct implementations to programming problems we specified strategies in minutes after inspecting implementations.
ii our methodology for specifying and matching algorithmic strategies is both expressive and pre cise.
in particular we were able to specify all strategie s using our specification language and our dynamic analysis correctly matched each implementation with the intended strategy.
this paper makes the following contributions we observe that there are different algorithmic strategies used in functionally correct attempts to introductory programming assignments these strategies merit different performance related feedback.
we describe a new language construct called observe for specifying an algorithmic strategy .
we describe a dynamic analysis based approach to test whetherastudent simplementationmatchestheteacher s specification .
ourexperimental results illustrate theeffectiveness ofou r specification language and dynamic analysis .
.
overview in this section we motivate our problem definition and various aspects of our solution by means of various examples .
.
motivation fig.
1shows our runningexamples.
programs a i im showsome sample implementations for the anagram problem which involves testing whether the two input strings can be permuted to become equal on the pex4fun platform.
all programs are examples of inefficient implementations because of their quadratic asymptotic complexity .
an efficient solution for example is to first collect e.g.
in an array t he number of occurrences of each character in both strings and then compare them leading to linear asymptotic complexity .
algorithmic strategies .
in implementations imwe identify three different algorithmic strategies .
implementationsc1 c3iterate over one of the input strings and for each character in that string count the occurrences of that character in both strings counting strategy .
implementationss1 s3sort both input strings and check if they are equal sorting strategy .
implementations r1 r3iterate over one of the input strings and remove corresponding characters from the other string removing strategy .
implementation details .
an algorithmic strategy can have several implementations.
in case of counting strategy implementation c1callsmanuallyimplementedmethod countchar to count the number of characters in a string lines and while implementation c2uses a special c construct lines and and implementation c3uses the library function splitfor that task lines and .
in case of the sorting strategy implementation s1employs binary insertion sort while implementation s2employs bubble sort and implementation s3uses a library call lines and .
we also observe different ways of removing a character from a string in implementations r1 r3.
desired feedback .
eachofthethreeidentifiedstrategies requires separate feedback independent of the underlying implementation details to help a student understand and fix the performance issues.
for the first strategy implementationsc1 c3 a possible feedback might be calculate the number of characters in each string in a preprocessing phase instead of each iteration of the main loop for the second strategy s1 s3 it might be instead of sorting input strings compare the number of character occurrences in each string and for the third strategy r1 r3 use a more efficient data structure to remove characters .
.
specifying algorithmicstrategies key values .
our key insight is that different implementations that employ the same algorithmic strategy generate thesame key values duringtheirexecutiononthesameinput.1bool puzzle string s string t 2if s.length !
t.length return false 4foreach char ch in s.tochararray 5if countchars s ch !
countchars t ch 7return false 9return true 11int countchars string s char c 12int number 14foreach char ch in s.tochararray 15if ch c number 18return number 1bool puzzle string s string t 2if s.length !
t.length 3return false 4else 5return s.all c 6s.where c2 c2 c .count 7t.where c2 c2 c .count b counting library c2 1bool puzzle string s string t 2if s.length !
t.length return false 3foreach var item in s 4if s.split item .length !
t.split item .length 6return false 8return true 1int binarysearch list char xs char y 2int low high xs.count 3while low high 4int mid high low low 5if y xs high mid 6else if y xs low mid 7else return mid 8return low 10char sort string xs 11var res new list char 12foreach var x in xs 13var pos binarysearch res x 14res.insert pos x 15return res.toarray 17bool puzzle string s string t 18return string.join sort s string.join sort t a counting manual c1 c counting split c3 d sorting binary insertion s1 1bool puzzle string s string t 2if s.length !
t.length return false 3char sa s.tochararray 4char ta t.tochararray 5for int j j sa.length j 6for int i i sa.length i 7if sa sa char temp sa sa sa sa temp 9if ta ta char temp ta ta ta ta temp 12for int k k sa.length k 13if sa !
ta return false 14return true 1bool puzzle string s string t 2var sa s.tochararray 3var ta t.tochararray 4array.sort sa 5array.sort ta 6return sa.sequenceequal ta f sorting library s3 1bool puzzle string s string t 2if s.length !
t.length return false 3foreach char c in t.tochararray 4int index s.indexof c 5if index return false 6s s.remove index 7return true 1bool puzzle string s string t 2return ispermutation s t 4bool ispermutation string s string t 5if s t return true 6if s.length !
t.length return false 7int index t.indexof s 8if index return false 10s s.substring 11t t.remove index 13return ispermutation s t e sorting bubble s2 g removing library r1 h removing recursive r2 1bool puzzle string s string t 2char sc s.tochararray 3char tc t.tochararray 4char c 5if sc.length!
tc.length return false 6for int i i sc.length i 7c sc 8for int j j tc.length j 9if tc c tc break if j tc.length return false 14return true 1puzzle string s string t 2if nd1 string tt t t s s tt 3for int i i s.length i 4int cnt1 cnt2 5for int j j s.length j 6if s s if nd2 observe s cnt1 10if !nd2 observefun split 11observe nd2?
cnt1 cnt1 12for int j j t.length j if t s if nd2 observe t cnt2 17if !nd2 observefun split 18observe nd2?
cnt2 cnt2 1puzzle string s string t 2if nd1 s s.toupperinvariant 3char ca s.tochararray 4array.sort ca 5if nd2 array.reverse ca 6observe ca k sorting specification ss 1puzzle string s string t 2if nd1 string tt t t s s tt 3for int i i s.length i 4if s.substring i t return 5int ni nd2 ?
i s.length i 6int k nd3 ?
t.indexof s t.lastindexof s 8t t.remove k 9observe t compareletterstring i removing manual r3 j counting specification cs l removing specification rs 1bool puzzle string s string t 2if s.length !
t.length return false 3char taux t.tochararray 4for int i i s.length i 5char sc s 6boolean exists false 7for int j j t.length j 8if sc taux exists true taux break 11if exists false return false 12return true 1bool compareletterstring string a string b 2var la a.where x char.isletter x 3var lb b.where x char.isletter x 4return la.sequenceequal lb 1bool puzzle string s string t 2if s.length !
t.length return false 3int cs new int 4int ct new int 5for int i i s.length i 6cs 7for int i i t.length i 8ct 9for int i i i 10if cs !
ct return false 11return true m removing manual r4 n custom data equality cde o efficient compare e1 1bool puzzle string s string t 2if s.length !
t.length 3return false 4char cs s.tochararray 5char ct t.tochararray 6int hash new int 7for int i i i 8hash 10foreach char ch in cs 11hash 12foreach char ch in ct 13hash 14for int i i i 15if hash return false 17return true 1void puzzle string s string t 2if nd1 string tt t t s s tt 3int cs new int ct new int 4cover tochararray 5cover tochararray 6cover 7for int i i s.length i 8cs 9observe cs 10for int i i t.length i 11if nd2 cs observe cs else ct observe ct 17cover 1bool puzzle string s string t 2if s.length !
t.length return false 3string cp t 4for int i i s.length i 5char k s bool found false 6for int j j cp.length j 7if cp k if j cp char cp.substring else if j cp.length cp cp.substring j char else cp cp.substring j char cp.substring j found true break 16if !found return false 17return true p efficient difference e2 q efficient specification es r removing separate computation r5 figure running example implementations and specificati ons of anagram assignment.for example the underlined expressions in the implementationsc1andc2both produce the key value sequence a b a b a a a b a b a a a b a b a a on the input strings aba and baa .
our framework allows a teacher to describe an algorithmic strategy by simply annotating certain expressions in a sample implementation using a special language statement observe.
our framework decides whether or not a student implementation matches a teacher specification by comparing their execution traces on common input s .
we say that an implementation qmatches a specification p if the execution trace of pis a subsequence of the execution trace ofq and for every observed expression in pthere is an expression in qthat has generated the same values.
we call this matching criterion a trace embedding .
the notion of trace embedding establishes a fairly strong connection between specification and implementation basically both programs produce the same values at corresponding locations in the same order.
our notion of trace embedding is an adaptation of the notion of a simulation relation to dynamic analysis.
non deterministic choice .
because of minor differences between implementations of the same strategy keyvalues can differ.
for example implementation c3uses a library function to obtain the number of characters while implementations c1andc2explicitly count them by explicitly iterating over the string.
moreover counted values inc3are incremented by one compared to those in c1andc2.c3thus yields a different but related trace split split split split split split oninput strings aba and baa .
to address variations in implementation details we includea non deterministic choice construct in our specification language.
the non determinism is fixed before the execution thus such a choice is merely a syntactic sugar tosuccinctlyrepresent multiple similar specifications nnon deterministic variables 2nspecifications .
specifications .cs ss andrsdenote the specifications for the counting strategy used in implementations c1 c3 sorting strategy used in s1 s3 and removing strategy used in r1 r3 respectively.
in cs the teacher observes the characters that are iterated over lines and the results of counting the characters lines and and use of library function split lines and .
also the teacher uses non deterministic boolean variables nd1 line to choose the string over which the main loop iterates as the input strings are symmetric in the anagram problem andnd2to choose between manual and library function implementations which also decides on observed counted values on lines and .
in ssthe teacher observes one of the input strings after sorting and non deterministica lly allows that implementations convert input string to uppercase nd1online2 andsortthestringinreverseorder nd2 online5 .
noticethatitisenoughtoobserveonlyonesorted input as in the case that the input strings are anagrams the sorted strings are the same.
in rsthe teacher observes the string with removed characters and non deterministcal ly chooses which string is iterated nd1on line direction of the iteration nd2on line and the direction in which the remove candidate is searched for nd3on line .
.
specificationsandimplementationsexpression e d v v1opbinv2 opunv v1 statement s v e v1 e v f v1 ... v n s0 s1 whilevdos skip ifvthens0elses1 observe v observefun f figure the syntax of llanguage.
in this section we introduce an imperative programming languagelthat supports standard constructs for writing implementations and has some novel constructs for writing specifications.
.
the language l the syntax of the language lis stated in fig.
.
we discuss the features of the language below.
expressions .a data value dis any value from some data domain setd which contains all values in the language e.g.
in c all integers characters arrays hashsets ... .
a variable vbelongs to a finite set of variables var.
anexpression is either a data value d a variable v an operator applied to variables v1 v2or an array access v1 .
here opbinrepresents a set of binary operators e.g.
andopuna set of unary operators e.g.
.
we point out that the syntax of lensures that programs are inthree address code operators can only be applied to variables but not to arbitrary expressions.
the motivation for this choice is that three address code enables us to observe any expression in the program by observing only variables.
we point out that any program can be automatically translated into three address code by assigning eac h subexpression toanewvariable.
for example thestatement v1 v2 a b can be translated into three address code as follows v3 a b v1 v2 v3.
this enables us to observe the subexpression a bby observing v3.
statements .
the statements of lallow to build simple imperative programs assignments to variables and array elements skipstatement composition of statements looping andbranchingconstructs.
we also allow library functio n calls inl denoted by v f v1 ... v n where f fis a library function name from a set of all library functions f. there are two special observe constructs which are only available to the teacher and not to the student .
we discuss the observe statements in .
below.
we assume that each statement sis associated with a unique program locationl and write l s. functions .
for space reasons we do not define functions here.
we could easily extend the language to recursive functions.
in fact we allow recursive functions in our implementation.
semantics .
weassume some standardimperative semantics to execute programs written in the language l e.g.
for c we assume the usual semantics of c .
the two observestatements have the same semantic meaning of the skipstatement.
computation domain .
we extend the data domain d by a special symbol ?
which we will use to represent any data value.
we define the computation domain val associated with our language lasval d f d .
weassume the data domain dis equipped with some equality relation d d d e.g.
for c we have x y diff aandbare of the same type and comparison by the equals method returns true .
we denote bye 2val valthe set of all relations over val.
we define a default equality relation edef eas follows wehave x y edefiffx ?ory ?or x y d. we have f x1 ... x n f y1 ... y n edef ifff f and xi yi edeffor all i n. computation trace .
a computation trace oversome finite set of programming locations locis a finite sequence of location value pairs loc val .
we use the notation locto denote the set of all computation traces over loc.
given some locandloc loc we denote by loc thesequencethatwe obtainbydeletingall pairs l val from wherel e atio slash loc .
.
student implementation in the following we describe how a computation trace is generated for a student implementation qon a given input .
the computation trace is initialized to the empty sequence .
then the implementation is executed on according to the semantics of l. during the execution we append location value pairs to for every assignment statement for l v1 eorl v1 ewe append l v1 to we denote by v1 the current value of v1 .
we point out that we add the complete array v1 to the trace for an assignment to an array variable v1.
for a library function call l v f v1 ... v n we append l f v v1 ... vn to .
we denote the resulting trace by llbracketq rrbracket .
this construction of a computation trace can be achieved by instrumenting the implementation in an appropriate manner.
.
teacher specification the teacher uses observe andobservefun for specifying the key values she wants to observe during the execution of the specification and for defining an equality relation over computation domain.
as usual the rectangular brackets and enclose optional arguments.
in the following we describe how a computation trace is generated for a specification pon a given input .
the computation trace is initialized to the empty sequence .
thenthespecification isexecutedaccordingtothesemantic s ofl.
during the execution we append location value pairs to only for observe andobservefun statements for l observe v we append l v to we denote by v the currentvalue of v .
forl observefun f we append l f x1 ... x n to wherexi vi if the ithargument to fhas been specified and xi ?
if it has been left out.
we denote the resulting trace by llbracketp rrbracket .
custom data equality .
the possibility of specifying an equality relation e eat some location lis very useful for the teacher.
we point out that in practice the teacher has to specify eby an equality function val val true false .
the teacher can use eto define the equality ofsimilar computation values .
we show its usage on examplesr3andr4 both examples implement the removing strategy discussed in in almost identical ways the only difference is on lines and respectively where implementations use different characters to denote a charac ter removed from a string and .
in specification rs the teacher uses the equality function compareletterstring defined in cde which compares only letters of twostrings to define value representations of both implementations regardless of used characters as equal.
we call a function loc eacomparison function .
we define l efor every statement l observe v e or l observefun f e .
for statements where has been left out we set the default value l edef.
non deterministic choice .
we assume that the teacher can use some finite set of non deterministic boolean variablesb nd1 ... ndn var these are not available to the student .
non deterministic choice allows the teach er to specify variations in implementations as discussed in .
non deterministic variables are similar to the input variables in the sense that are assigned before program is executed.
we note that this results into 2ndifferent program behaviors for a given input.
.
matching in this section we define what it means for an implementation to partially match orfully match a specification and describe the corresponding matching algorithms.
the teacher has to determine for each specification which definition of matching has to be applied.
in case of partial matching we speak of inefficient specifications and in case of full matching of efficient specifications .
.
trace embedding we start out by discussing the problem of trace embeddingthat we use as a building block for the matching algorithms.
subsequence .
we call c partial full amatching criterion.
let 1 l1 val1 l2 val2 ln valn and 2 l val l val l m val m be two computation traces over some set of locations loc and let be some comparison function as defined in .
.
we say 1is asubsequence of 2w.r.t.
to c written 1 c 2 if there are indices k1 k2 kn msuch that for all i nwe haveli l kiand vali val ki li in case of c fullwe additionally require that 1and 2 l1 ... ln have the same length.
we refer to vali val ki li asequality check .
if li id the identity relation over val for all i n we obtain the usual definition of subsequence.
since deciding subsequence i.e.
1 c 2 is a central operation in this paper we state complexity of this decisio n problem.
it is easy to see that deciding subsequence require s onlyo m equality checks basically one iteration over 2is sufficient.
mapping function .
letloc1andloc2be two disjoint sets of locations.
we call an injective function loc1 loc2amapping function .
we lift to a function loc1 loc2by applying it to every location i.e.
we set l1 val1 l2 val2 for l1 val1 l2 val2 loc1.
given a comparison function a matching criterion c and computation traces 1 loc1and 2 loc2we say that 1can be embedded in 2by iff 1 c 2 and write 1 c 2. we refer to asembedding witness .
executing a program on set of assignments igives rise to a set of traces one for each assignment i. we say that the set of traces 1 ican be embedded in 2 iby iff 1 c 2 for all i.definition trace embedding .
trace embeddingis the problem of deciding for given sets of traces 1 i and 2 i a comparison function and a matching criterionc if there is a witness mapping function such that 1 c 2 for all i. complexity .
clearly trace embeddingis in np assuming equality checks can be done in polynomial time we first guess the mapping function loc1 loc2and then check 1 c 2 for all i which is cheap as discussed above .
however it turns out that trace embedding is npcomplete evenfor asingleton seti asingleton computation domainval and the full matching criterion .
theorem .trace embedding is np complete assuming equality checks can be done in polynomial time .
proof.
in order to show np hardness we reduce permutation pattern to trace embedding.
first we formally define permutation pattern.
let n kbe positive integers withk n. let be a permutation of n and let be a permutation of k .
we say occursin if there is an injective function k n such that is monotone i.e.
for all r s kwe have r s and k is a subsequence of n .permutation pattern is the problem of deciding whether occurs in .
we now give the reduction of permutation pattern to trace embedding.
we will construct two traces 1and 2 over a singleton computation domain val and over the sets oflocations loc1 ... k andloc2 ... n .
weset i id the identity function on val for every i loc1.
because valis singleton we can ignore values in the rest of the proof.
we set 1 k k and 2 n n .
because every i k occurs exactly twice in 1and 2 partial and full matching criteria are equivalent so we can ignore the difference.
we now show that occurs in iff there is an injective function loc1 loc2with 1 2. we establish this equivalence by two observations first because every i k occurs exactly twice in 1and 2we have k 12 n and k n iff 1 2. second k 12 niff loc1 loc2is monotone.
algorithm .
fig.
shows our algorithm embed for the trace embedding problem.
a straightforward algorithmic solution for the trace embedding problem is to simply test all possible mapping functions.
however there is an exponential number of such mapping functions w.r.t.
to the cardinality of loc1andloc2.
this exponential blowup seems unavoidable as the combinatorial search space is responsib le for the np hardness.
the core element of our algorithm is a pre analysis that narrows down the space of possible mapping functions effectively.
we observe that if l2 l1 and 1 c 2 then there exists a trace embedding restricted to locations l1andl2 formally 1 l1 l1 mapsto l2 c 2 l2 .
the algorithm uses this insight to create a bipartite grap h g loc1 loc2of potential mapping pairs in lines .
a pair of locations l1 l2 gis apotential mapping pair iff there exists a trace embedding restricted to locations l1and l2 as described above.
the key idea in finding an embedding witness is to construct a maximum bipartite matching ing.
a maximum bipartite matching has an edge connecting every program1 embed 1 i 2 i loc1 loc2 c g loc1 loc2 for alll1 loc1 l2 loc2 for all i if 1 l1 e atio slash l1 mapsto l2 c 2 l2 g g l1 l2 break for all maximumbipartitematching g found true for all i if 1 e atio slash c 2 found false break iffound true return true returnfalse figure algorithm for trace embedding problem.
location from loc1to a distinct location in loc2and thus gives rise to an injective function .
we point out that such an injective function does not need to be an embedding witness because by observing only a single location pair at a time it ignores the order of locations.
thus for each maximum bipartite matching the algorithm checks in lines if it is indeed an embedding witness.
the key strength of our algorithm is that it reduces the search space for possible embedding witnesses .
the experimental evidence shows that this approach significantly reduces the number of possible matchings and enables avery efficient algorithm in practice as discussed in .
.
partialmatching wenowdefinethenotionof partial matching alsoreferred to simply as matching which is used to check whether an implementation involves at least those inefficiency issue s that underlie a given inefficient specification.
definition partial matching .
letpbe a specification with observed locations loc let be the comparison function specified by p and let qbe an implementation whose assignment statements are labeled by loc .
then implementation q partially matches specification p on a set of inputs i if and only if there exists a mapping function loc1 loc2and an assignment to the non deterministic variables ndsuch that 1 c 2 for all input values i where 1 llbracketp rrbracket nd 2 llbracketq rrbracket and c partial.
fig.
describes an algorithm for testing if an implementation partially matches a given specification over a given s et of input valuations i. in lines the implementation qis executed on all input values i. in line the algorithm iterates throughall assignments ndtothenon deterministic variables bpof the specification p. in lines the specification pis executed on all inputs i. with both sets of traces available line calls subroutine embedwhich returnstrueiff there exists a trace embedding witness.
example .
we now give an example that demonstrates our notion of programs and that contains example applications of algorithms embedandmatches .
in fig.
we state two implementations a and b and one specification c .
these programs represent simplified versions transformed into three adress code of r1 after function inlining r31 matches specification p implementation q inputsi loc1 observed locations in p comparison function specified by p c matching criterion loc2 assignment locations of q for all i 2 llbracketq rrbracket bp non deterministic variables in p for allassignments ndtobp for all i 1 llbracketp rrbracket nd ifembed 1 i 2 i loc1 loc2 c returntrue returnfalse figure matching algorithm.
1puzzle s t 2i 3n s 4while i n 5c s 6j 7cnt1 8while j n 9c2 s if c c2 cnt1 cnt1 j j 13j 14cnt2 15while j n c2 t if c c2 cnt2 cnt2 j j 20i i a 1puzzle s t 2i 3n s 4while i n 5c s 6ss split s c 7cnt1 ss 8st split t c 9cnt2 st 10i i b 1puzzle s t 2i 3n s 4while i n 5c s 6observe c 7j 8cnt1 9while j n c2 s if nd1 observe c2 j j 14j 15if !nd1 observefun split 17while j n c2 t if nd1 observe c2 j j 22if !nd1 observefun split 24i i c figure implementations a b and spec.
c .
andsc .
note that every assignment and observe statement is on its own line we denote line iin program x by by location lx i. the argument has been left out for all locations in the specification thus we have l edef for all specification locations l. algorithm matches runs all three programs on input values s aab and t aba .
for program a we obtain the following computation trace a la la la a la la la a la la la a la la la b la la similarly for program b we obtain b lb lb lb a lb split aab a lb lb split aba a lb lb lb a for specification c we obtain two traces depending on the choice for the non deterministic variable nd1 c t lc a lc a lc a lc b lc a lc b c f lc a lc split ?
?
lc split ?
?
algorithm matches then calls embedto check for trace embedding.
algorithm embedfirst constructs a potential graphg which contains an edge for two locations of the specification and the implementation that show the same values.
forimplementation a weobtainthefollowing graph ga lc la lc la lc la lc la lc la .
noticethat lc 6showsthesamevaluesasthelocations la la la in the implementation a .
however there is only one maximalmatchingin ga a lc la lc la lc la which is also an embeddingwitness thus implementation a matches specification c .
for implementation b and nd1 true we obtain the graphgb t lc lb from which we cannot construct a maximal matching.
however for nd1 false we obtain gb f lc lb lc lb lc lb which is also an embedding witness thus implementation b matches specification c .
.
full matching below we will define the notion of full matching which is used to match implementations against efficient specifications.
we will require that for every loop and every library function call in the implementation there is a correspondin g loop and library function call in the matching specification .
in order to do so we need some helper definitions.
observed loop iterations .
we extend the construction of the implementation trace definedin .
for each statementl whilevdos we additionally appendelement l to the trace whenever the loop body sis entered.
we call l aloop iteration .
let be a embedding witness s.t.
1 2. we say that observes all loop iterations iff between every two loop iterations l in 2there exists a pair l val such that l .
l l .
in other words we require that between any two iterations of the same loop there exists some observed location l .
observed library function calls .
we say that observes all library function calls iffforevery l f val1 ... valn in 2there is a l such that l l. definition full matching .
letpbe a specification with observed locations loc let be the comparison function specified by p and let qbe an implementation whose assignment statements are labeled by loc .
then implementation qfully matches specification p on a set of inputs i if and only if there exists a mapping function loc1 loc2and an assignment to the non deterministic variables ndsuch that 1 c 2 for all input valuations i where 1 llbracketp rrbracket nd 2 llbracketq rrbracket c full and observes all loop iterations and library function calls.
we note that procedure embed can easily check at line whether the current mapping observes all loop iterations and library function calls.
itis tediousforateacherto exactly specify all possible loop iterations and library function calls used in different effici ent implementations.
we add two additional constructs to the languagelto simplify this specification task.
cover statement .
we extendlby twocover statements l cover f andl cover v .
the first statement is the same as the statement l observefun f except that we allow the embedding witness to not map lto any location in the implementation.
thisenablestheteachertospecifythatfunction f v1 ... v m may appear in the implementation.
the second statement allows to maplto a location l that appears at most v times for each appearance of l where v is the current value of the specified variable v. thuscover v enables the teacher to cover any loop with up to v iterations.
example .
now we present examples for efficient implementations e1ande2 and specification es for the anagram problem .
the teacher observes computed values on lines 12and and uses anon deterministicchoice on line to choose if implementations count the number of characters in each string or decrement one number from another.
also the teacher allows up totwo library function calls and two loops with at most iterations defined by coverstatements on lines and .
.
extensions in this section we discuss useful extensions to the core material presented above.
these extensions are part of our implementation but we discuss them separately tomake the presentation easier to follow.
one to many mapping .
accordingtodefinitionoftrace embedding an embedding witness maps one implementation location to a specification location i.e.
it construc ts a one to one mapping.
however it is possible that a student splitsa computation of some value over multiple locations.
for example in the implementation stated in r5 the student removes a character from a string across three different locations on lines and depending on the location of the removed character in the string.
this requires to map a singlelocation from the specification to multiple locations in the implementation!
for this reason we extend the notion of trace embedding to one to many mappings loc1 2loc2where l l for all l e atio slash l .
it is easy to extend procedure embed to this setting the potential graph gis also helpful to enumerate every possible one to many mapping.
however it is costly andunnecessary tosearch for arbitrary one to ma ny mappings.
we use heuristics to consider only a few one tomany mappings.
for example one of the heuristics in our implementation checks if the same variable is assigned in di fferent branches of an if statement e.g.
in example r5 for all three locations there is an assignment to variable cp .
although many to many mappings may seem more powerful we point out that the teacher can always write a specification that is more succinct than the implementation of the student i.e.
the above described one to many mapping s provide enough expressivity to the teacher.
non deterministic behaviour .
trace embedding requiresequal values in thesame order in the specification and implementationtraces.
however animplementationcanuse alibraryfunctionwithnon deterministicbehaviour e.g.
the values returned by a random generator or the iteration order over a set data structure.
for such library functions we elim inate non determinism by fixing one particular behaviour i.e we fix the values returned by a random generator or the iteration order over a set during program instrumentation.
these fixes do not impact functionally correct programs because they cannot rely on some non deterministic behaviour but allow us to apply our matching techniques.
.
implementationandexperimentswe now describe our implementation and present an experimental evaluation of our framework.
more details on our experiments can we found on the website .
.
experimental setup our implementation of algorithm matches is in c and analyzes c programs i.e.
implementations and specifications are in c .
we used microsoft s roslyn compiler framework for instrumenting every sub expressio n to record value during program execution.
data.
weused 3preexistingproblems from pex4fun as mentioned in the anagram problem where students are asked to test if two strings could be permuted to become equal the issorted problem where students are asked to test if the input array is sorted and the caesarproblem where students are asked toapply caesar cipher to the input string.
we have chosen these specific problems because they had a high number of student attempts diversity in algorithmic strategies and a problem was explicitly stated for many problems on pex4fun platform students have to guess the problem from failing input output examples .
we also created a new course on the pex4fun platform with programming problems.
these problems were assigned as a homework to students in a second year undergraduate course.
we created this course to understand performance related problems that csstudents make as opposed to regular pex4fun users who might not have previous programming experience.
we encouraged our students to write efficient implementations by giving more points for performance efficiency than for mere functional correctness .
we omit the description of the problems here but all descriptions are available on the original course page .
.
methodology in the following we describe the methodology by which we envision the technique in the paper to be used.
theteacher maintainsasetof efficientandinefficientspecifications.
a new student implementation is checked against all available specifications.
if the implementation matche s some specification the associated feedback is automatical ly provided to the student otherwise the teacher is notified that there is a new unmatched implementation.
the teacher studies the implementation and identifies one of the following reasons for its failure to match any existing specificati on i the implementation uses a new strategy not seen before.
in this case the teacher creates a new specification.
ii th e existing specification for the strategy used in the implemen tation is too specific to capture the implementation.
in this case the teacher refines that existing specification.
this overall process is repeated for each unmatched implementation.
new specification .
a teacher creates a new specification using the following steps i copy the code of the unmatched implementation.
ii annotate certain values and function calls with observe statements.
iii remove any un necessary code not needed in the specification from the implementation.
iv identify input values for the dynamic analysis for matching.
v associate a feedback with the specification.
specification refinement .
to refine a specification the teacher identifies one of the following reasons as to why an implementation did not match it i the implementation differs in details specified in the specification ii th e0 ofinspection steps of matched implementations a of required inspection steps time of matched implementations b time required to write refine specifications anagram issorted caesar ofinspection steps of matched implementations c of required inspection steps time of matched implementations d time required to write refine specifications doublechar longestequal longestword runlength vigenere basetobase catdog minimaldelete commonelement order3 ofinspection steps of matched implementations c of required inspection steps time of matched implementations d time required to write refine specifications 2dsearch tableaggsum intersection reverselist sortingstrings minutesbetween maxsum median digitpermutation coins seq235 figure the number of inspection steps and time required to completely specify assignments.problem correct inefficientnsind ls liosoimperformance name implement.
implement.
avg.
max.
anagram .
.
.
.
.
issorted .
.
.
.
.
caesar .
.
.
.
.
doublechar .
.
.
.
.
longestequal .
.
.
.
.
longestword .
.
.
.
.
runlength .
.
.
.
.
vigenere .
.
.
.
.
basetobase .
.
.
.
.
catdog .
.
.
.
.
minimaldelete .
.
.
.
.
commonelement .
.
.
.
.
order3 .
.
.
.
.
2dsearch .
.
.
.
.
tableaggsum .
.
.
.
.
intersection .
.
.
.
.
reverselist .
.
.
.
.
sortingstrings .
.
.
.
.
minutesbetween .
.
.
.
.
maxsum .
.
.
.
.
median .
.
.
.
.
digitpermutation .
.
.
.
.
coins .
.
.
.
.
seq235 .
.
.
.
.
table list of all assignments with the experimental resul ts.
specification observes more values than those that appear in the implementation iii the implementation uses differen t data representation.
in case i the teacher adds a new nondeterministic choice and if necessary observes new valu es or function calls in case ii the teacher observes less val ues and in case iii the teacher creates or refines a custom data equality.
input values .
our dynamic analysis approach requires theteachertoassociate inputvalueswithspecifications.
t hese input values should cause the corresponding implementations toexhibittheirworst case behavior otherwise anin efficient implementation might behave similar toan efficient implementation and for this reason match the specification of the efficient implementation.
this implies that trivialinputs should be avoided.
for example two strings with unequal lengths constitute a trivial input for the counting strateg y since each of its three implementations c1 c3 then exit immediately.
similarly providing a sorted input for t he sorting strategy is meaningless.
we remark that it is easy for a teacher who understands the various strategies to provide good input values.
granularity of feedback .
we want to point out that the granularity of a feedback depends on the teacher.
for example in a programming problem where sorting the input value is an inefficient strategy the teacher might not want to distinguish between different sorting algorithms as they d o not require adifferent feedback.
however in a programming problem where students are asked to implement a sorting algorithm it makes sense to provide a different feedback for different sorting algorithms.
.
evaluation we report results on the problems discussed above in table .
results from manual code study .
we first observe that a large numberof students managed to write afunctionally correct implementation on most of the problems col umncorrect implementations .
this shows that pex4fun succeeds in guiding students towards a correct solution.
our second observation is that for most problems a large fraction of implementations is inefficient column inefficient implementations especially for anagram problem .
this shows that although students manage to achieve functional correctness efficiency is still an issue recall that in our homework the students were explicitly asked and given extra points for efficiency .
we also observe that for all except two problems there is at least one inefficient algorithmic strategy and for most problems .
there are several inefficient algorithmic strategies column n .these results highly motivate the need for a tool that can find inefficient implementations and also provide a meaningful feedback on how to fix the problem .
precision and expressiveness .
for each programming assignment we used the above described methodology and wrote a specification for each algorithmic strategy both ef ficient and inefficient .
we then manually verified that each specification matches all implementations of the strategy hence providing desired feedback for implementations.
this shows that our approach is preciseandexpressive enough to capture the algorithmic strategy while ignoring low lev el implementation details.
teacher effort .
to provide manual feedback to students the teacher would have to go through every implementation and look at its performance characteristics.
in our approac h the teacher has to take a look only at a few representative implementations.
in column swe report the total number of inspection steps that we required to fully specify one programming problem i.e.
the number of implementations that the teacher would had to go through to provide feedbackonallimplementations.
forthe3pre existingproblem s the teacher would only have to go through out of or around implementations to provide full feedback .
fig.
shows the number of matched implementations with each inspection step as well the time it took us to create refine allspecifications we measured the time it takes from seeing an unmatched implementation until writing refining a matching specification for it .
in columnls liwe report the largest ratio of specification and average matched implementation in terms of lines of code.
we observe that in half of the cases the largest specification is about the same size or smaller than the average matched implementation.
furthermore the number of the input values that need to be provided by the teacher is across all problems column i .
in all but one problem issorted one set of input values is used for all specifications.
also in about one third of the specifications there was no need for non deterministic variables and the largest number used in one specification is column nd .overall our semi automatic approach requires considerably less teach er effort than providing manual feedback .
performance .
we plan to integrate our framework in a mooc platform so performance as for most web applications is critical.
our implementation consists of tw o parts.
the first part is the execution of the implementation and the specification usually small programs on relatively small inputs and obtaining execution traces which is in most cases neglectable in terms of performance.
the second part is the embedalgorithm.
as discussed in .
the challenge consists in finding an embedding witness .
withosobserved variables in the specification and oiobserved variables in the implementation there areoi!
oi os !
possible injective mapping functions.
e.g.
for the sortingstrings problem that gives 1026possible mapping functions oi os .
however our algorithm reduces this huge search space by constructing a bipartite graph g of potential mappings pairs.
in mwe report the number of mapping functions that our tool had to explore.
e.g.
for sortingstrings only different mapping functions had to be explored.
for all values os oiandm we report the maximal numberacross all specifications.
inthe last column we state the total execution time required to decide if one implementation matches the specification average and maximal .
note that this time includes execution of both programs exploration of all assignments to non deterministi c boolean variables and finding an embedding witness .
our tool runs in most cases under half a second per implementation.these results show that our tool is fast enough to be used in an interactive teaching environment.
.
threats to validity unsoundness .
our method is unsound in general since it uses a dynamic analysis that explores only a few possible inputs.
however we did not observe any unsoundness in our large scale experiments.
if one desires provable soundness an embedding witness could be used as a guess for a simulation relation that can then be formally verified by other techniques.
otherwise a student who suspects an incorrect feedback can always bring it to the attention of the teacher.
program size .
we evaluated our approach on introductory programming assignments.
although questions about applicability to larger programs might be raised our goal was not to analyze arbitrary programs but rather to develop a framework to help teachers who teach introductory programming with providing performance feedback currently a manual error prone and time consuming task.
difficulty of the specification language .
although we did not perform case study with third party instructors we report our experiences with using the proposed language.
we would also like to point out that writing specifications is a one time investment which could be performed by an experienced personnel.
.
related work .
automated feedback there has been a lot of work in the area of generating automated feedback for programming assignments.
this work can be classified along three dimensions a aspects on which the feedback is provided such as functional correct ness performance characteristics or modularity b natur e of the feedback such as counterexamples bug localization o r repair suggestions and c whether static or dynamic analysis is used.
ihantola et.al.
present a survey of various systems developed for automated grading of programming assignments.
the majority of these efforts have focussed on checking for functional correctness.
this is often done by examining the behavior of a program on a set of test inputs.
these test inputs can be manually written or automatically generated .
there has only been little work in testing for non functional properties.
the assyst system uses a simple form of tracing for counting execution steps to gather performance measurements .
the scheme robo system counts the number of evaluations done which can be used for very coarse complexity analysis.
the authors conclude that better error messages are the most important area of improvement .
the ai community has built tutors that aim at bug localization by comparing source code of the student and the teacher s programs.
laura converts teacher s and student s program into a graph based representation and compares them heuristically by applying program transformationswhilereportingmismatchesaspotentialbugs.
talus matches a student s attempt with a collection of teacher s a lgorithms.
it first tries to recognize the algorithm used and then tentatively replaces the top level expressions in the student s attempt with the recognized algorithm for generatin g correction feedback.
in contrast we perform trace comparison instead of source code comparison which provides robustness to syntactic variations.
striewe and goedicke have proposed localizing bugs by trace comparisons.
they suggested creating full traces of program behavior while running test cases to make the program behavior visible to students .
they have also suggested automatically comparing the student s trace to that of a sample solution for generating more directed feedback.
however no implementation has been reported.
we also compare the student s trace with the teacher s trace but we look for similarities as opposed to differences.
recently it was shown that automated techniques can also provide repair based feedback for functional correctn ess.
singh s sat solving based technology can successfully generate feedback of up to corrections on around of all incorrect solutions from an mit introductory programming course in about seconds on average.
while test inputs provide guidance on whya given solution is incorrect and bug localization techniques provide guidance on where the error might be repairs provide guidance on howto fix an incorrect solution.
we also provide repair suggestions tha t are manually associated with the various teacher specifica tions but for performance based aspects.
furthermore our suggestions are not necessarily restricted to small fixes.
.
performance analysis the programming languages and software engineering communities have explored various kinds of techniques to generate performance related feedback for programs.
symbolic execution based techniques have been used for identifying non termination related issues .
the speed project investigated use of static analysis techniques for estimating symbolic computational complexity of programs .
goldsmith et.al.
used dynamic analysis techniques for empirical computational complexity .
the toddler tool reports a specific pattern computations with repetitive and similar memory access patterns .
the cachetor tool reports memoization opportunities by identifying ope rations that generate identical values .
in contrast we are interested in not only identifying whether or not there i s a performance issue but also identifying its root cause and generating repair suggestions.
.