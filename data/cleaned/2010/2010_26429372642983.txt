fusing fault localizers lucia1 david lo1 and xin xia2 1school of information systems singapore management university 2college of computer science and technology zhejiang university lucia.
davidlo smu.edu.sg xxkidd zju.edu.cn abstract many spectrum based fault localization techniques have been proposed to measure how likely each program element is the root cause of a program failure.
for various bugs the best technique to localize the bugs may differ due to the characteristics of the buggy programs and their program spectra.
in this paper we leverage the diversity of existing spectrum based fault localization techniques to better localize bugs using data fusion methods.
our proposed approach consists of three steps score normalization technique selection and data fusion.
we investigate two score normalization methods two technique selection methods and five data fusion methods resulting in twenty variants of fusion localizer.
our approach is bug specific in which the set of techniques to be fused are adaptively selected for each buggy program based on its spectra.
also it requires no training data i.e.
execution traces of the past buggy programs.
we evaluate our approach on a common benchmark dataset and a dataset consisting of real bugs from three medium to large programs.
our evaluation demonstrates that our approach can significantly improve the effectiveness of existing state of the art fault localization techniques.
compared to these state of the art techniques the best variants of fusion localizer can statistically significantly reduce the amount of code to be inspected to find all bugs.
our best variants can increase the proportion of bugs localized when developers only inspect the top most suspicious program elements by more than and increase the number of bugs that can be successfully localized when developers only inspect up to program blocks by more than .
categories and subject descriptors d. .
testing and debugging debugging aids d. .
software engineering distribution maintenance and enhancement corrections keywords fault localization data fusion .
introduction many fault localization techniques have been proposed to locate the root cause of a program failure by analyzing the program traces permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
ase september vasteras sweden.
copyright acm ... .
.
the abstraction of program behaviors .
spectrum based fault localization techniques compare the spectra of correct and failed executions to identify program elements i.e.
statements blocks methods and components that are likely to be the root cause of a program failure.
these techniques often use statistical analysis to assign a suspiciousness score to each program element based on its likelihood to be faulty.
the higher the score the more suspicious an element is.
a list of the most suspicious program elements is then presented to developers.
developers can then inspect the list starting from the most suspicious elements.
lucia et al.
have found that the best performing spectrum based fault localization techniques vary for different buggy programs .
some techniques can rank faulty elements at the top positions for some buggy programs while for other buggy programs they rank faulty elements low in the list.
in this work we aim to better localize the bugs by leveraging diversity of existing spectrum based fault localization techniques in particular association measures tarantula and ochiai .
since these techniques are lightweight we could inexpensively obtain suspiciousness scores for program elements by using different techniques.
different from the approach proposed by santelices et al.
that analyze several types of program spectra using a single technique we combine many techniques that analyze a single type of program spectra i.e.
block hit spectra .
data fusion methods have been proposed in the domain of information retrieval to rank documents such that the most relevant ones are in the top positions by combining ranking information from different retrieval systems .
we incorporate data fusion methods with the goal of ranking the faulty program elements higher in the list by combining the scores or ranks assigned to program elements by different fault localization techniques.
our approach referred to asfusion localizer normalizes the suspiciousness scores of different fault localization techniques selects fault localization techniques to be fused and combines the selected techniques using a data fusion method.
we propose variants of fusion localizer that use different score normalization technique selection and data fusion methods.
related to our work wang et al.
propose anapproach that linearly combines the scores of a number of association measures to rank faulty program elements at the top positions.
their approach generates a weight for each association measure using genetic algorithm based on a set of training data i.e.
program traces of the past program failures and the corresponding faults of the past failures .
however training data is often unavailable in many cases such as when developers work onanew software or when developers do not store traces of the past program failures.
furthermore the bugs and failures in the training set may not be representative enough for the incoming buggy programs which could limit the effectiveness of the approach in localizing faults.
different from this technique our approach requires no training set to leverage diversity of fault localization techniques.
furthermore our approach is bug specific it adaptively chooses a different set of techniques to be fused for different buggy programs based on their program spectra.
we have evaluated our approach on a commonly used benchmark dataset consisting of small to medium sized programs written in c and java and our own dataset consisting of real bugs collected from larger programs namely rhino lucene and ant.
we compare our approach against a number of state of the art spectrumbased fault localization techniques that also do not require training data and analyze a single type of program spectra i.e.
taran tula ochiai theoretically best spectrum based fault localization techniques and theoretically best genetic programming gp based fault localization techniques .
our experiment results show that our approach outperforms these techniques.
the best performing variants of fusion localizer i.e.
zzero one bias combanz andzzero one overlap combanz statistically significantly outperform the state of the art spectrum based fault localization techniques.
these best variants require statistically significantly smaller average percentage of code inspected to locate faulty elements as compared to the best performing state of the art fault localization techniques i.e.
vs. .
when developers only inspect of the most suspicious program elements these best variants could improve the percentage of bugs localized by the best performing state of the art fault localization techniques by to .
furthermore when developers only inspect the top most suspicious program blocks these best variants could improve the number of bugs localized by the best performing state of the art fault localization techniques by to .
the main contributions of this work are as follow .
we leverage diversity of association measures tarantula and ochiai to better localize bugs using data fusion methods.
.
we provide a bug specific approach which adaptively selects a set of techniques to be fused for each buggy program.
.
we propose an approach that does not require any training data e.g.
program traces of the past program failures to select which techniques to be fused to better localize bugs in programs.
.
we show that combining the lists of most suspicious program elements recommended by different fault localization techniques i.e.
association measures tarantula and ochiai using data fusion methods can improve the effectiveness in localizing faults and statistically significantly outperform the state of theart spectrum based fault localization techniques.
we organize this work as follows.
we first present closely related work in section .
section provides a motivating example to illustrate the benefit of our data fusion approach.
we elaborate our approach in section .
section presents our experiment results that demonstrate the effectiveness of our approach.
we finally conclude and mention future work in section .
.
related work a number of fault localization techniques have been proposed to help developers find the locations of faults in programs .
in this section we discuss several techniques that are closely related to this work.
the survey here is by no means complete.
one family of fault localization techniques is spectrum based fault localization techniques that analyze program spectra of correct and failed executions using statistical analysis to identify possible faulty program elements e.g.
statements basic blocks func tions and components .
jones and harrold propose a technique called tarantula to measure the suspiciousness of program elements to be the root cause of program failures based on the spectra of correct and failed executions of the programs and then descendingly rank the elements based on their suspiciousness scores .
similarly abreu et al.
propose a technique called ochiai similarity coefficient which is well known in the biology community to localize faults and show that ochiai can effectively localize bugs .
a number of association measures introduced in statistic and data mining community have also been applied for fault localization .
the studies in show that there is no single measure that outperforms other measures for all bugs.
our technique aims to leverage diversity of the above techniques to better localize bugs.
instead of empirically studying the effectiveness of a fault localization technique on various faults naish et al.
theoretically analyze a number of formulas that can be used to compute suspiciousness scores of program elements in idealized conditions .
their study is later extended by xie et al.
which theoretically analyze formulas and group them into equivalence classes .
they prove that under some conditions two families i.e.
er1 and and er5 outperform the rest.
these families include five formulas naish1 naish2 wong1 russel rao and binary.
instead of manually designing fault localization formulas yoo generates a number of formulas using genetic programming .
the effectiveness of these formulas are then theoretically studied by xie et al.
.
they find that gp13 gp02 gp03 andgp19 are the best ones for fault localization.
instead of generating new formulas we combine multiple formulas to improve their effectiveness in localizing faults.
the above techniques analyze a single type of program spectra to assign suspiciousness scores to program elements.
differently santelices et al.
collect a number of program spectra types i.e.
statement branches and du pair spectra where for each program spectra a single fault localization technique i.e.
ochiai is used to assign a suspiciousness score for each program element .
for each program element they combine its suspiciousness scores produced by analyzing different types of program spectra.
different from santelices et al.
s technique our technique analyzes a single program spectra type i.e.
block spectra using a number of fault localization techniques.
thus we are investigating orthogonal directions and it is possible to combine our approach and santelices et al.
s approach in a future work.
our technique is also related to the technique proposed by wang et al.
.
for every program element their technique linearly combines the scores of a number of association measures where each measure obtains a weight which is calculated based on a set of training data using genetic algorithm.
different from their technique our technique does not require any training data which makes our technique applicable to new programs or when program spectra of relevant past program failures are unavailable.
also their technique applies the same set of measures and the same set of weights to localize bugs for different buggy programs.
different from wang et al.
s technique our technique selects a different set of techniques or set of weights to localize faults for each buggy program based on its program spectra.
while wang et al.
s approach is one sizefits all our approach is bug specific.
.
motiv ating example this section provides an illustration of the benefit of using data fusion to leverage different techniques to help ranking faulty program elements at the top positions.
figure contains a sample program code excerpted from one of our subject programs i.e.
128ochiai klosgen ochiai klosgenpiatetsky shapiro return .
.
.
block i dprogram element ssuspicious scores normalized scores combsum .
.
.
.
3del sum .
ap a for n n itmax n .
.
.
11double a x double ap del sum int n double temp if x .
.
.
.
4sum del x ap if abs del abs sum eps .
.
.
bugs supposed to be temp sum exp x a log x lgamma a temp sum exp x a log x lgamma a return temp .
.
1piatetsky shapirofigure an example of using a data fusion method method gser of tot info version .
in this example we divide the code into five program blocks.
the bug is in block where the value assigned to a variable temp is incorrectly calculated.
various spectrum based fault localization techniques such as ochiai klosgen and piatetsky shapiro can be used to assign asuspicious ness score to each program block.
based on thescore ofeach program block developers could inspect the program blocks starting from the most suspicious blocks.
figure also shows the suspiciousness score of each program block as output by ochiai klosgen and piatetsky shapiro.
these scores are computed by analyzing the program traces collected during the executions of the test cases that come with the program i.e.
tot info .
according to ochiai and klosgen the most suspicious program blocks are blocks to followed by block then block .
since blocks to receive the same score in the worst case developers need to inspect three blocks to find the buggy block.
according to piatetsky shapiro blocks and are the most suspicious program blocks followed by blocks and .
since blocks and receive the same score in the worst case developers need to inspect two blocks to find the buggy block.
in this example locating the faulty block based on the recommendation by piatetsky shapiro requires examining fewer blocks than when following the recommendation by ochiai or klosgen.
a simple data fusion method to combine asetof techniques is combsum .
comb sum canbeused tocombine the scores output by ochiai klosgen and piatetsky shapiro to produce a new score for each program block.
for each program block the new score is calculated by summing up the normalized scores given by ochiai klosgen and piatetsky shapiro.
as the ranges of the scores produced by these techniques may be different we need to normalize the scores to make them comparable.2from figure the combsum score for block is .
we also compute the combsum score for the other blocks similarly.
finally we find that block is the most suspicious block as it has the highest score among all of the blocks.
using the list of most suspicious blocks recommended by combsum developers could locate the faulty block by only inspecting the first block which is more effective than using the list of most suspicious blocks recommended by either ochiai klosgen or piatetsky shapiro.
in this example we show that a data fusion method can be used to boost the effectiveness of fault localization techniques.
1please refer to for the formulas that these techniques use to compute the suspiciousness scores.
2we elaborate the details of the normalization process in section .
.
fusion localizer in this section we present our approach that incorporates data fusion methods to locate the source of a program failure.
the overview of this approach is presented in section .
.
three main steps of our approach namely score normalization technique selection and data fusion are elaborated in sections .
.
and .
respectively.
for each step we present several techniques that we can use to achieve the respective goal.
.
overview our approach combines the scores from different spectrum based fault localization techniques to produce a new ranking with the goal of improving fault localization effectiveness.
in this work we employ spectrum based fault localization techniques because they are lightweight and have good accuracies.
nevertheless it is also possible to use other fault localization techniques that can assign scores to program elements.
the overall framework of our approach named fusion localizer is shown in figure .
the input to our approach is a set of spectrum based fault localization techniques which computes the suspiciousness scores of all program elements in a buggy program.
in this work we use two well known spectrum based fault localization techniques tarantula and ochiai as well as association measures that have been studied for fault localization .
different techniques use different formulas to calculate suspiciousness scores.
each formula has its own characteristics especially in terms of the range and distribution of the suspiciousness scores computed using it.
thus normalizing the scores is essential so that scores produced by different measures can be compared with one another.
for every technique the suspiciousness scores that are assigned to program elements can be normalized into a new set of scores that fall in the range of zero to one.
section .
elaborates methods that we use in this work to normalize the scores.
after the scores are normalized our approach adaptively selects techniques to be fused together based on the spectra of the buggy program.
our goal is to select a set of techniques that complement one another well for a particular buggy program.
section .
elaborates the methods that we use in this work to select the techniques.
given a set of normalized scores from the selected techniques wecombine the scores using a number of existing data fusion methods.
anew setofscores would then beassigned toprogram elements forthegiven buggy program.
these new scores canbe used to create a new list for developer s inspection.
section .
elab129figure overview of fusion localizer orates themeth odsthatweusetocombine thenormalized scores from theselected fault localizationtechniques.
.
step score normalization in this work we apply two score normalization methods zeroone score normalization and reciprocal ranking normalization .
each of them can be used as the first step of fusion localizer.
the following paragraphs discuss how these normalization methods work.
zero one score normalization this method transforms scores from different fault localization techniques into the same range i.e.
zero to one.
the method works as follows.
letnbe the total number of techniques and mbe the total number of program elements for a given buggy program then si ej denotes the score of the j th program element assigned by the ith technique where j mand i n. furthermore let max sidenotes the maximum score produced by the i th technique and min s idenotes the minimum score produced by the i th technique.
the normalized score of the j th program element given by the i th technique is calculated as follows s norm i ej si ej min s i max si min s i reciprocal rank normalization instead of directly normalizing a list of scores produced by different techniques this method considers the ranks of program elements and transforms them into normalized scores.
the method works as follows.
letnbe the total number of techniques and mbe the total number of program elements in a buggy program.
also let ri ej denotes the rank of the j th program element assigned by the i th technique where j mand1 i n. the rank of a program element is the number of program elements with higher or the same scores.
the normalized score of the j th program element ranked by the i th technique is calculated as follows s norm i ej ri ej .
step technique selection in this work we adapt overlap based selection and biasbased selection to select a subset of techniques to be fusedtable example overlap based selection technique top most suspicious blocks ochiai block block block block block klosgen block block block block block piatetsky shapiro block block block block block tarantula block block block block block together from the input set of fault localization techniques.
the adapted meth odsareinstance orbug specific since theselected techniques may differfordifferentbuggy programs.
furthermore these methods do not require any training data to select techniques.
each of them can be used as the second step of fusion localizer.
the following paragraphs elaborate how we adapt these two methods for fault localization.
overlap based selection this method selects techniques to be fused together based on the overlap between the list of top k most suspicious program elements produced by a fault localization technique and the top k lists produced by other techniques.
by default we set k to be of the total number of program elements that the input buggy program has.
if this number is less than we set k to .
this method first measures the overlap rate of each technique with other techniques as follows definition .
o verlap rate .letlallbe a set of program elements that appears in at least one of the top k lists produced by the set of fault localization techniques.
also let libe a set of program elements that appears in the top k list of the i th technique but not in the top k lists of other techniques.
the overlap rate the i th technique with other techniques is calculated as follows o rate i lall li lall example given a buggy program consider four fault localization techniques i.e.
ochiai klosgen piatetsky shapiro and tarantula that return the top most suspicious program elements i.e.
program blocks as shown in table .
based on table the set of program blocks returned by at least one of the four techniques denoted by lall is block block block block block block block block block block .
ochiai recommends two program blocks that are not recommended by the other techniques i.e.
lochiai block block .
asfor klosgen piatetsky shapiro and tarantula each ofthem recommends one block that is not recommended by other techniques lklosgen block lpiatetsky shapiro block and ltarantula block .
hence the overlap rate of ochiai among the other techniques can be calculated as .we cancompute theoverlaprateoftheother three techniques inthe same way they are .
after calculating the overlap rate of each technique we sort the techniques in ascending order of their overlap rates and select the top n techniques.
in this way we include techniques that have more unique results i.e.
top k lists .
by default we set nto be of all input techniques.
bias based selection this method selects a subset of techniques to be fused based on the bias rate of each technique towards thenorm considering the top k lists returned by each technique.
by default we set k to be of the total number of program elements that the input buggy program has.
if this number is less than we set k to .
130this method represents each technique as a vector of zeroes and ones representing whether each of the program elements occurs in its top k list.
it constructs the norm which is a vector containing the number of top k lists each program element belongs to.
this method then computes a bias rate for each technique as follows definition .
b iasrate .letnbe the number of input techniques and mbe the number of program elements that appear in a top k list produced by at least one of the techniques.
let libe a vector of zeros and ones that represents whether each program element appears in the top k list of the i th technique where i n. the norm lallis a vector containing the number of top k lists each program element appears in.
the bias rate of the i th technique is calculated as follows bias li lall sim l i lall sim l i lall pm j 1lj lalljqpm j 1l2 j qpm j 1l2 allj in the above formulas sim l i lall is the cosine similarity between vector liand vector lall .
example based on table the set of program blocks that appears in at least one top lists is block block block block block block block block block block .
block is recommended by four techniques while blocks and are recommended by three techniques.
block is recommended by two techniques and the rest of the blocks are recommended by only one technique.
from these pieces of information the norm lallis .
to calculate the bias rate of ochiai to the norm i.e.
bias lochiai lall we first calculate the similarity score of ochiai with the norm.
the similarity score of lochiai with the norm lallis .
which is calculated as follows sim l lall p10 based on the similarity score the bias rate of ochiai is .
.
.
wecancompute thebias rateoftheother techniques in thesame way.
the bias rate of klosgen is 13p10 .
.
piatetsky shapiro has the same bias rate as tarantula i.e.
14p10 .
.
for each technique we calculate the bias rate of the results and sort them in decreasing order of their bias rates.
we then select the top n of the techniques with the aim of including techniques that are less similar towards the norm.
by default we set nto be of the input fault localization techniques.
.
step data fusion our approach adapts an unsupervised data fusion method proposed in the information retrieval community to combine normalized scores from selected fault localization techniques.
in this work we leverage five well known unsupervised data fusion methods in the domain of information retrieval namely combsum combmnz combanz correlation based fusion methods and borda count .
each of them can be used as the third step of fusion localizer.
the following paragraphs elaborate how the five popular fusion methods can be adapted for fault localization.
we use the example shown in figure to illustrate how each method works.
combsum this method combines the scores from different techniques by simply summing up their scores.
this method assumes that each technique is equally important.
example.
based on figure the set of new scores of blocks to would be .
and .
combanz this method combines the scores from different techniques by computing the average of the non zero scores.
letej denotes the j th program element and tidenotes the i th technique.
thescore assigned to program element ejby technique ti is denoted as ti ej .
suppose there are ntechniques andmejdenotes thenumberoftechniques thatassign anon zero score toej com banz calculates thenew score forejasfollows score ej m ej nx i 1ti ej example.
based on figure the set of new scores of blocks to would be .
.
combmnz combmnz is a variant of combanz it multiplies the summation of all scores for a given element with the number of techniques that assign a non zero score to the element.
let ejdenotes the j th program element and tidenotes the i th technique.
thescore assigned to program element ejby technique ti is denoted as ti ej .
suppose there are ntechniques and mej denotes the number of systems that give a non zero score to ej combmnz calculates thenew score forejasfollows score ej mej nx i 1ti ej example.
based on figure the set of new scores of blocks to would bef2 3g .
.
correlation based methods different from the above methods correlation based methods assume each technique is not equally important.
the importance of a technique is represented by its weight.
based on the weights of the techniques these methods linearly combine i.e.
sum up the scores assigned by different techniques multiplied by their weights.
letejdenotes the j th program element and ti ej denotes the score assigned to program element ejby the i th technique.
also let widenotes the weight assigned to the i th technique and nbe the number of techniques.
the new score of program element ejis calculated as follows score ej nx i 1wi ti ej the following paragraphs describe the weight calculation procedures of two correlation based methods corra and corrb.
.
corra this method computes the correlation among the techniques based on the overlap of the lists of top n most suspicious program elements returned by the techniques.
the method aims to minimize the domination of a certain group of techniques that tend to return similar results by assigning a heavier weight to a technique that has less correlation with other techniques.
let the sets of top n most suspicious program elements returned by the i th and j th techniques be denoted as liandljrespectively where i6 j. the overlap ratio between liandljis calculated as follows 131overlapratio ij jlitljj n suppose there are ntechniques we calculate the weight of the i th technique based on the average of its overlap ratio with other techniques as follows wi n 1nx j j6 ioverlapratio ij example.
based on the example in table and the top most suspicious program elements returned by each technique the overlap ratio between ochiai and klosgen is while the ratio between ochiai and piatetsky shapiro is .
.
thus the weight assigned to ochiai is .
.
similarly the weights for klosgen and piatetsky shapiro are .
and .
.
based onthese weights we calculatethesetofnew scores forthese blocks using equation thesetofnew scores would be .
.
.
.
.
.
in this work we denote the variant of corra which calculates the correlation among the measures based on the top of the most suspicious program elements by corra top10 and another variant that is based on the top of the most suspicious program elements as corra top50 .
.
corrb corrb is a correlation based method that also computes the weight of a technique based on the overlap of its list of top n most suspicious program elements with other lists produced by other techniques.
let the list of top n most suspicious program elements returned by the i th technique be denoted as li.
for a program element e let us denote the number of top n lists it belongs to as list e .
let lalldenotes a set of program elements which appears in at least one of the lists produced by the techniques.
suppose there are ntechniques to be fused the weight of thei th technique can be calculated as follows wi p e2l ilist e jl ij jlij jlallj wherejlijdenotes the number of elements returned by the i th technique andjlalljdenotes the number of elements that appear in at least one of the lists returned by the techniques.
example.
based on the example in table and the top most suspicious program elements returned by each technique lochiai lklosgen and lpiatetsky shapiro are block block block block block block and block block block respectively.
thus lallis block block block block block .
also list block list block and list block are and respectively.
from the above the weight assigned to ochiai is .
.
the weights for klosgen and piatetsky shapiro can be computed in the same way and they are .
and .
respectively.
there fore the set of new scores for these blocks calculated using equation would be .
.
.
.
.
.
in this work we denote the variant of corrb method which calculates the correlation among the measures based on the top of the most suspicious program elements by corrb top10 and another variant of corrb method which is based on the top of the most suspicious program elements as corrb top50 borda count this method converts the normalized scores that are assigned to program elements by each selected technique into ranks program elements with higher scores would obtain smaller ranks.
for each element this method sums up the ranking pointstable example of ranks and ranking points given by ochiai klosgen and piatetsky shapiro block ranks ranking points block block block block block of an element given by a set of techniques.
the ranking point of an element given by a technique is defined as the substraction of the element s rank in the list produced by the technique from the total number of program elements in the input buggy program.
letejdenotes the j th program element and ri ej denotes the rank assigned to program element ejby the i th technique.
also letnedenotes the number of program elements and ndenotes the number of techniques.
borda count calculates thenew score for program elementejas follows score ej nx i ne ri ej example.
table shows the ranking points for each program block in figure given by ochiai klosgen and piatetsky shapiro.
based on the summation of their ranking points the set of new scores for blocks to would be .
.
empirical ev aluation this section presents our subject programs our evaluation metrics and our experiment results.
some threats to validity are also discussed.
.
dataset we evaluate the effectiveness of data fusion methods presented in section .
to localize faults in buggy programs.
each buggy program contains a single bug that could span across multiple program elements.
table briefly describes our subject programs.
in this work we evaluate eight subject programs written in c one real program namely space from the software artifact infrastructure repository sir and seven siemens programs namely print tokens print tokens2 replace schedule schedule2 tcas and tot info.
each of the eight programs has a number of buggy versions.
we manually instrument these buggy programs at block level.
after excluding buggy versions that our instrumentation cannot reach e.g.
versions with bugs inglobal variable declarations we evaluate buggy versions.
we also analyze two real java programs from the sir namely nanoxml and xml security .
in this work we analyze four versions of nanoxml i.e.
versions and and three versions of xml security i.e.
versions and .
each program version has multiple buggy versions and we also instrument them at block level.
after excluding buggy versions that have no failed test cases we evaluate buggy versions.
the above subject programs have often been used to evaluate many fault localization techniques .
despite their popularity the size of the above subject programs are relatively small.
most of the bugs in the above subject programs are also synthetic rather than real.
thus we create another dataset consisting of real bugs from three larger programs namely rhino lucene and ant .
rhino bugs and test suite are obtained from the ibugs repository which was created by dallmeier and 132table dataset descriptions dataset loc number of buggy versionsnumber of test cases print token print token2 replace schedule schedule2 tcas tot info space nanoxml v1 nanoxml v2 nanoxml v3 nanoxml v5 xml security v1 xml security v2 xml security v3 rhino 49k lucene 88k ant 264k zimmermann .
asforlucene andant weobtaintheir bugs and testsuites from their bug tracking and version control systems following the procedure described by dallmeier and zimmermann .
in particular we consider lucene bugs that were reported for versions .
to .
and ant bugs that were reported for versions .
.
to .
.
.
kawrykow and robillard observed that not all changes made to fix a bug are essential many of them are cosmetic changes or simple refactorings that do not change the behavior of a program .
thus to find the root cause of a real bug i.e.
the buggy program blocks we need to manually inspect the code that are changed to fix the bug.
to help us in the manual inspection we only include rhino lucene and ant bugs whose fixes only change at most five lines of code.
among these bugs we also only choose bugs that have at least one failed test case covering the faulty lines.
.
evaluation criteria we evaluate the effectiveness of a fault localization technique either using data fusion or not in localizing faults based on the following commonly used metrics percentage of code inspected for each bug we measure the percentage of program blocks that a developer needs to inspect to locate all the faulty program elements.
this metric depends on the rank of the faulty program elements in the list.
in this paper we report the average percentage of program blocks inspected over all the bugs.
proportion of bugs localized we compute the proportion of bugs that can be localized when developers inspect up to a certain percentage of program blocks.
absolute amount of code inspected as studied by panin and orso developers may only inspect a certain number of most suspicious program elements recommended by an automatic debugging tool.
thus we also compute the number of bugs that can be localized when developers inspect up to eprogram blocks.
in this study we set eto .
we assume that is still a reasonable number of program elements thatdeveloper would inspect.
.
experiment results we evaluate the effectiveness of various variants of our approach to localize faults.
we denote a variant of fusion localizer aszx y z where xspecifies a score normalization method i.e.
zero one or reciprocal yspecifies a technique selection method i.e.
overlap or bias and zspecifies a data fusion method such as combanz corra top10 corra top50 corrb top10 corrb top50 combsum combmnz or borda count.
their effectiveness are compared with the effectiveness of the well known spectrum based fault localization techniques namely tarantula and ochiai .
we also compare with the theoretically best spectrum based fault localization techniques namely naish1 naish2 binary wong1 and russel rao as well as the theoretically best genetic programming gp based fault localization techniques namely gp02 gp03 gp13 and gp19 .
table average percentage of code inspected to localize all bugs.
technique average technique average zzero one overlap combanz21.
naish2 .
zzero one bias combanz21.
gp13 .
zzero one bias combsum22.
ochiai .
zzero one overlap corrb top50 .
gp03 .
zzero one overlap combsum23.
tarantula .
zzero one overlap corrb top10 .
gp19 .
zzero one overlap combmnz23.
naish1 .
zzero one bias corrb top10 .
gp02 .
zzero one bias corrb top50 .
russel rao .
zzero one overlap corra top10 .
binary .
zzero one bias combmnz23.
wong1 .
zzero one bias corra top10 .
.
.
percentage of code inspected in terms of average percentage of code inspected to localize all bugs twelve variants of fusion localizer perform better than the state of the art fault localization techniques.
these variants fuse the techniques using combanz corra top10 corra top50 corrb top10 corrb top50 combsum and combmnz by first normalizing the scores using zero one normalization and selecting the techniques using either the bias based or overlap based method.
they could achieve smaller average percentage of code inspected i.e.
.
to .
as compared to the best performing state of the art fault localization technique i.e.
naish2 .
among the state of the art fault localization techniques naish2 achieves the smallest average percentage of code inspected i.e.
.
followed by gp13 i.e.
.
and ochiai i.e.
.
.
see table for the details of average percentage of code inspected for the above variants of fusion localizer and the state of the art fault localization techniques.
to investigate whether the differences in the average percentage of code inspected between our twelve variants and the best performing state of the art fault localization techniques i.e.
naish2 gp13 and ochiai are significant or not we perform a statistical significance test namely wilcoxon signed rank test at significance level.
this statistical test does not assume that the data 133should follow normal distribution.
based on the significance tests zzero one bias combanz andzzero one overlap combanz significantly outperform naish2 with p values equal to .
and .
respectively.
they also significantly outperform gp13 and ochiai with p values .
.
the other ten variants could only significantly outperform ochiai with p values .
.
table lists the p values when we compare each of the best performing fusion localizer variants with each of the best performing state of the art fault localization techniques using wilcoxon signed rank test.
table statistical significance test results fusion localizer variant p value over ochiaip value over gp13p value over naish2 zzero one overlap combanz .
.
.
zzero one bias combanz .
.
.
zzero one bias combsum .
.
.
zzero one overlap corrb top50 .
.
.
zzero one overlap combsum .
.
.
zzero one overlap corrb top10 .
.
.
zzero one overlap combmnz .
.
.
zzero one bias corrb top10 .
.
.
zzero one bias corrb top50 .
.
.
zzero one overlap corra top10 .
.
.
zzero one bias combmnz0.
.
.
zzero one bias corra top10 .
.
.
figure improvement of zzero one bias combanz over naish2 in terms of percentage of code inspected furthermore we plot the improvements of the best performing variant of fusion localizer namely zzero one bias combanz over the three best performing state of the art fault localization techniques namely naish2 gp13 and ochiai for each of the buggy versions in figures and respectively.
we plot the improvements made byzzero one bias combanz because it achieves the most significant improvement over naish2 i.e.
the lowest p value over naish2 .
the improvement is based on the difference in percentage of code inspected.
the graphs only show the buggy versions where the improvements are either positive our technique performs better ornegative our technique performs worse .
there are buggy versions in which zzero one bias combanz improves naish2 and gp13.
as compared to ochiai it has better performance for buggy versions.
in addition there are and buggy versions in which zzero one bias combanz performs the same as naish2 gp13 and ochiai respectively.
from the figures it is clear that our best variant outperforms the three best performing state of the art fault localization techniques for most of the buggy versions.
figure improvement of zzero one bias combanz over gp13 in terms of percentage of code inspected .
.
proportion of bugs localized we also evaluate the number of buggy versions in which developers could find the faulty program elements by inspecting a certain percentage of program elements.
table shows the proportion of bug localized when developers only inspect the top of the most suspicious program elements produced by the state of the art fault localization techniques and our twelve variants that have better average percentage of code inspected than the best performing state of the art fault localization techniques.
when of the most suspicious program elements are inspected zzero one overlap combanz andzzero one bias correlation based can localize more bugs as compared to the other variants of fusion localizer and the stateof the art fault localization techniques.
they canlocalize .
to .
of the bugs while the best performing state of the art fault localization technique i.e.
ochiai can localize .
of the bugs.
naish2 and gp13 can localize only .
of the bugs.
figure improvement of zzero one bias combanz over ochiai in terms of percentage of code inspected 134figure comparing zzero one bias combanz zzero one overlap combanz with naish2 gp13 and ochiai thus these two best variants could improve the best performing state of the art fault localization techniques by .
to .
.
in addition eight other variants of fusion localizer can localize more bugs than the best performing state of the art fault localization technique i.e.
ochiai when of program elements are inspected.
they can localize .
to .
of the bugs.
thus our best variants can improve number of bugs that can be localized when developers only inspect a small percentage of code.
table proportion of bug localized when only of blocks are inspected.
technique bug technique bug zzero one overlap combanz46.
zzero one bias combmnz38.
zzero one bias combanz46.
gp03 .
zzero one bias combsum43.
gp02 .
zzero one overlap combsum43.
tarantula .
zzero one bias corrb top10 .
naish2 .
zzero one overlap corrb top10 .
gp13 .
zzero one overlap corra top10 .
naish1 .
zzero one bias corra top10 .
gp19 .
zzero one bias corrb top50 .
russel rao .
zzero one overlap corrb top50 .
binary .
ochiai .
wong1 .
zzero one overlap combmnz41.
furthermore we plot the proportion of bug localized using our two best variants i.e.
zzero one overlap combanz andzzero one bias combanz naish2 gp13 ochiai and tarantula when different percentage of program elements are inspected as shown in figures .
based on the figure our two best variants can localize more bugs when dif table number of bugs localized when only up to most suspicious program elements are inspected i.e.
hit technique hit technique hit zzero one bias combanz91 ochiai zzero one overlap combanz87 naish1 zzero one overlap combsum87 naish2 zzero one bias corra top10 gp13 zzero one overlap corra top10 gp03 zzero one bias corrb top10 gp02 zzero one overlap corrb top10 tarantula zzero one bias corrb top50 gp19 zzero one overlap corrb top50 russel rao zzero one bias combsum84 binary zzero one overlap combmnz84 wong1 zzero one bias combmnz78 ferent percentages of program elements are inspected as compared to the best performing state of the art fault localization techniques.
.
.
absolute amount of code inspected we also investigate the number of bugs that can be localized when only a small number of program elements i.e.
10program blocks are inspected.
the results are shown in table .
the table shows that our twelve variants can localize more bugs than the state of the art fault localization techniques.
they can localize to bugs while the best performing state of the art fault localization technique i.e.
ochiai can only localize bugs.
amongst our variants zzero one bias combanz can localize the largest number of bugs as compared to the other techniques.
its relative improvement over ochiai naish2 and gp13 are and respectively.
these results also show that our best variants can substantially improve the number of bug localized when developers only inspect a small number of program elements.
.
discussion in this section we discuss the effect of score normalization technique selection and varying the number of techniques to be fused together on the performance of fusion localizer.
at the end of this section we describe some threats to validity.
effect of score normalization.
to investigate the effect of the score normalization step we disable this step and evaluate the effectiveness of the resultant solution.
we find that without score normalization the performance of the best performing variant of fusion localizer is not as good as the best performing variant that normalizes the scores.
without normalization the average percentage of program block inspected to localize all bugs achieved by the best variant is .
which islarger than theresultofthebestvariantthatnormalizesthe scores i.e.
.
.
when developers only inspect up to of program blocks the best variant that does not normalize the scores can only localize of the bugs which is smaller than the percentage of bugs that are successfully localized by the best variant that normalizes the scores i.e.
.
.
also when inspecting up to program blocks the number of bugs localized by the best variant that does not normalize the scores is not even half of those 135achieved by the best variant that normalizes the scores bugs vs. bugs .
therefore normalization is an important step to improve the performance of fusion localizer.
effect of technique selection.
to investigate the effect of the technique selection step we disable this step and evaluate the effectiveness of the resultant solution.
when we fuse all fault localization techniques the performance of the best variant is worse than the best variant that employs technique selection.
when the technique selection step is disabled on average the best variant can localize all bugs when .
of code are inspected which is not as good as the result achieved by the best variant that employs technique selection i.e.
.
.
when developers only inspect up to of program blocks the best variant that does not use technique selection localizes a smaller percentage of bugs than the percentage localized by the best variant that uses technique selection i.e.
.
vs. .
.
similarly when developers only inspect up to program blocks the best variant that does not use technique selection localizes a smaller number of bugs than the number localized by the best variant that employs technique selection i.e.
vs. .
therefore applying technique selection can improve the performance of fusion localizer.
effect of number of techniques to be fused.
to evaluate the effect of the number of techniques to be fused by our fusion localizer we use one of our best variants i.e.
zzero one bias combanz and set the number of techniques to be selected to top top top and all of the techniques.
let us refer to the sub variants of zzero one bias combanz as v25 v50 v75 and v100.
by default fusion localizer selects top of the techniques.
we find that the average percentage of code inspected to locate all bugs are .
.
.
and .
for v25 v50 v75 and v100 respectively.
when developers only inspect the top of the code the percentage of bugs localized by v25 v50 v75 and v100 are .
.
and .
respectively.
when developers only inspect the top program blocks the number of bugs localized by v25 v50 v75 and v100 are and respectively.
the results show that selecting the top of the techniques the default option is the best setting.
threats to validity.
threats to internal validity relates to errors in our experiments.
we have checked our implementation but there could be bugs that we do not notice.
threats to external validity relates to the generalizability of our findings.
we have analyzed bugs from programs written in c and java.
the programs vary from small to large programs.
the bugs vary from synthetic to real bugs.
in the future we plan to reduce this threat to external validity further by investigating more bugs from more systems written in various programming languages.
threats to construct validity relates to the suitability of our evaluation metrics.
we have used common metrics used to analyze past fault localization studies .
we have also used another metric i.e.
hit to address the concern raised by parnin and orso .
hit only considers the performance of a fault localization tool when a small number of program elements in our case program blocks are inspected.
the measure was previously used by information retrieval ir based bug localization studies that find buggy program files given a textual bug report .
admittedly there is no large scale study that shows positive correlation or its absence between improving hit or other rank based metrics and time and effort saved when developers use a fault localization technique to debug various kinds of bugs.
still improving rank based metrics is a step towards building a fault localization technique that can pinpoint the location ofbugs in the top position most of the time.
such a technique will be highly effective since developers can trust its output.
the location pinpointed by such tool can be a good starting point for developers to reason on the root cause behind a set of failures and how to fix the bug.
this location can also be used as input to other studies for example automated bug fixing .
.
conclusion and future work in this paper we propose an approach named fusion localizer to fuse a number of spectrum based fault localization techniques.
our propose approach consists of three steps score normalization technique selection and data fusion.
we investigate two score normalization methods two technique selection methods and five data fusion methods resulting in twenty variants of fusion localizer.
fusion localizer does not require any training data i.e.
execution traces of past relevant program failures to select the set of techniques to be fused.
this allows our approach to be used for new programs or programs where program spectra of past relevant bugs are unavailable.
furthermore our approach is bug specific in which the set of techniques to be fused is adaptively selected for each buggy program based on its spectra.
we evaluate our approach using a common benchmark dataset and a dataset that contains real bugs from three medium to large programs.
our evaluation shows that the best performing variants offusion localizer i.e.
zzero one bias combanz andzzero one overlap combanz statistically significantly outperform the state of the art spectrumbased fault localization techniques i.e.
ochiai theoretically best spectrum based fault localization techniques and theoretically best genetic programming gp based fault localization techniques .
our best variants require smaller average percentage of code inspected to locate faulty elements as compared to the best performing stateof the art fault localization techniques i.e.
vs. .
when developers only inspect of the most suspicious program elements these best variants could improve the best performing stateof the art fault localization techniques i.e.
ochiai naish2 and gp13 by to .
furthermore when developers only inspect the top most suspicious program blocks these best variants could improve the best performing state of the art fault localization techniques by to .
in addition there are many other variants of fusion localizer that can outperform the stateof the art fault localization techniques albeit not statistically significantly .
these variants use corra top10 corrb top10 corrb top50 combsum and combmnz to fuse the selected techniques by first normalizing the scores using zero one normalization and by selecting the techniques using the bias based or overlap based selection methods.
as a future work to improve the effectiveness of our proposed approach further we plan to create new technique selection and fusion methods that are specifically designed for fault localization.
also rather than only returning a list of most suspicious program elements we plan to extend studies on bug signature mining e.g.
and return additional contextual information that can help developers debug.
additionally we plan to perform a user study to evaluate the effectiveness of our technique in saving developer time and effort when localizing real bugs from various subject programs written in various programming languages.
acknowledgement we would like to thank tien duy b. le for his help in collecting the real bugs and test suites from lucene and ant bug tracking and version control systems following the approach by dallmeier and zimmermann .
.