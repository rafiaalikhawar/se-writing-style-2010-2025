enablers inhibitors and perceptions of testing in novice software teams raphael pham stephan kiesling olga liskin leif singery and kurt schneider leibniz universit t hannover hannover germany raphael.pham stephan.kiesling olga.liskin kurt.schneider inf.uni hannover.de yuniversity of victoria victoria bc canada lsinger uvic.ca abstract there are many di erent approaches to testing software with di erent bene ts for software quality and the development process.
yet it is not well understood what developers struggle with when getting started with testing and why some do not test at all or not as much as would be good for their project.
this missing understanding keeps us from improving processes and tools to help novices adopt proper testing practices.
we conducted a qualitative study with computer science students.
through interviews we explored their experiences and attitudes regarding testing in a collaborative software project.
we found enabling and inhibiting factors for testing activities the di erent testing strategies they used and novices perceptions and attitudes of testing.
students push test automation to the end of the project thus robbing themselves from the advantages of having a test suite during implementation.
students were not convinced of the return of investment in automated tests and opted for laborious manual tests which they often regretted in the end.
understanding such challenges and opportunities novices face when confronted with adopting testing can help us improve testing processes company policies and tools.
our ndings provide recommendations that can enable organizations to facilitate the adoption of testing practices by their members.
categories and subject descriptors d. .
management programming teams general terms human factors keywords testing adoption motivation enablers inhibitors.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
fse november hong kong china copyright acm ... .
.
.
introduction automated testing has many proven bene ts.
test driven development tdd can help shape software design .
unit testing is a prerequisite for refactoring and regression tests keep defects from reappearing.
however adoption of testing practices can be problematic.
in a previous study we encountered several commercial as well as open source projects in which testing was either an afterthought or not used at all.
additionally we have experienced similar situations in industry projects and with students when resources become constrained testing is sometimes the rst activity to be discontinued.
our aim is to better understand this special role of testing relative to other development practices.
insights into this relationship should help us design better policies processes and tools around testing which should improve overall software quality.
the study presented here is one step towards this larger goal.
in our qualitative study we focus on teams of novice software developers about to nish their university studies.
most of them will soon begin a career as software developer in industry.
thus the insights provided by our study can be useful for organizations that employ novice software developers and want to improve how they train and leverage them.
by understanding why novices do or do not adopt testing practices process managers can actively remove barriers and facilitate desired testing behavior.
researchers can use our contributions to guide the creation of new tools and practices that support novices in adopting good testing practices.
on the one hand we uncover technical challenges for which better tool support is needed.
on the other hand research into policies in software development can bene t from our ndings regarding attitudes towards testing.
for educators our study documents testing related preconceptions that they might encounter in their own students.
we also found a set of weaknesses in current education that we believe if addressed would help prepare students much better for careers as software developers and managers.
this paper is structured as follows the succeeding section discusses related work.
we then describe the software project that we conducted our study in and provide details about our study design.
section documents our ndings which we then discuss in section along with our study s limitations and threats to its validity.
section concludes the paper.
.
related work we now discuss related work with a focus on empirical studies that have explored testing behavior in software engineering teams.
.
factors that influence testing kanij merkel and grundy investigated which factors affect e ectiveness of testing.
in a questionnaire based survey they inquired about the importance of factors such as tools and training but also more human centered factors like personality characteristics and experience.
they nd that among others good domain knowledge experience and interpersonal skills were considered important.
in another empirical study they investigated whether the personality of testers in uences how e ectively they test.
they found several weak correlations between personality characteristics and testing e ectiveness.
karhu et al.
reported on factors that are important for speci cally supporting test automation.
in our interview based study we also explore perceptions and opinions but in addition to that probe into concrete experiences.
further we add an additional perspective by studying developers who are mostly new to testing.
rooksby et al.
explored how social and organizational aspects in uence testing.
beer and ramler investigated the in uence of experience on e ective testing.
they further describe the sources and perceived value of experience for testing.
ellims et al.
argue that unit testing is often criticized for its high perceived costs .
they investigated the relations between testing costs and bene ts in three case studies.
the authors found that the perceived costs were probably exaggerated compared to the bene ts of testing activities.
furthermore feedback can in uence the motivation to adopt practices.
kanij et al.
explored feedback mechanisms in the testing domain .
they report on a lack of methods and research for assessing testing performance.
in a literature review they found several factors and assessed their importance as perceived by practitioners.
all these factors can in uence testing behavior.
in our study we explore the factors that were most prominent to the participants by asking about their opinions and experiences.
.
adoption of software testing practices ng et al.
explored software testing practices in australian industry.
they inquired about currently used testing methods tools and metrics and listed several barriers to their adoption.
causevic et al.
focused on test driven development tdd .
in a systematic literature review they identi ed several factors that limit the adoption of tdd in industry.
limiting factors include higher development time and insu cient experience but also more indirect problems like domain speci c issues and a lack of upfront design.
benton describes decision categories and strategies that need to be addressed in order to establish a software test organization.
in our study we likewise nd inhibitors of testing adoption.
in addition to that we also report on experiences that positively in uence the adoption of testing.
we further differentiate between practices for automated and manual testing.
.
perception and state of the art of testing runeson conducted a questionnaire based survey on unit testing in industry.
he reports on current practices bene ts and problems of unit testing.
he also showed that there are di erent perceptions of what constitutes a unit test.
in another qualitative survey in industry engstr om and runeson investigated regression testing in order to help understand it better.
zaidman et al.
considered testing in more detail through mining repositories.
they examined whether repository mining can help nd out how test code co evolves with production code and present their results for three case studies.
vegas and basili present a characterization schema that illustrates which testing techniques are suitable for a given project.
they note that collecting su cient information which is often distributed among di erent sources to choose appropriate testing techniques is a major problem for software developers.
latoza et al.
report on developer work habits in general and also elaborate on unit testing.
although the developers in their study reported to spend about half of their time on xing defects unit testing was one of the activities the developers spent the least time on.
viewing testing through the eyes of a novice as conveyed in our study adds further insights into testing strategies and challenges for developers.
in addition to this we also highlight less tangible aspects like attitudes towards and preconceptions of testing.
.
the software project course since the software engineering group at leibniz universit at hannover organizes an annual software project course swp for third year computer science undergraduates.
all participating students are divided into teams of ve students per team.
in fall students were divided into teams teams of ve students each one team of four students and one team of three students.
these teams were assigned to work with various technologies.
six teams created a java desktop application and ve teams implemented an android app.
seven teams created a web application and two teams created an emf eclipse based application.
in the course every team elects a project leader and a quality agent from its members.
the project itself lasts months in which the team needs to elicit requirements design implement and test a software product.
at the end of the project the customer conducts an acceptance test and either accepts or rejects the product.
customers are members of our group o ering projects they are interested in.
therefore some teams had the same task assigned in parallel but had to work independently of each other sometimes with slightly modi ed requirements.
our group tries to conduct software projects that are as realistic as possible while controlling complexity and size of the projects.
this is essential for being able to compare them.
in addition to customers our group also provides each team with a coach for technical and process related help.
the projects follow a waterfall like process with each phase ending in a quality gate.
these act as checkpoints and ensure some basic qualities of the products such as adherence to coding standards a minimum amount of unit tests or the existence of use cases in a requirements speci cation.if a team fails a quality gate they can rework their artifacts and attempt the quality gate again.
failing the same quality gate twice will abort the project however this has not happened yet.
to participate in the software project course we require students to have passed a programming course java as well as basic courses on software engineering software quality and version control.
the latter are all taught by our group as well.
at the end of the course when students can be sure that they have either passed or failed we conduct interviews with all members of a team simultaneously using the lid technique .
this is a moderated post mortem meeting where all team members recall events of the past project.
this allows us to capture students perceptions of the course while they are still vivid but at the same time without any fear of failing the course.
.
study design with the participants of the fall software project course as participants we conducted a grounded theory study about the testing behavior of novice developers.
we interviewed all students at the end of the course right after the lid session and recorded the interviews.
the interviews lasted minutes on average.
as suggested by hoda et al.
we used an iterative data analysis approach to extract our theory of our students testing behavior.
we report our ndings in section .
.
research questions in our study we tried to understand the testing behavior of our students in the software project course in which we try to approximate or simulate an environment that is similar to a software project in industry.
we were interested in supporting factors that helped students to methodically test their product and in inhibiting factors that kept them from so.
in this context methodical testing describes testing e ort that encompasses preparation guided execution and some form of documentation.
for example carefully thinking about input values and correct output values deliberately executing the application and noting the results di ers from a quick exploratory execution.
as is often sensible grounded theory we did not nalize our research questions before starting data collection.
however we had topics of interest in mind.
the following are the research questions we arrived at after iterative qualitative analysis using open coding selective coding axial coding and writing memos.
testing strategies rq1 how did students test their software products?
enabling and inhibiting factors rq2 what factors supported students in testing methodically and what factors hindered them?
testing attitude rq3 what did students think of testing methodically?
testing in the swp process rq4 how did students incorporate testing in their engineering process?
.
semi structured interviews the interviews were conducted at the end of the software project course.
at that point students had nished their projects and had already passed or failed the course.
each interview lasted between and minutes they were conducted by two researchers.
the interview was semistructured they were based on a script that inquired about test activities and strategies employed by the students their reasons for choosing them their prior experiences with development and testing the problems they encountered and how they solved them their understanding of automated testing and di erent testing techniques and nally the lessons they learned about testing in the project.
however as interesting topics came up in the discussion we delved into those to gain deeper insights.
after each interview we revised our interview script to de emphasize topics that we had already saturated and to add new interesting details to discuss in future interviews.
.
data analysis all interviews were recorded and transcribed.
two researcher previewed the interviews thoroughly and took notes.
all researchers identi ed about key points in the interviews and noted them.
in the next step similar key points were aggregated and coded into one code.
we constructed codes in total.
from these codes di erent themes emerged and we grouped codes accordingly.
the following themes helped us gain an overview of our data attitude towards testing and software engineering motivation and amotivation regarding testing team internal organization of test e orts timing of testing in the development process the parts of the application under test aut that were tested testing related challenges strategies to direct test e orts during development general automated testing including strategies motivations problems and bene ts manual and automatic gui testing including strategies motivations problems and bene ts tools used for testing from there we extracted higher level concepts that connected di erent codes and explained phenomena that we encountered in our data.
in total we extracted concepts.
we grouped these concepts into four categories and one core category.
these can be seen in fig.
.
we collected quantitative data at several points but report such numbers for illustrative purposes only.
.
population the population of students was self selected all participants were asked to take part in the interviews but were also informed that they could decline without consequences.
of students were studying in their 5th semester students were enrolled in their 7th semester and four studentshad been studying for four years and longer.
for the remaining students we have no data available regarding their study progress.
regarding the experiences of the students we divided our population into three groups.
the rst group only had experiences with software development in courses and consists of students.
the second group of students had already conducted private software projects.
students had worked as software developers in commercial settings and make up the third group.
considering all the information given by the students at the beginning of the course of students had passed a basic course on programming in java.
at least students had passed a basic course on software quality and students had passed one on software engineering.
students had passed a non mandatory course on security engineering.
.
findings in our study we found that the students actual testing behavior is in uenced by a wealth of factors which can be seen in fig.
.
we di erentiate four categories education experiences gaps of knowledge form a baseline of technical knowledge.
this is also the origin of the students attitudes and preconceptions towards testing.
the students perception of testing plays an important role in how they will approach a concrete task.
lastly the students testing behavior is in uenced by external inuence factors such as management support or resource constraints.
in the following we rst explain the observed testing behavior and then move on to discuss in uencing factors.
testing behavioreducation experience gaps of knowledgeattitudes and preconceptionsperception of testingexternal influence factors causecontextexplains encourages discouragesinfluencesinfluencesinfluences shapesshapesconsequence figure the categories observed in our study forming our theory of testing behavior.
.
testing behavior the software project course is divided into three phases a requirements phase a design phase and an implementation phase.
testing took di erent forms in the project.
students distinguished between automated testing we denote this with a and manual testing .
automated testing meant having dedicated test code for the automated execution of some part of the aut excluding the user interface and some assertion.
junit tests were the most prominent example.
manualtesting was divided into di erent approaches when it came to gui testing students mostly relied on smoke testing s even though they did not call it that.
smoke testing was the execution of the aut to verify the correctness of the currently nished or modi ed code.
smoke testing was done without documentation and solely served the selective assertion of freshly made changes.
manual gui testing mg di ered from smoke testing in that it encompassed several steps for asserting a whole use case in the gui and not just one step.
sometimes these manual gui tests were conducted in a more systematic manner using a protocol or a checklist mg .
lastly some teams automated their gui tests ag through a framework such as selenium or android s robot .
out of teams only four teams discussed their testing strategy in the rst phase of the development process.
another ve teams planned their testing strategy in the implementation phase and only two of those in the beginning of that phase.
the remaining teams did not plan testing in advance cf.
table .
when it came to team internal organization of testing efforts teams implicitly decided to let every author test their own code.
in two cases teams i and l the quality agent of the team took the role of testing mentor.
he managed the test process and provided the team with example tests to work on.
teams felt pressured by the project deadline into ceasing testing e orts by far too little time to be able to write extensive tests.
then we could have tested the gui with selenium .
.
.
yes it was mainly the time.
yes i also felt time pressure.
team t the testing activity that was omitted the most frequently was the automation of gui tests.
often gui tests implied a learning time that some teams were not able or willing to invest.
only teams conducted automated gui tests cf.
table .
table shows all teams testing e orts in context of the development process.
all teams started testing in the last phase of the project even though some had talked about it earlier.
teams managed to automate tests earlier than at the end of the implementation phase.
the rest opted for manual testing and automation at the end of the project.
teams reported to have underestimated the e ort required for implementation and testing became a secondary concern.
i have been caught on the implementation until the end.
me too.
i have been working on everything and then thought testing is admittedly nice but it s of secondary importance.
first something must be up.
team j most of the teams that prepared testing beforehand and talked about it early managed to automate their tests during implementation and even produce automated gui tests.
team g speci cally decided against automated gui tests as they were con dent to have tested their gui su ciently in manual runs with protocols.
the two sided dilemma of late tests.
why do students push testing to the end of the project?
they are already overwhelmed with programming and testing becomestable test timetable of teams.
legend t talk a automated testing s smoke testing mg manual gui testing mg manual gui testing with protocol ag automated gui testing requ.
design implementation bmebme begin mid end a a a a b mg mg mg a c s mg s mg s mg d t a e s mg f s mg s mg s mg g t ttt mg a mg a mg a h t a it a ag t a ag a ag j a s mg k mg a mg a mg a l a m t a a s mg n a o a a a p t s a ag s a ag s a ag q s s a r s s s mg s t a s mg ag t a mg a mg a mg a secondary concern.
at project start the aut is still fuzzy and students explore the problem s solution space.
automated testing seems hindering at this stage especially in the beginning i always nd it difcult to grasp automated test cases.
in the beginning is still vague.
one thinks yeah right now i d like to just see how it works and just start implementing.
yeah it s this uncertainty again.
team s later on when the aut begins to take form testing still takes a backseat.
students have the feeling that an incomplete aut is not ready to be tested automatically.
they perceive the added test code as a burden that introduces unnecessary test maintenance.
students misinterpret the burden of test maintenance as technical debt and accumulate technical debt in the process.
students opt to introduce automated tests when the aut nears completion.
thought testing is admittedly nice but it s of secondary importance.
first something must be there.
particularly if i start right now while our work is pretty unstable and we are permanently reconstructing things i m nding it relatively pointless to write a test which one also would have to change every time.
because the things that we were testing were changing heavily.
because everything was still far too dynamic.
at the end there was no time left.
that s why we never tested.
team j this feeling was especially strong regarding the user interface of the application.
the gui of an application changes a lot during implementation and thus introduces high maintenance costs for automated gui tests.
i found it pretty exhausting to test the gui directly while implementing it.
since many thingswere changing on the side i was like i want to change this and then would also have to change tests.
therefore one rather implemented the whole gui rst and then wrote test cases for it.
team s some teams preferred to push gui automation near the end of the project after the gui was nearly nished.
the same applied for most automated tests of other parts of the aut.
this strategy however introduces the rst part of the dilemma of late tests .
students rob themselves of the advantages of having automated test suites during implementation and not only at the end.
some of the advantages are regression tests as a safety net against erroneous changes.
shaping the software design by thinking about tests.
reducing technical debt in the long run.
students avoid automation by switching to manual testing.
by manually smoke testing the application repeatedly during implementation students uncover a lot of defects by hand.
this however is repetitive time costly and monotone.
additionally students stillbegin to automate tests at the end of development as the existence of an automated test suite is required in the development process.
this introduces the second part of the dilemma of late tests students are then disappointed by the low defect detection rate.
as most defects have been uncovered by manual labor before the newly added test suite does not perform as hoped.
at this point students clearly recognize the cost of automation but cannot see its bene ts.
one student pinpointed that testing does have a cost a cost one will have to pay anyway.
however the earlier one invests in these tests the more bene t can be gained from them.
he explained that in order to do so one has to conquer one s weaker self one thinks that the actual logic that one writes is the major thing and not the test cases.
but that s this contradictory thing.
when one writes automated tests that s a constant e ort but it also brings in netly many bene ts especially the earlier you write them.
but you have to conquer your weaker self to write tests earlier.
team s six teams agreed that testing earlier in the development process would have been bene ciary well when one is it right from the beginning it makes much more sense than thinking at the end now i ll also do a few test cases.
one bene ts more.
team q .
education experiences and gaps in knowledge the category education experiences and gaps of knowledge summarizes how the students education and experiences shaped their testing behavior.
we discuss in how far university courses helped them whether they had prior private experiences and whether they had worked on a commercial project before.
education.
university courses provide students with a wealth of testing knowledge.
students were introduced tothe testing technique test rst .
the use of junit was practiced in class.
di erent test design strategies such as partition testing white box testing black box testing and others were explained and practiced.
however students complained that the importance of testing is not conveyed strongly enough in courses.
additionally the satisfying feeling of uncovering an actual defect is never experienced they do not feel accomplished.
you don t realize what a good feeling it is when you run a test.
i think in the practical part many things are missing too.
the software quality course was very theoretical.
team s university courses do not seem to provide practical knowledge or experience and students do not develop a habit of testing.
i ve heard something about it in a lecture.
one has never actually carried it out in practice.
one has talked about it theoretically but i haven t had any practical a nity to it.
team t experiences.
out of teams only two teams s i had team members with prior experience in testing.
eight teams claimed to have no prior experience in methodical testing and test automation except for knowledge from lectures and exercises.
this heightened the barrier of getting started with testing.
in the beginning i ve had many problems with just re ecting upon the best way to test something.
we were all not so experienced to instantly know how to test it.
team c also most teams did not know any other testing tool besides junit which had been introduced in a course.
some students self directed their learning and used books and internet tutorials as resources.
however some topics were harder to nd than others such as gui automation with eclipse.
gaps of knowledge.
besides their lack of experience with test methods and automation other gaps of knowledge became apparent.
one such gap concerns the concept of gui automation for testing purposes.
six teams admitted to have no idea how to automate and test a gui.
these and others resorted to repeated manual executions of the user interface.
i was responsible for the visualization aspect of the software and mostly i just tested by executing .
i constantly changed something and then looked at it because i didn t have any ideas at all on how to test that.
team d further students encountered problems when debugging .
five student teams constantly put print statements all over their code to output variables for debugging.
this method required a constant clean up of debugging code and when an error reappears the statements were reintroduced.
when you re using system.out.println you also have to remove it when you re done.
and suddenly you notice that it doesn t work again and you have to add all the statements all over again.
team ralso this kind of error detection proved faulty due to misreads of outputs but when i m everything manually even if i try to not miss any edge cases i might sill misread the output that i get.
team t another four teams tried to gain insights into their applications inner workings and states by excessively making use of java s logger class.
this indicates that our population was not familiar with proper debugging mechanisms.
another relevant topic is the use of measurement tools to keep track of a project s testing e orts.
twelve teams admitted that they had never used any coverage tools when testing.
even though they did engage in automated testing measuring their progress did not seem important to them.
according to one team testing was nished when all possible errors were detected.
yes when we have tested everything that can occur.
so everything that we think of.
team t that same team later complained to have no feeling when to stop testing as they could not cover all possible inputs you don t know exactly when you re done.
when have i tested enough?
which inputs do i have to expect now?
team t .
attitudes and preconceptions this section is concerned with the students attitude towards testing and test automation.
further we discuss preconceptions of testing and their impacts.
attitude.
students generally saw testing as a part of software engineering.
however they were not particularly fond of test automation.
they value implementing over testing.
a functional product was more important than automation of tests and many teams resorted to manual testing e orts.
i am not really fond of it.
i like to implement but eventually these are fair and help pretty much if there is a defect so that one can really fast uncover that.
team s this attitude towards testing may originate from di erent factors.
firstly students were eager to begin writing code and nd a solution to the proposed problem.
writing tests instead of source code does not feel as accomplishing as creating new functionality.
the bene t is not immediately apparent.
naturally is less exciting than implementing some function.
you get to see less of it.
team q compared to producing new functionality writing test codefeels unproductive .
there is no imminent reward.
well it feels unproductive if you write tests at the beginning and actually you are thinking no i d rather start with implementation straightaway quickly building a website have a look how this will come out.
team ssecondly testing is perceived as an additional and secondary task i thought that this testing was rather secondary.
well generally i would do it sure.
team p thirdly some students displayed an anxious attitude towards testing .
testing uncovered defects in their work and this entailed more work.
students did not like that.
you are a little bit sad or unhappy when you nd a defect.
well naturally you don t want to nd that that is for sure.
.
but then you realize that you will absolutely have to do some more work or you realize that something is missing.
to put it short you are not done yet.
team o lastly some teams recognized the maintenance cost of a test suite and felt demotivated by it.
new tests meant higher test maintenance when the aut changed again.
introducing tests into development felt like increasing the technical debt to them instead of lowering it in the long run.
personally i found this gui test even more impracticable.
i mean me writing gui tests incidentally all the time and because our gui changes all the time dynamically... i thought that to be too much e ort and i did not like that one bit.
team s out of teams four teams explained to feel in uenced in their testing behavior because of the educational status of the project.
one student explained that his testing e ort was reduced as this project would end with the course and would not be developed further.
preconceptions.
students felt in uenced in their testing behavior by di erent factors that they did not further explain and regarded as common knowledge.
we regard these statements as preconceptions.
theproject size was an important factor for students.
according to them smaller projects would not need to be tested.
at which point a project would become large enough to justify systematic testing did not become clear.
thecriticality of a project was also important to students.
they felt that systematic testing would be justi ed by the potential damage that could be done by software defects.
games for example would not necessarily need the same quality assurance as software for atms.
games do not have the same quality requirements as other software such as software that is required to work correctly.
for example atms.
with this kind of software there can be great damage but defects in games are simply annoying but not serious.
that s my take on that.
team i as some of our proposed software projects were indeed games this attitude may have in uenced the teams testing behavior negatively.
lastly students adjusted their testing e ort according to theperceived complexity of the code or their project s requirements.
however at which point code or a problembecame complex enough to warrant a test was highly subjective.
one student explained that some conditional statements do not need to be tested.
this preconception taken together with the attitude of regarding tests and test maintenance as a burden might lead to technical debt in the long run.
the program is not complex enough for some error to come up.
if it was a complex program then there could be a hidden defect that one could uncover with a test.
but these programs are mostly if statements or something like that and you check that it should work except when you make a mistake.
but even your unit test can be faulty.
team a another common preconception was that the unit testing framework junit is best suited to test mathematical functions .
five teams saw the greatest value of junit in checking internal calculations.
one team member of a web application project with little calculations explained their lack of junit tests with the absence of calculations and the use of third party libraries.
i think it is reasonable to test when you have many projects that really use formulas or somethings like that mathematical formulas.
in our case we often used third party components.
team r the misconception that junit is best suited for mathematical comparisons may be founded in the way junit is often presented in a mathematical context when introduced in courses.
.
perceptions of testing this section describes perceptions of testing tasks from the view point of students.
this includes problems and motivations for their testing behavior.
students are aware of the bene ts of an automatic test suite.
automatic tests can quickly uncover freshly introduced erroneous changes to the aut.
this heightens the condence in the code well i will write tests in the future just because they nd defects far quicker.
if someone makes changes to the program it may work without shutting down or some simple stu stops working that you don t see straight away.
and if you have automated tests you will notice straightaway.
that is its advantage.
team s students experienced that thinking about test design also enhances the aut and helps them nd important edge cases.
having tests was useful especially if one saw the reason for them.
writing tests makes you think what kind of translation could trigger what kind of failure.
special cases like that you can write tests for and then you can always be sure that if someone changes the code and executes your tests that in of cases the program will work as expected.
team showever students are also aware of the costs of testing.
writing automated tests takes cognitive and manual e ort.
often students did not have the time to read up on testing and did not nd adequate tutorials online.
from the perspective of a student writing test code that is nearly as big as the concerned aut code seems ine cient.
no i will not go through the e ort of writing tests and think them all through just to cover one line of code or so.
team t instead of investing in writing tests most students decided for manual testing.
this leads to faster execution and faster feedback and is cognitively less taxing.
these were tests on the gui of the application i did not know how to automate these.
anyways i was quicker when we just clicked through it myself and checked whether it worked or not.
perceived this automation would be more e ort than to just do it manually.
team b the downsides of manual gui tests are manifold.
these kinds of tests have to be repeated after every change to the aut which can be tiring.
if the aut needs to be in a speci c state to start testing this setup state needs to be established manually every time .
one team wanted to test the behavior of a later stage of a card game and had to play through all preceding stages for each manual test.
also testers tend to forget steps or make mistakes.
one advantage of manual gui tests over automated gui tests is that humans are more robust against changes in the test script if i did it manually i would just say if i click new task or if i click create new task that is not important for the human but if does not nd create new task then it will not click on it at least in robotium.
team p gui testing is perceived as something very di cult and ominous by the students.
of teams regarded gui testing as generally di cult.
de ning the target value for a gui test is challenging.
one reason might be that the purpose of a gui test can be misunderstood.
students often reduced gui tests to asserting that some gui element is placed correctly.
many defects cannot be found this way when you consider guis.
you cannot determine if an icon is misplaced.
you really can t. team g in other cases students rightfully wanted to assert certain geometrical attributes in an editor but did not know how to do so.
this team could not nd any technical solution to their problem and opted for visual checks.
i nd it di cult to check if some pixels are displayed correctly.
how could one formulate this correctly?
if it is about two lines being perpendicular i nd it easier to execute it and visually check for myself.
team d .
external influencing factors this section describes external in uencing factors with impact on the teams.
in uencing factors may be originated from the organization organization policies advisors coaches or mentors.
since the course s team members were undergraduate students other courses may have in uenced their working behavior by limiting their available time and consequently in uencing the time they may have spent on their projects.
organizational advice.
some coaches of our teams partially discouraged their teams from testing their products.
one coach advised her team to give up unit testing.
another coach recommended writing tests after coding only because test rst was hard to apply by novice teams.
one team had been completely excused from automated testing because of time pressure.
it had been advised to concentrate on manually executed acceptance testing in the end of their project instead of automated tests during the implementation phase.
many coaches in the software project excused their teams from testing their gui automatically.
in the case of eclipse applications or java based games gui automation was regarded as too di cult for undergraduate teams.
later on they told us that gui tests with a bot or so were not even required.
testing manually by hand was ok. team h even though one team wanted to automate their gui tests and had already begun so one advice form above su ced and the team stopped all e orts in that regard.
than we thought we were expected to write gui tests and we started so.
in parallel we had a talk with our coach and he said no you don t have to do this gui stu and we stopped that.
team m at the same time teams complained about missing organizational guidelines about required tests as well as missing speci cations for testing processes.
we really did not know how much we were supposed to test in order to pass this quality gate.
it just did not say and that was frustrating!
team c furthermore imprecise guidelines in uenced the teams testing behavior.
guidelines did not specify a high number of tests thus students did not feel obliged to deliver many tests.
there was no guideline which contains information about using these aspects.
well what we have done in total has been relatively little.
for me i was surprised that it hasn t been valued much.
team f no time to learn although testing is taught in courses students have no practical experiences in testing and even so students may have forgotten how to test correctly.
well i did not know about junit.
team r in this case teams have to learn how to test.
because of the time pressure mentioned above time is short in their project which leads to having no time to learn testing .
especially gui testing is time consuming while learning how to test or becoming acquainted with frameworks which led to missing gui tests.
then one is satis ed with junit and uses it.
i mean time was short.
team a5.
summary this section summarizes our ndings with respect to the research questions we asked in section .
our rst research question was concerned with how students test their software products i.e.
which testing strategies they use.
students distinguished between automated and manual testing.
of those who used automated testing most wrote unit tests with junit.
for testing the whole application most teams used unsystematic smoke testing with only some using more rigorous forms of manual testing with a testing protocol or a checklist.
a few teams automated their gui tests.
only four teams had talked about testing in the rst phase of the project.
teams did not plan their testing e orts at all.
two teams had a testing mentor among their members who provided examples and guided the other team members in their testing e orts.
all teams started testing only in the last project phase.
testing was perceived as a secondary concern.
the second research question inquired about enabling and inhibiting factors with regards to testing.
teams said they had no time to learn testing during the project as requirements design and development took up most of their time.
students perceived the project as uncritical and not complex enough to warrant testing putting o learning testing for real projects.
many theoretically knew unit testing and junit but had not used it in a real project before.
students said they had not experienced for themselves the bene ts that testing can bring.
they especially mentioned that there was no feeling of accomplishment which would have motivated them to practice or use testing more.
many had no experience or knowledge in gui or integration testing and thus were overwhelmed with the technicalities of these practices so they did not use them.
one team with a more experienced student was relatively successful in its testing e orts.
this student actively acted as a testing mentor and di used the practice in the team.
another team also had a member with prior experience but he did not actively mentor his team s member consequently testing did not become a focus in that project.
our third research question was concerned with students attitudes towards testing.
students are aware of the benets of automated testing but at the same time know that testing incurs a cost.
relative to their actual implementation students said that the e ort required for testing seemed very high.
especially gui testing was perceived as very difcult.
thus they opted for manual testing which they said was easier in the moment and gave faster feedback.
study participants liked the feeling of accomplishment that came from implementing software features but at the same time said that they did not experience that feeling with testing.
this made them feel less motivated to write tests.
some students even said that writing test code makes them feel unproductive or that testing was a secondary task distinct from actual software development.
others disliked nding defects as that would mean more work.
finally the fourth research question asked how students incorporated testing into their engineering process.
they started testing late in the process as they perceived their projects to be too unclear and unstable.
thus students chose not to invest their time into writing tests that they would have had to change later anyway.
this notion was especially prevalent towards gui tests as they were perceived as signi cant maintenance burden.teams started to test when they perceived their projects as stable.
however they had found most defects by then through manual testing.
thus even when they nally wrote tests they did not get to experience the bene ts of testing.
even though some students claimed otherwise we suspect that missing out on that positive experience will make it less likely for students to test early in future projects.
.
discussion this section discusses our ndings in light of di usion of innovations theory as well as their potential impact for organizations educators and researchers.
it concludes with a discussion of our study s limitations and threats to validity.
.
diffusing testing practices di usion of innovations theory describes how innovations tools ideas or practices perceived as new are adopted by individuals and organizations and how they di use in social systems.
testing can be regarded as one such idea or practice.
testing is often not taught alongside programming thus adopting testing practices requires a change in behavior for no immediate or guaranteed bene t. rather one of the main perceived bene ts of testing is that it can avoid the possible but not guaranteed occurrence of defects.
as such the consequences of adopting testing are uncertain it may or may not prove bene cial in the future.
di usion of innovations theory calls such practices and tools preventive innovations .
rogers argues that the motivation of an individual to adopt such a behavior is usually rather weak as bene ts are uncertain and behavior change is associated with costs.
thus individuals need cues to actions to eventually start adopting a tool or practice.
these cues can be both personal experiences or experiences of others for example watching a colleague or role model be successful with testing or experiencing problems oneself that were caused by not having written test code.
however as became clear in our study novices usually have not had much exposure to such experiences personal or otherwise.
the question then is how can we expose students novices or junior developers to experiences that help them adopt testing practices?
singer proposes a set of interventions to facilitate the di usion of software engineering practices that do not change the development process.
this might be a suitable approach when processes cannot be changed.
in more exible contexts pair programming and mentoring seem like more powerful means to in uence developer behavior.
pair programming has long been known to facilitate learning and student performance .
as such it seems like a suitable approach to help di use practices such as automated testing among novices.
we saw a more lightweight but related approach in our study a testing mentor that emerged in one team team i c.f.
table exposed team members to good testing practices guided them in their e orts and provided examples that students were able to build upon.
such a mentor would not necessarily need to be restricted to being on a single team they could visit di erent teams from time to time di using practices through the whole organization.
both pair programming and mentoring can be applied in organizational and educational contexts.
in addition students might want to expose themselves to good testing prac tices in a self directed manner.
the results of one of our previous studies indicate that participation in open source projects may be a very suitable approach for this.
however open source can feel intimidating for some.
in a di erent study we found out about an alternative mode of self directed peer based learning the pairwithme twitter hashtag .
twitter users use the hashtag to nd random strangers for remote pair programming on a problem of their choosing.
we suspect that this creates a marketplace for learning that opens up the possibilities for an individual to learn from a diverse set of others.
.
implications forsoftware development organizations our study uncovered some phenomena that they quite possibly need to confront as well albeit in weaker form.
some coaches from our group discouraged teams from automated testing.
we conclude that the o cial policy in our group was thus not clear enough.
in addition the explicit guidelines given to students were apparently not demanding enough.
for us this constitutes a good reminder that policies and guidelines in education and professional organizations alike need to be clear and explicit if employees are expected to enact them.
even though organization are unlikely to have teams solely composed of novices they still need to train and accustom new employees to expected practices and conventions.
thus it seems likely that adopting a method that di uses desired practices amongst an organization s members as proposed in the preceding section would be bene cial.
toeducators our results demonstrate that there is still a lot of potential for optimizing the learning experience.
students were busy learning team based development gathering and documenting requirements designing and implementing their software.
this left them no time to learn testing practices simultaneously.
just as they had been taught programming before our results suggest that there is a need for purely testing oriented projects that let students focus on this part of software development.
because of our results and discussing in the preceding section we suspect con gurations with peer learning mentoring or pair programming to have great potential for such a testing course.
finally we hope that software engineering researchers will be interested to conduct similar studies on the perceptions and attitudes of developers towards testing.
as we discuss in the succeeding section our study has some limitations that warrant its replication in other contexts.
relatedly a quantitative study on our ndings would be desirable.
from a more technical perspective we found gui testing to be very challenging for students.
powerful tools and techniques are often the focus of software engineering research.
our study suggests that the practical adoption of software engineering practices also depends on the usability of practices and tools.
thus we urge researchers to invest e ort into lowering the barriers for developers to use their artifacts.
.
limitations and threats to validity we were interested in the phenomena that happened in students testing behavior.
even though we had study participants we do not claim statistical signi cance.
we intend to test the strength of our ndings in a follow up study.
as this study was conducted within a student project some limitations related to this apply.
participants said that they did not take the project too seriously as it was a coursefor learning and no critical software was developed.
students were also busy with other courses at the same time which probably intensi ed the time pressure they felt.
yet time pressure applies in commercial projects as well.
our followup study will focus on quantitatively validating or invalidating the phenomena we saw in this study with professional software developers of di erent experience levels.
our population was self selected as students were free to decline the interview without any consequences.
yet none made use of this option our population was the complete set of one semester s software project course participants.
the interviews took part when all students had already successfully passed the project.
we encouraged them to talk freely and found them to be very candid e.g.
some openly admitted that they only tested their project because at least some testing was mandatory in the course.
we have no reason to believe that our participants might have given us an inaccurate picture of the testing related events.
our ndings cannot be generalized to other populations.
this is a known limitation of grounded theory studies.
more studies are needed to nd out which of these phenomena appear in other contexts.
however our ndings might still hold for many other novices that are about to or have just completed their university degrees in computer science.
teams comprised only of novice developers are unlikely to be the norm.
however because of the relatively extreme manifestation of our population in this regard we suspect that we were able to uncover phenomena that might be present in weaker forms in many individuals or teams.
.
conclusions and outlook we interviewed computer science students about their testing behavior in a software project course.
these students were about to earn their bachelor s degrees in computer science and join the software industry.
amongst other ndings we documented that novice developers may perceive testing as a secondary cumbersome task that they are not motivated to spend e ort on as they have not experienced its bene ts before.
time pressure keeps them from crossing the chasm between learning testing and becoming productive with it.
since testing is a preventive innovation motivation to invest e ort into learning it is especially low.
this sentiment was especially pronounced for gui testing as it is even more challenging technically.
our results suggest that software companies could bene t from being aware of these experiences perceptions and attitudes of junior developers.
collaborative development with more senior developers might help mitigate this and similar problems with other software engineering practices.
educators might need to consider providing additional courses solely focused on testing or using alternative learning methods such as peer learning mentoring or pair programming.
we hope that software engineering researchers will conduct similar studies in di erent contexts.
in addition the technical barriers we discovered provide problems with testing tools and practices that have yet to be solved by research.
as our next step we will conduct a quantitative study comparing our ndings with the situations of experienced as well as inexperienced professional software developers from industry.
this will allow us to trace how developers testing practices develop over time and will help identify gaps in both academic education and industrial training.
.