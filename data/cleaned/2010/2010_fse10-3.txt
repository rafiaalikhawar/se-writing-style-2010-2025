directed test suite augmentation techniques and tradeoffs zhihong xuy yunho kim moonzoo kim gregg rothermely myra b. coheny ydepartment of computer science and engineering university of nebraska lincoln zxu grother myra cse.unl.edu computer science department korea advanced institute of science and technology kimyunho kaist.ac.kr moonzoo cs.kaist.ac.kr abstract test suite augmentation techniques are used in regression testing to identify code elements affected by changes and to generate test cases to cover those elements.
our preliminary work suggests that several factors influence the cost and effectiveness of test suite augmentation techniques.
these include the order in which affected elements are considered while generating test cases the manner in which existing regression test cases and newly generated test cases are used and the algorithm used to generate test cases.
in this work we present the results of an empirical study examining these factors considering two test case generation algorithms concolic and genetic .
the results of our experiment show that the primary factor affecting augmentation is the test case generation algorithm utilized this affects both cost and effectiveness.
the manner in which existing and newly generated test cases are utilized also has a substantial effect on efficiency but a lesser effect on effectiveness.
the order in which affected elements are considered turns out to have relatively few effects when using concolic test case generation but more substantial effects when using genetic test case generation.
categories and subject descriptors d. .
testing and debugging general terms algorithms experimentation .
introduction software engineers use regression testing to validate software as it evolves.
to do this cost effectively they often begin by running existing test cases.
existing test cases however may not be adequate to validate the code or system behaviors that are present in a new version of a system.
test suite augmentation techniques e.g.
address this problem by identifying where new test cases are needed and then creating them.
despite the need for test suite augmentation most research on regression testing has focused on using existing test cases.
there has been research on approaches for identifying affected elements code components potentially affected by changes but these approaches leave the task of generating new test cases to enpermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
fse november santa fe new mexico usa.
copyright acm ... .
.gineers.
there has been research on automatically generating test cases given pre supplied coverage goals e.g.
but this research has not attempted to integrate the test case generation task with reuse of existing test cases for augmentation.
in principle any test case generation technique could be used to generate test cases for a modified program.
we believe however that test case generation techniques that leverage existing test cases hold the greatest promise where test suite augmentation is concerned.
this is because existing test cases provide a rich source of data on potential inputs and code reachability and existing test cases are naturally available as a starting point in the regression testing context.
further recent research on test case generation has resulted in techniques that rely on dynamic test execution and such techniques can naturally leverage existing test cases.
in prior work we developed a directed test suite augmentation technique .
the technique begins by using a regression test selection algorithm to identify code affected by changes and existing test cases relevant to testing that code.
the technique then uses the identified test cases to seed a concolic test case generation approach to create test cases that execute the affected code.
a case study shows that the approach improves both the efficiency of the technique and its ability to cover affected elements.
further work examined a similar approach to augmentation using a genetic algorithm for test case generation.
while these initial results are encouraging our attempts to create augmentation techniques show that several factors can potentially influence the cost and effectiveness of those techniques.
three factors in particular appear to be the order in which affected elements are considered while generating test cases the manner in which existing and newly generated test cases are used and the algorithm used to generate test cases.
to create effective test suite augmentation techniques we need to understand the influence of the foregoing factors.
based on such an understanding we should be better able to create augmentation techniques that leverage test cases in a cost effective manner.
we have therefore designed and conducted a controlled experiment investigating these factors in the context of test suite augmentation.
our experiment considers concolic and genetic test case generation algorithms two different orderings of affected elements and two different manners of using existing test cases.
we consider each relevant combination on these on four object programs measuring the effectiveness of the approaches in terms of code coverage and their costs in terms of the time required to perform augmentation.
the results of our experiment show that among the factors that we consider the primary factor affecting augmentation is the algorithm utilized to generate test cases this affects both augmentation cost and effectiveness.
the manner in which existing and newly generated test cases are utilized also has a substantial effect on ef ficiency but a lesser effect on effectiveness.
the order in which affected elements are considered turns out to have relatively few effects when using concolic test case generation but more substantial effects when using genetic test case generation.
this work makes several contributions.
we provide a new formalized algorithm for performing augmentation using various test case generation algorithms and various settings of potentially influential factors.
we report results on the first controlled experiment considering test suite augmentation and the first such experiment to compare different test case generation techniques in the augmentation context genetic and concolic .
our results provide additional evidence that directed test suite augmentation techniques can be effective.
our results reveal factors that researchers and experimentalists should consider when attempting to create and study directed test suite augmentation techniques.
.
background .
test suite augmentation letpbe a program let p0be a modified version of p and lettbe a test suite for p. regression testing is concerned with validatingp0.
to facilitate this engineers often begin by reusing t and a wide variety of approaches have been developed for rendering such reuse more cost effective via regression test selection rts e.g.
and test case prioritization e.g.
.
test suite augmentation techniques in contrast are not concerned with reuse of t. rather they are concerned with the tasks of identifying affected elements portions of p0or its specification for which new test cases are needed and then creating or guiding the creation of test cases that exercise these elements .
various algorithms have been proposed for identifying affected elements in software systems following changes.
some of these operate on levels above the code such as on models or specifications but most operate at the level of code and in this paper we focus on these.
code level techniques use various analyses such as slicing on program dependence graphs to select existing test cases that should be re executed while also identifying portions of the code that are related to changes and should be tested.
however these approaches do not provide methods for generating actual test cases to cover the identified code.
four recent papers specifically address test suite augmentation.
two of these present an approach that combines dependence analysis and symbolic execution to identify chains of data and control dependencies that if tested are likely to exercise the effects of changes.
a potential advantage of this approach is a fine grained identification of affected elements however the papers present no specific algorithms for generating test cases.
a third paper presents an approach to program differencing using symbolic execution that can be used to identify affected elements more precisely than and yields constraints that can be input to a solver to generate test cases for those requirements.
however this approach is not integrated with reuse of existing test cases.
as mentioned in section the test suite augmentation approach that we presented in integrates an rts technique with an adaptation of the concolic test case generation approach presented in .
this approach leverages test resources and data obtained from prior testing sessions to perform both the identification of coverage requirements and the generation of test cases to cover these.
the augmentation approach presented in operates similarly but uses a genetic algorithm to generate test cases.
case studies of the approaches shows that both can be effective and efficient.
both of these studies however are small and neither study comparesmultiple augmentation approaches.
further while describes potentially influencing factors it investigates only one.
.
test case generation while in practice test cases are often generated manually there has been a great deal of research on techniques for automated test case generation.
for example there has been work on generating test cases from specifications from formal models and by random or quasi random selection of inputs e.g.
.
in this work we focus on code based test case generation techniques many of which have been investigated in prior work.
among these several techniques e.g.
use symbolic execution to find the constraints in terms of input variables that must be satisfied in order to execute a target path and attempt to solve this system of constraints to obtain a test case for that path.
while the foregoing test case generation techniques are static other techniques make use of dynamic information.
executionoriented techniques incorporate dynamic execution information into the search for inputs using function minimization to solve subgoals that contribute toward an intended coverage goal.
goaloriented techniques also use function minimization to solve subgoals leading toward an intended coverage goal however they focus on the final goal rather than on a specific path concentrating on executions that can be determined through analysis to possibly influence progress toward that goal.
several test case generation techniques use evolutionary or searchbased approaches e.g.
such as genetic algorithms tabu search and simulated annealing to generate test cases.
other work combines concrete and symbolic test execution to generate test inputs.
this second approach is known asconcolic testing ordynamic symbolic execution and has proven useful for generating test cases for c and java programs.
the approach has been extended to generate test data for database applications and for web applications using php .
.
augmentation techniques we now describe the augmentation techniques that we consider.
.
augmentation basics .
.
coverage criterion we are interested in code based augmentation techniques and these typically involve specific code coverage criteria.
in this work we focus on code coverage at the level of branches that is outcomes of predicate statements.
while stronger than statement coverage branch coverage is more tractable than criteria such as path coverage and more likely to scale to larger systems.
.
.
identifying affected elements as noted in section test suite augmentation consists of two tasks identifying affected elements and creating test cases that exercise these elements.
in this work the factors we are studying concern the second of these tasks thus we choose a typical and practical approach for performing the first.
given program pand its test suitet and modified version p0ofp to identify affected elements inp0we execute the test cases in tonp0and measure their branch coverage.
any branch in p0that is not covered is an affected element.
this approach corresponds to the common retest all regression testing process in which existing test cases are executed onp0first and then augmentation is performed where needed.
.
.
ordering affected elements our augmentation techniques operate on lists of affected elements and we believe that the order in which these elements areconsidered can affect the techniques.
in this work we investigate the use of a depth first order of affected elements.
the depth first order dfo of nodes in a graph is the reverse of the order in which nodes are last visited in a preorder traversal of the graph .
in dataflow analysis dfo causes nodes that are earlier in control flow to be considered prior to those that follow them and can speed up the convergence of an analysis.
we conjecture that by considering affected elements in this order we may be able to speed up the process of generating test cases because test cases generated for elements earlier in flow may incidentally cover elements occurring later in flow obviating the need to consider those later elements again.
in our case we construct the dfo in terms of branches and on a program s interprocedural control flow graph icfg .
we first build the icfg then we traverse the icfg recording the branches that we visit both forward and while backtracking .
this recorded information lets us calculate the reverse of the order in which branches are last visited.
finally we filter out branches that were not designated as affected to obtain our ordered list of affected elements.
.
.
main augmentation algorithm algorithm controls the augmentation process beginning with an initial set of existing test cases tc an ordered set of affected elements target branches baffini and an iteration limit niter.
the algorithm assigns baffinitobaff line which henceforth contains a set of affected elements still needing to be covered.
the main loop lines continues until we can no longer increase coverage which may result due to reaching the iteration limit in the test case generation routines .
within this loop for each branch bt2baff ifbtis not covered we call a test case generation algorithm to generate test cases line .
if the algorithm successfully generates and returns new test cases this means that at least some new coverage has been achieved in the program although btmay or may not have been covered in the process .
input set of existing test cases tc ordered set of affected elementsbaffini and an iteration limit niter output tcaugmented with new test cases 1baff baffini 2newcoverage true 3whilenewcoverage do 4newcoverage false foreachbt2baffdo ifnotcovered then newtests augment tc b aff bt niter ifnewtests !
empty then newcoverage true end ifusenew then tc newtests tc end end end 16end algorithm main augmentation algorithm to accommodate our other factor of concern the manner in which existing and new test cases are used we allow for the possibility of adding the newly generated test cases back into our set of available test cases.
if the boolean flag usenew is set to true this causes the algorithm to combine the newly generated test cases with the original test cases lines and then this newly formedtcis used for the next iteration of our algorithm.
we next describe two different test case generation algorithms that can be invoked at line to generate new test cases.
.
genetic test suite augmentation genetic algorithms for structural test case generation begin with an initial often randomly generated test data population and evolve the population toward targets that can be blocks branches or paths in a program .
to apply such an algorithm to a program the test inputs must be represented in the form of a chromosome and a fitness function must be provided that defines how well a chromosome satisfies the intended goal.
the algorithm proceeds iteratively by evaluating all chromosomes in the population and then selecting a subset of the fittest to mate.
these are combined in a crossover stage where information from one half of the chromosomes is exchanged with information from the other half to generate a new population.
a small percentage of chromosomes in the new population are mutated to add diversity back into the population.
this concludes a single generation of the algorithm.
the process is repeated until a stopping criterion has been met.
algorithm describes the genetic algorithm used in our experiment.
the algorithm accepts four parameters a set of test cases tc a set of affected elements baff an uncovered target branch bt and an iteration limit niter.
the algorithm returns a set of new test casesntc consisting of all test cases generated that covered any previously uncovered branches in p. instead of using random test cases to form an initial population we take advantage of existing test cases to seed the population.
we run this algorithm for each target branch bt.
as the starting population we select all of the test cases reaching method mbt the method that contains bt this determines the population size.
input a set of test cases tc a set of affected elements baff an uncovered target branch bt2baff and an iteration limit niter output a set of new test cases ntc 1tccur tc set of current target test cases 2ntc set of new test cases generated 3tcbt ftest cases intccurthat reach method mbt the method containing bt 4population tcbt 5i 6repeat 7fitness calculatefitness population 8population select population fitness 9population crossover population 10population mutate population 11i i foreachtc2population do execute tc iftccovers new branches in baffthen updatebaff ntc ntc tc end end 19untili niterorbtis covered 20returnntc algorithm genetic augment algorithm the algorithm repeats for a number of generations set by the variableniter or untilbtis covered.
the first step line is to calculate the fitness of all test cases in the population.
since the fitness of a test case depends on its relationship to the branch we are trying to cover calculating the fitness requires that we run the test case.
for test cases provided initially we can use coverage information obtained while performing the prior execution of tc which in our case occurred in conjunction with determining affected elements.
next a selection is performed line which orders and chooses thebest half of the chromosomes to use in the next step.
this population is divided into two halves retaining the ranking and the first chromosome in the first half is mated with the first chromosome in the second half and this continues until all have been mated.
next line a small percentage of the population is mutated after which all test cases in the current population are executed.
if btis covered or the iteration limit is met we are finished line otherwise we iterate.
.
concolic test suite augmentation concolic testing concolic execution concretely executes a program while carrying along a symbolic state and simultaneously performing symbolic execution of the path that is being executed.
it then uses the symbolic path constraint gathered along the way to generate new inputs that will drive the program along a different path on a subsequent iteration by negating a predicate in the path constraint.
in this way concrete execution guides the symbolic execution and replaces complex symbolic expressions with concrete values when needed to mitigate the incompleteness of the constraint solvers .
conversely symbolic execution helps to generate concrete inputs for the next execution to increase coverage in the concrete execution scope.
in the traditional application of concolic testing test case reuse is not considered and the focus of test generation is on path coverage.
first a random input is applied to the program and the algorithm collects the path condition for this execution.
next the algorithm negates the last predicate in this path condition and obtains a new path condition.
calling a constraint solver on this path condition yields a new input and a new iteration then commences in which the algorithm again attempts to negate the last predicate.
if the algorithm discovers that a path condition has been encountered before it ignores it and negates the second to last predicate.
this process continues until no more new path conditions can be generated.
ideally the end result of the process is a set of test cases that cover all paths.
in this work we alter the foregoing approach to function in the context of the main augmentation algorithm presented in section .
.
this includes leveraging existing test cases and operating on an ordered list of affected elements at the level of branch coverage.
we use the following notation cfg p np ep is a control flow graph of a target programpwherenpis a set of nodes statements in p and epis a set of edges branches in p betweennp.
apath condition pcof a target program pis a conjunction bi1 bi2 binwherebi1 binare edges in epand executed in order.
note that ncan be larger thanjepj since one branch in a loop body of pmay be executed multiple times i.e.
it is possible that bik bilfork6 l .
delneg pc j generates a new path condition from a path conditionpcby negating a branch occurring at the jth position inpcand removing all subsequent branches.
for example delneg bi1 bi2 bi3 bi1 bi2.
bis a paired branch of a branch b i.e.
ifbis athen branch bis the else branch .
lastpos b pc returns a last position jof a branchbijin a path condition pcwhereb bij i.e.
8j k n bik6 b .
solve pc returns a test case satisfying the path condition pc ifpcis satisfiable unsat otherwise.
algorithm describes our concolic augmentation algorithm.
the algorithm accepts the same four parameters accepted by the genetic algorithm and returns a set ntc of new test cases.
lines detail the main procedure of the algorithm.input a set of test cases tc a set of affected elements baff an uncovered target branch bt2baff and an iteration limit niter output a set of new test cases ntc 1tccur tc a set of the current target test cases 2ntc a set of all new test cases generated 3repeat 4ntc cur a set of newly generated test cases in the current execution of line to line 5tcbt fall test cases in tccurthat reachbt iftcbt then return end 9pcbt fpath conditions obtained from executing test cases intcbt foreachpc2pcbtdo foreachi lastpos bt pc toi niter 1do ifi 0then pc0 delneg pc i tcnew solve pc0 iftcnew6 unsat and tcnewcovers uncovered branches in baffthen updatebaff ntc cur ntc cur ftcnewg end end end end 22tccur ntc cur 23ntc ntc ntc cur 24untilntc cur 25returnntc algorithm concolic augment algorithm initially the current target test cases tccur from which new test cases are generated are the old test cases tc line and ntc is empty line .
the start of the main procedure resets the set of newly generated test cases ntc cur line and selects test cases that can reach bt the paired branch of bt from among the current target test cases tccur line .
if there are no such test cases the algorithm terminates lines .
if there are such test cases the algorithm obtains path conditions by executing the target program with selected test cases line .
from each obtained path condition pc the algorithm generates niternew path conditions as follows.
suppose the last occurrence of btis located in the mth branch ofpc.
then the algorithm generates niternew path conditions lines by negating bim bim b im niter 1and removing all following branches in pc respectively line .
if a newly generated path condition pc0has a solution tcnew a new test case line andtcnew covers uncovered branches in baff line baffis updated to reflect the new status of coverage line and tcnewis added to the set of newly generated test cases ntc cur line .
note that the iteration limit niterparameter is a tuning parameter that determines how far back in a path condition the augmentation approach will go and in turn can affect both the efficiency and the effectiveness of the approach.
.
empirical study our goal is to investigate the two augmentation techniques considered focusing on the factors we have discussed.
we thus pose the following research questions.rq1 how does the order of consideration of affected elements affect augmentation techniques?
rq2 how does the use of existing and newly generated test cases affect augmentation techniques?
rq3 how do genetic and concolic test case generation techniques differ in the augmentation context?
.
objects of analysis to facilitate technique comparisons programs must be suitable for use by both implementations.
also programs must be provided with test suites that need to be augmented.
to select appropriate objects we examined c programs available in the sir repository .
we selected four programs see table each of which is available with a large universe of test cases representing test cases that could have been created by engineers in practice for these programs to achieve requirements and code coverage .
the object programs that we selected do not have actual sequential versions that can be used to model situations in which evolution renders augmentation necessary.
we were able however to define a process by which a large number of test suites that need augmenting and that possess a wide range of sizes and levels of coverage adequacy could be created for the given object program versions.
this lets us model a situation where the given versions have evolved rendering prior test suites inadequate and require augmentation.
to create such test suites we did the following.
first for each object program pwe used a greedy algorithm to sample p s associated test universe u to create test suites that were capable of covering all the branches coverable by test cases in u. next we measured the minimum size tmin and maximum size tmax for these suites.
we then randomly chose a number nsuch that tmin n tmax and randomly selected ntest cases from u to create a test suite a. we measured the coverage achieved by aonp and ifawas coverage adequate for pwe discarded it.
we repeated this step until non coverage adequate test suites had been created.
statistics on the sizes and coverages of these test suites are given in table .
.
variables and measures .
.
independent variables our experiment manipulated three independent variables iv1 order in which affected elements are considered.
as orders of affected elements we use the depth first order described in section .
and a baseline approach that orders affected elements randomly.
iv2 manner in which existing and new test cases are reused.
we consider two approaches to reusing test cases namely the approach in which a test case generation algorithm attempts to utilize only existing test cases and the approach in which it uses existing along with newly generated test cases.
iv3 test case generation technique.
we consider two test case generation techniques namely the genetic and concolic techniques described in sections .
and .
respectively.
.
.
dependent variables and measures we wish to measure both the effectiveness and the cost of augmentation techniques under each combination of potentially affecting factors.
to do this we selected two variables and measures.
dv1 effectiveness in terms of coverage.
the test case augmentation techniques that we consider are intended to work with existing test suites to achieve higher levels of coverage in atable experiment objects program functions loc branches test cases printtok1 printtok2 replace tcas table branch coverage and sizes of initial test suites program branch coverage test suite size avg min max avg min max printtok1 .
.
printtok2 .
.
replace .
.
tcas .
.
modified program p0.
to measure the effectiveness of our techniques we track the number of branches in p0that can be covered by each augmented test suite.
dv2 cost in terms of time.
to track the cost of augmentation for each application of an augmentation technique we measure the wall clock time required to apply the technique.
.
experiment setup several steps had to be followed to establish the experiment setup needed to conduct our experiment.
.
.
extended programs to implement our concolic test case generation technique we created a tool based on crest .
crest transforms a program s source code into an extended version in which each original conditional statement with a compound boolean condition is transformed into multiple conditional statements with atomic conditions without boolean connectives i.e.
if b1 b2 f is transformed into if b1 if b2 f .
to facilitate fair comparisons between concolic and genetic algorithms however we cannot apply the former to extended programs and the latter to non extended programs.
we thus opted to create extended versions of all four programs and apply both algorithms to those versions.
.
.
iteration limits genetic algorithms iteratively generate test cases and an iteration limit governs the stopping point for this activity.
similarly the concolic approach that we use employs an iteration limit that governs the maximum number of path conditions that should be solved to generate useful test cases.
these iteration limits can affect both the effectiveness and the cost of the algorithms.
thus we cannot run experiments with just one iteration limit per approach because this would result in a case where our comparisons might reflect iteration limits rather than differences in techniques.
for this reason we chose multiple iteration limits for each test case generation approach using for concolic and for genetic.
the different numbers are due to the different meanings of iterations across the two algorithms as explained in sections .
and .
.
.
.
technique tuning genetic algorithms must be tuned to the object programs on which they are to be run.
this does not present a problem in a test suite augmentation setting because tuning can be performed on early system versions and then the resulting tuned algorithms can be utilized on subsequent versions.
for this study we tuned our genetic algorithms by applying them directly to the extended object programs absent any existing suites.
.
experiment operation given our independent variables an individual augmentation technique consists of a triple g a m where g is one of the two test case generation techniques genetic or concolic a is one of two affected element orders random or depth first and m is one of the two test case reuse approaches old test cases or new old test cases .
an individual augmentation technique application consists of an augmentation technique applied at an iteration limit l where l is one of our five values.
our experiment thus employs eight augmentation techniques and augmentation technique applications.
each of these is applied to each of our four object programs for each of the test suites that we created for that program.
this results in augmentation technique applications for each of which we collect our dependent variables to obtain the data sets needed for our analysis.
our experiments were run on a linux box with an intel core2duo e8400 at .6ghz and with 16gb ram running fedora as an os.
.
threats to validity the primary threat to external validity for this study involves the representativeness of our object programs and test suites.
we have examined only four relatively small c programs and other objects may exhibit different cost benefit tradeoffs.
furthermore our programs are chosen to allow application of both genetic and concolic testing and thus do not reveal cases in which program characteristics might disable one but not the other of these approaches.
a second threat to external validity pertains to our algorithms we have utilized only one variant of a genetic test case generation algorithm and one variant of a concolic testing algorithm and we have applied both to extended versions of the object programs where the genetic approach does not require this and might function differently on the original source code.
subsequent studies are needed to determine the extent to which our results generalize.
the primary threat to internal validity is possible faults in the implementation of the algorithms and in tools we use to perform evaluation.
we controlled for this threat through extensive functional testing of our tools.
a second threat involves inconsistent decisions and practices in the implementation of the techniques studied for example variation in the efficiency of implementations of techniques could bias data collected.
where construct validity is concerned there are other metrics that could be pertinent to the effects studied.
in particular our measurements of cost consider only technique run time and omit costs related to the time spent by engineers employing the approaches.
our time measurements also suffer from the potential biases detailed under internal validity given the inherent difficulty of obtaining an efficient technique prototype.
.
results and analysis as an initial overview of the data tables and present the average coverage and cost values obtained per program across all test suites for each iteration level for each combination of order of affected elements and test reuse approach.
each table presents results for concolic and genetic techniques under one combination.
we now present and analyze our data with respect to our three research questions in turn.
.
rq1 order of affected elements our first research question pertains to the effects of using different orders of affected elements in this case depth first order versus random.
table presents data relevant to this question.
the table presents results per program with coverage results in the left half and cost results in the right half.
column headers use mnemonicsto indicate techniques gdo corresponds to genetic dfo old gdn to genetic dfo new old gro to genetic random old grn to genetic random new old cdo to concolic dfo old cdn to concolic dfo new old cro to concolic random old and crn to concolic random new old .
individual columns correspond to techniques compared thus column with header gdo vs gro compares genetic dfo old to genetic random old in each column then the only source of variance between the techniques compared is the order.
each entry in the table summarizes the differences observed between the two techniques for each of the five iteration limits with d indicating that the technique using depth first order exhibited the greater mean coverage or cost value r indicating that the technique using random order exhibited the greater mean coverage or cost value and indicating that techniques exhibited equal mean coverage.
for example for tcas comparing gdo and gro the table contains d d r r indicating that at the lowest two iteration levels depth first order produced better coverage at the third level the orders produced equal coverage and at the upper two levels random order produced better coverage.
for each pair of techniques compared for each iteration limit l we applied a t test to the coverage cost data obtained across all test suites augmented to determine whether there is a statistically significant difference between the two techniques at iteration limit l using 05as the confidence level.
in the table bolditalicized fonts indicate statistically significant differences.
for example for printtok1 comparing gdo and gro the only statistically significant difference between techniques occurred at iteration level .
it is these statistical differences that we focus on with respect to our research question.
we begin by considering the results for the genetic algorithm.
where coverage is concerned no clear advantage resides in either test case order and results are relatively similar in the cases where old or new and old test cases are used.
across all iteration limits and programs dfo and random orders each achieve better results than the other almost half of the time but there are only two statistically significant differences between the two orders.
these occur onprinttok1 andreplace at the third iteration level with dfo exhibiting better results once and random once.
where cost results for the genetic algorithm are concerned we see different trends.
first in the gdo vs gro column there are cases where order causes statistically significant differences these include all results for tcas andprinttok1 .
in the gdn vs grn column there are also cases again including all cases for tcas andprinttok1 .
in all but one of these cases random is more costly than dfo.
turning to the concolic approach where coverage is concerned we do see an increase in the number of statistically significant differences between techniques to cases.
however in this case there is no clear superiority adhering to either of the two test case orders each of random and dfo are superior in several cases and there are no apparent patterns involving iteration limits or programs to indicate factors potentially influencing this.
finally considering cost results for concolic we again see a large number of statistically significant differences in costs with in the cdo vs cro case and in the cdn vs crn case.
here however there is no clear advantage adhering to either random or dfo orders each is superior a number of times.
.
rq2 use of existing and new test cases our second research question pertains to the effects of reusing existing and newly generated test cases.
table presents data relevant to this question.
the table format is similar to that of table table coverage using dfo order and old test cases coverage cost genetic printtok1 .
.
.
.
.
.
.
.
.
.
printtok2 .
.
.
.
.
.
.
.
.
.
replace .
.
.
.
.
.
.
.
.
.
tcas .
.
.
.
.
.
.
.
.
.
concolic printtok1 .
.
.
.
.
.
.
.
.
.
printtok2 .
.
.
.
.
.
.
.
.
.
replace .
.
.
.
.
.
.
.
.
.
tcas .
.
.
.
.
.
.
.
.
.
table coverage using dfo order and old and new test cases coverage cost genetic printtok1 .
.
.
.
.
.
.
.
.
.
printtok2 .
.
.
.
.
.
.
.
.
.
replace .
.
.
.
.
.
.
.
.
.
tcas .
.
.
.
.
.
.
.
.
.
concolic printtok1 .
.
.
.
.
.
.
.
.
.
printtok2 .
.
.
.
.
.
.
.
.
.
replace .
.
.
.
.
.
.
.
.
.
tcas .
.
.
.
.
.
.
.
.
.
table coverage using random order and old test cases coverage cost genetic printtok1 .
.
.
.
.
.
.
.
.
.
printtok2 .
.
.
.
.
.
.
.
.
.
replace .
.
.
.
.
.
.
.
.
.
tcas .
.
.
.
.
.
.
.
.
.
concolic printtok1 .
.
.
.
.
.
.
.
.
.
printtok2 .
.
.
.
.
.
.
.
.
.
replace .
.
.
.
.
.
.
.
.
.
tcas .
.
.
.
.
.
.
.
.
.
table coverage using random order and old and new test cases coverage cost genetic printtok1 .
.
.
.
.
.
.
.
.
.
printtok2 .
.
.
.
.
.
.
.
.
.
replace .
.
.
.
.
.
.
.
.
.
tcas .
.
.
.
.
.
.
.
.
.
concolic printtok1 .
.
.
.
.
.
.
.
.
.
printtok2 .
.
.
.
.
.
.
.
.
.
replace .
.
.
.
.
.
.
.
.
.
tcas .
.
.
.
.
.
.
.
.
.
table impact of order in which affected elements are considered on coverage and cost.
coverage cost gdo vs gro gdn vs grn cdo vs cro cdn vs crn gdo vs gro gdn vs grn cdo vs cro cdn vs crn printtok1 r ddd r d r d d r d d d d d d d d d d r r r r r r r r r r rrr d d rrrd d printtok2 d d r r d r r r d d r r r r r r r r r rr r d d r d r dd r r r d d r rr d d replace r rrr r r r d r r d r r r r r r r d d d d d d d d d d r r rr d r r r r tcas d d r r d d r d d rrdd d rddd r r r r r r r r r r rrd d d rrd d d table impact of reuse of existing test cases on coverage and cost.
coverage cost gdo vs gdn gro vs grn cdo vs cdn cro vs crn gdo vs gdn gro vs grn cdo vs cdn cro vs crn printtok1 nn n n n nn n nn n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n printtok2 nnn n n nnn n n n n n n n n n n n n n n n n n n n n n n n n n n n nn n n n replace n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n tcas n n nn nnn o nn n n n n nn n n n n n n n n n n n n n n n n n n n n n nbut in keeping with the goal of comparing across test case reuse approaches the differences in terms compared all involve reuse approaches old versus new old .
we begin by considering the results for the genetic algorithm.
where coverage is concerned in all but three cases the use of new test cases is superior to reusing only old test cases.
there are also many cases where test case reuse approach has a statistically significant effect.
these include eight comparisons in the case where dfo is used and ten in the case where random order is used.
results vary across programs with replace exhibiting significant differences in all cases.
where cost results for the genetic algorithm are concerned we see much larger effects in all cases the use of new test cases adds to costs and the effect of so is statistically significant.
turning to the concolic approach where coverage is concerned here we see even stronger evidence that test case reuse approach matters with the use of new test cases always more effective and in all but three cases statistically significantly so.
finally considering cost results for concolic we note significant differences in all but one case again with greater costs adhering to the use of new test cases.
.
rq3 test case generation algorithm our third research question pertains to the effects of using different test case generation algorithms and we begin by comparing effectiveness.
one issue to consider in this involves inherent differences in the test case generation algorithms .
in section .
we described the reasoning behind using several iteration limits for each algorithm we expect concolic and genetic algorithms to respond differently over different limits and using different limits lets us observe techniques independent of the threat to internal validity that would attend the use of a single iteration limit.
where comparisons of techniques are concerned there is no inherent relationship between a given iteration limit for concolic and a given iteration limit for genetic that is concolic limits and do not correspond in any way to genetic limits and .
it follows that we cannot validly compare algorithms to each other on a per iteration limit basis.
instead for each object programp we locate the iteration limit lgat which the genetic algorithm operates most effectively on p and the iteration limit lcat which the concolic algorithm operates best on p and we compare the algorithms at their respective optimal iteration limits.
table presents data relevant to rq3 with respect to algorithm effectiveness following the analysis procedure just described.
the table provides data for each object program and for each of the four combinations of affected element ordering and test reuse strategies studied.
an individual table entry indicates which technique achieved higher coverage and italics indicate cases where the difference was statistically significant.
as the table shows on every program but replace the genetic algorithm outperforms the concolic algorithm in each category in which they were compared.
on replace the advantage goes to concolic.
all differences were statistically significant.
turning to efficiency note that this comparison is complicated by the inherent differences in our two implementations.
in fact it is quite difficult to fairly compare our two implementations for efficiency because they are derived from different sources they cannot be said to represent optimal implementations of the two algorithms.
thus we restrict ourselves to observing efficiency differences in a qualitative fashion.
as data presented in tables shows costs for the genetic algorithm range from times in the tens of seconds to times above seconds while costs for the concolic algorithm range from times in the tenths of seconds to times near 10table comparison of coverage genetic vs concolic program gdo gdn gro grn program vs cdo vs cdn vs cro vs crn printtok1 g g g g printtok2 g g g g replace c c c c tcas g g g g seconds.
with our current implementations this represents a very large difference in favor of the concolic approach.
a further issue involves the effects that increasing iteration limits have on the respective algorithms.
here as remarked earlier increases in limits seem to correspond to roughly similar increases proportionally in costs.
this provides some post hoc justification for our choice of particular iteration limits in that they seem somewhat comparable in terms of their effects on relative effort.
.
discussion and implications we now discuss the results presented in the prior section and comment on their implications for research and practice.
test case order order of affected elements is not likely to significantly affect algorithm effectiveness because the same elements will ultimately be considered under any order and this is what we saw in our study.
where costs are concerned in contrast we do see some differences.
our results show that dfo can provide savings in costs when using the genetic algorithm.
this can be explained by observing that with the genetic algorithm if we work with higherlevel branches first we can incidentally cover additional branches.
also test cases that cover branches higher in dependency chains will have inputs that are close to those used to reach lower branches thereby seeding the population with inputs that help the algorithm cover those more quickly.
with the concolic algorithm in contrast cost saving results are mixed.
we suspect this is because test cases generated to cover bt lines of algorithm may not cover other uncovered branches unless these uncovered branches share a common ancestor branch in a short distance from bt less thanniter in an execution tree.
in such cases the ordering of affected elements does not matter in terms of cost.
all things considered we could argue that dfo has the potential to be more efficient than random ordering when using genetic algorithms but the fact that this result occurs only for printtok1 and tcas leads us to be cautious about this.
furthermore there seems to be no clear benefit to using either order where the concolic approach is concerned.
still these results do not preclude finding some other orderings that are more predictably cost effective.
test case reuse approach our results show that the use of new test cases in addition to existing test cases almost always significantly increases the cost of test generation by both techniques.
this result can be explained by the correlation between technique effort and the number of test cases used to seed the technique.
having additional test cases impacts both techniques it controls the population size in the genetic algorithm while the concolic technique must consider each test case supplied to it.
the use of new test cases also significantly increased test generation technique effectiveness in almost all cases in which the concolic approach was used and in many cases where the genetic approach was used.
this difference in results can be explained as follows.
with the genetic algorithm having additional test casesto work with can increase population diversity and improve the chances that crossover will generate chromosomes that cover previously uncovered branches however changes due to the increase might not be substantial when just a few test cases are added to those that had been used previously.
the concolic approach in contrast utilizes each new test case independently and can gain from each as such.
if these results generalize we have a true cost benefit tradeoff.
with both techniques there is a potential payoff for incurring the additional costs involved in reusing test cases and this effect is much larger for the concolic technique than for the genetic technique.
whether any effectiveness gain is worth the additional cost however must be assessed relative to the system being verified.
test case generation techniques concolic and genetic test case generation techniques did perform statistically significantly differently in our study with the genetic algorithm exhibiting greater effectiveness than the concolic algorithm on printtok1 printtok2 and tcas under all combinations of other factors.
it appears that the genetic algorithm is more costly potentially by two orders of magnitude than the concolic algorithm in this although again this comparison is complicated by the presence of several potentially confounding factors.
these observations prompt us to explore possible causes for differences.
generally speaking concolic testing can generate test cases effectively as long as a target program does not contain many complex symbolic expressions or utilize pointer arithmetic non linear arithmetic and external library calls on symbolic variables etc.
this is because new test cases can be generated by the concolic approach only if a generated path condition can be solved by the underlying constraint solver.
genetic algorithms may be more flexible than concolic in that the chromosome and fitness can be adapted to many input types and data structures.
the quality of the test cases generated and the algorithm cost however will be dependent on how well fitness is defined and how well the parameters of the algorithm are tuned and these will be application specific.
for instance if we set our mutation rate too high or if our crossover selection or fitness are not carefully designed then we may fail to converge quickly causing longer run times.
similarly since we must run all of our test cases to calculate fitness if we use a population that is too large this will negatively impact cost.
in the case of our study our object programs do not contain complex symbolic expressions but all of the programs except tcas take strings as inputs.
faced with string inputs genetic algorithms can easily mutate these covering additional branches and they can attempt to use quite a few different mutants.
concolic algorithms cannot as easily address these programs because they transform test cases only locally that is given a target branch btand a base path condition pc line of algorithm the concolic algorithm transforms a number of branches no greater than niter.
the inherent differences between concolic and genetic algorithms and the observed differences in our study suggest that augmentation techniques which combine both approaches either using both on a particular target or differentially applying one or the other depending on characteristics of a target might be more cost effective than approaches that utilize just single techniques.
iteration limits we did not consider iteration limit to be an independent variable rather we blocked our analyses per iteration limit value since this is our stopping criterion.
we did examine our data however to assess iteration limit effects.first there does appear to be an increasing trend in coverage values as iteration limits increase.
beginning with the genetic algorithm and considering the cases in which limits increase i.e.
four increases per program progressing from to to to and to coverage values for gdo increase as limits increase in of cases coverage values for gro increase as limits increase in of cases coverage values for gdn increase as limits increase in of cases and coverage values for grn increase as limits increase in of cases.
the coverage increases however are small overall never more than two and only eight are statistically significant which indicates that our genetic algorithm is converging.
iteration trends occur for the concolic algorithm as well with values generally increasing by small amounts in all cases.
in this case of these increases are statistically significant suggesting that iteration plays a more measurable role for the concolic approach than for the genetic approach and that further increases may provide opportunities to increase effectiveness.
where algorithm costs are concerned iteration limits have larger effects.
for the genetic algorithm costs differ across iteration limits by relatively substantial amounts i.e.
by factors ranging from four to six from iteration limits to .
where the concolic algorithm is concerned we also see increases in costs as iteration limits increase.
the increases are smaller numerically than those observed with the genetic algorithm but they are similar in terms of the factors involved i.e.
they increase by factors ranging from three to ten from iteration limits to .
.
conclusions and future work in this work we have focused on test suite augmentation and our results have several implications for the creation and further study of augmentation techniques.
the results also have implications however for engineers creating initial test suites for programs.
this is because such engineers often begin at least at the system test level with black box requirements based test cases.
it has long been recommended that such test suites be extended to provide some level of coverage.
the techniques we have presented can conceivably serve in this context too working with initial blackbox test cases and augmenting these.
there are additional factors that influence augmentation that we have not examined directly in this work.
program characteristics certainly play a role because they can impact the ability of test case generation techniques to function cost effectively as described in sections .
and .
.
characteristics of existing test suites also matter.
arguably larger test suites or test suites that are more comprehensive in the inputs that they provide or the coverage that they achieve might be more cost effective to augment.
we attempted to control for such characteristics in our experiment by using initial test suites with varying sizes and coverage characteristics but a more formal study of this factor could be helpful.