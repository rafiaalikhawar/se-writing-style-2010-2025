symbolic search based testing arthur baars universidad polit ecnica de valencia valencia spain abaars pros.upv.esmark harman university college london crest centre london u.k. mark.harman ucl.ac.ukyoussef hassoun king s college london london u.k. youssef.hassoun kcl.ac.ukkiran lakhotia university college london crest centre london u.k. k.lakhotia ucl.ac.uk phil mcminn university of sheffield sheffield u.k. p.mcminn sheffield.ac.ukpaolo tonella fondazione bruno kessler trento italy tonella fbk.eutanja vos universidad polit ecnica de valencia valencia spain tvos dsic.upv.es abstract we present an algorithm for constructing fitness functions that improve the efficiency of search based testing when trying to generate branch adequate test data.
the algorithm combines symbolic information with dynamic analysis and has two key advantages it does not require any change in the underlying test data generation technique and it avoids many problems traditionally associated with symbolic execution in particular the presence of loops.
we have evaluated the algorithm on industrial closed source and open source systems using both local and global search based testing techniques demonstrating that both are statistically significantly more efficient using our approach.
the test for significance was done using a onesided paired wilcoxon signed rank test.
on average the local search requires .
and the global search .
fewer fitness evaluations when using a symbolic execution based fitness function generated by the algorithm.
index terms search based testing symbolic execution fitness functions i. i ntroduction automation is essential in software testing because the process is very slow and consequently expensive if undertaken manually.
this need to automate software testing has provided a rich set of challenging problems for the research community for over thirty years.
one approach to software test automation that has achieved a great deal of recent attention is searchbased software testing sbst .
sbst uses meta heuristic algorithms to automate the generation of test inputs that meet a test adequacy criterion.
one of the most widely studied test adequacy criteria in sbst is branch coverage the adequacy criterion considered in this paper.
despite the large body of work in sbst focusing on branch coverage the state of the art fitness function definitions used for branch adequate testing have changed little since the early seminal work on the daimler automated software testing system which has been in use for more than a decade .
though there have been many developments in sbst these focus on changing the search algorithms and the way in which they are used rather than the underlying fitness functions on which all metaheuristic search relies.
this paper takes a different approach and proposes to use static analysis.
in particular we use a form of partial symbolicexecution to statically collect information available at compile time that can be used to define richer and more expressive fitness functions.
we do not perform a complete symbolic execution as this would be computationally expensive.
rather we compute smaller amounts of symbolic information that can be used to imbue a fitness function with a much finer characterisation of the true search landscape which defines the location of the global optima that represent the coverage of individual branches.
our aim in attacking the underlying fitness function is to provide an approach that makes sbst more efficient and possibly more effective regardless of the particular search algorithm used to generate the test data.
we present results for two widely used approaches to demonstrate empirically that our approach does indeed make sbst more efficient.
there are many search algorithms that we could have chosen to study in our experimental work.
a recent survey of search based approaches in software engineering listed search based algorithms that have been used in sbst work.
clearly it is not possible to report results for all of them in this paper.
rather than make an arbitrary choice of algorithms to study we choose to empirically study a local search the widely used alternating variable method a vm of korel and a global search the genetic algorithm approach used by wegener et al.
and widely followed by other subsequent sbst research .
our reason for this choice was that these two approaches characterise the two possible outcomes for the primary choice of which algorithm to use whether it will be local or global.
most of the other algorithms used in sbst are formed by a combination of local and global search.
our results indicate that the partial symbolic information we compute can indeed improve the efficiency of sbst for both real world production code and for open source.
in the case of a local search the information also leads to improved effectiveness of sbst.
the primary contributions of this paper are we introduce an algorithm for improving sbst by enriching fitness functions with statically collected symbolic information.
because our approach targets the fitness function itself it applies to any and every sbst techniqueand can be incorporated without change to the searchbased algorithm that uses the enriched fitness function.
we introduce an approach to overcome the problem of loops in traditional symbolic execution that allows us to approximate the impact of symbolic information on fitness.
we introduce a new metric called the approximation level1to account for uncertainty whenever we cannot compute precise symbolic information such as in the presence of loops.
we present the results of an empirical study on both open and closed source code the results of which indicate that our enriched fitness functions are significantly more efficient than their traditional counterparts.
the rest of the paper is organised as follows the next section provides an overview of the standard fitness function used in sbst for branch coverage.
section iii introduces our fitness function enhancement approach while section iv introduces the code analysis algorithm based on symbolic execution.
section v presents the empirical study with corresponding threats to validity discussed in section vi.
section vii describes related work and section viii draws conclusions.
ii.
b ackground meta heuristic algorithms rely on a fitness function to guide the search towards a global optimum i.e.
the desired test data.
for branch coverage the state of the art fitness function comprises two measures a branch distance and an approach level .
when both these measures are 0the desired test data has been found.
the approach level records how many of a target branch s control dependent nodes were not executed by a particular input.
the fewer control dependent nodes executed the further away the input is from executing the target in control flow terms.
consider the example from figure and assume the target is the true branch of node .
if an input takes the false branch at node then the approach level is and if an input takes the false branch at node the approach level is 1and so forth.
whenever an input misses the target branch the branch distance measure is used to compute how close the input was to staying on a path leading to the target.
it is computed using the condition of the last control flow graph node in an input s execution trace which holds a transitive control dependence on the target and where execution diverged from the target.
resuming the example from figure if an input takes the false branch at node the branch distance is computed through x k where kis a failure constant k throughout this paper .
different branch distance formulae exist depending on the relational predicate types used within the condition of branching nodes on which the target is control dependent.
the interested reader is referred to the work of tracey et al.
for a complete list of branch distance functions.
1note that the definition of approximation level in this paper is not to be confused with the approximation level defined in which is equivalent to theapproach level metric described in section ii.void foo int x int y int z if x if y z if x z target fig.
.
example c code used to demonstrate the standard fitness function used in search based testing.
for a target branch t an input vector v and a node n where execution diverged from t the complete fitness value is then computed by combining the branch distance and approach level ffn t v approach level t v norm branch distance t v note that the branch distance measure is normalized to a value between using either of the following normalization functions norm d braceleftbigg1 .
dor d d used in this paper this fitness function can be inefficient when multiple interdependent conditions need to be satisfied as in the example from figure .
for instance when trying to cover the true branch at node the values chosen for the inputs x yand zthat satisfy the first two conditions are unlikely to traverse the true branch at node .
this is because the probability of the search optimizing both yandzto0is low.
in general optimizing each condition in isolation as is the case with the standard fitness function can be considered sub optimal.
symbolic execution on the other hand is able to capture such constraints and interdependencies between variables in the form of a path condition .
for example the path condition describing the execution where all conditions evaluate to true in figure would be an bracketle tx y z x z an bracketri ht where x yandzdenote symbolic variables corresponding to the three integer inputs x y z .
for the purpose of testing a path condition can be fed to a constraint solver to obtain concrete input values which can be used to execute the program.
however it is well known that static symbolic execution of a program faces several challenges arising from loops and code constructs that cannot easily be symbolically executed such as unknown library functions complex pointer arithmetic and functions pointers to name but a few.
loops in particular are a common problem because they can result in infinitely many program paths and further when trying to cover a target branch it may not be possible to determine the number of loop iterations necessary to reach the target a priori.the field of dynamic symbolic execution dse also known as concolic testing first introduced by godefroid et al.
tries to overcome some of the challenges faced by static symbolic execution.
in dse information obtained through dynamic analysis is used to aid symbolic execution.
the work presented in this paper proposes to do the opposite i.e.
use information gathered through symbolic execution to aid sbst.
iii.
s ymbolically enhanced fitness function the hypothesis underlying the research work presented in this paper assumes that incorporating information obtained from symbolic execution into the fitness function for branch coverage reduces the number of fitness evaluations required to cover a branch.
we call our approach fitness function enhancement because the information collected along a program path using symbolic execution is used in place of the traditional approach level and branch distance measures.
before the formal presentation of the fitness function enhancement algorithm we provide some initial intuition.
we propose to replace the branch distance measure introduced in section ii with a path distance measure.
assume an input follows the false branch at node in figure and that our target is the true branch of node .
we start by computing a path expression representing all paths from node to the target.
let this path expression be abc the edge labels a b c refer to the sub graph shown on the right in figure .
we then symbolically execute this path expression to obtain a set of partial path conditions.
in our example this set denotes a singleton of the form an bracketle tx y z x z an bracketri ht because there is only one path from node to the true branch of node .
next we apply the branch distance measure from section ii to each of the atomic conditions in the path condition i.e.
x y z x z and sum the results to form a path distance.
in case we have more than one path distance we choose the minimum for our fitness computation.
the intuition behind this choice is that the path condition with the smallest path distance is the closest to being satisfied by an input.
it may not always be possible to symbolically execute a path expression due to sources of uncertainty.
to account for this we introduce a second measure called the approximation level .
the approximation level will be defined as the number of conditions that cannot be added to a path condition and are thus not considered in the path distance.
for example a condition that uses variables whose definition originates from a statement inside a loop will be dropped.
this is because in general we do not know how often a loop is executed thus we also do not know the final value of the variables that are defined in a loop.
other sources of uncertainty can include variables defined through system calls to which we do not have access.
the next section will provide formal definitions of the approximation level andpath distance along with the algorithm for computing the enhanced fitness function eff .void foo int n int a int b int s if n for int i i n i s i if a n if s if b s target t fig.
.
illustrative c code involving a loop with nested if statements used to demonstrate the symbolically enhanced fitness function.
a. definitions letpbe the path expression representing all paths between a start node nand a target node t. this path expression may contain loops represented as terms of the form a .
for such terms we may opt for an arbitrary level of unrolling e.g.k times but we cannot handle unbounded potentially infinite unrollings.
as a consequence when the upper limit for the number of unrollings is reached we make the assumption that variables defined in any successive loop iterations are destroyed since in general we cannot determine the required number of loop iterations.
such variables will be represented by the term d .
the path expression involving loops i.e.
a can thus be expanded as a a a2 a3 ... akd by replacing a with a a a2 a3 ... akd in the path expression pwe obtain an approximated path expression p primewhich contains some destroy terms of the form d .
in the path condition produced by symbolic execution ofp prime we drop any clauses involving variables whose definition is inside a destroyed sub path.
such destroyed clauses are counted and their number defines the approximation level used in the fitness function.
path conditions built by dropping one or more conditions are said to be partial the others are said to be complete .
definition .
branch distance a quantification in the range of a boolean branch condition such that the value zero is obtained iff the condition evaluates to true.
values close to1indicate that the condition is far from being satisfied.
intermediate values should be such as to smoothly guide the search toward satisfying the condition.
definition .
path distance a quantification of the partial or complete path condition given by the sum of the branch distances computed for the conditions appearing as nondestroyed in the path condition for the approximated path expression.
it is zero when all conjuncts in the path condition evaluate to true.whenever we build a partial path condition we are dropping a number of conditions which involve data dependencies originating in a loop.
the number of dropped conditions is the approximation level.
definition .
approximation level the approximation level along a path is the number of conditions that are dropped from the path condition since they involve variables defined inside loops that are used in the condition.
an approximated path expression p primecan always be normalized into a sum of alternative paths.
in fact in p prime loops a are replaced by alternative k bounded loop iterations hence p prime contains only sequence multiplication and alternative sum operators which can be normalized into a sum of products by resorting to distribution of multiplication over sum.
definition .
fitness function let the normalized approximated path expression p primehave the form p1 p2 ... ph the fitness function efffor a node nis defined as effn m i n ff1 ff2 ... ffh where ff1 ff2 ... ffhare the fitness functions for the atomic paths in p prime each being computed as the sum of approximation level and path distance ffi approximation level path distance pi consider the example code in figure and assume our target is the true branch at node .
if an input traverses the false branch at node the path expression representing all paths from node to the target is a bc defg .
we may distinguish paths not entering the loop bc from paths which enter it one or more times i.e.
k .
the first case not entering the loop is described by the path expression adefg .
symbolically executing this path expression yields the following path condition an bracketle tn n a n s b s an bracketri ht.
the path described by this path condition is clearly infeasible because the conditions n 0and0 n are mutually exclusive.
hence we will not consider it any further.
the second case entering the loop one or more times can be described by the path expression abcd defg .
the term d indicates that all variable definitions occurring along the path bcare to be treated as unknown because the number of iterations for the loop bcis unknown it will be one or more .
for the example in figure two variables are defined inside the loop bc sandi.
since we do not know how often the loop will be executed we also do not know the final values ofsandiwhen we exit the loop.
therefore we drop any conditions obtained by symbolically executing the sub path following the term d that involve such variables i.e.
we do not add those conditions to the path condition.
the approximation level accounts for this by being incremented for each condition that is dropped.
completing our example symbolically executing the path expression abcd defg yields the path condition an bracketle tn n a n an bracketri ht.
since we dropped three conditions n s b s the approximation level is .
thus the approximation level allows us to distinguish an input reaching node and taking the false branch from an input taking the true branch at node and thus getting closer to the target.
note that the approximation level reaches 0once we reach node .
iv.
a lgorithm to compute symbolically enhanced fitness functions algorithm compute symbolically enhanced fitness functions input cfg control flow graph of the program under test t target edge to be covered output effn fitness function to be used by each test case reaching node n for each cfg node nholding a transitive control dependency on t for each cfg node n n nholds a transitive control dependency on tdo compute the sub graph subcfg nofcfg from ntot i.e.
the intersection between nodes edges forward reachable from nand nodes edges backward reachable from t apply the node reduction algorithm to determine the path expression pforsubcfg n compute the approximated path expression p primefrom pby approximating loops a in the path expression pasa a a2 a3 ... akd for some fixed value of k normalize the approximated path expression p primeinto a sum of products p prime p1 p2 ... ph for each path piin the normalized path expression p primedo perform a symbolic execution along pi keeping track of destroyed variables and annotating destroyed conditions as d the result is path condition pci turn the path condition pciinto a fitness function ffiby replacing conditions with branch distances and destroyed conditions with end for define the fitness function effnfor node nas effn min ff1 ff2 ... ffh end for algorithm shows the pseudo code for the computation of the enhanced fitness functions introduced in the previous section.
input to the algorithm is a program represented as its control flow graph cfg and a cfg edge tthat represents the current test target i.e.
the branch to be covered.
the output produced by the algorithm is a set of symbolically enhanced fitness functions one for each cfg node nthat holds a transitive control dependency on t. for each such node that is part of the execution trace of an input the corresponding fitness function is evaluated with the minimum value forming the overall fitness for that input.
for all nodes nthat hold a transitive control dependency on the target branch algorithm determines the path expression prepresenting all paths from nto the target t steps .
then loops are approximated typically as a ad and an approximated path expression p primeis computed and normalized into a sum of products steps .
for each normalized approximated path expression picomposing the path p prime symbolic execution is used to compute the corresponding path condition pci step .
whenever a destroyed sub pathis encountered during the symbolic execution all variables defined inside the sub path are collected among the destroyed variables.
successively added conditions which make use of destroyed variables are marked as destroyed conditions.
in step the path condition pciis converted into a fitness function forpiby replacing conditions with branch distances except for destroyed conditions which increase the approximation level by one.
the final fitness function for node nis the minimum among the fitness function values computed along the alternative paths appearing in the normalized approximated path expression.
it is important to note that we cannot use a constraint solver to provide a set of input values that satisfy a path condition pci.
this is because the path expression pinot always captures all execution paths from the entry node of a cfg to a target edge t. it is computed using only a sub graph of the entire cfg see step in algorithm i.e.the graph representing all execution paths between a critical branching node and t. consequently pcimay contain local variables rendering the use of a constraint solver infeasible.
v. e mpirical study the aim of the empirical study in this paper is to analyse the impact of using the enhanced fitness function in sbst.
the two research questions to be addressed by the study are as follows research question effect of effon branch coverage .
the level of branch coverage achieved i.e.
effectiveness of the testing technique is often the main focus when investigating an automated test data generation approach.
our proposed change in fitness function should not negatively affect the level of coverage achieved by a test data generation technique.
does this hypothesis hold?
research question effect of effon efficiency .
alongside coverage efficiency is also an important factor of any testing technique.
does the enhanced fitness function make sbst more efficient and if so what is the performance increase?
we selected two commonly used search algorithms for evaluation a form of hill climbing known as the alternating variable method a vm first introduced by korel and a genetic algorithm ga based on the approach described by wegener et al.
.
details of the two algorithms can be found in section v a and section v b respectively.
the search based testing framework iguana was extended to include the enhanced fitness function proposed in this paper and subsequently used to perform the test data searches.
the study was performed on branches drawn from five different c programs2 two of which were provided by daimler two are open source and one is the well studied triangle program.
the input domain for each function is composed of global variables and formal parameters.
we chose 2programs were chosen arbitrarily.
however all branches in the empirical study have been used to evaluate search based testing techniques in the past .
thus we considered them good candidates for evaluating a new fitness function for sbstnot to use any input domain reduction and defined the domain of each variable according to its declared type.
details of the subjects used in the empirical study can be found in table i. the programs f2and defroster are industrial case studies provided by daimler and represent production code for engine and rear window defroster control systems.
the code is machine generated from a design model of the desired behaviour.
to complement the industrial examples two opensource case studies were selected.
tiff .
.
is a library for manipulating images in the tag image file format tiff .
the functions tested comprise routines for placing images on pages and for building overview compressed sample images.
finally triangle is the well known triangle classification program often used as a benchmark program in automated test data generation studies.
each search for test data was performed 30times for every combination of fitness function and search algorithm.
if test data was not found to cover a branch after fitness evaluations the search was terminated.
serendipitous coverage i.e.
branches covered by accident during the test data generation process was ignored so that a distinct search was carried out for every branch.
the success or failure of each search was recorded along with the number of fitness evaluations required to find the test data.
from this the success rate of each branch can be calculated the percentage of the 30runs in which test data to execute the branch was found.
the 30runs were performed using an identical list of fixed seeds for random number generation so as to provide a basis for assessment with tests for statistical significance using a one sided paired wilcoxon signed rank test.
such tests are necessary to provide robust results in the presence of the inherently stochastic behaviour of the search algorithms.
to facilitate replication we will now discuss the configuration of the two search algorithms used in the study.
a. alternating variable method setup the a vm is a simple but effective optimization technique .
it is a form of hill climbing and works by continuously changing an input parameter to a function in isolation.
initially all arithmetic type inputs are initialized with random values.
then so called exploratory moves are made for each input in turn.
these consist of adding or subtracting a delta from the value of an input.
for integral types the delta starts off at i.e.
the smallest increment decrement .
when a change leads to an improved fitness value the search tries to accelerate towards an optimum by increasing the size of the neighbourhood move with every step.
these are known as pattern moves .
the formula used to calculate the delta added or subtracted from an input is 2it dir prec i where itis the repeat iteration of the current move for pattern moves direither 1or1 and prec ithe precision of the ithinput variable.
the precision applies to floating point variables only i.e.
it is 0for integral types .
it denotes a scale factor for the size of a neighbourhood move.
for example setting the precision prec i of an input to 1limits the smallest possible move to .
.
increasing the precision to 2limitstable i details of the test subjects .thelines of code column contains the ansic output of the sloccount tool used in its default setting and applied to the root source directory of each prog ram .
test lines of number of number of approximate domain subject function code branches loops size bibclean check isbn check issn defroster defroster main f2 f2 tiff .
.
tiff getsourcesamples tiff setsample placeimage triangle triangle total the smallest possible move to .
and so forth.
for all experiments carried out in this paper the precision for floating point variables was fixed at .
once no further improvements can be found for an input the search continues optimizing the next input parameter and may recommence with the first input if necessary.
in case the search stagnates i.e.
no move leads to an improvement the search restarts at another randomly chosen location in the search space.
this is known as a random restart strategy and is designed to overcome local optima and enable the a vm to explore a wider region of the input domain for the function under test.
b. genetic algorithm setup a ga is a global search algorithm first proposed by holland in the 1970s .
the configuration of the ga used in this paper is based on the approach described by wegener et al.
who used geatbx by hartmut pohlheim .
an overall population of 300individuals is divided into six competing sub populations which begin with 50individuals each.
each sub population evolves separately using selection recombination mutation and re insertion strategies.
after evaluation individuals in each sub population are sorted using a linear ranking method with a selection pressure of .
.
then individuals are selected for reproduction through stochastic universal sampling sus .
in sus the probability of an individual being selected is proportionate to its rank based fitness value.
selected individuals are recombined using a discrete recombination strategy whereby an offspring receives each gene from either parent with an equal probability.
after recombination offspring individuals are mutated according to the breeder genetic algorithm mutation strategy .
the mutation operator is applied with probability len where lenis the number of genes in an individual i.e.
the length of the input vector .
for each gene to be mutated a mutation range ri size dom iis defined where dom iis the domain size of the ithinput parameter and size is a mutation step size.
the mutation step size varies for each of the six sub populations and is defined as size popwith pop .
the mutated value of an input parameter can thus be computed as vi xi ri .
addition or subtraction is chosen with an equal probability and summationtext15 x 0 x x where xis1with a probability of1 16and0otherwise.
after mutation offspring are reinserted into a sub population using an elitist reinsertion strategy.
that is the top of the current generation is retained and the remaining individuals are replaced by fitter offspring.
a feature of the wegener model is that the six subpopulations of the ga compete with one another for the number of individuals each sub population evolves.
an average fitness value is computed for each sub population and this value is used to linearly rank the sub populations again using a selection pressure of .
.
the rank based fitness value rank of a sub population is then used to compute a progress value prog for the population in generation gusing the formula prog g .
prog g .
rank .
then after every four generations the populations are ranked according to their progress value prog and the size of each sub population is updated with weaker sub populations transferring individuals to stronger ones.
however no sub population can lose its last five individuals preventing it from dying out.
finally a general migration of individuals takes place after every 20th generation where sub populations randomly exchange of their individuals with one another.
c. results research question effect of effon branch coverage .
figure shows the coverage achieved by the a vm and the ga for each test subject.
a branch is counted as covered if the search for test data succeeded in at least one out of the thirty runs.
as can be seen using a symbolically enhanced fitness function does not negatively affect the level of branch coverage achieved by either local or global search.
instead thega is able to cover a branch that it previously failed to cover.
similarly the local search is able to cover more branches when using the enhanced fitness functions.
to gain a better understanding of how the proposed approach affects each search algorithm we also computed the success rate for each search target.
table ii lists the branches for which we observed a difference in success rate when using the enhanced fitness function.
the ga exhibits little variation.
for three branches the success rate is slightly reduced when using the enhanced fitness function.
however for five branches the success rate increases.
compared to the ga the enhanced fitness function has a bigger impact on the success rate of the a vm.
for branches where we observed a difference the trend is in an increase in success rate.
five branches stand out particularly because the a vm failed to find test data for these using the standard fitness function.
with the enhanced fitness function the search was able to find the required test data in all of the 30runs.
the effect of the enhanced fitness function is not always beneficial though for example branches in the function f2from daimler are covered with a reduced success rate.
this function is interesting because some ifstatements check if a subtraction operation on operands of type short int resulted in an over or underflow.
for example for one branch where the enhanced fitness function performed worse than the standard fitness function the path distance measure is computed using the path condition an bracketle tv11 v9 v11 v9 an bracketri ht.
the conjuncts of the path condition correspond to three nested ifstatements in the original code.
when the path distance is computed the first two conjuncts pull into the opposite direction of the last conjunct.
that is as the branch distance for the first two conjuncts converges towards the branch distance for the third conjunct increases until an overflow occurs.
the standard fitness function which optimizes each of the conjuncts in turn does not appear to suffer from this problem and is able to reliably find the required test data.
all cases where the enhanced fitness function did worse than the standard fitness function for f2were in code that checks for over or underflow errors.
research question effect of effon efficiency .
the results support the hypothesis that enhancing the fitness function with information gathered from symbolic execution can reduce the number of fitness evaluations required to cover a branch.
details of the average number of fitness evaluations required by each search technique are given in table iii.
the trend for the ga is to require fewer fitness evaluations with the enhanced fitness function.
this difference is particularly visible for three functions where we observed more than a reduction in fitness computations.
however there is again one case placeimage from tiff .
.
where we see a small increase in the number of fitness evaluations.
as with the success rates the a vm benefits more from the enhanced fitness function than the ga. four functions require fewer than of the fitness evaluations compared to the standard fitness function.
this is not surprising since all these functions contain branches for which the a vm failed to find0102030405060708090100branch coverage std.
ffenhanced ffbranch coverage with the genetic algorithm 0102030405060708090100branch coverage std.
ffenhanced ffbranch coverage with the alternating variable method fig.
.
this figure shows the branch coverage achieved by the genetic algorithm top and the alternating variable method bottom when using the standard and enhanced fitness functions.
the graphs confirm that symbolically enhanced fitness functions are equally or more effective than the standard fitness functions.
test data using the standard fitness function but for which it achieved a success rate using the enhanced fitness function.
conversely the a vm uses more fitness evaluations with the enhanced fitness function for f2 because branches are covered with a lower success rate and each failed search results in 000fitness evaluations.
to see if the differences in efficiency for the ga and the a vm are statistically significant we used the statistical tool r to perform a paired one sided wilcoxon signed rank test with continuity correction and specified an alpha level of0.
.
for both the ga and a vm we obtained a pvalue of2.
.
this pvalue indicates that the difference in the number of fitness evaluations required by each search algorithm is statistically significant p .
finally we also recorded the time taken to perform the upfront static analysis required by the enhanced fitness function.
to obtain a reasonable sample pool we repeated this analysis30times for each function.
the average analysis times alongside standard deviation are recorded in table iv.
loops often result in path explosion even when only a single loop unrolling is performed.
thus the analysis takes longer for functions containing one or more loops.
note that the symbolic analysis is performed once per function and can be re used by a search algorithm for all branches containedtable ii difference in success rates with the standard fitness function and the enhanced fitness function .branches are only listed if there is a difference for either the av m orga.
a success rate means a search algorithm was unable to cover a br anch in all of the 30repeat runs .a1 success rate means a search was able to find the required test d ata in each of the 30trials .
test subject a vm ga function branch id standard enhanced standard enhanced bibclean check issn 53t .
.
.
check issn 55t .
.
.
check issn 58t .
.
check issn 58f .
.
f2 f2 4t .
.
f2 15t .
.
f2 35t .
.
f2 43t .
.
.
.
tiff .
.
tiff getsourcesamples 14t .
.
tiff getsourcesamples 17t tiff getsourcesamples 20t .
.
tiff getsourcesamples 23t .
.
tiff getsourcesamples 26t .
.
tiff getsourcesamples 29t .
.
tiff getsourcesamples 32t .
.
tiff setsample 2t .
.
tiff setsample 5t .
.
tiff setsample 8t .
.
tiff setsample 11t .
.
tiff setsample 14t .
.
tiff setsample 17t .
.
tiff setsample 20t .
.
triangle triangle 14t triangle 15t .
.
triangle 15f .
.
triangle 17t triangle 17f .
.
triangle 19t .
.
triangle 21t .
.
table iii normalized average fitness evaluations required by the ga and av m using the standard and enhanced fitness functions .
test subject a vm ga function standard enhanced standard enhanced bibclean check isbn .
.
.
.
check issn .
.
.
.
defroster defroster main .
.
.
.
f2 f2 .
.
.
.
tiff .
.
tiff getsourcesamples .
.
.
.
tiff setsample .
.
.
.
placeimage .
.
.
.
triangle triangle .
.
.
.
table iv average time in milliseconds taken over 30trials to perform the up front static analysis required by the enhanced fitness function .the standard deviation is shown in the right most column .
test subject analysis time ms stddev function bibclean check isbn .
.
check issn .
.
defroster defroster main .
.
f2 f2 .
.
tiff .
.
tiff getsourcesamples .
.
tiff setsample .
.
placeimage .
.
triangle triangle .
.
within that function.
therefore compared to the overall execution time of the test data generation algorithms we consider the analysis times reported in this paper as acceptable.
future work might investigate how we can make the static analysis more efficient for example by re using symbolic information for nested branches.
vi.
t hreats to validity naturally there are threats to validity in any empirical study such as this.
the first issue to address is the threat to the internal validity of the experiments i.e.
whether there has been a bias in the experimental design that could affect the obtained results.
one potential source of bias comes from the configuration of the algorithms used in the test data generation tool iguana.
the settings for the ga and a vm were taken from previous studies that looked at generating branch adequate test data.
thus they have been shown in the past to provide a good trade off between effectiveness and efficiency.
another potential source of bias comes from the inherent stochastic behaviour of the meta heuristic search algorithms.
the most reliable and widely used technique for overcoming this source of variability is to perform statistical tests using a sufficiently large sample of result data.
in order to ensure a large sample size experiments were repeated times providing a reasonable pool of data from which to draw observations and ensuring sample means were normally distributed.
to show that the enhanced fitness function is more efficient than the standard fitness function used in sbst a test for a statistical significant difference in the sample means was performed.
we used a one sided paired wilcoxon signed rank test with the confidence level set at .
a further source of bias includes the selection of the functions used in the empirical study which could potentially affect its external validity i.e.
the extent to which it is possible to generalize from the results obtained.
the study draws upon code from real world programs both from industrialproduction code and from open source.
while we sampled a variety of programming styles and sources we only considered functions from five programs.
therefore caution is required before making any claims as to whether these results would be observed on other functions.
instead the results reported herein should only be seen to provide some initial intuition and a larger study is required to validate or refute our findings.
vii.
r elated work the present paper is the first to develop an amended form of symbolic execution for sbst.
previous work on developing symbolic execution as a practical means of improving automated testing focussed on constraint based testing techniques leading to the development of the very active field now known as dynamic symbolic execution dse .
this field began with the seminal work by godefroid et al.
on directed automated random testing dart which combined symbolic execution with random testing.
since then a number of authors have followed this approach which is sometimes referred to as concolic testing as well as dse .
dse and sbst have developed as separate schools of thought in automated software testing each with their own advantages and disadvantages.
the introduction of dynamic symbolic execution creates a significant step forward in the development of previous constraint based approaches to automated test data generation on which dse builds.
our introduction of partial symbolic execution as a means of augmenting sbst seeks to provide a similar impetus to sbst research.
like dse we augment an existing test automation technique with a form of symbolic execution and like dse we need to amend traditional symbolic execution to ameliorate its problems.
however dse performs a complete symbolic execution sometimes using concrete values in place of symbolic values whereas our approach does not use concrete values but retains the symbolic nature of symbolic execution.
rather than performing a complete symbolic execution we perform a localised or partial symbolic computation and use approximation to overcome the problems of static symbolic execution.
the first authors to propose a combination of sbst and dse were inkumsah and xie with the ev acon framework.
their framework targets test data generation for object oriented code written in ja v a and uses two existing tools etoc an evolutionary test data generation tool and jcute a dse tool.
method sequences putting the class containing the method under test into specific states are constructed by etoc.
then jcute is used to maximize code coverage of a given method sequence by generating values for the sequences input parameters.
the method sequences with optimized parameter values are then passed back to etoc for further optimization.
more recently lakhotia et al.
investigated a combination of sbst and dse in order to improve dse s ability to handle constraints over floating point variables.
their workintegrated the a vm also used in this paper and evolution strategies into pex a dse tool for .net.
lakhotia et al.
also proposed a combination of symbolic execution with search in order to improve sbst.
inspired by the work on cute they use symbolic execution to extend and improve the a vm for pointer inputs.
the work presented in this paper differs from all previous work in that it is the first to consider symbolic execution in order to improve a fitness function used in sbst.
a benefit of this approach lies in its generality it may be used with any search algorithm.
furthermore the enhanced fitness function does not require a constraint solver despite making use of symbolic execution techniques.
the path condition generated through symbolic execution is transformed into a fitness function to guide an optimisation algorithm.
this is an advantage when testing code that contains floating point computations or calls to system libraries.
viii.
c onclusion this paper has introduced and evaluated a symbolic searchbased software testing approach for the branch coverage test adequacy criterion.
we propose to replace the existing branch distance andapproach level measures with two new measures path distance andapproximation level .
the new metrics make use of information gathered from symbolic execution.
an empirical study performed on branches taken from a mix of open source and industrial programs confirmed our hypothesis that a symbolically enhanced fitness function can make search algorithms more efficient.
the proposed approach was evaluated with two commonly used algorithms in searchbased software testing the alternating variable method and a genetic algorithm.
the main goal of the enhanced fitness function is to make search based testing more efficient.
however it also enables the alternating variable method a form of hill climbing to cover branches for which the search failed using the traditional fitness function.
future work will investigate how symbolic search based testing can be further developed to not only improve efficiency but also effectiveness of a search algorithm.
acknowledgement arthur baars kiran lakhotia paolo tonella and tanja vos are funded through the european union project fittest ict2009.
.
no .
mark harman is supported by epsrc grants ep g060525 ep d050863 gr s93684 gr t22872 and also by the kind support of daimler berlin bms and vizuri ltd. london.
phil mcminn is supported in part by epsrc grants ep g009600 ep f065825 and ep i010386 .