understanding performance stairs elucidating heuristics bryan marker don batory and robert van de geijn department of computer science the university of texas at austin bamarker cs.utexas.edu batory cs.utexas.edu rvdg cs.utexas.edu abstract how do experts navigate the huge space of implementations for a given specification to find an efficient choice with minimal searching?
answer they use heuristics rules of thumb that are more street wisdom than scientific fact.
we provide a scientific justification for dense linear algebra dla heuristics by showing that only a few decisions out of many possible are critical to performance once these decisions are made the die is cast and only relatively minor performance improvements are possible.
the implementation performance space of dla is stair stepped.
each stair is a set of implementations with very similar performance and surprisingly share key design decision s .
high performance stairs align with heuristics that prescribe certain decisions in a particular context.
stairs also tell us how to tailor the search engine of a dla code generator to reduce the time it needs to find implementations that are as good or better than those crafted by experts.
categories and subject descriptors d. .
d. .
g. efficiency d. .
software engineering design tools and techniques computer aided software engineering general terms design performance.
keywords program generation dense linear algebra high performance software distributed memory computing model driven engineering .
introduction writing high performance software requires considerable skill.
in immature domains programmers not only have to know what to code but how to code they shoulder the burden of both application design and attaining high performance.
in mature domains standard application programming interfaces apis are used programmers code what they want in terms of permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
ase september vasteras sweden.
copyright is held by the owner author s .
publication rights licensed to acm.
acm ... .
.
apis while experts bear the burden of how to implement apis so that user applications run efficiently.
this separation of concerns has generally worked well it is the basis of modern software engineering tools called middleware.
the task of an expert is non trivial.
there may be hundreds or thousands of possible ways to implement each api operation.
an expert must at least intuitively be familiar with them all.
yet experts explore only a few possible ways using insights to navigate myriad prospects to find good if not optimal implementations quickly.
such insights are heuristics they are intuitive guides that experts learn over time.
why heuristics work is more street wisdom than scientific fact.
we found ourselves in a unique position to relate heuristics to scientific insight.
our research automates the development of dense linear algebra dla libraries libraries that are defined by standard apis and that are coded by experts per hardware architecture.
dla experts shoulder the burden of writing high performance library routines they must know how to code efficient algorithms how to customize algorithms for target architectures and how to navigate huge implementation spaces quickly to find the highestperforming algorithms.
we have automated the exploration of these spaces by generating all implementations using a methodical process and we evaluate the efficiency of each implementation via cost estimation.1this is how we find the best performing algorithm that experts would intuitively select .
in all tests generated code is the same or better than experts hand produced implementations.
we discovered that the space of implementation performance is not smooth but stair stepped each stair represents a set of implementations that perform approximately the same and surprisingly that share design decisions.
that is a few design decisions out of many possible are critical to performance.
once these decisions have been made the die is cast and only relatively minor performance improvements are subsequently possible the important decisions relate to algorithm selection and parallelization while the less important ones optimize data communication.
of course some stairs overlap where the performance difference between key decisions is minimal and secondary decisions rise to significance.
heuristics align with combinations of decisions that eliminate outright poor performing designs.
to exploit this observation requires design knowledge to be modularized by design decisions so that good decisions or decision combinations can be distinguished from bad decisions decision combinations .
we modularize such decisions in dla by transformations not code modules.
1runtimes can be quite long and require thousands of cores on expensive machines so empirical timing data is not viable to judge implementation efficiency.
estimates must be used.
in this paper we explain how tools can be built based on these ideas and show how to exploit the staired structure of an implementations performance space to reduce the number of implementations to explore.
for complicated algorithms with intractably large search spaces this reduces search time to less than an hour and the final code that it produces is as good as or better than that produced by an expert.
the main contributions of this paper are our explanation of how an expert effectively codes a highperformance algorithm without spending months exploring options.
we use two classes of transformations refinements and optimizations and now further classify refinements in two ways variant refinements and rephrasing refinements explained below so we can identify which dla design decisions are important.
we identified variant refinements and rephrasing refinements.
our evidence of how stairs of an implementation performance space can be exploited to effectively reduce the search for efficient implementations.
we conjecture that our findings are representative of other domains where our analysis and approach could be applied.
admittedly this will take more time to prove or disprove .
this paper presents a valuable data point in this quest the domain of dla.
we begin with a brief overview of how we generate the space of implementations for a given operation in the domain.
our approach is called design by transformation dxt more details are given in .
.
design by transformation consider the universe of dataflow applications.
each application is represented by a directed acyclic graph dag .
every node or boxdenotes an operation.
operation inputs and outputs are incoming and outgoing edges respectively.
operations can be either an interface or a primitive.
an interface has no implementation details other than a name inputs outputs preconditions and postconditions .
a primitive additionally has a given code implementation eg an api function call .
an expert starts with a dag that specifies a desired algorithm independent of implementation or hardware architecture specifics.
usually this dag contains only interfaces.
we encode design knowledge of how to implement interfaces using refinements.
a refinement is a transformation that replaces an interface with a graph with lower level interfaces or primitives implementing that interface.
it might use architecture specific operations or algorithms.
for example a refinement can encode how to parallelize an operation.
refinements are applied repeatedly until the graph contains only primitives.
this represents an implementation of the starting graph but not necessarily the most efficient implementation.
optimizations can yield higher performance.
an optimization is a transformation that replaces a subgraph with another subgraph that implements the same functionality but in a different way.
an expert generally applies a sequence of optimizations to improve performance.
dxter is our tool that automatically applies refinements and optimizations to a user specified graph.
it relies on a knowledge base of transformations that we have mined from re engineered dla code.
dxter applies all transformations that it can to form a space of all possible implementations of the starting graph.
it then rank orders these implementations using cost estimates.
each primitive which represents a function call has a cost estimate based on the data matrix sizes input to the node and the target hardware eg an estimate of cost to move data between cores .for distributed memory dla first order cost estimates are sufficient to enable an expert to judge trade offs between the cost of communicating data over a network and increasing parallelism that is enabled by that communication.
just as an expert estimates efficiency when manually coding dxter does so automatically by summing the estimated runtime of all nodes on a graph .
then the graph with the lowest estimated cost is converted to code and output by dxter.
.
big picture classical development of an algorithm starts with a specification s and through a series of design decisions which we represent as refinements and optimizations an algorithm a1is produced.
the derivation of a1is represented as a path from stoa1 figure a .
in general a large space of algorithms may exist for s. this space is encoded as a decision orderivation tree a tiny tree of three derivations is shown in figure a .
all of the derived algorithms a1 a17 a21 implement s but do so differently and have different performance.
it is the task of a domain expert to intuitively navigate this tree to find the best performing algorithm for a given situation.
s s a s b s a s b slower performance faster performance figure tree of algorithm derivations from a spec s. as derivation trees go figure a is as typical as it is misleading.
its arrows transformations suggest that all are of equal importance.
this is not the case certainly not for dla.
some arrows design decisions make a bigdifference in the ultimate runtime performance of an algorithm most arrows merely tweak performance up or down.
figure b more realistically emphasizes the importance of decisions with respect to performance.
the longer the arrow the more significant is its impact on performance.
the higher the algorithm s placement in figure b the slower it executes lower is better .
it is the responsibility of a domain expert to know intuitively the arrows decisions that are performance significant from those that are not.
this knowledge is rarely written down it is an art mastered by domain experts.
as we demonstrate throughout this paper in dla choices of how to parallelize operations ie refinements make a substantially greater impact on performance than subsequent optimizations.
note the trees of figure are specific for a particular context such as matrix size or architecture.
change the context algorithm a21may become the fastest.
by no means do the arrows of derivation trees have a fixed length or direction this extra dimension of context egwhat are the inputs to the operations whose algorithms are to be optimized significantly complicates the job of an expert and any generative tool.
suppose we could plot algorithms vsruntime on a graph.
points along the x axis are algorithms that are derived from spec s the y axis indicates algorithm runtime where lower faster is better.
by sorting algorithms on the x axis from poorest performing to best performing one would imagine a graph like figure a which has a smooth flowing curve the best algorithms are at the far right.
a runtime algorithm b runtime algorithm c algorithmruntime d algorithmruntime distinct stairs design decisionsfigure shapes of performance space.
but a plot of actual algorithm runtime pairs yields something quite different it is a discrete set of stairs as in figure b where each stair represents variations of a set of algorithms that share a major design decision eg a long arrow in figure b .
and like a fractal a single stair internally is a set of closely performing stairs as in figure c recursively representing the progressively smaller effects of less important design decisions.
distinct stairs can overlap as in figure d where fundamentally similar refinements compete for the best performance.
this is the shape of a performance space that experts intuitively navigate they use their intuition about the relationship between design decisions and the stair s whose algorithms they explore even though they may be completely unaware of the stair nature of their space.
as we are among the first to be able to generate a space of algorithms that implement a specification at least in dla we can now see the entire performance space of which experts could only glimpse a few points at a time.
this enables us to connect specific refinements to overall algorithm performance.
the following sections document concrete instances of these ideas in the domain of distributed memory dla.
.
dla and elemental background elemental is a distributed memory dla library with functionality similar to scalapack .
it includes implementations of common high level functionalities such as matrix factorization eigensolvers and solvers for systems of equations.
elemental also includes an api of primitives that are used to implement these high level functionalities.
in prior work we demonstrated how design knowledge for elemental is encoded in dxt.
we start with interfaces that represent sequential and architecture agnostic dla operations.
we encode elemental specific transformations that parallelize and optimize algorithms.
dxter explores the implementation space for each input graph a spec in the vernacular of section to generate a graph that