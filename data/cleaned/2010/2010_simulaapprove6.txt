an enhanced test case selection approach for model based testing an industrial case study hadi hemmatia b lionel brianda b andrea arcuria shaukat alia b a simula research laboratory b department of informatics university of oslo hemmati briand arcuri shaukat simula.no abstract in recent years model based testing mbt has attracted an increasingly wide interest from industry and academia .
mbt allows automatic generation of a large and comprehensive set of test cases from system models e.g.
state machines which leads to the systematic testing of the system.
however even when using simple test strategies applying mbt in large industrial systems often leads to generating large sets of test cases that cannot possibly be executed within time and cost constraints.
in this situation test case selection techniques are employed to select a subset from the entire test suite such that the selected subset conforms to available resources while maximizing fault detection.
in this paper we propose a new similarity based selection technique for state machine based test case selection which includes a new similarity function us ing triggers and guards on transitions of state machines and a genetic algorithm based selection algorithm.
applying this technique on an industrial case study we show that our proposed approach is more effective in detecting real faults than existing alternatives.
we also assess the overall benefits of model based test case selection in our case study by comparing the fault detection rate of the selected subset with the maximum possible fault detection rate of the original test suite.
categories and subje ct descriptors d. .
general terms experimentation and verification.
keywords test case selection model based testing similarity based selection genetic algorithms.
.
introduction model based testing mbt is getting increasing attention both in industry and academia as a test automation approach .
the idea is to generate executable test cases by systematically traversing specification models e.g.
represented as uml state machines based on a test strategy such as a coverage criterion that aims to cover certain features of the model e.g.
all transitions .
there are many academic and commercial mbt t ools and some studies report on the applicability and cost effectiveness of mbt .
unfortunately in practice more specifically at the integration and system levels mbt may lead to very large test suites even for simple coverage criteria.
we have observed cases leading to the generation of thousands of test cases for relatively modest industrial case studies with well known coverage criteria such as all transition pairs and all roundtrip paths .
therefore in many situations where deadlines are tight resources limited the testing cost is high due to the use of hardware in the loop or access to dedicated test infrastructures e.g.
network executing the entire test suite is not an option.
this is typically the case for many embedded and distributed systems.
for example system level testing of a video conferencing system requires establishing connections with other video conferencing systems over the network and streaming audio and video and communicating control data.
to test the software of such system we have to assign enough resources actual physical devices dedicated for the test to the test case which increases the cost of executing each test case compared to running a test case created for testing a local function on a pc.
in addition such test cases should properly handle acceptable delays in the system execution and the network communication which means that the execution time of each test case can be quite high in such systems.
the goal of selection techniques given limited resources leading to an estimated maximum test suite size is to maximize the fault detection rate of the selected subset.
in general this test case selection problem is np hard traditional set cover .
other than random selection there have been two main types of test case selection heuristics proposed in the literature.
the first class of techniques coverage based tries to directly maximize the coverage of the selected subset and the second type similarity based which has recently been getting more interest among researchers is about minimizing similarity where its definition varies on different studies between selected test cases and each selected subset of test cases contains test cases that are less simila r to each other .
in this paper we propose a new similarity based selection technique which is applied on test suites automatically generated from uml state machines.
the approach which does not require any execution information and is applied before executing any test case first improves the similarity function for model based test case selection introduced in by using triggers and guards on transitions of uml state machine as a basis of measuring similarity.
second it improves the selection algorithm by using genetic algorithms ga instead of a greedy search .
this work to the best of author s knowledge is the first to address similarity based test case selection for uml based testing.
the selection technique is integrated with a fully automated test case generation tool trust where the input s are uml state machines and output s are the selected executable test cases.
the context and objectives of industrial case study can be briefly characterized as follows our selection technique is applied to an industrial system where mbt was already used for test case generation there are no seeded faults and all faults are based on actual mistakes made by developers the size of the test suite is significantly larger than that of previous similar studies more than double of their largest test suite a comparison is performed not only with other similarity based techniques even those which are not specific to mbt but are applicable but also with all other well known selection techniques additional coverage based ga based coverage and random selection we provide a thorough discussion on cost analysis the improvement in terms of fault detection rate by our se lection technique is compared to using a stricter coverage criteri on and the practical benefits of using our test case selection technique for mbt is investigated by showing that our approach can select a small approximately subset of the automa tically generated test suite which can find more than of the faults detectable by the entire test suite.
the rest of the paper is organized as follows.
the next section reports on background information about test case selection.
section discusses t he basic principles regarding ga which are necessary to understand the paper.
section provides a brief overview of related works covering similarity based selection techniques.
section introduces our approach for test case selection in state machine based testing and section reports the experimentation results of applying the technique on a n industrial case study.
section concludes the paper and outlines our future work plan.
.
test case selection there are several strategies for reducing the num ber of automatically generated test cases in mbt.
one can try using a stricter coverage criterion i.e.
the criterion that results in fewer number of test cases .
for instance if using all transition pairs generates a far too large test suite the all transitions criterion can be adopted instead to decrease the number of test cases which still achieves systematic testing but may reduce the fault detection rate.
however often this is not a practical solution as one cannot ensure that the number of test cases will be below a required threshold.
test suite reduction can also be useful when the goal is to minimize the test suite by removing redundant test cases with respect to a criterion e.g.
code coverage .
in test case selection given a maximum number of test cases the goal is to select a subset of the entire test suite that maximizes fault detection.
prioritization techniq ues on the other hand do not remov e any test case but order their execution and therefore do not address our problem.
as a result we focus in this paper only on test case selection.
test case selection is mostly studied in the context of regression testing where the goal of test case selection is to find a subset of the original test suite that guarantee s the execution of fault revealing test cases .
the main difference s between model based test case selection and selection in the context of regression testing are that in our context we are not interested in finding the affected parts of the system and we do not have execution information of the test suite as it is the case in regression testing.
therefore heuristics such as using component meta data model differences and execution traces e.g.
call stack are not applicable here.
in addition most studies in test c ase selection even those which are general purpose and not specific to regression testing are based on code level information and do not directly apply to mbt e.g.
code based dependency analysis and additional statement coverage .
rather mbt selection heuristic s are based only on the characteristics of the abstract test cases.
there are three main classes of selection techniques which are introduced for mbt random or semi random selection where there is no guidance to select test cases .
coverage based selections where we hypothes ize that the test cases which have m ore coverage such as model based and requirement based coverage are more likely to detect faults .
the i dea is inspired from redundant test case removal in test case reduction where redundant test cases are those which have the same coverage.
note that a ssessing the coverage of a test case must not necessarily require its execution .
for example transition coverage in a state machine can be determined if traceability has been preserved between a test case and its source state machine.
most coveragebased techniques are re expressed into optimization problems where the goal is to select the best combination or permutation in case of prioritization of test cases to achieve full coverage .
for example in a greedy search selects at every step the test case that covers the most uncovered statements whereas in a ga is used to find the maximum coverage.
similarity based selections where we hypothes ize th at the more diverse the test cases the higher their fault revealing capacity .
to use this approach one needs a dis similarity function to measure the diversity of a subset by averaging all pair wise similarity values.
code based similarity functions have been proposed in the literature.
however to the bes t of authors knowledge there is only one model based similarity function denoted here as identical transitions similarity it .
for any two test paths tp i and tpj it tpi tpj is defined as the number of identical transitions which in uml state machines means same source states triggers and target states in tp i and tpj divided by the average length number of transitions in the test path of tp i and tpj .
after defining a similarity function a selection algorithm is required to choose a sample of test cases with the minimum pair wise similarity among its members.
.
genetic algorithm s for a given similarity measure several alternative selection techniques can be used such as optimization techniques g reedy search and clustering.
in this paper we use ga and compare it with greedy search which is the only reported similarity based test case selection algorithm to date in the context of state based testing and mbt in general as a baseline.
ga is used in this paper since the nature of our problem which is a form of optimization resembles typical problems addressed in search based software engineering where ga is the most used and successful reported technique .
a more comprehensive study of selection algorithms will be part of our future work.
though further details on how we have employed ga in a test case selection context will be discussed in section we provide below minimum backgr ound information on ga. ga rely on four basic features population selection crossover and mutation.
more than one solution is considered at the same time population .
at each generation i.e.
at each step of the algorithm some good solutions in the current population chosen by the selection mechanism generate offspring using the crossover operator.
this operator combines parts of the chromosomes i.e.
the solution representation of the offspring with a certain probability otherwise it just produce s copies of the parents.
these new offspring solutions will fill the population of the next generation.
the mutation operator is applied to make small changes in the chromosomes of the offspring.
to avoid the possible loss of good solutions a number of best solutions can be copied directly to the new generation without any modification.
another option is to use a steady state approach in which only the offspring that are not worse than their parents are added to the next generations.
fitter individuals should have more chances to survive and reproduce.
this is represented by the selection mechanism and there are several variants for it.
eventually after a number of generations an individual that solves the addressed problem will be evolved.
.
related wo rk in this section we only review studies on similarity based test case selection techniques since we have already discussed about alternative techniques and their limitations for our context in section .
although there exist studies regarding similarity based selection minimization and prioritization on code based testing model based test case selection using a similarity function has not been a focus of study in the literature.
however many ideas from code based selection can be adapted to mbt.
not surprisingly most similarity based techniques have been performed in the context of code based regression testing and use code coverage or other types of execution information.
in the similarity function is based on all def use pairs coverage and they use a classification algorithm as a selection technique where they classify similar test cases in one class and distribute their selection over different classes .
basic block coverage in the code e.g .
statement coverage is a basis for defining similarity function s in and .
greedy search adaptive random selection and clustering are used in these studies for selection.
in different heuristics are used based on execution information from the original test suite to support regression testing e.g.
memory operations with values from dynamic execution of a test case is used in a similarity function .
ledru et al.
have introduced a similarity based selection technique which can be applied on both code based and model based techniques since it is based on the test scripts and not the source code or a specification model .
the basic idea is to analyze the test script as a string and compare each pair of test cases as two strings using edit distance functions such as levenshtein .
in th e current paper we refer to this similarity function as string based similarity sb .
using this function ledru et al.
applied a g reedy search to select test cases.
the only similarity based test case selection technique in mbt is introduced in where s equences of transitions in a labeled transition system lts model of the software under test sut are used for representing test paths.
the similarity function is it as defined in section and the selection technique is a g reedy search.
this work and the work of ledru in can be considered as potential baselines of comparison for our study.
some empirical studies do not use basic random selection as a baseline of comparison.
however it is very important to at least compare any meta heuristic based technique with random selection to show that the improvement if any is worth the extra cost which is incurred when using such heuristics.
furthermore other studies do not have a comparison wi th coveragebased technique s which may be considered state of practice.
.
test case selection based on similarities between test paths using triggers and guards the problem of test ca se selection in our context can be formalized as given a test suite ts that detects a set of faults f in the system our goal is to maximiz e fd s n where sn is a subset of ts of size n and fd s n is the percent age of f which is detected by sn .
since there is no information about the fault detection rate of each test case without prior execution a surrogate measure for fd s n is required.
in similarity based selection techniques the assumption is that the more diverse the selected subset the larger the number of detected faults .
therefore the problem is reformulated as minimizing ssssssssssss ssnn ssssssssssss ssnn ssssssssssnnss ttttss ttttjj ttttss ttttjj ssnn ss jj where simfunc tpi tp j returns the similarity of two test paths abstract test cases in mbt in sn represented by tp i and tpj.
according to this definition we need to define a representation for a test path tp a similarity function simfunc and a selection algorithm to select the optimal s n. in mbt findi ng the best test case representation depends on the type of input model which in our case is a uml .
state machine.
a path on the model test path seems to be the best representation s ince it is both abstract enough to be used as a similarity function input and rich enough to contain all relevant state based testing information.
abstract t est cases in this notation called test path are sequences of state s and transitions identified by their corresponding trigger.
if a transition has k triggers it will be considered to be k transitions from the same source to the same target but with different triggers.
a test path can therefore be formalized as follows tp init trans trans event target event target trans event triggername guardvalue id guardvalue triggername where init and target are taken from the set of states and triggername and guradname from the set of triggers and guards on the transitions of the model and id is a unique id assigned to transitions which do not have any trigger or guard.
if a transition is guarded event contains guardvalue .
the similarity function that we use in this study is similar to it in with a minor but important difference.
because it is based on identical transitions they do not consider two transitions which have the same trigger same method call or same signal reception but different source or target state to be identical.
however our similarity measur e trigger based similarity tb is based on identical triggers.
according to this definition of identical triggers tb is defined as follows tb tpi tpj number of identical trigg ers in tpi and tpj divided by the average length number of transitions in the test path of tpi and tpj .
since identical triggers are more likely than identical transitions to be present in two test paths tb can be considered less strict than it in assigning similarity to test paths .
as a result tb might be more effective in cases where there are identical triggers in different transitions in the state machine which is a common situation .
tb tends to distinguish similarity among transitions in a more gradual fashion.
for e xample let us assume tp1 a b tp c b and tp d e where numbers are state identifiers and characters are trigger names and there is no guard .
note that tp3 is completely different than the two others no similarities except for the initial state .
though similarity based test case selection seek s to keep the selected test cases as diverse as possible it cannot detect any similarity between any pair of t est paths as there is no identical transitions among tp1 tp2 and tp3.
however tb tp1 tp2 .
since there is one identical trigger b and the average length of the two test paths is two .
therefore if we want to select two test paths out of the thr ee it selects randomly since all similarity values are zero but tb will choose one of tp or tp2 to discard thus achieving more diversity among remain ing test cases .
in this paper we use a steady state ga as a selection technique.
an individual i.e .
a solution to the problem is s n subset of ts with size n .
given a similarity function simfunc tpi tpj the fitness function f to minimize is the sum of simfunc tpi tpj for each pair of tp i tpj in ts ssssssssssss ssnn .
the selection mechanism is the rank selection with bias .
which has been shown to work well .
the populat ion size is fixed to .
we use a single point crossover to combine two different parents ssnnxx and ssnnyy.
a random position r such that r n is chosen.
all test paths in ssnnxx from position r and onward are swapped with the values in the same positions in ssnnyy.
crossover is applied with probability p xover .
in our experiment s with probability pxover the offspring are just be copies of their parents.
for example if ss41 and ss42 are two individuals of the population in iteration i and r there is a probability of .
that they will be replaced by ss41 and ss42 in iteration i where ss41 tttt1 tttt2 tttt3 tttt4 aannaa ss42 ttttaa ttttbb ttttss ttttaa ss41 tttt1 tttt2 ttttss ttttaa aannaa ss42 ttttaa ttttbb tttt3 tttt4 the selected mutation operator is similar to what is typically used for bit strings.
each test path in s n is mutated with probability n .
a mutated test path is replaced by a test path that is selected at random from the set of all possible test paths.
for example if ss4xx tttt1 tttt2 ttttss ttttaa and tttt5 ttss then ss4yy tttt1 tttt2 tttt5 ttttaa can be a mutated version of ss4xx.
the pseudo code of the employed ga is defined as follows sample a population g of m test cases uniformly from the search space i.e.
the set of all possible valid sets with a given size n repeat until the specified time is expired choose ss nnxx and ssnnyy from g ssnnxx ssnny crossover ssnnxx ssnnyy ppxxxxxxxxss mutate ssnnxx ssnny if valid ssnnxx ssnny min ff ssnnxx ff ssnny min f ssnnxx f ssnnyy then ssnnxx ssnnxx and ssnnyy ssnny notice that we only accept valid solutions.
a solution s n is valid if all the test paths in s n are unique.
the first randomly generated population is forced to contain only unique test paths.
however search operators such as crossover and mutation can produce new offspring that have repeated test paths in them.
there are several ways to handle constraints in evolutionary algorithms.
one way is to design search operators that always produce valid individuals.
in this paper we simply discard the offspring that are not valid.
the smaller the sample test suite size the lower the probability of such occurrences.
since we focus here on small samples of test cases this seems as a more suitable strategy in our context.
for example in our case study experiment s while sampling less than of the total test suite the probability of generating an invalid individual in one ga run is less than .
increasing the sample size to of the test suite increases this probability up to .
however even with a chance of invalid individual generation given the fixed short time for one run of the ga it is still more effective than its baseline of comparison greedy search in detecting faults.
note that this probability also depends on the stopping criterion since if we let the ga run longer the diversity in the ga population decreases which then results in less invalid individual s generated by the crossover operator .
we have applied three types of stopping criteria for ga in this study stopping after s pecific number of iterations stopping after a fixed period of time e.g.
1sec and letting the ga run for some time e.g.
1sec and then stop only if ther e is no improvement over a specified period of time e.g.
milliseconds .
.
empirical evaluation in this section we assess the effectiveness of the proposed approach by apply ing it on an industrial case study .
in addition we evaluate its fault detection rate referred below as fdr by comparing it to other alternatives already reported in the literature.
information about the case study is sanitized due to confidentiality restri ctions .
.
case study description the sut is a safety monitoring component in a safety critical control system implemented in c .
we chose this system because it exhibits a complex state based behavior that is modeled as uml state machines complemented by constraints specifying state invariants and guards which are useful to derive automated test oracles.
this sut is typical of a broad category of reactive systems interacting with sensors and actuators.
the first version of the system including models and code was developed and verified by company experts and our research team.
the faults used in the study were introduced during maintenance activities of subsequent versions of the sut by developers and re introduced for the purpose of the experiment in the latest version of the sut .
the correct and most up to date uml state machine representing the latest version of the sut s behavior consists of one orthogonal state with two regions.
enclosed in the first region are two simple states and two simple composite states.
the simplecomposite states contain two and three simple states.
the second region encloses one simple state an d four simple composite states that again consist of respectively two two two and three simple states.
this adds up to one orthogonal state simple states six simple composite states and a maximum hierarchy level of two.
the unflattened state machine contains transitions and the flattened state machine consists of simple states and transitions.
among the faults of them were sneak paths illegal transitions in the modified model .
to detect such faults the model should account for the behavior of the sut when receiving unexpected triggers .
such robustness behavior is not currently modeled and t herefore these faults could not be caught by any test case generated fr om the model.
the remaining faults detectable by the test cases generated from the model are collected and faulty version s of the code mutant programs are made by introducing one fault per program.
each of t hese faults belong s to one of the following categories wrong guards on transitions wrong state invariant missing transition and wrong onentry action of states.
the purpose was to study each real fault in isolation in order to avoid masking effects and compute fault detection scores .
since a test case stops executing after detecting the first failure in a program with multiple faults we should either rerun test cases on the sut after each bug fix or isolate faults by seeding one fault per mutant program .
we chose the latter case to avoid manual bug fixing after each run.
our approach should not be confused with mutation testing which makes use of mutation operators to create faults and then seed them in the sut one by one.
in our approach all faults were real faults as described above.
in the next step the correct uml state machine is given to our test case generation tool as an input model and executable test cases were automatically generated.
note that our selection technique is based on similarities between test paths abstract test cases without test data .
in general differen t faults can be detect ed by the same test path instantiated with different test data .
therefore it is necessary to run the selected test paths with different input data and compare the fdr distribution of the test paths selected by different techniques .
however in our case study if a test path has the ability to detect a fault it can be detected by any valid test data for that test path.
t herefore in our experiment we have one test case per test path and the fdr of a test path is equal to the fdr of the corresponding test case.
.
experiment design to evaluate our selection technique we formulated the following four research questions rq1.
which similarity measure is more effective for uml state machine based test case selection in terms of fdr ?
rq2.
is using ga for test case selection significantly more costeffective in terms of time spent to find a solution compared to a greedy search?
rq3.
are similarity based selection techniques more effective than coverage based and random selection techniques ?
rq4.
in the context of mbt what is the practical benefit of test case selection on a representative industrial case study when applying ga using our similarity measure tb ?
for the first three research questions the input test suite is generated by trust using all transitions coverage and in rq4 we will discuss about the effect of using other coverage criteria.
the test suite is made of test cases and can detect all detectable faults.
among test cases cannot detect any faults and c atch at least one fault.
the average number of detected faults per test case is .
and the maximum is five .
each fault is also detected on average by test cases.
there are nine faults which are only detected by three test cases and two faults are detectable by test cases.
to capture the randomness of fdr results which exists for all selection algorithms even in greedy search when it needs to select among test cases which have the same similarity measure we ran each experi ment times and report distribution statistics .
we report the results of different techniques for sample sizes less than of the test suite with intervals of since our focus is for practical reasons on smaller size subsets.
this is due t o the fact that in practice test case selection is mostly used for selecting a relatively small sample of the test suite .
furthermore for large sample sizes all selection techniques will usually be as good as random selection which typically detects most faults.
we have performed parametric t test and nonparametric mann whitney statistical tests with a significance level .
to compare the fdr means and medians of the proposed and alternative selection techniques.
due to space constraints we only report the result s of the non parametric test since it is more robust than the t test when there are strong departures from normality and since we have a large enough sample of observations .
in addition we provide fdr means and medians over di fferent runs for six sample sizes.
to compare effectiveness of different techniques we use three measures based on fdr .
these measures are complementary and help interpreting the fdr from different ang les ss is the number of faults detected by ssss a subset of size i selected by technique from the test suite ts with size n divided by the total number of detectable faults in ts in our case .
this measure is used in the paper wherever we want to simply report the fdr for a given technique and sample size.
since we run each test suite times on faulty programs we report the fdr means and variances.
aassaaaass .
enables the overall comparison of two selection techniques for a range of sample sizes.
aassaaaass which is inspired by the apfd measure for test case prioritization is adapted to test case selection in our context.
it is a measure for comparing curves and measures the sum of all ss for all sample sizes in the given inter vals and range to m .
more precisely it is equal to the area under the curve representing ss y axis over different sample sizes x axis .
since sample size has discrete values the area under the curve is calculated as aassaaaass ss ss ss ss ss where aassaaaass as we discussed in this paper we report the result of sample sizes less than of the test suite with intervals of therefore we always report aassaaaa14010 .
min k is the minimum number of test cases from the given test suite ts that are selected by technique to detect at least kk of the detectable faults.
this measure is more useful from a practical standpoint when selection techniques are compared with respect to their reduction in cost while ensuring a given fault detection rate.
to compare the cost of ga and greedy the execution time spent by the algorithms to select a subset is used as cost measure.
the experiments has been conducted on a pc with intel core tm duo cpu .
hz a nd gb memory running windows .
.
experiment results in the following subsections we investigate each of the research questions stated above.
.
.
which similarity measure is more effective for uml state machine based test case selection in terms of fdr ?
since there is no reported similarity based selection measure for uml state machines we need to tailor results from the most similar studies to obtain a baseline of comparisons.
sb by ledru et al.
in and it by cartaxo et al .
in are two potential similarity functions that we can adapt and apply on uml state machinebased test paths.
the measure it was straightforward to apply in our case using the representation of our test paths from section .
we identify each transition uniquely by a string composed of its source state trigger guard a nd target state.
states are identified by their name triggers by the name of the operation or signal reception and guards by their constraint.
this means that transitions can be considered identical only if the entire string is the same.
since sb is a ge neral purpose function it applies to the text of test scripts it requires some modifications to be useful for our case.
this was necessary since our executable test scripts are long and contain significant platform dependant information.
therefore comparing such test scripts as strings results in useless similarity measures which are significantly blurred by irrelevant information.
but we nevertheless decided to implement our adjusted version of sb for strings using abstract test scripts which in our c ase are the test paths defined in section .
therefore all elements of the test paths states triggers and guards constitute the alphabet of the strings to be compared.
we then applied levenshtein distance with standard parameters for match and for mismatch and gap on these strings.
we denote this technique as modified sb ms .
the main difference between ms and it is the fact that ms accounts for orders of states and triggers w ith or without guards in the paths whereas it only looks at the number of common transitions.
we also have introduced yet another measure using only state similarities identical state similarity is which is equal to the number of identical states in two test paths divided by their average number of states.
this measure is at the same level of detail as it but targeting different state related faults.
we compare ms is and tb with it as it is the only directly applicable solution from the literature for our models.
we use a greedy search since this is the technique used with it in the original study .
in short for all similarity measures our implementation of similarity based greedy search is exactly the same as in and works as follows in each step the algorithm finds the most similar pair o f test cases and removes the one which has less number of transitions from the test suite.
this will continue till the number of remaining test paths in the test suite becomes equal to the required sample size.
removing the shorter test path in the selected pair actually aims to keep transition coverage as high as possible while diversifying the subset.
in cases where there is more than one pair with maximum similarity value one of them is randomly chosen.
figure and figure show the fdr means of the g reedy search using tb is ms and it ss ttbbgr ss iissgr ss ssssgr and ss iittgr after running the algorithms times for sample sizes less than of the test suite .
in addition summarizes means and medians of ss for these techniques and reports the mann whitney test results highlighting cells in gray shade whe n there is a statistical difference between the selected comparison techniques and our proposed similarity measure tb.
the results show that tb and is have the highest and lowest fault detection rates respectively .
the reason that is is by far worse than the others can be explained by the fact that there ar e commonly several transitions per state and is simply ignore s differences between them as far as they have the same source or target states.
the results also show that it is more effective than sb for smaller sample sizes.
this means that even when string similarity measures e.g.
levenshtein use detailed path information e.g.
the order of states and triggers it may not be effective without careful tuning e.g.
gap and mismatch and therefore makes such an approach less practical.
since it is more effective than ms and is we now take it as a baseline of comparison with our proposal tb.
as it is shown in figure figure and table for sample sizes less than of the test suite ss ttbbgr is always higher than ss iittgr and after both techniques find all faults.
this difference between tb and it goes up to sample size and is also shown to be statistically significant.
an o verall comparison of the two curves also show s the improvement brought by tb aassaaaa14010 ttbbttss .
vs. aassaaaa14010 iittttss .
.
this shows that in practice our case study suggests it is likely better to use tb than it.
tbgr is also very effective with respect to finding most faults with fewer test cases min ttbb of the test suite vs. min iitt of the test suite .
although on average tb is always more effective than it looking at figure suggests that both techniques show a large variance for smaller sample sizes.
in practice this means that if the tester runs ou t of luck selecting a subset of test cases can lead to a very low fault detection.
in the next section we show how using ga can help increas e our confidence in tb by decreasing its variance.
figure .
the average fdr of tbgr itgr msgr isgr for different sample sizes .
table .
rq1 the median and mean fdr s per sample size to intervals of over runs and the mann whitney test results significant differences on me dians with tbgr highlighted as gray cells for different measures using greedy search .
selection technique fdr s per s ample size tbgr median .
.
.
mean .
.
.
.
.
.
.
itgr median .
.
.
.
.
.
.
.
mean .
.
.
.
.
.
.
.
.
isgr median .
.
.
.
.
.
.
.
.
.
mean .
.
.
.
.
.
.
.
.
.
msgr median .
.
.
.
.
.
.
mean .
.
.
.
.
.
.
.
table .
rq2 the median and mean fdr s per sample size to intervals of over runs and the mann whitney test results significant differences on medians with tbga 175ms highlight ed as gray cells for different selection techniques.
selection technique fdr per s ample size tbga 175ms median .
.
.
mean .
.
.
.
.
.
.
.
.
.
tbga ms median .
.
.
.
.
mean .
.
.
.
.
.
.
tbgr median .
.
.
mean .
.
.
.
.
.
.
itgr median .
.
.
.
.
.
.
.
mean .
.
.
.
.
.
.
.
.
cvgr median .
.
.
.
.
.
.
.
.
.
mean .
.
.
.
.
.
.
.
.
.
rnd median .
.
.
.
.
.
.
.
.
.
mean .
.
.
.
.
.
.
.
.
.
figure .
fdr y axis boxplots for different selection techniques x axis for sample sizes ranging from to by intervals of over .
the boxplots show the 10th 25th 50th 75th and 90th percentiles and means .
.
.
is using ga for test case selection significantly more cost effective in terms of time spent to find a solution compared to a greedy search?
before discussing about the cost effectiveness analysis between ga and greedy search it is worth mentioning that using an exhaustive search in our case and for most realistic cases is not an option since the search space size for selecting a subset of size n is equal to the number of possible n combinations within a test suite of a given size.
in our case as an example the search space size for n of the test suite is .
.
our implementation of greedy search does not have any parameter settings .
in this paper we do not tune ga instead we use the parameters based on our previous experience in using ga .
the only setting of ga that we will discuss here is the stopping criterion since it has direct effect on ga s cost and there is no obvious decision.
in this paper we only report the result taken from experiments with the fixed execution time stop ping criterion since we wanted to keep cost constant when compari ng fdr with greedy search.
cost here will be measured as execution time since this drives the applicability of a test strategy as discussed in section .
running greedy search times for sample sizes from to showed that it needs 175ms on average for each selection.
therefore we set the ga stopping criterion to 175ms to compare their fdr using constant execution time.
next we will increase execution time to a significantly larger but yet practical number 1000ms and investigate how much more effective ga can be.
note that greedy search cannot be improved even if one can afford running it for a longer period of time as opposed to ga which can potentially be improved within practical bounds .
using our proposed similarity measure tb we investigate the extent to which ga can improve fdr .
using execution times of 175ms as for greedy search figure and figure show fdr distributions for ga and greedy search using t b ss ttbbga and ss ttbbttss while running the algorithms times for each sample size from to of the test suite .
greedy always show s a lower fdr table shows that the differences are statistically significant than ga for sample sizes less than of the test suite with a maximum difference of sample size .
in practice for large test suites this is probably the most important part of the sample size range.
f or larger sample sizes an execution tie of 175ms does not seem to be enough for ga to be as effective as greedy search .
the main reason is that for larger sample size g a takes a great deal of time to generate an initial population with unique test paths and does not have enough time to generate many subsequent popula tions.
s till for the overall sample size range ga is more effective aassaaaa ttbbttss .
vs. aassaaaa14010 ttbbttaa .
.
to find of the faults both techniques need the same number of test cases min ttbbttaa min ttbbttss .
however the fdr variance for greedy search is significantly higher than that for ga figure especially for sample sizes less than of the test suite .
this mean s that although both techniques on average can find of the faults with test cases ga entails less r isk.
in practice people need to be confident in the results of a technique to use it.
they cannot rely on chance.
one selects only one subset and no one wants to incur the risk no matter how low the probability of missing most of the faults.
the inc rease in execution time for ga s stopping criterion sh ows that on average there is no practically significant fdr improvement aassaaaa14010 ttttssttaa .
for both 175ms and 1sec execution times .
in this case r unning ga for longer execution times does not seem to produce significantly better results.
an explanation could be within 175ms ga finds a near optimal solution in our case .
however increasing execution time helps decreas e the fdr variance and therefore decreases the risk involved in test selection .
another point is that ga needs less time for smaller sample sizes.
therefore ga running 175ms starts to perform slightly worse than ga running 1000ms for subsets larger than of the test suite as illustrated in figure sample sizes .
figure .
the average fdr of tbgr and tbga 175ms for different sample sizes.
.
.
are similarity based selection techniques more effective than coverage based and random selection techniques?
in this research question we are interested in the improvement that similarity based techniques can provide for model based test case selection when compared to simpler alternatives .
we compar e our proposal tbga with three different techniques random selection rnd as a baseline of comparison for any type of meta heuristic search additional coverage greedy selection cvgr and it gr as the state of the art for similarity based techniques .
we also have experimented with using ga for coverage based selection as it is defined in .
the results show that cvgr outperforms the ga coverage based technique in our case study as visible in figure .
therefore we compare with cvgr in this section .
all techniques are spending almost the same execution time for selecti on on average less than ms .
figure and figure show fdr for the different techniques ss ttbbga ss iittgr ss ccxxttss ss rnd wh en running the algorithms times for each sample size fr om to .
based on table for all sample sizes tbga 175ms is significantly more effective than the others .
as we can see that on average the fdr of tbga is significantly higher than that for rnd and cvgr for all sample sizes with maximum differences of rnd and cvgr .
the comparison over the entire sample size range also confirms this observation aassaaaa14010 aannaa .
aassaaaa14010 ccxxttss .
and aassaaaa14010 ttbbttaa .
.
the next best technique both in terms of ss and aassaaaass10 is itgr which shows that again a similarity based technique outperform s the coverage based and random selection.
tb ga is also very effective in finding more faults with less number of test cases.
for example tb ga 175ms can find of the faults with only test cases min ttbbttaa where both coverage based and random selection techniques cannot find of the faults even when using test cases .
another observation is that coverage based techniques are not much more effective than random selection.
figure .
the average fdr of rnd cvgr itgr tbga 175ms for different sample sizes .
.
in the context of mbt what is the practical benefit of test case selection on a representative industrial case study when applying tbga ?
in this sub section we look at a broader question which is about the usefulness of test case selection for reducing the size of the test suite generated by mbt tools which is the main motivation for this study.
we will answer rq4 by answering two subquestions rq4.
.
are test selection technique s more effective than using stricter coverage criteria?
rq4.
.
how effective is test selection in reducing the cost of testing in mbt?
as we discussed in section using a stricter criterion for example using all transitions instead of all transition pairs is an alternative to selection techniques.
if after using the least demanding criterion e.g.
all transitions the test suite is still too large then using criteria such as all l ength n where n is the maximum test path length can be used.
here we compare these alternatives with using a similarity based selection technique.
in our case n results in around test cases and n yields test cases .
since tb ga 1sec shows on average a fdr with test cases then a test suite of is obviously suboptimal .
comparing the result of l ength with tbga 175ms yields ttbbttaa .
whereas llxxnnlltth 2 .
.
this result confirm s our claim that stricter criteria cannot be a replacement for test selection techniques.
with respect to rq .
we are looking at the reduction of cost that a selection technique like tb ga can provide for a mbt testing strategy.
in our case the original test suite contains test cases.
for a one second execution time min ttbbttaa meaning that test cases are as effective same fdr as the entire test suite test cases entai ling a reduction in cost.
as we discussed earlier in distributed and embedded software systems as our case study system where test execution cost can be very significant this reduction is of practical importance.
.
.
discussion on validity threat s in this subsection we discuss the potential threats to the validity of the study using the framework discussed in about conducting empirical studies for search based testing.
construct v alidity for measuring test execution cost we used the actual time spent by different algorithms and running a ll algorithms on the same machine.
our effectiveness measure fdr is based on a set of real faults as explained earlier that we used to create mutant programs .
internal validity we implemented both greedy and ga algorithms and strived to achieve the same level of optimiz ation .
ga parameter tuning may have positive effect on its performance which we have not systematically carried out but greedy does not have any influential parameter.
this means that ga could possibly work better with some fine tuning.
regarding our implement ation of it since we had to adapt its definition to our context uml state machine and the encoding and representation of test paths it might be a potential threat and one c ould argue that it is possible to more effective ly implement it.
conclusion validity hundred independent runs were performed to account for random variation and obtain a sufficient number of observations to report means median s and standard deviation s. we used the t test and mann whitney test for in dependent samples to check the statistical differences in fdr across selection techniques but only reported the latter here for reasons explained earlier .
we also discussed about practical significance by looking at the magnitude of the differences between fdr and cost of different techniques.
external validity our results rely on one industrial case study using a given set of real faults .
though running such studies is very time consuming it is obviously required to replicate it as many times as possible.
however as discussed earlier the system used here is typical of a broad category of industrial systems control systems with state dependent behavior controlling sensors and actuators.
.
conclusions and future work in this paper we introduced a new technique for selecting test cases in the context of model based testing mbt more specifically uml state machine based testing.
our mot ivation is to make mbt scalable in situations where executing test cases satisfying a coverage criterion e.g.
all transitions is too expensive such as when there is hardware in the loop interacting external systems or test case executions are lengthy .
we propose a new similarity based test case selection technique which contains a similarity measure based on uml state machines triggers and guards on the transitions .
it uses a genetic algorithm ga as a selection mechanism in order to minimize similarity among test cases .
our results based on an industrial case study of a safety controller showed that our approach yields significantly better results than other altern atives such as random coverage based and other exis ting similarity based selecti on techniques .
we also have shown that our technique can significantly reduce the cost of test case execution in mbt by selecting of the test suite to be executed while retaining a fault detection rate .
in the future we plan to have a more exhau stive investigation of other possible similarity measures and selection techniques.
we will also investigate hybrid technique s which use both coverage and similarity measures for example using a multi objective ga. we will also conduct additional studies on other industrial system s to replicate the current study .
.