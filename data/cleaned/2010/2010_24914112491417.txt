practical static analysis of javascript applications in the presence of frameworks and libraries magnus madsen aarhus university denmarkbenjamin livshits microsoft research usamichael fanning microsoft corporation usa abstract javascript is a language that is widely used for both webbased and standalone applications such as those in the windows operating system.
analysis of javascript has long been known to be challenging due to the language s dynamic nature.
on top of that most javascript applications rely on large and complex libraries and frameworks often written in a combination of javascript and native code such as c and c .
stubs have been commonly employed as a partial speci cation mechanism to address the library problem alas they are tedious and error prone.
however the manner in which library code is used within applications often sheds light on what library apis return or pass into callbacks declared within the application.
in this paper we propose a technique which combines pointer analysis with a novel use analysis to handle many challenges posed by large javascript libraries.
our techniques have been implemented and empirically validated on a set of windows javascript applications averaging lines of code together with about lines of library code demonstrating a combination of scalability and precision.
categories and subject descriptors f. .
program analysis general terms algorithms languages keywords points to analysis use analysis javascript libraries .
introduction while javascript is increasingly used for both web and server side programming it is a challenging language for static analysis due to its highly dynamic nature.
recently much attention has been directed at handling the peculiar features of javascript in pointer analysis data ow analysis and type systems .
the majority of work thus far has largely ignored the fact that javascript programs usually execute in a rich execution environment.
indeed web applications run in a browserpermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
esec fse august saint petersburg russia copyright acm ... .
.based environment interacting with the page through the extensive html dom api or sophisticated libraries such as jquery.
similarly node jsapplications run inside an application server.
finally javascript applications in the windows os which are targets of the analysis in this paper call into the underlying os through the windows runtime.
in depth static analysis of these application hinges on our understanding of libraries and frameworks.
unfortunately environment libraries such as the html dom and the windows runtime lack a full javascript implementation relying on underlying c or c which is outside of what a javascript static analyzers can reason about.
popular libraries such as jquery have a javascript implementation but are hard to reason about due to their heavy use of re ective javascript features such as eval computed properties runtime addition of elds etc.
the standard solution to overcome these problems is to write partial javascript implementations also known as stubs to partially model library api functionality.
unfortunately writing stubs is tedious time consuming and error prone.
use analysis the key technical insight that motivates this paper is that observing uses of library functionality within application code can shed much light on the structure and functionality of unavailable library code.
by way of analogy observing the e ect on surrounding planets and stars can provide a way to estimate the mass of an invisible black hole.
this paper describes how to overcome the challenges described above using an inference approach that combines pointer analysis and use analysis to recover necessary information about the structure of objects returned from libraries and passed into callbacks declared within the application.
example we open with an example illustrating several of the challenges posed by libraries and how our technique can overcome these challenges.
the code below is representative of much dom manipulating code that we see in javascript applications.
var canvas document .
queryselector leftcol .
logo var context canvas .
getcontext 2d context .
fillrect c. width c. height context .
strokerect c.width c. height in this example the call to queryselector retrieves a canvas element represented at runtime by an htmlcanvaselement object the context variable points to acanvasrenderingcontext2d object at runtime.
context is then used for drawing both a lled and stroked rectangle on the canvas .
since these objects and functions are implemented as part of the browser api and html dom no javascript implementation that accurately represents thempermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse august saint petersburg russia copyright acm ... .
is readily available.
furthermore note that the return value of the queryselector call depends on the css expression provided as a string parameter which is di cult to reason about without an accurate model of the underlying html page.
there are two common approaches for attempting to analyze this code statically model queryselector as unsoundly returning a reference to htmlelement prototype .
this approach su ers from a simple problem htmlelement prototype does not de ne getcontext so this call will still be unresolved.
this is the approach used for auto completion suggestions in the eclipse ide.
model queryselector as returning any html element within the underlying page.
while this approach correctly includes the canvas element it su ers from returning elements on which getcontext is unde ned.
while previous work has focused on tracking elements based on their ids and types extending this to tracking css selector expressions is non trivial.
neither solution is really acceptable.
in contrast our analysis will use pointer information to resolve the call todocument queryselector and then apply use analysis to discover that the returned object must have at least three properties getcontext width and height assuming the program runs correctly.
looking through the static heap approximation only the htmlcanvaselement has all three properties.
assuming we have the whole program available for analysis this must be the object returned by queryselector .
from here on pointer analysis can resolve the remaining calls to fillrect and strokerect .
.
applications of the analysis the idea of combining pointer analysis and use analysis turns out to be powerful and useful in a variety of settings call graph discovery knowledge about the call graph is useful for a range of analysis tools.
unlike c or java in javascript call graphs are surprisingly di cult to construct.
reasons for this include re ection passing anonymous function closures around the program and lack of static typing combined with an ad hoc namespace creation discipline.
api surface discovery knowing the portion of an important library such as winrt utilized by an application is useful for determining the application s attack perimeter.
in aggregate running this analysis against many applications can provide general api use statistics for a library helpful for maintaining it e.g.
by identifying apis that are commonly used and which may therefore be undesirable to deprecate .
capability analysis the windows application model involves a manifest that requires capabilities such as camera access orgps location access to be statically declared.
however in practice because developers tend to over provision capabilities in the manifest static analysis is a useful tool for inferring capabilities that are actually needed .
automatic stub creation our analysis technique can create stubs from scratch or identify gaps in a given stub collection.
when aggregated across a range of application over time this leads to an enhanced library of stubs useful for analysis and documentation.
auto complete auto complete or code completion has traditionally been a challenge for javascript.
our analysismakes signi cant strides in the direction of better autocomplete without resorting to code execution.
throughout this paper our emphasis is on providing a practically useful analysis favoring practical utility even if it occasionally means sacri cing soundness.
we further explain the soundness trade o s in section .
.
contributions we make the following contributions we propose a strategy for analyzing javascript code in the presence of large complex libraries often implemented in other languages.
as a key technical contribution our analysis combines pointer analysis with a novel use analysis that captures how objects returned by and passed into libraries are used within application code without analyzing library code.
our analysis is declarative expressed as a collection of datalog inference rules allowing for easy maintenance porting and modi cation.
our techniques in this paper include partial andfulliterative analysis the former depending on the existence of stubs the latter analyzing the application without any stubs or library speci cations.
our analysis is useful for a variety of applications.
use analysis improves points to results thereby improving call graph resolution and enabling other important applications such as inferring structured object types interactive auto completion and api use discovery.
we experimentally evaluate our techniques based on a suite of windows javascript applications averaging line of code in combination with about lines of partial stubs.
when using our analysis for call graph resolution a highly non trivial task for javascript the median percentage of resolved calls sites increases from .
to .
with partial inference.
our analysis is immediately e ective in two practical settings.
first our analysis nds about twice as many winrt api calls compared to a na ve pattern based analysis.
second in our auto completion case study we out perform four major widely used javascript ides in terms of the quality of auto complete suggestions.
.
analysis challenges before we proceed further we summarize the challenges faced by any static analysis tool when trying to analyze javascript applications that depend on libraries.
.
whole program analysis whole program analysis in javascript has long been known to be problematic .
indeed libraries such as the browser api the html dom node jsand the windows api are all implemented in native languages such as c and c these implementations are therefore often simply unavailable to static analysis.
since no javascript implementation exists static analysis tool authors are often forced to create stubs.
this however brings in the issues of stub completeness as well as development costs.
finally javascript code frequently uses dynamic code loading requiring static analysis at runtime further complicating whole program analysis.
.
underlying libraries frameworks while analyzing code that relies on rich libraries has been recognized as a challenge for languages such as java javascript presents a set of unique issues.
complexity even if the application code is well behaved and amenable to analysis complex javascript applications frequently use libraries such as jquery and prototype.
while these are implemented in javascript they present their own challenges because of extensive use of re ection such as eval or computed property names.
recent work has made some progress towards understanding and handling eval but these approaches are still fairly limited and do not fully handle all the challenges inherent to large applications.
scale of libraries underlying libraries and frameworks are often very large.
in the case of windows applications they are around lines of code compared to for applications on average.
requiring them to be analyzed every time an application is subjected to analysis results in excessively long running times for the static analyzer.
.
tracking interprocedural flow points to analysis e ectively embeds an analysis of interprocedural data ow to model how data is copied across the program.
however properly modeling interprocedural data ow is a formidable task.
containers the use of arrays lists maps and other complex data structures frequently leads to con ated data ow in static analysis an example of this is when analysis is not able to statically di erentiate distinct indices of an array.
this problem is exacerbated in javascript because of excessive use of the dom which can be addressed both directly and through tree pointer traversal.
for instance document body is a direct lookup whereas document getelementsbyname body is an indirect lookup.
such indirect lookups present special challenges for static analyses because they require explicit tracking of the association between lookup keys and their values.
this problem quickly becomes unmanageable when css selector expressions are considered e.g.
the jquery selector function as this would require the static analysis to reason about the tree structure of the page.
re ective calls another typical challenge of analyzing javascript code stems from re ective calls into application code being invisible .
as a result callbacks within the application invoked re ectively will have no actuals linked to their formal parameters leading to variables within these callback functions having empty points to sets.
.
informal analysis assumptions here we informally state some analysis assumptions.
our analysis relies on property names to resolve values being either a returned by library functions or b passed as arguments to event handlers.
thus for our analysis to operate properly it is important that property names are static.
in other words we require that objects being passed to and from the library exhibit class like behavior properties are not dynamically added or removed after the object has been fully initialized.
the presence of a property does not rely on program controlow e.g.
the program should not conditionally add one property in a then branch while adding a di erent property in an else branch.
win8 application dom 45k objects builtin 1k objects winjs 1k objects winrt 13k objects figure structure of a windows javascript app.
name lines functions alloc.
sites fields builtin dom winjs windows api total figure approximate stub sizes for common libraries.
libraries should not overwrite properties of application objects or copy properties from one application object to another.
however the library is allowed to augment the global object with additional properties.
property names should not be computed dynamically i.e.
one should not use o instead of o pq .
.
soundness while soundness is a highly attractive goal for static analysis it is not one we are pursuing in this paper opting for practical utility on a range of applications that do not necessarily require soundness.
javascript is a complex language with a number of dynamic features that are di cult or impossible to handle fully statically and hard tounderstand semantic features .
the reader is further referred to the soundiness e ort .
we have considered several options before making the decision to forgo conservative analysis.
one approach is de ning language subsets to capture when analysis results are sound.
while this is a well known strategy we believe that following this path leads to unsatisfactory results.
first language restrictions are too strict for real programs dealing with di cult to analyze javascript language constructs such as with and eval and intricacies of the execution environment such as the function object etc.
while language restrictions have been used in the past these limitations generally only apply to small programs i.e.
google widgets which are mostly under lines of code .
when one is faced with bodies of code consisting of thousands of lines and containing complex libraries such as jquery most language restrictions are immediately violated.
second soundness assumptions are too di cult to understand and verify statically.
for example in ali et al.
merely explaining the soundness assumptions requires three pages of text.
it is not clear how to statically check these assumptions either not to mention so e ciently bringing the practical utility of such an approach into question.
.
overview the composition of a windows or win8 javascript application is illustrated in figure .
these are frequently complex applications that are not built in isolation in addition to resources such as images and html win8 applications depend on a range of javascript libraries for communicating with the dom both using the built in javascript dom api and rich libraries such as jquery and winjs an appli 501cation framework and collection of supporting apis used for windows html development as well as the underlying windows runtime.
to provide a sense of scale information about commonly used stub collections is shown in figure .
.
analysis overview the intuition for the work in this paper is that despite having incomplete information about this extensive library functionality we can still discern much from observing how developers use library code.
for example if there is a call whose base is a variable obtained from a library the variable must refer to a function for the call to succeed.
similarly if there is a load whose base is a variable returned from a library call the variable must refer to an object that has that property for the load to succeed.
example a summary of the connection between the concrete pointer analysis and use analysis described in this paper is graphically illustrated in figure .
in this example function process invokes functions mute and playsound depending on which button has been pressed.
both callees accept variable a an alias of a library de ned windows media audio as a parameter.
the arrows in the gure represent the ow of constraints.
points to analysis downward arrows ows facts from actuals to formals functions receive information about the arguments passed into them while the use analysis upward arrows works in the opposite direction owing demands on the shape of objects passed from formals to actuals.
speci cally the points to analysis ows variable a de ned inprocess to formals xandy.
within functions playsound andmute we discover that these formal arguments must have functions volume and mute de ned on them which ows back to the library object that variable amust point to.
so its shape must contain functions volume and mute.
use analysis the notion of use analysis above leads us to an inference technique which comes in two avors partial and full.
partial inference assumes that stubs for libraries are available.
stubs are not required to be complete implementations instead function bodies are frequently completely omitted leading to missing data ow.
what is required is that all objects functions and properties javascript term for elds exposed by the library are described in the stub.
partial inference solves the problem of missing ow between library and application code by linking together objects of matching shapes a process we call uni cation section .
.
full inference is similar to partial inference but goes further in that it does not depend on the existence of any stubs.
instead it attempts to infer library apis based on uses found in the application.
paradoxically full inference is often faster than partial inference as it does not need to analyze large collections of stubs which is also wasteful as a typical application only requires a small portion of them.
in the rest of this section we will build up the intuition for the analysis we formulate.
precise analysis details are found in section and the companion technical report .
library stubs stubs are commonly used for static analysis in a variety of languages starting from libc stubs for c programs to complex and numerous stubs for javascript built ins and dom functionality.
example here is an example of stubs from the winrt function playsound x x.volume ... function process button var a windows.media.audio if button mute mute a if button play playsound a ...a flows to parameter x function mute y y.mute audioprototype volume function mute function a flows to parameter y constraint x has function volume propagates to aconstraint y has function mute propagates to afigure points to owing facts downwards and use analysis owing data upwards.
library.
note that stub functions are empty.
windows .
storage .
stream .
fileoutputstream function windows .
storage .
stream .
fileoutputstream .
prototype writeasync function flushasync function close function this stub models the structure of the fileouputstream object and its prototype object.
it does not however capture the fact that writeasync and flushasync functions return anasyncresults object.
use analysis can however discover this if we consider the following code var s windows .
storage .
stream var fs new s. fileoutputstream ... fs.
writeasync ... .
then function ... we can observe from this that fs writeasync should return an object whose then is a function.
these facts allow us to unify the return result of writeasync with the promise jproto kobject the prototype of the promise object declared in the winjs library.
.
symbolic locations and unification abstract locations are typically used in program analyses such as a points to analysis to approximate objects allocated in the program at runtime.
we employ the allocation site abstraction as an approximation of runtime object allocation denoted by domain hin our analysis formulation .
in this paper we consider the partial and full inference scenarios.
it is useful to distinguish between abstract locations in the heap within the application denoted as ha and those within libraries denoted as hl .
additionally we maintain a set of symbolic locations hs these are necessary for reasoning about results returned by library calls.
in general both library and application abstract locations may be returned from such a call.
it is instructive to consider the connections between the variable vand heap hdomains.
figure 4a shows a connection between variables and the heap h ha hs hlin the context of partial inference.
figure 4b shows a similar connection between variables and the heap h ha hs in the context of full inference which lacks hl.
variables within the vdomain have points to links to heap elements in h helements are connected with points to links that have property names.
since at runtime actual objects502heap for partialhl hs ha variable domain f g heap for full hs ha variable domain f gfigure partial a above and full b below heaps.
are either allocated within the application ha or library code hl we need to unify symbolic locations hswith those in haandhl.
.
inference algorithm because of missing interprocedural ow a fundamental problem with building a practical and usable points to analysis is that sometimes variables do not have any abstract locations that they may point to.
of course with the exception of dead code or variables that only point to null undefined this is a static analysis artifact.
in the presence of libraries several distinct scenarios lead to dead returns when a library function stub lacks a return value dead arguments when a callback within the application is passed into a library and the library stub fails to properly invoke the callback dead loads when the base object reference receiver has no points to targets.
strategy our overall strategy is to create symbolic locations for all the scenarios above.
we implement an iterative algorithm.
at each iteration we run a points to analysis pass and then proceed to collect dead arguments returns and loads introducing symbol locations for each.
we then perform a uni cation step where symbolic locations are unied with abstract locations.
a detailed description of this process is given in section .
iterative solution an iterative process is required because we may discover new points to targets in the process of uni cation.
as the points to relation grows additional dead arguments returns or loads are generally discovered requiring further iterations.
iteration is terminated when we can no longer nd dead arguments dead returns or dead loads and no more uni cation is possible.
note that the only algorithmic change for full analysis is the need to create symbolic locations for dead loads.
we evaluate the iterative behavior experimentally in section .
uni cation strategies uni cation is the process of linking or matching symbolic locations with matching abstractnewobj v1 v h h v v object instantiation assign v1 v v v variable assignment load v1 v v v p p property load store v1 v p p v v property store formalarg f h z z v v formal argument formalret f h v v formal return actualarg c c z z v v actual argument actualret c c v v actual return callgraph c c f h indicates that fmay be invoked by a call site c pointsto v v h h indicates that vmay point toh heapptsto h1 h p p h h indicates that h1 spproperty may point to h2 prototype h1 h h h indicates that h1may have h2in its internal prototype chain figure datalog relations used for program representation and pointer analysis.
appalloc h h appvar v v represents that the allocation site or variable originates from the application and not the library specialproperty p p properties with special semantics or common properties such as prototype orlength prototypeobj h h indicates that the object is used as a prototype object figure additional datalog facts for use analysis.
locations.
in section .
we explore three strategies unify based on matching of a single property all properties and prototype based uni cation.
.
techniques we base our technique on pointer analysis and use analysis.
the pointer analysis is a relatively straightforward owand context insensitive subset based analysis described in guarnieri et al.
.
the analysis is eld sensitive meaning that it distinguishes properties of di erent abstract objects.
the call graph is constructed on they because javascript has higher order functions and so the points to and call graph relations are mutually dependent.
the use analysis is based on uni cation of symbolic and abstract locations based on property names.
.
pointer analysis the input program is represented as a set of facts in relations of xed arity and type summarized in figure and described below.
relations use the following domains heapallocated objects and functions h program variables v call sitesc properties p and integers z. the pointer analysis implementation is formulated declaratively using datalog as has been done in range of prior projects such as whaley et al.
for java and gatekeeper for javascript .
the javascript application is rst normalized and then converted into a set of facts.
these are combined with datalog analysis rules resolved using the microsoft z3 xpoint solver .
this is a relatively standard formulation more information about individual facts is given in the companion technical report .
rules for the andersen style inclusion based points to analysis are shown in figure 7a.
4pointsto v h newobj v h pointsto v1 h assign v1 v2 pointsto v2 h pointsto v2 h2 load v2 v1 p pointsto v1 h1 heapptsto h1 p h heapptsto h1 p h store v1 p v pointsto v1 h2 pointsto v2 h2 heapptsto h1 p h prototype h1 h2 heapptsto h2 p h prototype h1 h2 newobj h1 v pointsto v f heapptsto f prototype h3 callgraph c f actualarg c v pointsto v f assign v1 v2 callgraph c f formalarg f i v actualarg c i v z assign v2 v1 callgraph c f formalret f v1 actualret c v2 a inference rules for an inclusion based points to analysis expressed in datalog.
resolvedvariable v pointsto v prototypeobj h prototype h deadargument f i formalarg f i v resolvedvariable v appalloc f i deadreturn c v2 actualarg c v1 pointsto v1 f actualret c v2 resolvedvariable v2 appalloc f deadload h p load v1 v2 p pointsto v2 h hasproperty h p appvar v1 appvar v2 deadload h2 p load v1 v2 p pointsto v2 h1 prototype h1 h2 hasproperty h2 p symbolic h2 appvar v1 appvar v2 deadloaddynamic v1 h loaddynamic v1 v2 pointsto v2 h resolvedvariable v1 appvar v1 appvar v2 deadprototype h1 newobj h v pointsto v f symbolic f hassymbolicprototype h candidateobject h1 h2 deadload h1 p hasproperty h2 p symbolic h1 symbolic h2 hasdynamicprops h1 hasdynamicprops h2 specialproperty p candidateproto h1 h2 deadload h1 p hasproperty h2 p symbolic h1 symbolic h2 hasdynamicprops h1 hasdynamicprops h2 prototypeobj h2 nolocalmatch h1 h2 prototype h2 h3 8p deadload h1 p hasproperty h2 p 8p deadload h1 p hasproperty h3 p candidateproto h1 h2 candidateproto h1 h3 h26 h3 unifyproto h1 h2 nolocalmatch h1 h2 candidateproto h1 h2 8p deadload h1 p hasproperty h2 p foundprototypematch h unifyproto h unifyobject h1 h2 candidateobject h1 h2 foundprototypematch h1 8p deadload h1 p hasproperty h2 p b use analysis inference.
figure inference rules for both points to and use analysis.
.
extending with partial inference we now describe how the basic pointer analysis can be extended with use analysis in the form of partial inference .
in partial inference we assume the existence of stubs that describe all objects functions and properties.
function implementations as stated before may be omitted.
the purpose of partial inference is to recover missing ow due to missing implementations.
flow may be missing in three di erent places arguments return values and loads.
deadload h h p p where his an abstract location andpis a property name.
records that property pis accessed from h but hlacks a pproperty.
we capture this with the rule deadload h p load v1 v2 p pointsto v2 h hasproperty h p appvar v1 appvar v2 here the pointsto v2 h constraint ensures that the base object is resolved.
the two appvar constraints ensure that the load actually occurs in the application code and not the library code.
deadargument f h i z where fis a function and iis an argument index.
records that the i th argument has novalue.
we capture this with the rule deadargument f i formalarg f i v resolvedvariable v appalloc f i here the appalloc constraint ensures that the argument occurs in a function within the application code and not in the library code argument counting starts at .
deadreturn c c v v where cis a call site and vis the result value.
records that the return value for call site chas no value.
deadreturn c v2 actualarg i v1 pointsto v1 f actualret i v2 resolvedvariable v2 appalloc f here the pointsto v1 f constraint ensures that the call site has call targets.
the appalloc f constraint ensures that the function called is not an application function but either a a library function or b a symbolic location.
we use these relations to introduce symbolic locations into pointsto heapptsto and prototype as shown in figure .
in particular for every dead load dead argument and dead return we introduce a fresh symbolic location.
we restrict the introduction of dead loads by requiring that the504inference constraints facts isfull 1relations solve constraints constraints facts 2repeat newfacts make symbols relations isfull facts facts newfacts relations solve constraints constraints facts 6until newfacts make symbols relations isfull 1facts 2for h p 2relations deadload h p if symbolic h or isfull facts newheapptsto h p newh 5for f i 2relations deadargument h z v formalarg facts newpointsto v newh 8for c v 2relations deadreturn c v facts newpointsto v newh uni cation 11forh2relations deadprototype h facts newprototype h newh 13for h1 h2 2relations unifyproto h h facts newprototype h1 h2 15for h1 h2 2relations unifyobject h h for h3 p h 2relations heapptsto h p h facts newheapptsto h3 p h 18return facts figure iterative inference algorithms.
base object is not a symbolic object unless we are operating in full inference mode.
this means that every load must be uni ed with an abstract object before we consider further uni cation for properties on that object.
in full inference we have to drop this restriction because not all objects are known to the analysis.
.
unification uni cation is the process of linking or matching symbolic locations swith matching abstract locations l. the simplest form of uni cation is to do no uni cation at all.
in this case no actual ow is recovered in the application.
below we explore uni cation strategies based on property names.
9shared properties the obvious choice here is to link objects which share at least one property.
unfortunately with this strategy most objects quickly become linked.
especially problematic are properties with common names such aslength ortostring as all objects have these properties.
8shared properties we can improve upon this strategy by requiring that the linked object must have allproperties of the symbolic object.
this drastically cuts down the amount of uni cation but because the shape of sis an overapproximation requiring all properties to be present may link to too few objects introducing unsoundness.
it can also introduce imprecision if we have swith function trim we will unify sto all string constants in the program.
the following rule candidateobject h1 h2 deadload h1 p hasproperty h2 p symbolic h1 symbolic h2 hasdynamicprops h1 hasdynamicprops h2 specialproperty p expresses which symbolic and abstract locations h1andh2 arecandidates for uni cation.
first we require that the symbolic and abstract location share at least one property.
second we require that neither the symbolic nor the abstract object have dynamic properties.
third we disallow commonly used properties such as prototype and length as evidence for uni cation.
the relation below captures when two locations h1andh2are uni ed unifyobject h1 h2 candidateobject h1 h2 8p deadload h1 p hasproperty h2 p this states that h1andh2must be candidates for uni cation and that if a property pis accessed from h1then that property must be present on h2.
ifh1andh2are uni ed then theheapptsto relation is extended such that any place where h1may occur h2may now also occur.
prototype based uni cation instead of attempting to unify with all possible abstract locations l an often better strategy is to only unify with those that serve as prototype objects.
such objects are used in a two step uni cation procedure rst we see if all properties of a symbolic object can be satis ed by a prototype object if so we unify them and stop the procedure.
if not we consider all non prototype objects.
we take the prototype hierarchy into consideration by unifying with the most precise prototype object.
our tr discusses the issue of selecting the most precise object in the prototype hierarchy .
.
extending with full inference as shown in the pseudo code in figure we can extend the analysis to support full inference with a simple change.
recall in full inference we do not assume the existence of any stubs and the application is analyzed completely by itself.
we implement this by dropping the restriction that symbolic locations are only introduced for non symbolic locations.
instead we will allow a property of a symbolic location to point to another symbolic location.
introducing these symbolic locations will resolve a load and in so potentially resolve the base of another load.
this in turn may cause another dead load to appear for that base object.
in this way the algorithm can be viewed as a frontier expansion along the known base objects.
at each iteration the frontier is expanded by one level.
this process cannot go on forever as there is only a xed number of loads and thereby dead loads and at each iteration at least one dead load is resolved.
.
experimental ev aluation .
experimental setup we have implemented both the partial and fullinference techniques described in this paper.
our tool is split into a front end written in c and a back end which uses analysis rules encoded in datalog as shown in section .
the frontend parses javascript application les and library stubs and generates input facts from them.
the back end iteratively executes the z3 datalog engine to solve these constraints and generate new symbolic facts as detailed in section .
all times are reported for a windows machine with a xeon 64bit core cpu at .
ghz with gb of ram.
we evaluate our tool on a set of javascript applications obtained from the windows application store.
to provide505alloc.
call lines functions sites sites properties variables figure benchmarks sorted by lines of code.
a sense of scale figure shows line numbers and sizes of the abstract domains for these applications.
it is important to note the disparity in application size compared to library stub size presented in figure .
in fact the average application has lines of code compared to almost lines of library stubs with similar discrepancies in terms of the number of allocation sites variables etc.
partial analysis takes these sizable stubs into account.
.
call graph resolution we start by examining call graph resolution.
as a baseline measurement we use the standard pointer analysis provided with stubs without use analysis.
figure shows a histogram of resolved call sites for baseline and partial inference across our applications.
we see that the resolution for baseline is often poor with many applications having less than of call sites resolved.
for partial inference the situation is much improved with most applications having number of applications baseline number of applications partial inference figure percentage of resolved call sites for baseline points to without stubs and partial inference.
partial full points to na vefigure resolving winrt api calls.
over call sites resolved.
this conclusively demonstrates that the uni cation approach is e ective in recovering previously missing ow.
full inference as expected has of call sites resolved.
note that the leftmost two bars for partial inference are outliers corresponding to a single application each.
.
case study winrt api resolution we have applied analysis techniques described in this paper to the task of resolving calls to winrt api in windows javascript applications.
winrt functions serve as an interface to system calls within the windows os.
consequently this is a key analysis to perform as it can be used to compute an application s actual as compared to declared capabilities.
this information can identify applications that are over privileged and which might therefore be vulnerable to injection attacks or otherwise provide a basis for authoring malware.
the analysis can also be used for triaging applications for further validation and testing.
figures in the text show aggregate statistics across all benchmarks whereas figure represents the results of our analysis across applications those that are largest in our set.
to provide a point of comparison we implemented a na vegrep like analysis by means of a javascript language parser which attempts to detect api use merely by extracting fully quali ed identi er names used for method calls property loads etc.
technique apis used na ve analysis points to points to partial points to full 320as expected we observe that the na ve analysis is very incomplete in terms of identifying winrt usage.
the base points to analysis provides a noticeable improvement in results but is still very incomplete as compared to the full and partial techniques.
partial and full analysis are generally comparable in terms of recall with the following di erences allanalysis approaches are superior to na ve analysis.
the number of api uses found by partial and full is roughly comparable.
results appearing only in full analysis often indicate missing information in the stubs.
partial analysis is e ective at generating good results given fairly minimal observed in application use when coupled with accurate stubs.
as observed previously common property names lead to analysis imprecision for partial analysis.
we highlight several examples that come from further examining analysis results.
observing the following call5060.
.
.
.
.
169seconds benchmarks lines of code partial fullfigure running times in seconds.
gray is partial inference.
black is full inference.
sorted by lines of code.
driveutil .
uploadfilesasync server .
imagesfolderid .
then function results ... leads the analysis to correctly map then to the winjs promise prototype then function.
a load like var json windows .
storage .
applicationdata .
current .
localsettings .
values correctly resolves localsettings to an instance of windows storage applicationdatacontainer .
partial analysis is able to match results without many observed uses.
for instance the call x.getfolderasync backgrounds is correctly resolved to getfolderasync on object windows storage storagefolder prototype .
.
case study auto complete we show how our technique improves auto completion by comparing it to four popular javascript ides eclipse indigo sr2 for javascript developers intellij idea visual studio and visual studio .
figure shows ve small javascript programs designed to demonstrate the power of our analysis.
the symbol indicates the placement of the cursor when the user asks for autocompletion suggestions.
for each ide we show whether it gives the correct suggestion x and how many suggestions it presents these tests have been designed to have a single correct completion.
we illustrate the bene ts of both partial and full inference by considering two scenarios.
for snippets stubs for the html dom and browser apis are available so we use partial inference.
for windows application snippets no stubs are available so we use full inference.
for all snippets our technique is able to nd the right suggestion without giving any spurious suggestions.
we further believe our analysis to be incrementalizable because of its iterative nature allowing for fast incremental auto complete suggestion updates.
.
analysis running time figure shows the running times for partial and full inference.
both full and partial analysis running times are quite modest with full usually nishing under seconds on large applications.
this is largely due to the fast z3 datalog engine.
as detailed in our technical report full inference requires approximately two to three times as many iterations as partial inference.
this happens because the full inference algorithm has to discover the namespaces starting from the global object whereas for partial inference namespaces are known from the stubs.
despite the extra iterations full in ference is approximately two to four times faster than partial inference.
.
examining result precision soundness app ok incomplete unsound unknown stubs total app1 app2 app3 app4 app5 app6 app7 app8 app9 app10 total 200we have manually inspected call sites twelve resolved ve polymorphic and three unresolved in randomly picked benchmark apps to estimate the precision and unsoundness of our analysis this process took about two hours.
figure to the right provides results of our examination.
here ok is the number of call sites which are both sound and complete i.e.
their approximated call targets match the actual call targets incomplete is the number of call sites which are sound but have some spurious targets i.e.
imprecision is present unsound is the number of call sites for which some call targets are missing i.e.
the set of targets is too small unknown is the number of call sites for which we were unable to determine whether it was sound or complete due to code complexity stubs is the number of call sites which were unresolved due to missing or faulty stubs.
out of the inspected call sites we nd sites which were unsoundly resolved i.e.
true call targets were missing.
of these three were caused by json data being parsed and the fourth was caused by a type coercion which is not handled by our implementation.
here is an example unsoundness related to json json .
parse str .x.
split remember that use analysis has no knowledge of the structure of json data.
thus in the above code use analysis can see that the returned object should have property x however it cannot nd any objects application or library with this property thus it cannot unify the return value.
furthermore we found that for call sites the analysis had some form of imprecision i.e.
more call targets than could actually be executed at runtime .
we found two reasons for this property names may be shared between different objects and thus if use analysis discovers a property read like x slice and has no further information about x it soundly concludes that xcould be an array or a string as both has the x slice function.
we observed similar behavior foraddeventlistener queryselector and appendchild all frequently occurring names in html dom we found several errors in existing stubs for instance doubledeclarations like winjs .ui.
listview function winjs .ui.
listview as an example of imprecision consider the code below var encodedname url.
slice url.
lastindexof here urlis an argument passed into a callback.
in this case use analysis knows that urlmust have property slice however both arrays and strings have this property so use analysis infers that urlcould be either an array or a string.
in reality urlis a string.507eclipse intellij vs vs category code x x x x partial inference 1dom loopvar c document getelementbyid canvas var ctx c getcontext 2d var h c height var w c w7 0x x 2callbackvar p ffirstname john lastname doe g function compare p1 p2 f var c p1 firstname p2 firstname if c!
return c return p1 last g7 0x 7x?k 3local storagevar p1 ffirstname john lastname doe g localstorage putitem person p1 var p2 localstorage getitem person document writeln mr p2 lastname p2 f 0x full inference 4namespacewinjs namespace define game audio play function fg volume function fg game audio volume game audio p7 0x 1x?k 5pathsvar d new windows ui popups messagedialog var m new windows ui 7x?k figure auto complete comparison.
?means that inference uses all identi ers in the program.
marks the autocomplete point the point where the developer presses ctrl space or a similar key stroke to trigger auto completion.
.
related work pointer analysis and call graph construction declarative points to analysis explored in this paper has long been subject of research .
in this paper our focus is on call graph inference through points to which generally leads to more accurate results compared to more traditional type based techniques .
ali et al.
examine the problem of application only call graph construction for the java language.
their work relies on the separate compilation assumption which allows them to reason soundly about application code without analyzing library code except for inspecting library types.
while the spirit of their work is similar to ours the separate compilation assumption does not apply to javascript resulting in substantial di erences between our techniques.
static analysis of javascript a project by chugh et al.
focuses on staged analysis of javascript and nding information ow violations in client side code .
chugh et al.
focus on information ow properties such as reading document cookies and url redirects.
a valuable feature of that work is its support for dynamically loaded and generated javascript in the context of what is generally thought of as whole program analysis.
the gatekeeper project proposes a points to analysis together with a range of queries for security and reliability as well as support for incremental code loading.
sridharan et al.
presents a technique for tracking correlations between dynamically computed property names in javascript programs.
their technique allows them to reason precisely about properties that are copied from one object to another as is often the case in libraries such as jquery.
their technique only applies to libraries written in javascript so stubs for the dom and windows apis are still needed.
schafer et al.
study the issue of auto completion for javascript in much more detail than we do in section and propose a solution to javascript autocompletion within ides using a combination of static and runtime techniques .
type systems for javascript researchers have noticed that a more useful type system in javascript could preventerrors or safety violations.
since javascript does not have a rich type system to begin with the work here is devising a correct type system for javascript and then building on the proposed type system.
soft typing might be one of the more logical rst steps in a type system for javascript.
much like dynamic rewriters insert code that must be executed to ensure safety soft typing must insert runtime checks to ensure type safety.
several project focus on type systems for javascript .
these projects focus on a subset of javascript and provide sound type systems and semantics for their restricted subsets.
as far as we can tell none of these approaches have been applied to large bodies of code.
in contrast we use pointer analysis for reasoning about large javascript programs.
the type analysis for javascript tajs project implements a data ow analysis that is object sensitive and uses the recency abstraction.
the authors extend the analysis with a model of the html dom and browser apis including a complete model of the html elements and event handlers .
.
conclusions this paper presents an approach that combines traditional pointer analysis and a novel use analysis to analyze large and complex javascript applications.
we experimentally evaluate our techniques based on a suite of windows javascript applications averaging lines of code in combination with about lines of stubs each.
the median percentage of resolved calls sites goes from .
to .
with partial inference to with full inference.
full analysis generally completes in less than seconds and partial in less than seconds.
we demonstrated that our analysis is immediately e ective in two practical settings in the context of analyzing windows applications both full and partial nd about twice as many winrt api calls compared to a na ve pattern based analysis in our auto completion case study we out perform four major widely used javascript ides in terms of the quality of autocomplete suggestions.
.