green streams for data intensive software thomas w. bartenstein and yu david liu suny binghamton binghamton ny13902 usa ftbarten1 davidlg binghamton.edu abstract this paper introduces g reen streams a novel solution to address a critical but often overlooked property of data intensive software energy efficiency.
g reen streams is built around two key insights into data intensive software.
first energy consumption of data intensive software is strongly correlated to data volume and data processing both of which are naturally abstracted in the stream programming paradigm second energy efficiency can be improved if the data processing components of a stream program coordinate in a balanced way much like an assembly line that runs most efficiently when participating workers coordinate their pace.
g reen streams adopts a standard stream programming model and applies dynamic voltage and frequency scaling dvfs to coordinate the pace of data processing among components ultimately achieving energy efficiency without degrading performance in a parallel processing environment.
at the core of g reen streams is a novel constraint based inference to abstract the intrinsic relationships of data flow rates inside a stream program which uses linear programming to minimize the frequencies hence the energy consumption for processing components while still maintaining the maximum output data flow rate.
the core algorithm of g reen streams is formalized and its optimality is established.
the effectiveness of g reen streams is evaluated on top of the streamit framework and preliminary results show the approach can save cpu energy by an average of with a performance improvement.
i. i ntroduction from megabyte scale youtube apps on smart phones to gigabyte scale netflix applications on laptops and to terabytescale nasa scientific computations on servers dataintensive software is quickly becoming the new norm of modern computing.
software engineering for big data is an active area of research with innovations addressing diverse goals such as architectural soundness programmability performance and seamless database integration .
a critical goal that has received less attention than it deserves is the energy efficiency of data intensive software.
according to us environment protection agency epa data centers in were responsible for up to .
of the total us electricity consumption and recent reports show the percentage has increased to .
.
in .
in the consumer sphere battery powered hand held devices such as smart phones and tablets are experiencing explosive growth in popularity.
on both high end and low end platforms dataintensive software is widely used data center applications are predominately data intensive in nature smart phone apps related to video music and maps are among the most commonly used.
in recent years a number of software centric solutionshave been proposed to address energy efficiency through design patterns programming language designs and compiler and runtime optimizations but none has focused on data intensive software.
this is unfortunate because the root cause of energy consumption for data intensive software is often a combination of high volume data processing and complex data flows distinctive traits not sufficiently addressed by solutions built around control flowcentric models.
in this paper we propose g reen streams a novel energyefficient solution that addresses data intensive software.
at its essence g reen streams is an energy efficient twist to standard stream programming models .
stream programming is a general purpose paradigm where software is composed as a stream graph where nodes of the graph are data processing components called filters and edges of the graphs are data flows called streams .
compared with control flowcentric models e.g.java and c the streaming model exposes data processing and data flow at the forefront of programming.
its friendliness to parallelism crucial in the multi core era has been well articulated.
g reen streams elucidates yet another beneficial trait of the stream paradigm its friendliness for improving energy efficiency crucial in the big data era.
the energy efficiency solution of g reen streams is based on a key insight into stream programming a stream graph like a manufacturing assembly line can be operated with more efficiency if the rates of streams can be coordinated so that one filter may output a data item to a stream justin time for consumption by the next filter on the receiving end of the stream.
g reen streams optimizes the tradeoffs between performance and energy consumption through judicious adjustment of the stream rates a goal achieved by a novel combination of static inference and dynamic scaling of cpu frequencies through dynamic v oltage and frequency scaling dvfs .
concretely this paper makes the following technical contributions a novel constraint based rate inference algorithm to statically compute the intrinsic relationships among data streams and coordinate them in an energy efficient fashion the use of linear programming to compute the minimal frequencies necessary to execute individual filters while at the same time maintaining the maximum output rate of the whole application a formal account of the g reen streams core and more importantly a formal analysis of the optimality of allfig.
.
stream composition a sequence b split join c loop frequency selections which intuitively translates to the analytical optimality of energy reduction a prototype implementation that involves dvfs instrumentations on top of a parallel stream processing infrastructure an evaluation that demonstrates the effectiveness of our approach in saving energy without degrading performance.
broadly g reen streams explores the unbeaten path of constructing energy efficient software where innovations on programming models program analyses and runtime systems converge.
to the best of our knowledge this unified softwarecentered approach is unique in addressing energy efficiency of data intensive software.
ii.
b ackground a. stream programming model the stream paradigm organizes software into basic units of first in first out fifo data streams flowing through stream filters.
a data stream is simply a list of data objects of fixed size.
a stream filter is a unit of software which consumes data from a single input data stream and produces data on a single output data stream.
the description of the details of a stream filter is implementation dependent but can be viewed abstractly like a function with internal computation.
stream filters pop a fixed number of data items from their input stream when that data is available process the input data and push a fixed number of derived data items onto their output stream.
a stream program is represented as a stream graph which can be decomposed as sub graphs which ultimately decomposes to simple filters.
there are three common forms of composition as represented in figure .
the simplest is sequential composition in which the output stream of one sub graph feeds the input stream of the second sub graph figure a .
the split join composition figure b first splits a single input stream to two or more streams each of fig.
.
an example stream graph beamformer which will be fed to different sub graphs.
the output streams of these sub graphs will be joined together into a single output stream.
a third less commonly used composition style is a loop configuration figure c .
here the output of the body sub graph is split into an output stream and a feedback stream.
the feedback stream feeds a loop sub graph whose output is joined to the input stream and the result feeds the body sub graph.
for instance the full stream graph for the beamformer benchmark is graphically represented in figure .
in this figure each colored oval represents a stream filter and sub graphs are surrounded by rectangles.
it is well known that a major benefit of stream programming is its natural support for parallelism.
for instance two filters with different functionalities can be deployed as different threads running on different cpu cores achieving task parallelism whereas two instances of the same filter code can take different data and run in parallel as well achieving data parallelism.
logically speaking every filter such as every oval box in figure can be mapped to a separate thread and run in parallel.
in real world stream programming systems optimizations exist to map muliple logical filters into one thread .
b. the stream paradigm expressiveness and applicability popular terms such as video streaming are both a boon and a burden to the stream paradigm.
it vividly demonstrates what onestreaming application looks like but at the same time may lead to misconceptions about the generality of stream programming.
is the stream paradigm a general purpose software development paradigm?
we answer this question in two dimensions.
from the perspective of language expressiveness the stream model is a variant of the data flow programming model .
the namesake difference between control flow and dataflow programming highlights the individual strengths of each model but in terms of language expressiveness the two models are on par commonly used control flows are eithersupported or encodable in the dataflow model and data flow analysis is a standard semantic analysis for the control flow model .
most of the recently developed stream languages are extensions from java c like languages a hybrid of both paradigms.
below the surface the most nontrivial semantic difference between the two models is the dataflow model generally assumes a non shared memory model between filters different filters only access the same memory through explicit input output stream connections.
with a growing awareness off the vulnerabilities of shared memory models e.g.race conditions and atomicity violations nonshared memory models are becoming more popular in new languages such as scala and go .
the combination of non shared memory models and the explicit identification of parallelism in stream languages make them naturally conducive to constructing highly effective parallel software.
from the perspective of applicability any software where the program can be decomposed as a graph of data flows will naturally fit into a stream programming paradigm.
in modeling this application style is among the most classic software architectures and resonates in current research on software processes and work flows.
in programming the stream paradigm is known to be relevant to graphical user interface gui programming gui events as streams sensor network programming sensing data as streams database programming query results as streams and robotics programming signals as streams .
c. dynamic voltage and frequency scaling dvfs dvfs is a common cpu feature where the operational frequency and the supply voltage of the cpu can be dynamically adjusted.
virtually all cpus being used today from arm cortex on droid smartphones intel core on laptops and desktops to high end clusters in data centers support dvfs.
it the era of multi core cpus the frequencies of individual cores can often be adjusted separately a feature known as multiple frequency domain support.
for instance the amd zambezi family a family of or core cpus shipped in supports this feature.
dvfs is often used as an effective power management strategy in vlsi and architecture research.
in addition to small portions related to static leakage the vast majority of a cpu s power consumption presults from its dynamic operation which can be roughly computed as p c v2 f wherevis the voltage fis the frequency and cis the capacitance.
the energy consumption eis an accumulation of power consumption over time roughly e p twhere tis the operating time.
due to the innate nature of cpu vlsi design voltage and frequency are often scaled together.
in a multi core context it has been known that power has a somewhat cubic relation to dvfs scaling .
scaling down the cpu frequency is thus effective in saving power .
saving energy however is slightly more complex because a reduction of frequency may increase the execution time t. dvfs based energy management thus often deals with the trade off between energy consumption and performance.a hs pi stream application p p p0stream graph jpkhnsa nsb nja njbip0 jp hnj nfi nfo nsip0 jfh ni noi f filter s hd rti stream lab filter label d2 integer data element n2 nat natural number rt2 float rate fig.
.
stream programming core abstract syntax iii.
t hegreen streams algorithm this section describes the algorithm used to statically determine an optimal dvfs setting for multiple cores executing a parallelized stream process.
a. abstract syntax we formalize a small core of stream programming whose abstract syntax is represented in figure .
a stream application a is represented as a tuple hs pi wheresis the input stream and pis a stream graph.
each stream is represented by tuplehd rti whereddefines a sequence of data dand rtrepresents data rate i.e.the frequency the elements in dbecome available.
for convenience we only formalize the case where stream data are integers.
a stream graph is either a filter fh ni noi or composed of two stream graphs p andp0 via either sequential composition p p0 or splitjoin composition pkhnsa nsb nja njbip0 or loop composition p hnj nfi nfo nsip0.
a filterfh ni noiis the basic building block of a stream application.
each filter pops consumes nidata elements from its input stream and pushes produces nodata elements on its output stream.
to keep this presentation simple we are abstract about the internal implementation of filters but a filter is most easily pictured as a function taking niinput elements as parameters and returning nooutput elements as the return value.
each filter is explicitly labeled .
for a stream graph p the set of all filter labels appearing in pis computed by convenience function filters p whose definition is obvious.
operationally hs fh ni noiifeeds elements in dto filterfin a fifo fashion at the rate of rt wheres hd rti.
an output stream the result of applying foverd is implicit.
stream application hs p p0ican be viewed as having s as the input stream of p whose output stream is then fed to p0as input.
application hs pkhnsa nsb nja njbip0ifirst splits the data elements in stream sinto two streams in a roundrobin fashion following the distribution factor hnsa nsbi thecomputation waits until nsa nsbdata elements are available on its input stream s and then writes the first nsaof these data elements to the input stream of p and thensbdata elements to the input stream of p0.
this process then repeats.
for instance given s h rtifor some rt and nsa nsb the data elements fed to the input of p are and those fed to the input of p0are .
the second part of the parallel operation is to join the data elements output from pandp0into a single stream again in a round robin fashion following the aggregation factor hnja njbi.
the process waits until there are at least njadata items available on the output of p and at leastnjbdata items available as the output of p0.
when both conditions are met njadata items from pandnjbdata items fromp0are transferred to the output of the composed stream.
the meaning ofhs p hnj nfi nfo nsip0iis to first join sand the output stream of p0 i.e.the output stream of the feedback loop following the aggregation factor hnj nfoi then feed the joined stream as the input stream of p and finally divide the output stream of pinto two following the distribution factor hnfi nsi one of which becomes the final output stream while the other of which is the input stream ofp0.
note that there are some restrictions on the values of nfiandnfoin order to ensure that a feedback loop stream graph can achieve a steady state schedule a topic out of the scope of this paper.
r rvj jrijro rate variable constraint set linear constraint over r rv rate variable name fig.
.
inference elements b. constraint based rate inference we define a novel constraint based algorithm to infer the intrinsic rate dependencies of different elements of a stream program.
the inference algorithm represents the data stream rates as rate variables defined in figure .
a rate variable r is the abstract representation of a stream rate used to constrain and reason about stream rates statically.
the most basic form of a rate variable is rv simply a name that the inference algorithm can internally generate where every fresh generation specifies the creation of a distinct rate variable with a distinct name.
the second form of a rate variable is a filter label .
when a filter label appears in a constraint it doubles as a rate variable that abstractly represents the natural rate of a filter.
the natural rate is the intrinsic rate at which a filter can process a single set of data i.e.the inverse of time required to take nidata items from the input stream process it through the filter and put nodata items onto the output stream.
when a filter executes at its natural rate the rate at which items are consumed from the input stream is ni and the rate at which items are added to the output stream is no.
for convenience we further provide two pre defined rate variables riandroto represents the input rate and output rate of the entire stream graph respectively.
the core inference rules for rate constraints are defined in figure .
function rc r p r0 collects the constraints for stream graph pwhen its input stream rate and output stream rate are represented by randr0respectively.
each rule is defined over a particular syntactical construct and represents a principle of g reen streams that we now elaborate.
a principle of natural bound clearly the output rate of a filter is dependent on the input rate to that filter.
it might be tempting to consider a filter as a pipeline whose output stream rate can be infinite given an infinite input stream rate.
this naive view ignores the execution model of a stream program a filter cannot start processing a second set of input data items until it has finished with the first.
therefore even if data items arrive at the input to a filter very fast the filter cannot execute faster than its natural rate.
thus the maximum output rate of a filter is not only constrained by the rate of the input stream r0 r no niin r filter but also the natural rate of the filter itself r0 noin the same rule .
b principle of sequential balance given a stream graph involving sequential composition p1 p2 it would be a waste of energy if p1can output data items at the rate of items a second whereas p2can only take in data items at the rate of items a second.
it would also be a waste of energy ifp2can only output items a second and p1could take in data items at the rate of items a second.
in both cases the party with a faster rate has no positive impact on the overall output rate of the stream graph the ultimate throughput that matters.
g reen streams balances the output of p1with the input ofp2.
observe that in r seq rvis used both as the output rate of p1 as inrc r p1 rv and the input rate ofp2 as inrc rv p2 r0 .
c principle of join balance given a split join composition of two streams paandpb in the form of pakhnsa nsb nja njbipb let us first assume nja and njb .
it would be a waste of energy if the output rate ofpawere vastly greater than that of pb because in this case the two streams are joined together by taking items from the two streams in a round robin fashion from pa and from pb and thepabranch would have to wait for thepbbranch.
more generally in r par we use rv0 aand rv0 bto represent the output rates of paandpbrespectively where the balanced execution would conform to the constraint rv0 a nja rv0 b njb.
the rest of the generated constraints of the same rule describes the intrinsic dependencies of rates.
here rvaand rvbare the input rates of paandpbrespectively.
the first two constraints denote how the rates of the two are split from the input rate of the whole stream graph whereas the last constraint describes how the output rate of the whole stream graph is combined.
notice that the r loop rule is simply a variation of the r par rule because a loop composition can be viewed as a reversed split join configuration.
in this case rvbis the rate r filter rc r fh ni noi r0 def fr0 r no ni r0 nog r seq rc r p1 p2 r0 def rc r p1 rv rc rv p2 r0 if rvfresh r par rc r pakhnsa nsb nja njbipb r0 def rc rva pa rv0 a rc rvb pb rv0 b rva r nsa nsa nsb rvb r nsb nsa nsb rv0 a nja rv0 b njb rv0 a rv0 b ro9 if rva rvb rv0 a rv0 bfresh r loop rc r pb hnj nfi nfo nsipf r0 def rc rvb pb rv0 b rc rvf pf rv0 f r nj rv0 f nfo rvb ri rv0 f r0 rv0 b ns nfi ns rvf rv0 b nfi nfi ns9 if rvb rvf rv0 b rv0 ffresh fig.
.
constraint based rate inference for the joined stream combining the input stream of the graph and the output stream of the feedback loop and rv0 bis the rate of the stream to be split into the output stream of the graph and the input stream of the feedback loop.
since any stream graph is inductively defined over the forms of compositions of filters the inductive definition in figure is sufficient to compute constraints over arbitrary stream graphs.
c. relating frequency and natural rate our ultimate goal is to select appropriate frequencies for individual filters a task that we will tackle in sec.
iii d. first we must elucidate how frequencies are related to our rate inference.
let us abstractly represent the supported frequencies of a cpu core as a total order h freq i where each element freq2 freq in the concrete scenario would be an available frequency supported by the cpu in hertz .
for simplicity we only consider homogeneous architectures where all cores support the same number of available frequencies for dvfs.
we use max freq to compute the upper bound of freq .
we further define a mapping function lab freq!
float that given a filter label lab and a frequency freq2 freq freq computes the natural rate for filter labeled under operating frequency freq.
intuitively records how fast a data item can be output by filter when the filter is running on a cpu core of a particular frequency.
we rely on profiling to compute .
concretely we profile a filter to determine the natural rate of that filter at the maximum cpu frequency and assume an inversely proportional relationship between frequency and elapsed time of the filter.
this relationship can be defined with the equation freq max freq freq max freq we elaborate on this implementation detail in section iv c.d.
linear programming for optimal frequency selection from an abstract perspective g reen streams follows two steps to select frequencies for specific filters.
first we assume every filter runs at the highest cpu frequency and compute the maximum possible output rate of the whole stream graph.
this is described as algorithm below.
second we compute the lowest possible frequency at which individual filters can execute assuming we must maintain the maximum possible rate computed in the first step.
this is conducted by algorithm below.
the central idea here is both steps can be achieved by performing linear programming over the constraints we inferred earlier section iii b .
before we explain the details let us first introduce some notation related to linear programming.
notation min obf represents an instance of linear programming to minimize an objective function obf over constraints .
it computes a mapping whose domain coincides with the rate variables that appear in obf and whose range is the floating point numbers for rates rt .
in other words all rate variables in all constraints are now solved including the subset of variables we care about.
for example a typical result looks like meaningr1should be of rate .
andr2should be of rate .
if we wanted to achieve the minimality of obf.
objective function obftakes the form of a linear expression.
for convenience we use symbol to represent the ast expansion of addition i.e.m rv2frv1 rv2grvis equivalent to objective function rv1 rv2.
the meaning of notation max obf is identical to min obf except that we are maximizing the objective function.
next let us define the constraints of a stream graph assuming that all filters are executing at the maximum frequency possible.
in other words each filter can operate at its highest natural rate.
the definition is a simple substitution of all rate variables that represent filter natural rates with a concrete rate whenthe maximum frequency is used.
notation frt rgmeans substitute every occurrence of rin withrt.
definition global constraints with maxed out filters given a stream graph p mofcons p is defined asrc ri p r o f freq 1g f n freq ng where filters p andfreq max freq .
with this the maximum output rate of a stream graph p is an instance of linear programming of maximizing roover global constraints with maxed out filters algorithm max output rate given a stream graph p maxout p denotes the maximum output rate with unbounded input rate.
it is defined as rt where max mofcons p ro ro7!
rt .
note that we do not bound the input rate of the stream graph here.
this is not necessary because intuitively the natural rate of individual filters and the constraints associated with them will limit the output rate of the whole stream graph.
hence linear programming cannot yield unbounded results.
obviously for users of g reen streams who would like to artificially bound the input rate of the stream graph a variant algorithm can be provided as follows definition max output rate with bounded input rate given a stream graph pand a pre defined input rate rt0 maxoutb p rt0 denotes the maximum output rate with bounded input rate rt0.
it is defined as rt where max mofcons p frt0 rigro .
finally given that we know the maximum output rate the issue of reducing individual frequencies of filter executions and hence energy consumption is a matter of minimizing the natural rate of individual filters algorithm minimal frequency given a stream graph p the minimal frequency required for filter without affecting the overall output rate denoted as minfreq p is defined as the least value freq in freq such that freq rtand rc ri p r o fmaxout p rog and min !
rt .
e. global optimality and algorithm optimization algorithm leaves two issues to be resolved.
first it only says how to find the minimal frequency for a particular filter.
does this localized optimality seemingly greedy to the particular filter being subjected to linear programming also lead to global optimality?
second the algorithm requires linear programming to be used for every filter in the stream graph which is not an efficient solution.
the following theorem addresses the first issue with algorithm above namely algorithm is a globally optimal algorithm.
theorem natural rate independence for fixed output given a stream graph pand a pre determined output rate rt then if frt1 1ghas solutions and frt2 2ghas solutions then frt1 1gfrt2 2ghas solutions where 22filters p and rc ri p r o frt rog.
this important theorem states the independence of satisfiability of filter natural rates given a fixed output rate ofthe stream graph.
here represents the necessary constraints to allow the stream graph to maintain an output rate rt and 1and 2are two filter natural rate variables filters p .
the fact that frt1 1ghas solutions implies that by setting the natural rate of the filter represented by tort1 the output rate of the stream graph is maintained.
similarly the fact that frt2 2ghas solutions means that by setting the natural rate of the filter represented by 2tort2 the output rate of the stream graph is maintained as well.
the theorem thus tells us that the settings of 1and hence the minimal frequency selections of the two do not interfere with each other and by setting 1tort1and setting 2to rt2at the same time the stream graph can still maintain it output rate rt.
finally the independence of natural rate variables intuitively tells us that minimizing the natural rates of filters one by one is no better than minimizing the sum of all of them together.
this leads to an optimized algorithm where one instance of linear programming can compute all minimal natural rates of all filters and hence compute all minimal frequencies theorem linear programming compositionality given a stream graph pand some pre defined rate constant rt and rc ri p r o frt rog min i for each i2filters p andmin m i2filters p i !
rt0 n7!rt0 n then rt1 rt0 and rtn rt0 n. iv.
e xperimental results a. implementation we implemented g reen streams as an extension to streamit1 version .
.
a sophisticated stream programming infrastructure.
there were several significant modifications to streamit required in order to implement g reen streams including the following the inclusion of run time monitors for profiling natural rate section iii c .
the ability to perform and manipulate dvfs for streamit applications.
to demonstrate the effectiveness of our approach in context support was added to select one of four different dvfs configurations a g reen streams configuration which sets dvfs frequencies based on the results of our static analysis.
a fast configuration in which all dvfs frequencies are forced to the highest possible frequency.
this configuration is likely to deliver the fastest possible performance but also consume the most energy.
an on demand configuration in which all dvfs frequencies are managed by the standard ondemand governor in linux.
the on demand governor modulates dvfs frequency based on demand.
cores with a high work load are run at a high dvfs frequency to improve performance.
cores with a low workload are run at a low dvfs frequency to energy.
the on demand dvfs configuration is the configuration most often used in dvfs capable microprocessors and is considered the default configuration.
a slow configuration in which all dvfs frequencies are forced to the lowest possible frequency.
this configuration is likely to deliver the slowest performance.
the implementation of the filter frequency selection algorithm section iii d .
the ability to assign a filter to a core and set dvfs for that core at run time.
the streamit compiler is equipped with an optimization performed during an intermediate pass called partitioning .
partitioning transforms and load balances the source program stream graph into a stream graph that contains a small number of relatively independent filters that can be mapped to independent cores in a multi core architecture.
the load balancing optimizations of streamit partitioning enable high parallel efficiency on multi core hardware.
the g reen streams algorithm is implemented over the post partitioning stream graph.
b. experimental environment all experiments were performed on an amd fx bulldozer microprocessor running debian linux version .
.
.
the processor was configured as an core multiprocessor with the turbo boost feature disabled.
all normal operating system tasks were executing in the background but all experiments were performed with no other load on the system.
our experiments consisted of running five streamit benchmarks in each of the four dvfs configurations five times while measuring the system current draw using a current meter on the cpu power cable of the microprocessor.
since the cpu is supplied at a constant voltage of 12v the power is directly proportional to the measured current and the energy consists of the power consumed over time.
we used a fluke i30 ac dc current clamp which accurately measures current with a resolution of 1ma using hall effect technology.
current measurements were taken every 100th of a second and stored on an independent system.
these measurements were then post processed to isolate each trial run where a trial run consists of a single execution of a benchmark program in a single dvfs configuration.
five trials were collected for each benchmark in each dvfs configuration to avoid intermittent errors or current draw based on external factors such as cache latencies.
we automated the testing of a single benchmark by creating a loop that cycled through each dvfs state with a three second sleep between each trial and then executing that loop five times.
this ensured that there were no latencies between dvfs states.
the benchmark programs we tested were a subset of benchmarks developed for the streamit compiler .
the five benchmark programs we selected were as follows.
beamformer an implementation of standard beamforming or spatial filtering.
this is a signal processing fig.
.
error between computed natural rate and profiled natural rate technique that combines signals in such a way as to achieve constructive interference or destructive interference depending on the spatial relationship of the signals.
beamforming is used in several applications including seismology radio astronomy etc.
bitonicsort an implementation of batcher s bitonic sort network for sorting power of sized key sets.
dct an implementation of a two dimensional 8x8 inverse discrete cosine transfer which transforms a 16x signal from frequency domain to signal domain.
dct is used in both jpeg and mpeg coding.
des an implementation of a data encryption standard block cipher.
this implementation uses stages of processing rather than the required by the us government des standard.
v ocoder an implementation of a the speech filter analysis portion of a source filter model.
the analysis includes fourier analysis a low pass filter a bank of band pass filters and a pitch detector.
c. experimental results in section iii c we introduced a formula to calculate natural rate with the assumption that the relationship between dvfs frequency and the elapsed time of a specific filter is inversely proportional g reen streams profiles the active elapsed time using the maximum cpu frequency but assumes that the active elapsed time for lower frequencies can be estimated proportionally.
in order to validate this assumption we profiled each of the filters in the five benchmarks at all valid dvfs frequencies .6ghz .3ghz .7ghz .1ghz and .4ghz monitoring the active elapsed time.
we compared our estimated elapsed time with the monitored elapsed time.
the graph in figure shows the percentage of error z axis resulting from this assumption.
filters are on the x axis and frequencies on the y axis.
while there are some filters at some frequencies that show significant error the average error is well below .table i dvfs f requencies assigned to benchmark filters frequency in ghz benchmark .
.
.
.
.
beamformer bitonicsort dct des v ocoder the g reen streams compiler was run against the five benchmarks described above each of which contains filters that can be independently scheduled as threads after streamit partitioning see section iv a .
the g reen streams algorithm determines the optimum frequency for each of the filters.
table i shows the dvfs frequencies computed according to our algorithm and the number of filters for each benchmark assigned to each frequency.
our core cpu has independently adjustable frequency domains i.e.every pair of cores need to share a single frequency.
due to this hardware constraint g reen streams needs to map the filters threads to dvfs frequency domains.
in so one filter in each benchmark except dct was forced to a higher frequency than the one computed by our algorithm.
we then collected current measurements for all benchmarks in all dvfs configurations.
the first observation is that the results show a remarkable consistency.
the results from the trials of the beamformer benchmark appear in figure grouped by different dvfs configurations.
observe that the instantaneous current fluctuations which given constant voltage is proportional to power consumption over time are very similar for different trials of the same dvfs configurations.
other benchmarks showed similar consistency.
this consistency reinforces the concept that our experimental environment produced reliable results.
given this consistency we are able to consolidate results from different trials of the same dvfs configuration and the same benchmark by taking the average current at each time.
the consolidated graph for the beamformer benchmark is in figure .
following our discussion earlier the instantaneous current readings y axis are proportional to the instantaneous power consumption because the cpu has a constant voltage of 12v .
the figure demonstrates the effect of running all cores at their top speed the purple line which consumes high power but finishes the fastest versus running all cores at their lowest speed the blue line which incurs the lowest power consumption but takes significantly longer to complete.
the g reen streams line green shows performance that almost matches the fast line but with significantly less power consumption.
the only surprising data in this graph is the on demand line in red .
the on demand dvfs configuration consumes more power than the fast state but performs slightly slower.
we speculate this is because the on demand dvfs governor spends extra energy to switch dvfs frequencies fig.
.
beamformer trial consistency x unit .
second y unit 1ma fig.
.
beamformer execution over different dvfs configurations x unit .
second y unit 1ma and the somewhat erratic resource demand of the beamformer benchmark may cause the on demand governor to switch too frequently.
figure contains the dvfs configuration comparison for the other four benchmarks.
in this figure the dct benchmark is the most interesting graph.
the g reen streams dvfs configuration not only requires less power than either the fast state or the on demand state but also finishes significantly sooner than either the fast or the on demand dvfs configuration.
the des graph is also interesting because it demonstrates the static nature of g reen streams .
in the des case the on demand dvfs configuration is better at handling an application for which the resource requirements change over time.
the energy consumption of each benchmark dvfs configuration is proportional to the area under each curve in figure and figure .
since the cpu is supplied at afig.
.
other benchmarks over different dvfs configurations x unit .
second y unit 1ma constant voltage of 12v the power is directly proportional to the measured current and the energy consists of the power consumed over time.
our data collection method enabled simple energy consumption calculations based on summing the current measurements for the entire time span of a given trial.
since current measurements were taken every 100th of a second we can compute the instantaneous energy consumption for that measurement by multiplying the measurement value sec and v .
the total energy consumed by the cpu for that trial is the sum of all instantaneous energy consumption values.
fig.
.
energy and performance figure and tables ii and iii present the results of average performance and cpu energy consumption for all five benchmarks.
in three of the five benchmarks beamformer dct and v ocoder the energy consumption with g reen streams was less than the on demand energy consumption and in all benchmarks except v ocoder the performance oftable ii energy consumption per benchmark benchmark slow ondem greenstr fast beamformer .
.
.
.
bitonicsort .
.
.
.
dct .
.
.
.
des .
.
.
.
v ocoder .
.
.
.
table iii timeconsumption per benchmark benchmark slow ondem greenstr fast beamformer .
.
.
.
bitonicsort .
.
.
.
dct .
.
.
.
des .
.
.
.
v ocoder .
.
.
.
green streams was comparable or better than all other dvfs states.
clearly the dct benchmark which was the most computation intensive and had the most stable resource requirements was the best demonstration of the advantages of green streams .
v. r elated work a number of energy management strategies have been proposed for stream applications primarily from the systems community.
benoit et.
al.
considers a subset of stream programs that can be modeled as serial parallel workflows and studies the problem of mapping such workflows to cmps to minimize energy.
eprof designs an energy efficient scheduling algorithm for stream applications with a nondvfs based solution.
rangasamy et.
al.
used stream programs as the context to evaluate the effectiveness of three dvfs schemes one based on a petri net performance model one based on profiling and one based on hardware.
none of these efforts reduce the problem to a program analysis over stream programs as we do nor do they perform constraintbased inference over stream rates.
dvfs as an implementation strategy has been used in compiler and run time optimizations.
hsu et.
al.
defines a compiler optimization algorithm where memory intensive regions of the program control flow are identified and a cpu s frequency is scaled down in these regions to reduce energy consumption.
xie et.
al.
evaluates the limitations and opportunities of dvfs in a control flow centric setting.
an operating system solution is proposed to reduce energy efficiency by scheduling fixed deadline tasks judiciously.
several energy aware programming models have been proposed as extensions to java like languages.
green defines a framework where programmers can customize quality of service qos to balance the trade off qos and energy consumption.
enerj allows data to be approximated and applies hardware techniques to approximate data to saveenergy.
energy types defines a type system to reason about program energy phase behaviors and energy states.
both enerj and energy types use dvfs as an implementation strategy they are otherwise unrelated to our approach.
clause et.
al.
explores the impact of different design patterns on energy consumption.
the impact of different synchronization patterns on energy consumption was also explored .
related work on stream programming and its applications was summarized in sec.
ii b. vi.
c onclusion green streams provides a practical and effective solution to save energy for data intensive software.
the stream programming paradigm not only provides appropriate language abstractions for developing data intensive software but also offers the ideal structure and predictability for effective energy management.
in the future we plan to extend g reen streams to support dynamic adaptability.
instead of relying on off line profiling and static inference frequency selections can be adaptive to the fluctuations of the run time and changing resource requirements.