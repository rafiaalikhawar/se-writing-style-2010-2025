an experience report on scaling tools for mining software repositories using mapreduce weiyi shang bram adams ahmed e. hassan software analysis and intelligence lab sail school of computing queen s university kingston ontario canada swy bram ahmed cs.queensu.ca abstract the need for automated software engineering tools and techniques continues to grow as the size and complexity of stud ied systems and analysis techniques increase.
software engi neering researchers often scale their analysis techniques using specialized one off solutions expensive infrastructures or heuristic techniques e.g.
search based approaches .
how ever such efforts are not reusable and are often costly tomaintain.
the need for scalable analysis is very prominent in the mining software repositories msr field which spe cializes in the automated recovery and analysis of large data stored in software repositories.
in this paper we explore the scaling of automated software engineering analysis tech niques by reusing scalable analysis platforms from the webfield.
we use three representative case studies from the msrfield to analyze the potential of the mapreduce platform to scale msr tools with minimal effort.
we document our experience such that other researchers could benefit fromthem.
we find that many of the web field s guidelines forusing the mapreduce platform need to be modified to betterfit the characteristics of software engineering problems.
categories and subject descriptors d. .
metrics performance measures general terms performance keywords mining software repositories cloud computing mapreduce .
introduction the mining software repositories msr field recovers and studies data stored in large software repositories includ ing source control repositories bug repositori es archived communications deployment logs and code repositories .
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted w ithout fee provided that copies are not made or distributed for pro fit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior speci fic permission and or a fee.ase september antwerp belgium.
copyright acm ... .
.the msr field is one of the many fields within software engineering that continue to benefit from the development ofautomated software engineering tools and techniques.
these automated techniques continuously need to scale as larger systems are being analyzed and more complex techniques are being used to analyze these systems.
for instance recent studies show that the debian linux distribution doubles in size every two years currently at 323m sloc while recent efforts continue to archive very largerepositories of source code based on the strong belief that thewisdom of thousands of coders can help improve the qualityof any one project.
moreover complex model checking and analysis techniques continue to be developed to help locate bugs in large software e.g.
.
to cope with the scale of the analyzed data and the complexity of the used algorithms researchers often make use ofone off solutions heuristic based optimizations e.g.
search based software engineering or specialized commercial systems e.g.
.
however these solutions are too expen sive to acquire or maintain and they often require lengthydevelopment time.
the lack of off the shelf ways to scaleanalysis techniques hinders research progress as researchersspend considerable time tackling side problems that are of limited interest to them but which they must solve to ensure the adoption of their research in practice.
for example d ccfinder a distributed version of the cc finder clone detection tool achieves a speed up factor of us ing a custom client server architecture consisting of pcs.this specialized architecture requires substantial development and maintenance effort to keep it running correctly.
standard platforms are needed that would enable largescale studies with minimal effort and without the need for continuous maintenance.
over the past decade the webfield has developed a significant expertise in dealing withlarge scale problems.
that community has developed several standard platforms that have been extensively reused by its members.
hadoop and pig are examples ofsuch platforms.
we firmly believe that our community canbenefit from these platforms to scale software engineeringstudies.
in prior work we explored the use of hadoop amapreduce implementation to scale and speed up one particular software evolution study.
we could reduce the running time of the study tool by to .
it is not clear though whether findings generalize to other kinds of softwareengineering analyses and how to address the challenges weencountered with configuration and designing mapreduce strategies.
in this paper we use the msr field as a sub field within software engineering to study the benefits and challenges of scaling several software engineering analyses using the largescale data processing platforms.
in particular we use three representative case studies from the msr field to demon strate that the mapreduce web analysis platform could be used to successfully scale msr tools with minimal effort.
the main contributions of our paper are as follows .
we document our experience in scaling several msr problems such that other researchers could benefit from our experience.
.
we also report the changes needed to the web field s guidelines for the mapreduce platform when applying mapreduce to msr analyses.
these changes highlight the different characteristics of software engineering analyses compared to web analyses and must be addressed to ensure that software engineering researchers get the most benefit out of the mapreduce platform.
while we apply scalable web analysis platforms in the context of msr analyses we believe that many software engineering research problems that require automated anal ysis would benefit from these platforms.
we hope that ourwork will encourage other researchers to explore the scalingof their automated techniques using such platforms.
the rest of the paper is organized as follows.
section provides the background and related work of our research.
mapreduce and the expected challenges of migrating msr tools to mapreduce are introduced in section .
we presentour case study in section followed by a report about ourexperiences in addressing the challenges in section .
section evaluates the ability of mapreduce to scale different types of msr analyses.
section discusses threats to valid ity.
finally section presents the conclusions of this paper.
.
background trends in msr.
in recent years two major trends can be observed in the msr field that are also representative for many other fields of ase.
the first trend is that the data analyzed by software engineering researchers is exploding in size.
recent empirical studies exhibit such a trend with many researchers exploring large numbers of indepen dent software products instead of a single software product.
empirical studies on debian gnu linux by gonzalez barahona et al.
analyze up to million lines of source code from releases of the debian distribution which contains over software packages.
similarly mockus andbajracharya et al.have been developing methods to amass and index tbs of source code history data .
estima tion indicates that an entire year of processing is needed to amass such large source code .
this growth of data is not exceptional.
studies show that the debian distributionis doubling in size approximately every two years .
a second trend in software engineering is the use of ever more sophisticated automated techniques.
clone detection techniques are examples of this trend.
text based and tokenbased techniques such as cc finder use raw source code or lexical tokens to detect code clones in a softwareproject.
however as these clone detection techniques areonly able to detect a limited number of clone types more complex techniques that require much more comput ing power and running time are needed to detect more types of code clones with higher precision.approaches to scale msr.
the growth of data and the increase in the complexity of msr studies bring many challenges that hinder the progress of the msr field.
yet there is little work that aims to address these challenges.
to enable large scale msr studies researchers continue to develop ad hoc solutions that migrate msr studies to dis tributed computing environments.
the simplest and most naive way is using batch scripts to split input data across a cluster of machines deploy the tools unchanged to themachines run the tools in parallel and finally merge the out put of every machine.
however naive approaches mostly donot support load balancing error recovery and require ad ditional programming effort.
other approaches such as dccfinder kenyon and sage re engineer the original non distributed msr study tools to enable themto run on a distributed environment.
distributed comput ing libraries such as mpi can assist in developing dis tributed msr study tools.
however the re engineering ofexisting tools requires additional programming effort and software engineering researchers are neither experts in distributed system programming nor willing to spend effort onthe programming.
over the past years parallel database systems such as vertica have been used to perform large scale dataanalyses.
recently work by stonebraker et al .
shows that parallel database systems are challenging to install and configure properly and they typically do not provide efficientfault tolerance.
msr researchers are neither experts in in stalling parallel databases nor can they afford the time tolearn the intricacies of such systems.
moreover msr experiments typically only extract and read large amounts of data from software repositories without ever updating this data.using parallel database system is not an optimal solutionfor scaling msr experiments.
search based software engineering sbse holds great promise for scaling software engineering techniques by transforming complex algorithms into search algorithms which yield approximate solutions in a shorter time span.
forexample kirsopp et al .
use various search algorithms to find an accurate cost estimate for software projects.
in addition to optimized performance most search algorithms are naturally parallelizable to support even larger scale experiments .
however sbse only offers a set of general techniques to solve problems and still require consider able application specific customization to achieve significantspeed ups.
not all msr analyses benefit from approximatesolutions either.
the web field has developed large scale data analysis platforms over the years.
these platforms such as mapreduce are designed to run in distributed environments and typically leverage a distributed data storage technique.
widely and successfully used in the web field these platforms are able to analyze massive amounts of web data.
because the intensive analyses in the msr field and the web field are both scan centric no random access and read only these platforms are very promising for scaling msr analy ses.
shang et al.
have presented preliminary results that demonstrate that the analysis of large scale software engineering data could benefit from such large scale data analysis platforms despite a number of challenges.
this paper explores whether mapreduce can successfully scale a rangeof typical msr analyses discusses how to address the var ious challenges of migrating msr analyses to mapreduce 276and analyzes the differences between guidelines from the web field and our experience.
we then show the applicability of mapreduce in scaling other types of msr analyses.
.
mapreduce mapreduce is a distributed platform for processing very large data sets .
the platform originally proposed by google is used by google on a daily basis to process large amounts of web data.
mapreduce enables a distributed divide and conquer programming model.
the model consists of two phases a massively parallel map phase followed by an aggregating re duce phase.
the input data for mapreduce is broken down into a list of key value pairs.
mappers processes assigned to the map phase accept the incoming pairs process themin parallel and generate intermediate key value pairs.
allintermediate pairs having the same key are then passed to aspecific reducer process assigned to the reduce phase .each reducer performs computations to reduce the data to one single key value pair.
the output of all reducers is the final result of a mapreduce run.an example of mapreducing an msr analysis.
to illustrate how mapreduce can be used to support msr we consider performing a classical msr analysis of the evolution of the total number of lines of code loc of a software project.
the input data of this msr analysis is a source code repository.
the repository is broken down intoa list of key value pairs as version number source code file name .
mappers accept every such pair count the loc of the corresponding source file and generate as intermediatekey value pair version number loc .
for example for a file with loc in version .
a mapper will generate a key value pair of .
.
afterwards each list of key value pairs with the same key i.e.
version number is sent to the same reducer which sums locs in the list and gen erates as output the key value pair version number sum loc .
if a reducer receives a list with key .
a n dt h e list consists of two values and the reducer will sum the values and and output .
.
the mapreduce platform holds great promise for scaling msr experiments because it is .a mature and proven platform.
mapreduce is widely used with great success by the web field andother communities.
for example the new york timeshas recently used mapreduce to transform all its oldarticles into pdf format in a cost effective manner .
.a simple and affordable solution.
mapreduce uses a simple distributed divide and conquer programming model.
mapreduce can be deployed on commod ity hardware which makes scaling msr experimentsmore affordable.
.a read optimized platform.
mapreduce is designed to perform large scale read only data analyses such asthe scan centric msr analyses.
challenges of mapreducing msr analyses although mapreduce holds great promise for msr we envision a number of important challenges based on ourprevious experience of using mapreduce .
we use themapreduce example above to motivate and explain thesechallenges.
the goal of this paper is to document our ex periences addressing these challenges across various types of msr analyses and to carefully examine the guidelinesproposed by the web field regarding these challenges.
by documenting the differences in analyses and data processed by both communities we hope that the software engineering field will be able to exploit the full power of mapreduce toscale software engineering analyses.challenge migrating msr analyses to a divide and conquer programming model.
the first challenge is to find out how to migrate an existing msr analysis to a divide and conquer programming model.
this migration has two important aspects.
.locality of analysis.
a divide and conquer programming model works best when the processing of each broken data part is independent of the processing of the other parts i.e.
a local algorithm .
countingthe number of lines of code loc for every sourcefile is an example of a local algorithm as this can bedone for each file in isolation and the results of eachdata part can just be added up.
global algorithms e.g.
clone detection would require each data part e.g.
set of files to have access to the whole data set.
semi local algorithms e.g.
source code differencing require more data than just local data but not thewhole data set e.g.
only two files .
it is interesting tonote that an analysis might be global due to the implementation of an analysis not due to the analysis itself.
for example several analyses require access to the fullcode base when robust techniques such as island pars ing could be used to overcome this implementationrequirement and would ensure local analysis.
.availability of source code.
having access to the source code of an msr study tool provides more flexible ways to map an msr algorithm to a divide and conquer programming model.
however re engineering a tool internally increases the risk of introducing bugs.
challenge locating a suitable cluster.
distributed platforms typically run on a cluster of machines.
we list below a few aspects for locating clusters .private cluster versus public cluster.
a public cluster is available and accessible to everyone whereas a private cluster is not.
.dedicated cluster versus shared cluster.
dedicated clusters ensure that only one user uses the machines at the same time while machines in the sharedcluster may be used by many users at the same time.
.specialized cluster versus general purpose cluster.specialized clusters are designed and optimized for mapreduce e.g.
while general purpose clusters might result in sub optimal performance.
on the one hand private dedicated specialized clusters provide the most optimal performance.
on the other hand public shared general purpose clusters require the lowest financial cost.
there are eight possible combinations of the three aforementioned aspects.
to illustrate the possi ble types of clusters we show four types as examples.
machines in a research lab private dedicated and specialized .
research shows that computers are idle half of the time .
by bundling these com puters together a small cluster can be created.
machines in a student lab private dedicatedand general .
computers in student labs of universities can be used as medium sized mapreduce clusters.
scientific clusters public shared and general .
some scientific clusters e.g.
sharcnet have hundreds or thousands of machines and are specifically designed for scientific computing.
the large scaleof these clusters enables running experiments on massive amounts of data.
optimized clusters public dedicated and specialized .
some clusters are optimized for mapreduce e.g.
the ec2 mapreduce instances offered by amazon .
optimized clusters are often too costly.
challenge optimizing mapreduce strategy de sign and cluster configuration.
the different implementations and configurations of the mapreduce platform influence the performance of mapreduce experiments yet finding the optimal implementationand configuration is challenging.
.static breakdown of analysis.
the optimal granularity for breaking down the analysis should be carefully examined.
for example counting the loc of a software project can be decomposed into different dataparts that are executed in parallel to count the locof every source code file fine grained or everysubsystem coarse grained .
the finer the granularity the more parallelism that can be achieved.
however finer granularity leads to m ore overhead since additional map and reduce procedures must be scheduled and executed.
although this granularity principle is well known in distributed computing choosing thebest granularity in the context of the mapreduce plat form is still challenging.
.dynamic breakdown of processing.
once the static breakdown is determined the granularity of pro cessing the input data can still be altered dynamically.mapreduce implementations typically allow sending anumber of map and reduce procedures to a machine at the same time as a hadoop task .
in our loc example one single source code file could besent to a machine for analysis or an ad hoc group offiles could be sent together in a batch.
the composi tion of hadoop tasks can be completely arbitrary byt h em a p r e d u c ep l a t f o r m .
.determining the optimal number of machines.a third way to optimize the performance of a mapre duce cluster is by changing the number of machines.adding more machines might not always lead to betterperformance or effective use of resources due to plat form overhead.
for example adding more machines requires more data transfer over the network extra computing power and possibly additional usage fees.
challenge managing data during analysis.
mapreduce needs a data management strategy to store and propagate large data fast enough to avoid being a bottleneck.
two data storage choices are typically available .distributed file system.
input data and intermediate data are stored in one distributed file system that spreads its data to every machine of the cluster to in crease i o bandwidth and the total amount of storage and to achieve fault tolerance.
.local file system.
saving data in the local file system does not require data replication and transfer on the network.table eight types of msr analyses.
name description locality metadata analysis direct analysis on the ex tracted metadata from soft ware repositories e.g.
.
local static sourcecode analysis static program analysis onsource code e.g.
.
local global semi local source codedifferencing and analysis analysis of changes between versions of source code e.g.
.
semi local software metrics measuring and analyzing met rics of software repositories e.g.
.
local global semi local visualization visualizing information mined from software repositories e.g.
.
global clone detection methods detecting and analyzing sim ilar source code fragments e.g.
.
global data mining applying data mining techniques on software repositories e.g.
.
global social network analysis social and behavioural anal ysis on software repositories e.g.
.
semi local choosing the best data storage strategy for different types of analyses is very important and challenging.
challenge recovering from errors.
during the experiments the machines in the cluster might crash and the msr study tools used in the experiments might fail or throw exceptions.
the mapreduce platformneeds to catch failures and exceptions from both hardwareand software during large scale experiments.
handling and recovering errors is import ant when migrating msr study tools to a mapreduce cluster.
.
case studies this section briefly present s the three case studies that we used to study how to address the challenges of migrating msr tools to the mapreduce platform.
.
subject systems and input data we chose three representative msr case studies and associated tools to counter potential bias.
prior research identifies eight major types of msr analyses as shown in ta ble .
techniques across these types require time consuming processing and must cope with growing input data.
we select three msr tools that cover six out of the eight types of msr analyses.
section discusses the applicability ofmapreduce to the two types of msr analyses that are notcovered by our case studies i.e.
visualization and social net work analysis .
we summarize below our case study tools.
j rex.
cvs repositories contain the historical snapshots of every file in a software project with a log of everychange during the history of the software project.
j rex similar to c rex processes cvs repositories to extract information e.g.
author name and changemessage from each cvs transaction.
transform source code into an xml representation.
abstract source code changes from the line level line1 has changed to the program entity level functionf1 no longer calls function f2 .
calculate software metrics e.g.
loc.
278table overview of the three subject tools.
j rex cc finder jack programming language java python perl source code available not available available input data eclipse datatools freebsd log files no.
input datatype cvs repos itory source code execution log table characteristics of the input data.
data size data type files eclipse .4gb cvs repository datatools 227mb cvs repository freebsd .1gb source code log files no.
.9gb execution log log files no.
.1gb execution log j rex performs types of msr analyses i.e.
metadata analysis static source code analysis source code differencing and software metrics .
cc finder.
cc finder is a token based clone detection tool designed to extract code clones from systems developed in several programming languages e.g.
c andc .
cc finder belongs to the clone detection analysis type.
jack.
jack is a log analyzer that uses data mining techniques to process system execution logs and automat ically identify problems in load tests .
jack performsthe metadata analysis and data mining msr studies.
source code of j rex and jack was available to us.
.
experimental environment to perform our evaluation we require input data a cluster of machines and a mapreduce implementation.
we use the cvs repository archives of eclipse a widely used java ide and datatools a data management platform as j rex s input data.
we downloaded the latest version of these archives on september .
freebsd is an opensource operating system.
we use the source code distribu tion of freebsd version .
as the input data for cc finder.finally two groups of execution log files are used as inputdata of jack .
tables and give an overview of the three software engineering tools and their input data.
our experiments are performed on two clusters machines of a student lab and machines of a scientific cluster called sharcnet .
table shows the configuration of the two clusters.
from previou s research we also have experience using a cluster in a research lab.
we choose hadoop as our mapreduce implementation.
hadoop is an open source implementation of mapreduce supported by yahoo!
and widely used in industry.hadoop not only implements the mapreduce model butalso provides a distributed file system called the hadoop distributed file system hdfs .
hadoop supplies java interfaces to implement mapreduce operations and to controlthe hdfs.
another advantage for users is that hadoop bydefault comes with libraries of basic and widely used map and reduce implementations for example to break downfiles into lines.
with these libraries users occasionally do not have to write new code to use mapreduce.
.
performance to illustrate the scalability improvements of mapreduce for msr analyses we briefly discuss the performance obtained using mapreduce in our experiments compared totable configuration of mapreduce clusters.
student lab sharcnet machines cpu intel q6600 .4ghz xeon .0ghz memory 3gb 8gb network gigabit gigabit os ubuntu .
centos .
disk size 10gb 64gb table best results for the migrated msr tools.
tool name input data one machine mapreduceversion cluster j rex eclipse 755min 80min sharcnet cc finder freebsd 59hours student lab jack log file no.
580min 98min sharcnet the performance on a single machine without mapreduce.
we repeated each experiment three times and always re port the median value of our results.
a more detailed analysis of the performance gains of mapreduce for j rex can be found in previous work .
table shows the bestperformance for each tool with the eclipse cvs repository freebsd source code and the 10gb system execution log files as input data respectively.
for cc finder we cannotperform code clone detection in the freebsd source code on one machine because of memory limitations.
from the table we can see that on a cluster of machines sharcnet the running time of j rex and jack is reduced by a fac tor and respectively.
for cc finder the running time isonly hours.
livieri et al.
claim that using cc finder to detect code clones in the freebsd source code requires days.
although the experiments are performed on different hardware environments the huge difference of running timegives an idea of the scalability of mapreduce.
.
migration experiences while the previous section confirms that mapreduce can effectively scale several types of msr analyses it took us several attempts and experiments to achieve such performance results.
in this section we distill our experience such that others would benefit from them.
for each challengefrom section we discuss our findings and provide advicebased on our experience.
we also compare our findings relative to common guidelines provided by the web field.challenge migrating msr tools to a divide andconquer programming model.
we used the following strategies to map the msr tools to a divide and conquer programming model.
j rex.
similar to the original j rex the history of every single file is processed in isolation.
every input key value pair contains the raw data of one file in the cvs repository.
the mappers pass the key value pairs as file name version number of the file to reducers.
reducers perform computations to analyze the evolutionary information of all therevisions of a particular file.
for example if file a.java hasthree revisions the mapping phase gets file names and revision numbers as input and generates every revision number of the file such as a.java a .java .
the reducer generates a.java evolutionary information of a.java .t h e f u l l implementation details are discussed in .
cc finder.
our mapreduce implementation adopts the same computation model as d ccfinder which consists of the following steps figure example of the typical computational model of clone detection techniques.
.
dividing source code into a number nof file groups.
.
combining every two file groups together resulting into n n file group pair id file names in both file groups pairs which are sent to mappers.
.
mappers send the pair to a reducer.
.
the reducer invokes cc finder on a particular pair to run the clone analysis.
figure shows an example of the computational model for detecting code clones in files.
from the figure we can see that every file needs to be compared to every other filea n dt oi t s e l f r e s u l t i n gi n t o6p a i r s .
jack.
jack detects system problems by analyzing log files.
the mapper receives every file name as input key value pair and passes file name file name to the reducer.
passing only the file name instead of the file content avoidsi o overhead.
reducers receive the file name and invokejack to analyze the file.
in the global analyses we have to put required data into reducer.
for local analyses such as evolution of sloc and jack we can use both mapper and reducer.
semi localanalyses can follow the migration strategy of either globalor local analyses.
since the outputs of the different jackinvocations do not need to be aggregated we only need one mapreduce phase instead of both mappers and reducers.
we put all jack functionality in reducers but could just as well have put it in the mappers.
similar migration strate gies are found in examples of mapreduce strategies such as distributed grep .
notable findings.
we summarize below our main observations.
.locality of analysis.
a majority of mapreduce uses in the web field are local in nature while for our case study we find that our three tools cover three levels of locality.
the jack tool performs local analysis because the analysis of a file does not depend on otherfiles.
cc finder performs global analysis because ev ery source code file must be compared to all the inputsource code files.
j rex performs semi local analy sis because it compares consecutive revisions of every source code file.
in another perspective both jrex and jack have the algorithmic complexity of n which is the number of input files while cc finder hasthe algorithmic complexity of n .y e t a l l t o o l s s h o w good performance after being mapreduced.
for ccfinder we adopted the computation model proposed by using the services provided by the mapreduceplatform instead of spending considerable time implementing the platform for such a computation model.
for j rex we found that for each analysis we neededa subset of the data i.e.
all consecutive revisions ofa particular file hence we had to ensure that all thedata is mapped to the same machine in the cluster.
.availability of source code.
when no source code was available we used a program wrapper which cre ates a process to call executable programs.
whenthe source code was available we sometimes had touse a program wrapper to invoke the tool because thetool and the mapreduce implementation used differ ent programming languages e.g.
jack is written in perl while developers need to use java on hadoop .
when the tool s source code was available and writtenin java e.g.
for j rex the source code of the toolwas modified to migrate to mapreduce.
migrating local and semi local analyses is much simpler than migrating global analyses.
little design effort is re quired for migrating j rex and jack.
cc finder as aglobal analysis required more design effort than the othertools.
we implemented to lines of java code to migrate each tool.
challenge locating a suitable cluster in previous research we used a four machine mapreduce cluster in our research lab.
in this paper we used a cluster in a student lab and a cluster in sharcnet.
we document below our experiences using these three types of clusters.research lab.
the heterogeneous nature of research labs complicates the deployment of mapreduce implementations such as hadoop.
these implementations require commonconfiguration choices on every machine such as a common user name and installation location.
in an effort to reduce the complexity of deployments in research labs we exploredthe use of virtual machines instead of the actual machines.the virtual machines unify the operating system user nameand installation location.
however virtual machines intro duce additional overhead especially for i o intensive analysis while for cpu intensive analysis the overhead turned out to be minimal.student lab.
the limited and unstable nature of storage in the student lab limited the use of hadoop.
all toooften student labs provide too limited disk space for analy sis and machines are typically configured to erase all space when booting up.
the limited storage space prevented us from running experiments that performed global or semi local analysis.sharcnet.
while sharcnet and other scientific computing clusters provide the desired disk space and homogeneous configuration we were not able to use the main clusters of sharcnet.
most scientific clusters make useof specialized schedulers to ensure fair sharing of the clus ter which do not support hadoop.
fortunately the shar cnet operators gave us special access to a small testingcluster without scheduling requirements.
notable findings.
heterogeneous infrastructures are not frequently used in the web field.
hence the support provided by mapreduce implementations like hadoop for such infrastructures islimited.
in the research community heterogeneous infras tructures are the norm rather than the exception.
we hope that future versions of hadoop will provide better support.
280for now we have explored the use of virtual machines on heterogenous infrastructures to provide a homogeneous cluster.
the virtual machine solution works well for noni o intensive analysis and as a playground for analysis and debugging before deployment on larger clusters.
we have used such a virtual playground to verify our mapreduce migration before deploying on expensive commercial hadoop clusters such as the amazon ec2 hadoop images .
while scientific clusters provide an ideal homogeneous infrastructure their schedulers have yet to adapt to mapreduce s model.
researchers should work closer with the ad ministration teams of scientific clusters such that mapreduce friendly schedulers are adopted by these clusters.
challenge optimization of mapreduce we now discuss our observations regarding the optimization of mapreduce processing.
static breakdown of analysis.
we explored the use of fine grained most often used in the web field and coarse grained breakdown in our migration of the different tools.
for example for the cc finder tool we started to read files from the input source code repos itory and record the size of every file until the total file sizereached a certain threshold.
the fine grained breakdownprocessed 200mb of files per part while the coarse grainedbreakdown processed 1gb of data per part the cc finder version we had did not support more than 1gb of data .
for j rex we explored the use of single files and sub folders forbreakdown granularity.
in these experiments we found thatcoarse grained breakdown is two to three times faster thanfine grained breakdown because the processing time of each fine grained unit has a large portion wasted on communication overhead.
this finding confirms common knowledge indistributed computing.
dynamic breakdown of processing.
we studied the impact of the dynamic breakdown of processing on performance by varying the number of processing tasks in hadoop.
we experimented with j rex using the datatools cvs repository and jack using the log filesno.
on machines in sharcnet.
we set the number ofhadoop tasks to the number of machines and recordedthe running time of every machine in the cluster.
in theviolin plots of figure the top value corresponds to the maximum machine running time across all the machines which determines the running time of the whole mapre duce process.
the taller the grey box in the violin plot theless balanced the workload of machines.
we then increased the number of hadoop tasks to for j rex and the number of files see table for jack and compared the findings for the increased hadoop task count to the performance of j rex and jack with just 10hadoop tasks.
the plots in figure show that the runningtime of every machine after increasing the number of hadooptasks is more balanced than before lower grey boxes in the violin plot .
however running jack with more hadoop tasks is faster than with fewer hadoop tasks while runningj rex with more hadoop tasks is slower.
this contradictory result is caused by the different types of input data in the two software systems.
the input data of j rex is a cvs repository .
cvs repositories store the history of each file in a separate file leading to a large number of input files.
as shown in table jack only hasa few dozen files as input.
the granularity of input files isfiner for j rex than for jack.
increasing the number of figure violin plots of machine running time for jack and j rex.
hadoop tasks yields a more balanced workload for both jrex and jack.
however this also increases the overhead of the platform to control and monitor hadoop tasks.
as aresult the best number of hadoop tasks for j rex seems to be the number of machines i.e.
coarsest granularity.
for jack the best number of hadoop tasks seems to be thenumber of input files i.e.
the finest granularity.
determining the optimal number of machines.to determine the optimal number of machines in our case study we varied the number of machines from to on jrex for the datatools cvs repository and on jack for the no.
log files.
the number of hadoop tasks are and optimal dynamic breakdown for j rex and jack respec tively.
figure shows the corresponding running times.
wenotice that the performance of j rex grows sub linearly while the performance of jack plateaus.
closer analysis indicates that this is primarily due to two reasons .platform overhead.
the platform overhead is the time that the mapreduce platform uses to control hadoop tasks while the analysis time is the actual execution time of mappers and reducers.
in our experiments we find that the platform overhead is around13 of the total running time with machines and of the total running time with machines.
addingmachines into the cluster introduces additional overhead.
however as the platform overhead is dominated by the analysis time when large scale analysis mapreduce performs better with larger scale analyses.
.unbalanced workload.
an unbalanced workload causes machines to be idle.
for example a machine that is assigned much heavier work than others in creases the total running time as the whole mapreduce run will have to wait for that machine.
in our experiments unbalanced workload is the main reasonfor the un optimal of jack.
in figure jack doesnot improve its performance when moving from ma chines to machines.
we checked the system logsof the mapreduce platform and found that one of the hadoop tasks with the largest input log file took much longer than the other hadoop tasks which had to waitfor that one hadoop task to finish.
as a distributed platform mapreduce requires transferring data over the network.
accessing a large amount of dataalso requires a large amount of i o. intuitively i o mightbe another possible source of the overhead.
we observed theoutput of vmstat on every machine in the cluster and found that the percentage of cpu time spent on i o is less than1 on average which means that in our experiment i o was not a bottleneck.
figure running time trends of j rex and jack w i t h5t o1 0m a c h i n e s .
notable findings.
the web field often uses mapreduce to perform local analysis with each broken down part requiring substantial processing.
in contrast based on our case studies we note thatmany software engineering tasks e.g.
parsing a single file require analyses that vary in locality.
on the one hand we would suggest researchers to analyze files in groups instead of individually in order to reduce platform overhead.however the grouping of files might cause imbalance in therunning time of hadoop tasks with some parts requiringmore processing time than others.
this in turn reduces the parallelism of the platform.
in short we can conclude that large scale analysis on balanced input data benefits more from more machines in the cluster than small scale analysiswith unbalanced input data.
our studies indicate that the recommended parameter configurations for using hadoop on web data do not work well for all types msr studies.
for web data it is recommended that the number of map procedures is set to avalue in between to m and that the number of reduce procedures is set to .
or .
m n w i t h nbeing the number of machines and mbeing the number of processes that can run simultaneously on one machine which is typically the number of cores of the machines .
this recommendation works well for web analysis which is typically fine grained.
fine grained msr tools like j rex which have a large number of input key value pairs can still adopt these recommendations.
coarse grained msr toolslike jack which have a small number of input key value pairs should not adopt these recommendations.
instead such tools should set the number of reduce procedures tobe the same as the number of input key value pairs i.e.
thenumber of input files.challenge managing data during analysis we used both distributed and local file systems.
.distributed file system.
hadoop offers a distributed file system hdfs to exchange data between differentmachines of a cluster.
such file systems are optimizedfor reading and perform poorly for writing data .with many msr tools generating a large number of intermediate files the overhead of using hdfs is substantial.
for example if j rex were to use hdfswhen analyzing eclipse j rex would require almost190 writes to hdfs a major slowdown .
there fore we avoided the use of hdfs whenever possible opting instead for the local file system.
in the special case where no source code is available for an msr tool it might not even be possible to use hdfs asaccessing hdfs data requires using special apis.
.local file system.
in our experiments we find that using every machine s local file system provides themost optimal solution of storing intermediate and output data.
for example cc finder and the log ana lyzer both output results to files which we store in local file system.
since the output files are spread on different machines we have to retrieve the results afterthe mapreduce run is completed.
however we have totake the risk of losing output data and re performing the analysis when a machine crashes.
notable findings.
hdfs is the default data storage of hadoop for the web analyses but was not designed for fast data writing which is necessary in saving msr analyses result data.
from our experience we recommend the use of the local file systemif the result data consists of a large amount of files and the use of hdfs if the result data is small in size.
challenge error recovery our experiments evaluated the error recovery of hadoop.
.environment failure.
to examine the error recovery of hadoop we performed an experiment with j rex and the datatools cvs repository on machines.first we killed mapreduce processes and restartedthem after minute.
we gradually increased the num ber of killed processes starting from until the wholemapreduce job failed.
second we did the same thing as the first step but without restarting the processes.
our experimental results show that mapreduce jobsprocess well with up to out of machines killed.however the running time increases from min to 22min.
if we restore the working processes the hadoopjob can finish successfully with up to half of the machines down at the same time.
.tool error.
the strategy of addressing msr tool errors depends on the implementation of the map and reduce procedures.
if the mapreduce platformcatches an exception the platform will automaticallyre start the mapper or reducer.
according to our experience if a program wrapper is used in the mapreduce algorithm the wrapper needs to take the outputof the msr study tool determine the running status and throw an exception to the mapreduce platformto exploit mapreduce s tool error recovery.
alternatively the wrapper can restart the analysis without throwing the exception to the mapreduce platform.in both cases tool error can be caught and recovered.
notable findings.
we found that hadoop s error recovery mechanism enabled us to have agile clusters with machines joining and leaving the cluster based on need.
in particular in our re search lab students can join and leave a cluster based ontheir location and their current needs for the machine.
because of hadoop an msr tool might be executed millions of times.
hence better reporting is needed by msr tools such that any failure can be spotted easily within the millions of executions.
we are currently exploring the use oftechniques to detect anomalies in load tests e.g.
fordetecting possible failures of the execution of an msr tool.
.
applicability this section discusses the applicability of mapreduce to all the eight types of msr analyses presented in section .
for each type we present possible migration strategies.
thesestrategies basically all depend on whether or not an analysisis local.
we summarize in table the main challenges of migration ease of migration and existence of prior research about scaling the analysis.
282table applicability of performing msr analysis using the mapreduce platform.
name main challenge ease of migrating prior re search metadata analysis challenge easy no static source codeanalysis challenge easy ormedium no source code differenc ing and analysis challenge easy no software metrics challenge easy or medium no visualization challenge hard no clone detection methods challenge hard yes data mining challenge hard yes social network analysis challenge medium yes metadata analysis.
in metadata analysis data can just be broken down by the type of the metadata.
for example bug repository analysis can be broken down to analyzing individual bug reports.
static source code analysis.
local static analyses can be migrated by breaking down the source code into several local parts and using a program wrapper to invoke the existing tools.
if the static analysis process is non local the process of every source code file will consist of two steps collecting the required data in the other source code files performing analysis on the file and its collected data.
source code differencing and analysis.
the process can be broken down by files or by consecutive revisions.
jrex performs source code differencing.
software metrics.
the mapreduce strategies can be designed based on the types of software metrics.
our example of studying the evolution of loc of a software projectin section is an example of a software metric.
visualization.
the visualization techniques that we consider consist of a regular msr technique followed by thegeneration of a visualization.
clone detection methods.
clone detection techniques are non local.
this is the reason why they are hard tomigrate to mapreduce.
livieri et al .
proposes an approach to map clone detection to divide and conquer which we adopted in our case study as mapreduce strategy.
data mining.
many data mining techniques require the entire data to build a model or to retrieve information whichmakes data mining techniques hard to migrate to mapre duce.
however research has been performed to address the challenges of data mining algorithms to mapreduce.
as such some open source libraries are available for runningdata mining algorithms on hadoop .
social network analysis.
social networks can be analyzed as a graph with nodes and edges.
some of the analysesof the entire graph can be broken down to analyses of individual nodes or edges.
x rime is a hadoop library for social network analysis.
b a s e do nt h ee x a m i n a t i o no ft h e8t y p e so fm s ra n a l y s e s most analyses are able to migrate to mapreduce despitesome challenges.
moreover previous research e.g.
has addressed migrating some of the challenging analyses.
.
threats to validity we discuss the threats to validity for our findings.
generalizability.
w ec h o s et os c a l et h r e em s rt o o l s .a l though we chose tools across different types of msr stud ies and using different subject systems to avoid potential bias of our studies to any special msr study our results may not generalize to other msr studies.
however ourcase studies provide promising findings and we encourageother researchers to explore mapreducing their tools.
sec tion provides a brief discussion of generalization acrossother msr studies.
shared hardware environment.
the scientific computing environment we used is a shared cluster.
the usage of other users on the cluster may have impacted our case studyresults which would threaten our findings.
to counter thisthreat we tried to use the cluster when it was idle we re peated each experiment three times and we reported the median value of the results.
subjectivity bias.
some findings in our research can include subjectivity bias.
for example one of the msr tools in our experiment was developed by the author of this pa per while the other two are not.
using our own tools forexperimentation may cause subjectivity bias.
however in practice one will typically only alter the source code of tools that they know well.
more case studies on other msr toolsare needed to verify our findings.
.
conclusion automated software engineering tools continue to play an important role in the analysis of large data sets using sophisticated algorithms.
in an effort to scale such tools developers often opt for ad hoc one off solutions that are costly to develop and maintain.
in this paper we demon strate that standard large scale data processing platforms like mapreduce could be used to effectively and efficiently scale msr tools despite several challenges.
we documentour experiences such that others would benefit from them.
we find that while mapreduce provides an efficient platform we must follow different guidelines when configuringmapreduce runs instead of following the standard web fieldguidelines.
in particular software engineering analyses areoften not local and software engineering analyses require dif ferent configuration than to web analyses to achieve optimal performance.
we hope that our experiences will help others exploring the use of large scale data analysis platforms toscale automated software engineering tools instead of de veloping their own solutions.
.