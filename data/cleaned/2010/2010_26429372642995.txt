concurrent transformation components using contention context sensors erik sterlund software technology group linnaeus university v xj sweden erik.osterlund lnu.sewelf l we software technology group linnaeus university v xj sweden welf.lowe lnu.se abstract sometimes components are conservatively implemented as thread safe while during the actual execution they are onlyaccessed from one thread.
in these scenarios overly conser vative assumptions lead to suboptimal performance.
the contribution of this paper is a component architecture that combines the benefits of different synchronizationmechanisms to implement thread safe concurrent compo nents.
based on the thread contention monitored at run time context aware composition and optimization select theappropriate mechanism.
on changing contention it revisesthis decision automatically and transforms the componentsaccordingly.
we implemented this architecture for concur rent queues sets and ordered sets.
in all three cases ex perimental evaluation shows close to optimal performanceregardless of the actual contention.
as a consequence programmers can focus on the semantics of their systems and e.g.
conservatively use thread safecomponents to assure consistency of their data while defer ringimplementationandoptimizationdecisionstocontention context aware composition at runtime.
categories and subject descriptors d. .
programming techniques concurrent programming e .
data structures keywords context aware composition concurrent components .
introduction parallel programs and concurrent components that can run safely in concurrent i.e.
contended contexts are increas ingly important with the rise of symmetric multiprocessing smp architectures.
a common problem programmers faceis that the level of runtime contention of a component isunknown at development time.
if multiple layers of applica tion programming interfaces apis depend on one another permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full cita tion on the first page.
copyrights for components of this work owned by others thanacm must be honored.
abstracting with credit is permitted.
to copy otherwise or re publish to post on servers or to redistribute to lists requires prior specific permissionand or a fee.
request permissions from permissions acm.org.ase september v ster s sweden acm ... .
.
becomes increasingly difficult to know which level of contention a component will be exposed to.
often a conserva tive approach is taken.
a thread safe component is pickedif there is a possibility that an api is used in a parallel con text e.g.
by a multi threaded application.
however if thecontention was known alternative component variants maybe preferable.
thedreamofnothavingtomanuallypickcomponentvariants based on assumed contention traces back to old classeslike vector in the java class library.
all methods were syn chronized so that programmers could assume thread safetyalways.
unfortunately the approach led to bad sequentialperformance and unscalable parallel performance due to theuse of locks.
therefore the dream was abandoned in latergenerations of the class library and the responsibility ofpicking the appropriate component variant became a bur den for programmers again.
the burden got worse with theadvent of lock free components.
now in addition to know ing whether thread safety is needed or not the componentvariant picked also depends on assumed level of contention.
universal constructions like e.g.
transactional memory tm based on either software stm orhardware htm provide good scalable performanceand ease of use.
lock free components provideeven better concurrent performance while coarse grainedbiased locking is the fastest in absence of concurrency.
there is no single best synchronization mechanism.
instead of trying to find the ultimate synchronization mech anism combining the pros of all existing approaches thispaper seeks to find a way of implementing and composingcomponents using different synchronization mechanisms andpick the appropriate one automatically.
this paper proposes a novel methodology inspired by context aware composition and adaptive spin locks .its goal is simple provide the optimal uncontended perfor mance and the optimal concurrent performance at the sametime.
the idea is to start with optimistic biased locks thatare essentially for free in terms of performance.
at signsof actual contention adapt and break the lock by eitherswitching to a more fine grained locking scheme that scalesbetter or transform into a completely lock free solution formaximum scalability.
this methodology extends context aware composition to use components in a concurrent context where before onlythe components could split work to be done in parallel.
adaptive spin locks are great at sensing different contention and adapting the time to spin before yielding to theos.
this paper goes even further and provides an api sig223 nalling into the application that there is a lock bottleneck.
this allows arbitrary user defined action to deal with theproblem.
this paper contributes with contention awarecomposition a methodology for dealing with overhead andscalability problems of concurrent components under stati cally unpredictable contention.
contention aware compo sition applied to java concurrency data structures.
.
evalu ations running on our own modified openjdk showing thattheseconcurrentcomponentsperform almost aswellastheb e s tk n o w nc o m p o n e n tf o re a c hc o n t e n t i o nc o n t e x t .
the paper is organized as follows section introduces three standard synchronization mechanisms locks lock freealgorithms andtm.section3introducestransformingcom ponents using context aware composition at runtime basedon contention as a context property.
section shows howcontentioncanbemonitoredefficientlywhilesection5showsthat an implementation of the actual component transfor mation can be implemented efficiently.
section introducesthe java concurrency data structures used in evaluation highlights some implementation details and finally describesthe evaluation and the evaluation results.
finally section 7discusses the related work and section concludes the pa per.
.
synchronization mechanisms we refer to concurrent components as data structures implementing an api whose instances are consistent in a con current executiton context.
in object oriented languages concurrent components are instances of classes that are con sistent even if accessed by several threads concurrently.
we describe three different synchronization mechanisms used to implement concurrent components locks lock free synchronization using atomic instructions like compare and swap cas tm.
we argue they all have their weak nesses and strengths specifically for our main concern inthispaper performance .
wediscussthetheoreticalprosand cons of each synchronization mechanism in both almost se quential and highly concurrent execution contexts.
.
locks alockcanbeacquiredbyoneandonlyone owner thread thatmaycontinuewithitsexecution.
itblocksotherthreadstrying to acquire the lock until the owner releases it again.locks are arguably the most common synchronization mech anism because of their availability and ease of use.
they arealso flexible in the sense that the locking granularity canbe varied to achieve scalability.
problems such as deadlockswill not be discussed here as we are only interested in perfor mance and not in programming and verification efficiency.
sequential context in an almost sequential execution context coarse grained locks and sequential algorithmsimplementing an api tend to always win.
if it can be stat ically proven that objects never escape a thread by man ual or automated escape analysis locks can even be elidedcompletely and the sequential code can run at no additionaloverhead.
even when it is not provable statically that a lockbelongs to a single thread exclusively the lock may opti mistically assume so using biased locking .
therefore itinstalls the presumed owner thread the first time it is lockedusing cas.
if the owner stays the same locking and unlock ing is performed simply by writing and correspondingly a n di sv e r yf a s t .concurrent context inconcurrentexecutioncontexts locks suffer from problems predicted by amdahl s law .since locks fundamentally only allow one thread to executeat a time locked programs do not scale very well when thesequential parts dominate the concurrent parts.
there are ways to mitigate this bottleneck by using a different locking scheme.
one solution is to use fine grainedlocking where only some objects of a complex componentlocal to a change are locked instead of locking the wholecomponent instance.
for instance only some nodes in atree are locked instead of locking the whole tree.
anothersolution is to use readers writer locks that allow multiplereaders but only one writer at a time.
conclusion locking is superior for sequential execution but may not be the best candidate for concurrent use.
.
lock free synchronization lock free algorithms were introduced to deal with the problems of locks.
synchronizing instructionsare used only on memory locations where there are actualdata conflicts.
they read and remember values from thememory locations perform calculations and write the resultback to these locations.
using operations like cas theydetect conflicts i.e.
if another thread has changed the valuein between.
then they try again in a biased loop withbranch prediction optimized for the success and not thetry again branch .
this allows concurrent modification ofcomponents as long as there are no data conflicts and thus somehow mitigates the problems of amdahl s law.
due to the inherent complexity of these algorithms not allsequentialdatastructureshavelock freeimplementationsyet.
also a truly lock free algorithm requires the underlyingexecutionenvironment includingthememorymanagertobelock free to retain its progress guarantee which is difficult toassure.
it requires e.g.
lock free garbage collection orhazard pointers .
however this paper is not concernedwith guaranteeing true lock freedom or real time properties.our interest is only the scalable performance characteristicsof this class of algorithms for concurrent components.
sequential context the performance of such lock free algorithms greatly depend on the hardware and how fast itscas instruction is compared to normal memory accesses.
historically x86 implemented lock cmpxchg cas by locking the whole memory bus globally during the execu tion of the instruction.
newer implementations however lock only the cache line where the cas is executed.
astrongcasrequiresacquirereleasesemanticsandhence needs to issue a full memory fence.
in certain architecturesthis might be a relatively expensive operation requiring allwrite buffers and caches to be serialized.
in the case of x86 which is considered strongly consistent all aligned memory accesses already have acquire re lease semantics and the lock cmpxchg instruction already implicitly issues a complete memory fence for free.
in other architectures such as power which is weakly consistent the cost is higher.
here enforcing the acquire re leasesemanticsrequires anexpensiveheavyweight sync memory fence instruction a lwarx load link and stwcx store conditional in a loop until the instruction can returna valid result free from spurious failures a lightweightisyncfence to serialize all writes.
224lock free algorithms can also rely on volatile memory accesses with acquire release semantics whose performance may similarly depend on which architecture it runs on.
additionally even if the volatile memory accesses including cas are as fast as non volatile memory accesses lock freealgorithmsarestilltypicallyslowerbecausetheyarefun damentally designed to handle data conflicts e.g.
branchesfor loops retrying committing their changes which is nevernecessary in a sequential execution.
moreover simple com ponent attributes such as the size of a collection are typi cally computed on demand in a lock free implementation inorder to reduce cache clashes.
in the example of the size at tribute this leads to an o n o p e r a t i o ni n s t e a do fa n o operation of a corresponding sequential data structure thatsimply maintains a size counter because it does not need tooptimize for concurrency.
concurrent context is where the merits of lock free programming becomes visible.
lock free components com mit changes at linearization points using cas and op tionally lazily asynchronously on any subsequent opera tions update