diversity in software engineering research meiyappan nagappan software analysis and intelligence lab queen s university kingston canada mei cs.queensu.ca thomas zimmermann microsoft research redmond wa usa tzimmer microsoft.com christian bird microsoft research redmond wa usa christian.bird microsoft.com abstract one of the goals of software engineering research is to achieve generality are the phenomena found in a few projects reflective of others?
will a technique perform as well on projects other than the projects it is evaluated on?
while it is common sense to select a sample that is representative of a population the importan ce of diversity is often overlooked yet as important .
in this paper we combine ideas from representativeness and diversity and introduce a measure called sample coverage defined as the percentage of projects in a population that are similar to the given sample.
we introduce algorithms to compute the sample coverage for a given set of projects and to select the projects that increase the coverage the most.
we demonstrate our technique on research presented over the span of two years at icse and fse with respect to a population of active open source projects monitored by ohloh.net .
knowing the coverage of a sample enhance s our ability to reason about the findings of a study .
furthermore we propose reporting guidelines for research in addit ion to coverage scores papers should discuss the target population of the research universe and dimensions that potentially can influence the outcomes of a research space .
categories and subject descriptors d. .
metrics genera l terms measurement performance experimentation keywords diversity representativeness sampling coverage .
introduction over the past twenty years the discipline of software engineering research has grown in maturity and rigor.
researchers have worked towards maximizing the impact that software engine ering research has on practice for example by providing techniques and results that are as general and thus as useful as possible.
however achie ving generality is not easy basili et al.
remarked that general conclusions from empirical studies in software engineering are difficult because any process depends on a potentially large number of relevant contex t variables .
with the availability of oss projects the software engineering research community has moved to more extensive validation.
as an extreme example the study of smalltalk feature usage by robbes et al.
examined projects .
another example is the study by gabel and su that examined projects .
but if care isn t taken when selecting which proje cts to analyze then increasing the sample size does not actually contribute to the goal of increased generality.
more is not necessarily better .
as an example consider a researcher who wants to investigate a hypothesis about say distributed development on a large number of projects in an effort to demonstrate generality.
the researcher goes to the json.org website and randomly selects twenty projects all of them json parsers.
because of the narrow range of functionality of the projects in the sample any findings will not be very representative we would learn about json parsers but littl e about other types of software.
while this is an extreme and contrived example it shows the importance of systematically selecting projects for empirical research rather than selecting projects that are convenient.
with this paper we provide technique s to assess the quality of a sample and to identify projects that could be added to further improve the quality of the sample.
other f ields such as medicine and sociology have published and accepted methodological guidelines for subject selection .
while it is common sense to select a sample that is representative of a populati on the importance of diversity is often overlooked yet as important .
as stated by the research governance frame work for health and social care by the department of health in the uk it is particularly important that the body of research evidence available to policy makers reflects the diversity of the population.
similarly t he national institutes of health in the united states developed guidelines to improve diversity by requiring that certain subpopulations are included in trials .
the aim of such guidelines is to ensure that studies are relevant for the entire population and not just the majority group in a population.
intuitively the concepts of diversity and representativeness can be defined as follows diversity.
a diverse sample contains members of every subgroup in the population and within the sample the subgroups have roughly equal size.
let s assume a population of subjects of type x and subjects of type y. in this case a perfectly diverse sample w ould be x and y .
representativeness.
in a representative sample the size of each subgroup in the sample is proportional to the size of that subgroup in the population.
in the example above a perfectly representative sample would be x and y. note that based on our definitions diversity roughly equal size and representativeness proportional are ortho gonal concepts.
a highly diverse sample does not guarantee high representativeness and vice versa.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
esec fse august saint petersburg russia copyright acm ... .
.
in this paper we combine ideas from diversity and representativeness and introduce a measure called sample coverage or simply coverage defined as the per centage of projects in a population that are similar to a given sample .
rather than relying on explicit subgroups that are often difficult to identify in the software domain we use implicit subgroups neighborhoods based on similarities between projects we will discuss details in section .
sample coverage allows us to assess the quality of a given sample the higher the coverage the better section .
.
further it allows prioritizing projects that could be added to further improve the quality of a given sample section .
.
here t he idea is to select projects bas ed on the size of their neighborhood not yet covered by the sample .
in other words select projects first that add the most coverage to a sample .
this is a hybrid selection strategy neighborhoods are typically picked only once reflecting ideas from diversity but the neighborhoods with the highest coverage are picked first reflecting ideas from representativeness .
we make the following contributions with this paper .
we introduce a vocabulary universe space and configuration and technique for measu ring how well a sample covers a population of projects.
.
we present a technique for selecting projects in order to maximize the coverage of a study.
.
we provide a publicly available r implementation of the algorithms and the data used in this paper.
both hav e been successfully evaluated by the esec fse artifact evaluation committee and found to meet expectations.
.
we assess the sample coverage of papers over two years at icse and fse with respect to a population of active open source projects and provide guidance for reporting project selection .
understanding the coverage of a sample can help to understand the context under which the results are applicable .
we hope that the techniques and recommendations in this paper will be used by research ers to achieve consistent methods of selecting and reporting projects for their research.
in the rest of this paper we first present a general technique for evaluating the coverage of a sample with respect to a population of software projects and selectin g a sample with maximum coverage section .
we then demonstrate this technique by calculating the coverage of research over two years at ic se and fse section .
then we provide appropriate meth ods of reporting coverage and project selection in genera l and discuss implications section .
finally we present related work section and our conclusions section .
.
sample coverage in this section we present a technique for assessing the coverage of a sample we first introduce our terminology section .
and .
followed by algorithms to score the coverage of a sample of projects section .
and select the projects that increase the coverage the most section .
.
we implemented both algorithms from section .
and .
in the r programming language they are available as an r package.
the appendix has a walkthrough on how to use our implementation.
.
universe space and configuration the universe is a large set of projects it is often also called population.
the universe can vary for different research areas.
for example research on mobile phone applications will have a different universe than web applications.
possible universes all open source projects all closed source projects all web applications all mobile phone applications all open source projects on ohloh and many others.
within the universe each project is characterized with one or more dimensions .
possible dimensions total li nes of code number of developers main programming language project domain recent activity project age and many others.
the set of dimensions that are relevant for the generality of a research topic define the space of the research topic.
similar to u niverses the space can vary between different research topics.
for example we expect program analysis research to have a different space than empirical research on productivity possible space for program analysis research total lines of code main pro gramming language.
possible space for empirical research on productivity total lines of code number of developers main programming language project domain recent activity project age and likely others.
the goal for a research study should be to provide a high coverage of the space in a universe .
the underlying assumption of this paper is that projects with similar values in the dimensions that is they are close to each other in the space are representative of each other .
this assumption is commonly made in the software engineering field especially in effort estimation research .
for each dimension d we define a similarity function that decides whether two projects p1 and p2 are similar with respect to that dimension similar d p1 p2 true false the list of the similarity functions for a given space is called the configuration .
configuration c similar ... similar n similar to universe and space similarity functions and the configuration can vary across research studies .
for some research topics projects written in c might be considered similar to projects written in c while for other researc h they might be considered different.
to identify similar projects within the universe we require the projects to be similar to each other in all dimensions.
similar p1 p2 similar d p1 p2 d if no similarity function is defined for a dim ension we assume the following default functions with p the value of project p in dimension d and e the absolute positive value of the specified expression e for numeric dimensions e.g.
number of developers we consider two projects to be similar in a dimension if their values are in the same order of magnitude as computed by log and expressed by the .
threshold below .
similar d p1 p2 log 10p1 log 10p2 .
for categorical dimensions e.g.
main programming language we consider two projects to be s imilar in a dimension if the values are identical.
similar d p1 p2 p1 p2 as mentioned above the similarity functions can be overridden in a configuration.
different configurations may exist for different research topics and areas.
the dis tinction into numerical and categorical dimensions is a simplification as not all measurements of software are on a numerical and absolute scale.
measurements that are on ordinal scale could easily be accounted for with custom similarity functions.
.
exampl e coverage and project selection figure a shows a sample universe and a sample space the universe contains projects each represented by a point.
the space is defined by two dimensions the number of developers horizontal and the number of lines of code vertical .
in practice the universe can be thousands of projects and the space can be defined by numerous dimensions not just two.
we will present a more complex instantiation of our framework in section .
consider project a in figure a which is represented by an enlarged point.
the light gray areas indicate the projects that are similar to project a in one dimension based on the similarity functions that are defined in the configuration .
the intersection of the light gray areas the dark gray area indicates the projects that are similar to a with respect to the entire space.
in total seven other projects are similar to a. thus project a covers of the universe.
we can also compute coverage for individual dimensions project a covers for number of developers and for lines of code.
figure b illustrates how a second project increases the coverage if we add project b ten additional projects are covered the universe coverage increase to .
the coverage of the developer and lines of code dimensions increases to and respectively.
however if we add project c instead of project b there is only little i mpact on coverage.
all similar projects have been already covered because project c is close to project a. thus the universe coverage increases only to .
ba developers lines of code developersa c a b fig.
.
sample universe of projects defined by a two dimensional space.
a the light gray areas indicate projects similar to project a in one dimension.
the dark gray areas indicate projects similar to project a in both dimensions.
b project b increases the coverage of the space more than project c does because c is too similar to projects already covered by project a. this illustrates an important point to provide a good coverage of the universe one should select projects that are diverse rather than similar to each other .
we now introduce algorithms to score the coverage score projects and to select additional projects such that the coverage is maximized next projects .
.
computing coverage we compute the sample coverage of a set of projects p for a given universe u an n dimensional space d and a configuration similar ... similar n as follows.
recall that the definition of similar is similar similar ... similar n coverage q similar p q p p u as discussed before research topics can have d ifferent parameters for universe space and configuration.
therefore it is important to not just report the coverage but also the context in which it was computed what projects is the research intending to be relevant algorithm i. scoring projec ts score projects projects p universe u space d config c c space c dim for each project p p c project u for each dimension d d are similar p q c p q sim projects q are similar p q c project c project sim projects c dim c dim sim projects c space c space c project score c space u dim score apply c dim x x u return score dim score algorithm ii.
selecting the next projects next projects k projects p universe u space d config c result similar p q c p q ... c p q c space q similar p q p p candidates u p for i ... k c best p best na for each candidate p candidates c candidate q similar p q c new c space c candidate c space if c new c best c best c new p best p if p best na break result append result p best candidates candidates p best c space c space c best return result for universe ?
what criteria matter for findings to hold for other projects space configuration ?
to compute the coverage for a set of projects we implemented the algorithm shown in algorithm i in r. for each project p p the algorithm computes the set of projects c project that ar e covered by p lines .
as a naming convention we use the prefix c in variable names for sets of covered projects.
in addition the algorithm computes the projects c dim covered by each dimension d line .
after iterating through the set p the algorithm computes the coverage score within the entire space line and for each dimension line .
the apply function maps the function x x u to the vector c dim and returns a vector with the result.
.
project selection in order to guide project selection in such a way that the coverage of a sample is maximized we implemented the greedy algorithm that is shown in algorithm ii.
the input to the algorithm is the number k of projects to be selected a set of already select ed projects p a universe u an n dimensional space d and a configuration c similar ... similar n .
the algorithm returns a list of up to k projects the list is ordered decreasingly based on how much the projects increase the coverage of the space.
the set of preselected projects p can be empty.
by calling the algorithm with p and k u one can order the entire universe of projects based on their coverage increase and returns the subset of projects that is needed to cover the entir e universe for a score of .
the main part of the algorithm is the loop in lines that is repeated at most k times.
the loop is exited early lines when no project is found that increases the coverage in this case the entire universe has been covered score of .
the algorithm maintains a candidate set of projects candidates which is initialized to the projects in universe u but not in p line we use to denote set difference .
the body of the main loop computes for each candi date p candidates lines how much its coverage line would increase the current coverage c space line and memorizes the maximum increase lines .
at the end of an iteration i the project p best with the highest coverage increase is appended to the result list and then removed from the candidates list lines the current coverage c space is updated to include the projects in c best line .
our r implementation includes several optimizations that are not included in algorithm i for the sake of comprehension.
to reduce the cost of set operations we use index vectors in r similar to bit vectors .
computing the projects similar to a candidate in line is an expensive operation and we therefore cache the results ac ross loop iterations.
lastly starting from the second iteration we do process candidates in line in decreasing order of their c new values from the previous iteration.
the c new values from iteration i are an upper bound of how much a can didate can contribute to the coverage in iteration i. if the current best increase c best in iteration i is greater or equal than the previous increase c new of the current candidate in iteration i we can exit the inner loop lines an d skip the remaining candidates.
this optimization significantly reduces the search space for projects.
.
implementation in r the r implementation of the algorithms for computing coverage and selecting next projects is publicly available .queensu.ca replication representativeness .
the ohloh case study in this section we provide an example of how to apply our technique and illustrate how it can be used to quantify the coverage of software engineering research.
.
the ohloh universe we chose as universe the active projects that are monitored by the ohloh platform .
ohloh is a social coding platform that collects data such as main programming language number of developers licenses as well as software metrics lines of code activity statistics etc.
.
note that the ohloh data is just one possible universe and there are many other universes that could be used for similar purposes.
to collect data to describe the projects i n the universe we used the following steps .
we extracted the identifiers of active projects using the project api of ohloh.
we decided to include only active projects in the universe because we wanted to measure coverage for ongoing development.
we foll owed richard sands definition of an active project that is a project that had at least one commit and at least committers in the last months.
.
for each project identifier we extracted three different categories of data each with one call to the api .
the first is the analysis category which has data about main programming language source code size and contributors.
the second is the activity category which summarizes how much source code developers have changed each month commits churn .
we accumulated the activity data for the period of june to may .
finally we collected what is called the factoid category.
this category contains basic observations about projects such as team size project age comment ratio and license conflicts.
.
we aggregated the xml files returned by the ohloh apis and converted them into tab separated text files using a custom script.
we removed projects from the universe that had missing data p rojects had no main language or an incomplete code analysis or invalid data projects had a negative number for total lines of code .
after selecting only active projects and removing projects with missing and invalid data the universe consists of a t otal of projects.
this number is comparable to the number of active projects reported by richard sands .
.
the ohloh space we use the following dimensions for the space .
the list of dimensions is inspired by the comparison feature in ohloh.
the data for the dimensions is provided by ohloh.
main language.
the most common programming language in the project.
ohloh ignores xml and html when making this determination.
total lines of code.
blank lines and comment lines are excluded by ohloh when counting lines of code.
number of contributors months .
contributors with at least one commit in the last months.
number of churn months .
number of added and deleted lines of code excl uding comment lines and blank lines in the last months.
number of commits months .
commits made in the last months.
project a ge.
the ohloh factoid for project age projects less than year old are young between year and years they are norm al between and years they are old and above years they are very old.
project a ctivity.
the ohloh factoid for project activity if during the last calendar months there were at least fewer commits than in the prior months the activity is decreasing if there were more commits the activity is increasing otherwise the activity is stable.
in our case metrics for the last months are for the period of june to may .
again this is just one possible space and there will be oth er dimensions that can be relevant for the generality of research.
figure shows the distributions of the dimensions in our dataset.
there are over programming languages captured in the ohloh dataset the most frequently used languages are java pytho n c and javascript.
a large number of projects are very small in terms of size people and activity projects are less than lines of code yet projects exceed a million lines of code.
many projects have only contributors proje cts and not more than commits projects in the last months.
again there are extreme cases with hundreds of contributors and thousands of commits.
.
covering the ohloh universe as a first experiment we computed the set of projects required to cover the entire population of ohloh projects.
for this we called the next projects algorithm with n an empty initial project list p and the default configuration see section .
.
next projects n projects p universe u ohloh space d config c figure shows the results with a cumulative sum plot.
each point x y in the graph indicates that the first x projects returned by next projects covered y percent of the ohloh universe.
the first projects or .
covered .
of the universe projects covered and projects covered the entire universe.
in table we show the first projects returned by the algorithm next projects .
these are the projects that increase the coverage of the space the most.
we draw the following conclusions.
first small software projects written in dynamic languages dominate the list seven of the f irst nine are in ruby or python and under loc .
are researchers exploring the problems faced by these projects?
even when considering all projects these projects together comprise less than loc and just over commits an order of ma gnitude lower than for apache http mozilla firefox or eclipse jdt .
the time and space required to analyze or evaluate on these projects are fairly low providing a ripe opportunity for researchers to achieve impact without large resource demands.
this result also counters a common criticism of some software engineering research some people expect that research always has to scale to large software and pay less attention to smaller projects .
however as table i and figure show the space covered by smaller projects is non negligible .
.
covering the ohloh universe with the icse and fse conferences we now apply our technique instantiated with the ohloh universe to papers from premiere conferences in the software engineering field the international conf erence on software engineering icse and foundations of software engineering fse .
this section does not mean to make general conclusions about the entire fig.
.
histograms of the dimensions in the ohloh universe.
fig.
.
number of projects that are needed to cover the ohloh universe.
each point in the graph means that x projects can cover y percent of the universe.
software engineering community.
rather r esults should only be viewed in the context of the papers in those two years of those two conferences icse and fse .
to create the dataset the first author read each full paper of the main technical research track in each conference looked for the software projects that were analyzed and recorded the number and if mentioned the names of the projects in a spreadsheet.
we then queried ohloh for each of the software projects to find the corresponding identifier which we used to cross reference the data with our corpus.
some projects we could not cross reference with our dataset because of any one of the following reasons a the project was not indexed by ohloh b the paper used an aggregated set of projects and particular project s were not named in the paper c the project does not meet the criteria to be incl uded in the universe e.g.
the project has not been under development in the past year has only one developers or has missing or invalid data.
the analysis of the icse and fse conferences revealed several large scale studies that analyzed hundreds if no t thousands of projects.
some of these papers we had to exclude from our analysis as they either analyzed closed source projects or did not report the names of the individual projects analyzed or analyzed inactive ohloh projects.
what are the most frequent ly used projects in the icse and fse conference s?
we found unique projects that were analyzed by the icse and fse conferences in the two year period.
out of these we could map to the universe of active ohloh projects.
the most frequently studied projects were the eclipse java development tools jdt in papers apache http server in papers gzip jedit apache xalan c and apache lucene each in papers and mozilla firefox in papers.
another frequently studied project is linux which was analyzed in papers.
while the linux project is listed on ohloh the code analysis has not yet completed table .
the first projects returned by next projects n projects p universe u ohloh space d config c with the increase in coverage name language lines contributors commits churn age activity increase serialize with options ruby normal increasing .
java chronicle java young stable .
hike ruby normal stable .
talend service factory java normal stable .
openobject library python normal stable .
ruote amqp pyclient python normal stable .
sign server python young stable .
redcloth formatters plain ruby normal decreasing .
python yql python normal decreasing .
mraspaud s mpop python normal stable .
appengine toolkit javascript normal stable .
socket.io java java young stable .
glinux c very old decreasing .
pax url java old decreasing .
honeycrm java normal decreasing .
table .
the representativeness of all icse and fse papers in the past years as well as the five most representative paper s. the universe is the active ohloh projects the space is main language total lines of code contributors churn commits project age project activity and the configuration consists of the default similarity functions.
all papers of icse and fse past years gabel and su.
uniqueness of source codeapel et al.
semistructured mergebeck and diehl.
modularity and code couplinguddin et al.
analysis of api usage conceptsjin and orso.
reproducing field failures score .
.
.
.
.
.
main language .
.
.
.
.
.
total lines of code .
.
.
.
.
.
contributors months .
.
.
.
.
.
churn months .
.
.
.
.
.
commits months .
.
.
.
.
.
project age .
.
.
.
.
.
project activity .
.
.
.
.
.
and only limited information is available no activity no lines of code .
therefore we ignored linux from our analysis.
how much of the ohloh universe do the icse and fse conferences cover?
the ohloh projects analyzed in the two years of the icse and fse conferences covered .
of the ohloh population.
at a first glance this score seems low but one has to keep in mind that it is based on strict notion of coverage values in all dimensions have to be similar for a project to be similar to another.
low scores are not bad as we will discuss in section .
.
our algorithm also measures the coverage for each dimension.
here numbers are very promising see column all papers of icse and fse in table for all but one dimension the coverage scores exceed which indicates that research publi shed at icse and fse covers a wide spectrum of software in terms of team size activity and project size.
the lowest score is for programming language but still at an impressive .
.
the unstudied languages highlight opportunities for future researc h objective c is used by vim script by scala by erlang by and haskell by projects.
what are showcases of research with high coverage ?
we identified several outstanding papers in terms of coverage .
in table the columns to show the total coverage score and the dimension scores for the five papers with the highest coverage a study of the uniqueness of source code by gabel and su analyzed over projects of which were named in the paper and analyzed in depth.
the score is computed for only the named projects.
the bulk of the corpus is from the source distribution of the fedora linux distribution rel.
.
the authors studied multiple programming languages c c java .
semistructured merge rethinking merge in revision control systems by apel et al.
evaluated a merge algorithm on projects written in the c python and java languages.
on the congruence of modularity and code coupling by beck and diehl analyzed small to medium sized projects written in java.
temporal analysis of api usage concepts by uddi n et al.
studied client software projects.
they covered a wide spectrum of project size .
to .
kloc but given the nature of their study focused on older projects with larger amounts of history.
bugredux reproducing field failures for in house debugging by jin and orso recreated failures of real world programs.
the size of the projects was between .
and kloc.
agai n the total scores seem to be low which we will discuss in section .
.
more importantly however the numbers in table ii allow assessing which dimensions papers covered well and which dimensions need improvement .
for example beck and diehl uddin et al.
and jin and orso focused on a single programming language java and c respectively .
to further increase the generality additional languages may be studied.
another example is project age all three papers focus ed on older projects possibly because they needed long project histories that are only available for older projects.
note that this is not a criticism of this research these are merely ideas on how to increase the coverage of the ohloh universe.
also note that the relevant target universe may be different for each paper.
for example research on java projects may limit itself to a java universe.
it is noteworthy that several of these papers selected their subjects with respect to a dimension that is not included in our space the functionality of the software.
this dimension could be easily added to our space and accounted for in our score computation given the availability of data.
.
data availability all data that has been used for the experiments in t his section is available at the following url.
this includes the ohloh data for universe and space and spreadsheets with the conference data.
.
discussion having introduced our technique for asse ssing the coverage of a project sample and demonstrated it on recent software engineering research we now discuss issues surrounding the use of such a technique in research.
the use is not as straightforward as one might think.
here are some considerati ons.
.
understanding low coverage one observation that we have made in the course of using our techniques is that many studies have low levels of coverage .
at first glance one might be tempted to conclude that these studies do not contribute much to the body of knowledge in software engineering or that others with higher coverage are better.
a low coverage of a study does not devalue the research but rather gives further insight into the results.
for example zhou et al.
s recent result that bug report attributes can be used to automatically identify the likely location of a fix was evaluated on eclipse jdt swt aspectj and zxing .
the coverage score for this paper across the ohloh universe is .
.
the low coverage does not mean that the results are invalid or not useful.
rather it yields additional insight into the technique .
for example a ll projects used in this paper were java and c codebases aimed at developers swt and zxing are li braries eclipse jdt and aspectj are tools for java development for a universe of developer oriented java libraries and tools the coverage score would likely be higher.
as the paper demonstrated bugs reported against libraries and java tools contain relevant information to help identify fix locations.
thus others building on this work might also evaluate on java tools and libraries.
other avenues of research include investigating whether the approach also works well for codebases where bug reporter s are not as likely to be developers.
coverage scores do not increase or decrease the importance of research but rather enhance our ability to reason about it.
.
the quest for generality the discussion from the previous subsection leads to a related point.
few empirical findings in software engineering are completely general .
a finding that is true in the context of large scale java development for enterprise server on a ten year old codebase may not hold for a relatively new android widget.
there may be fear when reporting results and trying to achieve generality that unless some hypothesis is confirmed in all cases it is does not contribute to the body of knowledge in software engineering and is not fit for publication.
this isn t so.
kitchenham s work on within and cross company effort estimation showed that it is indeed possible to estimate effort of one project based on history of others but that there is no general rule for effort estimation.
rather they used regression analysis to find that similarities in the size of the development tea m number of web pages and high effort functions between projects in different companies are related to similar effort requirements i.e.
different projects have different effort requirements but projects that are similar to each other have similar effo rt needs .
knowledge can be synthesized even when empirical results differ along dimensions in the space .
systematic reviews rely upon this principle.
the recent review of fault prediction performance by hall et al.
essentially constructed a space consisting of modeling techniques metrics used and granularity and found that fault prediction approaches performed differently.
however they were also able to conclude that simpler modeli ng techniques such as na ve bayes and logistic regression tended to perform the best.
in the same way selecting projects that cover a large area in the project universe and examining where results are valid and where they are not does give deeper insigh t into the research results.
as murphy hill et al.
explain simply explaining the context in which a study occurs goes a long way towards creating impactful research because this allows someone to decide whether your research applies to her.
results that differ can still have value especially in a space that is highly covered.
.
reporting coverage we have provided a technique for computing coverage scores for samples and for selecting a sample o f software projects with high coverage .
while selecting projects in a rigorous and systematic way is important reporting in a consistent and consumable manner is just as important.
most papers include a summary of characteristics of the projects included e.g.
size age number of checkins number of contributors language .
this is an appropriate place to report the coverage of the selected sample of projects.
as illustrated in s ection the universe and the space that is used should also be explicitly described and the rationale provided.
how was the universe chosen?
why was each dimens ion in the space selected?
for example one might select only java projects as a universe if a technique only makes sense in the context of java.
if projects from different parts of the space show different results they should be reported and discussed.
differences by dimension or location in the space provide a unique opportunity to refine theories and investigate further.
finally i ssues in sampling can affect external validity .
any potential problems or gaps in coverage should be dis cussed in a secti on discussing validity usually entitled threats to validity or limitations .
always report the universe space and configuration with any coverage score.
.
next steps what do we hope will come from this work?
our goal has not been to claim or imply tha t prior work is flawed but rather to show that we can improve our practice and provide methods to do so.
it is our hope that researchers will begin to select projects in a more systematic way and improve the reporting on why projects were selected .
the concepts introduced in this paper can also be exploited for replication studies either to strictly replicat e a study on similar sample s or otherwise to replicate on different samples in order to determine whether the previously observed results generali ze.
we realize that different studies and techniques are aimed at different problems and thus the goal may not always be to achieve maximum coverage of all software projects.
further more the dimensions that people care about may differ.
for instance whe n evaluating techniques for mining api rules the age of each project may not be of concern.
our technique is general enough that researchers can define their own universe the population they want to target with their research and space the dimensions that are relevant for their research .
but it does little good if each study reports its coverage using different and opportunistic spaces and universes.
we hope that this work sparks a dialog about diverse and representative software engineering research and that some level of consensus on what universes and spaces are appropriate will be achieved.
for some areas finding appropriate dimensions that relate to generality and can be easily quantified might be chal lenging.
it is likely that different subdisciplines will arrive at different answers to these questions which we feel is reasonable.
.
related work we identified related work in the areas of representativeness reporting guidelines and software testing.
representativeness some of the earliest research studies on representativeness were by kahneman and tversky .
in their study they stated that the sample size is not related to any property of the population and will have little to no effect on judgment of likelihood .
in their experiments they determined that people s perception of the likelihood of an event dep ended more on its representativeness to the population than the size of it.
thus they concluded that there is a difference between people s judgment and the normative probabilities.
they call this the representative heuristic .
in a more recent study ni lsson et al.
investigated the cognitive substrate of the representativeness heuristic.
in our study we borrow the concept of representativeness from them.
however unlike their studie s we are not evaluating the likelihood of an event or how people s perception differs from the actual probability of an event.
we rather propose the means to measure the representatives of the sample software systems used in the case study to the popul ation the relevant universe of software .
selecting samples for case studies has been a challenge in fields such as clinical trials social sciences and marketing for decades.
hence studies such as the one by robinson et al.
evaluated selection biases and their effects on the ability to make inferences based on results in clinical trials.
they found that biases did exist certain subgroups were underrepresented e.g.
women while others were ov errepresented e.g.
blacks .
their statistical models found that the selection biases may not influence general outcomes of the trials but would affect generalizability of results for select subgroups.
representativeness in software engineering another area of research that often encounters the issue of representativeness is the field of systematic literature reviews.
if the set of studies selected to be a part of the literature review is not representative of the research field under study the n the conclusions of the reviews can potentially be biased.
hence a variety of guidelines that are written for conducting systematic literature surveys place a large emphasis on the selection of the studies that will be included in the review .
all the guidelines suggest that the researchers conducting the review must make the selection and rejection criteria clear for the reader to place the conclusions in context.
in literature review studies researcher s are not looking for a represen tative or diverse but rather a complete sample.
the goal in literature reviews is to obtain every possible sample before including or rejecting them from the study.
hence steps such as searching the gray area of publications and asking experts in the fie ld are suggested to obtain a more inclusive initial sample.
one line of research that attempts to rigorously achieve generality is the work on the cocomo cost estimation model by boehm et al.
.
in this model they collect software development project data and model it in order to help estimate and plan for the cost effort and schedule of a project.
the center for systems and software engineering at the university of southern california t o this day collects data to have a more representative dataset of projects and to calibrate the model in order to provide better estimates .
kemerer in his validation of software cost estimation mod els found that using an untuned cost estimation model can produce inaccurate estimates up to in some cases .
in a more recent study chen et al.
examined how to prepare the available data in order to obtain better estimates.
unlike chen et al.
s work we do not provide techniques to pre process an individual dataset.
our research goals are more similar to the rese arch goals of the cocomo model.
the cocomo model builds a statistical model with the available datasets.
then it tries to fit the current project that needs estimation in this model to determine the particular space in the universe that this project bel ongs to.
we use similar concepts but attempt to determine how diverse the current set of projects is in terms of the universe.
reporting guidelines there have been several studies in software engineering on guidelines for conducting and reporting empiric al software engineering research.
.
most of these studies focus on the process to be followed in an empirical study.
one of the common theme s is that all of the studies include a set of guidelines for reporting the experimental setting.
this description will help the reader in understanding the context of the study and allows future researchers to replicate the study.
with respect to the sa mple of software systems used in the experiments these studies do not discuss how to select the sample but rather discuss what to report about the selection.
unlike these studies in our work we present a technique for quantifying the coverage of a samp le with respect to a population universe thereby helping people to better understand the context under which the results of a study are applicable.
software testing a key step in software development is testing the software to identify software componen ts that may have bugs due to the current set of changes that have been applied to the software.
ideally in this step it is best to re run all available test cases to give the best confidence that all components are bug free.
however due to limited resou rces this may not be possible and hence a test case selection strategy has to be adopted.
the primary goal of a test case selection strategy is to identify the minimal set of test cases that are required to be re run so that the quality of the entire sof tware can be assured at a certain acceptable level.
therefore we can think of test case selection as the process of identifying a relevant sample from all the available test cases that covers the set of changes made by a developer .
the software testing community has extensively studied test case selection strategies .
a set of the different approaches that have been proposed for regression test selection is presented in the survey by yoo and harman .
they identify a set of open research problems that have not been received much attention in the testing community.
graves et al.
and rothermel and harrold in their respective research also present different test case selection techniques that are available and also empirically compare these techniques.
orthogonal array testing is a b lack box testing technique used when the number of inputs to a system is relatively small but too large to allow for exhaustive testing of every possible input to the systems .
permutations are chosen in such a way that responses each give a unique piece of information .
although related the approaches for orthogonal array testing are not a good fit for the universe and spaces described in this paper.
first there is a large number of potential input values for example there are main programming lang uages and many different magnitude for size of projects in terms of lines of code and developers.
second the dimensions in the space are not statistically independent one of the key assumptions of orthogonal array testing and many of the permutations i dentified may not exist in the universe for example a haskell project with contributors and only commits in the last twelve months .
the techniques in this paper consider only projects that exist in the universe.
similar to picking test cases or parameter value s to assure a certain level of quality in our research we intend to pick a set of projects from a universe to be used in a case study that is diverse enough such that the claims made in the case study are more reliable.
at the same tim e there are some differences for test coverage a line or method or basic block has to be actually executed in order to be counted for the coverage score.
in contrast for sample coverage it is sufficient if a similar project has been included in the sa mple.
in addition test selection strategies have different objectives they optimize test executions in order to reveal failures fast i.e.
the defect detection likelihood.
the techniques presented in this paper optimize for maximizing diversity of a s ample instead.
.
conclusion with the availability of open source projects the software engineering research community is examining an increasing number of software projects to test individual hypothesis or evaluate individual tools.
however m ore is not ne cessarily better and the selection of projects does count as well.
with this paper we provide the research community with a technique to assess how well a research study covers a population of software projects.
this helps researchers to make informed de cisions about which projects to select for a study.
our technique has three parameters universe space and configuration which all can be customized based on the research topic and should be reported together with the coverage for any sample that is sc ored.
in our future work we will further quantify the trade off between efficiency and effectiveness if one reduces the number of projects while keeping the same coverage one can save time efficiency or one can increase the number of projects and increase coverage and the effectiveness of research.
to achieve the maximum effectiveness for a given experimental effort it will be important to quantify the impact of a lack of coverage on the results reported for s oftware engineering experiments.
we hope that this work sparks a dialog about diverse and representative research in software engineering and that some level of consensus on appropriate universes and spaces will be reached which likely will differ across different subdisciplines.
we al so hope that more datasets will become available that allow us to explore alternative universes and spaces.
our technique also extends to researchers analyzing closed source projects.
they can now describe the universe and space of their projects without revealing confidential information about the projects or their metrics and place their results in context.
companies can use our technique to place academic research into the context of their own development by computing the coverage against a company specific universe and space.
.