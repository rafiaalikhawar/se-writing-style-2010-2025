synthesizing api usage examples raymond p.l.
buse and westley weimer department of computer science university of virginia charlottesville va usa fbuse weimerg cs.virginia.edu abstract key program interfaces are sometimes documented with usage examples concrete code snippets that characterize common use cases for a particular data type.
while such documentation is known to be of great utility it is burdensome to create and can be incomplete out of date or not representative of actual practice.
we present an automatic technique for mining and synthesizing succinct and representative human readable documentation of program interfaces.
our algorithm is based on a combination of path sensitive dataflow analysis clustering and pattern abstraction.
it produces output in the form of well typed program snippets which document initialization method calls assignments looping constructs and exception handling.
in a human study involving over participants of our generated examples were found to be at least as good at humanwritten instances and were strictly preferred to state of the art code search.
i. i ntroduction professional software developers spend most of their time trying to understand code .
maintaining and evolving high quality documentation is crucial to help developers understand and modify code .
in reports by and studies of developers api use examples have been found to be a key learning resource .
that is documenting how to usean api is preferable to simply documenting the function of each of its components.
one study found that the greatest obstacle to learning an api in practice is insufficient or inadequate examples.
we present an algorithm that automatically generates api usage examples.
given a data type and software corpus i.e.
a library of programs that make use of the data type we extract abstract use models for the data type and render them in a form suitable for use by humans as documentation.
the state of the art in automated support for usage examples in known as code search .
typically the problem is phrased as one of ranking concrete code snippets on criteria such as representativeness and conciseness.
in zhong et al.
described a technique called mapo for mining and recommending example code snippets .
more recently kim et al.
presented a tool called exoadocs which also finds and ranks code examples for the purpose of supplementing j avadocembedded examples .
such examples can be useful but they are very different from human written examples.
mined examples often contain extraneous statements even when slicing is employed.
in addition they often lack the context required to explicate thematerial they present.
in general mined examples are long complex and difficult to understand and use.
good humanwritten examples on the other hand often present only the information needed to understand the api and are free of superfluous context.
human written documentation has two important disadvantages however it requires a significant human effort to create and is thus often not created and it may not be representative of or up to date with actual use.
in this paper we present a technique for automatically synthesizing human readable api usage examples which are well typed and representative.
we adapt techniques from specification mining to model api uses as graphs describing method call sequences annotated with control flow information.
we use data flow analysis to extract important details about each use beyond the sequence of method calls such as how the type was initialized and how return values are used.
we then abstract concrete uses into high level examples.
because a single data type may have multiple common use scenarios we use clustering to discover and coalesce related usage patterns before expressing them as documentation.
our generated examples display a number of important advantages over both state of the art code search and human written examples both of which we compare to in a human study.
unlike mined examples our generated examples contain only the program statements needed to demonstrate the target behavior.
where concrete examples can be needlessly specific our examples adopt the most common types and names for identifiers.
unlike human written examples our examples are by construction well formed syntactically and well typed.
where previous approaches to code ranking adopted simple heuristics based on length and a simple use count e.g.
our abstract examples are structured and generated with a robust and well defined notion of representativeness.
because our approach is fully automatic the examples are also cheap to construct and can be always upto date.
additionally their well formedness properties make them ideal automated tasks like for code completion .
the main contributions of this paper are a study of api usage examples.
we characterize goldstandard human written examples from the java sdk.
furthermore we present results from a large survey on example quality and utility.
an algorithm for the automatic construction of exampledocumentation.
the algorithm takes as input a software corpus and a target data type.
it produces a ranked list of well typed human readable code snippets which exemplify typical use of that data type.
a prototype implementation of the algorithm and a comparison of its output to human written example documentations.
a human study with over participants suggests our tool could replace as many as of human generated examples.
ii.
m otivating example in modern software development api documentation tools such as j avadochave become increasingly prevalent and variants exist for most languages e.g.
p ython doc ocaml doc etc.
.
one of the principles of j avadocis including examples for developers .
not all examples are created equal however.
features such as conciseness representativeness well chosen variable names correct control flow and abstraction all relate to documentation quality.
consider java s bufferedreader class which provides a buffering wrapper around a lower level non buffered stream.
the human written usage example included in the official java development kit version is bufferedreader in new bufferedreader new filereader foo.in while this example has the merit of being concise it shows only how to create a bufferedreader not how to use one.
by contrast our algorithm produces filereader f initialized previously bufferedreader br new bufferedreader f while br.ready string line br.readline do something with line br.close this exemplifies one common usage pattern for a bufferedreader repeatedly calling its readline method while it remains ready .
the variable names brandfwere selected from among the most common human choices for bufferedreader andfilereader and were synthesized together here no single usage example need exist that uses both of those names in tandem.
in addition the example also demonstrates the importance of control flow readline is called repeatedly but only after checking ready .
finally the initialized previously and do something with line comments indicate points where different human developers would write different code and highlight the most direct places for a developer to adapt this code example into an existing setting.
in practice there is more than one way to use a bufferedreader .
our algorithm can produce a ranked list of examples based on clusters of representative human usages.
the second example we produce is inputstreamreader i initialized previously bufferedreader reader new bufferedreader i string s while s reader.readline !
null do something with s reader.close this second example shows that other concrete argument types can be used to create a bufferedreader e.g.
a inputstreamreader can be used as well as a filereader .
in addition it shows that there is a different usage pattern that involves always calling readline but then checking the return value against null rather than calling ready .
both of the examples produced by our algorithm are well formed and introduce commonly named well typed temporaries for function arguments and return values.
it is also possible to use code search and slicing techniques to produce api examples.
such a tool from kim et al.
produces an output consisting of more than lines on the same bufferedreader query not shown .
because they lack information related program semantics slicing based approaches have trouble distinguishing between relevant an irrelevant details in an example.
in the output of kim et al.
s tool a bufferedreader is initialized with system.in .
to a new user it may be difficult to tell if this argument is necessary or as in this case coincidental.
variable names are also often too specific to the example string acl in br.readline kim et al.
s tool is less descriptive than string line br.
readline for the general case.
furthermore sliced examples do not type check out of context and include many irrelevant statements.
we seek to produce high quality usage example documentation automatically.
to do so we must first understand how humans write usage examples and what they look for in usage documentation.
iii.
h uman written usage examples in this section we present a study of human written api examples.
the purpose of this study is to establish key guidelines for automatically creating examples that share the best properties of human written ones.
we seek to determine the desired size and readability of examples and the importance of generality and correctness.
we answer such questions by analyzing examples found in the standard java api docs and through the results of a brief survey on the importance of various characteristics of examples.
a. properties of human written examples we explore the java software development kit sdk documentation because it is authoritative generally considered to be of high quality and is written for a general audience of java developers.
furthermore each example isfigure .
histogram of the sizes in lines of usage examples embedded in the standard java api documents.
tied to a specific class and not for example to a coding task or other request .
we identified examples in the java sdk by searching for pre formatted text e.g.
contained in pre or code tags and found instances.
we then manually inspected each one selecting only those consisting of java statements e.g.
ignoring lists of methods and other text .
in all we found classes of the total which contain a usage example.
length.
we first consider the sizes of examples measured in lines of code.
the full distribution of example sizes is presented in figure .
on average human written examples were lines long but the median size was lines.
while a significant number of examples are quite long we note that human written examples are typically very concise.
we hypothesize that automated examples should be of a similar length to agree with human preferences and make a suitable supplement for existing examples.
abstract initialization.
we also note that many humanwritten examples use special markers such as ellipses to indicate that an input variable should be assigned a contextspecific value.
for example the glyphindex variable in this documentation for java.awt.font.glyphmetrics int glyphindex ... glyphmetrics metrics glyphvector.getglyphmetrics glyphindex int isstandard metrics.isstandard float glyphadvance metrics.getadvance similarly an example from text.messageformat uses variables initialized with 7and a disturbance in the force which are clearly chosen arbitrarily.
int planet string event a disturbance in the force string result messageformat.format at time on date there was on planet number integer .
planet new date event we hypothesize that automatically constructed documentation should also use such abstract initialization to highlight inputs to the examples.we hypothesize that generated documentation should employ common concrete type and variable names where applicable but only when they represent truly frequent usage patterns.
the algorithm presented in this paper annotates all variable which should be initialized with additional context with an initialized previously comment.
abstract use.
many examples contained an abstract placeholder indicating where the user should insert contextspecific usage code.
for example the documentation for java.text.characteriterator makes it clear that the user should do something with or otherwise process the character cinside the loop for char c iter.first c !
characteriterator.done c iter.next processchar c we hypothesize that synthesized examples must similarly and concisely indicate where context specific user code should be placed and what variables it should manipulate.
the algorithm presented in this paper employs do something with x annotations in such cases.
exception handling.
of the examples contained some exception handling.
reasoning about programs that use exceptions is difficult for humans and also for automatic tools and analyses e.g.
.
often exceptions are caught trivially i.e.
no action is taken to resolve the underlying error or the mechanism is purposely circumvented .
this example for java.nio.
file.filevisitor is indicative try file.delete catch ioexception exc failed to delete do error handling here return filevisitresult.continue we hypothesize that tool generated documentation should mention exception handling but only when it is common or necessary for correctness.
the algorithm presented in this paper learns common exception handling patterns in the corpus and distills examples representative of exception handling practice.
b. survey results as part of the evaluation of the tool presented in this paper we conducted a human study involving over participants primarily undergraduates at the university of virginia enrolled in a class entitled software development methods which places a heavy focus on learning the java language and its standard set of apis.
details about the study can be found in section vii a. as part of the study humans were asked what factors are important in a good example?
some common themes emerged multiple uses.
users wanted examples of different ways to use the class it shouldn t model something extremely specific it should include something that the class will be most commonly used for.
documentation must be able to show multiple uses.
if you just show one example of a possible use it probably won t be the one that interests me.
we should show examples of different ways a class can be used.
the best documentation shows all the different ways to use something so it s helpful in all cases.
our algorithm uses clustering to capture multiple uses.
readability.
users wanted examples that were easy to read and understand a good example is easy to understand and read.
many were explicit readable and understandable are the most important aspects.
slicing away unrelated code was critical less irrelevant unrelated stuff in the example is better.
a key component of readability is conciseness the example should use as little code as possible and show the most basic version of the problem.
you can have additional more complicated problems if necessary.
in section vi b we empirically demonstrate that our algorithm produces readable examples.
naming.
one key aspect of readability was the choice of identifier names they should be simple and understandable.
users preferred logical variable names declaring variable names to represent what they do are clear naming of variables and variables demonstrating standard naming .
the importance of identifier names has been previously studied e.g.
.
our algorithm tracks common variable naming information from concrete source code to produce understandable variable names.
variables.
users also prefer documentation that includes intermediate variables and temporaries showing declarations and the use of many temporary variables helps to make good documentation.
the human written documentation in section ii elides temporary variables by contrast our algorithm produces well typed clearly named temporaries.
the study also included a set of likert scale questions concerning the importance of several aspects of usage examples.
the properties were size how concise is the example?
readability how easy is it to understand?
representativeness will it be useful for what i want to do?
and concreteness can i compile and use it?
.
figure shows the results.
notably readability was the most important of the four features with almost every participant ranking it as very important or important.
note that readability is judged even more important than representativeness which as been traditionally considered most important e.g.
.
representativeness and size were the next most important and concreteness was least important among the four.
however all four features were at least important on average and must thus inform the design of our automatic example documentation algorithm.
iv.
a lgorithm description figure .
human survey responses about the importance of various features of example documentation.
this section describes our documentation generation algorithm.
the algorithm is designed to produce documentation with the qualities found in human written examples section iii a and the qualities praised by humans in our survey section iii b .
figure formalizes our algorithm in pseudo code and is referenced throughout this section.
our algorithm has four key phases.
in path enumeration section iv a we statically enumerate intra procedural traces.
in predicate generation section iv b paths are merged into a smaller number of concrete uses .
conceptually each concrete use corresponds a single static instantiation of the target type.
the third step applies a clustering algorithm to identify groups of concrete uses that are similar section iv c .
these clusters are then merged into a small set of abstract uses which intuitively correspond to the ways the class is used in the corpus.
finally we sort the abstract uses by their representativeness flatten them into a best method ordering and distill them into human readable documentation section iv d .
a. path enumeration for efficiency we first filter the entire corpus selecting only files that include a reference to the target class.
we then process each method in each of the remaining classes of the corpus in turn.
note however that example generation does not require complete coverage of a corpus.
once a sufficiently large number of examples are found such that the model becomes stable the process can terminate.
we first enumerate the loop free control flow paths of each method figure lines our analysis is thus pathsensitive and potentially exponential.
we obtain loop free paths by adding a statement to a path at most once in effect we consider each loop to either be taken once or not at all.
this decision can occasionally result in imprecise or incorrect documentation however we see in section vii that this occurs infrequently in practice.input target class t. input software corpus corp .
input distance metric on concrete uses dist .
input clustering parameter k. input least upper bound operator on statement set t. input comparison operator on statement lattice v. path enumeration letpaths for all methodmincorp do ifmreferencestthen paths paths enumerateacyclicpaths m symbexe use seeds letseeds letsymexe paths for all corpus paths path inpaths do letsymexe path for all statementsstmt inpath in order do hpathpreds sym regi symbexe path stmt for allhp qi2symregdo symexestmt stmt symexe path symexe path hsymexestmt path preds stmti for all sub expressions einstmt do ifematches new s ematches obj d typeof d t eis a function parameter typeof e t then seeds seeds feg symexe paths symexe paths fsymexepathg concrete uses letconcrete uses for all expressionsseed inseeds do letseed paths for all pathspinsymexepaths do letsliced path fsjs2p seed is a sub expression of sg seed paths seed paths fslicedpathg letnodes fsj 9p2seed paths s2pg letedgew s1 s2 jfpjp2seed paths p s s gj concrete uses concrete uses fhnodes edge wig for allc2concrete uses do normalizeedgeweights c abstract uses letclusters kme k concrete uses dist for all clustersc2clusters do letnodes tfabstj9hn ei2c abst2ng for allhabst abst 2i2nodes do abstedgew abst abst for allhcon con 2i2n hn ei2cdo ifcon 1vabst con 2vabst 2then abstedgew abst abst e con con letordered argmax s1 sn2nodes !flow s1 sn abst edge w output generatecode ordered figure .
high level pseudo code of our algorithm.
b. predicate generation next we use symbolic execution to compute intraprocedural path predicates logical formulae that describe conditions under which each statement can be reached figure line .
to obtain these formulae each control flow path is symbolically executed.
we track conditionalstatements e.g.
ifandwhile and evaluate their guarding predicates using the current symbolic values for variables.
we collect the resulting predicates in conjunction they form the path predicate for a given statement in the method.
in addition to the statement itself and its path predicates we also record a version of the statement where each subexpression is replaced by the current value of that expression from the symbolic register file lines .
for example x.add s might becomefnew linkedlist g.add hello .
next we identify use seeds expressions which represent a static instantiation of the target type new object allocations field