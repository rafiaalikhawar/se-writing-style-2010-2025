self adaptive software meets control theory a preliminary approach supporting reliability requirements antonio filieri carlo ghezzi alberto leva martina maggio dipartimento di elettronica e informazione politecnico di milano piazza l. da vinci milano italy ffilieri ghezzi leva maggio g elet.polimi.it abstract this paper investigates a novel approach to derive self adaptive software by automatically modifying the model of the application using a control theoretical approach.
self adaptation is achieved at the model level to assure that the model which lives alongside the application at run time continues to satisfy its reliability requirements despite changes in the environment that might lead to a violation.
we assume that the model is given in terms of a discrete time markov chain dtmc .
dtmcs can express reliability concerns by modeling possible failures through transitions to failure states.
reliability requirements may be expressed as reachability properties that constrain the probability to reach certain states denoted as failure states.
we assume that dtmcs describe possible variant behaviors of the adaptive system through transitions exiting a given state that represent alternative choices made according to certain probabilities.
viewed from a control theory standpoint these probabilities correspond to the input variables of a controlled system i.e.
in the control theory lexicon control variables .
adopting the same lexicon such variables are continuously modified at run time by a feedback controller so as to ensure continuous satisfaction of the requirements despite disturbances i.e.
changes in the environment.
changes at the model level may then be automatically transferred to changes in the running implementation.
the approach is methodologically described by providing a translation scheme from dtmcs to discrete time dynamic systems the formalism in which the controllers are derived.
an initial empirical assessment is described for a case study.
conjectures for extensions to other models and other requirements concerns e.g.
performance are discussed as future work.
keywords adaptive software control theory dynamic systems non functional requirements reliability run time verification.
i. introduction software systems are increasingly required to be selfadaptive.
if certain requirements change they must be able to adapt their behavior to keep satisfying them.
moreover they should be able to detect changes in the environment in which they are embedded and automatically adapt their behavior to prevent violations of the expected quality attributes functional and nonfunctional they must fulfill.
in this paper we focus on systems that must guarantee certain reliability requirements expressed quantitatively as constraints on the probability of reaching certain failure states.
furthermore we focus on changes that occur in the environment in which the application is situated which may lead toreliability vulnerabilities.
the typical scenario we implicitly refer to is a service oriented application soa that composes a number of existing internal or external services through a workflow service orchestration .
the external services may have their own failure profiles which affect the overall reliability of the composite application.
external services are viewed as part of the environment since they are not under control of the application and may evolve autonomously.
for example their failure profile may change dynamically due to the upload of a new version of the application or changes in the delivery infrastructure.
user profiles are another possible environment phenomenon affecting the application.
in our context user profiles can be modelled as the probability that different options are selected by the user whenever there are choices in the interaction with the composite service.
in this paper we focus on self adaptation at the model level.
that is we assume that a model of the application is kept alive at run time .
we further assume that adaptation is performed at the model level and then reified at the implementation level.
we assume that the composite application is formally modeled by a discrete time markov chain dtmc .
dtmcs are known as a useful formalism to describe systems from the reliability viewpoint and to support reasoning about it.
since a dtmc is just a finite state machine with probabilities attached to transitions it can easily model service invocations that may fail by two transitions exiting a certain state respectively representing success and failure and user profiles by transitions exiting a given state and representing different choices made by users.
reliability requirements may be typically expressed as reachability properties i.e.
as a relational formula constraining the probability of reaching certain states that represent failure situations.
to support self adaptation this paper explores a novel approach based on control theory see figure .
we assume that our goal is to maintain a certain reliability profile for the application being designed.
for simplicity let us assume the profile to simply be a certain target value of the overall probability of failure.
the output is a sequence of events that represent successes or failures.
the sequence of events is transformed into the actual probability of failure by the learning block .
this block transforms a sequence of failureevents into a probability typically using a bayesian approach as discussed in .
blocks system andcontroller in figure represent the modeled system and the controller respectively.
the goal of the controller is to provide input values to the system so that the resulting output the observed sequence of failure and success events does not violate the requirement expressed by the target despite disturbances .
controller system learning block target actual input output fig.
.
block diagram of the controlled system.
to understand what inputs and disturbances are in our context we must first discuss how we deal with adaptation at the model level.
we assume that the software model describes all possible variations that may be chosen to support adaptation.
that is the modeler anticipates a number of ways through which the system may self adapt its behavior.
in a dtmc framework choices can be expressed by using probabilities which label transitions corresponding to the choice of different behaviors.
by changing these probabilities it is possible to either increase or decrease the chance that a certain functionality is selected.
in the extreme case by setting a probability to or a certain functionality is either excluded or included.
these probabilities are inputs of our controlled system generated by the controller.
by changing them the controller tries to ensure continuous satisfaction of the target reliability despite disturbances.
disturbances in turn are changes in the independent variables also modeled by transition probabilities that represent physical phenomena like changes in the failure probability of external services or in the user profiles.
to the best our knowledge the control theoretical approach illustrated in this paper is a novel contribution to self adaptive system models.
in this paper we illustrate the approach and provide an initial experimental assessment.
the paper is organized as follows.
section ii introduces the claims of this work and sketches the use of software models and abstractions for dynamic adaptation and control.
in section iii a dtmc model for reliability is described and the case study used in the rest of this paper is presented.
section iv proposes a way to translate dtmc models into discrete time dynamic systems.
the control of the resulting dynamic system is shown in section v that provides formal properties assessment and shows the application of the proposed technique to the chosen case study evaluated in section vi.
related works are described in section vii while section viii concludes the paper.ii.
c ontrol theory and software modeling the dynamics of software execution are very complex.
nonetheless being able to control those dynamics would mean having a software capable to adapt and on line tune itself to meet the specified requirements.
however the presence of intrinsic non linearities the variety of usage profiles the distribution process and the interconnection of heterogeneous components are some of the reasons why it is so hard to directly provide a comprehensive behavioral model suitable for control.
at the same time the need for continuous verification of specific properties lead to the definition of simpler models.
these models are simple enough to allow the systematic synthesis of controllers capable of driving the modeled dynamics and still able to capture a number of aspects of the running software that significantly characterize the software behavior and support assessment of some of its properties.
in this paper we refer to a controller as any system that properly coupled to the software system makes it fulfill its requirements whenever they are feasible.
requirements can be strict constraints on the behavior e.g.
reliability equal to a certain value or related to the optimization of certain metrics on the observed software executions e.g.
minimization of outsourcing costs or maximization of throughput .
this work is aimed at supporting the claim that control theory provides a number of instruments that software engineers can exploit to ensure the achievement of extra functional design goals in presence of changes in the environment.
to do so we focus on the following main kinds of reaction the controlled system should be able to provide change of the target requirements.
if for some reason the required nominal value of the overall reliability of the composed system changes the controller should be able to drive the system toward a new operative state satisfying the requirements.
robustness to sudden changes or fluctuations around the nominal operative point assumed at design time for the environment phenomena.
interdependence among software parts and components involves the use of thirdparty services remote storage computing resources out of the control of each company and so on.
all these parts are characterized by the values of certain qos metrics usually stated in convenient service level agreements.
during normal execution those values may deviate from nominal values because of external factors hardly predictable a priori e.g.
load conditions or hardware failures .
actual values can be estimated on line via monitoring.
robustness to accuracy errors in measurement and monitoring.
to capture relevant metrics of the execution we rely on monitoring and or other measurement procedures.
each of these might get stuck into temporary bias or might require a certain time to produce an appropriate accuracy.
we look for a controller able to provide a reasonable behavior even in presence of transitory errors on measured values.
such an ability besides reducingthe sensitivity to measurement errors allows for the use of less invasive monitoring instruments sometimes required for high accuracy but expensive as performance overhead.
in the following we provide a formal assessment of these properties based on mathematical modeling and we show the practical implications with a case study.
iii.
c ontrol oriented reliability modeling in this paper we focus on reliability to ground the exposition with a practical example of the application of the proposed methodology.
the approach can be extended to similar analytical models for performance and costs see section v .
reliability is an intrinsically probabilistic property since it depends on the usage of the system and on external resources whose characteristics are often uncertain .
in order to capture the behavior of the system a widely adopted model is a discrete time markov chain dtmc .
a dtmc can be used to represent all the relevant states of a software execution and the probability to move from each state to another.
among all the states one state is the initial state1.
among the other states one or more represent the successful completion of the execution or the occurrence of a failure.
in this paper we assume there is a single success state sr .
such an assumption does not reduce the expressiveness of the model2.
failure and success states are modeled as absorbing states i.e.
states with a self loop transition labeled with probability .
the rationale here is is that we view success and failure as definitive conditions as the system reaches either condition it cannot progress any more.
all states that are not absorbing are called transient states .
formally a finite dtmc is a tuple s s0 p l where sis a finite set of states s0is the initial state p s s!
is a stochastic matrix i.e.
8si2s sj2sp si sj l s!2apis a labeling function that marks every state siwith the atomic propositions ap that are true insi.
we will interchangeably use both the notation p si sj and pijto refer to the entry i j of the matrix p corresponding to the probability of moving from state sito state sj.
a path through a dtmc is a possibly infinite sequence of states s0s1s2 where si 1is reachable from sithrough a transition.
the probability pinduces a probability space on the set of all possible paths .
the probability of a path with length ncan be defined as 1it is also possible to extend the definition by introducing an initial distribution dproviding for each state sithe probability dithat the process will start there.
the same effect can be achieved in our case by introducing a special initial state s0such that 8sip s0 si di.
2in fact one could add a single success state reachable with probability by every other state considered as successful in the general case and obtain the mentioned case.
p r ifn 0i.e.
s0 p r p s0 s1 p s1 s2 p sn sn ifn for the purposes of this analysis an execution of a software is completely described by its trace that is the corresponding path through the dtmc.
reliability is the probability of successfully accomplishing an assigned task.
in our setting it can be defined as the probability of reaching the state representing successful completion sr given that the execution started from its initial state s0 .
thus reliability is defined as p r where is the set of all possible paths starting from s0and ending in sr. given that sris an absorbing state reliability can be paraphrased as the probability of reaching sr since once reached srcannot be left.
properties of a dtmc can be expressed using the pctl probabilistic temporal logic language .
our reliability property is a particular kind of reachability property expressed by the pctl formula true u state sr where uis the until temporal operator.
the vector xwhose entries xicorrespond to the probabilities of reaching srfrom state siis computed as solution of the linear equation system in variables fxijsi2sg xi ifsi sr ifsi sris absorbing sj2sp si sj xjotherwise thus the item x0corresponds to the probability of the pctl formula true u state srevaluated in the initial state.
in our dtmc model some transitions are labeled with variable probability values.
these transitions belong to two classes.
one class represents unknown or changing behaviors exhibited by the environment which may influence the overall behavior of the application and hence satisfaction of the overall requirements.
an example may be the set of transitions exiting a given state which represent different options that a user may select in an interactive state whose labels represent the probabilities that different choices are selected.
in the realistic case where user profiles may change transition probabilities are labeled as variables.
the value of such variables representing the disturbances is dynamically computed by monitoring the application at run time collecting concrete real values and then inferring the associated probability through a learning component like the one introduced in figure .
the other class represents control variables already introduced earlier whose value is generated by the controller and is input to the system s model see also figure .
these variables can be assigned any value compatible with design requirements and the constraints determined by their nature.
that is every control variable can assume a value in the set and the sum of the probabilities of the transitions leaving a certain state must be one.our objective is thus to design a controller that decides system s settings i.e.
decides control variables given the current situation i.e.
knowledge of system structure and measures or estimates of environment situation in order to keep the system satisfying its requirements.
this objective can be achieved by exploiting well established control theoretical instruments with a number of additional features relevant for the assessment of actual software quality as will be explained in sections iv and v. a. a representative example in this section we introduce a simple running case study consisting of a model for an image processing application.
the high level software model is shown in figure .
the purpose of the system is to apply a filter to incoming images followed by a beautifying post processing phase.
it is equipped with three different implementations of the filter direct filtering via internal software iterative filtering via internal software and direct filtering via outsourcing to an external service.
the dtmc system model is provided in figure .
the figure shows that all operations have a certain probability of failure represented by transitions entering state sf .
state s1 represents the point of choice between the different filtering options.
the probabilities that govern this choice and the probability of applying one more iteration after the execution of the iterative filter represented by state s2 are the control variables in our setting.
control variables are indicated by probability variables ciin figure referring to figures and c1ais the probability of choosing the iterative filter c1bis the probability of choosing the internal direct filter and thus c1a c1bthe probability of outsourcing c5is the probability of requesting another iteration of the iterative filter .
these values can be changed online by the controller while the software is executing.
the controller in fact observes the overall behavior i.e.
the overall probability of success or failure and tries to guarantee the requested global reliability requirement by adjusting the invocation probabilities.
image filtering service iterative filter internal direct filter external filter postprocessing fig.
.
schema of the software system.
we assume that all the alternatives are implemented by black box services that can be invoked and observed from outside only.
for each of these services a run time monitor collects failure or success rates and estimates its reliabilityas the probability that a invocation to the service will fail3.
it is necessary to postulate in the environment the existence of monitoring instruments .
in fact the reliability of the computational units is time varying and the overall reliability depends on these values.
even if their nominal values are known at design time unpredictable events could alter them altering as a consequence also the software behavior.
this is not uncommon since the alteration could for example simply come from sharing components with other customers so that at different times their availability depends on load conditions of computational resources.
service reliability for each server are thus just observable values subject to variations during time disturbances .
s0 s1s2 s3 s4s6 sr sfr0 r0c1a c1b c1a c1b r2 c5 r61 r r3 r4 r6s5 c5 r4r3 fig.
.
dtmc mode for the example system.
by solving the equation system for x0it is possible to obtain a closed formula that describes the explicit dependency of reliability s on control variables c and measured reliabilities r .
s r0 r6 c1a c5 r2 c5 r2 c1br3 c1a c1b r4 the formula of sshown in the equation will be later used to design the controller in sections iv and v4.
iv.
s oftware models as dynamic systems in this section we show how the dynamic evolution of the running software as observed via the corresponding dtmc model can be cast in the simple control theoretical framework of discrete time dynamic systems through which we achieve self adaptation of the behavior to react to changing conditions in the environment.
due to space limitations the background theory can not be fully stated here but the 3estimates are here assumed to be statistically correct and representative of the average or worst case depending on the desired analysis scenario.
interested readers can refer to for a deeper discussion about dtmc parameters estimation at runtime which is out of the scope of this paper.
4the same formula can be obtained by exploiting state of the art techniques from parametric model checking and dtmc analysis in interested reader can refer to books such as .
a discretetime dynamic system is described by the equations x k f x k u k dx k y k g x k u k dy k where x2 rnx u2 rnuandy2 rnyare called respectively the state input and output vectors dx2 rnxanddy2 rny the state and output disturbance vectors being those zeros if there are no variations with respect to the nominal conditions f andg are real valued vector functions of convenient dimensions and kis an integer index counting the instants not necessarily evenly spaced in time when the system undergoes an evolution step.
in a more general form f andg could depend on an arbitrary number of real valued parameters possibly time varying.
the term step k denotes the time span between the k th and the k th instant.
vector dxrepresents disturbances corresponding to observable values in the environment that affect the system s state.
vector dyaccounts for measurement errors of the controlled variables.
the first equation in is called the state equation and dictates what the system state will be at the end of step kgiven what it was at the beginning and given also the actions exerted on the system in that step that are assumed to be correctly summarized by the values of uanddxat its beginning.
the state equation represents the dynamic system s character as difference equations i.e.
owing to the contextual presence of two subsequent index values.
in other words the state equation gives the system memory of the past and explains why the same action generally yields different effects depending on the system condition when it is applied.
the input vector u represents manipulated variables that can be used to influence the system s behavior while the state disturbance dxaccounts for any action other than u i.e.
for any external entity that actually influences the system state and that in some cases can possibly be measured but never manipulated.
the second equation in is instead called the output equation.
it is not dynamic as shown by the presence of a single index value and in most problems of interest it describes what one measures vector y to appreciate the system s behavior.
the disturbance vector dyrepresents possible alterations of said measurements due e.g.
to noise but notof the actual evolution of the system state.
a key concept of control theory is that modeling an object in the form improves per se insight into that object by providing a formal model for its dynamic evolution.
in fact so naturally leads to distinguishing whether the same action yielded a different outcome than the previous time it was applied because the modeled object was in a different state or something other than that affected it or some of its parameters changed or any combination thereof .
as is well known for control system design such a distinction is of paramount importance when controlling the system as trying to counteract the wrong cause for an undesired effect can simply be disruptive.
also models like inherently givea quantitative and generally tractable meaning to the idea that the system s reaction to a stimulus is related to its previous conditions .
on a similar front observe that a model like is concerned not only with the condition that the system can possibly reach under constant inputs as k!
but also with the way the system moves in time.
more generally in the absence of disturbances and assuming complete knowledge of the system i.e.
of f g the initial state x k0 and the input trajectory u k k k0 uniquely determine the state trajectory x k and the output trajectory y k fork k0.
disturbances and or time variances may alter that nominal behavior and ultimately motivate the use of feedback as explained in the next section.
let us now specialize the general framework to the case of control oriented software modeling.
suppose that the adaptation mechanism no matter how designed acts at instants identified by an index k as in .
also let the average duration of a step be significantly longer than the time scale of the controlled system s dynamics.
translating from the control jargon to the case of interest this means for example that if at the beginning of a step some controller altered the transition probabilities of the dtmc then at the end of the same step the effects of our actions can be measured .
hence in this case model reduces to s k f r k r k c k where s k is the reliability in step k the state as defined in the general model of equation c k are the control variables set for step k i.e.
decided at its beginning and kept constant through the step r k the expected reliabilities for step k which in this example are estimated via monitoring but in other case may also be nominal and possibly constant values and r k accounts for any discrepancy between the real and expected reliabilities in step k. the form of function fstems from the dtmc model solving the associated linear system as for equation in section iii a. although model is nonlinear and time varying it has the very interesting property of being a pure delay system i.e.
the state vector does not appear on the right hand side of the state equation the output being sitself.
in system theoretical terms what is here done is taking the steady state model coming from dtmcs and using it in a dynamic framework under the assumption that any action at the beginning of a step has exhausted its effect at the end of that step.
v. c ontrolling the system sdynamics by feedback in a nutshell the idea of feedback can be summarized as plugging the controlled system into a larger one where its input is made dependent on its measured output possibly its state or an estimation of it in the case it cannot be measured and on the desired behavior for the controlled system.
additionally disturbance measurements can be brought into play if available.
recalling model this means in general setting up a control law in the form xc k fc xc k w k by k bx k bdx k bdy k u k gc xc k w k by k where the hat symbol recalls that in the real world only measurements or estimates of some quantities are available i.e.
from now on bqmeans a measured or estimated value of q for any variable q .
in xcis the controller s state vector x in equation that refers to a general system wtheset point i.e.
the desired behavior for part of the controlled system s state and output e.g.
the desired reliability.
notice that the controller state and the desired behavior are assumed to be known exactly which is mere common sense.
the control law can be defined explicitly or as it is the case here implicitly stating the controller s state and output to be the solution of an optimization problem.
notice also that the effect of the control applied at the k th step is measurable and visible in the feedback signal at time k .
by joining and we obtain a closed loop system.
its inputs are the set point wand the disturbances dxanddy its state is the union of xandxc and its output can be taken as the set of variables for which a desired behavior is specified.
if the controller is properly designed formal guarantees can be provided on the behavior of the closed loop also in the presence of time variances and or disturbances.
due to the lack of space it is impossible here to report the underlying theory therefore we move directly to the application for the solution of the addressed problem for further theoretical details the reader can refer to .
referring to the dtmc model as the software application model there are transition probabilities that can be controlled the control variables and others that are not dependent on any action but are observable and measurable during software execution disturbances e.g.
software failures.
as previously anticipated in the following the controllable transition probabilities are identified by variables c k i.e.
the control variables.
at the same time the reliabilities r k are disturbed non controllable transition probabilities.the obtained model is therefore in the form and wis the target value for s. based on the current value s k an estimation of the future value s k is available.
such an estimation is obtained by substituting the estimated or measured reliabilities in the function fand using the control variables computed for step k notice that any measurements of sinclude the effect of dy s k f r k c k now let j k fj c be a cost function on the control variables c k .
for example consider the two control variables c1a k c1b k that stand for the probabilities of sending the incoming request to three different services the third one is constrained to be c1a k c2b k the cost of those values could be the cost of sending the request to each of the available services.
when there is no mapping between the software the dtmc is modeling and a cost function naturally derived fromthe domain of the application5 the designer can introduce a non informative cost function such as a constant value to indicate no preferences among all the feasible solutions.the controller comes into play by solving the optimization problem minj c subject to the constraints jjw s k jj jjw s k jj 8ci k ci k where is a value in the range that affects the convergence rate of the solution that is in the next step we expect the absolute error to be reduced by a factor .
the set of constraints has to be extended with probabilistic constraints the sum of outgoing transitions from each state has to be as done for the control variables ci.
formal assessment to start notice that for each step kwhere a solution of the optimization problem exists the error w s k has an exponential decay.
this is obtained by construction based on how the controller was designed first constraint in .
moreover under the same assumption the time to converge to the desired solution is known.
let e be the initial error w s then e k ke according to the exponential decay.
if one assumes the system converged when the error e k then in nominal conditions this happens when k log e if the system is no more in nominal conditions i.e.
if r k is not the value for r k expected at design time the proposed solution is robust whenever a solution is found for the optimization problem.
in fact in such a case the first constraint of holds.
in the ideal case s k s k .
suppose now that there is an additive term due to a difference in the estimation ofr k r k r k and therefore s k s k s k .
the error norm becomes jjw s k s k jjand the following equations hold jjw s k s k jj jj w s k jj jj s k jj jjw s k jj jjw s k jj notice that the second equation of comes from the existence of a solution for the optimization problem.
as a consequence in the presence of a solution the stability still holds while the convergence time equation does not hold anymore.
however if jj s k jj jjw s k jj the error norm is guaranteed to diminish albeit not at the unfeasible desired rate.
some words deserve to be spent on the role of .
the closer is to zero the faster is the system convergence.
however when the error is closer to zero there could be 5cost estimation methodologies in the context of software reliability is an open research field.
the interested reader could refer for example to .oscillations when changes occur as testified by the inequality .
on the contrary when approximates one the system convergence is slow the oscillations could occur potentially before the error approaches zero but are less intense.
notice however that the performed analysis is very powerful and we are using the triangle inequality to upper estimate the norm of the difference with the sum of the norms.
this is definitely a coarse overbound and makes the proposed assessment remarkably conservative.
such a characteristic is however shared by numerous robustness related control theoretical results and historically accepted in exchange for easily applicable criteria.
the interested reader can find a discussion in .
the situation in which the optimization problem has no feasible solutions triggers the intervention of a higher level controller or even a human operator because there is no control variable assignment that can further reduce the error.
however the employed solver goes as close as possible to the unfeasible constraint therefore reaching the optimum value that is reachable in the system conditions.
although a complete treatment of the matter is deferred to future works an intermediate and all in all effective solution can be to employ reliability estimates to possibly recompute the set point as the feasible value nearest to the desired one.
if this is done the previously devised results apparently apply and permit a possibly suboptimal but very simple management of the situation.
vi.
e xperimental evaluation as anticipated the design of the control system starts from the closed formula expression defined in equation .
for the proposed case study the control system acts minimizing j c j1ac1a j1bc1b j5c5 where j1a j1bandj5are equal to one therefore assuming all costs are equals.
in the case study the first constraint of equation is considered with an equal sign supposing that the requirement is that the system expose exactly a certain reliability.
in our first experiment the reliability required over time is changed to show how the controller reacts to changes in the desired value.
the simulation is divided into four different slots each having 25time units.
during the first slot the reliability requirement is set to while in the following one it is .
in the third slot the desired reliability is and it increases to 6in the last slot.
all these numbers are feasible considering the reliabilities of the involved services.
figure depicts the overall system reliability s over time.
figure shows the control signals c1ais represented with a dashed line while c1bis the continuous curve the dashed dotted line shows how c5changes over time.
perturbations to the nominal model were added in the form of disturbances to the services reliabilities ri in order to show the controller convergence previously formally proved.
the expressions of the reliabilities are .
.
.
.
.
time unitsreliabilityfig.
.
reliability of the system set point dashed and achieved value solid .
r0 02stp k 20stp k 10stp k r2 02stp k 20stp k 15stp k r3 02stp k 97stp k 50stp k r5 r8 05stp k where stprepresents the step function6andkcounts the time units.
the changes in the reliabilities are introduced to test the control system ability to respond to external variations.
notice thatr3goes to zero in the time interval k 65therefore accounting for the complete failure of the internal non iterative filter.
the control system sharply counteracts the failure of the internal direct filter changing the control variables as can be noted in figure at time k .
.
.
.
.
time unitscontrol variables fig.
.
control variables of the system c1adashed c1bsolid and c5dashed dotted.
this experiment allows us to test the response to both transient behaviors e.g.
small variations of the operating conditions and to changes of the operative scenario e.g.
the complete failure of a service.
6stp k ifk 0and0otherwise.one may also consider the cost of a service as a time varying parameter of the control system.
we tested the same system where the cost of the iterative filter j1b becomes in the interval k .
figure shows the control variables in this case.
notice that the reliability set point is attained obtaining the same results shown in figure .
with this test we demonstrated that the system is able to attain the set point specification and to minimize the cost of the overall solution also in the presence of different operating conditions for example changes of service costs.
fig.
.
control variables of the system c1adashed c1bsolid and c5dashed dotted.
notice that intuitively figures and are equal except for the mentioned interval where costs are modified.
in figure the control system changes the transition probabilities to make the software system perform as in figure according to the differences in the cost function for the diverse software stages.
the overall cost is therefore minimized.
vii.
r elated work adaptation is playing a key role in the development of software applications .
compiler level advancements have been developed to support adaptive implementations for performance or power and low level architectures are dynamically adjusted and targeted .
control theory is capturing an increasing interest from the software engineering community that looks at selfmanagement as a means to meet qos requirements despite environmental changes and fluctuations of external phenomena.
examples of this trend can be seen in research on control of web servers data centers and clusters management and operating systems .
self management techniques are also prominent in industry e.g.
companies like ibm see projects like the ibm touchpoint simulator the k42 operating system oracle oracle automatic workload repository and intel intel ras technologies for enterprise .
the application of control theory in software engineering however is still in a very preliminary stage.
developing accurate system models for software is in fact hard.
moreover strong mathematical skills are needed in order to deal withcomplex non linear dynamics of real systems .
these difficulties usually lead to the design of controllers focused on particular operating regions or conditions and ad hoc solutions that address a specific computing problem using control theory but do not generalize .
for example in the specific problem of building a controller for a .net thread pool is addressed.
to the best of our knowledge control of software through a dtmc model capturing its reliability related properties was not explored previously.
moreover the approach proposed in this paper in general for any reachability property over dtmcs regardless of the specific application.
hence it can be applied in general.
concerning the control of markov processes most of the approaches in literature cover only special cases.
a general control approach for continuous time markov chains ctmcs has been proposed by brockett in .
the goal of the controller is to set the value of control transition rates in order to control selected transition rates through minimizing a quadratic cost function over the controls.
we are considering brockett s model to apply the methodology presented in this paper for performance driven adaptation of software systems.
viii.
c onclusions the application of control theory to the systematic construction of adaptive software is a challenging and potentially very valuable approach.
this paper has just scratched the surface by focusing on adaptation of a specific class of models discrete time markov chains dtmcs for a specific class of requirements that need to be preserved global reliability expressed through a reachability property specific phenomena whose changes may lead to requirements violations changes that may be expressed as updates in certain probabilities associated with transitions and a specific way to attempt adaptation by controlling the model generating new values for other probabilities which represent control variables .
future research will need to generalize beyond all the specifics .
for example future research should be dealing with other formal models that may address other classes of non functional properties e.g.
continuous time markov chains to deal with performance or markov reward models to deal with costs and with multi objective goals to achieve and preserve.
moreover on the modeling side the overall chain could be modeled introducing also other aspects of the software execution e.g.
service rates.
the resulting model would become nonlinear since the state is directly affected by the control variables the inputs in a multiplicative way.
this brings into play more complex control solutions and opens interesting perspectives also for control researchers.
acknowledgment this research has been partially funded by the european commission programme ideas erc project smscom.