Boosting Path-Sensitive Value Flow Analysis via
Removal of Redundant Summaries
Yongchao Wang, Yuandao Cai, and Charles Zhang
Department of Computer Science and Engineering
The Hong Kong University of Science and Technology, Hong Kong, China
Email: {ywanghz, ycaibb, charlesz }@cse.ust.hk
Abstract â€”Value flow analysis that tracks the flow of values
via data dependence is a widely used technique for detecting a
broad spectrum of software bugs. However, the scalability issue
often deteriorates when high precision (i.e., path-sensitivity) is
required, as the instantiation of function summaries becomes
excessively time- and memory-intensive. The primary culprit, as
we observe, is the existence of redundant computations resulting
from blindly computing summaries for a function, irrespective
of whether they are related to bugs being checked. To address
this problem, we present the first approach that can effectively
identify and eliminate redundant summaries, thereby reducing
the size of collected summaries from callee functions without
compromising soundness or efficiency. Our evaluation on large
programs demonstrates that our identification algorithm can
significantly reduce the time and memory overhead of the state-
of-the-art value flow analysis by 45% and 27%, respectively. Fur-
thermore, the identification algorithm demonstrates remarkable
efficiency by identifying nearly 80% of redundant summaries
while incurring a minimal additional overhead. In the largest
mysqld project, the identification algorithm reduces the time by
8107 seconds (2.25 hours) with a mere 17.31 seconds of additional
overhead, leading to a ratio of time savings to paid overhead (i.e.,
performance gain) of 468.48 Ã—. In total, our method attains an
average performance gain of 632.1 Ã—.
Index Terms â€”value flow analysis, inter-procedural analysis
I. I NTRODUCTION
Path-sensitive value-flow analysis [1]â€“[11] is highly effec-
tive in detecting a broad spectrum of software bugs, such
as memory leaks in resource usage, null pointer dereference
in memory safety, and the propagation of tainted data in
security properties, by tracking the flow of values along data
dependence relations. Essentially, detecting these bugs boils
down to collecting feasible source-sink paths over a program
dependence graph [1], [3]. For instance, detecting the null
pointer dereference (NPD), considering the null value as the
source and the pointer dereference statement as the sink. The
process involves a two-step process: collecting paths that link
a null value and a pointer dereference statement, and then
verifying the satisfiability of the path conditions for those
paths.
To scale the analysis to large-scale software systems with
millions of lines of code, existing approaches [3]â€“[6], [12]â€“
[14] employ a bottom-up strategy to gather feasible source-
sink paths. Specifically, when analyzing a function, these
approaches compute the intra-procedural value-flow paths and
the corresponding path conditions as function summaries. The
value-flow paths and conditions are referred to as summarypaths and summary conditions, respectively. To ensure that
only feasible summaries are collected, a constraint solver is
invoked to verify the summary condition once the summary
path is collected, despite being a computationally costly pro-
cess. To avoid redundant path searching and analysis of callee
functions, existing approaches clone the summaries of callees
and reuse them continuously to supplement the more extended
summaries collected within caller functions. The summary
cloning and summary condition verification process continues
until the highest function in the call graph (known as the root)
is reached. At this point, the algorithm can directly identify
source-sink paths by examining summary paths originating
from sources and terminating at sinks. Since each summary
path carries its corresponding path conditions, we can use
the terms â€œsummaryâ€ and â€œsummary pathâ€ interchangeably
without losing generality.
We use the buggy program shown in Fig. 1(a) to illustrate
the existing bottom-up compositional value flow analysis. We
use the symbol Ï€to represent a value-flow path, while Ï•and
Ï†represent path conditions. Moreover, the variable videnotes
that variable vis either used or defined at Line i. Specifically,
one of the function summaries for foo, represented as Ï€4in
Fig. 1(c), summarizes the propagation path of variable a2. The
variable a2receives the return value from the qux function
in Line 2 and is subsequently passed to the bar function
in Line 5. On one hand, the summary path Ï€4is generated
by combining the summaries Ï€1andÏ€3, which are collected
during the analysis of the quxandbarfunctions, respectively,
before analyzing the foofunction. On the other hand, the
summary condition Ï•Ï€4is obtained by instantiating edges and
the corresponding guards along the summary path Ï€4[3]. The
guard Ï†2of the edge p11â†’printf (âˆ—p13)is the constraint
ofp11Ì¸=NULL 12, which is instantiated when collecing the
summary Ï€3by traversing from vertex Ï†2on the program
dependence graph, shown in Fig. 1(b). Once the summary
condition Ï•Ï€4is instantiated, the summary is verified by the
constraint solver Z3[15] before it is stored. The summary
conditions Ï•Ï€1,Ï•Ï€2, and Ï•Ï€3are also verified when collected.
If a summary condition is unsatisfiable( unsat ), it is discarded
to avoid an unfeasible summary being maintained. (We provide
such a case in Appendix Section A.) Moreover, the summary
Ï€1of the quxfunction is cloned twice (cloned one denoted
asÏ€â€²
1) with different calling contexts (Line 2 and Line 3)
to account for the different propagation paths between thearXiv:2502.04952v3  [cs.SE]  12 Feb 2025ğœ™!!:m"#$=ğ‘ğ‘ˆğ¿ğ¿19$âˆ§ğ‘%=m&'$âˆ§ğ‘(=ğ‘%âˆ§ğ‘“&)=ğ‘(âˆ§ğ‘“&(=ğ‘“&)âˆ§ğ‘’(=ğ‘“&(âˆ§ğ‘’*		=ğ‘’(1.voidfoo(int*c) {2.int*a = qux();3.int*b = qux();4.int*e = NULL;5.bar(a);6.e = baz(b);7.if(ğœ‘&â‰¡e != NULL) { 8.printf(*c);}9.printf(*a);//NPD happens!10.}11.voidbar(int* p) {12.if(ğœ‘"	â‰¡p != NULL) {13.printf(*p);}14.}15.int* baz(int* f) {16.returnf;17.}18.int* qux() {19.int* m = NULL;20.returnm;21.}(a)CodeExample(b)ProgramDependenceGraph (PDG)(c)Functionsummariesforfooanditscallees.ğ‘ğ‘ˆğ¿ğ¿19â†’ğ‘š!"ğœ‹#:ğ‘##$!ğ‘ğ‘Ÿğ‘–ğ‘›ğ‘¡ğ‘“(âˆ—ğ‘#%)ğœ‹%:ğ‘“#&â†’ğ‘“#'ğœ‹!:
ğœ™!":ğ‘+=ğ‘&âˆ§e*â‰ ğ‘ğ‘ˆğ¿ğ¿*âˆ§ğœ™!!Pathconditions:callees:ğœ™!#:m"#=ğ‘ğ‘ˆğ¿ğ¿19âˆ§ğ‘"=m&'âˆ§ğ‘)=ğ‘"âˆ§ğ‘&&=ğ‘)âˆ§ğ‘&%=ğ‘&&âˆ§(ğœ‘"â‰¡ğ‘&&â‰ ğ‘ğ‘ˆğ¿ğ¿&&)ğœ™!$%	ğœ™!&	ğœ™!'	ğœ™!$	Valueflowpaths:foo:ğ‘#$"â‰¡)#*+,--#ğ‘ğ‘Ÿğ‘–ğ‘›ğ‘¡ğ‘“(âˆ—ğ‘.)ğœ‹/:ğœ‹0:â†’ğ‘!â†’ğ‘&â†’ğ‘ğ‘ˆğ¿ğ¿19â†’ğ‘š!"ğœ‹#ğ‘##$!ğ‘ğ‘Ÿğ‘–ğ‘›ğ‘¡ğ‘“(âˆ—ğ‘#%)ğœ‹%ğ‘ğ‘ˆğ¿ğ¿191â†’ğ‘š!"1â†’ğ‘%â†’ğ‘'â†’ğ‘“#&â†’ğ‘“#'â†’ğ‘’'â†’ğ‘’/ğœ‹':ğœ‹#1ğœ‹!â†’ğ‘!â†’ğ‘ğ‘Ÿğ‘–ğ‘›ğ‘¡ğ‘“(âˆ—ğ‘2)ğ‘ğ‘ˆğ¿ğ¿19â†’ğ‘š!"ğœ‹&:ğœ‹#
ğœ™!(:m"#=ğ‘ğ‘ˆğ¿ğ¿19âˆ§ğ‘"=m&'âˆ§ğ‘'=ğ‘"ğœ™!$	data dep.control dep.ğ‘"ğ‘(ğ‘&&ğ‘“&)ğ‘“&(ğ‘š&'ğ‘š"#ğ‘)ğ‘ğ‘ˆğ¿ğ¿19
ğ‘’(ğ‘ğ‘Ÿğ‘–ğ‘›ğ‘¡ğ‘“(âˆ—ğ‘+)ğ‘&â‰ ğ‘ğ‘ˆğ¿ğ¿*trueğ‘’*ğ‘ğ‘Ÿğ‘–ğ‘›ğ‘¡ğ‘“(âˆ—ğ‘&%)â‰ ğ‘ğ‘ˆğ¿ğ¿&"trueğ‘%ğ‘ğ‘Ÿğ‘–ğ‘›ğ‘¡ğ‘“(âˆ—ğ‘')
ğœ‘&ğœ‘"ğœ‘&ğœ‘!Fig. 1: Bottom-up analysis for the code shown in (a). The (b) shows the corresponding program dependence graph (PDG). (c)
shows the partial function summaries collected during the bottom-up analysis. Redundant summaries are highlighted in red.
summaries Ï€4andÏ€6(which summarizes the propagation
path of variable b3). This cloning mechanism eliminates the
necessity of searching for and analyzing the qux function
again, leading to improved efficiency.
The Explosive Summary Problem. However, the bottom-
up approach still faces challenges in terms of analysis time
and memory consumption. According to a report [3], a single
analysis for a project with millions of lines of code can
take several hours and require hundreds of gigabytes (GB) of
memory. The main reason for this is the exponential growth
in the size of summaries due to cloning for different calling
contexts. Even worse, exploded summaries lead to frequent
calls to the constraint solver, as each summary collection
necessitates a call to the solver. For example, in the previous
example, the summary Ï€1is cloned and stored as two copies
(Ï€1andÏ€â€²
1) within the function foo. This leads to the collection
of three new summaries Ï€4,Ï€5, and Ï€6, which eventually
result in three calls to the constraint solver. When analyzing
higher-level callers, the need for additional clones can cause
significant performance issues.
Existing techniques to improve the performance have fo-
cused on achieving efficient summary path collection [16],
[17] and the verification of summary conditions [6]. Specif-
ically, Shi [16] and Tang [17] proposed a parallel algorithm
to accelerate summary path collection, reducing the analysis
time. Shiâ€™s recent work [6] introduced a unified representation
of summary paths and summary conditions on the program
dependence graph, enabling the direct verification of summary
conditions on the PDG and eliminating the need for additional
computation and storage of summary conditions.
Our Approach. To tackle this problem, we propose the first
approach that identifies and eliminates â€œuselessâ€ summaries
while also reducing the size of collected summaries from
callee functions. Our key observation is that certain summariesin the callee functions do not contribute to any source-sink
path (even when their summary condition is satisfiable( sat))
and, thus, can be safely ignored without compromising the
analysisâ€™s precision. For example, in Fig. 1(c), the summary Ï€6
obtained from the function foodoes not lead to any bugs since
there are no dereference operations on the inlined NULLâ€²
19
from the callee function qux. As a result, it is unnecessary
to compute the summary Ï€6and solve its path condition Ï•Ï€6.
Additionally, we can further reduce unnecessary computations
by avoiding the cloning of Ï€1, not collecting Ï€2(and solving
the summary condition) to eliminate the redundant Ï€6. Our
experiments (as shown in Table I under the â€œ#Redunâ€ column)
indicate that approximately 20% of redundant summaries are
computed, solved, and maintained throughout the analysis
process on average.
The benefit of our approach is twofold. First, our approach
efficiently reduces time and memory usage by eliminating
unnecessary computations of summaries, which can become
exponentially large as the analysis progresses. Second, the
high-cost invocation of a constraint solver to verify â€œuselessâ€
summaries is subsequently avoided. These two unique advan-
tages make our approach more practical for efficiently analyz-
ing large-scale software systems. Our approach is orthogonal
and can be used in conjunction with other approaches, such as
enhancing the summary representation by employing advanced
data structures, i.e., graph structures, for representing and
resolving summary conditions [6], and effectively collecting
summaries in a parallel [17] or pipelined manner [16].
Challenges and Solutions. The challenge lies in identifying
redundant summaries precisely and efficiently without hurting
the precision of the analysis. Specifically, determining the
contribution of a summary often relies on information from
upper-layer functions that have not been analyzed yet.
Our key insight is that a useful summary should be a compo-nent of paths or path conditions associated with a source-sink
path of interest. Specifically, the summary should be reachable
from at least one pair of sources and sinks or derived from
the path conditions of the source-sink paths. In Fig. 1, the
usability of summary Ï€2is decided by evaluating its reacha-
bility with the source-sink pairs (NULL 19, printf (âˆ—a9))and
(NULL 19, printf (âˆ—p13)). That is, we assess the reachabil-
ity of the source NULL 19and the sink printf (âˆ—a9)(or
printf (âˆ—p13)) using the head f15and tail f16ofÏ€2, which are
parameter and return of function baz. They are represented as
(NULL 19, f15),(f16, printf (âˆ—a9)), and(f16, printf (âˆ—p13)).
Without considering how Ï€2will be used in caller foo, we can
still decide that Ï€2is not reachable from the two mentioned
source-sink pairs. Consequently, Ï€2is deemed redundant in the
long run and can be promptly discarded. Using this insight,
we have devised a principled, sound, and efficient contri-
bution identification algorithm powered by a novel concept,
namely contribution abstraction , to identify the contributing
summaries. We give more details in Section III.
Results. We have implemented the contribution identi-
fication (CI) algorithm based on the state-of-the-art value
flow analysis, Fusion [6], and evaluated it on 17 real-world
programs. The evaluation results show our CI algorithm can
significantly reduce the time and memory overhead of the
Fusion by 45% and 27%, respectively. Furthermore, the CI
algorithm can efficiently identify almost 80% of redundant
summaries while only incurring a minimal additional over-
head. In the largest project, the mysqld case, CI helps Fusion
save 8107 seconds (2.25 hours) with only 17.31 seconds
of overhead, resulting in a ratio of time savings to paid
overhead (performance gain) of 468.48 Ã—. Overall, CI achieves
a substantial average performance gain of 632.1 Ã—.
To sum up, this paper makes three main contributions:
â€¢We identify and address the redundant summary defi-
ciency in the prior value flow analysis.
â€¢We design the contribution identification algorithm to
identify redundant summaries efficiently and effectively.
â€¢On average, the contribution identification algorithm can
substantially enhance the performance of value flow anal-
ysis, reducing time consumption by 45% and minimizing
memory utilization by 27%.
II. B ACKGROUND AND PRELIMINARY
This section introduces the background of path-sensitive
value flow analysis and basic notations throughout the paper.
A. Background
We assume that the target program is in the static single
assignment (SSA) form [18], where each variable has only
one definition and multiple definitions are merged using a Ï•-
assignment, following many existing works [3], [7], [9], [12],
[13], [19]. All elements within an array or a union structure
are considered to be aliases. In our implementation, we have
utilized the existing methods to resolve points-to relations [3].
Program Dependence Graph (PDG). Given the program
P, PDG is constructed to characterize how a value flows from
one program statement to another through edges labeled withpath constraints. We follow the previous works [3], [7], [9] to
construct the program dependence graph, where the definition,
the use of all variables, and operators are modeled as vertices.
Definition 1. A program dependence graph for a function is
a directed graph denoted as G= (V, O, E d, Ec):
â€¢Vis a set of vertices, each of which is denoted by v@si,
meaning the variable vis defined or used at a statement
si. We write v@siasvifor short as the program is in the
SSA form. The guard vertices are denoted as VgâŠ†V.
â€¢Ois a set of operator vertices (binary âŠ•or unary âŠ—),
each of which represents a symbolic expression.
â€¢EdâŠ†(VâˆªO)Ã—(VâˆªO)is a set of directed edges.
(vi, vj)âˆˆEdmeans that the value viflows to value vj.
Edges are labeled with guards from Vgâˆªtrue , which
represent the constraints that qualify the value flow.
â€¢EcâŠ†VÃ—Vbis a set of control dependence edges.
Example 1. In Fig. 1(b), the two value flows from c1to
printf (âˆ—c8)and from p11toprintf (âˆ—p13)are qualified by the
branch expressions at Line 7 and Line 12. Therefore, the two
edges (c1, print (âˆ—c8))and(p11, printf (âˆ—p13))are labeled by
guards Ï†1andÏ†2. The expression of these branches can be
derived by searching the PDG from guard vertices Ï†1andÏ†2,
which are e7Ì¸=NULL 7andp11Ì¸=NULL 12, respectively.
To check a given value-flow path Ï€[3], the path condition
Ï•Ï€incorporates not only the value flows represented by the
edges but also the value flows related to the instantiation of
the guard vertices labeled on those edges. Note that these
two categories of value flows are not identical. The value
flows related to the instantiation of guard vertices can be
interconnected with the value flows of other paths. Thus, the
path condition Ï•Ï€often relates more paths beyond just Ï€.
Example 2. Recall Fig. 1(c), the summary Ï€7:c1Ï†1âˆ’ â†’
printf (âˆ—c8)summaries the value flow from c1toc8with
the guard Ï†1. The value flow represented by the edge is
encoded as c8=c1âˆ§Ï†1. When instantiating the constraint
represented by the guard Ï†1, which states that e7Ì¸=NULL 7,
the value flow of e7is tracked. This results in the identification
of the summary path of Ï€6, represented as NULLâ€²
19â†’
mâ€²
20â†’ Â·Â·Â· â†’ e6â†’e7. Consequently, the path condition
ofÏ€6is applied in this context. Taking all of this into
consideration, the path condition of Ï€7can be expressed as
c8=c1âˆ§e7Ì¸=NULL 7âˆ§Ï•Ï€6. Summary condition Ï•Ï€7
involves more complex value flow than summary path Ï€7due
to instantiating the constraint represented by the guard Ï†1.
Given a value-flow path Ï€on the program dependence graph
G,Ï€[i]represents iâˆ’th vertex vi@sion the path. Specifically,
we use Ï€[âˆ’1]to denote the tail element of Ï€. Given sets V1
andV2, which are subsets of the vertices Vin the PDG, we
useÎ (V1, V2)to represent the set of value-flow paths from a
vertex in V1to another vertex in V2.
The path conditions of a set of value-flow paths Î (V1, V2)
are represented as Î¦(V1, V2, Vg), The additional VgdenotesAlgorithm 1: Path-Sensitive Value Flow Analysis
1Procedure pathSensitveAnalysis( P)
2 Build call graph CG and PDG of P;
3 S(Vsrc, Vsink)â† âˆ…;
4 foreach fâˆˆCG do
5 Sf(Vfp, Vfr)â† âˆ…;Sf(Vfp, Vsink)â† âˆ…;Sf(Vsrc, Vfr);
6 foreach fâˆˆCG in bottom-up order do
7 foreach câˆˆcallees of fdo
8 collectCloneSolveSmry (Sf(Vfp, Vfr), c);
9 collectCloneSolveSmry (Sf(Vfp, Vsink), c);
10 collectCloneSolveSmry (Sf(Vsrc, Vfr), c);
11 collectSrcSinkPath (S(Vsrc, Vsink), c);
12 âˆ€(Ï€, Ï†)âˆˆS(Vsrc, Vsink),report Ï€as a bug if Ï†issat;
the set of guard vertices that necessitate instantiation during
the construction of the path conditions.
Bottom Up Value Flow Analysis. Given the PDG and bug-
specific sources Vsrcand sinks Vsink, the path-sensitive value
flow analysis is to collect Î (Vsrc, Vsink)andÎ¦(Vsrc, Vsink, Vg).
To determine the presence of bugs, each path Ï€inÎ (Vsrc, Vsink)
is evaluated by checking its path condition Ï•Ï€using a con-
straint solver. If the path condition Ï•Ï€is determined to be
sat, the path Ï€is reported as a detected bug. To scale up the
collection of Î (Vsrc, Vsink)andÎ¦(Vsrc, Vsink, Vg), the existing
path-sensitive approaches [3], [5], [6], [13], [16], [20] use
a compositional manner that analyses each function on a
call graph from the bottom. Note that existing bottom-up
analyses [3], [5], [13], [16], [20] first compute the Strongly
Connected Components (SCC) of the call graph to make it
acyclic. Then, the path-sensitive methods compute symbolic
summaries for each function. These summaries are subse-
quently instantiated in the callersâ€™ different contexts, allowing
them to be reused to merge various source-sink paths and
their corresponding path conditions, thereby eliminating the
redundant re-analysis of each function.
However, the alternative top-down approaches [21]â€“[24]
analyze functions in a call graph from top to bottom, producing
summaries for specific program contexts that cannot be reused
for all source-sink paths. Thus, they require analyzing the
same function multiple times for different calling contexts,
sacrificing path sensitivity. As a result, these approaches can
only determine the reachability of a source-sink pair without
providing the connecting paths and path conditions.
To construct complete source-sink paths, bottom-up ap-
proaches gather three types of summaries.
Definition 2 (Function Summary) .A summary for the func-
tionfis represented by a tuple s= (Ï€, Ï•Ï€), where summary
pathÏ€captures a value flow path after the callee functionsâ€™
summaries are cloned. The summary condition Ï•Ï€encodes
value flows of Ï€and value flows instantiated from guard
vertices that are labeled on Ï€.
â€¢Transfer summary S(Vfp, Vfr)summarizes value flow
paths from the functionâ€™s formal parameters Vfpto the
functionâ€™s formal return Vfr.â€¢Input summary S(Vfp, Vsink)summarizes value flow paths
from the functionâ€™s formal parameters to a sink within the
function or its callee functions.
â€¢Output summary S(Vsrc, Vfr)summarizes value flow paths
from sources to the functionâ€™s formal return. The sources
are found within the function or callee functions.
Existing work [3], [5] shows that collecting these different
categories of value flow paths is sound for bug detection.
Corresponding to VfpandVfrthat represent the sets of formal
parameters and formal return, VapandVarrepresent the sets of
actual parameters and actual return. We denote total summaries
that are collected from function fasSf(Vh, Vt) = (Î f,Î¦f).
VhandVtare the head vertices and tail vertices of the sum-
mary path that could be collected in Algorithm 1. Specifically,
Vhare the head vertices come from Vfp,VarandVsrc, and Vt
are the tail vertices come from Vap, Vfr, Vsink, and Vg.
Algorithm 1 presents the existing bottom-up summary
collection [3], [5], [6], [13], [16], [20] of S(Vsrc, Vsink)
for the given program P. In general, it is accomplished
by two helper functions: collectCloneSolveSmry
and collectSrcSinkPath . The first function,
collectCloneSolveSmry , is responsible for collecting
summaries by cloning the calleeâ€™s summaries and then
solving the summary condition, filtering out the unsat ones.
The second function, collectSrcSinkPath , collects the
source-sink paths that can be discovered after collecting the
summaries in the current function. The overall Algorithm 1
begins by constructing the CG and PDG for the program
P. It then initializes a global set S(Vsrc, Vsink)to maintain
all the source-sink paths, as well as three summary sets for
each function to maintain the three types of summaries. The
algorithm proceeds to process each function in a bottom-up
fashion, collecting three types of function summaries (in
Lines 8, 9, and 10) and source-sink paths (in Line 11),
assisted by the two helper functions. Finally, the algorithm
reports bugs in Line 12 by solving the path condition after
all functions have been analyzed.
ThecollectCloneSolveSmry helper collects sum-
maries directly from the current function if the value flow path
does not pass through a function call. Otherwise, it collects
summaries by concatenating the inlined summaries from the
called function c. For example, in Fig. 1, the summaries Ï€1Ï€2,
andÏ€3are collected directly from their respective functions,
while others are collected by concatenating callee summaries.
A single summary is collected in two steps: collecting the
summary path Î and instantiating the summary condition Î¦.
Instantiating the summary condition often requires additional
summary paths. As demonstrated in Example 2, instantiating
a summary condition often involves additional value flow
starting from the guard vertex labeled on the summary path.
Once a condition is instantiated, it is solved by a constraint
solver. If a summaryâ€™s condition is unsat , the summary is
discarded because an infeasible summary implies that the re-
sulting source-sink path is also infeasible. The helper function
puts the feasible summaries into three types of summary sets,which would be used in the caller functions in the incoming
analysis. At that time, the summaries are inlined, which helps
the caller form long summaries and possible source-sink paths.
Example 3. Recall Fig. 1(c). Functions qux,baz, and bar
are called by the function foo. Thus, qux,baz, and barare
analyzed first, while foois analyzed later. In function qux,
only the output summary s1is generated between the source
Vsrc={NULL 19}and the formal return Vfr={m20},
and then Ï•Ï€1is verified. Thus, qux hasSqux(Vsrc, Vfr) =
{s1= (Ï€1, Ï•Ï€1)}, with the other three sets being empty.
In function baz, only the transfer summary s2is collected
between the formal parameter Vfp={f15}and the formal
return Vfr={f16}, with the condition verified. Thus, baz
hasSbaz(Vfp, Vfr) ={s2= (Ï€2, Ï•Ï€2)}, with the other three
sets being empty. In function bar, the input summary s3is
collected between the formal parameter Vfp={p11}and the
sinkVsink={printf (âˆ—a9)}, with condition verified. Thus,
bar owns Sbar(Vfp, Vsink) ={s3= (Ï€3, Ï•Ï€3)}, with the
other three sets being empty. Since there is a conditional edge
inÏ€3, its summary condition Ï•Ï€3involves the instantiation
of the constraint represented by the guard Ï†2, which is
p11Ì¸=NULL 11. This involves the value flow path of p11,
which coincides with its summary path.
Example 4. When analyzing the top layer function foo,
the summaries are cloned from the bottom layer functions
accordingly. When collecting the transfer summaries starting
from formal parameter Vfp={c1}, which reaches a sink
printf (âˆ—c8)but cannot reach any actual input in Vap=
{a5, b6}, no transfer summaries are gathered as a result.
When collecting the input summaries, the summary s7is
generated with a summary path collected from the formal
parameter Vfp={c1}to the sink Vsink={printf (âˆ—c8)},
without cloning callee summaries. However, the summary
condition Ï•Ï€7necessitates instantiating the guard vertex Ï†1,
where Vg={Ï†1}. To this end, the value flow starting from Ï†1
is tracked. When reaching the actual output e6of the function
call to barin line 6, the summary s2is cloned from the callee
bar. Moving forward, when reaching the actual output b3of
the function call to quxin line 3, the summary s1is cloned,
thus forming the summary s6. Finanly Ï•Ï€7is verified.
When collecting the output summaries, because the Vsrc
in the current function is empty, the output summaries of
the callee function are cloned, introducing additional sources.
Thus, in line 2, the summary s1is inlined again, which is
the output summary of the function qux. By combining the
summary s1, the value path from the output a2toa5is traced
and involves the call to the function barin line 5. Since a5
is passed to bar, the input summary or transfer summary that
starts at the corresponding formal parameter is inlined. In our
case, the input summary s3of the function baris inlined. After
concatenating with the input summary, the path reaches a sink,
forming a complete source-sink path, but does not reach any
formal return. Thus, no output summary is collected.
ThecollectSrcSinkPath helper is similar to thecollectCloneSolveSmry but tries to collect the source-
sink paths in each iteration and does not solve the path
conditions. In the example of Fig. 1, the helper collects no
source-sink paths from bottom-layer functions, as no such
paths are formed, but it collects two source-sink paths, s4and
s5, from the upper-layer function foo. Eventually, Ï•Ï€4andÏ•Ï€5
are solved when reporting bugs in Line 12 of Algorithm 1.
III. O VERVIEW
In this section, we illustrate the problem using the motivat-
ing example and briefly describe our key idea.
A. Explosive Summary Problem
To detect the bug, the bottom-up collection of function
summaries outlined in Algorithm 1 can collect and maintain a
superset of the function summaries that are actually required.
As highlighted in red in Fig. 1(c), the summaries s2,s6, and
s7do not contribute to the two source-sink paths, s4and
s5, for detecting the NPD bug, i.e., either as components of
these paths or their associated path conditions. Specifically,
non-contributing summaries can arise in two scenarios in
Algorithm 1. First, when collecting three types of summaries,
over-summarization can occur. For instance, when analyzing
the function baz, there is no prior knowledge of which the
specific summary contributes, resulting in the conservative
collection of all summaries within it. Consequently, the non-
contributing summary s2is collected as a transfer summary.
Second, non-contributing summaries can be induced through
the cloning of callee summaries. For example, the summary
s6is a non-contributing summary generated by cloning and
concatenating with the callee summary s2. Additionally, given
that there are no source-sink paths within the function boothat
rely on s2, and considering that s6is deemed non-contributory,
the cloning of s2from function bazshould be avoided during
the analysis of foo. As summaries are maintained and cloned
into higher-level functions, the size of Sfcan exponentially
increase due to the explosion of paths. More importantly,
collecting non-contributing summaries introduces expensive
constraint-solving. To sum up, collecting and cloning only
the contributing summaries can significantly improve scala-
bility. The challenge lies in identifying redundant summaries
precisely and efficiently without hurting the precision of the
analysis.
B. Removing Redundant Summaries
We first propose the key idea of assessing whether a sum-
mary is contributing or not by solving two graph reachability
problems between heads and tails of the summary swith
distinct reaching targets (source-sink pairs or guards) without
computing any summaries. Based on the graph reachability ab-
straction, we design the contribution identification algorithm,
which identifies a set of necessary head and tail vertices for
identifying the contributing summaries. Summaries that are
collected outside these necessary head and tail vertices are
identified as non-contributing automatically. Next, we explainhow our graph reachability abstraction and algorithmic design
overcome the above challenges.
Contributing Summmary. Our key observation is that
whether a summary is contributing hinges on two aspects: its
path contribution, where it must be a component of source-sink
paths, and its condition contribution, where it must be involved
in the path conditions associated with a source-sink path.
Thus, we establish the definition of a contributing summary
generated from a function based on its contribution to the
source-sink paths S(Vsrc, Vsink).
Definition 3 (Contributing Summary) .A summary sâˆˆSf
is considered a contributing summary for function fif it
satisfies at least one of the following criteria: (1) Path Con-
tribution: The summary path Ï€is used to connect at least
one source-sink path, i.e., Ï€âˆˆÎ (Vsrc, Vsink). (2) Condition
Contribution: The summary path Ï€is used to instantiate at
least one guard vertex labeled along the source-sink paths,
i.e.,Ï•Ï€âˆˆÎ¦(Vsrc, Vsink, Vg).
We use Fig. 1 as an example. The path Ï€1is reachable
from both source-sink pairs (NULL 19, printf (âˆ—p13))and
(NULL 19, printf (âˆ—a9)). In addition, the path Ï€3is reachable
from the source-sink pair (NULL 19, printf (âˆ—p13)). There-
fore, they are identified as contributing summaries; indeed,
they are components of two source-sink paths, Ï€4andÏ€5.
Comparatively, the paths Ï€2,Ï€6, and Ï€7are neither reachable
by any pair of sources and sinks nor reachable by the guard
vertex Ï†2labeled on the source-sink path Ï€4. Thus, these paths
Ï€2,Ï€6, and Ï€7are identified as non-contributing summaries.
Additionally, despite the reachability of the summary Ï€6from
the guard vertex Ï†1labeled on Ï€7, more specifically, the tail
ofÏ€6, denoted as (e7), being reachable from Ï†1, the summary
Ï€7does not contribute to any source-sink path or conditions.
Consequently, it becomes redundant for NPD detection.
In summary, the summary contribution is identified by
assessing two reachabilities between specific heads and tails
of the summary path with various targets:
1) Path contribution: If the summary s= (Ï€, Ï•Ï€)has the
path contribution, a source-sink pair ( (src, sink )âˆˆVsrcÃ—
Vsink) exists, where srccan reach both Ï€[0]andÏ€[âˆ’1],
andsink is reached by both Ï€[0]andÏ€[âˆ’1].
2) Condition contribution: If the summary s= (Ï€, Ï•Ï€)has
the condition contribution criteria, there exists a guard
vertex g âˆˆVgfrom Î¦(Vsrc, Vsink, Vg)that are reached by
Ï€[0]andÏ€[âˆ’1].
With the above abstraction, the assessment of contributing
summaries is reduced to two graph reachability problems. In
Section IV, we give a sound, efficient, and effective contribu-
tion identification algorithm by applying the abstraction.
IV. C ONTRIBUTION IDENTIFICATION
In this section, we first present three technical designs
of our contribution identification algorithm. We then give
the details of the identification algorithm that identifies the
necessary vertices for path and condition contribution. Finally,
we establish the soundness of our approach, analyze thecomplexity of algorithms, and discuss the advanced graph
reachability with consideration of the calling context.
Preserving the precision of the analysis. To ensure this,
instead of directly utilizing the abstractions to identify non-
contributing summaries, the identification algorithm uses the
abstractions to soundly identify all necessary head vertices
Vhand tail vertices Vtthat are reached by source-sink pairs
(path contribution) as well as guard vertices Vgthat are labeled
on source-sink paths (condition contribution). This means that
contributing summaries can only be collected within necessary
vertices, which we denote as VN. Therefore, summaries
contributing to source-sink paths can be collected within VN
as in the traditional methods. In contrast, summaries collected
outside VNare considered as the non-contributing summaries.
The soundness proof is given in Section IV-C.
Efficient and effective identification. The identification
process relies on graph reachability. More precise graph
reachability results in fewer necessary vertices VNbeing
identified, allowing for recognizing more non-contributing
summaries starting outside of VN. However, using advanced
reachability algorithms increases the identification overhead.
The complexity of more advanced reachability algorithms
often outweighs the precision gains they can provide. To strike
a balance, i.e., spending minimal overhead while significantly
boosting the efficiency of path-sensitive analysis, we select the
classic breadth-first search ( bfs) algorithm for implementing
our abstractions. More discussion about this is in Section IV-D.
Resolving implicit contribution. The source of the implicit
contribution comes from the condition contribution of a sum-
mary. With the abstractions, resolving the implicit contribution
is transferred to gather the necessary guard vertices that are la-
beled on source-sink paths. The key is that the necessary guard
vertices could be obtained from edge sets that are reachable
from the necessary heads and tails for path contribution.
The contribution identification algorithm is outlined in Al-
gorithm 2. At a high level, it identifies necessary vertices
VNin two parts for path and condition contribution, re-
spectively, through three stages. First, it identifies the first
part of necessary vertices VNfor path contribution using the
procedure identifyPathContrib in Algorithm 2. Next,
using these necessary heads and tails for path contribution,
we collect the necessary guard vertices with the procedure
collectNecGuards in Algorithm 3. Lastly, based on the
necessary guard vertices and heads and tails that are not
identified for path contribution, we further identify the second
part of necessary vertices for condition contribution using the
procedure identifyCondContrib in Algorithm 3.
A. Path Contribution Identification
Procedure identifyPathContrib in Algorithm 2 uti-
lizesbfs to explore the graph separately from both the source
and sink vertices. Since a vertex vonly needs to be reachable
by at least one source-sink pair, the bfs initiated from the
source (sink) vertices maintain a shared visiting set called
srcVisited (sinkVisited ). This ensures that each ver-
tex is visited only once during the bfs from the sourcesAlgorithm 2: Contribution Identification
1Procedure identifyContrib( G)
2 VNâ† âˆ…;Vcandâ† âˆ…;
3 identifyPathContrib (G,VN,Vcand);
4 identifyCondContrib (G,VN,Vcand);
5 return VN;
6Procedure identifyPathContrib( G,VN,Vcand)
7 srcVisited â† âˆ…; sinkVisited â† âˆ…;
8 foreach vâˆˆVsrcdo
9 bfs(srcVisited, v, G, forward);
10 foreach vâˆˆVsink do
11 bfs(sinkVisited, v, G, backward);
12 VNâ†srcVisited âˆ©sinkVisited âˆ©(VtâˆªVhâˆ’Vg);
13 Vcandâ†srcVisited âˆªsinkVisited âˆ’VN;
(sinks). After completing all bfs, the necessary vertices for
path contribution can be obtained by computing the intersec-
tion between the vertices visited both by srcVisited and
sinkVisited andVtâˆªVhâˆ’Vgin Line 12. As the guard
vertices could not have the path contribution, the necessary
vertices only come from VtâˆªVhâˆ’Vg. Vertices that are
visited by sources and sinks but not identified as necessary
vertices for path contribution are called candidates, denoted
asVcand. These vertices may have condition contribution,
which are computed on Line 13 and passed to the procedure
identifyCondContrib on Line 4.
B. Condition Contribution Identification
The necessary guard vertices are labeled on the edges of
the source-sink paths. Thus, necessary guard vertices can be
collected using the necessary vertices for path contribution.
The necessary guards are collected and maintained in Vnec
g
through procedure gatherNecGuards , using the bfsEdge
traversal to gather the visited edges. Two shared edge sets,
fwdEdges andbwdEdges , are utilized to keep track of the
visited edges for forward and backward bfsEdge starting
from the vertices in VN, respectively. These two sets en-
sure that each edge is visited only once during the forward
and backward bfsEdge . For each edge (u, v)encountered
infwdEdges , if the reverse edge (v, u)is also found in
bwdEdges , the label Ld(u, v)is added to Vnec
g.
After collecting the necessary guard vertices, the algo-
rithm then proceeds to collect another part of the necessary
vertices for condition contribution. If a vertex has already
been identified for path contribution, separately identifying
its condition contribution is unnecessary. Thus, the procedure
identifyCondContrib explores the vertices from the
candidates in the forward direction and from each necessary
guard vertex in the backward direction. During the bfs iter-
ations, the shared sets fwdVisited andbwdVisited are
utilized to keep track of the visited vertices in each direction,
respectively. By examining the head and tail vertices present
in both fwdVisited andbwdVisited sets, another part
of the necessary vertices can be identified.Algorithm 3: Condition Contribution Identification
1Procedure identifyCondContrib( G,VN,Vcand)
2 Vnec
gâ† âˆ…; fwdVisited â† âˆ…; bwdVisited â† âˆ…;
3 gatherNecGuards (VN,Vnec
g);
4 foreach vâˆˆVcanddo
5 bfs(fwdVisited, v, G, forward);
6 foreach vâˆˆVnec
gdo
7 bfs(bwdVisited, v, G, backward);
8 VNâ†VNâˆª(fwdVisited âˆ©bwdVisited) âˆ©(VtâˆªVh);
9Procedure gatherNecGuards( VN,Vnec
g)
10 fwdEdges â† âˆ…; bwdEdges â† âˆ…;
11 foreach vâˆˆVNdo
12 bfsEdge (fwdEdges, v, G, forward);
13 foreach vâˆˆVNdo
14 bfsEdge (bwdEdges, v, G, backward);
15 foreach (u, v)âˆˆbwdEdges âˆ©fwdEdges do
16 Vnec
gâ†Vnec
gâˆªLd(u, v);
Example 5. Procedure identifyPathContrib â€™s output
is{NULL 19, m20, a2, a5,printf(âˆ—a9), p11,printf(âˆ—p13)}, and
the necessary guard vertice is {Ï†2}. The vertices that have con-
dition contribution are {p11, a2, a5, m20, NULL 19, Ï†2}and
some of them are included in the path contribution. Thus,
the output of the procedure identifyCondContrib is
{Ï†2}. Also, the set VNto assess the contributing summary is
{NULL 19, m20,printf(âˆ—a9), p11,printf(âˆ—p13), a2, a5, Ï†2}.
C. Soundness
We propose the following theorem to establish the
soundness of abstracting contributions in identifying non-
contributing summaries for function fbased on VN.
Theorem 1 (Soundness) .Given the set VNidentified, for
any function fâˆˆP, if a summary s= (Ï€, Ï•)is collected
and neither Ï€[0]norÏ€[âˆ’1]appears in VN, it must be a non-
contributing summary for function f. Canceling the corre-
sponding operations does not affect S(Vsrc, Vsink).
See the proof in Appendix Section B.
Example 6. In Fig. 1, collecting summary path Ï€6and veri-
fying its condition Ï•Ï€6are prevented because it is determined
that cloning Ï€â€²
1to concatenate with b3â†’b6would result in
a non-contributing summary. It is because b3is not included
inVN. Similarly, the collection and verification of summaries
s2ands7are removed because the head vertices f15andc1
of these summaries are not present in VN.
D. Summary and Discussion
Based on the identification of VN, as outlined in Theorem 2,
Algorithm 1 can be improved and revised as Algorithm 4.
During the process of collecting the three types of summaries,
the algorithm incorporates a filtering step for the head, tail,
and guard vertices using VN. The filtering step guarantees
that summaries located outside of VNare not collected or
cloned, effectively eliminating non-contributing summaries.Algorithm 4: New Path-Sensitive Value Flow Analysis
1Procedure newPathSensitveAnalysis( P)
2 Build call graph CG and PDG of P;
3 VNâ†identifyContrib (PDG);
4 /*The initialize part is the same as the Algorithm 1 */
5 foreach fâˆˆCG in bottom-up order do
6 /*Pruning the redundancies. */
7 Vfpâ†Vfpâˆ©VN;Vapâ†Vapâˆ©VN;
8 Vfrâ†Vfrâˆ©VN;Varâ†Varâˆ©VN;Vgâ†Vgâˆ©VN;
9 /*The summary collection part, which is the same
as the Alogirhtm 1. */
10 âˆ€(Ï€, Ï†)âˆˆS(Vsrc, Vsink),report Ï€as a bug if Ï†is sat;
Verification of these summaries by a constraint solver is
thus avoided. Next, we discuss the important points of the
algorithm, including its complexity, precision, and efficiency.
Complexity. The procedure identifyPathContrib in-
volves searching the PDG Gat most twice, as do each of the
other procedures, since each edge is visited only once, either
in the forward or backward traversal direction. As a result, the
overall complexity is linear with respect to the size of PDG.
Precision and Efficiency. The soundness of VNensures
the correct collection of contributing summaries. However,
there may still be vertices within VNthat lead to non-
contributing summaries. The precision of VNcan be increased
by minimizing the number of such vertices, thereby identifying
more non-contributing summaries. The reason for the incorrect
collection of some vertices in VNis that Algorithm 2 utilizes
a traditional reachability algorithm, specifically the bfs, to
address the reachability problems without differentiating the
calling context under which the summary could be used. How-
ever, certain non-contributing summaries can only be identified
under specific contexts, i.e., via context-free-language (CFL)
reachability [22], [25]â€“[29]. Consequently, non-contributing
summaries that are reachable under traditional reachability
algorithms but not under context-sensitive reachability al-
gorithms could be further identified. The precision of VN,
therefore, depends on the approach used to solve reachability.
The CFL reachability algorithm takes calling context into con-
sideration by respectively labeling function calls and returns
with matched parentheses [kand]kat line k. Thus, a vertex iis
context-sensitively reachable from a vertex jif the label string
of the path does not contain any mismatched parentheses.
Example 7. In Fig. 1 (b), the following edges are labeled with
parentheses to fulfill the requirements of the CFL reachability
algorithm: m20]2âˆ’ â†’a2,m20]3âˆ’ â†’b3,a5[5âˆ’ â†’p11,b6[6âˆ’ â†’f15,
andf16]6âˆ’ â†’e6. By replacing bfs with a CFL reachability
algorithm in Algorithm 2, we would produce VN=
{NULL 19, m20,printf(âˆ—a9), p11,printf(âˆ—p13), a2, a5, Ï†2},
which is the same as when using bfs. In this case, using the
CFL reachability algorithm does not improve the precision.
In practice, the precision of VNthat can be improved
by CFL reachability is limited. In our evaluation, approxi-
mately 80% of non-contributing summaries were successfullyTABLE I: |Sall|is total size of collected summaries.
#Redun is the number of redundant summaries that occur,
with the percentage relative to |Sall|shown in parentheses.
#Identified is the number of identified summaries by CI,
with the percentage relative to #Redun shown in parentheses.
#Src and#Sink represent the number of sources and sinks.
ID Program KLoC |Sall| #Redun #Identified #Src #Sink
1 leela 21 47.2K 12.4K( 26% ) 9.3K( 75% ) 15 3.2K
2 nab 24 34.6K 5.2K( 15% ) 3.7K( 73% ) 88 3.6K
3 x264 96 94.2K 24K( 26% ) 19K( 79% ) 58 7.7K
4 wrf 130 51.1K 10.1K( 20% ) 8.4K( 83% ) 123 4.3K
5 omnetpp 134 405.6K 78.1K( 19% ) 66.1K( 85% ) 146 27.5K
6 povray 170 231.5K 45.8K( 20% ) 33.5K( 73% ) 24 14.5K
7 cactus 257 1.1M 307.7K( 29% ) 257.5K( 84% ) 38 49.8K
8 imagick 259 381.4K 30.3K( 8%) 22.5K( 74% ) 154 12.2K
9 perlbmk 362 1.4M 217.8K( 15% ) 197.7K( 91% ) 232 40.9K
10 cam4 407 46.7K 10.1K( 22% ) 7.2K( 72% ) 53 3.4K
11 parest 427 3.6M 658.3K( 18% ) 555.9K( 84% ) 62 215.7K
12 xalanbmk 520 1.4M 294.4K( 21% ) 258.9K( 88% ) 23 77.7K
13 gcc 1304 3.5M 382.3K( 11% ) 287.4K( 75% ) 181 146.2K
14 blender 1577 3.2M 605.7K( 19% ) 505.6K( 83% ) 127 182.6K
15 libicu 537 1.1M 190.4K( 17% ) 165.8K( 87% ) 307 76.7K
16 ffmpeg 1346 2.1M 393.6K( 19% ) 244.7K( 62% ) 491 146.3K
17 mysqld 2030 3.8M 723.6K( 19% ) 519.2K( 72% ) 141 215.4K
avg 1.3M 234.7K( 19% ) 186K( 79% )
identified using bfs. However, in terms of efficiency, CFL
reachability often encounters a cubic complexity barrier [26]â€“
[29]. As demonstrated by our experiment in Fig. 2, using a
CFL-based algorithm to collect VNsignificantly decreases
overall performance. Thus, we use bfs.
V. E VALUATION
We have implemented the contribution identification (CI)
algorithm in Algorithm 2 to identify the path and condition
contribution in the state-of-the-art value flow analysis tool
Fusion [6] for detecting NPD in C/C++ code. We denote
Fusion with CI enabled as Light-Fusion, which serves as the
performance-boosted client powered by our technique. We
investigate the following three questions:
â€¢(RQ1 ): How effective and efficient is CI in identifying
the summary contribution?
â€¢(RQ2 ): How much can CI boost the performance of
existing value-flow analysis?
â€¢(RQ3 ): Can CI enhance the path-sensitive analyzerâ€™s per-
formance to be comparable with the top-down approach?
A. Experimental Setup
Baselines. Fusion collects the summaries in a parallel way,
i.e., parallelizing functions located within the same level of
the call graph, and uses the graph representation of summary
conditions [6]. First, we compare Light-Fusion with Fusion.
We did not compare to [16] [17] as their methodologies
involve generating redundant summaries to enable parallelism,
which contradicts the principles and objectives of our ap-
proach. In addition, we have developed a variant of Light-
Fusion (denoted as CFL-Light-Fusion) that uses a more precise
identification algorithm achieved through CFL reachability.
Specifically, we adopted the open-source implementation of
the state-of-the-art CFL reachability algorithm [30] provided
by [31] and replaced the bfs used in Algorithm 2. Lastly, we
compare the Light-Fusion to PhASAR [32], an open-sourcedTABLE II: The running time and memory usage of Fusion
(F), Light-Fusion (L-F), and building of PDG are presented,
along with CIâ€™s running time and performance gains (Gains).
Memory(GB) Time(s)
ID F L-F PDG F L-F PDG CI Gains
1 18.42 13.13( 29% ) 1.1 185 61( 67% ) 6 0.11 1127.27
2 5.67 4.77( 16% ) 0.9 380 315( 17% ) 5 0.08 812.5
3 2.12 0.94( 56% ) 1.1 362 290( 20% ) 23 0.23 311.69
4 3.1 2.98( 4%) 0.9 231 126( 45% ) 6 0.13 807.69
5 3.52 2.63( 25% ) 3.6 627 187( 70% ) 39 1.11 395.33
6 44.78 13.23( 70% ) 2.2 2087 869( 58% ) 35 0.67 1828.83
7 17.17 12.95( 25% ) 8.8 1435 524( 63% ) 423 3.34 272.67
8 79.98 74.89( 6%) 7.9 3795 3485( 8%) 118 2.23 139.14
9 102.7 77.9( 24% ) 19.7 8075 5641( 30% ) 312 8.67 280.9
10 2.52 2.08( 17% ) 11 409 343( 16% ) 65 0.14 471.43
11 18 7.32( 59% ) 32.6 10281 3450( 66% ) 497 14.22 480.48
12 32.06 18.83( 41% ) 10.6 5172 1689( 67% ) 114 4.91 709.95
13 215.11 178.11( 17% ) 35.7 19484 16569( 15% ) 515 15.75 185.07
14 336.37 234.88( 30% ) 21.9 10848 4454( 59% ) 536 12.11 527.91
15 131.92 83.77( 36% ) 12.4 8261 3660( 56% ) 124 4.01 1147.95
16 144.93 97.82( 33% ) 22.7 11018 4710( 57% ) 348 8.1 778.48
17 393.99 269.69( 32% ) 36.3 16157 8050( 50% ) 471 17.31 468.48
avg 91.31 66.65( 27% ) 13.5 5812.18 3201.35( 45% ) 213.94 5.48 632.1
implementation of top-down approaches [21]â€“[24]. To mitigate
the impact of the execution environment, we ran experiments
three times and calculated the average performance and per-
formance gains.
Subjects. We have included all the large programs from the
SPEC CPU@2017 benchmark [33] that consist of more than
10 KLoC. Additionally, we have selected three large programs,
namely libicu ,ffmpeg , and mysqld , which are widely-used
software systems in their respective domains.
Sources and Sinks. For checking NPD, NULL pointers are
selected as sources. The dereference operations are selected
as sinks. Table I lists the evaluation subjects with statistics of
sources and sinks.
Environment. All experiments were run on a server with
eighty â€œIntel Xeon CPU E5-2698 v4@2.20GHzâ€ processors
and 512 GB of memory running Ubuntu-18.04. Each program
is analyzed with a limit of 12 hours and 256 GB of memory.
Fifteen threads are used to analyze the functions in the same
layer when running both Fusion and Light-Fusion. The solver
used to verify constraints is Z3[15].
B. RQ1: Effectiveness and Efficiency
To study the effectiveness of CI, we run two experiments
for each benchmark. In the first experiment, we execute Fusion
to produce the results S(Vsrc, Vsink)and collect all potential
summaries that could be generated during analysis, denoted as
Sall. Note that Sallcontains the non-contributing summaries,
which is a superset of S(Vsrc, Vsink). The summary size of
each benchmark is recorded in the |Sall|column of Table I.
Second, we count non-contributing summaries from Sallbased
on the definition of contributing summaries (Definition 3). The
relative number of non-contributing summaries is reported in
the â€œ#Redunâ€ column of Table I.
In the second experiment, we run Light-Fusion using the
same configuration as Fusion to produce S(Vsrc, Vsink). Light-
Fusion, however, incorporates an additional identification al-
gorithm, CI, to filter out non-contributing summaries before
the summary collection and cloning. We count the number
of identified non-contributing summaries and then compare
it with the total number of non-contributing summaries inthe first experiment to determine the identification ratio. The
findings are listed in the â€œ#Identifiedâ€ column of Table I.
Throughout both experiments, the PDG of each benchmark
is pre-built once and persisted to disk. Both Fusion and
Light-Fusion read the same PDG as input when analyzing
a benchmark. We monitor the execution time, the memory
consumption, and the analysis results, S(Vsrc, Vsink). The per-
formance data for the two runnings and the building of PDG
are listed in Table II. In the second set, we specifically record
the time consumed by CI, as the memory usage generally stays
low, below 200 MB in 15 benchmarks, with the exceptions of
blender at 265 MB and mysqld at 252 MB. The running time
of CI is listed in the â€œCIâ€ column of Table II.
Soundness. We compare the analysis results S(Vsrc, Vsink)
across both sets and the unsafe sinks reported by Fusion and
Light-Fusion in Section V-D. They remain the same, demon-
strating the preservation of the precision of our approach.
Effectiveness. While using normal graph reachability ( bfs)
to collect necessary vertices VN, CI soundly approximates the
summary contribution without considering context sensitivity.
Thus, some redundant summaries could be incorrectly classi-
fied as contributing ones. Column â€œ#Identifiedâ€ in Table I lists
the number of redundant summaries that can be identified and
the percentage relative to redundant summaries that occur for
each benchmark. We observe that CI can precisely identify
redundant summaries, reaching the high ratio from 62% (in
ffmpeg ) to 91% (in perlbench ). On average, CI correctly
identifies 79% of redundant summaries. One could reject the
bogus VNby reaching context sensitivity. However, handling
context sensitivity may be more costly. We examine this aspect
in Section V-C. The high rate of identification achieved by
CI in most projects shows that there is limited room for
improvement with a context-sensitive identification algorithm.
Efficiency. Table II presents the running performance of
Fusion, Light-Fusion, CI, and the performance gains when
applying CI. Light-Fusion, using our CI to prune redundant
summaries, includes CIâ€™s running time in its performance met-
rics. For all benchmarks, CIâ€™s running time for collecting VN
remains below a minute. Specifically, using CI significantly
improves the running time and memory of Light-Fusion, as
evidenced by the data in the â€œTimeâ€ and â€œMemoryâ€ columns
of the table. Without computing and maintaining the redundant
summaries captured by CI, the average running time of Fusion
is reduced from 5812.18 seconds to 3201.35 seconds, saving
over 40 minutes (or 2,610.83 seconds). Also, the average
memory usage for Fusion drops from 44.26 GB to 33.88 GB.
Breakdown. To investigate how much resource is spent
collecting redundant summaries and how much resource is
spent on calling the constraint solver to verify the condi-
tions of redundant summaries, we break down the reduced
performance in Table II. This is obtained by computing the
difference in running time and memory between Fusion and
Light-Fusion, as shown in Table II. Additionally, we present
the number of solver calls avoided in Table III. Once the
summary path is collected, the constraint solver is called; thus,
the avoided calls of the constraint solver equal the number ofTABLE III: #Solver is the number of saved solver calls,
which is equal to the number of identified redundant sum-
maries ( #Identified column in Table I). The total ( T)
reduction in performance, performance of calling the solver
(S), with the percentage of each with respect to the total
reduction in performance shown in parentheses.
ID #SolverTime(s) Memory(GB)
T S T S
1 9.3K 124 110( 89% ) 5.29 1.3( 25% )
2 3.7K 65 59( 91% ) 0.9 0.1( 11% )
3 19.0K 72 66( 92% ) 1.18 0.26( 22% )
4 8.4K 105 95( 90% ) 0.12 0.01( 8%)
5 66.2K 440 403( 92% ) 0.89 0.18( 20% )
7 257.5K 911 840( 92% ) 4.22 1( 24% )
8 22.5K 310 280( 90% ) 5.09 1.4( 28% )
9 197.7K 2434 2222( 91% ) 24.8 5.6( 23% )
10 7.2K 66 59( 89% ) 0.44 0.1( 23% )
11 555.9K 6831 6403( 94% ) 10.68 3.3( 31% )
12 258.9K 3483 3320( 95% ) 13.23 4.3( 33% )
13 287.4K 2915 2817( 97% ) 37 8.9( 24% )
14 505.6K 6394 6188( 97% )101.49 37.1( 37% )
15 165.8K 4601 4403( 96% ) 48.15 12( 25% )
16 244.7K 6308 6099( 97% ) 47.11 8.8( 19% )
17 519.2K 8107 7803( 96% ) 124.3 26.8( 22% )
avg 268.7K 2610 2487( 95% ) 24.7 6.66( 27% )
redundant summaries identified, as shown in the data in the
columns â€œ#Identifiedâ€ in Table I and â€œ#Solverâ€ in Table III.
For the total reduced running time, almost 90% is spent on
verifying the conditions of redundant summaries across the
benchmarks. As the size of the program grows, the complexity
of the summary conditions tends to increase as well. This
results in longer summary paths and more time required to
solve these conditions. Therefore, the proportion of time spent
on the solver increases from 89% to 97%. On the other hand,
for the total reduced memory, almost 73% is consumed by
storing the collected summaries.
Performance Gains. It is noted that the running time of CI
does not hurt the performance of Light-Fusion. The â€œGainsâ€
column in the table illustrates the performance gains achieved
by using CI, which is the ratio of the time saved by Light-
Fusion to the overhead incurred by CI. In the povray (ID 6)
case, CI achieves the highest performance gain of 1828.83 Ã—
by reducing 1218 seconds with only 0.67 seconds of overhead.
In the mysqld (ID 17) case, CI reduces the most time, saving
8107 seconds (2.25 hours), which is nearly half of the original
Fusion running time, with only 17.31 seconds of overhead. On
average, CI achieves a performance gain of 632.1 Ã—.
C. RQ2: Performance Boosting
Fusion vs. Light-Fusion. The performance comparison
between Fusion and Light-Fusion is listed in Table II. The
percentage numbers in parentheses represent the extra per-
formance requirements of Fusion against Light-Fusion. On
average, both the time and memory could be reduced by
45% and by 27% by using CI. The time reduction is more
significant than the memory reduction since analyzers allocate
considerable CPU resources to summary collection and solv-
ing path conditions, which can be NP-hard [4], [34]. Thus,
pruning redundant summaries can save significant time by
conserving CPU resources. The memory reduction percentages
are constrained by the number of redundant summaries in the
1234567891011121314151617FusionCFL-Light-Fusion Light-FusionTime(Seconds)6hoursFig. 2: Light-Fusion vs. its variants
benchmarks, as indicated by the â€œ#Redunâ€ column in Table I,
which shows an average redundancy ratio of 19% closely
corresponding to the average memory reduction percentages.
Light-Fusion vs. CFL-Light-Fusion. To explore the impact
of enhancing the CI precision, such as by using the CFL
reachability [26]â€“[29] to reach context sensitivity and identify
more redundant summaries compared to bfs, we replaced bfs
in CI with the state-of-the-art CFL reachability algorithm [30].
The modified algorithm was executed as the CFL-Light-
Fusion instance compared with Fusion and Light-Fusion. We
monitored the running time on all three instances.
The results presented in Fig. 2 demonstrated that CFL-
Light-Fusion did not yield performance improvements; in-
stead, it significantly slowed down the process, particularly
as the program size increased. Notably, CFL-Light-Fusion
failed to analyze benchmarks beyond cam4 (ID 10) within
a six-hour timeframe. This decrease in performance can be
attributed mainly to the cubic complexity of CFL-based ap-
proaches [26]â€“[29], which introduce substantial overhead that
outweighs the precision benefits. As a result, trading efficiency
for precision becomes impractical.
D. RQ3: Comparing to Top-down Approaches
To evaluate the performance improvements of the path-
sensitive analyzer compared to top-down approaches [21]â€“
[24], [35], we conducted a comparative analysis between
Light-Fusion and PhASAR [32]. Using the latest release [36]
ofPhASAR at the time of writing, we configured it to analyze
the same source-sink pairs as Light-Fusion to ensure a fair
comparison.
Performance. The results shown in Fig. 3 show the running
time and memory usage of Fusion, Light-Fusion, and PhASAR ,
which are represented by blue, green, and red bars, respec-
tively. In general, both Fusion and Light-Fusion require more
resources compared to PhASAR , as indicated by the taller blue
and green bars compared to the red bars. However, the green
bars (representing Light-Fusion) are closer in height to the
red bars ( PhASAR ) than the blue bars (representing Fusion).
In some benchmarks, the green bars are even lower than the
red bars. For example, the running time of Light-Fusion for
cactus (ID 7) and xalanbmk (ID 12), as well as the memory
usage for x264 (ID 3), are lower than those of PhASAR .
Next, we quantify the amount of running time and memory
among Fusion, Light-Fusion, and PhASAR . The results show1234567891011121314151617FusionLight-FusionPhASAR
1234567891011121314151617Time(logscale)Memory(logscale)Fig. 3: Performance: Fusion vs. Light-Fusion vs. PhASAR .
that Fusion requires 3.35 Ã—the time and 9.75 Ã—the memory
consumed by PhASAR on average. However, Light-Fusion can
reduce the requirements to just 1.4 Ã—the time and 6.95 Ã—the
memory. Additionally, Light-Fusion has performance compa-
rable with PhASAR on benchmarks such as leea (ID 1), x264
(ID 3), omnetpp (ID 5), cactus (ID 7), xalanbmk (ID 12), and
ffmpeg (ID 16), requiring only an additional 0.5 Ã—ofPhASAR â€™s
execution time. However, Fusion could only complete x264
(ID 3) within the same threshold.
Analysis Results. We record the unsafe sinks reported by
Fusion, Light-Fusion, and PhASAR for each benchmark. A
sink is considered unsafe if there is a feasible path from a
source to the sink. Note that top-down approaches, such as
PhASAR , usually sacrifice path sensitivity for better scalability.
As a result, they may misclassify safe sinks as unsafe ones.
First, the results show that the unsafe sinks reported by
Light-Fusion are the same as those reported by Fusion, demon-
strating our approachâ€™s precision-preserving nature. Next,
we examine the unsafe sinks reported by Light-Fusion and
PhASAR . Light-Fusion identifies 90% of the sinks, which
are reported as unsafe by PhASAR , as actually being safe,
indicating a high false-positive rate for PhASAR .
Additionally, nearly 92% of unsafe sinks identified by Light-
Fusion are also identified by PhASAR . However, PhASAR
fails to report some unsafe sinks identified by Light-Fusion
due to not modeling the value flow of library functions after
manual verification. We provide the complete comparison data
in Appendix Section C.
In conclusion, our method incorporates path-sensitive anal-
yses without compromising precision and still achieves good
performance. This aligns with common industrial require-
ments [37], [38] of maintaining both high performance and
low false positive rates.VI. R ELATED WORK
Compositional Analysis. Many compositional analyses aim
to improve efficiency by reusing information within a proce-
dure as summaries [3], [12], [16], [21], [24], [38], [39], which
include top-down and bottom-up summaries. Most program
analyses prefer a bottom-up approach [3], [12], [16], [38],
[39]. In these approaches, a functionâ€™s effect is represented
using bottom-up summaries, and the summary of a callee is
inlined into the summary of its caller. This avoids redundant
analysis of individual functions. However, when collecting the
summary of a callee, it is challenging to determine whether
the summary will be useful to callers since the callers are
typically analyzed afterward. Our work employs a lightweight
analysis to pre-compute a set of vertices, which allows us
to determine whether a summary should be computed and
reduces unnecessary computations.
Value Flow Analysis. Cherem et al. [1] utilized value
flow analysis to detect software bugs such as memory leaks.
Subsequently, several works have aimed to refine the recall and
precision of this analysis [3], [5]â€“[7], [9]. However, most of
these analyses are not inter-procedurally path-sensitive, with
the exceptions of Pinpoint [3] and Fusion [6]. Fusion is an
optimization of the performance issues identified in Pinpoint,
which were caused by the explosion of summaries and paths
in inter-procedural analysis. Fusion addresses this problem
by eliminating the storage of path conditions. However, it is
worth noting that even with Fusion, there are still redundant
summaries and paths being computed in function summaries,
which cannot be fully optimized. While this work helps Fusion
overcome redundancy issues related to function summaries.
VII. C ONCLUSION
We present the contribution identification algorithm, which
addresses the redundant summary deficiency in the prior value
flow analysis. It identifies redundant summaries efficiently
and effectively without compromising soundness or efficiency.
Furthermore, it results in an average decrease in the time and
memory overhead of state-of-the-art path-sensitive value flow
analysis by 45% and 27%, respectively. In the end, it enables
path-sensitive analyses without compromising precision and
still achieves good performance, making it comparable to path-
insensitive analyses.
VIII. A CKNOWLEDGMENT
We thank the anonymous reviewers for valuable feedback
on earlier drafts of this paper, which helped improve its
presentation. This work is funded by research donations from
Huawei, TCL, and Tencent. Yuandao Cai is the corresponding
author.
REFERENCES
[1] S. Cherem, L. Princehouse, and R. Rugina, â€œPractical memory leak
detection using guarded value-flow analysis,â€ in Proceedings of the
28th ACM SIGPLAN Conference on Programming Language Design
and Implementation , ser. PLDI â€™07. ACM, 2007, pp. 480â€“491.[2] B. Livshits and M. S. Lam, â€œTracking pointers with path and context
sensitivity for bug detection in c programs,â€ in Proceedings of the 9th
European Software Engineering Conference Held Jointly with the 11th
ACM SIGSOFT International Symposium on the Foundations of Software
Engineering , ser. ESEC/FSE â€™03. ACM, 2003, pp. 317â€“326.
[3] Q. Shi, X. Xiao, R. Wu, J. Zhou, G. Fan, and C. Zhang, â€œPinpoint:
Fast and precise sparse value flow analysis for million lines of code,â€ in
Proceedings of the 39th ACM SIGPLAN Conference on Programming
Language Design and Implementation , ser. PLDI â€™18. ACM, 2018, pp.
693â€“706.
[4] G. Fan, R. Wu, Q. Shi, X. Xiao, J. Zhou, and C. Zhang, â€œSmoke:
Scalable path-sensitive memory leak detection for millions of lines of
code,â€ in Proceedings of the 41st International Conference on Software
Engineering , ser. ICSE â€™19. IEEE, 2019, pp. 72â€“82.
[5] Q. Shi, R. Wu, G. Fan, and C. Zhang, â€œConquering the extensional
scalability problem for value-flow analysis frameworks,â€ in Proceedings
of the 42nd International Conference on Software Engineering , ser. ICSE
â€™20. ACM, 2020, pp. 812â€“823.
[6] Q. Shi, P. Yao, R. Wu, and C. Zhang, â€œPath-sensitive sparse analysis
without path conditions,â€ in Proceedings of the 42nd ACM SIGPLAN
International Conference on Programming Language Design and Im-
plementation , 2021, pp. 930â€“943.
[7] Y . Sui, D. Ye, and J. Xue, â€œDetecting memory leaks statically with
full-sparse value-flow analysis,â€ IEEE Transactions on Software Engi-
neering , vol. 40, no. 2, pp. 107â€“122, 2014.
[8] Y . Sui, P. Di, and J. Xue, â€œSparse flow-sensitive pointer analysis
for multithreaded programs,â€ in Proceedings of the 14th International
Symposium on Code Generation and Optimization , ser. CGO â€™16. IEEE,
2016, pp. 160â€“170.
[9] Y . Sui and J. Xue, â€œSvf: Interprocedural static value-flow analysis in
llvm,â€ in Proceedings of the 25th International Conference on Compiler
Construction , ser. CC â€™16. ACM, 2016, pp. 265â€“266.
[10] C. Wang, W. Wang, P. Yao, Q. Shi, J. Zhou, X. Xiao, and C. Zhang,
â€œAnchor: Fast and precise value-flow analysis for containers via memory
orientation,â€ ACM Transactions on Software Engineering and Method-
ology , vol. 32, no. 3, pp. 1â€“39, 2023.
[11] C. Wang, P. Yao, W. Tang, Q. Shi, and C. Zhang, â€œComplexity-
guided container replacement synthesis,â€ Proceedings of the ACM on
Programming Languages , vol. 6, no. OOPSLA1, pp. 1â€“31, 2022.
[12] D. Babic and A. J. Hu, â€œCalysto: Scalable and precise extended static
checking,â€ in Proceedings of the 30th International Conference on
Software Engineering , ser. ICSE â€™08. IEEE, 2008, pp. 211â€“220.
[13] Y . Xie and A. Aiken, â€œScalable error detection using boolean satisfia-
bility,â€ in Proceedings of the 32nd ACM SIGPLAN-SIGACT Symposium
on Principles of Programming Languages , ser. POPL â€™05. ACM, 2005,
pp. 351â€“363.
[14] R. Wu, Y . He, J. Huang, C. Wang, W. Tang, Q. Shi, X. Xiao, and
C. Zhang, â€œLibalchemy: A two-layer persistent summary design for tam-
ing third-party libraries in static bug-finding systems,â€ in Proceedings of
the IEEE/ACM 46th International Conference on Software Engineering ,
2024, pp. 1â€“13.
[15] L. De Moura and N. BjÃ¸rner, â€œZ3: An efficient smt solver,â€ in Proceed-
ings of the 14th International Conference on Tools and Algorithms for
the Construction and Analysis of Systems , ser. TACAS â€™08. Springer,
2008, pp. 337â€“340.
[16] Q. Shi and C. Zhang, â€œPipelining bottom-up data flow analysis,â€ in Pro-
ceedings of the 42nd International Conference on Software Engineering ,
ser. ICSE â€™20. ACM, 2020, pp. 835â€“847.
[17] W. Tang, D. Dong, S. Li, C. Wang, P. Yao, J. Zhou, and C. Zhang,
â€œOctopus: Scaling value-flow analysis via parallel collection of realiz-
able path conditions,â€ ACM Transactions on Software Engineering and
Methodology , 2023.
[18] R. Cytron, J. Ferrante, B. K. Rosen, M. N. Wegman, and F. K. Zadeck,
â€œEfficiently computing static single assignment form and the control
dependence graph,â€ ACM Transactions on Programming Languages and
Systems (TOPLAS) , vol. 13, no. 4, pp. 451â€“490, 1991.
[19] C. Cadar, D. Dunbar, D. R. Engler et al. , â€œKlee: Unassisted and auto-
matic generation of high-coverage tests for complex systems programs,â€
inProceedings of the 8th USENIX Symposium on Operating Systems
Design and Implementation , ser. OSDI â€™08. USENIX, 2008, pp. 209â€“
224.
[20] P. Cousot and R. Cousot, â€œModular static program analysis,â€ in Proceed-
ings of the 11th International Conference on Compiler Construction , ser.
CC â€™02. Springer, 2002, pp. 159â€“179.[21] T. Reps, S. Horwitz, and M. Sagiv, â€œPrecise interprocedural dataflow
analysis via graph reachability,â€ in Proceedings of the 22nd ACM
SIGPLAN-SIGACT Symposium on Principles of Programming Lan-
guages , ser. POPL â€™95. ACM, 1995, pp. 49â€“61.
[22] T. Reps, S. Horwitz, M. Sagiv, and G. Rosay, â€œSpeeding up slicing,â€ in
Proceedings of the 2nd ACM SIGSOFT International Symposium on the
Foundations of Software Engineering , ser. FSE â€™94. ACM, 1994, pp.
11â€“20.
[23] B. R. Murphy and M. S. Lam, â€œProgram analysis with partial transfer
functions,â€ in Proceedings of the 2000 ACM SIGPLAN workshop on
Partial evaluation and semantics-based program manipulation , 1999,
pp. 94â€“103.
[24] M. Sagiv, T. Reps, and S. Horwitz, â€œPrecise interprocedural dataflow
analysis with applications to constant propagation,â€ Theoretical Com-
puter Science , vol. 167, no. 1, pp. 131â€“170, 1996.
[25] T. Reps, â€œShape analysis as a generalized path problem,â€ in Proceedings
of the 1995 ACM SIGPLAN Symposium on Partial Evaluation and
Semantics-based Program Manipulation , ser. PEPM â€™95. ACM, 1995,
pp. 1â€“11.
[26] J. Kodumal and A. Aiken, â€œThe set constraint/cfl reachability connection
in practice,â€ in Proceedings of the 25th ACM SIGPLAN Conference
on Programming Language Design and Implementation , ser. PLDI â€™04.
ACM, 2004, pp. 207â€“218.
[27] S. Chaudhuri, â€œSubcubic algorithms for recursive state machines,â€ in
Proceedings of the 35th ACM SIGPLAN-SIGACT Symposium on Prin-
ciples of Programming Languages , ser. POPL â€™08. ACM, 2008, pp.
159â€“169.
[28] M. Yannakakis, â€œGraph-theoretic methods in database theory,â€ in Pro-
ceedings of the 9th ACM SIGACT-SIGMOD-SIGART Symposium on
Principles of Database Systems , ser. PODS â€™90. ACM, 1990, pp. 230â€“
242.
[29] D. Melski and T. Reps, â€œInterconvertibility of a class of set constraints
and context-free-language reachability,â€ Theoretical Computer Science ,
vol. 248, no. 1-2, pp. 29â€“98, 2000.
[30] Y . Lei, Y . Sui, S. Ding, and Q. Zhang, â€œTaming transitive redundancy
for context-free language reachability,â€ Proceedings of the ACM on
Programming Languages , vol. 6, no. OOPSLA2, pp. 1556â€“1582, 2022.
[31] â€œPOCR: Light-weight CFL-reachability solver,â€ https://github.com/
kisslune/POCR, 2022 Oct.
[32] P. D. Schubert, B. Hermann, and E. Bodden, â€œPhasar: An inter-
procedural static analysis framework for c/c++,â€ in Tools and Algorithms
for the Construction and Analysis of Systems , T. V ojnar and L. Zhang,
Eds. Cham: Springer International Publishing, 2019, pp. 393â€“410.
[33] J. Bucek, K.-D. Lange, and J. v. Kistowski, â€œSpec cpu2017: Next-
generation compute benchmark,â€ in Companion of the 2018 ACM/SPEC
International Conference on Performance Engineering , 2018, pp. 41â€“42.
[34] S. A. Cook, â€œThe complexity of theorem-proving procedures,â€ in Logic,
Automata, and Computational Complexity: The Works of Stephen A.
Cook , 2023, pp. 143â€“152.
[35] S. Arzt, S. Rasthofer, C. Fritz, E. Bodden, A. Bartel, J. Klein,
Y . Le Traon, D. Octeau, and P. McDaniel, â€œFlowdroid: Precise context,
flow, field, object-sensitive and lifecycle-aware taint analysis for android
apps,â€ in Proceedings of the 35th ACM SIGPLAN Conference on
Programming Language Design and Implementation , ser. PLDI â€™14.
ACM, 2014, pp. 259â€“269.
[36] â€œPhasar Github Release 03/24/2024,â€ https://github.com/
secure-software-engineering/phasar/releases/tag/v2403, 2024 March 24.
[37] A. Bessey, K. Block, B. Chelf, A. Chou, B. Fulton, S. Hallem, C. Henri-
Gros, A. Kamsky, S. McPeak, and D. Engler, â€œA few billion lines
of code later: Using static analysis to find bugs in the real world,â€
Communications of the ACM , vol. 53, no. 2, pp. 66â€“75, 2010.
[38] S. McPeak, C.-H. Gros, and M. K. Ramanathan, â€œScalable and incre-
mental software bug detection,â€ in Proceedings of the 14th European
Software Engineering Conference Held Jointly with the 21st ACM
SIGSOFT International Symposium on the Foundations of Software
Engineering , ser. ESEC/FSE â€™13. ACM, 2013, pp. 554â€“564.
[39] A. Aiken, S. Bugrara, I. Dillig, T. Dillig, B. Hackett, and P. Hawkins,
The Saturn Program Analysis System . Stanford University, 2006.
APPENDIX
The appendix includes an example that is removed be-
cause of the unsatisfiable summary condition in Section A,
soundness proof of contribution identification algorithm 2 in1.int*bar() {2.int*a = qux();3.if(ğœ‘!â‰¡a != NULL)4.returna;5.}6.int*qux() {7.int* m = NULL;8.returnm;9.}10.int*foo() {11.int*b= bar();12.printf(*b);13.}(a)CodeExample(b)ProgramDependenceGraph (PDG)(c)Functionsummariesforfoo,barandqux.Pathconditions:ğ‘ğ‘ˆğ¿ğ¿7â†’ğ‘š!ğœ‹":qux:ğœ™"!:m#=ğ‘ğ‘ˆğ¿ğ¿7âˆ§ğ‘$=m#âˆ§ğ‘%=ğ‘$âˆ§ğ‘&=ğ‘$âˆ§(ğœ‘!â‰¡ğ‘&â‰ ğ‘ğ‘ˆğ¿ğ¿&)ğœ™""	Valueflowpaths:bar:ğœ‹#:â†’ğ‘#$!ğ‘%ğ‘ğ‘ˆğ¿ğ¿7â†’ğ‘š!ğœ‹"data dep.control dep.ğ‘%ğ‘š'ğ‘š#ğ‘$ğ‘ğ‘ˆğ¿ğ¿7â‰ ğ‘ğ‘ˆğ¿ğ¿&trueğœ‘!ğœ‘!ğ‘&ğœ™"!:â€¦	âˆ§ğ‘&=ğ‘ğ‘ˆğ¿ğ¿7âˆ§(ğœ‘!â‰¡ğ‘&â‰ ğ‘ğ‘ˆğ¿ğ¿&)foo:
ğ‘!!ğ‘ğ‘Ÿğ‘–ğ‘›ğ‘“(âˆ—ğ‘!$)Fig. 4: An illustration example where the summary Ï€2is removed due to the unsatisfiable summary condition Ï•Ï€2. Bottom-up
analysis for the code shown in (a). The (b) shows the corresponding program dependence graph (PDG). (c) shows the function
summaries collected during the bottom-up analysis.
TABLE A.1: Classification of unsafe sinks (US) and safe sinks
(S) reported by Fusion (F), Light-Fusion (LF), and PhASAR
(P).
ID #Sinks F-US LF-US P-US LF-US âˆ©P-US LF-S âˆ©P-S LF-S âˆ©P-US LF-US âˆ©P-S
1 3184 2 2 11 2 3173 9 0
2 3581 9 9 86 9 3,495 77 0
3 7657 0 0 5 0 7652 5 0
4 4273 1 1 261 0 4012 261 1
5 27489 28 28 207 21 27282 186 7
6 14490 31 31 93 24 14397 69 7
7 49769 26 26 378 24 49391 354 2
8 12156 12 12 111 10 12045 101 2
9 40888 19 19 669 16 40219 653 3
10 3418 8 8 217 4 3201 213 4
11 215747 35 35 103 35 215644 68 0
12 77705 28 28 281 24 77424 257 4
13 146208 79 79 3592 76 142616 3516 3
14 182621 65 65 3902 63 178719 3839 2
15 76727 103 103 2382 93 74345 2289 10
16 146284 92 92 1102 84 145182 1018 8
17 215431 168 168 2007 162 213424 1845 6
Section B and a comparison of results of Fusion, Light-Fusion,
andPhASAR in Section C.
A. Pruning Unsatisfied Summary
In traditional path-sensitive value flow analysis, if a sum-
mary condition is unsatisfiable( unsat ), it is removed to avoid
maintaining an unfeasible summary. Figure 4 provides an ex-
ample of this. The summary Ï€2that is collected from function
barwill be discarded because its summary condition Ï•Ï€2is
unsat . The summary condition contains clauses indicating that
a3could be a NULL value and not be a NULL value at the
same time, as highlighted in the dashed box. As a result, the
function fooclones no summary from the function bar, and
no feasible source-sink path is detected in the case.
B. Soundness Proof of Algorithm 2
Theorem 2 (Soundness) .Given VNidentified, for any func-
tionfâˆˆP, if a summary s= (Ï€, Ï•)is being collected
and neither Ï€[0]norÏ€[âˆ’1]appear in VN, it must be a non-
contributing summary for function f. Canceling the corre-
sponding operations does not affect S(Vsrc, Vsink).
Proof. Proof by contradiction.In Algorithm 1, suppose the summary sthat is collected
between Vf
handVf
tis a contributing summary, even though
Ï€[0]/âˆˆVNandÏ€[âˆ’1]/âˆˆVN. Thus, the source-sink pair
(src, sink )or a guard vertex glabeled on the source-sink
path that reaches the head Ï€[0]or tail Ï€[âˆ’1]are not in VN.
However, if such a head or tail vertex exists, Algorithm 2
would include it in VN: either on Line 12 in the procedure
identifyPathContrib , or on Line 16 in the procedure
identifyCondContrib . Therefore, we arrive at a contra-
diction, as this implies that Ï€[0]âˆˆVNorÏ€[âˆ’1]âˆˆVN.
In Algorithm 1, when collecting the summary sby concate-
nating it with the summaries that are cloned from callee func-
tions, following the same judgment conditions as described in
the previous case, if it is determined to be a non-contributing
summary, the operation of cloning scshould be canceled.
C. Comparison Results of Fusion, Light-Fusion, and PhASAR
Table A.1 shows the classification results of unsafe sinks
and sinks reported by Fusion, Light-Fusion, and PhASAR ,
by examining unsafe sinks and safe sinks reported by both
tools (LF-US âˆ©P-US and LF-S âˆ©P-S columns), and unsafe sinks
reported by one tool but not the other (LF-US âˆ©P-S and LF-
Sâˆ©P-US columns).
First, the unsafe sinks reported by Fusion (F-US) and Light-
Fusion (LF-US) are identical, demonstrating the precision-
preserving nature of our approach.
Second, as shown in the LF-S âˆ©P-US column, PhASAR
mistakenly reports a large number of sinks as unsafe, resulting
in high false positive rates due to not collecting and verifying
the path conditions. The majority of these sinks actually cannot
be successfully reached by sources due to unsatisfiable path
conditions. Different from the Phasar, Light-Fusion considers
path conditions, thereby excluding the mistakenly reported
sinks from the top-down approaches.
Additionally, PhASAR fails to report some unsafe sinks that
are reported by Light-Fusion as shown in the LF-US âˆ©P-S
column.