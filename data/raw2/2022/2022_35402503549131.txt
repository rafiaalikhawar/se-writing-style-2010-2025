TowardInteractiveBugReporting for(Android App) End-Users
Yang Song
Collegeof William & Mary
USAJunayed Mahmud
GeorgeMason University
USAYingZhou
Universityof Texasat Dallas
USA
OscarChaparro
Collegeof William & Mary
USAKevinMoran
GeorgeMason University
USAAndrianMarcus
Universityof Texasat Dallas
USA
DenysPoshyvanyk
Collegeof William & Mary
USA
ABSTRACT
Many software bugsare reported manually, particularly bugsthat
manifestthemselvesvisually intheuserinterface.End-userstypi-
callyreportthesebugsviaappreviewingwebsites,issuetrackers,
or in-app built-in bug reporting tools, if available. While these sys-
temshavevariousfeaturesthatfacilitatebugreporting( e.g.,textual
templates or forms), they often provide limitedguidance, concrete
feedback,orqualityverificationtoend-users,whoareofteninexpe-
rienced at reporting bugs and submit low-qualitybug reports that
lead to excessive developer effort in bug report management tasks.
Weproposeaninteractivebugreportingsystemforend-users
(Burt),implementedasatask-orientedchatbot.Unlikeexistingbug
reportingsystems, Burtprovidesguidedreportingofessentialbug
reportelements( i.e.,theobservedbehavior,expectedbehavior,and
steps to reproduce the bug), instant quality verification, and graph-
icalsuggestionsfor theseelements.Weimplementedaversionof
Burtfor Android and conducted an empirical evaluation study
with end-users, who reported 12 bugs from six Android apps stud-
iedinpriorwork.Thereportersfoundthat Burt‚Äôsguidanceand
automatedsuggestions/clarificationsareusefuland Burtiseasyto
use.Wefoundthat Burtreportscontainhigher-qualityinformation
thanreportscollectedviaatemplate-basedbugreportingsystem.
Improvements to Burt, informed by the reporters, include support
forvariouswordingstodescribebugreportelementsandimproved
qualityverification.Ourworkmarksanimportantparadigmshift
from staticto interactive bugreportingfor end-users.
CCS CONCEPTS
¬∑Softwareanditsengineering ‚ÜíSoftwaremaintenancetools .
KEYWORDS
Bug Reporting,Task-OrientedChatbots, Android Apps
Permissionto make digitalor hard copies of allorpart ofthis work for personalor
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACM
mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,
topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ESEC/FSE ‚Äô22, November 14≈õ18,2022, Singapore, Singapore
¬©2022 Associationfor Computing Machinery.
ACM ISBN 978-1-4503-9413-0/22/11.
https://doi.org/10.1145/3540250.3549131ACMReference Format:
YangSong,JunayedMahmud,YingZhou,OscarChaparro,KevinMoran,
Andrian Marcus, and Denys Poshyvanyk. 2022. Toward Interactive Bug
Reporting for (Android App) End-Users. In Proceedings of the 30th ACM
JointEuropeanSoftwareEngineeringConferenceandSymposiumontheFoun-
dationsofSoftwareEngineering(ESEC/FSE‚Äô22),November14≈õ18,2022,Sin-
gapore,Singapore. ACM,NewYork,NY,USA, 13pages.https://doi.org/10.
1145/3540250.3549131
1 INTRODUCTION
Bug report management is an important and costly software en-
gineering activity. While certain types of bugs can be reported
automatically via a known oracle ( e.g., crashes), recent studies
haveillustratedthatmorethanhalfofthebugsreportedinopen
source software relate to functional problems with no automati-
callyidentifiableoracle[ 59]and,hence,mustbereportedmanually.
High-qualitybugreportsareessentialforbugtriageandresolution
and they are expected to describe at minimum the observed (incor-
rect) behavior ( OB), the steps to reproduce the bug ( S2Rs), and the
expected(correct) software behavior( EB) [25,48,65].
One of the main difficulties that contributes to quality issues in
end-user bug reporting is the knowledge gap between end-users
and developers [ 44,53]. That is, there is often a gap between what
end-users knowandwhatdevelopers need[65],generallyduetothe
factthatusersarebothunfamiliarwiththeinternalsofthesoftware
and with the explicit types of information that are important for
developers ( e.g.,the OB, EB, andS2Rs).
Most current reporting systems are not designed to address the
above-mentionedknowledgegapbetweenend-usersanddevelop-
ers.Inparticular,currentsystemsaretypicallylackingalongtwo
important dimensions: (1) they offer limited guidance related to
whatneeds to be reported and howit needs to be reported; and (2)
nofeedbackisofferedtoreportersonwhethertheinformationthey
provided is correct or complete. In consequence, given the static
natureofthesebugreportinginterfaces,theburdenofproviding
high-qualityinformation restsonthe reporters.
Wepositthatan interactive reportingsolutioncanhelptobridge
the developer≈õend-user knowledge gap. Inspired by prior work on
question/answering systems for debugging [ 47], we argue that a
conversational agent ( i.e., a chatbot) can successfully guide end-
users through the reporting process, while offering interactive sug-
gestions andinstantquality verification.
344
ESEC/FSE ‚Äô22, November14≈õ18, 2022,Singapore, Singapore Yang Song,JunayedMahmud,Ying Zhou,Oscar Chaparro, Kevin Moran, Andrian Marcus, DenysPoshyvanyk
Inthispaper,weintroduceandevaluateatask-orienteddialogue
system for BUg RepoRTing (orBurt) that is capable of providing
instant feedback for each element of a bug description ( i.e., OB, EB,
and S2Rs), while actively guiding corrections, where needed. Burt
combinesnovelandstate-of-the-arttechniquesfordynamicsoft-
ware analysis, naturallanguage processing, and automated report
qualityassessment.Wedesignedanddevelopedthecurrentversion
ofBurtto work for Android apps, but its architecture is platform-
agnosticanditcanbeinstantiated,withsomeengineeringeffort,for
other types of GUI-based applications ( e.g., web-based, desktop, or
iOS-based).Inparticular, Burtconstructsagraphofprogramstates
usingbothcrowdsourcedappusagedataandautomatedGUI-based
exploration techniques. The chatbot then parses and interprets
end-user descriptions of various bug report elements by matching
them to states and transitions in the constructed graph, and pro-
duces graphical suggestions regarding information that is likely
tobereported( e.g.,thenextS2Rs).Additionally, Burtrecognizes
when end-users provide incomplete or ambiguous information and
suggests improvements or clarifications to the users. Traditional
task-orientedchatbotstypicallyhavedirect accesstoastructured
andeasilyparseableknowledge-base[ 11].Incontrast, Burtismore
complex,asitreconcileshigh-leveldescriptionsprovidedbyend
usersandmatchesthesetotechnicalprograminformation,bridging
the end-userto developer knowledge gap.
We evaluated Burtempirically, asking 18 end-users, with vari-
ouslevelsofpriorbugreportingexperience,toreport12bugsfrom
sixAndroidappsusingaprototypeimplementationof Burt.We
foundthattheguidanceandautomatedsuggestions/clarifications
made by the chatbot were accurate, useful, and easy to use, and
the collectedbug reportsare high-quality. Weasked 18 additional
end-users to report the same bugs with a template-based bug re-
portingsystem( Itrac)andcomparedthequalityofthesereportsto
thosereportedwith Burt.Burtreportshavefewerincorrectand
missingS2Rsthanthe Itracreports.Wealsofoundthat Burthelps
novicebugreportersprovidemorecorrectsteps,andexperienced
reporters avoid missingsteps.
In summary,the contributionsofthis paper are as follows:
‚Ä¢Burt,thefirsttask-oriented,conversationalagentthatsupports
end-users in reporting bugs (currently for Android apps), with
features such as automated suggestions, real-time feedback,
prompts for information clarification,andgraphicalcues.
‚Ä¢Theresultsofanempiricalevaluationinvolving36end-users
thatinvestigates user experiences, preferences, and attributes
ofinteractivebugreportingwith Burt,aswellasthequality
ofthe resultingbugreports.
Ourworkopensthedoortoanewwayofthinkingaboutend-
userbugreporting,usingconversationalagents,shiftingthestate
of the art from statictointeractive bug reporting. While Burtis a
prototype, we expect that it will serve as the foundation fora new
classofinteractivebug reportingsystems,combiningelementsof
existingstaticsystemswithfeaturesofconversationalagents[ 36].
2 BURT:A CHATBOTFORBUG REPORTING
We propose a task-oriented chatbot for BUg RepoRTing (Burt).
Burtoffers a variety of features for interactive bug reporting such
as the ability to (i) guide the user in reporting essential bug report
1   - The Chat Box 2   - Reported Steps Panel4   - Quick Action 
Panel
3   - Screen Capture Panel5   - Tips Panel
Figure 1:B URT‚Äôsgraphicaluserinterface
elements, (ii) check the quality of these elements, (iii) offer instant
feedbackaboutissues,and(iv) providegraphicalsuggestions.
Burtis designed to collect three key elements for developers
during bug triage and resolution [ 48,57,65]: theobserved behavior
(OB),theexpected behavior (EB),and the steps to reproduce the bug
(S2Rs).Burtcollectsthesefromtheuserthroughadialogueand
generatesa web-basedbug reportcontaining textualdescriptions
for theseelements withattachedscreen captures of the system.
Burt‚Äôsdesignconsistsofthreemaincomponents,inspiredbythe
typicalarchitectureoftask-orienteddialoguesystems[ 36],which
adapttechniquesfromautomatedprogramanalysisandnaturallan-
guage processing to facilitate bug reporting. Burt‚ÄôsNatural Lan-
guage Parser (NL) parses the relevant information from end-user
responsestothechatbot.The DialogueManager(DM) dictates
the structured conversation flow for Burt‚Äôs reporting process and
handles the presentation of multi-modal ( e.g., screenshots and text)
informationtotheuser.Finally,the ReportProcessingEngine
(RP)mapsinformationparsedfromuserresponsestovariousstates
in a program execution model for a given app in order to assess
bugelementquality.Thecurrentversionof Burtisdesignedfor
Androidappsandbuildsitsexecutionmodelusingacombination
ofautomatedappexplorationandcrowdsourcedusertraces.Inthis
section, we present Burt‚Äôscomponentsindetail.
2.1 GraphicalUser Interface (GUI)
We designed Burtas a web-based application that includes both a
standardchatbotinterfacealongwithadditionalvisualcomponents
as illustrated in Fig. 1. TheChat Box
 allows the end-user to
provide textual descriptions of the OB, EB, and S2Rs as well as
interact with the graphical information that Burtdisplays ( e.g.,
recommendationsofthenextS2Rsviascreenshots).The Reported
Steps Panel
 enumerates and displays the S2Rs that the user has
reported.Thetextualdescriptionofthereportedstepscanbeedited
andthelastreportedstepcanbedeleted,iftheusermakesamistake
andwishestocorrectit.The ScreenCapturePanel
 displaysscreen
capturesofthelastthreeS2Rs.The QuickActionPanel
 provides
buttonstofinishreportingthebug,restartthebugreportingsession,
and(pre)viewthebugreportbeingcreated≈õthesecanbeactivated
345TowardInteractive BugReporting for(Android App) End-Users ESEC/FSE ‚Äô22, November14≈õ18, 2022,Singapore, Singapore
anytime.The TipsPanel
 displaysrecommendationstoend-users
onhowtouse BurtandhowtobetterexpresstheOB,EB,andS2Rs.
Thetipschangedependingonthecurrentstageoftheconversation.
2.2 NaturalLanguage Parser (NL)
BurtparsestheOB,EB,andS2Rdescriptionsprovidedbyend-users
usingdependencyparsingviatheStanfordCoreNLPtoolkit[ 50].
This process obtains the tree of grammatical dependencies [ 17]
between words in a sentence and extracts the relevant words from
thetree.ThisparsingtechniqueisneededbytheReportProcessing
Enginetoassessthequalityofparsedbugreportelementsandto
helpdirectthe flowofconversation (see Sec. 2.4.2).
Burtfirstutilizestheheuristic-basedapproachintroducedby
Chaparro et al.[29] to identify the type of a sentence ( e.g., con-
ditional, imperative, or passive voice) for each message received
fromtheuser.Thisapproachimplementsheuristics(basedonde-
pendency parsing and part-of-speech tagging [ 50]) to identify dis-
course patterns in OB, EB, and S2R descriptions [ 29]. Once the
sentence type is identified, Burtexecutes a series of algorithms to
extract the relevant words from the sentence, based on prior work
on quality assessment of S2Rs [ 28]. In essence, we implemented
16parsingalgorithmsthattraversethegrammaticaltrees[ 17]of
end-user sentences which have a different structure depending on
the sentence type ( e.g., conditional or imperative). Each algorithm
parsessentencesofonetype.Allthe16algorithmsimplemented
for the different types of OB/EB/S2R sentences can be found in our
onlinereplication package [ 21].
Burtparses asinglesentence using the following format:
[subject] [action] [object] [preposition] [object2]
where the subjectis the actor ( e.g., the user or an app component)
performingthe action,whichisanoperationortask( e.g.,tap,create,
crash);the objectisan≈Çentity≈ædirectlyaffectedbythe action,and
object2isanother≈Çentity≈ærelatedtotheobjectbythe preposition .
An≈Çentity≈æisanounphrasethatmayrepresentnumeric/textual
appinput,domainconcepts,GUIcomponents, etc.Dependingon
thesentence,itstype,andwhetheritdescribesanOB,EB,orS2R,
thewords( e.g.,thesubject,preposition orobject2)extractedfrom
the entity are requiredoroptional.
For example, for the Mileage Android app [ 12], the OB sentence
≈ÇTheaveragefueleconomyshowsaNaNvalue≈æ ,writteninpresent
tense, is parsed as [average fuel economy] [shows] [NaN value] .
The EB sentence ≈Çfuel economy statistics should be calculated cor-
rectly≈æ, which uses the modal≈Çshould≈æ, isparsed as [average fuel
economy] [is] [calculated] .TheS2Rsentence ≈ÇSavethecarfillup≈æ ,
written imperatively,isparsedas [user] [saves] [car fillup] .
SomesentencesdescribeacombinationofOB,EBandS2Rsin
asinglephrase.Forexample,thesentence ≈ÇTheappstoppedwhen
I added a new time range≈æ describes both an OB and a S2R. This
sentenceisparsedby Burtas[app] [stopped] astheOB,and [add]
[new time range] as the S2R. In this example, Burtextracts the
S2Rfromthesentenceasfollows.First,itlocatestheadverb ≈Çwhen≈æ
in the parsed grammatical tree, then it follows the relationship
that leads to the verb ≈Çadd≈æfor which ≈Çwhen≈æis the adverbial
modifier. Next, Burtlocatestheverb‚Äôsnominalsubject≈ÇI≈æ and its
direct object ≈Çtime range≈æ . If these relationships donot exist in the
tree, the sentence is not conditional, as expected. Otherwise, Burt
Prompt User 
for OB/EB/S2R 
Descrip6onUser Writes 
OB/EB/S2R
Screen 
Match?Check OB/EB/S2R
Quality
Show
Screens to UserSelect One
Screen
Ask for Next Bug 
Report Element
Ask User to 
Rephrase
User 
Re-phrases 
OB/EB/S2R
Figure 2: Burt‚Äôsdialogueflow forqualitychecking
extracts the verb ≈Çadd≈æas theactionand the noun phrase ≈Çtime
range≈æas theobject. In the end, this sentence is parsed as the S2R:
[add] [new time range] .
When multiple sentences compose a single user message, Burt
only parses the initial sentence. When Burtis unable to parse a
usermessage( e.g.,becauseitcannotidentifythe subject),itasks
theusertorephrasethesentence. Burt‚ÄôsTipsPanel
 anduser
guide suggests patterns to the user to phrase the OB, EB, and S2Rs.
2.3 Dialogue Manager (DM)
Burt‚Äôs dialogue flow consists of three main phases: OB, EB, and
S2R collection. Burt‚Äôs dialogue is multi-modal in nature, and is
capableofsuggestingbothnaturallanguageandgraphicalelements,
suchasscreenshots,tohelpguidetheuserthroughthereporting
process. The DM relies upon the RP engine to assess the quality of
bug elementsreportedbyendusers(see Sec. 2.4.2).WhileBurt‚Äôs
dialogueflowproceedslinearlytocaptureeachbugelement(the
OB, EB, and S2Rs, in that order), the dialogue flow is similar for all
elements.Therearetwomaindialogueflowsthat Burtnavigates:(i)
performing quality checks on written bug report elements (applies
toallbugelements),and(ii)automatedsuggestionofS2Rs(forS2Rs
only). Nextwe describe thesetwomain dialogueflows.
2.3.1 Dialogue Flow for Bug Element Quality Checks (OB/EB/S2R).
Before the dialogue begins, a user must select the target app by
clickingonitsicon.Then, Burt‚Äôsdialogueflowforqualitychecking,
illustrated in a modified swimlane diagram in Figure 2, is initiated,
startingwith the OB. To begin the qualitychecking process, Burt
promptstheusertoprovidethebugelement(OB/EB/S2R). Burt
automatically parses the description of the element and the RP
engine verifiesits quality (see Sec. 2.4.2).
If the OB/EB/S2R is matched to an app screen from Burt‚Äôs exe-
cutionmodel(seeSec. 2.4.1),Burtaskstheuserforconfirmation
ofthematchedscreen.Iftheuserconfirms, Burtproceedstothe
nextphaseoftheconversation( e.g.,askingfortheEBornextS2Rs),
otherwise, Burtasks the userto rephrase the bugelement.
Iftherearenoappscreenmatches, Burtinformstheuserabout
theissueandaskshertorephrasetheOB/EB/S2R.Oncetheuser
provides a new description, the quality verification procedure is
re-executed.Ifthereare multiplematches,Burtprovidesalistofup
tofiveappscreenshots(derivedfromtheappexecutionmodel)that
matchthedescription.Theusercantheninspecttheappscreens
346ESEC/FSE ‚Äô22, November14≈õ18, 2022,Singapore, Singapore Yang Song,JunayedMahmud,Ying Zhou,Oscar Chaparro, Kevin Moran, Andrian Marcus, DenysPoshyvanyk
Suggest Likely 
Screens from 
Current Posi6onUser Selects 
One, Mul6ple, 
or No Screens
Screen
Selected?
Suggest 
Addi6onal
Screens
User Selects 
One, Mul6ple, 
or No Screens
Ask User 
if they 
would like 
addi6onal
screen 
sugges6ons 
(if any)User 
Responds Yes 
or No
Response
Prompt User for 
S2R Descrip6onUser Writes 
S2R
Figure 3:DialogueFlow forS2R Predictions
andselecttheonethatshebelievesbestmatchesherdescription
ofthe bugelement. Ifnone are selected, Burtsuggestsadditional
appscreensifany.Iftheuserselectsoneappscreen, Burtsaves
the bug element description and screen, and proceeds to collecting
the next bug element. After three unsuccessful attempts to provide
a high quality OB description, Burtrecords the (last) provided OB
description for bug report generation. This process proceeds for
each bug element starting with the OB. S2Rs are treated slightly
differently since Burtcan alsopredictS2Rs as we describe next.
2.3.2 DialogueFlowforSuggestingS2Rs. BURTsuggestspotential
nextS2Rsthattheusermayhaveperformedduringactualappusage,
depending on the last reported step and the user-selected screen
thatishavingtheproblem, i.e.,theOBscreen.Figure 3illustrates
this process. This dialogue flow uses a predictive algorithm that
usesBurt‚Äôsexecutionmodel(seeSec. 2.4.3).Thesuggestionsare
displayedasalistofappscreens,eachscreenrepresentingaS2R.
Each S2R in the list displays the screen capture with a textual
description placed below the image. The screen capture is visually
annotated with a yellow oval highlighting the GUI component
(e.g., a button) executedby the step. The usercan select none, one,
or multiple of the suggested S2Rs. When a S2R is selected, Burt
suggests additional S2Rs if any. When none are selected and Burt
has more suggestions, Burtasks the user if she wants to get more
suggestions.Ifso, Burtdisplaysthem.Otherwise, Burtprompts
the userto describe the nextS2R.
2.3.3 Collecting Input Values. User input from type-like steps ( e.g.,
≈ÇI entered 5 gallons ≈æ) are extracted by Burtfrom the objector
object2oftheparsedS2Rs,byidentifyingliteralvaluesorquoted
text. If the input value is missing or generic ( i.e., not a literal or
≈Çtext≈æ),Burtprompts the user to provide the input. This is only ac-
tivatedifthematchedS2RisconfirmedbytheuserasacorrectS2R.
2.4 Report Processing Engine(RP)
Burt‚Äôs RP Engine is composed of three sub-components: (i) the
AppExecutionModel ,(ii)theDialogueQualityProcessor whichmaps
parsedbugreportelementstoappstatesfromthemodel,and(iii)
theS2RResponsePredictor whichinferslikelynextS2Rs,givenan
existing setofS2Rs already mappedto the executionmodel.2.4.1 AppExecutionModel. Theappexecutionmodelisagraph
thatstoressequentialGUI-levelappinteractions( e.g.,taps,types,or
swipesperformedonscreenGUIcomponents)andtheappresponse
to those interactions ( i.e., app screens). These interactions and app
responsesareproducedusingtwostrategies:(1)byexecutingan
automatedsystematicappexplorationadaptedfrom CrashScope ‚Äôs
GUI-ripping Engine [52,54], and (2) by recording (crowdsourced)
app usage information from app end-users or developers. Both the
systematic app exploration and app usage data are collected before
Burtisdeployedfor use.
AppExecutionModelDataCollection. ThisisBurt‚Äôsplat-
form-specific part and would be constructed differently for non-
Androidapplications. Burtusesaversionof CrashScope ‚ÄôsGUI-
rippingengine [52,54]togenerateappexecutiondataintheform
of sequential interactions. CrashScope enables dynamic analy-
sis of Android apps that utilizes a set of systematic exploration
strategies ( e.g., top-down and bottom-up) and has been shown
to exhibit comparable coverage to other automated mobile test-
ing techniques [ 52]. For a detailed description of the engine, we
refer the readers to Moran et al.‚Äôs previous work [ 52,54]. As in
prior work [ 23,24,31,37,40], we instantiate data collection by
recordinglow-levelappeventtracesusingthe getevent,sendevent ,
uiautomator utilities includedinthe Android OS andSDK.
Collectingcrowdsourceduserappusagedataservestwomain
purposes: (1) increase the coverage of app states and screens in
Burt‚Äôsexecutionmodel;and(2)augmentthemodelwithscenarios
thatarecommonduringnormalappusage.Section 2.5describes
the procedure that we implemented to collect the crowdsourced
data. Crowdsourceddata collection leadsto the same types of app
eventsas the automaticapp explorationdoes.
App Execution Model Structure. The execution model is a
directedweightedgraph ùê∫=(ùëâ,ùê∏),whereùëâisthesetofunique
app screens with complete GUI hierarchies [ 2], andùê∏is a set of
app interactions performed on the screens‚Äô GUI components. In
this model, two screens with the same number, type, size, and
hierarchicalstructureofGUIcomponentsareconsideredasingle
vertex.ùê∏is a set of unique tuples of the form (ùë£ùë•,ùë£ùë¶,ùëí,ùëê), where
ùëíis an application event (tap, type, swipe, etc.) performed on a
GUI component ùëêfrom screen ùë£ùë•, andùë£ùë¶is the resulting screen
right after the interaction execution. Each edge stores additional
information about the interaction, such as the textual data input
(onlyfortypeevents)andtheinteractionexecutionorderdictatedby
theappusage(manualorautomatic).Thegraph‚Äôsstartingnodehas
onlyoneoutgoinginteraction,whichcorrespondstotheapplication
launch.AGUIcomponentisuniquelyrepresentedbyatype( e.g.,
a button or a text field), an identifier, a label ( ‚ÄòOK‚Äôor‚ÄòCancel‚Äô),
and its size/position in the screen. Additional information about
a component is stored in the graph, for example, the component
descriptiongivenbythedeveloper,theparent/childrencomponents,
andanannotatedscreencaptureoftheapphighlightingtheGUI
component being interacted with. The screen captures are used in
the screen suggestionsmadeby Burt(see Sec.2.4.3).
Thegraphedgeshaveaweightwhichindicatesthelikelihood
of a given app interaction represented as a state transition. The
weights are utilized by the S2R Response Predictor (see Sec.2.4.3),
which aims to suggest S2Rs that end-users would perform when
normally using given app features. To enable accurate predictions,
347TowardInteractive BugReporting for(Android App) End-Users ESEC/FSE ‚Äô22, November14≈õ18, 2022,Singapore, Singapore
Burtassignshigherweightsto interactionsexecutedbyhumans
than those executed automatically by CrashScope . To accomplish
this,Burtsets the weight of an edge to the number of timesit was
executedinthecollectedusagedata.Ifanedgeisnotexecutedbya
human,butwasexecutedby CrashScope ‚Äôssystematicexploration,
then edge weight is set to one, even if CrashScope executes the
same interaction multiple times. While this weight assignment
scheme isstraightforward,itprovedto be effective (see Sec. 4).
2.4.2 DialogueQualityProcessor. Basedonpriorwork[ 28],Burt‚Äôs
quality definition is based on the ability to match a textual bug de-
scription(OB,EB,orS2R)tothescreens(states)andinteractions
(edges) of the execution model. A textual description is consid-
ered to be high-quality if it can be precisely matched to the exe-
cutionmodel,otherwiseitisdeemedlow-quality.Thisdefinition
andBurt‚Äôs dialogue features that prompt users to improve low-
quality descriptions aim to reduce the knowledge gap between the
reporters,whoareunfamiliarwithappinternalsandmaynotknow
howtoexpressabug,anddevelopers,whodefineandimplement
the vocabulary capturedin Burt‚Äôsexecutionmodel.
Assessing OB Quality. Burtfirst builds a query to the app ex-
ecution model by concatenating the non-empty elements from the
parseddescription,namelythe subject,action,object,andobject2.
Then, it preprocesses the query using lemmatization [ 50] and at-
tempts to retrieve all matching GUI components via an adapted
version of the matching procedure proposed by prior work [ 28].
Thisprocedurecomputes thesimilarityscorebetweenthe query
andtheelementsfromaGUIcomponent,namelythecomponent
label,thedescription,andtheIDspecifiedbytheoriginaldeveloper.
The similarity is computed based on a normalized length of the
longest common substring between query and the component ele-
ments. If such similarity is greaterthan orequal to 0.5, then there
is a match, otherwise there is a mismatch. If the initial query does
notmatchanappscreen, Burtrunsadifferentquerybyusingonly
thesubject,since,basedonourexperience,itmayindicateakey
GUI componentthat isdirectlyrelatedwithabug.
Burtkeepsa listof theapp screens with atleast one matching
GUI component. Such a list is sorted in increasing order by the
distance between the starting state in the execution model and the
matchedstate.Ifthislistisempty,itmeanstheOBdescriptiondoes
notusevocabularyfromtheappscreensandneedstoberephrased.
Ifthislistcontainsonlyoneelement,itisusedtoshowtheuserthe
potentialbuggyappscreen,whichtheuserhastoconfirmascorrect
or incorrect. Otherwise, if the list contains multiple elements, it
isusedtodisplaythepossiblebuggyappscreenssothattheuser
decides the appropriate screen. The selected OB screen by the user
is tracked in the execution model and is used for (1) EB description
matching, (2) the prediction of the next S2Rs, and (3) asking the
userif the last providedS2R isthe last step to replicate the bug.
Assessing EB Quality. Burtperforms the matching approach
described above using the parsed EB description against the OB
screenconfirmedbytheuser. BurtassumestheOBscreenisthe
one that should work correctly, therefore, it attempts to match the
EB description to it. If the user did not select an OB screen, the EB
matchingisbypassedandtheEBdescriptionissavedforgenerating
the bug report. If the EB description does not match the OB screen,
it means the vocabulary used in the EB description is differentfrom the OB screen, and the EB description should be rephrased.
However, rather than prompting the user to rephrase it, Burtasks
the userif the OBscreen isthe one that should work correctly.
AssessingS2RQuality. Burtadaptsthestepresolution/match-
ing algorithm proposed by Chaparro et al.[28] and performs ex-
ploration of the execution model driven by the matching of the
reportedS2Rs.Bydefault, BurtassumesthefirstS2Rperformed
by a user is launching the app and the current graph state is set to
be the firstapp screen that results from this operation.
ForaprovidedS2Rdescription,startingfromthecurrentstate,
Burttraverses the graph in a depth-first manner and performs
stepresolutiononeachstate.Stepresolutionistheprocessofde-
termining the most likely app interactions that the S2R refers to
ina particular state( i.e., app screen).Theresult isa set of resolved
interactions for the S2R on the selected states. If the S2R resolution
failsforthesestates(eitherwithamismatchoramultiple-match
result),thenitmeansthateither:(1)thereareappstatesnotpresent
in the execution model, or (2) the S2R description is of low-quality.
Theresolved interactions are matched against the interactions
(i.e.,theedges)fromthegraph,bymatchingtheirsourcestate ùë£ùë•,
the event ùëí, and the component ùëê. If a pair of interactions match,
then they are considered to be the same interaction. The matching
returnsasetofinteractionsfromthegraphthatmatchtheresolved
ones. If this set is empty, it means that the resolved interactions
werenotcoveredbytheappexplorationandthequalityassessment
returns a low-quality result with a mismatch. If the reason for the
mismatchisbecauseofmultiple-componentor-eventmatch( i.e.,
theS2RdescriptionmatchesmultipleGUIcomponentsormapto
multiple events), Burtconsiders theS2R as ambiguous,and Burt
indicatesthattheS2R‚Äôs actioncorrespondstomultipleevents,or
theobjectorobject2matchmultipleGUIcomponents.Ifthereisa
no-match, Burtspecifies the problematic vocabulary from the S2R
elements: action,object,object2,orany combination of these.
Otherwise,ifthe setof resolvedinteractions isnotempty, Burt
proceeds with selecting the most relevant interaction that corre-
spondstotheS2Rdescription,byselectingtheonewhosesource
state isthe nearestto the currentexecutionstate inthe graph.
2.4.3 S2RResponsePredictor. BURTpredictsthenextS2Rsthata
user may have performed in practice. The prediction is executed
duringthefollowingdialoguescenarios(seeFig. 3):(1)whenanOB
screenfromtheexecutionmodelhasbeenselected/confirmedby
theuser,(2)whentheS2Rcollectionphasestarts,(3)rightafterthe
userconfirmsamatchedS2RforherS2Rdescription,or(4)when
the userhas already selectedone ormore S2Rs suggestions.
Burtimplementsashortest-pathapproachtopredictthenext
S2Rs. First, Burtdetermines the paths between the current graph
state and the corresponding OB state. Then, Burtcomputes the
likelihoodscore basedonthe executionmodeledge weights.
Burtuses the equation below to compute the score ùëÜùëùof an
ùëõ-edge path ùëù={ùë§1,ùë§2,...,ùë§ùëõ},withùë§ùëòbeing edge ùëò‚Äôsweight:
ùëÜùëù=1
ùëõ/summationtext.1
ùëòùë§ùëò+1
ùëõ
The first term in the sum is the average weight among all path
edges andthe secondterm isafactor that favorsshorterpaths.
Once the paths are ranked by their scores (in descending order),
these are modified to include loops, i.e., steps that lead to the same
appscreen( e.g.,typesforprovidinginputvalues).Then,onlythe
348ESEC/FSE ‚Äô22, November14≈õ18, 2022,Singapore, Singapore Yang Song,JunayedMahmud,Ying Zhou,Oscar Chaparro, Kevin Moran, Andrian Marcus, DenysPoshyvanyk
first five steps for each path are selected. With only the first five
steps, all unique paths are kept and only the top-2 paths are saved
forbeingpresentedtotheuser.Thefirstoneisalwayspresented
andiftheuserdoesnotselectanyofthestepsasbeingthenextS2Rs
and wants more suggestions, the second path is presented next.
Every time the user selects a suggested step as being the next step,
the prediction/suggestion processrestarts withnewpredictions.
2.5 BURTImplementation
Burtis currently implemented as a webapplication with two ma-
jorcomponents:thefront-end,developedwiththeReact Chatbot
Kit[14],andtheback-end,developedwithSpringBoot[ 16].Burt‚Äôs
implementationistailoredforAndroidapplications,however,its
underlyingtechniquesaregenericenoughtobeeasilyimplemented
forothertypesofsoftware√êtheAppExecutionModelDataCol-
lection isthe only platform-specific part.
Tocollectthecrowdsourcedappusagetracesfor Burt,twocom-
puter science students, who did not have knowledge of our studied
bugs, were instructed to use the apps‚Äô features as they typically
would do, and recorded traces that exercise key app features. Addi-
tionally,twoofthepaperauthorsrecordedsequencessimulating
appdeveloperswhotesttheapps.Thesetraceswereconvertedand
mergedintoappexecutionmodelsforeachofthestudiedappsas
described in Sec. 2.4.1. In practice, developers can utilize recorded
tests, crowdsourced data, or automated app exploration techniques
witha≈Çone-time≈æcostfor buildingthe app executionmodel.
3 EMPIRICALEVALUATION DESIGN
We conducted two user studies to evaluate: (1) Burt‚Äôs perceived
usefulnessandusability;(2) Burt‚Äôsintrinsicaccuracyinperforming
bugreportelementqualityverificationand prediction;and(3)the
quality of the bug reports collected with Burt, compared with
reports collected by a template-based bug reporting system. We
aim to answer the following researchquestions(RQs):
RQ1:WhatBurtfeatures doreportersperceiveas (not)useful?
RQ2:WhatBurtfeaturesdoreportersperceiveas(not)easytouse?
RQ3:What is the accuracy of Burtin performing bug element
quality verification and prediction during the bug reporting process?
RQ4:What is the quality of the bug reports collected by Burtcom-
pared to reports collected by a template-based bug reporting system?
To answer the RQs, we selected a set ofAndroidapp bugsused
in prior research (Sec. 3.1), and asked bug reporters to report these
bugsusing Burtandtoevaluatetheirexperience(Sec. 3.2).Weana-
lyzedtheconversationsthereportershadwith Burtandmeasured
how accurate Burtwas during the reporting process (Sec. 3.3).
Then, we asked additional participants to report the same bugs
with a template-based bug reporting system (Secs. 3.4.1and3.4.2),
and analyzed the collected bug reports to measure their quality
basedonbugelementcorrectness(Sec. 3.4.3).Wepresentanddis-
cuss the results in Sec. 4. Our user studies were approved by an
Institutional Review Board (IRB) and conducted remotely due to
restrictionsrelatedto COVID-19.
3.1 AppsandBug Dataset
We selected 12 Android app bugs from the bug dataset provided
by Cooper et al.[31]. The apps in the dataset support different appTable 1:Appsand bugdataset
AppBug ID #ofS2Rs Bug type
APODCC3 11Incorrect colorinGUIcomponent
RB 5 Error message onscreen
DROIDCC5 7 Crash
CC6 12 Crash
GNUCC9 13 Duplicated GUIcomponent
RC 5 Crash
GROWCC5 10 Crash
RC 8 Crash
TIMECC1 16 GUIcomponentdisappears
CC4 9 Crash
TOKCC2 10 Crash
CC7 6GUIcomponentdoes not appear
domains and have been studied in prior research [ 24,28,52,53].
The apps are: AntennaPod (APOD) [ 3] ≈õ a podcast manager, Time
Tracker(TIME)[ 18]≈õatime-trackingapp,AndroidToken(TOK)[ 1]
≈õ a one-time-password generation app, GnuCash (GNU) [ 8] ≈õ a
personal finances manager, GrowTracker (GROW) [ 9] ≈õ a plant
monitoringapp,andDroidWeight(DROID)[ 6]≈õapersonalweight
tracking app. This dataset provides, for each bug, the APK installer
thatcontainsthebug,thedescriptionoftheincorrect(observed)app
behavior(OB),theexpectedappbehavior(EB),andthe(minimal)
listofthe steps to reproduce the bug(S2Rs).
Fromthe60bugs(35crashesand25non-crashes)inCooper et
al.‚Äôs dataset [ 31], we selected 12 bugs (7 crashes, 1 handled error,
and4non-crashes)usingastratifiedrandomapproach(seeTable 1).
Werandomlyselectedtwobugsfor eachofthesixapps,ensuring
thatthebugsrepresentavarietyofbugtypesthatmanifestvisually
onthedevice(crashes,GUIissues,functionalbugs, etc.)andhave
a diverse number and type of S2Rs (taps, types, swipes, etc.). Six
bugs contain 5‚àí9(minimal) S2Rs, and six bugs contain 10‚àí16
(minimal) S2Rs (see Table 1). The 12 bugs are reproducible on a
specificweb-based Android emulatorconfiguration(virtual Nexus
5X withAndroid 7.0 configuredviathe Appetize.io [ 5]service).
3.2 RQ 1& RQ2:BURT‚ÄôsUser Experience
We asked participants to report a selected subset of bugs using
Burt,andevaluate theirexperience viaan onlinequestionnaire.
3.2.1 BURTBugReporterRecruitment. Wereachedoutto36po-
tentialparticipantswithmixedexperienceinbugreportingfrom
our personal network, who were not involved in or aware of the
purpose of this work. They were offered a $15 USD gift card for
participation.Fromthese,24userscompletedthestudyanddata
fromsixparticipantswasdiscardedduetolow-effortanswers,thus
resulting in valid responses from 18 participants. Four of the six
participantsdidnottreatthestudyseriously,thatis,theysubmitted
incompletereports(e.g.,onlytheOBwasreported)andanswered
allsurveyquestionswiththesameresponse.Theremainingtwo
participantsreportedcompletelydifferentbugstotheonesassigned.
Five participants had not reported a software bug before, nine had
reportedfiveorfewerbugs,andtheremainingfourhadreported
morethanfivebugs.Theparticipantswereunfamiliarwith Burt
andthe selectedapps/bugs.
349TowardInteractive BugReporting for(Android App) End-Users ESEC/FSE ‚Äô22, November14≈õ18, 2022,Singapore, Singapore
Table2:QuestionnaireforevaluatingB URT‚Äôsuserexperience
ID Question
Q1Howoften were Burt‚Äôsscreen suggestions useful?
Q2Howoften was Burtable to understandyour OB/EB/S2Rs?
Q3How often were you able to understand Burt‚Äôs messages/questions?
Q4WasBurt‚Äôspanelofreported steps useful?
Q5Howeasy to use was Burtoverall?
Q6Which of Burt‚Äôsfeatures didyoufind easy/difficult to use?
Q7What additional functionality (if any) would you like to see in Burt?
3.2.2 BugAssignmentandReporting. Eachofthe18participants
was randomly assigned to report three bugs (from the 12 selected)
withBurt,eachbugcorrespondingtoadistinctapp.Thereporters
were instructed to report the bugs in a given (random) order to
account for potential learning biases. The bug reporting procedure
consisted of five tasks which included the users: (i) watching a
short instructional video that explained how to use Burtvia an
example; (ii) familiarizing themselves with the apps on the web-
based emulator; (iii) watching a video demonstrating the observed
and expected behavior for each assigned bug (with annotations
toensure properunderstanding); (iv)reproducingthe bugson the
web-based emulator; and (v) reporting each bug with Burt. We
aimed to control for participantunderstanding ofthebugs so that
the effectofpotentialmisunderstandingswasminimized.
3.2.3 BURT‚ÄôsUserExperienceAssessment. Aftertheparticipants
reported the three assigned bugs, they answered an online ques-
tionnairethatwasmeanttoassess Burt‚Äôsusefulnessandeaseof
use and to obtain feedback for potential improvements to Burt.
Table2shows the questions asked to the participants, which are
inspiredbythe PARADISE [ 39]evaluation framework.
To address RQ1, we focused on evaluating Burt‚Äôs four main
features: (1) Burt‚Äôs app screen suggestions for the OB, EB, and
S2Rs; (2)Burt‚Äôs ability to parse and match the OB, EB, and S2R de-
scriptions provided by the user; (3) Burt‚Äôs messages and questions
given to the user; and (4) Burt‚Äôs panel of reported S2Rs, which
allowsthe userto visualizeandedit thereportedS2Rs. Questions
Q1-Q5 in Table 2aim to address RQ1and used a 5-level Likert
scale[55].Weaskedtheparticipantsto(optionally)provideajus-
tification/rationalefortheiranswers.Eachbuginvolvedmultiple
screensuggestions,OB/EB/S2Ruserdescriptions,and Burtmes-
sages/questions.QuestionsQ1-Q3refertothefrequencyofthese
userinteractionswith Burt.
To address RQ2, the reporters assessed Burt‚Äôs overall ease of
use(Q5)andindicated Burt‚Äôsspecificfeaturesthatwereeasyor
difficult to usefor them (Q6). Q5used aused a5-level Likert scale
and Q6 requested an open-ended response. The reporters were
also asked to indicate additional features they would like to see
inBurt(Q7). Additional open-ended questions were asked (not
showninTable 2) to obtain feedbackonhowto improve Burt.
3.3 RQ 3:BURT‚ÄôsIntrinsicAccuracy
Toanswer RQ3,weanalyzedtheconversationsthatthereporters
hadwith Burttodetermine:(1)howoften Burtwasabletocor-
rectlymatchOB/EB/S2Rdescriptionstotheappexecutionmodel
asconfirmedbythereporters;and(2)howoftentheuserselected
oneormoreofthesuggestedappscreensasbeingcorrect( i.e.,theymatchthereporters‚ÄôOB/EB/S2Rdescriptions).Wecomputedstatis-
tics onthe (meta)datathat Burtcollected fromthe conversations,
such as, the type of messages that Burtasked and the type of user
responses (as definedby Burt‚ÄôsDialogueManager≈õsee Sec. 2.3).
3.4 RQ 4:BURT‚ÄôsBug Report Quality
We describe the methodology to answer RQ4inthis section.
3.4.1Itrac: A Web Form for Bug Reporting. We implemented a
web/template-based bug reporting interface, called Itrac, using
Qualtrics [ 22].Itracoffers the same features of professional issue
trackers ( e.g., GitHub Issues [ 7] or JIRA [ 10]), for reporting the OB,
EB,andS2Rs.Specfically, Itracprovidestextboxeswithexplicit
prompts that ask for the bug summary/title and the OB, EB, and
S2Rs.Inaddition, ItracpromptsthereportertoprovidetheS2Rs
usinganumberedlist(viaagiventemplate).Thereporterscanwrite
freely their own bugdescriptions in thetext boxes and also attach
images/files. We use Itracrather than an existing professional
issue tracker to simplify the reporting process for the reporters
because they can use Itracwithouthavingto logintoaservice.
3.4.2 BugReportingwith Itrac.Followingthemethodologyde-
scribed in Sect. 3.2.1, we recruited 18 more end-users, who did not
participate in the Burtstudy, and asked them to report a subset
of bugs using Itrac. These reporters did not know about Burt,
Itrac, and the selected apps/bugs, and had a similar bug reporting
experiencetothatofthegroupwhoreportedthebugswith Burt.
Fiveofthenewreportershadnotpreviouslyreportedasoftware
bug, eight had reported one to five bugs, and the remaining five
hadreportedmore thanfive bugs.
We assigned the same sets of three bugs used in the Burtstudy
to the new users (trying to match the bug reporting experience)
and instructed them to report the bugs using Itracin the same
orderfrombefore.Priortoreportingthebugs,theparticipantswere
instructedto:(i)familiarizethemselveswiththeappsbyusingthem
ontheweb-basedemulator;(ii)watchavideodemonstratingthe
bugs(withannotationstoensureproperunderstanding);and(iii)
reproducing the bugsonthe web-basedemulator.
3.4.3 Measuring Bug Report Quality. We estimate the quality of
the collected bug reports (via BurtandItrac) by assessing the
correctness of the OB, EB, and S2Rs described in the reports, based
onthequalitymodelproposedbyChaparro etal.[28].Threeauthors
manually compared each collected report with the ground truth
scenarios fromCooper etal.‚Äôsdataset[ 31],whichincludedcorrect
descriptionsoftheOBandEBandaminimumviablesetofS2Rs.
Usingthismethodology,wecomputedthefollowing:(i)thenumber
ofincorrectOB/EB/S2Rdescriptions;and(ii)thenumberofmissing
S2Rs. To limit the effect of subjective assessments, two authors
performedthebugreportanalysisindependentlyandathirdauthor
reviewedtheresults,reachingconsensusamongallthreeincaseof
discrepancies.Inordertodeterminehowhelpful BurtandItrac
are for novices or more experienced reporters, we analyzed bug
report qualityacrossdifferentlevels of bugreportingexperience.
4 RESULTS AND ANALYSIS
We present anddiscuss the results of our evaluation for eachRQ.
350ESEC/FSE ‚Äô22, November14≈õ18, 2022,Singapore, Singapore Yang Song,JunayedMahmud,Ying Zhou,Oscar Chaparro, Kevin Moran, Andrian Marcus, DenysPoshyvanyk
Never Rarely Sometimes O!en AlwaysScreens
OB
EB
S2Rs
Messages
Panel
Useless Somewhat Useless Neutral Somewhat Useful Useful
DiÔ¨Äicult Somewhat Di Ô¨Äicult Neutral Somewhat Easy EasyEase of Use
Figure 4:User experienceresults forB URT(Q1-Q5)
4.1RQ1:BURT‚ÄôsPerceivedUsefulness
Fig.4summarizes the users‚Äô answers on: (i) their perceived useful-
ness ofBurt‚Äôs screen suggestions (row labeled Screens); (ii)Burt‚Äôs
abilitytounderstandtheuser‚ÄôsOB,EB,andS2Rdescriptions(rows
OB,EB, andS2Rs); (iii) how often they were able to understand
Burt‚Äôsmessagesandquestions(row Messages);(iv)theirperceived
usefulness of Burt‚Äôs panel of reported S2Rs (row Panel); and (v)
Burt‚Äôsoveralleaseofuse (row EaseofUse ).
App Screen Suggestions . Half of the 18 participants (9) agreed
thatBurt‚Äôsappscreensuggestionswere oftenuseful,andtheother
half (9)agreed theywere sometimes useful. Asfor their rationales,
one participant mentioned that the next S2R screen suggestions
"were useful because they shortened the time it took me to explain
howtoreproducethebug" .Otherparticipantshighlightedthatthe
suggestions "werehelpfulinmakingsureIwasprovidingtheexact
steps I wanted to describe" , or thatBurt≈Çgave very good suggestions
whenitcouldfigureoutwhichscreenhadthebugbasedontheinitial
report≈æ.Someoftheparticipantsevenhopedthat Burtcanprovide
suggestions more frequently. These results illustrate the usefulness
ofBurt‚Äôsapp screen suggestions.
Some participants noted, though, that ≈Çthe suggestions were a
little inaccurate≈æ . We found that the inaccuracies stemmed from
Burtnot being able to recognize/match the user‚ÄôsOB description
becauseofgenericwording,withoutdetails( e.g.,≈Çtheappcrashed≈æ ).
Notethatthe Burt‚ÄôsS2RsuggestionsarenotactivatediftheOB
description is not matched to an app screen, which affected the
reportersexperience.Also,theparticipantsrecommendedthatit
would be useful to have suggestions of ≈Çbug triggering screenshots≈æ ,
as currently, Burt‚Äôs screen captures may not show the bug that
the user wants to report. The participants also found some sugges-
tions confusing because the screen captures for the S2Rshighlight
≈Çnon-existentbuttons≈æ .Thisstemsfrom Burt‚ÄôssystematicGUIex-
plorationtechnique, whichcan executeeventsonGUI components
such as,layoutsorviews,whichare often not visibleto the user.
OB,EB,andS2RUnderstanding. Thereportershaveaposi-
tive overall impression on how often Burtunderstood their OB,
EB, and S2R descriptions. Specifically, Burtwas able to oftenoral-
ways(sometimes )understandtheOB/EB/S2Rdescriptionsof9/10/11
(9/6/6)participants(outof18).Onlytwo/oneparticipant(s)feltthat
BurtrarelyrecognizedtheirEB/S2Rs.
Our analysis of the open-ended answers also reveals that some
participants were generally satisfied with Burtin terms of bug
descriptionunderstanding.This canbe seenincommentssuch as
≈ÇI‚Äômquitesatisfiedwiththerecognitionrate[fortheS2Rs],evenbetterthantalkingtoarealagent≈æ ,≈ÇItalwaysunderstandsmydescriptionof
theOB/EBwhenItriedtousekeywordsfromapps≈æ ,≈Çitwaskindofeasy
forburttounderstandmy(EB)description≈æ ,and≈ÇItcanunderstand
metodescribetheerrorbehavior≈æ .However,severalparticipantshad
a less positive perception of Burt‚Äôs bug description understanding
stating thatit is "difficult tomatch Burt‚Äôs language" , they"need to
follow specific pattern" so thatBurtis able to understand, and they
≈Çusually had to paraphrase≈æ their descriptions. These comments
stem from our design decision to limit the language that users
could use to describe the OB, EB, and S2Rs, and inaccuracies in
bug description matching. However, we observed, based on the
reporters‚Äôcommentsandtheirconversationswith Burt,thatthe
participants learned how to describe the OB/EB/S2Rs using Burt‚Äôs
preferredformatsafterreportingthefirstbug.Still,thereporters‚Äô
main recommendation was to improve Burt‚Äôs ability to recognize
additionalvocabulary andwaysof phrasingthe OB/EB/S2Rs.
BURT‚ÄôsMessagesandQuestions. Eleven(of18)participants
oftenunderstood Burt‚Äôs messages and questions, while six partici-
pantsunderstoodthem sometimes .Onlyinonecase,thereporter
rarelyunderstoodthe messages/questions.
The analysis of their rationales reveals that generally Burt‚Äôs
messages/questionswere ≈Çveryeasytounderstand≈æ .Oneparticipant
wrote that Burt‚Äôs≈Çwording was always clear and I could always tell
whatBurtwas asking for≈æ , also echoed by multiple participants.
Someparticipantsrecommendedtoimprovethemessagesandques-
tions,assometimestheywereunclearandtoosimilartoeachother.
For example, for Burt‚Äôs question ≈ÇWas this the last S2R that you
performed?≈æ , the participants suggested to clarify which last S2R
Burtwasreferringto.
ThePanelofReportedS2Rs. Burt‚ÄôspanelofreportedS2Rs
was deemed to be useful(somewhat useful ) by 9 (6) participants.
Only one participant found that the panel was somewhat useless .
The participants commented that the panel was ≈ÇVery useful for
visualizingabugreport≈æ ,that≈ÇItwasgoodtoseewhatwasgetting
logged≈æ,andthatitwasuseful ≈Çasawayformetoreviewthatthe
reproduction steps I entered are complete≈Ç .
Summaryoffindingsfor RQ1:Overall,reportersfound Burt‚Äôs
screensuggestionsandS2Rpanel useful.They alsohada positive
impression of Burt‚Äôs OB/EB/S2Rs understanding and messages.
Improvementsarerequiredfor Burttosupportadditionalwording
ofbugreport elements andmore accuratesuggestions.
4.2RQ2:BURT‚ÄôsPerceivedEaseofUse
Twelve reporters indicated Burtwas either easyorsomewhat easy
to use. Four reporters were neutral, while two reporters expressed
itwassomewhatdifficult to use (see Easeofuse inFig.4).
We analyzed thereporterresponses regarding whichof Burt‚Äôs
featurestheyfoundeasy/difficulttouse.Ingeneral,theparticipants
expressedthat Burt‚ÄôsGUI≈Çisreallyhelpful≈æ ,≈Çconcise≈æ,and≈Çeasy
to use and understand≈æ . Multiple reporters indicated that selecting
Burt‚Äôsappscreensuggestionswaseasytouseandsomeofthem
were very enthusiastic about them. One reporter mentioned that "I
likedthescreenshotsalot,veryeasytoreporttheprocesstoreproduce
a bug". Other reporters expressed that "The suggestions & confirma-
tions were very easy to use. When it had the right idea, confirming
it was just amatter of clickinga button" , and that Burt≈Çguides the
351TowardInteractive BugReporting for(Android App) End-Users ESEC/FSE ‚Äô22, November14≈õ18, 2022,Singapore, Singapore
Table 3:Qualityassessmentresults forbugreports(BRs) collected by BurtandItrac
App-Bug ID#ofBRs Avg.#ofS2RsAvg.#(%) of Avg.#(%) of #ofBRs with #ofBRs with
incorrectS2Rs missingS2Rs incorrectOB incorrectEB
Itrac Burt Itrac Burt Itrac Burt Itrac Burt Itrac Burt Itrac Burt
APOD-CC3 5 5 4.6 7.4 0.6(16.7%) 0.6(9.7%) 6.4(58.2%) 3.4(30.9%) 0 1 0 3
APOD-RB 4 4 3.3 4.8 0.0(0.0%) 1.8(30.6%) 1.0(20.0%) 1.0(20.0%) 1 1 1 0
DROID-CC5 6 6 4 4.3 0.3(11.1%) 0.5(10.0%) 1.3(19.0%) 0.7(9.5%) 1 2 1 1
DROID-CC6 6 6 4.5 8.5 1.3(44.4%) 1.2(13.7%) 5.0(41.7%) 2.0(16.7%) 0 3 1 1
GNU-CC9 5 5 6.4 10.2 0.8(26.7%) 0.2(2.5%) 4.8(36.9%) 3.2(24.6%) 1 0 1 0
GNU-RC 3 3 4.7 4.3 0.0(0.0%) 0.3(6.7%) 0.0(0.0%) 0.0(0.0%) 0 1 0 0
GROW-CC5 4 4 4.8 7.5 1.3(28.1%) 0.0(0.0%) 4.5(45.0%) 3.5(35.0%) 0 0 0 0
GROW-RC 4 4 5.8 7.5 1.0(30.0%) 0.5(7.1%) 1.8(21.9%) 1.5(18.8%) 1 3 1 0
TIME-CC1 5 5 7.8 10.4 1.0(24.0%) 0.2(2.9%) 6.6(41.3%) 6.2(38.8%) 0 1 0 0
TIME-CC4 4 4 4.3 8 1.0(24.4%) 0.3(5.0%) 3.0(33.3%) 1.3(13.9%) 1 2 2 1
TOK-CC2 4 4 4.8 10.3 0.3(8.3%) 0.8(6.8%) 2.5(25.0%) 0.5(5.0%) 2 2 0 0
TOK-CC7 4 4 5 5.8 0.5(16.7%) 0.3(3.6%) 1.5(25.0%) 0.8(12.5%) 1 0 1 0
Overall 54 54 5 7.5 0.7 (20.4%) 0.6 (8.3%) 3.4 (32.0%) 2.1 (19.4%) 8 16 8 6
usertoprovidea"step-by-step"view≈æ .Thepanelofreportedsteps
waseasy ≈Çto explore≈æ anditwaseasyto ≈Çremoveevents≈æ from it.
Themainreasonbehindusagedifficultieswasthelimitedvocab-
ulary that Burtunderstands, also observed before for RQ1. The
reporters recommended to let the users upload their own screen
captureswhen Burtisunabletoattachscreenstotheuser‚Äôsbug
descriptions,andthe abilityto delete/modify anystep.
Finally,forboth RQ1&RQ2,wefoundnonotabledifferences
inBurt‚Äôsperceivedusefulnessandeaseofusebetweendifferent
levels ofuser‚Äôsbugreportingexperience.
4.3RQ3:BURT‚ÄôsIntrinsicAccuracy
We analyzed the 54 conversations that reporters had with Burtto
determinehowoften Burtwasabletocorrectly(1)matchOB/E-
B/S2Rdescriptionstotheexecutionmodel,and(2)suggestrelevant
OB/S2R app screensto the reporters.
OBReporting. Wefoundthatin3of54conversations(5.5%),
Burtwasabletomatchthereporter‚ÄôsOBdescriptiontothecor-
rectscreenthatshowedortriggeredthebug,asconfirmedbythe
reporter during the conversation. In 35 of 54 conversations (64.8%),
Burtmatched the OB descriptionto multipleapp screens. In those
cases,Burtsuggested the top-5 matched screens so that the re-
porter selected the one s/he was referring to. In 29 of these 35
reports (80%), the reporter selected one of the suggested screens,
while in the remaining 6, the suggested screens were irrelevant.
For the remaining 16 of the 54 conversations (29.6%), Burtwas
not able to match the OB description with any app screen because
of incorrect OB wordingfrom the user and inaccuracies in Burt‚Äôs
messageparserandprocessing.Overall, Burtwasabletocorrectly
matchtheirOBdescriptionsin32of54oftheconversations(59.3%).
EBReporting. AsdescribedinSect. 2.4.2,Burtcanonlymatch
the reporter‚Äôs EB description when there is a matched/selected
OBscreen.Otherwise, BurtcollectstheEBdescriptionfromthe
userasis.Inthe32caseswhen BurtcanverifyEBquality, Burt
was able to match the EB against the OB screen in 17 cases (53.1%)
without having to ask the reporter for confirmation. In 6 of the 32
cases (18.8%), the users confirmed the matched OB screen when
Burtaskedthemaboutthat.Intheremaining9cases(28.1%), Burt
wasnot ableto parse the providedEB description.S2R Reporting. Burtmatched a writtenS2R with a stepfrom
the execution model 205 times in total across the 54 conversations
(3.8timesperconversationonavg.).In157ofthesecases(76.6%),
Burtwas able to match S2Rs correctly. Burtpredicted and sug-
gestedthenextS2Rsin146cases(4.6timesperconversationonavg.)
forthe32conversationswheretherewasamatched/selectedOB
screen.Wefoundthatthereportersselected1.6ofthe3.9suggested
S2Rs (on avg.) in 91 cases (62.3%). In 13 of the 32 conversations,
the reporter always selected S2Rs from the suggested list, meaning
at least one suggestion was correct. In all the 54 conversations,
BurtaskedtheusertorephrasetheirS2Rs176times(3.9timesper
conversationonavg.).Wefoundthatinatleast59ofthesecases
(33.5%),theusermadeamistakeordescribedthestepincorrectly
(e.g.,≈Çincorrectresult≈æ or≈Çno more steps≈æ ).
Summary of findings for RQ3:The results support the users‚Äô
ratings(RQ1)onhowoften Burt‚ÄôsOB/S2Rscreensuggestionwere
usefulandhowoften Burtwasabletounderstandtheuser‚ÄôsOB/E-
B/S2R descriptions. The accuracy assessment revealed cases where
Burt‚Äôs strugglesto parse andmatchtheusers‚Äôdescriptions, how-
ever,Burtisabletocontinuewithrephrasingprompts.Theoverall
accuracy indicates that the techniques we used in building Burt‚Äôs
components are adequate. Improvements are planned for future
work to improve Burt‚Äôsaccuracy.
4.4RQ4:Bug Report Quality
Table3summarizesthequalitymeasuresofthe 54√ó2=108bug
reports, collected with ItracandBurt, for the 12 bugs in our
dataset (eachbugisreportedin3to 6reports).
S2RQuality. Overall,asshowninTable 3,Burtreportscontain
fewer incorrect S2Rs than Itracreports on avg. (8.3% vs. 20.4%)
andfewermissingS2Rs(19.4%vs.32%),comparedtotheground-
truth scenarios of the 12 bugs. We performed an analysis to verify
whether there there statistically significant differences between
BurtandItraconthepercentageofincorrectandmissingS2Rs.
We applied the Wilcoxon signed-rank test [ 41] and Cliff‚Äôs delta
(CD) [30] on the results, across the 12 bugs (at 95% confidence
level),sincewehavepairedordinalmeasurements(foreachbug)
that do not necessarily follow normal distributions. We found that
Burt‚Äôs bug reports have fewer incorrect ( ùëù=0.0261) and fewer
352ESEC/FSE ‚Äô22, November14≈õ18, 2022,Singapore, Singapore Yang Song,JunayedMahmud,Ying Zhou,Oscar Chaparro, Kevin Moran, Andrian Marcus, DenysPoshyvanyk
Table 4:S2R qualityby bugreporting experience
Reporting # ofBRsAvg.# of Avg.% of Avg.% of
S2Rs incorrect S2Rs missing S2Rs
experience Itrac Burt Itrac Burt Itrac Burt Itrac Burt
Novice 15 15 3.5 6.7 33.6% 6.7% 45.6% 31.3%
Intermediate 24 27 5.2 7.5 20.1% 11.5% 35.5% 20.0%
Experienced 15 12 6.1 8.6 7.6% 3.2% 12.8% 3.2%
Overall 54 54 5 7.5 20.4% 8.3% 32.0% 19.4%
missing steps ( ùëù=0.0025) thanItrac‚Äôs reports, with a large effect
size (CD=0.5and0.527,respectively).
The main reasons for incorrect S2Rs are generic/unclear step
wording(4in Burtand36Itracreports),duplicateS2Rs(13in Burt
reports, zero in Itracreports), and extra S2Rs (10 in Burtand one
inItracreports). Examples of steps with unclear/generic wording
include≈ÇAdd comment≈Ç or≈ÇI searched for tech≈Ç , where the user
eitherreferstohigh-levelappfeatures,whichmaptomultiplesteps
that are not explicit, or does not specify which GUI components
should be used and/or which action should be applied on them.
ExtraS2Rsareirrelevantreportedsteps( e.g.,≈ÇIdidnothingelse ≈Ç).
WeidentifiedtwomainreasonsforduplicateS2Rs:(1)usermistakes;
and(2)duplicateappscreenssuggestedby Burtandselectedby
the users. The latter stems from the design of Burt‚Äôs execution
model that considers structural variations of the same screen as
different screens (see Sec. 2.4.1). An example is when the users
employ different keyboard layouts ( e.g., numeric vs. alphanumeric)
to enter inputvaluesonthe same screen.
OB/EB Quality. MoreBurtreports have an incorrect OB de-
scription compared to Itracreports (16 vs. 8 out of 54 reports),
while a comparable number of BurtandItracreports have an
incorrect EB description (8 vs. 6). We found that there is no sta-
tistically significant difference between the number of Burtand
Itracbug reportswith incorrectexpectedbehavior ( ùëù=0.1586),
with a small effect size (CD =0.222) in favor of Burt. FewerItrac
reports than Burtreports have an incorrect observed behavior
(ùëù=0.0352), withamedium effectsize (CD =0.361).
The incorrect OB/EB descriptions (in 18 Burtreports and 10
Itracreports total) occurred either because the participants did
notprovideenoughdetailsaboutthebug( e.g.,≈Çtheappcrashed≈æ )
ortheydescribedtheirinabilitytoperformanactionratherthan
describing the bug itself ( e.g.,≈ÇI can‚Äôt add/delete a comment≈æ vs.
≈ÇCrash when trying to add/delete acomment≈æ ).
For the 18 Burtreports, we found that, in 14 cases the users
describedthe OB/EB incorrectly to begin with and Burtcorrectly
prompted them to rephrase them. Nonetheless,they still reported
an incorrect OB/EB. In four cases, Burtaccepted the incorrect
OB/EB, and in only three of the cases, Burtprompted incorrect
OB/EB reporting after the user correctly described them. This is
mainly dueto Burt‚Äôscurrentlimitationonthe OB/EB wording.
Summary of findings for RQ4:Overall,Burtbug reports
containhigher-qualityS2Rsthan Itracbugreports,andcomparable
EBdescriptions.Theresultsindicatethatimprovementsto Burt
are neededto bettercollectOBdescriptionsfrom the reporters.
Novice vs. Experienced Bug Reporters. Our original expecta-
tionwasthat Burtwouldhelpnovicereportersmorethan Itrac,
astheexperiencedreporterslikelyusedtemplate-basedreporting
systemsbefore.We compared the quality of the bug reports across different lev-
els of user‚Äôs bug reporting experience. While we did not observe
notabledifferencesintermsofOB/EBquality,wefounddifferences
in S2R quality, which we discuss. Table 4shows the S2R quality
results for three groups: novice bug reporters (with noprior re-
porting), intermediate reporters (who had reported 1-5 bugs), and
experiencedreporters (whohadreported6+ bugs).
RegardingincorrectS2Rs,experiencedandintermediatereporters
producedabouttwiceasmanyincorrectS2Rswith Itrac,compared
toBurt(33.6%vs.6.7%,and20.1%vs.11.5%onavg.,respectively).
At the same time, novices produced about five times more incor-
rect steps with Itracthan with Burt(7.6% vs. 3.2% on avg.). This
indicates that Burthelpsnovices mostto avoid incorrectS2Rs.
Table4tells a different story for missing S2Rs. Novices and
intermediate reporters missed ‚âà1.5 times fewer S2Rs with Burt,
compared to Itrac, while experienced reporters missed four times
fewer S2Rs with Burt. Surprisingly, this indicates that Burthelps
experiencedreporters mostto avoid missingsteps.
Wedonotspeculateonthereasonsbehindtheseobservations,
as more in-depthstudiesare neededfor proper explanations.
5 LIMITATIONSAND THREATS TO VALIDITY
BeforeBurtis deployed for use, either systematic app exploration
data orcrowdsourced appusagedataneeds tobe collected tocon-
structtheappexecutionmodel.Theevaluationresultsindicatethat
Burtperformsreasonablywellwiththedatacollectedby Crash-
Scopeand only four people. However, we expect that additional
data (more covered states and scenarios) would improve Burt‚Äôs
quality verification of reported elements and screen/step sugges-
tions, enabling the reportingof different bug types, under a variety
of reproduction scenarios. To confirm our expectations, additional
studiesare neededfor future work.
Burtis evaluated in a lab setting where reporters were exposed
to the bugsthrough videos, rather than letting them findthe bugs
while using the apps, as users would do in real life. As in prior
studies[28,53],weadoptedthissettingmainlytoreduceparticipant
effort and fatigue. To address the lack of knowledge about the
apps/bugs, we instructed the users to get familiar with the apps
by using them and with the bugs by reproducing them on the
emulatorbeforetheyreportedthebugs.Weaddressedpotentialbug
misunderstandingsvia2/3-wordannotations addedto the videos.
A diverse group of reporters participated in the studies, who
have different levels of bug reporting experience. Since we offered
thereportersamonetaryincentivefortheirparticipationandsome
ofthemarestudentsfromourinstitution(s),theymayhavebeen
motivated to diligently provide high-quality bug reports, which
maynotnecessarilybethecaseinareal-lifescenario.However,we
expect this factor to have a minimal impact on the results since (1)
we used the same procedure to recruit both BurtandItracusers,
and (2) the bug reporting experience in both reporter groups are
almostthesame(onlytwo Itracusershaveadifferentexperience).
Our evaluation did not consider how easy or difficult it is (for
developers) to understand and reproduce the ItracandBurtbug
reports. Instead, we focused on assessing bug report quality, as
doneby priorwork [ 28]. Assessing bugreport understanding and
reproductionisinourplansforfuturework.Additionally,wedid
353TowardInteractive BugReporting for(Android App) End-Users ESEC/FSE ‚Äô22, November14≈õ18, 2022,Singapore, Singapore
notaccountforthecomplexityofthebugsinourdataset.However,
weselectedbugsofdiversetypesanddistributionsoftheS2Rs.Our
future work willinvestigate howbugcomplexityaffects Burt.
Finally, giventhe relatively expensive nature of our evaluation,
we limited it to 12 bugs from six apps, reported by 36 participants,
which affects the external validity of our conclusions. A larger
evaluation, possibly performed on a larger sample of apps, bugs,
andparticipants isinour plans for future work.
6 RELATED WORK
We discuss Burt‚Äôsadvancements inrelation to prior work.
Issue/Bug Reporting Systems . A variety of systems currently
enable end-users and developers to manually report software bugs,
namely, issue/bug trackers ( e.g., GitHub Issues [ 7] or JIRA [ 10]),
built-in bug reporting interfaces in desktop and web apps ( e.g.,
GoogleChrome[ 15]),in-appbugreportingframeworks( e.g.,BugSee
[19]), app stores [ 4,20], and Q&A platforms [ 26]. These systems
typicallyconsistofweb/GUIforms(withtext-basedtemplates)that
allow reportersto providebug descriptions,indicate bug/system
metadata,andattachrelevantfiles.Someofthesesystemscollect
technical information ( e.g., configuration parameters) and offer
screen recording that enable graphicalbugreporting.
While existing systems provide features that facilitate bug re-
porting,theyofferlimitedguidancetobugreporters,lackquality
verification of bug report information, and do not provide con-
cretefeedbackonwhetherthisinformationiscorrectandcomplete.
These are some of the main reasons for having low-quality bug
reports,whichhaveimportantrepercussionsfordevelopers[ 65,66].
Researchershaveexploredimprovingbugreportinginterfaces,
as we do in this work. Moran et al.[53] proposed Fusion, a web-
based system that allows the user to report the S2Rs graphically
by selecting (via dropdown lists) images of the GUI components
andactions(taps,swipes, etc.)thatcanbeappliedonthem.More
recently,Fazzini etal.proposed EBug[34],amobileappbugreport-
ing system similar to Fusionthat suggests potential future S2Rs
to the reporter while they are writing them. Record-and-replay
tools[37,43,51,56]offertheabilitytorecorduseractionsduring
app usage ( e.g.,when abugisfound) andreplaythemlater.
Burtofferstwomainadvancementsoverpriortechniqueslike
Fusion.First,Burtwasdesignedtosupportend-userswithlittleor
no bug reporting experience. For example, Fusionwas not created
to specifically cater to end-users, as inexperienced users found
itmore difficult to use as compared to alternatives [ 53]. Second,
whereas past systems helped to provide structured mechanisms to
facilitate the reporting process ( e.g., through drop-down selectors)
theydonotoffer interactive assistancewhenreportingabug. Burt
offers such interactivity through its automated suggestions, real-
time quality assessment, and prompts for information clarification.
Bug Report Quality Analysis. Surveys and interviews with
developersand end-users[ 48,57,65]have identifiedthe observed
softwarebehavior(OB),theexpectedbehavior(EB),andthesteps
toreproduce(S2Rs)thebugsasessentialbugreportelementsfor
developersduringbugtriageandresolution.Unfortunately,such
elements are often missing, unclear, or ambiguous, as indicated
bynumerousstudiesanddevelopers[ 13,27,33,35,38,46,64,65],
whichhave anegative impact onbugreport managementtasks.In consequence, researchers have proposed techniques to better
capture and manage high-quality information in bug reports. Prior
work[25,29,32,58,62,63,65]proposedwaystoautomaticallyiden-
tify different essential elements in bug reports ( e.g., S2Rs [49,61]),
analyzetheirquality,andgivefeedbacktoreportersaboutpotential
issuesinthem.In particular,Zimmermann etal.[65] proposedan
approachtopredictthequalitylevelofabugreportbasedonfactors
such as readability or presence of keywords. Hooimeijer et al.[42]
measured quality properties of bug reports ( e.g., readability) to pre-
dict when a report would be triaged. Zanetti et al.[60] proposed
an approach based on collaborative information to identify invalid,
duplicate, or incomplete bug reports. Imran et al.[45] proposed an
approach to suggest follow-up questions for incomplete reports.
Songetal.[29,58]proposedatechniquetodetectwhentheOB,EB,
and S2Rs are absentin submitted bug reports.Chaparro et al.[28]
evaluated the quality of the S2Rs in bug reports through the Eu-
lertool, which integrates dynamic app analysis, natural language
processing, andgraph-basedapproaches.
Ourworkbuildsuponpriorresearch fortheautomatedquality
verification of bug descriptions by developing quality checks for
new types of bug elements ( i.e., OB/EB) and by designing dialogue
flows capable of guiding the user during the bug reporting process.
7 CONCLUSIONS
Burtis a task-oriented chatbot for interactive Android app bug
reporting.Unlike existingbugreportingsystems, Burtcan guide
end-usersinreportingessentialbugreportelements( i.e.,OB,EB,
andS2Rs),provideinstantfeedbackaboutproblemswiththisinfor-
mation,andproducegraphicalsuggestionsoftheelementsthatare
likely to be reported.
Eighteen end-users reported 12 bugs from six Android apps
and reported that, overall, Burt‚Äôs guidance and automated sug-
gestions/clarifications are accurate, useful, and easy to use. The
resulting bug reports are higher-quality than reports created via
Itrac,atemplate-basedbugreportingsystem,byother18reporters.
Specifically, Burtreportscontainfewerincorrectandmissingre-
production steps compared to Itracreports. We observed that
Burtis most helpful to novice reporters for avoiding incorrect
S2Rs. Surprisingly, Burtseems to be most useful to experienced
reporters for avoidingmissingreproduction steps.
The reporters provided feedbackfor refining thesupported dia-
log,byincludingsupportadditionalwordingstodescribetheOB,
EB,andS2Rs.Thestudiesalsorevealedareasofimprovementfor
Burtwithrespectto the verification of the reportedelements.
8 DATA-AVAILABILITYSTATEMENT
We provide an online replication package [ 21] that contains a com-
plete implementation of Burt,Burt‚Äôs app execution data, code
and data about Burt‚Äôs evaluation, and documentation that enables
the verification and validation of our work and future research on
bugreportingsystems.
ACKNOWLEDGEMENTS
We thank all the study participants for their time and feedback.
This work is supported by the NSF grants: CCF-1955837 and CCF-
1955853. Any opinions, findings, and conclusions expressed herein
aretheauthorsanddonotnecessarilyreflectthoseofthesponsors.
354ESEC/FSE ‚Äô22, November14≈õ18, 2022,Singapore, Singapore Yang Song,JunayedMahmud,Ying Zhou,Oscar Chaparro, Kevin Moran, Andrian Marcus, DenysPoshyvanyk
REFERENCES
[1]2021. Android Token. https://f-droid.org/en/packages/uk.co.bitethebullet.
android.token/ .
[2]2021. Android‚ÄôsLayoutandLayoutValidation. https://developer.android.com/
studio/debug/layout-inspector .
[3]2021. AntennaPod. https://play.google.com/store/apps/details?id=de.danoeh.
antennapod&hl=en_US&gl=US .
[4]2021. App Store: Ratings, Reviews, and Responses. https://developer.apple.com/
app-store/ratings-and-reviews/ .
[5] 2021. Appetize.io. https://appetize.io/ .
[6] 2021. Droid Weight. https://fossdroid.com/a/droidweight.html .
[7] 2021. GitHubIssue Tracker - https://github.com/features .
[8]2021. GnuCash. https://play.google.com/store/apps/details?id=org.gnucash.
android&hl=en_US&gl=US .
[9] 2021. GrowTracker. https://f-droid.org/en/packages/me.anon.grow/ .
[10] 2021. JIRA BugReporting System- https://www.atlassian.com/software/jira .
[11]2021. Microsoft Azure Chatbot Architecture. https://docs.microsoft.com/en-
us/azure/architecture/reference-architectures/ai/conversational-bot .
[12] 2021. Mileage. https://fossdroid.com/a/mileage.html .
[13]2021. An open letter to GitHub from the maintainers of open source projects.
https://github.com/dear-github/dear-github .
[14]2021.ReactChatbotKit. https://fredrikoseberg.github.io/react-chatbot-kit-docs/ .
[15]2021. Report an issue or send feedback on Chrome. https://support.google.com/
chrome/answer/95315 .
[16] 2021. Spring Boot. https://spring.io/projects/spring-boot .
[17]2021. Stanford Dependencies. https://nlp.stanford.edu/software/stanford-
dependencies.html .
[18]2021. A Time Tracker. https://f-droid.org/en/packages/com.markuspage.android.
atimetracker/ .
[19] 2021. https://www.bugsee.com .
[20]2021. Write a review on Google Play. https://support.google.com/googleplay/
answer/4346705 .
[21]2022. Onlinereplicationpackage. (2022). https://doi.org/10.5281/zenodo.6977413
[22]2022. Qualtrics:SurveySoftware. https://www.qualtrics.com/core-xm/survey-
software/ .
[23]Carlos Bernal-C√°rdenas, Nathan Cooper, Madeleine Havranek, Kevin Moran,
Oscar Chaparro, Denys Poshyvanyk, and Andrian Marcus. 2022. Translating
VideoRecordingsofComplexMobileAppUIGesturesIntoReplayableScenarios.
IEEE Transactions onSoftwareEngineering (2022), to appear.
[24]Carlos Bernal-C√°rdenas, Nathan Cooper, Kevin Moran, Oscar Chaparro, An-
drian Marcus, and Denys Poshyvanyk. 2020. Translating video recordings of
mobileappusagesintoreplayablescenarios.In ProceedingsoftheACM/IEEE42nd
InternationalConference onSoftwareEngineering (ICSE‚Äô20) . 309≈õ321.
[25]Nicolas Bettenburg, Sascha Just, Adrian Schr√∂ter, Cathrin Weiss, Rahul Premraj,
andThomasZimmermann.2008. WhatMakesaGoodBugReport?.In Proceedings
ofthe16thInternationalSymposiumontheFoundationsofSoftwareEngineering
(FSE‚Äô08). 308≈õ318.
[26]AadityaBhatia,ShaoweiWang,MuhammadAsaduzzaman,andAhmedEHassan.
2022. A Study of Bug Management Using the Stack Exchange Question and
Answering Platform. IEEE Transactions on Software Engineering 48, 2 (2022),
502≈õ518.
[27]Silvia Breu, Rahul Premraj, Jonathan Sillito, and Thomas Zimmermann. 2010.
Information Needs in Bug Reports: Improving Cooperation Between Developers
andUsers.In ProceedingsoftheConferenceonComputerSupportedCooperative
Work (CSCW‚Äô10) . 301≈õ310.
[28]OscarChaparro,CarlosBernal-C√°rdenas,JingLu,KevinMoran,AndrianMarcus,
MassimilianoDi Penta,DenysPoshyvanyk,andVincent Ng. 2019. Assessingthe
QualityoftheStepstoReproduceinBugReports.In Proceedingsofthe27thACM
Joint Meetingonthe FoundationsofSoftwareEngineering (ESEC/FSE‚Äô19) . 86≈õ96.
[29]OscarChaparro,JingLu,FiorellaZampetti,LauraMoreno,MassimilianoDiPenta,
Andrian Marcus, Gabriele Bavota, and Vincent Ng. 2017. Detecting Missing
InformationinBugDescriptions.In Proceedingsofthe11thJointMeetingonthe
FoundationsofSoftwareEngineering (ESEC/FSE‚Äô17) . 396≈õ407.
[30]Norman Cliff. 2014. Ordinal methods for behavioral data analysis . Psychology
Press.
[31]Nathan Cooper, Carlos Bernal-C√°rdenas, Oscar Chaparro, Kevin Moran, and
Denys Poshyvanyk. 2021. It Takes Two to Tango: Combining Visual and Textual
Information for Detecting Duplicate Video-Based Bug Reports. In Proceedings of
the 43rd IEEE/ACM International Conference on Software Engineering (ICSE‚Äô21) .
160≈õ161.
[32]StevenDaviesandMarcRoper.2014. What‚Äôsinabugreport?.In Proceedingsofthe
8th International Symposium on Empirical Software Engineering and Measurement
(ESEM‚Äô14) . 26:1≈õ26:10.
[33]Mona Erfani Joorabchi, Mehdi Mirzaaghaei, and Ali Mesbah. 2014. Works for
Me!CharacterizingNon-reproducibleBugReports.In ProceedingsoftheWorking
Conference onMiningSoftwareRepositories(MSR‚Äô14) . 62≈õ71.
[34]MattiaFazzini,KevinPatrickMoran,CarlosBernal-Cardenas,TylerWendland,
Alessandro Orso, and Denys Poshyvanyk. 2022. Enhancing Mobile App BugReportingviaReal-timeUnderstandingofReproductionSteps. IEEETransactions
onSoftwareEngineering (2022), to appear.
[35]Mattia Fazzini, Martin Prammer, Marcelo d‚ÄôAmorim, and Alessandro Orso. 2018.
Automatically translating bug reports into test cases for mobile apps. In Pro-
ceedings of the 27th International Symposium on Software Testing and Analysis
(ISSTA‚Äô18) . 141≈õ152.
[36]Jianfeng Gao, Michel Galley, and Lihong Li. 2019. Neural Approaches to Con-
versational AI. Foundations and Trends in Information Retrieval 13, 2-3 (2019),
127≈õ298.
[37]LorenzoGomez,IulianNeamtiu,TanzirulAzim,andToddMillstein.2013.RERAN:
Timing- and touch-sensitive record and replay for Android. In Proceedings of the
35thInternationalConference onSoftwareEngineering (ICSE‚Äô13) . 72≈õ81.
[38]Philip J. Guo, Thomas Zimmermann, Nachiappan Nagappan, and Brendan Mur-
phy. 2010. Characterizing and predicting which bugs get fixed: an empirical
study of Microsoft Windows. In Proceedings of the 32nd International Conference
onSoftwareEngineering (ICSE‚Äô10) . 495≈õ504.
[39]MelitaHajdinjakandFranceMiheliƒç.2006.ThePARADISEevaluationframework:
Issues and findings. ComputationalLinguistics 32,2 (2006), 263≈õ272.
[40]Madeleine Havranek, Carlos Bernal-C√°rdenas, Nathan Cooper, Oscar Chaparro,
Denys Poshyvanyk, and Kevin Moran. 2021. V2S: a tool for translating video
recordings of mobile app usages into replayable scenarios.In Proceedings of the
IEEE/ACM43rdInternationalConferenceonSoftwareEngineering(ICSE‚Äô21) .65≈õ68.
[41]Myles Hollander, Douglas A Wolfe, and Eric Chicken. 2013. Nonparametric
statisticalmethods . John Wiley& Sons.
[42]PieterHooimeijer andWestleyWeimer.2007. Modeling BugReportQuality.In
Proceedings of the 22nd International Conference on Automated Software Engineer-
ing(ASE‚Äô07) . 34≈õ43.
[43]Yongjian Hu, Tanzirul Azim, and Iulian Neamtiu. 2015. Versatile yet lightweight
record-and-replay for android. In Proceedings of the 2015 ACM SIGPLAN Inter-
nationalConferenceonObject-OrientedProgramming,Systems,Languages,and
Applications(OOPSLA‚Äô15) . 349≈õ366.
[44]DaHuo,TaoDing,CollinMcMillan,andMalcomGethers.2014. Anempirical
study of the effects of expert knowledge on bug reports. In Proceedings of the
InternationalConferenceonSoftwareMaintenanceandEvolution(ICSME‚Äô14) .1≈õ10.
[45]MiaMohammadImran,AgnieszkaCiborowska,andKostadinDamevski.2021.
Automatically Selecting Follow-up Questions for Deficient Bug Reports. In In
proceedings of the 18th IEEE/ACM International Conference on Mining Software
Repositories(MSR‚Äô18) . 167≈õ178.
[46]G√ºn Karag√∂z and Hasan S√∂zer. 2017. Reproducing failures based on semiformal
failurescenario descriptions. SoftwareQuality Journal 25,1 (2017), 111≈õ129.
[47]AmyJ.KoandBradA.Myers.2008. DebuggingReinvented:AskingandAnswer-
ing Why and Why Not Questions about Program Behavior. In Proceedings of the
30thInternationalConference onSoftwareEngineering (ICSE‚Äô08) . 301≈õ310.
[48]EeroI.LaukkanenandMikaV.M√§ntyl√§.2011. SurveyReproductionofDefect
ReportinginIndustrialSoftwareDevelopment.In ProceedingsoftheInternational
Symposium on Empirical Software Engineering and Measurement (ESEM‚Äô11) . 197≈õ
206.
[49]HuiLiu, Mingzhu Shen,Jiahao Jin, and Yanjie Jiang. 2020. Automated classifi-
cationofactionsinbugreportsofmobileapps.In Proceedingsofthe29thACM
InternationalSymposiumonSoftwareTestingand Analysis(ISSTA‚Äô20) . 128≈õ140.
[50]Christopher D Manning, Mihai Surdeanu, John Bauer, Jenny Rose Finkel, Steven
Bethard,andDavidMcClosky.2014. TheStanfordCoreNLPNaturalLanguage
Processing Toolkit. In Proceedings of the 52nd Annual Meeting of the Association
for ComputationalLinguistics (ACL‚Äô14) . 55≈õ60.
[51]KevinMoran,RichardBonett,CarlosBernal-C√°rdenas,BrendanOtten,Daniel
Park,andDenysPoshyvanyk.2017. On-devicebug reportingforandroidappli-
cations.In ProceedingsoftheIEEE/ACM4thInternationalConferenceonMobile
SoftwareEngineering and Systems(MOBILESoft‚Äô17) . 215≈õ216.
[52]Kevin Moran, Mario Linares-V√°quez, Carlos Bernal-C√°rdenas,ChristopherVen-
dome, and Denys Poshyvanyk. 2016. Automatically Discovering, Reporting and
Reproducing Android Application Crashes. In Proceedings of the International
Conference onSoftwareTesting,Verification and Validation (ICST‚Äô16) . 33≈õ44.
[53]KevinMoran,MarioLinares-V√°squez,CarlosBernal-C√°rdenas,andDenysPoshy-
vanyk. 2015. Auto-completing Bug Reports for Android Applications. In Pro-
ceedings of the Joint Meeting on Foundations of Software Engineering (FSE‚Äô15) .
673≈õ686.
[54]KevinMoran,MarioLinares-Vasquez,CarlosBernal-Cardenas,CristopherVen-
dome,andDenysPoshyvanyk.2017. CrashScope:APracticalToolforAutomated
TestingofAndroidApplications.In Proceedingsofthe39thIEEE/ACMInternational
Conference onSoftwareEngineering (ICSE‚Äô17) . 15≈õ18.
[55]Abraham Naftali Oppenheim.1992. Questionnaire Design, Interviewingand Atti-
tude Measurement . PinterPublishers.
[56]Zhengrui Qin, Yutao Tang, Ed Novak, and Qun Li. 2016. MobiPlay: A Remote
Execution Based Record-and-replay Tool for Mobile Applications. In Proceedings
of the 38th International Conference on SoftwareEngineering (ICSE‚Äô16) . 571≈õ582.
[57]Tommaso Dal Sasso, Andrea Mocci, and Michele Lanza. 2016. What Makes a
SatisficingBugReport?.In ProceedingsoftheInternationalConferenceonSoftware
Quality, Reliability and Security(QRS‚Äô16) . 164≈õ174.
355TowardInteractive BugReporting for(Android App) End-Users ESEC/FSE ‚Äô22, November14≈õ18, 2022,Singapore, Singapore
[58]Yang Song and Oscar Chaparro. 2020. BEE: a tool for structuring and analyzing
bugreports.In Proceedingsofthe28thACMJointMeetingonEuropeanSoftware
EngineeringConferenceandSymposiumontheFoundationsofSoftwareEngineering
(ESEC/FSE‚Äô21) . 1551≈õ1555.
[59]LinTan,ChenLiu,ZhenminLi,XuanhuiWang,YuanyuanZhou,andChengxiang
Zhai. 2014. Bug characteristics in open source software. Empirical Software
Engineering 19,6 (2014), 1665≈õ1705.
[60]Marcelo Serrano Zanetti, Ingo Scholtes, Claudio Juan Tessone, and Frank
Schweitzer. 2013. Categorizing Bugs with Social Networks: A Case Study on
Four Open Source Software Communities. In Proceedings of the International
Conference onSoftwareEngineering (ICSE‚Äô13) . 1032≈õ1041.
[61]Yu Zhao, Kye Miller, Tingting Yu, Wei Zheng, and Minchao Pu. 2019. Automati-
callyextractingbugreproducingstepsfrom android bugreports. In Proceedings
oftheInternationalConferenceonSoftwareandSystemsReuse(ICSR‚Äô19) .100≈õ111.
[62]Yu Zhao, Ting Su, Yang Liu, Wei Zheng, Xiaoxue Wu, Ramakanth Kavuluru,
William GJ Halfond, and Tingting Yu. 2022. ReCDroid+: Automated End-to-EndCrashReproductionfromBugReportsforAndroidApps. ACMTransactionson
SoftwareEngineering and Methodology (TOSEM) 31,3 (2022), 1≈õ33.
[63]Yu Zhao, Tingting Yu, Ting Su, Yang Liu, Wei Zheng, Jingzhi Zhang, and
William G.J. Halfond. 2019. ReCDroid: Automatically Reproducing Android
Application Crashes from Bug Reports. In Proceedings of the 41st IEEE/ACM
InternationalConference onSoftwareEngineering (ICSE‚Äô19) . 128≈õ139.
[64]Thomas Zimmermann, Nachiappan Nagappan, Philip J. Guo, and Brendan Mur-
phy.2012. Characterizingandpredictingwhichbugsgetreopened.In Proceedings
ofthe InternationalConference onSoftwareEngineering (ICSE‚Äô12) . 1074≈õ1083.
[65]ThomasZimmermann,RahulPremraj,NicolasBettenburg,SaschaJust,Adrian
Schr√∂ter, and Cathrin Weiss. 2010. What Makes a Good Bug Report? IEEE
Transactions onSoftwareEngineering 36,5 (2010), 618≈õ643.
[66]Thomas Zimmermann, Rahul Premraj, Jonathan Sillito, and Silvia Breu. 2009.
Improvingbugtrackingsystems.In Proceedingsofthe31stInternationalConference
onSoftwareEngineering (ICSE‚Äô09) . 247≈õ250.
356