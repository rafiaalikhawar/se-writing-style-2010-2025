DEAR: A Novel Deep Learning-based Approach
for Automated Program Repair
Yi Li
New Jersey Inst. of Technology
New Jersey, USA
yl622@njit.eduShaohua Wangâˆ—
New Jersey Inst. of Technology
New Jersey, USA
davidsw@njit.eduTien N. Nguyen
University of Texas at Dallas
Texas, USA
tien.n.nguyen@utdallas.edu
ABSTRACT
Theexistingdeeplearning(DL)-basedautomatedprogramrepair
(APR) models are limited in fixing general software defects. We
present DEAR, a DL-based approach that supports fixing for the
generalbugsthatrequiredependentchangesatoncetooneormul-
tiple consecutive statements in one or multiple hunks of code. We
firstdesignanovelfaultlocalization(FL)techniqueformulti-hunk,
multi-statementfixesthatcombinestraditionalspectrum-based(SB)
FL with deep learning and data-flow analysis. It takes the buggy
statementsreturnedbytheSBFLmodel,detectsthebuggyhunks
tobe fixedatonce,and expandsabuggy statement ğ‘ ina hunkto
includeother suspiciousstatementsaround ğ‘ .Wedesigna two-tier,
tree-based LSTM model that incorporates cycle training and uses a
divide-and-conquerstrategy tolearn propercode transformations
for fixing multiple statements in the suitable fixing context consist-
ing of surrounding subtrees. We conducted several experiments to
evaluateDEARonthreedatasets:Defects4J(395bugs),BigFix(+26k
bugs), and CPatMiner (+44k bugs). On Defects4J dataset, DEAR
outperforms the baselines from 42%â€“683% in terms of the number
of auto-fixed bugs with only the top-1 patches. On BigFix dataset,
itfixes31â€“145morebugsthanexistingDL-basedAPRmodelswith
the top-1 patches. On CPatMiner dataset, among 667 fixed bugs,
thereare169(25.3%)multi-hunk/multi-statementbugs.DEARfixes
71 and 164 more bugs, including 52 and 61 more multi-hunk/multi-
statement bugs, than the state-of-the-art,DL-based APR models.
CCS CONCEPTS
â€¢Softwareanditsengineering â†’Softwaremaintenancetools.
KEYWORDS
Automated Program Repair; Deep Learning; Fault Localization;
ACM Reference Format:
Yi Li, Shaohua Wang, and Tien N. Nguyen. 2022. DEAR: A Novel Deep
Learning-based Approach for Automated Program Repair. In 44th Inter-
national Conference on Software Engineering (ICSE â€™22), May 21â€“29, 2022,
Pittsburgh, PA, USA. ACM, New York, NY, USA, 13 pages. https://doi.org/10.
1145/3510003.3510177
âˆ—Corresponding Author
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Â© 2022 Association for Computing Machinery.
ACM ISBN 978-1-4503-9221-1/22/05...$15.00
https://doi.org/10.1145/3510003.35101771 INTRODUCTION
Researchers haveproposed several approachesto helpdevelopers
inautomaticallyidentifyingandfixingthedefectsinsoftware.Such
approaches are referred to as automated program repair (APR). The
APR approaches have been leveraging various techniques in the
areasofsearch-basedsoftwareengineering, softwaremining, machine
learning (ML), and deep learning (DL).
Forsearch-basedapproaches [9,10,24,30],asearchstrategyisper-
formedinthespaceofpotentialsolutionsproducedbymutatingthe
buggycodeviaoperators.Otherapproachesusesoftwareminingtomineandlearnfixingpatterns frompriorbugfixes[
15,17,19,20,27]
orsimilarcode[ 28,32].Fixingpatternsareatthesourcecodelevel
[19,20]oratthechangelevel[ 13,16,40].Machinelearning hasbeen
used to mine fixing patterns and the candidate fixes are ranked ac-
cordingtotheirlikelihoods[ 21,22,33].WhilesomeDL-basedAPR
approaches learn similar fixes [ 11,41,42], other ones use machine
translation or neural network models with various code abstrac-
tions to generate patches [5, 6, 12, 18, 35, 38, 39].
Despitetheirsuccesses, thestate-of-the-artDL-basedAPRap-
proaches are still limited in fixing the general defects, which involve
the fixing changes to multiple statements in the same or different
partsofafileordifferentfiles (whicharereferredtoas hunks).None
ofexistingDL-basedapproachescanautomaticallyfixthebug(s)
withdependentchangestomultiplestatementsinmultiplehunks
at once. They supports fixing only individual statements. If we use
such a tool on the current statement, the tool treats that statement
asincorrectandtreatstheotherstatementsascorrect.Thisdoes
notholdsincetofixthecurrentstatement,theremainingunfixed
statementsmustnotbetreatedascorrectcode.Thus,itmightbein-
accurate when using existing DL-based APR tools to fix individual
statements for multi-hunk/multi-statement bugs. While DL pro-
videsbenefitsforfixlearning,thislimitationmakestheDL-based
APRapproacheslesscapablethantheotherdirections(search-based
and pattern-based APR), which support multiple-statement fixes.
In thispaper, weaim toadvance deep learning-basedAPR by in-
troducing DEAR, a DL-based model that supports fixing for the
generalbugswithdependentchangesatoncetooneormultiplebuggy
statementsbelongingtooneormultiplebuggyhunksofcode.T odo
that, we make the following key technical contributions.
First,wedevelopa faultlocalization(FL)techniqueformulti-hunk,
multi-statementbugsthatcombinestraditionalspectrum-basedFL
(SBFL)withDLanddata-flowanalysis.DEARusesaSBFLmethodto
identifytherankedlistofsuspiciousbuggystatements.Then,ituses
that list of buggy statements to derive the buggy hunks that need
to be fixed together by fine-tuning the pre-trained BERT model [ 8],
to learn the fixing-together relationships among statements. We
alsodesignanexpansionalgorithmthattakesabuggystatement
5112022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:56:15 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Yi Li, Shaohua Wang, and Tien N. Nguyen
ğ‘ in a hunk as a seed, and expands to include other suspicious
consecutive statements around ğ‘ . To achieve that, we use an RNN
modeltoclassifythestatementsasbuggyornot,andusedata-flow
analysis for adjustment and then form the buggy hunks.
Second,aftertheexpansionstep,wehaveidentifiedallthebuggy
hunk(s)withbuggystatement(s).Wedevelopa compositionalap-
proach to learning and then generating multi-hunk, multi-statement
fixes. In our approach, from the buggy statements, we use a divide-
and-conquer strategy to learn each subtree transformation in Ab-
stract Syntax Tree (AST). Specifically, we use an AST-based differ-
encing technique to derive the fine-grained, AST-based changes
and the mappings between buggy and fixed code in the training
data.Thosefine-grainedsubtreemappingshelpourmodelavoid
incorrectalignmentsofbuggyandfixedcode,thus,ismoreaccurate
in learning multiple AST subtree transformations of a fix.
Third, we have enhanced and orchestrated a tree-based, two-
layer Long Short-Term Memory (LSTM) model [ 18] withan atten-
tion layer and a cycle training to help DEAR to learn the proper
code fixing changes in the suitable context of surrounding code.
For each buggy AST subtree identified by our fault localization, we
encode it as a vector representation and apply that LSTM model to
derive thefixed code.In thefirst layer,it learnsthe fixingcontext,
i.e.,thecodestructuressurroundingabuggyASTsubtree.Inthesecondlayer,itlearnsthecodetransformationstofixthatbuggy
subtree using the context as an additional weight.
Finally, there mightbe likely multiple buggysubtrees. To build
thesurroundingcontextforeachbuggysubtree ğµ,intraining,we
includetheASTsubtrees afterthefixesoftheotherbuggysubtrees
(ratherthanthosebuggysubtreesthemselves).Therationaleisthat
the subtrees after fixes actually represent the correct surrounding
code forğµ. (Note: in training, the fixed subtrees are known).
We conducted experiments to evaluate DEAR on three large
datasets:Defects4J [1](395bugs), BigFix[18](+26kbugs),and CPat-
Miner dataset [26] (+44k bugs). The baseline DL-based approaches
include DLFix [ 18], CoCoNuT [ 23], SequenceR [ 6], Tufano19 [ 38],
CODIT[5],andCURE[ 14].DEARfixes31%(i.e.,+11),5.6%(i.e.,+41),
and 9.3% (i.e., +31) more bugs than the best-performing baseline
CURE on all three datasets, respectively, using only Top-1 patches
and with seven times fewer training parameters on average. On
Defects4J, it outperforms those baselines from 42%â€“683% in terms
of thenumber offixed bugs.On BigFix,it fixes31â€“145 morebugs
than those baselines with the top-1 patches. On CPatMiner, among
667 fixed bugs from DEAR, there are 169 (25.3%) multi-hunk/multi-
statementones.DEARfixes71,164,and41morebugs,including
52,61,and40moremulti-hunk/multi-statementbugs,thanexisting
DL-based APR tools CoCoNuT, DLFix, and CURE. We also com-
paredDEARagainst8state-of-the-artpattern-basedAPRtools.Ourresults show that DEAR generates comparable and complementary
results to the top pattern-based APR tools. On Defects4J, DEARfixes 12 bugs (out of 47) including 7 multi-hunk/multi-statement
bugs that the top pattern-based APR tool could not fix.
In brief, the key contributions of this paper include
A. Advancing DL-based APR for general bugs with multi-
hunk/multi-statement fixes: DEAR advances DL-based APR
for general bugs. We show that DL-based APR can achieve the
comparable and complementary results as other APR directions.
B. Advanced DL-based APR Techniques:1public boolean verifyUserInfo(String UID, String password, String SSN) {
2 String retrieved_password = "";
3 String retrieved_SSN = "";
4if(UID != null){
5- retrieved_password = getPassword(UID);
6+ retrieved_password = getPassword(toUpperCase(UID));
7+ } else {
8+ return false;
9+}
10-boolean password_check= compare(password,retrieved_password);
11+ boolean password_check= compare(passwordHash(password),retrieved_password);
12if(password_check) {
13 retrieved_SSN = getSSN(UID);
14 boolean SSN_check = compare(SSN, retrieved_SSN);
15 if(SSN_check) {
16 return true;
17 }
18 }
19return false;
20 }
Figure 1: A General Fix with Multiple Dependent Changes
1) Anovel FL technique for multi-hunk, multi-statement fixes
that combines spectrum-based FL with DL and data-flow analysis;
2)Acompositionalapproach withadivide-and-conquerstrategy
to learn and generate multi-hunk, multi-statement fixes; and
3)Thedesignandorchestrationofthetwo-layerLSTMmodel
with the enhancementsvia the attention layer and cycle training.
C.ExtensiveEmpiricalEvaluation: 1)DEARoutperformsthe
existing DL-based APR tools; 2) DEAR is the first DL-based APR
modelperformingatthesamelevelintermsofthenumberoffixed
bugs as the state-of-the-art, pattern-based tools and generate com-
plementary results; 3) Our data and tool are publicly available [2].
2 MOTIVATION
2.1 Motivating Example
Letuspresentabug-fixingexampleandourobservationsformo-
tivation.Figure1showsanexampleofabugin verifyUserInfo ,which
verifies the given user ID, password and Social Security Number
against usersâ€™ recordsin thedatabase. Thisbug manifestsin three
folds.First,thedeveloperforgottohandlethecasewhen UIDisnull.
Thus,forfixing,(s)headdedan elsebranchatthelines7â€“9.Second,
thedeveloperforgottoperformtheuppercaseconversionforthe
UID,causinganerrorbecausetherecordsforuserIDsinthedatabase
all have capital letters. The corresponding bug-fixing change is the
additionofthecallto toUpperCase() onUIDatline6.Third,because
the passwords stored in the database are encoded via hashing, the
inputpasswordfromauserneedstobehashedbeforeitiscompared
against the one in the database. Thus, the developer added the call
topasswordHash() onpasswordbeforecallingthemethod compare()at
line 11. From this example, we have the following observations:
Observation1[AFixwithDependentChangestoMultiple
Statements]: This bug requires the dependent fixing changes to
multiplestatementsatonceinthesamefix:1)addingthe elsebranch
with the returnstatement (lines 7â€“9), 2) adding toUpperCase at line
6, and 3) adding passwordHash at line 11. Making changes to the
individualstatementsoneatatimewouldnotfixthebugsinceboth
thegivenarguments UIDandpasswordneedtobeproperlyprocessed.
UIDneeds to be null checked and capitalized, and passwordneedsto
be hashed.Those dependent changesto multiple statementsmust
occur at once in the same fix for the program to pass the test cases.
512
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:56:15 UTC from IEEE Xplore.  Restrictions apply. DEAR: A Novel Deep Learning-based Approach for Automated Program Repair ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
The state-of-the-art DL-based APR approaches [ 6,18]fix one
individual statement at a time. In Figure 1, the fault localization
toolreturnstwobuggylines:line5andline10.Assumethatsucha
DL-basedAPRtoolisusedtofixthestatementatline5.Itwillmake
the fixing change to the statement at line 5 (e.g., modify line 5 and
add lines 7â€“9), however, with the assumption that the statement at
line 10 and other lines are correct. With this incorrect assumption,
such a fix will not make the code pass the test cases since bothchanges must be made. Thus, the individual-statement, DL-based
APR tools cannot fix this bug by fixing one buggy statement at a
time. In general, a bug might require dependent changes to multiple
statements (in possibly multiple hunks) in the same fix.
Moreover,thepattern-basedAPRtoolsmightnotbeabletofix
this defect because the code in this example is project-specific and
might not match with any bug-fixing patterns.
Observation2[Many-to-ManyASTSubtreeTransforma-
tions]:Afixcaninvolvethechangesto multiplesubtrees.Forex-
ample, the ifstatement has a new elsebranch. The argument of
thecallto getPassword() wasmodifiedintothecallto toUpperCase() .
Thisfixalsoinvolves many-to-manysubtreetransformations.Inthis
example, a fix transforms the two buggy statements (line 5 andline 10), into four statements (the
ifstatement having new else
branch, the returnstatement at line 8, the modified statement with
toUpperCase atline6,andthemodifiedstatementwith passwordHash at
line 11).Thus, a fixcan bebroken intomultiple subtreetransforma-
tions,andifusinga compositionapproachwithadivide-and-conquer
strategy, we can learn the individual transformations.
Observation3[CorrectFixingContext]: Abugfixoftende-
pends on the context of surrounding code. For example, to get the
password from a given UID, one needs to capitalize the ID, thus, in
correctcode,themethodcallto toUpperCase islikelytoappearwhen
themethodcallto getPassword ismade.Therefore, buildingcorrect
fixingcontextisimportant.InFigure1,amodelneedstolearnthefix
(line5â†’line6)w.r.t.surroundingcode,whichneedstoincludethe
fixed code at line 11 (rather line 10 because line 10 is buggy). To fix
line5,thecorrectcontextmustinclude passwordHash atline11.Thus,
the correct context for a fix to a buggy statement must include the
fixed code of another buggy statement ğ‘ â€™, rather than ğ‘ â€™ itself.
2.2 Key Ideas
From the observations, we draw the following key ideas:
Key Idea 1 .AFaultLocalizationMethodforMulti-hunk,Multi-
statement Patches: From Observation 1, we design a novel FL
method that combines traditional spectrum-based FL (SBFL) with DL
anddata-flowanalysis.WeuseaSBFLtoobtainarankedlistofcan-
didate statements to be fixed with their suspiciousness scores. We
extend the result from SBFL in two tasks. First, we design a hunk-
detection algorithm to use DL to detect the hunks that need to be
dependently changed together in the same patch, because SBFL tool
returns the suspicious candidatesfor the fault, but not necessarily
tobe fixedtogether. Second,wedesign an expansion algorithm
that takes each of those detected fixing-together hunks and ex-
pandsit toinclude consecutivesuspicious statementsin thehunk.
InFigure1,theSBFLtoolreturnsline5assuspicious.Afterhunkde-
tection,DEARusesdatadependenciesviavariable retrieve_password
to include the statement at line 10 as to be fixed as well.Key Idea 2 .ACompositionalApproachtoLearningandGen-
erating Multi-hunk, Multi-statementFixes :
Divide-and-ConquerStrategy in Learning Multi-hunk/Multi-stmt
Fixes.To auto-fix a bug with multiple statements, a tool needs to
makeğ‘š-to-ğ‘›statement changes, i.e., ğ‘šstatements might generally
becomeğ‘›statements after the fix. A naive approach would let a
model learn the code structure changes and make the alignmentbetween the code before and after the fix. Because a fix involves
multiple subtree transformations (Observation 2), during training,
a model might incorrectlyalign the code before and after the fix,thus, leading to incorrect learning of the fix. For example, with-
outthisstep,themodelmightmap retrieved_password atline10to
the same variable at line 6 (the correct map is line 11). Thus, to
facilitatelearningbug-fixingcodetransformations,duringtraining,
we usea divide-and-conquer strategy. We integrate into DEAR a
fine-grainedAST-basedchangedetectionmodeltomaptheASTs
beforeand afterthefix. Suchmappingsenable DEAR tolearn the
more local fixing changes to subtrees. For example, the fine-grained
ASTchangedetectioncanderivethatthestatementsatlines4â€“5,
and 7 become the statements at lines 4, and 6â€“9; and the statement
at line 10 becomes the one at line 11. We can break them into twogroups and align the respective AST subtrees for DEAR to learn.
Compositional Approach in Fixing Multiple Subtrees
.Wesupport
the fixes having multiple statements in one or multiple hunks
byenhancingthedesignandorchestrationofatree-basedLSTM
model [18]t oadd an attention layer and cycle training (Section 3.3).
Whilethatmodelfixesonesubtreeatatime,weneedtoenhanceit
to fix multiple AST subtrees at once.
Specifically,wemodifyitsoperationsinthetwo-layerstocon-
sidermultiplebuggysubtreesatonce.Forexample,duringtraining,
wemarkeachoftheASTsubtreesofthestatementsatline5and
line10beforethefixasbuggy.Atthefirstlayer,foreachsubtreefor
a buggy statement, we replaceit with a pseudo-node, and consider
thenewASTwithits(pseudo-)nodesasthefixingcontextforthe
buggy statement. The pseudo-node is computed via an embedding
technique to capture the structure of the buggy statement (Sec-
tion3.2).Atthesecondlayer,DEARlearnsthetransformationfrom
the subtree for the statement at line 5 into the subtree for the fixed
statementsatthelines6â€“9.Thevectorforthefixingcontextlearned
from the first layer is used as a weight in the code transformation
learning in the second layer. We repeat the same process for every
buggy statement. For fixing, we perform the composition of the
fixing transformationsfor all buggy statements at once.
Key Idea 3 .TransformationLearningwithCorrectSurround-
ing Fixing Context: To learn the correct context for a fix to a
statement, we need to train the model withthe fixed versions of the
otherbuggystatements (Observation3).Forexample,fortraining,
to learn thefix to the statement atline 5 with toUpperCase ,am od e l
needstointegratethefixedversionoftheotherbuggyline,i.e.,the
codeatline11with passwordHash asthefixingcontext(insteadofthe
buggyline10).Ifthesurroundingcodebeforethefixisused(i.e.,
line 10), the model will learn the incorrect context to fix the line 5.
2.3 Approach Overview
2.3.1TrainingProcess. Theinputfortrainingincludesthesource
code before and after a fix (Figure 2), which is parsed into ASTs.
513
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:56:15 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Yi Li, Shaohua Wang, and Tien N. Nguyen
Figure 2: Training Process Overview
Theoutputincludesthetwo trainedmodelsforcontextlearning and
fortreetransformationlearning (fixing).Thecontextlearningmodel
(CTL) aims to learn the weights (representing the impact of the
context)tomakeanadjustmenttothetreetransformationlearning
result. The tree transformation learning model (TTL) aims to learn
code transformation for the fix to a buggy AST subtree.
ContextLearning (Sections3.2â€“3.3).Thefirststepistobuildthe
before-/after-fixing contexts for training. With divide-and-conquer
strategy,weuseCPatMiner[ 26]toderivethe changed,inserted,and
removedsubtrees (key idea 2). As a result, the AST subtrees for the
buggy statements are mapped to the respective fixed subtrees. For
eachbuggysubtreeandrespectivefixedsubtree,webuildtwoASTs
oftheentiremethodascontexts,onebeforeandoneafterthefix,
and use both of them for training at the input layer and the output
layer of the tree-based LSTM context learning model (Section 3.3).
To build the correct context for each buggy subtree, we leverage
key idea 3: we train our model with the fixed versions of the other
buggysubtrees.Finally,thevectorscomputedfromthislearning
are used as the weights in tree transformation learning.
TreeTransformationLearning (Section3.4).WefirstuseCPat-
Miner[26]toderivethesubtreemappings.Tolearnbug-fixingtree
transformations,eachbuggysubtree ğ‘‡itselfanditsfixedsubtree
ğ‘‡/primeafter the fix are used at the input layer and the output layer
ofthe secondtree-basedLSTM fortraining. Moreover,theweight
representing the context computed as the vector in the context
learning model is used an additional input in this step.
2.3.2Fixing Process. Figure 3 illustrates the fixing process. The
input includes the buggy source code and the set of test cases.
Fault Localization and Buggy-Hunk Detection (Section 4.1).
Fromkeyidea1,wefirstuseaSBFLtooltolocatebuggystatements
withsuspiciousnessscores.Hunkdetectionalgorithmusesthose
statementstoderivethebuggyhunksthatneedtobefixedtogether.
Multi-StatementExpansion (Section4.2).BecauseSBFLmight
returnonestatementforahunk,weaimtoexpandtopotentially
include more consecutive buggy statements. To do so, we combine
RNN [7] and data-flow analysis to detect more buggy statements.
Tree-based Code Repair (Section 4.3). For the detected buggy
statementsfrommulti-statementexpansion,weusekeyidea2tode-
rivefixestomultiplebuggysubtreesatonce.Forabuggysubtree ğ‘‡,
we build the AST of the method as the context, and use it as the
inputofthetrainedcontextlearningmodel(CTL)toproducethe
weightrepresentingtheimpactofthecontext.Thebuggysubtree ğ‘‡
is used as the input of the trained tree transformation model (TTL)
to produce the context-free fixed subtree ğ‘‡/prime. Finally, that weight is
used to adjust ğ‘‡/primeinto the fixed subtree ğ‘‡/prime/primefor a candidate patch.
Weapplygrammaticalrulesandprogramanalysisonthecurrent
candidate code to produce the fixed code. We re-rank and validate
thefixedcodeusingtestcasesinthesamemannerasinDLFix[ 18].
Figure 3: Fixing Process Overview
3 TRAINING PROCESS
3.1 Pairing Buggy and Fixed Subtrees
Thetrainingdatacontainsthepairsofthesourcecodeofthemeth-
odsbeforeandafterthefixes.Notethatafixmightinvolvemultiple
methods.Insteadofpairingtheentirebuggymethodwiththefixed
one, we use a divide-and-conquer strategy to help the model to
betterlearnthefixingtransformationsinthepropercontexts.First,
we use the CPatMiner tool [26] to derive the fixing changes.
If a subtree corresponds to a statement, we call it statement
subtree.FromtheresultofCPatMiner,weusethefollowingrules
to pair the buggy subtrees with the corresponding fixed subtrees:
1.A buggysubtree( ğ‘†-subtree)is asubtreewith updateordelete.
2. If ağ‘†-subtree is deleted, we pair it with an empty tree.
3.Ifabuggy ğ‘†-subtreeismarkedas update,(i.e,itis updatedor
itschildrennode(s)couldbe inserted,deleted orupdated),wepaired
this buggy ğ‘†-subtree with its corresponding fixed ğ‘†-subtree.
4. If ağ‘†-subtree is insertedand its parent node is another ğ‘†-
subtree, we pair it with that parent ğ‘†-subtree. If the parent node
is not an ğ‘†-subtree, we pair an empty tree to the corresponding
insertedğ‘†-subtree.
3.2 Context Building
Figure4illustratesourcontextbuildingprocess.Foreachpairof
thebuggyAST ğ¼1andfixedAST ğ‘‚1(Section3.1),weperformalpha-
renaming on the variables. In Step 1, we encode each AST node
withthevectorusingthewordembeddingmodelGloVe[ 29](which
captures well code structure) by considering a statement node as a
sentenceandeachcodetokenasaword.Weusethosevectorsto
labeltheASTnodesin ğ¼1andğ‘‚1.TheASTsafterthissteparethe
vectorized ASTs ğ¼2andğ‘‚2, before and after the fix.
InStep2,weprocesseachpairofthebuggy ğ‘†-subtreeğ‘‡ğ‘inğ¼2and
the corresponding fixed ğ‘†-subtreeğ‘‡ğ‘“inğ‘‚2. First, we perform node
summarizationon ğ‘‡ğ‘andğ‘‡ğ‘“by using TreeCaps [4] to capture the
treestructuresof ğ‘‡ğ‘andğ‘‡ğ‘“intoğ‘‰ğ‘ andğ‘‰/primeğ‘ ,respectively.Second,for
eachoftheotherbuggy ğ‘†-subtrees,e.g., ğ‘‡/prime
ğ‘,andtheircorresponding
fixedğ‘†-subtrees,e.g., ğ‘‡/prime
ğ‘“,weprocessasfollows.Because ğ‘‡/prime
ğ‘“isthe
fixed version of ğ‘‡/prime
ğ‘, we replace ğ‘‡/prime
ğ‘withğ‘‡/prime
ğ‘“in the building of the
resultingcontext ğ¼3beforefixing(keyidea3).Thatis,wereplace
eachoftheotherbuggysubtreeswithitsfixedversion.However,
tobuildtheresultingcontext ğ‘‚3afterfixing,wekeep ğ‘‡/prime
ğ‘“becauseit
is the fixed subtree, thus, providing the correct context.
The resulting AST, ğ¼3, is used as the before-the-fix context for
thebuggy ğ‘†-subtreeğ‘‡ğ‘andusedat theinputlayer oftheencoder
inthecontextlearningmodel(CTL).TheresultingAST, ğ‘‚3,isused
as the after-the-fix context for ğ‘‡ğ‘“and used at the output layer of
thedecoderinCTL(Figure4).Finally,thevectors ğ‘‰ğ‘ andğ‘‰/primeğ‘ willbe
used as the weighting inputs for tree transformation learning later.
514
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:56:15 UTC from IEEE Xplore.  Restrictions apply. DEAR: A Novel Deep Learning-based Approach for Automated Program Repair ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Figure 4: Context Building to Train Context Learning Model
Figure5:CycleTraininginAttention-basedTree-basedLSTM
3.3Context Learning via Tree-based LSTM with
Attention Layer and Cycle Training
For context learning and tree transformation learning, we enhance
thetwo-layer,tree-based,LSTMmodelsinDLFix[ 18]withattention
layerandcycletraining.Wehaveaddedanattentionlayerintothat
model,whichnowhas3layers:encoderlayer,decoderlayerand
attentionlayer(Figure5).Fortheencoderanddecoder,tolearnthe
fixing context expressed in ASTs, we use Child-Sum Tree-based
LSTM [36]. Unlike the regular LSTM that loops for each time step,
this model loops for each subtree to capture structures.
Wealsouse cycletraining [45]forfurtherimprovement.Cycle
trainingaimstohelpamodellearnbetterthemappingbetweenthe
inputandoutputbycontinuingtotrainandre-traintoemphasizeonthemappingbetweenthem.Thisishelpfulinthesituationsinwhichabuggycodecanbefixedinmultiplewaysintodifferentfixedcode,ormultiplebuggycodecanbefixedintoonefixedcode.Thismakes
the regular tree-based LSTM less accurate. With cycle training, the
pairofaninputandthemostlikelyoutputisemphasizedtoreduce
the noise of such one-to-many or many-to-one relations.
Cycle training occurs between encoder and decoder. We use the
forward mapping ğ‘€:ğ´â†’ğµto denote the process of ğ‘’ğ‘›ğ‘ğ‘œğ‘‘ğ‘’ğ‘Ÿâ†’
ğ‘ğ‘¡ğ‘¡ğ‘’ğ‘›ğ‘¡ğ‘–ğ‘œğ‘› â†’ğ‘‘ğ‘’ğ‘ğ‘œğ‘‘ğ‘’ğ‘Ÿ, and the backward mapping ğ‘:ğµâ†’ğ´to
denote the process of ğ‘‘ğ‘’ğ‘ğ‘œğ‘‘ğ‘’ğ‘Ÿâ†’ğ‘ğ‘¡ğ‘¡ğ‘’ğ‘›ğ‘¡ğ‘–ğ‘œğ‘› â†’ğ‘’ğ‘›ğ‘ğ‘œğ‘‘ğ‘’ğ‘Ÿ(Figure 5).
We apply the adversarial losses for both ğ‘€andğ‘to get the two
loss functions ğ¿ğ‘Ÿğ‘¢ğ‘›(ğ‘€,ğ·ğµ,ğ´,ğµ)andğ¿ğ‘Ÿğ‘¢ğ‘›(ğ‘,ğ·ğ´,ğµ,ğ´). The differ-
encebetween ğ‘(ğ‘€(ğ´))andğ´,andthatbetween ğ‘€(ğ‘(ğµ))andğµ
are usedto generate cycle-consistencyloss ğ¿ğ‘ğ‘¦ğ‘(ğ‘€,ğ‘)forğ‘€and
ğ‘to ensure the learned mapping functions are cycle-consistent.
Mathematically, we have two loss functions ğ¿ğ‘Ÿğ‘¢ğ‘›(ğ‘€,ğ·ğµ,ğ´,ğµ)and
ğ¿ğ‘Ÿğ‘¢ğ‘›(ğ‘,ğ·ğ´,ğµ,ğ´).Withtheincentivecycleconsistencyloss ğ¿ğ‘ğ‘¦ğ‘(ğ‘€,
ğ‘), the overall loss function is computed as follows:
ğ¿ğ‘ğ‘¦ğ‘(ğ‘€,ğ‘)=ğ¸ğ‘âˆ¼ğ‘ğ‘‘ğ‘ğ‘¡ğ‘(ğ‘)[||ğ‘(ğ‘€(ğ‘))âˆ’ğ‘||1]
+ğ¸ğ‘âˆ¼ğ‘ğ‘‘ğ‘ğ‘¡ğ‘(ğ‘)[||ğ‘€(ğ‘(ğ‘))âˆ’ğ‘||1](1)
Figure 6: Tree Transformation Learning ( ğ‘‰ğ‘†,ğ‘‰/prime
ğ‘†in Figure 4)
ğ¿(ğ‘€,ğ‘,ğ·ğ‘,ğ·ğ‘)=ğ¿ğ‘Ÿğ‘¢ğ‘›(ğ‘€,ğ·ğµ,ğ´,ğµ)+ğ¿ğ‘Ÿğ‘¢ğ‘›(ğ‘,ğ·ğ´,ğµ,ğ´)
+ğ›¼ğ¿ğ‘ğ‘¦ğ‘(ğ‘€,ğ‘)(2)
Whereğ¿(ğ‘€,ğ‘,ğ·ğ‘,ğ·ğ‘)is the loss function for the entire cycle
training; ğ‘€andğ‘are the mapping functions to map ğ´toğµand
ğµtoğ´;ğ·ğ´is aimed to distinguish between the predicted result
ğ‘(ğ‘€(ğ´))andtherealresult ğ´;ğ·ğµisaimedtodistinguishbetween
thepredictedresult ğ‘€(ğ‘(ğµ))andtherealresult ğµ;ğ¿ğ‘Ÿğ‘¢ğ‘›isthecycle
consistency loss function for the running function ğ‘€,ğ‘;ğ¿ğ‘ğ‘¦ğ‘is
theincentivizedcycleconsistencyloss;and ğ›¼istheparameterto
control the relative importance of the two objectives.
3.4 Tree Transformation Learning
Figure 6 illustrates the tree transformation learning process. We
usethesametree-basedLSTMmodelwithattentionlayerandcycle
training as in Section 3.3 to learn the code transformation for each
buggyğ‘†-subtreeğ‘‡ğ‘.InStep1, webuildtheword embeddingsfor
allthecodetokensasinSection3.2.EachASTnodeinthebuggy
ğ‘†-subtree ( ğ‘‡ğ‘) andthe fixed one ( ğ‘‡ğ‘“) is labeled with its vectorrep-
resentation(Figure6).Next,weusethesummarizedvectors ğ‘‰ğ‘ and
ğ‘‰/primeğ‘ computed from context learning in Figure 4 as the weights and
perform cross-product for each vector of the node in the buggy
ğ‘†-subtreeğ‘‡ğ‘andforeachoneinthefixed ğ‘†-subtreeğ‘‡ğ‘“,respectively.
Thetworesultingsubtreesaftercross-productareusedattheinput
andoutputlayersofthetree-basedLSTMmodelfortreetransfor-
mationlearning.Weusecross-productbecauseweaimtohavea
vector as the label for a node and use it as a weight representing
the context to learn code transformations for bug fixes.
4 FIXING PROCESS
4.1 Fixing-together Hunk Detection Algorithm
The first step of fixing multi-hunk, multi-statement bugs is for our
FL method to detect buggy hunk(s) that are fixed together in the
same patch. To do that, we fine-tune Googleâ€™s pre-trained BERT
model[8]tolearnthe fixing-togetherrelationshipsamongstatements
using BERTâ€™s sentence-pair classification task. Then, we use the
fine-tunedBERTmodelinanalgorithmtodetectfixing-together
hunks. Let us explain our hunk detection algorithm in details.
4.1.1Fine-tuningBERTtoLearnFixing-togetherRelation-
shipsamongStatements. Wefirstfine-tuneBERTtolearniftwo
statements are needed to be fixed together or not. Let ğ»be a set
of the hunks that are fixed together for a bug. The input for the
trainingprocessisallthesets ğ»sforallthebugsinthetrainingset.
Step 1.For a pair of hunks ğ»ğ‘–andğ»ğ‘—inğ», we take every pair of
statements ğ‘†ğ‘˜andğ‘†ğ‘™, one from each hunk, and build the vectors
515
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:56:15 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Yi Li, Shaohua Wang, and Tien N. Nguyen
with BERT. We consider the pair of statements ( ğ‘†ğ‘˜,ğ‘†ğ‘™) as being
fixed-together in the same patch to fine-tune BERT.
Step 2.Step1isrepeatedforallthepairsofthestatements( ğ‘†ğ‘˜,ğ‘†ğ‘™)s
inallthepairs ğ»ğ‘–andğ»ğ‘—inğ».WealsorepeatStep1forall ğ»s.We
use them to fine-tune the BERT model to learn the fixing-together
relationships among any two statements in all pairs of hunks.
4.1.2Using Fine-tuned BERT for Hunk Detection. After ob-
taining the fine-tuned BERT, we use it in determining whether the
hunks of code need to be fixed together or not. The input of of
this procedure is the fine-tuned BERT model, buggy code ğ‘ƒ, and
test cases. The output is the groups of hunks that need to be fixed
together. The process is conducted in the following steps.
Step 1.We use a spectrum-based FL tool (in our experiment, we
usedOchiai[ 3])torunonthegivensourcecodeandtestcases.It
returns the list of buggy statements and suspiciousness scores.Step 2
.Theconsecutivestatementswithinamethodreturnedby
the FL tool are grouped together to form the hunks ğ»1,ğ»2, ...,ğ»ğ‘š.
Step 3.To decide if a pair of hunks ( ğ»ğ‘–,ğ»ğ‘—)n e e d st ob efi x e dt o -
gether, we use the BERT model that was fine-tuned. Specifically,
for every pair of statements ( ğ‘†ğ‘˜,ğ‘†ğ‘™), one from each hunk ( ğ»ğ‘–,ğ»ğ‘—),
we use the fine-tuned BERT to measure the fixing-together rela-
tionshipscorefor( ğ‘†ğ‘˜,ğ‘†ğ‘™).Thefixing-togetherscorebetween ğ»ğ‘–and
ğ»ğ‘—is the average of the scores of all the pairs of statements within
ğ»ğ‘–andğ»ğ‘—,respectively.Iftheaveragescoreforallthestatement
pairsishigherthanathreshold,weconsider( ğ»ğ‘–,ğ»ğ‘—)asneededto
befixedtogether.Fromthepairsofthedetectedhunks,webuild
thegroupsofthefixing-togetherhunks.ThegroupofhunksthathasanystatementwiththehighestOchiaiâ€™ssuspiciousnessscore
will be ranked and fixed first. The rationale is that such a group
contains the most suspicious statement, thus, should be fixed first.
4.2 Multiple-Statement Expansion Algorithm
A detected buggy hunk from the algorithm in Section 4.1 might
contain only one statement since each of those suspicious state-ments is originally derived by a SBFL tool, which does not focus
on detecting consecutive buggy statements in a hunk. Thus, in this
step, we take the result from the hunk detection algorithm, and
expand it to include potentially more statements in a hunk.
Key Idea.Ourideaistocombinedeeplearningwithdataflowanal-
ysis. We first train an RNN model with GRU cells [ 7] (will be ex-
plainedinSection4.2.2)tolearntodecidewhetherastatementis
buggy or not. We collect the training data for that model from the
realbuggystatements.Wethenusedata-flowanalysistoadjustthe
result.Specifically,ifastatementislabeledasbuggybytheRNN
model, no adjustment is needed. However, even when the RNN
model decides a given statement ğ‘ asnon-buggy, and if ğ‘ has a data
dependency with a buggy statement, we still mark ğ‘ asbuggy.
4.2.1ExpansionAlgorithm. TheinputofMulti-StatementExpan-
sionalgorithmisthebuggystatement buggyS,i.e.,theseedstatement
of a hunk. The output is a buggy hunk of consecutive statements.
First, it produces a candidate list of buggy statements by includ-
ingğ‘statements before and ğ‘statements after buggyS(Expand2N-
CandidatesList atline2).Inthecurrentimplementation, ğ‘=5.Then,Algorithm 1 Multiple-StatementExpansion Algorithm
1:function MultiStatementsExpansion( ğ‘ğ‘¢ğ‘”ğ‘”ğ‘¦ğ‘†)
2:ğ‘ğ‘ğ‘›ğ‘‘ğ‘†ğ‘¡ğ‘šğ‘¡ğ‘  =ğ¸ğ‘¥ğ‘ğ‘ğ‘›ğ‘‘2ğ‘ğ¶ğ‘ğ‘›ğ‘‘ğ‘–ğ‘‘ğ‘ğ‘¡ğ‘’ğ‘ ğ¿ğ‘–ğ‘ ğ‘¡ (ğ‘ğ‘¢ğ‘”ğ‘”ğ‘¦ğ‘†)
3:ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘…ğ‘’ğ‘ ğ‘¢ğ‘™ğ‘¡ =ğ‘…ğ‘ğ‘ğ¶ğ‘™ğ‘ğ‘ ğ‘ ğ‘–ğ‘“ğ‘–ğ‘’ğ‘Ÿ (ğ‘ğ‘ğ‘›ğ‘‘ğ‘†ğ‘¡ğ‘šğ‘¡ğ‘  )
4:ğ‘’ğ‘¥ğ‘ğ‘ğ‘›ğ‘‘ğ‘…ğ‘’ğ‘ ğ‘¢ğ‘™ğ‘¡ =ğ·ğ‘ğ‘¡ğ‘ğ·ğ‘’ğ‘ğ´ğ‘›ğ‘ğ‘™ğ‘¦ğ‘ ğ‘–ğ‘  (ğ‘ğ‘ğ‘›ğ‘‘ğ‘†ğ‘¡ğ‘šğ‘¡ğ‘ ,ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘…ğ‘’ğ‘ ğ‘¢ğ‘™ğ‘¡ )
5:returnğ‘’ğ‘¥ğ‘ğ‘ğ‘›ğ‘‘ğ‘…ğ‘’ğ‘ ğ‘¢ğ‘™ğ‘¡
6:function DataDepAnalysis( ğ‘ğ‘¢ğ‘”ğ‘”ğ‘¦ğ‘†,ğ‘ğ‘ğ‘›ğ‘‘ğ‘†ğ‘¡ğ‘šğ‘¡ğ‘  ,ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘…ğ‘’ğ‘ ğ‘¢ğ‘™ğ‘¡ )
7:ğ‘ğ‘¢ğ‘”ğ‘”ğ‘¦ğ»ğ‘¢ğ‘›ğ‘˜ =ğºğ‘’ğ‘¡ğ¶ğ‘’ğ‘›ğ‘¡ğ‘’ğ‘Ÿğµğ‘¢ğ‘”ğ‘”ğ‘¦ğ»ğ‘¢ğ‘›ğ‘˜ (ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘…ğ‘’ğ‘ ğ‘¢ğ‘™ğ‘¡ )
8:ğ·ğ·ğ¸ğ‘¥ğ‘ğ‘ğ‘›ğ‘‘ğ»ğ‘¢ğ‘›ğ‘˜ (ğ‘ğ‘¢ğ‘”ğ‘”ğ‘¦ğ‘†,ğ‘ğ‘¢ğ‘”ğ‘”ğ‘¦ğ»ğ‘¢ğ‘›ğ‘˜,ğ‘‡ğ‘œğ‘ğ»ğ‘ğ‘™ğ‘“ (ğ‘ğ‘ğ‘›ğ‘‘ğ‘†ğ‘¡ğ‘šğ‘¡ğ‘  ))
9:ğ·ğ·ğ¸ğ‘¥ğ‘ğ‘ğ‘›ğ‘‘ğ»ğ‘¢ğ‘›ğ‘˜ (ğ‘ğ‘¢ğ‘”ğ‘”ğ‘¦ğ‘†,ğ‘ğ‘¢ğ‘”ğ‘”ğ‘¦ğ»ğ‘¢ğ‘›ğ‘˜,ğµğ‘œğ‘¡ğ»ğ‘ğ‘™ğ‘“ (ğ‘ğ‘ğ‘›ğ‘‘ğ‘†ğ‘¡ğ‘šğ‘¡ğ‘  ))
10:returnğ‘ğ‘¢ğ‘”ğ‘”ğ‘¦ğµğ‘™ğ‘œğ‘ğ‘˜
11:function DDExpandHunk( ğ‘ğ‘¢ğ‘”ğ‘”ğ‘¦ğ‘†,ğ‘ğ‘¢ğ‘”ğ‘”ğ‘¦ğ»ğ‘¢ğ‘›ğ‘˜ ,ğ‘ğ‘ğ‘›ğ‘‘ğ‘†ğ‘¡ğ‘šğ‘¡ğ‘  )
12:for each(ğ‘ ğ‘¡ğ‘šğ‘¡âˆˆğ‘ğ‘ğ‘›ğ‘‘ğ‘†ğ‘¡ğ‘šğ‘¡ğ‘  )&(ğ‘ ğ‘¡ğ‘šğ‘¡âˆ‰ğ‘ğ‘¢ğ‘”ğ‘”ğ‘¦ğ»ğ‘¢ğ‘›ğ‘˜ )do
13: ifğ»ğ‘ğ‘ ğ·ğ‘ğ‘¡ğ‘ğ·ğ‘’ğ‘ (ğ‘ ğ‘¡ğ‘šğ‘¡,ğ‘ğ‘¢ğ‘”ğ‘”ğ‘¦ğ‘† )then
14: ğ‘ğ‘¢ğ‘”ğ‘”ğ‘¦ğ»ğ‘¢ğ‘›ğ‘˜ =ğ‘ğ‘¢ğ‘”ğ‘”ğ‘¦ğ»ğ‘¢ğ‘›ğ‘˜ âˆªğ‘ ğ‘¡ğ‘šğ‘¡
15: else break
16:returnğ‘ğ‘¢ğ‘”ğ‘”ğ‘¦ğ»ğ‘¢ğ‘›ğ‘˜
Figure 7: Multiple-Statement Expansion Example
it uses the RNN model to act as a classifier to predict whether each
statement (except buggyS) inthe candidatelist is buggyor not (RN-
NClassifier atline3).TotrainthatRNNmodel,weusethebuggy
statementsinthebuggyhunksinthetrainingdata(seeSection4.2.2).
TreeCaps [4] is used to encode the statements.
InDataDepAnalysis (line4),toadjusttheresultsfromtheRNN
model, we obtain buggyHunk surrounding the buggy statement
buggyS,consistingofthestatementsbeforeandafter buggyS,thatwere
predicted as buggy by the RNN model (line 7). We then examine
statement-by-statement in the upward direction from the center
buggystatementinthecandidatelist(line8,via TopHalf)andinthe
downwarddirection(line9,via BotHalf).In DDExpandHunk,wecon-
tinuetoexpand(upwardordownward)thecurrentbuggyhunk bug-
gyHunktoincludeastatementthatisdeemedasbuggybytheRNN
model or hasa data dependency withthe center buggy statement
buggyS(lines13â€“14). We stoptheprocess (upwardor downward),
ifweencounteranon-buggystatementwithoutdatadependency
withbuggySorweexhaustthelist(line15).Finally,thebuggyhunk
containing consecutive buggy statements is returned.
In Figure 7, the SBFL tool returns the buggy statement at line 4.
AllstatementsareencodedintothesetsofvectorsviaGloVe[ 29]
andclassifiedbytheRNNmodel.Weexpandfromthestatementat line 4 upward to include line 3 (even though the RNN model
predicteditasnon-buggy),sinceline3hasadatadependencywith
thebuggystatementatline4viathevariable c.Weincludeline5
becausetheRNNmodelpredictstheline5asbuggy.Atthistime,we
stoptheupwardanddownwarddirectionsbecauseweencounter
the non-buggy statements at lines 2 and 6 that do not have data
dependencywithline4.Thatis,lines1â€“2and6â€“7areexcluded.The
final result includes the statements at lines 3â€“5 as the buggy hunk.
4.2.2BuggyStatementPredictionwithRNN. Wepresenthow
to use an GRU-based RNN model [ 7] to predict a buggy statement.
Training. To train the RNN model, we use the buggy/non-buggy
statementsinallthehunksinthetrainingdataset.WeuseGloVe[ 29]
516
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:56:15 UTC from IEEE Xplore.  Restrictions apply. DEAR: A Novel Deep Learning-based Approach for Automated Program Repair ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
to encode each token in a statement so that a statement is repre-
sented by a sequence of token vectors. We use the neural archi-tecture of the GRU-based RNN model [
7] to consume the GloVe
vectors of statements associated with the buggy/non-buggy labels.
The RNN model operates in the time steps. At the time step ğ‘˜
(ğ‘˜>=1), atthe inputlayer, GRUconsumes theGloVe vectorsof the
ğ‘˜ğ‘¡â„statement ğ‘†ğ‘˜. At the output layer, ğ‘†ğ‘˜i sl a b e l e da s1i fi ti sa
buggy statement and as 0 otherwise. In addition to the input at the
time step ğ‘˜+1, we feed the output of the time step ğ‘˜to the GRU.
Prediction. ThetrainedGRU-basedRNNmodelisusedinExpansion
Algorithmatline3topredictifastatementinthehunkisbuggy
or not. The model takes a statement in the form of GloVe token
vectors. It takes the vectors of all the statements in a hunk and
labels them as buggy or non-buggy in multiple-time-step manner.
4.3 Tree-based Code Repair
Figure8illustratesthisprocess.Afterderivingthebuggyhunk(s)
in the method(s), DEAR performs code repairing for all buggy
statements in all the hunks at once using the trained LSTM models.
The tree-based code repair is conducted in the following steps:
Step 1.Identifying buggy S-subtrees. For each hunk, we parse the
code into AST, and identify the buggy ğ‘†-subtrees corresponding to
the derived buggy statements. In Figure 8, the ğ‘†-subtrees ğ‘‡1and
ğ‘‡2are identified as buggy. Ifa buggy ğ‘†-subtree is partof another
largerbuggy ğ‘†-subtree,wejustneedtoperformfixingonthelarger
ğ‘†-subtree since that fix also fixes the smaller ğ‘†-subtree.
Step 2.Embedding and Summarization. We perform word embed-
ding using GloVe [ 29] and tree summarization using TreeCaps [ 4]
on all the buggy subtrees to obtain the contexts. For example, in
Figure 8,ğ‘‡1andğ‘‡2are summarized into two vectors ğ‘‰1andğ‘‰2.
Step 3.Predict Context. We use the trained context learning model
(CTL) to run on the context with the AST nodes including also the
summarized nodes to predict the context. In the resulting AST, the
structure is the same as the AST for the input context, except thatthe summarized nodes become the new ones. For example,
ğ‘‰1and
ğ‘‰2in the context becomes ğ‘‰/prime
1andğ‘‰/prime
2after Step 3.
Step 4.AddingWeights. Theweights ğ‘‰1andğ‘‰2fromStep2areused
in a product withthe vectors in the buggy subtrees ğ‘‡1andğ‘‡2. Each
nodeinğ‘‡1andğ‘‡2isrepresentedbyamultiplicationvectorbetween
the original vector of the node and the weight vector ğ‘‰/prime
1orğ‘‰/prime
2.
Step 5.Predict Transformations. We use the trained tree transfor-
mation learning model to predict the subtrees ğ‘‡/prime
1andğ‘‡/prime
2of the fix.
Step 6.Removing Weights. We remove the weight from Step 4 to
obtainthecandidatefixedsubtreeforabuggyone.Forexample,weremove
ğ‘‰/prime
1andğ‘‰/prime
2toobtainthecandidatefixedsubtrees ğ‘‡1ğ‘“andğ‘‡2ğ‘“.
However, because we know the cross product and a vector, we can
get the unlimited number of solutions. Thus, to produce a singlesolution
ğ‘‡1ğ‘“andğ‘‡2ğ‘“, for each node in ğ‘‡/prime
1andğ‘‡/prime
2, we assume that
ğ‘‰/prime
1andğ‘‰/prime
2areverticalwiththenodevector ğ‘‰ğ‘›1inğ‘‡/prime
1andğ‘‰ğ‘›2inğ‘‡/prime
2.
Then,wecangettheunweightednodevector ğ‘‰/prime
ğ‘›1inğ‘‡1ğ‘“asfollows:
ğ‘‰/prime
ğ‘›1=ğ‘‰/prime
1Ã—ğ‘‰ğ‘›1
ğ‘‰/prime
1/dotaccğ‘‰/prime
1(3)
Figure 8: Tree-based Code Repair
After having the vector for each node in a fixed S-subtree ğ‘‡1ğ‘“,
we generated candidate patches based on word embedding. For
each node, we calculated the cosine similarity score between its
vectorğ‘‰/prime
ğ‘›1and each vector in the vector list for all tokens. To
generate candidate patches, we select the token ğ‘¡in the list. Token
ğ‘¡has its similarity score ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’ğ‘¡for one node in the fixed ğ‘†-subtree.
By adding all ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’ğ‘¡for all the tokens, we have the total score,
ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’ğ‘ ğ‘¢ğ‘š,foracandidate.Weselectthetop-5candidatesforeach
node to generate the candidates and sort them based on ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’ğ‘ ğ‘¢ğ‘š.
4.4 Post-processing
Anaiveapproachwouldfacecombinatorialexplosioninforming
thecandidatefix(es)becauseforeachnodeinthesub-tree,wemain-
taintop-5candidates.However,whenwecombinethecandidates
for all the nodes in the fixed sub-tree, many candidates are not
valid for the current method in the project. Therefore, when we
formacandidatebycombiningallthecandidatesforthenodes,we
applyasetoffilterstoverifytheprogramsemanticsinthesame
manner as in DLFix [ 18]. This allows us to eliminate invalid candi-
dates immediately. Specifically, we use the alpha-renaming filter to
change the names back to the normal Java code using a dictionary
containing all the valid names in the scope, the syntax-checkingfilter to remove the candidates with syntax errors, and the name
validation filter to check the validity of the variables, methods, and
classes. Moreover, for further improvement, we use beam search
tomaintainonlythetop-rankedcandidatefixes.Thus,wedonot
exhaust all compositions in forming the statements. This helps
maintain a manageable number of candidates.
Afterapplyingallthefilters,wealsousedDLFix[ 18]â€™sre-ranking
schemeonthecandidatepatches.Wethenusedtestcasestoconductpatchvalidationonthosecandidates.Weverifyeachpatchfromthe
toptothebottomuntilacorrectpatchisidentifiedandthepatch
validationends.Ifallcandidatesforfixingalocationcannotpass
all the test cases, we select the next location to repeat the process.
5 EMPIRICAL EVALUATION
5.1 Research Questions
To evaluate DEAR, we seek to answer the following questions:
RQ1. Comparative Study with Deep Learning-based APR
modelsonDefects4Jbenchmark. HowwelldoesDEARperform
in comparison with existing DL-based APR models on Defects4J?
RQ2. Comparative Study with Deep Learning-based APR
modelsonLargeBugDatasets. HowwelldoesDEARperformin
comparisonwith DL-based APRmodelson large-scalebugdatasets?
517
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:56:15 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Yi Li, Shaohua Wang, and Tien N. Nguyen
RQ3.ComparativeStudywithPattern-basedAPRapproaches
on Defects4J. How well does DEAR perform in comparison with
the state-of-the-art, pattern-based APR approaches?
RQ4. Sensitivity Analysis of DEAR. How do various factors
affect the overall performance of DEAR in APR?
RQ5. Time Complexity and Modelâ€™s Training Parameters.
What is time complexity and the numbers of training parameters?
5.2 Data Collection
We have conducted our empirical evaluation on three datasets:
1)Defects4J v1.2.0 [1] with 395 bugs with test cases;
2)BigFix[18] with +26k bugs in +1.8 million buggy methods;
3)CPatMiner [26] with +44k bugs from 5,832 Java projects.
All experiments were conducted on a workstation with a 8-core
Intel CPU and a single GTX Titan GPU.
5.3 Experimental Methodology
5.3.1RQ1. Comparison with DL-based APR on Defects4J.
Comparative Baselines. WecompareDEARwithfivestate-of-the-art
DL-basedAPRmodels: DLFix[18],CoCoNuT [23],SequenceR [6],
Tufano19 [38],CODIT[5], andCURE[14].
Procedure and Settings. We replicated all DL-based APRs except
CURE,whichisunavailable.Were-implementedCUREfollowing
thedetailsintheirpaper.WetrainedallDLapproachesonthebugs
andfixesinCPatMinerdatasetandtestedthemonall395bugsin
Defects4J(nooverlapbetweenthetwodatasets).AllDLapproaches
wereappliedwiththesamefaultlocalizationtool,Ochiai[ 3],and
patchvalidationwiththetestcasesinDefects4J.Followingprior
experiments [ 13,18], we set a 5-hour running-time limit for a tool
for patch generation and validation.
WetunedDEARwiththefollowingkeyhyper-parametersusing
thebeam-search:(1)BERTforhunkdetection:epochsize(e-size)
(2,3,4,5),batchsize(b-size) (8,16,32,64),andlearningrate(l-rate)
(3ğ‘’âˆ’4,1ğ‘’âˆ’4,5ğ‘’âˆ’5,3ğ‘’âˆ’5,1ğ‘’âˆ’5); (2) LSTM for Multi-Statement Expan-
sionandcoderepair:e-size (100,150,200,250),b-size(32,64,128,256),
and l-rate (0.0001,0.0005,0.001,0.003,0.005); (3) GloVe for repre-
sentation vectors: vector size (v-size) (100,150,200,250), l-rate
(0.001,0.003,0.005,0.01),b-size(32,64,128,256),ande-size (100,150,
200,250). The other default parameters were used.
The best setting for DEAR is (1) e-size=4, b-size=32, l-rate=1 ğ‘’âˆ’4
forBERT;(2)e-size=200,l-rate=0.003,b-size=128forLSTM;(3)v-
size=200, l-rate=0.001, b-size=64, e-size=200 for GloVe. For other
models, we tuned with the parameters in their papers, e.g., the
vector length of word2vec, learning rate, and epoch size to find
the best parameters for each dataset. We tuned all approaches with
theaforementionedparametersonthesame CPatMiner datasetto
obtainthebestperformance.Onceweobtainedthebestparameters
for each model, we used them for later experiments.
Quantitative Analysis. We report the numbers of bugs that a
model can auto-fix for the following bug-location types:
Type-1. One-Hunk, One-Statement: A bug with the fix in-
volving only one hunk with one single statement.
Type-2. One-Hunk, Multi-Statements: A bug with the fix
involving only one hunk with multiple statements.
Type-3. Multi-Hunks, One-Statement: A bug with the fix
involving multiple hunks; each hunk with one fixed statement.Type-4. Multi-Hunks, Multi-Statements: A bug with the fix
involving multi-hunks;each hunk has multiple statements.
Type-5. Multi-Hunks, Mix-Statements: A bug with the fix
involvingmultiplehunks,andsomehunkshaveonestatementand
other hunks have multiple statements.
Evaluation Metrics. We report the number of bugs that can be
correctlyfixedandthenumberofplausiblepatches(i.e.,passingall
test cases, but not the actual fixes) using the top candidate patches.
5.3.2RQ2.ComparisonwithDL-basedAPRonLargeDatasets.
Comparative Baselines. WecompareDEARwiththesamebaselines
as in RQ1 on two large datasets: BigFix and CPatMiner.
Procedure and Settings. First,weevaluatedallDL-basedAPRmod-
els on BigFix and CPatMiner. Following DLFix and Sequencer, we
randomlysplitdatainto80%/10%/10%fortraining,tuning,andtest-
ing.Second,wehavecross-datasetevaluation:trainingDL-based
approachesonCPatMinerandtestingonBigFix,andviceversa.Un-likeDefects4J,BigFixandCPatMinerdatasetsdonothavetestcases.
Without test cases, we cannot use fault localization and patch vali-
dation for all DL approaches. Thus, we fed the actual bug locations
into the DL models, including locations on buggy hunks and state-
ments.TheDL-basedbaselinesdonotdistinguishhunks,instead
processeachbuggystatementatatime.Weusedevelopersâ€™actual
fixes as the ground truth to evaluate the DL-based approaches.
Evaluation Metrics. We use the top-ğ¾metric, defined as the ratio
betweenthenumberoftimesthatacorrectpatchisinarankedlist
of the top ğ¾candidates over the total number of bugs.
5.3.3RQ3.ComparisonwithPattern-basedAPRonDefects4J.
Comparative Baselines. We compare DEAR with the state-of-the-
art,pattern-basedAPRtoolsonDefects4J: Elixir[33],ssFix[43],
CapGen [40],FixMiner [16],Avatar[19],Hercules [34],Sim-
Fix[13], andTbar[20]. We were able to replicate the following
pattern-basedbaselines: Elixir,ssFix,FixMiner,SimFix,TBar
underthesamecomputingenvironments.Wesetthetimelimitto5hoursforthetools.Fortheotherbaselines,duetounavailablecode,
we use the results reported in their papers as they were run on the
same dataset. We used the same setting and evaluation metric.
5.3.4RQ4.SensitivityAnalysis. Weevaluatetheimpactsofdif-
ferent factors on DEARâ€™s performance. We consider the following:
(1)hunkdetection(Hunk);(2)multi-statementexpansion(Expan-
sion);(3)multi-statementtreemodelandcycletraining;and(4)data
splittingscheme.Weusetheleft-one-outstrategyforeachfactor.
We evaluate the first three factors on Defects4J and the last one on
CPatMiner since we need a larger dataset for various splitting.
5.3.5TimeComplexityandNumbersofParametersinModel
Training. We measure the training and fixing time for a model
and its number of parameters for model training on the datasets.
6 EMPIRICAL RESULTS
6.1 RQ1. Comparison Results with DL-based
APR Models on Defects4J
6.1.1WithFaultLocalization. WefirstevaluatetheAPRmodels
whenusingwiththefaultlocalizationtoolOchiai[ 3].Tables1and2
showthecomparisonresultsamongDEARandthebaselinemodels.
518
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:56:15 UTC from IEEE Xplore.  Restrictions apply. DEAR: A Novel Deep Learning-based Approach for Automated Program Repair ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Table 1: RQ1. Comparison with DL-based APR Models on
Defects4J with Fault Localization
Projects Chart Closure LangMathMockito TimeTotal
Sequencer 3/3 4/5 2/2 6/9 0/0 0/0 15/19
CODIT 1/2 2/5 0/0 3/5 0/0 0/0 6/12
Tufano19 3/4 3/5 1/1 6/8 0/0 0/0 14/18
DLFix 5/12 6/10 5/12 12/18 1/1 1/2 30/55
CoCoNuT 6/11 6/9 5/13 13/21 2/2 1/1 33/57
CURE 6/13 6/10 5/14 16/23 2/2 1/2 36/71
DEAR 8/16 7/11 8/15 20/33 1/2 3/6 47/91
X/Y: are the numbers of correct and plausible patches, respectively.
Table 2: RQ1. Detailed Comparison with DL-based APR Mod-
els on Defects4J with Fault Localization
Bug Types DLFixCoCoNuT CUREDEAR
Type 1. One-Hunk One-Stmt 30 33 3629
Type 2. One-Hunk Multi-Stmts 0 0 04
Type 3. Multi-Hunks One-Stmt 0 0 011
Type 4. Multi-Hunks Multi-Stmts 0 0 01
Type 5. Multi-Hunks Mix-Stmts 0 0 02
Total 30 33 3647
As seen in Table 1, DEAR can auto-fix the most number of bugs
(47)andgeneratethemostnumberofplausiblepatches(91)thatpass
alltestcasesonDefects4J.Particularly,DEARcanauto-fix32,41,33,
17, 14, and 11 more bugs than Sequencer, CODIT, Tufano19, DLFix,
CoCoNuT,andCURE,respectively(i.e.,213%,683%,236%,57%,42%,
and31%relativeimprovements).ComparedwiththosetoolsinthatorderonDefects4J,DEARcanauto-fix35,34,41,18,31,and18bugs
that thosetools missed,respectively. Via theoverlapping analysis
betweentheresultof DEAR andthoseofthe baselinescombined,
DEAR can fix 18 unique bugs that they missed.
Table2showsthecomparisonbetweenDEARandthetopDL-
based baselines (DLFix, CoCoNuT, CURE) w.r.t. different bug types.
Forsingle-hunk bugs (Types 1-2), DEAR fixes 33 bugs including
4 unique single hunk bugs that the other tools missed.
Formulti-hunk bugs (Types 3â€“5), DEAR can fix 14 bugs that
cannotbefixedbyDLFix,CoCoNuT,andCURE.ExistingDL-based
APRmodelscannotfixthosebugssincethemechanismoffixing
one statement at a time does not work on the bugs that require thefixes with dependent changes to multiple statements at once. Thus,
they do not produce correct patches for those cases.
Formulti-hunk or multi-statement bugs (Types2â€“5),DEARfixes
18 of them (out of 47 fixed bugs, i.e., 38.3% of total fixed bugs).
6.1.2Without Fault Localization. We also compared DEAR
withothertoolsinthefixingcapabilitieswithouttheimpactofa
third-party FL tool. All the tools under comparison (Table 3) were
pointed to the correct fixing locations and performed the fixes. As
seen, if the fixing locations are known, DEARâ€™s fixing capability
isalsohigherthanthosebaselines(53bugsversus44,40,and48).
Importantly,itcanfix20multi-hunk/multi-statementbugs(37.7%
of a total of 53 fixed bugs), while CoCoNuT, DLFix, and CURE can
fix only 7, 5, and 10 such bugs.
DEARismoregeneralthanexistingDL-basedmodelsbecauseit
can support dependent fixes with multi-hunks or multi-statements.
Importantly, it significantly improves these DL-based models andTable 3: RQ1. Comparison with DL-based APR Models on
Defects4J without Fault Localization (i.e., Correct Location)
Bug Types DLFixCoCoNuT CUREDEAR
Type 1. One-Hunk One-Stmt 35 37 3833
Type 2. One-Hunk Multi-Stmts 1 3 34
Type 3. Multi-Hunks One-Stmt 4 3 613
Type 4. Multi-Hunks Multi-Stmts 0 0 01
Type 5. Multi-Hunks Mix-Stmts 0 1 12
Total 40 44 4853
Table 4: RQ2. Comparison with DL APRs on Large Datasets
CPatMiner
(4,415 tested bugs)BigFix
(2,594 tested bugs)
Tool/Dataset Top-1 Top-3 Top-5 Top-1 Top-3 Top-5
Sequencer 7.8% 8.9%10.3% 8.5% 9.1%10.8%
CODIT 4.5% 7.4% 9.2% 3.9% 6.3% 9.1%
Tufano19 8.6% 9.3%11.2% 7.7% 8.8% 9.6%
DLFix 11.4% 12.3% 13.1% 11.2% 11.9% 12.5%
CoCoNuT 13.5% 14.7% 15.3% 12.2% 13.6% 14.3%
CURE 14.2% 15.1% 15.5% 12.9% 14.2% 14.1%
DEAR 15.1% 15.6% 16.8% 14.1% 15.4% 16.3%
Table 5: RQ2. Comparison with DL APRs on Cross-Datasets
Tool/DatasetCPatMiner(Train)/BigFix BigFix(Train)/CPatMiner
Top-1 Top-3 Top-5 Top-1 Top-3 Top-5
Sequencer 5.4% 5.8% 6.2% 5.3% 6.1% 7.2%
CODIT 2.5% 4.0% 4.4% 3.2% 5.2% 6.4%
Tufano19 4.5% 5.4% 5.7% 5.9% 6.3% 7.6%
DLFix 6.3% 6.9% 7.3% 8.2% 8.7% 9.2%
CoCoNuT 6.7% 7.4% 8.1% 8.3% 9.6%10.7%
CURE 7.1% 7.7% 8.2% 8.7% 9.9%10.9%
DEAR 7.5% 8.1% 8.6% 9.6%10.2% 11.3%
raisestheDLdirectiontothesamelevelastheotherAPRdirections
(search-basedandpattern-based),whichcanhandlemulti-statement
bugs.Moreover,DEARisfullydata-drivenanddoesnotrequirethe
defined fixing patterns as in the pattern-based APR models.
6.2 RQ2. Comparison Results with DL-based
APR Models on Large Datasets
Table4showsthatDEARcanfixmorebugsthananyDL-basedAPR
baselines on the two large datasets. Using the top-1 patches, DEAR
canfix15.1%ofthetotal4,415bugsinCPatMiner.Itfixes40â€“322
more bugs than the baselines with top-1 patches. On BigFix, it can
fix 14.1% of the total 2,594 bugs with the top-1 patches. It can fix
31â€“145 more bugs than those baselines with the top-1 patches.
Table5showsthatDEARalsooutperformedthebaselinesinthe
cross-datasetsettinginwhichwetrainedthemodelsonCPatMiner
and tested them on BigFix and vice versa.
Table 6 shows the detailed comparative results on CPatMiner
w.r.t. different bug types. As seen, DEAR can auto-fix more bugs
on every type of bug locations on the two large datasets. Among 667
fixedbugs,DEARhasfixed169multi-hunkormulti-stmtbugsof
Types 2â€“5 (i.e., 25.33% of the total fixed bugs). DEAR fixes more
bugs(71,164,and41more),andfixesmorebugsineachbugtype
than the baselines CoCoNuT, DLFix, and CURE, respectively.
519
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:56:15 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Yi Li, Shaohua Wang, and Tien N. Nguyen
Table 6: RQ2. Detailed Analysis. Top-1 Result Comparison
with DL-based APR Models on CPatMiner Dataset
Types (#bugs)CoCoNuT CURE DLFix DEAR
#Fixed #Fixed #Fixed #Fixed
Type-1 (1,668) 28.7% (479) 29.8%(497) 23.7% (395) 29.9% (499)
Type-2 (530) 1.3% (7) 2.1% (11) 0.6% (3) 4.2% (22)
Type-3 (879) 12.4% (109) 13.2% (116) 11.8% (104) 13.7% (120)
Type-4 (1,089) 0% (0) 0% (0) 0% (0) 2.0% (22)
Type-5 (249) 0.4% (1) 0.8% (2) 0.4% (1) 2.0% (5)
Total (4,415) 13.5% (596) 14.2% (626) 11.4% (503) 15.1% (667)
Table 7: RQ3. Comparison with Pattern-based APR Models
Projects Chart Closure LangMathMockito TimeTotal
ssFix 3/7 2/11 5/12 10/26 0/0 0/4 20/60
CapGen 4/4 0/0 5/5 12/16 0/0 0/0 21/25
FixMiner 5/8 5/5 2/3 12/14 0/0 1/1 25/31
ELIXIR 4/7 0/0 8/12 12/19 0/0 2/3 26/41
AVATAR 5/12 8/12 5/11 6/13 2/2 1/3 27/53
SimFix 4/8 6/8 9/13 14/26 0/0 1/1 34/56
Tbar 9/14 8/12 5/13 19/36 1/2 1/3 43/81
Hercules 8/10 8/13 10/15 20/29 0/0 3/5 49/72
DEAR 8/16 7/11 8/15 20/41 1/2 3/6 47/91
X/Y: are the numbers of correct and plausible patches; Dataset: Defects4J
DEARfixes52,61,and40moremulti-hunk/multi-stmtbugs,and
20,104,and2moreone-hunk/one-stmtbugsthanCoCoNuT,DLFix,
andCURE.Forthemulti-statementbugs(Types2and5)thatthe
other tools fixed, the fixed statements are independent. This result
showsthatfixingeachindividualstatementatatimedoesnotwork.
6.3 RQ3. Comparison Results with
Pattern-based APR Models
AsseeninTable7,DEARperformsatthesamelevelintermsofthe
number of bugs as the top pattern-based tools Hercules and Tbar.
Table 8 displays the details of the comparison w.r.t. different
bugtypes.Asseen,DEARfixes7Multi/Mix-Statementbugs(Types
2,4â€“5)thatHerculesmissed.Investigatingfurther,wefoundthat
Hercules is designed to fix replicated bugs, i.e., the hunks must
havesimilarstatements.Those7bugsarenon-replicated,i.e.,the
buggy hunks have different buggy statements or a buggy hunk has
multiplenon-similarbuggystatements.ForTypes1and3,DEAR
fixes9lessone-statementbugsthanHerculesduetoitsincorrect
fixes. In total, DEAR fixes 12bugs that Hercules misses: Chart-
7,16,20,24; Time-7; Closure-6,10,40; Lang-10; Math-41,50,91.
Compared to Tbar, DEAR fixes 15 more multi-hunk/multi-stmt
bugs.Tbarisnotdesignedtofixmulti-statementsatonceasDEAR.
Instead,itfixesonestatementatatime,thus,doesnotworkwell
when those 15 bugs require dependent fixes to multiple statements.
The3bugs ofType2thatTbarcan fixaretheonesthatthefixes to
individual statements are independent. The same reason is applied
toSimFix.Tbarfixes11morecorrectone-hunk/one-statementbugs.
In brief, we raise DEAR, a DL-based model, to the comparable
and complementary level with those pattern-based APR models.
6.4 RQ4. Sensitivity Analysis
6.4.1 ImpactofFixing-togetherHunkDetection. AsseeninTable9,
without hunk detection, DEAR can auto-fix 35 bugs. With hunk
detection, DEAR can fix 14 more multi-hunk bugs (Types 3-5). ItTable8:RQ3.DetailedComparisonwithPattern-basedAPRs
Bug Types SimFixTbarHercules DEAR
Type 1. One-Hunk One-Stmt 304034 29
Type 2. One-Hunk Multi-Stmts 130 4
Type 3. Multi-Hunks One-Stmt 3015 11
Type 4. Multi-Hunks Multi-Stmts 000 1
Type 5. Multi-Hunks Mix-Stmts 000 2
Total 344349 47
Table 9: RQ4. Sensitivity Analysis on Defects4J
Variant Without
Hunk-DetWithout
ExpansionWithout
Attention-cycleDEAR
Type-1 31 30 26 29
Type-2 40 2 4
Type-3 01 3 9 11
Type-4 00 1 1
Type-5 00 2 2
Total 35 43 40 47
fixes two lessType-1 bugs due tothe incorrect hunk detection.In
brief,hunkdetectionisusefulsincethemulti-hunk/multi-statement
bugs require dependent fixes to multiple hunks at once.
6.4.2 Impact of Multi-Statement Expansion. As seen in Table 9,
withoutexpansion,DEAR fixes 43bugsinDefects4J.Withexpan-
sion,itfixes 7moremulti-stmtbugsinTypes2,4,5whileitfixestwo
less Type-3 bugs and one less Type-1 bug. The reason of fixing less
bugs in these two types is that the multi-statement expansion may
expandthebuggyhunkincorrectlybyregardingasingle-statement
bug as a multi-statement bug. Even so, DEAR still can fix more
bugs, showing the usefulness of the multi-statement expansion.
To compare the impact of Hunk Detection and Multi-Statement
Expansion, let us note that the variant of DEAR without Hunk-
Detection missed all 14 multi-hunk bugs (Types 3,4,5). The variant
without Expansion missed all 7 multi-statement bugs (Types 2,4,5).
However, let us consider how challenging it is to fix them. Among
14 multi-hunk bugs fixed with Hunk-Detection, 11 bugs are of
Type-3 (multi-hunk/one-statement), in which some approaches
(e.g.,Hercules)canhandlebyfixingonestatementatatime.Only3
bugs are of Types 4â€“5. In contrast, all 7 bugs fixed with Expansion
aremulti-statementbugs(Types2,4,5),whichcannotbefixedby
existingDL-basedAPRapproaches.Thus,Expansioncontributes
to handling more challenging bugs than Hunk-Detection.
6.4.3 ImpactofTree-basedLSTMmodelwithAttentionandCycle
Training. (Attention-cycle)TomeasuretheimpactofAttentionand
Cycle Training, we removed those two mechanisms from DEAR to
produce a baseline. Our results show that in Defects4J, DEAR fixes
7 more bugs on all bug types than the baseline (17.5% increase).
This result indicates the usefulness of the two mechanisms.
6.4.4 Impact of Training Dataâ€™s Size. Table 10 shows that the size
of training data has impact on DEARâ€™s performance. As seen in
Table10,themoretrainingdata,thehighertheDEARâ€™saccuracy.
This is expected as DEAR is a data-driven approach. But even with
less training data (70%/30%), DEAR achieves 11.7% for top-1 result,
whichisstillhigherthanDLFix(11.4%intop-1)andSequencer(7.7%
in top-1); both are with more training data (90%/10% splitting).
520
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:56:15 UTC from IEEE Xplore.  Restrictions apply. DEAR: A Novel Deep Learning-based Approach for Automated Program Repair ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Table 10: Impact of the Size of Training Data
Splitting Scheme on CPatMiner dataset 90%/10% 80%/20% 70%/30%
% Total Bugs at Top-1 15.1% 13.8% 11.7%
1public void excludeRoot(String path) {
2âˆ’ String url = toUrl(path);
3âˆ’ findOrCreateContentRoot(url).addExcludeFolder(url);
4+ Url url = toUrl(path);
5+ findOrCreateContentRoot(url).addExcludeFolder(url.getUrl());
6}
7public void useModuleOutput(Stringproduction, String test) {
8modifiableRootModel.inheritCompilerOutputPath( false);
9âˆ’ modifiableRootModel.setCompilerOutputPath(toUrl(production));
10âˆ’ modifiableRootModel.setCompilerOutputPathForTests(toUrl(test));
11+ modifiableRootModel.setCompilerOutputPath(toUrl(production).getUrl());
12+ modifiableRootModel.setCompilerOutputPathForTests(toUrl(test).getUrl());
13}
Figure 9: A Multi-hunk/Multi-statement Fix in CPatMiner
6.5 RQ5. Time Complexity and Parameters
Trainingtimeof DEARonCPatMinerwas+22hoursandpredicting
on CPatMiner took 2.4-3.1 seconds for each candidate patch. Train-
ing of DEAR on BigFix took 18-19 hours and predicting on BigFix
took 3.6-4.2 seconds for each candidate. Predicting on Defects4J
tookonly2.1secondsforacandidateduetoamuchsmallerdataset.
Test execution time was +1 second per test case. Test validation
took 2â€“20 minutes for all the test cases for a bug fix.
The best baseline, CURE [ 14], fixes fewer bugs than DEAR (RQ1
and RQ2), and requires 7 and 7.3 times more training parameters
than DEAR on CPatMiner and BigFix, respectively. Specifically,
DEARandCURErequire0.39Mand3.1Mtrainingparameterson
CPatMiner,and0.42Mand3.5MparametersonBigFix.Thus,DEAR
is less complex than CURE, while achieving better results.
Threats to Validity. We tested on Java code. The key modules in
DEAR are language-independent, except for the third-party FL
and post-processing with program analysis. Pattern-based APR
tools require a dataset with test cases, thus, we compared them on
Defects4Jonly.Wetriedourbesttore-implementthepattern-based
APR baselines and CURE for a fair comparison.
Illustrative Example. Figure 9 shows a correct fix from DEAR. It
correctly detects two buggy hunks; each with multiple statements.
DEARleveragesthevariablenamesexistinginthesamemethod
(modifiableRootModel atline8)incomposingthefixedcodeatlines11â€“
12.TheDL-basedbaselines,Sequencer[ 6]andCoCoNuT[ 23],treat
code as sequences, and does not derive well the structural changes
forthisfix.DLFixfixesonestatementatatime,thus,doesnotwork
(the fixes at line 2 and line 3 depend on each other). For pattern-
based APRs [13, 34], there is no fixing template for this bug.
Limitations. DEAR has the following limitations. First, as with ML
approaches, fixes with rare or out-of-vocabulary names are chal-
lenging.Withmoretrainingdata,DEAR hashigherchancetoen-
counter the ingredients to generate a new name. Second, we focus
onlyonthebugsthatcausefailingtests.Security,vulnerabilities,
and non-failing-test bugsare still its limitations.Third, we cannot
generate fixes with several new statements added or arbitrarilylarge sizes of dependent fixed statements. Fourth, the expansionalgorithmproducesincorrecthunkstobefixed,leadingtofixingin-correctstatements.Finally,wecurrentlyfocusonJava,however,the
basic representations used in DEAR, e.g., token, AST, dependency,
are universal to any program language. Only third-party FL and
post-processing with semantic checkers are language-dependent.
7 RELATED WORK
Deep Learning-based APR approaches. DeepRepair [ 42] learns
code similarities to select the repair ingredients from code frag-ments similar to the buggy code. DeepFix [
11] learns the syntax
rules to fix syntax errors. Ratchet [ 12], Tufano et al.[39], and Se-
quenceR[ 6]mainlyuseneuralnetworkmachinetranslation(NMT)
withattention-basedencoder-decoderandcodeabstractionstogen-
eratepatches.CODIT[ 5]encodescodestructures,learnscodeedits,
and adopt an NMT model to suggest fixes. Tufano et al.[38] learn
codechangesusingasequence-to-sequenceNMTwithcodeabstrac-tionsandkeywordreplacing.DLFix[
18]hasatree-basedtranslation
modeltolearnthefixes.CoCoNuT[ 23]developsacontext-aware
NMT model. CURE [ 14] proposes a code-aware NMT using GPT
model [31]. The existing DL-based APR models fix individual state-
ments at a time and are ineffective for multi-hunk/multi-stmt bugs.
Pattern-based APR approaches. Those approaches have mined
and learned fix patterns from prior fixes [ 15,17,19,27], either auto-
maticallyorsemi-automatically[ 17,19,20,27].Prophet[ 22]learns
code correctness models from a set of successful human patches.
Droix[37]learnscommon root-causesforcrashesusing asearch-
based repair. Genesis [ 21] automatically infers patch generation
fromusersâ€™submittedpatches.HDRepair[ 17]minesfixpatterns
with graphs. ELIXIR [ 33] uses templates from PAR with local vari-
ables,fields, orconstants, tobuild fixedexpressions. CapGen[40],
SimFix[13],FixMiner[ 16]relyonfrequentcodechangesextracted
from existing patches. Avatar [ 19] exploits fix patterns of static
analysisviolations.Tbar[ 20]isatemplate-basedAPRtoolwiththe
collectedfixpatterns.Angelix[ 25]catchesprogramsemanticsto
fix methods. ARJA [ 44] generates lower-granularity patch repre-
sentation enabling efficient searching. We did not compare with
AngelixsincewecomparedwithCapGenthatoutperformsAngelix.
WecouldnotreproduceARJA,however,ARJAfixesonly18bugs,
while DEAR fixes 42 bugs on the same four projects in Defects4J.
8 CONCLUSION
In thiswork, wemake three keycontributions: 1)a novel FLtech-
nique for multi-hunk, multi-statement fixes combining traditional
SBFLwithdeeplearninganddata-flowanalysis;2)acompositionalapproachtogeneratemulti-hunk,multi-statementfixeswithdivide-
and-conquer strategy; and 3) enhancements and orchestration of a
two-layer LSTM model with the attention layer and cycle training.
OnDefects4J,DEARoutperformstheDL-basedAPRbaselinesfrom
42%â€“683% in terms of the number of fixed bugs. On BigFix, it fixes
31â€“145morebugswiththetop-1patches.OnCPatMiner,itfixes
40â€“52 more multi-hunk/multi-stmt bugs than the baselines.
ACKNOWLEDGMENTS
ThisworkwassupportedinpartbytheUSNationalScienceFounda-
tion (NSF) grants CNS-2120386, CCF-1723215, CCF-1723432, TWC-
1723198, CCF-1518897,and CNS-1513263.
521
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:56:15 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Yi Li, Shaohua Wang, and Tien N. Nguyen
REFERENCES
[1] 2019. The Defects4J Data Set. https://github.com/rjust/defects4j
[2]2021.DEAR: A Novel Deep Learning-based Approach for Automated Program
Repair. https://github.com/AutomatedProgramRepair-2021/dear-auto-fix
[3]Rui Abreu, Peter Zoeteweij, and Arjan J.c. Van Gemund. 2006. An Evaluation of
Similarity Coefficients for Software Fault Localization. In Proceedings of the 12th
PacificRimInternationalSymposiumonDependableComputing(PRDC).39â€“46.
https://doi.org/10.1109/PRDC.2006.18
[4]NghiD.Q.Bui,YijunYu,andLingxiaoJiang.2021. TreeCaps:Tree-BasedCapsule
Networks for Source Code Processing. Proceedings of the AAAI Conference on
Artificial Intelligence 35, 1 (May 2021), 30â€“38. https://ojs.aaai.org/index.php/
AAAI/article/view/16074
[5]Saikat Chakraborty, Yangruibo Ding, Miltiadis Allamanis, and Baishakhi Ray.
2020. CODIT: Code Editingwith Tree-Based Neural Models. IEEE Transactions
on Software Engineering (2020). https://doi.org/10.1109/TSE.2020.3020502
[6]Zimin Chen, Steve James Kommrusch, Michele Tufano, Louis-NoÃ«l Pouchet,
DenysPoshyvanyk,andMartinMonperrus.2019. SEQUENCER:Sequence-to-
SequenceLearningforEnd-to-EndProgramRepair. IEEETransactionsonSoftware
Engineering (2019). https://doi.org/10.1109/TSE.2019.2940179
[7]Kyunghyun Cho, Bart van MerriÃ«nboer, Caglar Gulcehre, Dzmitry Bahdanau,
Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning Phrase
RepresentationsusingRNNEncoderâ€“DecoderforStatisticalMachineTranslation.
InProceedings of the 2014 Conference on Empirical Methods in Natural Language
Processing (EMNLP). Association for Computational Linguistics, Doha, Qatar,
1724â€“1734. https://doi.org/10.3115/v1/D14-1179
[8]JacobDevlin,Ming-WeiChang,KentonLee,andKristinaToutanova.2019. BERT:Pre-trainingofDeepBidirectionalTransformersforLanguageUnderstanding.InProceedingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies,Volume1(LongandShortPapers) .AssociationforComputationalLinguistics,Minneapolis,Minnesota,
4171â€“4186. https://doi.org/10.18653/v1/N19-1423
[9]ClaireLeGoues,MichaelDewey-Vogt,StephanieForrest,andWestleyWeimer.
2012. A systematic study of automated program repair: Fixing 55 out of 105
bugsfor $8each.In Proceedingsof the34thInternationalConference onSoftware
Engineering (ICSEâ€™12). 3â€“13. https://doi.org/10.1109/ICSE.2012.6227211
[10]ClaireLeGoues,ThanhVuNguyen,StephanieForrest,andWestleyWeimer.2012.GenProg:AGenericMethodforAutomaticSoftwareRepair. IEEETransactionson
SoftwareEngineering 38,1(Jan2012),54â€“72. https://doi.org/10.1109/TSE.2011.104
[11]Rahul Gupta, Soham Pal, Aditya Kanade, and Shirish Shevade. 2017. DeepFix:Fixing Common C Language Errors by Deep Learning. In Proceedings of the
Thirty-First AAAI Conference on Artificial Intelligence (San Francisco, California,
USA)(AAAIâ€™17). AAAI Press, 1345â€“1351.
[12]HideakiHata,EmadShihab,andGrahamNeubig.2018. Learningtogeneratecor-rectivepatchesusingneuralmachinetranslation. arXivpreprintarXiv:1812.07170
(2018).
[13]Jiajun Jiang, Yingfei Xiong, Hongyu Zhang, Qing Gao, and Xiangqun Chen.2018. Shaping Program Repair Space with Existing Patches and Similar Code.InProceedings of the 27th ACM SIGSOFT International Symposium on Software
Testing and Analysis (Amsterdam, Netherlands) (ISSTA 2018). Association for
ComputingMachinery,NewYork,NY,USA,298â€“309. https://doi.org/10.1145/
3213846.3213871
[14]Nan Jiang, Thibaud Lutellier, and Lin Tan. 2021. CURE: Code-Aware Neural
MachineTranslationforAutomaticProgramRepair.In Proceedingsofthe43rd
International Conference on Software Engineering (ICSEâ€™21) . 1161â€“1173. https:
//doi.org/10.1109/ICSE43902.2021.00107
[15]Dongsun Kim, Jaechang Nam, Jaewoo Song, and Sunghun Kim. 2013. Automatic
patch generation learned from human-written patches. In Proceedings of the
35th International Conference on Software Engineering (ICSEâ€™13). 802â€“811. https:
//doi.org/10.1109/ICSE.2013.6606626
[16]Anil Koyuncu, Kui Liu, TegawendÃ© F BissyandÃ©, Dongsun Kim, Jacques Klein,Martin Monperrus, and Yves Le Traon. 2020. Fixminer: Mining relevant fix
patternsforautomatedprogramrepair. EmpiricalSoftwareEngineering 25(2020),
1980â€“2024. https://doi.org/10.1007/s10664-019-09780-z
[17]Xuan Bach D. Le, David Lo, and Claire Le Goues. 2016. History DrivenProgram Repair. In Proceedings of the 23rd IEEE International Conference on
Software Analysis, Evolution, and Reengineering (SANERâ€™16), Vol. 1. 213â€“224.
https://doi.org/10.1109/SANER.2016.76
[18]Yi Li, Shaohua Wang, and Tien N. Nguyen. 2020. DLFix: Context-Based Code
TransformationLearningforAutomatedProgramRepair.In Proceedingsofthe
ACM/IEEE42ndInternationalConferenceonSoftwareEngineering (Seoul,South
Korea)(ICSEâ€™20).AssociationforComputingMachinery,NewYork,NY,USA,
602â€“614. https://doi.org/10.1145/3377811.3380345
[19]Kui Liu, Anil Koyuncu, Dongsun Kim, and TegawendÃ© F. BissyandÃ¨. 2019.
AVATAR:FixingSemanticBugswithFixPatternsofStaticAnalysisViolations.
InProceedings of the 26th IEEE International Conference on Software Analysis,
EvolutionandReengineering(SANERâ€™19).1â€“12. https://doi.org/10.1109/SANER.
2019.8667970[20]Kui Liu, Anil Koyuncu, Dongsun Kim, and TegawendÃ© F. BissyandÃ©. 2019. TBar:
Revisiting Template-Based Automated Program Repair. In Proceedings of the 28th
ACMSIGSOFTInternationalSymposiumonSoftwareTestingandAnalysis (Beijing,
China)(ISSTAâ€™19).AssociationforComputingMachinery,NewYork,NY,USA,
31â€“42. https://doi.org/10.1145/3293882.3330577
[21]Fan Long, Peter Amidon, and Martin Rinard. 2017. Automatic Inference of
CodeTransforms forPatch Generation.In Proceedingsof the11thJoint Meeting
on Foundations of Software Engineering (Paderborn, Germany) (ESEC/FSEâ€™17).
Association for Computing Machinery, New York, NY, USA, 727â€“739. https:
//doi.org/10.1145/3106237.3106253
[22]Fan Long and Martin Rinard. 2016. Automatic Patch Generation by Learn-ing Correct Code. In Proceedings of the 43rd Annual ACM SIGPLAN-SIGACT
Symposium on Principles of Programming Languages (St. Petersburg, FL, USA)
(POPL â€™16). Association for Computing Machinery, New York, NY, USA, 298â€“312.
https://doi.org/10.1145/2837614.2837617
[23]ThibaudLutellier,HungVietPham,LawrencePang,YitongLi,MoshiWei,and
Lin Tan. 2020. CoCoNuT: Combining Context-Aware Neural Translation Models
Using Ensemble for Program Repair. In Proceedings of the 29th ACM SIGSOFT
InternationalSymposiumonSoftwareTestingandAnalysis (VirtualEvent,USA)
(ISSTAâ€™20). Association for Computing Machinery, New York, NY, USA, 101â€“114.
https://doi.org/10.1145/3395363.3397369
[24]Matias Martinez and Martin Monperrus. 2016. ASTOR: A Program Repair Li-brary for Java (Demo). In Proceedings of the 25th International Symposium on
SoftwareTestingandAnalysis (SaarbrÃ¼cken,Germany) (ISSTAâ€™16).Associationfor
ComputingMachinery,NewYork,NY,USA,441â€“444. https://doi.org/10.1145/
2931037.2948705
[25]Sergey Mechtaev, Jooyong Yi, and Abhik Roychoudhury. 2016. Angelix: Scalable
MultilineProgramPatchSynthesisviaSymbolicAnalysis.In Proceedingsofthe
38thInternationalConferenceonSoftwareEngineering (Austin,Texas) (ICSEâ€™16) .
Association for Computing Machinery, New York, NY, USA, 691â€“701. https:
//doi.org/10.1145/2884781.2884807
[26]HoanAnhNguyen,TienN.Nguyen,DannyDig,SonNguyen,HieuTran,and
Michael Hilton. 2019. Graph-Based Mining of in-the-Wild, Fine-Grained, Seman-
ticCodeChangePatterns.In Proceedingsofthe41stInternationalConferenceon
Software Engineering (ICSE â€™19). IEEE Press, 819â€“830. https://doi.org/10.1109/
ICSE.2019.00089
[27]Hoang Duong Thien Nguyen, Dawei Qi, Abhik Roychoudhury, and Satish Chan-
dra. 2013. SemFix: Program repair via semantic analysis. In Proceedings of
the 35th International Conference on Software Engineering (ICSEâ€™13). 772â€“781.
https://doi.org/10.1109/ICSE.2013.6606623
[28]Tung Thanh Nguyen, Hoan Anh Nguyen, Nam H. Pham, Jafar Al-Kofahi, and
Tien N. Nguyen. 2010. Recurring Bug Fixes in Object-Oriented Programs. In Pro-
ceedings of the 32nd ACM/IEEE International Conference on Software Engineering -
Volume1 (CapeTown,SouthAfrica) (ICSEâ€™10).AssociationforComputingMa-
chinery, New York, NY, USA, 315â€“324. https://doi.org/10.1145/1806799.1806847
[29]JeffreyPennington,RichardSocher,andChristopherD.Manning.2014. GloVe:
GlobalVectorsforWordRepresentation.In EmpiricalMethodsinNaturalLan-
guage Processing (EMNLP). 1532â€“1543. http://www.aclweb.org/anthology/D14-
1162
[30]Yuhua Qi, Xiaoguang Mao, Yan Lei, Ziying Dai, and Chengsong Wang. 2014.
TheStrengthofRandomSearchonAutomatedProgramRepair.In Proceedings
ofthe36thInternationalConferenceonSoftwareEngineering (Hyderabad,India)
(ICSEâ€™14).AssociationforComputingMachinery,NewYork,NY,USA,254â€“265.
https://doi.org/10.1145/2568225.2568254
[31] Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. 2018. Im-
proving language understanding by generative pre-training. (2018).
[32]BaishakhiRayandMiryungKim.2012. ACaseStudyofCross-SystemPortingin
ForkedProjects.In ProceedingsoftheACMSIGSOFT20thInternationalSympo-
sium on the Foundations of Software Engineering (Cary, North Carolina) (FSEâ€™12).
Association for Computing Machinery, New York, NY, USA, Article 53, 11 pages.
https://doi.org/10.1145/2393596.2393659
[33]RiponKSaha,YingjunLyu,HiroakiYoshida,andMukulRPrasad.2017. Elixir:
Effectiveobject-orientedprogramrepair.In Proceedingsofthe32ndIEEE/ACM
InternationalConferenceonAutomatedSoftwareEngineering(ASEâ€™17).648â€“659.
https://doi.org/10.1109/ASE.2017.8115675
[34]SeemantaSaha,RiponK.Saha,andMukulR.Prasad.2019. HarnessingEvolutionforMulti-HunkProgramRepair.In Proceedingsofthe41stInternationalConference
onSoftwareEngineering (ICSEâ€™19).IEEEPress,13â€“24. https://doi.org/10.1109/
ICSE.2019.00020
[35]Abigail See, Peter J Liu, and Christopher D Manning. 2017. Get to the point:
Summarizationwithpointer-generatornetworks. arXivpreprintarXiv:1704.04368
(2017).
[36]Kai Sheng Tai, Richard Socher, and Christopher D. Manning. 2015. Improved
Semantic Representations From Tree-Structured Long Short-Term Memory Net-
works. In Proceedings of the 53rd Annual Meeting of the Association for Computa-
tional Linguistics and the 7th International Joint Conference on Natural Language
Processing(Volume1:LongPapers).AssociationforComputationalLinguistics,
Beijing, China, 1556â€“1566. https://doi.org/10.3115/v1/P15-1150
522
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:56:15 UTC from IEEE Xplore.  Restrictions apply. DEAR: A Novel Deep Learning-based Approach for Automated Program Repair ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
[37]Shin Hwei Tan, Zhen Dong, Xiang Gao, and Abhik Roychoudhury. 2018. Repair-
ing Crashes in Android Apps. In Proceedings of the 40th International Conference
onSoftwareEngineering (Gothenburg,Sweden) (ICSEâ€™18).AssociationforCom-
putingMachinery,NewYork,NY,USA,187â€“198. https://doi.org/10.1145/3180155.
3180243
[38]MicheleTufano,JevgenijaPantiuchina,CodyWatson,GabrieleBavota,andDenys
Poshyvanyk. 2019. On Learning Meaningful Code Changes Via Neural Machine
Translation. In Proceedings of the 41st IEEE/ACM International Conference on
SoftwareEngineering(ICSEâ€™19).25â€“36. https://doi.org/10.1109/ICSE.2019.00021
[39]Michele Tufano, Cody Watson, Gabriele Bavota, Massimiliano Di Penta, Martin
White, andDenys Poshyvanyk. 2018. AnEmpirical Investigation into Learning
Bug-FixingPatchesintheWildviaNeuralMachineTranslation.In Proceedingsof
the33rdACM/IEEEInternationalConferenceonAutomatedSoftwareEngineering
(Montpellier,France) (ASEâ€™18).AssociationforComputingMachinery,NewYork,
NY, USA, 832â€“837. https://doi.org/10.1145/3238147.3240732
[40]Ming Wen, Junjie Chen, Rongxin Wu, Dan Hao, and Shing-Chi Cheung. 2018.
Context-Aware Patch Generation for Better Automated Program Repair. In Pro-
ceedingsofthe40thInternationalConferenceonSoftwareEngineering (Gothenburg,
Sweden)(ICSEâ€™18). Association for Computing Machinery, New York, NY, USA,
1â€“11. https://doi.org/10.1145/3180155.3180233[41]Martin White, Michele Tufano, Matias Martinez, Martin Monperrus, and Denys
Poshyvanyk. 2019. Sorting and Transforming Program Repair Ingredients via
Deep Learning Code Similarities. In Proceedings of the 26th IEEE International
ConferenceonSoftwareAnalysis,EvolutionandReengineering(SANERâ€™19).479â€“490.
https://doi.org/10.1109/SANER.2019.8668043
[42]MartinWhite,MicheleTufano,ChristopherVendome,andDenysPoshyvanyk.
2016. Deeplearningcodefragmentsforcodeclonedetection.In Proceedingsof
the 31st IEEE/ACM International Conference on Automated Software Engineering
(ASE). ACM, 87â€“98.
[43]QiXinandStevenP.Reiss.2017. LeveragingSyntax-RelatedCodeforAutomatedProgram Repair. In Proceedings of the 32nd IEEE/ACM International Conference on
AutomatedSoftwareEngineering (Urbana-Champaign,IL,USA) (ASEâ€™17).IEEE
Press, 660â€“670.
[44]YuanYuanandWolfgangBanzhaf.2020. ARJA:AutomatedRepairofJavaPro-
grams via Multi-Objective Genetic Programming. IEEE Transactions on Software
Engineering (TSE) 46, 10 (2020), 1040â€“1067. https://doi.org/10.1109/TSE.2018.
2874648
[45]J. Zhu, T. Park, P. Isola, and A. A. Efros. 2017. Unpaired Image-to-Image Transla-
tion Using Cycle-Consistent Adversarial Networks. In 2017 IEEE International
Conference on Computer Vision (ICCV). 2242â€“2251. https://doi.org/10.1109/ICCV.
2017.244
523
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:56:15 UTC from IEEE Xplore.  Restrictions apply. 