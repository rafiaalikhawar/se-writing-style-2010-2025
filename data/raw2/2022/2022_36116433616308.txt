RevisitingNeural Program Smoothing forFuzzing
Maria-Irina Nicolae
Irina.Nicolae@bosch.com
RobertBoschGmbH
BoschCenter forAI
Stuttgart, GermanyMaxEisele
MaxCamillo.Eisele@bosch.com
RobertBoschGmbH
Stuttgart, Germany
SaarlandUniversity
Saarbrücken, GermanyAndreasZeller
zeller@cispa.de
CISPA Helmholtz Center for
InformationSecurity
Saarbrücken, Germany
ABSTRACT
Testingwithrandomlygeneratedinputs(fuzzing)hasgainedsig-
niﬁcant traction due to its capacity to expose program vulnerabili-
ties automatically. Fuzz testing campaigns generate large amounts
of data, making them ideal for the application of machine learn-
ing(ML).Neuralprogramsmoothing ,aspeciﬁcfamilyof ML-guided
fuzzers,aimstouseaneuralnetworkasasmoothapproximation
ofthe program target for newtest casegeneration.
Inthispaper, weconductthemostextensive evaluation ofneu-
ral program smoothing ( NPS) fuzzers against standard gray-box
fuzzers (>11 CPU years and >5.5 GPU years), and make the fol-
lowing contributions: (1) We ﬁnd that the original performance
claims for NPSfuzzersdo not hold; a gap we relate to fundamen-
tal,implementation,andexperimentallimitationsofpriorworks.
(2) We contribute the ﬁrst in-depth analysis of the contribution
of machine learning and gradient-based mutations in NPS. (3) We
implement Neuzz++, which shows that addressing the practical
limitationsof NPSfuzzersimprovesperformance,butthat standard
gray-boxfuzzersalmostalwayssurpass NPS-basedfuzzers. (4)Asa
consequence, we propose new guidelines targeted at benchmarking
fuzzingbasedonmachinelearning,andpresentMLFuzz,aplatform
with GPU access for easy and reproducible evaluation of ML-based
fuzzers. Neuzz++,MLFuzz,andallourdataare public.
CCSCONCEPTS
•Security and privacy →Software security engineering ;•Soft-
ware and its engineering →Software testing and debugging ;•
Computing methodologies →Neuralnetworks .
KEYWORDS
fuzzing,machinelearning,neuralnetworks,neuralprogramsmooth-
ing
ACM Reference Format:
Maria-IrinaNicolae,MaxEisele,andAndreasZeller.2023.RevisitingNeural
Program Smoothing for Fuzzing. In Proceedings of the 31st ACM Joint Euro-
pean Software Engineering Conference and Symposium on the Foundations of
Software Engineering (ESEC/FSE ’23), December 3–9, 2023, San Francisco, CA,
USA.ACM,NewYork,NY,USA, 13pages.https://doi.org/10.1145/3611643.
3616308
ESEC/FSE ’23, December 3–9, 2023, San Francisco, CA,USA
©2023 Copyright heldby theowner/author(s).
ACM ISBN 979-8-4007-0327-0/23/12.
https://doi.org/10.1145/3611643.36163081 INTRODUCTION
Inrecentyears,fuzzing—testingprogramswithmillionsofrandom,
automaticallygeneratedinputs—hasbecomeoneofthepreferred
methods for ﬁnding bugs and vulnerabilities in software, mainly
due to its speed, low setup eﬀorts, and successful application in
the industry. Google’s OSSFuzz initiative [ 23], for instance, has
revealedthousands ofbugs in open-sourcesoftware.
Fueled by success stories of practical fuzzing, researchers are
constantlyseekingwaystomakefuzzersmoreeﬃcient[ 28].The
most popular approach is still coverage-guided fuzzing: generate
newtestcasesfromprioronesusinganevolutionarysearchthat
optimizes code coverage through a ﬁtness function. Techniques
used to enhance fuzzers include concolic execution [ 40,48], or
staticanalysis[ 47].Alongthem,machinelearningmethodshave
increasinglybeenappliedtodiﬀerentpartsofthefuzzingloopin
academic research[ 7,12,16,19,35].
Fuzz testing generates signiﬁcant amounts of data which make
a welcomeinput for machinelearning.Moreover,obtaining labels
throughfeedbackfromthefuzzerortheprogramismostoftenfast
and cheap. Constructing a dataset for training machine learning
modelsisthusrelativelystraightforwardinfuzzing.However,de-
spitetheirincreasedtractionintheresearchcommunityinthepast
decade,ML-basedfuzzers are not widely usedin practice [ 33].
Recently, neural program smoothing [38,39,46] has been pro-
posed to approximate the tested program with a neural network.
The trained model learns to predict coverage from test cases, be-
ing additionallysmoothand diﬀerentiable. Thesepropertiesallow
computinggradients,whichcannotreadilybedoneonprograms
directly. Test cases are mutated into new ones based on the pre-
dictions of the neural network using gradient descent. The use
of gradients allows to steer the mutations in the most relevant
directions,whichhavehigherchancesofreachingnewcoverage.
Despite promisingsigniﬁcant performancegains, both in terms of
codecoverageandnumberofbugsfound,thesemethodsarenot
currently usedbypractitioners for testingrealsoftware.
Motivated by the applicabilityof neural program smoothing to
real-worldfuzzing,weprovidea systematicandthoroughanalysis
ofNPS-guided fuzzing methods with the followingcontributions:
(1)We provide a critical analysis of NPS-guided fuzzing, un-
covering fundamental,conceptual and practical limitations
thatwere previously ignored. We show that neural network
performancedoesnottranslatetoimprovedcoverage, asthe
modelfails tocapture rare edge coverage.
(2)We compare multiple NPS-guided fuzzers in an extensive
benchmarkagainstAFL,AFL++,andtherecentHavoc MAB
on23targetprograms. NPS-guidedfuzzersunderperformre-
gardingcodecoverageandbugﬁnding,whichis atoddswith
Thiswork islicensedunderaCreativeCommonsAttribution4.0Interna-
tional License.
133
ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA Maria-IrinaNicolae, MaxEisele, andAndreas Zeller
the results from the original papers. We explain this perfor-
mancegapbyoutdatedorincorrectexperimentalpractices
inprior work.
(3)We reimplement Neuzz as a custom mutator for AFL++ and
show that ﬁxing practical limitations of NPSsigniﬁcantly
improves fuzzing performance. Nevertheless, we ﬁnd that
neural program smoothing methods are outperformed by
state-of-the-art gray-box fuzzers, despite their use of addi-
tionalcomputationresources.
(4)Based on our ﬁndings, we propose better-suited guidelines
for evaluating ML-enhanced fuzzing, and present MLFuzz,
the ﬁrst fuzzing benchmarking framework with GPU sup-
portdedicatedto ML-basedfuzzing. MLFuzzallowsforeasy,
reproducible evaluation of fuzzers with or without machine
learning,similartostandardpracticesusedbyFuzzBench[ 33].
The remainder of the paper is structured as follows. Section 2
introducesprior workon coverage guided fuzzingand neural pro-
gramsmoothing,beforetacklingourmainanalysisonlimitations
ofneuralprogramsmoothingin Section3.Section4 presentsour
implementation of NPSfuzzing and the benchmarking platform.
Section5 coversexperiments,followedbynewexperimentalguide-
linesinSection6.Weconcludethisworkin Section7.Allourresults
andcode are publiclyavailable ( Section 8).
2 BACKGROUND
Coverage-guided fuzzing. Coverage-guidedfuzzersexplorethe
input space of a program startingfrom a few sampleinputs called
seeds. They mutate the seeds into new test cases based on a ﬁtness
criterion, whichrewardsreachingnewcodecoverageobtainedby
gray-box access through binary instrumentation. Test cases that
increasecoveragearekeptinthecorpustobeevolvedfurther.Over
time, the input corpus and the total code coverage grow. During
execution,thefuzzerchecksthetargetprogramforunwantedbe-
havior,notablycrashesandhangs.Popularcoverage-guidedfuzzers
are American Fuzzy Lop (AFL) [ 49], its successor AFL++ [ 18], and
libFuzzer[ 30].Alongsidebasicmutations,mostgray-boxfuzzers
usethehavocmutationstrategy,whereaﬁxednumberofrandomly
chosen atomic mutations are chained to a more complex muta-
tion [18]. Motivated by the success of havoc in modern fuzzers,
HavocMAB[45] wasdesignedtoimplementthehavoc strategyas a
two-layermulti-armedbandit [ 4]. Despitethe trivial rewardfunc-
tion used by the bandit, Havoc MABclaims to signiﬁcantly improve
code coverageover random havoc inextensive benchmarks.
Fuzzing with machine learning. MLhas been applied to vari-
oustasksinthefuzzingloop.Neuralbytesieve[ 35]experiments
with multiple types of recurrent neural networks that learn to
predict optimal locations in the input ﬁles to perform mutations.
Angora [ 12] uses byte-level taint tracking and gradient descent
to mutate test cases towards new coverage. FuzzerGym [ 16] and
Böttinger etal.[7]formulatefuzzingasareinforcementlearning
problem that optimizes coverage. In parallel to mutation gener-
ation, machine learning is naturally ﬁt for generating test cases
directly.Skyﬁre[ 42]learnsprobabilisticgrammarsforseedgenera-
tion.Learn&Fuzz[ 19]usesasequence-to-sequencemodel[ 41]to
implicitlylearnagrammartoproducenewtestcases.GANFuzz[ 25]
usesgenerativeadversarialnetworks(GANs)[ 20]todothesamefor
2. Test Case
4. Edge Coverage7. Gradient-guided
Mutations 3. Instrumented
ProgramI. Model Training
1. Corpus
8. New 
Test CasesII. Test Case Generation
∇
5. Neural Network6. Gradient 
Computation Figure 1:Neuralprogram smoothing forfuzzing.
protocols.DeepFuzz[ 29]learnstogeneratevalidCprogramsbased
on a sequence-to-sequence model for compiler fuzz testing. The
applicationof MLtofuzzingiscoveredmoreextensivelyin[ 36,44].
Neural program smoothing. Program smoothing [ 10,11] was
initially introduced as a way to facilitate program analysis and
overcome the challenges introduced by program discontinuities.
Among the uses of machine learning in fuzzing, neural program
smoothingisoneofthemostrecentandpopularmethods,dueto
its great performance in the original studies. Neuzz [ 39] trains a
neural network to serve as a smooth approximation of the original
programintermsofcodecoverage( Figure1).First,alltestcases(2)
from the corpus (1) are executedon the instrumentedprogram (3)
toobtaintheirindividualcodecoverage(4),i.e.edgecoveragefrom
afl-showmap . The respective pairs of test case and coverage are
then used to train a neural network (5), which learns to predict the
coverage for each test case. Being smooth and diﬀerentiable, the
neural network can be used for computing gradients, the values
of derivatives of the program w.r.t. its inputs. These indicate the
direction andrate of fastest increasein the function valueand can
be used to ﬂip speciﬁc edges in the bitmap from zero to one (6).
Eachgradientcorrespondstoonebyteintheinput.Thelocations
withthehighestgradientvaluesaremutated(7)toproposenewtest
cases (8) that should reach the targeted regions of the code. This
ideaisinspiredbyadversarialexamples,morepreciselyFGSM[ 21],
where a change in the input in the direction of the sign of the
gradient issuﬃcient to changethe modeloutcome.
MTFuzz[ 38]extendsNeuzzwithmultitasklearning[ 8]:theneu-
ral network is trained against three types of code coverage instead
of only edge coverage. Context-sensitive coverage [12,43] distin-
guishesbetweendistinctcallerlocationsforthesamecoverededge,
whileapproach-sensitive coverage [2] introduces a third possible
valueinthecoveragebitmapreﬂectingwhenanedgewasnearly
coveredbecausetheexecutionhasreachedaneighboringedge.The
threetypesofcoveragehelplearnajointembeddingthatisusedto
determineinterestingbytesformutationinthetestcase.Thebytes
arerankedusingasaliencyscore,whichiscomputedasthesumof
gradientsforthatbyteinthelearnedembeddingspace.Each“hot
byte”ismutatedbytryingoutallpossiblevalues,withoutfurther
relying onthe gradients.
134Revisiting Neural Program SmoothingforFuzzing ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
PreFuzz [ 46] attempts to solve some limitations of Neuzz and
MTFuzz by extending Neuzz in two ways. The program instrumen-
tation is changed to include all neighboring edges of covered ones
in thebitmap. This information isused toprobabilistically choose
which edge to target next for coverage, with the end goal of en-
couragingdiversityinedgeexploration.Additionally,thesuccess
of havoc mutations [ 18] is leveraged: after the standard Neuzz mu-
tation,havocisappliedprobabilisticallytopre-deﬁnedsegmentsof
bytesinthe test case,according to theirgradient value.
3 ANALYZINGNEURAL PROGRAM
SMOOTHING
In this section, we provide our main analysis of neural program
smoothing, covering both the concepts behind NPS, as well as
existingfuzzerimplementations.Wetacklethreeorthogonalper-
spectives:(i)conceptualorfundamental,(ii)implementationand
usability,and(iii) experimental considerations.
3.1 Conceptual Limitations
(C1)Approximationerrorsoftheneuralnetwork. Beingan
empiricalprocess,neuralnetworktrainingcansuﬀerfromerrors
introduced in the training process by, e.g., limited training data
andtrainingtime,orsensitivitytohyperparameters.Eveninthe
idealcase, beingasmoothapproximation,the NPSmodelwillalways
diﬀer from the actual program exactly at the most interesting points ,
i.e., discontinuities, branches, and jumps. This approximation error
is intrinsic to a smoothing approach and, at the same time, what
allowsNPSmethods to use gradients and numeric optimization
towardsproducing newinputs.
(C2)Capacitytoreachtargetededges. Arguably,themost
salientresearchquestiontoelucidateaboutneuralprogramsmooth-
ing iswhether the gradient-guidedmutation canindeedreach the
targetededges.As NPSisbasedonmultiplecomponents( Figure1),
the overall performance of the fuzzer critically depends on the
eﬀectiveness ofits individualcomponents:
(1) The prediction accuracyofthe neuralnetwork (5);
(2)The capacity of the gradient-based mutations (7) to achieve
the expectednewcoverageonthe target program.
The experiments we perform later in the paper show that the
machinelearningcomponentasusedbyneuralprogramsmoothing
hasimpairedperformance.Tothebestofourknowledge,prior NPS
studieshavenotassessedwhatthemodelwaslearningandwhether
itwasreachingits objective.
(C3) Incomplete coverage bitmaps. Another central limi-
tation of neural program smoothing that we uncover relates to
the incompleteness of the coverage bitmaps that the neural net-
work receives. All NPSfuzzers retrieve covered edges through
afl-showmap , which only reports the edge IDs that are reached.
Whenthecoverageinformationfromallseedsisputtogetherfor
theoverallbitmapusedfortrainingtheneuralnetwork,itthusonly
contains edges that were reached at least once by any of the seeds.
As such, unseen edges are not part of the bitmap and cannot be
explicitly targetedanddiscoveredby themodel.In practice, ifthe
neural network does discover new edges, it is rather inadvertently
due to randomness. While having access to only an incomplete
coverage bitmap is aconceptual limitation,it can be addressedonan implementation level. It is suﬃcient to change the instrumenta-
tionoftheprogramtoincludeuncoverededgestoovercomethis
issue. Among existing NPSfuzzers, PreFuzz is the only one that
considersinformationaboutneighborsofreachededgesinthecov-
erage bitmap, albeit not motivated by the limitation we uncover.
Theirgoalisrathertobeabletochoosethenextedgetotargetina
probabilistic fashion, depending on the degree of coverage of each
edge andits neighbors.
The fundamental limitations uncovered in this section, while
someeasiertosolvethanothers,arewhatweseeasmainobstaclein
theadoptionof NPS-basedfuzzinginpractice.Aswillbeconﬁrmed
inSection 5, the experiments are consistent with these limitations.
3.2 Implementation andUsabilityLimitations
We now turn to practical aspects that make existing approaches
to neural program smoothing inconvenient to use, such that an
independent evaluation requires majoreﬀortandcode rewriting.
(I1) Use of outdated components. Existing implementations
ofneuralprogramsmoothing[ 38,39,46],alongwithHavoc MAB[45]
areimplementedasextensionsofAFLinsteadofusingthemorere-
cent, more performant AFL++ as base. Moreover, their dependency
on outdated Python, TensorFlow and PyTorch versions impacts
usability.Forthepurposeofexperiments,wehavepatchedthecode
andupdatedthedependenciesofallthesefuzzers,asevenforthe
most recent ones, some of their used libraries were already not
available at the time oftheir publication.
(I2)Diﬃcultyinbuildingtargets. PriorNPSstudiesprovided
thebinariesusedintheirownresearch,ensuringreproducibility.
However,forafuzzertobepractical,itisadvisabletoratherpro-
vide instructions on how to build new programs for its use. This
isespeciallyimportant when the fuzzer uses custom target instru-
mentation.MTFuzz[ 38],forinstance,compilesatargetprogramin
ﬁvediﬀerentwaysduetotheintroductionofthreeadditionaltypes
ofinstrumentation.Forthis reason,we excludeMTFuzz fromour
empirical study as not being practical for real-world fuzzing. More-
over, we argue that the three types of coverage used by MTFuzz
aretoalargeextentredundant(conceptuallimitation)andcould
begroupedintoauniﬁedcoverage,thusreducingthebuildeﬀort
for this fuzzer.
(I3)Useofmagicnumbers. Themagicnumbersprogramming
antipattern [ 31] is frequently encountered in the implementations
ofneuralprogramsmoothing-basedfuzzers.Thesevaluesandother
algorithmicchangesarenotmentionedintheoriginalpaperswhere
eachNPSfuzzerisintroduced.Itisthusdiﬃculttoestablishwhether
theperformanceofeachmethodisstrictlylinkedtoitsproposedal-
gorithmorrathertotheimplementationtweaks.E.g.,themaximum
numberofmutationguidinggradientsperseedissetto500;this
valueisnot aparameterof the algorithm presentedinthe paper.
Ourﬁndingsaboveshowthattheeﬀorttosetupexisting NPS
fuzzersandbuildtargetsforthemissigniﬁcantlyhigherthanfor
standardgray-boxfuzzers,suchasAFLanditsvariants,orlibFuzzer.
3.3 EvaluationLimitations
Inthissection,wehighlightﬂawsandlimitationsofpreviousex-
perimental evaluations of NPSfuzzers and Havoc MAB, which have
ledto unrealistic performance claims.
135ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA Maria-IrinaNicolae, MaxEisele, andAndreas Zeller
(E1) Experimental protocol. The more recent NPSpublica-
tions [38,46]lack of comparisons with recent gray-box fuzzers, such
asAFL++andlibFuzzer—fuzzersthatwereavailableandconﬁrmed
asstate-of-the-artlongbeforetheirpublication.Havoc MAB[45]has
includedNeuzzandMTFuzzintheirevaluationalongsideAFL++.
However, we ﬁnd that they use the same binary target for both
AFL and AFL++, instead of building the program separately for
AFL++. AFL++ runs on AFL instrumented binaries, but not eﬃ-
ciently. Moreover, the size of the coverage bitmap is usually larger
forAFL++thanwithAFLinstrumentation;hence,codecoverage
as measured by the fuzzers is not directly comparable. This makes
the conclusions inthe Havoc MABevaluation [ 45]questionable.
(E2) Fuzzer conﬁguration for speed. We note that prior
studies benchmarking NPSmethods compile their targets using
afl-gcc, which results in slower targets and thus impacts fuzzing
speed. The AFL++ documentation recommends using preferably
afl-clang-fast orafl-clang-lto [17].Additionally,AFL-based
fuzzers have multiple options for transferring fuzz data to the pro-
gram. The most basic is to have AFL write test cases to ﬁle, and
the target program executed with command line options to pro-
cess the ﬁle as input. The more sophisticated and recommended
persistent mode uses a fuzzing harness that repeatedly fetches fuzz
data from AFLvia shared memory andexecutes thefunction with
thetestdataasinputwithoutrestartingthewholeprogram.“ All
professionalfuzzingusesthismode ”,accordingtotheAFL++man-
ual [5]. Depending on the target, the persistent mode can increase
thethroughputby2–20 ×[18].Previousneuralsmoothingpapers
seem to run all experiments by feeding inputs via ﬁles, which
should considerably slow down all fuzzers. This is consistent with
theirresults,wherethemoremodernAFL++consistentlyperforms
worse than AFL in the Havoc MABstudy [45], and the targets are
printed with command line arguments in the original Neuzz pa-
per[39].Weconjecturethatthistipsthescaleinfavorof ML-based
fuzzers, which are themselves orders of magnitude slower than
modern fuzzers [ 16]. This statement is validated experimentally in
Section 5.7 .
4 IMPLEMENTING NEUZZ++ AND MLFUZZ
Inthissection,weintroduce Neuzz++, ourimplementationofneural
programsmoothingthataimstosolvesomelimitationsidentiﬁedin
Section 3, as well as the new experimental platform for evaluating
ML-basedfuzzers.
Neuzz++. We implement a variation of Neuzz as a custom muta-
tor for AFL++, which we name Neuzz++ (see Figure 2). This allows
ourmethodtoleveragemostAFL++features,likeitsstandardmuta-
tions and power schedule. More importantly, it allows for machine
learning-produced test cases and randomly mutated ones to evolve
from each other. We choose AFL++ as base for our implementation
for its state-of-the-art performance, thus addressing Issue I1. Being
acustommutator,Neuzz++ismodular,easytobuild,andintegrated
withadefaultAFL++installation.
In practice, Neuzz++ consists of two parts: the main AFL++ pro-
cess with the custom mutator implemented in C, and a Python
extensionthatiscalledformachinelearningoperations.Thetwo
processes communicate using named pipes. We set a minimum
requirementof /u1D447testcasesinthecorpusforthecustommutatorto
AFL
Gradient-guided
FuzzingExisting NPS-guided
FuzzersNeuzz++
AFL++
Gradient-guided
Custom 
MutatorAFL++
MutationsMutation 
Scheduler1 hour
23 hours24 hoursFigure 2: Operation mode of previous NPS-guided fuzzers
andour Neuzz++.
run.Theseareusedtotraintheneuralnetworkfortheﬁrsttime;the
model is retrained at most every hour if at least ten new test cases
have been added to the corpus1. This allows to reﬁne the model
over time with new coverage information from recent test cases.
In practice, we use /u1D447=200; this value is tuned experimentally and
aimstostrikethebalanceacrossalltargetsbetweenfuzzingwith
machinelearningasearlyaspossible,whilewaitingforenoughdata
tobeavailableformodeltraining.Intuitively,alargerdatasetpro-
ducesabetterperformingmodel. afl-showmap isusedtoextract
the coverage bitmap. We introduce a coverage caching mechanism
formodelretrainingwhichensuresthatcoverageiscomputedonly
for new test cases that were produced since last model training.
Each time the C custom mutator is called by AFL++, it waits for
thePythoncomponenttocomputeandsendthegradientsofthe
test case. Based on these, the mutations are computed by the C
mutatorandreturnedtoAFL++.IncontrasttoNeuzz,thegradients
arenotprecomputedpertestcase,theyarenotsavedtodisk,the
neural network is kept in memory, and the gradients are computed
onlyondemand.Theseoptimizationsminimizethetimespenton
ML-relatedcomputations,keeping more time for fuzzing.
The neuralnetwork isamulti-layer perceptron(MLP)withthe
samestructureasNeuzz(onehiddenlayer,4096neurons).Asshown
inthePreFuzzpaper[ 46],we alsofoundthatdiﬀerentneuralnet-
workarchitecturesdonotimprovefuzzingperformance.Incontrast
toNPSfuzzers,wekeep10%ofthetestcasesasvalidationsetfor
evaluatingtheperformanceofthemodel.WeusetheAdamopti-
mizer[26], alearningrateof 10−4,andcosine decaywithrestarts.
It is easy to parallelize model training and the main AFL++ rou-
tineforimprovedfuzzingeﬀectivenesswhentestingrealtargets.
However,forexperimentalevaluation,wechoosetohaveAFL++
wait for the neural network to train, similarly to previous imple-
mentationsofneuralprogramsmoothingfuzzers.Thisallowsfor
fair experimental comparison and computation resource allocation.
Theoriginal Neuzzimplementation appliesfour diﬀerentmuta-
tionpatternsoneachbyteselectedaccordingtothehighestranking
gradients: incrementing the byte value until 255, decrementing the
byte value down to 0, inserting a randomly sized chunk at the byte
location, and deleting a randomly sized chunk starting at the given
byte location. We apply the same mutation pattern for Neuzz++.
1Neuzz and PreFuzz solve this issue by running AFL for the ﬁrst hour of fuzzing, then
usethe collected data for modeltraining( Figure2).
136Revisiting Neural Program SmoothingforFuzzing ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
MLFuzz. MLFuzzservesasabenchmarkingframeworkforbuild-
ing testtargets, runningfuzzing trialsinanisolated environment,
andanalyzing the ﬁndings.Itsmain features are:
•Test targets from Google Fuzzer Test Suite [ 22] are com-
piled with the recommended and most recent compiler of
theappropriatefuzzer;thebuildscriptsaremadeavailable
(addressing Issue I2andissueE2).
•Targets are compiled with AddressSanitizer [ 37] to detect
memory errors.
•Six fuzzers are currently included in MLFuzz: AFL v2.57b,
AFL++ v3.15a, Havoc MAB, Neuzz, PreFuzz and our Neuzz++.
•TheimplementationiscontainerizedviaDocker[ 32].Python
dependency speciﬁcation is handled via virtual environ-
mentsandPoetry [ 15].
•EachfuzzingtrialrunsononededicatedCPUandoptionally
one GPUfor fuzzersthat support it.
•All supported fuzzers have been modiﬁed to acceptseeding
oftheirrandom number generatorfor reproducibleresults.
•Forallfuzzers,coverageismeasuredbyreplayingthecorpus
at the end of a run. We use binaries instrumented with AFL
to ensure we do not disadvantage the AFL-based fuzzers,
andafl-showmap fromAFL++, sinceithasalarger bitmap
withless hash collisions.
•Test cases are transmitted to fuzzers via shared memory,
with the option to switch to slow transmission of test cases
viathe ﬁle system(addresses Issue E2).
5 EXPERIMENTS
This section introduces our experiments and practical analysis,
complementing the main ﬁndings from previous sections. After
presenting our setup ( Section 5.1 ), we assess the performance of
thecomponents of NPS-basedfuzzers in Section5.2 . We compare
our Neuzz++ to prior neuralprogram smoothingfuzzers andstan-
dard gray-box fuzzers in an extensive benchmark in Section 5.3 .
Sections 5.4 to5.6explore the added beneﬁt of machine learning to
NPSfuzzers,while Section5.7 shedslightonexperimentalprotocol
diﬀerences with previous NPSpublications and their impact on
fuzzingresults. Finally,we report bugsfoundin Section 5.8 .
5.1 ExperimentalSetup
AllexperimentsareperformedonaserverrunningUbuntu20.04
withfourNvidiaTitanXpGPUs.Ourstudyincludesthesixfuzzers
fromMLFuzz:AFLandAFL++asstandardgray-boxfuzzers,Havoc MAB
as recent fuzzer claiming state-of-the-art performance, and NPS
fuzzers Neuzz, PreFuzz, and our own Neuzz++. We use the origi-
nal implementation and parameters provided by the authors for
allbaselines,exceptwhenstatedotherwise.Wepatchthecodeof
NeuzzandPreFuzztoportthemtoPython3.8.1,CUDA11.5,Tensor-
Flow2.9.1[ 1]andPyTorch1.4[ 34],astheoriginalimplementations
arebasedonoutdatedlibrariesthatarenotavailableanymoreor
incompatible withour hardware.
We choose Google Fuzzer Test Suite [ 22] and FuzzBench [ 33] as
standard,extensivebenchmarksforourexperimentalevaluation.
Wemakeuseof23targets,summarizedin Table1.Theseareselected
forbeingaccessible,havingdependenciesavailableonUbuntu20.04,
andbeingnon-trivialtocoverthroughfuzztesting.NotethatweTable 1: Target programs from Google Fuzzer Test Suite [ 22]
andFuzzBench [ 33].
Target Format SeedsaLOCb
Source:Fuzzer Test Suite
boringssl-2016-02-12 SSLprivatekey 107 102793
freetype2-2017 TTF, OTF, WOFF 2 95576c
guetzli-2017-3-30 JPEG 2 6045
harfbuzz-1.3.2 TTF, OTF, TTC 58 21413
json-2017-02-12 JSON 1 23328
lcms-2017-03-21 ICC proﬁle 1 33920
libarchive-2017-01-04 archiveformats 1 141563
libjpeg-turbo-07-2017 JPEG 1 35922
libpng-1.2.56 PNG 1 24621
libxml2-v2.9.2 XML 0 203166
openssl-1.0.2d DERcertiﬁcate 0 262547
pcre2-10.00 PERL regex 0 67333
proj4-2017-08-14 custom 44 6156
re2-2014-12-09 custom 0 21398
sqlite-2016-11-14 custom 0 122271
vorbis-2017-12-11 OGG 1 17584
woﬀ2-2016-05-06 WOFF 62 2948
Source:FuzzBench
bloaty ELF, Mach-O, etc. 94 690642
curl comms.formats 41 153882
libpcap PCAP 1287 56663
openh264 H.264 174 97352
stb imageformats 467 71707
zlib zlib compressed 1 30860
aTargetsthatdonothaveseedsuse the default from Fuzzbench.
bRetrieved with cloc[14].
onlyincludetargetsfromFuzzBenchiftheyarenotalreadyincluded
inFuzzerTestSuite.Allresultsarereportedfor24hoursoffuzzing.
We repeat each experiment 30 times to account for randomness,
unless stated otherwise. Each standard gray-box fuzzer is bound to
oneCPUcore,while NPSfuzzersareallottedoneCPUandoneGPU
pertrial.Themainmetricsusedforevaluationarecodecoverage
andnumberofbugsfound.Forcodecoverage,weuseedgecoverage
as deﬁned by the AFL family offuzzers. However,we emphasize
thatAFLandAFL++computeedgecoveragediﬀerently.Inorderto
avoidthemeasuringerrorsintroducedwhenignoringthisaspect,
we count coverage by replaying the corpus using afl-showmap
from AFL++ on the same binary, independently of which fuzzer
wasusedintheexperiment.Thesetupweuseﬁxesallexperimental
limitationswe highlightedin Section 3.3 (Issues E1 andE2).
5.2 Performance ofMachine Learning Models
Wenowinvestigatethequalityofcoveragepredictionsbytheneural
network and gradient-based mutations, in relation to concerns
about the fundamental principle of neural program smoothing
(Section 3.1 ). We tackle the following questions:
•Can the neuralnetwork learn to predict edge coverage?
•Can gradient-basedmutations reachtargetededges?
To this end, we propose quantitative and qualitative analyses of
the performance of the neural network in neural program smooth-
ing fuzzers. Without loss of generality, we investigate these based
onNeuzz++asaproxyforallneuralprogramsmoothingfuzzers
137ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA Maria-IrinaNicolae, MaxEisele, andAndreas Zeller
Figure 3: Predictedand actualedgecoverage on libpngforthe entire corpus. Top: ML-predictedcoverage (pink) is trivialand
almostconstantovertestcases.Wheneachedgeistargetedbymutations,predictedcoverage(orange)increasesforcertain
edges,butmanycodeedgesremainunattainable.Bottom:Coverageextractedwith afl-showmap showsthatalledgespresent
have been covered at least onceby thecorpus.
Table 2:Datasetproperties andneuralnetworkevaluation.
Target %covered edges Acc Prec Recall F1 PR-AUC
bloaty 17.1% 0.53 0.17 0.18 0.17 0.15
boringssl 19.3% 0.90 0.18 0.17 0.17 0.20
curl 15.2% 0.89 0.15 0.15 0.15 0.23
freetype2 8.6% 0.89 0.09 0.09 0.09 0.10
guetzli 18.5% 0.84 0.18 0.18 0.18 0.19
harfbuzz 6.9% 0.93 0.07 0.07 0.07 0.07
json 12.7% 0.88 0.11 0.08 0.09 0.10
lcms 20.9% 0.84 0.19 0.19 0.19 0.21
libarchive 6.9% 0.94 0.07 0.06 0.06 0.07
libjpeg 17.8% 0.84 0.17 0.09 0.17 0.18
libpcap 6.4% 0.92 0.06 0.06 0.06 0.07
libpng 28.8% 0.86 0.28 0.27 0.27 0.29
libxml2 10.5% 0.92 0.10 0.09 0.09 0.11
openh264 21.4% 0.81 0.22 0.30 0.21 0.22
openssl 31.2% 0.79 0.30 0.30 0.29 0.31
pcre2 4.3% 0.96 0.04 0.03 0.03 0.04
proj4 8.2% 0.95 0.08 0.07 0.07 0.08
re2 16.2% 0.87 0.15 0.13 0.13 0.16
sqlite 16.3% 0.91 0.12 0.12 0.12 0.17
stb 6.0% 0.92 0.06 0.05 0.05 0.06
vorbis 29.6% 0.81 0.30 0.30 0.30 0.30
woﬀ2 22.8% 0.85 0.22 0.22 0.21 0.13
zlib 16.1% 0.85 0.14 0.10 0.11 0.16
included in our study. As all these methods use the same neural
networkarchitecture,lossfunction,methodoftraining,etc.,itisto
beexpectedthattheirmodelswillachievethesameperformance
whentrainedonthesamedataset.Theresultsoftheanalysescan
be summarizedas followsandare detailedsubsequently:•Table2quantiﬁesthemodelperformanceforalltargetsin
terms ofstandardmachine learningmetrics;
•Figure 3provides a qualitative analysis of model predictions
for agiven target, opposing themto correctlabels.
•Lastly,Figure3alsoassessesthecapacityoftheneuralnet-
work to reachedges throughgradient-basedmutations.
MLperformance metrics. To assess one factor of diﬃculty of
themachinelearningtask,weevaluatedatasetimbalanceforthe
training corpus. This measures the percentage of the positive class
(covered edges, in our case the minority) in the coverage bitmap of
thetrainingset.Recallthatthebitmapisproducedby afl-showmap
and accounts for the coverage obtained by the corpus before train-
ing;thecoveragewasnotnecessarilyachievedbasedonaneural
network, but rather by AFL++ mutations. Note that this value is
averaged across test cases and edges; rare edges might have much
smallercoverageratios,resulting in more diﬃcultyin trainingan
accuratemodelforthoseedges.Whenfacingclassimbalance,the
modeltendstopreferthemajorityclass,thusmakingwrongpre-
dictions. For this reason, the performance of the neural network is
assessed using precision, recall, F1-score, and precision-recall ( PR)
trade-oﬀ as performance metrics for the neural network. Accu-
racy is also computed for completeness, but keep in mind that
this metric is misleading for imbalanced datasets2. We measure
the area-under-the-curve ( AUC) of thePRmetric to evaluate all
theoperationalpointsoftheneuralnetwork.Similartoaccuracy,
PR-AUCsaturates at one, but is more sensitive to wrong predic-
tions in the positive class. The learning setup of neural program
smoothingisamulti-labelbinaryclassiﬁcationtask,i.e.,foreach
2One cantrivially predict all-zeros (no coverage)and obtainveryhigh accuracy.
138Revisiting Neural Program SmoothingforFuzzing ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
test case, multiple binary predictions are made, one per edge; in
consequence,themetricsarecomputedforeachedgeinthebitmap
independently,thenaveragedoveralledges,andﬁnallyaveraged
over trialrepetitions.
Table2reportsthemodelperformancemetrics,alongwiththe
percentage of the positive class in the dataset as imbalance metric.
Allmodel metrics are computed on a10% holdout setof testcases
that were not used for training. As Neuzz++ retrains the model
multiple times, all measurements are performed on the last trained
neural network using the state of the corpus at that time. The
precision,recall,F1-score,and PR-AUCvaluesin Table2indicate
that the neural network has low performance. These metrics are
particularlylowwhentheclassimbalanceisstronger,i.e.,forsmall
values of “%covered edges”. The dataset imbalance is quite extreme
for seven targets, where the positive class represents less than 10%
ofthe dataset,makingpredictions particularlydiﬃcult.
To provide an intuition into what the neural network learns,
wedesignaqualitativeevaluationofitspredictedcoverage.This
experimentusesthetarget libpngandthetestcasesgeneratedin
a 24-hours run of Neuzz++. Figure 3 shows two coverage plots
for this target for the entire corpus, where each “column” in the
plotrepresentsonetestcase,whileeach“row”isaprogramedge.
We compare the coverage predicted by a trained MLmodel for
the same test cases and edges ( Figure 3top) to the true coverage
extracted with afl-showmap (bottom). The bottom plot isthe cov-
erage bitmap extracted with afl-showmap for the corpus and used
formodeltrainingbyNeuzz,PreFuzz,andNeuzz++.Areduction
(deduplication) operation is applied to it, which for libpngreduces
the number of edges from 900 to the 293 present in the plot; this
operation also explains any visual artifacts present in the image,
asthe edges are reordered.The pink areas ofthe twoplots diﬀer
signiﬁcantly,withthemodelpredictionsbeingalmostconstantover
alltestcases:themodelonlypredictstrivialcoverageandfailsto
capture rare edges. While this is a consequence of the diﬃculty
ofthemachinelearningtasks(smalldataset,classimbalance,too
few samples w.r.t. the size of the test cases and bitmaps, see Ta-
ble2),itresultsinlargeapproximationerrorsintheneuralnetwork,
asoutlinedin IssueC1.Moreover,recallthatNeuzz,PreFuzzand
Neuzz++usethesame MLmodeltypeandstructure,withminordif-
ferences in the training procedure and similar model performance.
Our ﬁndingsthus extend to allNPSmethods.
Finally,weinvestigatetheeﬀectivenessofgradient-basedmu-
tationsasessentialcomponentof NPSfuzzers.Inthesamesetup
onlibpngfromthe previoussection, we apply Neuzz++ mutations
tothecorpusgeneratedbya24-hoursfuzzingrunasfollows.For
each edge in the bitmap, we consider the case when it is explicitly
targeted and generate all mutations with a maximum number of
iterationsinthemutationstrategy. Figure3(top)plotsthepredicted
coveragefor each testcase and edge before the mutations, aswell
as the increment of coverage after mutation. Each edge (row) is
considered covered by one test case (column) if atleast one ofthe
few thousand mutations generated to target it reaches the code
location.Theresultsrepresentcoverageestimatedbythe MLmodel,
not run on the program. However, the coverage the model predicts
is an optimistic estimate of the one actually achieved on the target,
asthemodeldictatedthemutations.NotethatthemutationsaregeneratedinthesamewayforNeuzz,PreFuzzandNeuzz++;our
analysisthus applies to allmethodsandtargets.
Figure 3 (top) indicates that some locations are more readily
reachable through mutations. The harder to reach edges overall
match the rarer edges of the corpus, as measured by afl-showmap
in the bottom plot. Most importantly, none of the edges targeted
or covered by the mutations in the top plot represent new coverage .
Recall that, by NPSmethods’ design, a code edge is only present in
the bitmap only if it has already been covered by the initial corpus
used for training ( Issue C3). This becomes evident in the bottom
plot ofFigure 3: all edges have been covered by at least one test
case.Aswillbeshownlater,thisfundamentalﬂawof NPSmethods
translates to a limited practical capacity of reaching new coverage.
Themodelpredicts trivialedge coverage ( Issue C1), and
gradientmutations cannot target new edges( Issue C3).
5.3 ComparingCodeCoverage
We present the main experiment comparing the achieved code
coverage of available neural program smoothing approaches to
AFL,AFL++andtherecentHavoc MABinTable3(averagecoverage)
andFigure 4(coverage over time). This experiment alone requires
atotalcomputationtime of over 11 CPUyears and5.5 GPUyears.
Overall, AFL++ obtains the best performance on ten targets,
followed by Havoc MABwith eight targets, and Neuzz++ on par
withAFL,winningtwotargetseach.InviewofAFL++performance
w.r.t.AFL,itisclearthatnotincludingAFL++asabaselineinall
priorneuralprogramsmoothingworksleadstooverlyoptimistic
conclusionsabouttheircapacities.After AFL++,Havoc MABisthe
secondmostperformantfuzzerintermsofcodecoverage.However,
weﬁndthatitdoesnotreachtheexpectedrankingadvertisedin
the Havoc MABpaper [45].
We observe that Neuzz and PreFuzz are never in the top two
fuzzers. Moreover, although they were designed to improve AFL
performance, their coverage is in most cases lower than that of
AFL. AFL wins on 20 out of 23 targets over Neuzz, and 18 out of 23
overPreFuzz.PreFuzzoutperformsNeuzzonmosttargets,however
this diﬀerence is signiﬁcant only on six targets (see conﬁdence
intervals in Figure 4). This ﬁnding is also at odds with original
PreFuzz results [ 46], where the performance gap is signiﬁcantly
wider.Section 5.7 is dedicated to further explaining thediﬀerence
in performance with the initial papers. Neuzz++ obtains higher
coveragethanNeuzzandPreFuzzon21programs,provingthatour
improvements over thesemethodsare eﬀective.
Targetslibarchive, libxml2, proj4, andwoﬀ2exhibit the most
variabilityamongfuzzers.NeuzzandPreFuzzexhibitlargestandard
deviation on woﬀ2,where coverage varies depending if the fuzzers
reach plateau or not. For the other targets, it seems AFL-based
fuzzersdo not perform as well as AFL++-basedones.
Overall, AFL++achieves the highestcode coverage.Among
NPS fuzzers, Neuzz++ achieves the highestcode coverage.
139ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA Maria-IrinaNicolae, MaxEisele, andAndreas Zeller
Table 3:Average edgecoverage andstandard deviationover30runs.
Best value inbold,second best underlined.
Target AFL AFL++ Havoc MAB Neuzz PreFuzz Neuzz++
bloaty 14220±4915607±10015240±19412518±79012936±31915296±196
boringssl 2936±342940±342956±12863±142867±212930±32
curl 13002±110313398±137614121±3248999±2119048±21811260±1401
freetype2 10722±12611090±10411408±958569±2818870±38610960±138
guetzli 7306±216772±97398±297099±267141±456702±7
harfbuzz 12056±13711887±13711953±14610672±11010875±10211654±65
json 2033±52018±112036±01974±791970±862032±12
lcms 2483±1981904±4412423±2771593±3721876±4331809±455
libarchive 3708±3835281±2074970±1533729±2893718±2255246±204
libjpeg 2685±823058±1612980±1922647±52664±602892±189
libpcap 2203±2193733±1152833±2431859±3581875±3733529±155
libpng 1234±71235±31240±21220±61219±71241±3
libxml2 4857±2869155±9895416±2734895±4034853±2717306±1191
openh264 13381±34115234±1514902±10914135±24114537±14215126±80
openssl 1891±61899±11894±41878±71884±81886±8
pcre2 7797±1427960±1428076±987555±767575±777763±67
proj4 1837±16215585±1014190±7411526±5141849±3924550±78
re2 6680±526717±76777±266497±1626547±1106731±30
sqlite 2004±1542123±122121±01982±1582025±1462125±16
stb 3305±1093390±113413±203286±183315±143380±14
vorbis 2317±62348±42342±192186±292181±402311±38
woﬀ2 3305±33472±343418±362080±6671650±8933062±530
zlib 615±12623±6620±5592±10595±12620±3Table4:AverageedgecoverageofML
componentover30runs.
Neuzz PreFuzz Neuzz++
292±206666±593261±166
0±20±011±19
141±182153±88534±245
635±225865±255429±130
28±1169±3532±13
161±52377±145345±163
2±321±46216±86
61±210344±415 8±23
105±97101±1241136±206
4±56±6103±35
43±2759±411608±289
2±31±2105±31
52±4674±32950±215
1846±2902248±284148±67
6±76±691±70
0±213±91396±160
186±242145±204197±82
25±9324±75660±209
0±00±094±129
122±77150±8277±13
186±21186±4216±11
5±1614±4939±21
9±910±824±14
5.4 CodeCoverage from Machine Learning
After presenting total coverage for 24-hour runs in Table 3, we
now measure how much of the total coverage can be attributed
to the machine learning component for each NPSfuzzer. On one
hand, the goal is to discount the coverage produced strictly by AFL
in the ﬁrst hour of Neuzz and PreFuzz runs (recall that they use
AFL for data collection, see Figure 2) and only measure the NPS
fuzzers’contribution.Ontheotherhand,wewishtodothesamefor
Neuzz++, and separate its contribution from that of the base fuzzer
AFL++.AsNeuzz++isacustommutatorforAFL++,itsseedsusually
alternate with regular AFL++ seeds. To this end, we measure edge
coveragebycorpusreplaying,thistimeonlytakingintoaccount
theseedsobtainedbyNeuzz,PreFuzzandNeuzz++,respectively.
ForNeuzzandPreFuzz,thisisequivalenttoexcludingtheﬁrsthour
ofcoverage,asdonebytheoriginalauthors.Inpractice,thiswill
includeML-based mutations, but also other hard-coded mutations
thatthemethodsapply,suchashavocinthecaseofPreFuzz. Table4
summarizesthe comparisonof edge coverage obtained by the ML
componentsofNeuzz,PreFuzz,andNeuzz++.Programnamesare
alignedwith Table3.
Neuzz++ obtains the highest coverage in 14 over 23 targets,
with values at least one order of magnitude higher than Neuzz
and PreFuzz. Nevertheless, even on targets where Neuzz++ does
notobtainthehighest MLcoverage(e.g., freetype2,harfbuzz ),the
overall Neuzz++ edge coverage ( Table 3) is higher than that of
NeuzzandPreFuzz,withthelattertwoobtaininglowercoverage
than their base fuzzer AFL. The added value of Neuzz and PreFuzz
is low in nine, respectively ﬁve targets, with coverage close to zero.
In these cases, Neuzz and PreFuzz do not achieve (almost) any
coverage past the ﬁrst hour of fuzzing with AFL (see also Figure 4).Thisreinforcesourpreviousconclusionthatthetimespentusing
NeuzzandPreFuzzmightbebetterspentapplyingtheAFLorAFL++
mutation strategy. Moreover, the Neuzz++ results suggest that it
mightbeneﬁtfromthealternation between ML-guidedmutations
andstandardAFL++ones.Weexplorethislastpointwithadditional
analysesin Section 5.5 .
Formost programs, the timebudgetspentonNeuzzor
PreFuzz is better spentonstandard gray-box fuzzing.
5.5 Quality ofMachine Learning TestCases
We now aim to assess the quality of the test cases found by the
machine learning component of Neuzz++. We do so with two anal-
yses: we investigate (i) the inclusion of ML-generated inputs in the
AFL++powerscheduleforfurthermutation,and(ii)therarityof
code edges foundthroughmachine learning-basedmutations.
First,Table 5presents statistics regarding ML-produced test
cases for each target averaged over all trials. The column “%ML
seeds” shows the overall percentage of inputs produced through
MLmutations. Out of these, “%MLcov+” discover new coverage
(relative percentage). Finally, “%derived” is the total percentage of
thecorpusproducedbydirectmutationsof ML-basedinputs.We
ﬁndthattheratioofmachinelearninginputsvariessigniﬁcantly
acrosstargets,representinguptoathirdofthecorpus. MLtestcases
seemtobemostimpactfulforﬁndingnewcoverageonprograms
wheretheyrepresentalowpercentageofthecorpus.Onaverage,
eachMLtest case is mutated at least once successfully, generating
newtest casesthat are kept byNeuzz++ inthe corpus.
140Revisiting Neural Program SmoothingforFuzzing ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
0 6 12 18 241100012000130001400015000bloaty
0 6 12 18 24286028802900292029402960boringssl-2016-02-12
0 6 12 18 2490001000011000120001300014000curl
0 6 12 18 247500800085009000950010000105001100011500freetype2-2017
0 6 12 18 24660067006800690070007100720073007400guetzli-2017-3-30
0 6 12 18 2495001000010500110001150012000harfbuzz-1.3.2
0 6 12 18 24150016001700180019002000json-2017-02-12
0 6 12 18 241200140016001800200022002400lcms-2017-03-21
0 6 12 18 243500400045005000libarchive-2017-01-04
0 6 12 18 2424002500260027002800290030003100libjpeg-turbo-07-2017
0 6 12 18 24100015002000250030003500libpcap
0 6 12 18 241180119012001210122012301240libpng-1.2.56
0 6 12 18 24400050006000700080009000libxml2-v2.9.2
0 6 12 18 2412000125001300013500140001450015000openh264
0 6 12 18 2418601870188018901900openssl-1.0.2d
0 6 12 18 246500675070007250750077508000pcre2-10.00
0 6 12 18 2410002000300040005000proj4-2017-08-14
0 6 12 18 2461006200630064006500660067006800re2-2014-12-09
0 6 12 18 2419001950200020502100sqlite-2016-11-14
0 6 12 18 24300030503100315032003250330033503400stb
0 6 12 18 242000210022002300vorbis-2017-12-11
0 6 12 18 24100015002000250030003500woff2-2016-05-06
0 6 12 18 24580590600610620zlib
Havoc_MAB
AFL++
PreFuzz
Neuzz
Neuzz++
AFL
Relative time (hours)Edge coverage
Figure 4: Average edge coverage over time with 95% conﬁ-
denceinterval.Table 5: Statistics for ML-generated test cases of Neuzz++.
“%ML seeds” and “%derived” are computed over the total size
ofthecorpus.“%MLcov+”is relative to “%ML seeds”.
Target %MLseeds %MLcov+ %derived
bloaty 4.72% 28.3% 8.78%
boringssl 27.7% 3.3% 27.5%
curl 18.6% 26.1% 33.1%
freetype2 2.2% 31.9% 3.8%
guetzli 9.9% 9.8% 13.8%
harfbuzz 6.6% 30.2% 15.2%
json 13.7% 37.3% 25.4%
lcms 1.6% 57.1% 1.1%
libarchive 18.3% 30.2% 34.9%
libjpeg 11.8% 10.7% 15.9%
libpcap 13.8% 40.0% 20.8%
libpng 19.6% 13.8% 41.0%
libxml2 15.1% 23.9% 30.1%
openh264 10.2% 8.0% 8.5%
openssl 30.6% 5.6% 28.7%
pcre2 18.3% 17.4% 29.88%
proj4 5.5% 49.7% 7.4%
re2 23.3% 22.8% 34.7%
sqlite 8.1% 20.2% 6.2%
stb 14.8% 15.3% 19.9%
vorbis 6.0% 8.3% 7.9%
woﬀ2 3.8% 19.8% 5.2%
zlib 16.9% 20.7% 18.1%
Thesecondanalysisstudieswhether NPSfuzzersexplorecode
areas that are harder to reach by standard fuzzers. In that case,
neuralprogramsmoothingfuzzerscouldbeusedinanensemble
ofdiverse fuzzers, openingthepath for allfuzzers torare parts of
the code [ 13].To measure the rarity of edgesreached by Neuzz++,
we comparetheedgeIDsthatNeuzz++ andAFL++ reachon each
program, all trials joint. The edge IDs are obtained by replaying all
the test caseswith afl-showmap .
We summarize the results in Table 6as follows: Neuzz++ (de-
notedN+)revealslessthan0.5%additionaledgesthatAFL++(de-
notedA+)in16outof23targets.Neuzz++doesnotﬁndanysuchex-
clusiveedgesforeightprograms;itismostsuccessfulon lcms,with
8.2%exclusiveedges.Ontheotherhand,AFL++ﬁndsupto16.4%ex-
clusive edges, lacking exclusive edges on only two programs ( json
andsqlite). We can therefore conclude that NPS-guided fuzzers
explore essentiallythe same code areas as traditional fuzzers.
NPS fuzzers ﬁndlessrare edgesthangray-box fuzzers.
5.6 NPS-based Fuzzing withoutGPUs
Due to their increased performance for linear algebra and data
throughput,GPUsarethe defactostandardformachinelearning.
AllNPSmethodsstudiedinthispaperleverageGPUaccesstotrain
machine learning models and compute gradients for test case mu-
tations.Inpractice,thismeansthattheyusemorecomputational
resources than state-of-the-art gray-box fuzzers, and that practi-
tionersarerequiredtoinvestinadditionalhardware.Inthissection,
we wish to assess the performance of NPSmethods in the absence
ofGPUs.Model trainingwithonlyCPUaccessshouldbeslower,
141ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA Maria-IrinaNicolae, MaxEisele, andAndreas Zeller
Table 6:Reached edges forAFL++(A+)andNeuzz++(N+).
Target A+ N+ A+ ∪N+ A+ \N+ N+ \A+
bloaty 5131 4926 5139 213 8
boringssl 1210 1208 1210 2 0
curl 6862 6656 6899 243 37
freetype2 6555 6292 6575 283
guetzli 2645 2624 2655 31 10
harfbuzz 5438 5081 5440 359 2
json 2036 2036 2036 0 0
lcms 935 1010 1019 9 84
libarchive 3622 3223 3649 426 27
libjpeg-turbo1565 1539 1565 26 0
libpcap 2869 2628 2901 273 32
libpng 621 616 621 5 0
libxml2 5401 4856 5410 554 9
openh264 5849 5840 5851 11 2
openssl 812 811 812 1 0
pcre2 5548 5355 5577 222 29
proj4 2802 2343 2803 460 1
re2 2391 2426 2440 14 49
sqlite 950 950 950 0 0
stb 2012 2014 2021 7 9
vorbis 1142 1100 1142 42 0
woﬀ2 1254 1268 1270 2 16
zlib 337 333 337 4 0
Table7:Averageedgecoverageof NPSfuzzerswithandwith-
outGPU access(10 runs).
Neuzz PreFuzz Neuzz++
Target CPU GPU CPU GPU CPU GPU
harfbuzz 10607 10677 1067510897 1163111664
libjpeg 2618 2647 26352688 2998 2892
sqlite 2017 1993 2049 2089 21212127
woﬀ2 1919 18161702 954 3288 3389
but it should not impact the performance ofthe trained model. As
such, any loss in fuzzing performance comes from spending more
time training and less fuzzing. For this small experiment, we select
four targets that operate on a varied range of input formats for
diversity.Weperformtentrialsofall NPSfuzzerswithandwithout
GPUaccess ( Table7).
Nine of twelve experiments obtain more code coverage when
training themodelonGPU, whichis to be expected.The exception
is PreFuzz on woﬀ2, which is however aligned with this fuzzer’s
tendencyofsometimesbecomingstuckonthisprogram( Table3).
Overall,thefuzzingperformanceonGPUismarginallybetter,as
trainingtimesfor NPSmodelsarerelativelyshort.Thegapbetween
CPUandGPUseemstighterforNeuzz++,whichweattributetoan
alreadyoptimizedandshorttrainingprocedure,whichcannotbe
muchfurther improvedbyGPUs.
Using GPUsusuallyresultsin better coverage for
NPS fuzzers.
5.7 ImpactofTestCaseTransmission Method
InIssueE2,weunderlinedthat NPS-guidedfuzzersuseﬁlestotrans-
fer test cases to the target program. We now show that test caseTable 8: Relative degradation of edge coverage not using per-
sistent mode(10 runs).
Target AFL AFL++ Havoc MABNeuzz PreFuzz Neuzz++
harfbuzz -8.9% -60.2% -2.9% -3.4% -2.6% -2.9%
libjpeg -2.8% -55.7% -5.9% -8.9% -7.7% -14.6%
sqlite 0.1% -57.4% -0.3% -4.9% -7.9% -1.7%
woﬀ2 -34.5% -84.3% -40.4% -43.8% -46.8% -0.6%
transmission has a major impact on fuzzing performance for the
methods in [ 38,39,45,46]. We note that AFL++ does not reach the
performance of its predecessor AFL by a margin in the Havoc MAB
work [45]. This is inconsistent with several other large bench-
marks [3,33], where AFL++ ranks among the top fuzzers. While
notusingthepersistencemodeslowsdownall fuzzers,weexpect
state-of-the-artgray-boxfuzzerstobeaﬀectedthemost,i.e.,they
would lose their competitive advantage of speed. This experiment
uses the same targets andsetupas the previous section.
Table 8presents the performance diﬀerence when the persis-
tencemodeisnotused.Thissetupreproducesboththeprotocoland
results from Havoc MAB[45], the only paper that compares NPS-
guided fuzzers against AFL++. As expected, coverage decreases
whenpassinginputsthroughﬁlesandrestartingtheprogramfor
eachtestcase.Mostinterestingly,AFL++showsthelargestslow-
downwithaconsistentcoveragelossover50%,whiletheAFL-based
fuzzersmainlyshowsingle-digitpercentagedegradation.Conse-
quently, not using the recommended persistence mode can distort
the ranking of fuzzers in a benchmark. In our opinion, this set-
ting does not yield a fair or practically relevant comparison. Worth
mentioning here is that Neuzz++ can compensate the performance
loss of its base fuzzer AFL++, obtaining more coverage in absolute
values. As conjectured, results indicate that NPS-guided fuzzers
suﬀerlessunder slowoperationthanotherfuzzers.Despite that,
we are still not able to reproduce the performance of Neuzz and
PreFuzzagainst AFL reportedinthe originalpapers.
AFL++is most slowed down when not using
the persistent mode.
5.8 Bugs Found
Themaingoaloffuzzingistoﬁndasmanyuniquebugsaspossible.
The default coverage-based crash identiﬁcation mechanism of AFL
andAFL++tendstoovercountuniquebugs[ 27].Toimprovethis
behavior, we apply a more precise stack trace-based deduplication
algorithm.Wethereforeexecuteeachreportedcrashinginputon
thetargetwithinGNUdebugger( GDB)andretrieveallstackframe
addresses when the error occurs. This list of addresses then serves
as a unique identiﬁer of the triggered bug. Note that deduplication
based on stack traces is ineﬀective when stack overﬂow errors
occur,because the stack framesare then corrupted.
Table 9contains the number of crashes with unique stack trace
signaturesacrossalltrialsforeachtargetthatreportedanycrashes.
NeuzzandPreFuzzﬁndthelowestnumberofcrashinginputs(none
for most targets), followed by AFL, their base fuzzer; Havoc MAB
signiﬁcantly improves over AFL. AFL++ is most successful in re-
vealingcrashes,withmostbugsfoundandalltargetscovered.In
summary, all NPS-based fuzzers ﬁnd fewer crashing inputs than
the fuzzerthey are basedupon.
142Revisiting Neural Program SmoothingforFuzzing ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
Table 9:Bugsfoundafter stack trace deduplication.
Target AFL AFL++ Havoc MABNeuzz PreFuzz Neuzz++
bloaty 1 1 2 0 0 1
guetzli 8 264 5 0 0 170
harfbuzz 0 355 1 0 0 12
json 20 11 22 18 16 10
lcms 0 16 0 0 0 8
libarchive 0 1 0 0 0 0
libxml2 0 648 1 0 0 289
openssl 138 1324 409 37 40 721
pcre2 87 4174 262 40 35 1371
re2 0 172 1 0 0 2
vorbis 0 2 1 0 0 0
woﬀ2 20 361 671 1 1 172
NPS-guided fuzzers ﬁnd fewer bugs than standard fuzzers.
6 BENCHMARKINGML-BASED FUZZERS
Fuzzerevaluation is an openresearch topic abundently studied in
recent works [ 3,6,27,33]. A common guideline is that each fuzzer
must be tested on multiple programs, using multiple repetitions to
account for randomness. The recommended number of repetitions
revolves around 10–20 trials. Besides the average performance,
indicatorsof variability(i.e.,conﬁdence intervals, statisticaltests)
are necessary to assess the signiﬁcance of the results. The main
goal of fuzzers is to ﬁnd bugs, which suggests that unique bugs
foundinﬁxedtimeshouldbetheevaluationmetric.However,since
bugs are rather rare, the performance of fuzzers is often measured
incodecoverageovertime.This maybejustiﬁedbyobservations
thatmorecodecoveragecorrelateswithmorebugsfound[ 6].To
complementtheseprinciples,weproposethefollowingpractices
when evaluatingnovel machine learning-basedfuzzingmethods:
(1)Analyzeeachnewcomponentinthefuzzingloop. Both
performance evaluations and ablation studies of MLmodels
arecritical.Metricsspeciﬁctothetasksolvedshouldbeused
(e.g.,accuracy,orprecisionandrecallforclassiﬁcation,mean
absolute error or mean squared error for regression, etc.).
These complement the view on the overall system perfor-
mance,i.e.,coverageorbugsfoundinthecaseoffuzzing. ML
evaluation shouldemploya validationset distinctfromthe
training data to avoid an overly optimistic estimates [ 24].
(2)Usestate-of-the-artfuzzersandconﬁgurationsasbase-
lines.Lacking strong baselines prevents one from claiming
novelstate-of-the-artaccomplishmentsintermsofcodecov-
erageandbugsfound.Allfuzzersinanexperimentshould
be conﬁgured for performance (e.g., appropriate compiler,
compilation options, harness, input feeding mode). We also
recommendintroducingnewscientiﬁcortechnicalcontri-
butionsbasedonrecentfuzzersandevaluationplatforms,as
opposedto theiroldercounterparts.
(3)Usecomparablemetricsforfuzzingperformance. As
not all fuzzers measure the same type of coverage, we en-
couragetheuseofone commonevaluationmetricbetween
multiplefuzzers.Inpractice,thisiseasiestdonebyreplaying
thecorpusattheendofafuzzingtrial,asimplementedby
FuzzBench [ 3,33]andMLFuzz.
(4)Repeat trials often enough to account for variance. We
proposetouse30trialsforfuzzingevaluation,resultingin
tight conﬁdence intervals. This sample size is commonlyused in statistics and deemed suﬃcient for the central limit
theorem[ 9]tohold.Asshownin Figure4,ML-basedfuzzers
can have higher coverage variability than gray-box fuzzers,
thus requiring more trialsfor stable baselining.
(5)Ensurereproducibleresultsbyﬁxingandserializing
parameters. Whileitisdiﬃculttocontrolallsourcesofran-
domness when training MLmodels on GPUs, it remains a
goodpracticeinbothmachinelearningandsoftwaretesting
tocontrolpossiblesourcesofrandomnessbyseedingrandom
number generators and reusing the same seeds. Experimen-
talconﬁgurationsand,inthecaseof ML,hyperparameters
should be documentedfor reproducibility.
(6)Ensureusabilityofproposedfuzzers. Itshouldbe pos-
sible to run a newly proposed fuzzer on programs outside
the original publication study. Providing a containerized en-
vironment can sustainably decrease setup eﬀorts. We also
supportintegrationofnewfuzzerswithexistingbenchmark-
ingplatforms, such as FuzzBench andnowMLFuzz.
7 CONCLUSION AND CONSEQUENCES
Neural program smoothing for fuzzing neither reaches its adver-
tisedperformance,nordoesitsurpassolderfuzzingtechniquesthat
are still state-of-the-art. In our in-depth analysis of NPSfuzzers,
we analyzed conceptual limitations of previously published ap-
proaches, as well as implementation and evaluation issues. Our
comprehensive benchmark showed that NPS-guided fuzzers were
by far unable to reach their stated performance. Addressing the
implementationissuesdidnotsuﬃcetooutperformstate-of-the-art
gray-boxfuzzers.Thereasonforthelimitedfuzzingperformance
lies in the diﬃculty of the machine learning task, which yields
trivial models onthe data available duringfuzzing.
To guide future fuzzing research and practical validation, we
developedimprovedexperimentalguidelinestargetingfuzzingwith
machine learning. Our MLFuzz framework for ML-based fuzzers
includes patched and containerized versions of the investigated
fuzzers to help with additional benchmarking. We encourage re-
searcherstoperformablationstudiesandprovidedeeperinsights
intothe componentsthey introduce infuzzing.
While we highlight fundamentallimitationsof neural program
smoothing, whether and how much this technique can enhance
fuzzingremainsanopentopicforfutureresearch.Wehopethatthis
workcontributestofairandcomprehensiveevaluationsoffuture
fuzzers, be they ML-basedornot.
8 DATA AVAILABILITY
The open-source implementation of Neuzz++ and MLFuzz, the
evaluation setup,andraw results are available at
https://github.com/boschresearch/mlfuzz
https://github.com/boschresearch/neuzzplusplus .
ACKNOWLEDGEMENTS
ThanksareduetoJosselin Feistandthe anonymousreviewersfor
valuable discussions that have led to paper improvements. This
work was supported by the German Federal Ministry of Education
and Research (BMBF, project CPSec – 16KIS1565 and 16KIS1564K).
143ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA Maria-IrinaNicolae, MaxEisele, andAndreas Zeller
REFERENCES
[1]Martín Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen,
Craig Citro, Greg S. Corrado, Andy Davis, Jeﬀrey Dean, Matthieu Devin, San-
jay Ghemawat, Ian Goodfellow, Andrew Harp, Geoﬀrey Irving, Michael Isard,
YangqingJia,RafalJozefowicz,LukaszKaiser,ManjunathKudlur,JoshLevenberg,
DandelionMané,RajatMonga,SherryMoore,DerekMurray,ChrisOlah,Mike
Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul
Tucker,VincentVanhoucke,VijayVasudevan,FernandaViégas,OriolVinyals,
Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng.
2015. TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems.
https://www.tensorﬂow.org. Softwareavailable from tensorﬂow.org.
[2]Andrea Arcuri. 2010. It Does Matter How You Normalise the Branch Distance in
SearchBasedSoftwareTesting.In InternationalConferenceonSoftwareTesting,
Veriﬁcation and Validation . 205–214. https://doi.org/10.1109/ICST.2010.17
[3]DarioAsprone,JonathanMetzman,AbhishekArya,GiovaniGuizzo,andFederica
Sarro.2022. ComparingFuzzersonaLevelPlayingFieldwithFuzzBench.In IEEE
InternationalConferenceonSoftwareTesting,VeriﬁcationandValidation-Industry
(ICST Industry) .https://doi.org/10.1109/ICST53961.2022.00039
[4]Peter Auer, Nicolò Cesa-Bianchi, and Paul Fischer. 2002. Finite-time Analysis
of the Multiarmed Bandit Problem. Machine Learning 47, 2 (2002), 235–256.
https://link.springer.com/article/10.1023/A:1013689704352
[5]Jana Aydinbas. 2022. AFLplusplus Persistence Mode README.
https://github.com/AFLplusplus/AFLplusplus/blob/stable/instrumentation/
README.persistent_mode.md . Accessed:2023-05-10.
[6]Marcel Böhme, Laszlo Szekeres, and Jonathan Metzman. 2022. On the Reliability
ofCoverage-BasedFuzzerBenchmarking.In InternationalConferenceonSoftware
Engineering (ICSE) .http://seclab.cs.sunysb.edu/lszekeres/Papers/ICSE22.pdf
[7]Konstantin Böttinger, Patrice Godefroid, and Rishabh Singh. 2018. Deep Re-
inforcement Fuzzing. In IEEE Security and Privacy Workshops (SPW) . 116–122.
https://arxiv.org/abs/1801.04589
[8]Rich Caruana. 1997. Multitask Learning. Machine Learning 28 (1997), 41–75.
https://doi.org/10.1023/A:1007379606734
[9]Horng-JinhChang,Kuo-ChungHuang,andChao-HsienWu.2006.Determination
ofsamplesizeinusingcentrallimittheoremforWeibulldistribution. International
journalofinformation and managementsciences 17(2006), 31–46.
[10]SwaratChaudhuri,Sumit Gulwani,and RobertoLublinerman.2010. Continuity
Analysis of Programs. In ACM SIGPLAN-SIGACT Symposium on Principles of
ProgrammingLanguages(POPL) .57–70.https://doi.org/10.1145/1706299.1706308
[11]Swarat Chaudhuri and Armando Solar-Lezama. 2011. Smoothing a Program
Soundly and Robustly. In Computer Aided Veriﬁcation (CAV) .https://www.cs.
utexas.edu/~swarat/pubs/cav11.pdf
[12]Peng Chen and Hao Chen. 2018. Angora: Eﬃcient Fuzzing by Principled Search.
InIEEE Symposium on Security and Privacy (SP) .https://web.cs.ucdavis.edu/
~hchen/paper/chen2018angora.pdf
[13]YuanliangChen,YuJiang,FuchenMa,JieLiang,MingzheWang,ChijinZhou,Xun
Jiao,and Zhuo Su.2019. EnFuzz:EnsembleFuzzing with SeedSynchronization
amongDiverseFuzzers.In USENIXSecuritySymposium(USENIXSecurity) .https:
//www.usenix.org/system/ﬁles/sec19-chen-yuanliang.pdf
[14] AlbertDanial. 2021. cloc: v1.92 .https://doi.org/10.5281/zenodo.5760077
[15]Poetrydevelopers.2018. PythonPoetry. https://python-poetry.org . Accessed:
2022-10-20.
[16]William Drozd and Michael D. Wagner. 2018. FuzzerGym: A Competitive
Framework for Fuzzing and Learning. CoRR(2018). arXiv: 1807.07490 http:
//arxiv.org/abs/1807.07490
[17]Andrea Fioraldi, Dominik Maier, Heiko Eißfeldt, and Marc Heuse. [n.d.]. AFL++
best practices. https://aﬂplus.plus/docs/fuzzing_in_depth . Accessed: 2022-10-20.
[18]Andrea Fioraldi, DominikMaier,Heiko Eißfeldt,andMarc Heuse.2020. AFL++
:combiningincrementalstepsoffuzzingresearch.In USENIXWorkshoponOf-
fensive Technologies (WOOT) . USENIX Association. https://www.usenix.org/
conference/woot20/presentation/ﬁoraldi
[19]PatriceGodefroid,HilaPeleg,andRishabhSingh.2017. Learn&Fuzz:Machine
learningfor input fuzzing.In IEEE/ACM InternationalConference onAutomated
SoftwareEngineering (ASE) .https://doi.org/10.1109/ASE.2017.8115618
[20]Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-
Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative
AdversarialNets.In AdvancesinNeuralInformationProcessingSystems(NIPS) ,
Vol.27.CurranAssociates,Inc. https://proceedings.neurips.cc/paper/2014/ﬁle/
5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf
[21]Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. 2015. Explaining
andHarnessingAdversarialExamples.In InternationalConferenceonLearning
Representations (ICLR) .https://arxiv.org/abs/1412.6572
[22]Google. 2017. Fuzzer test suite. https://github.com/google/fuzzer-test-suite .
Accessed:2022-10-20.
[23]Google.2022. OSS-Fuzz. https://google.github.io/oss-fuzz/ . Accessed:2022-10-20.
[24]Trevor Hastie, Robert Tibshirani, and Jerome Friedman. 2009. The elements
of statistical learning: data mining, inference and prediction (2 ed.). Springer.
http://www-stat.stanford.edu/~tibs/ElemStatLearn/[25]ZhichengHu,JianqiShi,YanHongHuang,JiawenXiong,andXiangxingBu.2018.
GANFuzz: A GAN-Based Industrial Network Protocol Fuzzing Framework. In
ACM International Conference on Computing Frontiers . 138–145. https://doi.org/
10.1145/3203217.3203241
[26]Diederik P. Kingma and Jimmy Ba. 2015. Adam: A Method for Stochastic
Optimization. In International Conference on Learning Representations (ICLR) .
https://arxiv.org/abs/1412.6980
[27]GeorgeKlees,AndrewRuef,BenjiCooper,ShiyiWei,andMichaelHicks.2018.
Evaluating fuzz testing. In ACM SIGSAC Conference on Computer and Communi-
cations Security(CCS) . 2123–2138.
[28]Jun Li, Bodong Zhao, and Chao Zhang. 2018. Fuzzing: a survey. Cybersecurity 1,
1 (2018), 1–13.
[29]Xiao Liu, Xiaoting Li, Rupesh Prajapati, and Dinghao Wu. 2019. DeepFuzz:
Automatic Generation of Syntax Valid C Programs for Fuzz Testing, In AAAI
Conference on Artiﬁcial Intelligence (AAAI). AAAI Conference on Artiﬁcial
Intelligence 33,1044–1051. https://doi.org/10.1609/aaai.v33i01.33011044
[30]LLVM. 2022. libFuzzer - a libraryfor coverage-guided fuzz testing. https://llvm.
org/docs/LibFuzzer.html . Accessed:2022-10-20.
[31]Robert C. Martin and James O. Coplien. 2009. Clean code: a handbook
of agile software craftsmanship . Prentice Hall. https://archive.org/details/
cleancodehandboo00mart_843
[32]DirkMerkel. 2014. Docker:lightweightlinuxcontainersfor consistentdevelop-
mentand deployment. Linux journal 2014,239(2014), 2.
[33]Jonathan Metzman, László Szekeres, Laurent Maurice Romain Simon, Read Trev-
elin Sprabery, and Abhishek Arya. 2021. FuzzBench: An Open Fuzzer Bench-
marking Platform and Service. In ACM Joint Meeting on European Software Engi-
neeringConferenceandSymposiumontheFoundationsofSoftwareEngineering
(ESEC). Association forComputing Machinery, New York,NY, USA, 1393–1403.
https://doi.org/10.1145/3468264.3473932
[34]AdamPaszke,SamGross,FranciscoMassa,AdamLerer,JamesBradbury,Gre-
gory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga,
Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison,
AlykhanTejani,SasankChilamkurthy,BenoitSteiner,LuFang,JunjieBai,and
Soumith Chintala. 2019. PyTorch: An Imperative Style, High-Performance Deep
LearningLibrary. In AdvancesinNeuralInformationProcessingSystems(NeurIPS) ,
H. Wallach, H. Larochelle, A. Beygelzimer, F. d 'Alché-Buc, E. Fox, and R. Garnett
(Eds.).Curran Associates,Inc.,8024–8035. http://papers.neurips.cc/paper/9015-
pytorch-an-imperative-style-high-performance-deep-learning-library.pdf
[35]MohitRajpal,WilliamBlum,andRishabhSingh.2017. Notallbytesareequal:
Neural byte sievefor fuzzing. CoRR(2017).https://arxiv.org/abs/1711.04596
[36]Gary J. Saavedra, Kathryn N. Rodhouse, Daniel M. Dunlavy, and Philip W.
Kegelmeyer. 2019. A Review of Machine Learning Applications in Fuzzing.
CoRR(2019).https://arxiv.org/abs/1906.11133
[37]Konstantin Serebryany, Derek Bruening, Alexander Potapenko, and Dmitry
Vyukov. 2012. AddressSanitizer: A Fast Address Sanity Checker. In USENIX
ConferenceonAnnualTechnicalConference(USENIXATC) .https://dl.acm.org/
doi/10.5555/2342821.2342849
[38]DongdongShe,RahulKrishna,LuYan,SumanJana,andBaishakhiRay.2020. MT-
Fuzz: fuzzing with a multi-task neural network. In ACM Joint European Software
EngineeringConferenceandSymposiumontheFoundationsofSoftwareEngineering
(ESEC/FSE) .https://dl.acm.org/doi/pdf/10.1145/3368089.3409723
[39]DongdongShe,KexinPei,DaveEpstein,JunfengYang,BaishakhiRay,andSuman
Jana. 2019. NEUZZ:eﬃcient fuzzing with neural program smoothing. In IEEE
SymposiumonSecurityand Privacy (S&P) .https://arxiv.org/abs/1807.05620
[40]NickStephens,JohnGrosen,ChristopherSalls,AndrewDutcher,RuoyuWang,
JacopoCorbetta,YanShoshitaishvili,ChristopherKrügel,andGiovanniVigna.
2016. Driller: Augmenting Fuzzing Through Selective Symbolic Execution. In
NDSS.https://www.ndss-symposium.org/wp-content/uploads/2017/09/driller-
augmenting-fuzzing-through-selective-symbolic-execution.pdf
[41]Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014. Sequence to Sequence
LearningwithNeuralNetworks.In AdvancesinNeuralInformationProcessing
Systems(NIPS) ,Vol.27.CurranAssociates,Inc. https://proceedings.neurips.cc/
paper/2014/ﬁle/a14ac55a4f27472c5d894ec1c3c743d2-Paper.pdf
[42]JunjieWang,BihuanChen, LeiWei,and YangLiu. 2017. Skyﬁre: Data-Driven
Seed Generation for Fuzzing. In IEEE Symposium on Security and Privacy (SP) .
579–594. https://doi.org/10.1109/SP.2017.23
[43]Jinghan Wang, Yue Duan, Wei Song, Heng Yin, and Chengyu Song. 2019. Be
Sensitive and Collaborative: Analyzing Impact of Coverage Metrics in Grey-
boxFuzzing.In InternationalSymposiumonResearchinAttacks,Intrusionsand
Defenses (RAID2019) . USENIXAssociation, 1–15.
[44]YanWanga,Peng Jiaa,Luping Liub,and Jiayong Liu. 2019. Asystematicreview
of fuzzing based on machine learning techniques. CoRR(2019).https://arxiv.
org/abs/1908.01262
[45]MingyuanWu,LingJiang,JiahongXiang,YanweiHuang,HemingCui,Lingming
Zhang,andYuqunZhang.2022.OneFuzzingStrategytoRuleThemAll.In Interna-
tional Conference on Software Engineering (ICSE) . Association for Computing Ma-
chinery,NewYork,NY,USA,1634–1645. https://doi.org/10.1145/3510003.3510174
[46]MingyuanWu,LingJiang,JiahongXiang,YuqunZhang,GuoweiYang,Huixin
Ma,SenNie,ShiWu,HemingCui,andLingmingZhang.2022. Evaluatingand
144Revisiting Neural Program SmoothingforFuzzing ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
improving neural program-smoothing-based fuzzing. In International Conference
on Software Engineering (ICSE) .http://zhangyuqun.com/publications/icse2022a.
pdf
[47]ValentinWüstholzandMariaChristakis.2020. TargetedGreyboxFuzzingwith
Static Lookahead Analysis. In Proceedings of the ACM/IEEE 42nd International
Conference on Software Engineering . Association for Computing Machinery, New
York, NY, USA,789–800. https://doi.org/10.1145/3377811.3380388[48]InsuYun,SanghoLee,MengXu,YeongjinJang,andTaesooKim.2018. QSYM:
APracticalConcolicExecutionEngineTailoredforHybridFuzzing.In USENIX
Security Symposium (USENIX Security) . USENIX Association, 745–761. https:
//www.usenix.org/conference/usenixsecurity18/presentation/yun
[49] Michal Zalewski.2017. American fuzzylop. https://github.com/google/AFL .
Received 2023-02-02; accepted 2023-07-27
145