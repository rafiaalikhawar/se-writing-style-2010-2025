TransMap : Pinpointing Mistakes in Neural CodeTranslation
BoWang
bo_wang@u.nus.edu
National University ofSingapore
Singapore,SingaporeRuishi Li
liruishi@u.nus.edu
National University ofSingapore
Singapore,Singapore
MingkaiLi
t0927617@u.nus.edu
National University ofSingapore
Singapore,SingaporePrateek Saxena
prateeks@comp.nus.edu.sg
National University ofSingapore
Singapore,Singapore
ABSTRACT
Automated code translation between programming languages can
greatly reduce the human eﬀort needed in learning new languages
or in migrating code. Recent neural machine translation models,
such as Codex, have been shown to be eﬀective on many code
generation tasks including translation. However, code produced by
neural translators often has semantic mistakes. These mistakes are
diﬃculttoeliminatefromtheneuraltranslatoritselfbecausethe
translator isa black box, which isdiﬃcult to interpret or control
comparedtorule-basedtranspilers.Weproposetheﬁrstautomated
approachtopinpointsemanticmistakesincodeobtainedafterneu-
ralcodetranslation.Ourtechniquesareimplementedinaprototype
tool called TransMap whichtranslatesPythontoJavaScript, both
of which are popular scripting languages. On our created micro-
benchmarks of Python programs with 648semantic mistakes in
total,TransMap accurately pinpoints the correct location for a ﬁx
for87.96%,oftenhighlighting 1-2linesfortheusertoinspectper
mistake. We report on our experience in translating 5 Python li-
brarieswithupto 1/u1D458linesofcodewith TransMap .Ourpreliminary
user study suggests that TransMap can reduce the time for ﬁxing
semantic mistakes by around 70% compared to using a standard
IDE with debuggers.
CCSCONCEPTS
•Computingmethodologies →Machinetranslation ;•Soft-
ware andits engineering →Imperative languages .
KEYWORDS
Code Translation,Large LanguageModels,Semantic Mistakes
ACM Reference Format:
Bo Wang, Ruishi Li, Mingkai Li, and Prateek Saxena. 2023. TransMap :
Pinpointing Mistakes in Neural Code Translation. In Proceedings of the
31stACMJointEuropeanSoftwareEngineeringConferenceand Symposium
on the Foundations of Software Engineering (ESEC/FSE ’23), December 3–9,
2023, San Francisco, CA, USA. ACM, New York, NY, USA, 13pages.https:
//doi.org/10.1145/3611643.3616322
ESEC/FSE ’23, December 3–9, 2023, San Francisco, CA,USA
©2023 Copyright heldby theowner/author(s).
ACM ISBN 979-8-4007-0327-0/23/12.
https://doi.org/10.1145/3611643.36163221 INTRODUCTION
Automated code translation is the process of transforming code
fromoneprogramminglanguagetoanother.Suchtechniquescan
help developers express ideas in one language syntax and then
easilytransferthemtootherlanguageswithouttheencumbrance
of learning a new language syntax. Automatic code translation can
also lower the cost of migrating code bases from a legacy language
toamodern language[ 22]orfrom one platform to another[ 1].
Anewapproachtoprogrammigrationortranslationhasbecome
possiblebasedonneuralnetworkmodels[ 43,46,55].Thesetech-
niqueswereoriginallydevelopedfornaturallanguagegeneration
tasks[6,30,42]butalsoshowedpromisingresultsincode-related
tasks. For example, astate-of-the-art neural code generator Codex
[9] is ﬁne-tuned on a popular language model [ 30] and it backs
the AI pair programmer Copilot [ 20] in Visual Studio Code. It is
a general-purpose generative model trained on billions of lines
of code from public repositories. It has recently been utilized for
translatingcode between programming languages [ 4].
Neural code translation oﬀers a promising approach for mostly
automatic code translation. These translators are trained in an un-
supervised mannerfromexamplesonalargecorpus,savingmanual
eﬀort in devising translation rules. The translated code is often
natural-looking,unlikecompiler-generatedcode.Thisisbecause
neural code translators can capture the conventions seen in lots of
trainingdata derived from real code. Furthermore, state-of-the-art
neural translators are derived from large natural language models
and can take into account natural language hints like comments or
variable namingconventions duringtranslation.
In this work, our goal is to improve neural code translation
forcodewritteninscriptinglanguages.Wespeciﬁcallytargetthe
translationofPythonprogramstoJavaScript.Boththeselanguages
are popular and have many similarities being statically untyped,
andtherefore we believe oﬀeraconcrete startingpoint.
However, neural code translators can introduce errors in gener-
atedcode.Priorworkhasobservedthatcodeproducedfromneural
code generators can have syntax mistakes, operator precedence
errors,misuseofAPIs,incorrectdatatypes,andsoon[ 23,43].Mis-
takesareeithersyntacticorsemantic.Syntacticmistakesviolatethe
target language syntax and can be easily detected by syntax check-
ers.Semanticmistakes,ontheotherhand,canresultincodethat
does not executeor executes but outputswrong values. For many
of these, a ﬁx location is also not immediately visible from running
Thiswork islicensedunderaCreativeCommonsAttribution4.0Interna-
tional License.
999
ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA BoWang,Ruishi Li, MingkaiLi, andPrateek Saxena
Figure 1: An example of translated code from a neural code generator. The code contains 3translation mistakes: two semantic
mistakes andone syntax mistake. The gray and whiteshading isthe visualization of thesource map generated by TransMap .
tests or syntax checkers. We call such mistakes hidden. In micro-
benchmarks discussed later in Section 6,84.93%of all mistakes are
semantic, andmore thanhalfoftheseare hiddenmistakes.
Inthispaper,wethereforefocusontheproblemofautomatically
pinpointing hiddenmistakesinthetranslatedcode.Giventhesource
code,itstranslatedcodethatcontainssemanticmistakes,anderror-
triggeringtests,thegoalistoautomaticallyﬁndthepositionsinthe
translatedcodewheresmallmodiﬁcationsaresuﬃcienttoproduce
translated code that passes the tests. These pinpointed locations
serve as an aid to human programmers: They can focus on 1-2
lines of codeto ﬁx,instead of thewhole inputprogram. Whilewe
believe our techniques can be combined with upstream tasks such
as automated repair or test generation, we consider these analyses
as orthogonal and retain the human developer in the translation
loop,keeping withthe notionthat "theuserknowsbest".
The challenge in pinpointing hidden mistakes when working
with neural code generators is that their behaviour is diﬃcult to
interpretorexplain.Accesstostate-of-the-artmodelsisoftenblack-
box,andevenwithwhite-boxaccess,neuralnetworkswithbillions
ofparametersare challengingtoanalyze.Severalmechanismsde-
vised in the context of natural language translation tasks, from
which neural code translators are derived, donot necessarily lend
actionableinsightsforcodetranslationtasks.Forexample,theneu-
ral attention mechanism can identify which part of the input code
themodelconcentratesontoproduceanoutputsnippet[ 49],but
thissignalistoonoisyanddoesnotexplainwheretheerrorsare
introducediftheyare.Furthermore,littlemodiﬁcationinthesource
codeorthe decoding algorithms[ 58] of a modern neural generator
like Codex can result in unpredictable changes in the translated
code,makingthe processofpinpointing mistakesad-hoc.
A key technical diﬃculty in pinpointing translation mistakes
is that we have tests that run on two diﬀerent programs, one
written in the source language and the other in the target. This
setup is unlike that in fault localization [ 5,26,28,41,44,59] orrepair [17,18,21,34,57] which works with the same program.
Therefore, we propose to reconstruct a line-to-line mapping be-
tween the source and target program, analogous to "source maps"
producedbytraditionalcompilers.Suchmappingsallowustocom-
pareexecutiontracesrunonthesourceandtargetprogramsand
narrow down locations to focus on. Our solution requires only
black-boxaccesstotheneuralcodegeneratorandavoidsmaking
manycomputationallyexpensivequeriestoit.Thismakestheap-
proachcompatiblewithupdatesincodegeneratorsandlightweight.
It also avoids manually writing hard-coded rules for speciﬁc types
oftranslationmistakes,heavy-weightanalyses,orformallanguage
semantics. Our techniques are embodied in a prototype tool called
TransMap ,whichisshort for Translationwithsource Map.
We create a micro-benchmark for quantitative evaluation, de-
rivedfrom 3sourcesofrealPythonprograms:LeetCode[ 15],Hu-
manEvalX [ 10], and GeeksForGeeks benchmarks [ 43]. Each bench-
markcontainsPythonsourcecode,translatedJavaScriptcodeob-
tained from querying Codex, passing/failing tests, and manually
determined ﬁxes to all the translation mistakes suﬃcient to pass
thetests.Thereare648identiﬁedsemanticmistakeswithmanually
validatedﬁxesintotal.Weevaluate TransMap onourquantitative
benchmarksanditcansuccessfullypinpoint 87.96%ofallthe 648
semantic mistakes and 84.44%of all the hidden mistakes. The ﬁnal
reported position ranges by TransMap have an average length of
1.23lines, which highlights that the developer only needs to focus
theirattention onavery small range of the code to devise aﬁx.
Weconductapreliminaryuserstudytouse TransMap forde-
bugging code translations with diﬀerent lengths (10-200 lines) and
ﬁnd thatTransMap can save around 70% of the time for ﬁxing the
codecomparedtousinganindustry-standardIDE(VSCode[ 32])
with Python and JavaScript debuggers. Furthermore, we report on
aqualitativeexperiencebyauthorsinusing TransMap totranslate
5larger Pythonlibraries of about 120to1/u1D458linesof code.
1000TransMap : PinpointingMistakes in Neural Code Translation ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
2 PROBLEM OVERVIEW
We begin byshowing an example for whichCodex,astate-of-the-
art neural generator, produces a useful initial Python to JavaScript
translation.Ithasseveralmistakes,thelocationsofwhicharenot
straightforward to pinpoint by just running the given tests and ob-
serving theruntimeerrors.This motivatestheneedfor TransMap .
2.1 Motivating Example
The left part of Figure 1is an executable Python code that has
one function with a list as the input and returns an integer. The
rightpartistheJavaScriptcodetranslatedfromthePythoncode
byCodex.Therearesomecomplextasksduringthetranslationbut
Codexmanagestocorrectlytranslatethem.Firstly,thePythoncode
createsa defaultdict -typed1dictionaryandusesitonline5,line
7,andline10.AsJavaScriptdoesnothavetheequivalentbuilt-in
datatype, Codex translates the defaultdict datatype inPython
to theObjectdata type with a key-existence check before access,
e.g.,atlines7-9inJavaScript.Thistypeofcheckiscorrectlyomitted
in Codexoutput whenthekeyis presentin thedictionary, e.g.,at
lines 15-16. Secondly, the Python code has a list comprehension on
line10,whichdoesnotnativelyexistinJavaScript.Codextranslates
the list comprehension into statements with the same semantics: a
forloopinJavaScriptatlines14-17.Thirdly,PythonAPIs,suchas
len(arr) ,sum(..),anddatatypeoperations,suchas arr[-1],
are correctly translated into arr.length ,arr.reduce(...) , and
arr[arr.length - 1] inJavaScript.
While Codex translates most parts of the code correctly, the full
translatedcodeisnotsyntacticallycorrect—asyntaxcheckercan
discover a syntax mistake on line 23. Even if the syntax mistake
is ﬁxed,thetranslatedcodestilloutputs diﬀerentresultsfromthe
sourceunder thesametestcases.Acarefulreader willnoticethat
there are at least two other semantic mistakes, for which small
modiﬁcationstotheJavaScriptcodearesuﬃcienttomakeitcorrect.
The3mistakeshighlightedinFigure 1are as follows:
•SyntacticMistake1 :theif-else toencodea ternaryexpres-
sionviolatesJavaScriptsyntaxonline23.Thecorrecttranslation
isreturn max_conn==-1 ? -1 : avg_conn-max_conn; .
•Semantic Mistake 1 : thearr.sort() has diﬀerent seman-
tics inPythonandJavaScript. The correspondingPythoncode
arr.sort() online11sorts arrinascendingnumericalorder
whereas line 18 of JavaScript sorts elements alphabetically as
strings. For example, the sort of an array [2, 11, 5] will re-
turn[2, 5, 11] afterexecuting line10 ofthe Pythoncodeand
[11, 2, 5] afterexecutingline18oftheJavaScriptcode.The
correcttranslatedcode should be arr.sort((a,b)=> a-b); .
•SemanticMistake2 :the/operationinJavascripthasadiﬀerent
meaningwith //operationinPython.Line15ofPythoncode
meansintegerdivision,e.g., 12//5 = 2 butline21ofJavaScript
code is ﬂoating point division, e.g., 12/5 = 2.4 . The correct
translatedcode should be avg_conn = Math.floor(../..); .
Figure2brieﬂysummarizesourevaluationonmorebenchmarks
presented later in Secion 6.1. We ﬁnd that 84.93%of all mistakes
are semantic among which more than half are hidden mistakes.
For such mistakes, running the program either throws no runtime
1Itprovides a default valuefor non-existingkeys, insteadof raising errors.
Figure2:Distributionoftranslationmistakesinourmicro-
benchmarks presented later inSection 6.1.
errors but produces wrong output values, or it throws runtime
errors but the error locations are not where the right ﬁx is needed.
2.2 ProblemSetup andChallenges
Inoursetup,wearegiventhesourceandtargetprogramsgener-
ated from the black-box neural generator, together with unit tests.
It is straightforward to translate test inputs and outputs across
languages; therefore, assume the availability of such tests. Tests
under which the outputs of the source and target programs are the
samearedeemedas passing,whereasthoseonwhichtheydiﬀerare
deemedas failing.Ourgoalistopinpointlocationsinthetranslated
code where ﬁxes are suﬃcient to have allgiven test casespass.
Black-box neural code generators are neither explainable nor
stable to input perturbations. Unlike compilers of which the behav-
iors can be explained in deterministic transpilation rules, neural
code generators can introduce unpredictable changes in the output
on small changes in input. For instance, Codex can produce totally
diﬀerentresultsandmistakesforthesameinputevenwithsmall
changes in its auxiliary inputs, such as in sampling methods or
samplingtemperatures.Expressingthebehaviorofthegenerator
indeterministic rulesfor further analysisisdiﬃcult.
Another challenge comes from the complexity of the context-
dependentsemanticsofstatementsintheprogram.Forexample,in
untypedlanguagessuchasPythonandJavaScript,thesemanticsofa
statementmaydependontypesandpossiblevaluerangesofrelated
variables, and how a piece of code should be translated would also
depend on the earlier translation of related variables. For example,
while line 7 of Python ( g[u - 1].append(...) ) is semantically
equivalenttolines7-10inJavaScript,suchequivalenceisunderthe
context that g’s data type is mapped from defaultdict (Python)
toObject(JavaScript), and the value of uin JavaScript is equal
tou - 1in Python due to the translation at line 4. If gwere
adictin Python and uwere translated to represent the same
value,g[u-1].append(...) in Python would be equivalent to
g[u-1].push(...) inJavaScriptinsteadoflines7-10.Onepossible
solutiontothischallengeisto modelsharedsemanticsacrossthe
twolanguageswithcontextawareness.But,suchspeciﬁcationsare
labor-intensive andchangeas the concernedlanguagesevolve.
Inthispaper,weaimtoprovidean automaticandlightweight
proceduretopinpointsemanticmistakesinneuralcodetranslation
that is largely agnostic to the internals of the neural generator.
The fewer the pinpointed locations, the better—we hope the user’s
attention can be drawn to as fewlocations to ﬁxas possible.
Our solution works on the following key principle: Rather than
trying to reconstructexternally whythe generatorproduces a cer-
tain output, we simply ask the neural code generator to explain
itself,i.e.,toproduceamappingbetweenthesourcecodeandits
1001ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA BoWang,Ruishi Li, MingkaiLi, andPrateek Saxena
Figure3:Workﬂowof TransMap topinpointandﬁxthetrans-
lationmistakes. TransMap hastwokeycomponents:theneu-
ral source map generator andthetrace comparator.
owntranslatedcodeinaformatwedesigned.Weshowthatsuch
mapping,coupledwithanexecutiontracecomparisontechnique,
can automaticallypinpointmistakeswithhigh ﬁdelity.
3TRANSMAP :OVERVIEW
Figure3showstheworkﬂowof TransMap thatworksinaloopwith
a userto pinpoint andﬁx the translationmistakes. The translated
codeispre-translatedbytheneuralcodegeneratorfromthesource
and they form a code pair. ①The code pair is given as input to our
neural source map generator to generate its source map. Given the
codepair,itssourcemap,andtheunittestsofthesourceandthe
translated code, the trace comparator reports the location of the
ﬁrstsemanticmistakeinthetranslatedcodetotheuser. ②Theuser
ﬁxesthetranslatedcodebasedonthemistakereportof TransMap .
If the ﬁxed code does not pass the unit tests, it means that the
translation has other semantic mistakes. Thus, the translated code
would be updated ( ③)andthenextiteration ofthis processwould
start from ①to pinpoint the next mistake. The process stops when
the translatedcode has nomistakesremaining, i.e.,alltests pass.
Source Map Generation. The ﬁrst component in TransMap gen-
erates the source map, a line-to-line mapping between the given
source and translated code pair. Source map creation is standard
incompiler-basedtranslators[ 33,51],butithasnotbeendemon-
stratedforneuralcodetranslationyet,tothebestofourknowledge.
Our main insight to solving this challenge is that we can ask the
neural code generator to explain itself. We propose a pre-designed
prompttoguide theneural codegeneratorto outputthemapping.
Our observation stems from the in-context learning capability of
manymodernlargetransformer-basedgenerativemodels[ 6,7,45],
which allows the model to learn a new task from only a few ex-
amples providedas“prompts”[ 6].We callthem promptexamples .
In-context learningdoes not needto change the generative model
andonlyrequiresblack-boxaccesstoit.Foroursourcemapping
task, the in-context learning prompt starts with a ﬁxedprompt
example of the mapping task that we designed, followed by the
pair ofprograms(/u1D446,/u1D447)for whichwe want to create a sourcemap.
Our ﬁxed prompt example has a hard-coded pair of source and
target programs and the corresponding source map between themFigure4:One-shotin-contextlearningprompttemplate(part
AandB) forsource map generationand its output(part C).
created manually.This example essentially illustrates or “teaches”
the model how to create a source map. When we provide this ﬁxed
prompt example, together with the programs given as input to
TransMap(/u1D446,/u1D447)totheneuralcodegenerator,itmimicsthetask
demonstratedintheﬁxedpromptexampleon (/u1D446,/u1D447).Figure4brieﬂy
shows the prompt template and Section 4.1details the mechanism.
Onemaynaturallyaskwhydoesthisapproachtosourcemap
generationwork.Theexplanationstemsfromwhyin-contextlearn-
ing works [ 60]: in-context learning succeeds when the neural net-
work model is able to infer some shared latent concepts in the
1002TransMap : PinpointingMistakes in Neural Code Translation ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
providedpromptexamples.Thelatentconceptlearntfortransla-
tion is the mapping between semantically similar statements in
the two languages. Such latent concepts, if learnt for translation,
should alsobe abletoprovidesourcelinemaps.The ﬁxedprompt
exampleteachesthemodelhowtoexplicitlyrepresentitinoutputs.
When designing the prompt, computational costs become a bot-
tleneck. While in-context learning works better with more prompt
examples, the computational cost of the attention mechanism in
moderntransformer-basedneuralcodegeneratorsincreasesnon-
linearlywithpromptlength.Themodeltakeslongertotranslate
longerinputsandtherefore,themodelqueryinterfacelimitsthe
number of lexical tokens. For example, Codex can only process 8/u1D458
tokens per query at most for the prompt plus the generated text.
Toreducethelengthofthepromptandsavemoretokensforthe
generatedsourcemap,we only use one ﬁxedprompt example.
With a single prompt example, we cannot “teach” very complex
taskstoneuralcodegeneratorssincetheirlimitedreasoningand
arithmetic computation capability come into play [ 14]. Thus, even
though our prompt example is short, it is empirically selected to
minimizeambiguityinthesourcemappingtask—itonlyrequires
the neural code generator to copy existing code and annotations to
showthelinecorrespondence,withoutgeneratinganynewcode
or performing complex arithmetic computations. Additionally, we
alsosetthe samplingtemperature to 0since thetaskrequiresno
creativity[ 36].Withthesedesignchoices,weempiricallyobserve
that the noise in the generated source maps is quite low, as shown
in Section 6.2. Figure1visualizes the source map automatically
generatedusing our approach withwhite andgray shading.
Trace Comparison. After we get the source map, the next step
inTransMap is to execute the source and target programs with
the given test inputs, which results in execution traces. TransMap
comparestheseexecutiontracestopinpointalocationwherethe
executionstates,i.e.,valuesoftracedprogramvariables, diﬀer.A
simplisticapproachtotracecomparisonwouldbetotracethesource
and translated program statement by statement. This approach
leadstoalargeamountoftracedata.Furthermore,theintermediate
states at eachindividual statement inalarger block ofstatements
canturnouttobediﬀerentbetweenthesourceandtargettraces,
while still producing the same output at the end of the block. As an
example,afterline14inJavaScript,thevariable arrisboundtoan
emptyarray,but arrisneveremptyinPython.However,thevalue
ofarrischangedmultipletimesbeforeline17whereitﬁnallyhas
the same valueas inPythonafter line10.
We can improve the above simplistic approach by using our
sourcemap.Thesourcemapgivesus(possiblynoisy)line-to-line
mappingwhichisanaturalsegmentationintheprogramstoper-
form comparisons. Code segments which cannot be sub-divided
basedonthesourcemaparecalled atomicpieces .Wecannowrecord
and compare program states between corresponding atomic pieces
ofthesourceandthetranslatedcode.However,thisnaiveapproach
can identifyspuriouslocations to inspect.
Toillustratewhy,considerthetranslationexampleinFigure 1
again.Letusassumethatthesyntaxerroronline23hasbeenﬁxed
by the userso that onlysemantic mistakes remain. Ifwe trace per
atomicpiece,wewillinsertapairoftracepointsbetweenline6and
line 7 in both Python and JavaSript. The Line 7 of the Python codemaps to lines 7-9 of the JavaScript code, but the program values
diﬀer—variable uon the Python side is not equal to the variable
uon the JavaScript side, and that is because the translated code is
assigning times[i][0]-1 rather than times[i][0] tou. Thus,
the naive approach would report a trace discrepancy at lines 3-6 as
variables uandvhavediﬀerentvaluesunderalmostallexecutions.
However, if we carefully inspect the behavior of the whole loop,
lines3-6areunnecessarytoinspectandwouldwasteuserattention.
This is because lines 7-10 in the translated code consistently use u
instead of u-1,sothe valuesof local variables after the combined
code block (lines 3-10) produce the same result as the Python code.
Further, thisapproachcreates large traces, as trace lengthgrows
withalgorithmic complexityof the code (e.g.,withnestedloops).
Weproposeasimplesolutionwecall dynamicgranularitytracing
toaddressthischallenge.Dynamicgranularitytracingcompares
executionstatesattheboundarieswherethesemanticsofthesource
and the translated code reach an agreement, hoping to skip past
diﬀerences in intermediate states. The intuition is to mimic the
debugging process of a programmer to some extent where the
granularityof“breakpoints”isincreasediterativelywhileweare
gettingcloserandclosertotheexactpositionofthemistake.For
example, on the translation in Figure 1, the tracing starts with
statements in the function scope at ﬁrst to trace the program at
lines 5, 6, 9, etc. of Python and 2, 3, 12, etc. of JavaScript. Notice
that it will not trace inside the ﬁrst for loop but only compare
theprogramstatesbeforeandafterit.Thus,thetracecomparator
concludesthattheﬁrst forloopiscorrectandmovesontospot
mistake 1 at line 18. Once the user ﬁxes that, it will report mistake
2 which is in a deeper block scope. The translation passes all tests
after mistake2isﬁxedbythe userinour example.
4TRANSMAP :COMPONENTS
Two main components of TransMap , the source map generator
andtracecomparator,worktogethertopinpointlocationswhere
the usercan focustheirattention.
4.1 SourceMapGenerator
Given the source and the translated code (/u1D446,/u1D447)by the neural code
generator, the goal of the source map generator is to output a map-
pingbetweenatomicpiecesinthesourceand the translated code.
Anatomicpieceisatuple (/u1D434[ℓ/u1D460],/u1D434[ℓ/u1D461]),where/u1D434[ℓ/u1D460]and/u1D434[ℓ/u1D461]are
ordered lists ofstatements correspondingto theline number ℓ/u1D460in
thesourceprogram and ℓ/u1D461inthetranslatedprogram, respectively.
Thesourcemap isan orderedlistof atomicpieces.
Asbrieﬂyexplained,weusein-contextlearningwithprompts
to the neural code generator for creating source maps. Figure 4
shows the prompt template that is used for all input programs.
Conceptually,this promptcanbedividedintotwoparts.Theﬁrst
part is aﬁxedpair of code fragments that is used to demonstrate
the task of creating source maps. Speciﬁcally, it has a ﬁxed Python
codeanditsJavaScriptequivalentwiththesourcemapannotations
in comments, as seen in Figure 4, part A. This is the “one-shot”
example of the task we want to teach the generator to perform [ 6].
Note that part A of the prompt does not change for diﬀerent (/u1D446,/u1D447).
The second part of the prompt template consists of the given
Pythonsourceprogram /u1D446andthegivenJavaScripttranslatedcode /u1D447,
1003ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA BoWang,Ruishi Li, MingkaiLi, andPrateek Saxena
butwithoutanysourcemapannotations.Theneuralcodegenerator
is expected to learn how to perform the task demonstrated by
partAoftheprompttemplateandauto-completeit.Theprompt
completion if successfully done, would copy the programs (/u1D446,/u1D447)
andaddannotationstothemwhichserveasthesourcemapping.
The output section of Figure 4shows the part completed by the
neural code generator. It can be seen that the model has added
code comments line-by-line to both the Python program /u1D446and
JavaScript program /u1D447providedto itinpart B of the template. From
this output it is straightforward to parse the programs, create a list
ofstatementscorrespondingtoeachlinenumberspeciﬁedinthe
comments, andobtain the sourcemap.
Inordertoarriveatthisspeciﬁcprompttemplate,weperformed
promptengineeringempiricallyoftwokinds:promptparaphras-
ing [25] and prompt scoring [ 13]. For prompt paraphrasing, we
mutated both the source mapping instruction ( ##### Match ... )
and the comments before statement numbers ( --- py stmt ) to
create prompt variations to select from. They are highlighted in
greeninFigure 4.Wetried 32variationsonlysinceeachqueryto
the code generatorincurs acost.
We then compared prompt variations using prompt scoring[ 13].
We deﬁne the score of a prompt output as the log probability of
ﬁlling all the statement numbers correctly (red circles in Figure 4).
Speciﬁcally, let /u1D436/u1D456=1be the event that the /u1D456/u1D461ℎstatement in the
output is correctly mapped (else /u1D436/u1D456=0), then we are interested
intheeventthatall /u1D436/u1D456equalto1.Thescore /u1D439(/u1D443,/u1D44B)foraprompt
variation /u1D443onaspeciﬁc sourcemapexample /u1D44Biscomputedas:
/u1D439(/u1D443,/u1D44B)=logPr/bracketleftBig/parenleftBig/productdisplay.1
/u1D456C/u1D456/parenrightBig
=1/bracketrightBig
=log/productdisplay.1
/u1D456Pr/bracketleftBig
C/u1D456=1|/parenleftBig/productdisplay.1
/u1D457</u1D456C/u1D457/parenrightBig
=1/bracketrightBig
(chain rule)
=/summationdisplay.1
/u1D456logPr/bracketleftBig
C/u1D456=1|/parenleftBig/productdisplay.1
/u1D457</u1D456C/u1D457/parenrightBig
=1/bracketrightBig
=/summationdisplay.1
/u1D456token_logprob(/u1D441/u1D456,full_correct_output )
Thequantitiesinthelaststepareprovidedbytheneuralcode
generatorand /u1D441/u1D456isthe/u1D456/u1D461ℎstatementnumbertoken.Multiplevalues
token_logprob(token, output) for the same outputcan be ob-
tainedfromasinglequerytoCodex.Wetesteachofthe 32prompt
variationson 10distinctsourcemapexamplesthatwemanuallycre-
ated for validation. For each source map example, we obtain scores
for all prompt variations. For each example /u1D44B/u1D461, we compute the
ranking of candidate /u1D443/u1D458asRank(/u1D443/u1D458,/u1D44B/u1D461)where higher /u1D439(/u1D443/u1D458,/u1D44B/u1D461)is
better. We choose the prompt with the highest average rank across
the10sourcemapexamples, computedas1
10/summationtext.110
/u1D461=1Rank(/u1D443/u1D458,/u1D44B/u1D461).
4.2 TraceComparator
Oncewehavethesourcemap,thetracecomparatorinstrumentsthe
two given programs (/u1D446,/u1D447). It then runs the test cases on them and
comparestheirexecutiontraces.Forexecutiontracing,bothpro-
grams(/u1D446,/u1D447)are instrumented with 2kinds of logging: tracepoints
andline coverage . The tracepoint instrumentation logs program
statesatthebeginningstatementofeachatomicpiece.Thetrace-
point is thus a 3-tuple (ℓ/u1D460,ℓ/u1D461,/u1D451), whereℓ/u1D460is the line number of the
ﬁrstsourcestatementofanatomicpiece, ℓ/u1D461isthelinenumberof
the ﬁrst target statement of the same atomic piece, and /u1D451is theAlgorithm1 DynamicGranularityTracingAlgorithm
1:procedure DynamicGranularityTracing (/u1D443/u1D461,/u1D443/u1D460,/u1D440,/u1D447,L/u1D45A/u1D44E/u1D465)
2:L←1 ⊲Listhe currenttracing level
3:/u1D446/u1D460←{1,2,...#Line(/u1D443/u1D460)},/u1D446/u1D461←{1,2,...#Line(/u1D443/u1D461)}
4:whileL≤L/u1D45A/u1D44E/u1D465do
5: /u1D447′=Filter(/u1D447, /u1D465→/u1D465./u1D459≤L∧/u1D465./u1D460∈/u1D446/u1D460∧/u1D465./u1D461∈/u1D446/u1D461)
6:(Γ/u1D460,Γ/u1D461)←RunCollectTrace (/u1D443/u1D461,/u1D443/u1D460,/u1D447′)
7: /u1D458←FindDivergingStep (Γ/u1D460,Γ/u1D461)
8: if/u1D458isNonethen
9: return∅,∅⊲Nodivergence,code iscorrect
10: /u1D436/u1D460←GetCoveredLinesInBetween (Γ/u1D460,/u1D458−1,/u1D458)
11: /u1D436/u1D461←GetCoveredLinesInBetween (Γ/u1D461,/u1D458−1,/u1D458)
12: /u1D436′
/u1D461←MapSrcLinesToTgt (/u1D440,/u1D436/u1D460),
13: /u1D436′/u1D460←MapTgtLinesToSrc (/u1D440,/u1D436/u1D461),
14: /u1D446/u1D461←/u1D436/u1D461∪/u1D436′
/u1D461,/u1D446/u1D460←/u1D436/u1D460∪/u1D436′/u1D460
15: L=L+1 ⊲Increasetracing level
16:return/u1D446/u1D460,/u1D446/u1D461⊲Suspicious lines(sourceandtarget)
levelofthetracepoint.Thelevelofthetracepointisitslexicalscope
depthandalllocalvariablesaccessibleinthatscopearelogged.For
example, line 7 in Python is at level 2and line 3 is at the lowest
level0(globalscope).Foratracepointtobevalid,thescopelevel
forthesourcestatementandthetargetstatementareexpectedto
be the same—if not, we do not trace thosestatements.
The instrumented logging statements before each tracepoint
recordalllocalvariablesaccessibleinthatscopeandtheirvalues.
However,thisisnotsuﬃcienttoknowthesetofexecutedlinesafter
hittingonetracepointandbeforehittinganother.Theexecutedlines
inbetweenarenotnecessarilythecodebetweentwotracepoints
duetocontrol-ﬂowtransitionstatementsuchas break,continue ,
andthrow. We therefore use line coverage instrumentation to get
allthe executedlinesinbetween, andhence the controlﬂow.
Afterthecodeinstrumentation,weobtainapairofinstrumented
programs that are executed under given tests. As brieﬂy discussed
earlier in Section 3, we employ dynamic granularity tracing to
minimize spurious locations being reported to the user. Our pro-
posed algorithm for such dynamic granularity tracing and trace
comparison is showninAlgorithm 1. It performsmultiplerounds
of tracing on instrumented programs, with each round increasing
thetracinggranularity.Linecoverageinformationissmallandis
alwaysturnedon.
The input to Algorithm 1includes the instrumented source pro-
gram/u1D443/u1D460,theinstrumentedtranslatedprogram /u1D443/u1D461,thesource map
/u1D440,staticmetadata /u1D447forselectivelyturningtracepointsonoroﬀ,
andthe maximum tracing level /u1D43F/u1D45A/u1D44E/u1D465.
Speciﬁcally,intheveryﬁrstround,thealgorithmstartsattracing
level1(/u1D43F=1) with all the lines marked “suspicious”, i.e., the set of
suspiciouslines /u1D44B/u1D460and/u1D44B/u1D461areinitializedtoalllinesintheprograms
(lines2-3inAlgorithm 1).Inthisround,allthetracepointsatlevel1
areenabledforloggingbuttracepointsathigherlevelsaredisabled
(checked in line 5). For example, this means all local variables at
functionscopearetracedinJavaScript.Thetracingisperformedby
running the instrumented program on unit tests and collecting the
logs. The enabled tracepoints in the program will record program
states tologs (line 6).Thetrace logs, represented by Γ/u1D460andΓ/u1D461,are
1004TransMap : PinpointingMistakes in Neural Code Translation ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
sequences of log items where each log entry item consists of the
tracepoint index and values of local variables. The trace logs Γ/u1D460
andΓ/u1D461will then be compared step by step. If no mismatch is found
in the traces, it implies that the programs behave the same thus
the algorithm halts. Otherwise, the algorithm will ﬁnd the ﬁrst
mismatchinglogitemanditscorrespondingdivergingtracepoint
(line7). It then obtains the executed lines between the diverging
tracepointandtheprevioustracepointwheretheprogramstates
have not diverged from the line coverage information (line 10).
Onlythoselinesarenowmarkedsuspicious,therefore,theupdated
/u1D44B/u1D460and/u1D44B/u1D461arereduced.Thisﬁnishesoneroundoftracingandthe
algorithm goes on to perform the next round of tracing with an
increased tracing level 2 (line 15). In the round with tracing level 2,
allthetracepointsoutsideofthesuspiciouslinesetwillbedisabled.
For tracepoints that are still within the reduced suspicious lines
set, tracepoints up to level 2 will be enabled (line 5). The second
round of tracing can further reduce the set of suspicious lines with
more tracepoints concentrated around the unknown mistake. This
processrepeatsuntilthemaximumtracinglevelisreached,andthe
ﬁnal setsofsuspiciouslinesare returnedas the result (line 16).
When deciding if the source and translated code diverge at one
tracepoint, we resort to the notion observational equivalence (up to
the given tests)rather thansemantic equivalence.We log the data
types to their canonical forms and compare the canonical forms
instead of the original data types. The idea is to project various
data types into a minimum set of simplest data types. For example,
List,Array,Deque, and other similar data typescan be mapped
toJSONarray. int,float,andothernumerictypescanbemapped
to JSON number. This tracing and comparison process does lose
some information, but it reconciles the diﬀerence in data types
acrossthesourceandtargetlanguages.Whileourtracingandvalue
comparator implementation has been suﬃcient for our reported
evaluation, itcan be improvedinfuture versionsof TransMap .
5 IMPLEMENTATION
TransMap usesCodexastheneuralcodegeneratorwiththetrans-
lation prompt shown in Figure 5. It starts with a ﬁxed pair of mini-
malistic code fragments that demonstrate the translation task. The
nextpartisthegivenPythonsourcecodethatneedstobetranslated
(left-bottom).Theneuralcodegeneratorcompletesthepromptwith
translatedJavaScript code (right-bottom) as the output.
ThesourcemapgeneratorqueriesCodexforthesourcemapand
weusethestandardgreedydecodingwiththetemperaturesetto
0 and/u1D45Dto 1.It parses the generated text from Codex to compute
atomic pieces. It assumes that every line in the translation belongs
to some atomic piece and that the atomic pieces order the line
numbers in Python source and the JavaScript target in the same
order, withnodiscontinued atomicpiecethat ismixedwith other
atomic pieces. This assumption enables simpler implementation
for our trace comparator andempirically it is satisﬁed most of the
time. The source map generator will abort if it cannot output a
valid source map. When updated programs (/u1D446,/u1D447)are processed,
onlyfewlinesareupdatedandsotheupdatedsourcemapcanbe
computedfrom cachedsourcemapswithoutqueryingCodex.
Thetracecomparatorisimplementedassource-levelcodeinstru-
mentationandoﬄine analysisontraceﬁles. Theinstrumentation
Figure5:One-shotpromptfor theneuralcodegeneratorto
translate Python codeinto JavaScript code.
requires simple static analysis to get the list of local variables at
the position of each tracepoint. Thisis implementedwiththe help
of tree-sitter [ 50] AST queries and Python’s built-in support for
reﬂection at runtime(e.g. local()).
TransMap reports the suspicious lines as given by Algorithm 7
and the variables with diverging values. The trace implementa-
tion includes runtime type information which is considered during
value comparisons2. When a trace mismatch is found, TransMap
provides both the suspicious variable and the “Jump-to-deﬁnition”
utilitytotheuser.Theusercanﬁxthevariabletypedeclaration,its
type deﬁnition,orits use at the suspiciouslines.
Intotal,TransMap isimplementedinaround 5/u1D458linesofPython
andJavaScriptandanother 5/u1D458linesofUIcodeforeasierinteraction.
6 EVALUATION
We evaluate TransMap for identifying mistakes in neural code
translationfromPythontoJavaScript.Ourevaluationfocuseson
the following fouraspects:
(1)Motivation (Section 6.1):What kinds of translation mis-
takes does Codex make for which TransMap isof value?
(2)Eﬀectiveness (Section 6.2):How eﬀective is TransMap at
pinpointing translation mistakes?
(3)CaseStudy(Section 6.3)Howmuchhumaneﬀortdoesit
take to translate real-world programs using TransMap ?
(4)User Study (Section 6.4)How helpful is TransMap for
usersto pinpointandﬁxthe translation mistakes?
Micro-benchmarksforPinpointingNeuralTranslationMis-
takes.Pinpointingmistakesinneuralcodetranslationacrosslan-
guages is relatively new. We thus created a set of benchmarks that
extendsthoseusedinrecentworks[ 52].Eachsampleprogramin
the micro-benchmarks contains the following:
•sourceprogram,
•aneuraltranslatedprogram from Codex withmistakes,
•test casesfor the sourceandtranslatedcode,
•alistofmistakesinthe code withlinelocations andﬁxes,
•the ﬁxedtranslatedprogram that passesthe tests.
2Similartypeslikearray,queue,andlistareclusteredasthesame“simpletype”for
comparisonsin ourimplementation.
1005ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA BoWang,Ruishi Li, MingkaiLi, andPrateek Saxena
Wecreateourmicro-benchmarksbasedon 3popularbenchmarks
on code related tasks: LeetCode Python-to-JS benchmarks ( 1067
programs)[ 52],GeeksForGeeksbenchmarks( 699programs)[ 43],
and HumanEvalX benchmarks ( 164programs) [ 10]. Taking the
LeetCode benchmarks as an example, the process to create our
micro-benchmarks is shown below. First, we query Codex to trans-
lateallprogramsintheLeetCodebenchmarksintoJavaScriptusing
thetranslation promptinFigure 5. Theprovided testcasesfor the
source programs are simple, thus we obtained their corresponding
versions for translated code using straightforward string substi-
tution. Next, we run the translated code on unit tests and collect
thefailingprograms.Thisgivesus 424programs.Thenwemanu-
ally check these failing programs and ﬁlter out those ( 132of them)
where the translated code is either unﬁxable or not corresponding
to the source at all. We consider a program as unﬁxable if com-
pletely rewriting it or implementing non-existing functions and
data types used by the translation is necessary to make it pass the
tests. Further discussion on these is presented in Section 6.5. After
the ﬁltering, we manually check the remaining 292programs, pin-
pointtheirmistakes,andwriteaﬁxforeachmistake.Intheend,we
validate459mistakesfrom 292programsonLeetCodebenchmarks.
Similarly, we collect 235mistakes from 136programs on Geeks-
ForGeeksbenchmarksand 69mistakesfrom 51programsonHu-
manEvalX benchmarks. In total, we have 479programs and 763
mistakes with ﬁxes ( 115syntax mistakes and 648semantic mis-
takes). The translated programs are about 17.53lines on average
as shown in column /u1D434/u1D43F/u1D436/u1D457/u1D460of Table1and the longest program has
66lines.Thedetailedcharacteristicsofthemicro-benchmarksare
providedinthe supplementary materials[ 2].
EvaluationMetrics. Toevaluatetheeﬀectivenessof TransMap ,
we check if TransMap can pinpoint the semantic mistakes in our
micro-benchmarks. For the program with more than one semantic
mistake, we generate its partially-ﬁxed variant programs in which
only one semantic mistake exists. This gives us as many variant
programs as semantic errors in this program. We look at the suspi-
cious lines highlighted at the end. If the suspicious lines contain
themistake,wecountitassuccessful.Wealsocomputetheaverage
numberofsuspiciouslinesthattheuserneedstoinspect,aswellas
theaverageratiobetweenthesuspiciouslinesandthetotallinesin
the program.
Baseline. The baseline approach is simply to run the given unit
tests without TransMap . If a runtime error appears, we check if
that line number is the location where the ﬁx is needed. If not,
it is counted as a failure. Note that for hidden mistakes, where
programstatesdiﬀerbutnoruntimeerrorsarethrown,thebaseline
approach cannotpinpointthem.
System Speciﬁcation. We runall experiments ona desktopwith
32GB of RAM and an i7 9700 8-Core CPU. To query the Codex
modelforgeneratingtranslationsandsourcemaps,wedirectlyuse
OpenAIAPI withoutlocal computation[ 37].
6.1Quantifying Mistakes in Codex Translations
It is useful to understand thekind of errors made by Codex before
wecanquantifywhere TransMap providesmostvalue.Figure 6
shows the distribution of all the 763translation mistakes in all our45.61%
0.52%
22.67%16.12%12.45%2.62%
84.93%15.07%Different Result
Other Runtime Error
Runtime Reference Error
Runtime Type Error
Confused Syntax
Minor Syntax Mistake
Semantic Mistakes
Syntax Mistakes
Figure 6: Distribution of mistakes in our micro-benchmarks
micro-benchmarks. Among them, syntax mistakes and semantic
mistakesaccount for 15.07%(115) and84.93%(648), respectively.
Asyntaxcheckerspotssyntaxmistakesevenwithout TransMap .
Mostsyntaxmistakes( 82.61%)areduetoCodexconfusingJavaScript
syntax with Python syntax and producing Python-like expressions
inJavaScript.Forexample,theexpression [int(x)for x in y] is
wronglytranslatedintotheexpression [parseInt(x)for x in y] .
ThereisnolistcomprehensionsyntaxsupportinJavaScriptthusthe
correcttranslationshouldbe y.map(x => parseInt(x)) .These
mistakes are not minor lexical edits, but can often be resolved with
an online search of the error description [ 38]. A minority of the
syntax mistakes are due to minor errors (e.g., missing parentheses).
For example, Codex translates for loops for a, b in arr into
for (let a,b of arr){...} but misses a pair of square brack-
etsaround a,b(i.e.,for(let [a,b] of ... ).
Around half of the semantic mistakes (45.61% out of 84.93%)
cause no runtime errors but result in diﬀerent results from their
corresponding Python source. For the other half of the semantic
mistakes, most of them cause either reference errors or type errors.
The detailed distributions of mistakes in each micro-benchmark
are showninthe supplementary materials[ 2].
Semantic mistakes can be more subtle and can result in runtime
errors (39.32%of all mistakes). We divide runtime errors caused
by semantic mistakes into three types: runtime reference error,
runtime type error, and other runtime errors. They account for
22.67%,16.12%,0.52%of all mistakes, respectively, as shown in
Figure6.Anexampleofruntimereferenceerrorisusingundeclared
variablesornon-existingfunctions.MisuseofAPIandoperators
or accessing a numeric value as if it is an object will result in
runtime type errors. Occasionally, the translated program might
not terminate and exceed the maximum call stack. Most of such
mistakesthatcauseruntimeerrorscanbeﬁxedbychangingtheAPI
calls,operators,oraddingvariabledeclarationsattheruntimeerror
location. However, the locations of 14.67%runtime errors ( 6.79%of
allsemantic mistakes)do not matchthe correctﬁxlocations.
Theother 53.70%ofthesemanticmistakes( 45.61%ofallmistakes)
cause no runtime errors but make the translated code diﬀer in
outputoftheunittestsfromthesource.Thistypeofmistakecan
be further dividedintoseveral sub-types:
1006TransMap : PinpointingMistakes in Neural Code Translation ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
Table 1:Distributionsofmistakeson micro-benchmarks andperformanceof TransMap compared to the baseline approach
Micro-BenchmarksMistaken Prog. Mistakes Baseline TransMap
Count /u1D434/u1D43F/u1D436/u1D457/u1D460Syntax Semantic /u1D446/u1D460/u1D452/u1D45A /u1D446/u1D460/u1D452/u1D45A/u1D446ℎ/u1D456/u1D451/u1D446/u1D451/u1D456/u1D453/u1D43F/u1D460/u1D462/u1D460/u1D445/u1D460/u1D462/u1D460
Leetcode 29220.2686 (18.7%) 373(81.3%) 42.09% 87.67% 82.41% 81.96% 1.317.23%
GeeksForGeeks 13613.05 16 (6.8%) 219(93.2%) 39.27% 88.58% 86.47% 88.50% 1.117.44%
HumanEvalX 5111.4913 (18.8%) 56 (81.2%) 23.21% 87.50% 88.37% 87.80% 1.1810.90%
Total*/Average 479* 17.53 115* 648* 39.51% 87.96% 84.44% 84.77% 1.237.62%
•Semanticconfusion ,i.e.,confusingsimilarAPIsanddatatypes.
Suchastranslatingfrom int(x)intoMath.floor(x) orMath.
trunc(x) (diﬀerentwhenx<0), a[i]toa.at(i) ora.get(i) .
•Wrong assumptions about the JavaScript runtime and APIs.
Suchastranslating a,b = c.popleft() toa = c.shift()[0];
b = c.shift()[1]; (shiftis not pure and will change c),
translate not arr to!arr(Theequivalentexpressionshould
bearr.length === 0 whenarrisan array).
•Others,i.e.,mistakesthatseemtobediﬃculttoclusterorcatego-
rize. Such as missing a function call in the translation, assigning
absurd values(such as [[0], [0]] ) tovariables, and introduc-
ing a temporary variable with the same name as a local variable.
6.79%of the semantic mistakes in our micro-benchmarks cause
runtimeerrorsatlocationsdiﬀerentfromthemistakes. 53.70%of
thesemanticmistakescausenoruntimeerrorsbutgivediﬀerent
results.TransMap isaimedatpinpointingsuch hiddenmistakes.
6.2 Eﬀectiveness of TransMap
We evaluate TransMap onthe numberoflines that the user hasto
inspecttoﬁxeachmistakeinourmicro-benchmarks.Ifthelines
highlighted by TransMap contain the location to ﬁx, the pinpoint-
ingisdeemedsuccessfulandafailureotherwise.Ourresultsonthe
micro-benchmarks are shown in Table 1, where/u1D446/u1D460/u1D452/u1D45A,/u1D446ℎ/u1D456/u1D451,/u1D446/u1D451/u1D456/u1D453
represent the ratio of successfully pinpointed mistakes to the total
semantic mistakes, hiddenmistakes, and mistakesthat cause diﬀer-
entoutputresultsfromthesourcerespectively.Thequantities /u1D43F/u1D460/u1D462/u1D460
and/u1D445/u1D460/u1D462/u1D460represent the number of highlighted suspicious lines and
its ratio totheprogram size,averaged overthesemanticmistakes
successfully pinpointedby TransMap .
Amongthe setofsemanticmistakes, TransMap canpinpoint
87.96%ofthemsuccessfully.Incontrast,thebaselinesuccessfully
pinpoints only 39.51%of thesemantic mistakes. Thus, TransMap
signiﬁcantlyimprovesoverthebaseline.Itssuccessratiocanachieve
95%satisfactionrateamongdevelopersaccordingtothiswork[ 29].
Thesuspiciouscodelines /u1D43F/u1D460/u1D462/u1D460byTransMap are 1.23 lines,which
is 7.62% of the program code lines on average. This means that the
useroftenonlyneedstofocuson 1-2linestounderstandthemis-
take and to ﬁx it. It shows that TransMap can eﬃciently pinpoint
thesemanticmistakesforshortcodefragmentswithhighaccuracy.
TransMap performs well on the hidden mistakes that the base-
lineapproachcannotﬁndatall.Asshownin /u1D446ℎ/u1D456/u1D451columnofTable 1,
82.41%- 88.37% of hidden mistakes can be pinpointed among three
micro-benchmarks. For semantic mistakes that do not cause any
runtimeerrorsbutdiﬀerentresultsfromthesourcecode, TransMap
isabletosuccessfullydiagnose84.77%mistakes( /u1D446/u1D451/u1D456/u1D453)onaverage.We also look at the quality of the generated source map speciﬁ-
cally.We ﬁndthat 93.8%ofthegeneratedsource mapsare correct.
Failingcasesare discussedinSection 6.5.
87.96%ofsemanticmistakesinourmicro-benchmarksarepin-
pointedsuccessfullyby TransMap ,comparedto 39.51%bybase-
line.The userinspectsonly 1.23linesonaverageper mistake.
6.3 CaseStudies
Howmuchdoes TransMap helpintranslatinglargerreal-world
Python programs to JavaScript? We report on the qualitative expe-
rience of translating 5 Python libraries using TransMap as an aid.
TheirLoC(excludingtests)andthenumberofsemanticmistakes
are shown in Table 2. We select those modules because they are
standalone,havenoexternaldependencies,andtheircodecanbe
segmented and translated function-by-function without signiﬁcant
lossofcontext.We hadnoapriorifamiliarity withtheselibraries.
We explain our methodology in detail using the ﬁrst module
(strsimpy )asanexample.The strsimpy libraryimplementsmany
stringfunctionstocomputesimilarityanddistancemeasures.Italso
comes with unit tests. It has 800+stars on GitHub and around 20/u1D458
downloadsperweek3.Itcontainsaround1klinesofcodedistributed
in35 Pythonﬁlesandhas nothird-partydependencies.
Before translating this Python library to JavaScript, we ﬁrst
merge the relatedPython program ﬁles into standaloneprograms
andconvertunitteststoJavaScript.Morespeciﬁcally,wemanually
mergethe35ﬁleswiththeirunittestsinto5self-containedprogram
ﬁlesaccordingtotheirdependencyrelation.Weﬁrstconvertunit
tests in Python into JavaScript using Codex and manually post-
processtoensurethetestsaretranslatedcorrectly.Thisisfairlyeasy
sincetheunittestsaremostlyfunctioncallsandassertionsthatare
straightforward to convert. It is worth noting that all these manual
eﬀorts on merging ﬁles and converting unit tests can be further
reducedwithsuﬃcientengineeringwhenintegrating TransMap
intomodern IDEs orinotherbuildenvironments.
Eachofthe 5self-containedprogramﬁleisaround 200lines.Ifwe
translateoneﬁleandcreateitssourcemapinoneattempt,itwould
exceed the token limit of the Codex API. We observe that 50is a
feasiblelinenumberofthesourcecodetobetranslatedandmapped
inonequery.Thus,wesplitthecodeintosegmentsofaround 50
lineswhilepreservingtheboundariesofclassesandfunctions.Then,
each segment is translated with Codex, source-mapped separately
byTransMap ,andthenmergedbackafterﬁnishingallsegments.
Thesesteps are fully amenableto complete automation.
3https://github.com/luozhouyang/python-string-similarity .Thedownloadstatistics
wereobtained from https://pypistats.org/packages/strsimpy on28January2023.
1007ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA BoWang,Ruishi Li, MingkaiLi, andPrateek Saxena
Figure7:Anexamplereport ofahidden semanticmistake
pinpointed by TransMap . It contains the mistake location
and variables with diﬀering values in the source and the
translated code.
We then run programs and ﬁx the syntax mistakes caught by
syntax checkers so that only semantic mistakes are remaining. Af-
ter that, we start TransMap to work with the user iteratively to
pinpoint(by TransMap )andﬁx(bytheuser)semanticmistakesfol-
lowing the workﬂow shown in Figure 3. In each round, TransMap
outputs the suspicious lines that contain the ﬁrst semantic mistake
found in the translated code, together with the detailed informa-
tion of the diverging tracepoint (e.g., the mismatching between the
expected value in the source and the actual value in the translated
code of variables), and the corresponding source lines in Python
accordingtothesourcemap.Forexample,Figure 7showstheinfor-
mation reported by TransMap on one of the semantic mistakes in
this case study. TransMap pinpoints the mistake atthe JavaScript
codeline 194withthecorrespondingPythoncodeline 167.Besides,
it gives the local variable values in two code and highlights the
inequivalent variable offset_arr . With this report, the human
user is expected to ﬁgure out that the mistake is caused by the
semantic confusion of pop(...) in JavaScript and provide the ﬁx:
Line 194 in JavaScript should be offset_arr.splice(i, 1) that
removes the /u1D456-th element from offset_arr .
TransMap correctlypinpointsthelocationofallofthe13hidden
mistakes in the translated code automatically. With those mistakes
highlighted from TransMap , one of the authors of this work with
noaprioriexperiencewiththelibrary,ﬁxedalloftheminabout1
hour.The ﬁnal JavaScript translation passesallthe given tests.
Inadditionto strsimpy ,resultsof4morecasestudiesareshown
inTable2.TransMap correctlypinpoints128ofthe130hiddenmis-
takesandhas12falsepositives(FPs).FPsareduetotypediﬀerences
ofsome variables. The user can disable tracingthem to continue
debugging. The supplementary materialgives more details.
TransMap pinpoints128ofthe130hiddenmistakesintransla-
tionsof5Pythonlibraries, with12 false positives.Table2: Pythonlibrariesforcasestudies:LoCmeansLinesof
Code,Sem.M.meansthenumberofsemanticmistakes,#Hid.
meansthenumberofhiddenmistakes,#TPand#FPmean
truepositivesandfalsepositivesof TransMap respectively.
Module LoCSem. M. #Hid./ #TP / #FP
strsimpy 92642 13/ 13/ 0
mathgen 791100 95/ 95/ 5
colorsys 1213 3 / 3 / 0
heapq 18415 9 / 8 / 3
html 77625 10/ 9 / 4
Table3:Thenumberofunﬁnishedtasksandthemediantime
forusersto pinpoint hidden mistakesand ﬁnish tasks
GroupShortProgram LongProgram/u1D441unﬁn/u1D447/u1D460/u1D45D/u1D45C/u1D461/u1D447/u1D461/u1D45C/u1D461/u1D44E/u1D459/u1D447/u1D460/u1D45D/u1D45C/u1D461/u1D447/u1D461/u1D45C/u1D461/u1D44E/u1D459
/u1D43A/u1D450452s739s1020s1255s7
/u1D43A/u1D452 60s235s286s365s2
6.4 User Study
Weconductapreliminaryuserstudyontheusefulnessof TransMap
in the debugging taskof pinpointing and ﬁxing hidden mistakes.
Evaluation metrics are the time users spend pinpointing and ﬁxing
bugs,andthenumberofunﬁnishedtasks.Weinvite24computersci-
encegraduates4,whohavenopriorfamiliaritywith TransMap ,and
randomlydividethemintoacontrolgroup /u1D43A/u1D450(withoutTransMap )
andanexperimentalgroup /u1D43A/u1D452(withTransMap ).Twogroupsare
given the same set of programs consisting of randomly sampled
8 short programs (< 20 lines) from our micro-benchmarks and 4
long code segments (> 150 lines) from strsimpy library. Each par-
ticipant is randomly assigned 3 debugging tasks: 2 short programs
and 1long program, and we make sure every program is assigned
tothreeuserspergroup.Eachprogramcontainsonemistakeand
only a one-line ﬁx is needed to pass tests. If they spend more than
15 minutes, they have the option to abandon that program, which
would be regarded as an unﬁnished task. The results are presented
in Table3. The/u1D441unﬁncolumn shows the number of unﬁnished
tasks out of 36 tasks per group. After removing these samples, the
medianofthetimetoconﬁrmthelineofmistakeandthemedianof
thetotaltimetoﬁnishthistaskispresentedas /u1D447/u1D460/u1D45D/u1D45C/u1D461and/u1D447/u1D461/u1D45C/u1D461/u1D44E/u1D459.We
canseethatthemediantimetopinpointhiddenmistakesreduces
87% on short code and 72% on long code when using TransMap
compared to using the VS Code debugger. Moreover, the total time
to pinpoint and ﬁx mistakes also reduces by 68% on short code and
71%onlongcode.Additionalresultsoftheuserstudyarepresented
inthe supplementary material[ 2].
6.5 Discussion
Unﬁxable Cases When Creating Micro-benchmarks. We
removed unﬁxable translations due to a known issue referred to
ashallucination inlargelanguagemodels[ 24,31]. Such unﬁxable
translations typicallyhave aheavy relianceonnon-existentAPIs,
data types, and operators lacking JavaScript equivalents. Although
4All participants reported having at least some familiarity with Python or JavaScript.
1008TransMap : PinpointingMistakes in Neural Code Translation ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
Table 4: Accuracy of source mapping and breakdown of fail-
uresunder diﬀerentstyles ofthetranslated code
Scenario AccuracyFailure Breakdown
NEQ.OOB.DISO.
Fixed Translation 94.5% 2.1%2.1%1.4%
BuggyTranslation 92.5% 3.8%1.7%2.1%
AddedComments 93.8% 1.4%2.7%2.1%
RenamedVariables 91.4% 2.1%5.8%0.7%
Multiple Functions 89.4% 4.8%3.1%2.7%
TransMap can identify these mistakes, ﬁxing them is complicated,
andwefounditgenerallysimplertoentirelyrewritethetranslation.
TransMap cannothelpmuchinsuchinstances,examplesofwhich
are providedinthe supplementary material[ 2].
The Types of Failures in Source Mapping. In our evaluation of
the micro-benchmarks, 6.2% of the source mapping are counted as
failures. There are three types offailures:
•Code Not Equal(NEQ) :3.4%. Some code linesin the mapping
outputare diﬀerentfrom the input(i.e.,Part C andBinFig. 4).
•OutofBound(OOB) :1.5%.Someannotatedstatementnumbers
inthetranslation(JavaScript)donotexistinthesource(Python).
•Disorder(DISO) : 1.2%.Somestatements are mappedwrongly.
Wecounttheﬁrsttwotypesasinvalidandthethirdtypeasinaccu-
rate.Mostofthefailurecasescanbeﬁxedwithmanualmodiﬁca-
tionsto several linesofthe mapping.
RobustnessofSourceMapping. Toassesshowvaryingstylesof
thetranslatedcodeaﬀecttheperformanceofsourcemapping,we
conduct additionalexperiments5on thesame LeetCodeprograms
fromourevaluation.WeintroducedchangestotheﬁxedJavaScript
translationsinvariousways:commentinsertion,variablerenaming,
andfunctionconcatenation.Table 4showsthatthesetransforma-
tionsdegradetheaccuracyofsourcemappingbyabout1-5%.The
supplementary material[ 2]has amore detaileddiscussion.
PossibleLimitationsofIn-contextLearningusingLLMs. LLMs
can typically generalize froma fewexamples [ 19,60],yet the con-
textwindowrestrictsthecomplexityoftasksthattheycontextualize.
Further, their reasoning capability is token-limited, leading to a
subparperformanceonsomefew-shotreasoningtasksasindicated
byBrown et al .However, methods like chain-of-thoughts [ 56] can
be usedto enhance outcomes withincreasedoutputlength.
TransMap vs. Conventional Code Alignment Approaches.
To our knowledge, most of the conventional approaches to code
andtracealignment[ 41,54,61]focusondiﬀerentversionsofthe
code inthe same language. We observe neural codetranslation can
make unpredictable transformations, such as breaking, merging,
reorderingstatements,transformingloopstructure,andsoon.Thus,
an LLM-based self-explanatory approach is potentially easier to
implementandmoreaccurateforcodetranslationsbytheLLMitself.
However,theapproachhassomepitfalls,includingnoisyoutputand
the limiting context length inherent in LLMs. Enhancements could
potentially come from imposing output restrictions on language
models [40]andexpandingthe contextwindow[ 47].
5WeusedChatGPT3.5[ 35]insteadofCodexforthisexperimentand4casestudies
(exceptstrsimpy )since Codexbecamepubliclyunavailable to us.7 RELATED WORK
This is the ﬁrst work on automatically pinpointing mistakes for
neural code generator outputs when attempting to translate across
programming languages. This problem is related to non-neural
code translation andfaultlocalizationindiﬀerentways.
CodeTranslation. Traditionalcompilersandtranspilationtools
are the most common approaches used today. The readability of
thegeneratedcodeisoftenlimitedandtheeﬀorttowritecompilers
is signiﬁcant. To address these issues, a recent line of work uses
natural language processing tools for code generation and trans-
lation. TransCoder [ 43] proposed unsupervised code translation
using back-translation. Szafraniec et al .proposed to train neural
decompilerstotranslatebetweenlanguagesthatcanbecompiled
toLLVMIR.Largerstate-of-the-artmodelssuchasCodex[ 9]are
also trained in an unsupervised manner and can translate between
multiplelanguages.However,alloftheseapproachessuﬀerfrom
noisy outputs with mistakes. Our work on TransMap is motivated
from these observations and aims to augment existing neural code
translators.Anotherlineofworkwithalongerhistoryistousesym-
bolicapproachesforcodetranslation.TXL[ 11]isadomain-speciﬁc
languageforwritingcodetranslators.Amorerecentworkintro-
duces DuoGlot [ 52], a system that combines rule-based translation
with rule synthesis from user-provided examples. This approach
has the beneﬁts of being predictable, but generally requires human
eﬀortandexpertisetowriterules. TransMap isanincomparable
alternative: it directs the user to a ﬁx in the translated program,
ratherthangeneraltransformation rulesacrosslanguages.
FaultLocalization. Fault location is a richareaof priorresearch
whichalsopinpointserrorsinbuggyprogramsgiventests[ 59].The
keydiﬀerencefrom theseworksisthattests in ourproblemsetup
runontwoprogramsindiﬀerentlanguages.Thenovelchallengeis
thereforeinmappingexecutionsemanticsbetweentheprograms
especiallyaftertheyhaveundergoneablack-boxneuraltranslation.
TransMap introduces generic capabilities, such as source maps,
that can act as an important aid to adapt existing fault localization
techniquestoneuralcodegeneratorsinthefuture.Priortechniques
have focused on diﬀerent aspects: improving statistical scoring
functions [ 3,27], ranking mechanisms [ 5,44], better reasoning
under mutations [ 62], increase the quality of test suites [ 39,48],
improving trace analysis [ 12], symbolic reasoning for root cause
analysis[ 8,16,28,41], andmore.
8 CONCLUSION
Weprovidetheﬁrstsystematicapproachtopinpointingerrorsin
code translated from one program language to another by modern
neural translators. Our TransMap identiﬁes mistakes with high
ﬁdelity inshort JavaScript fragments translatedfrom Python.
9 DATA AVAILABILITY
Our code and datasets are available on Zenodo[53]. The latest
version and supplementary materials [ 2] can be found on Github.
ACKNOWLEDGMENTS
We thank the anonymous reviewers. This research is supported
by grants given by the Ministry of Education in Singapore: Tier-2
grant MOE-T2EP20220-0014 andTier-1 grant T1 251RES2023.
1009ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA BoWang,Ruishi Li, MingkaiLi, andPrateek Saxena
REFERENCES
[1]2002. Chapter15-MicrosoftSaysJUMP—JavaUserMigrationPath. In C#ForJava
Programmers , Brian Bagnall, Philip Chen, Stephen Goldberg, Jeremy Fairdoth,
and Harold Cabrera (Eds.). https://doi.org/10.1016/B978-193183654-8/50019-0
[2] 2023. SupplementaryMaterial .https://github.com/HALOCORE/TransMap
[3]RuiAbreu,PeterZoeteweij,andArjanJCVanGemund.2007. Ontheaccuracyof
spectrum-based faultlocalization. In Testing:Academic and industrial conference
practice and research techniques-MUTATION (TAICPART-MUTATION 2007) . IEEE,
89–98.https://doi.org/10.1109/TAIC.PART.2007.13
[4]Shraddha Barke, Michael B. James, and Nadia Polikarpova. 2023. Grounded
Copilot:HowProgrammersInteractwithCode-GeneratingModels. Proc.ACM
Program.Lang. 7,OOPSLA1,Article78(apr2023),27pages. https://doi.org/10.
1145/3586030
[5]TimBlazytko,MoritzSchlögel,CorneliusAschermann,AliAbbasi,JoelFrank,
SimonWörner,andThorstenHolz.2020. AURORA:StatisticalCrashAnalysisfor
AutomatedRootCauseExplanation.In Proceedingsofthe29thUSENIXConference
onSecuritySymposium(SEC’20) .USENIXAssociation,USA,Article14,18pages.
[6]Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,
PrafullaDhariwal,ArvindNeelakantan, Pranav Shyam, GirishSastry,Amanda
Askell,etal .2020. Languagemodelsarefew-shotlearners. Advancesinneural
information processingsystems 33(2020), 1877–1901.
[7]StephanieC.Y.Chan,AdamSantoro,AndrewK.Lampinen,JaneX.Wang,Aa-
ditya Singh, Pierre H. Richemond, Jay McClelland, and Felix Hill. 2022. Data
DistributionalPropertiesDrive EmergentIn-ContextLearningin Transformers.
http://arxiv.org/abs/2205.05055 arXiv:2205.05055 [cs].
[8]SatishChandra,EminaTorlak,ShaonBarman,andRastislavBodik.2011. Angelic
Debugging.In Proceedingsofthe33rdInternationalConferenceonSoftwareEngi-
neering(Waikiki, Honolulu, HI, USA) (ICSE ’11) . Association for Computing Ma-
chinery, New York, NY, USA, 121–130. https://doi.org/10.1145/1985793.1985811
[9]MarkChen,JerryTworek,HeewooJun,QimingYuan,HenriquePondedeOliveira
Pinto,JaredKaplan,HarriEdwards,YuriBurda,NicholasJoseph,GregBrockman,
et al.2021. Evaluating large language models trained on code. arXiv preprint
arXiv:2107.03374 (2021).
[10]CodeGeeX.2023. HumanEval-X:AnewbenchmarkforMultilingualProgram
Synthesis. https://github.com/THUDM/CodeGeeX .
[11]James R Cordy. 2006. The TXL source transformation language. Science of
Computer Programming 61, 3 (2006), 190–210. https://doi.org/10.1016/j.scico.
2006.04.002
[12]WeidongCui,XinyangGe,BarisKasikci,BenNiu,UpamanyuSharma,Ruoyu
Wang, and Insu Yun. 2018. REPT: Reverse Debugging of Failures in Deployed
Software. In Proceedings of the 13th USENIX Conference on Operating Systems
Design and Implementation (Carlsbad,CA, USA) (OSDI’18) .USENIX Association,
USA,17–32.
[13]Joe Davison, Joshua Feldman, and Alexander Rush. 2019. Commonsense Knowl-
edge Mining from Pretrained Models. In Proceedings of the 2019 Conference on
Empirical Methods in Natural Language Processing and the 9th International
Joint Conference on Natural Language Processing (EMNLP-IJCNLP) . Associa-
tion for Computational Linguistics, Hong Kong, China, 1173–1178. https:
//doi.org/10.18653/v1/D19-1109
[14]Gregoire Deletang, Anian Ruoss, Jordi Grau-Moya, Tim Genewein, Li Kevin
Wenliang, Elliot Catt, Chris Cundy, Marcus Hutter, Shane Legg, Joel Veness, and
Pedro A Ortega. 2023. Neural Networks and the Chomsky Hierarchy. https:
//openreview.net/forum?id=WbxHAzkeQcn
[15]doocs.2023. LeetCodesolutionsinanyprogramminglanguage. https://github.
com/doocs/leetcode .
[16]EvrenErmis,MartinSchäf,andThomasWies.2012. Errorinvariants.In FM2012:
FormalMethods:18th InternationalSymposium,Paris,France,August 27-31,2012.
Proceedings 18 . Springer, 187–201. https://doi.org/10.1007/978-3-642-32759-9_17
[17]ZhiyuFan,XiangGao,MartinMirchev,AbhikRoychoudhury,andShinHweiTan.
2023. AutomatedRepairofProgramsfromLargeLanguageModels.In Proceedings
ofthe45thInternationalConferenceonSoftwareEngineering (Melbourne,Victoria,
Australia) (ICSE ’23) . IEEE Press, 1469–1481. https://doi.org/10.1109/ICSE48619.
2023.00128
[18]XiangGao,YannicNoller,andAbhikRoychoudhury.2022. ProgramRepair. arXiv
preprint arXiv:2211.12787 (2022).https://doi.org/10.48550/arXiv.2211.12787
[19]ShivamGarg,DimitrisTsipras,PercyLiang,andGregoryValiant.2022. What
can transformers learn in-context? a case study of simple function classes. arXiv
preprint arXiv:2208.01066 (2022).https://doi.org/10.48550/arXiv.2208.01066
[20]OpenAI Github. 2023. GitHub Copilot ·Your AI pair programmer. https://github.
com/features/copilot/ .
[21]Rahul Gupta, Soham Pal, Aditya Kanade, and Shirish Shevade. 2017. DeepFix:
Fixing Common C Language Errors by Deep Learning. In Proceedings of the
Thirty-First AAAI Conference on Artiﬁcial Intelligence (San Francisco, California,
USA)(AAAI’17) . AAAI Press,1345–1351.
[22]AnnaIrrera.2017. BanksscrambletoﬁxoldsystemsasIT’cowboys’rideinto
sunset.https://www.reuters.com/article/us-usa-banks-cobol-idUSKBN17C0D8 .[23]Naman Jain, Skanda Vaidyanath, Arun Iyer, Nagarajan Natarajan, Suresh
Parthasarathy, Sriram Rajamani, and Rahul Sharma. 2021. Jigsaw: Large Lan-
guage Models meet Program Synthesis. http://arxiv.org/abs/2112.02969
arXiv:2112.02969 [cs].
[24]Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii,
YeJinBang,AndreaMadotto,andPascaleFung.2023. SurveyofHallucinationin
Natural Language Generation. ACM Comput. Surv. 55, 12, Article 248 (mar 2023),
38pages. https://doi.org/10.1145/3571730
[25]Zhengbao Jiang, Frank F. Xu, Jun Araki, and Graham Neubig. 2020.
How Can We Know What Language Models Know? Transactions
of the Association for Computational Linguistics 8 (07 2020), 423–438.
https://doi.org/10.1162/tacl_a_00324 arXiv:https://direct.mit.edu/tacl/article-
pdf/doi/10.1162/tacl_a_00324/1923867/tacl_a_00324.pdf
[26]WeiJinandAlessandroOrso.2013. F3:FaultLocalizationforFieldFailures.In
Proceedings of the 2013 International Symposium on Software Testing and Analysis
(Lugano, Switzerland) (ISSTA 2013) . Association for Computing Machinery, New
York, NY, USA,213–223. https://doi.org/10.1145/2483760.2483763
[27]James Jones, Mary Harrold, and John Stasko. 2002. Visualization of test informa-
tiontoassistfaultlocalization. Proceedings-InternationalConferenceonSoftware
Engineering , 467–477. https://doi.org/10.1145/581339.581397
[28]ManuJoseandRupak Majumdar. 2011. Cause ClueClauses:ErrorLocalization
UsingMaximumSatisﬁability. SIGPLANNot. 46,6(jun2011),437–446. https:
//doi.org/10.1145/1993316.1993550
[29]Pavneet Singh Kochhar, Xin Xia, David Lo, and Shanping Li. 2016. Practitioners’
ExpectationsonAutomatedFaultLocalization.In Proceedingsofthe25thInter-
nationalSymposiumonSoftwareTestingandAnalysis (Saarbrücken,Germany)
(ISSTA2016) .AssociationforComputingMachinery,NewYork,NY,USA,165–176.
https://doi.org/10.1145/2931037.2931051
[30]GuillaumeLample,MyleOtt,AlexisConneau,LudovicDenoyer,andMarc’Aurelio
Ranzato. 2018. Phrase-Based & Neural Unsupervised Machine Translation. ,
5039–5049 pages. https://doi.org/10.18653/v1/D18-1549
[31]Junyi Li, Xiaoxue Cheng, Wayne Xin Zhao, Jian-Yun Nie, and Ji-Rong Wen.
2023. HaluEval:ALarge-ScaleHallucinationEvaluationBenchmarkforLarge
LanguageModels. arXive-prints (2023),arXiv–2305. https://doi.org/10.48550/
arXiv.2305.11747
[32] Microsoft.2023. Visual Studio Code. https://code.visualstudio.com/ .
[33]mozilla. 2023. source-map: Consume and generate source maps. https://github.
com/mozilla/source-map
[34]Hoang Duong Thien Nguyen, Dawei Qi, Abhik Roychoudhury, and Satish Chan-
dra.2013. SemFix:Programrepairviasemanticanalysis.In 201335thInternational
Conference on Software Engineering (ICSE) . 772–781. https://doi.org/10.1109/
ICSE.2013.6606623
[35] OpenAI. 2023. ChatGPT. https://openai.com/blog/chatgpt .
[36]OpenAI. 2023. Code completion - OpenAI API. https://platform.openai.com/
docs/guides/code/best-practices .
[37] OpenAI. 2023. OpenAI API. https://openai.com/api/ .
[38]StackOverﬂow. 2023. DoesJavaScriptsupport array/listcomprehensionslike
Python?https://stackoverﬂow.com/questions/31353213/does-javascript-support-
array-list-comprehensions-like-python .
[39]Carlos Pacheco, Shuvendu K. Lahiri, Michael D. Ernst, and Thomas Ball. 2007.
Feedback-DirectedRandomTestGeneration.In Proceedingsofthe29thInterna-
tional Conference on Software Engineering (ICSE ’07) . IEEE Computer Society,
USA,75–84. https://doi.org/10.1109/ICSE.2007.37
[40]GabrielPoesia,OleksandrPolozov,VuLe,AshishTiwari,GustavoSoares,Christo-
pher Meek, and Sumit Gulwani. 2022. Synchromesh: Reliable code gener-
ation from pre-trained language models. http://arxiv.org/abs/2201.11227
arXiv:2201.11227 [cs].
[41]Dawei Qi, Abhik Roychoudhury, Zhenkai Liang, and Kapil Vaswani. 2012. DAR-
WIN: An Approachto Debugging Evolving Programs. ACM Trans. Softw.Eng.
Methodol. 21,3,Article19 (jul2012),29pages. https://doi.org/10.1145/2211616.
2211622
[42]Colin Raﬀel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang,
Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. Exploring the
LimitsofTransferLearningwithaUniﬁedText-to-TextTransformer. J.Mach.
Learn. Res. 21,1,Article140(jan2020),67pages.
[43]Baptiste Roziere, Marie-Anne Lachaux, Lowik Chanussot, and Guillaume
Lample. 2020. Unsupervised Translation of Programming Languages. In
Advances in Neural Information Processing Systems , H. Larochelle, M. Ran-
zato, R. Hadsell, M.F. Balcan, and H. Lin (Eds.), Vol. 33. Curran Associates,
Inc.,20601–20611. https://proceedings.neurips.cc/paper_ﬁles/paper/2020/ﬁle/
ed23fbf18c2cd35f8c7f8de44f85c08d-Paper.pdf
[44]ShiqiShen,AashishKolluri,ZhenDong,PrateekSaxena,andAbhikRoychoud-
hury. 2021. Localizing Vulnerabilities Statistically From One Exploit. In Proceed-
ings of the 2021 ACM Asia Conference on Computer and Communications Security
(Virtual Event, Hong Kong) (ASIA CCS ’21) . Association for Computing Machin-
ery, NewYork, NY, USA,537–549. https://doi.org/10.1145/3433210.3437528
[45]RichardShin and BenjaminVanDurme.2022. Few-Shot Semantic Parsing with
LanguageModelsTrainedonCode.In Proceedingsofthe2022Conferenceofthe
1010TransMap : PinpointingMistakes in Neural Code Translation ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
North American Chapter of the Association for Computational Linguistics: Human
LanguageTechnologies .AssociationforComputationalLinguistics,Seattle,United
States,5417–5425. https://doi.org/10.18653/v1/2022.naacl-main.396
[46]MarcSzafraniec,BaptisteRoziere,HughLeather,FrancoisCharton,PatrickLa-
batut, and Gabriel Synnaeve. 2022. Code Translation with Compiler Representa-
tions. (July2022). http://arxiv.org/abs/2207.03578 arXiv:2207.03578 [cs].
[47]Yi Tay, Mostafa Dehghani, Dara Bahri, and Donald Metzler. 2022. Eﬃcient
Transformers: A Survey. 55, 6, Article 109 (dec 2022), 28 pages. https://doi.org/
10.1145/3530811
[48]Nikolai Tillmann and Jonathan De Halleux. 2008. Pex–white box test generation
for.NET.In TestsandProofs:SecondInternationalConference,TAP2008,Prato,Italy,
April 9-11, 2008. Proceedings 2 . Springer, 134–153. https://doi.org/10.1007/978-3-
540-79124-9_10
[49]SindhuTipirneni,MingZhu,andChandanKReddy.2022. StructCoder:Structure-
Aware Transformer for Code Generation. arXiv preprint arXiv:2206.05239 (2022).
https://doi.org/10.48550/arXiv.2206.05239
[50]treesitter.2023.Tree-sitter|Introduction. https://tree-sitter.github.io/tree-sitter/ .
[51]typescriptlang. 2023. TSConﬁg Reference: Source Map. https://www.
typescriptlang.org/tsconﬁg#sourceMap
[52]Bo Wang, Aashish Kolluri, Ivica Nikolić, Teodora Baluta, and Prateek Saxena.
2023. User-Customizable Transpilation of Scripting Languages. 7, OOPSLA1,
Article82(apr2023),29pages. https://doi.org/10.1145/3586034
[53]BoWang,RuishiLi,MingkaiLi,andPrateekSaxena.2023. TransMap:Pinpointing
MistakesinNeuralCodeTranslation(Artifact) .https://doi.org/10.5281/zenodo.
8283633
[54]Haijun Wang, Yun Lin, Zijiang Yang, Jun Sun, Yang Liu, Jinsong Dong, Qinghua
Zheng,andTingLiu.2021. ExplainingRegressionsviaAlignmentSlicingand
Mending. IEEE Transactions on Software Engineering 47, 11 (2021), 2421–2437.
https://doi.org/10.1109/TSE.2019.2949568
[55]Yue Wang, Weishi Wang, Shaﬁq Joty, and Steven C.H. Hoi. 2021. CodeT5:
Identiﬁer-aware Uniﬁed Pre-trained Encoder-Decoder Models for Code Un-
derstanding and Generation. In Proceedings of the 2021 Conference on Empir-
ical Methods in Natural Language Processing . Association for ComputationalLinguistics, Online and Punta Cana, Dominican Republic, 8696–8708. https:
//doi.org/10.18653/v1/2021.emnlp-main.685
[56]JasonWei,XuezhiWang,DaleSchuurmans,MaartenBosma,EdChi,QuocLe,
andDennyZhou.2022. Chainofthoughtpromptingelicitsreasoninginlarge
language models. arXiv preprint arXiv:2201.11903 (2022).https://doi.org/10.
48550/arXiv.2201.11903
[57]WestleyWeimer,ThanhVuNguyen,ClaireLeGoues,andStephanieForrest.2009.
AutomaticallyFindingPatchesUsingGeneticProgramming.In Proceedingsofthe
31st International Conference on Software Engineering (ICSE ’09) . IEEE Computer
Society, USA,364–374. https://doi.org/10.1109/ICSE.2009.5070536
[58]Sean Welleck, Ilia Kulikov, Jaedeok Kim, Richard Yuanzhe Pang, and Kyunghyun
Cho. 2020. Consistency of a Recurrent Language Model With Respect to Incom-
plete Decoding. In Proceedings of the 2020 Conference on Empirical Methods in
NaturalLanguageProcessing(EMNLP) .AssociationforComputationalLinguistics,
Online, 5553–5568. https://doi.org/10.18653/v1/2020.emnlp-main.448
[59]W. Eric Wong, Ruizhi Gao, Yihao Li, Rui Abreu, and Franz Wotawa. 2016. A
SurveyonSoftwareFaultLocalization. IEEETransactionsonSoftwareEngineering
42,8 (2016), 707–740. https://doi.org/10.1109/TSE.2016.2521368
[60]SangMichaelXie,AditiRaghunathan,PercyLiang,andTengyuMa.2022. An
Explanation of In-context Learning as Implicit Bayesian Inference. http://arxiv.
org/abs/2111.02080 arXiv:2111.02080 [cs].
[61]Bin Xin, William N. Sumner, and Xiangyu Zhang. 2008. Eﬃcient Program
Execution Indexing. In Proceedings of the 29th ACM SIGPLAN Conference on
Programming Language Design and Implementation (Tucson, AZ, USA) (PLDI
’08). Association for Computing Machinery, New York, NY, USA, 238–248.
https://doi.org/10.1145/1375581.1375611
[62]Xiangyu Zhang, Neelam Gupta, and Rajiv Gupta. 2006. Pruning Dynamic Slices
with Conﬁdence. SIGPLAN Not. 41, 6 (jun 2006), 169–180. https://doi.org/10.
1145/1133255.1134002
Received 2023-02-02; accepted 2023-07-27
1011