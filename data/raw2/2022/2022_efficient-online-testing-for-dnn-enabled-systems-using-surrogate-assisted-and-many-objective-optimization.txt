Efficient Online Testing for DNN-Enabled Systems using
Surrogate-Assisted and Many-Objective Optimization
Fitash Ul Haq
University of Luxembourg
Luxembourg
fitash.ulhaq@uni.luDonghwan Shin
University of Luxembourg
Luxembourg
donghwan.shin@uni.luLionel Briand
University of Luxembourg
Luxembourg
University of Ottawa
Ottawa, Canada
lionel.briand@uni.lu
ABSTRACT
WiththerecentadvancesofDeepNeuralNetworks(DNNs)inreal-
world applications, such as Automated Driving Systems (ADS) for
self-drivingcars,ensuringthereliabilityandsafetyofsuchDNN-
enabledSystemsemergesasafundamentaltopicinsoftwaretesting.
Oneoftheessential testingphasesofsuchDNN-enabledsystems
isonline testing, where the system under test is embedded into a
specificandoftensimulatedapplicationenvironment(e.g.,adriving
environment) and tested in a closed-loop mode in interaction with
theenvironment.However,despitetheimportanceofonlinetesting
for detecting safetyviolations, automaticallygenerating newand
diversetestdatathatleadtosafetyviolationspresentsthefollow-
ing challenges: (1) there can be many safety requirements to be
considered atthe sametime, (2)running ahigh-fidelity simulator
is often very computationally-intensive, and (3) the space of all
possibletestdatathatmaytriggersafetyviolationsistoolargeto
be exhaustively explored.
In this paper, we address the challenges by proposing a novel
approach, called SAMOTA (Surrogate-Assisted Many-Objective
Testing Approach), extending existing many-objective search al-
gorithms for test suite generation to efficiently utilize surrogate
modelsthat mimic the simulator, but are much less expensive to
run. Empirical evaluation results on Pylot,an advanced ADS com-
posed of multiple DNNs, using CARLA, a high-fidelity driving
simulator,showthatSAMOTAissignificantlymoreeffectiveand
efficientatdetectingunknownsafetyrequirementviolationsthan
state-of-the-art many-objective test suite generation algorithms
andrandomsearch.Inother words,SAMOTAappearstobeakey
enabler technology for online testing in practice.
CCS CONCEPTS
â€¢Software and its engineering â†’Empirical software valida-
tion;Search-based software engineering.
KEYWORDS
DNN testing, online testing, many-objective search, surrogate-
assisted optimization, self-driving cars
This work is licensed under a Creative Commons Attribution International 4.0 
License.
ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Â© 2022 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-9221-1/22/05.
https://doi.org/10.1145/3510003.3510188ACM Reference Format:
FitashUlHaq,DonghwanShin,andLionelBriand.2022.EfficientOnline
Testing for DNN-Enabled Systems using Surrogate-Assisted and Many-
Objective Optimization. In 44th International Conference on Software Engi-
neering(ICSEâ€™22),May21â€“29,2022,Pittsburgh,PA,USA. ACM,NewYork,
NY, USA, 12 pages. https://doi.org/10.1145/3510003.3510188
1 INTRODUCTION
GiventherecentachievementsofDeepNeuralNetworks(DNNs)
inmanyapplications,includingimageclassification[ 19]andobject
detection[ 44],they areincreasingly usedinautonomous systems,
such as Automated Driving Systems (ADS) for self-driving cars.
Therefore, ensuring the reliability of DNN-Enabled Systems (DES)
insuchcontextsemergesasafundamentaltopicinsoftwaretesting.
As discussed by Haq et al . [14], DNN testing has two distinct
phases:offline testing where DNNs are tested as individual units
based on test datasets obtained without involving the DNNs under
test,andonlinetesting whereDNNsareembeddedintoaspecificap-
plicationenvironment(e.g.,adrivingenvironment,oftensimulated
given its safety-critical nature) and tested in a closed-loop mode
in interaction with the application environment. In other words,onlinetestingisapriorimorerealisticandconsidersthatpredic-
tionsgeneratedbytheDNNswhenobservinganenvironmentstate
attimeğ‘¡impacttheenvironmentstatesafter ğ‘¡.Forexample,only
online testing can observe the accumulation of minor prediction
errors over time, eventually causing a critical safety violation (e.g.,
colliding with a pedestrian).
However, despite the importance of online testing for detect-
ing safety violations, automatically generating new and diversetestdatathatleadstosafetyviolationsentailsseveralchallenges.First, there can be many safety requirements, often independentfrom each other, to be considered at the same time. Second, run-
ning a high-fidelity simulator to check safety violations is typically
computationally-intensive; the higher the fidelity of a simulator,
the more time it takes to simulate, which directly impacts the cost
of online testing. Third, the space of all possible test data that may
trigger safety violations is too large to be exhaustively explored.
Contributions. To address the above challenges, we propose a
novelapproach,calledSAMOTA(Surrogate-AssistedMany-Objective
TestingApproach),thatcombinestwodistincttechniques:(1) many-
objective search [2,29] to effectively achieve many independent ob-
jectives(i.e.,causingsafetyviolations)withinalimitedtimebudget
and (2)surrogate-assisted optimization [17] to efficiently search for
critical test data using surrogate models that mimic the simulator,
toacertainextent,butarecomputationallymuchlessexpensive.In
8112022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)
ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Fitash Ul Haq, Donghwan Shin, and Lionel Briand
particular,followingstate-of-the-artsurrogate-assistedoptimiza-
tionalgorithms[ 21,39,43],SAMOTAusestwosearchphases: global
search(withglobalsurrogatemodels)that exploresthesearchspace
bycapturingtheglobaloutlineofthefitnesslandscapeusingglobal
surrogate models, and local search (with local surrogate models)
thatexploitsthe local details around promising areas found by the
globalsearch.Wealsoimprovethelocalsearchperformanceusinga
novel,clustering-basedapproachthatgeneratesonelocalsurrogate
model for test data belonging to the same promising area.
Though SAMOTA can be applied to any DES that should be
verifiedwithonlinetesting,weevaluatedtheefficiencyandeffec-
tivenessoftheapproachinthecontextofADS.Specifically,weuse
CARLA [ 7], a high-fidelity driving simulator, and Pylot [ 13], an
advanced DNN-enabled ADS (DADS) composed of multiple DNNs
capable of various tasks, such as traffic light detection, traffic sign
detection, object tracking, and object classification. More than 300
computinghoursofexperimentalresultsshowthatSAMOTAissig-
nificantly more effective and efficient at detecting unknown safety
violationsthanstate-of-the-artmany-objectivetestsuitegeneration
algorithms and random search, within the same time budget.
The contributions of this paper are summarized as follows:
â€¢SAMOTA, a novel approach to automatically and efficiently
generate test data for online testing by carefully combining
many-objective search and surrogate-assisted optimization;
â€¢Anextensiveempirical evaluationofSAMOTA,in termsof
efficiencyandeffectiveness,anditscomparisonwithstate-
of-the-art alternatives and random search;
â€¢a publicly available replication package of the evaluation,
including the implementation of SAMOTA (see Section 6.6).
Significance. Inmanycyber-physicaldomains,itisclearlyimpor-
tant to identify potential safety violations in a DES through online
testing,involvingahigh-fidelitysimulatorintheloop,especially
when there are complex interactions between the system and its
environment.SAMOTAprovidesanefficientandeffectiveonline
testing approach using surrogate models while considering many
safetyrequirementsatthesametime.Itisapracticalenablerforthe
online testing of complex DES in realistic contexts. Our research is
also an important step towards the scalable testing of DES, a very
active research area in software testing.
Paper Structure. The rest of the paper is organized as follows.
Section2providesbackgroundinformationonsearch-basedtestingandsurrogatemodels.Section3formalizestheproblemoftestsuite
generation for the online testing of DES. Section 4 positions our
workwithrespecttorelatedwork.Section5describesourapproach.
Section 6 evaluates our approach in the context of ADS. Section 7
concludes the paper.
2 BACKGROUND
2.1 Search-based Testing
Search-based software testing (SBST) [ 26] is arguably one of the
most successful fields in software testing research. The key idea is
to recast a testing problem as an optimization problem by properly
defining fitness functions considering the objectives of the testing
problem.Forexample,Panichellaetal . [29]recastedtheproblem
of test suite generation for branch coverage as a many-objectiveoptimization problem, where the objectives are to cover individual
branchesand thefitnessfunction foreachobjective estimatesthe
likelihoodofcoveringabranch.Toefficientlyachieveeachobjective
individuallyasmuchaspossible,Panichellaetal . [29]introduced
a many-objectivesearch algorithm, named MOSA,that is tailored
for test suite generation. Later, Abdessalem et al . [2]presented
analternativealgorithmformany-objectivetestsuitegeneration,
namedFITEST,byextendingMOSAtodynamicallyreducethesize
ofpopulationsduringthesearchandthusimprovesitsefficiency.
Both MOSA and FITEST are carefully designed for the test suite
generation problem by considering many objectives at the same
timeandareknowntobeeffectiveinthisapplicationcontext[ 2,29].
2.2 Surrogate Models
EvolutionaryAlgorithms(EAs)havebeensuccessfullyappliedto
manycomplexengineeringproblems[ 9].However,thefitnessfunc-
tion evaluation of such complex problems often involves computa-
tionally expensive simulations or calculations [ 18]. To address this
issue,manyresearchershaveinvestigated surrogatemodels thatcan
replacethecomputationallyexpensivefunctionevaluationswith
muchlessexpensiveapproximations.Amongthem,webrieflyintro-ducethemostwidelyusedsurrogatemodeltypes,i.e.,Kriging[
33],
polynomial regression [ 34], radial basis function networks [ 5], and
their ensemble [12].
2.2.1 Kriging. Kriging(alsoknownasgaussianprocessregression)
is one of the most widely used surrogate models since the 1970s.
Similar to regression analysis, it predicts the value of a function as
a combination of linear functions using a stochastic process. While
it provides the error value for each prediction, it is relatively more
time-consumingfor training than other surrogate models.
2.2.2 Polynomial Regression. As a form of statistical regression
analysis,polynomialregressionmodelstherelationshipbetween
theindependentvariable ğ‘¥andthedependentvariable ğ‘¦intheform
ofğ‘›thdegreepolynomialin ğ‘¥.Thoughitissimpleandintuitive,the
existenceof afewoutliers canseverely distorttheapproximation
in nonlinear problems [28].
2.2.3 Radial Basis Function Network. Aradialbasisfunctionnet-
work is an artificial neural network that consists of three layers:
input, hidden, and output layers. Radial basis functions are used as
activationfunctions,andtheoutputofthenetworkisaweighted
sum of radial basis functions. It is known to provide both computa-
tional efficiency and reasonable training accuracy [21].
2.2.4 Ensemble. Though many surrogate models have been stud-
ied,thereisnosinglesurrogatemodelthatconsistentlyperforms
well for all problems [ 16]. To mitigate the issue, the ensemble of
different surrogate models can be considered. Specifically, givenan ensemble model mcomposed of member models
ğ‘š1,...,ğ‘šğ‘˜,
the final output of mfor an input ğ‘¥, denoted with Ë†ğ‘¦m(ğ‘¥), is the
weightedsumofall ğ‘˜memberoutputsas Ë†ğ‘¦m(ğ‘¥)=/summationtext.1ğ‘˜
ğ‘–=1ğ‘¤ğ‘–Ã—Ë†ğ‘¦ğ‘šğ‘–(ğ‘¥)
whereË†ğ‘¦ğ‘šğ‘–(ğ‘¥)istheoutputof ğ‘šğ‘–forğ‘¥andğ‘¤ğ‘–isaweightfor Ë†ğ‘¦ğ‘šğ‘–(ğ‘¥).
FollowingGoeletal .[12],ğ‘¤ğ‘–isdefinedas ğ‘¤ğ‘–=(/summationtext.1ğ‘˜
ğ‘—=1ğ‘’ğ‘—)âˆ’ğ‘’ğ‘–
(ğ‘˜âˆ’1)/summationtext.1ğ‘˜
ğ‘–=1ğ‘’ğ‘–where
ğ‘’ğ‘–is the training error of ğ‘šğ‘–.
Anotheradvantageofusingensemblemodelsisthatwecaneas-
ilycomputethe uncertainty ofapredictionofanensemblemodel.
812Efficient Online Testing for DNN-Enabled Systems using Surrogate-Assisted and Many-Objective Optimization ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Specifically, the uncertainty of Ë†ğ‘¦m(ğ‘¥), denoted with ğ›¿m(ğ‘¥),i sd e -
fined asğ›¿m(ğ‘¥)=ğ‘šğ‘ğ‘¥ğ‘–,ğ‘—(|Ë†ğ‘¦ğ‘šğ‘–(ğ‘¥)âˆ’Ë†ğ‘¦ğ‘šğ‘—(ğ‘¥)|)forğ‘–,ğ‘—âˆˆ{1,2,...,ğ‘˜}
andğ‘–â‰ ğ‘—. In other words, the uncertainty is calculated using the
maximumdifferencebetweentheoutputsofthe ğ‘˜membermodels.
3 PROBLEM DEFINITION
Inthissection,weprovideageneralbutpreciseproblemdescription
regarding test suite generation for DES in the context of online
testing. We use DADS (DNN-enabled ADS) as an example of DES,
but the description can easily be generalized to all DES.
Inonlinetesting,theDADSundertestareembeddedinto adriv-
ingenvironment,ofteninaloopwithasimulatorduetothehigh
cost and risk associated with the real-world testing of vehicles.
Using a simulator also enables the generation of various driving
scenariosusingthesimulatorâ€™scontrollableattributes.Inasimu-lator, the DADS receives sensor data (e.g., an image capturing adriving scene) generated by the simulator and produces controlcommands (e.g., steering angle, throttle, and brake) to drive theego vehicle. Since the control commands actually drive the ego
vehicle being simulated in online testing, predictions generated
by the DNNs of the DADS at time
ğ‘¡impact the sensor data to be
generated after ğ‘¡. Therefore, it is essential to run the simulator for
a specific driving scenario and check if a safety violation occurs.
The goal of online test suite generation forDADSis to generate a
minimalsetofdrivingscenariosthatcausethesystemundertest
to violate as many safety requirements as possible.
Morespecifically,let ğ‘ beadrivingscenariothatdefinestheroad
topology, weather condition, and the trajectory of other mobile ob-jects (e.g., other vehicles and pedestrians) in a virtual environment.
Thedetaileddefinitionof ğ‘ (i.e.,thedefinitionoftestinputspace)
can vary depending on the configurable attributes of the simulator.
ByembeddingaDADS ğ‘‘intoasimulatorandrunningitfor ğ‘ ,at
timeğ‘¡, the simulator generates ğ‘‘â€™s sensor data ğ‘–ğ‘¡, such as an image
capturingthedrivingscene(status) vğ‘ ,ğ‘¡takenbythefront-facing
camera mounted on the ego vehicleâ€™s dashboard. By taking ğ‘–ğ‘¡,ğ‘‘
producescontrols ğ‘‘(ğ‘–ğ‘¡)=(stğ‘¡,acğ‘¡,brğ‘¡)wherestğ‘¡,acğ‘¡,andbrğ‘¡rep-
resent steering, acceleration, and braking commands, respectively.
The simulator then updates vğ‘ ,ğ‘¡+1by taking into account ğ‘‘(ğ‘–ğ‘¡). For
each vğ‘ ,ğ‘¡,wecanverifyifasafetyrequirementisviolatedornot.For
example,regardingthesafetyrequirementoflane-keeping(i.e.,theegovehicleshouldbeinthecenterofthelane),wecanmeasurethedistanceoftheegovehiclefromthecenterofthelanein v
ğ‘ ,ğ‘¡.Ifthe
distanceislargerthanacertainthreshold,thesafetyrequirementis
violated.Ingeneral,let ğ‘…beasetofsafetyrequirementsand ğ‘Ÿ(vğ‘ ,ğ‘¡)
be the degree of the violation for a safety requirement ğ‘Ÿâˆˆğ‘…in
vğ‘ ,ğ‘¡. We say that ğ‘‘violatesğ‘Ÿinğ‘ ifğ‘Ÿ(vğ‘ ,ğ‘¡)>ğœ–ğ‘Ÿfor anyğ‘¡during
the simulation time of ğ‘ , whereğœ–ğ‘Ÿis a threshold for ğ‘Ÿ. Though that
may not be possible, test suite generation attempts to generate aminimal set of test scenarios
TSthat satisfies ğ‘Ÿ(vğ‘ ,ğ‘¡)>ğœ–ğ‘Ÿfor all
ğ‘Ÿâˆˆğ‘…for some test scenarios ğ‘ âˆˆTS.
Testsuite generationfor DADS inonline testingentails several
challenges. First, the test input space is too large to be exhaus-tively explored because there are many attributes having many
optionsthatcan beselectedforgeneratinga certainscenario.For
example,roadtypehasmultipleoptions,suchasstraight,curved,
and cross junction. Second, there are many safety requirements,usually independent of each other. For example, complying with
traffic lights is independent from keeping the center of a lane. This
furtherincreasesthecomplexityoftheproblem.Third,runninga
simulatorforascenarioisoftentime-consumingduetotheinten-
sivecomputationsrequiredtodynamicallyupdatemobileobjects
andrenderdrivingscenesin virtualworlds,withhighfidelity;for
example,inourcasestudy,onescenarioexecutioninonlinetesting
takes 5-10 minutes. Fourth, depending upon the accuracy of thesystemundertest,itmaybeinfeasibletofindascenariocausing
violationsforsomesafetyrequirements.Consideringalimitedtime
budget,ifsuchinfeasibilityisobservedatruntime,itisessentialtodynamicallyandefficientlydistributecomputationresourcestothe
othersafetyrequirements.Lastbutnotleast,DNNsinDADSare
oftendevelopedbyathirdparty,withexpertiseinML,whodoes
not provide access to internal information of the DNNs. Therefore,
online testing should be conducted in a black-box manner without
relying on internal information.
Toaddressthechallengesmentionedabove,asdetailedinSec-
tion 5, we suggest combining two distinct techniques: (1) many-objectivesearchalgorithmstoeffectivelyachievemanyindepen-
dentobjectives(i.e.,causingsafetyviolations)withinalimitedtime
budgetand(2)surrogatemodelsthatmimicthesimulator,tothe
extentpossible, whilebeingcomputationally muchlessexpensive.
Furthermore, since it is black-box, this approach is DNN agnostic,
e.g.,itdoesnotmakeanyassumptionsabouttheDNNarchitecture.
4 RELATED WORK
4.1 Online Testing for DNN-Enabled Systems
In recent years, online testing for DNN-Enabled Systems (DES) has
attracted more attention, especially in the context of ADS.
Gambi et al . [11]presented AsFault, a tool for automatically
generating road networks based on a genetic algorithm to test if
theegovehicleundertestkeepsthecenterofthelanewhiledriving
inasimulatedenvironment.Majumdaretal .[23]presentedPara-
cosm, a language and tool to systematically define and generate
test scenarios for autonomous driving simulations. They used a
fuzzing-basedtestinputgenerationstrategytoachievehighcombi-
natorial coverage for the attribute values that define the test input
space. Tuncali et al . [36]presented Sim-ATAV, a testing framework
to generates test cases, using covering arrays and requirements fal-
sification methods, for autonomous vehicle with machine learning
components. Seymour et al . [31]presents an empirical study, in
whichtheygeneratedtestcases,usingmetamorphicandequivalent
partitioning techniques, to test DADS in black-box settings. Riccio
and Tonella [30]presented DeepJanus, a search-based approach
to generate similar input pairs, which causes the DADS under test,
with a focus on lane keeping, to mispredict for one input and work
finefortheotherinput.Despitethissignificantbodyofwork,no
existing study focuses on performing efficient online testing for
DES, with many objectives (requirements), using surrogate models.
One notable exception is the study of Abdessalem et al . [1]as
theyusedMLmodels(i.e.,decisiontrees)tobetterguidethesearch
process towards promising areas for efficient online testing for
vision-based DADS. Nevertheless, their approach is inherently dif-
ferentfrom ourssince theirmodelsare notsurrogate models that
can replace the computationally expensive fitness evaluations with
813ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Fitash Ul Haq, Donghwan Shin, and Lionel Briand
much less expensive approximations but classification models that
help focus the search on the critical test input space. Furthermore,
they used the classification models outside the search algorithm
(i.e., NSGA-II) to reduce the search space, whereas we use surro-
gate models inside the searchalgorithm to calculate fitness scores
withoutusingexpensivesimulators.Infact,theirapproachisbased
on learnable evolutionary search [ 27], whereas our approach is
basedonsurrogate-assistedoptimization[ 17].Therefore,thetwo
approachesareorthogonal,meaningthatonecaneasilycombine
thetwoapproachestogether;forexample,onecanuseSAMOTA
insteadofNSGA-IIfortheapproachofAbdessalemetal . [1]and
iteratively reduce the search space using decision trees while re-
ducing the execution time of fitness evaluations using surrogate
models in the main search algorithm.
4.2 Surrogate-Assisted Optimization
Addressingcomputationallyexpensiveoptimizationproblemsusing
surrogatemodels(seesection2.2fordetails)hasbeenwidelystudied
in the field of surrogate-assisted optimization [17].
Among many studies, Zhou et al . [45]presented a pioneering
idea of combining global and local surrogate models to acceler-
ate evolutionary optimization. Specifically, they used global sur-
rogate models to filter some promising individuals, and utilizedlocal surrogate models that represent the local fitness landscapein the vicinity of the individual to accelerate convergence. Theexperimental results on multimodal benchmark functions and a
real-worldaerodynamicshapedesignproblemshowedthattheideaof combining global and local searches yields significant savings in
computational cost when compared to alternatives.
Followingupontheideaofcombiningglobalandlocalsearches,
Wang et al . [39]additionally used the prediction uncertainty of
globalsurrogatemodelstoselectcandidatesforactualfitnessevalu-
ations. By providing the actual fitness scores of the most uncertain
candidates,itmaximizestheinformationgainofthesurrogatemod-
els, making them more accurate faster. Recently, Liu et al . [21]
alsoexperimentallyconfirmedthatusingthemostuncertaincandi-
dates in addition to the best predicted candidates was a promising
strategyforsolvingbenchmarkproblemswithupto30dimensions.
However, no existing study addresses surrogate-assisted opti-
mization, combining global and local surrogate models, applied to
the problem of test suite generation for DES online testing.
5 SURROGATE-ASSISTED MANY-OBJECTIVE
SEARCH FOR TEST SUITE GENERATION
Thissectionprovidesasolutiontotheproblemoftestsuitegenera-
tionforDADS,describedinSection3,bycombiningmany-objective
search and surrogate models. In the following subsections, we first
describehowmany-objectivesearchcanbeusedfortheproblem
of test suite generation for DADS. We then present our novel algo-
rithm for surrogate-assisted many-objective search.
5.1Test Suite Generation using Many-Objective
Search
As describedin Section2.1, MOSA[ 29] andFITEST [ 2] havebeen
introducedinthecontextofsoftwaretestingtomaximallycover
individual test targets (e.g., branches). Therefore, we can apply thealgorithmstoourproblembycarefullydefiningasetofcorrespond-
ing test targets (objectives) and fitness functions.
Based on the problem definition in Section 3, we can define
test objectives as violations of safety requirements. Specifically, for
a set of safety requirements ğ‘…={ğ‘Ÿ1,...,ğ‘Ÿğ‘›}and a DADS ğ‘‘, the
objectives to be achieved by a many-objective search algorithm
areğ‘Ÿğ‘–(vğ‘ ,ğ‘¡)>ğœ–ğ‘Ÿğ‘–forallğ‘–=1,...,ğ‘›whereğ‘Ÿğ‘–(vğ‘ ,ğ‘¡)isthedegreeof
violationofğ‘‘forasafetyrequirement ğ‘Ÿğ‘–inscenarioğ‘ attimeğ‘¡and
ğœ–ğ‘Ÿğ‘–is a violation threshold pre-defined by domain experts for each
requirement ğ‘Ÿğ‘–.Inotherwords,thesetofobjectivesisdefinedas
ğ‘‚={ğ‘œ1,...,ğ‘œğ‘›}whereğ‘œğ‘–isğ‘Ÿğ‘–(vğ‘ ,ğ‘¡)>ğœ–ğ‘Ÿğ‘–forğ‘–=1,...,ğ‘›.
Usingthesetofobjectives,wecanapplyMOSAorFITESTwhose
pseudo-code is presented in Algorithm 1. It takes as input a setof objectives
ğ‘‚={ğ‘œ1,...,ğ‘œğ‘›}, a population size ğ‘ğ‘ , and a set of
thresholdsğ¸={ğœ–ğ‘Ÿ1,...,ğœ–ğ‘Ÿğ‘›}; it returns an archive (i.e., a test suite)
ğ´that aims to maximally achieve individual objectives in ğ‘‚.
Algorithm 1: Many-Objective Search for Test Suite Generation
Input :Set of Objectives ğ‘‚
Population Size ğ‘ğ‘ 
Set of Error Threshold ğ¸
Output:Archiveğ´
1Archiveğ´â†âˆ…
2Set of Uncovered Objectives ğ‘ˆâ†ğ‘‚
3Set of Test Cases ğ‘ƒâ†initialPopulation (ğ‘ğ‘ )
4whilenot (stopping-condition) do
5Set of Test Cases ğ‘„â†generateOffspring (ğ‘ƒ)
6Set of Test Cases ğ‘Šâ†calculateFitnessSim (ğ‘ƒâˆªğ‘„)
7ğ´,ğ‘ˆâ†updateArchive (ğ´,ğ‘Š,ğ¸,ğ‘‚ )
8ğ‘ƒâ†generateNextGen (ğ‘Š,ğ‘ˆ)
9returnğ´
The algorithm begins with initializing ğ´, a set of uncovered
objectivesğ‘ˆ,andasetoftestcases(i.e.,testscenariosinourcontext)
ğ‘ƒofthesizeğ‘ğ‘ (lines1â€“3).Untilthestoppingcriterionismet(e.g.,a
predefined computational time budget is exhausted), the algorithm
repeatsthefollowing:(1)generatinganewsetoftestcases ğ‘„using
genetic operators from ğ‘ƒusingcrossover andmutation (line 5), (2)
generating another set of test cases ğ‘Šby merging ğ‘ƒandğ‘„and
calculatingtheirfitnessscoresbyexecutingasimulatorforevery
candidates in ğ‘Š(line 6), (3) updating ğ´andğ‘ˆusingğ‘Šandğ¸such
thatğ‘ˆexcludes the objectives that are covered (achieved) by ğ‘Š
forğ¸andğ´includesthetestcasesfrom ğ´âˆªğ‘Š,whicharebestat
achieving the covered objectives (line 7), and (4) generating thenext generation
ğ‘ƒfromğ‘Šconsidering ğ‘ˆusingselection(line 8).
The algorithm ends by returning ğ´(line 9).
The main differences between MOSA and FITEST are in the
initialPopulation function(line3)andthe generateNextGen function
(line8):MOSAinitializes ğ‘ƒasasetofrandomlygeneratedtestcases
and keeps |ğ‘ƒ|=ğ‘ğ‘ (typicallyğ‘ğ‘ is set to|ğ‘‚|), whereas FITEST uses
an adaptive random generation technique [ 6] to promote initial
diversity and keeps reducing |ğ‘ƒ|as|ğ‘ˆ|decreases.
5.2 Surrogate-Assisted Many-Objective Search
Algorithm1appearstobesuitableforsolvingtheproblemoftest
suite generation for DADS for online testing. However, iteratively
814Efficient Online Testing for DNN-Enabled Systems using Surrogate-Assisted and Many-Objective Optimization ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
evaluatingthefitnessscoresofcandidatetestscenariosusingsimu-
lationsmaytakeaprohibitiveamountoftime,preventingthegener-ationofaneffectivetestsuitewithinareasonabletimebudget.Toad-
dress this, we present a novel algorithm, called Surrogate-Assisted
Many-Objective Testsuite generationAlgorithm (SAMOTA), that
extends Algorithm 1 to effectively utilize surrogate models.
Following state-of-the-art surrogate-assisted optimization algo-
rithms[21,35,39],SAMOTA usesthe ideaofiterating twosearch
phases, namely globalsearch and localsearch. Briefly speaking,
globalsearch(withglobalsurrogatemodels)first exploresthesearch
space by capturing the global outline of the fitness landscape, and
then local search (with local surrogate models) exploitsthe promis-
ingareasfoundbytheglobalsearch.Onlythebestpredictedtest
cases that are found through cooperation between global and lo-
cal search are evaluated through expensive simulations, whose
results will be used to build more accurate surrogate models in the
next iteration,thus iteratively finding morepromising test cases.
This search process continues until the computational budget is
exhausted. Since it is usually difficult to accurately approximate
the whole search space relying on global surrogate models only,
such cooperation between global and local search is more effective
at achieving the search objectives [ 45]. The details of global and
local searches will be provided in Â§ 5.2.1 and Â§ 5.2.2, respectively.
Inadditiontoapplyingthestate-of-the-art,surrogate-assisted
optimization algorithms to the important software engineering
problemoftestsuitegeneration,weaddressitslimitationsinour
context. We observed that these algorithms generate either too
many local surrogate models that tend to degrade performance or
only one local surrogate model that cannot accurately capture the
local fitness landscape of individual promising areas. To addressthe issues, we introduce a novel, clustering-based approach that
generatesonelocalsurrogatemodelperclustercomposedoftest
cases thatbelong tothe same promisingarea. Before wemove on
to the details, we first provide an overview of SAMOTA below.
Similar to Algorithm 1, SAMOTA (whose pseudo-code is shown
inAlgorithm2)takesasinputasetofobjectives ğ‘‚,apopulationsize
ğ‘ğ‘ ,andasetoferrorthresholds ğ¸,plusthemaximumnumbersof
iterations for global search ğ‘”maxand local search ğ‘™max(as stopping
criteria for global and local search), the percentage of test casesto be used for training local surrogate models
ğœ‚, the minimum
numberoftestcasesinacluster ğ‘ğ‘šforlocalsearch,andadatabase
ğ·that keeps all test cases already evaluated by the simulator (if
any);SAMOTAthenreturnsanarchive ğ´asinAlgorithm1andthe
databaseğ·updated during the execution. The updated database
can be used as input for future execution.
The algorithm begins with initializing ğ´, the set of uncovered
objectivesğ‘ˆ,andthesetoftestcases ğ‘ƒofsizeğ‘ğ‘ (lines1-3).Forthe
initializationof ğ‘ƒwhilepromotingdiversity,anadaptiverandom
generation technique [ 6] is used. The fitness scores of the test
cases inğ‘ƒare then computed by executing a simulator (line 4) and
updatesğ´andğ‘ˆusingğ‘ƒandğ¸suchthatğ‘ˆexcludestheobjectives
that are covered (achieved) by ğ‘ƒwith respect to the given error
thresholdsğ¸andğ´includes the test cases from ğ´âˆªğ‘ƒ, which are
bestatachievingthecoveredobjectives(line5).Thealgorithmalso
updatesğ·toincludeğ‘ƒsincethesimulatorisexecutedforalltest
casesinğ‘ƒ(line6).Untilthestoppingcriterionismet,thealgorithm
repeats the surrogate-assisted global search (lines 8â€“11) and theAlgorithm 2: SAMOTA
Input :Set of Objectives ğ‘‚
Population Size ğ‘ğ‘ 
Set of Error Thresholds ğ¸
Max Iteration for Global Search ğ‘”max
Max Iteration for Local Search ğ‘™max
Percentage of Test Cases for Local Search ğœ‚
Minimum Number of Test Cases in Cluster ğ‘ğ‘š
Databaseğ·
Output:Archiveğ´
Updated Database ğ·
1Archiveğ´â†âˆ…
2Set of Uncovered Objectives ğ‘ˆâ†ğ‘‚
3Set of Test Cases ğ‘ƒâ†InitialPopulation (ğ‘ğ‘ )
4ğ‘ƒâ†calculateFitnessSim (ğ‘ƒ)
5ğ´,ğ‘ˆâ†updateArchive (ğ´,ğ‘ƒ,ğ¸,ğ‘‚ )
6ğ·â†updateDatabase (ğ·,ğ‘ƒ)
7whilenot (stopping-condition) do
8Set of Test Cases Ë†ğ‘‡ğ‘”â†GS(ğ·,ğ‘ˆ,ğ‘ ğ‘ ,ğ‘”max,ğ¸)
9Set of Test Cases ğ‘‡ğ‘”â†calculateFitnessSim (Ë†ğ‘‡ğ‘”)
10ğ´,ğ‘ˆâ†updateArchive (ğ´,ğ‘‡ğ‘”,ğ¸,ğ‘‚)
11ğ·â†updateDatabase (ğ·,ğ‘‡ğ‘”)
12Set of Test Cases Ë†ğ‘‡ğ‘™â†LS(ğ·,ğ‘ˆ,ğ‘™max,ğ‘ğ‘š,ğœ‚)
13Set of Test Cases ğ‘‡ğ‘™â†calculateFitnessSim (Ë†ğ‘‡ğ‘™)
14ğ´,ğ‘ˆâ†updateArchive (ğ´,ğ‘‡ğ‘™,ğ¸,ğ‘‚)
15ğ·â†updateDatabase (ğ·,ğ‘‡ğ‘™)
16returnğ´,ğ·
surrogate-assisted local search (lines 12â€“15). For the global search,
the algorithm generates the set of test cases Ë†ğ‘‡ğ‘”that are expected
tosatisfyğ‘ˆwithrespectto ğ¸usingalgorithm GS(line8,detailed
in Â§ 5.2.1), calculates the fitness scores of the test cases in Ë†ğ‘‡ğ‘”by
executing the simulator to generate the set of test cases ğ‘‡ğ‘”that
alsocontainstheiractualfitnessscores(line9),andupdates ğ´,ğ‘ˆ,
andğ·usingğ‘‡ğ‘”, as done for ğ‘ƒ(lines 10-11). For the local search,
the algorithm repeats the same procedures as for the global search,
except that it generates the set of test cases Ë†ğ‘‡ğ‘™, that are expected
to better satisfy ğ‘ˆthanË†ğ‘‡ğ‘”, with respect to ğ¸using algorithm LS
(line 12, detailed in Â§ 5.2.2). The algorithm ends by returning ğ´
andğ·(line 16). Note that |Ë†ğ‘‡ğ‘”|and|Ë†ğ‘‡ğ‘™|decrease as |ğ‘ˆ|decreases,
resultinginfurtherreducingthenumberofexpensiveexecutions
of the simulator.
5.2.1 GS(Global Search). Thisalgorithmaimstoexplorethesearch
space using global surrogate models for uncovered objectives. It
basicallyusesthesamesearchframeworkasAlgorithm1andre-
turns the besttest case for each uncovered objective in terms of
the fitness score predicted by the global surrogate model trained
usingallthetestcasesinthedatabase.Recallthattheresultingtest
caseswill beevaluatedusing thesimulator(line9 inAlgorithm2)
to calculate their actual fitness scores, and the database will beupdated to include the test cases with their actual fitness scores,leading to more accurate surrogate models in the next iteration
ofGS. To further improve the accuracy, GSadditionally finds and
returnsthe mostuncertain testcaseforeachuncoveredobjective
basedontheuncertaintyofthesurrogatemodelpredictions,which
815ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Fitash Ul Haq, Donghwan Shin, and Lionel Briand
canbemeasured,forexample,accordingtothemagnitudeofthe
disagreementamongtheoutputsofthemembersofanensemble
surrogate model as explained in section 2.2.
Specifically,the GSalgorithm(Algorithm3)takesasinputthe
databaseğ·, the set of uncovered objectives ğ‘ˆ, the population size
ğ‘ğ‘ , the maximum number of iterations ğ‘”max, and the set of error
thresholdsğ¸; it returns a set of resulting test cases Ë†ğ‘‡ğ‘”found by
global surrogate models trained using ğ·.Ë†ğ‘‡ğ‘”consists of the most
promising test case for each uncovered objective ğ‘¢âˆˆğ‘ˆand the
most uncertain test case for each ğ‘¢, leading to |Ë†ğ‘‡ğ‘”|â‰¤|ğ‘ˆ|Ã—2.
Algorithm 3: GS (Global Search)
Input :Databaseğ·
Set of Uncovered Objectives ğ‘ˆ
Population Size ğ‘ğ‘ 
Max Iteration ğ‘”max
Set of Error Thresholds ğ¸
Output:Set of Test Cases Ë†ğ‘‡ğ‘”
1Set of Global Surrogates ğ‘€ğ‘”â†trainGlobals (ğ·,ğ‘ˆ)
2Set of Best Test Cases Ë†ğ‘‡ğ‘â†âˆ…
3Set of Most Uncertain Test Cases Ë†ğ‘‡ğ‘›â†âˆ…
4Integer Counter ğ‘–â†0
5Set of Test Cases ğ‘ƒâ†initialPopulation (ğ‘ğ‘ )
6whileğ‘–<ğ‘”maxdo
7Set of Test Cases ğ‘„â†genOffspring (ğ‘ƒ)
8Set of Test Cases ğ‘Šâ†calcFitnessGS (ğ‘ƒâˆªğ‘„,ğ‘€ ğ‘”)
9Ë†ğ‘‡ğ‘,Ë†ğ‘‡ğ‘›,ğ‘ˆâ†update(Ë†ğ‘‡ğ‘,Ë†ğ‘‡ğ‘›,ğ‘Š,ğ‘ˆ,ğ¸)
10ğ‘ƒâ†generateNextGen (ğ‘Š,ğ‘ˆ)
11ğ‘–â†ğ‘–+1
12returnË†ğ‘‡ğ‘âˆªË†ğ‘‡ğ‘›
Thealgorithmbeginswithtrainingthesetofglobalsurrogate
modelsğ‘€ğ‘”(one per an uncovered objective in ğ‘ˆ) using all the test
casesinğ·(line1).Thealgorithmtheninitializesthesetofbesttest
casesË†ğ‘‡ğ‘, the set of most uncertain test cases Ë†ğ‘‡ğ‘›, the counter ğ‘–, and
the set of test cases ğ‘ƒof sizeğ‘ğ‘ (lines 2â€“5). While ğ‘–<ğ‘”max, the
algorithm repeats the following steps: (1) generate the offspring ğ‘„
fromğ‘ƒ(line7),(2)generatethesetoftestcases ğ‘Šbymergingğ‘ƒand
ğ‘„and predicting their fitness scores using ğ‘€ğ‘”while recording the
uncertainty of individual predictions (line 8), (3) update Ë†ğ‘‡ğ‘,Ë†ğ‘‡ğ‘›, and
ğ‘ˆsuchthat Ë†ğ‘‡ğ‘includesthebesttestcasefrom Ë†ğ‘‡ğ‘âˆªğ‘Šforeachğ‘¢âˆˆğ‘ˆ,
Ë†ğ‘‡ğ‘›includesthemostuncertaintestcasefrom Ë†ğ‘‡ğ‘›âˆªğ‘Šforeachğ‘¢âˆˆğ‘ˆ,
andğ‘ˆexcludestheobjectivescoveredby Ë†ğ‘‡ğ‘(line9),(4)generate
the next generation ğ‘ƒfromğ‘Šforğ‘ˆ(line 10), and (5) increase ğ‘–by
1 (line 11). The algorithm ends by returning Ë†ğ‘‡ğ‘”=Ë†ğ‘‡ğ‘âˆªË†ğ‘‡ğ‘›(line 12).
Note that each global surrogate model should be able to provide
theuncertaintyofindividualpredictionsinadditiontopredicted
fitnessscores.Anensemblemodelalreadysatisfiestherequirement
asthedisagreementamongtheoutputsoftheensemblemembers
can be used to measure uncertainty (see section 2.2 for more de-tails). Following the widely used surrogate models in the area of
surrogate-assisted optimization [ 21,39], we combine Kriging, poly-
nomialregression,andradialbasisfunctionnetworkmodelsinto
anensemblesurrogatemodelforglobalsearchtoaccuratelypro-
videfitnessscorepredictionsandeasilycalculatetheuncertainty
of individual predictions.
Figure 1: Illustration of clustering-based, local surrogate
model generation
5.2.2 LS(Local Search). This algorithm aims to exploit promising
areas, found by the global search, using local surrogate models.
For each promising area for each uncovered objective, it finds and
returns the best predicted test case based on a single-objectivesearch. Since inexpensive surrogate models are used for fitness
evaluations, we can use population-based optimization algorithms,
such as Genetic Algorithm [ 41], rather than single-state optimiza-
tion algorithms to increase the search performance. An important
challenge is how to train a local surrogate model that accurately
captures the local fitness landscape of a certain area.
AnapproachproposedbyZhouetal .[45]buildsalocalsurrogate
modelusingthe ğ‘šnearestdatapointsinthedatabaseforeachof
the topğœ‚% individuals (in terms of their actual fitness scores) in
the database. While each surrogate model can intuitively represent
the local fitness landscape in the vicinity of a good individual,the number of the surrogate models can be an issue (especiallyconsideringthegrowthofthedatabase)becausethelocalsearch
shouldbeiteratedforeachindividualanduncoveredobjectiveto
findthebesttestcase.AnotherapproachproposedbyWangetal .
[39]builds one local surrogate model for all top ğœ‚% individuals
at once. While this is clearly better than the former solution in
termsofnumberofsurrogatemodels,thetop ğœ‚%individualscanbe
toowidespread,making thesurrogatemodelunable toaccurately
capture the localfitness landscape.
To address the limitations of existing approaches in our context,
weintroduceaclustering-basedapproachforlocalsurrogatemodel
generation, which combines the benefits of the two approaches
described above by limiting the number of surrogate models while
avoidingthecombinationoftopindividualsthataretoofaraway
from each other. Our approach once again first selects the top
ğœ‚%individuals.Butitthenclusterstheselectedindividualsbased
ontheirvicinityinthefitnesslandscape.Basedontheclustering
results, our approach builds one local surrogate model for each
cluster.TakingFigure1asasimpleuni-dimensionalexamplewhere
the dots denote all test cases in the database and the red circles
indicate the clusters generated for thetop 10 test cases.While the
individualsarewidespreadinthefitnesslandscape,alocalsurrogate
modelisbuiltbasedonthetestcasesineachcluster,toallowthe
local search to exploit the best candidates located in a specific area.
For clustering test cases, we use Hierarchical Density-Based
Spatial Clustering of Applications with Noise (HDBSCAN) [ 25],
with an optional parameter specifying the minimum number of
data points in each cluster. One can select the minimum number
if the minimum amount of training data is already known for a
816Efficient Online Testing for DNN-Enabled Systems using Surrogate-Assisted and Many-Objective Optimization ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
certain surrogate model type to be used; otherwise, the default
value of 5 provided by HDBSCAN can be used.
Algorithm 4: LS (Local Search)
Input :Databaseğ·
Set of Uncovered Objectives ğ‘ˆ
Max Iteration ğ‘™max
Percentage for Training Surrogate Models ğœ‚
Minimum Number of Test Cases in Cluster ğ‘ğ‘š
Output:Set of Test Cases Ë†ğ‘‡ğ‘™
1Set of Test Cases Ë†ğ‘‡ğ‘™â†âˆ…
2foreachObjectiveğ‘¢âˆˆğ‘ˆdo
3Set of Clusters ğ¶â†generateClusters (ğ·,ğœ‚,ğ‘¢,ğ‘ ğ‘š)
4foreachCluster (Set of Test Cases) ğ‘ƒâˆˆğ¶do
5 Surrogate Model ğ‘šğ‘¢â†trainLocal (ğ‘ƒ)
6 Test Case Ë†ğ‘‡ğ‘â†ğ‘›ğ‘¢ğ‘™ğ‘™
7 Integer Counter ğ‘–â†0
8 whileğ‘–<ğ‘™maxdo
9 Set of Test Cases ğ‘„â†genOffspring (ğ‘ƒ)
10 Set of Test Cases ğ‘Šâ†calcFitnessLS (ğ‘ƒâˆªğ‘„,ğ‘š ğ‘¢)
11 Ë†ğ‘‡ğ‘â†updateBestPredicted (Ë†ğ‘‡ğ‘,ğ‘Š)
12 ğ‘ƒâ†generateNextGen (ğ‘Š)
13 ğ‘–â†ğ‘–+1
14 Ë†ğ‘‡ğ‘™â†Ë†ğ‘‡ğ‘™âˆª{Ë†ğ‘‡ğ‘}
15returnË†ğ‘‡ğ‘™
Algorithm4presentsthepseudo-codeforlocalsearch,including
our clustering-based local surrogate model generation. It takes
as input the database ğ·, the set of uncovered objectives ğ‘ˆ, the
maximumnumberofiterations ğ‘™max,thepercentageoftestcasesin
ğ·tobeusedfortraininglocalsurrogatemodels ğœ‚,andtheminimum
numberof datapoints inacluster ğ‘ğ‘š;it returnsa setoftest cases
Ë†ğ‘‡ğ‘™thatareexpectedtobethebestatsatisfying ğ‘ˆaccordingtolocal
surrogate models. Note that Ë†ğ‘‡ğ‘™may contain multiple test cases for
oneobjectiveiftherearemultiplepromisingareasforoneobjective.
Algorithm 4 begins with initializing a set of test cases Ë†ğ‘‡ğ‘™(line 1).
For each uncovered objective ğ‘¢âˆˆğ‘ˆ, the algorithm finds the best
test cases (possibly many if there are many promising areas) to
be added into Ë†ğ‘‡ğ‘™(lines 2â€“14). Specifically, the algorithm generates
clusters,withtheminimumnumberoftestcases ğ‘ğ‘šineachcluster,
fromthetop ğœ‚%testcasesin ğ·1forğ‘¢(line3),trainsalocalsurrogate
model for each cluster (lines 4â€“5), and finds the best predicted test
caseË†ğ‘‡ğ‘using the local surrogate model (lines 6â€“13). The algorithm
ends by returning Ë†ğ‘‡ğ‘™(line 15).
UnlikeGS,LSdoes not use the uncertainty of surrogate modelsâ€™
predictions. Therefore, considering computationally efficiency, we
canuseanyofthenon-ensemblemodelsdescribedinsection2.2.We
will show how to find the best configurationfor LS, including the
surrogatemodeltype,inourempiricalevaluation(seesection6.2).
6 EMPIRICAL EVALUATION
Thissectionreportstheempiricalevaluationofourapproachfor
efficientDNNtestingwhenappliedtoanopen-sourceDADS.Specif-
ically, we investigate the following research questions:
1Ifthenumberofthetop ğœ‚%testcasesin ğ·islessthanğ‘ğ‘š,thenthetop ğ‘ğ‘štestcases
inğ·are used.RQ1:What is the best configuration for LS?
RQ2:Howdoalternativeapproachesfareintermsoftesteffective-
ness?
RQ3:How do alternative approaches fare in terms of test effi-
ciency?
RQ1 aims to find the best configuration for LSbefore we investi-
gatetheeffectivenessandefficiencyofSAMOTA.Asexplainedin
Â§5.2.2,weproposeanewclustering-basedapproachforbetterlocal
surrogate model generation in LS. However, compared to existing
approaches, we need to assess our clustering-based approach in
terms of the effectiveness of LS. Furthermore, its impact may vary
depending on the types of surrogate models (e.g., Kriging, poly-
nomialregression,andradialbasisfunctionnetwork).Toanswer
these questions, we compare the combinations of surrogate model
generation approachesand surrogatemodel typesin termsof the
abilityof LStofindthemostcriticaltestinputsforagiventimebud-
get. Notice that we do not investigate the best configuration for GS
since this has already been investigated in existing studies [ 20,21]
and we will therefore rely on reported results.
Using the best configuration for LSresulting from answering
RQ1, RQ2 and RQ3 aim to investigate the effectiveness and ef-ficiency of SAMOTA, respectively, in comparison to â€œnaiveâ€ ap-
proaches that do not use surrogate models, such as MOSA, FITEST,
and Random Search (with archive). To answer RQ2, we investigate
howmanysafetyviolationsarefoundbytestsuitesgeneratedus-
ingdifferentapproachesgivenatimebudget.ToanswerRQ3,we
investigatehowquicklytargetsafetyviolationsarefoundbytest
suitesgeneratedusingdifferentapproaches.Theanswerswillshow
howeffectiveandefficientSAMOTAcanbebyadaptingtheidea
of surrogate-assisted optimization.
We conducted our evaluation on Ubuntu 18.04 running on Intel
i9-9900K CPU with RTX 2080 Ti (11 GB) and 32 GB memory.
6.1 Case Study Subjects
We use Pylot [ 13], a publicly available DADS, as our case study
subject.Toenablesimulation-basedtesting,wealsouseCARLA[ 7],
a high-fidelity, open-source simulator for ADS.
Pylot is a DADS for developing and testing autonomous vehicle
components (e.g., perception, prediction, planning) on the CARLA
simulatorandreal-worldvehicles[ 13].Givenadrivingenvironment
(either simulated or real), it drives the ego vehicle by controlling
itsacceleration,braking,andsteeringaccordingtoinputdatady-
namically collected though sensors (e.g., camera and LiDAR). To
achieve this, it consists of multiple components providing various
functions of an autonomous vehicle, such as traffic light detection,
lane detection, and object tracking. For each component, Pylot pro-
vides the implementations of state-of-the-art approaches based on
pre-trained DNNs. For example, SSD (Single Shot Detector) [ 22]i s
used for object detection while SORT (Simple Online and Realtime
Tracking) [4] and DeepSORT [42] enable obstacle tracking.
CARLA [7] is an open-source simulator based on the Unreal En-
gine [8], designed to support training, development, and validation
ofADS.CARLAprovideshand-crafted,high-fidelityvirtualmaps
having various static environments, such as different road types
(e.g., straights and curves), different sizes of buildings, different
817ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Fitash Ul Haq, Donghwan Shin, and Lionel Briand
shapesoftrees,anddifferentpositionsfortrafficlights.Suchconfig-
urableattributescanbeusedtodefinethetestinputspaceofDADS.
Inourevaluation,weconsiderasmanyconfigurableattributesas
possible: road type, start/end-point on maps, the presence of other
vehiclesinfront/same/oppositelane,othervehicletypes,vehicle
speed,the densityofpedestrians,thepresenceoftreesandbuild-
ings, time of day, and weather condition. To avoid invalid scenario
generation(e.g.,theroadtypeisâ€˜straightâ€™whilethestart-pointona
map is â€˜at the start of a curve roadâ€™), we use additional pre-defined
constraintsontheattributevalues.Moredetailsareprovidedinthe
supporting materials [37].
ConsideringthecapabilityofCARLAtocomputerelatedmetrics
(e.g.,thedistancebetweenvehicles),weusethefollowingsix(safety)
requirementsforPylot:(1)followthecenterofthelane,(2)avoid
collisionwithothervehicles,(3)avoidcollisionwithpedestrians,
(4) avoid collision with static objects (e.g., traffic signs), (5) abide
by traffic rules (e.g., traffic lights), and (6) reach the destination
within a given time. More details about the requirements and their
implementationsare provided in the supporting materials.
We selected the combination of Pylot and CARLA as our case
study subject since (1) Pylot is an advanced, DNN-based ADS com-
posed of multiple autonomous driving components, (2) Pylot isdesigned to be easily usable in simulated environments createdby CARLA, and (3) both are publicly available. While Apollo
2is
another DADS one could rely on in our investigation, we do not
use it because of compatibility issues (e.g., not compatible with thelatest version of CARLA) and incomplete implementations (e.g., its
camera perception module is not available).
6.2 RQ1: Best Configuration for Local Search
6.2.1 Setup. To answer RQ1, we generate a set of test cases by
executing LSusing different configurations and measure the Local
Search Effectiveness (LSE) of the test set. Since LSaims to return
a set of test cases that are expected to be the best at satisfying
the given search objectives (i.e., violating safety requirements) by
predicting the fitness scores of the test cases, the LSEof a test
set can be measured by its actualfitness scores for all objectives.
Specifically,wemeasurethe LSEofasetoftestcases ğ‘‡asLSE(ğ‘‡)=/summationtext.1
ğ‘œâˆˆğ‘‚max ğ‘¡âˆˆğ‘‡ğ‘“(ğ‘¡,ğ‘œ)
|ğ‘‚|whereğ‘‚is a set of objectives and ğ‘“(ğ‘¡,ğ‘œ)is the
(normalized)actualfitnessscoreofatestcase ğ‘¡âˆˆğ‘‡foranobjective
ğ‘œâˆˆğ‘‚. In other words, we calculate the maximum actual fitness
scoreachievedwhenrunningalltestcasesin ğ‘‡foreachobjective
inğ‘‚and average these scores across all objectives.
Regarding the LSconfigurations, we consider the combinations
of surrogate model types and generation approaches. Surrogatemodel types include KriGing (KG) [
33], Polynomial Regression
(PR) [34], and Radial basis Function network (RF) [ 5]a st h e ya r e
the most widely used in the literature [ 12,21,39]. For RF, we set
thenumberofneuronsinthehiddenlayerto10sinceitgavethe
best accuracy at predicting the fitness scores of test cases in our
preliminary evaluation. Similarly, we set the degree of polynomial
models for PR to 2 based on our preliminary evaluation. Regarding
surrogatemodelgeneration,asalreadydiscussedinÂ§5.2.2,there
arethreedifferentapproachesforasetofdatapoints(i.e.,testcases
with actual fitness scores): (1) build one surrogate model using all
2https://github.com/ApolloAuto/apolloFigure 2: Distribution of LSEvalues for different LS configu-
rations
thedatapoints;(2)buildonesurrogatemodelforeachdatapoint
anditsneighbors ;and(3)buildonesurrogatemodelforeachcluster
afterclustering the data points. The first and second approaches
(i.e.,allandneighbors ) come from existing work [ 39,45] while
thethirdapproachisnewlyproposedinthispaper.However,we
decided to exclude the second approach because it generates toomany surrogate models to process as the number of data pointsprovided to LSincreases duringtheexecution ofSAMOTA. Asa
result, we consider a total six configurations (i.e., the combination
of3surrogatemodeltypesand2surrogatemodelgenerationap-proaches). For simplicity, an LSconfiguration is denoted by
ğ‘‹ğ‘Œ
whereğ‘‹âˆˆ{RF,PR,KG}refers to the surrogate model type and
ğ‘Œâˆˆ{al,cl}refers to the surrogate model generation approach (i.e.,
allandclustering ). For example, KGcldenotes the configuration
thatusesKrigingandthe clustering approachformodelgeneration.
To runLS, we need to set its inputs: the database ğ·, the set
of target objectives ğ‘ˆ, the maximum number of iterations ğ‘™max,
the percentage of data points in ğ·to be used for training local
surrogatemodels ğœ‚,andtheminimumnumberofdatapointsina
clusterğ‘ğ‘š.Togeneratediversetestscenariosin ğ·,weuse4-way
combinatorial coverage for all the attributes used to define the test
input space, resulting in |ğ·|=587. We select ğ‘™max=200, based
on our preliminary evaluations, since increasing ğ‘™maxabove 200
no longer significantly increases the predicted fitness scores ofthe test cases generated by LS. We select
ğœ‚=20% following the
recommendationsofarecentpaper[ 21].Forğ‘ğ‘š,weusethedefault
value of 5 provided by HDBSCAN [25].
Toaccountforrandomnessin LS,werepeattheexperiment20
times. We apply the non-parametric Mannâ€“Whitney U test [ 24]t o
assess the statistical significance of differences in LSEacrossLS
configurations. Since we statistically test five hypotheses for each
LSconfiguration(aswecomparethesix LSconfigurationspairwise),
we use a level of significance ğ›¼=0.05/5=0.01 by applying the
Bonferroni correction [ 40] to reduce the risk of Type 1 errors. We
also measureVargha and Delaneyâ€™s Ë†ğ´ğ´ğµ[38] tocapture the effect
sizeofthedifference,whichcanbetypicallycharacterizedassmall,
medium, and large when the Ë†ğ´ğ´ğµvalue exceeds 0.56, 0.64, and
0.71, respectively. Note that Ë†ğ´ğ´ğµ=1âˆ’Ë†ğ´ğµğ´andË†ğ´ğ´ğµ=Ë†ğ´ğµğ´=0.5
means there is no statistical difference between the two compared
configurations.
6.2.2 Results. Figure 2 shows the distribution of the LSEvalues
forthesix LSconfigurations.Theorangebarandthegreentriangle
in the middle of each box represent the median and the average,
818Efficient Online Testing for DNN-Enabled Systems using Surrogate-Assisted and Many-Objective Optimization ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Table 1:Statistical comparison results forLS configurations
AB ğ‘-value Ë†ğ´ğ´ğµAB ğ‘-value Ë†ğ´ğ´ğµ
ğ‘…ğ¹ğ‘ğ‘™ğ‘…ğ¹ğ‘ğ‘™0.001 0.78ğ‘…ğ¹ğ‘ğ‘™ğ¾ğºğ‘ğ‘™0.162 0.59
ğ‘…ğ¹ğ‘ğ‘™ğ‘ƒğ‘…ğ‘ğ‘™0.015 0.70ğ‘ƒğ‘…ğ‘ğ‘™ğ‘ƒğ‘…ğ‘ğ‘™0.000 0.90
ğ‘ƒğ‘…ğ‘ğ‘™ğ‘…ğ¹ğ‘ğ‘™0.001 0.78ğ¾ğºğ‘ğ‘™ğ‘ƒğ‘…ğ‘ğ‘™0.033 0.67
ğ‘…ğ¹ğ‘ğ‘™ğ¾ğºğ‘ğ‘™0.347 0.54ğ¾ğºğ‘ğ‘™ğ‘ƒğ‘…ğ‘ğ‘™0.000 0.86
ğ¾ğºğ‘ğ‘™ğ‘…ğ¹ğ‘ğ‘™0.019 0.69ğ‘ƒğ‘…ğ‘ğ‘™ğ¾ğºğ‘ğ‘™0.001 0.79
ğ‘…ğ¹ğ‘ğ‘™ğ‘ƒğ‘…ğ‘ğ‘™0.000 0.90ğ‘ƒğ‘…ğ‘ğ‘™ğ¾ğºğ‘ğ‘™0.308 0.55
ğ‘…ğ¹ğ‘ğ‘™ğ‘ƒğ‘…ğ‘ğ‘™0.495 0.50ğ¾ğºğ‘ğ‘™ğ¾ğºğ‘ğ‘™0.003 0.76
ğ‘…ğ¹ğ‘ğ‘™ğ¾ğºğ‘ğ‘™0.001 0.78 - - - -
respectively. Table 1 additionally shows the results of statistical
comparisonsbetweendifferent LSconfigurations.Thecolumns A
andBindicatethetwoconfigurationsbeingcompared.Thecolumns
ğ‘-valueandË†ğ´ğ´ğµindicate the statistical significance and effect size,
respectively, when comparing AandBin terms of LSE.
Let us first compare the two surrogate model generation ap-
proaches, i.e., alandcl, for the same surrogate model type. In
Figure2,forallsurrogatemodeltypes,the clapproachseemsbet-
ter than the alapproach. In Table 1, given a level of significance
ğ›¼=0.01,wecanseethatthedifferencebetween clandalforthe
same surrogate model type is statistically significant in all cases.
Furthermore,the Ë†ğ´ğ´ğµvalueisalwaysgreaterthan0.71,meaning
thatclis largely better than alin terms of LSE. In particular, the
differencebetween PRclandPRalisextreme(ğ‘-value=0.000and
Ë†ğ´ğ´ğµ=0.90).Thisisbecausethe alapproachyieldsoutliersbycon-
sidering all data points at once, thus making the surrogate models
(especiallyPR)inaccurate,whereasthe clapproachdoesnotthanks
to clustering. As a result, for the same surrogate model type, using
theclapproachisclearlybetter,showingthepracticalusefulness
of our clustering approach in local surrogate model generation.
Therankingofthesurrogatemodeltypes,basedontheiraver-
ageLSEvalues over 20 runs, is RFcl,PRcl, andKGcl, respectively.
However, with ğ›¼=0.01, the differences between them are all in-
significant, meaning that it does not make a difference, in terms of
LSE,whether RFcl,PRcl,orKGclisused.Nevertheless,theresults
donotimplythatthereisnosignificantdifferenceamongRF,PR,
andKGforallproblems.Ifpossible,inpractice,itisbetterforen-
gineerstodeterminethebestsurrogatemodeltypefor LSbefore
runningSAMOTA.Whileitrequiresadataset ğ·containingdiverse
testcaseswithactualfitnessscores,suchadatasetcouldbeavail-
ableifthesystemundertestalreadywentthroughsystemtesting
andthetestresultsregardingsafetyrequirementswererecorded.
Otherwise, one can opt for RFclas it is known to provide both
computational efficiency and reasonable training accuracy [ 21]. In
our evaluation, we therefore use RFclfor the remaining RQs.
To conclude, the answer to RQ1 is that our clustering-based ap-
proach (cl) for surrogate model generation is significantly better
than the existing approach ( al) in all cases but there is no practical
difference overall between different surrogate model types. In prac-
tice,itisthereforebettertoexperimentallydeterminethebestlocal
surrogatemodeltypeforagivensystemundertest,whilerelying
onclfor surrogate model generation. Otherwise, RFclcan be the
default option when this is not possible.Table 2: Statistical comparison results for different search
approaches
AB ğ‘-value Ë†ğ´ğ´ğµAB ğ‘-value Ë†ğ´ğ´ğµ
MO FI 0 .377 0.53 SI MO 0 .000 0.77
FI RS 0 .411 0.52 SE MO 0 .000 0.75
SI FI 0 .001 0.76 SI RS 0 .000 0.82
SE FI 0 .002 0.74 SE RS 0 .000 0.81
MO RS 0 .229 0.56 SI SE 0 .210 0.56
6.3 RQ2: Test Effectiveness
6.3.1 Setup. ToanswerRQ2,wegenerateatestsuiteusingSAMOTA
anditsalternatives(e.g.,MOSAandFITEST)forafixedtimebudget
and measure the Test Effectiveness (TE) of the test suite, defined
as the proportion of safety requirements that are violated when
runningthetestsuiteoverthetotalnumberofsafetyrequirements.
TEranges between 0 and 1, where higher values are desirable.
For SAMOTA, if we have a database that keeps test cases and
their actual fitness scores computed in previous testing sessions,
thedatabasecanbeprovidedasinput(seeAlgorithm2).Though
SAMOTA canstart without it,providing a non-emptydatabase as
an initial input can boost the effectiveness of SAMOTA by improv-
ingtheaccuracyofsurrogatemodelsearly.Tobetterunderstand
this, we use two configurations, i.e., SAMOTA starting with an
emptydatabase(SAMOTA-E)andSAMOTAstartingwithaninitial
database (SAMOTA-I). For the initial database, we use 4-way com-
binatorial coverage based on all the attributes used to define the
test input space to generate diverse test cases, as we did for RQ1.
As alternatives to SAMOTA, we use MOSA [ 29] and FITEST [ 2],
astheyarethestate-of-the-artmany-objectivetestsuitegeneration
algorithms. We also use Random Search (RS) that randomly gen-
eratestest casesfor eachiteration, asa baseline.Similar toMOSA
and FITEST, we use an archive in RS so that it keeps the best at
satisfyingindividualobjectivesinthearchiveuntilthesearchends;
the resulting archive is a test suite generated by RS. RS will pro-
videinsightintohoweasythesearchproblemisandwillhelpus
evaluatetheimpactofusing advanced searchalgorithms,suchas
MOSA, FITEST, and SAMOTA, on test effectiveness.
TheinitialpopulationsizeofMOSA,FITEST,andSAMOTAisthe
number of objectives. To be consistent in terms of population size,
wesetthenumberofnewlygeneratedtestcasesateachiterationof
RStobethenumberofobjectives.Fortheotherparameters,suchas
mutation and crossover rates in MOSA, FITEST, and SAMOTA-E/I,
we adapt the default values used by Fraser and Arcuri [10].
To account for randomness in all approaches, we repeat the
experiment 20 times. For each run, we use the same budget of two
hours, as we found that it was long enough to converge in our
preliminaryevaluation.WeapplytheMannâ€“WhitneyUtest[ 24]
to assess the statistical significance of differences in TEamong
approaches. Since we statistically test four hypotheses for eachapproach (as we compare RS, MOSA, FITESET, SAMOTA-E, andSAMOTA-I pairwise), we use a level of significance
ğ›¼=0.05/4=
0.0125 by applying the Bonferroni correction [ 40] as we did for
RQ1.WealsomeasureVarghaandDelaneyâ€™s Ë†ğ´ğ´ğµ[38]tocapture
the effect size of the difference.
819ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Fitash Ul Haq, Donghwan Shin, and Lionel Briand
Figure 3: Distribution of TEvalues for different search ap-
proaches
6.3.2 Results. Figure3showsthedistributionof TEvaluesachieved
by RS, MOSA (MO), FITEST (FI), SAMOTA-E (SE), and SAMOTA-I
(SI)over20runs.Again,theorangebarandthegreentriangleinthe
middle of each box represent the median and average, respectively.
Table2,whoseformatisthesameasTable1,presentstheresultsof
statisticalcomparisonsbetweendifferentapproaches.Noticethat
some safety requirements may never be violated, and therefore
absoluteTEvalues cannot be interpreted; we use these values only
for comparison purposes.
Overall, the results show that SAMOTA-I is the best in terms
of the average TEvalue for 20 runs. With a level of significance
ğ›¼=0.0125,thedifferencebetweenSAMOTA-IandSAMOTA-Eisin-
significant(ğ‘-value=0.210),butthedifferencesbetweenSAMOTA-
I/E and the others are all significant with large effect sizes. This
meansthat,byleveragingsurrogatemodels,SAMOTAcanbesignif-
icantlymoreeffectivethanthestate-of-the-arttestsuitegeneration
approaches and random search in terms of revealing unknown
safety violations within a reasonable time budget.
Interestingly,thedifferencesbetweenMOSAandRSandbetween
FITSETandRSareinsignificant( ğ‘-valuesare0.229and0.411,re-
spectively), meaning that MOSA and FITEST are notsignificantly
better than RS in terms of TE. A detailed analysis of the results
shows that this is because the two-hour time budget is not enough
for MOSA and FITEST to evaluate and evolve candidate test cases
many times; on average, across 20 runs, only around five gener-
ationswerecompletedduringeachrunofMOSAandFITEST.In
contrast, SAMOTA went through more than 800 generations using
global and local surrogate models, within the same time budget,and therefore yielded significantly higher TEvalues than MOSA
andFITESTasaresult.ThisalsoconfirmsthatthesurrogatemodelsofSAMOTAaresufficientlyaccuratetoeffectivelyguidethesearch
towards test cases that cause safety violations. However, we would
expectthedifferencebetweenSAMOTAandMOSAorFITESTto
diminish with a much longer time budget allowing them to go
throughmanymoregenerations.Nevertheless,suchascenariois
unrealistic in practice as SAMOTA is likely to remain significantly
more effective than its alternatives for practical time budgets.
Anotherinterestingresultisthatthereisnostatisticaldifference
betweenSAMOTA-IandSAMOTA-E,meaningthatprovidingan
initial database in SAMOTA does not lead to a significant improve-
mentindetectingsafetyviolations.ThisimpliesthatSAMOTAcan
generate good enough test suites even without an initial database,Figure 4: Test efficiency for different search approaches
animportancepracticalconsideration.InRQ3,wewillfurthercom-
pare SAMOTA-I and SAMOTA-E in terms of test efficiency (i.e.,
how fast safety violations are detected).
Toconclude,theanswertoRQ2isthat,inourcontext,SAMOTA
is significantly more effective than other many-objective search
algorithmstailoredfortestsuitegeneration.Furthermore,SAMOTAcanachieveacceptabletesteffectivenesswithoutaninitialdatabase.
6.4 RQ3: Test Efficiency
6.4.1 Setup. To answer RQ3, we use the same approaches and
setupsasinRQ2(i.e.,SAMOTA-I/E,MOSA,FITEST,andRS).We
generateatestsuiteusingeachapproachandmeasureits execution
timetoachieve specific TEvalues(i.e., 1/6,2/6,..., 6/6asthere are
six safety requirements in total).
To account for randomness, as we did in RQ2, we repeat the
experiment20times.Noticethatwecannotcalculatetheaverage
executiontimefor20runstoachieveaspecific TEvaluebecause
not all 20 runs necessarily achieve such TEvalue (even for TE=
1/6). Therefore, we compute how the average TEvalues for 20 runs
vary over time from 20min to 120min, in steps of 20min.
6.4.2 Results. Figure 4 shows the relationship between the execu-
tiontimeandtheaverage TEvaluesfor20runsacrossallapproaches.
For example, RS is always at the bottom, meaning that, on average,
RS achieves the lowest TEvalues compared to the others over the
same time period.
ComparingSAMOTA-IandSAMOTA-E,wecanseethatSAMOTA-
I achieves higher TEvalues than SAMOTA-E for the first 60 minon
average,butthisdifferencevanishesafter80min.Thisisbecause
thesurrogatemodelsofSAMOTA-Earerelativelyinaccurateinthe
beginning,asnoinitialdatabasewasprovided,buttheygetmore
accurateovertimeasthedatabasegrows.Suchgrowthalsoexplains
whyMOSAachievesahigheraverage TEvaluethanSAMOTA-E
after 20min and why this trend is reversed after 80min.
Comparing SAMOTA-I/E and alternatives, SAMOTA-I is always
at the top, meaning that it is always faster than the alternativesto achieve the same level of test effectiveness. This is the same
forSAMOTA-E,exceptforthefirst40 minwhereitisslowerthan
MOSA for the reason provided above.
To conclude, the answer to RQ3 is that SAMOTA is more effi-
cientthanalternativetestsuitegenerationapproachesusingmany-objectivesearchassoonasitssurrogatemodelsbecomesufficiently
accurate.AninitialdatabasecanboosttheefficiencyofSAMOTA
820Efficient Online Testing for DNN-Enabled Systems using Surrogate-Assisted and Many-Objective Optimization ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
in the initial search phase and allow it to surpass other techniques
right from the start.
6.5 Threats to Validity
SinceweuseaspecificDES(i.e.,Pylot),coupledwithasimulator
(i.e., CARLA), external validity is our main challenge here. How-
ever,PylotandCARLAarerespectivelyrepresentativeofadvanced
DADS and high-fidelity driving simulators, in terms of accuracy,
fidelity, and performance [ 7,13]. Furthermore, no other realistic
DADS, coupled with a high-fidelity simulator, is publicly available
atthispoint,whichisindeedanimpedimenttofurtherexperiments
on this topic. Note that such experiments would likely be highly
computationally-intensive,giventhatittookmorethan300com-
putinghoursinourcase.Nevertheless,furtherexperimentswith
different DES and high-fidelity simulators would be required to
strengthen the generalizability of our results.
We want to remark that the applicability of SAMOTA is not
limitedtoaspecificDESsincenoneofthealgorithms(2-4)assumes
specificDESproperties.Aslongastherearemanysafetyrequire-
ments (possibly independent from each other) for a DES under
testandthefitnessevaluationforeachrequirementisexpensive,
SAMOTA would show promising results as compared to the other
algorithms that do not use surrogate models.
6.6 Data Availability
The replication package of our experiments â€” including the imple-
mentation of search algorithms, simulator, and the details of the
experimental setup â€” is available on Figshare [37].
7 CONCLUSION
In this paper, we present SAMOTA, a novel approach to effectively
and efficiently generate test data for DNN-enabled systems in the
context of online testing. In essence, it provides a strategy to effec-
tivelycombinesurrogate-assistedoptimizationandmany-objective
search. Empirical evaluation results on an advanced DNN-enabled
ADS, with a high-fidelity driving simulator, show that SAMOTA
is significantly more effective and efficient, with a large effect size,
than the state-of-the-art many-objective test suite generation algo-
rithms and random search.
Aspartoffuturework,weplantofurtherinvestigateandexplain
the safety violations detected by our approach; for example, wecan derive association rules between the test scenario attribute
values and the resulting safety violations using association rule
mining algorithms [
15]. We also plan to increase the number of
case studies by using high-fidelity simulators in the domain of
autonomousdrones,suchasPEDRA[ 3]andAirSim[ 32],toincrease
the generalizabilityof our results.
ACKNOWLEDGMENTS
ThisworkhasreceivedfundingfromLuxembourgâ€™sNationalRe-
searchFund(FNR)undergrantBRIDGES2020/IS/14711346/FUNTASY,
the European Research Council under the European Unionâ€™s Hori-
zon 2020 research and innovation programme (grant agreementNo 694277), IEE S.A. Luxembourg, and NSERC of Canada underthe Discoveryand CRCprograms.Donghwan Shinwas alsopar-
tiallysupportedbytheBasicScienceResearchProgrammethroughthe National Research Foundation of Korea (NRF) funded by the
Ministry of Education (2019R1A6A3A03033444).
REFERENCES
[1]RajaBenAbdessalem,ShivaNejati,LionelCBriand,andThomasStifter.2018.
Testingvision-basedcontrolsystemsusinglearnableevolutionaryalgorithms.
In2018IEEE/ACM40thInternationalConferenceonSoftwareEngineering(ICSE).
IEEE, 1016â€“1026.
[2]RajaBenAbdessalem,AnnibalePanichella,ShivaNejati,LionelC.Briand,and
Thomas Stifter. 2018. Testing Autonomous Cars for Feature Interaction Failures
Using Many-Objective Search. In Proceedings of the 33rd ACM/IEEE International
Conference on Automated Software Engineering (Montpellier, France) (ASE 2018).
Association for Computing Machinery, New York, NY, USA, 143â€“154. https:
//doi.org/10.1145/3238147.3238192
[3]Aqeel Anwar and Arijit Raychowdhury. 2020. Autonomous Navigation via Deep
Reinforcement Learning for Resource Constraint Edge Nodes Using Transfer
Learning. IEEEAccess 8(2020),26549â€“26560. https://doi.org/10.1109/ACCESS.
2020.2971172
[4]Alex Bewley, Zongyuan Ge, Lionel Ott, Fabio Ramos, and Ben Upcroft. 2016.
Simple online and realtime tracking. In 2016 IEEE international conference on
image processing (ICIP). IEEE, 3464â€“3468.
[5]David S Broomhead and David Lowe. 1988. Radial basis functions, multi-variable
functionalinterpolationandadaptivenetworks . TechnicalReport.RoyalSignals
and Radar EstablishmentMalvern (United Kingdom).
[6]TsongYuehChen,Fei-ChingKuo,RobertG.Merkel,andT.H.Tse.2010. Adaptive
Random Testing: The ART of test case diversity. Journal of Systems and Software
83, 1 (2010), 60â€“66. https://doi.org/10.1016/j.jss.2009.02.022 SI: Top Scholars.
[7]Alexey Dosovitskiy, German Ros, Felipe Codevilla, Antonio Lopez, and Vladlen
Koltun.2017. CARLA:AnOpenUrbanDrivingSimulator.In Proceedingsofthe1st
Annual Conference on Robot Learning (Proceedings of Machine Learning Research,
Vol. 78), Sergey Levine, Vincent Vanhoucke, and Ken Goldberg (Eds.). PMLR,
1â€“16. https://proceedings.mlr.press/v78/dosovitskiy17a.html
[8] Epic Games. 2019. Unreal Engine. https://www.unrealengine.com[9]
P.JFlemingandR.CPurshouse.2002. Evolutionaryalgorithmsincontrolsystems
engineering: a survey. Control Engineering Practice 10, 11 (2002), 1223â€“1241.
https://doi.org/10.1016/S0967-0661(02)00081-3
[10]Gordon Fraser and Andrea Arcuri. 2013. Whole Test Suite Generation. IEEE
Transactions on Software Engineering 39, 2 (2013), 276â€“291. https://doi.org/10.
1109/TSE.2012.14
[11]AlessioGambi,MarcMueller,andGordonFraser.2019.AutomaticallyTestingSelf-
DrivingCarswithSearch-BasedProceduralContentGeneration.In Proceedingsof
the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis
(Beijing, China) (ISSTA 2019). Association for Computing Machinery, New York,
NY, USA, 318â€“328. https://doi.org/10.1145/3293882.3330566
[12]Tushar Goel, Raphael T Haftka, Wei Shyy, and Nestor V Queipo. 2007. Ensemble
ofsurrogates. StructuralandMultidisciplinaryOptimization 33,3(2007),199â€“216.
https://doi.org/10.1007/s00158-006-0051-9
[13]IonelGog,SukritKalra,PeterSchafhalter,MatthewA.Wright,JosephE.Gonzalez,and Ion Stoica. 2021. Pylot: A Modular Platform for Exploring Latency-Accuracy
Tradeoffs in Autonomous Vehicles. arXiv:2104.07830 [cs.RO]
[14]Fitash Ul Haq, Donghwan Shin, Shiva Nejati, and Lionel C. Briand. 2021. Can
OfflineTestingofDeepNeuralNetworksReplaceTheirOnlineTesting? Empirical
Software Engineering 26, 90 (2021). https://doi.org/10.1007/s10664-021-09982-4
[15]Jochen Hipp, Ulrich GÃ¼ntzer, and Gholamreza Nakhaeizadeh. 2000. Algorithms
for Association Rule Mining â€” a General Survey and Comparison. SIGKDD
Explor. Newsl. 2, 1 (June 2000), 58â€“64. https://doi.org/10.1145/360402.360421
[16]Ruichen Jin, Wei Chen, and Timothy W Simpson. 2001. Comparative studies
ofmetamodellingtechniquesundermultiplemodellingcriteria. Structuraland
multidisciplinary optimization 23, 1 (2001), 1â€“13. https://doi.org/10.1007/s00158-
001-0160-4
[17]Yaochu Jin. 2011. Surrogate-assisted evolutionary computation: Recent advances
andfuturechallenges. SwarmandEvolutionaryComputation 1,2(2011),61â€“70.
https://doi.org/10.1016/j.swevo.2011.05.001
[18]Yaochu Jin and Bernhard Sendhoff. 2009. A systems approach to evolution-ary multiobjective structural optimization and beyond. IEEE Computational
IntelligenceMagazine 4,3(2009),62â€“76. https://doi.org/10.1109/MCI.2009.933094
[19]ShutaoLi,WeiweiSong,LeyuanFang,YushiChen,PedramGhamisi,andJÃ³nAtli
Benediktsson.2019. DeepLearningforHyperspectralImageClassification:An
Overview. IEEE Transactions on Geoscience and Remote Sensing 57, 9 (2019),
6690â€“6709. https://doi.org/10.1109/TGRS.2019.2907932
[20]DudyLim,YaochuJin,Yew-SoonOng,andBernhardSendhoff.2010. GeneralizingSurrogate-AssistedEvolutionaryComputation. IEEETransactionsonEvolutionary
Computation 14, 3 (2010), 329â€“355. https://doi.org/10.1109/TEVC.2009.2027359
[21]Qunfeng Liu, Xunfeng Wu, Qiuzhen Lin, Junkai Ji, and Ka-Chun Wong. 2021. A
novel surrogate-assistedevolutionaryalgorithm withanuncertainty grouping
based infill criterion. Swarm and Evolutionary Computation 60 (2021), 100787.
821ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Fitash Ul Haq, Donghwan Shin, and Lionel Briand
https://doi.org/10.1016/j.swevo.2020.100787
[22]Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed,
Cheng-Yang Fu, and Alexander C Berg. 2016. Ssd: Single shot multibox detector.
InEuropeanconferenceoncomputervision.Springer,21â€“37. https://doi.org/10.
1007/978-3-319-46448-0_2
[23]Rupak Majumdar, Aman Mathur, Marcus Pirron, Laura Stegner, and Damien
Zufferey.2019. Paracosm:ALanguageandToolforTestingAutonomousDriving
Systems. arXiv:1902.01084[cs.SE]
[24]Henry B Mann and Donald R Whitney. 1947. On a test of whether one of
two random variables is stochastically larger than the other. The annals of
mathematical statistics (1947), 50â€“60.
[25]LelandMcInnes,JohnHealy,andSteveAstels.2017.hdbscan:Hierarchicaldensity
based clustering. Journal of Open Source Software 2, 11 (2017), 205.
[26]Phil McMinn. 2011. Search-Based Software Testing: Past, Present and Future. In
2011 IEEE Fourth International Conference on Software Testing, Verification and
Validation Workshops. 153â€“163. https://doi.org/10.1109/ICSTW.2011.100
[27]RyszardSMichalski.2000. Learnableevolutionmodel:Evolutionaryprocesses
guided by machine learning. Machine learning 38, 1 (2000), 9â€“40. https://doi.
org/10.1023/A:1007677805582
[28]Harvey J. Motulsky and Lennart A. Ransnas. 1987. Fitting curves to datausing nonlinear regression: a practical and nonmathematical review. The
FASEBJournal 1,5(1987),365â€“374. https://doi.org/10.1096/fasebj.1.5.3315805
arXiv:https://faseb.onlinelibrary.wiley.com/doi/pdf/10.1096/fasebj.1.5.3315805
[29]Annibale Panichella, Fitsum Meshesha Kifetew, and Paolo Tonella. 2015. Refor-
mulatingBranchCoverageasaMany-ObjectiveOptimizationProblem.In 2015
IEEE 8th International Conference on Software Testing, Verification and Validation
(ICST). 1â€“10. https://doi.org/10.1109/ICST.2015.7102604
[30]VincenzoRiccioandPaoloTonella.2020. Model-BasedExplorationoftheFrontier
of Behaviours for Deep Learning System Testing. In Proceedings of the 28th ACM
JointMeetingonEuropeanSoftwareEngineeringConferenceandSymposiumon
the Foundations of Software Engineering (Virtual Event, USA) (ESEC/FSE 2020).
Association for Computing Machinery, New York, NY, USA, 876â€“888. https:
//doi.org/10.1145/3368089.3409730
[31]JohnSeymour,Dac-Thanh-ChuongHo,andQuang-HungLuu.2021.AnEmpirical
Testing of Autonomous Vehicle Simulator System for Urban Driving. arXiv
preprint arXiv:2108.07910 (2021).
[32]Shital Shah, Debadeepta Dey, Chris Lovett, and Ashish Kapoor. 2018. AirSim:
High-Fidelity Visual and Physical Simulation for Autonomous Vehicles. In Field
and Service Robotics, Marco Hutter and Roland Siegwart (Eds.). Springer Interna-
tional Publishing, Cham, 621â€“635.
[33]Michael L Stein. 2012. Interpolation of spatial data: some theory for kriging.
Springer Science & Business Media.
[34]StephenM Stigler.1974. Gergonneâ€™s 1815paperon thedesign andanalysisof
polynomialregression experiments. HistoriaMathematica 1,4 (1974),431â€“439.
[35]ChaoliSun,YaochuJin,JianchaoZeng,andYangYu.2015. Atwo-layersurrogate-
assisted particle swarm optimization algorithm. Soft computing 19, 6 (2015),
1461â€“1475. https://doi.org/10.1007/s00500-014-1283-z
[36]Cumhur Erkan Tuncali, Georgios Fainekos, Hisahiro Ito, and James Kapinski.
2018. Simulation-basedAdversarialTestGenerationforAutonomousVehicles
withMachineLearningComponents.In 2018IEEEIntelligentVehiclesSymposium
(IV). 1555â€“1562. https://doi.org/10.1109/IVS.2018.8500421
[37]FitashUlHaq,DonghwanShin,andLionelBriand.2022. ReplicationPackageFor
"Efficient Online Testing for DNN-based Systems using Surrogate-Assisted and
Many-Objective Optimization". https://doi.org/10.6084/m9.figshare.16468530
[38]AndrÃ¡s Vargha and Harold D. Delaney. 2000. A Critique and Improvement of
the CL Common Language Effect Size Statistics of McGraw and Wong. Journal
of Educational and Behavioral Statistics 25, 2 (2000), 101â€“132. https://doi.org/10.
3102/10769986025002101arXiv:https://doi.org/10.3102/10769986025002101
[39]H. Wang, Y. Jin, and J. Doherty. 2017. Committee-Based Active Learning for
Surrogate-AssistedParticleSwarmOptimizationofExpensiveProblems. IEEE
Transactions on Cybernetics 47, 9 (2017), 2664â€“2677. https://doi.org/10.1109/
TCYB.2017.2710978
[40]Eric W Weisstein. 2004. Bonferroni correction. https://mathworld. wolfram. com/
(2004).
[41]Darrell Whitley. 1994. A genetic algorithm tutorial. Statistics and computing 4, 2
(1994), 65â€“85. https://doi.org/10.1007/BF00175354
[42]NicolaiWojke,AlexBewley,andDietrichPaulus.2017.Simpleonlineandrealtime
tracking with a deep association metric. In 2017 IEEE International Conference on
Image Processing (ICIP). 3645â€“3649. https://doi.org/10.1109/ICIP.2017.8296962
[43]C. Yang, J. Ding, Y. Jin, and T. Chai. 2020. Offline Data-Driven Multiobjective
Optimization: Knowledge Transfer Between Surrogates and Generation of Final
Solutions. IEEE Transactions on Evolutionary Computation 24, 3 (2020), 409â€“423.
https://doi.org/10.1109/TEVC.2019.2925959
[44]Zhong-Qiu Zhao, Peng Zheng, Shou-Tao Xu, and Xindong Wu. 2019. Object
Detection With Deep Learning: A Review. IEEE Transactions on Neural Networks
andLearning Systems 30,11 (2019),3212â€“3232. https://doi.org/10.1109/TNNLS.
2018.2876865[45]Zongzhao Zhou, Yew Soon Ong, Prasanth B Nair, Andy J Keane, and Kai YewLum. 2006. Combining global and local surrogate models to accelerate evolu-
tionary optimization. IEEE Transactions on Systems, Man, and Cybernetics, Part C
(ApplicationsandReviews) 37,1(2006),66â€“76. https://doi.org/10.1109/TSMCC.
2005.855506
822