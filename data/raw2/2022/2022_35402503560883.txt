Exploring the Under-Explored Terrain of Non-open Source Data
for Software Engineering through the Lens of
Federated Learning
Shriram Shanbhag‚àó
RISHA Lab , Dept. of Computer Science & Engineering
Indian Institute of Technology Tirupati, India
cs20s503@iittp.ac.inSridhar Chimalakonda‚Ä†
RISHA Lab , Dept. of Computer Science & Engineering
Indian Institute of Technology Tirupati, India
ch@iittp.ac.in
ABSTRACT
The availability of open source projects on platforms like GitHub
has led to the wide use of the artifacts from these projects in soft-
ware engineering research. These publicly available artifacts have
been used to train artificial intelligence models used in various
empirical studies and the development of tools. However, these ad-
vancements have missed out on the artifacts from non-open source
projects due to the unavailability of the data. A major cause for
the unavailability of the data from non-open source repositories
is the issue concerning data privacy. In this paper, we propose
using federated learning to address the issue of data privacy to
enable the use of data from non-open source to train AI models
used in software engineering research. We believe that this can
potentially enable industries to collaborate with software engineer-
ing researchers without concerns about privacy. We present the
preliminary evaluation of the use of federated learning to train a
classifier to label bug-fix commits from an existing study to demon-
strate its feasibility. The federated approach achieved an F1 score
of 0.83 compared to a score of 0.84 using the centralized approach.
We also present our vision of the potential implications of the use
of federated learning in software engineering research.
CCS CONCEPTS
‚Ä¢Software and its engineering ‚ÜíCollaboration in software
development .
KEYWORDS
software engineering research, non-open source data, data privacy,
federated learning
ACM Reference Format:
Shriram Shanbhag and Sridhar Chimalakonda. 2022. Exploring the Under-
Explored Terrain of Non-open Source Data for Software Engineering through
the Lens of Federated Learning. In Proceedings of the 30th ACM Joint Euro-
pean Software Engineering Conference and Symposium on the Foundations of
‚àóContribution - Technical Work, Writing
‚Ä†Contribution - Idea, Supervision, Writing
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
ESEC/FSE ‚Äô22, November 14‚Äì18, 2022, Singapore, Singapore
¬©2022 Association for Computing Machinery.
ACM ISBN 978-1-4503-9413-0/22/11. . . $15.00
https://doi.org/10.1145/3540250.3560883Software Engineering (ESEC/FSE ‚Äô22), November 14‚Äì18, 2022, Singapore, Sin-
gapore. ACM, New York, NY, USA, 5 pages. https://doi.org/10.1145/3540250.
3560883
1 INTRODUCTION
Open-source repository mining is one of the most important sources
of data for software engineering research. A platform like GitHub
has over 200 million repositories as of April 2022, with over 44
million being public. The artifacts such as source code, discussion
forums, pull requests, and so on from GitHub projects have been
used in a wide variety of research in the domain of software engi-
neering [3‚Äì5, 17, 20].
Due to the availability of huge amounts of data, AI techniques
are being applied to the data to arrive at insights about the projects,
the developers, and their behaviour and also in building AI based
tools that are aimed at helping the developers [ 14,23,29]. The
availability of huge data has also introduced the scope for the devel-
opment of AI tools aimed at helping the developers by automating
some of the tasks of the software development process, thereby
enabling them to make intelligent decisions and increasing their
efficiency [ 22,23,29,32]. Examples include automated identifica-
tion of non-functional requirements [ 6,29], effort estimation [ 23],
classification of issue reports [ 22], automatic tagging of pull re-
quests [ 14], clone detection [ 32] etc. In addition, machine learning
models have also been used in large-scale empirical studies based
on GitHub artifacts [ 10,24,25]. While these AI models have been
used in tool development and empirical studies, the data used to
train these models largely comes from open-source repositories.
Due to various restrictions, the data from non-open source projects
that include private GitHub repositories and proprietary software
projects by various organizations cannot be used for training.
This lack of access to non-open source repositories prevents the
researchers from leveraging a large amount of non-open source
data for software engineering research. Several factors contribute
to the unavailability of the data from non-open source reposito-
ries. Platforms such as GitHub do not provide access to the data
from private repositories. The projects involving the development
of proprietary software developed by various companies are also
reluctant to share the data from their software projects due to the
issues concerning the mindset of the industry, trust, confidentiality,
and intellectual property concerns [18, 27].
Collaborations between the industry and the researchers can
help overcome this issue to an extent. However, several factors
can hamper the prospects of such collaborations [ 18,27,34]. The
concept of technology transfer discourages researchers that are
1610
ESEC/FSE ‚Äô22, November 14‚Äì18, 2022, Singapore, Singapore Shriram Shanbhag and Sridhar Chimalakonda
focused on knowledge exchange from having collaborations with
the industry [ 34]. The collaborations are generally backed by con-
tracts with several terms and conditions [ 18]. The long-term goals
of the research often do not align with the short-term goals of the
industry [ 27], which introduces an additional impediment to start-
ing a collaboration. Even with collaboration, access to sufficient
data is an issue due to confidentiality, and the terms of the contract
[12]. It must be pointed out that software engineering research
collaborations do exist between academia and the industry. But
largely remain restricted to a few software companies [ 1,9,33]
such as Google, Microsoft, Meta, etc.
Missing out on the data from non-open source projects and
private repositories on GitHub has major downsides in software
engineering research. The research based on GitHub data misses
out on a majority of the GitHub repositories as only around 44 mil-
lion1of the over 200 million repositories on GitHub are public. The
results obtained from open source projects may not generalize well
for industry projects. Many factors such as geography, organization
factors, project characteristics, etc. influence software development
[13]. As an example, Fendler found that the software engineering
practices recommended for the western world did not fit well in the
African context in Namibia [ 8] demonstrating how geographic and
cultural factors influence software development. The type of organi-
zation also influences software development practices. For instance,
startups typically run on tight budgets, high uncertainty, lack of
resources, etc. [ 30] would have different practices and strategies
compared to a large organization with adequate budget, resources,
and teams. Research merely based on the data from publicly avail-
able projects may not be able to reflect these nuances. From the
industry perspective, it may be more desirable for them to have the
results that would include the data from their projects along with
the open source. A scenario where several companies can collab-
oratively use their data to support software engineering research
may generate better results and insights.
In this paper, we present the idea of leveraging federated learning
[19] to use the data from non-open source software projects in
software engineering research.
Our vision is to tap the potential of the largely under-
explored software artifacts and data available in non-open
source context to
‚û∫Incorporate non-open source data in existing soft-
ware engineering research to gain insights that may
either confirm or contradict existing results.
‚û∫Improve existing AI tools developed using models
trained by only using open-source data.
2 FEDERATED LEARNING
Federated learning [ 19] is an approach of distributed machine learn-
ing that enables training on decentralized data spread across devices.
In non-distributed machine learning approaches, the data from dif-
ferent devices is aggregated on a central server and is used for
training the model. In federated learning, however, the model from
a central server is shipped to the device, trained locally, and the
1https://web.archive.org/web/20220320121942/https://github.com/search?q=is:publicupdated model parameters are sent back to the central server. The
updated parameters from different devices are used to update the
model in the server using an appropriate aggregation algorithm.
Since federated learning brings the model over to the device instead
of sending the data over to the server, the data never leaves the
device. Thus it addresses the issues with data privacy and data
ownership to an extent. The potential implications of this have also
led the researchers to study the software development life cycle of
the federated learning systems [ 16]. The earliest use of federated
learning was its application in Google keyboard to collaboratively
learn from different devices running the Android operating system
[11]. Federated learning is being applied to areas where data privacy
is critical such as healthcare [ 26], banking [ 28], smart homes [ 36]
etc. However, the application of federated learning in software engi-
neering largely remains unexplored. Although Wang et al. [ 31] have
explored the use of federated learning for heterogeneous defect
prediction, their primary focus has been on model improvement,
motivating the need for our work.
Since data privacy and confidentiality are a major concern of
the non-open source projects, we see great potential for the use of
federated learning in software engineering research.
3 PRELIMINARY EVALUATION
In this section, we present a preliminary evaluation of the use of
federated learning to train a machine learning model using the data
from software repositories. The goal of our evaluation is to find
out whether the use of federated learning in a model with the data
from software repositories lets us achieve a performance similar to
centralized learning. We evaluated the use of federated learning to
train a model to classify the commits as "bug-fix" commit or not as
proposed by Zafar et al. [ 35] on the dataset shared by the authors.
We first give a brief description of the work by Zafar et al. [ 35], and
then we explain our federated learning approach.
Zafar et al. [ 35] proposed the use of deep neural networks model
called BERT to automatically label commit messages with high
accuracy. They focused on labeling classifying commit messages
as ‚Äúbug-fix‚Äù commit or not. In the paper, the authors proposed the
use of BERT, that can understand the context of commit messages.
They first proposed rules for semantic interpretation of commit
comments. Using the rules, the authors labeled a dataset of 2155
commit messages as bug-fix and non bug-fix commits. The authors
then used this dataset to build a commit classification model by
fine-tuning the pre-trained BERT model. The model achieved a
significant improvement over existing approaches with an accuracy
of 92.2% on the test set.
Figure 1 describes the federated learning approach we used to
train and evaluate the commit classification model. We split the
training dataset provided by Zafar et al. [ 35] into 3 smaller datasets
D1,D2andD3. The number of data points in D1,D2andD3were
1000, 500 and 332 respectively. These datasets in our evaluation
could be considered equivalent to the datasets from private reposi-
tories used to train the models locally. We choose to split the data
unevenly to simulate the likely scenario of different repositories
holding different amounts of data.
The architecture of the model we used is the same as described
by Zafar et al. [ 35] in their paper. We used the BERT uncased model
1611Exploring the Under-Explored Terrain of Non-open Source Data for Software Engineering ... ESEC/FSE ‚Äô22, November 14‚Äì18, 2022, Singapore, Singapore
Figure 1: Federated learning approach we used to train and evaluate the commit classification model. The datasets D1,D2and
D3represent the private repositories
with 12 transformer layers, 12 attention heads, and a hidden layer
size of 768. We added an additional dense layer containing a single
neuron with a sigmoid activation function. We set the learning rate
and maximum sequence lengths to 2e-5 and 512 tokens, respectively,
as mentioned in the original work [ 35]. We call this model the
central model depicted by M1.
We created 3 copies of the model and trained them on the datasets
D1,D2andD3. This can be thought of as sending the model to the
private repositories and training them with the private data. The
batch size of the training data was set to 8, and the models were
trained for 3 epochs as described by Zafar et al. [ 35]. The commit
messages did not have to be pre-processed as BERT already has
a word level tokenizer. The updated parameters of each of these
models, U1,U2, and U3after training was aggregated using the
federated averaging algorithm. This is equivalent to sending the
updated weights from each of the repositories to the central server
for aggregation. The resultant weights from the aggregation were
loaded into the central model to form the updated model M2.
The Federated averaging algorithm used for aggregation was
proposed in a paper by McMahan et al. [ 19] where the method was
experimentally shown to efficiently train high quality models while
minimizing the number of rounds of communication. The equation
to aggregate local models using the federated averaging algorithm
is shown below.
ùë§ùë°+1‚Üêùêæ‚àëÔ∏Å
ùëò=1ùëõùëò
ùëõùë§ùëòùë°+1
Here, ùë§ùë°+1represents the parameters of the central model, ùë§ùëòùë°+1
represents the parameters of the updated local model from the client
k. The parameters of the local model at the client is scaled based on
the proportion of the data points held by the client. The fraction
ùëõùëò
ùëõin the equation accounts for this scaling.4 RESULTS
We evaluated the performance of our model trained using federated
learning on a test dataset provided by Zafar et al. [ 35]. The test
dataset consisted of 324 labeled commit messages. The authors
reported the accuracy of the model as 92.2% on their test set. As no
code for replication of their work was shared in the paper, we imple-
mented the model ourselves using the instructions provided in the
paper. Considering the issues with reproducibility of deep learning
models [ 15], to ensure a fair comparison of the performance of the
federated learning approach, we also trained the model we built in
a centralized approach on all of the training data and evaluated its
performance.
The results of the models trained using the centralized and feder-
ated approaches are summarized in Table 1. The original work [ 35]
had achieved true positives (TP), true negatives (TN), false positives
(FP), and false negatives (FN) of 97, 202, 15, and 10, respectively.
However, the model we trained in the centralized mode was able
to achieve TP, TN, FP, and FN values of 86, 206, 11, and 21, respec-
tively. The accuracy of the centralized approach was 90.1%, with
an F1 score of 0.84. The difference in the accuracy values could be
because of various factors such as framework, hardware, library
versions, etc. that are known to influence the reproducibility [ 7] in
deep learning models. The model trained in the federated approach
was able to achieve TP, TN, FP, and FN values of 90, 197, 20, and 17,
respectively, with an accuracy of 88.6%. The F1 score was 0.83.
To summarize, the federated approach where the central
model did not ever see the data, was able to achieve a
performance ( accuracy=88.6%, F1-score=0.83 ) close to the
centralized approach ( accuracy=90.1%, F1-score=0.84 ).
Although the performance of the federated approach is slightly
lower than the centralized approach, we believe that the results
are promising enough for further exploration as federated learning
provides several advantages concerning privacy preservation.
1612ESEC/FSE ‚Äô22, November 14‚Äì18, 2022, Singapore, Singapore Shriram Shanbhag and Sridhar Chimalakonda
Table 1: Results of the preliminary evaluation
Approach True Positives True Negatives False Positives False Negatives Accuracy F1-Score
Centralized (Zafar et al. [35]) 97 202 15 10 92.2% 0.89
Centralized (our model) 86 206 11 21 90.1% 0.84
Federated 90 197 20 17 88.6% 0.83
5 IMPLICATIONS
Majority of the research on software engineering today is based on
open source data. One of the major impediments to the use of non-
open source data is the data privacy concerns of the organizations
that own them. It is here that we envision the use of federated
learning to address this challenge in software engineering research.
Few of the potential implications of this include:
‚Ä¢The use of federated learning could enable different compa-
nies to collaboratively use their data to support research that
could help improve software development and maintenance.
Currently, this is being done by a select few companies such
as Google, Microsoft, Meta, etc. We see a potential for simi-
lar collaborations from companies across geographies, scale,
and domains to cater to their needs. As an example, the in-
formation technology services companies based out of India
could use data from thousands of their internal projects to
contribute to the research aimed at improving the software
engineering practices in the context of Indian IT services.
‚Ä¢The AI tools developed to solve problems in the software
development domain trained using open source data could
incorporate the data from non-open source domains. Given
the drastic variation in practices between open-source and
industry projects, this could enhance the usefulness of the
tools for the developers in the industry. As an example, a tool
like GitHub Copilot2could be further improved using the
data from private repositories owned by private companies.
This could enhance its utility and quality as the tool would
also learn practices followed in the industry.
‚Ä¢We envision the emergence of the area of "privacy-preserving
software engineering research" with the mechanisms estab-
lished for the private entities to grant the use of their data for
the research. The mechanisms could also be designed to ad-
dress many of the quirks currently associated with industry
research collaborations.
‚Ä¢Replication of existing work with non-open source data
could lead to novel insights that may confirm or challenge
existing results in software engineering research.
‚Ä¢The global nature of open source software development
makes it harder to perform organization and geography-
specific research by mining software repositories. This could
become easier to an extent as non-open source data becomes
available for use.
In summary, we envision a new line of research that integrates
and leverages open and non-open source data, and a wide spectrum
of AI tools for software engineering designed for multiple contexts
such as different geographies, organizations, cultures and domains.
2https://copilot.github.com/6 CHALLENGES
In this paper, we proposed the idea of using the federated learning
approach to utilize the data from industrial and non-open source
projects in software engineering research. However, to get to the
point where researchers could use non-open source data, many
issues/questions require research.
While federated learning approach could protect the privacy of
the organization‚Äôs data, connecting to a central server to send/re-
ceive the model would require some kind of trust to be established
between the researcher and the organization. Establishing con-
nections to a third-party server could pose a security issue. Even
communicating the model updates could possibly reveal sensitive
information [ 21]. Even if federated learning could address the issue
of data privacy, other challenges exist in research industry collabo-
rations. As the data comes from multiple sources, it may not always
be in a format required for training the model. A key challenge
would also include establishing the mechanisms to get the data in
a format required for training at the source.
The data from the clients is never sent to the server, which
ensures data privacy. However, the clients get permission to up-
date the model parameters. This leaves a loophole for malicious
clients to the system to perform model poisoning attack [2]. Mali-
cious clients or clients with low-quality data may negatively affect
the model built using the federated process. Another challenge
would be dealing with the statistical heterogeneity of the data.
Since organizations and software development teams have varying
practices influenced by many factors [ 13], the data may be highly
non-identically distributed. This may add additional complexity.
Federated learning requires frequent transmission of the machine
learning model parameters between the clients and the central
server. The use of large deep learning models with large gradient
vectors resulting from training updates of each client could make
communication very expensive.
7 CONCLUSION
Driven by the need to explore non-open source data, we envisioned
the use of federated learning to enable the use of non-open source
artifacts in software engineering research. We believe that it ad-
dresses a major concern of data privacy that prevents organizations
from granting access to their data for research purposes. We per-
formed a preliminary evaluation of the approach on an existing
study of classifying bug-fix commits using the federated approach,
achieving an F1 score of 0.83 compared to the score of 0.84 from
the centralized approach. Furthermore, we presented the possible
implications of our work, which include the evolution of novel AI
tools based on open and non-open source data and the emergence
of areas such as context-specific and privacy-preserving software
engineering research.
1613Exploring the Under-Explored Terrain of Non-open Source Data for Software Engineering ... ESEC/FSE ‚Äô22, November 14‚Äì18, 2022, Singapore, Singapore
REFERENCES
[1]Saleema Amershi, Andrew Begel, Christian Bird, Robert DeLine, Harald Gall, Ece
Kamar, Nachiappan Nagappan, Besmira Nushi, and Thomas Zimmermann. 2019.
Software engineering for machine learning: A case study. In 2019 IEEE/ACM 41st
International Conference on Software Engineering: Software Engineering in Practice
(ICSE-SEIP) . IEEE, 291‚Äì300. https://doi.org/10.1109/ICSE-SEIP.2019.00042
[2]Eugene Bagdasaryan, Andreas Veit, Yiqing Hua, Deborah Estrin, and Vitaly
Shmatikov. 2020. How to backdoor federated learning. In International Conference
on Artificial Intelligence and Statistics . PMLR, 2938‚Äì2948.
[3]Sebastian Baltes, Richard Kiefer, and Stephan Diehl. 2017. Attribution required:
Stack overflow code snippets in GitHub projects. In 2017 IEEE/ACM 39th Interna-
tional Conference on Software Engineering Companion (ICSE-C) . IEEE, 161‚Äì163.
https://doi.org/10.1109/ICSE-C.2017.99
[4]Tegawend√© F Bissyand√©, David Lo, Lingxiao Jiang, Laurent R√©veillere, Jacques
Klein, and Yves Le Traon. 2013. Got issues? who cares about it? a large
scale investigation of issue trackers from github. In 2013 IEEE 24th interna-
tional symposium on software reliability engineering (ISSRE) . IEEE, 188‚Äì197.
https://doi.org/10.1109/ISSRE.2013.6698918
[5]J√ºrgen Cito, Gerald Schermann, John Erik Wittern, Philipp Leitner, Sali Zumberi,
and Harald C Gall. 2017. An empirical analysis of the docker container ecosystem
on github. In 2017 IEEE/ACM 14th International Conference on Mining Software
Repositories (MSR) . IEEE, 323‚Äì333. https://doi.org/10.1109/MSR.2017.67
[6]Jane Cleland-Huang, Raffaella Settimi, Xuchang Zou, and Peter Solc. 2007. Auto-
mated classification of non-functional requirements. Requirements engineering
12, 2 (2007), 103‚Äì120. https://doi.org/10.1007/s00766-007-0045-1
[7]Matt Crane. 2018. Questionable answers in question answering research: Repro-
ducibility and variability of published results. Transactions of the Association for
Computational Linguistics 6 (2018), 241‚Äì252. https://doi.org/10.1162/tacl_a_00018
[8]Jens Fendler and Heike Winschiers-Theophilus. 2010. Towards contextualised
software engineering education: an African perspective. In Proceedings of the 32nd
ACM/IEEE International Conference on Software Engineering-Volume 1 . 599‚Äì607.
https://doi.org/10.1145/1806799.1806888
[9]Aakash Goel, Bhuwan Chopra, Ciprian Gerea, Dhr√∫v M√°t√°ni, Josh Metzler, Fahim
Ul Haq, and Janet Wiener. 2014. Fast database restarts at facebook. In Proceedings
of the 2014 ACM SIGMOD international conference on Management of data . 541‚Äì549.
https://doi.org/10.1145/2588555.2595642
[10] Junxiao Han, Emad Shihab, Zhiyuan Wan, Shuiguang Deng, and Xin Xia. 2020.
What do programmers discuss about deep learning frameworks. Empirical Soft-
ware Engineering 25, 4 (2020), 2694‚Äì2747. https://doi.org/10.1007/s10664-020-
09819-6
[11] Andrew Hard, Kanishka Rao, Rajiv Mathews, Swaroop Ramaswamy, Fran√ßoise
Beaufays, Sean Augenstein, Hubert Eichner, Chlo√© Kiddon, and Daniel Ram-
age. 2018. Federated learning for mobile keyboard prediction. arXiv preprint
arXiv:1811.03604 (2018).
[12] Regina Hebig, Truong Ho Quang, Michel RV Chaudron, Gregorio Robles, and
Miguel Angel Fernandez. 2016. The quest for open source projects that use UML:
mining GitHub. In Proceedings of the ACM/IEEE 19th International Conference on
Model Driven Engineering Languages and Systems . 173‚Äì183. https://doi.org/10.
1145/2976767.2976778
[13] Rashina Hoda, Muhammad Ali Babar, Yogeshwar Shastri, and Humaa Yaqoob.
2016. Socio-cultural challenges in global software engineering education. IEEE
Transactions on Education 60, 3 (2016), 173‚Äì182. https://doi.org/10.1109/TE.2016.
2624742
[14] Jing Jiang, Qiudi Wu, Jin Cao, Xin Xia, and Li Zhang. 2021. Recommending tags
for pull requests in GitHub. Information and Software Technology 129 (2021),
106394. https://doi.org/10.1016/j.infsof.2020.106394
[15] Chao Liu, Cuiyun Gao, Xin Xia, David Lo, John Grundy, and Xiaohu Yang. 2021.
On the Reproducibility and Replicability of Deep Learning in Software Engineer-
ing. ACM Transactions on Software Engineering and Methodology (TOSEM) 31, 1
(2021), 1‚Äì46. https://doi.org/10.1145/3477535
[16] Sin Kit Lo, Qinghua Lu, Chen Wang, Hye-Young Paik, and Liming Zhu. 2021.
A systematic literature review on federated machine learning: From a software
engineering perspective. ACM Computing Surveys (CSUR) 54, 5 (2021), 1‚Äì39.
https://doi.org/10.1145/3450288
[17] Wanwangying Ma, Lin Chen, Xiangyu Zhang, Yuming Zhou, and Baowen Xu.
2017. How do developers fix cross-project correlated bugs? a case study on
the github scientific python ecosystem. In 2017 IEEE/ACM 39th International
Conference on Software Engineering (ICSE) . IEEE, 381‚Äì392. https://doi.org/10.
1109/ICSE.2017.42
[18] Silverio Mart√≠nez-Fern√°ndez and Helena Martins Marques. 2014. Practical ex-
periences in designing and conducting empirical studies in industry-academiacollaboration. In Proceedings of the 2nd International Workshop on Conducting
Empirical Studies in Industry . 15‚Äì20. https://doi.org/10.1145/2593690.2593696
[19] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and
Blaise Aguera y Arcas. 2017. Communication-efficient learning of deep net-
works from decentralized data. In Artificial intelligence and statistics . PMLR,
1273‚Äì1282.
[20] Meiyappan Nagappan, Romain Robbes, Yasutaka Kamei, √âric Tanter, Shane McIn-
tosh, Audris Mockus, and Ahmed E Hassan. 2015. An empirical study of goto in
C code from GitHub repositories. In Proceedings of the 2015 10th Joint Meeting on
Foundations of Software Engineering . 404‚Äì414. https://doi.org/10.1145/2786805.
2786834
[21] Milad Nasr, Reza Shokri, and Amir Houmansadr. 2019. Comprehensive privacy
analysis of deep learning: Passive and active white-box inference attacks against
centralized and federated learning. In 2019 IEEE symposium on security and privacy
(SP). IEEE, 739‚Äì753. https://doi.org/10.1109/SP.2019.00065
[22] Nitish Pandey, Debarshi Kumar Sanyal, Abir Hudait, and Amitava Sen. 2017.
Automated classification of software issue reports using machine learning tech-
niques: an empirical study. Innovations in Systems and Software Engineering 13, 4
(2017), 279‚Äì297. https://doi.org/10.1007/s11334-017-0294-1
[23] Przemyslaw Pospieszny, Beata Czarnacka-Chrobot, and Andrzej Kobylinski. 2018.
An effective approach for software project effort and duration estimation with
machine learning algorithms. Journal of Systems and Software 137 (2018), 184‚Äì196.
https://doi.org/10.1016/j.jss.2017.11.066
[24] Mohammad Masudur Rahman and Chanchal K Roy. 2014. An insight into the
pull requests of github. In Proceedings of the 11th working conference on mining
software repositories . 364‚Äì367. https://doi.org/10.1145/2597073.2597121
[25] Baishakhi Ray, Daryl Posnett, Vladimir Filkov, and Premkumar Devanbu. 2014.
A large scale study of programming languages and code quality in github. In
Proceedings of the 22nd ACM SIGSOFT international symposium on foundations of
software engineering . 155‚Äì165. https://doi.org/10.1145/2635868.2635922
[26] Ali Raza, Kim Phuc Tran, Ludovic Koehl, and Shujun Li. 2022. Designing ecg
monitoring healthcare system with federated transfer learning and explainable
ai.Knowledge-Based Systems 236 (2022), 107763. https://doi.org/10.1016/j.knosys.
2021.107763
[27] Per Runeson. 2012. It Takes Two to Tango‚ÄìAn Experience Report on Industry‚Äì
Academia Collaboration. In 2012 IEEE Fifth International Conference on Software
Testing, Verification and Validation . IEEE, 872‚Äì877. https://doi.org/10.1109/ICST.
2012.190
[28] Geet Shingi. 2020. A federated learning based approach for loan defaults predic-
tion. In 2020 International Conference on Data Mining Workshops (ICDMW) . IEEE,
362‚Äì368. https://doi.org/10.1109/ICDMW51313.2020.00057
[29] John Slankas and Laurie Williams. 2013. Automated extraction of non-functional
requirements in available documentation. In 2013 1st International workshop
on natural language analysis in software engineering (NaturaLiSE) . IEEE, 9‚Äì16.
https://doi.org/10.1109/NAturaLiSE.2013.6611715
[30] Michael Unterkalmsteiner, Pekka Abrahamsson, Xiaofeng Wang, Anh Nguyen-
Duc, Syed QA Shah, Sohaib Shahid Bajwa, Guido H Baltes, Kieran Conboy, Eoin
Cullina, Denis Dennehy, et al .2016. Software startups‚Äìa research agenda. e-
Informatica Software Engineering Journal 10, 1 (2016), 89‚Äì123. https://doi.org/10.
5277/e-Inf160105
[31] Aili Wang, Yutong Zhang, and Yixin Yan. 2021. Heterogeneous Defect Prediction
Based on Federated Transfer Learning via Knowledge Distillation. IEEE Access 9
(2021), 29530‚Äì29540. https://doi.org/10.1109/ACCESS.2021.3058886
[32] Martin White, Michele Tufano, Christopher Vendome, and Denys Poshyvanyk.
2016. Deep learning code fragments for code clone detection. In 2016 31st
IEEE/ACM International Conference on Automated Software Engineering (ASE) .
IEEE, 87‚Äì98. https://doi.org/10.1145/2970276.2970326
[33] Laurie Williams, Gabe Brown, Adam Meltzer, and Nachiappan Nagappan. 2011.
Scrum+ engineering practices: Experiences of three microsoft teams. In 2011
International Symposium on Empirical Software Engineering and Measurement .
IEEE, 463‚Äì471. https://doi.org/10.1109/ESEM.2011.65
[34] Claes Wohlin. 2013. Empirical software engineering research with industry: Top
10 challenges. In 2013 1st international workshop on conducting empirical studies
in industry (CESI) . IEEE, 43‚Äì46. https://doi.org/10.1109/CESI.2013.6618469
[35] Sarim Zafar, Muhammad Zubair Malik, and Gursimran Singh Walia. 2019. To-
wards standardizing and improving classification of bug-fix commits. In 2019
ACM/IEEE International Symposium on Empirical Software Engineering and Mea-
surement (ESEM) . IEEE, 1‚Äì6. https://doi.org/10.1109/ESEM.2019.8870174
[36] Yang Zhao, Jun Zhao, Linshan Jiang, Rui Tan, Dusit Niyato, Zengxiang Li,
Lingjuan Lyu, and Yingbo Liu. 2020. Privacy-preserving blockchain-based feder-
ated learning for IoT devices. IEEE Internet of Things Journal 8, 3 (2020), 1817‚Äì1829.
https://doi.org/10.1109/JIOT.2020.3017377
1614