Causality in Configurable Software Systems
Clemens Dubslaff
clemens.dubslaff@tu-dresden.de
Centre for Tactile Internet with Human-in-the-Loop (CeTI)
Technische UniversitÃ¤t Dresden
Dresden, GermanyKallistos Weis
kallistos@cs.uni-saarland.de
Saarland University
Saarland Informatics Campus
SaarbrÃ¼cken, Germany
Christel Baier
christel.baier@tu-dresden.de
Technische UniversitÃ¤t Dresden
Dresden, GermanySven Apel
apel@cs.uni-saarland.de
Saarland University
Saarland Informatics Campus
SaarbrÃ¼cken, Germany
ABSTRACT
Detecting and understanding reasons for defects and inadvertent
behavior in software is challenging due to their increasing com-
plexity. In configurable software systems, the combinatorics that
arises from the multitude of features a user might select from adds
a further layer of complexity. We introduce the notion of feature
causality, which is based on counterfactualreasoning and inspired
by the seminal definition of actual causality by Halpern and Pearl.
Featurecausalityoperatesatthelevelofsystemconfigurationsand
is capable of identifying features and their interactions that are the
reason for emerging functional and non-functional properties. We
present various methods to explicate these reasons, in particular
well-established notions of responsibility andblamethat we ex-
tendtothefeature-orientedsetting.Establishingacloseconnection
of feature causality to prime implicants, we provide algorithmsto effectively compute feature causes and causal explications. By
means of an evaluation on a wide range of configurable software
systems,includingcommunitybenchmarksandreal-worldsystems,
we demonstrate the feasibility of our approach: We illustrate how
our notion of causality facilitates to identify root causes, estimate
the effects of features, and detect feature interactions.
ACM Reference Format:
ClemensDubslaff,KallistosWeis,ChristelBaier,andSvenApel.2022.Causal-
ity in Configurable Software Systems. In 44thInternationalConferenceon
Software Engineering (ICSE â€™22), May 21â€“29, 2022, Pittsburgh, PA, USA. ACM,
New York, NY, USA, 13 pages. https://doi.org/10.1145/3510003.3510200
1 INTRODUCTION
Configurablesoftwaresystemsofferawidevarietyofconfiguration
options that control the activation of features desired by the user
and that influence critical functional and non-functional properties
such as performance. The often huge configuration spaces render
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Â© 2022 Association for Computing Machinery.
ACM ISBN 978-1-4503-9221-1/22/05...$15.00
https://doi.org/10.1145/3510003.3510200the detection, prediction, and explanation of defects and inadver-
tentbehaviorchallengingtasks.Whiletherearespecificallytailored
analysis methods to tackle this challenge [ 85], research on their
explainability is still in its infancy [ 8]. The potentially exponential
number of system configurations and corresponding analysis re-
sults, bug reports, or other feature-dependent properties demand
techniques for a meaningful and feasible interpretation.
In this paper, we present a set of fundamental concepts and
methods to identify and interpret properties of configurable sys-
temsattheleveloffeatures bycausalreasoning. We introduce the
notion of feature causes as feature selections that are the reason
for emergent system behaviors. Our notion of feature causality is
inspired by the seminal counterfactual definition of actualcausal-
ityby Halpern and Pearl [ 45,46]. Relevant analysis and reasoning
tasksthatweaddressincludetodeterminefeaturesthatcauseabug,
the degree to which some configurations are responsible for bad
system performance, or which features necessarily have to interact
for inadvertent behavior.
Since features correspond to system functionalities specified by
software engineers, they often have a dedicated meaning in the
target application domain [ 4]. To this end, defects (and other be-
haviors of interest) detected at the level of features can provide
important insights for the resolution of variabilitybugs [1,40,72]
andconfiguration-dependent behavior [44,63,77,78]. As such, they
are certainly more informative and actionable than low-level pro-
gramtracesalone.Developersmaychoosetofocusonthosefeature
implementations identified as root causes of bugs or simply disal-
low or coordinate the activation of certain features when defects
are related to them.
Our presented techniques are generic in the sense that they
are neither language-, architecture-, nor environment-specific and
applicablewithinanyeffectivemethodtoanalyzeortestvariability-
aware properties. To this end, causal reasoning on both variability-
aware white-box and black-box analyses is supported. This com-
plements existing causal reasoning techniques for the detection of
root causes: Approaches such as delta-debugging [ 24,95], causal
testing [51], or causal trace analysis [ 11] require a white-box anal-
ysis that operates at the level of code and are not variability-aware.
Hence,theyusuallywouldhavetobeappliedonamultitudeofsys-temconfigurationsforavariability-awarecausalanalysis,suffering
from a combinatorial blowup. We envision applications of feature
causality at those development phases where analysis methods are
3252022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:52:58 UTC from IEEE Xplore.  Restrictions apply. used, for instance, in software product line engineering. Also in
production-level deployments our techniques shall be useful to
optimize software through causally relevant configurations.
Evaluation. We present algorithms to compute feature causes,
represent, and interpret them by means of concise logic formu-las, feature interactions, and responsibility andblame[
17]. Our
prototypical implementation relies on binary decision diagrams
(BDDs)[13] and the computation of prime implicants using the de-
facto standard two-level logic minimizer Espresso [ 61]. By means
ofananalysisofseveralconfigurablesystems,includingcommunity
benchmarks and real-world systems, we investigate feature causes
and their properties. We demonstrate that our notion of featurecauses and methods to represent them help to pinpoint features
relevantfortheconfigurablesystemâ€™spropertiesandillustratehow
feature interactions can be detected and quantified.
Contributions. In summary, our contributions are:
â€¢We introduce the notion of feature causality inspired by the
well-establishedcounterfactualdefinitionofactualcausalityby
Halpern and Pearl [45, 46].
â€¢We show that feature causes coincide with certain prime impli-
cants, leading to an algorithm to compute all feature causes.
â€¢Weprovidemethodstointerpretandrepresentfeaturecausesby
propositional formulas, responsibility and blame, and potential
feature interactions.
â€¢We offer a BDD-based prototype to compute and represent
feature causes and feature interactions.
â€¢We conduct several experiments illustrating how to determine
and reason about feature causes in different realistic settings.
Supplement. Proofs of the theoretical statements are included
in [30]. The source code of our implementation and raw data to
reproduce our experiments are publicly available [36].
2 BACKGROUND
In this section, we revisit basic concepts and notions from logics
and configurable systems used throughout the paper.
Interpretations. Apartialinterpretation over a set ğ‘‹is a partial
mapping ğœ•:ğ‘‹â‡€{true,false}.Wedenoteby supp(ğœ•)thesupport
ofğœ•,i.e.,thesetofallelements ğ‘¥âˆˆğ‘‹whereğœ•(ğ‘¥)isdefined.Wesay
thatğœ•is atotal interpretation ifsupp(ğœ•)=ğ‘‹and denote by Î”(ğ‘‹)
andÎ˜(ğ‘‹)the set of partial and total interpretations, respectively.
Given a partial interpretation ğœ•âˆˆÎ”(ğ‘‹), we define its semantics
/llbracketğœ•/rrbracketâŠ†Î˜(ğ‘‹)as the set of all total interpretations ğœƒâˆˆÎ˜(ğ‘‹)where
for allğ‘¥âˆˆsupp(ğœ•)we have ğœ•(ğ‘¥)=ğœƒ(ğ‘¥). We say that ğœ•âˆˆÎ”(ğ‘‹)
coversğœ•/primeâˆˆÎ”(ğ‘‹)if/llbracketğœ•/prime/rrbracketâŠ†/llbracketğœ•/rrbracket. For a set of partial interpretations
PâŠ†Î”(ğ‘‹),wedefine /llbracketP/rrbracket=/uniontext.1
ğœ•âˆˆP/llbracketğœ•/rrbracket.Theğ‘¥-expansion ofapartial
interpretation ğœ•âˆˆÎ”(ğ‘‹)is the partial interpretation ğœ•â†‘ğ‘¥âˆˆÎ”(ğ‘‹)
wheresupp(ğœ•â†‘ğ‘¥)=supp(ğœ•)\{ğ‘¥}and where ğœ•â†‘ğ‘¥(ğ‘¦)=ğœ•(ğ‘¦)for all
ğ‘¦âˆˆsupp(ğœ•)\{ğ‘¥}. For a set of total interpretations TâŠ†Î˜(ğ‘‹),a n
implicant ofTis a partial interpretation ğœ•âˆˆÎ”(ğ‘‹)where /llbracketğœ•/rrbracketâŠ†T.
We callğœ•aprime implicant ifğœ•is minimal, i.e., /llbracketğœ•â†‘ğ‘¥/rrbracket/notsubseteqlTfor all
ğ‘¥âˆˆsupp(ğœ•).
Propositional logics. Apropositional logic formula over a set ğ‘‹is
an expression defined by the grammar
ğœ™=true|false|ğ‘¥|Â¬ğœ™|ğœ™âˆ§ğœ™|ğœ™âˆ¨ğœ™email system
sign encryption
Caesar AES RSA
Figure 1: Feature diagram for the email system example
whereğ‘¥ranges over ğ‘‹. Thelength|ğœ™|of a formula ğœ™is recursively
definedby |true|=|false|=|ğ‘¥|=1,|Â¬ğœ™|=|ğœ™|+1,and|ğœ™0âˆ§ğœ™1|=
|ğœ™0âˆ¨ğœ™1|=|ğœ™0|+|ğœ™1|+1.Forapartialinterpretation ğœ•âˆˆÎ”(ğ‘‹),w e
writeğœ•|=ğœ™if eitherğœ™=true,ğœ™=ğ‘¥âˆˆsupp(ğœ•)andğœ•(ğ‘¥)=true,
ğœ™=Â¬ğœ“and notğœ•|=ğœ“,ğœ™=ğœ™0âˆ§ğœ™1andğœ•|=ğœ™0andğœ•|=ğœ™1, and
ğœ™=ğœ™0âˆ¨ğœ™1andğœ•|=ğœ™0orğœ•|=ğœ™1. The semantics of ğœ™is the set of
all satisfying total interpretations /llbracketğœ™/rrbracket={ğœƒâˆˆÎ˜(ğ‘‹):ğœƒ|=ğœ™}.
Configurablesystems. A widely adopted concept to model con-
figurable systems is by means of features [ 4].Featuresencapsulate
optional or incremental units of functionality [ 94] and are used
to describe commonalities and variabilities of whole families of
systems. At an abstract level, we fix a set ğ¹of Boolean configu-
ration options where each element corresponds to some featureof the system. We call a total interpretation
ğœƒâˆˆÎ˜(ğ¹)overğ¹a
configuration, which we usually describe by listing the selectedfeatures, i.e., the features
ğ‘¥âˆˆğ¹whereğœƒ(ğ‘¥)=true. The set of
Valid configurations VâŠ†Î˜(ğ¹)comprises those configurations for
whichthereexistsacorrespondingsystemimplementation,usually
specified by a feature diagram [54]. A partial interpretation over ğ¹
is calledpartial configuration.
Example2.1. As the running example, consider a simple email
systemoverfeatures ğ¹={ğ‘š,ğ‘ ,ğ‘’,ğ‘,ğ‘,ğ‘Ÿ },formalizingthebasee mail
system functionality, optional features for signing and encryption,
and encryption methods Caesar,AES, andRSA. For the encryption
features,weassumethatexactlyonecanbeselected.Thedescribed
variability constraints for the email system are specified in the
feature diagram shown in Figure 1, leading to valid configurations
V={ğ‘š,ğ‘šğ‘’ğ‘,ğ‘šğ‘’ğ‘,ğ‘šğ‘’ğ‘Ÿ,ğ‘šğ‘ ,ğ‘šğ‘ ğ‘’ğ‘,ğ‘šğ‘ ğ‘’ğ‘,ğ‘šğ‘ ğ‘’ğ‘Ÿ }.
3 FEATURE CAUSALITY
The notion of causality has been extensively studied in philosophy,
social sciences, and artificial intelligence [ 37,42,66,92]. We focus
onactual causality, describing binary causal relationships between
cause events ğ¶and effect events ğ¸. Halpern and Pearl formalized
actual causality based on the concept of counterfactualdependen-
cies[57] using a structural-equation approach [ 45â€“47]. The idea
of counterfactual reasoning [ 90] relies on the assumption that ğ¸
would not have happened if ğ¶had not happened before, which
corresponds to the standard â€œbut-forâ€ test used in law.
In this section, we take inspiration of the definition by Halpern
and Pearl [ 45,46] to establish a notion of causality at the level
of features. Here, we interpret the selection of features as events
consideredforactualcausality.Thebasicreasoningtaskweaddressthenamountsto determinethosefeatureselectionsthatcauseagiven
326
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:52:58 UTC from IEEE Xplore.  Restrictions apply. Causality in Configurable Software Systems ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Î˜(ğ¹)
E V\EV
/llbracketğ›¾/rrbracketğœ‚ ğœ‚
/llbracketğœ•/rrbracket
Figure 2: Configuration sets for feature causality
effect property. Examples for effect properties are â€œthe execution
time is longer than five minutesâ€ or â€œthe system crashesâ€.
We assume to have described the effect properties as effect set
EâŠ†Vof valid configurations for which an effect property can be
observed. Elements of Eare called effectinstances. All other valid
configurationsin V\Eareassumednottoexhibittheeffect.Feature
selections are naturally specified by partial configurations. Clearly,
apartialconfiguration ğ›¾canonlybeacauseoftheeffectif ğ›¾ensures
the effect to emerge, i.e., all valid configurations covered by ğ›¾are
effect instances. Furthermore, following counterfactual reasoning,
we require for ğ›¾being a cause that, if we would select features of
ğ›¾differently, there might be a configuration for which the effect
does not emerge. These two intuitive conditions on causality are
reflected in our formal definition of causes of Ew.r.t.V:
Definition 3.1. Afeature cause of an effect Ew.r.t. valid configu-
rationsVis a partial configuration ğ›¾âˆˆÎ”(ğ¹)where
(FC1)âˆ…â‰ /llbracketğ›¾/rrbracketâˆ©VâŠ†E and
(FC2)/llbracketğ›¾â†‘ğ‘¥/rrbracketâˆ©V/notsubseteqlEfor allğ‘¥âˆˆsupp(ğ›¾).
We denote by Causes(E,V)the set of all causes for Ew.r.t.V.
In caseFC1holds for a partial configuration ğ›¾, we say that ğ›¾
issufficient forEw.r.t.V[40]. The counterfactual nature of FC2
ensures that for every feature cause ğ›¾andğ‘¥âˆˆsupp(ğ›¾)there is a
counterfactualwitness ğœ‚âˆˆ/llbracketğ›¾â†‘ğ‘¥/rrbracketâˆ©(V\ E) . That is, a valid feature
configurationwheretheeffectdoesnotemergebutwherechanging
one feature selection may yield an effect instance. Note that FC2
ensures minimality of the feature cause w.r.t. its support, i.e., drop-
pingconditionsoninterpretationsoffeaturesnecessarilyleadstoa
partial configuration that is not sufficient for the effect anymore.
In the formal definition of Halpern and Pearl causality [ 45], coun-
terfactuality and minimality are stated in two distinct conditions.
We usually denote configurations in Ebyğœ‚, counterfactual wit-
nesses in V\Ebyğœ‚, and feature causes by ğ›¾. Figure 2 depicts the
relation between valid configurations, effects, causes, and counter-
factual witnesses.
Example 3.2. Let us continue our running example of the con-
figurable email system introduced in Example 2.1. We consider an
effect property reflecting â€œlong decipher timeâ€, e.g., that it takes in
averagemorethanthreemonthsforanattackertodecryptanemail.
Assume that this effect property can be observed by configurations
in which AES or RSA are selected, i.e., E={ğ‘šğ‘’ğ‘,ğ‘šğ‘’ğ‘Ÿ,ğ‘šğ‘ ğ‘’ğ‘,ğ‘šğ‘ ğ‘’ğ‘Ÿ }.
Conversely,inallvalidconfigurationsinwhichAESandRSAarenot
selected, the effect does not emerge. In this setting, the encryption
featuresAESandRSAarebothcausessinceallvalidconfigurations
with either feature show the effect. Considered in isolation, AES
and RSA are not necessary for the effect, as one can choose the
other encryption feature (RSA or AES, respectively) to ensure the
effect.Thesignfeaturedoesnottriggertheeffectandisnotacause.
Interestingly,afurthercauseisgivenbyselectingtheencryption
feature and explicitly deselecting the Caesar feature, illustratingthat also explicitly not selecting features might be a cause of some
effect. This hints at the fact that causes can be represented in dif-
ferent ways, addressed later in the paper.
Formalizing this intuition, we check whether the three partial
configurations ğ›¾ğ‘,ğ›¾ğ‘Ÿ, andğ›¾ğ‘’Â¯ğ‘given by
(i)supp(ğ›¾ğ‘)={ğ‘}withğ›¾ğ‘(ğ‘)=true,
(ii)supp(ğ›¾ğ‘Ÿ)={ğ‘Ÿ}withğ›¾ğ‘Ÿ(ğ‘Ÿ)=true, and
(iii)supp(ğ›¾ğ‘’Â¯ğ‘)={ğ‘’,ğ‘}withğ›¾ğ‘’Â¯ğ‘(ğ‘’)=trueandğ›¾ğ‘’Â¯ğ‘(ğ‘)=false
are indeed feature causes of Ew.r.t.Vaccording to Definition 3.1:
First,notethat /llbracketğ›¾ğ‘’Â¯ğ‘/rrbracketâˆ©V=(/llbracketğ›¾ğ‘/rrbracketâˆª/llbracketğ›¾ğ‘Ÿ/rrbracket)âˆ©V=Eandboth, /llbracketğ›¾ğ‘/rrbracketâˆ©V
and /llbracketğ›¾ğ‘Ÿ/rrbracketâˆ©V, are non-empty. Hence, FC1is fulfilled for ğ›¾ğ‘’Â¯ğ‘,ğ›¾ğ‘,
andğ›¾ğ‘Ÿ.Tocheck FC2,weobservethat /llbracketğ›¾ğ‘â†‘ğ‘/rrbracket=/llbracketğ›¾ğ‘Ÿâ†‘ğ‘Ÿ/rrbracket=Î˜(ğ¹)and
/llbracketğ›¾ğ‘’Â¯ğ‘â†‘ğ‘’/rrbracketâˆ©V=Eâˆª{ğ‘š,ğ‘šğ‘ },and
/llbracketğ›¾ğ‘’Â¯ğ‘â†‘ğ‘/rrbracketâˆ©V=Eâˆª{ğ‘šğ‘’ğ‘,ğ‘šğ‘ ğ‘’ğ‘ }.
Hence,ğ‘šis a counterfactual witness for ğ›¾ğ‘,ğ›¾ğ‘Ÿ, andğ›¾ğ‘’Â¯ğ‘w.r.t.ğ‘,ğ‘Ÿ,
andğ‘’, respectively, while ğ‘šğ‘’ğ‘can serve as such for ğ›¾ğ‘’Â¯ğ‘andğ‘.I ti s
easy to check that there are no further feature causes since for all
otherpartialconfigurationssufficientfor Ew.r.t.V(FC1)thereare
expansions towards ğ›¾ğ‘,ğ›¾ğ‘Ÿ,o rğ›¾ğ‘’Â¯ğ‘(thus, violating FC2).
3.1 Effect Properties and Sets
Ourdefinitionoffeaturecausalityreliesonagiveneffectset,which
is assumed to comprise all those valid configurations where the ef-
fectpropertyholds.Wenowelaboratemoreonhowtoobtaineffect
sets from analyzing configurable systems. In fact, our generic defi-
nition supports a multitude of effect properties for which the only
assumptionisthatthereisaneffectivemethodtodetermineallcon-
figurations in which the effect property holds. Such methods also
include variability-aware white-box analyses [ 88,91], where the
sourcecodeoroperationalbehaviorofsystemvariantsisaccessible,
aswellasblack-boxanalysesrelyingontestingorsampling[ 44,53].
Inthefollowingparagraphs,weexemplifyhowtoobtaineffectsets
from analysis results. Our discussions reflect the effect properties
in the experimental evaluation section (see Section 5) and do not
claim to be exhaustive.
Functionalproperties. To reason about causality w.r.t. functional
properties, the effect set can be determined by variability-awarestatic analysis [
10,72] or model checking [ 5,23,68]. In the latter
case, effect properties can be formalized, e.g., in a temporal logic
suchasLTL[ 69]orCTL[ 20].Modelcheckingconfigurablesystems
againstLTLandCTLpropertieshasbroadtoolsupport[e.g. 22,25].
Given a formula ğœ‘that specifies the effect property, these tools
explicitly return the effect set
Eğœ‘={ğœƒâˆˆV:ğœƒ|=ğœ‘}
ofvalidconfigurations ğœƒâˆˆVwhosecorrespondingsystemvariants
satisfyğœ‘. Since model checking is based on an exhaustive analysis,
an analysis also exposes those valid configurations for which the
effect property does not hold. The same is possible for variability-
aware static analysis [12, 72].
Non-functionalproperties. Besides functional properties, also
non-functional properties of configurable systems can serve aseffect property and give rise to an effect set. Let
ğœŒ:Vâ†’Rbe a
functionthatresultsfromaquantitativeanalysisoftheconfigurable
system in question. Values ğœŒ(ğœƒ)for a valid configuration ğœƒâˆˆV
327
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:52:58 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Clemens Dubslaff, Kallistos Weis, Christel Baier, and Sven Apel
may stand for the performance achieved, the probability of failure,
or the energy consumed in the system variant that corresponds to
ğœƒ. To obtain ğœŒfor real-world systems, Siegmund et al. [ 77,78]p r e -
sented a black-box method to generate linear-equation models for
performance measures by multivariable linear regression on sam-
pledconfigurations.Otherblack-boxapproachesrelyonregression
trees [44], Fourier learning [ 96], or probabilistic programming [ 27].
Related white-box approaches use insights of local measurements
and taint analysis information [ 88] or profiling information [ 91].
Variability-aware probabilistic model checking pursues a white-
box analysis approach on state-based operational models where
effect properties are specified in quantitative variants of temporal
logic [31,84]. These approaches have been implemented in the
tools ProFeat [19] and QFLan [86].
GivenğœŒthat results from one of the analysis approaches men-
tioned above, an effect set can be specified by imposing a threshold
ğœâˆˆRcombined with a comparison relation âˆ¼towards
EğœŒâˆ¼ğœ={ğœƒâˆˆV:ğœŒ(ğœƒ)âˆ¼ğœ}.
Example3.3. In Example 3.2, we informally specified the effect
of a â€œlong decipher timeâ€ as taking more than three months to
decrypt an email without having the encryption key available. By
a variability-aware quantitative analysis on the email system, we
may obtain a function ğœŒthat, for a configuration ğœƒ, returns the
minimal time in years to decipher an email sent with the system
variant corresponding to ğœƒ. Analysis results could be, e.g., ğœŒ(ğœƒ)=0
with no encryption, ğœŒ(ğœƒ)=10âˆ’7with Caesar, ğœŒ(ğœƒ)=1 with AES,
andğœŒ(ğœƒ)=2 with RSA selected in ğœƒ, respectively. Then, EğœŒ>0.25
provides the effect set Eof Example 3.2.
On computing effect sets. The effect set and the set of valid con-
figurations can be of exponential size in the number of features.
An efficient computation of these sets depends on the analysis
techniques used and are independent from our causal framework.
However,specificallytailoredvariability-awareanalysistechniquescantackletheexponentialblowup,e.g.,throughsymbolicrepresen-
tation of family models [29, 85].
3.2 Computation of Feature Causes
For a given effect set Eand a set of valid configurations Valong
with a partial configuration ğœ•, Definition 3.1 directly provides a
polynomial-timealgorithmtodecidewhether ğœ•isacauseof Ew.r.t.
Vby checking FC1andFC2. From this, we obtain a simple ap-
proach to compute the set Causes(E,V)by successively checking
expansions for sets of features applied on elements in Eas candi-
dates for causes. Since there might be exponentially many such
expansions, this approach easily renders infeasible already within
a small number of features.
In this section, we present a practical algorithm to compute the
set of causes, which relies on a connection of Definition 3.1 to the
notion of prime implicants (see Section 2):
Lemma 3.4. For any partial configuration ğœ•âˆˆÎ”(ğ¹)
/llbracketğœ•/rrbracketâˆ©VâŠ†E iff /llbracketğœ•/rrbracketâŠ†/parenleftbigÎ˜(ğ¹)\V/parenrightbigâˆªE.
Following this lemma, every cause of Ew.r.t.Vis also an impli-
cant of/parenleftbigÎ˜(ğ¹)\V/parenrightbigâˆªEdue toFC1and even a prime implicant due
toFC2. Conversely, every prime implicant ğœ•of/parenleftbigÎ˜(ğ¹)\V/parenrightbigâˆªEforAlgorithm 1: Computation of feature causes
input :E,VâŠ†Î˜(ğ¹)
output:Causes(E,V)
1ifE=âˆ…then return âˆ…
2P:=Compute-Primes/parenleftbig(Î˜(ğ¹)\V)âˆªE/parenrightbig
3forallğœ•âˆˆPwhere /llbracketğœ•/rrbracketâˆ©E=âˆ…doP:=P\{ğœ•}
4returnP
which /llbracketğœ•/rrbracketâˆ©Eâ‰ âˆ…is a cause due to FC1. This directly suggests an
algorithmtocomputecausesviaprimeimplicants:Algorithm1first
generates prime implicants as cause candidates and then removes
those candidates that are not sufficient for Ew.r.t.V. Figure 2
reflects this situation where ğ›¾andğœ•are prime implicants with ğ›¾
being a cause and ğœ•not: at least one effect instance is covered by
ğ›¾, while this is not the case for ğœ•and hence would be removed
by Algorithm 1. Prime implicants of a set of configurations canbe computed in polynomial time in the size of the input set [
83],
which directly leads to:
Theorem 3.5. Given valid configurations VâŠ†Î˜(ğ¹)and effect
setEâŠ†V,Algorithm1computes Causes(E,V),thesetoffeature
causes for Ew.r.t.V, in polynomial time in |Î˜(ğ¹)|.
Note that the set of valid configurations and the effect set can
be both exponential in the number of features and there might be
exponentiallymanyprimeimplicants[ 16]intheworstcase.Hence,
Algorithm 1 is exponential in the number of features.
Example 3.6. Let us illustrate the computation of feature causes
of Example 3.2 by Algorithm 1. First notice that
/parenleftbigÎ˜(ğ¹)\V/parenrightbigâˆªE=Î˜(ğ¹)\{ğ‘š,ğ‘šğ‘’ğ‘,ğ‘šğ‘ ,ğ‘šğ‘ ğ‘’ğ‘ }
comprising60featureconfigurations.Theprimeimplicantsforthis
set are computed in Line 2, which yields
P={ğ›¾Â¯ğ‘š,ğ›¾ğ‘,ğ›¾ğ‘Ÿ,ğ›¾ğ‘’Â¯ğ‘,ğ›¾Â¯ğ‘’ğ‘}.
Here, we used notations as in Example 3.2, e.g., supp(ğ›¾Â¯ğ‘’ğ‘)={ğ‘’,ğ‘},
ğ›¾Â¯ğ‘’ğ‘(ğ‘’)=false, andğ›¾Â¯ğ‘’ğ‘(ğ‘)=true. Clearly, all configurations
covered by ğ›¾Â¯ğ‘šorğ›¾Â¯ğ‘’ğ‘are not valid and hence also no effects. Thus,
theyareremovedinLine3,leadingto Causes(E,V)={ğ›¾ğ‘,ğ›¾ğ‘Ÿ,ğ›¾ğ‘’Â¯ğ‘}.
4 CAUSAL EXPLICATIONS
Since the number of feature causes can be exponential in the num-
ber of features, a mere listing of all causes is neither feasible norexpedient for real-world software systems. This holds for both,
humans that have to evaluate causal relationships in configurable
systems, e.g., during software development, and machines that
might use feature causes for further processing and reasoning.
In this section, we present and discuss several methods to com-
putecausalexplications, i.e., mathematical or computational con-
structs that arise from processing feature causes to provide useful
causalrepresentationsandmeasures[ 8].Explicationsarecloselyre-
latedtoexplanations,bywhichwemeanhuman-understandableob-
jectsemployedwithinanintegratedsystem,e.g.,infeature-oriented
software development or in production-level deployments.
Ourmethodsforcomputingexplicationsrelyontechniquesfrom
propositional logic and circuit optimization [ 61,65], responsibility
328
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:52:58 UTC from IEEE Xplore.  Restrictions apply. Causality in Configurable Software Systems ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
andblame[ 17],andfeatureinteractions[ 40].Theyalltakeaglobal
perspective on sets of feature causes rather than only considering
single feature causes in isolation. In the following, we fix sets of
valid configurations VâŠ†Î˜(ğ¹)and effects EâŠ†V.
4.1 Distributive Law Simplification
A rather natural explication for a set of causes CâŠ†Causes(E,V)
is to represent Cas propositional logic formula, e.g., as the charac-
teristic formula ğœ’(C)defined in disjunctive normal form (DNF)
ğœ’(C)=/logicalordisplay.1
ğœ•âˆˆC/parenleftbig/logicalanddisplay.1
ğ‘¥âˆˆsupp(ğœ•)
ğœ•(ğ‘¥)=trueğ‘¥âˆ§/logicalanddisplay.1
ğ‘¥âˆˆsupp(ğœ•)
ğœ•(ğ‘¥)=falseÂ¬ğ‘¥/parenrightbig.
Clearly,ğœ’(C)has the same size as Cand its representation does
not exhibit any advantage compared to C. Methods to minimize
propositional logic formulas [ 48,60,61] could be used to yield
smallformulas ğœ‘coveringthesameconfigurationsas C,i.e.,where
/llbracketğœ‘/rrbracket=/llbracketC/rrbracket. While beneficial for related problems in configurable
systems analysis, e.g., for presence condition simplification [ 89],
such methods vanish causal information, i.e., the set of causes C
cannot be reconstructed from the reduced formula ğœ‘. To provide a
small formula that maintains the causal information of C, we use a
simple yet effective reduction method, which we call distributive
law simplification (DLS). The basic idea is to factorize common fea-
ture selections in a DNF formula step by step, exploiting the ğ‘›-ary
distributive law /llbracket/logicalortext.1ğ‘›
ğ‘–=1(ğœ™âˆ§ğœ“ğ‘–)/rrbracket=/llbracketğœ™âˆ§/logicalortext.1ğ‘›ğ‘–=1ğœ“ğ‘–/rrbracket. Each factoriza-
tion leads to a length reduction of (ğ‘›âˆ’1)Â·|ğœ™|, where|ğœ™|is the
length of the propositional formula factored out. Obviously, these
transformations are reversible, such that the original DNF ğœ’(C)
and hence the set of causes Ccan be reconstructed. The final for-
mulalengthdependsontheformulasfactoredout,thesubformulas,
and the factorization order. Determining a formula through DLS
that has minimal size is close to global optimization problems for
propositional logic formulas and thus computationally hard. For
practical applications, we hence employ a heuristics that reduces a
givenformula ğœ‘inDNFbystepwisefactoringoutliteralsthathave
maximal number of occurrences in DNF subformulas. We denote
the reduced formula obtained by this heuristics by DLS(ğœ‘).
4.2 Causeâ€“Effect Covers
The complete set of causes may contain several candidates to de-
scribe reasons for the effect emerging in a single system variant.
If not interested in all causes but in a set of causes that covers all
effects (i.e., that contains, at least, one cause for every system vari-
ant) we might ask for a preferably small covering set. Formally, a
causeâ€“effectcover ofEis a setCâŠ†Causes(E,V)whereEâŠ† /llbracketC/rrbracket.
We say that such a cover Cisminimal if there is no causeâ€“effect
coverC/primeofEwhere|C/prime|<|C|.
Example4.1. FortheemailsysteminExample3.2wedirectlysee
that{ğ›¾ğ‘’Â¯ğ‘}and{ğ›¾ğ‘,ğ›¾ğ‘Ÿ}are the only causeâ€“effect covers of E. Thus,
{ğ›¾ğ‘’Â¯ğ‘}is a minimal causeâ€“effect cover of Eas|{ğ›¾ğ‘,ğ›¾ğ‘Ÿ}|>|{ğ›¾ğ‘’Â¯ğ‘}|.
Determining minimal causeâ€“effect covers is computationally
hard for the same reasons as for minimal primeâ€“cover computa-
tion [65]. Hence, for practical applicability, heuristics that lead to
nearly minimal causeâ€“effect covers are of interest.Definition4.2. Thebinaryrelation /triangleleftequalâŠ†Î”(ğ¹)Ã—Î”(ğ¹),whereğœ•/triangleleftequalğœ•/prime
stands for ğœ•/primeto beat least as general as ğœ•w.r.t.E, is defined by
ğœ•/triangleleftequalğœ•/primeiff/llbracketğœ•/rrbracketâˆ©EâŠ† /llbracketğœ•/prime/rrbracketâˆ©E.
The set of most general causes ğ‘šCauses(E,V)comprises those
causes for Ew.r.t.Vthat are /triangleleftequal-maximal in Causes(E,V).
From the above definition, we directly establish an algorithm
to compute ğ‘šCauses(E,V)by computing /triangleleftequalonCauses(E,V)in
quadratic time and selecting elements maximal w.r.t. /triangleleftequal. While
ğ‘šCauses(E,V)already provides a causeâ€“effect cover of E, there
might be different most general causes that cover the same set of
effect instances. Towards nearly minimal causeâ€“effect covers, we
thus might pick one of those candidates with minimal support to
obtain an even further concise representation.
4.3 Responsibility and Blame
Tomeasuretheinfluenceofcausesoneffects,ChocklerandHalpern
[17] introduced degrees of responsibility andblame, ranging from
zero to one for â€œnoâ€ to â€œfullâ€ responsibility and blame, respectively.
Responsibility measures how relevant a single cause is for an effect
in a specific context. Blamedenotes the expected overall responsi-
bility according to a given probability distribution on all contexts
where the effect emerges. We take inspiration from these mea-
sures and present corresponding notions for feature causality. In
short, the degree of responsibility is the maximal share of features
contributing to the effect, i.e., features that would have to be recon-
figured to provide a counterfactual witness.
Example 4.3. We rephrase the majority example by Chockler
and Halpern [ 17] in our setting. Consider eleven features whose
configurationsare allvalid. We areinterestedin responsibilitiesfor
theeffectthatthemajorityoffeaturesisactive.Ifallelevenfeaturesareactive,eachfeaturehasaresponsibilityof1
/6,sincesixfeatures
sharetheresponsibilityfortheeffect:Besidesthefeatureofinterest,
further five features have to be reconfigured towards a majority of
inactive features. In a configuration where six features are active
and five not, each of the six active ones is fully responsible for the
effect: If this feature would be reconfigured, more features would
beinactivethanactive.Wethenassignresponsibilityofonetoeach
of the six active features.
Inwhatfollows,weformalizedegreesofresponsibilityandblame
for single features as in the example above. An extension of this
notion to partial configurations to explicate feature interactions is
provided in Section 4.4.
Feature responsibility. Intuitively, the degree of responsibility of
a single feature ğ‘¥âˆˆğ¹is defined as the maximal share to contribute
to causing the effect in an effect instance ğœ‚âˆˆE. In the case that ğ‘¥
does not appear in the support of any cause ğ›¾covering ğœ‚, feature
ğ‘¥does not contribute to causing the effect in ğœ‚and thus has no
responsibility. Otherwise, ğ‘¥shares its responsibility with, at least,
a minimal number of other features, whose switch of its interpreta-
tion inğœ‚would lead to a counterfactual witness ğœ‚, i.e.,ğœ‚âˆˆV \ E.
We formalize such switches in configurations by a function
switch:â„˜(ğ¹)Ã—Î˜(ğ¹)â†’Î˜(ğ¹)
whereforany ğ‘ŒâŠ†ğ¹andğœƒâˆˆÎ˜(ğ¹),wehave switch(ğ‘Œ,ğœƒ)(ğ‘¦)=ğœƒ(ğ‘¦)
ifğ‘¦âˆ‰ğ‘Œandswitch(ğ‘Œ,ğœƒ)(ğ‘¦)=Â¬ğœƒ(ğ‘¦)otherwise.
329
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:52:58 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Clemens Dubslaff, Kallistos Weis, Christel Baier, and Sven Apel
Definition 4.4. Thedegree of responsibility of a feature ğ‘¥âˆˆğ¹
in the context ğœ‚âˆˆEfor which there is ğ›¾âˆˆCauses(E,V)with
ğœ‚âˆˆ/llbracketğ›¾/rrbracketandğ‘¥âˆˆsupp(ğ›¾)is defined as
resp(ğ‘¥,ğœ‚)=1
min{|ğ‘Œ|:ğ‘ŒâŠ†ğ¹,ğ‘¥âˆˆğ‘Œ,switch(ğ‘Œ,ğœ‚)âˆˆV \ E}
and asresp(ğ‘¥,ğœ‚)=0 otherwise.
Note that due to FC2there exists at least one counterfactual
witness in the case ğ‘¥appears in a cause covering ğœ‚and hence, the
denominator of the above fraction is finite and greater than zero.
Example4.5. Continuing the email example (see Example 3.2),
themailfeature ğ‘šandsignfeature ğ‘ donothaveanyresponsibility
foralongdeciphertimeinanyconfigurationastheydonotappear
in any of the causes ğ›¾ğ‘,ğ›¾ğ‘Ÿ, andğ›¾ğ‘’Â¯ğ‘. Also the AES feature ğ‘has
no responsibility in configurations ğ‘šğ‘’ğ‘Ÿorğ‘šğ‘’ğ‘Ÿğ‘ , since the only
covering causes are ğ›¾ğ‘’Â¯ğ‘andğ›¾ğ‘Ÿ, not containing ğ‘in their support.
Besides the analogous case for the RSA feature ğ‘Ÿ, other degrees of
responsibility are 1 /2: switching a feature ğ‘¥inğœ‚usually requires
one further feature to switch towards a configuration of V\E. For
example, selecting the Caesar feature ğ‘inğœ‚=ğ‘šğ‘’ğ‘requires also to
deselect the AES feature ğ‘, leading to ğœ‚=ğ‘šğ‘’ğ‘âˆˆV\ E.
Blame.Degreesofresponsibilityarelocallydefinedw.r.t.acontext,
whileoneissurelyalsointerestedinaglobalmeasureofresponsibil-
ityofafeatureorpartialconfigurationw.r.t.allpossiblecontexts,i.e.,
effectconfigurations.The degreeofblame isdefinedastheexpected
degreeofresponsibilityonaprobabilitydistribution ğœ‹:Vâ†’[0,1]
over valid configurations V, i.e., where/summationtext.1
ğœƒâˆˆVğœ‹(ğœƒ)=1.
Definition 4.6. Thedegree of blame of a feature ğ‘¥âˆˆğ¹w.r.t. a
distribution ğœ‹overVis defined as
blame(ğ‘¥,ğœ‹)=/summationdisplay.1
ğœ‚âˆˆEğœ‹(ğœ‚)Â·resp(ğ‘¥,ğœ‚).
Example4.7. To illustrate the degree of blame, continue Exam-
ple 4.5, where we assume a uniform distribution ğœ‹over effect con-
figurations, i.e., ğœ‹(ğœ‚)=1/|E|=1/4 for allğœ‚âˆˆEand 0 otherwise.
Then,blame(ğ‘¥,ğœ‹)=1/4/summationtext.1
ğœ‚âˆˆEresp(ğ‘¥,ğœ‚)and thus, blame(ğ‘¥,ğœ‹)is
1/2 forğ‘¥âˆˆ{ğ‘’,ğ‘},3/8 forğ‘¥âˆˆ{ğ‘,ğ‘Ÿ}, and 0 for ğ‘¥âˆˆ{ğ‘š,ğ‘ }.
On the choice ofblame distributions. The distribution ğœ‹mod-
els the frequency of valid configurations to occur, for which there
are several scenarios that lead to a reasonable definition of ğœ‹. One
natural distribution may model the frequency of users choosing a
configuration in the configurable system. But also the frequencyof effect configurations is useful, e.g., to model the frequency a
certain bug is reported by users when the effect corresponds to thepropertyofamalfunction.Inthecasesuchstatisticsarenotathand
or one is interested in the degree of blame from a developerâ€™s per-
spective, uniform distributions over valid configurations or effects
are canonical candidates for ğœ‹.
4.4 Feature Interactions
A notorious problem in configurable systems is the presence of
(inadvertent) feature interactions [3,14], which describe system
behaviors that emerge due to a combination of multiple featuresnot easily deducible from the featuresâ€™ individual behaviors. Thedetection, isolation, and resolution of feature interactions play acentral role in the development of configurable systems and be-
yond [4,94]. We now show how our black-box causal analysis at
the level of features (see Section 3.1) can be used for the detection
and isolation of feature interactions. These can provide the basis
for fine-grained, white-box feature-interaction resolution as done
by Garvin and Cohen [40].
Detection. The first problem we address is to detect the necessity
of feature interactions for an effect to emerge. Garvin and Cohen
presented a formal definition of featureinteractionfaults to capture
faults in configurable systems that necessarily arise from the inter-
playbetweenmultiplefeatures[ 40].Notably,theircharacterization
is also at the abstraction level of features and relies on black-boxtesting of faults, similar to our perspective on effects. We trans-fer their definition to our setting, but covering arbitrary effects
instead of faults only. Recall that a partial configuration ğœ”âˆˆÎ”(ğ¹)
issufficient forEw.r.t.Vifâˆ…â‰ /llbracketğœ”/rrbracketâˆ©VâŠ†E (seeFC1).
Definition 4.8. A partial configuration ğœ”âˆˆÎ”(ğ¹)is ağ‘¡-way inter-
action witness forEw.r.t.Vif
(FI1)ğœ”sufficient for Ew.r.t.Vwith|supp(ğœ”)|=ğ‘¡and
(FI2)there is no Ë†ğœ”sufficient for Ew.r.t.Vwith|supp(Ë†ğœ”)|=ğ‘¡âˆ’1.
Basically, there is a one-to-one correspondence between interac-
tion witnesses and feature causes with minimal support:
Theorem 4.9. For any partial configuration ğ›¾âˆˆÎ”(ğ¹)withğ‘¡=
|supp(ğ›¾)|we have that
(1)ifğ›¾is ağ‘¡-way interaction witness for Ew.r.t.V, thenğ›¾âˆˆ
Causes(E,V), and
(2)ifğ›¾âˆˆCauses(E,V)and there is no Ë†ğ›¾âˆˆCauses(E,V)with
|supp(Ë†ğ›¾)|<ğ‘¡,thenğ›¾isağ‘¡-wayinteractionwitnessfor Ew.r.t.V.
Tothisend,Algorithm1,incombinationwithaprojectiontofea-
ture causes with minimal support, can be used to decide whether
the effect emerges necessarily from feature interactions: A nec-essary feature interaction takes place in the case these minimal
feature causes all have a support involving, at least, two features.
Example4.10. Returning to Example 3.2, there are exactly two
causes that are both 1-way interaction witnesses: ğ›¾ğ‘andğ›¾ğ‘Ÿ. The
causeğ›¾ğ‘’Â¯ğ‘does not witness a necessary 2-way feature interaction
since although having support size of two, ğ›¾ğ‘andğ›¾ğ‘Ÿhave support
size one (cf. Theorem 4.9(2)). Hence, the effect describing long
decipher time is not necessarily related to a feature interaction.
Isolation. The second problem we address is to pinpoint features
responsible for feature interactions. For this, observe that Defini-
tion 4.8 is similar to Definition 3.1, but with a different notion of
minimality: While FI2ensures global minimality over all partial
configurations, FC2ensures local minimality through expansions,
takingtheindividualselectionoffeaturesintoaccount.Topinpoint
those features that actually interact towards the effect, feature
causes can be interpreted as a form of interactionwitnesses at the
local level instead of the global perspective taken for ğ‘¡-way interac-
tion witnesses: Switching some feature a cause does not ensure theeffecttoemergeanymoreâ€“hence,theswitchedfeatureisnecessaryfortheeffect.Forinstance,inExample4.10,theinteractionbetween
encryption and Caesar being disabled is witnessed by the feature
330
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:52:58 UTC from IEEE Xplore.  Restrictions apply. Causality in Configurable Software Systems ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
causeğ›¾ğ‘’Â¯ğ‘. Feature causes thus also provide a criterion for feature
interactionsattheoperationallevelandcanbeusedtoguideamore
in-depth white-box feature interaction analysis, possibly reducing
the naive exponentially-sized feature-interaction search space.
Feature interaction responsibility and blame. Any subset of
thesupportsoffeaturecausesthatcontainsmorethantwofeatures
provides candidates for an actual interaction between the features
contained. Since both, the number of feature causes and their ex-
pansions, can be exponential in the number of features, feature
interactions isolated via a causal analysis might still be difficult to
interpret by developers. Based on the degree of responsibility for
single features, we now provide a variant to measure responsibility
andblameoffeatureinteractions,wherehighvaluesindicatestrong
relevance of the interaction and low values weak relevance.
Definition 4.11. Thedegree of responsibility of a partial con-
figuration ğœ•âˆˆÎ”(ğ¹)in the context ğœ‚âˆˆEfor which there is
ğ›¾âˆˆCauses(E,V)withğœ‚âˆˆ/llbracketğ›¾/rrbracketandsupp(ğœ•)âŠ†supp(ğ›¾)and
ğœ•(ğ‘¥)=ğ›¾(ğ‘¥)for allğ‘¥âˆˆsupp(ğœ•)is defined as
resp(ğœ•,ğœ‚)=1
min{|ğ‘Œ|:ğ‘ŒâŠ†ğ¹,supp(ğœ•)âˆ©ğ‘Œâ‰ âˆ…,switch(ğ‘Œ,ğœ‚)âˆˆV \ E}
and asresp(ğœ•,ğœ‚)=0 otherwise.
Note that, for ğœ•(ğ‘¥)=ğœ‚(ğ‘¥)andsupp(ğœ•)={ğ‘¥}, Definition 4.11
agrees with Definition 4.4. The degree of responsibility is non-zero
in the case of a single feature if the feature appears in some cause,
whereasthedegreeoffeatureinteractionresponsibilityisnon-zero
if some cause is an expansion of the potential feature interaction.
Feature interaction blame is defined as in Definition 4.6 but withreplacing the single feature
ğ‘¥âˆˆğ¹by the partial configuration
ğœ•âˆˆÎ”(ğ¹)standing for the potential feature interaction of interest.
5 EXPERIMENT SETUP
To evaluate our causal analysis and explication algorithms, we
conducted a number of experiments comprising many analyses on
community benchmarks and real-world examples from the area of
configurable software systems.
5.1 Research Questions
Ourevaluationisdrivenbyfourresearchquestionsthataddressthe
key issue of whether and how the notion of feature causality facili-
tates identifying root causes, estimating the effects of features, and
detecting feature interactions in controlled and practical settings.
(RQ1)Can feature causes be effectively computed in real-world
settings and support the detection of reasons for different
effects of interest?
(RQ2)DoDLSrepresentation,causeâ€“effectcovers,andresponsibil-
ity and blame degrees provide concise causal explications?
(RQ3)Is feature causality beneficial for guiding the configuration
of systems under variability-aware constraints?
(RQ4)Canfeatureinteractionsandconfiguration-dependentanom-
alies be detected and isolated based on feature causality?
5.2 Implementation
We implemented our algorithms to compute feature causes and
explicationsintheprototypicaltoolFeatCause.WritteninPython,our tool relies on the engines for logical expressions and binary
decisiondiagrams(BDDs)of PyEDA,alibraryforelectronicdesign
automation [ 28]. The tool takes the sets of valid feature configura-
tionsVand effects Eas input. FeatCause supports different input
formats for these sets, e.g., by Boolean expressions in DNF or CNF.
Internally, sets of (partial) feature configurations are efficiently rep-
resentedasreducedorderedBDDs[ 13].Inadditiontotheircompact
and hence space-efficient representation, we chose BDDs because
they provide an efficient method to check satisfiability (required,e.g., for Line 3 in Algorithm 1). We first implemented a naive al-gorithm directly checking the conditions FC
1andFC2, but even
for small examples, we easily ran into timeouts. Hence, we devised
Algorithm 1, which uses prime implicants to efficiently determine
feature causes (cf. Section 3). To compute prime implicants, we
used the tool Espresso [ 61], well known from circuit optimization,
through an interface that mediates between our BDD represen-tations and the DNF representations in Espressoâ€™s PLA format.
This interface is also used to provide minimal and nearly minimal
causeâ€“effect covers through Espresso-Signature and Espresso,
respectively,whichcanthenbecomparedwithourheuristiccauseâ€“effectcoverbymostgeneralcauses(seeSection4.2).Whileitiswell
known that the length of DNFs can be exponential in the size of
theBDDrepresentingthesameBooleanfunction,generatingDNFs
from our BDD representations did not face any significant blowup
andrequirednegligibletimeinallourexperiments.Besidesthecore
tool, we have implemented several conversion scripts to generate
valid feature configuration sets from TVL [ 21] and effect sets from
analysis results returned by variability-aware analysis tools such
asProVeLines[ 25]andProFeat[ 19](seealsoSection3.1)andthe
data sets from Siegmund et al. [77] and Kaltenecker et al. [53].
5.3 Subject Systems
To answer our research questions, we selected a diverse set of
subject systems, ranging from popular community benchmarks to
more involved systems with non-functional properties and from
real-world settings (see Table 1 for an overview).
From Cordy et al. [ 25], we use Minepump, Elevator, and CFDP
systemsandanalyzedthemagainsttheaccompaniedLTLproperties
using the variability-aware model checker ProVeLines. Further-
more, we took the Email and Elevator from von Rhein et al. [ 89]
and analyzed multiple defects provided as propositional logic for-
mula generated by SPLVerifier [5].
For quantitative properties, we generated effect sets from con-
figurable system analysis results as illustrated in Section 3.1 for
three classes of systems. First, we considered configurable systems
modeled for the variability-aware probabilistic model checker Pro-
Feat[19],comprisingabodysensornetwork(BSN)model[ 74]and
a velocity control loop (VCL) model of an aircraft [ 32,35]. In both
systems, the reliability (R) of the system is analyzed in terms ofthe probability of failure of sensors and control components, re-
spectively.Second,wegeneratedeffectsetsfromperformancemea-
surements of real-world configurable software systems that have
been used to evaluate performance modeling techniques [ 53,77].
In particular, we selected five systems from different domains: a
compiler framework (LLVM), a database-system (BerkeleyDB), a
compression tool (Lrzip), a video encoder (x264), and a toolbox for
331
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:52:58 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Clemens Dubslaff, Kallistos Weis, Christel Baier, and Sven Apel
Table 1: Statistics of feature causality experiments
Property System # |V| |ğ¹|Time Average size of
[type] [s] EC ğ‘šCDLS
ğœ‘CFDP 10 5613 0.21 28 7.30 2.60 58%
Elevator 136 256 9 0.09 128 0.58 0.58 26%
Minepump 82 12811 0.29 64 1.77 0.91 43%
ğœ€ğµLinkedList 42 20419 18.97 102 47.40 8.36 54%
Linux 2116777216 25 5.88 2222.14 22.14 80%
PKJab 28 7212 0.42 36 8.43 4.86 72%
Prevaylar 42 247 0.20 12 3.57 2.17 93%
SNW 42 324036 2751.32 1620 2110.31 18.90 37%
ZipMe142 649 0.19 32 4.19 2.69 93%
ğœ€ğ‘€Curl 28 76814 83.07 384 96.75 67.39 59%
h264 28 115217 355.37 576229.86 113.93 53%
SQLite 213932160 40 34826.86 1310729 1881.67 436.48 27%
WGet 28 512017 777.26 2560 298.11 201.79 51%Property System # |V| |ğ¹|Time Average size of
[type] [s] EC ğ‘šCDLS
ğœ€ğ‘‡Apache 28 19210 2.85 9628.79 22.96 69%
Elevator 228 106 0.14 53.21 2.25 80%
Email 28 4010 1.01 2022.32 8.21 69%
h264 56 115217 32.24 576 68.98 22.71 51%
ZipMe2 42 64016 1.73 320 11.07 9.98 72%
ğœğ‘…BSN 4 29811 0.63 149 21.00 8.75 68%
VCL 222097152 21 60403.78 1048576 3718.05 3718.05 36%
ğœğ‘‡BerkeleyDB 36 256019 5.71 1280 13.03 4.28 72%
DUNE 46 230432 3950.15 1152 724.87 46.00 46%
LLVM 30 102412 16.21 512 53.57 53.57 55%
Lrzip 48 43220 5.71 216 13.85 1.90 69%
x264 48 115217 2.38 576 7.50 3.75 78%
We list for each type of effect property (functional LTL properties ğœ‘, precision accuracy threshold properties ğœ€, and other threshold properties ğœ) the considered subject systems, the
numbers of experiments (#), valid configurations ( |V|), features ( |ğ¹|), and the overall time in seconds to compute feature causes and most general causes. The second part of the
table lists the average sizes of the effect sets ( E), feature causes ( C=Causes(E,V)), causeâ€“effect covers by most general causes ( ğ‘šC=ğ‘šCauses(E,V)), and DLS formulas
relative to the characteristic formula of causes (DLS= |DLS(ğœ’(C))|/|ğœ’(C)|in percent).
solving partial differential equations (DUNE). For these systems,
we chose thresholds on the runtime (T) of the system executions.
Third, we constructed effect sets for several systems from studies
onperformancepredictionofnon-functionalproperties[ 78,79,81],
such as Apache, Linux, SQLite, and WGet. For these, we used
the black-box approach by Siegmund et al. [ 80], which uses mul-
tivariable linear regression methods to generate variability-aware
performancemodels.Ourthresholdsforconstructingeffectsetsareimposedonthepredictionaccuracyofthefollowingthreedifferent
non-functional properties on those systems: runtime (T), binary
size (B), and memory footprint (M).
5.4 Operationalization
ForRQ1,wecomputebothsets Causes(E,V)andCauses(V\E,V),
i.e.,thefeaturecausesoftheeffectpropertyanditsnegation.Based
on these feature causes, we further compute causeâ€“effect covers
ğ‘šCauses(E,V)andğ‘šCauses(V\E,V), distributive law simplifi-
cation (DLS), as well as responsibility and blame values for each
single feature and cause to answer RQ2. For blame computations,
we assume a uniform distribution over all effects, due to the ab-
sence of further statistical information and taking a developersâ€™perspective (cf. Section 4.3). For RQ
3, we compute single feature
blames based on a uniform effect distribution to measure the in-
fluence of individual features onto the effect. We compute feature
interaction blames on pairs of features to address RQ4, again as-
sumingauniformeffectdistribution.Table1provideskeystatistics
about our experiments, focusing on model characteristics and the
time to compute feature causes and most general feature causes.
AllexperimentswereconductedonanAMDRyzen73800X8-Core
system with 32GB of RAM running Debian 10 and Python 3.7.3.
6 RESULTS
Wediscussourresultsw.r.t.thedifferentkindsofcausalexplications
of Section 4. First, we discuss statistics on our experiments, also
quantitativelyanalyzingthepotentialofcausalexplicationsbymost
general causes and DLS-reduced formulas. Then, we address our
research questions in more depth by means of three representative
subject systems. Here, we focus on properties not detectable by
classical causal white-box analysis methods [51, 95].6.1 Descriptive Statistics (RQ 1and RQ 2)
The computability of feature causes is of major interest for our
evaluation. Table 1 provides an overview of the subject systems for
which we generated effect sets and applied our feature causality
analysis. We see that our algorithms compute feature causes in
reasonable time, within a few seconds for most subject systems. To
create the effect sets, we considered several effect properties, asdescribed in Section 3.1:
ğœ‘stands for LTL properties; ğœ€ğµ,ğœ€ğ‘€, and
ğœ€ğ‘‡for thresholds on the accuracy of a prediction model for binary
size,memory footprint, and run time; andğœğ‘…andğœğ‘‡forreliability
and runtime thresholds, respectively. This variety of properties
already illustrates the wide range of applications and potential use
of feature causality. The sizes of valid configuration and effect sets
crucially influence the time for computing feature causes, whichis as expected since the complexity of Algorithm 1 is dominatedby the computation of prime implicants of
/parenleftbigÎ˜(ğ¹)\V/parenrightbigâˆªE. Since
our implementation relies on BDDs for the representation of valid
configurationandeffectsets,itishoweverwellpossiblethatwithin
similar sizes, computation times can significantly differ. This ismainly due to the fact that BDD sizes highly depend on the spe-
cific nature of the represented Boolean functions and the variable
order chosen [ 13]. For instance, while the experiments on DUNE
and BerkeleyDB (see Table 1) have similar sized sets VandE,
their runtimes differ in two orders of magnitude. We see that the
number of most general feature causes is often way smaller than
the overall number of feature causes, which renders the creation
of causeâ€“effect covers by most general causes sensible to support
concise explications. Interestingly, causeâ€“effect covers by most
general causes and Espresso minimization [ 61] yield the same re-
sults in almost all of our experiments, which proves our heuristics
to be effective. In the same vein, the application of DLS leads to
greatreductionsoflogicalrepresentationsoffeaturecauses,e.g.,onaveragebyalmost3/4intheElevator
1subjectsystem(seeTable1).
ForRQ1andRQ2, we conclude that feature causes are com-
putable in reasonable time. A substantial reduction of the set of
feature causes and causeâ€“effect covers can be performed with
DLS formulas and most general feature causes, respectively.
332
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:52:58 UTC from IEEE Xplore.  Restrictions apply. Causality in Configurable Software Systems ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Table 2: Minepump â€“ (most general) feature causes
Blame Feature cause (characteristic formula)
0.29 Highâˆ§Command âˆ§Â¬Stopâˆ§MethaneAlarm
0.57 Highâˆ§Startâˆ§MethaneAlarm
0.14 Highâˆ§Command âˆ§Â¬Stopâˆ§MethaneSensor âˆ§Â¬MethaneQuery
0.57 Highâˆ§Startâˆ§Stop
0.57 Highâˆ§Lowâˆ§Start
0.29 Highâˆ§Startâˆ§MethaneSensor âˆ§Â¬MethaneQuery
0.29 Highâˆ§Lowâˆ§Command âˆ§Â¬Stop
6.2 Feature Cause Explications (RQ 2)
We discuss the explications of feature causes that we have gen-
erated by the example of the Minepump system [ 23], which is
frequently used in the configurable systemsâ€™ analysis community.
This system models a water pump of a mine with |ğ¹|=11 fea-
tures on which requirements expressed in LTL are imposed (see
Section 3.1). An analysis of the stabilization property, formalizing
that the Minepump system eventually stabilizes (the pumps are
eventually continuously on or off), using ProVeLines returned
|E|=28configurationswherethepropertyholdsand |V\E|=100
configurations where it does not hold.
The direct interpretation of features responsible for this effect
property is difficult, as it requires to investigate the result of all
|V|=128 configurations. A causal analysis returned seven feature
causeslistedwiththeirdegreeofblameinTable2.Theyalreadypro-
vide hints which features are responsible for the property. Among
the feature causes, three are most general, highlighted in Table 2.
They have the highest degree of partial configuration blame while
the most lengthy cause has the smallest degree. Our DLS heuristics
on most general causes yields
Highâˆ§Startâˆ§(Stopâˆ¨Lowâˆ¨MethaneAlarm)
providing a concise representation of feature cause candidates ex-
plicating the effect property. That is, selecting features High,Start,
and one of the three features Stop,Low,o rMethaneAlarm covers
all causally relevant configurations for the Minepump system to
stabilize. On other subject systems, explications are also effective,
but with less drastic reductions than for the Minepump example.
Answering RQ2, feature causes are of reasonable size compared
to the complete analysis results, i.e., most general feature causes
and DLS provide concise explications for feature causes. Respon-
sibility and blame reflect the impact of feature causes.
6.3 Causality-guided Configuration (RQ 3)
Featureblameprovidesaquantitativemeasureonthecausalimpactof feature selections w.r.t. a set of configurations. This measure can
be used to support configuration decisions, e.g., by prioritizing fea-
tureswithhighblamevaluesincasetheeffectpropertyisdesirable.
We investigate such a causality-guided configuration on the veloc-
ity control loop (VCL) subject system [ 34,35]. The VCL models an
aircraft velocity controller in SimuLink for which its reliability in
terms of probability of failure is of interest. A common principle to
increase the reliability of a system is by triple modular redundancy
(TMR)where system components are triplicated and their output
are combined via a majority vote. Dubslaff et al. [ 32] suggested tomodel and analyze systems with such protection mechanisms using
family-basedmethodsfromconfigurablesystemsâ€™analysis.Toeachcomponent they assign a protectionfeature that specifies whether a
componentistriplicatedornot.Comprising21componentseligible
for protection, the VCL model has |V|=221=2097152 valid
featureconfigurations.Clearly,thehighestreliabilityisachievedby
protecting all components. However, each protection comes at its
costs in terms of execution time, energy costs, and packaging size.
Whileitisknownhowtodetermineprotectionconfigurationswith
optimal reliabilityâ€“cost tradeoff [ 32], reasons for why a protection
configuration is optimal or why a component was selected for pro-
tection are typically unclear. We address this issue exploiting our
causal analysis methods. Using the variability-aware probabilistic
model checking tool ProFeat [ 19], we generated effect sets EğœŒ<ğœğ‘…
w.r.t.ğœŒmapping to the probability of failure of the VCL within
two control-loop executions and reliability thresholds ğœğ‘…between
0.019 and 0 .0641. Table 3 shows the degree of feature blame for 18
protection features of the 21 components of VCL (cf. Section 4.3).
The three components not shown in the table are input compo-
nents, having zero degree of blame and hence do not contributeto the systemsâ€™ reliability. With the lowest threshold
ğœğ‘…=0.019,
the effect set contains only 32 out of the 221feature configurations;
almost all protections of components are responsible for the lowprobability of failure. Increasing the threshold lowers the degreeof blame since the effect set increases, leading to less counterfac-tual witnesses. Using our blame analysis, we can directly deduce
advice for engineers about components protections towards high
reliability: With tight reliability constraints, one should protect the
â€œAccelerationâ€component,followedbytheâ€œIntegratorâ€component,
as their blames are significantly higher than for other components
(cf.upperrowsofTable3).Whenhigherfailureratesareacceptable,
one should prefer to protect the components â€œSum2â€ and â€œSum3â€
instead of the â€œIntegratorâ€ component due to their higher impact
on reliability (cf. lower rows of Table 3).
ForRQ3, we conclude that feature causes and degrees of blame
reveal and quantify the impact of features on the desired effect
and, this way, are able to guide the feature configuration process.
6.4 Feature Interactions (RQ 4)
Causalreasoningprovidesanewangletostudyfeatureinteractions
in configurable systems. For illustration of how to detect and iso-
late feature interactions, we perform causal analysis on the Lrzip
subject system, modeling a compression system for which runtime
characteristics of the compression algorithms are of interest. Since
thenumberoffeaturecausesandtheirexpansionscanbebothexpo-nentialinthenumberoffeatures,adirectevaluationoftheruntimesand causal analysis results is difficult. We hence investigate feature
interactions through their degrees of blame as described at the end
ofSection4.3.Thesubjecteffectsets EğœŒ>ğœğ‘‡dependontheruntime
ğœŒ:Vâ†’Rin seconds for a configuration compressing a file that is
obtained as by Siegmund et al. [ 53,77] and a runtime threshold ğœğ‘‡
1To ensure timely analysis results, real-world failure probability measures were in-
creased by a factor 100[34]. Resulting higher values might seem unrealistic but
arguably do not affect the causal analysis measuring the impact of protections.
333
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:52:58 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Clemens Dubslaff, Kallistos Weis, Christel Baier, and Sven Apel
Table 3: Feature blame for the VCL redundancy system
ğœğ‘…
[10âˆ’2]
MFunc
Sum1,
Sum4
Memory
MOne, P,
vCruise
SpentFuel,
I
D
Prod
DragForce,
EThrust
Integrator
Sum5
Sum3Sum2
Acceleration
1.90.631.000.631.001.001.000.631.001.001.001.001.001.00
2.00.700.800.770.820.941.000.700.821.000.800.800.801.00
2.20.490.550.550.610.750.950.490.611.000.550.550.551.00
2.50.350.380.360.400.460.650.350.401.000.380.380.381.00
2.90.280.290.280.290.310.330.280.290.910.290.290.291.00
3.40.280.290.300.300.320.380.280.300.570.290.300.300.97
4.00.260.270.270.270.280.310.260.270.370.270.340.340.86
4.70.240.250.250.250.250.260.250.250.300.250.360.360.78
5.50.240.240.240.240.250.260.240.250.270.260.370.390.68
6.40.23 0.23 0.23 0.230.240.240.240.250.270.270.350.410.61Table 4: Feature interaction blame for Lrzip
ğœğ‘‡ Gzip Lrzip Zpaq
[102s]89 4 â€“ 6 789 4 â€“ 7 8 â€“ 9
20.0020.009
3 0.0330.0330.0330.033
4 0.0420.0420.042
5 0.0420.0420.042
6 1-way 0.0420.0420.042
7 2-way 0.0560.0560.0560.0560.056
8 0.0560.0560.0560.0560.056
9 0.0630.063 0.0630.063
10 0.0630.063 0.0630.063
11 0.071 0.0710.071
12 0.0830.083
Â·Â·Â·22 0.0830.083
23 0.250
(see end of Section 3.1). We then focus on 2-way interactions by in-
vestigating potential feature interactions between the compression
algorithmandcompressionlevelresponsibletohavehighruntimes.
Forthiswecomputedegreesoffeatureinteractionblameforpartial
configurations ğœ•wheresupp(ğœ•)âˆˆ{Gzip,Lrzip,Zpaq}Ã—{1,...,9}
andğœ•(ğ‘¥)=truefor eachğ‘¥âˆˆsupp(ğœ•). In the columns of Table 4,
weshowthedegreesoffeatureinteractionblamesforthresholds ğœğ‘‡
ranging from ğœğ‘‡=200ğ‘ toğœğ‘‡=2300ğ‘ . Empty cells correspond to
combinationsofcompressionalgorithmandlevelthatdonotappear
in any cause and thus have zero blame. In these cases, we can con-
clude that no feature interaction takes place. Higher blame values
indicate that the combined responsibility of the compression algo-
rithmandlevelhasagreatercausalimpactonruntime.Notably,weobservethat,withanincreasingthreshold,thelevelofcompressionisincreasinglyresponsibleforlongerruntime.Certaincompression
algorithms always have runtimes above the threshold indepen-
dentlyofthecompressionlevel.Thisleadstoaconfigurationblame
of zero at any compression level, e.g., thresholds ğœğ‘‡â‰¤600ğ‘ for the
Zpaqalgorithm shown in the upper right of Table 4. Note that, in
these cases, Zpaqserves as 1-way interaction witness according to
Definition4.8.Allgreaterthresholdsfor LrzipandZpaqdonothave
1-way but 2-way interaction witnesses. That is, being above the
runtime threshold is a result of a feature interaction between the
compression algorithm and those compression levels not showing
zero blame. Notice that the sums of the given feature interaction
blames for ğœğ‘‡â‰¥700ğ‘ that contain algorithms LrziporZpaqadd up
to1/2.Thatis,nootherfeaturesaretobeblamedforexceedingthe
runtime threshold.
Features have a dedicated meaning and one would hence expect
higherruntimesforhighercompressionlevels.Tothisend,itseems
odd that the feature interaction of Lrzipand compression level 9
is less to blame for higher runtimes than for levels 7 and 8. This
indicates an anomaly of the feature interaction between Lrzipand
thecompressionlevels7,8,and9.Furtherinvestigationsonanalysis
results and feature causes support these findings: averaged over
all measurements of Lrzipconfigurations, we observe runtimes of
1064.9s at compression level 7 (standard deviation 4.1s), 1181.7s at
level8(standarddeviation3.2s),andonly830.5satlevel9(standard
deviation 2.6s). Hence, Lrzipat level 9 is not causally relevant for
exceedingtheexecutiontimethresholdof900s,asthecompression
level 9 feature is not contained in any cause with Lrzip. However,
this insight is difficult to obtain relying purely on the performanceinfluencemodelgivenby ğœŒ,asthiswouldrequirehandcraftedanal-
ysis of all 432 analysis results (see Table 1).
ForRQ4we conclude that feature causes can provide hints for
feature interactions and anomalies arising from them. Blame
measures render themselves promising to quantify the influence
of feature interactions that contribute to certain effects.
7 DISCUSSION
In this section, we discuss potential threats to validity of our exper-
iments and relate our findings to existing work from the literature.
7.1 Threats to Validity
A threat to internal validity arises from the correctness of the anal-
ysis results from which we generated the effect sets. While for
functional properties this threat is not crucial due to exact model-
checking techniques used in our experiments, for non-functional
properties the results have been partly established using machine
learning.Tomitigatethisthreat,wecarefullychoseeffect-setthresh-oldssuchthattheeffectsetsremainstablealsowithinsmallthresh-oldvariations.Notethatthechoiceoftheeffectsethasnoinfluenceontheapplicabilityofourcausalitydefinitionsbutonlyontowhatextentcausalitycanserveasanexplication.Forblamecomputations
in our experiments, we assumed a uniform distribution over all
effects, taking a developersâ€™ perspective where frequencies on how
often an effect occurs in a real-world setting are not yet accessible.
Other distributions could change our quantitative results, it is un-
likelythattheywouldalterourconclusionsaboutcausalinfluencesoffeaturesandfeatureinteractions.Toincreasetheinternalvalidity
of our prototype, we implemented and evaluated several methods
to compute causes. These include a naive brute-force approach and
two additional methods to generate prime implicants, independent
from the tool Espresso.
Naturally, the choice of subject systems threatens external valid-
ity, which includes the kinds of effect sets on which we evaluatecausality. To alleviate this threat, we included a wide variety of
systems with multiple properties from different areas to our eval-
uation. They comprise several real-world software systems often
used to evaluate sampling strategies and performance-modeling
approaches.Wefurtheraddedseveralcommunitybenchmarksfrom
the feature-oriented model-checking community as well as a large-
scale redundancy system from reliability engineering.
334
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:52:58 UTC from IEEE Xplore.  Restrictions apply. Causality in Configurable Software Systems ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
7.2 Related Work
Various techniques for software defect detection have been pro-
posed in the literature, ranging from testing [ 62] and static code
analysis [ 64] to model checking [ 9]. These techniques have been
also extended for analyzing configurable systems to tackle huge
configuration spaces [ 85]. While such methods are able to iden-
tify defects and their location, the challenge of finding root causes
for defects remains. A methodology to identify causes of defects
during software development is provided through root cause analy-
sis[73,75], which can be supported by a multitude of techniques
for causal reasoning [ 66,67]. To the best of our knowledge, the
foundationsforacombinationofconfigurablesystemsanalysisand
causal reasoning as we presented in this paper have not yet been
addressedintheliterature.Inthefollowing,wediscussrelatedwork
in the fields of configurable systems analysis and causal reasoning.
Configurablesystemsanalysisandexplications. Foranalyzing
configurable software systems, many approaches have been pre-
sented in the last two decades [ 70,85]. There is broad tool support
forvariability-awaretestingandsampling[ 10,44,52,53,80],static
analysis[ 12,72,87,88,91],andmodelchecking[ 5,19,23,25,68,86].
There is a substantial corpus of work on determining those fea-
tures in a configurable system that are responsible for emerging
effects [e.g. 56,71,93]. The focus has been mainly on detecting fea-
ture interactions [ 3,14,15]. Siegmund et al. [ 78] and Kolesnikov et
al. [55] describe non-functional feature interactions as interactions
where the composed non-functional property diverges from the
aggregation of the individual contributions of the single features.
Garvin and Cohen [ 40] provided a formal definition of feature in-
teraction faults based on black-box analysis to guide white-box
isolation of interaction faults.
An incremental software configuration approach to optimize
non-functional properties has been presented by Nair et al. [ 63],
which complements our causality-guided software configuration
we exemplified in Section 6.3 based on feature causality and pre-
computed analysis results.
Toreducethesizeofpropositionallogicformulasinconfigurable
systems,vonRheinetal.[ 89]proposedtoexcludeinformationabout
valid configurations and use two-level logic minimization, e.g., by
the Espresso heuristics [ 60,61]. Our DLS method differs from this
approach by prioritizing causal information over reduction.
Causal reasoning. Algorithmic reasoning about actual causes
following the structural-equation approach by Halpern and Pearl
[45,46]iscomputationallyhardinthegeneralcase[ 2,38].However,
tractableinstancessuchastheBooleancasehavebeenidentifiedbyEiter and Lukasiewicz [
39]. For deciding whether a partial interpre-
tationisanactualcauseintheBooleancase,IbrahimandPretschner
presented an approach based on SAT solving [ 49]. To compute all
causes, their implementation relies on checking causality for all
possible partial interpretations, suffering from an additional expo-
nential blowup in the number of variables, which we avoid within
our approach using prime implicant computations.
Using test generation methods relying on program trace infor-
mation, program locations that are the origin of the defect can be
identified [ 51,76]. Analyzing differences between program states
of sampled failing and passing executions, deltadebugging identi-
fies code positions relevant for an emerging failure [ 24]. Similarly,causes for detects can be determined by analyzing counterexample
traces [11,43]. Faults can be also located by causal inference on
graphs constructed from statement and test coverage data [7].
Iqbal et al. present a static technique to generate causal models
of a given configurable system using causal interference and sta-
tistical counterfactual reasoning [ 50]. This model is used to detect
performance bugs and provide hints for their resolution. While we
focused on actual causality and rigorous analysis, they are inter-
ested intype causality to answer more generic questions.
8 CONCLUDING REMARKS
Finding actual causes for an effect event becomes increasingly im-
portant in many research areas, also driven by high demands from
politics and society. We introduced a formal definition and algo-rithms to identify causes in configurable systems that relies oncounterfactual reasoning and connections to classical problems
of propositional logics and circuit optimization. We demonstrated
their potential by analyzing several subject systems, including real-
world software systems and popular community benchmarks. To
enable explanations for causes and their impact onto effects, we
proposed explication techniques to concisely represent causes and
quantify the causal impact of features. We showed that our ex-plications are meaningful and can support the development of
configurable software systems by causality-guided configuration
andisolatingfeatureinteractions.Withourprototypicalimplemen-
tation, we showed that our algorithms are effective on real-world
systems of varying sizes and run in reasonable time.
While already shown to be effective, our implementation could
be enhanced by directly integrating feature cause computationsinto optimized algorithms to compute prime implicants, e.g., re-lying on prime implicant computations at the level of BDDs [
26].
Combined with state-of-the-art BDD libraries such as CUDD [82],
the computation of causes might become feasible for even larger
systems than considered in this paper.
Another direction is by enhancing our analysis of feature inter-
action blames (see Theorem 4.9) with in-depth white-box analy-
ses [40] to pinpoint root causes in source code for a great variety
of effect properties using feature causality.
Further applications could be imagined for context-aware sys-
temswhere feature-oriented formalisms have been shown great
applicability [ 18,33,59]. Here, our causal framework could reason
about contexts responsible for certain effects, e.g., in self-adaptive
systems [ 6]. In this vein, dynamic configurable systems [30,41]a r e
also an interesting direction to be considered. In such systems, fea-
tures can be activated or deactivated during runtime, e.g., to model
upgrade and downgrade of systems. The detection and isolation
of feature interactions in dynamic configurable systems is a well-
known challenge [ 58]. It is a promising avenue of further work to
extend our causal framework to determine root causes and identify
feature interactions in the dynamic setting [11].
Acknowledgments. TheauthorsaresupportedbytheDFGthrough
the Collaborative Research Center TRR 248 (https://perspicuous-computing.science), the Cluster of Excellence EXC 2050/1 (CeTI,project ID 390696704, as part of Germanyâ€™s Excellence Strategy,
project AP 206/11-1, and the Research Training Groups QuantLA
(GRK 1763) and RoSI (GRK 1907).
335
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:52:58 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Clemens Dubslaff, Kallistos Weis, Christel Baier, and Sven Apel
REFERENCES
[1]Iago Abal, Jean Melo, Åtefan StÄƒnciulescu, Claus Brabrand, MÃ¡rcio Ribeiro, and
Andrzej WÄ…sowski. 2018. Variability Bugs in Highly Configurable Systems: A
Qualitative Analysis. TransactionsonSoftwareEngineeringandMethodology 26,
Article 10 (2018).
[2]Gadi Aleksandrowicz, Hana Chockler, Joseph Y. Halpern, and Alexander Ivrii.
2017. The Computational Complexity of Structure-Based Causality. Artificial
Intelligence Research 58 (2017), 431â€“451.
[3]Sven Apel, Joanne M. Atlee, Luciano Baresi, and Pamela Zave. 2014. Feature
Interactions: The Next Generation (Dagstuhl Seminar 14281). Dagstuhl Reports 4
(2014), 1â€“24.
[4]Sven Apel, Don S. Batory, Christian KÃ¤stner, and Gunter Saake. 2013. Feature-
Oriented Software Product Lines - Concepts and Implementation. Springer.
[5]Sven Apel, Alexander von Rhein, Philipp Wendler, Armin GrÃ¶ÃŸlinger, and Dirk
Beyer.2013.Strategiesforproduct-lineverification:Casestudiesandexperiments.InProceedingsof the35thInternationalConferenceonSoftwareEngineering(ICSE).
IEEE, 482â€“491.
[6]Uwe AÃŸmann, Christel Baier, Clemens Dubslaff, Dominik Grzelak, Simon
Hanisch, Ardhi P P Hartono, Stefan KÃ¶psell, Tianfang Lin, and Thorsten Strufe.
2021.Tactilecomputing:EssentialbuildingblocksfortheTactileInternet. Academic
Press, Chapter 13, 301â€“326.
[7]George K. Baah, Andy Podgurski, and Mary Jean Harrold. 2010. Causal Infer-ence for Statistical Fault Localization. In Proceedings of the 19th International
Symposium on Software Testing and Analysis (ISSTA). ACM, 73â€“84.
[8]ChristelBaier,ClemensDubslaff,FlorianFunke,SimonJantsch,RupakMajumdar,
Jakob Piribauer, and Robin Ziemek. 2021. From Verification to Causality-Based
Explications. In Proceedings of the 48th International Colloquium on Automata,
Languages,andProgramming(ICALP) ,Vol.LIPIcs:198.SchlossDagstuhlâ€“Leibniz-
Zentrum fÃ¼r Informatik, 1â€“20.
[9] Christel Baier and Joost-Pieter Katoen. 2008. Principles of Model Checking.M I T
Press.
[10]MauriceH.terBeek,FerruccioDamiani,MichaelLienhardt,FrancoMazzanti,andLucaPaolini.2019. StaticAnalysisofFeaturedTransitionSystems.In Proceedings
of the 23rd Systems and Software Product Line Conference (SPLC). ACM, 39â€“51.
[11]IlanBeer,ShohamBen-David,HanaChockler,AvigailOrni,andRichardJ.Trefler.
2012. Explaining counterexamples using causality. Formal Methods in System
Design40 (2012), 20â€“40.
[12]Eric Bodden, TÃ¡rsis TolÃªdo, MÃ¡rcio Ribeiro, Claus Brabrand, Paulo Borba, and
Mira Mezini. 2013. SPLLIFT: statically analyzing software product lines in min-
utes instead of years. In Proceedings of the 34th Conference on Programming
Language Design and Implementation (PLDI). ACM, 355â€“364.
[13]Randal E. Bryant. 1986. Graph-Based Algorithms for Boolean Function Manipu-
lation.Transactions on Computers 35 (1986), 677â€“691.
[14]MuffyCalder,MarioKolberg,EvanH.Magill,andStephanReiff-Marganiec.2003.Featureinteraction:acriticalreviewandconsideredforecast. ComputerNetworks
41 (2003), 115â€“141.
[15]Muffy Calder and Alice Miller. 2006. Feature interaction detection by pairwise
analysis of LTL propertiesâ€”A case study. FormalMethodsinSystemDesign 28
(2006), 213â€“261.
[16]Ashok K. Chandra and George Markowsky. 1978. On the number of prime
implicants. Discrete Mathematics 24 (1978), 7â€“11.
[17]Hana Chockler and Joseph Y. Halpern. 2004. Responsibility and Blame: A
Structural-Model Approach. Artificial Intelligence Research 22 (2004), 93â€“115.
[18]Philipp Chrszon, Christel Baier, Clemens Dubslaff, and Sascha KlÃ¼ppelholz. 2020.
From Features to Roles. In Proceedingsofthe24thSystemsandSoftwareProduct
Line Conference (SPLC). ACM, Article 19, 11 pages.
[19]Philipp Chrszon, Clemens Dubslaff, Sascha KlÃ¼ppelholz, and Christel Baier. 2018.ProFeat:feature-orientedengineeringforfamily-basedprobabilisticmodelcheck-
ing.Formal Aspects of Computing 30 (2018), 45â€“75.
[20]Edmund M. Clarke, E. Allen Emerson, and Aravinda P. Sistla. 1986. Automatic
verificationoffinite-stateconcurrentsystemsusingtemporallogicspecifications.
Transactions on Programming Languages and Systems 8 (1986), 244â€“263.
[21]AndreasClassen,QuentinBoucher,andPatrickHeymans.2011. AText-basedAp-
proach to Feature Modelling: Syntax and Semantics of TVL. Science of Computer
Programming 76 (2011), 1130â€“1143.
[22]Andreas Classen, Maxime Cordy, Patrick Heymans, Axel Legay, and Pierre-Yves
Schobbens.2012. ModelcheckingsoftwareproductlineswithSNIP. International
Journal on Software Tools for Technology Transfer 14 (2012), 589â€“612.
[23]Andreas Classen, Maxime Cordy, Pierre-Yves Schobbens, Patrick Heymans, Axel
Legay,andJean-FranÃ§oisRaskin.2013. FeaturedTransitionSystems:Foundations
for Verifying Variability-Intensive Systems and Their Application to LTL Model
Checking. Transactions on Software Engineering 39 (2013), 1069â€“1089.
[24]Holger Cleve and Andreas Zeller. 2005. Locating causes of program failures. In
Proceedingsofthe27thInternationalConferenceonSoftwareEngineering(ICSE).
ACM, 342â€“351.
[25]Maxime Cordy, Andreas Classen, Patrick Heymans, Pierre-Yves Schobbens, and
Axel Legay. 2013. ProVeLines: a product line of verifiers for software productlines. InProceedings of the 17th Systems and Software Product Line Conference
(SPLC). ACM, 141â€“146.
[26]Olivier Coudert and Jean Christophe Madre. 1992. Implicit and Incremental
ComputationofPrimesandEssentialPrimesofBooleanFunctions.In Proceedings
of the 29th European Design Automation Conference (EURO-DAC). IEEE, 36â€“39.
[27]Johannes Dorn, Sven Apel, and Norbert Siegmund. 2020. Mastering Uncertainty
in Performance Estimations of Configurable Software Systems. In Proceedings of
the 35th Conference on Automated Software Engineering (ASE). IEEE, 684â€“696.
[28]Chris Drake. 2015. Pyeda: Data structures and algorithms for electronic design
automation.In Proceedingsofthe14thPythoninScienceConference(SciPy).26â€“31.
[29]Clemens Dubslaff. 2019. Compositional Feature-Oriented Systems. In Proceed-
ingsof the17thConference onSoftware EngineeringandFormal Methods(SEFM),
Vol. LNCS:12226. Springer, 162â€“180.
[30]ClemensDubslaff.2021. QuantitativeAnalysisofConfigurableandReconfigurable
Systems. Ph.D. Dissertation. TU Dresden, Institute for Theoretical Computer
Science.
[31]Clemens Dubslaff, Christel Baier, and Sascha KlÃ¼ppelholz. 2015. Probabilistic
Model Checking for Feature-Oriented Systems. Transactions on Aspect-Oriented
Software Development LNCS:8989 (2015), 180â€“220.
[32]ClemensDubslaff,KaiDing,AndreyMorozov,ChristelBaier,andKlausJanschek.2019. Breaking the Limits of Redundancy Systems Analysis. In Proceedings of the
29th European Safety and Reliability Conference (ESREL). 2317â€“2325.
[33]ClemensDubslaff,PatrickKoopmann,andAnni-YasminTurhan.2019. Ontology-
Mediated Probabilistic Model Checking. In Proceedings of the 15th Conference on
integrated Formal Methods (iFM), Vol. LNCS:11918. Springer, 194â€“211.
[34]ClemensDubslaff,AndreyMorozov,ChristelBaier,andKlausJanschek.2020. Iter-ativeVariableReordering:TamingHugeSystemFamilies.In Proceedingsofthe4th
Workshop on Models for Formal Analysis of Real Systems (MARS), Vol. EPTCS:316.
Open Publishing Association, 121â€“133.
[35]ClemensDubslaff,AndreyMorozov,ChristelBaier,andKlausJanschek.2020. Re-ductionMethodsonError-PropagationGraphsforQuantitativeSystemsReliabil-ity Analysis. In Proceedingsof the30thEuropeanSafetyand ReliabilityConference
(ESREL) and 15th Probabilistic Safety Assessment and Management Conference
(PSAM).
[36]Clemens Dubslaff, Kallistos Weis, Christel Baier, and Sven Apel. 2021. FeatCause
â€“ Sources and Data. https://github.com/dubslaff/FeatCause
[37] Ellery Eells. 1991. Probabilistic causality. Cambridge University Press.
[38]Thomas Eiter and Thomas Lukasiewicz. 2002. Complexity results for structure-
based causality. Artificial Intelligence 142 (2002), 53â€“89.
[39]Thomas Eiter and Thomas Lukasiewicz. 2006. Causes and explanations in the
structural-model approach: Tractable cases. Artifical Intelligence 170, 6-7 (2006),
542â€“580.
[40]Brady J. Garvin and Myra B. Cohen. 2011. Feature Interaction Faults Revisited:
An Exploratory Study. In Proceedings of the 22nd International Symposium on
Software Reliability Engineering (ISSRE). ACM, 90â€“99.
[41]HassanGomaaandMohamedHussein.2003. DynamicSoftwareReconfiguration
in Software Product Families. In Proceedings of the 5th Workshop on Software
Profuct Family Engineering (PFE), Vol. LNCS:3014. 435â€“444.
[42]Irving J. Good. 1959. A theory of causality. BritishJournalforthePhilosophyof
Science9 (1959), 307â€“310.
[43]Alex Groce and Willem Visser. 2003. What Went Wrong: Explaining Coun-
terexamples. In Proceedings of the 10th Workshop on Model Checking of Software,
Vol. LNCS:2648. Springer, 121â€“135.
[44]Jianmei Guo, Dingyu Yang, Norbert Siegmund, Sven Apel, Atrisha Sarkar, Pavel
Valov, Krzysztof Czarnecki, Andrzej Wasowski, and Huiqun Yu. 2018. Data-
Efficient Performance Learning for Configurable Systems. Empirical Software
Engineering 23 (2018), 1826â€“1867.
[45]Joseph Y. Halpern. 2015. A Modification of the Halpern-Pearl Definition ofCausality. In Proceedingsofthe24thInternationalJointConferenceonArtificial
Intelligence (IJCAI). AAAI, 3022â€“3033.
[46]Joseph Y. Halpern and Judea Pearl. 2001. Causes and Explanations: A Structural-
Model Approach - Part I: Causes. In Proceedings of the 17th Conference in Uncer-
tainty in Artificial Intelligence (UAI). Morgan Kaufmann, 194â€“202.
[47]Joseph Y. Halpern and Judea Pearl. 2001. Causes and Explanations: A Structural-
Model Approach - Part II: Explanations. In Proceedingsof the17thInternational
Joint Conference on Artificial Intelligence (IJCAI). Morgan Kaufmann, 27â€“34.
[48]Edith Hemaspaandra and Henning Schnoor. 2011. Minimization for Generalized
Boolean Formulas. In Proceedingsofthe22ndInternationalJointConferenceon
Artificial Intelligence (IJCAI). IJCAI/AAAI, 566â€“571.
[49]Amjad Ibrahim and Alexander Pretschner. 2020. From Checking to Inference:
Actual Causality Computations as Optimization Problems. In Proceedings of
the18thSymposiumAutomatedTechnologyforVerificationandAnalysis(ATVA),
Vol. LNCS:12302. Springer, 343â€“359.
[50]Md Shahriar Iqbal, Rahul Krishna, Mohammad Ali Javidian, Baishakhi Ray, and
Pooyan Jamshidi. 2021. CADET: Debugging and Fixing Misconfigurations using
Counterfactual Reasoning. arXiv:2010.06061 [cs.SE]
[51]Brittany Johnson, Yuriy Brun, and Alexandra Meliou. 2020. Causal Testing:Understanding Defectsâ€™ Root Causes. In Proceedings of the 42nd International
336
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:52:58 UTC from IEEE Xplore.  Restrictions apply. Causality in Configurable Software Systems ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Conference on Software Engineering (ICSE). ACM, 87â€“99.
[52]Christian Kaltenecker, Alexander Grebhahn, Norbert Siegmund, and Sven Apel.
2020. TheInterplayofSamplingandMachineLearningforSoftwarePerformance
Prediction. Software 37 (2020), 58â€“66.
[53]Christian Kaltenecker, Alexander Grebhahn, Norbert Siegmund, Jianmei Guo,
andSvenApel.2019. Distance-BasedSamplingofSoftwareConfigurationSpaces.
InProceedings of the 41st International Conference on Software Engineering (ICSE).
IEEE, 1084â€“1094.
[54]KyoC.Kang,SholomG.Cohen,JamesA.Hess,WilliamE.Novak,andA.Spencer
Peterson.1990. Feature-OrientedDomainAnalysis(FODA)FeasibilityStudy. Tech-
nical Report. Carnegie-Mellon University Software Engineering Institute.
[55]SergiyS.Kolesnikov,NorbertSiegmund,ChristianKÃ¤stner,AlexanderGrebhahn,
and Sven Apel. 2019. Tradeoffs in modeling performance of highly configurable
software systems. Software and Systems Modeling 18 (2019), 2265â€“2283.
[56]D. Richard Kuhn, Dolores R. Wallace, and Albert M. Gallo. 2004. Software fault
interactions and implications for software testing. Transactions on Software
Engineering 30 (2004), 418â€“421.
[57]David Lewis. 1973. Counterfactual Theories of Causation. Journal of Philosophy
(1973), 556â€“567.
[58]Yu Liu and RenÃ© Meier. 2009. Resource-Aware Contracts for Addressing FeatureInteraction in Dynamic Adaptive Systems. In Proceedings of the 5th International
Conference on Autonomic and Autonomous Systems (ICAS). IEEE, 346â€“350.
[59]JacopoMauro,MichaelNieke,ChristophSeidl,andIngridChiehYu.2016.Context
Aware Reconfiguration in Software Product Lines. In Proceedings of the 10th
Workshop on Variability Modelling of Software-intensive Systems (VaMoS). ACM,
41â€“48.
[60]Edward J. McCluskey Jr. 1956. Minimization of Boolean Functions. BellSystem
Technical Journal 35 (1956), 1417â€“1444.
[61]Patrick McGeer, Jagesh Sanghavi, Robert Brayton, and Alberto Sangiovanni
Vincentelli.1993.Espresso-Signature:ANewExactMinimizerforLogicFunctions.
InProceedings of the 30th Design Automation Conference (DAC). ACM, 618â€“624.
[62] Glenford J. Myers. 2004. The art of software testing. Wiley.
[63]VivekNair,ZheYu,TimMenzies,NorbertSiegmund,andSvenApel.2020.Finding
Faster Configurations Using FLASH. Transactions on Software Engineering 46
(2020), 794â€“811.
[64]Flemming Nielson, Hanne R. Nielson, and Chris Hankin. 2010. Principles of
Program Analysis. Springer.
[65]WolfgangJ.Paul.1975. BoolescheMinimalpolynomeundÃœberdeckungsprobleme.
Acta Informatica 4 (1975), 321â€“336.
[66]JudeaPearl.2009. Causality:Models,ReasoningandInference (2nded.). Cambridge
University Press.
[67] J. Peters, D. Janzing, and B. SchÃ¶lkopf. 2017. Elements ofCausal Inference:Foun-
dations and Learning Algorithms. MIT Press.
[68]Malte Plath and Mark Ryan. 2001. Feature integration using a feature construct.
Science of Computer Programming 41 (2001), 53â€“84.
[69]Amir Pnueli. 1977. The Temporal Logic of Programs. In Proceedingsofthe18th
Symposium on Foundations of Computer Science (SFCS). IEEE, 46â€“57.
[70]H. Post and C. Sinz. 2008. Configuration Lifting: Verification Meets Software
Configuration. In Proceedings of the 23rd Conference on Automated Software Engi-
neering (ASE). IEEE, 347â€“350.
[71]Xiao Qu, Myra B. Cohen, and Gregg Rothermel. 2008. Configuration-Aware
Regression Testing: An Empirical Study of Sampling and Prioritization. In Pro-
ceedings of the 17th International Symposium on Software Testing and Analysis
(ISSTA). ACM, 75â€“86.
[72]Alexander Von Rhein, JÃ¶rg Liebig, Andreas Janker, Christian KÃ¤stner, and Sven
Apel.2018. Variability-AwareStaticAnalysisatScale:AnEmpiricalStudy. Trans-
actions on Software Engineering and Methodology 27, Article 18 (2018).
[73]ABSGroupInc.RiskandReliabilityDivision.1999. RootCauseAnalysisHandbook:
A Guide to Effective Incident Investigation. Government Institutes.
[74]GenaÃ­na Nunes Rodrigues, Vander Alves, Vinicius Nunes, AndrÃ© Lanna, Maxime
Cordy, Pierre-Yves Schobbens, Amir Molzam Sharifloo, and Axel Legay. 2015.
Modeling and Verification for Probabilistic Properties in Software Product Lines.
InProceedings of the 16th Symposium on High Assurance Systems Engineering
(HASE). IEEE, 173â€“180.
[75]James J Rooney and Lee N. Vanden Heuvel. 2004. Root Cause Analysis For
Beginners. Quality Progress 37 (2004), 45.
[76]Jeremias RÃ¶ÃŸler, Gordon Fraser, Andreas Zeller, and Alessandro Orso. 2012. Iso-
lating Failure Causes through Test Case Generation. In Proceedingsofthe2012
InternationalSymposiumonSoftwareTestingandAnalysis(ISSTA) .ACM,309â€“319.
[77]Norbert Siegmund, Alexander Grebhahn, Sven Apel, and Christian KÃ¤stner. 2015.
Performance-Influence Models for Highly Configurable Systems. In Proceedings
ofthe10thJointMeetingonFoundationsofSoftwareEngineering(ESEC/FSE).ACM,
284â€“294.
[78]Norbert Siegmund, Sergiy S. Kolesnikov, Christian KÃ¤stner, Sven Apel, Don
Batory,MarkoRosenmÃ¼ller,andGunterSaake.2012. Predictingperformancevia
automated feature-interaction detection. In Proceedingsof the34thInternational
Conference on Software Engineering (ICSE). IEEE, 167â€“177.[79]Norbert Siegmund, Marko RosenmÃ¼ller, Christian KÃ¤stner, Paolo G. Giarrusso,
Sven Apel, and Sergiy S. Kolesnikov. 2013. Scalable prediction of non-functional
properties in software product lines: Footprint and memory consumption. Infor-
mationandSoftwareTechnology 55 (2013), 491â€“507. Special Issue on Software
Reuse and Product Lines.
[80]Norbert Siegmund, Marko RosenmÃ¼ller, Martin Kuhlemann, Christian KÃ¤stner,
Sven Apel, and Gunter Saake. 2012. SPL Conqueror: Toward Optimization of
Non-Functional Properties in Software Product Lines. Software Quality Journal
20 (2012), 487â€“517.
[81]Norbert Siegmund, Alexander von Rhein Sven, and Apel. 2013. Family-based
Performance Measurement. SIGPLAN Notices 49, 3 (2013), 95â€“104.
[82]Fabio Somenzi. 1997. CUDD 3.0.0. http://vlsi.colorado.edu/~fabio/CUDD/html/
[83] Tadeusz Strzemecki. 1992. Polynomial-time algorithms for generation of prime
implicants. Journal of Complexity 8 (1992), 37â€“63.
[84]Maurice H. ter Beek, Axel Legay, Alberto Lluch Lafuente, and Andrea Vandin.2016. Statistical Model Checking for Product Lines. In Proceedings of the 7th
SymposiumonLeveragingApplicationsofFormalMethods(ISoLA),Vol.LNCS:9952.
Springer, 114â€“133.
[85]Thomas ThÃ¼m, Sven Apel, Christian KÃ¤stner, Ina Schaefer, and Gunter Saake.2014. A Classification and Survey of Analysis Strategies for Software Product
Lines.Computing Surveys 47 (2014), 6:1â€“6:45.
[86]Andrea Vandin, Maurice H. ter Beek, Axel Legay, and Alberto Lluch La-fuente. 2018. QFLan: A Tool for the Quantitative Analysis of Highly Recon-
figurableSystems.In Proceedingsonthe22ndSymposiumonFormalMethods(FM),
Vol. LNCS:10951. Springer, 329â€“337.
[87]Miguel Velez, Pooyan Jamshidi, Florian Sattler, Norbert Siegmund, Sven Apel,
and Christian KÃ¤stner. 2020. ConfigCrusher: Towards White-Box Performance
Analysis for Configurable Systems. AutomatedSoftwareEngineering 27 (2020),
265â€“300.
[88]MiguelVelez,PooyanJamshidi,NorbertSiegmund,SvenApel,andChristianKÃ¤st-
ner. 2021. White-Box Analysis over Machine Learning: Modeling Performance
of Configurable Systems. In Proceedingsofthe43rdInternationalConferenceon
Software Engineering (ICSE). IEEE.
[89]Alexander von Rhein, Alexander Grebhahn, Sven Apel, Norbert Siegmund, Dirk
Beyer, and Thorsten Berger. 2015. Presence-Condition Simplification in Highly
Configurable Systems. In Proceedings of the 37th International Conference on
Software Engineering (ICSE). IEEE, 178â€“188.
[90]Sandra Wachter, Brent D. Mittelstadt, and Chris Russell. 2017. CounterfactualExplanations without Opening the Black Box: Automated Decisions and the
GDPR.Harvard Journal of Law and Technology 31 (2017), 841â€“887.
[91]Max Weber, Sven Apel, and Norbert Siegmund. 2021. White-Box Performance-
Influence Models: A Profiling and Learning Approach. In Proceedings of the 43rd
International Conference on Software Engineering (ICSE). IEEE.
[92]Jon Williamson. 2009. Probabilistic Theories of Causation. The Oxford Handbook
of Causation (2009), 185â€“212.
[93]Cemal Yilmaz, Myra B. Cohen, and Adam A. Porter. 2006. Covering arrays for
efficient fault characterization in complex configuration spaces. Transactions on
Software Engineering 32 (2006), 20â€“34.
[94]Pamela Zave. 2001. Feature-Oriented Description, Formal Methods, and DFC.InProceedings of the Workshop on Language Constructs for Describing Features.
Springer, 11â€“26.
[95]AndreasZeller.2002. IsolatingCause-EffectChainsfromComputerPrograms.In
Proceedings of the 10thSymposium on Foundations of Software Engineering(FSE).
ACM, 1â€“10.
[96]Yi Zhang, Jianmei Guo, Eric Blais, and Krzysztof Czarnecki. 2015. Performance
Prediction of Configurable Software Systems by Fourier Learning (T). In Pro-
ceedingsofthe30thConferenceonAutomatedSoftwareEngineering(ASE). IEEE,
365â€“373.
337
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:52:58 UTC from IEEE Xplore.  Restrictions apply. 