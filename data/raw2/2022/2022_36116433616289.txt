Contextual PredictiveMutation Testing
Kush Jain
CarnegieMellonUniversity
UnitedStatesUriAlon
CarnegieMellonUniversity
UnitedStates
Alex Groce
NorthernArizona University
UnitedStatesClaire Le Goues
CarnegieMellonUniversity
UnitedStates
ABSTRACT
Mutation testing is a powerful technique for assessing and improv-
ing test suite quality that arti/f_icially introduces bugs and checks
whetherthetestsuitescatchthem.However,itisalsocomputation-
ally expensive and rarely scalesto large projects. One promising
recent approach to tackling this problem uses machine learning to
predict whether the tests will detect the synthetic bugs, without
actually running those tests. However, existing predictive muta-
tiontestingapproachesstillmisclassify33%ofarandomlysampled
setofmutant-testsuitepairs.WeintroduceMutationBERT,anap-
proachforpredictivemutationtestingthatsimultaneouslyencodes
thesourcemethodmutationandtestmethod,capturingkey context
in the input representation. Thanks to its higher precision, Mu-
tationBERT saves 33% of the time spent by prior work to verify
livemutants,andimprovesprecision,recall,andF1scoreinboth
same project and cross project settings. MutationBERT not only
enhances the state-of-the-art in predictive mutation testing, but
also presents practical bene/f_its for real-world applications, both in
savingdevelopertime and/f_indinghardtodetect mutants.
CCSCONCEPTS
•Software and its engineering →Dynamic analysis ;Soft-
ware testing and debugging .
KEYWORDS
test oracles,code coverage,mutation analysis
ACM ReferenceFormat:
Kush Jain, Uri Alon, Alex Groce, and Claire Le Goues. 2023. Contextual
Predictive Mutation Testing. In Proceedings of the 31st ACM Joint European
Software Engineering Conference and Symposium on the Foundations of Soft-
wareEngineering(ESEC/FSE’23),December3–9,2023,SanFrancisco,CA,USA.
ACM,NewYork,NY,USA, 12pages.https://doi.org/10.1145/3611643.3616289
1 INTRODUCTION
Mutation testing is a well established technique for evaluating test
suite quality [ 7,12,15]. Mutation testing works by introducing
synthetic bugs based on a /f_ixed set of rules (“mutation operators”),
rangingfrominvertingconditionalstatementstochangingunary
ESEC/FSE ’23,December 3–9, 2023, SanFrancisco, CA, USA
©2023 Copyright held bytheowner/author(s).
ACM ISBN979-8-4007-0327-0/23/12.
https://doi.org/10.1145/3611643.3616289andbinaryoperators.Thetestsuiteisthenrunoneachbuggycode
copy (also referred to as a “mutant” of the original program. If the
test suite fails on a mutant, the mutant is considered “detected”
(or“killed”;thisisthedesiredoutcome),otherwisethemutantis
“undetected”(a“live”mutant).
Empirically, mutation testing has been shown to improve test
suites in ways correlated with real world fault detection [ 17,25].
However, one of its major limitations is its computational cost:
test suites must be run on each mutant, in principle. Large-scale
systems commonly have hundreds of thousands of mutants [ 9,11],
since mutants scale with size of the codebase and mutation opera-
tors considered. Myriad approaches, including weak mutation [ 14],
meta mutation [ 31], mutation sampling [ 9], and mutant prioriti-
zation[19],havebeenproposedtotacklethiscomputationalcost.
However,theytypicallyrequirestillintractablyexpensiveinstru-
mentationorstaticanddynamicanalyses,andusuallyrelyonsome
kindofrandomsampling,compromisingtheir usefulnessinprac-
tice.Mutationtestinghasbeguntoachieveindustryadoption[ 4,26]
atcompanieslikeMetaandGoogle,leveragingadditionalheuris-
tics and idle compute time. However, current industrial practice
is focused on identifying undetected mutants in newly committed
code.Thisis,inessence,thetipoftheiceberg;thevastunderwa-
terdomainofundetectedmutants(and,thus,testweaknesses)in
existingcodepre-datestheadoptionoflimitedmutationanalysis.
Runningallmutantsonexistinglargecodebasestosurfacethese
problems is stilltooexpensive.
Research on Predictive Mutation Testing1[20,22,36] takes a
diﬀerent approach to scalable mutation testing, using machine
learningto predict whetheramutant will be detected ornot with-
outactuallyrunningthetests. TheinitialPMTwork[ 36]empirically
demonstratedacorrelationbetweenstaticanddynamiccodefea-
tures and mutant detection, but falls short of practical utility [ 1] in
termsofactualF1oraccuracyoftheresultingmodel.Seshat[ 20]
improvesontheoriginalPMTmodelbyusing“naturallanguage
channels”, including the modi/f_ied code (pre- and post-mutation),
andkeywordsfromthetestmethodandsourcemethodname.This
eliminatestheexpensivedynamicanalysesfromthePMTapproach
andprovidesmoredetailedpredictionofwhichtestsdetectamutant
inparticular(themutant-testmatrix).However,althoughSeshat
outperformstheoriginalPMTmodel,itstillsuﬀersfromsigni/f_icant
false postives, with a precision of 0.66 on our test set (Section 4),
costingvaluable developertime.
1The /f_irst publication [ 36] both named the problem “Predictive Mutation Testing” and
introducedamodel/approachtosolveitnamed“PMT”.Ingeneralinthispaper,weuse
“PMT” to refer to the problem of predicting whether a test/suite will detect a mutant,
rather than thespeci/f_icmodelproposed in that paper.
Thiswork islicensedunderaCreativeCommonsAttribution4.0Interna-
tional License.
250
ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA Kush Jain, Uri Alon,AlexGroce,andClaire Le Goues
Code Files
Test FilesM1 M2
T1
T2
Mutant-Test Matrix
 Mutation Testing
ToolData
PreprocessingMutationBERT 
Model 
Mutated Method-Covered
Test Suite PairsMutant-Test
Method File Pair1 2 3 4
Figure 1: An overview of MutationBERT’s work/f_low. Step 1○provides source and test /f_iles to a mutation testing tool. In Step
2○, the mutation tool generates mutants and correspondng covering tests, which are preprocessed, tokenized, and formatted.
InStep3○,MutationBERT takesthese inputs to produce (Step 4○) thefullmutant-testmatrix.
Weobservethatthereissigni/f_icantadditional contextual infor-
mation embedded in bothsource and test code well beyond simply
themutatedlineandmethodnamesconsideredinpriorwork.By
context, we mean both the method surrounding a modi/f_ied line
for a given mutant, as well as the body of the test method, in their
entirety.Thisintuitionissupportedbythefactthatcodeandtest
context are strongly correlated with how useful a mutant is (in
termsofwhetheramutantisredundant,equivalent,ortrivial)[ 18].
Inthispaper,webuildonthisinsighttoenableeﬀectiveandeﬃcient
contextual predictive mutation testing.
WeintroduceMutationBERT,amodelforpredictivemutation
testing that takes as input the mutated source method and cor-
responding test method. MutationBERT learns the relationship
between them to predict whether the test will fail on that modi/f_ied
method. To this end, we introduce a novel input representation
that encodes each mutation as a token level diﬀ applied to a source
method, followed by the corresponding test. We then use a pre-
trained transformer [ 32] architecture to encode source and test
methods,andfurther /f_inetune itfor our task.
A transformer maps a sequence of tokens to a contextual em-
beddingthatcansubsequentlybe/f_inetunedtodownstreamtasks.
Transformershavebeenshowntobehighlyeﬀectiveacrossawide
rangeofsoftwareengineeringtasks,rangingfromcodecompletion
tomergecon/f_lictresolution[ 2,8,30,34].Theirhighlyparallelarchi-
tecturemeansthatinferencetimeislow,ascomparedtoRNNsused
inpriorworkinpredictivemutationtesting[ 20].Toourknowledge,
ourworkisthe/f_irsttoapplythisrecentadvancementtothisdomain.
Asimpliedbythename,MutationBERTbuildsonrecentadvance-
mentsinpretrainedcodemodelsby/f_inetuningCodeBERT[ 8]for
mutationtesting.Duetohavingseensomuchcode,pretrainedmod-
els have a better representation and understanding of source code
syntax and semantics, and thus are better equipped for tackling
source-intensive taskssuch as mutation testing.
Like Seshat, MutationBERT requires no computationally expen-
sivestaticordynamicanalysis,norinstrumentation,asMutation-
BERT operates entirely on source text. MutationBERT can also
generatethefullmutant-testmatrix.Generatingthefullmatrixis
essential for many applications of mutation testing. For example, if
amutantispredictedtobedetectedbyonlyaverysmallnumberof
tests,thepredictioncanbecon/f_irmedbyrunningjustthosetests.
Mutants predicted to be undetected can similarly be checked byrunningthetestsconsideredmostlikely(thoughstillunlikely)to
detectthem.Importantlyinpractice,adeveloperwhowantstoadd
testing to cover an undetected mutant will certainly want to know
whichexistingtestswouldbemostlikelytodetectthemutant,since
oftenthewayto/f_ixsuchaproblemistostrengthentheoracleor
extend the behaviorofan existing test.
Tosummarize,our core contributionsare as follows:
•An extensive empirical evaluation of predictive mutation
testingtools,measuringbothinferencetimeandtheruntime
costsavings.Weconsiderthetradeoﬀbetweenprecisionand
recall, and discuss its impact on the end user, /f_inding that
MutationBERT’shigherprecisionsaves33%ofthetotaltime
spentcheckingmutantsoverpriorwork.Wealsoevaluate
ability to detect non-trivial mutants, /f_inding MutationBERT
hasa30%improvementinaccuracyoverthestate-of-the-art.
•WeintroduceMutationBERT,the/f_irstpredictivemutation
testing model to incorporate source and test code context.
MutationBERTcanpredictentiremutant-testmatricesalong
with whether mutants are detected or not by test suites.
MutationBERT has a 8% improvement in F1 score when
predicting test matrices, and over a 12% improvement in
F1scoreoverthestate-of-the-artbaselinewhenpredicting
whetheramutantisdetected.Whilerecallremainsrelatively
stable, precision improves by 25%, meaning that mutants
labeledasundetectedbyMutationBERTaremuchlesslikely
to be false postives.
•Weperformanextensiveanalysisofthedesigndecisions,in-
cluding an examination of alternative input representations
thatleveragebothsourceandtestmethodcontext.We/f_ind
thattoken-leveldiﬀisthemosteﬀectiveinputrepresentation
for mutant prediction.
Wereleaseourdataset,sourcecode,andmodelcheckpointsat
https://doi.org/10.5281/zenodo.7600371 , includingdetailedinstruc-
tions on how to reproduce all of our results and use our model. We
hope that this will enable the community to deploy our model and
further builduponour work.
2 CONTEXTUALPREDICTIVE MUTATION
TESTING
Figure1overviews the MutationBERT work/f_low. Our work/f_low
takesaprojectandtestsuiteasinput,andusesagivensource-level
251Contextual Predictive MutationTesting ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
1public RegularTimePeriod next() {
2Hour result;
3-if(this.hour!=LAST_HOUR_IN_DAY ){
4+if(this.hour>LAST_HOUR_IN_DAY ){
5 result = newHour(this.hour + 1, this.day);
6}
7...
8}
9
10public void testNext() {
11Hour h = newHour(1, 12, 23, 2000);
12h = (Hour) h.next();
13assertEquals(2000, h.getYear());
14...
15}
(a)Motivating example1<CLS>
2public RegularTimePeriod next() {
3Hour result;
4if(this.hour <BEFORE> != <AFTER> > <ENDDIFF>
5 LAST_HOUR_IN_DAY) {
6 result = newHour(this.hour + 1, this.day);
7}
8...
9}
10<SEP>
11public void testNext() {
12Hour h = newHour(1, 12, 23, 2000);
13h = (Hour) h.next();
14assertEquals(2000, h.getYear());
15...
16}
(b) Model encoding of example
Figure2:AsnippetofcodefromthepopularJFreeChartJavaproject,whereamutationchanging !=to>isapplied(Figure 2a).
Theprovidedtestfailstodetectthismutant.Figure 2bshowshowweencodethismutantinourapproach.Newlyaddedspecial
tokens are marked in brown .
mutation testing tool (step 1○, Section2.1) to generate a set of mu-
tants and tests that cover them (step 2○). Most mutation testing
tools provide coverage out of the box, as a way to prune uncov-
ered mutants, which will always be undetected. We encode the
method/test pairsin an input representation (step 3○, Section2.2),
to be passed as input to our trained model (step 4○, Section 2.3).
The model predicts whether the test will detect or fail to detect
themutant(step 5○).Overallmutant-testpairs,thesepredictions
comprisethe mutant-testmatrix forthe program.Thisoutputcan
be optionally post-processed to aggregate predictions across the
wholetestsuite.Thisproduces fortheuser asetof mutantslikely
undetected by the test suite; these can be inspected directly, or
ranked by existing mutant prioritization algorithms [ 4,19,26]. As
thedeveloperaddstests,moreinterestingmutantsareidenti/f_ied,
leadingto bettertest suites over time.
As an illustrative example, consider Figure 2a, which shows a
(simpli/f_ied) code and test snippet from JFreeChart.2Thenext()
method returns the next hour for a given RegularTimePeriod .
ThetestNext methodchecksthatitworkscorrectlyfor23:00on
December1st,2000.Althoughthistestmethod maylookcompre-
hensive, note that it does not fail if we change the !=operator
to>on line 3. A better test suite would include another method
that includes a time that is not the last hour of a day, which would
correctly fail on the mutated code. We will refer to this example
throughout subsequent sections to clarifyour contribution.
2.1 (Predictive)Mutation Testing
Mutation testing [ 7] is the process of synthetically introducing
faults into programs and measuring the eﬀectiveness of tests in
catchingthem.Asetofprogramtransformations,knownas“mu-
tation operators” take regular code and create buggy copies of it.
These operators vary [ 6,10,16], but some common operators in-
cludenegatingconditions( if (a)toif (!a)),replacingarithmetic
operators( a + btoa - b),replacingrelationaloperators( a < b
toa > b), and /f_lipping conditionals ( a == btoa || b). Each time
2https://github.com/jfree/jfreechartone of these rules is applied to a program, a new mutantis created,
each diﬀering only slightly from the original program. The change
inFigure 2acreates one such mutant for the next()method.
Test adequacy is measured by running the entire test suite on
each mutant; the goal is a test suite that detects all mutants, in-
creasing con/f_idence that the suite would detect unintentional bugs
as well. The test suite corresponding to the single test testNext()
in Figure 2adoes not detect the mutant; presenting this mutant to
a developer would ideally motivate them to create the necessary
additional tests. Mutation score, or the ratio of detected mutants
tototalmutants,providesaroughmeasureoftestadequacy,out-
performingcodecoverageintermsofcorrelationwithreal-world
fault detection [ 17,25]. Mutation testing has seen some industry
adoption [ 4,26]. Prominent recent uses at Facebook and Google
apply it only to changed code at commit-time, which still requires
large amounts of idle compute [ 27] because of the massive com-
putational expense of running it over an entire codebase. Tackling
this scalability problem [ 5]isthe core motivation of our work.
Ourapproachisparametricwithrespecttoexistingsource-level
mutationtestingtoolandcanintegratewithexistingapproaches
likeMajor[ 16]anduniversalmutator[ 10].Forourevaluationwe
use a set of mutants collected by Major [ 16] on the Defects4J 2.0
dataset providedbyKimetal.[ 20]withthe Seshatexperiments.
TechniquesforPredictivemutationtesting[ 20,22,36]usema-
chinelearningtopredictwhetheratestoratestsuitewilldetect
a mutant without actually running those tests. We provide more
detailedcomparisoninSection 7.Forthepurposesofunderstand-
ing our technique, however, note that one limitation of the /f_irst
ML-based approach for mutation testing prediction [ 36]isthat its
performancedegradessigni/f_icantlywhenitisnottrained/evaluated
onmutantsthatarenotcovered(executed)byanyofthetestsin
the test suite [ 1]. Uncovered mutants are trivially undetected by
a test suite, since a test cannot fail due to a bug on a line it does
notexecute.Theyarethusnotinterestingforthetaskofpredictive
mutation testing. We therefore follow precedent set in subsequent
work [20]andexclude uncoveredmutants from the task.
252ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA Kush Jain, Uri Alon,AlexGroce,andClaire Le Goues
2.2 Input Representation
Our goal is to train a model that predicts whether a given test will
detect a given mutant. Concretely, a mutant is a typically small
modi/f_icationtoatypicallymuchlargercode/f_ile.Prioreﬀortstorep-
resentcodechangesforthepurposeofML,fallintothreemaincate-
gories:de/f_iningasetoffeaturesrelatedtothemodi/f_ication[ 20,36]
representing the modi/f_ication with a graph [ 21,33,35] or repre-
sentingthe“before”and“after”ofthemodi/f_icationwithmultiple
embeddings [ 30].
For earlier PMT models [ 20,36] that did not use pretrained
transformers,de/f_iningasetoffeaturesandaggregatingthemintoa
singlevectormadesense.However,toleveragethegainsfromusing
a pretrained model like CodeBERT [ 8], we need to represent our
inputsinthesamewayasthepretrainedmodel,makingthefeature-
based approach unviable. Following best practices in pretrained
transformers, we use the same input embeddings for encoding the
mutatedcode andthe tests.
Thus, we represent each mutant-test pair as a token level diﬀ to
MutationBERT, using the special tokens <BEFORE> ,<AFTER>and
<ENDDIFF> . For example, if the line ...if a == b:... is changed
to...if a != b:... ,weencodeitinthefollowingmanner: ...if
a <BEFORE> == <AFTER> != <ENDDIFF> b:... .Thisencodediﬀs
compactly,whilepreservingoriginalcode structure.
Figure2bshowshowourmodelencodesthemotivatingexam-
ple. We provide the model with the source method encoded as a
token-level diﬀ,followed bythetestmethod.Ourmodelthenout-
putswhethersuchamutantisdetectedorundetected.Wefollow
CodeBERT[ 8]intheiruseofspecialtokens <CLS>and<SEP>.Code-
BERTuses <CLS>and<SEP>to denote codeandnaturallanguage
input,using <CLS>tokenfordownstreamclassi/f_icationtasks(we
discuss this in more detail in Section 2.3). Similarly, we separate
code and test with the special <SEP>token. We take the hidden
representationof the <CLS>tokenas the vectorwhich we train the
modelto classifywhether this mutant isdetectedornot.
2.3 Model
Our model can predict either the entire mutant-test matrix for a
project, or whether a single mutant is detected by an entire test
suite.Ourmodelisapre-trainedCodeBERTmodel/f_ine-tunedtothe
mutationtestingtask,withanovelinputrepresentation.CodeBERT
[8]isapretrainedmodelthatleveragesthetransformerarchitec-
ture [32]. It was trained to predict maskedtokens (code or natural
languagetokensreplacedwith <MASK>)forbothsourcecodeand
natural language. CodeBERT uses special <CLS>and<SEP>tokens
to denote code and natural language, using the <CLS>token for
classi/f_ication in downstream tasks. CodeBERT was pretrained on a
corpusof6.4millionfunctionsacrosssevendiﬀerentprogramming
languages;largepretrainedmodelslikeCodeBERTareapplicable
toavarietyofdownstreamtasksrangingfromcodecompletion[ 8],
tomergecon/f_lictresolution[ 30],andcodesummarization[ 2].To
thebestofourknowledge,wearethe/f_irsttoleveragepretrained
models for the taskofpredictive mutation testing.
Weformulatemutationanalysisasabinaryclassi/f_icationtask
to CodeBERT. We provide CodeBERT with both the source method
encoded as a token level diﬀ and the test method (Section 2.2).
After feeding the inputto CodeBERT, we pass the encoding of the<CLS>token through a linear layer, which is then used to make the
/f_inal classi/f_ication. The model is called for each mutant-test pair to
constructthe entire mutant-test matrix.
We use the probability output of the model to aggregate pre-
dictionsacrosseachmutant’ssetofcoveredtests,andconsidera
mutanttobe“detected”ifthecon/f_idenceofthemodelonatleast
oneofthe tests isgreater than0.25:
pred/u1D440,/u1D447=/braceleftBigg
“detected” (/u1D45A/u1D44E/u1D465/u1D461∈/u1D447/u1D440/u1D462/u1D461/u1D44E/u1D461/u1D456/u1D45C/u1D45B/u1D435/u1D438/u1D445/u1D447 (/u1D440,/u1D461))>0.25
“undetected” otherwise
(1)
where/u1D440corresponds to the mutant and /u1D447corresponds to the
set of tests that cover the mutant. We chose 0.25 as our con/f_idence
threshold, as it was able to reduce the number of false positives
when evaluated on our validation dataset, with a precision of 0.76,
whilenot reducing the overall F1score of 0.80.
3 EXPERIMENTALSETUP
Wecompare MutationBERTwithSeshat[ 20],the currentstate-of-
the-artmodelforPMT,usingthedatasetfromthatpaper.Weask
the following researchquestions:
RQ1: Eﬀectiveness: How well does MutationBERT perform
inasameproject setting? Inasameproject setting,aPMTmodel
istrainedonpreviousversionsofaproject,andthenusedtopre-
dicttestmatrices,unkilledmutants,ormutationscoresforsubse-
quent versions. We compare MutationBERT to Seshat on a within-
projecttask,evaluatingthemodels’correctnesswhenpredicting
test-mutant matrices andover the test suite- level aggregation.
RQ2: Generality: How well does MutationBERT perform in
acrossproject setting? Inacrossproject setting,aPMTmodelis
trainedusingdatafromoneprojectandthenusedtopredicttest-
mutant behavior for a diﬀerent project. This is much more diﬃcult
than the same project setting, but could be especially applicable
whenstartinganewproject,forexample.WecompareMutation-
BERT to Seshat on the cross-project task using the same metrics as
thesameproject task.
RQ3: Design Decisions: How do diﬀerent input representa-
tionsandaggregationapproachesaﬀectour/f_inalmodel? We
analyze and compare severalinput representations as well asag-
gregationapproachestovalidatethedesigndecisionsunderlying
MutationBERT.
RQ4:QualitativeAnalysis:WhatarecausesofMutationBERT
mispredictions? Wemanuallyexamine100caseswhereourmodel
misclassi/f_iesamutantasdetectedorundetectedtoidentifycommon
reasons for failures andbetterunderstandlimitations.
RQ5: Eﬃciency: How eﬃcient is MutationBERT compared
to priorwork, andregular mutation testing? We address how
MutationBERT compares to Seshat, and characterize the perfor-
mance improvement itprovidesover regularmutation testing.
RQ6:MutantImportance:HoweﬀectiveisMutationBERTat
predictingdiﬃcult-to-detect mutants?
WeaddresshowMutationBERTcomparestoSeshatwithregards
to howmanytests detectamutant, aproxyfor mutant diﬃculty.
253Contextual Predictive MutationTesting ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
Table 1:Our datasetcomprisingof6 Defects4J 2.0 projects.
Project Date LOC #tests
commons-lang 2013-07-26 21,788 2,291
jfreechart 2010-02-09 96,382 2,193
gson 2017-05-31 7,826 1,029
commons-cli 2010-06-17 2,497 354
jackson-core 2019-01-06 25,218 573
commons-csv 2017-12-11 1,619 290
3.1 Baseline
We compare against the Seshat baseline [ 20]. Seshat is a state-
of-the-art model for mutation testing, which has been shown to
outperformPMT[ 36]by0.14to0.45 F1scoredependingonproject.
Similarto our model, Seshathas no overhead in static ordynamic
analysis,operatingentirelyonsourcelevelfeatures,unliketheprior
modelPMT,whichrequiresbothstaticanddynamicanalysistorun.
However, unlikeour model,Seshat operates over a set offeatures:
thesourcemethodname,thetestmethodname,themutatedline
before and after, and a one-hot encoding of the mutation operator.
Seshat /f_irst encodes the source and test method names with a bidi-
rectional GRU. It then concatinates the resulting embeddings with
a one-hot encoding of the mutation operator to classify the mutant
as detectedorundetectedbythe test.
Like our model, Seshat outputs a con/f_idence score for each
mutant-testpair,whichweaggregatetopredictwhetherthemutant
is detected or not by the entire test suite. We aggregate Seshat’s
predictions across each mutant’s set of covered tests by comparing
con/f_idencetoathreshold.Wesetthisthresholdto0.10,whichin
ourexperiments producedthe highest F1score for Seshat invalida-
tion(Seshatdoesnotmentionaathresholdintheirpaper,sowe
performthesameoptimizationaswedidforMutationBERT).We
thus aggregate as follows:
pred/u1D440,/u1D447=/braceleftBigg
“detected” (/u1D45A/u1D44E/u1D465/u1D461∈/u1D447/u1D446/u1D452/u1D460/uni210E/u1D44E/u1D461(/u1D440,/u1D461))>0.10
“undetected” otherwise(2)
whereMcorresponds to the mutant and Tcorresponds to the set of
tests that cover the mutant.
3.2 Dataset
We reuse the dataset released with the Seshat experiments [ 20].
This dataset consists of a full mutation analysis in Major [ 16] of
six large scale Java projects, with extensive testing, across multiple
versions,takenfromDefects4Jv2.0.0(statisticsshowninTable 1).
This dataset considers only mutants that are actually covered by
sometest,since uncoveredmutantscannot be detectedbya given
test suite (andcan be discardedwithasimplecoverageheuristic).
Note that the Seshat evaluation [ 20] analyzed the cross-version
setting in detail, training models on previous versions of programs
to predict matrices for subsequent versions. The models remain
eﬀective across versions many years apart. This is likely a function
of the fact that code (and mutation behavior) is quite stable over
time,as showninthe dataset descriptioninKimetal.[ 20].Table 2: Tests, mutants and mutant-test pairs (pairs) for
bothsameprojectandcrossprojectsettings,acrosstraining
(train),validation(val),andtest(test)sets.Notethatmutant-
testpairsonlyinclude tests that coveragiven mutation.
Split#tests #mutants #pairs
SameProjecttrain6,124 68,702 1,522,924
val5,644 8,688 197,527
test5,637 8,648 195,140
CrossProjecttrain4,725 79,128 1,460,344
val1,171 5,427 402,296
test 261 1,040 42,687
Thus,intheinterestofspaceandcomputationaleﬀort,werestrict
ourattentiontosingleversionsperprojectforallRQs.Weselect
thelatestversionsofthesixprojectsinDefects4J2.0andperform
a 80-10-10 split between train, validation and test sets. In the same
projectsetting,wesplitbymutant-testsuitepair.Thisisincontrast
tothepriorevaluation,thatis,mutant-testpairsfromthe sametest
suitemustbepartofthesamesubset.Practically,ourenvisioned
application does not include a situation where a PMT model could
be trained on data corresponding to whether half the tests in a
given test suite detect a given mutant, and then used to predict the
behavior of the other half. This explains why we reran Seshat (and
whyour numbersmaynotmatchthoseinthe originalpaper).For
the cross project setting, we split by project, where each project
consistsofasetofmutant-testsuitepairs.Weusetheexactsame
splitsforourmodelandforSeshat.Table 2showsstatisticsabout
our same projectandcrossprojectsplits.
3.3 Preprocessing andTraining
WeusethepretrainedRoBERTatokenizer(BPEtokenizer[ 29])with
vocabularysizeof50,000tokensforallprogramminglanguagesthat
isprovidedwithCodeBERT. We /f_inetune CodeBERTwithcontext
window size of 1024 tokens, and thus only provide MutationBERT
the /f_irst 1024 tokens of the code and test combinations. Such cases
account for 14.6% ofallmutant test pairs.
WefollowthesamestepsthatKimetal .[20]tooktotrainSeshat.
WetrainSeshatfor10epochs,withabatchsizeof512,andlearning
rateof3e-3.WetrainMutationBERTforeightepochswithlearning
rate of1e-5and batch size of 64. We use a weighted loss function
according tothedistribution ofdetectedandundetectedmutant-
test pairs. We use a linear warmup to 1000 steps, followed by a
cosineannealing decay,inaccordancewithbest practicesfor/f_ine
tuning transformers [ 28]. Both models’ loss functions converge
using these settings. We /f_ine-tuned our model on a Nvidia GeForce
RTX 3080 for one weekfor atotal of 115k steps.
3.4 MetricsandSettings
Onewaytousemodelsforpredictivemutationtestingistocom-
putemutant-testmatrices,whichpredict,foreachmutant,whether
each test passes or fails. In general, most tests pass on most mu-
tants.Thatis,atestdetectingamutantistheminorityclass.Inthis
254ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA Kush Jain, Uri Alon,AlexGroce,andClaire Le Goues
setting, model precisionrefers to how accurately mutants are iden-
ti/f_ied asdetected, while recallreferstothe proportionofdetected
mutants labeled correctly. In the mutant-test matrix setting 72% of
mutant-test pairs are undetected. We care that our model is able to
accurately predict the remaining 28% of detected mutants; the goal
isto identifythe fewtests that detecteachmutant.
Anotherwaytousethesemodelsistopredictwhetheranentire
test suite detects a particular mutant. Here, the majority class is
detectedmutants;61%ofmutantsaredetected.Thecoregoalhereis
to accurately identify the undetected mutants, to guide developers
to improve test suites. Therefore, we de/f_ine precision and recall
diﬀerently than in the the mutant-test matrix setting. In the test
suite setting, model precisionrefers to how accurately mutants are
identi/f_ied as undetected , while recall refers to the proportion of
undetected mutants that are classi/f_ied correctly. Precision is thus
importantinunderstandingthepotentialcostofaPMTmodelin
termsoftimeneededtoeitheractualrunthetestsuitetocon/f_irmits
predictions,ortimewastedbyadeveloperinspectinganultimately
uninteresting mutant. Recallis also important to overall model
usefulness:ifamodelmissesalargenumberofundetectedmutants,
key gaps intest suite qualitycould remain.
We report precision, recall and F1 score (which balances the
two) for all models in the /f_irst three research questions. For RQ1
(sameproject)andRQ2(crossproject),weevaluateperformance
both on the base test set (195,140 mutant-test pairs). For eﬃcacy of
prediction over the entire test suite, we evaluate MutationBERT on
thesamedataset,aggregatedatthetestsuitelevel(8648testsuites).
ForRQ3, we evaluate diﬀerent aggregation thresholds and input
representationchoicesonthevalidationsetconsistingof120,710
mutants, again reporting precision, recall, and F1 scores; we evalu-
ate both mutant-test predictions and mutant-test suite predictions.
Due to compute constaints associated with a larger context win-
dow, we use the 512 token context window to evaluate diﬀerent
thresholds andinputrepresentations.
For RQ4, to ensure a representative sample of misclassi/f_ications,
we randomly select 100 examples where our model misclassi/f_ies
amutantasbeingdetectedorundetected.Wemanuallyexamine
each example and try to understand the cause of the misprediction.
Finally,webucketthesemispredictionsinaseriesofcategoriesand
discuss theseindetail.We dothis to informa general assay ofthe
limitationsofourtechnique;wedo notmakestrongclaimsabout
the generalizabilityofthis qualitative assessment.
For RQ5, we run 1000 iterations of Seshat and MutationBERT,
with a batch size of one, on a workstation with an Nvidia GeForce
RTX3080GPU,with100warmupiterations.Wereporttheaverage
time taken over these 1000 iterations as the inference time for
each model. To compute comparative time and speedups against
regular mutation testing, we use numbers from previous work [ 20]
inconjunction withour inference time numbers.
For RQ6, we report accuracy of Seshat and MutationBERT with
respect to percentage of tests that kill a mutant. The goal is to
measurewhetherMutationBERTisonlycorrectlyclassifying"easy"
to detect or "trivial" mutants where the majority of tests detect the
given mutant or whether MutationBERT is capable of correctly
classifying mutants that are more diﬃcult to detect.4 RESULTS AND ANALYSIS
We report results for all/f_ive RQs,anddiscuss their implications.
4.1 RQ1: Same Project Performance
Table3shows the results of MutationBERT and Seshat on the test
setforthe sameproject setting.Thecentercolumnsshowresults
in predicting whether a test will detect a particular mutant, rele-
vant to constructing the overall mutant-test matrix. MutationBERT
outperforms Seshat across all metrics: MutationBERT’s F1score is
0.75,comparedtoSeshat’s0.67.Interestingly,MutationBERTand
Seshat have similar precision (0.66 for Seshat vs 0.72 for Mutation-
BERT); the models report similar numbers of false positives (cases
wherethemodelsmisclassifyatestasdetectingamutant).How-
ever,MutationBERThashigherrecall(0.77,versus0.68),meaning
that MutationBERT is more likely to correctly identify cases where
atest detectsamutant.
When the predictions are aggregated into test suite level predic-
tions (right-hand columns), recall that undetected mutants are the
minority class, /f_lipping the meaning of precision and recall (Sec-
tion3.4).SeshatandMutationBERTboth/f_indsimilarnumbersof
undetectedmutants,butMutationBERThasmuchhigherprecision,
0.81,comparedtoSeshat’s0.56.Falsepositivesarecostly,asthey
costdevelopersvaluabletimeexaminingmutantsthatareinreality
detectedbytheirtest suite.
Another way of viewing these results is in terms of the diﬀer-
encebetweenthemutationscoreestimatedbyapredictivemutation
model, and the actual mutation score. Recall that mutation score
isthetrueratioofdetectedmutantstototalmutants;empirically,
mutation score provides a better measure of test adequacy than
code coverage [ 17,25] and thus is useful (albeit usually expensive)
to compute. The gold mutation score (true mutation score) on our
testsetis0.59.Seshatestimatesamutationscoreof0.40overthe
entire dataset, an error of 0.19. MutationBERT computes a muta-
tion score of 0.61, a diﬀerence of only 0.02 from the true answer.
MutationBERTthushasmuchlowererror inestimatingmutation
score onthis dataset as comparedto Seshat.
4.2 RQ2: Cross Project Performance
Table3also shows the cross project setting (bottom rows), where a
model istrained on one set ofprojects and evaluated on another.
Again, MutationBERT outperforms Seshat (0.68 precision and 0.37
recallforMutationBERTand0.58precisionand0.29recallforSe-
shat). That said, in the mutant-test predictions, both precision and
recall drop signi/f_icantly for both approaches; this suggests that
trainingdatacontainingproject-speci/f_icvocabularyandmethods
contributesubstantiallytothesameprojectperformance.Thisis
consistent with other results showing that projects have distinct
vocabularyandstyle,makingcrossprojectpredictiondiﬃcultfor
manytasks[ 3,13].Precisioncontinuestobequiteabithigherthan
recallinthe crossprojectsetting,for both models.
At the test suite level, we /f_ind that MutationBERT outperforms
Seshatonallmetrics.Precisionisverylowforbothtools;Seshat
and MutationBERT both misclassify a signi/f_icant proportion of
undetected mutants, however MutationBERT has a signi/f_icantly
higherprecision.Recallisalsolowinthecrossprojectsetting,at
0.39 for Seshat and 0.65 for MutationBERT. However, this indicates
255Contextual Predictive MutationTesting ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
Table3:ComparisonbetweenSeshatandMutationBERTonbothsameprojectandcrossprojectsettingsintermsofprecision,
recallandF1score.Inbothsameprojectandcrossprojectsettings,MutationBERToutperformsSeshatacrossallmetrics,with
anF1score diﬀerenceof12% on thesameprojectsettingand F1score diﬀerenceof28% on the cross project setting.
Setting ModelMutant-Test Matrix Test Suite
Precision Recall F1 Precision Recall F1
SameProjectSeshat 0.66 0.68 0.67 0.56 0.820.67
MutationBERT 0.72 0.77 0.75 0.81 0.780.79
CrossProjectSeshat 0.58 0.29 0.38 0.24 0.39 0.30
MutationBERT 0.68 0.37 0.48 0.52 0.65 0.58
thatinacrossprojectsettingMutationBERTiscapableof/f_inding
more undetectedmutants thanSeshat.
On the cross project test set, the gold mutation score is 0.77.
Seshatdiﬀersfromthisvaluesigni/f_icantly,withamutationscore
of0.63(errorof0.14).MutationBERTismuchcloser,predictinga
mutation score of0.72(errorof0.05).
4.3 RQ3: Input Representations and
AggregationApproaches
Weproposedanewinputrepresentationforthemutationpredic-
tionproblem.Here,wedescribeseveralalternativesthatwethen
experimentally evaluate.We alsodescribe alternative aggregation
approaches. Then, we evaluate these alternatives (all on the vali-
dation set) to motivate the input representation and aggregation
approachesinour /f_inal model.
4.3.1 Input Representations. We outline various input representa-
tions that incorporate source and test context for our model. For
allinputrepresentations,weseparatemethodcodeandtestcode
witha<CLS> token, whichwe use for classi/f_ication.
No Diﬀ (Binary Task): Our simplest approach is to directly ap-
plythemutationandfeedthemodelboththemutatedversionof
the code and unmutated version of the code. For example, when
changing ==to!=in...if a == b:... wefeedthemodelboth
...if a == b:... and...if a != b:... (Figure3b).
Since we have likelihood scores for both the mutated and un-
mutated versions of the code, we try two modes of evaluation. Our
/f_irst mode feeds the model the mutated code, and takes its pre-
diction.Oursecondmodefeedsthemodelboththemutatedcode
andunmutatedcodeandobtainsitsprobabilityofbeingdetected.
Then it subtracts these two probabilities from each other (since we
know the /f_irst datapoint is always undetected), and compares this
diﬀerenceagainstadynamicallysetthreshold.Wetryallthresholds
between0.01and0.99inincrementsof0.01onthevalidationset,
andselectthe bestperformingthreshold.
TokenLevelDiﬀ: Werepresenteachmutationasatokenleveldiﬀ.
Forexampleifaline ...if a == b:... ischangedto ...if a !=
b:...,weencodeitinthefollowingmanner: ...if a <BEFORE>
== <AFTER> != <ENDDIFF> b:... (Figure3c).Thisallowsforthe
mostcompactfootprintinencodingthediﬀs,allowingourmodel
tolearnhowcertaindiﬀscoupledwiththesurroundingcodeand
test are correlatedwithamutant being detectedornot detected.
LineLevelDiﬀ: For line level diﬀs, we represent diﬀs in terms of
changetosourcelines.ThisinputrepresentationissimilartotokenTable 4: Precision, recall and F1scores of all models at pre-
dicting the mutant-test matrix on the validation set. Token
diﬀandlinediﬀarethebestperformingmodels,withanF1
score of0.78.
Model Precision Recall F1
Seshat 0.73 0.75 0.74
TokenDiﬀ 0.79 0.77 0.78
LineDiﬀ 0.79 0.77 0.78
NoDiﬀ (Normal) 0.74 0.72 0.73
NoDiﬀ (Threshold - 0.01) 0.73 0.72 0.73
level diﬀ. In our example, we encode the mutation as ...<BEFORE>
if a == b: <AFTER> if a != b: <ENDDIFF> ... (Figure3d).
Wehypothesizethatthismightperformbetterthantokendiﬀ,as
CodeBERTwaspretrainedfor taskssuch as nextlineprediction.
4.3.2 AggregationApproaches. Weoutlineaggregationapproaches
thatwetriedforourtestmatrixmodel.Practically,thisaggregation
holdsvalue,asundetectedmutants(mutantsnotdetectedbythe
entire test suite) are ones of interest to developers, as they indi-
cate testing inadequacy. Speci/f_ically, in order to use such a model,
aggregate predictions need to be accurate, otherwise undetected
mutants willbe identi/f_iedincorrectly.
Threshold Aggregation: We aggregate the predictions of both
predictive mutation testing models by using various probability
thresholds (0.1, 0.25, 0.5, 0.75 and 0.9). Speci/f_ically, we only label
a test as detecting a mutant if the model predicts the test detects
the mutant with probability above the de/f_ined threshold. We vary
thresholds to observe their eﬀect on precision, recall, and F1 score.
LearnedAggregation: Wealsotriedlearninganaggregationbased
oﬀoftheembeddingsofthe<CLS>tokenafterCodeBERTencoding.
Weuseatransformerwiththreelayerstotaketheseembeddings
andaggregatethem.Wethenusealinearlayertoclassifybasedoﬀ
of this learned aggregate embedding whether the test suite detects
or fails to detect the mutant. We evaluate this learned aggrega-
tion both using a weighted loss function (according to the data
distribution) andusing anormal lossfunction.
4.3.3 Experimental Results. We evaluate input representations on
our validation set for Defects4J 2.0. The data distribution is 72%
undetected and 28%detected for test matrices.The No Diﬀmodel
256ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA Kush Jain, Uri Alon,AlexGroce,andClaire Le Goues
-if(a==b)...
+if(a!=b)...
(a)Example sourcemutation<CLS> ... if(a == b)... <SEP> ...
<CLS> ... if(a != b)... <SEP> ...
(b) No Diﬀ
<CLS> ... if(a<BEFORE> == <AFTER> != <ENDDIFF> b)... <SEP> ...
(c) TokenDiﬀ
<CLS> ... <BEFORE> if(a == b) <AFTER> if(a != b) <ENDDIFF> ... <SEP> ...
(d)LineDiﬀ
Figure 3: Input representations for encoding mutations applied to source code. Each sub/f_igure shows a diﬀerent input repre-
sentation on the same example of changing ==to!=. Token diﬀ and line diﬀ were the best performing input representations
andwe chose to use token diﬀ as the/f_inalinput representation inMutationBERT.
requires two examples per mutant, making an even more unbal-
anced distribution (86% undetected, 14% detected). Therefore, in
training thesemodels, we use a weighted loss function thatpenal-
izesmissclass/f_icationsof detectedmutantsmorethanundetected
mutants. The weights are diﬀerent for the Token Diﬀ andLine Diﬀ
models andthe NoDiﬀmodel.
Table4compares our novel input representations against the
baseline Seshat model. Token Diﬀ andLine Diﬀ perform almost
identically, with approximately a 4% improvement in F1 score over
baseline(weusethetokendiﬀmodelforourotherresults).Some-
whatsurprisingly,whenthediﬀisnotexplicitlyspeci/f_ied(inthe
NoDiﬀmodels),themodelfailstoreasonabouthowcoderelates
totestspassingorfailingThisisfurthersupportedbythethresh-
olding (in the No Diﬀmodels) having no eﬀect on validation F1
score (regardless of what the threshold is from 0.01 to 0.99). We
hypothesize that knowing the mutation applied is a key piece of
contextforaccuratepredictions.Bothourtokenandlinediﬀmodels
have tokens that specifythe startandend ofthe appliedoperator.
Wesimilarlyevaluateaggregationstrategiesonthevalidation
set,atthetestsuitelevel(thegoaloftheaggregationstrategiesis
to predict over test suites). Table 5shows results of all aggregation
strategies we triedonthe validation set.
We/f_indthatevenwiththesmallchangeinF1scorebetweenthe
twomodelsfortestmatrixprediction,thereissigni/f_icantchange
in F1 score when it is aggregated at the test suite level. This is
dueto thecompounding eﬀectof errors,asan errorin anyone of
the tests inthe test matrixcan cause the wholesuite to be labeled
incorrectly, making even a small diﬀerence in F1 score equate to
large diﬀerences inthe aggregatedmatrix.
Toselectthresholds,weusethevalidationsetandtheF1score
followedbyprecision.Precisionismoreimportantthanrecallhere,
because the cost of a false postive is high. Speci/f_ically, a false posi-
tivemeansthatadeveloperwillseeamutantthatissupposedto
indicatetestinadequacywheninrealitytheirtestsareadequate.We
/f_indthatthebestthresholdforSeshatis0.10andthebestthreshold
for MutationBERT is0.25.
4.4 RQ4: ToolMisclassi/f_ications
To understand our model’s limitations, we examined 100 randomly
sampled examples of MutationBERT misclassi/f_ications from ourTable 5: Threshold and aggregation approaches, predicting
test suites on the validation set. The best threshold for Se-
shat is 0.10; for MutationBERT, 0.25. We /f_ind that the trans-
former aggregation approaches have lower precision than
the selected threshold approach, meaning more false posi-
tives.
Model Threshold Precision Recall F1
Seshat0.10 0.57 0.83 0.67
0.25 0.56 0.85 0.67
0.50 0.48 0.92 0.66
0.75 0.52 0.87 0.65
0.90 0.51 0.89 0.65
MutationBERT0.10 0.76 0.84 0.80
0.25 0.76 0.84 0.80
0.50 0.75 0.86 0.80
0.75 0.74 0.87 0.80
0.90 0.73 0.88 0.80
trans (weighted) N/A 0.75 0.85 0.80
trans (unweighted) N/A 0.75 0.85 0.80
Table 6: Reasons MutationBERT incorrectly classi/f_ies mu-
tants. In 71/100 cases, MutationBERT lacks suﬃcient con-
text, while in the remaining 29/100 cases MutationBERT
misses acontextualclue.
Category Case Count
Not enough contextHelper test method 44
Method 24
Class 3
MissedclueCode 22
Methodname 7
validation set. We categorize causes of failures in Table 6. Upon
inspection, we classi/f_ied each example into two high-level buckets:
Not enough context andMissed clue .Not enough context refers to
cases where the model was missing context that even a human
would need to classify the case correctly. The large majority of
257Contextual Predictive MutationTesting ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
ourexamples(71/100)fellunderthisbucket.Thesecondcategory
consists of Missed clue s, where the model missed some crucial clue
to mutant behavior(29/100).
Wewereabletosubdividethehigh-levelbucketsintocommon
subcategories. For Not enough context these are Helper test method ,
MethodandClass.Helper test method refers to cases where the test
methodconsists primarily ofinvocationstoanothermethod.One
example isas follows:
public void testJava2DToValue() {
checkPointsToValue(edge, plotArea);
this.axis.setRange(0.5, 10);
checkPointsToValue(edge, plotArea);
...
}
Testmethod testJava2DToValue invokeshelpermethod checkPointsToValue
multipletimes.Withoutthehelpermethodcode,MutationBERT
lacks the context (or even knowledge of relevant test assertions) to
make an accurateprediction onany mutant.
TheMethodcategory refers to the model lacking necessary
sourcecontext.For example:
public <T> TypeAdapter<T> create(...)
public void testDeserializeNullField() throws
IOException {
Truck truck = truckAdapter.fromJson(...);
...
}
This example shows a test that invokes the fromJsonmethod, which
theninvokes create.Withoutthecodefor fromJson,MutationBERT
cannot reason about how a mutant in createwould aﬀect a test
calling fromJson.
FinallyClassreferstocaseswheretheconstructorofaclassis
mutated, but the test invokes a subclass and thus is missing the
subclass constructorcontext.The following example showsthis:
public StrokeMap()
public void testCloning() {
PiePlot p1 = newPiePlot();
...
}
Inthisexample, testCloning isinvokingtheconstructorof PiePlot,
which is a subclass of StrokeMap. Without seeing the constructor
ofPiePlot,MutationBERTcannotunderstandhowmutantstothe
StrokeMapconstructoraﬀectthe test.
Missedclue isdividedinto CodeandMethodname .Coderefers
to cases where the model missed a context clue in the source code
that indicatedthat mutant detetion.For example:
1public boolean hasNext() throws IOException {
2...
3-return p!=PEEKED_END_OBJECT
4-&&p!=PEEKED_END_ARRAY ;
5+return true&&p!=PEEKED_END_ARRAY ;
6}
7
8public void testDoubleArrayDeserialization() {
9double[] values = gson.fromJson(...)
10assertEquals(0.0, values[0]);
11...
12}
In this example, the mutant on line 3, replaces the object check
with true, but the test is only for arrays. Thus, the mutant will not
bedetectedbytheprovidedtest,sincetheobjectcheckisnotbeingtested. MutationBERT misses the correlation between the object
checkandthe test assertsalllookingat arrays.
Finally,Method name refers to cases where the model fails to
detect an important context clue in the method name. For example:
1public BufferedImage createBufferedImage(...,
ChartRenderingInfo info) {
2...
3-if(info!=null){
4+if(true){
5 info.setRenderingSource(...);
6}
7}
8
9public void testDrawWithNullInfo()
Thisexampleshowsamutantthatreplacesanullcheckon infowith
true.Sincethetestisacasewhere infoisnull,onthemutatedcode,
there will be a null pointer dereference. Thus a NullPointerException
willbethrownandthemutantwillbekilled.MutationBERTfailsto
seethecorrelation betweenthetestnameand themutantapplied.
4.5 RQ5: Eﬃciency
Finally,we discusstheeﬃciencyand performance bene/f_its ofMu-
tationBERT as compared to Major or Seshat. Table 7shows time to
run eachtool,includingMajor,for allmutants inaproject(center
column), and time to run including a con/f_irmatory check for the
predictive techniques (right-handcolumns).
Seshat and MutationBERT have comparable inference time in
our experiments: 34 ms for MutationBERT and 17 ms for Seshat. In
termsofpracticalimpactonauserinterestedinper-mutantpredic-
tion, the diﬀerence between 17 and 34 ms is negligible. Meanwhile,
as Table7shows, the time required to compute a full mutation
score for a given project is the same order of magnitude (10s of
minutes),whileboth an order-of-magnitudefaster thanMajor.
However,despitebeingslowerthanSeshatonaper-prediction
basis, MutationBERT stilloﬀers signi/f_icant computational savings
for the end-user aiming to improve a test suite (the original goal
ofmutationtesting,andconsistentwithitsuseatcompanieslike
GoogleandMeta).Inthissetting,theuserreceivesalistofunde-
tectedmutantstoinspectandusetocreatenewtests.Apractical
applicationforpredictivemutationtestingshouldincludea check
ofeachpredicted-undetectedmutantbeforepresentingthelistto
thedeveloperto/f_ilterincorrectpredictions;thisensuresthatthe
tool is presenting truly actionable information and saves the de-
velopertimeandfrustrationincon/f_irmingthetool’sresults.The
right-hand-sideofTable 7showsthatbecauseMutationBERThas
higherprecisionthanSeshat(andsimilarrecall),itspredictionscan
beveri/f_iedandthusputtousebythedevelopermuchmorequickly.
4.6 RQ6: MutantImportance
Figure4shows model accuracy ofboth Seshat and MutationBERT
withrespecttopercentageofdetectingtestsinagivenmutant’stest
suite.Mutantswithahighproportionofdetectingtestsarelikely
tobetrivial,whilemutantswithfewdetectingtestsaremorelikely
tobeinteresting.WecompareMutationBERTtoSeshatindetecting
trivial vshard to detect mutantsby reporting modelaccuracy as a
functionofpercentageofdetectingtests.Mutantsthatarekilledby
all testsare trivial,andwe hypothesizetheyareeasier formodels
258ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA Kush Jain, Uri Alon,AlexGroce,andClaire Le Goues
Table 7: Time to run Major, MutationBERT, and Seshat, over all mutants (center columns), or incorporating a con/f_irmation
checkbefore presenting unkilled mutantsto theuser(right-handcolumns).
NoChecking Checking
Project Major(s) MutationBERT (s) Seshat (s) MutationBERT (s) Seshat (s)
commons-lang 12,924 748 374 3324 5767
jfreechart 64,719 1424 712 18458 23838
gson 16,738 150 75 6136 8611
commons-cli 1,290 53 26 542 841
jackson-core 113,343 809 405 33035 52231
commons-csv 5,289 36 18 1458 2550
0.0 0.2 0.4 0.6 0.8 1.0
Percentage of killing tests0.40.50.60.70.8Average accuracyAverage accuracy vs percentage of killing tests
(a)Accuracy vs. percentage of killing mutantsfor Seshat
0.0 0.2 0.4 0.6 0.8 1.0
Percentage of killing tests0.600.650.700.750.800.850.900.95Average accuracyAverage accuracy vs percentage of killing tests
(b) Accuracy vs. percentage of killing mutantsfor MutationBERT
Figure 4: Accuracy vs. percentage of killing mutants for Se-
shat andMutationBERT
to detect, while mutants with fewer detecting tests are more likely
to be interestingandmore diﬃcult for models to detect.
As expected, both approaches are less accurate at detecting mu-
tantsthatfailfewertests.Importantly,however,MutationBERTout-
performsSeshatconsiderablyonharder-to-detectmutants(thosefailing1%-20%ofthetestsuite),by30%.AlthoughSeshatisslightly
more accurate at classifying mutants that fail no tests at all (0.82
accuracyvs.0.78),MutationBERT’s overallaccuracyishigher,by
17%.Overall,MutationBERTismoreaccuratethanpriorworkin
predictingmutant behavior,especiallythe hard-to-detectcases.
5 DISCUSSION
Practically,MutationBERTisusefulforbothofthecoreenduser
tasks in mutation testing: 1) as a more complete measure of testing
adaquacy (computing mutation score) [ 9,23] and 2) to identify
undetectedmutantsthatindicatepotentialinadequaciesinexisting
testingeﬀorts[ 4,26].
In the classical sense, mutation testing serves to evaluate test
suite quality [ 7,12,15]. Mutation score, or the proportion of de-
tected mutants to total mutants, provides a powerful measure of
howwelltested,includingintermsofactualoraclestrength,agiven
pieceofcodeis.MutationBERTdrasticallyreducestheamountof
timeneededtocomputemutationscore,takingapproximately30
ms per mutant test pair, substantially lower than the actual cost
of executinga test (and compilingmutants). The errorrate of Mu-
tationBERT is also low, with MutationBERT having below a 5%
error in predicting mutation score for both same and cross project
settings,substantiallylowerthanSeshat.FurthernotethatasTa-
ble7shows,itisplausiblethatusingMutationBERTtoapproximate
mutation score will be faster (in our data, about twice as fast) as
even approximating score by samplingasfew as10% ofmutants.
Sampling 10% of mutants is likely to be no more accurate than
MutationBERT[ 9],andadditionallyprovides nodataonmutants
notsampled,whileourapproachprovidesagoodapproximation
ofthe result for allmutants.
Morerecently,companieslikeGoogle[ 26]andFacebook[ 4]use
mutation testing to pinpoint undetected mutants that reveal issues
withtestadaquacy.MutationBERTsubstantiallysavestimehere,as
unlike Seshat, it still achieves over 60% accuracy in predicting hard
todetectmutants.Whenshownasetofundetectedmutants,adevel-
operwouldbeabletotrustMutationBERT’soutput.Evenverifying
theoutputofallmutantsclassi/f_iedasundetectedbyMutationBERT
/f_irst saves 71% of time when compared to regular mutation testing,
signi/f_icantly more than Seshat’s 57% time savings. We note that
withveryhighactual mutationscores(whereexaminingunkilled
mutants is most useful), the time required to discover /u1D45Bundetected
mutants using MutationBERT is likely to be muchbetter than with
Seshatortraditional mutation testing.
259Contextual Predictive MutationTesting ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
6 LIMITATIONSAND THREATS
Limitations: MutationBERT depends on GPU availablity to eﬃ-
cientlymakepredictions.OnaCPU,MutationBERTtakes84mil-
lisecondsperprediction,or12mutant-testpairspersecond(afar
cry from the 29 mutant-test pairs per second on a GPU). Note that
boththeseCPUandGPUtimesaretheoreticalworstcases,since
thesetimeswerecomputedusingabatchsizeofone.Manycurrent
CIpipelinesarelargelyCPU-based,potentiallycompromisingprac-
tical utility. However, cloud providers increasingly provide GPU
access;recently,GitHubactionsannouncedplanstodothesamefor
CI.3Indeed,GPUsarebecomingmorebroadlyaccessible,including
via idle GPU time or services like Google Colab. Future testing
approachesare thus increasingly realistic to deploy inpractice.
Threats to Validity: The main internal threat to validity is our
implementationofMutationBERT.Weusedwidelyavailableand
popular libraries such as PyTorch and Pandas for managing data
and building the model to help mitigate this threat. We release our
modelsandimplementationforinspectionandextensionbyothers.
The external threats to validity lie in our dataset of mutants and
tests.Wereusedthedataproducedbypriorworkonalargedataset
(Defects4J) that has been used and validated in many other studies
insoftwareengineering.Sincethisdatasetissourcedfrommultiple
diﬀerentprojects,the results are more likely to generalize.
Finally, threats to construct validity lie primarily in our evalua-
tionmetrics.Wereportwidelyusedmetricsinmachinelearning,
i.e., precision, recall and F1 score. We also practically discuss how
thesemetrics translate to the real world use case.
7 RELATED WORK
Severalapproacheshavebeenproposedtotacklethecomputational
costofmutantexecution,includingweak-mutation,meta-mutation,
mutation-sampling, and mutant prioritization. Oﬀutt et. al [ 23]
proposereducingthesetofmutationoperatorsinordertoprune
the seach space of mutants. Gopinath et al . [9]demonstrate that
with a small fraction of mutants randomly sampled, one can easily
approximatemutationscore.Metamutation[ 31]combinesmultiple
mutants into one larger combined mutant and executes the test on
this combined mutant. Kaufman et. al [ 19] focus on computing the
probabilitythatmutantsadvancetheadequacyofagiventestsuite.
Google[26]andMeta[ 4]applymutationtesting onlytochanged
code at commit-time, and display undetected mutants as part of
code review. Developers can quickly identify potential testing gaps
before code reaches production. Google further uses heuristics
[26]toavoidmutatingaridlines(linesthatwhenmutatedcreate
unproductivemutants,suchasloggingstatements),whileMetauses
a learned targeted set of mutation operators [ 4]. However, even
this more narrow application (just to changed code in a commit,
restricted to one mutant-per-line or a small set of operators) is
expensive,requiring large amountsofidle compute [ 27].
Approaches to reducing the cost of mutation analysis were cate-
gorized as do smarter ,do faster, anddo fewerby Oﬀutt et al. [ 24].
Thedo smarter approaches include space-time trade-oﬀs, weak
mutation analysis, and parallelization of mutation analysis. The
do fasterapproaches include mutant schemagenerationandother
3https://github.com/github/roadmap/issues/505methodstomakemutantsrunfaster.Finally, dofewerapproaches
include selective mutation andmutant sampling.
Recently,PredictiveMutationTesting[ 36]proposedanewmeans
of tackling these problems through the use of machine learning.
PMTde/f_inesasetoffeaturesandusesthesetopredictwhethera
given mutant is detected or not by the test suite. The original PMT
approachrequirescostlyinstrumentationtocollectfeatures.Seshat
[20]achiveshigheraccuracywithloweroverheadbyexclusively
usinginformationaboutthesourcecodeandmutationitself(source
method,test method,andmutatedline).
Similar to Seshat, we also exclusively use information about the
source code and mutation itself; however we exploit CodeBERT
(amodelpre-trainedonsourcecode)overthecontextofboththe
sourceandtestmethodsalongwitharepresentationofthemutation
applied.We/f_indthatthisadditionalcontextishelpfulinpredicting
theoutcomeofwhetheramutantisdetectedorundetected,inboth
same-projectandcross-projectsettings.
8 CONCLUSION
In this paper, we present MutationBERT, a tool for predicting both
test matrices and aggregating these predictions. We perform an
extensive evaluation of our model, /f_inding that we save 33% of
Seshat’stimeifadeveloperweretoverifyallmutantsthateither
model predicted as undetected. We also outperform Seshat, the
state of the art model by 8% F1score in predicting test matrices
and12%F1scoreinpredictingtheaggregatedtestsuiteoutcome.
We also achieve similar performance in the cross project setting,
outperformingSeshatby10% F1scoreinpredictingtestmatrices
and 28%F1score in predicting test suites. Finally, we analyze cases
whereourmodelfailstoclassifythemutantasdetectedorunde-
tected. From this analysis, we /f_ind that in the majority of cases
where our model incorrectlyclass/f_ies a test as detecting or failing
todetectamutant,itlackssuﬃcientcontext.Thiscontextoftenlies
intesthelpermethods,ormethodsthatareinvokedbythetestthat
invokethe source method. MutationBERT hasa relatively limited
context window of 1024 tokens, so incorporating this additional
informationwouldlikelyrequireusingalargelanguagemodelwith
larger contextwindowsizes such as Codex.
9 DATA AVAILABLITY
We make all data, modeling checkpoints, and code publically avail-
able athttps://doi.org/10.5281/zenodo.7600371 . We include steps
required to reproduce our results in the README /f_ile both from
scratch and using our provided checkpoints. The scripts to run our
preprocessingareunder preprocessing ;scriptstotrainourmodel
are under runtime; and scripts to run our evaluation on the test
setareunder evaluation .Fullinformationonhowtoreproduce
our results isavailable in README.md .
10 ACKNOWLEDGEMENTS
We would like to thank the authors of Seshat for providing us with
dataandcodeforourbaselineexperiments.Thisworkissupported
inpartbytheUSNationalScienceFoundation,awardsCCF-2129388
andCCF-1910067.
260ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA Kush Jain, Uri Alon,AlexGroce,andClaire Le Goues
REFERENCES
[1]Alireza Aghamohammadi and Seyed-Hassan Mirian-Hosseinabadi. 2020. The
Threat to the Validity of Predictive Mutation Testing: The Impact of Uncovered
Mutants. CoRRabs/2005.11532 (2020). https://doi.org/10.48550/arXiv.2005.11532
[2]Wasi Ahmad, Saikat Chakraborty, Baishakhi Ray, and Kai-Wei Chang. 2021. Uni-
/f_ied Pre-training for Program Understanding and Generation. In North American
Chapter of the Association for Computational Linguistics: Human Language Tech-
nologies (NAACL-HLT’21) .2655–2668. https://doi.org/10.18653/v1/2021.naacl-
main.211
[3]Tou/f_iqueAhmedandPremkumarDevanbu.2023. Few-ShotTrainingLLMsfor
Project-Speci/f_icCode-Summarization.In AutomatedSoftwareEngineering (ASE
’23). Article177, 5 pages. https://doi.org/10.1145/3551349.3559555
[4]MoritzBeller,Chu-PanWong,JohannesBader,AndrewScott,MateuszMachalica,
Satish Chandra, and Erik Meijer. 2021. What It Would Take to Use Mutation
TestinginIndustry-AStudyatFacebook.In InternationalConferenceonSoftware
Engineering: Software Engineering in Practice (ICSE ’18) . IEEE, 268–277. https:
//doi.org/10.1109/ICSE-SEIP52600.2021.00036
[5]N. N. Bokaei and M. R. Keyvanpour. 2019. A Comparative Study of Whole
Issues and Challenges in Mutation Testing. In Conference on Knowledge Based
Engineering and Innovation (KBEI ’19) . 745–754. https://doi.org/10.1109/KBEI.
2019.8735019
[6]Henry Coles, Thomas Laurent, Christopher Henard, Mike Papadakis, and An-
thony Ventresque. 2016. PIT: A Practical Mutation Testing Tool for Java (Demo).
InInternationalSymposiumonSoftwareTestingandAnalysis (ISSTA’16) .449–452.
https://doi.org/10.1145/2931037.2948707
[7]R.A.DeMillo,R.J.Lipton,andF.G.Sayward.1978. HintsonTestDataSelection:
Help for the Practicing Programmer. IEEE Computer 11, 4 (Apr 1978), 34–41.
https://doi.org/10.1109/C-M.1978.218136
[8]Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong,
Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, and Ming Zhou. 2020. CodeBERT:
A Pre-Trained Model for Programming and Natural Languages. In Findings of
theAssociationforComputationalLinguistics:EMNLP (EMNLP’20) .1536–1547.
https://doi.org/10.18653/v1/2020./f_indings-emnlp.139
[9]RahulGopinath,AminAlipour, Iftekhar Ahmed, CarlosJensen, and Alex Groce.
2015. How Hard Does Mutation Analysis Have to Be, Anyway?. In Software
Reliability Engineering . 216–227. https://doi.org/10.1109/ISSRE.2015.7381815
[10]Alex Groce, Josie Holmes, Darko Marinov, August Shi, and Lingming Zhang.
2018. An Extensible, Regular-Expression-Based Tool for Multi-Language Mutant
Generation.In InternationalConferenceonSoftwareEngineering (ICSE’18) .25–28.
https://doi.org/10.1145/3183440.3183485
[11]AlexGroce,KushJain,RijnardvanTonder,GoutamkumarTulajappaKalburgi,
andClaireLeGoues.2022. LookingforLacunaeinBitcoinCore’sFuzzingEﬀorts.
InInternational Conference on Software Engineering: Software Engineering in
Practice (ICSE’22) .https://doi.org/10.1145/3510457.3513072
[12]R.G.Hamlet.1977.TestingProgramswiththeAidofaCompiler. IEEETransactions
on Software Engineering SE-3, 4 (1977), 279–290. https://doi.org/10.1109/TSE.
1977.231145
[13]Vincent J Hellendoorn and Premkumar Devanbu. 2017. Are Deep Neural Net-
workstheBestChoiceforModelingSourceCode?.In JointMeetingoftheEuropean
SoftwareEngineeringConferenceandtheSymposiumontheFoundationsofSoftware
Engineering (ESEC/FSE ’17) . 763–773. https://doi.org/10.1145/3106237.3106290
[14]W.E.Howden.1982. WeakMutationTestingandCompletenessofTestSets. IEEE
Transactions on Software Engineering SE-8, 4 (1982), 371–379. https://doi.org/10.
1109/TSE.1982.235571
[15] Yue Jia and Mark Harman. 2010. Ananalysis and survey of the development of
mutationtesting. IEEETransactionsonSoftwareEngineering 37,5(2010),649–678.
https://doi.org/10.1109/TSE.2010.62
[16]RenéJust.2014. TheMajorMutationFramework:EﬃcientandScalableMutation
AnalysisforJava.In InternationalSymposiumonSoftwareTestingandAnalysis
(ISSTA ’14) . Association for Computing Machinery, 433–436. https://doi.org/10.
1145/2610384.2628053
[17]RenéJust,DarioushJalali,LauraInozemtseva,MichaelDErnst,ReidHolmes,and
Gordon Fraser. 2014. Are Mutants a Valid Substitute for Real Faults in Software
Testing?.In SymposiumonFoundationsofSoftwareEngineering (FSE’14) .654–665.
https://doi.org/10.1145/2635868.2635929
[18]René Just, Bob Kurtz, and Paul Ammann. 2017. Inferring Mutant Utility from
Program Context. In ACM SIGSOFT International Symposium on Software Testing
and Analysis (ISSTA’17) . 284–294. https://doi.org/10.1145/3092703.3092732[19]SamuelJ.Kaufman,RyanFeatherman,JustinAlvin,BobKurtz,PaulAmmann,and
René Just. 2022. Prioritizing Mutants to Guide Mutation Testing. In International
Conference on Software Engineering (ICSE ’22) .https://doi.org/10.1145/3510003.
3510187
[20]JinhanKim,JuyoungJeon,ShinHong,and ShinYoo.2022. PredictiveMutation
Analysis viatheNaturalLanguage Channel inSource Code. ACMTransactions
on Software Engineering Methodology 31, 4, Article 73(2022). https://doi.org/10.
1145/3510417
[21]WeiMa,MengjieZhao,EzekielSoremekun,QiangHu,JieM.Zhang,MikePa-
padakis,MaximeCordy,XiaofeiXie,andYvesLeTraon.2022. GraphCode2Vec:
Generic Code Embedding via Lexical and Program Dependence Analyses. In
MiningSoftwareRepositories (MSR’22) .524–536. https://doi.org/10.1145/3524842.
3528456
[22]DongyuMao,LingchaoChen,andLingmingZhang.2019. AnExtensiveStudy
on Cross-Project Predictive Mutation Testing. In Software Testing, Validation and
Veri/f_ication (ICST ’19) . 160–171. https://doi.org/10.1109/ICST.2019.00025
[23]A.JeﬀersonOﬀutt,AmmeiLee,GreggRothermel,RolandH.Untch,andChristian
Zapf.1996. AnExperimentalDeterminationofSuﬃcientMutantOperators. ACM
Transactions on Software Engineering Methodology 5, 2 (1996), 99–118. https:
//doi.org/10.1145/227607.227610
[24]A. Jeﬀerson Oﬀutt and Roland H. Untch. 2001. Mutation 2000: Uniting the
Orthogonal. In Mutation Testing for the New Century . Springer, 34–44. https:
//doi.org/10.5555/571305.571314
[25]Mike Papadakis, Donghwan Shin, Shin Yoo, and Doo-Hwan Bae. 2018. Are
Mutation Scores Correlated with Real Fault Detection? ALarge ScaleEmpirical
Study on the Relationship between Mutants and Real Faults. In International
Conference onSoftware Engineering (ICSE ’18) . 537–548. https://doi.org/10.1145/
3180155.3180183
[26]Goran Petrovic and Marko Ivankovic. 2018. State of Mutation Testing at Google.
InInternational Conference on Software Engineering: Software Engineering in
Practice (ICSE’18) . 163–171. https://doi.org/10.1145/3183519.3183521
[27]GoranPetrovic,MarkoIvankovic,BobKurtz,PaulAmmann,andRenéJust.2018.
AnIndustrialApplicationofMutationTesting:Lessons,Challenges,andResearch
Directions. In Software Testing, Veri/f_ication and Validation Workshops (ICSTW
’18). 47–53.https://doi.org/10.1109/ICSTW.2018.00027
[28]MartinPopeland OndrejBojar.2018. TrainingTips fortheTransformerModel.
CoRRabs/1804.00247 (2018). https://doi.org/10.48550/arXiv.1804.00247
[29]Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016. Neural Machine
Translation of Rare Words with Subword Units. In Association for Computational
Linguistics (ACL’16) . 1715–1725. https://doi.org/10.18653/v1/P16-1162
[30]AlexeySvyatkovskiy,Sarah Fakhoury,NegarGhorbani,ToddMytkowicz,Eliz-
abeth Dinella, Christian Bird, Jinu Jang, Neel Sundaresan, and Shuvendu K.
Lahiri. 2022. Program Merge Con/f_lict Resolution via Neural Transformers.
InSymposium on the Foundations of Software Engineering (FSE ’22) . 822–833.
https://doi.org/10.1145/3540250.3549163
[31]Roland H. Untch, A. Jeﬀerson Oﬀutt, and Mary Jean Harrold. 1993. Mutation
Analysis Using Mutant Schemata. ACMSIGSOFT Software EngineeringNotes 18,
3 (1993), 139–148. https://doi.org/10.1145/154183.154265
[32]Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N. Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is
all you need. Advances in Neural Information Processing Systems 30 (2017).
https://doi.org/10.5555/3295222.3295349
[33]Wenhan Wang, Ge Li, Bo Ma, Xin Xia, and Zhi Jin. 2020. Detecting Code Clones
withGraphNeuralNetwork andFlow-AugmentedAbstractSyntaxTree. CoRR
abs/2002.08653 (2020). https://doi.org/10.48550/arXiv.2002.08653
[34]Yue Wang, Weishi Wang, Sha/f_iq Joty, and Steven C.H. Hoi. 2021. CodeT5:
Identi/f_ier-aware Uni/f_ied Pre-trained Encoder-Decoder Models for Code Un-
derstanding and Generation. In Empirical Methods in Natural Language Pro-
cessing (EMNLP ’21) . Association for Computational Linguistics, 8696–8708.
https://doi.org/10.18653/v1/2021.emnlp-main.685
[35]MichihiroYasunagaandPercyLiang.2020. Graph-Based,Self-SupervisedPro-
gramRepairfromDiagnosticFeedback.In InternationalConferenceonMachine
Learning (ICML’20) . Article1001. https://doi.org/10.5555/3524938.3525939
[36]Jie Zhang, Ziyi Wang, Lingming Zhang, Dan Hao, Lei Zang, Shiyang Cheng,
and Lu Zhang. 2016. Predictive Mutation Testing. In International Symposium
onSoftwareTestingandAnalysis (ISSTA’16) .342–353. https://doi.org/10.1145/
2931037.2931038
Received 2023-02-02; accepted 2023-07-27
261