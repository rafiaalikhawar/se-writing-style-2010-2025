ExAIS: Executable AI Semantics
Richard Schumi
Singapore Management University
Singapore
rschumi@smu.edu.sgJun Sun
Singapore Management University
Singapore
junsun@smu.edu.sg
ABSTRACT
Neuralnetworkscanberegardedasanewprogrammingparadigm,
i.e.,insteadofbuildingever-morecomplexprogramsthrough(often
informal) logical reasoning in the programmers’ mind, complex
‘AI’systemsarebuiltbyoptimisinggenericneuralnetworkmodels
withbigdata.Inthisnewparadigm,AIframeworkssuchasTen-
sorFlowandPyTorchplayakeyrole,whichisasessentialasthecompiler for traditional programs. It is known that the lack of aproper semantics for programming languages (such as C), i.e., acorrectness specification for compilers, has contributed to manyproblematic program behaviours and security issues. While it isin general hard to have a correctness specification for compilersdue to the high complexity of programming languages and theirrapid evolution, we have a unique opportunity to do it right thistime for neural networks (which have a limited set of functions,
andmostofthemhavestablesemantics).Inthiswork,wereport
our effort on providing a correctness specification of neural net-
work frameworks such as TensorFlow. We specify the semantics of
almost all TensorFlow layers in the logical programming language
Prolog.Wedemonstratetheusefulnessofthesemanticsthroughtwo applications. One is a fuzzing engine for TensorFlow, which
featuresastrongoracleandasystematicwayofgeneratingvalid
neuralnetworks. Theother isamodel validationapproachwhich
enables consistent bug reporting for TensorFlow models.
KEYWORDS
AIframeworks,AIlibraries,deeplearningmodels,semantics,speci-
fication,testcasegeneration,modelvalidation,AImodelgeneration
ACM Reference Format:
Richard Schumi and Jun Sun. 2022. ExAIS: Executable AI Semantics. In
44thInternationalConferenceonSoftwareEngineering(ICSE’22),May21–
29, 2022, Pittsburgh, PA, USA. ACM, New York, NY, USA, 12 pages. https:
//doi.org/10.1145/3510003.3510112
1 INTRODUCTION
Artificial intelligence (AI) refers to intelligence expressed by ma-
chines. It can be based on imitating human intelligence or learning
behaviour. For example, the technique called deep learning (DL)
appliesartificialneuralnetworkstosimulatetheneuronsofnatural
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
onthe firstpage.Copyrights forcomponentsof thisworkowned byothersthan the
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or
republish,topostonserversortoredistributetolists,requirespriorspecificpermission
and/or a fee. Request permissions from permissions@acm.org.
ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
© 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-9221-1/22/05...$15.00
https://doi.org/10.1145/3510003.3510112brains[36].Inrecentyears,the dramaticgrowthofdataandcom-
putingpowerhasledtothespreadofDLapproacheswhichenabled
numerous new technologies, like autonomous driving, language
processing, and face recognition [34].
Inprinciple,AIsystemscanbeseenasanewprogrammingpara-
digm.Insteadofbuildingprogramsthrough(ofteninformal)logical
reasoning by programmers, AI systems are built by training neural
networkmodelswithbigdata.Forconventionalprogramming,com-
pilersorinterpretersaremajordevelopmenttools.Similarly,forthe
development of neural networks the focus is on AI frameworks (or
libraries) such as TensorFlow and PyTorch, which provide utilities,
algorithms, and various types of layers that constitute DL models.
The lack of a proper semantics (or correctness specifications)
for programming languages has resulted in many critical issuessuch as inconsistencies or vulnerabilities. Generally, it is hard to
developacomprehensivespecificationforcompilersduetothehighcomplexityandtherapidevolutionofprogramminglanguages[
39].
However,webelievethatitismorefeasibleforAIframeworks,since
the semantics of AI frameworks are usually stable and simpler, i.e.,
thesetoffunctionsandlayersusedinpopularmachinelearning
models are usually limited.
AlthoughAIsystemshavebeenprovensuccessfulinmanyap-
plications, they are not error free. Especially in safety critical appli-
cations,likeautonomousdriving,ormedicalsystems,evensmall
bugscanhavesevereconsequences.Thus,weneedsystematicwell-
grounded analysis methods for AI systems. While the lack of a
properlanguagespecificationhashinderedmanyprogramanalysistasks,wehavehereauniqueopportunitytostartafreshbybuildingaformalsemanticsofAIsystems,whichthenservesasasolidfoun-
dation for developing ever more sophisticated analysis methodsfor AI systems. In this work, we make such an attempt by devel-oping an executable (formal) semantics for AI frameworks. Thatis, we introduce a Prolog specification for almost all TensorFlow
layers. Our specification provides the foundation for solving many
AI analysis problems, such as AI test generation, model validation,
and potentially AI model synthesis. In the following, we present
one example application of the semantics, AI test generation.
Recently, testing DL systems has become a popular research
topic, with a variety of approaches [ 24,30,44]. In comparison, test-
ingAIframeworkshasgainedlessattention.AbuginanAIlibrarycanpotentiallyputallsystemsthatwerebuiltwiththelibraryatrisk.Hence,itiscrucialtoensurethecorrectnessoftheselibraries.Multi-pleresearchersmadesomeearlyattempts[
22,23,33,38,40,41,43],
although existing approaches suffer from at least two major issues.
First, existing approaches often have a weak oracle (i.e., a test case
passesifsomesimplealgebraicpropertiesaresatisfied[ 22]orr e-
sultsinsimilaroutputsontwoimplementations[ 40]),whichcan
make it difficult to find deep semantic bugs. Second, existing ap-
proaches fail to systematically generate valid AI models, i.e., to our
8592022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:19:35 UTC from IEEE Xplore.  Restrictions apply. ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Richard Schumi and Jun Sun
knowledge, the state-of-the-art approach has a success rate of 25%
in generating valid models (after a complicated process combining
NLP techniques with manually designed templates) [29].
Ourexecutablesemanticssolvesthesetwoissuesnaturally.First,
given an AI model, our semantics can be executed to compute pre-
cisely the constraints that are satisfied by the output (based on the
Prolog’sunderlyingunificationandrewritingsystem),whichserves
as astrong testoracle. Second,our semantics facilitatesthe devel-
opmentofafuzzing-basedtestgenerationmethodtosystematically
producevalidAImodels.Oursemanticsfacilitatesthegeneration
process by providing feedback in the form of a badness-value that
indicateshowfarthemodelisawayfrombeingvalid(i.e.,satisfying
the precondition of all layers of the model). Our evaluation shows
thatwesignificantlyimprovethesuccessrateofgeneratingvalid
AImodel(e.g.,99%)andcangeneratediversemodelarchitectures
consisting of various layers (in the form of sequences and complex
graphs) as well as layer arguments, weights, and input data.
Besides,having anexecutable semanticsof anAIlibrary opens
thedoorforarangeofotherexcitingresearch.Forinstance,itallows
systematic validation and bug reporting for AI models, e.g., by
investigatingautomaticallywhethercertainpreconditionsrequired
by a specific AI component are violated, and by checking if the
architectureofamodelisvalid.Weremarkthatexistingdebugging
techniques for AI systems rely on simple oracles (such as shape
mismatch), which is preliminary compared to the oracle that isprovided by our semantics. For another instance, our semantics
potentiallysupportsthedevelopmentofsynthesisingtechniques
for AI models. That is, given certain user requirements (e.g., on the
input format, the output constraints and perhaps a model sketch),
theproblemofsynthesisingAImodelscanbereducedtoasearch
problembasedonthewell-specifiedsemanticsofallcomponents
inexistingAIframeworks,i.e.,bycomposingthecomponentsin
different ways and checking if the user requirements are satisfied.
To sum up, we present the following contributions in this work.
•We introduce an executable semantics of an AI library (i.e., Ten-
sorFlow), which captures the behaviour of the DL layers.
•To demonstrate the relevance of our semantics, we present a
novel testing method for AI libraries that applies the semantics
as test oracle and utilises it to generate valid AI models. Our
method was able to reveal 14 issues and bugs in TensorFlow.
•We illustrate a model validation method that can identify issues
of invalid AI models, like a wrong model architecture, based on
our semantics, and that supports consistent bug reporting.
Structure. Therestofthepaperisstructuredasfollows.InSect.2,
we introduce our semantics and show how we specify different
layers.In Sect.3, wepresent twoapplicationsof thesemantics. In
Sect.4,weevaluatethesetwoapplicationssystematically.Lastly,
we review the related work in Sect. 5 and conclude in Sect. 6.
2 AI FRAMEWORK SEMANTICS
Inthissection,westartwithabriefintroductionofthelogicpro-
gramminglanguageProlog[ 32]thatweadoptforthedevelopment
of our AI framework semantics. Afterwards, we describe our ap-
proach on developing the semantics through examples. In general,
to support a variety of analysis tasks including testing, debugging
andevensynthesisingAImodels,itisimportantthatthesemanticsfulfilsthefollowingrequirements[ 35,39].First,thesemanticsmust
be declarative and high-level so that it avoids complications dueto implementation-level optimisation and to facilitate a concise
specificationthatisindependentofimplementationdetails.Second,
it must support symbolic reasoning to allow various property, con-
sistency and correctness checks, and thus it must be specified in
logic. Lastly, it must be executable so that it can be used to support
a variety of automated analysis tasks, like testing or debugging.
2.1 Prolog
Prolog is a declarative language that relies on first order logic.
ProgramsinPrologarebuiltwithrulesandfacts,whichareusually
concerned with mathematical relations. Hence, we believe that
Prologissuitableforaformalsemanticrepresentation.Theremight
be more formal mathematical semantic models that, e.g., rely on
Coq [38], but such notations are not as flexible and would make it
difficult to support a large number of layers.
In Prolog, a user can ask queries, and the answer is computed
automaticallybasedon therules andfacts witha unificationalgo-
rithm.Thefollowingexampleshowstwofactsstatingthat average
andflatten are layers and a rule that says that layers are AI com-
ponentsai_components.
layer(average).
layer(flatten).
ai_components (X):- layer(X).
Ausermayaskqueriessuchas ai_components(flatten). ,which
is simplyanswered by true,or ai_components(X). where Xis a
variable which produces the following results.
X = average;
X = flatten.
A rulecan generallybe seen asa predicatethat hasarguments (in
the header) and describes the relation between these arguments
withaconjunctionofclausesinthebodyoftherule.Arguments
can be atoms (lowercase) or variables (uppercase). Prolog supports
a number of data types and has built-in features for various math-
ematical operations. Moreover, it includes functions for list and
string processing, and higher order programming notations [21].
Prolog is a well-suited specification language for our purpose
formultiplereasons.First,itis largelyintuitiveandconvenientto
use(i.e.,byspecifyingrulesandfacts)andhasareasonablylarge
user base, which is extremely important as we intend to invite the
open-source community to collaboratively maintain the semantics.
Second,itsupportsvariouslistoperationsandmathematicalexpres-
sions,whichishelpfulforcapturingthesemanticsofAIlibraries
that involve mathematical operations on multidimensional data.
Third,Prologsupportsautomatedreasoning(throughanunderly-
ingrewritingandsearchsystem),whichisessentialforourpurpose.
Lastly, Prolog is a well-studied declarative programming language,
whichisfundamentallydifferentfromtheimperativeprogramming
that isused toimplement AI frameworks.This makes itunlikely
that our semantics will have the same bugs in the implementation.
2.2 Specifying the Semantics
Inthiswork,wefocusondevelopingasemanticsfortheTensorFlow
framework, since it is the most popular AI framework. TensorFlow
860
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:19:35 UTC from IEEE Xplore.  Restrictions apply. ExAIS: Executable AI Semantics ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
02 04 06 08 01 0 00510
line countfrequency
Figure1:Histogramofthefrequenciesoflinenumbersused
to specify the layers in Prolog.
isacomplexframeworkthatprovidesvarioustools,implementa-
tions, and features for the development of AI systems. We system-
aticallygothrougheverycomponentintheTensorFlowframework
andidentifyallthecomponentswhicharerelevanttoAImodels
themselves (rather than, components for the training process). Our
goal is to implement a comprehensive semantics for one of its core
components,i.e.,thelayers[ 19].Wespecifythesemanticsofnearly
alllayersexceptafewlayersforpracticalreasons.Adetaileddiscus-sion of the omitted layers is in Sect. 4. In total, we specify the layerfunctionalitythatisrequiredtoperformapredictionof72layersof
different types, we did not implement any TensorFlow algorithmsthat areconcerned with the trainingof models ordata processing.
Afulllistoftheselayersisavailableinourrepository[ 10].Foreach
layer, we systematically go through the documentation, and run
tests to understand the semantics. Unfortunately, the semantics of
quite a numberof layers are under-specified,and we have to seek
further help from online forums and/or the authors. In multiple
cases, we identify under-specified or mis-specified behaviours, like
wrong handling of unexpected layer arguments, or missing restric-
tions for layer inputs (more details are in Sect. 4). This suggests
thatformalisingthesemanticsaloneisalreadyuseful,andcanhelp
to improve AI frameworks.
Thesemanticsofeachlayerisspecifiedusingoneormorerulesin
Prolog.Figure1showsahistogramofthefrequenciesofthenumber
oflines(orrules)requiredforthelayers.Itcanbeseenthatmany
layers only require less than 10 lines. The reason is that they reuse
predicatesofotherlayers,orbuilt-inrules.Amajorfractionoflayersrequiresnomorethan40lines,andtheremaininglayershavenearly
all less than 80 lines. One outlier (the Dot layer) has 106 lines sincethe implementation supports various axis combinations for the dot
product.Intotal,thesemanticsconsistsofabout3200linesofProlog
code and on average 44 lines per layer (when shared predicatesare considered). The implementation of nearly all layers has anone-to-one correspondence with the deterministic functionalityof the TensorFlow layers. This allows us to, given an AI model,
straightforwardlyinvoketherelevantrulesinoursemanticsand
apply them to generate constraints on the model output.
WeremarkthatsincethesePrologrulesarespecifiedbyhumans,
theyarepotentiallybuggyaswell.Standardpracticesareappliedto
ensure the correctness of the semantics itself, such as code review,
manualtesting(e.g.,usingdocumentationexamples)andautomated
testing (e.g., using our own fuzzing engine). While we cannot becompletely sure that the semantics is correct, we have reason tobelieve that it is reasonably so. In general, one can always argue1 dense_layer ([I|Is], IWs, Bs, [O|Os]) :-
2 depth([I|Is],2),
3 dense_node_comp (I, IWs, Bs, O),
4 dense_layer (Is, IWs, Bs, Os).
5
6 dense_layer ([I|Is], IWs, Bs, [O|Os]) :-
7 depth([I|Is],D), D > 2,
8 dense_layer (I, IWs, Bs, O),
9 dense_layer (Is, IWs, Bs, Os).
10
11 dense_layer ([], _, _, []).
12
13 dense_node_comp ([I|Is],[IW|IWs],Res0,Res) :-
14 multiply_list_with (IW,I,Res1),
15 add_lists (Res0,Res1,Res2),
16 dense_node_comp (Is,IWs,Res2,Res).
17
18 dense_node_comp ([],[],Res,Res).
Listing 1: Prolog semantics of the Dense layer.
that correctness is an illusion and all there is is consistency (e.g.,
between manually-programmed TensorFlow and manually-writtenPrologsemantics).Thatis,aslongasthesamebugisnotpresentin
boththeimplementationandthesemantics,inconsistencywould
ariseandeitherTensorFloworoursemanticswillbefixed.Inthe
following, we illustrate our semantics with multiple examples.
Dense layer. Listing 1 shows our Prolog semantics of a Dense
layer[6].Itisastandarddenselyconnectedlayer,whichcontainsa
number of nodes and each is connected with all inputs. The output
iscomputedbytheweightedsumofallinputsateachnodewith
anaddedbiasvalue.Ourspecificationworksasfollows.Therule
startinginLine1 hasmultipleparameters:alist [I|Is],aweight
arrayIWs,andabiasarray Bs(whichcanbeintuitivelyregarded
as inputs) and a list Os(which can be regarded as the output). The
list notation [I|Is]enables accessto the firstelement Iand the
remaining elements Isof a list. Line 2 constrains the depth of the
nestedinputtotwo.Wehandlehigherdimensionalinputseparately.
Line 3 applies a predicate that is true when Ocan be unified as the
expected output for an input I, and Line 4 is a recursive constraint,
which intuitively continues with the next inputs.
The rule in Lines 6–9 is similar, except that it handles (layer)
inputs with a higher dimension, which is checked in Line 7, andrecursivelyuses ourinitialpredicatefromLine1since thedense
layeronlyperformscomputationsintheinnermostlistevenwhenitreceiveshighdimensionalinputdata.Line11(andLine18)arethe
base cases for the recursion, i.e., when only an empty list remains.
ThepredicateinLine13encodesthemainlayerfunctionalityand
becomes true when the Resvariable is the expected output for the
input[I|Is].Ithasthesameargumentsasourfirstruleandanaddi-
tional temporary variable Res0for the result. It consists of clauses
for multiplying the weight arrays IWwith each input Iand for
addingtheresultsinLine16.Thepredicates multiply_list_with
andadd_lists are straightforward and are therefore omitted.
With this Prolog semantics, we can now answer a variety of
queries, e.g., to compute the expected output of a Dense layer. The
followinglistingshowssomeexamples.Thefirstisabasicquery
with two inputs and two nodes and the second has three nodes
and more complex input. It can be seen that even such a small and
simple specification can handle high dimensional input with just a
few lines of code. The third query fails due to invalid arguments
861
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:19:35 UTC from IEEE Xplore.  Restrictions apply. ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Richard Schumi and Jun Sun
since the number of nodes must be equivalent to the size of the
bias array and also to the second dimension of the weight array.
Manylayershavenon-trivialpreconditionslikethat.Thismakesthe
generation of test data difficult. In Section 3, we will illustrate how
wecanidentifysuchinvalidinputsandproduceusefulinformation
about the source and severity of such issues to support our model
validation and test generation approaches.
dense_layer ([[4,9]], [[5,8],[7,6]], [4,3], X).
X = [[87, 89]]
dense_layer ([[[[[1,2,3]]],[[[4,5,6]]]]],
[[2,3,4],[5,4,6],[7,6,8]], [2,3,4], X).
X = [[[[[35, 32, 44]]] , [[[77, 71, 98]]]]]
dense_layer ([[3,1]], [[8,4],[2,7],[3,9]], [7], X).
false.
Conv1Dlayer. Aconvolutionlayer[ 2]shiftsakernel(orpool)
over the input space and produces the weighted sum of the ele-ments within the kernel. It can, for instance, be used for imagepreprocessing or recognition. Listing 2 illustrates the (simplified
forthesakeofpresentation)semanticsofthislayer.Line1showsa
predicate for the layer, which has the (layer) input data Is, a num-
berKernelSize for theone dimensional sizeof the window that
shouldbeshifted,aweightarray IWsforthekernelelements,abias
arrayBsofvaluesthatareaddedtotheoutput,astepsize Strides,
a Boolean Padding for optionally enlarging the input data, e.g., by
surroundingitwithzeros,andtheoutputdata Os,asparameters.
Lines 2–4 apply predicates for checking the validity of the layer
inputs and arguments, i.e., to ensure that the input dimensions are
asrequired,tocheckthatthekernelisnottoolargefortheinput,
andtoverifythattheweightsarevalid.Anexampleimplementa-
tionofsuchapreconditionisgiveninSect.3.3.Line5appliesthe
pool1Dpredicate,whichisagenericpredicatefordifferenttypes
of poolingor convolutionaloperations, and itbecomes truewhen
Oscan be unified with the result of the operation.
Line 7 shows the pool1Dpredicate, which has the same argu-
ments as the conv1D_layer with an additional Poolfunc meta-
predicate to decide what should happen within the pool, and an
argument MultiLayerPool to specify if the pool should be shifted
overthesecondaxisoftheinputspace.Next,thereisacalltoasub-
predicate for one sample of the input in Line 8, with initialisations
ofcoordinatesandatemporaryoutputvariable,Line9iteratesover
the other samples, and Line 11 is a simple stopping clause.
In Lines 13–17, we apply padding with the calc_padding pred-
icate that is true when LeftP, andRightPare padding sizes to
maintain the input shape after pooling, and by using these vari-ables for the
padding1D predicate that succeeds when Is1isIs
withpadding.ThepredicateinLines19–24doestheactualappli-
cation of the convolution. Line 21 utilises the pool predicate, i.e.
the weighted sum of the kernel, for a given position X,Y, which is
then appended to the output in Line 22. Next, Line 23 has a con-ditional clause that introduces new variables
X1,Y1for the next
coordinates given the current pool position, and finally Line 24
performs recursion to continue with the next coordinates.
Lines 26–31 are defined similarly, except that the pool is also
shifted over the second axis by iterating over the Ycoordinate1 conv1D_layer (Is,KernelSize,IWs,Bs,Strides,Padding,Os):-
2check_dimensions(Is,3),
3check_valid_kernel(Is,KernelSize,Padding),
4check_valid_weight_shapes(Is,KernelSize,IWs,Bs),
5 pool1D(sum,Is,KernelSize,Strides,Padding,IWs,Bs, false,Os).
6
7 pool1D(Poolfunc,[I|Is],PoolSize,Strides,Padding,IWs,Bs,
MultiLayerPool,[O|Os]):-
8 pool1D(Poolfunc,I,0,0,PoolSize,Strides,Padding,IWs,Bs,
MultiLayerPool,[],O),
9 pool1D(Poolfunc,Is,PoolSize,Strides,Padding,IWs,Bs,
MultiLayerPool,Os).
10
11 pool1D(_,[],_,_,_,_,_,_,[]).
12
13 pool1D(Poolfunc,[[I|Is0]|Is],0,0,PoolSize,Strides, true,IWs,Bs,
MultiLayerPool,[],Os) :-
14 atomic(I), length([[I|Is0]|Is],L),
15 calc_padding (L,PoolSize,Strides,LeftP,RightP),
16 padding1D ([[I|Is0]|Is], x,LeftP, RightP, Is1),
17 pool1D(Poolfunc,Is1,0,0,PoolSize,Strides, false,IWs,Bs,
MultiLayerPool,[],Os).
18
19 pool1D(Poolfunc,[[I|Is0]|Is],X,0,PoolSize,Strides, false,IWs,Bs
,false,Os0,Os) :-
20 atomic(I), length([[I|Is0]|Is],LX),
21 get_pool_res1D (Poolfunc,[[I|Is0]|Is],X,Y,PoolSize,Strides,
IWs,Bs, false,O),
22 insert_pool_field (Os0,O, true,X,Y,Strides,Os1),
23(X+Strides+PoolSize =< LX -> X1 is X+Strides; X1 is LX+1),
24 pool1D(Poolfunc,[[I|Is0]|Is],X1,0,PoolSize,Strides, false,IWs
,Bs, false,Os1,Os).
25
26 pool1D(Poolfunc,[[I|Is0]|Is],X,Y,PoolSize,Strides,Padding,IWs,
Bs,true,Os0,Os) :-
27 atomic(I), length([[I|Is0]|Is],LX),
28 get_pool_res1D (Poolfunc,[[I|Is0]|Is],X,Y,PoolSize,Strides,
IWs,Bs, true,O),
29 insert_pool_field (Os0,O, true,X,Y,Strides,Os1),
30(X+Strides+PoolSize =< LX -> X1 is X+Str ides,Y1 is Y; X1 is
0,Y1 is Y+1),
31 pool1D(Poolfunc,[[I|Is0]|Is],X1,Y1,PoolSize,Strides,Padding,
IWs,Bs, true,Os1,Os).
32
33 pool1D(_,[[I|Is0]|Is],X,Y,_,_, false,_,_,_,Os,Os) :-
34 atomic(I),
35(length([[I|Is0]|Is],LX), X >= LX;
36 length([I|Is0],LY), Y >= LY).
Listing 2: Simplified Prolog specification of a pooling layer.
insteadofjustusingthesumoverthesevalues.Finally,Lines33–
36 show a stopping clause, which becomes true when one of the
indexesX,Yis outside the input space.
Similarly, with the above semantics, we can now query this
layer as shown in the following examples. The first example has
integerandthesecondhasfloating-pointinputs.Itcanbeseenthat
variables are not limited to a specific type, our implementations
works for integers as well as floating-point numbers.
conv1D_layer ([[[9, 9, 6, 5, 3], [4, 5, 5, 8, 2], [2, 4, 2, 3,
10]]], 3,[[[4, 5], [4, 5], [3, 4], [2, 5], [4, 3]], [[5, 4],
[5, 1], [3, 1], [5, 2], [3, 5]], [[2, 4], [1, 1], [5, 3], [3,
1], [3, 5]]],[0, 0], 1, false, X).
X = [[[275, 271]]]
conv1D_layer ([[[0.0113, 0.1557, 0.1804], [0.8732, 0.317, 0.9175],
[0.7246, 0.833, 0.8881]]] , 2,[[[0.0419, 0.2172], [0.9973,
0.6763], [0.6917, 0.452]], [[0.0743 , 0.9004], [0.52, 0.5426],
[0.4529, 0.5032]]],[0, 0], 1, false, X).
X = [[[0.92579027, 1.60921455], [1.8765842, 2.3700637]]]
An interesting aspect of this layer is that a lot of the functionality
canbereusedforotherlayers.Inparticular,the pool1Dpredicateis
862
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:19:35 UTC from IEEE Xplore.  Restrictions apply. ExAIS: Executable AI Semantics ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
1 dropout_layer (Is, Os, Rate, AcceptedRateDiff) :-
2count_atoms(Is,N), count_atoms(Os,NO), NO = N,
3count_occurrenc es(Is,0,NZeroOrig),
4count_occurrenc es(Os,0,NZeroNew),
5RealRate is (NZeroNew - NZeroOrig) / (N -NZeroOrig),
6Diff is abs(Rate - RealRate),
7(Diff > Acc eptedRateDiff -> ( write("Expected Rate: " ),
writeln(Rate), write(" Actual Rate: " ), writeln(
RealRate), false); true).
Listing 3: Prolog specification of the Dropout layer.
defined generic so that it can be applied for the semantics of many
related layers. For example, it is applied for simple pooling layers,
like (global) average or max pooling and for other convolutional
layers, like separable convolution and locally connected layers.
Non-deterministiclayers. Althoughmostlayershavedetermin-
istic behaviour when their weights are known, there are a few
exceptionsincluding layerssuch asDropout,AlphaDropout, Spa-
tialDropout, GaussianDropout, and GaussianNoise. All of them
either have built-in non-determinism (i.e., random behaviour) or
areprobabilisticinnature(i.e.,producingoutputsthatfollowsacer-tainprobabilitydistribution).WedefinedPrologrulesthatconstrain
these layers to satisfy high-level properties which are documented
in the respective documentation, e.g., if the layer is expected toproduceresultsthatareaccording toa specific distribution,they
should. We demonstrate how this is done for the dropout layer [ 8].
Thislayerisexpectedtosetvaluesoftheinputtozeroaccordingto
agivenrate.(Additionally,thelayeralsoaddsnoisetothedata,but
we neglect this feature in the example for brevity.) Listing 3 shows
a predicate that checks if the dropout actually occurs at a given
rate.Theargumentsaretheinputs Is,theoutputsfromTensorFlow
Os, the rate, and a threshold AcceptedRateDiff for the maximum
difference to the observed rate. Line 2 shows predicates which are
true when NandNOcan be unified with the number of input and
outputvalues,whichmustbeequal.Line3doesthesameforthe
number of zeros in the input, and Line 4 for the number of zeros inthegivenoutput.Next,Line5sets
RealRate totheobservedrateof
dropouts while considering the already existing zeros in the input,
andLine6applies the absfunctiontoobtainthedifferencetothe
expected rate. Finally, Line 7 checks if the difference is bigger than
our threshold and writes a message if that is the case.
3 APPLICATIONS OF THE SEMANTICS
Thesemanticshasmanyapplications.Inthissection,wedemon-
stratetwoofthem.Weillustratetheoveralldesignofourtesting
and model validation approaches and show step-by-step examples.
3.1 AI Framework Testing
Recently, multipleresearchersstarted working onAI frameworktesting [
22,23,33,38,40,41,43]. While an impressive number of
bugs have been identified, there are still many open challenges.
Based on our executable semantics, we introduce a novel AI frame-
worktestingmethodwhichimprovestheexistingapproachesby
addressing the following problems. (1) The oracle problem (i.e.,how we verify if the output is correct). (2) The test generation
problem (i.e., how can we effectively generate valid test cases). Forthe first problem, the existing approaches focus on differential test-
ing[33,41,43]orasimpleformofmetamorphictesting[ 22,23,40].
For differential testing, multiple libraries (or implementations) are
comparedagainsteachother,andbugsareidentifiedwhenanin-
consistency is found. The kind of metamorphic testing done on AI
frameworks introduces changes in the test input (i.e., an AI model)
that should not affect the output. A different output would thus
indicate a bug. In other words, such testing relies on the algebraic
propertythat‘deadcode’doesnotchangethemodel’sbehaviour.
Differential testing is powerful since a second implementation can
serve asa good test oracle.However, a secondindependent imple-
mentation is not always available, especially for new algorithms.
Evenifitisavailable,itisstillpossiblethatitsuffersfromthesame
bugsduetoreasonssuchasusingthesameunderlyinglibraryor
implementingcertainoptimisationinthesame‘wrong’way.Our
methodcanalsobeseenasaformofdifferentialtesting,butitis
unlikelythatoursemanticswill suffersfrom thesamebugssinceit
is developed in a different modelling paradigm at a high-level (e.g.,
where little performance optimisation is involved). On the other
hand, metamorphic testing is usually limited to specific types ofbugs based on algebraic properties (i.e., a very small piece of thesemantics) which are used to guide the test generation. Anotherissue that limits the applicability of both approaches is the non-deterministic behaviour of the layers, e.g., inconsistency may bedue to non-deterministic or probabilistic behaviours rather thanbugs.Usually,thetrainingofAImodelscontainsrandomfactorsthat cause small discrepancies in different implementations and
makeanexactcomparisonandtheidentificationofbugsdifficult.
Thisissueissometimesresolvedbyrelyingonapproximatingor-
acles that accept a range of inputs. This is not an ideal solutionsinceitoftenrequiresmanualadjustments[
31].Basedonourse-
mantics, we have an alternative more powerful solution for thisproblem. By developing our semantics with a focus on the high-
levelbehaviourofthelayers,wecantesttheresultsofanAImodel
independentlyofthenon-deterministictrainingalgorithms.This
facilities the detection of subtle bugs without the interference of
underlying non-deterministicor probabilistic behaviours.
The second problem, i.e., the test case generation problem, is
oftenaddressedbyusingexistingbenchmarkexamplesorbymodi-
fying these examples, e.g., via mutation [ 43]. The problem of the
formeristhatexistingexamplesarelimitedinbothnumbersandva-riety. The problem of the latter is that test cases generated through
mutation are often invalid, e.g., due to non-trivial preconditions
thatmustbesatisfiedbythelayers.MostAIlibrariescontaindozensofdifferentlayersthatcanbeconnectedinsequencesorincomplex
graphstructurestoformdeeplearningmodels.Therearesimple
layers, like a densely connected layer, and also highly complicated
layers which apply operations on multidimensional inputs or even
combinethefunctionalityofotherlayers.Usually,theyneedanum-
ber of configuration arguments, e.g., for specifying the number
ofneuronsorafiltersize.Mostlayershavepreconditionsforthe
inputsandhencetheycannotbefreelycombined.Toaddressthis
problem, a recent approach [ 29] proposes to extract information
about theinput requirements from thelibrary documentation and
togenerate‘valid’testcasesaccordingly.However,afterallitsef-
fort, it still has very limited capability in producing valid test data,
i.e., the success rate is around 25%.
863
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:19:35 UTC from IEEE Xplore.  Restrictions apply. ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Richard Schumi and Jun Sun
Test Case
GenerationProlog
SpecificationAI
Library
Test
CasesExecution
with AI LibExecution
with Spec-
ification
Test
OutputsTest
OutputsOutput
Comparison
Pass/Fail
Verdictinput/output
artefact
process
Figure2:Overviewofthedataflowofourtestingapproach.
Inthiswork,wedevelopafuzzingmethodwhichutilisesfeed-
backfrom oursemanticstoenable asystematicwayof producing
validtestcases,i.e.,byfindinglayers(andassociatedarguments)
that are compatible with each other. Moreover, our approach ex-
ploresvariouslayerargumentsinordertofindinterestingcombi-
nationsthatmight reveal bugs. The overallw orkflowisdepictedin
Fig. 2. Next, we will explain the involved tasks and components.
Ourmethodhastwomaincomponents.First,themostimportant
component is the oracle, which is our executable Prolog semantics.
Given a deep learning model (in the form of collection of layers
and their arguments) and the input data, the oracle executes the
semantics to produce a prediction, in a similar fashion as it is done
byanAIlibrary.Second,thetestcasegeneratorisatoolthatpro-
duces test data in the form of multidimensional arrays anda deep
learningmodelasacollectionoflayersandtheirrespectiveargu-
ments. Our test case generator is based on fuzzing techniques and
produces random inputdata and models. Thefocus of the genera-
tionistoproducecomplexmodelswithgraphstructuresinordertoextensivelytestcombinationsofdifferentlayersinvarioussettings.
Inthefollowing,weusethesimplifiedsemanticsoftheconvo-
lution layer that we showed in the last section to demonstrate the
test generation. The test case generator produces test input dataas well as a deep learning model (including layer arguments) toreveal bugs or inconsistencies in the AI library. The model andthe input data (for performing a prediction) together form a test
case. A test case is automatically generated in the form of a Prolog
query, which is given to the Prolog interpreter to compute a result
withaunificationalgorithm.Forexample,asimplequeryforour
convolutional layer is as follows.
conv1D_layer ([[[5,8,7],[9,10,7],[3,7,7]]],2,
[[[1],[1],[1]],[[1],[1],[1]]],[0],1, false,1,X).
The same test case for TensorFlow is expressed as a simple Python
program as shown in Listing 4. The first lines are imports and
configurations. Lines 3-4 define the actual deep learning model. In
Lines 5-8 we overwrite the weights for the kernel and the biases in1 import tensorflow as tf, numpy as np
2 fromtensorflow.keras import layers, m odels
3model = tf.keras.Sequential([
4 layers.Conv1D(1, (2),strides=(1), input_shape=(3, 3)) ])
5w = model.get_weights()
6w[0] = np.array([[[1], [1], [1]], [[1], [1], [1]]])
7w[1] = np.array([0])
8model.set_weights(w)
9x = tf.constant ([[[5, 8, 7], [9, 10, 7], [3, 7, 7]]])
10 print(np.array2string(model.predict(x,steps=1)))
Listing 4: TensorFlow example of a Conv1D layer.
order to support a deterministic prediction. Usually these weights
areinitialisedrandomlyandtunedthroughtraining.Line9setsthe
input data and Line 10 performs a prediction with the model for
the input data, which gives us the test output.
Finally,wecomparetheoutputofthetestprogram(thatincludes
theAIlibrary)totheoutputofthesemantics.Atestfailsifthecon-
straints produced by the semantics are not satisfied by the output
from the Python program. In general, such a failure can be caused
bybugsinthelibraryandpossiblybybugsinthesemantics.For
ourexample,theoutputwas [[[46], [43]]] inbothcases,which
represents a successful test. A bug is identified when there is an
inconsistency in the outputs (prediction results) of the TensorFlow
programandofoursemantics.Ifthereisaninconsistency,welo-
calisethebugbycheckingwhichlayerspecificationisviolated,and
by manually checking the cause.
3.2 Test Case Generation
The test case generator is a tool that can produce models in the
form of Python scripts (that use TensorFlow) as well as models
represented as Prolog queries. It also generates random test inputs
(intheformofmultidimensionalarraysthatneedtohaveaspecific
shape or number of dimensions depending on the first layer) fora prediction with a model and layer arguments, which can alsobe the weights of layers. The generation is done by the test casegenerator alongside the AI model generation while considering
input requirements. The details about the required arguments can
be found in the TensorFlow documentation. A test case is a model
together with the associated test inputs.
The main functionality of the test generator is the generation of
diversefunctionalmodels. Pseudocodeofthegenerationprocess
is illustrated in Algorithm 1. It consists of two major functions
forrandomlybuildingamodelandforfindingavalidmodel.The
first is a recursive function (Line 1) that starts by selecting aninitial root layer and continues to connect random layers ontoit. The algorithm increases the probability of stopping based onthe
levelthat represents the distance of the current layer to the
root layer (Line 2) to prevent too large models. Many layers cantake the output of one layer as input, and some can have inputs
from multiple layers, e.g., to perform mathematical operations, like
addition, or multiplication of the inputs. Hence, there is a variable
forthenumberofinputs,whichissetaccordingtothegenerated
layer(Lines5–7).Finally,therecursionisperformedforeachinput,aconnectionisformedwiththeassociatedfunctions(byfeedingtheoutputofalayerasinputtoanotherlayer),andthelayerisreturned.
The model in this case is just the root layer that is connected to
other layers. Note that the models produced by this function are
864
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:19:35 UTC from IEEE Xplore.  Restrictions apply. ExAIS: Executable AI Semantics ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
Algorithm 1 Pseudo code of the test model generation.
Input:GenHelper : helper class containing a map of layer generators (Layer.Name →Generator)
SemanticHelper helper class for the execution of the semantics
1:function recursiveGeneration(level, rand)
2:iflevel=0∨rand.nextBool()then⊿Allow deeper graph based on the random result
3: returnnull ⊿End of the recursion
4:layer←GenHelper .generateLayer ()⊿Generates a random layer incl. arguments
5:inputNumber ←1
6:iflayer.hasMultipleInputs ()then ⊿Check if layer requires multiple inputs
7: inputNumber ←rand.nextInteger (3)
8:fori←1toinputNumber do
9: layer1←recursiveGeneration (level−1,rand)
10: layer1.setParent(layer),layer.addChild(layer1) ⊿Connect layer
11:returnlayer
12:function findValidModel(layer,maxTries,rand) ⊿findvalidmodelgiventherandommodel
13:fori←1tomaxTries do
14: (success,error)←SemanticHelper .run(layer)⊿run the semantics, get success/error
15: ifsuccess then
16: returnlayer
17: else iferror.getLocation ()=lastError.getLocation ()∧
error.getBadness () ≥lastError.getBadness ()then
18: layer←lastLayer,error←lastError ⊿Restore model if no improvement
19: else
20: lastLayer ←layer,lastError ←error,layer1←error.getLocation ()
21: ifrand.nextBool ()then
22: layer1.regenerateArgs () ⊿Reset the layer arguments
23: else if rand.nextBool ()then
24: options←[”Reshape”,”UpSampling ”,”Cropping ”,”Padding”,...]
25: layer2←GenHelper .generateLayer (options)⊿Generate one of the options
26: layer1.insertLayerBeforeChild (layer2) ⊿Insert layer before input
27: else if rand.nextBool ()then
28: layer2←GenHelper .generateLayer ()
29: layer1.replaceWith (layer2)⊿Replace current layer with another layer
30: else if rand.nextBool ()then
31: layer2←GenHelper .generateLayer ()
32: layer1.replaceChildWith (layer2)⊿Replace input layer with another layer
33:returnnull
most likely invalid, and for simplicity it produces models in the
form of trees. The semantics also supports more complex graphs.
Thesecondfunctiontakesthis model asabasistofindavalid
model with the help of the semantics (Line 12). Our semantics can
identify invalid models based on layer preconditions, which are
defined as part of the corresponding Prolog rules. These precon-ditionsgivefeedbackin theformofabadnessvalueto guidethe
generationprocesstowardsvalidmodels.Givenaconcretemodel
andapreconditiontobesatisfied,thebadnessvalueisdefinedin
the same wayas fitness in search-based software testing[ 25]. It is
a distance metric that increases when the model is further away
frombecomingvalid,i.e.,werankthepreconditionsbasedonsever-
ityandcalculateavaluebymultiplyingaseverityfactorwiththe
difference of, e.g., an expected argument value to an observed one.
Line14showsthatweapplya SemanticHelper torunourseman-
tics and to retrieve a success or an error message. If the semantics
was executed successful then the model is valid and the algorithm
stops (Line 16). If an error occurs during the execution, we check ifitoriginatesfromthesamelayerasapreviouserror,andifitismoreseverethanthelasterror(basedonthebadnessvalue),whichwould
indicatethatthelastmodelchangedidnotimprovethemodel.In
this case, we restore the last model (Line 18). Otherwise, we try
to adoptthe modelto graduallyimprove itsvalidity (Lines21–32).
This is done by randomly selecting a potential model modification
forthelayerthatcausesinvalidity,likeregeneratingarguments,in-sertingalayertochangetheinputshapes/dimensions,orreplacingthe layer with one of its input layers. This process is repeated until
a valid model is found or a maximum number of tries is reached.
An example graph model that was generated with our approach
is illustrated in Fig. 3. The nodes in the model represent layers and
Figure 3: Model visualisation in graph form.
thearrowsshowthedataflow.Itcanbeseenthatthemodelincludes
various layers, like convolutional or reshape, and the output of
themodelisderivedfromtherootlayer,i.e.thataveragelayerat
thebottom.Thecorresponding TensorFlowandPrologmodelare
available online in our repository [10].
3.3 Model Validation
Another application of our semantics is the model validation by
identifying bugs in faulty (or invalid) AI models. It can be chal-
lenging to create working models, especially since the layers have
numerous preconditions that need to be fulfilled when they areusedorcombined.Forexample,commonerrorsarewronginput
shapes and dimensions, or arguments that are invalid for the input
data, like a convolution kernel or an axis value that is too large for
an input dimensions [ 27,45]. AI libraries, like TensorFlow, already
produce error message to detect such issues. However, they can
be difficult to understand, the messages are not always consistent
for the same type of issue, and in rare cases there is no error for
aproblematicmodel(seetheexamplebelow).Hence,weprovide
an alternative way to validate models by identifying and reporting
issues precisely and consistently with the help of our semantics.
By converting an existing TensorFlow model into our Prolog repre-
sentation, we can exploit our semantics to check if there are any
precondition violations in the model, which would make it invalid.
An example precondition is shown in Listing 5. It checks if a
croppinglayerappliestoomuchcropping,whichwouldresultin
anemptyoutput.Thereisapredicate check_empty_cropping that
hasthelayerinputandoutputasargumentsanditistruewhenthe
output is not empty. Otherwise, an exception is thrown. First, in
Lines1–2thereisarecursiverulefortheinspectionofmultidimen-
sionaloutput.Next,theruleinLine3makesourpredicatetrue,if
anynumericalvalueisfoundintheoutput.Ifthatisnotthecase,
then we generate an error message Lines 4–7.
865
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:19:35 UTC from IEEE Xplore.  Restrictions apply. ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Richard Schumi and Jun Sun
1check_empty_cropping(Is, [O|_]) :-
2check_empty_cropping(Is,O).
3check_empty_cropping(_,O) :- number(O).
4check_empty_cropping(Is ,[]) :-
5writeln( "Invalid Model" ), S1="Cropping Error, Input Shape " ,
6shape(Is,Shape),term_string(Shape,T),string_concat(S1,T,S),
7throw(S).
Listing 5: Prolog code of a layer precondition.
1 import tensorflow as tf, numpy as np
2 fromtensorflow.keras import layers, m odels
3
4in0 = tf.keras.layers.Input(shape=([2, 2]))
5in1 = tf.keras.layers.Input(shape=([2, 2]))
6Max = layers.MaxPool1D( pool_size =(1), name = 'Max')(in0)
7Con = layers.Conv1D(2 ,(1),padding= 'valid' ,name='Con')(in1)
8Cro = layers.Cropping1D(cropping=((5, 5)), name = 'Cro')(Con)
9Con1 = layers.C oncatenate( axis=1, name = 'Con1')([Max,Cro])
10
11model = models.Model(inputs=[in0,in1], outputs=Con1)
12
13w = model.get_layer( 'Con').get_weights()
14w[0] = np.array([[[0.572, 0.621], [0.5388, 0.5741]]])
15w[1] = np.array([0, 0])
16model.get_layer( 'Con').set_weights(w)
17in0 = tf.constant([[[1.313, 1.02], [1.45, 1.92]]])
18in1 = tf.constant([[[ 0.9421, 0.7879], [0 .809,0.855]]])
19 print(np.array2string(model.predict([in0,in1],steps=1)))
Listing 6: Simple example model bug in a TensorFlow.
An example TensorFlow model that contains a corresponding
cropping issue is shown in Listing 6. It can be seen that our model
consists of four layers, a convolutional layer that is connected
with a cropping layer, a maximum pool layer, and a concatenate
layer that takes the outputs of the cropping and pool layers. The
same model in Prolog is shown in Listing 7. This model has a
slightly different structure as our previous model queries. First, we
assign the layers to variables, which we then pass in a list to the
exec_layers function. Thisfunction is asimple wrapperfor the
execution of a list of layers that helps to identify the name of a
layer that violates a precondition.
Themodelmightseemvalidatafirstglance,butinvestigating
the cropping arguments shows that the values are too big. Thiscauses an empty intermediate output in the cropping layer. Ex-
pectedly,oursemanticsisabletoidentifythisissueandproduces
anerror.TensorFlowhasnoerrormessage[ 5].Themodelisjust
executed, and the concatenation is performed with the empty out-
put,which meansthatthefirst branchofthe modeliscompletely
ignored. Especially in large models, it can be challenging to findsuchissuessinceonlyintermediateresultsrevealsuchproblems.
The TensorFlow developers confirmed that this should not happen
and that an additional check will be added [5].
Our semantics are not only important for the test generation,
but they also enable a reliable way to identify issues in AI models.
Error messages in AI libraries are not always consistent becauseof multiple (or device-specific) implementations of a layer. Our
preconditionsareeasytodefine andcanspeed uptheidentification
of issues by highlighting problematic layers and by presenting con-
sistent messages that could, e.g., support automatic error handling.
In future work, we aim to provide a more user friendly tool with a
graphical user interface in order to facilitate the usage of both our1A = max_pool1D_layer ([[[1.313,1.02],[1.45,1.92]]],1,1,false,
Max),
2B = conv1D_layer([[[0.9421,0.7879],[0.809,0.855]]],1,[[[0.572,
0.621],[0.5388, 0.5741]]],[0,0], 1, false, 1, Con),
3C = cropping1D_layer(Con, 5, 5, Cro),
4D = concatenate_layer([Max,Cro], 1, Con1),
5 exec_layers ([A,B,C,D],[ "Max","Con","Cro","Con1"],Con1, "Con1")
Listing 7: Simple example model bug in a Prolog.
testcasegenerationandmodelvalidationapproachesinapracticalsetting,e.g,toproducetestmodelsforvariouspurposesandtofind
issues with existing models.
4 EVALUATION
We implemented our semantics for almost all TensorFlow layers
anddevelopedtwoexampleapplications,i.e.,AIframeworktesting,
and model validation to find invalid AI models. In this section, we
evaluate the effectiveness of the approaches. We design multiple
experiments to answer the following research questions (RQ).
•RQ1: Is Prolog expressive and efficient enough for AI semantics
analysis? Therearevariousspecificationlanguagesthatmight
besuitedfordevelopingasemanticsofanAIframework.Hence,
we want to highlight the advantages of using Prolog.
•RQ2:DoesthesemanticsallowustoeffectivelygeneratevalidAI
test cases? This is important since one of the applications of our
semanticsisAIframeworktestingandforthatitisnecessaryto
produce good test models.
•RQ3:Isourtestgenerationmethodbasedonthesemanticseffective
for finding AI framework bugs? To further motivate the usage of
our testing method, we show what bugs and issues it can reveal.
•RQ4:HowwellcanoursemanticsreportbugsofinvalidAImodels?
Another application of our semantics is the model validation.
We will show the advantages of our method compared with the
default bug reporting capabilities of TensorFlow.
The experiments were performed on a 7th Gen. Lenovo X1 Carbon
ThinkPad with a 8th Gen i7 CPU with four 1.80 GHz cores and
16GBRAM.We mainlytestedTensorFlow2.4, butalsodiscovered
issues in version 1.14. For executing the Prolog semantics, we used
SWI-Prolog 8.2.1 and the test generator was built in Java 13.0.7.
Below are our answers to the research questions.
RQ1:IsPrologexpressiveandefficientenoughforAIsemanticsanal-
ysis?Inordertoanswerthisquestion,wereportourfindingson
developingourPrologsemantics.FromtheTensorFlowdocumen-
tation [19], we identified 79 unique non-abstract and non-wrapper
layersthatwewantedtoimplement.Forpracticalreasons,wecouldnotsupportalllayers,butwewereabletodevelopourspecificationfor72layersofvarioustypes,likemathematical,normalisation,con-
volutional, recurrent, pooling, dense, activation, cropping, padding,
dropout,andmostoftheselayerssupportnearlyallarguments.We
implemented the core functionality of these layers to be able to
perform predictions. Our specification is not concerned with learn-
ing/trainingalgorithms,datapreprocessingandmodel(accuracy)
evaluations or optimisations. A full list of the layers is availableonline [
10]. We did not develop a specification for the remain-
ing 7 layers (ActivityRegularization,AdditiveAttention, Attention,
DenseFeatures,Lambda,MultiHeadAttention,StackedRNNCells)
866
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:19:35 UTC from IEEE Xplore.  Restrictions apply. ExAIS: Executable AI Semantics ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
10 20 30 40 500.511.522.5
model size (number of layers)run time [s]
Figure 4: Run time of the semantics for rising model sizes.
since they have too generic or flexible input requirements, like a
generic iterable that can contain other layers, or arbitrary func-tions or queries. Moreover, we could not fully support all layerargumentsandfeatures,e.g.,weimplementedtheMaskinglayeras a stand-alone layer, but not the influencing behaviour that itcan have on other layers. We had to omit some layer argumentssince they would have violated our specification requirement of
staticweights,i.e.,thereareinitialisers,regularisers(forweights,
kernels, or biases) that we did not implement since we statically
set these attributes. Moreover, we did not implement activation or
dropout features within the layers since the same behaviour can
be achieved by adding an independent activation, or dropout layer.
We left out some arguments, like constraints, data formats, or a
trainableoption,duetotheircomplexityorbecausetheyhavean
influenceoutsidethescopeofoursemanticswhichisnotconcerned
with the training of AI models. Some layers, like GRU, have an op-
tiontochooseaspecificimplementationofthelayer.Forsimplicity,
weimplementedthedefaultimplementations.Itshouldbenoted
that only seven layers had detailed (mathematical) descriptions
inthedocumentation,44wereexplainedwithexamplesorhada
reference paper, and the remaining 21 layers were under-specified
orhadjustverylimitedexamples.Fromour72implementedlayers,
seven had non-deterministic properties, hence instead of exactlyspecifying their behaviour, we defined Prolog rules that check if
theyfollowthedescribedpropertiesfromthedocumentationsas
explained in Sect. 2. For the remaining 65 layers, we directly speci-
fiedthefunctionality,whichenablesaneasyexecutionandanexact
comparison of the prediction results from our semantics to Tensor-
Flow. The implementation effort of the semantics was about eight
work months, which partially also includes the time to acquire the
relevant domain knowledge.
We evaluated the execution time of our semantics in order to
illustrate the applicability for non-trivial use cases. Figure 4 shows
the achievedrun timesfor increasingmodel sizes.We createdthe
modelsbyadoptingthelevelvariableofthetestgenerationfrom
Algorithm1,bysettingtheinputdatasizeto4KB,andbytakingthe
averageovertenmodelsforeachdatapoint.Itcanbeseen,thatfor
small modelswith aboutten layersand non-trivialinputs therun
time of the semantics is only about 0.6s, and even for models with
about50layers,apredictioncanbedoneinlessthan3s.Hence,we
believe our semantics is fast enough for reasonable models.
A major advantage of using Prolog is its declarative and high-
levelspecificationstyle,whichenablesacompactandstraightfor-
ward implementation. We only needed about 3200 lines of code for
all 72 layers, and on average 44 lines per layer, because Prolog has
alreadyalotofbuilt-infunctionality,likelistoperations,anditalso
facilitates the reuse of code. In contrast, TensorFlow has a hugeTable 1: Found TensorFlow issues and bugs.
Issue TypeFixed or
ConfirmedPending or
UnconfirmedTotal
TensorFlow bugs 2 1 3
Error message bugs 4 2 6
Documentation bugs 4 1 5
Total 10 4 14
code base with about three million lines of code. Hence, we believe
our specification provides a good opportunity to AI developers to
learn more about the inner workings of layers, and that Prolog is a
well suited specification language since it supports a compact and
convenient implementationof most layers.
RQ2:DoesthesemanticsallowustoeffectivelygeneratevalidAItest
cases?In order to evaluate the effectiveness of our test generation
approach,weusedourtestgeneratortoproduce10,000testmodels.
The run time of the generation was about 35 hours (on average
12.6spermodel),ofwhichmosttimewasspentongraduallyfinding
a valid model with feedback information from the execution of the
semantics. Our generated AI models had an average size of 9.89layers (excluding input layers), and we used small inputs with a
range of one to four values per dimension since bigger sizes vastly
increased the overall size of our highly dimensional input data.
Compared to state-of-the-art approaches for testing AI frame-
works,ourgeneratedmodelshavemorediversityintermsoflayers
andstructure.Arelatedfuzzingmethod[ 29]onlytestssinglelayers
anditisunclearhowmanylayersitcantestwithvalidinputs.A
differential testing approach [ 43] can produce valid models with
mutation, but they are less diverse since the mutations are only
concernedwithsequentialmodelaspects,andtheycanonlyadd24
types of layers to the mutants. Other related approaches have less
variety since they only use existing models or adopt the input data.
Outofthe10,000testcases99.1%werevalid,i.e.wewereableto
producethesamepredictionresultwithoursemanticsasTensor-
Flowforthesamemodelandinputs.Seventestcasesfailedbecause
of a dependency issue of the Masking layer [ 14] that we could not
fully support. (Almost all layers work independently, but the Mask-
inglayerisanexception.Itrequiresallfollowinglayerstoskipa
specific input time step.) Two tests failed due to rare inputs which
causedinconsistencieswiththeTensorFlowinputargumentchecks.
Wearestillinvestigatingthisissuebecauseofitsrareoccurrence.
Finally, one test failed due to a minor inconstancy in the handling
offloating-pointvalues,whichonlyoccurredveryrarelywhena
lot of computations with recurrent layers were performed.
The high percentage of valid AI models that we were able to
achieve with our test case generation shows that our method iseffective, especially considering the low percentage (25%) of the
related work [ 29]. Moreover, we were able to reveal various issues
andbugsaswewillseeintheanswertothenextresearchquestions.
RQ3:Isourtestgenerationmethodbasedonthesemanticseffective
forfindingAIframeworkbugs? Withourgeneratedtestcases,we
were able to discover various issues and bugs in TensorFlow. Some
ofwhichwereactualfaultsinTensorFlow,afewissueswererelated
to wrong or misleading error messages, and there were some doc-
umentationbugs.Table1showsanoverviewofthefoundissues,
their type, and if they were confirmed or not.
867
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:19:35 UTC from IEEE Xplore.  Restrictions apply. ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Richard Schumi and Jun Sun
The most interesting bug that we found was related to the pop-
ular activation function (or layer) called ReLU, which showed a
wrong behaviour for negative thresholds that violated the descrip-
tionofthedocumentation[ 15].Webelievethatthisbugisthemost
significantsince itisconcernedwith oneofthemost commonac-
tivation functions, and AI models that used this function with a
negative threshold (and negative) values might have suffered from
inaccuracy ormight have produced unexpectedprediction results.
Another bug was regarding the ConvLSTM2D layer, which pro-
duced potentially wrong prediction results in rare cases [ 4], and
one was an ignored argument [11].
Anissuewasregardinganerrormessagethatsuggestedthatan-
othernumberformatisrequired,butwhentheformatwaschanged
thenthemessagestatedtheoriginalformatwasneeded[ 12].There
were various similar error message related issues [3, 5, 9, 17, 20].
A documentation bug was about a missing preconditions de-
scription that caused an error when certain arguments were notequal in a SeparableConv layer [
16]. A number of similar issues
[1, 7, 13, 18] were also related to documentation inconsistencies.
In total, we found 14 issues that we reported to the TensorFlow
developersandthathelpedtoimprovetheframework.Tenissues
wereconfirmedorarealreadyfixed,fourareunconfirmedorstill
pending. Note that our method focuses on semantic bugs, like the
ReLUbug[ 15],thatarehardertofind.Relatedworkcannotdirectly
becomparedduetosimplertypesoforacles,whichwewillexplain
in Sect.5. Hence,we believe itis reasonableeffective, andthe fact
thatwefoundamajorbuginoneofthemostcommonactivation
layers highlights the need for a good executable semantics.
RQ4:HowwellcanoursemanticsreportbugsofinvalidAImodels?
In order to evaluate the bug finding or localisation capabilitiesof our semantics, we generated 100 invalid models by running
our test case generation method that gradually finds valid models.
Retrieving the last model of this process allowed us to have invalidmodels that only contain a single bug, which facilitates the manual
analysis of the issues. We evaluated the type of issues that madethe models invalid and compared the bug finding and reporting
capabilities of our semantics to TensorFlow.
Table2showsanoverviewofthetypesandfrequenciesofissues,
and the number of TensorFlow inconsistencies that we found. The
majority(57)ofthemodelswereinvalidduetodimensionerrors
caused by layers requiring input data with a maximum, minimum
orspecificdimension,orwhenalayerhasmultipleinputsandtheir
dimensions are not matching. The next large portion, 29 models
wereinvalidduetoinconsistentinputdatathatoccurswhenalayer
takesmultipleinputsandthereisarequirementthattheinputsneed
tobethesameshapeorthesizeofsomedimensionsmustmatch.
The remaining 14 models were invalid due to argument errors, like
apool orkernelsize thatistoo large,or inconsistenciesinweight
(or biases) shapes. Most convolutional layers require weight arrays
tohaveaspecificshapethatcandependontheinputsize.Hence,a
modelcan,e.g.,becomeinvalidwhentheshapeoftheweightsis
inconsistent with the input shape.
Many error messages from TensorFlow were inconsistent as
indicated in the last column of Table 2. Even for simple cases like a
wrong input dimension, there are different messages (“ValueError:
Input 0 of layer X is incompatible with the layer: expected ndim=5,Table 2: Overview of the identified model validation issues.
Model Issue OccurrencesTensorFlow
Inconsistencies
Dimension Error 57 5
Inconsistent Input Shapes 29 2
Argument Error 14 3
found ndim=3.” or “ValueError: Shape must be rank 4 but is rank 5
forX.”or“ValueError:Inputsshouldhaverank4.Receivedinput
shape ...”). The reason for these differences might be that the
error messagesare produced independentlyin differentlayers. In
contrast,wecaneasilyreuseapreconditionthatproducesthesame
message in all layers. This facilitates automatic error processing.
There were cases in which TensorFlow did not produce an error,
althoughthereshouldbeone.Forexample,whencroppinglayers
are used with a too large cropping values, then TensorFlow will
justproduceanemptyoutput[ 5](moredetailsareinSect.3.3).A
similar issue was regarding the input shape verification that did
not occur with specific prediction methods [9].
SameasTensorFlow,oursemanticswasabletoidentifythelayers
that were causing an invalid model in all cases. In four cases, there
were discrepancies regarding the type of error. The reason for that
issimple.Someissuescanhavemultiplecauses,e.g.,whenaweight
shape is inconsistent with an input, then either of them may be
wrong.Generally,ourproducedmessagesaresimpler,consistent,
andatahighlevel.Tobefair,TensorFlow’serrormessagescould
beattimesmoredetailed(forbetterdebugging),butourfocusisonautomaticerrorhandling.Notethatthereseemstobenootherwork
investigatingTensorFlow’serrormessagesforAImodels.Finally,
withourapproachitismucheasiertoaddpreconditionsforspecial
usecasesortypesoflayerssincethecodeismuchmorecompact,
which makes it easy to find the right place to add a precondition.
Discussion. Athreattothevalidityofourevaluationmightbe
that there are limited ways that we can compare with existing
works. This might have been interesting. However, there were not
manyrelatedapproachesthatcouldbeusedforafaircomparison
since the closest related work for generating AI models worked
with a much weaker oracle and only focused on simpler bugs.
One might argue that our AI framework semantics is limited
sinceitismostlyconcernedwiththebehaviouroflayers.AIframe-
works have other important components, e.g., it would be inter-
esting to specify the learning algorithms. However, in this work
wefocusedonthestaticbehaviouroflayerssincewebelieveitis
a good start for more general AI framework semantics, and our
specificationisvaluablesinceitcanperformpredictionsforvariouscomplexAImodels.Moreover,weillustratedhownon-deterministic
properties can be evaluated with Prolog.
Anotherpotentialthreattothevalidityofourevaluationcouldbe
thatthe testinputs weused togenerate AImodelswere toosmall
for a realistic study. AI models can handle huge data like largeimages or videos. Hence, it is true that an evaluation with larger
test inputs might be more realistic, but bugs in the AI frameworks
as well as in AI models could be independent of the input size.
We believe that our test models with rather small inputs were still
reasonable and did not represent a big limitation. Moreover, it is
well-known that small test cases can reveal various bugs [28].
868
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:19:35 UTC from IEEE Xplore.  Restrictions apply. ExAIS: Executable AI Semantics ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
Onemightarguethatourmodelvalidationapproachisnotas
useful as TensorFlow’s bug reporting capabilities. It is true that the
produced error messages from TensorFlow are more sophisticated,
and they might be better for debugging. However, our goal was
to produce simple and consistent error messages that can be used
for applications such as automatic error handling or even model
repair. Moreover, we wanted to provide an easy way to add new
preconditionsandreportingcapabilities,whichcanbehelpfulsince
not all model issues were identified by TensorFlow.
5 RELATED WORK
Executable semantics for programming languages are related to
our work because AI libraries have a similar purpose as a compiler.
For example, there are various executable semantics for popular
programminglanguagesthatwerebuildwiththeKframework[ 35].
InthesamewayasourAIframeworkspecification,suchsemanticscanbeusedasastrongtestoracleandfacilitatethetestgeneration.
ArelatedapproachthatalsoworkswithAIspecificationswas
presented by Selsam et al. [ 38]. The authors apply an interactive
proofing tool and partial synthesis of some system components to
construct an AI system and to prove its correctness. Such a system
can also be seen as a formal specification similar to ours since it
canbeusedtodetectbugs.However,inthisworktheauthorsfocus
more on an alternative (library) implementation that is correct by
design, andthey only focuson a limitedAI system. Moreover,the
authors point out that their proof relies on an idealised setting
withinfinite-precisionrealnumbersthatarereplacedforaconcrete
execution, which can be a potential source for bugs.
The closest related work to our testing approach was presented
by Wang et al. [ 43]. The authors show a differential testing ap-
proach called LEMON that uses mutations to produce test cases,
anditappliesaheuristic strategytoguidethegenerationinorder
to amplify inconsistencies between different DL libraries. Theydo this to get rid of noise introduced by non-determinism in DL
libraries.Withourapproach,wecandirectlytestmanylibrarycom-
ponentsdeterministically,whichmakestheidentificationofbugs
much easier. Moreover, we do not have to rely on the existenceof other libraries. Our semantics can also be used to test newlydeveloped features that are only provided by a single library. A
similarapproachcalledCRADLEwaspresentedbyPhametal.[ 33].
CRADLE alsoperforms differential testing,and itapplies distance
metrics to detect inconsistent outputs. It localises the source of an
inconsistencybytrackingandanalysinganomaliesintheexecution
graph. Similarly, Srisakaokul et al. [ 41] show a differential method
for supervised learningsoftware and demonstrateit for k-Nearest
Neighbour and Naive Bayes implementations.
ArelatedfuzzingmethodwasillustratedbyLi[ 29].Theapproach
relies on extracting information from AI library documentations to
find input requirements of deep learning layers, which are needed
to generate testdata. In contrast toour work, thismethod only has
verylimitedcapabilitiestoproducevalidtests(about25%)andtheir
oracle can only detect documentation bugs or input violations.
Dwarakanath et al.[ 23] have developed new metamorphic re-
lationsformetamorphictestingofAIlibraries.Forexample,they
perform permutations, rearrangements, or rotations of the input
datathatshouldnotchangetheoutput.Then,theyidentifybugsbased on unexpected changes in the output. They evaluate theirmethod by artificially introducing bugs into image classificationsystems. A similar metamorphic method for validation was pre-
sented by Ding et al. [ 22]. The approach works with metamorphic
relationsthat,e.g.,add(orremove)imagesorimagecategoriesto
the training, test or validation data. They also work with image
classifiers.Anothermetamorphicmethodthatpermutatesrowsand
columns,shufflesandrenamesinputfeaturesinordertoevaluate
the balancedness of machine learning classifiers was introducedby Sharma and Wehrheim [
40]. In contrast to these approaches,
oursemanticswillworkwithmuchmoreAIapplications,andits
strong oracle supports the detection of a wider range of bugs.
Related to our model validation method are some debugging
approaches [ 26,37,42] for AI models that offer features like visual-
isation or auditing, to find issues. However, such approaches are
usuallylimitedtospecifictypesofmodels,e.g.,classifiers,andtheir
focus is not on introducing custom validation options.
6 CONCLUSION
WehaveintroducedanovelexecutablesemanticsforAIframeworks
andillustratedtwoofitsapplications.Oursemanticsisimplemented
in Prolog and it focuses on the deterministic behaviour of deep
learning layers. With Prolog, we could develop almost all layers of
TensorFlow in a convenient and compact specification style.
One major application of our semantics is the automatic genera-
tion of test AI models. We applied a fuzzing approach that incorpo-
ratesfeedbackfromthesemanticstograduallyfindvalidmodels.
Theapproachwasabletoconsistentlyproducevalidmodelsin99%
of the cases, which is much higher than related approaches. More-
over,weevaluated theeffectivenessof thismethodfor findingAI
framework bugs, and the results were encouraging. We discovered
variousissuesandbugsinTensorFlowandcouldtherebyhelpto
improve this AI framework. Most notably, we even found a bug in
the well-established ReLU function.
Another application that we presented is the validation of deep
learningmodels.Oursemanticsisbuildwithvariouspreconditions
that can find bugs in invalid AI models. The evaluation showed
thatwecanproduceconsistenterrormessages,andwewereable
to identify issues that could not be discovered by TensorFlow.
Webelievethatthesetwoapproacheshighlighttheusefulness
and generality of our semantics, which will also enable further ap-
plications.Inthefuture,weaimtoexploredifferenttestgeneration
methods and AI model synthesis.
Acknowledgments. This project is supported by the National Re-
searchFoundation,SingaporeandNationalUniversityofSingapore
through its National Satellite of Excellence in Trustworthy Soft-
ware Systems(NSOE-TSS)office underthe Trustworthy Software
Systems – Core Technologies Grant (TSSCTG) award no. NSOE-
TSS2019-03.
Any opinions, findings and conclusions or recommendations
expressed in this material are those of the author(s) and do not
reflecttheviewsofNationalResearchFoundation,Singaporeand
NationalUniversityofSingapore(includingitsNationalSatelliteof
Excellence in Trustworthy Software Systems (NSOE-TSS) office).
Additionally, we would like to thank Mengdi Zhang and Ayesha
Sadiq for their help with some experiments of this work.
869
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:19:35 UTC from IEEE Xplore.  Restrictions apply. ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Richard Schumi and Jun Sun
REFERENCES
[1]2020. Wrong default value in GRU layer documentaion. https://github.com/
tensorflow/tensorflow/issues/45705
[2]2021. 1DConvolution Layer. https://www.tensorflow.org/api_docs/python/tf/
keras/layers/Conv1D
[3]2021. AveragePooling3D does not support float64 and produces confusing error
message. https://github.com/tensorflow/tensorflow/issues/48644
[4]2021. ConvLSTM2D layer wrong computation. https://github.com/keras-
team/keras/issues/15224
[5]2021. cropping layeradditional error message. https://github.com/tensorflow/
tensorflow/issues/50612
[6]2021. Dense Layer. https://www.tensorflow.org/api_docs/python/tf/keras/
layers/Dense
[7]2021. Dot layer incomplete description. https://github.com/tensorflow/
tensorflow/issues/45706
[8]2021. Dropout Layer. https://www.tensorflow.org/api_docs/python/tf/keras/
layers/Dropout
[9]2021. error reporting model(x) vs model.predict(x). https://github.com/
tensorflow/tensorflow/issues/50618
[10]2021. ExAIS:ExecutableAISemanticsRepository. https://github.com/rschumi0/
ExAIS
[11]2021. InputSpecargumentignored. https://github.com/keras-team/keras/issues/
15225
[12]2021. InputSpec missing float64 support and wrong error message. https:
//github.com/keras-team/keras/issues/15226
[13]2021. layerorderinfunctionalAPIgraphmodels. https://github.com/tensorflow/
tensorflow/issues/50306
[14]2021. Masking Layer. https://www.tensorflow.org/api_docs/python/tf/keras/
layers/Masking
[15]2021. ReLU layer wrong result with negative threshold. https://github.com/
tensorflow/tensorflow/issues/48646
[16]2021. SeparableConv documention missing argument constraint. https://github.
com/tensorflow/tensorflow/issues/45259
[17]2021. Softmaxlayerunexpectedandconfusingerrormessage. https://github.
com/tensorflow/tensorflow/issues/50467
[18]2021. Softmax layer unexpected behaviour for axis=0. https://github.com/
tensorflow/tensorflow/issues/48647
[19]2021. TensorFlow layer documentation. https://www.tensorflow.org/api_docs/
python/tf/keras/layers
[20]2021. Wrong error message for DepthwiseConv2D. https://github.com/
tensorflow/tensorflow/issues/45703
[21]Max Bramer. 2013. Logic Programming with Prolog. Springer. https://doi.org/10.
1007/978-1-4471-5487-7
[22]Junhua Ding, Xiaojun Kang, and Xin-Hua Hu. 2017. Validating a Deep Learning
FrameworkbyMetamorphicTesting.In 2ndIEEE/ACMInternationalWorkshop
onMetamorphic Testing, MET@ICSE2017,BuenosAires, Argentina,May22,2017.
IEEE Computer Society, 28–34. https://doi.org/10.1109/MET.2017.2
[23]Anurag Dwarakanath, Manish Ahuja, Samarth Sikand, Raghotham M. Rao,
R.P.JagadeeshChandraBose,NevilleDubash,andSanjayPodder.2018. Iden-tifying implementation bugs in machine learning based image classifiers us-ing metamorphic testing. In Proceedings of the 27th ACM SIGSOFT Interna-
tional Symposium on Software Testing and Analysis, ISSTA 2018, Amsterdam, The
Netherlands,July16-21,2018,FrankTipandEricBodden(Eds.).ACM,118–128.
https://doi.org/10.1145/3213846.3213858
[24]ThomasMichaelFehlmann.2020. AutonomousReal-TimeTesting:TestingArtificial
Intelligence and Other Complex Systems. Logos Verlag Berlin GmbH.
[25]Mark Harman, Phil McMinn, Jerffeson Teixeira de Souza, and Shin Yoo. 2010.
SearchBasedSoftwareEngineering:Techniques,Taxonomy,Tutorial.In Empirical
Software Engineering and Verification - International Summer Schools, LASER
2008-2010, Elba Island, Italy, Revised Tutorial Lectures (Lecture Notes in Computer
Science), Bertrand Meyer and Martin Nordio (Eds.), Vol. 7007. Springer, 1–59.
https://doi.org/10.1007/978-3-642-25231-0_1
[26]FredHohman,MinsukKahng,RobertPienta,andDuenHorngChau.2019. Visual
AnalyticsinDeepLearning:AnInterrogativeSurveyfortheNextFrontiers. IEEE
Trans.Vis.Comput.Graph. 25,8(2019),2674–2693. https://doi.org/10.1109/TVCG.
2018.2843369
[27]NargizHumbatova,GunelJahangirova,GabrieleBavota,VincenzoRiccio,AndreaStocco,andPaoloTonella.2020. Taxonomyofrealfaultsindeeplearningsystems.
InICSE’20:42ndInternationalConferenceonSoftwareEngineering,Seoul,South
Korea, 27 June - 19 July, 2020, Gregg Rothermel and Doo-Hwan Bae (Eds.). ACM,
1110–1121. https://doi.org/10.1145/3377811.3380395[28]Daniel Jackson and Craig Damon. 1996. Elements of Style: Analyzing a Software
Design Feature with a Counterexample Detector. In Proceedings of the 1996 Inter-
national Symposium on Software Testing and Analysis, ISSTA 1996, San Diego, CA,
USA, January 8-10, 1996. ACM, 239–249. https://doi.org/10.1145/229000.226322
[29]Yitong Li. 2020. Documentation-Guided Fuzzing for Testing Deep Learning API
Functions. Master’s thesis. University of Waterloo.
[30]Lei Ma, Fuyuan Zhang, Minhui Xue, Bo Li, Yang Liu, Jianjun Zhao, and
YadongWang.2018. CombinatorialTestingforDeepLearningSystems. CoRR
abs/1806.07723(2018). http://arxiv.org/abs/1806.07723
[31]MahdiNejadgholiandJinqiuYang.2019. AStudyofOracleApproximationsin
TestingDeepLearningLibraries.In 34thIEEE/ACMInternationalConferenceon
Automated Software Engineering, ASE 2019, San Diego, CA, USA, November 11-15,
2019. IEEE, 785–796. https://doi.org/10.1109/ASE.2019.00078
[32]UlfNilssonandJanMałuszyński.1990. Logic,programmingandProlog. Wiley
Chichester.
[33]HungVietPham,ThibaudLutellier,WeizhenQi,andLinTan.2019. CRADLE:
cross-backendvalidationtodetectandlocalizebugsindeeplearninglibraries.InProceedingsofthe41stInternationalConferenceonSoftwareEngineering,ICSE2019,
Montreal, QC, Canada, May 25-31, 2019, Joanne M. Atlee, Tevfik Bultan, and Jon
Whittle (Eds.). IEEE / ACM, 1027–1038. https://doi.org/10.1109/ICSE.2019.00107
[34]SamiraPouyanfar,SaadSadiq,YilinYan,HaimanTian,YudongTao,MariaE.Presa
Reyes, Mei-Ling Shyu, Shu-Ching Chen, and S. S. Iyengar. 2019. A Survey on
DeepLearning:Algorithms,Techniques,andApplications. ACMComput.Surv.
51, 5 (2019), 92:1–92:36. https://doi.org/10.1145/3234150
[35]Grigore Rosu and Traian-Florin Serbanuta. 2010. An overview of the K semantic
framework. J. Log. Algebraic Methods Program. 79, 6 (2010), 397–434. https:
//doi.org/10.1016/j.jlap.2010.03.012
[36]Jürgen Schmidhuber. 2015. Deep learning in neural networks: An overview.
Neural Networks 61 (2015), 85–117. https://doi.org/10.1016/j.neunet.2014.09.003
[37]EldonSchoop,ForrestHuang,andBjoernHartmann.2021. UMLAUT:Debugging
DeepLearningProgramsusingProgramStructureandModelBehavior.In CHI
’21: CHI Conference on Human Factors in Computing Systems, Virtual Event /
Yokohama,Japan,May8-13,2021,YoshifumiKitamura,AaronQuigley,Katherine
Isbister,TakeoIgarashi,PernilleBjørn,andStevenMarkDrucker(Eds.).ACM,
310:1–310:16. https://doi.org/10.1145/3411764.3445538
[38]DanielSelsam,PercyLiang,andDavidL.Dill.2017. DevelopingBug-FreeMa-
chine Learning Systems With Formal Mathematics. In Proceedings of the 34th
InternationalConferenceonMachineLearning,ICML2017,Sydney,NSW,Australia,
6-11 August 2017 (Proceedings of Machine Learning Research), Doina Precup and
YeeWhyeTeh(Eds.),Vol.70.PMLR,3047–3056. http://proceedings.mlr.press/
v70/selsam17a.html
[39]Traian-Florin Serbanuta, Grigore Rosu, and José Meseguer. 2009. A rewritinglogic approach to operational semantics. Inf. Comput. 207, 2 (2009), 305–340.
https://doi.org/10.1016/j.ic.2008.03.026
[40]ArnabSharmaandHeikeWehrheim.2019. TestingMachineLearningAlgorithms
for Balanced Data Usage. In 12th IEEE Conference on Software Testing, Validation
and Verification, ICST 2019, Xi’an, China, April 22-27, 2019. IEEE, 125–135. https:
//doi.org/10.1109/ICST.2019.00022
[41]Siwakorn Srisakaokul, Zhengkai Wu, Angello Astorga, Oreoluwa Alebiosu, and
Tao Xie. 2018. Multiple-Implementation Testing of Supervised Learning Soft-
ware.InTheWorkshopsoftheTheThirty-SecondAAAIConferenceonArtificial
Intelligence, NewOrleans,Louisiana, USA,February 2-7,2018 (AAAI Workshops),
Vol.WS-18.AAAIPress,384–391. https://aaai.org/ocs/index.php/WS/AAAIW18/
paper/view/17301
[42]HendrikStrobelt,SebastianGehrmann,MichaelBehrisch,AdamPerer,Hanspeter
Pfister, and Alexander M. Rush. 2019. Seq2seq-Vis: A Visual Debugging Tool
for Sequence-to-Sequence Models. IEEE Trans. Vis. Comput. Graph. 25, 1 (2019),
353–363. https://doi.org/10.1109/TVCG.2018.2865044
[43]ZanWang, MingYan,Junjie Chen,ShuangLiu,and DongdiZhang.2020. Deep
learning library testing via effective model generation. In ESEC/FSE ’20: 28th
ACM Joint European Software Engineering Conference and Symposium on theFoundations of Software Engineering, Virtual Event, USA, November 8-13, 2020,
PremDevanbu,MyraB.Cohen,andThomasZimmermann(Eds.).ACM,788–799.
https://doi.org/10.1145/3368089.3409761
[44]Jie M. Zhang, Mark Harman, Lei Ma, and Yang Liu. 2019. Machine Learning
Testing: Survey, Landscapes and Horizons. CoRRabs/1906.10742 (2019). http:
//arxiv.org/abs/1906.10742
[45]YuhaoZhang,YifanChen,Shing-ChiCheung,YingfeiXiong,andLuZhang.2018.
AnempiricalstudyonTensorFlowprogrambugs.In Proceedingsofthe27thACM
SIGSOFTInternationalSymposiumonSoftwareTestingandAnalysis,ISSTA2018,
Amsterdam, The Netherlands, July 16-21, 2018, Frank Tip and Eric Bodden (Eds.).
ACM, 129–140. https://doi.org/10.1145/3213846.3213866
870
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:19:35 UTC from IEEE Xplore.  Restrictions apply. 