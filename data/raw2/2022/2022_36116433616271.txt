Copilotingthe Copilots:Fusing LargeLanguageModels with
Completion Engines forAutomated Program Repair
Yuxiang Wei
Universityof Illinois
Urbana-Champaign,USA
ywei40@illinois.eduChunqiuSteven Xia
Universityof Illinois
Urbana-Champaign,USA
chunqiu2@illinois.eduLingming Zhang
Universityof Illinois
Urbana-Champaign,USA
lingming@illinois.edu
ABSTRACT
During Automated Program Repair (APR), it can be challenging
to synthesize correct patches for real-world systems in general-
purposeprogramminglanguages.RecentLargeLanguageModels
(LLMs) have been shown to be helpful “copilots” in assisting de-
velopers with various coding tasks, and have also been directly
appliedforpatchsynthesis.However,mostLLMstreatprogramsas
sequencesoftokens,meaningthattheyareignorantoftheunderly-
ingsemanticsconstraintsofthetargetprogramminglanguage.This
resultsinplentyofstaticallyinvalidgeneratedpatches,impeding
thepracticalityofthetechnique.Therefore,we propose Repilot,a
general code generation framework to further copilot the AI “copi-
lots” (i.e., LLMs) by synthesizing more validpatches during the
repairprocess.OurkeyinsightisthatmanyLLMsproduceoutputs
autoregressively(i.e.,tokenbytoken),resemblinghuman writing
programs,whichcanbesigni/f_icantlyboostedandguidedthrougha
Completion Engine. Repilot synergistically synthesizes a candidate
patchthroughtheinteractionbetweenanLLMandaCompletion
Engine,which1)prunesawayinfeasibletokenssuggestedbythe
LLMand2)proactivelycompletesthetokenbasedonthesugges-
tions provided by the Completion Engine. Our evaluation on a
subset of the widely-used Defects4j 1.2 and 2.0 datasets shows that
Repilot outperforms state-of-the-art techniques by /f_ixing 27% and
47%morebugs,respectively.Moreover,Repilotproducesmorevalid
andcorrectpatchesthanthebaseLLMwiththesamebudget.While
we focus on leveraging Repilot for APR in this work, the overall
approach isalsogeneralizable to othercode generationtasks.
CCS CONCEPTS
•Softwareanditsengineering →Softwaretestinganddebug-
ging;Automatic programming .
KEYWORDS
Program Repair,LargeLanguageModel,CompletionEngine
ACMReference Format:
YuxiangWei,ChunqiuStevenXia,andLingmingZhang.2023.Copiloting
the Copilots: FusingLargeLanguage Models withCompletionEngines for
AutomatedProgramRepair.In Proceedingsofthe31stACMJointEuropean
Permissionto make digitalor hard copies of allorpart ofthis work for personalor
classroom use is granted without fee provided that copies are not made or distributed
forpro/f_itorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
onthe/f_irstpage.Copyrights forcomponentsofthisworkownedbyothersthanthe
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or
republish,topostonserversortoredistributetolists,requirespriorspeci/f_icpermission
and/or a fee. Request permissions from permissions@acm.org.
ESEC/FSE ’23, December 3–9, 2023, San Francisco, CA,USA
©2023 Copyright heldby the owner/author(s). Publicationrightslicensed to ACM.
ACM ISBN 979-8-4007-0327-0/23/12...$15.00
https://doi.org/10.1145/3611643.3616271Software Engineering Conference and Symposium on the Foundations of Soft-
wareEngineering(ESEC/FSE’23),December3–9,2023,SanFrancisco,CA,USA.
ACM,NewYork,NY,USA, 13pages.https://doi.org/10.1145/3611643.3616271
1 INTRODUCTION
Automated Program Repair (APR) seeks to reduce the manual bug-
/f_ixingeﬀortofdevelopersbyautomaticallysynthesizingpatches
given the original buggy code [ 20]. State-of-the-art traditional
APR tools are mainly based on handcrafted repair templates to
match the buggy code patterns and apply the corresponding code
changes [ 21,41]. Although outperforming other traditional tech-
niques [37,43,47], such tools can only /f_ixthe bug types within the
preset templates and cannot generalize to new bug types. With the
development of Deep Learning (DL) techniques, researchers build
learning-based APR [ 29,72,74] tools based on Neural Machine
Translation (NMT) [ 57] architecture. They train NMT models to
translate buggy code into correct code by learning from pairs of
buggyand/f_ixedcodescrapedfromopen-sourcecommits.However,
as discussed in prior work [ 67], the training sets of these tools can
be limitedinsize andalsocontain irrelevantornoisycommits.
Morerecently,researchershaveleveragedthegrowthinthe/f_ield
ofNLPtodirectlyuseLarge LanguageModels(LLMs)[ 10,17]for
APR[31,66,67].LLMsnotonlyachieveimpressiveperformanceon
manyNLPtasks[ 7],butarealsoshowntobereliable“copilots”1in
assistingdeveloperswithvariouscodingtasks[ 4,40].Thereason
isthatmodernLLMsoftenincludelargeamountsofavailableopen-
source code repositories as part of their training dataset. Recogniz-
ingthepowerofLLMs,researchershaverecentlyappliedLLMsfor
APR: instead of translating buggy code into correct code, LLMs are
directly used to synthesize the correct patch from the surrounding
context. AlphaRepair [ 67] reformulates the APR problem as a cloze
(orin/f_illing)task[ 2,19]: it/f_irst replacesthe buggycodesnippets
with masked tokens and then uses CodeBERT [ 17] to /f_ill correct
code ingiven the surrounding context. Otherstudies on LLMsfor
APRhaveappliedevenlargerLLMswithdiﬀerentrepairsettings
(includinggeneratingcomplete patch functions)[ 33,53,66].
While prior LLM for APR techniques achieve state-of-the-art
bug-/f_ixing performance, they use LLMs in a black-box manner,
where the underlying LLM generate programs according to theto-
ken distribution without any structural or semantic understanding
ofthecode.TohighlightthelimitationswithcurrentLLMsforAPR
tools, In Figure 1we show 3 scenarios where LLM can generate
incorrectpatches. 1Generatinginfeasibletokens .InFigure 1.1,
theLLMhasahighprobability(>90%)ofgenerating Stringtocom-
plete the asString method. However asString is not a valid /f_ield
accessfortheobject tandisalsonotpartofthescopeofthecurrent
1One popular AIpairprogrammer tool(based onCodex[ 10])is named Copilot[ 22].
172
ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA Yuxiang Wei, Chunqiu StevenXia,andLingming Zhang
String name = t.asEnd Tag
Name
Tag
16%
7%
…
asEndTag
!
 Hard to generate rare tokens2
final EndTag asEndTag () {…}
String name = t.asEndTag().
name 
normalName 
toString
name
 ! 50%
…toString
 6%
 No explicit consideration of types3
String name = t.as
asEndTag 
asStartTag 
asComment 
asDoctype 
asCharacter
! String
Name
 !
End
 !91%
0.2%3%
…Language model 
Predictions Completions
 Generating infeasible tokens1
Figure 1:Limitationsofexisting LLM-based APRapproaches.
buggy method. In this case, the patchs generated using asString
will never be correct as it cannot compile. By directly using the
model probabilities, LLMs are likely to generatemanypatchesus-
ing invalid tokens and decrease the likelihood of generating the
correctpatchwith End(0.2%). 2Hardtogenerateraretokens .
LLMs usually cannot generate a complete identi/f_ier name in one
stepsinceitusessubwordtokenization[ 55]tobreakuncommon
words into smaller subwords. These uncommon words manifest
asrareidenti/f_iersincode,whereidenti/f_iernamesareCamelCase
or underscore combinations of multiple words (e.g., asEndTag in
Figure1.2).Assuch,LLMsneedtogeneratetheseidenti/f_iersstep
by step, needing not only multiple iterations but also accurate out-
putineachstep.Sincepriorapproaches[ 33,66]samplebasedon
probability,thelikelihoodofcompletingararetokento/f_ixabug
can be extremelylow. 3No explicit consideration of types .In
addition topotentiallygeneratingout-of-scopeidenti/f_iers, LLMs
do nothave accesstovarioustype informationthat giveshints to
the valid identi/f_iers. In Figure 1.3, the return type of asEndTag() is
EndTag, whose de/f_inition is not explicitly given to the LLM in its
immediatecontext.Assuch,LLMsdonotknowthecorrectmem-
ber/f_ieldsof EndTagandmaygenerateinvalidpatchescontaining
identi/f_iersthatdonot/f_ittherequiredtype.Onthecontrary,aCom-
pletionEnginehasfullaccesstotheprojectandcaneasily/f_igure
out the return type of asEndTag() through static analysis on the
abstractsyntaxtreeoftheprogram.Bytreatingcodeasasequence
oftextual tokens, the importanttype information isnot encoded.
To address the aforementioned limitations, we propose Repilot,
a framework to further copilot the AI “copilots” (i.e., LLMs) via
fusing LLMs with Completion Engines to synthesize more valid
patches. CompletionEngines [ 48]canparse incompleteprograms
andreasonaboutthesemanticsinanerror-tolerantmanner.Our
keyinsightis tolikenLLMautoregressivetokengenerationasahu-
mandevelopercodewriting,wheretheCompletionEnginecanprovide
real-time updates to check if the human/LLMs written partial code is
valid. Repilot /f_irst uses the LLM to provide the probabilities of gen-
eratingthenexttokeninthepatchandthenqueriestheCompletion
Engine to modify the probability list by dynamically zeroing the
probabilitiesofinvalidtokens.Wecanthensamplefromthenew
probabilitylisttoselectthenexttoken.Furthermore,recognizing
the ability for Completion Engines to suggest completions, we use
this feature whenever there is only one possible identi/f_ier suﬃx
tocompletethecontext.ThisnotonlyallowsRepilottogenerate
patches with valid rare and long identi/f_iers but also reduces the
work of LLMs needed to iteratively generate long identi/f_ier names.
For example, Repilot directly prunes the StringandNametokens
in Figure 1.1 as they are infeasible according to the Completion
Engine, but still accepts the correct Endtoken. In Figure 1.2, theCompletion Enginerecognizes that asEndTag istheonlyvalid con-
tinuationtothepre/f_ix asEnd,soRepilotdirectlycompletesthistoken
without querying the LLM. To combat the time cost of Completion
Engine,weimplementseveraloptimizationtechniquestominimize
theoverhead.Notethattherecent Synchromesh work[52]alsoem-
ploys a Completion Engine for reliable code generation with LLMs.
However, it relies on expert-designed constraints and only targets
domain-speci/f_ic languages (e.g., SQL). Repilot directly works for
general-purposeprogramminglanguageswhileintroducingmini-
mal overhead and can proactively complete the current generation
using the CompletionEngine withoutqueryingthe LLM.
To demonstrate the generalizability of Repilot, we instantiate
Repilot with two LLMs having distinct architectures and sizes:
CodeT5-large[ 61],anencoder-decoderLLMwith770millionpa-
rameters, and InCoder-6.7B [19], a decoder only LLM with 6.7
billionparameters,bothcapableofcodein/f_illingfrompre/f_ixand
suﬃxcontext.WefurtherimplementaJavaCompletionEnginefor
RepilotbasedontheEclipseJDTLanguageServer[ 1,18]sinceit
provides various semantics-based analyses through a consistent
Language Server Protocol [ 48]. We evaluate Repilot on a subset of
thewidelystudiedDefects4J1.2and2.0datasets[ 32]anddemon-
strate state-of-the-art results in both the number of correct /f_ixes
and compilation rate — the percentage of the generated patches
thatcanbesuccessfullycompiled.Furthermore,whileweevaluated
RepilotforAPRinthiswork,webelievetheoverallframeworkcan
be easily applied to other code generation tasks, including code
completion [ 16,73], program synthesis [ 40,52], and test genera-
tion[14,65]. In summary,we make the following contributions:
•Direction. We open a new direction for fusing LLMs with Com-
pletionEngines for more powerful APR and beyond. Compared
to prior techniques which either perform post-processing to /f_ix
invalid generations or use simple static methods to approximate
thesevalidtokens,ourapproachleveragesapowerfulCompletion
Enginetodirectlyprovideaccuratefeedbackonpartialprograms
to avoid invalidtoken generations.
•Technique. WeimplementRepilot,anLLMforAPRapproach
instantiatedwith the CodeT5 and InCoder modelsto perform
cloze-style repair combined with our modi/f_ied Eclipse JDT Lan-
guage Server [ 1,18] as the Completion Engine. In Repilot, we
use the Completion Engine to systematically prune invalid to-
kens generated by LLMs and to directly complete code given the
current pre/f_ix. Furthermore, we implement optimizations to sig-
ni/f_icantlyreducetheoverheadof Repilot.Wehaveopen-sourced
our toolat: https://github.com/ise-uiuc/Repilot .
•Study.WecompareRepilotagainststate-of-the-artAPRtoolson
Defects4J 1.2 and 2.0. Repilot is able to achieve new state-of-the-
art results of 66 Defects4J 1.2 single-hunk bugs and 50 Defects4J
173Copilotingthe Copilots: Fusing Large LanguageModelswithCompletion EnginesforAutomatedProgram Repair ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
2.0 single-line bugs /f_ixed respectively with 30 more combined
/f_ixesacrossbothdatasetscomparedtothepreviousbestbaseline.
Our further evaluation shows that Repilot consistently improves
the validity and correctness of the generated patches with a
limitedoverhead(7%for CodeT5 andnegligiblefor InCoder).
2 BACKGROUNDAND RELATED WORK
2.1 Large Language Models forCode
RecentadvancesinNaturalLanguageProcessing(NLP)haveem-
powered the idea of using Large Language Models (LLMs) that are
pre-trained on enormous corpora of natural language and code for
various code-related tasks [ 4,5,10,38,70]. LLMs are based on the
transformerarchitecture[ 59]thatcanbecategorizedinto encoder-
only,decoder-only andencoder-decoder . Encoder-only models
use only the encoder component by training using Masked Lan-
guage Modeling (MLM) [ 15] objective where a small percentage
(e.g.,15%)ofthetokensaremaskedon.ThegoalofMLMistore-
coverthesemaskedtokensgiventhesurroundingcontext.Encoder-
only models such as CodeBERT [ 17] and GraphCodeBERT [ 23] are
designedtoprovidearepresentationoftheinputcodetobeusedfor
downstream tasks such as code classi/f_ication [ 71]. Decoder-only
models, on the other hand, aim to autoregressively generate to-
kensbasedonallpreviouslygeneratedtokens.CodeGEN[ 50,51],
Codex[10]andPolyCoder[ 70]areexamplesofdecoder-onlyLLMs
where they can be used for code autocompletion tasks. Diﬀerent
from encoder- and decoder-only LLMs, encoder-decoder models
(e.g., CodeT5 [ 60,61] and PLBART [ 3]) combine both encoder and
decoder together and jointly train both components together. A
commonly used pre-training objective for encoder-decoder models
is Masked Span Prediction (MSP) where random spans (multiple
consecutivetokens)arereplacedwithsinglemaskedtokensandthe
modelslearnto /f_illinthemaskedspanwiththecorrectsequenceof
tokens.Furthermore,decoder-onlymodelslike InCoder [19]can
alsodoin/f_illingthroughthecausallanguagemodeling[ 2]objective.
Instead of using thedecoder topredict the nexttoken in the origi-
nal training data, similar to MSP, InCoder also replaces random
spanswith masked spantokens. During training, InCoder learns
toautoregressivelyrecovertheoriginalspans.Withthistraining
strategy,InCoder can perform in/f_illing with bidirectional context
similar to encoder-decoder models,enabling cloze-style repair.
2.2 CodeCompletion
Code completion is one of the most frequently used features in
IntegratedDevelopmentEnvironments(IDEs).Itsubstantiallyal-
leviatesthecomplexityofsoftwaredevelopmentbyinteractively
suggesting program constructs after the user’s caret position while
programmers are typing, including identi/f_ier names and library
APIs. Code completion is now an indispensable infrastructure of
the most widely-used programming languages and can be easily
integrated into most modern text editors thanks to the presence
of the Language Server Protocol [ 48], which standardizes the com-
municationbetweentoolsandlanguageservices.Traditionally,a
semantics-based CompletionEngine isimplementedontopofase-
ries of complex incremental syntactic and semantic analyses of
the target programming language, since it needs to understand
partially written programs and provide real-time feedback. TheCompletionEnginehasfullaccesstoaprojectrepositoryanditsde-
pendencies and can produce suggestions according to its semantic
understanding. Recent advances in LLMs demonstrate the capa-
bilityofgeneratinglongandcomplicatedcompletions.However,
they may produce unreasonable programs due to the limitation in
the code context size and the loss of program analysis by simply
treating programs as token sequences. In this paper, we use the
term Completion Engine to refer to the semantics-based one. We
formally de/f_ine the expected properties of a Completion Engine in
our framework inDe/f_inition 3.4.
2.3 Automated ProgramRepair
AutomatedProgramRepair(APR)aimstogeneratepatchesgiven
thebuggycodelocationandthebug-exposingtests.Traditionally,
APRapproachcanbecategorizedasconstraint-based[ 13,35,43,47],
heuristic-based [ 36,37,63] and template-based [ 21,25,34,41,42,
46]. Among these classic techniques, template-based tools have
been shown to achieve the highest number of bug /f_ixes by using
handcrafted repair templates to target speci/f_ic bug patterns [ 21].
However,thesehandcraftedpatternscannotcoveralltypesofbugs
thatexistandassuch,template-basedtoolscannot/f_ixbugsoutside
oftheirpre-determinedtemplates.
To address the issue faced by template-based APR tools, re-
searchersresorttoNeuralMachineTranslation(NMT)[ 57]tode-
velopNMT-basedAPRtools[ 11,29,39,44,72,74].NMT-basedAPR
tools train an NMTmodel to translatethe inputbuggy code into
the correct code through bug-/f_ixing datasets containing pairs of
buggy and /f_ixed code. However, these bug-/f_ixing datasets may con-
tainonlyasmallnumber/typesofbug/f_ixes,especiallycompared
to a large amount of available open-source code snippets, due to
the diﬃculty in obtaining bug-/f_ixing commits [ 67]. Additionally,
the datasets can fail to /f_ilter out unrelated commits [ 30] such as
refactoring,whichaddsnoisetothetrainingdatasets.Duetothis
reliance on training using bug-/f_ixing datasets, these NMT-based
tools alsocannot generalizeto bug typesnot seenduringtraining.
Recently, researchers begin to directly apply LLMs for APR [ 66].
AlphaRepair [ 67] is the /f_irst to directly use LLMs for cloze-style
(or in/f_illing-style) APR: it masks out the buggy code snippet and
thenusesCodeBERT[ 17]todirectly/f_illinthecorrectcodegiven
the surrounding context. While AlphaRepair demonstrates the po-
tential to use encoder-only models for cloze-style APR, other stud-
ies [33,53,66] have looked into applying all three types of LLM ar-
chitecture.FitRepair[ 64]furtherimprovesAlphaRepairviadomain-
speci/f_ic/f_ine-tuningandpromptingstrategiesleveragingtheplastic
surgeryhypothesis[ 6].Evenmorerecently,researchershaveap-
plied dialogue-based models for APR [ 8,56,68,69]. For example,
ChatRepair [69]proposesafullyautomatedconversationalAPR
approach by learning from prior patching attempts, including both
patch code andtest failure information.
Compared to traditional and NMT-based APR techniques, LLM-
basedtechniquesareabletoachievenewstate-of-the-artbug-/f_ixing
results[66,67].Whiletheperformanceisimpressive,oneparticular
limitation of these techniques is the lack of guidance in patch gen-
eration. Prior work mainly treats theLLM as a black box and only
queriesthemodelviabeamsearch[ 67]orsampling[ 33,53,66].This
174ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA Yuxiang Wei, Chunqiu StevenXia,andLingming Zhang
means LLMs, while powerful, may still generate invalid patches
given the currentcode context.
In this work, we address these limitations by using a semantics-
basedCompletionEnginetoguideandprunetheLLMsearchspace.
OurapproachisorthogonaltorecentLLM-basedAPRtechniques
and can be easily combined with them. In fact, NMT-based APR
techniques have alsoattempted to tackle this problem. CURE [ 29]
/f_irststaticallyobtainsthevalididenti/f_iersandforcestheNMTmodel
toonlyselectfromvalididenti/f_iersduringgeneration.Recoder[ 74]
builds an edit-based NMT model to enforce syntax correctness and
introduce placeholder tokens and then as a post-processing step,
Recoder will replace placeholder tokens with statically determined
valid identi/f_iers. RewardRepair [ 72] on the other hand, attempts to
increase the number of compilable patches by penalizing uncompi-
lable patches during training. Compared to these prior techniques,
Repilot is more general andeﬀective.Repilot doesnot require any
domain-speci/f_ic training and leverages the incremental analysis of
oﬀ-the-shelfCompletionEnginestoenforceguaranteedconstraints
to guide LLMsonthe /f_ly.
3 PRELIMINARIES
In this section, we /f_irst de/f_ine concepts about programming lan-
guagesusedthroughoutthepaper(§ 3.1).Thenwediscussthe formal
abstractions of the two key components used in our Repilot frame-
work:CompletionEngine(§ 3.2)andLargeLanguageModel(§ 3.3).
These two abstractions are crucial in that each of them describes a
collection of /f_itting implementations ,which forms the reason why
Repilot isageneralizable framework.
3.1 Languages with Static Checking
Wenowintroducetheconceptofprogramminglanguagesequipped
with static checking and de/f_ine the feasibility of a partial program
before the formulation ofthe CompletionEngine (De/f_inition 3.3).
De/f_inition3.1(ProgrammingLanguagewithStaticChecking). A
programming language with static checking is de/f_ined as a pair of
itscharacterset Σplanditsstaticspeci/f_ication Φ⊆Σ∗
plasaunary
relation on Σ∗
pl.
PLs=(Σpl,Φ), (3.1)
Givenaprog∈Σ∗
pl,thenotation Φ(prog)(orprog∈Φ)statesthat
progis a statically valid program in this language. For statically-
typedprogramminglanguageslikeJava,thecompilationcheckisa
kindofstaticchecking.
De/f_inition 3.2 (Static Feasibility of A PartialProgram). For apar-
tiallywrittenprogram prog∈Σ∗
pl,wesayitisfeasibleatthecaret
positioncaretwithrespecttothestaticspeci/f_ication Φ,written as
(prog,caret)⊨Φ, if and only if there exists a possible continuation
aftercaretwith which completing progresults in a statically valid
program. The de/f_initioncan be formally written as
(prog,caret)⊨Φ≜∃cont∈Σ∗
pl,Φ(prog[caret←cont]),(3.2)
where we use the notation prog[caret←cont]as the action of
completing progatcaretwithcont,i.e.
prog[caret←cont]≜prog0..caret·cont·progcaret..|prog|.(3.3)InAlgorithm 1,weextendthisnotationtoaccepta range:N×N,so
thatprog[range←hunk]speci/f_ies the action of replacing prog’s
contentswithin rangewithhunk.
3.2 AbstractionofCompletion Engines
A Completion Engine, showed in Figure 2, provides suggested con-
tinuations to apartiallywritten program given the caretposition.
De/f_inition3.3(CompletionEngine). Formallyspeaking,aCom-
pletion Engine CEisapair
CE=(Σpl,complete), (3.4)
whereΣplisthe character setof the target language,and
complete:(Σ∗
pl,N)→P(Σ∗
pl)∪{unknown}(3.5)
is a function to obtain the completions given a program at some
caret position, with unknown indicatingthe enginecannot deter-
mine the suggestions from the code context (e.g., when completing
avariabledeclaration).Notethatwemakeadistinctionbetween
unknown andemptycompletions ∅becauseinthispaperweare
interested in a speci/f_ic group of strictCompletion Engines that
helpsdeterminethe feasibilityof apartialprogram.
Completion 
Engine
… 
public MultiplePiePlot(…) { 
  super(); 
  this.set 
…
Program and caret position
Dataset 
DatasetGroup 
BackgroundAlpha 
DataExtractOrder 
DrawingSupplier 
ForegroundAlpha 
…
Completions(/uni03A3∗
pl,N)→P(/uni03A3∗
pl)∪{unknown }(/uni03A3∗
pl,N)P(/uni03A3∗
pl)∪{unknown }
complete
Figure 2:AbstractionofaCompletion Engine.
De/f_inition 3.4 (Strict Completion Engine). Assume that a Comple-
tion Engine CEcan obtain a set of completions given a program
progfeasible at caret(i.e.,(prog,caret)⊨Φ):
completions =complete(prog,caret)
wherecompletions ≠unknown .(3.6)
Then,CEis said to be strict if and only if, under this condition,
continuing progwith any code that does not match with this set of
completions yields an infeasible program at the new caret position:
∀c∉Pre/f_ix(completions),(prog′,caret′)̸⊨Φ,
whereprog′=prog[caret←c]andcaret′=caret+|c|,
Pre/f_ix(·)={/u1D450|/u1D460∈·and/u1D450isapre/f_ix of /u1D460orvice versa}.(3.7)
Thisde/f_initionessentiallymeansthatastrictCompletionEngine
shouldnotgiveincorrectsuggestions.Itshouldreturn unknown
wheneverunsure.AtrivialstrictCompletionEnginecanbetheone
that alwaysreturns unknown .
3.3 AbstractionofLLMs
In this section, we give a formal abstraction of an encoder-decoder
basedLLMasshowedinFigure 3,whichinpracticeismorecomplex
butconformstotheabstraction.Theabstractionsubsumesdecoder-
only models and can also describe encoder-only models that use
the encoder outputs directlyas token probabilitiesfor generation.
175Copilotingthe Copilots: Fusing Large LanguageModelswithCompletion EnginesforAutomatedProgram Repair ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
lm EncRep EncRep →(/uni03A3∗
lm→DecRep) lm
Decoder inputsEncoder Decoder
Encoder inputs   /uni03A3∗
lm→EncRep EncRep DecRep
Probability Map
! 91%3%…
/uni03A3lm→[0,1]
/uni03A3∗
lm EncRep EncRep DecRep/uni03A3∗
lm EncRep EncRep DecRep→EncRep EncRep DecRep EncRep EncRep →DecRep)
…
Figure 3:Abstractionofencoder-decoderbased LLM.
De/f_inition3.5(LargeLanguageModel). Formally,Wede/f_inean
encoder-decoder basedLLM LMas a3-tuple
LM=(Σlm,encode,decode), (3.8)
whereΣlmis avocabulary consisting of the set of tokens de/f_ined
by the model. The encoder encodeis a function that maps from an
inputsequenceto its encodedrepresentation in EncRep:
encode:Σ∗
lm→EncRep. (3.9)
The decoder decode, de/f_ined below, then memorizes the encoded
representation in EncRep, takes as input a sequence of tokens, and
produces as outputits decodedrepresentation in DecRep:
decode:EncRep→/parenleftbigΣ∗
lm→DecRep/parenrightbig. (3.10)
Inthisde/f_inition,thedecodermemorizingtheencodedrepresen-
tation is modeled as a higher-order function that returns a detailed
decoding function given the encoded representation. The decoded
representation in DecRepessentially assignsa probability toeach
token in the vocabulary to state its likelihood of being the next
token inthe sequence.Therefore,we can de/f_ineDecRepas
DecRep=Σlm→[0,1]. (3.11)
4 APPROACH
FollowingmostrecentdeeplearningbasedAPRtools[ 67,72,74],
Repilot focuses on /f_ixing single-hunk bugs, where the patch is
obtainedbychangingacontinuoussectionofcodeunderperfect
fault localization. Repilot can be extended for multi-hunk bugs
by replacing all hunk locations at the same time with separate
in/f_illing tokens and using LLM to generate the replacement hunks.
Bene/f_itingfromtheeraofLLMs,asshowninFigure 4,inthispaper,
we treat the repair problem as a clozetask [67], where a patch is
formedby/f_irstreplacingthebuggyhunkwithamaskedspantoken
(<SPAN>)andthenusingtheLLMtodirectsynthesizethe/f_ixedhunk
from the surroundingcode contextto replace the span token.
private boolean inSpecificScope(...) { 
   int bottom = stack.size() -1; 
   if (bottom > MaxScopeSearchDepth) { 
      bottom = MaxScopeSearchDepth; 
   } 
   final int top = bottom > …
Bug
private boolean inSpecificScope(...) { 
   final int bottom = stack.size() - 1 
   final int top = bottom > … Cloze
Patch
private boolean inSpecificScope(...) { 
    
   final int top = bottom > … <SPAN>
Figure 4:Cloze-style program repair.
4.1 Overview
Figure5shows an overview of how Repilot synthesizes a program
that acts as therepaired hunkoftheoriginal buggy program. The
generation loop consists of a loop that keeps updating the gen-
eration with tokens newly generated from the synergy between
the language model and Completion Engine. The loop starts byapplyingthecurrentgenerationastheinputtothelanguagemodel
(1),whichreturnsasearchspaceofamappingfromasuggested
nexttoken toitsprobability.Repilot thenenters atokenselection
phasethatrepeatedlysamplesatokenfromthesearchspace,check-
ing its feasibility, and pruning the search space until a token is
accepted. Every time a token is sampled, Repilot /f_irst checks if it
hitsthememorization( 2),whichstoresthetokensthatareknown
tobe feasibleor infeasible.The memorization ofinfeasibletokens
includestheuseofapre/f_ixtreedatastructure(Trie)discussedin
§4.3.Whenthetokenhitsthememorizationandisinfeasible,the
search space is prunedby setting this token’s probability to zero
(3),andthenextsamplingwillrunontheupdatedsearchspace.
In this way, the same token is not sampled again during the token
selectionphase.Ifthetokenmissesthememorization,thesearch
space is pruned under the guidance of the Completion Engine ( 4),
whichweelaboratein§ 4.2. Providedthatthesampledtokenisre-
jected by the Completion Engine, Repilot zeroes out its probability.
Otherwise, it is accepted and this token selection process termi-
nates. The memorization gets updated in both cases ( 5). After a
token is accepted ( 6), we further leverage the Completion Engine,
tryingtoactivelycompletethetoken( 7).Theactivecompletion,
discussed in § 4.4, may either produce more tokens or add noth-
ing to the accepted token. Finally, Repilot appends all the newly
generated tokens to the current generation and begins a new loop
untilacompletepatchisgenerated.Theloopstopswhenthemodel
generatesthe specialtoken end-token.
Algorithm 1detailsthisprocessandshowshowacompletepatch
programisgeneratedusingwhatisestablishedin§ 3.Itadditionally
describes how Repilot performs the pre-processing (Lines 3to6)
and formalizes completion-guided pruning procedure illustrated
in Figure 5using two functions GuidedPrune andActively-
Complete (Lines7to17). In all our algorithms, we use a "dot-
notation"tospecifyanentityofatuple(e.g., LM.encode),butuse
anabbreviationformwhenthecontextisclear(e.g., ΣlmandΣplfor
LM.ΣlmandCE.Σpl).We also optionally apply typeannotations for
clari/f_ication.Notethatwesimplifythede/f_initionoftheCompletion
Engine by restricting it to be called with one program. In practice,
aCompletionEngineisalwaysinitializedwiththeentireproject
andcan providesuggestionsbasedonglobalinformation.
4.2 Completion-GuidedSearch SpacePruning
In this section, we explain the core idea of how Repilot utilizes a
CompletionEngine to prune the search spaceof an LLM.
Algorithm 2explainsindepthhowaCompletionEnginehelps
prune the model’s search space. The function GuidedPrune takes
asinputsaCompletionEngine CE,thecurrentprogram prog,the
currentcaretposition caret,andtheprobabilitymap tokensgivenby
the model, and produces a token next-tokenas the continuation of
theprogram progatposition caret.Thefunctionconsistsofa while-
loop (Lines 2to11) where Repilot /f_irst samples a possible next
tokenaccordingtotheprobabilities(Line 3),updatesthecurrent
program accordingly (Line 4), and moves the caretafter next-token.
Repilot then invokes the Completion Engine using the function
complete de/f_ined in Equation ( 3.5), given the program prog′and
thecaretposition caret′.Iftheresultisnot unknown butthereis
no completion (Line 8), it means that no possible continuation can
176ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA Yuxiang Wei, Chunqiu StevenXia,andLingming Zhang
Token sampling loopLanguage 
Model
Completion 
EngineActive 
Completion
Completion 
Engine
PruningNew tokens


EndTag String name = t.as



…
Generated tokens

…
String* …Memorization
(Trie)
Search space
…3%Name91%String
End
0.2%
Pruned search space0%Name0%String
End
0.2%



…

End

Prune with 
Memorization
Obtain probabilities from 
Language Model1Check memorization2
Update Memorization5
Prune using Completion Engine43
Token 
accepted6
Actively complete the token7Update the patch with new tokens8
Figure 5:Overview of Repilot.
Algorithm1 MainRepairLoopof Repilot
Inputs:Large Language Model LM, Completion Engine CE, Buggy pro-
gramprog, andRange ofbuggyhunk range.
Output: Patch forthe buggyprogram.
1:funcRepair(LM,CE,prog:Σ∗
pl,range:N×N)→Σ∗
pl:
2:⊲Initializationsbased on De/f_inition 3.5 ⊳
3:encoder-inputs:Σ∗
lm:=BuildInputs(prog,range)
4:encoded-rep:EncRep:=LM.encode(encoder-inputs)
5:decoder:Σ∗
lm→DecRep:=LM.decode(encoded-rep)
6:hunk:Σ∗
lm:=/u1D700
7:whiletruedo
8: ⊲Formpatchby replacing buggyhunkwith hunk ⊳
9: patch:=prog[range←Str(hunk)]
10: ⊲Movecaretafterthe currentgeneration ⊳
11: caret:=range.start+|Str(hunk)|
12: tokens:Σlm→[0,1]:=decoder(hunk)
13: next-token:Σlm:=GuidedPrune(CE,patch,caret,tokens)
14: ifnext-token=end-tokenthen
15: returnpatch
16: completion -toks:Σ∗
lm:=ActivelyComplete (CE,patch,caret)
17: hunk:=hunk·next-token·completion -toks
be formed after next-token, so the token next-tokenis considered
infeasible,thus pruned(Line9)inthisroundofsearch,andtheloop
willcontinue(Line 10).Otherwise,weconsiderthetokenfeasible
andreturn next-token(Line11).
ThepruningatLine 9isdonebysettingtheprobabilityofthe
entrynext-tokenoftheprobabilitymap tokenstozero.Thenotation
usedat this lineisde/f_inedsubsequently.Assumethat
f:X→Y={x0↦→y0,x1↦→y1,...} (4.1)
isan arbitrary function, and
a:X⇀Y={x′
0↦→y′
0,x′
1↦→y′
1,...} (4.2)
isapartialfunction ofthesametype,meaningthatonlyasubsetof
inputs in the domain Xis associated with an output in the range Y.
We de/f_ine the action of changing the output values of the inputs in
fusing the assignments given by aas
f[a]=(f−fremoved)∪a
wherefremoved={x′↦→f(x′)|x′↦→y′∈a}.(4.3)
4.3 Memorization forFaster Search
Algorithm 2(GuidedPrune ) involves a loop of trials and pruning
actions, which slows down the repair task in some situation. ToAlgorithm2 Completion-GuidedSearch Space Pruning
Inputs:Completion Engine CE, Current Program prog, Caret Position
caret, andToken Probability Map tokens.
Output: Nexttoken next-tokento generate.
1:funcGuidedPrune (CE,prog,caret,tokens:Σlm→[0,1])→Σlm:
2:whiletruedo
3: next-token:Σlm:=Sample(tokens)
4: prog′:=prog[caret←Str(next-token)]
5: caret′:=caret+|Str(next-token)|
6: ⊲completions :P(Σ∗
pl)∪{unknown} ⊳
7: completions :=CE.complete(prog′,caret′)
8: ifcompletions ≠unknown and|completions|=0then
9: tokens:=tokens[{next-token↦→0}]
10: continue
11: returnnext-token
speedup its search procedure, we apply several memorization tech-
niques to reduce the frequency of invoking the Completion Engine
for analysis.
Memorizing rejectedtokens. To repair a bug in practice requires
generatingplentyofsamples,meaningthatthesameprogram prog′
andcaret′(Lines4to5)mayoccurrepeatedlyinAlgorithm 2(Guid-
edPrune ).Therefore,wecanmemorizeallthetokensprunedat
Line9bystoringtheminavariable
rejected:(Σ∗
pl,N)→P(Σlm), (4.4)
whichmapsfromaprogram progandacaretposition carettoaset
of rejected tokens. Then we zero the probabilities of the rejected
tokens inadvance,written as
tokens:=tokens[{tok↦→0|tok∈rejected(prog,caret)}],(4.5)
before the while-loop(Line 2) starts.
Memorizingacceptedtokens. Besidesrejectedtokens,wecanalso
memorizetokens that are acceptedbefore inavariable
accepted:(Σ∗
pl,N)→P(Σlm) (4.6)
to avoid the overhead incurred from querying the Completion
Engine at Lines 7to8.
BuildingaPre/f_ixTreeofRejectedTokens. Itiscommonthatmany
tokens in the vocabulary of the language model are pre/f_ixes of
another.Anditisobvious thatifatokenisrejected,meaningthat
no possible continuation can be formed after the token to obtain a
staticallyvalidprogram,thenanytokensharingsuchpre/f_ixshould
be rejected. For this reason, we build and keep updating a pre/f_ix
tree, or Trie, of all the rejected tokens given progandcaret, and
177Copilotingthe Copilots: Fusing Large LanguageModelswithCompletion EnginesforAutomatedProgram Repair ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
checksifanyofthetokensintheTrieisapre/f_ixof next-tokenright
afterLine 3inAlgorithm 2.Ifitisthecase,Repilotdirectlyskipsto
the nextiteration, avoidingfurther analysis.
4.4 ActiveCompletion
NotonlyisaCompletionEngineabletodeterminethefeasibilityof
apossiblenexttokensuggestedbythemodel,asshownin§ 4.2,butit
can alsoproactively suggest a potential continuation of the current
program without querying the model, just like how developers
bene/f_itfrom autocompletion.
Algorithm 3describes active completion indetail. Thefunction
ActivelyComplete takesthreeinputs:theCompletionEngine CE,
the current program prog, and the current caret position caret, and
outputsasequenceoftokens completion -toksasthecontinuationof
progatcaret. Initially, Repilot gets the completion result according
toEquation( 3.5),givenprogandcaret(Line2),andchecksifitis
unknown (Line3). If it is the case ( completions =unknown ), the
result is set to an empty string, meaning no extra completions are
produced (Line 4). Otherwise, Repilot calculates the common pre/f_ix
ofallthecompletions(Line 6).Notethatthetypeoftheresultant
variablecompletion isasequenceofcharactersintheProgramming
Language alphabet, diﬀerent from the language model’s Σlm, so
Repilot further aligns the completion to /f_it the model’s vocabulary
(Line7). Finally,the result isreturnedat Line 8.
Algorithm3 Active Completion
Inputs:Completion Engine CE, Program prog, andCaret Position caret.
Output: Theactivelycompleted tokens completion -toks.
1:funcActivelyComplete (CE,prog,caret)→Σ∗
lm:
2:completions :P(Σ∗
pl)∪{unknown}:=CE.complete(prog,caret)
3:ifcompletions =unknown then
4: completion -toks:=/u1D700
5:else
6: completion :Σ∗
pl:=CommonPrefix(completions)
7: completion -toks:Σ∗
lm:=AlignTokens(Σlm,completion)
8:returncompletion -toks
4.5 Soundness of Repilot
Inthissection,weshowthetheoreticalguaranteeofeachalgorithm
discussedabove underthe condition that theCompletion Engine is
strict(De/f_inition 3.4).
Lemma4.1(SoundnessofPruning). Thetokensprunedaway
in Algorithm 2(GuidedPrune )resultin infeasbileprograms.
Discussion. From Equation ( 3.7) in De/f_inition 3.4, we can de-
duce that a program is infeasible at some caret position if the Com-
pletionEnginedoesnotreturn unknown butthesetofcompletions
isempty,i.e.,
|completions|=0→(prog,caret)̸⊨Φ
ifcompletions ≠unknown(4.7)
ThepruningatAlgorithm 2happensatLines 8to9,whichisexactly
what is described above. As a result, we can conclude that the
programwith next-tokenappendedisinfeasible,andhenceitissafe
for Repilot to abandonthe token. □Lemma4.2(SoundnessofMemorization). Thememorization
discussed in § 4.3does not aﬀect GuidedPrune ’s behavior.
Discussion. Thetheoremholdsbecauseallthememorization
techniquesmentionedin§ 4.3donotchangethesemanticsof Guid-
edPrune but only speedupthe process. □
Lemma4.3(SoundnessofActiveCompletion). Ifaprogram
is feasible at some caret position, the new program produced by Algo-
rithm3(ActivelyComplete )is feasible at itsnew caret position.
Discussion. Based on Equation ( 3.7) from De/f_inition 3.4, any
continuations not matching the set of completions would bring
aboutaninfeasibleprogram.Inthecasewherethesecompletions
have a shared common pre/f_ix, any continuations not starting with
this common pre/f_ix would be invalid. Therefore, completing the
originalprogramwiththecommonpre/f_ix(Line 6inAlgorithm 3)
isthe only wayto yieldanewfeasible program. □
On the basis of Lemmas 4.1to4.3, we can easily prove that
Repilot’soverallalgorithm issound.
Theorem4.4(OverallSoundness). Algorithm 1(Repair)does
not miss any feasible programs in the language model’s search space.
When will Repilot fail? Although the theorems are about the
soundnessof Repilot,i.e.,it prunesthesearchspacecorrectly ,itdoes
notprovidesanyguaranteethatRepilot producesavalidpatch every
time. Therefore, Repilot’s expected behavior is to be able to obtain
valid patches more eﬃciently, rather than being entirely error-free
duringthe generation.
5 EXPERIMENTALSETUP
Inthispaper,westudythefollowingresearchquestionstoevaluate
Repilot.
•RQ1:How does Repilot’s bug /f_ixing capability compare with
state-of-the-artAPR techniques (§ 6.1)?
•RQ2:How eﬀective is Repilot in improving the compilation rate
ofpatch generation(§ 6.2)?
•RQ3:Areallcomponentsof Repilotmakingpositivecontribu-
tionsto its eﬀectiveness (§ 6.3)?
•RQ4:Can Repilot generalize to diﬀerent subjects of bugs and
models (§ 6.4)?
We/f_irstcomparetherepairperformanceof Repilot,instantiated
withCodeT5,againststate-of-the-artAPRtoolsacrossbothtradi-
tional, NMT-based, and LLM-based tools on the Defects4J datasets
inRQ1.InRQ2,wethencloselyevaluatetheimprovementincompi-
lationrate—percentageofcompilablepatchesgeneratedtodemon-
strate that Repilot is not only eﬀective in bug repair but can gener-
ate a higher number of compilable patches compared with existing
tools. Furthermore, we perform a detailed ablation study in RQ3
to evaluate the contribution of diﬀerent components of Repilot.
Finally, in RQ4, we extend our evaluation of Repilot beyond its use
withCodeT5inthepreviousRQs.Wegoastepfurtherbyimple-
mentingRepilotwith InCoder andassessingtheperformanceof
Repilot usingboth CodeT5and InCoder onsingle-hunkbugs from
both Defects4J 1.2 and 2.0 to demonstrate the generalizability of
Repilot acrossdiﬀerentLLMsandbugsubjects.
178ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA Yuxiang Wei, Chunqiu StevenXia,andLingming Zhang
5.1 Implementation
We use the Python implementation of the CodeT5-large and the
InCoder-6.7B models obtained on Hugging Face [ 26]. We build
our generation pipeline in Python with 5K lines of code and imple-
mentamodi/f_iedversionoftheEclipseJDTLanguageServer[ 1,18]
in Java with 1.5K additional lines of code, which serves as the
strictCompletion Engine of our framework. Our default genera-
tion usestop-p nucleus sampling [ 24] with/u1D45D=1.0,temperature =
1.0,/u1D45A/u1D44E/u1D465-/u1D461/u1D45C/u1D458/u1D452/u1D45B/u1D460=50and samples 5000 times per bug for fair
comparisonsagainstpriorworks(§ 6.1and§6.2).Duetothehigh
cost of APR, we sample 500 times per bug for the ablation study
(§6.3) and the generalizability evaluation (§ 6.4). Following prior
work[39,44,67,74],weuseatimeoutof5hourstogenerateand
validate all patches per bug. We generate and validate patches on a
32-CorewithRyzenThreadripperPRO3975WXCPU,256GBRAM
and NVIDIA RTX A6000 GPU,runningUbuntu20.04.4LTSwith
Java versionOpenJDK 1.8.0_181.
5.2 Subject Programs
We use the popular repair benchmark of Defects4J for our evalu-
ation. Defects4J is a manually curated Java dataset with pairs of
buggy and patched versions of the source project along with de-
veloper test suites for validation. Following prior work and APR
literatureconvention,weseparateDefects4JintoDefects4J1.2,con-
taining 391 bugs (removing 4 depreciated bugs) from 6 Java source
projects,andDefects4J2.0,containing438newbugsfrom9addi-
tional projects. For Defects4J 1.2, we focus on only the single-hunk
bugs as Repilot is designed for single-hunk repair. Note this is also
the evaluation setting used in the prior baseline [ 72]. Furthermore,
weremovethebugsthatareincompatiblewithourCompletionEn-
gineduetoengineeringissues.Intotal,weconsider138single-hunk
bugsfromDefects4J1.2and135single-hunkbugsfromDefects4J
2.0.ForourmainevaluationinRQ1,followingthesamesetupas
priorLLMforAPRwork[ 66,67],wereporttheresultsonall135
single-hunk bugs from Defects4J 1.2 and 76 single-line bugs (a
subsetofsingle-hunk bugs)fromDefects4J2.0.Meanwhile,inour
generalizabilitystudy(RQ4),wefurtherevaluateRepilotonthefull
set of single-hunk bugs from both Defects4J 1.2 and 2.0 for both
CodeT5 and InCoder.
5.3 ComparedTechniques
WecompareRepilotagainststate-of-the-artbaselinesfromtradi-
tional, NMT-based, and LLM for APR tools. We evaluate against
AlphaRepair [ 67] as it is the top performing LLM for APR ap-
proach. For NMT-based approaches, we choose 6 recent tools:
RewardRepair[ 72],Recoder[ 74],CURE[ 29],CoCoNuT[ 44],DL-
Fix [39] and SequenceR [ 11] based on the NMT architecture. Addi-
tionally,wecompareagainst12traditionalAPR tools:PraPR[ 21],
TBar[41],AVATAR[ 42],SimFix[ 28],FixMiner[ 34],CapGen[ 63],
JAID [9], SketchFix [ 25], NOPOL [ 13], jGenProg [ 45], jMutRe-
pair[46]andjKali[ 46].Altogether,weinclude19APRbaselinesand
compare Repilot against them on Defects4J 1.2 and 2.0. Our evalua-
tionsettingisonperfectfaultlocalization–wheretheground-truth
locationofthebugisgiventotheAPRtool.Wenotethatthisisthe
preferred evaluation setting as it eliminates any diﬀerences caused
bydiﬀerentfaultlocalizationmethods[ 29,44,58,74].WefollowtheTable1:Numberofcorrect/f_ixesonDefects4J1.2single-hunk
andDefects4J 2.0 single-linebugs
Tool Methodology#Correct Fixes
Defects4J 1.2 Defects4J 2.0 Total
CoCoNuT NMT 30 - -
DLFix NMT 32 - -
PraPR Template 35 - -
TBar Template 41 7 48
CURE NMT 43 - -
RewardRepair NMT 45 24 69
Recoder NMT 51 10 61
AlphaRepair LLM 52 34 86
Repilot LLM 66 50 116
Repilot RewardRepairAlphaRepairRecoder
CURE
8 7
Repilot RewardRepairAlphaRepairRecoder
Others
a) with best LLM and NMT-based baselines b) with all APR tools
Figure 6:Correct/f_ixVenndiagramson Defects4J 1.2
conventionusedinpriorwork[ 21,29,41,74]anddirectlyreport
the bug/f_ixresults obtainedfrom previous studies[ 21,67,72].
5.4 EvaluationMetrics
•Plausiblepatches arepatchesthatpassalltestcasesbutmay
violate the real userintent.
•Correct patches are patches that are semantically equivalent
to the developer patch. Following common APR practice, we
determine semantic equivalency by manually examining each
plausiblepatch.
•Patch compilation rate is also used in many deep learning
based APR works [ 29,72], which indicates the percentage of
compilablepatchesinallgeneratedpatches.
6 RESULTANALYSIS
6.1 RQ1: Comparisonwith ExistingTools
In RQ1 and RQ2, we follow the prior approach for cloze-style
APR[67]to makeuse ofrepairtemplates forafaithful evaluation.
Instead of replacing the entire buggy line with model-generated
code,thesetemplatessystematicallykeeppartsofthebuggyline
to reduce the amount of code the LLM needs to generate. Note
thatwedonotapplyanyrepairtemplatesinRQ3andRQ4because
we consider a smaller number of samples there (i.e., 500 samples
as shown in Section 5.1) and also want to focus on the impact of
diﬀerentexperimental con/f_igurations.
Defects4J1.2. We/f_irstcompareRepilotagainstthestate-of-the-art
APRtoolsonsingle-hunkbugsfromDefects4J1.2.Table 1shows
the number of correct patches produced by Repilot, evaluated in
cloze-style, along with the baselines. Repilot achieves the new state-
of-the-artresultof66correctbug/f_ixesonDefects4J1.2,outperforming
179Copilotingthe Copilots: Fusing Large LanguageModelswithCompletion EnginesforAutomatedProgram Repair ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
private String getRemainingJSDocLine() {            
String result = stream. getRemainingJSDocLine ();            
unreadToken = NO_UNREAD_TOKEN;            
return result;            
}
unreadToken = NO_UNREAD_TOKEN; +
Bug-ID: Closure-133
Patch Generation ProcessLLMCompletion 
Engine
Figure 7:Uniquebug/f_ixby Repilot on Defects4J 1.2
all previous APR tools . Figure6a shows the Venn diagram of the
unique bugs /f_ixed for the top performing LLM- and NMT-based
APR tools where Repilot is able to obtain the highest number of
8uniquebugsFurthermore,Figure 6bcomparestheuniquebugs
/f_ixed for all top-performing baselines and with all other APR tools
combined (Others). We observe that Repilot is able to /f_ix 7 bugs
that nootherbaselineshave been ableto /f_ixsofar.
To demonstrate the ability of Repilot to /f_ix diﬃcult bugs, Fig-
ure7shows a unique bug ( Closure-133 ) from Defects4J 1.2 that
only Repilot can /f_ix. This bug is /f_ixed by adding the new assign-
mentstatementusingtheglobalvariable NO_UNREAD_TOKEN whichis
diﬃculttogenerateasitdoesnotappearwithinthesurrounding
contextofthebuglocation.Repilot/f_irstusesCodeT5togeneratethe
initial pre/f_ix of unread. Then using the Completion Engine, Repilot
recognizes that Tokenis the only semantically correct continuation
anddirectlyperformsactivecompletiontoreturn unreadToken .Sim-
ilarly for generating NO_UNREAD_TOKEN , Repilot /f_irst generates NO_
and then uses active completion to directly generate this rare iden-
ti/f_ierwithouthavingtorepeatedlysampletheLLM.Itisdiﬃcultfor
prior LLM- and NMT-based APR tools to generate this /f_ix as LLMs
or NMT models may not be able to complete this rare identi/f_ier
since it requires multiple continuous steps to generate. In contrast,
Repilot,throughtheuseofactivecompletion,candirectlygenerate
this rare identi/f_ier given only the initial identi/f_ier pre/f_ix to quickly
arrive at this correctpatch.
Defects4J 2.0. We further evaluate Repilot against baselines eval-
uatedonthesingle-linebugsinDefects4J2.0.Forthesebugs,we
followpriorapproachforcloze-styleAPR[ 67]tomakeuseofrepair
templates.Insteadofreplacingtheentirebuggylinewithmodel-
generated code, these templates systematically keep parts of the
buggyline(e.g.,pre/f_ixorsuﬃx,methodparametersandcalls)tore-
ducetheamountofcodetheLLMneedstogenerate.Weapplythese
repairtemplatesforDefects4J2.0single-linebugsonlysincethey
aredesignedforsingle-linebugs.Table 1alsoshowsthenumber
ofcorrect/f_ixesonDefects4J2.0comparedwiththebaselines.We
observethat Repilotisableto/f_ixthehighestnumberofbugs50(16
morethanthenextbestbaseline)onDefects4J2.0. Thisimprovement
over existing baselines shows that Repilot can generalize to two
versionsofDefects4Jdatasetsanddemonstratesthepowerofrepair
templates to boost the performance ofLLM-basedAPR tools.
Figure8showsauniquebugfromDefects4J2.0thatonlyRepilot
can/f_ix.First,Repilotgeneratesthepatchuptothecaretposition.
TheCompletionEnginethen capturestheexacttypeof theobject
fromToken.EndTag toString. Using this information, Repilot cor-
rectlyprunestokensthatarenotapartofthe Stringclass(e.g., name
andtext). Hence, the generated patch contains a valid Stringclass
private void popStackToClose(Token.EndTag endTag) {
String elName = endTag.name();
String elName = endTag.name().toLowerCase();
Element firstFound = null ;+
Bug-ID: Jsoup-77
Patch Generation Process-
String elName = endTag.name().text        
name
...        
toLower      
Type: Token.EndTagType: String
✓
✕
✕
Completion EngineFigure 8:Uniquebug/f_ixby Repilot on Defects4J 2.0
Table2:ComparisonwithexistingAPRtoolsoncompilation
rate on Defects4J 1.2. "-"denotes data notavailable.
Tool% Compilable Patches
Top-30 Top-100 Top-1000 Top-5000
SequenceR 33% - - -
CoCoNuT 24% 15% 6% 3%
CURE 39% 28% 14% 9%
AlphaRepair 25% 22% 16% 13%
RewardRepair 45% 38% 33%1-
Repilot 66% 62% 58% 59%
1Thisisthe top200ratefor RewardRepair as it doesnot include top1000
method of toLowerCase() which correctly /f_ixes this bug. Similar
to the previous unique bug /f_ix in Defects4J 1.2, prior LLM-based
APRtoolsmaywastealotoftimegeneratingsemanticallyincor-
rect continuations as they do not have access to the type infor-
mation. Furthermore, NMT-based APR tools such as CURE [ 29],
over-approximatingthelistofvalididenti/f_iersbystaticallygrabbing
all the accessible /f_ields, may not generate this /f_ix since a pruned
identi/f_ier (e.g., name) can also be valid for a diﬀerent object type.
Repilot uses the Completion Engine to analyze partial programs
andrealizecomplex type propagationfor eﬀective pruning.
6.2 RQ2: CompilationRateAnalysis
We evaluate the compilation rate of the patches generated by Repi-
lot compared with prior learning-based APR techniques. Table 2
shows the percentage of compilable patches on the Defects4J 1.2
dataset.Weobservethatacross allnumbersofpatchesgenerated,
Repilotsigni/f_icantlyimprovesthepercentageofcompilablepatches
compared with prior tools. We /f_irst notice that LLM-based APR
tools(RepilotandAlphaRepair),areabletosustaintheircompila-
tionratecomparedwithNMT-basedtools(CoCoNuTandCURE)
where the compilation rate drastically decreases as we increase the
number of patches. This shows the ability for LLMs to generate
large amounts of reasonable patches. Repilot is able to sustain a
near 60% compilationpercentage at 1000 patches generated while
the prior approach isbarelyabove 30%.
Compared with CURE [ 29], where an overestimation of valid
identi/f_iers is obtained via static analysis and used to prune invalid
tokensgeneratedbyNMTmodel,Repilotleveragesthepowerful
CompletionEnginetokeeptrackofthecurrentcontexttoobtain
a more accurate pruning step. Furthermore, compared with Re-
wardRepair [ 72], where the compilation rate is boosted through
penalizinguncompilablepatchesduringtraining,Repilotdirectly
uses a LLM combined with a Completion Engine to avoid this high
180ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA Yuxiang Wei, Chunqiu StevenXia,andLingming Zhang
Table 3:Componentcontributionof Repilot
Variant Generation
Time%Compilable
Patches%Plausible
Patches#Plausible
Fixes#Correct
Fixes
Repilot∅0.232s 43.2% 3.95% 56 37
Repilotp0.294s 60.7% 5.02% 62 41
Repilotm
p0.255s 58.7% 4.82% 60 40
Repilot 0.248s 63.4% 5.21% 63 42
costoftraininganewmodel.Additionally,Repilotusestheactive
completion ability of Completion Engine to directly generate these
rare identi/f_iers to further boost the compilation rate. As such, Repi-
lot is able to achieve the highest percentage of compilable patches
acrossallfourdiﬀerentsettings.
6.3 RQ3: Ablation Study
Tostudythecontributionofeachcomponentof Repilottoitsoverall
eﬀectiveness, we conduct an ablationstudy that aims at justifying
the following hypothesis:
•Algorithm 2(GuidedPrune )helpsLLMtoachievevalid(compi-
lable)patchesmore eﬃciently onaprunedsearchspace.
•Memorization(§ 4.3)reducesthefrequencyofqueryingtheCom-
pletion Engine,thus speeding uppatch synthesis.
•Active completion provides further guidance of synthesis that
andhelpsRepilot eﬃciently achieve more valid patches.
•The plausible rate of patches becomes higher along with the
compilation rate.
Togivegroundsforthesehypotheses,wesetupthefollowing
fourvariants:
•Repilot∅uses only the baseLLM(CodeT5) for patch synthesis.
•Repilotpapplies pruning de/f_inedinAlgorithm 2.
•Repilotm
pleveragesmemorization (§ 4.3) ontop ofpruning.
•Repilot employs active completion for further guidance.
andevaluatethembycomparingthemagainsttheireﬃciencyin
generatingcompilable,plausiblepatches, andcorrectpatches.
Table3shows the generation time (in seconds per patch), the
contributionintermsofthepercentageofcompilableandplausi-
blepatchesamongalluniquelygeneratedpatches,thenumberof
plausible /f_ixes, and the number of correct /f_ixes for each of the four
variantsonDefects4J1.2single-hunkbugs.We/f_irstobservethat
just using the base LLM for APR ( Repilot∅), we achieve the lowest
compilationrateat43.2%.Byaddingthepruningprovidedbythe
Completion Engine, we can signi/f_icantly improve the compilation
rateto60.7%,thenumberofplausible/f_ixesfrom56to62,andthe
numberofcorrect/f_ixesfrom37to41.Additionalimprovementis
made by adding the active completion technique to achieve the
full Repilot with the highest compilation rate at 63.4%, plausible
percentage 5.21%, the most number of plausible /f_ixes at 63, and the
mostcorrect/f_ixes at 42.
Looking at the patch generation time, starting from Repilot∅,
addingpruningviaCompletionEngineincursanover25%overhead.
However, this can be signi/f_icantly reduced by using memorization
(Repilotp) to achieve around 10% overhead by avoiding querying
theCompletion Engineoncewe knowanidenti/f_ier isinvalid. Fur-
thermore, active completion can further reduce the overhead to7%sinceinsteadofhavingtosampletheLLMforeachstepinthe
generation, we can activelycomplete an identi/f_ier.
Asaresult,allthecomponentscontributetotheoveralleﬀective-
nessof Repilot.Repilotcanconsistentlyincreasethecompilation
andplausiblerate,aswellasproducemoreplausible/correct/f_ixes
while incurring minimal overhead compared with directly using
LLMsfor patch synthesis.
6.4 RQ4: Generalizability
To demonstrate the generalizability of Repilot across diﬀerent sub-
jects of bugs and models, on the one hand, we further evaluate
RepilotwithCodeT5onallsingle-hunkbugsofDefects4J2.0.On
the other hand, we additionally instantiate and evaluate Repilot
withalarger InCoder-6.7Bmodel.IdenticaltoRQ3,wealsoconduct
500samples inRQ4 dueto the high costof APR.
Table4shows the comparison between the baseline Repilot∅
and our full Repilot approach across diﬀerent subjects of bugs and
models.WeconsiderthesamesetofDefects4J1.2single-hunkbugs
as inRQ3 andan extrasetof Defects4J2.0 single-hunkbugs.
Upon investigation, we can see that Repilot with CodeT5 sur-
passes the baseline on Defects4J 1.2 as illustrated in RQ3. Further-
more,onDefects4J2.0,itcanalsoachieve18.1percentagepoints
(pp)morecompilableand3.0ppmoreplausiblepatches,aswellas6
moreplausible/f_ixesand4morecorrect/f_ixes,witha7.4%overhead.
Meanwhile,whenRepilotisinstantiatedwith InCoder,itstill
producesmorecompilableandplausiblepatches,aswellasmore
plausibleandcorrect/f_ixesonbothDefects4J 1.2and Defects4J2.0
over the baseline InCoder. It eventually gives 6 more correct /f_ixes
onDefects4J1.2 and1more onDefects4J2.0.
One major diﬀerence comparing Repilot with InCoder and
CodeT5 is that when Repilot is equipped with InCoder, a much
larger model than CodeT5, it incurs negligible overhead. This is
becausecomparedtothehighcostofautoregressivesamplingusing
largermodels,theextracostfromqueryingtheCompletionEngine
ismuch smallerand thustrivializesthe overheadof Repilotwhen
appliedonlargermodels.Also,thelarger InCoder model,whether
or not it is applied with Repilot, can consistently /f_ix more bugs
across bothDefects4J 1.2and2.0thanCodeT5, further con/f_irming
prior /f_indingthat larger LLMsoften perform betterfor APR [ 66].
Overall,theexperimentalresultsindicatethatRepilotcangener-
alizetodiﬀerentsetsofbugs(bothsingle-hunkbugsinDefects4J
1.2 and2.0) as well as larger LLMs( InCoder)
7 LIMITATIONS
First, to bring out Repilot’s full potential, it is important that the
CompletionEnginecanprovideusefulguidancewhileremaining
strict (De/f_inition 3.4). However, it is generally more diﬃcult to
balance the usefulness and strictness of a Completion Engine in
many dynamically typed programming languages, such as Python,
comparedwithJavastudiedinthispaper,whichisastaticallytyped
programming language. Meanwhile, there is a growing trend of
dynamicallytypedlanguagesadoptingsupportfortypehints[ 12,
49,54].Consideringthis,webelievethatRepilotcanstillprovide
signi/f_icant advantagesinsuch environments.
Another limitation of Repilot lies in the evaluation. On the one
hand, while it is true that an increase in the compilation rate of
181Copilotingthe Copilots: Fusing Large LanguageModelswithCompletion EnginesforAutomatedProgram Repair ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
Table 4:Generalizability of Repilot across bothsubjectsofbugsand models
Variant Model Subject ofBugs Generation Time %Compilable Patches %PlausiblePatches #PlausibleFixes #Correct Fixes
Repilot∅CodeT5-large Defects4J 1.2 0.232s 43.2% 3.95% 56 37
Repilot CodeT5-large Defects4J 1.2 0.248s 63.4% 5.21% 63 42
Repilot∅CodeT5-large Defects4J 2.0 0.230s 46.7% 9.02% 59 41
Repilot CodeT5-large Defects4J 2.0 0.247s 64.8% 12.02% 65 45
Repilot∅InCoder-6.7B Defects4J 1.2 1.70s 32.4% 3.85% 70 48
Repilot InCoder-6.7B Defects4J 1.2 1.70s 47.2% 4.96% 78 54
Repilot∅InCoder-6.7B Defects4J 2.0 1.67s 34.6% 5.06% 67 45
Repilot InCoder-6.7B Defects4J 2.0 1.69s 48.0% 6.87% 68 46
Repilotcanleadtothediscoveryofmoreplausibleandcorrect/f_ixes,
it is important to note that a signi/f_icantly higher compilation rate
does not necessarily translate to a proportionally large increase
in plausible and correct /f_ixes. On the other hand, Repilot is only
evaluated with CodeT5 for RQ1 and RQ2 with a 5000 sampling
budget.CodeT5isarather“small”LLMcomparedtothoseLLMs
with billions of parameters. Although we further include InCoder-
6.7B as a multi-billion-parameter LLM in RQ4, due to time cost, we
only sample 500 times per bug, which may be insuﬃcient to re/f_lect
the distribution of the generated patches. Overall, the scope of our
evaluation consideringtwoLLMs (CodeT5 and InCoder)and one
programminglanguage(Java)isstillnarrowgiventhatRepilotis
ageneralframeworkthatcanbeinstantiatedwithanypairofan
LLMandaCompletionEngine for someprogramming language.
Finally, despite the examples we show in the paper, our eval-
uation lacks strong empirical evidence to support the claim that
LLMs have diﬃculty in generating rare tokens and how Repilot
solvestheproblem.Besides,ourevaluationlimitstheapplication
of Repilot to patch synthesis, even though we claim that Repilot
canbeappliedtoothercodegenerationtasks.Inthefuture,wewill
apply and evaluateRepilot on more diverse code generation tasks.
8 THREATS TO VALIDITY
Internal. We share thesame main internal threat to validity with
priorAPRtoolswherewehavetomanuallyexamineeachplausible
patch to determine patch correctness. We address this by carefully
analyzingeachpatchtodetermineifitissemanticallyequivalent
to the reference developer patch. Furthermore, we have released
our full setofcorrectpatchesfor publicevaluation [ 62].
OuruseoftheCodeT5modelposesanotherinternalthreatwhere
the open-source training dataset of GitHub projects [ 27] may over-
lap with our evaluation of Defects4J. We follow prior work [ 66,67]
andaddressthisbycomputingthecorrectbug/f_ixesof Repilotfrom
Defects4J that is part of the CodeT5 training data. In total, 7 out
of 66 and 6 out of 50 overlap with training data on Defects4J 1.2
and2.0respectively.Forcomparisonfairness,ifweweretoexclude
these7and6bugsandcomparethemwiththepreviousbaseline
toolsontheremainingbugs,wearestillabletoachievethehighest
bug /f_ixes at 59 and 44 (best baseline at 45 and 29). The same threat
appliestotheuseof InCoder,butsinceitsdetailedtrainingdatais
notrevealed,weareunabletoexplicitlyaddressthisproblem.To
mitigate the problem, we only evaluate InCoder in RQ4, where all
the variants face the same potentialleakage.Moreover,ourmodi/f_iedimplementationofthecompletionen-
ginerequiresmanual inspectiontoguaranteesoundnessproperty.
In practice, this is a signi/f_icant trust base that may introduce false
positives during pruning. However, our theorem still provides a
partialguarantee andisable to explainunsoundness. At the same
time, our evaluation result justi/f_ies our claims and demonstrates
the practicalityof Repilot.
Finally,inourevaluation,wefollowtheconventionusedinprior
worktodirectlyreportthebug/f_ixresultswithoutreproducingthem,
which poses a threat to the reliability of the results. Meanwhile,
we onlyrun eachof our experimentsonce, whichcould introduce
extrastatisticalbiases.
External. The main external threat to validity comes from our
evaluation dataset where the performance of Repilot may not gen-
eralizetootherdatasets.Toaddressthis,wecompareRepilotagainst
state-of-the-artbaselinesonbothDefects4J1.2and2.0toshowthat
the performance is sustained across both versions. To address this
further,weplantoevaluateRepilotonadditionalAPRdatasetsalso
acrossdiﬀerentprogramming languages.
9 CONCLUSION
We propose Repilot — the /f_irst APR approach to combining the
directusageofLLMs(e.g.,CodeT5and InCoder)withon-the-/f_ly
guidance provided by Completion Engines. During autoregressive
token generation, Repilot queries the Completion Engine not only
topruneinvalidtokensbutalsoto proactivelycomplete thecurrently
generatedpartialprogram,therebyreducingthesearchspaceofthe
LLM.Ourevaluationonasubsetofthewidely-studiedDefects4J1.2
and2.0datasetsshowsRepilotisabletoachievethestate-of-the-art
results. Furthermore, Repilot, through the usage of Completion
Engine, is able to generate more valid and compilable patches than
priortoolswithminimaloverheadcomparedwithdirectlyusing
LLMsfor APR.
DATA AVAILABILITY
Wehaveopen-sourcedRepilot,whichcanbeaccessedonGitHub
athttps://github.com/ise-uiuc/Repilot .Additionally,animmutable
artifact for Repilot ispubliclyavailable onZenodo [ 62].
ACKNOWLEDGMENTS
Wethankallthereviewersfortheirinsightfulcomments.Wealso
thank Yifeng Ding for his helpful discussion on this work. This
work was partially supported by NSF grants CCF-2131943 and
CCF-2141474,as well as Kwai Inc.
182ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA Yuxiang Wei, Chunqiu StevenXia,andLingming Zhang
REFERENCES
[1] 2023. EclipseJDTLS. https://projects.eclipse.org/projects/eclipse.jdt.ls .
[2] Armen Aghajanyan, Bernie Huang, Candace Ross, Vladimir Karpukhin, Hu Xu,
NamanGoyal, Dmytro Okhonko,MandarJoshi,GargiGhosh,MikeLewis, and
LukeZettlemoyer.2022.CM3:ACausalMaskedMultimodalModeloftheInternet.
CoRRabs/2201.07520 (2022). arXiv: 2201.07520 https://arxiv.org/abs/2201.07520
[3]Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, and Kai-Wei Chang.
2021. Uni/f_ied Pre-training for Program Understanding and Generation.
arXiv:2103.06333 [cs.CL]
[4]Jacob Austin, Augustus Odena, Maxwell I. Nye, Maarten Bosma, Henryk
Michalewski, David Dohan, Ellen Jiang, Carrie J. Cai, Michael Terry, Quoc V. Le,
andCharlesSutton.2021. ProgramSynthesiswithLargeLanguageModels. CoRR
abs/2108.07732 (2021). arXiv: 2108.07732 https://arxiv.org/abs/2108.07732
[5]Shraddha Barke, Michael B. James, and Nadia Polikarpova. 2023. Grounded
Copilot:HowProgrammersInteractwithCode-GeneratingModels. Proc.ACM
Program.Lang. 7,OOPSLA1,Article78(apr2023),27pages. https://doi.org/10.
1145/3586030
[6]EarlT.Barr,YuriyBrun,PremkumarDevanbu,MarkHarman,andFedericaSarro.
2014. ThePlastic SurgeryHypothesis.In Proceedings ofthe 22nd ACMSIGSOFT
International Symposium on Foundations of Software Engineering (Hong Kong,
China)(FSE2014) .AssociationforComputingMachinery,NewYork,NY,USA,
306–317. https://doi.org/10.1145/2635868.2635898
[7]Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan,
PrafullaDhariwal,ArvindNeelakantan, Pranav Shyam, GirishSastry,Amanda
Askell,SandhiniAgarwal,ArielHerbert-Voss,GretchenKrueger,TomHenighan,
Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeﬀrey Wu, Clemens Winter,
ChristopherHesse,MarkChen,EricSigler,MateuszLitwin,ScottGray,Benjamin
Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya
Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners.
CoRRabs/2005.14165 (2020). arXiv: 2005.14165 https://arxiv.org/abs/2005.14165
[8]Jialun Cao, Meiziniu Li, Ming Wen, and Shing-Chi Cheung. 2023. A study on
Prompt Design, Advantages and Limitations of ChatGPT for Deep Learning
ProgramRepair. CoRRabs/2304.08191(2023). https://doi.org/10.48550/ARXIV.
2304.08191 arXiv:2304.08191
[9]Liushan Chen,YuPei, and Carlo A. Furia. 2017. Contract-basedprogramrepair
withoutthe contracts.In 2017 32nd IEEE/ACM International Conference on Auto-
matedSoftwareEngineering(ASE) .637–647. https://doi.org/10.1109/ASE.2017.
8115674
[10]Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de
OliveiraPinto,JaredKaplan,HarriEdwards,YuriBurda,NicholasJoseph,Greg
Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf,
Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail
Pavlov,AletheaPower,LukaszKaiser,MohammadBavarian,ClemensWinter,
Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fo-
tios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex
Nichol,AlexPaino,NikolasTezak,JieTang,IgorBabuschkin,SuchirBalaji,Shan-
tanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh
Achiam,VedantMisra,EvanMorikawa,AlecRadford,MatthewKnight,Miles
Brundage,MiraMurati,KatieMayer,PeterWelinder,BobMcGrew,DarioAmodei,
Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. 2021. Evaluating Large
Language Models Trained onCode. arXiv: 2107.03374 [cs.LG]
[11]Zimin Chen, Steve Kommrusch, Michele Tufano, Louis-Noël Pouchet, Denys
Poshyvanyk,andMartinMonperrus.2021. SequenceR:Sequence-to-Sequence
Learning for End-to-End Program Repair. IEEE Transactions on Software Engi-
neering47,9 (2021), 1943–1959. https://doi.org/10.1109/TSE.2019.2940179
[12]Clojure 2023. Typed Clojure: An Optional Type System for Clojure. https:
//typedclojure.org .
[13]FavioDeMarco,JifengXuan,DanielLeBerre,andMartinMonperrus.2014. Auto-
maticRepairofBuggyIfConditionsandMissingPreconditionswithSMT.In Pro-
ceedingsofthe6thInternationalWorkshoponConstraintsinSoftwareTesting,Veri/f_i-
cation,andAnalysis (Hyderabad,India) (CSTVA2014) .AssociationforComputing
Machinery,NewYork,NY,USA,30–39. https://doi.org/10.1145/2593735.2593740
[14]Yinlin Deng, Chunqiu Steven Xia, Haoran Peng, Chenyuan Yang, and Lingming
Zhang. 2023. Large Language Models Are Zero-Shot Fuzzers: Fuzzing Deep-
LearningLibrariesviaLargeLanguageModels.In Proceedingsofthe32ndACM
SIGSOFT International Symposium on Software Testing and Analysis (Seattle, WA,
USA)(ISSTA 2023) . Association forComputing Machinery, New York, NY, USA,
423–435. https://doi.org/10.1145/3597926.3598067
[15]JacobDevlin,Ming-WeiChang,KentonLee,andKristinaToutanova.2019. BERT:
Pre-trainingofDeepBidirectionalTransformersforLanguageUnderstanding.In
Proceedingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociation
forComputationalLinguistics:HumanLanguageTechnologies,Volume1(Longand
ShortPapers) .AssociationforComputationalLinguistics,Minneapolis,Minnesota,
4171–4186. https://doi.org/10.18653/v1/N19-1423
[16]Yangruibo Ding, Zijian Wang, Wasi Uddin Ahmad, Hantian Ding, Ming Tan,
Nihal Jain, Murali Krishna Ramanathan, Ramesh Nallapati, Parminder Bhatia,
Dan Roth, and Bing Xiang. 2023. CrossCodeEval: A Diverse and MultilingualBenchmark for Cross-File CodeCompletion. arXiv: 2310.11248 [cs.LG]
[17]Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong,
Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, and Ming Zhou. 2020. Code-
BERT: A Pre-Trained Model for Programming and Natural Languages. CoRR
abs/2002.08155. arXiv: 2002.08155 https://arxiv.org/abs/2002.08155
[18]Eclipse Foundation and Yuxiang Wei. 2023. UniverseFly/eclipse.jdt.ls: Modi/f_ied
EclipseJDTLS1.0.3 .https://doi.org/10.5281/zenodo.8278193
[19]Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida Wang, Eric Wallace, Freda Shi,
Ruiqi Zhong, Scott Yih, Luke Zettlemoyer, and Mike Lewis. 2023. InCoder: A
Generative Model for Code In/f_illing and Synthesis. In The Eleventh International
ConferenceonLearningRepresentations .https://openreview.net/forum?id=hQwb-
lbM6EL
[20]LucaGazzola,DanielaMicucci,andLeonardoMariani.2019. AutomaticSoftware
Repair: A Survey. IEEE Transactions on Software Engineering 45, 1 (2019),34–67.
https://doi.org/10.1109/TSE.2017.2755013
[21]Ali Ghanbari, Samuel Benton, and Lingming Zhang. 2019. Practical Program
Repair via Bytecode Mutation. In Proceedings of the 28th ACM SIGSOFT In-
ternational Symposium on Software Testing and Analysis (Beijing, China) (IS-
STA 2019) . Association for Computing Machinery, New York, NY, USA, 19–30.
https://doi.org/10.1145/3293882.3330559
[22]GithubCopilot2023. GitHubCopilot:YourAIpairprogrammer. https://github.
com/features/copilot .
[23]Daya Guo, Shuo Ren, Shuai Lu, Zhangyin Feng, Duyu Tang, Shujie LIU, Long
Zhou, Nan Duan, Alexey Svyatkovskiy,Shengyu Fu,Michele Tufano, Shao Kun
Deng, Colin Clement, Dawn Drain, Neel Sundaresan, Jian Yin, Daxin Jiang,
and Ming Zhou. 2021. GraphCodeBERT: Pre-training Code Representations
withDataFlow.In InternationalConferenceonLearningRepresentations .https:
//openreview.net/forum?id=jLoC4ez43PZ
[24]Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. 2020. The
CuriousCaseofNeuralTextDegeneration.In InternationalConferenceonLearning
Representations .https://openreview.net/forum?id=rygGQyrFvH
[25]JinruHua,MengshiZhang,KaiyuanWang,andSarfrazKhurshid.2018. SketchFix:
AToolforAutomatedProgramRepairApproachUsingLazyCandidateGener-
ation. InProceedingsofthe201826thACMJointMeetingonEuropean Software
EngineeringConferenceandSymposiumontheFoundationsofSoftwareEngineering
(Lake Buena Vista, FL, USA) (ESEC/FSE 2018) . Association for Computing Ma-
chinery, New York, NY, USA, 888–891. https://doi.org/10.1145/3236024.3264600
[26] HuggingFace2023. Hugging Face. https://huggingface.co .
[27]Hamel Husain, Ho-Hsiang Wu, Tiferet Gazit, Miltiadis Allamanis, and Marc
Brockschmidt.2019. CodeSearchNetChallenge:EvaluatingtheStateofSemantic
CodeSearch. CoRRabs/1909.09436(2019). arXiv: 1909.09436 http://arxiv.org/abs/
1909.09436
[28]JiajunJiang,YingfeiXiong,HongyuZhang,QingGao,andXiangqunChen.2018.
Shaping Program Repair Space with Existing Patches and Similar Code. In ISSTA
2018(Amsterdam, Netherlands). Association for Computing Machinery, New
York, NY, USA,298–309. https://doi.org/10.1145/3213846.3213871
[29]Nan Jiang, Thibaud Lutellier, and Lin Tan. 2021. CURE: Code-Aware Neural
MachineTranslationforAutomaticProgramRepair.In Proceedingsofthe43rd
International Conference on Software Engineering (Madrid, Spain) (ICSE ’21) . IEEE
Press,1161–1173. https://doi.org/10.1109/ICSE43902.2021.00107
[30]YanjieJiang,HuiLiu,NanNiu,LuZhang,andYaminHu.2021.ExtractingConcise
Bug-FixingPatchesfromHuman-WrittenPatchesinVersionControlSystems.In
Proceedings of the 43rd International Conference on Software Engineering (Madrid,
Spain)(ICSE ’21) .IEEEPress,686–698. https://doi.org/10.1109/ICSE43902.2021.
00069
[31]HarshitJoshi,JoséCambronero,SumitGulwani,VuLe,IvanRadicek,andGust
Verbruggen. 2023. Repair Is Nearly Generation: Multilingual Program Repair with
LLMs. AAAI. https://www.microsoft.com/en-us/research/publication/repair-is-
nearly-generation-multilingual-program-repair-with-llms/
[32]René Just, Darioush Jalali, and Michael D. Ernst. 2014. Defects4J: A Database
of Existing Faults to Enable Controlled Testing Studies for Java Programs. In
Proceedings of the 2014 International Symposium on Software Testing and Analysis
(SanJose,CA,USA) (ISSTA2014) .AssociationforComputingMachinery,New
York, NY, USA,437–440. https://doi.org/10.1145/2610384.2628055
[33]SophiaDKolak,RubenMartins,ClaireLeGoues,andVincentJosuaHellendoorn.
2022. Patch Generation with Language Models: Feasibility and Scaling Behavior.
InDeepLearningfor CodeWorkshop .https://openreview.net/forum?id=rHlzJh_
b1-5
[34]AnilKoyuncu,KuiLiu,TegawendéF.Bissyandé,DongsunKim,JacquesKlein,
Martin Monperrus, and Yves Le Traon. 2020. FixMiner: Mining Relevant Fix
Patterns for Automated Program Repair. Empirical Softw. Engg. 25, 3 (may 2020),
1980–2024. https://doi.org/10.1007/s10664-019-09780-z
[35]Xuan-Bach D. Le, Duc-Hiep Chu, David Lo, Claire Le Goues, and Willem Visser.
2017. S3: Syntax- and Semantic-Guided Repair Synthesis via Programming
by Examples. In Proceedings of the 2017 11th Joint Meeting on Foundations of
Software Engineering (Paderborn, Germany) (ESEC/FSE 2017) . Association for
ComputingMachinery,NewYork,NY,USA,593–604. https://doi.org/10.1145/
3106237.3106309
183Copilotingthe Copilots: Fusing Large LanguageModelswithCompletion EnginesforAutomatedProgram Repair ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
[36]Xuan Bach D. Le, David Lo, and Claire Le Goues. 2016. History Driven Program
Repair. In SANER (2016) , Vol. 1. 213–224. https://doi.org/10.1109/SANER.2016.76
[37]ClaireLeGoues,ThanhVuNguyen,StephanieForrest,andWestleyWeimer.2012.
GenProg:AGenericMethodforAutomaticSoftwareRepair. IEEETransactions
onSoftwareEngineering 38,1(2012),54–72. https://doi.org/10.1109/TSE.2011.104
[38]YujiaLi,DavidChoi,JunyoungChung,NateKushman,JulianSchrittwieser,Rémi
Leblond,TomEccles,JamesKeeling,FelixGimeno,AgustinDalLago,Thomas
Hubert,PeterChoy,CypriendeMassond’Autume,IgorBabuschkin,XinyunChen,
Po-Sen Huang, Johannes Welbl, Sven Gowal, Alexey Cherepanov, James Molloy,
DanielJ.Mankowitz,EsmeSutherlandRobson,PushmeetKohli,NandodeFreitas,
Koray Kavukcuoglu, and Oriol Vinyals. 2022. Competition-level code generation
withAlphaCode. Science378,6624(2022),1092–1097. https://doi.org/10.1126/
science.abq1158 arXiv:https://www.science.org/doi/pdf/10.1126/science.abq1158
[39]Yi Li, Shaohua Wang, and Tien N. Nguyen. 2020. DLFix: Context-Based Code
TransformationLearningforAutomatedProgramRepair.In Proceedingsofthe
ACM/IEEE42ndInternationalConferenceonSoftwareEngineering (Seoul,South
Korea)(ICSE’20) .AssociationforComputingMachinery,NewYork,NY,USA,
602–614. https://doi.org/10.1145/3377811.3380345
[40]Jiawei Liu, Chunqiu Steven Xia, Yuyao Wang, and Lingming Zhang. 2023. Is
Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large
Language Models for CodeGeneration. arXiv: 2305.01210 [cs.SE]
[41]Kui Liu, Anil Koyuncu, Dongsun Kim, and Tegawendé F. Bissyandé. 2019. TBar:
Revisiting Template-Based Automated Program Repair. In Proceedings of the 28th
ACMSIGSOFTInternationalSymposiumonSoftwareTestingandAnalysis (Beijing,
China)(ISSTA 2019) . Association for Computing Machinery, New York, NY, USA,
31–42.https://doi.org/10.1145/3293882.3330577
[42]Kui Liu, Jingtang Zhang, Li Li, Anil Koyuncu, Dongsun Kim, Chunpeng Ge, Zhe
Liu, Jacques Klein, and Tegawendé F. Bissyandé. 2023. Reliable Fix Patterns
Inferred from Static Checkers for Automated Program Repair. ACM Trans. Softw.
Eng. Methodol. 32, 4, Article 96 (may 2023), 38 pages. https://doi.org/10.1145/
3579637
[43]FanLong and Martin Rinard.2015. StagedProgram Repair with Condition Syn-
thesis.In Proceedingsofthe201510thJointMeetingonFoundationsofSoftware
Engineering (Bergamo, Italy) (ESEC/FSE 2015) . Association for Computing Ma-
chinery, New York, NY, USA, 166–178. https://doi.org/10.1145/2786805.2786811
[44]ThibaudLutellier,HungVietPham,LawrencePang,YitongLi,MoshiWei,and
Lin Tan. 2020. CoCoNuT: Combining Context-Aware Neural Translation Models
Using Ensemble for Program Repair. In Proceedings of the 29th ACM SIGSOFT
InternationalSymposiumonSoftwareTestingandAnalysis (VirtualEvent,USA)
(ISSTA2020) .AssociationforComputingMachinery,NewYork,NY,USA,101–114.
https://doi.org/10.1145/3395363.3397369
[45]Matias Martinez,ThomasDurieux, RomainSommerard, JifengXuan,andMartin
Monperrus.2017. AutomaticRepairofRealBugsinJava:ALarge-ScaleExperi-
mentontheDefects4jDataset. EmpiricalSoftw.Engg. 22,4(aug2017),1936–1964.
https://doi.org/10.1007/s10664-016-9470-4
[46]Matias Martinez and Martin Monperrus. 2016. ASTOR: A Program Repair
Library for Java (Demo). In Proceedings of the 25th International Symposium
on Software Testing and Analysis (Saarbrücken, Germany) (ISSTA 2016) . As-
sociation for Computing Machinery, New York, NY, USA, 441–444. https:
//doi.org/10.1145/2931037.2948705
[47]Sergey Mechtaev, Jooyong Yi, and Abhik Roychoudhury. 2016. Angelix: Scalable
MultilineProgramPatchSynthesisviaSymbolicAnalysis.In Proceedingsofthe
38thInternationalConferenceonSoftwareEngineering (Austin,Texas) (ICSE’16) .
Association for Computing Machinery, New York, NY, USA, 691–701. https:
//doi.org/10.1145/2884781.2884807
[48]Microsoft 2023. Language Server Protocol. https://microsoft.github.io/language-
server-protocol .
[49] Microsoft 2023. TypeScript. https://www.typescriptlang.org .
[50]Erik Nijkamp, Hiroaki Hayashi, Caiming Xiong, Silvio Savarese, and Yingbo
Zhou.2023. CodeGen2:LessonsforTrainingLLMsonProgrammingandNatural
Languages. arXiv: 2305.02309 [cs.LG]
[51]Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou,
SilvioSavarese,andCaimingXiong.2022. CodeGen:AnOpenLargeLanguage
Modelfor Codewith Multi-Turn ProgramSynthesis. arXiv:2203.13474.
[52]Gabriel Poesia, Alex Polozov, Vu Le, Ashish Tiwari, Gustavo Soares, Christopher
Meek, and SumitGulwani. 2022. Synchromesh: Reliable Code Generationfrom
Pre-trained Language Models. In International Conference on Learning Represen-
tations.https://openreview.net/forum?id=KmtVD97J43e
[53]Julian Aron Prenner, Hlib Babii, and Romain Robbes. 2022. Can OpenAI’s Codex
Fix Bugs? An Evaluation on QuixBugs. In APR ’22(Pittsburgh, Pennsylvania).
Associationfor ComputingMachinery, New York,NY, USA,69–75. https://doi.
org/10.1145/3524459.3527351
[54] Python2023. TypeHintsin Python. https://peps.python.org/pep-0484/ .
[55]Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016. Neural Machine
TranslationofRareWordswithSubwordUnits.In Proceedingsofthe54thAnnual
Meeting oftheAssociationforComputational Linguistics(Volume1: Long Papers) .
AssociationforComputationalLinguistics,Berlin,Germany,1715–1725. https:
//doi.org/10.18653/v1/P16-1162[56]Dominik Sobania, Martin Briesch, Carol Hanna, and Justyna Petke. 2023.
An Analysis of the Automatic Bug Fixing Performance of ChatGPT.
arXiv:2301.08653 [cs.SE]
[57]Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014. Sequence to Sequence
LearningwithNeuralNetworks.In AdvancesinNeuralInformationProcessing
Systems,Z.Ghahramani,M.Welling,C.Cortes,N.Lawrence,andK.Q.Weinberger
(Eds.), Vol. 27. Curran Associates, Inc. https://proceedings.neurips.cc/paper_
/f_iles/paper/2014//f_ile/a14ac55a4f27472c5d894ec1c3c743d2-Paper.pdf
[58]MicheleTufano,Cody Watson,GabrieleBavota, Massimiliano Di Penta,Martin
White,andDenysPoshyvanyk.2019. AnEmpiricalStudyonLearningBug-Fixing
Patches in the Wild via Neural Machine Translation. ACM Trans. Softw. Eng.
Methodol. 28, 4, Article 19 (sep 2019), 29 pages. https://doi.org/10.1145/3340544
[59]Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N. Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is All You
Need.InProceedingsofthe31stInternationalConferenceonNeuralInformation
ProcessingSystems (LongBeach,California,USA) (NIPS’17).CurranAssociates
Inc.,Red Hook,NY, USA,6000–6010.
[60] YueWang,Hung Le,Akhilesh DeepakGotmare, NghiD. Q.Bui,JunnanLi,and
Steven C. H. Hoi. 2023. CodeT5+: Open Code Large LanguageModelsforCode
Understandingand Generation. arXiv: 2305.07922 [cs.CL]
[61]Yue Wang, Weishi Wang, Sha/f_iq Joty, and Steven C.H. Hoi. 2021. CodeT5:
Identi/f_ier-aware Uni/f_ied Pre-trained Encoder-Decoder Models for Code Un-
derstanding and Generation. In Proceedings of the 2021 Conference on Empir-
ical Methods in Natural Language Processing . Association for Computational
Linguistics, Online and Punta Cana, Dominican Republic, 8696–8708. https:
//doi.org/10.18653/v1/2021.emnlp-main.685
[62]YuxiangWei,ChunqiuStevenXia,andLingmingZhang.2023. ESEC/FSE’23Arti-
factfor"CopilotingtheCopilots:FusingLargeLanguageModelswithCompletion
EnginesforAutomatedProgramRepair". https://doi.org/10.5281/zenodo.8281250
[63]Ming Wen, Junjie Chen, Rongxin Wu, Dan Hao, and Shing-Chi Cheung. 2018.
Context-Aware Patch Generationfor Better Automated Program Repair. In Pro-
ceedingsofthe40thInternationalConferenceonSoftwareEngineering (Gothenburg,
Sweden)(ICSE ’18) . Association for Computing Machinery, New York, NY, USA,
1–11.https://doi.org/10.1145/3180155.3180233
[64]Chunqiu Steven Xia, Yifeng Ding, and Lingming Zhang. 2023. Revisiting the
PlasticSurgeryHypothesisviaLargeLanguageModels. arXiv: 2303.10494 [cs.SE]
[65]Chunqiu Steven Xia, Matteo Paltenghi, Jia Le Tian, Michael Pradel, and
Lingming Zhang. 2023. Universal Fuzzing via Large Language Models.
arXiv:2308.04748 [cs.SE]
[66]Chunqiu Steven Xia, Yuxiang Wei, and Lingming Zhang. 2023. Automated
ProgramRepairintheEraofLargePre-TrainedLanguageModels.In Proceedings
ofthe45thInternationalConferenceonSoftwareEngineering (Melbourne,Victoria,
Australia) (ICSE ’23) . IEEE Press, 1482–1494. https://doi.org/10.1109/ICSE48619.
2023.00129
[67]Chunqiu Steven Xia and LingmingZhang. 2022. Less Training, More Repairing
Please: Revisiting Automated Program Repair via Zero-Shot Learning. In Pro-
ceedings of the 30th ACM Joint European Software Engineering Conference and
Symposium on the Foundations of Software Engineering (Singapore, Singapore)
(ESEC/FSE 2022) . Association for Computing Machinery, New York, NY, USA,
959–971. https://doi.org/10.1145/3540250.3549101
[68]Chunqiu Steven Xia and Lingming Zhang. 2023. Conversational Automated
ProgramRepair. CoRRabs/2301.13246(2023). https://doi.org/10.48550/ARXIV.
2301.13246 arXiv:2301.13246
[69]Chunqiu StevenXiaandLingmingZhang. 2023. Keep the ConversationGoing:
Fixing162outof337bugsfor$0.42eachusingChatGPT. arXiv: 2304.00385 [cs.SE]
[70]Frank F. Xu, Uri Alon, Graham Neubig, and Vincent Josua Hellendoorn. 2022.
ASystematic EvaluationofLargeLanguageModelsofCode.In Proceedingsof
the6thACMSIGPLANInternationalSymposiumonMachineProgramming (San
Diego,CA,USA) (MAPS 2022) .Association forComputingMachinery,NewYork,
NY, USA,1–10. https://doi.org/10.1145/3520312.3534862
[71]ZhilinYang,ZihangDai,YimingYang,JaimeCarbonell,RuslanSalakhutdinov,
andQuocV.Le.2019. XLNet:GeneralizedAutoregressivePretrainingforLanguage
Understanding . Curran Associates Inc.,Red Hook,NY, USA.
[72]He Ye, Matias Martinez, and Martin Monperrus. 2022. Neural Program Re-
pair with Execution-Based Backpropagation. In Proceedings of the 44th Inter-
national Conference on Software Engineering (Pittsburgh, Pennsylvania) (ICSE
’22). Association for Computing Machinery, New York, NY, USA, 1506–1518.
https://doi.org/10.1145/3510003.3510222
[73]FengjiZhang,BeiChen,YueZhang,JackyKeung,JinLiu,DaoguangZan,YiMao,
Jian-Guang Lou, and Weizhu Chen. 2023. RepoCoder: Repository-Level Code
CompletionThroughIterativeRetrievalandGeneration. arXiv: 2303.12570 [cs.CL]
[74]QihaoZhu, ZeyuSun, Yuan-anXiao,WenjieZhang, Kang Yuan, YingfeiXiong,
and Lu Zhang.2021. A Syntax-Guided EditDecoder forNeuralProgramRepair.
InESEC/FSE 2021 (Athens, Greece). Association for Computing Machinery, New
York, NY, USA,341–353. https://doi.org/10.1145/3468264.3468544
Received 2023-02-02; accepted 2023-07-27
184