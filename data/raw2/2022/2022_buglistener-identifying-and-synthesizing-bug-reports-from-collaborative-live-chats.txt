BugListener: Identifying and Synthesizing Bug Reports from
Collaborative Live Chats
Lin Shi1,2, Fangwen Mu1,2, Yumin Zhang1,2,Y eY a n g5, Junjie Chen6, Xiao Chen1,2, Hanzhi
Jiang1,2,Ziyou Jiang1,2, Qing Wang1,2,3,4âˆ—
1Laboratory for Internet Software Technologies, Institute of Software Chinese Academy of Sciences, Beijing, China
2University of Chinese Academy of Sciences, Beijing, China
3State Key Laboratory of Computer Science, Institute of Software Chinese Academy of Sciences, Beijing, China
4Science & Technology on Integrated Information System Laboratory,
Institute of Software Chinese Academy of Sciences, Beijing, China
5School of Systems and Enterprises, Stevens Institute of Technology, Hoboken, NJ, USA
6Tianjin University, College of Intelligence and Computing, Tianjin, China
{shilin,fangwen2020,yumin2020,chenxiao2021,hanzhi2021,ziyou2019,wq}@iscas.ac.cn,
yyang4@stevens.edu, junjiechen@tju.edu.cn
ABSTRACT
In community-based software development, developers frequently
relyonlive-chattingtodiscussemergentbugs/errorstheyencounter
in daily development tasks. However, it remains a challenging task
to accurately record such knowledge due to the noisy nature of
interleaveddialogsinlivechatdata.Inthispaper,wefirstformulate
thetaskofidentifyingandsynthesizingbugreportsfromcommu-
nity live chats, and propose a novel approach, named BugListener,
toaddressthechallenges.Specifically,BugListenerautomatesthree
sub-tasks: 1) Disentangle the dialogs from massive chat logs by
usingaFeed-Forwardneuralnetwork;2)Identifythebug-report
dialogs from separated dialogs by leveraging the Graph neural net-
work to learn the contextual information; 3) Synthesize the bug
reports by utilizing Transfer Learning techniques to classify the
sentences into: observed behaviors (OB), expected behaviors (EB),
andstepstoreproducethebug (SR).BugListenerisevaluatedonsix open source projects. The results show that: for bug report
identification,BugListenerachievestheaverageF1of77.74%,im-provingthebestbaselineby12.96%;andforbugreportsynthesis
task, BugListener could classify the OB, EB, and SR sentences with
theF1of84.62%,71.46%,and73.13%,improvingthebestbaselinesby
9.32%, 12.21%, 10.91%, respectively. A human evaluation study also
confirmstheeffectivenessofBugListeneringeneratingrelevantandaccuratebugreports.Thesedemonstratethesignificantpotentialof
applying BugListener in community-based software development,
for promoting bug discovery and quality improvement.
âˆ—Corresponding author.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Â© 2022 Association for Computing Machinery.
ACM ISBN 978-1-4503-9221-1/22/05...$15.00
https://doi.org/10.1145/3510003.3510108KEYWORDS
Bug Report Generation, Live Chats Mining, Open Source
ACM Reference Format:
LinShi1,2,FangwenMu1,2,YuminZhang1,2,YeYang5,JunjieChen6,Xiao
Chen1,2,HanzhiJiang1,2,ZiyouJiang1,2,QingWang1,2,3,4.2022. BugListener:
IdentifyingandSynthesizingBugReportsfromCollaborativeLiveChats
.In44thInternationalConferenceonSoftwareEngineering(ICSEâ€™22),May
21â€“29, 2022, Pittsburgh, PA, USA. ACM, New York, NY, USA, 13 pages. https:
//doi.org/10.1145/3510003.3510108
1 INTRODUCTION
Collaborative communication via live chats allows developers to
seek information and technicalsupport, share opinions and ideas,
discuss issues, and form community development [ 14,16], in a
moreefficientwaycomparedwithasynchronouscommunication
suchasemailsorforums[ 42,65,66].Consequently,collaborative
livechattinghasbecomeanintegralpartofmostsoftwaredevelop-
mentprocesses,notonlyforopensourcecommunitiesconstituting
globally distributed developers, but also for software companies to
facilitatein-houseteamcommunicationandcoordination,esp.in
accommodating remote work due to the COVID-19 pandemic [ 49].
Existingliteraturereportsthatdevelopersarelikelytojoincol-
laborative live chats to discuss problems they encountered during
development [ 5,6,13,52]. Shi et al. [ 62] analyzed 749 live-chat
dialogs from eight OSS communities, and found 32% of the dialogs
are reporting unexpected behaviors, such as something does not
work,reliabilityissues,performanceissues,anderrors.Infact,these
reportingproblemsusuallyimplypotentialbugsthathavenotbeen
found. Fig. 1 illustrates an example slice of collaborative live chats
[1] from the Docker community. In this conversation, developer
DavidreportedaperformancebugthatDockertookalotofdisk
space, and Lena indeed confirmed Davidâ€™s feedback. Then, Jack
provided a suggestion to help resolve this problem but failed in the
end. Althoughdevelopers haverevealed this bugvia collaborative
livechats,thehighlydynamicandmulti-threadingnatureoflive
chattingmakesthisbug-reportconversationgetquicklyfloodedby
new incoming messages. After several months, Docker developers
calltoremembrancethisbugwiththefrustratedcommentssuch
as â€œlost all my system backupsâ€ and â€œitâ€™s a shameâ€, when thereare several formal bug reports (i.e., #30254, #31105, and #32420)
2992022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Lin Shi et al.
ÆµÅÆŒÄÆ‰Å½ÆŒÆš
'DYLG'HF
,WKLQN,KDYHVRPHWKLQJLPSRUWDQWWRVD\,W
VWKHVHFRQGWLPH
WKDWWKLVKDSSHQVZLWKPH ,LQVWDOOGRFNHURQ/LQX[0LQW $IWHU
VRPHKRXUVWKHGLVNLVIXOO ,ORVWDOOP\V\VWHPEDFNXSV,WKLQN,
KDYHWRUHSRUWWKLVEHFDXVHLW
VDVKDPH:KHQ,GHOHWHDOO
GRFNHULPDJHVDQGXQLQVWDOOGRFNHU,KDYH*%IUHH6RPHRQHWHOOVPH
+RZWKLVLVHYHQSRVVLEOHWKDWGRFNHUXVHV
*%" &DQGRFNHUDYRLGXVLQJVXFKKXJHGLVN"3OHDVHIL[WKDW
8QWLOWKHUH,ZLOOEHXVLQJGRFNHURQDYLUWXDOPDFKLQHEHFDX VH,
FDQ
WWUXVWWKLVVRIWZDUHDQ\PRUH
'HFJUHDWIHHGEDFN
/HQD
-DFN
'HF#-DFN'RHVQ
WPDNHDQ\VHQVH
$IWHU,UHVWDUWP\FRPSXWHUWKH
GLVNIUHHVSDFHNHHSVGHFUHDVLQJ'HF#'DYLGLWVRXQGVOLNH\RXSHUIRUPHGDLQVWHDGRIDDQGHQGHGXSILOOLQJ\RXUGLVNGRFNHUSXOOVRPHKXJHUHSRVLWRU\
GRFNHUSXOOVRPHKXJHUHSRVLWRU\VSHFLILFWDJ
'DYLG
'HVFULSWLRQ
,KDYHVRPHWKLQJLPSRUWDQWWRVD\,W
VWKHVHFRQGWLPHWKDWWKLVKDSSHQV
ZLWKPH,ORVWDOOP\V\VWHPEDFNXSV,WKLQN,KDYHWRUHSRUW WKLV
EHFDXVHLW
VDVKDPH:KHQ,GHOHW HDOOGRFNHULPDJHVDQGXQLQVWDOO
GRFNHU,KDYH*%IUHH+RZWKLVLVHYHQSRVVLEOHWKDWGRF NHUXVHV
*%"8QWLOWKHUH,ZLOOEHXVLQJGRFNHURQDYLUWXDOPDFKLQHEHFDXVH
,FDQ
WWUXVWWKLVVRIWZDUHDQ\PRUH2EVHUYHG%HKDYLRU
$IWHUVRPHKRXUVWKHGLVNLVIXOO([SHFWHG%HKDYLRU
&DQGRFNHUDYRLGXVLQJVXFKKXJHGLVN"6WHSVWRUHSURGXFH
,LQVWDOOGRFNHURQ/LQX[0LQW
Fig. 1: An example of identifying and synthesizing a bug
report from the Docker collaborative live chats.
reflecting the similar problem that was submitted to the GitHub
bug repository. We can observe that, if the bug discussed in live
chatscouldbeidentifiedanddocumentedinatimelymanner,the
bugmayhavebeenresolvedearlierbytheDockercommunity.Con-
sequently, the Docker community may have the opportunity to
prevent many failure incidents associated with this bug [54].
Althoughthelivechatscouldbeatremendousdatasourceem-
bedded withbug reportsover time,it is quitechallenging tomine
massivechatmessagesduetothefollowingbarriers. (1)Entangled
andnoisydata.Livechatstypicallycontainentangled,informal
conversationscoveringawiderangeoftopics[ 44].Moreover,there
exist noisy utterances such as duplicate and off-topic messagesin chat messages that do not provide any valuable information.Such entangled and noisy nature of live chat data poses a diffi-
cultyinanalyzingandinterpretingthecommunicativedialogues.
(2) Understanding complex dialog structure . In complex di-
alogs,developersusuallyeitherconfirmorrejectabugreportby
replying to previous utterances. Since the â€œreply-toâ€ relationship is
not linear to the dialog structure, it is necessary to employ moresophisticated techniques to handle nonlinear dialog structure, in
orderto learnprecise feedback andreduce thelikelihoodof intro-
ducing false-positive.For example,the utteranceâ€œWhen Iuse the
â€˜automationNameâ€™ key, I get an error that it is not a recognized
W3C capability.â€ is very likely to be classified as a bug proposal.
However, when examining the dialog, we found that the following-
up utterances pointed out the error was not a valid bug. Instead, it
was caused by the userâ€™s action of importing incorrect packages.
(3)Extremelyexpensiveannotation.Thelivechatsaretypically
largeinsize.Itisextremelyexpensivetoannotatebugreportsfrom
chat messages due to the high volume corpus and a low propor-tion of ground-truth data. Only a few labeled chat messages are
categorizedintobugreporttypes.Thus,thelabeledresourcesforsynthesizingbugreportsarealsolimited.Howtomakemaximaluse
ofthelimitedlabeleddatatoclassifytheunlabeledchatmessages
accurately becomes a critical problem.
In this work, we propose a novel approach, named BugListener,
whichcanidentifybug-reportdialogsfrommassivechatlogsand
synthesize complete bug reports from predicted bug-report dialogs.
BugListeneremploysadeepgraph-basednetworktocapturethe
complexdialog structure,and atransfer-learning networkto syn-
thesize bug reports. Specifically, BugListener addresses the chal-
lengeswiththree elaboratedsub-tasks:1)Disentanglethe dialogs
frommassivechatlogsbyusingaFeed-Forwardneuralnetwork.
2) Identify bug-report dialogs from separated dialogs by modeling
theoriginaldialogtothegraph-structureddialogandleveraging
the Graph neural network (GNN) to learn the complex context
representation.3)Synthesizethebugreportsfrompredictedbug-
report dialogs using Transfer Learning techniques. Specifically, we
use the pre-trained BERT model provided by Devlin et al. [ 21]
and fine-tune it twice using the external BEE dataset [ 68] and our
owndataset,respectively.Toevaluatetheproposedapproach,we
collect and annotate 1,501 dialogs from six popular open-source
projects. The experimental results show that our approach signifi-
cantlyoutperformsallotherbaselinesinbothtwotasks.Forbug
report identification task, BugListener achieves an average F1 of
77.74%, improving the best baseline by 12.96%. For bug report syn-
thesistask,BugListenercouldclassifysentencesdepictingobserved
behavior (OB), expected behavior (EB), and steps to reproduce (SR)
with the F1 of 84.62%, 71.46%, and 73.13%, respectively, improving
thebestbaselineby9.32%,12.21%,and10.91%,respectively.Wealsoconductahumanevaluationtoassessthecorrectnessandqualityof
the generated bug reports, showing that BugListener can generate
relevant and accurate bug reports.
The main contributions and their significance are as follows.
â€¢We propose an automated approach, named BugListener, based
on a deep graph-based network to effectively identify the bug-report dialogs, and a transfer-learning network to extensively
synthesizebugreports.WebelievethatBugListenercan facili-
tatecommunity-basedsoftwaredevelopmentbypromot-
ing bug discovery and quality improvement.
â€¢We evaluate the BugListener by comparing with state-of-the-art
baselines, with superior performance.
â€¢Dataavailability:publiclyaccessibledatasetandsourcecode
[2] to facilitate the replication of our study and its application in
other contexts.
In the remaining of this paper, Sec. 2 defines the problem. Sec. 3
elaboratestheapproach.Sec.4presentstheexperimentalsetup.Sec.5demonstratestheresultsandanalysis.Sec.6describesthehuman
evaluation. Sec. 7 discusses indications and threats to validity. Sec.
8 introduces the related work. Sec. 9 concludes our work.
2 PROBLEM DEFINITION
To facilitate the problem definition and further discussion, we first
provide some basic concepts and notations used in this study:
â€¢A chat log (L) corresponds to a sequence of utterances ğ‘¢ğ‘–in
chronological order, denoted by ğ¿={ğ‘¢1,ğ‘¢2,...,ğ‘¢ğ‘›}.
â€¢Anutterance( ğ‘¢ğ‘–)consistsofthetimestamp,developerrole,and
textual message, denoted by ğ‘¢ğ‘–=<ğ‘¡ğ‘–ğ‘šğ‘’,ğ‘Ÿğ‘œğ‘™ğ‘’,ğ‘¡ğ‘’ğ‘¥ğ‘¡ >.
300â€¢Adeveloperrole( ğ‘Ÿğ‘œğ‘™ğ‘’)inadialogisdefinedaseithera reporter
oradiscussant.A reporterreferstoadeveloperlaunchingadialog,
whileadiscussant referstoadeveloperparticipatinginthedialog.
Denoted by ğ‘Ÿğ‘œğ‘™ğ‘’âˆˆ{ğ‘Ÿğ‘’ğ‘ğ‘œğ‘Ÿğ‘¡ğ‘’ğ‘Ÿ,ğ‘‘ğ‘–ğ‘ ğ‘ğ‘¢ğ‘ ğ‘ ğ‘ğ‘›ğ‘¡ }.
â€¢A dialog ( ğ·ğ‘–)is a sequence of ğ‘˜utterances ğ‘¢ğ‘–, retaining the
â€œreply-toâ€relationshipamongutterances,denotedby ğ·ğ‘–={ğ‘¢R1
1,
ğ‘¢R2
2,...,ğ‘¢Rğ‘˜
ğ‘˜}.
â€¢Arelationalcontextforutterance ğ‘¢ğ‘–(Rğ‘–)isasetofundirected
"reply-to"relationshipidentifiers,eachidentifiercorresponding
to a message replying to or replied by ğ‘¢ğ‘–. If two utterances share
the same superscript, then it implies one replies to the other. For
example, ğ·={ğ‘¢ğ‘…1,ğ‘…2
1,ğ‘¢ğ‘…1
2,ğ‘¢ğ‘…2
3}represents that both ğ‘¢2andğ‘¢3
reply to ğ‘¢1.
Our work then targets at automatically identifying and synthe-
sizing bug reports from community live chats. We formulate the
task of automatic bug report generation from live chats with three
elaborated sub-tasks:
(1)Dialogdisentanglement:Giventhehistoricalchatlog ğ¿,dis-
entangle it into separate dialogs {ğ·1,ğ·2,...,ğ·ğ‘›}.
(2)Bug-ReportdialogIdentification(BRI):Givenaseparatedialog
ğ·ğ‘–,findabinaryfunction ğ‘“sothat ğ‘“(ğ·ğ‘–)candeterminewhether
the dialog involves bug-reporting messages.
(3) Bug-Report Synthesis (BRS): Assuming that the content of
bugreportsismadeupofsentencesextractedfromthereportersâ€™ut-
terances,givenallthereporterâ€™sutterances ğ‘ˆğ‘Ÿinthepredictedbug-
reportdialog ğ·ğ‘–,findafunction ğ‘”sothatğ‘”(ğ‘ˆğ‘Ÿ)={ğ·ğ¸ğ‘†,ğ‘‚ğµ,ğ¸ğµ,ğ‘†ğ‘… },
whereğ·ğ¸ğ‘†,ğ‘‚ğµ,ğ¸ğµ, andğ‘†ğ‘…representthecollectionsofsentences
inğ‘ˆğ‘Ÿthat depict Description, Observed Behavior, Expected Behavior,
andStep to Reproduce.
3 APPROACH
TherearefivemainstepstoconstructBugListener,asshowninFig.
2. These include:(1) dialog disentanglement and data augmentation
to prepare the data; (2) utterance embedding to convert utterances
intosemanticvectors;(3)graph-basedcontextembeddingtocon-
struct dialog graph and learn the contextual representation by em-
ploying a two-layer graph neural network; (4) dialog embedding
andclassificationtolearnwhetheradialogisabug-reportdialog;
and(5)bugreportsynthesistoformacompletebugreport.Next,
we present details of each step.
3.1 Data Disentanglement and Augmentation
In this step, We first separate dialogs from the interleaved chat
logsusingaFeed-Forwardnetwork.Then,weaugmenttheoriginal
dialog dataset utilizing a heuristic data augmentation method to
overcome the insufficient labeled resource challenge.
3.1.1 Dialog Disentanglement. Utterances from a single conver-
sation thread are usually interleaved with other ongoing conver-sations, and therefore need to be divided into individual dialogsaccordingly. To find a reliable disentanglement model, we exper-iment with four state-of-the-art dialog disentanglement models,i.e., BILSTM model [
29], BERT model [ 21], E2E model [ 44], and
FF model, using our manual disentanglement dataset as detailed
inSection4.1later.Thecomparisonresultsfromourexperiments
show that the FF model significantly outperforms the others on
disentanglingdeveloperlivechatbyachievingthehighestscoresonNMI,Shen-F,F1,andARImetrics.Theaveragescoresofthese
four metrics are 0.74, 0.81, 0.47, and 0.57 respectively1.
Specifically, the FF model is a Feed-Forward neural network
with 2 layers, 512-dimensional hidden vectors, and softsign non-
linearities. It employs a two-stage strategy to resolve dialog disen-
tanglement. First, the FF model predicts the â€œreply-toâ€ relationship
between every two utterances in the chat log based on averaged
pre-trained word embedding and many hand-engineered features.
Second, it clusters the utterances that can reach each other via the
â€œreply-toâ€ predictions as one dialog. Thus, the FF-model can output
not only the utterances in one dialog but also their â€œreply-toâ€ rela-
tionship,whichisessentialforconstructingtheinternalnetwork
structure of dialogs.
3.1.2 Data Augmentation. Toaddressthelimitedannotationand
data imbalance issue, a heuristic data augmentation mechanism is
employed to enlarge the dataset through dialog mutation. The key
todialogmutationistoaltertheutteranceformsandretaintheir
semantics.Toachievethat,wemutatealongutterancebyreplacing
a few words with their synonyms, or mutate a short utteranceby replacing it with another short utterance. Specifically, givena dialog
ğ·={ğ‘¢1,ğ‘¢2,...,ğ‘¢ğ‘›}, we generate ğ‘different mutants by
iterating the following steps ğ‘times. For each utterance ğ‘¢ğ‘–in a
dialogğ·, we perform either an utterance-level replacement or a
word-level replacement based on its length, and generate a new
utterance ğ‘¢ğ‘–/prime=Î“(ğ‘¢ğ‘–):
âˆ€ğ‘¢ğ‘–âˆˆğ·,Î“(ğ‘¢ğ‘–)=/braceleftBigg
ğ‘¢ğ‘˜|ğ‘¢ğ‘–|â‰¤ğœƒ
SR(ğ‘¢ğ‘–)|ğ‘¢ğ‘–|>ğœƒ(1)
where|ğ‘¢ğ‘–|denotes the length of ğ‘¢ğ‘–, andğœƒis a predefined threshold
(We empiricallyset ğœƒ=5inthisstudy). ğ‘¢ğ‘˜istheutterancethatis
randomly selected from the entire dialog corpus with a length less
thanğœƒ.SR(ğ‘¢ğ‘–)denotes the synonym-replacement operation that
hasbeenwidelyusedbyNLPtextaugmentationtask[ 76].Afterall
utterances in dialog ğ·are processed, we then obtain a new dialog
ğ·ğ‘ğ‘¢ğ‘”={ğ‘¢1/prime,ğ‘¢2/prime,...,ğ‘¢ğ‘›/prime}.
Toachievedatabalancing,foreachproject,wefirstaugmentthe
NBRdialogstoacertainnumber,thenweaugmentBRdialogsto
matchthesamenumber.TakingtheAngularprojectasanexample,
wefirstaugmenttheNBRdialogsfrom179to358(2times),then
augment the BR dialogs from 86 to 358 for balancing purposes.
3.2 Utterance Embedding
The utterance embedding aims to encode semantic information of
words, as well as to learn the representation of utterances.
Word encoding. We encode each word in utterances into a
semantic vector by utilizing the deep pre-trained BERT model [ 21],
whichhasachievedimpressivesuccessinmanynaturallanguage
processingtasks[ 47,72].ThelastlayeroftheBERTmodeloutputs
a 768-dimensional contextualized word embedding for each word.
Utteranceencoding. Withallthewordvectors,weuseTextCNN
[77]tolearntheutterancerepresentation.TextCNNisaclassical
method for sentence encoding by using a shallow ConvolutionNeural Network (CNN) [
38] to learn sentence representation. It
hasanadvantageoverlearningoninsufficientlabeleddata,since
1Duetospace,experimentaldetailsonevaluationexistingdisentanglementmodels
are provided on our website [2].
301ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Lin Shi et al.
İ„à¬¸ İ„à¬·İ„à¯œ İ„à¬¶İ‘à¬¶ İ‘à¯œ
İ‘à¬¸ İ‘à¬·
X
X
X3.2. Utterance Embedding 3.1 Dialog Di sentanglement
and Augmentation
Dialog (D)3.3 Graph-based Co ntext Embedding
Dialog (Dâ€™)Construct Dialog 
Graph G
İ‘à¬µ
â€¦
İ„à¬µ
â€¦
BERTTextCNNİ‘à¬µ
İ‘à¯œ
İ‘à¯¡ â€¦â€¦
â€¦ â€¦İ‘à¬µ
İ‘à¯œ
İ‘à¯¡Embed Graph Context
â€¦İ‘à¬µ
İ„à¬µİ‘à¯¡
İ„à¯¡
â€¦
â€¦
Label=NBR3.4 Dialog Embeddin g and Classification 3.5 Bug Reports SynthesisDialog (D)Chat log
Data 
Augmentation
Augmented 
Dialog DatasetDialog 
DatasetDialog
Disentanglementâ€¦
Dialog embedding
FC LayerSum Pooling
SoftmaxÜ¿à¬µ Ü¿à¯¡
Label = BRMax Pooling
Des: XXXX
OB: XXXXEB: XXXXSR: XXXX
Bug ReportOBLarge Annotated
5,067 Bug Reports
( Externel )
à¢˜à¢Ô¢à¢˜à¢
EB SR DESBug Report Dialogs
( Internel )
gEnglish Wikipedia 
and BooksCorpus
( Externel )
Prune Reporterâ€™s 
utterances
FC LayerFine-tuned 
BERT
FC LayerTwice 
Fine-tuned 
BERTPre-trained 
BERT
Fig. 2: Overview of BugListener.
itemploysaconcisenetworkstructureandasmallnumberofpa-
rameters.Weusefourdifferentsizeconvolutionkernelswith100
featuremapsineachkernel.Theconvolutedfeaturesarefedtoa
Max-Pooling layer followed by the ReLUactivation [ 50]. Then, we
concatenate these features and input them into a 100-dimensional
full-connectedlayertoobtainthe100-dimensionalutteranceem-
bedding/vecğ‘¢ğ‘–. After encoding all the utterances of a dialog ğ·, we can
get utterance-embedded dialog ğ·/prime={/vecğ‘¢1,/vecğ‘¢2,.. ,/vecğ‘¢ğ‘›}.
3.3 Graph-based Context Embedding
Thisstepaimstocapturethegraphicalcontextofutterancesinone
dialog. Given the utterance-embedded dialog ğ·/prime={/vecğ‘¢1,/vecğ‘¢2,.. ,/vecğ‘¢ğ‘›}
with the set of â€œreply-toâ€ relationship R, we first construct a dialog
graphğº(ğ·/prime). Then, we learn the contextual information of ğº(ğ·/prime)
via a two-layer graph neural network, and output ğºğ‘(ğ·/prime)where
each vertex in ğºğ‘(ğ·/prime)restores the contextual information of the
correspondingvertexin ğº(ğ·/prime).Finally,Weconcatenateeachvertex
inğº(ğ·/prime)withitscorrespondingvertexin ğºğ‘(ğ·/prime),andoutputthe
sequence of combination as the dialog vector ğ¶={/vecğ‘1,/vecğ‘2,...,/vecğ‘ğ‘›}.
3.3.1 Construct Dialog Graph. Giventheutterance-embeddeddi-
alogğ·/primeconsisting of ğ‘utterances and the set of â€œreply-toâ€ rela-
tionshipR,weconstructadirectedgraph ğº(ğ·/prime)=(V,E,W,T),
whereVisthevertexset, Eistheedgeset, Wistheweightsetof
edges, and Tis the set of edge types. More specifically:
Vertex.Eachutteranceisrepresentedasavertex ğ‘£ğ‘–âˆˆV.W euse
theutteranceembedding /vecğ‘¢ğ‘–toinitializethecorrespondingvertex
ğ‘£ğ‘–. Theğ‘£ğ‘–will be updated during the graph learning process.
Edge.We construct the edge set Ebased on the â€œreply-toâ€ re-
lationship. The edge ğ‘’ğ‘–ğ‘—âˆˆEdenotes that there is a â€œreply-toâ€
relationship between ğ‘¢ğ‘–andğ‘¢ğ‘—.
Edge Weight. The edge weight ğ‘¤ğ‘–ğ‘—is the weight of the edge
ğ‘’ğ‘–ğ‘—, with 0 â‰¤ğ‘¤ğ‘–ğ‘—â‰¤1, where ğ‘¤ğ‘–ğ‘—âˆˆWandğ‘–, ğ‘—âˆˆ[1,2,...,ğ‘].
ğ‘¤ğ‘–ğ‘—is determined by the similarity of /vecğ‘¢ğ‘–and/vecğ‘¢ğ‘—. Specifically, we
employ pair-wise dot product to compute the similarity score of
pair vertices. Then, we normalize the similarity score and calculate
the edge weight ğ‘¤ğ‘–ğ‘—:
ğ‘¤ğ‘–ğ‘—=/vecğ‘¢ğ‘–TÂ·ğ‘Šğ‘’/vecğ‘¢ğ‘—
/summationtext.1
ğ‘˜âˆˆğ‘(ğ‘–,âˆ—)/vecğ‘¢ğ‘–TÂ·ğ‘Šğ‘’/vecğ‘¢ğ‘˜(2)whereğ‘Šğ‘’isatrainablematrixusedtoperformlinearfeaturetrans-
formationonvertex, ğ‘(ğ‘–,âˆ—)denotesthesetofverticesthatvertex
ğ‘£ğ‘–points to.
EdgeType. Wedefinethetypeoftheedge ğ‘’ğ‘–ğ‘—asğ‘¡ğ‘–ğ‘—âˆˆT,accord-
ingtothe developer-roledependency ofğ‘’ğ‘–ğ‘—.Specifically,weconsider
four types of edges in this study, i.e., ğ‘Ÿâ†’ğ‘Ÿ,ğ‘Ÿâ†’ğ‘‘,ğ‘‘â†’ğ‘Ÿ, and
ğ‘‘â†’ğ‘‘,where ğ‘Ÿdenotesthereporter, ğ‘‘denotesthediscussant,as
we defined in the previous section.
3.3.2 Embed Dialog Graph Context. Givenadialoggraph ğº(ğ·/prime),
weemployatwo-layergraphneuralnetwork(GNN)[ 59]toembed
the graph context of dialog structure and developer-role depen-
dency, respectively. We output ğºğ‘(ğ·/prime)where each vertex restores
graph context information.
Structure-levelGNN. Inthefirstlayer,abasicGNN[ 31]isused
tolearnthestructure-levelcontextforeachvertexinagivengraph,
including embedding its neighbor vertices via the â€œreply-toâ€ edges,
as well as the features contained in the neighbor vertices.
A basic GNN layer can be implemented as follows:
ğ‘£ğ‘–(ğ‘™+1)=ğœ/parenleftbigg
ğ‘Š(ğ‘™)
1ğ‘£ğ‘–(ğ‘™)+ğ‘Š(ğ‘™)
2/summationdisplay.1
ğ‘—âˆˆğ‘(âˆ—,ğ‘–)ğ‘£ğ‘—(ğ‘™)/parenrightbigg
(3)
where ğ‘(âˆ—,ğ‘–)denotes the set of neighboring vertices that point
to vertex ğ‘£ğ‘–.ğ‘£ğ‘–(ğ‘™)represents the updated vertex at layer ğ‘™, and
ğ‘£ğ‘–(ğ‘™+1)represents the updated vertex at layer ğ‘™+1.ğœdenotes a
non-linearfunction,suchassigmoidorReLU, ğ‘Š(ğ‘™)
1andğ‘Š(ğ‘™)
2are
trainable parameter matrices. We introduce the edge weights to
betteraggregatethelocalinformation.Hence,theupdatedvertex
ğ‘£ğ‘–(1)of the structure-level GNN layer is calculated as:
ğ‘£ğ‘–(1)=ğœ/parenleftbigg
ğ‘Š(1)
1/vecğ‘¢ğ‘–+ğ‘Š(1)
2/summationdisplay.1
ğ‘—âˆˆğ‘(âˆ—,ğ‘–)ğ‘¤ğ‘—ğ‘–/vecğ‘¢ğ‘—/parenrightbigg
(4)
whereğ‘¤ğ‘—ğ‘–denotes the edge weight from vertex ğ‘£ğ‘—to vertex ğ‘£ğ‘–.
Role-levelRGCN. Inthesecondlayer,wefurthercapturethe
high-levelcontextualinformationbyleveragingRelationalGraph
Convolutional Networks (RGCN) [ 60]. RGCN is a generalization
ofGraphConvolutionalNetworks(GCN)[ 36]whichextendsthe
hierarchical propagation rules and takes the edge types between
302vertices into account. Since RGCN explicitly models the neighbor-
hood structures, it can better handle multi-relational graph data
likeourdialoggraph,whichcontainsfouredgetypes.Thevertex ğ‘£ğ‘–
is updated by applying the RGCN over the output of the first layer.
ğ‘£ğ‘–=ğœ/parenleftbigg
ğ‘Š(2)
1ğ‘£ğ‘–(1)+/summationdisplay.1
ğ‘¡âˆˆğ‘‡/summationdisplay.1
ğ‘—âˆˆğ‘ğ‘¡
(âˆ—,ğ‘–)1
ğ‘ğ‘–,ğ‘¡ğ‘Š(2)
ğ‘¡ğ‘£ğ‘—(1)/parenrightbigg
(5)
whereğ‘ğ‘¡
(âˆ—,ğ‘–)denotesthesetofverticesthatpointtovertex ğ‘£ğ‘–under
edge type ğ‘¡âˆˆT.ğ‘ğ‘–,ğ‘¡is a normalization constant that can either be
learnedorsetinadvance(suchas ğ‘ğ‘–,ğ‘¡=|ğ‘ğ‘¡
(âˆ—,ğ‘–)|).ğœdenotesanon-
linear function, ğ‘Š(ğ‘™)
2andğ‘Š(ğ‘™)
ğ‘¡are trainable parameter matrices,
the latter matrix changes under different edge types. The output
of role-level RGCN is the ğºğ‘(ğ·/prime)where each vertex ğ‘£ğ‘–restores the
embedded graph context /vecâ„ğ‘–for utterance ğ‘¢ğ‘–.
3.3.3 Combined representation. To enrich the utterance represen-
tation,weconcatenateeachvertexin ğº(ğ·/prime)withitscorresponding
vertexin ğºğ‘(ğ·/prime),andoutputthesequenceofcombinationasthe
dialog vector ğ¶={/vecğ‘1,/vecğ‘2,...,/vecğ‘ğ‘›}, where/vecğ‘ğ‘–=[/vecğ‘¢ğ‘–âŠ•/vecâ„ğ‘–], andâŠ•is the
concatenation operator.
3.4 Dialog Embedding and Classification
This step aims to obtain the representation of an entire dialog and
classify it as either a positive or a negative bug-report dialog.
DialogEmbedding. Weinputthedialogvector ğ¶={/vecğ‘1,/vecğ‘2,...,/vecğ‘ğ‘›}
totheSum-Pooling andtheMax-Pooling layerrespectively.Then,
we concatenate the output vectors to get the dialog embedding /vecğ‘”:
/vecğ‘”=|ğ‘‰|/summationdisplay.1
ğ‘–=1/vecğ‘ğ‘–âŠ•Maxpooling (/vecğ‘1,...,/vecğ‘ğ‘›) (6)
whereâŠ•is the concatenation operator, |ğ‘‰|is the number of the
graphâ€™s vertices.
Dialog Classification. The label is predicted by feeding the
dialogembedding /vecğ‘”intotwoFull-Connected (FC)layersfollowed
by theSoftmaxfunction:
P=softmax(ğ¹ğ¶2(ReLU(ğ¹ğ¶1(/vecğ‘”ğ‘’)))) (7)
wherePisthe2-lengthvector[ ğ‘ƒ(NBR|ğ·),ğ‘ƒ(BR|ğ·)],theğ‘ƒ(NBR|ğ·)
is the predicted probability of non-bug-report dialog, the ğ‘ƒ(BR|ğ·)
is the predicted probability of bug-report dialog.
Finally,weminimizethelossthroughtheFocalLoss[ 43]func-
tion. The Focal Loss improves the standard Cross-Entropy Loss by
addinga focusingparameter ğ›¾â‰¥0.Itfocuseson trainingon hard
examples, while down-weight the easy examples.
ğ¹ğ¿=âˆ’/summationdisplay.1
ğ‘–ğ›¼ğ‘–(1âˆ’Pğ‘–)ğ›¾ğ‘¦ğ‘–log(Pğ‘–) (8)
whereğ‘¦ğ‘–is theğ‘–-th element of the one-hot ground-truth label (BR
or NBR), ğ›¼ğ‘–andğ›¾are tunable parameters.
3.5 Bug Report Synthesis
Due to the high volume of live chat data and the low proportion of
ground-truthbug-reportdialogs,itisdifficulttogetenoughtraining
data for bug report synthesis task. To address this challenge, we
utilizeatwicefine-tunedBERTmodel,whichprovestobeeffective
toimproveperformancethroughmoresophisticatedtransferringknowledge from the pre-trained model [ 21]. Specifically, we use
apre-trainedBERTandfine-tuneittwiceusingtheexternalBEE
dataset and our BRS dataset, as shown in the dashed box of â€˜3.5â€™ in
Fig. 2.
(1) Initial Fine-tuning BERT model. The BERT model is
a bidirectional transformer using a combination of Masked Lan-
guageModel andNextSentencePrediction.ItistrainedfromEnglish
Wikipedia (2,500M words) and BooksCropus (800M words) [ 79].
TheentireBERTmodelisastackof12BERTlayerswithmorethan
100 million parameters.
Based on an assumption that the contents of bug reports are
likely from the reportersâ€™ utterances, we perform the initial fine-
tune on the task of classifying bug-report contents into OB, EB, SR,
andOthers.First,weselecttheexternalBEEdatasetproposedby
Songetal.[ 68]thatincludes5,067bugreports,11,776OBsentences,
1,568EBsentences,and24,655SRsentencesasthesourcedataset.
Second,followingthepreviousstudy[ 68],wepreprocesssentences
inthe5,076bugreportswithlowercase,tokenization,excludingnon-
Englishandoverlong(over200words)ones.Third,wefreezethe
firstninelayersofthepre-trainedBERTandupdatetheparameters
ofthelastthreelayersviathesentencesinthe5,076bugreports.We
take the output of the first token (the [CLS ] token) as the sentence
embedding. Finally, we input the sentence embedding into a FC
layertoproducetheprobabilitiesofOB( ğ‘ƒğ‘),EB(ğ‘ƒğ‘’),SR(ğ‘ƒğ‘ ),and
Others ( ğ‘ƒğ‘œ). We apply Cross-Entropy Loss when measuring the
difference between truth and prediction:
ğ¿ğ‘œğ‘ ğ‘ =âˆ’(ğ‘¦ğ‘ğ‘™ğ‘œğ‘”(ğ‘ƒğ‘)+ğ‘¦ğ‘’ğ‘™ğ‘œğ‘”(ğ‘ƒğ‘’)+ğ‘¦ğ‘ ğ‘™ğ‘œğ‘”(ğ‘ƒğ‘ )+ğ‘¦ğ‘œğ‘™ğ‘œğ‘”(ğ‘ƒğ‘œ))(9)
whereğ‘¦ğ‘,ğ‘¦ğ‘’,ğ‘¦ğ‘ , andğ‘¦ğ‘œindicate the ground-truth labels of sen-
tences.
(2) Twice fine-tuning BERT model. Given the above fine-
tuned BERT model, we perform the second round of fine-tuningon our BRS dataset as follows. We first collect all the reporterâ€™sutterances
ğ‘ˆğ‘Ÿin Dialog ğ·as our inputs. Since ğ‘ˆğ‘Ÿmay contain
trivial contents that are less meaningful for reporting bugs, we
prunethe ğ‘ˆğ‘Ÿintoğ‘ˆ/primeğ‘Ÿiftheysatisfythefollowingheuristicrules:(1)
remove the sentence ğ‘ if: (ğ‘™ğ‘’ğ‘›ğ‘”ğ‘¡â„(ğ‘ )â‰¤5) AND ( ğ‘ does not contain
[URL],[EMAIL], [HTML],[CODE]or[VERSION]) (2)removethe
stringğ‘ ğ‘¡ğ‘Ÿfromitssentenceif: âˆ€ğ‘ ğ‘¡ğ‘Ÿâˆˆ{â€œHiâ€,â€œHiAllâ€,â€œheythereâ€,â€œHi
everybodyâ€, â€œhey guysâ€, â€œhi guysâ€, â€œguysâ€, â€œHi thereâ€, â€œthank youâ€,
â€œthanksâ€, â€œthanks anywayâ€, â€œthanks for replayingâ€, â€œok, thanksâ€,
etc.}.Second,wetransfertheBERTmodelpreviouslyfine-tunedon
the external bug report dataset for initialization, and replace theoriginal FC layer with a new one. Third, the BERT model is fine-
tunedthesecondtimevialabeledsentencesin ğ‘ˆ/primeğ‘Ÿusingasmaller
learning rate.
(3) Bug reports assembling. When generating bug reports,
weassemblesentencesthatarepredictedtothesamecategoryin
chronological order. To fully retain the useful information in ğ‘ˆ/primeğ‘Ÿ,
we assemble all the sentences that belong to the â€œOthersâ€ category
asthedescriptionparagraph.Intheend,wecouldgenerateabug
reportwithitsdescription,observedbehavior,expectedbehavior,
and step to reproduce according to best practices for bug reporting
[8, 80].
303ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Lin Shi et al.
4 EXPERIMENTAL DESIGN
To evaluate the proposed BugListener approach, our evaluation
specifically addresses three research questions:
RQ1: How effective is BugListener in identifying bug-report
dialogs from live chat data?
RQ2: How effective is BugListener in synthesizing bug reports?
RQ3: How does each individual component in BugListener con-
tribute to the overall performance?
4.1 Data Preparation
4.1.1 Studied Communities. Many OSS communities utilize Gitter
[27] or Slack [ 28] as their live communication means. Considering
the popular, open, and free access nature, we select studied com-
munities from Gitter2. Following previouswork [ 51,63] ,weselect
popularandactivecommunitiesasourstudiedsubjects.Specifically,
we select the Top-1 most participated communities from six active
domains,coveringfrontendframework,mobile,datascience,De-
vOps,collaboration, andprogramming language.Then,we collect
the live chat utterances from these communities. Gitter provides
RESTAPI[ 26]togetdataaboutchattingroomsandpostutterances.
Inthisstudy,weusetheRESTAPItoacquirethechatutterances
of the six selected communities, and the retrieved dataset contains
all utterances as of â€œ2020-12-31â€.
4.1.2 Preprocessing and Disentanglement. Fordatapreprocessing,
we first convert all the words in utterances into lowercase, and
removethestopwords.Wealsonormalizethecontractionsinutter-
ances with contractions [ 37] library and use Spacy [ 4] for lemmati-
zation.Followingpreviouswork[ 10,71],wereplacetheemojiswith
specific strings to standard ASCII strings. Besides, we detect low
frequencytokenssuchasURL,emailaddress,code,HTMLtag,and
version number with regular expressions, and substitute them into
[URL],[EMAIL],[HTML],[CODE],and[VERSION]respectively.
Then,we usetheFFmodel[ 39]todivide theprocesseddatainto
individual dialogs as introduced in Sec. 3.1.1. The detailed statistic
is shown in the â€œEntire Populationâ€ column of Table 1.
4.1.3 Sampling and Filtering. After dialog disentanglement, the
numberof individualchatdialogs remainsquite large.Limitedby
thehumanresourceoflabeling,werandomlysample100dialogs
from each community. The samplepopulation accounts for about
1.1% of the entire population. Although the ratio is not large, we
considertheselecteddialogsarerepresentativebecausetheyarerandomly selected from six diverse communities. The details of
sampling results are shown in the â€œSample Populationâ€ column of
Table 1.
SinceBugListenerreliesonnaturallanguageprocessingtoun-
derstand the dialog, dialogs that have too much noise or do not
contain enough information are almost incomprehensible and thus
cannotdecideabugreport.Followingthedatacleaningprocedures
of previous studies [ 51,63], we excluded noisy dialogs by apply-
ingthefollowingexclusioncriteria:1)Dialogsthatarewrittenin
non-Englishlanguages;2)Dialogswherethecodeorstacktracesac-countsformorethan90%oftheentirechatcontent;3)Low-quality
dialogssuchasdialogswithmanytyposandgrammaticalerrors.
2InSlack,communitiesarecontrolledbytheteamadministrators,whereasinGitter,
access to the chat data is public4)Dialogsthatinvolvechannelrobotswhichmainhandlesimple
greeting or general information messages.
4.1.4 Ground-truth Labeling. For each sampled dialog obtained in
thepreviousstep,welabelground-truthdatafromthreeaspects:(1)
Correct disentanglement results. For each sampled dialog, we man-
ually correct the prediction of the â€œreply-toâ€ relationships between
utterances, as well as the disentanglement results. (2) Label dialogs
with BR and NBR (See the â€œSample Populationâ€ column in Table 1).
For each dialog that has been manually corrected, we manually la-
belitwithaâ€œBRâ€oranâ€œNBRâ€tag,accordingtowhetheritdiscusses
a certain bug that should be reported. (3) Label sentences with OB,
EB, and SR (See the â€œBRS Datasetâ€ column in Table 1). For each
dialoglabeledwithBR,wefirstpruneallreporterâ€™sutterances ğ‘ˆğ‘Ÿ
toobtain ğ‘ˆ/primeğ‘ŸasdescribedinSec.3.5(2).Thenwelabeleachsentence
inğ‘ˆ/primeğ‘Ÿwith observed behavior (OB), expected behavior (EB), and
step to reproduce (SR), according to their contents.
To ensure the labeling validity, we built an inspection team,
whichconsistedoffourPhDstudents.AllofthemarefluentEng-
lishspeakers,andhavedoneeitherintensiveresearchworkwith
software development or have been actively contributing to open-
sourceprojects.Wedividedthemintotwogroups.Theresultsfrom
both groups were cross-checked and reviewed. When a labeled
resultreceiveddifferentopinions,wehostedadiscussionwithall
team members to decide through voting. Based on our observation,
thecorrectnessofautomateddialogdisentanglementis79%.The
average Cohenâ€™s Kappa about bug report identification is 0.87, and
the average Cohenâ€™s Kappa about bug report synthesis is 0.84.
4.1.5 Dataset augmentation and balancing. ForBRItask,weaug-
ment the dataset as introduced in Sec. 3.1. For each project, we
first augment the NBR data eight times,and then augment the BR
data until BR and NBR data are balanced. The details are shownin the â€œBRI Datasetâ€ column in Table 1. For BRS task, we apply
EDA[76]techniquestoaugmentOB,EB,SRsentencesuntiltheir
numbers are balanced.We further incorporatean external dataset
fortransferlearning.TheexternaldatasetisprovidedbySongetal.
[68],including5,067bugreportswith11,776OBsentences,1,568
EB sentences, and 24,655 SR sentences.
4.2 Baselines
The first two RQs require comparison with state-of-the-art base-
lines.Weemployfourcommonmachine-learning-basedbaselines
applicableto bothRQ1andRQ2, including NaiveBayesian (NB)
[48],Random Forest (RF) [41],Gradient Boosting Decision
Tree (GBDT) [34], andFastText [33]. In addition, we employ sev-
eral baselines applicable to RQ1 and RQ2, respectively.
AdditionalBaselinesforidentifyingbug-reportdialogs(
RQ1).Furthermore, we also consider some existing approaches
that can identify sentences or mini-stories which are discussing
problems. CNC[32]isthestate-of-the-artlearningtechniqueto
classify sentences in comments taken from online issue reports.
They proposed a CNN [ 38]-based approach to classify sentences
intosevencategoriesofintentions:FeatureRequest,SolutionPro-
posal,ProblemDiscovery,etc.ToachievebetterperformanceoftheCNCbaseline,weretraintheCNCmodelonourBRIdataset.Weas-semblealltheutterancesinadialogasanentry,andpredictwhether
304BugListener: Identifying and Synthesizing Bug Reports from Collaborative Live Chats ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Table1:OurExperimentDataset.(Part,Dial,Uttr,Senareshortforparticipatingdevelopers,dialog,utterance,andsentence,
respectively. BR and NBR denote bug-report and non-bug-report dialogs. ğ‘ˆğ‘Ÿdenotes sentences in reporterâ€™s utterances, and ğ‘ˆ/primeğ‘Ÿ
denotes the pruned ğ‘ˆğ‘Ÿ.)
SamplePopulation BRIDataset BRSDatasetEntire PopulationNBR BR Augmented NBR Augmented BR BRDialog Reporter Sen. BRcontent
Project Part. Dial. Uttr Dial.Uttr.Dial.UttrDial. Uttr.Dial. UttrDial.Sen.UrUrâ€™OBEBSRDES
Angular 22,467 79,619 695,183 1791,043 86268 358 2,086 3581,132 866475074461773440195
Appium 3,979 4,906 29,039 16973784233 338 1,474 338 935845964783971802944144
Docker 8,810 3,964 22,367 17291661185 344 1,832 3441,037 614383673221503532105
DL4J 8,31027,256 252,846 1781,070 79373 356 2,140 3561,781 798285905021843256230
Gitter 9,260 7,452 34,147 20781363304 414 1,626 4141,898 637334323691591915176
Typescript 8,31818,812 196,513 2031,016 2085406 2,032 4061,625 201761381184812850
Total 61,144142,009 1,230,095 1,1085,5953931,448 2,216 11,190 2,216 8,408 39334182,5122,154898161195900
Table 2: Baseline comparison across the six communities for bug-report dialog identification (%).
Angular Appium Docker DL4J Gitter Typescript AverageMethodsPRF1PRF1PRF1PRF1PRF1PRF1PRF1
BugListener 82.9379.0780.9569.3980.9574.7377.4278.6978.0585.0772.1578.0882.0987.3084.6270.0070.0070.0077.8278.0377.74
NB 58.8873.2665.2862.2266.6764.3765.5231.1542.2262.7934.1844.2672.9255.5663.0635.2930.0032.4359.6048.4751.94
GBDT72.2260.4765.8265.1769.0567.0566.0054.1059.4685.0064.5673.3859.7782.5469.3335.1465.0045.6163.8865.9563.44
RF 75.0059.3066.2372.1567.8669.9468.7536.0747.3172.7320.2531.6862.3476.1968.5760.0030.0040.0068.5048.2853.96
FastText77.5952.3362.5068.5472.6270.5256.6049.1852.6374.5148.1058.4667.2461.9064.4640.9145.0042.8664.2354.8658.57
CNC 80.3652.3363.3867.0570.2468.6074.5162.2967.8684.4448.1061.2968.1871.4369.7752.0065.0057.7871.0961.5764.78
DECA 51.3245.3548.1551.1652.3851.7645.5759.0251.4342.2248.1044.9755.3649.2052.1021.5755.0030.9944.5351.5146.57
Casper67.6553.4959.7466.0685.7174.6160.5670.4965.1582.1458.2368.1573.3369.8471.5432.5065.0043.3363.7167.1363.75
the entry belongs to problem discovery. DECA[69] is the state-of-
the-art rule-basedtechnique foranalyzing development emails.It
isusedtoclassifythesentencesofemailsintoproblemdiscovery,
solutionproposal,informationgiving,etc.,byusinglinguisticrules.
We use the twenty-eight linguistic rules [ 61] for identifying the
â€œproblem discoveryâ€ utterances in a dialog and regard the dialog
containing the â€œproblem discoveryâ€utterances as the bug-report
dialog.Casper [ 30]is a method for extracting and synthesizing
user-reportedmini-storiesregardingappproblemsfromreviews.
SimilartotheCNCbaseline,wealsoretraintheCaspermodelon
the BRI dataset, and apply it to determine bug-report dialogs by
assembling all the utterances in a dialog as one entry.
AdditionalBaselineforsynthesizingbugreports(RQ2). We
investigatedsevenstate-of-the-artapproachesforthebugreport
synthesistask,includingCUEZILLA[ 80],DeMlBUD[ 12],iTAPE
[17], S2RMiner [ 78], infoZilla [ 9], Euler [11] and BEE [ 68]. Among
theaboveapproaches,onlythereplicationpackagesfromiTAPE,
S2RMiner, andBEE areavailable.Since iTAPEand S2RMiner clas-
sify SR sentences, and only BEE share the same target with us,
thatistoclassify OB,EB,SR, andOthersentencesforbugreports.
Therefore,wechooseBEEasouradditionalbaselinesforbugreport
synthesis.BEEcomprisesthreebinaryclassificationSVM,which
can tag sentences with OB, EB, or SR labels.
ThisleadstoatotalofsevenbaselinesforRQ1,andfivebaselines
for RQ2.
4.3 Evaluation Metrics
We use three commonly-used metrics to evaluate the performance
ofbothtwotasks,i.e., Precision,Recall,andF1.(1) Precisionrefersto
theratioofthenumberofcorrectpredictionstothetotalnumber
ofpredictions;(2) Recallreferstotheratioofthenumberofcorrect
predictions to the total number of samples in the golden test set;and (3)F1is the harmonic mean of precision and recall. Whencomparing the performances, we care more about F1 since it is
balanced for evaluation.
4.4 Experiment Settings
The experimental environment is a desktop computer equipped
with an NVIDIA GeForce RTX 3060 GPU, intel core i5 CPU, 12GB
RAM, running on Ubuntu OS.
ForRQ1,weapply Cross-ProjectEvaluation onourBRIdatasetto
perform the training process. We iteratively select one project as a
test dataset, and the remaining five projects for training. We train
BugListener with 32 batch_size. We choose Adamas the optimizer
withlearning_rate =1e-4. To avoid over-fitting,we set dropout=0.5,
andadoptthe L2-regularization withğœ†=1e-5.The ğ›¼andğ›¾ofFocal
Lossfunctionare0and2,respectively.WhentrainingGBDT,we
set thelearning_rate =0.1 and the n_estimators =100; For RF, we set
themin_samples_leaf =10andthe n_estimators =100;Wetrain100
epochs for FastText, and set the learning_rate =0.1, the window
sizeofinputn-gramas2;Casperchooses SVM.SVC asthedefault
function, with rbfas the kernel, 3 as the degree, and 200 as the
cache_size ; CNC selects 32 as the batch_size, 128-dimensional word
embedding,fourdifferentfiltersizesof [2,3,4,5]with128filters,
30trainingepochs,and dropout=0.5.Forthesehyper-parameters,
we use greedy search [ 40] as the parameter selection method to
obtain the best performance.
ForRQ2,inthefirstfine-tuneround,wetrainBugListeneronthe
external BEE dataset (see Sec. 4.1.5) with 64 batch_size. We set the
warmupproportionofBERTmodelto0.1,andthevalueofgradient
clipto1.0.Wechoose Adamastheoptimizerwith learning_rate =1e-
4andweightdecayrate =0.01.WetrainBugListenerfor13epochs
and save the best model. In the second fine-tune round, we usethe same parameters while changing the batch_size from 64 to 8,
theepochfrom 13 to 70, and the learning_rate from 1e-4 to 1e-6.
We apply a 10-fold partition on the BRS dataset to perform the
secondaryfine-tuning,i.e.,weuseninefoldsforfine-tuning,and
305ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Lin Shi et al.
theremainingonefortesting.ForNB/GDBT/RF/FastTextbaselines,
we usethe greedy strategyto tune parametersto achieve the best
performance. For the additional baseline BEE, we directly utilize
its open API [67] to predict OB, EB, and SR sentences.
ForRQ3,wecompareBugListenerwithitstwovariantsinbugre-
port identification task: 1) BugListener w/o CNN, which removes
theTextCNN.2) BugListenerw/oGNN,whichremovesthegraph
neural network. BugListener with its two variants use the same pa-
rameters when training. We compare BugListener with its variant
without transferring knowledge from the external BEE dataset (i.e.,
BugListener w/o TL) in bug report synthesis task. BugListener
w/o TL has the same network structure with BugListener, but it
doesnotusetheexternalBEEdatasetandisonlyfine-tunedonour
BRS dataset.
5 RESULTS AND ANALYSIS
5.1 Performance in Identifying Bug Reports
Table 2 shows the comparison results between the performance
ofBugListenerandthoseofthesevenbaselinesacrossdatafrom
six OSS communities, for BRItasks. The columns correspond to
Precision, Recall, and F1. The highlighted cells indicate the best
performancefromeachcolumn.Then,weconductthenormality
testandT-testbetweeneverytwomethods.Overall,thedatafollows
anormaldistribution,andBugListenersignificantly( ğ‘âˆ’ğ‘£ğ‘ğ‘™ğ‘¢ğ‘’ <
0.01) outperforms the seven baselines on F1. Specifically, when
comparing with the best Precision-performer among the seven
baselines, i.e., CNC, BugListener can improve its average precision
by6.73%.Similarly,BugListenerimprovesthebestRecall-performer,
i.e., Casper, by 10.90% for average recall, and improves the best F1-
performer, i.e., CNC, by 12.96% for average F1. At the individualproject level, BugListener can achieve the best F1-score in all six
communities.
ForBRI tasks , we believe that the performance advantage of
BugListenerismainlyattributedtotherichrepresentativenessof
its internal construction, from two perspectives: (1) BugListenermodels the textual dialog as the dialog graph thereby can effec-
tively exploit the graph-structured knowledge. While the structure
informationismissinginthebaselinemethodsthattreatadialog
as a linear structure. (2) BugListener leverages a novel two-layer
GNNmodelwithconsideringtheedgetypesbetweenutterancesto
learn a high-level contextual representation. Thus it can capture
the latent semantic relations between utterances more accurately.
Answering RQ1: On average, BugListener has the best pre-
cision, recall, and F1, i.e., 77.82%, 78.03%, and 77.74%, improving
the best F1-baseline CNC by 12.96%. On individual projects, it also
outperformstheotherbaselineswithachievingthebestF1-score
in all six communities.
5.2 Performance in Synthesizing Bug Reports
Fig. 3 summarizes the comparison results between the averageperformance of BugListener and the five baselines, for BRStask.
We can see that, BugListener can achieve the highest performance
in predicting OB, EB, and SR sentences. It outperforms the six
baselinesintermsofF1.ForpredictingOBsentences,itreachesthe
highest F1 (84.63%), improving the best baseline FastText by 9.32%.
For predicting EB sentences, it reaches the highest F1 (71.46%),/g1/g2/g1/g3/g1/g4/g1/g5/g1/g6/g1/g7/g1/g8/g1/g9/g1/g10/g1/g2/g1/g1
/g11/g28/g22/g16/g23/g26/g27/g21/g24/g21/g25 /g14/g20/g26/g27/g19/g21/g29/g27 /g18/g14 /g15/g11/g12/g19 /g17/g11 /g11/g13/g13/g14/g12 /g13/g12 /g16/g15
/g9/g5/g1/g10/g7/g1
/g9/g3/g1/g9/g7/g1
/g7/g11/g1/g8/g4/g1/g9/g2/g1
/g7/g8/g1/g7/g6/g1/g9/g4/g1
/g7/g6/g1
/g6/g11/g1/g9/g4/g1
/g7/g5/g1/g7/g4/g1/g8/g11/g1
/g9/g1/g3/g6/g1
Fig. 3: Baseline comparison for bug report synthesis.
improvingthe bestbaseline FastTextby12.21%. Forpredicting SR
sentences, it reaches the highest F1 (73.13%), improving the best
baseline FastText by 10.91%.
OurapproachismoreeffectivetoclassifyOB,EB,andSRsen-
tences in live chats than others, mainly due to two reasons: (1) By
leveraging the transfer learning technique, BugListener can obtain
generalknowledgefromexistingbugreports,thuswouldfurther
boosttheclassificationperformancesonthelimitedresource.(2)
By employing the state-of-the-art BERT model which has a strong
abilitytolearnsemanticsviathetransformerstructure,BugListener
can capture richer semantic features in word and sentence vectors.
WenoticethatFastTextachievethesecondperformances.These
resultsaremainlyduetothat,FastTextcanbetterunderstandthe
contextbycapturingtheneighborwordsusingafixed-sizewindow
whenembeddingwords.wealsonoticethatBEEperformstheworst
on predictingEB (average F1is only7%). These resultsare mainly
due to that, BEE is trained from the external normal bug reports
dataset, and the expression style for EB sentences is quite different
betweenthoseinnormalbugreportsandthoseinliveconversations.
TheEBsentencesinbugreportsarelikelyexpressedinadeclarative
tonethatstatethereporterâ€™sexpectationasanobjectivefact,e.g.,â€œI
wishdockercansavediskusageâ€.Whileinlivechats,EBsentences
aremorelikelyexpressedinaninterrogativetonethatthereporters
inquiry or ask for a reply, e.g., â€œCan docker avoid using such huge
disk?â€. Therefore, it is difficult for BEE to predict EB sentences
correctly on live chat data.
Answering RQ2: BugListener outperforms the six baselines
in predicting OB, EB, and SR sentences in terms of F1. The three
categoriesâ€™averagePrecision,Recall,andF1are75.57%,77.70%,and
76.40%, respectively.
5.3 Effects of Main Components
Fig.4(a)presentstheperformancesofBugListeneranditstwovari-
antsforBRItask.Wecanseethat,theF1 performanceofBugLis-
tener is higher than all two variants across all the six communities.
WhencomparedwithBugListenerandBugListenerw/oGNN,re-
movingtheGNNcomponentwillleadtoadramaticdecreaseofthe
averageF1(by17.22%)acrossallthecommunities.Thisindicates
that the GNN is an essential component to contribute to BugLis-
tenerâ€™s high performances. When compared with BugListener and
BugListener w/o CNN, removing the TextCNN component will
lead to the average F1 declines by 13.85%. It is mainly because the
TextCNN model can capture the intra-utterance semantic features,
which improves the classification performance.
306BugListener: Identifying and Synthesizing Bug Reports from Collaborative Live Chats ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA

$QJXODU $SSLXP 'RFNHU '/- *LWWHU 7\SHVFULSW%XJ/LVWHQHU
%XJ/LVWHQHUZR&11
%XJ/LVWHQHUZR*11
(a) The BRI performance
     65
(%
2%%XJ/LVWHQHU
ZR7/%XJ/LVWHQHU





(b) The BRS performance
Fig. 4: The component analysis.
Fig.4 (b)shows theperformance ofBugListener anditsvariant
without transferring knowledge from the external BEE dataset for
BRStask. We can see that, without the knowledge transferred
from the external BEE dataset, the F1 will averagely decrease by
2.52%,6.06%,3.13%forOB,EB,andSRprediction,respectively.This
indicatesthatincorporatingthetransferredexternalknowledgecan
largelyincreasetheperformanceonEBprediction,whileslightly
increase the performance on OB and SR prediction.
AnsweringRQ3: TheGNN,TextCNN,andTransferLearning
techniqueadoptedbyBugListenerarehelpfulforbugreportidenti-
fication and synthesis.
6 HUMAN EVALUATION
To further demonstrate the generalization and usefulness of our
approach, we apply BugListener on recent live chats from five new
communities:Webdriverio,Scala,Materialize,Webpack,andPan-
das (note that these are different from our studied communitiesso that all data of these communities do not appear in our train-
ing/testing data). Then we invite nine human annotators to assess
thecorrectness,quality,andusefulnessofthebugreportsgenerated
by BugListener.
Human Annotators. We recruit nine participants, including
twoPhDstudents,twomasterstudents,threeprofessionaldevel-
opers and two senior researchers, all familiar with the five open
source communities. They all have at least three years of software
developmentexperience,andfourofthemhavemorethantenyears
of development experience.
Procedure.First,wecrawltherecentone-month(July2021to
August 2021) live chats of the five new communities from Gitter,
whichcontain3,443utterances.Second,weapplyBugListenerto
disentangleandconstructthelivechatsintoabout562separated
dialogs. Among them, BugListener identifies 31 potential bug
reportsin total3. For each participant, we assign 9-11 bug reports
3Limited by the space, we list the details about the 31 bug reports on our website [ 2].of the communities that they are familiar with. Each bug reportis evaluated by three participants. For each bug report, each par-
ticipant has the following information available: (1) the associated
opensourcecommunity;(2)theoriginaltextualdialogsfromGitter;
(3) the bug report generated by BugListener.
The survey contains three questions: (1) Correctness: Whether
thedialogisdiscussingabugthatshouldbereportedatthatmo-
ment (Yes or No)? (2) Quality: How would you rate the quality of
Description, Observed Behavior, Expected Behavior, and Step to
Reproduceinthebugreport(usingafive-levelLikertscale[ 18])?
(3)Usefulness:HowwouldyouratetheusefulnessofBugListener
(using a 5-level Likert scale)?
Results. To validate the correctness of bug reports identified
by BugListener, we ask each participant to determine whether it is
a real bug report and aggregate group decision based on the ma-
jority vote from the three participants. To validate the quality and
usefulness of each identified bug report, we ask each participant
torateusingaschemefrom1-10andusetheaveragescoreofthe
three evaluations as the final score. Fig. 5(a) shows the bar and
piechartdepictingthecorrectnessofBugListener.Amongthe31
bug reports identified by BugListener, 24 (77%) of them are correct,
while 7 (23%) of them are incorrect. The correctness is in line with
our experiment results (80% precision of bug report identification).
The bar chart shows the correctness distributed among the five
communities.Thecorrectnessrangesfrom63%to100%.Theper-
ceived correctness indicates that BugListener is likely generalized
tootheropensourcecommunitieswitharelativelygoodandsta-
ble performance. Fig. 5(b) shows an asymmetric stacked bar chart
depicting the perceived quality and usefulness of BugListenerâ€™s
bugreports,intermsofdescription,observedbehavior,expected





:HEGULYHULR 0DWHULDOL]H 3DQGDV6FDOH :HESDFN&RUUHFW ,QFRUUHFW



(a) Correctness
        



  




3HUFHQWDJH'HV
2%
(%
65
8VHIXOQHVV
4XDOLW\'LVVDWLVILHG 6RPHZKDWGLVVWLVILHG 1RWGLVVDWLVILHG
6RPHZKDWVDWLVILHG 6DWLVILHG
(b) Quality and usefulness
Fig. 5: Results of human evaluation
307ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Lin Shi et al.
behavior,andsteptoreproduce.Wecanseethat,thehighquality
of bug report description is highly admitted, 85% of the responses
agreethatthebugreportdescriptionissatisfactory(i.e.,â€œsomewhat
satisfiedâ€ or â€œsatisfiedâ€). The high quality of OB, EB, and S2R are
also moderately admitted (62%, 46%, and 58% on aggregated cases,
respectively). In addition, the usefulness bar chart shows that 71%
of participants agree that BugListener is useful. We will further
discuss where does BugListener perform unsatisfactorily in Sec.7.2.
7 DISCUSSION
Encouraged by the significant advantages of BugListener as shown
inSec.6,webelievethatourapproachcouldfacilitatethebugdis-
coveringprocess andsoftwarequalityimprov ement.Inthissection,
weproposepotentialusagescenariosaswellasimprovementop-
portunities for future work.
7.1 Potential Usage Scenario
Software Engineering Bots are widely known asconvenient ways
forworkflowstreamliningandproductivityimprovement[ 3,22,35].
BugListener can be easily incorporated into a collaborative bot on
Gitter, following the basic implementation ideas: first, the OSS
repository owner or core team members who care about the po-tential bugs could subscribe to their interesting chat rooms viaBugListener; then, BugListener will monitor the corresponding
chat rooms and send potential bug reports periodically; and finally,
for the bug reports that are confirmed by subscribers, BugListener
couldautomaticallypullthemtocoderepositoriessuchasGithubor
Gitlab that are well integrated with Gitter. We believe that BugLis-
tener could enhance individual and team productivity as well as
improving software quality.
7.2 Improvement Opportunities
AsreportedinSec.6,7outof31bugreportsareincorrectlylabeled
by BugListener. To identify further improvement opportunities
forfollow-upstudies,wesummarizedthefollowingspecialcases
based on examining the human evaluation results that necessitates
further studies to improve the performance of BugListener.
(1)Dialogswithafewornofeedback. Wefoundthat5outof
the 7 incorrect cases are related to insufficient feedback, i.e., three
monologues, and the other two with less than five utterances in
total.Whendecidingwhetheradialogcontainsabugornot,the
feedbackprovidedbyotherdevelopersisimportant. Forexample,
feedback such as â€œit is still not workingâ€ and â€œcould you please
file an issueâ€ likely indicate the discussing bug should be reported.
Therefore, it is difficult for BugListener to predict dialogs with
insufficient feedback. In the future, follow-up research can enrich
the bug report classification by adding different confidence levels:
HighandNormal.â€œHighâ€referstothebugreportsthatthereporter
or the discussants have confirmed, and â€œNormalâ€ refers to the bug
reports that have the potential.
(2)Dialogsreflectingusermisuse/mistake. Weobservedthat
2/7incorrectbugreportsareactuallyassociatedwithinstallation
and version-update due to the usersâ€™ mistake or negligence. The
differencebetweenâ€œBugsâ€andâ€œusermisuse/mistakeâ€issubtle.Both
of them might contain negative complaints, error stack traces, and
similarkeywordssuchasâ€œIgeterrorsâ€,â€œnotaddressedatallâ€,etc.In the future, follow-up studies are needed to incorporate priori
knowledge (e.g., dialogs discussing installation, updating, or build-
ingissuesarelikelynotreportingbugs.)tobetterdistinguishthe
two categories.
7.3 Threats to Validity
The first threat is generalizability. BugListener is only evaluated
on six open-source projects, which might not be representative of
closed-sourceprojectsorotheropen-sourceprojects.Theresults
may be different if the model is applied to other projects. However,
ourdataset comesfrom sixdifferentfields. Thevarietyof projects
relatively reduce this threat.
The second threat may come from the results of automated dia-
logdisentanglement.Inthisstudy,wemanuallyinspectandcorrectthedisentanglementresultstoensurehigh-qualityinputsforevalu-atingBugListener.Theaveragecorrectnessis79%inourinspection.However,forthefullyautomaticusageofBugListener,thetrade-off
option would be directly adopting the automated disentanglement
results.Thus,inreal-worldapplicationscenarioswithoutmanual
correction, a slight drop in performance might be observed. To
alleviatethethreat,fourstate-of-the-artdisentanglementmodels
are selected and experimented on live chat data. We adopt the best
performing modelamong thefour models,the FFmodel, todisen-
tanglethelivechat.Theresultsofhumanevaluationstudyshow
thatBugListener canachieve 77%precisionwithout manualcorrec-
tion,andtheperformanceonlyslightlydeclinedby3%compared
with BugListener taking the corrected dialogue as input. Therefore,
we believe this can serve as a good foundation for BugListenerâ€™s
fully automatic usage.
Thethirdthreatrelatestotheconstructofourapproach.First,
we hypothesize that the contents of bug reports likely consist of
reportersâ€™utterances,whichoccasionallyresultsinmissingcontextinformation.Toalleviatethethreat,wethoroughlyanalyzedwhere
our approach performs unsatisfactorily in Sec. 7.2, and planned
future work for improvement.Second, we enlarge our BRI dataset
by using a heuristic data augmentation, which may alter the se-manticsoftheoriginaldialog.Toalleviatethethreat,weemploy
the utterance mutation fromtwo dimensions (utterance-level and
word-level), which has been commonly used in augmenting the
datasetsforNLPtasks[ 23,76].Itcouldreducesemanticchangesof
the overall dialogs to a minimum.
The fourth threat relates to the suitability of evaluation metrics.
We utilize precision, recall, and F1 to evaluate the performance.We use the dialog labels and utterance labels manually labeled
as ground truth when calculating the performance metrics. Thethreats can be largely relieved as all the instances are reviewed
withaconcludingdiscussionsessiontoresolvethedisagreementin
labelsbasedonmajorityvoting.Thereisalsoathreatrelatedtoour
humanevaluation.Wecannotguaranteethateachscoreassigned
to every bug report is fair. To mitigate this threat, each bug report
isevaluated by3 humanevaluators,and weuse theaveragescore
of the 3 evaluators as the final score.
8 RELATED WORK
Identifying Bug Reports. Identifying bug reports from user feed-
back timely and precisely is vital for developers to update their
308BugListener: Identifying and Synthesizing Bug Reports from Collaborative Live Chats ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
applications. Many approaches have been proposed to identify
bugs or problems from app reviews [ 24,25,30,45,46,58,74,75],
mailing lists [ 69,70], and issue requests [ 7,32,53,55,73]. For ex-
ample, Vu et al. [ 74] detected emerging mobile bugs and trends
by counting negative keywords based on Google Play. Maalej etal. [
45,46] leveraged natural language processing and sentiment
analysis techniques to classify app reviews into bug reports, fea-
turerequests,userexperiences,andratings.Scalabrinoetal.[ 58]
developedCLAPtoclassifyuserreviewsintobugreports,feature
requests,andnon-functionalissuesbasedonarandomforestclassi-fier.DiSorboetal.[
69,70]classifiedsentencesindevelopermailing
listsintosixcategories:featurerequest,opinionasking,problem
discovery, solution proposal, information seeking, and information
giving.Huangetal.[ 32]addressedthedeficienciesofDiSorboet
al.â€™s taxonomy by proposing a convolution neural network (CNN)-
basedapproach.Ourworkdiffersfromexistingresearchesinthat
wefocusonidentifyingbugreportsfromcollaborativelivechats,
whichposedifferentchallengesaschatmessagesareinterleaved,
unstructured, informal, and typically have insufficient labeled data
than the previously analyzed documents.
Synthesizing Bug Reports. Several efforts have been made to
synthesize bug reports by utilizing heuristic rules automatically
[8,9,20,80].Asheuristicapproachesoftenfailtocapturethediverse
discourseinbugreports,learning-basedapproacheshavebeenpro-posed[
11,17,68,78].Songetal.[ 68]proposedatoolthatintegrates
threeSVMmodelstoidentifytheobservedbehavior,expectedbe-
havior,andS2Ratthesentencelevelinbugreports.Zhaoetal.[ 78]
proposedanSVM-basedapproachthatautomaticallyextractsthe
textual description of steps to reproduce (S2R) from bug reports.
Chaparro et al. [ 11] proposed a sequence-labeling-based approach
that automatically assesses the quality of S2R in bug reports. Chen
etal.[17]proposedaseq2seq-basedapproachthatautomatically
generates titles regarding the textual bodies written in bug reports.
Most of these methods focus on structuring or synthesizing bug re-portsfromtextualdescriptionsthatdepictingbugsinasingle-partystyle,whileourapproachtargetstoautomaticallystructureandsyn-thesizebugreportsfrommulti-partyconversations,complementing
the existing studies on a novel resource.
Knowledge Extraction from Collaborative Live Chats. Re-
cently,moreandmoreworkhasrealizedthatcollaborativelivechats
play an increasingly significant role in software development, andare a rich and untapped source for valuable information about the
softwaresystem[ 13,14,42].Severalstudiesarefocusingonextract-
ingknowledgefromcollaborativelivechats.Chatterjeeetal.[ 15]
automatically collected opinion-based Q&A from online developer
chats.Shietal.[ 64]proposedanapproachtodetectfeature-request
dialoguesfromdeveloperchatmessagesviathedeepsiamesenet-
work. Qu et al. [ 56] utilized classic machine learning methods to
predictuserintentwithanaverageF1of0.67.Rodegheroetal.[ 57]
presented a technique for automatically extracting information rel-
evant to user stories from recorded conversations. Chowdhury and
Hindle [19] filtered out off-topic discussions in programming IRC
channels by engaging Stack Overflow discussions. The findings of
previousworkmotivatetheworkpresentedinthispaper.Ourstudy
is different from the previous work as we focus on identifying and
synthesizingbugreportsfrommassivechatmessagesthatwould
beimportantandvaluableinformationforsoftwareevolution.Inaddition,ourworkcomplementstheexistingstudiesonknowledge
extraction from developer conversations.
9 CONCLUSION
Inthispaper,weproposedanovelapproach,namedBugListener,
whichcanautomaticallyidentifyandsynthesizebugreportsfrom
livechatmessages.BugListenerleveragesanovelgraphneuralnet-
work to model the graph-structured information of dialog, thereby
effectively predicts the bug-report dialogs. BugListener also adopts
atwicefine-tunedBERTmodelbyincorporatingthetransferlearn-
ingtechniquetosynthesizecompletebugreports.Theevaluation
results show that our approach significantly outperforms all other
baselines in both BRI and BRS tasks. We also conduct a human
evaluation to assess the correctness and quality of the bug reports
generated by BugListener. We apply BugListener on recent livechats from five new communitiesand obtain 31 potentialbug re-
portsintotal.Amongthe31bugreports,77%ofthemarecorrect.
71% of human evaluators agree that BugListener is useful. These
results demonstrate the significant potential of applying BugLis-tenerincommunity-basedsoftwaredevelopment,forpromoting
bug discovery and quality improvement.
ACKNOWLEDGMENTS
Wedeeplyappreciateanonymousreviewersfortheirconstructive
andinsightfulsuggestionstowardsimprovingthismanuscript.This
work is supported by the National Key Research and Development
Programof ChinaunderGrantNo.2018YFB1403400,theNational
Science Foundation of China under Grant No. 61802374, 62002348,
62072442, 614220920020 and Youth Innovation Promotion Associa-
tion Chinese Academy of Sciences.
REFERENCES
[1]2016. Chats in Docker Community. https://gitter.im/docker/docker?at=
5866382e058ca96737a943e7/.
[2] 2021. BugListener. https://github.com/BugListener/BugListener2022/.
[3]Ahmad Abdellatif, Khaled Badran, and Emad Shihab. 2020. MSRBot: Using Bots
to Answer Questions from Software Repositories. Empir. Softw. Eng. 25, 3 (2020),
1834â€“1863.
[4] Explosion AI. 2019. Spacy. https://spacy.io/.[5]
RanaAlkadhi,TeodoraLata,EmitzaGuzman,andBerndBruegge.2017. Rationale
in Development Chat Messages: An Exploratory Study. In Proceedings of the
14th International Conference on Mining Software Repositories, MSR 2017. IEEE
Computer Society, 436â€“446.
[6]Rana Alkadhi, Manuel Nonnenmacher, Emitza Guzman, and Bernd Bruegge.2018. HowdoDevelopersDiscussRationale?.In 25thInternationalConference
on Software Analysis, Evolution and Reengineering, SANER 2018. IEEE Computer
Society, 357â€“369.
[7]Deeksha Arya, Wenting Wang, Jin L. C. Guo, and Jinghui Cheng. 2019. Analysis
and Detection of Information Types of Open Source Software Issue Discussions.
InProceedings ofthe41st InternationalConference onSoftware Engineering,ICSE
2019, Montreal, QC, Canada, May 25-31, 2019. 454â€“464.
[8]Nicolas Bettenburg, Sascha Just, Adrian SchrÃ¶ter, Cathrin Weiss, Rahul Premraj,
andThomasZimmermann.2008. WhatMakesaGoodBugReport?.In Proceedings
of the 16th ACM SIGSOFT International Symposium on Foundations of Software
Engineering. ACM, 308â€“318. https://doi.org/10.1145/1453101.1453146
[9]NicolasBettenburg,RahulPremraj,ThomasZimmermann,andSunghunKim.
2008. Extracting Structural Information from Bug Reports. In Proceedings of the
2008 international working conference on Mining software repositories. 27â€“30.
[10]Isabelle Boutet, Megan LeBlanc, Justin A Chamberland, and Charles A Collin.2021. Emojis Influence Emotional Communication, Social Attributions, and
Information Processing. Computers in Human Behavior 119 (2021), 106722.
[11]OscarChaparro,CarlosBernal-CÃ¡rdenas,JingLu,KevinMoran,AndrianMarcus,
Massimiliano Di Penta, Denys Poshyvanyk, and Vincent Ng. 2019. Assessing
the Quality of the Steps to Reproduce in Bug Reports. In Proceedings of the ACM
JointMeetingonEuropeanSoftwareEngineeringConferenceandSymposiumon
309ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Lin Shi et al.
theFoundationsofSoftwareEngineering,ESEC/SIGSOFTFSE2019,Tallinn,Estonia,
August 26-30, 2019. ACM, 86â€“96. https://doi.org/10.1145/3338906.3338947
[12]OscarChaparro,JingLu,FiorellaZampetti,LauraMoreno,MassimilianoDiPenta,
Andrian Marcus, Gabriele Bavota, and Vincent Ng. 2017. Detecting Missing
Information in Bug Descriptions. In Proceedings of the 2017 11th Joint Meeting on
Foundations of Software Engineering. 396â€“407.
[13]PreethaChatterjee,KostadinDamevski,NicholasA.Kraft,andLoriL.Pollock.
2020. Software-relatedSlackChatswithDisentangledConversations.In MSRâ€™20:
17th International Conference on Mining Software Repositories. ACM, 588â€“592.
[14]Preetha Chatterjee, Kostadin Damevski, Lori Pollock, Vinay Augustine, and
Nicholas A Kraft. 2019. Exploratory Study of Slack Q&A Chats as a Mining
SourceforSoftwareEngineeringTools.In Proceedingsofthe16thInternational
Conference on Mining Software Repositories. IEEE Press, 490â€“501.
[15]Preetha Chatterjee, Kostadin Damevski, and Lori L. Pollock. 2021. Automatic Ex-
traction of Opinion-based Q&A from Online Developer Chats. In 43rd IEEE/ACM
International Conference on Software Engineering, ICSE. IEEE, 1260â€“1272. https:
//doi.org/10.1109/ICSE43902.2021.00115
[16]Preetha Chatterjee, Minji Kong, and Lori L. Pollock. 2020. Finding Help with
ProgrammingErrors:AnExploratoryStudyofNoviceSoftwareEngineersâ€™Focus
in Stack Overflow Posts. J. Syst. Softw. 159 (2020).
[17]Songqiang Chen, Xiaoyuan Xie, Bangguo Yin, Yuanxiang Ji, Lin Chen, andBaowen Xu. 2020. Stay Professional and Efficient: Automatically Generate Ti-tlesforYourBugReports.In 35thIEEE/ACMInternationalConferenceonAuto-
mated Software Engineering, ASE 2020. 385â€“397. https://doi.org/10.1145/3324884.
3416538
[18]PeterMChisnall.1993. QuestionnaireDesign,InterviewingandAttitudeMea-
surement. Journal of the Market Research Society 35, 4 (1993), 392â€“393.
[19]Shaiful Alam Chowdhury and Abram Hindle. 2015. Mining StackOverflow to
Filter Out Off-Topic IRC Discussion. (2015), 422â€“425.
[20]StevenDaviesandMarcRoper.2014. Whatâ€™sinaBugReport?.In 2014ACM-IEEE
International Symposium on Empirical Software Engineering and Measurement,
ESEM â€™14, Maurizio Morisio, Tore DybÃ¥, and Marco Torchiano (Eds.). ACM, 26:1â€“
26:10.
[21]JacobDevlin,Ming-WeiChang,KentonLee,andKristinaToutanova.2019. BERT:Pre-trainingofDeepBidirectionalTransformersforLanguageUnderstanding.InProceedingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociation
for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019,
Minneapolis,MN,USA,June2-7,2019,Volume1(LongandShortPapers).4171â€“4186.
https://doi.org/10.18653/v1/n19-1423
[22]LindaErlenhov,FranciscoGomesdeOliveiraNeto,andPhilippLeitner.2020. AnEmpiricalStudyofBotsinSoftwareDevelopment:CharacteristicsandChallenges
from a Practitionerâ€™s Perspective. In ESEC/FSE â€™20: 28th ACM Joint European
SoftwareEngineeringConferenceandSymposiumontheFoundationsofSoftware
Engineering, Virtual Event. ACM, 445â€“455.
[23]Steven Y. Feng, Varun Gangal, Jason Wei, Sarath Chandar, Soroush Vosoughi,
Teruko Mitamura,andEduardH. Hovy.2021. ASurveyof DataAugmentation
Approaches for NLP. In Findings of the Association for Computational Linguistics:
ACL/IJCNLP2021,OnlineEvent,August1-6,2021,Vol.ACL/IJCNLP2021.968â€“988.
https://doi.org/10.18653/v1/2021.findings-acl.84
[24]CuiyunGao,JichuanZeng,MichaelR.Lyu,andIrwinKing.2018. OnlineApp
Review Analysis for Identifying Emerging Issues. In Proceedings of the 40th
International Conference on Software Engineering, ICSE 2018. ACM, 48â€“58.
[25]CuiyunGao,WujieZheng,YuetangDeng,DavidLo,JichuanZeng,MichaelR.
Lyu,andIrwinKing.2019.EmergingAppIssueIdentificationfromUserFeedback:
Experience on WeChat. In Proceedings of the 41st International Conference on
SoftwareEngineering:SoftwareEngineeringinPractice,ICSE(SEIP)2019 .IEEE/
ACM, 279â€“288.
[26] Gitter. 2020. REST API. https://developer.gitter.im/docs/rest-api.[27] Google. 2020. Gitter. https://gitter.im/.[28] Google. 2020. Slack. https://slack.com/.[29]
Gaoyang Guo, Chaokun Wang, Jun Chen, Pengcheng Ge, and Weijun Chen.2019. Who is answering whom? Finding "Reply-To" relations in group chats
withdeepbidirectionalLSTMnetworks. 22,Suppl1(2019),2089â€“2100. https:
//doi.org/10.1007/s10586-018-2031-4
[30]HuiGuoandMunindarP.Singh.2020. Caspar:ExtractingandSynthesizingUserStoriesofProblemsfromAppReviews.In ICSEâ€™20:42ndInternationalConference
on Software Engineering. ACM, 628â€“640.
[31]WilliamLHamilton,RexYing,andJureLeskovec.2017. RepresentationLearning
on Graphs: Methods and Applications. arXiv preprint arXiv:1709.05584 (2017).
[32]QiaoHuang,XinXia,DavidLo,andGailC.Murphy.2018. AutomatingIntention
Mining.IEEE Transactions on Software Engineering PP, 99 (2018), 1â€“1.
[33]Armand Joulin, Edouard Grave, Piotr Bojanowski, Matthijs Douze, HÃ©rve JÃ©gou,
andTomasMikolov.2016. FastText.zip:Compressingtextclassificationmodels.
arXiv preprint arXiv:1612.03651 (2016).
[34]Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma,
QiweiYe,andTie-YanLiu.2017. LightGBM:AHighlyEfficientGradientBoostingDecisionTreef.In AdvancesinNeuralInformationProcessingSystems.3146â€“3154.[35]Chaiyakarn Khanan, Worawit Luewichana, Krissakorn Pruktharathikoon, Ji-
rayusJiarpakdee,ChakkritTantithamthavorn,MorakotChoetkiertikul,Chaiy-
ong Ragkhitwetsagul, and Thanwadee Sunetnanta. 2020. JITBot: An Explainable
Just-In-TimeDefectPredictionBot.In 35thIEEE/ACMInternationalConference
on Automated Software Engineering, ASE 2020. IEEE, 1336â€“1339.
[36]Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with
GraphConvolutionalNetworks.In InternationalConferenceonLearningRepre-
sentations (ICLR).
[37] kootenpv. 2019. Contractions. https://github.com/kootenpv/contractions/.[38]
AlexKrizhevsky,IlyaSutskever,andGeoffreyEHinton.2012.ImagenetClassifica-
tion with Deep Convolutional Neural Networks. Advances in neural information
processing systems 25 (2012), 1097â€“1105.
[39]Jonathan K Kummerfeld, Sai R Gouravajhala, Joseph Peper, Vignesh Athreya,
Chulaka Gunasekara, Jatin Ganhotra, Siva Sankalp Patel, Lazaros Polymenakos,
and Walter S Lasecki. 2018. A Large-Scale Corpus for Conversation Disentangle-
ment.arXiv preprint arXiv:1810.11118 (2018).
[40]MingyangLi,LinShi,YeYang,andQingWang.2020. ADeepMultitaskLearning
Approach for Requirements Discovery and Annotation from Open Forum. In
35th IEEE/ACM International Conference on Automated Software Engineering,ASE 2020, Melbourne, Australia, September 21-25, 2020 . IEEE, 336â€“348. https:
//doi.org/10.1145/3324884.3416627
[41]AndyLiaw,MatthewWiener,etal .2002. ClassificationandRegressionbyran-
domForest. Rn e w s2, 3 (2002), 18â€“22.
[42]BinLin,AlexeyZagalsky,Margaret-AnneD.Storey,andAlexanderSerebrenik.
2016. WhyDevelopersAreSlackingOff:UnderstandingHowSoftwareTeams
Use Slack. In Proceedings of the 19th ACM Conference on Computer Supported
Cooperative Work and Social Computing. 333â€“336.
[43]Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr DollÃ¡r. 2017.
FocalLossforDenseObjectDetection.In ProceedingsoftheIEEEinternational
conference on computer vision. 2980â€“2988.
[44]Hui Liu, Zhan Shi, Jia-Chen Gu, Quan Liu, Si Wei, and Xiaodan Zhu. 2020. End-
to-End Transition-Based Online Dialogue Disentanglement. In Proceedings of the
Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI 2020,
Christian Bessiere (Ed.). 3868â€“3874. https://doi.org/10.24963/ijcai.2020/535
[45]WalidMaalej,ZijadKurtanovic,HadeerNabil,andChristophStanik.2016. On
the AutomaticClassification of AppReviews. Requir. Eng. 21, 3(2016), 311â€“331.
https://doi.org/10.1007/s00766-016-0251-9
[46]WalidMaalejandHadeerNabil.2015. BugReport,FeatureRequest,orSimply
Praise?onAutomaticallyClassifyingAppReviews.In 2015IEEE23rdinternational
requirements engineering conference (RE). IEEE, 116â€“125.
[47]Harish Tayyar Madabushi, Elena Kochkina, and Michael Castelle. 2020. Cost-
Sensitive BERT for Generalisable Sentence Classification with Imbalanced Data.
arXiv preprint arXiv:2003.11563 (2020).
[48]AndrewMcCallum,KamalNigam,etal .1998. AComparisonofEventModels
for Naive Bayes Text Classification. In AAAI-98 workshop on learning for text
categorization, Vol. 752. Citeseer, 41â€“48.
[49]CourtneyMiller,PaigeRodeghero,Margaret-AnneD.Storey,DenaeFord,and
Thomas Zimmermann. 2021. "How Was Your Weekend?" Software Development
Teams Working From Home During COVID-19. CoRRabs/2101.05877(2021).
[50]VinodNairandGeoffreyEHinton.2010.RectifiedLinearUnitsImproveRestricted
Boltzmann Machines. In Icml.
[51]Shengyi Pan, Lingfeng Bao, Xiaoxue Ren, Xin Xia, David Lo, and Shanping Li.[n.d.]. Automating Developer Chat Mining. In 36th IEEE/ACM International
ConferenceonAutomatedSoftwareEngineering,ASE2021,Melbourne,Australia,
November 15-19, 2021. 854â€“866. https://doi.org/10.1109/ASE51524.2021.9678923
[52]Esteban Parra, Ashley Ellis, and Sonia Haiduc. 2020. GitterCom: A Dataset of
OpenSourceDeveloperCommunicationsinGitter.In MSRâ€™20:17thInternational
Conference on Mining Software Repositories. ACM, 563â€“567.
[53]QuentinPerez,Pierre-AntoineJean,ChristelleUrtado,andSylvainVauttier.2021.Bug or not bug? That is the Question. In 29th IEEE/ACM International Conference
on Program Comprehension, ICPC 2021, Madrid, Spain, May 20-21, 2021. IEEE,
47â€“58. https://doi.org/10.1109/ICPC52881.2021.00014
[54]AntÃ´nio Mauricio Pitangueira, Paolo Tonella, Angelo Susi, Rita Suzana Pi-tangueira Maciel, and MÃ¡rcio de Oliveira Barros. 2017. Minimizing the Stake-
holder DissatisfactionRisk inRequirement Selectionfor NextRelease Planning.
Information & Software Technology 87 (2017), 104â€“118.
[55]Jantima Polpinij. 2021. A Method of Non-bug Report Identification from Bug
ReportRepository. Artif.LifeRobotics 26,3(2021),318â€“328. https://doi.org/10.
1007/s10015-021-00681-3
[56]C.Qu,L.Yang,W.B.Croft,Y.Zhang,J.Trippas,andM.Qiu.2019. UserIntent
Prediction in Information-seeking Conversations. In CHIIR â€™19.
[57]PaigeRodeghero, SiyuanJiang,AmeerArmaly, andCollinMcMillan.2017. De-
tectingUserStoryInformationinDeveloper-clientConversationstoGenerate
Extractive Summaries. In Proceedings of the 39th International Conference on
SoftwareEngineering,ICSE2017,BuenosAires,Argentina,May20-28,2017.49â€“59.
[58]Simone Scalabrino, Gabriele Bavota, Barbara Russo, Massimiliano Di Penta, and
Rocco Oliveto. 2019. Listening to the Crowd for the Release Planning of Mobile
Apps.IEEE Trans. Software Eng. 45, 1 (2019), 68â€“86. https://doi.org/10.1109/TSE.
2017.2759112
310BugListener: Identifying and Synthesizing Bug Reports from Collaborative Live Chats ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
[59]FrancoScarselli,MarcoGori,AhChungTsoi,MarkusHagenbuchner,andGabriele
Monfardini.2008. TheGraphNeuralNetworkModel. IEEEtransactionsonneural
networks 20, 1 (2008), 61â€“80.
[60]Michael Schlichtkrull, Thomas N Kipf, Peter Bloem, Rianne Van Den Berg, Ivan
Titov,andMaxWelling.2018. ModelingRelationalDatawithGraphConvolu-
tional Networks. In European semantic web conference. Springer, 593â€“607.
[61]s.e.a.l. 2017. UZH-s.e.a.l.-Development Emails Content Analyzer (DECA). https:
//www.ifi.uzh.ch/en/seal/people/panichella/tools/DECA.html.
[62]LinShi,XiaoChen,YeYang,HanzhiJiang,ZiyouJiang,NanNiu,andQingWang.
2021. A First Look at Developersâ€™ Live Chat on Gitter. In Proceedings of the 29th
ACM Joint Meeting on European Software Engineering Conference and Symposium
on the Foundations of Software Engineering. 391â€“403.
[63]LinShi,ZiyouJiang,YeYang,XiaoChen,YuminZhang,FangwenMu,Hanzhi
Jiang, and Qing Wang. [n.d.]. ISPY: Automatic Issue-Solution Pair Extraction
from Community Live Chats. In 36th IEEE/ACM International Conference on
AutomatedSoftwareEngineering,ASE2021,Melbourne,Australia,November15-19,
2021. 142â€“154. https://doi.org/10.1109/ASE51524.2021.9678894
[64]Lin Shi, Mingzhe Xing, Mingyang Li, Yawen Wang, Shoubin Li, and Qing Wang.
2020. Detection of Hidden Feature Requests from Massive Chat Messages viaDeepSiameseNetwork.In ICSEâ€™20:42ndInternationalConferenceonSoftware
Engineering. ACM, 641â€“653.
[65]Emad Shihab, Zhen Ming Jiang, and Ahmed E. Hassan. 2009. On the Use of
Internet Relay Chat (IRC) Meetings by Developers of the GNOME GTK+ Project.
InProceedings of the 6th International Working Conference on Mining Software
Repositories, MSR 2009 (Co-located with ICSE), Vancouver, BC, Canada, May 16-17,
2009, Proceedings. 107â€“110.
[66]EmadShihab,ZhenMingJiang,andAhmedE.Hassan.2009. StudyingtheUse
ofDeveloperIRCMeetingsinOpenSourceProjects.In 25thIEEEInternational
ConferenceonSoftwareMaintenance(ICSM2009),September20-26,2009,Edmonton,
Alberta, Canada. 147â€“156.
[67]Yang Song and Oscar Chaparro. 2020. BEE. http://bugreportchecker.ngrok.io/
api/.
[68]YangSongandOscarChaparro.2020. BEE:AToolForStructuringandAnalyzing
Bug Reports. In Proceedings of the 28th ACM Joint Meeting on European Software
EngineeringConferenceandSymposiumontheFoundationsofSoftwareEngineering.
1551â€“1555.
[69]Andrea Di Sorbo, Sebastiano Panichella, Corrado Aaron Visaggio, Massim-iliano Di Penta, Gerardo Canfora, and Harald C. Gall. 2015. DevelopmentEmails Content Analyzer: Intention Mining in Developer Discussions (T). In
30th IEEE/ACM International Conference on Automated Software Engineering, ASE
2015, Lincoln, NE, USA, November 9-13, 2015. 12â€“23.
[70]Andrea Di Sorbo, Sebastiano Panichella, Corrado Aaron Visaggio, Massimil-
iano Di Penta, Gerardo Canfora, and Harald C. Gall. 2016. DECA: DevelopmentEmailsContentAnalyzer.In Proceedingsofthe38thInternationalConferenceon
SoftwareEngineering,ICSE2016,Austin,TX,USA,May14-22,2016-Companion
Volume. ACM, 641â€“644. https://doi.org/10.1145/2889160.2889170
[71]Chanchal Suman, Sriparna Saha, Pushpak Bhattacharyya, and Rohit Shyamkant
Chaudhari.2021. EmojiHelps!AMulti-modalSiameseArchitectureforTweet
User Verification. Cognitive Computation 13, 2 (2021), 261â€“276.
[72]CongSunandZhihaoYang.2019. TransferLearninginBiomedicalNamedEntity
Recognition:AnEvaluationofBERTinthePharmaCoNERtask.In Proceedings
of The 5th Workshop on BioNLP Open Shared Tasks. 100â€“104.
[73]Pannavat Terdchanakul, Hideaki Hata, Passakorn Phannachitta, and Kenichi
Matsumoto. 2017. Bug or Not? Bug Report Classification Using N-Gram IDF. In
2017IEEEInternationalConferenceonSoftwareMaintenanceandEvolution,ICSME
2017,Shanghai,China,September17-22,2017.IEEEComputerSociety,534â€“538.
https://doi.org/10.1109/ICSME.2017.14
[74]Phong MinhVu, Tam TheNguyen, Hung VietPham, andTungThanh Nguyen.
2015. MiningUserOpinionsinMobileAppReviews:AKeyword-BasedApproach
(T).In30thIEEE/ACMInternationalConferenceonAutomatedSoftwareEngineering,
ASE 2015. IEEE Computer Society, 749â€“759.
[75]Phong MinhVu, Hung VietPham, Tam TheNguyen, andTungThanh Nguyen.
2016. Phrase-based Extraction of User Opinions in Mobile App Reviews. In
Proceedingsofthe31stIEEE/ACMInternationalConferenceonAutomatedSoftware
Engineering, ASE 2016. ACM, 726â€“731.
[76]Jason W. Wei and Kai Zou. 2019. EDA: Easy Data Augmentation Techniques for
Boosting Performance on Text Classification Tasks. In Proceedings of the 2019
Conference on Empirical Methods in Natural Language Processing and the 9th
InternationalJointConferenceonNaturalLanguageProcessing,EMNLP-IJCNLP
2019,HongKong,China,November3-7,2019.6381â€“6387. https://doi.org/10.18653/
v1/D19-1670
[77]YeZhangandByronC.Wallace.2015. ASensitivityAnalysisof(andPractitionersâ€™
Guide to) Convolutional Neural Networks for Sentence Classification. CoRR
abs/1510.03820(2015).
[78]Yu Zhao, Kye Miller, Tingting Yu, Wei Zheng, and Minchao Pu. 2019. Automati-
cally Extracting BugReproducing Steps from Android Bug Reports.In Reuse in
theBigDataEra-18thInternationalConferenceonSoftwareandSystemsReuse,
ICSR. 100â€“111. https://doi.org/10.1007/978-3-030-22888-0_8
[79]Yukun Zhu, Ryan Kiros, Rich Zemel, Ruslan Salakhutdinov, Raquel Urtasun,
Antonio Torralba, and Sanja Fidler. 2015. Aligning Books and Movies: Towards
Story-Like Visual Explanations by Watching Movies and Reading Books. In The
IEEE International Conference on Computer Vision (ICCV).
[80]ThomasZimmermann,RahulPremraj,NicolasBettenburg,SaschaJust,Adrian
Schroter, and Cathrin Weiss. 2010. What Makes a Good Bug Report? IEEE
Transactions on Software Engineering 36, 5 (2010), 618â€“643.
311