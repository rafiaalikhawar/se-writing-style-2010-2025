Learning Program Semantics for VulnerabilityDetection via
Vulnerability-Specific Inter-procedural Slicing
BozhiWuâˆ—
SingaporeManagementUniversity
Singapore
bozhiwu@smu.edu.sgShangqing Liuâ€ 
NanyangTechnologicalUniversity
Singapore
shangqingliu666@gmail.comYang Xiao
ChineseAcademy ofSciences
China
xiaoyang@iie.ac.cn
Zhiming Li
NanyangTechnologicalUniversity
Singapore
ZHIMING001@e.ntu.edu.sgJunSun
SingaporeManagementUniversity
Singapore
JunSun@smu.edu.sgShang-WeiLin
NanyangTechnologicalUniversity
Singapore
shang-wei.lin@ntu.edu.sg
ABSTRACT
Learning-basedapproachesthatlearncoderepresentationsforsoft-
warevulnerabilitydetectionhavebeenproventoproduceinspiring
results. However, they stillfailtocapture complete andprecisevul-
nerabilitysemanticsforcoderepresentations.Toaddressthelimita-
tions, in this work, we propose a learning-based approachnamely
SnapVuln ,which/f_irstutilizesmultiplevulnerability-speci/f_icinter-
procedural slicing algorithms to capture vulnerability semantics
of various types and then employs a Gated Graph Neural Network
(GGNN)withanattentionmechanismtolearnvulnerabilityseman-
tics. We compare SnapVuln with state-of-the-art learning-based ap-
proachesontwopublicdatasets,andcon/f_irmthat SnapVuln outper-
formsthem.Wefurtherperformanablationstudyanddemonstrate
that the completeness and precision of vulnerability semantics cap-
turedbySnapVuln contribute tothe performance improvement.
CCSCONCEPTS
â€¢Security and privacy â†’Software security engineering .
KEYWORDS
Vulnerability detection,programsemantics,code representations.
ACM ReferenceFormat:
Bozhi Wu, Shangqing Liu, Yang Xiao, Zhiming Li, Jun Sun, and Shang-
Wei Lin. 2023. Learning Program Semantics for Vulnerability Detection
via Vulnerability-Speci/f_ic Inter-procedural Slicing. In Proceedings of the
31stACMJoint EuropeanSoftwareEngineeringConferenceand Symposium
on the Foundations of Software Engineering (ESEC/FSE â€™23), December 3â€“9,
2023, San Francisco, CA, USA. ACM, New York, NY, USA, 13pages.https:
//doi.org/10.1145/3611643.3616351
1 INTRODUCTION
Software security is crucial in practice and thus has attracted wide-
spread attention from academia and industry. Although various
âˆ—AlsowithNanyang TechnologicalUniversity.
â€ Corresponding author.
ESEC/FSE â€™23,December 3â€“9, 2023, SanFrancisco, CA, USA
Â©2023 Copyright held bytheowner/author(s).
ACM ISBN979-8-4007-0327-0/23/12
https://doi.org/10.1145/3611643.3616351techniques including symbolic execution [ 7,14,53], data /f_low anal-
ysis[5,16,23]andfuzztesting[ 29,49,57]havebeenproposedto
improvesoftwaresecurity,itisstillafarfrombeingsolved.Speci/f_i-
cally, symbolic executionaims at traversingall execution paths to
/f_indthevulnerabilitiesbutsuï¬€ersfrompathexplosionproblems.
Staticanalysissuchasdata/f_lowanalysismayresultinexcessive
false positives while fuzz testing will result in high false negatives.
Inspired by the great success of deep learning techniques, many
learning-based approaches [ 15,17,18,37â€“40,51,68,70] have been
proposedtobuildanautomatedvulnerabilitydetectionsystemand
achieveencouragingresults.Themainideaoflearning-basedap-
proaches is tolearneï¬€ective coderepresentations from programs
that can reveal vulnerability patterns for vulnerability classi/f_ica-
tion.Forexample,Russelletal.[ 51]utilizeConvolutionalNeural
Network (CNN) and Gated Recurrent Unit (GRU) to learn vector
representations from lexical tokens of source code for vulnera-
bility detection. To obtain comprehensive code representations,
Devign [68] /f_irst extracts four kinds of graphs from the source
code,includingAbstractSyntaxTree(AST),ControlFlowGraph
(CFG),Data Flow Graph(DFG)and NaturalCode Sequence (NCS),
and learn code representations from these graphs using graph neu-
ral network (GNN) for vulnerability detection. But the extracted
programsemanticsarenotallaboutvulnerabilities.Inordertocap-
ture the precise vulnerabilitypatterns, VulDeePecker [ 40] applies
slicing techniques on Data Dependency Graph (DDG) to extract
program semantics of vulnerable parts, and leverage BLSTM to
generate the /f_inal code representationsforvulnerability classi/f_ica-
tion. However, existing learning-based approaches still suï¬€er from
the following two limitations, which prevent them from obtaining
precise program semantics of vulnerable parts for code representa-
tiongeneration.Inthispaper,werefertotheprogramsemanticsof
vulnerable parts as vulnerability semantics .
Limitation1: The extracted vulnerability semantics are
incomplete. Some works [ 15,51,68] utilize neural networks to
detect vulnerabilities for a single function. One well-received work
Devign [68] constructed a code property graph to extract program
structures and utilized graph neural networks (GNNs) to learn
program semantics for vulnerability detection. Although it pro-
ducedinspiringresults,itonlyfocusesonsingle-functiondetection,
while the semantics of callee functions are missed because the im-
plementationsofthesecalleefunctionsarenotconsideredinthe
proposed approach. In practice, vulnerabilities may span across
Thiswork islicensedunderaCreativeCommonsAttribution4.0Interna-
tional License.
1371
ESEC/FSE â€™23, December3â€“9, 2023,San Francisco, CA, USA Bozhi Wu, Shangqing Liu, Yang Xiao, ZhimingLi, Jun Sun,andShang-WeiLin
multiplefunctions(i.e.,betweenafunctionanditscalleefunctions).
Hence,thesetechniquestargetingsingle-functiondetectioncannot
capture complete vulnerabilitysemantics.
Limitation2: The extracted vulnerability semantics are
imprecise. Other works [ 17,38â€“40] leverage program slicing al-
gorithmstoextractvulnerabilitysemanticsstartingfromvarious
vulnerableprogrampoints(e.g.,dangerousAPIcallsorvariables)
for code representation generation. However, these slicing algo-
rithmscannotdiscriminatethesinkorsource,andeverystatement
that depends on the vulnerable program points will be included.
Thisproblemhasalsobeenstatedinpreviousresearchwork[ 28].
Therefore,statementsunrelatedtovulnerabilitieswillbeintroduced
intothesliceasnoise,makingtheextractedvulnerabilityseman-
tics imprecise. Besides, these slicing algorithms perform slicing on
DDG or Program Dependence Graph (i.e., PDG), without consid-
ering CFG that reveals the program execution order. This would
leadtofailuretocatchthesemanticsofvulnerabilitiescausedby
incorrectexecutionorder,suchasâ€œUseAfterFreeâ€,whichistrig-
geredwhentheoperationâ€œuseâ€occursaftertheoperationâ€œfreeâ€.In
summary,theprogramslicingalgorithmsusedinpreviouslearning-
basedapproachesareinsuï¬ƒcienttocaptureprecisevulnerability
semantics.
To address the aforementioned limitations, in this work, we pro-
poseSnapVuln , a learning-based approach that applies multiple
vulnerability-speci/f_ic inter-procedural algorithms that identify the
sourceandsinktocapturepreciseprogramsemanticsofvariousvul-
nerability types for vulnerability detection. Speci/f_ically, we extract
theInter-proceduralGraph(IG)fromthesourcecode,whichcan
beregardedasacombinationofPDG,CFGandCallGraphs(CG).
Then, we design multiple vulnerability-speci/f_ic slicing algorithms
for diï¬€erent vulnerability types to capture precise vulnerability se-
mantics, which identify source and sink and further operate on the
inter-proceduralgraph.Inthiswork,weimplementvulnerability-
speci/f_icslicingalgorithms forsix common vulnerability types in
C/C++. To learn better code representation for diï¬€erent vulnerabil-
itytypes,weemployasubmodelforeachvulnerabilitytype,which
utilizes a Gated Graph Neural Network (GGNN) with an attention
mechanism,andaGNNmodelforvulnerabilitiesnotcoveredbythe
slicingalgorithms.Afterthat,weensemblethesubmodelsandGNN
model to predict vulnerabilities. For instance, given an example,
SnapVuln extractssixtypesofsubgraphsfromIGaspotentialvul-
nerabilitysemanticsaccordingtotheprogramslicingalgorithms.
Eachtypeofsubgraphisthenfedintothecorrespondingsubmodel,
whichcapturethestructuralsemanticsinthesubgraphsanddynam-
ically learn diï¬€erent weights for diï¬€erent subgraphs to generate
bettercoderepresentations.TheIGisfedintotheGNNmodelto
capturecomprehensiveprogramsemantics.Finally,weensemble
the output of the six submodels and the GNN model to obtain a
comprehensive prediction.
Todemonstratetheeï¬€ectivenessof SnapVuln,weconductexten-
siveexperimentsontwopublicdatasetsandcompare SnapVuln with
sevenstate-of-the-artbaselines.Theexperimentalresultsshowthat
SnapVuln outperforms these baselines. We further perform an abla-
tionstudytodemonstratethatthecompletenessandprecisionof
our learned vulnerability semantics contribute to the improvement
of vulnerability detection. In summary, our main contributions are
as follows:1intSMB2_write (...){
2 ...
3 req->sync_hdr.ProcessId = cpu_to_le32(io_parms->pid);
4 ...
5- cifs_small_buf_release(req);
6 ...
7 if (rc) {
8 trace_smb3_write_err(xid, req->PersistentFileId,
9 ...
10 }
11+ cifs_small_buf_release(req);
12 ...
13}
14voidcifs_small_buf_release (void*buf_to_free){
15 ...
16 mempool_free(buf_to_free, cifs_sm_req_poolp);
17 ...
18}
19voidmempool_free (void*element, mempool_t *pool){
20 ...
21 pool->free(element, pool->pool_data);
22}
(a) â€œUse AfterFreeâ€from commit 6a3eb33
1intdtls1_buffer_message (SSL *s, intis_ccs){
2 hm_fragment *frag;
3 ...
4 frag = dtls1_hm_fragment_new(s->init_num, 0);
5+ if (!frag)
6+ return 0;
7 memcpy(frag->fragment, s->init_buf->data, s->init_num );
8 ...
9 frag->msg_header.msg_len = s->d1->w_msg_hdr.msg_len;
10 frag->msg_header.seq = s->d1->w_msg_hdr.seq;
11 frag->msg_header.type = s->d1->w_msg_hdr.type;
12 ...
13 item = pitem_new(seq64be, frag);
14 if ( item == NULL){
15 dtls1_hm_fragment_free(frag);
16 return0;
17 }
18 ...
19}
(b) â€œNull Pointer Dereferenceâ€from commit 7a9d59c
Figure 1: Two Real-world Examples from GitHub Open-
source Projects. The lines starting with â€œ-â€ indicates that
these lines of statements have security risks and they are
/f_ixed by thestatements marked with â€œ+â€.
â€¢We propose dedicated slicing algorithms for six common vul-
nerability types in C/C++ to achieve precise vulnerability se-
mantics. To the best of our knowledge, we are the /f_irst to design
vulnerability-speci/f_icslicingalgorithmstocaptureprecisevulner-
ability semantics based on diï¬€erent vulnerability characteristics.
â€¢We incorporate the attention mechanism into the gated graph
neural network (GGNN) to ensure that the model can learn to
assigndiï¬€erentweightstosubgraphsproducedbyslicingalgo-
rithms,soastohelpthemodellearnbetterrepresentationsfor
vulnerabilitydetection.
â€¢Weanalysethelimitationsofexistingdeeplearning-basedworks
for vulnerabilitydetection andshow that thecompletenessand
precision of vulnerability semantics is vital for automated vul-
nerability detection byextensive experiments.
â€¢We conduct extensive experiments to compare SnapVuln with
seven state-of-the-art baselines, including /f_ive learning-based
vulnerabilitydetectionbaselinesandtwopre-trainedapproaches
on two public datasets. Experimental results show that SnapVuln
outperformsthesebaselinessigni/f_icantly.Wehavemadeourcode
anddata publicat our website [ 6]for reproduction.
2 MOTIVATION
The key to learning-based vulnerability detection is to learn better
code representations for the detection. To achieve this, program
semanticsaboutvulnerableparts(herereferto vulnerabilityse-
mantics) should be well captured for representation. Therefore, in
ordertoinvestigatehowwellexistinglearning-basedapproaches
capture vulnerability semantics, we conduct an in-depth analy-
sis and discover two important aspects on which learning-based
approachesshould improve.
1372Learning Program Semantics forVulnerabilityDetectionviaVulnerability-SpecificInter-proceduralSlicing ESEC/FSE â€™23, December3â€“9, 2023,San Francisco, CA, USA
g2g1
SamplePDGs
CFGs
CGsInter-procedural 
Graph GenerationVulnerability -specific 
Program Slicing SubModel Architecture
IGGGNN
â€¦Subgraph 1
Subgraph kSubgraph 2Attention
FC Layer
â€¦g1
g2
gkBO Subgraphsâ€¦Prediction 
(0/1)[cls] a
gkâ€¦ğ‘1
ğ‘2
ğ‘ğ‘˜
â€¦
ML Subgraphs
â€¦
DF Subgraphs
â€¦
IGOutputSubmodel_1
â€¦
Ensemble
GNN_modelTraining & testing
GNN_model ArchitectureGGNNIG
FC Layerg
OutputSubmodel_2
Submodel_6Sample k subgraphs
Sample k subgraphs
Sample k subgraphs
Figure 2:The overview of SnapVuln .
Table 1: Line number of statements captured by diï¬€erent
slicing approachesfortheexample inFigure 1(b).
Linenumber GroundTruth VulDeePecker SySeVR DeepWukong SnapVuln
2/enc-33 /enc-33 /enc-33 /enc-33 /enc-37
4/enc-33 /enc-33 /enc-33 /enc-33 /enc-33
7/enc-33 /enc-33 /enc-33 /enc-33 /enc-33
9/enc-37/enc-33 /enc-33 /enc-33 /enc-37
10/enc-37/enc-33 /enc-33 /enc-33 /enc-37
11/enc-37/enc-33 /enc-33 /enc-33 /enc-37
13/enc-37/enc-33 /enc-33 /enc-33 /enc-37
14/enc-37 /enc-37 /enc-33 /enc-33 /enc-37
15/enc-37/enc-33 /enc-33 /enc-33 /enc-37
16/enc-37 /enc-37 /enc-33 /enc-33 /enc-37
Finding 1: Inter-procedural analysis should be introduced
tocapturethecompletevulnerabilitysemantics. Inthereal
world, itis common for avulnerability to span multiple functions.
Forexample,asshowninFigure 1(a),thepointerâ€œreqâ€isusedagain
online8afterbeingfreedonline5,whichtriggersâ€œUseAfterFreeâ€
vulnerability.Thisvulnerabilityspansthreefunctions.Ifonlythe
functionâ€œSMB2_writeâ€ isconsidered asinput,the functionâ€œmem-
pool_freeâ€thatcontainstheimportantsemanticsofreleasingmem-
orywillbelost,andconsequently,themodelwillbeunabletolearn
coderepresentationwellforvulnerabilitydetection.However,exist-
inglearning-basedapproachessuchasDevign[ 68],REVEAL[ 15]
and Draper [ 51] detect vulnerabilities for a single function. There-
fore,aninter-proceduralanalysisshouldbeintroducedtocapture
completevulnerabilitysemanticsacrossmultiplefunctionsforcode
representation generation.
Finding2:Slicingalgorithmsshouldbedesignedtocapture
precise vulnerability semantics. We investigate how existing
learning-based approachesobtain vulnerability semanticsfor code
representation generation, and discover that most of them can
not capture precise vulnerability semantics. Speci/f_ically, VulDeeP-
ecker[40]performedprogramslicingonDDGbasedonlibrary/API
functioncalls,whileSySeVR[ 39]andDeepWukong[ 17]performed
program slicing on PDGs. On one hand, these slicing algorithms
do not capture the control /f_low information (i.e., CFG) in the code,
whichmakesthemimpossibletorevealsomevulnerabilitiescaused
by wrong execution order, such as "Use After Free". On other hand,
theseslicingalgorithmsmayincludestatementsthatarenotrelated
to vulnerabilities,since somestatements that are not related to vul-
nerabilitiesmayalsodependonvulnerability-relatedstatements.
We take the â€œNull Pointer Dereferenceâ€ sample in Figure 1(b)as
an example,and follow theslicingalgorithms in these approachestoobtainthecorrespondingresultsshowninTable 1.Weassume
thattheseapproachestakeline4asaslicingcriterion,wherethe
functionâ€œdtls1_hm_fragment_newâ€iscalled.Theresultsshowthat
theyobtain160%morestatementsthanrealvulnerabilitysemantics,
which are imprecise. We can infer thatslicing algorithms should
be improvedto capture precise vulnerabilitysemantics.
3 APPROACH
Motivated by the aforementioned /f_indings, we propose a learning-
based approach namely SnapVuln . It applies vulnerability-speci/f_ic
inter-proceduralslicingalgorithmstocapturecompleteandprecise
vulnerability semantics of various vulnerability types in C/C++
and leverages a GGNN with an attention mechanism to learn good
representations for vulnerabilitydetection. We present the details
ofSnapVuln below.
3.1 Overview
Figure2showstheoverviewof SnapVuln,whichmainlyconsistsof
threecomponents:inter-proceduralgraphgeneration,vulnerability-
speci/f_ic program slicing, and the well-designed models. In the /f_irst
component, we extract CFGs, PDGs and call graphs from each
sample, and utilize them to construct an inter-procedural graph to
representthecompleteprogramsemanticsforeachsample.Thesec-
ond component utilizes the vulnerability-speci/f_ic inter-procedural
slicing algorithms to extract the precise vulnerability semantics
from the complete program semantics. As a result, multiple sets
ofsubgraphsareextractedfromtheinter-proceduralgraph,each
containingthepotentialvulnerabilitysemanticscorrespondingto
itsspeci/f_ictype.Thethirdcomponentemploysmultiplesubmod-
elsandaGNNmodeltoindividuallycapturethedistincttypesof
vulnerability semantics for vulnerability detection. Speci/f_ically, the
novel submodel that customizes a GGNN with an attention mecha-
nism is proposed to capture the vulnerability semantics of speci/f_ic
typefromthecorrespondingsetofsubgraphsindividually.More-
over,toaddressvulnerabilitiesthatarenotcoveredbytheslicing
algorithms, we utilize a GNN model to capture the comprehensive
program semantics of the sample from the inter-procedural graph.
ThisGNNmodelcanbeconsideredasasubmodelwithoutanatten-
tionmechanism,allowingittoidentifyandpredictthoseunhandled
vulnerabilities by the slicing algorithms. Finally, the predictions
from the multiple submodels and the GNN model are ensembled to
1373ESEC/FSE â€™23, December3â€“9, 2023,San Francisco, CA, USA Bozhi Wu, Shangqing Liu, Yang Xiao, ZhimingLi, Jun Sun,andShang-WeiLin
generatethe/f_inalpredictions.Thisensembleapproachcombines
theoutputsof each model, resulting in more accurate and reliable
predictions for vulnerabilitydetection.
Process: In the training phase, SnapVuln constructs the inter-
procedural graphs for all training data and extracts six sets of
subgraphsforeachsample.Thesixsetsofsubgraphscontainpo-
tential vulnerability semantics of speci/f_ic types. Since a sample
may generate an arbitrary number of subgraphs, we randomly
sample/u1D458subgraphs from each set to represent the vulnerability
semantics corresponding to its speci/f_ic type, and de/f_ine them as
G={/u1D4541,...,/u1D454/u1D458}.Afterthat,eachsetofsubgraphs G,corresponding
to a speci/f_ic vulnerability type, is individually fed into a submodel
fortraining.Thesesubmodelsaredesignedtolearnandcapturethe
speci/f_ic vulnerability semantics associated with each vulnerability
type. Furthermore, the inter-procedural graphs are used to train
a GNN model, which aims to capture vulnerabilitysemantics that
arenothandledbytheexistingslicingalgorithms.Allthesemodels
are trained independently. If a new slicing algorithm is introduced
for other vulnerability type, a new submodel can be added, and
the subgraphsextracted by thenew slicing algorithmcan be used
to train the submodel. This modular approach provides scalability
by allowing the incorporation of new slicing algorithms and the
expansion of therange ofvulnerability typesthat can be detected.
Inthetestingphase,sixsetsofsubgraphsandaninter-procedural
graphareextractedfromeachsample.Foreachsetofsubgraphs,
/u1D458subgraphsaresampledtorepresentthevulnerabilitysemantics
of its speci/f_ic type. After that, the six sets of subgraphs, along
with the inter-procedural graph,are then individually fed into the
corresponding well-trained submodels and GNN model. Finally,
SnapVuln ensembles the outputs of the submodels and GNN model
to make a/f_inal prediction for eachsample.
3.2 Inter-procedural GraphGeneration
In order to capture the complete vulnerability semantics, the inter-
procedural analysis should be utilized in the data preprocessing
stage. Therefore, we utilize the popular static analysis tool Jo-
ern[1]toextractcodepropertygraphsandfurtherbuildaninter-
proceduralgraph for eachsample.
De/f_inition. In this paper, an inter-procedural graph I/u1D43Ais a di-
rectedgraphconsistingofasetofnodesandedgeswhereeachnode
representsonestatementinthesampleandeachedgerepresents
the relationship between two statements, including control /f_low,
data/controldependency,andfunctioncall.Theinter-procedural
graphI/u1D43Ais a combination of CFGs, PDGs and call graphs (i.e.,
CGs), which exposes a variety of program semantics for vulner-
ability detection. Speci/f_ically, PDGs reveal the data and control
dependency of the program, which can be utilized for detecting
somespeci/f_ictypesofvulnerabilities.Forexample,withdetailed
datadependenciesonthetargetpointerandsomecontroldepen-
dencies, we can intuitively infer whether the program lacks the
operation of releasing memory or not. CFGs further supplement
someother typesof vulnerabilitiessuch asâ€œUse AfterFreeâ€, since
CFGs revealthe explicitexecution orderof statements,we cande-
tect whether the memory is used after free on CFGs. CGs can be
usedtoenrichinter-proceduralgraphstoallowforinter-procedural
analysis.Therefore,weextracttheinter-proceduralgraph(IG)to
ensure that complete vulnerabilitysemantics are captured.
CFG
DDG
CDG
CG
8751
15
1720
223Figure 3:IG ofFig. 1(a).
0
26
341
5Source
Sinkedges
vulnerability semanticsstatements
program semanticsFigure4:vulnerabilitysemantics.
Generation process. To build inter-procedural graphs, we /f_irst
employ the popular static tool Joern [ 1] to extract CFGs, PDGs
and CGs from the source code, where PDG consists of data de-
pendencies (DDG) and control dependencies (CDG). Speci/f_ically,
through the call graphs generated by Joern, we identify the call
edge between caller function and callee function, soas to connect
CFGs and PDGs of diï¬€erent functions and get the inter-procedural
graph for the sample. In this way, The inter-procedural graph con-
tains the complete programsemantics and is able tosupport inter-
procedural analysis. We illustrate an inter-procedural graph for
the example of Figure 1(a)in Figure 3. Speci/f_ically, CFG, DDG
and CDG in the functions "SMB_write", "cifs_small_buf_release"
and "mempool_free" are extracted /f_irst. Then according to the call
graph, thefunction â€œcifs_small_buf_releaseâ€ iscalled in statement
5ofthefunctionâ€œSMB_writeâ€.Therefore,weestablishacalledge
between statement 5 of the function â€œSMB_writeâ€ and the func-
tion â€œcifs_small_buf_releaseâ€. Similarly, a call edge is established
betweenthefunction"cifs_small_buf_release"andthestatement
of line 15 in the function "mempool_free". Finally, we obtain the
inter-proceduralgraph inFigure 3.
3.3 Slicing Algorithms
Byconstructingtheinter-proceduralgraphforeachsample,wecap-
turethecompleteprogramsemantics.However,programsemantics
are not equal to vulnerability semantics. As shown in Figure 4, vul-
nerabilitysemanticsareonlyapartofprogramsemantics.There-
fore, we need to further extract precise vulnerability semantics
for code representationgeneration.Inspired byprevious work on
slicingalgorithmsnamedChopping[ 28],whichidenti/f_iesthestate-
mentsthatcausethede/f_initionsofthesourcetoaï¬€ect theusesof
the sink, we propose vulnerability-speci/f_ic inter-procedural slicing
algorithmsforvariousvulnerabilitytypes,whicharewell-designed
by identifying sources and sinks based on the characteristics of
eachvulnerabilitytype.
KeyIdea. Thekeyideaofvulnerability-speci/f_icinter-procedural
slicing algorithms is to locate the vulnerability-relevant part of
thewholeinter-proceduralgraphandsliceitouttorepresentthe
vulnerability semantics. In detail, SnapVuln locates the source (i.e.,
where it comes from) and sink (i.e., where it ends) [ 64] of potential
vulnerabilityinthecode,andtakesthepathsfromsourcetosinkto
constructasubgraphasarepresentationofvulnerabilitysemantics.
Since diï¬€erent vulnerability types have diï¬€erent causes, leading to
diï¬€erent sourcesand sinks, we propose speci/f_ic slicing algorithms
accordingtothecharacteristicsofdiï¬€erentvulnerabilitytypesto
captureprecisevulnerabilitysemantics.Inthispaper,weimplement
slicing algorithms for six common vulnerability types in C/C++.
Weillustratethecorrespondingalgorithmsforeachvulnerability
type indetails.
1374Learning Program Semantics forVulnerabilityDetectionviaVulnerability-SpecificInter-proceduralSlicing ESEC/FSE â€™23, December3â€“9, 2023,San Francisco, CA, USA
1#define BUFSIZE 256
2intmain(intargc,char**argv) {
3char*buf;
4buf = (char*)malloc(sizeof( char)*BUFSIZE);
5strcpy(buf, argv[ 1]);
6}
(a) Buï¬€er Over/f_low1char*getBlock (intfd) {
2char* buf = ( char*) malloc(BLOCK_SIZE);
3if (read(fd, buf, BLK_SIZE)!= BLK_SIZE) {
4returnNULL; }
5return buf;
6}
(b) MemoryLeak1voidmain(){
2structhostent *hp;
3...
4hp = gethostbyaddr(addr, 10);
5strcpy(hostname, hp->h_name);
6}
(c) Null Pointer Dereference
1intmain(){
2intc;
3inta =102410241024 ;
4intb =1024*1024;
5c = a*b;
6}
(d) Integer Over/f_low1char* ptr = ( char*)malloc (SIZE);
2if (err) {
3abrt =1;
4free(ptr);}
5if (abrt) {
6logError( "operation aborted" , ptr);}
(e) Use AfterFree1char* ptr = ( char*)malloc (SIZE);
2if (abrt) {
3free(ptr);
4}
5...
6free(ptr);
(f) Double Free
Figure 5:Simple Examples ofSix Vulnerability Types.
Type 1:Buï¬€er Over/f_low(BO). A buï¬€erover/f_lowoccurswhen
the program copies an input buï¬€er to an output buï¬€er without
verifying that the size of the input buï¬€er is less than the size of the
outputbuï¬€er.An example isshowninFigure 5(a).
Source:Ingeneral,therearetwotypesofbuï¬€erover/f_low,i.e.,stack-
basedandheap-based,whereover/f_lowoccursonarrays(stack)and
pointers(heap)respectively.Therefore,wetaketheallocationof
arrays and pointers as potential sources. For example, line 4 in
Figure5(a)isthe source.
Sink:The sink of buï¬€er over/f_low is a statement that invokes func-
tion calls or assignments to manipulate pointers or arrays. The
function callincludes â€œstrcpyâ€,â€œmemcpyâ€andso on,whilethe as-
signment is various, where any statement that assigns value to
memory that pointer points to or array with index are all included.
For example,line5inFigure 5(a)isthe sink.
Algorithm: SnapVuln takes sinks in the target program as the
slicingcriterionandperformsbackwardslicingoninter-procedural
PDG to obtain the statements that aï¬€ect the sinks until all the
sourcesintheinter-proceduralPDGarereached.Notethatwedo
notperformforwardslicingbytakingsourcesasaslicingcriterion,
because it will include those statements that are aï¬€ected by the
sourcebutnotrelatedtothevulnerability.Wepresentthedetails
inAlgorithm 1.
Algorithm 1: Slicingfor â€œbuï¬€erover/f_lowâ€
Input :Inter-proceduralPDG /u1D456/u1D45D/u1D451/u1D454
Output:Vulnerabilityfeatures /u1D463/u1D450
1Retrieve all expression statements thatwriteto arraysor pointers assinks /u1D458/u1D460
2Initialize/u1D463/u1D450=âˆ…
3for/u1D458âˆˆ/u1D458/u1D460do
4/u1D460=backwardSlicing (/u1D458,/u1D456/u1D45D/u1D451/u1D454)
5/u1D454=constructGraph (/u1D460,/u1D456/u1D45D/u1D451/u1D454)
6/u1D463/u1D450=/u1D463/u1D450/uniontext.1/u1D454
7return/u1D463/u1D450
Type 2: Memory Leak (ML). A memory leak occurs when the
program does not suï¬ƒciently track and release memory after it
has beenused. Itconsumes theremaining memory. An example is
showninFigure 5(b).
Source:The source of memory leak vulnerability is an assignment
statementthatallocatesmemoryspacetoapointer.Forexample,in
thesourcecodeofLinuxkernel,theprogrammaycallstandardfunc-
tion (i.e., â€œmallocâ€, â€œcallocâ€) directly, or call wrapper functions (i.e.,
â€œcifs_buf_getâ€,â€œAcquireQuantumInfoâ€).Thesewrapperfunctions
can be found by analyzing the call graph of the program. For ex-
ample, â€œcifs_buf_getâ€ calls â€œmempool_allocâ€, and â€œmempool_allocâ€
calls â€œpool->allocâ€, therefore, â€œcifs_buf_getâ€ can be taken as source.Sink:Accordingtothecharacteristicsofthememoryleak,itwill
betriggeredifthememoryhasnotbeenreleaseduntiltheendof
theprogram.Therefore,wetaketheendoftheprogramasasinkif
there are nostatements that free the memory.
Algorithm: SnapVuln takesthesourcesasaslicingcriterionand
performs forward slicing on inter-procedural PDG to obtain the
statementsthatareaï¬€ectedbythesourcesuntiltheendoftheinter-
procedural PDG or free functions are found. The slicing process is
showninAlgorithm 2.
Algorithm 2: Slicingfor â€œmemoryleakâ€
Input :Inter-proceduralgraph /u1D456/u1D45D/u1D451/u1D454
Output:Vulnerabilityfeatures /u1D463/u1D450
1Retrieve all statements thatassignto pointers andinvokefunctioncallsassources /u1D452/u1D460
2Initialize/u1D463/u1D450=âˆ…
3for/u1D452âˆˆesdo
4/u1D460=forwardSlicing (/u1D452,/u1D456/u1D45D/u1D451/u1D454)
5/u1D454=constructGraph (/u1D460,/u1D456/u1D45D/u1D451/u1D454)
6/u1D463/u1D450=/u1D463/u1D450/uniontext.1/u1D454
7return/u1D463/u1D450
Type 3: Null Pointer Dereference (NP). A null pointer deref-
erence occurs when the program accesses a pointer that expects
to be valid but is NULL instead. Figure 5(c)shows an example of a
null pointer dereference.
Source:Similartomemoryleak,thesourceofnullpointerderef-
erenceisalsoanassignmentstatementthatinvokesAPIfunction
callssuchasâ€œmallocâ€andâ€œcallocâ€toallocatememoryspacefora
pointer.
Sink:According tothe characteristics ofnull pointerdereference,
we conclude that it will be triggered when the null pointer is used
forthe/f_irsttime.Therefore,wetakethe/f_irststatementusingthe
pointer as the potential sink. For example, Line 7 in Figure 1(b)is a
sink,instead ofline9to line11.
Algorithm 3: Slicingfor â€œnull pointerâ€
Input :Inter-proceduralgraph /u1D456/u1D454
Output:Vulnerabilityfeatures /u1D463/u1D450
1Let/u1D456/u1D45D/u1D451/u1D454be theinter-proceduralPDG in /u1D456/u1D454
2Let/u1D456/u1D450/u1D453/u1D454be theinter-proceduralCFGin /u1D456/u1D454
3Retrieve statements that assign the return value of function calls to pointers as sources /u1D452/u1D460
4Initialize/u1D463/u1D450=âˆ…
5for/u1D452âˆˆ/u1D452/u1D460do
6/u1D460/u1D451=forwardSlicing (/u1D452,/u1D456/u1D45D/u1D451/u1D454)
7/u1D460/u1D450=forwardSlicing (/u1D452,/u1D456/u1D450/u1D453/u1D454)
8/u1D453/u1D460=computeFirstStatement (/u1D452,/u1D460/u1D451,/u1D460/u1D450)
9Choose path from /u1D452to/u1D453/u1D460asslice/u1D460
10/u1D454=constructGraph (/u1D460,/u1D456/u1D45D/u1D451/u1D454)
11/u1D463/u1D450=/u1D463/u1D450/uniontext.1/u1D454
12returnvc
Algorithm: For null pointer dereference, SnapVuln takes state-
mentsthatassignthereturnvalueoffunctioncallstopointersas
1375ESEC/FSE â€™23, December3â€“9, 2023,San Francisco, CA, USA Bozhi Wu, Shangqing Liu, Yang Xiao, ZhimingLi, Jun Sun,andShang-WeiLin
sources (i.e., slicing criterion). To locate the corresponding sinks
(i.e.,the/f_irststatementusingthepointersinsources), SnapVuln /f_irst
performsforwardslicingstartingfromslicingcriterionontheinter-
proceduralgraphandobtainsallstatementsthataredata-dependent
onthepointersaccordingtoPDG,aswellastheexecutionorder
accordingtoCFG.Withdatadependenciesbetweenstatementsand
correspondingexecutionorder,wecandeducethe/f_irststatement
usingthepointersinsources.Aftercollectingthesourcesandsinks,
SnapVuln selects the path from sources to sinks as vulnerability
semantics. The processispresentedinAlgorithm 3.
Type 4: Integer Over/f_low (IO). An integer over/f_low occurs
whenanintegervalueisincrementedaftercalculationtoavalue
thatistoolargetostoreintheassociatedrepresentation,asdepicted
inthe example ofFigure 5(d).
Source:Thesourceofintegerover/f_lowisthestatementthatassigns
valuetoavariable,whosetypemaybeint,long,short,andsoon.
The type indicates the range ofvariables.
Sink:Based onthe characteristics ofinteger over/f_low,those state-
ments that perform arithmetic operations (e.g, +, *, ++) on the vari-
ablemaytriggerintegerover/f_lowvulnerability.Therefore, SnapVuln
takes such statements as sinks.
Algorithm 4: Slicingfor â€œintegerover/f_lowâ€
Input :Inter-proceduralgraph /u1D456/u1D45D/u1D451/u1D454
Output:Vulnerabilityfeatures /u1D463/u1D450
1Retrieve all statements thatcontain arithmetic operators assinks /u1D458/u1D460
2Initialize/u1D463/u1D450=âˆ…
3for/u1D458âˆˆ/u1D458/u1D460do
4/u1D460=backwardSlicing (/u1D458,/u1D456/u1D45D/u1D451/u1D454)
5/u1D454=constructGraph (/u1D460,/u1D456/u1D45D/u1D451/u1D454)
6/u1D463/u1D450=/u1D463/u1D450/uniontext.1/u1D454
7return/u1D463/u1D450
Algorithm: SnapVuln performsbackwardslicingoninter-procedural
PDGbytakingsinksasaslicingcriterionuntilthesourceisreached.
Similar to the buï¬€er over/f_low, SnapVuln does not perform forward
slicing by taking the sources as a slicing criterion, since it will also
includestatementsthatdependonthesourcesbutarenotrelated
to the vulnerability.The detailedprocessislistedinAlgorithm 4.
Type5:UseAfterFree(UAF). Heapmemoryisexplicitlyal-
locatedtopointersthroughAPIfunctioncalls(suchasâ€œmallocâ€).
Oncetheheapmemoryisusedagainafterrelease,aâ€œuseafterfreeâ€
vulnerability occurs. Figure 5(e)displays an example of use after
free vulnerability.
Algorithm 5: Slicingfor â€œuse afterfreeâ€
Input :Inter-proceduralgraph /u1D456/u1D454
Output:Vulnerabilityfeatures /u1D463/u1D450
1Let/u1D456/u1D45D/u1D451/u1D454be theinter-proceduralPDG in /u1D456/u1D454
2Let/u1D456/u1D450/u1D453/u1D454be theinter-proceduralCFGin /u1D456/u1D454
3Retrieve all statements thatassignto pointers andinvokefunctioncallsassources /u1D452/u1D460
4Initialize/u1D463/u1D450=âˆ…
5for/u1D452âˆˆ/u1D452/u1D460do
6/u1D460/u1D451=forwardSlicing (/u1D452,/u1D456/u1D45D/u1D451/u1D454)
7/u1D460/u1D450=forwardSlicing (/u1D452,/u1D456/u1D450/u1D453/u1D454)
8/u1D460/u1D459=computeLastStatement (/u1D452,/u1D460/u1D451,/u1D460/u1D450)
9Forward sliceon /u1D456/u1D454from/u1D452to/u1D459/u1D460,andobtainslice /u1D460
10/u1D454=constructGraph (/u1D460,/u1D456/u1D454)
11/u1D463/u1D450=/u1D463/u1D450/uniontext.1/u1D454
12return/u1D463/u1D450
Source:Similartomemoryleakvulnerability,thesourceofuseafter
free vulnerability is also an assignment statement that allocates
heap memory space to a pointer, including standard functions and
wrapper functions.Sink:Basedonthecharacteristics,auseafterfreevulnerabilitywill
be triggered when a program uses memory again after it has been
freed. Therefore, the sink should be the /f_irst statement that utilizes
thepointerafterthefreeoperation.However,determiningwhich
statements perform the free operation can be challenging, since
theymaybewrappedwithinuser-de/f_inedfunctions.Toaddressthis,
we propose capturing the sink by considering the last statement
that uses the pointer as the end of the slicing, which can ensure
that the sink andthe free operation are includedinthe slice.
Algorithm: Foruseafterfree,thekeyistolocatethelaststatement
that usesthe pointersin sources,whichensures theslice contains
thesink.Toachievethis, SnapVuln /f_irstperformsforwardslicing
starting from the source on the inter-procedural graph and obtains
allstatementsthataredata-dependentonthepointersaccordingto
PDG,aswellastheexecutionorderaccordingtoCFG.Withdata
dependencies between statements and corresponding execution
order,wecandeducethelaststatementthatusesthepointers.After
collectingthesourceandsink, SnapVuln performsforwardslicing
fromsourcetosinkontheinter-proceduralgraphandgetstheslice
as vulnerability semantics. The details of the slicing algorithm are
showninAlgorithm 5.
Type 6: Double Free (DF). If the same heap pointer is released
twiceormoreinaprogram,adoublefreevulnerabilityoccurs,as
showninthe example ofFigure 5(f).
Source:Similar to use after free vulnerability, the source of double
free vulnerability is an assignment statementthat allocates heap
memory spaceto apointer.
Sink:Thesinks ofdoublefree aretwo ormore freeoperations on
pointersinsources.Similartouseafterfree,identifyingstatements
usedforfreeoperationscanbechallenging.Therefore,wealsotake
the last statementthat uses the pointers as the end of slicing.
Algorithm: Unlike use after free, double free is not related to
execution order. The vulnerability semantics of a double free issue
areassociatedwithhowmanytimesapointerisfreed.Therefore,we
perform forward slicing on inter-procedural PDG from the sources
tothelaststatementthatusesthepointersofthesources.Inthis
way, we can track all statements that manipulate the pointers to
capturethevulnerabilitysemantics.Theprocessissimilartouse
after free in Algotirhm 5. The only distinction is that in steps 9
and10,thealgorithmreplaces /u1D456/u1D454with/u1D456/u1D45D/u1D451/u1D454fordoublefreeanalysis.
Consequently,we do not present the detailedalgorithm.
3.4 Model Design
SnapVuln /f_irstemployssixsubmodelsandaGNNmodeltolearnvul-
nerabilitysemanticsfromsixsetsofsubgraphsandinter-procedural
graph respectively, and then ensemble the outputs of these mod-
els to make a /f_inal prediction. In particular, the novel submodel
customizesaGGNNwithanattentionmechanism,whichmakes
it eï¬€ectively capture the structural information within each sub-
graph and learn distinct weights for the subgraphs within each
set to generate representations. The six submodels are designed
to independently capture the vulnerability semantics associated
with a speci/f_ic vulnerability type. For the GNN model, it can be
seen as a submodel without attention mechanism, aiming to learn
comprehensiveprogramsemanticsfrominter-proceduralgraphfor
vulnerability detection. This enables SnapVuln to detect vulnerabil-
itiesthat are not coveredbythe slicing algorithms.
1376Learning Program Semantics forVulnerabilityDetectionviaVulnerability-SpecificInter-proceduralSlicing ESEC/FSE â€™23, December3â€“9, 2023,San Francisco, CA, USA
Subgraph 1
Subgraph 2â€¦
Subgraph K75153
Subgraph35ï¼Œ
57ï¼Œ
515ï¼Œ
edges
35
715
nodesğ’‰30
ğ’‰50
ğ’‰70
ğ’‰150
Node Initializationğ’‰30
ğ’‰50
ğ’‰70
ğ’‰150SUM & GRU
hop 1ğ’‰31
ğ’‰51
ğ’‰71
ğ’‰151SUM & GRU
hop 2ğ’‰3ğ‘¡âˆ’1
ğ’‰5ğ‘¡âˆ’1
ğ’‰7ğ‘¡âˆ’1
ğ’‰15ğ‘¡âˆ’1SUM & GRU
hop tâ€¦ğ’‰3ğ‘¡
ğ’‰5ğ‘¡
ğ’‰7ğ‘¡
ğ’‰15ğ‘¡Max Pooling
ğ’‰ğ‘”
Graph EmbeddingAttention
â€¦ğ’‰ğ‘”1
ğ’‰ğ‘”2
ğ’‰ğ‘”ğ‘˜[cls] aâ€¦ğ’‰ğ‘”1
ğ’‰ğ‘”2
ğ’‰ğ‘”ğ‘˜ğ‘1
ğ‘2
ğ‘ğ‘˜ğ’‰ğºFC Layer
Sigmoid
GGNNpsub
Figure 6:Anexample ofFigure 3to illustratethepipelineofthe submodel.
3.4.1 Submodel. Each submodel learns vulnerability semantics
from a set of subgraphs G={/u1D4541,...,/u1D454/u1D458}per sample. The submodel
/f_irst transforms nodes and edges in each subgraph /u1D454/u1D456into vector
representations, and then utilizes a GGNN to learn graph represen-
tation/u1D489/u1D454/u1D456for each subgraph. After that, the submodel leverages
the attention mechanism over the graph representations of a set
ofsubgraphs Gsothatitcanlearntoassigndiï¬€erentweightsfor
eachsubgraphandobtainthevector /u1D489Gbytheweightedsumma-
tionofeachgraphrepresentation /u1D489/u1D454/u1D456.Finally,wetake /u1D489Gwitha
fullyconnectedlayertogeneratetheoutputofthesubmodel.We
describe each componentin the submodelin details below, and use
anexampleinFigure 3toillustratethepipelineofthesubmodel,as
showninFigure 6.
Node Initialization. For each subgraph /u1D454/u1D456âˆˆ G, it can be rep-
resented as /u1D454/u1D456=(V,E)where the node /u1D463âˆˆ Vin/u1D454/u1D456consists of a
code statement and the edge /u1D452âˆˆ Erepresents diï¬€erent relations
betweennodesincludingdata/controldependencies,control/f_low
and function calls. Since the node /u1D463consists of a code statement
(i.e.,asequenceofmultipletokens),toobtainthenodeinitialvector
representation, we sum up each token vector initialized by a learn-
able embedding matrix /u1D46CâˆˆR/u1D45AÃ—/u1D451in the code statement, where /u1D45A
is the length of the vocabulary set and /u1D451is the dimensional length.
Thenodeinitialvectorrepresentationcanbeexpressedas /u1D4890/u1D463âˆˆR/u1D451.
GraphEmbedding. Foreachsubgraph /u1D454/u1D456âˆˆ G,weutilizeGGNN
astheencodertolearnthegraphrepresentation /u1D489/u1D454/u1D456.Speci/f_ically,for
node/u1D463in/u1D454/u1D456,weutilizea/f_ixednumberofhops(i.e., /u1D447)topropagate
theinformationalongtheedges.Ateachcomputationhop /u1D461,where
1â‰¤/u1D461â‰¤/u1D447, we utilize the summation function to aggregate the
neighboring node features computed from the previous hop and
this processcan be expressedas follows:
/u1D489/u1D461
/u1D441(/u1D463)=SUM({/u1D489/u1D461âˆ’1
/u1D462|âˆ€/u1D462âˆˆ/u1D441(/u1D463)}) (1)
where/u1D441(/u1D463)is a set of neighborhood nodes that are connected to /u1D463.
Then a gated recurrentunit[ 19]isused to updatethefeature of /u1D463,
whichcan be formulatedas follows:
/u1D489/u1D461
/u1D463=GRU(/u1D489/u1D461âˆ’1
/u1D463,/u1D489/u1D461
/u1D441(/u1D463)) (2)
Aftera/f_ixednumberofhops(i.e., /u1D447),weobtainthe/f_inalnode
representation /u1D489/u1D447/u1D463forthenode /u1D463.Wefurtherapplythemax-pooling
overallnodes(i.e., {/u1D489/u1D447/u1D463|âˆ€/u1D463âˆˆ V})ofsubgraph /u1D454/u1D456toobtainthegraph
representation /u1D489/u1D454/u1D456as follows:
/u1D489/u1D454/u1D456=maxpool(FC({/u1D489/u1D447
/u1D463|âˆ€/u1D463âˆˆ V})) (3)
whereFC(Â·)isafullyconnectedlayer.Foreachsubgraph /u1D454/u1D456âˆˆ G,
weobtainitscorrespondinggraphrepresentationdenotedas /u1D46E=
{/u1D489/u1D4541,...,/u1D489/u1D454/u1D458}where/u1D46EâˆˆR/u1D458Ã—/u1D451.Attention. Wefurtheraddanattentionmoduletoensurethat
the model learns to assign diï¬€erent weights of subgraphs Gfor
the prediction. Speci/f_ically, we add an extra token â€œ[CLS]â€ with
its initial vector /u1D489clsand concatenate it with /u1D46Eto obtain a new
representation /u1D46Eâ€²={/u1D489cls,/u1D489/u1D4541,...,/u1D489/u1D454/u1D458}where/u1D46Eâ€²âˆˆR(/u1D458+1)Ã—/u1D451. In-
spiredbyselfattention[ 54],weusescaleddot-productattentionto
obtaindiï¬€erentweightsforsubgraphs Ganditcanbeexpressed
as follows:
/u1D468=so/f_tmax(/u1D478/u1D472/u1D447
âˆš
/u1D451) /u1D489G=/u1D458/summationdisplay.1
/u1D457=1/u1D44E/u1D457/u1D489/u1D457(4)
where/u1D46Eâ€²=/u1D478=/u1D472,/u1D482âˆˆR/u1D458+1is the vector of the index token
â€œ[CLS]â€ in the matrix /u1D468âˆˆR(/u1D458+1)Ã—(/u1D458+1),/u1D44E/u1D457is the value of the /u1D457-th
indexfor thesubgraph /u1D454/u1D457inthevector /u1D482,/u1D489/u1D457âˆˆR/u1D451isthevectorof
the index /u1D457in/u1D46Eâ€²âˆˆR(/u1D458+1)Ã—/u1D451and/u1D451is the dimensional length. The
vector/u1D482isconsideredastheweightedvectorlearntbythemodel
for diï¬€erentsubgraphs.
Prediction. Wetaketheweightedrepresentation /u1D489Gfollowed
byafully connectedlayer for the prediction:
psub=Sigmoid(FC(/u1D489G)) (5)
wherepsubdenotes the probability computed by the activation
functionSigmoid.
3.4.2 GNN Model. The GNN model can be considered as a sub-
modelwithoutanattentionmechanism,sharingthesameGGNN
moduleasthesubmodelinFigure 6.ByutilizingtheGGNNmodule,
theGNNmodelconvertstheinter-proceduralgraphintoagraph
representationdenotedas /u1D489I/u1D43A.Subsequently,wemapthegraph
representation /u1D489I/u1D43Ato the predicted probabilities in the prediction
module,describedas follows:
pIG=Sigmoid(FC(/u1D489IG)) (6)
3.4.3 Ensemble Model. Through the above feature learning pro-
cess, we obtain predicated probabilities from the six submodels
andGNNmodel.The/f_inalstepistoensemblethelearnedresults
fromthesemodelsforthe/f_inalprediction.Therearemultipleways
toachievethisgoal.Inthiswork,werefertoasimilarpaper[ 69]
whichensemblestwomodelstoidentifysecurity-relatedpatches,
anduseaweightedcombinationofthesemodelsoutputasensemble
model,whichcan be describedas follows:
prob=/u1D6FCÂ· (psub1+psub2+...+psubi+pIG) (7)
1377ESEC/FSE â€™23, December3â€“9, 2023,San Francisco, CA, USA Bozhi Wu, Shangqing Liu, Yang Xiao, ZhimingLi, Jun Sun,andShang-WeiLin
where/u1D456=6and/u1D6FC=1/(/u1D456+1).Theclassi/f_icationresultis0for prob
less than0.5 and1for the others,as below:
prediction =/braceleftbigg1,ifprobâ‰¥0.5
0,ifprob<0.5(8)
4 EVALUATION
Todemonstratetheeï¬€ectivenessof SnapVuln,weconductextensive
experiments to investigate the following fourresearchquestions.
â€¢RQ1: Can SnapVuln outperform state-of-the-artbaselines?
â€¢RQ2: Can the completeness of the extracted vulnerability seman-
tics aï¬€ectthe performance invulnerabilitydetection?
â€¢RQ3: Can the precision of the extracted vulnerability semantics
aï¬€ectthe performance ofvulnerabilitydetection?
â€¢RQ4: What is the memory usage and execution time of SnapVuln
indetecting vulnerabilitiescomparedto the baselines?
4.1 EvaluationSetup
4.1.1 Dataset. Tostudytheaboveresearchquestions,weshould
choose a dataset containing multi-function samples for evaluation,
since the impact of vulnerability semantic completeness can be
revealed by comparing the vulnerability detection performance
onsamplesofthesingle-functionversionandthecorresponding
multi-function version. We search the papers from 2018 to 2022 for
vulnerability datasets in C/C++, and /f_ind several public datasets
includingDevign[ 68],Draper[ 51],Fan[20],D2A[66]andJuliet[ 2].
Intheend,wechooseareal-worldvulnerabilitydatasetD2Aand
awidelyusedsyntheticdatasetJulietasevaluationdatasetssince
they are datasets containingmulti-function samples.
Preprocessing: Weconductthefollowingstepstopreprocessthe
datasets for the evaluation:
1)Wecollectthesamplesofsixcommonvulnerabilitytypesin
C/C++fromD2AandJuliet,and/f_ilteroutthosesamplesthatcannot
beparsedintocodepropertygraphsbyJoern.Finally,wegetthe
/f_inaldatasetforevaluation,asshowninTable 2.Sincesamplesin
Juliet contains tokens with obvious vulnerability meanings such as
â€œsinkâ€,â€œsourceâ€,â€œgoodâ€andâ€œbadâ€,Wenormalizethemtoâ€œnormâ€,
andmapalluser-de/f_inedfunctionnamestosymbolicnames(e.g.,
func0).
2)Tosupportthestudy,weneedtoobtaintheevaluationdatasets
ofthesingle-functionversionandthecorrespondingmulti-function
version.Sincethesamplesintheoriginaldatasetsaremulti-function,
we only need to obtain the corresponding single-function version.
Speci/f_ically,givenamulti-functionvulnerability,weselectthefunc-
tion that triggers the vulnerability as the corresponding single-
functionversion.FortheexampleinFigure 1(a),â€œUseAfterFreeâ€is
triggered at line 8 of function â€œSMB2_writeâ€. Therefore, we choose
the function "SMB2_write"as the single-functionversion.
3)Formodeltrainingandtesting,wesplitthedataofeachvul-
nerability type with the ratio of 80%:10%:10%, and then fuse the
divideddataofeachvulnerabilitytypeasthetrain/validation/test
setfor evaluation.
4.1.2 Baseline. Toevaluate SnapVuln ,weselect/f_ivestate-of-the-
artlearning-basedvulnerabilitydetectionapproachesandtwopop-
ular pre-trained approachesasbaselines. Speci/f_ically, the existing
/f_ive vulnerability detection approaches can be divided into twoTable 2:The statisticsofthe used datasets.
DatasetJuliet D2A
#SamplesLoC #Tokens#SamplesLoC #Tokens
min max avg min max avg min max avg min max avg
BO 10074 8 63 21 53 349 128 2437 8 2156 328 62 9235 2140
IO 3744 8 34 17 34 172 71 10624 4 2303 270 28 8206 1755
NP 316 6 34 13 22 131 55 413 8 1027 125 73 4296 849
ML 1548 9 30 17 33 196 91 - - - - - - -
DF 880 8 25 15 25 154 66 - - - - - - -
UF 458 9 40 19 35 213 89 - - - - - - -
Non-Vuln 17002 6 63 13 23 339 111 13321 5 2807 258 39 9609 2107
Total 34022 6 63 16 22 349 110 26795 4 2807 267 28 9609 1951
categories:(1)function-leveldetection(i.e.,detectingvulnerabili-
tiesatfunctiongranularity),suchasDevign[ 68]andREVEAL[ 15].
(2)multi-function-leveldetection(i.e.,detectingvulnerabilitiesat
thegranularityofmultiplefunctions),suchasVulDeePecker[ 40],
SySeVR [ 39], and DeepWukong [ 17]. Since the pre-trained mod-
elsachievepromisingresultsinmanycode-relatedtasks[ 48,67],
we also compare SnapVuln with two popular pre-trained models
(i.e.,CodeBERT[ 21]andGraphcodebert[ 25]).Weusetheirimple-
mentation if available (i.e., REVEAL, SySeVR and DeepWukong,
CodeBERT, and Graphcodebert) and re-implement the approaches
otherwiseaccording to their papers (i.e.,Devign,VulDeePecker).
4.1.3 Metrics. Following previous works [ 17,39,68], we select
thewidelyusedmetricsofaccuracyandF1-scoretoevaluatethe
vulnerability detection performance of diï¬€erent approaches. Accu-
racy is the ratio of the number of correct predictions to the total
number of input samples, which indicates the correctness of iden-
tifying both vulnerable and non-vulnerable samples. F1-score is
the harmonic mean between precision and recall and indicates the
balance between them, where precision implies the correctness of
predictedvulnerablesamplesandrecallimpliestheeï¬€ectivenessof
vulnerabilityprediction.
4.1.4 ModelSe/t_ting. Wesettheembeddingsizeoftokensto128
andthebatchsizeto16fortraining.Thehopissetto4.Thenumber
of subgraphs /u1D458is set to 16 and 4 on D2A and Juliet respectively.
Notethatwewillintroducewhyandhowwechoosethenumber
ofsubgraphsinSection 4.2.4.WeadopttheAdamoptimizerwith
a learningrate of 0.001to train themodel onNVIDIA RTX A6000
with10-epoch patience for early stopping. The modelsettings are
validatedto achieve the optimal performance viagrid search.
4.1.5 EvaluationProcedure. ForRQ1,wecompare SnapVuln with
baselines on D2A and Juliet, respectively. For RQ2, to verify the
completeness of vulnerability semantics on the detection perfor-
mance, we conduct comparative experiments on the datasets of
themulti-functionversionandthecorrespondingsingle-function
version. Fora fair comparison,we disable the slicingcomponent
and just utilize interprocedural-graph to conduct experiments (i.e.,
SnapVuln _single/SnapVuln _multi). For RQ3, to evaluate the pre-
cision of extracted vulnerability semantics on the detection per-
formance,we/f_irstperformanablationstudyon SnapVuln bydis-
ablingtheslicingcomponenttoverifytheeï¬€ectivenessofslicing
algorithms (i.e., SnapVuln _multi). Then we compare our proposed
slicing algorithms with three typical slicing algorithms respec-
tively proposed by VulDeePecker, SySeVR and DeepWukong for
further veri/f_ication (i.e., SnapVuln _vuldeepecker, SnapVuln _sysevr
andSnapVuln _deepwukong). Speci/f_ically, DeepWukong extracted
subgraphs from PDGs by taking API function calls or arithmetic
operationsas aslicing criterion,while VulDeePecker and SySeVR
1378Learning Program Semantics forVulnerabilityDetectionviaVulnerability-SpecificInter-proceduralSlicing ESEC/FSE â€™23, December3â€“9, 2023,San Francisco, CA, USA
Table 3:The evaluationresults on twoopen-source datasets.
ApproachD2A Juliet
IO BO NP Overall IO BO NP ML DF UF Overall
Acc F1 P R Acc F1 P R Acc F1 P R Acc F1 P R Acc F1 P R Acc F1 P R Acc F1 P R Acc F1 P R Acc F1 P R Acc F1 P R A cc F1 P R
Devign 67.2 67.6 66.8 68.4 66.1 65.9 66.2 65.6 61.8 56.7 65.5 50.0 67.0 67.1 66.8 67.4 61.7 53.5 68.0 44.1 65.8 65.7 65.8 65.6 58.9 53.1 61.9 46.4 64.2 64.9 63.6 66.2 62.5 62.3 62.6 62.0 75.0 73.2 78.9 68.2 64.6 58.7 70.6 50.2
REVEAL 67.5 68.3 66.8 69.7 63.6 64.5 62.9 66.2 62.5 57.7 66.1 51.2 67.1 69.1 65.1 73.6 62.6 61.3 63.4 59.3 67.8 67.9 67.7 68.2 62.5 64.1 61.5 66.8 64.8 66.9 63.2 71.0 65.7 68.1 63.6 73.3 68.7 69.9 67.4 72.6 66.8 68.0 65.5 70.6
VulDeePecker 67.4 66.7 68.1 65.3 67.5 66.7 68.3 65.1 61.0 57.8 63.0 53.4 67.3 66.5 68.2 64.8 76.0 78.5 71.1 87.7 66.6 66.8 66.4 67.2 77.8 80.5 71.7 91.7 69.9 71.4 68.0 75.2 53.9 46.1 55.5 39.5 57.9 57.7 57.9 57.4 69.0 71.1 66.6 76.2
SySeVR 68.0 67.1 69.1 65.3 69.2 68.3 70.4 66.4 64.0 62.1 65.6 58.8 68.1 67.2 69.1 65.4 84.8 85.0 84.1 85.9 67.7 61.0 76.8 50.6 83.3 83.3 83.3 83.3 75.9 74.6 79.0 70.7 60.1 49.0 67.8 38.3 66.7 62.9 70.9 56.5 71.2 68.6 75.2 63.1
DeepWukong 69.7 70.9 68.2 73.7 66.6 67.2 66.0 68.4 65.0 64.5 65.4 63.6 68.7 69.6 67.8 71.4 81.3 82.6 77.2 88.8 68.8 66.8 71.4 62.8 83.3 84.2 80.0 88.9 73.9 75.1 71.8 78.8 58.4 51.9 61.6 44.8 61.1 58.3 62.8 54.4 72.1 72.5 71.4 73.7
CodeBERT 74.8 77.1 70.7 84.775.2 77.1 71.5 83.673.2 71.8 74.7 69.1 74.3 76.6 70.2 84.393.3 93.0 96.689.7 82.2 79.2 95.0 67.9 92.2 92.3 90.8 93.9 81.8 78.6 85.1 73.0 75.6 69.5 92.4 55.7 63.0 45.2 79.8 31.5 83.7 81.4 90.6 73.9
Graphcodebert 76.1 77.2 73.8 81.0 75.0 75.7 73.6 77.8 70.7 69.2 72.0 66.7 75.6 76.7 73.4 80.2 94.8 94.9 92.697.379.6 77.1 88.1 68.5 82.8 83.1 81.8 84.3 77.0 74.4 83.7 66.9 86.9 86.9 87.5 86.3 71.7 66.7 81.3 56.5 83.1 81.7 89.0 75.5
SnapVuln 81.0 80.7 79.2 82.378.1 77.7 79.1 76.474.4 73.4 76.9 70.780.6 80.7 80.1 81.6 88.2 87.3 94.0 81.6 92.1 91.8 95.5 88.4 96.4 96.3 99.9 92.995.3 95.4 93.4 95.4 79.8 78.4 86.7 71.7 88.8 88.3 92.3 84.593.4 93.6 91.0 96.4
SnapVuln_single 68.7 69.2 68.2 70.2 66.1 66.5 65.6 67.4 64.5 62.0 66.7 57.9 68.6 69.0 68.2 69.8 65.0 66.1 64.1 68.2 66.4 60.8 73.0 52.1 69.6 70.2 69.0 71.5 64.9 59.1 70.8 50.7 64.1 55.4 73.2 44.6 75.3 74.9 76.1 73.8 65.8 66.0 65.6 66.3
SnapVuln_multi 71.4 70.9 72.3 69.6 72.0 67.6 78.9 58.5 66.1 68.8 63.8 74.671.1 70.2 72.5 68.0 74.2 78.0 68.1 91.2 70.8 73.5 67.2 81.1 76.8 81.2 70.5 95.069.9 72.5 66.8 79.1 66.9 67.7 66.0 69.6 78.4 81.2 71.9 93.272.1 74.9 68.1 83.2
SnapVuln_vuldeepecker 74.2 74.4 73.9 74.9 74.1 74.9 72.7 77.2 65.0 64.1 65.8 62.5 75.0 75.1 74.8 75.4 81.3 83.3 75.3 93.2 73.7 74.1 72.9 75.3 80.0 82.0 74.6 90.9 87.7 89.0 80.5 99.475.0 67.9 95.0 52.8 74.4 76.1 71.4 81.4 76.3 77.2 74.2 80.5
SnapVuln_sysevr 77.4 76.7 79.0 74.6 73.7 72.0 77.0 67.6 73.4 71.2 76.6 65.8 77.1 77.0 77.4 76.6 82.8 82.6 83.5 81.6 81.3 81.7 80.1 83.4 83.9 84.8 80.6 89.3 89.9 90.7 83.6 99.3 81.5 81.7 80.8 82.6 84.1 84.8 81.3 88.6 84.2 84.9 81.2 88.8
SnapVuln_deepwukong 76.2 76.2 76.1 76.3 73.7 73.5 74.2 72.8 67.5 68.3 66.7 70.0 76.7 76.5 77.3 75.7 79.6 72.6 95.8 58.4 81.5 79.6 88.6 72.3 84.0 84.2 83.3 85.1 93.2 93.2 92.3 94.2 80.3 73.2 96.459.0 81.5 79.6 88.6 72.3 85.0 84.8 86.3 83.3
sliced a sequence of code statements on DDGs and PDGs respec-
tively.Since SnapVuln takesgraphsasinput,wetransformthecode
statements extracted by VulDeePecker and SySeVR into graphs by
connectingthestatementsbasedonDDGsandPDGs.Inthisway,
we can compare the performance of slicing algorithms of diï¬€erent
approacheswithauni/f_iedmodel SnapVuln .
4.2 EvaluationResults
4.2.1 ComparisonwithState-of-the-artApproaches(RQ1). The/f_irst
two rows of Table 3present the results of baselines on D2A and
Juliet. We observe that SnapVuln outperforms baselines on the
overalltestset ofD2A andJuliet interms ofaccuracyandF1.
As seen in Table 3,SnapVuln outperforms vulnerability detec-
tionbaselines(/f_irstrow) byat least11%(absolutediï¬€erences)and
surpasses pre-trained models(second row) by atleast 4% interms
ofaccuracyandF1ontheoveralltestset,whichshowstheeï¬€ective-
nessofSnapVuln.Furthermore,formosttypesofvulnerabilities(i.e.,
â€œbuï¬€er over/f_lowâ€, â€œmemory leakâ€ and â€œuse after freeâ€), SnapVuln
also has higher accuracy, except for â€œinteger over/f_low (IO)â€ and
â€œdouble free (DF)â€ on Juliet testset. For these cases, the pre-trained
models achieve higher accuracy.Since the samples from Juliet are
syntheticand simple,which leadsto powerfulpre-trained models
easily capture the inner features among the samples. In contrast,
SnapVuln outperformsthepre-trainedmodelsonD2Adataset,indi-
catingthat SnapVuln ismoreeï¬€ectiveforreal-worldvulnerabilities.
We attribute this to the vulnerability-speci/f_ic inter-procedural slic-
ing algorithms that are designed to capture precise vulnerability
semantics.
Analysis .We conclude that in most cases, SnapVuln achieves
the best performance for vulnerability detection, especially on the
real-world D2A testset. It is attributed to the complete and precise
vulnerability semantics capturedby the slicing algorithms and the
attention mechanismusedinthemodeltodynamicallyassigndif-
ferent weights for subgraphs. The shortcomings of the baselines
aretwofold.Ononehand,thebaselinessuchasDevigncapturethe
vulnerability semantics on the single function, which are incom-
plete for vulnerability detection. On other hand, some approaches
such as VulDeePecker, SySeVR, and DeepWukong propose the gen-
eralslicingalgorithmswithoutconsideringthecharacteristicsof
diï¬€erentvulnerabilitytypesforvulnerabilitydetection,which are
imprecise.Furthermore,althoughthepre-trainedapproachescan
achieve better performance compared with the aforementioned
vulnerabilitydetectionbaselines, theyare limitedby learningpre-
cise vulnerability semantics that SnapVuln does for vulnerability
detection.AnswertoRQ1: Theoverallperformanceof SnapVuln outper-
formsexistingapproachesonthereal-worlddatasetD2Aandthe
syntheticdataset Juliet.
4.2.2 The Completeness of Vulnerability Semantics(RQ2). The re-
sultsofSnapVuln _singleand SnapVuln _multiarepresentedinTa-
ble3, we can observe that the overall detection performance on
multi-function datasets is better than single-function datasets in
terms ofaccuracyandF1 onD2A andJuliet.
Inparticular,theaccuracyformulti-functionversionare2.5%and
6.3% higher than that of single-function version on the overall test-
sets of D2A and Juliet. Furthermore, we /f_ind that the performance
of each vulnerabilitytype is improved when using multi-function
datasets D2A and Juliet. In addition, the magnitude of the improve-
ment on D2A is smaller than Juliet. For example, the vulnerability
typeâ€œintegerover/f_lowâ€onD2Aincreasesby2.7%inaccuracywhile
Juliet increasesby9.2%.
Analysis .Weattributetheimprovementstotheversionofthe
multifunctiondatasetconsistingofthecompletevulnerabilityse-
manticstohelpthemodellearnmorevulnerability-relatedfeatures
comparedwiththesinglefunctionforvulnerabilitydetection.How-
ever,wealsoneedtopointoutthatwhenintroducingmulti-function
fordetection,wealsointroducesubstantialnoise(i.e.,vulnerability-
irrelevant semantic information) for the model, especially in the
real-world dataset D2A. In contrast, the Juliet dataset is a synthetic
datasetthatcontainsfewercodestatementsunrelatedtovulnera-
bilities.Hence,theirrelevantinformationislessthanD2Aonthe
version of multi-function datasets, which provides more notice-
ableimprovements.Italsoindicatesthatthecompletevulnerability
semantics are not suï¬ƒcient for the model to obtain good perfor-
manceandsomeslicingalgorithmsareneededtoextractprecise
vulnerabilitysemantics for the detection.
AnswertoRQ2: Thecompletenessoftheextractedvulnerabil-
ity semanticsaï¬€ects theperformance ofvulnerability detection.
Although some vulnerability-irrelevant semantic information is
introducedatthesametime,itcanstillimprovedetectionperfor-
mance.Italsoindicatesthatpreciseslicingcriteriaaredemanded
to reduce the noiseandfurther improve the performance.
4.2.3 The Precision of Vulnerability Semantics (RQ3). The exper-
imentalresultsofdiï¬€erentslicingalgorithmsthatbaselinesused
arepresentedinthelastrowofTable 3.First,comparingtheresults
ofSnapVuln withSnapVuln _multi, we can /f_ind that the improve-
mentsaresigni/f_icant,whichdemonstratesthatslicingisaneï¬€ec-
tive approach to remove vulnerability-irrelevant information for
1379ESEC/FSE â€™23, December3â€“9, 2023,San Francisco, CA, USA Bozhi Wu, Shangqing Liu, Yang Xiao, ZhimingLi, Jun Sun,andShang-WeiLin
vulnerabilitydetection.Furthermore,bycomparingtheresultsof
diï¬€erentslicingalgorithmswith SnapVuln ,we/f_indthat SnapVuln
achieves better performance in terms of vulnerability detection,
which demonstrates that our slicing algorithm is eï¬€ective in ex-
tractingrelevantvulnerabilitysemantics.
Speci/f_ically,whenusingtheslicingalgorithms,theaccuracyof
SnapVuln on the overall testset of D2A and Juliet increases by 9.5%
and 21.3% respectively. Furthermore, the accuracy of each type
ofvulnerabilityonD2AandJuliethasalsoimproved.Inaddition,
compared with other slicing algorithms, SnapVuln achieves 5.6%,
3.5%,3.9%higheraccuracythanVulDeePecker,SySeVRandDeep-
Wukong on the overall testset of D2A and 17.1%, 9.2%, and 8.4% on
Juliet.
Analysis .The improved performance by SnapVuln can be at-
tributed to the precise vulnerability semantics captured by the
proposed slicing algorithms for the six most dangerous vulnera-
bility types. Through the vulnerability-speci/f_ic inter-procedural
slicingalgorithms, SnapVuln isabletoextractfeaturescontaining
precisevulnerabilitysemanticsasthemodelinputfromsamples,
thus improving the eï¬€ectiveness and accuracy of SnapVuln. On the
contrary, the baselines either perform slicing on DDG to obtain
allstatementsthataredata-dependentonAPIfunctioncalls(e.g.,
VulDeePecker)orsliceonPDGtogetrelatedstatements(e.g.,Sy-
SeVRandDeepWukong)asvulnerabilitysemantics,withoutconsid-
ering the characteristics of diï¬€erent vulnerability types. Therefore,
theyinevitablyintroducestatementsirrelevanttovulnerabilities
as modelinput,resultinginpoorperformance.
Answer to RQ3: The precision of the extracted vulnerability
semanticsisvitaltotheperformanceofvulnerabilitydetection.
Compared with other slicing approaches, we con/f_irm that our
slicing algorithms extractmore precise vulnerabilitysemantics.
4.2.4 Performance Analysis (RQ4). In this RQ, we /f_irst conduct
experiments to determine the optimal value of /u1D458that achieves the
best performance while keeping training feasible. Based on this
selected/u1D458, we further analyze SnapVuln and baselines with respect
to the time spent on constructing and analyzing a sample and
memory requirements for training andtesting.
Choice of k .The value of /u1D458(i.e., the number of sampled subgraphs
per set in each sample) may aï¬€ect the memory requirement and
vulnerability detection performance, since a larger /u1D458requires more
memoryformodeltrainingandtesting,whileasmaller /u1D458valuemay
causethelossofvulnerabilitysemanticsoflargesamples,resulting
indetectionfailure.Weexperimentwithdiï¬€erent /u1D458todetermine
the optimal value. As depicted in Figure 7(a)and Figure 7(b), we
observethat valuesbelow /u1D458=16and/u1D458=4showworse resultsin
D2A and Juliet, respectively. Additionally, increasing the values of
/u1D458does not result in consistent improvement. Hence, setting /u1D458to 16
for D2A and 4 for Juliet can be considered a reasonable sweet spot
betweencapturingsuï¬ƒcientinformationforvulnerabilitydetection
andkeepingtrainingfeasibleintheGPUâ€™smemory.Furthermore,
from the table in Figure 7(a)and Figure 7(b), we can /f_ind that
the average number of subgraphs per set is 54 and 5 in D2A and
Juliet, respectively. Setting /u1D458above 16 in D2A and above 4 in Juliet
may be bene/f_icial forsomelarge samples. However,in most cases,
16 subgraphs in D2A and 4 subgraphs in Juliet contain suï¬ƒcient
(a) D2A
 (b) Juliet
Figure 7:The impact of /u1D458on accuracyand F1.
Table 4:Time andmemory spenton the twodatasets.
DatasetD2A Juliet
Time(s) Memory(GB) Time(s) Memory(GB)
constructing analyzing CPU GPU constructing analyzing CPU GPU
Devign 2.60 0.04 23.4 41.2 0.93 0.01 8.4 3.0
REVEAL 2.60 0.03 23.7 39.6 0.93 0.01 9.1 3.2
VulDeePecker 3.35 0.03 8.5 5.5 1.05 0.01 6.1 1.4
SySeVR 3.82 0.03 7.6 5.6 1.10 0.01 6.2 1.7
DeepWukong 3.90 0.05 24.2 10.6 1.08 0.01 6.4 1.6
CodeBERT - 0.03 5.8 14.2 - 0.01 5.6 14.2
Graphcodebert - 0.03 5.7 14.2 - 0.01 5.6 14.2
SnapVuln 4.68 0.19 29.0 43.3 1.22 0.10 9.7 3.5
informationforvulnerabilitydetection,whichmaybeattributed
to the overlap between thesesubgraphs.For example, somesmall
subgraphsmaybepartofthoselargersubgraphs,sincetheymay
be sliced from branches of those larger subgraphs. This may result
inthesesubgraphs containingduplicatevulnerabilitysemantics.
Time and Memory .All approaches, with the exception of the pre-
trainedmodels(i.e.,CodeBERTandGraphcodebert),arerequired
to construct graphs for vulnerability detection. Considering the
varioustimerequiredforgraphconstructionandanalysisacross
diï¬€erent samples, we calculate the average time across all samples
torepresentthetimespentbyeachapproach.FromtheTable 4,we
can observe that SnapVuln spends more time than the baselines,
especiallythetimespentonconstructingthegraphs.Thatcanbe
attributed to the incorporation of inter-procedural graph construc-
tion and the execution of multiple slicing algorithms. However, in
practice, we reduce the time toless than 0.5secondpersample by
multiprocessing, making the time spent by SnapVuln acceptable.
Furthermore,regarding memory usage,werecordthe maximum
memoryconsumedbyeachapproach.Since SnapVuln employsmul-
tipleindependentlytrainedsubmodels,wetakethelargestmemory
consumed by these submodels as its /f_inal result. As can be seen
fromTable 4,SnapVuln consumesmore memory in CPUand GPU
compared to the baselines during model training (except for the
pre-trainedmodelsonJuliet),especiallyinthereal-worlddataset
D2A.However,comparedtoDevignusingthesameGGNNnetwork,
the GPUmemoryusage of SnapVuln hasonlywitnessedaminor
increase, with an additional 2.1 GB. This can be attributed to the
preciseslicingalgorithms,whichgreatlyreducesthesizeofeach
subgraph. As a result, despite the utilization of multiple subgraphs
per sample for vulnerability detection, the memory requirement
remains relatively stable and does not experience signi/f_icant in-
crease.Hence, SnapVuln provedtobeacceptableintermsoftime
andmemory requirements.
Answer to RQ4: SnapVuln is optimal with /u1D458of 16 on D2A and 4
on Juliet. Although SnapVuln takes more time and memory than
baselines,itprovedto be acceptable.
1380Learning Program Semantics forVulnerabilityDetectionviaVulnerability-SpecificInter-proceduralSlicing ESEC/FSE â€™23, December3â€“9, 2023,San Francisco, CA, USA
5 DISCUSSION
When scaling SnapVuln to real-world industry databases, it may
encounter challenges of the diversity of vulnerability types and
sample size. (1) Vulnerability types . Vulnerabilities in real-world
codebases are diverse, and the slicing algorithms in SnapVuln may
not coverevery single case. In thiswork, we employmultiplesub-
models and a GNN model to individually capture the distinct types
ofvulnerabilitysemanticsforvulnerabilitydetection.Ononehand,
the GNN models can capture comprehensive program semantics
to detect those vulnerabilities that are not handled by slicing algo-
rithms.Ontheotherhand,thismodularapproachenables SnapVuln
to easily accommodate other vulnerability types by simply adding
new slicing algorithms and submodels without the need to retrain
existing submodels. Furthermore, it helps prevent the aggregation
of all subgraphs into a single model, thereby mitigating the sub-
stantialincreaseinGPUmemoryrequirements.(2) Samplesize .
when dealing with large samples, such as entire programs that can
spanthousandsoflinesofcode, SnapVuln mayfacechallengesin
processing and analyzing them eï¬€ectively. To scale SnapVuln to
those samples with immense lines of code, we may increase the
value of/u1D458or employ methods to divide them into smaller pieces
for testing.For instance,thesamplesare constrainedto functions
at the /f_ile level orwithin the three calllevels.
6 THREATS TO VALIDITY
Internal validity: (1) Some samples may be mislabled in the
datasets (i.e., D2A [ 66] and Juliet [ 2]). On one hand, we trust most
oftheirlabelingresults,sinceJulietismaintainedbythedomain
experts in NIST, and D2A is collected through diï¬€erential analysis
andenhancedwithanindustrial-strengthstaticanalysistool.On
the other hand, we manually validate both datasets and remove
thosemislabeledsampleswefound.(2)Thetoolâ€œJoernâ€mayfail
togeneratethecorrectinter-proceduralgraphsforsomesamples.
To avoid this problem, we delete those samples that are incorrectly
parsedbyâ€œJoernâ€.(3) SnapVuln leveragesaGGNNtocapturevul-
nerability semantics for vulnerability detection. However, diï¬€erent
models may be suitable for diï¬€erent vulnerability types. For exam-
ple,GNNs,whichcanencodecodestructureinformation,maybe
better suited for vulnerability types involving complex logic, while
pre-trainedmodelsmaybebettersuitedforsmall-sampleorsimple
vulnerabilitytypes,sincetheylearnalotofbackgroundknowledge
from a large code corpus with huge model parameters. More re-
search should be conducted to study how to choose appropriate
modelsforspeci/f_icvulnerabilitytypes.(4)InRQ3,were-implement
the slicing algorithms from the baselines in SnapVuln , by follow-
ing their provided implementation as outlined. The reproduced
algorithms mayhave somediï¬€erence from the originalones.
Externalvalidity: SnapVuln isdesignedtodetectvulnerabilities
in C/C++ program. To support other programming languages, it is
necessarytodesignslicingalgorithmstailoredtothevulnerabilities
speci/f_ic to those languages. Furthermore, vulnerability datasets for
thoselanguagesare alsorequiredto retrain the models.
7 RELATED WORK
Program Slicing Techniques. Program slicing is a useful decom-
positiontechniqueforextractingprogramstatementsrelevanttosome special computation, starting from a subset of program be-
haviourandslicingthatprogramintoaminimalformthatstillpro-
ducesthatbehavior[ 63].Itwas/f_irstproposedbyWeiser[ 61]in1979,
which supports intra-procedural program slicing. After that, many
studiesrelatedtoprogramslicingsareproposed,suchasextensions
ofthealgorithmproposedbyHorwitz[ 11,12,27,35],computing
eï¬ƒciency [ 44,45], and SDG construction [ 26,34]. Program slicing
has been applied to many aspects of the software development life
cycle,includingsoftwaremaintenance[ 31â€“33,65],softwaremea-
surement [ 9,10,30] and software debugging [ 13,24,28,47,50,52].
It has also been used to capture program semantics to generate
coderepresentationsinlearning-basedvulnerabilitydetectionap-
proaches[ 17,38â€“40].However,theseprogramslicingalgorithms
include vulnerability-unrelated statements for code representation
generation. In this paper, referring to the inter-procedural chop-
ping [50] which identi/f_ies the statements that cause the de/f_initions
ofthesourcetoaï¬€ecttheusesofthesink,weproposevulnerability-
speci/f_ic inter-procedural slicing algorithms to capture precise vul-
nerability semantics for code representation generation.
GNNsforSoftwareEngineering. Sincegraphneuralnetworks
(GNN)cancaptureextensivestructureinformationincode,ithas
becomeincreasinglypopularforvarioustasks[ 4,8,36,41â€“43,46,
58,59,62]insoftwareengineering.Forexample,fortypeinference
task, Allamanis et al. [ 3] propose modeling the type information
foroptionally-typedlanguagesbyembeddinganabstractsyntax
tree and data /f_low analysis based graph with a gated graph neural
network (GGNN); For code summarization task, attempts has been
madetoincorporatesynacticalandsematiccodeinformationlever-
aginggraphneuralnetworks[ 22,36,41],whichempiricallydemon-
strates superior performance than sequence-based models. For vul-
nerability detection, graph neural networks are widely used to
leveragestructureinformationsuchascontrol/f_lowandprogramde-
pendencyinthecodetogeneraterepresentations[ 15,17,37,56,68].
Therefore,inthispaperweleverage graphneuralnetworktocap-
ture vulnerability semantics in the code for vulnerability detection.
8 CONCLUSION
We propose SnapVuln , a novel learning-based approach, which
employs vulnerability-speci/f_ic inter-procedural slicing algorithms
for diï¬€erent vulnerability types inC/C++ to capture complete and
precise vulnerability semantics for code representation generation
andincorporatestheattentionmechanismtothegatedgraphneural
network (GGNN)to ensure the modelassign diï¬€erent weightsfor
subgraphstolearnbetterrepresentations.Extensiveexperiments
on two public datasets demonstrate that SnapVuln outperforms
seven state-of-the-art baselines. We also conduct an ablation study
todemonstratethatthecompletenessandaccuracyofvulnerability
semantics contributeto the performance improvement.
ACKNOWLEDGMENTS
ThisresearchispartiallysupportedbytheMinistryofEducation,
Singapore under its Academic Research Fund Tier 3 (Award ID:
MOET32020-0004),ChineseNationalNaturalScienceFoundation
under Grant #62202462. Any opinions, /f_indings and conclusions
or recommendations expressed in this material are those of the
author(s) and do not re/f_lect the views of the Ministry of Education,
Singapore.
1381ESEC/FSE â€™23, December3â€“9, 2023,San Francisco, CA, USA Bozhi Wu, Shangqing Liu, Yang Xiao, ZhimingLi, Jun Sun,andShang-WeiLin
REFERENCES
[1] 2022. joern.https://joern.io/
[2] 2022. Juliet.https://samate.nist.gov/SARD
[3]MiltiadisAllamanis,EarlTBarr,SolineDucousso,andZhengGao.2020. Typilus:
Neuraltype hints.In Proceedingsof the41stacmsigplan conferenceon program-
minglanguagedesignand implementation . 91â€“105.
[4]Miltiadis Allamanis, Henry Jackson-Flux, and Marc Brockschmidt. 2021. Self-
supervisedbugdetectionandrepair. AdvancesinNeuralInformationProcessing
Systems34(2021), 27865â€“27876.
[5]Frances E. Allen and John Cocke. 1976. A program data /f_low analysis procedure.
Commun. ACM 19,3 (1976), 137.
[6]Authors. 2023. Learning Precise Program Semantics for Vulnerability Detec-
tion via Type-speci/f_ic Inter-procedural Slicing. https://sites.google.com/view/
snapvuln.
[7]Domagoj BabiÄ‡, Lorenzo Martignoni, Stephen McCamant, and Dawn Song. 2011.
Statically-directed dynamic automated test generation. In Proceedings of the 2011
InternationalSymposiumonSoftwareTestingand Analysis . 12â€“22.
[8]DavidBieber,CharlesSutton,HugoLarochelle,andDanielTarlow.2020.Learning
toexecuteprogramswithinstructionpointerattentiongraphneuralnetworks.
AdvancesinNeural InformationProcessingSystems 33(2020), 8626â€“8637.
[9]James M Bieman and Byung-Kyoo Kang. 1998. Measuring design-level cohesion.
IEEE Transactions onsoftwareengineering 24,2 (1998), 111â€“124.
[10]JamesMBiemanandLindaMOtt.1994. Measuringfunctionalcohesion. IEEE
transactions onSoftwareEngineering 20,8 (1994), 644â€“657.
[11]DavidBinkley.1993. Preciseexecutableinterproceduralslices. ACMLetterson
ProgrammingLanguages and Systems(LOPLAS) 2,1-4 (1993), 31â€“45.
[12]DavidBinkley.1993. Slicinginthepresenceofparameteraliasing.In Software
Engineering Research Forum . 261â€“268.
[13]Robert S Boyer, Bernard Elspas, and Karl N Levitt. 1975. SELECTâ€”a formal
systemfortestinganddebuggingprogramsbysymbolicexecution. ACMSigPlan
Notices10,6 (1975), 234â€“245.
[14]Sang Kil Cha, Maverick Woo, and David Brumley. 2015. Program-adaptive
mutational fuzzing. In 2015 IEEE Symposium on Security and Privacy . IEEE, 725â€“
741.
[15]Saikat Chakraborty, Rahul Krishna, Yangruibo Ding, and Baishakhi Ray. 2021.
Deep learning based vulnerability detection: Are we there yet. IEEE Transactions
onSoftwareEngineering (2021).
[16]Walter Chang, Brandon Streiï¬€, and Calvin Lin. 2008. Eï¬ƒcient and extensible
securityenforcementusingdynamicdata/f_lowanalysis.In Proceedingsofthe15th
ACMconference onComputer and communicationssecurity . 39â€“50.
[17]XiaoCheng,HaoyuWang,JiayiHua,GuoaiXu,andYuleiSui.2021. Deepwukong:
Statically detecting software vulnerabilities using deep graph neural network.
ACMTransactionsonSoftwareEngineeringandMethodology(TOSEM) 30,3(2021),
1â€“33.
[18]XiaoCheng,GuanqinZhang,HaoyuWang,andYuleiSui.2022. Path-sensitive
code embedding via contrastive learning for software vulnerability detection.
InProceedings of the 31st ACM SIGSOFT International Symposium on Software
Testingand Analysis . 519â€“531.
[19]Kyunghyun Cho, Bart Van MerriÃ«nboer, Caglar Gulcehre, Dzmitry Bahdanau,
Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning phrase
representations using RNN encoder-decoder for statistical machine translation.
arXiv preprint arXiv:1406.1078 (2014).
[20]Jiahao Fan, Yi Li, Shaohua Wang, and Tien N Nguyen. 2020. AC/C++ code
vulnerabilitydatasetwithcodechangesandCVEsummaries.In Proceedingsof
the 17thInternationalConference onMiningSoftwareRepositories . 508â€“512.
[21]Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong,
LinjunShou,BingQin,TingLiu,DaxinJiang,etal .2020. Codebert:Apre-trained
modelfor programmingand natural languages. arXiv preprint arXiv:2002.08155
(2020).
[22]PatrickFernandes,MiltiadisAllamanis,andMarcBrockschmidt.2018. Structured
neural summarization. arXiv preprint arXiv:1811.01824 (2018).
[23]Lloyd D Fosdick and Leon J Osterweil. 1976. Data /f_low analysis in software
reliability. ACMComputingSurveys(CSUR) 8,3 (1976), 305â€“330.
[24]Peter Fritzson, Nahid Shahmehri, Mariam Kamkar, and Tibor Gyimothy. 1992.
Generalizedalgorithmicdebuggingandtesting. ACMLettersonProgramming
Languages and Systems(LOPLAS) 1,4 (1992), 303â€“322.
[25]Daya Guo, Shuo Ren, Shuai Lu, Zhangyin Feng, Duyu Tang, Shujie Liu, Long
Zhou, Nan Duan, Alexey Svyatkovskiy, Shengyu Fu, et al .2020. Graphcodebert:
Pre-training code representations with data /f_low. arXiv preprint arXiv:2009.08366
(2020).
[26]Dixie Hisley, Matt Bridges, and Lori Pollock. 2002. Static interprocedural slicing
of shared memoryparallel programs. (2002).
[27]SusanHorwitz,ThomasReps,andDavidBinkley.1990. Interproceduralslicing
using dependence graphs. ACM Transactions on Programming Languages and
Systems(TOPLAS) 12,1 (1990), 26â€“60.
[28]Daniel Jackson and Eugene J Rollins. 1994. Chopping: A generalization of slic-
ing. TechnicalReport. CARNEGIE-MELLON UNIVPITTSBURGH PADEPT OFCOMPUTERSCIENCE.
[29]Dae R Jeong, Kyungtae Kim, Basavesh Shivakumar, Byoungyoung Lee, and Insik
Shin. 2019. Razzer: Finding kernel race bugs through fuzzing. In 2019 IEEE
SymposiumonSecurityand Privacy (SP) . IEEE,754â€“768.
[30]Byung-Kyoo Kang andJamesM Bieman.1996. Design-level cohesionmeasures:
Derivation, comparison, and applications. In Proceedings of 20th International
Computer Softwareand ApplicationsConference: COMPSACâ€™96 . IEEE,92â€“97.
[31]TaehoKim,Yeong-TaeSong,LawrenceChung,andDungTHuynh.1999. Soft-
warearchitectureanalysisusingdynamicslicing.In AoM/IAoM17thInternational
Conference onComputer Science . 242â€“247.
[32]TaehoKim,Yeong-TaeSong,LawrenceChung,andDungTHuynh.2000. Soft-
ware architecture analysis: a dynamic slicing approach. International Journal of
Computer & InformationScience 1,2 (2000), 91â€“103.
[33]TaehoKim,Yeong-TaeSong,LawrenceChung,andDTHyunh.1999. Dynamic
softwarearchitectureslicing.In Proceedings.Twenty-ThirdAnnualInternational
ComputerSoftwareandApplicationsConference(Cat.No.99CB37032) .IEEE,61â€“66.
[34]AkosKiss,JuditJÃ¡sz,GÃ¡borLehotai,andTiborGyimÃ³thy.2003. Interprocedu-
ral static slicing of binary executables. In Proceedings Third IEEE International
Workshop onSourceCodeAnalysisand Manipulation . IEEE,118â€“127.
[35]Arun Lakhotia. 1992. Improved interprocedural slicing algorithm. Report CACS
TR-92-5-8,UniversityofSouthwestern Louisiana (1992).
[36]Alexander LeClair, Sakib Haque, Lingfei Wu, and Collin McMillan. 2020. Im-
proved code summarization via a graph neural network. In Proceedings of the
28thinternational conference onprogramcomprehension . 184â€“195.
[37]YiLi,ShaohuaWang,TienNNguyen,andSonVanNguyen.2019. Improvingbug
detection via context-based code representation learning and attention-based
neuralnetworks. ProceedingsoftheACMonProgrammingLanguages 3,OOPSLA
(2019), 1â€“30.
[38]Zhen Li, Deqing Zou, Shouhuai Xu, Zhaoxuan Chen, Yawei Zhu, and Hai Jin.
2021. Vuldeelocator:adeeplearning-based/f_ine-grainedvulnerabilitydetector.
IEEE Transactions onDependableand SecureComputing (2021).
[39]ZhenLi,DeqingZou,ShouhuaiXu,HaiJin,YaweiZhu,andZhaoxuanChen.2021.
Sysevr:Aframeworkforusingdeeplearningtodetectsoftwarevulnerabilities.
IEEE Transactions onDependableand SecureComputing (2021).
[40]Zhen Li, Deqing Zou, Shouhuai Xu, Xinyu Ou, Hai Jin, Sujuan Wang, Zhijun
Deng,andYuyiZhong.2018. Vuldeepecker:Adeeplearning-basedsystemfor
vulnerability detection. arXiv preprint arXiv:1801.01681 (2018).
[41]ShangqingLiu,YuChen,XiaofeiXie,JingKaiSiow,andYangLiu.2020. Retrieval-
AugmentedGenerationforCodeSummarizationviaHybridGNN.In International
Conference onLearning Representations .
[42]Shuwen Liu, Bernardo Grau, Ian Horrocks, and Egor Kostylev. 2021. Indigo:
Gnn-based inductive knowledge graph completion using pair-wise encoding.
AdvancesinNeural InformationProcessingSystems 34(2021), 2034â€“2045.
[43]Shangqing Liu, Xiaofei Xie, Lei Ma, Jingkai Siow, and Yang Liu. 2021. Graph-
searchnet:Enhancinggnnsviacapturingglobaldependencyforsemanticcode
search.arXiv preprint arXiv:2111.02671 (2021).
[44]PanosELivadasandStephenCroll.1993. Systemdependencegraphconstruction
forrecursive programs. In Proceedings of1993IEEE 17thInternationalComputer
Softwareand ApplicationsConference COMPSACâ€™93 . IEEE,414â€“420.
[45]Panos E Livadas and Stephen Croll. 1995. A new algorithm for the calculation of
transitive dependences. Journal of Software Maintenance: Research and Practice 7,
3 (1995), 151â€“176.
[46]WaiWengLo,SiamakLayeghy,MohanadSarhan,MarcusGallagher,andMar-
ius Portmann. 2022. GNN-based Android Malware Detection with Jumping
Knowledge. arXiv preprint arXiv:2201.07537 (2022).
[47]RLyle.1987. Automaticprogrambuglocationbyprogramslicing.In Proceedings
2nd international conference oncomputers and applications . 877â€“883.
[48]EhsanMashhadiandHadiHemmati.2021. Applyingcodebertforautomatedpro-
gram repair of java simple bugs. In 2021 IEEE/ACM 18th International Conference
onMiningSoftwareRepositories(MSR) . IEEE,505â€“509.
[49]Brian S Pak. 2012. Hybrid fuzz testing: Discovering software bugs via fuzzing
andsymbolicexecution. SchoolofComputerScienceCarnegieMellonUniversity
(2012).
[50]Thomas Reps and Genevieve Rosay. 1995. Precise interprocedural chopping.
InProceedingsofthe3rdACMSIGSOFTSymposiumonFoundationsofSoftware
Engineering . 41â€“52.
[51]Rebecca Russell, Louis Kim, Lei Hamilton, Tomo Lazovich, Jacob Harer, Onur
Ozdemir, Paul Ellingwood, and Marc McConley. 2018. Automated vulnerability
detectioninsourcecodeusingdeeprepresentationlearning.In 201817thIEEE
international conference on machine learning and applications (ICMLA) . IEEE,
757â€“762.
[52] Ehud Yehuda Shapiro. 1982. Algorithmic programdebugging . YaleUniversity.
[53]NickStephens,JohnGrosen,ChristopherSalls,AndrewDutcher,RuoyuWang,
Jacopo Corbetta, YanShoshitaishvili, Christopher Kruegel, and Giovanni Vigna.
2016. Driller:AugmentingFuzzingThroughSelectiveSymbolicExecution..In
NDSS, Vol. 16.1â€“16.
[54]Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, Åukasz Kaiser, and Illia Polosukhin. 2017. Attention is all
1382Learning Program Semantics forVulnerabilityDetectionviaVulnerability-SpecificInter-proceduralSlicing ESEC/FSE â€™23, December3â€“9, 2023,San Francisco, CA, USA
you need. Advancesinneuralinformation processingsystems 30(2017).
[55]PetarVeliÄkoviÄ‡,GuillemCucurull,Arantxa Casanova,AdrianaRomero,Pietro
LiÃ²,and YoshuaBengio. 2018. GraphAttentionNetworks.In InternationalCon-
ference onLearning Representations .
[56]HuantingWang,GuixinYe,ZhanyongTang,ShinHweiTan,SongfangHuang,
Dingyi Fang, Yansong Feng, Lizhong Bian, and Zheng Wang. 2020. Combin-
inggraph-basedlearningwithautomateddatacollectionforcodevulnerability
detection. IEEE Transactions on Information Forensics and Security 16 (2020),
1943â€“1958.
[57]Junjie Wang, Bihuan Chen, Lei Wei, and Yang Liu. 2019. Superion: Grammar-
awaregreyboxfuzzing.In 2019 IEEE/ACM 41st InternationalConference onSoft-
wareEngineering (ICSE) . IEEE,724â€“735.
[58]Wenhan Wang, Ge Li, Bo Ma, Xin Xia, and Zhi Jin. 2020. Detecting code clones
withgraphneuralnetworkand/f_low-augmentedabstractsyntaxtree.In 2020IEEE
27thInternationalConferenceonSoftwareAnalysis,EvolutionandReengineering
(SANER). IEEE,261â€“271.
[59]YuWang,KeWang,FengjuanGao,andLinzhangWang.2020. Learningsemantic
program embeddings with graph interval neural network. Proceedings of the
ACMonProgrammingLanguages 4,OOPSLA (2020), 1â€“27.
[60]JiayiWei,MaruthGoyal,GregDurrett,andIsilDillig.2020.Lambdanet:Probabilis-
tictypeinferenceusinggraphneuralnetworks. arXivpreprintarXiv:2005.02161
(2020).
[61]MarkDavid Weiser.1979. Programslices: formal,psychological,and practical in-
vestigationsofanautomaticprogramabstractionmethod . UniversityofMichigan.
[62]BozhiWu,ShangqingLiu,RuitaoFeng,XiaofeiXie,JingkaiSiow,andShang-Wei
Lin.2022. EnhancingSecurityPatchIdenti/f_icationbyCapturingStructuresin
Commits. IEEE Transactions onDependableand SecureComputing (2022).
[63]BaowenXu,JuQian,XiaofangZhang,ZhongqiangWu,andLinChen.2005. A
brief surveyof program slicing. ACM SIGSOFT Software Engineering Notes 30, 2(2005), 1â€“36.
[64]FabianYamaguchi,NicoGolde,DanielArp,andKonradRieck.2014.Modelingand
discoveringvulnerabilitieswith codepropertygraphs. In 2014IEEESymposium
onSecurityand Privacy . IEEE,590â€“604.
[65]Jianjun Zhao. 1998. Applying slicing technique to software architectures. In
Proceedings. Fourth IEEE International Conference on Engineering of Complex
Computer Systems(Cat. No. 98EX193) . IEEE,87â€“98.
[66]Yunhui Zheng, Saurabh Pujar, Burn Lewis, Luca Buratti, Edward Epstein, Bo
Yang, Jim Laredo, Alessandro Morari, and Zhong Su. 2021. D2A: a dataset
built for AI-based vulnerability detection methods using diï¬€erential analysis. In
2021IEEE/ACM43rdInternationalConferenceonSoftwareEngineering:Software
Engineering inPractice (ICSE-SEIP) . IEEE,111â€“120.
[67]JiayuanZhou,MichaelPacheco,ZhiyuanWan,XinXia,DavidLo,YuanWang,
and Ahmed E Hassan. 2021. Finding A Needle in a Haystack: Automated Mining
of Silent VulnerabilityFixes. In 2021 36th IEEE/ACM InternationalConference on
AutomatedSoftwareEngineering (ASE) . IEEE,705â€“716.
[68]Yaqin Zhou, Shangqing Liu, Jingkai Siow, Xiaoning Du, and Yang Liu. 2019.
Devign:Eï¬€ectivevulnerabilityidenti/f_icationbylearningcomprehensiveprogram
semantics via graph neural networks. Advances in neural information processing
systems32(2019).
[69]Yaqin Zhou, Jing Kai Siow, Chenyu Wang, Shangqing Liu, and Yang Liu. 2021.
Spi:Automatedidenti/f_icationofsecuritypatchesviacommits. ACMTransactions
onSoftwareEngineering and Methodology (TOSEM) 31,1 (2021), 1â€“27.
[70]Deqing Zou, Sujuan Wang, Shouhuai Xu, Zhen Li, and Hai Jin. 2019.
/u1D707VulDeePecker: A Deep Learning-Based System for Multiclass Vulnerability
Detection. IEEETransactionsonDependableandSecureComputing 18,5(2019),
2224â€“2236.
Received 2023-02-02; accepted 2023-07-27
1383