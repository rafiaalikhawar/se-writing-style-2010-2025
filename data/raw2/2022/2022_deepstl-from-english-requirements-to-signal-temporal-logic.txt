DeepSTL - From English Requirements to Signal Temporal LogicJie Hejie.he@tuwien.ac.atTechnische UniversitÃ¤t WienVienna, AustriaEzio Bartocciezio.bartocci@tuwien.ac.atTechnische UniversitÃ¤t WienVienna, AustriaDejan NiÄkoviÄ‡Dejan.Nickovic@ait.ac.atAIT Austrian Institute of TechnologyVienna, AustriaHaris Isakovicharis@vmars.tuwien.ac.atTechnische UniversitÃ¤t WienVienna, AustriaRadu Grosuradu.grosu@tuwien.ac.atTechnische UniversitÃ¤t WienVienna, AustriaABSTRACTFormal methods provide very powerful tools and techniques for thedesign and analysis of complex systems. Their practical applicationremains however limited, due to the widely accepted belief that for-mal methods require extensive expertise and a steep learning curve.Writing correct formal speci#cations in form of logical formulas isstill considered to be a di$cult and error prone task.In this paper we propose DeepSTL, a tool and technique for thetranslation of informal requirements, given as free English sen-tences, into Signal Temporal Logic (STL), a formal speci#cationlanguage for cyber-physical systems, used both by academia andadvanced research labs in industry. A major challenge to devisesuch a translator is the lack of publicly available informal require-ments and formal speci#cations. We propose a two-step work%owto address this challenge. We#rst design a grammar-based genera-tion technique of synthetic data, where each output is a random STLformula and its associated set of possible English translations. Inthe second step, we use a state-of- the-art transformer-based neuraltranslation technique, to train an accurate attentional translatorof English to STL. The experimental results show high transla-tion quality for patterns of English requirements that have beenwell trained, making this work%ow promising to be extended forprocessing more complex translation tasks.CCS CONCEPTSâ€¢Requirements Engineeringâ†’Formal Speci/f_ication;â€¢For-mal Veri/f_icationâ†’Signal Temporal Logic (STL).KEYWORDSRequirements Engineering, Formal Speci#cation, Signal TemporalLogic (STL), Machine TranslationACM Reference Format:Jie He, Ezio Bartocci, Dejan NiÄkoviÄ‡, Haris Isakovic, and Radu Grosu.2022. DeepSTL - From English Requirements to Signal Temporal Logic. InPermission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor pro#t or commercial advantage and that copies bear this notice and the full citationon the#rst page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior speci#c permissionand/or a fee. Request permissions from permissions@acm.org.ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USAÂ© 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 978-1-4503-9221-1/22/05. . . $15.00https://doi.org/10.1145/3510003.351017144th International Conference on Software Engineering (ICSE â€™22), May 21â€“29, 2022, Pittsburgh, PA, USA.ACM, New York, NY, USA, 13 pages. https://doi.org/10.1145/3510003.35101711 INTRODUCTIONâ€œWhat is reasonable is real. That which is real is reasonable.â€This famous proposition from Hegel, saying that everything has itsâ€œlogicâ€, often resonates in Aliceâ€™s mind. Alice is a veri#cation engi-neer responsible for safety-critical cyber-physical systems (CPS).She advocates the use of formal methods with requirements speci-#ed in logic, as part of the development of complex CPS.Formal speci#cations enable rigorous reasoning about a CPSproduct (for example its model checking or systematic testing) dur-ing all its design phases, as well as during operation (for example viaruntime veri#cation) [1]. Alice is frustrated by the resistance of hercolleagues to adopt formal methods in their design methodology.She is aware that one major bottleneck in a wider acceptance ofthese techniques results from the steep learning curve to translateinformal requirements expressed in natural language into formalspeci#cations. The correspondence between a requirement writ-ten in English and its temporal logic formalization is not alwaysstraightforward, as illustrated in the example below:â€¢English Requirement:Whenever V_Mot is detected to become equal to 0, then at atime point starting after at most 100 time units Spd_Act shallcontinuously remain on 0 for at least 20 time units.â€¢Signal Temporal Logic (STL):G(rise(V_Mot=0)â†’F[0,100]G[0,20](Spd_Act=0))Bob is Aliceâ€™s colleague and an expert in machine learning. He in-troduces Alice to the tremendous achievements in natural languageprocessing (NLP), demonstrated by applications such as GoogleTranslate and DeepL. Alice is impressed by the quality of transla-tions between natural languages. She realizes that NLP is a technol-ogy that can reduce the gap between engineers and formal methods,and signi#cantly increase the acceptance of rigorous speci#cations.However, Alice also observes that this potential solution doesnot come without challenges. In order to build a translator fromone spoken language to another, there is a huge amount of textsavailable in both languages that can be used for training and thereis also a series of systematic translation solutions. In contrast, fortranslating CPS requirements given in natural language into formalspeci#cations, there are two major challenges:
6102022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)ICSE â€™22, May 21â€“29, 2022, Pi/t_tsburgh, PA, USAJie He, Ezio Bartocci, Dejan NiÄkoviÄ‡, Haris Isakovic, and Radu Grosuâ€¢Challenge 1: Lack of available training data. The informal re-quirement documents are sparse and often not publicly available,and formal speci#cations are even sparser.â€¢Challenge 2: No mature solutions for translating English re-quirements into formal speci#cations, where special features ofthese two languages need to be considered.In this paper, as a#rst attempt to adopt NLP to tackle the abovetwo challenges, we propose DeepSTL, a method and associatedtool for the translation of CPS requirements given in relatively freeEnglish to Signal Temporal Logic (STL) [2], a formal speci#cationlanguage used by the CPS academia and industry. To develop Deep-STL we address the following#ve research questions (RQ), thesolutions of which are also our main contributions.RQ1:What kind of empirical statistics of STL requirements, foundin scienti#c literature, can guide data generation?RQ2:How to generate synthetic examples of STL requirementsconsistently with the empirically collected statistics?The#rst two research questions are related toChallenge 1. ForRQ1, empirical STL statistics in literature and practice are analyzedin Section 4. ForRQ2, we design in Section 5, a systematic grammar-based generation of synthetic data sets, consisting of pairs of STLformulae and their associated set of possible English translations.RQ3:How eï¬€ective is DeepSTL in learning synthetic STL?RQ4:How well does DeepSTL extrapolate to STL requirementsfound in scienti#c literature?RQ5:How do alternative deep learning mechanisms used in ma-chine translation compare to DeepSTLâ€™s transformer archi-tecture?The last three research questions are relevant toChallenge 2.They are addressed in Section 6 and discussed in Section 7. We em-ploy a corresponding transformer-based NLP architecture, whoseattention mechanism enables the e$cient training of accurate trans-lators from English to STL. We also compare DeepSTL with othermachine translation techniques with respect to translating per-formance, on synthetic STL training and test data set, and theirextrapolations.The collected data and the implementation codes in this papercan be found in the provided links1.2 RELATED WORKFrom Natural Language to Temporal LogicsDespite manyapproaches proposed in the literature [3â€“16], the problem of trans-lating natural language requirements into temporal logics remainsstill open [9]. The main challenge arises from translating an am-biguous and context-sensitive language into a more precise andcontext-free formal language. To facilitate and guide the translationprocess, most of the available methods require the use of prede#nedspeci#cation patterns [4,8,17] or of a restricted and more controllednatural language [6,12,18]. Handling the direct translation of un-constrained natural languages is instead more cumbersome. Otherworks [3,11,13,15] address this problem by translating the naturallanguage expression#rst into an intermediate representation. Then,the translation process continues by applying a set of manually1Artifact DOI:10.6084/m9.#gshare.19091282Code repository:https://github.com/JieHE-2020/DeepSTLprede#ned rules/macros mapping the intermediate representationinto temporal logic expressions. These approaches are centeredon Linear Temporal Logic (LTL) [19], a temporal logic suitable toreason about events occurring over logical-time Boolean signals.In this paper we consider instead (for the#rst time to the bestof our knowledge) the problem of automatic translation of uncon-strained English sentences into Signal Temporal Logic (STL) [2],a temporal logic that extends LTL with operators to express tem-poral properties over dense-time real-valued signals. STL is a well-established formal language employed in both academia and ad-vanced industrial research labs to specify requirements for CPSengineering [20, 21].Semantic ParsingOur problem can be considered an exampleof semantic parsing [9]. This task consists in automatically translat-ing sentences written in a context-sensitive natural language intomachine-understandable expressions such as executable code orlogical representations. Semantic parsers are automatically learnedfrom a set of utterances written in natural languages that are anno-tated with the semantic interpretation in the target language. Somerelevant toolkits [9] available for developing semantic parsers areWASP [22], SEMPRE [23], KRISP [24], SippyCup [25], and CornellSemantic Parsing [26]. Applications of semantic parsing includethe translation of questions or commands expressed in natural-language into Structured-Query-Language (SQL) queries [27â€“31],Python code [32], bash commands [33], and other domain speci#clanguages [34]. The main di$culty for this task is to learn the setof semantic rules that can cover all the potential ambiguity arisingwhen translating from a context-sensitive natural language. Thus,to be eï¬€ective, this task requires a large training data set.In order to cope with the lack of publicly available informal-requirement and formal-speci#cation data sets, we#rst designa grammar-based generation technique of synthetic data, whereeach output is a random STL formula and its associated set ofpossible English translations. Then we address a neural-translationproblem, where a deep neural network is trained to predict, giventhe utterance in English, the optimal STL formula expressing it. Ourwork leverages general-purpose deep learning frameworks such asPyTorch [35] or Tensor%ow [36], and of state-of-the-art solutionsbased on transformers and their attention mechanisms [37].3 SIGNAL TEMPORAL LOGIC (STL)Signal Temporal Logic (STL) with bothpastandfutureoper-ators is a formal speci#cation formalism used by the academicresearchers and practitioners to formalize temporal requirementsof CPS behaviors. STL allows to express real time requirementsof continuous-time real-valued behaviors. An example is a simplebounded stabilization property formulated as follows:WheneverV_In is above 5, then there must exist a time point in the next 10 timeunits, at which the value of signal V_Out should be less than 2.The syntax of an STL formulağ‘£over a setğ‘Ÿof real-valuedvariables is de#ned by the grammar:ğ‘£:=ğ‘’âˆ¼â„|Â¬ğ‘£|ğ‘£1âˆ¨ğ‘£2|ğ‘£1U/u1D43Cğ‘£2|ğ‘£1S/u1D43Cğ‘£2whereğ‘’âˆˆğ‘Ÿ,âˆ¼âˆˆ{â‰¥,>,=,<,â‰¤},â„âˆˆQ,ğ‘âŠ†[0,()is a non-emptyinterval. For intervals of the form[ğ‘™,ğ‘™], we will use the notation{ğ‘™}instead. With respect to a signalğ‘œ:ğ‘Ÿ)[0,ğ‘§)â†’R, the semantics ofan STL formula is described via the satis#ability relation(ğ‘œ,ğœƒ)|=ğ‘£,611DeepSTL - From English Requirements to Signal Temporal LogicICSE â€™22, May 21â€“29, 2022, Pi/t_tsburgh, PA, USAindicating that the signalğ‘œsatis#esğ‘£at the time indexğœƒ:(ğ‘œ,ğœƒ)|=ğ‘’âˆ¼â„â†”ğ‘œ(ğ‘’,ğœƒ)âˆ¼â„(ğ‘œ,ğœƒ)|=Â¬ğ‘£â†”(ğ‘œ,ğœƒ)+|=ğ‘£(ğ‘œ,ğœƒ)|=ğ‘£1âˆ¨ğ‘£2â†”(ğ‘œ,ğœƒ)|=ğ‘£1or(ğ‘œ,ğœƒ)|=ğ‘£2(ğ‘œ,ğœƒ)|=ğ‘£1U/u1D43Cğ‘£2â†”âˆƒğœ–âˆˆ(ğœƒ+ğ‘)âˆ©T:(ğ‘œ,ğœ–)|=ğ‘£2andâˆ€ğœƒ<ğ›½<ğœ–,(ğ‘œ,ğ›½)|=ğ‘£1(ğ‘œ,ğœƒ)|=ğ‘£1S/u1D43Cğ‘£2â†”âˆƒğœ–âˆˆ(ğœƒ/ğ‘)âˆ©T:(ğ‘œ,ğœ–)|=ğ‘£2andâˆ€ğœ–<ğ›½<ğœƒ,(ğ‘œ,ğ›½)|=ğ‘£1We useSandUas syntactic sugar for theuntimedvariants of thesinceS(0,()anduntilU(0,()operators. From the basic de#nitionof STL, we can derive the following standard operators.tautologytrue=,âˆ¨Â¬,contradictionfalse=Â¬truedisjunctionğ‘£1âˆ§ğ‘£2=Â¬(Â¬ğ‘£1âˆ¨Â¬ğ‘£2)implicationğ‘£1â†’ğ‘£2=Â¬ğ‘£1âˆ¨ğ‘£2eventually,#nallyF/u1D43Cğ‘£=true U/u1D43Cğ‘£always, globallyG/u1D43Cğ‘£=Â¬F/u1D43CÂ¬ğ‘£onceO/u1D43Cğ‘£=true S/u1D43Cğ‘£historicallyH/u1D43Cğ‘£=Â¬O/u1D43CÂ¬ğ‘£rising edgerise(ğ‘£)=ğ‘£âˆ§Â¬ğ‘£S truefalling edgefall(ğ‘£)=Â¬ğ‘£âˆ§ğ‘£S trueWe can now formalize the rather verbose English descriptionof the aboveBounded responserequirement, with a succinct STLformula as follows:G(V_In>5â†’F[0,10](V_Out<2)).This formula can be directly used during the veri#cation of aCPS before it was deployed, or to generate a monitor, checking thesafety of the CPS, after its deployment.4 EMPIRICAL STL STATISTICSIn order to address the relative lack of publicly available STLspeci#cations, we develop a synthetic-training-data generator, asdescribed in Section 5. Instead of exploring completely random STLsentences, the generator should focus on the creation of commonlyused STL speci#cations. In addition, every STL formula shall beassociated to a set of natural language formulations, with commonlyused sentence structure and vocabulary.We analyzed over 130 STL speci#cations and their associatedEnglish-language formulation, from scienti#c papers and industrialdocuments. The investigated literature covers multiple applicationdomains: speci#cation patterns [20], automatic driving [21,38,39],robotics [40â€“44], time-series analysis [45] and electronics [2,46].Although this literature contains data that is not statistically ex-haustive, it still provides valuable information to guide the designof the data generator and address the research questionRQ1.We present our results on the statistical analysis of the STLspeci#cations in Section 4.1 and of their associated natural-languagerequirements in Section 4.2.4.1 Analysis of STL Speci/f_icationsWe conducted two main types of analysis for the STL speci#ca-tions encountered in the literature: (1) Identi#cation of commontemporal-logic templates, and (2) Computation of the frequencyof individual operators. During analysis, we made several otherrelevant observations that we report at the end of this subsection.4.1.1 STL-Templates Distribution.We identi#ed four common STLtemplates that we call:Invariance/Reachability,Immediate response,Temporal responseandStabilization/Recurrence.Invariance/Reachability template:Bounded and unboundedinvariance and reachability are the simplest temporal STL proper-ties. They have the formGğ‘£,G[/u1D44E,/u1D44F]ğ‘£,Fğ‘£orF[/u1D44E,/u1D44F]ğ‘£, whereğ‘£is anatomic predicate. We provide one example of bounded-invariance(BI) [38], and one example of unbounded-reachability (UR) [41]speci#cation, respectively, as encountered in our investigation:ğ´ğ‘:G[/u1D70F/u1D460,/u1D447](.<ğ¶/u1D459),ğ¿ğ¶u1D445:F(ğ‘’>0.4)Immediate response template:This template represents formu-las of the formG(ğ‘£â†’ğ¶u1D713), whereğ‘£andğ¶u1D713are atomic propositionsor their Boolean combinations. Except for the startingGoperator,there are no other temporal operators in the formula. An exampleof an immediate response (IR) speci#cation is the one from [20]:ğ‘ğ¶u1D445:G(not_Eclipse=0â†’sun_currents=0).Temporal response template:This template represents formu-las of the formG(ğ‘£â†’ğ¶u1D713), whereğ‘£andğ¶u1D713can have non-nestedtemporal operators. We illustrate several TR speci#cations that weencountered in the literature. They all belong to this class:ğ¶u1D447ğ¶u1D4451:G(rise(Op_Cmd=Passive)â†’F[0,500]Spd_Act=0)ğ¶u1D447ğ¶u1D4452:G(currentADCSMode=SMâ†’ğ¶u1D443U[0,10799]Â¬ğ¶u1D443)[20]ğ¶u1D447ğ¶u1D4453:G(rise(gear_id=1)â†’G[0,2.5]Â¬fall(gear_id=1))[21]Inğ¶u1D447ğ¶u1D4452 above,ğ¶u1D443â‰¡real_Omega/target_Omega=0.Stabilization/Recurrence template:These templates representformulas allowing one nesting of the temporal operators. Typicalnesting isGFğ‘£for recurrence (RE), andFGğ‘£for stabilization (ST),with their bounded counterparts. Hereğ‘£is a non-temporal formula.The following speci#cations from the literature are in this category:ğ¶u1D446ğ¶u1D447:F[0,14400]G[4590,9963](ğ‘’10â‰¥0.325)[45]ğ¶u1D445ğ¶u1D438:G[0,12](F[0,2]regionAâˆ§F[0,2]regionB)[43]Other formulas:These are formulas that do not fall into any ofthe above categories. The following speci#cation belongs to thisclass:G(rise(ğ‘£1)â†’F[0,/u1D4611](rise(ğ‘£2)âˆ§(ğ‘£2U[/u1D4612,/u1D4613]ğ‘£3)))It captures the following requirement:Whenever the preconditionğ‘£1becomes true, there is a time withinğ¶u1D4611units whereğ‘£2becomes trueand continuously holds untilğ‘£3becomes true within another interval[ğ¶u1D4612,ğ¶u1D4613].This pattern is used in the electronics#eld [2] to describethe situation where one digital signal tracks another [46].Statistics:We encountered 39Invariance/Reachability(30.0%), 27Immediate response(20.8%), 33Temporal response(25.4%) and 31Stabilization/Recurrence(23.8%) templates. The category of Othertemplates is orthogonal to the#rst four ones since it includes adhoc formulas. There are overall 13 (39.4%)Temporal responseand 6(19.3%)Stabilization/Recurrencetemplates belonging to this type.4.1.2 STL-Operators Distribution.We investigated the distributionof the STL-operators as encountered in the speci#cations found inthe above-mentioned literature. Figure 1 summarizes our results.612ICSE â€™22, May 21â€“29, 2022, Pi/t_tsburgh, PA, USAJie He, Ezio Bartocci, Dejan NiÄkoviÄ‡, Haris Isakovic, and Radu Grosu
/u1D465=/u1D462/u1D465>/u1D462/u1D465â‰¥/u1D462/u1D465</u1D462/u1D465â‰¤/u1D462rise(/u1D711)fall(/u1D711)F/u1D43C/u1D711G/u1D43C/u1D711/u1D7111U/u1D43C/u1D7112O/u1D43C/u1D711H/u1D43C/u1D711/u1D7111S/u1D43C/u1D7112Â¬/u1D711/u1D7111âˆ§/u1D7112/u1D7111âˆ¨/u1D7112/u1D7111â†’/u1D7112306090120150
Figure 1: Frequency Distribution of STL Operators.We#rst discuss the (atomic) numeric predicates. We observe thatthe equality operator occurs more often in numerical predicatesthen the other (â‰¤,<,â‰¥,>) relations. This happens because manyspeci#cations refer to discrete mode signals and equality is used tocheck if a discrete variable is in a given mode.Conjunction and implication are the two most frequently usedBoolean operators. Conjunction is often used to specify that a signalmust lie within a given range. Implication is used in a pretty widerange of response speci#cations.Theriseandfalloperators are typically used in front of anatomic predicate (for examplerise(ğ‘’>.)). The frequency of risingedges is higher than that of falling edges, which can be explainedby the fact that many speci#cations refer to time instants where acondition starts holding, rather than when it stops holding.TheGoperator has a much higher frequency than any othertemporal operator. This is not surprising because 86.2% (112/130) ofthe speci#cations are invariance or response or recurrence proper-ties that start with an always operator. TheFoperator ranks secondand is often used in speci#cations of robotic applications to de#nereachability objectives. We also remark that â€œeventuallyâ€ is used inbounded/unbounded and stabilization properties.We#nally observe that future temporal operators (G,F,U) areused more often than their past counterparts (O,H,S) and thatunary temporal operators (G,F,H,O) are used more often thanthe binary ones (U,S). These two observations are explained by thefact that most declarative speci#cations have a natural future%avor(a trigger now implies an obligation that must be ful#lled later) andunary temporal operators are easier to understand and handle.4.1.3 Other Observations.In this section, we discuss additional#ndings that we discovered during the analysis of the STL speci#-cations occurring in the literature:â€¢We found a frequent usage of the pattern|ğ‘’/ğ¶u1D466.alt|to denote thepointwise distance between signalsğ‘’andğ¶u1D466.alt, especially in themotion control applications [39â€“41].â€¢Some publications use abstract predicates to denote complextemporal patterns, without providing their detailed formalization.One such example is the use of the predicatespike(ğ‘’)to denotea spike occurring within the signalğ‘’[20].â€¢It is relatively common in the literature to decompose a complexSTL speci#cation into multiple simpler ones, by giving a nameto a sub-formula and using that name as an atomic propositionin the main formula.â€¢Time bounds in temporal operators and signal thresholds aresometimes given as parameters, rather than constants.â€¢rise,falland past temporal operators are normally used aspre-conditions, while future operators are often used as post-conditions. Negation is used conservatively, e.g.,Â¬fallis usedto represent a particular stabilized condition should hold for adesignated time interval [2].4.2 Analysis of NL Speci/f_icationsIn this section we investigate the usage of natural language(NL) in the literature to express informal requirements, which arethen formalized using STL. In particular, we identi#ed the Englishvocabulary used to formulate STL operators and sentences, andstudied the quality, accuracy and preciseness of the language.4.2.1 English formulation of STL sentences.We considered severalaspects (e.g., nouns, verbs, adverbs, etc.) when studying the use ofnatural language in the formulation of:â€¢Numeric (atomic) predicates,â€¢Temporal operators (phrases),â€¢Speci#c scenarios (e.g., a rising/falling edge).The main outcome of this analysis is that the language featuresused in the studied requirements are unbalanced and sparse andthat it is hard to identify a general recurring pattern. We illustratethis observation with two representative examples:â€¢Example 1: We counted diï¬€erent English utterances to expressthe semantics ofğ‘’>.. The most frequently used collocationis â€œbe aboveâ€, which appears overall four times. Next comesâ€œincrease aboveâ€ (somewhat ambiguous because this may alsorepresent a rising edge), which is used two times. Then â€œbe higherthanâ€, â€œbe larger thanâ€ and â€œbe greater thanâ€ are only used oncerespectively. However, we do not#nd any requirements usingother synonymous expressions like â€œbe more thanâ€ or â€œbe overâ€.â€¢Example 2: We observed that two temporal adverbs are fre-quently used to expressG[0,/u1D461]andH[0,/u1D461], which are â€œfor at leastğ¶u1D461time units (ğ¶u1D46ğ¿,ğ¶u1D45Ağ¶u1D46ğ¿, etc.)â€ (eight times) and â€œfor more thanğ¶u1D461timeunitsâ€ (six times). However, other reasonable possibilities likeâ€œfor the following/pastğ¶u1D461time unitsâ€ are not found.The sparsity and lack of balance may be a consequence of therelative small base of publicly available literature that de#nes thistype of requirements. Despite the fact that the#ndings of thisanalysis may not be su$ciently representative, we can still use theoutcomes to improve our synthetic generation of examples.4.2.2 Language/Q_uality.For the English requirements found in theliterature, of particular interest is the language quality: How accu-rately does a requirement re%ect the semantics of its correspondingSTL formula? Given this criterion, we classify the studied Englishrequirements intoClear,IndirectandAmbiguousrequirements.Clear:These requirements have a straightforward STL formalisa-tion that results in an unambiguous speci#cation without room forinterpretation. An example of a clear requirement is the sentence:613DeepSTL - From English Requirements to Signal Temporal LogicICSE â€™22, May 21â€“29, 2022, Pi/t_tsburgh, PA, USAIf the value of signal control_error is less than10â—¦, then the value ofsignal currentADCSMode shall be equal to NMF[20]. The resultingSTL speci#cation is given by the formula:G(control_error<10â†’currentADCSMode=NMF)Indirect:These requirements need an expert to translate theminto an STL formula that faithfully captures the intended meaning.They typically assume some implicit knowledge that must be addedto the formal speci#cation from the context. An example is thesentence:The vehicle shall stay within the lane boundaries, if this ispossible with the actuators it is equipped with[39]. This is an indirectrequirement formalized using the following STL formula:G(ğ¶u1D7ğ¿F<ğ¶u1D7ğ¿F/u1D45A/u1D44E/u1D465â†’P)HerePis the contextual sub-formula:vehicleâŠ†corridor.Ambiguous:These requirements lack key information that cannotbe easily inferred from the context and that must be extracted fromexternal sources, such as tables,#gures, timing diagrams, or experts.They use vague and ambiguous language, and can have multipleinterpretations. An example is the following sentence:To preventthe destruction of the device by avalanche due to high voltages, thereis a voltage clamp mechanismğ¶u1D44D,/u1D446(./u1D44D)implemented, that limitsnegative output voltage to a certain levelğ¶u1D449/u1D446/ğ¶u1D449,/u1D446(./u1D44D). Please referto Figure 10 and Figure 11 for details[46]. This is an ambiguousrequirement that can be translated to the following STL formulas:G(ğ¶u1D449/u1D442/u1D448/u1D447<ğ¶u1D449/u1D43A/u1D441,âˆ§ğ‘/u1D43F>0â†’ğ¶u1D449/u1D442/u1D448/u1D447=ğ¶u1D449/u1D446/ğ¶u1D449,/u1D446(./u1D44D))G(ğ¶u1D449/u1D442/u1D448/u1D447<ğ¶u1D449/u1D43A/u1D441,â†’ğ¶u1D449/u1D442/u1D448/u1D447=ğ¶u1D449/u1D446/ğ¶u1D449,/u1D446(./u1D44D))The English requirement only vaguely mentions the post-condition.The pre-condition characterizes the drop of voltageğ¶u1D449/u1D442/u1D448/u1D447belowğ¶u1D449/u1D43A/u1D441,when the inductive load is being switched oï¬€. This is ob-tained from the previous context and Figure 11 of [46] with somephysical knowledge that inductive current has to change smoothly.We encountered 46Clear(35.4%), 43Indirect(33.1%), and 41Ambiguous(31.5%) English requirements.5 CORPUS CONSTRUCTIONThis section addresses research questionRQ2. It#rst introducesa new method for the automatic generation of STL sentences andtheir associated natural language requirements. The generatorincorporates the outcomes from Section 4 for improved results.Finally, we use this method to do the actual generation of STL-speci#cation/NL-requirements pairs.5.1 Corpus GenerationIn the following, we propose an automatic procedure for ran-domly generating synthetic examples. Each example consists of:(1) An STL formula, and (2) A set of associated sentences in Englishthat describe this formula. We associate multiple natural-languagesentences to each formal STL requirement to re%ect the fact thatformal speci#cations admit multiple natural language formulations.We illustrate this observation using theBounded responsespeci#ca-tion from Section 3, formalized as the STL formula below:G(V_In>5â†’F[0,10](V_Out<2))This admits multiple synonymous English formulations, including:â€¢Globally, if the value of V_In is greater than 5, then#nally thevalue of V_Out should be smaller than 2 at a time point within10 time units.â€¢It is always the case that when the signal V_In is larger than 5,then eventually at sometime during the following 10 time unitsthe signal V_Out shall be smaller than 2.This example shows that two NL formulations of the same STLformula can be very diï¬€erent, making the generation of syntheticexamples a challenging task. The systematic translation of unre-stricted STL is indeed extremely di$cult, especially for speci#ca-tions that include multiple nesting of temporal operators. In prac-tice, deep nesting of temporal formulas is rarely used because theresulting speci#cations tend to be di$cult to understand.Hence, we#rst restrict STL to a rich but well-structured sub-fragment that facilitates a fully automated translation, while at thesame time covering commonly used speci#cations.5.1.1 Restricted-STL Fragment.In this subsection, we present therestricted fragment of STL that we support in our synthetic examplegenerator. We de#ne this fragment using three layers that can bemapped to the syntax hierarchy identi#ed in Section 4.1.1.The bottom layer, calledsimple-phrase(SP) layer, consists of:(1)Atomic propositions(/u1D736) including rising and falling edgesand (2)Boolean combinationsof up to two atomic propositions.ğ¶u1D6FC:=ğ‘’â—¦â„|Â¬ (ğ‘’â—¦â„)|rise(ğ‘’â—¦â„)|fall(ğ‘’â—¦â„)|Â¬rise(ğ‘’â—¦â„)|Â¬fall(ğ‘’â—¦â„)SP :=ğ¶u1D6FC|ğ¶u1D6FCâˆ§ğ¶u1D6FC|ğ¶u1D6FCâˆ¨ğ¶u1D6FCwhereğ‘’is a signal name,â„is a constant or a mode name, andâ—¦âˆˆ{<,â‰¤,=,â‰¥,>}.The middle layer, which we calltemporal-phrase(TP) layer,admits the speci#cation of temporal formulas over simple phrases:TP :=TP/prime|Â¬TP/prime|riseTP/prime|fallTP/prime|Â¬riseTP/prime|Â¬fallTP/primeTP/prime:=UTO/u1D43C(ğ¶u1D6FC)|(ğ¶u1D6FC)BTO/u1D43C(ğ¶u1D6FC)whereUTOâˆˆ{F,G,O,H}andBTOâˆˆ{U,S}are unary and binarytemporal operators, respectively.ğ‘is an interval of the form[ğ¶u1D4611,ğ¶u1D4612]with 0â‰¤ğ¶u1D4611<ğ¶u1D4612â‰¤(. This can be omitted ifğ¶u1D4611=0 andğ¶u1D4612=(.The top layer, which we call singlenested-temporal-phrase(NTP)layer, allows the formulation of formulas with a single nest-ing of a subset of temporal operators:NTP :=F/u1D43CG/u1D43C(ğ¶u1D6FC)|G/u1D43CF/u1D43C(ğ¶u1D6FC)whereğ‘follows the same de#nition as mentioned above.Finally, with an auxiliary syntactical componentP:=SP|TP,formulağ¶u1D713de#nes thesupported fragmentof STL that we map tothe four template categories discussed in Section 4.1.1.ğ¶u1D713:=G/u1D43C(SP)|F/u1D43C(SP)(ğ‘ğ¶u1D45Bğ¶u1D463ğ‘™ğ¶u1D45Fğœƒğ‘™ğ¶u1D45Bğ¶ğ¶u1D452/ğ¶u1D445ğ¶u1D452ğ‘™ğ¶ğ¶uni21ğ¿Eğ‘™ğ¶u1D44Fğœƒğ¶u1D459ğœƒğ¶u1D461ğ¶u1D466.alt)|G(SPâ†’SP)(ğ‘ğ¶u1D45Ağ¶u1D45Ağ¶u1D452ğ‘§ğœƒğ‘™ğ¶u1D461ğ¶u1D452 ğ¶u1D45Fğ¶u1D452ğ¶u1D46ğ¿,ğ¶u1D45Cğ¶u1D45Bğ¶u1D46ğ¿ğ¶u1D452)|G(Pâ†’TP)(ğ¶u1D447ğ¶u1D452ğ¶u1D45A,ğ¶u1D45Cğ¶u1D45Fğ‘™ğ¶u1D459 ğ¶u1D45Fğ¶u1D452ğ¶u1D46ğ¿,ğ¶u1D45Cğ¶u1D45Bğ¶u1D46ğ¿ğ¶u1D452)|G(Pâ†’NTP)(ğ¶u1D446ğ¶u1D461ğ‘™ğ¶u1D44Fğœƒğ¶u1D459ğœƒğ¶u1D467ğ‘™ğ¶u1D461ğœƒğ¶u1D45Cğ¶u1D45B/ğ¶u1D445ğ¶u1D452ğ¶â„ğ¶u1D45Fğ¶u1D45Fğ¶u1D452ğ¶u1D45Bğ¶ğ¶u1D452)This fragment balances betweengenerality, needed to expresscommon-practice requirements, andsimplicity, needed to facilitatethe automated generation of synthetic examples. It results in thefollowing restrictions: (1) We allow the conjunction and disjunction614ICSE â€™22, May 21â€“29, 2022, Pi/t_tsburgh, PA, USAJie He, Ezio Bartocci, Dejan NiÄkoviÄ‡, Haris Isakovic, and Radu Grosuof only two atomic propositions, (2) Only one atomic propositionis allowed inside a temporal operator inTP, (3) We do not allowBoolean combinations ofSPandTPformulas, and (4) Formulasoutside the four mentioned templates are not supported.By relating the generator-fragmentğ¶u1D713to the empirical statisticsin Section 4.1.1, Figure 2 summarizes for each syntactical category,the proportion of templates that the fragment can support.
010203040
Invariance/Reachability Immediate response Temporal response Stabilization/RecurrenceSupportNot Support (complex grammar) Not Support (other)26 (96.3%)38 (97.4%)1 (3.7%)
14 (42.4%)6 (18.2%)13 (39.4%)
10 (32.3%)15 (48.4%)6 (19.3%)1 (2.6%)
Figure 2: STL Template Support Summary.The generator nearly supports allInvariance/Reachabilitytem-plates appearing in our database. ForImmediate responseones, thereis one template missing due to restriction (1). ForTemporal responsetemplates, we are able to support 42.4% of them. For the not sup-ported ones, 18.2% use a complex grammar that violates restriction(2) and (3), while the remaining ones (39.4%) belong to theothercategory for ad hoc purposes. Concerning nesting formulas, weonly considerStabilization/Recurrencetemplates. Other combina-tions such asFFğ‘£orFğ‘£1Uğ‘£2are not supported: 48.4% of them arein thecomplex grammargroup, while the left 19.3% are in theothercategory.5.1.2 Random-Sampling STL Formulas.This short subsection brie%ydescribes how we sample STL speci#cations from the restrictedfragment. The main idea is to decorate the grammar rules withprobabilities according to the template distribution collected inSection 4.1 and the operator distribution shown in Figure 1.Consequently, we use the probabilities described in Section 4.1to generate the four categories of fragmentğ¶u1D713, which will naturallymake theGoperator rank#rst to a large extent, followed by theFoperator, regarding to usage frequency. The frequencies of theother operators within these categories are as discussed above.5.1.3 Translating STL into English.The main translation strategylinked to 4.2 is as follows. For the predicates used to express logicalrelations in the bottom layer, we use (with some reservations mainlywith regards to accuracy) the frequencies of Section 4.2.1. This way,the translation candidates are selected with diï¬€erent weights. Forthe others, such as the adverbs specifying temporal information,we incorporated relevant English utterances encountered in ourdatabase, on the condition that the generation and recognition canbe done with both accuracy and%uency. Furthermore, we reservedenough space to add synonymous utterances that can be typicallyused but that are not included in the database.In order to systematically organize the translation and maximizelanguage%exibility, we start with the translation of atomic propo-sitions (de#ned asğ¶u1D6FCin 5.1.1) in the bottom syntactical layer, anduse this as a pivot to tackle temporal phrases and their nestingscenarios in the middle and top layers.Bottom layer.The English counterparts of atomic propositionstypically consist of a subject, a predicate, and an object. They areindispensable in each English sentence. Hence, their variationsespecially in the predicate (including the choice of verbs, formats,tenses, and their active/passive voice) are considered#rst. Thework%ow for the organisation of their translations, which is dividedinto aHandlerand aTranslator, is illustrated in Figure 3.TypePositionGenerationInformation InstructionAdverbialInformationPredicateCommands
Generation
Information 
Instruction
Adverbial
Information
Predicate
Commands
HandlerRandomly selectedTranslationsAssemblerTemplateRefinerRandomizedSamplerRefined TemplateTranslationList
Assembler
Template
Refiner
Randomized
Sampler
Refined
Template
Translation
T
T
ListTranslatorFigure 3: Translation Procedure for Atomic Propositions.The Handler, as a preprocessor, takes theTypeandPositioninfor-mation as inputs.Typeis a branch ofğ¶u1D6FCused to compute and outputtheGeneration Information. This includes anindex(it triggers acorresponding translation strategy),identi/f_iers,numbers, and theSTL expressionof a randomly generated atomic proposition.Positionspeci#es the location of the proposition. This determineswhether the translation states a certain scenario - if it is a condition(before implication symbol â€œâ†’â€), or if it emphasizes that a propertyhas to hold with a satis#ed condition (after â€œâ†’â€). In the latter case,modal verbs like â€œshouldâ€ orâ€œmustâ€ will be used, and often togetherwith adverbial modi#ers like â€œinstantlyâ€ or â€œwithout any delayâ€ incase ofImmediate responseformulas. This information is embeddedintoPredicate Commands, incorporating the choice of verbs, theirformat, and the use of modal verbs and of adverbial modi#ers.Generation InformationandPredicate Commandsare sent to theTemplate Re/f_iner(inside Translator), whose architecture is shownin Figure 4. Here, the subject and object placeholders within thetemplates can be replaced by randomly generated identi#ers andnumbers. The verbs associated to predicates are changed to theirproper format, and are decorated with adverbs when applicable.
GenerationInformation PredicateCommandsRaw TemplateSubject & ObjectExtractor
S
ubject
& 
Object
ExtractorPredicateRefiner
Predicate
RefinerRefined SubjectRefined ObjectRefined PredicateRefined TemplateTemplate Refiner
Figure 4: Template Re/f_iner.In the next step, theAssemblermodule of the Translator com-pletes the re#ned templates into a complete sentence that also615DeepSTL - From English Requirements to Signal Temporal LogicICSE â€™22, May 21â€“29, 2022, Pi/t_tsburgh, PA, USAincludes adverbial modi#ers. Finally, theRandomized Samplermod-ule of the Translator, samples a designated number of sentencesfrom the overall translation list.Middle/Top layer.The translation approach presented above isextended to temporal phrases in a straight-forward manner, becausethe sentences generated by the bottom layer, can be reused exceptfor the need to add adverbial modi#ers, and enrich the verb tensesaccording to the temporal operators.
FIË³ x  (temporal operator)z (tense)
SDVWSUHVHQWIXWXUHtier 1: TPà²¬
y (variant) (S, Â¬ fall (TPà²¬), future)
TPà²¬rise (TPà²¬)Â¬TPà²¬$%
Translation beforeimplication 
&'()
GIË³ OIË³ HIË³ Ë³1UIË³2Ë³1SIË³2fall (TPà²¬)Â¬ rise (TPà²¬)Â¬ fall (TPà²¬)tier 2: Â¬TPà²¬tier 3: rise (TPà²¬)tier 4: fall (TPà²¬)tier 5: Â¬ rise (TPà²¬)tier 6: Â¬ fall (TPà²¬)Translation afterimplication (F, TPà²¬, future)
(F, TPà²¬, present)Figure 5: Translation of Temporal Phrases.The temporal aspects nevertheless do increase the translationcomplexity. We need to consider three orthogonal aspects (dimen-sions) as shown in Figure 5. Theğ‘’-axis represents the six STLtemporal operators from theTPlayer, theğ¶u1D466.alt-axis their variantspreceded by the negation, rising or falling edge operators, and theğ¶u1D467-axis the choice of a verb tense in English for speci#c temporal op-erators. Hence, a node in Figure 5 represents a speci#c combinationof these three aspects.We adopt a slicing approach to tackle the complexity. We#rstprocess nodes A-F with present tense, where the six temporal oper-ators are used individually. Then we enrich the usage of verb tensesaccording to the semantics of a particular operator and its nestingsituation. This results in tierTP/primewhile preserving language%exi-bility. The same approach is used for processing unary operatorsin tierÂ¬TP/prime. The semantics of direct negation of binary operators,rising/falling edges and their negations for layerTPare compli-cated. Considering their relatively low usage frequency, we provideseveral#xed templates to facilitate their translations.5.2 Corpus StatisticsFollowing the approach described in Section 5.1, we have au-tomatically generated a corpus consisting of 120,000 STL-Englishpairs where each pair consists of a randomly generated STL formulaand one of its generated translation in natural language.5.2.1 STL-Formula Statistics.In Figure 6 we provide the frequen-cies of the STL operators in our synthetic dataset (above corpus).As one can see they are largely consistent with the ones in Figure 1.As before, the most frequent STL operator is the global temporaloperatorG/u1D43Cğ‘£with 138,715 occurrences. The least frequent STLoperator is theğ‘£1S/u1D43Cğ‘£2temporal operator with 5,105 occurrences.While this frequency diï¬€ers a bit from Figure 1, it is still consistentwith the empirical results.
/u1D465=/u1D462/u1D465>/u1D462/u1D465â‰¥/u1D462/u1D465</u1D462/u1D465â‰¤/u1D462rise(/u1D711)fall(/u1D711)F/u1D43C/u1D711G/u1D43C/u1D711/u1D7111U/u1D43C/u1D7112O/u1D43C/u1D711H/u1D43C/u1D711/u1D7111S/u1D43C/u1D7112Â¬/u1D711/u1D7111âˆ§/u1D7112/u1D7111âˆ¨/u1D7112/u1D7111â†’/u1D711225K50K75K100K125K
Figure 6: Frequency of STL operators in the corpus.Table 1 shows the statistics of templates and subformulas in thegenerated corpus. As mentioned in Section 4.1, an STL template isde#ned as the parse tree of a formula without its leaves. For exam-ple, the template for the formulağ‘£=G(In>5â†’F[0,10]Out<2)isG(ğ‘£1â†’F[0,10]ğ‘£2). Each formula has a#nite number of sub-formulas. For example the formulağ‘£above has#ve subformulas:ğ‘£5=G(In>5â†’F[0,10]Out<2),ğ‘£4=In>5â†’F[0,10]Out<2,ğ‘£3=F[0,10]Out<2,ğ‘£2=Out<2, andğ‘£1=In>5.Table 1: STL Formula Statistics: # unique STL formulas, #unique STL templates, # subformulas for each formula.# formulas# templates# subformula per formulaminmaxavg.median120,0005,8522186.987Table 2 shows the mutual mapping relation between STL op-erators and STL formulas in our corpus. We count for each STLoperator, how many formulas it has appeared in. This produces thecontainment statistics shown in the last three columns.Table 2: STL-Formula Mapping Statistics: # STL operators foreach formula, # STL formulas for each operator.# STL oper. per formula# formulas per STL oper.avg.medianmaxavg.medianmax6.9871842,120.345,125101,870Since identi#ers and constants frequently appear in our corpus,we also analyzed their frequency, as shown in Table 3.5.2.2 Natural-Language Statistics.The statistical results of the nat-ural language in our corpus are shown in Table 4. There are only265 diï¬€erent eï¬€ective English words (considering word variants,not including signal names which are strings generated randomly),616ICSE â€™22, May 21â€“29, 2022, Pi/t_tsburgh, PA, USAJie He, Ezio Bartocci, Dejan NiÄkoviÄ‡, Haris Isakovic, and Radu GrosuTable 3: Identi/f_ier and Constants Statistics: average numberof identi/f_iers per formula, # of chars used per identi/f_ier, #number of digits used per constant.# identi#ersper formula# chars per identi#er# digits per constantminavg.medianminavg.median2.5915.50512.312constituting a relatively small vocabulary. This is understandablebecause most English words are used to express the logical relationin STL, the number of which is thus limited. Besides, Table 4 recordsthe statistics of eï¬€ective word numbers in all English sentences. Italso counts for each English word, the number of English sentencesusing it.Table 4: English Statistics: # unique sentences, # uniquewords, # words per sentences and # sentences per word.# sent.# word# words per sent.# sent. per wordavg.medianavg.median120,00026538.493714,220.284,555.56 MACHINE TRANSLATIONIn order to answer questionsRQ3-5, we take advantage of thecorpus generated as discussed in the previous sections, to developDeepSTL, a tool and technique for the translation of informal re-quirements given as free English sentences, into STL. DeepSTLemploys a state-of-the-art transformer-based neural-translationtechnique, to train an accurate attentional translator. We comparethe performance of DeepSTL with other NL translator architectureson the same corpus, and we also investigate how they are able toextrapolate to sentences out of the corpus.6.1 Neural Translation AlgorithmsThe translation of natural language into STL formulas can beabstracted as the following probabilistic problem. Given an encod-ing sequencee=(ğ¶u1D4521,ğ¶u1D4522,. . . ,ğ¶u1D452/u1D45A)from the source language (Englishrequirements), a decoding sequences=(ğ¶u1D46ğ¿1,ğ¶u1D46ğ¿2,. . . ,ğ¶u1D46ğ¿/u1D45B)from thetarget language (STL formulas) generates all of its tokensğ¶u1D46ğ¿/u1D458con-ditioning on the decoded history of the target sequenceğ¶u1D46ğ¿</u1D458andthe whole input of the source sequenceesuch that:ğ¶u1D443(s|e;ğ¶u1D7ğ¿3)=/producttext.1/u1D45B/u1D458=1ğ¶u1D443(ğ¶u1D46ğ¿/u1D458|ğ¶u1D46ğ¿</u1D458,e;ğ¶u1D7ğ¿3)whereğ¶u1D7ğ¿3are the parameters of the model. Acurrent practice in the community of NLP is to learn these prob-abilities through Neural Translation (NT) where the tokens areencoded into real vectors.6.1.1 NT-Architectures considered.We considered three main NT-architectures: sequence to sequence (seq2seq), sequence to sequenceplus attention (Att-seq2seq), and the transformer architecture.Seq2seq architecture.Seq2seq uses two recurrent neural networks(RNNs), one in the encoder, and one in the decoder, to sequentiallyprocess the sentences, word by word [47].Att-seq2seq architectureA drawback of the seq2seq architecture,is that it gradually encodes the dependencies among words in theinput and output sentences, by sequentially passing the informationto the next cell of the RNN. As a consequence, far-away dependen-cies may get diluted. In order to correct this problem, an attentionmechanism is introduced in att-seq2seq, to explicitly capture andlearn these dependencies [48].Transformer-architectureThe previous two architectures are rel-atively slow to train, because the RNNs hinder parallel processing.To alleviate this problem, the transformer architecture, introducesa self-attention mechanism, dropping completely the use of RNNs.This dramatically speeded up thecomputation time of attention-based neural networks, and conferred a considerable momentumto NT [37]. For this reason we adopted a transformer-based archi-tecture for our DeepSTL translator.6.1.2 Preprocessing and Tokenization.There are three main fea-tures that distinguish our translation problem from general transla-tion tasks between natural languages (NL2NL):(1)Out of Vocabulary (OOV): The signal names, we call themidenti#ers for short, and numbers, can be arbitrarily speci#ed.Therefore, it is impossible to maintain a#xed-size vocabularyto cover all imaginable identi#ers and numbers.(2)High Copying Frequency:During translation, identi#ers andnumbers need to be much more frequently copied from thesource language to the target language than in NL2NL.(3)Unbalanced Language:English is a kind of high-resource lan-guage while STL formulas belong to a low-resource logicallanguage that has very limited exclusive vocabulary.In view of the above characteristics, a successful translation ofEnglish to STL requires more than in NL2NL, a correct tokenizationof identi#ers and numbers. Although one can use an explicit copy-ing mechanism [49], this method requires to modify the structureof the neural network, which may increase complexity.Subword tokenizationWe therefore adopt a subword techniqueto tokenize sequences during data preprocessing. Subword algo-rithms, such as Byte-Pair-Encoding (BPE) [50], WordPiece [51] andUnigram [52], are commonly used in state-of-art NT systems totackle the OOV problem. Without modifying the model structure,these algorithms are able to split words into meaningful morphemesand even independent characters based on statistical rules.Ideally, we hope when identi#ers and numbers are tokenized,they can be respectively encoded by separate characters and digits.For example,PWMand12.5are expected to get encoded as[â€˜Pâ€™,â€˜Wâ€™, â€˜Mâ€™]and[â€˜1â€™, â€˜2â€™, â€˜.â€™, â€˜5â€™]respectively. This way, wecan use a limited number of characters and digits to represent arbi-trary identi#ers and numbers. We chose BPE due to its simplicity.The tokenization procedure of BPE is executed as follows: (1) Splitevery word (separated by a space) in the source data to a sequenceof characters. (2) A prepared token list will include all possiblecharacters (without repetition) in the source data. (3) The most fre-quently occurring pair of characters inside a word are merged andadded to the token list, then this pair will be treated as an indepen-dent character afterwards. (4) Step 3 is repeated until the size of thetoken list reaches to an upper limit or a speci#ed hyperparameter.After tokenization, when a sequence is encoded, the generated listis iterated from the longest token to the shortest token attemptingto match and substitute substrings for each word in the sequence.Inspired by BPE algorithm, before tokenization, identi#ers andconstants have to be split into characters and digits in advance,so that for each pair of two adjacent characters and digits, there617DeepSTL - From English Requirements to Signal Temporal LogicICSE â€™22, May 21â€“29, 2022, Pi/t_tsburgh, PA, USAwould be a whitespace between them (e.g.,PWM->PWM,12.5->12.5). In this way, characters and digits will not participate inthe merging procedure of BPE. Hence, during the encoding phase,only characters and digits in the generated token list can matchidenti#ers and constants after they are recognized and split.During testing time, although it is easy to use regular expres-sions to match numbers and split them into digits, it is challengingto accurately match identi#ers. This is because identi#ers can benon-meaningful permutations of characters, or complete Englishwords. These two scenarios cannot be easily distinguished. An idealmethod is to adopt Name Entity Recognition (NER) to match iden-ti#ers and split them. Now identi#ers are automatically identi#ed,by checking that they do not belong to our data-set of commonlyused English words, or the English formulation of STL operators.6.2 Implementation Details6.2.1 Data split.We overall generated 120000 English-STL pairs,from which we#rst sampled 10% (12000) to prepare a#xed testingset. For the rest, before each training experiment, we sampled 90%(97200) of them for training, and 10% (10800) for validation.6.2.2 Hyperparameters.The implementation of the three modelsmentioned in 6.1.1 are mainly based on [53] with several modi#ca-tions using Pytorch. The following describes how hyperparametersare chosen for each model and the optimizer.Seq2seqWe used Gated Recurrent Unit (GRU) [54] as RNN units.The encoder is a 2-layer bidirectional RNN with hidden sizeğ¶uni21ğ¿E=128for each direction, and the decoder is a 2-layer unidirectional RNNwithğ¶uni21ğ¿E=256. The embedding dimension for mapping a one-hotvector of a token into real valued space is 128. Drop out rate is 0.1.Att-seq2seqFor the encoder-decoder, we used the same hyper-parameters as Seq2seq-architecture. For Bahdanau attention [48],we used a feed-forward neural network with 1 hidden layer and128 neurons to calculate attention score.TransformerFor the encoder and the decoder, they both have4 layers with 8 attention heads; Input and output dimensions foreach computing block are always kept asğ‘§model=128; Neuronnumber in feed-forward layers equals toğ‘§/u1D453/u1D453=512; Drop out rateis 0.1; For layer normalization,ğ¶u1D716=10/5.OptimizerWe used Adam Optimization algorithm [55] withğ¶u1D6FD1=0.9,ğ¶u1D6FD1=0.98,ğ¶u1D716=10/9, while the learning rateğ¶u1D459ğ¶u1D45Fis dynamicallyscheduled as (slightly changed from [37]):ğ¶u1D459ğ¶u1D45F=,Â·ğ‘§/0.5modelÂ·min(ğ¶u1D46ğ¿ğ¶u1D461ğ¶u1D452,_ğ¶u1D45Bâ„ğ¶u1D45A/0.5,ğ¶u1D46ğ¿ğ¶u1D461ğ¶u1D452,_ğ¶u1D45Bâ„ğ¶u1D45AÂ·ğ‘œğ‘™ğ¶u1D45Fğ¶u1D45Aâ„,/1.5/u1D460/u1D461/u1D452/u1D45D/u1D460)whereğ‘œğ‘™ğ¶u1D45Fğ¶u1D45Aâ„,/u1D460/u1D461/u1D452/u1D45D/u1D460=4000,ğ‘§model=128.ğ¶u1D46ğ¿ğ¶u1D461ğ¶u1D452,_ğ¶u1D45Bâ„ğ¶u1D45Arepresents thetraining steps (training on one batch corresponds to one step).,isan adjustable parameter for each architecture, and we chose 1, 0.1and 2 for Seq2seq, Att-seq2seq and Transformer respectively. ForSeq2seq and Att-seq2seq models, in order to ease gradient explosiondue to long sequence dependency, we also used gradient clippingto limit the maximum norm of gradients to 1.OtherWe dealt with variable length of input and output sequenceusing padding. We#rstly encoded all English and STL sequencesinto subword token lists, from which we picked the maximumlength as the step limit both for the encoder and the decoder. Duringtraining, for sequence whose length is smaller than the maximumvalue, we padded a special token<pad>to its end for complement.6.2.3 Train/Validate/Test Procedure.For training and validation,we used â€œteacher forcingâ€ strategy in the decoder. We#rstly pre-pared two special tokens<bos>(begin of sentence) and<eos>(end of sentence). Suppose the reference output of the decoderisABC<eos>. To start with, we input<bos>as a starting signal tothe decoder and hoped that it could outputA. No matter whetherthe actual#rst output of the decoder isA, we then sentAto the de-coder, and hoped that it would outputB. This procedure continuesuntil the maximum step length of the decoder is reached.We summed up all token-level (only for valid length) cross-entropy loss between the prediction and reference sequence, anddivided it by the maximum length of the decoder. This is the lossfor one sample. We trained a batch of 64 samples in parallel. Thebatch loss is averaged over all sample losses inside a single batch,which is used for back propagation to update network parameters.For testing, â€œteacher forcingâ€ is abandoned. The only token man-ually input to the decoder is<bos>for initialization. At each timestep of decoding, the decoder adopts a greedy search strategy, out-putting a token with maximum probability only based on its outputin the previous step and the output of the encoder. The decodingprocedure will end until the decoder outputs an<eos>token or themaximum limit length is reached.6.3 Results6.3.1 Loss/Accuracy Curves.We trained Seq2seq, Att-seq2seq andTransformer architectures for 80, 10 and 40 epochs respectively,usingSTL formula accuracy(de#ned in 6.3.2) in validation as anindicator to stop training. The validation loss/accuracy curves areobtained by 5 independent experiments and shown as follows.
Figure 7: Validation Loss.
Figure 8: Validation Formula Accuracy.618ICSE â€™22, May 21â€“29, 2022, Pi/t_tsburgh, PA, USAJie He, Ezio Bartocci, Dejan NiÄkoviÄ‡, Haris Isakovic, and Radu GrosuFigure 7 and Figure 8 show that, with the guidance of â€œteacherforcingâ€, all the three models are able to converge during training,making the STL formula accuracy approach to 1 when the networkbecomes stabilized. The only diï¬€erence is the rate of convergence,which depends on many factors like the volume of the model (e.g.,number of parameters), noises, learning rate, etc.6.3.2 Testing Metrics.We#rstly report two diï¬€erent measures ofaccuracy: theSTL formula accuracy(ğ¶u1D434/u1D439) and thetemplate accuracy(ğ¶u1D434/u1D447). The#rst measures the alignment accuracy for the referenceand prediction sequence in a string level, while the second#rstlytransforms the reference and predication instances into STL tem-plates and then calculates their alignment accuracy. For example,Formula:always(x>0)â‡’Template:always ( phi )Formula:always(y>0)â‡’Template:always ( phi )The#rst line is reference sequence and the second line representsmodel prediction. For better illustration, we insert a white-spacebetween each token and thus there are six tokens in the formulas,and four tokens in the templates. For formulas, overall#ve tokensappear in the same position -â€˜alwaysâ€™, â€˜(â€™, â€˜>â€™, â€˜0â€™, â€˜)â€™,while the left one tokenâ€˜xâ€™in the reference is mistranslated toâ€˜yâ€™. Therefore, the formula accuracyğ¶u1D434/u1D439=5/6. As for the template,since all tokens are aligned with each other, the template accuracyğ¶u1D434/u1D447=1.We also report another metric called BLEU (Bilingual Evalua-tion Understudy) [56] that has been pervasively used in machinetranslation research. It evaluates the number of n-grams (ğ¶u1D45B=4)appearing in the reference sequence. The best BLEU score for a pairof sequences is 1, which means complete overlapping.Table 5: Testing Accuracy.Formula Acc.Template Acc.BLEUSeq2seq0.071Â±0.03880.207Â±0.08680.092Â±0.0361Att-seq2seq0.977Â±0.00600.980Â±0.00630.996Â±0.0011Transformer0.987Â±0.00280.995Â±0.00140.998Â±0.0005In Table 5, it can be seen that once â€œteacher forcingâ€ is removed,the performance of Seq2seq architecture decreases dramatically,which is partly due to its lack of attention mechanism to realize self-correction. For the other two models, both of them can achieve veryhigh accuracy, with Transformer slightly better than Att-seq2seq.Since the testing data and training data are sampled from the samedata-set, in this sense, these two models show high translationquality when the distribution of language patterns in testing casesare similar to the training data. We also#nd that the templateaccuracy is higher than the formula accuracy. This phenomenon isunderstandable - once one formula is transformed into the form oftemplate, the potential translation errors in identi#ers, constantsand logical relation symbols are masked.6.3.3 Extrapolation.In the following, we use the informal require-ments that we identi#ed from the literature in Section 4 to evaluatehow well the machine learning algorithm generalizes the transla-tion outside of the training and validation data set.In order to have a fair evaluation, we used the 14Clearrequire-ments (10% of the entire set) with the template structure supportedby our tool. We pre-processed the requirements to remove unitsthat are not supported by our tool. Table 6 summarizes the accu-racy results for the three learning approaches. We see that withnon-synthetic examples the formula accuracy drops considerablyfor all algorithms, while the average template accuracy remainsrelatively high (89.9%) for the Transformer approach. We believethat higher availability of publicly available informal requirementsthat could be used for training would considerably help improvingthe accuracy of the approach.Table 6: Extrapolation Accuracy.Formula Acc.Template Acc.BLEUSeq2seq0.050Â±0.02830.158Â±0.08950.027Â±0.0120Att-seq2seq0.559Â±0.08650.742Â±0.06600.888Â±0.0348Transformer0.712Â±0.06780.899Â±0.01000.962Â±0.0030In the following, we provide three examples2that illustrate thepossibilities and the limits of our approach (random seed=100).We also report the following metric that considers the averagelogarithmic value of the output con#dence at each decoding step:ğ¶u1D436/u1D45A=1/u1D43F/u1D6FC/summationtext.1/u1D43F/u1D458=1logğ¶u1D443(ğ¶u1D46ğ¿/u1D458|ğ¶u1D46ğ¿</u1D458,e;ğ¶u1D7ğ¿3)whereğ¶u1D43Fis the length of the out-put sequence,ğ¶u1D6FCis an adjustable factor which is set to 0.75 by de-fault, andğ¶u1D45Aâˆˆ{ğ¶u1D46ğ¿,ğ‘™,ğ¶u1D461}withğ¶u1D46ğ¿,ğ‘™,ğ¶u1D461denoting Seq2seq, Att-seq2seqand Transformer model respectively.Example 1:If the value of signal RWs_angular_momentum isgreater than 0.35, then the value of signal RWs_torque shall beequal to 0. [20]â€¢Transformer (ğ¶u1D436/u1D461=/0.01393):always ( RWs_angular_momentum > 0.35 -> RWs_torque == 0 )â€¢Att-seq2seq (ğ¶u1D436/u1D44E=/0.30038):always ( RWs_angular_mxyomemeEqm < 0.3-> RWs_torque==0)â€¢Seq2seq (ğ¶u1D436/u1D460=/2.77145):always (WNcAi1iDSDDyD1yD2y171a71aa2345324621 ) 5......too long, display omittedExample 2:Whenever Op_Cmd changes to Passive then in re-sponse Spd_Act changes to 0 after at most 500 time units.â€¢Transformer (ğ¶u1D436/u1D461=/0.00091):always ( rise ( Op_Cmd == Passive ) -> eventually [ 0 : 500 ] (rise( Spd_Act == 0 ) ) )â€¢Att-seq2seq (ğ¶u1D436/u1D44E=/0.10360):always ( rise ( Op_Cmd == Passive ) ->not( eventually [ 0 : 500] ( Spd_Act == 0 ) ) )â€¢Seq2seq (ğ¶u1D436/u1D460=/3.03260):always ( rise (PIweD > 12.3 Q8y5yDy6y1y1R11y1y1g1y1A......too long, display omittedExample 3:Whenever V_Mot enters the range [1, 12] then inresponse starting after at most 100 time units Spd_Act must be inthe range [100, 1000].â€¢Transformer (ğ¶u1D436/u1D461=/0.00873):always ( rise ( V_Mot >= 1 and V_Mot <= 12 ) -> eventually [ 0 :100 ] ( Spd_Act >= 100 and Spd_Act <= 1000 ) )â€¢Att-seq2seq (ğ¶u1D436/u1D44E=/0.06080):always ( rise ( V_Mot >= 1 and V_Mot <= 12 ) ->not( eventually[ 0 : 100 ] ( Spd_Act >= 100 and Spd_Act <= 1000 ) ) )2These examples are the actual outputs of the translator. They are not displayed in amathematical way. The part that is incorrectly translated is represented in blue color.619DeepSTL - From English Requirements to Signal Temporal LogicICSE â€™22, May 21â€“29, 2022, Pi/t_tsburgh, PA, USAâ€¢Seq2seq (ğ¶u1D436/u1D460=/2.68981):always ( rise (p_qHX > 4 Q3DaQaDamymaOlQ ) ya ) 4 fall......too long, display omittedThe extrapolation test shows the poor translation of Seq2seqthat is consistent with its low accuracy measured in Table 5. Thetranslation quality of Transformer and Att-seq2seq is much higher.It is however sensitive to how similar the patterns used in theinformal requirement are to the ones used in the training data.In Example 1, Transformer makes the correct translation, whileAtt-seq2seq fails to copy the identi#er and the number, and â€œgreaterthanâ€ is mistranslated into â€œ<â€. In Example 2, Transformer tendsto add ariseoperator before the subformula wrapped inside anFoperator, although in some occasions this is equivalent to the actualintention of the requirement because â€œchanges toâ€ often indicatesthe signi#cance of a rising edge. On the other side, Att-seq2seqadds a negation operatorÂ¬in front of the subformula startingwith anFoperator, so the meaning becomes reversed. In Example 3,Transformer translates the requirement correctly while Att-seq2seqmakes the same mistake. For the three examples considered, theSeq2seq model fails to translate all of them, without even guessingcorrectly the template: it tends to generate lengthy symbols withoutexplicit meaning.7 DISCUSSIONCorpus GeneratorOne of the major limitations is that the natu-ral language is still generated through a rule-based approach withhuman intervention. Although for commonly-used STL formulas,the corpus generator can already produce enormous%uent syn-onymous translations, the diversity in expression is still limited.However, it is this â€œcold-startâ€ approach that makes it possible inthe future to adopt automatic data augmentation techniques [57]in NLP to produce much more English utterances exponentially.These new variants may involve diï¬€erent linguistic features, suchas ambiguity and vagueness.Furthermore, the English requirements produced from the cor-pus generator are generic texts strictly following the semantics ofSTL without incorporating terminology and domain knowledgeof a particular#eld, e.g., electronics, robotics, and biology. Howto cover, characterize and process this information with modulardesign patterns is a future research direction.Neural TranslatorAn important improvement would be to unifythe pipeline in data preprocessing: we need to combine Name En-tity Recognition (NER) [58,59] technique with the look-up tablemethod to recognize arbitrarily designated identi#ers, or those thatare already given in signal tables from industrial data sheets.Besides, translation accuracy and decoding con#dence should befurther exploited for training because they are indicators of transla-tion performance. In fact, the template accuracy mentioned in 6.3.2is biased by design in that it penalizes positional mismatches (withcumulative eï¬€ect) more strongly than individual token mismatch-ing errors. Hence, an unbiased criterion for quantifying templateaccuracy needs to be considered. For translation con#dence, a highlevel is not necessarily indicating that the decoder will always insiston the correct translation - sometimes it implies that the decodermay be stubborn to the wrong output (Example 2 of Transformerin 6.3.3). However, for lower con#dence values, they tend to indi-cate insu$cient training of a particular feature due to unbalancedtraining samples. Given the rich information conveyed, these twometrics can be promisingly used as feedback signals to guide the op-timization of the loss function so that diï¬€erent problems occurringin training can be detected and corrected.Furthermore, due to the attention mechanism, Att-seq2seq isstill a strong competitor to Transformer, despite being inferior incertain test metrics and cases. Although it is interesting to improvetranslation quality from multiple Transformer-based pre-trainingtechniques [60] with large models, it is also important to#gure outwhat role attention mechanism exactly plays in translation: unlikethe English in daily communications or in literature, the contextsused to specify formal languages like STL are relatively limited.Thus, an English-STL translator that only depends from statisticalinformation learned from a data set (as generally it occurs in NL2NLtranslators) may be not ideal.However, the approach presented here still depends on learn-ing the statistical features of the training data rather than reallyunderstanding the requirement language. This is the reason forthe mistranslation of â€œgreater thanâ€ into â€œ<â€ in Example 1 of Att-seq2seq. Given this, in 6.3.3 it is reasonable to see the drop inaccuracy when testing cases are very diï¬€erent from what havebeen trained. To build DeepSTL with enhanced trustworthiness,the integration of syntactic and semantic information into the end-to-end learning process using attention mechanism will be a topicof further investigation.Finally, from a user interaction point of view, the next generationof DeepSTL should output multiple possible translations for the userto choose from, thus remembering the userâ€™s language preferencesin order to provide customized service.8 CONCLUSIONWe studied the problem of translating CPS natural languagerequirements to STL, commonly used to formally specify CPS prop-erties by the academic community and practitioners. To addressthe lack of publicly available natural language requirements, wedeveloped a procedure for automatically generating English sen-tences from STL formulas. We employed a transformer-based NLParchitecture to e$ciently train an accurate translator from Englishto STL. Experiments demonstrated promising results.While this work focuses on STL speci#cations and CPS applica-tions, the underlying principles can be applied to other domainsand speci#cation formalisms and have a signi#cant positive impacton the#eld of requirement engineering. Unlike natural languages,formal speci#cations have a very constrained structure. We believethat this observation can be further explored in the future to de-velop an even more robust translation mechanism and thus furtherstrengthen requirements engineering methodologies.ACKNOWLEDGMENTSThis project has received funding from the European Unionâ€™sHorizon 2020 research and innovation programme under grantagreement No 956123, and funding from the Austrian FFG ICT ofthe Future program under grant agreement No 880811.620ICSE â€™22, May 21â€“29, 2022, Pi/t_tsburgh, PA, USAJie He, Ezio Bartocci, Dejan NiÄkoviÄ‡, Haris Isakovic, and Radu GrosuREFERENCES[1]Ezio Bartocci, Jyotirmoy Deshmukh, Alexandre DonzÃ©, Georgios Fainekos, OdedMaler, Dejan NiÄkoviÄ‡, and Sriram Sankaranarayanan. Speci#cation-based moni-toring of cyber-physical systems: a survey on theory, tools and applications. InLectures on Runtime Veri/f_ication, pages 135â€“175. Springer, 2018.[2]Oded Maler and Dejan NiÄkoviÄ‡. Monitoring properties of analog and mixed-signal circuits.International Journal on Software Tools for Technology Transfer,15(3):247â€“268, 2013.[3]Rani Nelken and Nissim Francez. Automatic translation of natural languagesystem speci#cations. InProc. of CAVâ€™96: the 8th International Conference onComputer Aided Veri/f_ication, volume 1102 ofLNCS, pages 360â€“371. Springer,1996.[4]Matthew B. Dwyer, George S. Avrunin, and James C. Corbett. Patterns in propertyspeci#cations for#nite-state veri#cation. InProc. of ICSEâ€™ 99: the 1999 InternationalConference on Software Engineering, pages 411â€“420. ACM, 1999.[5]Aarne Ranta. Translating between language and logic: What is easy and whatis di$cult. InProc. of CADE-23: the 23rd International Conference on AutomatedDeduction, volume 6803 ofLNCS, pages 5â€“25. Springer, 2011.[6]Hadas Kress-Gazit, Georgios E. Fainekos, and George J. Pappas. Translatingstructured english to robot controllers.Adv. Robotics, 22(12):1343â€“1359, 2008.[7]Rongjie Yan, Chih-Hong Cheng, and Yesheng Chai. Formal consistency checkingover speci#cations in natural languages. InProc. of DATE 2015: the 2015 Design,Automation & Test in Europe, pages 1677â€“1682. ACM, 2015.[8]Marco Autili, Lars Grunske, Markus Lumpe, Patrizio Pelliccione, and AntonyTang. Aligning qualitative, real-time, and probabilistic property speci#cationpatterns using a structured english grammar.IEEE Trans. Software Eng., 41(7):620â€“638, 2015.[9]Andrea Brunello, Angelo Montanari, and Mark Reynolds. Synthesis of LTLformulas from natural language texts: State of the art and research directions. InProc. of TIME 2019: the 26th International Symposium on Temporal Representationand Reasoning, volume 147 ofLIPIcs, pages 17:1â€“17:19. Schloss Dagstuhl - Leibniz-Zentrum fÃ¼r Informatik, 2019.[10]Allen P. Nikora and Galen Balcom. Automated identi#cation of LTL patternsin natural language requirements. InProc. of ISSRE 2009: the 20th InternationalSymposium on Software Reliability Engineering, pages 185â€“194, 2009.[11]Constantine Lignos, Vasumathi Raman, Cameron Finucane, Mitchell P. Marcus,and Hadas Kress-Gazit. Provably correct reactive control from natural language.Auton. Robots, 38(1):89â€“105, 2015.[12]Rongjie Yan, Chih-Hong Cheng, and Yesheng Chai. Formal consistency checkingover speci#cations in natural languages. InProc. of 2015 Design, Automation Testin Europe Conference Exhibition (DATE), pages 1677â€“1682. IEEE, 2015.[13]Shalini Ghosh, Daniel Elenius, Wenchao Li, Patrick Lincoln, Natarajan Shankar,and Wilfried Steiner. ARSENAL: automatic requirements speci#cation extractionfrom natural language. InProc. of NFM 2016: the 8th International Symposium onNASA Formal Methods, volume 9690 ofLNCS, pages 41â€“46. Springer, 2016.[14]Alessandro Fantechi, Stefania Gnesi, Gioia Ristori, Michele Carenini, MassimoVanocchi, and Paolo Moreschini. Assisting requirement formalization by meansof natural language translation.Formal Methods Syst. Des., 4(3):243â€“263, 1994.[15]Juraj Dzifcak, Matthias Scheutz, Chitta Baral, and Paul Schermerhorn. Whatto do and how to do it: Translating natural language directives into temporaland dynamic logic representation for goal management and action execution. InProc. of ICRA 2009: the IEEE International Conference on Robotics and Automation,pages 4163â€“4168, 2009.[16]Christopher B. Harris and Ian G. Harris. Generating formal hardware veri#cationproperties from natural language documentation. InProceedings of the 2015IEEE 9th International Conference on Semantic Computing (IEEE ICSC 2015), pages49â€“56, 2015.[17]Sascha Konrad and Betty H. C. Cheng. Real-time speci#cation patterns. InProc.of ICSE: the 27th International Conference on Software Engineering, ICSE â€™05, page372â€“381, New York, NY, USA, 2005. ACM.[18]TainÃ£ Santos, Gustavo Carvalho, and Augusto Sampaio. Formal modelling of envi-ronment restrictions from natural-language requirements. InProc. of SBMF 2018:the 21st Brazilian Symposium on Formal Methods: Foundations and Applications,volume 11254 ofLNCS, pages 252â€“270. Springer, 2018.[19]Amir Pnueli. The temporal logic of programs. InProc. of the 18th AnnualSymposium on Foundations of Computer Science, pages 46â€“57. IEEE, 1977.[20]Chaima Boufaied, Maris Jukss, Domenico Bianculli, Lionel Claude Briand, andYago Isasi Parache. Signal-based properties of cyber-physical systems: Taxonomyand logic-based characterization.Journal of Systems and Software, 174:110881,2021.[21]Bardh Hoxha, Houssam Abbas, and Georgios E. Fainekos. Benchmarks for tem-poral logic requirements for automotive systems. In Goran Frehse and MatthiasAlthoï¬€, editors,Proc. of ARCH@CPSWeek 2014/15: the 1st and 2nd InternationalWorkshop on Applied veRi/f_ication for Continuous and Hybrid Systems, volume 34ofEPiC Series in Computing, pages 25â€“30. EasyChair, 2014.[22]Yuk Wah Wong and Raymond J. Mooney. Learning for semantic parsing withstatistical machine translation. In Robert C. Moore, Jeï¬€A. Bilmes, JenniferChu-Carroll, and Mark Sanderson, editors,Proc. of Human Language TechnologyConference of the North American Chapter of the Association of ComputationalLinguistics. The Association for Computational Linguistics, 2006.[23] Sempre: Semantic parsing with execution, Accessed 2021.[24]Rohit J. Kate and Raymond J. Mooney. Using string-kernels for learning semanticparsers. In Nicoletta Calzolari, Claire Cardie, and Pierre Isabelle, editors,Proc. ofACL 2006: the 21st International Conference on Computational Linguistics and 44thAnnual Meeting of the Association for Computational Linguistics. The Associationfor Computer Linguistics, 2006.[25] Sippycup, Accessed 2021.[26] Yoav Artzi. Cornell SPF: Cornell semantic parsing framework, 2016.[27]Navid Yaghmazadeh, Yuepeng Wang, Isil Dillig, and Thomas Dillig. Sqlizer: querysynthesis from natural language.Proc. ACM Program. Lang., 1(OOPSLA):63:1â€“63:26, 2017.[28]Fei Li and H. V. Jagadish. Constructing an interactive natural language interfacefor relational databases.Proc. VLDB Endow., 8(1):73â€”-84, September 2014.[29]Lappoon R. Tang and Raymond J. Mooney. Automated construction of databaseinterfaces: Intergrating statistical and relational learning for semantic parsing. InProc. of 2000 Joint SIGDAT Conference on Empirical Methods in Natural LanguageProcessing and Very Large Corpora, pages 133â€“141. Association for ComputationalLinguistics, 2000.[30]John M. Zelle and Raymond J. Mooney. Learning to parse database queries usinginductive logic programming. InProc. of AAAI 96, IAAI 96:the Thirteenth NationalConference on Arti/f_icial Intelligence and Eighth Innovative Applications of Arti/f_icialIntelligence Conference, pages 1050â€“1055. AAAI Press / The MIT Press, 1996.[31]Victor Zhong, Caiming Xiong, and Richard Socher. Seq2sql: Generating struc-tured queries from natural language using reinforcement learning.CoRR,abs/1709.00103, 2017.[32]Yusuke Oda, Hiroyuki Fudaba, Graham Neubig, Hideaki Hata, Sakriani Sakti,Tomoki Toda, and Satoshi Nakamura. Learning to generate pseudo-code fromsource code using statistical machine translation (T). In Myra B. Cohen, LarsGrunske, and Michael Whalen, editors,Proc. of ASE 2015: the 30th IEEE/ACMInternational Conference on Automated Software Engineering, pages 574â€“584. IEEEComputer Society, 2015.[33]Xi Victoria Lin, Chenglong Wang, Luke Zettlemoyer, and Michael D. Ernst.NL2Bash: A corpus and semantic parser for natural language interface to thelinux operating system. In Nicoletta Calzolari, Khalid Choukri, Christopher Cieri,Thierry Declerck, Sara Goggi, KÃ´iti Hasida, Hitoshi Isahara, Bente Maegaard,Joseph Mariani, HÃ©lÃ¨ne Mazo, AsunciÃ³n Moreno, Jan Odijk, Stelios Piperidis,and Takenobu Tokunaga, editors,Proc. of LREC 2018: the Eleventh InternationalConference on Language Resources and Evaluation. European Language ResourcesAssociation (ELRA), 2018.[34]Chris Quirk, Raymond Mooney, and Michel Galley. Language to code: Learningsemantic parsers for if-this-then-that recipes. InProceedings of the 53rd AnnualMeeting of the Association for Computational Linguistics and the 7th InternationalJoint Conference on Natural Language Processing (Volume 1: Long Papers), pages878â€“888, Beijing, China, 2015. Association for Computational Linguistics.[35]Nikhil Ketkar.Introduction to PyTorch, pages 195â€“208. Apress, Berkeley, CA,2017.[36]MartÃ­n Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeï¬€reyDean, Matthieu Devin, Sanjay Ghemawat, Geoï¬€rey Irving, Michael Isard, Manju-nath Kudlur, Josh Levenberg, Rajat Monga, Sherry Moore, Derek Gordon Murray,Benoit Steiner, Paul A. Tucker, Vijay Vasudevan, Pete Warden, Martin Wicke,Yuan Yu, and Xiaoqiang Zheng. Tensor%ow: A system for large-scale machinelearning. InProc. of OSDI 2016: the 12th USENIX Symposium on Operating SystemsDesign and Implementation, pages 265â€“283. USENIX Association, 2016.[37]Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need.In Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna M. Wallach, RobFergus, S. V. N. Vishwanathan, and Roman Garnett, editors,Advances in Neu-ral Information Processing Systems 30: Annual Conference on Neural InformationProcessing Systems 2017, pages 5998â€“6008, 2017.[38]Xiaoqing Jin, Jyotirmoy V Deshmukh, James Kapinski, Koichi Ueda, and KenButts. Powertrain control veri#cation benchmark. InProceedings of the 17thinternational conference on Hybrid systems: computation and control, pages 253â€“262, 2014.[39]Christoph Gladisch, Thomas Heinz, Christian Heinzemann, Jens Oehlerking,Anne von Vietinghoï¬€, and Tim P#tzer. Experience paper: Search-based testingin automated driving control applications. In2019 34th IEEE/ACM InternationalConference on Automated Software Engineering (ASE), pages 26â€“37. IEEE, 2019.[40]Zhiyu Liu, Bo Wu, Jin Dai, and Hai Lin. Distributed communication-awaremotion planning for multi-agent systems from stl and spatel speci#cations. In2017 IEEE 56th Annual Conference on Decision and Control (CDC), pages 4452â€“4457.IEEE, 2017.[41]Parv Kapoor, Anand Balakrishnan, and Jyotirmoy V Deshmukh. Model-basedreinforcement learning from signal temporal logic speci#cations.arXiv preprintarXiv:2011.04950, 2020.621DeepSTL - From English Requirements to Signal Temporal LogicICSE â€™22, May 21â€“29, 2022, Pi/t_tsburgh, PA, USA[42]Derya Aksaray, Austin Jones, Zhaodan Kong, Mac Schwager, and Calin Belta.Q-learning for robust satisfaction of signal temporal logic speci#cations. In2016IEEE 55th Conference on Decision and Control (CDC), pages 6565â€“6570. IEEE, 2016.[43]Hsuan-Cheng Liao. A survey of reinforcement learning with temporal logicrewards, 2020.[44]Wenliang Liu and Calin Belta. Model-based safe policy search from signaltemporal logic speci#cations using recurrent neural networks.arXiv preprintarXiv:2103.15938, 2021.[45]Gang Chen, Mei Liu, and Zhaodan Kong. Temporal-logic-based semantic fault di-agnosis with time-series data from industrial internet of things.IEEE Transactionson Industrial Electronics, 68(5):4393â€“4403, 2020.[46]In#neon datasheet. https://www.in#neon.com/dgdl/In#neon-BTS5016-2EKA-DS-v01_00-EN.pdf?#leId=5546d4625a888733015aa41a5e161129.[47]Ilya Sutskever, Oriol Vinyals, and Quoc V Le. Sequence to sequence learning withneural networks. InAdvances in neural information processing systems, pages3104â€“3112, 2014.[48]Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine trans-lation by jointly learning to align and translate.arXiv preprint arXiv:1409.0473,2014.[49]Jiatao Gu, Zhengdong Lu, Hang Li, and Victor O.K. Li. Incorporating copyingmechanism in sequence-to-sequence learning. InProceedings of the 54th AnnualMeeting of the Association for Computational Linguistics (Volume 1: Long Papers),pages 1631â€“1640. Association for Computational Linguistics, 2016.[50]Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translationof rare words with subword units. InProc. of ACL 2016: the 54th Annual Meetingof the Association for Computational, Volume 1: Long Papers, 2016.[51]Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V. Le, Mohammad Norouzi,Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, Jeï¬€Klingner, Apurva Shah, Melvin Johnson, Xiaobing Liu, Lukasz Kaiser, StephanGouws, Yoshikiyo Kato, Taku Kudo, Hideto Kazawa, Keith Stevens, George Kurian,Nishant Patil, Wei Wang, Cliï¬€Young, Jason Smith, Jason Riesa, Alex Rudnick,Oriol Vinyals, Greg Corrado, Macduï¬€Hughes, and Jeï¬€rey Dean. Googleâ€™s neuralmachine translation system: Bridging the gap between human and machinetranslation.CoRR, abs/1609.08144, 2016.[52]Taku Kudo. Subword regularization: Improving neural network translationmodels with multiple subword candidates. InProceedings of the 56th AnnualMeeting of the Association for Computational Linguistics (Volume 1: Long Papers),pages 66â€“75, Melbourne, Australia, July 2018. Association for ComputationalLinguistics.[53]Aston Zhang, Zachary C Lipton, Mu Li, and Alexander J Smola. Dive into deeplearning.arXiv preprint arXiv:2106.11342, 2021.[54]Kyunghyun Cho, Bart Van MerriÃ«nboer, Dzmitry Bahdanau, and Yoshua Bengio.On the properties of neural machine translation: Encoder-decoder approaches.arXiv preprint arXiv:1409.1259, 2014.[55]Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization.arXiv preprint arXiv:1412.6980, 2014.[56]Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. Bleu: a methodfor automatic evaluation of machine translation. InProceedings of the 40th annualmeeting of the Association for Computational Linguistics, pages 311â€“318, 2002.[57]Steven Y Feng, Varun Gangal, Jason Wei, Sarath Chandar, Soroush Vosoughi,Teruko Mitamura, and Eduard Hovy. A survey of data augmentation approachesfor NLP.arXiv preprint arXiv:2105.03075, 2021.[58]Jing Li, Aixin Sun, Jianglei Han, and Chenliang Li. A survey on deep learning fornamed entity recognition.IEEE Transactions on Knowledge and Data Engineering,34(1):50â€“70, 2020.[59]Vikas Yadav and Steven Bethard. A survey on recent advances in named entityrecognition from deep learning models.arXiv preprint arXiv:1910.11470, 2019.[60]Xipeng Qiu, Tianxiang Sun, Yige Xu, Yunfan Shao, Ning Dai, and XuanjingHuang. Pre-trained models for natural language processing: A survey.ScienceChina Technological Sciences, 63(10):1872â€“1897, 2020.
622