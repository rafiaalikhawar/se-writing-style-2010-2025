Improving Machine Translation Systems via
Isotopic Replacement
Zeyu Sun
Key Laboratory of High Confidence
Software Technologies, MoE
School of Computer Science,
Peking University
szy_@pku.edu.cnJie M. Zhangâˆ—
University College London
jie.zhang@ucl.ac.ukYingfei Xiong
Key Laboratory of High Confidence
Software Technologies, MoE
School of Computer Science,
Peking University
xiongyf@pku.edu.cn
Mark Harman
Meta platforms and
University College London
mark.harman@ucl.ac.ukMike Papadakis
University of Luxembourg
michail.papadakis@uni.luLu Zhang
Key Laboratory of High Confidence
Software Technologies, MoE
School of Computer Science,
Peking University
zhanglucs@pku.edu.cn
ABSTRACT
Machinetranslationplaysanessentialroleinpeopleâ€™sdailyinterna-
tional communication. However, machine translation systems are
farfromperfect. To tacklethisproblem,researchershaveproposed
several approaches to testing machine translation. A promising
trendamongtheseapproachesistousewordreplacement,where
only one word in the original sentence is replaced with another
wordtoformasentencepair.However,precisecontroloftheim-
pact of word replacement remains an outstanding issue in these
approaches.
Toaddressthisissue,weproposeCAT,anovelword-replacement-
basedapproach,whosebasic ideaistoidentifywordreplacement
with controlled impact (referred to as isotopic replacement). To
achieve this purpose, we use a neural-based language model to
encodethesentencecontext,anddesignaneural-network-based
algorithmtoevaluatecontext-awaresemanticsimilaritybetween
twowords. Furthermore,similar toTransRepair,a state-of-the-art
word-replacement-basedapproach,CATalsoprovidesautomatic
fixing of revealed bugs without model retraining.
Our evaluation on Google Translate and Transformer indicates
thatCATachievessignificantimprovementsoverTransRepair.In
particular, 1) CAT detects seven more types of bugs than TransRe-
pair; 2) CAT detects 129% more translation bugs than TransRepair;
3) CAT repairs twice more bugs than TransRepair, many of which
may bring serious consequences if left unfixed; and 4) CAT has
better efficiency than TransRepair in input generation (0.01s v.s.0.41s) and comparable efficiency with TransRepair in bug repair
(1.92s v.s. 1.34s).
âˆ—Corresponding author.
ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Â© 2022 Association for Computing Machinery.
ACM ISBN 978-1-4503-9221-1/22/05...$15.00
https://doi.org/10.1145/3510003.3510206KEYWORDS
machinetranslation,testingandrepair,machinelearningtesting,
neural networks
ACM Reference Format:
Zeyu Sun, Jie M. Zhang, Yingfei Xiong, Mark Harman, Mike Papadakis,
andLuZhang.2022.ImprovingMachineTranslationSystemsviaIsotopic
Replacement.In 44thInternationalConferenceonSoftwareEngineering(ICSE
â€™22), May 21â€“29, 2022, Pittsburgh, PA, USA. ACM, New York, NY, USA,
12 pages. https://doi.org/10.1145/3510003.3510206
1 INTRODUCTION
Machine translation systems, such as Google Translate, translate a
textfromasourcelanguageintoatargetlanguageautomatically.
They play an essential role in overcoming communication barriers
acrosstheglobe,providingtranslationservicestomillionsofend
users everyday. In2018, Facebook reportedits deployment ofma-
chinetranslationsupportingapproximately2,000languagepairs,
servingapproximately4.5billiontranslatedpostimpressionsevery
day,therebyallowing600millionpeopletoreadtranslatedposts
in their mother tongue [ 14]. By January of 2021, Google Translate
has been reported to support 109 languages, with more than 100
billion words translated per day [34].
Poortranslationshavebeenknowntobeaseriousproblemfor
a considerably long period of time. For example, mistranslations of
Article 17 of the Treaty of Uccialli led to a war [ 9], while mistrans-
lation of the Japanese governmentâ€™s response may have influenced
American Governmentâ€™s decision to use the atom bomb during
WorldWar II[ 1]. Theseproblems predate theadvent ofmachine
translation,butarearguablyexacerbatedbytheapparenteasewith
which machines may now translate natural languages.
Theprofoundconsequencesofmistranslationpriortoautoma-
tionareconcernedwithsituationswherethereisaclearimperative
foraccuratetranslationandplentyofhumansareinvolvedinthe
translation process.How muchmore perniciouscould such asitu-
ation become, as we rely more and more on automated machinetranslation; currently with translation processes that afford few
checks and corrections?
11812022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:21:06 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Sun and Zhang, et al.
As we move to a scenario in which machines routinely translate
natural language sentences, the potential for misunderstandings
maybecomemagnified.Thismakesautomatedtranslationanim-
portantnewapplicationfortestingandevaluation.Furthermore,
given that machine translation is typically used in scenarios where
there is no human in the loop, and thus no time to respond to
failedtestcases,itisalsohighlyimportantthatwehaveinplace
techniques for automated repair.
Machinetranslationsystemscurrentlyhavefarmorefrequent
mistranslations than human translations, causing problems in eco-
nomics and safety, becoming a source of international tension, and
alsopotentiallyviolatinghumanrights[ 32].Theseissueshighlight
the importance of automatic improvement of machine translations.
Recently,quiteafewapproaches(e.g.,SIT[ 15],TransRepair[ 32],
and PathInv [ 12]) have been proposed for testing machine transla-
tion systems. In particular, approaches based on word replacement,
whereonlyonewordintheoriginalsentenceisreplacedwithan-
other word, have received intensive attention. Intuitively, since
onlyonewordintheoriginalsentenceischanged,theprediction
of the corresponding change on the translation is thus easier than
the situation where multiple words in the original sentence are
changed.However,precisecontroloftheimpactofwordreplace-
ment in word-replacement-based approaches is still difficult due to
the fuzzy semantics of natural language words.
Inthispaper,weproposeanovelword-replacement-basedap-
proach (namedCAT1) tomachine translationtesting. Given asen-
tence in the source language, CAT performs isotopic replacement,
which is a special type of word replacement, to generate new sen-
tences. The goal of isotopic replacement is to control the impactof word replacement so that the translation of the sentence after
wordreplacementshouldverylikelybesimilartothetranslation
of the sentence before word replacement. Our insight is that thekey to control the impact of word replacement is to control thesemantic difference between the two words. In a typical natural
language, the semantics of a word is comparatively stable, but the
semantics mayalso varyto someextent indifferent sentences[ 8].
Therefore, it is necessary to consider the impact of contexts on the
semantics of words when performing isotopic replacement. As a
result, we design an algorithm to calculate context-aware semantic
similarity between each pair of words. Our algorithm uses a neural
architecture to encode the sentence context during replacement,
thereby making the replacement context-aware. On top of context
encoding,ouralgorithmfurtherperformsneural-basedsemantic
evaluationtoguaranteethatthesemanticdifferencebetweenthe
words under replacement is small enough. Following TransRepair,
our approach is also able to repair bugs revealed during testing.
WeempiricallyevaluatedCATtogetherwithTransRepairontwo
state-of-the-artmachinetranslationsystems,GoogleTranslate[ 10]
and Transformer [ 33]. The translation is between the top two most
widelyusedlanguages,EnglishandChinese,with2,001sentence
pairs. Our experimental results show that CAT significantly out-performs TransRepair in both effectiveness and efficiency: CATdetects
seven more types of bugs than TransRepair. It detects
129%/129%morebugsandrepairs199% /238%morebugsthanTran-
sRepaironGoogleTranslate/Transformer,respectively.Overhalf
1Context-Aware replacement for improving machine Translation.of the detected mistranslations can be automatically fixed by CAT.
Furthermore,CAThasbetterefficiencythanTransRepairininput
sentence generation (0.01s v.s. 0.41s) costs 80% and competitive
efficiency with TransRepair in repairing (1.92s v.s. 1.34s).
Tosummarise,thispapermakesthefollowingcontributions:A
novel approach (named CAT) to improving machine translation
based on isotopic replacement, where the key technique is a novel
algorithmforcalculatingcontext-awaresemanticsimilaritytoiden-
tify isotopic replacement. An extensive evaluation to demonstrate
theeffectivenessandefficiencyofCAT,indicatingthatCATsignifi-
cantly outperforms the state-of-the-art approaches.
Theimplementationcode,thedataweused,togetherwiththe
fullexperimentalresultsofthispaperareavailableathttps://github.
com/zysszy/CAT.
2 RELATED WORK
We divide the related work of our paper into two parts: machine
translation testing in Section 2.1 and machine translation repair in
Section 2.2.
2.1 Machine Translation Testing
Therearedifferentpropertiestotestinmachinetranslationtesting.
Heigold et al. [ 17], Belinkov and Bisk [ 2], and Zhao et al. [ 39]
focusedontestingrobustness,i.e.,whethermachinetranslatorsare
influenced by minor errors, typos, or noises in the input sentences.
More approaches focus on testing the correctness of machine
translators.Themajordifferenceslieintheheuristicsadoptedin
these approaches.
Pesuetal.[ 27]proposedanapproachbasedoncross-reference.
In particular, this approach focuses on checking whether the direct
translation(fromasourcelanguagetoatargetlanguage)andthe
indirecttranslation(fromthesourcelanguagetoanintermediate
language and then from the intermediate language to the targetlanguage) of the same sentence produce the same results. Cao etal. [
3] proposed a similar approach, where they check whether
thetranslationbetweendifferenttranslationsystemsproducethe
similar translation results.
Themainstreamapproachestestcorrectnessviathecombination
ofinputmutationandmetamorphicrelation[ 38].Theyadoptthe
strategyofcontrolledinputgenerationofnewsentencesorphrases
in the source language. Given a sentence in the source language,
such an approach generates a related sentence or phrase; then theoriginal sentence and the generated sentence (phrase) are fed into
thetranslatorundertest;andtheapproachcomparesthetranslationresultsofthetwotodeterminewhetherabugisfound.Inparticular,
Purity [16] breaks the original sentence into phrases and checks
whethersome phrasesalone havedifferent translationscompared
with their translations for the original sentence.
Except for Purity, other approaches based on controlled input
generationadoptwordreplacement.Thatistosay,theseapproaches
generate a new sentence via replacing one word in the original
sentencewithanotherrelatedword.Guptaetal.[ 12]detectatrans-
lation bug by replacing a word with another word with completely
different meaning, and expect that the word replacement shouldyield different translations. Sun and Zhou [
31] replace a human
1182
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:21:06 UTC from IEEE Xplore.  Restrictions apply. Improving Machine Translation Systems via
Isotopic ReplacementICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
	


	

	





		
	
Figure 1: Overview of CAT.
namebeforeâ€œlikeâ€orâ€œhateâ€withanotherhumanname.Theyex-
pect that the translations of the sentences before and after word
replacementshouldbesimilar.Heetal.[ 15]replaceonewordin
the original sentence with another word that would also fit intothe structure of the original sentence, and expect that the twotranslations of the original sentence and the generated sentenceshould also have a similar structure. In particular, this approach
(namedSIT)adoptsthemaskedlanguagemodel(MLM)[ 5]todeter-
mine which words are likely to fit into the structure of the original
sentence.NotethatthewordreplacementinSITisprimarilysyn-
tacticalwithoutexplicitconsiderationofsemantics.Furthermore,
sinceMLMconsidersthecontextoftheoriginalsentencewhengen-
erating the replacement, many syntactically suitable replacements
are excluded. For example, when facing Make it a requirement that
only half is to be used in polling stations (except in Wales)., SIT gen-
erates a sentence by replacing â€œhalfâ€ with â€œEnglishâ€. The approach
(named TransRepair) to machine translation testing proposed in
Sun et al. [ 32] replaces a word with another semantically similar
word (e.g., girls âˆ’ â†’boys), and expect the generated sentence may
lead to a similar translation with the original translation for the
unchanged part in thesentence. In particular, TransRepair adopts
vectorrepresentationofwords[ 26,29]tocalculatethesimilarity
ofeach pairofwords.Sincethe vectorrepresentation ofeachword
is calculated on the basis of all sentences containing the word in a
corpus,thesimilarityvaluesbetweenwordsusedinTransRepair
do not consider the specific context of the original sentence.
Ourapproach(namedCAT)tomachinetranslationtestinggener-
ally falls into the category of word-replacement-based approaches.
Similar to SIT [ 15] and TransRepair [ 32], our approach also ex-
pectsthatthechangeofonewordwouldnotresultinsubstantial
differenceinthetranslations.However,ourapproachisbasedon
the concept of isotopic replacement, where one word is replaced
with only words that differ subtly from the original word. Then
weproposeaspeciallydesignedalgorithmtodeterminewhether
awordreplacementisanisotopicreplacement.Inparticular,our
algorithmisbasedoncalculatingcontext-awaresemanticsimilar-
ity, for which to our knowledge no straightforward combinationof MLM and vector representation of words are able to achieveour purpose. Another distinct merit of our approach is that iso-
topicreplacementisapplicabletoallpartsofspeech,whileexisting
word-replacement-based approaches are specific to only few parts
ofspeech.Forexample,wordreplacementinSITisspecifictonouns
and adjectives; and word replacement in TransRepair is specific to
nouns, adjectives, and numbers.Therehavebeenwordreplacementresearchforothertasks,such
as attacking/testing/defending models on different classification
tasks[11,19,20,24,28,37].Therequirementoftheirwordreplace-
ment is to keep the classification result unchanged. As a result, the
replacementmayleadtogrammarerrors,havecompletelydifferent
context, or affect the translation of the unchanged part in a sen-
tence, thereby not being applicable for machine translation testing.
ForCAT,weusetheisotopicreplacementandthebasicideaisto
identifywordreplacementwithcontrolledimpacttothetranslation
of the whole sentence.
2.2 Machine Translation Repair
Torepairtherevealedbugsandimprovemachinetranslation,exist-
ing approaches are typically based on data augmentation. Heigold
etal.[17],Sperberetal.[ 30],andBelinkovandBisk[ 2]proposed
to add the generated sentences (noises) used for robustness testing
to the training data and retrain the model. Cheng et al. [ 4] and
Ebrahimi et al. [ 7] used the gradient-based approach to generating
sentences for model retraining. Different from these approaches,
therearealsosomeapproachesimprovingrobustnessofmachine
translationbydesigningsomeadditionalneuralcomponents.Cheng
et al. [4] added a component to distinguish the noises from the
training set, while Belinkov and Bisk [ 2] used a character-level
representation.
Theaboveapproachesneedmodelretraining.Toourknowledge,
theonlyapproachthatisabletorepairmachinetranslationwithout
model retraining is TransRepair by Sun et al. [ 32]. In particular,
TransRepair adopts a post processing based strategy for repair. For
a bug-revealing sentence, TransRepair generates several similarsentences via the same word replacement strategy in its testing
phase;andthencombinesthetranslationsofthesesimilarsentencesandtheoriginalsentencetorepairthebug.OurCATadoptsasimilar
strategy withTransRepair forrepair, butthe generationof similar
sentencesfor repairin CAT isalso basedon isotopicreplacement.
Accordingtoourevaluationresults,therepaireffectivenessofCAT
significantly outperforms that of TransRepair.
3 APPROACH
3.1 Overview
Ourapproach(namedCAT)followsthegeneralprocessofword-
replacement-based approaches: Given an input sentence ğ‘ and a
wordğ‘¤inğ‘ ,ourapproachidentifiesasetofwords(denotedas ğ‘Šğ‘¤),
eachofwhichcanbeusedtoreplace ğ‘¤inğ‘ .Foreachword ğ‘¤ğ‘“âˆˆğ‘Šğ‘¤,
1183
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:21:06 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Sun and Zhang, et al.

 	   
		         
	

	
	 		

Figure 2: BERT-based context-aware word replacement.
our approach further ensures thatthe replacement of ğ‘¤withğ‘¤ğ‘“
inğ‘ isisotopicreplacement,whichonlysubtlyimpacts ğ‘ .Thekey
idea to realise isotopic replacement is to evaluate context-aware
semantic similarity between ğ‘¤and each candidate replacement
wordğ‘¤ğ‘Ÿâˆˆğ¶ğ‘¤in the context of ğ‘ .
Figure 1 depicts an overview of CAT. There are two stages in
CAT for conducting isotopic replacement. In the first stage, CAT
generates a set of word replacement candidates ğ¶ğ‘¤for each word
ğ‘¤intheinputsentence ğ‘ .Inthesecondstage,CATidentifiesthe
final set of words ğ‘Šğ‘¤from word candidates ğ¶ğ‘¤to achieve iso-
topicreplacementviaevaluatingcontext-awaresemanticsimilarity
between each word in ğ‘¤ğ‘Ÿâˆˆğ¶ğ‘¤and the word ğ‘¤in sentence ğ‘ .
This section mainly introduces these two parts (candidate word
generationinSection3.2andsemanticevaluationinSection3.3).
The remaining steps of translation testing and repair are similar
to the corresponding steps in TransRepair. To make our presen-tation self-contained, we provide some necessary information in
Section 3.4 for convenience.
3.2 Candidate Word Generation
Inordertorealiseisotopicreplacement,wefirstgenerateasetof
candidatewords ğ¶ğ‘¤foreachword ğ‘¤intheinputoriginalsentence
ğ‘ ,whereğ‘Šğ‘¤âŠ‚ğ¶ğ‘¤,basedon thecontextforfurther evaluationof
context-aware semantic similarity.
Given an input sentence ğ‘ , CAT generates such candidate words
ğ¶ğ‘¤byensuringthateachwordin ğ¶ğ‘¤isalsosuitableforthecontext.
Torealiseouridea,weusetheBidirectionalEncoderRepresenta-
tionsfromTransformers(BERT)[ 5]toencodethesentencecontext
and check which words are suitable for the context.
Figure2showstheoverviewofcontext-awarewordreplacement
inCAT.AsaTransformer[ 33]basedpre-trainedmodel,BERTtakes
aninputsentenceandoutputsareal-valued vectorforeachword
withinthesentencebasedonthecontext.Whenperformingaword
replacement, a word to be replaced in the input sentence is first
masked by a special mark â€œ[MASK]â€. For example, in Figure 2, the
wordâ€œWithinâ€ismaskedfortheinputsentenceâ€œWithinthepast
decades...â€.Thesentencewiththemaskedwordisthenfedtothe
BERTmodel,whichextractsasetofreal-valuedvectors.Toconduct
word replacement, BERT feeds the vector of the word â€œ[MASK]â€ to
apre-trainedlinearclassifierandgetsasetofpredictedwordswith
different prediction probability.Givenaninputsentence ğ‘ withawordsequence ğ‘¤1,ğ‘¤2,Â·Â·Â·,ğ‘¤ğ‘,
whereğ‘isthetotalnumberofwords,wemaskthewordsinthe
sentence in turn (one word being masked each time) and feed each
masked sentence into BERT.
TheoutputsofBERTareasetofvectors ğ’‰1,ğ’‰2,Â·Â·Â·,ğ’‰ğ‘,which
denotesthecontext-awarevectorrepresentationoftheinputwords.
Then, a pre-trained linear classifier takes the vector of the masked
word ğ’‰maskasaninput,andoutputsasetofinitialcandidatewords
ğ¶ğ‘–. Each word in ğ¶ğ‘–has a predictive probability. The sum of the
probabilitiesofallthecandidatewordsis1.0.Wethenuseaprob-
ability filter to discard the words with low predictive probability
(we set the threshold as 0.05 to remove the words that are most
unlikely to be qualified). In addition, if the word is the same as the
originalwordwemasked,wediscardthisword.Finally,wetreatthe remaining words as word candidates
ğ¶ğ‘¤ğ‘šğ‘ğ‘ ğ‘˜for the masked
wordğ‘¤ğ‘šğ‘ğ‘ ğ‘˜, each of which can be used to fill the masked word in
the original input sentence for replacement.
Notethat,theaboveprocedureforwordgenerationiscontext-
aware,becauseBERTpredictsthemaskedwordbasedonexactly
the remaining parts of the sentence.
3.3 Semantic Evaluation
Isotopicreplacementaimstoidentifyasetofwords ğ‘Šğ‘¤foreach
wordğ‘¤in input sentence ğ‘ such that each word in ğ‘Šğ‘¤only subtly
differsfrom ğ‘¤inthecontextof ğ‘ .Incandidatewordgeneration,we
generateasetofcandidatewords ğ¶ğ‘¤fortheword ğ‘¤inğ‘ .However,
there are occasions that BERT predicts a masked word that has
similarcontextwiththeoriginalword,butwithdifferentmeanings.
Therefore, we next compute the context-aware semantic similarity
and use it to discard the inappropriate words in ğ¶ğ‘¤for identifying
the final word set ğ‘Šğ‘¤.
To achieve our purpose, we propose a novel neural-based mech-
anism for the evaluation of context-aware semantic similarity. The
key step to compute the context-aware semantic similarity in CAT
is to measure the wordvector similarity between the originalword
anditsreplacedword.Inourapproach,weagainuseBERTtoget
the output word vectors, which is the most widely used word2vec
approach in natural language processing [ 5,21,40]. Unlike the us-
age of BERT in candidate word generation in the previous section,
we do not feed BERT with a masked sentence, but directly take the
wholetokenisedsentenceasitsinput.Inthismanner,BERTfirst
representsawordasavectortrainedfromthetrainingcorpus.The
vector indicates the semantics of this single word. BERT further
considersthesentencecontextandcomputesacontext-awarese-
mantic representation. In this way, we get a series of word vectors
for each word in each sentence, as the final word vectors.
Then, we measure the context-aware semantic similarity be-
tween the word ğ‘¤inğ‘ (denoted by ğ’‰ğ‘) and the candidate word
ğ‘¤ğ‘Ÿâˆˆğ¶ğ‘¤inğ‘ ğ‘Ÿ, which is generated via replacing ğ‘¤inğ‘ withğ‘¤ğ‘Ÿ,
(denotedby ğ’‰ğ‘)byusingthecosinesimilarity CosSimoftheirword
vectors:
CosSim(ğ’‰ğ‘,ğ’‰ğ‘)=ğ’‰ğ‘ğ’‰ğ‘
|ğ’‰ğ‘||ğ’‰ğ‘|. (1)
The overall process of our semantic evaluation is detailed by
Algorithm 1. Foran input sentence ğ‘ ,aw o r dğ‘¤inğ‘ , and theset of
the candidatewords ğ¶ğ‘¤generated viacandidate wordgeneration,
we aim at getting a final word set ğ‘Šğ‘¤. We first define an empty set
1184
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:21:06 UTC from IEEE Xplore.  Restrictions apply. Improving Machine Translation Systems via
Isotopic ReplacementICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
ğ‘Šğ‘¤for collecting the words after evaluation (Line 1). For the word
ğ‘¤inğ‘ , we further extract its word vector ğ’‰ğ‘via BERT (Lines 2).
Next,foreachcandidateword ğ‘¤ğ‘Ÿâˆˆğ¶ğ‘¤,weuseittoreplace ğ‘¤in
ğ‘ andgenerateamutantsentence ğ‘ ğ‘Ÿ(Lines3and4).Fortheword
ğ‘¤ğ‘Ÿinğ‘ ğ‘Ÿ, we extract its word vector ğ’‰ğ‘(Line 5). Then, to capture
the context-aware semantic similarity of the above two words, we
compute the introduced cosine similarity ğ¶ğ‘œğ‘ ğ‘†ğ‘–ğ‘šof their word
vectors ğ’‰ğ‘andğ’‰ğ‘(Line 6). If the similarity is above the predefined
threshold ğ‘†ğ‘‡â„ğ‘Ÿğ‘’ğ‘ â„ğ‘œğ‘™ğ‘‘ (we set the threshold to be 0.85), it passes
the evaluation (Line 7). Thus, we add the word ğ‘¤ğ‘Ÿto the set ğ‘Šğ‘¤as
afinalgeneratedone(Line8).Afterwehaveevaluatedallwords
automatically,weoutputthefinalwordset ğ‘Šğ‘¤forwordğ‘¤inğ‘ (Line
11). This process ensures that the replacement of ğ‘¤withğ‘¤ğ‘“âˆˆğ‘Šğ‘¤
inğ‘ is isotopic.
Finally,weinturnusetheword ğ‘¤ğ‘“âˆˆğ‘Šğ‘¤toreplacetheword
ğ‘¤inğ‘ and repeat this process for each word in ğ‘ to generate a final
set of sentences ğ‘€ğ‘“. We refer to each of these finally generated
sentences as a mutant [ 18,25]. This generated set of mutants is
further used for automatic testing (each mutant is paired with the
original sentence as one test input pair) and repair.
Algorithm 1: Process of semantic evaluation
Data:ğ‘ :theinputsentence; ğ‘¤thewordintheinputsentence ğ‘ ;ğ¶ğ‘¤
the set of the candidate words for the word ğ‘¤(the output of
the candidate word generation)
Result:ğ‘Šğ‘¤: the final set of words, each of which can be used to
replaceğ‘¤inğ‘ 
1ğ‘Šğ‘¤={}
2ğ’‰ğ‘=BERT(ğ‘ ,ğ‘¤)
3foreach candidate word ğ‘¤ğ‘Ÿâˆˆğ¶ğ‘¤do
4ğ‘ ğ‘Ÿ=Replace(ğ‘ ,ğ‘¤,ğ‘¤ ğ‘Ÿ)
5 ğ’‰ğ‘=BERT(ğ‘ ğ‘Ÿ,ğ‘¤ğ‘Ÿ)
6ğ‘†ğ‘–ğ‘šğ‘–ğ‘™ğ‘ğ‘Ÿğ‘–ğ‘¡ğ‘¦ =CosSim(ğ’‰ğ‘,ğ’‰ğ‘)
7ifğ‘†ğ‘–ğ‘šğ‘–ğ‘™ğ‘ğ‘Ÿğ‘–ğ‘¡ğ‘¦ >=ğ‘†ğ‘‡â„ğ‘Ÿğ‘’ğ‘ â„ğ‘œğ‘™ğ‘‘ then
8 ğ‘Šğ‘¤=ğ‘Šğ‘¤âˆªğ‘¤ğ‘Ÿ
9end
10end
11returnğ‘Šğ‘¤
3.4 Testing and Repair
The process of test oraclegeneration and black/grey-box repair in
CAT is the same as TransRepair. We briefly introduce the details in
this section.
3.4.1 Test Oracle Generation. Foreachtestinput (ğ‘ ,ğ‘š),whereğ‘šâˆˆ
ğ‘€ğ‘“,letğ‘Ÿ(ğ‘ )andğ‘Ÿ(ğ‘š)bethetranslationresultsofinputsentences
ğ‘ and its mutant ğ‘š. Mutant ğ‘šis generated by replacing a word
ğ‘¤1inğ‘ with another word ğ‘¤2. CAT generates the test oracle by
computing the similarity between ğ‘Ÿ(ğ‘ )andğ‘Ÿ(ğ‘š)excluding the
translationchangescausedby ğ‘¤1andğ‘¤2.Toremovethecontext
changes, we computes the similarity of the subsequences of ğ‘Ÿ(ğ‘ )
andğ‘Ÿ(ğ‘š)andfurtherselectsthelargestsimilaritytoapproximate
the similarity of ğ‘Ÿ(ğ‘ )andğ‘Ÿ(ğ‘š). When the similarity is below the
predefined threshold, CAT reports an inconsistency bug.3.4.2 Black/Grey-box Repair. Black-box and grey-box repair trans-
formthe originaltranslation basedon thebesttranslation among
thetranslationsformutants.Therearetwowaysofchoosingthe
best translation, one using predictive probability (grey-box), the
other using cross-reference (black-box).
In detail, CAT first repairs the translation of the original sen-
tences in a bug-revealing test case and then it seeks to find a trans-
lation for the mutant, which passes the consistency test.
For the original sentence, CAT generates a set of mutants and
gets their translations. It further ranks these translations based
on thepredictive probability ofthe machinetranslation orcross-
reference in decreasing order. CAT maps back the translation with
thehighestrankingtothetranslationoforiginalsentenceviaword
alignment [ 23]. If the mapping back fails, it selects the translation
with a lower ranking.
Forthemutant,CATusesthesamerepairprocessastheoriginal
sentence but marks the output as a candidate solution. We then
checks whether the candidate solution passes the testing with the
repaired translation of the original sentence as test input. If not,
CAT proceeds by checking other candidate solutions.
4 EXPERIMENTAL SETUP
Inthissection,weintroducetheprocedurewefollowtoevaluate
CAT.
4.1 Research Questions
To evaluate CAT we begin by investigating the extent to which iso-
topicreplacementbringsvalueintesting,i.e.,helpstheconstruction
of test cases. Thus, we ask:RQ1: How effective is CAT in generating test inputs?
To answer this question, we consider the quantity, distribution,
validity, and diversity of the test inputs generated with isotopic
replacement. To ensure validity, we conduct a manual check on
whether the replaced word in the mutant leads to grammatical
errors, whether the semantic meaning of the mutant sentence is
reasonable,andwhetherthemutantoughttohaveconsistenttrans-
lations with the original sentence.
By showing that CAT helps designing test inputs, we then turn
our attention to the actual value of interest, bug detection and bug
repair. We first focus on bug detection and ask:RQ2: How effective is CAT in bug detection?
Here,wefocusonthebug-revealingabilityofCAT.Tothisend,we
test Google Translate (GT) and Transformer with the test inputsgenerated in RQ1 to investigate: 1) the number of inconsistency
bugs reported by automated test oracles; 2) the diversity of the de-
tected inconsistency bugs; 3) the precision, recall, and F-1 measure
of bug detection based on manual inspection.
Having presented the bug-revealing ability of CAT, we turn our
attention to its repairing ability. Hence, we ask:RQ3: How effective is CAT in bug repair?
Toanswerthisquestion,foreachreportedbugonGoogleTranslate
(GT) and Transformer, we use CAT to repair the bug automatically
(withbothblack-boxandgrey-boxrepair).Wethusfollowthesame
procedureasinRQ2andinvestigate:1)therepaireffectivenessmea-
suredbyautomatedtestoracles;2)thediversityofrepairedbugs;
and 3) the validity of reported fixes based on manual inspection.
1185
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:21:06 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Sun and Zhang, et al.
Uptothispoint,inouranalysis,weonlyinvestigatedtestand
repair effectiveness. However, this analysis tells nothing about the
time required to conduct the testing and repair tasks. Therefore,
we ask:
RQ4: What is the efficiency of CAT?
Toanswerthisquestion,werepeattheexperimentsofCATinRQ1-
3andrecordthetimecost.Then,weinvestigate:1)thetimecost
ofisotopicreplacement;2)thetimecostofbugdetectionforeach
sentence; 3) the time cost of repairing a bug.
Since CAT follows TransRepair for improving machine trans-
lation, for eachresearch question, we set TransRepair [ 32]a sa
baseline, and report the improvement of CAT over TransRepair
underidenticalconfiguration. Thecomparisonwithother testing
approaches can be referred to the extended analysis in Section 6.1.
4.2 Machine Translators
ThesameasTransRepair,weconsiderthefollowingtwostate-of-
the-artmachinetranslators:1)Transformer[ 33],themostwidely
studied machine translation system by the research community; 2)
GoogleTranslate[ 10],themostwidelyusedend-to-endmachine
translation system developed by Google.
Transformer: Transformerisanattention-basedsequence-to-sequence
model designed fornatural languageprocessing tasks. Ithave been
shown to be effective in various areas including machine trans-
lation [33], question answering [ 5], and others [ 6]. In this paper,
weusedidenticalparametersTransformermodelusedin[ 32]2to
achieve a fair comparison.Google Translate:
Google Translate is a neural machine trans-
lation system developed by Google. We select Google Translatedue to it being a mainstream translation system, which has over
500 million total users with more than 100 billion words translated
daily [34].
4.3 Implementation Settings
The implementation of CAT is based on the standard BERT that is
publiclyavailable[ 36].TheBERTmodelcontains24-layers,1024
hidden size, 16 heads. The model was trained on 16 TPU chips for
one million steps with a batch size of 256. For TransRepair, we
implement it with the same setting according to the paper [ 32]. To
perform a fair comparison, we follow the setting of the previous
approach [ 32] and generate at most 5 valid mutants for each input
sentence during testing and at most 16 valid mutants for eachsentence in a each buggy test case during repair. We perform an
additionalexperimentinSection6.2tostudytheinfluenceofthis
mutant number upper bound.
We conduct experiments on Ubuntu 16 .04 with 256GB RAM
andfourIntelE5-2620v4CPUs.Theneuralnetworks(BERTand
Transformer) are all trained and inference on 8 Nvidia Titan RTXs.
4.4 Dataset
Foreaseofcomparison,weusethesamedatasetasTransRepair[ 32],
the News Commentary dataset [ 35]. This dataset has been adopted
as a standard benchmark for translator evaluation [ 13]. It contains
2We use the same hyper-parameters, random seeds, deep learning library and trained
the model for the same epochs.2,001 parallel sentences that are different from the training set and
validation set used for Transformer training.
5 RESULTS
Inthissection,weintroducetheresultsofourexperimenttoanswer
the research questions.
5.1 Effectiveness of Test Generation (RQ1)
Toanswerthisquestion,foreachtestsentenceinourdataset(2,001
alltogether),wegeneratemutantswithCATandTransRepair.Each
mutant is paired with the original sentence to form a test input.
Wethenrecordthequantity(i.e.,totalnumberoftestinputs),dis-
tribution (i.e., the number of generated test inputs per sentence),
validity(i.e.,whetherthemutantandtheoriginalsentenceinatest
inputshouldyieldconsistenttranslationsforbugdetection),and
diversity (i.e., the types of generated mutants).Quantity:
Forthe2,001inputsentences,11,045candidatewords
are generated by isotopic replacement, and 1,103 are further dis-
cardedbycandidatefiltering(usingautomaticsemanticevaluation).Intotal,CATgenerates9,942mutantsthatcouldbepairedwiththe
originalsentencesastestinputsfortranslationtesting.ForTran-
sRepair,itgenerates21,960mutantcandidatesbywordreplacement
with17,268discardedbycandidatefiltering(usingStandfordparser).
It finally yields 4,692 test inputs.
TheseresultsshowthatCATgeneratessignificantlymoretest
inputs than TransRepair. In particular, CATâ€™s isotopic replacement
increases candidatesâ€™ possibility of passing semantic evaluation.
For CAT, 90% of the mutant candidates pass the filtering; for Tran-
sRepair, only 21% mutant candidates pass the filtering due to its
ignoranceofthecontextinformationoftheoriginalinputsentences.
Inthefollowing,wedigdeepintothedistribution,diversity,and
validity of the generated mutants.
Distribution: We use violin graphs to demonstrate the entire dis-
tributionoftestinputsgeneratedforeachsentence.Figure3showstheresults.Inthisfigure,weobservethatthenumberoftestinputs
generated by CAT reaches 5 (the upper bound, more details in Sec-
tion 4.3) for most of the input sentences. However, for TransRepair,
many sentences have fewer than 5 test inputs.
In particular, the isotopic replacement enables CAT to generate
test inputs for almost all the sentences (with only three sentences,
i.e., 0.15%, having no generated test inputs). However, for Tran-sRepair, it fails to generate test inputs for as many as 43.7% of
the sentences. Consequently, TransRepair is not able to detect any
translation bugs for those sentences.Diversity:
We further compare CAT and TransRepair from the as-
pectofmutantdiversity,i.e.,thetypeofgeneratedmutantsinterms
ofpart-of-speechofthereplacedw ord.Thepart-of-speechtypes
include Noun, Adj. (Adjective), Adv. (Adverb), Num. (Numeral),
Verb, Deter. (Determiner), Conj. (Conjunction), Pron. (Pronoun),
Prep. (Preposition), and Others.
Figure4showsthenumberofmutantsbelongingtoeachtype.
Overall, we observe that most mutants TransRepair generated are
for nouns, adjectives, and numerals as mentioned in Section 1.
By contrast, CAT generates mutants for seven more types of
part-of-speech.Thisdemonstrateddiversityisimportantbecause
1186
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:21:06 UTC from IEEE Xplore.  Restrictions apply. Improving Machine Translation Systems via
Isotopic ReplacementICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
012345
CAT TransRepairNumber of mutants per sentence
Figure3:Distributionofthegeneratedmutantsforeachsen-
tence. CAT generates 5 test inputs (the upper bound) for al-mostalltheinputsentences,whileTransRepairfailstogen-erate any test inputs for 43.7% of the sentences.
different types of test inputs reveal different types of inconsis-tency bugs. For example, TransRepair will miss the detection of
inconsistency bugs aroused by verbs, which plays a key role in the
understanding of the sentence translation.
0100020003000
Noun Verb Prep. Num. Adj. Deter. Adv. Pron. Conj. OthersNumber of test inputsCAT TransRepair
Figure 4: Number of generated test inputs ( ğ‘¦-axis) per mu-
tant type ( ğ‘¥-axis). This figure shows that CAT generates
more diverse mutants than TransRepair.
Validity: Thevaliditymeasurestheproportionofthegeneratedtest
inputsentencesthatarequalifiedfortranslationtesting.Thefirst
two authors manually check the validity separately. If a generated
mutantis1)grammaticallycorrect;2)semanticallyreasonable;and
3) ought to yield semantic-identical translation with the original
sentence (excluding the replaced word), we deem the test input to
be valid. We randomly sample 200 test cases for each approach.
Ourmanualinspection3indicatesthat96.5%ofthetestinputs
generatedbyCATarevalid.Invalidmutantexamplesare1) Greater
(protection âˆ’ â†’priority) should be given to whistleblowers, Sir Eric says;
2)The (Supplement âˆ’ â†’Suppression) of Public Sports Facilities;. For
TransRepair,93.0%ofitstestinputsarevalid.Theseresultsshow
thatCATnotonlygeneratesmoretestinputs,butalsogenerates
more qualified test inputs for inconsistency bug detection.
3TheCohenâ€™sKappais0.96onaverage,whichindicatesthatourmanualinspection
results are highly consistent.Rememberthatweusesemanticevaluationtofilterwordcan-
didatestoimprovemutantvalidity.Thus,weareinterestedtoin-
vestigate the effectiveness of semantic evaluation. It turns out that
withoutsemanticevaluation,10.0%ofthetestinputsareinvalid4.
With semantic evaluation, this proportion is reduced to 3.5%. Thus,
semantic evaluationremoves (10%- 3.5%)/ 10%= 65%invalid test
inputs.
We further investigate the validity of test inputs on different
typesofmutants.Table1showstheresults.Ineachcell,thefirst/second
number is for the valid/total number of inputs belonging to the
corresponding type. The ratio in brackets is the proportion of valid
inputs. Interestingly, we observe that the â€œAdj.â€ mutant type has
thelowestvalidityforbothCATandTransRepair.Thisobservation
shows possibilities for further validity improvement for test input
generation in machine translation testing.
Overall, for RQ1, we have the following conclusion:
Answer to RQ1 : CAT outperforms TransRepair in the
quantity, distribution, diversity, and validity of the gen-
eratedtestinputs.Inparticular,CATgenerates 9,942test
inputs, covering 99.9%of the input sentences and 10types
of mutants, with a validity score of 96.5%based on man-
ualinspection.ForTransRepair,thesenumbersare4,692,
66.3%, 3, and 93.0%, respectively.
5.2 Effectiveness of Bug Detection (RQ2)
To answer RQ2, for each test input generated by CAT or Tran-
sRepair,wefeeditintoGoogleTranslateandTransformertoget
itstranslations,thenapplythesimilaritymetricstoautomatically
decide the test input reveals a bug.
Table2showsthenumberofbugsreportedbyCATandTransRe-
pairwitheachsimilaritymetric.WeobservethatCATsignificantly
outperforms TransRepair in the number of reported bugs. On aver-
age,CATdetects129%morebugsthanTransRepaironbothGoogle
Translate and Transformer.
We further investigate the diversity of the reported bugs. The
results are shown in Figure 5, where we select the reported bugs
ontheLCSsimilaritymetricasanexample.WeobservethatCAT
reports diverse bugs aroused by 1 0 types of part-of-speeches. Tran-
sRepaircanonlydetectthebugsfornouns,adjectives,andnumerals
but could hardly detect bugs aroused by the words in other part-of-
speeches.
The overall results are as expected because as shown by RQ1,
CAT generates a larger quantity of, more diverse, and more widely
distributed mutants than TransRepair, which contributes to its
overall bug detection ability.
Usingthesimilaritymetricasanapproximationoftestoracles,
asmentionedbySunetal.[ 32],mayhavedifferencewithhuman
oracles (i.e., human judgement about whether the translations are
consistent). To investigate such a threat, Sun et al. [ 32] sampled
sentencesandconductedmanualinspectiontogettheperformance
of oracle approximation. In this paper, following their work, we
4The Cohenâ€™s Kappa is 0.86.
1187
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:21:06 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Sun and Zhang, et al.
Table 1: Validity of test inputs on different typesofmutantsbasedo npart-of-speec h (RQ1).
Method Noun Adj. Adv. Num. Verb Deter. Conj. Pron. Prep. Others
TransRepair 83/92(90%) 16/20 (80%) 0/0 (0.0%) 86/87 (99%) 0/0 (0.0%) 0/0 (0.0%) 0/0 (0.0%) 0/0 (0.0%) 1/1 (100.0%) 0/0 (0.0%)
CAT 65/69(94%) 11/14 (79%) 11/11 (100%) 18/18 (100%) 29/29 (100%) 18/18 (100%) 6/6 (100%) 5/5 (100%) 24/24 (100%) 6/6 (100%)
Table 2: Number of reported bugs (RQ2).
Metric TransRepair CAT
GTLCS 2,198 5,109
ED 2,210 5,128
TFIDF 2,430 5,381
BLEU 2,126 4,852
TransformerLCS 1,957 4,545
ED 1,963 4,573
TFIDF 2,146 4,798
BLEU 1,897 4,325
050010001500
Noun Verb Prep. Num. Adj. Deter. Adv. Pron. Conj OthersNumber of detected bugsCAT (GT) CAT (Transformer) TransRepair (GT) TransRepair (Transformer)
Figure 5: Number of reported bugs ( ğ‘¦-axis) per mutant type
(ğ‘¥-axis). This figure shows that CAT reports more diverse
bugs than TransRepair.
uniformly sampled5100 test inputs for each approach. For each
sampled test input and its translation results, the first two authors
manuallycheckwhetherthetestinputandtheirtranslationsreveal
inconsistency bugs6, then compare the human judgement with the
judgement ofsimilarity metrics. Thepurpose isto check whether
usingthe similaritymetrictoreport bugsisa threattothe superi-
ority of CAT over TransRepair shown by Table 2.
We present the precision, recall, and F1-score of the manual
inspectionresults.Whencalculatingthesemetrics,falsepositive
(FP) means that the similarity metric judges the translations as
inconsistent (buggy) but manual inspection judges them as con-
sistent(non-buggy);falsenegative(FN)meansthatthesimilarity
metricjudgesthetranslationsasconsistent(non-buggy)butmanual
inspection says they are inconsistent (buggy).
The results show that for CAT, similarity metric has a precision
of 0.72, a recall of 0.90, and an F1 score of 0.80 on average. For
TransRepair,similarityhasaprecisionof0.70,arecallof0.95,andan
F1 score of 0.80 on average. These results indicate that the validity
of the bugs reported by CAT is similar to that by TransRepair.
TransRepair has slightly better recall than CAT. This is because
5Wesamplethetestcasethat revealsabugand thetestcasethatfail torevealabug
with equal probability.
6The Cohenâ€™s Kappa is 0.97 on average.manymutantsTransRepairgeneratedarevianumeralsreplacement
(asshownbyFigure4),whichinfluencethetranslationconsistency
less than other mutant types.
Overall,ourmanualinspectiondemonstratesthatthevalidityof
the bugs reported by CAT is similar to those reported by TransRe-
pair. Thus, using the similarity metric to report bugs is not a threat
to the superiority of CAT over TransRepair shown by Table 2.
Answer to RQ2 : CAT detects seven more types of bugs
thanTransRepairindiversity,aswellas 129%morebugs
than TransRepair in quantity.
5.3 Effectiveness of Bug Repair (RQ3)
Foreaseofcomparison,weletCATandTransRepairfixthesame
setofdetectedbugs,i.e.,thebugsdetectedbyCAT.Foreachbug,
we let CAT and TransRepair generate at most 16 mutants (the
mutantnumber upper boundforrepair introducedinSection4.3)
on both the original sentence and the mutant in the test case to
conductautomatictranslationrepair.ForTransformer,weusecross-
reference to conduct black-box repair, and predictive probability
to conduct grey-box repair. The predictive probability of Google
Translate is inaccessible, we thus only conduct black-box repair.
To answer RQ3, we first present the number of repaired bugs
accessed by similarity metrics. Then, we present the diversity ofrepair bugs aroused by the words in different part-of-speeches.
Finally,wepresentthetranslationimprovementaccessedbymanual
inspection.Repair effectiveness accessed by similarity metrics.
The re-
sultsareshowninTable3.Eachcellpresentsthenumberofrepaired
bugsbasedonthesimilaritymetrics,aswellastheproportionof
repaired bugs (against the total number of bugs detected by CAT).
TheupperrowsareforGoogleTranslate(GT),thebottomrowsare
for Transformer.
We observe that CAT repairs much more bugs than TransRepair.
Forexample,forGoogleTranslatewiththeLCSsimilaritymetric,
CATrepairs53%ofthereportedbugs,whileTransRepaironlyre-
pairs 17%. On average, CAT repairs 199% / 238% more bugs than
TransRepair onGoogleTranslate/Transformerwithblack-box re-
pair (using cross-reference), and 190% more bugs than TransRepair
on Transformer with grey-box repair (using probability).Diversity of repairedbugs.
We furtherinvestigate theeffective-
nessofCATindifferenttypesofrepairedbugsdetectedbythewordreplacementindifferentpart-of-speeches.Sincedifferenttypeshave
different numbers of reported bugs, we focus on the proportion of
repaired bugs against the number of reported bugs for each type.
1188
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:21:06 UTC from IEEE Xplore.  Restrictions apply. Improving Machine Translation Systems via
Isotopic ReplacementICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Table 3: Number and proportion of repaired bugs (RQ3).
Approach Metric Probability Cross-reference
TransRepair (GT)LCS - 890 (17%)
ED - 890 (17%)
TFIDF - 980 (18%)
BLEU - 886 (18%)
CAT (GT)LCS - 2,729 (53%)
ED - 2,730 (53%)
TFIDF - 2,741 (51%)
BLEU - 2,719 (56%)
TransRepair (Transformer)LCS 738 (16%) 684 (15%)
ED 744 (17%) 689 (15%)
TFIDF 810 (17%) 748 (16%)
BLEU 739 (17%) 708 (16%)
CAT (Transformer)LCS 2,193 (48%) 2,399 (53%)
ED 2,196 (48%) 2,399 (52%)
TFIDF 2,231 (47%) 2,415 (50%)
BLEU 2,176 (50%) 2,344 (54%)
0204060
Noun Verb Prep. Num. Adj. Deter. Adv. Pron. Conj. OthersProportion of repaired bugs (%)CAT (GT) CAT (Transformer) TransRepair (GT) TransRepair (Transformer)
Figure6:Proportionofrepairedbugsagainstthenumberof
reported bugs ( ğ‘¦-axis) per bug type ( ğ‘¥-axis).
TheresultsareshowninFigure67.WeobservethatCATachieves
alarger proportionof repaired bugsthanTransRepairamong all
bugtypes.Furthermore,wefindthatCATrepairs42%-64%/43%-
68%ofbugsonTransformer/GoogleTranslateamongallbugtypes.
TransRepair repairs 45% / 50% of bugs among numerals but only
5%-14% / 7%-18% of bugs among other bug types on Transformer /
Google Translate. TransRepair generates mutants for nouns, adjec-
tives, and numerals, but it can still repair bugs in other types. This
isbecausethesemanticsoftheunchangedpartyieldedbydifferent
types of replacement could be the same.
Validity of repaired translations. The first two authors manu-
ally check the bug fixes on the LCS similarity metric with cross-
reference on Transformer. The purpose is to check whether a bug
fixbased onthesimilarity metricindeedimproves thetranslation
consistency.
Although CAT aims to repair translation inconsistency, it has a
â€œbonusâ€ benefit of improving translation acceptability, which cap-
tures the property that a translation meets human assessment of a
reasonable(akaacceptable)translation.Thus,themanualinspec-
tionconsiderstwoaspects:1)theconsistencyoftranslationsbeforeand after repair; 2) the acceptability of the translations for the orig-
inal sentence as well as the mutants before and after repair. For
7We present the proportion of bugs repaired by cross-reference on the LCS similarity
metric as an exampleeachdimension,wesetupthreelabelsâ€œImprovedâ€,â€œUnchangedâ€,
and â€œDecreasedâ€. We randomly sampled 100 reported fixes. Foracceptability, it checks the translation improvement of both the
original sentence and the mutant, thus all together 200 inspections
are conducted.
Table 4: Manual inspection results on reported fixes (RQ3)
Aspect Improved Unchanged Decreased
TransRepairConsistency 87 12 1
Acceptability 32 149 19
CATConsistency 93 7 0
Acceptability 32 153 15
Table 4 shows the results8. From this table, for consistency
improvement, CAT successfully improves the consistency for 93
(93%) fixes, the remaining 7 (7%) fixes have unchanged consistency.
WhereasforTransRepair,itimprovestheconsistencyfor87(87%)
fixes,12(12%)fixeshaveanunchangedconsistency,1(1%)casehas
a dropped consistency. For the improvement in translation accept-
ability, CAT improves the translation acceptability for 32 (16.0%)sentences, with 15 (7.5%) sentencesâ€™ acceptability being dropped
(duetopossibletrade-offbetweenqualityandconsistencyaswell
as the incorrect alignment from the word alignment tool during
repair).TransRepairimprovesacceptabilityforthesamenumber
of sentences (32), but leads to decreased acceptability for 19 (9.5%)
cases.
Table 5 shows some examples of translations that could be re-
paired by onlyCAT (TransRepair could repair none of them). In
this table, the first column is the input sentence. The second col-
umn is the Chinese translation of the input as well as the detected
translation bug (explained in blue text). The last column shows the
repaired translations.
AnswertoRQ3 :CATrepairstwicemorebugsthanTran-
sRepair. For diversity, CAT repairs approximately halfof the bugs under each bug type, whereas TransRepair
achieves competitive performance on only numerals (53%
for CATv.s. 47% for TransRepair),failing to repair 89% ofthe bugs under other types.
5.4 Efficiency (RQ4)
ToanswerRQ4,werecordthetimecostofCATandTransRepair
during the process of mutant generation, bug detection, and bugrepair. The results are shown in Table 6. Overall, both CAT and
TransRepairhavegoodefficiencyunderourconfiguration(seemore
details in Section 4.3) in their automatic testing and repair tasks.
This high efficiency is important to guarantee that end users do
notneedtowaitforalongtimetogetthefinalrepairedtranslation
while using machine translators on line.
Specifically,formutantgeneration,themeantimecostis0.01s
permutantforCATand0.41sforTransRepair.Thereasonisthat
8The Cohenâ€™s Kappa score of the translation acceptability and translation consistency
are 0.96 and 0.97, respectively.
1189
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:21:06 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Sun and Zhang, et al.
Table 5: Examples of buggy translations that CAT can repair whereas TransRepair cannot.
Original input sentence Originaltranslationandthebug(explainedinblue
text)Repaired translation
Around140,000peoplehaveaheartattackinEng-
landeveryyear,andaquarterofthesegoontohave
another attack or a stroke.æ¯å¹´åœ¨è‹±å›½çº¦æœ‰140ä¸‡äººå¿ƒè„ç—…å‘ä½œï¼Œå…¶ä¸­å››åˆ†ä¹‹ä¸€
ç»§ç»­å‘ä½œæˆ–ä¸­é£ã€‚ [Bug:â€œ140,000â€isincorrectlytrans-
lated to â€œ1.4 millionâ€]æ¯å¹´åœ¨è‹±å›½çº¦æœ‰140,000 äººå¿ƒè„ç—…å‘ä½œï¼Œå…¶ä¸­å››
åˆ†ä¹‹ä¸€ç»§ç»­å‘ä½œæˆ–ä¸­é£ã€‚[â€œ140,000â€ is correctly
translated to â€œ140,000â€.]
Your patience never fails to disappoint me. ä½ çš„è€å¿ƒæ°¸è¿œä¸ä¼š è®©æˆ‘å¤±æœ›[Bug: â€œnever fails toâ€ is
incorrectly translated to its opposite meaning â€œ æ°¸è¿œä¸
ä¼šâ€, which means â€œneverâ€.]ä½ çš„è€å¿ƒæ€»æ˜¯è®©æˆ‘å¤±æœ›[â€œnever failsâ€ is correctly
translated to â€œæ€»æ˜¯â€.]
Therehemanagedpresidentialprotocolandgovern-
ment staff, the Kremlin website says (in Russian ).å…‹é‡Œå§†æ—å®«ç½‘ç«™è¯´ï¼Œä»–åœ¨é‚£é‡Œç®¡ç†ç€æ€»ç»Ÿåè®®å’Œæ”¿
åºœå·¥ä½œäººå‘˜ã€‚ [Bug:â€œin Russianâ€ is not translated.]é‚£é‡Œï¼Œä»–ç®¡ç†äº†æ€»ç»Ÿåè®®å’Œæ”¿åºœå·¥ä½œäººå‘˜ï¼Œå…‹é‡Œ
å§†æ—å®«ç½‘ç«™è¯´ï¼ˆä¿„æ–‡ ï¼‰ã€‚[â€œin Russianâ€ is correctly
translated to â€œä¿„æ–‡â€.]
TransRepair uses Stanford Parser to parse each sentence for apply-
ing word replacement as well as filtering mutant candidates. CAT
directlyusestheinferenceoftheBERTmodel.Itavoidstheparsing
process, thereby greatly improving the efficiency.
Table 6: Efficiency of CAT and TransRepair (RQ4).
Approach TransRepair CAT
Mutantgeneration 0.41s0.01s
Bug detection 0.99s0.27s
Bug Repair 1.34s1.92s
The lower cost of CAT in mutant generation also contributes
to itslower costin bugdetection: CAT needs0.27s onaverage for
examining each sentence to report bugs, while TransRepair needs
0.99s.
For each reported bug, CAT spends 1.92s to conduct the auto-
matic repair, TransRepair spends 1.34s. The reason is that Tran-sRepair is not able to generate many mutants when fixing a bug,
yet each mutant requires a fetch of translation from Google Trans-
late/Transformerfortherepairprocess.Consequently,itstimespent
on each bug is lower than CAT. However, this lower time comes at
a significant cost: most bugs could not be repaired successfully (as
we have observed in RQ2) due to the insufficiency of mutants.
The overall results lead to the following conclusion:
Answerto RQ4 : CAT is significantly more efficient than
TransRepairinmutantgeneration(0.01sv.s.0.41s)andbug
detection (0.27s v.s. 0.99s). CAT has comparable efficiency
(slightlyworse)withTransRepairinbugrepair(1.92sv.s.
1.34s),whichisattributedtothelargernumberofmutants
that it employs.
6 EXTENDED ANALYSIS
In this section, we provide an analysis beyond the scope of our
research questions that can improve the understanding and better
explain the effectiveness of CAT.6.1 Comparison with Other Translation
Testing Approaches
AsintroducedinSection2,apartfromTransRepair,therearealso
some other translation testing approaches. This section explores
their effectiveness and discusses their differences with CAT.
We compare CAT (with LCS metric) with three most recently
publishedtestingmethods:SIT[ 15],PatInv[ 12],andPurity[ 16].For
SIT,PatInv,andPurityweusedtheirreleasedcodeandparameterise
themaccordingtotheirbestperformingparameters,asshownby
theirpapers.Table7presentsthenumberofbugsdetectedbythesefourapproachesonGoogleTranslate(GT)andTransformer.Ascanbe seen by these results, CAT and SIT detect many more bugs than
TransRepair, PatInv, and Purity.
Table 7: Number of reported bugs for different machine
translation testing methods.
Translator TransRepair SIT PatInv Purity CAT
GT 2,198 5,576 82 3,459 5,109
Transformer 1,957 5,368 99 3,518 4,545
These bugs are reported according to each approachâ€™s own test
oracles.Thus,theyhavevariousbugtypes,notnecessarilyinconsis-tency bugs. To explore the possibility of employing these approachforthesamepurposeofCAT(i.e.,todetectinconsistencybugs),we
further conduct a manual inspection on the bugs each approach
reported, and report their validity in detecting inconsistency bugs.
To this end, the first two authors manually inspected9the reported
bugs and checked whether they actually exposed inconsistencytranslationissues.TheresultsofthisanalysisarerecordedinTa-ble 8. In this table, false positive (FP) means that the approachreports the translations as problematic (buggy) but the manualinspection actually finds out that it is correct, i.e., it is not a bug.False negative (FN) means that the approach reports the transla-tions as non-buggy but the manual inspection reveals that it isactually problematic (it is a bug). We observe that CAT achievesa significantly higher F1-score than SIT, PatInv, and Purity. Thisis not surprising considering that SIT, PatInv, and Purity aim to
detect different types of bugs.
9The Cohenâ€™ Kappa score of SIT / PatInv / Purity is 0.94 / 0.89 / 0.92, respectively.
1190
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:21:06 UTC from IEEE Xplore.  Restrictions apply. Improving Machine Translation Systems via
Isotopic ReplacementICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Table 8: Validity of reported bugs for different translation
testing methods.
Approach TN FN FP TP Precision Recall F1
TransRepair 0.48 0.02 0.15 0.35 0.70 0.95 0.80
SIT 0.28 0.22 0.33 0.17 0.34 0.44 0.38
PatInv 0.27 0.23 0.47 0.03 0.06 0.12 0.08
Purity 0.42 0.08 0.29 0.21 0.42 0.72 0.53
CAT 0.46 0.04 0.15 0.35 0.70 0.90 0.79
6.2 Influence of Mutant Number on Bug
Testing and Repair
Inourexperiment,followingthepreviouswork,wesetthemaxi-
mummutantnumberto5forbugdetection,andto16forbugrepair.
Hereweinvestigatetheinfluenceofthisboundonthenumberof
detected and repaired bugs.
Forbugdetection,werepeattheexperimentswithatmost1or3
mutantspersentence.Table9showsthenumberofbugsdetectedby
CAT and TransRepair when using different upper bounds (number
ofmutants)onthefourmetrics.Wefindthatahighernumberof
mutantsleadstoahighernumberofdetectedbugsforbothCAT
and TransRepair. Notably, CAT detects approximately twice thebugs as those detected by TransRepair for all the three different
bounds we examined.
Table 9: Influence of the upper bound of mutant number in
bug detection.
MetricTransRepair CAT
13 5 13 5
LCS 5751,385 1,957 1,0322,707 4,545
ED 5761,389 1,963 1,0362,728 4,573
TFIDF 6271,511 2,146 1,0492,861 4,798
BLEU 5531,340 1,897 1,0012,577 4,325
For bug repair, we repeat the experiments with a maximum
numberof4or8mutants.Table10recordstherelatedresults.As
can be seen, no matter what upper bound we use, CAT repairs
morethanthreetimesthenumberofbugsrepairedbyTransRepair.Interestingly,weobservethatevenwith4mutants,CATcanstillfix
143%morebugsthanTransRepairwith16mutants.Thisisbecause
TransRepairfailstogeneratemutantsformanysentences(aswe
have observed from Figure 3), thus it is not able to repair any of
the bugs falling into these cases.
7 THREATS TO VALIDITY
Threats to external validity mainly lie in the evaluation dataset
and the models we used. First, though our approach applies todifferent datasets and translation models, so far, we follow Tran-sRepair [
32] and have only implemented and evaluated it on the
same2,001sentencesandtwotranslationmodels.Sofuturework
is needed to understand the performance of CAT on other datasets
andmodels.Second,thoughweonlyuseBERTmodel[ 5]toextractTable10:Influenceoftheupperboundofmutantnumberin
bug repair.
MetricTransRepair CAT
481 6 481 6
LCS 516 605 684 1,724 2,117 2,399
ED 526 611 689 1,728 2,141 2,399
TFIDF 584 678 748 1,747 2,139 2,415
BLEU 536 635 708 1,667 2,053 2,344
the context-aware word embeddings, our approach is still compati-
blewithothercontext-awareembeddingmodels(e.g.,Roberta[ 22]).
This is a future work to be explored.
Threatstointernalvalidity mainlylieinourmanualassessment.
We follow TransRepair [ 32] and use the same human evaluation
criteria.Tofurtherreducethebiaswhencomparingdifferentmeth-
ods, we randomised the sentences/test inputs to guarantee thatthe method each sentence belongs to remains unknown to theauthors. The high kappa scores indicate that the bias in human
evaluation is minor. We also release the details of human labelling
on Github (available at https://github.com/zysszy/CAT) to improve
the transparency and replicability.
8 CONCLUSION
We propose CAT, an isotopic replacement based approach to im-
proving machine translation. As a special type of replacement, iso-
topicreplacementsubtlycontrolstheimpactwhenreplacingwords.
Thisisachievedbyusinganeural-basedlanguagemodeltoencode
the sentence context and designing another neural-network-based
algorithmtoevaluatecontext-awaresemanticsimilaritybetween
twowords.SuchreplacementisthenusedinasimilarwayasTran-
sRepair to detect and repair translation bugs. The experimental
resultsonGoogleTranslateandTransformershowthatCATsuc-
cessfullydetects129%/129%morebugsandrepairs199%/238%more
bugs than TransRepair on Google Translate/Transformer.
For future work, we plan to investigate other oracle approxi-
mationtechniquestofurtherimproveCATâ€™sperformanceinbug
detection and repair.
ACKNOWLEDGMENTS
ZeyuSun,YingfeiXiong,andLuZhangaresponsoredbytheNa-
tional Key Research and Development Program of China under
GrantNo.2019YFE0198100,theInnovationandTechnologyCom-
mission of HKSAR under Grant No. MHP/055/19, and National
NaturalScienceFoundationofChinaunderGrantNo.61922003.Jie
M.ZhangandMarkHarmanaresupportedbytheERCadvanced
grant with No. 741278. Mike Papadakis is supported by the Lux-
embourg National Research Fund (FNR) through the CORE project
C17/IS/11686509/CODEMATES.
REFERENCES
[1][n.d.]. The worst translation mistake in history. https://pangeanic.co.uk/
knowledge/the-worst-translation-mistake-in-history/
[2]YonatanBelinkovandYonatanBisk.2018. Syntheticandnaturalnoisebothbreak
neural machine translation. In Proc. ICLR.
1191
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:21:06 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Sun and Zhang, et al.
[3]Jialun Cao, Meiziniu Li, Yeting Li, Ming Wen, and Shing-Chi Cheung. 2020.
SemMT: A Semantic-based Testing Approach for Machine Translation Systems.
CoRRabs/2012.01815 (2020). arXiv:2012.01815 https://arxiv.org/abs/2012.01815
[4]YongCheng,LuJiang,andWolfgangMacherey.2019. RobustNeuralMachine
TranslationwithDoublyAdversarialInputs.In Proceedingsofthe57thConference
of the Association for Computational Linguistics, ACL 2019, Florence, Italy, July
28- August 2, 2019, Volume 1: Long Papers. 4324â€“4333. https://www.aclweb.org/
anthology/P19-1425/
[5]JacobDevlin,Ming-WeiChang,KentonLee,andKristinaToutanova.2019. BERT:Pre-trainingofDeepBidirectionalTransformersforLanguageUnderstanding.In
Proceedingsof the2019 Conferenceof theNorthAmerican Chapterof theAssocia-
tionforComputationalLinguistics:HumanLanguageTechnologies,NAACL-HLT
2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers), Jill
Burstein,ChristyDoran,andThamarSolorio(Eds.).AssociationforComputa-
tional Linguistics, 4171â€“4186. https://doi.org/10.18653/v1/n19-1423
[6]AlexeyDosovitskiy,LucasBeyer,AlexanderKolesnikov,DirkWeissenborn,Xi-
aohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. 2020. An Imageis Worth 16x16 Words: Transformers for Image Recognition at Scale. CoRR
abs/2010.11929 (2020). arXiv:2010.11929 https://arxiv.org/abs/2010.11929
[7]JavidEbrahimi,AnyiRao,DanielLowd,andDejingDou.2018. HotFlip:White-
Box Adversarial Examples for Text Classification. In Proceedings of the 56th
Annual Meeting of the Association for Computational Linguistics (Volume 2: Short
Papers). Association for Computational Linguistics, Melbourne, Australia, 31â€“36.
https://doi.org/10.18653/v1/P18-2006
[8]Silvia P Gennari, Maryellen C MacDonald, Bradley R Postle, and Mark S Seiden-
berg. 2007. Context-dependent interpretation of words: Evidence for interactive
neural processes. Neuroimage 35, 3 (2007), 1278â€“1286.
[9]CarloGiglioandRichardCaulk.1965. Article17oftheTreatyofUccialli. Journal
of African History (1965), 221â€“231.
[10] Google. 2021. Google Translate. http://translate.google.com.[11]
Chuan Guo, Alexandre Sablayrolles, HervÃ© JÃ©gou, and Douwe Kiela. 2021.Gradient-based Adversarial Attacks against Text Transformers. In Proceed-
ings of the 2021 Conference on Empirical Methods in Natural Language Pro-cessing, EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 7-11November, 2021, Marie-Francine Moens, Xuanjing Huang, Lucia Specia, and
Scott Wen-tau Yih (Eds.). Association for Computational Linguistics, 5747â€“5757.
https://aclanthology.org/2021.emnlp-main.464
[12]Shashij Gupta, Pinjia He, Clara Meister, and Zhendong Su. 2020. Machinetranslation testing via pathological invariance. In ESEC/FSE â€™20: 28th ACM
Joint European Software Engineering Conference and Symposium on the Foun-
dationsofSoftwareEngineering,VirtualEvent,USA,November8-13,2020,Pr em
Devanbu, Myra B. Cohen, and Thomas Zimmermann (Eds.). ACM, 863â€“875.
https://doi.org/10.1145/3368089.3409756
[13]HanyHassan,AnthonyAue,ChangChen,VishalChowdhary,JonathanClark,
Christian Federmann, Xuedong Huang, Marcin Junczys-Dowmunt, WilliamLewis, Mu Li, et al
.2018. Achieving human parity on automatic chinese to
english news translation. arXiv preprint arXiv:1803.05567 (2018).
[14]KimHazelwood,SarahBird,DavidBrooks,SoumithChintala,UtkuDiril,Dmytro
Dzhulgakov, Mohamed Fawzy, Bill Jia, Yangqing Jia, Aditya Kalro, James Law,Kevin Lee, Jason Lu, Pieter Noordhuis, Misha Smelyanskiy, Liang Xiong, and
Xiaodong Wang. 2018. Applied Machine Learning at Facebook: A Datacenter
Infrastructure Perspective. In 24th International Symposium on High-Performance
Computer Architecture (HPCA 2018), February 24-28, Vienna, Austria.
[15]Pinjia He, Clara Meister, and Zhendong Su. 2020. Structure-invariant testing for
machinetranslation.In 2020IEEE/ACM42ndInternationalConferenceonSoftware
Engineering (ICSE). IEEE, 961â€“973.
[16]PinjiaHe,ClaraMeister,andZhendongSu.2021. TestingMachineTranslation
via Referential Transparency. In 2021 IEEE/ACM 43rd International Conference on
Software Engineering (ICSE). IEEE, 410â€“422.
[17]Georg Heigold, Stalin Varanasi, GÃ¼nter Neumann, and Josef van Genabith. 2018.
HowRobustAreCharacter-BasedWordEmbeddingsinTaggingandMTAgainst
Wrod Scramlbing or Randdm Nouse?. In Proceedings of the 13th Conference of
the Association for Machine Translation in the Americas, AMTA 2018, Boston, MA,
USA, March 17-21, 2018 - Volume 1: Research Papers. 68â€“80. https://aclanthology.
info/papers/W18-1807/w18-1807
[18]Yue Jia and Mark Harman. 2011. An Analysis and Survey of the Development of
Mutation Testing. IEEE Transactions on SoftwareEngineering 37, 5 (Septemberâ€“
October 2011), 649 â€“ 678.
[19]DiJin,ZhijingJin,JoeyTianyiZhou,andPeterSzolovits.2020. IsBERTReally
Robust?AStrongBaselineforNaturalLanguageAttackonTextClassification
andEntailment.In TheThirty-FourthAAAIConferenceonArtificialIntelligence,
AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence
Conference,IAAI2020,TheTenthAAAISymposiumonEducationalAdvancesin
ArtificialIntelligence,EAAI2020,NewYork,NY,USA,February7-12,2020.AAAI
Press, 8018â€“8025. https://aaai.org/ojs/index.php/AAAI/article/view/6311
[20]Linyang Li, Ruotian Ma, Qipeng Guo, Xiangyang Xue, and Xipeng Qiu. 2020.
BERT-ATTACK:AdversarialAttackAgainstBERTUsingBERT.In Proceedingsof the 2020 Conference on Empirical Methods in Natural Language Processing,
EMNLP 2020, Online, November 16-20, 2020, Bonnie Webber, Trevor Cohn, Yulan
He,andYangLiu(Eds.).AssociationforComputationalLinguistics,6193â€“6202.
https://doi.org/10.18653/v1/2020.emnlp-main.500
[21] Xin Li,Lidong Bing,WenxuanZhang, andWai Lam.2019. ExploitingBERT for
End-to-EndAspect-basedSentimentAnalysis.In Proceedingsofthe5thWorkshop
on Noisy User-generated Text (W-NUT 2019). 34â€“41.
[22]YinhanLiu,MyleOtt,NamanGoyal,JingfeiDu,MandarJoshi,DanqiChen,Omer
Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. Roberta: Arobustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692
(2019).
[23]YangLiuandMaosongSun.2015. Contrastiveunsupervisedwordalignmentwith
non-local features. In Twenty-Ninth AAAI Conference on Artificial Intelligence.
[24]John X. Morris, Eli Lifland, Jin Yong Yoo, Jake Grigsby, Di Jin, and Yanjun Qi.
2020. TextAttack:AFrameworkforAdversarialAttacks,DataAugmentation,and
Adversarial TraininginNLP. In Proceedingsof the2020 Conferenceon Empirical
Methods in Natural Language Processing: System Demonstrations, EMNLP 2020
- Demos, Online, November 16-20, 2020, Qun Liu and David Schlangen (Eds.).
AssociationforComputationalLinguistics,119â€“126. https://doi.org/10.18653/
v1/2020.emnlp-demos.16
[25]Mike Papadakis, Marinos Kintis, Jie Zhang, Yue Jia, Yves Le Traon, and Mark
Harman.2019. Mutationtestingadvances:ananalysisandsurvey. In Advances
in Computers. Vol. 112. Elsevier, 275â€“378.
[26]Jeffrey Pennington, Richard Socher, and Christopher Manning. 2014. Glove:
Globalvectorsforwordrepresentation.In Proceedingsofthe2014conferenceon
empirical methods in natural language processing (EMNLP). 1532â€“1543.
[27]DanielPesu,ZhiQuanZhou,JingfengZhen,and DaveTowey.2018. AMonte
Carlo Method for Metamorphic Testing of Machine Translation Services. In 3rd
IEEE/ACMInternationalWorkshoponMetamorphicTesting,MET2018,Gothenburg,Sweden,May27,2018.ACM,38â€“45. http://ieeexplore.ieee.org/document/8457612
[28]FanchaoQi,YuanYao,SophiaXu,ZhiyuanLiu,andMaosongSun.2021. Turnthe
CombinationLock:LearnableTextualBackdoorAttacksviaWordSubstitution.
InProceedings of the 59th Annual Meeting of the Association for Computational
Linguisticsandthe11thInternationalJointConference onNaturalLanguagePro-
cessing,ACL/IJCNLP2021,(Volume1:LongPapers),VirtualEvent,August1-6,2021,
Chengqing Zong, Fei Xia, Wenjie Li, and Roberto Navigli (Eds.). Association
for Computational Linguistics, 4873â€“4883. https://doi.org/10.18653/v1/2021.acl-
long.377
[29] SpaCy. 2019. SpaCy. https://spacy.io/.[30]
Matthias Sperber, Jan Niehues, and Alex Waibel. 2017. Toward robust neuralmachine translation for noisy input sequences. In International Workshop on
Spoken Language Translation (IWSLT).
[31]Liqun Sun and Zhi Quan Zhou. 2018. Metamorphic testing for machine trans-lations: MT4MT. In 2018 25th Australasian Software Engineering Conference
(ASWEC). IEEE, 96â€“100.
[32]Zeyu Sun, Jie M. Zhang, Mark Harman, Mike Papadakis, and Lu Zhang. 2020.
Automatic testing and improvement of machine translation. In ICSE. 974â€“985.
https://doi.org/10.1145/3377811.3380420
[33]Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
AidanNGomez,ÅukaszKaiser,andIlliaPolosukhin.2017. Attentionisallyou
need.InProceedings of the 31st International Conference on Neural Information
Processing Systems. Curran Associates Inc., 6000â€“6010.
[34] Wikipedia. 2014. Wikipedia. https://dumps.wikimedia.org/.[35]
WMT.2018.News-Commentary.http://data.statmt.org/wmt18/translation-task/.
[36]ThomasWolf,LysandreDebut,VictorSanh,JulienChaumond,ClementDelangue,
Anthony Moi, Pierric Cistac, Tim Rault, RÃ©mi Louf, Morgan Funtowicz, Joe
Davison,SamShleifer,PatrickvonPlaten,ClaraMa,YacineJernite,JulienPlu,
CanwenXu,TevenLeScao,SylvainGugger,MariamaDrame,QuentinLhoest,
and Alexander M. Rush. 2020. Transformers: State-of-the-Art Natural Language
Processing.In Proceedingsofthe2020ConferenceonEmpiricalMethodsinNatural
Language Processing: System Demonstrations. Association for ComputationalLinguistics, Online, 38â€“45. https://www.aclweb.org/anthology/2020.emnlp-
demos.6
[37]YuanZang,FanchaoQi,ChenghaoYang,ZhiyuanLiu,MengZhang,QunLiu,and
Maosong Sun. 2020. Word-level Textual Adversarial Attacking as Combinatorial
Optimization. In Proceedings of the 58th Annual Meeting of the Association for
Computational Linguistics, ACL 2020, Online, July 5-10, 2020, Dan Jurafsky, Joyce
Chai,NatalieSchluter,andJoelR.Tetreault(Eds.).AssociationforComputational
Linguistics, 6066â€“6080. https://doi.org/10.18653/v1/2020.acl-main.540
[38]Jie M Zhang, Mark Harman, Lei Ma, and Yang Liu. 2019. Machine Learning
Testing:Survey,LandscapesandHorizons. arXivpreprintarXiv:1906.10742 (2019).
[39]Zhengli Zhao, Dheeru Dua, and Sameer Singh. 2017. Generating Natural
Adversarial Examples. CoRRabs/1710.11342 (2017). arXiv:1710.11342 http:
//arxiv.org/abs/1710.11342
[40]WangchunshuZhou,TaoGe,KeXu,FuruWei,andMingZhou.2019. BERT-based
lexical substitution. In Proceedings of the 57th Annual Meeting of the Association
for Computational Linguistics. 3368â€“3373.
1192
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:21:06 UTC from IEEE Xplore.  Restrictions apply. 