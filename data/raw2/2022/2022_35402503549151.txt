Semi-supervisedPre-processing forLearning-BasedTraceability
Framework onReal-WorldSoftwareProjects
Liming Dong
StateKey Laboratory of Novel
SoftwareTechnology, Software
Institute, Nanjing University
Nanjing,Jiangsu,China
limingdongmongol@163.comHe Zhang
StateKey Laboratory of Novel
SoftwareTechnology, Software
Institute, Nanjing University
Nanjing,Jiangsu,China
hezhang@nju.edu.cnWei Liu
StateKey Laboratory of Novel
SoftwareTechnology, Software
Institute, Nanjing University
Nanjing,Jiangsu,China
mf20320093@smail.nju.edu.cn
Zhiluo Weng
StateKey Laboratory of Novel
SoftwareTechnology, Software
Institute, Nanjing University
Nanjing,Jiangsu,China
mf21320156@smail.nju.edu.cnHongyuKuang
StateKey Laboratory of Novel
SoftwareTechnology, Software
Institute, Nanjing University
Nanjing,Jiangsu,China
khy@nju.edu.cn
ABSTRACT
The traceability of software artifacts has been recognized as an
important factor to support various activities in software devel-
opmentprocesses.However,traceabilitycanbedifficultandtime-
consuming to create and maintain manually, thereby automated
approaches have gained much attention. Unfortunately, existing
automated approaches for traceability suffer from practical issues.
This paper aims to gain an understanding of the potential chal-
lengesfortheunderperformingofthestate-of-the-art,ML-based
tracelinkclassifiersappliedinreal-worldprojects.Byinvestigating
differentindustrialdatasets,wefoundthattwocritical(andclassic)
challenges,i.e.dataimbalanceandsparseproblems,lieinreal-world
projectsâ€™ traceability automation. To overcome these challenges,
we developed a framework called SPLINT to incorporate hybrid
textualsimilaritymeasuresandsemi-supervisedlearningstrategies
asenhancementstothelearning-basedtraceabilityapproaches.We
carried out experiments with six open-source platforms and ten in-
dustry datasets. The results confirm that SPLINT is able to operate
at higher performance on two communitiesâ€™datasets. Specifically,
theindustrial datasets, whichsignificantly sufferfromdataimbal-
ance and sparsity problems, show an increase in F2-score over 14%
and AUC over 8% on average. The adjusted class-balancing and
self-trainingpoliciesusedinSPLINT(CBST-Adjust)alsoworkef-
fectivelyfortheselectionofpseudo-labelsonminorclassesfrom
unlabeledtrace sets,demonstrating SPLINTâ€™s practicability.
CCS CONCEPTS
Â·Software andits engineering â†’Maintaining software .
Permissionto make digitalor hard copies of allorpart ofthis work for personalor
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACM
mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,
topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ESEC/FSE â€™22, November 14Å›18,2022, Singapore, Singapore
Â©2022 Associationfor Computing Machinery.
ACM ISBN 978-1-4503-9413-0/22/11...$15.00
https://doi.org/10.1145/3540250.3549151KEYWORDS
SoftwareTraceability,Semi-supervisedLearning,Learning-based
Model,Industry Practice,Data Imbalance,Data Sparsity
ACMReference Format:
Liming Dong, He Zhang, Wei Liu, Zhiluo Weng, and Hongyu Kuang. 2022.
Semi-supervisedPre-processingforLearning-BasedTraceabilityFramework
on Real-World Software Projects. In Proceedings of the 30th ACM Joint Euro-
peanSoftwareEngineeringConferenceandSymposiumontheFoundations
of Software Engineering (ESEC/FSE â€™22), November 14Å›18, 2022, Singapore,
Singapore. ACM, New York, NY, USA, 13pages.https://doi.org/10.1145/
3540250.3549151
1 INTRODUCTION
SoftwaretraceabilityreferstoÅ‚ theabilitytointerrelateanyuniquely
identifiablesoftwareengineeringartifacttoanyother,maintainre-
quired links over time, and use the resulting network to answer ques-
tions of both the software product and development process Å¾ [29]1.
Softwaretraceabilitycanfacilitatetasksinallphasesofthesoftware
andsystemsengineeringlifecycle,providingforbothproductiv-
ityandqualitygains[ 28,60].Withtheimprovementofsoftware
traceabilityasaprimaryconcern,theresearchersandprojectstake-
holderscanbefreetofocusonotheractivitiesanddecisionsthat
utilise their skills and knowledge. Achieving affordable traceability
willbecomecriticaltosoftwareprojectmanagementbysupport-
ing tasks including requirements reuse and validation [ 19], change
management[ 52],projectandriskmanagement[ 54],bugpredic-
tionandlocalization [ 57],testcases prioritizing[ 36].Traceability
of software process data can facilitate the construction of a sim-
ulation model that resembles real-world software processes and
canbeofspecialassistancetoprojectmanagersforplanningand
decisionsupportduringtheearlystagesofthedevelopmentlifecy-
cle[3,42].Insuchcases,softwaretraceabilityisafundamentalpart
of project management and quality assurance practice, which sup-
portsbothresearchersandpractitionerstoincreasemaintainability
andreliabilityofsoftware systemsandprocesses [ 18,55,66,68].
1CoEST:Center of excellence for softwaretraceability
570
ESEC/FSE â€™22, November14Å›18, 2022,Singapore, Singapore Liming Dong,He Zhang,WeiLiu, ZhiluoWeng, andHongyu Kuang
Unfortunately, researchers have also found that high-quality
trace links are difficult to manually recover and maintain [ 25] due
to the large size of potential trace links among different artifacts
(e.g.,requirements,issues,andcode),andthefrequentchangesin
software artifacts caused by a more iterative development process.
Theubiquitousadoptionofversioncontrolsystems(e.g.,GitHub)
and issue tracking systems (e.g., Jira) is now the common practice
for developers to tag code commits with issue IDs during their
daily development tasks in a real-world project managed by the
software repository. These explicitly tagged trace links between
source code (e.g., recorded by commits) and system functionalities
(e.g., described by issues tagged with "New Feature" or "Bug") thus
lay a good foundation for learning-based approaches to support
automated traceability tasks for real-worldprojects, indicating an
appreciable save of human efforts when the project keeps evolving.
Totacklethisproblem,asignificantamountofresearchhasbeen
conducted with a goal of helping developers recover traceability
automatically[ 12,22,73].Theseincludeprobabilisticapproaches[ 5,
51], information retrieval (IR) techniques (the Vector Space Model
(VSM) [4], Latent Semantic Indexing (LSI) [ 47], Latent Dirichlet
Allocation (LDA) [ 7], Jenson Shannon model (JS) [ 1], etc.) and
learning-based approaches (machine learning [ 21,50] and deep
learning[ 30,43,62])to recover the missingtrace links.
Advancesinautomatictraceabilitytechniqueshavebeenachieved
and most of them evaluated in OSS projects [ 43,59,62] and also
gradually applied to industrial projects with positive improve-
ments [30,51,61]. Many existing studies use datasets gathered
either from the Center of Excellence for Software & System Trace-
ability2(e.g., academic-led projects)or fromfree and opensource
(OSS) community projects [ 32,58,73]. We found, however, that au-
tomated traceability techniques are not well validated empirically,
especially in industrial environments. Even with rapid progress in
learning-based technologies, industry partners are struggling to
integrateautomatedtraceabilitypracticesandintegratetheminto
theirdevelopmentprocesses[ 48].Therefore,westilllackenough
knowledge about the practical reasons for underperformance of
automatedtraceability approachesinindustrialprojects.
Thus, the goal of this study is to evaluate the effectiveness of
learning-based automated traceability approaches in real-world
projects. In order to better understand how automated traceability
worksfordifferenttypesofprojectsindifferentcommunities,we
firstevaluatetheperformanceoflearning-basedtrace-linkclassi-
fiers using six OSS projects from GitHub [ 59], and ten industrial
projects from our collaborative organization. We seek to charac-
terize the severity of the underperforming trace-link classifier and
to identify potential problems for outcome prediction through our
study.Fromtheanalysisofoverallperformanceondifferentcom-
munitiesâ€™(i.e.OSSandindustrial)datasets,weobservedthattwo
classic challengesare most relevant to hinderreal-worldprojectsâ€™
traceability prediction:data imbalance andsparseness.
To meet these two challenges in traceability research, we found
that the semi-supervised learning (SSL) algorithm is efficient to
solvetheproblemsofbothimbalancedlabelsandinsufficientsample
labels for many practical applications at the same time [ 72]. In
particular, SSL algorithms can be used to augment the training set
2http://coest.org/withunlabelledsampleswhenthelabeleddataissparse.Inthiscase,
theaddedsamplesareassignedpseudo-labelsbasedontheoriginal
labelled data model. SSL has also been extensively studied in class
imbalance scenarios in recent research. Researchers [ 34,67,70]
suggestthatleveraging unlabeled databySSL and self-supervised
learningcan benefitclass-imbalancedlearning.
Hence,inlightoftheaboveissues,wepresentedaframework
based on the Semi-Supervised Pre-processing for LearnINg-based
Traceability (SPLINT) to address the data imbalance and sparsity
problemthatexistinlearning-basedtraceabilityapproaches,and
furtherenhancethetraceabilityscenariosforreal-worldsoftware
projects.WeemployedSSL[ 34,70]toupdatethetrainingsetand
adjustedclass-balancingself-training(CBST-Adjust)strategiesto
rebalancethetrainingsetdistribution.Further,toaddressdataspar-
sity in the feature matrix of trace-link classifier, we evaluated how
features contribute in theprojects from both communities, respec-
tively. The result shows that textual information from software
artifacts in industrial projects accounts for the most important fea-
tures.Thus,weinvestigatedthesemanticsofsoftwareartifactsand
mergedhybridIR-basedtextual similaritymeasures intoSPLINT.
ToevaluatetheeffectivenessofSPLINT,wecomparedSPLINT
withtwostate-of-the-arttraceabilityapproaches(i.e.pureIR-based
approachandclassictracelinksclassifiers[ 59])ontenindustrial
projectsandsixOSSprojects.OurevaluationshowsthatSPLINT
achievesanaverage29.70%betterF2and17.04%betterAUCacross
the six OSS projects, and 20.1% better F2 and 13.05% better AUC
across 10 industrial projects than the VSM model. Further, SPLINT
configuration achieves an average 0.93% better F2 and 0.76% better
AUC value across the six OSS projects, and 14.87% better F2 and
8.39%betterAUCvalueonthe10industrialprojectscomparedto
the baseline trace-link classifier [ 59]. The hybrid textual similarity
featuresandtheincorporatedSSLmechanisminSPLINTcontribute
to its overall effectiveness, and the SSL mechanism in particular
contributestotheindustrialprojectsthatencounterheavierdata
imbalance andsparsity.This studyâ€™scontributionsare as follows:
â€¢Aninvestigationwasconductedtoanalyzewhythewidely-used
automatedtrace-linkclassifiersunderperforminreal-worldscenar-
ios. Typically, in industrial projects, we found that data imbalance
and sparseness issues pose major challenges in predicting trace
links.
â€¢ASemi-SupervisedPre-processingforLearning-basedTraceability
framework,SPLINT,wasproposed.SPLINTisabletomitigatedata
imbalance challenges via semi-supervised learning strategies and
selectunlabeledtrace linkseffectivelythroughthe CBST-Adjust.
â€¢SPLINTwasdemonstratedtobemorepracticalandeffectivefor
supportingtraceabilitytaskswithsixopen-sourceprojectsandten
industrialprojects.
2 PROBLEM STATEMENT
This section illustrates an investigation study on traceability ap-
proachevaluationforreal-worldsoftwareprojectsandmotivates
our traceability framework.
2.1 Investigation Study
Becauseofthelackofpracticalevaluation,weconcentrateonthe
traceabilityapproachevaluationforreal-worldsoftwareprojects
inthis study.
571Semi-supervisedPre-processingforLearning-BasedTraceability Framework onReal-WorldSoftware Projects ESEC/FSE â€™22, November14Å›18, 2022,Singapore, Singapore
Data Collection. Firstly, we reviewed data provided by one of
our collaborators, a leading global supplier of information and
communicationtechnology(ICT)andsmartdeviceswithoperations
in over 100 countries and regions. To conduct our investigative
study, we selected 10 of the 54 initiatives that enable access to
software repositoriesandmeetthe following criteria:
1)The projects chosen are representative of the key product
services developed by our industrial collaborators (e.g., Plat-
form, App );
2)Themetadataofsoftwareartifactsisavailabletousandcan
be taken from associatedsoftware repositories;
3) Continuous release versionsofthe projectare available.
Itisgenerallythecasethat Appprojectsprovidedirectservice
to external users.Typically, theyupdateartifactsfrequently, have
larger project sizes, more iterative development processes, and
more involved engineers, which lead to poor traceability and main-
tenance. In contrast, Platformprojects are mainly focused on inter-
nalengineers.Duetotheirsmallersize,seniordevelopersusually
handle artifact managementandmaintenancedirectly.
Recently,ourcollaboratorsbegantofocusonrequirements-to-
commitstraceability.Theyexpectedthesetracelinkstoimprove
the credibility of the software development process. Thus, they
established a rule that software engineersare unabletoclosea re-
quirement without at least one traced commit. However, we found
thatourcollaboratorshadrelativelyweaktraceabilitymanagement
for other artifacts, especially in issue-commit links where tight
developmentcycles(i.e.,aroundone-monthreleasecycles)make
it difficult to force developers to create and maintain 100% issue
(defects)-commit links. Meanwhile, the requirements traceability
rulehasjustbeenestablished.Itis notadvisabletoforcesoftware
engineers to guarantee all forms of trace links. Even so, managers
incollaboratedorganizationsstillseektoassurethequalityofissue
trackingsothattheycangovernsoftwareprocessdataandaccel-
erate software process digitization. To this end, the organization
seeksautomatedwaysto manage traceability issues.
Table 1:ProjectStatistics
Proj. DomainCreation
DateCleaned
CommitsCleaned
IssuesExisting
LinksLinked
Issues(%)Imba.
Ratio
De. Database 2004-8 1,108 478 300 48.7% 73
Dr. Engine 2005-12 2,989 1728 1031 50.8% 25
Gr.Language 2003-9 5,368 1170 1017 69.4% 215
In.Database 2009-3 5,546 2287 2008 68.3% 64
Ma.Automation 2004-1 1,747 530 315 51.5% 21
Pi.Language 2007-10 429 295 288 77.6% 9
Average 2,865 1,081 827 61.07% 68
P1 APP 2018-1 16,912 1,764 1,305 25.1% 241
P2 APP 2018-3 12,229 1,389 1,111 39.0% 160
P3 APP 2018-1 4,888 448 279 28.6% 85
P4 APP 2018-3 7,271 856 770 24.9% 248
P5Platform 2018-3 1,649 188 257 33.5% 34
P6Platform 2018-3 2,903 337 544 34.1% 70
P7Platform 2018-12 6,114 405 948 45.2% 145
P8Platform 2018-3 514 192 144 44.3% 47
P9Platform 2018-8 2,437 270 287 45.2% 65
P10 Platform 2018-3 3,609 631 874 47.4% 123
Average 5,853 648 652 36.72% 122
Thus,wechosetenprojectswithproblematicissue-committrace
links from our collaborators (shown in Table 1, will be discussed
later).Tostudythetraceabilityapproachpracticalevaluationondif-
ferentcommunityprojects,thenwechosethedatasetsproposedbyRath et al. [ 59] as well, which contains the traceability datasets his-
toryofsixopen-sourceApacheprojectsonGitHubwithalongevo-
lutionhistory,ensuringlarge-scaleartifactsandexistingcommit-
issue trace links available. As the issues data mined from industrial
projectsarethe defectreportsinissuetrackingsystems,whichis
a self-build system and records bug (defect) reports that mainly
identifiedbytesters.Tofairlycomparewiththeindustrialones,we
usedbug-committracelinksasourcasefromsixOSSprojectsonly.
The statistics about the selected projects are listed in Table 1, in-
cludingtheircreationdate,numberofsource(i.e.issues)andtarget
(i.e. code commits) artifacts, and the percentage of the linked ratio
ofsourceartifacts(i.e. #linked issues/#allissues ). We denoteindus-
trial projects as ğ‘ƒ1toğ‘ƒ10and use OSS project abbreviations (build
automation(Maven(Ma)),databases(Derby(De),Infinispan(In)),
languages(Groovy(Gr),Pig(Pi)),andaruleengine(Drools(Do)))
as in [59]. As a result of the selected projects including different
sizes of code commits (e.g., 100, 1,000 to 10,000), it ensures real-
world projects scaling at multiple scales. On the other hand, due
tothelongevolutionhistoryofsixopen-sourceApacheprojects
usedin[59],ensuringsufficientcommitsandexistingcommit-issue
tracelinksavailable.Onaverage,36.72%ofissues( ğ‘‘ğ‘’ğ‘“ğ‘’ğ‘ğ‘¡)inten
industrial projects are linked to code commits, a situation that is
significantly worse than the issue-commit links situations (61.67%)
within six open-source projects [ 59]. The linking ratio of issues in
thespecificprojectsvaries,theworstlinkedratiodroppingtonearly
20% (e.g., P1 and P4). In reality, approximately 80 percent of issues
arefunctional,andtheother20percentarenonfunctionalissues
that mainlyrelated to performance and security issues discovered
byconsultingthe internal developersofour collaborators.Hence,
mostissuesshouldberelatedtocodechanges.Whileduetonon-
mandatorytaggingofcommits,manyissueshavenotracetoany
commitsduringareal-worldproject.Consequently,thissituation
notonlymakeexistingtracelinkslessqualified,butalsothosemake
thetrainingoftracelinkclassifierstofacegreaterobstaclesbecause
oflimitedamountoflearningdata.Thus,real-worldprojectsare
struggling withrecover andmaintenancesoftware traceability.
2.2 The Motivating Question
Weplannedtoexplorethefollowingmotivatingquestionfirstbased
ontenindustrialprojectsandsix OSS projects.
MQ1: How well does the state-of-the-art ML-based trace link clas-
sifier workin real-lifeprojects?
The ideal configuration of the ML-based traceability recovery
procedureshasbeenstudiedinthepreliminaryresearch.Ingeneral,
these studies agree that using the Random Forest classification
algorithmswiththesyntheticminorityover-samplingtechnique
(SMOTE),theover-samplingtechniquewhichistheoptimumfor
datarebalancingandclassificationalgorithm[ 24,50].Besides,we
followed the link classifier model introduced by Rath et al. [ 59]
with the rest of the components (i.e. data selection, feature sets,
datasplitting)as our baseline,becausetheirworkalso focusedon
generatingmissinglinksatthecommitlevelonreal-world,large-
scaleOSS projectsthat fitthe scenarios discussedinour paper.
OverallPerformance(MQ1). ThebestF2(ametrictorepresent
overallperformances,definedinSection 4.1)distributionisreported
forallprojectsinFigure 1byusingthetrainingframeworkfrom
ourbaseline,respectively.Asshownintheright-handx-axis,the
572ESEC/FSE â€™22, November14Å›18, 2022,Singapore, Singapore Liming Dong,He Zhang,WeiLiu, ZhiluoWeng, andHongyu Kuang
bottombluesixbarsindicateF2valuesforsixOSSprojects,andthe
upper blue ten bars indicate F2 values for ten industrial projects.
Theindustrialprojectsshowedunderperformedresultsasindicated
by the F2-score distribution with around 30% on average. This is
significantlylowerthantheperformancepresentedinpreviousOSS
projectswithan averageF2-score ofnearly 80%.
For further analyzing the problems encountered by industrial
projects, we also presented the imbalance ratio for the sampling
dataset of each project along the left hand in x-axis in Figure 1.
The imbalance ratio is calculated by dividing the number of major
classes(â€˜Falseâ€™ links) by thenumberofminor classes(â€˜Trueâ€™ links)
interms of #Falsedividedby #True tracelinks .
-250 -230 -210 -190 -170 -150 -130 -110 -90 -70 -50 -30 -10 10 30 50 70 90DerbyDroolsGroovyInfinispanMavenPigP1P2P3P4P5P6P7P8P9P10
Imbalance Ratio(False/True Links) F2 scores
Figure1:Performanceofstate-of-the-artML-basedtracelink
classifier[ 59]on OSS andindustrialprojects
2.3 EncounteredChallenges
Wefoundthefollowingtwochallengesaffectingtheeffectiveness
of current ML-based tracing approaches. Industrial initiatives may
cause the higher imbalance ratio (e.g., the imbalance ratio reaches
around120onaverage)andlimitedsamplingtracelinksbecause
ofthe lower linkedissuesratio,withonly around 36.72%.
2.3.1 DataImbalance. Thedataimbalanceproblemisexacerbated
bythetightdevelopmentprocessesforindustrialsoftwareprojects.
Ontheonehand,industrialprojectsarebusiness-orientedwithlim-
iteddevelopmenttimeanddeadlinesandintensivecodingactivities.
As a result, whencompared tothe sixOSS projects, these projects
producedahigherproportionofcodecommitswithfewersource
artifacts.WeseeOSSprojectsthathavemaintainedcomparablesize
issuesandcodecommitswithroughlyN*1,000forovertenyears.
In contrast, as shown in Table 1, most industrial projects have just
â‰ˆ (ğ‘âˆ—100)ofissueswith â‰ˆ (ğ‘âˆ—1,000),evenâ‰ˆ (ğ‘âˆ—10,000)of
code commits in their shorter history. As a result, the discrepancy
in the ratio between source and target artifacts exacerbates the
severityofdata imbalance insampling datasets.
Second,thenatureofsoftwaretraceabilitymakesitlikelythat
an issue will be traced back to one or more code commits, so all
potentialcodecommitsproducedduringtheissuelifecyclewere
selected as target artifacts. In an industrial setting, where code
commits are made more frequently, a greater proportion of code
commits will be selected as candidate target artifacts for issues.This will result in a substantial imbalance between candidate links
taggedâ€˜Trueâ€™andthosetaggedâ€˜Falseâ€™.
2.3.2 Data Sparseness. The sparsity of data can be seen from the
following twoperspectives.
1) Feature space sparsity: The first one is the data sparsity in
the extracted feature matrix, which impairs the effectiveness of
industrialsamplingdatasets.Wedonatefeaturesetsas ğ‘1toğ‘18,
thedetaileddescriptionsshowninTable 3asdefinedin[ 59].Fig-
ure2displays the sparsity of each column in the feature matrix
(#(null)/#(all)) intwocommunitydatasets.Industrialprojectsreturn
more sparse process features (e.g., a3, a6, a9, and a12) than OSS
datasets, while textual similarity features (e.g., a17) had more valid
values. As a result, industrial projects have trouble offering mean-
ingfulprocessfeatures. Thedefinedfeaturesetsinpreviouswork
(a1toa18),whichperformwellinsixOSSprojects[ 59],however,
failtocapturethedetailsoftracelinkagesintheselectedindustrial
projects. This is because the recorded information on industrial
projects reveals incorrect metadata on derived artifacts, and the
process features can be incorrect or distorted when compared with
whatactuallyoccurs.Theassignedauthorsofissuesmay,forex-
ample, be core developers, while the code committers and fixers
may go to another developer (i.e. outsourcing developers). In an
enterprise environment, itisawidely usedcooperative solution.
OSS 0 0 0.865 0 0 0.040 0 0 0.143 0 0 0.340 0 5E-05 0.038 0.849 0.75 6 0.987
Industry 0 0 0.957 0 0 0.276 0 0.123 0.837 0 0.123 0.837 0 3.636 0 .066 0.004 0 0.947a1 a2 a3 a4 a5 a6 a7 a8 a9 a10 a11 a12 a13 a14 a15 a16 a17 a1800.20.40.60.81Feature  Sparsity
Figure 2:Feature sparsity
Asafurtherinvestigation,wecalculatedPearsonâ€™sCoefficient
valuesfortwodatasetstoassessthecorrelationbetweenfeatures
and labeled ground truth. Table 2shows the correlation index of
each numeric feature for two datasets, where ğ‘ğ‘œğ‘Ÿğ‘Ÿ.signifies the
average correlation coefficient of a feature with labeled value.We
discovered that process-related features (i.e. a4Å›a16) have lower
correlation values with golden linkages in industrial datasets. Tex-
tualsimilarity(i.e.a17)appearstobethemostsignificantfeaturein
bothdatasets.Thishighlightstheimportanceoftextualsimilarity
characteristics, particularly in industrial projects, and that the cap-
turing of semantic information should be reinforced in real-world
industrialprojects.
2)Samplesizesparsity: Thereisasecondfrontofdatasparsity
causedbythelimitedlabeledtracesets.Whenthesampleoflabeled
dataissmall,thedistributionoflearnedtrainingsetissparse(see
Table1).Inspiteoftheindustryprojectproducinggreaterquantities
ofartifacts,thereareproducedlimitedexistinglinks.However,it
is costly for developers to manually tag the links again in real-
world scenarios. Even the most familiar developers were unable to
recall thecorrect trace linksafter thelong evolution. Asshown in
Figure1,theeffectofsamplesizehasagreatimpactonthetrace
model performance. For example, when the number of existing
573Semi-supervisedPre-processingforLearning-BasedTraceability Framework onReal-WorldSoftware Projects ESEC/FSE â€™22, November14Å›18, 2022,Singapore, Singapore
linksinP6-P9droptolessthan500,thebestF2-scoresofthoselinks
decrease significantly to less than 30%. Even the P7 have nearly
1,000 exiting links, whose performance is limited by its higher
imbalance ratio.
Table 2:Correlation Coefficient(Features,Label)
Dataset OSS Industry
ğ¹ğ‘’ğ‘ğ‘¡ğ‘¢ğ‘Ÿğ‘’ğ‘  ğ‘ğ‘œğ‘Ÿğ‘Ÿ.ğ‘âˆ’ğ‘£ğ‘ğ‘™ğ‘¢ğ‘’ ğ‘ğ‘œğ‘Ÿğ‘Ÿ.ğ‘âˆ’ğ‘£ğ‘ğ‘™ğ‘¢ğ‘’
a3 0.1 0.0742 0.2 0.0188âˆ—
a4 -0.11 0.0229âˆ—-0.06 0.0296âˆ—
a5 -0.12 0.0367âˆ—0.01 0.1682
a6 0.02 0.0257âˆ—0.05 0.0238âˆ—
a7 -0.13 0.0318âˆ—-0.01 0.1706
a8 -0.06 0.0705 0 0.4963
a9 0.11 0.0300âˆ—0 0.3710
a11 -0.12 0.0048âˆ—âˆ—0 0.4903
a12 0.1 0.1158 0 0.3549
a14 -0.06 0.0725 0 0.2003
a15 -0.02 0.191 0.01 0.1795
a16 -0.08 0.0309âˆ—-0.06 0.0267âˆ—
a17 0.41 0.0000âˆ—âˆ—0.36 0.0457âˆ—
a18 0.27 0.0006âˆ—âˆ—0.31 0.0240âˆ—
âˆ—0.05 significantlevel,âˆ—âˆ—0.01 significantlevel
Thus, due to the above issues, we propose a framework based
on the semi-supervised pre-processing method (SPLINT), to ad-
dressthedataimbalanceandsparsityproblemsthatareinherent
to learning-based traceability approaches and to predict better out-
comes inreal-world situations.
3 SPLINTFRAMEWORK
3.1 The OverviewProcessofSPLINT
Figure3showstheoverviewofSPLINT.Theenhancedtracelinkpre-
diction approach used semi-supervised learning strategies. SPLINT
enhanced three of the pre-processing stages, i.e. data selection,
featureextraction,andmostimportantly,datarebalancing,where
thereadjustsettingsandenhancedstrategies inSPLINTare high-
lighted in red. As presented in Section 2.1, software artifacts are
producedfrequentlyinreal-worldsettings,soanautomatictrace-
abilityapproachiscrucialtosupporttracelinkrecoveryfordata
governanceaswellastoovercometwogenericlimitationsofsuper-
vised trace link classification. To achieve this goal, following the
existingwork[ 59,64],SPLINTselectedsoftwareartifactsandorga-
nizedthecandidatetracelinksduringdataselection,thatis,thefirst
stageinSPLINT.Next,thedataarelabeledanddividedintolabeled
andunlabeledsetsrespectivelyinSPLINT.Athirdstageinvolved
addingmorehybridsimilarityfeatures,duetotheimportanceof
semantic information as one major factor for alleviating one of
the major limitations discussed in our paper (i.e. heavier feature
sparsityinreal-worldprojects).Inthefourthstage,thelabeleddata
were then split by chronological order of issue and with a static
splitrateof4:1,resultingin80%trainingsetand20%testset.Sothat
allpairsoftracelinksappearedbeforethetestset,andmuchcloser
tothepracticalscenarioinsupportingtraceabilitytasks[ 17,44,59].
The fifth stage comprised semi-supervised learning combined with
datarebalancing,whichisthecoreofSPLINT.Specifically,itisused
to solve one of the major challenges we discussed in Section 2.1(i.e.
reduce the effect of sampling sparsity caused by the low ratio of
existing links). Additionally, it is used to resolve the problem of
data imbalance, which is caused by the traceability approachesâ€™
inherent difficulty and the frequent production of and evolution
ofartifactsovertime.InSPLINT,CBSTideaisincorporatedwith
SSLbyestimatingthelikelihoodforanunlabeledtracelinktobe-
long to each class instead of dependent on deterministic labels,which might exacerbate the data imbalance ratio of the training
set again. Further,we adjustedthe selectionpolicy forunlabeled
dataofclass-balancingself-training(CBST-Adjust)andsystemati-
cally investigated the effectiveness of CBST-Adjust in a real-world
scenario inthe following experiments.
3.2 Data Selection
We collected our experiment datasets from responding software
repositoriesbycleaninginitialartifactsetsandminingâ€˜resolvedâ€™
issues and â€˜not abandonedâ€™ commits. During the data selection
phase, SPLINT extracts the cleaned artifacts and uses the adjust
time-based heuristic function ğ‘–ğ‘ _ğ‘ğ‘ğ‘›ğ‘‘ğ‘–ğ‘‘ğ‘ğ‘¡ğ‘’ [59] for each project to
combine the candidate trace links.
Thedelayintervalsinreal-worldprojectsaredifferentinvarious
domains,setting ğœ–asastaticvariablecouldnotfitthereal-world
project context. Given that the code commits were linked with
requirements and issues that are already â€˜closedâ€™ or â€˜resolvedâ€™ is
a common phenomenon, we readjusted and computed ğœ–in each
projectindividuallytoensurewecouldsampleasmanypotential
candidate target artifacts as possible.
ğ‘–ğ‘ _ğ‘ğ‘ğ‘›ğ‘‘ğ‘–ğ‘‘ğ‘ğ‘¡ğ‘’ (ğ¼,ğ¶)=ğ‘ğ‘Ÿğ‘’ğ‘ğ‘¡ğ‘’ğ‘‘(ğ¼) â‰¤ğ‘ğ‘œğ‘šğ‘šğ‘–ğ‘¡ğ‘¡ğ‘’ğ‘‘ (ğ¶)
â‰¤ğ‘Ÿğ‘’ğ‘ ğ‘œğ‘™ğ‘£ğ‘’ğ‘‘(ğ¼) +ğœ–
ğœ–=ğ‘šğ‘’ğ‘‘ğ‘–ğ‘ğ‘›_ğ‘ğ‘’ğ‘Ÿğ‘ğ‘Ÿğ‘œğ‘—ğ‘’ğ‘ğ‘¡ (|ğ‘ğ‘œğ‘šğ‘šğ‘–ğ‘¡ğ‘¡ğ‘’ğ‘‘ (ğ¶) âˆ’ğ‘Ÿğ‘’ğ‘ ğ‘œğ‘™ğ‘£ğ‘’ğ‘‘(ğ¼) |)
ğ‘¤â„ğ‘’ğ‘› ğ‘5<0ğ‘ğ‘›ğ‘‘ ğ¶âˆˆğ‘–ğ‘ _ğ‘™ğ‘–ğ‘›ğ‘˜ğ‘’ğ‘‘(ğ¼)(1)
3.3 FeatureExtraction
Textual Similarity Features. We discussed in Section 2.1how
generalprocess-relatedfeatures[ 59]areunsuitableinreal-world
industrial projects causing feature sparsity problems and under-
performing results (see Figure 2). Furthermore, ten more textual
similarityfeatureshavebeenaddedbasedonthepreviouswork[ 51]
totakefulladvantageofthesemanticinformationtohelpdistin-
guish â€˜Trueâ€™ from â€˜Falseâ€™ links (refer to Table 2) and build powerful
trace links classifier model. New features are highlighted in bold in
Table3.
â€¢standalonetextualsimilarity:a17-a22 .Therearesixfea-
turesincludingIR-basedalgebraicmodeling(VSM,VSM-2gram[ 14,
59],LSIandJS),topicmodeling(LDAandNMF)[ 51].TheseIR-based
techniques were used standalone to measure the textual similarity
between the issuedescriptionandcode messages.
â€¢hybrid textual similarity: a23-a27 . The five features listed
below in Table 3utilize the Gethers et al. [ 27] methodology to
combine different techniques. When normalizing the measures,
eachsimilarity measure is weighted.As a result, hybridsimilarity
measures can be generated from any two IR-based techniques. For
each technique, the weighting factor ğœ†is equal to 0.5 as similar
to[51],asthiswasthebestperformingconfigurationreportedin
the previous work [ 27].
3.4 Data Rebalancing
Forindustrialsettings,thereisaheavierimbalanceddistribution
of data for major â€˜Falseâ€™ trace links and minor â€˜Trueâ€™ trace links,
which may hinder prediction quality of pseudo-labelsâ€™ accuracy.
InSPLINT,wecombinedclass-balancingself-learningwithsemi-
supervisedlearningandre-sampling to mitigate the problem.
3.4.1 Semi-Supervised Learning. In cases where few labeled train-
ing data are available, but a large number of unlabeled data are
574ESEC/FSE â€™22, November14Å›18, 2022,Singapore, Singapore Liming Dong,He Zhang,WeiLiu, ZhiluoWeng, andHongyu Kuang
...Source
Artifacts
Target  
ArtifactsProcess
FeaturesHybrid Similarity
Features
Feature
VectorsChronological 
 Order Data Splitting
Feature Extraction
Final Model
 
...
Updated Training
Trace Set  Rebalancing
IterativelyUnlabeled
Trace Set  ...Re-sampling  
(SMOTE)Labeled Training 
Trace Set  
Sampling Set 
 Updating Labeled Training 
Set  
Psuedo Labels  Label SmoothingUnlabeled
Trace Set  
PredictBase Model
Class-Balancing Self-Training (CBST)SSL(Semi-supervised Learning) Data Rebalancing Data Labeling
Source  
Artifacts
Target 
ArtifactsClosed
Artifacts
Linked 
ArtifactsUnlinked 
Artifacts
Candidate Target 
Artifacts Set of Software 
Repository
CreateTime( ) CloseTime( )Data Selection
...
CBST-AdjustTest 
SetTraining 
Set
Figure 3:Overview process ofSPLINT
Table 3:Feature Sets inSPLINT
Features ID Description
stakeholdersa1ğ‘‘ğ‘’ğ‘£ğ‘’ğ‘™ğ‘œğ‘ğ‘’ğ‘Ÿ (ğ¼)
a2ğ‘ğ‘œğ‘šğ‘šğ‘–ğ‘¡ğ‘¡ğ‘’ğ‘Ÿ (ğ¶)
a31(ğ‘–ğ‘“ ğ‘ğ‘œğ‘šğ‘šğ‘–ğ‘¡ğ‘¡ğ‘’ğ‘Ÿ (ğ¶) âˆˆğ‘‘ğ‘’ğ‘£ğ‘’ğ‘™ğ‘œğ‘ğ‘’ğ‘Ÿ (ğ¼)),0ğ‘œğ‘¡â„ğ‘’ğ‘Ÿğ‘¤ğ‘–ğ‘ ğ‘’
temporala4ğ‘ğ‘œğ‘šğ‘šğ‘–ğ‘¡ğ‘¡ğ‘’ğ‘‘ (ğ¶) âˆ’ğ‘ğ‘Ÿğ‘’ğ‘ğ‘¡ğ‘’ğ‘‘(ğ¼)
a5ğ‘Ÿğ‘’ğ‘ ğ‘œğ‘™ğ‘£ğ‘’ğ‘‘ (ğ¼) âˆ’ğ‘ğ‘œğ‘šğ‘šğ‘–ğ‘¡ğ‘¡ğ‘’ğ‘‘ (ğ¶)
a61(ğ‘–ğ‘“ ğ‘4ğ‘ğ‘›ğ‘‘ ğ‘5â‰¥0),0ğ‘œğ‘¡â„ğ‘’ğ‘Ÿğ‘¤ğ‘–ğ‘ ğ‘’
a7|ğ‘5|<ğœ€, ğœ€=ğ‘šğ‘’ğ‘‘ğ‘–ğ‘ğ‘›_ğ‘ğ‘’ğ‘Ÿğ‘ğ‘Ÿğ‘œğ‘—ğ‘’ğ‘ğ‘¡ (|ğ‘5|)
previous
tracelinksa8ğ‘ğ‘œğ‘šğ‘šğ‘–ğ‘¡ğ‘¡ğ‘’ğ‘‘ (ğ¶) âˆ’ğ‘ğ‘œğ‘šğ‘šğ‘–ğ‘¡ğ‘¡ğ‘’ğ‘‘ (ğ¶ğ‘),
Cp={maxCommitted(Cx) |ğ‘–ğ‘ _ğ‘™ğ‘–ğ‘›ğ‘˜ğ‘’ğ‘‘(ğ¶ğ‘¥,ğ¹)âˆ§
committed(Cx)<committed(C)}
a9ğ‘œğ‘£ğ‘’ğ‘Ÿğ‘™ğ‘ğ‘(ğ¶,ğ¶ğ‘),ğ‘œğ‘£ğ‘’ğ‘Ÿğ‘™ğ‘ğ‘ =(ğ‘šğ‘œğ‘‘(ğ¶) âˆ©ğ‘šğ‘œğ‘‘(ğ¶ğ‘))/
max(mod(C),mod(Cp))
a10ğ‘ğ‘œğ‘šğ‘šğ‘–ğ‘¡ğ‘’ğ‘Ÿ (ğ¶ğ‘)
next
tracelinksa11ğ‘ğ‘œğ‘šğ‘šğ‘–ğ‘¡ğ‘¡ğ‘’ğ‘‘ (ğ¶ğ‘›) âˆ’ğ‘ğ‘œğ‘šğ‘šğ‘–ğ‘¡ğ‘¡ğ‘’ğ‘‘ (ğ¶),
Cn={minCommitted(Cx) |ğ‘–ğ‘ _ğ‘™ğ‘–ğ‘›ğ‘˜ğ‘’ğ‘‘(ğ¶ğ‘¥,ğ¼)âˆ§
committed(Cx)>committed(C)}
a12ğ‘œğ‘£ğ‘’ğ‘Ÿğ‘™ğ‘ğ‘(ğ¶,ğ¶ğ‘›), ğ‘œğ‘£ğ‘’ğ‘Ÿğ‘™ğ‘ğ‘ =ğ‘šğ‘œğ‘‘(ğ¶) âˆ©ğ‘šğ‘œğ‘‘(ğ¶ğ‘›)/
max(mod(C),mod(Cn))
a13ğ‘ğ‘œğ‘šğ‘šğ‘–ğ‘¡ğ‘’ğ‘Ÿ (ğ¶ğ‘›)
current
tracelinksa14ğ¼_ğ‘œğ‘ğ‘’ğ‘›ğ‘’ğ‘‘=| {ğ¼ğ‘¥|ğ‘œğ‘ğ‘’ğ‘›ğ‘’ğ‘‘(ğ¼) âˆ§
created(I) â‰¤ğ‘ğ‘œğ‘šğ‘šğ‘–ğ‘¡ğ‘¡ğ‘’ğ‘‘ (ğ¶) â‰¤ğ‘Ÿğ‘’ğ‘ ğ‘œğ‘™ğ‘£ğ‘’ğ‘‘ (ğ¼)} |
a15|ğ‘‘ğ‘’ğ‘£ğ‘’ğ‘™ğ‘œğ‘ğ‘’ğ‘Ÿ (ğ¼_ğ‘œğ‘ğ‘’ğ‘›ğ‘’ğ‘‘) |
a16ğ¶_ğ‘™ğ‘–ğ‘›ğ‘˜ğ‘’ğ‘‘=| {ğ¶ğ‘¥|ğ‘–ğ‘ _ğ‘™ğ‘–ğ‘›ğ‘˜ğ‘’ğ‘‘(ğ¶ğ‘¥,ğ¼)âˆ§
committed(Cx)<committed(C)} |
standalone
textual
similaritya17VSM(ğ‘ ğ‘–ğ‘š(ğ‘‘ğ‘’ğ‘ ğ‘ğ‘Ÿğ‘–ğ‘ğ‘¡ğ‘–ğ‘œğ‘› (ğ¼),ğ‘šğ‘’ğ‘ ğ‘ ğ‘ğ‘”ğ‘’ (ğ¶)))
a18VSM-2gram( ğ‘ ğ‘–ğ‘š(ğ‘‘ğ‘’ğ‘ ğ‘ğ‘Ÿğ‘–ğ‘ğ‘¡ğ‘–ğ‘œğ‘› (ğ¼),ğ‘šğ‘’ğ‘ ğ‘ ğ‘ğ‘”ğ‘’ (ğ¶)))
a19LSI(ğ‘ ğ‘–ğ‘š(ğ‘‘ğ‘’ğ‘ ğ‘ğ‘Ÿğ‘–ğ‘ğ‘¡ğ‘–ğ‘œğ‘› (ğ¼),ğ‘šğ‘’ğ‘ ğ‘ ğ‘ğ‘”ğ‘’ (ğ¶)))
a20JS(ğ‘ ğ‘–ğ‘š(ğ‘‘ğ‘’ğ‘ ğ‘ğ‘Ÿğ‘–ğ‘ğ‘¡ğ‘–ğ‘œğ‘› (ğ¼),ğ‘šğ‘’ğ‘ ğ‘ ğ‘ğ‘”ğ‘’ (ğ¶)))
a21LDA(ğ‘ ğ‘–ğ‘š(ğ‘‘ğ‘’ğ‘ ğ‘ğ‘Ÿğ‘–ğ‘ğ‘¡ğ‘–ğ‘œğ‘› (ğ¼),ğ‘šğ‘’ğ‘ ğ‘ ğ‘ğ‘”ğ‘’ (ğ¶)))
a22NMF(ğ‘ ğ‘–ğ‘š(ğ‘‘ğ‘’ğ‘ ğ‘ğ‘Ÿğ‘–ğ‘ğ‘¡ğ‘–ğ‘œğ‘› (ğ¼),ğ‘šğ‘’ğ‘ ğ‘ ğ‘ğ‘”ğ‘’ (ğ¶)))
hybrid
textual
similaritya23VSM+LDA( ğ‘ ğ‘–ğ‘š(ğ‘‘ğ‘’ğ‘ ğ‘ğ‘Ÿğ‘–ğ‘ğ‘¡ğ‘–ğ‘œğ‘› (ğ¼),ğ‘šğ‘’ğ‘ ğ‘ ğ‘ğ‘”ğ‘’ (ğ¶)))
a24JS+LDA(ğ‘ ğ‘–ğ‘š(ğ‘‘ğ‘’ğ‘ ğ‘ğ‘Ÿğ‘–ğ‘ğ‘¡ğ‘–ğ‘œğ‘› (ğ¼),ğ‘šğ‘’ğ‘ ğ‘ ğ‘ğ‘”ğ‘’ (ğ¶)))
a25VSM+NMF( ğ‘ ğ‘–ğ‘š(ğ‘‘ğ‘’ğ‘ ğ‘ğ‘Ÿğ‘–ğ‘ğ‘¡ğ‘–ğ‘œğ‘› (ğ¼),ğ‘šğ‘’ğ‘ ğ‘ ğ‘ğ‘”ğ‘’ (ğ¶)))
a26JS+NMF(ğ‘ ğ‘–ğ‘š(ğ‘‘ğ‘’ğ‘ ğ‘ğ‘Ÿğ‘–ğ‘ğ‘¡ğ‘–ğ‘œğ‘› (ğ¼),ğ‘šğ‘’ğ‘ ğ‘ ğ‘ğ‘”ğ‘’ (ğ¶)))
a27VSM+JS(ğ‘ ğ‘–ğ‘š(ğ‘‘ğ‘’ğ‘ ğ‘ğ‘Ÿğ‘–ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘¡ğ‘™ğ‘’ (ğ¼),ğ‘šğ‘’ğ‘ ğ‘ ğ‘ğ‘”ğ‘’ (ğ¶)))
generatedaspartofreal-worldtraceabilitylinks,SSLisanatural
choice[15].SSLupdatesandaugmentslabeledtrainingdata( ğ·ğ‘™)
withunlabeledtracedata( ğ·ğ‘¢)andachievesfinalwell-trainedtrace
linkclassifier ( ğ‘“ğ‘“ğ‘–ğ‘›ğ‘ğ‘™) byfollowing steps:
a)BaseClassifier ğ‘“ğ‘ğ‘ğ‘ ğ‘’Learning. Abinarytracelinkclassification
problem can have either â€˜Trueâ€™(b) or â€˜Falseâ€™ (0) as the label with
equal probability (i.e. 0.5). With the help of the original labeled
imbalanced training trace set ğ·ğ‘™, we have obtained a base trace
linksclassifier, ğ‘“ğ‘ğ‘ğ‘ ğ‘’.b)Pseudo-labelsGeneration. Inthedatalabelingphase,thefea-
tures matrixof theunlabeled tracedata ( ğ·ğ‘¢)are extracted aswell.
Specifically,thebasetracelinkclassifier ğ‘“ğ‘ğ‘ğ‘ ğ‘’isappliedtoproduce
pseudo-labels Ë†ğ·ğ‘¢for unlabeledtrace sets.
c) Pseudo-labels Selection. For updating training trace set, the
binary pseudo-labels with high prediction probability scores (>
ğ‘ğ‘Ÿğ‘œğ‘ğ‘ğ‘ğ‘–ğ‘™ğ‘–ğ‘¡ğ‘¦ ğ‘¡â„ğ‘Ÿğ‘’ğ‘ â„ğ‘œğ‘™ğ‘‘ ) are given preference to be selected, and
integratedintolabeledtracesetsonthebasisofthebaseclassifierâ€™s
(ğ‘“ğ‘ğ‘ğ‘ ğ‘’) prediction.
d) Training Set Updating. AfterË†ğ·ğ‘¢for unlabeled trace set ğ·ğ‘¢
are generated, the subset ğ‘†ğ‘ ğ‘¢ğ‘ğ‘ ğ‘’ğ‘¡of generated pseudo-labels of
Ë†ğ·ğ‘¢are combined with original labeled training trace set ğ·ğ‘™. The
updatingtrainingset( ğ·ğ‘™âˆªğ‘†ğ‘ ğ‘¢ğ‘ğ‘ ğ‘’ğ‘¡)arearrangedaccordingtothe
chronologicalorderinwhichtheywereperformedtotrainthetrace
linkclassifier.
e) Final Classifier ğ‘“ğ‘“ğ‘–ğ‘›ğ‘ğ‘™Training. In this step, ğ·ğ‘™âˆªğ‘†ğ‘ ğ‘¢ğ‘ğ‘ ğ‘’ğ‘¡was
usedfortrainingtracelinkmodeliterativelyforobtainingafinal
classifier ğ‘“ğ‘“ğ‘–ğ‘›ğ‘ğ‘™untiltominimizethelossfunctiononbothmajor
andminorclasses.
Traditional SSLShortcomings. Pseudo-labels Ë†ğ·ğ‘¢are vitalto
the outcome. Traditional self-training (ST) in SSL [ 40,63] can ef-
fectively detect binary trace links on balanced class datasets, since
the classifierâ€™s accuracy improves with time. The traditional ST
algorithm,however,didnotfitmorepracticalscenarioswithheavy
imbalancedistribution[ 67].ToimplementSSLinthetracelinkclas-
sifier more effectively and practically, the following shortcomings
needto be addressed:
First,theheavierclassimbalancedistributioninlabeledtraceset
could cause trace link classifier to be biased, and thus generated
pseudo-labels Ë†ğ·ğ‘¢of unlabelled trace links ğ·ğ‘¢could also be biased.
Infact,theuniformselectionthresholdintraditionalSTproducesa
heavierimbalancebetweenselectedpseudo-labelsonmajorclasses
andminorclasses,duetomajorclasseshavinghigherprobability
scores.Apseudo-labelisalsotrainedasadiscretelatentvariable
that, under traditional SSL algorithms [ 40,63], is either one-hot
or entirely zero. As a result of such a large logit difference, the
modelwillassignpseudo-labelsleadingtooverfitting.Therefore,
575Semi-supervisedPre-processingforLearning-BasedTraceability Framework onReal-WorldSoftware Projects ESEC/FSE â€™22, November14Å›18, 2022,Singapore, Singapore
this decreases the modelâ€™s adaptability and overconfidence in its
predictions. In this way, a subset of unlabeled data ğ‘†ğ‘ ğ‘¢ğ‘ğ‘ ğ‘’ğ‘¡ignores
minorclassesalongthetrainingprocessandtrainsanoverconfident
trace linkclassifier.
3.4.2 Pseudo-labels Generation and Selection. We used the con-
fidence regularization and CBST proposed by [ 74,75] in SSL as
references to conduct the self-training policy in step b) and c) in
order to overcome the problems mentionedabove.
Label Smoothing. At step b), the loss function instructs the
classifier to predict that a probability in the target class will con-
vergeto1and0inthenon-targetclass,i.e.generatingpseudo-labels
usingone-hotvectors.Itmakesthemodelselectthesparsepseudo-
labelswithlesscontributiontowardsthetraining.Tosmooththe
pseudo-labels, we implemented the negative entropy label regu-
larizer (LRENT) proposed in [ 75] and let the model choose the
pseudo-labels with smoothness instead of sparse ones. Specifically,
regularizedlabelsreducetheconfidence(themaxofoutputsoftmax)
andraisethe probability level for otherclasses.
Class-BalancingSelf-Training(CBST). Toensuremorebal-
ancedpseudo-labelselectioninstepc),weusedtheCBSTpolicy.
The threshold property ğ‘‡ğ‘§is transformed into a pseudo-label by
normalizingitwithatargetclass ğ‘§.Forclass ğ‘§,ğ‘‡ğ‘§isaparameterfor
determiningthepercentageofpseudo-labelsfromthesubset ğ‘†ğ‘¢,ğ‘§.
The Figure 4shows the selection process in CBST and determin-
ing the threshold property ğ‘‡ğ‘§. Calculate the prediction probability
scoresforeachtraceinstanceinunlabeleddataonallclassesand
thentakethemaximumprobabilityforeachclass.Allpredictions
arethensortedbyclassindescendingorder. ğ‘‡ğ‘§suchthat ğ‘’ğ‘¥ğ‘(ğ‘‡ğ‘§)
equals the probability ranked at round ( ğ‘âˆ— |Ë†ğ·ğ‘¢,ğ‘§|) [74], where
|Ë†ğ·ğ‘¢,ğ‘§|indicatesthenumberofunlabeledtraceinstancepredicted
as classğ‘§. More importantly, ğ‘ğ‘§is the circular parameter that is
used to take the probability ranked at ğ‘†ğ‘¢,ğ‘§=topğ‘ğ‘§âˆ—100%for each
class[74]whichcouldcontributetomitigatetheimbalanceproblem
in selected subset ğ‘†ğ‘ ğ‘¢ğ‘ğ‘ ğ‘’ğ‘¡=ğ‘†ğ‘¢,1âˆªğ‘†ğ‘¢,0. By using this normalized
threshold,pseudo-labels canbeassignedto classeswithrelatively
lowscores,yetwithhighwithin-classconfidenceandarenolonger
dependentonhigherdeterministicclassprobabilities ğ‘ƒ(ğ‘–)which
are easily skewedtowardsmajorclasses.
Selected
SelectedObtain Sampling Set in
CBST 
Obtain Sampling Set in CBST-
Adjust Determine Probability Threshold Select Pseudo Labels for Each Class z Step b).  
Pseudo-Labels 
Generation Step c). Pseudo-Labels Selection
Label Smoothing = top( )
0.9, 0.8   0.5           0Class(true)
 = top( )
1, 0.99, 0.98      0.5          0Class(false)
Figure 4:Pseudo-labelsgenerationandselection
CBST-Adjust. The data distribution in ğ‘†ğ‘ ğ‘¢ğ‘ğ‘ ğ‘’ğ‘¡obtained from
CBST framework is still biased toward major classes, due to the
numberofunlabeleddatawithprobabilityrankedat ğ‘ğ‘§âˆ—100%in
major class is far larger than that in minor class. As an example,unlabeled trace set ğ·ğ‘¢contains approximately (N*10,000) â€˜Falseâ€™
linksand(N*100)â€˜Trueâ€™links.Subsetprobabilities ğ‘‡ğ‘§formajorand
minorclassesmightcomputedtobe0.95and0.7,respectively.In
theend,thatresultinginaround ğ‘†ğ‘¢,0â‰ˆ (ğ‘âˆ—1,000)majorclasses
andğ‘†ğ‘¢,1â‰ˆ (ğ‘âˆ—10)minorclasseswereselectedin ğ‘†ğ‘ ğ‘¢ğ‘ğ‘ ğ‘’ğ‘¡.Thisis
duetothefactthatmostpseudo-labelsarepredictedasâ€˜Falseâ€™links
withhigherprobabilities,thus,evenwithsuchahighprobability
threshold, still return a substantial amount of pseudo-labels for
major classes that could be higher than the selection threshold
ğ‘‡ğ‘šğ‘ğ‘—ğ‘œğ‘Ÿ. We used the sampling rate introduced in by Wei et al. [ 67]
to select more pseudo-labels from minor classes in the subsequent
iterationofSSLtoobtainalessbiasedtracelinkclassifier.Unlabeled
tracelinks thatarepredictedasmajor classesappearin ğ‘†ğ‘ ğ‘¢ğ‘ğ‘ ğ‘’ğ‘¡as
the balance of ğ‘Ÿ1=(#ğ‘‡ğ‘Ÿğ‘¢ğ‘’/#ğ¹ğ‘ğ‘™ğ‘ ğ‘’)ğ›¼, andğ‘Ÿ0=(#ğ‘‡ğ‘Ÿğ‘¢ğ‘’/#ğ‘‡ğ‘Ÿğ‘¢ğ‘’)ğ›¼,
whereğ›¼â‰¥0tunesthe sampling, respectively.
Also, it should be noted that there are other mechanisms to
smooth and select pseudo-labels in class-balancing policies [ 71] of
SSL, and we merely use one of the simple and effective strategies.
3.4.3 Re-sampling. The SSL framework is also compatible with
existing re-sampling methods, hence, we used SMOTE [ 16] on
updated training set ğ·ğ‘™âˆªğ‘†ğ‘ ğ‘¢ğ‘ğ‘ ğ‘’ğ‘¡in each round of SSL phase, to
generate minor trace instances artificially by interpolating data
from knownminorcasesinsampling data.
4 EXPERIMENTSETUP
This experiment investigates the following research questions:
â€¢RQ1:CanSPLINTbettersupportautomatictracelinkpredictiontasks
in real-world projects?
â€¢RQ2: How is each component enhanced in SPLINT contributing to
effectiveness?
â€¢RQ3:HowdoesdifferentCBST-Adjustparametersimpacttheeffec-
tivenessofSPLINT?
In order to answer our three research questions, we conducted
the several experiments with six OSS software projects and ten
industrialprojects.
4.1 Experiment Metrics
Our paper presents ğ‘ƒğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘› (P),ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™(R), andğ¹ğ›½results for the
minorclass. ğ‘ƒğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘› =ğ‘‡ğ‘ƒ
ğ‘‡ğ‘ƒ+ğ¹ğ‘ƒwhileğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™=ğ‘‡ğ‘ƒ
ğ‘‡ğ‘ƒ+ğ¹ğ‘,where TP,
FP, and FN refer to the number of true positives (a trace link is
predicted to be â€˜Trueâ€™ and its ground truth is also â€˜Trueâ€™), false pos-
itives(atracelinkispredictedtobeâ€˜Trueâ€™butitsgroundtruthis
â€˜Falseâ€™),andfalsenegatives(atracelinkispredictedtobeâ€˜Falseâ€™but
its ground truth is â€˜Trueâ€™), respectively. ğ¹ğ›½=ğ›½âˆ—(ğ‘ƒğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘› âˆ—ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™)
ğ›½âˆ—ğ‘ƒğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘› +ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™
is used to measure the classifierâ€™s performance as a trade-off be-
tween precision and recall. In traceability research, higher recall is
arguablymoreimportantthanprecisioninpractice[ 43].Hence,we
report the best F2 scores in our experiments by enumerating the
thresholds. AUC is the global area under the Receiver Operating
Characteristic (ROC) curve that is independent and robust of class
distributions of the sample dataset [ 13,41]. The performance of
the classifier was evaluated using the AUC when imbalance effects
were eliminated.
4.2 Experiment Details
WeconductedourexperimentonOpenStackNovaServerwithfour
Intel Core Processors(Skylake)and4GB RAM.
576ESEC/FSE â€™22, November14Å›18, 2022,Singapore, Singapore Liming Dong,He Zhang,WeiLiu, ZhiluoWeng, andHongyu Kuang
Table 4:ComparisonofVSM,baseline [ 59]andSPLINTbest configuration (RQ1)
A.M.De. Dr. Gr. In.Ma. Pi. Avg.(Imp.) P1 P2 P3 P4 P5 P6 P7 P8 P9P10 Avg.(Imp.)IR(VSM)P21.54 60.32 36.28 42.60 20.00 70.59 41.89(+50.36) 51.09 62.41 47.92 16.00 47.06 65.22 41.33 31.25 41.67 56.67 44.88( +13.55)
R59.15 59.69 28.98 41.31 39.13 74.23 50.41(+32.01) 14.33 40.49 28.05 4.4918.18 15.31 7.5119.23 12.20 24.11 17.75( +26.51)
F235.07 47.85 24.15 33.25 26.28 58.78 37.56(+29.70) 13.39 34.84 24.47 4.2016.58 14.46 7.1816.67 11.36 21.79 15.90( +20.61 )
AUC77.82 79.13 64.32 70.22 68.26 84.13 73.98(+17.04) 57.13 70.17 63.76 52.19 58.83 57.60 53.67 59.21 56.00 62.00 58.73( +13.05)BaselineP90.65 93.68 90.41 93.28 94.58 99.57 93.70(-1.45) 21.55 53.71 32.21 44.91 61.37 22.28 44.05 30.62 2.9127.74 34.85( +23.59)
R80.56 96.11 70.19 76.18 68.11 93.67 80.80(+1.62) 55.24 52.09 10.47 37.09 51.90 15.62 5.4818.40 1.5650.29 27.54( +16.73)
F265.91 76.49 58.78 63.26 57.71 75.84 66.33( +0.93) 33.67 41.93 9.6830.74 42.84 13.29 5.3116.00 1.3834.61 21.65( +14.87)
AUC89.86 97.91 85.02 88.03 83.98 96.78 90.26( +0.76) 77.27 75.85 55.08 68.44 74.89 57.46 52.72 58.78 50.01 74.59 63.39( +8.39)SPLINTP84.91 96.13 88.24 94.93 89.29 100.00 92.25 55.05 43.56 84.38 81.82 61.40 91.94 26.42 50.00 31.34 31.97 58.43
R83.33 96.67 72.82 78.24 67.57 95.92 82.42 58.92 61.32 42.19 49.61 60.34 54.29 14.89 24.00 32.81 50.29 44.26
F266.91 77.25 60.36 64.87 56.82 77.37 67.26 46.48 45.36 37.50 43.08 48.44 47.30 13.05 21.43 26.01 36.10 36.52
AUC90.92 98.25 86.31 89.08 83.64 97.96 91.02 79.38 80.31 71.04 74.78 78.96 77.11 57.33 61.76 65.36 74.69 71.78
4.2.1 Comparison Experiment. As SPLINT is an enhancing ap-
proach based on ML-based traceability, we compared it with the
state-of-the-art supervised ML-based trace link classifier proposed
by Rath et al. [ 59]. Throughout the research, we aim to explore
whether SPLINT can mitigate some of the challenges hindering
current traceability approaches in practice. To what extent can per-
formance improvements be achieved tosupport traceability tasks.
Due tothe challenges, simplesize sparsity and feature space spar-
sity(analyzedinSection 2)areuniquetolearning-basedmethods,
we havestillconsideredclassicalIR tracing techniques(e.g.,VSM)
incomparisontoSPLINT.WereportthebestF2scoresofeachbase-
linemodelsinourexperimentsbyenumeratingthethresholds.It
is noteworthy that different combinations of these parameters can
producedifferentresults;hence,wereportthebestconfiguration
of SPLINT parameters with best F2 scores for each project with
followingvalues[ 74,75]:proportionvariable ğ‘1âˆˆ {0.1,0.15,0.2},
ğ‘–ğ‘›ğ‘ğ‘Ÿğ‘’ğ‘ğ‘ ğ‘’ ğ‘Ÿğ‘ğ‘¡ğ‘’ âˆˆ {0.025,0.05,0.1}in CBST-Adjust of SPLINT, and
theğ‘–ğ‘¡ğ‘’ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘œğ‘› âˆˆ {1,2,3}.
4.2.2 AblationExperiment. AspartofRQ2,inordertoexamine
the contributions of the main enhanced components to SPLINT, in-
cludingnewhybridtextualsimilarityfeatures,andSSLmechanisms
basedonCBST,we constructedtwovariants ofSPLINT:
â€¢SPLINT_noHybridIR , which removes the hybrid similarity fea-
turesfromSPLINT.Thus,itdirectlyusespredefinedfeaturessets
(a1toa18inTable 3)totrainthetracelinkclassifier,butstilluses
the unlabeleddata to buildthe final trace linkclassifier.
â€¢SPLINT_noSSL , which removes the component of SSL mech-
anism from SPLINT. It uses the original labeled sets without the
additional selected unlabeled data to build the trace link classifier.
4.2.3 DifferentCBST-AdjustParametersImpactonSSL.. Weper-
formanextensiveexperimenttoevaluateandunderstandthein-
fluence of hyper-parameters in CBST-Adjust on SSL mechanism.
More specifically, tobetter explore selection processâ€™ effectiveness
in â€˜Trueâ€™ link prediction, we examine CBST-Adjust in SSL phase
withdifferentparametersvalues(seeSection 4.2.1).Further,weem-
ployedtheCBST-AdjustselectionstrategyinSSLphaseandextend
theiterationroundsuntilto5roundstoobservetheperformance
trendsofSPLINT.Besides,werandomlyselectP5astheexperiment
data in RQ3. Source code of SPLINT as well as datasets and our
experimental results are available online [ 23]. Reproducibilityand
asubsequent investigation onotherdatasets are hence facilitated.
5 EVALUATION RESULTS
In this section we answer our researchquestionsone byone.
InTable5,weshowtheaveragetrainingandtestingtimeontwo
communities datasets. Because of the complexity of the SPLINTdata-rebalancingprocess,thetrainingtimeissignificantlylonger,
whilethetestingtimeissimilar.Itisacceptablebecausere-training
is not often required (unless the new version of the project is re-
leased),andSPLINTâ€™strainingtimecanbeshortenedthroughaddi-
tionalcomputing resourceswhen itisinpractical use.
Table 5:TrainingandTesting Time forSPLINTvs.baseline
Datasets Time Baseline SPLINT
IndustryTrain(hour) 0.022h 0.331h
Test(second) 0.205s 0.210s
OSSTrain(hour) 0.002h 0.308h
Test(second) 0.081s 0.089s
5.1 Effectiveness ofSPLINT(RQ1)
Table4displaysresultsforbaselinemodels,includingtraditional
IR models (e.g.,VSM), the trace link classifier proposed by Rath et
al. [59] and SPLINT. In the first six columns are results from the
OSS datasets, followed by ten columns for industrial datasets, as
well as averages and improvement rates (A-B) of SPLINT(A) based
on baseline models (B) [ 59]. The bolded values indicate the best
results for eachproject(foreachcolumn).
Thereportmainlydiscussestheaverageimprovementratesof
two communitiesâ€™projects.Inalmostall metrics,VSMisthe least
efficientonselectedOSSprojects.However,itwasbetterthanbase-
linelearning-basedtracelinksclassifier[ 59]onhalfoftheindustrial
projects (e.g., P3, P6, P7, P8 and P9). It is likely that most industrial
projectsstemfromtheirratherchaoticprocessfeaturesduetopoor
traceabilitymanagementpoliciesortightdevelopmentprocesses
(see Section 2.3). Therefore, textual features are further demon-
strated as essential for industrial projects. With the combination of
several different text similarity features, the SPLINT configuration
scores a 29.70% better F2 and a 17.04% better AUC across the six
OSS projects, and a 20.1% better F2 and a 13.05% better AUC across
tenindustrialprojectsthanthe VSM model.
Thebaselinetracelinksclassifier[ 59]achievesthehighestpreci-
sioninOSSprojects Derby,GroovyandMaven andindustrialproject
P7.SPLINToutperformsbaselinetracelinksclassifiers[ 59]on15
out of 16 projects in terms of F2 and AUC, due to its advantages
when pre-processing issue-commit datasets with large imbalances
andseveredatasparseness.Inproject Maven,baselinetracelinks
classifier [ 59] shows competitive results compared with SPLINT
best configuration. The SPLINT configuration achieves an aver-
age 0.93% better F2 and 0.76% better AUC value across the six OSS
projects,and14.87%betterF2and8.39%betterAUCvalueontheten
industrialprojectscomparedto baselinetrace linksclassifier [ 59].
577Semi-supervisedPre-processingforLearning-BasedTraceability Framework onReal-WorldSoftware Projects ESEC/FSE â€™22, November14Å›18, 2022,Singapore, Singapore
Overall, the results from the selected six OSS projects and ten
industrialprojectsconcludedthatSPLINTperformedbetterthan
classic IR method and the state-of-the-art ML-based trace link
modelsforâ€˜Trueâ€™linkspredictionbetweenissue(defect)reportsand
code commits.
5.2 Contributions ofEnhanced Components in
SPLINT(RQ2)
In Figure 5, we present the results of our ablation experiment in
termsofF2.Itallowsustoevaluatethecontributionofenhanced
componentsseparatelyinSPLINT.SPLINTwasexaminedintwo
differentconfigurations.
The first, "SPLINT_noHybridIR" uses the SSL mechanism to
selectunlabeled datafor training classifier,similartoSPLINT,but
ignores all hybrid textual similarity features in feature sets (see
Section3.3).
In comparisonto SPLINT,SPLINT_noHybridIRhasaslightde-
crease for OSS projects and a much larger decrease in industrial
projectsonaverage.Industrialprojectsshowsignificantdropsin
F2,withaveragereductionsofover5%.Usinghybridtextualsimi-
laritymeasureshaslessimpactonOSSprojects(F2decreasedby
approximately0.9%),particularlyon Maven.Indeed,theF2value
evenincreasesslightly.Nevertheless,evenwithoututilizingthehy-
brid IR features, SPLINT_noHybridIRuses unlabeled data toscale
uptrainingsetstomitigatedataimbalanceandsamplingsparsity
issues of the baseline trace links classifier, resulting in higher F2
for 5outof6OSS projectsand7outof10 industrialprojects.
TheconfigurationofSPLINT_noSSLcombinesthesamesetof
featuresasSPLINT,butignoresunlabeledtracelinkswhenupdating
the training sets during rebalancing (see Section 3.4). The result
is that for almost all projects, SPLINT_noSSL vs. SPLINT gives a
largerdecreasethanSPLINT_noHybridIRvs.SPLINT,wherethe
F2 is reduced by an average of 2.5% and 14% for OSS and industrial
projects, respectively. The interpretation is that the SPLINT_noSSL
configuration uses the limited labeled data created in the initial
sample, which suffers from both data imbalance and sample size
sparsityissues.Withthehigherimbalanceratiosandlowerexplicit
link rates, the decrease in SPLINT_noSSL can most clearly be seen
inprojectsP1andP4wheretheF2decreasedtoover30%,compared
to nearly 45%withSPLINT.
0.00%10.00%20.00%30.00%40.00%50.00%60.00%70.00%80.00%90.00%
derby drools groovy
infinispanmavenpig P1 P2 P3 P4 P5 P6 P7 P8 P9P10F2 ScoreIR(VSM) Baseline SPLINT SPLINT-noHybridIR SPLINT-noSSL
Figure 5: Comparison of baselines approaches and different
configurationsofSPLINTinterms ofF2 (RQ2)As a summary, SPLINT has both hybrid textual similarity fea-
turesandtheincorporatedSSLmechanismcontributetoitsoverall
effectiveness,and theSSL mechanisminparticularcontributes to
projectsthat encounter heavierdataimbalance and sparsity.
5.3 ImpactofCBST-Adjust Parameters(RQ3)
TheCBST-Adjustalgorithmusesthe ğ‘/ğ‘–ğ‘›ğ‘ğ‘Ÿğ‘’ğ‘ğ‘ ğ‘’ ğ‘Ÿğ‘ğ‘¡ğ‘’ (seeSection
3.4.2)astheselectionprobabilitythreshold,whichdeterminesthe
quality ofinclusionofthe pseudo-labeledsamples ineachiteration
round.Further,CBST-Adjustusesthesamplingrate ğ›¼asintroduced
by[67],whichcontrolstheper-classsamplingimbalancebiasby
followingtherulethatthelessfrequentaclassis,themoreunla-
beled samples that are predicted as this class are included into the
pseudo-labeledset.
Acomparisonofthedifferentvaluesof ğ‘/ğ‘–ğ‘›ğ‘ğ‘Ÿğ‘’ğ‘ğ‘ ğ‘’ ğ‘Ÿğ‘ğ‘¡ğ‘’ withthe
ğ›¼=1/3sampling rate is shown in Figure 6(a). SSLâ€™s first round
of AUC showed an increase trend no matter what ğ‘/ğ‘–ğ‘›ğ‘ğ‘Ÿğ‘’ğ‘ğ‘ ğ‘’ ğ‘Ÿğ‘ğ‘¡ğ‘’
values were used. However, continually addingunlabeled samples
to the training set resulted in a slight decline in the latter round.
Thereasonforthisisthatbyselectingmoreunlabeledsamplesin
minor classes with highquality earlieron,thiscould help balance
andimprove thetracelinkclassifier learningprocess.In thelatter
round, however, many of the selected unlabeled samples are of
lowquality.Wehavechosen ğ‘/ğ‘–ğ‘›ğ‘ğ‘Ÿğ‘’ğ‘ğ‘ ğ‘’ ğ‘Ÿğ‘ğ‘¡ğ‘’ =0.2/0.025giventhe
largestimprovementintheprojectP5(redlinein 6(a))inthefirst
iteration. When we explore how different ğ‘/ğ‘–ğ‘›ğ‘ğ‘Ÿğ‘’ğ‘ğ‘ ğ‘’ ğ‘Ÿğ‘ğ‘¡ğ‘’ values
impact the prediction effectiveness of trace link classifiers further,
the boundaries between the differentvaluesare hardto discern.
But there are clear boundaries between different sampling rates
ğ›¼as shown in Figure 6(b). In the case where ğ›¼=0(green line in
Figure6(b)),thesamplingpolicyfallsbacktoconventionalCBST
with the same proportion of unlabeled data from per class samples
addedintothelabeledset,resultinginthelowestimprovementafter
generationsofretraining.Classrebalancingsamplingrate( ğ›¼>0)
worksbycontrollingthesamplesizeofthemajorclassesandadding
more samples to the minor classes, which is particularly important
in order to strengthen the performance on â€˜Trueâ€™ links because
ofthedatasparsityandimbalance.Inotherwords,large ğ›¼biases
pseudo-labeled samples towards minority classes. Indeed, large
ğ›¼achieves better AUC as shown in Figure 6(b). Across multiple
parameter configurations, we find that ğ›¼=1achieves the best
class-rebalancing strength.
AswiththetrendsinFigure 6(b),inthetailrounds,itwasstill
difficult to avoid the low-quality samples found within selected
pseudo-labels hindering the modelsâ€™ performance. CBST-Adjust,
should pay careful attention to the quality of pseudo-labels and in
thelateriterations rounds inorder toavoid low qualityunlabeled
samples affecting trace linkmodels.
CBST-Adjust is sensitive to different configurations of hyper-
parametersfortraceability prediction.
6 DISCUSSION
Tothebestofourknowledge,thisisthefirststudythatempirically
investigate the traceability approach using large-scale multiple
industrialdatasets.Thissectiondiscussestheissuesandlessonswe
encounteredduringthis work.
578ESEC/FSE â€™22, November14Å›18, 2022,Singapore, Singapore Liming Dong,He Zhang,WeiLiu, ZhiluoWeng, andHongyu Kuang
0.70.720.740.760.780.80.82
0 1 2 3 4 5AUC
Iteration0.1/0.05 0.15/0.05
0.2/0.025 0.2/0.05
0.2/0.1 p/increase rateÎ±=1/3
(a)Effect of ğ‘/ğ‘–ğ‘›ğ‘ğ‘Ÿğ‘’ğ‘ğ‘ ğ‘’ ğ‘Ÿğ‘ğ‘¡ğ‘’ in CBST-
Adjust(ğ›¼=1/3)0.70.720.740.760.780.80.82
0 1 2 3 4 5AUC
IterationÎ±=0 Î±=1/4 Î±=1/3
Î±=1/2 Î±=1p/increase rate=0.2/0.1
(b)Effect of ğ›¼in CBST-Adjust
(ğ‘/ğ‘–ğ‘›ğ‘ğ‘Ÿğ‘’ğ‘ğ‘ ğ‘’ ğ‘Ÿğ‘ğ‘¡ğ‘’ =0.2/0.1)
Figure 6: AUC of different configurations of hyper-
parametersforCBST-Adjust (RQ3)
6.1 LessonsLearned
Specifically,ourpaperempiricallyanalyzedtwogeneralchallenges
oflearning-basedtraceabilityapproachesinindustrialprojects,data
sparsityandimbalance,whichenablesresearchersandpractitioners
tobetterunderstandthereasonbehindtheunderperformanceof
current automated traceability techniques in practice. As part of
our objectives, SPLINT indeed improved the effectiveness of the
baseline trace link classifier model and classic IR model across
industrialandOSS projectsas showninour study.
Asalimitationofourstudy,weexaminedonlyissues-commit
links recovery tasks. Ideally, enterprises strive to ensure end-to-
end traceability, including traceability between artifacts generated
during various activities, including architecture design, detailed
design,coding,testing,andmaintenance.Aconnectionshouldalso
existbetweeneachoftwoartifacts.Asamatteroffact,differentar-
tifactsaregeneratedbydifferentroleswithindifferentteams.With
more developers and tighter schedule pressure, coding activities
may cause more severe traceability issues. Thus, ensuring code-
relatedtraceabilityshouldbenefitmoreusersandhaveabroader
impact. There is a higher demand for companies for creating, re-
covering,andmaintainingcode-relatedartifactsâ€™traceability(e.g.,
codecommitsandsourcecode)Indeed,SPLINTneedstobefurther
investigated for the potential of recovering other types of artifactsâ€™
traceability.Whenlearning-basedapproachesareusedtotracetwo
artifacts,webelieveSPLINTisaviableoption.Ourfutureworkwill
involveworkingwithourindustrialpartnersonSPLINTappliedto
requirement-to-committraceability,asthesedataandtheirtrace
linksarenowavailable,butstillsufferfrom traceabilityreliability
issues.Forfurtherexplorationonrecoveringimplicitassociation
artifacts,e.g.,testcases-to-code,wealsoexpecttouseintermediate
artifacts, e.g., requirement [ 61] to improve our approach. Addi-
tionally, a more detailed validation and analysis of SPLINT across
variousorganizationsâ€™ projectsisrequiredinthe near future.
WeobservethatSPLINTisnotyetabletoachievesatisfactory
performance in industrial projects. Source code file information is
limited(becauseofconfidentiality),sowewerenotabletomeasure
the most crucial feature, i.e. textual similarity between the most
similar committed source code file and the issue [ 59]. We therefore
only measured the textual similarity of two artifact descriptions
bysegmentingChinesewordsusing Jiebaandcalculatingtheco-
sinesimilaritythrough tf-idfschema.Anothermainreasonsisthat
existing linkstaggedbyhumans havea largeproportionofincor-
rect ground truthtrace linksinlabeled data.In real-life situations,
finding the really useful and correct links to form training samples
isoneofthemajorchallengesoflearning-basedapproaches.Itispossibletoincreasegroundtruthtracelinkaccuracybyusing active
learning[49,56]toselectrepresentativeandlessdatafortraining
rather than all labeled data at once. Although this requires some
effortfromdevelopers,thedatasetswilleliminateincorrectlinks
and train models based on representative data. Furthermore, the
incorporationofactivelearningintoSSLmechanisms[ 31]might
leadto more beneficialresults.
Finally, as discussed in RQ3, the optimal configuration of hyper-
parameters with the appropriate iteration rounds needs further
studytoensurethequalityofselectedunlabeledsamplesanden-
hancethestrengthofclass-balancingmechanismwhenapplying
CBST-Adjust to support real-world traceability with large imbal-
anceproblems.
6.2 Threatsto Validity
Intermsofinternalvalidity,theremightbeathreatfromSPLINT
implementations for the compared experiments. In order to reduce
this threat, Section 4.2presents a detailed description of the experi-
mentalsetupandimplementationdata.Moredetailedexperiment
datasets and the source code are shared online [ 23]. Besides the
more frequent code commits in real-world projects, the artifacts
selectedinourpapermightboosttheimbalanceratioaswell.There
isapossibilitythatnotallincludedcommitsareappropriatetoorga-
nizecandidatetracelinks,sincesomecommitsrelatetoothertasks
(e.g.,newrequirement).Inindustrialcontexts,however,itisinad-
visabletoexcludesuchcommitsbecausemanydevelopersforget
toindicate theissueIDassociated withcodechanges, replacedby
tagging requirements IDfor code changes. To mitigate the impact
of included candidate commits, we adopt ğœ–interval proposed by
Rathetal. [ 59] butadjusting itasadynamicparameteraccording
toindividualprojectconstraints.Toreducetherandomeffectsof
trainingbias,werepeattrainingandtestingtentimesandcompute
theaverageresults.Todemonstratesignificantdifferencesbetween
the different models, we applied the Wilcoxon signed-rank test.
As a result of the static splitting rate of 4:1, sample bias towards
trainingandtestsetsmayresult.A5-foldtime-seriesvalidationwas
performed as well. Because of the different distribution of the data
in each fold, time-series validation did not outperform the static
splitrate.Allexperimentswererunwithasinglestaticsplittingrate,
ensuring the valid comparison of different classifiers. To reduce
samplingbias,wewillstudytheeffectsofthesplittingrateinfuture.
The datasets used may pose an external threat to validity. Aligning
with the previous work [ 59], we used the OSS datasets common to
others. Various commercial projects from different product lines
wereusedforevaluatingindustrydatasetsbutfromasingleorga-
nization. Our findings may suffer from an external validity issue if
being generalized to a broader set of opensourceand commercial
projects.SPLINTisexpectedtobeevaluatedonmoredatasetsfrom
avarietyofdomainsandorganizationsinthe future.
7 RELATED WORK
7.1 AutomaticTraceability Approaches
The studies have devoted considerable effort to developing new
approaches to automatic traceability. The most commonly used
approachesincludeIRtechniques(e.g.,VSM[ 33,69],LSI[36,46],
JS [2]) to rank artifacts or candidate links based on document sim-
ilarity. Further, the topic modeling techniques, e.g., LDA [ 8,53]
579Semi-supervisedPre-processingforLearning-BasedTraceability Framework onReal-WorldSoftware Projects ESEC/FSE â€™22, November14Å›18, 2022,Singapore, Singapore
andNonNegative MatrixFactorization(NMF)[ 51]can effectively
captureuniqueinformation.Thus,weappliedhybridtextualsim-
ilarity measures used in[ 51] to achieve deep parsing into textual
similarity features to mitigate sparseness in features matrix for
real-world industrial applications. The learning-based models (e.g.,
RCLinker [ 39], TRAIL [ 50]) to traceability is also being used for
developing classifiers that can determine whether the links are
related[26,45].Comparativelytopreviousstudiesthatproposed
ML-basedapproaches,ourworkdoesnotonlyfocusonapplying
aML-basedtracelinkmodelbutalsoempiricallyinvestigatesthe
reasonsforML-basedmodelsperformpoorlyinreal-worldprojects.
Few studies have examined possible solutions to the data imbal-
ance problem. Researchers have used under-sampling to rebalance
the training set when modeling trace links [ 39,59,64]. Contrary
to this, TRAIL [ 50] suggests the use of oversampling (SMOTE).
Re-samplingislesseffectiveagainstseveredataimbalanceissues
caused by complex development processes in real-world scenar-
ios,[35,38].Differentfrompreviousworks,weincorporatesemi-
supervised learning for training a trace link classifier in SPLINT,
which has the ability to predict trace links better with unlabeled
sets,aswellasmitigateimbalancesbyincorporatingtheadjusted
CBST policy. Furthermore, integrating semi-supervised learning
strategies help mitigate the problems caused by data sparsity as
well as the limited amount of training data, which is one of the
obvious weaknesses of [ 43,49]. Other previous studies provide
some specific solutions for limited data challenge, such as using
deep learning techniques (TraceBERT [ 43]), capturing developer
feedback [ 51], and integrating active learning [ 49]. Despite this,
thesesolutionshavenotbeenempiricallyevaluatedinvariousscale
real-worldindustrialprojects.OurpaperdemonstratesthatSPLINT
is more effective than a state-of-the-art supervised approach, as
evidencedbyboththeOSSaswellasindustrialcommunityprojects.
7.2EmpiricalEvaluationonIndustrialDatasets
Ingeneral,researchersexamined theevaluationoftraceabilityap-
proaches onindustrial datasets inlessclosely related research[ 20,
28,52,73]. This is largely due to the availability of industrial
datasets.Severalrecentpublicationshaveconcentratedonempir-
ical analyses on real-world traceability applications [ 6,9,11,60].
Forexample,thepriorworkusedIRtechniquestorecoverthetrace
linksbetweensourcecodeandtestcasestoseeifIRtechniquescan
be used to support test case selection with industry data [ 65], they
found that scaling IR techniques to industry data is challenging.
Guoetal.[ 30]proposedaDL-basedmodelontheRNNforgenerat-
inglinksbetweensubsystemrequirementsanddesigndefinitions
against a smalldataset from a communication-based traincontrol
system.Bycombiningmultiplemeasuresoftextualsimilarity,de-
veloper feedback, and transitive links, Moran et al. [ 51] implement
a hierarchical probabilistic model (Comet) based on a company
system(i.e.Cisco). anddevelopedaJenkinsPlugin.
The work we do contributes to the two newly identified chal-
lenges (i.e. the availability of traceability datasets and the appli-
cation of traceability approaches in real-world scenarios) in the
2017 Grand Challenges of Traceability [ 6], in order to facilitate
theapplicationoftraceabilityapproachestoreal-worldsituations.
The focus of our work is not only on real-world applications of
traceability approaches, but also on exploring the root causes ofunderperformanceoflearning-basedtraceabilityapproachesem-
pirically by analyzing data based on multiple scales of industry
systemsfrom alarge ICT enterprise.
7.3 Semi-SupervisedLearning in Traceability
RecentpapershavestartedimprovingSSLapproachesfortheim-
balanceddistributionofdataincomputervisionresearch[ 37,67,
70]. In two similar studies, the use of unlabeled data was investi-
gated[10,49].Bellaetal.[ 10]presentedasemi-supervisedlearning
approach based on IR-based similarity measures. This technique
involves choosing the training set heuristically based on the IR re-
sults.Ascomparedtotheheuristicthresholdsuggestedin[ 10],our
adjusted framework (CBST-Adjust) is more practical and effective
in mitigating the data imbalance and sparsity problems encoun-
teredinreal-worldsettings.Millsetal.,[ 49]usedactivelearning
(ALCATRAL) and trace link classifier to work with less training
data. Active learning is suggested for preparing initial labeled data
for training purposes, which is then verified by developers. The
difficultyliesinthefactthat,afteralongevolution,trainingdata
is difficult to tag. In this paper, we propose a trace link classifier
frameworkwithSSLtogenerateunlabeleddataautomaticallyto
eliminaterepetitive manual labeling.
8 CONCLUSION
Theexistingautomated traceability approachessufferfrompracti-
calissuesinspiteofexperiencingyearsofexperimentation.This
paperproposesSemi-SupervisedPre-processingforLearning-based
Traceability framework (SPLINT) with the incorporationof an ad-
justed class-balancing self-training in semi-supervised learning
(SSL) mechanism and hybrid semantic similarities. It is capable
of solving data imbalance and sparsity problems encountered in
real-world projects. SPLINT was evaluated on six large-scale open-
sourceprojectsandtenindustrialprojectsselectedfromourpart-
ners. The results were compared against two state-of-the-art trace-
ability approaches (simple IR and classic trace links classifiers [ 59]
that are used to predict issue-commit trace links. SPLINT was also
examined separately for the contributions of incorporated compo-
nents. Evaluation results confirm hybrid semantic similarity and
SSLmechanismscan assistinpredictingissue-committracelinks
thatareaffectedbydataimbalancesandsparsity.Inaddition,the
adjustedCBSTinSSL(CBST-Adjust)usedinthispaperworksef-
fectivelyfortheselectionofpseudo-labelsonminorclassesfrom
unlabeledtrace sets,demonstrating SPLINTâ€™s practicability.
ACKNOWLEDGMENTS
HongyuKuangisthecorrespondingauthorofourpaper.Ifyouare
interestedin our work, pleasedonot hesitate tocontact him.This
workissupportedbytheNationalNaturalScienceFoundationof
China (No.62072227), the National Key Research and Development
ProgramofChina(No.2019YFE0105500)jointlywiththeResearch
Council of Norway (No.309494), the Key Research and Develop-
mentProgramofJiangsuProvince(No.BE2021002-2),aswellasthe
Intergovernmental Bilateral Innovation Project of Jiangsu Province
(No.BZ2020017).
DATA-AVAILABILITYSTATEMENT
The authorsconfirmthatthedataandsource codesupporting the
findingsofthis study are available at [ 23].
580ESEC/FSE â€™22, November14Å›18, 2022,Singapore, Singapore Liming Dong,He Zhang,WeiLiu, ZhiluoWeng, andHongyu Kuang
REFERENCES
[1]AhronAbadi,MordechaiNisenson,andYahalomitSimionovici.2008. ATrace-
ability Technique for Specifications. In Proceedings of the 16th International Con-
ference onProgramComprehension (ICPC â€™08) .IEEEComputer Society,103Å›112.
https://doi.org/10.1109/ICPC.2008.30
[2]NasirAli,Yann-GaÃ«lGuÃ©hÃ©neuc,andGiulianoAntoniol.2013. Trustrace:Mining
Software Repositories to Improve the Accuracy of Requirement Traceability
Links.IEEE Transactions on Software Engineering 39, 5 (2013), 725Å›741. https:
//doi.org/10.1109/TSE.2012.71
[3]Nauman Bin Ali and Kai Petersen. 2012. A Consolidated Process for Software
ProcessSimulation:StateoftheArtandIndustryExperience.In Proceedingsof
the38thEuromicroConferenceonSoftwareEngineeringandAdvancedApplications
(SEAA â€™12) . IEEE Computer Society, 327Å›336.
[4]Giuliano Antoniol, Gerardo Canfora, Gerardo Casazza, Andrea De Lucia, and
Ettore Merlo. 2002. Recovering Traceability Links between Code and Documen-
tation.IEEE Transactions onSoftwareEngineering 28,10(2002), 970Å›983.
[5]GiulianoAntoniol,GerardoCanfora,AndreaDeLucia,andEttoreMerlo.1999.
RecoveringCodetoDocumentationLinksinOOSystems.In Proceedingsofthe6th
WorkingConference on ReverseEngineering (WCREâ€™99) .IEEEComputerSociety,
136Å›144. https://doi.org/10.1109/WCRE.1999.806954
[6]Giuliano Antoniol, Jane Cleland-Huang, Jane Huffman Hayes, and Michael Vier-
hauser. 2017. Grand Challenges of Traceability: The Next Ten Years. CoRR
abs/1710.03129 (2017).
[7]Hazeline U. Asuncion, Arthur U. Asuncion, and Richard N. Taylor. 2010. Soft-
wareTraceability withTopicModeling. In Proceedingsofthe 32ndInternational
ConferenceonSoftwareEngineering (ICSEâ€™10) .95Å›104. https://doi.org/10.1145/
1806799.1806817
[8]HazelineU.Asuncion,ArthurU.Asuncion,andRichardN.Taylor.2010. Software
traceability with topic modeling. In Proceedings of the 32nd ACM/IEEE Inter-
national Conference on Software Engineering (ICSE â€™10) . ACM, 95Å›104. https:
//doi.org/10.1145/1806799.1806817
[9]ThazinWinWinAung,HuanHuo,andYuleiSui.2020. ALiteratureReviewof
Automatic Traceability Links Recovery for Software Change Impact Analysis. In
Proceedings ofthe28th InternationalConferenceon ProgramComprehension (ICPC
â€™20). ACM,14Å›24. https://doi.org/10.1145/3387904.3389251
[10]EmmaEffaBella,Marie-PierreGervais,RedaBendraou,LaurentWouters,andAli
Koudri.2018. Semi-SupervisedApproachforRecoveringTraceabilityLinksin
Complex Systems. In Proceedings of 23rd International Conference on Engineering
of Complex Computer Systems (ICECCS â€™18) . IEEE Computer Society, 193Å›196.
https://doi.org/10.1109/ICECCS2018.2018.00030
[11]Markus Borg. 2014. Embrace your issues: compassing the software engineering
landscapeusingbugreports.In ACM/IEEEInternationalConferenceonAutomated
Software Engineering (ASE â€™14) . ACM, 891Å›894. https://doi.org/10.1145/2642937.
2653469
[12]Markus Borg, Per Runeson, and Anders ArdÃ¶. 2014. Recovering from a
Decade: A Systematic Mapping of Information Retrieval Approaches to Soft-
ware Traceability. Empirical Software Engineering 19, 6 (2014), 1565Å›1616.
https://doi.org/10.1007/s10664-013-9255-y
[13]Andrew P Bradley. 1997. The Use of the Area Under the ROC Curve in the
Evaluation of Machine Learning Algorithms. Pattern recognition 30, 7 (1997),
1145Å›1159. https://doi.org/10.1016/S0031-3203(96)00142-2
[14]William B. Cavnar. 1995. Using An N-Gram-Based Document Representation
With A Vector Processing Retrieval Model. NIST SPECIAL PUBLICATION SP
(1995), 269Å›269.
[15]Olivier Chapelle, Bernhard SchÃ¶lkopf, and Alexander Zien (Eds.). 2006. Semi-
SupervisedLearning . The MITPress.
[16]NiteshV.Chawla,KevinW.Bowyer,LawrenceO.Hall,andW.PhilipKegelmeyer.
2002. SMOTE:SyntheticMinorityOver-samplingTechnique. JournalofArtificial
IntelligenceResearch 16(2002), 321Å›357. https://doi.org/10.1613/jair.953
[17]Bihuan Chen, Linlin Chen, Chen Zhang, and Xin Peng. 2020. BUILDFAST:
History-AwareBuildOutcomePredictionforFastFeedbackandReducedCost
in Continuous Integration. In Proceedings of the 35th International Conference on
Automated Software Engineering (ASE â€™20) . IEEE, 42Å›53. https://doi.org/10.1145/
3324884.3416616
[18]Xiaofan Chen and John C. Grundy. 2011. Improving Automated Documentation
toCodeTraceabilitybyCombiningRetrievalTechniques.In Proceedingsofthe
26th International Conference on Automated Software Engineering (ASE â€™11) . IEEE
Computer Society, 223Å›232.
[19]JaneCleland-Huang.2012. TraceabilityinAgileProjects. In SoftwareandSystems
Traceability . 265Å›275.
[20]JaneCleland-Huang.2015. TowardMeaningfulIndustrial-AcademicPartnerships.
IEEE Software 32,1 (2015), 18Å›21. https://doi.org/10.1109/MS.2015.20
[21]JaneCleland-Huang,AdamCzauderna,MarekGibiec,andJohnEmenecker.2010.
A Machine Learning Approach for Tracing Regulatory Codes to Product Specific
Requirements. In Proceedings of the 32nd International Conference on Software
Engineering (ICSE â€™10) . ACM, 155Å›164. https://doi.org/10.1145/1806799.1806825
[22]AngeloCorallo,MariaElenaLatino,MartaMenegoli,andPierpaoloPontrandolfo.
2020. A Systematic Literature Review to Explore Traceability and LifecycleRelationship. International Journal of Production Research 58, 15 (2020), 4789Å›
4807.https://doi.org/10.1080/00207543.2020.1771455
[23]LimingDong,HeZhang,WeiLiu,ZhiluoWeng,andHongyuKuang.2022. SPLINT
Packagefor"Semi-supervisedPre-processingforLearning-BasedTraceabilityFrame-
work onReal-World SoftwareProjects" .https://doi.org/10.5281/zenodo.7111136
[24]Tianbao Du, Guohua Shen, Zhi-qiu Huang, Yaoshen Yu, and Dexiang Wu.
2020. Automatic Traceability Link Recovery via Active Learning. Frontiers
of Information Technology & Electronic Engineering 21, 8 (2020), 1217Å›1225.
https://doi.org/10.1631/FITEE.1900222
[25]AlexanderEgyed,FlorianGraf,andPaulGrÃ¼nbacher.2010. EffortandQuality
ofRecoveringRequirements-to-CodeTraces:TwoExploratoryExperiments.In
Proceedings of the 18th International Requirements Engineering Conference (RE
â€™10). IEEE Computer Society, 221Å›230. https://doi.org/10.1109/RE.2010.34
[26]Davide Falessi, Massimiliano Di Penta, Gerardo Canfora, and Giovanni Cantone.
2017.Estimatingthenumberofremaininglinksintraceabilityrecovery. Empirical
Software Engineering 22, 3 (2017), 996Å›1027. https://doi.org/10.1007/s10664-016-
9460-6
[27]Malcom Gethers, Rocco Oliveto, Denys Poshyvanyk, and Andrea De Lucia.
2011. On Integrating Orthogonal Information Retrieval Methods to Improve
Traceability Recovery. In Proceedings of the 27th International Conference on
Software Maintenance (ICSM â€™11) . IEEE Computer Society, 133Å›142. https:
//doi.org/10.1109/ICSM.2011.6080780
[28]OrlenaGotel,JaneCleland-Huang,JaneHuffmanHayes,AndreaZisman,Alexan-
der Egyed, Paul GrÃ¼nbacher, Alex Dekhtyar, Giuliano Antoniol, and Jonathan I.
Maletic.2012. The GrandChallengeofTraceability (v1.0) . Springer, 343Å›409.
[29]O. C. Z. Gotel and Anthony Finkelstein. 1994. An Analysis of the Requirements
Traceability Problem. In Proceedings of the 1st International Conference on Re-
quirementsEngineering .IEEEComputerSociety,94Å›101. https://doi.org/10.1109/
ICRE.1994.292398
[30]Jin Guo, Jinghui Cheng, and Jane Cleland-Huang. 2017. Semantically Enhanced
SoftwareTraceabilityUsingDeepLearningtechniques.In Proceedingsofthe39th
International Conference on Requirements Engineering (ICSE â€™17) . 3Å›14.https:
//doi.org/10.1109/ICSE.2017.9
[31]Jiannan Guo, Haochen Shi, Yangyang Kang, Kun Kuang, Siliang Tang, Zhuoren
Jiang, Changlong Sun, Fei Wu, and Yueting Zhuang. 2021. Semi-supervised
Active Learning for Semi-supervised Models: Exploit Adversarial Examples with
Graph-based Virtual Labels. In Proceedings of the 2021 IEEE/CVF International
ConferenceonComputerVision(ICCVâ€™21) .IEEE,2876Å›2885. https://doi.org/10.
1109/ICCV48922.2021.00289
[32]Mouna Hammoudi, Christoph Mayr-Dorn, Atif Mashkoor, and Alexander Egyed.
2021. A Traceability Dataset for Open Source Systems. In Proceedings of the 18th
InternationalConferenceonMiningSoftwareRepositories(MSRâ€™21) .IEEE,555Å›559.
https://doi.org/10.1109/MSR52588.2021.00073
[33]JaneHuffmanHayes,AlexDekhtyar,andSenthilKarthikeyanSundaram.2006.
AdvancingCandidateLinkGenerationforRequirementsTracing:TheStudyof
Methods. IEEE Transactions onSoftwareEngineering 32,1 (2006), 4Å›19.
[34]Minsung Hyun, Jisoo Jeong, and Nojun Kwak. 2020. Class-Imbalanced Semi-
Supervised Learning. CoRRabs/2002.06815 (2020).
[35]Harsurinder Kaur, Husanbir Singh Pannu, and Avleen Kaur Malhi. 2019. A
Systematic Review on Imbalanced Data Challenges in Machine Learning: Ap-
plications and Solutions. Comput. Surveys 52, 4 (2019), 79:1Å›79:36. https:
//doi.org/10.1145/3343440
[36]Nilam Kaushik, Ladan Tahvildari, and Mark Moore. 2011. Reconstructing Trace-
ability between Bugs and Test Cases: An Experimental Study. In Proceedings
of the 18th Working Conference on Reverse Engineering (WCRE â€™11) . 411Å›414.
https://doi.org/10.1109/WCRE.2011.58
[37]JaehyungKim,Youngbum Hur, SejunPark, EunhoYang,SungJu Hwang,and
JinwooShin.2020. DistributionAligningRefineryofPseudo-labelforImbalanced
Semi-supervisedLearning.In Proceedingsof33rdAnnualConferenceonNeural
InformationProcessingSystems (NeurIPS â€™20) .
[38]BartoszKrawczyk.2016. Learningfromimbalanceddata:openchallengesand
future directions. Progress in Artificial Intelligence 5, 4 (2016), 221Å›232. https:
//doi.org/10.1007/s13748-016-0094-0
[39]Tien-Duy B Le, Mario Linares-VÃ¡squez, David Lo, and Denys Poshyvanyk. 2015.
RCLinker:AutomatedLinkingofIssueReportsandCommitsLeveragingRich
Contextual Information. In Proceedings of the 23rd International Conference on
Program Comprehension (ICPC â€™15) . 36Å›47.https://doi.org/10.1109/ICPC.2015.13
[40]Dong-Hyun Lee. 2013. Pseudo-Label : The Simple and Efficient Semi-Supervised
LearningMethodforDeepNeuralNetworks. ICML2013Workshop:Challenges
inRepresentation Learning (07 2013).
[41]Stefan Lessmann, Bart Baesens, Christophe Mues, and Swantje Pietsch. 2008.
Benchmarking Classification Models for Software Defect Prediction: A Proposed
Framework and Novel Findings. IEEE Transactions on Software Engineering 34, 4
(2008), 485Å›496. https://doi.org/10.1109/TSE.2008.35
[42]YueLi,HeZhang,LimingDong,BohanLiu,andJinyuMa.2020. Constructing
a Hybrid Software Process Simulation Model in Practice: An Exemplar from
Industry. In Proceedings of the 15th International Conference on Software and
SystemProcesses (ICSSP â€™20) .
581Semi-supervisedPre-processingforLearning-BasedTraceability Framework onReal-WorldSoftware Projects ESEC/FSE â€™22, November14Å›18, 2022,Singapore, Singapore
[43]Jinfeng Lin, Yalin Liu, Qingkai Zeng, Meng Jiang, and Jane Cleland-Huang. 2021.
Traceability Transformed: Generating more Accurate Links with Pre-Trained
BERT Models. In Proceedings of the 43rd International Conference on Software
Engineering (ICSEâ€™21) .IEEE,324Å›335. https://doi.org/10.1109/ICSE43902.2021.
00040
[44]Bohan Liu, He Zhang, Lanxin Yang, Liming Dong, Haifeng Shen, and Kaiwen
Song. 2020. An Experimental Evaluation of Imbalanced Learning and Time-
SeriesValidationintheContextofCI/CDPrediction.In Proceedingsofthe24th
Evaluation and Assessment in Software Engineering (EASE â€™20) . ACM, 21Å›30.
https://doi.org/10.1145/3383219.3383222
[45]SugandhaLohar,SorawitAmornborvornwong,AndreaZisman,andJaneCleland-
Huang. 2013. Improving Trace Accuracy through Data-Driven Configuration
andCompositionofTracing Features.In JointMeeting oftheEuropeanSoftware
Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of
Software Engineering (ESEC/FSE â€™13) . ACM, 378Å›388. https://doi.org/10.1145/
2491411.2491432
[46]MarcoLormansandArievanDeursen.2006. CanLSIhelpReconstructingRe-
quirements Traceability in Design and Test?. In Proceedings of 10th European
ConferenceonSoftwareMaintenanceandReengineering (CSMRâ€™06) .IEEECom-
puter Society, 47Å›56. https://doi.org/10.1109/CSMR.2006.13
[47]AndrianMarcus,JonathanI.Maletic,andAndreySergeyev.2005. Recoveryof
TraceabilityLinksbetweenSoftware DocumentationandSourceCode. Interna-
tional Journal of Software Engineering and Knowledge Engineering 15, 5 (2005),
811Å›836. https://doi.org/10.1142/S0218194005002543
[48]Salome Maro, Miroslaw Staron, and Jan-Philipp SteghÃ¶fer. 2017. Challenges
of Establishing Traceability in the Automotive Domain. In Software Quality.
ComplexityandChallengesofSoftwareEngineeringinEmergingTechnologies-9th
International Conference (SWQD â€™17) . Springer, 153Å›172. https://doi.org/10.1007/
978-3-319-49421-0_11
[49]Chris Mills, Javier Escobar-Avila, Aditya Bhattacharya, Grigoriy Kondyukov,
Shayok Chakraborty, and Sonia Haiduc. 2019. Tracing with Less Data: Active
LearningforClassification-BasedTraceabilityLinkRecovery.In Proceedingsof
the 35th International Conference on Software Maintenance and Evolution (ICSME
â€™19). IEEE,103Å›113. https://doi.org/10.1109/ICSME.2019.00020
[50]ChrisMills,JavierEscobar-Avila,andSoniaHaiduc.2018. AutomaticTraceability
Maintenance via Machine Learning Classification. In Proceedings of the 34th
InternationalConferenceonSoftwareMaintenanceandEvolution(ICSMEâ€™18) .IEEE
Computer Society, 369Å›380. https://doi.org/10.1109/ICSME.2018.00045
[51]KevinMoran,DavidN.Palacio,CarlosBernal-CÃ¡rdenas,DanielMcCrystal,Denys
Poshyvanyk, Chris Shenefiel, and Jeff Johnson. 2020. Improving the Effective-
ness of Traceability Link Recovery Using Hierarchical Bayesian Networks. In
Proceedingsofthe42ndInternationalConferenceonSoftwareEngineering (ICSE
â€™20). ACM,873Å›885.
[52]ChristianNeumullerandPaulGrÃ¼nbacher.2006. AutomatingSoftwareTraceabil-
ity in Very Small Companies: A Case Study and Lessons Learned. In Proceedings
of the 21st International Conference on Automated Software Engineering (ASE â€™06) .
145Å›156.
[53]Rocco Oliveto, Malcom Gethers, Denys Poshyvanyk, and Andrea De Lucia. 2020.
OntheEquivalenceofInformationRetrievalMethodsforAutomatedTraceability
Link Recovery: A Ten-Year Retrospective. In Proceedings of 28th International
Conference on Program Comprehension (ICPC â€™20) . ACM, 1. https://doi.org/10.
1145/3387904.3394491
[54]Michael C. Panis. 2010. Successful Deployment of Requirements Traceability
in a Commercial Engineering Organization...Really. In Proceedings of the 18th
InternationalRequirements Engineering Conference (REâ€™10) . 303Å›307.
[55]RezaMeimandiParizi,SaiPeckLee,andMohammadDabbagh.2014. Achieve-
ments and Challenges in State-of-the-Art Software Traceability Between Test
and CodeArtifacts. IEEE Transactions onReliability 63,4 (2014), 913Å›926.
[56]JulianAronPrennerandRomainRobbes.2021.MakingthemostofsmallSoftware
Engineering datasets with modern machine learning. CoRRabs/2106.15209
(2021).
[57]Michael Rath,David Lo,and Patrick MÃ¤der.2018. Analyzing Requirementsand
Traceability Information to Improve Bug Localization. In Proceedings of the 15thInternationalConference onMiningSoftwareRepositories (MSR â€™18) . 442Å›453.
[58]Michael Rath and Patrick MÃ¤der. 2019. The SEOSS 33 DatasetÃRequirements,
Bug Reports, Code History, and Trace Links for Entire Projects. Data in brief 25
(2019), 104005. https://doi.org/10.1016/j.dib.2019.104005
[59]MichaelRath,JacobRendall,JinL.C.Guo,JaneCleland-Huang,andPatrickMÃ¤der.
2018. Traceability in the Wild: Automatically Augmenting Incomplete Trace
Links. In Proceedings of the 40th International Conference on Software Engineering
(ICSEâ€™18) . ACM,834Å›845. https://doi.org/10.1145/3180155.3180207
[60]Patrick Rempel and Patrick MÃ¤der. 2017. Preventing Defects: The Impact of
Requirements Traceability Completeness on Software Quality. IEEE Transactions
onSoftwareEngineering 43,8 (2017), 777Å›797.
[61]Alberto D. Rodriguez, Jane Cleland-Huang, and Davide Falessi. 2021. Leveraging
IntermediateArtifactstoImproveAutomatedTraceLinkRetrieval.In Proceedings
of the 37th International Conference on Software Maintenance and Evolution . IEEE,
81Å›92.https://doi.org/10.1109/ICSME52107.2021.00014
[62]Hang Ruan, Bihuan Chen, Xin Peng, and Wenyun Zhao. 2019. DeepLink: Re-
coveringIssue-CommitLinksBasedonDeepLearning. JournalofSystemsand
Software158(2019), 110406. https://doi.org/10.1016/j.jss.2019.110406
[63]Ana Stanescu and Doina Caragea. 2014. Semi-Supervised Self-training Ap-
proaches for Imbalanced SpliceSite Datasets (BICoB â€™14) .
[64]Yan Sun, Qing Wang, and Ye Yang. 2017. FRLink: Improving the Recovery
of Missing Issue-Commit Links by Revisiting File Relevance. Information and
SoftwareTechnology 84(2017),33Å›47. https://doi.org/10.1016/j.infsof.2016.11.010
[65]MichaelUnterkalmsteiner,TonyGorschek,RobertFeldt,andNiklasLavesson.
2016. Large-scale information retrieval in software engineering - an experience
reportfromindustrialapplication. EmpiricalSoftwareEngineering 21,6(2016),
2324Å›2365. https://doi.org/10.1007/s10664-015-9410-8
[66]RobertWatkinsandMarkNeal.1994. WhyandHowofRequirementsTracing.
IEEE Software 11,4 (1994), 104Å›106.
[67]Chen Wei, Kihyuk Sohn, Clayton Mellina, Alan L. Yuille, and Fan Yang. 2021.
CReST: A Class-Rebalancing Self-Training Framework for Imbalanced Semi-
Supervised Learning. CoRRabs/2102.09559 (2021). https://doi.org/10.1109/
CVPR46437.2021.01071
[68]Stefan Winkler and Jens von Pilgrim. 2010. A Survey of Traceability in Re-
quirementsEngineering and Model-Driven Development. Software and Systems
Modeling 9,4 (2010), 529Å›565.
[69]Suresh Yadla, Jane Huffman Hayes, and Alex Dekhtyar. 2005. Tracing re-
quirements to defect reports: an application of information retrieval tech-
niques.Innovations in Systems and Software Engineering 1, 2 (2005), 116Å›124.
https://doi.org/10.1007/s11334-005-0011-3
[70]YuzheYangandZhiXu.2020. RethinkingtheValueofLabelsforImprovingClass-
Imbalanced Learning. In Proceedings of 34th the Annual Conference on Neural
InformationProcessingSystems (NeurIPS â€™20) .
[71]YuzheYang,KaiwenZha,Ying-CongChen,HaoWang,andDinaKatabi.2021.
DelvingintoDeepImbalancedRegression.In Proceedingsofthe38thInternational
Conference onMachineLearning (ICML â€™21) . PMLR, 11842Å›11851.
[72]HongboZhang,BinengZhong,QingLei,Ji-XiangDu,JialinPeng,Duansheng
Chen, and Xiao Ke. 2017. Sparse Representation-Based Semi-Supervised Regres-
sionforPeopleCounting. ACMTransactionsonMultimediaComputingCommuni-
cations and Applications 13, 4 (2017), 47:1Å›47:17. https://doi.org/10.1145/3106156
[73]Waleed Zogaan, Palak Sharma, Mehdi Mirakhorli, and Venera Arnaoudova. 2017.
Datasets from FifteenYears ofAutomated RequirementsTraceability Research:
CurrentState,Characteristics,andQuality.In Proceedingsofthe25thInternational
RequirementsEngineeringConference .IEEEComputerSociety,110Å›121. https:
//doi.org/10.1109/RE.2017.80
[74]Yang Zou, Zhiding Yu, B. V. K. Vijaya Kumar, and Jinsong Wang. 2018. Un-
supervisedDomainAdaptationforSemanticSegmentationviaClass-Balanced
Self-Training. In Proceedings of the 15th European Conference on Computer Vision
(ECCV â€™18) . Springer, 297Å›313. https://doi.org/10.1007/978-3-030-01219-9_18
[75]YangZou,ZhidingYu,XiaofengLiu,B.V.K.VijayaKumar,andJinsongWang.
2019. Confidence Regularized Self-Training. In 2019 IEEE/CVF International
ConferenceonComputerVision(ICCVâ€™19) .IEEE,5981Å›5990. https://doi.org/10.
1109/ICCV.2019.00608
582