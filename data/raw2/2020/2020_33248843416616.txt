BuildFast: History-Aware Build Outcome Prediction for Fast
Feedback and Reduced Cost in Continuous Integration
Bihuan Chen
School of Computer Science and Shanghai
Key Laboratory of Data Science
Fudan University
Shanghai, ChinaLinlin Chen
School of Computer Science and Shanghai
Key Laboratory of Data Science
Fudan University
Shanghai, China
Chen Zhang
School of Computer Science and Shanghai
Key Laboratory of Data Science
Fudan University
Shanghai, ChinaXin Peng
School of Computer Science and Shanghai
Key Laboratory of Data Science
Fudan University
Shanghai, China
ABSTRACT
Longbuildtimesincontinuousintegration(CI)cangreatlyincrease
thecostinhumanandcomputingresources,andthusbecomeacom-monbarrierfacedbysoftwareorganizationsadoptingCI.Buildout-comepredictionhasbeenproposedasoneoftheremediestoreducesuchcost.However,thestate-of-the-artapproacheshaveapoorpre-dictionperformanceforfailedbuilds,andarenotdesignedforpracti-calusagescenarios.Toaddresstheproblems,wefirstconductanem-
pirical study on 2,590,917 builds to characterize build times in real-
worldprojects,andasurveywith75developerstounderstandtheir
perceptionsaboutbuildoutcomeprediction.Then,motivatedbyourstudyandsurveyresults,weproposeanewhistory-awareapproach,namedBuildFast,topredictCIbuildoutcomescost-efficientlyandpractically.Wedevelopmultiplefailure-specificfeaturesfromclosely
related historical builds via analyzing build logs and changed files,
andproposeanadaptivepredictionmodeltoswitchbetweentwo
modelsbasedonthebuildoutcomeofthepreviousbuild.Weinves-tigateapracticalonlineusagescenarioof BuildFast,wherebuilds
are predicted in chronological order, and measure the benefit from
correct predictions and the cost from incorrect predictions. Our
experiments on 20 projects have shown that BuildFast improved
the state-of-the-art by 47.5% in F1-score for failed builds.
CCS CONCEPTS
•Software and its engineering →Maintaining software.
KEYWORDS
Continuous Integration, Build Failures, Failure Prediction
ACM Reference Format:
Bihuan Chen, Linlin Chen, Chen Zhang, and Xin Peng. 2020. BuildFast:
History-AwareBuildOutcomePredictionforFastFeedbackandReduced
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ASE ’20, September 21–25, 2020, Virtual Event, Australia
© 2020 Association for Computing Machinery.
ACM ISBN 978-1-4503-6768-4/20/09...$15.00
https://doi.org/10.1145/3324884.3416616Cost in Continuous Integration. In 35th IEEE/ACM International Conference
onAutomatedSoftwareEngineering(ASE’20),September21–25,2020,Virtual
Event, Australia. ACM, New York, NY, USA, 12 pages. https://doi.org/10.
1145/3324884.3416616
1 INTRODUCTION
Continuousintegration(CI)isasoftwaredevelopmentpracticewhere
developersarerequiredtomergetheircodeintoasharedrepositoryfrequently[
15,19].Eachintegrationisthenverifiedthroughanau-
tomatedbuild,includingdependencyinstallation,codecompilationandtestcaseexecution.CIbringsmultiplebenefitstoasoftwareor-ganization;e.g.,ithelpstofindandfixintegrationerrorsearlierandfaster,improvedeveloperpr oductivity,improvepro ductqualityand
reduce development and delivery time [15, 27, 28, 52].
Apartfromthebenefits,CIcanincurhighcosts[ 28].Inparticular,
oneofthewell-recognizedcostsinCIiscausedbythetimedurationofabuild(a.k.a.buildtime)[
22,28].Asreportedbyarecentstudyon
open-sourceprojects,over40%ofthebuildshaveatimedurationofover30minutes[
22],whichfarexceedstheacceptablebuildtimeof
10 minutes [ 19,27]. Such long build times greatly increase the cost
in human and computing resources, and hence become a common
barrier faced by software organizations adopting CI [27, 53].
Ontheonehand,developersneedtowaitforalongtimetogetin-
tegrationfeedbackbeforetheycontinuetoworkontheverified,lat-estcodebase.Asaresult,developerslosefocusandbecomelesspro-
ductive, which hinders parallel development and overshadows the
benefitsofCI.Ontheotherhand,computingresourcesrequiredforrunningbuildsareusuallyinproportiontobuildtimes[
42].Hence,a
tremendous investment in computing resources (e.g., millions of
dollars in Google [28]) is needed to support slow builds.
ToreducesuchcostinCI,anumberoftechniqueshavebeenpro-
posedfromdifferentperspectives.Onelineofworkisfocusedonde-
velopingtestcaseprioritizationtechniques[ 9,16,36,39,60]andtest
caseselectiontechniques[ 41,49]intoCIinordertominimizetestex-
ecutiontimesandspeedupbuilds.Complementarytothem,oneline
of work attempts to skip specific builds (e.g., only having non-
sourcecodechanges)forsavingtheirwholebuildtimesviaman-
ual configurations [ 12,13] or automated rule-based/learning-based
methods [ 3,4]. More aggressively, build outcome prediction [ 18,
25,26,33,44,47,56,59] leverages machine learning techniques
422020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE)
topredictbuildoutcomessuchthatthecostofthebuildsthatare
predicted to pass can be reduced. As our empirical study reports
that over 70% of the builds are passed (Sec. 2.1), build outcome
prediction can potentially lead to high cost reduction.
Despiterecentadvances,buildoutcomepredictionstillsuffersthe
followingproblems,heavilyhinderingtheirpracticaladoptioninCI.
First,failed builds have a poor prediction performance. Since passed
buildsoftenaccountforaverylargeportionofallbuildsinaproject,existingtechniquestendtopredictbuildsaspassedsuchthattheycanstillyieldanoverallgoodperformancealthoughtheyhaveapoorper-formanceonfailedbuilds.However,failedbuilds,ifincorrectlypre-dicted,canincurhighcost.Moreimportantly,existingtechniquesfailtoutilizefeaturesthatcanbettercapturethecharacteristicsofbuildfailures.Specifically,sometechniques[
25,33,47,56]leveragesocial
andtechnicalfactorstolearnpredictionmodelswithoutdistinguish-ingpassedandfailedbuilds.Morerecently,sometechniques[
26,44]
trytoleveragefailure-specificfeatures,butinacoarse-grainedway
(e.g., failure ratio [44] and types of build failures [26]).
Second,practicalusagescenariosarenotwellconsidered.AsCIbuilds
arriveinchronologicalorder,abuild’soutcomeshouldbepredictedbasedonapredictionmodellearnedfromitspreviousbuilds.Hence,theperformanceofexistingtechniquesobtainedbywidely-usedcross-
validationdeviatestheperformanceinpractical onlinescenarios.Such
negativedeviationshavealsobeenempiricallyreported[
57].More-
over,thecostfromincorrectpredictionsandthebenefitfromcorrect
predictions are important indicators, which are closely relevant to
practical usage scenarios. However, without accounting for usage
scenarios, existing techniques only measure the prediction perfor-
mance, but do not systematically analyze the cost and benefit.
Inthispaper,wefirstconductalarge-scaleempiricalstudy,using
2,590,917 builds from 1,621 GitHub projects, to investigate the timedurationofCIbuilds.Ourstudyisdesignedtocharacterizethesever-ityofslowbuildsinpracticeandmotivatethepotentialofbuildout-comeprediction.Wealsoconductanonlinesurveywith75develop-erstoretrievefirst-handinformationaboutdevelopers’perceptions
ofbuildoutcomeprediction.Oursurveyresultsrevealconsistent
concernswiththeabovetwoproblemsofbuildoutcomeprediction.
Then,toaddressthetwoproblems,weproposeahistory-awareap-
proach,BuildFast,topredictCIbuildoutcomescost-efficientlyandpractically.Itcanhelptoobtainfastintegrationfeedbackandreduceintegrationcost.Specifically,toaddressthefirstproblem,wedesign
multiple failure-specific features via digging deep into historical
builds,i.e.,analyzingbuildlogs andchangedfilesfromcloselyre-
latedhistoricalbuilds.Wealsodevelopanadaptivepredictionmodeltoswitchbetweentwomodelsbasedontheoutcomeofthepreviousbuild.Thesetwomodelsareseparatelytrained,respectivelyusinga
representative set of builds. To address the second problem, we in-
vestigateapracticalonlineusagescenarioof BuildFast,wherethe
builds are predicted in chronological order, to measure the benefit
from correct predictions and the cost from incorrect predictions.
Toevaluatetheeffectivenessandefficiencyof BuildFast,wecom-
paredBuildFastwiththreestate-of-the-artapproaches[ 26,44,59]
on20Javaopen-sourceprojects.Ourevaluationresultshavedemon-stratedthatBuildFastcansignificantlyimprovethebestofthestate-of-the-artapproachesby47.5%inF1-scoreforfailedbuildswithoutlosingF1-scoreforpassedbuilds.Thebenefitof BuildFastexceeds
its cost; and the average time overhead to predict a build is 1.3seconds, which is practical. We also demonstrated the contribution
of each component in BuildFast to its effectiveness improvement.
In summary, this paper makes the following contributions.
•Weconductedanempiricalstudytocharacterizebuildtimesinreal-
worldprojectsaswellasadevelopersurveytounderstandtheirper-
ceptions on build outcome prediction.
•Weproposedahistory-awareapproach,namedBuildFast,topre-
dict CI build outcomes cost-efficiently and practically.
•Weconductedlarge-scaleexperimentson20open-sourceprojects
to demonstrate the effectiveness and efficiency of BuildFast.
The rest of the paper is structured as follows. Section 2 presents
anempiricalstudyofbuildtimesandadevelopersurveytomotivate
build outcome prediction. Section 3 introduces the proposed ap-proach in detail. Section 4 evaluates the proposed approach. Sec-
tion 5 reviews related work before Section 6 draws conclusions.
2 MOTIVATION
Inthissection,wefirstpresentanempiricalstudyofbuildtimesinalargecorpusofopen-sourceprojectsandthenreportoursurveywith
developers to better motivate build outcome prediction.
2.1 Build Time Study
Ourempiricalstudyofbuildtimesisfocusedonopen-sourceprojectsduetotheirpubliclyavailablebuilddata.Westartwiththedatasetpro-posedbyZhangetal.[
62],whichcontainstheCIbuildhistoryof3,799
open-sourceJavaprojectshostedonGitHub.Tothebestofourknowl-edge,thisisthelargestdatasetofCIbuilds.TofurtherensurethattheprojectsuseCIfrequently,weexcludetheprojectsthathavelessthan
300 builds, which results in 1,621 projects with a total of 2,612,775
builds.Indetail,2,590,917(99.2%)ofthemhaveabuildstateof passed,
erroredorfailed. An errored or failed build is called a brokenbuild.
Thedifferenceisthattheerrorthatcausesanerroredbuildoccursin
anearlierbuildphasethantheerrorthatcausesafailedbuild.There-maining21,858(0.8%)ofbuildshaveuncommonstates(i.e., canceled
andstarted), and thus are not considered in this study.
Using2,590,917buildsfrom1,621projects,ourstudyisdesignedto
answer the following three research questions.
RQ1:Howlongisthetimedurationofpassed,erroredandfailedCI
builds across all the projects?
RQ2:Howmanypassed,erroredandfailedCIbuildscanbecon-
sidered as slow in each project?
RQ3:Howmuchbuildtimeisconsumedbythepassed,erroredand
failed CI builds in each project?
InRQ1,wereporttheoverallbuildtimedistributionrespectivelyfor
allpassed,erroredandfailedbuildsinthe2,590,917builds.In RQ2,we
measureforeachprojecttheratioofslowbuildsamongallpassed,er-roredandfailedbuildsrespectively,andreporttheratiodistributionacrossallprojects.Here,weregardabuildasslowifithasabuildtimeofmorethan10minutes,becausetheacceptablebuildtimeis10min-utes[
19,27].Ourresultsfrom RQ1andRQ2aimtocharacterizethe
generalityandseverityoftheincurredhighcostsbybuildtimes,andmotivatethepotentialvalueofbuildoutcomepredictioninreducingcosts.In
RQ3,wemeasureforeachprojectthetotalbuildtimeofall
passed,erroredandfailedbuildsrespectively,analyzeitsratiotothe
43(a) Build Time (b) Ratio of Slow Builds (c) Ratio of Build Time
Figure 1: Distributions of Build Time, Ratio of Slow Builds and Ratio of Build Time w.r.t. Build States
totalbuildtimeofallbuildsineachproject,andreporttheratiodis-
tributionacrossallprojects.Ourresultsfrom RQ3aimtorepresent
thespaceofcostreductionthatcanbepotentiallyexploredbybuildoutcomeprediction.Itisalsoworthmentioningthat,ofthe2,590,917builds,72.2%,10.5%and17.3%arepassed,erroredandfailed,respec-tively.Onlyaboutonequarterofthebuildsarebroken;andsuchim-
balance between passed and broken builds can challenge learning-
based build outcome prediction (as discussed in Sec. 1).
OverallBuildTime(RQ1). Fig.1agivestheoverallbuildtimedis-
tributionforallbuilds,passedbuilds,erroredbuilds,failedbuildsand
brokenbuildsinviolinplotinlogarithmicscale.Thethreelinesineach
plotrespectivelydenotetheupperquartile,themedianandthelowerquartile.Weobservethatthemediantimedurationofallbuildsis9.3minutes,whichismuchshorterthanreportedinapreviousstudy[
22]
(i.e.,20minutes).Thislargedifferencecouldbeattributedtothesmall
dataset(i.e.,104,442buildsin67projects)ofthepreviousstudy[ 22].
Wealsoobservethatpassed,errored,failedandbrokenbuildshavea
mediantimedurationof9.4,5.2,10.5and8.9minutesrespectively.Ex-ceptforerroredbuilds,themediantimedurationofpassed,failedandbrokenbuildsisveryclosetotheacceptable10-minutebuildtime[
19,
27],denotedbythebluelineinFig.1a.Morespecifically,47.7%,40.7%,
51.4%and47.4%ofthepassed,errored,failedandbrokenbuildsareslowbuilds.Further,onequarterofthepassed,errored,failedandbro-kenbuildshaveatimedurationofover22.3,26.2,30.2and28.9min-utes,while8.1%,12.6%,14.1%and13.5%ofthepassed,errored,failedandbrokenbuildseventakemorethananhourtorun.TheseresultsdemonstratethatCIbuildsoftentakeamoderatelylongtimetorun.Inthatsense,developersneedtowaitforamoderatelylongtimeto
get the integration feedback, which incurs moderately high costs.
RatioofSlowBuilds(RQ2). Fig.1bshowsthedistributionofthe
ratioofslowbuildsamongpassed,errored,failedandbrokenbuildsacrossallprojectsinviolinplot.Usingthemedians,weobservethatatleast15.2%,13.3%,9.1%and12.6%ofthepassed,errored,failedandbrokenbuildsareslowinhalfoftheprojects.106(6.5%)projectshave
noslowbuild.Atfirstglance,thisresultseemstobeinconsistent
withtheresultinFig.1a(i.e.,aroundhalfofthebuildsareslow).This
canbeexplainedbytheobservationthatprojectswithalargerlinesofcodearemorelikelytohavealargernumberofbuildsandahigherratioofslowbuilds,andthedifferenceisstatisticallysignificant(i.e.,p<0.0001inWilcoxonSigned-Ranktest).Moreover,usingtheupper
quartiles,wesurprisinglyobservethatmorethan61.9%,40.0%,46.7%and42.7%ofthepassed,errored,failedandbrokenbuildsareslowinTable 1: Survey Questions
Q1Are you a professional or part-time software developer?
Q2How large is your company?
Q3How many years of Java programming experience do you have?
Q4How many projects have you worked on?
Q5How many years of CI experience do you have?
Q6How often does your team trigger CI builds of your projects?
Q7Are CI builds of your projects time-consuming?
Q8Would CI build outcome prediction techniques be useful for CI-
based software development?
Q9Why would CI build outcome prediction be useful?
Q10Why would CI build outcome prediction not be useful?
onequarteroftheprojects.TheseresultsindicatethatslowbuildsareamoderatelycommonproblemfacedbydevelopersadoptingCI,es-
pecially in large-scale projects.
RatioofBuildTime(RQ3). Fig.1cpresentsthedistributionof
theratioofbuildtimeconsumedbythepassed,errored,failedandbro-kenbuildsacrossallprojectsinviolinplot.Wecanobservethatmorethan72.4%,83.6%and90.2%ofthebuildtimeisconsumedbypassedbuildsin75%,50%and25%oftheprojects,whereasatmost9.8%,16.4%and27.6%ofthebuildtimeisconsumedbybrokenbuildsin25%,50%and75%oftheprojects.Thisisconsistentwiththeimbalancednum-
ber of passed and broken builds. These results demonstrate that a
considerablylargeamountoftimeisspentinpassedbuilds,whichrep-resentstheoptimalcostreductionthatcanbepotentiallyachievedby
build outcome prediction (see Sec. 3.4 for a detailed discussion).
2.2 Developer Survey
OuronlinesurveyisdesignedfordeveloperswhoparticipatedinCI-basedsoftwaredevelopment.Therefore,werandomlyselect15,000de-
velopersfrom57,939developerswhotriggeredCIbuildsinthe1,621
projectsusedinourempiricalstudy.Wesendanemailtoeachofthe
15,000developerstointroducethebackgroundonbuildoutcomepre-
dictionandinvitethemtotakeouronlinequestionnairesurvey.Wepromisethattheirparticipationwouldremainconfidential,andouranalysis and reporting would be based on aggregated responses. Inresponsetoourinvitation,75developersfinishedthequestionnaire
within one week (i.e., a participation rate of 0.5%).
AsreportedinTable1,oursurveyconsistsof10questionstolearn
aboutalltheparticipants’professionalbackground,CIusage,and
44perceptions ofbuild outcome prediction.The completequestion-
naire with options is available at our website [2].
ProfessionalBackground(Q1-Q4) .Ofallparticipants,93.3%are
professionaldevelopers,andonly6.7%arepart-timedevelopers.45.3%
workinacompanyofmorethan100employees,12.0%workinacom-
panyof51to100employees,and42.7%workinacompanyofupto50
employees.42.7%haveover10yearsofexperienceinJavaprogram-
ming,32.0%have6to10years,and25.3%haveupto5years.58.7%have
participatedinthedevelopmentofmorethan15projects,5.3%haveparticipatedin11to15projects,and36.0%haveparticipatedinupto
10projects.Webelievethattheparticipantshaveconsiderablygood
experience in parallel software development.
CIUsage(Q5-Q7). 16.0%oftheparticipantshaveusedCIforover
10years,41.3%and34.7%haverespectivelyusedCIfor6to10years
and2to5years,andonly8.0%haveusedCIforlessthan2years.Withrespecttothebuildfrequency,for52.0%oftheparticipants,theirteamaveragelytriggersaCIbuildeveryhour,andfor34.7%ofthepartici-pants,theirteamaveragelytriggersaCIbuildeveryminute.9.3%alsocommenttheirteamtriggersaCIbuildforeverycommit.WhenaskedaboutwhetherCIbuildsaretime-consuming,69.3%fullyagree,while
26.7% clearly disagree and 4% are not sure.
PerceptionofBuildOutcomePrediction(Q8-Q10). 48.0%of
theparticipantsthinkthatbuildoutcomepredictionwouldbeuseful,but26.7%thinkthatitwouldnotbeuseful.25.3%arenotsuremostlybecauseitdependsonhowitworksandhowwellitworks.Further,
theparticipantsreportthreemajorreasonsfortheusefulness,i.e.,
obtainingfastfeedbackofCIbuilds(61.3%),savingtimeoverheadofCIbuilds(50.7%),andacceleratingsoftwaredevelopment(41.3%).Ontheotherhand,theparticipantsalso revealfourmajor reasonsforthe
uselessness,i.e.,lackingpredictionperformance(especiallyforfailed
builds) (81.3%), delaying the discovery of bugs due to incorrect pre-
dictions(73.3%),lackingexplainability(andhencedevelopersdonottrustit)(48.0%),andincreasingthedifficultyofbugfixingduetoin-
correct predictions (44.0%). Besides, around half of the participants
commentedthatCIbuildshadtoberantoobtainthebuildartifactsthatwouldbeneededbyotherprojects,especiallyforpassedbuilds.
Insights. Fromoursurveyresults,webelievethatbuildoutcome
predictionhasitsownpotentialmeritforfastfeedbackandreducedcostinCI.However,thepredictionperformance(especiallyforfailedbuilds)shouldbetakengreatcareof,asamajorityofthedevelopers
have concerns on it. The cost and benefit of build outcome predic-
tion should be holistically investigated under a practical usage sce-
nariosothatdeveloperscanhaveaholisticviewratherthanfearing
the cost andcan have more trust to trybuild outcome prediction.
3 METHODOLOGY
Inthissection,wefirstpresentanoverviewof BuildFast,andthen
elaborate each step of BuildFast in detail.
3.1 Overview
Ourhistory-awarebuildoutcomepredictionapproachusesmachinelearningtechniques,andhencehastwobasicphases:trainingphaseandpredictionphase.Inthetrainingphase,BuildFastfirstextractsthreesetsoffeaturesforeachbuildinatargetproject(i.e.,featureex-
tractioninSec.3.2).Then,BuildFasttrainsanoveladaptivepre-
dictionmodelwiththe extractedfeaturesfromasetof builds (i.e.,Table 2: Features about the Current Build
IDFeature Description
C1src_churn # of lines of production code changed
C2test_churn # of lines of test code changed
C3src_ast_diff whetherproductioncodeischangedinAST
C4test_ast_diff whether test code is changed in AST
C5line_added # of added lines in all files
C6line_deleted # of deleted lines in all files
C7files_added # of files added
C8files_deleted # of files deleted
C9files_modified # of files modified
C10src_files # of production files changed
C11test_files # of test files changed
C12config_files # of build script files changed
C13doc_files # of documentation files changed
C14class_changed # of classes modified, added or deleted
C15met_sig_modified # of method signatures modified
C16met_body_modified # of method bodies modified
C17met_changed # of methods added or deleted
C18field_changed # of fields modified, added or deleted
C19import_changed # of import statements added or deleted
C20class_modified # of classes modified
C21class_added # of classes added
C22class_deleted # of classes deleted
C23met_added # of methods added
C24met_deleted # of methods deleted
C25field_modified # of fields modified
C26field_added # of fields added
C27field_deleted # of fields deleted
C28import_added # of import statements added
C29import_deleted # of import statements deleted
C30commits # of commits included
C31fix_commits # of bug-fixing commits included
C32merge_commits # of merge commits included
C33committers # of unique committers
C34by_core_member whether a core member triggers the build
C35is_master whetherthebuildoccursonmasterbranch
C36time_interval time interval since the previous build
C37day_of_week day of week when the build starts
C38time_of_day time of day when the build starts
prediction model generation in Sec. 3.3). In the prediction phase,
BuildFast extracts the same sets of features for a build under pre-
diction, and uses the trained model to predict its build outcome.
Moreover,wesystematicallyexploreapracticalusagescenarioof
BuildFast to measure the cost and benefit (i.e., cost-benefit analy-
sisinSec.3.4).AlthoughcurrentlyimplementedforJavaprojects
thatuseTravisastheCIservice,BuildFastcanbeeasilyextended
to support other programming languages and other CI services by
providing specific implementations for feature extraction.
3.2 Feature Extraction
Wesurveythefeaturesadoptedinthestate-of-the-artapproaches[ 26,
44,45,59],andfindthattheirfeaturesaremostlydirectlytakenfrom
theTravisTorrentdatabase[ 7],whichisageneral-purposedatabase
butisnotspecializedforbuildoutcomeprediction.Asaresult,high-levelcoarse-grainedfeaturesareusedwithoutfurtherdiggingdeep
45Table 3: Features about the Previous Build
IDFeature Description
P1pr_state build state (i.e., passed, errored or failed)
P2pr_compile_error whether compilation error occurs
P3pr_test_exception whether tests throw exceptions
P4pr_tests_ok # of tests passed
P5pr_tests_fail # of tests failed
P6pr_duration overall time duration of the build
P7pr_src_churn # of lines of production code changed
P8pr_test_churn # of lines of test code changed
intothecharacteristicsaboutbuildfailures.Therefore,weintroduce
severalfine-grainedfailure-specificfeaturestoenhancetheexistingfeaturesbasedonadetailedanalysisofbuildlogsandchangedfiles.
Buildlogscontainhistoricalknowledgeaboutpreviousbuildfail-
ures[30,32,46,54]whichcanbelearnedtopredictfuturebuildout-
comes,whilehowfilesarechangedinabuildcanaffectitsbuildout-
come. In general, we derive the features of a build (i.e., the current
build)inthreedimensions,i.e.,featuresaboutthecurrentbuild,fea-
tures about the previous build, and features about historical builds.
FeaturesabouttheCurrentBuild. Asthebuildlogofthecur-
rentbuildisunavailable(atpredictiontime),wederivethefeaturesfromfilechangesinthecurrentbuild.Table2givesthefeatureswithournewfeaturesinbold.C
1–C6representline-levelchanges,where
C3and C4are newly derived to analyze changes at the level of ab-
stractsyntaxtree(AST)sothatformattingchanges(e.g.,removingaspace)thatwillnotfailabuildaredistinguished.C
7–C13denotefile-
level changes by distinguishing various kinds of files. C 14–C19are
class-, method-, field- and import-level changes. However, they failtodistinguishhowaclass,method,fieldandimportischanged.Forexample,adeletedclasshasahigherprobabilitytocauseabuildfail-urethananaddedclassbecausethedeletedclassmightbeusedbutitsusageisnotaccordinglyupdated.Hence,wederivenewfeatures
C20–C29to distinguish modified, added and deleted classes, meth-
ods,fieldsandimports.C 30–C33denotecommit-levelknowledge.
Asabuildincludesasetofcommits,weintroduceC 31–C32todistin-
guishthetypesofcommitsasbug-fixingandmergingcommitshaveahighprobabilitytocausebuildfailuresduetopotentialincompletefix or merging conflict, and C
33to measure the degree of collabora-
tioninthecurrentbuildasahighdegreeofcollaborationmightleadtoahighpossibilityofconflicts.Finally,C
34–C38representthemeta
dataaboutthecurrentbuild,i.e.,whotriggersthecurrentbuild,and
where andwhen thecurrent buildis triggered. Herewe introduce
C34and C35because core members may less likely to fail a build
and developers work more carefully on master branches.
FeaturesaboutthePreviousBuild. Asbuildfailuresoftencon-
secutivelyoccur[ 26],thecharacteristicsofthepreviousbuildoften
serveasagoodindicator.Table3reportsthefeaturesaboutthepre-
viousbuildofthecurrentbuildwithournewfeaturesinbold.Specif-
ically,P1–P6arederivedfromthebuildlogofthepreviousbuild.We
introduceP 4andP5tomeasurethedegreeoffailurecausedbytest-
ing.Intuitively,alargernumberoffailedtestsindicatesahigherdif-
ficulty to fix the failed build, and thus a higher probability to have
a consecutive build failure. P 6measures the build time of the previ-
ous build. A longer build time indicates a higher complexity of the
code and thus a higher possibility to fail. P 7and P8measure theTable 4: Features about Historical Builds
IDFeature Description
H1fail_ratio_pr % of broken builds in all the previous builds
H2fail_ratio_pr_incincrementoffail_ratio_pratlastbrokenbuild
to fail_ratio_pr at penultimate broken build
H3fail_ratio_re % of broken builds in recent 5 builds
H4fail_ratio_com_pr%ofbrokenbuildsinallthepreviousbuilds
thatweretriggeredbythecurrentcommitter
H5fail_ratio_com_re%ofbrokenbuildsinrecent5buildsthatwere
triggered by the current committer
H6last_fail_gap # of builds since the last broken build
H7consec_fail_max maximum of # of consecutive broken builds
H8consec_fail_avg average of # of consecutive broken builds
H9consec_fail_sum sum of # of consecutive broken builds
H10commits_on_files # of commits on the files in last 3 months
H11file_fail_prob_maxmaximum of the probability of each changed
file involved in previous broken builds
H12file_fail_prob_avgaverageoftheprobabilityofeachchangedfile
involved in previous broken builds
H13file_fail_prob_sumsumoftheprobabilityofeachchangedfilein-
volved in previous broken builds
H14pr_src_files#ofproductionfileschangedbetweenthelat-
est passed build and the previous build
H15pr_src_files_insize of the intersection of src_files and
pr_src_files
H16pr_test_files# of test files changed between the latest
passed build and the previous build
H17pr_test_files_insize of the intersection of test_files and
pr_test_files
H18pr_config_files#ofbuildscriptfileschangedbetweenthelat-
est passed build and the previous build
H19pr_config_files_insize of the intersection of config_files and
pr_config_files
H20pr_doc_files#ofdocumentationfileschangedbetweenthe
latest passed build and the previous build
H21pr_doc_files_insize of the intersection of doc_files and
pr_doc_files
H22log_src_files# of production files reported in thebuild log
of the previous build
H23log_src_files_insize of the intersection of log_src_files and
src_files
H24log_test_files#oftestfilesreportedinthebuildlogofthe
previous build
H25log_test_files_insizeoftheintersectionoflog_test_filesand
test_files
H26team_size size of team contributing in last 3 months
degree of code changes in the previous build; and a high degree of
code changes may also increase the difficulty to fix the failed build.
FeaturesaboutHistoricalBuilds. Table4reportsthefeatures
about historical builds with our new features in bold. In particular,
H1–H5represent statistics about previous broken builds by distin-
guishing all previous builds, the recent five builds, and all previous
builds and the recent five builds triggered by the committer of the
current build.Here we introduceH 2to measurethe increment be-
tween the failure ratio at the last and penultimate broken build. A
positivevalueindicatesanincreasingtrendinbuildfailures.H 6–H9
arenewlyintroducedtomodelthedistancetothelastbrokenbuild,
andthenumberofhistoricalconsecutivebrokenbuilds.Alarger
46valueofthesefeaturesindicateahigherpossibilityofbuildfailures.
H10–H25arenewlydesignedtomeasuretheconnectionofthefiles
changedinthecurrentbuild(hereafterreferredtoascurrentfilesfor
theeaseofpresentation)tohistoricalbuilds.Indetail,H 10measures
thenumberofcommitsinthelastthreemonthsthatchangethecur-rentfiles.Ahighvalueofthisfeaturedenotesthatthecurrentbuildchangesfrequentlychangedfiles.Asfrequentlychangedfilesoftenhavehighpotential ofbugs[
14],itislikely tofailthecurrentbuild.
H11–H13measuretheprobabilitythateachcurrentfileischangedin
previousbrokenbuilds.Thehigherthevalue,thehigherpossibilitytofailthecurrentbuild.H
14,H16,H18andH20measurethenumber
ofproduction,test,buildscriptanddocumentationfileschanged
between the latest passed build and the previous build. If the previ-
ous build is broken, they actually measure the files changed in the
previous consecutive broken builds. Therefore, a higher value indi-
catesahigherdifficultytofixpreviousbrokenbuilds.H 15,H17,H19
andH21measuretheintersectionbetweenthecurrentfilesandthe
changedfilesinpreviousconsecutivebrokenbuilds.Thesmallertheintersection,thelowerpossibilitytofixpreviousbrokenbuilds.Sim-ilarly,H
22andH24measurethenumberofproductionandtestfiles
reportedinthebuildlogofthepreviousbuild.Suchfilesarelistedinbuildlogsmostlyduetoexceptionsinproductionandtestfiles,and
hence indicate the potential root causes of exceptions. Therefore, a
higher value indicates a higher difficulty to fix exceptions. H 23and
H25measuretheirintersectiontocurrentproductionandtestfiles.A
smaller intersection indicates a lower possibility to fix exceptions.
H26measures the degree of collaboration in the last three months.
Duetospacelimitation,weomittheimplementationdetailoffea-
ture extraction. The implementation and a detailed explanation of
each feature are available at our website [2].
3.3 Prediction Model Generation
Ourpredictionmodelisdesignedtohavetwocharacteristics,i.e.,fea-
ture selection and adaptive model, to improve the performance.
FeatureSelection. AsshowninTable2,3and4,atotalof72fea-
turesareintroducedfromthreedimensions.Consideringthepoten-
tially different characteristics of different projects, we leverage fea-
tureselectionmethods[ 24]toautomaticallyselectthefeaturesthat
contributemosttobuildoutcomepredictionforaspecificproject,in-steadofmanuallydeterminingafixedsetoffeaturesforallprojects.
Aswillbediscussedinourevaluation(seeSec.4.4),differentsetsof
features are selected for different projects.
AdaptiveModel. Whetherthepreviousbuildfailsorpasseshasa
differentimpactonthedevelopmentactivitiesinthecurrentbuild.Ifthepreviousbuildfails,developersmainlyconductcorrectiveorpre-
ventiveactivitiesduringthecurrentbuild.Ifthepreviousbuildpasses,
developers mainly perform adaptive or perfective activities during
thecurrentbuild.Thus,tolearnsuchdifferenceswithoutconfusingthemodel,weseparateourtrainingdatasetintotworepresentative
datasets; i.e., the first dataset includes the builds whose previous
buildfailsandtheseconddatasetincludesthebuildswhoseprevious
build passes. However, both datasets still have imbalanced data for
passed and failed builds, which might hinder the prediction perfor-
mance for failed builds. To partially solve this problem, we include
allthefailedbuildsintothetwodatasetswithoutdistinguishingthe
buildoutcomeoftheirpreviousbuild;i.e.,wefurtherincludethefailed builds whose previous build passes into the first dataset, andfurther include the failed builds whose previous build fails into the
seconddataset.Basedonthesetwodatasets,werespectivelytrainamodeltopredictbuildoutcomes.Inthisway,inthepredictionphase,if the build under prediction has a failed previous build, we use the
first model, and if the build under prediction has a passed previous
build, we use the second model.
3.4 Cost-Benefit Analysis
Practicalusagescenarioshavetobeanalyzedtomeasurethecostandbenefitofbuildoutcomeprediction.AsCIbuildsarriveinchronolog-icalorder,buildoutcomehastobepredictedinanonlinewayinchrono-logicalorder.Exceptfor[
18,45,59],alltheexistingapproachesdonot
predict in chronological order but in a cross-validation way (i.e., a
buildmaybepredictedbasedonamodellearnedfromfuturebuilds).
Following this online scenario, build outcome prediction can be
usedintwoscenarios,dependingonwhetherthepredicted-to-passbuildsareranornot.First,eachbuildisactuallyran.However,teammembersandprojectmanagerscouldhavemoreconfidencetostartusingthelatestcodebaseandconductingprojectplanwithoutwait-ingforthebuildtofinishifitispredictedtopass.Hence,computingresourcesarenotreduced;butwaitingtimesarereduced,promotingparalleldevelopmentandspeedingupthereleasecycle.Second,thepredicted-to-failbuildsareactuallyran,whilethepredicted-to-passbuildsareskipped.Therefore,computingresourcesarealsoreduced.Inbothscenarios,however,developersmayworkonthebuggycodebaseandneedtoredoorrollbacktheirworkifthepredictionisnot
correct (i.e., predicted-to-pass builds actually fail). In the latter sce-
nario,thoseintegrationerrorsmayaccumulateforalongtimewith-
out timely correction, increasing the fixing efforts.
Asindicatedbyoursurvey(seeSec.2.2),developershavemorecon-
cernsonthesecondaggressiveusagescenario,e.g.,delayingthedis-coveryofbugsduetoincorrectpredictions,increasingthedifficultyofbugfixingduetoincorrectpredictions,andrequiringthebuildar-tifactsthatwouldbeneededbyotherprojects.Therefore,wedecidetotakethefirstconservativeusagescenario.Underthisscenario,thebenefitcomesfromthecorrectpredictionforpassedbuilds.Hereweusethebuildtimeofsuchbuildsastheindicatorofthe benefit.Aswe
donotdirectlypinpointtherootcauseofbuildfailures,weconsidernobenefitfromthecorrectpredictionforfailedbuilds.Correspond-ingly, the cost comes from the incorrect prediction for failed builds.Hereweusethebuildtimeofsuchbuildsastheindicatorofthe cost,
andconsidernocostfromtheincorrectpredictionforpassedbuildsbecausedeveloperswouldwaitforthebuildtocompleteinthesame
wayasnobuildoutcomepredictionapproachisused.Finally,we
define the gainas the difference between benefit and cost.
4 EVALUATION
WehaveimplementedBuildFastin13.1KlinesofPython,Rubyand
Javacode,using scikit-learn [1]formachinelearningandClDiff
[29] for code change analysis. We have released the code of Build-
Fast at our website [2] with the dataset used in our evaluation.
4.1 Evaluation Setup
To evaluate the effectiveness and efficiency of the proposed ap-
proach,wecomparedourapproachwiththreestate-of-the-artbuild
47Table 5: Project Statistics
ID ProjectCreation
DateLOC StarsPassed
BuildsFailed
Builds
P1 HikariCP 2013-10 12.5K 6,091 1,388 158
P2caelum/vraptor4 2013-05 26.6K 322 1,770 227
P3 Checkstyle 2013-08 210.7K 2,940 2,261 235
P4 Achilles 2012-11 48.3K 192 632 94
P5 DSpace 2012-03 172.9K 342 1,791 175
P6jackson-databind 2011-12 114.1K 1,550 1,720 718
P7Closure Compiler 2014-04 368.9K 4,017 1,972 171
P8 Graylog 2010-05 175.8K 4,046 5,736 828
P9 jOOQ 2011-04 181.6K 2,181 1,168 583
P10 Optiq 2012-08 141.7K 225 559 152
P11 Kill Bill 2012-10 169.5K 1,609 1,227 1,851
P12lWicket-Bootstrap 2012-02 1.4K 284 621 695
P13 Vectorz 2012-09 53.5K 137 1,147 64
P14 MyBatis-3 2013-02 58.1K 6,659 824 71
P15 OWL API 2013-02 154.4K 296 1,149 223
P16 Pushy 2013-08 7.2K 759 732 116
P17 QuickML 2011-09 19.3K 218 625 314
P18 Retrofit 2010-09 20.4K 26,096 1,617 299
P19 Rexster 2010-02 23.4K 446 495 93
P20 Weld 2010-08 151.5K 275 1,669 175
outcome prediction approaches, and measured the contribution of
eachcomponentinBuildFasttoitseffectiveness,using20GitHub
Javaprojects.Ourevaluationisdesignedtoanswerthefollowing
research questions.
•RQ4:Howistheeffectivenessof BuildFastinpredictingbuildout-
comes, compared with the state-of-the-art approaches? (Sec. 4.2)
•RQ5:Howistheefficiencyof BuildFastinpredictingbuildout-
comes, compared with the state-of-the-art approaches? (Sec. 4.3)
•RQ6:HowisthecontributionofeachcomponentinBuildFastto
the achieved effectiveness of BuildFast? (Sec. 4.4)
Dataset. Werandomlyselected20projectsfromthe1,621projects
used in our empirical study (see Sec. 2.1). The statistics about these
projectsarelistedinTable5,includingtheircreationdate,linesofcode,
thenumberofstars,andthenumberofpassedandfailedbuilds.We
can see that these projects are mostly large in size, and have a longevolutionhistory,whichensuresdiversebuilddata.Foreachproject,
we split the builds into the training and testing dataset by 3:1.
ComparisonApproaches. ForRQ4andRQ5,weselected BS1
[26],BS2[44]andBS3[59]asthebaselinesbecause BS1andBS2are
thestate-of-artapproachesthatpredictinacross-validationwayand
BS3isthestate-of-artapproachthatpredictsinchronologicalorder.
ForRQ6,weranBuildFastbyremovingfeatureselection,bytrain-
ingonlyonemodelwithallbuilds,bytrainingtwomodelswithout
including all failed builds, and by excluding our new features.
EvaluationMetrics. Followingpriorworks,weusedprecision,
recall,F1-scoreandAUCtomeasuretheaccuracyofbuildoutcomeprediction.Wedistinguishedprecision,recallandF1-scoreforpassed
buildsandfailedbuildsforadetailedcomparisonacrossdifferent
approaches.Wealsousedbenefit,costandgain(seeSec.3.4)tomea-surethecost-efficiency.As
BS3isdesignedforoptimizingAUC,we
canonlymeasureitsAUC.Insummary,weusedaccuracyandcost-
efficiency to indicate the effectiveness.
ModelConfiguration. Duringmodelgeneration(seeSec.3.3),we
adoptedChi-SquaredTesting[ 23]toselectthetop30featuresforour
first model, and Information Gain [ 35] to select the top 25 features
for our second model. Besides, we used XGBoost [ 11] with de-
faultparametersastheclassifier.Thisconfigurationwasempiricallyestablishedasgood.Forspacelimitation,detailedcomparisonsto
other configurations are available at our website [2].
4.2 Effectiveness Evaluation (RQ4)
Table6presentstheresultsof BS1,BS2,BS3andBuildFastwithre-
specttotheseveneffectivenessmetrics.Thefirstcolumnshowsthebuildoutcomepredictionapproaches,thesecondcolumnliststhemet-rics,andthenexttwentycolumnsreportthemetricvaluesforeachprojectundereachapproach,andthelastcolumngivestheaverageforprecision,recall,F1-scoreandAUCandthesumforbenefit,costandgainacrossallprojects.Theunitofbenefit,costandgainishour.
Comparedwith
BS1,BuildFastsignificantlyimprovedthepreci-
sion,recallandF1-scoreforfailedbuildsby16.5%,60.2%and47.5%;andsuchdifferenceswerestatisticallysignificantusingWilcoxonSigned-Ranktest.Meanwhile,BuildFastslightlyimprovedtheF1-scoreforpassedbuilds.Overall,BuildFastimprovedF1-scoreandAUCof
BS1
by3.9%and5.5%,withthedifferencesstatisticallysignificant.Forben-
efit,costandgain,therewasnostatisticallysignificantdifference
due to the minority of failed builds and the variance of build times.
Still,BuildFasthadatotalgainof2,131hoursforallprojectsfromone-fourthofthebuilds(i.e.,testingdata)withitsbenefitexceeding
its cost. Thus, BuildFast is cost-efficient and can save CI cost.
Comparedwith BS2whichwasdesignedto improvetheaccuracy
forfailedbuilds,BuildFastsignificantlyimprovedalltheaccuracymetricsexceptfortherecallforfailedbuilds.Overall,BuildFastim-provedF1-scoreforfailedbuilds,F1-scoreforpassedbuilds,F1-scoreandAUCby55.2%,42.0%,43.0%and19.5%;andthedifferenceswere
statistically significant. Due to such a large accuracy improvement
for passed builds, BuildFast improved gain by 74.2%.
Comparedwith BS3whichwasspecificallydesignedtooptimize
AUC,BuildFaststillsignificantlyimprovedAUCby27.7%,andthe
differencewasstatisticallysignificant.Surprisingly, BS3achievedthe
lowestAUCamongthefourapproaches.Thiscouldbeattributed
to the seven coarse-grained features in their work.
BuildFastsignificantlyoutperformedthebestofthestate-of-the-art approaches,
BS1, by 47.5% in F1-score for failed builds
without losing the F1-score for passed builds. Besides, Build-
Fast saved a sum of 2,131 hours for all the 20 projects.
4.3 Efficiency Evaluation (RQ5)
Table7reportsthetimeoverheadofthefourapproaches.Thefirstcol-
umn lists the specific approach phases, i.e., training phase and pre-
dictionphase.Thetimeoverheadofpredictionphaseiscomposedoftwo parts in form of
a+b, where adenotes feature extraction time
andbdenotesoutcomepredictiontime.Wecanseethat BS2tookthe
longesttimefortraining,i.e.,averagely469.8secondsforeachproject,
because it used cascaded classifiers, while BuildFast took 6.9 sec-
onds,whichwaslongerthan BS3butshorterthan BS1.Astraining
isaone-timejob,thistimeoverheadisacceptable.Ontheotherhand,
BuildFast took 1.3 seconds to extract features for each build, and
another0.004secondstoobtainthepredictedbuildoutcome.While
being the slowest due to the large number of used features, Build-
Fast is still practical for real-world projects.
48Table 6: Effectiveness Comparisons to the State-of-the-Art
A.Metric P1P2P3P4P5P6P7P8P9P10P11P12P13P14P15P16P17P18P19P20AllBS1Pre.f.500.000.1251.00.267.604.500.328.833.636.862.792.667.000.571.000.769.469.500.389.491
Pre.p.896.879.918.943.964.899.932.925.937.795.525.824.952.889.884.797.824.855.795.954.869
Pre. .852.773.852.947.934.851.900.870.910.758.779.804.936.790.845.637.807.791.720.924.834
Rec.f.067.000.017.250.200.457.063.227.819.179.820.913.167.000.098.000.577.185.333.113.274
Rec.p.9921.00.9891.00.975.942.995.953.942.969.602.627.9951.00.989.979.920.958.886.990.935
Rec. .890.879.909.944.942.863.928.887.910.784.766.801.948.889.877.783.811.830.745.945.867
F1f.118.000.030.400.229.520.113.268.826.280.841.848.267.000.167.000.659.266.400.175.320
F1p.941.936.952.971.970.920.962.939.939.873.561.712.973.941.934.879.869.904.838.972.899
F1.851.823.876.928.938.855.901.878.910.735.771.795.933.837.837.703.803.798.726.931.841
AUC .619.568.610.873.683.808.636.773.883.785.763.853.878.515.815.713.844.788.813.643.743
Benefit 10.57.5968.917.468.330.7127.3431.731.298.6559.21.78.649.054.49.18.325.610.1214.32,732
Cost 1.10.614.30.63.31.85.317.41.016.8520.80.40.55.24.02.50.82.86.36.1611
Gain 9.46.9954.616.865.028.9122.0414.330.281.838.41.38.143.850.46.67.522.83.8208.22,121BS2Pre.f.102.500.072.075.107.157.228.144.271.318.848.707.088.000.128.667.596.305.500.143.298
Pre.p.884.883.908.933.969.786.954.949.893.797.553.839.967.886.600.812.795.860.871.927.853
Pre. .798.836.839.870.932.683.902.875.731.685.775.759.917.788.540.783.732.768.776.881.793
Rec.f.433.036.407.950.400.871.460.680.974.359.858.952.667.000.951.083.538.290.667.597.559
Rec.p.531.995.528.056.849.092.879.593.076.766.534.388.583.975.211.990.830.868.771.278.590
Rec. .520.879.518.123.830.219.848.601.310.671.777.731.588.867.129.808.738.772.745.294.598
F1f.166.067.123.139.168.266.305.237.424.337.853.811.155.000.215.148.566.298.571.231.304
F1p.663.935.668.106.905.164.915.730.140.781.543.531.727.929.315.892.812.864.818.428.643
F1.609.831.623.108.873.181.871.685.214.677.776.701.695.825.145.743.734.770.755.410.611
AUC .640.648.409.674.596.647.448.718.827.666.768.819.846.599.517.761.741.709.552.537.656
Benefit 5.67.4520.20.961.73.1115.3267.82.582.9492.11.04.947.60.59.27.122.98.845.81,707
Cost 0.40.68.50.03.00.53.05.90.115.5431.50.30.25.20.12.40.72.52.11.9484
Gain 5.26.8511.70.958.72.6112.3261.92.467.460.60.74.742.40.46.86.420.46.743.91,223BS3AUC .389.699.560.020.704.5421.00.970.717.167.574.2931.00.899.630.135.531.949.859.636.614BuildFastPre.f.600.381.227.692.263.674.200.701.819.621.870.871.889.333.400.833.759.418.733.152.572
Pre.p.899.905.922.957.966.898.932.935.936.848.545.945.980.894.883.870.900.895.969.957.902
Pre. .866.842.864.937.936.862.879.913.906.795.789.900.975.832.822.863.855.816.909.915.874
Rec.f.100.286.085.450.250.443.095.314.819.462.828.971.667.067.098.417.788.492.917.226.439
Rec.p.992.936.974.984.968.958.970.987.936.914.625.776.995.983.979.979.884.864.886.932.926
Rec. .894.858.900.944.938.874.907.925.906.808.777.895.976.881.868.867.854.802.894.895.883
F1f.171.327.123.545.256.534.129.434.819.529.848.918.762.111.157.556.774.452.815.182.472
F1p.943.920.947.970.967.927.951.960.936.880.582.852.988.937.928.922.892.879.925.944.913
F1.858.849.879.939.937.863.891.912.906.798.782.892.975.845.831.848.854.808.897.905.874
AUC .683.717.654.713.755.797.711.830.907.793.795.939.898.672.737.880.885.839.924.554.784
Benefit 10.56.9954.017.167.731.3124.2445.431.092.9576.92.08.648.253.99.08.123.410.2201.92,723
Cost 1.00.414.00.53.22.04.814.11.012.6520.00.10.24.83.91.80.51.70.05.5592
Gain 9.56.5940.016.664.529.3119.4431.330.080.356.91.98.443.450.07.27.621.710.2196.42,131
Table 7: Efficiency Comparisons to the State-of-the-Art
Phase BS1 BS2 BS3BuildFast
Training (sec) 9.4 469.8 0.4 6.9
Prediction (sec) 0.2 + 0.001 0.1 + 0.002 0.1 + 0.001 1.3 + 0.004
BuildFasttook6.9secondsfortraining,and1.3secondsto
predict for a build, which was acceptable for practical usages.
4.4 Ablation Study (RQ6)
Table8showstheresultofourablationstudytomeasurethecontri-
butionofvarioussettingsinBuildFasttotheeffectivenessinSec.4.2.
RemovingFeatureSelection. BuildFasthadadegradationin
almostalltheaccuracymetricsafterremovingfeatureselection.Sig-
nificantly,theprecisionforfailedbuildsdecreasedby9.7%from0.572to0.516,andtherecallforpassedbuildsdecreasedby6.5%from0.926to0.866.Overall,F1-scorehadadegradationof5.0%.Therewasnosig-nificantdifferenceforAUC,benefit,costandgain.Theseresultsshowthatfeatureselectioncontributestotheimprovedaccuracyforboth
failed and passed builds by selecting representative features.
TrainingOneModelwithAllBuilds .Whenonlyonemodelwas
trainedin BuildFast withall builds,BuildFast suffereda signifi-
cant degradation in all the precision, recall, F1-score and AUC met-ricsexceptfortherecallforfailedbuilds.Overall,F1-scoreforfailed
builds,F1-scoreforpassedbuilds,F1-score,andAUCdecreasedby20.8%,
20.3%,18.2%and5.5%.Becauseofsuchalargedegradationforpassedbuilds,gaindecreasedby11.0%.Theseresultsindicatethatouradop-tionoftwomodelsgreatlycontributestoaccuracyandcost-efficiency
by learning specialized knowledge from distinguishable build data.
TrainingTwoModelswithoutAllFailedBuilds. Whenwedid
notincludeallfailedbuildsintothetrainingdataofthetwoseparate
models,BuildFasthadadegradationinallmetrics.Significantly,
49Table 8: Contributions of Each Component in BuildFast
A.Metric P1P2P3P4P5P6P7P8P9P10P11P12P13P14P15P16P17P18P19P20AllBuildFast without Feature SelectionPre.f.400.119.556.421.556.221.146.685.814.800.885.787.778.000.385.846.695.444.667.123.516
Pre.p.896.876.923.952.967.911.932.933.939.803.617.909.975.885.885.879.895.890.886.960.896
Pre. .841.785.893.913.949.798.875.910.906.802.819.835.964.787.822.872.832.816.830.917.858
Rec.f.067.571.085.400.250.757.111.291.828.205.865.962.583.000.122.458.788.452.667.339.440
Rec.p.988.417.994.956.991.481.949.987.933.984.659.597.990.967.972.979.839.888.886.869.866
Rec. .886.435.919.914.959.526.889.923.906.802.814.819.967.859.865.875.823.815.830.841.833
F1f.114.196.147.410.345.342.126.408.821.327.875.866.667.000.185.595.739.448.667.180.423
F1p.939.565.957.954.979.629.941.959.936.884.637.721.983.924.926.926.866.889.886.912.871
F1.849.520.890.913.952.582.882.909.906.754.816.809.965.822.833.860.826.816.830.874.830
AUC .739.505.718.807.771.721.706.825.903.804.836.924.840.560.757.821.861.835.917.608.773
Benefit 10.53.1973.216.669.415.5122.5444.930.9101.0611.71.58.547.253.59.08.023.910.2182.82,744
Cost 1.10.313.80.53.20.85.214.91.017.2392.10.20.35.23.91.60.31.92.14.1470
Gain 9.42.8959.416.166.214.7117.3430.029.983.8219.61.38.242.049.67.47.722.08.1178.72,274BuildFast with One ModelPre.f.417.145.148.500.039.556.113.163.265.392.870.608.333.000.4001.00.833.433.636.140.400
Pre.p.904.915.922.949.893.916.979.9391.00.909.574.000.989.888.883.828.828.885.861.956.851
Pre. .851.822.858.916.856.857.917.868.809.788.797.370.952.789.822.862.830.810.804.914.825
Rec.f.167.714.136.350.850.571.873.5291.00.795.8501.00.833.000.098.167.577.419.583.226.537
Rec.p.971.422.930.972.056.911.467.728.024.625.614.000.899.992.9791.00.946.891.886.925.712
Rec. .883.457.864.926.091.856.496.709.279.665.792.608.896.881.868.833.829.813.809.889.722
F1f.238.241.142.412.075.563.200.249.420.525.860.756.476.000.157.286.682.426.609.173.374
F1p.937.577.926.960.106.914.632.820.047.741.593.000.942.937.928.906.883.888.873.940.728
F1.860.537.861.920.105.857.601.768.144.690.794.460.916.833.831.782.819.811.806.901.715
AUC .644.591.634.740.589.791.695.693.904.774.807.789.853.578.749.855.830.833.898.583.741
Benefit 10.33.2909.516.93.529.773.7328.90.765.1574.60.07.748.654.19.28.724.110.1196.72,375
Cost 0.90.213.50.60.31.50.511.30.05.1424.00.00.15.24.02.20.82.00.65.1478
Gain 9.43.0896.016.33.228.273.2317.60.760.0150.60.07.643.450.17.07.922.19.5191.61,897BuildFast without All Failed DataPre.f.429.316.189.636.278.636.194.662.826.708.872.855.778.333.333.917.737.414.692.152.548
Pre.p.898.897.926.950.966.891.932.930.936.846.533.926.975.894.880.880.907.888.912.954.896
Pre. .847.827.865.926.937.850.879.906.908.814.788.883.964.832.811.887.853.809.856.913.868
Rec.f.100.214.169.350.250.400.095.262.819.436.816.962.583.067.073.458.808.444.750.161.411
Rec.p.984.936.934.984.971.956.969.987.939.945.636.746.990.983.979.990.866.875.886.951.925
Rec. .886.849.871.937.940.865.906.920.908.826.772.877.967.881.865.883.848.803.851.910.878
F1f.162.255.179.452.263.491.128.375.823.540.843.905.667.111.120.611.771.428.720.156.450
F1p.939.916.930.966.969.922.950.958.938.893.580.826.983.937.927.931.886.881.899.953.909
F1.854.836.868.928.938.852.891.904.908.810.778.874.965.845.825.867.849.806.853.912.868
AUC .684.692.655.762.714.780.719.825.908.803.796.933.919.609.649.843.874.833.919.629.777
Benefit 10.46.9914.917.167.231.2123.7445.431.196.5586.52.08.548.253.99.17.923.610.2201.3269,5
Cost 1.00.513.40.63.22.04.815.41.012.7534.00.20.34.84.01.70.42.00.45.9608
Gain 9.46.4901.516.564.029.2118.9430.030.183.852.51.88.243.449.97.47.521.69.8195.42,087BuildFast without Our New MetricsPre.f.286.269.500.471.455.597.333.625.825.588.867.864.750.000.389.750.629.402.615.268.524
Pre.p.895.898.919.952.967.910.930.925.934.807.576.852.970.885.890.861.873.873.882.956.888
Pre. .828.822.885.917.945.859.887.898.905.756.795.859.958.787.827.839.795.795.814.921.855
Rec.f.067.250.034.400.250.529.048.203.810.256.854.913.500.000.171.375.750.347.667.177.380
Rec.p.979.907.997.964.986.931.993.988.939.945.602.776.990.967.961.969.795.897.857.974.921
Rec. .879.828.917.922.955.865.924.916.906.784.792.860.962.859.862.850.780.806.809.933.870
F1f.108.259.063.432.323.561.083.307.817.357.860.888.600.000.237.500.684.372.640.214.415
F1p.935.902.957.958.977.920.960.955.936.871.589.812.980.924.924.912.832.885.870.965.903
F1.844.825.883.919.948.862.897.896.905.751.793.858.958.822.838.829.785.800.811.926.858
AUC .657.591.604.838.767.813.730.823.906.750.800.893.871.608.761.842.853.824.850.730.776
Benefit 10.46.7976.216.769.130.4126.4445.731.195.3559.62.08.547.653.68.97.424.19.9209.82,739
Cost 1.10.414.20.43.21.75.317.51.116.1442.80.40.45.23.71.80.52.22.15.8526
Gain 9.36.3962.016.365.928.7121.1428.230.079.2116.81.68.142.449.97.16.921.97.8204.02,213
theF1-scoreforfailedbuildsdecreasedby4.7%.Thisisconsistentto
ourmotivationofincludingallfailedbuildsintothetwomodeltrain-ingprocess,i.e.,partiallysolvingtheunbalancedsizeoffailedbuilds
in order to improve the prediction accuracy for failed builds.
ExcludingOurNewFeatures. Afterweexcludednewfeatures,
BuildFast had a significant degradation in accuracy metrics forfailed builds. Overall, the F1-score for failed builds decreased by
12.1%. This indicatesthe importance of ournew features to model
the characteristics of build failures. To further look into the impor-
tanceofournewfeatures,weanalyzedthemostimportantfeatures
inourtwomodelsacrossallprojectsbyaccumulatingafeature’s
importancevalue,computedduringfeatureselection,acrossallthe
50Table 9: Important Features in Our Two Models
First Model Second Model
Feature Imp.Proj. Feature Imp.Proj.
pr_state .14720 pr_state .33320
fail_ratio_pr .111 1fail_ratio_com_re .07320
log_src_files_in .07212 log_src_files_in .06720
pr_test_exception .06920file_fail_prob_sum .054 2
pr_src_files .062 9 team_size .05314
field_modified .059 2 files_added .051 1
last_fail_gap .055 9 class_changed .050 1
pr_src_churn .048 1 met_deleted .043 2
commits_on_files .047 3file_fail_prob_max .040 5
pr_tests_ok .04614 test_ast_diff .039 7
file_fail_prob_sum .044 8 field_deleted .039 6
fail_ratio_com_re .043 9merge_commits .039 5
consec_fail_sum .03914 src_churn .037 2
file_fail_prob_max .037 9 line_deleted .036 1
pr_duration .037 8 commits .036 5
by_core_member .036 4 is_master .03510
src_files .034 5 import_added .034 7
met_body_modified .034 6 line_added .034 2
log_src_files .03312 last_fail_gap .034 3
import_added .033 3commits_on_files .034 8
projects.Thetop20importantfeaturesforourtwomodelsarere-
ported in Table 9, where Imp.denotes the accumulated importance
value of a feature, and Proj.denotes the number of projects that se-
lect a feature. We can see that more than half of the important fea-
tures are newly introduced in this work (highlighted in bold). This
indicates the usefulness of our new features. Besides, these impor-
tant features are actually selected in various number of projects,
meaningthatdifferentprojectsselectdifferentsetsoffeatures.This
demonstrates the importance of feature selection.
Feature selection, adaptive models, and newly introduced fea-
tures all contribute positively to the achieved effectiveness of
BuildFast, especially for failed builds.
4.5 Discussion
We discuss the threats to and limitations of this work.
Threats. First,wedesignedanonlinesurveywithGitHubdevel-
opers instead of face-to-face interviews because it can allow us to
recruitarelativelylargenumberofparticipants(althoughthepartic-
ipant rate was low). Second, we decided to not offer compensation
butaskparticipantstovoluntarilytakethesurvey.Weexpectedthat
developers who were really interested in build outcome prediction
andwellmotivatedwouldparticipateinthissurveyandthusthe
survey quality couldbe improved. Third,BuildFast was only eval-
uatedagainstopen-sourceprojectswithoutdevelopers’feedback.
Experiments with industrial projects and developers are needed to
better measure the practical usages of BuildFast.
Limitations. First, although BuildFast outperforms the state-
of-the-artapproachessignificantlyinpredictionaccuracyforfailed
builds,wehavetoadmitthatthereisstillaroomforimprovements.Onepotentialwayistounderstandthesemanticsofcodechangesbyrecentadvancesindeepcoderepresentationlearning[
5],asweonly
focusoncodechangesatsyntacticlevel.Second,BuildFastonly
predictswhetherabuildfails,butcannotidentifytherootcauses
which would be useful for developers to fix the failure in advance.
We plan to extend BuildFast to classify a failed build into several
root causes (e.g., compilation errors and testing failures).5 RELATED WORK
Wereviewthemostcloselyrelatedworkonbuildprediction,costre-
duction in CI, empirical studies about CI, and defect prediction.
BuildPrediction. HassanandZhang[ 25]useddecisiontreesto
predictbuildoutcomewithcombinedfeaturesrelatedtosocial,tech-
nical,coordinationandprior-buildfactors.Theirmodelcorrectly
predicted 69% of the failed builds and 95% of the passed builds on alargeprojectattheIBMTorontoLabs.Wolfetal.[
56]adoptedsocial
networkanalysistoobtaincommunicationstructuremeasures,andleveragedsuchmeasuresintoaBayesianclassifiertopredicttheout-comeofabuild.Theyachievedprecisionandrecallbetween50%and
76%onIBM’sJazzproject.Then,Schroter[
47]extendedWolfetal.’s
work[56]byaddingtechnicaldependenciesintothesocialnetwork.
Kwan et al. [ 33] analyzed the effect of social-technical congruence
(i.e.,thematchbetweenthecoordinationneedsestablishedbytech-
nical domain and the coordination activities carried out by project
members)onbuildoutcome.TheirstudyontheIBMRationalTeamConcertprojectshowedthatsocial-technicalcongruencehadaneg-
ativeeffectonintegrationbuildsuccessrate.Thesocialfactorsin
these approaches are often organization-specific, greatly hindering
the generalizability of predictive models over a wider audience. In-
stead, BuildFast is specifically designed for CI environment, and
thus can be applied to any project as long as it adopts CI.
Finlayetal.[ 18]useddatastreamminingtechniquesbasedoncode
metrics(i.e.,basicmetrics,dependencymetrics,complexitymetrics,
cohesionmetrics,andHalsteadmetrics)to predictbuildoutcome.
They achieved 72% accuracy on IBM’s Jazz project. As only source
codefileswereincludedinmetriccomputation,thisapproachcould
not predict build failures caused by errors in non-source code files
(e.g.,configurationfiles).Recently,NiandLi[ 44]usedcascadedclas-
sifierstopredictbuildoutcomeinCIbasedonfile-levelmetricsfrom
the current and previous build and failure statistics from historical
builds.Similarly,HassanandWang[ 26]leveragedmetricsfromthe
currentandpreviousbuild.Differently,theyincludedmetricsabout
failure type of the previous build and coarse-grained code changes
inthecurrentbuild,anddidnotconsiderhistoricalbuilds.Differentfromsuchapproaches,weextractfine-grainedcodechangefeaturesfromhistoricalbuilds.NiandLi[
45]proposedtodynamicallyadapt
a pool of classifiers learned from various projects to a new project
thatdoesnothavesufficientdataofbuilds.Thisapproachisorthog-onaltothepreviousapproachesandourapproach,becauseitreusestheclassifierstrainedbythepreviousapproachesandourapproach.
XiaandLi[
57]investigatedtheaccuracyofnineclassifiersintheon-
linebuildoutcomepredictionscenario,andfoundthattheaccuracyfelltoafairlylowlevel.XieandLi[
59]targetedtheonlinescenario,
and proposed a semi-supervised online AUC optimization method.
However,thecoarse-grainedfeatureshinderitseffectiveness.Ex-
ceptforthreeapproaches[ 18,45,59],allthepreviousbuildoutcome
prediction approacheswere evaluated in thecross-validation way,
and thus they might not work well in the practical online scenario.
Instead, BuildFast targets the online scenario. Moreover, apart
fromtheaccuracyindicators,weanalyzethebenefitfromcorrect
predictionsandthecostofincorrectpredictionstosystematically
evaluate the cost-effectiveness of BuildFast. Recently, Jin and Ser-
vant[31]proposedSmartBuildSkiptopredictthefirstbuildsina
sequence of build failures with a machine learning classifier and
51then determine that all subsequent builds will fail until it observes
a passed build. This approach targets a different usage scenario of
BuildFast,andourclassifiercanbeintegratedintotheirapproach.
Besides,Bisongetal.[ 8]developedapredictivemodeltopredict
thebuildtimeofabuildjobinCI.McIntoshetal.[ 40],Xiaetal.[ 58]
and Macho et al. [ 37] used machine learning techniques to predict
whether source code changes will induce changes in the build sys-
tem (i.e., build configuration co-changes). These techniques target
a different prediction problem than BuildFast.
CostReductioninCI. Apartfrombuildoutcomeprediction,var-
ioustechniqueshavebeenproposedtoreducecostinCI.Forexam-
ple,toreducebuildcost,someplugins[ 12,13]aredesignedintoCIser-
vicesfordeveloperstoskipsomebuildsbymanuallyconfiguring
thebuildprocess;Abdalkareemetal.[ 4]proposedarule-basedtech-
niquetoautomaticallyidentifycommitsthatcanbeCIskipped;fol-
lowed by a machine learning-based approach [ 3]; and Gambi et
al.[21]developedanovelbuildsystemthatcanlazilyretrieveparts
oflibrariesthatareneededduringtheexecutionofabuildtarget.Tu-
fanoetal.[ 51]proposedtoanalyzedeveloper’schangesandpredict
whether it impacts the longest critical path, whether it may lead to
buildtimeincreaseandthedelta,andthepercentageoffuturebuilds
that might be affected by such changes. To reduce testing cost, Ce-
lik et al. [ 10] consolidated repetitive and expensive setup activities
into pre-configured testing virtual machines; and a number of test
case prioritization [ 9,16,36,39,60] and test case selection [ 41,49]
havebeendevelopedintoCItominimizetestexecutioncost.These
techniques are orthogonal to BuildFast as they focus on different
aspects in CI. Ideally, they can be combined together to achieve
optimal cost reduction.
EmpiricalStudiesaboutCI. Withthewidespreadadoptionof
CI,empiricalstudieshavebeenwidelyconductedtoinvestigatedif-ferentaspectsofCI,e.g.,usage,cost,benefits,barriersandneedswhendevelopersuseCI[
27,28,52],typeandfrequencyofbuildfailuresin
CI[30,32,46,54],buildfailurescausedbycompilation[ 48,62],test-
ing[6,34]andstaticviolationsinstaticanalysis[ 61],noiseandhet-
erogeneity[ 20]inhistoricalbuilddataset[ 7],characteristicsoflong
buildduration[ 22],anti-patternsinCI[ 53],andtestcodeevolution
in CI [43]. Some studies [ 22,28] reported concrete evidence on ex-
pensive build cost, and some studies [ 27,53] revealed that waiting
for builds to finish is a common barrier faced by developers. There-fore,thesestudiesmotivatetheneedforbuildoutcomepredictionto
save build cost. Besides, studies about build failures [ 30,32,46,54]
shed light on our feature selection.
Defect Prediction. Defectpredictionhasbeenwidelystudied.
Generally,defectpredictionmethods(e.g.,[ 14,17,38,50,55])build
machinelearningmodelsbasedondifferentkindsofmetricsand
predictdefectsatdifferentgranularitylevels.Asdefectprediction
mostlyfocusesondefectsinsourcecodefilesandbuildfailurescanbecausedbyerrorsinnon-sourcecodefiles,defectpredictiontech-
niquescannotdirectlytranslatetobuildoutcomepredictioninCI.
6 CONCLUSIONS
In this paper, motivated by our empirical study on build times and
ourdevelopersurveyonbuildoutcomeprediction,weproposea
newhistory-awareapproach,namedBuildFast,topredictCIbuild
outcomes cost-efficiently and practically. Our experiments on 20projects have demonstrated that BuildFast can improve the state-
of-the-artapproachesby47.5%inF1-scoreforfailedbuildswithoutlosingtheaccuracyforpassedbuilds,andthebenefitof BuildFast
exceeds its cost, bringing fast feedback and reduced CI cost.
ACKNOWLEDGMENTS
This work was supported by the National Natural Science Founda-
tion of China (Grant No. 61802067).
REFERENCES
[1][n.d.].scikit-learn. RetrievedMay6,2020fromhttp://scikit-learn.github.io/stable
[2] [n.d.]. BuildFast. Retrieved May 6, 2020 from https://buildfastinci.github.io
[3]RabeAbdalkareem,SuhaibMujahid,andEmadShihab.2020. AMachineLearning
ApproachtoImprovetheDetectionofCISkipCommits. IEEETransactionson
Software Engineering (2020).
[4]Rabe Abdalkareem, Suhaib Mujahid, Emad Shihab, and Juergen Rilling. 2019.
WhichcommitscanbeCIskipped? IEEETransactionsonSoftwareEngineering
(2019).
[5]Miltiadis Allamanis, Earl T Barr, Premkumar Devanbu, and Charles Sutton. 2018.
A survey of machine learning for big code and naturalness. Comput. Surveys 51,
4 (2018), 81.
[6]Moritz Beller, Georgios Gousios, and Andy Zaidman. 2017. Oops, my tests broke
the build: An explorative analysis of Travis CI with GitHub. In Proceedings of the
IEEE/ACM14thInternationalConferenceonMiningSoftwareRepositories.356–367.
[7]MoritzBeller,GeorgiosGousios,andAndyZaidman.2017. Travistorrent:Syn-
thesizingtravisciandgithubforfull-stackresearchoncontinuousintegration.
InProceedings of the IEEE/ACM 14th International Conference on Mining Software
Repositories. 447–450.
[8]Ekaba Bisong, Eric Tran, and Olga Baysal. 2017. Built to last or built too fast?
evaluatingpredictionmodelsforbuildtimes.In ProceedingsoftheIEEE/ACM14th
International Conference on Mining Software Repositories. 487–490.
[9]Benjamin Busjaeger and Tao Xie. 2016. Learning for Test Prioritization: An
Industrial Case Study. In Proceedings of the 2016 24th ACM SIGSOFT International
Symposium on Foundations of Software Engineering. 975–980.
[10]Ahmet Celik, Alex Knaust, Aleksandar Milicevic, and Milos Gligoric. 2016. BuildSystem with Lazy Retrieval for Java Projects. In Proceedings of the 24th ACM SIG-
SOFT International Symposium on Foundations of Software Engineering. 643–654.
[11]TianqiChenandCarlosGuestrin.2016. Xgboost:Ascalabletreeboostingsystem.
InProceedings of the 22nd acm sigkdd international conference on knowledge
discovery and data mining. 785–794.
[12]Travis CI. [n.d.]. Customizing the Build - Skipping a Build. Retrieved February
2, 2020 from https://docs.travis-ci.com/user/customizing-the-build/#skipping-a-
build
[13]Cloudbee.[n.d.]. JenkinsEnterprisebyCloudBees14.5UserGuide-Usingthe
Skip Next Build plugin. Retrieved February 2, 2020 from https://docs.huihoo.
com/jenkins/enterprise/14/skip.html
[14]MarcoD’Ambros,MicheleLanza,andRomainRobbes.2012. Evaluatingdefect
prediction approaches: a benchmark and an extensive comparison. Empirical
Software Engineering 17, 4-5 (2012), 531–577.
[15]Paul M Duvall, Steve Matyas, and Andrew Glover. 2007. Continuous integration:
improving software quality and reducing risk. Pearson Education.
[16]Sebastian Elbaum, Gregg Rothermel, and John Penix. 2014. Techniques forImproving Regression Testing in Continuous Integration Development Envi-
ronments.In Proceedingsofthe22ndACMSIGSOFTInternationalSymposiumon
Foundations of Software Engineering. 235–245.
[17]NormanEFentonandMartinNeil.1999. Acritiqueofsoftwaredefectprediction
models.IEEE Transactions on software engineering 25, 5 (1999), 675–689.
[18]JacquiFinlay,RusselPears,andAndy MConnor.2014. Datastreamminingfor
predicting software build outcomes using source code metrics. Information and
Software Technology 56, 2 (2014), 183–198.
[19]Martin Fowler. 2000. Continuous Integration. http://martinfowler.com/articles/
originalContinuousIntegration.html
[20]KeheliyaGallaba,ChristianMacho,MartinPinzger,andShaneMcIntosh.2018.
Noise and heterogeneity in historical build data: an empirical study of Travis
CI.InProceedingsofthe33rdACM/IEEEInternationalConferenceonAutomated
Software Engineering. 87–97.
[21]AlessioGambi,ZabolotnyiRostyslav,andSchahramDustdar.2015. Improving
Cloud-BasedContinuousIntegrationEnvironments.In Proceedingsofthe37th
International Conference on Software Engineering - Volume 2. 797–798.
[22]TaherAhmedGhaleb,DanielAlencarDaCosta,andYingZou.2019. Anempirical
study of the long duration of continuousintegration builds. Empirical Software
Engineering 24, 4 (2019), 2102–2139.
[23]PriscillaEGreenwoodandMichaelSNikulin.1996. Aguidetochi-squaredtesting.
Vol. 280. John Wiley & Sons.
52[24]IsabelleGuyonandAndréElisseeff.2003. AnIntroductiontoVariableandFeature
Selection. Journal of Machine Learning Research 3, Mar (2003), 1157–1182.
[25]Ahmed E Hassan and Ken Zhang. 2006. Using decision trees to predict the
certificationresultofabuild.In Proceedingsofthe21stIEEE/ACMInternational
Conference on Automated Software Engineering. 189–198.
[26]Foyzul Hassan and Xiaoyin Wang. 2017. Change-Aware Build Prediction Model
forStallAvoidanceinContinuousIntegration.In Proceedingsofthe11thACM/IEEE
International Symposium on Empirical Software Engineering and Measurement .
157–162.
[27]MichaelHilton, NicholasNelson,Timothy Tunnell,DarkoMarinov,and Danny
Dig. 2017. Trade-offs in continuous integration: assurance, security, and flexi-
bility. InProceedings of the 2017 11th Joint Meeting on Foundations of Software
Engineering. 197–207.
[28]MichaelHilton,TimothyTunnell,KaiHuang,DarkoMarinov,andDannyDig.
2016. Usage,costs,andbenefitsofcontinuousintegrationinopen-sourceprojects.
InProceedings of the 31st IEEE/ACM International Conference on Automated Soft-
ware Engineering. 426–437.
[29]KaifengHuang,BihuanChen,XinPeng,DaihongZhou,YingWang,YangLiu,
andWenyunZhao.2018. ClDiff:GeneratingConciseLinkedCodeDifferences.InProceedingsofthe33rdACM/IEEEInternationalConferenceonAutomatedSoftware
Engineering. 679–690.
[30]MdRakibulIslamandMinhazFZibran.2017. Insightsintocontinuousintegration
buildfailures.In ProceedingsoftheIEEE/ACM14thInternationalConferenceon
Mining Software Repositories. 467–470.
[31]Xianhao Jin and Francisco Servant. 2020. A Cost-efficient Approach to Building
in Continuous Integration. In Proceedings of the 42nd International Conference on
Software Engineering.
[32]Noureddine Kerzazi, Foutse Khomh, and Bram Adams. 2014. Why do auto-
mated buildsbreak? anempirical study.In Proceedings ofthe IEEEInternational
Conference on Software Maintenance and Evolution. 41–50.
[33]IrwinKwan,AdrianSchroter,andDanielaDamian.2011. Doessocio-technical
congruence have an effect on software build success? a study of coordinationin a software project. IEEE Transactions on Software Engineering 37, 3 (2011),
307–324.
[34]AdriaanLabuschagne,LauraInozemtseva,andReidHolmes.2017. Measuringthe
costofregressiontestinginpractice:astudyofJavaprojectsusingcontinuous
integration.In Proceedingsofthe201711thJointMeetingonFoundationsofSoftware
Engineering. 821–830.
[35]ChangkiLeeandGaryGeunbaeLee.2006.Informationgainanddivergence-based
feature selection for machine learning-based text categorization. Information
processing & management 42, 1 (2006), 155–165.
[36]Jingjing Liang, Sebastian Elbaum, and Gregg Rothermel. 2018. Redefining priori-
tization:continuousprioritizationforcontinuousintegration.In Proceedingsof
the 40th International Conference on Software Engineering. 688–698.
[37]Christian Macho, Shane McIntosh, and Martin Pinzger. 2016. Predicting buildco-changes with source code change and commit categories. In Proceedings
of the IEEE 23rd international conference on software analysis, evolution, and
reengineering. 541–551.
[38]LechMadeyskiandMarcinKawalerowicz.2017. Continuousdefectprediction:
the idea and a related dataset. In Proceedings of the IEEE/ACM 14th International
Conference on Mining Software Repositories. 515–518.
[39]DusicaMarijan,ArnaudGotlieb,andSagarSen.2013. TestCasePrioritization
forContinuousRegressionTesting:AnIndustrialCaseStudy.In Proceedingsof
the 2013 IEEE International Conference on Software Maintenance. 540–543.
[40]ShaneMcintosh,BramAdams,MeiyappanNagappan,andAhmedEHassan.2014.
Mining co-change information to understand when build changes are necessary.
InProceedings of the IEEE International Conference on SoftwareMaintenanceand
Evolution. 241–250.
[41]AtifMemon,ZebaoGao,BaoNguyen,SanjeevDhanda,EricNickell,RobSiem-
borski, and John Micco. 2017. Taming Google-Scale Continuous Testing. In
Proceedingsofthe39thInternationalConferenceonSoftwareEngineering:Software
Engineering in Practice Track. 233–242.
[42]JohnMicco.2013. Continuousintegrationatgooglescale. https://eclipsecon.org/
2013/sites/eclipsecon.org.2013/files/2013-03-24%20Continuous%20Integration%
20at%20Google%20Scale.pdf
[43]Gustavo Sizilio Nery, Daniel Alencar da Costa, and Uirá Kulesza. 2019. An
EmpiricalStudyoftheRelationshipbetweenContinuousIntegrationandTest
Code Evolution. In Proceedings of the IEEE InternationalConferenceon Software
Maintenance and Evolution. 426–436.
[44]Ansong Ni and Ming Li. 2017. Cost-effective build outcome prediction using
cascadedclassifiers.In ProceedingsoftheIEEE/ACM14thInternationalConference
on Mining Software Repositories. 455–458.
[45]Ansong Ni and Ming Li. 2018. Poster: ACONA: Active Online Model Adapta-
tionforPredictingContinuousIntegrationBuildFailures.In Proceedingsofthe
IEEE/ACM 40th International Conference on Software Engineering: Companion.
366–367.
[46]ThomasRausch,WaldemarHummer,PhilippLeitner,andStefanSchulte.2017.
An empirical analysis of build failures in the continuous integration workflowsofJava-basedopen-sourcesoftware.In ProceedingsoftheIEEE/ACM14thInterna-
tional Conference on Mining Software Repositories. 345–355.
[47]AdrianSchroter.2010. Predictingbuildoutcomewithdeveloperinteractionin
jazz.InProceedingsoftheACM/IEEE32ndInternationalConferenceonSoftware
Engineering. 511–512.
[48]Hyunmin Seo, Caitlin Sadowski, Sebastian Elbaum, Edward Aftandilian, and
RobertBowdidge.2014. Programmers’builderrors:acasestudy(atgoogle).In
Proceedingsofthe36thInternationalConferenceonSoftwareEngineering.724–734.
[49]AugustShi,SureshThummalapenta,ShuvenduK.Lahiri,NikolajBjorner,and
JacekCzerwonka.2017. OptimizingTestPlacementforModule-LevelRegression
Testing.In Proceedingsofthe39thInternationalConferenceonSoftwareEngineering.
689–699.
[50]MingTan,LinTan,SashankDara,andCalebMayeux.2015. Onlinedefectpredic-
tion for imbalanced data. In Proceedings of the IEEE/ACM 37th IEEE International
Conference on Software Engineering. 99–108.
[51]Michele Tufano, Hitesh Sajnani,and Kim Herzig. 2019. Towards predicting the
impactofsoftwarechangesonbuildingactivities.In ProceedingsoftheIEEE/ACM
41stInternationalConferenceonSoftwareEngineering:NewIdeasandEmerging
Results. 49–52.
[52]BogdanVasilescu,YueYu,HuaiminWang,PremkumarDevanbu,andVladimir
Filkov. 2015. Quality and productivity outcomes relating to continuous integra-
tioninGitHub.In Proceedingsofthe10thJointMeetingonFoundationsofSoftware
Engineering. 805–816.
[53]Carmine Vassallo, Sebastian Proksch, Harald C Gall, and Massimiliano Di Penta.
2019. Automated reporting of anti-patterns and decay in continuous integra-tion. InProceedings of the IEEE/ACM 41st International Conference on Software
Engineering. 105–115.
[54]CarmineVassallo,GeraldSchermann,FiorellaZampetti,DanieleRomano,Philipp
Leitner, Andy Zaidman, Massimiliano Di Penta, and Sebastiano Panichella. 2017.
AtaleofCIbuildfailures:Anopensourceandafinancialorganizationperspective.
InProceedingsoftheIEEEinternationalconferenceonsoftwaremaintenanceand
evolution. 183–193.
[55]Zhiyuan Wan, Xin Xia, Ahmed E Hassan, David Lo, Jianwei Yin, and Xiaohu
Yang. 2018. Perceptions, expectations, and challenges in defect prediction. IEEE
Transactions on Software Engineering (2018).
[56]Timo Wolf, Adrian Schroter, Daniela Damian, and Thanh Nguyen. 2009. Predict-
ing build failures using social network analysis on developer communication.
InProceedings of the IEEE 31st International Conference on Software Engineering.
1–11.
[57]Jing Xia and Yanhui Li. 2017. Could we predict the result of a continuousintegration build? An empirical study. In Proceedings of the IEEE International
Conference on Software Quality, Reliability and Security Companion. 311–315.
[58]XinXia,DavidLo,ShaneMcIntosh,EmadShihab,andAhmedEHassan.2015.
Cross-projectbuildco-changeprediction.In ProceedingsoftheIEEE22ndInterna-
tional Conference on Software Analysis, Evolution, and Reengineering. 311–320.
[59]ZhengXieandMingLi.2018.CuttingtheSoftwareBuildingEffortsinContinuous
Integration by Semi-Supervised Online AUC Optimization. In Proceedings of the
27th International Joint Conference on Artificial Intelligence. 2875–2881.
[60]ShinYoo,RobertNilsson,andMarkHarman.2011. FasterfaultfindingatGoogle
using multi objective regression test optimisation. In Proceedings of the 8th Euro-
peanSoftwareEngineeringConferenceandtheACMSIGSOFTSymposiumonthe
Foundations of Software Engineering.
[61]Fiorella Zampetti, Simone Scalabrino, Rocco Oliveto, Gerardo Canfora, and Mas-
similiano Di Penta. 2017. How open source projects use static code analysistoolsincontinuousintegrationpipelines.In ProceedingsoftheIEEE/ACM14th
International Conference on Mining Software Repositories. 334–344.
[62]Chen Zhang, Bihuan Chen, Linlin Chen, Xin Peng, and Wenyun Zhao. 2019.
A large-scale empirical study of compiler errors in continuous integration. In
Proceedingsofthe201927thACMJointMeetingonEuropeanSoftwareEngineering
Conference and Symposium on the Foundations of Software Engineering. 176–187.
53