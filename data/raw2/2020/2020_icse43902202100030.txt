AutoCCAG : An Automated Approach to
Constrained Covering Array Generation
Chuan Luo, Jinkun Liny, Shaowei Caiy, Xin Chenz, Bing Hez, Bo Qiao, Pu Zhao,
Qingwei Lin, Hongyu Zhangx, Wei Wu{, Saravanakumar Rajmohany, Dongmei Zhang
Microsoft Research, China
yState Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, China
zMicrosoft 365, United States
xThe University of Newcastle, Australia
{L3S Research Center, Leibniz University Hannover, Germany
{chuan.luo, v-xich15, v-hebi, boqiao, puzhao, qlin, saravar, dongmeiz}@microsoft.com,
{jkunlin, william.third.wu}@gmail.com, caisw@ios.ac.cn, hongyu.zhang@newcastle.edu.au
Abstract â€”Combinatorial interaction testing (CIT) is an impor-
tant technique for testing highly conï¬gurable software systems
with demonstrated effectiveness in practice. The goal of CIT is to
generate test cases covering the interactions of conï¬guration op-
tions, under certain hard constraints. In this context, constrained
covering arrays (CCAs) are frequently used as test cases in CIT.
Constrained Covering Array Generation (CCAG) is an NP-hard
combinatorial optimization problem, solving which requires an
effective method for generating small CCAs. In particular, effec-
tively solving t-way CCAG with t>4is even more challenging.
Inspired by the success of automated algorithm conï¬guration
and automated algorithm selection in solving combinatorial
optimization problems, in this paper, we investigate the efï¬cacy
of automated algorithm conï¬guration and automated algorithm
selection for the CCAG problem, and propose a novel, automated
CCAG approach called AutoCCAG . Extensive experiments on
public benchmarks show that AutoCCAG can ï¬nd much smaller-
sized CCAs than current state-of-the-art approaches, indicating
the effectiveness of AutoCCAG . More encouragingly, to our best
knowledge, our paper reports the ï¬rst results for CCAG with a
high coverage strength ( i.e.,5-way CCAG) on public benchmarks.
Our results demonstrate that AutoCCAG can bring considerable
beneï¬ts in testing highly conï¬gurable software systems.
Index Terms â€”Constrained Covering Array Generation, Auto-
mated Algorithm Optimization
I. I NTRODUCTION
Nowadays, there are increasing demands for customized
software and services. Developing highly conï¬gurable systems
has attracted considerable attention in both academia and
industry. A highly conï¬gurable system provides many options,
through which users can easily customize the system [1]â€“
[3]. However, testing such a highly conï¬gurable system is
challenging. It is hard or even infeasible to test all possible
conï¬gurations (combinations of options) [4], [5], as the num-
ber of conï¬gurations grows exponentially with the number of
options and only certain speciï¬c conï¬gurations may lead to
system failures. For example, assuming that a software system
has 15 options with 3 possible values each, there are more
than ten million ( 315= 14;348;907) possible conï¬gurations
in the worst case. Hence, the time required for testing all these
Qingwei Lin is the corresponding author of this work.conï¬gurations could be unacceptably high, which creates an
urgent need for more practical testing methods.
It is well recognized that combinatorial interaction testing
(CIT) [4]â€“[19] is an effective and practical way for detecting
option-combination related faults in a conï¬gurable software
system. More generally, CIT tests a moderate number of
conï¬gurations sampled from the entire conï¬guration space
[18], thereby signiï¬cantly reducing the number of required
test cases. This sampling process for CIT generates a covering
array (CA). A t-way CA covers all possible combinations
of the values of any set of tconï¬guration options, where
t, the coverage strength, is a small integer value (usually
ranging from 2 to 5) [5], [18]. In practice, for conï¬gurable
systems, there are also hard constraints (mutual dependen-
cies and exclusiveness) among the options. The problem of
constrained covering array generation (CCAG), which aims to
ï¬nd minimum-sized constrained covering arrays (CCAs) while
satisfying a given set of hard constraints, is the core problem
of CIT and is in theory NP-hard [20].
Practical algorithms for tackling the CCAG problem can be
categorized into three main classes: greedy algorithms ( e.g.,
[6], [7], [11], [12], [16]), constraint-encoding algorithms ( e.g.,
[9], [13]), and meta-heuristic algorithms ( e.g., [8], [10], [14],
[15], [17], [18]). Greedy algorithms can handle 2-way and 3-
way CCAG rapidly, but the CCAs produced by them are often
very large and can be unacceptable in practical scenarios where
considerable time is required for testing a single conï¬guration
[8], [14]. Constraint-encoding algorithms ï¬rst encode a given
CCAG instance into a constraint optimization problem and
then solve it using a constraint solver. Although constraint-
encoding algorithms can solve 2-way CCAG, they typically
fail to tackle 3-way CCAG. In contrast, meta-heuristic algo-
rithms are able to tackle both 2-way and 3-way CCAG, and
usually produce much smaller-sized 2-way and 3-way CCAs
than the greedy algorithms. However, effectively solving t-
way CCAG ( t>4) still remains a challenge for meta-heuristic
algorithms [18], [21].
It is important to solve t-way CCAG with t>4. Much work
(e.g., [4], [19], [22]â€“[24]) has provided evidence that higher
2012021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)
1558-1225/21/$31.00 Â©2021 IEEE
DOI 10.1109/ICSE43902.2021.00030
coverage strength indicates stronger fault detection capability.
The literature [22] shows that 3-way CCAG detects only
74% of faults for the widely-used trafï¬c collision avoidance
system [25]â€“[27], while 4-way and 5-way CCAG can detect
89% and 100% of faults for that system, respectively. Also,
a recent work [23] shows that up to about 25% of faults
would be missed if we do not use combinatorial testing
with high coverage strength ( t>4). Another recent work
[24] demonstrates that, through extensive empirical study on
various software, the fault detection rate of t-way CCAG with
t>4is up to 9.54% more than that of 3-way CCAG. Actually,
for life-critical applications ( e.g., aviation), even one fault can
be fatal [4], [23]. Furthermore, t-way CCAG with t>4can
ï¬nd corner-case faults that could cause serious consequences
and are very difï¬cult to be detected through manual testing.
For example, a recent study in LG Electronics [19] shows
that, through 4-way and 5-way combinatorial testing, LG
Electronics detected critical faults in washing machines and
refrigerators. More importantly, these faults could cost tens of
millions of dollars if they had to be ï¬xed after sale [19].
To our best knowledge, very few work focuses on effective
solving of the challenging 4-way and 5-way CCAG problems.
For example, recently a GPU-enabled parallel CCAG algo-
rithm called CHiP [18] reports the experimental results for
4-way CCAG on a number of benchmarking instances, but
the CCA sizes reported by CHiP are remarkably large and the
runtime of CHiP is considerably long (which can be observed
in Section V and in the literature [18]).
In this paper, for the ï¬rst time, we study the efï¬cacy of auto-
mated algorithm optimization techniques for CCAG, with a fo-
cus on solving t-way CCAG with t= 4andt= 5. Many meta-
heuristic algorithms expose parameters whose settings greatly
affect their performance [28]. For instance, in the context of
CIT, a representative, state-of-the-art meta-heuristic algorithm
called TCA [14], which is able to produce small CCAs in many
cases [14], [16], introduces a number of parameters that have
substantial impact on its performance. Automated algorithm
optimization techniques, including automated algorithm con-
ï¬guration ( e.g., [28]â€“[34]) and automated algorithm selection
(e.g., [35]â€“[40]), have been demonstrated to be effective on a
variety of NP-hard combinatorial problems such as Boolean
satisï¬ability ( e.g., [28], [31], [35]) and minimum vertex cover
(e.g., [41]). In this paper, we conduct research on leveraging
automated algorithm optimization techniques to optimize the
existing CCAG algorithm TCA, in order to make it more
capable of solving 4-way and 5-way CCAG.
Speciï¬cally, we propose a novel, automated CCAG ap-
proach, dubbed AutoCCAG , which can automatically schedule
TCA with different conï¬gurations for solving t-way CCAG
effectively, through leveraging the automated algorithm con-
ï¬guration and automated algorithm selection techniques.
Through extensive experiments, we present that AutoCCAG
achieves much better performance than current state-of-the-art
CCAG algorithms, including TCA [14], CASA [8] and CHiP
[18]. In particular, our comparative experiments are conducted
on a broad range of real-world application instances from pub-lic benchmarks. Our experimental results clearly demonstrate
thatAutoCCAG signiï¬cantly outperforms current state-of-the-
art CCAG algorithms for 4-way and 5-way CCAG on real-
world instances. In addition, the performance of AutoCCAG
is better than or equal to that of all its state-of-the-art CCAG
competitors for 2-way and 3-way CCAG on all these instances.
Our main contributions in this paper are as follows.
We provide clear empirical evidences that automated al-
gorithm conï¬guration and automated algorithm selection
can push forward the state of the art in CCAG solving.
We propose a novel, automated CCAG approach dubbed
AutoCCAG , which leverages the effectiveness of auto-
mated conï¬guration and automated selection techniques.
We perform extensive experiments, demonstrating that
AutoCCAG performs signiï¬cantly better than existing
state-of-the-art CCAG algorithms for solving 4-way and
5-way CCAG on real-world instances.
II. P RELIMINARIES
In this section, we ï¬rst introduce combinatorial interaction
testing, and then survey automated algorithm optimization.
A. Combinatorial Interaction Testing
We introduce deï¬nitions and notations related to CIT and
formally describe the CCAG problem.
a) System Under Test (SUT): The deï¬nition of a system
under test (SUT, also known as instance in this paper) is a
pairS= (P;C), where Pis a collection of options and C
is a collection of constraints on the permissible combinations
of values of the options in P. For each option pi2P, the set
of feasible values is denoted as Vi.
To formally deï¬ne the CCAG problem, we need to introduce
the deï¬nitions of tuple andtest case , as described below.
b) Tuple: Given an SUT S= (P;C), a tuple is a set
of pairs, denoted by =f(pi1;vi1);(pi2;vi2);:::; (pit;vit)g,
which implies that option pij2Ptakes the value vij2Vij.
A tuple of size tis called at-tuple.
c) Test Case: Given an SUT S= (P;C), a test case tc
is a tuple that covers all options in P. In another word, a test
case is a complete assignment to P.
In practice, the options of most software systems are subject
to hard constraints on the allowable combination of values.
Since testing with invalid test cases would waste much testing
time, it is critical to guarantee that all generated test cases are
valid. Given an SUT S= (P;C), a tuple or test case is valid
if, and only if, it does not violate any constraint in C. Besides,
a tupleiscovered by test case tcif, and only if, tc, that
is, the options in take the same values as the ones in tc.
Since all necessary notations are deï¬ned, we introduce the
concept of constrained covering array (CCA) and the for-
mal formulation of the constrained covering array generation
(CCAG) problem as below.
d) Constrained Covering Array (CCA): Given an SUT
S= (P;C), at-way constrained covering array CCA (S;t)
is a set of valid test cases, such that any valid t-tuple is covered
by at least one test case in CCA , wheretis called the covering
strength of CCA.
202e) Constrained Covering Array Generation (CCAG):
Given an SUT S= (P;C)and a covering strength t, the prob-
lem oft-way constrained covering array generation (CCAG)
is to ï¬nd at-way CCA of minimum size.
In practice, meta-heuristic algorithms [8], [10], [14], [15],
[17], [18] can construct much smaller-sized CCAs than other
types of algorithms. Among existing meta-heuristic algorithms
for CCAG, TCA [14] is considered as the representative and
state-of-the-art one. TCA is a typical local search CCAG
algorithm, which starts from a (partial) CCA as its initial
solution, and iteratively improves the current solution via
making small modiï¬cations. Reported by the literature [14],
TCA can produce CCAs with much smaller sizes than existing
approaches on extensive 2-way and 3-way CCAG instances.
B. Automated Algorithm Optimization Techniques
We ï¬rst describe automated algorithm conï¬guration, and
then introduce automated algorithm selection.
1) Automated Algorithm Conï¬guration: Actually, many
practical algorithms have hyper-parameters whose settings
considerably affect performance; this especially holds for
meta-heuristic algorithms for solving combinatorial optimiza-
tion problems [28]. The automated algorithm conï¬guration
(also known as automated hyper-parameter tuning ) technique
is to address the following question: given a conï¬gurable al-
gorithm and a set of instances, how to determine the optimized
conï¬guration (also known as hyper-parameter settings ) of the
given algorithm for solving the given set of instances? Re-
cently, there has been a growing body of automated algorithm
conï¬guration for determining optimized hyper-parameter set-
tings [28]â€“[34]. Automated conï¬guration has been successful
applied in various ï¬elds, such as data mining [42], automated
machine learning [43], and deep learning [44].
2) Automated Algorithm Selection: The automated algo-
rithm selection technique is to address the following question:
when there exist a number of base algorithms aiming at solving
the identical problem, how to select the most suitable one?
Considerable attentions have been paid to this question, result-
ing in various promising approaches [35]â€“[39]. Automated al-
gorithm selection has shown its effectiveness in solving many
NP-hard combinatorial problems, such as Boolean satisï¬ability
[35], maximum satisï¬ability [45], answer set programming
[46], and constraint satisfaction problem [39].
III. T HEAutoCCAG APPROACH
In this section, we propose a novel, effective automated
CCAG approach called AutoCCAG , which leverages effective
automated conï¬guration and automated selection techniques.
A. Top-level Design of AutoCCAG
The main idea of our proposed AutoCCAG approach is
to advance the state of the art in CCAG solving through
automated algorithm conï¬guration and automated algorithm
selection. We ï¬rst illustrate the top-level design of AutoCCAG
in Figure 1. There are three key components in our AutoCCAG
approach: 1) conï¬guration optimizer; 2) promising conï¬gura-
tion generator; 3) conï¬guration scheduling planner.
Promising 
Config. SetCfg1Cfg2 Cfgnâ€¦ 
Run target algorithm
with scheduling plan
Constrained Covering ArrayScheduling PlanCfg1 Cfg2 Cfgn
rmc(Cfg1)Â·tmcrmc(Cfg2)Â·tmc rmc(Cfgn)Â·tmcâ€¦ Training 
Instances
Config. Scheduling PlannerCfg1Config. 
Optimizer
Cfgn Cfg2
Promising Config. Generator
Config. 
OptimizerConfig. 
OptimizerTI TI TI 
â€¦ 
Marginal Contribution CalculationTarget 
Algorithm
Instance
to solveFig. 1. Top-level design of AutoCCAG .
1) Workï¬‚ow of AutoCCAG :As illustrated in Figure 1,
AutoCCAG works as follows: Given a target, conï¬gurable
CCAG algorithm a, the conï¬guration optimizer of AutoCCAG
utilizes automated conï¬guration to determine the optimized
conï¬guration for a; the promising conï¬guration generator of
AutoCCAG aims to generate a set of promising conï¬gurations
ofawith complementary strength; the conï¬guration schedul-
ing planner of AutoCCAG leverages automated selection to
construct a scheduling plan for target CCAG algorithm a.
Finally, AutoCCAG runs target CCAG algorithm awith the
generated scheduling plan to solve a given instance, to produce
the constrained covering array for that instance.
2) Target CCAG Algorithm: As discussed before, we ï¬rst
need to decide the target CCAG algorithm adopted by
AutoCCAG . As reported in the literature [14] and also observed
in our experiments (in Tables I and II), TCA [14] can produce
notably smaller-sized CCAs than other existing algorithms
ont-way CCAG ( 26t65). Also, TCA is a conï¬gurable
algorithm, and its original version has 3 conï¬gurable hyper-
parameters. One hyper-parameter is Boolean-valued, and has
two possible values: True orFalse . Another one is a positive
integer hyper-parameter. The remaining one is a real-valued
hyper-parameter ranging from 0 to 1. In fact, a powerful
paradigm called programming by optimization (PbO) [47],
which advocates practitioners to expand the design space of
target algorithms, has shown its effectiveness in improving
meta-heuristic algorithms for solving a variety of NP-hard
problems, e.g., Boolean satisï¬ability [48] and minimum vertex
cover [41]. Inspired by the success of the PbO paradigm, we
expand the design space of TCA through the PbO paradigm,
203Alg. 1: Method BOAC for Conï¬guration Optimizer
Input: TB_BOAC : time budget for BOAC ;
TI: a collection of training instances;
a: the target algorithm;
Output: Cfg: optimized conï¬guration of a;
1Cfg the default conï¬guration of a;
2Perf the average performance of awithCfg onTI;
3(Cfg;Perf) (Cfg;Perf);
4ML a GP model trained using sample (Cfg;Perf);
5while time budget TB_BOAC is not reached do
6 SC a set of randomly sampled conï¬gurations of a;
7 ifwith a probability of half then
8 Cfg the conï¬guration of awith the largest
expected improvement assessed by ML from SC;
9 else
10 Cfg the conï¬guration of awith the largest
variance assessed by ML from SC;
11 Perf the average performance of awithCfg onTI;
12 ifPerf is better than Perfthen
(Cfg;Perf) (Cfg;Perf);
13 ML is incrementally updated by adding a new sample
(Cfg;Perf);
14return Cfg
and thus make TCA incorporate more conï¬gurable algorithm
mechanisms. For each of these newly incorporated, conï¬g-
urable algorithm mechanisms, one new, Boolean-valued hyper-
parameter is introduced in TCA to decide whether this new
algorithm mechanism is activated. Hence, AutoCCAG utilizes
the PbO-based version of TCA as its target CCAG algorithm.
B. Conï¬guration Optimizer
Since automatically conï¬gured algorithms have exhibited
state-of-the-art performance on a wide range of combinatorial
problems [28], [31], [49], it is advisable to design a conï¬gura-
tion optimizer based on automated algorithm conï¬guration in
AutoCCAG . Hence, the ï¬rst step is to investigate to what de-
gree automated algorithm conï¬guration is effective for CCAG.
1) Details of BOAC :Bayesian optimization (BO) [50] is an
effective framework for automatically tuning hyper-parameters
of conï¬gurable algorithms [31]. The BO framework constructs
and updates a machine learning model to learn the effect
of hyper-parameter settings on target algorithm performance,
and iteratively determines a promising conï¬guration via the
constructed machine learning model. An effective machine
learning model for BO is Gaussian process (GP) [51]. Given
a conï¬guration of the target, conï¬gurable algorithm, GP can
evaluate its potential beneï¬t using expected improvement (EI)
[52] and assess its diversiï¬cation property using variance [53].
Based on the BO framework, we propose a new method
called BOAC (Bayesian Optimization based Automated Con-
ï¬guration ) for our conï¬guration optimizer. BOAC utilizes GP
as its machine learning model. The BOAC method is outlined
in Alg. 1, and needs 3 inputs: 1) the time budget for BOAC ,
denoted by TB_BOAC ; 2) a collection of training instances,
denoted by TI; 3) the target algorithm to be conï¬gured, de-
noted bya. The output of BOAC is the optimized conï¬guration
of the target algorithm a, denoted by Cfg.BOAC works in an iterative manner until the time budget
TB_BOAC forBOAC is reached (Line 5 in Alg. 1). In each
iteration, BOAC obtains a new sample, i.e., a pairwise item
consisting of a conï¬guration chosen by GP, denoted by Cfg,
and the average performance of awithCfg across all training
instances in TI, denoted by Perf (Lines 8, 10 and 11 in
Alg. 1)1. After obtaining the new sample, in each iteration
BOAC â€™s machine learning model MLwould be incrementally
updated by adding a new sample ( Cfg;Perf ) (Line 13 in
Alg. 1). Then we need to specify how BOAC chooses a
promising conï¬guration using GP in each iteration. In each
iteration, BOAC ï¬rst constructs a candidate conï¬guration set
SC, where each candidate is randomly sampled from the
whole conï¬guration space (Line 6 in Alg. 1). Then BOAC
switches between the exploitation mode and the exploration
mode to pick a promising conï¬guration. Since it is important
to balance exploitation and exploration [31], in our work, with
a probability of half, BOAC works in the exploitation mode: it
picks the conï¬guration Cfgwith the largest EI assessed by ML
from SC(Line 8 in Alg. 1); otherwise, BOAC works in the
exploration mode: it chooses the conï¬guration Cfg with the
largest variance assessed by ML from SC(Line 10 in Alg.
1). Since in each iteration BOAC â€™s machine learning model
ML would be incrementally updated by using a new sample,
the conï¬guration determined by BOAC would become more
effective with the number of iterations increases [54].
2) Conï¬guration Protocol: In this paper, AutoCCAG ap-
plies our proposed algorithm optimization method BOAC to
conduct automated algorithm conï¬guration. For automated
conï¬guration, we use one benchmark as the training set.
Our BOAC method is utilized to minimize the size of the
generated CCA. Following the common setting of automated
conï¬guration [55], we use a time budget of 2 days for the
conï¬guration process of BOAC , and a cutoff time of 300
seconds per algorithm run during the conï¬guration process
ofBOAC . Once the conï¬guration process is completed, the
conï¬guration determined by BOAC is reported as the ï¬nal
outcome of our conï¬guration process.
C. Promising Conï¬guration Generator
In Section III-B, we introduce how to use conï¬guration op-
timizer to determine the optimized conï¬guration for an conï¬g-
urable algorithm on a given collection of training instances. We
note that the obtained optimized conï¬guration shows the best
average performance across all training instances; however,
this does not mean that the obtained optimized conï¬guration
can achieve the best performance on each training instance. In
fact, it is recognized that, for the same conï¬gurable algorithm,
its various conï¬gurations show diverse performance when
solving different instances [56]. Hence, it is advisable to
generate a set of promising conï¬gurations with complementary
strength, and then use the automated selection technique to
leverage the complementary strength of them.
1For the ï¬rst iteration, since the GP model ML has not been constructed,
the default conï¬guration of aand the average performance of awith the
default conï¬guration are chosen (Lines 1 and 2 in Alg. 1).
204Alg. 2: Method PCG for Promising Conï¬guration Generator
Input: IB_PCG : iteration budget for PCG ;
TB_BOAC : time budget for BOAC ;
TI: a set of training instances;
a: the target algorithm;
Output: PC: a set of promising conï¬gurations of a;
1PC ?;
2while time budget IB_PCG is not reached andTI6=?do
3 Cfg the optimized conï¬guration of target algorithm
aselected by BOAC using TB_BOAC ,TIas inputs;
4 PC PC[fCfgg;
5 remove such instances, where target algorithm awith
conï¬guration Cfgcan achieve or exceed best known
CCA sizes, from TI;
6return PC
To address this challenge, we propose a new method dubbed
PCG , which is a promising conï¬guration generator to recom-
mend a set of promising conï¬gurations with complementary
strength. Our proposed PCG method is listed in Alg. 2, and
needs 4 inputs: 1) IB_PCG ,i.e.,the iteration budget for PCG
(following the practical standard [57], in this paper IB_PCG
is set to 4); 2) TB_BOAC ,i.e.,the time budget for BOAC ;
3)TI,i.e., a collection of training instances; 4) a,i.e., the
target algorithm. The output of PCG is a set of promising
conï¬gurations, denoted by PC.
In the beginning, PCG initializes PC as an empty set
(Line 1 in Alg. 2). Then PCG works in an iterative manner
until one of the termination criteria is met. As indicated in
Alg. 2, there are two termination criteria for PCG : 1) the
iteration budget IB_PCG is reached; 2) the training instance
setTIbecomes empty. In each iteration, PCG ï¬rst activates
BOAC to determine the optimized conï¬guration Cfgusing
TB_BOAC ,TIandaas inputs (Line 3 in Alg. 2); then
PCG addsCfgintoPC(Line 4 in Alg. 2). At the end of each
iteration, PCG removes such instances, where target algorithm
awith the conï¬guration Cfgfound in this iteration can
achieve or exceed best known CCA sizes2, from TI(Line 5 in
Alg. 2); the main intuition is that, in the subsequent iterations
we only focus on those instances where the conï¬gurations
already in PCshow moderate performance, in order to better
ï¬nd those conï¬gurations with complementary strength.
In summary, the main idea of PCG is to ï¬nd such conï¬gura-
tions, which can achieve better performance on those instances
where previously determined conï¬gurations show moderate
performance. As a result, PCG is able to generate a set of
promising conï¬gurations with complementary strength on all
training instances.
D. Conï¬guration Scheduling Planner
Thanks to our proposed PCG method, for a given CCAG
algorithma(i.e., TCA in this paper), we can obtain a set of
promising conï¬gurations PCwith complementary strength on
all training instances.
2For the best known CCA size for each instance, we collect the value from
previous studies [8], [14], [15], [18].It has been widely recognized that providing a scheduling
plan consisting of a combination of different effective conï¬g-
urations is able to achieve signiï¬cantly better results than just
determining a single conï¬guration [37]. The intuition is that
running a scheduling plan would exploit the complementary
strength among all conï¬gurations in this plan, and could
achieve more robust performance than just using a single
conï¬guration [37]. Also, the literature [58] conducts extensive
empirical study to demonstrate that, for the Boolean satisï¬-
ability (SAT) problem, which is a well-known, prototypical
NP-hard combinatorial problem, the effective conï¬gurations
for solving the SAT problem are usually not similar, result-
ing in different clusters of effective conï¬gurations in the
entire conï¬guration space. Besides, the literature [9], [13]
demonstrates that there is a strong connection between the
CCAG problem and the SAT problem (the CCAG problem
can be encoded into the SAT problem), so it is possible that
there might be different clusters of effective conï¬gurations for
solving the CCAG problem. Hence, an advisable solution is
to provide a scheduling plan which consists of a bunch of
conï¬gurations with different time budgets rather than a single
conï¬guration with the whole time budget. Then we need to
address the following challenge: given a new instance and the
cutoff time for solving the new instance, how to select suitable
conï¬gurations from PCand allocate suitable time budget for
each selected conï¬guration?
In order to address this challenge, we propose a novel
method named CSP, which is a conï¬guration scheduling
planner based on the automated selection technique.
1) Marginal Contribution: Before introducing the details
of our CSP method, we introduce an important concept called
marginal contribution [59], which can measure the contribu-
tion of each conï¬guration underlying the whole scheduling
plan. Since the methods for computing marginal contribution
for various problems are different, we utilize a logarithmic-
based method for computing marginal contribution in the
context of CCAG solving, which is described as follows.
Given a set of TCAâ€™s promising conï¬gurations PC, notation
size(PC)denotes the performance ( i.e.,the averaged size of
resulting CCAs on all training instances) achieved by an ideal
conï¬guration selector which leverages the complementary
strengths of the TCA â€™s conï¬gurations in PC. The absolute
marginal contribution (amc) for each conï¬guration b2PC
is calculated below:
amc(b) = lnsize(PCnfbg)
size(PC)(1)
After obtaining the absolute marginal contribution for each
conï¬guration b2PC, the relative marginal contribution
(rmc) for each conï¬guration b2PC is calculated below:
rmc(b) =amc(b)P
c2PCamc(c)(2)
2) Details of CSP:Our CSP method is outlined in Alg.
3, and provides a scheduling plan based on the marginal
contribution calculation. The time budget assigned to our CSP
method is the whole given cutoff time.
205Alg. 3: Method CSP for Conï¬guration Scheduling Planner
Input: tmc: cutoff time for solving instance i;
PC: a set of promising conï¬gurations of the target
algorithm found by SPC;
Output: listmc: optimized conï¬guration schedule plan;
1listtmp [ ];
2foreach conï¬guration b2PC do
3 calculate rmc(b)according to Equation 2;
4 listtmp.append( [b,rmc(b)]);
5sortlisttmpbyrmc in a descending order;
6listmc [ ];
7foreach pairwise tuple [b,rmc(b)]inlisttmpdo
8 listmc.append( [b,rmc(b)tmc]);
9return listmc;
As described in Alg. 3, the procedures of our CSP method
are described as follows: For each conï¬guration bunderlying
the given set of promising conï¬gurations PC, the relative
marginal contribution for conï¬guration b(i.e.,rmc(b)) is
computed according to Equation 2. Then all conï¬gurations
are sorted by their rmc values in a descending order. The
scheduling plan generated in this stage consists of all conï¬g-
urations whose rmc values are greater than 0, and the time
budget allocated to each component algorithm is proportional
to its rmc value.
Finally, through the above procedures, CSP constructs the
ï¬nal scheduling plan listmc. After the ï¬nal scheduling plan
listmcis obtained, our AutoCCAG approach runs the target
CCAG algorithm with the ï¬nal scheduling plan listmcto solve
a given instance, and thus generates the constrained covering
array for that instance.
IV. E XPERIMENTAL DESIGN
In this section, we describe the experimental design of this
work in detail. In particular, we ï¬rst introduce the benchmarks
used in the experiments. Then we present the research ques-
tions of this paper. After that, we describe the competitors.
Finally, we introduce the experimental setup.
A. Benchmarks
Since the literature [14] utilizes two benchmarks ( i.e.,
Real-world andSynthetic ) to evaluate the performance
ofTCA, we therefore adopt these two benchmarks in our
experiments. Both benchmarks are readily available online.
Moreover, we include an additional real-world application
benchmark entitled IBM into our experiments.
In our experiment, a benchmark is a collection of CCAG
instances, where each CCAG instance consists of two ï¬les,
i.e.,the model ï¬le and the constraint ï¬le. More details about
benchmarks are available online3. We brieï¬‚y describe the
Real-world ,IBM andSynthetic benchmarks below.
Real-world . This benchmark includes 5 real-world in-
stances and has been intensely studied in literature [8], [10],
[14], [15], [18], [22], [60], [61]. These instances are derived
3https://github.com/chuanluocs/AutoCCAGfrom Apache, an inï¬‚uential open-source web sever applica-
tion; Bugzilla, a widely used web-based bug tracker; GCC,
a well-known compiler collection from the GNU community
containing compilers and libraries for multiple programming
languages; SPIN-S and SPIN-V , the simulator- and veriï¬er-
variants of SPIN, a widely-used model checking tool. This
benchmark was ï¬rst presented by Cohen et al. [60]4.
IBM. This real application benchmark is comprised of 20
practical instances, originally introduced in the literature [62],
and is available online5. These instances are generated aiming
to provider better service for IBM customers, and cover a
broad range of real-world application ï¬elds, including health
care, insurance, network management, storage, etc.
Synthetic . This benchmark contains 30 synthetic in-
stances that were generated to resemble the characteristics of
real-world software systems in Real-world . These synthetic
instances were originally described by Cohen et al. [61]4.
TheSynthetic benchmark is used as the training set
required by AutoCCAG . In this paper, AutoCCAG is trained
by solving 3-way CCAG on all instances in the Synthetic
benchmark. The Real-world andIBM benchmarks are
adopted as the testing set and are used to evaluate the practical
performance of AutoCCAG and other state-of-the-art CCAG
algorithms. Due to the page limit, we only list the results
ofAutoCCAG and its competitors for solving 4-way and 5-
way CCAG on Real-world and 10 hardest instances in
IBM in Tables Iâ€“IV. The complete results of AutoCCAG and
its competitors for solving 4-way and 5-way CCAG on all
instances in the IBM benchmark are available online3(where
the results on all instances in the Real-world andIBM
benchmarks for 2-way and 3-way CCAG can be also found).
B. Research Questions
To evaluate the effectiveness of AutoCCAG , we aim to
answer the following research questions (RQs). In the context
of CCAG solving, previous meta-heuristic solvers can achieve
good performance for 2-way and 3-way CCAG, but effectively
solving 4-way and 5-way CCAG still remains a challenge [18],
[21]. Hence, in this paper, we focus on advancing the current
state of the art in 4-way and 5-way CCAG solving.
RQ1: Can the use of automated conï¬guration improve
the state of the art in 4-way and 5-way CCAG solving?
In this RQ, we evaluate the efï¬cacy of our proposed
conï¬guration optimizer BOAC for 4-way and 5-way CCAG.
We would like to explore if the performance of the state-of-
the-art CCAG algorithm TCA can be improved through BOAC .
In particular, we ï¬rst utilize BOAC to ï¬nd the optimized
conï¬guration for the original version of TCA, resulting in
the original version of TCA with the optimized conï¬guration,
dubbed TCA-opt . Then we conduct experiments to demonstrate
whether TCA-opt shows performance improvement over TCA.
RQ2: Can automated selection be leveraged to improve
the state of the art in 4-way and 5-way CCAG solving?
4http://cse.unl.edu/~citportal/public/tools/casa/benchmarks.zip
5https://researcher.watson.ibm.com/researcher/ï¬les/il-ITAIS/
ctdBenchmarks.zip
206TABLE I
COMPARING AutoCCAG WITH TCA-opt ,TCA,CASA AND CHiP FOR 4-WAY CCAG ON THE RE A L-W O R L D ANDIBM BENCHMARKS . THE RUN
TIME IS MEASURED IN SECOND .
InstanceAutoCCAG TCA-opt TCA CASA CHiP
min (avg) time min (avg) time min (avg) time min (avg) time size time
Apache 772 (789.2) 8068.3 838 (838.0) 9652.3 â€“ (â€“) >10000 â€“ (â€“) >10000 838 86169
Bugzilla 167 (167.8) 428.4 168 (169.6) 637.6 171 (172.4) 896.7 274 (280.7) 931.0 176 20821
GCC 374 (379.2) 8477.7 444 (444.0) 8199.0 â€“ (â€“) >10000 â€“ (â€“) >10000 444 103177
SPIN-S 308 (308.0) 44.1 308 (308.0) 121.6 311 (317.6) 331.7 355 (362.1) 862.6 339 12853
SPIN-V 1113 (1117.0) 911.5 1562 (1562.6) 937.6 1637 (1655.3) 981.9 â€“ (â€“) >1000 1166 33773
Healthcare2 159 (166.6) 757.7 169 (171.4) 376.6 171 (173.3) 463.1 184 (186.8) 298.6 177 905
Healthcare3 723 (729.1) 768.1 757 (763.4) 851.6 770 (773.1) 928.0 1127 (1159.4) 955.3 851 29062
Healthcare4 1317 (1320.4) 906.7 1475 (1494.3) 987.1 1763 (1791.2) 997.2 2492 (2605.8) 944.0 1536 36719
Insurance 75361 (75361.0) 165.4 75486 (75489.1) 992.1 76273 (76310.5) 997.4 474131 (613700.6) 972.0 75764 213365
NetworkMgmt 5610 (5610.0) 233.8 5610 (5610.0) 337.7 5610 (5610.1) 561.1 6008 (6045.9) 975.5 5610 207136
ProcessorComm1 485 (487.8) 452.2 489 (491.7) 461.2 491 (495.3) 633.2 571 (589.1) 902.0 544 11187
ProcessorComm2 574 (575.1) 595.7 585 (587.0) 517.3 592 (595.6) 876.5 850 (869.9) 961.3 837 7942
Services 6404 (6407.8) 807.7 6409 (6414.1) 853.4 6419 (6431.3) 961.1 7198 (7312.1) 953.7 6855 441412
Storage4 5486 (5494.0) 951.9 6077 (6084.0) 993.8 6774 (6805.1) 999.0 9393 (9500.5) 942.1 5671 86073
Storage5 10982 (11010.8) 821.8 13161 (13163.1) 971.0 14067 (14104.0) 993.1 â€“ (â€“) >1000 13292 36930
In this RQ, to study the effectiveness of automated selection,
we conduct comparisons between AutoCCAG and TCA-opt .
Actually, TCA-opt , which runs the original version of TCA
with a conï¬guration selected by BOAC , does not leverage the
effectiveness of automated selection.
RQ3: How does AutoCCAG compare against state-of-
the-art algorithms for 4-way and 5-way CCAG?
In this RQ, AutoCCAG is compared against three state-of-
the-art CCAG algorithms, i.e., TCA [14], CASA [8] and CHiP
[18], for solving 4-way and 5-way CCAG.
RQ4: Can AutoCCAG show state-of-the-art performance
for 4-way and 5-way CCAG with a shorter cutoff time?
In this RQ, AutoCCAG is evaluated to solve 4-way and
5-way CCAG instances with a half of the cutoff time. We
compare the results of AutoCCAG using a half of the cutoff
time against the results of TCA-opt using the full cutoff time,
to demonstrate the efï¬ciency of AutoCCAG .
C. Competitors
In this paper, AutoCCAG is compared with 3 state-of-the-art
CCAG algorithms, i.e., TCA [14], CASA [8] and CHiP [18].
TCA [14] is a state-of-the-art two-mode meta-heuristic algo-
rithm. Reported in the literature [14], TCA outperforms a num-
ber of CCAG algorithms including CASA [8],Cascade [12]
andACTS [11] on many real-world and synthetic instances.
CASA [8] is a high-performance simulated annealing CCAG
algorithm6. Reported in the literature [8], CASA outperforms
a greedy construction algorithm mAETG [61] on a number of
real-world and synthetic instances.
CHiP [18] is a recently-proposed, effective hybrid parallel
CCAG algorithm, which can use vast amount of parallelism
provided by graphics processing units. As reported in the
literature [18] and claimed by the authors of CHiP [18], CHiP
reports the ï¬rst and state-of-the-art results for solving 4-way
CCAG on the Real-world andIBM benchmarks.
6http://cse.unl.edu/~citportal/We note that HHSA [15] is an effective CCAG algorithm for
2-way and 3-way CCAG. Since the implementation of HHSA
available online7does not support solving t-way CCAG with
t>4, we do not include HHSA into our comparisons for 4-
way and 5-way CCAG. The results of comparing AutoCCAG
with HHSA for 2-way and 3-way CCAG are available online3,
and AutoCCAG can ï¬nd smaller-sized or equal-sized CCAs
than HHSA on all instances for 2-way and 3-way CCAG.
D. Experimental Setup
All experiments in this paper were conducted on a com-
puting server with 2.50GHz Intel Xeon E7-8890 v3 CPU and
1.0TB memory, running GNU/Linux. Because meta-heuristic
algorithms are usually randomized, we performed 10 indepen-
dent runs per instance for each algorithm. For solving 4-way
CCAG, the cutoff time of each algorithm run is set to 1,000
CPU seconds, following the experimental setup of TCA [14].
Since no CCAG algorithm can report feasible solutions for
4-way CCAG on the â€˜Apacheâ€™ and â€˜GCCâ€™ instances within
1,000 CPU seconds, in our experiments the cutoff time of
each algorithm run for solving 4-way CCAG on the â€˜Apacheâ€™
and â€˜GCCâ€™ instances is set to 10,000 CPU seconds. It is
recognized that solving 5-way CCAG is much more difï¬cult
than solving 4-way CCAG, and solving 5-way CCAG requires
vast computing time [21]. Thus, for 5-way CCAG, the cutoff
time of each algorithm run is set to 10,000 CPU seconds.
In our experiments (especially in Tables Iâ€“IV), for TCA,
if there is no speciï¬c description, it is evaluated using the
original version with the default conï¬guration. For CASA , it is
evaluated using the conï¬guration recommended by its authors
[8]. For CHiP , we do not have the access to its source code,
and only its binary executable is available8. We tried to run
the binary executable of CHiP on all instances for solving 4-
way CCAG using the cutoff time of 1,000 seconds (the same
7http://www0.cs.ucl.ac.uk/staff/Y .Jia/projects/cit_hyperheuristic/
downloads/Comb_Linux_64.tar.gz
8https://github.com/susoftgroup/CHiP
207TABLE II
COMPARING AutoCCAG WITH TCA-opt ,TCA,CASA AND CHiP FOR 5-WAY CCAG ON THE RE A L-W O R L D ANDIBM BENCHMARKS . THE RUN TIME
IS MEASURED IN SECOND .
InstanceAutoCCAG TCA-opt TCA CASA CHiP
min (avg) time min (avg) time min (avg) time min (avg) time size time
Apache â€“ (â€“) >10000 â€“ (â€“) >10000 â€“ (â€“) >10000 â€“ (â€“) >10000 â€“ â€“
Bugzilla 560 (561.5) 8200.2 688 (688.9) 9665.4 788 (794.5) 9922.2 1194 (1480.7) 7787.6 â€“ â€“
GCC â€“ (â€“) >10000 â€“ (â€“) >10000 â€“ (â€“) >10000 â€“ (â€“) >10000 â€“ â€“
SPIN-S 1174 (1174.0) 860.2 1174 (1174.0) 2908.4 1174 (1174.0) 2987.9 1222 (1228.8) 9589.3 â€“ â€“
SPIN-V 5941 (6060.4) 8991.6 8202 (8202.0) 3376.0 â€“ (â€“) >10000 â€“ (â€“) >10000 â€“ â€“
Healthcare2 517 (520.9) 6926.7 517(521.0) 6422.9 521 (523.7) 6352.7 558 (574.2) 4524.8 â€“ â€“
Healthcare3 3197 (3207.5) 8229.9 3934 (3938.2) 9944.8 4214 (4243.6) 9973.2 9908 (12729.9) 9572.7 â€“ â€“
Healthcare4 6885 (6904.5) 9594.7 8184 (8184.0) 9527.0 9353 (9380.3) 9624.7 57417 (57417.6) 6155.1 â€“ â€“
Insurance 452575 (452779.8) 9912.4 491558 (491561.7) 9900.7 496934 (497147.8) 9946.2 â€“ (â€“) >10000 â€“ â€“
NetworkMgmt 24664 (24679.9) 9875.5 24665 (24680.2) 9874.4 24705 (24721.2) 9915.8 28209 (28382.9) 9737.4 â€“ â€“
ProcessorComm1 2037 (2038.7) 5987.4 2041 (2043.6) 7643.3 2042 (2044.7) 8157.0 2586 (2630.7) 9829.3 â€“ â€“
ProcessorComm2 2506 (2508.9) 5938.1 2583 (2588.3) 9600.1 2808 (2886.8) 9990.1 4293 (4895.8) 9620.5 â€“ â€“
Services 32869 (32887.9) 9315.2 33208 (33243.9) 9890.9 36510 (36616.9) 9998.0 42928 (43319.7) 9592.2 â€“ â€“
Storage4 34005 (34027.1) 9882.3 39222 (39228.3) 9939.4 43552 (43632.1) 9959.8 192964 (264817.2) 9296.9 â€“ â€“
Storage5 65854 (66047.4) 9561.7 78317 (78318.2) 9457.1 85304 (85411.2) 9728.6 â€“ (â€“) >10000 â€“ â€“
cutoff time adopted by AutoCCAG ), but in our experimental
environment CHiP cannot report feasible solutions for almost
all instances. Actually, this is not surprising; the experimental
results in the literature [18] report that, for solving 4-way
CCAG, on the majority of instances, CHiP requires more than
tens of thousands (and even more than hundreds of thousands)
of seconds and needs vast amount of parallelism provided by
graphics processing units to obtain feasible solutions. As a
result, the experimental results of CHiP for solving 4-way
CCAG are taken from the literature [18]. Also, the binary
executable of CHiP does not support solving t-way CCAG
witht>4, so in Table II we mark â€˜â€“â€™ for the results of CHiP
for solving 5-way CCAG.
For each algorithm on each instance, we report the smallest
size (â€˜minâ€™) and the averaged size (â€˜avgâ€™) of the CCA found
by the respective algorithm over 10 runs. In addition, for each
algorithm on each instance, we report the running time (â€˜timeâ€™)
required for ï¬nding the optimized CCAs averaged over 10
runs, and all running times were measured in CPU seconds.
If an algorithm failed to ï¬nd a CCA during all 10 runs, we
report the results as â€˜â€“ (â€“)â€™. In Tables Iâ€“IV, for each instance,
we use boldface to indicate the best results with regard to
CCA size in our comparisons.
Moreover, in Tables Iâ€“IV, for each instance, we individually
compare the performance of AutoCCAG against that of each
competitor; we conduct Wilcoxon signed-rank tests to check
the statistical signiï¬cance of the results and calculate the
Vargha-Delaney effect sizes [63] for each pairwise comparison
between AutoCCAG and each of its competitors. For each
instance, if a) all the p-values of Wilcoxon signed-rank tests at
95% conï¬dence level are smaller than 0.05, and b) the Vargha-
Delaney effect sizes for all pairwise comparisons (between
AutoCCAG and each of its competitors) are greater than 0.71
(indicating large effect sizes) [63], [64], we consider the per-
formance improvement of AutoCCAG over all its competitors
statistically signiï¬cant and meaningful, and mark the results of
AutoCCAG using underline . In Table I, the experimental resultsofCHiP are taken directly from the literature [18], which were
obtained by only performing one run of CHiP per instance.
Therefore, we do not conduct statistical test to compare the
performance of our AutoCCAG approach with that of CHiP .
For our BOAC method, following the literature [65], we adopt
the ARD MatÃ©rn 5/2 kernel as its GP kernel and use the hyper-
parameter settings recommended in the literature [65].
V. E XPERIMENTAL RESULTS
In this section, we report the experimental results, to show
both the effectiveness and the efï¬ciency of AutoCCAG .
A. RQ1: Performance Improvement for 4-way and 5-way
CCAG by Automated Conï¬guration
We utilize BOAC to ï¬nd the optimized conï¬guration for
the original version of TCA, resulting in TCA-opt (i.e., the
original version of TCA with the optimized conï¬guration).
That is to say, for solving a given CCAG instance, TCA-opt
runs the original version of TCA with the single, optimized
conï¬guration. The comparative results of TCA-opt andTCA
for 4-way and 5-way CCAG on the Real-world andIBM
benchmarks are reported in Tables I and II, respectively. We
note that the full results are available online.3As can be clearly
seen from Tables I and II, on both metrics of â€˜smallest sizeâ€™
and â€˜averaged sizeâ€™, the performance of TCA-opt is better than
or equal to that of TCA on all instances.
The experimental results in Tables I and II demonstrate that
the state of the art in 4-way and 5-way CCAG solving can be
considerably advanced using automated conï¬guration.
B. RQ2: Performance Improvement for 4-way and 5-way
CCAG by Automated Selection
The major difference between AutoCCAG andTCA-opt is
that AutoCCAG runs the PbO-based version of TCA with
a scheduling plan (consisting of multiple high-performing
conï¬gurations of the PbO-based version of TCA), while TCA-
optruns the original version of TCA with a single, optimized
208TABLE III
COMPARING AutoCCAG (WITH THE CUTOFF TIME OF 500 SECONDS )
AGAINST TCA-opt (WITH THE CUTOFF TIME OF 1,000 SECONDS )FOR
4-WAY CCAG ON THE RE A L-W O R L D ANDIBM BENCHMARKS . THE
RUN TIME IS MEASURED IN SECOND .
InstanceAutoCCAG (500 sec) TCA-opt (1,000 sec)
min (avg) time min (avg) time
Apache â€“ (â€“) >500 â€“ (â€“) >1000
Bugzilla 167 (167.9) 388.2 168 (169.6) 637.6
GCC â€“ (â€“) >500 â€“ (â€“) >1000
SPIN-S 308 (308.0) 44.1 308 (308.0) 121.6
SPIN-V 1119 (1124.1) 472.8 1562 (1562.6) 937.6
Healthcare2 161 (168.0) 344.3 169 (171.4) 376.6
Healthcare3 728 (731.8) 397.2 757 (763.4) 851.6
Healthcare4 1331 (1335.6) 476.9 1475 (1494.3) 987.1
Insurance 75361 (75361.0) 165.4 75486 (75489.1) 992.1
NetworkMgmt 5610 (5610.0) 233.8 5610 (5610.0) 337.7
ProcessorComm1 485 (488.7) 381.5 489 (491.7) 461.2
ProcessorComm2 575 (576.5) 298.7 585 (587.0) 517.3
Services 6406 (6408.8) 484.3 6409 (6414.1) 853.4
Storage4 5518 (5523.5) 481.3 6077 (6084.0) 993.8
Storage5 11041 (11053.3) 452.8 13161 (13163.1) 971.0
conï¬guration. Hence, TCA-opt does not leverage the effec-
tiveness of automated selection. The comparative results of
AutoCCAG and TCA-opt for 4-way and 5-way CCAG on
both Real-world andIBM benchmarks are summarized
in Tables I and II, respectively. According to Tables I and
II, the results present that, when compared to TCA-opt , our
AutoCCAG approach is able to consistently achieve better or
equal performance on all instances in terms of the metrics of
â€˜smallest sizeâ€™ and â€˜averaged sizeâ€™.
The experimental results in Tables I and II provide evidence
that automated selection can signiï¬cantly push forward the
state of the art in 4-way and 5-way CCAG solving.
C. RQ3: Comparison among AutoCCAG and State-of-the-art
CCAG Algorithms for 4-way and 5-way CCAG
Related to this RQ, we conduct experiments on extensive
real-world applications instances to compare our AutoCCAG
approach against existing state-of-the-art CCAG algorithms, in
order to show the effectiveness of AutoCCAG .
The experimental results of AutoCCAG and its state-of-the-
art competitors ( i.e., TCA ,CASA and CHiP ) for 4-way and
5-way CCAG on the Real-world andIBM benchmarks
are presented in Tables I and II, respectively. It is clear that,
AutoCCAG performs much better than all its competitors for
solving 4-way and 5-way CCAG on these two benchmarks.
For solving 4-way CCAG, on the metric of â€˜smallest sizeâ€™,
AutoCCAG performs much better than all its state-of-the-art
competitors on 14 out of 15 instances presented in Table I;
for the remaining instance ( i.e.,â€˜NetworkMgmtâ€™), AutoCCAG ,
TCA and CHiP can ï¬nd the CCA with the same smallest
size of 5,610 (besides, CASA performs worse than AutoCCAG ,
TCA andCHiP on this instance), but the run time required by
AutoCCAG (233.8 sec) is much less than TCA (561.1 sec) and
CHiP (207,136 sec). Also, on the metric of â€˜averaged sizeâ€™,
AutoCCAG performs much better than all its state-of-the-art
competitors on all 15 instances presented in Table I.TABLE IV
COMPARING AutoCCAG (WITH THE CUTOFF TIME OF 5,000 SECONDS )
AGAINST TCA-opt (WITH THE CUTOFF TIME OF 10,000 SECONDS )FOR
5-WAY CCAG ON THE RE A L-W O R L D ANDIBM BENCHMARKS . THE
RUN TIME IS MEASURED IN SECOND .
InstanceAutoCCAG (5,000 sec) TCA-opt (10,000 sec)
min (avg) time min (avg) time
Apache â€“ (â€“) >5000 â€“ (â€“) >10000
Bugzilla 566 (567.8) 4531.8 688 (688.9) 9665.4
GCC â€“ (â€“) >5000 â€“ (â€“) >10000
SPIN-S 1174 (1174.0) 860.2 1174 (1174.0) 2908.4
SPIN-V 6429 (6809.1) 3231.8 8202 (8202.0) 3376.0
Healthcare2 521 (522.9) 3605.9 517 (521.0) 6422.9
Healthcare3 3210 (3221.5) 4476.7 3934 (3938.2) 9944.8
Healthcare4 6973 (6994.0) 4928.8 8184 (8184.0) 9527.0
Insurance 456781 (457835.1) 4999.8 491558 (491561.7) 9900.7
NetworkMgmt 24773 (24788.6) 4963.9 24665 (24680.2) 9874.4
ProcessorComm1 2038 (2040.0) 4560.3 2041 (2043.6) 7643.3
ProcessorComm2 2506 (2511.3) 3582.7 2583 (2588.3) 9600.1
Services 32987 (33031.0) 4694.4 33208 (33243.9) 9890.9
Storage4 34207 (34261.6) 4966.9 39222 (39228.3) 9939.4
Storage5 66857 (66966.8) 4992.9 78317 (78318.2) 9457.1
For solving 5-way CCAG, except two instances ( i.e.,
â€˜Apacheâ€™ and â€˜GCCâ€™) where no CCAG algorithm can report
feasible solutions within the cutoff time, on both metrics of
â€˜smallest sizeâ€™ and â€˜averaged sizeâ€™, AutoCCAG achieves much
better performance than all its state-of-the-art competitors on
12 out of 13 instances presented in Table II; for the remaining
instance ( i.e.,â€˜SPIN-Sâ€™), AutoCCAG andTCA ï¬nd the CCAs
with the smallest and averaged sizes of both 1,174 (besides,
CASA performs worse than AutoCCAG and TCA on this
instance), but the run time required by AutoCCAG (860.2 sec)
is much less than TCA (2,987.9 sec).
The experimental results in Tables I and II provide evidence
that our AutoCCAG approach performs much better than all
its competitors and dramatically pushes forward the state of
the art in 4-way and 5-way CCAG solving.
D. RQ4: Evaluating AutoCCAG with a shorter cutoff time for
4-way and 5-way CCAG
In order to analyze the efï¬ciency of AutoCCAG , we conduct
more experiments to study the performance of AutoCCAG with
a shorter cutoff time for solving 4-way and 5-way CCAG. In
the experiments related to this RQ, AutoCCAG is evaluated to
solve 4-way and 5-way CCAG instances with a half of the
standard cutoff time.
The results of AutoCCAG (with a half of the standard cutoff
time, i.e., 500 seconds for 4-way CCAG and 5,000 seconds
for 5-way CCAG) and TCA-opt (with the full cutoff time,
i.e.,1,000 seconds for 4-way CCAG and 10,000 seconds for
5-way CCAG) for solving 4-way and 5-way CCAG on the
Real-world andIBM benchmarks are reported in Tables
III and IV, respectively. From Table III, for solving 4-way
CCAG, on both metrics of â€˜smallest sizeâ€™ and â€˜averaged sizeâ€™,
AutoCCAG achieves better or equal performance compared to
TCA-opt on all instances. Also, from Table IV, for solving
5-way CCAG, on both metrics of â€˜smallest sizeâ€™ and â€˜aver-
aged sizeâ€™, AutoCCAG achieves better or equal performance
209compared to TCA-opt on all instances but two. As shown
in Table II, for those two instances (â€˜Healthcare2â€™ and â€˜Net-
workMgmtâ€™), in terms of â€˜smallest sizeâ€™ and â€˜averaged sizeâ€™,
AutoCCAG with the full cutoff time achieves better or equal
performance compared to TCA-opt with the full cutoff time.
The experimental results in Tables III and IV provide
evidence that AutoCCAG with even a half of cutoff time
can perform much better than TCA-opt with full cutoff time
for solving 4-way and 5-way CCAG, which indicates that
AutoCCAG requires much less run time to perform better than
TCA-opt on solving the majority of CCAG instances.
E. Threats to Validity
There are three potential threats to validity of our evaluation:
Cutoff time: A potential threat to validity in our experi-
ments is the cutoff time we set for each algorithm for solving
4-way CCAG. Following the existing work [14], we set the
cutoff time to 1,000 seconds. According to the results reported
in Table I, AutoCCAG can ï¬nd CCAs for all instances except
two (â€˜Apacheâ€™ and â€˜GCCâ€™), which indicates that the cutoff time
is reasonable. Nevertheless, the cutoff time might not be long
enough for all experiments. To reduce this threat, we conduct
additional experiments to run AutoCCAG and its competitors
to solve â€˜Apacheâ€™ and â€˜GCCâ€™, with the cutoff time of 10,000
seconds. The results in Table I show that AutoCCAG is still
able to take much less computation time to ï¬nd much smaller-
sized CCAs compared to all competing CCAG algorithms on
these 2 instances. For solving 5-way CCAG, the cutoff time
for each algorithm run is set to 10,000 CPU seconds as the
5-way CCAG problem is more challenging and requires more
computations. In our future work, we will design methods for
recommending optimal cutoff time for the CCAG problem.
Generalt-way coverage: Although in this paper we only
show the effectiveness of AutoCCAG through experiments on
4-way and 5-way CCAG, in fact, AutoCCAG is able to deal
with general t-way CCAG as well. For example, AutoCCAG
is able to deal with 2-way and 3-way CCAG. Due to limited
space, we do not report our empirical results for 2-way and
3-way CCAG in this paper, but they are available online.3
Actually, on the metrics of â€˜smallest sizeâ€™ and â€˜averaged sizeâ€™,
the performance of AutoCCAG is better than or equal to that
of all its state-of-the-art competitors ( i.e., TCA ,CASA ,HHSA
and CHiP ) on all instances in the Real-world andIBM
benchmarks for solving 2-way and 3-way CCAG. Further-
more, AutoCCAG supports other coverage criteria such as 6-
way coverage. We will evaluate the effectiveness of AutoCCAG
int-way coverage ( t>6) in our future work.
Training set: According to Section IV-A, the training set
used in our experiments is the Synthetic benchmark, which
consists of 30 instances, and a potential threat to validity of
our experiments is the small training set. As introduced in
Section III, GP is the main machine learning model underlying
AutoCCAG , and supports small training set [66]. Besides, a
recent study [41] shows that using a small training set can
achieve the state-of-the-art performance in solving the problemof minimum vertex cover, a well-known NP-hard combi-
natorial optimization problem. Furthermore, as described in
Section IV-A, the Synthetic benchmark resembles the
Real-world benchmark, and there is no explicit relationship
between the Synthetic benchmark and the IBM benchmark.
However, according to Tables I and II, AutoCCAG (trained on
theSynthetic benchmark) performs best on all instances
in the IBM benchmark (which covers extensive applications),
indicating the generality of AutoCCAG .
VI. R ELATED WORK
Combinatorial interaction testing (CIT) is an important
research topic in software engineering, and has been well
explored for the last two decades. For the general information
(e.g., theoretical work and practical achievement), interested
readers can refer to the book written by Kuhn et al. [67] and
the survey summarized by Nie and Leung [20].
Practical algorithms for solving CCAG can be classiï¬ed
into three main categories: greedy algorithms, meta-heuristic
algorithms and constraint-encoding algorithms. Greedy algo-
rithms can rapidly generate a CCA in some scenarios where
the metric of size is not the primary objective. Popular greedy
algorithms can be categorized into two main classes: one-
test-at-a-time (OTAT) algorithms and in-parameter-order (IPO)
algorithms. The well-known algorithm AETG is the ï¬rst one
using the OTAT strategy [6]. Bryce et al. proposed a generic
framework of the AETG -like algorithm [68]. Afterwards a
number of variations of AETG were proposed [12], [16], [69]â€“
[71]. The IPO algorithms extended horizontally and vertically
to cover the tuples [7], [72]. Many variations of the IPO
algorithms were also proposed ( e.g., [73], [74]).
Meta-heuristic algorithms work in an iterative manner:
during the search process, those algorithms aim at seeking
a CCA with a particular size k; once ak-sized CCA is found,
then the algorithms will try to seek a CCA with the size
smaller than k. Meta-heuristic algorithms include tabu search
[14], [70], [75]â€“[78], simulated annealing [8], [15], [79]â€“[81],
genetic algorithm [82], [83], etc. Actually, besides CCAG,
meta-heuristic algorithms have exhibited success in solving
various NP-hard problems [84]â€“[88].
Based on simulated annealing CCAG algorithms [60], [61],
Garvin et al. proposed the one-sided narrowing and t-set
replacement techniques [8], [10], resulting in an inï¬‚uential
CCAG algorithm called CASA [8], which reduces runtime and
ï¬nds smaller-sized CCAs. Jia et al. proposed a CCAG algo-
rithm named HHSA [15], which uses hyper-heuristic search
and dynamically applies different strategies during the search.
Linet al. proposed effective meta-heuristic CCAG algorithms
dubbed TCA [14] and FastCA [77], which use tabu search
to reduce the number of uncovered valid tuples, in order to
improve the performance for solving CCAG. Recently, Mercan
et al. presented an effective, parallel CCAG algorithm called
CHiP [18], which can use vast amount of graphics processing
units to implement the parallelism.
In addition, there is another way to tackle this problem.
Banbara et al. [9] and Yamada et al. [13] encoded the CCAG
210problem into the SAT problem and then use powerful con-
straint solvers to handle the resulting SAT-encoded instance.
Yamada et al. proposed a constraint-encoded algorithm called
Calot [13], which shows effectiveness for solving 2-way
CCAG. More particularly, it can prove the optimality for 2-
way CCAG on a number of instances [13]. However, solving
t-way CCAG ( t>3) still remains a challenge for constraint-
encoding algorithms.
VII. C ONCLUSION
In this paper, we propose a novel, automated CCAG ap-
proach dubbed AutoCCAG , which is able to leverage the pow-
erful automated conï¬guration and automated selection tech-
niques for solving the challenging CCAG problem. Extensive
experiments on a broad range of real-world instances demon-
strate that our AutoCCAG approach signiï¬cantly outperforms
its state-of-the-art CCAG competitors for solving 4-way and
5-way CCAG on public, real-world application benchmarks.
Also, the performance of AutoCCAG is better than or equal to
that of all its state-of-the-art CCAG competitors for solving
2-way and 3-way CCAG on these public benchmarks.
The testing benchmarks used in our experiments and the
detailed experimental results (including the experimental re-
sults of all CCAG algorithms for solving 2-way, 3-way, 4-
way and 5-way CCAG on all testing instances) are available
athttps://github.com/chuanluocs/AutoCCAG .
REFERENCES
[1] F. Medeiros, C. KÃ¤stner, M. Ribeiro, R. Gheyi, and S. Apel, â€œA
comparison of 10 sampling algorithms for conï¬gurable systems,â€ in
Proceedings of ICSE 2016 , 2016, pp. 643â€“654.
[2] M. Al-Hajjaji, T. ThÃ¼m, M. Lochau, J. Meinicke, and G. Saake, â€œEffec-
tive product-line testing using similarity-based product prioritization,â€
Software and Systems Modeling , vol. 18, no. 1, pp. 499â€“521, 2019.
[3] C. Kaltenecker, A. Grebhahn, N. Siegmund, J. Guo, and S. Apel,
â€œDistance-based sampling of software conï¬guration spaces,â€ in Proceed-
ings of ICSE 2019 , 2019, pp. 1084â€“1094.
[4] D. R. Kuhn, D. R. Wallace, and A. M. Gallo, â€œSoftware fault interactions
and implications for software testing,â€ IEEE Transactions on Software
Engineering , vol. 30, no. 6, pp. 418â€“421, 2004.
[5] C. Yilmaz, M. B. Cohen, and A. A. Porter, â€œCovering arrays for
efï¬cient fault characterization in complex conï¬guration spaces,â€ IEEE
Transactions on Software Engineering , vol. 32, no. 1, pp. 20â€“34, 2006.
[6] D. M. Cohen, S. R. Dalal, M. L. Fredman, and G. C. Patton, â€œThe
AETG system: An approach to testing based on combinatiorial design,â€
IEEE Transactions on Software Engineering , vol. 23, no. 7, pp. 437â€“444,
1997.
[7] Y . Lei and K. Tai, â€œIn-parameter-order: A test generation strategy for
pairwise testing,â€ in Proceedings of HASE 1998 , 1998, pp. 254â€“261.
[8] B. J. Garvin, M. B. Cohen, and M. B. Dwyer, â€œAn improved meta-
heuristic search for constrained interaction testing,â€ in Proceedings of
International Symposium on Search Based Software Engineering 2009 ,
2009, pp. 13â€“22.
[9] M. Banbara, H. Matsunaka, N. Tamura, and K. Inoue, â€œGenerating
combinatorial test cases by efï¬cient SAT encodings suitable for CDCL
SAT solvers,â€ in Proceedings of LPAR 2010 , 2010, pp. 112â€“126.
[10] B. J. Garvin, M. B. Cohen, and M. B. Dwyer, â€œEvaluating improvements
to a meta-heuristic search for constrained interaction testing,â€ Empirical
Software Engineering , vol. 16, no. 1, pp. 61â€“102, 2011.
[11] L. Yu, Y . Lei, M. N. Borazjany, R. Kacker, and D. R. Kuhn, â€œAn efï¬cient
algorithm for constraint handling in combinatorial test generation,â€ in
Proceedings of ICST 2013 , 2013, pp. 242â€“251.
[12] Z. Zhang, J. Yan, Y . Zhao, and J. Zhang, â€œGenerating combinatorial
test suite using combinatorial optimization,â€ Journal of Systems and
Software , vol. 98, pp. 191â€“207, 2014.[13] A. Yamada, T. Kitamura, C. Artho, E. Choi, Y . Oiwa, and A. Biere,
â€œOptimization of combinatorial testing by incremental SAT solving,â€ in
Proceedings of ICST 2015 , 2015, pp. 1â€“10.
[14] J. Lin, C. Luo, S. Cai, K. Su, D. Hao, and L. Zhang, â€œTCA: An efï¬cient
two-mode meta-heuristic algorithm for combinatorial test generation,â€ in
Proceedings of ASE 2015 , 2015, pp. 494â€“505.
[15] Y . Jia, M. B. Cohen, M. Harman, and J. Petke, â€œLearning combinatorial
interaction test generation strategies using hyperheuristic search,â€ in
Proceedings of ICSE 2015 , 2015, pp. 540â€“550.
[16] A. Yamada, A. Biere, C. Artho, T. Kitamura, and E. Choi, â€œGreedy com-
binatorial test case generation using unsatisï¬able cores,â€ in Proceedings
of ASE 2016 , 2016, pp. 614â€“624.
[17] P. Galinier, S. Kpodjedo, and G. Antoniol, â€œA penalty-based tabu search
for constrained covering arrays,â€ in Proceedings of GECCO 2017 , 2017,
pp. 1288â€“1294.
[18] H. Mercan, C. Yilmaz, and K. Kaya, â€œCHiP: A conï¬gurable hybrid
parallel covering array constructor,â€ IEEE Transactions on Software
Engineering , vol. 45, no. 12, pp. 1270â€“1291, 2019.
[19] M. Park, H. Jang, T. Byun, and Y . Choi, â€œProperty-based testing for LG
home appliances using accelerated software-in-the-loop simulation,â€ in
Proceedings of ICSE-SEIP 2020 , 2020, pp. 120â€“129.
[20] C. Nie and H. Leung, â€œA survey of combinatorial testing,â€ ACM
Computing Surveys , vol. 43, no. 2, pp. 11:1â€“11:29, 2011.
[21] C. Song, A. A. Porter, and J. S. Foster, â€œiTree: Efï¬ciently discovering
high-coverage conï¬gurations using interaction trees,â€ IEEE Transactions
on Software Engineering , vol. 40, no. 3, pp. 251â€“265, 2014.
[22] D. R. Kuhn and V . Okun, â€œPseudo-exhaustive testing for software,â€ in
Proceedings of SEW 2006 , 2006, pp. 153â€“158.
[23] R. Kuhn, R. N. Kacker, J. Y . Lei, and D. E. Simos, â€œInput space coverage
matters,â€ IEEE Computer , vol. 53, no. 1, pp. 37â€“44, 2020.
[24] R. Huang, H. Chen, Y . Zhou, T. Y . Chen, D. Towey, M. F. Lau, S. Ng,
R. Merkel, and J. Chen, â€œCovering array constructors: An experimental
analysis of their interaction coverage and fault detection,â€ The Computer
Journal , 2020.
[25] M. Hutchins, H. Foster, T. Goradia, and T. J. Ostrand, â€œExperiments
of the effectiveness of dataï¬‚ow- and controlï¬‚ow-based test adequacy
criteria,â€ in Proceedings of ICSE 1994 , 1994, pp. 191â€“200.
[26] G. Rothermel and M. J. Harrold, â€œEmpirical studies of a safe regression
test selection technique,â€ IEEE Transactions on Software Engineering ,
vol. 24, no. 6, pp. 401â€“419, 1998.
[27] V . Okun, P. E. Black, and Y . Yesha, â€œTesting with model checker:
Insuring fault visibility,â€ WSEAS Transactions on Systems , vol. 2, no. 1,
pp. 77â€“82, 2003.
[28] F. Hutter, H. H. Hoos, K. Leyton-Brown, and T. StÃ¼tzle, â€œParamILS:
An automatic algorithm conï¬guration framework,â€ Journal of Artiï¬cial
Intelligence Research , vol. 36, pp. 267â€“306, 2009.
[29] C. AnsÃ³tegui, M. Sellmann, and K. Tierney, â€œA gender-based genetic
algorithm for the automatic conï¬guration of algorithms,â€ in Proceedings
of CP 2009 , 2009, pp. 142â€“157.
[30] M. Birattari, Z. Yuan, P. Balaprakash, and T. StÃ¼tzle, â€œF-Race and
iterated F-Race: An overview,â€ in Experimental Methods for the Analysis
of Optimization Algorithms . Springer, 2010, pp. 311â€“336.
[31] F. Hutter, H. H. Hoos, and K. Leyton-Brown, â€œSequential model-based
optimization for general algorithm conï¬guration,â€ in Proceedings of
LION 2011 , 2011, pp. 507â€“523.
[32] C. AnsÃ³tegui, Y . Malitsky, H. Samulowitz, M. Sellmann, and K. Tier-
ney, â€œModel-based genetic algorithms for algorithm conï¬guration,â€ in
Proceedings of IJCAI 2015 , 2015, pp. 733â€“739.
[33] M. LÃ³pez-IbÃ¡Ã±ez, J. Dubois-Lacoste, L. PÃ©rez CÃ¡ceres, T. StÃ¼tzle, and
M. Birattari, â€œThe irace package: Iterated racing for automatic algorithm
conï¬guration,â€ Operations Research Perspectives , vol. 3, pp. 43â€“58,
2016.
[34] N. Dang, L. P. CÃ¡ceres, P. D. Causmaecker, and T. StÃ¼tzle, â€œConï¬guring
irace using surrogate conï¬guration benchmarks,â€ in Proceedings of
GECCO 2017 , 2017, pp. 243â€“250.
[35] L. Xu, F. Hutter, H. H. Hoos, and K. Leyton-Brown, â€œSATzilla:
Portfolio-based algorithm selection for SAT,â€ Journal of Artiï¬cial In-
telligence Research , vol. 32, pp. 565â€“606, 2008.
[36] S. Kadioglu, Y . Malitsky, M. Sellmann, and K. Tierney, â€œISAC â€“
Instance-speciï¬c algorithm conï¬guration,â€ in Proceedings of ECAI 2010 ,
2010, pp. 751â€“756.
[37] S. Kadioglu, Y . Malitsky, A. Sabharwal, H. Samulowitz, and M. Sell-
mann, â€œAlgorithm selection and scheduling,â€ in Proceedings of CP 2011 ,
2011, pp. 454â€“469.
211[38] Y . Malitsky, A. Sabharwal, H. Samulowitz, and M. Sellmann, â€œAlgorithm
portfolios based on cost-sensitive hierarchical clustering,â€ in Proceedings
of IJCAI 2013 , 2013, pp. 608â€“614.
[39] M. Lindauer, H. H. Hoos, F. Hutter, and T. Schaub, â€œAutoFolio:
An automatically conï¬gured algorithm selector,â€ Journal of Artiï¬cial
Intelligence Research , vol. 53, pp. 745â€“778, 2015.
[40] M. Lindauer, H. H. Hoos, K. Leyton-Brown, and T. Schaub, â€œAutomatic
construction of parallel portfolios via algorithm conï¬guration,â€ Artiï¬cial
Intelligence , vol. 244, pp. 272â€“290, 2017.
[41] C. Luo, H. H. Hoos, S. Cai, Q. Lin, H. Zhang, and D. Zhang, â€œLocal
search with efï¬cient automatic conï¬guration for minimum vertex cover,â€
inProceedings of IJCAI 2019 , 2019, pp. 1297â€“1304.
[42] C. Thornton, F. Hutter, H. H. Hoos, and K. Leyton-Brown, â€œAuto-
WEKA: combined selection and hyperparameter optimization of classi-
ï¬cation algorithms,â€ in Proceedings of KDD 2013 , 2013, pp. 847â€“855.
[43] M. Feurer, A. Klein, K. Eggensperger, J. T. Springenberg, M. Blum,
and F. Hutter, â€œEfï¬cient and robust automated machine learning,â€ in
Proceedings of NIPS 2015 , 2015, pp. 2962â€“2970.
[44] T. Domhan, J. T. Springenberg, and F. Hutter, â€œSpeeding up automatic
hyperparameter optimization of deep neural networks by extrapolation
of learning curves,â€ in Proceedings of IJCAI 2015 , 2015, pp. 3460â€“3468.
[45] C. AnsÃ³tegui, J. Pon, M. Sellmann, and K. Tierney, â€œReactive dialectic
search portfolios for MaxSAT,â€ in Proceedings of AAAI 2017 , 2017, pp.
765â€“772.
[46] H. Hoos, M. T. Lindauer, and T. Schaub, â€œclaspfolio 2: Advances in
algorithm selection for answer set programming,â€ Theory and Practice
of Logic Programming , vol. 14, no. 4-5, pp. 569â€“585, 2014.
[47] H. H. Hoos, â€œProgramming by optimization,â€ Communications of the
ACM , vol. 55, no. 2, pp. 70â€“80, 2012.
[48] C. Luo, H. H. Hoos, and S. Cai, â€œPbO-CCSAT: Boosting local search
for satisï¬ability using programming by optimisation,â€ in Proceedings of
PPSN 2020 , 2020, pp. 373â€“389.
[49] F. Hutter, M. LÃ³pez-IbÃ¡Ã±ez, C. Fawcett, M. T. Lindauer, H. H. Hoos,
K. Leyton-Brown, and T. StÃ¼tzle, â€œAClib: A benchmark library for
algorithm conï¬guration,â€ in Proceedings of LION 2014 , 2014, pp. 36â€“
40.
[50] J. Mockus, Bayesian Approach to Global Optimization: Theory and
Applications . Kluwer Academic Publishers, 1989.
[51] D. J. C. MacKay, Information Theory, Inference, and Learning Algo-
rithms . Cambridge University Press, 2003.
[52] D. R. Jones, M. Schonlau, and W. J. Welch, â€œEfï¬cient global optimiza-
tion of expensive black-box functions,â€ Journal of Global Optimization ,
vol. 13, no. 4, pp. 455â€“492, 1998.
[53] B. Shahriari, K. Swersky, Z. Wang, R. P. Adams, and N. de Freitas,
â€œTaking the human out of the loop: A review of Bayesian optimization,â€
Proceedings of the IEEE , vol. 104, no. 1, pp. 148â€“175, 2016.
[54] C. Luo, B. Qiao, X. Chen, P. Zhao, R. Yao, H. Zhang, W. Wu,
A. Zhou, and Q. Lin, â€œIntelligent virtual machine provisioning in cloud
computing,â€ in Proceedings of IJCAI 2020 , 2020, pp. 1495â€“1502.
[55] F. Hutter, M. Lindauer, A. Balint, S. Bayless, H. H. Hoos, and K. Leyton-
Brown, â€œThe conï¬gurable SAT solver challenge (CSSC),â€ Artiï¬cial
Intelligence , vol. 243, pp. 1â€“25, 2017.
[56] L. Xu, H. H. Hoos, and K. Leyton-Brown, â€œHydra: Automatically
conï¬guring algorithms for portfolio-based selection,â€ in Proceedings of
AAAI 2010 , 2010.
[57] A. FrÃ©chette, N. Newman, and K. Leyton-Brown, â€œSolving the station
repacking problem,â€ in Proceedings of AAAI 2016 , 2016, pp. 702â€“709.
[58] L. Xu, A. R. KhudaBukhsh, H. H. Hoos, and K. Leyton-Brown,
â€œQuantifying the similarity of algorithm conï¬gurations,â€ in Proceedings
of LION 2016 , 2016, pp. 203â€“217.
[59] L. Xu, F. Hutter, H. Hoos, and K. Leyton-Brown, â€œEvaluating com-
ponent solver contributions to portfolio-based algorithm selectors,â€ in
Proceedings of SAT 2012 , 2012, pp. 228â€“241.
[60] M. B. Cohen, M. B. Dwyer, and J. Shi, â€œInteraction testing of highly-
conï¬gurable systems in the presence of constraints,â€ in Proceedings of
ISSTA 2007 , 2007, pp. 129â€“139.
[61] â€”â€”, â€œConstructing interaction test suites for highly-conï¬gurable sys-
tems in the presence of constraints: A greedy approach,â€ IEEE Trans-
actions on Software Engineering , vol. 34, no. 5, pp. 633â€“650, 2008.
[62] I. Segall, R. Tzoref-Brill, and E. Farchi, â€œUsing binary decision diagrams
for combinatorial test design,â€ in Proceedings of ISSTA 2011 , 2011, pp.
254â€“264.
[63] A. Vargha and H. D. Delaney, â€œA critique and improvement of the CL
common language effect size statistics of McGraw and Wong,â€ Journalof Educational and Behavioral Statistics , vol. 25, no. 2, pp. 101â€“132,
2000.
[64] F. Sarro, M. Harman, Y . Jia, and Y . Zhang, â€œCustomer rating reactions
can be predicted purely using app features,â€ in RE 2018 , 2018, pp. 76â€“
87.
[65] J. Snoek, H. Larochelle, and R. P. Adams, â€œPractical Bayesian opti-
mization of machine learning algorithms,â€ in Proceedings of NIPS 2012 ,
2012, pp. 2960â€“2968.
[66] J. C. Platt, C. J. C. Burges, S. Swenson, C. Weare, and A. Zheng,
â€œLearning a Gaussian process prior for automatically generating music
playlists,â€ in Proceedings of NIPS 2001 , 2001, pp. 1425â€“1432.
[67] D. R. Kuhn, R. N. Kacker, and Y . Lei, Introduction to combinatorial
testing . CRC press, 2013.
[68] R. C. Bryce, C. J. Colbourn, and M. B. Cohen, â€œA framework of greedy
methods for constructing interaction test suites,â€ in Proceedings of ICSE
2005 , 2005, pp. 146â€“155.
[69] Y .-W. Tung and W. S. Aldiwan, â€œAutomating test case generation for
the new generation mission software system,â€ in Proceedings of IEEE
Aerospace Conference 2000 , 2000, pp. 431â€“437.
[70] R. C. Bryce and C. J. Colbourn, â€œThe density algorithm for pairwise in-
teraction testing,â€ Software Testing, Veriï¬cation and Reliability , vol. 17,
no. 3, pp. 159â€“182, 2007.
[71] â€”â€”, â€œA density-based greedy algorithm for higher strength covering
arrays,â€ Software Testing, Veriï¬cation and Reliability , vol. 19, no. 1, pp.
37â€“53, 2009.
[72] Y . Lei, R. Kacker, D. R. Kuhn, V . Okun, and J. Lawrence, â€œIPOG: A
general strategy for t-way software testing,â€ in Proceedings of ECBS
2007 , 2007, pp. 549â€“556.
[73] Z. Wang, C. Nie, and B. Xu, â€œGenerating combinatorial test suite for
interaction relationship,â€ in Proceedings of SOQUA 2007 , 2007, pp. 55â€“
61.
[74] Y . Lei, R. Kacker, D. R. Kuhn, V . Okun, and J. Lawrence, â€œIPOG/IPOG-
D: efï¬cient test generation for multi-way combinatorial testing,â€ Soft-
ware Testing, Veriï¬cation and Reliability , vol. 18, no. 3, pp. 125â€“148,
2008.
[75] K. J. Nurmela, â€œUpper bounds for covering arrays by tabu search,â€
Discrete Applied Mathematics , vol. 138, no. 1-2, pp. 143â€“152, 2004.
[76] L. Gonzalez-Hernandez, N. Rangel-Valdez, and J. Torres-Jimenez, â€œCon-
struction of mixed covering arrays of variable strength using a tabu
search approach,â€ in Proceedings of COCOA 2010 , 2010, pp. 51â€“64.
[77] J. Lin, S. Cai, C. Luo, Q. Lin, and H. Zhang, â€œTowards more efï¬cient
meta-heuristic algorithms for combinatorial test generation,â€ in Proceed-
ings of ESEC/SIGSOFT FSE 2019 , 2019, pp. 212â€“222.
[78] Y . Fu, Z. Lei, S. Cai, J. Lin, and H. Wang, â€œWCA: A weighting local
search for constrained combinatorial test optimization,â€ Information and
Software Technology , vol. 122, p. 106288, 2020.
[79] M. B. Cohen, P. B. Gibbons, W. B. Mugridge, and C. J. Colbourn,
â€œConstructing test suites for interaction testing,â€ in Proceedings of ICSE
2003 , 2003, pp. 38â€“48.
[80] M. B. Cohen, P. B. Gibbons, W. B. Mugridge, C. J. Colbourn, and
J. S. Collofello, â€œVariable strength interaction testing of components,â€
inProceedings of COMPSAC 2003 , 2003, p. 413.
[81] M. B. Cohen, C. J. Colbourn, and A. C. H. Ling, â€œAugmenting simulated
annealing to build interaction test suites,â€ in Proceedings of ISSRE 2003 ,
2003, pp. 394â€“405.
[82] S. A. Ghazi and M. A. Ahmed, â€œPair-wise test coverage using genetic
algorithms,â€ in Proceedings of CEC 2003 , vol. 2, 2003, pp. 1420â€“1424.
[83] J. D. McCaffrey, â€œGeneration of pairwise test sets using a genetic
algorithm,â€ in Proceedings of COMPSAC 2009 , 2009, pp. 626â€“631.
[84] C. Luo, S. Cai, W. Wu, and K. Su, â€œDouble conï¬guration checking in
stochastic local search for satisï¬ability,â€ in Proceedings of AAAI 2014 ,
2014, pp. 2703â€“2709.
[85] C. Luo, K. Su, and S. Cai, â€œMore efï¬cient two-mode stochastic local
search for random 3-satisï¬ability,â€ Applied Intelligence , vol. 41, no. 3,
pp. 665â€“680, 2014.
[86] C. Luo, S. Cai, W. Wu, Z. Jie, and K. Su, â€œCCLS: An efï¬cient
local search algorithm for weighted maximum satisï¬ability,â€ IEEE
Transactions on Computers , vol. 64, no. 7, pp. 1830â€“1843, 2015.
[87] C. Luo, S. Cai, K. Su, and W. Wu, â€œClause states based conï¬guration
checking in local search for satisï¬ability,â€ IEEE Transactions on Cyber-
netics , vol. 45, no. 5, pp. 1014â€“1027, 2015.
[88] C. Luo, S. Cai, K. Su, and W. Huang, â€œCCEHC: An efï¬cient local
search algorithm for weighted partial maximum satisï¬ability,â€ Artiï¬cial
Intelligence , vol. 243, pp. 26â€“44, 2017.
212