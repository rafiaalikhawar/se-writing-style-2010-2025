AID: An automated detector for gender-inclusivity
bugs in OSS project pages
Amreeta Chatterjee1, Mariam Guizani1, Catherine Stevens1, Jillian Emard1, Mary Evelyn May1,
Margaret Burnett1, Iftekhar Ahmed2, Anita Sarma1
1Oregon State University, Corvallis, OR 97330, USA ,2University of California, Irvine, Irvine, CA
fchattera,guizanim,stevecat,emardj,mayma g@oregonstate.edu, burnett@eecs.oregonstate.edu,
iftekha@uci.edu, anita.sarma@oregonstate.edu
Abstract ‚ÄîThe tools and infrastructure used in tech, including
Open Source Software (OSS), can embed ‚Äúinclusivity bugs‚Äù‚Äî
features that disproportionately disadvantage particular groups
of contributors. To see whether OSS developers have existing
practices to ward off such bugs, we surveyed 266 OSS developers.
Our results show that a majority (77%) of developers do not use
any inclusivity practices, and 92% of respondents cited a lack of
concrete resources to enable them to do so. To help Ô¨Åll this gap,
this paper introduces AID, a tool that automates the GenderMag
method to systematically Ô¨Ånd gender-inclusivity bugs in software.
We then present the results of the tool‚Äôs evaluation on 20 GitHub
projects. The tool achieved precision of 0.69, recall of 0.92, an
F-measure of 0.79 and even captured some inclusivity bugs that
human GenderMag teams missed.
Index Terms ‚ÄîGender inclusivity, automation, open source,
information processing
I. I NTRODUCTION
A new class of bug is beginning to gain visibility in software
engineering literature: the inclusivity bug. An inclusivity bug
is software behavior that disproportionately disadvantages a
particular group of users of that software. To date, the most
studied type of inclusivity bugs are gender-inclusivity bugs,
most (but not all) of which disproportionately disadvantage
women [1]‚Äì[8].
Some gender-inclusivity bugs in software manifest them-
selves overtly, such as with non-inclusive language [9],
[10], gender-stereotyped game characters [11], or gender-
stereotyped job matches [12], [13]. Detecting overt gender-
inclusivity bugs is relatively straightforward, by deÔ¨Ånition of
the term ‚Äúovert‚Äù (although actually Ô¨Åxing them is not always
straightforward). However, non-overt gender-inclusivity bugs
are not so obvious, such as software behaviors and workÔ¨Çows
that are biased against cognitive or behavioral styles more
common in one gender than another. For example, among the
software-relevant gender differences pointed out in Stumpf et
al.‚Äôs survey are gender clusters of differences in the colors and
sounds people can distinguish, how people comprehend and
interpret verbal/written communications, their spatial process-
ing, their attitudes toward technological risks, and how they
process information [10].
The extent to which such non-overt gender-inclusivity bugs
permeate software is large. The lowest percentage we have
been able to locate is one team‚Äôs report of inclusivity bugs in‚Äúonly‚Äù 12% of the features they considered [14]; other teams
have reported much higher rates of inclusivity bugs [4], [7],
[14]. For example, in one recent study on a group of OSS
projects, the rate of gender-inclusivity bugs reported by OSS
professionals that were then veriÔ¨Åed by OSS newcomers was
63% [15].
Fortunately, there are methods that can help software pro-
fessionals Ô¨Ånd, Ô¨Åx, and/or avert inclusivity bugs (e.g., [16],
[17]). One of these is GenderMag ( Gender Inclusiveness
MagniÔ¨Åer) [3], which provides the foundation of the tool
presented in this paper. GenderMag is a method that enables
developers to systematically Ô¨Ånd gender-inclusivity bugs in
their software or workÔ¨Çow so that they can Ô¨Åx the bugs.
GenderMag variants have been used in a variety of domains,
including digital libraries [18], learning tools and websites [3],
[14], [19], [20], machine learning interfaces [14], robotics [6],
search engines [7], and OSS projects [15], [21].
Unfortunately, however, using any of these methods can
be expensive, because they are entirely manual and labor-
intensive. For example, GenderMag‚Äôs creators recommend that
at least 3 evaluators spend 1-2 hours per session [22], where
a session usually covers only 1-3 use-cases. In fact, Ô¨Ånding
ways to reduce the cost was a major theme in a recent Ô¨Åeld
study of 10 teams‚Äô work to integrate GenderMag into their
development processes [20].
Can a software tool help to address this problem, to increase
the viability of debugging inclusivity bugs that lurk in soft-
ware? To Ô¨Ånd out, we conducted a survey of experienced OSS
developers (OSS‚Äôers), to learn what tools and other inclusivity
debugging resources developers actually use.
Informed by the study, we then created AID, a tool that
automates a ‚Äúvertical slice‚Äù of GenderMag. We used a vertical
slice instead of all of GenderMag for two reasons. First, since
this is the Ô¨Årst of a new class of software tools (inclusivity bug
detectors), we needed a tractable way to investigate whether
this class of tools is even possible. Second, it enabled us to
empirically investigate AID‚Äôs effectiveness under the strict
controls that a single vertical slice affords. SpeciÔ¨Åcally, this
version of the tool uses a portion of allthe components of
GenderMag‚Äîa portion of its scope (OSS GitHub projects),
one of its personas (Abi), and one of its cognitive styles (the in-
formation processing style). We then empirically investigated
14232021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)
1558-1225/21/$31.00 ¬©2021 IEEE
DOI 10.1109/ICSE43902.2021.00128
TABLE I
THEFACETS & A BI‚ÄôS VALUES FOR EACH (SEE[3] FOR THE FOUNDATIONS
BEHIND EACH )
Facet Abi‚Äôs Values
Moti vations Uses technology to accomplish tasks
Computer Self-EfÔ¨Åcacy Low compared to peers
Attitude towards Risk Risk-a verse
Information Processing Style Comprehensi ve
Learning Style Learns by process
thetool‚Äôs results on 20 OSS GitHub projects.
This paper presents AID and reports our empirical Ô¨Åndings.
The contributions of this paper are:
A survey of 266 experienced OSS developers‚Äô inclusivity
debugging practices, and the tools/guidelines they use for
these practices;
AID, the Ô¨Årst software tool to automate the detection of
inclusivity bugs; and
An empirical investigation of AID‚Äôs efÔ¨Åcacy on 20 OSS
GitHub projects.
II. B ACKGROUND : THEGENDER MAGMETHOD
AID is a partial automation of the GenderMag method [3].
GenderMag is a process that enables software professionals
to systematically locate gender-inclusivity ‚Äúbugs‚Äù in the user-
facing portions of their software. Locating these bugs is
a prerequisite to Ô¨Åxing them. GenderMag has been used
successfully in a variety of domains, including university
webware, educational software, machine-learning interfaces,
mobile apps, digital libraries, search engines, and software
tools [3], [7], [14], [18]‚Äì[21], [23].
At the core of GenderMag method are Ô¨Åve problem solving
styles, or facets , each backed by extensive foundational re-
search [3], [10]. The Ô¨Åve facets are: Motivations for using
technology, Computer Self-EfÔ¨Åcacy, Attitude towards Risk,
Information Processing Style, and Learning Style. Each facet
has a range of possible values, and GenderMag uses three
multi-personas (Abi, Pat, and Tim) to bring different facet
values to life (Table I and Figure 1). Each persona embodies
a different set of values for the Ô¨Åve facets. Facet values
statistically more common among women are assigned to Abi,
those more common among men are assigned to Tim, and a
mix of various facet values are assigned to Pat. These facet
values are what deÔ¨Åne each persona‚Äôs problem-solving style.
Other persona attributes (e.g., job, age, hobbies, preferred
pronouns, etc...) are customizable.
Of particular interest to this paper is the Information Pro-
cessing facet as it pertains to the Abi persona, because the
tool we present is a partial automation of that facet from
Abi‚Äôs perspective. The information processing facet describes
how a user receives new information to make decisions about
actions to take, in order to accomplish a task. The Abi persona
processes information comprehensively‚Äîthat is, by gathering
fairly complete information before proceeding. At the opposite
end of the information processing spectrum of values is the
Tim persona, who is more likely to process informationselectively and act upon the Ô¨Årst promising information they
Ô¨Ånd, then backtrack if needed [24].
To conduct a GenderMag session, a software team ‚Äúchan-
nels‚Äù one of these personas, chooses a use-case (a task for
the persona to try to accomplish), and walks through that
use-case (task) using a specialized version of the Cognitive
Walkthrough (CW) family [25]. In this process, the team
answers one question for each subgoal and two questions for
each action that the software team is hoping a user will take
to accomplish the task. The ‚Äúaction‚Äù questions are answered
before and after performing the action. The questions are:
Fig. 1. The Abi persona, with their information processing style facet value
enlarged for readability. (See supplemental materials at [26] for the full
version.)
Subgoal Question (S-Q): Will <persona > have
formed this subgoal as a step to their overall goal?
(Yes/No/Maybe, why, what facets did you use)
Action Question#1 (A-Q#1): Will <persona >know to
take the action? (Yes/No/Maybe, why, what facets did
you use)
Action Question#2 (A-Q#2): If <persona >takes the
action, will they know they did the right thing and are
making progress toward their goal? (Yes/No/Maybe, why,
what facets did you use)
If the team answers as No/Maybe to any of these questions
and attributes it to one of the <persona >‚Äôs facet, then (and
only then) it is considered an inclusivity bug. AID automates
the process described above for Abi‚Äôs information processing
facet value.
III. F ORMATIVE STUDY
To understand (1) the state of inclusivity evaluations in OSS
and (2) the challenges behind incorporating such evaluations
in the development process, we conducted a formative inves-
tigation in the form of a survey.
A. Survey Methodology
We recruited OSS developers as survey participants as
our goals were to learn about inclusivity evaluation practices
and needs inside OSS. We aimed to get the perspective of
experienced OSS developers since in this version of AID we
are using GitHub-based project pages as our test subjects.
1424TABLE II
INCLUSIVITY PRACTICE SURVEY DATA GROUPED BY DEMOGRAPHICS .
Yes 23%
(61 of 266)No 77%
(205 of 266)
1-49 (102 respondents) 18% 82%
50-999 (65 respondents) 25% 75%
1,000-5,000 (34 respondents) 21% 79%Size
>5,000 (65 respondents) 31% 69%
<3months (7 respondents) 43% 57%
3-6months (5 respondents) 0% 100%
7mo.-1 yr. (4 respondents) 0% 100%Experience
>1year (250 respondents) 23% 77%
Paid (221 respondents) 24% 76% Participation
Type Unpaid (45 respondents) 20% 80%
When recruiting participants we used the number of follow-
ers as a Ô¨Åltering criterion since experienced OSS developers
are more likely than newcomers to accrue followers. For
example, Blincoe et al. found that popular GitHub OSS‚Äôers
inÔ¨Çuence their followers and attract them to new projects [27].
We used the number of followers as a Ô¨Ålter criterion because
experienced OSS developers are more likely than newcomers
to accrue followers. For example, Blincoe et al. found that
popular GitHub OSS‚Äôers inÔ¨Çuence their followers and attract
them to new projects [27].
In order to do that, we used the GitHub search tool to
retrieve 5,000 usernames that are among the top-followed
GitHub OSS‚Äôers. To get the contacts of this list 5,000 user-
names, we modiÔ¨Åed a tool called Zen [28], which obtained
email addresses for 3,124 of these usernames. We sent the
survey to these 3,124 experienced OSS developers.
The survey had a total of eight questions, comprising
Yes/No, multiple choice, and open-ended questions. In addi-
tion to collecting demographic information, the survey used
branching logic when asking about existing inclusivity eval-
uation practices. If the participant indicated that their de-
velopment practices include doing some form of inclusivity
evaluation, we asked more about these; otherwise we asked
what challenges prevent them from doing so. In pilot runs,
the survey took about Ô¨Åve minutes to complete.
We emailed this survey to 3,124 developers. 253 of the
emails bounced or were unreachable, which resulted in 2,871
recipients. At the end of the two weeks during which the
survey remained open, we received 394 responses, or a re-
sponse rate of 13.7% (394/2,871). This response rate com-
pares favorably to the 7.9% survey response rate found in
a previous software engineering study [29]. We removed the
survey responses that had partial answers, leaving us with 266
responses. The survey questions and the tool used to retrieve
the developers‚Äô email addresses are provided at [26].
B. Survey Results
Over three-fourths (77%) of the survey respondents reported
that they do not incorporate inclusivity practices into their soft-
ware development processes. As Table II‚Äôs rightmost column
shows, the majority of every demographic group reported not
using inclusivity practices.
When those who responded ‚ÄúNo‚Äù were asked why, they
responded as summarized in Figure 2. Almost half the reasonsrelated to lack of awareness/interest. SpeciÔ¨Åcally, about 30%
of the reasons were a lack of awareness of such practices or
of the importance of doing so, another 12% reported lack of
support from management, and 13% (‚Äúother, please specify‚Äù)
explained that such practices were up to individual developers,
or that they were unnecessary, unimportant, or even harmful:
P84: ‚ÄúInclusivity happens on an ad-hoc basis and depends on
the individual engineer... ‚Äù
P123: ‚ÄúEveryone I work with uses internet handles. I have no
clue if ‚ÄòLadyOTheLake‚Äô, is a guy, gal, minority, straight, gay,
... We just code and make good stuff. ‚Äù
P145: ‚ÄúOpen source communities have never prioritized inclu-
sivity. ‚Äù
The above reasons are perhaps unsurprising, given that the
concept of Ô¨Ånding/Ô¨Åxing inclusivity bugs within technology
itself, beyond accessibility (e.g., providing alt text), is a
relatively recent one in software engineering. For example,
to the best of our knowledge, the Ô¨Årst paper in the software
engineering community to even mention the concept of soft-
ware‚Äôs inclusivity bugs was only a decade ago (2010) [30],
and the Ô¨Årst software engineering presentation of a systematic
process for software developers to Ô¨Ånd such bugs wasn‚Äôt until
2016 [31].
Reasons like the above are, at best, only indirectly ad-
dressable by creating a new tool. However, the remaining
46% of the reasons survey participants gave‚Äîlack of speciÔ¨Åc
guidelines (26%), the costs of inclusivity evaluation (12%),
and lack of tools (8%)‚Äîare all potential fodder for software
engineering tools.
In fact, even the 23% of respondents who did report using
inclusivity practices in their development processes did not
have much in the way of concrete techniques in their existing
inclusivity efforts. Only 28 of these Yes-respondents (less than
one-third of the Yes‚Äôs) reported using a technique of any sort.
Of these 28 Yes-respondents, nine use mainly ad-hoc in-
clusivity techniques (Figure 2, bottom four bars), such as
inspecting their work for stereotyping language or character
depictions; relying on user feedback or user study results; or
following general codes of conduct. Another nine relied on
internal/custom tools (Figure 2, second bar from the top).
Only four public inclusivity techniques were reported by
any respondents: GenderMag with/without the GenderMag
Recorder‚Äôs Assistant (10 respondents), public guidelines for
inclusive language in code [32] (one respondent), public
guidelines for inclusive documentation [33] (one respondent),
and public guidelines for ethical collection of training data [34]
(one respondent). GenderMag was the only inclusivity tech-
nique used by multiple respondents.
The above 28 respondents‚Äîthe only respondents who re-
ported using any speciÔ¨Åc techniques, tools, or guidelines‚Äî
are only 8% of the total respondents. The other Yes‚Äôs instead
described a lack of tools and/or guidelines in their inclusivity
efforts:
P299: ‚ÄúWe don‚Äôt use speciÔ¨Åc techniques... ‚Äù
P130: ‚ÄúLack of knowledge and tools makes developers reinvent-
ing the wheels all the time. ‚Äù
1425P60: ‚Äú...there are no such guidelines or tools ... I hope that just
as we have guidelines for code quality we [could] also have
inclusivity principles... ‚Äù
Fig. 2. (Left): No-respondents‚Äô reasons/challenges for not using inclusivity,
as a percentage of all challenges. (Note: Data shown totals 101%, due to
rounding of each individual bar.) (Right): Yes-respondents‚Äô uses of different
inclusivity techniques.
IV. AID
Even the few survey respondents who reported using a
concrete technique had only a little ammunition to address
three of the tool-relevant challenges alluded to above: costs,
lack of tools, and lack of concrete guidelines. Regarding
costs, GenderMag was the only publicly available method
used, and it is costly, requiring teams of multiple software
professionals to work together in sessions that can last two or
more hours [20]. Regarding tools, other than a few mentions
of internal tools, no respondent reported tool usage other
than the Recorder‚Äôs Assistant, which is simply a note-taking
organizational aid. Regarding guidelines, a few respondents
pointed to concrete guidelines, but none went beyond language
use and stereotyping issues. Together, these three categories
accounted for 46% of the challenges reported by survey
participants who do not use any form of inclusivity evaluation
(Figure 2), and were also pointed out by some participants
who douse some kind of inclusivity evaluation.
To overcome these challenges, we created AID, a tool
whose ultimate goal is to automatically detect non-overt gen-
der inclusivity bugs like those described in Section I. In this
paper we report on our Ô¨Årst step‚Äîautomating a vertical slice
of GenderMag inclusivity evaluations‚Äîtoward this ultimate
goal.
Fig. 3. A snapshot of a spreadsheet with inputs and outputs from a manual
GenderMag session (information processing facet only). AID uses the Subgoal
and Action columns as input and produces similar outputs as the manual
GenderMag session. Orange backgrounds: Use-case and Subgoal inputs;
white backgrounds: Action inputs; blue backgrounds: GenderMag evaluation
outputs.
Fig. 4. Overview of AID‚Äôs architecture
One choice that deÔ¨Åned our vertical slice was the type of
software we scoped our tool to. We scoped our tool to use
OSS platforms , which is an important genre for inclusivity
bug detection because (1) these platforms are the sole mecha-
nism through which OSS community members can interact,
and (2) OSS tools and technology have pervasive gender-
inclusivity bugs [15], [21]. Another choice in deÔ¨Åning our
vertical slice was the persona. We chose GenderMag‚Äôs Abi
persona as per the ‚ÄúAbi Ô¨Årst‚Äù practice, commonly used because
Abi has historically provided the most powerful lens for
revealing inclusivity bugs [20]. The third choice was the facet.
We decided on the information processing style facet, because
OSS projects are information-rich environments.
For this vertical slice, AID takes as inputs the use-cases,
subgoals, and actions for a GenderMag session as well as the
URLs of the project‚Äôs GitHub pages (Figure 3). Using these
inputs, AID evaluates the project‚Äôs GitHub pages against its
model and produces an inclusivity bug report similar to the
blue region of Figure 3.
A. Deriving the model
The question of how to automate GenderMag presents a
number of challenges. First, there are an inÔ¨Ånite number of
platforms and UIs that could be evaluated, each of which have
an inÔ¨Ånite number of use-cases. Second, as a member of the
CW family, GenderMag involves simulating (other) humans,
a task that some people Ô¨Ånd difÔ¨Åcult to accomplish [35]. The
few researchers who have automated CWs for limited purposes
(e.g., [36]) have done so under the assumption that users
are homogeneous, and have not attempted to take into ac-
count the range in people‚Äôs cognitive styles. Finally, extensive
GenderMag session data does not yet exist, which prevents
some kinds of approaches from being viable. For example,
a machine-learning approach would require training a model
using data from millions of GenderMag sessions, including
the context associated with each (platform, UI elements, etc.)
Since AID is the Ô¨Årst investigation into whether an in-
clusivity bug detector is even possible, the tool‚Äôs feature-
completeness was not a critical consideration. Thus, we coun-
teracted the Ô¨Årst and second challenges via the vertical slice
already discussed. To address the third challenge, we turned
to a decision-rule approach.
An advantage of decision rules is that beyond statistical
patterns, they can also harness relevant theories, such as
those in GenderMag‚Äôs foundational core (e.g., self-efÔ¨Åcacy
theory [37], information processing theory [24], etc.) Thus,
they do not require nearly as much empirical data.
1426That said, we still needed some empirical data to ground
our decision rules in OSS-relevant data‚Äîthe inclusivity bugs
in real OSS projects and why they occur (recall Figure 3).
Toward that end, we obtained GenderMag session data from
two active OSS teams (Projects F and J) that have already used
GenderMag to improve their projects‚Äô inclusivity. Project F is
a GitHub-based platform to help newcomers become familiar
with OSS; it has 21 contributors and 2.5 million lines of
code. Project J is a GitHub-based data science project with
295 contributors and 1.3 million lines of code. The project
teams shared their GenderMag session materials, which in-
cluded their use-cases, customized GenderMag personas, and
evaluation outputs (recall Figure 3). Together these teams‚Äô
data identiÔ¨Åed 19 inclusivity bugs related to Abi‚Äôs information
processing style.
To supplement the data obtained from the external projects,
we sought out additional GitHub-based OSS projects to con-
duct additional GenderMag evaluations.
We turned to the classiÔ¨Åcation by Fronchetti et al., which
classiÔ¨Åed 450 OSS GitHub-based projects into three groups
based on the average growth of newcomers: (1) Logarithmic
growth (71 projects); (2) linear growth (322 projects); and
(3) Exponential growth (57 projects) [38]. We randomly se-
lected six projects from each group, resulting in 18 projects
of varying maturity, size and domain (Table III).
We then manually conducted GenderMag sessions on them
to produce data about the inclusivity bugs within these projects
pertaining to the information processing style facet. In order
to remain consistent with sessions from Projects F & J, we
used the same Abi persona (which was customized to be a
newcomer) and use-cases that they had used (Table IV). These
sessions covered 255 actions and produced answers to a total
of 510 questions‚Äîtwo questions per action (Section II). (The
sessions also produced answers to 126 subgoal questions, but
since none referred to information processing style, we did not
include them in the analysis.) The answers to these questions
revealed 257 inclusivity bugs‚Äîsteps in the use-cases where
OSS‚Äôers with Abi‚Äôs comprehensive information processing
style would be disadvantaged. These 257 inclusivity bugs plus
the 19 inclusivity bugs from the Projects F & J, a total of 276
inclusivity bugs, comprised the dataset from which we derived
the model‚Äôs decision rules.
B. Reliability Safeguards
We used multiple strategies to safeguard the reliability of
the GenderMag session outputs (see Figure 3) used to infer
our decision rules and the empirical results from AID.
1) Inter-Rater Reliability of GenderMag Session Outputs:
The Ô¨Årst safeguard was inter-rater reliability, to ensure con-
sistency of the GenderMag session outputs we conducted on
the 18 projects. Two pairs of researchers had each conducted
GenderMag sessions. To measure consistency of their Gen-
derMag session outputs, we drew upon inter-rater reliability
calculations often used with qualitative analysis [39]. Specif-
ically, each team independently ran GenderMag sessions on
20% of the use-cases. They then compared their outputs usingthe Jaccard index [40] to calculate a consensus, which resulted
in 83% agreement. Given this level of team consensus [40],
the two teams divided the remaining projects.
2) Validation against OSS Teams‚Äô GenderMag Session Out-
puts: The above is a measure of consistency between the two
teams of researchers. To measure consistency with real OSS
teams‚Äô GenderMag outputs, we validated our research teams‚Äô
outputs against those from Projects F & J. Recall that Teams F
& J conducted the GenderMag sessions themselves on their
own projects.
We grouped the 19 inclusivity bugs from Projects F & J
into 9 categories for cross validation purposes (Table VIII,
which will be discussed further in Section V) through three
rounds of negotiated agreement [41] among four researchers.
Validating the GenderMag sessions we conducted against
those of Projects F & J, 69% of the inclusivity bugs from the
sessions we conducted matched the inclusivity bug categories
of Projects F & J. Validating in the other direction, 79% of
the inclusivity bugs from Projects F & J‚Äôs GenderMag sessions
matched the inclusivity bugs in the sessions we conducted.
3) Cross-validation of Tool Results: Finally, we cross-
validated each individual inclusivity bug that AID identiÔ¨Åed
for all 20 projects against the inclusivity bugs manually iden-
tiÔ¨Åed in GenderMag sessions on all 20 projects. The results
of this cross-validation are in Section V.
C. Model: Decision rules
To create the decision rules driving AID, the Ô¨Årst and
second authors analyzed the GenderMag data from the 20
projects (F & J + 18 GenderMag‚Äôed by the research team).
They analyzed each inclusivity bug and the ‚Äúwhys‚Äù behind it,
as well as the UI. Through inductive reasoning they abstracted
the ‚Äúwhys‚Äù into a set of 11 decision rules. Then through
three rounds of negotiated agreement they reÔ¨Åned and merged
similar rules to create the Ô¨Ånal set of Ô¨Åve distinct rules, which
form the foundation of AID.
AID attempts to emulate a ‚Äúreal‚Äù GenderMag session by
taking as input a spreadsheet that lists the data that humans
would use when performing a GenderMag session. The Ô¨Årst
three columns are the use-case, subgoal, and action inputs, and
the fourth column is the webpage URL for that step in the
CW. (Section II details a GenderMag session process.) Figure
4 displays the overview of AID‚Äôs architecture and Figure 3
shows an example of an input sent to AID for the use-case
‚ÄúFile an issue‚Äù.
From this input, AID extracts the sentence structure from
the text in the subgoal and action. It does so through a com-
bination of Natural Language Processing (NLP) techniques,
such as lexical analysis [42], part-of-speech tagging [43] and
dependency parsing [44]. Overall, AID uses Python 3.7.4 and
associated libraries (spaCy, BeautifulSoup, gensim, xlrd) to
implement the decision rules. The code is available at [26].
The implementation details of each rule are discussed next.
1) Cues to needed information: The Ô¨Årst rule in our set
checks for situations where OSS‚Äôers like Abi would not Ô¨Ånd
all the information they need to complete their task. For
1427TABLE III
CHARACTERISTICS OF THE 18PROJECTS THAT RESEARCHERS EVALUATED USING GENDER MAG
Name Programming Language LOC # Contributors Age Domain
imathis/octopress Ruby 3,734 118 11 application software
chaplinjs/chaplin CoffeeScript 13,390 82 8 web libraries and frameworks
antirez/disque C 68,192 54 5 non-web libraries and frameworks
sahat/satellizer TypeScript 101,984 129 6 web libraries and frameworksLogarithmic
Growth
winjs/winjs JavaScipt 252,912 40 6 web libraries and frameworks
ionic-team/ionic-framework TypeScript 193,047 385 7 non-web libraries and frameworks
scalaz/scalaz Scala 47,027 184 10 non-web libraries and frameworks
donnemartin/system-design-primer Python 10,382 103 3 web libraries and frameworks
synrc/n2o Erlang 5,199 60 7 system software
tmux/tmux C 58,833 5 5 application softwareExponential
Growth
sbt/sbt Scala 78,067 229 11 software tools
ubernetes/kubernetes Go 4,199,364 2,781 6 software tools
rails/rails Ruby 347,581 4,253 5 software tools
symfony/symfony PHP 803,528 2,153 10 web libraries and frameworks
deÔ¨Ånitelytyped/deÔ¨Ånitelytyped TypeScript 2,586,278 11,763 8 documentation
alpaca-lang/alpaca Erlang 13,513 16 4 software toolsLinear
Growth
libuv/libuv C 72,501 395 7 system software
TABLE IV
USE-CASES USED FOR GENDER MAG EVALUATIONS
# Use-case
UC1: Use-case 1 Find an issue to work on
UC2: Use-case 2 File an issue
UC3: Use-case 3 Make a documentation contribution
Fig. 5. AID‚Äôs approach for capturing inclusivity bugs (Rule 1)
example, the wording of the subgoal serves as the information
that Abi seeks, and the words from actions serve as cues to
direct Abi to a UI action. Without such cues, Abi would face
difÔ¨Åculty Ô¨Ånding all the information they need. For example,
for Project4 , UC1 (Find an issue to work on), S1 (Find
the issue list)‚Äôs A ction1 , the human team reported, Project4-
UC1S1A1: ‚Äú There‚Äôs nothing about the ‚Äòissue list‚Äô. ‚ÄòIssue‚Äô is
mentioned in one of the sections but in a different context ‚Äù.
Rule 1 captures this using the model shown in Figure 5.



	Rule 1: Keywords from subgoals and associated actions
should be present on the webpage.
To check if the webpage includes the words from a subgoal
and action sequence, AID extracts lexical features, including
the Part-of-Speech (POS) tag of each word using spaCy [45].It then adds the nouns and adjectives from the POS to a
list of ‚Äúkeywords‚Äù that it searches for in the webpage. For
example, in the third row of Table V, Abi‚Äôs subgoal (S2) is to
‚ÄúFile a new bug report issue‚Äù and the associated action (A1)
is: ‚ÄúClick on the tracker link‚Äù. AID parses these sentences to
add [‚Äúnew‚Äù, ‚Äúbug‚Äù, ‚Äúreport‚Äù, ‚Äúissue‚Äù] and [‚Äútracker‚Äù, ‚Äúlink‚Äù]
to the list of keywords.
The tool does not include verbs (e.g., ‚Äúclick‚Äù), since these
are usually commands to a human, not labels or content-
oriented keywords. We also exclude DOM words (e.g., link,
header, footer, etc.) and words like ‚Äúinformation‚Äù and ‚Äúdata‚Äù
from the list of keywords because these words can have overly
broad interpretations.
The next step is to look for these keywords in the webpage.
Our initial approach performed a simple string search. How-
ever, this resulted in keyword matches that were on parts of
the webpage that were irrelevant for the speciÔ¨Åc subgoal.
Thus, to detect relevant information to the speciÔ¨Åc subgoal
and action under evaluation, we retrieve all the sentences on
the webpage that contain any of the keywords. Then we use
dependency parsing [44] to extract the relationship between
the words in each sentence as shown in Figure 6. The term
subtree refers to smaller syntactic units within these sentences.
AID then navigates the dependency parse tree (as shown in
Figure 6) by extracting the subtree of each of the keywords in
them. If one keyword is found in another keyword‚Äôs subtree, it
shows a syntactic relationship between them and is considered
relevant to the subgoal or action.
For example, Figure 6 shows the tree structure from a sen-
tence in the webpage of Project-6: ‚ÄúBefore submitting a pull
request, we ask that you please create an issue that explains
the bug or feature request‚Äù. This results in a dependency parse
tree with ‚Äúask‚Äù as the root. We check the subtree of ‚Äúissue‚Äù
and see that ‚Äúbug‚Äù (another keyword) is in the list of elements
of the tree. Therefore, AID determines that this sentence is
indeed about issues that are bugs and does not report an
inclusivity bug when evaluating the action (A1) for subgoal
(S2) in Table V.
1428TABLE V
EXAMPLE OF INPUT TO AID
Use-Case Subgoal Action URL
UC2: File an issue S1:Find information about Ô¨Åling an issue A1-Q#1: Click on reporting a bug symfon y.com/doc/current/contributing/code/index.html
UC2: File an issue S1:Find information about Ô¨Åling an issue A1-Q#2: Click on reporting a bug symfon y.com/doc/current/contributing/code/bugs.html
UC2: File an issue S2:File a new bug report issue A1-Q#1: Click on the tracker link symfon y.com/doc/current/contributing/code/bugs.html
UC2: File an issue S2:File a new bug report issue A1-Q#2: Click on the tracker link github .com/symfony/symfony/issues
Fig. 6. The dependency parse tree for the sentence ‚Äú Before submitting a
pull request, we ask that you please create an issue that explains the bug or
feature request. ‚Äù The dashed blue border encompasses all the elements in the
subtree of the keyword ‚Äúissue‚Äù. The keywords ‚Äúissue‚Äù and ‚Äúbug‚Äù are bordered
in green.
2) Situating Abi in the context of the action performed:
On clicking a link, the destination page should offer cues to
help Abi‚Äôs understand that they have reached the right place.
If a project page fails to use words similar to what a link label
hinted at, OSS‚Äôers like Abi could get confused. For example,
when the team clicked on a link labeled ‚ÄúHow to Ô¨Åle an issue‚Äù
but didn‚Äôt Ô¨Ånd relevant information on the resulting page, their
inclusivity bug report said: Project1-UC2S1A3: ‚Äú The link takes
to a page that does not really mention how to Ô¨Åle issues which
is what the link said. Abi might not think that this is where
she wanted to go. ‚Äù
This team‚Äôs observation echoes others‚Äô recommendations
that words in a link‚Äôs label should be prominent on the link‚Äôs
destination page [46], leading to our second rule:



	Rule 2:Linked pages should contain keywords from link
labels.
AID checks for Rule 2 for linked pages and thus, the pages
that are an input to Action Question #2 (e.g., .../issues in
S2:A1-Q#2 in Table V). But since it evaluates each page
independently (it is agnostic of past CW steps) it needs to
identify the link in the previous step that brought the OSS‚Äôer
to this page. Therefore, it analyzes the webpage that was an
input to the previous CW step (S2A1-Q#1, .../bugs.html). It
also parses the text of S2A1-Q#1 and using the same parsing
technique explained above extracts the nouns to create a list
of keywords (‚Äútracker‚Äù is the only noun in our example).
Next it extracts all the link labels in this page (S2A1-Q#1,
.../bugs.html) that match the nouns (‚Äútracker‚Äù). Note: this a
step to remove nouns from (sometimes wordy) action text
that do not match the link label. AID then searches for the
Fig. 7. AID‚Äôs approach for capturing inclusivity bugs (Rule 2)
Fig. 8. AID‚Äôs approach for capturing inclusivity bugs (Rule 3)
keywords in the linked page (i.e., S2A1-Q#2, .../issues). If
it cannot Ô¨Ånd that keyword anywhere in the page it reports
an inclusivity bug. Figure 7 details the steps in which AID
captures inclusivity bugs arising due to a Rule 2 violation.
3) Information link navigation: OSS‚Äôers like Abi click on
a link only after gathering enough information and planning
their next step. Labeled links provide Abi with information
about the webpage they are supposed to visit. As a team
reported for Project15-UC1S1A1: ‚Äú It [link] doesn‚Äôt talk about
issue lists and there are a lot of links which don‚Äôt say where
they lead to. ‚Äù The team felt that Abi would not know which
link to navigate to since all the links in the page had non-
descriptive labels.
Other work agrees, recommending that links should have
descriptive yet unique link labels and begin with keywords
[47]. Rule 3 captures this tenet.


Rule 3:Links should be labeled with a keyword or phrase.
1429AID checks if links on the page it is evaluating are labeled
with a keyword or phrase. To extract the link labels, we wrote
a custom web scraper using BeautifulSoup [48]. AID then
checks the link labels and reports a bug if the URL of the link
is the same as its label, as shown in Figure 8.
4) Cues about ‚Äúissue‚Äù characteristics: Our fourth and Ô¨Åfth
rules focused on issues in GitHub. Past research has reported
that Ô¨Ånding a task to work on is especially difÔ¨Åcult for some
OSS‚Äôers, such as newcomers [49] and mentors [50]. To address
this problem, GitHub recommends using issue labels and
provides a set of default labels (e.g., ‚Äúbugs‚Äù, ‚Äúdocumentation‚Äù,
‚Äúgood Ô¨Årst issue‚Äù). Figure 10 shows examples of issue labels.
When OSS‚Äôers like Abi come to the issue page they look for
cues from the issue labels to gather information about the task
(e.g., the type of task, which part of the codebase are related
to the issue, what skills are needed). When issues are not
labeled they can get discouraged. As pointed out for Project7-
UC1S3A1: ‚Äú Neither issue seems to be...very clearly labeled.
So because of her info processing style, Abi might not be able
to gather enough information about the issues listed and give
up‚Äù. This leads to our fourth rule (see Figure 9).

 
Rule 4: Issues should have labels.
AID checks for labels on open issues and reports a bug if the
issues are unlabeled. It checks for labels for the Ô¨Årst 25 open
issues1, which it extracts using the GitHub API.
However, simply having labeled issues might not be sufÔ¨Å-
cient. The Cognitive Walkthrough at the core of GenderMag is
about learnability to a Ô¨Årst-time user‚Äîi.e., an OSS newcomer
in this domain. Thus, the humans‚Äô GenderMag sessions re-
ported issues relating to newcomers, such as:
Project6-UC1S3A1: ‚ÄúThe issues are well labeled, but there is
no sign as to what would be a good one for a Ô¨Årst timer like
Abi, she might feel unsure and not choose one. ‚Äù



	Rule 5: Issues should have newcomer-friendly labels
(when appropriate).
Rule-5 evaluates the issue label text to check if
it is newcomer-friendly by string-matching against the
list of newcomer-friendly labels in ‚ÄúMunGell/awesome-for-
beginners‚Äù GitHub repository [51]. This list is curated from
187 projects in 22 programming languages.
We implemented this set of decision rules with some
trepidation. They are text-processing rules done statically, and
derived from GenderMag sessions of a relatively small set of
projects. Would such rules be able to Ô¨Ånd the same kinds of
inclusivity bugs in arbitrary OSS pages that humans bring to
GenderMag sessions by stepping into the shoes of a persona?
V. AID‚Äô SEFFECTIVENESS
We ran AID on the 20 projects described above which
produced 353 inclusivity bugs. Compared with the inclusivity
bugs identiÔ¨Åed by the humans who had conducted GenderMag
sessions manually on the same projects and use-cases, AID‚Äôs
1GitHub shows 25 issues per page and an OSS‚Äôer newcomer like Abi is
unlikely to look further if she doesn‚Äôt see any cues for her task.
Fig. 9. AID‚Äôs approach for capturing inclusivity bugs (Rule 4 & 5)
Fig. 10. Example of an inclusivity bug due to Rule 5 violation : Issue labels
are not newcomer-friendly
precision was 0.69, recall was 0.92, and F-measure was 0.79.
Table VI details precision, recall, and F-measures.
A. Precision: A closer look at false positives
AID disagreed with the human evaluators in 110 of the
353 inclusivity bugs it reported. Since false positives play a
critical role in developers‚Äô dissatisfaction with current tools
[52], AID‚Äôs precision, a measure of false positive rate, could
be critical to its acceptance. In this section, we consider which
of these 110 ‚Äúextra‚Äù inclusivity bugs‚Äîi.e., those the tool found
but the humans did not‚Äîreally were false positives, and why.
AID indeed produced false positives for three reasons:
(1) its use of static analysis instead of dynamic analysis, (2) its
reliance solely on the HTML of the webpage, and (3) its
semantic limitations. There were 49 of these false positives
(45% of the total extra inclusivity bugs).
TABLE VI
AID‚Äô SPRECISION , RECALL AND F-MEASURE ,WITH HUMAN
GENDER MAG SESSIONS AS THE GOLD STANDARD (SECTION IV-B).
Precision Recall F-measure
Rule 1 0.64 0.89 0.74
Rule 2 0.75 1.00 0.86
Rule 3 0.70 1.00 0.83
Rule 4 0.74 1.00 0.85
Rule 5 0.53 1.00 0.69
Overall 0.69 0.92 0.79
1430TABLE VII
61INCLUSIVITY BUGS WHERE AID WAS CORRECT AND THE HUMAN
TEAMS WERE INCORRECT .
Category of Evidence # Example
Internal (Team activities):
Team mentioned the bug later 27Noinformation about contributions on the README Ô¨Åle.
AID reported this bug earlier than a team did,
but the team found the bug in the next step.
Team didn‚Äôt mention the bug,
but they Ô¨Åxed it later3Unlabelled issues on an issue list. Team didn‚Äôt report it,
but we could see from the post-Ô¨Åx project version
they had Ô¨Åxed it.
Team mentioned the bug earlier
but not here20Tool reported a bug every time it found it, but teams did
notbother to repeat.
External (Nielsen‚Äôs) 11Unlabelled web link was not in the direct path a team was
evaluating.
Static Analysis: Analyzing an action like ‚ÄúMake a change
to the Readme.md‚Äù requires (human) input during the session‚Äôs
walkthrough, and that human input affects what gets displayed
next during the walkthrough. Because AID uses solely static
analysis of the webpage HTML, it cannot take user inputs
like the above into account, which can generate false positives.
Addressing this type of false positive would require some way
of gathering user input data, either ‚Äúon the spot‚Äù or from
a corpus of user inputs to this question. There were three
instances of this type of false positives.
Reliance on text content/labels: AID does not currently
do image analysis. For example, for the action ‚Äúclick on
pencil icon‚Äù on the Readme page, AID looks for keywords
‚Äúpencil‚Äù and ‚Äúicon‚Äù. If the image Ô¨Ålename for the pencil
icon is something like word ‚Äúpencil‚Äù or ‚Äúicon‚Äù (e.g., <IMG
src=‚ÄúIcons/pencil.png‚Äù >), AID would realize that it relates
to the action; otherwise it does not. In contrast, the human
evaluators easily recognized the icon from its appearance on
their screen. Addressing this type of false positive would
require adding some form of image processing. There were
15 false positives of this type.
English semantics: AID does not currently address un-
derlying semantics of English language usage. For example,
‚ÄúFind something to work on‚Äù would translate to ‚ÄúÔ¨Ånd an issue
to work on‚Äù for many OSS‚Äôers, but the tool does not know this.
Some of AID‚Äôs semantic limitations could be improved though
the use of synonym dictionaries or methods for detecting
term similarity like Latent-Semantic Indexing or TF-IDF [53],
[54]; others would require semantic analyses accounting for
antecedents, referents, and/or context [55]. There were 31 false
positives from the tool‚Äôs semantic limitations.
AID was actually right . The remaining 61 of the 110
‚Äúextra‚Äù inclusivity bugs were not false positives. Rather, the
tool was correct in the three categories: (1) evaluator false
negatives, (2) repetitions of the same inclusivity bug, and
(3) the tool going ‚Äúbeyond the call of duty‚Äù to Ô¨Ånd things it
didn‚Äôt need to Ô¨Ånd. Table VII summarizes them. We identiÔ¨Åed
the instances where AID was correct in the following manner.
First, we looked at every bug AID found that the GenderMag
teams did not. When evidence existed that AID was ‚Äúright‚Äù,
we associated the evidence with the instances of those bugs,
as discussed next.
As Mahotody et al.‚Äôs survey of Cognitive Walkthroughs
shows, although humans performing methods in the CW-
family report few false positives (10% or below across numer-ous studies), their propensity for false negatives has run as high
as 70% false negative rates [25], in which the humans simply
miss seeing some of the problems. Likewise with GenderMag,
although humans‚Äô false positive rates are well below 10% [3],
[7], human GenderMag users tend to miss some inclusivity
bugs. The human evaluators in this investigation were also
subject to this phenomenon. In 27 instances (see Table VII,
Row2), the tool Ô¨Çagged a bug that the team missed, but the
team mentioned the bug later in subsequent steps of their
GenderMag sessions.
In another three inclusivity bugs that AID found, the
Project-F team didn‚Äôt mention the bug, but they Ô¨Åxed it later
as part of their overall changes (see Table VII, Row3). This
suggests that the Project-F team eventually realized that it was
problematic. From this we conclude that tool was right in
identifying these three bugs. Thus, the total of human-tool
team differences due to humans‚Äô false negatives was 30.
There were 20 instances where AID identiÔ¨Åed bugs that
humans did not report because of repetitions. AID does not
realize when it reports the same bug more than once, such as
if the same bug arises in more than one step of a use-case. In
contrast, humans do realize it, and sometimes do not bother to
report the same inclusivity bug if it occurs a second time. In 20
such cases, the team mentioned the bug earlier, but not here
(see Table VII, Row4). These repetitions can be potentially
annoying, but they are not false positives.
Finally, sometimes AID reported inclusivity bugs that were
unlabeled links in locations not directly in the direct path
of the use-case (see Table VII, Row5). There would have
been no reason for the human teams to Ô¨Ånd these inclusivity
bugs if they strictly followed the use-cases. Still, that does
not mean that such bugs were false positives. We argue they
were true positives: that unlabeled links can be inclusivity
bugs for comprehensive information processors like Abi, who
want to Ô¨Ånd all the relevant information. Without a clear label,
Abi‚Äôs would be unable to predict whether information might
lie behind the link. This may be why the Nielsen/Norman
group emphasizes the need for links to use descriptive anchor
text that uses keywords to facilitate information processing
[47]. The tool‚Äôs ‚Äúbeyond the call of duty‚Äù to relax the strict
boundaries of the use-case sequence resulted in 11 of these
inclusivity bugs that the human teams did not Ô¨Ånd.
B. Recall: A closer look at false negatives
AID‚Äôs recall rate was extremely high, with a total recall of
0.92. In Rules 2-5, AID‚Äôs recall was a perfect 1.0, perhaps
because these rules implement straightforward string compar-
isons. The tool noticed all instances of rules like these, so
whenever the humans noticed it, AID would too.
The tool‚Äôs recall gaps all came from Rule 1, which produced
20 false negatives. All of these came from the tool‚Äôs treatment
of subgoals‚Äô and actions‚Äô use of verbs. We decided that, when
a word was being used as a verb (e.g., ‚Äúclick‚Äù in ‚Äúclick on
reporting a bug‚Äù in UC2S1A1, Table V) the tool would not
treat them as keywords to be searched for in the webpage.
1431TABLE VIII
TRIANGULATION OF BUGS FOUND BY TEAMS F & J, THE 18
GENDER MAGS WE CONDUCTED ,AND AID. O VER 70% OF THE
HUMAN -REPORTED BUGS HUMAN FELL INTO F & J‚Äô S ORIGINAL 9
CATEGORIES . AID FOUND 74% OF THE BUGS THE HUMANS FOUND .
Inclusi vity Bugs F J 18Projects AID
Notenough information: page X 38 32
README: Unclear path to the
readmeX X 17 17
README: no info about subgoal X 39 33
Lacks understanding of OSS terms:
can‚Äôt match to subgoalXX 5 5
Template: Pull request:
notenough instructionsXX 1 1
Template: Filing an issue: not enough
instructionsX X 23 2
Notenough information: to choose
optionsX XX 12 11
Notenough information: to take
actionXXXX 17 15
ISSUES in issue list: not enough
information for users to pick a taskX X 26 17
Other 79 70
Total 12 7 257 203
However, in the subgoal (S1): ‚ÄúFind information about how
to Ô¨Åle an issue‚Äù, the verb ‚ÄúÔ¨Åle‚Äù describes the process of
reporting an issue. Thus, although the tool did not consider
the word ‚ÄúÔ¨Åle‚Äù to be worth looking for here, the human teams
in their sessions did look for information about the process of
Ô¨Åling an issue on the project page: Project3-UC2S1A1‚Äú ...there
is nothing that says [about] Ô¨Åle a new issue so Abi might feel
some uncertainty with her action. ‚Äù This issue accounted for
all 20 of AID‚Äôs false negatives.
C. Results Triangulation
Table VIII shows the inclusivity bugs reported by all sources
in the categories of bugs the humans found, triangulated
among Project F, Project J, the 18 sessions we conducted, and
AID. Each bug category occupies a row of the table. (The table
does not include the bugs that AID found that the humans did
not.) AID‚Äôs low performance on Template bugs was due to its
static-only analysis, as discussed earlier. Every category of bug
was cross-validated by at least three of these four sources and,
as the table shows, AID found 74% (203/(12+7+257)) of the
bugs the humans reported.
VI. T HREATS TO VALIDITY
This section presents the different threats to validity and
how we mitigated them.
First, two teams of researchers manually identiÔ¨Åed the
inclusivity bugs using the GenderMag method, so subjectivity
of the data can be considered a threat to validity. To minimize
this threat, we calculated the inter-rater reliability among the
two teams and also validated our data against inclusivity bugs
found by two external OSS teams (F & J) using GenderMag.
The second threat to validity of our tool lies in the 110
disagreements between AID‚Äôs Ô¨Åndings and human evaluators‚Äô
Ô¨Åndings. In order to mitigate that, we further analyzed these
disagreements to understand their origin. We found different
types of disagreements, some were linked to the limited scope
of our tool (when the tool was wrong), others (where the toolwas more comprehensive than a human evaluator) originated
from humans not capturing all possible inclusivity issues.
The Ô¨Ånal threat is the generalizability of AID in its current
scope. AID can be applied to any OSS project in GitHub
(28 million public repos) and other hosting sites (Gitlab,
bitbucket). As a Ô¨Årst step, AID focused on OSS Projects
hosted on GitHub, thus, the applicability of our tool might not
generalize to other version control platforms or other non-OSS
technology. However, some of AID‚Äôs rules (e.g., Rule1) can
be applied on any web app or webpage. AID also currently
automates only a vertical slice of GenderMag, with the Abi
persona and their speciÔ¨Åc information processing style. This
scoping allowed us to investigate AID‚Äôs feasibility and effec-
tiveness under stricter controls, but impacts its generalizability.
Most of these threats can be mitigated by (1) future work
that addresses the limitations of the tool; (2) extending AID to
also evaluate for Abi‚Äôs other cognitive facets, and to the other
GenderMag personas (Pat, Tim); and (3) expanding the scope
of software upon which AID runs beyond OSS platforms.
VII. R ELATED WORK
The nearest neighbours of the GenderMag method are
the Williams recommendations and InclusiveMag. Williams
pointed out several ways gender-inclusivity bugs can arise,
such as hidden gender bias during the product cycle and
women being reluctant to voice their opinions when they are
outnumbered in a brainstorming session [16], [56]. Williams
also offers concrete recommendations to head off such causal
factors, such as assembling groups of at least 60% women
during brainstorming sessions and having an equal vote distri-
bution by gender when using informal voting systems [16].
InclusiveMag [17] is a meta-method that spawns methods
like GenderMag, for under-served software users. It provides
a step-by-step approach for researchers and practitioners to
generate methods to evaluate their software. However, neither
of these methods have been automated.
GenderMag is a member of the Cognitive Walkthrough
family. Mahatody et al.‚Äôs [25] comprehensive literature survey
of CWs describes many CW variations, some of which focus
on reducing problems with the classic CW [57]‚Äì[59] such as
by reducing the time it requires. Nielsen et al. recommended
that a note-taking tool for CWs to address issues like these
by guiding the analyst through each CW step, in order to
avoid missing steps and to more accurately record results,
integrating a CW tool into a prototyping tool [60]. When
CWs were Ô¨Årst introduced, Rieman et al. created a tool to
record the results of a human-run CW [61]. The GenderMag
Recorder‚Äôs Assistant [62] is a recent note-taking tool to help
humans organize GenderMag session output‚Äîtheir answers to
the CW questions, additional notes and screenshots pertinent
to each question. These tools are for supporting humans doing
a CW and not the automation of the method itself.
Farther aÔ¨Åeld, there is a variety of work relating to au-
tomation of usability evaluation. For example, Mathur et al.
introduced a ‚ÄúUsability Evaluation Framework‚Äù [63], a model
to automate usability evaluation for mobile apps based on
1432prevailing usability guidelines. Baker et al. created a prototype
to automate usability testing for handheld devices [64]. It
measures software usability by recording user actions and
compares the user‚Äôs actions to those expected by the developer.
The WebTANGO prototype [65] predicts user‚Äôs information
seeking behaviour and webpage navigations, calculating fac-
tors like the time for a user to scan a page, based on its
complexity. Dingli et al. proposed a framework and tool that
evaluates websites by considering usability guidelines [66].
However, tools like these do not evaluate inclusivity.
Various tools exist to help with accessible design. WA VE
[67] is a tool for evaluating accessibility principles. It indicates
if information on a webpage is accessible by visually impaired
people by checking for alternative text, structural markup, and
reading order. Additionally, it Ô¨Çags audio content for the deaf
population. Vischeck [68] is a tool for low-vision simulation,
which uses image processing techniques to create views for
low-vision users. AATT [69] provides an accessibility API to
test web applications for conformance to the Web Content
Accessibility Guidelines (WCAG). Even though these tools
assist in the implementation for more inclusive products, they
do not consider cognitive diversity.
Closest to our work is the AutoCWW [70], a tool that au-
tomates the CW to identify website navigation problems [71].
It takes a goal from the user along with a list of webpages the
user is supposed to navigate. It then computes the similarity
of the goal text with the headings and link labels of the input
pages, to see if a user who wanted to Ô¨Ånd the right link could
navigate to the correct webpage. AutoCWW only evaluates
webpages with respect to the overall use-case while AID has a
more Ô¨Åne-grained task oriented approach. AutoCWW assumes
a ‚Äúgeneric‚Äù user and not inclusivity of diverse users. For
example, it does not take into account different styles of pro-
cessing information such as Abi‚Äôs comprehensive information
processing style. GitHub OSS‚Äôers with this style are unlikely
to just click on potentially suitable links until after gathering
enough information to understand what is available and how
they might like to proceed through it. In contrast, AID checks
if a user like Abi (and, in future versions, like Tim or like Pat)
would gather the ‚Äúright amount‚Äù of information to navigate in
the needed direction for their current actions.
VIII. C ONCLUDING REMARKS
The effectiveness that AID showed at automatically detect-
ing these 20 OSS project sites‚Äô inclusivity bugs is promising.
As we have pointed out, the Ô¨Åve rules at the core of our
model used static, text-processing techniques. Despite this fact,
even under the conservative assumption that humans were
the ‚Äúgold standard‚Äù, AID achieved a precision rate of 0.69.
Further, closer scrutiny revealed that more than half of its
false positives under this assumption were not actually false
positives (Table VI). Further, its recall rate of 0.92 is better
than most recall rates by human users of the CW family [25].
How could the tool have done so well? Researchers have
reported the heavy workloads some humans experience using
GenderMag [72]. Part of their workload is trying to ‚Äúbecome‚Äùsomeone else (here, one of the GenderMag personas), which
some humans have difÔ¨Åculty doing (e.g., [35]). Yet, the tool
did remarkably well with static text analysis, without even
attempting to model the persona.
We hypothesize that the reason for AID‚Äôs success lies in the
concrete, pattern-based approach we used to develop the rules.
When humans use GenderMag, they work from the root of
inclusivity bugs‚Äîproblem-solving style diversity. In contrast,
in developing the rules, we worked from patterns of symptoms
of the problems the human teams found, and encoding them
in rules. Our results suggest that the concrete, pattern-based
approach we used is promising.
A goal of this work was to Ô¨Ånd out whether it was possible
for a software tool to automatically detect inclusivity bugs. As
our results with AID show, such a tool is both possible and
feasible to implement.
Despite its concrete rules, AID is rooted in theory, inherited
from the foundations of GenderMag. As Shaw and others have
argued, scientiÔ¨Åc theory lets technological development pass
limits previously imposed by relying on intuition and experi-
ence [73]. For example, Shaw points out, for centuries, many
architectural structures (buildings, bridges, tunnels, canals)
could be built only by master craftsmen. Not until scientists
developed theories of statics and strength of materials, were
today‚Äôs extraordinary engineering accomplishments possible,
such as the Hong Kong‚ÄìZhuhai‚ÄìMacau Bridge spanning 55
miles of ocean, by ‚Äúordinary‚Äù engineers. In computer science
we see the same phenomenon. For example, expert developers
once built compilers using only hard-won intuitions gained
from extensive experience, but formal language theory has
brought tasks like parser and compiler writing to a level where
undergraduate computer science students now routinely build
them in their coursework [74]. AID follows this path through
its theory foundations, as a step toward enabling ‚Äúordinary‚Äù
developers to Ô¨Ånd inclusivity bugs without needing to become
experts in GenderMag.
Our survey‚Äôs results suggest that tools like this are needed:
92% of our respondents lacked any speciÔ¨Åc tools or ap-
proaches they could use to check for inclusivity bugs.
P115: ‚ÄúI wasn‚Äôt aware of methods, but I try to get feedback
from and build for a diverse set of users. ‚Äù
P156: ‚ÄúI can make mistakes ...[but] I strive to not do evil. ‚Äù
IX. A CKNOWLEDGEMENTS
We thank our survey participants and Teams F & J. This
work is partially supported by the National Science Foundation
under Grant numbers 1815486, 1901031 and 21-0045.
REFERENCES
[1] M. M. Burnett, L. Beckwith, S. Wiedenbeck, S. D. Fleming, J. Cao,
T. H. Park, V . Grigoreanu, and K. Rector, ‚ÄúGender pluralism in problem-
solving software,‚Äù Interacting with computers , vol. 23, no. 5, pp. 450‚Äì
460, 2011.
[2] L. Beckwith, C. Kissinger, M. Burnett, S. Wiedenbeck, J. Lawrance,
A. Blackwell, and C. Cook, ‚ÄúTinkering and gender in end-user pro-
grammers‚Äô debugging,‚Äù in Proceedings of the SIGCHI conference on
Human Factors in computing systems , 2006, pp. 231‚Äì240.
1433[3] M. Burnett, S. Stumpf, J. Macbeth, S. Makri, L. Beckwith, I. Kwan,
A. Peters, and W. Jernigan, ‚ÄúGendermag: A method for evaluating
software‚Äôs gender inclusiveness,‚Äù Interacting with Computers , vol. 28,
no. 6, pp. 760‚Äì787, 2016.
[4] M. Burnett, R. Counts, R. Lawrence, and H. Hanson, ‚ÄúGender hcl and
microsoft: Highlights from a longitudinal study,‚Äù in 2017 IEEE Sympo-
sium on Visual Languages and Human-Centric Computing (VL/HCC) .
IEEE, 2017, pp. 139‚Äì143.
[5] M. Burnett, S. D. Fleming, S. Iqbal, G. Venolia, V . Rajaram, U. Farooq,
V . Grigoreanu, and M. Czerwinski, ‚ÄúGender differences and program-
ming environments: across programming populations,‚Äù in Proceedings
of the 2010 ACM-IEEE international symposium on empirical software
engineering and measurement , 2010, pp. 1‚Äì10.
[6] D. Showkat and C. Grimm, ‚ÄúIdentifying gender differences in in-
formation processing style, self-efÔ¨Åcacy, and tinkering for robot tele-
operation,‚Äù in 2018 15th International Conference on Ubiquitous Robots
(UR) . IEEE, 2018, pp. 443‚Äì448.
[7] M. V orvoreanu, L. Zhang, Y .-H. Huang, C. Hilderbrand, Z. Steine-
Hanson, and M. Burnett, ‚ÄúFrom gender biases to gender-inclusive
design: An empirical investigation,‚Äù in Proceedings of the 2019 CHI
Conference on Human Factors in Computing Systems , 2019, pp. 1‚Äì14.
[8] R. Tatman, ‚ÄúGender and dialect bias in YouTube‚Äôs automatic
captions,‚Äù in Proceedings of the First ACL Workshop on Ethics
in Natural Language Processing . Valencia, Spain: Association for
Computational Linguistics, Apr. 2017, pp. 53‚Äì59. [Online]. Available:
https://www.aclweb.org/anthology/W17-1606
[9] C. P ¬¥erez and L. S ¬¥aenz, ‚ÄúGender-inclusive language in games and
its localization challenges,‚Äù https://medium.com/@keywordsstudios/
gender n-inclusive n-language n-inn-games n-andn-itsn-localization n
-challenges n-e132fde36b76, 2019, accessed: 2020-08-27.
[10] S. Stumpf, A. Peters, S. Bardzell, M. Burnett, D. Busse, J. Cauchard,
and E. Churchill, ‚ÄúGender-inclusive hci research and design: A concep-
tual review,‚Äù Foundations and Trends in Human-Computer Interaction ,
vol. 13, no. 1, pp. 1‚Äì69, 2020.
[11] X. Kondrat, ‚ÄúGender and video games: How is female gender generally
represented in various genres of video games?‚Äù Journal of Comparative
Research in Anthropology and Sociology , vol. 6, no. 01, pp. 171‚Äì193,
2015.
[12] I. A. Hamilton, ‚ÄúWhy it‚Äôs totally unsurprising that amazon‚Äôs recruitment
ai was biased against women,‚Äù https://www.businessinsider.com/
amazon-ai-biased-against-women-no-surprise-sandra-wachter-2018-10,
2018, accessed: 2020-08-27.
[13] M. Kay, C. Matuszek, and S. A. Munson, ‚ÄúUnequal representation
and gender stereotypes in image search results for occupations,‚Äù in
Proceedings of the ACM Conference on Human Factors in Computing
Systems , 2015, pp. 3819‚Äì3828.
[14] M. Burnett, A. Peters, C. Hill, and N. Elarief, ‚ÄúFinding gender-
inclusiveness software issues with gendermag: a Ô¨Åeld investigation,‚Äù
inProceedings of the 2016 CHI Conference on Human Factors in
Computing Systems , 2016, pp. 2586‚Äì2598.
[15] S. H. Padala, C. J. Mendez, L. F. Dias, I. Steinmacher, Z. S. Hanson,
C. Hilderbrand, A. Horvath, C. Hill, L. Simpson, M. Burnett, M. Gerosa,
and A. Sarma, ‚ÄúHow gender-biased tools shape newcomer experiences
in oss projects,‚Äù IEEE Transactions on Software Engineering , 2020.
[16] G. Williams, ‚ÄúAre you sure your software is gender-neutral?‚Äù Interac-
tions , vol. 21, no. 1, pp. 36‚Äì39, 2014.
[17] C. Mendez, L. Letaw, M. Burnett, S. Stumpf, A. Sarma, and C. Hilder-
brand, ‚ÄúFrom gendermag to inclusivemag: An inclusive design meta-
method,‚Äù in IEEE Symposium on Visual Languages and Human-Centric
Computing (VL/HCC) . IEEE, 2019, pp. 97‚Äì106.
[18] S. J. Cunningham, A. Hinze, and D. M. Nichols, ‚ÄúSupporting gender-
neutral digital library creation: A case study using the gender-
mag toolkit,‚Äù in International Conference on Asian Digital Libraries .
Springer, 2016, pp. 45‚Äì50.
[19] A. Shekhar and N. Marsden, ‚ÄúCognitive walkthrough of a learning
management system with gendered personas,‚Äù in Conference on Gender
& IT . ACM, 2018, pp. 191‚Äì198.
[20] C. Hilderbrand, C. Perdriau, L. Letaw, J. Emard, Z. Steine-Hanson,
M. Burnett, and A. Sarma, ‚ÄúEngineering gender-inclusivity into soft-
ware: Ten teams‚Äô tales from the trenches,‚Äù in ACM/IEEE International
Conference on Software Engineering , 2020.
[21] C. Mendez, H. S. Padala, Z. Steine-Hanson, C. Hilderbrand, A. Horvath,
C. Hill, L. Simpson, N. Patil, A. Sarma, and M. Burnett, ‚ÄúOpen source
barriers to entry, revisited: A sociotechnical perspective,‚Äù in Proceedingsof the 40th International Conference on Software Engineering , 2018, pp.
1004‚Äì1015.
[22] M. Burnett, S. Stumpf, L. Beckwith, and A. Peters, ‚ÄúThe gendermag kit:
How to use the gendermag method to Ô¨Ånd inclusiveness issues through
a gender lens,‚Äù 2020.
[23] C. Gralha, M. Goulao, and J. Araujo, ‚ÄúAnalysing gender differences in
building social goal models: A quasi-experiment,‚Äù in IEEE International
Requirements Engineering Conference , ser. RE 2019, 2019.
[24] J. Meyers-Levy and B. Loken, ‚ÄúRevisiting gender differences: What we
know and what lies ahead,‚Äù Journal of Consumer Psychology , vol. 25,
no. 1, pp. 129‚Äì149, 2015.
[25] T. Mahatody, M. Sagar, and C. Kolski, ‚ÄúState of the art on the
cognitive walkthrough method, its variants and evolutions,‚Äù Intl. Journal
of Human‚ÄìComputer Interaction , vol. 26, no. 8, pp. 741‚Äì785, 2010.
[26] Anonymous, ‚ÄúAID: An automated inclusivity-bug detector,‚Äù Aug. 2020.
[Online]. Available: https://doi.org/10.5281/zenodo.4007579
[27] K. Blincoe, J. Sheoran, S. Goggins, E. Petakovic, and D. Damian,
‚ÄúUnderstanding the popular users: Following, afÔ¨Åliation inÔ¨Çuence and
leadership on github,‚Äù Information and Software Technology , vol. 70, 10
2015.
[28] G. user s0md3v. (2020) Zen Ô¨Ånd email addresses of github users.
[Online]. Available: https://https://github.com/s0md3v/Zen
[29] F. Medeiros, M. Ribeiro, R. Gheyi, S. Apel, C. K ¬®astner, B. Ferreira,
L. Carvalho, and B. Fonseca, ‚ÄúDiscipline matters: Refactoring of pre-
processor directives in the ifdef hell,‚Äù IEEE Transactions on Software
Engineering , vol. 44, no. 5, pp. 453‚Äì469, 2018.
[30] M. Burnett, S. D. Fleming, S. Iqbal, G. Venolia, V . Rajaram, U. Farooq,
V . Grigoreanu, and M. Czerwinski, ‚ÄúGender differences and program-
ming environments: across programming populations,‚Äù in Proceedings
of the 2010 ACM-IEEE International Symposium on Empirical Software
Engineering and Measurement , 2010, pp. 1‚Äì10.
[31] M. Burnett, ‚ÄúWomenomics and gender-inclusive software: What soft-
ware engineers need to know (invited talk),‚Äù in ACM SIGSOFT Inter-
national Symposium on Foundations of Software Engineering , 2016.
[32] R. Grey, ‚ÄúInclusive chromium code.‚Äù [Online].
Available: https://chromium.googlesource.com/chromium/src/+/master/
styleguide/inclusive code.md
[33] Google, ‚ÄúWriting inclusive documentation.‚Äù [Online]. Available:
https://developers.google.com/style/inclusive-documentation
[34] Deep Learning for Coders with fastai and PyTorch . O‚ÄôReilly, 2020.
[35] A. Oleson, C. Mendez, Z. Steine-Hanson, C. Hilderbrand, C. Perdriau,
M. Burnett, and A. J. Ko, ‚ÄúPedagogical content knowledge for teaching
inclusive design,‚Äù in Proceedings of the 2018 ACM Conference on
International Computing Education Research , 2018, pp. 69‚Äì77.
[36] M. H. Blackmon, P. G. Polson, C. Lewis et al. , ‚ÄúAutomated cognitive
walkthrough for the web (autocww),‚Äù in Workshop Date: April , vol. 21,
2002, p. 22.
[37] A. Bandura, Social Foundations of Thought and Action . Prentice Hall,
1986.
[38] F. Fronchetti, I. Wiese, G. Pinto, and I. Steinmacher, ‚ÄúWhat attracts
newcomers to onboard on oss projects? tl; dr: Popularity,‚Äù in IFIP
International Conference on Open Source Systems . Springer, 2019,
pp. 91‚Äì103.
[39] S. E. Stemler, ‚ÄúA comparison of consensus, consistency, and measure-
ment approaches to estimating interrater reliability,‚Äù Practical Assess-
ment, Research, and Evaluation , vol. 9, no. 1, p. 4, 2004.
[40] J. R. Landis and G. G. Koch, ‚ÄúThe measurement of observer agreement
for categorical data,‚Äù biometrics , pp. 159‚Äì174, 1977.
[41] D. R. Garrison, M. Cleveland-Innes, M. Koole, and J. Kappelman,
‚ÄúRevisiting methodological issues in transcript analysis: Negotiated
coding and reliability,‚Äù The Internet and Higher Education , vol. 9, no. 1,
pp. 1‚Äì8, 2006.
[42] J. Pustejovsky and B. Boguraev, ‚ÄúLexical knowledge representation and
natural language processing,‚Äù ArtiÔ¨Åcial Intelligence , vol. 63, no. 1-2, pp.
193‚Äì223, 1993.
[43] S. Abney, ‚ÄúPart-of-speech tagging and partial parsing,‚Äù in Corpus-based
methods in language and speech processing . Springer, 1997, pp. 118‚Äì
136.
[44] J. Nivre, ‚ÄúAn efÔ¨Åcient algorithm for projective dependency parsing,‚Äù
inProceedings of the Eighth International Conference on Parsing
Technologies , 2003, pp. 149‚Äì160.
[45] spaCy Natural Language Processing Library , 2015 (accessed April,
2020), https://spacy.io/.
1434[46] K. Pernice, A Link is a Promise , 2014 (accessed June, 2020), https:
//www.nngroup.com/articles/link-promise/.
[47] M. McCloskey, Writing Hyperlinks: Salient, Descriptive, Start with Key-
word , 2014 (accessed June, 2020), https://www.nngroup.com/articles/
writing-links/.
[48] L. Richardson, beautifulsoup 4 4.9.1 , 2006 (accessed April, 2020), https:
//pypi.org/project/beautifulsoup4/.
[49] I. Steinmacher, T. Conte, M. A. Gerosa, and D. Redmiles, ‚ÄúSocial
barriers faced by newcomers placing their Ô¨Årst contribution in
open source software projects,‚Äù in Proceedings of the 18th ACM
Conference on Computer Supported Cooperative Work Social
Computing , ser. CSCW ‚Äô15. New York, NY , USA: Association
for Computing Machinery, 2015, p. 1379‚Äì1392. [Online]. Available:
https://doi.org/10.1145/2675133.2675215
[50] S. Balali, U. Annamalai, H. S. Padala, B. Trinkenreich, M. A. Gerosa,
I. Steinmacher, and A. Sarma, ‚ÄúRecommending tasks to newcomers in
oss projects: How do mentors handle it?‚Äù
[51] ‚ÄúAwesome Ô¨Årst PR opportunities,‚Äù https://github.com/MunGell/
awesome-for-beginners, 2019, accessed: 2019-08-17.
[52] B. Johnson, Y . Song, E. Murphy-Hill, and R. Bowdidge, ‚ÄúWhy don‚Äôt
software developers use static analysis tools to Ô¨Ånd bugs?‚Äù in 2013 35th
International Conference on Software Engineering (ICSE) . IEEE, 2013,
pp. 672‚Äì681.
[53] S. T. Dumais et al. , ‚ÄúLatent semantic indexing (lsi) and trec-2,‚Äù Nist
Special Publication Sp , pp. 105‚Äì105, 1994.
[54] R. Baeza-Yates, B. Ribeiro-Neto et al. ,Modern information retrieval .
ACM press New York, 1999, vol. 463.
[55] J. Han, A. Sun, H. Zhang, C. Li, and S. Shi, ‚ÄúCase: Context-aware
semantic expansion.‚Äù in AAAI , 2020, pp. 7871‚Äì7878.
[56] C. F. KARPOWITZ, T. MENDELBERG, and L. SHAKER, ‚ÄúGender
inequality in deliberative participation,‚Äù American Political Science
Review , vol. 106, no. 3, p. 533‚Äì547, 2012.
[57] V . Grigoreanu and M. Mohanna, ‚ÄúInformal cognitive walkthroughs (icw)
paring down and pairing up for an agile world,‚Äù in Proceedings of the
SIGCHI Conference on Human Factors in Computing Systems , 2013,
pp. 3093‚Äì3096.
[58] A. Sears, ‚ÄúHeuristic walkthroughs: Finding the problems without the
noise,‚Äù Int. J. Hum. Comput. Interact. , vol. 9, pp. 213‚Äì234, 1997.
[59] R. Spencer, ‚ÄúThe streamlined cognitive walkthrough method, working
around social constraints encountered in a software development com-
pany,‚Äù in Proceedings of the SIGCHI conference on Human Factors in
Computing Systems , 2000, pp. 353‚Äì359.
[60] N. Jacobsen and B. John, ‚ÄúTwo case studies in using cognitive walk-
through for interface evaluation,‚Äù 2000.
[61] J. Rieman, S. Davies, D. C. Hair, M. Esemplare, P. Polson, and C. Lewis,
‚ÄúAn automated cognitive walkthrough,‚Äù in Proceedings of the SIGCHI
Conference on Human Factors in Computing Systems , ser. CHI ‚Äô91.
New York, NY , USA: Association for Computing Machinery, 1991, p.
427‚Äì428. [Online]. Available: https://doi.org/10.1145/108844.108986
[62] C. Mendez, Z. S. Hanson, A. Oleson, A. Horvath, C. Hill, C. Hilder-
brand, A. Sarma, and M. Burnett, ‚ÄúSemi-automating (or not) a socio-
technical method for socio-technical systems,‚Äù in 2018 IEEE Symposium
on Visual Languages and Human-Centric Computing (VL/HCC) . IEEE,
2018, pp. 23‚Äì32.
[63] N. Mathur, S. A. Karre, and Y . R. Reddy, ‚ÄúUsability evaluation frame-
work for mobile apps using code analysis,‚Äù in Proceedings of the 22nd
International Conference on Evaluation and Assessment in Software
Engineering 2018 , 2018, pp. 187‚Äì192.
[64] F. T. W. Au, S. Baker, I. Warren, and G. Dobbie, ‚ÄúAutomated usability
testing framework,‚Äù in Proceedings of the Ninth Conference on Aus-
tralasian User Interface - Volume 76 , ser. AUIC ‚Äô08. AUS: Australian
Computer Society, Inc., 2008, p. 55‚Äì64.
[65] M. Y . Ivory, ‚ÄúWeb tango: towards automated comparison of information-
centric web site designs,‚Äù in CHI‚Äô00 extended abstracts on Human
factors in computing systems , 2000, pp. 329‚Äì330.
[66] A. Dingli and J. Mifsud, ‚ÄúUseful: A framework to mainstream web site
usability through automated evaluation,‚Äù 2011.
[67] L. R. Kasday, ‚ÄúA tool to evaluate universal web accessibility,‚Äù in
Proceedings on the 2000 conference on Universal Usability , 2000, pp.
161‚Äì162.
[68] Vischeck , (accessed Dec, 2020), http://www.vischeck.com/.
[69] AATT , (accessed Dec, 2020), https://github.com/paypal/AATT.
[70] M. Kitajima, M. H. Blackmon, P. G. Polson, and C. Lewis, ‚ÄúAutocww
: Automated cognitive walkthrough for the web,‚Äù 2002.[71] M. Blackmon, P. Polson, M. Kitajima, and C. Lewis, ‚ÄúCognitive walk-
through for the web,‚Äù vol. 4, 04 2002, pp. 463‚Äì470.
[72] C. Hill, S. Ernst, A. Oleson, A. Horvath, and M. Burnett, ‚ÄúGendermag
experiences in the Ô¨Åeld: The whole, the parts, and the workload,‚Äù in 2016
IEEE Symposium on Visual Languages and Human-Centric Computing
(VL/HCC) . IEEE, 2016, pp. 199‚Äì207.
[73] M. Shaw, ‚ÄúProspects for an engineering discipline of software,‚Äù IEEE
Software , vol. 7, no. 6, pp. 15‚Äì24, 1990.
[74] A. Aho, M. Lam, R. Sethi, and J. Ullman, ‚ÄúCompilers: Principles,
techniques, and tools . boston, ma, usa: Addison-wesley longman
publishing co,‚Äù p. 1009, 2006.
1435