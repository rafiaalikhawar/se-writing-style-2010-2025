Generalizable and Interpretable Learning for Configuration
Extrapolation
Yi Ding
MIT CSAIL
Cambridge, MA, USA
ding1@csail.mit.eduAhsan Pervaiz
University of Chicago
Chicago, IL, USA
ahsanp@uchicago.edu
Michael Carbin
MIT CSAIL
Cambridge, MA, USA
mcarbin@csail.mit.eduHenry Hoffmann
University of Chicago
Chicago, IL, USA
hankhoffmann@cs.uchicago.edu
ABSTRACT
Modern software applications are increasingly configurable, which
puts a burden on users to tune these configurations for their target
hardware and workloads. To help users, machine learning tech-
niques can model the complex relationships between software
configuration parameters and performance. While powerful, these
learners have two major drawbacks: (1) they rarely incorporate
prior knowledge and (2) they produce outputs that are not inter-
pretable by users. These limitations make it difficult to (1) leverage
information a user has already collected (e.g., tuning for new hard-
ware using the best configurations from old hardware) and (2) gain
insights into the learnerâ€™s behavior (e.g., understanding why the
learner chose different configurations on different hardware or for
different workloads). To address these issues, this paper presents
two configuration optimization tools, GilandGil+, using the pro-
posed generalizable and interpretable learning approaches. To in-
corporate prior knowledge, the proposed tools (1) start from known
configurations, (2) iteratively construct a new linear model, (3) ex-
trapolate better performance configurations from that model, and
(4) repeat. Since the base learners are linear models, these tools are
inherently interpretable. We enhance this property with a graphical
representation of how they arrived at the highest performance con-
figuration. We evaluate GilandGil+ by using them to configure
Apache Spark workloads on different hardware platforms and find
that, compared to prior work, GilandGil+ produce comparable,
and sometimes even better performance configurations, but with
interpretable results.
CCS CONCEPTS
â€¢Software and its engineering â†’Software configuration man-
agement and version control systems ;â€¢Computing method-
ologiesâ†’Machine learning approaches .
ESEC/FSE â€™21, August  23â€“28, 2021, Athens, Greece
Â© 2021 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-8562-6/21/08.
https://doi.org/10.1145/3468264.3468603KEYWORDS
Configuration, machine learning, generalizability, interpretability
ACM Reference Format:
Yi Ding, Ahsan Pervaiz, Michael Carbin, and Henry Hoffmann. 2021. Gen-
eralizable and Interpretable Learning for Configuration Extrapolation. In
Proceedings of the 29th ACM Joint European Software Engineering Conference
and Symposium on the Foundations of Software Engineering (ESEC/FSE â€™21),
August 23â€“28, 2021, Athens, Greece. ACM, New York, NY, USA, 13pages.
https://doi.org/10.1145/3468264.3468603
1 INTRODUCTION
The increasing configurability of modern software makes it chal-
lenging for users to tune performance due to high complexity:
tremendous configuration spaces and complicated interactions be-
tween these configuration parameters [ 39,45,49,50]. Configura-
tions have a large influence on application performance such as
latency [ 42], throughput [ 3], and energy consumption [ 8]. As a
result, tools to help tune application configurations for high perfor-
mance have become a crucial yet challenging research area.
To configure software applications efficiently, machine learning
(ML) approaches have been applied to model the complex relation-
ships between configuration parameters and performance. Most
prior work on incorporating ML approaches in software perfor-
mance modeling is to first randomly sample assignments of config-
uration parameters for the application, measure the applicationâ€™s
performance with the sampled parameters, train a learner on these
samples, predict the performance for unsampled configurations,
and then deploy the software in the configuration with the best
predicted performance [ 1,18,23,47]. The most sophisticated of
these learnersâ€”e.g., neural networks [ 16], random forests [ 33], and
Gaussian process regression [ 7,29]â€”are black-box, meaning that
users have no visibility into their internal workings [9].
Although black-box ML approaches are effective at software
performance modeling, there are two practical limitations to be
addressed for efficient, optimal configuration search:
â€¢Difficulty incorporating prior knowledge. Prior ML-based
tools have little ability to leverage information a user has pre-
viously collected. Such tools require significant data collection:
they must start from scratch by generating numerous random
configurations and collecting their performance. Two specific
scenarios are considered as follows:
728This work is licensed under a Creative Commons Attribution International 4.0 License.
ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece Yi Ding, Ahsan Pervaiz, Michael Carbin, and Henry Hoffmann
â€“Scenario 1: Workload X runs slowly due to some faulty con-
figuration settings [ 50,52]. To find a better configuration, a
user can randomly sample new configurations from scratch,
run X for each to collect performance data, and build a new ML
model. To avoid this tedious process, a user can instead lever-
age the known configurationsâ€”even though they are slowâ€”to
build a model that can extrapolate to find a better configura-
tion. This strategy saves time as it does not need new initial
training data collection.
â€“Scenario 2: Workload Y has been tuned to work at the optimal
configuration on hardware A. Due to some hardware upgrade
or scheduling issues, A is no longer available and Y has to be
deployed on hardware B. Using prior approaches, users would
randomly sample configurations on B, collect performance
data, and build a ML model for configuration search [ 13,20,28].
An alternative is to incorporate prior knowledge by using
configurations known to run fast on A and developing a model
to extrapolate the configuration space from A to B. In Â§5.3,
we show that incorporating prior knowledge achieves better
performance than starting from scratch with random sampling.
â€¢Lack of interpretability. Prior work evaluates their black-box
models only for their performance prediction accuracy; it is diffi-
cult for users to interpret the prediction results [ 32]. Considering
again the above two scenarios:
â€“Scenario 1: Users hope to understand the underlying factorsâ€”
from software applications to hardware resourcesâ€”that cause
the low performance and thus avoid the similar issues in the
future [25, 43, 48].
â€“Scenario 2: Users hope to interact with the learners and gain
insights into why prior configurations are slow and how faster
configurations are achieved. They also hope such knowledge
to generalize across different hardware and workloads [ 47,51].
To address these limitations, we present GilandGil+ : config-
uration extrapolation tools that incorporate prior knowledge to
achieve high performance and provide interpretability to advance
human knowledge. To incorporate prior knowledge, GilandGil+
use existing information about configurations as initial training
samples and then extrapolate to even higher performance configu-
rations. To achieve interpretability, the key insight is to iteratively
construct linear models that approximate the true nonlinear func-
tion such that the most important configuration parameters can
be interpreted as a combination of both their weights in the linear
model and the changes in those weights as the model is iteratively
updated. To help understand the relationships between the applica-
tion and the computer system on which it runs, Gil+ augments Gil
with a hierarchical model that connects application-level configu-
rations, low-level system metrics (e.g., context switches and cache
misses), and the final application performance (see detailed defini-
tions in Â§3.1). Additionally, we develop graphical tools to visualize
these relationships to help users interpret learning results.
We implement GilandGil+ , and evaluate them on Apache Spark
workloads of HiBench [ 14], which is a widely used benchmark suite
to evaluate data processing frameworks [ 53]. We run ten workloads
covering a wide range of categories on three different hardware
platforms. We consider two experimental settings corresponding to
scenarios 1and 2, respectively. Our results show the following:
Figure 1: Gil+ hierarchical model relating application con-
figurations, low-level system metrics, and performance.
â€¢GilandGil+ achieve better extrapolation performance than ran-
dom sampling, neural networks [ 16] and genetic algorithms [ 53],
with results comparable to Bayesian optimization [ 33] (Â§5.1, ??).
â€¢For all learners, incorporating prior knowledge achieves 2â€“15%
performance improvements compared to starting from scratch
with random sampling for initial training (Â§5.3).
â€¢Gil+ enables the users to interact with the learners and interpret
relationships between application-level configurations, low-level
system metrics, and performance via visualization tools (Â§5.4).
In summary, this work makes the following contributions:
â€¢Proposing GilandGil+ , two configuration extrapolation tools
that incorporate prior knowledge to avoid starting from scratch.
â€¢Demonstrating the benefits of incorporating prior knowledge
into learning systems for configuration extrapolation.
â€¢Developing visualization tools for GilandGil+ to help users
interpret learning results.
â€¢Releasing code and data for GilandGil+ in https://github.com/y-
ding/gil.
2 MOTIVATIONAL EXAMPLE
As an example of the value our tools, we study Apache Spark work-
loads from HiBench [ 14] on three different hardware from a public
heterogeneous cloud systemâ€”the Chameleon Cloud Research Plat-
form [ 21]. We use the names that Chameleon1uses for different
hardware with details shown in Table 2, which includes three hard-
ware microarchitecturesâ€”Skylake, Haswell, and Storage; the first
two are compute servers, the last is optimized for disk bandwidth.
We determine the best configuration for each workload and specific
hardware by exhaustive search among our measurements.
Gil+ develops a hierarchical model connecting application-level
configurations, low-level system metrics, and performance shown
in Figure 1 (see detailed definitions in Â§3.1). In particular, Gil+ builds
a linear model between low-level system metrics and performance,
and for each low-level system metric, Gil+ builds a linear model
between application-level configuration parameters and it. With
the extra low-level system layer in-between, Gil+ makes it easier
1https://www.chameleoncloud.org/hardware/
729Generalizable and Interpretable Learning for Configuration Extrapolation ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece
BMR
CMR
IPC CSRPFR
âˆ’1.0âˆ’0.50.00.51.0Before
After
(a)nweight
BMR
CMR
IPC CSRPFR
âˆ’1.0âˆ’0.50.00.51.2Before
After (b)lr
Figure 2: Visualizing learned relationships between low-
level systems metrics and performance. The value on each
axis shows how the corresponding low-level system met-
ric influences performance when moving from Haswell (Be-
fore) to Storage (After).
for users to reason about the hardware and software cross-stack
interactions as well as tune application-level configurations.
To illustrate GIL+â€™s behavior, we use the nweight workload
from HiBench. Consider the case where Haswell is available first
for deployment, and the high-performance configurations have
been tuned for Haswell, either by human users or learners. Later, a
new class of Storage machines with a small processor downgrade
(slightly reduced clockspeed and last-level cache) and huge storage
system upgrade (see details in Table 2) becomes available. A rea-
sonable hypothesis would be that for the nweight workload, the
upgraded storage system will outweigh the small downgrade in
computing power. Thus when we deploy nweight on Storage, it is
natural to start the high-performance Haswell configurations and
run them directly on Storage.
Unfortunately, we find that the performance (throughput) can
be more than 20% worse on Storage than Haswell, for the same
configuration. Even if black-box learners from prior work are used
to tune configurations using these available configurations, the best
possible performance we find on Storage is still 10% worse than the
best Haswell performance. Even worse, these black-box learners
provide no interpretation of their results. Thus, at this point, the
user might be wondering if Storage is fundamentally slower for
nweight , or if the black-box learners simply need more time to
search for a better configuration. With a black-box learner, there is
no way for a user to gain insight into these questions. Gil+ , on the
other hand produces an interpretable model that a user can inspect.
Figure 2a shows the nweight interpretation results between ap-
plication performance and low-level system metrics before and
after applying Gil+ to tune application-level configurations on
Storage. In other words, the before configurations are those that
perform well on Haswell and the after configurations are those
that perform well on Storage. The label for each axis in the radar
chart represents a specific low-level system metric (see details in
Table 3) and the value on each axis is the learned linear coefficient
mapping from the low-level system metric to application-level per-
formance. See Â§3.4 to know more about how we visualize the results.
This chart shows that IPC (instructions per cycle) changes mostâ€”
a sharp spike towards IPCâ€”after applying Gil+ , which indicates
that higher IPC is associated with better performance on Storage
âˆ’0.25 0.00 0.25 0.50 0.75
Linear coefficient differencesBMRCMRIPCCSRPFRspark.broadcast.blockSize
spark.shuffle.file.buffer
spark.executor.memory
spark.broadcast.compress
spark.kryoserializer.buffer
spark.memory.fraction
spark.reducer.maxSizeInFlight
spark.io.compression.snappy.blockSize
spark.speculation.interval
spark.shuffle.spill.compress
spark.driver.memory
spark.task.maxFailures
spark.shuffle.compress
spark.speculation.quantile
spark.network.timeoutFigure 3: Visualizing learned relationships between low-
level system metrics and application-level configurations
fornweight workload. The magnitude of each bar shows how
much the corresponding application-level configuration pa-
rameter changes each low-level system metric when moving
from Haswell to Storage (with larger bars indicating larger
effects). This enables users to relate the large effects from
application-level configurations to the effects each low-level
system metric has on performance in Figure 2.
and thus application-level configurations should be tuned to in-
crease IPC. These results immediately provide insights into why
Haswell performs better than Storage: Haswellâ€™s faster clock and
larger last-level cache are likely beneficial for an application that
wants increased computational power. Being able to interpret the
model gives us certain confirmation that Haswell is really faster
than Storage for this workload. Furthermore, Gil+ can be used to
discover workloads that behave similarly and infer the possible
optimal deployment for new workloads. Figure 2b shows the radar
chart for lr: it behaves similarly to nweight : both having sharp
spikes towards IPC, which indicates that they would likely benefit
from the same hardware. In other words, it may not be worthwhile
running lron Storage, because nweight is faster on Haswell than
on Storage and it is likely that lrwill be faster on Haswell as
well. In contrast, black-box learners cannot report back this type of
information to human users.
Nevertheless, no configuration optimizer can directly affect IPC,
instead they must tune the application-level configurations to in-
crease nweight â€™s IPC and, then, its performance. Therefore, Gil+
builds interpretable models that map application-level configura-
tions and low-level system metrics to tune configuration parameters.
Figure 3 shows the absolute linear coefficient differences between
after and before applying Gil+ (starting from configurations that
perform well on Haswell and arriving at configurations that per-
form well on Storage). This figure shows that, although Storage
has only a small difference in processor, the application-level con-
figurations that help achieve this throughput change greatly (i.e.,
spark.broadcast.blocksize ). In contrast, black-box learners are
not able to provide such insights to help users understand why they
get different optimal configurations for different hardware. Since
Gil+ starts from prior knowledgeâ€”configurations that work well
on Haswellâ€”and then finds high-performance configurations on
Storage, this provides users insights into the differences between
730ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece Yi Ding, Ahsan Pervaiz, Michael Carbin, and Henry Hoffmann
Figure 4: Workflow for GilandGil+ tools.
the configurations they know well and those that Gil+ finds. Ad-
ditionally, our empirical results (see Â§5.3) show that extrapolating
from known configurations can achieve better performance than
starting from scratch with randomly sampling from the tremendous
configuration space.
3 PROPOSED TOOLS
In this section, we will first define related terminologies, and then
introduce two proposed tools GilandGil+ , and then describe the
visualization tools for model interpretation, and finally discuss the
limitations of the proposed tools.
3.1 Definitions
Figure 4 illustrates GilandGil+ . The input includes a workload to
optimize, a list of application-level configurations, and the low-level
system metrics and performance data to be collected.
Workload. A workload is a configurable software application. We
evaluate Apache Spark workloads (shown in Table 4), but in princi-
ple this could be any configurable software system whose quantita-
tive behavior we want to understand and optimize.
Configuration. A configuration for a software application, repre-
sented by a ğ‘-dimensional vector where ğ‘is the number of config-
uration parameters:
xğ‘–=[ğ‘¥ğ‘–1, . . . , ğ‘¥ ğ‘– ğ‘—, . . . , ğ‘¥ ğ‘–ğ‘], (1)
where xğ‘–is the ğ‘–-th configuration, ğ‘¥ğ‘– ğ‘—is the value of the ğ‘—-th con-
figuration parameter in the ğ‘–-th configuration. For instance, ğ‘is 20
corresponding to the 20 Apache Spark configuration parameters in
our evaluation (Â§5) (shown in Table 1).
Low-level system metric (LLSM) . LLSM is the quantifiable be-
havior of the underlying OS (e.g., context switches) and hardware
(e.g., cache misses) that helps understand the application-level per-
formance. These are represented as a ğ‘‘-dimensional vector assum-
ing there are ğ‘‘metrics to measure and understand:
uğ‘–=[ğ‘¢ğ‘–1, . . . ,ğ‘¢ ğ‘– ğ‘—, . . . ,ğ‘¢ ğ‘–ğ‘‘], (2)
where uğ‘–is the ğ‘–-th low-level system metric vector, ğ‘¢ğ‘– ğ‘—is the value
of the ğ‘—-th metric in the ğ‘–-th low-level system metric vector. For
example, in this work ğ‘‘is 5 as five low-level system metrics are
studied as shown in Table 3.
Performance. Performance is the measured behavior for a work-
load on certain hardware. This work focuses on throughput, which
is the rate of the total data delivered in the network [3].
Each configuration and its corresponding measurementâ€”including
low-level system metrics and performanceâ€”is a sample .Giland
Gil+ use these samples to build performance models to search the
optimal configuration as an output. Specifically, GilandGil+ buildAlgorithm 1 Gilperformance model.
Require: ğ‘‹tr âŠ²Training configuration set
Require: ğ‘‹te âŠ²Test configuration set
Require: ğ‘Œtr âŠ²Training performance set
Require: ğ‘˜ âŠ²Sample budget at each round
Require: ğ‘‡ âŠ²Number of rounds
1:foreach round ğ‘¡=1, . . . ,ğ‘‡ do
2: Train model that maps configurations ğ‘‹trto performance ğ‘Œtr.
3: Use above trained model to predict performance on ğ‘‹te.
4: Select ğ‘˜configuration set ğ‘‹ğ‘¡with best predicted performance.
5: Run workload to get true performance ğ‘Œğ‘¡forğ‘‹ğ‘¡.
6: Update training configuration set ğ‘‹trâ†ğ‘‹trâˆªğ‘‹ğ‘¡.
7: Update training performance set ğ‘Œtrâ†ğ‘Œtrâˆªğ‘Œğ‘¡.
8: Update test configuration set ğ‘‹teâ†ğ‘‹te\ğ‘‹ğ‘¡.
9: Train model that maps configurations ğ‘‹trtoğ‘Œtr.
10: Use the trained model to predict performance for test configuration set ğ‘‹te.
11: Interpret results using tools in Â§3.4.
12:Output: configuration xâ˜…with the best predicted performance and interpretation
results visualized by radar and bar charts.
a series of models relating application-level configurations to per-
formance, a series of models relating the low-level system metrics
to performance, and a series of models relating application-level
configurations to each low-level system metric. Then, the coeffi-
cients learned from these models are passed to model interpretation
to visualize the results as another output. Next, we will elaborate
the performance models and interpretation visualization.
3.2 GilPerformance Model
To improve performance accuracy and promote search space explo-
ration, Giliteratively interacts with the workload by sequentially
learning an unknown function ğ‘“â€”modeling the relationships be-
tween application configuration and performanceâ€”with a sample
budget. At each iteration, limited configurations are selected to
update ğ‘“. After all iterations are completed, Giluses the learned ğ‘“
to evaluate the remaining (untested) configurations to find the one
with the best predicted performance. In this process, two challenges
(CHs) need to be addressed:
CH1: Designing a model to learn the unknown function ğ‘“.
CH2: Formulating a query strategy to select the samples.
We will address these two CHs as follows.
3.2.1 Learning Linear Functions. To learn the unknown function ğ‘“,
Giluses a linear regression model [ 10].Gilchooses linear model
over other nonlinear models, such as neural networks [ 12] and
Gaussian process regression [7, 29], due to several advantages:
â€¢Better extrapolation ability. Although nonlinear models usually
achieve higher overall prediction accuracy than linear models,
they are more likely to overfit the training set, which leads to poor
extrapolation performance when facing unseen data points [ 6].
In contrast, linear models are less likely to overfit and thus gen-
eralize better on unseen data.
â€¢Interpretability. Linear models are naturally interpretable: the lin-
ear coefficients quantify the relationships between independent
metrics and performance: a positive coefficient indicates positive
correlation between a metric and performance, while a nega-
tive coefficient indicates negative correlation. The coefficientsâ€™
magnitudes represent the strength of these relationships.
731Generalizable and Interpretable Learning for Configuration Extrapolation ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece
For the ğ‘–-th configuration xğ‘–, assuming its measured performance
isğ‘¦ğ‘–, the linear regression model will be:
ğ‘¦ğ‘–=ğ›½1ğ‘¥ğ‘–1+ğ›½2ğ‘¥ğ‘–2+. . .+ğ›½ğ‘ğ‘¥ğ‘–ğ‘+ğœ–ğ‘–, (3)
where ğ›½1, . . . , ğ›½ ğ‘are coefficients corresponding to ğ‘configuration
parameters, and ğœ–ğ‘–is the noise (usually assumed to be a Gaussian).
The linear model is solved via ridge regression, which is a regular-
ized method to avoid overfitting [ 10].Thus Giladdresses CH1 by
iteratively estimating the unknown function with linear models.
3.2.2 Active Learning. Gilapplies active learning to iteratively
query samples over successive rounds. At each round, Gilcollects
samples that are intended to improve the model predictions for the
best configurations. After evaluating the new samples, the model
is updated using these samples and then the next round begins. As
such, the key is to come up with a query function that converges
quickly so that Gilcan find the optimal configuration across spaces
with limited samples. This is not trivial because the model needs to
balance the tradeoff between explorationâ€”avoiding local optima
in training spaceâ€”and exploitationâ€”improving the predictions for
the highest performance configurations in new space.
Given the base learner is linear, Giloptimizes locally by querying
samples with the best predicted performance at each step: for each
step ğ‘¡, assume the predictive function is ğ‘“ğ‘¡, then the optimizer
searches for a subset ğ‘†with ğ‘˜configurations such that:
ğ‘†=arg max
ğ‘ âˆˆğ‘†,|ğ‘†|=ğ‘˜Ã•
ğ‘ ğ‘“ğ‘¡(ğ‘ ). (4)
This query strategy selects a subset of configurations with the best
predicted performance at each round. Intuitively, picking config-
urations with the best performance is more likely to improve the
prediction accuracy for the best performance configurations in the
next round. With this query strategy, Giladdresses CH2 by search-
ing the optimal configuration as rapidly as possible. Algorithm 1
summarizes the procedures for Gilperformance model.
3.3 Gil+ Performance Model
Gilinterprets the relationships between the application-level con-
figuration parameters and ultimate performance by quantifying the
learned coefficient for each application-level configuration parame-
ter. To further benefit from interpretation, we propose a hierarchi-
cal performance model that relates application-level configuration
parameters to performance through low-level system metrics. In
particular, we hope to understand not just how each application
parameter influences performance, but also how that influence
manifests through low-level system metrics like cache misses or
context switches.
To accomplish this goal, we present Gil+ , illustrated in Figure 1.
We consider five low-level system metrics in this paper (see details
in Table 3). In principle, Gil+ could be applied to any set of low-level
system metrics. We incorporate this extra layer as follows.
Algorithm 2 summarizes the procedures for Gil+ . Instead of di-
rectly building models mapping from application configurations to
performance, Gil+ first builds an model that maps from low-level
system metrics to performance. Then, Gil+ obtains the low-level
system metric vector [ğ‘¢1, . . . ,ğ‘¢ 5]with the best predicted perfor-
mance from test low-level system metric set ğ‘ˆte, as in line 3. Next,
forğ‘–-th low-level system metric ğ‘ˆğ‘–, ğ‘–=1. . . ,5,Gil+ builds a modelAlgorithm 2 Gil+ hierarchical performance model.
Require: ğ‘‹tr âŠ²Training configuration set
Require: ğ‘‹te âŠ²Test configuration set
Require: ğ‘ˆtr âŠ²Training low-level system metric set
Require: ğ‘ˆte âŠ²Test low-level system metric set
Require: ğ‘Œtr âŠ²Training performance set
Require: ğ‘‘ âŠ²Number of low-level system metrics (LLSMs)
Require: ğ‘˜ âŠ²Sample budget for each low-level system metric at each round
Require: ğ‘‡ âŠ²Number of rounds
1:foreach round ğ‘¡=1, . . . ,ğ‘‡ do
2: Train model that maps LLSMs ğ‘ˆtrto performance ğ‘Œtr.
3: Get LLSM vector [ğ‘¢1, . . . ,ğ‘¢ ğ‘‘]with best predicted performance from ğ‘ˆte.
4: foreach LLSM ğ‘ˆğ‘–, ğ‘–=1, . . . ,ğ‘‘ do
5: Train model that maps ğ‘‹trtoğ‘ˆğ‘–
tr.
6: Use trained model to predict on ğ‘ˆğ‘–
te.
7: Select ğ‘˜configurations ğ‘‹ğ‘–
ğ‘¡with closest predicted ğ‘–-th LLSM values to ğ‘¢ğ‘–.
8: Run workload to get true LLSM value ğ‘ˆğ‘–
ğ‘¡and performance ğ‘Œğ‘–
ğ‘¡forğ‘‹ğ‘–
ğ‘¡.
9: Update training configuration set ğ‘‹trâ†ğ‘‹trâˆªğ‘‹ğ‘–
ğ‘¡.
10: Update training LLSM set ğ‘ˆtrâ†ğ‘ˆtrâˆªğ‘ˆğ‘–
ğ‘¡.
11: Update training performance set ğ‘Œtrâ†ğ‘Œtrâˆªğ‘Œğ‘–
ğ‘¡.
12: Update test configuration set ğ‘‹teâ†ğ‘‹te\ğ‘‹ğ‘–
ğ‘¡.
13: Train model that maps configurations ğ‘‹trtoğ‘Œtr.
14: Use the trained model to predict performance for test configuration set ğ‘‹te.
15: Interpret results using tools in Â§3.4.
16:Output: configuration xâ˜…with the best predicted performance and interpretation
results visualized by radar and bar charts.
that maps from application configurations to ğ‘ˆğ‘–. Then, Gil+ selects
topğ‘˜application configurations that have the closest predicted ğ‘–-th
low-level system metric values to ğ‘¢ğ‘–, and these ğ‘˜configurations and
corresponding measurements will be queried for the next round, as
in line 7-8. After all training and test sets are updated, Gil+ trains
the model on the final training configuration and performance sets,
and uses it to evaluate the remaining test configurations, picking
the one with the best predicted performance as the output, as in
line 13-14. The intuition of this hierarchical model is to select ap-
plication configurations that induce the nearest low-level system
metric values producing the best predicted performance.
3.4 Interpretation by Visualization
We interpret results from performance models via visualization. We
focus on Gil+ because of its extra low-level system metric layer,
which makes it possible to investigate the cross-stack interactions
between system and application levels. We visualize the learned
relationships between (1) performance and low-level system metrics
and (2) low-level system metrics and configuration parameters.
We use radar charts to depict the relationships between perfor-
mance and low-level system metrics and how they change before
and after applying Gil+ . These charts visualize the differences
between the initial, user-provided configurations and the final rela-
tionships that Gil+ learns. If users provide configurations that are
known to work well on different hardware, then these charts will
visualize the differences in the influence of these initial configura-
tions and those Gil+ learned. We choose radar charts because they
can show multiple metrics simultaneously and quickly compare
different values in each axis. The label for each axis represents a
specific low-level system metric and the value on each axis is the
learned linear coefficient mapping from low-level system metric to
performance. The changes are visualized with different colors.
We use bar charts to illustrate the relationships between low-
level system metrics and application configuration parameters. We
732ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece Yi Ding, Ahsan Pervaiz, Michael Carbin, and Henry Hoffmann
choose bar charts because there are multiple low-level system met-
rics and we need to compare each with their relationships with
configuration parameters. Take nweight workload in Figure 3 as
an example. The y-axis represents each low-level system metric,
and the x-axis represents the learned absolute linear coefficient
differences before and after applying Gil+ . Each bar represents
different configuration parameters, and their direction and length
correspond to the x-axis. With bar charts, we can interpret the
learned relationship between low-level system metrics and con-
figuration parameters, and how their influences to each low-level
system metric change.
3.5 Discussion and Limitations
GilandGil+ use linear models as base learners to achieve inter-
pretability, which would lose a slight amount of overall prediction
accuracy compared to using more sophisticated black-box learners
such as neural networks [ 12], gradient boosting trees [ 4], and Gauss-
ian process regression [ 7,35]. Moreover, these black-box learners
are more likely to overfit the training data and make conservative
judgment in exploring new space. To compensate for the lose of
prediction accuracy, GilandGil+ employ an iterative learning
paradigm to allow the model to correct itself every time there is an
error [ 27]. Meanwhile, Bayesian optimization updates the model
iteratively using a black-box learnerâ€”Gaussian process regression,
and usually achieves high prediction accuracy [ 38], which is also
demonstrated in our evaluation in Section 5. While powerful, it is
uninterpretable and thus does not provide insights into how the
highest performance configuration is reached. To sum up, Giland
Gil+ are practical trade-offs between accuracy and interpretability.
4 EXPERIMENTAL METHODOLOGY
This section describes our experimental setup and evaluation method-
ologies to demonstrate the effectiveness of GilandGil+ at configu-
ration extrapolation in multiple workloads, hardware, and settings.
4.1 Systems
4.1.1 Software. We use Apache Spark 2.2.3 [ 54]2as our software
distributed computing framework. Each experiment has a server
node and four worker nodes. We choose a wide range of config-
uration parameters that reflect significant Spark properties cate-
gorized by shuffle behavior, data compression and serialization,
memory management, execution behavior, networking, and sched-
uling. Table 1 shows the total 20 parameters in detail. We use sim-
ilar parameters to prior work [ 53] but not the same set because
Spark has actually reduced the number of user visible configuration
parametersâ€”precisely because configuring them is challenging.
4.1.2 Hardware. We run experiments on a public cloud computing
system: the Chameleon Cloud Research Platform [21]. We use the
names that Chameleon3uses for three Intel x86 processors shown
in Table 2. We collect five low-level system metrics that have been
shown to influence application performance [ 24]. Table 3 shows
the five low-level system metrics in detail.
2https://spark.apache.org/docs/2.2.3/configuration.html
3https://www.chameleoncloud.org/hardware/4.2 Workloads
We select ten Apache Spark workloads from the HiBench4big data
benchmark suite [ 14] with details shown in Table 4. These work-
loads cover various domains including microbenchmarks (micro),
machine learning (ML), websearch, and graph analysis; and they
exhibit a wide range of resource usage. For ten workloads with
2000 configurations per workload on three hardware platforms,
it took four weeks of computing time to collect all these data for
experimental evaluation in this paper.
4.3 Points of Comparisons
We compare the following approaches:
â€¢Default : the default application-level configuration provided by
the Apache Spark developers.
â€¢RS: randomly sample configurations and select the best with a
linear regression performance model.
â€¢NN: a design space exploration method with neural network and
intelligent sampling proposed in [16].
â€¢DAC: a configuration parameter tuning approach with the en-
semble tree model and genetic algorithm proposed in [53].
â€¢BO: Bayesian optimization for configuration tuning [33].
â€¢Gil: generalizable and interpretable learning relating application
configurations and performance.
â€¢Gil+ : generalizable and interpretable learning relating applica-
tion configurations, low-level system metrics, and performance.
â€¢OPT: exhaustive search for the true optimal configuration over
the entire measurements.
RS, NN, and DAC are non-iterative learning methods that train
only once, while BO, Gil, and Gil+ are iterative methods that train
multiple rounds until the sample budget is met. NN, DAC, and BO
use black-box models, while RS, Gil, and Gil+ are interpretable.
All parameters for these algorithms used in our experiments are
selected via cross validations.
4.4 Evaluation Metric
For each workload, we compare the Relative Performance (RP) be-
tween the best performance (throughput) found from the learning-
based configuration search methods and the true optimal perfor-
mance (found through exhaustive search over our measurements):
RP=100%âˆ—ğ‘Œpredâˆ’ğ‘Œopt
ğ‘Œopt, (5)
where ğ‘Œpredis the best performance from the above methods and
ğ‘Œoptis the optimal performance. Lower RP is better.
4.5 Evaluation Methodology
We randomly generate 2000 application-level configurations for
each workload, which is a commonly used size in prior work [ 53].
For each workload, we run it at each configuration on different
hardware to record their performances. We divide the total con-
figurations into three levels: low, modest, and high performance
with corresponding ratios [0.5,0.3,0.2]; e.g., the high-performance
configurations are the top 20% of the measured configurations. The
optimal configuration for each workload on each hardware is ob-
tained via exhaustive search over our measurements. We then use
4https://github.com/Intel-bigdata/HiBench
733Generalizable and Interpretable Learning for Configuration Extrapolation ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece
Table 1: Details of the 20 Apache Spark 2.2.3 configuration parameters.
Configuration parameter Range Description
spark.reducer.maxSizeInFlight 24â€“128 Maximum size of map outputs to fetch simultaneously from each reduce task, in MB.
spark.shuffle.file.buffer 24â€“128 Size of the in-memory buffer for each shuffle file output stream, in KB.
spark.shuffle.sort.bypassMergeThreshold 100â€“1000 Avoid merge-sorting data if there is no map-side aggregation.
spark.speculation.interval 100â€“1000 How often Spark will check for tasks to speculate, in millisecond.
spark.speculation.multiplier 1â€“5 How many times slower a task is than the median to be considered for speculation.
spark.speculation.quantile 0â€“1 Percentage of tasks which must be complete before speculation is enabled.
spark.broadcast.blockSize 2â€“128 Size of each piece of a block for TorrentBroadcastFactory, in MB.
spark.io.compression.snappy.blockSize 24â€“128 Block size used in snappy, in KB.
spark.kryoserializer.buffer.max 24-128 Maximum allowable size of Kryo serialization buffer, in MB.
spark.kryoserializer.buffer 24â€“128 Initial size of Kryoâ€™s serialization buffer, in KB.
spark.driver.memory 6â€“12 Amount of memory to use for the driver process, in GB.
spark.executor.memory 8â€“18 Amount of memory to use per executor process, in GB.
spark.network.timeout 20â€“500 Default timeout for all network interactions, in second.
spark.locality.wait 1â€“10 How long to launch a data-local task before giving up, in second.
spark.task.maxFailures 1â€“8 Number of task failures before giving up on the job.
spark.shuffle.compress false, true Whether to compress map output files.
spark.memory.fraction 0â€“1 Fraction of (heap space - 300 MB) used for execution and storage.
spark.shuffle.spill.compress false, true Whether to compress data spilled during shuffles.
spark.broadcast.compress false, true Whether to compress broadcast variables before sending them.
spark.memory.storageFraction 0.5â€“1 Amount of storage memory immune to eviction.
Table 2: Details of the hardware platforms.
Skylake Haswell Storage
Processor Gold 6126 E5-2670 E5-2650
RAM size 192 GB 128 GB 64 GB
# of Threads 48 48 40
Clockspeed 2.6 GHz 3.1 GHz 3.0 GHz
L3 cache 19.25 MB 30 MB 25 MB
Memory speed 2.666 GHz 2.133 GHz 2.133 GHz
# Mem channels 6 4 4
Network speed 10 GbE 0.1 GbE 10 GbE
Disk vendor Samsung Seagate Seagate
# Disks 1 1 16
Disk bandwidth 6 Gb/s 6 Gb/s 24 Gb/s
Table 3: Details of the five low-level system metrics.
Abbr. Low-level metrics Description
BMR Branch misses rate # branch misses/ # total branch misses
CMR Cache misses rate # cache misses/ # total cache misses
CSR Context switch rate # context switch/ # cpu cycles
PFR Page faults rate # page faults/ # cpu cycles
IPC Instruc. per cycle # instruction / # cpu cycles
the methods mentioned above to search for the best configuration
for each workload on different hardware. Since our goal is to ex-
amine the extrapolation ability of each algorithm, we consider the
following two experimental settings:
â€¢low2high : training set only has configurations of low perfor-
mance, and test set has configurations with a wide range of
performance. This setting corresponds to scenario 1in Â§1; i.e.,Table 4: Details of the ten HiBench workloads.
Workload Data size Workload Data size
wordcount 32 GB lr 8 GB
terasort 3.2 GB linear 48 GB
als 0.6 GB rf 0.8 GB
bayes 19 GB pagerank 1.5 GB
kmeans 20 GB nweight 0.9 GB
this represents the case where users start from configurations of
low performance and aim to extrapolate to high performance .
â€¢mod2high : training set only has configurations of modest perfor-
mance that run fast from a different hardware, and test set has
configurations with a wide range of performance. For instance,
if the training set has configurations that run fast on Haswell,
but run modestly on Skylake, the search phase will evaluate all
configurations in test set to pick the one predicted to run fastest
on Skylake. Since we have 3 hardware, we have 6 training-test
pairs. This setting corresponds to scenario 2in Â§1; i.e., this rep-
resents the case where users have found configurations of high
performance for one hardware and attempt to use those as a
starting point to optimize for a different hardware.
In Algorithm 1 and 2, ğ‘‡andğ‘˜are set as small numbers to demon-
strate that GilandGil+ can produce comparable and better results
on a small sample budget than those methods without intelligent
sampling (e.g., RS). Since the collected dataset size for each hard-
ware is 2000, we choose 20% and 10% for low2high andmod2high â€”
i.e., 400 and 200â€”which are much smaller than thousands used in
prior work [53]. low2high requires more labeled data for training
because it extrapolates larger space than mod2high does. ğ‘˜is set as
20. We report results averaged over 5 runs with different seeds.
734ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece Yi Ding, Ahsan Pervaiz, Michael Carbin, and Henry Hoffmann
5 EXPERIMENTAL EVALUATION
We examine the following research questions (RQs):
â€¢RQ1: How good are GilandGil+ at extrapolating from configu-
rations of low performance to high performance ( low2high )?
â€¢RQ2: How good are GilandGil+ at extrapolating from configu-
rations of modest performance to high performance ( mod2high )?
â€¢RQ3: Does incorporating prior knowledge improve extrapolation
performance compared to starting from scratch?
â€¢RQ4: What can we interpret from visualization in case studies?
5.1 RQ1: How good are GilandGil+ at
extrapolation from configurations of low
performance to high performance?
We examine the extrapolation results from configurations of low
performance to high performance in low2high setting. Figure 5
shows the relative performance (RP) results for each method. The
strip label on the right for each row of bar charts represents the
hardware platform for the experiments. The x-axis represents each
workload, and the y-axis represents RP. Lower is better (closer to
optimal). The last column, HarMean, shows the harmonic mean
results over all workloads, which are also quantified in Table 5.
Table 5: Harmonic mean results over all workloads of each
hardware for low2high . The last column HarMean is the har-
monic mean over three hardware.
Skylake Haswell Storage HarMean
DEFAULT 43% 29% 25% 31%
RS 22% 11% 11% 13%
NN 22% 17% 13% 16%
DAC 36% 18% 19% 22%
BO 14% 1% 2% 2%
GIL 13% 7% 7% 8%
GIL+ 10% 7% 5% 7%
For non-iterative learning methods, RS is generally better than
NN and DAC, which is a bit counter-intuitive as we would think
that linear models are not as powerful as black-box models. How-
ever, as discussed in Â§3.2.1, despite perhaps overall lower prediction
accuracy, linear models are less likely to overfit and thus promote
extrapolation. In contrast, black-box models such as neural net-
works and ensemble trees are more likely to overfit and make less
accurate predictions for unseen data. For iterative learning meth-
ods, BO is slightly (5 percentage points) better than GilandGil+
because black-box models generally have higher prediction accu-
racy than linear models. Overall, iterative learning methods are
better than non-iterative ones because they encourage extrapo-
lation in the iterative process. These results demonstrate that Gil
andGil+ â€™s iterative learning can provide performance comparable
to the best black-box methods and overcome faulty (or extremely
low-performance) configurations.5.2 RQ2: How good are GilandGil+ at
extrapolating from configurations of
modest performance to high performance?
We examine the extrapolation results from configurations of modest
performance to high performance in mod2high setting. Figure 6, 7,
and 8 show the relative performance (RP) for each method on three
target hardware platforms, respectively. In each figure, the strip
label on the right for each row of bar charts represents the hardware
platform where the starting configurations are from. The x-axis
represents each workload, and the y-axis represents RP for the
target hardware. Lower is better (closer to optimal). The last column,
HarMean, shows the harmonic mean results over all workloads,
which are also quantified in Table 6.
Table 6: Harmonic mean results over all workloads of each
hardware for mod2high . The last column HarMean is the har-
monic mean over three hardware.
Skylake Haswell Storage HarMean
DEFAULT 43% 29% 25% 31%
RS 17% 10% 9% 11%
NN 19% 13% 9% 13%
DAC 22% 14% 10% 14%
BO 7% 1% 2% 2%
GIL 2% 2% 6% 2%
GIL+ 7% 6% 3% 4%
The results analyzed in the low2high setting almost hold for the
mod2high setting. RS is better than NN and DAC, and BO is almost
comparable to GilandGil+ . Overall, BO, GilandGil+ are better
than RS, NN, and DAC due to their iterative learning paradigm.
These results demonstrate that GilandGil+ are comparable to the
best black-box learners. Different from prior methods, GilandGil+
can benefit from starting from user suggested configurations, which
is evidence that incorporating human knowledge is beneficialâ€”it gets
GilandGil+ on par with the best black-box learner.
5.3 RQ3: Does incorporating prior knowledge
improve extrapolation performance
compared to starting from scratch?
As further evidence of the benefits of extrapolating from prior
knowledge, we compare starting from scratch with random sam-
pling to incorporating prior knowledge for initial training. Fig-
ure 9 shows the aggregated improvements from incorporating prior
knowledge over starting with random sampling across all work-
loads in the mod2high setting (higher is better). Overall, all learners
benefit from incorporating prior knowledge with improvements
from 2% to 15% in harmonic mean, where GilandGil+ both have
3% improvement. Starting from scratch achieves lower performance
because random sampling over the whole space loses initial direc-
tion for extrapolation, while a tighter cluster of samples provides a
clearer direction to pursue next, and reduces the chance of getting
stuck in local optima. These results demonstrate the efficacy of Gil
andGil+ by incorporating prior knowledge for initial training.
735Generalizable and Interpretable Learning for Configuration Extrapolation ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece
SkylakeHaswellStorageals bayes kmeans linear lr nweight pagerank rf terasort wordcount HarMean0255075
0255075
0255075
WorkloadsRP (%)DEFAULT RS NN DAC BO GIL GIL+
Figure 5: Relative performance (RP) of each method in low2high setting for different hardware (lower is better).
HaswellStorageals bayes kmeans linear lr nweight pagerank rf terasort wordcount HarMean020406080
020406080
WorkloadsSkylake RP (%)DEFAULT RS NN DAC BO GIL GIL+
Figure 6: Relative performance (RP) of each method in mod2high setting when Skylake is the target hardware (lower is better).
SkylakeStorageals bayes kmeans linear lr nweight pagerank rf terasort wordcount HarMean020406080
020406080
WorkloadsHaswell RP (%)DEFAULT RS NN DAC BO GIL GIL+
Figure 7: Relative performance (RP) of each method in mod2high setting when Haswell is the target hardware (lower is better).
SkylakeHaswellals bayes kmeans linear lr nweight pagerank rf terasort wordcount HarMean0204060
0204060
WorkloadsStorage RP (%)DEFAULT RS NN DAC BO GIL GIL+
Figure 8: Relative performance (RP) of each method in mod2high setting when Storage is the target hardware (lower is better).
5.4 RQ4: What can we interpret from
visualization in case studies?
To demonstrate the scope of our visualization tools for interpre-
tation, we use two case studies in different applications: cause
interpretation and deployment prediction.5.4.1 Cause Interpretation. We examine the Gil+ â€™s ability to inter-
pret the causes for low performance by visualizing the coefficients
of the learned relationships mapping from low-level system metrics
to performance, and mapping from application configurations to
low-level system metrics. Figure 10 shows two workloads running
on Skylake and how their coefficients change from low performance
736ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece Yi Ding, Ahsan Pervaiz, Michael Carbin, and Henry Hoffmann
05101520
Haswell Skylake Storage HarMean
WorkloadsImprovement (%)RS NN DAC BO GIL GIL+
Figure 9: Improvements from incorporating prior knowl-
edge over starting with random sampling (higher is better).
to high performance. The common thing observed in two radar
charts is that both workloads need higher BMR and CMR for higher
performance. This is counter-intuitive because higher BMR and
CMR conventionally lead to lower performance. To interpret the
radar charts correctly, we need to read every axis together. It is
not that increasing BMR and CMR increases performance; rather
increasing BMR and CMR together, while reducing CSR is key to
achieving better performance.
Figure 11 shows the corresponding bar charts for the absolute
learned coefficient differences from application configuration pa-
rameters on each low-level system metric. We can see that the
ways to get similar system-level metrics changes are different for
different workloads via different application-level configuration
parameter changes. For linear , the influence magnitudes of BMR
and CMR from configuration parameters do not change much.
Forlr, the largest influence changes of BMR and CMR are from
spark.memory.fraction .These results demonstrate Gil+ â€™s ability
to interpret causes for low performance by discovering the relation-
ships between application configurations, low-level system metrics,
and performance.
BMR
CMR
IPC CSRPFR
âˆ’1.0âˆ’0.50.00.51.0Before
After
(a)linear
BMR
CMR
IPC CSRPFR
âˆ’0.50.00.51.01.52.0Before
After (b)lr
Figure 10: Visualizing learned relationships between low-
level systems metrics and performance. The value on each
axis shows how the corresponding low-level system met-
ric influences performance when moving from low perfor-
mance (Before) to high performance (After) on Skylake.
5.4.2 Deployment Prediction. We show that the learned coeffi-
cients of the model mapping from low-level system metrics to
performance can predict the deployment benefits across hardware.
Figure 12 shows two radar charts, where for each workload, config-
urations running fast on Haswell and their performance on Storage
are used for initial training to obtain the before coefficients. These
coefficients represent how fast configurations found on Haswell be-
have when they are on Storage. Then, we apply Gil+ to iteratively
âˆ’0.6 âˆ’0.4 âˆ’0.2 0.0 0.2
Linear coefficient differencesBMRCMRIPCCSRPFRspark.speculation.quantile
spark.executor.memory
spark.broadcast.blockSize
spark.shuffle.spill.compress
spark.driver.memory
spark.broadcast.compress
spark.shuffle.file.buffer
spark.speculation.interval
spark.task.maxFailures
spark.kryoserializer.buffer.max
spark.kryoserializer.buffer
spark.locality.wait
spark.network.timeout
spark.memory.fraction
spark.speculation.multiplier
spark.memory.storageFraction
spark.reducer.maxSizeInFlight
spark.shuffle.compress
spark.shuffle.sort.bypassMergeThreshold
spark.io.compression.snappy.blockSize(a)linear
âˆ’3 âˆ’2 âˆ’1 0
Linear coefficient differencesBMRCMRIPCCSRPFRspark.memory.storageFraction
spark.executor.memory
spark.broadcast.compress
spark.kryoserializer.buffer.max
spark.driver.memory
spark.shuffle.sort.bypassMergeThreshold
spark.io.compression.snappy.blockSize
spark.shuffle.file.buffer
spark.broadcast.blockSize
spark.shuffle.compress
spark.speculation.quantile
spark.shuffle.spill.compress
spark.task.maxFailures
spark.kryoserializer.buffer
spark.speculation.multiplier
spark.network.timeout
spark.locality.wait
spark.speculation.interval
spark.memory.fraction
(b)lr
Figure 11: Visualizing learned relationships between low-
level system metrics and application-level configurations.
The magnitude of each bar shows how much the correspond-
ing application-level configuration parameter changes each
low-level system metric when moving from low perfor-
mance to high performance (with larger bars indicating
larger effects). This enable users to relate the large effects
from application-level configurations to the effects each
low-level system metric has on performance in Figure 10.
extrapolate the configurations that can run fast on Storage until
the sample budget is met. The after coefficients represent how the
best configurations found on Storage behave.
Figure 12a and 12b show that the two workloads alsandkmeans
both have sharp spikes away from CSR, meaning that they both
benefit from decreased influence from CSR. Thus, we predict that
both workloads have same best hardware deployment. This pre-
diction is validated by the true data that the hardware choice for
the best performance of both workloads is Storage over Haswell.
This also tells users that there is no need to tune both workloads
separately on both hardware to find which hardware will be a bet-
ter deployment because it is likely that they will have the same
best hardware deployment due to their similar low-level system
737Generalizable and Interpretable Learning for Configuration Extrapolation ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece
BMR
CMR
IPC CSRPFR
âˆ’1.0âˆ’0.50.00.51.0Before
After
(a)als
BMR
CMR
IPC CSRPFR
âˆ’1.0âˆ’0.50.00.51.0Before
After (b)kmeans
Figure 12: Visualizing learned relationships between low-
level systems metrics and performance. The value on each
axis shows how the corresponding low-level system met-
ric influences performance when moving from Haswell (Be-
fore) to Storage (After).
behavior. These results show that our interpretation tool enables the
users to interact with the learners and acquire the knowledge that
generalizes across different hardware workloads.
6 RELATED WORK
ML for configuration management. ML techniques confront
the complexity of software configuration management [ 13,37,40,
49]. ML is generally incorporated into configuration tuning via
performance modeling [ 20,20,40]; i.e., the process of learning a
function mapping application-level configuration parameters to
quantifiable behavior (e.g., latency, throughput, energy consump-
tion) [ 3,8,15,30,31,42,55]. For instance, ConEx uses evolutionary
Markov Chain Monte Carlo sampling to find high-performance
configurations for big data systems [ 23]. OtterTune uses Gaussian
processes to tune database configurations [ 42]. OpenTuner uses an
ensemble of genetic algorithms to tune configuration parameters
for computer programs [ 2]. More recently, there has been a growing
interest in tuning ML systems themselves using other black-box
optimization techniques [11, 26, 46].
Transfer learning. Transfer learning is a common approach
to incorporate prior knowledge, which gains knowledge from one
problem and applies it to a different but related problem [ 34]. For
configurable software systems, the knowledge can be transferred
across different workloads and hardware environments to reduce
data collection efforts [ 17]. For instance, a cost-aware transfer learn-
ing method uses Gaussian process to transfer knowledge from
simulators to real systems [ 19]. L2S uses active learning to select
samples for knowledge transfer to a new domain [ 18]. BEETLE uses
a discovery step to identify the most relevant source from multi-
ple sources of data [ 22]. However, these works are fundamentally
different from our proposal in that they use black-box models, in
which the knowledge transferred is not interpretable by users [ 36].
In contrast, GilandGil+ not only incorporate prior knowledge to
improve application performance, but produce interpretable results
to help expand that knowledge.
Interpretability. There has been an emerging line of work on
interpreting software systems. Comprex proposes a white-box per-
formance model based on a data-flow analysis [ 44], which does notincorporate prior knowledge or use learning. Valov et al use linear
models to transfer knowledge across different hardware environ-
ments [ 41], but they directly use the model learned from the source
on the target software applications, and thus do not extrapolate to
improve results. Our proposed methods use linear models to provide
users an interpretation of the interactions between application-level
configurations, low-level system metrics, and performance [ 5]. Our
proposed tools GilandGil+ combine the advantages of transfer
learning and interpretability to improve configuration extrapolation
results and give feedback to users.
7 CONCLUSION
This paper introduces two configuration extrapolation tools, Gil
andGil+ , that incorporate prior knowledge and produce inter-
pretable results. These tools also produce a graphical interpretation
of how they arrived at the highest performance application config-
uration. Our results show that GilandGil+ achieve application
performance comparable to the best black-box learner, and outper-
form those starting from scratch with random sampling for initial
training, which demonstrates the benefits of incorporating prior
knowledge into the learning process. Additionally, the graphical
visualization tools enable users to interact with the learners and
interpret relationships between application-level configurations,
low-level system metrics, and performance. We hope this work can
inspire software engineering researchers to consider prior knowl-
edge and model interpretability when applying machine learning
techniques to performance modeling.
ACKNOWLEDGMENTS
We are grateful to Alex Renda who read the early draft of this work
and provided extremely valuable feedback. We thank the anony-
mous reviewers for their helpful feedback to improve the final
paper. Yi Dingâ€™s work is supported by the National Science Founda-
tion under Grant 2030859 to the Computing Research Association
for the CIFellows Project. Ahsan Pervaiz and Henry Hoffmannâ€™s
work is supported by NSF (grants CCF-2028427, CNS-1956180, CCF-
1837120, CNS-1764039), ARO (grant W911NF1920321), and a DOE
Early Career Award (grant DESC0014195 0003). Michael Carbinâ€™s
work is supported in part by the National Science Foundation (NSF
CCF-1918839). Results presented in this paper were obtained using
the Chameleon testbed supported by the National Science Founda-
tion. Any opinions, findings, and conclusions or recommendations
expressed in this material are those of the authors and do not nec-
essarily reflect the views of the funding agencies.
REFERENCES
[1]Miltiadis Allamanis, Earl T Barr, Premkumar Devanbu, and Charles Sutton. 2018.
A survey of machine learning for big code and naturalness. ACM Computing
Surveys (CSUR) 51, 4 (2018), 81. https://doi.org/10.1145/3212695
[2]Jason Ansel, Shoaib Kamil, Kalyan Veeramachaneni, Jonathan Ragan-Kelley,
Jeffrey Bosboom, Una-May Oâ€™Reilly, and Saman Amarasinghe. 2014. Opentuner:
An extensible framework for program autotuning. In Proceedings of the 23rd
international conference on Parallel architectures and compilation . 303â€“316. https:
//doi.org/10.1145/2628071.2628092
[3]Adam Belay, George Prekas, Ana Klimovic, Samuel Grossman, Christos Kozyrakis,
and Edouard Bugnion. 2014. IX: A Protected Dataplane Operating System for High
Throughput and Low Latency. In 11th USENIX Symposium on Operating Systems
Design and Implementation (OSDI 14) . 49â€“65. https://doi.org/10.1145/2997641
738ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece Yi Ding, Ahsan Pervaiz, Michael Carbin, and Henry Hoffmann
[4]Tianqi Chen and Carlos Guestrin. 2016. Xgboost: A scalable tree boosting system.
InProceedings of the 22nd acm sigkdd international conference on knowledge
discovery and data mining . 785â€“794. https://doi.org/10.1145/2939672.2939785
[5]David Culler, Jaswinder Pal Singh, and Anoop Gupta. 1999. Parallel computer
architecture: a hardware/software approach . Gulf Professional Publishing.
[6]Tom Dietterich. 1995. Overfitting and undercomputing in machine learning.
ACM computing surveys (CSUR) 27, 3 (1995), 326â€“327. https://doi.org/10.1145/
212094.212114
[7]Yi Ding, Risi Kondor, and Jonathan Eskreis-Winkler. 2017. Multiresolution Ker-
nel Approximation for Gaussian Process Regression. In Proceedings of the 31st
International Conference on Neural Information Processing Systems (Long Beach,
California, USA) (NIPSâ€™17) . Curran Associates Inc., Red Hook, NY, USA, 3743â€“3751.
https://doi.org/10.5555/3294996.3295131
[8]Yi Ding, Nikita Mishra, and Henry Hoffmann. 2019. Generative and multi-
phase learning for computer systems optimization. In Proceedings of the 46th
International Symposium on Computer Architecture . 39â€“52. https://doi.org/10.
1145/3307650.3326633
[9]Finale Doshi-Velez and Been Kim. 2017. Towards a rigorous science of inter-
pretable machine learning. arXiv preprint arXiv:1702.08608 (2017).
[10] Julian J Faraway. 2014. Linear models with R . CRC press. https://doi.org/10.4324/
9780203507278
[11] Daniel Golovin, Benjamin Solnik, Subhodeep Moitra, Greg Kochanski, John
Karro, and D Sculley. 2017. Google vizier: A service for black-box optimization.
InProceedings of the 23rd ACM SIGKDD international conference on knowledge
discovery and data mining . 1487â€“1495. https://doi.org/10.1145/3097983.3098043
[12] Ian Goodfellow, Yoshua Bengio, Aaron Courville, and Yoshua Bengio. 2016. Deep
learning . Vol. 1. MIT press Cambridge. https://doi.org/10.5555/3086952
[13] Jianmei Guo, Krzysztof Czarnecki, Sven Apel, Norbert Siegmund, and Andrzej
WÄ…sowski. 2013. Variability-aware performance prediction: A statistical learning
approach. In 2013 28th IEEE/ACM International Conference on Automated Software
Engineering (ASE) . IEEE, 301â€“311. https://doi.org/10.1109/ASE.2013.6693089
[14] Shengsheng Huang, Jie Huang, Yan Liu, Lan Yi, and Jinquan Dai. 2010. Hibench:
A representative and comprehensive hadoop benchmark suite. In Proc. ICDE
Workshops . 41â€“51.
[15] Connor Imes, Steven A. Hofmeyr, and Henry Hoffmann. 2018. Energy-efficient
Application Resource Scheduling using Machine Learning Classifiers. In Proceed-
ings of the 47th International Conference on Parallel Processing, ICPP 2018, Eugene,
OR, USA, August 13-16, 2018 . ACM, 45:1â€“45:11. https://doi.org/10.1145/3225058.
3225088
[16] Engin Ãpek, Sally A McKee, Rich Caruana, Bronis R de Supinski, and Martin
Schulz. 2006. Efficiently exploring architectural design spaces via predictive
modeling. ACM SIGOPS Operating Systems Review 40, 5 (2006), 195â€“206. https:
//doi.org/10.1145/1168917.1168882
[17] Pooyan Jamshidi, Norbert Siegmund, Miguel Velez, Christian KÃ¤stner, Akshay
Patel, and Yuvraj Agarwal. 2017. Transfer learning for performance modeling
of configurable systems: An exploratory analysis. In 2017 32nd IEEE/ACM Inter-
national Conference on Automated Software Engineering (ASE) . IEEE, 497â€“508.
https://doi.org/10.1109/ASE.2017.8115661
[18] Pooyan Jamshidi, Miguel Velez, Christian KÃ¤stner, and Norbert Siegmund. 2018.
Learning to sample: Exploiting similarities across environments to learn perfor-
mance models for configurable systems. In Proceedings of the 2018 26th ACM Joint
Meeting on European Software Engineering Conference and Symposium on the Foun-
dations of Software Engineering . 71â€“82. https://doi.org/10.1145/3236024.3236074
[19] Pooyan Jamshidi, Miguel Velez, Christian KÃ¤stner, Norbert Siegmund, and Prasad
Kawthekar. 2017. Transfer learning for improving model predictions in highly
configurable software. In 2017 IEEE/ACM 12th International Symposium on Soft-
ware Engineering for Adaptive and Self-Managing Systems (SEAMS) . IEEE, 31â€“41.
https://doi.org/10.1109/SEAMS.2017.11
[20] Christian Kaltenecker, Alexander Grebhahn, Norbert Siegmund, and Sven Apel.
2020. The interplay of sampling and machine learning for software performance
prediction. IEEE Software 37, 4 (2020), 58â€“66. https://doi.org/10.1109/MS.2020.
2987024
[21] Kate Keahey, Jason Anderson, Zhuo Zhen, Pierre Riteau, Paul Ruth, Dan Stanzione,
Mert Cevik, Jacob Colleran, Haryadi S. Gunawi, Cody Hammock, Joe Mambretti,
Alexander Barnes, FranÃ§ois Halbach, Alex Rocha, and Joe Stubbs. 2020. Lessons
Learned from the Chameleon Testbed. In Proceedings of the 2020 USENIX Annual
Technical Conference (USENIX ATC â€™20) . USENIX Association. https://doi.org/10.
1145/3355738.3355750
[22] Rahul Krishna, Vivek Nair, Pooyan Jamshidi, and Tim Menzies. 2020. Whence to
Learn? Transferring Knowledge in Configurable Systems using BEETLE. IEEE
Transactions on Software Engineering (2020). https://doi.org/10.1109/TSE.2020.
2983927
[23] Rahul Krishna, Chong Tang, Kevin Sullivan, and Baishakhi Ray. 2020. ConEx:
Efficient Exploration of Big-Data System Configurations for Better Performance.
IEEE Transactions on Software Engineering (2020). https://doi.org/10.1109/TSE.
2020.3007560
[24] Benjamin C Lee and David M Brooks. 2006. Accurate and efficient regression
modeling for microarchitectural performance and power prediction. ACM SIGOPSoperating systems review 40, 5 (2006), 185â€“194. https://doi.org/10.1145/1168917.
1168881
[25] Chi Li, Shu Wang, Henry Hoffmann, and Shan Lu. 2020. Statically inferring
performance properties of software configurations. In EuroSys â€™20: Fifteenth
EuroSys Conference 2020, Heraklion, Greece, April 27-30, 2020 , Angelos Bilas, Kostas
Magoutis, Evangelos P. Markatos, Dejan Kostic, and Margo I. Seltzer (Eds.). ACM,
10:1â€“10:16. https://doi.org/10.1145/3342195.3387520
[26] Lisha Li, Kevin Jamieson, Giulia DeSalvo, Afshin Rostamizadeh, and Ameet
Talwalkar. 2017. Hyperband: A novel bandit-based approach to hyperparameter
optimization. The Journal of Machine Learning Research 18, 1 (2017), 6765â€“6816.
https://doi.org/10.5555/3122009.3242042
[27] Weiyang Liu, Bo Dai, Ahmad Humayun, Charlene Tay, Chen Yu, Linda B Smith,
James M Rehg, and Le Song. 2017. Iterative machine teaching. In International
Conference on Machine Learning . PMLR, 2149â€“2158. https://doi.org/10.5555/
3305890.3305903
[28] FlÃ¡vio Medeiros, Christian KÃ¤stner, MÃ¡rcio Ribeiro, Rohit Gheyi, and Sven Apel.
2016. A Comparison of 10 Sampling Algorithms for Configurable Systems. In
Proceedings of the 38th International Conference on Software Engineering (Austin,
Texas) (ICSE â€™16) . Association for Computing Machinery, New York, NY, USA,
643â€“654. https://doi.org/10.1145/2884781.2884793
[29] Atefeh Mehrabi, Aninda Manocha, Benjamin C Lee, and Daniel J Sorin. 2020.
Bayesian Optimization for Efficient Accelerator Synthesis. ACM Transactions on
Architecture and Code Optimization (TACO) 18, 1 (2020), 1â€“25.
[30] Nikita Mishra, Connor Imes, John D. Lafferty, and Henry Hoffmann. 2018.
CALOREE: Learning Control for Predictable Latency and Low Energy. In Pro-
ceedings of the Twenty-Third International Conference on Architectural Support for
Programming Languages and Operating Systems (Williamsburg, VA, USA) (ASP-
LOSâ€™18) . New York, NY, USA, 184â€“198. https://doi.org/10.1145/3173162.3173184
[31] Nikita Mishra, Huazhe Zhang, John D. Lafferty, and Henry Hoffmann. 2015. A
Probabilistic Graphical Model-Based Approach for Minimizing Energy Under
Performance Constraints. In Proceedings of the Twentieth International Conference
on Architectural Support for Programming Languages and Operating Systems
(Istanbul, Turkey) (ASPLOSâ€™15) . New York, NY, USA, 267â€“281. https://doi.org/10.
1145/2775054.2694373
[32] Christoph Molnar. 2020. Interpretable machine learning . Lulu. com.
[33] L. Nardi, A. Souza, D. Koeplinger, and K. Olukotun. 2019. HyperMapper: a
Practical Design Space Exploration Framework. In 2019 IEEE 27th International
Symposium on Modeling, Analysis, and Simulation of Computer and Telecommu-
nication Systems (MASCOTS) . IEEE Computer Society, Los Alamitos, CA, USA,
425â€“426. https://doi.org/10.1109/MASCOTS.2019.00053
[34] Sinno Jialin Pan and Qiang Yang. 2009. A survey on transfer learning. IEEE
Transactions on knowledge and data engineering 22, 10 (2009), 1345â€“1359. https:
//doi.org/10.1109/TKDE.2009.191
[35] Carl Edward Rasmussen. 2003. Gaussian processes in machine learning. In
Summer school on machine learning . Springer, 63â€“71.
[36] Cynthia Rudin. 2019. Stop explaining black box machine learning models for
high stakes decisions and use interpretable models instead. Nature Machine
Intelligence 1, 5 (2019), 206â€“215. https://doi.org/10.1038/s42256-019-0048-x
[37] Atri Sarkar, Jianmei Guo, Norbert Siegmund, Sven Apel, and Krzysztof Czarnecki.
2015. Cost-Efficient Sampling for Performance Prediction of Configurable Sys-
tems (T). In 2015 30th IEEE/ACM International Conference on Automated Software
Engineering (ASE) . 342â€“352. https://doi.org/10.1109/ASE.2015.45
[38] Bobak Shahriari, Kevin Swersky, Ziyu Wang, Ryan P Adams, and Nando De Fre-
itas. 2015. Taking the human out of the loop: A review of Bayesian optimization.
Proc. IEEE 104, 1 (2015), 148â€“175. https://doi.org/10.1109/JPROC.2015.2494218
[39] Norbert Siegmund, Alexander Grebhahn, Sven Apel, and Christian KÃ¤stner. 2015.
Performance-influence models for highly configurable systems. In Proceedings
of the 2015 10th Joint Meeting on Foundations of Software Engineering . 284â€“294.
https://doi.org/10.1145/2786805.2786845
[40] Norbert Siegmund, Sergiy S Kolesnikov, Christian KÃ¤stner, Sven Apel, Don Ba-
tory, Marko RosenmÃ¼ller, and Gunter Saake. 2012. Predicting performance via
automated feature-interaction detection. In 2012 34th International Conference on
Software Engineering (ICSE) . IEEE, 167â€“177. https://doi.org/10.1109/ICSE.2012.
6227196
[41] Pavel Valov, Jean-Christophe Petkovich, Jianmei Guo, Sebastian Fischmeister, and
Krzysztof Czarnecki. 2017. Transferring performance prediction models across
different hardware platforms. In Proceedings of the 8th ACM/SPEC on International
Conference on Performance Engineering . 39â€“50. https://doi.org/10.1145/3030207.
3030216
[42] Dana Van Aken, Andrew Pavlo, Geoffrey J Gordon, and Bohan Zhang. 2017.
Automatic database management system tuning through large-scale machine
learning. In Proceedings of the 2017 ACM International Conference on Management
of Data . 1009â€“1024. https://doi.org/10.1145/3035918.3064029
[43] Kenzo Van Craeynest, Aamer Jaleel, Lieven Eeckhout, Paolo Narvaez, and Joel
Emer. 2012. Scheduling heterogeneous multi-cores through performance impact
estimation (PIE). In 2012 39th Annual International Symposium on Computer
Architecture (ISCA) . IEEE, 213â€“224. https://doi.org/10.1145/2366231.2337184
739Generalizable and Interpretable Learning for Configuration Extrapolation ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece
[44] Miguel Velez, Pooyan Jamshidi, Norbert Siegmund, Sven Apel, and Christian KÃ¤st-
ner. 2021. White-Box Analysis over Machine Learning: Modeling Performance of
Configurable Systems. Proceedings of the 43rd International Conference on Software
Engineering (ICSE 21) (2021). https://doi.org/10.1109/ICSE43902.2021.00100
[45] Kashi Venkatesh Vishwanath and Nachiappan Nagappan. 2010. Characterizing
cloud computing hardware reliability. In Proceedings of the 1st ACM symposium
on Cloud computing . 193â€“204. https://doi.org/10.1145/1807128.1807161
[46] Chengcheng Wan, Muhammad Husni Santriaji, Eri Rogers, Henry Hoffmann,
Michael Maire, and Shan Lu. 2020. ALERT: Accurate Learning for Energy and
Timeliness. In 2020 USENIX Annual Technical Conference, USENIX ATC 2020, July
15-17, 2020 , Ada Gavrilovska and Erez Zadok (Eds.). USENIX Association, 353â€“369.
https://www.usenix.org/conference/atc20/presentation/wan
[47] Zhiyuan Wan, Xin Xia, David Lo, and Gail C Murphy. 2019. How does machine
learning change software development practices? IEEE Transactions on Software
Engineering (2019). https://doi.org/10.1109/TSE.2019.2937083
[48] Shu Wang, Chi Li, Henry Hoffmann, Shan Lu, William Sentosa, and Achmad Imam
Kistijantoro. 2018. Understanding and auto-adjusting performance-sensitive
configurations. ACM SIGPLAN Notices 53, 2 (2018), 154â€“168. https://doi.org/10.
1145/3173162.3173206
[49] Tianyin Xu, Long Jin, Xuepeng Fan, Yuanyuan Zhou, Shankar Pasupathy, and
Rukma Talwadker. 2015. Hey, you have given me too many knobs!: understanding
and dealing with over-designed configuration in system software. In Proceedings
of the 2015 10th Joint Meeting on Foundations of Software Engineering . 307â€“319.
https://doi.org/10.1145/2786805.2786852[50] Tianyin Xu, Xinxin Jin, Peng Huang, Yuanyuan Zhou, Shan Lu, Long Jin, and
Shankar Pasupathy. 2016. Early detection of configuration errors to reduce
failure damage. In 12th USENIX Symposium on Operating Systems Design and
Implementation (OSDI 16) . 619â€“634. https://doi.org/10.5555/3026877.3026925
[51] Tianyin Xu, Vineet Pandey, and Scott Klemmer. 2016. An HCI view of configura-
tion problems. arXiv preprint arXiv:1601.01747 (2016).
[52] Zuoning Yin, Ding Yuan, Yuanyuan Zhou, Shankar Pasupathy, and Lakshmi
Bairavasundaram. 2011. How do fixes become bugs?. In Proceedings of the 19th
ACM SIGSOFT symposium and the 13th European conference on Foundations of
software engineering . 26â€“36. https://doi.org/10.1145/2025113.2025121
[53] Zhibin Yu, Zhendong Bei, and Xuehai Qian. 2018. Datasize-aware high dimen-
sional configurations auto-tuning of in-memory cluster computing. In Proceedings
of the Twenty-Third International Conference on Architectural Support for Program-
ming Languages and Operating Systems . 564â€“577. https://doi.org/10.1145/3173162.
3173187
[54] Matei Zaharia, Mosharaf Chowdhury, Michael J Franklin, Scott Shenker, Ion
Stoica, et al .2010. Spark: Cluster computing with working sets. HotCloud 10,
10-10 (2010), 95. https://doi.org/10.5555/1863103.1863113
[55] Huazhe Zhang and Henry Hoffmann. 2019. PoDD : power-capping dependent
distributed applications. In Proceedings of the International Conference for High
Performance Computing, Networking, Storage and Analysis, SC 2019, Denver, Col-
orado, USA, November 17-19, 2019 , Michela Taufer, Pavan Balaji, and Antonio J.
PeÃ±a (Eds.). ACM, 28:1â€“28:23. https://doi.org/10.1145/3295500.3356174
740