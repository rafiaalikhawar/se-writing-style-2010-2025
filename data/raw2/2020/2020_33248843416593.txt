Continuous Compliance
Martin Kellogg1,‚àóMartin Sch√§f2Serdar Tasiran2Michael D. Ernst1,2
1University of Washington2Amazon Web Services
USA
kelloggm@cs.washington.edu,schaef@amazon.com,tasirans@amazon.com,mernst@cs.washington.edu
ABSTRACT
Vendorswhowishtoprovidesoftwareorservicestolargecorpo-
rationsandgovernmentsmustoftenobtainnumerouscertificates
of compliance. Each certificateasserts that the software satisfies a
complianceregime,likeSOCorthePCIDSS,toprotecttheprivacy
and security of sensitive data. The industry standard for obtaining
a compliance certificate is an auditor manually auditing source
code.Thisapproachisexpensive,error-prone,partial,andprone
to regressions.
Wepropose continuouscompliance toguaranteethatthecodebase
stays compliant on each code change using lightweight verifica-
tiontools.Continuouscomplianceincreasesassuranceandreduces
costs.
Continuous compliance is applicable to any source-code compli-
ance requirement. To illustrate our approach, we built verification
tools for five common audit controls related to data security: cryp-
tographically unsafe algorithms must not be used, keys must be at
least256bitslong,credentialsmustnotbehard-codedintoprogram
text, HTTPS must always be used instead of HTTP, and cloud data
stores must not be world-readable.
We evaluated our approach in three ways. (1) We applied our
toolstoover5millionlinesofopen-sourcesoftware.(2)Wecom-
pared our tools to other publicly-available tools for detecting mis-
usesofencryptiononapreviously-publishedbenchmark,finding
thatonlyoursaresuitableforcontinuouscompliance.(3)Wede-
ployed a continuous compliance process at AWS, a large cloud-
services company: we integrated verification tools into the compli-
anceprocess(includingauditorsacceptingtheiroutputasevidence)
and ran them on over 68 million lines of code. Our tools and the
data for the former two evaluations are publicly available.
CCS CONCEPTS
‚Ä¢Software and its engineering ‚ÜíSoftware verification ;Au-
tomated static analysis; Data types and structures.
KEYWORDS
compliance,SOC,PCIDSS,FedRAMP,keylength,encryption,hard-
coded credentials, pluggable type systems
* Some of the work was performed while this author was an intern at AWS.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
onthe firstpage.Copyrights forcomponentsof thisworkowned byothersthan the
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or
republish,topostonserversortoredistributetolists,requirespriorspecificpermission
and/or a fee. Request permissions from permissions@acm.org.
ASE ‚Äô20, September 21‚Äì25, 2020, Virtual Event, Australia
¬© 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-6768-4/20/09...$15.00
https://doi.org/10.1145/3324884.3416593ACM Reference Format:
MartinKellogg,MartinSch√§f,SerdarTasiran,andMichaelD.Ernst.2020.
Continuous Compliance. In 35th IEEE/ACM International Conference on
AutomatedSoftwareEngineering(ASE‚Äô20),September21‚Äì25,2020,Virtual
Event, Australia. ACM, New York, NY, USA, 13 pages. https://doi.org/10.
1145/3324884.3416593
1 INTRODUCTION
A compliance regime like the PCI DSS [ 61], FedRAMP [ 35], or
SOC [4] encodes a set of best practices. For example, all of these
regimes require that data be stored encrypted and that the encryp-
tion used be strong.
Manyorganizationsarerequiredbylaw,bycontract,orbyin-
dustry standard to only use software that is compliant with one or
more regime. For example:
‚Ä¢VISA requires companies that process credit card transactions
tousesoftwarethatiscompliantwiththePCIDSS(Payment
Card Industry Data Security Standard) [80]. PCI DSS certifica-
tion assures card issuers that merchants will safely handle con-
sumer credit card data [ 61]. Other card issuers have similar re-
quirements[ 53,71],andsomeU.S.statesdefinenon-compliance
asatype ofcorporatenegligenceforwhich companies canbe
sued [56, 66].
‚Ä¢The U.S. government requires that cloud vendors be compliant
with FedRAMP (Federal Risk and Authorization Management
Program) [35, 78].
‚Ä¢ManycustomersofsoftwareprovidersexpectaSOC(System
andOrganizationControls)report[ 4],whichisusedtoevaluate
how seriously potential vendors take security [2, 42].
When making a purchasing decision, an organization with com-
pliance requirements typically requests an up-to-date compliance
certificate from an accredited third-party auditor, also known as a
Qualified Security Assessor (QSA) [21].
Acomplianceregimeismadeupofmany requirements.Foreach
requirement,theQSAimposessome control‚Äîaspecificrule,usually
defined by industry standard, and a process for enforcing that rule.
For example, a QSA might impose the control ‚Äúuse 256-bit mode
AES‚Äù for the requirement ‚Äúuse strong encryption.‚Äù
A compliance regime may also make requirements about the
processused to create or run the software, such as what data is
logged or which employees have access to data. This paper focuses
on requirements about the source code. Continuous compliance
automates checking of these compliance requirements.
1.1 Problems with manual audits
Currently, the enforcement of source-code controls is primarilymanual: employees of the auditor examine selected parts of the
softwaretoensureitfollowseachcontrol.Thestateoftheartsuffers
the following problems:
5112020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE)
CostTo sell its product, a vendor must participate in audits‚Äî
often multiple times per year to show continuing adherence to
thecomplianceregime.Thevendormustpaythesalaryofits
internal compliance officers, spend engineering time gathering
evidence, and pay external auditors‚Äîoften at significant and
rising expense (more than $3.5 million each for a sample of 46
organizations in 2011) [ 28,63]. A failed audit can cost millions
of dollars more [34].
Judgment Humanscanmakemistakesofjudgment.Engineers
may provide non-compliant code for audit, which may lead to
expensivefailedaudits.Auditorsmayincorrectlycertifynon-
compliantcode‚Äîfalsenegatives.Auditorsmayraiseconcerns
about safe code‚Äîfalse positives that must be investigated at
further expense.
Sampling Auditors routinely sample randomly from the code
underaudit,becauseitistooexpensivetomanuallyexamineit
all. The standard reporting format for a PCI DSS audit includes
a section dedicated to sampling procedures [62].
Regressions Audits occur periodically‚Äîtypically every six or
twelvemonths.Everycodechange isachance forthesoftwaretofall outof compliance. Ina studybyVerizon‚Äôsaudit division,
only52.5%oforganizationswithanactivecompliancecertifi-
cation passed their re-audit without significant changes [77].
Ourgoalistoreducecosts,increaseassuranceandcoverage,and
prevent regressions by deploying lightweight verification tools.
1.2 Our approach: continuous compliance
Wepropose continuouscompliance,whichrunsaverificationtool
on every commit to check compliance properties in source code.
Moreformally,continuouscomplianceistheprocessofautomat-
ically enforcing source-code compliance controls whenever the
code is changed, such as on every compiler invocation, commit, or
pullrequest.Continuouscomplianceisaninstanceofcontinuous
testing [67] and continuous integration [16, 32].
Continuouscomplianceeliminatestheneedformanualaudits
for specific source-code controls, resolving the problems described
insection1.1.Themarginalcostofanauditisnegligible,because
auditors accept the results of running the verifier. The opportu-nity for mistakes is smaller: our tools found dozens of findingsof interest to compliance auditors that all prior approaches hadmissed, because the verifier checks the entire codebase. Regres-
sions are caught immediately when they occur, when it is cheaper
fordeveloperstofixthem[ 17].Evenifcontinuouscomplianceis
implemented only for some source-code controls, it reduces the
scope of manual audits and makes them easier, cheaper, and more
reliable.
Implementingasystemforcontinuouscomplianceischallenging.
Tobeacceptabletoauditors,developers,andcomplianceofficers,
the continuous compliance system must be:
‚Ä¢sound: it must not miss defects. If it might suffer a false nega-
tive(missedalarm),thenamanualauditwouldstillberequired.
‚Ä¢applicable to legacy source-code.
‚Ä¢scalable to real-world codebases.
‚Ä¢simplesothatbothdevelopersandnon-technicalauditorscan
understand it and interpret its output.
‚Ä¢preciseenough to produce few time-wasting false alarms.1.3 Contributions
There are four main contributions of our work:
‚Ä¢aconceptual contribution:therecognitionthatsource-codecom-
plianceisanexcellentdomainforthestrengthsandweaknesses
of (some varieties of) formal verification.
‚Ä¢anengineering contribution: we designed and built five prac-
ticalverificationtoolscorrespondingtocommoncompliance
controls.
‚Ä¢anempirical contribution:weevaluatedtheverificationtools‚Äô
efficacyon654open-sourceprojects.Wealsocomparedthem
to state-of-the-art alternatives to demonstrate that only verifi-
cationtoolsaresuitableforcontinuouscompliance‚Äîunsound
bug-finding tools are insufficient.
‚Ä¢anexperiential contribution:wedeployedcontinuouscompli-
ance at Amazon Web Services (AWS). We report the reactions
of developers and auditors to the introduction of continuous
compliance.Webelievethatthiscontributionisthemostimpor-
tant:itisaconcretesteptowardmakingverificationpractical
for everyday developers.
Ourkeyconceptualcontributionisrecognizingthebenefitsof
verification tools tocompliance auditors. The ideas werenot obvi-
oustocomplianceofficersandauditors.Thestateofthepracticeis
manualcodeexamination,andthestateoftheartisrun-timecheck-
ing. Research roadmaps for improving the certification process do
not even mention source code verification [ 50,52,76]. The ideas
were not obvious to working developers. They believed that formal
verification would require high annotation burden and would pro-
duce many false positive warnings. The ideas were not obvious
totheverificationcommunity,whohavefocusedonprogrammers
(or modelers) rather than other important stakeholders such as
compliance auditors.
Ourengineeringcontributionsaremodestbutnon-trivial.We
implementedfiveopen-sourceverificationtoolsforJava.Thefive
compliance controls are common to many compliance regimes:
encryptionkeys mustbesufficiently long,insecurecryptographic
algorithmsmustnotbeused,sourcecodemustnotcontainhard-
coded credentials, outbound connections must use HTTPS, andcloud data stores must not be world-readable. We implemented
our analyses as typecheckers, because typecheckers scale well and
are more familiar to developers than other automated verification
approaches such as abstract interpretation, model checking, and
SMT-based analysis.
Ourempiricalcontributionsapplythesetoolsto654open-source
projects(section6)andcomparethemtostate-of-the-arttoolsfor
findingmisusesofcryptographicAPIsonapreviously-published
benchmark, with a focus on their suitability for continuous compli-
ance (section 7). Only our tools suffered no false negatives‚Äîthat is,
they did not miss any real problems.
Our experiential contribution is deploying a continuous com-
pliance systemat scale atAWS, as partof its regulardevelopment
process. Currently, 7 of its core services with a compliance require-
mentrunverificationtoolsoneachcommit,ensuringcontinuous
compliance. External auditors accepted our verification tools asreplacements for manual audits for these 7 services (section 8.1).
Both developers andcompliance teams are nowmore receptive to
formal methods than they were before: both AWS and the auditors
512Figure 1: A sample of evidence that the nitor-vault program [79]
only uses 256-bit keys to encrypt data in its source code.
havespokenpubliclyonhowverificationhasimprovedtheirpro-
cess [83]. Security and compliance teams also run verifiers on a
significant fraction of code at the company on a regular schedule‚Äî
themostrecentrun(section8.2)scannedover68millionlinesof
code and required only 23 type annotations.
2 COMPLIANCECERTIFICATIONWORKFLOW
Section2.1describesthestate-of-the-artapproachforcompliance
certification of source-code properties, and section 2.2 describes
ourcontinuouscomplianceapproach.Eachsubsectionhighlights
three key phases of the workflow for comparison:
‚Ä¢development of the source code,
‚Ä¢preparation for an audit, and
‚Ä¢reviewby auditors.
Asarunningexample,considertheindustrycompliancestan-
dard for AES encryption, which is to use the 256-bit mode. This
rule corresponds to Testing Procedure 3.6.1.b in the PCI DSS [61].
2.1 Traditional audit workflow
While developers developsoftware, they must keep in mind the
compliancerulesandmentallychecktheircodeastheywriteit.Be-
cause compliance failures are very serious, significant code review
effort is also expended toward keeping the codebase compliant.
Toprepare for the review, an internal compliance officer re-
questsevidencethat the program uses 256-bit keys. Each engineer-
ingteammusttaketimetorespondtothisrequest.Typically,the
developers search the codebase for encryption keys, API usages,
and related code. The evidence they provide is screenshots like
fig. 1 or links into their codebase.
Atthetimeofthe review,thehumanauditorrandomlysamples
thesecodesnippetsandcheckstheselectedsnippetsmanually.Ifthe
auditor has a concern about the code, they contact the engineering
teamresponsibleandquestionthemaboutthecode.Iftheengineers
are unable to satisfy the auditor, then the auditor refuses to certify
compliance.Thisprocessisdependentontheauditor‚Äôsjudgment
and trust in the engineering teams‚Äîthe auditor only examines a
small part of the code directly.
2.2 Auditworkflowwithcontinuouscompliance
While developers develop software, they write and maintain light-
weight machine-checked specifications of its behavior. In a case
studyatAWS,thesespecificationsconsistedof9annotationsacross
107,628linesofcode(section8.1.1).Theverificationtoolrunson
everycommitand,optionally,everytimethedevelopercompiles
the code. If the tool issues a warning, the developer examines it. If
the warning is a true positive‚Äîthat is, the code is incorrect‚Äîthe
developerfixesthecode.Ifthewarningisafalsepositive,thede-
veloper suppresses the warning and writes a brief explanation as aCipher cipher = Cipher.getInstance("AES/ECB/PKCS5Padding");
cipher.init(Cipher.ENCRYPT _MODE, mySecretKey);
return cipher.doFinal(message);
Figure 2: Code example for encrypting a message. A common com-
pliance requirement is that the algorithm name that is passed to
Cipher.getInstance must be FIPS compliant [1].
code comment, which creates an easily searchable audit trail in the
code.Suppressingawarningwasnecessaryonlyonceinover68
million lines of source code at AWS (see section 8).
No action is needed to preparefor a review.
At the time of the review, the auditor rejects the code if the
verification tool outputs any warnings. If developers suppressed
any warnings, the auditor inspects the code near the suppressed
warning(theyareautomaticallysearchable).Theauditorcanalso
check the implementation of the verification tool, which is very
short,changesrarely,andispubliclyavailable.Inourexperience,
auditors are willing to accept that the tool is part of the trusted
computing base, in much the same way that they do not inspect
the compiler.
3 CONTINUOUS COMPLIANCE CONTROLS
We have implemented verification tools for the following controls.
3.1 Cryptographic key length
The PCI DSS and other compliance regimes require strong encryp-
tionkeystobeused.Inpractice,acontrolusedforthisrequirement
is that encryption keys must be sufficiently long. Our analysis han-
dles 4 key-generation libraries.
For javax.crypto.spec ,aSecretKeySpec objectmaybeconstructed
using a length parameter ‚â•32 (since it is specified in bytes) or a
byte array that is at least 32 bytes long.
For java.security.SecureRandom ,the nextBytes(byte[]) methodmust
bepassedanarrayofatleast32bytes,and next(int)mustbepassed
an integer ‚â•256. Both methods are often used to generate keys.
For org.bouncycastle.crypto ,e v e r y KeyGenerationParameters object
must be constructed with a strengthargument that is ‚â•256.
ForAWS‚ÄôsKeyManagementService(KMS)[ 19],adatakeymust
be at least 256 bits long. A client sets the size of the generated data
key by calling methods on a ‚Äúkey request object‚Äù:
‚Ä¢call withNumberOfBytes(int) with a value ‚â•32, or
‚Ä¢call withDataKeySpec(String) with the string "AES_256",o r
‚Ä¢call withDataKeySpec(DataKeySpec) with DataKeySpec.AES _256.
3.2 Cryptographic algorithms
Another common requirement in compliance regimes is the use
ofstrong cryptographic algorithms [61]. Figure 2 shows a use of
encryptioninJava.Acompliancecontrolforthiscodeisthatthe
string passed into the JCE method Cipher.getInstance must be on an
allow list from the compliance regime [1, 10].
AWShadpreviouslywrittenalexicalanalysistovalidateuses
ofcryptographicAPIs,butitwasnotsufficient.Infigs.1and2,a
literal is the argument to a key-generation routine, but this was
rarely the case at AWS, whose default style guide suggests the use
of static final fields. These fields are not necessarily in the same
classasthemethodcall,andthevaluescanbeheldinvariablesand
513passed around the program. Another failed attempt at AWS was to
searchforallstringliteralsintheprogramandrejecttheprogramif
anyliteralstringwasnotonthecomplianceallowlist.Thissufferedtoomanyfalsepositivesthatrequiredhumanexamination,because
differentalgorithmsarepermittedfordifferentuses.Theseissues
motivated the need for a semantic analysis like ours.
3.3 Web requests
PCIDSSrequirement4.1[ 61]mandatesthatcommunicationacross
opennetworksbeencrypted;othercomplianceregimeshavesimilarrequirements.Acommoncontrolfortheserequirementsisthatweb
requests be made over HTTPS rather than over HTTP. In practice,
thiscontrolissatisfiedinJavacodebycheckingthatstringspassed
to the URL constructor start with ‚Äúhttps‚Äù. A syntactic check is
insufficient:aURLmightbeconstructedbyconcatenatingseveral
variables, or might be stored in a field far from its use.
3.4 Cloud data store initialization
Data subject to compliance requirements is sometimes stored inthe cloud. Even if the cloud provider has the appropriate compli-
ance certification, there are often additional controls on how cloud
services are used.
For example, third-party guidelines for HIPAA-compliant use of
Amazon S3 [5, 57], a popular object storage service, include:
‚Ä¢new buckets must not be, and cannot become, world-readable,
‚Ä¢new buckets must be encrypted, and
‚Ä¢newbucketsareversioned,sothatdataisnotlostifoverwritten.
Enforcingtheseguidelinesrequirescheckingthatthecorrespond-
ingsettermethodsofthebuilderusedtoconstructthebucketare
called, and that their arguments are certain constant values.
3.5 Hard-coded credentials
Credentials ‚Äîpasswords,cryptographickeys,etc.‚Äîmustnotbehard-
codedinsourcecode.ThePCIDSShasanentiresection(¬ß8)devoted
to requirements on passwords [ 61]. Hard-coded credentials violate
several of these requirements: that passwords must be unreadable
duringstorageandtransmission(¬ß8.2.1)andthatcredentialsnot
be shared between multiple users (¬ß8.5).
Our analysis handles these APIs:
‚Ä¢Inthe java.security package, SecureRandom mustnotbeinitialized
withahard-codedseed. KeyStore‚Äôsstoreand loadmethodsmust
not use a hard-coded password.
‚Ä¢In the javax.crypto.spec package, these must not be hard-coded:
SecretKeySpec ‚Äôskeyparameter, PBEKeySpec ‚Äôspasswordparameter,
PBEParameterSpec ‚Äôssaltparameter, and IvParameterSpec ‚Äôsivpa-
rameter.
3.6 Other controls
Ourvisionforcontinuouscompliance‚Äîthatis,automatedchecking
of source-code compliance properties‚Äîis broad. The above are just
afewexamplesofcontrolsthatcanbeenforcedusingcontinuous
compliance.Webelievethatanycompliancerequirementcurrently
controlled by manual audits of source code could be automated
using our proposed approach of lightweight verification tools. Theaudit procedure is designed to be tractable for a human unfamil-
iarwiththesourcecode,sothepropertytobecheckedisusually
simple and local‚Äîwhich both make it likelier to be amenable to
programanalysis.Twofurtherexamplesthatwehaveprototyped
arethatdatamustbeencryptedatrest(thatis,whenstoredondisk
as opposed to in RAM) and data must be protected by a checksum.
The procedure to implement a new analysis (which we followed
fortheabove)is:talktotheauditors,findachecktheycurrently
enforce with manual code audits, then formalize and implement it.
4 TECHNICAL APPROACH
In order to satisfy the requirements of section 1.2, we designed
dataflow analyses to perform verification.
4.1 Dataflow analysis via typechecking
Wechosetoimplementeachanalysisasatypesystem.Thecontinu-
ouscomplianceapproachcanbeinstantiatedwithotherautomated
verification techniques, such as abstract interpretation or symbolic
execution. We chose type-checking because it was already familiar
to the Java developers at AWS. Type-checking is also modular, fast,
and scalable. Pluggable type-checking is sound [ 30], and the proof
extendsdirectlytoallthetypesystemsinthispaper(proofsomitted
for space).
Our implementation uses the Checker Framework [ 59], a frame-
work for building pluggable typecheckers for Java. Our implemen-
tation handles all Java features, including polymorphism. It per-forms local type inference within a method body, so developers
write annotations only at method boundaries, where they serve as
machine-checked documentation.
Aswithanytypesystem,everyassignmenttoavariablemust
be from an expression whose type is a subtype of the variable‚Äôsdeclared type. For example, when a formal parameter type has a
qualifier,itisatypeerrorifanycallsite‚Äôsargumentdoesnotsatisfy
the given property.
4.2 An enhanced constant value analysis
Our analysis needs to estimate, for each expression in the program,
whether the expression‚Äôs value is any of the following:
‚Ä¢single integer value.
‚Ä¢single string value.
‚Ä¢setsofvalues.Forexample,anexpressionmightbeknownat
compiletimetoevaluatetooneofthestrings "aes/cbc/pkcs5padding" ,
"aeswrap",o r "rsa/ecb/oaeppadding" .
‚Ä¢integer ranges, including unbounded ones.
‚Ä¢estimates of array lengths, and sets of them.
‚Ä¢user-defined enumerated types, and sets of them.
‚Ä¢regular expressions to represent sets of strings, and sets of
regular expressions so users do not need to write disjunctions
within regexes.
A traditional constant propagation and folding analysis [ 81]
handlesthefirsttwofeatures.Weuseanenhancedconstantfoldingandintervalanalysisthathandlesthethirdandfourthfeatures[
23].
Weuseanarrayindexinganalysisthathandlesthefifthfeature[ 44].
We made numerous bug fixes and enhancements to the existing
tools to improve precision. We designed and implemented the last
two features (sections 4.3 and 4.4).
514Table1:Examplesofannotationsfrom[23]thatareusedbyourveri-
ficationtool.Allannotationargumentsarecompile-timeconstants.
Declaration Meaning
@IntVal(42) int x xhas exactly the value 42
@StringVal( {"a", "b" }) String s s has the value "a"or"b"
@IntRange(from=0, to=9) int x x ‚Äôs value is in the range [0,9]
byte @ArrayLen(32) [] a acontains exactly 32 elements
Ourimplementationexpressesabstractvaluesastypes.Forex-
ample, @IntVal({-1, 1}) is a type qualifier, and the type ‚Äú @IntVal({-1,
1}) int‚Äù represents an integer whose run-time value is either -1 or
1;equivalently,itrepresentstheset {‚àí1,1}.Table1showsthemost
important abstractions of the constant value analysis. Our type
systems use and/or extend these abstractions. The type hierarchy
appears in [23, 44]; our extensions fit in naturally.
4.3 Enums
Tohandleenums,werepurposedtheexistinghandlingofstrings
(the @StringVal annotation). Our implementation treats the enum
name as the string value. This implementation approach re-uses
existing logic without the need for code duplication.
4.4 Regular expressions
We added anewabstraction @MatchesRegex that expresses apossibly-
infinite set of strings via a set of regular expressions. For exam-
ple [68]:
class Cipher {
static Cipher getInstance(@MatchesRegex({"aes/gcm. *", "rsa/ecb. *"})
String algorithm);
}
Thetypeofthe algorithmparameteris @MatchesRegex(...) String ,and
it restricts the values that may be passed as arguments.
Subtypingforregularexpressiontypesisahardproblem.Sub-
sumption for regular expressions is EXPTIME-complete [ 69]. Stan-
dard(butnotregular)featuressuchasbackreferencesmakeeven
regexmatching NP-hard [ 26]. Precise subtyping for regular expres-
siontypes[ 33,37]isasleastashardastheseproblems.However,we
need a fast, decidable algorithm that is understandable to develop-
ers.Ourimplementationimposesthefollowingsound,approximate
subtyping relationship ( ùëÜ1andùëÜ2are sets of regular expressions):
ùëÜ1‚äÜùëÜ2
@MatchesRegex( ùëÜ1) String <:@MatchesRegex( ùëÜ2) String
This approximation was always adequate in our case studies.
Atypequalified by @StringVal canbea subtypeofonequalified
by@MatchesRegex (ùë†ùëòis a string and ùëüùëòis a regular expression):
‚àÉùëñ,ùëó:ùë†ùëñ.matches( ùëüùëó)
@StringVal({ ùë†1,...,ùë†ùëö}) String
<:@MatchesRegex({ ùëü1,...,ùëüùëõ}) String
No other types are subtypes of @MatchesRegex(...) String . If another
typeflowstoanexpressionwithsuchatype(includingstringvalues
not in the allow list), the tool issues a warning.4.5 Type inference
We implemented a whole-program type inference tool [ 24] that
inferstypesviafixpointanalysis.TheCheckerFrameworkimple-
ments local (intra-method) type inference. The type inference tool
repeatedly runs a type-checker, records the results of local type
inference, and appliesthem to the next iteration. Theannotations
are stored in a side file to avoid changing programmers‚Äô source
code. When a fixed point is reached, the user is shown the final
results of type-checking.
For example, consider the following program:
int id(int y) { return y; }
i n tx=1 ;id(x, ...);
Typeinferenceonthepossibleintegervaluesinthisprogramwould
produce three @IntVal(1) annotations:
‚Ä¢one on the field x, because 1is assigned to x,
‚Ä¢one on the parameter y, because idis called with xas an argu-
ment, and
‚Ä¢oneonthereturnvalueof id,becausethereturnvalueflows
from the parameter
To annotate the above program, our type inference approach
would take three rounds, one for each of the required annotations,
because each is dependent on the previous one. Note that this type
inferenceapproachissound,becauseitstillrunstheverifieronthe
annotatedcode:ithasthesameinterfacetotheverifierasahumanannotator.Bythesametoken,inferencecanwriteoverly-restrictive
types, as in the example above ( id‚Äôs parameter and return type are
annotated as @IntVal(1) , but a human would have instead written a
polymorphic specification).
Type inference is useful to auditors who otherwise would be ill-
equipped to reason about source code. It also enables type systems
whoseannotationburdenwouldbeimpracticalforahuman(see
section 5.5).
5 VERIFYING COMPLIANCE CONTROLS
This section details the verification tools we built to verify that
Java programs are compliant with the controls in section 3. Our
framingoftheproblemmadeitsimpletoexpressandimplement
the dataflow analyses.
5.1 Cryptographic key length
Our key-length typechecker is just an application of our enhanced
constant value analysis.
AnyanalysisrequiresaspecificationoflibraryAPIs.Thisone-
time, manual process is performed by a verification engineer work-ingwithacomplianceofficer.Oncewritten,thespecificationcanbere-useduntilthelibraryinterfacechanges(whichishighlyunlikely)
or the compliance regime is updated (which is rare).
Figure 3 is the full specification for the KMS API. When these
restrictions on all uses of the API are enforced at compile time, no
datakeycanbegeneratedthatissmallerthan256bits,meetingthe
compliancecontrolinsection3.1.Thespecificationsfortheother
libraries of section 3.1 are similar but simpler; fig. 3 is the largest.
515package com.amazonaws.services.kms.model;
class GenerateDataKeyRequest {
withKeySpec(@StringVal("AES _256") String keySpec);
withKeySpec(@StringVal("AES _256") DataKeySpec keySpec);
withNumberOfBytes(@IntRange(from=32) Integer numberOfBytes);
setKeySpec(@StringVal("AES _256") String keySpec);
setKeySpec(@StringVal("AES _256") DataKeySpec keySpec);
setNumberOfBytes(@IntRange(from=32) Integer numberOfBytes);
}
class GenerateDataKeyWithoutPlaintextRequest {
withKeySpec(@StringVal("AES _256") String keySpec);
withKeySpec(@StringVal("AES _256") DataKeySpec keySpec);
withNumberOfBytes(@IntRange(from=32) Integer numberOfBytes);
setKeySpec(@StringVal("AES _256") String keySpec);
setKeySpec(@StringVal("AES _256") DataKeySpec keySpec);
setNumberOfBytes(@IntRange(from=32) Integer numberOfBytes);
}
Figure3:OurfullspecificationforAWSKMS.Theselibraryannota-
tions guarantee that the keys KMS generates are 256 bits or more.
5.2 Cryptographic algorithms
Ourcryptographicalgorithmtypecheckerisimplementedontop
of the enhanced constant value analysis.
Weannotatedlibrarymethodsthatacceptcryptographicalgo-
rithmsasinput,suchas javax.crypto.Cipher orjava.security.Signature ,
with an allow list of accepted algorithm names.
For user convenience,our tool defines @CryptoAllowed as an alias
for @MatchesRegex .@CryptoAllowed behaves identically but makes it
clear to readers that the code is cryptographically relevant.
Ourtoolhasaliasesofparticular @CryptoAllowed annotationsfor
eachcomplianceregime. @CryptoAllowedPCI ,forexample,corresponds
totherequirementsofthePCIDSS.Eachaliasisdefinedonce,bya
cryptography expert and a compliance officer together. A welcome
side effect of centrally-defined allow-listing annotations is that ad-
justing the analysis to changes in compliance requirements is easy:
the regular expressions in the allow list can be updated without
changing any program source code, not even type annotations.
5.3 Web requests
Ourwebrequesttypecheckerisasimpleextensiontoconstantvalue
analysisthatintroducesanewannotation. @StartsWith("x") issyntac-
ticsugarfor @MatchesRegex("x. *").Forexample, @StartsWith("https://")
matches "https://www.foo.com" but not "foo"or"http://www.foo.com" .
5.4 Cloud data store initialization
To prove that a new Amazon S3 bucket is properly initialized, two
kinds of facts are necessary:
‚Ä¢setter methods for the required properties on the Bucketor
BucketProps builder object must have been called, and
‚Ä¢the arguments to the setter methods must be certain constants.
Forexample,toshowthatabucketisversioned,the versioned(boolean)
method must be called, and its argument must be true.
Fortheformer,ouranalysismusttrackthesetofmethodsthat
havedefinitelybeencalledonthebuilderobject,andcheckthatthe
required methods are all included in the set when buildis called.
An accumulationanalysis [ 45], arestricted form of typestateanal-
ysis[73]thatdoesnotrequireawhole-programaliasanalysisforsoundness, can verify that all required methods are called on a
builder.Weusedtheimplementationfrom[ 45]andwrotespecifi-
cations for Bucketand BucketProps .
Our enhanced constant value analysis handles the latter.
5.5 Hard-coded credentials
We implemented a dataflow analysis (similar to taint tracking [ 39])
to track the flow of manifest literals through the program. Thesources in our taint analysis are manifest literals in the program
text(strings like "abcd",integerslike 5,bytearrays like {0xa, 0x1} ,
etc.).ThesinksarecallstotheAPIsinsection3.5.Thetypechecker
enforces that manifest literals do not flow to the sinks.
Our type system has two type qualifiers:
‚Ä¢@MaybeDerivedFromConstant is the type of any manifest literal, and
of any expression into which a manifest literal might flow. For
example, "abcd"and x+1have this type.
‚Ä¢@NonConstant is the type of any other expression in the program.
It is the default qualifier, meaning that an unannotated type
like Stringactually means @NonConstant String .
@NonConstant isasubtypeof @MaybeDerivedFromConstant .Thismeansthat
a program may assign a non-constant value to a variable whose
type is qualified with @MaybeDerivedFromConstant , but not vice-versa.
5.5.1 Using whole-program type inference. Thistaint-trackingtype
system requires substantially more user-written annotations than
theprecedingconstant-propagationtypesystems,becausemany
variables and values in programs are derived from constants.
Ingeneral,typeinferencefortaint-trackingisdifficult,becausea
humanmustfirstlocateallthesourcesandallthesinks.Inourcase,however,thesourcescanbeidentifiedautomatically(manifestliter-alsintheprogram),andthesinksareknownaheadoftime(theAPIs
listed in section 3.5). The inference tool (section 4.5) can therefore
determinewhethereachprogramelementmighthavebeenderived
from a constant, without the need for human intervention‚Äîthat is,
all required annotations can be derived automatically.
6 CASESTUDYONOPEN-SOURCESOFTWARE
To permit reproduction, we open-sourced our tools [ 6,7,18,58]
and applied them to open-source software. The scripts and dataused for sections 6 and 7 are available at https://doi.org/10.5281/
zenodo.3976221.
6.1 Methodology
For each API mentioned in section 3, we searched GitHub for
projects that contain at least one use of the relevant API. We used
all projects for which running a standard Maven or Gradle build
task( mvn compile orgradle compileJava )intherootdirectorysucceeds,
under either Java 8 or Java 11.
Running our tool requires supplying a -processor argument to
each invocation of javac. We augmented do-like-javac [ 43] for that
purpose. It first runs the build system in debug mode and scans
thelogsforinvocationsof javac.Then,itreplaysthoseinvocations,
with the -processor command-line argument added, in the same
environment‚Äîfor example, after other build steps that compilation
may depend on. Sometimes, replaying the build is not success-ful; this is reported as ‚Äúinfrastructure error‚Äù in table 2. The most
516Table2:Ourverificationtools,runonopen-sourceprojectsthatuse
relevant APIs. Ver is verified projects. TP is projects with true pos-
itives, but no false positives. T&FP is projects with both true andfalse positives. FP is projects with false positives, but no true posi-tives. IE is ‚Äúinfrastructure errors‚Äù: projects on which do-like-javacfails. TO is timeouts (1-hour limit). Total is the total number of
projects.TheLoCcolumnomitsinfrastructureerrorsandtimeouts.
Throughout, LoC is non-comment, non-blank lines of Java code.
API Ver TP T&FP FP IE TO Total LoC
Key Length 27% 22% 12% 9% 8% 23% 78 373K
Crypto. Algos. 19% 42% 8% 3% 11% 17% 237 2.4M
Web Request 56% 6% 13% 6% 0% 19% 16 6K
Cloud Data 21% 68% 0% 5% 0% 5% 19 5K
Credentials 26% 15% 15% 22% 15% 7% 304 3.0M
Total 157 176 77 82 78 84 654 5.7M
24% 27% 12% 13% 12% 13% 100%
common reasons are that the project‚Äôs custom build logic is not
idempotent,therearenoobservablejavaccommands,ortheproject
uses javac options that are incompatible with the -processor flag.
Tofullyautomatetheprocess,weranallverifierswithwhole-
program inference (section 4.5) enabled. We set a timeout of one
hour. Our verifiers are fast, but inference might not terminate. Our
typecheckerscontainwideningop eratorstoprev entinfiniteascend-
ing chains, but do not contain corresponding narrowing operators.
Insomecases,inferencethereforeintroducesaninfinitedescending
chain, leading to a timeout.
Wemanuallyinspectedeachwarningissuedbyeachverifier,and
classified it as a true positive (a failure to conform to a compliance
requirement) or a false positive (a warning issued by the tool that
doesnotcorrespondtoacomplianceviolation).Wecountedcrashes
and bugs in the Checker Framework as false positives.
6.2 Findings
Table 2 shows the results. The key takeaways of our study were:
‚Ä¢Muchopen-sourcesoftware,initsdefaultconfiguration,con-
tains compliance violations. Compliance officers should review
open-source software before it handles customer data.
‚Ä¢Mostwarningsweretruepositives.Amajorattractionofun-
sound bug-finding tools is that they tend to have low false-
positiverates,butoursoundverificationtoolsdoreasonably
well(seesection7foradirectcomparisontobug-findingtools).
Themajority(72%)offalsepositivesareissuedbythecredentials
checker.Therelativelyhighrateoffalsepositivesfromthischecker
is due to the limitations of the type inference tool (section 4.5):itcannotalwaysinfertheappropriatetypequalifiersfortypear-guments (Java generics). Any time it is incorrect, the credentials
checker issues a false positive.
6.3 Example compliance violations
Figure 4 shows two examples of compliance violations:
(a)AnHSM(HardwareSecurityModule)simulator[ 38]usesthe
DESencryptionalgorithm.AnHSMisaphysicaldeviceused
for managing encryption keys. Practical brute-force attacks
against DES were public knowledge as early as 1998 [31].if (sCommand.contains("#S#>")) {
SecretKey sk _w_key_VNN = new SecretKeySpec(b _w_key_VNN, "DES");
...
}
(a) An example use of an insecure encryption algorithm.
private static final String KEY = "j8m2gnzbvkavx7c2a94g";
...byte[] keyBytes = KEY.getBytes("UTF-8");MessageDigest sha = MessageDigest.getInstance("SHA-1");keyBytes = sha.digest(keyBytes);SecretKeySpec secretKeySpec = new SecretKeySpec(keyBytes, "AES");
(b) An example use of a hard-coded key.
Figure 4: Example compliance violations our checkers found.
(b)Acommand-lineemailclient[ 70]usesahard-codedkey.The
SecretKeySpec thus generated is used to encrypt user passwords,
a major security risk.
The maintainers of these projects might not consider these com-
pliance violations to be bugs, because they might not care about
whethertheirprojectsareusableincontextsthatrequirecompli-
ancecertification,suchaseducation,healthcare,commerce,orgov-
ernment work. However, if theseprojects were to be used in such
contexts, each compliance violation would be a serious concern.
7 COMPARISON TO OTHER TOOLS
We compared our tool to previous tools for preventing misuse
of cryptographic APIs. Previous tools do not warn about short
keylengthsormisuseofcloudAPIs,soourevaluationfocuseson
selectingcryptographicalgorithms,hard-codedcredentials,andthe
useofHTTPvs.HTTPS.ThedevelopersofCryptoGuard[ 65]have
developedamicrobenchmarksetofmisusesofcryptography,which
they call CryptoAPIBench [ 3]. Their paper evaluates CryptoGuard
against SpotBugs, Coverity, and CogniCrypt ùëÜùê¥ùëÜùëá. We repeated
theirexperiments,andextendedthemtoincludeourverification
tools,forthesubsetoftheirevaluationthatourtoolscover(11/16
categories of cryptographic misuse). We evaluated on two versions
ofthebenchmark:theoriginalandaversionwhoselabelingofsafe
and unsafe code reflects compliance rules.
7.1 Tools compared
Wecomparedourverifiertofourstate-of-the-arttoolsthatdetect
misuses of cryptographic APIs.
‚Ä¢SpotBugs[ 25]isthesuccessorofFindBugs[ 8],aheuristic-based
staticanalysistoolthatusesbugpatterns.Somebugpatterns
relatetocryptography.Itisheavilyusedinindustry.Weused
two versions of SpotBugs, configured differently: the standard
desktop version 4.0.2 ( SpotBugsD), and version 3.1.12 config-
ured with the ruleset from the SWAMP [ 74], which contains
additionalsecuritybugpatterns( SpotBugsS).Forbothversions,
we only enabled warnings in the SECURITYcategory.
‚Ä¢Coverity[ 13]isacommercialbug-findingtool.WeusedCover-
ity‚Äôs free trial in April 2020 for the experiments in this section.
They provided no version number.
‚Ä¢CogniCrypt ùëÜùê¥ùëÜùëá[47] is a tool that checks user-written specifi-
cations (in the custom CrySL language) consisting of typestate
517Table 3: Comparison of tools for finding misuses of cryptographic
APIs, on relevant parts of CryptoAPIBench.
Spot- Spot- Cover- Cogni- Crypto- This
BugsDBugsSity Crypt Guard paper
Original Labeling
Precision - 0.46 0.67 0.69 0.86 0.78
Recall 0.0 0.24 0.29 0.66 0.93 1.0
Compliance Labeling
Precision - 0.69 1.0 0.79 1.0 0.97
Recall 0.0 0.32 0.38 0.61 0.88 1.0
properties, required predicates, forbidden methods, and con-
straints on method parameters using synchronized push-down
systems. We used CrySL version 2.7.1 for these experiments,
with the included JCA rules.
‚Ä¢CryptoGuard[ 65]isabug-findingtoolaugmentedwithaslicing
algorithm to allow it find more bugs. Its design emphasizes
maintainingalowfalsepositiveratewhilescalingtorealistic
programs. We built CryptoGuard from source code [22].
Thesetoolsweredesignedtopreventmisuseofcryptography1,not
tosupportthecompliancecertificationprocess.Thesetwogoalsare
related‚Äîboth aim to reduce the number and cost of vulnerabilities
that occur in the wild‚Äîbut lead to different design choices:
‚Ä¢Bug-finding tools like the above four tools aim for low false
positive rates (high precision, or high confidence that eachreported warning is useful), even at the cost of false nega-
tives(unsoundness)[ 40].Bycontrast,automatedcompliance
requires verification‚Äîno false negatives. Given an unsound
tool,thecodewouldstillneedtobeauditedbyhandincasethe
tool missed an error. Put another way, auditors prefer sound
approaches over manual examination, and they prefer manual
examination over unsound tools.
‚Ä¢Compliancerequirementscanbestrongerthantypicaldevel-
oper guidelines. For example, section 3.1 describes the compli-
ance requirement to use a 256-bit key. None of the above tools
implementsthischeck,so(toavoiddisadvantagingthosetools)
we did not use it in our comparison.
7.2 Results
Table3showstheresultsofthecomparison.Precisionandrecall
are defined identically to CryptoAPIBench [ 3]. Our numbers differ
from[3]slightlybecauseweusednewerversionsofthetools.Only
our verifier achieves 100% recall; the other tools are unsound.
Fromacomplianceperspective,CryptoAPIBenchmisclassifies
some unsafe code as safe:
‚Ä¢CryptoAPIBench labels 19 unsafe calls in unexecuted code,
similar to fig. 5, as safe.
‚Ä¢CryptoAPIBench‚Äôs ‚Äúinsecure asymmetric encryption‚Äù require-
ment allows any RSA algorithm, so long as the key is not 1024bits. Our compliance controls also specify the padding scheme
becausetherearepublishedattacksagainstthedefaultpadding
scheme used by Java [ 14]. CryptoAPIBench labels 11 calls to
Cipher.getInstance("RSA") that use the default padding as safe.
1The tools also have other capabilities, but our evaluation focuses on this aspect of
their functionality.public SecretKey getKMSKey(final int keyLength) {
GenerateDataKeyRequest request = new GenerateDataKeyRequest();
if (keyLength == 128) {
request.withKeySpec(DataKeySpec.AES _128);
} else {
request.withKeySpec(DataKeySpec.AES _256);
}// set other parameters...GenerateDataKeyResponse response = awsKMS.generateDataKey(request);...
}
Figure5:Codefromaservicewithacodepaththatcouldhavebeen
used to generate a 128-bit key.
The‚Äúcompliancelabeling‚Äùintable3reclassifiesthesecallstoreflect
compliance rules.
Overall, the results show the promise of sound approaches to
detecting and preventing program errors, such as misuses of cryp-
tography, with high precision while maintaining soundness.
8 CASE STUDIES AT AWS
We performed two case studies at Amazon Web Services (AWS).
Inthefirstcasestudy,7teamswithacompliancerequirement
ran the key-length verifier (section 3.1) on each commit. If the veri-
fier fails to prove compliance, their continuous delivery process is
blocked.Thiscasestudyshowsthattheverifierisrobustenough
tobedeployedinarealisticsetting,andthatdevelopersandcom-
plianceofficers seeenough valuein ittoopt intoa verification tool
that could block deployment.
In a second case study, we ran both the key-length verifier and
the cryptographic algorithm verifier as part of large-scale security
scanning infrastructure. This second case study shows that both
verifiers can be easily integrated in an automated system, and that
they produce high-quality findings.
8.1 Continuous delivery case study
This case study investigates whether a) compliance officers care
about the output of our verifier, and b) developers accept a verifica-
tion tool as part of their continuous integration. Some key findings
of this case study were:
‚Ä¢TheverifierreportsnowarningsonanyofthecoreAWSser-
vices that were subject to compliance requirements.
‚Ä¢Old manual audit workflows missed compliance-relevant code.
‚Ä¢Using verification tools saved time and effort for developers.
‚Ä¢Developers who were initially skeptical of formal verification
technology were convinced of its value by our tool‚Äôs ease of
use and effectiveness.
8.1.1 Results. The key-length verifier was easy to use. Develop-
ers had to write only 9 type qualifiers in 107,628 lines of code: 3
@StringVal annotations, 4 @IntValannotations, and 2 @IntRangeanno-
tations.Thetoolissuedonly1warningthatthecomplianceofficersdidnotconsideratruepositive.Thiswasaneasydecisionforthem:
the code was manifestly not compliance related. We determined
thatitwascausedbytheCheckerFramework‚Äôsoverly-conservative
polymorphic (that is, Java generics) type inference algorithm [54].
Whilerunningtheverifiers,developersfoundseveralservices
that were compliant but error-prone or confusing. As one example,
518consider the code in fig. 5. This code can generate a 128-bit key,
but its clients never cause it to do so. A developer verified thisfact by changing the type of the
keyLengthparameter from intto
@IntVal(256) int and runningour verification tool.It verifiedevery
client codebase, proving that the keyLength == 128 codepath is not
used. Without a verification tool like ours that can run on each
commit, the presence of such code paths, even if unused, is danger-ous:adevelopermightchangeclientcode,orwritenewclientcode,
withoutconsideringthecompliancerequirement.Ourtoolallows
developers to discover unsafe code paths, and also to be certain
that they are not being used when they are discovered.
Atthe timeofwriting, thecontinuousintegration jobhasrun
1426 times and has issued a warning 3 times, each of which was
quickly fixed. The small number of failures is probably because
most developers run it on their local machines before committing.
We do not know how many of those local runs have revealed a
problem with the code.
Another discovery while typechecking was that four services
hadprovidedincompleteevidencetoauditors:theevidencedidnot
cover every part of their codebase that generated encryption keys.
Developers explained that they had not realized that those parts of
thecodewerecompliance-relevant.Bycontrast,ourverifierchecks
allofthecode.Theexternalauditorswereparticularlyexcitedby
this finding: one said that ‚Äúit eliminates a lot of the trust‚Äù that
auditorspreviouslyneededtohaveinengineeringteamstoprovide
them with complete evidence.
Externalauditorswereexcitedtobeonthecuttingedgeofau-
tomation for compliance: they can advertise as providing higher
assurancethanotherauditors,andtheircostsgodown.TheAWS
internal compliance officers can continuously monitor compliance
via continuous integration jobs triggered on every commit.2
AWS encourages its customers, and providers of third-party
services, to use these tools [83].
8.1.2 Developers‚Äô reactions. We began rolling out our verification
tools to compliance-relevant services at AWS in September 2018.
Tooursurprise,weencounteredlittleresistanceaswebeganthe
rollout‚Äîthe first team we contacted immediately integrated the
key-lengthverifierandenableditintheircontinuousintegration
process,andthencanceledthemeetingwehadscheduledwiththem.
Theseearly-adoptingdeveloperstoldusthattheywerefrustrated
bycompliance‚Äôsongoingcost:gatheringevidenceisanirritating
distraction from their regular work.
Other engineering teams are also convinced. Each team saves
time by not having to prepare for audits. One developer told us,
‚ÄúTheCheckerFrameworksolutionisagreatmechanismandstep
toward automating audit evidence requests. This has saved myteam 2 hours every 6 months and we also don‚Äôt have to worryabout failing an audit control.‚Äù (The 2-hour savings is per team,
percontrol,forthedevelopersalone.)Theeffortofonboardinga
projecttouseaverificationtoolislessthantheengineeringcostofprovidingevidencefortheveryfirstaudit,nottomentionsavingstocomplianceofficersandtheexternalauditor.Afterthat,thesavings
accumulate.
2They set up a second CI service, so that compliance is monitored even if the engi-
neering team were to disable the verifier in their CI setup.Table 4: Running the key length and crypto algorithm verifiers at
AWS. The key length verifier is only run on packages that use the
specific library routine. The crypto algorithm verifier is run on a
subset of all Java code at AWS.
Key length Crypto algorithms
Verified, no annotations 215 packages 37,077 packages
Verified, annotations 23 packages 0 packages
True positive warning 15 packages 158 packagesFalse positive warning 1 package 0 packages
Total 254 packages 37,235 packages
8,481,188 LoC 68,416,620 LoC
8.2 Scanning-at-scale case study
Inthesecondcasestudy,asecurityteamrantwoofourverifiers
(key-length and crypto algorithms, sections 5.1 and 5.2) on code
beyondwhatneedstobeaudited.Thiscasestudydemonstratesthat
our approach requires few developer-written annotations and that
warningsoftenrevealinterestingissues.Ourverifiersareintegrated
into a system that scans a set of highly-used packages on a fixed
schedule.Findingsofthesescansarereportedtosecurityengineers
and triaged manually.The security team is interested in analyzers
that report security-related findings that can be triaged without
in-depthcodeknowledge,andthathaveasignal-to-noiseratiothat
is manageable by a security engineer.
Table 4 categorizes each package into one of four categories:
Verified, no annotations : The verifier completed successfully
without any manually written annotations. If subject to a com-
pliance regime, these codebases would be verifiable withoutany
human onboarding effort.
Verified,annotations : The verifier initially issued an error on
these codebases. After writing one or more type annotations in the
codebase,theverifiersucceeds.Ifsubjecttoacomplianceregime,
theseprojectswouldbeverifiable withhumanonboardingeffort.In
23 cases (once in each of 23 packages), the call to a key generation
library was wrapped by another method; a developer had to write
one annotation to specify each wrapper method. Because type-
checkingisintraprocedural,anannotationmustbeplacedwhere
relevantdataflowscrossprocedureboundariesorentertheheap.
Thetypecheckerissuesawarningifaneededannotationismissing.
Thus,developers canuse thetoolto identifythese locations.Note
thatdeveloper-writtenannotationsarechecked,nottrusted.The
only trusted annotations are those for libraries (e.g., fig. 3).
True positive : The verifier issued an error that corresponds to
a compliance violation, if that codebase were to be subjected to
acomplianceaudit.Thekeylengthverifierfound15instancesof
code that used 128-bit keys. The crypto algorithm verifier found
158 uses of weak or outdated crypto algorithms. AWS‚Äôs internal
complianceofficersconfirmedthatnoneofthesecodebaseswere
actually subject to audits. All true positives were examined by a
security engineer to ensure that the findings were correct and that
no production code was affected. The crypto algorithm verifier
received positive feedback from security engineers since it is easy
to configure and outperformed an existing text-based check that
was running in the scanning infrastructure.
519False positive : The verifier issued an error, indicating that it
cannot prove a property. Manual examination determined that the
code never misbehaves at run time, but for a reason that is beyond
the capabilities of the verification tool. The key length verifier
reported 1 false positive: the keylength was hard-coded correctly,
butwasloadedviadependencyinjection,whichourverifierdoes
not precisely model.
We computed the compile-time overhead of using our tools. We
randomly sampled 52 projects using the key length verifier and 87
projectsusingthecryptographicalgorithmverifierfromthosein
table 4. We recorded their run time with and without our tools. On
average, our tools increased the full compile time for the project
from 51 to 134 seconds (2.6√ó). As part of a continuous integration
workflow, developers found this overhead acceptable.
9 THREATS TO VALIDITY
Our verification tools check only some properties; a program they
approve might fail unrelated compliance controls or might contain
otherbugs.Itdoesnotchecknativecode,andaverifiedprogram
maybelinkedwithunverifiedlibraries.Ithasmodesthatadoptun-
soundnessesfromJava,suchascovariantarraysubtypingandtype
arguments in casts. Like any implementation, it may contain bugs.
Oursampleprogramsmaynotberepresentative.Wemitigated
this threat by considering over 70 million lines of code from a
variety of projects, but it is all Java code.
10 LESSONS LEARNED
Verification is a good fit for compliance. A key contribution of
this work is the observation that source-code compliance is a good
targetforverification.Existingcompliancecontrolsareinformalspecifications that are already being checked by humans. These
properties are relatively simple. Yet, the domain is mission-critical.
Though researchers have struggled to make verification appealing
todevelopers,wehavediscoveredanothercustomerforverification
technology‚Äîcompliance auditors.
Because controls are designed to be checked by a human un-
familiar with the source code, most are amenable to verification.
Therearetwopropertiesofcompliancecontrolsthatmakethem
more verification-friendly:
‚Ä¢the controls are usually local, so that a human can check them
quickly.
‚Ä¢the controls are usually simple, so that a human without in-
depth knowledge of the code can check them.
Both of these properties make it more likely that a given control
can be automated. We believe that any compliance property that is
currently checked by manual examination of source code can be
automated.
Does someone else ever have to read the code? Compliance certifi-
cationisanexampleofa codereading task:someoneotherthanthe
developerexaminesthecodetocheckforaspecificproperty.Other
codereadingtasksarealsoamenabletoautomation.Forexample,
checkingtheformattingofcodeisanothercodereadingtaskwhich
has already been automated.Using verification tools changes developer attitudes. This work
hashadasignificanteffectinchangingattitudestowardverifica-tion. Developers and compliance officers started out skeptical of
formalmethods,butnowtheyareenthusiastic.Equallyimportantly,
developers on teams notsubject to compliance requirements are
observing their peers using verification. The adoption of new tech-
nologyisfundamentallyasocialprocess[ 41],andsocialpressureis
an important factor influencing whether security tools are adopted
bypractitioners[ 82].Webelievethatsimple,scalabletechniques
are both a research contribution and the best way to widely dis-
seminate formal verification. We encourage other researchers who
areinterestedinimpacttodeploytheirtoolsinwaysthatreduce
developers‚Äô workload by eliminating existing tasks that developers
must perform regularly.
Verificationcansavetimefordevelopers. Whendeveloperscon-
siderusingverificationtechnologiesinisolation,theymusttrade
offdevelopertime(towriteannotations,runtheverificationtool,
etc.) against improved software quality. The developers we worked
with at AWS are busy, and some were initially skeptical of verifica-
tion. They believed that a formal verification tool would have two
serious costs3:
‚Ä¢Developerswouldhavetospendalotoftimeannotatingthe
codebase before seeing benefits from the tool.
‚Ä¢The verification tool would issue false positives that would
waste engineering time to investigate, then rewrite the code or
the annotations.
Thesefears were grounded inexperience withformal verification
toolslikeOpenJML[ 49]thataredesignedtoprovecomplexproper-
ties.Becausedevelopersmustalreadydotheworktocertifytheir
software as compliant,they found the introduction ofverification
toautomatethat taskawelcomechange.Rather thanverification
becoming an extra task for them, verification replacedan existing,
unpleasant task. We encourage other verification researchers inter-
ested in impact in practice to use verification to replace existing
tasks developers must perform.
Moveothernon-testingtasktocontinuousintegration. Inmuchthe
samewaythatcontinuousintegrationimprovessoftwarequality
byrunningtestsmorefrequently,continuouscomplianceincreases
the confidence of auditors that compliance is maintained between
audits.Webelievethatresearchersshouldexplorewhetherthereareothersoftware-adjacenttasksthatcanbemovedintothecontinuous
integrationworkflow,aswehavedoneforcomplianceusingour
verification tools.
Verification is useful for stakeholders other than programmers.
Compliance auditors are a non-traditional customer of verification
technology. Nevertheless, we found that auditors readily accepted
verification and that it fit well into their workflow. Compliance,
like verification, is concerned with soundness‚Äîthe cost of a failed
auditisastronomical,especiallyforacompanylikeAWSwithmany
customers who must remain compliant themselves. This similarity
inthinkingandgoalsbetweencomplianceandverificationmade
our success possible. We encourage other verification research
3Thedeveloperswere notconcernedaboutcodeclutter;theywereusedtothebenefits
of annotations from using tools like Lombok, Guice, and Spring.
520interestedin impactinpractice toinvestigateother stakeholdersin
the correctness of software besides the developers themselves.
11 RELATED WORK
Practitionersandresearchersrecognizethecurrentlimitationsof
manual compliance audits, and they are actively seeking improve-
ments. We classify previous work into manual approaches, testing,
run-time checking, and static analysis.
Manual.Theindustry-standardapproachtocode-levelcompli-
anceismanualexamination.Therehasbeensomeworkonimprov-
ing the current manual audit approach by simplifying the software
inspection process [ 55]. By contrast,our approach aims toreplace
parts of the manual process with an automated one.
Testing.Mostpreviousresearchonsource-codelevelcompliance
hasaimed toapplyautomated orsemi-automatedtesting [ 11,36,
72,76].Automatedtestsreducecostsandpreventmistakesmade
while manually executing the tests (but not those in designing and
implementingthetests).However,testsarestillincomplete:tests
can show the presence of defects, but not their absence.
E-commerce merchants who must be compliant with the PCI
DSS can use an Approved Scanning Vendor (ASV) to automatically
certify that their websites meet some parts of the PCI DSS. Recent
work[64]hasshownthatextantASVsareunsoundandmis-certify
many vulnerable websites in practice. Further, most ( ‚àº86%) mer-
chant websites have one or more ‚Äúmust-fix‚Äù vulnerability, showing
the need for sound verification tools like ours.
Run-time checking. A recent approach is ‚Äúproactive‚Äù compliance,
which is analogous to run-time checking. Even if run-time checks
are exhaustive and correct, a violation causes the program to crash.
Researchinthisareaaimstoimproverun-timeperformanceand
retain interoperability with uninstrumented code [15, 51, 52].
Staticanalysis.Toourknowledge,ourworkisthefirsttouseau-
tomated, sound static analysis (lightweight verification) for source-
code compliance properties like those described in section 3.
Arecentliteraturereviewsplitcomplianceautomationintothree
categories: retroactive (i.e. log scanning), intercept-and-check (i.e.
atruntime,checkoperationsforcompliance),andproactive(which
theydescribeaslikeintercept-and-check,butwithsomeprecom-
putationtoreducethe run-time burden) [ 52].Theydonotmention
soundverification.Ullahetal.describeaframeworkforbuildingan
automatedcloudsecuritycompliancetool[ 76].Theirframework
does not include sound static analysis perse, but does have a place
forASVs,whichtheyregardasbest-effortbugfinders.Recentwork
ondesigningacloudservicewhichcouldbecontinuouslycompliant
did not consider using a verification tool to achieve that goal [50].
Formal methods like process modeling have been applied to
compliance problems, especially in safety-critical domains such as
railway[12]andautomotivesystems[ 9].TheCOMPASproject[ 27]
isacollectionofformalapproachestobusinessprocessmodeling
appliedtocompliance.KokashandArbabmodeledprocessesinthe
Reo language and analyzed them for compliance [ 46]. Tran et al.
developed a framework for expressing compliance requirements in
a service-oriented architecture [ 75]. These approaches are comple-
mentary to ours. They check properties about a process or about a
modelof thesystem, but theygiveno guarantees aboutits source
code or its implementation.Thereisawealthofspecificationandverificationworkthatis
notrelatedtocompliancerequirements.Pavlovaetal.developed
a technique for inferring JML annotations that encode security
policies of JavaCard applets [ 60]. Their approach utilizes the JACK
proof assistant, so it is neither automated nor usable by workaday
programmersorauditors.Furthermore,thesecuritypoliciesthey
checkdonotoverlapwiththerequirementsofcomplianceregimes.
Our work assumes cooperation between a developer and an
auditor. A similar assumption is made by the SPARTA [ 29] toolkit
for statically verifying that Android apps did not contain malicious
information flows, which posits a hypothetical high-assurance app
store. We address a differentdomain‚Äîcompliance‚Äîand we report
on wide-scale, real-world usage.
Analyzing uses of cryptography APIs. Most (90% or more) Java
applications that use cryptography misuseit [20], and most (>80%)
securityvulnerabilitiesrelatedtocryptographyareduetoimproper
usageofcryptographicAPIs[ 48].CogniCrypt ùëÜùê¥ùëÜùëá[47]isatech-
niquebasedonsynchronizedpush-downsystemsforfindingunsafe
usesofcryptographyAPIs.CryptoGuard[ 65]isaheuristic-based
tool based on program slicing for finding unsafe uses of cryptogra-
phy APIs. We compare to both in section 7.
12 CONCLUSION
Complianceis anexcellentdomainto showthatverification tools
are ready for real-world deployment to solve real-world problems,
especiallytodeveloperswhomightotherwisebeskepticalofthe
value of verification. Lightweight verification tools like typecheck-
ers are a good fit for compliance: they provide much higher assur-
ance than either manual audits or unsound bug-finding tools, atlower cost. Sound verifiers can be narrowly scoped to individualproperties like compliance controls. This makes them simple to
design andimplement. It alsomaintains a lowannotation burden,
making them as easy to use as unsound bug-finding tools.
Ourexperienceshowsthatverificationscalestoindustrialsoft-
ware at AWS, and that the business derived significant value from
ourefforts.Aslongasverificationautomatesworktheyarealready
doing, developers are enthusiastic about adopting it.
We look forward to a future in which verification technology is
widespread‚Äîbothforcomplianceandforcorrectness.Ourtools‚Äî
running in production at AWS for a large cohort of real developers,
saving them time and effort‚Äîare a step towards that goal.
Acknowledgments: Wethankthedevelopersandcomplianceofficersat
AWS who participated and provided feedback, especially Zaanjana Sreeku-
mar.ThankstoSeanMcLaughlinforhishelpwiththisproject.Thanksto
Ranjit Jhala for comments on a draft of this paper.
REFERENCES
[1]2002. FIPS PUB 140-2, Security Requirements for Cryptographic Modules.
U.S.Department of Commerce/National Institute of Standards and Technology.
[2]Bhargav Acharya. 2016. Why Cloud Providers Need a SOC Report. https:
//www.schellman.com/blog/why-cloud-providers-need-a-soc-report. Accessed
28 March 2019.
[3]Sharmin Afrose,Sazzadur Rahaman,and Danfeng Yao. 2019. CryptoAPI-Bench:
A Comprehensive Benchmark on Java Cryptographic API Misuses. In 2019 IEEE
Cybersecurity Development (SecDev). IEEE, 49‚Äì61.
[4]AICPA. 2017. SOC 2 examinations and SOC for Cybersecurity examinations:
Understanding the key distinctions. https://www.aicpa.org/content/dam/aicpa/interestareas/frc/assuranceadvisoryservices/downloadabledocuments/
cybersecurity/soc-2-vs-cyber-whitepaper-web-final.pdf. Accessed1February
2019.
521ASE ‚Äô20, September 21‚Äì25, 2020, Virtual Event, Australia Martin Kellogg, Martin Sch√§f, Serdar Tasiran, and Michael D. Ernst
[5]Amazon Web Services, Inc. 2006. Amazon S3. https://aws.amazon.com/s3/.
Accessed 17 April 2020.
[6]aws-kms-compliance-checker Developers. 2020. awslabs/aws-kms-compliance-
checker. https://github.com/awslabs/aws-kms-compliance-checker. Accessed
11 August 2020.
[7]awslabs/aws-crypto-policy-compliance-checker Developers. 2020. awslabs/aws-
crypto-policy-compliance-checker. https://github.com/awslabs/aws-crypto-
policy-compliance-checker. Accessed 11 August 2020.
[8]NathanielAyewah,DavidHovemeyer,J.DavidMorgenthaler,JohnPenix,and
William Pugh. 2008. Using static analysis to find bugs. IEEE Software 25, 5
(September 2008), 22‚Äì29.
[9]GhadaBahigandAmrEl-Kadi.2017. Formalverificationofautomotivedesignin
compliancewithISO26262designverificationguidelines. IEEEAccess 5(2017),
4505‚Äì4516.
[10]Elaine B. Barker, William C. Barker, William E. Burr, W. Timothy Polk, and
Miles E. Smid. 2007. SP 800-57. Recommendation for Key Management, Part 1:
General (Revised). Technical Report. Gaithersburg, MD, United States.
[11]Jason Bau, Elie Bursztein, Divij Gupta, and John Mitchell. 2010. State of theart: Automated black-box web application vulnerability testing. In 2010 IEEE
Symposium on Security and Privacy. IEEE, 332‚Äì345.
[12]CinziaBernardeschi,AlessandroFantechi,StefaniaGnesi,SalvatoreLarosa,Gior-
gioMongardi, andDarioRomano.1998. Aformalverificationenvironmentfor
railwaysignalingsystemdesign. FormalMethodsinSystemDesign 12,2(1998),
139‚Äì161.
[13]AlBessey,KenBlock,BenChelf,AndyChou,BryanFulton,SethHallem,CharlesHenri-Gros,AsyaKamsky,ScottMcPeak,andDawsonEngler.2010. Afewbillion
lines of code later: using static analysis to find bugs in the real world. Commun.
ACM53, 2 (2010), 66‚Äì75.
[14]Daniel Bleichenbacher. 1998. Chosen ciphertext attacks against protocols based
on the RSA encryption standard PKCS# 1. In Annual International Cryptology
Conference. Springer, 1‚Äì12.
[15]S√∂renBleikertz, CarstenVogel,Thomas Gro√ü,andSebastian M√∂dersheim.2015.
Proactivesecurityanalysisofchangesinvirtualizedinfrastructures.In Proceed-
ings of the 31st annual computer security applications conference. ACM, 51‚Äì60.
[16]Grady Booch. 1991. Object Oriented Design with Applications. Benjamin/Cum-
mings.
[17]KABriski,PoonamChitale,ValerieHamilton,AllanPratt,BStarr,JVeroulis,and
B Villard. 2008. Minimizing code defects to improve software quality and lower
developmentcosts. DevelopmentSolutions.IBM.Crawford,B.,Soto,R.,delaBarra,
CL(2008).
[18]bucket-complaince-checker Developers. 2020. kelloggm/bucket-compliance-
checker. https://github.com/kelloggm/bucket-compliance-checker. Accessed 11
August 2020.
[19]Matthew Campagna. 2015. Aws key management service cryptographic details.
[20]Alexia Chatzikonstantinou, Christoforos Ntantogian, Georgios Karopoulos, and
ChristosXenakis.2016. Evaluationofcryptographyusageinandroidapplications.
InInternational Conference on Bio-inspired Information and Communications
Technologies (formerly BIONETICS). 83‚Äì90.
[21]PCISecurityStandardsCouncil.2020. QualifiedSecurityAssessors. https://www.
pcisecuritystandards.org/assessors_and_solutions/qualified_security_assessors.
Accessed 14 April 2020.
[22]CryptoGuard Developers. 2020. CryptoGuardOSS/crypto-
guard. https://github.com/CryptoGuardOSS/cryptoguard/commit/
2898b5b5ec25d94bbedda271638385c0fa6e0c9c. Accessed 26 April 2020.
[23]Checker Framework Developers. 2019. Constant Value Checker. https://
checkerframework.org/manual/#constant-value-checker. Accessed10August
2019.
[24]Checker Framework Developers. 2020. Whole-program Inference. https:
//checkerframework.org/manual/#whole-program-inference. Accessed 17 April
2020.
[25]SpotBugs Developers. 2020. SpotBugs. https://spotbugs.github.io/. Accessed 24
April 2020.
[26]Mark Jason Dominus. 2001. Perl regular expression matching is NP-hard. https:
//perl.plover.com/NPC/.
[27]Schahram Dustdar. 2010. COMPAS: Compliance-driven Models,Languages, and Architectures for Services: Publishable Summary.https://cordis.europa.eu/docs/projects/cnect/5/215175/080/reports/001-
publishablesummarylongversion1.pdf. Accessed 4 April 2019.
[28]Stacy English and Susannah Hammond. 2018. Cost of Compliance
2018. https://legal.thomsonreuters.com/content/dam/ewp-m/documents/legal/
en/pdf/reports/cost-of-compliance-special-report-2018.pdf. Accessed 26 Febru-
ary 2019.
[29]Michael D. Ernst, Ren√© Just, Suzanne Millstein, Werner Dietl, Stuart Pernsteiner,
Franziska Roesner, Karl Koscher, Paulo Barros, Ravi Bhoraskar, Seungyeop Han,
PaulVines, andEdwardX. Wu.2014. Collaborativeverificationofinformation
flow for a high-assurance app store. In CCS 2014: Proceedings of the 21st ACM
ConferenceonComputerandCommunicationsSecurity.Scottsdale,AZ,USA,1092‚Äì
1104.[30]Jeffrey S. Foster, Manuel F√§hndrich, and Alexander Aiken. 1999. A theory of
typequalifiers.In PLDI‚Äô99:ProceedingsoftheACMSIGPLAN‚Äô99Conferenceon
Programming Language Design and Implementation. Atlanta, GA, USA, 192‚Äì203.
[31]Electronic Frontier Foundation. 1998. Cracking DES: Secrets of encryption
research, wiretap politics and chip design.
[32] Martin Fowler and Matthew Foemmel. 2006. Continuous integration.[33]
Alain Frisch and Luca Cardelli. 2004. Greedy regular expression matching. InAutomata, Languages and Programming: 31st International Colloquium, ICALP
2004. Turku, Finland, 618‚Äì629.
[34]Dan Fritsche and Bhavana Sasne. 2015. Whitepaper: The Costs of Failing a PCI-
DSS Audit. https://www.hytrust.com/wp-content/uploads/2015/08/HyTrust_
Cost_of_Failed_Audit.pdf. Accessed 18 March 2019.
[35]GSA. 2017. FedRAMP SECURITY ASSESSMENT FRAMEWORK, Version
2.4. https://www.fedramp.gov/assets/resources/documents/FedRAMP_Security_
Assessment_Framework.pdf. Accessed 31 January 2019.
[36]Hossein Homaei and Hamid Reza Shahriari. 2019. Athena: A framework toautomaticallygeneratesecuritytestoracleviaextractingpoliciesfromsource
code and intended software behaviour. Information and Software Technology 107
(2019), 112‚Äì124.
[37] Haruo Hosoya, J√©r√¥me Vouillon, and Benjamin C. Pierce. 2005. Regular Expres-
sion Types for XML. ACM Transactions on Programming Languages and Systems
27, 1 (January 2005), 46‚Äì90. https://doi.org/10.1145/1053468.1053470
[38]hsm-simulator Developers. 2019. gjyoung1974/hsm-
simulator. https://github.com/gjyoung1974/hsm-simulator/blob/
432b2b6e9fd63936347293743e54a8e572367fda/src/com/goyoung/crypto/
hsmsim/commands/crypto/GenerateVISAWorkingKey.java. Accessed 5 May
2020.
[39]WeiHuang,YaoDong,andAnaMilanova.2014. Type-basedtaintanalysisfor
Java web applications. In International Conference on Fundamental Approaches to
Software Engineering. Springer, 140‚Äì154.
[40]Brittany Johnson, Yoonki Song, Emerson Murphy-Hill, and Robert Bowdidge.
2013. Whydon‚Äôtsoftwaredevelopersusestaticanalysistoolstofindbugs?.In
ICSE2013,Proceedingsofthe35thInternationalConferenceonSoftwareEngineering.
San Francisco, CA, USA, 672‚Äì681.
[41]ElenaKarahanna,DetmarWStraub,andNormanLChervany.1999. Information
technologyadoptionacrosstime:across-sectionalcomparisonofpre-adoption
and post-adoption beliefs. MIS quarterly (1999), 183‚Äì213.
[42]AudreyKatcher.2019. UnderstandingHowUsersWouldMakeUseofaSOC2Re-
port. https://www.rubinbrown.com/soc2_user_document_111710.pdf. Accessed
28 March 2019.
[43]Martin Kellogg. 2020. do-like-javac. https://github.com/kelloggm/do-like-javac.
Accessed 24 April 2020.
[44]MartinKellogg,VlastimilDort,SuzanneMillstein,andMichaelD.Ernst.2018.Lightweight verification of array indexing. In ISSTA 2018, Proceedings of the
2018 International Symposium on Software Testing and Analysis. Amsterdam,
Netherlands, 3‚Äì14.
[45]Martin Kellogg, Manli Ran, Manu Sridharan, Martin Sch√§f, and Michael D. Ernst.
2020. Verifying Object Construction. In ICSE 2020, Proceedings of the 42nd Inter-
national Conference on Software Engineering. Seoul, Korea.
[46]NatalliaKokashandFarhadArbab.2008. Formalbehavioralmodelingandcompli-anceanalysisforservice-orientedsystems.In InternationalSymposiumonFormal
Methods for Components and Objects. Springer, 21‚Äì41.
[47]StefanKr√ºger,JohannesSp√§th,KarimAli,EricBodden,andMiraMezini.2018.
CrySL: An extensible approach to validating the correct usage of cryptographic
APIs. InECOOP 2018 ‚Äî Object-Oriented Programming, 32nd European Conference.
Amsterdam, Netherlands, 10:1‚Äì10:27.
[48]David Lazar, Haogang Chen, Xi Wang, and Nickolai Zeldovich. 2014. Why does
cryptographic software fail?: a case study and open problems. In Asia-Pacific
Workshop on Systems. ACM, 7.
[49]GaryTLeavens,AlbertLBaker,andClydeRuby.2006. PreliminarydesignofJML:
AbehavioralinterfacespecificationlanguageforJava. ACMSIGSOFTSoftware
Engineering Notes 31, 3 (2006), 1‚Äì38.
[50]Sebastian Lins, Stephan Schneider, and Ali Sunyaev. 2018. Trust is good, control
isbetter:Creatingsecurecloudsbycontinuousauditing. IEEETransactionson
Cloud Computing 6, 3 (2018), 890‚Äì903.
[51]Suryadipta Majumdar, Yosr Jarraya, Momen Oqaily, Amir Alimohammadifar,
MakanPourzandi,LingyuWang,andMouradDebbabi.2017. Leaps:Learning-
basedproactivesecurityauditingforclouds.In EuropeanSymposiumonResearch
in Computer Security. Springer, 265‚Äì285.
[52]SuryadiptaMajumdar,TaousMadi,YosrJarraya,MakanPourzandi,LingyuWang,
and Mourad Debbabi. 2018. Cloud Security Auditing: Major Approaches and
Existing Challenges. In Symposium on Foundations & Practice of Security.
[53]Mastercard. 2017. Site Data Protection (SDP) Program, Frequently Asked Ques-
tions. https://globalrisk.mastercard.com/wp-content/uploads/2017/03/Site-Data-
Protection-SDP-Program-FAQs-1-March-2017.pdf. Accessed 18 March 2019.
[54]Suzanne Millstein. 2016. Implement Java 8 type argument inference. https:
//github.com/typetools/checker-framework/issues/979. Accessed17April2020.
522Continuous Compliance ASE ‚Äô20, September 21‚Äì25, 2020, Virtual Event, Australia
[55]Deepti Mishra and Alok Mishra. 2009. Simplified software inspection process in
compliancewithinternational standards. ComputerStandards&Interfaces 31,4
(2009), 763‚Äì771.
[56]MS325E.64.2007. AccessDevices;BreachofSecurity. MinnesotaStatutes(2018):
Chapter 325E, Section 64.
[57]Jacob Nemetz and Brett Lieblich. 2019. Dash Compliance Automation ‚Äî S3 Secu-
rity Controls. https://www.dashsdk.com/docs/aws/hipaa/amazon-s3/. Accessed
8 April 2020.
[58]no-literal-checker Developers. 2020. kelloggm/no-literal-checker. https://github.
com/kelloggm/no-literal-checker. Accessed 11 August 2020.
[59]Matthew M. Papi, Mahmood Ali, Telmo Luis Correa Jr., Jeff H. Perkins, and
MichaelD.Ernst.2008. PracticalpluggabletypesforJava.In ISSTA2008,Proceed-
ingsofthe2008InternationalSymposiumonSoftwareTestingandAnalysis.Seattle,
WA, USA, 201‚Äì212.
[60]MarielaPavlova, GillesBarthe, LilianBurdy, MariekeHuisman, andJean-Louis
Lanet. 2004. Enforcinghigh-level securityproperties forapplets. In Conference
on Smart Card Research and Advanced Applications. Springer, 1‚Äì16.
[61]PCISecurityStandardsCouncil.2018. PaymentCardIndustry(PCI)DataSecurity
Standard,v.3.2.1. https://www.pcisecuritystandards.org/documents/PCI_DSS_
v3-2-1.pdf. Accessed 26 February 2019.
[62]PCI Security Standards Council. 2018. PCI DSS v3.2.1 Template for Report on
Compliance.https://www.pcisecuritystandards.org/documents/PCI-DSS-v3_2_1-
ROC-Reporting-Template.pdf. Accessed 4 April 2019.
[63]Ponemon Institute LLC. 2011. The True Cost of Compliance. https://www.
ponemon.org/local/upload/file/True_Cost_of_Compliance_Report_copy.pdf. Ac-
cessed 3 April 2019.
[64]SazzadurRahaman,GangWang,andDanfengYao.2019. SecurityCertification
inPayment CardIndustry:Testbeds,Measurements, andRecommendations.In
Proceedingsofthe2019ACMSIGSACConferenceonComputerandCommunications
Security. 481‚Äì498.
[65]SazzadurRahaman,YaXiao,SharminAfrose,FahadShaon,KeTian,MilesFrantz,
Murat Kantarcioglu, and Danfeng (Daphne) Yao. 2019. CryptoGuard: High preci-
sion detection of cryptographic vulnerabilities in massive-sized Java projects. In
CCS 2019: Proceedings of the 21st ACM Conference on Computer and Communica-
tions Security. London, UK, 2455‚Äì2472.
[66]RCW 19.255.020. 2010. Liability of processors, businesses, and vendors. Revised
Code of Washington, Title 19, Chapter 19.255, Section 19.255.020.
[67]DavidSaffandMichaelD.Ernst.2003. Reducingwasteddevelopmenttimevia
continuoustesting.In ISSRE2003:FourteenthInternationalSymposiumonSoftware
Reliability Engineering. Denver, CO, 281‚Äì292.
[68]Martin Schaef. 2019. Example of how to whitelist crypto algo-
rithms. https://github.com/awslabs/aws-crypto-policy-compliance-
checker/blob/master/stubs/javax.crypto.astub. Accessed 11 August 2020.
[69]Helmut Seidl. 1990. Deciding Equivalence of Finite Tree Automata. SIAM J.
Comput.19, 3 (June 1990), 424‚Äì437. https://doi.org/10.1137/0219027
[70]sendmail Developers. 2015. NewSaigonSoft/sendmail. https://github.com/
NewSaigonSoft/sendmail/blob/e31d9a86c7f863c59fc51d5fd2c1b60cc4586faf/src/
main/java/com/newsaigonsoft/sendmail/SecurePassword.java. Accessed 5 May
2020.
[71]Square,Inc.2017. PCICompliance:WhatYouNeedtoKnow. https://squareup.
com/guides/pci-compliance. Accessed 18 March 2019.
[72]Philipp Stephanow and Christian Banse. 2017. Evaluating the performance of
continuous test-based cloud service certification. In International Symposium on
Cluster, Cloud and Grid Computing. IEEE Press, 1117‚Äì1126.
[73]Robert E. Strom and Shaula Yemini. 1986. Typestate: A programming language
conceptforenhancingsoftwarereliability. IEEETransactionsonSoftwareEngi-
neeringSE-12, 1 (January 1986), 157‚Äì171.
[74]TheSWAMPTeam.2020. WelcomeToTheSWAMP. https://continuousassurance.
org/. Accessed 24 April 2020.
[75]Huy Tran, Ta‚Äôid Holmes, Ernst Oberortner, Emmanuel Mulo, Ag-nieszka Betkowska Cavalcante, Jacek Serafinski, Marek Tluczek, Aliaksandr
Birukou, Florian Daniel, Patricia Silveira, et al .2010. An end-to-end framework
for business compliance in process-driven SOAs. In 2010 12th International
Symposium on Symbolic and Numeric Algorithms for Scientific Computing. IEEE,
407‚Äì414.
[76]KaziWaliUllah,AbuShohelAhmed,andJukkaYlitalo.2013. Towardsbuildingan
automated security compliance tool for the cloud. In Trust, Security and Privacy
in Computing and Communications (TrustCom). IEEE, 1587‚Äì1593.
[77]Ciske van Oosten, Anne Turner, Cynthia B. Hanson, Dyana Pearson, Ronald
Tosto,andAndiBaritchi.2018. Verizon2018PaymentSecurityReport. Accessed
26 February 2019.
[78]Steven VanRoekel. 2011. Security Authorization of Information Systems inCloud Computing Environments. https://www.fedramp.gov/assets/resources/
documents/FedRAMP_Policy_Memo.pdf. Accessed 31 January 2019.
[79]vaultDevelopers.2020. NitorCreations/vault. https://github.com/NitorCreations/
vault/blob/3c3ec65879c82bb353b4cf4d22898abb0b7b578f/java/src/main/java/
com/nitorcreations/vault/VaultClient.java. Accessed 8 May 2020.[80]VISA, Inc. 2017. Data Security Compliance Requirements for Service
Providers. https://usa.visa.com/dam/VCOM/download/merchants/data-security-
compliance-service-providers.pdf. Accessed 31 January 2019.
[81]Mark N Wegman and F Kenneth Zadeck. 1991. Constant propagation with
conditionalbranches. ACMTransactionsonProgrammingLanguagesandSystems
(TOPLAS) 13, 2 (1991), 181‚Äì210.
[82]JimWitschey,OlgaZielinska,AllaireWelk,EmersonMurphy-Hill,ChrisMay-
horn, and Thomas Zimmermann. 2015. Quantifying developers‚Äô adoption ofsecurity tools. In Proceedings of the 2015 10th Joint Meeting on Foundations of
Software Engineering. ACM, 260‚Äì271.
[83]Chad Woolf, Byron Cook, and Tom McAndrew. 2019. Automate Compliance
Verification on AWS Using Provable Security. https://www.youtube.com/watch?
v=BbXK_-b3DTk. Accessed 25 August 2020.
523