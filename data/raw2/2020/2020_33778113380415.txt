Fuzz Testing based Data Augmentation to Improve Robustness
of Deep Neural Networks
Xiang Gao‚àó
NationalUniversityof Singapore, Singapore
gaoxiang@comp.nus.edu.sgRipon K. Saha
Fujitsu Laboratories of America, Inc, USA
rsaha@us.fujitsu.com
Mukul R. Prasad
Fujitsu Laboratories of America, Inc, USA
mukul@us.fujitsu.comAbhik Roychoudhury
NationalUniversityof Singapore, Singapore
abhik@comp.nus.edu.sg
ABSTRACT
Deepneuralnetworks(DNN)havebeenshowntobenotoriously
brittle to small perturbations in their input data. This problem is
analogoustotheover-fittingproblemintest-basedprogramsyn-
thesis and automatic program repair, which is a consequence of
the incompletespecification, i.e., the limited tests or training exam-
ples, that the program synthesis or repair algorithm has to learn
from.Recently,testgenerationtechniqueshavebeensuccessfully
employedto augmentexisting specificationsof intendedprogram
behavior, to improve the generalizability of program synthesis and
repair. Inspired by these approaches, in this paper, we propose a
techniquethatre-purposessoftwaretestingmethods,specifically
mutation-basedfuzzing,toaugmentthetrainingdataofDNNs,with
the objective of enhancing their robustness. Our technique casts
theDNNdataaugmentationproblemasanoptimizationproblem.It
usesgeneticsearchtogeneratethemostsuitablevariantofaninput
data to use for training the DNN, while simultaneously identifying
opportunitiestoacceleratetrainingbyskippingaugmentationin
many instances. We instantiate this technique in two tools, Sensei
and Sensei-SA, and evaluate them on 15 DNN models spanning
5popularimagedata-sets.OurevaluationshowsthatSenseican
improve the robust accuracy of the DNN, compared to the state of
theart,on eachofthe15models,byupto11.9%and5.5%onaverage.
Further,Sensei-SAcanreducetheaverageDNNtrainingtimeby
25%,while still improving robust accuracy.
CCSCONCEPTS
‚Ä¢Computingmethodologies ‚ÜíNeuralnetworks ;‚Ä¢Software
and its engineering ‚ÜíSearch-based software engineering ;
Software testing and debugging.
KEYWORDS
GeneticAlgorithm,DNN,Robustness,Data Augmentation
‚àóThisworkwasmainlydonewhentheauthorwasaninternatFujitsuLabsofAmerica.
Permissionto make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACM
mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ICSE‚Äô20,May23‚Äì29,2020,Seoul, Republic of Korea
¬© 2020Association for Computing Machinery.
ACM ISBN 978-1-4503-7121-6/20/05...$15.00
https://doi.org/10.1145/3377811.3380415ACM Reference Format:
XiangGao,RiponK.Saha,MukulR.Prasad,andAbhikRoychoudhury.2020.
Fuzz Testing based Data Augmentation to Improve Robustness of Deep
Neural Networks. In 42nd International Conference on Software Engineering
(ICSE‚Äô20),May23‚Äì29,2020,Seoul,RepublicofKorea. ACM,NewYork,NY,
USA,12 pages. https://doi.org/10.1145/3377811.3380415
1 INTRODUCTION
Programmingbyexamples(PBE)suchastest-basedprogramsynthe-
sis and automated program repair [ 1,18], automatically generates
programsthat conformtothe specificationindicatedby thegiven
examples. Since the given examples usually constitute an incom-
plete specification of intended behavior, the generated program
mayover-fit the given examples and thereby notexhibit intended
behaviorsontheun-seenpartoftheinputspace.Over-fittingisa
commonproblemintest-basedprogramsynthesis[ 1,9]andauto-
matedprogramrepair[ 18,25].Similarly,machine/deeplearning[ 7]
also faces the over-fitting problem. In machine learning, a model is
usuallylearnedfromatrainingset(ofinputs),andthendeployed
on a testing set. Over-fitting in machine learning systems impacts
two related but distinct properties of such systems: (1) inadequate
standard generalization, where the trained model shows high accu-
racyonthetrainingset,butcannotbegeneralizedtodatapoints
outside the training set, e.g., the testing set, and (2) inadequate
robustgeneralization,wherethemodelshowhighaccuracyonboth
trainingandtestingsets,butcannotbegeneralizedtoinputsthat
are small perturbations of training/testing inputs; these small per-
turbations may stillconstitute legalinputs, butthe learnedmodel
often mis-classifies such inputs. Robust generalization renders the
learned models resilient against such small perturbations.
Standardgeneralizationdoesnotimplyrobustnessgeneraliza-
tion.Forinstance,amodel,evenwith99%accuracyonitstesting
dataset, could misclassify the input variations generated by sim-
ple spatial transformation (e.g., rotation) with high confidence [ 8].
Figure 1 presents an example from the GTSRB dataset. Robust gen-
eralizationitselfcanbeoftwotypes,dependingontheoperation
context.Inasecuritysetting,robustgeneralizationagainstadver-
sarial inputs aims to protect a model against a powerful adversary,
thatcanmodifytheinputinsophisticatedandtargetedways(i.e.,
anattack),suchasobscuringafewspecificpixelsinanimage,to
makethemodelmis-predict.Thisscenariohasbeenpopularizedby
theworkonadversarialtesting[ 11,12,23,29]andmorerecently,
adversarial robust generalization [ 4,14,17,21,31,45]. A second
scenario, however, is p erturbations due to natural variations in
*&&&"$.OE*OUFSOBUJPOBM$POGFSFODFPO4PGUXBSF&OHJOFFSJOH	*$4&
ICSE ‚Äô20, May 23‚Äì29, 2020, Seoul, Republic of Korea Xiang Gao, Ripon K. Saha, Mukul R. Prasad, and Abhik Roychoudhury

(a) Original image is cor-
rectly classified

(b) Incorrect classification
afteronedegree rotation
Figure 1: A motivating example from the GTSRB dataset
environmental conditions when capturing input data. Examples
of this are variations due to weather conditions (e.g., snow, fog)
ortheillumination(e.g.,dayornight)forthe samelocation,fora
self-driving car, or variations in the position, angle, or exposuresettings for a camera capturing the same subject. Recent workhas highlighted the poor robustness of Deep Learning models to
such variations [ 19,24,30,47]. In this work, we focus on the latter
scenarioandinvestigatehowsoftwaretestingtechniquescanbeap-pliedfortherobustgeneralizationofDeepNeuralNetworks(DNNs)
to natural environmental variations.Although we present our ap-
proach in the context of DNNs, the core ideas are more broadly
applicableto learning systems.
Inthefieldoftestdrivenprogramsynthesisandprogramrepair,a
prominentclassofrecentte chniquesimprovesthe generalizationof
generatedprogramsbyaugmentingexistingtestsuites[ 9,40,41,43].
Test case generation techniques (such as random testing, search-
based evolutionarytesting, symbolicexecution, grey-boxfuzzing)
have been used to augment existing specifications of intended pro-
grambehavior[ 40,41,43].Inparticular,coverage-basedgrey-box
fuzzing approaches, such as AFL [ 32], have shown utility in aug-
menting existing test suites for program repair [ 10]. In grey-box
fuzzing algorithms, i[1]nputs are randomly mutated to generate
newinputsandhigherpriorityisassignedtoinputsthatexercise
newandinterestingpaths.Theintuitionbehindthesetechniquesisthatcoveringmoreprogrampathsenablesustofindrepresentative
tests and covers more program functionality.
Ataconceptuallevel,trainingAImodelsisanalogoustoprogram
synthesis [ 1]. A learning system generates a model that can clearly
classifyagiveninputtoitscorrespondinglabel.Specifically,neuralnetworkmodelscanbeconsideredaslayersofprogramstatements
connectedbyaparametermatrix.Givenasetoftrainingdata(in-
puts)withlabels(outputs),theknowledgeacquiredduringtraining
is encoded intoparameters that connect layers. Thus,it is natural
toask ifsoftware testgeneration basedaugmentationtechniques,
which have been successfully applied to improve generalization of
programsynthesisandrepair,canbere-purposedforrobustgen-
eralizationofDNNs.Thispaperdevelopsthisidea,byemploying
mutation-based fuzzing for data augmentation of DNNs.
It is a common practice to boost the standard generalization
ofDNNs,usingbasicdataaugmentation,where, duringtheinitial
training, each training input is substituted by a (single) randomly-
generated,label-preservingvariant[ 16,27].Amoresophisticated
versionof thisis donein mixup[46],a recentlyproposedstate-of-
the-art data augmentation technique, that trains a DNN on convex
combinations of pairs of data and their labels. However, as shown
in Section5,while thisboosts thestandard generalizationand the
robustgeneralizationtoadversarialexamples,ithaslimitedimpactontherobustgeneralizationto naturalvariations.Further,thespace
of potential label-preserving transformations and their parameter

	




	
	


(a) Standard model





	


(b) State-of-the-art




	




(c)Sensei
Figure 2: The loss for various transformations of the moti-
vating example after augmented training.
values is very rich [ 8,24,30]. Thus, na√Øve augmentation with all or
severalvariantsisnotviableeither‚Äîitwouldsignificantlyincrease
the size of the training set and training time. In the past, robust op-
timization [ 2], based on gradient descent, has been used to defend
DNNs against adversarial examples [ 8,21]; these techniques try to
generatetheworstvariant,basedonalossfunction,andadditto
the training set. However, as shown in Figure 2(a), the input space
ofspatialtransformations,whichareprominentlyrepresentedin
naturalenvironmentalvariations(forvisionapplications),ishighlynon-convex.Thegradientdescenttechniquesperformratherpoorly
in such scenarios [ 8], and therefore not applicable for our problem.
Evenastate-of-the-artaugmentationapproach[ 8]performspoorly
for such non-convex space as shown in Figure 2(b). It is important
to note that while our data augmentation technique generates and
usesthegenerateddata duringinitialtraining,almostalltechniques
toimproverobustness[ 14,15,17,24,30,31]generateadversarial
examplesbyanalyzingatrainedmodelandsubsequently re-train
themodelonthisnewdata.Ourevaluation(Section5)demonstrates
thatourtechniqueprovidesbetterrobustgeneralizationthanthe
latter approach. Concurrent with our work, Yang et al. have pro-posed an orthogonal approach to improving DNN robustness to
spatialvariations[ 42].Theirapproachmodifiesthelossfunction
oftheDNNbyaddinganinvariant-inducingregularizationtermtothestandardempiricalloss.Thisiscomplementarytoourproposed
data augmentation based mechanism of improving robustness. Ex-
ploring the combination of these two approaches could present an
interesting opportunity forfuture work.
Proposedtechnique. Inthispaper,weproposeanewalgorithm
thatusesguidedtestgenerationtechniquestoaddressthedataaug-mentationproblemforrobustgeneralizationofDNNsundernatural
environmentalvariations.Specifically,wecastdataaugmentation
problemasanoptimizationproblem,andusegeneticsearchona
space of the natural environmental variants of each training input
data, toidentify the worstvariant foraugmentation. Theiterative
nature of the genetic algorithm (GA) is naturally overlaid on the
multi-epoch training schedule of the DNN, where in each iteration,
for eachtrainingdata,the GA explores asmall population of vari-
ants and selects the worst, for augmentation, and further uses it as
theseedforthesearchinthenextepoch,graduallyapproachingthe
worst variant, without explicitly evaluating all possible variants.
Further, we propose a novel heuristic technique, called selective
augmentation which allows skipping augmentation completely for
a training data point in certain epochs based on an analysis of the
DNN‚Äôscurrentrobustnessaroundthatpoint.Thisallowsasubstan-tial reduction in the DNN‚Äôs training time under augmentation. The
contributionsof this paper include:
Fuzz Testing based Data Augmentation to Improve Robustness of Deep Neural Networks ICSE ‚Äô20, May 23‚Äì29, 2020, Seoul, Republic of Korea
‚Ä¢Weformalizethedataaugmentationforrobustgeneralizationof
DNNs,undernaturalenvironmentalvariations,asasearchprob-
lem and solve the search problem using fuzz testing approaches,
specifically using genetic search.
‚Ä¢Toreducetheoverheadcausedbydataaugmentation,wepropose
a selective data augmentation strategy, where only part of datapoints are selected to be augmented.
‚Ä¢
Asapracticalrealizationoftheproposedtechnique,weimple-
menttwo prototype tools Senseiand Sensei-SA.
‚Ä¢Weevaluatetheproposedapproachon15DNNmodels,spanning
5 popular image data-sets. The results show that the Sensei can
improve the robust accuracy of allthe models, compared to the
stateoftheart,byupto11.9%and5.5%onaverage.Sensei-SAcanreduce DNN average training time by 25%, while still improving
robustaccuracy.Currently,ourapproachhasonlybeenevaluated
onimageclassificationdatasets.However,conceptually,itmay
have wider applicability.
2 BACKGROUND
2.1 Fuzz Testing
Fuzztestingisacommonandpracticalapproachtofindsoftware
bugs or vulnerabilities, where new tests are generated by mutating
existingseeds(inputs).Byselectingtheseedstomutateandcon-
trolling the number of generated mutations, we can effectively and
efficientlyachieveacertaintestinggoal(e.g.highcodecoverage).
Algorithm1brieflydescribeshowgreyboxfuzzing(e.g.AFL[ 32])
works. Given a set of initial seed inputs S, the fuzzer chooses s
fromSinacontinuousloop.Foreach s,thefuzzerdeterminesthe
number of tests, which is called the energyofs, to be generated by
mutating s. Then, we execute program Pwith the newly generated
tests/prime(line 6) and monitor the run-time behavior. Whether s/primeis
addedtotheseedqueueisdeterminedbyafitnessfunction(line7),
whichdefineshow good test s/primeis toachieve a certaintesting goal.
Algorithm1: Test generation via greybox fuzzing
Input:seed inputs S; program P
1whiletimeout is not reached do
2s:=chooseNext( S);
3energy:=assignEnergy( s);
4forifrom 1 to energy do
5 s/prime:=mutate(s);
6 execute (P,s/prime);
7 iffitness(s/prime)>threshold then
8 S:=S‚à™s/prime;
9end
10end
2.2 Training Deep Neural Networks
Given a DNN model Mwith a set of parameters (or weights)Œ∏‚àà
Rpbeing trained on a training dataset Dthat consists of pairs of
examples x‚ààRd(drawn from a representative distribution) and
corresponding labels y‚àà[k], the objective of training Mis to infer
optimal values of Œ∏such that the aggregated loss over Dcomputed
byMis minimum. Following the treatment in [ 21], this can beexpressed as the following minimization problem:
min
Œ∏E(x,y)‚àºD[L(Œ∏,x,y)] (1)
whereL(Œ∏,x,y)is a suitable cross-entropy loss function for Mand
E(x,y)‚àºD()is a risk function that (inversely) measures the accuracy
ofMoveritstrainingpopulation.Inpractice,thesolutiontothis
problem is approximated in a series of iterative refinements to the
values of Œ∏, calledepochs. In each epoch, Œ∏is updated with the
objective of minimizing the loss of training data.
2.3 Robustness of DNNs
DNNshavedemonstratedimpressivesuccessinawiderangeofap-
plications[ 3,48].However,DNNshavealsobeenshowntobequite
brittle, i.e., not robust, to small changes in their input. Specifically,
a DNNMmay correctly classify an input xwith its corresponding
labell, but incorrectly classify an input x+Œ¥that issimilartox,
with label l/prime, wherel/nequall/prime. Although our ideas are broadly applica-
ble, the sequel assumes a DNN performing an image classification
task.Inthiscontext, xisanimage,and x+Œ¥aperceptuallysimilar
(to the humanuser) variant of x.
As discussed earlier, this work targets robustness issues arising
from natural, environmental perturbations Œ¥in the input data and
notperturbations Œ¥constructed adversarially, in a security context.
The allowed perturbations Œ¥can be represented as a neighborhood
Saround input x, such that ‚àÄŒ¥‚ààS,x+Œ¥constitutes legal input
forMandisperceptuallysimilarto xandhencecarriesthesame
labell.Scan be simulated through a set of parameterized trans-
formations T(/vecœÅ,x)={t1(œÅ1,x),t2(œÅ2,x),...,tk(œÅk,x)}(where/vecœÅ=
/angbracketleftœÅ1,œÅ2,...,œÅk/angbracketright),includingcommonimagetransformationssuchas
rotation,translation,brightnessorcontrastchanges, etc.,asdoneby
recentworkonrobustnesstestingofDNNs[ 8,24,30].Alternatively,
Scan be synthesized using generative models such Generative Ad-
versarial Neural Networks (GANs) [ 20,47]. We employ the former
approach. Specifically, a variant x/primeof image xcan be computed
by applying the composition of transformations t1,t2,...,tkin
sequence (denoted by t)o nx, as:
x/prime=t(/vecœÅ,x)=tk(œÅk,...,t2(œÅ2,t1(œÅ1,x))...)(2)
2.4 Data Augmentation for DNNs
Since DNNs self-learn the relevant features from the training data
they may learn irrelevant features of the specific data (i.e., over-
fitting) and generalize poorly to other data [ 16]. To improve (stan-
dard)generalizationofDNNsitiscommonpracticetoperforma
basic form of data augmentation where, during training, in each
epoch,eachtrainingdataisreplacedbyavariantcreatedbyran-
domly applying some sources of variation or noise (for example
the transformations Tabove). As shown in Section 5, this basic
strategyalsoboostsrobustgeneralizationbutwithsignificantroom
for improvement. Data augmentation can be performed in mainly
twowaysfromthetrainingperspective:i) duringinitialtraining:
syntheticdataisgeneratedon-the-flybasedonsomeheuristicsand
thenaugmentedwiththetrainingdataduringthetrainingofthe
original model, ii) retraining: in a two-staged fashion where in
the first step, additional data are selected based on the feedbackon the original model, and then in the second step, the model is
retrained with the augmented data.
ICSE ‚Äô20, May 23‚Äì29, 2020, Seoul, Republic of Korea Xiang Gao, Ripon K. Saha, Mukul R. Prasad, and Abhik Roychoudhury
3 SENSEI: AN AUTOMATIC DATA
AUGMENTATION FRAMEWORK FOR DNNS
Sensei targets improving the robust generalization of a DNN in-
training, under natural environmental variations, by effectively
augmenting the training data. In general, data augmentation could
involve adding, removing, or replacing an arbitrary number of
trainingdatainputs.However,Sensei, likeseveralaugmentation
approaches [ 8,21], implements a strategy of either replacing each
data with a suitable variant or leaving it unchanged. Thus, the
totalsizeofthetrainingdatasetisalsounchanged.Thus,thekey
contributionof Senseiis to identifythe optimal replacement for
eachtrainingdata.Inaddition,weintroduceanoptimizedversionof
SenseicalledSensei-SAtooptimizethetrainingtimebypotentially
skippingaugmentationfor somedatainputs.
3.1 Problem Formulation
ThetaskoftrainingaDNNunderrobustgeneralizationcanbecast
as modified version of Equation 1, where, in addition to optimizingforparameters
Œ∏wealsoneedtoselect,foreachtrainingdatainput
x, a suitable variant x/prime=x+Œ¥, whereŒ¥‚ààS. Following [ 21] this
can be cast as the following saddle-point optimization problem:
min
Œ∏E(x,y)‚àºD[max
Œ¥‚ààSL(Œ∏,x+Œ¥,y)] (3)
Senseiapproximatesthesolutionofthisoptimizationproblem
bydecouplingtheinnermaximizationproblem(whichsolvesfor Œ¥)
from the outer minimization problem (which optimizes Œ∏). This is
done by allowing the usual iterative epoch-based training schedule
to optimize for, but in each epoch, for each training data x, solving
the inner maximization problem to find the optimal variant x+Œ¥.
Specifically,giventhesetoftransformations T(/vecœÅ,x)definingneigh-
borhoodSandusinganoverloadeddefinitionof Sintermsofthe
parameter vector /vecœÅ, Sensei solves following optimization problem:
Definition 1 (Augmentation target ).Given a seed training
datainput xandtransformation function t(/vecœÅ,x)definingneighbor-
hoodSofx,find/vecœÅyieldingtheoptimalvariant x/prime(perEquation2)
to optimize:
max
/vecœÅ‚ààSL(Œ∏,t(/vecœÅ,x),y) (4)
3.2 An Overview
In order to solve the optimization problem defined in Equation 4effectively and efficiently, our proposed approach includes twonovel insights. Our first insight is that although traditional dataaugmentation techniques improve the robust generalization by
training the DNN with some random variations of the data-points,
afuzztestingbasedapproachsuchasguidedsearchmaybemore
effectivetofindoptimalvariantsofdatapointstotraintheDNN,
andhence,toimprovetherobustgeneralization.Oursecondinsightisthatnotalldatapointsinthetrainingdatasetaredifficulttolearn.Somedatapointsrepresentidealexamplesinthetrainingsetwhile
some are confusing. Therefore, treating all the points similarly
regardlessoftheirdifficultieslevelsmayresultinwasteofvaluable
trainingtime.Wemaysaveasignificantamountoftrainingtime
by spending the augmentation effort on only the challenging data-
points while skipping augmenting for ideal or near-ideal examples.!"


!



	 	
	

 
Figure 3: An overview of Sensei for one seed image in oneepoch.Givenimagesareonlyforillustrationpurposeswith-out proper scaling.
Algorithm2: Overall algorithm
Input:Training set ( X,Y), number of training epochs nE, population
sizepopSize, crossover probability p
Output:ModelM
1epoch:= 1;
2M:=train(X,Y); // train M with original data in first epoch
3foriinrange(0, |X|)do
4Popi:=randomInitPopulation( X[i]);
5isPWRobust i:= False;
6end
7whileepoch<nEdo
8epoch:=epoch+1;
9foriinrange(0, |X|)do
10 ifisPWRobust ithen
11 isPWRobust i:=isRobust( X[i]);
12 continue; // selective augmentation
13 children:=genPop(Pop i,p, popSize ); // Alg.3
14 f:=fitness(M, children ); // Equation 5
// replace original data with child with highest fitness
15 X[i]:=selectBest(children, f);
16 Popi:=select(children, f); // new population
17 isPWRobust i:=pointWiseRobust( X[i], Popi);
18end
19M:=train(X,Y);
20end
Figure 3 presents an overview of the proposed framework, Sen-
sei, for one seed image and for one epoch. There are two maincomponents in Sensei: i) optimal augmentation and ii) selective
augmentation,whichbasicallyrealizethetwoaforementionedin-
sights. Algorithm 2 provides even further detail on how the overall
approach is overlaid on the multi-epoch training schedule of M.
Sensei starts training Mwith the original data point in the first
epoch(line2).However,fromthesecondepoch,the optimalaug-
mentation module efficiently finds the most potential variation ( x/prime)
Fuzz Testing based Data Augmentation to Improve Robustness of Deep Neural Networks ICSE ‚Äô20, May 23‚Äì29, 2020, Seoul, Republic of Korea
that challenges Mthe most, replace xwithx/primeand usex/primefor train-
ing(line13-16).The selectiveaugmentation moduleisintendedto
optimize the training time. When it is enabled, Sensei does not
augment every data-point ( x) right away. Rather, the selective aug-
mentation module first determines whether the current state of M
is robust around x. If so, Sensei-SAkeeps skipping the augmenta-
tion ofx(line 10-12, 17) until Mbecomes unrobust around x. Note
that, Sensei is in-training data augmentation approach, i.e., data
generationand augmentationhappen on-the-fly during training.
3.3 OptimalAugmentation
Theoretically, a DNN could be trained with infinite number of real-
istic variants ( x/prime) to increase the robust generalization. However, it
is impractical to explore many variations of original data-points in
abrute-forcefashion.Therefore,themainchallengeinautomatic
data augmentation is identifying the optimal variations of data-
points efficiently that would force the model to learn the correct
feature of the representing class. In Sensei, our key insight is that
sincethegeneticalgorithmiswell-knowntoexplorealargesearch
spaceefficientlytofindoptimalsolutionsbymimickingevolution
and natural selection, we can effectively employ it to find an op-timal variant for each data-point in each epoch to improve the
robust generalization. Furthermore, the iterative nature of genetic
algorithmsnaturallygetsoverlaidonthemulti-epochtrainingof
the DNN, whichmakes thesearch very efficient.
Adaptinggeneticalgorithms(GA)toanyprobleminvolvesde-
sign of three main steps: (i) representation of chromosomes, (ii)
generation of population usinggenetic operators, and iii) mathemat-
ical formulationof a fitness function.
3.3.1 RepresentationofChromosome. Ingeneticalgorithms(GA),
achromosome consists of a set of genesthat defines a proposed
solution that the GA is trying to solve. In Sensei, we representa chromosome as a set of operations that would be applied on agiven input to get the realistic variations, which is basically the
transformation vector /vecœÅ=/angbracketleftœÅ1,œÅ2,...,œÅk/angbracketrightdescribed in Section ??.
For instance, we can derive a realistic variation ( x/prime) of image ( x)
by rotating xby one degree and then translating it by one pixel,
simulatingthe angleand movement of camera in real life.
3.3.2 Generation of population. In GA, a population is a set of
chromosomesthatrepresentsasubsetofsolutionsinthecurrent
generation.InSensei,theinitialpopulation,whichisthepopulation
in the first epoch, are created randomly. In subsequent generations
(epochs),thepopulationis constitutedthroughtwogeneticopera-
tors:mutationandcrossover andthenthroughaselectiontechnique.
Given the current population, a crossover probability and
population size, Sensei applies mutation and crossover opera-tions on the chromosomes in the current population to gen-erate a new population, as presented in Algorithm 3. Muta-tion is performed by randomly changing a single operation
(change parameter) in the chromosome. Crossover is done to
create a new chromosome by merging two randomly selectedexisting chromosomes. Specifically, given two random chromo-somes:
c1={rotation:1,translation :2,shear:‚àí0.15}andc2=
{rotation:‚àí1,translation :‚àí3,shear:0.1}, thecrossover operatorAlgorithm3: Generationof population
Input:CurrentPopulation Pop, crossover probability p, population
sizepopSize
Output:OffSpring children
1children:= {};
2whilesize(children)<popSize do
3r:=U(0,1);
4ifr<pthen // use crossover
5 x1,x2:=selectParents(Pop );
6 x/prime
1,x/prime
2:=crossover( x1,x2);
7else // use mutate
8 x:=selectParent(Pop );
9 op:=randomSelectOp(Operations );
10 x/prime
1:=mutate(x,op);
11end
12ifisValid(x/prime
1)then
13 children=children‚à™x/prime
1
14end
15end
16returnchildren;
first generates a random number, rbetween 1 and the chromo-
some length ( l) and merges c1andc2by taking 1 to rtransfor-
mations from c1andr+1t oltransformations from c2to form
a new chromosome cn. For the given example, r=2 produces
cn={rotation:1,translation :‚àí3,shear:0.1}.Senseiapplies either
mutationorcrossoveroperationbasedonthegivencrossoverprob-ability.Itshouldbenotedthatonceanewchromosomeisgeneratedthroughthe mutationor crossover, itis validated tomake sure that
itiswithintherangeofeachtransformationthatwesetglobally
(line12).Furthermore,Senseialwaysappliestheresultingtransfor-
mationvector (chromosome)on theoriginalimage (asopposed to
applyingonanalready transformeddata)topreventtheresulting
data from being unrealistic. Once the new population is generated,
they are evaluated and only best set is passed as a current popula-
tionforthenextgeneration(line17inAlgorithm2).Thebestsetis
selected through a fitness function.
3.3.3 Fitness function. In GA, a fitness function evaluates how
close a proposed solution (chromosome) is compared to an optimal
solution.Thedesignofafitnessfunctionplaysanimportantrole
in GA since if the fitness function becomes the bottleneck of thesystem, the entire system would be inefficient. Furthermore, the
fitness function should be intuitive and clearly defined to measure
the quality of a given solution. In Sensei, we define the fitness
function based on the empirical loss of the DNN. More specifically,
since the training of DNN focuses on minimizing loss across the
entire training data-set, the variant that suffers in more loss by the
DNNshouldbe used in the augmented training to make the DNN
more robust. Formally:
floss(x/prime)=L(Œ∏,x/prime,y) (5)
Othermetricsasfitnessfunction. Anymetricthatquantifies
the quality of a DNN with respect to a test input may be used as
afitnessfunction.Someoftheconcreteexamplesincludeneuron
ICSE ‚Äô20, May 23‚Äì29, 2020, Seoul, Republic of Korea Xiang Gao, Ripon K. Saha, Mukul R. Prasad, and Abhik Roychoudhury
Table 1: Short data-set descriptions and statistics
Data-set #Train #Test #CL #MD Description
GTSRB 38047 12632 43 4GermanTraffic
SignBenchmark
FM 60000 10000 10 3 Zalando‚Äôs article
CFR 50000 10000 10 4 Object recognition
SVHN 73257 26032 10 2 Digit recognition
IMDB 345693 115231 5 2Face data-setwithgender& age labels
CFR:CIFAR-10 #CL:#Classes #MD:# DNN Models
coverage[ 24]andsurpriseadequacy[ 15].Nevertheless,thecom-
putation of the fitness function should be reasonably fast so that it
does not become the bottleneck of the system.
3.4 Selective Augmentation
Unliketraditionaltechniquesthataugmentallthedata-pointinthe
trainingsetirrespectivetheirnature,Sensei-SAskipsdata-points
thatarealreadyclassifiedby Mrobustly.Therefore,theselective-
augmentation technique is solely based on the robustness analysis
ofMw.r.t. a data-point x. We formalize the robustness w.r.t. a data-
point aspoint-wise robustness which could be determined based on
the followingtwo kinds metrics:
Classification-basedrobustness. Amodelis point-wiserobust
w.r.t. a data-point xif and only if it classifies xandallthe label
preserving realistic variations ( x/prime)correctly.
Loss-based robustness. A model is point-wise robust w.r.t. a
data-point xif and only if the prediction loss of xor any label pre-
servingrealistic variations ( x/prime)is not greater than a loss threshold.
For selective-augmentation, Sensei-SA first determines whether
Mis point-wise robust w.r.t. the seed. If the seed is robust, Sensei-
SA does not augment it until the seed is incorrectly classified by M
insubsequentepochsorthepredictionlossby Mislessthan loss
threshold. At any point, Mis unrobust w.r.t. the seed, Sensei-SA
uses the optimalaugmentationmodule to augment the seed.
4 EXPERIMENTAL SETUP
We evaluateSensei with respect to three research questions:
RQ1HoweffectivelydoesSenseiimprovetherobustnessofDNN
models compared to state-of-the-art approaches?
RQ2Howeffectivethe‚Äúselectiveaugmentation"moduleinreduc-
ing thetraining time?
RQ3Howdoesthevalueofhyper-parametersaffecttheeffective-
ness andefficiency of Sensei?
4.1 DatasetandModels
Since computer vision is one of the most popular applications of
deep learning, to evaluate our approach, we selected a wide range
ofimageclassificationdatasetsdescribedinTable1.Thesedatasets
cover various applications such as traffic sign classification, object
recognition,andage/genderprediction.Furthermore,allofthese
datasets have been widely used to evaluate training algorithms,
adversarial attack and adversarial defense techniques. For eachdataset,columns #Train,#Test,and #CLinTable1showthenumber
of training, testing images, and the number of classes, respectively.
Foreachdataset,wecollectedmultiplemodels(Column #MD)
fromopen-sourcerepositories.Morespecifically,weselectedfour
models for GTSRBfrom [28,38,39], three models from [ 28,36,37]
forFashion-MNIST (FM). The models for CIFAR-10 include Wide-
Resnet[44]andthreeResnet[ 13]modelswith20,32,50layers,re-
spectively, which are collected from [ 33]. ForSVHN,w eu s e da
VGGmodel[ 28]andamodelfrom[ 34].AsforIMDB,weconsider
twomodels:VGG16and VGG19[ 28][35].Exceptaugmentingthe
trainingdata,wedonotchangetheoriginalmodelarchitectures.
All the detailed parameters can be found in repository of Sensei1.
4.2 Generationof Realistic Variations
SenseifocusesonimprovingtherobustnessofDNNmodelsbyaug-
mentingtrainingdatawithnaturalenvironmentalvariations.Since,
we focus on the applications with image, we choose two major
kindsofimageoperations:i)geometricoperationsii)coloropera-
tions to simulate the camera movements and lighting conditions in
real life. To make sure the translated images are visually similar to
natural ones, we restrict the space of allowed perturbations follow-
ing [8] where it is applicable. The operations and corresponding
restrictions with respect to an image xare as follows:
‚Ä¢rotation(x,d): rotatexbyddegree within a range [-30, 30].
‚Ä¢translation( x,d):horizontallyorverticallytranslate xbydpixels
withina range of [-10%, 10%] of image size.
‚Ä¢shear(x,d): horizontally shear xwith a shear factor dwithin a
range of [-0.1, 0.1].
‚Ä¢zoom(x,d): zoom in/out xwith a zoom factor dranging [0.9,1.1]
‚Ä¢brightness( x,d):uniformlyaddorsubtractavalue dforeachpixel
ofxwithina range of [-32, 32]
‚Ä¢contrast(x,d):scaletheRGBvalueofeachpixelof xbyafactor
dwithinrange of [0.8, 1.2]
Theseimageoperationspreservethecontentoforiginalimage.
Sinceimagesin these datasets do not have any information about
the pixels outsidetheirboundary, the space beyond the boundary
is assumed to be constant 0 (black) at every point.
4.3 Evaluation Metric
Since Sensei is focused on improving the robustness of DNN mod-
els,followingEngstrometal.[ 8],wecomputerobustaccuracyof
Sensei to answer each research question. More specifically, robust
accuracyistheproportionofimagesinthetestingdatasetwhere
the prediction of a DNN does not fluctuate with any small realistic
perturbations.Formally,letusassumethatthereisanimage xin
the testing datasetthat belongs to a class c.TSis a set of paramet-
ric transformations with a size of m. Applying a transformation
ts‚ààTSonxgives us a transformed image x/prime.X/primeis the set of all
transformed images resulting from TS.S o|TS|=|X/prime|. A DNN is
robust around xif and only if M(x/prime)=cfor allx/prime‚ààX/prime. Finally, let
usassumethat nInstances isthenumberofimagesinthetesting
dataset,andamongthem nRobustInstances isthenumberofimages
whereMisrobust.Thentherobustaccuracyof Mforthedataset
is:
1https://sensei-2020.github.io
Fuzz Testing based Data Augmentation to Improve Robustness of Deep Neural Networks ICSE ‚Äô20, May 23‚Äì29, 2020, Seoul, Republic of Korea
robustaccuracy =nRobustInstances
nInstances(6)
5 EXPERIMENTAL RESULTS
5.1 Implementation
WeimplementSenseiontopofKerasversion2.2.4(https://keras.io),
whichisawidelyusedplatformthatprovidesreliableAPIsfortrain-
ing and testing DNNs. More specifically, we implement a new data
generator that augments the training data during training. Our
datageneratortakesasinputsthecurrentmodelandoriginaltrain-
ingset,augmentstheoriginaldataandthenfeedstheaugmented
data to the training process at each step. The augmented data is
generated and selected using the approach described in Section 3.
5.2 ExperimentalConfigurations
Weconductedalltheexperimentsonamachineequippedwithtwo
TitanVGPUsandXeonSilver4108CPU128Gmemoryand16.04
Ubuntu.Alltheexperimentspecificconfigurationsaredescribedin
the respective answers. Since genetic algorithm in Sensei involves
random initialization and decision, we ran each experiment five
timesindependently and reported the arithmetic average results.
5.3 RQ1: Effectiveness of Sensei
We perform a comprehensive set of experiments to evaluate the
effectivenessof Senseicomparedtothestate-of-the-artdataaug-
mentationapproaches from various perspectives.
5.3.1 Exp-1: Does Sensei solve the saddle point problem effectively?
AsweexplainedinSection3.1,theeffectivenessofadataaugmenta-
tion technique lies in how effectively it solves the inner maximiza-
tion of the saddle point problem in Equation 4. Therefore, in our
first experiment, we check whether Sensei is indeed effective in
finding the most lossy variants effectively than the state-of-the-art
techniques.Tothisend,wetrainedeachmodelfollowingthreedata
augmentationstrategies:
(1)Randomaugmentation .Thisisoneofthemostfrequently
used data augmentation strategies in practice since it is abuilt-in feature in the Keras framework. In this approach,givenasetofperturbations,arandomperturbationisper-
formed for each image at each step (epoch). However, to
makethecomparisonfairwecustomizetheapproachtogive
it the same combination of transformations as in Sensei.
(2)W-10.Themostrecentdataaugmentationapproachfornat-
uralvariants,whichiscalledWorst-of-10[ 8].W-10generates
tenperturbationsrandomlyforeachimageateachstep,and
replacestheoriginalimagewiththeoneonwhichthemodel
performs worst [8] (e.g. highest loss).
(3)Sensei.TomakethecomparisonfairwithW-10,theresults
of Sensei are generated using a population size of 10.
Results. Figure 4 presents the logarithmic training loss for two
models: GTSRB-1 and CIFAR-10-1. The results show that although
Senseistartswithverysimilarperformanceintheinitialepochs,
due to the systematic nature of Sensei, soon it outperforms W-
10 for every model and dataset. Therefore, the genetic algorithm(a) GTSRB-1 (b) CIFAR-10-1
Figure 4: Effectiveness in identifying most lossy variants intwo models GTSRB-1 and CIFAR-10-1 (under T3)
baseddataselectioninSenseiismoreeffectivetosolvetheinner
maximizationproblem than RandomandW-10based techniques.
5.3.2 Exp-2: Does Sensei perform better than the state-of-the-art
data augmentation techniques in any number of transformations? It
isharderto achieverobustaccuracyas thenumberoftransforma-
tionoperatorsincreasessincetherearejustmoreoptionstofoolthe
model.Therefore,wefurtherinvestigatehowtheeffectivenessof
Sensei vary as the number of transformations increases. We calcu-
laterobustaccuracyunderthree(T3)andsiximagetransformationoperators(T6)separately.T3experimentationincludestherotation,
translation,and shear image operations as defined in Section 4.2.
Results. Table2presentscoreresultsofthepaper,whichshows
the robust accuracy of all the models trained using the Standard,
Random,W-10and Sensei strategy using three and six transforma-
tion operators. From the results using T3, we see that even though
theStandard training achieves over 91% average standard accu-
racy (shown in column TestAcc), the robust accuracy sharply drops
to 5% on average (Column 4). Randomaugmentation and W-10
basedtrainingsignificantlyimprovetherobustaccuracyforeach
dataset. However, Sensei achieves the highest robust accuracy for
allmodelsofalldata-sets(highlighted).Senseiimprovedtherobust
accuracy from 8.2% to 18.7% w.r.t. random augmentation and from
1.7% to 6.1% w.r.t. state-of-the-art W-10. When we increased the
number of transformation operators from three (T3) to six (T6),
we see that the robust accuracy for all augmentation strategies
decreased significantly. This is expected due to two facts: i) under
T6, the generated variants are less similar with original images and
ii) under T6, a larger number of perturbations are generated for
eachimage,andanimageismorelikelytobeconsideredasmisclas-
sified, since an image will be regarded as misclassified if one of its
perturbation is misclassified. However, in this harder problem, the
improvementbySenseicomparedtobothrandomaugmentation
andW-10isgreaterthanthatofT3.Onaverage,Senseiachieves
22.2% higher robust accuracy than Random, and 6.6% than W-10.
ThisalsodemonstratesthatSenseiperformsbetterinlargersearch
space. Please note that we do not evaluate the models designed
for IMDB with six transformation operators, because face image is
very sensitive to the change of color palette.
5.3.3 Exp-3: Does Sensei perform better than the adversarialexample-based retraining approaches? In Section 2.4, we briefly
described how data augmentation can be performed during ini-
tialtrainingvs.adversarialretraining.Theeffectivenessof Sensei
ICSE ‚Äô20, May 23‚Äì29, 2020, Seoul, Republic of Korea Xiang Gao, Ripon K. Saha, Mukul R. Prasad, and Abhik Roychoudhury
Table 2: The robust accuracy for Random, W-10 andSensei. Sensei uses loss-based fitness function.
Model Size(MB) TestAccRobustaccuracyunder3 trans. op. (T3 )Robustaccuracyunder6 trans. op.(T6 )
Standard Random W-10 Sensei Standard Random W-10 Sensei
GTSRB-1 16 98.00 3.20 77.60 85.80 90.80 2.10 49.90 64.00 67.90
GTSRB-2 258 95.40 2.40 70.80 84.60 86.30 1.60 44.70 57.30 62.10
GTSRB-3 11 97.92 0.70 72.10 83.30 88.70 0.60 42.40 56.70 64.40
GTSRB-4 114 95.31 1.60 72.80 82.40 86.90 1.10 35.10 58.10 65.40
FM-1 305 92.80 0.20 65.70 79.20 83.60 0.00 39.90 64.20 70.50
FM-2 21 92.70 0.30 60.20 72.20 78.00 0.00 39.70 61.90 68.80
FM-3 6 92.79 0.20 63.10 73.90 77.40 0.00 38.20 57.60 65.40
CIFAR-10-1 7 88.32 1.30 52.20 61.80 67.20 0.10 33.10 47.10 55.20
CIFAR-10-2 279 88.54 1.40 56.70 64.90 67.90 0.10 35.30 48.80 56.20
CIFAR-10-3 5 88.01 1.80 73.30 76.50 81.50 0.40 57.40 70.60 72.50
CIFAR-10-4 3 87.09 1.10 47.50 60.10 66.20 0.04 28.20 44.30 54.70
IMDB-1 88 85.81 28.00 69.00 71.90 79.60 -- --
IMDB-2 126 84.97 29.30 74.10 81.90 83.90 -- --
SVHN-1 7 94.01 0.40 75.20 83.60 85.50 0.20 72.90 82.40 84.00
SVHN-2 29 92.82 0.70 56.00 67.80 74.90 0.40 52.10 58.90 70.80
AVG - 91.63 4.84 65.75 75.33 79.89 0.51 43.76 59.38 65.99
lies in that it effectively selects the optimal variation of the seed
data, epoch by epoch. In contrast, in retraining based approach,once the adversarial examples are selected, they are fixed across
epochs. Inthis experiment,we comparethese two approaches.To
thisend,followingthepopularretrainingapproaches[ 15,24],we
replicated the adversarial training in a benign setting. The step
includes:i)trainingthemodelusingtheoriginaltrainingdata,ii)
generating the adversarial examples by our transformations, i.e.,
thevariantsthatfooltheDNNs,iii)selectingthebestadversarial
examples, adding in the training data, and retraining the model
for 5 additional epochs. To make the comparison fair, we generate
theequalnumberofvariantsinStep-2asof Sensei.Forexample,
if Sensei generates 10 variants per data-point in one epoch and
runs100epochs,wegenerate1,000adversarialexamplesforagiven
data-point, and choose the best variant of each data by the loss
function.Westillusetheattackmodelandevaluationmetricshown
in Section 4.3.
Table 3: Average robust accuracy bySensei vs.Retraining
Approach GTSRB FM CIFAR-10 IMDB SVHN
Retraining 78.26 68.24 43.72 70.21 68.30Sensei 88.18 79.67 70.70 81.75 80.20
Results. Table 3 presents the average robust accuracy of all
modelsforSenseiandtheretrainingbasedapproach.Theresults
show that Sensei improves the robust accuracy from 10% to 27%
comparedtoadversarialretraining,andtheresultsareconsistent
across all datasets. Therefore, although adversarial retraining is
very effective in a security-aware setting,Sensei is more effective
in improving robust generalization in a benign setting.
5.3.4 Exp-4:CanSenseipreservethestandardaccuracywhileim-
provingrobustgeneralization? Improvingtherobustaccuracywould
onlyaddvalueif Senseicanretainthestandardaccuracy.Therefore,
we investigate how Sensei performs in terms of standard accuracy.Results. Table 4 presents the averagestandard accuracy of the
experimented models without data augmentation (2nd column)and trained by Sensei (4th column). Results show that the orig-inal (Standard) models are highly accurate. After we augmented
eachmodelbySenseitoincreasetheirrobustgeneralization,the
standard accuracy increased even further for four out five datasets.
5.3.5 Exp-5: How does Sensei perform compared to other state-of-the-art generalization techniques? mixup[
46] is a recent data
augmentation approach that improves standard generalization and
also guards against pixel-level perturbations in security-aware set-
tings.mixuptrains a neural network on convex combinations of
pairsofexamplesandtheirlabelstofavorsimplelinearbehavior
in-betweentrainingexamples.mixup‚Äôssource-codetoreplicatethe
results for CIFAR-10 is available online [ 46]. We adapted mixup
in our setting, verified with CIFAR-10 that our result is consistent
with [46],and ranit for all the models and dataset in our study.
Table 4: Average accuracy of mixup vs.Sensei
ModelsStandard accuracy Robustaccuracy
Stand. mixup Sensei Stand. mixup Sensei
GTSRB 96.65 97.24 97.43 1.98 1.72 88.18
FM 92.77 92.95 89.53 0.23 1.69 79.67
CIFAR-10 87.98 92.45 90.93 1.40 1.69 70.70
IMDB 85.40 89.51 88.30 28.65 30.23 81.75
SVHN 93.40 95.94 94.60 0.55 0.25 80.20
Results. Table4comparestheaveragerobustaccuracyachieved
by mixup and Sensei both for standard generalization and ro-
bust generalization across all models. The results show that mixup
and Sensei both overall imp rovedstandard generalization. In fact,
mixup is a little better than Sensei for standard generalization.However, mixup performed poorly in improving robust general-
ization for real-world naturally occurring variants. It performed
Fuzz Testing based Data Augmentation to Improve Robustness of Deep Neural Networks ICSE ‚Äô20, May 23‚Äì29, 2020, Seoul, Republic of Korea
marginallybetterthanno-augmentation.Incontrast,Senseiclearly
outperformed mixup for every dataset for robust generalization.
Comparison with Yang et al. [42] . Very recently, Yang et al.
have proposed an approach to increase DNN robustness to spa-
tial transformations, by modifying the loss function of the DNN.
Specifically,theyretaintherandomW-10augmentationstrategy[ 8]
butaddan invariant-inducing regularization term to the standard
empirical loss, to boost robustness. However, their technique is
implementedinadifferentframework(TensorFlow,versusKeras
forSensei)andtheirexperimentsareperformedonsignificantly
differentDNNmodelsandwithdifferenttransformations(only2
versus up to 6 used by Sensei) and evaluation metrics. This makes
afair,head-to-headquantitativecomparisoninfeasibleatpresent.
However, for an initial assessment of relative performance, we ran
SenseionCIFAR-10,withamodel substantiallysimilar tooneused
in [42], and using the same two transformations. The results show
thatSenseireducestheerror(theevaluationmetricusedin[ 42])
by23.5%overW-10whiletheirtechniquereduceditby21.9%,as
reportedin[ 42].Thus,Senseicanmatchorsurpasstheirtechnique
in this case.
Conceptually, Sensei and [ 42] improve DNN robustness
throughfundamentally differentmechanisms.Senseiusesa data-
augmentation approach ‚Äì a black-box technique, while Yang et
al.useare-designedlossfunction‚Äìawhite-boxapproach.These
techniques are thus complementary and combining them for even
greater robustness improvement could be interesting future work.
Senseisolvesthe innermaximization problemmore effec-
tively than the state of the art. It is able to improve the robust
accuracyoftheDNN,comparedtothestateoftheart,oneach
of the 15 models, by upto 11.9%, while retaining standard test
accuracy.Furthermore,forbenignvariations,Senseioutper-
formsdataaugmentationapproachesboththatarebasedon
adversarial retraining or that target standard generalization.
5.4 RQ2: Effect of Selective Data Augmentation
We analyze the performance of Sensei-SA in terms of (i) train-
ing time and (ii) robust accuracy compared to Sensei and W-10.
Notethatthestandardtrainingrequiresonlyoneforwardpropa-
gationforcalculatingthelossandonebackwardpropagationfor
calculating gradients to update the weights per data-point at each
epoch.However,thetrainingtimewithdataaugmentationincludes
the additional time for optimal selection. Specifically, Sensei re-
quiresNadditional forward propagation to calculate the fitness of
Nnewly generated population (same for W-10to find the worst
case). Following the standard protocol [ 16], we do not count the
imagetransformationtimebecausethesetasksarecompletedon
CPU,whichisexecutedinparallelwiththetrainingtaskprocessed
on GPU. For this experiment, we set loss threshold in Sensei-SA to
1e‚àí3 (described in Section 3.4).
Table 5 summarizes the robust accuracy and training time for
allthe dataset.Column Improvement representsthe improvement
achieved by Sensei-SA compared to W-10and the last column
presentsCohen‚ÄôsDvalues[ 5]toshowtheeffectsizeofimprove-
mentsoverthefiveruns. TheevaluationresultsindicatethatSen-
sei-SA significantly improve robust accuracy over W-10.F r o mt h eTable 5:Sensei-SA vs.W-10 and Sensei
ModelsRobustaccuracy/ Training time(min)
W-10 Sensei Sensei-SA Improve D-value
GTSRB 84.03 / 18.4 88.18 / 18.8 86.13 / 11.9 2.10/ 36% 6.3
FM 75.10 / 28.2 79.67 / 29.3 78.63 / 20.9 3.53/ 21% 25.6
CIFAR-10 65.83 / 192 70.70 / 158 69.40 / 120 3.57/ 34% 35.0
IMDB 76.90 / 946 81.75 / 962 81.09 / 952 4.19/ (1%) 22.3
SVHN 75.70 / 58.8 80.20 / 58.9 79.65 / 51.5 3.95/ 13% 42.5
results,wecanalsoseethatwiththehelpofselectiveaugmentation,
Sensei-SA reduced the training time by 25% on average. The train-
ingtimeofmodelsfor IMDBisnotsignificantlyreduced,because
predicting the age of a person is very hard even for human, and
onlyveryfewdatapointsarerobustenoughtobeexcludedfrom
augmentation. It should be noted that although Sensei-SA selec-
tively augmented the data points, on average, the robust accuracy
achieved by Sensei-SA is 3% higher than that of W-10. However,
compared to Sensei, Sensei-SA reduced the robust accuracy by
0.5-1.5%for mostof the models.
On average, Sensei-SA reduces the training time by 25%,
whileit improves robust accuracy by 3% compared to W-10.
5.5 RQ3: Sensitivity of Hyper-Parameters
In this section, we evaluate how the choice of different hyper-
parametersinfluencethe performance of Sensei.
	
					


      	

		 	
	
	
      
	

	



	

      
	

Figure 5: Robust accuracy and normalized training time for
one model in (a) GTSRB (b) CIFAR-10 and (c) FM bySensei
5.5.1 Populationsize. Sincepopulationsizeisanimportantparam-
eter in any genetic search [ 26], we evaluate Sensei using different
population size. Figure 5 presents the robust accuracy and training
timeofthreemodelstrainedbySenseiwithpopulationsizerang-
ing (3, 30). The training time in the graph is normalized compared
tothetrainingtimeofpopulationsizeof3.Theresultsshowthat
therobustaccuracyineachmodelincreaseswiththeincreaseof
populationsize.However,ahighpopulationsizealsoimpactsthe
trainingtimenegatively.ResultsshowthatSenseiworksefficiently
when the population size is between 10 and 15. Further increase of
the population size does not improve the robust accuracy a lot.
Sensei works efficiently between the population size 10
and 15 for both robust accuracy and training time.
ICSE ‚Äô20, May 23‚Äì29, 2020, Seoul, Republic of Korea Xiang Gao, Ripon K. Saha, Mukul R. Prasad, and Abhik Roychoudhury
Table 6: The robust accuracy of Sensei with loss-based and
coverage-based fitness function
Fitness GTSRB FM CIFAR-10 IMDB SVHN
Loss-based 88.18 79.67 70.70 81.75 80.20
Neuron Coverage 85.17 79.32 69.90 81.40 80.43
5.5.2 Fitnessfunction. Theefficiencyofageneticsearchdependsa
lotonthefitnessfunction.AlthoughweevaluatedSenseirigorously
usingloss-based fitnessfunction,aswediscussedinSection3.3.3,
other metrics such as neuron coverage-based [24]o rsurprise ade-
quacy[15]canbealsousedasafitnessfunction.Table6presents
the robust accuracy of Sensei for neuron coverage based fitness
function.Theresultsshowthatbothloss-basedandcoverage-based
fitness functions achieve very similar robust accuracy. Since sur-
prise adequacyis correlated toneuron coverage [ 15],weexpecta
similarperformancealsousingsurpriseadequacy.However,loss
basedfitnessfunctionmaybeabetterchoicesinceneuroncoverage
based fitness function increases the training time by 50% than that
of loss-based fitness function. The reason is that computation of
neuron coverage is more expensive than training loss.
Thestate-of-the-artDNNqualitymetricssuchasneuron
coverage show similar performances in terms of robust ac-curacy and thus, can be used as a fitness function in Sensei
forrobustgeneralization.However, loss-based fitnessfunction
maybe a better choice due to shorter training time.
Table 7: Effect of selection metric in Sensei-SA in terms of
average robust accuracy (loss threshold: 1e-3)
Metrics GTSRB FM CIFAR-10 IMDB SVHN
Loss-based 86.13 78.63 69.40 81.09 79.65
Classification-based 79.08 64.33 49.35 63.00 63.42
5.5.3 Selectionmetrics. Theperformanceof Sensei-SAintermsof
bothrobustaccuracyandtrainingtimedependsontheeffectiveness
of thepoint-wise robustness metric (defined in Section 3.4). The
evaluation results in Table 7 show that the loss-based selection
outperforms the classification-based selection for all the models.
The reason is that the loss-based selection is more conservative
than the classification-based selection. Still, loss-based selection is
good enough to skip sufficient number of data-points to achieve
25% trainingtime reduction, on average.
Loss-basedrobustness isbetterthan classification-basedro-
bustnessin selective augmentation.
5.5.4 Lossthreshold. Inloss-based selection,thelossthresholdis
one of the important factors that may affect the effectiveness of
Sensei-SA.Figure6showsrobustaccuracyandnormalizedtrainingtimeof Sensei-SAwithlossthresholdinrange(0,1e
‚àí1).Thetrain-
ing time is normalized to Standard training time. From the results,
	





	
	
 
	
	





				

	





	


Figure6:Therobustaccuracyandnormalizedtrainingtime
ofonemodelfrom(a)GTSRB(b)CIFAR-10(c)FMtrainedbySensei-SE with variouslossthresholds in range (0, 1e‚àí1).
as expected we observe that both the robust accuracy and training
timedecreasewiththeincreaseoflossthreshold.H owever, some
datasets are more sensitive to the loss threshold than the others in
terms of robust accuracy. For instance, the robust accuracy for the
CIFAR-10model isverysensitive tothelossthreshold.However,robust accuracy of GTSRB and FM models did not decrease a lot
whenwe changed the loss threshold from 1e-5 to 1e-3.
The effect of loss threshold in selective augmentation is
datasetspecific. However, a value of 1e-3 showed a balanced
performance across datasets in terms of robust accuracy.
5.6 Threatsto Validity
Internal validity: We have tried to be consistent with established
practice in the choice and application of image transformations,and training schedule for DNNs. For parameters specific to our
technique,includingpopulationsizeandfitnessfunctionforGA,
selection function and loss threshold for selective augmentation
we have performed a sensitivity analysis to justify the claims.
External validity: Although we used 5 popular image datasets,
and several DNN models per dataset in our evaluation, our results
may not generalize to other datasets, or models, or for other ap-
plications. Further, our experiments employ six commonly used
imagetransformations,tomodelnaturalvariations.However,our
results may not generalize to other sources of variations.
6 RELATED WORK
ADNNcanbeviewedasaspecialkindofprogram.Softwareen-
gineering techniques for automated test generation, as well fortest-driven program synthesis and repair, have either directly in-
spired or have natural analogs in the area of DNN testing and
training. The contributions of these techniques relative to ours can
be compared in terms of the following four facets.
Test adequacy metrics. Inspired by structural code coverage
criteria,Peietal.[ 24]proposedNeuronCoveragetomeasurethe
quality of a DNN‚Äôs test suite. DeepGauge [ 19] built upon this work
and introduced a number of finer-grained adequacy criteria, in-
cludingk-Multisection Neuron Coverage and Neuron Boundary
Coverage. Kim et al. [ 15] also proposed a metric called surprise ad-
equacy to select adversarial test inputs. MODE [ 20] performs state
differentialanalysistoidentifythebuggyfeaturesofthemodeland
Fuzz Testing based Data Augmentation to Improve Robustness of Deep Neural Networks ICSE ‚Äô20, May 23‚Äì29, 2020, Seoul, Republic of Korea
then performs training input selection on this basis. Our contribu-
tionisorthogonaltothesetestselectioncriteria.Wedemonstrate
howtoinstantiateourtechniquewitheitherstandardmodelloss
or neuron coverage. In principle, Sensei could be adapted to use
othercriteriaas well.
Testgenerationtechnique. The earliest techniques proposed
for DNN testing were in a security setting, as adversarial testing,
initially for computer vision applications. Given an image, the aim
is to generate a variant, with a few pixels selectively modified ‚Äì
anadversarial instance ‚Äì on which the DNN mis-predicts. Such
techniques include [ 29], FGSM [ 12], JSMA [ 23] and so on. At a
high level, these approaches model the generation of adversarialexamplesasanoptimizationproblemandsolvetheoptimizationproblem using first-order methods (gradient ascent). Generative
machinelearning,suchasGAN[ 11],canalsobeusedtogenerate
adversarial inputs. In contrast to the above techniques, our focus is
thespaceofbenignnaturalvariations,suchasrotationandtrans-
lation. Engstrom et al. showed that such transformations yield anon-convex landscape not conducive to first-order methods [
8].
Thus, our test generation technique uses fuzzing, based on genetic
search. Recently, Odena and Goodfellow proposed TensorFuzz [ 22]
thatcombinescoverage-guidedfuzzingwithproperty-basedtestingtoexposeimplementationerrorsinDNNs.However,theircoverage
metric, property oracles, and fuzzing strategies are all designed
around this specific objective and not suitable for our objective of
data augmentation driven robustness training. DeepXplore [ 24]
generates test inputs that lead to exhibit different behaviors by
different models for the same task. Our approach does not require
multiplemodels.DeepTest[ 30]andDeepRoad[ 47]usemetamor-
phic testing to generate tests exposing DNN bugs in the context of
anautonomousdrivingapplication.WhileSensei‚Äôssearchspaceis also defined using metamorphic relation, the mode of explor-
ing the search space (genetic search) and incorporating them (data
augmentation)is fundamentally different from these techniques.
Test incorporation strategy. The vast majority of DNN test
generationtechniques[ 14,15,17,24,30,31]firstuseatrainedDNN
togeneratethetests(oradversarialinstances)andthenusethemtore-traintheDNN,toimproveitsaccuracyorrobustness.Bycontrast,
SenseifallsinthecategoryofdataaugmentationapproacheswherenewtestdataisgeneratedandusedduringtheinitialDNNtraining.
As shown in our evaluation our data augmentation yields better
robustness compared to the former generate and re-train approach.
Dataaugmentationcanbeperformedwithdifferentobjectives.
AutoAugment [ 6] uses reinforcement learning to find the best aug-
mentationpoliciesinasearchspacesuchthattheneuralnetwork
achievesthehighest(standard)accuracy.Mixup[ 46]isarecently
proposedstate-of-the-artdataaugmentationtechniquethattrainsaneuralnetworkonconvexcombinations ofpairsofexamples(suchasimages)andtheirlabels.Ourevaluation(Section5)confirmsthat
mixupimprovesbothstandardaccuracyandrobustaccuracyina
security setting but performs poorly in terms of robust accuracy in
abenignsetting.Bycontrast,Sensei,withacompletelydifferent
search space and search strategy excels in this area.
OurworkisinspiredbythetheoreticalworkofMadryetal.[ 21]
whoformulatedthegeneraldataaugmentationproblemasasad-
dlepointoptimizationproblem.Ourworkinstantiatesapracticalsolution for that problem in the context robustness training for be-
nignnaturalvariationsbyusingageneticsearchnaturallyoverlaid
on the iterative training procedure for a DNN. The work closestto ours is the one by Engstrom et al. [
8] who were the first to
show that benign natural image perturbations, notably rotationand translation, can easily fool a DNN. They proposed a simple
dataaugmentationapproachrandomlysampling Nperturbations
and replacing the training example with the one with the worst
loss.Ourapproachimprovesonboththerobustaccuracyaswell
as the training time of Engstrom‚Äôs approach, by using a systematic
genetic search to iteratively find the worst variant to augment and
usingalocalrobustnesscalculationtosavetheaugmentationand
training time.
Robustmodels. Recently,Yangetal.[ 42]proposedanorthogo-
nal approach to improve the robustness deep neural network mod-
elsbymodifyingtheDNNlossfunctionandaddinganinvariant-
inducingregularizationtermtothestandardempiricalloss.Con-
ceptually, this regularization based white-box approach is comple-
mentary to our black-box approach of data augmentation. Combin-
ing the two approaches, for even greater robustness improvement,
could be interesting future work.
7 CONCLUSION
Recent research has exposed the poor robustness of DNNs to small
perturbationstotheirinput.Asimilarlackofgeneralizabilitymani-
fests, as the over-fitting problem, in the case of test-based program
synthesis and repair techniques where test generation techniques
have recently been successfully employed to augment existing
specifications ofintended programbehavior. Inspiredby theseap-
proaches,inthispaper,weproposedSensei,atechniqueandtool
that adapts software testing methods for data augmentation ofDNNs, to enhance their robustness. Our technique uses genetic
search to generate the most suitable variant of an input data to use
for training the DNN, while simultaneously identifying opportuni-
ties to accelerate training by skipping augmentation, with minimal
loss of robustness. Our evaluation of Sensei on 15 DNN modelsspanning 5 popular image datasets shows that, compared to thestate of the art, Sensei is able to improve the robust accuracy of
the DNNs by upto 11.9% and on average 5.5%, while also reducing
the DNN‚Äôstrainingtimeby 25%.
Since significant amount of decision making in public-facing
softwaresystemsarebeingaccomplishedviadeepneuralnetworks,reasoningaboutneuralnetworkshasgainedprominence.Insteadof
developing verification or certification approaches, this paper has
espoused the approach of data augmentation via test generation to
improveorrepairhyper-propertiesofdeepneuralnetworks.Ina
broadersense,thisworkalsoservesasanexampleofharnessing
therichbodyofworkontesting,maintenance,andevolutionfor
traditionalsoftware, for developing AI-based software systems.
ACKNOWLEDGMENTS
ThisworkwaspartiallysupportedbytheNationalSatelliteofExcel-
lence in Trustworthy Software Systems, funded by NRF Singapore
underNationalCybersecurity R&D(NCR) programme.
ICSE ‚Äô20, May 23‚Äì29, 2020, Seoul, Republic of Korea Xiang Gao, Ripon K. Saha, Mukul R. Prasad, and Abhik Roychoudhury
REFERENCES
[1]Rajeev Alur, Rishabh Singh, Dana Fisman, and Armando Solar-Lezama. 2018.
Search-based Program Synthesis. Commun.ACM 61 (2018).
[2]Aharon Ben-Tal, LaurentEl Ghaoui,and ArkadiNemirovski. 2009. Robust opti-
mization. Vol. 28. Princeton University Press.
[3]Mariusz Bojarski, Davide Del Testa, Daniel Dworakowski, Bernhard Firner, Beat
Flepp,PrasoonGoyal,LawrenceDJackel,MathewMonfort,UrsMuller,Jiakai
Zhang, et al .2016. End to end learning for self-driving cars. ArXiv preprint
arXiv:1604.07316 (2016).
[4]NicholasCarliniandDavidWagner.2017. Magnetand"efficientdefensesagainst
adversarial attacks" are not robust to adversarial examples. ArXiv preprint
arXiv:1711.08478 (2017).
[5]JacobCohen.2013. Statisticalpoweranalysisforthebehavioralsciences .Routledge.
[6]Ekin D. Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan, and Quoc V. Le.
2019. AutoAugment: Learning Augmentation Strategies From Data. In The IEEE
Conferenceon Computer Vision and Pattern Recognition (CVPR) .
[7]Pedro M Domingos. 2012. A few useful things to know about machine learning.
Communicationof the ACM 55,10 (2012), 78‚Äì87.
[8]Logan Engstrom, Brandon Tran, Dimitris Tsipras, Ludwig Schmidt, and Alek-
sander Madry. 2019. Exploring the Landscape of Spatial Robustness. In Interna-
tionalConferenceon Machine Learning (ICML) . 1802‚Äì1811.
[9]Yu Feng, Ruben Martins, Osbert Bastani, and Isil Dillig. 2018. Program synthesis
usingconflict-drivenlearning.In Proceedingsofthe39thACMSIGPLANConference
on Programming Language Design and Implementation (PLDI). ACM, 420‚Äì435.
[10]XiangGao,SergeyMechtaev,andAbhikRoychoudhury.2019. Crash-avoiding
ProgramRepair.In ACMSIGSOFTInternationalSymposiumonTestingandAnalysis
(ISSTA).
[11]IanGoodfellow,JeanPouget-Abadie,MehdiMirza,BingXu,DavidWarde-Farley,
Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative adversarial
nets.InAdvances in Neural Information Processing Systems (NIPS). 2672‚Äì2680.
[12]Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. 2015. Explaining
and harnessing adversarial examples. In International Conference on Learning
Representations(ICLR) .
[13]KaimingHe,XiangyuZhang,ShaoqingRen,andJianSun.2016. Deepresidual
learningforimagerecognition.In ProceedingsoftheIEEEconferenceonComputer
VisionandPatternRecognition (CVPR) . 770‚Äì778.
[14]Ling Huang, Anthony D Joseph, Blaine Nelson, Benjamin IP Rubinstein, and
JD Tygar. 2011. Adversarial machine learning. In Proceedings of the 4th ACM
Workshop on Security and Artificial Intelligence. ACM, 43‚Äì58.
[15]Jinhan Kim, Robert Feldt, and Shin Yoo. 2019. Guiding deep learning system
testingusingsurpriseadequacy.In Proceedingsofthe41stInternationalConference
on Software Engineering (ICSE). IEEE Press, 1039‚Äì1049.
[16]AlexKrizhevsky,IlyaSutskever,andGeoffreyEHinton.2012. Imagenetclassifica-
tionwithdeepconvolutionalneuralnetworks.In AdvancesinNeuralInformation
Processing Systems (NIPS). 1097‚Äì1105.
[17]AlexeyKurakin,IanGoodfellow,andSamyBengio.2017. Adversarialmachine
learning at scale. In International Conference on Learning Representations (ICLR) .
[18]Claire Le Goues, Michael Pradel, and Abhik Roychoudhury. 2019. Automated
Program Repair. Commun.ACM 62,12 (2019).
[19]LeiMa,FelixJuefei-Xu,FuyuanZhang,JiyuanSun,MinhuiXue,BoLi,Chunyang
Chen, Ting Su, Li Li, Yang Liu, et al .2018. Deepgauge: Multi-granularity testing
criteriafordeeplearningsystems.In Proceedingsofthe33rdACM/IEEEInterna-
tionalConferenceon Automated Software Engineering (ASE) . ACM, 120‚Äì131.
[20]ShiqingMa,YingqiLiu,Wen-ChuanLee,XiangyuZhang,andAnanthGrama.
2018. MODE:automatedneuralnetworkmodeldebuggingvia statedifferential
analysisandinputselection.In Proceedingsofthe201826thACMJointMeeting
on European Software Engineering Conference and Symposium on the Foundations
of Software Engineering (ESEC/FSE). ACM, 175‚Äì186.
[21]Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
AdrianVladu.2018.Towardsdeeplearningmodelsresistanttoadversarialattacks.
InInternationalConferenceon Learning Representations .
[22]AugustusOdenaandIanGoodfellow.2018. Tensorfuzz:Debuggingneuralnet-
works with coverage-guided fuzzing. In International Conference on Machine
Learning(ICML).
[23]NicolasPapernot,PatrickMcDaniel,SomeshJha,MattFredrikson,ZBerkayCelik,
and Ananthram Swami. 2016. The limitations of deep learning in adversarial
settings. In 2016 IEEE European Symposium on Security and Privacy (EuroS&P) .
IEEE,372‚Äì387.[24]Kexin Pei, Yinzhi Cao, Junfeng Yang, and Suman Jana. 2017. Deepxplore: Au-
tomated whitebox testing of deep learning systems. In Proceedings of the 26th
Symposium on Operating Systems Principles (SOSP). ACM, 1‚Äì18.
[25]ZichaoQi,FanLong,SaraAchour,andMartinRinard.2015. Ananalysisofpatch
plausibility and correctness for generate-and-validate patch generation systems.
InInternationalSymposiumon Software Testing and Analysis (ISSTA) .
[26]O.Roeva,S.Fidanova,andM.Paprzycki.2013. Influenceofthepopulationsize
onthegeneticalgorithmperformanceincaseofcultivationprocessmodelling.In2013FederatedConferenceonComputerScienceandInformationSystems.371‚Äì376.
[27]PatriceYSimard,DavidSteinkraus,JohnCPlatt,etal .2003. Bestpracticesfor
convolutional neural networks applied to visual document analysis.. In Proceed-
ingsoftheSeventhInternationalConferenceonDocumentAnalysisandRecogni-
tion(ICDAR), Vol. 3.
[28]Karen Simonyan and Andrew Zisserman. 2015. Very deep convolutional net-
works for large-scale image recognition. In International Conference on Learning
Representations(ICLR) .
[29]ChristianSzegedy,WojciechZaremba,IlyaSutskever,JoanBruna,DumitruErhan,
Ian Goodfellow, and Rob Fergus. 2014. Intriguing properties of neural networks.
InInternationalConferenceon Learning Representations (ICLR) .
[30]YuchiTian,KexinPei,SumanJana,andBaishakhiRay.2018. Deeptest:Automated
testing of deep-neural-network-driven autonomous cars. In Proceedings of the
40thInternationalConferenceon Software Engineering (ICSE) . ACM, 303‚Äì314.
[31]Florian Tram√®r, Alexey Kurakin, Nicolas Papernot, Ian Goodfellow, Dan Boneh,
andPatrickMcDaniel.2018. Ensembleadversarialtraining:Attacksanddefenses.
InInternationalConferenceon Learning Representations (ICLR) .
[32]Website. 2019. American Fuzzy Lop (AFL). http://lcamtuf.coredump.cx/afl
Accessed: 2019-04-08.
[33]Website.2019. Cifar-10. https://github.com/BIGBALLON/cifar-10-cnn. Accessed:
2019-03-10.
[34]Website. 2019. Cifar-10. https://github.com/yh1008/deepLearning. Accessed:
2019-03-10.
[35]Website.2019. Cifar-10. https://github.com/abars/YoloKerasFaceDetection. Ac-
cessed: 2019-03-10.
[36]Website.2019. Fashion-MNIST. https://github.com/umbertogriffo/Fashion-mnist-
cnn-keras. Accessed: 2019-03-10.
[37]Website. 2019. Fashion-MNIST. https://github.com/markjay4k/Fashion-MNIST-
with-Keras. Accessed: 2019-03-10.
[38]Website. 2019. GTSRB. https://github.com/chsasank/Traffic-Sign-Classification.
keras. Accessed: 2018-10-30.
[39]Website. 2019. GTSRB. https://github.com/xitizzz/Traffic-Sign-Recognition-
using-Deep-Neural-Network. Accessed: 2018-10-30.
[40]QiXinandStevenPReiss.2017. Identifyingtest-suite-overfittedpatchesthrough
test case generation. In Proceedings of the 26th ACM SIGSOFT International Sym-
posium on Software Testing and Analysis (ISSTA). ACM, 226‚Äì236.
[41]Yingfei Xiong, Xinyuan Liu, Muhan Zeng, Lu Zhang, and Gang Huang. 2018.
Identifying patch correctness in test-based program repair. In Proceedings of the
40thInternationalConferenceon Software Engineering (ICSE) . ACM, 789‚Äì799.
[42]Fanny Yang, Zuowen Wang, and Christina Heinze-Deml. 2019. Invariance-
inducing regularization using worst-case transformations suffices to boost accu-
racyandspatialrobustness.In AdvancesinNeuralInformationProcessingSystems
(NIPS). 14757‚Äì14768.
[43]ZhongxingYu,MatiasMartinez,BenjaminDanglot,ThomasDurieux,andMartin
Monperrus.2018. Alleviatingpatchoverfittingwithautomatictestgeneration:
a study of feasibility and effectiveness for the Nopol repair system. Empirical
Software Engineering (2018),1‚Äì35.
[44]Sergey Zagoruyko and Nikos Komodakis. 2016. Wide Residual Networks. In
BritishMachineVisionConference(BMVC) .
[45]Valentina Zantedeschi, Maria-Irina Nicolae, and Ambrish Rawat. 2017. Efficient
defenses against adversarial attacks. In Proceedings of the 10th ACM Workshop on
Artificial Intelligence and Security. ACM, 39‚Äì49.
[46]Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz. 2017.
mixup:Beyondempiricalriskminimization.In InternationalConferenceonLearn-
ingRepresentations(ICLR) .
[47]Mengshi Zhang, Yuqun Zhang, Lingming Zhang, Cong Liu, and Sarfraz Khur-
shid. 2018. DeepRoad: GAN-based metamorphic testing and input validation
frameworkforautonomousdrivingsystems.In Proceedingsofthe33rdACM/IEEE
InternationalConferenceon Automated Software Engineering (ASE) . 132‚Äì142.
[48]WenyiZhao,RamaChellappa,PJonathonPhillips,andAzrielRosenfeld.2003.
Facerecognition:Aliteraturesurvey. ACMcomputingsurveys(CSUR) 35,4(2003),
399‚Äì458.
