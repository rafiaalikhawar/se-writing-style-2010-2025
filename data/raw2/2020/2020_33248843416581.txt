Automating Just-In-Time Comment Updating
Zhongxin Liu‚àó‚Ä†
Zhejiang University
China
liu_zx@zju.edu.cnXin Xia‚Ä°
Monash University
Australia
xin.xia@monash.edu
Meng Yan
Chongqing University
China
mengy@cqu.edu.cnShanping Li
Zhejiang University
China
shan@zju.edu.cn
ABSTRACT
Code comments are valuable for program comprehension and soft-
waremaintenance, andalsorequiremaintenance withcodeevolu-
tion. However, when changing code, developers sometimes neglect
updatingtherelatedcomments,bringingininconsistentorobsolete
comments(aka.,badcomments).Suchcommentsaredetrimental
since theymay misleaddevelopers andlead tofuture bugs.There-
fore, it is necessary to fix and avoid bad comments. In this work,
wearguethatbadcommentscanbereducedandevenavoidedby
automaticallyperformingcommentupdateswithcodechanges.We
refer to this task as ‚ÄúJust-In-Time (JIT) Comment Updating‚Äù and
proposeanapproachnamed CUP(CommentUPdater)toautomate
this task. CUP can be used to assist developers in updating com-mentsduringcodechangesandcanconsequentlyhelpavoidthe
introduction of bad comments. Specifically, CUP leverages a novel
neural sequence-to-sequencemodel tolearn comment updatepat-
ternsfromextantcode-commentco-changesandcanautomatically
generate a new comment based on its corresponding old comment
and code change. Several customized enhancements, such as a spe-
cial tokenizer and a novel co-attention mechanism, are introduced
in CUP by us to handle the characteristics of this task. We builda dataset with over 108K comment-code co-change samples and
evaluate CUP on it. The evaluation results show that CUP outper-
forms an information-retrieval-based and a rule-based baselines
bysubstantialmargins,andcanreducedevelopers‚Äôeditsrequired
for JIT comment updating. In addition, the comments generatedby our approach are identical to those updated by developers in
1612(16.7%)testsamples,7timesmorethanthebest-performing
baseline.
‚àóAlso with Ningbo Research Institute.
‚Ä†Also with PengCheng Laboratory.
‚Ä°Corresponding author.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ASE ‚Äô20, September 21‚Äì25, 2020, Virtual Event, Australia
¬© 2020 Association for Computing Machinery.
ACM ISBN 978-1-4503-6768-4/20/09...$15.00
https://doi.org/10.1145/3324884.3416581CCS CONCEPTS
‚Ä¢Softwareanditsengineering ‚ÜíSoftwaremaintenancetools ;
Maintaining software ; Software evolution.
KEYWORDS
Comment updating, Code-comment co-evolution, Seq2seq model
ACM Reference Format:
Zhongxin Liu, Xin Xia, Meng Yan, and Shanping Li. 2020. Automating Just-
In-Time Comment Updating. In 35th IEEE/ACM International Conference on
AutomatedSoftwareEngineering(ASE‚Äô20),September21‚Äì25,2020,Virtual
Event, Australia. ACM, New York, NY, USA, 13 pages. https://doi.org/10.
1145/3324884.3416581
1 INTRODUCTION
Code comments are a vital source of software documentation. De-
velopersrecordvariousinformation,suchastheintention,imple-
mentationandusageofacodesegment,coderelations,andcode
evolutions [ 34,36,42] in comments, which makes code comments
valuableforunderstandingsourcecodeandfacilitatingthecommu-
nicationbetweendevelopers[ 53,55].Apriorstudyhasshownthat,
besidessourcecode,commentsareconsideredasthemostessential
softwareartifactsforprogramcomprehensionandmaintenance[ 7].
Despite the value of comments, developers may forget or ig-
noretheupdatesofcommentswhenchangingsourcecode[ 43,50],
whichmaybringininconsistentorobsoletecomments(aka.,bad
comments)[ 43,44,50].Table1presentsabadcommentexamplein
ApacheKafka[ 1].ThemethodinTable1registersthemetricsofthe
producer,consumer,andadminclients,whileonlytheconsumer
clientsarementionedinitsassociatedcomment.Hence,thecom-
mentisaninconsistentcomment.Beforebeingfixedbydevelopers,
this comment had existed for over eight months. During this time,
it may mislead developers, waste their time to double-check the
implementation,complicatecodereviews,andresultintheintro-
duction of bugs [ 16,35,43,44,46]. Therefore, bad comments have
negativeeffectstotherobustnessofasystemandmayincreasethe
cost of its development and maintenance. It is necessary to fix bad
comments in time or avoid introducing them.
Tofigureouthowandwhenbadcommentsareintroduced,we
furthercheckedthechangehistoryofthemethodinTable1.We
found that at the beginning, only the consumer clients‚Äô metrics
were registered in this method, but two following code changes
addedtheproducerandadminclients‚Äômetrics,respectively,without
5852020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE)
Table 1: A bad comment example
public Map<MetricName, ? extends Metric> metrics() {
...
for(finalStreamThread thread : threads) {
result.putAll(thread .producerMetrics());
result.putAll(thread .consumerMetrics());
result.putAll(thread.adminClientMetrics());
}
...}
MethodComment : Get read-only handle on global metrics registry, in-
cludingstreamsclient‚Äôsownmetricsplusitsembeddedconsumerclients‚Äô
metrics.
Updated Comment : Get read-only handle on global metrics registry,
including streams client‚Äôs own metrics plus its embedded producer, con-
sumerand admin clients‚Äô metrics.
updatingthecomment.Thisfindinginspiresusthatifcomments
can be automatically updated with each code change, it is possible
to reduce and even avoid the introduction of bad comments.
In this work, we refer to the task that performs comment up-
dateswithcodechangesas"Just-In-Time(JIT)CommentUpdating"
and propose a novel approach named CUP(CommentUPdater)
to automate this task. Intuitively, this task can be automated us-
ingmanuallyderivedpatternsandrules. However, comments are
free-form texts written in natural languages and are far less formal
than source code. Thus, it is challenging and time-consuming to
manually summarize and adaptively apply comment update pat-terns. CUP tackles this task in another way. It leverages a novel
neural sequence-to-sequence (seq2seq) model to learn the patterns
ofcommentupdatesoccurringwithcodechangesandautomaticallygeneratenewcommentsbasedonthecorrespondingoldcommentsandcodechanges.CUPcanbeusedtoassistdevelopersinupdating
comments during code changes, and can consequently help reduce
and avoid the introduction of bad comments.
Neural seq2seq models have been shown to be effective for
many software engineering (SE) tasks [ 14,28,48]. However, the
seq2seqmodelsusedinothertaskscannotbedirectlyadoptedto
JIT comment updating due to two main characteristics of this task:
First,weneedtopreservetheformatofcommentswhiledealing
with out-of-vocabulary (OOV) words. OOV words are pervasive
insoftwareartifactsandneedtobecarefullyhandledinmanySE
tasks [14,28,48]. Furthermore, because the goal of this task is to
update comments instead of generate them from scratch, it is also
necessary to keep the format of old and new comments consistent.
Second, this task takes both code changes and old comments as
input.Oldcommentsserveasthebasisofupdatesandcodechanges
can provide important guidance and clues. Thus, this task requires
neuralseq2seqmodelstolearntherepresentationsofcodechanges
and old comments simultaneously and capture their relationships
effectively.
To cope with the first characteristic, we propose a simple but
effective way to tokenize code and comments, which can not only
reduceOOVwordsbutalsokeeptheformatinformationofcom-
ments. The copy mechanism [ 38] is also adopted to copy OOV
words and format information from the input during generation.
Forthesecondcharacteristic,ourseq2seqmodelfirstleveragestwodistinctencoderstoencodecodechangesandoldcomments,respec-
tively. Then, to better capture relationships between code changes
and comments, we build a unified vocabulary for both code and
commenttokens,adoptapre-trainedfastTextmodeltoobtainword
embeddings, and integrate a novel co-attention mechanism to our
seq2seqmodel.Theunifiedvocabularyensuresthesametokensap-
pearing in code and comments have identical representations. The
fastTextembeddingsprovideaccuratesyntacticandsemanticinfor-
mation of each token. The co-attention mechanism can effectively
link and fuse information in code changes and comments.
Toevaluateourapproach,weextractcodechangesfrom1,496
popular engineered Java projects hosted on GitHub, carefully con-
structing a dataset with 108K code-comment co-change samples.
An information-retrieval-based (IR-based) method, a rule-based
methodandaspecialmethodwhichdirectlyoutputsoldcomments
are used as baselines. We evaluate CUP and the baselines on our
dataset interms of Accuracy, Recall@5and two metrics proposed
by us named Average Edit Distance (AED) and Relative Edit Dis-tance (RED). The evaluation results show that CUP outperforms
all baselines in terms of all metrics. Specifically, CUP can replicate
commentupdatesperformedbydevelopersin1612(16.7%)cases,
whichare7timesmorethanthebest-performingbaseline.Itisalso
theonlyapproachwithREDlessthan1,whichindicatesthatitcan
reduce developers‚Äô efforts in JIT comment updating.
In summary, the contributions of this paper include:
(1)We propose a novel approach, namely CUP, to automate
JIT comment updating. CUP is based on a neural seq2seq
modelandintroducesseveralcustomizedimprovementsto
effectively handle the characteristics of this task.
(2)Webuildadatasetwithover108Kcode-commentco-changesamplesforJITcommentupdating.Tothebestofourknowl-
edge, it is the first large dataset for this task.
(3)We extensively evaluate CUP on the dataset using four met-
rics. CUP is shown to outperform three baselines and can
reduce developers‚Äô efforts in updating comments.
(4)Weopensourceourreplicationpackage[ 4,5],includingthe
dataset, the source code of CUP, our trained model and test
results, for follow-up works.
The remainder of this paper is organized as follows: Section 2
describestheJITcommentupdatingtaskandtheusagescenarios
of our approach. We elaborate on our approach in Section 3 and
illustrate how we build our dataset in Section 4. Section 5 presents
theproceduresandresultsofourevaluation.InSection6,wediscuss
the situations where our approach may fail, a quality assurancemethod for our approach, the performance of our approach in
termsBLEU-4andMETEORandthethreatstovalidity.Afterabrief
review of related work in Section 7, we conclude this paper and
point out future work in Section 8.
2 PROBLEM AND USAGE SCENARIO
In this section, we formalize the JIT comment updating task and
describe the usage scenarios of our approach.
2.1 Problem Formulation
This work targets at automating JIT comment updating, i.e., au-
tomaticallyupdatingcommentswithcodechanges.Thistaskcan
586
	














	 







Figure 1: The overall framework of our approach.
beformalizedasfollows:giventhepre-andpost-changeversions
of a code snippet t,t/primeand the pre- and post-change versions of
its associated comment x,y(x/nequaly), find a function fso that
f(t,t/prime,x)=y. Hereon, we refer to t,t/prime,xandyasold code,new
code,oldcomment,and newcomment,respectively.Wetacklethis
task by devising and training a neural seq2seq model to approxi-
matef.Inaddition,sincethegoalistoupdatecommentsinstead
of generate them from scratch, keeping the format of old and new
comments consistent is regarded as an essential requirement.
2.2 Usage Scenario
Our approach, namely CUP, takes a code change and its associated
oldcommentasinput,aimingtogeneratethecorrespondingnew
comment. Its usage scenarios are as follows:
Firstofall,CUPcanbeusedtoassistdevelopersinperforming
JITcommentupdating.Whendevelopersmakeacodechange,CUP
can automatically provide update suggestions for the associated
comments.IfthecommentsgeneratedbyCUParecorrect,develop-
ers can quickly perform comment updates through one click. Even
ifCUP‚Äôssuggestionsareonlypartiallycorrect,theycanalsoreduce
developers‚Äôeditsrequiredtoupdatecomments.Therefore,CUPcanhelpimprovedevelopers‚ÄôproductivitywithrespecttoJITcomment
updating and avoid the introduction of bad comments.
CUPisalsoabletofixexistingbadcommentswiththehelpof
bad comment detection tools. For example, developers can first
leverage the tool proposed byLiu et al. [ 26] to identify comments
requiringupdatesineachhistoricalcodechange.Then,CUPcanbe
usedtoautomaticallyupdatethedetectedbadcommentsinstead
of manually check and modify them.
3 APPROACH
The overall framework of our approach is illustrated in Figure 1. It
consists of three phases, i.e., data flattening, model training, and
comment updating. Specifically, we first flatten the code -comment
co-changesamplesextractedfromsourcecoderepositoriesasse-
quences.Then,ourneuralseq2seqmodelistrainedusingtheflat-
tened data. Finally, given a code change and its associated old
comment,thetrainedmodelcanautomaticallygenerateanewcom-
ment to replace the old one. In this section, we elaborate on the
data flattening phase and our neural seq2seq model.
3.1 Data Flattening
In this phase, we convert code changes and comments into se-
quencessothattheycanbeprocessedbyourneuralseq2seqmodel.ti
t/prime
i
aim
m
equalFiles
Files
equal‚àÖ
Info
insert.
.
equalremove
remove
equalAll
‚àÖ
delete(
(
equalfiles
id
replace)
)
equalmFilesInfo.remove(id);mFiles.removeAll(files);
an edit
Figure 2: Converting a code change to an edit sequence.
3.1.1 Tokenization. Forcomments,wefirsttokenizethembyspaces
and punctuation marks. Spaces are removed while punctuation
marks are reserved. Then, compound words, which refer to thetokens constructed by concatenating multiple vocabulary wordsaccording to camel or snake conventions, are split into multiple
tokenstoreduceOOVwords.Afterthat,iftwoadjacenttokensarenot split by space, we insert a special token ‚Äú<con>‚Äù between them
to mark they are concatenated.
Asfor code changes,eachofthemiscomposedofanold code
snippetandanewcodesnippet.Thetwosnippetsarefirsttokenized
using a lexer. Inner comments and white spaces are removed. Each
identifieristokenizedbasedoncamelcasingandsnakecasing,and
‚Äú<con>‚Äù is also inserted to join the subtokens. String literals are
tokenized like comments.
The key issue in software artifact tokenization is how to deal
with compound words. In the literature, the common ways in-
clude: not changing compound words [ 28], splitting them [ 14] and
adding a special symbol ‚Äú</t>‚Äù at the end of each token beforesplitting [
19] (e.g., ‚ÄúinputBuffer‚Äù ‚Üí‚ÄúinputBuffer</t>‚Äù ‚Üí‚Äúinput
Buffer</t>‚Äù). However, the first way cannot reduce OOV words.
Thesecondwaymayloseformatinformation,i.e.,atokensequence
mayfailtoberecoveredtoitsoriginalsentence.Thethirdwaycan-
not handle the situation wherea subtoken of a compound word is
generatedasanindependenttoken.Forexample,‚Äúinput‚Äùcannotbegeneratedasanindependentwordifitiscopiedfrom‚ÄúinputBuffer‚Äù,
since it does not end with ‚Äú</t>‚Äù. Compared to these methods, our
tokenizercanberegardedas‚Äúasking‚Äùtheneuralmodeltoalsolearn
format information by inserting ‚Äú<con>‚Äù to mark concatenation.
Simpleisit,itcaneffectivelykeepcommentformatconsistent.Also,topreserveformatinformation,wedonotlowercasetokensinboth
code and comments.
3.1.2 Code Change Representation. After tokenization, each code
changeisconvertedtotwotokensequences.Wecansimplyusetwoencoders to encode them, which however, makes it hard to capture
fine-grained modifications between them. To better represent each
codechange,wefirstalignitstwotokensequencesusingadifftoolandthenconstructaneditsequencebasedonthealignment,similar
to [54],as itsrepresentation,as shownin Figure2. Each element
in an edit sequence is a triple < ti,t/prime
i,ai> and is named as an edit.
tiis a token in the old code and t/prime
iis a token in the new code. ai
istheeditactionthatconverts titot/prime
i,whichcanbe insert,delete,
equalorreplace.If aiisinsert(delete),ti(t/prime
i)willbetheemptytoken
‚àÖ. Such edit sequences can not only preserve the information of
the old code and the new code, but also highlight the fine-grained
changes between them.
587LSTM
et/prime
1et1 ea1
t1t/prime
1a1h/prime1
LSTM
et/prime
2et2 ea2
t2t/prime
2a2h/prime2
LSTM
et/prime
3et3 ea3
t3t/prime
3a3h/prime3
LSTM
ex1
x1h1
LSTM
ex2
x2h2
LSTM
ex3
x3h3Co-AttentionLSTM
h1g1LSTM
h2g2LSTM
h3g3LSTM LSTM LSTM
h/prime1 g/prime
1 h/prime2 g/prime
2 h/prime3 g/prime
3Code Change Attention
u/prime1 u/prime2 u/prime3Comment Attention
u1 u2 u3
Contextual
Embed Layer
Embedding
LayerCo-Attention
LayerModeling
LayerLSTM
eÀÜy1
<s>LSTM
eÀÜy2
ÀÜy2LSTM
eÀÜy3
ÀÜy3¬∑¬∑¬∑u/prime3
u3Dense + Softmax
s1 s2 s3y1 y2Weighted Sum
Pvocab
3y3
c/prime3
c3Pcode
3 Pcmt
3
Code Change Encoder Comment Encoder Decoder
Figure 3: The architecture of our neural seq2seq model.
3.2 Overview of Our Neural Seq2Seq Model
Thearchitectureofourneuralseq2seqmodelispresentedinFig-
ure3.Ourmodeltakesasinputaneditsequence E=[<t1,t/prime
1,a1>,
¬∑¬∑¬∑,<|tn,t/primen,an>]and an old comment x=[x1,¬∑¬∑¬∑ ,x|x|], aiming
to generate the new comment y=[y1,¬∑¬∑¬∑ ,y|y|].nis the length of
theeditsequence.Indetail,itleveragestwodistinctencoders,i.e.,
CodeChangeEncoderandCommentEncoder,toencodetheedit
sequenceandtheoldcomment,respectively,andgeneratesthenew
commentthroughanLSTM(longshort-termmemory)[ 13]decoder.
An encoder-side co-attention mechanism is leveraged to learn the
relationships between the code change and the old comment. Two
pointer generators [ 38] are used in the decoder to enable copy-
ing tokens from both the new code and the old comment during
generation.
3.3 Encoders
The two encoders, i.e., Code Change Encoder and Comment En-
coder, are nearly the same in structure. Each encoder is composed
of four ordered layers: an embedding layer, a contextual embed
layer, a co-attention layer, and a modeling layer.
3.3.1 The Embedding Layer. This layer is responsible for mapping
thethreekindsoftokens,i.e.,codetokens,commenttokens,and
editactions,intoembeddings.Thereareonlyfoureditactions,so
werandomlyinitializeanembeddingmatrixforthemandupdateit
during training. For code and comment tokens, we first build a uni-
fied vocabulary from all training codeand comment tokens. Then
weuseapre-trainedfastTextmodel[ 11]toobtainthewordembed-
ding of each token. Instead of two distinct vocabularies for code
andcomments,wepreferaunifiedonebecauseitensuresthesame
tokensincodeandcommentshavethesameembeddings,which
can ease the capture of references between code and comments.
Pre-trained word embeddings are used for providing accurate syn-
tactic and semantic information. In addition, we choose fastText
instead of other pre-trained models because the word embeddings
learnedby fastTextcontain subtokeninformation andit caneffec-
tively map OOV words and subtokens into embeddings, which are
very suitable for this task.3.3.2 The Contextual Embed Layer. For each encoder, we place
a distinct Bi-LSTM (Bidirectional LSTM) on the top of the em-bedding layer to model the temporal interactions between edits
(comment tokens) and represent each edit (comment token) as a
contextualvector.ForCodeChangeEncoder,thethreeembeddings,
i.e.,eti,et/prime
i,eai, of each edit Eiare first concatenated horizontally,
and then input to the Bi-LSTM, as follows:
h/prime
i=Bi-LSTM( h/prime
i‚àí1,h/prime
i+1,[eti;et/prime
i;eai])
whereh/prime
iis the contextual vector of this edit. Comment Encoder
computes thecontextual vector hiof eachcomment token xiin a
similarwaywith xi‚Äôsembedding exiasinput.Forconvenience,the
contextual vectors of the old comment and the code change can be
stacked as matrices H‚ààR2d√ó|x|andH/prime‚ààR2d√ón, respectively.
3.3.3 The Co-Attention Layer. So far, the code change and the
oldcommentarerepresentedindependently.However,tocapture
relationshipsbetweenthem,itisnecessarytolinkandfusetheir
information.Thislayerisusedtoaddressthisneedandisshared
bythetwoencoders.Ittakesasinputthecontextualvectors,i.e., H
andH/prime, and outputs a comment-aware (edit-aware) feature vector
foreachedit(commenttoken)alongwiththeoriginalcontextual
vector of this edit (comment token) to the consequent layer.
Indetail,eachfeaturevectorisindeedacontextvectorcomputed
by the dot-production attention mechanism [ 29]. Formally, the
feature vector –¥iof the comment token xiis calculated by:
–¥i=H/primeŒ≤i (1)
Œ≤i=softmax(H/prime/latticetopWŒ≤hi) (2)
Œ≤iis the attention weights of xion all edits and measures how
important each edit is with respect to xi.WŒ≤‚ààR2d√ó2dis the
trainable parameters. The feature vector –¥/prime
iof the edit Eiis com-
putedinnearlythesamewayexceptthattheattentionsarederived
oppositely, i.e., from edits to comment tokens, as follows:
–¥/prime
i=HŒ≤/prime
i
Œ≤/prime
i=softmax(H/latticetopW/latticetop
Œ≤h/prime
i)
588Wecanseethat –¥isignifiesandcapturestheinformationrelated
to comment token xifrom the whole code change. Meanwhile, –¥/prime
i
highlights and keeps the information related to edit Eifrom the
wholeoldcomment.Thesefeaturevectorsprovideafoundationfor
capturing relationships between code and comments.
3.3.4 The Modeling Layer. This layer produces the final represen-
tation of each edit (comment token) based on its contextual vector
and comment-aware (edit-aware) feature vector. The two encoders
use two distinct Bi-LSTMs to learn such representations. In detail,
given a comment token xi, its final representation uiis calculated
as follows:
ui=Bi-LSTM(u i‚àí1 ,ui+1 ,[–¥i;hi])
The final representation u/prime
iof an edit Eiis calculated similarly:
u/prime
i=Bi-LSTM(u/prime
i‚àí1,u/prime
i+1,[–¥/prime
i;h/prime
i])
ui(u/prime
i) is expected to contain the contextual information of xi(Ei)
with respect to both the code change and the old comment. For
convenience,werefertothestackedmatricesofall uiandallu/prime
ias
U‚ààR2d√ó|x|andU/prime‚ààR2d√ón, respectively.
3.4 Decoder
WeuseanLSTM-baseddecodertogeneratenewcomments.Bi -LSTM
isnotsuitableforthedecoder,sinceanewcommentisgenerated
tokenbytoken.Thedecodertakesasinput UandU/primeobtainedfrom
the two encoders and produces the new comment by sequentially
generating its tokens.
Weconcatenatethelasthiddenstatesofthetwomodelinglayers
as the initial state s0of the decoder‚Äôs LSTM. The right side of
Figure 3 illustrates how a comment token is generated. In detail,
at decoding step j, the input ÀÜyjis first mapped into an embedding
eÀÜyjusing Comment Encoder‚Äôs embedding layer. ÀÜyjis the previous
reference token when training or the previous generated token
whentesting.Then,thedecodercomputesthehiddenstate sjbased
oneÀÜyj, the previous hidden state sj‚àí1and the previous output
vectoroj‚àí1(computed by Equation 3), as follows:
sj=LSTM(sj‚àí1 ,[eÀÜyj;oj‚àí1])
The decoder also adopts the dot-production attention mecha-
nism, which derives a context vector at each time step as the repre-
sentationoftheencoder‚Äôsinput.Therearetwodistinctencoders,
sothedecodercomputestwocontextvectors,i.e., cjfromtheold
comment and c/prime
jfrom the code change, following Equation 1 and 2.
Then,cj,c/prime
jandsjareconcatenatedtocalculateanoutputvector
oj‚ààRland a vocabulary distribution Pvocab
j:
oj=tanh(V[cj;c/prime
j;sj]) (3)
Pvocab
j=softmax(V/primeoj)
V‚ààR(4d+l)√ólandV/prime‚ààRv√ólare learnable parameters and vis
the size of the unified vocabulary. Pvocab
jcan be directly used to
generatethetargettoken.Forexample,wecanchoosethetoken
with the highest probability as the output of time step j.
However, the decoder cannot generate OOV words if it only
chooses tokens from the vocabulary. We observed that an OOV
word in a new comment usually can be found in its corresponding
oldcommentand/ornewcode.Therefore,wealsoadoptthepointergenerator[ 38]toalleviatetheOOVproblemfollowingLiuetal.[ 28].
Specifically,twopointergeneratorsareleveragedtocopytokens
from the old comment and the new code, respectively:
Pcmt
j(yj)=/summationdisplay.1
k:xk=yjŒ±jk
Pcode
j(yj)=/summationdisplay.1
k:t/prime
k=yjŒ±/prime
jk
Pcmt
j(yj)andPcode
j(yj)are the probabilities of copying yjfrom the
old comment and the new code. Œ±jkandŒ±/prime
jkare the attention
weightsof xkandEkwithrespecttotimestep j,andarecalculated
with the context vectors cjandc/prime
j
Atlast,theconditionalprobabilityofproducing yjattimestep j
is computed as:
p(yj|y<j,x,E)=Œ≥jPvocab
j(yj)+
(1‚àíŒ≥j)(Œ∏jPcmt
j(yj)+(1‚àíŒ∏j)Pcode
j(yj))(4)
Œ≥jandŒ∏jmeasure the probabilities of generating yjby selecting
from the vocabulary and copying from the old comment, respec-
tively. Each of them is modelled by a single-layer feed-forward
neural network jointly trained with the decoder.
4 DATA PREPARATION
Inthiswork,webuildourdatasetfromJavaprograms.However,
ourapproachislanguage-agnosticandwebelieveitcanbeeasily
adapted for other languages. We concentrate on co-changes be-tween methods and their header comments (method comments),
becauseJavamethodscanbepreciselyassociatedwiththeircom-
ments, while it is non-trivial to accurately link comments and codeofothergranularity,e.g.,astatement.Inaddition,forcomments,our
approachcapturesupdatepatternsatsentencelevel,i.e.,updates
onecommentsentenceatatime.Thisisbecause1)it isrelatively
easy to recognize patterns at a small but coherent granularity [ 54]
and 2) a method comment with multiple sentences can also beupdated iteratively. For convenience, in this section we use com-
menttorefertoacommentsentenceand docforawholemethod
comment.
Thissectiondescribeshowweextractmethod-docco-changein-
stances,i.e.,<oldcode, newcode, olddoc,newdoc>,fromcoderepos-
itories, how we convert qualified instances into method-comment
co-change samples, i.e., <old code, new code, old comment, new com-
ment>, and how we build our dataset.
4.1 Data Collection
Wenetal.[ 50]collectedalistof1,500JavarepositoriesfromGitHub
for studying code-comment inconsistencies. All the repositories
were selected based on a rigorous procedure, have no less than 500
commits,andweremanuallyverifiedbyWenetal.tobepopular
engineeredprojects.Wereusedthislisttocollectdata.Indetail,wefirstclonedthe1,500repositoriesfromGitHub.However,wefound
two repositories, i.e., pig4cloud/pig andwyouflf/xUtils, had been
removedfromGitHubandtwootherrepositories,i.e., liferay/liferay-
portalandJetBrains/MPS,weretoolargetobeclonedinreasonable
time. Therefore,1,496 repositories were successfullycloned.Then,
589weconstructedmethod-docco-changeinstancesbyextractingmod-
ified methods and their corresponding docs from each non-merge
commit of every repository. Methods and docs were associated
usingJavaParser[ 2].Weobtained1,063Kmethod-docco-change
instances after filtering out the instances with unchanged docs.
4.2 Modified Method Extraction
Itisnon-trivialtoextractmodifiedmethodsfromacommit,since
developers may change method signatures. To do this, we first
leveragedGumTree[ 8]tocalculatemethodmappingsbetweentwo
revisions.Then,basedonsuchmappings,wecomparedtheASTs
of each old method and its new version to identify and extract
modifiedmethods. Commentswere ignoredfor ASTcomparisons.
However,GumTreeisnotdesignedformatchingmethodsand
we found that for short methods and methods with similar bodies,
themethodmappingsextractedbyGumTreearenotalwaysaccu-
rate.Toalleviatethisproblem,wecustomizedGumTree‚Äôsmatching
algorithm to better extract method mappings. In detail, GumTree‚Äôs
matchingalgorithmtakestwotrees T1andT2asinputandcontains
two ordered phases: the top-down phase and the bottom-up phase.
Thetop-downphasematchesisomorphicsubtreesbetweenthetwo
trees and the bottom-up phase tries to find additional mappings in
abottom-upway.WecustomizedGumTreebyaddinganadditional
phase named method-matching phase betweenthe two phases.
Thismethod-matchingphaseisbasedonourobservationthat
ifmethod miinT1andmethod mjinT2havethesamesignature,
they usually should be matched. In addition, if mi‚Äôs signature is
differentfromthatof mjbuttheyhavethesamenameandnoother
methodsinboth T1andT2usethisname,itisverylikelythat mjis
modified from mi. Specifically, this phase first collects unmatched
MethodDeclaration nodesM1andM2fromT1andT2, respectively.
Then,foreachmethod miinM1,ifonlyonemethod mjinM2has
thesamesignatureasit, miandmjarematchedandremovedfrom
M1andM2. After checking method signatures and updating M1
andM2, this phase continues tomatch the remaining methods in
M1andM2with respect to method names in a similar way.
It took over 290 hours to extract modified methods from the
1,496 repositories using 40 cores of Intel Xeon 2.7GHz CPU.
4.3 Data Preprocessing
We preprocessed the 1,063K method-doc co-change instances as
follows:
4.3.1 FilterOutUnqualifiedInstances. Thisstepaimstoreduceun-
related information in docs and filter out unqualified instances. We
observed that if a doc is a line comment, it is usually a commented
annotationinsteadofamethoddescription.So,wefirstremovedthe
instanceswithlinecommentsasdocs.Adoccancontainafree-form
description section and a tag section. Compared to the description
section, the tag section is more formal and structured, and can
bewellhandledusingrule-basedmethods.Therefore,wefocusedonthedescriptionsectionanddeletedthetagsectionineachdoc.
Then,‚Äú@inheritDoc‚Äù,codesnippetsandhtmltagswereremoved
fromeachdoc.Thedocscontaining‚Äú(non-Javadoc)‚Äùornon-ascii
characterswerefilteredout.Inaddition,sinceourapproachfocuses
on comment updating, which requires the old and new comments
tobenon-emptyanddifferent,wefilteredouttheinstanceswithemptyor identicaldocs. Finally, theinstancescontaining abstract
methodswerealsodeletedtoreducemethodmismatching.After
this step, we obtained 242,649 qualified instances.
4.3.2 Construct Co-Change Samples. A doc may contain multiple
sentences. This step is responsible for further processing docs and
matching sentences between each old doc and its new doc. Before
sentencematching,wefirstreplacedemails,urls,references(e.g.,
‚Äú#123‚Äù) and versions (e.g., ‚Äú1.2.3‚Äù) in docs with ‚ÄúEMAIL‚Äù, ‚ÄúURL‚Äù,
‚ÄúREF‚Äù and ‚ÄúVERSION‚Äù, respectively, to reduce noise. Next, we split
each doc into sentences using NLTK [ 3], removed the sentences
with only punctuation marks and tokenized the remaining sen-
tences using the tokenizer described in Section 3.1.1. Then, given a
pairofdocs,wecalculatedtheword-levelLevenshteindistance[ 24],
which is the minimum word edits (insertions, deletions and sub-
stitutions)requiredtochangeasentenceintotheother,betweeneach old sentence and each new sentence and constructed a dis-
tancematrix.Basedonthismatrix,theoldandnewsentencesare
matchedinabest-fitway.Afterthat,wefilteredoutthematched
pairs of which the two sentences are identical if ignoring punctua-
tion.Ifthedistanceofapairislargerthantheoldsentence‚Äôslength
and 5, this pair should be regarded as a rewrite instead of an up-
date. Hence we also filtered out such pairs. Finally, each remaining
matched pair was used to construct a method-comment co-change
sample,i.e.,<oldcode, newcode, oldcomment, newcomment >.We
canseethatonemethod-docco-changeinstancecanbesplitinto
multiple method-comment co-change samples, which share thecode change but have their own sentence pairs. As a result, we
constructed172,745method-commentco-changesamples,which
belong to 147,844 method-doc co-change instances.
4.3.3 SetMaxLengthandMaxDistance. Duetothelimitedmem-
oryofGPUandtoreducethetrainingtime,wesetthemaxlengthsofcodeeditsequences,oldcomments,andnewcommentstobe500,50,and50basedonthecorresponding90thquantilesofourdataset.Inaddition,acommentchangeisverylikelytobearewriteinsteadofanupdateiftheabsoluteorrelativeeditdistancebetweentheold,
and new comments is large. The relative edit distance is defined
astheabsolutedistancedividedbytheoldcomment‚Äôslength.We
find that the absolute and relative edit distances of 80% samplesare no more than 12 and 0.67, respectively. To reduce comment-
rewrite samples, we filtered out the samples of which the absolute
or relative distances is larger than 12 or 0.67. At last, we obtained
108,695 method-comment co-change samples, which come from
98,553 method-doc co-change instances.
4.4 Data Splitting
The 108,695 samples are extracted from 48,007 commits. A com-
mit may contain duplicate samples since developers may perform
systematic or recurring code changes in one commit [ 20,33]. So,
beforesplittingthedata,wededuplicatedsampleswithineachcom-
mit to reduce bias, which resulted in the deletion of 2,981 samples.
Foreachproject,wesorteditscommitsintheascendingorderof
commitcreationtime,putthefirst80%commitsintothetraining
set, shuffled the remaining 20% commits and evenly split them into
the validation and test set. In this way, we ensure all comment
updatesin thetrainingset occurredbeforethose inthevalidation
590and test sets. We also noticed that git operations like ‚Äúcherry -pick‚Äù,
‚Äúrebase‚Äùand‚Äúsquash‚Äùcanintroduceduplicatesamplesamongdiffer-
ent commits. Therefore, after splitting, duplicate samples between
thetest(validation)andtrainingsetswerealsofilteredoutbyus.As
aresult,ourfinaltraining,validationandtestsetsconsistof85,657,
9,475, 9,673 method-comment co-change samples, respectively.
5 EVALUATION
Inthissection,wefirstpresentthebaselinesandtheevaluationmet-rics. Then,we describe ourexperiment settings, research questions
(RQs), and the corresponding experimental results.
5.1 Baselines
ToevaluatetheperformanceofCUP,weusethreebaselinesbelong-
ing to different types: Origin, FracoUpdater and NNUpdater.
5.1.1 Origin. Origin is a special baseline which directly outputs
theoldcommentsasresults.BycomparingCUPwithOrigin,we
canknowwhetherthecommentsgeneratedbyCUParecloserto
the new comments than the old comments.
5.1.2 FracoUpdater. Fraco [37] is a tool proposed by Ratol and
Robillard to detect fragile comments with respect to rename refac-
toringsandisshowntoperformbetterthanEclipse‚Äôsrefactoring
tool.AlthoughthepaperproposingFracodoesnotclaimthatFracocanupdatefragilecommentswithrenamerefactorings,wefindtheimplementationofFracoprovidesaquick-fixfeaturetofixdetected
fragile comments. When developers conduct a rename refactoring,
Fraco will be triggered to identify the references between com-
ment phrases and the renamed identifier. The quick-fix feature can
thenautomaticallyreplacefragilecommentphraseswiththenew
identifiernamebasedonheuristicrules.Wemanuallyextractthe
detectionalgorithmandthequick-fixfeaturefromFraco‚Äôssource
codeandwrapthemasanofflinecommentupdatingtoolnamed
FracoUpdater by us. Given a code change and a corresponding old
comment, FracoUpdater first leverages RefactoringMiner [ 47]t o
detectrenamerefactoringsfromthecodechange.Then,foreach
detected rename refactoring, it uses Fraco‚Äôs detection algorithm to
identify fragile comment phrases in the old comment with respect
to this rename. Finally, Fraco‚Äôs quick-fix feature is applied to fix
detected fragile phrases. If there is no rename refactoring detected,
nofragilecommentphraseidentifiedornofixperformedbyFraco‚Äôs
quick-fix feature, FracoUpdater outputs the old comment as the
result. We use FracoUpdater as a rule-based baseline.
5.1.3 NNUpdater. NNUpdater,shortforNearest-Neighbor-based
commentUpdater,isanIR-basedbaselineproposedbyusforthis
task.LikeNNGen[ 27]forcommitmessagegeneration,thehypoth-
esis behind NNUpdater is that similar code changes may lead to
similaroreventhesamecommentchanges.Givenatestsample,i.e.,
a code change and its old comment, NNUpdater first finds its most
similartrainingsampleandthenreusesthenewcommentofthe
nearestneighborasoutput.Specifically,tomeasurethesimilarity
simchgbetween two code changes, NNUpdater converts each of
them to a unified difffile, represents difffiles as tf-idf vectors and
calculatesthecosinesimilaritybetweensuchvectors.Thesimilarity
simcmtbetween two old comments are also calculated in the sameway. The similarity simbetween two samples is then defined as:
sim=Œ±¬∑simchg+(1‚àíŒ±)¬∑simcom ,0‚â§Œ±‚â§1.
5.2 Evaluation Metrics
We use Accuracy, Recall@5 and two metrics proposed by us for
this task, namely Average Edit Distance (AED) and Relative Edit
Distance (RED), to evaluate CUP and the baselines.
AccuracyandRecall@5areusedtopresenttowhatextendan
approachcangenerate correctcomments.W eusecorrectcomments to
refertothegeneratedcommentswhichareidenticaltothereference
comments if we ignore the punctuation marks at the end of the
comments.Indetail,Accuracyisthepercentageofthetestsamples
wherecorrectcomments aregeneratedonthefirsttries.Recall@5
is similar to Accuracy, but allows the approach to try 5 times.
AED measures the average edits developers need to perform
toperfectlyupdatecommentsafterusingaJITcommentupdater.
RED is similar to AED, but measures the average of relative edit
distances. Formally, given a test set with Nsamples, an approach‚Äôs
AED and RED are:
AED=1
NN/summationdisplay.1
k=1edit_distance( ÀÜy(k),y(k))
RED=1
NN/summationdisplay.1
k=1edit_distance( ÀÜy(k),y(k))
edit_distance( x(k),y(k))
whereedit_distance istheword-levelLevenshteindistanceand ÀÜy(k)
refers to the comment generated for the kthsample. We can see
thatifanapproach‚ÄôsREDislessthan1,developerscanexpectto
spend less efforts in updating comment after using this approach.
5.3 Experiment Settings
Forourapproach,300-dimensionalwordembeddingsareusedfor
edit actions, code tokens and comment tokens. The fastText model
ispre-trainedonCommonCrawlandWikipedia[ 6],andthepre-
trainedwordembeddingsarefrozenduringtraining.Thehidden
states of the Bi-LSTMs and the LSTM in our model are 256 and
512 dimensions (i.e., d=256 and l=512), respectively. All the LSTMs
have only one layer. The unified vocabulary only keeps the tokens
appearing more than once, and its size turns out to be 44,578.
CodeChangeEncoder,CommentEncoder,andDecoderinour
model are jointly trained to minimize the cross entropy. During
training,weoptimizetheparametersofourmodelusingAdam[ 21]
with a batch size of 32. A dropout [ 41] rate of 0.2 is used for all
LSTM layers and the dense layer before computing Pvocab
j. The
model is validated every 500 batches on the validation set usingperplexity (the smaller the better) with a batch size of 32. We set
the learningrate of Adam to0.001 and clip thegradients norm by
5. The learning rate is decayed by a factor of 0.5 if the validation
perplexity does not decrease for 5 validations and we call this as a
trial. We stop training after 5 trials. The model with best (smallest)
validation perplexity is used for evaluation. When testing, beam
search of width 5 is used to generate comments.
For NNUpdater, we tune its Œ±on the validation set through grid
searchwith0.1asthestepsizeandsurprisinglyfindthat Œ±=0,i.e.,
onlyusingcodechangesimilarity,canachievethebestAccuracy.
So, we set the Œ±in NNUpdater to 0.
591Table 2: Comparisons of our approach with each baseline
Approach Accuracy Recall@5 AED RED
Origin 0.0% (0) / 3.74 1.000
FracoUpdater 2.0% (196) / 3.76 1.022
NNUpdater 1.3% (125) 1.4% 15.25 7.068
CUP 16.7%(1612) 26.1% 3.54 0.958
*Thenumbersinbracketsarethenumbersofgenerated correctcom-
ments.
5.4 RQ1: The Effectiveness of Our Approach
To investigate the effectiveness of our approach, i.e., CUP, we eval-
uateitandthebaselinesonourdatasetintermsofAccuracy,Re-
call@5, AED, and RED. The evaluation results are shown in table 2.
Origin and FracoUpdater only generate one candidate for each
sample, so their Recall@5 is marked as ‚Äú/‚Äù. We can see that CUP
outperformsallthebaselinesintermsofallevaluationmetrics.It
can correctly update comments in 1672 (16.7%) cases on the first
tries, over 7 times more than the best-performing baseline, and can
generate correct comments for 26.1% of the test samples within 5
attempts.
LargeimprovementsareachievedbyCUPoverNNUpdaterin
terms ofall metrics. Whencompared to Originand FracoUpdater,
CUP performs much better on Accuracy and Recall@5, and also
outperformsthemintermsofAEDandREDbysubstantialmargins.
We also conduct Wilcoxon signed-rank tests [ 51] at the confidence
levelof95%.Thep-valuesofCUPcomparedwiththethreebaselinesintermsofAccuracy,Recall@5,AEDandREDarealllessthan0.001,
which meansthe improvements achievedby CUP arestatistically
significant. These results indicate CUP can update comments more
effectivelyandaccuratelythanthethreebaselines.Inaddition,CUP
istheonlyapproachofwhichtheAEDislessthanOrigin‚ÄôsAED
andtheREDislessthan1.ThishighlightsthatCUPcanreducethe
edits developers need to perform for JIT comment updating.
TofurtherfigureoutthereasonsofCUP‚Äôsbetterperformance,
wemanuallyinspectthetestresults.Basedonourinspection,we
find that compared to NNUpdater and FracoUpdater, CUP has two
major advantages:
First,CUPcanlearnandapplydiversecommentupdatepatterns
automatically,whileNNUpdaterandFracoUpdaterarelimitedto
specifictypesofcommentupdates.Specifically,NNUpdaterrelies
on repeating new comments between test and training samplesto generate correct comments. It may work well on some specific
cases, but lacks the generalization ability. FracoUpdater is basedon manually summarized rules. It can obtain accurate results on
identifier-renaming-relatedcommentupdates,butcannothandle
other types of updates, e.g., updates related to type change. Incontrast, CUP leverages a probabilistic model to learn commonpatterns of JIT comment updates from extant code-comment co-
changes. The patterns learned by CUP are more diverse than those
of NNUpdater and FracoUpdater, and can cover more samples. For
example,Table3presentsatestsample.Inthissample,thedeveloper
used a wildcard, i.e., ‚Äú*_compiler_t‚Äù, in the old comment to refer to
theannotationandthemethodname.Whentheannotationandthe
method name are changed, the wildcard should also be modifiedTable 3: Test sample 1
Code Change:
- @NativeType("shaderc_spvc_compiler_t")
- public static long sh aderc_spvc_compiler_initialize(){
- long __functionA ddress = Functions.
compiler_initialize;
+ @NativeType("shaderc_spvc_context_t")+ public static long shaderc_spvc_context_create() {+ long __functionAddres s = Functions.context_create;
return invokeP(__functionAddress);
}
Old Comment : Any function operating on a {@code *_compiler_t} must
offer the basic thread-safety guarantee.
NewComment :Anyfunctionoperatingona{@code *_context_t}must
offer the basic thread-safety guarantee.
NNUpdater: Operation fails.
FracoUpdater :Anyfunctionoperatingona{@code *_compiler_t}must
offer the basic thread-safety guarantee.
CUP-co-attn : Any function operating on a {@code *_compiler_create}
must offer the basic thread-safety guarantee.
CUP-uni-vocab :Anyfunctionoperatingona{@code *_compiler_t}must
offer the basic thread-safety guarantee.
CUP-fastText : Any function operating on a {@code *_context_context_t}
must offer the basic thread-safety guarantee.
CUP: Any function operating on a {@code *_context_t} must offer the
basic thread-safety guarantee.
accordingly. It is non-trivial to design and implement rules for this
kindofcases.BothNNUpdaterandFracoUpdaterfailtoperform
the correct update, while CUP succeeds.
Second, CUP can update semantic references between code and
comments. NNUpdater does not take code-comment relationships
intoconsideration.FracoUpdaterisabletodetectsomesemantic
matching betweenrenamed identifiersand commentphrases, but
itsquick-fixrulescannotcorrectlyupdatesuchmatching.Different
from them, CUP explicitly adopts some components, such as the
co-attention mechanism and the unified vocabulary, to enable our
seq2seqmodeltoeffectivelycapturetherelationshipsbetweencode
andcomments.Basedonourmanualinspection,CUPcanupdate
not only lexical but also semantic references between code and
comments with code changes. Table 4 presents an example. We
can see that the developer fixed the ‚ÄúcreateSessionFolder‚Äù as ‚Äútrue‚Äù,hence the corresponding description in the old comment should beremoved.NNUpdaterandFracoUpdaterfailtohandlethiscase,but
CUP accurately identifies such description and removes it when
generating the new comment.
In summary, CUP significantly outperforms the three base-
lines.TheREDofCUPindicatesthatCUPcanhelpdevelopers
reduce their efforts in JIT comment updating.
5.5 RQ2: The Effects of Main Components
Thekeyofthistaskistoeffectivelycapturetherelationshipsand
references between code and comments. To meet this need, we
592Table 4: Test sample 2
Code Change:
- private String getSessionFileName(String
sessionIdentifier, boolean createSessionFolder)
+ private String getSessionFileName(String
sessionIdentifier)
{
- File sessionFolder = folders.get(sessionIdentifier,
createSessionFolder);
+ File sessionFolder = folders.get(sessionIdentifier,
true);
return new File(sessionFolder, "data").
getAbsolutePath();
}
OldComment :Ifthesessionfolder(folderthatcontainsthefile)doesnot
existand createSessionFolder is true, the folder will be created.
New Comment : If the session folder (folder that contains the file) does
not exist, the folder will be created.
NNUpdater: Marker => Point
FracoUpdater :Ifthesessionfolder(folderthatcontainsthefile)doesnot
existand createSessionFolder is true, the folder will be created.
CUP-co-attn : If the session folder does not exist and createSessionFolder
is true, the folder will be created.
CUP-uni-vocab :Ifthesessionfolder(folderthatcontainsthefile)does
not exist and createSessionFolder is true, the folder will be created.
CUP-fastText : If the session folder (folder that contains the file) does not
existand createSessionFolder, the folder will be created.
CUP: If the session folder (folder that contains the file) does not exist, the
folder will be created.
adopt a co-attention mechanism, build a unified vocabulary, and
use the word embeddings pre-trained by fastText for better repre-
senting, linking and fusing the information in code changes and
comments. In this research question, we compare CUP with itsthree variants: 1)
CUP-co-attn , which removes the co-attention
layer from CUP, 2) CUP-uni-vocab , which uses two distinct vo-
cabularies, instead of a unified vocabulary, for code and comment
tokens,respectively,and3) CUP-fastText ,whichdoesnotusethe
embeddings pre-trained by fastText. Such comparisons can help
usunderstandtheimpacts ofthethreecomponentstoCUP‚Äôsper-
formance. There are some other improvements adopted by CUP,
suchasthespecialtokenizerforpreservingcommentformatand
thecopymechanism.Wedonotinvestigatetheireffectsbecausesome ofthem are believedby usto be indispensable for thistask
andtheeffectivenessofothershasbeeninvestigatedbyprevious
related works.
The results of our comparisons are presented in Table 5. We can
seethatCUPperformsbetterthanthethreevariantsintermsofall
metrics.ForAccuracy,theimprovementsachievedbyCUPrange
from1.3%to3.8%,andCUPcangenerateatleast118more correct
comments than the variants. Wilcoxon signed-rank tests [ 51]a r e
also used to check the significance of the performance improve-ments. All the p-values are less than 0.01, which means CUP sig-nificantly outperforms the three variants. These results indicatethattheco-attentionmechanism,theunifiedvocabularyandthe
fastText embeddings are useful and effective for this task.Table 5: Comparisons of our approach with three variants
Approach Accuracy Recall@5 AED RED
CUP-co-attn 12.9% (1250) 23.6% 3.72 1.046
CUP-uni-vocab 15.4% (1494) 25.3% 3.59 0.989
CUP-fastText 13.6% (1320) 23.5% 3.73 1.057
CUP 16.7%(1612) 26.1% 3.54 0.958
Tobetterunderstandtheseperformancedifferences,wemanu-
ally inspect the test results of the three variants. We find that CUP
will capture more incorrect code-comment references without the
co-attention mechanism, and it may not know how to update com-
mentsormayperforminaccurateupdatesontherightreferences
if the unified vocabulary and the fastText embeddings are replaced.
Asanexample,forsample1inTable3,CUP-co-attnbuildsanin-
correctreference between‚Äút‚Äù and‚Äúcreate‚Äù, CUP-uni-vocabcannot
predict the proper update and regards modifying nothing as the
best solution, and CUP-fastText successfully captures the reference
between‚Äúcompiler‚Äùand‚Äúcontext‚Äùbutinaccuratelygeneratestwo
consecutive‚Äúcontext‚Äùtoupdate‚Äúcompiler‚Äù.Inthesamplepresented
inTable4,CUP-co-attnpredicts thatthecode element‚ÄúcreateSes-
sionFolder‚Äù is related to the comment phrase ‚Äú(folder that contains
thefile)‚Äù,andincorrectlyremovessuchphrase.CUP-uni-vocabcan-
not handle this case and chooses to update nothing. CUP-fastText
onlycapturespartofthereferenceandmakesaninaccurateupdate
by only deleting ‚Äú is true‚Äù. These results demonstrate the three
componentsallplayanimportantroleincapturingandupdating
code-comment references.
In summary, the co-attention mechanism, the unified vo-
cabulary, and the fastText embeddings adopted by CUP are
helpful for capturing and updating code-comment references
and can boost the effectiveness of CUP.
6 DISCUSSION
In this section, we discuss the situations where CUP may fail, a
quality assurance method which can improve CUP‚Äôs practicability,
theperformanceofCUPintermsofBLEU-4andMETEOR,andthe
threats to the validity of this work.
6.1 Where Does Our Approach Fail
Wecarefullyinspectanumberofrandomlyselectedsampleswhere
CUP fails to generate correct comments and summarize several
badsituationsofCUPfromthem.Acommonbadsituationisthat
developers only optimize their language expression and the old
andnewcommentsareofthesamemeaning.Suchoptimizations
can be lexical, e.g., fixing a typo, capitalizing the first word and
pluralizingaverb,orsemantic,i.e.,usingabetterwaytoexpress
the samemeaning, or both.If the patternof an expressionupdate
is rare in the dataset, CUP may not be able to capture and apply it
without any clue.
In the second situation, the code changes and old comments do
notprovideenoughinformationforCUPtoinferthecorrespond-
ing comment updates. For example, in a test sample, the developer
593Table6:TheperformanceofourapproachwiththeQAfilter
Approach Accuracy Recall@5 AED RED
CUP 16.7% (1612) 26.1% 3.54 0.958
CUP+QA 31.8% (1612) 38.3% 2.98 0.920
addedthephrase‚Äú(chunked)‚Äùinthenewcomment.However,‚Äúchun-
ked‚Äùdoesnotappearinthecodechangeorthe oldcomment,and
cannot be derived from any code element. Therefore, CUP is not
able to perform the update.
Another situation is that the code changes and/or comment up-
datesaretoocomplicatedforCUPtoperfectlyhandle.Forexample,
the developer may modify several similar code elements in a code
change and update their semantic references in the comment si-
multaneously. CUP may correctly update some of the comment
phrasesbutnotalwaysall.Wethinktherearetwomainreasonspre-
venting CUP from perfectly handling complicated code-comment
co-changes. First, CUP does not leverage program analysis tools
likeRefactoringMinertoexplicitlyextractinformationfromcode
changes. Although CUP can handle many situations without such
tools,it mayget confusedand failto focuson theimportantparts
when a code change contains many modifications unrelated to the
comment update. Second, for each sample, CUP only scans the old
comment and generates the new comment once. Therefore, it may
be challenging for CUP to correct many comment phrases simulta-
neously. It would be interesting to address these limitations, but it
is beyond the scope of this work.
In addition, it is worth mentioning that some samples may fit
multiple situations instead of only one. For example, developersmayupdatemultiplecode-commentreferencesandoptimizethe
language expression in one comment change.
6.2 Quality Assurance for Our Approach
Fromourmanualinspection,wealsofindthatforthesampleswhere
CUP is not capable of performing perfect JIT comment updates,
CUPmaychooseto modifynothinganddirectlygeneratetheold
comments.Basedonthisfinding,weproposeaqualityassurance
filter(QAfilter)toimprovethepracticabilityofCUP.Specifically,foreachsample,theQAfiltersimplycomparesthecommentgenerated
byCUPwiththeoldcomment.Iftheyareidentical,theQAfilter
marks this sample as imperfect (i.e., cannot be perfectly handled
by CUP) and removes it.
After using this QA filter, we re-evaluate CUP on our dataset.
Table6presentstheevaluationresults.WecanseethattheQAfilter
improvesCUPintermsofallmetrics.Indetail,itnearlydoublesthe
Accuracy as the consequence of filtering out 4602 out of 9673 test
samples.TheAEDandREDalsodecreasebysubstantialmargins.
These results indicate that the QA filter can make our approach
moreusefulandaccurateinpracticeandcanimprovedevelopers‚Äô
confidence on our approach.
6.3 Other Evaluation Metrics
Prior studies often use BLEU-4 and METEOR, which are flexible
inwordorder,toevaluatecommentgenerationmethods.Wealso
compare the performance of CUP and the baselines on our datasetTable 7: The BLEU-4 and METEOR scores of our approach
and the baselines
Approach #Update BLEU-4 METEOR
Origin 0/9673 70.2 50.2
FracoUpdater 631/9673 70.5 50.3
NNUpdater 9142/9673 14.3 17.7
CUP 5071/9673 72.0 51.2
*#Update referstothenumberofthetestsampleswhere
the generated comments are different from the old com-
ments.
intermsofBLEU-4andMETEOR.Theevaluationresultsareshown
in Table 7, where BLEU-4 and METEOR scores are presented aspercentage values between 0 and 100. We can see that CUP canobtain better BLEU-4 and METEOR scores than the three base-lines. Since BLEU-4 and METEOR are calculated at corpus level,
statistical significance is tested using paired bootstrap resampling
following[ 22]with1000resamples.Allthep-valuesarelessthan
0.001, which indicates that our approach significantly outperforms
the three baselines in terms of the two metrics.
Indetail,CUPimprovesNNUpdaterbylargemargins.Origincan
achieve high BLEU-4 and METEOR scores since it directly outputs
theoldcomments,whicharenaturallysimilartothecorrespond-
ing new comments updated by developers. The performance of
FracoUpdaterisclosetothatofOrigin,becauseinmost(9042out
of9673)cases,FracoUpdaterdoesnotperformanyupdateanddi-
rectly outputs the old comments too. In contrast, CUP performs
updates on 5071 (52.4%) samples and significantly outperforms Ori-
gin and FracoUpdater in terms of BLEU-4 and METEOR. These
results further confirm the better performance of CUP.
6.4 Threats to Validity
One threat to the validity of this work is that our dataset is built
onlyfromJavaprojectsandonlycontainstheupdatesofmethod
comments, which may not be representative of all programminglanguages and comment types. However, Java is one of the most
popular programming languages. Method comments are an im-
portanttypeofcommentsandareoftenreferredtobydevelopers
forprogram comprehension.Besides, ourproposedmodel isinde-
pendent of programming languages and comment types. It can be
appliedtoprojectsofotherlanguagesandbetrainedtogenerate
other types of comments.
Anotherthreatisrelatedtothemethodmappingswebuildfrom
commits.Beforeextractingmodifiedmethodsfromacommit,we
use GumTree to match the methods in two revisions. However,some method mappings identified by GumTree are suboptimal.
We mitigate this threat by 1) adding a new phase in GumTree to
improve its accuracyin method matching, 2) filteringthe samples
with abstract methods, which are often mismatched. In addition,we manually checked 200 samples in our test set and only found
one suboptimal method mapping. Therefore, we believe the threat
is limited.
5947 RELATED WORK
This section discusses related work concerningcode-comment co-
evolution, comment generation, inconsistent comment detection.
7.1 Code-Comment Co-Evolution
Priorworkshaveinvestigatedtheco-evolutionbetweensourcecode
andcodecommentsfromdifferentperspectives[ 9,10,16,18,25,50].
Forexample,Fluriet al.[ 9,10]studiedhowsource code andcom-
ments co-evolved and found that 90% of the comment changestriggeredbycodechangesweredoneinthesamerevisionasthe
associatedcodechanges.TheyalsohighlightedthatAPIcomments
areoftenadaptedretroactively.Inaddition,Ibrahimetal.[ 16]in-
vestigated the relationship between comment update practice and
softwarebugsinthreeopen-sourcesystemsandfoundabnormal
comment update behavior is a good indicator for predicting fu-
ture bugs. Linares-Vasquez et al. [ 25] studied how developers doc-
umented database usages in method comments and pointed out
that the comments of database-related methods are less frequently
updated than source code. Recently, Wen et al. [ 50] conducted a
large-scale empirical study, which analyzed the chances that dif-
ferentcodechangetypestriggercommentupdatesanddefineda
taxonomyofthecode-commentinconsistenciesfixedbydevelopers.
Different from these studies, our work aims to automatically
updatecommentswithcodechanges.Theempiricalfindingspre-
sentedbypreviousstudiesmotivateourworkandshedlightinto
the JIT comment updating task.
7.2 Comment Generation
Automatic comment generation techniques may also help develop-
ersupdatecommentsbydirectlygeneratingnewcommentsfrom
changedmethods.Manypreviousworksproposedtogeneratecodecommentsusingrule-basedandIR-basedmethods[
12,31,32,40,52].
For example, Sridhara et al. [ 40] proposed an approach to generate
comments for Java methods using summary information in source
codeandmanuallydefinedtemplates.Togenerateacommentfor
a code snippet, ColCom [52] first finds similar code snippets from
opensourceprojectsandthenreusesandtailorstheircommentsasoutput.Recently,moreandmoreresearchersleveragedprobabilistic
models to perform comment generation [ 14,15,17,23,49,57]. For
example, Iyer et al. [ 17] proposed a neural attention model named
CODE-NNtogeneratesummariesforC#andSQLsnippets.Deep-
Com,anapproachproposedbyHuetal.[ 14],usesastructure-based
traversal(SBT)methodtoflattenASTsandcombinessuchflattened
sequenceswithanencoder-decodermodeltogeneratecomments
for Java methods. In their follow-up work, Hu et al. [ 15] devised
Hybrid-DeepCom to enhance DeepCom by combining source code
and the SBT sequences together to generate comments. In a paral-
lelwork,LeClairetal.[ 23]proposedasimilarmodel,whichalso
represents code texts and the SBT sequences using two distinct
encoders, for comment generation.
Althoughourapproachcanberegardedasgeneratingcomments
through a seq2seq model, it focuses on updating pre-existing com-
ments instead of generating comments from scratch. Moreover,
when updating a comment, our approach considers both the old
commentandthecorrespondingcodechangeinsteadofonlythenewcode.Therefore,webelievetheJITcommentupdatingproblem
and the comment generation problem are different.
7.3 Inconsistent Comment Detection
Researchers have investigated the detection of inconsistent com-
ments.Mostpriorworksfocusedonthecommentsrelatedtospe-
cificcodepropertiesorofspecifictypes[ 39,43‚Äì46,56].Forexample,
Tanetal.[ 43‚Äì45]proposedaseriesofapproachestodetectcode-
commentinconsistenciesrelatedtospecificprogrammingconcepts,
such as lock mechanisms [ 43,44], function calls [ 43] and inter-
rupts [45]. Their approaches extract concept-related rules from
comments basedon NLPtechniques andcheck sourcecode againsttheextractedrulesusingstaticprogramanalysis.Sridharaetal.[
39]
proposed a technique to identify obsolete TODO comments based
on information retrieval, linguistics and semantics. Several studies
targetedatgeneralcommentsandtookcodechangesintoconsider-
ation [26,30,37]. For instance, Ratol and Robillard [ 37]p r o po s eda
rule-based approach named Fraco to detect fragile comments with
respect to identifier renaming. Liu et al. [ 26] leveraged machine
learning techniques and 64 manually-crafted features derived from
code,commentsandcode-commentrelationshipstocheckwhether
to update a comment when its associated code is changed.
All these techniques focus on detecting inconsistent or obso-
lete comments, while our approach targets at automatically up-
datingcommentswithcodechangestoavoidtheintroductionof
inconsistent and obsolete comments. We believe our approach is a
complement instead of a competitor to these techniques.
8 CONCLUSION AND FUTURE WORK
Thisworkaimstoreduceandavoidtheintroductionofbadcom-
mentsbyautomaticallyupdatingcommentswithcodechanges,i.e.,
automating Just-In-Time (JIT) comment updating. To tackle thistask, we propose an approach named
CUP(CommentUPdater),
whichleveragesanovelseq2seqmodeltolearncommonpatternsof
JITcommentupdatesfromextantcode-commentco-changesand
canautomaticallygeneratenewcommentsbasedonthecorrespond-
ing old commentsand code changes. Severalimprovements,such
asaspecialtokenizerandaco-attentionmechanism,areintroduced
inCUPtohandlethecharacteristicsofthistask.Comprehensive
experimentsonadatasetwithover108Kcode-commentco-change
samples show that CUP outperforms three baselines by significant
marginsandcanreducetheeditsthatdevelopersperformforJIT
comment updating.
In the future, we plan to investigate the effectiveness of CUP
incross-projectsettings.WealsoplantoadaptCUPtoothercode
granularity, such as statements, and other comment types, such as
inner comments of methods. In addition, it would be an interesting
futuredirectiontoproposemoreadvancedtechniquestoaddress
CUP‚Äôs limitations.
ACKNOWLEDGMENTS
ThisresearchwaspartiallysupportedbytheNationalKeyR&DPro-
gramofChina(No.2018YFB1003904),NSFCProgram(No.61972339),theAustralianResearchCouncil‚ÄôsDiscoveryEarlyCareerResearcher
Award(DECRA)(DE200100021),andAlibaba-ZhejiangUniversity
Joint Institute of Frontier Technologies.
595REFERENCES
[1]2020. A commit in Apache Kafka. https://github.com/apache/kafka/commit/
9dc76f8872b862ca008562cdcf8cf50524e2eaa3.
[2] 2020. JavaParser. https://javaparser.org/.
[3]2020. Natural language toolkit NLTK 3.5 documentation. http://www.nltk.org/.
[4] 2020. Our replication package. https://tinyurl.com/jitcomment.[5] 2020. Our source code on GitHub. https://github.com/tbabm/CUP.[6]
2020. Word vectors for 157 languages. https://fasttext.cc/docs/en/crawl-vectors.
html.
[7]Sergio Cozzetti B de Souza, Nicolas Anquetil, and K√°thia M de Oliveira. 2005.
A study of the documentation essential to software maintenance. In Proceed-
ings of the 23rd annual International Conference on Design of Communication:
Documenting & Designing for Pervasive Information. 68‚Äì75.
[8]Jean-R√©my Falleri, Flor√©al Morandat, Xavier Blanc, Matias Martinez, and Martin
Monperrus. 2014. Fine-grained and accurate source code differencing. In Pro-
ceedings of the 29thInternational Conference on AutomatedSoftware Engineering.
313‚Äì324.
[9]BeatFluri,MichaelWursch,andHaraldCGall.2007. DoCodeandComments
Co-Evolve? On the Relation between Source Code and Comment Changes. In
Proceedings of the 14th Working Conference on Reverse Engineering. 70‚Äì79.
[10]Beat Fluri, Michael W√ºrsch, Emanuel Giger, and Harald C Gall. 2009. Analyzing
theco-evolutionofcommentsandsourcecode. SoftwareQualityJournal 17,4
(2009), 367‚Äì394.
[11]Edouard Grave, Piotr Bojanowski, Prakhar Gupta, Armand Joulin, and Tomas
Mikolov.2018. LearningWordVectorsfor157Languages.In Proceedingsofthe
International Conference on Language Resources and Evaluation.
[12]SoniaHaiduc,JairoAponte,LauraMoreno,andAndrianMarcus.2010. Onthe
UseofAutomatedTextSummarizationTechniquesforSummarizingSourceCode.
InProceedings of the 17th Working Conference on Reverse Engineering. 35‚Äì44.
[13]SeppHochreiterandJ√ºrgenSchmidhuber.1997. Longshort-termmemory. Neural
Computation 9, 8 (1997), 1735‚Äì1780.
[14]XingHu,GeLi,XinXia,DavidLo,andZhiJin.2018. Deepcodecommentgenera-tion.InProceedingsofthe26thInternationalConferenceonProgramComprehension.
200‚Äì210.
[15]Xing Hu, Ge Li, Xin Xia, David Lo, and Zhi Jin. 2019. Deep code comment
generationwithhybridlexicalandsyntacticalinformation. EmpiricalSoftware
Engineering (2019), 1‚Äì39.
[16]Walid M Ibrahim, Nicolas Bettenburg, Bram Adams, and Ahmed E Hassan. 2012.
On the relationship between comment update practices and software bugs. Jour-
nal of Systems and Software 85, 10 (2012), 2293‚Äì2304.
[17]Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, and Luke Zettlemoyer. 2016.
Summarizingsourcecodeusinganeuralattentionmodel.In Proceedingsofthe
54th Annual Meeting of the Association for Computational Linguistics. 2073‚Äì2083.
[18]ZhenMing JiangandAhmedE Hassan.2006. Examiningthe evolutionofcode
commentsin PostgreSQL.In Proceedings oftheInternational Workshop onMining
Software Repositories. 179‚Äì180.
[19]Rafael-Michael Karampatsis, Hlib Babii, Romain Robbes, Charles Sutton, and
Andrea Janes. 2020. Big Code!= Big Vocabulary: Open-Vocabulary Models for
Source Code. CoRRabs/2003.07914 (2020). https://arxiv.org/abs/2003.07914
[20]Miryung Kim and David Notkin. 2009. Discovering and representing systematic
code changes. In Proceedings of the 31st International Conference on Software
Engineering. 309‚Äì319.
[21]DiederikPKingmaandJimmyBa.2015. Adam:AMethodforStochasticOpti-
mization. In Proceedings of the 3rd International Conference on Learning Represen-
tations.
[22]Philipp Koehn. 2004. Statistical significance tests for machine translation evalua-
tion. InProceedings of the Conference on Empirical Methods in Natural Language
Processing. 388‚Äì395.
[23]Alexander LeClair, Siyuan Jiang, and Collin McMillan. 2019. A neural model for
generatingnaturallanguagesummariesofprogramsubroutines.In Proceedings
of the 41st International Conference on Software Engineering. 795‚Äì806.
[24]Vladimir I Levenshtein. 1966. Binary codes capable of correcting deletions,
insertions, and reversals. In Soviet Physics Doklady, Vol. 10. 707‚Äì710.
[25]Mario Linares-V√°squez, Boyang Li, Christopher Vendome, and Denys Poshy-
vanyk.2015. Howdodevelopersdocumentdatabaseusagesinsourcecode?.In
Proceedings of the 30th International Conference on Automated Software Engineer-
ing. 36‚Äì41.
[26]ZhiyongLiu,HuanchaoChen,XiangpingChen,XiaonanLuo,andFanZhou.2018.
Automaticdetectionofoutdatedcommentsduringcodechanges.In Proceedingsof
the42ndAnnualComputerSoftwareandApplicationsConference,Vol.1.154‚Äì163.
[27]Zhongxin Liu, Xin Xia, Ahmed E Hassan, David Lo, Zhenchang Xing, and Xinyu
Wang.2018. Neural-machine-translation-basedcommitmessagegeneration:how
far are we?. In Proceedings of the 33rd International Conference on Automated
Software Engineering. 373‚Äì384.
[28]Zhongxin Liu, Xin Xia, Christoph Treude, David Lo, and Shanping Li. 2019.
Automatic Generation of Pull Request Descriptions. In Proceedings of the 34th
International Conference on Automated Software Engineering. 176‚Äì188.[29]Minh-Thang Luong, Hieu Pham, and Christopher D Manning. 2015. Effective
approaches to attention-based neural machine translation. In Proceedings of the
Conference on Empirical Methods in Natural Language Processing. 1412‚Äì1421.
[30]Haroon Malik, Istehad Chowdhury, Hsiao-Ming Tsou, Zhen Ming Jiang, and
AhmedEHassan.2008. Understandingtherationaleforupdatingafunction‚Äôs
comment. In Proceedings of the International Conference on Software Maintenance.
167‚Äì176.
[31]Laura Moreno, Jairo Aponte, Giriprasad Sridhara, Andrian Marcus, Lori Pollock,
andKVijay-Shanker.2013. Automaticgenerationofnaturallanguagesummaries
for java classes. In Proceedings of the 21st International Conference on Program
Comprehension. 23‚Äì32.
[32]Najam Nazar, Yan Hu, and He Jiang. 2016. Summarizing software artifacts:
A literature review. Journal of Computer Science and Technology 31, 5 (2016),
883‚Äì909.
[33]Tung Thanh Nguyen, Hoan Anh Nguyen, Nam H Pham, Jafar Al-Kofahi, and
Tien N Nguyen. 2010. Recurring bug fixes in object-oriented programs. In
Proceedings of the 32nd International Conference on Software Engineering. 315‚Äì
324.
[34]Yoann Padioleau, Lin Tan, and Yuanyuan Zhou. 2009. Listening to program-
mers Taxonomies and characteristics of comments in operating system code. In
Proceedingsofthe31stInternationalConferenceonSoftwareEngineering .331‚Äì341.
[35]DavidLorgeParnas.2011. Precisedocumentation:Thekeytobettersoftware. In
The Future of Software Engineering. Springer, 125‚Äì148.
[36]Luca Pascarella,Magiel Bruntink, and AlbertoBacchelli. 2019. Classifying code
commentsinJavasoftwaresystems. EmpiricalSoftwareEngineering (2019),1‚Äì39.
[37]InderjotKaurRatolandMartinPRobillard.2017. Detectingfragilecomments.InProceedingsofthe32ndIEEE/ACMInternationalConferenceonAutomatedSoftware
Engineering. 112‚Äì122.
[38]Abigail See, Peter J Liu, and Christopher D Manning. 2017. Get to the point:
Summarizationwithpointer-generatornetworks.In ProceedingsoftheAnnual
Meeting of the Association for Computational Linguistics. 1073‚Äì1083.
[39]GiriprasadSridhara.2016. Automaticallydetectingtheup-to-datestatusofToDo
comments in Java programs. In Proceedings of the 9th India Software Engineering
Conference. 16‚Äì25.
[40]Giriprasad Sridhara, Emily Hill, Divya Muppaneni, Lori Pollock, and K Vijay-
Shanker.2010. Towardsautomaticallygeneratingsummarycommentsforjava
methods.In ProceedingsoftheInternationalConferenceonAutomatedSoftware
Engineering. 43‚Äì52.
[41]Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan
Salakhutdinov.2014. Dropout:asimplewaytopreventneuralnetworksfrom
overfitting. The Journal of Machine Learning Research 15, 1, 1929‚Äì1958.
[42]DanielaSteidl,BenjaminHummel,andElmarJuergens.2013. Qualityanalysis
ofsourcecodecomments.In Proceedingsofthe21stInternationalConferenceon
Program Comprehension. 83‚Äì92.
[43]Lin Tan, Ding Yuan, Gopal Krishna, and Yuanyuan Zhou. 2007. /* iComment:
Bugs or bad comments?*. In Proceedings of the 21st ACM SIGOPS Symposium on
Operating Systems Principles. 145‚Äì158.
[44]Lin Tan, Ding Yuan, and Yuanyuan Zhou. 2007. Hotcomments: how to make
programcomments moreuseful?. In Proceedings ofthe 11thUSENIXWorkshopon
Hot Topics in Operating Systems. 1‚Äì6.
[45]Lin Tan, Yuanyuan Zhou, and Yoann Padioleau. 2011. aComment: mining anno-
tationsfromcommentsandcodetodetectinterruptrelatedconcurrencybugs.In
Proceedings of the 33rd International Conference on Software Engineering. 11‚Äì20.
[46]Shin Hwei Tan, Darko Marinov, Lin Tan, and Gary T Leavens. 2012. @ tCom-
ment: Testing Javadoc Comments to Detect Comment-Code Inconsistencies. In
Proceedingsofthe5thInternationalConferenceonSoftwareTesting,Verification
and Validation. 260‚Äì269.
[47]NikolaosTsantalis,MatinMansouri,LalehM.Eshkevari,DavoodMazinanian,
andDannyDig.2018. AccurateandEfficientRefactoringDetectioninCommit
History.In Proceedingsofthe40thInternationalConferenceonSoftwareEngineering.
483‚Äì494.
[48]Michele Tufano, Jevgenija Pantiuchina, Cody Watson, Gabriele Bavota, andDenys Poshyvanyk. 2019. On learning meaningful code changes via neural
machinetranslation.In Proceedingsofthe41stInternationalConferenceonSoftware
Engineering. 25‚Äì36.
[49]Yao Wan, Zhou Zhao, Min Yang, Guandong Xu, Haochao Ying, Jian Wu, andPhilip S Yu. 2018. Improving automatic source code summarization via deepreinforcement learning. In Proceedings of the 33rd International Conference on
Automated Software Engineering. 397‚Äì407.
[50]FengcaiWen,CsabaNagy,GabrieleBavota,andMicheleLanza.2019. Alarge-scale empirical study on code-comment inconsistencies. In Proceedings of the
27th International Conference on Program Comprehension. 53‚Äì64.
[51]FrankWilcoxon.1992. Individualcomparisonsbyrankingmethods. In Break-
throughs in Statistics. Springer, 196‚Äì202.
[52]Edmund Wong, Taiyue Liu, and Lin Tan. 2015. Clocom: Mining existing source
code for automatic comment generation. In Proceedings of the 22nd International
Conference on Software Analysis, Evolution, and Reengineering. 380‚Äì389.
[53]Scott N Woodfield, Hubert E Dunsmore, and Vincent Yun Shen. 1981. The effect
of modularization and commentson program comprehension. In Proceedings of
596the 5th International Conference on Software Engineering. 215‚Äì223.
[54]PengchengYin,GrahamNeubig,MiltiadisAllamanis,MarcBrockschmidt,and
AlexanderLGaunt.2018. Learningtorepresentedits.In Proceedingsofthe7th
International Conference on Learning Representations.
[55]Annie TT Ying, James L Wright, and Steven Abrams. 2005. Source code that
talks: an exploration of Eclipse task comments and their implication to repos-itory mining. In Proceedings of the International Workshop on Mining Software
Repositories. 1‚Äì5.[56]YuZhou,RuihangGu,TaolueChen,ZhiqiuHuang,SebastianoPanichella,and
HaraldGall.2017. AnalyzingAPIsdocumentationandcodetodetectdirective
defects.In Proceedingsofthe39thInternationalConferenceonSoftwareEngineering.
27‚Äì37.
[57]YuZhou,XinYan,WenhuaYang,TaolueChen,andZhiqiuHuang.2019. Aug-
menting Java method comments generation with context informationbased onneural networks. Journal of Systems and Software 156 (2019), 328‚Äì340.
597