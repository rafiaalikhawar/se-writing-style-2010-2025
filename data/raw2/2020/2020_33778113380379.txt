Dissector: Input Validation for Deep Learning Applications by
Crossing-layer Dissection
Huiyan Wang
cocowhy1013@gmail.com
State Key Lab for Novel Software
Technology, Nanjing University
Nanjing, China
Department of Computer Science and
Technology, Nanjing University
Nanjing, ChinaJingwei Xu∗
jingweix@nju.edu.cn
State Key Lab for Novel Software
Technology, Nanjing University
Nanjing, China
Department of Computer Science and
Technology, Nanjing University
Nanjing, ChinaChang Xu∗
changxu@nju.edu.cn
State Key Lab for Novel Software
Technology, Nanjing University
Nanjing, China
Department of Computer Science and
Technology, Nanjing University
Nanjing, China
Xiaoxing Ma
xxm@nju.edu.cn
State Key Lab for Novel Software
Technology, Nanjing University
Nanjing, China
Department of Computer Science and
Technology, Nanjing University
Nanjing, ChinaJian Lu
lj@nju.edu.cn
State Key Lab for Novel Software
Technology, Nanjing University
Nanjing, China
Department of Computer Science and
Technology, Nanjing University
Nanjing, China
ABSTRACT
Deeplearning(DL)applicationsarebecomingincreasinglypopular.
Their reliabilities largely depend on the performance of DL models
integrated in these applications as a central classifying module.
Traditional techniques need to retrain the models or rebuild and
redeploytheapplicationsforcopingwithunexpectedconditions
beyond the models’ handling capabilities. In this paper, we take
afaulttoleranceapproach,Dissector,todistinguishingthosein-
puts that represent unexpected conditions (beyond-inputs) from
normalinputsthatarestillwithinthemodels’handlingcapabilities
(within-inputs), thus keeping the applications still function with
expected reliabilities. The key insight of Dissector is that a DL
model should interpret a within-input with increasing confidence,
while a beyond-input would probably cause confused guesses in
the prediction process. Dissector works in an application-specific
way, adaptive to DL models used in applications, and extremely
efficiently,scalabletolarge-sizedatasetsfromcomplexscenarios.
The experimental evaluation shows that Dissector outperformed
state-of-the-arttechniquesintheeffectiveness(AUC:avg.0.8935
and up to 0.9894) and efficiency (runtime overhead: only 3.3–5.8
milliseconds).Besides,italsoexhibitedencouragingusefulnessin
∗Correspondingauthors.
Permission tomakedigitalorhardcopiesofallorpartofthisworkforpersonal or
classroom useisgrantedwithoutfeeprovided thatcopiesarenotmadeordistributed
forprofitorcommercialadvantageand thatcopiesbearthisnoticeand thefullcitation
onthefirstpage.Copyrightsfor componentsof thisworkownedby othersthanACM 
mustbehonored. Abstracting withcreditispermitted. Tocopyotherwise, orrepublish,
topostonserversortoredistribute tolists,r equires priorspecificpermissionand/ora
fee.Requestpermissions frompermissions@acm.org.
ICSE’20,May23–29,2020,Seoul,3FQVCMJDPG,orea
©2020Association forComputing Machinery.
ACMISBN978-1-4503-7121-6/20/05. ..$15.00
https://doi.org/10.1145/3377811.3380379defensingagainstadversarialinputs(AUC:avg.0.9983)andimprov-
ingaDLmodel’sactualaccuracyinuse(upto16%forCIFAR-100
and20%for ImageNet).
KEYWORDS
deep learning, fault tolerance, input validation
ACM Reference Format:
Huiyan Wang, Jingwei Xu, Chang Xu, Xiaoxing Ma, and Jian Lu. 2020.
Dissector:InputValidationforDeepLearningApplicationsbyCrossing-
layerDissection.In 42ndInternationalConferenceonSoftwareEngineering
(ICSE’20),May23–29,2020,Seoul,Korea. ACM,NewYork,NY,USA,12pages.
https://doi.org/10.1145/3377811.3380379
1 INTRODUCTION
Deep learning (DL) is assisting applications in a growing way [ 2,5,
16,22,52,61,63]. In such applications, DL models are typically in-
stantiatedfromtrainingscenarios,andlaterparticipateindecision-
making as a central classifier for new scenarios. This practice sim-
plifiesthesoftwaredesigninspecifyinghowsoftwareshouldbe-
have for complex scenarios. With this benefit, DL applications are
increasingly emerging for complex scenarios that are otherwise
challengingfortraditionalprograms,e.g.,imageclassification[ 5],
object identification [22], and self-driving [2, 57, 66].
However,duetothedifferencebetweennewscenariosandtrain-
ing scenarios, as well as the evolution [ 7] of, and noises in, new
scenarios,evenasuccessfulDLapplicationcanstillencounterin-
putsthatarebeyonditsDLmodel’shandlingcapability.Thenthe
consequencesareunexpectedpredictionsinthedecision-making
andabnormalbehaviors from the application.
One could consider replacing the concerned DL model with a
newone(e.g.,withdifferentgeneralizability)[ 12,53],orupgrading
the model by retraining it with more data from new scenarios
(e.g.,criticaldata[ 56],corner-casedata[ 11,47,57],orless-biased
*&&&"$.OE*OUFSOBUJPOBM$POGFSFODFPO4PGUXBSF&OHJOFFSJOH	*$4&
ICSE’20,May23–29,2020,Seoul, Korea Huiyan Wang, Jingwei Xu, Chang Xu, Xiaoxing Ma, and Jian Lu
data [37]). Although helpful, the replacing or retraining practice is
non-trivial, and especially not preferred after the DL application’s
deployment(e.g.,self-drivingalreadyputintouse).Furthermore,
theapplicationcouldbedisrupted fromitsnormalexecution,and
itself mayneed rebuilding and redeployment, not to mention that
such issues keep arising in future (e.g., new weather conditions,
obstacles,or environments encountered on highways).
Inthispaper,weconsidera faulttolerance approach.Afterappli-
cationdeployment,wemaketheapplicationrecognizetheinputs
that are beyond its DL model’s handling capability and prevent
themfromimpactingitsdecision-making(e.g.,isolatedorreferring
to manual driving), since the predictions for these inputs are unex-
pected and probably misleading or wrong. Then the application is
still functionalto other inputs and behaves as originally expected,
withouttheneedformodelretrainingorapplicationredeployment.
Thisapproachcanalsobeflexibleforcopingwithcomplexscenarios
thatcan hardly be fully anticipated in advance [2, 16].
Ourapproachrelatestoinputvalidation[ 58,66]ordataclean-
ing[4,19–21]efforts,butweargueforaddressingtheproblemfrom
an application’s perspective rather than focusing on the inputs
themselves only. First, comparing the inputs to original training
datamaynotbefeasible,eitherbecauseoftheunavailabilityordue
to the overwhelming runtime overhead [ 6,18,66]. Second, even
if one could do so, different DL models can be instantiated fromthe same training data by different DL algorithms with different
parameters,andthusthesamevalidationorcleaningtechniquecanhardlymakefilteredinputssuitthevaryinghandlingcapabilitiesofdifferent DL models. Therefore, our approach has to be application-
specific, aware of its target DL model (model-aware), as well as
beingefficient, incurring only marginal overhead at runtime.
Besides,ourapproachhastoaddressakeyproblem,i.e., telling
whentheinputstoanapplicationarebeyonditsDLmodel’shan-
dlingcapability.Thisischallengingbecausethereisnooracledefin-ingpreciselytheboundaryofaDLmodel’shandlingcapability,and
even the specific DL algorithm used for instantiating this model
does not help much on this (its scope of generalization never ex-
plicitly specified). Regarding this, we make two observations. First,
whentheinputsarebeyondaDLmodel’shandlingcapability,their
predictionscaneasilybemisleadingorwrong,leadingtoalower
accuracy. Second, such misleading or wrong predictions do not
come with no clue; instead, they can be perceived during the DL
model’s prediction process.
Basedontheaboveanalyses,weinthispaperproposeanovel
technique,Dissector,tomonitoraDLapplication’sinputsandiso-
late those possibly beyond its DL model’s handling capability from
impactingtheapplication’sdecision-making.First,thistechnique
is model-aware, monitoringwhether a DL model interprets anin-
putwithincreasingconfidenceinitspredictiontowardsthefinal
result by collecting its uniqueness evidence. If yes, Dissector con-
siderssuchinputs withinthemodel’shandlingcapability(named
within-inputs ), or otherwise, beyondthat (named beyond-inputs ).
In practice, adversarial inputs that are dedicatedly generated forattacking DL models are one example of beyond-inputs; besides,
natural inputs collected by a physical camera (e.g., a photo image)
canalsobebeyondorwithinaccordingtoitstargetDLmodel’shan-dling capability. Second, this technique is also lightweight, without
anyheavydatacomparisonoranalysisoperation.ThisenablesittoInput layer Hidden layers Output layer

	

Probability
vector
O


Input
Figure 1: DL model architecture
validateinputsefficientlyatruntime,capableforcomplexscenarios
with large-scaledata.
We experimentally evaluated Dissector and compared it to
state-of-the-arttechniques(mMutant[ 58]andMahalanobis[ 28])in
distinguishingbeyond-inputsfromwithin-inputs.Theexperiments
reported promising results for Dissector (AUC: 0.8223–0.9894),
whileexisting techniqueswereless effective(AUC:0.6827–0.9770
and 0.6692–0.8334, respectively). What is worth mentioning is that
Dissector applied successfully to large datasets like ImageNet,
while existing techniques incurred crashing cases due to large-
memory issues. Besides, Dissector was extremely efficient at run-
time(3.3–5.8millisecondspersample),about45xand763xspeedup
versus existing techniques, respectively. Finally, Dissector also
exhibitednicehelpindefensingagainstadversarialinputs(AUC:
0.9962–0.9998) and improving a DL model’s actual accuracy in use
(e.g., by 19% for CIFAR-100 and 20% for ImageNet).
We summarize our contributions in this paper below:
•Proposedalightweighttechniqueforautomatedvalidation
of inputs to DL applications (as classifiers).
•Evaluated our technique’s performance using real-world
large-scaleDL models.
•Explored our technique’s usefulness in relevant fields.
The remainder of this paper is organized as follows. Section 2
introducestheDLbackground.Section3presentsourDissector
technique for automated within-input validation for DL applica-
tions.Section4experimentallyevaluatesDissector’sperformance
and compares it to existing techniques. Section 5 explores Dis-
sector’susefulnessinrelevantfields.Finally,Section6discusses
related work in recent years, and Section 7 concludes this paper.
2 BACKGROUND
DLmodelsareusedinDLapplicationsmainlyfordecision-making,
which concerns the model training andinput predication the two
phases. We below introduce the background on the two phases as
well as the related DL model architecture to facilitate our subse-
quentdiscussions.
The model training phase takes training data (e.g., a set of im-
age samples, each with a category label like cat or dog), and in-stantiates (trains) a DL model to represent the knowledge in the
data by specific DL algorithms like Convolutional Neural Network
(CNN)[12,53].Thentheinputpredictionphasetakesthetrained
DLmodel(orDLmodelwhenwithnoambiguity)astheknowledge
to predict labels for new inputs. To distinguish, we name the in-
putsusedintrainingandprediction trainingsamples andpredicting
samples, respectively.
ADLmodelisthekeyarchitectureinDL,whichwasinspired
from human brains with millions of neurons, transferring infor-
mation by electrical impulses across layers [ 24]. DL models are
Dissector: Input Validation for Deep Learning Applications by Crossing-layer Dissection ICSE ’20, May 23–29, 2020, Seoul, Korea
Sub-model Generator (3.2)Trained DL 
model
Training 
samplesSub-model pool
OnlinePrediction snapshot profiler (3.3) Validity analyzer (3.4)
Predicting samplePrediction 
snapshot1
Prediction 
snapshot2
Prediction 
snapshot3
Prediction 
profilePVscoreSVscore1
SVscore2
SVscore3
Confidence score for the
validity degree of the given
predicting sample
Offline
Weight growth
Figure 2: Dissector overview
similarly based on the notion of neurons, which represent features
learnedfromtrainingsamplesonneuronsorganizedbylayers,as
shown in Fig. 1 (a fully-connected DNN example). In the model
training phase, a DL model learns values for neuron parameters
(e.g., bias and weights), which represent features extracted from
training samples.Then in theinput prediction phase,the parame-
tervaluesareusedforcalculatinganddecidingthemostsuitable
labels for inputted predicting samples. Formally, given a predicting
sample, the DL model generates a probability vector in the formof {
l0:prob0,l1:prob1, ...,lm−1:probm−1}, suggesting probability
probiforthissamplebeing classified into label li(all probabilities
summed up to one if normalized, e.g., by function softmax [43]).
Typically, the label with the highest probability is decided as the
final prediction result.
3 THE DISSECTOR APPROACH
DL applications rely on their integrated DL models for input pred-
ication and decision-making, and thus their reliability depends
largelyonthesemodels’predictionaccuracies.Inthissection,we
presentourDissectorapproachtodistinguishingbeyond-inputs
fromwithin-inputssothattheconcernedDLapplicationscanwork
with inputs within their handling capabilities. In the following,
we start with an overview of Dissector and then elaborate on its
detailed methodology.
3.1 Overview
Dissector consists of three main components, namely, sub-model
generator, prediction snapshot profiler, and validity analyzer, as
shown in Fig. 2.
Thesub-modelgenerator (Step1)takesatrainedDLmodel Mand
its corresponding training samples, and returns a sequence of sub-
models to represent different levels of knowledge in M. Generally,
asub-model kencodesthepartialknowledgefrom M’sfirsttoits
k-th layers. Note that the sub-model generation is conducted only
once in an offline way. Later, the generated sub-models can be
reused for validating predicting samples inputted to this DL model.
Theprediction snapshot profiler andvalidity analyzer work to-
gether for online input validation for distinguishing beyond-inputs
from within-inputs. Given a predicting sample, the profiler (Step 2)trackshowthesampleisinterpretedusingthesequenceofgener-
atedsub-models,andmakessnapshotsatdifferentlayers.Itcom-
poses a final prediction profile based on the collected snapshots.
Then the analyzer (Step 3) examines the prediction profile and
expectsthatawithin-inputshouldbeinterpretedbyaDLmodel
withincreasingconfidencetowardsitsfinalpredicationresultby
collectingitsuniquenessevidence.Otherwise,itisconsideredtobe
a beyond-input. A confidence score (PVscore) is calculated to indi-
cate the likelihood the predicting sample is within the DL model’s
handling capability. With the score, the application built on this
DLmodelcanthendecidewhetherornottoacceptthisinputted
sample and its corresponding prediction result, according to its
domain-specific requirements.
We elaborate on the three steps in turn below.
3.2 Step1: Sub-model Generator
GivenatrainedDLmodel M,thefirststepgeneratesasequenceof
sub-modelsrepresentingthegrowingpartialknowledgeencoded
in this DL model. These sub-models are used later for validating
whetheragiveninputisinterpretedbyaDLmodelwithincreasing
confidencetowards to its final prediction result.
As illustrated in Fig. 3, each sub-model kis composed of two
parts: one part is copied from the original DL model M(first layer
tointermediatelayer k)withallstructuresandparametervalues
inherited (e.g., neurons, weights, and bias), and the other part is
thelinksfromlayer ktotheoutputlayer(withlabelsin M),which
are newly trained using the original training samples. Generating
thefirstpartisstraightforward,whilegeneratingthesecondpart
needs some time, depending on M’s scale, but it is done only once.
Here,weadoptalinearregression(LR)structureforthesecond-part
training as the meta-model, since it is one of the most widely used,
proved effective structures in DNN for the final prediction layer [ 8,
12,26,53,55], and has been widely suggested in many existing
work[37,65].ThisarchitecturestrictlyfollowsaDLmodel’stypical
design. Specifically, the LR structure in a sub-model refers to a
one-layerfullyconnectedstructurewithcrossentropyasitsloss
function.
A DL model can generate as many sub-models as the number of
its intermediate layers. Users can, of course, choose to generate all
orsome,dependingontheirtimebudgets.Ourlaterexperiments
generatedonlyfourtosevensub-models,whicharealreadyenough
ICSE’20,May23–29,2020,Seoul, Korea Huiyan Wang, Jingwei Xu, Chang Xu, Xiaoxing Ma, and Jian Lu
For this layer k
Given DL model Generated sub-modelkPart 2: Newly trained LR
structure using training samplesPart 1: From the
original DL model
Figure 3: Sub-model generation
for achieving quite promising results. Besides, we note that our
Dissector approachis applicable to general DL models: although
we discuss DNN models here, CNN sub-models can be similarly
prepared by treating each convolutional layer as a normal layer.
3.3 Step2: Prediction Snapshot Profiler
WhenfeedinganinputtoagivenDLmodel,thesecondsteptracks
howtheDLmodelinterpretsthisinputbasedonthesub-models
generated in the last step. Dissector transforms the problem of
validatingthisinputfortheoriginalDLmodelintothatofexam-
ininghowthisinputis interpretedinthesegeneratedsub-models,
andobtains asequenceof correspondingprobabilityvectors (nor-
malized by function softmax). Since these sub-models represent
thegrowingpartialknowledgeencodedintheoriginalDLmodel,
these probability vectors explain how the DL model interprets the
inputlayer by layer.
Wenameeachthusobtainedprobabilityvectora predictionsnap-
shotforthe concernedsub-model. Byconnecting theseprediction
snapshots in order, Dissector obtains the whole prediction pro-
fileforthisparticularinputgoingthroughallthesub-models,i.e.,
{snapshot 0,...,snapshot n−1},whichisusedforexaminingthisinput’s
validitydegree in the next step.
3.4 Step3: Validity Analyzer
Based on the prediction profile obtained for the given input, thethird step analyzes the validity for each snapshot in this profile
(snapshotvalidity ),andthenthevalidityforthewholeprofile(profile
validity), so as to calculate the validity degree for the given input.
By validity degree, we expect that a within-input should be
predictedinawaythattheDLmodelusedforpredictingthisinput
shouldhaveanincreasingconfidencewhencrossingtheinputlayer,
through hidden layers, finally to the output layer. This is based on
our observation that since a within-input fits in the DL model’s
handlingcapability,themodelshouldwellrecognizethisinputin
its prediction process, instead of being confused by two or more
possible guesses during the prediction.
3.4.1 Snapshotvaliditymeasurement. Foreachsnapshotinapre-
dictionprofile,Dissectormeasuresitsvaliditybyanalyzingwhether
andhowitscorrespondinginput’sfinalpredictionresultis uniquely
supported by the probability vector in this snapshot.
Suppose that an input Iis fed to a DL model M(withmlabels)
andMpredictsIaslabellx.Dissectorconsidershowasnapshot
supportsthispredictionresult.Letthesnapshotunderconsideration
besnapshot k,whichisaprobabilityvector,takingtheformof{ l0:prob0,l1:prob1,...,lm−1:probm−1}.Therearetwocases: lxisalready
associated with the highest probability in this vector, or otherwise.
Forthefirstcase,Dissector(encouragingly)measuresthesnap-
shot’s unique support by how much lx’s associated probability
exceedsthesecondhighestprobabilityinthisvector.Let lSHthe
labelhavingthebestshottoconfusetheprediction(i.e.,withthe
second highest probability). Intuitively, the larger the difference
between the probabilities for label lxandlSHis, themore uniquely
the prediction result lxis supported in this snapshot.
Forthesecondcase, lxisnotassociatedwiththehighestprob-
ability.Dissector(penalizingly)measuresthesnapshot’sunique
support by how much the actual highest probability (with label lH)
exceeds that of lxin this vector. Similarly, the larger the difference
between the probabilities for label lHandlxis, theless uniquely
the prediction result lxis supported in this snapshot.
Following this intuition, we measure the snapshot validity as
follows (let snapshot[l]returnl’s associated probability):
SVscore k(lx,snapshot k)=
⎧⎪⎪ ⎨
⎪⎪⎩snapshotk[lx]
snapshotk[lx]+snapshotk[lSH],lxwiththe highestprobability;
1−snapshotk[lH]
snapshotk[lx]+snapshotk[lH],otherwise.
The snapshot validity score falls in range [0, 1]. The closer it
isto1,themoreuniquelythecurrentsnapshotsupportsthefinal
prediction result lx.
3.4.2 Profilevaliditymeasurement. Basedonthesequenceofcalcu-
latedsnapshotvalidityscores,Dissectorthenmeasuresthevalidity
for the whole prediction profile with respect to our expected in-
creasingconfidenceforaDLmodelininterpretingwithin-inputs
towards their final prediction results.
Since each snapshot corresponds to one particular intermediate
layer in the original DL model M, we normalize these snapshot
validity scores with increasing weights from the first intermediate
layertothelastone(i.e.,increasing k),echoingouraforementioned
“increasing confidence”. Therefore, we measure the profile validity
as follows:
PVscore (lx)=/summationtext.1n
k=1SVscore k(lx,snapshot k)×weiдhtk/summationtext.1nk=1weiдhtk.
3.4.3 Weightparametersetup. Theprecedingequationrequiresthe
setup for a sequence of increasing weight values. Instead of giving
ad hoc choices or tuning specially for our experimental subjects,
we try three popular growth types, namely, linear,logarithmic,a n d
exponential, in our Dissectorframework.
Table 1 lists general formulas for calculating weight values with
respecttothesethreegrowthtypes,where xcorrespondstonumber
kofthespecificlayer( snapshot k)andyrepresentsitscorresponding
weight value weiдhtk. However, these formulas contain too many
parameters for setup. Fortunately, they are subject to reduction
without losing essentials, since the weight values participate in
bothnumeratorsanddenominatorsoftheequation.Asshownin
Table 1, the reduced formulas contain one ( α)o rt w o( αandβ)
parameters only, and in our later evaluation we would investigate
the impactsof their values onDissector’s performance.
Dissector: Input Validation for Deep Learning Applications by Crossing-layer Dissection ICSE ’20, May 23–29, 2020, Seoul, Korea
Table 1: Parameter reduction for modeling weights
Growthtype General formula Reduced formulas # para
Linear y=ax+k(1)y=x2→1(2)y=αx+1
Logarithmic y=alogb(kx+c1)+c2(1)y=lnx
5→2 (2)y=αlnx+1
(3)y=αln(βx+1)+1
Exponential y=aekx+b1+b2(1)y=eβx
4→2(2)y=αeβx+1
Generally, for a given input Ia n daD Lm od e l M, Dissector’s
calculated PVscorevaluerepresents I’svaliditydegreewithrespect
toM,and thisvaluehas beennormalized to[0,1]. Thecloserthe
PVscorevalueistoone, Iismorelikeawithin-inputto M(within
M’shandlingcapability),orotherwise,morelikeabeyond-input
toM(beyondM’s handling capability).
4 EVALUATION
Inthissection,weevaluateDissectorandcompareittoexisting
techniques in distinguishing beyond-inputs from within-inputs for
DL applications.
4.1 Research Questions
We aim to answer the following four research questions:
RQ1(Effectiveness): How effective is Dissector in distinguish-
ingbeyond-inputsfromwithin-inputs,ascomparedtoexistingtech-
niques?
RQ2 (Efficiency): HowefficientisDissectorinthisprocess,as
compared to existing techniques?
RQ3 (Controlling factors): How do Dissector’s model-aware
treatment, weight growth type, and internal parameters affect its
effectiveness?
RQ4 (Usefulness): How does Dissector help defense against
adversarial inputs and improve a DL model’s actual accuracy in use?
4.2 ExperimentalSubjects,Design,and Process
We introduce experimental subjects, design, and process below.
Experimentalsubjects. Weusedasexperimentalsubjectsfour
popularimageclassificationdatasetsintheDLfield,namely,MNIST,
CIFAR-10, CIFAR-100, and ImageNet, each associated with a state-
of-the-art DL model, as shown in Table 2. (1) MNIST[25]i sa n
image database for hand-writing digit classification (ten labels).
Itcontains60,000 trainingsamplesand10,000 predictingsamples
for testing. Its DL model is LeNet4 [ 26]. (2)CIFAR-10 [22]i sa n
imagedatabaseforobjectrecognition(alsotenlabels).Itcontains
50,000trainingsamplesand10,000predictingsamples.ItsDLmodel
isWRN-28-10(WRNforshort)[ 64].(3)CIFAR-100 [22]issimilar
to CIFAR-10 but with 100 labels. It contains 50,000 training sam-
ples and 10,000 predicting samples. Its DL model is ResNeXt-29
(8x64d) (ResNeXt for short) [ 60]. (4)ImageNet [5] is a much larger
databaseforimagerecognition(with1,000labels).Itcontains1.2
milliontrainingsamplesand50,000predictingsamples.Weused
its ILSVRC2012version [51], and its DL model is ResNet101 [12].
Experimentaldesign. Wedesignedthefollowingtwoindepen-
dent variablesto control the experiments:Table 2: Descriptions for datasets and associated DL models
Dataset Description # labels # samples DL model
MNIST Digitclassification 10 60,000/10,000 LeNet4
CIFAR-10 Object recognition 10 50,000/10,000 WRN
CIFAR-100 Object recognition 100 50,000/10,000 ResNeXt
ImageNet Imagerecognition 1,000 1,200,000/50,000 ResNet101
•Subject.We used a total of four subjects, each concerning
adatasetandaDLmodel,namely,MNIST+LeNet4,CIFAR-
10+WRN,CIFAR-100+ResNeXt,andImageNet+ResNet101.
Whenwithnoambiguity,werefertoeachonebythedataset
name only.
•Technique. WecomparedDissectorwithtwostate-of-the-
art techniques closely related to input validation, namely,
mMutant[ 58],basedonmodelmutationanalysis,andMa-
halanobis [ 28], based on data-distance measurement. Dis-
sector was configured into three variants (three weight
growth types), namely, Dissector-linear, Dissector-log, and
Dissector-exp.mMutant wasconfigured intofour variants
(four mutation operators), namely, mMutant-GF, mMutant-
NAI,mMutant-WS, and mMutant-NS (no mixture recom-
mended[ 58]).Mahalanobis wasconfiguredusingitsoriginal
setting[28].Allthesetechniqueswereeitheroriginallyde-
signedorslightlyadaptedtoreportanormalizedscorein[0,
1] for a given input, with a value close to 1 suggesting more
“within”and to 0 more “beyond”.
The three techniques need some setups. (1) Dissector needs to
selectDLmodellayersforsub-modelgeneration.ForLeNet4,we
selectedalllayerssinceithasonlyfour.Forcomplexmodels,we
selectedpartoftheirlayersforefficiency.ForWRNandResNext,
we selected layers after each block, and for ResNet101, we selected
layers uniformly within each convolution group (i.e., layers 10, 22,
46,70,91,100,and101).(2)mMutantneedstoconfigureamutation
degree. This parameter was set to 0.05 for MNIST, and 0.005 for
CIFAR-10 as suggested [ 58]. It was also set to 0.005 for CIFAR-100
as it is similar to CIFAR-10. However, mMutant failed to apply
toImageNetduetoitshugemodelsizes(incurring OutOfMemo-
ryException (OOM)). Even if one could do so, we estimated that it
needs 1,500–2,000 mutants for ImageNet, which would cost over
1,000GB RAM and significant time overhead (over weeks with our
GPUresources).Sowehadtogiveitup.(3)ForMahalanobis,we
followeditsoriginalsetting[ 28]toselect10%samplesundertestto
trainitsweightparameters,andthusitseffectivenessmeasurement
was based on remaining 90% samples. Similarly, Mahalanobis also
failed to apply to ImageNet, causing OOMexceptions when its
GDA classifier analyses stored and processed intermediate resultsconcerningtraining samples.
We designed the following two dependent variables to evaluate
the three techniques:
•AUC.WeusedthepopularAreaUnderCurve(AUC)basedon
TruePositiveRate(TPR)andFalsePositiveRate(FPR)data
to measure how effective a technique is in distinguishingbeyond-inputs from within-ones. To do so, by varying athreshold from 0 to 1 and comparing it to the technique’s
reportedscoresforitsreceivedinputs,theseinputscanbe
separatedinto acorresponding setof within-onesand that
ICSE’20,May23–29,2020,Seoul, Korea Huiyan Wang, Jingwei Xu, Chang Xu, Xiaoxing Ma, and Jian Lu
Table 3: PVscore comparison between incorrectly-predicted samples and correctly-predicted samples
Subject (dataset + DL model) AccuracyIncorrectly-predicted samples Correctly-predicted samples t-test(indep.)
# samples Avg. Std. v. Med. # samples Avg. Std. v. Med. tvalue pvalue
MNIST+ LeNet4 98.41% 159 0.52 0.18 0.49 9,841 0.96 0.06 0.98 30.10 1.85e-67
CIFAR-10+ WRN 96.21% 379 0.75 0.16 0.78 9,621 0.94 0.08 0.98 22.46 4.44e-72
CIFAR-100+ ResNeXt 82.15% 1,785 0.61 0.17 0.61 8,215 0.84 0.14 0.88 53.29 ≈0.01
ImageNet+ ResNet101 77.31% 11,344 0.49 0.22 0.47 38,656 0.76 0.19 0.81 121.59 ≈0.0
1denotingthatthecorresponding pvalueis quite close to 0.0, with the difference even smaller than sys.float_info.epsilon in python.
of beyond-ones (both varying). Then by comparing the two
sets of inputs to the ground truths of real within-inputs and
beyond-inputs (discussed later), one can calculate respective
TPR and FPR data and corresponding AUC values (areas
belowthecurves):thelarger,themoreeffectivethetechnique
is in distinguishing beyond-inputs from within-ones.
•Timeoverhead. Werecordedthetimespentbyatechnique
onitsofflinework(offlineoverhead)andonlinework(online
overhead). The offline work is the sub-model preparation
forDissector,mutantgenerationformMutant,andlayer-
wise GDA classifier analysis for Mahalanobis. The online
workisthevalidityanalysisforDissector,LCRanalysisfor
mMutant,and distancescoringfor Mahalanobis.
Experimental process. We conducted all experiments on a
LinuxserverwiththreeIntelXeonE5-2660v3CPUs@2.60GHz,16
Tesla K80 GPUs, and 500GB RAM, running Ubuntu 14.04.
For RQ1 (effectiveness), we calculate AUC values to compare
Dissector withmMutant and Mahalanobis for their effectiveness
in distinguishing beyond-inputs from within-inputs.
For RQ2 (efficiency), we measure offline and online time over-
headstocompareDissectorwithmMutantandMahalanobisfor
their feasibilities in the input validation. The offline time overhead
(once)shouldbeacceptable,andtheonlinetimeoverhead(repeated)
shouldbe marginal.
ForRQ3(controllingfactors),westudyhowDissector’seffec-
tiveness can be affected by its internal factors.
ForRQ4(usefulness),westudyhowDissectorcanhelpdefense
againstadversarialinputsandimproveaDLmodel’sactualaccuracy
in use. For the former, we composed a set of inputs that contain
bothtrainingsamplesandadversarialonesgeneratedfromthemby
a popular attacker FGSM [ 10]. We study how effective Dissector
isindistinguishingthesetwotypesofsamples.Forthelatter,we
controlled the threshold to study how Dissector improves a DL
model’sactualaccuracyinuse.Wealsocalculatedthenumberof
samplesthusisolated, which should be acceptable.
4.3 ExperimentalResultsand Analyses
We report and analyze experimental results, and answer the pre-
ceding four research questions in turn.
4.3.1 RQ1(Effectiveness). Asmentionedearlier,calculatingAUC
valuesforeffectivenessmeasurementneedsthegroundtruthsof
realbeyond-inputsandwithin-inputs.Inthefollowing,wefirstdis-
cussacandidateforsimulatingthegroundtruthsandthencalculate
AUC values based on it.Ground truths. We note that the ground truths of real beyond-
inputs and within-inputs do not naturally exist, because otherwise
distinguishing beyond-inputs from within-inputs becomes a trivial
thing and already solved. Regarding this, we consider finding acandidate for simulating the ground truths. According to earlier
discussions,beyond-inputsprobablycauseaDLmodeltopredict
in a misleading or wrong way. For example, for the four subjects, a
randomguesswouldcauseanaccuracyof10%,10%,1%,and0.1%,
farbelowtheirDLmodels’accuracies(77–98%,asinTable3).There-
fore,weconsiderapropercandidateforbeyond-inputslikethose
incorrectly-predicted samples, while that for within-inputs like
thosecorrectly-predictedsamples.Furthermore,ifthissimulation
isreasonable,Dissectorshouldbeabletodistinguishthemclearly
byitsPVscoremeasurement.Therefore,westudythetwosetsof
samplesin TableTable 3 to see whether they behave as expected.
Fromthetable,weobservethat:(1)theincorrectly-predictedsam-
ples from all predicting samples obtained only a 0.49–0.75 PVscore
value (avg. 0.59), while those correctly-predicted samples obtained
0.76–0.96 (avg. 0.88), with clear differences; (2) for each subject, its
difference is still evident, e.g., 0.52 vs. 0.96, 0.75 vs. 0.94, 0.61 vs.
0.84, and 0.49vs. 0.76,with the latterclose to its model accuracy.
We usedt-test [38] to measure how significant such differences
are in a statistic way. With the null hypothesis that “Dissector
generatedPVscorevalueswithnosignificantdifferencebetween
incorrectly-predictedandcorrectly-predictedsamples”,weobtaineda series of
p-valueslisted in the last column of Table 3, all of which
are far less than 0.05. Thus one can reject this hypothesis at a 95%
confidencelevel.Withthisresult,wewouldlaterusethetwosets
ofincorrectly-predictedsamplesandcorrectly-predictedsamples
foreachsubjecttosimulatethegroundtruthsofrealbeyond-inputs
andwithin-inputstofacilitatetheeffectivenesscomparison.The
pointisthatalthoughthissimulationisaroughestimation,thelogic
still holds (from being a beyond-input to being predicted probably
incorrectly), which suffices for our experimental comparisons.
AUCcomparison. As mentioned earlier, we measure AUC val-
uestocomparethethreetechniques’effectivenessindistinguishing
beyond-inputs from within-inputs. For Dissector’s three variants,
we first studied their simplest forms, i.e., Dissector-linear ( y=x),
Dissector-log( y=lnx),andDissector-exp( y=ex).Table4lists
AUCcomparisonresults (the larger, the better, with range [0, 1]).
From the table, we observe that: (1) for each of the four subjects,
DissectoralwaysobtainedthebestAUCvalues,e.g.,0.9869–0.9894
forMNIST,0.8740–0.8963forCIFAR-10,0.8516–0.8726forCIFAR-
100,and0.8223–0.8562forImageNet;(2)mMutantobtainedonly
0.9449–0.9770,0.7346–0.8643, and0.6827–0.7129forthe firstthree
Dissector: Input Validation for Deep Learning Applications by Crossing-layer Dissection ICSE ’20, May 23–29, 2020, Seoul, Korea
Table4:AUCcomparisonamongthreetechniquesindistin-
guishingbeyond-inputs from within-inputs
Technique MNIST
+LeNet4CIFAR-10
+WRNCIFAR-100
+ResNeXtImageNet
+ResNet101
Dissector-linear 0.9894 0.8740 0.8516 0.8250
Dissector-log 0.9869 0.8963 0.8641 0.8223
Dissector-exp 0.9878 0.8960 0.8726 0.8562
mMutant-GF 0.9712 0.8643 0.6999 OOM
mMutant-NAI 0.9770 0.8577 0.7129 OOM
mMutant-WS 0.9449 0.8483 0.6827 OOM
mMutant-NS 0.9575 0.7346 0.6871 OOM
Mahalanobis 0.7504 0.8334 0.6692 OOM
thehighestAUCvalueforeachsubject is made bold.
75.7317.9 318.5 253.22,756.43,912.1
47.1689.1878.1
01,0002,0003,0004,000
MNIST+LeNet4 CIFAR-10+WRN CIFAR-100+ResNeXtOverhead (s)
DISSECTOR mMutant Mahalanobia
(a) Offline time overhead comparison (in second)
3.3 3.8 4.3210.72,870.4 2,830.6
2.8166.6 194.8
01,0002,0003,000
MNIST+LeNet4 CIFAR-10+WRN CIFAR-100+ResNeXtOverhead (ms)
DISSECTOR mMutant Mahalanobia
(b) Online time overhead comparison (in millisecond)
Figure 4: Timeoverhead comparison
subjects(withcleargapstoDissector),andcrashedwith OOMex-
ceptionsforthelargestsubjectImageNet;(3)Mahalanobisobtained
evenlowervalues,0.7504,0.8334,0.6692,forthefirstthreesubjects,
respectively, and also failed for the largest subject ImageNet; (4)
the threeDissectorvariantsbehavedsimilarly satisfactorily, and
Dissector-expworkedslightlybetterforImageNet;(5)forlarge
subjectslikeCIFAR-100andImageNet,Dissectorbehavedmore
stably (still above 0.85 and 0.82), but mMutant and Mahalanobis
eitherledtolargelyreducedAUCvalues(below0.72and0.67)or
crashed with OOMexceptions.
Therefore, we answer RQ1 as follows: Dissector was effective
in distinguishing beyond-inputs from within-inputs (AUC: 0.8223–0.9894), and behaved more stably and suitably than existing tech-
niquesfor subjectsof varying accuracies and sizes.
4.3.2 RQ2 (Efficiency). We then compare the three techniques’
time overheads, for both offline and online work. We reported the
comparisondataforthefirstthreesubjectsinFig.4(ImageNetdata
were either incomplete or too large to fit in the figure, discussed
later).ForDissector,wechoseDissector-linear( y=x),andfor
mMutant,we chosemMutant-NAI (other variantsweresimilar to
the chosenonesin time overheads).
From Fig. 4(a) and Fig. 4(b), we observe that: (1) regarding the
offlineoverhead,mMutantalwaystookthemosttime:253.2seconds
forMNIST,2,756.4secondsforCIFAR-10,and3,912.1secondsfor
CIFAR-100,whicharesignificantlymorethanwhatDissectorandTable 5: AUC comparison for studying Dissector’s model-
aware treatment
Analyzingscenario Applicationscenario
(ForMNIST) LeNet4 DNN2 LeNet5
LeNet4[26] 0.9878 0.9005(−7.3%) 0.9574(−3.1%)
DNN210.9129(−7.6%) 0.9716 0.9063(−8.3%)
LeNet5[26] 0.9720(−1.6%) 0.9248(−4.8%) 0.9882
(ForCIFAR-10) WRN VGG16 DenseNet
WRN[64] 0.8960 0.8695(−5.2%) 0.8828(−2.2%)
VGG16[53] 0.8837(−1.4%) 0.9176 0.8759(−2.9%)
DenseNet [8] 0.8686(−3.1%) 0.8626(−6.0%) 0.9024
(ForCIFAR-100) ResNeXt VGG16 DenseNet
ResNeXt [60] 0.8726 0.8352(−3.3%) 0.8425(−2.4%)
VGG16[53] 0.7680 (−12 .0%) 0.8636 0.7798(−9.7%)
DenseNet [8] 0.7980(−8.5%) 0.7997(−7.4%) 0.8634
(ForImageNet) ResNet101 ResNet50 VGG16
ResNet101 [12] 0.8562 0.8432(−2.1%) 0.8408(−0.9%)
ResNet50 [12] 0.8308(−3.0%) 0.8609 0.8440(−0.5%)
VGG16[53] 0.7938(−7.3%) 0.8012(−6.9%) 0.8483
1denoting a simple two-hidden-layer fully connected multilayer neural network.
Mahalanobiscost:75.7,317.9(least),and318.5(least)secondsfor
theformer,and47.1(least),689.1,and878.1secondsforthelatter;
(2) regarding the online overhead, mMutant again took the most
time:210.7millisecondspersampleforMNIST,2,870.4milliseconds
for CIFAR-10, and 2,830.6 milliseconds for CIFAR-100, which arealso significantly more than what Dissector and Mahalanobis
cost:3.3,3.8(least),and4.3(least)millisecondspersampleforthe
former,and2.8(least),166.6,and194.8millisecondsforthelatter;
(3) altogether, Dissector took only several minutes to complete its
offline preparation, and several milliseconds to validate an inputat runtime, which are very attractive; (4) for the more important
runtime input validation, mMutant had to take 63.3–763.3x time to
that of Dissector, and Mahalanobis took 0.8–45.3x time.
For the largest subject ImageNet with its ResNet101 model, Dis-
sectorspentaround90hoursonitsofflinepreparation,andneeded
5.8millisecondsforitsonlinevalidationpersample.90hoursare
comparabletothesubject’ownDLmodel’trainingtime[ 62].Since
requiredonlyonce,thetimeisacceptable.Dissector’sonlineover-
head is still marginal (several milliseconds), suggesting that it is
extremely stable even for complex subjects like ImageNet. On the
contrary, both mMutant and Mahalanobis failed to apply to this
subject as explained earlier.
Therefore, we answer RQ2 as follows: Dissector was highly effi-
cient with acceptable offline overhead and marginal online overhead
(severalmilliseconds),andmuchfasterthanexistingtechniques(upto
12.3x and to 763.3x speedup for offline and online work, respectively).
4.3.3 RQ3(Controllingfactors). WenextstudyhowDissector’s
model-aware treatment (validating inputs with respect to DL mod-
elsusedinapplications)contributestoitseffectiveness,andhowits
inherent growth type and other parameters affect the effectiveness.
Model-awaretreatment. Dissectorvalidatesinputsandiden-
tifiesbeyond-inputsbasedonitspreparedsub-models,whichare
derivedfromDLmodelsusedinapplications.Thus,Dissectoris
naturally model-aware, and we have observed Dissector’s unique
ICSE’20,May23–29,2020,Seoul, Korea Huiyan Wang, Jingwei Xu, Chang Xu, Xiaoxing Ma, and Jian Lu
effectiveness from this treatment earlier. Still, we want to know
howDissector’seffectivenesswouldbecompromisedifthemodel
its analysis depends on deviates from the model it is applied to.
To be specific, the former model is the one from which Dissec-
tor prepares sub-models, and the latter model is the one that
defines/simulates the sets of real beyond- and within-inputs (i.e.,
groundtruths).If Dissector’smodel-awaretreatmentisnotnec-
essary, two models being different will not cause the effectiveness
largelycompromised; otherwise, it will.
For this part of experiments, we took the best Dissector-exp
for example. Besides, for each subject, we additionally associated it
with two more popular DL models, and thus each dataset was now
withthree DL models, as in Table 5 (original DL model is listed at
thefirstrowandfirstcolumn).NotethatthesenewDLmodelsmay
have different accuracies, e.g., for CIFAR-100, the three models had
anaccuracyof82.15%,68.61%,and73.97%respectively,exhibiting
the required diversity for experiments.
Table5comparesAUCvaluesamongninecombinationsforeach
ofthefoursubjects,inwhichthe analyzingscenario referstothe
modelDissector’sanalysisdependsonandthe applicationscenario
refers to the model it is applied to. From the table, we observe that:
(1) when the analyzing and application scenarios were the same,
Dissector indeed always obtained the best effectiveness results
(diagonal values in each rectangle area, marked in bold); (2) when
thetwoscenariosweredifferent,AUCvalueswerecompromised
by a varying degree of 0.5–12.0%, which is not small; (3) in spite
of scenarios being different, Dissector could still obtain mostly
higherAUCvaluesthanexistingtechniquesforscenariosbeingthe
same,e.g.,betterthanthebestmMutant-NAIin67.5%cases,and
better than Mahalanobis in 100% cases.
Therefore,weconsiderDissector’smodel-awaretreatmentnec-
essary and important for its best effectiveness. Besides, even if it is
compromised, Dissectorcould still bringsatisfactory results.
Weight growth type and other parameters. As mentioned
earlier,Dissectorcanbeconfiguredintothreevariants(withthree
weight growth types, namely, logarithmic, linear, and exponential).
Besides,itcouldbefurthercustomizedbytwoparameters, αand
β. Previously, we explored only the simplest forms for the three
variants, and now we study the impact of different αandβvalues
(from 1 to 100).
Table6comparestheimpactof Dissector’sweightgrowthtype
andαandβparameters on its three variant families, according
tothesetupinTable1.Fromthetable,weobservethat:(1)three
weightgrowthtypesbehavesimilarlywithstableAUCvaluesfor
eachsubject(0.0000–0.0085,0.0000–0.0446,and0.0000–0.0459dif-
ferences,respectively);(2)althoughtheexponentialgrowthcould
be a bit unstable for some cases, it obtained the best results mostly,
with AUC values highest (0.9377, 0.8855, and 0.8564) for CIFAR-
10+WRN, CIFAR-100+ResNeXt, ImageNet+ResNet101, respectively,
and quite close (only 0.0018 gap) to the highest AUC value (0.9900)
for MNIST+LeNet4, and we owe the results to this type’s nature
(e.g.,moreaggressiveinthegrowthandvalidation);(3)AUCvalues
areallover0.80,withmost(around76%)over0.85andupto0.9900,
suggesting Dissector’s general effectiveness among a wide range
of parameter values.
The exponential growth seems to more favor complex subjects
(i.e., the latter three subjects). It might be due to the concerned DLTable 6: AUC comparison for the impact of weight growth
type and other parameters
Growth
type(α,β)MNIST
+LeNet4CIFAR-10
+WRNCIFAR-100
+ResNeXtImageNet
+ResNet101
Lineary=x0.9894 0.8740 0.8516 0.8250
(1,-) 0.9897 0.8650 0.8431 0.8250
(10,-) 0.9894 0.8726 0.8505 0.8241
(100,-) 0.9894 0.8738 0.8515 0.8249
Logarith
-micy=lnx0.9869 0.8963 0.8641 0.8223
(1,-) 0.9898 0.8657 0.8411 0.8147
(10,-) 0.9880 0.8894 0.8598 0.8212
(100,-) 0.9871 0.8953 0.8636 0.8222
(1,1) 0.9899 0.8556 0.8414 0.8110
(1,10) 0.9900 0.8534 0.8287 0.8086
(1,100) 0.9900 0.8508 0.8258 0.8067
(10,1) 0.9898 0.8632 0.8393 0.8152
(10,10) 0.9899 0.8557 0.8311 0.8100
(10,100) 0.9900 0.8517 0.8268 0.8073
(100,1) 0.9898 0.8645 0.8308 0.8158
(100,10) 0.9899 0.8560 0.8315 0.8107
(100,100) 0.9900 0.8518 0.8269 0.8074
Exponen
-tialy=ex0.9878 0.8960 0.8726 0.8562
(-,1) 0.9878 0.8960 0.8726 0.8562
(-,10) 0.9768 0.9377 0.8855 0.8564
(-,100) 0.9768 0.9377 0.8855 0.8564
(1,1) 0.9882 0.8918 0.8705 0.8561
(1,10) 0.9768 0.9377 0.8855 0.8564
(1,100) 0.9768 0.9377 0.8855 0.8564
(10,1) 0.9878 0.8955 0.8724 0.8564
(10,10) 0.9768 0.9377 0.8855 0.8564
(10,100) 0.9768 0.9377 0.8855 0.8564
(100,1) 0.9878 0.8959 0.8726 0.8562
(100,10) 0.9768 0.9377 0.8855 0.8564
(100,100) 0.9768 0.9377 0.8855 0.8564
models’ structures.For the firstsubject MNIST+LeNet4, itsmodel
is of relatively simple structure (only four layers), and the linearand logarithmic growths can well model its weight with normal
growthtypes.Forthelatterthreecomplexsubjects,theirmodels
areofquitecomplexstructures(e.g.,ResNet101witharoundone
hundredlayers),thusincurringquitecomplexbehaviorsinlayer-
wise sample predictions, and the exponential growth can better
model their weights with own aggressive growth.
Therefore, we answer RQ3 as follows: Dissector’s model-aware
treatmentisnecessaryandimportantforitsbesteffectiveness;besides,
its weight growth type and αandβparameters slightly affect its
stableness,butits effectiveness generallyholds.
4.3.4 RQ4 (Usefulness). We finally study how Dissector helps
byitsinputvalidationin defensing againstadversarialinputsand
improving a DL model’s actual accuracy in use.
Defensing against adversarial inputs. We are interested in
whether Dissector can also identify adversarial attacking sam-
ples by its beyond-input recognition. As mentioned earlier, we
usedapopularadversarialattackerFGSM[ 10]togenerateadver-
sarial attacking samples ( L2norm adopted and attack step set to
0.016 [23]) based on original predicting samples from the four sub-
jects.Cleansamples wereselectedfromthepredictingsampleswhen
their predictions were correct, and adversarial attacking samples
wereselectedfromthegeneratedoneswhentheirpredictionswere
Dissector: Input Validation for Deep Learning Applications by Crossing-layer Dissection ICSE ’20, May 23–29, 2020, Seoul, Korea
Table7:AUCcomparisonamongthreetechniquesinidenti-
fyingadversarialattackingsamples
Technique MNIST
+LeNet4CIFAR-10
+WRNCIFAR-100
+ResNeXtImageNet
+ResNet101
Dissector-linear 0.9979 0.9996 0.9979 0.9966
Dissector-log 0.9980 0.9997 0.9981 0.9962
Dissector-exp 0.9987 0.9998 0.9990 0.9986
mMutant-GF 0.9665 0.7792 0.7998 OOM
mMutant-NAI 0.9752 0.7637 0.7652 OOM
mMutant-WS 0.9441 0.7952 0.7715 OOM
mMutant-NS 0.9557 0.7478 0.7739 OOM
Mahalanobis 0.8152 0.9276 0.9949 OOM
thehighestAUCvalueforeachsubject is made bold.
incorrect.ThenwestudywhetherDissectorcandistinguishad-
versarialattackingsamplesfromcleansamplesasitdidforbeyond-
and within-inputsin earlier experiments.
Table 7 lists Dissector’s AUC values on this aspect, and also
compares it to earlier techniques mMutant and Mahalanobis. From
thetable,weobservethat:(1)whenmixingadversarialattacking
samplesandcleansamplestogether,Dissectorobtainedhighest
andstableAUCvalues(alwaysover0.9962andupto0.9998)iniden-
tifying the former from them, outperforming the other techniques
(0.7478–0.9752 for mMutant and 0.8152–0.9949 for Mahalanobis)
fortheirapplicablesubjects;(2) mMutantwas unstablewithAUC
values ranging in 0.7478–0.9752, performing no better than any
Dissector variant (Dissector-exp won in all cases), and failedfor ImageNet due to OOM exceptions; (3) Mahalanobis obtained
betterAUCvaluesthanmMutantforCIFAR-10andCIFAR-100,but
behaved worse for MNIST and similarly failed for ImageNet.
As a whole, we consider Dissector very useful (AUC value
nearlyone)inidentifyingadversarialattackingexamplesbybeyond-
inputs,asoneofpopularDL-basedsecurityapplications.Weowe
this to Dissector’s dedicated design of examining increasing con-
fidenceforgiveninputs,thusabletoidentifyadversarialonesby
profilingandanalyzingtheirwholecrossing-layerpredictionpro-
cess,sinceatraditionalattackcanseldomconsiderthewholeDL
model in a crossing-layer way.
Improving a DL model’s actual accuracy in use. Each DL
modelisassociatedwithanaccuracywhengivenasetofpredicting
samplesfortesting(e.g.,thoselistedinTable3).WithDissector,
the given predicting samples are refined by isolating those beyond-
inputs, and then the remaining ones (within-inputs) can bring a
better accuracy.To distinguish, wename the former original accu-
racyand the latter actual accuracy in use. We are interested in how
muchDissectorcanhelpimprovetheaccuracy.Notethatthisis
just one possible application of Dissector (more discussed later).
Weuse athreshold todecide whethera predictingsample with
a distinct PVscore value reported by Dissector is a within- (when
above)orbeyond-(whenbelow)input.Fig.5illustrateshowaDL
model’sactualaccuracywasimprovedunderdifferentthresholds.
Fromthefigure,weobservethat:(1)allthreeDissectorvariants
(linear, logarithmic, and exponential growths with simplest forms)
exhibited clear accuracy improvements with the growth of Dissec-
tor’sthresholdvalue;(2)forsubjectsMNISTandCIFAR-10,whose
original accuracies were already very high (98.41% and 96.21%),Dissector’scontributionstotheiraccuracyimprovementwererel-
atively slow but steady (finally reaching 99–100%); (3) for subjects
CIFAR-100 and ImageNet, whose original accuracies were some-
whatlow(82.15%and77.31%),Dissector’scontributionstotheir
accuracy improvement were quite impressive (finally by 15–16%and 19–20%); (4) even with a conservative threshold value of 0.8,
thethreeDissectorvariantsrealizedasatisfactoryactualaccuracy
of 95–100%, 94–100%, and 91–100%, respectively.
Someapplicationsmightconcernthenumberofisolatedsamples
asthecostforthe accuracyimprovement.Sowealsoinvestigated
thisissue.TakeDissector-linear( y=x)forexample.Whenone
set the threshold to 0.6 and 0.8, the four subjects’ actual accura-
cies could already be largely improved, e.g., CIFAR-100’s accuracy
improvedfrom82%to89%and96%,respectively.Accordingly,its
number of isolated samples was 14% and 43%. If it was Dissec-
tor-exp, the number of isolated samples was much less, e.g., 9%
and21%,respectively.Nevertheless,thesubjectitselfalsoplayed
animportantroleonthisnumber,e.g.,forMNIST(withthehigh-
est original accuracy), isolated samples were only 0–1% for both
thresholdsand all Dissector variants.As a comparison, when us-
ing other techniques for input validation, we encountered moreisolated samples. For example, when expecting the same 89% ac-
tualaccuracyfortheCIFAR-100+ResNeXtsubject,mMutant-NAI
andMahalanobiscaused21%and47%samplesbeingisolatedbut
Dissector-expisolatedonly9%samples.ThissuggeststhatDissec-
tor’s beyond-input identification is more precise and thus more
cost-effective.
ThisapplicationdoesnothavetoretraintheconcernedDLmodel,
andinsteadbringsatransparentaccuracyimprovement,thusbeing
very attractive. The fault tolerance idea behind Dissector actu-
ally maximizes the potential of the original DL model about what
it can actually do. Besides the simple treatment of isolating theidentified beyond-inputs, one can also refer to other DL models,
applications,orevenmanualcontrols(e.g.,forself-driving).This
direction deserves more research efforts.
Therefore,weanswerRQ4asfollows: Dissectorareusefulfor
defensing against adversarial inputs and improving a DL model’s
actualaccuracyin use.
4.4 ThreatAnalyses
Ourselectionofthefoursubjects,namely,MNIST,CIFAR-10,CIFAR-
100,andImageNetwiththeirassociatedDLmodels,mightthreaten
theexternalvalidity ofourexperimentalconclusions.Wetriedto
alleviatethisthreatbythefollowingefforts:(1)thefourdatasetsare
verypopularandhavebeenwidelyusedinrelevantresearch[ 11,18,
47,58];(2)theirassociatedmodelsarealsostate-of-the-artDLones;
(3)thesedatasetsandmodelsdifferfromeachotherbyvaryingtop-
ics (e.g., digit, image, and general object recognitions), labels (from
10 to 1,000), scales (from 70,000 to 1,250,000 samples), model types
(e.g.,LeNet4,WRN,ResNeXt,andResNet101),modellayers(from5
to101layers),andmodelaccuracies(from77.31%to98.41%),which
makethesesubjectsdiverseandrepresentative.Therefore,ourex-
perimental conclusions should generally hold, although specific
datacould be inevitably different for other subjects.
Threats to the external validity might also come from our se-
lected techniques for the experimental comparisons, which include
ICSE’20,May23–29,2020,Seoul, Korea Huiyan Wang, Jingwei Xu, Chang Xu, Xiaoxing Ma, and Jian Lu
75%80%85%90%95%100%
0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1Practical acuracy
ThresholdMNIST+LeNet4
CIFAR10+WRN
CIFAR100+ResNext
Imagenet+ResNet101
(a) Dissector-linear75%80%85%90%95%100%
0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1Practical acuracy
ThresholdMNIST+LeNet4
CIFAR10+WRN
CIFAR100+ResNext
Imagenet+ResNet101
(b) Dissector-log75%80%85%90%95%100%
0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1Practical acuracy
ThresholdMNIST+LeNet4
CIFAR10+WRN
CIFAR100+ResNext
Imagenet+ResNet101
(c) Dissector-exp
Figure 5: Accuracy improvement under different thresholds forDissector
mMutant[ 58]andMahalanobis[ 28].Wenotethataswearguedear-
lier, identifying beyond-inputs for a DL application should be from
the perspective of the application and ought to be lightweight run-
time validation. Thus, existing work right focused on this problem
andmeetingtherestrictioncanbelittle(excludingsomeoptions,
e.g., DeepRoad [ 66] and Surprise [ 18]). We selected mMutant be-
causeitresemblesourfocusbyidentifyingunqualifiedinputsby
DLmodel mutationanalysis (softwareengineering area).Besides,
theworkwaspublishedinMay2019,astherepresentativeofthe
state-of-the-arttechniques.WealsoselectedMahalanobisbecauseit
similarlyuseslayer-wiseinformationtoidentifyout-of-distribution
samples for DL modelsbased on distance measurements (artificial
intelligence area). The work is also the latest (Dec 2018), closely
related to our problem, as the representative of distance-based and
distribution-based data comparison techniques.
Ourinternalthreat mainlycomesfromthe lackof groundtruths
for distinguishing beyond-inputs from within-inputs. We used the
inputs predicted incorrectly and those predicted correctly to simu-
late beyond-inputs and within-inputs, respectively. As discussed
earlier,suchestimationmightberough,butsincethelogic(from
beyond-input to probably incorrect prediction) holds (RQ1), our
experimentalconclusions wouldlargely hold.To furtheralleviate
this threat, we conducted the experiments to study Dissector’s
usefulness (RQ4), which frankly disclosed what Dissector can
indeedhelpdefenseagainstadversarialinputsandimproveaDL
model’sactualaccuracyinuse,evenifbasedonourgroundtruth
simulation. Considering that our subjects have necessary diver-
sities as discussed above, our experimental conclusions can hold
generally.Still,duetothegroundtruthproblem,weplantovalidate
Dissectorin more and practical application scenarios.
5 DISSECTORAPPLICATIONS
We discuss potential Dissectorapplicationsbelow:
Tolerating imperfect DL models. DL models can hardly be perfect
forcomplexapplicationscenarios.Eveniftheyareacceptablefor
now, application scenarios can evolve from time to time and cause
themodelstobehaveunexpectedlyunsatisfactorily,asdiscussed
earlier. With an input validation wrapper like Dissector, a DL
application built on such DL models can be substantially improved
by automatically recognizing beyond-inputs with respect to what
these DL models actually do. Especially when the application is
deployedinanunstableenvironment,suchanautomatedtechnique
does help in a convenient way.Refining DL models. For the case DL models themselves have to
be refined, Dissector’s identified beyond-inputs form a critical set
for consideration. This set of inputs are beyonda DL model’s han-
dling capability, and would probably cause misleading or incorrect
predictions.Thenuserscanconsiderwhetherandhowtousethem,
e.g., for expanding the model’s scope by retraining it with these
beyond-inputs,orstrengtheningitsoriginalscopebykeepingthem
isolated.Moreissuessuchasmodelstabilityandcornercasescan
alsobe taken into consideration during this refinement process.
Comparing DL models’ accuracies. Traditionally, DL models can
be directly compared by their prediction accuracies with respect
to givensamples from anapplication scenario. With aDissector-
alike input validation wrapper, the comparison can now have new
considerations. Suppose that models A and B have original accura-
cies of 75% and 80% for this scenario. With Dissector, their actual
accuraciesinuse mightbe improvedto 90% and 85% instead.This
calls for new research opportunities on how to understand a DL
model’s actual accuracy in practice.
Measuring deployment suitability. A DL application might be
deployed in a complex application scenario, which cannot be fully
anticipatedortested.Basedonhowmanyinputsareidentifiedas
beyond-onesaswellastheresultingaccuracy,Dissectorcanbe
used for suggesting whether and how the concerned DL model
suits its deployment. More applications include assigning the most
suitable DL model from a set of candidates to the scenario, as well
as balancing the assignment of multiple DL models to multiple
applicationscenarios.
Defensingagainstadversarialinputs. Adversarialinputscanbe
substantial attacks toa DL application, and thus identifyingthem
is beneficial. Our evaluation shows that although most adversarial
inputsbehavedlikebeyond-inputs,fewofthemmightstillpassthe
validationand behavelikewithin-ones.Currently,thereis strong
evidence [ 1] showing that taking all adversarial inputs into retrain-
ing could probably bias a DL model. Then this set of adversarial,
yet still within-inputs, becomes an interesting source for critical
model improvement. More research can be initiated on this aspect.
6 RELATED WORK
Theworkstudiedinthis paperrelatestoqualityimprovementfor
DLmodelsandapplications.Webrieflydiscussrepresentativework
in recent years, on data quality assurance, DL-related verification,
testingand debugging,and adversarialattack.
Data quality assurance. One line of work focuses on assuring
quality data for DL models, so as to improve their reliability in use.
Dissector: Input Validation for Deep Learning Applications by Crossing-layer Dissection ICSE ’20, May 23–29, 2020, Seoul, Korea
Somework[ 4,19–21]focusedondatacleaningtechniquesinorder
topreparequalifiedtrainingdataforinstantiatingmodels.Other
work [13,28,30,31] regarded training samples as in-distribution
andrefinedgivennewsamplesbyidentifyingout-of-distribution
ones as outliers a statistic way. This line of work typically focuses
ondatacharacteristics,andseldomconsidersrequirementsfrom
applicationsbuilton these data.
DL-relatedverification. Thislineofworkattemptstoformallyver-
ifyDLmodelsfortheirquality.Somework[ 17,49]proposedtouse
symbolictechniquesforabstractingtheinputspaceforaDLmodel,
but could hardlyscale to large and complex ones. Some [ 9,15,41]
couldworkforrelativelylargermodels,butsupportedonlyspecific
neural networks. The others [ 14,48,59,67] targeted at security-
criticalorsafety-criticalDL-assistedapplications,andverifiedthem
forsafetyproperties.Ourworkcomplementsthisline,byvalidating
inputsat runtime for better model performance.
Testing and debugging. This third line of work aims to generate
diverse and realistic corner cases to expose possible flaws in DL
models.Forexample,DeepXplore[ 47]convertedthecorner-case
generation problem to a joint optimization one, and searched to-
wardsamodel’sdecisionboundaries.MoreworkexaminedDLmod-
elsbytesting,e.g.,byimagetransformation[ 57],inputfuzzing[ 11],
mutationtesting[ 35],andmetamorphictesting[ 66].Tomeasure
thetestingadequacy,variouscoveragecriteriawereproposed,in-
cludingtheneuroncoverage[ 47,57],SScoverage[ 54],neuron-and
layer-level coverage [ 34], combination dense coverage [ 36], and
surprisecoverage[ 18].Interestingly,itwasalsoarguedthatsuch
structuralcoveragecriteriaforDLmodelscouldbemisleading[ 29].
Finally, DL models could be debugged for their flaws by analyzing
biased data distribution [ 37]. Our work also complements this line,
by runtime validation for tolerating unexpected problems after the
concerned DL models have been tested and deployed.
Adversarialattack. Finally,proposingbetterDLmodelsagainst
adversarial attacks is getting hotter. On one hand, adversarial at-
tacking techniques were proposed to generate adversarial sam-
ples with small artificial perturbations to fool DL models, e.g., L-
BFGS[56],FGSM[ 10],JSMA[45],C&W[3],Uni.perturbation[ 39],
and DeepFool [ 40]. On the other hand, defense techniques were
also proposed to identify such fooling samples, e.g., adversarial
sample detection [ 58], adversarial training [ 56], foveation-based
defense[32],gradientregularization/masking[ 33,42,50],defensive
distillation[ 44,46],andGAN-baseddefense[ 27].Theytogetherim-
proveDLmodelsinarecursiveway.Ourworkcanalsobeusedfor
identifyingadversarialattackingsamples as one of its application.
7 CONCLUSION
In this paper, we proposed Dissector for effective and efficient
validation of inputs to DL applications. Dissector distinguishes
beyond-inputs from within-inputs by collecting prediction unique-
nessevidence,andworksinamodel-awareandlightweightway.
The experimental evaluation confirmedDissector’s unique effec-
tivenessandclear gains overexistingtechniques.Dissectoralso
exhibitedencouraging usefulnessindefensing againstadversarialinputsand improving a DL model’ actual accuracy in use.
Currently,Dissectorhastobeconfiguredforitsgrowthtype
andparameters,althoughtheydonotaffectmuch( <5%).Weareconsideringguidingtheconfigurationbypredictionfeedbacksofitsgeneratedsub-modelstomakeDissectorfullyautomated.Besides,
Dissector needs to be tested in more application scenarios, for
both more practical validation and more usefulness exploration.
ACKNOWLEDGMENTS
This work was supported in part by National Key R&D Program
(Grant#2017YFB1001801)andNationalNaturalScienceFoundation
(Grants #61932021, #61690204, and #61802170) of China. The au-
thorswouldalsoliketothankthesupportfromtheCollaborative
InnovationCenterofNovelSoftwareTechnologyandIndustrializa-
tion,Jiangsu,China.
REFERENCES
[1]Naveed Akhtar and Ajmal Mian. 2018. Threat of adversarial attacks on deep
learningin computer vision: A survey. IEEEAccess 6 (2018), 14410–14430.
[2]Mariusz Bojarski, Davide Del Testa, Daniel Dworakowski, Bernhard Firner, Beat
Flepp,PrasoonGoyal,LawrenceDJackel,MathewMonfort,UrsMuller,Jiakai
Zhang, et al .2016. End to end learning for self-driving cars. arXiv preprint
arXiv:1604.07316 (2016).
[3]Nicholas Carlini and David Wagner. 2017. Towards evaluating the robustness
ofneuralnetworks.In Proceedingsofthe38thIEEESymposiumonSecurityand
Privacy(SP 2017). IEEE, 39–57.
[4]XuChu,JohnMorcos,IhabFIlyas,MouradOuzzani,PaoloPapotti,NanTang,
and Yin Ye. 2015. KATARA: A Data Cleaning System Powered by Knowledge
BasesandCrowdsourcing. (2015).
[5]Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. 2009. Im-
agenet: A large-scale hierarchical image database. In Proceedings of the 2009
IEEEConferenceonComputerVisionandPatternRecognition(CVPR2009).Ieee,
248–255.
[6]Reuben Feinman, Ryan R Curtin, Saurabh Shintre, and Andrew B Gardner. 2017.
Detecting adversarial samples from artifacts. arXiv preprint arXiv:1703.00410
(2017).
[7]JoÃčo Gama, IndrÄŮ Å¡liobaitÄŮ, Albert Bifet, Mykola Pechenizkiy, and Hamid
Bouchachia. 2014. A Survey on Concept Drift Adaptation. ACM Computing
Surveys (CSUR) 46 (04 2014). https://doi.org/10.1145/2523813
[8]Huang Gao, Liu Zhuang, Laurens Van Der Maaten, and Kilian Q. Weinberger.2017. Densely Connected Convolutional Networks. In Proceedings of the IEEE
Conferenceon Computer Vision and Pattern Recognition (CVPR 2017) .
[9]XavierGlorot,AntoineBordes,andYoshuaBengio.2011. Deepsparserectifier
neuralnetworks. In Proceedingsof the14th InternationalConferenceon Artificial
IntelligenceandStatistics(AISTATS 2011) . 315–323.
[10]Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. 2014. Explaining and
harnessingadversarialexamples. arXivpreprint arXiv:1412.6572 (2014).
[11]JianminGuo,YuJiang,YueZhao,QuanChen,andJiaguangSun.2018. DLFuzz:
differentialfuzzingtestingofdeeplearningsystems.In Proceedingsofthe201826th
ACM Joint Meeting on European Software Engineering Conference and Symposium
on the Foundations of Software Engineering (ESEC/FSE 2018). ACM, 739–743.
[12]KaimingHe,XiangyuZhang,ShaoqingRen,andJianSun.2016. Deepresidual
learning for image recognition. In Proceedings of the 2016 IEEE Conference on
ComputerVisionandPatternRecognition (CVPR 2016) . 770–778.
[13]DanHendrycks and Kevin Gimpel. 2016. A Baseline for Detecting Misclassified
andOut-of-DistributionExamplesin Neural Networks. (10 2016).
[14]Xiaowei Huang, Marta Kwiatkowska, Sen Wang, and Min Wu. 2017. Safety
verification of deep neural networks. In Proceedings of the 2017 International
Conferenceon Computer Aided Verification (CAV 2017) . Springer, 3–29.
[15]Kevin Jarrett, Koray Kavukcuoglu, Yann LeCun, et al .2009. What is the best
multi-stagearchitecture for object recognition?. In Proceedings of the 2009 IEEE
12th International Conference on Computer Vision (ICCV 2009) . IEEE, 2146–2153.
[16]Kyle D Julian, Jessica Lopez, Jeffrey S Brush, Michael P Owen, and Mykel J
Kochenderfer. 2016. Policy compression for aircraft collision avoidance systems.
InProceedings of the 2016 IEEE/AIAA 35th Digital Avionics Systems Conference
(DASC 2016). IEEE, 1–10.
[17]Guy Katz, Clark Barrett, David L Dill, Kyle Julian, and Mykel J Kochenderfer.
2017. Reluplex:AnefficientSMTsolverforverifyingdeepneuralnetworks.In
Proceedingsofthe2017InternationalConferenceonComputerAidedVerification
(CAV 2017). Springer, 97–117.
[18]Jinhan Kim, Robert Feldt, and Shin Yoo. 2019. Guiding deep learning system
testing using surprise adequacy. In Proceedings of the 41th ACM/IEEE Interna-
tionalConferenceonSoftwareEngineering(ICSE2019),forthcoming,arXivpreprint
arXiv:1808.08444.
ICSE’20,May23–29,2020,Seoul, Korea Huiyan Wang, Jingwei Xu, Chang Xu, Xiaoxing Ma, and Jian Lu
[19]Sanjay Krishnan, Michael J. Franklin, Ken Goldberg, Jiannan Wang, and Eugene
Wu.2016. ActiveClean:AnInteractiveDataCleaningFrameworkForModernMa-
chine Learning. In Proceedings of the 2016 ACM SIGMOD InternationalConference
on Management of Data (SIGMOD’16).
[20]Sanjay Krishnan, Jiannan Wang, Michael J Franklin, Ken Goldberg, Tim Kraska,
Tova Milo,andEugeneWu. 2015. SampleClean:Fastand ReliableAnalyticson
DirtyData. BulletinoftheIEEEComputerSocietyTechnicalCommitteeonData
Engineering 38,3 (2015), 59–75.
[21]SanjayKrishnanandEugeneWu.2019. AlphaClean:AutomaticGenerationof
DataCleaningPipelines. (04 2019).
[22]Alex Krizhevsky and Geoffrey Hinton. 2009. Learning multiple layers of features
from tiny images. Technical Report. Citeseer.
[23]AlexeyKurakin,IanGoodfellow,andSamyBengio.2016. Adversarialmachine
learningat scale. arXivpreprint arXiv:1611.01236 (2016).
[24]JonathanLaserson.2011. FromNeuralNetworkstoDeepLearning:zeroinginon
thehumanbrain. XRDSCrossroadstheACMMagazineforStudents 18,1(2011),
29–34.
[25]YannLeCun.1998. TheMNISTdatabaseofhandwrittendigits. http://yann.lecun.
com/exdb/mnist/ (1998).
[26]Yann LeCun, Léon Bottou, Yoshua Bengio, Patrick Haffner, et al .1998. Gradient-
based learning appliedto document recognition. Proc. IEEE 86, 11(1998), 2278–
2324.
[27]Hyeungill Lee, Sungyeob Han, and Jungwoo Lee. 2017. Generative adversar-
ial trainer: Defense to adversarial perturbations with GAN. arXiv preprint
arXiv:1705.03387 (2017).
[28]Kimin Lee, Kibok Lee, Honglak Lee, and Jinwoo Shin. 2018. A Simple Unified
Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks.
InAdvancesinNeuralInformationProcessingSystems31(NIPS2018),S.Bengio,
H.Wallach,H.Larochelle,K.Grauman,N.Cesa-Bianchi,andR.Garnett(Eds.).
CurranAssociates, Inc., 7167–7177.
[29]Zenan Li, Xiaoxing Ma, Chang Xu, and Chun Cao. 2019. Structural CoverageCriteria for Neural Networks Could Be Misleading. In Proceedings of the 41th
ACM/IEEE International Conference on Software Engineering (ICSE 2019 NIER),
forthcoming.
[30]ShiyuLiang,YixuanLi,andR.Srikant. Principleddetectionofout-of-distribution
examples in neural networks. (????).
[31]ShiyuLiang,YixuanLi,andR.Srikant.2018. EnhancingTheReliabilityofOut-
of-distributionImageDetectionin Neural Networks. (2018).
[32]YanLuo,XavierBoix,GemmaRoig,TomasoPoggio,andQiZhao.2015.Foveation-basedmechanismsalleviateadversarialexamples. arXivpreprintarXiv:1511.06292
(2015).
[33]ChunchuanLyu,KaizhuHuang,andHai-NingLiang.2015. Aunifiedgradient
regularization family for adversarial examples. In Proceedings of the 2015 IEEE
InternationalConferenceon Data Mining (ICDM 2015) . IEEE, 301–309.
[34]Lei Ma, Felix Juefei-Xu, Fuyuan Zhang, Jiyuan Sun, Minhui Xue, Bo Li, Chun-
yangChen,TingSu,LiLi,YangLiu,etal .2018. DeepGauge:Multi-granularity
testingcriteriafordeeplearningsystems.In Proceedingsofthe33rdACM/IEEE
International Conference on Automated Software Engineering (ASE 2018) . ACM,
120–131.
[35]LeiMa,FuyuanZhang,JiyuanSun,MinhuiXue,BoLi,FelixJuefei-Xu,ChaoXie,LiLi,YangLiu,JianjunZhao,etal
.2018. DeepMutation:Mutationtestingofdeep
learningsystems.In Proceedingsofthe2018IEEE29thInternationalSymposium
on Software Reliability Engineering (ISSRE 2018). IEEE, 100–111.
[36] Lei Ma, FuyuanZhang, Minhui Xue, Bo Li, Yang Liu, Jianjun Zhao, and Yadong
Wang. 2018. Combinatorial testing for deep learning systems. arXiv preprint
arXiv:1806.07723 (2018).
[37]ShiqingMa,YingqiLiu,Wen-ChuanLee,XiangyuZhang,andAnanthGrama.
2018. MODE:automatedneuralnetworkmodeldebuggingvia statedifferential
analysisandinputselection.In Proceedingsofthe201826thACMJointMeeting
on European Software Engineering Conference and Symposium on the Foundations
of Software Engineering (ESEC/FSE 2018). ACM, 175–186.
[38]Richard Mankiewicz. 2005. The story of mathematics. Princeton University Press
PrincetonNj 9 (2005).
[39]Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Omar Fawzi, and Pascal
Frossard. 2017. Universal adversarial perturbations. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition (CVPR 2017). 1765–1773.
[40]Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and Pascal Frossard. 2016.DeepFool:asimpleandaccuratemethodtofooldeepneuralnetworks.In Pro-
ceedings of the 2016 IEEE Conference on Computer Vision and Pattern Recognition
(CVPR 2016). 2574–2582.
[41]Vinod Nair and Geoffrey E Hinton. 2010. Rectified linear units improve re-
stricted boltzmann machines. In Proceedings of the 27th International Conference
on Machine Learning (ICML 2010). 807–814.
[42]Linh Nguyen, Sky Wang, and Arunesh Sinha. 2018. A Learning and Masking
Approach to Secure Learning. In Proceedings of the 9th International Conference
on Decision and Game Theory for Security (GameSec 2018). Springer, 453–464.
[43]Michael A Nielsen. 2015. Neural networks and deep learning . Vol. 25. Determina-
tionpress San Francisco, CA, USA.[44]NicolasPapernotandPatrickMcDaniel.2017. Extendingdefensivedistillation.
arXivpreprint arXiv:1705.05264 (2017).
[45]NicolasPapernot,PatrickMcDaniel,SomeshJha,MattFredrikson,ZBerkayCelik,
and Ananthram Swami. 2016. The limitations of deep learning in adversarialsettings. In Proceedings of the 2016 IEEE European Symposium on Security and
Privacy(EuroS&P2016) . IEEE, 372–387.
[46]Nicolas Papernot, Patrick McDaniel, Xi Wu, Somesh Jha, and Ananthram Swami.
2016. Distillationasadefensetoadversarialperturbationsagainstdeepneural
networks. In Proceedings of the 2016 IEEE Symposium on Security and Privacy (SP
2016). IEEE, 582–597.
[47]Kexin Pei, Yinzhi Cao, Junfeng Yang, and Suman Jana. 2017. Deepxplore: Au-
tomated whitebox testing of deep learning systems. In Proceedings of the 26th
Symposium on Operating Systems Principles (SOSP 2017). ACM, 1–18.
[48]KexinPei,YinzhiCao,JunfengYang,andSumanJana.2017. Towardspractical
verification of machine learning: The case of computer vision systems. arXiv
preprint arXiv:1712.01785 (2017).
[49]Luca Pulina and Armando Tacchella. 2010. An abstraction-refinement approach
toverificationofartificialneuralnetworks.In Proceedingsofthe22ndInternational
Conferenceon Computer Aided Verification (CAV 2010) . Springer, 243–257.
[50]Andrew Slavin Ross and Finale Doshi-Velez. 2018. Improving the adversarial ro-
bustnessandinterpretabilityofdeepneuralnetworksbyregularizingtheirinput
gradients. In Proceedings of the 32nd AAAI Conference on Artificial Intelligence
(AAAI 2018).
[51]OlgaRussakovsky,JiaDeng,HaoSu,JonathanKrause,SanjeevSatheesh,Sean
Ma,ZhihengHuang,AndrejKarpathy,AdityaKhosla,MichaelBernstein,etal .
2015. Imagenet large scale visual recognition challenge. International Journal of
ComputerVision 115,3 (2015), 211–252.
[52]DavidSilver,AjaHuang, ChrisJMaddison,ArthurGuez,LaurentSifre,George
Van Den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershel-
vam, Marc Lanctot, et al .2016. Mastering the game of Go with deep neural
networksandtree search. Nature529,7587(2016),484.
[53]KarenSimonyanandAndrewZisserman.2014.Verydeepconvolutionalnetworks
forlarge-scaleimagerecognition. arXivpreprint arXiv:1409.1556 (2014).
[54]Youcheng Sun, Xiaowei Huang, and Daniel Kroening. 2018. Testing Deep Neural
Networks. arXivpreprint arXiv:1803.04792 (2018).
[55]Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir
Anguelov,DumitruErhan,VincentVanhoucke,andAndrewRabinovich.2014.
GoingDeeper with Convolutions. (09 2014).
[56]ChristianSzegedy,WojciechZaremba,IlyaSutskever,JoanBruna,DumitruErhan,
Ian Goodfellow, and Rob Fergus. 2013. Intriguing properties of neural networks.
arXivpreprint arXiv:1312.6199 (2013).
[57]YuchiTian,KexinPei,SumanJana,andBaishakhiRay.2018. Deeptest:Automated
testing of deep-neural-network-driven autonomous cars. In Proceedings of the
40thInternationalConferenceonSoftwareEngineering(ICSE2018) .ACM,303–314.
[58]Jingyi Wang, Guoliang Dong, Jun Sun, Xinyu Wang, and Peixin Zhang. 2019.
AdversarialSampleDetectionforDeepNeuralNetworkthroughModelMutation
Testing. In Proceedings of the 41st ACM/IEEE International Conference on Software
Engineering(ICSE2019),forthcoming,arXivpreprint arXiv:1812.05793 .
[59]Shiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, and Suman Jana. 2018.
Formalsecurityanalysisofneuralnetworksusingsymbolicintervals.In Proceed-
ings of the 27th USENIX Security Symposium (USENIX Security 2018). 1599–1614.
[60]Saining Xie, Ross Girshick, Piotr Dollár, Zhuowen Tu, and Kaiming He. 2017.
Aggregatedresidualtransformationsfordeepneuralnetworks.In Proceedings
of the IEEE conference on computer vision and pattern recognition (CVPR 2017).
1492–1500.
[61]Wayne Xiong, Jasha Droppo, Xuedong Huang, Frank Seide, Mike Seltzer, An-
dreasStolcke,DongYu,andGeoffreyZweig.2016. Achievinghumanparityin
conversationals peechrecognition. arXivpreprint arXiv:1610.05256 (2016).
[62]Yang You, Zhao Zhang, Cho-Jui Hsieh, and James Demmel. 2017. 100-epoch
ImageNet Training with AlexNet in 24 Minutes. CoRRabs/1709.05011 (2017).
arXiv:1709.05011http://arxiv.org/abs/1709.05011
[63]Zhenlong Yuan, Yongqiang Lu, Zhaoguo Wang, and Yibo Xue. 2014. Droid-
sec:deeplearninginandroidmalwaredetection.In ACMSIGCOMMComputer
CommunicationReview (CCR 2014) , Vol. 44. ACM, 371–372.
[64]Sergey Zagoruyko and Nikos Komodakis. 2016. Wide Residual Networks. (05
2016).
[65]Chen-Lin Zhang, Jian-Hao Luo, Xiu-Shen Wei, and Jianxin Wu. 2018. In Defense
of Fully Connected Layers in Visual Representation Transfer. 807–817. https:
//doi.org/10.1007/978-3-319-77383-4_79
[66]Mengshi Zhang, Yuqun Zhang, Lingming Zhang, Cong Liu, and Sarfraz Khur-
shid. 2018. DeepRoad: GAN-based metamorphic testing and input validation
frameworkforautonomousdrivingsystems.In Proceedingsofthe33rdACM/IEEE
International Conference on Automated Software Engineering (ASE 2018) . ACM,
132–142.
[67]HeZhu,ZikangXiong,StephenMagill,andSureshJagannathan.2019. Aninduc-
tivesynthesisframeworkforverifiablereinforcementlearning.In Proceedings
of the 40th ACM SIGPLAN Conference on Programming Language Design and
Implementation(PLDI2019) . ACM, 686–701.
