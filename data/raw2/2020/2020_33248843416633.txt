Attend and Represent: A Novel View on Algorithm Selection for
Software Verification
Cedric Richter‚àó
Paderborn University
Paderborn, Germany
cedricr@mail.upb.deHeike Wehrheim‚àó
Paderborn University
Paderborn, Germany
wehrheim@upb.de
ABSTRACT
Today,aplethoraofdifferentsoftwareverificationtoolsexist.When
having a concrete verification task at hand, software developers
thus face the problem of algorithm selection. Existing algorithm
selectors for software verification typically use handpicked pro-
gram features together with (1) either manually designed selection
heuristicsor(2)machinelearnedstrategies.Whilethefirstapproachsuffers from not being transferable to other selection problems, thesecondapproachlacksinterpretability,i.e.,insightsintoreasonsfor
choosing particular tools.
Inthispaper,weproposeanovelapproachtoalgorithmselec-
tion for software verification. Our approach employs representa-
tionlearning togetherwithan attentionmechanism.Representation
learningcircumvents feature engineering,i.e., avoidsthehandpick-ingofprogramfeatures.Attentionpermitsaformofinterpretability
ofthelearnedselectors.Wehaveimplementedourapproachand
haveexperimentallyevaluatedandcompareditwithexistingap-
proaches. The evaluation shows that representation learning does
not only outperform manual feature engineering, but also enables
transferability of the learning model to other selection tasks.
KEYWORDS
Software verification, algorithm selection, representation learning,
attention.
ACM Reference Format:
Cedric Richter and Heike Wehrheim. 2020. Attend and Represent: A Novel
ViewonAlgorithmSelectionforSoftwareVerification.In 35thIEEE/ACM
International Conference on Automated Software Engineering (ASE ‚Äô20), Sep-
tember 21‚Äì25, 2020, Virtual Event, Australia. ACM, New York, NY, USA,
13 pages. https://doi.org/10.1145/3324884.3416633
1 INTRODUCTION
Today,alargenumberofdifferenttoolsforsoftwareverificationex-
istasforinstancewitnessedbytheannualcompetitiononsoftware
verification SV-COMP [ 13]. For software developers, this poses the
questionof algorithmselection [55]forsoftwareverification:Which
‚àóThisauthorwaspartiallysupportedbytheGermanResearchFoundation(DFG)within
the Collaborative Research Centre "On-The-Fly Computing" (SFB 901).
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ASE ‚Äô20, September 21‚Äì25, 2020, Virtual Event, Australia
¬© 2020 Association for Computing Machinery.
ACM ISBN 978-1-4503-6768-4/20/09...$15.00
https://doi.org/10.1145/3324884.3416633tooltouseforaconcreteverificationtaskathand?Competitions
likeSV-COMPortoolcomparisonsinstudies(likethoseonAndroid
taint analysis tools [ 50,53]) only give a broad approximation of
the best tool for an actual verification task: while the tool might
perform best on average, it could very well show bad performance
on the specific task at hand.
This insight has stimulated research on automatic algorithm
selection for software verification, taking the concrete program
to be verified as input. Such approaches first of all fix featuresof
programswhicharerelevantforsoftwareverification,e.g.,theexis-tenceofloops(yes/no)ormorespecificallythetypeofloops.Hence
theseapproachesperformanexplicitfeatureengineeringtailored
totheproblemofverification.Second, strategies forselectionbased
onfeaturevaluesaredesigned,eitherbyhand[ 14]orlearnedvia
machinelearning[ 24,25,63].Whilesuchspecificallyengineered
approachesoftenperformwellontheirspecifictask,theyfallshorton (a) transferability and/or (b) interpretability: Manually designed
strategies cannot be transfered to other tasks, even if they are
closelyrelated,andmachinelearningbasedapproachestypically
cannot even partially explain reasons for selecting particular tools
to users.
In this paper, we propose a novel approach for algorithm selec-tion in software verification. The approach builds on a program
representation inacommon format,not specializedtothe taskof
algorithm selection for software verification. Our employed format
isasortofhierarchicalabstractsyntaxtree(AST)wherethehier-
archy defines the contextin which a program entity (like function
or statement) occurs. These so called contextualized syntax trees
are the inputs to our supervised representation learning method.
Representation learning in general is a technique intertwining the
learningofe.g.aclassificationtaskitselfwiththeautomaticdiscov-
eryoffeaturesnecessaryforthistask. Ourrepresentationlearner
is a neural network operating on contextualized syntax trees.
The representation learner in addition employs an attention
mechanism [64] to allow for a form of interpretability of selec-
tion results. Attention mechanisms have first been proposed for
neuralmachinetranslation[ 9,42]andsincethenemployedinvari-
ous areas [ 27,31,35,49]. Attention mimics the way humans learn:
they focus their attention on particular aspects of a task and letthese aspects (in the majority) determine how the task is solved.In machine learning, attention mechanisms determine ‚Äì simplyspeaking ‚Äì the set of features the learner should attend to most
whensolvingaspecifictask.Inoursetting,attentionsuppliesus
with weights on the program representation, the weight fixing the
attentiononprogrampartsinaspecificselectiontask.Byhighlight-
ingthesepartsaccordingtotheirweights,thesoftwaredeveloper
10162020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE)
can be informed about the program constituents responsiblefor a
particular tool selection.
Wehaveimplementedourrepresentationlearnerforcontextu-
alized syntax trees of C programs. To evaluate its effectiveness,
wehaveexperimentallycomparedittootheralgorithmselection
approachesforsoftwareverification:(1)aselectorwithhandpicked
booleanfeatures anda manuallydesignedselection strategy,(2) a
selector with the same handpicked boolean features and a decision
tree algorithm for strategy learning and (3) a selector with more
sophisticated but still handpicked features and a support vector
machineforstrategylearning.Wefocusedonfour,relativelysimilarselectiontasksforverification:(a)theselectionofatooloutofthose
participating in the software verification competition SV-COMP
20181,(b)theselection ofananalysisemployedwithintheconfig-
urable verification tool CPAchecker [ 16], (c) the selection between
just two of these analyses and (d) the selection of analyses to be
executedinsequence.Asprogramstobeverifiedandthusinputs
to the selector we have taken examples from the SV-COMP bench-
mark set. The experiments show that our representation learner
performs well on all four tasks, often requiring even less time than
the other machine-learning based approaches. Moreover, the repre-
sentation learned for one such task can directly (and successfully)
betransferredtoothertasks.Finally,attentionallowsustohigh-
light program parts relevant for a particular selection to users and
thus naturally supports interpretability.
In summary, we make the following contributions:
‚Ä¢Anovelrepresentationlearnerforsourcecode,readytoalso
be employed for learning other properties on code,
‚Ä¢anattentionmechanismforpartialinterpretabilityoflearned
selections,
‚Ä¢both their implementation and application to four selection
tasks, and
‚Ä¢anextensiveevaluationandcomparisontoseveralrelated
approaches.
Source code and supplementary materials are available online2.
2 FOUNDATIONS
In this section, we briefly explain the methods underlying our
approach,inparticulartheconceptofattentioninmachinelearning.
Westartbyclearlystatingourspecificalgorithmselectionproblem.
2.1 Problem Description
Theobjectiveofalgorithmselectionforsoftwareverificationisto
choosea verifier(outofsomesetofexistingverifiers)foragiven
program to be verified. We let Pbe the set of all programs and
V={ùëâ|ùëâ:P‚Üí{ùëá,ùêπ,ùëà}}bethesetofverifiers,eachmappinga
programtoaverificationoutcome {ùëá,ùêπ,ùëà}(ùëá=programiscorrect,
ùêπ= program contains error, ùëà= unknown). For simplicity, we
assume the correctness specification (property to be checked) to
be encoded inside the program and the outcome of a verifier to be
defined as ùëàif it violates any resource constraint during its run.
Notethatdependingontheselectiontaskwewillvarytheset V
in the following.
1https://sv-comp.sosy-lab.org/2018/
2https://github.com/cedricrupb/cst_transformint i;
float result;
float x = 10.0;
float grad = 0.0;
for( i = 0; i < 1000; i++) {
grad = 2*x;
x = x - 0.1*grad;
}
result = x*x;
assert( result < 0.001);hasLoophasFloat
(a) Strategy Selectorint i;
float result ;
float x = 10.0;
float grad = 0.0;
for( i=0 ; i < 1000 ; i++ ) {
grad = 2*x;
x = x - 0.1*grad;
}
result = x*x;
assert( result < 0.001);LOOP_IT LOOP_BOUND
COUNTERSCALAR_FLOAT
Lùëèùëúùë¢ùëõùëëùëíùëë
(b) Verifolio
int i;
float result;
float x = 10.0;
float grad = 0.0;
for(i = 0; i < 1000 ; i++) {
grad = 2*x;
x = x - 0.1*grad;
}
result = x*x;
assert( result < 0.001);Short bound
Loop
(c) BMC vs KIint i;
float result;
float x = 10.0;
float grad = 0.0;
for(i = 0;i < 1000; i++){
grad = 2*x;
x = x - 0.1*grad;
}
result = x*x ;
assert( result < 0.001);Float multiply
( d )P Av sK I
Figure 1: Example program with different features
SimilartoBeyeretal.[ 14],westudyamorefocusedalgorithm
selection problem over tools. Instead of also optimizing the runtimeor memory consumptionasin [
24],our goalisto maximize
thenumberofverificationtaskssolvedcorrectly.Moreformally,let
ùê∫‚äÜP√ó{ ùëá,ùêπ}be the set of verification problems (programs
with correctness specifications) annotated with a ground truth,
i.e.(ùëÉ,ùëá)‚ààùê∫only if the program ùëÉis correct. In addition, we
definesol:ùê∫‚Üí2Vwithsol(ùëÉ,ùë¶)={ùëâ‚ààV| ùëâ(ùëÉ)=ùë¶}as
themappingtothesetofcorrectverifiersforaninstance ùëÉ.No w ,
letAS={ùê¥|ùê¥:P‚ÜíV } be the set of considered algorithm
selectors,thentheproblemcanbeformulatedasfindinganoptimal
selector ùê¥‚àóthat maximizes the expectation of selecting a correct
verifier over random (ùëÉ,ùë¶)‚ààùê∫:
ùê¥‚àó=ùëéùëüùëîùëöùëéùë• ùê¥‚ààASE/bracketleftbig
ùê¥(ùëÉ)‚ààsol(ùëÉ,ùë¶)/bracketrightbig
(1)
Notethatinpracticetheexpectationoperator Eisevaluatedempir-
ically on a finite subset of ùê∫.
2.2 Features for Selection
Current algorithm selectors, might they be hand-madeor learned
viamachinelearningalgorithms,buildon features(orcharacteristics
or attributes) of programs. Such features are typically manuallychosen and are specialized to the selection task. The process of
selecting features is known as feature engineering.
Current algorithm selectors for software verification choose fea-
tures based on knowledge about strengths and weaknesses of veri-
fiers. However, as soon as these strengths and weaknesses change
(e.g., support for specific program aspects ‚Äì say pointers ‚Äì is im-
provedornovelverificationtechniquesaredevelopedandimple-
mented)ortheselectiontaskitselfchanges,chosenfeaturesbecome
inadequate and the tedious task of feature engineering has to be
1017repeated. Current algorithm selectors are often too rigid and static,
and hence cannot flexibly cope with changes.
Weillustratethisshortcomingonsomecurrentverificationtech-
niques (as implemented in tools). Consider the task of selecting
between the two verification techniques of Bounded Model Check-
ing(BMC)[ 21]andùëò-Induction(KI)[ 15].Theyarecomplementary:
BMC isa viablesolution ifthe programhas afinite (nottoo large)
number of execution paths. KI, on the other hand, extends BMC
with automatic loop invariant generation. However, the process of
generatinginvariantsisoftencostly,whichallowsBMCtobemore
efficientinthefinitecase[ 14].Moreprecisely,weexpectBMCto
be superior to KI if loop executions are bounded by a small con-
stant.AnoptimalalgorithmselectorchoosingbetweenBMCand
KIshouldbeengineeredtoexploitthisobservationordiscoveritby
learning from data. Consider now a slightly different selection task
choosingbetweenKIandanothertechniquecalledPredicateAb-
straction (PA) [ 17], both of which are good at proving correctness
ofprogramswithunboundedloops.Nowdifferentselectioncriteria
become relevant. For example, performance differences between
KIandPAcanbeduetotheindividualhandlingoffloatingpoint
operations and thus their detection becomes important.
Example: For a more detailed explanation take a look at Fig-
ure 1. It shows the same program snippet four times together with
specificfeatures,Figure1(a)forthestrategyselectorasemployedintoolCPAchecker[
14]andFigure1(b)forthetoolVerifolio[ 24].Fig-
ures 1(c) and 1(d) on the other hand show features which would be
required for two selection tasks. CPAchecker bases its decision on
simple features only; for our snippet it detects the occurrence of a
loopandafloatingpointvariable,and‚ÄìfortheselectiontaskBMC-
KI ‚Äì would choose technique KI. Verifolio extracts more specific
features, namely it in addition detects that the loop is bounded(by
findingthetypicalcomponentsofaforloop:initialization,bound
andcounter).Still,itwouldalsoselectKI,altogetherabandoning
BMCinthepresenceofloops.However,thebestchoicewouldbe
BMCastheloopiterationsareboundedbya smallconstant.Hence,
for the specific task of BMC-KI selection, the features shown in
Figure1(c)aremoreadequate.Moreover,anewselectiontaskmightrequiredifferent weightsonfeatures:whileBMC-KIshouldfocusat-
tention on feature Short bound andLoop, a PA-KI selector should
detect and focus on Float multiply as Figure 1(d) indicates.
In summary, different selection tasks require different features and
different weights on features evenif we keep the general objective
ofalgorithmselectionforsoftwareverification.Thisobservation
motivates a machine learning technique automating the discovery
of problem dependent characteristics. More specifically, we aim at
achievingtwolearningobjectivesatthesametime:(1)tolearna
representation of programs as vectors, mimicing the feature vectors
obtainedforstaticfeaturesets,ho wever,withoutanexplicitfeature
engineering, and (2) to learn the relevance and importance of such
features for the specific selection task.
2.3 Transformer
To learn representations of verification tasks, our approach builds
uponthesocalled Transformerarchitecture ofVaswanietal.[ 64].
Although such Transformers were mainly developed for natural
language processing, it has been shown that they work well inIbaked some cookies foryoucookiesCookies (Sweets)
Figure 2: Do we refer to web cookies or to sweets?
variousotherdomainslikeimagegeneration[ 19,49],musiccom-
position[ 35]andprogramrepair[ 31].Here,weexplainthebasic
principle behind the Transformer along the lines of an example
taken from natural language processing (NLP).
The example is the sentence given in Figure 2. Our objective
is to find an appropriate representation for this and similar sen-
tences,thisrepresentation being conditioned onaspecific context.
The learned representation should allow to furthermore learn a
classification task. In the NLP setting, a contextualized represen-
tation of a single word is often required, in our example ‚Äúcookies‚Äù.
The classification which we intend to learn is that the meaning of
‚Äúcookies‚Äù in the context of this sentence is ‚ÄúCookies (Sweets)‚Äù.
Finding a contextualized representation entails two steps: (1)
finding representations for each word and (2) aggregating these
representationsforanentiresentenceinameaningfulway.Both
of these steps are being learned, i.e., their calculation employs a
number of learnable parameters.
The initial representation is obtained from an encoding table
which assigns every word to a vector Rùëö, where ùëöis the dimen-
sionality hyperparameter. The sentence is then represented as a
sequence of word vectors [h1,h2,..., hùëõ]mapping each word to a
corresponding vector. In our example, the sequence length ùëõis 6
andh4is the initial representation of ‚Äúcookies‚Äù.
A key principle employed in the second step is the concept of a
context.Asweashumanscaneasilyseeinourexamplesentence,
themeaningofcookiesisthatofsweets,notwebcookies.Wedetect
thisby lookingat thecontext,specifically theword ‚Äúbaked‚Äù.Thus
our learning process should learn a representation for ‚Äúcookies‚Äù in
this context which is completely different from a representationof ‚Äúcookies‚Äù in the sentence ‚ÄúToday, I deleted all my cookies in
Firefox.‚Äù.
Attention. Thecoretechniqueaccomplishingafocustothemost
relevantinformationinthecontextisthe attention mechanism[ 9,
42]. Attention computes the relevance of a context word ùëóin the
context of a query term ùëñ(‚Äúcookies‚Äù) as follows:
ùëüùëñùëó=/parenleftBig
ùëäùëÑhùëñ/parenrightBig/parenleftBig
ùëäùêæhùëó/parenrightBigùëá
, (2)
whereùëáis matrix transposition and ùëäùëÑ,ùëäùêæare learnable param-
eter matrices. Setting the relevance is done by tuning ùëäùëÑand
ùëäùêæduring training. This is achieved by standard backpropagation
techniques in machine learning.
InFigure2,therelevanceofcontextwordswithrespecttothe
query term ‚Äúcookies‚Äù is depicted by thickness of lines: whereas
forinstance‚Äúbaked‚Äùisconsideredrelevantforthewordmeaning
‚Äúcookies‚Äù, ‚Äúsome‚Äù is not. Distinguishing the parameters ùëäùëÑ,ùëäùêæ
1018for i=0i<1000 i++ForStmtForStmt (Bounded)
Figure 3: The detection of a small bounded for statement.
in Equation 2 allows to learn an asymmetric relevance relation. In
ourexample,‚Äúbaked‚Äùmightbemorerelevantforthemeaningof
‚Äúcookies‚Äù than ‚Äúcookies‚Äù for the meaning of ‚Äúbaked‚Äù.
To obtain the necessary aggregation for an entire sentence, the
wordrepresentationsareaggregated withrespect tothepreviously
calculated relevance score:
ùõºùëñùëó=exp(ùëüùëñùëó/‚àöùëö)
/summationtext.1ùëõ
ùëò=1exp(ùëüùëñùëò/‚àöùëö), Aùëñ=ùëõ/summationdisplay.1
ùëó=1ùõºùëñùëóhùëó(3)
whereùëéùëñùëóistheattentionweightcomputedasasoftmaxnormaliza-
tionoftherelevancescore.Thecontextvector Aùëñisaweightedsum
of all context words weighted by their individual relevance for the
query term hùëñ. Inpractice, thecontext word representation hùëóbe-
foreaggregationandtheattentionresult Aùëñarefedthroughlearned
linear transformations ùëäùëâandùëäùëÇ, respectively. The transforma-
tion is here omitted for notational simplicity.
NeuralNetworkEncoders. Attentionsofarlearnsarepresentation
specifictoagivensentence.Overall,wewouldliketogeneralizethis
specific learning outcome to other contexts (here, other sentences).
This is the typical task of a neural network (NN). For simplicity,
we define the NN formally as a function ùúå. For a more technical
descriptionof ùúå,wereferto[ 64].Now,thefinalrepresentationis
obtainedbyapplying ùúåonthesumoftherepresentation hùëñandthe
result of the attention mechanism Aùëñ:
h/prime
ùëñ=ùúå(hùëñ+Aùëñ) (4)
Inourexamplesetting,anoptimal ùúåwouldfinallymaptheword
‚Äúcookies‚Äú in our example sentence to a classification as ‚ÄúCookies
(Sweets)‚Äú,and‚Äìcontrary‚Äìtherepresentationof‚Äúcookies‚Äúinthe
sentence ‚ÄúToday, I deleted all my cookies in Firefox.‚Äù to an alterna-
tive vector representation of ‚ÄúCookies (Web)‚Äú. In practice, Trans-
formers simultaneously calculate new representations for every
wordresultinginarefinedsentencerepresentation [h/prime
1,h/prime
2,..., h/primeùëõ].
By applying multiple Transformer layers composed of an attention
mechanism and NN encoders one after another, successively more
precise representations are obtained.
3 APPROACH
Inthissection,weintroduceourapproachfor simultaneously learn-
ingthefeaturerepresentationsofverificationtasksandthealgo-
rithmselectionitself.Aftergivingageneraloverview,wepresent
a hierarchical model for source code suitable for software verifi-cation. For learning a source code representation, we adapt the
Transformer architecture to explicit hierarchical learning.ForStmt Function Program
ForStmt (Bounded)
Function (Bounded Loop)
Program (BMC)
Figure 4: The representation process of a program.
3.1 Overview
Westartagainbygivinganexample,nowfromtheareaofsoftware
verification. Consider the program block given in Figure 3 and the
selection task of BMC-KI, as already discussed before. The block
consistsofanumberoflow-leveltokens(i,<,etc.).Theobjectiveis
now to learn a representation of this statement block capturing its
meaning and employ this representation to learn a classification
of the statement. For the task BMC-KI the classification we would
like to learn is (some subsymbolic form of) ‚ÄúForStmt (Bounded)‚Äù
becausethisisthecrucialinformationforselection.Notethatwe
neverfixsuchclassificationsbeforehandnorwilltherepresentation
learner call this ‚ÄúForStmt (Bounded)‚Äù at the end. Again, we employ
anattentionmechanismwhichhereshouldguaranteethetokens
‚Äúfor‚Äù and ‚Äú1000‚Äù to be highly relevant for ‚ÄúForStmt‚Äù and ‚Äú<‚Äù not.
This reflectsthe higher importance ofloop bound and‚Äúfor‚Äù token.
Astheconcreterepresentationistask-dependent(BMC-KI),weaim
to adapt the Transformer architecture to learn a task-dependent
representation.
Here,therelevantblockmeaningcanbededucedfromitscon-
stituent tokens. Now, we can apply the same idea to deduce the
relevant meaning of a function from its constituent statements and
of a program from its functions. We hence require a hierarchical
Transformerarchitecture.Oneverylevelinthishierarchy,anap-
propriate aggregation oftheconstituentrepresentationsneedstobe
learned.UsingtheexampleofBMC-KI,wevisualizeapossiblehier-archical representation process in Figure 4. On the lowest level, welearnthemeaningoftheforblocktobe‚ÄúForStmt(Bounded)‚Äùwhich
allowstolearnthefunctioncontainingthisblocktobe‚ÄúFunction
(Bounded Loop)‚Äù and the entire program to be ‚ÄúProgram (BMC)‚Äù
which finally leads to the selection of BMC over KI.
Tosummarizethenecessarystepsforobtainingarepresentation
learner for algorithm selection in software verification, we require
(1)an explicit model of the decomposition of a program into
tokens,blocksandfunctions.InSection3.2,wepresentan
appropriate hierarchical model.
(2)Amachinelearningtechniquethatoperatesonourmodel
while learning a program representation. We describe our
learning approach in Section 3.3.
AnoverviewofourfinalarchitecturecanbefoundinFigure5.A
programisfirsttransformedtoasocalled contextualizedsyntaxtree
(CST) (see next). The CST hierarchically composes program tokens
(redsquares)intohigh-orderconceptssuchasblocks,functionsand
programs (blue circles). In the first layer we encode every token as
a vector and iteratively aggregate vectors by a Transformer. The
Transformer outputs attention weights for every aggregation step
1019int main(){
int i;
float result;
float x = 10.0;
float grad = 0.0;
for(i=0 ;i<1 0 0 0 ;i + + ){
grad = 2*x;
x = x - 0.1*grad;
}
result = x*x;
assert( result < 0.001);
return 0;
}
ProgramùëÖ
...
... ...
... ... ... ...Hierarchical
Transformer
Layer
Encoding
LayerRepresentation
TokensStatementsFunctionsProgram
Architectureint main(){
int i;
float result;
float x = 10.0;
float grad = 0.0;
for(i = 0;i < 1000 ; i++) {
grad = 2*x;
x = x - 0.1*grad;
}
result = x*x;
assert( result < 0.001);
return 0;
}
Attention
BMC 0.63
KI 0.24
PA 0.13
Prediction
Figure 5: Hierarchical Transformer architecture for programs
whichwecanuseforvisualization.Finally,theobtainedprogram
representationcanbeusedforpredictionandselectionofaverifier
(giving scores to each verifier in the set V).
3.2 Contextualized Syntax Trees
To model the composition of syntactic elements into the context of
high-order program structures, we propose Contextualized Syntax
Trees(CST)asourprogrammodel.ACSTdistinguishesthreetypes
of program structures: Functions, statements and syntax tokens.
Syntaxtokenslikeliterals,variableaccessesoroperationsarede-
fined in the context of a statement, while statements are composed
to functions. Functions are defined in the context of a program
which act as the root of our CST.
Formalization: Formally,wedefineaCSTas ùê∂=(ùëÅ,Ctx,ùëõ0,ùëô)
whereùëÅis the set of nodes, Ctx:ùëÅ‚ÜíùëÅassigns every node to
its context (another node), ùëõ0‚ààùëÅis the tree root and ùëô:ùëÅ‚ÜíL
assignseverynodetoalabelinafinitelabelset L.Furthermore,the
set of nodes ùëÅ=ùëÉ‚à™ùêπ‚à™ùëÜ‚à™ùëácan be divided into disjoint subsets
for programs ùëÉ, functions ùêπ, statements ùëÜand syntax tokens ùëá.W e
restrict the context such that Ctx(ùëá)‚äÜùëÜ,Ctx(ùëÜ)‚äÜùêπ,Ctx(ùêπ)‚äÜùëÉ,
whileùëÉcontains only one element ùëõ0as the program root. The
depth of a node in a CST is the length of the path to the root.
Nodes that belong to the same depth ùëëare summarized to a set
ùëÅùëë={ùëõ‚ààùëÅ|depth(n) =ùëë}andùëÅ0={ùëõ0}.
Independenceassumption: Bydefinition,theCSTintroduces
a strong independence assumption: It is assumed that there are no
dependencies among tokens, statements or functions. While this is
nottrueingeneralandtheassumptionismerelymotivatedfrom
an efficiency perspective, the intuition here is that every program
elementisachallengeforaverifierbyitself.Thedifficultyofthe
individual challenge is then decided by its constituents. This de-
signdecision,however,imposesanotherchallengeforconstructing
the CST: How should a program be split into statements, when
statementsareoftencompositionsofotherstatements?Although
thereexistsmanypossiblesplits3,wechoosetosplittheprogramas
proposed byZhang etal. [68]. Morespecifically, we considerloop
headsandbranchconditionsasblocksindependentoftheirbody,
while statements occuring e.g. in a loop head are not recognized
3For instance, possible splits are loop head together with loop body or loop head
consisting of loop condition only.as independent blocks. This leads us to the following construction
procedure.
Construction: ToconstructaCST,wefirstparsetheprogram
intoitsabstractsyntaxtree(AST)[ 11].TheASTdoesnotonlysplit
the program into the necessary syntax tokens but also models the
syntactic structure of a program. Next, the AST is traversed and
the CST constructed:
(1)Function roots are identified by function declarations occur-
ring in the AST. Each function is represented by a function
nodeintheCSTandassignedtotheprogramroot.IfanAST
node is only reachable by traversing a function root ùëì, then
it belongs to the context of ùëì.
(2)Statement roots are identified. Every AST node that belongstoafunction,looporbranchbodyisconsideredtobeastate-
ment root. The tree rooted at a statement root is considered
as the statement‚Äôs AST. In the CST, we create a statementnode per statement and assign it to its function context.
Globallydefinedstatementsareassignedtoaspecial init
function.
(3)We flatten the statement AST by pre-order traversal and
createasyntaxtokenperASTnodeintheCST.Allcreated
nodesareassignedtotheassociatedstatementnodeinthe
CST. AST labels are kept in the CST.
Optimizations: Although the CST can now be used for model-
ing a program, we further optimized the model to meet memory
constraintsandavoidoverfittingofourlearnerinpractice.While
the CST can be used to model programs of arbitrary languages,the following optimizations are tailored to software verificationon C programs. The adaptions allowed us to train our machinelearning model on large-scale programs with thousands lines of
codes, e.g. code of the linux kernel.
Nodetyping. Followingtheapproachesin[ 22,56,57],wereplaced
concreteidentifiernames,literalvaluesandunaryandbinaryoper-ationsbyfixedlabels.Forinstance,wemapintegerstoidentifiersofcommonrangesdefinedbytheCstandard,i.e.,anintegerismappedto
BitLiteral ,ByteLiteral ,ShortLiteral ,IntegerLiteral or
LongLiteral .Althoughidentifiersincludingfunctionnamesare
replaced,wedistinguisha special MainFunction andInitFunction.
MainFunction labelsthemainfunctionoftheprogramand InitFunc-
tionis assigned to the dummy function that summarizes all global
1020Linear
¬¨Linear
¬¨Linear
¬¨
LayerNorm LayerNormHierarchical
Attention¬¨
Linear¬¨
LayerNormGELULinear¬¨
Figure 6: Architecture of a Hierarchical Transformer Layer
statements. Statements are labelled according to their statement
type. An example for a forstatement can be found in Figure 3.
Representing statementsas sets. To improve thespace-efficiency
ofaCST,weexperimentedwithreplacingthesequenceofsyntax
tokens at every statement with a set representation. Together with
aforementioned optimizations, we noticed a significantly higher
runtime efficiency and lower memory footprint while the accu-
racy degenerated only slightly. Therefore, we decided for our final
evaluation to represent statements as sets.
3.3 Hierarchical Transformer
For contextualized syntax trees, we now adapt the Transformer
[64] to operate on hierarchies instead of sequences. We denote the
modifiedTransformerasthe HierarchicalTransformer (HT).Modifi-
cationsarepresentedonthebasisofagivenCST ùê∂=(ùëÅ,Ctx,ùëõ0,ùëô).
Asthefirststep,theinitialrepresentation H={h0,h1,..., hùëõ}
is obtained from an encoding table which assigns every label in
Lto a vector in Rùëö. Every node ùëõùëñis then encoded by a vector
hùëñaccording to its label ùëô(ùëõùëñ). The objective of HT is to find a
refinedrepresentation H/prime={h/prime
0,h/prime
1,..., h/primeùëõ}suchthat h/prime
ùëñencodes
all necessary information of ùëõùëñand its children.
Depth-wisetransformation. IncontrasttotheoriginalTrans-
former, HT only considers the interaction between parent nodeand children: The representation of nodes at depth
ùëëis only de-
pendent on nodes at depth ùëë+1. Exploiting the definition of a
CST, the initial representations can be split depth-wise resultingin
Hùëë={‚Ñéùëñ‚ààH|ùëõùëñ‚ààùëÅùëë}. Now, we define HT as a depth-wise
function by the following formulation:
H/prime
ùëë=HT/parenleftBig
Hùëë,H/prime
ùëë+1/parenrightBig
(5)
Sincethenodesatmaximaldepth ùê∑havenochildren,weset H/prime
ùê∑=
Hùê∑.NotethatHTcomputesallnewrepresentations h/prime
ùëñforevery
hùëñ‚ààHùëëinparallel.WeschematicallydepicttheHTlayerinFigure6.
The visualization includes technical details which we discuss in
the remaining section. If we now iteratively apply the HT layerto acontextualized syntax tree,wewill obtainour final program
representation ùëÖ=h/prime
0after 3 steps.Decl ForStmt
Int VarRef For VarRef <Short
Figure 7: Masking for Hierarchical Attention. Dotted graylines will be ignored during attention computation.
Hierarchical attention.
Ifweapplytheattentionmechanism
naivelybetweenallparentrepresentationsin Hùëëandchildrepre-
sentationsin H/prime
ùëë+1,wewouldallowthateveryparentcanattendto
everychildevenifthechilddoesnotbelongtotheparent.Toavoid
this, we replace the relevance calculation while masking scores
between parents and non-children:
ÀÜùëüùëñùëó=/braceleftbiggùëüùëñùëó,if Ctx(ùëõùëó)=ùëõùëñ,
‚àí‚àû,otherwise(6)
whereùëüùëñùëóiscalculatedasdescribedinSection2.3betweentwonode
representations hùëñandh/prime
ùëó.Bysettingtherelevanceofanode ùëõùëófor
a parent node ùëõùëñto negative infinity, we say that ùëõùëóis infinitely
irrelevant for ùëõùëñasùëõùëóis not the child of ùëõùëñ. As the exponential
functionconvergesto0forlargenegativenumbers,theattention
betweenparentandnon-childrenismaskedout[ 64]inEquation
(3).Figure7givesanexampleformaskedoutattention.The ùê∑ùëíùëêùëô
node is not allowed to attend to the children of the ùêπùëúùëüùëÜùë°ùëöùë°.
Sparseevaluation. Inpractice,attentionmasking,asemployed
inhierarchicalattention,istypicallyappliedaftercomputingthe
relevancescore.Inotherwords,anattentionmatrixbetweenpar-
entandchildrenofthesize |ùëÅùëë|√ó|ùëÅùëë+1|iscomputedfirst.Then,
mostoftheresultsarethrownawayafterthemaskingoperation.
ExploitingthesparsityofaCST,weimplementedmaskedattentionsparselyonGPUs.Anattentionweightiscomputedifandonlyifit
is not masked out. As a result, time and memory consumption de-
creasesto ùëÇ(|ùëÅùëë+1|)perdepth ùëë.Inpractice,weobservesignificant
performance gains over dense computation on large CSTs.
Furtherdeviations. Inadditiontothemodificationsmentioned
above, the following deviations were applied: layer normaliza-tion [
8] as pre-norm [ 48,65],GELUactivation [ 32] as motivated
by [26] and the addition of dummy nodes [ 20,44]. Finally, we omit
multi-headed attention [64] to improve explainability.
AlgorithmSelection: Tocompleteouralgorithmselector,we
feed the obtained representation to a linear unit followed by a
softmaxactivation.Theoutputprovidesuswithaconditionalprob-
ability of solving the given problem instance (ùëÉ,ùë¶)correctly for
every considered verifier ùëâ‚ààV:
ùëù(ùëâ‚ààsol(ùëÉ,ùë¶)|ùëÉ) (7)
SuchaprobabilityisforinstanceshowninFigure5forthethree
available verifiers BMC, KI and PA in V. In practice, the verifier
with the highest probability is selected. Similar to [ 37,43], the
algorithm selector is trained to minimize the averaged negative
log-likelihood of the reference set ùëå=sol(ùëÉ,ùë¶):
loss=‚àí1
|ùëå|/summationdisplay.1
ùëâ‚ààùëålogùëù(ùëâ‚ààùëå|ùëÉ) (8)
1021Figure 8: Web UI for Model Exploration
3.4 Model exploration
Attentionisnaturally interpretable [20].Alearnedattentionweight
indicates how important a child is for the representation of its
parent. Clearly, a node that has an high impact on the model de-cision has to achieve an high attention score. More importantly,the program representation is mostly shaped by the CST nodes
that achieve the highest overall attention. Therefore, we believe an
explainable insight of the model behavior and also the following
algorithm selectiondecision canbe gained byanalyzing theatten-
tion weight. To explore the behavior of our algorithm selectors, we
implemented a Web UI to visualize the attention scores across our
model. An excerpt of the interface is shown in Figure 8.
Web UI features: Aftertraininganalgorithmselector,theob-
tained decision model can be uploaded to this web interface. After-
wards,itispossibletoquerythealgorithmselectorwithaprogram
written in C. The UI does not only show the model decision but
also highlights parts of the code with respect to its obtained atten-
tion. A menu shows implemented functions and their attention. By
selectingafunction, thefunctioncodewillbeshown. Wecolored
every statement in a function by its attention score. Statements
withhigherattentiongetadarkercolor.Byselectingastatement,
we show the attention score per syntax token in a bar diagram. Al-
ternatively, attention can be depicted in the form given in Figure 1.
In contrast to all other existing algorithm selectors for software
verification, our approach shows the reasons for a particular selec-
tiontothesoftwaredeveloper.Itthuspossessesacertainformof
interpretability which naturally comes with attention-based tech-
niques.Thewebinterfaceisincludedasapartofthesupplementary
material.
4 EVALUATION
Ourevaluationisdesignedtoinvestigatewhetherrepresentation
learning can relieve a developer from manual feature engineering
in the context of algorithm selection for software verification. The
investigation intends to answer the following research questions:
RQ1Canrepresentationlearningimprovealgorithmselection?
RQ2Dolearnedprogramrepresentationstransfertonewse-
lection tasks?
Figure 9: Histogram of the SV18dataset.
Tostudytheseresearchquestions,wedesignedindividualexperi-
mentsperquestion.Westartbydescribingthegeneralsetupforall
experiments in terms of dataset, evaluation metrics and baselines.
4.1 Dataset
Forourexperiments,wechoosethebenchmarksetemployedby
Beyeretal.[ 14]intheirworkonalgorithmselection.Werefertoit
asSV18.SV18consistsof5687programstakenfromthesoftware
verificationcompetitionSV-COMP2018.Everyverificationprob-
lem(program)belongstooneof11categoriesofthecompetition,
including ReachSafety onArray,BitVectorandFloatprograms.Using
the data set statistics, as shown in Figure 9, we can observe that
programs in SV18are unusually large, with a majority of over 84%
ofallprogramscontainingmorethan1000nodes.Foracompari-
son,recentcoderepresentationmethods[ 5,33]wereperformedon
programswithanaveragecodelengthofaround99tokens,while
the average program in SV18contains more than 50.000 nodes.
Now, choosing SV18as our dataset gives us the unique opportu-
nitytodefinethefollowingfouralgorithmselectiontasksonthe
same dataset:
BMC-KI. In this setting, an algorithm selector has to take a
binarydecisionbetweenBoundedModelChecking(BMC)
andùëò-Induction (KI). The choice of these is motivated by
our example in Section 2.2.
Algorithms is a selection task over a set of 6 verification
algorithms implemented in the configurable analysis tool
CPAchecker[ 14].ThesetincludesamongothersBMCand
KI.
Sequential Composition (SC) considersthreesequentialcom-
positions formed by the previously mentioned 6 verification
algorithms. For comparability, we choose the same composi-
tions as described by Beyer et al. [14].
Tools.For this task, the selector has to select one verification
tooloutofseveralSV-COMP2018participants.Wechoose
the10toolsthatsolvedatleastoneverificationtaskinevery
aforementioned category.
In the following, we refer to these entities to select from simply as
verifiers.
1022Datapreparation: Foreachselectiontask,welabeledprograms
with the subset of verifiers that solve the problem correctly within
15min. To measure the generalization performance of learning, we
split the dataset into a training and test set with ratio of 90:10. The
training set is again split with same ratio for obtaining a devel-
opmentset.Generatedsplitsmaintainthesamerelativeratiofor
verification problem per category as the source dataset. If neces-
sary,algorithmselectorsaretrainedonthetrainingsetwhilethe
development set serves for model selection. Experiment results
are reported for the test set. For reproduciblity, splits and labeling
are contained in supplementary material while programs can be
obtained from the official SV-COMP repository4.
4.2 Evaluation Metric
We evaluated all compared techniques with respect to their nor-
malizedaccuracy ùëõùê¥ùê∂ùê∂.Todeterminetheaccuracyofanalgorithm
selector ùê¥onatestset ùê∑consistingoflabeledprograms,weemploy
the following formula:
ùê¥ùê∂ùê∂=1
|ùê∑|/summationdisplay.1
(ùëÉ,ùëå)‚ààùê∑1[ùê¥(ùëÉ)‚ààùëå],ùëõ ùê¥ ùê∂ ùê∂ =ùê¥ùê∂ùê∂
ùëÇùê¥ùê∂ùê∂,
where 1is the indicator function, ùê¥(ùëÉ)is the selected verification
techniqueonaprogram ùëÉandùëåisthesetofverificationtechniques
that solve ùëÉcorrectly. Motivated by the oracle measure in [ 14],
we normalize the accuracy score based on the score of an oracle
denoted by ùëÇùê¥ùê∂ùê∂. An oracle always performs the best possible
selectionforataskathand,andthereforeitsaccuracyrepresents
the theoretically highest achievable score for a given test set.
Themeasure ùëõùê¥ùê∂ùê∂calculatesanaccuracyscorebetween0%and
100%.Whileascoreof0%indicatesthatnotasingleproblemcanbe
verified correctly, a score of 100% will be achieved if the algorithm
selector assigns every program to the best possible verifier.
4.3 Baselines
We compare our representation learner against a number of other
approaches for algorithm selection in software verification.
BestSelector simplyselectsthetechniquethatperformsbeston
the training set. While this is not a feasible selector in practice, we
reportitsperformancetoinvestigatewhetheralgorithmselectors
can improve the verification process.
CPA-Selector [14] is a completely hand-engineered algorithm
selector.CPA-Selectorextractsthefourbooleanfeatures hasLoop,
hasArray, hasFloat and hasComposite. Then, it employs fixed rules
toselectoneofthethreesequentialcompositionsusedinourSC
selection task. These manually designed rules hence cannot be
generalizedtoothertasks.Therefore,weonlyreportresultsforthe
SC task.
DT-Selector. Generalizing the idea of CPA-Selector, we con-
structedaselectorwiththesamefeatures,butusingDecisionTrees
(DT)[58]asitslearningparadigm.DTsareabletolearnselection
rulesinbooleanlogic.FollowingDemyanovaetal.[ 25],wetrain
onedecisiontreeperverifier.TheDTlearnstheprobabilitythatthis
verifier belongs to the set of correctly solving techniques. At the
end, the verifier with the highest predicted probability is selected.
4https://github.com/sosy-lab/sv-benchmarks/tree/svcomp18/cVerifolio [25] basesitsfeaturesoncustomstaticanalysisand
source code metrics including variable roles, detection of syntacti-
cally bounded loops and branching counts. Verifolio trains support
vector machines (SVMs) [ 59] with a radial basis kernel per verifier.
The SVM predicts whether a verifier achieves a correct result or
not. To achieve a probabilistic output, the SVMs are extended with
PlattScaling[ 51].Inourexperiment,theverifierwiththehighest
predicted probability is selected.
Kernel (RPC) [56] isaselectorwhichdoesnotemployanex-
plicitfeaturerepresentationforprograms.Kernel(RPC)transformsprogramsintographscapturingcontrolandprogramdependencies.
To bypass feature engineering, the authors designed a custom ker-
nelfunctionwhichcandirectlyoperateongraphrepresentations.
The selection function is then learned by a support vector machine
equipped with the kernel. The output of the SVMs are rankings
over all verifiers using ranking by pairwise comparison (RPC) [ 36].
4.4 Experimental Setup
Webrieflyreportonsomedatapreprocessing,thetrainingsetup
and the experiment protocol for our representation learner.
Datapreprocessing: Toapplyourlearningmethodtothe SV18
dataset, we first compute an AST for every program with the help
oftheCLANGCcompilerfrontend5.ThisisfollowedbytheCST
transformation as described in Section 3.2. On the training set
we perform further cleaning operations, while the development
and test set remains the same in all experiments. First of all, wededuplicated all isomorphic CSTs in our training set using the
Weisfeiler-Lehman test of isomorphism [
41]. To further counter
measure the memorization of our model [ 54], we removed training
exampleswhereanisomorphiccounterpartcanbefoundinthetest
set. Finally, we removed all examples which cannot be solved by
anyverifierindividuallypertask.Intotal,weprunebetween495
and 1266 out of 4607 training examples dependent on the task.
Trainingsetup: Ourapproachusesacommonhiddendimen-
siononalllayers.ForthetasksBMC-KIandAlgorithms,weemploy
a hidden dimension of 64 and a hidden dimension of 128 on SC
andTools.SimilartotheoriginalTransformer[ 64],Dropout[ 62]is
appliedoneverysublayerbeforeitisaddedtothepreviousinput
and on the final representation. For training, we used the AdamOptimizer [
39] withùõΩ1=0.9,ùõΩ2=0.98 and ùúñ=10‚àí9. We employ
a linear warmup and linear decay of the learning rate. To avoid
overfitting,westopthetrainingifthevalidationaccuracyonthe
developmentsetdoesnotimproveafter5trainingepochs.Ashyper-parameterofourtraining,wetunethelearningrate
‚àà[10‚àí6,10‚àí2],
warmup length ‚àà[0%,20%], weight decay ‚àà[10‚àí6,1], batch size
‚àà{8,16,32}and number of epochs ‚àà{30,100}.
ExperimentProtocol: Forallourexperiments,wetunehyper-
parameter via Bayesian Optimization [ 2,60] (BO). BO is allowed
totestupto150parametercombinationsperexperiment.Thepa-
rametersettingwiththehighestvalidationaccuracyisselectedandthenthecorrespondingmodelisevaluatedonthetestset.Wetrain
our model on a Tesla K80 accelerator. Techniques without GPU
support are trained on a six-core virtual machine with 32GB main
memory.Ifruntimesarereported,theyaremeasuredonalimited
5https://clang.llvm.org/
1023machine with 3.4 GHz@2 CPU and 15GB main memory. Runtime
measurements are limited to 15mins per example.
5 RESULTS
Next, we report on the results of our evaluation.
5.1 RQ1: Can representation learning improve
algorithm selection?
To investigate whether algorithm selection benefits from repre-
sentation learning, we design two experiments. During the first
experiment, we measure the selection accuracy of our algorithm
selectorequippedwithanattentionbasedrepresentationlearner
(Attn+RL). We compare the selection accuracy on all proposed se-
lection tasks with the performance of our baselines. The second
experiment is designed to evaluate the runtime necessary for selec-
tion.
Selectionaccuracy: OurevaluationresultsarepresentedinTa-
ble1.Allmeasurementsarereportedinnormalizedaccuracy ùëõùê¥ùê∂ùê∂
asapercentageonthetestset.Thebestresultsarehighlightedin
bold. For now, the row Attn+RL+TR can be ignored.
During our experiments, Verifolio aborted on two programs and
Kernel (RPC) ran into a timeout for 98 out of 551 test cases. For
thesetwo,thereportedresultshencereflecttheaccuracyofa hybrid
techniquethatusestheoriginalselectorwheneverpossibleandthe
BestSelector otherwise. For a fair comparison of pure prediction
accuracies, we thus in addition compare the selectors on a reduced
test set (see below).
While comparing the different selectors, we make the following
observations:
Selection helps verification Withoutalgorithmselection,we
would be forced to always use the same verifier, i.e., opti-
mally the one chosen by BestSelector. We see that everyother selection strategy is better than BestSelector, on all
selection tasks.
Learning of features improves over manual engineering
Kernel (RPC)and ourrepresentation learnerAttn+RL, thetwo approaches with learning of features, outperform the
selectorswithmanualfeatureengineeringonalltasksbut
SC.OnSC,Attn+RLisbetterthantheotherselectors.This
indicatesthatthereareimportantprogramfeatureswhich
manual feature engineering techniques have not discovered.
Representation learning further improves selection When
comparing just the two selectors without manual feature
engineering, we see that representation learning further im-
provesoverKernel(RPC)(withagainofupto3.39%)with
one slight exception: task Tools.
For the latter observation, we had a closer look at the differencebetween Kernel (RPC) and Attn+RL, and performed the experi-
ment again on a subset of SV18 for which the prediction of Kernel
(RPC) does not timeout, i.e., in which it does not work as a hybrid
technique. The results are given in Table 2. This shows that theprediction accuracy of Attn+RL is actually better or the same as
that of Kernel (RPC) on all selection tasks.
Aspartof answeringRQ1,wealsoperformeda runtimeexper-
iment to decide whether our representation learner can improvethe selection speed . To measure the runtime, we select the ToolsTable 1: Comparison of selectors on SV18
Approach BMC-KI Algorithms SC Tools
BestSelector 91.82 72.40 90.64 84.65
CPA-Selector - - 95.81 -
DT-Selector 93.03 84.50 95.81 89.25
Verifolio 92.40 85.19 96.04 89.76
Kernel (RPC) 94.24 88.14 95.08 94.12
Attn+RL 94.24 91.53 96.55 93.61
Attn+RL+TR 94.85 92.01 96.06 92.58
Table 2: Comparison of selectors on a subset of SV18
Approach BMC-KI Algorithms SC Tools
Kernel (RPC) 97.93 92.48 96.92 94.51
Attn+RL 97.93 93.59 97.48 95.08
task as it provides us with most verifiers to select from. Therefore,
reported results can be seen as an upper bound for all our tasks.During this experiment, we excluded BestSelector, CPA-Selectorand DT-Selector since their runtime for prediction is ‚Äì due to its
simplicity ‚Äì negligible anyway.
Figure 10 gives a quantile plot of the compared techniques. A
point(ùë•,ùë¶)represents that a selection for ùë•programs can be ob-
tained each within a timelimit of ùë¶seconds. Although the runtime
of all selectors starts similar, Kernel (RPC) does not scale well tolarge verification problems. Attn+RL and Verifolio have similarruntimes. A directcomparison of these twois given in Figure 11.
WecanseethatVerifolioisfasteronsmallprogramswhileAttn+RL
becomes faster as soon as the programs get larger.
In summary, representation learning can improve algorithm
selectionanditcanoutperformmanuallyengineeredtechniques
in both selection accuracy and runtime.
5.2 RQ2: Do learned program representations
transfer to new selection tasks?
To answer RQ2, we evaluated the transferability of learned rep-
resentations.Inotherwords,ourobjectiveistofindoutwhether
a representation learned for task ùê¥can be used for another task
ùêµ.Forthispurpose,weusethe representation ofAttn+RLtrained
ontask ùê¥andthenapplylogisticregression(LR)forlearningthe
algorithm selectorfor task ùêµ. Similar to Attn+RL, LR predicts the
probability of a correct verification per verifier while selecting the
approachwiththehighestpredictedprobability.Selectionaccuracy
is again reported in normalized accuracy and given in Table 3. The
entryinrow ùëãandcolumn ùëågivestheaccuracyofpredictionwhen
using the representation learned for ùëãfor the selection task ùëå6.
6Notethattheobtainedresultsformatchingrepresentationandlearningtaskneednot
tobeequaltotheresultsinTable1.Inourpreviousexperiment,thelearningprocedure
optimizes the representation to learn a selection rule. In contrast, LR optimizes its
selection rule to match the given representation.
1024Figure 10: Quantile plot for the different approaches
Figure 11: Runtime comparison of Attn+RL and Verifolio
We make the following observations:
Generality outperforms spezialisation ThetasksBMC-KI
and SC perform specific selections. Algorithms, containing
theverifiersemployedinBMC-KIandSC,canbeseenasa
generalizationofthesetwotasks(whileToolsiscomplemen-
tary to each of the other tasks). We see that using the repre-
sentationlearnedforAlgorithmscanverywellbeusedfor
the more specialized tasks BMC-KI and SC (even improving
overtherepresentationslearnedforthetasksthemselves),
but not the other way round.
Transfer of learned representations is competitive Wecom-
parethe(onaverage)bestrepresentationofAlgorithmswith
our otherbaselines. To easecomparison, row Attn+RL+TR
inTable1repeatsthegrayrowofAlgorithmsinTable3.We
seethatthereareonlysmalldifferencestothebestselectors,
still outperforming manual feature engineering.
Taking our runtime experiments into consideration, we come to
the following conclusion:
Programrepresentationslearnedonageneraltaskwithmultiple
verifiers transfer well to more specialized selection tasks.Table 3: Knowledge transfer between tasks
Train Eval
BMC-KI Algorithms SC Tools
BMC-KI 93.03 85.95 95.81 88.49
Algorithms 94.85 92.01 96.0692.58
SC 92.12 88.86 96.55 92.83
Tools 92.42 89.35 95.32 92.07
5.3 Interpretability
The attention mechanism, as applied by our representation learner,
allows us to reason about the decision process of a learned model.
Therefore, we can not only identify newly discovered features, but
also analyse erroneous predictions. To demonstrate the advantage
ofsuchaninsight,wevisualizetheattentioninFigure12fortwo
cases found in our test set. In each case, we present the function
with the highest attention score while highlighting the most at-
tendedlineinblue.Wehighlightthethreemostattendedtokensin the same line in red. In addition, we provide predictions of all
comparedmethodson thegivenprobleminthe settingoftheSC7
selection task. Analysing the specific cases, we make the following
observations:
New features lead to better decisions Inthecaseof range-
sum10,Attn+RLprovidesacorrectselectionincontrastto
most other methods. For this, the representation learner
had to discover a new feature which supports this decision.
Indeed, looking at the program elements with the highest
attentionscore,weseethatourmethoddiscoveredanewrel-
evantprogramfeaturenamely LongLong-To-Int-Cast.More
precisely, the model bases its decision on the long long
division which is then cast to an integer to fit the returntype. In fact, such a cast can become problematic on 64Bit
systemswhereaconversionfrom64Bit long long toa32Bit
intcanresultintounpredictablevalues.Inthepresenceof
unsafe conversions, a verification technique, like BMC in
this case, is required that can handle integers effectively on
a bit-precise level.
Limitations lead to erroneous predictions WhileAttn+RL
improves the selection performance on average, there exists
a few cases where the method fails. We provide the pro-gramseq-mthreaded as an erroneous case. When we view
theattentionvisualizationinFigure12,itbecomesclearwhy
the prediction fails: the variable argis represented in the
CSTasavariableaccess toavaluewithacustomdatatype.
Therefore, the selector wrongly bases its decision on the
occurrence of a variable with a custom datatype inside a
branch, instead of other program elements. However, _Bool
is a native type introduced in the C99 standard and most
verifiers can handle this type natively. Although Attn+RL
containsthisimprecisiontogeneralizetoarbitraryCstan-
dards,theanalysisofsucherrorcasesenablesthetailoring
7SCischosenasitistheonlyselectiontaskwhereeveryselectorprovidesaprediction.
1025rangesum10 (SC) seq-mthreaded (SC)
Program...
int rangesum ( int x[10])
{
int i;
long long ret;
ret = 0;int cnt = 0;
for (i = 0; i < 10; i++) {
if( i > 10/2){
ret = ret + x[i];cnt = cnt + 1;
}
}
if( cnt !=0)
return ret / cnt ;
else
return 0;
}
......
void assert(_Bool arg )
{
{
if ( ! arg ) {
{
ERROR: __VERIFIER_error();
}
}
}}
Ground Truth BMC-BAM-PA VA-BAM-KI, CPA-Seq
CPA-Selector VA-BAM-KI CPA-Seq
DT-Selector CPA-Seq CPA-Seq
Verifolio BMC-BAM-PA CPA-Seq
Kernel (RPC) CPA-Seq CPA-Seq
Attn+RL BMC-BAM-PA BMC-BAM-PA
Figure 12: Example for predictions of different selectors
taken from the test set
of the selector to specific selection tasks. In contrast, ker-
nel methods like Verifolio and Kernel (RPC) do not provide
such an insight, for it remains unclear why they provide the
wrong selection on the rangesum10 task.
6 RELATED WORK
In this work, we propose to learn program representations in order
to improve algorithm selection for software verification. We dis-cusshowourapproachrelates toprevious workin areassuch asalgorithm selection for software verification and representation
learning for programs.
AlgorithmSelection. Theautomaticselectionofalgorithmshas
a long successful history in many research areas including SATsolving [
67], constraint satisfaction programs [ 45] and combina-
torial search problems [ 40]. However, its potential for software
verification was only recently discovered with the development
ofmanually engineered [1,14,18] andmachine learning based se-
lectors [22,24,25,57,63]. Manually engineered techniques are
designed for a specific selection task at hand. Beyer et al. [ 14]p r o -
posedafixedsetofrulesforselectingapromisingverifiercombina-tion.Afzaletal.[
1]adaptedtheideafortheproprietaryverification
tool VeriAbs, while Chen et al. [ 18] employ specific rules to de-
cide between two implemented verification algorithms. Extending
these approaches to new selection tasks would require a complete
redesign.Incontrast,ourproposedrepresentationlearnercanbe
applied to a variety of selection tasks without modification.
Machinelearningbasedtechniquescanadapttoagivenselec-
tion problem by synthesizing a decision model from data. Machine
learnerlikeMUX[ 63]andVerifolio[ 25]extractafixedsetoffea-
tures of an input program, while learning the correlation between
features and verifier performance. In contrast to their work, repre-
sentationlearningdoesnotrequireanexplicitfeatureextractor,but
it learns an appropriate feature representation during training. Re-
cently,Czechetal.[ 22]decidedtoleavethefeatureselectiontothe
learningprocess,whichwaslaterextendedbyRichteretal.[ 56].Incontrasttothesemethods,ourincorporatedattentionmechanism
enables us to view program fragments that are most relevant for
the model decision. This does not only increase the interpretability
of representation learning but also lets us validate the decisions of
our approach.Finally,there existsautomatic selectiontechniques
[28, 30, 38, 47, 61] which do not consider the input program at all.
ProgramRepresentations. Theideaofcombiningprogrammodels
and representation learning is widely adopted with applicationson sequential models [
4,10,23,27,29,52], ASTs [6,7,34,46], de-
pendencegraphs [3,12] andcombinations thereof[66,68]. Inthis
section, we give a brief overview over two existing techniques that
are mostly related to our approach by targeting the transferability
of code representations. Code2Vec [ 7] also bases its representation
on information contained in an AST. The approach aims to predict
method names. In the process, Code2Vec samples a fixed limitednumber of paths. A neural network learns the representation of
pathsandtheiraggregationtoaprogramrepresentation.Theag-
gregationemploysasimilarattentionmechanism.However,dueto random sampling of a restricted number of paths, Code2Vec
might easily miss crucial information contained in the AST. In con-
trast, our approachlearns a deterministic program representation
considering all information necessary for algorithm selection. Re-
cently,CodeBert[ 27]wasproposedtolearnatransferableprogram
representation based on Transformers. The technique was trained
to model the relationship between code and its code documenta-
tion. Afterwards, they tested the representation for also predicting
method names. CodeBert is in general more expressive than our
approach, but very resource inefficient. CodeBert was pre-trained
on16highperformanceGPUswhileonlyconsideringsequences
of 512 tokens. Even after employing the learned representation,thesequencelengthwastruncatedat200tokensduetoresourceconstraints. In contrast, our approach can be trained on a singleGPU with examples of more than 1M tokens and it outperformsprevious selectors in runtime on a consumer-level system withonly two cores. Overall, we found that virtually all existing ap-
proachesonlytargetsmallprogramsnippetsinthecontextoflarge
datasets. This observation has (partially) motivated our work on
algorithmselectiononsoftwareverification,adomaininwhichwe
can demonstrate that our representation learning works well with
relatively small datasets and large programs.
7 CONCLUSION
In this paper, we showed that representation learning can improve
algorithm selection for software verification. Our representationlearner learns an aggregation of AST nodes into programmingconcepts. For this purpose, we proposed a hierarchical program
model, while adapting the Transformer architecture to hierarchicallearning.Theevaluationshowsthatmanuallydevelopedtechniquescanbereplacedbyarepresentationlearnerimprovingtheefficiencyandeffectivenessofaverificationsystem.Furthermore,thelearned
representation can be transferred to new selection tasks, givingsoftware engineers easy access to high-performance algorithm
selection in the context of their own verification tool.
In the future, we intend to apply our hierarchical representation
learner to other classification tasks for source code.
1026REFERENCES
[1]Mohammad Afzal, Supratik Chakraborty, Avriti Chauhan, Bharti Chimdyalwar,
PriyankaDarke,AshutoshGupta,ShrawanKumar,CharlesBabu,DivyeshUn-
adkat, and R Venkatesh. 2020. VeriAbs: Verification by Abstraction and Test
Generation (Competition Contribution). In International Conference on Tools and
Algorithms for the Construction and Analysis of Systems. Springer, 383‚Äì387.
[2]Takuya Akiba, Shotaro Sano, Toshihiko Yanase, Takeru Ohta, and Masanori
Koyama.2019. Optuna:ANext-generationHyperparameterOptimizationFrame-
work.InProceedingsofthe25rdACMSIGKDDInternationalConferenceonKnowl-
edge Discovery and Data Mining.
[3]MiltiadisAllamanis,MarcBrockschmidt,andMahmoudKhademi.2017. Learning
to represent programs with graphs. arXiv preprint arXiv:1711.00740 (2017).
[4]Miltiadis Allamanis, Hao Peng, and Charles Sutton. 2016. A convolutional at-
tention network for extreme summarization of source code. In International
conference on machine learning. 2091‚Äì2100.
[5]Uri Alon, Shaked Brody, Omer Levy, and Eran Yahav. 2018. code2seq: Gen-erating sequences from structured representations of code. arXiv preprint
arXiv:1808.01400 (2018).
[6]Uri Alon,Meital Zilberstein, OmerLevy, and EranYahav.2018. Ageneral path-basedrepresentationforpredictingprogramproperties. ACMSIGPLANNotices
53, 4 (2018), 404‚Äì419.
[7]Uri Alon, Meital Zilberstein, Omer Levy, and Eran Yahav. 2019. code2vec: Learn-
ing distributed representations of code. Proceedings of the ACM on Programming
Languages 3, POPL (2019), 1‚Äì29.
[8]Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. 2016. Layer normaliza-
tion.arXiv preprint arXiv:1607.06450 (2016).
[9]Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural ma-chine translation by jointly learning to align and translate. arXiv preprint
arXiv:1409.0473 (2014).
[10]RohanBavishi,MichaelPradel,andKoushikSen.2018. Context2Name:Adeep
learning-based approach to infer natural variable names from usage contexts.
arXiv preprint arXiv:1809.05193 (2018).
[11]Ira D Baxter, Andrew Yahin, Leonardo Moura, Marcelo Sant‚ÄôAnna, and Lorraine
Bier.1998. Clonedetectionusingabstractsyntaxtrees.In Proceedings.Interna-
tional Conference on Software Maintenance (Cat. No. 98CB36272). IEEE, 368‚Äì377.
[12]Tal Ben-Nun, Alice Shoshana Jakobovits, and Torsten Hoefler. 2018. Neural code
comprehension: A learnable representation of code semantics. In Advances in
Neural Information Processing Systems. 3585‚Äì3597.
[13]DirkBeyer.2017. SoftwareVerificationwithValidationofResults-(ReportonSV-COMP2017).In ToolsandAlgorithmsfortheConstructionandAnalysisofSystems
- 23rd International Conference, TACAS 2017, Held as Part of the European Joint
ConferencesonTheoryandPracticeofSoftware,ETAPS2017,Uppsala,Sweden,April
22-29,2017,Proceedings,PartII (LectureNotesinComputerScience) ,AxelLegay
and Tiziana Margaria (Eds.), Vol. 10206. 331‚Äì349. https://doi.org/10.1007/978-3-
662-54580-5_20
[14]DirkBeyerandMatthiasDangl.2018. StrategySelectionforSoftwareVerification
Based on Boolean Features - A Simple but Effective Approach. In Leveraging
ApplicationsofFormalMethods,VerificationandValidation.Verification-8thInter-
national Symposium,ISoLA 2018, Limassol,Cyprus, November 5-9,2018, Proceed-
ings, Part II (Lecture Notes in Computer Science), Tiziana Margaria and Bernhard
Steffen(Eds.),Vol.11245.Springer,144‚Äì159. https://doi.org/10.1007/978-3-030-
03421-4_11
[15]Dirk Beyer, Matthias Dangl, and Philipp Wendler. 2015. Boosting k-induction
withcontinuously-refinedinvariants.In InternationalConferenceonComputer
Aided Verification. Springer, 622‚Äì640.
[16]DirkBeyerandM.ErkanKeremoglu.2011. CPAchecker:AToolforConfigurable
Software Verification. In Computer Aided Verification - 23rd International Confer-
ence,CAV2011,Snowbird,UT,USA,July14-20,2011.Proceedings (LectureNotes
in Computer Science), Ganesh Gopalakrishnan and Shaz Qadeer (Eds.), Vol. 6806.
Springer, 184‚Äì190. https://doi.org/10.1007/978-3-642-22110-1_16
[17]DirkBeyer,MErkanKeremoglu,andPhilippWendler.2010. Predicateabstraction
with adjustable-block encoding. In Formal Methods in Computer Aided Design.
IEEE, 189‚Äì197.
[18]G. Chen, D. Wang, T. Li, C. Zhang, M. Gu, and J. Sun. 2018. Scalable Verifica-tionFrameworkforCProgram.In 201825thAsia-PacificSoftwareEngineering
Conference (APSEC). 129‚Äì138.
[19]Rewon Child, Scott Gray, Alec Radford, and Ilya Sutskever. 2019. Generating
longsequenceswithsparsetransformers. arXivpreprintarXiv:1904.10509 (2019).
[20]KevinClark,UrvashiKhandelwal,OmerLevy,andChristopherDManning.2019.
What Does BERT Look At? An Analysis of BERT‚Äôs Attention. arXiv preprint
arXiv:1906.04341 (2019).
[21]Edmund Clarke,Armin Biere,Richard Raimi,and YunshanZhu. 2001. Bounded
model checking using satisfiability solving. Formal methods in system design 19,
1 (2001), 7‚Äì34.
[22]Mike Czech, Eyke H√ºllermeier, Marie-Christine Jakobs, and Heike Wehrheim.2017. Predicting rankings of software verification tools. In Proceedings
of the 3rd ACM SIGSOFT International Workshop on Software Analytics,SWAN@ESEC/SIGSOFT FSE 2017, Paderborn, Germany, September 4, 2017, Olga
BaysalandTimMenzies(Eds.).ACM,23‚Äì26. https://doi.org/10.1145/3121257.
3121262
[23]Hoa Khanh Dam, Truyen Tran, and Trang Pham. 2016. A deep language model
for software code. arXiv preprint arXiv:1608.02715 (2016).
[24]YuliaDemyanova,ThomasPani,HelmutVeith,andFlorianZuleger.2015. Em-
pirical Software Metrics for Benchmarking of Verification Tools. In Computer
AidedVerification-27thInternationalConference,CAV2015,SanFrancisco,CA,
USA, July 18-24, 2015, Proceedings, Part I (Lecture Notes in Computer Science),Daniel Kroening and Corina S. Pasareanu (Eds.), Vol. 9206. Springer, 561‚Äì579.
https://doi.org/10.1007/978-3-319-21690-4_39
[25]YuliaDemyanova,ThomasPani,HelmutVeith,andFlorianZuleger.2017. Empir-
ical software metrics for benchmarking of verification tools. Formal Methods in
SystemDesign 50,2-3(2017),289‚Äì316. https://doi.org/10.1007/s10703-016-0264-5
[26]Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert:
Pre-trainingofdeepbidirectionaltransformersforlanguageunderstanding. arXiv
preprint arXiv:1810.04805 (2018).
[27]Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, MingGong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, et al
.2020. CodeBERT:
APre-TrainedModelforProgrammingandNaturalLanguages. arXivpreprint
arXiv:2002.08155 (2020).
[28]Jianmei Guo, Dingyu Yang, Norbert Siegmund, Sven Apel, Atrisha Sarkar, Pavel
Valov, Krzysztof Czarnecki, Andrzej Wasowski, and Huiqun Yu. 2018. Data-
efficient performance learning for configurable systems. Empirical Software
Engineering 23, 3 (2018), 1826‚Äì1867.
[29]RahulGupta,SohamPal,AdityaKanade,andShirishShevade.2017. Deepfix:Fix-
ing common c language errors by deep learning. In Thirty-First AAAI Conference
on Artificial Intelligence.
[30]Huong Ha and Hongyu Zhang. 2019. DeepPerf: performance prediction for
configurable software with deep sparse neural network. In 2019 IEEE/ACM 41st
International Conference on Software Engineering (ICSE). IEEE, 1095‚Äì1106.
[31]Vincent J. Hellendoorn, Charles Sutton, Rishabh Singh, Petros Maniatis, andDavid Bieber. 2020. Global Relational Models of Source Code. In International
Conference on Learning Representations. https://openreview.net/forum?id=
B1lnbRNtwr
[32]Dan Hendrycks and Kevin Gimpel. 2016. Gaussian error linear units (gelus).
arXiv preprint arXiv:1606.08415 (2016).
[33]Xing Hu, Ge Li, Xin Xia, David Lo, Shuai Lu, and Zhi Jin. 2018. SummarizingSource Code with Transferred API Knowledge. In Proceedings of the Twenty-
SeventhInternationalJointConferenceonArtificialIntelligence,IJCAI2018,July
13-19,2018,Stockholm,Sweden,J√©r√¥meLang(Ed.).ijcai.org,2269‚Äì2275. https:
//doi.org/10.24963/ijcai.2018/314
[34]Xing Hu, Yuhan Wei, Ge Li, and Zhi Jin. 2017. CodeSum: Translate Program
Language to Natural Language. ArXivabs/1708.01837 (2017).
[35]Cheng-ZhiAnnaHuang,AshishVaswani,JakobUszkoreit,NoamShazeer,IanSi-mon,CurtisHawthorne,AndrewMDai,MatthewDHoffman,MonicaDinculescu,andDouglasEck.2018.Musictransformer. arXivpreprintarXiv:1809.04281 (2018).
[36]E. H√ºllermeier, J. F√ºrnkranz, W. Cheng, and K. Brinker. 2008. Label Ranking by
Learning Pairwise Preferences. Artificial Intelligence 172 (2008), 1897‚Äì1917.
[37]Armand Joulin, Laurens van der Maaten, Allan Jabri, and Nicolas Vasilache.
2016. Learningvisualfeaturesfromlargeweaklysuperviseddata.In European
Conference on Computer Vision. Springer, 67‚Äì84.
[38]Christian Kaltenecker, Alexander Grebhahn, Norbert Siegmund, and Sven Apel.
2020. TheInterplayofSamplingandMachineLearningforSoftwarePerformance
Prediction. IEEE Software (2020).
[39]Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic opti-
mization. arXiv preprint arXiv:1412.6980 (2014).
[40]LarsKotthoff.2016. Algorithmselectionforcombinatorialsearchproblems:A
survey. In Data Mining and Constraint Programming. Springer, 149‚Äì190.
[41]WenchaoLi,HassenSaidi,HuascarSanchez,MartinSch√§f,andPascalSchweitzer.
2016. Detecting Similar Programs via The Weisfeiler-Leman Graph Kernel. In
ICSR (LNCS), Vol. 9679. Springer, 315‚Äì330.
[42]Minh-Thang Luong, Hieu Pham, and Christopher D Manning. 2015. Effec-tive approaches to attention-based neural machine translation. arXiv preprint
arXiv:1508.04025 (2015).
[43]Dhruv Mahajan, Ross Girshick, Vignesh Ramanathan, Kaiming He, Manohar
Paluri, Yixuan Li, Ashwin Bharambe, and Laurens van der Maaten. 2018. Explor-
ingthelimitsofweaklysupervisedpretraining.In ProceedingsoftheEuropean
Conference on Computer Vision (ECCV). 181‚Äì196.
[44]≈Åukasz Maziarka, Tomasz Danel, S≈Çawomir Mucha, Krzysztof Rataj, Jacek Tabor,
and Stanis≈Çaw Jastrzƒôbski. 2020. Molecule Attention Transformer. arXiv preprint
arXiv:2002.08264 (2020).
[45]StevenMinton.1996. Automaticallyconfiguringconstraintsatisfactionprograms:
A case study. Constraints 1, 1-2 (1996), 7‚Äì43.
[46]LiliMou,GeLi,ZhiJin,LuZhang,andTaoWang.2014. TBCNN:Atree-based
convolutional neural network for programming language processing. arXiv
preprint arXiv:1409.5718 (2014).
1027[47]Vivek Nair, Tim Menzies, Norbert Siegmund, and Sven Apel. 2017. Using bad
learnerstofindgoodconfigurations.In Proceedingsofthe201711thJointMeeting
on Foundations of Software Engineering, ESEC/FSE 2017, Paderborn, Germany,
September4-8,2017,EricBodden,WilhelmSch√§fer,ArievanDeursen,andAndrea
Zisman (Eds.). ACM, 257‚Äì267. https://doi.org/10.1145/3106237.3106238
[48]Toan Q Nguyen and Julian Salazar. 2019. Transformers without tears: Improving
the normalization of self-attention. arXiv preprint arXiv:1910.05895 (2019).
[49]Niki Parmar, Ashish Vaswani, Jakob Uszkoreit, ≈Åukasz Kaiser, Noam Shazeer,
Alexander Ku, and Dustin Tran. 2018. Image transformer. arXiv preprint
arXiv:1802.05751 (2018).
[50]FelixPauck,EricBodden,andHeikeWehrheim.2018. DoAndroidtaintanaly-
sistoolskeeptheirpromises?.In Proceedingsofthe2018ACMJointMeetingon
European Software Engineering Conference and Symposium on the Foundations of
Software Engineering, ESEC/SIGSOFT FSE 2018, Lake Buena Vista, FL, USA, No-
vember04-09,2018,GaryT.Leavens,AlessandroGarcia,andCorinaS.Pasareanu
(Eds.). ACM, 331‚Äì341. https://doi.org/10.1145/3236024.3236029
[51]John Platt. 1999. Probabilistic outputs for support vector machines and compar-
isons to regularized likelihood methods. In Advances in Large Margin Classifiers.
MIT Press, 6‚Äì74.
[52]Michael Pradel and Koushik Sen. 2018. DeepBugs: A learning approach to name-
based bug detection. Proceedings of the ACM on Programming Languages 2,
OOPSLA (2018), 1‚Äì25.
[53]Lina Qiu, Yingying Wang, and Julia Rubin. 2018. Analyzing the analyzers: Flow-
Droid/IccTA,AmanDroid,andDroidSafe.In Proceedingsofthe27thACMSIGSOFT
InternationalSymposiumonSoftwareTestingandAnalysis,ISSTA2018,Amster-
dam,TheNetherlands,July16-21,2018,FrankTipandEricBodden(Eds.).ACM,
176‚Äì186. https://doi.org/10.1145/3213846.3213873
[54]Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar. 2019.
Doimagenet classifiersgeneralizetoimagenet? arXivpreprint arXiv:1902.10811
(2019).
[55]JohnRice.1976. TheAlgorithmSelectionProblem. AdvancesinComputers 15
(1976), 65‚Äì118.
[56]Cedric Richter, Eyke H√ºllermeier, Marie-Christine Jakobs, and Heike Wehrheim.
2020. Algorithmselectionforsoftwarevalidationbasedongraphkernels. Autom.
Softw. Eng. 27, 1 (2020), 153‚Äì186. https://doi.org/10.1007/s10515-020-00270-x
[57]CedricRichterandHeikeWehrheim.2019. PeSCo:PredictingSequentialCom-
binations of Verifiers - (Competition Contribution). In Tools and Algorithms
fortheConstructionandAnalysisofSystems-25YearsofTACAS:TOOLympics,Held as Part of ETAPS 2019, Prague, Czech Republic, April 6-11, 2019, Proceed-ings, Part III (Lecture Notes in Computer Science), Dirk Beyer, Marieke Huis-
man, Fabrice Kordon, and Bernhard Steffen (Eds.), Vol. 11429. Springer, 229‚Äì233.
https://doi.org/10.1007/978-3-030-17502-3_19
[58]SRasoulSafavianandDavidLandgrebe.1991. Asurveyofdecisiontreeclassifier
methodology. IEEE transactions on systems, man, and cybernetics 21, 3 (1991),
660‚Äì674.
[59]B.Sch√∂lkopfandAJ.Smola.2001. LearningwithKernels:SupportVectorMachines,
Regularization, Optimization, and Beyond. MIT Press.
[60]Bobak Shahriari, Kevin Swersky, Ziyu Wang, Ryan P Adams, and Nando De Fre-
itas. 2015. Taking the human out of the loop: A review of Bayesian optimization.
Proc. IEEE 104, 1 (2015), 148‚Äì175.
[61]NorbertSiegmund,AlexanderGrebhahn,SvenApel,andChristianK√§stner.2015.
Performance-influence models for highly configurable systems. In Proceedings of
the 2015 10th Joint Meeting on Foundations of Software Engineering. 284‚Äì294.
[62]Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan
Salakhutdinov.2014. Dropout:asimplewaytopreventneuralnetworksfrom
overfitting. The journal of machine learning research 15, 1 (2014), 1929‚Äì1958.
[63]Varun Tulsian, Aditya Kanade, Rahul Kumar, Akash Lal, and Aditya V. Nori.
2014. MUX:algorithmselectionforsoftwaremodelcheckers.In 11thWorking
Conference on Mining Software Repositories, MSR 2014, Proceedings, May 31 - June
1,2014,Hyderabad,India,PremkumarT.Devanbu,SungKim,andMartinPinzger
(Eds.). ACM, 132‚Äì141. https://doi.org/10.1145/2597073.2597080
[64]Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, ≈Åukasz Kaiser, and Illia Polosukhin. 2017. Attention is all
y o un eed .I nAdvances in neural information processing systems. 5998‚Äì6008.
[65]Qiang Wang,Bei Li, Tong Xiao,Jingbo Zhu, ChangliangLi, Derek FWong,and
LidiaSChao.2019. Learningdeeptransformermodelsformachinetranslation.
arXiv preprint arXiv:1906.01787 (2019).
[66]Wenhan Wang, Ge Li, Bo Ma, Xin Xia, and Zhi Jin. 2020. Detecting Code Clones
with Graph Neural Network and Flow-Augmented Abstract Syntax Tree. In 2020
IEEE 27th International Conference on Software Analysis, Evolution and Reengi-
neering (SANER). IEEE, 261‚Äì271.
[67]Lin Xu, Frank Hutter, Holger H Hoos, and Kevin Leyton-Brown. 2008. SATzilla:
portfolio-based algorithm selection for SAT. Journal of artificial intelligence
research32 (2008), 565‚Äì606.
[68]JianZhang,XuWang,HongyuZhang,HailongSun,KaixuanWang,andXudong
Liu.2019. Anovelneuralsourcecoderepresentationbasedonabstractsyntax
tree. In2019 IEEE/ACM 41st International Conference on Software Engineering
(ICSE). IEEE, 783‚Äì794.
1028