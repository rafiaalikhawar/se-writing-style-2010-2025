A Behavioral NotionofRobustnessforSoftwareSystems
Changjian
Zhang
School ofComputer Science
Carnegie Mellon University
Pittsburgh,USA
changjiz@andrew.cmu.eduDavidGarlan
School ofComputer Science
Carnegie Mellon University
Pittsburgh,USA
garlan@cs.cmu.eduEunsuk Kang
School ofComputer Science
Carnegie Mellon University
Pittsburgh,USA
eskang@cmu.edu
ABSTRACT
Software systems are designed and implemented with assumptions
about the environment. However, once the system is deployed,
the actual environment may deviate from its expected behavior,
possiblyunderminingdesiredpropertiesofthesystem.Toenable
systematic design of systems that are robust against potential envi-
ronmental deviations, we propose a rigorous notion of robustness
forsoftwaresystems.Inparticular,therobustnessofasystemisde-
fined as the largest set of deviating environmental behaviors under
whichthesystemiscapableofguaranteeingadesiredproperty.We
describeanewsetofdesignanalysisproblemsbasedonournotion
of robustness, and a technique for automatically computing robust-
ness of a system given its behavior description. We demonstrate
potential applications of our robustness notion on two case studies
involving network protocols andsafety-critical interfaces.
CCS CONCEPTS
â€¢Softwareanditsengineering â†’Designingsoftware ;Formal
softwareverification ;Softwaresystemmodels ;Softwarereliability ;
Softwaresafety .
KEYWORDS
softwarerobustness,formalmethods,labelledtransitionsystems,
compositional reasoning
ACM ReferenceFormat:
Changjian Zhang, David Garlan, and Eunsuk Kang. 2020. A Behavioral
Notion of Robustness for Software Systems. In Proceedings of the 28th ACM
JointEuropeanSoftwareEngineeringConferenceandSymposiumontheFoun-
dationsofSoftwareEngineering(ESEC/FSEâ€™20),November8â€“13,2020,Virtual
Event, USA. ACM, New York, NY, USA, 12pages.https://doi.org/10.1145/
3368089.3409753
1 INTRODUCTION
Softwaresystemsaredesigned,implemented,andvalidatedwith
certainassumptionsabouttheenvironmentinwhichtheyarede-
ployed.Theseassumptionsinclude,forexample,theexpectedbe-
havior of a human user, the reliability of the underlying communi-
cationnetwork,orthecapabilityofanattackerthatmayattempt
to compromisethe security of thesystem.
ESEC/FSE â€™20, November 8â€“13, 2020, Virtual Event, USA
Â© 2020 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-7043-1/20/11.
https://doi.org/10.1145/3368089.3409753Oncethesystemisdeployed,however,theactualenvironment
may deviate from its expected behavior, either deliberately or erro-
neously due to a change in the operating conditions or a fault in
one of its parts. For instance, a user interacting with a computer
interface may inadvertently perform a sequence of actions in an
incorrect order; a network may experience a disruption and fail
todeliveramessageintime;oranattackermayevolveovertime
and obtain a wider range of exploits to compromise the system.
In these cases, the system may no longer be able to satisfy those
requirementsthat reliedon the original assumptions.
In well-established engineering disciplines such as aerospace,
civil,andmanufacturing,deviationsoftheenvironmentfromthe
norm are routinely and explicitly analyzed, and systems are de-
signed to be robustagainstthesepotentialdeviations [ 35]. In soft-
ware engineering, however, a standard notion of robustness seems
tobemissing,althoughasimilarconcepthasbeenstudiedincer-
tain domains. For example, in distributed systems and networks,
thenotionoffaulttolerancehasbeenlongstudied(e.g.,[ 18,30]),
butdoesnotgeneralizetoothertypesofsoftwaresystemswhere
environmental deviations are not limited to network failures or
delays.Incontrolengineering,asystemissaidtoberobustifsmall
deviations on an input result only in small deviations on an out-
put[43].Thisnotionofrobustness,however,isintendedforsystems
whose behaviors are modeled using continuous dynamics, and not
particularly suitablefordiscretebehaviors observedin software.
In this paper, we propose an approach for designing robust sys-
temsbased ona mathematically rigorous notionofrobustnessfor
software. In particular, we say that a system is robustwith respect
to apropertyand a particular set of environmental deviations if the
systemcontinuestosatisfythepropertyeveniftheenvironment
exhibits those deviations. Furthermore, we define the robustness of
asoftwaresystemasthesetofalldeviationsunderwhichasystem
continuestosatisfythatproperty.Basedonthesedefinitions,we
propose an analysis technique for automatically computing the
robustness of a systemgiven itsbehavioral description.
We argue that robustness itself is a type of software quality that
canberigorouslyanalyzedand designedfor.Thegoalofatypical
verification method is to check the following: Given system ğ‘€, en-
vironment ğ¸, andproperty ğ‘ƒ, does the system satisfythe property
under this environment (i.e., ğ‘€âˆ¥ğ¸|=ğ‘ƒ)? Our notion of robustness
enablesformulationofnewtypesofanalysesbeyondthis.Forin-
stance,wecouldaskwhetherasystemisrobustagainstaparticular
setofenvironmentaldeviations;giventwoalternativesystemde-
signs (both satisfying ğ‘ƒ), we could rigorously compare them by
generatingdeviationsagainstwhichonedesignisrobustbutthe
other isnot, and; givenmultiplesystemproperties(some ofthem
more critical than others), we could compare the environmental
deviationsunderwhich the systemcanguaranteethem.
1This work is licensed under a Creative Commons Attribution International 4.0 License.
ESEC/FSEâ€™20, November 8â€“13,2020, Virtual Event, USA Changjian Zhang, DavidGarlan,andEunsukKang
Weenvisionthatournotionofrobustnesscanbeusedtosupport
design activities across various domains. In this paper, we demon-
strate the application of our approach in two different domains:
(1) human-machine interactions, where we adopt the well-studied
models of human errors from the industrial engineering and hu-
manfactorsresearch[ 7,38]andshowhowourmethodcanbeused
to rigorously evaluate the robustness of safety-critical interfaces
against such errors, and (2) computer networks, where our method
is used to rigorously compare the robustness of network protocols
againstdifferent types of failures in theunderlyingnetwork.
The contributionsof thepaper areasfollows:
â€¢A systematic approach to designing systems that are robust
againstpotential environmental deviations(Section 2),
â€¢A formal notion of robustness for software systems (Sec-
tion3)andasetofanalysisproblemsthatevaluatesystem
designs withrespectto their robustness (Section 4),
â€¢Algorithmic techniques for automatically computing the ro-
bustnessofasystemandgeneratingsuccinctrepresentations
of robustness (Section 5), and,
â€¢A prototype implementation of the robustness analysis and
demonstrate our approach on two case studies involving
human-machineinterfacesandnetworkprotocols(Section 7).
2 MOTIVATING EXAMPLE
This section illustrates how our proposed notion of robustness
may be used to support a new type of design analysis and aid a
systematic development of systems that are robust against failures
orchanges in theenvironment.
(1)Analysis under thenormativeenvironment. As a motivat-
ing example, consider the design of a radiation therapy system
similar to the well-known Therac-25 machine [ 32]. State machines
in Figure 1describe three components in the system, including the
treatmentinterface (ğ‘€ğ¼),whichallowstheoperatortocontrolthe
device by performing interface actions (e.g., Xfor setting the beam
modetoX-ray),the beamsetter (ğ‘€ğµ),whichdeterminesthecurrent
modeofradiationtherapy(electronbeamandX-ray,whichdelivers
roughly 100 times higher level of current than the former), and
spreader(ğ‘€ğ‘†),whichisputinplaceduringtheX-raymodeinorder
to attenuate the effect of the high-power X-ray beam and limit
possibleoverdose.Theoverallbehaviorofthetherapysystem,as
modeledhere,iscapturedbythecompositionofthestatemachines,
ğ‘€=(ğ‘€ğ¼âˆ¥ğ‘€ğµâˆ¥ğ‘€ğ‘†).
The radiation therapy system is associated with a number of
safetyrequirements,oneofwhichstatesthatthespreadercanbe
removed only when the beam is delivered in the electron mode.
This requirement may formally be stated as the following property
in linear-temporallogic (LTL)[ 36]:
G(BeamDelivered âˆ§OutOfPlace â‡’EbeamMode )
whereBeamDelivered isapropositionthatholdswhen ğ‘€ğ¼enters
thestatewiththesamename(andsimilarlyforotherpropositions).
During a normal treatment process, a therapist is expected to
perform the following tasks: Select the correct therapy mode for
thecurrentpatientbypressingeither XorE,confirmthetreatment
databypressing Enterandthenfinallyinitiatethebeamdeliverytothe patient by pressing B. This normative behavior of the operator
ismodeledasstate machine ğ¸in Figure 1.
Supposethedesignerofthemachinewishestocheckwhether
the therapy system satisfies its safety requirements, assuming that
an operatorcarriesoutthe tasksas expected.Moregenerally,this
canbeformulatedasthefollowingcommon typeof analysis task:
Doesthesystem,undertheenvironmentthatbehaves
asexpected,satisfy a desiredproperty?
To performthis task,one mayapplyaverificationtechniquesuch
as model checking [ 14] to check whether the composition of the
machineandtheenvironmentsatisfiesadesiredproperty(however,
otheranalysistechniquesmaybejustapplicableaslongastheycan
be used to check ğ‘€âˆ¥ğ¸|=ğ‘ƒ). Performing this analysis confirms that
the system indeed satisfies the safety property that the spreader is
alwaysin-place duringthe X-raymode.
(2)Analysisofundesirableenvironmentaldeviations. Incom-
plexsystems,theenvironmentmaynotalwaysbehaveasexpected,
andpossiblyundermineassumptionsthatthesystemreliesonto
fulfill its requirements. For instance, in interactive systems, human
operators are far from perfect, and inadvertently make mistakes
fromtimetotimewhileperformingatask(e.g.,performasequence
of actions in a wrong order) [ 38]. In the context of a safety-critical
systemsuchasmedicaldevices,someoftheseoperatorerrors,if
permittedby theinterface, mayresult in a safety violation.
To discover these potential environmental deviations, the de-
signer decidesto perform the followinganalysis task:
What are possible ways in which the environment
maydeviatefromitsexpectedbehaviorandcausea
violation of theproperty?
Given the therapy system models ( ğ‘€andğ¸) and property ğ‘ƒ, the
designercanuseanexistinganalysistool(e.g.,LTSA[ 33])tocheck
whetherğ‘€|=ğ‘ƒ.Theanalyzermayreturnacounterexampletrace
that demonstrates how the operator could deviate from its norma-
tivebehavior(ascapturedby ğ¸)andcausea violation of ğ‘ƒ.
Suppose that one such trace contains the following sequence of
operatoractions: âŸ¨X,Up,E,Enter,BâŸ©.Thistracedepictsascenario
in which the operator accidentally selects the X-ray mode, corrects
themistakebypressingupandselectingtheelectronbeammode,
and then carrying on the rest of the treatment as intended (by con-
firmingthemode and firing thebeam).This sequence of operator
actions, however, may lead to a violation of the safety property
ğ‘ƒin the following way: When the operator presses B, the beam
setter may still be in the process of mode switch (i.e., state Switch-
ToBeam),causingthebeamtobedeliveredintheX-raymodewhile
the spreader is out of place. This scenario corresponds to one type
of failure that caused fatal overdoses in the Therac-25 system [ 32].
(3)Robustness analysis. Havingdiscoveredhowtheoperatorâ€™s
mistakecouldleadtoasafetyviolation,thedesignermodifiesthe
treatmentinterfacetoimproveitsrobustnessagainstthepossible
error. In this redesign, shown in Figure 1(e), the operator can press
Bto fire the beam only after the mode switch has been carried out
by the beam setter. As the next step, the designer wishes to ensure
that the system, as re-designed, is robust against the operatorâ€™s
mistake(i.e,itcontinuestosatisfythesafetypropertyevenunder
themisbehavingoperator).
2ABehavioralNotion ofRobustnessfor Software Systems ESEC/FSEâ€™20, November 8â€“13,2020, Virtual Event, USA
InPlaceOutOf
PlaceE
XEditing
Conï¬rm
XrayConï¬rm
Ebeam
Fire
XrayFire
Ebeam
Beam
DeliveredBBEnter EnterE X
UpUp
Up Up
EnterNotSet
Xray
ModeEbeam
Mode
SwitchTo
EbeamSwitchTo
XrayX E
SetSet
(b) Beam Setter (MB)
(a) Treatment Interface (MI) (c) Spreader (MS)Select
Mode
Conï¬rm
Mode
FireBeam
Task
CompleteX E
Enter
B
(d) Operator Task (E)X EXE
X EEditing
Conï¬rm
XrayConï¬rm
Ebeam
Fire
XrayFire
Ebeam
Beam
ReadySet SetEnter EnterE X
UpUp
Up Up
B
(e) Redesigned Interface (M'I)Beam
DeliveredEnterB B
Figure1: Labelled transitionsystemsfor aradiationtherapy system.
The designer couldcheck ğ‘€â€²|=ğ‘ƒwhereğ‘€â€²isthe redesign, if
noerrorsreturned,itmeansthat ğ‘€â€²isrobustagainstthemistake
and alsoğ‘€â€²can work under any environment. However, itâ€™s not
alwaysthecase.Morelikely,theanalyzermayreturnanothertrace
representing a new mistake, and it does not necessarily mean that
thesystemisrobustagainsttheoldone.
Instead,thedesignercanuseourtooltoperformthefollowing
robustness analysis task:
What are possible environmental deviations under
which the new design satisfies the property but the
olddesigndoes not?
Given the original system model ğ‘€, modified system model ğ‘€â€²,
normativeenvironment ğ¸,andproperty ğ‘ƒ,ouranalysisreturnsa
set of traces (expressed over environmental actions), each trace
describes a scenario where system ğ‘€â€²satisfies the property but ğ‘€
does not. For example, one of the traces is the sequence of oper-
ator actions discussed above: âŸ¨X,Up,E,Enter,BâŸ©, confirming that
the redesign has correctly addressed the risk of a possible safety
violation dueto this particular typeof mistake by theoperator.
The analysis steps (2) and (3) may be repeated to identify poten-
tialsafetyviolationsduetoothertypesofoperatormistakesand
furtherimprovetherobustness of thesystem.
3 ROBUSTNESS NOTION
This section describes the underlying formalism used to model
systems and environments (namely, labelled transition systems).
Wethenformallydefinethenotionofrobustnessandintroducea
new set of analysis problems that leverage this notion to reason
about therobustness of systems.
3.1 Preliminaries
In this work, we use labelled transition systems to model the be-
haviors of machines andenvironment.
3.1.1 Labelled Transition System. Alabelled transition system ğ‘‡is
a tupleâŸ¨ğ‘†,ğ›¼ğ‘‡,ğ‘…,ğ‘  0âŸ©whereğ‘†is a set of states, ğ›¼ğ‘‡is a set of actions
called the alphabet ofğ‘‡,ğ‘…âŠ†ğ‘†Ã—ğ›¼ğ‘‡âˆª {ğœ} Ã—ğ‘†defines the state
transitions(where ğœisadesignatedactionthatisunobservableto
the systemâ€™s environment), and ğ‘ 0âˆˆğ‘†is the initial state. An LTS isnon-deterministic ifâˆƒ(ğ‘ ,ğ‘,ğ‘ â€²),(ğ‘ ,ğ‘,ğ‘ â€²â€²) âˆˆğ‘…:ğ‘ â€²â‰ ğ‘ â€²â€²;otherwise,it
isdeterministic .
A traceğœâˆˆğ›¼ğ‘‡âˆ—of an LTS ğ‘‡is a sequence of observable actions
from the initial state. Then, the behavior of ğ‘‡is the set of all the
traces generatedby ğ‘‡, denoted ğ‘ğ‘’â„(ğ‘‡).
3.1.2 Operators. ForanLTS ğ‘‡=âŸ¨ğ‘†,ğ›¼ğ‘‡,ğ‘…,ğ‘  0âŸ©,theprojection opera-
torâ†¾isusedtoexposeonlysomesubsetofthealphabetof ğ‘‡.Given
ğ‘‡â†¾ğ´=âŸ¨ğ‘†,ğ›¼ğ‘‡âˆ©ğ´,ğ‘…â€²,ğ‘ 0âŸ©whereforany (ğ‘ ,ğ‘,ğ‘ â€²) âˆˆğ‘…,ifğ‘âˆ‰ğ´,then
(ğ‘ ,ğœ,ğ‘ â€²) âˆˆğ‘…â€², i.e.,ğ‘will behiddenby ğœ;otherwise, (ğ‘ ,ğ‘,ğ‘ â€²) âˆˆğ‘…â€².
Theâ†¾operator can also be applied to traces. We use ğœâ†¾ğ´to
denotethetracethat resultsfromremovingalltheoccurrencesof
actionsğ‘âˆ‰ğ´fromğœ.
Theparallel composition ||is a commutative and associative
operator which combines two LTSs by synchronizing their com-
mon actions and interleaving the remaining actions. Let ğ‘‡1=
âŸ¨ğ‘†1,ğ›¼ğ‘‡1,ğ‘…1,ğ‘ 1
0âŸ©andğ‘‡2=âŸ¨ğ‘†2,ğ›¼ğ‘‡2,ğ‘…2,ğ‘ 2
0âŸ©,ğ‘‡1||ğ‘‡2is an LTS ğ‘‡=
âŸ¨ğ‘†,ğ›¼ğ‘‡,ğ‘…,ğ‘  0âŸ©whereğ‘†=ğ‘†1Ã—ğ‘†2,ğ›¼ğ‘‡=ğ›¼ğ‘‡1âˆªğ›¼ğ‘‡2,ğ‘ 0=(ğ‘ 1
0,ğ‘ 2
0),
andğ‘…isdefinedas:Forany (ğ‘ 1,ğ‘,ğ‘ 1â€²) âˆˆğ‘…1andğ‘âˆ‰ğ›¼ğ‘‡2,wehave
((ğ‘ 1,ğ‘ 2),ğ‘,(ğ‘ 1â€²,ğ‘ 2)) âˆˆğ‘…; for any (ğ‘ 2,ğ‘,ğ‘ 2â€²) âˆˆğ‘…2andğ‘âˆ‰ğ›¼ğ‘‡1,
we have ((ğ‘ 1,ğ‘ 2),ğ‘,(ğ‘ 1,ğ‘ 2â€²)) âˆˆğ‘…; and for (ğ‘ 1,ğ‘,ğ‘ 1â€²) âˆˆğ‘…1and
(ğ‘ 2,ğ‘,ğ‘ 2â€²) âˆˆğ‘…2, wehave ((ğ‘ 1,ğ‘ 2),ğ‘,(ğ‘ 1â€²,ğ‘ 2â€²)) âˆˆğ‘….
3.1.3 Properties. In this work, we consider a class of properties
calledsafetyproperties [29].Inparticular,asafetyproperty ğ‘ƒcan
berepresentedasadeterministicLTSthatcontainsno ğœtransitions.
It defines the acceptable behaviors of a system ğ‘‡overğ›¼ğ‘ƒ, and
we say that an LTS ğ‘‡satisfiesğ‘ƒ(denoted ğ‘‡|=ğ‘ƒ) if and only if
ğ‘ğ‘’â„(ğ‘‡â†¾ğ›¼ğ‘ƒ) âŠ†ğ‘ğ‘’â„(ğ‘ƒ).
We check whether an LTS ğ‘‡satisfies a safety property ğ‘ƒ=
âŸ¨ğ‘†,ğ›¼ğ‘ƒ,ğ‘…,ğ‘  0âŸ©by automatically deriving an errorLTSğ‘ƒğ‘’ğ‘Ÿğ‘Ÿ=âŸ¨ğ‘†âˆª
{ğœ‹},ğ›¼ğ‘ƒ,ğ‘…ğ‘’ğ‘Ÿğ‘Ÿ,ğ‘ 0âŸ©whereğœ‹denotes the error state, and ğ‘…ğ‘’ğ‘Ÿğ‘Ÿ=ğ‘…âˆª
{(ğ‘ ,ğ‘,ğœ‹)|ğ‘âˆˆğ›¼ğ‘ƒâˆ§/nexâŸ©stsğ‘ â€²âˆˆğ‘†:(ğ‘ ,ğ‘,ğ‘ â€²) âˆˆğ‘…}. With this ğ‘ƒğ‘’ğ‘Ÿğ‘ŸLTS, we
test whether the error state ğœ‹is reachable in ğ‘‡||ğ‘ƒğ‘’ğ‘Ÿğ‘Ÿ. Ifğœ‹is not
reachable, then wecanconclude that ğ‘‡|=ğ‘ƒ.
3.2 Robustness Definition
Letğ‘€be the LTS of a machine, ğ¸the LTS of the environment, and
ğ›¼ğ¸ğ‘€=ğ›¼ğ‘€âˆ©ğ›¼ğ¸the common actions between the machine and
the environment. Then, we say ğ‘€â†¾ğ›¼ğ¸ğ‘€represents the set of all
environmental behaviors that are permitted by machine ğ‘€.
3ESEC/FSEâ€™20, November 8â€“13,2020, Virtual Event, USA Changjian Zhang, DavidGarlan,andEunsukKang
Machineğ‘€issaidtobe robustagainstasetoftraces ğ›¿âŠ†ğ‘ğ‘’â„(ğ‘€â†¾
ğ¸ğ‘€)ifandonlyifthesystemsatisfiesadesiredpropertyundera
newenvironment( ğ¸â€²)thatiscapableofadditionalbehaviorsin ğ›¿
comparedto theoriginal environment( ğ¸):
Definition3.1. Machineğ‘€isrobustagainst aset of traces ğ›¿with
respecttoenvironment ğ¸andproperty ğ‘ƒifandonlyif ğ›¿âŠ†ğ‘ğ‘’â„(ğ‘€â†¾
ğ›¼ğ¸ğ‘€),ğ›¿âˆ©ğ‘ğ‘’â„(ğ¸â†¾ğ›¼ğ¸ğ‘€)=âˆ…, and for every ğ¸â€²such that ğ‘ğ‘’â„(ğ¸â€²â†¾
ğ›¼ğ¸ğ‘€)=ğ‘ğ‘’â„(ğ¸â†¾ğ›¼ğ¸ğ‘€) âˆªğ›¿,ğ‘€||ğ¸â€²|=ğ‘ƒ.
The set of traces in ğ›¿are also called deviations ofğ¸â€²fromğ¸over
ğ›¼ğ¸ğ‘€.Then,the robustness ofamachineisdefinedasthelargestset
ofenvironmentaldeviations underwhichthe systemcontinues to
satisfy a desiredproperty:
Definition3.2. Therobustness ofmachine ğ‘€withrespecttoenvi-
ronment ğ¸andproperty ğ‘ƒ,denoted Î”(ğ‘€,ğ¸,ğ‘ƒ),isthesetoftraces
ğ›¿suchthat ğ‘€isrobustagainst ğ›¿withrespectto ğ¸andğ‘ƒ,andthere
exists no ğ›¿â€²suchthat ğ›¿âŠ‚ğ›¿â€²andğ‘€isalsorobustagainst ğ›¿â€².
beh(E/harpoonuprightÎ±EM)
<latexit sha1_base64="y4EHErQfBAvc+WWP7UAw0XQBmwo=">AAACCnicbZDLSsNAFIYnXmu9RV26GS1C3ZREBF0WpeBGqGAv0IQwmU6aoZOZMDMRSujaja/ixoUibn0Cd76N0zYLbf1h4OM/53Dm/GHKqNKO820tLa+srq2XNsqbW9s7u/befluJTGLSwoIJ2Q2RIoxy0tJUM9JNJUFJyEgnHF5P6p0HIhUV/F6PUuInaMBpRDHSxgrso5DE1Qb0sjRGMhWCSzqINfQQMwZsBLengV1xas5UcBHcAiqgUDOwv7y+wFlCuMYMKdVznVT7OZKaYkbGZS9TJEV4iAakZ5CjhCg/n54yhifG6cNISPO4hlP390SOEqVGSWg6E6RjNV+bmP/VepmOLv2c8jTThOPZoihjUAs4yQX2qSRYs5EBhCU1f4XYRIKwNumVTQju/MmL0D6ruYbvziv1qyKOEjgEx6AKXHAB6uAGNEELYPAInsEreLOerBfr3fqYtS5ZxcwB+CPr8wfx1ZnD</latexit><latexit sha1_base64="y4EHErQfBAvc+WWP7UAw0XQBmwo=">AAACCnicbZDLSsNAFIYnXmu9RV26GS1C3ZREBF0WpeBGqGAv0IQwmU6aoZOZMDMRSujaja/ixoUibn0Cd76N0zYLbf1h4OM/53Dm/GHKqNKO820tLa+srq2XNsqbW9s7u/befluJTGLSwoIJ2Q2RIoxy0tJUM9JNJUFJyEgnHF5P6p0HIhUV/F6PUuInaMBpRDHSxgrso5DE1Qb0sjRGMhWCSzqINfQQMwZsBLengV1xas5UcBHcAiqgUDOwv7y+wFlCuMYMKdVznVT7OZKaYkbGZS9TJEV4iAakZ5CjhCg/n54yhifG6cNISPO4hlP390SOEqVGSWg6E6RjNV+bmP/VepmOLv2c8jTThOPZoihjUAs4yQX2qSRYs5EBhCU1f4XYRIKwNumVTQju/MmL0D6ruYbvziv1qyKOEjgEx6AKXHAB6uAGNEELYPAInsEreLOerBfr3fqYtS5ZxcwB+CPr8wfx1ZnD</latexit><latexit sha1_base64="y4EHErQfBAvc+WWP7UAw0XQBmwo=">AAACCnicbZDLSsNAFIYnXmu9RV26GS1C3ZREBF0WpeBGqGAv0IQwmU6aoZOZMDMRSujaja/ixoUibn0Cd76N0zYLbf1h4OM/53Dm/GHKqNKO820tLa+srq2XNsqbW9s7u/befluJTGLSwoIJ2Q2RIoxy0tJUM9JNJUFJyEgnHF5P6p0HIhUV/F6PUuInaMBpRDHSxgrso5DE1Qb0sjRGMhWCSzqINfQQMwZsBLengV1xas5UcBHcAiqgUDOwv7y+wFlCuMYMKdVznVT7OZKaYkbGZS9TJEV4iAakZ5CjhCg/n54yhifG6cNISPO4hlP390SOEqVGSWg6E6RjNV+bmP/VepmOLv2c8jTThOPZoihjUAs4yQX2qSRYs5EBhCU1f4XYRIKwNumVTQju/MmL0D6ruYbvziv1qyKOEjgEx6AKXHAB6uAGNEELYPAInsEreLOerBfr3fqYtS5ZxcwB+CPr8wfx1ZnD</latexit><latexit sha1_base64="y4EHErQfBAvc+WWP7UAw0XQBmwo=">AAACCnicbZDLSsNAFIYnXmu9RV26GS1C3ZREBF0WpeBGqGAv0IQwmU6aoZOZMDMRSujaja/ixoUibn0Cd76N0zYLbf1h4OM/53Dm/GHKqNKO820tLa+srq2XNsqbW9s7u/befluJTGLSwoIJ2Q2RIoxy0tJUM9JNJUFJyEgnHF5P6p0HIhUV/F6PUuInaMBpRDHSxgrso5DE1Qb0sjRGMhWCSzqINfQQMwZsBLengV1xas5UcBHcAiqgUDOwv7y+wFlCuMYMKdVznVT7OZKaYkbGZS9TJEV4iAakZ5CjhCg/n54yhifG6cNISPO4hlP390SOEqVGSWg6E6RjNV+bmP/VepmOLv2c8jTThOPZoihjUAs4yQX2qSRYs5EBhCU1f4XYRIKwNumVTQju/MmL0D6ruYbvziv1qyKOEjgEx6AKXHAB6uAGNEELYPAInsEreLOerBfr3fqYtS5ZxcwB+CPr8wfx1ZnD</latexit>beh(WM,E,P)
<latexit sha1_base64="J/zr5GxedhsY5nYDa5EAUz8VHVI=">AAAB9XicbZBNS8NAEIYnftb6VfXoJViECqUkIuixKIIXoYL9gDaWzXbSLt1swu5GKaH/w4sHRbz6X7z5b9y2OWjrCwsP78wws68fc6a043xbS8srq2vruY385tb2zm5hb7+hokRSrNOIR7LlE4WcCaxrpjm2Yokk9Dk2/eHVpN58RKlYJO71KEYvJH3BAkaJNtaDj4NSs5velq/LtfFJt1B0Ks5U9iK4GRQhU61b+Or0IpqEKDTlRKm268TaS4nUjHIc5zuJwpjQIelj26AgISovnV49to+N07ODSJontD11f0+kJFRqFPqmMyR6oOZrE/O/WjvRwYWXMhEnGgWdLQoSbuvInkRg95hEqvnIAKGSmVttOiCSUG2CypsQ3PkvL0LjtOIavjsrVi+zOHJwCEdQAhfOoQo3UIM6UJDwDK/wZj1ZL9a79TFrXbKymQP4I+vzB90kkW4=</latexit><latexit sha1_base64="J/zr5GxedhsY5nYDa5EAUz8VHVI=">AAAB9XicbZBNS8NAEIYnftb6VfXoJViECqUkIuixKIIXoYL9gDaWzXbSLt1swu5GKaH/w4sHRbz6X7z5b9y2OWjrCwsP78wws68fc6a043xbS8srq2vruY385tb2zm5hb7+hokRSrNOIR7LlE4WcCaxrpjm2Yokk9Dk2/eHVpN58RKlYJO71KEYvJH3BAkaJNtaDj4NSs5velq/LtfFJt1B0Ks5U9iK4GRQhU61b+Or0IpqEKDTlRKm268TaS4nUjHIc5zuJwpjQIelj26AgISovnV49to+N07ODSJontD11f0+kJFRqFPqmMyR6oOZrE/O/WjvRwYWXMhEnGgWdLQoSbuvInkRg95hEqvnIAKGSmVttOiCSUG2CypsQ3PkvL0LjtOIavjsrVi+zOHJwCEdQAhfOoQo3UIM6UJDwDK/wZj1ZL9a79TFrXbKymQP4I+vzB90kkW4=</latexit><latexit sha1_base64="J/zr5GxedhsY5nYDa5EAUz8VHVI=">AAAB9XicbZBNS8NAEIYnftb6VfXoJViECqUkIuixKIIXoYL9gDaWzXbSLt1swu5GKaH/w4sHRbz6X7z5b9y2OWjrCwsP78wws68fc6a043xbS8srq2vruY385tb2zm5hb7+hokRSrNOIR7LlE4WcCaxrpjm2Yokk9Dk2/eHVpN58RKlYJO71KEYvJH3BAkaJNtaDj4NSs5velq/LtfFJt1B0Ks5U9iK4GRQhU61b+Or0IpqEKDTlRKm268TaS4nUjHIc5zuJwpjQIelj26AgISovnV49to+N07ODSJontD11f0+kJFRqFPqmMyR6oOZrE/O/WjvRwYWXMhEnGgWdLQoSbuvInkRg95hEqvnIAKGSmVttOiCSUG2CypsQ3PkvL0LjtOIavjsrVi+zOHJwCEdQAhfOoQo3UIM6UJDwDK/wZj1ZL9a79TFrXbKymQP4I+vzB90kkW4=</latexit><latexit sha1_base64="J/zr5GxedhsY5nYDa5EAUz8VHVI=">AAAB9XicbZBNS8NAEIYnftb6VfXoJViECqUkIuixKIIXoYL9gDaWzXbSLt1swu5GKaH/w4sHRbz6X7z5b9y2OWjrCwsP78wws68fc6a043xbS8srq2vruY385tb2zm5hb7+hokRSrNOIR7LlE4WcCaxrpjm2Yokk9Dk2/eHVpN58RKlYJO71KEYvJH3BAkaJNtaDj4NSs5velq/LtfFJt1B0Ks5U9iK4GRQhU61b+Or0IpqEKDTlRKm268TaS4nUjHIc5zuJwpjQIelj26AgISovnV49to+N07ODSJontD11f0+kJFRqFPqmMyR6oOZrE/O/WjvRwYWXMhEnGgWdLQoSbuvInkRg95hEqvnIAKGSmVttOiCSUG2CypsQ3PkvL0LjtOIavjsrVi+zOHJwCEdQAhfOoQo3UIM6UJDwDK/wZj1ZL9a79TFrXbKymQP4I+vzB90kkW4=</latexit>(Î±Eâˆ©Î±M)âˆ—
<latexit sha1_base64="g/aSx6Bpl16WBkNwTT88P++snGI=">AAACA3icbZDLSgMxFIYz9VbrbdSdboJFqC7KjAi6LIrgRqhgL9AZy5k0bUMzMyHJCGUouPFV3LhQxK0v4c63MW1noa0/BL785xyS8weCM6Ud59vKLSwuLa/kVwtr6xubW/b2Tl3FiSS0RmIey2YAinIW0ZpmmtOmkBTCgNNGMLgc1xsPVCoWR3d6KKgfQi9iXUZAG6tt75U84KIP+Ap7BATObjdH98dtu+iUnYnwPLgZFFGmatv+8joxSUIaacJBqZbrCO2nIDUjnI4KXqKoADKAHm0ZjCCkyk8nO4zwoXE6uBtLcyKNJ+7viRRCpYZhYDpD0H01Wxub/9Vaie6e+ymLRKJpRKYPdROOdYzHgeAOk5RoPjQARDLzV0z6IIFoE1vBhODOrjwP9ZOya/j2tFi5yOLIo310gErIRWeogq5RFdUQQY/oGb2iN+vJerHerY9pa87KZnbRH1mfPzCTle4=</latexit><latexit sha1_base64="g/aSx6Bpl16WBkNwTT88P++snGI=">AAACA3icbZDLSgMxFIYz9VbrbdSdboJFqC7KjAi6LIrgRqhgL9AZy5k0bUMzMyHJCGUouPFV3LhQxK0v4c63MW1noa0/BL785xyS8weCM6Ud59vKLSwuLa/kVwtr6xubW/b2Tl3FiSS0RmIey2YAinIW0ZpmmtOmkBTCgNNGMLgc1xsPVCoWR3d6KKgfQi9iXUZAG6tt75U84KIP+Ap7BATObjdH98dtu+iUnYnwPLgZFFGmatv+8joxSUIaacJBqZbrCO2nIDUjnI4KXqKoADKAHm0ZjCCkyk8nO4zwoXE6uBtLcyKNJ+7viRRCpYZhYDpD0H01Wxub/9Vaie6e+ymLRKJpRKYPdROOdYzHgeAOk5RoPjQARDLzV0z6IIFoE1vBhODOrjwP9ZOya/j2tFi5yOLIo310gErIRWeogq5RFdUQQY/oGb2iN+vJerHerY9pa87KZnbRH1mfPzCTle4=</latexit><latexit sha1_base64="g/aSx6Bpl16WBkNwTT88P++snGI=">AAACA3icbZDLSgMxFIYz9VbrbdSdboJFqC7KjAi6LIrgRqhgL9AZy5k0bUMzMyHJCGUouPFV3LhQxK0v4c63MW1noa0/BL785xyS8weCM6Ud59vKLSwuLa/kVwtr6xubW/b2Tl3FiSS0RmIey2YAinIW0ZpmmtOmkBTCgNNGMLgc1xsPVCoWR3d6KKgfQi9iXUZAG6tt75U84KIP+Ap7BATObjdH98dtu+iUnYnwPLgZFFGmatv+8joxSUIaacJBqZbrCO2nIDUjnI4KXqKoADKAHm0ZjCCkyk8nO4zwoXE6uBtLcyKNJ+7viRRCpYZhYDpD0H01Wxub/9Vaie6e+ymLRKJpRKYPdROOdYzHgeAOk5RoPjQARDLzV0z6IIFoE1vBhODOrjwP9ZOya/j2tFi5yOLIo310gErIRWeogq5RFdUQQY/oGb2iN+vJerHerY9pa87KZnbRH1mfPzCTle4=</latexit><latexit sha1_base64="g/aSx6Bpl16WBkNwTT88P++snGI=">AAACA3icbZDLSgMxFIYz9VbrbdSdboJFqC7KjAi6LIrgRqhgL9AZy5k0bUMzMyHJCGUouPFV3LhQxK0v4c63MW1noa0/BL785xyS8weCM6Ud59vKLSwuLa/kVwtr6xubW/b2Tl3FiSS0RmIey2YAinIW0ZpmmtOmkBTCgNNGMLgc1xsPVCoWR3d6KKgfQi9iXUZAG6tt75U84KIP+Ap7BATObjdH98dtu+iUnYnwPLgZFFGmatv+8joxSUIaacJBqZbrCO2nIDUjnI4KXqKoADKAHm0ZjCCkyk8nO4zwoXE6uBtLcyKNJ+7viRRCpYZhYDpD0H01Wxub/9Vaie6e+ymLRKJpRKYPdROOdYzHgeAOk5RoPjQARDLzV0z6IIFoE1vBhODOrjwP9ZOya/j2tFi5yOLIo310gErIRWeogq5RFdUQQY/oGb2iN+vJerHerY9pa87KZnbRH1mfPzCTle4=</latexit>Normative behaviors
of environment E Environmental deviations 
under which M satisfies P
i.e., its robustness (grey)Environmental deviations 
violating P (red)Set of all possible 
traces between M & E
beh(M/harpoonuprightÎ±EM)
Figure2:Behavioralrelationshipsbetweenpossibleenviron-
ments.
Figure2illustratestherelationshipsbetweenthebehaviorsof
possibleenvironmentsthatinteractwithamachinethroughshared
actionsğ›¼ğ¸âˆ©ğ›¼ğ‘€. The outermost circle represents the set of all
environmental behaviors that are permitted by the machine; the
innermost circle represents the normative behaviors of the envi-
ronment. The deviations of the environment could be classified
intotwosets:thoseunderwhichthemachinestillmaintainsade-
sired property ğ‘ƒ(i.e., its robustness), and the others that lead to its
violation (the area shadedredin Figure 2).
4 ANALYSIS PROBLEMS
Thissectiondefinesasetofanalysisproblemsforevaluatingsystem
designs withrespectto their robustness.
Problem 4.1 (Robustness analysis) .Given machine ğ‘€, environ-
mentğ¸, andproperty ğ‘ƒ, compute Î”(ğ‘€,ğ¸,ğ‘ƒ).
Given a method for computing the robustness of a machine
(describedinSection 5),wecanalsoperformthefollowinganalyses:
Problem 4.2 (Design comparison) .Given machines ğ‘€1andğ‘€2,
environment ğ¸, and property ğ‘ƒsuch that ğ›¼ğ‘€1âˆ©ğ›¼ğ¸=ğ›¼ğ‘€2âˆ©ğ›¼ğ¸,
compute set ğ‘‹=Î”(ğ‘€2,ğ¸,ğ‘ƒ) âˆ’Î”(ğ‘€1,ğ¸,ğ‘ƒ).
This analysis allows us to compare a pair of machines (repre-
sentingalternativedesignsofasystem)ontheirrobustnessagainst
thegivenenvironmentandproperty. ğ‘€2,forexample,maybeanevolution of ğ‘€1; the result of the analysis would describe precisely
the environmental deviations under which ğ‘€2is more robust than
ğ‘€1.Notethat ğ‘€1andğ‘€2may overlap,notnecessarily subsume,in
termsof their robustness.
Anothertypeofanalysiscanbeusedtoreasonabouthowthe
robustness of a machine changes depending on the property that it
attemptsto establish:
Problem4.3 (Property comparison) .Given machines ğ‘€, environ-
mentğ¸, and properties ğ‘ƒ1andğ‘ƒ2, compute set ğ‘‹=Î”(ğ‘€,ğ¸,ğ‘ƒ2) âˆ’
Î”(ğ‘€,ğ¸,ğ‘ƒ1).
For instance, suppose that ğ‘ƒ1says that â€œthe radiation therapy
systemshouldalwaysdeliverthecorrectamountofdosetoeach
patientâ€, while ğ‘ƒ2states that â€œthe system never overdoses patients
bydeliveringX-raywhilethespreaderisoutofplaceâ€(similarto
propertyğ‘ƒfrom Section 2). The result of this analysis could tell us,
for example, that the system is capable of guaranteeing ğ‘ƒ2(weaker
and arguably more critical of the two) even under certain operator
errors,while ğ‘ƒ1maybeviolatedundersimilar deviations.
In general, since improving robustness might introduce addi-
tionalcomplexityintothesystem,itmaybeacost-effectivestrategy
to design the system to be robust for most critical of the system
requirements [ 27]; our analysis could be used to support this ap-
proach to design.
5 ROBUSTNESS COMPUTATION
Thissectiondescribesamethodforautomaticallycomputingthe
robustnessofthemachinewithrespecttoagivenenvironmentand
a desiredproperty (Problem 4.1in Section 4).
5.1 Overview
Figure3shows the overall process of our approach to compute
the robustness of a machine ğ‘€with respect to environment ğ¸and
property ğ‘ƒ. The input of our tool is the LTS of ğ‘€,ğ¸, andğ‘ƒ. We
firstgeneratethe weakestassumption ofğ‘€(Section5.2)tocompute
Î”(ğ‘€,ğ¸,ğ‘ƒ). SinceÎ”may be infinite, we then generate a succinct
representationofit.Wecomputethe representative modelofÎ”(Sec-
tion5.3.1), group the traces into equivalence classes, and generate
afinitesetof representative traces(Section 5.3.2).Finally,wetake
anexternal deviation modelasinputtogenerateexplanationsfor
those representativetraces (Section 5.4).The final outputisaset of
pairs of a representativetraceanditsexplanation.
5.2 Weakest Assumption
Inassume-guaranteestyleofreasoning[ 28],amachineisconsid-
ered capable of establishing a property under some assumption
about the behavior of the environment. In our modeling approach,
an assumption is represented as some subset of all permitted envi-
ronmentalbehaviors;thelargestsuchsubsetiscalledthe weakest
assumption (thesecondlargestcircle in Figure 2). Moreformally:
Definition 5.1. Theweakestassumption ğ‘Šğ‘€,ğ¸,ğ‘ƒofamachine ğ‘€
with respect to environment ğ¸and property ğ‘ƒis an LTS which
defines the largest subset of the permitted environment behaviors
4ABehavioralNotion ofRobustnessfor Software Systems ESEC/FSEâ€™20, November 8â€“13,2020, Virtual Event, USA
Figure 3: Overview of the process for robustness computation. The input is the LTS of machine ğ‘€, environment ğ¸, and prop-
ertyğ‘ƒ. Section 5.2describes weakest assumption generation for computing Î”. Section 5.3describes generating robustness
representation(i.e.,asetofrepresentativetraces).Finally,Section 5.4describesexplanationgenerationfortherepresentative
traces.
ofğ‘€which satisfy property ğ‘ƒ, i.e.,
ğ‘ğ‘’â„(ğ‘Šğ‘€,ğ¸,ğ‘ƒ) âŠ†ğ‘ğ‘’â„(ğ‘€â†¾ğ›¼ğ¸ğ‘€) âˆ§ğ‘€||ğ‘Šğ‘€,ğ¸,ğ‘ƒ|=ğ‘ƒâˆ§
âˆ€ğ¸â€²:ğ‘€||ğ¸â€²|=ğ‘ƒâ†”ğ¸â€²|=ğ‘Šğ‘€,ğ¸,ğ‘ƒ
If stated otherwise, we willsimply write ğ‘Što meanğ‘Šğ‘€,ğ¸,ğ‘ƒfor
therest of thepaper.
Then,therobustnessofamachineisequivalenttoitsweakest
assumption minusthebehaviorsoftheoriginalenvironment.More
formally,wecancomputetherobustnessofmachine ğ‘€withrespect
toenvironment ğ¸andproperty ğ‘ƒbyconstructingthefollowingset:
Î”(ğ‘€,ğ¸,ğ‘ƒ)={ğœâˆˆğ‘ğ‘’â„(ğ‘Š) |ğœâˆ‰ğ‘ğ‘’â„(ğ¸â†¾ğ›¼ğ¸ğ‘€)}(1)
Weusetheapproach byGiannakopoulou et al.[ 20] to generate
the weakest assumption of a system to satisfy a certain safety
property. We briefly describe the approach: Given the system LTS
ğ‘€, theenvironmentLTS ğ¸, andthesafety property ğ‘ƒ,
(1)Compose system ğ‘€with the errorLTS of property ğ‘ƒ(as
defined in Section 3.1.3) and project its alphabet to the com-
mon actions between ğ‘€andğ¸, i.e., letğ›¼ğ¸ğ‘€=ğ›¼ğ‘€âˆ©ğ›¼ğ¸, we
compute (ğ‘€||ğ‘ƒğ‘’ğ‘Ÿğ‘Ÿ)â†¾ğ›¼ğ¸ğ‘€.
(2)Performbackwardpropagationoftheerrorstateover ğœtran-
sitions in the LTS obtained from Step 1. We prune all states
that are backward reachable from the error state via one or
moreğœsteps. The rationale is that if the system is in a state
whichcanentertheerrorstatewithsomeinternalactions,
then no environmentcanprevent theproperty violation.
(3)Determinize the LTS obtained from step 2 by applying ğœ
eliminationandsubsetconstruction[ 25].
(4)Remove the error state and all of its incoming transitions to
obtain the LTS that corresponds to the weakest assumption.
5.3 Representation ofRobustness
In general, the set of environmental traces that represent robust-
ness in Equation ( 1) may be infinite. Since simply enumerating
this set may not be an effective way to present this information
to the system designer, we propose a succinct, finiterepresenta-
tion of the robustness. The key idea behind our approach is that
manyofthetracesin Î”(ğ‘€,ğ¸,ğ‘ƒ)captureasimilartypeofdeviation
(e.g., a human operator erroneously skipping an action) and can be
groupedintothesameequivalenceclasswithasingle representativetracethat describes the deviation. Based on this idea, we describe a
methodforautomaticallyconverting Î”intoafinitenumberofsuch
equivalence classes(andthus,a finite set of representativetraces).
5.3.1 RepresentativeModelofRobustness. RecallfromEquation( 1)
thatÎ”containstracesthatareintheweakestassumption ğ‘Šbutnot
in the original normative environment ğ¸. To construct an LTS that
represents Î”,wetakeadvantageofthemethodtochecksafetyprop-
erties (described at the end of Section 3.1.3). In particular, we treat
theoriginalenvironment ğ¸projectedover ğ›¼ğ¸ğ‘€asasafetyproperty,
andcomputetracesin ğ‘Šthatleadtoaviolationofthisproperty;
any suchtracerepresentsa prefix of the traces in Î”(ğ‘€,ğ¸,ğ‘ƒ).
(a) E0 1 2a b
b
a c
c0 1 2a b
b
c0 1 2a b
b
c?
a c
(b) W (c) W  || E err
Figure 4: LTSâ€™s for a simple example illustrating the con-
struction of robustness.
Toillustrateourapproach,considerasimpleexampleinFigure 4,
whereğ‘Šis the weakest assumption generated from some machine
ğ‘€andğ¸istheoriginalenvironment.Tocomputetherepresentation
ofÎ”(ğ‘€,ğ¸,ğ‘ƒ), we first test whether ğ‘Š|=(ğ¸â†¾ğ›¼ğ¸ğ‘€), which is
equivalenttotestingwhethertheerrorstateisreachablein ğ‘Š||(ğ¸â†¾
ğ›¼ğ¸ğ‘€)ğ‘’ğ‘Ÿğ‘Ÿ, as shown in Figure 4(c). We say ğ‘Š||(ğ¸â†¾ğ›¼ğ¸ğ‘€)ğ‘’ğ‘Ÿğ‘Ÿis the
representative model ofÎ”(ğ‘€,ğ¸,ğ‘ƒ), and letÎ (ğ‘Š,ğ¸)be the set of all
theerrortraces in it.Then,
Î”(ğ‘€,ğ¸,ğ‘ƒ)={ğœâˆˆğ‘ğ‘’â„(ğ‘Š) |âˆƒğœâ€²âˆˆÎ (ğ‘Š,ğ¸):ğ‘ğ‘Ÿğ‘’ğ‘“ğ‘–ğ‘¥(ğœâ€²,ğœ)}(2)
whereğ‘ğ‘Ÿğ‘’ğ‘“ğ‘–ğ‘¥(ğœ1,ğœ2)meansğœ1is the prefix of ğœ2. Thus, a trace in
Î (ğ‘Š,ğ¸)canrepresentasetoftracesin Î”(ğ‘€,ğ¸,ğ‘ƒ)thatsharethis
prefix.Forourexample,trace âŸ¨ğ‘,ğ‘âŸ©inÎ (ğ‘Š,ğ¸)canrepresent,e.g.,
âŸ¨ğ‘,ğ‘,ğ‘,ğ‘,... âŸ©andâŸ¨ğ‘,ğ‘,ğ‘,ğ‘,... âŸ©inÎ”(ğ‘€,ğ¸,ğ‘ƒ).
5.3.2 RepresentativeTracesofRobustness. Nevertheless, Î (ğ‘Š,ğ¸)
mayalsobeinfinitedue to possible cycles.Forexample,in Figure
4(c),âŸ¨ğ‘,ğ‘,ğ‘,...,ğ‘ âŸ©wouldresultininfinitenumberoferrortraces.
Therefore, wefurtherdivide the traces intoequivalence classes:
5ESEC/FSEâ€™20, November 8â€“13,2020, Virtual Event, USA Changjian Zhang, DavidGarlan,andEunsukKang
Letğ‘‡ğ‘Š,ğ¸=âŸ¨ğ‘†ğ‘Š,ğ¸,ğ›¼ğ¸ğ‘€,ğ‘…ğ‘Š,ğ¸,ğ‘ 0âŸ©be the composition ğ‘Šâˆ¥(ğ¸â†¾
ğ›¼ğ¸ğ‘€)ğ‘’ğ‘Ÿğ‘Ÿ. Then,
Î (ğ‘Š,ğ¸)=/uniondisplay.1
ğ‘ âˆˆğ‘†ğ‘Š,ğ¸
ğ‘âˆˆğ›¼ğ¸ğ‘€Î ğ‘ ,ğ‘(ğ‘Š,ğ¸)where(ğ‘ ,ğ‘,ğœ‹) âˆˆğ‘…ğ‘Š,ğ¸
i.e.,Î ğ‘ ,ğ‘(ğ‘Š,ğ¸)denotes a subset of traces in Î (ğ‘Š,ğ¸)that all end
withtransition (ğ‘ ,ğ‘,ğœ‹). Then, wehave
Î”(ğ‘€,ğ¸,ğ‘ƒ)={ğœâˆˆğ‘ğ‘’â„(ğ‘Š) |âˆƒÎ ğ‘ ,ğ‘(ğ‘Š,ğ¸),âˆƒğœâ€²âˆˆÎ ğ‘ ,ğ‘(ğ‘Š,ğ¸):
ğ‘ğ‘Ÿğ‘’ğ‘“ğ‘–ğ‘¥(ğœâ€²,ğœ)}(3)
We say that Î ğ‘ ,ğ‘(ğ‘Š,ğ¸)is anequivalence class ofÎ (ğ‘Š,ğ¸). In
our example, we have two equivalence classes: Î 1,ğ‘(ğ‘Š, ğ¸)and
Î 2,ğ‘(ğ‘Š,ğ¸). Traces like âŸ¨ğ‘,ğ‘âŸ©andâŸ¨ğ‘,ğ‘,ğ‘,ğ‘,ğ‘ âŸ©all belong to class
Î 1,ğ‘(ğ‘Š,ğ¸); and traces like âŸ¨ğ‘,ğ‘,ğ‘âŸ©andâŸ¨ğ‘,ğ‘,ğ‘,ğ‘,ğ‘ âŸ©all belong to
classÎ 2,ğ‘(ğ‘Š,ğ¸).
Therationaleisthat: ğ‘ isthelaststatebyfollowingthenormative
behaviorsoftheoriginalenvironment,and ğ‘isthefirstdeviated
action. Thus, Î ğ‘ ,ğ‘(ğ‘Š,ğ¸)describes a class of traces that deviate
fromtheoriginalenvironmentfromthesamenormativestate ğ‘ and
by thesameaction ğ‘.
Sinceğ‘†ğ‘Š,ğ¸andğ›¼ğ¸ğ‘€are finite, so we have a finite number of
equivalence classes. We can simply generate them by enumerating
all the transitions leading to the error state. Then, we can pick
one of the traces in each equivalence class to represent Î”(ğ‘€,ğ¸,ğ‘ƒ).
Because we may not beinterested in howthe environment reaches
the last normative state, here we simply choose the shortest one.
Finally, wedefine:
Definition5.2. Therepresentation ofÎ”(ğ‘€,ğ¸,ğ‘ƒ),denotedby Î”ğ‘Ÿğ‘’ğ‘(
ğ‘€,ğ¸,ğ‘ƒ), is a finite set of traces such that each trace in it is the
shortesttraceof one of theequivalence classesof Î (ğ‘Šğ‘€,ğ¸,ğ‘ƒ,ğ¸).
Therefore, for our conceptual example, Î”(ğ‘€,ğ¸,ğ‘ƒ)can be repre-
sentedby: Î 1,ğ‘(ğ‘Š,ğ¸):âŸ¨ğ‘,ğ‘âŸ©, andÎ 2,ğ‘(ğ‘Š,ğ¸):âŸ¨ğ‘,ğ‘,ğ‘âŸ©.
5.4 Explanation ofRepresentativeTraces
By definition, a representative trace in Î”ğ‘Ÿğ‘’ğ‘(ğ‘€,ğ¸,ğ‘ƒ)contains only
actionsfrom ğ›¼ğ¸ğ‘€.Whilethistracedescribeshowtheenvironment
deviates from its expected behavior as observed by the machine,
itdoesnotcapturehowtheinternalbehavioroftheenvironment
couldhavecausedthisdeviation.Toprovidesuchan explanation for
an environmental deviation, we propose a method for augmenting
therepresentative traces withadditional domain-specificinforma-
tion(called faultyevents )abouttheunderlyingrootcausebehind
the deviation. In this approach, the normative model is augmented
with additional transitions on these faulty events (which are in-
ternal to the environment) and an automated method is used to
extract a minimal explanation for aparticularrepresentativetrace.
5.4.1 ExplanationsfromaDeviationModel. Inordertobuildexpla-
nations for representative traces, our tool takes a deviation model
as input, which contains normative and deviated behaviors, and
maps eachrepresentativetraceto a tracein thedeviation model.
Definition 5.3. Adeviation modelğ·ofenvironment ğ¸isanLTS
ğ‘‡=âŸ¨ğ‘†,ğ›¼ğ·,ğ‘…,ğ‘  0âŸ©whereğ›¼ğ·=ğ›¼ğ¸âˆª {ğ‘“1,ğ‘“2,...,ğ‘“ğ‘›},ğ‘“ğ‘–is a fault
in the environment, ğ‘ğ‘’â„(ğ¸) âŠ†ğ‘ğ‘’â„(ğ·â†¾ğ›¼ğ¸), andğ‘ğ‘’â„(ğ·â†¾ğ›¼ğ¸ğ‘€) âˆ©
Î”(ğ‘€,ğ¸,ğ‘ƒ)â‰ âˆ….Ourtoolmakesnoassumptionsonhowtogeneratesuchadevia-
tionmodel.Itcanbebuiltmanually(e.g.,Section 7.2usesamanually
defineddeviationmodel);oritcanbederivedfromexistingfault
models in other fields (e.g., Section 7.3derives the deviation model
fromanexistinghumanerrorbehaviormodel).Themodelmaynot
necessarily cover all the traces in Î”(ğ‘€,ğ¸,ğ‘ƒ); however, we say a
deviationmodel is complete withrespectto Î”(ğ‘€,ğ¸,ğ‘ƒ)ifand only
ifÎ”(ğ‘€,ğ¸,ğ‘ƒ) âŠ†ğ‘ğ‘’â„(ğ·â†¾ğ›¼ğ¸ğ‘€).
Then,anexplanationofarepresentativetraceisatraceinthe
deviation model:
Definition5.4. Foranytrace ğœâˆˆÎ”ğ‘Ÿğ‘’ğ‘(ğ‘€,ğ¸,ğ‘ƒ)andğœâ€²âˆˆğ‘ğ‘’â„(ğ·),
ifğœâ€²â†¾ğ›¼ğ¸ğ‘€=ğœ, then wesay ğœâ€²isanexplanation ofğœ.
(a) Original Environment E0 1 2a b
b
c
(b) Deviation Model D0 1 2ab
b
c3f1
c4f2a5
f3 f4
Figure5: Deviation model for thesimple example.
ConsideradeviationmodelforoursimpleexampleinFigure 5,
then: forthe representativetrace âŸ¨ğ‘,ğ‘âŸ©,wecan build explanations
âŸ¨ğ‘,ğ‘“1,ğ‘âŸ©andâŸ¨ğ‘,ğ‘“3,ğ‘“4,ğ‘âŸ©; and for the representative trace âŸ¨ğ‘,ğ‘,ğ‘âŸ©,
wecanbuildanexplanation âŸ¨ğ‘,ğ‘,ğ‘“2,ğ‘âŸ©.
5.4.2 The Minimal Explanation. In general, there could be infinite
numberofexplanationsforarepresentativetrace.However,similar
to software testing where we are often interested in the smallest
test cases against certain errors, here we are also only interested in
the explanation of ğœwhich contains the minimal number of faults.
Definition5.5. Theminimalexplanation forğœ=âŸ¨ğ‘0,...,ğ‘ğ‘›âˆ’1,ğ‘ğ‘›âŸ©
inÎ”ğ‘Ÿğ‘’ğ‘(ğ‘€,ğ¸,ğ‘ƒ)underdeviationmodel ğ·istheshortesttrace ğœâ€²âˆˆ
ğ‘ğ‘’â„(ğ·)whereğœâ€²â†¾ğ›¼ğ¸ğ‘€=ğœand faulty actions only exist between
ğ‘ğ‘›âˆ’1andğ‘ğ‘›.
Aminimalexplanation describes:1)howtheenvironmentcan
reach the last normative state without any faults; 2) and what
minimalsequenceoffaultshavecausedtheenvironmenttodeviate
fromthenormativebehavior.
Tocomputetheminimalexplanationfor ğœâˆˆÎ”ğ‘Ÿğ‘’ğ‘(ğ‘€,ğ¸,ğ‘ƒ),let
ğ‘‡ğœ=âŸ¨ğ‘†,ğ›¼ğ¸ğ‘€,ğ‘…,ğ‘ 0âŸ©be the LTS where ğœand its prefixes are the
only traces in it. Besides, wemakethe last action in ğœleadtoğœ‹to
denote the end state, i.e., (ğ‘ ,ğ‘ğ‘›,ğœ‹) âˆˆğ‘…. Then, we use BFS to search
theminimal explanationin ğ·||ğ‘‡ğœ, asshown in Algorithm 1.
Line 1-3 define an empty queue to store the remaining search
states and an empty set to store the visited states, and add the
initial state to the queue. The algorithm loops until the queue is
empty (Line 4). If the current visiting state is ğœ‹, then it returns the
current trace as the explanation (Line7-8); otherwise, it adds the
nextstatestothequeue.Specifically,ifthecurrenttracedoesnot
match the prefix of ğœ, i.e.,âŸ¨ğ‘0,...,ğ‘ğ‘›âˆ’1âŸ©, then it only adds states
with a non-faulty transition (Line 12-13). Since BFS returns on the
first result, it is guaranteed to find the minimal explanation. For
6ABehavioralNotion ofRobustnessfor Software Systems ESEC/FSEâ€™20, November 8â€“13,2020, Virtual Event, USA
Algorithm 1: Minimal explanationsearch
Data:A traceğœâˆˆÎ”ğ‘Ÿğ‘’ğ‘(ğ‘€,ğ¸,ğ‘ƒ)andtheLTS of ğ·||ğ‘‡ğœ
Result:The minimal explanation ğœâ€²âˆˆğ‘ğ‘’â„(ğ·)
1ğ‘:=empty queue ; // remaining search states
2ğ‘£:=empty set of states; // visited states
3enqueue( ğ‘,(ğ‘ 0,âŸ¨âŸ©));
4whileÂ¬isEmpty( q)do
5ğ‘ ,ğ‘¡:=dequeue( q);//ğ‘ the current state, ğ‘¡the
current trace
6ifğ‘ âˆ‰ğ‘£then
7 ifğ‘ =ğœ‹then
8 returnt;
9 else
10 ğ‘£:=ğ‘£âˆª{ğ‘ };
11 for(ğ‘ ,ğ‘,ğ‘ â€²) âˆˆğ‘…do
12 ifğ‘¡â†¾ğ›¼ğ¸ğ‘€=ğ‘ ğ‘¢ğ‘ğ‘‡ğ‘Ÿğ‘ğ‘ğ‘’ (ğœ,0,ğ‘›âˆ’1)then
enqueue( ğ‘,(ğ‘ â€²,ğ‘¡âŒ¢ğ‘));
/*ğ‘¡does not match âŸ¨ğ‘0,...,ğ‘ğ‘›âˆ’1âŸ©. */
13 else ifğ‘is notafault then
enqueue( ğ‘,(ğ‘ â€²,ğ‘¡âŒ¢ğ‘));
14 end
15 end
16end
17end
example,ouralgorithmreturns âŸ¨ğ‘,ğ‘“1,ğ‘âŸ©astheminimalexplanation
forâŸ¨ğ‘,ğ‘âŸ©instead of âŸ¨ğ‘,ğ‘“3,ğ‘“4,ğ‘âŸ©in the deviation model (Figure 5(b)).
6 ROBUSTNESS COMPARISON
This section describes a method to comparerobustness between a
pairofmachines(Problem 4.2),oramachineagainstapairofprop-
erties (Problem 4.3). According to Equation ( 1), to solve Problem
4.2, wehave
ğ‘‹=Î”(ğ‘€2,ğ¸,ğ‘ƒ) âˆ’Î”(ğ‘€1,ğ¸,ğ‘ƒ)
={ğœâˆˆğ‘ğ‘’â„(ğ‘Šğ‘€2) |ğœâˆ‰ğ‘ğ‘’â„(ğ¸â†¾ğ›¼ğ¸ğ‘€) âˆ§ğœâˆ‰ğ‘ğ‘’â„(ğ‘Šğ‘€1)}
By assuming ğ‘ğ‘’â„(ğ¸â†¾ğ›¼ğ¸ğ‘€) âŠ†ğ‘ğ‘’â„(ğ‘Šğ‘€1), we can simplify the
equationto:
ğ‘‹=Î”(ğ‘€2,ğ¸,ğ‘ƒ) âˆ’Î”(ğ‘€1,ğ¸,ğ‘ƒ)={ğœâˆˆğ‘ğ‘’â„(ğ‘Šğ‘€2) |ğœâˆ‰ğ‘ğ‘’â„(ğ‘Šğ‘€1)}
Then, we can use the same method described in Section 5.3to
generateitsrepresentation.Bycomputing ğ‘Šğ‘€2||(ğ‘Šğ‘€1)ğ‘’ğ‘Ÿğ‘Ÿ,wehave
Î (ğ‘Šğ‘€2,ğ‘Šğ‘€1)representingalltheprefixesof ğ‘‹.Similarly,wedivide
itintoequivalenceclasses,i.e., Î ğ‘ ,ğ‘(ğ‘Šğ‘€2,ğ‘Šğ‘€1)where(ğ‘ ,ğ‘)leads
to theerrorstate. Then, wehave
ğ‘‹=Î”(ğ‘€2,ğ¸,ğ‘ƒ) âˆ’Î”(ğ‘€1,ğ¸,ğ‘ƒ)
={ğœâˆˆğ‘ğ‘’â„(ğ‘Šğ‘€2) |âˆƒÎ ğ‘ ,ğ‘(ğ‘Šğ‘€2,ğ‘Šğ‘€1),
âˆƒğœâ€²âˆˆÎ ğ‘ ,ğ‘(ğ‘Šğ‘€2,ğ‘Šğ‘€1):ğ‘ğ‘Ÿğ‘’ğ‘“ğ‘–ğ‘¥(ğœâ€²,ğœ)}(4)
Finally,the representation ofğ‘‹=Î”(ğ‘€2,ğ¸,ğ‘ƒ)âˆ’Î”(ğ‘€1,ğ¸,ğ‘ƒ)isafinite
set of shortesttraces of Î ğ‘ ,ğ‘(ğ‘Šğ‘€2,ğ‘Šğ‘€1).
Weapplythesameprocessto ğ‘‹=Î”(ğ‘€,ğ¸,ğ‘ƒ2) âˆ’Î”(ğ‘€,ğ¸,ğ‘ƒ1).By
assuming that ğ‘ğ‘’â„(ğ¸â†¾ğ›¼ğ¸ğ‘€) âŠ†ğ‘ğ‘’â„(ğ‘Šğ‘ƒ1)and computing Î (ğ‘Šğ‘ƒ2,ğ‘Šğ‘ƒ1)anditsequivalence classes, wehave
ğ‘‹=Î”(ğ‘€,ğ¸,ğ‘ƒ2) âˆ’Î”(ğ‘€,ğ¸,ğ‘ƒ1)
={ğœâˆˆğ‘ğ‘’â„(ğ‘Šğ‘ƒ2) |âˆƒÎ ğ‘ ,ğ‘(ğ‘Šğ‘ƒ2,ğ‘Šğ‘ƒ1),
âˆƒğœâ€²âˆˆÎ ğ‘ ,ğ‘(ğ‘Šğ‘ƒ2,ğ‘Šğ‘ƒ1):ğ‘ğ‘Ÿğ‘’ğ‘“ğ‘–ğ‘¥(ğœâ€²,ğœ)}(5)
Then,the representation ofğ‘‹=Î”(ğ‘€,ğ¸,ğ‘ƒ2) âˆ’Î”(ğ‘€,ğ¸,ğ‘ƒ1)isafinite
set of shortesttraces of Î ğ‘ ,ğ‘(ğ‘Šğ‘ƒ2,ğ‘Šğ‘ƒ1).
7 CASESTUDIES
This section reports on our experience applying our proposed
method to evaluate the robustness of software designs. In par-
ticular, our goal was to answer the following research questions:
(1) Does our proposed notion of robustness capture the types of
environmentaldeviationsthatoccurinpractice?(2)Isournotion
ofrobustnessapplicableacrossmultipledomains?Toanswer(2),
we demonstrate the application of our method to two different
types of systems: namely, network protocols and safety-critical
interfaces.For(1),weshowthattherobustnesscomputedbyour
method indeed corresponds to environmental deviations that have
been studiedin therespectivedomains.
7.1 Implementation
We created our robustness analyzer on top of LTSA [ 33,34], a
modeling tool that supports automated reachability-based anal-
ysis of labelled transition systems. In our tool, the LTSâ€™s corre-
sponding to the input system, environment, and property are spec-
ified using FSP, the input modeling language of LTSA. We im-
plementthefunctionsincludingweakestassumptiongeneration,
representation generation, and explanation generation in a Kotlin
program (a JVM-based language). In particular, we take advan-
tageofthebuilt-intoolsupportofLTSAforcomposition,projec-
tion, and property checking over LTS. Our evaluation was done
on a Windows machine with 3.6GHz CPU and 32GB memory.
The source code of the implementation can be found on GitHub,
https://github.com/SteveZhangBit/LTSA-Robust.
7.2 NetworkProtocolDesign
This section describes a case study on rigorously evaluating the
robustness of network protocoldesigns. In particular, we focuson
two protocols:Anaiveprotocolthatassumesaperfectly reliable
communication channel, and the Alternate Bit Protocol (ABP) [ 42],
whichisspecificallydesignedtoguaranteeintegrityofmessages
overapotentiallyunreliablecommunicationchannel.Bycomputing
andcomparingtherobustnessofthetwo,weformallyshowthat
the ABP is indeed more robust than the naive protocol against
possiblefailuresinthechannel.Asfarasweknow,ourmethodis
thefirstautomatedtechniqueforformallyevaluatingtherobustness
of network protocols.
7.2.1 Models. Figure6showstheLTSâ€™sfortheenvironmentand
machines (i.e.,network protocols). Here, the environment ğ¸corre-
spondstoacommunicationchanneloverwhichmessagesaretrans-
mitted (with ğ›¼ğ¸={ğ‘ ğ‘’ğ‘›ğ‘‘[0..1],ğ‘Ÿğ‘’ğ‘[0..1],ğ‘ğ‘ğ‘˜[0..1],ğ‘”ğ‘’ğ‘¡ğ‘ğ‘ğ‘˜[0..1]}1).
Undernormalcircumstances,weexpectthatthechannelreliably
delivers messages to the intended receiver (i.e., it does not lose,
1ğ‘ ğ‘’ğ‘›ğ‘‘[0..1]referstoasetofactions {ğ‘ ğ‘’ğ‘›ğ‘‘[0],ğ‘ ğ‘’ğ‘›ğ‘‘[1]}.
7ESEC/FSEâ€™20, November 8â€“13,2020, Virtual Event, USA Changjian Zhang, DavidGarlan,andEunsukKang
(a) Perfect Channel ( E)|| Sender
Send
WaitAckWaitRec
OutputReceiver
WaitInput
Ackinput
send[0..1]getack[0..1]rec[0..1]
outputack[0..1]|| Transmit Channel
Send
ReceiveAck
GetAckAcknowledge ChannelSender ||
Send.0
WaitInputWaitRec.0
OutputReceiver
WaitInput
Ack/
WaitRec.1getack[0]rec[0]
output Send.1send[0], getack[1]
input
send[1], getack[0]getack[1]input
ack[0], rec[0]Outputrec[1]Ack/
WaitRec.0
outputack[1], rec[1]
rec[0]
send[x] rec[x] ack[x] getack[x]
(b) Naive Protocol ( MN) (c) ABP Protocol ( MABP)
Figure 6: (a) The perfect channel: the transmission channel transmits messages with parameter 0 or 1 from the sender to the
receiver; and the acknowledge channel transmits acknowledgements from the receiver back to the sender. (b) The naive pro-
tocol:Thesendersendsuserinputdatawitheither0or1,andwaitsontheacknowledgement;thereceiverwaitsonmessages,
output the data, and acknowledges with either 0 or 1. (c) The ABP protocol [ 19]: The sender first sends a message with 0, and
it continues sending the message until it receives an acknowledgement with 0. Then, it alternates the bit to send a message
with1.Thereceiverfirstwaitsonamessagewith0,anditcontinuessendingacknowledgementswith0untilitreceivesanew
messagewith 1. Then, itacknowledgeswith 1andwaits for anew messagewith 0.
duplicate,orcorruptmessages);thismodelofthenormativeenvi-
ronmentiscapturedastheperfectchannel in Figure 6(a).
A machine in this case study corresponds to a network protocol
whosegoalistoreliablydelivereachmessagefromthesendertoits
intendedreceiver.Inparticular,wecomparetwoprotocols:Anaive
protocolğ‘€ğ‘, which simply sends and receives messages assuming
the channel is reliable, and the Alternate Bit Protocol (ABP) ğ‘€ğ´ğµğ‘ƒ,
whichisdesigned to ensurereliable delivery evenin presence of
potentialfaultsintheunderlyingchannel.Figure 6(b)and6(c)show
their specificationsrespectively.
7.2.2 ComputingRobustnessandExplanations. Wedefinedprop-
ertyğ‘ƒasâ€œtheinput andoutputshould alternateâ€;in FSP:
property P = (input -> output -> P).
This property ensures that the sender sends a new message only
afteritreceivesthereceiverâ€™sacknowledgementthatthepreviously
sent messagewassuccessfullydelivered.
Weusedourtooltocomputetherobustnessofthetwoprotocols,
i.e.,Î”(ğ‘€ğ‘,ğ¸,ğ‘ƒ)andÎ”(ğ‘€ğ´ğµğ‘ƒ,ğ¸,ğ‘ƒ).Specifically, ğ¸contains9states
and24transitions, ğ‘€ğ‘contains20statesand67transitions,and
our tool spent 130ms to generate Î”ğ‘Ÿğ‘’ğ‘(ğ‘€ğ‘,ğ¸,ğ‘ƒ)and build their
explanations. Î”ğ‘Ÿğ‘’ğ‘(ğ‘€ğ‘,ğ¸,ğ‘ƒ)contains4 tracescorrespondingto4
equivalenceclasses. ğ‘€ğ´ğµğ‘ƒcontains30statesand104transitions,
andourtoolspent1s317mstogenerate Î”ğ‘Ÿğ‘’ğ‘(ğ‘€ğ´ğµğ‘ƒ,ğ¸,ğ‘ƒ)andtheir
explanations. Î”ğ‘Ÿğ‘’ğ‘(ğ‘€ğ´ğµğ‘ƒ,ğ¸,ğ‘ƒ)contains 107 traces corresponding
to 107 equivalence classes.
7.2.3 Analysis. We built a deviation model ğ·which contains mes-
sageloss,duplication,andcorruptionofbits(onlythebitparameter
0and1,butnotthemessagecontent)toprovideexplanationsfor
these representativetraces. Figure 7shows itsspecification.
Allthe4tracesin Î”ğ‘Ÿğ‘’ğ‘(ğ‘€ğ‘,ğ¸,ğ‘ƒ)correspondtothebitcorrup-
tion error. For example, the explanation for âŸ¨ğ‘ ğ‘’ğ‘›ğ‘‘[0],ğ‘Ÿğ‘’ğ‘[1]âŸ©is
âŸ¨ğ‘–ğ‘›ğ‘ğ‘¢ğ‘¡,ğ‘ ğ‘’ğ‘›ğ‘‘ [0],ğ‘ğ‘œğ‘Ÿğ‘Ÿğ‘¢ğ‘ğ‘¡,ğ‘Ÿğ‘’ğ‘ [1]âŸ©. We were surprised to find that
the naive protocol is robust against such errors (our expectationSend Lostsend[x]
loseReceivesend[x]
rec[x]Duplicatedrec[x]
duplicate
Corruptedcorrupt rec[1-x]
Figure7:Deviationmodelthatdescribesthefaultytransmis-
sion channel. The faulty acknowledge channel is similarly
structured andomitted here.
wasthatthenaiveprotocolwouldbenotrobustagainstanykind
of environmental deviations at all). This is because property ğ‘ƒ
is somewhat under-specified: It requires only that the input and
outputactionsalternate,anddoesnotsayanythingaboutthebit
parametersin thesent andcorrespondingreceivedmessages.
Forthe107tracesin Î”ğ‘Ÿğ‘’ğ‘(ğ‘€ğ´ğµğ‘ƒ,ğ¸,ğ‘ƒ),ourtoolfindsthemini-
mal explanationsfor99of them.Forexample,theexplanationfor
âŸ¨ğ‘ ğ‘’ğ‘›ğ‘‘[0],ğ‘ ğ‘’ğ‘›ğ‘‘[0]âŸ©isâŸ¨ğ‘–ğ‘›ğ‘ğ‘¢ğ‘¡,ğ‘ ğ‘’ğ‘›ğ‘‘ [0],ğ‘™ğ‘œğ‘ ğ‘’,ğ‘ ğ‘’ğ‘›ğ‘‘ [0]âŸ©corresponding
to message loss during transmission; the explanation for âŸ¨ğ‘ ğ‘’ğ‘›ğ‘‘[0],
ğ‘Ÿğ‘’ğ‘[0],ğ‘Ÿğ‘’ğ‘[0]âŸ©isâŸ¨ğ‘–ğ‘›ğ‘ğ‘¢ğ‘¡,ğ‘ ğ‘’ğ‘›ğ‘‘ [0],ğ‘Ÿğ‘’ğ‘[0],ğ‘œğ‘¢ğ‘¡ğ‘ğ‘¢ğ‘¡,ğ‘‘ğ‘¢ğ‘ğ‘™ğ‘–ğ‘ğ‘ğ‘¡ğ‘’,ğ‘Ÿğ‘’ğ‘ [0]âŸ©
corresponding to message duplication during transmission; and
the explanation for âŸ¨ğ‘ ğ‘’ğ‘›ğ‘‘[0],ğ‘Ÿğ‘’ğ‘[0],ğ‘ğ‘ğ‘˜[0],ğ‘”ğ‘’ğ‘¡ğ‘ğ‘ğ‘˜[1]âŸ©isâŸ¨ğ‘–ğ‘›ğ‘ğ‘¢ğ‘¡,
ğ‘ ğ‘’ğ‘›ğ‘‘[0],ğ‘Ÿğ‘’ğ‘[0],ğ‘œğ‘¢ğ‘¡ğ‘ğ‘¢ğ‘¡,ğ‘ğ‘ğ‘˜ [0],ğ‘ğ‘œğ‘Ÿğ‘Ÿğ‘¢ğ‘ğ‘¡,ğ‘”ğ‘’ğ‘¡ğ‘ğ‘ğ‘˜ [1]âŸ©corresponding
to thebitcorruptionerror duringacknowledgement.
Wefurthergroupedtherepresentativetracesbythetypeoffault
intheirexplanations,asshowninTable 1.Forexample, trans.{dupli-
cate,corrupt} representsasetofdeviationsinwhichthetransmitted
messageisduplicatedandthencorrupted(e.g., âŸ¨..ğ‘Ÿğ‘’ğ‘[0],ğ‘Ÿğ‘’ğ‘[1]âŸ©).
There may be multiple representative traces of the same fault type,
since the fault may occur at different points during an expected
sequence of environmental actions.
8ABehavioralNotion ofRobustnessfor Software Systems ESEC/FSEâ€™20, November 8â€“13,2020, Virtual Event, USA
Table 1: Summary of Î”ğ‘Ÿğ‘’ğ‘for ABP. â€œtransâ€ refers to errors
during transmission, and â€œackâ€ refers to errors during ac-
knowledgements.
Faulttypes #Traces Faulttypes #Traces
trans.lose 23ack.duplicate 14
trans.duplicate 18trans.{duplicate,corrupt} 4
trans.corrupt 8ack.{duplicate,corrupt} 2
ack.lose 22unexplained 8
ack.corrupt 8Total 107
OuranalysisshowsthattheABPprotocolismorerobustthan
the naiveprotocol in being able tohandle messagelossand dupli-
cation,asintendedbytheprotocoldesign[ 42].Inaddition,the8
unexplained traces also gave us an insight into a type of error that
ABP was previously unknown to be robust against; namely, that
thesendermayreceiveacknowledgmentsevenwhenthereceiver
does not send them. This type of deviation may occur, for example,
whenamaliciouschannelgeneratesadubiousacknowledgementto
deceivethesenderintobelievingthatamessagehasbeendelivered.
7.3 Radiation TherapySystem
The second case study focuses on the radiation therapy system
introduced in Section 2. Specifically, we compare the robustness
of the two designs (i.e., the original design and the redesign in-
volving an additional check to ensurethecompletion of themode
switch before beam delivery) and show that the redesign is in-
deed more robust against potential human errors. In particular, to
model normative and erroneous human behavior, we adopt the En-
hancedOperatorFunctionModel(EOFM)[ 8],aformalnotationfor
modelingtasksperformedoverhuman-machineinterfaces.Human
behavior modelinghasbeen studiedbyresearchersin humanfac-
torsandcognitivescience[ 24,38],andwereusetheirresultsinthis
casestudytodemonstratethatourapproachcanbecombinedwith
existingbehaviormodels in fieldsother thannetwork protocols.
7.3.1 EOFM. The Enhanced Operator Function Model (EOFM) [ 8]
is a formal description language for human task analysis , a well-
establishedsub-fieldofhumanfactorsthatfocusesonthedesign
ofhumanoperatortasksandrelatedfactors(e.g.,training,working
conditions, and error prevention) [ 2]. An EOFM describes the task
tobeperformedbyanoperatoroveramachineinterfaceasahierar-
chicalsetof activities.Eachactivityincludesasetof conditions that
describe(1)when theactivitycanbeundertaken( pre-conditions )
and(2)whenitisconsideredcomplete( completionconditions ).Each
activityisdecomposedintolower-levelsub-activitiesand,finally,
into atomic interface actions. Decomposition operators are used
to specify the temporal relationships between the sub-activities or
actions.TheEOFMlanguageisbasedXML,anditalsosupportsa
tree-likevisual notation.
Figure8shows a fragment of the EOFM model of the operatorâ€™s
tasks for the radiation therapy system (from [ 10]). It defines the
BeamSelectionTask,whichcanbeperformedonlyiftheinterfaceis
intheEditingstate;theoperatorcanselect eitherX-rayorelectron
beambypressing XorE,respectively;andtheactivityiscompleted
onlyif theinterfaceleaves theeditingstate.InterfaceState = Editing
aSelectXorE
aSelectXrayaSelect
EBeam
X Exor
ord ordInterfaceState != Editing
Figure 8: The EOFM model of the Beam Selection Task. A
rounded box defines an activity, a rectangular box defines
anatomicaction,andaroundedboxingrayincludesallthe
sub-activities/actions of a parent activity. The labels on the
directed arrows are decomposition operators. The triangle
in yellow defines the pre-conditions of an activity, and the
triangle inred defines thecompletion conditions.
7.3.2 Models. The LTSâ€™s used for this case study (shown in Fig-
ure1) were adopted from a prior work on formal safety analysis of
radiationtherapysystemunderpotentialhumanerrors[ 10],where
the system is modeled as a finite state machine and the human
operatortaskisspecifiedusinganEOFM.Adoptingtheirsystem
model into our LTS was straightforward. To translate the EOFM to
a corresponding LTS, we implemented an automatic EOFM-to-LTS
translator using a technique proposed in [ 11]; due to limited space,
weomit thedetails about ourtranslation process.
7.3.3 DeviationModel. Togenerateexplanationsfor Î”thatinvolve
human errors, we adopted a method for automatically augmenting
a model of a normative operator task (specified in EOFM) with
additionalbehaviorsthatcorrespondtohumanerrors[ 9].Inpar-
ticular, this approach leverages a catalog of human errors called
genotypes [38]. For example, one type of genotype errors named
commission describeserrorswheretheoperatoraccidentallyper-
forms an activity under a wrong condition.Other genotype errors
include omission (skippinganactivity)andrepetition.
Select 
ModeConfirm 
ModeFireBeamTask 
Complete
GoBackX
EEnter B
commission Up
Figure9: Apartial deviation model of theoperatortask.
Figure9shows a simplifiedversionof the deviationmodel that
was automatically generated from the EOFM model of the ther-
apist task. This model captures the operator making a potential
commissionerror;i.e.,deviatingfromtheexpectedtaskbypress-
ingUp. For simplicity, we only show one faulty transition here;
9ESEC/FSEâ€™20, November 8â€“13,2020, Virtual Event, USA Changjian Zhang, DavidGarlan,andEunsukKang
the complete deviation model is considerably more complex, since
commission,omission,orrepetitionerrorscanoccuratanystate
in thenormativeoperatormodel.
7.3.4 ComparingRobustnessof ğ‘€andğ‘€ğ‘….Wecomparedthero-
bustness of the two designs by computing ğ‘‹=Î”(ğ‘€ğ‘…,ğ¸,ğ‘ƒ) âˆ’
Î”(ğ‘€,ğ¸,ğ‘ƒ)(usingEquation( 4))andgeneratedrepresentativetraces
thatillustratedifferencesintheirrobustness.Specifically, ğ‘€con-
tains 19 states and 40 transitions, ğ‘€ğ‘…contains 19 states and 42
transitions. Our tool spent 958ms to compute the representation of
ğ‘‹, which contains 3 representative traces (i.e., implying that ğ‘€ğ‘…
ismorerobustthan ğ‘€againstthreetypesofoperatordeviations).
One of the traces represents the error that was discussed in Sec-
tion2:âŸ¨X,Up,E,Enter,BâŸ©. This shows that the redesign is indeed
robustagainstthe operator error involvingthe switchfromX-ray
to EBeam. Moreover, weused the deviationmodel to generate the
followingminimalexplanationforthistrace: âŸ¨X,commission ,Up,E,
Enter,BâŸ©,correspondingtotheoperatormakinga commission error
by unexpectedly pressing Upduringthetask.
Inaddition,computing Î”(ğ‘€,ğ¸,ğ‘ƒ)âˆ’Î”(ğ‘€ğ‘…,ğ¸,ğ‘ƒ)yieldedanempty
set,demonstratingthat theredesignofthesystemisstrictlymore
robustthantheoriginal design.
7.3.5 Comparing Robustness Under Two Properties. Recall that
property ğ‘ƒstatesthatthesystemshouldnotfireX-raywhenthe
spreader is out of place. It may also be desirable to ensure that
the system does not fire electron beam when the spreader is in
place (for example, resulting in under-dose, which, while not as
life-threatening as overdose, is still considered a critical error.) Let
ğ‘ƒâ€²be a property stating that the system must prevent both over-
dose as well as under-dose by ensuring the right mode of beam
depending on the configuration of the spreader. Intuitively, ğ‘ƒâ€²is a
stronger property than ğ‘ƒ.
Tocomparetherobustnessofthesystemagainstthesetwoprop-
erties,wecomputed ğ‘‹=Î”(ğ‘€,ğ¸,ğ‘ƒ)âˆ’Î”(ğ‘€,ğ¸,ğ‘ƒâ€²)byusingEquation
(5).Ourtoolspent2s98msandreturnedonerepresentativetrace,i.e.,
âŸ¨E,Up,X,Enter,BâŸ©.Sincethisbehaviorisallowedin Î”(ğ‘€,ğ¸,ğ‘ƒ)but
notinÎ”(ğ‘€,ğ¸,ğ‘ƒâ€²),wecanconclude fromthetheanalysis thatthe
the system(asexpected)islessrobustinestablishingthe stronger
property ğ‘ƒâ€²underpotential operatorerrors.
8 RELATEDWORK
Most of the prior works on robustness within the software engi-
neering community have focused on testing[39]. Techniques such
asfuzztesting(e.g.,[ 21]),model-basedtesting(particularlythose
that use a fault model [ 4,17]) and chaos testing [ 3] are designed to
evaluatetherobustnessofsystemsagainstunexpectedinputsoren-
vironmentalfailures.However,theprimarygoalofthesetechniques
istoidentifyundesirablesystembehaviors(e.g.,crashesorsecurity
violations)ratherthantocomputerobustnessasanintrinsiccharac-
teristic of the software. In addition, we believe that our robustness
metriccanpotentiallybeusedtocomplementandfurthersystem-
atizerobustnesstesting;forinstance,tracesin Î”couldbeusedto
guide the generation of test cases that are designed to evaluate the
systemagainstspecific types of environmental deviations.Various formal definitions of robustness for discrete systems
have been investigated [ 5,22,23,40]. One common characteris-
tics of these prior definitions is that they are all quantitative in
nature. For instance, Bloem et al. propose a notion of robustness
thatrelatesthenumberofincorrectenvironmentinputsandsystem
outputs(e.g.,theratioofincorrectoutputsoverinputsshouldbe
small)[5].Tabuadaetal.proposeadifferentnotionofrobustness
that assigns coststo certain input and output traces (e.g., a high
costmaybeassignedtoaninputtracethatdeviatessignificantly
from the expected behavior) and stipulates that an input with a
small cost should only result in an output with a proportionally
smallcost[ 40].Henzingeretal.adoptthenotionof Lipschitzcon-
tinuityfromthecontroltheorytodiscretetransitionsystemsand
use thedistancebetween a pair of expected and actual input traces
to quantifytheamount of environmental deviations[ 22,23].
In comparison, our notion of robustness is qualitative in that
itcapturesthe(possiblyinfinite)setofenvironmentaldeviations
under which the system guarantees a desired property. These two
types of metrics are complementary in nature and have their own
potential uses. While a quantitative metric may directly enable
ordering of design alternatives, our robustness contains additional
information about the environmental behaviors (e.g., specific types
of deviations)that canbeusedto improvethe systemrobustness.
Tabuada and Neider propose an extension of linear temporal
logiccalled robustlineartemporallogic (rLTL),whichallowsspec-
ifications stipulating that a â€œsmallâ€ violation of the environment
assumption must cause only a â€œsmallâ€ violation of the guarantee
bythesystem[ 41].Inparticular,theyuseamulti-valuedsemantics
tocapturedifferentlevelsofpropertysatisfactionbytheenviron-
ment (e.g., given an expected property of form Gğœ‘, being able to
satisfyonlyaweakerproperty F(Gğœ‘)wouldbeconsideredaâ€œsmallâ€
violation)[ 40].Althoughthefocusofourpaperisoncomputingro-
bustnessratherthanspecifyingit,rLTLcouldpotentiallybeusedto
characterize certain types of deviations that are temporal in nature.
Our notion of robustness can be regarded as one way of charac-
terizinguncertaintyabouttheenvironmentunderwhichthesystem
is capable guaranteeing a certain property. Researchers have devel-
oped various notations and analysis techniques for specifying and
reasoning about uncertainty [ 12,16,26,31]. For example, modal
transition systems (MTS) allow one to express uncertainty about
behaviorbyassigninga modality totransitions(e.g.,atransition
that can possibly but not necessarily occur is assigned modality
may) [31]. More recently, partial models have been developed as a
generalmodelingframeworkforspecifyingandreasoningabout
uncertainty on structural or behavioral aspects of a system [ 16].
Although the approach in this paper uses a purely trace-based en-
coding of robustness, these existing notations could potentially be
usedto providea morehigh-level representationof robustness.
In safety engineeringand risk management, operating envelope
(or sometimes safety envelope ) has been used to refer to the bound-
aryofenvironmentalconditionsunderwhichthesystemiscapable
ofmaintainingsafety[ 37].Thisconcepthasbeenadoptedinanum-
berofdomainssuchasaviation,robotics,andmanufacturing,but
asfarasweknow,hasnotbeenrigorouslydefinedinthecontext
of software. Our notion of robustness can be considered as one
possible definition of the operating envelope for software systems.
10ABehavioralNotion ofRobustnessfor Software Systems ESEC/FSEâ€™20, November 8â€“13,2020, Virtual Event, USA
9 DISCUSSIONS
Role of robustness in software development. We envision a
numberofdevelopmentscenariosinwhichournotionofrobustness
mayproveuseful.Inatypicalworkflow,thedevelopermaybegin
by constructing a candidate design that satisfies a desired property
underanormativeenvironment(i.e.,onewithoutanyerroneous
behaviors). Then,the robustness computed over thisinitial design
may reveal that the system is not capable of tolerating certain
deviationsthatthedeveloperhasinmind.Basedonthisinformation,
the system may be re-designed with an error handling mechanism
andanalyzedagaintocomputeitsnewrobustness.Thisprocessmay
berepeatedtoincrementallyachieveadesiredlevel ofrobustness.
Our analysis may also be used to reveal that a design is over-
engineered ,inthatitisrobustagainstdeviationsthatareunlikely
to occur (this situation may arise, for example, when a system is
deployedinamoreconstrainedenvironmentthanoriginallyantici-
pated).Over-engineeringhasitscost,ofteninformofadditional
complexity,andthus,thedevelopermaywishtosimplifythede-
sign to reduce its robustness to a desired level (e.g., byremoving
unnecessary failurehandling mechanisms).
Our approach also supports development of mixed-criticality
systems[ 13],wheresomeofthesystemrequirementsareconsid-
eredmorecriticalthanothers(e.g.,incertaindistributedsystems,
preventingnetworkmessagecorruptionmaybemoreimportant
thanensuringtimelydelivery).Suchasystemshouldbedesignedto
satisfyitscriticalpropertiesevenunderafaultyenvironment,while
it might be considered acceptable for other, non-critical properties
tobeviolatedunderthesamesituation.Byapplyingtheproperty
comparisonanalysisasstatedinProblem 4.3,thedevelopercanrig-
orouslycheckwhetheragivendesignachievesappropriatelevels
of robustness forproperties withdifferent levelsof criticality.
Strengthsof ourrobustness definition. Ourrobustnessnotion
provides information about:(1) what additional environmental be-
haviorsthesystemcanhandlecomparedtotheidealenvironmentor
an alternativedesign, and (2) what errors intheenvironment these
additional behaviors represent. For (1), we compute the differences
between the weakest assumption of a system and the normative
environment to denote its robustness; and we compare the robust-
ness of two designs by computing the differences in their weakest
assumptions.Sincerobustness,ingeneral,isaninfinitetraceset,
ourapproachprovidesatechniqueforcategorizingrobustnessin
termsof a finite number of representativetraces (Section 5.3).
For(2),adeviationmodelisusedtogenerateanexplanationthat
describes a deviation in terms of designated faulty events (Section
5.4). As we demonstrated on the radiation therapy system, these
modelscan beconstructed automatically from domain knowledge
that captures a set of common deviations in an application domain
(e.g.,humanerrors).Ingeneral,adeviationmodelmightnotcontain
enough faulty events to produce an explanation for a particular
representativetrace,identifiedasanunexplaineddeviation.How-
ever,webelievethatthiscanalsobeconsideredastrengthofour
approach, since these unexplained traces reveal the unexpected
side-effects (may or may bot be good) of a design decision and can
providedomainexpertswithinsightsaboutpreviouslyunknown
types of deviations (e.g., ABP being robust against an injection of a
dubiousacknowledgement, asdescribedat theend of Section 7.2).10 LIMITATIONS ANDFUTURE WORK
Properties. One limitation of the proposed approach is that our
currentnotionofrobustnessisspecificallydesignedfor safetyprop-
erties. As a next step, to enable reasoning about livenessproper-
ties [1], we plan to investigate an extended notion of robustness
wheretheenvironmentdeviatesfromitsexpectationnotonlyby
performing additional behaviors, but also by failingto perform
expected behaviors (thus possibly resulting in a liveness violation).
Scalability. Thescalabilityofourtoolhighlydependsontheweak-
estassumptiongenerationalgorithm;thegenerationoftherepre-
sentativetracesandexplanationsinvolvesonlyLTScomposition
and BFS search. As part of future work, we plan to improve our
toolbyleveragingtechniquesforefficientgenerationofweakestas-
sumptions(e.g.,thosethatuseL*learning[ 15]oracounterexample-
guidedmethod[ 6]).
Classifying deviations. Another limitation is that our current
methodofdefiningequivalenceclassesfor Î”maysometimesresult
inaclassificationthatistoofine-grained.Forexample,fortheABP
protocol, our tool generated 107 different classes of environmental
deviations (see Section 7.2). Intuitively, traces âŸ¨ğ‘ ğ‘’ğ‘›ğ‘‘[0],ğ‘ ğ‘’ğ‘›ğ‘‘[0]âŸ©
andâŸ¨...,ğ‘ ğ‘’ğ‘›ğ‘‘[1],ğ‘ ğ‘’ğ‘›ğ‘‘[1]âŸ©refer to the same type of fault (i.e., mes-
sagelossduringsending)andcouldbegroupedintothesameclass.
In future work, we plan to explore different strategies for gen-
eratingrepresentativetraces,leveragingabstraction-basedmeth-
ods to produce higher-level representations of deviations (e.g.,
âŸ¨...,ğ‘ ğ‘’ğ‘›ğ‘‘[ğ‘¥],ğ‘ ğ‘’ğ‘›ğ‘‘[ğ‘¥]âŸ©forsome event parameter ğ‘¥).
Redesigningfor robustness. One potential future direction is to
develop an approach for systematically redesigning a system to
improveitsrobustness:Givenmachine ğ‘€andsomeenvironmental
deviations ğ›¿underwhichthesystemfailstosatisfyproperty ğ‘ƒ,how
doweredesignthesystemtoberobustagainstsuchdeviations(i.e.,
ğ›¿âŠ†Î”(ğ‘€â€²,ğ¸,ğ‘ƒ)forredesignedmachine ğ‘€â€²)?Inparticular,weplan
to formulate this problem as a type of model transformation (from
ğ‘€toğ‘€â€²),andexplorealgorithmicmethodsfor(semi-)automatically
synthesizingtherobustredesign.
ACKNOWLEDGMENTS
Weâ€™dliketothankDanielJackson,StÃ©phaneLafortune,andStavros
Tripakis for their discussions on robustness, and anonymous re-
viewersfortheirsuggestionsthathelpedgreatlyimprovethispaper.
This workwas supportedinpart by theNational ScienceFoun-
dation awards CCF-1918140 and CNS-1801546. The project was
alsoco-financedbytheERDF-EuropeanRegionalDevelopment
FundthroughtheOperacionalProgramforCompetitivenessand
Internationalisation -COMPETE 2020 and by the PortugueseFoun-
dationforScienceandTechnology-FCTunderCMUPortugal.Any
opinions, findings, and conclusions or recommendations expressed
in this material are those of the authors and do not necessarily
reflecttheviews of thesponsoring agencies.
Thismaterialisbaseduponworkfundedandsupportedbythe
DepartmentofDefenseunderContractNo.FA8702-15-D-0002with
CarnegieMellonUniversityfortheoperationoftheSoftwareEn-
gineeringInstitute,afederallyfundedresearchanddevelopment
center.[DistributionStatementA]Thismaterialhasbeenapproved
for public release and unlimited distribution. Please see Copyright
notice for non-US Government use and distribution. (DM-0004369).
11ESEC/FSEâ€™20, November 8â€“13,2020, Virtual Event, USA Changjian Zhang, DavidGarlan,andEunsukKang
REFERENCES
[1]B. Alpern and F. B. Schneider. Defining liveness. Inf. Process. Lett. , 21(4):181â€“185,
1985.
[2] J. Annettand N. A.Stanton. TaskAnalysis . CRC Press,2000.
[3]A. Basiri, N. Behnam, R. de Rooij, L. Hochstein, L. Kosewski, J. Reynolds, and
C. Rosenthal. Chaos engineering. IEEESoftware ,33(3):35â€“41, May 2016.
[4]F.Belli,A.Hollmann,andW.E.Wong. Towardsscalablerobustnesstesting. In
2010FourthInternationalConferenceonSecureSoftwareIntegrationandReliability
Improvement ,pages208â€“216. IEEE,2010.
[5]R. Bloem, K. Chatterjee, K. Greimel, T. A. Henzinger, and B. Jobstmann.
Specification-centeredrobustness. In IndustrialEmbeddedSystems(SIES),2011
6thIEEEInternationalSymposiumon,SIES2011.Vasteras,Sweden,June15-17,2011 ,
pages 176â€“185, 2011.
[6]M. G. Bobaru, C. S. Pasareanu, and D. Giannakopoulou. Automated assume-
guaranteereasoningbyabstractionrefinement. In InternationalConferenceon
Computer AidedVerification(CAV) ,volume5123, pages135â€“148, 2008.
[7]M. L. Bolton. A task-based taxonomy of erroneous human behavior. Int. J. Hum.
Comput. Stud. ,108:105â€“121, 2017.
[8]M.L.BoltonandE.J.Bass. Enhancedoperatorfunctionmodel:Agenerichuman
task behavior modeling language. In 2009 IEEE International Conference on
Systems, Manand Cybernetics ,pages2904â€“2911. IEEE, 2009.
[9]M.L.BoltonandE.J.Bass. Generatingerroneoushumanbehaviorfromstrategic
knowledge in task models and evaluating its impact on system safety with
model checking. IEEE Transactions on Systems,Man, and Cybernetics: Systems ,
43(6):1314â€“1327,2013.
[10]M.L.Bolton,E.J.Bass,andR.I.Siminiceanu. Generatingphenotypicalerroneous
humanbehaviortoevaluatehuman-automationinteractionusingmodelchecking.
InternationalJournalof HumanComputer Studies ,70(11):888â€“906, 2012.
[11]M.L.Bolton,R.I.Siminiceanu,andE.J.Bass. Asystematicapproachtomodel
checking human-automation interaction using task analytic models. IEEE Trans-
actions on Systems, Man, and Cybernetics Part A:Systems and Humans , 41(5):961â€“
976, 2011.
[12]G.Brunsand P. Godefroid. Model checking partial statespaceswith 3-valued
temporal logics. In Computer Aided Verification, 11th International Conference,
CAV â€™99, Trento,Italy, July6-10,1999, Proceedings ,pages274â€“287, 1999.
[13]A. Burns and R. I. Davis. A survey of research into mixed criticality systems.
ACMComput. Surv. ,50(6):82:1â€“82:37,2018.
[14] E. M.Clarke,O.Grumberg, and D.Peled. Model checking . MIT Press, 2001.
[15]J. M. Cobleigh, D. Giannakopoulou, and C. S. P Ë‡asË‡areanu. Learning Assumptions
for Compositional Verification. In International Conference on Tools and Algo-
rithms for the Construction and Analysis of Systems , pages 331â€“346. Springer,
2003.
[16]M. Famelis,R. Salay, andM. Chechik. Partial models: Towards modeling andrea-
soningwithuncertainty. In 34thInternationalConferenceonSoftwareEngineering,
ICSE 2012, Zurich, Switzerland ,pages 573â€“583, 2012.
[17]J.-C. Fernandez, L. Mounier, and C. Pachon. A model-based approach for ro-
bustnesstesting. In IFIPInternationalConferenceonTestingofCommunicating
Systems,pages333â€“348. Springer,2005.
[18]M.J.Fischer,N.A.Lynch,andM.Paterson. Impossibilityofdistributedconsensus
with onefaulty process. J. ACM,32(2):374â€“382,1985.
[19]D. Giannakopoulou, J. Kramer, and J. Magee. Practical behaviour analysis for
distributedsoftwarearchitectures. In UKProgrammableNetworksandTelecom-
munications Workshop ,1998.
[20]D.Giannakopoulou,C.S.P Ë‡asË‡areanu,andH.Barringer. Assumptiongeneration
for software component verification. In Proceedings - ASE 2002: 17th IEEE In-
ternational Conference on Automated Software Engineering , pages 3â€“12. IEEE,
2002.[21]P. Godefroid,M. Y. Levin, D. A.Molnar, etal. Automated whiteboxfuzz testing.
InNDSS,volume8, pages151â€“166, 2008.
[22]T. A. Henzinger, J. Otop, and R. Samanta. Lipschitz robustness of finite-state
transducers.In 34thInternationalConferenceonFoundationofSoftwareTechnology
and Theoretical Computer Science, FSTTCS 2014, December 15-17, 2014, New Delhi,
India,pages431â€“443, 2014.
[23]T. A. Henzinger, J. Otop, and R. Samanta. Lipschitz robustness of timed I/O
systems. In Verification, Model Checking, and Abstract Interpretation - 17th Inter-
national Conference, VMCAI 2016, St. Petersburg, FL, USA, January 17-19, 2016.
Proceedings ,pages250â€“267, 2016.
[24]E. Hollnagel. Cognitive Reliability and Error Analysis Method (CREAM) . Elsevier
Science,1998.
[25]J.E.Hopcroft,R.Motwani,andJ.D.Ullman. Introductiontoautomatatheory,
languages, and computation. Acm SigactNews ,32(1):60â€“65, 2001.
[26]M. Huth, R. Jagadeesan, and D. A. Schmidt. Modal transition systems: A founda-
tion for three-valued program analysis. In Programming Languages and Systems,
10thEuropeanSymposiumonProgramming,ESOP2001HeldasPartoftheJoint
European Conferences on Theory and Practice of Software, ETAPS 2001 Genova,
Italy,April 2-6,2001, Proceedings ,pages155â€“169, 2001.
[27]D.JacksonandE.Kang.Separationofconcernsfordependablesoftwaredesign.In
ProceedingsoftheWorkshoponFutureofSoftwareEngineeringResearch,FoSER2010,
at the 18th ACM SIGSOFT International Symposium on Foundations of Software
Engineering, 2010, Santa Fe, NM, USA, November 7-11, 2010 , pages 173â€“176, 2010.
[28]C. B. Jones. Specification and design of (parallel) programs. In Information
Processing 83, Proceedingsof theIFIP9thWorld ComputerCongress, Paris, France,
September 19-23,1983 ,pages321â€“332, 1983.
[29]L. Lamport. Proving the correctness of multiprocess programs. IEEE Trans.
Software Eng. ,3(2):125â€“143, 1977.
[30]L. Lamport, R. E. Shostak, and M. C. Pease. The byzantine generals problem.
ACMTrans.Program. Lang.Syst. ,4(3):382â€“401, 1982.
[31]K. G. Larsen and B. Thomsen. A modal process logic. In Proceedings of the Third
AnnualSymposiumonLogic inComputer Science(LICSâ€™88),Edinburgh, Scotland,
UK, July5-8, 1988 ,pages203â€“210, 1988.
[32]N.G.Leveson andC. S.Turner. Investigation ofthetherac-25accidents. IEEE
Computer ,26(7):18â€“41, 1993.
[33] J. Magee and J. Kramer. State modelsand java programs . wiley Hoboken,1999.
[34]J. Magee, J. Kramer, and D. Giannakopoulou. Behaviour analysis of software
architectures. In Working Conference on Software Architecture , pages 35â€“49.
Springer,1999.
[35]H. Petroski. To engineer is human: The role of failure in successful design . St
Martins Press,1985.
[36]A. Pnueli. The temporal logic of programs. In 18th Annual Symposium on
Foundations of Computer Science, Providence, Rhode Island, USA, 31 October - 1
November 1977 ,pages 46â€“57,1977.
[37]J. Rasmussen. Risk management in a dynamic society: a modelling problem.
SafetyScience ,27(2):183 â€“213, 1997.
[38] J. Reason. HumanError . CambridgeUniversity Press,New York, 1990.
[39]A. Shahrokni and R. Feldt. A systematic review of software robustness. Informa-
tion andSoftware Technology ,55(1):1â€“17, 2013.
[40]P.Tabuada,A.Balkan,S.Y.Caliskan,Y.Shoukry,andR.Majumdar. Input-output
robustnessfordiscretesystems. In Proceedingsofthe12thInternationalConference
on Embedded Software, EMSOFT 2012, part of the Eighth Embedded Systems Week,
ESWeek2012, Tampere,Finland,October7-12,2012 ,pages217â€“226, 2012.
[41]P.TabuadaandD.Neider. Robustlineartemporallogic. In 25thEACSLAnnual
ConferenceonComputerScienceLogic,CSL2016,August29-September1,2016,
Marseille,France ,pages10:1â€“10:21, 2016.
[42]G. Tel.Introduction to Distributed Algorithms . Cambridge University Press, 2
edition, 2000.
[43] K. Zhouand J. C.Doyle. Essentials of RobustControl . Prentice-Hall, 1998.
12