Abacus: Precise Side-Channel Analysis
Qinkun Bao, Zihao Wang, Xiaoting Li, James R. Larusy, and Dinghao Wu
The Pennsylvania State University
yEPFL
Abstract ‚ÄîSide-channel attacks allow adversaries to infer sensi-
tive information from non-functional characteristics. Prior side-
channel detection work is able to identify numerous potential
vulnerabilities. However, in practice, many such vulnerabilities
leak a negligible amount of sensitive information, and thus
developers are often reluctant to address them. Existing tools
do not provide information to evaluate a leak‚Äôs severity, such as
the number of leaked bits.
To address this issue, we propose a new program analysis
method to precisely quantify the leaked information in a single-
trace attack through side-channels. It can identify covert infor-
mation Ô¨Çows in programs that expose conÔ¨Ådential information
and can reason about security Ô¨Çaws that would otherwise be
difÔ¨Åcult, if not impossible, for a developer to Ô¨Ånd. We model an
attacker‚Äôs observation of each leakage site as a constraint. We
use symbolic execution to generate these constraints and then
run Monte Carlo sampling to estimate the number of leaked bits
for each leakage site. By applying the Central Limit Theorem,
we provide an error bound for these estimations.
We have implemented the technique in a tool called Abacus,
which not only Ô¨Ånds very Ô¨Åne-grained side-channel vulnera-
bilities but also estimates how many bits are leaked. Abacus
outperforms existing dynamic side-channel detection tools in
performance and accuracy. We evaluate Abacus on OpenSSL,
mbedTLS, Libgcrypt, and Monocypher. Our results demonstrate
that most reported vulnerabilities are difÔ¨Åcult to exploit in
practice and should be de-prioritized by developers. We also Ô¨Ånd
several sensitive vulnerabilities that are missed by the existing
tools. We conÔ¨Årm those vulnerabilities with manual checks and
by contacting the developers.
I. I NTRODUCTION
Side channels are ubiquitous in modern computer systems
as sensitive information can leak through many mechanisms
such as power, electromagnetic radiation, and even sound [1]‚Äì
[5]. Among them, software side-channel attacks, such as cache
attacks, memory page attacks, and controlled-channel attacks,
are especially problematic as they do not require physical
proximity [6]‚Äì[11]. These attacks arises from shared micro-
architectural components in a computer processor. By observ-
ing inadvertent interactions between two programs, attackers
can infer program execution Ô¨Çows that manipulate secrets and
guess secrets such as encryption keys [12]‚Äì[15].
Many side-channel attacks originate in two code patterns:
data Ô¨Çow from secrets to load addresses and data Ô¨Çow from
secrets to branch conditions. We refer to them as secret-
dependent data accesses and control Ô¨Çows, respectively.
Recent work [14], [16]‚Äì[20] can detect many side-channel
vulnerabilities. For example, DATA [16] reports 2,248 poten-
tial leakage sites for the RSA implementation in OpenSSL
1.1.0f. Further analysis shows 1,510 leaks can be dismissed.
But that leaves 460 data-access leaks and 278 control-Ô¨Çowleaks. Many of these vulnerabilities have not been Ô¨Åxed by
developers for a variety of reasons. First, some vulnerable
implementations perform better. For example, RSA implemen-
tations usually adopt the CRT optimization, which is faster but
vulnerable to fault attacks [21]. Second, Ô¨Åxing vulnerabilities
can introduce new weaknesses. Third, most vulnerabilities
pose a negligible risk. Although some vulnerabilities result
in the key being entirely compromised [21], [22], many
others are less severe in reality. Therefore, we need a proper
quantiÔ¨Åcation metric to assess the sensitivity of side-channel
vulnerabilities, so a developer can efÔ¨Åciently triage them.
Previous work [20], [23] can identify numerous leakages
or even provide an upper bound on the amount of leakage,
which is useful to verify that an implementation is secure
if it incurs zero leakage. However, these techniques cannot
quantify the severity of a leak because they over approximate
the leakage. For example, CacheAudit [20] reports that the
upper-bound leakage of AES-128 exceeds the original key
size. Besides, existing side-channel quantiÔ¨Åcation work [20],
[23] assumes an attacker runs the target program multiple
times with different input secrets and calculates an ‚Äúaverage‚Äù
estimation, which is different from real attack scenarios when
the secret that an attacker wants to retrieve is Ô¨Åxed. As a
consequence, those results are less useful to assess the severity
level of each leakage site.
To overcome these limitations, we propose a novel method
to quantify information leakage precisely. We quantify the
number of bits that can leak during a real execution and
deÔ¨Åne the amount of leaked information as the cardinality
of possible secrets based on an attacker‚Äôs observation. Before
an attack, an adversary has a large but Ô¨Ånite input space.
Whenever the adversary observes a leakage site, they can
eliminate some impossible inputs and reduce the input space‚Äôs
size. In an extreme case, if the input space‚Äôs size reduces
to one, an adversary has determined the input, which means
all secret information (e.g., the entire secret key) is leaked.
By counting the number of inputs [24], we can quantify the
information leakage precisely. We use symbolic execution to
generate constraints to model the relation between the original
sensitive input and an attacker‚Äôs observations. Symbolic exe-
cution provides Ô¨Åne-grained information, but it is expensive
to compute. Therefore, prior symbolic execution work [14],
[18], [19] either analyzes only small programs or applies
domain knowledge [14] to simplify the analysis. We examine
the bottleneck of the trace-oriented symbolic execution and
optimize it to work for real-world crypto-systems.
We have implemented the proposed technique in a tool
7972021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)
1558-1225/21/$31.00 ¬©2021 IEEE
DOI 10.1109/ICSE43902.2021.00078
unsigned long long r;
int secret[32];
...
while (i>0){
r = (r *r) % n;
if(secret[--i] == 1)
r = (r *x) % n;
}
Figure 1: Secret-dependent
control-Ô¨Çow transfersstatic char FSb[256] = {...}
...
uint32 _t a = *RK++ ^ \
(FSb[(secret)) ^
(FSb[(secret >> 8)] << 8 ) ^
(FSb[(secret >>16)] << 16 ) ^
(FSb[(secret >>24)] << 24 );
...
Figure 2: Secret-dependent
data accesses
called Abacus and demonstrated it on real-world crypto li-
braries, including OpenSSL, mbedTLS, Libgcrypt, and Mono-
cypher. We collect execution traces of these libraries and apply
symbolic execution to each instruction. We model each side-
channel leak as a logic formula. These formulas precisely
model side-channel vulnerabilities. Then we use the conjunc-
tion of those formulas to model the leaks at a statement that ap-
pears in different location in the execution trace Ô¨Åle (e.g., leaks
inside a loop). Finally, we introduce a Monte Carlo sampling
method to estimate the information leakage. The experimental
results conÔ¨Årm that Abacus precisely identiÔ¨Åes previously
known vulnerabilities and reports how much information is
leaked and which byte in the original sensitive buffer is leaked.
We also test Abacus on side-channel-free algorithms. Abacus
produces no false positives. The result also shows the newer
version of crypto libraries leak less information than earlier
versions. Abacus also discovers new vulnerabilities. With the
help of Abacus , we conÔ¨Årm that some of these vulnerabilities
are severe.
In summary, we make the following contributions:
We propose a novel method that can quantify Ô¨Åne-grained
leaked information from side-channel vulnerabilities that
result from actual attack scenarios. Our approach dif-
fers from previous ones in that we model real attack
scenarios for one execution. We model the information
quantiÔ¨Åcation problem as a counting problem and use a
Monte Carlo sampling method to estimate the information
leakage.
We implement the method into a tool and apply it to
several pieces of real software. Abacus successfully
identiÔ¨Åes previous unknown and known side-channel vul-
nerabilities and calculates the corresponding information
leakage. Our results are useful in practice. The leakage
estimates and the corresponding trigger inputs can help
developers to triage and Ô¨Åx the vulnerabilities.
II. B ACKGROUND AND THREAT MODEL
A. Address-based Side-channels
Side channels leak sensitive information unintentionally
through different execution behaviors caused by shared hard-
ware components (e.g., CPU cache, TLB, and DRAM) in
modern computer systems [10]‚Äì[12], [22], [22], [25], [26].
The key intuition is that many of those side-channel attacks
happen when a program accesses different memory addresses
depending on the values in sensitive inputs . As shown in
Figure 1 and Figure 2, if a program executes different patterns
of control transfers or data accesses when it processes differentsensitive inputs, the program may be vulnerable to side-
channel attacks. Different side-channels can be exploited to
retrieve information at various granularities. For example,
cache side channels observe cache accesses at the level of
cache sets [11], cache lines [22], or Ô¨Åner granularities [27],
[28]. Other types of side-channels, such as controlled-channel
attack [6], can observe the memory accesses at the granularity
of memory pages.
B. Exisiting Information Leakage QuantiÔ¨Åcation
Information theory [29] tells us that if an event ethat occurs
with the probability p(e), we receive
I= log2p(e)
bits of information by knowing the event ehappened. Con-
sidering a char variable a, with one byte size in a C program,
its possible values range from 0 to 255. If we observe a
equals 1, without prior domain knowledge, the probability of
this observation is1
256. So, we obtain log(1
256) = 8 bits
of information, which is exactly the size of a char variable.
Existing work on information leakage quantiÔ¨Åcation typically
use Shannon entropy [17], [30], min-entropy [31], or max-
entropy [20], [32]. In these frameworks, the input sensitive
information Kis considered to be a random variable.
Letkbe one of the possible value of K. The Shannon
entropyH(K)is deÔ¨Åned as
H(K) = X
k2Kp(k) log2(p(k))
Shannon entropy can be used to quantify the initial uncer-
tainty about sensitive information. It measures the amount of
information in a system.
Min-entropy describes the information leaks for a program
in terms of its most likely input. For example, min-entropy can
be used to describe the highest chance of success in guessing
a password by using the most common password.
min-entropy = log2(pmax)
Max-entropy is deÔ¨Åned solely on the number of possible
observations.
max -entropy = log2n
As it is easy to compute, most recent works [20], [32] use max-
entropy as the deÔ¨Ånition of the amount of leaked information.
C. Threat Model
We assume that an attacker shares the same hardware plat-
form with the target. The attacker attempts to retrieve sensitive
information through address-based side-channel attacks. The
attacker has no direct access to the target‚Äôs memory or cache,
but it can probe its memory or cache at each program point. In
reality, the attacker will face many possible obstacles such as
the noisy observations of the memory or cache. However, for
this project, we assume the attacker has noise-free observations
as in previous work [14], [18], [20]. The threat model captures
most cache-based and address-based side-channel attacks. We
798only consider deterministic programs and assume an attacker
has access to the source code or binary executable of the target
program.
III.ABACUS : PRECISE SIDE-CHANNEL ANALYSIS
In this section, we discuss how Abacus quantiÔ¨Åes the
amount of leaked information. We Ô¨Årst present the limitation of
existing quantiÔ¨Åcation metrics. Then, we introduce our model,
the mathematical notation used in the paper, and our method.
A. Problem Setting
Existing static side-channel quantiÔ¨Åcation works [17], [20],
[33], [34] deÔ¨Åne information leakage using max entropy
or Shannon entropy. If zero bits of information leakage is
reported, a program is secure. However, when a tool using
these metrics reports leakage, it is the ‚Äúaverage‚Äù leakage. In a
real attack, the leakage could be dramatically different.
1char key[9] = input();
2if(strcmp(key, "password")) // leakage site C
3 pass(); // branch 1
4else
5 fail(); // branch 2
Figure 3: A dummy password checker
Consider a password checker sketched in Figure 3. The
password checker takes an 8-byte char array (exclude NULL
character) and checks if the input is the correct password. If
an attacker uses a side-channel attack to determine that the
code executes branch f1g, they can infer the password equals
to ‚Äúpassword‚Äù, in which case the attacker retrieves the full
password. Therefore, the total leaked information should be
64 bits, which equals to the size of the original sensitive input
when the code executes branch 1.
However, prior static approaches cannot precisely capture
the amount of leakage. According to the deÔ¨Ånition of Shan-
non entropy, the leakage will be1
264log21
264+264 1
264
log2264 1
2640bits. Max-entropy is deÔ¨Åned from the num-
ber of possible observations. Because the program has two
branches, tools based on max-entropy will report the code has
alog22 = 1 bit leakage.
Random Key (K)
Fixed Key (K)Target Program (P)
Observation (O)Observation (O)(a) Previous Model(b) Real AttackTarget Program (P)
Figure 4: The gap between a real attack and previous models
Both approaches fail to tell how much information is leaked
during the actual execution. The problem [35] with existing
methods is that their approaches do not consider input values
and real runtime information. They assume an attacker runs
the program multiple times with many different or randomsensitive inputs. As shown in Figure 4 (a), both Shannon
entropy and max-entropy give an ‚Äúaverage‚Äù estimate of the
information leakage. However, generating random inputs is
not the typical scenario for an adversary launching a side-
channel attack. In a typical attack, the adversary wants to
retrieve sensitive information, which is typically Ô¨Åxed (e.g.,
AES keys). The adversary performs their attack over and over
again with Ô¨Åxed input and guess the value bit by bit (e.g.,
Kocher‚Äôs timing attacks [36]), as in Figure 4 (b). We need a
theory for dynamic analysis that says an attack leaks xbits of
secret information, where xis useful in estimating the sensitive
level of the vulnerability. However, all previous methods fail
for real attack models. This is the Ô¨Årst challenge we face
(Challenge C1) .
B. Notation
In the section, we give necessary deÔ¨Ånitions and notation
for dealing with programs and side-channels. We use capital
letters (e.g., A) to represent a set. jAjrepresents the cardinality
of setA. We use corresponding lower case letters to represent
one element of the set (e.g., a2A).
We assume a program ( ) hasKas its sensitive input.
Kshould be a Ô¨Ånite set of keys. The program also takes
known messages Mas its input. During an AES encryption,
for example, is the encryption function. Kis the set of all
possible AES keys, and Mrepresents the set consisting of
all plaintext messages to be encrypted. In a real execution, an
adversary may have some observations ( O) of the program.
Examples of those observations include timing, CPU usages,
and electromagnetic signals (EM). This paper only uses secret-
dependent control Ô¨Çows and secret-dependent data accesses as
observations.
With the above deÔ¨Ånition, we have the following mapping
between,K,M, andO:
(K;M )!O
We model a side-channel in the following way. An adversary
does not have access to K, but he knows ,M, andO. For one
execution of a deterministic program, once k2Kandm2M
are Ô¨Åxed, the observation ( o2O) should also be determined.
An attacker knows ,o, andm. The attacker wants to infer the
value ofk. We useKoto denote the set of possible kvalues
that produce the same observation: Ko=fk2Kj(k;m)!
og
Then the problem of quantifying the amount of leaked
information can be restated as the following question:
How much uncertainty of Kis reduced if an attacker knows
,m, ando?
C. Theoretical Analysis (Solution to Challenge C1)
In information theory, the mutual information ( I) is a
measure of the mutual dependence between two variables. We
useIto describe the dependence between original sensitive
keys (K) and attackers‚Äô observations ( O), which is deÔ¨Åned as:
I(K;O) =X
k2KX
o2Op(k;o) log2p(k;o)
p(k)p(o)(1)
799wherep(k;o)is the joint probability mass function of K
andO. Alternatively, the mutual information can also be
equivalently expressed as:
I(K;O) =H(K) H(KjO) (2)
H(KjO)is the entropy of Kunder the condition O. It
quantiÔ¨Åes the uncertainty of K, given the value of O. In other
words, the conditional entropy H(KjO)marks the uncertainty
aboutKafter an adversary has made observations O.
H(KjO) = X
o2Op(o)X
k2Kp(kjo) log2p(kjo) (3)
In this project, we hope for a very precise deÔ¨Ånition of infor-
mation leakages. Suppose an attacker runs the target program
with one input, we want to know how much information they
can infer by observing the memory access patterns ( o). We
come to the simple formulation [31], [37] that
Information leakage =
Initial uncertainty  Remaining uncertainty :
Next, we compare the Eq. (2) with the above formulation,
we Ô¨ÅndH(K)is the Initial uncertainty andH(KjO)is
Remaining uncertainty . During a real attack, the observation
(o) is known. Thus we have H(KjO) =H(Kjo). Therefore,
we deÔ¨Åne the amount of leaked information as
Leakage =H(K) H(Kjo)
For a program ( ) without any domain information, all
possible sensitive inputs appear equally likely. Therefore, for
anyk2K,p(k) =1
jKj. We have
H(K) =X
k2K1
jKjlog2jKj= log2jKj
For anyk02KnKo,p(k0jo) = 0 . We get
H(K;o) = X
k2Kop(kjo) log2p(kjo)
 X
k`2(KnKo)p(k0jo) log2p(k0jo)
=X
k2Ko1
jKojlog2jKoj
= log2jKoj
DeÔ¨Ånition 1. Given a program with the input set K, an
adversary has the observation owhen the input k2Ko. We
denote it as
(Ko;m)!o
The amount of leaked information L(k)!obased on the
observation ( o) is
L(k)!o= log2jKj log2jKoj
The above deÔ¨Ånition can be understood in an intuitive way.
Suppose an attacker guesses a 128-bit encryption key. Without
any domain knowledge, they can Ô¨Ånd the key by performing anexhaustive search over 2128possible keys. However, assume
the program has a side-channel leakage site. After the program
Ô¨Ånishes execution, the attacker has some observations and only
needs to Ô¨Ånd the key by performing an exhaustive search over
2120possible keys. Then, we say that 8 bits of the information
is leaked. In this example, 2128is the size of Kand2120is
the size ofKo.
With this deÔ¨Ånition, if an attacker observes that the code
in Figure 3 executes branch 1, then Ko1=f\password"g.
Therefore, the information leakage LP(k)=o1= log2264 
log21 = 64 bits, which means the key is entirely leaked.
If the attacker observes the code hits branch 2, the leaked
information is LP(k)=o2= log2264 log2(264 1)0bits.
As the size of input-sensitive information is usually public,
the problem of quantifying the leaked information is equivalent
to the problem of estimating the size of input key jKojunder
the condition o2O.
D. Our Conceptual Framework
We now discuss how to model observations ( O), which are
the direct information that an adversary can obtain during a
side-channel attack.
During an execution, a program ( ) has many temporary
values (ti2T). Once(program),k(secret), and m(mes-
sage, public) are determined, tiis also Ô¨Åxed (for deterministic
programs). Therefore, ti=fi(;k;m ), wherefiis a function
that maps between tiand (,k,m).
In the paper, we consider two code patterns that can
be exploited to infer sensitive information by an attacker,
secret-dependent control transfers andsecret-dependent data
accesses .
1) Secret-dependent Control Transfers: A control-Ô¨Çow path
is secret-dependent if different input-sensitive keys ( K) can
lead to different branch conditions. We deÔ¨Åne a branch to be
secret-dependent if:
9ki1;ki22K; fi(;ki1;m)6=fi(;ki2;m)
An adversary can observe which branch the code executes
if the branch condition equals tb. We use the constraint
ci:fi(;k;m ) =tbto model the observation ( o) on secret-
dependent control-transfers.
2) Secret-dependent Data Accesses: Similar to secret-
dependent control-Ô¨Çow transfers, a data access operation is
secret-dependent if different input sensitive keys ( K) cause
access to different memory addresses. We use the model from
CacheD [14]. The low Lbits of the address are generally
unimportant in side-channels.
A data access is secret-dependent if:
9ki1;ki22K; fi(;ki1;m)>>L6=fi(;ki2;m)>>L
If the memory access equals to tb, we can use the constraint
ci:fi(;k;m )>> L =tb>> L to model the observation
of a secret-dependent data access.
800IV. S CALING TO REAL-WORLD CRYPTO SYSTEMS
In the previous section, we propose an information leakage
deÔ¨Ånition for realistic attack scenarios to model two types
of address-based side-channel leakages and showed how to
quantify them by calculating the number of input keys ( Ko)
that satisfy the formulas. Intuitively, we can use symbolic
execution to capture math formulas and model counting to
obtain the number of satisfying input keys ( Ko). However,
preliminary experiments showed that this approach was far too
expensive to use with real-world applications. In this section,
we discuss the bottlenecks in this approach and propose a
practical solution.
In general, Abacus faces the following performance chal-
lenges in scaling to production-system crypto analysis .
Symbolic execution ( Challenge C2 )
Counting the number of items in Ko(Challenge C3 )
A. Trace-oriented Symbolic Execution
Symbolic execution is notorious for its high performance
cost. Previous trace-oriented symbolic execution work [14],
[35] has serious performance bottlenecks. As a result, these
approaches either apply only to small programs [35] or re-
quire domain knowledge [38] to simplify the analysis. We
implement the approach presented in ¬ßIII and model the
side-channels as formulas. While the tools can analyze some
simple cases such as AES, it cannot handle complicated
examples such as RSA. We observe that Ô¨Ånding side-channels
using symbolic execution differs from traditional symbolic
execution, and it can be optimized to be as efÔ¨Åcient as other
methods.
1) Interpret Instructions Symbolically: Existing binary
analysis frameworks [39]‚Äì[41] translate machine instructions
into intermediate languages (IR) to simplify analysis since the
variety of machine instructions is enormous, and their seman-
tics is complex. The Intel Developer Manual [42] documents
more than 1000 different x86 instructions. Unfortunately, the
IR layer, which reduces the workload of these tools, is not
suitable for side-channels analysis because IR-based or source
code side-channels analyses do not represent the executed
instructions accurate enough to analyze fully their control
and memory accesses. For example, a compiler may use
conditional moves or bitwise operations to eliminate branches.
Also, as some IRs are not a superset or a subset of ISA, it is
hard to rule out conditional jumps introduced by IR and add
real branches eliminated by IR transformations.
Moreover, the IR causes signiÔ¨Åcant overhead [43]. Trans-
lating machine instructions into IR is time-consuming. For
example, REIL IR [44], adopted in CacheS [19], has multiple
transform processes, from binary to VEX IR, BAP IR, and
Ô¨Ånally REIL IR. Also, IR increases the total number of in-
structions. For example, x86 instruction test eax, eax transfers
into 18 REIL IR instructions.
Our Solution: We abandoned IR and expended the effort
to implement symbolic execution directly on x86 instructions.
Table I shows that eliminating the IR reduces the number of
instructions examined during analysis. Previous works [43]Table I: The number of x86, REIL IR, and VEX IR instructions
on the traces of crypto programs.
Number of
x86 InstructionsNumber of
VEX IRNumber of
REIL IR
AES OpenSSL 0.9.7 1;704 23 ;938 (15x) 62;045 (36x)
DES OpenSSL 0.9.7 2;976 41 ;897 (15x) 100;365 (33x)
RSA OpenSSL 0.9.7 1:61072:4108(15x) 5:9108(37x)
RSA mbedTLS 2.5 2:21073:1108(15x) 8:6108(39x)
also adopted a similar approach to speed up fuzzing. Our
implementation differs from that work in two aspects: 1) We
use complete constraints. 2) We run the symbolic execution on
one execution path each time. Our approach is approximately
30 times faster than using an IR (transferring ISA into IR and
symbolically executing it).
2) Constraint Solving: As discussed in ¬ßIII-D, the problem
of identifying side-channels can be reduced to the question:
Can we Ô¨Ånd two different input variables k1;k22K
that satisfy the formula fa(k1)6=fa(k2)?
Existing approaches rely on satisÔ¨Åability modulo theories
(SMT) solvers (e.g., Z3 [45]) to Ô¨Ånd satisfying assignments
tok1andk2. While this is a universal approach to solving
constraints, for constraints of this form, using custom heuris-
tics and testing is much more efÔ¨Åcient in practice. Constraint
solving is a decision problem expressed in logic formulas.
SMT solvers transfer the SMT formula into the boolean
conjunctive normal form (CNF) and feed it into the internal
boolean satisÔ¨Åability problem (SAT) solver. The translation
process, called ‚Äúbit blasting‚Äù, is time-consuming. Also, as the
SAT problem is a well-known NP-complete problem, it is hard
to deal when it comes to practical uses with huge formulas.
Despite the rapid improvement in SMT solvers in recent years,
constraint solving remains one of the obstacles to scaling the
analysis of real-world crypto-systems.
Our Solution: Instead of feeding the formula fa(k1)6=
fa(k2)into a SMT solver, we randomly pick k1;k22Kand
test them if they satisfy the formula. Our solution is based
on the following intuition. For most combination of (k1;k2),
fa(k1)6=fa(k2). As long as fais not a constant function,
suchk1;k2must exist. For example, suppose each time we
only have 5% chance to Ô¨Ånd such k1;k2, then after we test
with different input combination with 100 times, we have 1 
(1 0:05)100= 99:6%chance Ô¨Ånd such k1;k2. This type of
random algorithm works well for our problem.
B. Counting the Solutions
In this section, we present the algorithm to calculate the
information leakage based on DeÔ¨Ånition 1 (¬ßIII), answering
toChallenge C3 .
1) Problem Statement: For each leakage site, we model
it with a constraint using the method presented in ¬ßIII-D.
Suppose the address of the leakage site is i, we usecito
denote the constraint that models its side-channel leakage.
According to the DeÔ¨Ånition 1, to calculate the amount of
leaked information, the key is to calculate the cardinality of
Ko. Suppose an attacker can observe nleakage sites, and each
leakage site has the following constraints: c1;c2;:::;cn
respectively. The total leakage can be calculated from the
801constraintct(1;2;:::;n) =c1^c2^:::^cn. A simple
method is to pick elements kfromKand check if an element
is also contained in Ko. Assumeqelements satisfy this
condition. In expectation, we can usek
qto approximate the
value ofjKj
jKoj.
However, the above sampling method fails in practice due
to the following two problems:
1) The curse of dimensionality problem. ct(1;:::;n)is
the conjunction of many constraints. Therefore, the input
variables of each constraints will also be the input
variables of the ct(1;:::;n). The sampling method
fails asngrows.
2) The number of satisfying assignments could be expo-
nentially small. According to Chernoff bound, we need
exponentially many samples to get a tight bound.
However, despite above two problems, we also observe two
characteristics of the problem:
1)ct(1;2;:::;n)is the conjunction of several short con-
straintsci. The set containing the input variables of ci
is the subset of the input variables of ct(1;2;:::;n).
Some constraints have completely different input vari-
ables from other constraints.
2) Each time when we sample ct(1;2;:::;n)with a
point, the sampling result is SatisÔ¨Åed or not Not SatisÔ¨Åed .
The outcome does not depend on the result of previous
experiments. Also, as the amount of leaked information
is calculated by a logfunction, we need not exactly count
the number of solutions for a given constraint.
In regard to the above problems, we present our methods.
First, we split ct(1;2;:::;n)into several independent con-
straint groups. After that, we run a multi-step sampling method
for each constraint.
2) Maximum Independent Partition: For a constraint ci,
we deÔ¨Åne function , which maps the constraint into a set of
different input symbols. For example, (k1 +k2>128) =
fk1;k2g.
DeÔ¨Ånition 2. Given two constraints cmandcn, we call them
independent iff
(cm)\(cn) =?
Based on the DeÔ¨Ånition 2, we can split the constraint
ct(1;2;:::;n)into several independent constraints. There
are many partitions. For our project, we are interested in the
following one.
DeÔ¨Ånition 3. For the constraint ct(1;2;:::;n), we call
the constraint group g1;g2;:::;gmthe maximum independent
partition of ct(1;2;:::;n)iff
1)g1^g2^:::^gm=ct(1;2;:::;n)
2)8i;j2f1;:::;mgandi6=j;  (gi)\(gj) =?
3)For any other partitions h1;h2;:::;hm0satisfy 1) and
2),mm0
The reason we want a good partition of constraints is we
want to reduce the dimensions. For example, a good partition
ofF: (k1= 1)^(k2= 2)^(k3>4)^(k3 k4>10)would beg1: (k1= 1)g2: (k2= 2)g3: (k3>4)^(k3 k4>10)
We can sample each constraint independently and combine
them with Theorem 1.
Theorem 1. Letg1;g2;:::;gmbe a maximum independent
partition ofct(1;2;:::;n).Kcis the input set that satisÔ¨Åes
constraintc. We have the following equation in regard to the
size ofKc
jKct(1;2;:::; n)j=jKg1jjKg2j:::jKgnj
With Theorem 1, we change the problem of counting the
number of solutions to a complicated constraint in a high-
dimension space into counting solutions to several small
constraints. We compute the maximum independent partition
by iterating each iand applying the function over the
constrainti.
3) Multiple-step Monte Carlo Sampling: After we split
those constraints into several small constraints, we count the
number of solutions for each constraint. Even though the
dimension has been signiÔ¨Åcantly reduced by the previous step,
this is still a #P problem.
We apply the ‚Äúcounting by sampling‚Äù method. For the
constraintgi=ci1^ci2^;:::;^cij^;:::;^cim, if the solution
satisÔ¨Åesgi, it should also satisfy any constraint from ci1tocim.
In other words, Kcgishould be the subset of Kc1,Kc2, . . . ,
Kcm. We notice that ciusually has fewer inputs than gi. For
example, if cijhas only one 8-bit input variable, we can Ô¨Ånd
the exact solution set Kcijofcijby trying every possible 256
solution. After that, we only generate random input numbers
for the other input variables in constraint gi. With this simple
yet effective trick, we reduce the number of input while still
ensuring accuracy.
4) Error Estimation: Our result has a probabilistic guaran-
tee that the error of the estimated amount of leaked information
is less than 1 bit under the Central Limit Theorem (CLT) and
uncertainty propagation theorem.
Letnbe the number of samples and nsbe the number of
samples that satisfy the constraint C. Then we get ^p=ns
n. If
we repeat the experiment multiple times, each time we get a ^p.
As each ^pis independent and identically distributed, according
to the central limit theorem, the mean value should follow
the normal distributionp E(p)
pn!N(0;1). HereE(p)is the
mean value of p, andis the standard variance of p. If we
use the observed value ^pto calculate the standard deviation,
we can claim that we have 95%1conÔ¨Ådence that the error
p= p E(p)falls in the interval:
jpj1:96r
^p(1 ^p)
n
Since we use L= log2pto estimate the amount of leaked
information, we can have the following error propagation
formula L=p
pln 2by taking the derivative from DeÔ¨Åni-
tion 1. For Abacus , we want the error of estimated leaked
information ( L) to be less than 1 bit. So we getp
pln 21.
1For a normal distribution, 95% of variable pfall within two sigmas of
the mean.
802010101010110101010100010010100110100101010101100101010101111010100000110100001101010Binary CodeFormulasTraceReportpush ebpmov ebp, espsub esp, 0x18xor eax, eaxadd eax, ebxadd eax, 0x1f≈èk1&k2+k3 > 3 (k1+k3) % 64 = 1k1+k2+k4 = 0fead74b2: 2 bits k1 k2 k3fead74a1: 3 bits k1 k2 k4ffad3211: 5 bits k1 k2 k9ffad3111: 3 bits k1 k2 k7 k8ffadd12f: 2 bits k1 k2 k3‚Ä¶Figure 5: The workÔ¨Çow of Abacus .
Therefore, as long as n1:962(1 p)
p(ln 2)2, we have 95% conÔ¨Ådence
that the error of estimated leaked information is less than 1
bit. During the simulation, if nandpsatisfy this inequality,
the Monte Carlo simulation will terminate.
V. D ESIGN AND IMPLEMENTATION
A. Design
Figure 5 shows the three steps of Abacus . First, we run the
target program with a concrete input (sensitive information)
under the dynamic binary instrumentation (DBI) framework
to collect an execution trace. After that, we run the symbolic
execution to capture Ô¨Åne-grained semantic information for
each secret-dependent control-Ô¨Çow transfer and data access.
Finally, we run Monte Carlo (MC) simulation to estimate the
amount of leaked information.
1) Execution trace generation: The design goal of Aba-
cus is to estimate the information leakage as precisely as
possible. We run the target binary under a dynamic binary
instrumentation (DBI) tool to record execution traces and
runtime information. Once the sensitive information is loaded
into memory, we start to collect the trace. In this step, we
mark variables and buffers that hold the sensitive data by
either annotating the source code ( make_abacus_symbolic )
or telling the DBI tool of the memory address and the length
of secrets.
2) Instruction level symbolic execution: We model attack-
ers‚Äô observations from side-channel vulnerabilities with logic
formulas. Each formula captures the Ô¨Åne-grained information
between input secrets and leakage sites. The engine only
symbolically executes instruction that might be affected by
the input sensitive data. Abacus works on one path at a time.
The memory model is conceptually similar to other ofÔ¨Çine
executors (e.g., SAGE [46] and the trace-based executor of
BitBlaze [41]). That is, we use symbolic execution to track
secrets. When secrets are loaded into the memory, Abacus
starts to interpret instructions symbolically. We treat secrets as
symbols (S). For other variables, we use concrete values ( C)
from the execution. We do not know which instruction may
manipulate a secret until we execute it. For each instruction,
if all its operands and implicit memory accesses are concrete
values, we perform concrete calculation and update the des-
tination with the concrete value according to the instruction
semantics. Otherwise, we symbolically interpret the instruction
and update the destination with a formula.
3) Leakage estimation: We change the information leakage
quantiÔ¨Åcation problem into the counting problem. We propose
a Monte Carlo method to estimate the number of satisfying
solutions. With the help of the Central Limit Theorem (CLT),
we also give an error estimate with the probability, which
provides us with the precision guarantee .Table II: Evaluation results overview: Name, Side-channel
Leaks (Leaks), Secret-dependent Control-Ô¨Çows (CF), Secret-
dependent Data-Ô¨Çows (DF), The number of instructions (# In-
structions), Symbolic Execution (SE) and Monte Carlo (MC)
time.
Name # Leaks # CF # DF # Instructions SE MC
ms ms
AES168 0 68 39,855 512 1,052
AES268 0 68 39,855 520 1,057
AES475 0 75 1,704 231 9,199
AES588 0 88 1,350 36 1,924
AES688 0 88 1,350 35 1,961
AES788 0 88 1,420 36 2,161
AES888 0 88 1,586 43 1,631
DES115 0 15 4,596 58 162
DES215 0 15 4,596 57 162
DES46 0 6 2,976 163 4,677
DES58 0 8 2,593 166 6,509
DES68 0 8 2,593 165 5,975
DES78 0 8 4,260 182 5,292
DES86 0 6 8,272 229 5,152
seconds seconds
Chacha2030 0 0 149,353 2 0
Poly130530 0 0 1,213,937 15 0
Argon2i30 0 0 4,595,142 37 0
Ed2551930 0 0 5,713,619 271 0
ECDSA16 6 0 4,214,946 48 31
ECDSA24 4 0 4,192,558 102 1639
ECDSA55 4 1 8,248,322 101 62
ECDSA65 4 1 8,263,599 100 58
ECDSA75 4 1 6,100,465 76 42
ECDSA80 0 0 10,244,076 121 0
ECDSA90 0 0 9,266,191 102 59
minutes minutes
RSA16 6 0 22,109,246 39 41
RSA212 12 0 24,484,441 44 251
RSA4107 105 2 17,002,523 23 428
RSA538 27 11 14,468,307 29 436
RSA636 27 9 15,285,210 40 714
RSA731 22 9 16,390,750 34 490
RSA84 4 0 18,207,016 8 53
RSA98 8 0 18,536,796 5 780
RSA1011 9 2 9,527,231 2 38
RSA1114 14 0 10,513,606 14 503
RSA128 8 0 27,407,986 113 6560
Total 904 241 663 167,141,947 341m 10,232m
1mbedTLS 2.52mbedTLS 2.153Monocypher 3.0
4OpenSSL 0.9.75OpenSSL 1.0.2f6OpenSSL 1.0.2k
7OpenSSL 1.1.0f8OpenSSL 1.1.19OpenSSL 1.1.1g
10Libgcrypt 1.6.111Libgcrypt 1.7.312Libgcrypt 1.8.5
B. Implementation
Abacus consists of 16,729 lines of code in C++17 and
Python. It has three components: an Intel Pin tool that collects
the execution trace, the instruction-level symbolic execution
engine, and the backend that estimates the information leak-
age.
Our current implementation supports most Intel 32-bit in-
structions that are essential to Ô¨Ånd address-based side-channel
vulnerabilities, including bitwise operations, control transfer,
data movement, and logic instructions. The tool uses the real
values to update the registers and memory for instructions that
the implementation does not support. Therefore, the tool may
miss some leakages but will not raise false positives.
803VI. E VALUATION
We evaluate Abacus on widely used crypto libraries in-
cluding OpenSSL, mbedTLS, Libgcrypt and Monocypher. We
mark variables and buffers that store a secret. For DES and
AES, we mark symmetric keys as secrets. For RSA, we
mark private keys as secrets. For ECDSA, we mark nonces
and private keys as secrets. We build the source program
into 32-bit x86 Linux executables with GCC 7.5 running on
Ubuntu 16.04. We run our experiments on a 2.90GHz Intel
Xeon(R) E5-2690 CPU with 128GB RAM. The execution time
is calculated on a single-core. During our evaluation process,
we are interested in the following aspects:
1)Identifying side-channels leakages. IsAbacus effec-
tive to detect side-channels in real-world crypto sys-
tems? (¬ßVI-A and ¬ßVI-B)
2)Quantifying side-channel leakages. CanAbacus pre-
cisely report the number of leaked bits in crypto li-
braries? Is the number of leaked bits reported by Aba-
cus useful to justify the severity levels of each side-
channel vulnerability? (¬ßVI-C1, ¬ßVI-C2, ¬ßVI-C3)
A. Evaluation Result Overview
Table II summarizes the results. Abacus Ô¨Ånds 904 leaks
in the crypto libraries. Among these 904 leaks, 241 are due
to secret-dependent control-Ô¨Çow transfers and 663 are due to
secret-dependent data accesses.
Abacus also Ô¨Ånds that most side-channel vulnerabilities
leak very little information in practice, which conÔ¨Årms our
initial assumption. However, Abacus Ô¨Ånds some vulnera-
bilities with severe leakages. Prior research has conÔ¨Årmed
that some of these vulnerabilities can be exploited in real
attacks. With our tool, developers can distinguish non-critical
‚Äúvulnerabilities‚Äù from severe ones.
Symmetric encryption implementations in OpenSSL and
mbedTLS have signiÔ¨Åcant leakage due to their lookup table
implementations. Abacus conÔ¨Årms that those leakage comes
from table lookups. The new implementation of OpenSSL has
adopted several methods (e.g., one single S-box instead of four
lookup tables, smaller lookup tables) to mitigate the problem.
Those changes are rather easy but signiÔ¨Åcantly decrease the
total amount of leaked information as the quantiÔ¨Åcation result
indicates.
We also evaluate our tool on the RSA implementation. With
the optimization introduced in ¬ßIV, we need not apply domain
knowledge to simplify the analysis. Our tool identiÔ¨Åes all
leakage sites reported by CacheD [14] and Ô¨Ånd new leaks
in less time. We also Ô¨Ånd newer versions of RSA in OpenSSL
have fewer leaks. We will discuss the version changes and
corresponding leakages in ¬ßVI-C2.
Abacus can estimate how much information is leaked from
each vulnerability. During the evaluation, for each leakage site,
Abacus will stop once 1) it has 95% conÔ¨Ådence that the error
of the estimated leaked information is less than 1 bit, which
gives the leakage quantiÔ¨Åcation a precision guarantee , or 2)
it cannot reach the termination condition after 10 minutes. Inthe latter case, it means Abacus cannot estimate the amount
of leakage with a probabilistic guarantee. We manually check
these leakage sites and Ô¨Ånd most of them are quite severe. We
will present the details in the subsequent sections.
B. Comparison with the Existing Tools
In this section, we compare Abacus with the existing trace-
based side-channel detection tools on vulnerability detections.
For other tools, we use the data in the paper. As other tools
do not quantify leakage sites, we only include the time of
detecting vulnerabilities to perform a fair comparison.
The comparison result with CacheD [14] is shown in
Table III. Note that one statement in the source code can be
compiled into several machine instructions. So it is possible
that one statement can have multiple leakage points. Under
the circumstance, we think it is only a leakage. We have
conÔ¨Årmed that Abacus can identify all the secret-dependent
data access vulnerabilities reported by CacheD. In addition,
Abacus Ô¨Ånds many new ones. CacheD fails to detect some
vulnerabilities for two reasons. First, CacheD can only detect
secret-dependent data access vulnerabilities. Abacus can de-
tect secret-dependent control-Ô¨Çows as well. Second, according
to the CacheD paper, CacheD times out after 20 hours to
process asymmetric ciphers. CacheD applies some domain
knowledge to simplify and speed up the analysis. While those
optimizations do not introduce false positives, they may miss
some vulnerabilities. We notice that the number of instructions
in those traces are different due to the different analysis
starting functions and building options during the evaluation.
Table III shows that Abacus is faster than CacheD. Abacus is
much faster than CacheD when analyzing the same number of
instructions. For example, when we test Abacus on AES from
OpenSSL 0.9.7, Abacus is over 100x faster than CacheD.
DATA [16] identiÔ¨Åes side-channel leakages by Ô¨Ånding dif-
ferences in execution traces of the test program under various
secret inputs . According to the original DATA paper, it uses
443 different traces to analyze the side-channel vulnerabilities
in symmetric cyphers and 450 different traces to analyze
the side-channel vulnerabilities in asymmetric cyphers. On
the other hand, Abacus detects side-channel vulnerabilities
from one execution trace. Abacus uses symbolic analysis
to extract formulas that model each side-channel leakage.
After that, we sample the formula with various secret inputs
to detect and quantify each leakage site. In theory, DATA
might have better code coverage than Abacus because it
uses more execution traces, but Abacus has the following
advantages. a) Abacus is faster than DATA. For example, it
takes 116 minutes for DATA to detect vulnerabilities in the
RSA implementation in OpenSSL 1.1.0f. Abacus only spends
34 minutes, as shown in Table II. It takes 13 minutes and
20 minutes for DATA to analyze the side-channel leakages
in AES and DES, respectively. On the other hand, Abacus
Ô¨Ånishes its analysis in less than ten seconds while Ô¨Ånding
all the leakages reported by DATA. b) Because Abacus does
not run the test program again when we have a new secret
input ,Abacus can test more input secrets on those formulas
804Table III: Comparison with CacheD: Time, Secret-dependent
Control-Ô¨Çows (CF), Secret-dependent Data-Ô¨Çows (DF), The
Number of Instructions (# Instructions).
CacheD Abacus
Name Time (s) # Instructions DF Time (s) # Instructions CF+DF
AES143.4 791 48 0.23 1,704 0+75
AES248.5 2,410 32 0.04 1,350 0+88
RSA1199.3 674,797 1 1,351.6 17,002,523 105+2
RSA2165.6 473,392 1 1,753.3 14,468,307 27+11
RSA311542.3 26,848,103 2 128.1 9,527,231 9+2
RSA410788.9 27,775,053 0 891.7 10,513,606 14+0
Total 22,788.0 55,738,546 84 4,125.0 51,514,721 155+178
# of Instructions per second CacheD: 2,445 Abacus : 12,489
1OpenSSL 0.9.72OpenSSL 1.0.2f3Libgcrypt 1.6.14Libgcrypt 1.7.3
within the same time to achieve better precision. c) DATA
tries to use leakage models (domain knowledge) to classify
each leakage. The strength of Abacus is that it does not
need such domain knowledge. DATA reports 278 control-Ô¨Çow
and 460 memory-access leaks for the RSA implementation in
OpenSSL 1.1.0f. Among those leakages, they Ô¨Ånd one new
vulnerability in RSA after some manual analysis. Abacus
Ô¨Ånds the vulnerability and reports the vulnerability is severe
(int_bn_mod_inverse leaks more than 14.9 bits and BN_div
leaks more than 17.2 bits), which helps identify real sensitive
leaks. For each leakage site, Abacus can provide concrete
examples to trigger the issue and give an estimation to assess
the severity level of the vulnerability.
C. Case Studies
1) Symmetric Ciphers: DES and AES: We test both DES
and AES ciphers from mbedTLS and OpenSSL. Both cipher
implementations apply lookup tables, which improve perfor-
mance but can also introduce side-channels as well. During our
evaluation, we Ô¨Ånd mbedTLS 2.5 and 2.15.1 have the same
implementation of AES and DES. Therefore, our tool reports
the same leakages for both versions.
We Ô¨Ånd that the DES implementations in both mbedTLS
and OpenSSL have several severe information leakages in the
key schedule function. We do not see any mitigation in the
new version. We think it is not seen as worth the engineering
efforts given the life cycles of DES.
Abacus shows that the AES in OpenSSL 1.1.1 has less
leakage than other versions. OpenSSL 1.1.1 uses 1KB lookup
tables with 8-bit entries, unlike older versions that use a table
with 32-bit entries. Our tool suggests a smaller lookup table
might mitigate side-channel vulnerabilities.
2) Asymmetric Ciphers: RSA: We also evaluate Abacus on
RSA. Due to the page limit, we do not present the detailed
leakage report. As shown in Figure 6, the result indicates that
the newer versions of OpenSSL leak less information than
earlier versions. After version 0.9.7g, OpenSSL adopts a Ô¨Åxed-
window mod_exp_mont implementation for RSA. With this
design, the sequence of squares and multiples and the memory
access patterns are independent of the secret key. Abacus ‚Äôs
result conÔ¨Årms the new exponentiation implementation has
mitigated most leakages effectively because the four newer
versions have fewer leakages than version 0.9.7, which in-troduced this change. OpenSSL version 1.0.2f, 1.0.2k, and
1.1.0f almost have the same amount of leakage. We check the
ChangeLog and Ô¨Ånd only one change to patch vulnerability
CVE-2016-0702. Abacus Ô¨Ånds OpenSSL 1.1.1 and 1.1.1g
have signiÔ¨Åcantly less leaked information than other versions.
We check the ChangeLog of these two versions and Ô¨Ånd a
claim that the new RSA implementation adopts ‚Äúnumerous
side-channel attack mitigation‚Äù, which proves the effectiveness
of our quantifying method.
Our quantiÔ¨Åcation result shows vulnerabilities that leak
signiÔ¨Åcant amounts of information are more likely to be Ô¨Åxed
in the updated version. As presented in Figure 6, OpenSSL
0.9.7 has several severe leaks from function bn_sqr_comba8 ,
which is a main component of the OpenSSL big number
implementation. Shown in Figure 7, it has a secret-dependent
control Ô¨Çow at line 8. The value of the function parameter a
is derived from the secret key. As function bn_sqr_comba8
calls the macro ( sqr_add_c2 ) multiple times, and the code
can leak some information each time. Abacus indicates the
vulnerability is quite serious. It was patched in OpenSSL 1.1.1.
In Figure 8, control-Ô¨Çows transfers are replaced so there are no
leaks in the function sqr_add_c2 in OpenSSL 1.1.1. We note
that line 4 and 9 in Figure 7 both contain if branches. However,
they are not leaks because most compilers use add with
carry instruction to eliminate the branch. In addition, branches
can be compiled into non-branch machine instructions with
conditional moves. We notice a bitwise operation in Libgcrypt
1.8.5 is compiled to a conditional jump, which leads to a side-
channel leakage. Therefore, source-level code reviews are not
accurate enough to detect side-channels.
For vulnerabilities that leak less amount of information,
developers are more reluctant to Ô¨Åx them. For example,
OpenSSL 0.9.7 adds a Ô¨Åxed windows version of function
BN_mod_exp_mont_consttime to replace original function
BN_mod_exp_mont .Abacus detects a minor vulnerability
in the original function that can leak the last bit of the big
number m. In the updated version, developers make the Ô¨Åxed
windows the default option and rewrite most of the function.
However, the leakage site still exists in OpenSSL 1.1.1.
3) Monocypher: Monocypher is a small, easy to use
cryptographic library with performance comparable to Lib-
Sodium [47] and NaCl [48]. We choose four ciphers that
are designed to be side-channel resistant from the library.
Because those ciphers have no data Ô¨Çow from secrets to
branch conditions and load addresses. Monocypher should be
safe under our threat models. We analyze those ciphers with
Abacus , and it reports no leaks. This indicates that Abacus
is effective for validating countermeasures.
VII. D ISCUSSIONS AND LIMITATIONS
While recent work found many side-channel vulnerabilities,
we note that many of them have not been patched by devel-
opers. Side-channels are ubiquitous in software and it would
be difÔ¨Åcult to Ô¨Åx all of them. We need a tool that estimates
the sensitivity of each vulnerability so software engineers can
focus on ‚Äúsevere‚Äù leakages. For example, Abacus reports
805135791113*
Leakage Amount (bits)10305070Number of Leakages(a) OpenSSL 0.9.7
135791113*
Leakage Amount (bits)10305070Number of Leakages (b) OpenSSL 1.0.2f
135791113*
Leakage Amount (bits)10305070Number of Leakages (c) OpenSSL 1.0.2k
135791113*
Leakage Amount (bits)10305070Number of Leakages (d) OpenSSL 1.1.0f
135791113*
Leakage Amount (bits)10305070Number of Leakages (e) OpenSSL 1.1.1
135791113*
Leakage Amount (bits)10305070Number of Leakages (f) OpenSSL 1.1.1g
Figure 6: Side-channel leakages in different implementations of RSA in OpenSSL. We round the number of leaked information
into the nearest integer. The mark means timeout (see ¬ßVI-A).
1# define mul_add_c2(a,b,c0,c1,c2) \
2 t=(BN _ULLONG)a *b; \
3 tt=(t+t)&BN _MASK; \
4 if(tt < t) c2++; \
5 t1=(BN _ULONG)Lw(tt); \
6 t2=(BN _ULONG)Hw(tt); \
7 c0=(c0+t1)&BN _MASK2; \
8 if((c0 < t1) && (((++t2)&BN _MASK2) == 0)) c2++; \
9 c1=(c1+t2)&BN _MASK2; if((c1) < t2) c2++;
Figure 7: Macro sqr_add_c2 in OpenSSL 0.9.7
1# define mul_add_c2(a,b,c0,c1,c2) do{ \
2 BN_ULONG ta = (a), tb = (b); \
3 BN_ULONG lo, hi, tt; \
4 BN_UMULT _LOHI(lo,hi,ta,tb); \
5 c0 += lo; tt = hi+((c0<lo)?1:0); \
6 c1 += tt; c2 += (c1<tt)?1:0; \
7 c0 += lo; hi += (c0<lo)?1:0; \
8 c1 += hi; c2 += (c1<hi)?1:0; \
9 }while (0)
Figure 8: Macro sqr_add_c2 in OpenSSL 1.1.1
that the modular exponentiation using square and multiply
algorithms can leak more information than a key validation
function.
Software developers can use Abacus to Ô¨Ånd severe vulner-
abilities and reason about countermeasures. Abacus estimates
the amount of leaked information for each side-channel leak-
age in one execution trace. Abacus is useful for software
engineers to test programs and Ô¨Åx vulnerabilities. The design,
which is more precise in reporting true leakages as compared
with other static methods [49], [50], obviously misses leakages
on unexplored traces. The amount of leaked information also
depends on the secret key. However, as the tool is intended
for debugging and testing, we think it is a software engineer‚Äôs
responsibility to select the input key and trigger the path
in which they are interested. It is not a problem for crypto
software since virtually all keys follow similar computational
paths.
We use the amount of leaked information to represent the
sensitivity level of each side-channel vulnerability. Although
imperfect, Abacus produces a reasonable measurement for
each leak. For example, the simple modular exponentiation
is notoriously famous for multiple side-channel attacks [36].
During the execution, a single leak point may execute multiple
times and each time leak a different bit. In this case, Abacus
reports that the vulnerability can leak the whole key. However,
not every leak point inside a loop is severe. If a site in the loop
leaks the same bit from the original key, and these leaks are notindependent. Abacus captures most Ô¨Åne-grained information
by modeling each leak during the execution as a formula and
the conjunction of the formulas to describe its total effect.
Some leakage sites (e.g., square and multiply) can leak one
particular bit of the original key, but some leakage sites leak
one bit from several bytes in the original key. Abacus can
capture the dependency among the leaks and reports more
precise leakage information.
Abacus reaches full precision if the number of estimated
leaked bits equals to DeÔ¨Ånition 1. Abacus may lose precision
from the memory model it uses in theory. However, we did
not Ô¨Ånd false positives caused by the imprecise memory model
during our evaluation. Sampling introduces imprecision but
with a probabilistic guarantee. However, during the evaluation,
we Ô¨Ånd that Abacus cannot estimate the amount of leakage
for some leakage sites in a reasonable time, which means the
number ofKois very small. According to DeÔ¨Ånition 1, it
means the leakage is very severe. The sampling method in
¬ßIV seems simple and may miss some leakages (e.g., chosen
ciphertext attacks) in theory. However, the evaluation result
shows Abacus can identify all leakages found by the previous
work [14], [18], [19].
VIII. R ELATED WORK
There is a vast amount of work on side channel detec-
tion [14], [16]‚Äì[20], [51], mitigation [38], [52]‚Äì[59], infor-
mation quantiÔ¨Åcation [23], [33]‚Äì[35], [60]‚Äì[65], and model
counting [35], [66]‚Äì[69]. Here we only present work closely
related to ours. Due to space limit, we do not discuss related
work on side-channel attacks.
A. Detection and Mitigation
CacheAudit [20] uses abstract domains to compute an over
approximation of cache-based side-channel information leak-
age upper bound. However, it is difÔ¨Åcult to judge the sensitive
level of the side-channel leakage based on the leakage pro-
vided by CacheAudit. CacheS [19] improves on CacheAudit
with new abstract domains that only track secret-related code.
Like CacheAudit, CacheS cannot indicate the sensitive level
of side-channel vulnerabilities. CaSym [18] introduces a static
cache-aware symbolic reasoning technique to cover multiple
paths in a target program. Again, their approaches cannot
evaluate the sensitive level for each side-channel vulnerability,
and it only work on small code snippets.
806The dynamic approach, usually consists of taint analysis
and symbolic execution, can perform a very precise analy-
sis. CacheD [14] takes a concrete execution trace and runs
symbolic execution on the trace to get the formula of each
memory address. CacheD is quite precise in avoiding false
positives. However, CacheD is not able to detect secret-
dependent control-Ô¨Çows. We adopted a similar approach to
model the secret-dependent data accesses. Abacus differs
from CacheD in that we do not use traditional taint track-
ing or domain knowledge to cut the trace when identifying
secret-dependent data access vulnerabilities. Abacus works
on machine instructions directly instead of intermediate repre-
sentations. Moreover, Abacus Ô¨Ånds secret-dependent control-
Ô¨Çows at the same time and gives a precise quantiÔ¨Åcation of the
leakage. DATA [16] detects address-based side-channel vulner-
abilities by comparing different execution traces under various
test inputs. After collecting execution traces, DATA aligns
them and Ô¨Ånds the differences. It uses statistical hypothesis
testing to Ô¨Ånd true leakages. However, both imperfect trace
alignment and statistical testing result that DATA can produce
false positives. MicroWalk [17] uses mutual information (MI)
between sensitive input and execution state to detect side-
channels.
Both hardware [38], [52]‚Äì[55], [70] and software [49], [56]‚Äì
[59] side-channels mitigation techniques have been proposed
recently. Hardware countermeasures, including partitioning
hardware resources [52], randomizing cache accesses [38],
[55], and designing new architecture [71], require changes to
complex processors and are complex to adopt. On the contrary,
software approaches are usually easy to implement. Coppens
et al. [57] uses a compiler to eliminate key-dependent control-
Ô¨Çow transfers. Crane et al. [59] mitigated side-channels by
randomizing software. As for crypto libraries, the basic idea
is to eliminate key-dependent control-Ô¨Çow transfers and data
accesses. Common approaches include bit-slicing [72], [73]
and unifying control-Ô¨Çows [57].
B. QuantiÔ¨Åcation
Proposed by Denning [74] and Gray [75], Quantitative
Information Flow (QIF) aims at providing an estimation of the
amount of leaked information from the sensitive information
given the public output. If zero bits of the information are
leaked, the program is called non-interference. McCamant and
Ernst [62] quantify the information leakage as the network
Ô¨Çow capacity. Backes et al. [23] propose an automated method
for QIF by computing an equivalence relation on the set
of input keys. But the approach cannot handle real-world
programs with bitwise operations. Phan et al. [63] propose
symbolic QIF. The goal of their work is to ensure a program
is non-interference. They adopt an over approximation method
to estimate the total information leakage and their method does
not work for secret-dependent memory access side-channels.
Pasareanu et al. [65] combine symbolic analysis and Max-
SMT solving to synthesize the concrete public input that
can lead to the worst case leakage. They assume the target
program has multiple different input secrets and calculate theaverage leakage for one-Ô¨Åxed public input. CHALICE [35]
quantiÔ¨Åes the leaked information for a given cache behavior.
It symbolically reasons about cache behavior and estimates the
amount of leaked information based on cache miss/hit. Their
approach only scale to small programs, which limits its usage
in real-world applications. On the contrary, Abacus assesses
the sensitive level of side-channels with different granularities.
It can also analyze side-channels in real-world crypto libraries.
C. Model Counting
Model counting refers to the problem of computing the
number of models for a propositional formula (#SAT). There
are two approaches to solving the problem, exact model
counting and approximate model counting. We focus on ap-
proximate model counting since it is our approach. Wei and
Selman [66] introduce ApproxCount, a local search based
method using Markov Chain Monte Carlo (MCMC). Approx-
Count has the better scalability than exact model counters.
Other approximate model counter includes SampleCount [67],
Mbound [68], and MiniCount [69]. Unlike ApproxCount,
these model counters can give lower or upper bounds with
guarantees. Despite the rapid development of model counters
for SAT and some research [76], [77] on Modulo Theories
model counting (#SMT), they cannot be directly applied to
side channel leakage quantiÔ¨Åcation. ApproxFlow [60] uses
ApproxMC [78] for information Ô¨Çow quantiÔ¨Åcation, but it has
only been tested with small programs.
IX. C ONCLUSION
This paper presents a novel method to quantify address-
based side-channel leakage. We implement the method in
a prototype called Abacus and show its effectiveness in
Ô¨Ånding and quantifying side-channel leakage. With the new
deÔ¨Ånition of information leakage that models actual side-
channel attackers, quantifying the number of leaked bits helps
understand the severity level of side-channel vulnerabilities.
The evaluation conÔ¨Årms that Abacus is useful in estimating
the amount of leaked information in real-world applications.
X. D ATA AVAILABILITY
Abacus is publicly available at https://github.com/s3team/
Abacus. The repository also contains benchmarks, metadata,
and raw results of our experiments.
XI. A CKNOWLEDGEMENT
We thank Ziqi Wang, Pei Wang, Zhaofeng Chen, and the
anonymous reviewers for their valuable feedback. The work
was supported in part by the National Science Foundation
(NSF) under grant CNS-1652790, and the OfÔ¨Åce of Naval
Research (ONR) under grants N00014-16-1-2912, N00014-16-
1-2265, and N00014-17-1-2894.
807REFERENCES
[1] D. Agrawal, B. Archambeault, J. R. Rao, and P. Rohatgi, ‚ÄúThe EM side-
channel(s),‚Äù in International Workshop on Cryptographic Hardware and
Embedded Systems . Springer, 2002.
[2] M. Kar, A. Singh, S. Mathew, A. Rajan, V . De, and S. Mukhopadhyay,
‚ÄúImproved power-side-channel-attack resistance of an aes-128 core via
a security-aware integrated buck voltage regulator,‚Äù in ISSCC 2017 .
[3] S. Chari, C. S. Jutla, J. R. Rao, and P. Rohatgi, ‚ÄúTowards sound ap-
proaches to counteract power-analysis attacks,‚Äù in Annual International
Cryptology Conference . Springer, 1999.
[4] M. Alam, H. A. Khan, M. Dey, N. Sinha, R. Callan, A. Zajic, and
M. Prvulovic, ‚ÄúOne&done: A single-decryption em-based attack on
openssl‚Äôs constant-time blinded RSA,‚Äù in USENIX Security 18 .
[5] D. Genkin, A. Shamir, and E. Tromer, ‚ÄúRSA key extraction via low-
bandwidth acoustic cryptanalysis,‚Äù in Annual Cryptology Conference .
Springer, 2014.
[6] Y . Xu, W. Cui, and M. Peinado, ‚ÄúControlled-channel attacks: Determin-
istic side channels for untrusted operating systems,‚Äù in IEEE Symposium
on Security and Privacy 2015 .
[7] J. V . Bulck, M. Minkin, O. Weisse, D. Genkin, B. Kasikci, F. Piessens,
M. Silberstein, T. F. Wenisch, Y . Yarom, and R. Strackx, ‚ÄúForeshadow:
Extracting the keys to the intel SGX kingdom with transient out-of-order
execution,‚Äù in USENIX Security 18 .
[8] S. van Schaik, C. Giuffrida, H. Bos, and K. Razavi, ‚ÄúMalicious manage-
ment unit: Why stopping cache attacks in software is harder than you
think,‚Äù in USENIX Security 18 .
[9] S. Lee, M.-W. Shih, P. Gera, T. Kim, H. Kim, and M. Peinado, ‚ÄúInferring
Ô¨Åne-grained control Ô¨Çow inside SGX enclaves with branch shadowing,‚Äù
inUSENIX Security 17 .
[10] D. Gruss, R. Spreitzer, and S. Mangard, ‚ÄúCache template attacks:
Automating attacks on inclusive last-level caches,‚Äù in USENIX Security
15.
[11] F. Liu, Y . Yarom, Q. Ge, G. Heiser, and R. B. Lee, ‚ÄúLast-level cache
side-channel attacks are practical,‚Äù in IEEE Symposium on Security and
Privacy 2015 .
[12] D. A. Osvik, A. Shamir, and E. Tromer, ‚ÄúCache attacks and coun-
termeasures: The case of AES,‚Äù in Proceedings of the 2006 The
Cryptographers‚Äô Track at the RSA Conference on Topics in Cryptology ,
ser. CT-RSA‚Äô06. Springer-Verlag, 2006.
[13] D. Gullasch, E. Bangerter, and S. Krenn, ‚ÄúCache games ‚Äì bringing
access-based cache attacks on aes to practice,‚Äù in IEEE Symposium on
Security and Privacy 2011 .
[14] S. Wang, P. Wang, X. Liu, D. Zhang, and D. Wu, ‚ÄúCacheD: Identify-
ing cache-based timing channels in production software,‚Äù in USENIX
Security 17 .
[15] Y . Tsunoo, T. Saito, T. Suzaki, M. Shigeri, and H. Miyauchi, ‚ÄúCryptanal-
ysis of des implemented on computers with cache,‚Äù in Cryptographic
Hardware and Embedded Systems - CHES 2003 , C. D. Walter, √á. K.
Ko√ß, and C. Paar, Eds. Springer Berlin Heidelberg, 2003.
[16] S. Weiser, A. Zankl, R. Spreitzer, K. Miller, S. Mangard, and G. Sigl,
‚ÄúDATA - Differential Address Trace Analysis: Finding Address-based
Side-Channels in Binaries,‚Äù in USENIX Security 18 .
[17] J. Wichelmann, A. Moghimi, T. Eisenbarth, and B. Sunar, ‚ÄúMicrowalk:
A framework for Ô¨Ånding side channels in binaries,‚Äù in ACSAC ‚Äô18 , 2018.
[18] R. Brotzman, S. Liu, D. Zhang, G. Tan, and M. Kandemir, ‚ÄúCaSym:
Cache aware symbolic execution for side channel detection and mitiga-
tion,‚Äù in IEEE Symposium on Security and Privacy 2019 .
[19] S. Wang, Y . Bao, X. Liu, P. Wang, D. Zhang, and D. Wu, ‚ÄúIdentifying
cache-based side channels through secret-augmented abstract interpre-
tation,‚Äù in USENIX Security 19 .
[20] G. Doychev, D. Feld, B. Kopf, L. Mauborgne, and J. Reineke,
‚ÄúCacheAudit: A tool for the static analysis of cache side channels,‚Äù
inUSENIX Security 13 .
[21] C. Aum√ºller, P. Bier, W. Fischer, P. Hofreiter, and J.-P. Seifert, ‚ÄúFault at-
tacks on rsa with CRT: Concrete results and practical countermeasures,‚Äù
inInternational Workshop on Cryptographic Hardware and Embedded
Systems . Springer, 2002, pp. 260‚Äì275.
[22] Y . Yarom and K. Falkner, ‚ÄúFLUSH+RELOAD: A high resolution, low
noise, L3 cache side-channel attack,‚Äù in USENIX Security 14 .
[23] M. Backes, B. K√∂pf, and A. Rybalchenko, ‚ÄúAutomatic discovery and
quantiÔ¨Åcation of information leaks,‚Äù in IEEE Symposium on Security
and Privacy 2009 .[24] W. Wei and B. Selman, ‚ÄúA new approach to model counting,‚Äù in Theory
and Applications of SatisÔ¨Åability Testing , F. Bacchus and T. Walsh, Eds.
Springer Berlin Heidelberg, 2005.
[25] Q. Ge, Y . Yarom, D. Cock, and G. Heiser, ‚ÄúA survey of microarchitec-
tural timing attacks and countermeasures on contemporary hardware,‚Äù
Journal of Cryptographic Engineering , vol. 8, no. 1, 2018.
[26] J. Szefer, ‚ÄúSurvey of microarchitectural side and covert channels, attacks,
and defenses,‚Äù Journal of Hardware and Systems Security , vol. 3, no. 3,
2019.
[27] Y . Yarom, D. Genkin, and N. Heninger, ‚ÄúCachebleed: a timing attack
on openssl constant-time RSA,‚Äù Journal of Cryptographic Engineering ,
vol. 7, no. 2, 2017.
[28] D. Moghimi, J. Van Bulck, N. Heninger, F. Piessens, and B. Sunar,
‚ÄúCopyCat: Controlled Instruction-Level Attacks on Enclaves,‚Äù in
USENIX Security 20 .
[29] C. E. Shannon, ‚ÄúA mathematical theory of communication,‚Äù Bell system
technical journal , vol. 27, no. 3, pp. 379‚Äì423, 1948.
[30] D. Clark, S. Hunt, and P. Malacaria, ‚ÄúA static analysis for quantifying
information Ô¨Çow in a simple imperative language,‚Äù Journal of Computer
Security , vol. 15, no. 3, pp. 321‚Äì371, 2007.
[31] G. Smith, ‚ÄúOn the foundations of quantitative information Ô¨Çow,‚Äù in Foun-
dations of Software Science and Computational Structures , L. de Alfaro,
Ed. Springer Berlin Heidelberg, 2009.
[32] G. Doychev and B. K√∂pf, ‚ÄúRigorous analysis of software countermea-
sures against cache attacks,‚Äù in PLDI 2017 .
[33] K. Zhang, Z. Li, R. Wang, X. Wang, and S. Chen, ‚ÄúSidebuster:
automated detection and quantiÔ¨Åcation of side-channel leaks in web
application development,‚Äù in CCS 2010 .
[34] L. Bang, A. Aydin, Q.-S. Phan, C. S. P ÀòasÀòareanu, and T. Bultan, ‚ÄúString
analysis for side channels with segmented oracles,‚Äù in FSE 2016 .
[35] S. Chattopadhyay, M. Beck, A. Rezine, and A. Zeller, ‚ÄúQuantifying
the information leak in cache attacks via symbolic execution,‚Äù in
MEMOCODE ‚Äô17 .
[36] P. C. Kocher, ‚ÄúTiming attacks on implementations of difÔ¨Åe-hellman, rsa,
dss, and other systems,‚Äù in Annual International Cryptology Conference .
Springer, 1996, pp. 104‚Äì113.
[37] A. Askarov and S. Chong, ‚ÄúLearning is change in knowledge:
Knowledge-based security for dynamic policies,‚Äù in IEEE 25th Com-
puter Security Foundations Symposium (CSF) 2012 . IEEE, pp. 308‚Äì
322.
[38] Z. Wang and R. B. Lee, ‚ÄúNew cache designs for thwarting software
cache-based side channel attacks,‚Äù in ISCA ‚Äô07 .
[39] Y . Shoshitaishvili, R. Wang, C. Salls, N. Stephens, M. Polino,
A. Dutcher, J. Grosen, S. Feng, C. Hauser, C. Kruegel, and G. Vigna,
‚ÄúSoK: (state of) the art of war: Offensive techniques in binary analysis,‚Äù
inIEEE Symposium on Security and Privacy , 2016.
[40] D. Brumley, I. Jager, T. Avgerinos, and E. J. Schwartz, ‚ÄúBap: A binary
analysis platform,‚Äù in Computer Aided VeriÔ¨Åcation , G. Gopalakrishnan
and S. Qadeer, Eds., 2011.
[41] D. Song, D. Brumley, H. Yin, J. Caballero, I. Jager, M. G. Kang,
Z. Liang, J. Newsome, P. Poosankam, and P. Saxena, ‚ÄúBitblaze: A
new approach to computer security via binary analysis,‚Äù in International
Conference on Information Systems Security . Springer, 2008, pp. 1‚Äì25.
[42] Intel Corporation, Intel¬Æ64 and IA-32 Architectures Software Devel-
oper‚Äôs Manual , 2019.
[43] I. Yun, S. Lee, M. Xu, Y . Jang, and T. Kim, ‚ÄúQSYM: A practical concolic
execution engine tailored for hybrid fuzzing,‚Äù in USENIX Security 18 .
[44] T. Dullien and S. Porst, ‚ÄúReil: A platform-independent intermediate
representation of disassembled code for static code analysis,‚Äù 2009.
[45] L. De Moura and N. Bj√∏rner, ‚ÄúZ3: An efÔ¨Åcient SMT solver,‚Äù in
Proceedings of the Theory and Practice of Software, 14th International
Conference on Tools and Algorithms for the Construction and Analysis
of Systems , ser. TACAS‚Äô08/ETAPS‚Äô08, pp. 337‚Äì340.
[46] P. Godefroid, M. Y . Levin, D. A. Molnar et al. , ‚ÄúAutomated whitebox
fuzz testing.‚Äù in NDSS , vol. 8, 2008, pp. 151‚Äì166.
[47] LibSodium . [Online]. Available: https://libsodium.org
[48] D. J. Bernstein, T. Lange, and P. Schwabe, ‚ÄúThe security impact of a new
cryptographic library,‚Äù in International Conference on Cryptology and
Information Security in Latin America . Springer, 2012, pp. 159‚Äì176.
[49] J. B. Almeida, M. Barbosa, G. Barthe, F. Dupressoir, and M. Emmi,
‚ÄúVerifying constant-time implementations,‚Äù in USENIX Security 16 .
[50] J. Bacelar Almeida, M. Barbosa, J. S. Pinto, and B. Vieira, ‚ÄúFormal
veriÔ¨Åcation of side-channel countermeasures using self-composition,‚Äù
Sci. Comput. Program. , vol. 78, no. 7, 2013.
808[51] A. Langley, ‚Äúctgrind-checking that functions are constant time with
valgrind, 2010,‚Äù URL https://github. com/agl/ctgrind , vol. 84, 2010.
[52] D. Page, ‚ÄúPartitioned cache architecture as a side-channel defence
mechanism,‚Äù IACR Cryptology ePrint Archive , vol. 2005, 2005.
[53] D. Zhang, Y . Wang, G. E. Suh, and A. C. Myers, ‚ÄúA hardware design
language for timing-sensitive information-Ô¨Çow security.‚Äù
[54] X. Li, V . Kashyap, J. K. Oberg, M. Tiwari, V . R. Rajarathinam,
R. Kastner, T. Sherwood, B. Hardekopf, and F. T. Chong, ‚ÄúSapper: A
language for hardware-level security policy enforcement,‚Äù in ASPLOS
‚Äô14.
[55] M. Werner, T. Unterluggauer, L. Giner, M. Schwarz, D. Gruss, and
S. Mangard, ‚ÄúScattercache: Thwarting cache attacks via cache set
randomization,‚Äù in USENIX Security 19 .
[56] M.-W. Shih, S. Lee, T. Kim, and M. Peinado, ‚ÄúT-sgx: Eradicating
controlled-channel attacks against enclave programs.‚Äù in NDSS 2017 .
[57] B. Coppens, I. Verbauwhede, K. D. Bosschere, and B. D. Sutter,
‚ÄúPractical mitigations for timing-based side-channel attacks on modern
x86 processors,‚Äù in IEEE Symposium on Security and Privacy 2009 .
[58] E. Brickell, G. Graunke, M. Neve, and J.-P. Seifert, ‚ÄúSoftware mitiga-
tions to hedge aes against cache-based software side channel vulnera-
bilities.‚Äù IACR Cryptology ePrint Archive , vol. 2006, 2006.
[59] S. Crane, A. Homescu, S. Brunthaler, P. Larsen, and M. Franz, ‚ÄúThwart-
ing cache side-channel attacks through dynamic software diversity.‚Äù in
NDSS , 2015.
[60] F. Biondi, M. A. Enescu, A. Heuser, A. Legay, K. S. Meel, and
J. Quilbeuf, ‚ÄúScalable approximation of quantitative information Ô¨Çow in
programs,‚Äù in International Conference on VeriÔ¨Åcation, Model Checking,
and Abstract Interpretation . Springer, 2018, pp. 71‚Äì93.
[61] B. Kopf, L. Mauborgne, and M. Ochoa, ‚ÄúAutomatic quantiÔ¨Åcation of
cache side-channels,‚Äù in Computer Aided VeriÔ¨Åcation , P. Madhusudan
and S. A. Seshia, Eds. Springer Berlin Heidelberg, 2012.
[62] S. McCamant and M. D. Ernst, ‚ÄúQuantitative information Ô¨Çow as
network Ô¨Çow capacity,‚Äù in PLDI 2008 .
[63] Q.-S. Phan, P. Malacaria, O. Tkachuk, and C. S. P ÀòasÀòareanu, ‚ÄúSymbolic
quantitative information Ô¨Çow,‚Äù SIGSOFT Softw. Eng. Notes , vol. 37,
no. 6, 2012.
[64] Z. Zhou, Z. Qian, M. K. Reiter, and Y . Zhang, ‚ÄúStatic evaluation of
noninterference using approximate model counting,‚Äù in IEEE Symposium
on Security and Privacy 2018 .
[65] C. S. Pasareanu, Q.-S. Phan, and P. Malacaria, ‚ÄúMulti-run side-channel
analysis using symbolic execution and Max-SMT,‚Äù in IEEE 29th Com-
puter Security Foundations Symposium (CSF) 2016 . IEEE, pp. 387‚Äì
400.
[66] W. Wei and B. Selman, ‚ÄúA new approach to model counting,‚Äù in
International Conference on Theory and Applications of SatisÔ¨Åability
Testing . Springer, 2005, pp. 324‚Äì339.
[67] C. P. Gomes, J. Hoffmann, A. Sabharwal, and B. Selman, ‚ÄúFrom
sampling to model counting.‚Äù in IJCAI 2007 , 2007, pp. 2293‚Äì2299.
[68] C. P. Gomes, A. Sabharwal, and B. Selman, ‚ÄúModel counting: A new
strategy for obtaining good bounds,‚Äù in AAAI 2006 .
[69] L. Kroc, A. Sabharwal, and B. Selman, ‚ÄúLeveraging belief propagation,
backtrack search, and statistics for model counting,‚Äù in International
Conference on Integration of ArtiÔ¨Åcial Intelligence (AI) and Operations
Research (OR) Techniques in Constraint Programming . Springer, 2008,
pp. 127‚Äì141.
[70] K. v. Gleissenthall, R. G. Kƒ±cƒ±, D. Stefan, and R. Jhala, ‚ÄúIODINE:
Verifying constant-time execution of hardware,‚Äù in USENIX Security
19.
[71] M. Tiwari, J. K. Oberg, X. Li, J. Valamehr, T. Levin, B. Hardekopf,
R. Kastner, F. T. Chong, and T. Sherwood, ‚ÄúCrafting a usable micro-
kernel, processor, and i/o system with strict and provable information
Ô¨Çow security,‚Äù in ACM SIGARCH Computer Architecture News , vol. 39,
no. 3. ACM, 2011.
[72] R. K√∂nighofer, ‚ÄúA fast and cache-timing resistant implementation of
the AES,‚Äù in Cryptographers‚Äô Track at the RSA Conference . Springer,
2008.
[73] C. Rebeiro, D. Selvakumar, and A. Devi, ‚ÄúBitslice implementation of
aes,‚Äù in International Conference on Cryptology and Network Security .
Springer, 2006.
[74] D. E. Robling Denning, Cryptography and Data Security . Addison-
Wesley Longman Publishing Co., Inc., 1982.
[75] J. W. Gray III, ‚ÄúToward a mathematical foundation for information Ô¨Çow
security,‚Äù Journal of Computer Security , vol. 1, no. 3-4, pp. 255‚Äì294,
1992.[76] D. Chistikov, R. Dimitrova, and R. Majumdar, ‚ÄúApproximate counting in
smt and value estimation for probabilistic programs,‚Äù Acta Informatica ,
vol. 54, no. 8, pp. 729‚Äì764, 2017.
[77] Q.-S. Phan, ‚ÄúModel counting modulo theories,‚Äù arXiv preprint
arXiv:1504.02796 , 2015.
[78] S. Chakraborty, K. S. Meel, and M. Y . Vardi, ‚ÄúAlgorithmic improvements
in approximate counting for probabilistic inference: From linear to
logarithmic sat calls,‚Äù Tech. Rep., 2016.
809