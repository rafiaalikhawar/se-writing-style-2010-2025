Reducing DNN Properties to Enable FalsiÔ¨Åcation
with Adversarial Attacks
David Shriver
Department of Computer Science
University of Virginia
Charlottesville, Virginia, USA
dls2fc@virginia.eduSebastian Elbaum
Department of Computer Science
University of Virginia
Charlottesville, Virginia, USA
selbaum@virginia.eduMatthew B. Dwyer
Department of Computer Science
University of Virginia
Charlottesville, Virginia, USA
matthewbdwyer@virginia.edu
Abstract ‚ÄîDeep Neural Networks (DNN) are increasingly being
deployed in safety-critical domains, from autonomous vehicles
to medical devices, where the consequences of errors demand
techniques that can provide stronger guarantees about behavior
than just high test accuracy. This paper explores broadening
the application of existing adversarial attack techniques for
the falsiÔ¨Åcation of DNN safety properties. We contend and
later show that such attacks provide a powerful repertoire of
scalable algorithms for property falsiÔ¨Åcation. To enable the broad
application of falsiÔ¨Åcation, we introduce a semantics-preserving
reduction of multiple safety property types, which subsume prior
work, into a set of equivalid correctness problems amenable to
adversarial attacks. We evaluate our reduction approach as an
enabler of falsiÔ¨Åcation on a range of DNN correctness problems
and show its cost-effectiveness and scalability.
Index Terms‚ÄîfalsiÔ¨Åcation, formal methods, neural nets
I. I NTRODUCTION
As the performance and applicability of Deep Neural Net-
works (DNN) continues to increase, their deployment has
been explored for use in safety-critical domains, such as
autonomous vehicles [9], [15], [35] and medicine [17], [23],
[56]. As a result, checking the correctness of DNNs has
emerged as a key challenge to ensuring the safety of these
systems. For example, for the DroNet DNN that predicts a
steering angle and a probability of collision for an autonomous
quadrotor system [35], one such correctness property may
specify that if the probability of collision is low, then the
steering angle should not be extremely large.
One approach to checking correctness of DNN models is
veriÔ¨Åcation. In the past 3 years alone, dozens of DNN veriÔ¨Å-
cation techniques have been introduced for proving properties
of DNN models [7], [11], [13], [19]‚Äì[21], [24], [28]‚Äì[30],
[43], [44], [46], [47], [51], [54], [55], [57]‚Äì[59]. Unfortunately,
these approaches are often limited in their applicability, due
to their simplifying assumptions about DNN structure or to
high computational cost, making it difÔ¨Åcult to apply them to
real models [45], [61]. For example, due to the large size and
complex computation graph of DroNet, existing veriÔ¨Åers fail
to run or cannot Ô¨Ånish in a reasonable time.
A complementary approach to veriÔ¨Åcation is that of falsiÔ¨Å-
cation, which attempts to Ô¨Ånd violations of a property. While
veriÔ¨Åers can show that a property is true, falsiÔ¨Åers can often
Ô¨Ånd violations more quickly than veriÔ¨Åers when the property isfalse. FalsiÔ¨Åcation is an active area of research spanning prop-
erty types and application domains [1], [4], [16], [18]. In the
context of DNNs, one can view adversarial attacks [26], [32],
[36], [37], [49], [50] as falsiÔ¨Åers for DNN local robustness
properties. While these techniques often scale to real-world
DNNs, they are currently limited in the range of properties
they can falsify. For the DroNet example, adversarial attacks
support the scale and complex structure of the DNN, but are
designed only to Ô¨Ånd violations of robustness properties and
not safety properties like those relating speed and probability
of collision. As we discuss in ¬ßII-A, there is a broad range of
properties that could beneÔ¨Åt from the speed and applicability
of these falsiÔ¨Åers.
Driven in part by the cost of DNN veriÔ¨Åcation, and in
part by the limited property support for DNN falsiÔ¨Åcation,
we identify the key insight that many valuable property types
could be reduced into the more commonly supported form of
local robustness properties. We build on this insight to develop
an approach for reducing properties in an expressive, general
form to an equivalid set of local robustness properties, which
have wide support among both falsiÔ¨Åers and veriÔ¨Åers. Such
translation has the potential to bring existing techniques to
bear on falsifying DNN properties, leaving veriÔ¨Åers to focus
on proving that a property holds.
Our community has exploited property reduction for veriÔ¨Å-
cation and program analysis for decades. Perhaps best known
is the reduction from stateful safety properties to reachability
properties. For example, partial order reductions were broad-
ened in applicability by reducing stateful properties to a form
of deadlock [25], and both data Ô¨Çow analyses [40], [48] and
SAT solving [8] were applied to verify stateful properties by
formulating the reachability of error states. A second use of
reductions is to enable more efÔ¨Åcient algorithmic methods
to be employed. For instance, the -safety option of the
SPIN model checker permits it to use a signiÔ¨Åcantly faster
reachability algorithm [27]. Such reductions are now consid-
ered standard in veriÔ¨Åcation and program analysis. In the new
domain of DNN veriÔ¨Åcation and falsiÔ¨Åcation, however, the
lessons of such reductions have not yet taken root.
In this paper, we introduce an approach for reducing a DNN
and an associated safety property ‚Äì which we refer to as a
correctness problem ‚Äì into an equivalid set of correctness
2752021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)
1558-1225/21/$31.00 ¬©2021 IEEE
DOI 10.1109/ICSE43902.2021.00036
Fig. 1: Proposed approach reduces a DNN and its safety prop-
erty into an equivalid set of correctness problems formulated
with robustness properties that can be processed by falsiÔ¨Åers.
problems formulated with robustness properties that can be
processed by existing adversarial techniques. Figure 1 provides
an overview of the approach. By preserving validity, the trans-
lation supports both falsiÔ¨Åcation approaches, such as adver-
sarial attack algorithms, and existing veriÔ¨Åcation techniques.
The approach is fully automated which allows developers
to specify properties in a convenient form while leveraging
the complementary strengths of falsiÔ¨Åcation and veriÔ¨Åcation
algorithms.
The primary contributions of this work are: (1) an automated
approach for the reduction of DNN correctness problems as an
equivalid set of robustness problems; (2) an implementation
of our approach that employs a portfolio of falsiÔ¨Åers; and
(3) a study demonstrating that property reduction yields cost-
effective violations of general DNN correctness problems.
II. B ACKGROUND
This section presents prior work on DNN property speciÔ¨Å-
cation and approaches for their falsiÔ¨Åcation.
A. Properties of DNNs
Given a DNN,N:Rn!Rm, a property, (N), deÔ¨Ånes
a set of constraints over the inputs, X‚Äì the pre-condition,
and a set of constraints over the outputs, Y‚Äì the post-
condition. Checking property (N)attempts to prove or
falsify:8x2Rn:X(x)!Y(N(x)).
A survey on veriÔ¨Åcation of neural networks [33] identiÔ¨Åes
different representations for the input and output constraints
used by veriÔ¨Åcation techniques; two of these representations
are particularly useful in this work. A hyperrectangle is an
n-dimensional rectangle where constraints are formulated as
(xilbi)^(xiubi), wherelbi;ubi2Rand0i < n
deÔ¨Åne the lower and upper bounds on the value of each dimen-
sion ofx, respectively. A special case of hyperrectangles used
in our approach is the unit hypercube which is a hyperrectangle
where8i:(lbi= 0)^(ubi= 1) ; ann-dimensional hypercube is
denoted [0;1]n. Ahalfspace-polytope is a polytope which can
be represented as a set of linear inequality constraints, Axb,
whereA2Rkn,b2Rk,kis the number of constraints and
nis the dimension of x.
Using such encodings, researchers have speciÔ¨Åed a range of
desirable properties of DNNs. Here we distinguish three broad
categories: robustness, reachability, and differential properties.
Robustness properties originated with the study of adver-
sarial examples [50], [62]. Robustness properties apply to
classiÔ¨Åcation models and specify that inputs from a speciÔ¨Åcregion of the input space must all produce the same output
class. Robustness properties can be further classiÔ¨Åed as either
local or global robustness; the former asserts robustness in a
local region of the input domain and the latter over the entire
input domain. Detecting violations of robustness properties has
been widely studied, and they are a common type of property
for evaluating veriÔ¨Åers [21], [46], [47], [51], [54].
Reachability properties deÔ¨Åne the post-condition using con-
straints over output values rather than output classes, and are
thus not limited to classiÔ¨Åcation models. Such properties have
been used to evaluate DNN veriÔ¨Åers [29], [54]. Reachability
properties specify that inputs from a given region of the input
space must produce outputs that lie in a given region of the
output space. For example, a DNN model controlling the
velocity of an autonomous vehicle may have a safety property
specifying that the model never produces a desired velocity
value greater than the vehicles maximum physical speed for
any input in the input domain. Similarly to robustness, reach-
ability properties can be further classiÔ¨Åed as local or global.
For example, a global halfspace-polytope reachability (GHPR)
property would specify a halfspace-polytope constraint on
network output values that must hold for all inputs.
Differential properties are the most recently introduced
DNN property type [42]. These properties specify a difference
(or lack thereof) between outputs of multiple DNNs. One
type of differential property is equivalence, which states that
for every input, two DNN models produce the same output.
Such a property can be used to check that DNN semantics
are preserved after some modiÔ¨Åcation, such as quantization or
pruning. Differential properties can be supported by combining
multiple DNNs into a single network and expressing properties
over their combined input and output domains.
In addition to these three categories and as alluded earlier,
properties can also be classiÔ¨Åed by the form of their input
pre-condition. Global properties have the most permissive pre-
condition, enforcing the post-condition for any input in the
input domain of the DNN. For example, a DNN that operates
on images may accept values in [0;1]n. The pre-condition of
a global property would not restrict this domain any further.
Local properties only enforce the post-condition for inputs
within a designated region of the input domain. For example, a
local property for an image processing network may have the
precondition that inputs are within distance "of some given
inputx. This is especially common in robustness properties.
B. Adversarial Attacks and Fuzzing
One approach to checking properties of DNNs is through
the use of algorithms that seek to Ô¨Ånd examples that violate
a given speciÔ¨Åcation for a given model. Two categories of
techniques have been developed for DNNs that can be used
to falsify DNN property speciÔ¨Åcations.
Adversarial attacks are methods that are optimized to de-
tect violations of robustness properties [2], [62]. In general,
adversarial attacks take in a DNN model and an initial input,
and attempt to produce a perturbation that, when applied to
the input, will change the class predicted by the given model.
276These perturbations are often also subject to some constraints,
such as remaining within a given distance of some original
input. A perturbed input, commonly known as an adversarial
example is a violation to a local robustness property. To our
knowledge, adversarial attacks are a method of falsiÔ¨Åcation
that only supports the falsiÔ¨Åcation of robustness properties.
Adversarial attacks can be classiÔ¨Åed based on characteristics of
the attack, such as if they are white-box [26], [32], [36], [37],
[50] or black-box [49]; targeted [26], [50] or untargeted [32],
[37]; iterative [32], [36], [37] or one-shot [26], [50]; or by their
perturbation constraint (e.g., L0[49],L2[14], orL1[26],
[50]). A more exhaustive taxonomy and description of existing
adversarial attacks is available in the literature [2], [62].
Fuzzing involves randomly generating inputs within a given
input region (often the full input space), and checking whether
the outputs they produce violate a speciÔ¨Åed post-condition.
Fuzzing is more general than adversarial attacks, in that it can
support the falsiÔ¨Åcation of more than robustness properties,
but requires specifying input mutation functions and objective
functions (essentially an output oracle), for every type of
property that needs support. Examples of existing fuzzing
techniques include TensorFuzz [39] and DeepHunter [60].
III. A PPROACH
The primary goal of our approach is to amplify the power
of falsiÔ¨Åers, such as adversarial attacks, by increasing their
applicability. Our approach takes in a correctness problem
comprised of a DNN and a property, and encodes it as an
equivalid set of robustness problems, which then enables us to
run a portfolio of methods that are applicable to this restricted
problem class to uncover general property violations.
A. DeÔ¨Åning Property Reduction
Acorrectness problem is a pair, =hN;i, of a DNN,N,
and a property speciÔ¨Åcation , formed to determine whether
Nj=isvalid orinvalid .
Reduction, reduce : 	!P(	), aims to transform a
correctness problem, hN;i= 2	, to an equivalid form,
reduce ( ) =fhN1;1i;:::;hNk;kig, in which property
speciÔ¨Åcations deÔ¨Åne robustness properties:
i=8x:x2[0;1]n!N i(x)0>Ni(x)1
and networks have input domains deÔ¨Åned as unit hypercubes,
and output domains consist of two values ‚Äì indicating property
satisfaction and falsiÔ¨Åcation:
8hNi;ii2reduce ( ):Ni: [0;1]n!R2
As we demonstrate in ¬ßIV, reduction enables the application
of a broad array of efÔ¨Åcient DNN analysis techniques to
compute problem validity and/or invalidity.
As deÔ¨Åned, reduction has two key properties. The Ô¨Årst
property is that the set of resulting problems is equivalid with
the original correctness problem (a proof of this theorem is
included in Appendix A).
DroNet Prefix Suffix N0
N1
œÜ = ‚àÄx. (x ‚àä [0, 1]40000) ‚Üí (N(x)0 > N(x)1)Fig. 2: One of the robustness problems generated by reduction.
Theorem 1. Reduction maps an arbitrary correctness problem
to an equivalid set of correctness problems.
Nj= ,8hN i;ii2reduce ( ):Nij=i
The second property is that the resulting set of problems
all use the same property type, i.e., robustness; they all
assert thatN(x)0is the output class for all inputs. Applying
reduction enables veriÔ¨Åers or falsiÔ¨Åers to support a large set of
correctness problems by implementing support for this single
property type. We chose to reduce to robustness properties due
to their broad support among existing falsiÔ¨Åers and veriÔ¨Åers.
B. Overview
To illustrate, consider a property for DroNet [35]; a DNN for
controlling an autonomous quadrotor. Inputs to this network
are 200 by 200 pixel grayscale images with pixel values
between 0 and 1. For each image, DroNet predicts a steering
angle and a probability that the drone is about to collide
with an object. The property states that for all inputs, if the
probability of collision is no greater than 0:1, then the steering
angle is capped at 5degrees and is speciÔ¨Åed as:
8x:((x2[0;1]40000)^(N(x)Pcoll0:1))!( 5N(x)Steer5)
Adversarial attacks cannot be used off the shelf to falsify this
property, since it is not a robustness property.
To enable the application of adversarial attacks, we reduce
the property to a set of correctness problems with robustness
properties, such as the one shown in Figure 2. This partic-
ular example is reduced to two correctness problems with
robustness properties. Each of the problems pair a robustness
property (shown in the bottom of Figure 2) with a modiÔ¨Åed
version of the original DNN. The new DNN is created through
two key transformations. First, incorporating a preÔ¨Åx network
(shown in green in Figure 2) to reduce the input domain to a
unit-hypercube. This modiÔ¨Åcation ensures that the properties
for reduced problems can all use the same pre-condition.
Second, incorporating a sufÔ¨Åx network (shown in blue in
Figure 2) that takes in the inputs and outputs of the original
DNN and classiÔ¨Åes whether they constitute a violation of
the original property. This sufÔ¨Åx transforms the network into
a classiÔ¨Åer for which violations of a robustness property
correspond to violations of the original property.
C. Reduction Transformation
We rely on three assumptions to transform a correctness
problem into a reduced form. First, the constraints on the
network inputs must be represented as a union of convex
polytopes. Second, the constraints on the outputs of the
277Algorithm 1: Property Reduction
Input: Correctness problem hN;i
Output: A set of robustenss problems
fhN 1;1i;:::;hNi;iig
1begin
20 DNF (:)
3 	 ;
4 fordisjunct20do
5 hpoly disjunct tohpolytope( disjunct )
6 prex construct prex( hpoly )
7N0 N0:x7!concat(N(x);x)
8 sux construct sux( hpoly )
9N00 suxN0prex
100 8x:(x2[0;1]n=) N00(x)0>N00(x)1)
11 	 	[hN00;0i
12 return 	
Algorithm 2: disjunct tohpolytope
Input: Conjunction of linear inequalities i
Output: Halfspace polytope H
1begin
2H (A;b)whereAis an (jij)(m+n)matrix where
columns 0tom 1correspond to output variables N(x)0to
N(x)m 1and columns mtom+n 1correspond to input
variablesx0toxn 1
3 forineq j2ido
4 ifineq jusesthen
5 swap lhs and rhs; switch inequality to 
6 else ifineq juses>then
7 swap lhs and rhs; switch inequality to <
8 move variables to lhs; move constants to rhs
9 ifineq juses<then
10 decrement rhs; switch inequality to 
11Aj coefÔ¨Åcients of variables on lhs
12bj rhs constant
13 returnH
network must be represented as a union of convex polytopes.
Third, we assume that each convex polytope is represented
as a conjunction of linear inequalities. Complying with these
assumptions still enables properties to retain a high degree of
expressiveness as unions of polytopes are extremely general
and subsume other geometric representations, such as inter-
vals and zonotopes. ¬ßIV-A shows that these assumptions are
sufÔ¨Åcient to support existing DNN correctness problems.
Algorithm 1 deÔ¨Ånes the reduction transformation at a high
level. We present each step of the algorithm and describe their
application to the DroNet example described above.
1) Reformat the Property: Reduction Ô¨Årst negates the origi-
nal property speciÔ¨Åcation and converts it to disjunctive normal
form (DNF) ‚Äì line 2. Negating the speciÔ¨Åcation means that
a satisfying model falsiÔ¨Åes the original property. The DNF
representation allows us to construct a property for each
disjunct, such that if any are violated, the negated speciÔ¨Åcation
is satisÔ¨Åed and thus the original speciÔ¨Åcation is falsiÔ¨Åed. For
each of these disjuncts the approach deÔ¨Ånes a new robustness
problem, as described below.
2) Transform into halfspace-polytopes: Constraints in each
disjunct are converted to halfspace-polytope constraints, de-
Ô¨Åned over the concatenation of the input and output do-Algorithm 3: construct preÔ¨Åx
Input: Halfspace polytope H
Output: A fully-connected layer P
1begin
2lb= ( 1;:::; 1)
3ub= (1;:::;1)
4 forconstraint2Hdo
5 ifconstraint is over only input variables then
6 forxi2xdo
7 lbi maxfminxiconstraint;lb ig
8 ubi minfmax xiconstraint;ub ig
9W diag(ub lb)
10b lb
11P FullyConnectedLayer( W;b)
12 returnP
Algorithm 4: construct sufÔ¨Åx
Input: Halfspace polytope H= (A;b)
Output: A DNN with 2 fully connected layers S
1begin
2Sh ReLU(FullyConnectedLayer( A; b))
3W 
1 1:::1
0 0:::0
4So FullyConnectedLayer( W;~0)
5S SoSh
6 returnS
mains ‚Äì disjunct tohpolytope ()on line 5. This conversion
is described in Algorithm 2. A halfspace-polytope can be
represented in the form Axb, whereAis a matrix of k
rows, where each row represents 1 constraint, and dcolumns,
one for each variable. In this case, dis equal tom+n, the
size of the output space, plus the size of the input space. This
representation facilitates the transformation of constraints into
network operations. To build the matrix Aand vectorb, we Ô¨Årst
transform all inequalities in the conjunction to inequalities
with variables on the left-hand-side and constants on the right-
hand-side. The transformation Ô¨Årst converts toand>to
<‚Äì lines 4-7 of Algorithm 2. Then, all variables are moved
to the left-hand-side and all constants to the right-hand-side
‚Äì line 8. Next, <constraints are converted to constraints
by decrementing the constant value on the right-hand-side ‚Äì
lines 9-10. This transformation assumes that there exists a
representable number with greatest possible value that is less
than the right-hand-side. Finally, each inequality is converted
to a row of Aand value in b‚Äì lines 11-12.
3) PreÔ¨Åx Construction: Using the constructed halfspace-
polytope, Algorithm 1 next constructs a preÔ¨Åx to the original
network to ensure the input domain of the resulting network
is[0;1]n, wherenis the input dimensionality of the original
network ‚Äì construct prex ()on line 6. The algorithm to
construct the preÔ¨Åx is shown in Algorithm 3. The preÔ¨Åx is
constructed by Ô¨Årst extracting lower and upper bounds for
every input variable ‚Äì lines 2-8. This extracts the minimal
axis-aligned bounding hyperrectangle. The lower and upper
bounds can then be used to construct the preÔ¨Åx network,
which is a single n-dimensional fully-connected layer, with no
activation function, which has a diagonal weight matrix with
values equal to the ranges of the input variables, and biases
278equal to the lower bounds of each input. The preÔ¨Åx operates
on unit hypercubes, reducing the input space to the correctness
problems. The preÔ¨Åx also encodes any interval constraints over
the original input space, allowing them to be removed before
sufÔ¨Åx construction, which simpliÔ¨Åes the sufÔ¨Åx networks. For
the DroNet example, the diagonal of this matrix is a vector of
ones, while the biases are all 0.
Next, the original input values are forwarded to the end
of the original network and concatenated with the original
output layer ‚Äì line 7. Because constraints will be encoded as
a network sufÔ¨Åx that classiÔ¨Åes whether inputs are property
violations, this step is necessary to enable the encoding of
constraints over the inputs.
4) SufÔ¨Åx Construction: The sufÔ¨Åx subnetwork classiÔ¨Åes
whether inputs satisfy the speciÔ¨Åcation ‚Äì construct sux ()
on line 8. The algorithm for constructing the sufÔ¨Åx from the
halfspace-polytope constraints is shown in Algorithm 4. The
constructed sufÔ¨Åx has two layers, a hidden fully-connected
layer with ReLU activations, and dimension equal to the
number of constraints in the halfspace-polytope deÔ¨Åned by
the current disjunct, and a Ô¨Ånal output layer of size 2.
The hidden layer of the sufÔ¨Åx has a weight matrix equal to
the constraint matrix, A, of the halfspace-polytope represen-
tation, and a bias equal to  b‚Äì line 2. With this construction,
each neuron will only have a value greater than 0 if the
corresponding constraint is not satisÔ¨Åed, otherwise it will
have a value less than or equal to 0, which becomes equal
to 0 after the ReLU activation is applied. In the DroNet
problem for example, one of the constraints for a disjunct
is(N(x)S 5). For this conjunct we deÔ¨Åne the weights
for one of the neurons to have a weight of 1 from N(x)S, a
weight of 0 fromN(x)P, and a bias of 5.
The output layer of the sufÔ¨Åx has 2 neurons, each with
no activation function. The Ô¨Årst of these neurons is the sum
of all neurons in the previous layer, and has a bias value of
0. Because the neurons in the previous layer each represent
a constraint, and each of these neurons is 0 only when the
constraint is satisÔ¨Åed, if the sum of all these neurons is 0,
then the conjunction of the constraints is satisÔ¨Åed, indicating
that a violation has been found. The second of these neurons
has a constant value of 0 ‚Äì all incoming weights and bias
are 0. The resulting network will predict class 1 if the input
satisÔ¨Åes the corresponding disjunct and class 0 otherwise.
5) Correctness Problem Construction: Lines 9-11 of Al-
gorithm 1 deÔ¨Åne the reduced subproblem comprised of the
network that we have constructed and a robustness property.
The robustness property speciÔ¨Åcation is always the same and
states that the network should classify all inputs in the d-
dimensional hypercube as class 0 ‚Äì no violations. If a violation
is found to this property, then, according to Theorem 2,
the original property is violated by the unreduced input that
violated the robustness property. In the end, we have generated
a set of correctness problems such that, if any of the problems
is violated, then the original problem is also violated. This
comes from our construction of a property for each disjunct
in the DNF of the negation of the original property.D. Properties Over Multiple Networks
While Algorithm 1 is deÔ¨Åned over properties with a single
network, it can easily be applied to properties over multiple
networks, by combining those networks into a single large
network. This is specially relevant to check for equivalence
properties. This can be done by concatenating their input
and output vectors. This results in a single large network
with a computation path for each network. The transformation
algorithm can then be applied as before.
E. Implementation.
We implemented our approach in a system named DNNF1,
which accepts a DNN property speciÔ¨Åcation and correspond-
ing DNN as input, and returns whether a violation is found.
Whereas the reduction algorithm in ¬ßIII applies to properties
with unions of polytopes as input constraints, the current
implementation works on unions of hyperrectangles in the
input space. This was a convenience choice to simplify the
implementation while still accommodating most properties in
the veriÔ¨Åcation literature, as demonstrated in ¬ßIV-A.
IV. E MPIRICAL EVALUATION
We now assess the cost-effectiveness of reducing DNN
properties for falsiÔ¨Åcation by applying it to a range of DNN
property benchmarks that provide diversity in terms of prop-
erty types and DNN complexity. Our evaluation will attempt
to answer the following research questions:
RQ1: How expressive are the properties supported by
property reduction?
RQ2: How cost-effective is falsiÔ¨Åcation at Ô¨Ånding prop-
erty violations?
RQ3: How scalable is falsiÔ¨Åcation?
A. RQ1: On the Expressiveness of Reduction
We Ô¨Årst evaluate whether the assumptions about the prop-
erty speciÔ¨Åcation required by reduction, namely that the
original property is speciÔ¨Åed as a logical formula of linear
inequalities, is expressive enough to support DNN correctness
properties that have been proposed in existing work.
1) Setup: To evaluate the expressiveness of properties sup-
ported by our reduction, we analyze and catalog the bench-
marks used by the Ô¨Åve veriÔ¨Åers used in our later study, as
well as the benchmarks of a recent DNN veriÔ¨Åer competition,
VNN-Comp [34]. Additionally, we surveyed published papers
on DNN veriÔ¨Åcation in the past two years identifying 4
additional works [6], [22], [52], [53]. Finally, we include the
2 new benchmarks introduced in this work.
2) Results: We summarize the results in Table I, which lists
the benchmarks used in each work, the type and number of
properties in the benchmark and whether the properties are
supported by Algorithm 1 and our current implementation.
The property types use abbreviated names with the following
encoding: the Ô¨Årst symbol indicates whether the property is
global (G) or local (L); the second symbol indicates whether
1https://github.com/dlshriver/DNNF
279the input constraint can be represented as a hyper-rectangle
() or not ( ); the third symbol indicates whether the property
is a robustness (r) property, a reachability (R) property, or a
differential (D) property. Each cell under a property type indi-
cates the number of properties in the corresponding benchmark
of that type. The bolded benchmarks are used later in the study
for the evaluation of RQ2 and RQ3. We describe the details
of these benchmarks in more detail below.
The Ô¨Årst benchmark is ACAS Xu, introduced for the study
of the Reluplex veriÔ¨Åer [29], and used extensively since [6],
[12], [13], [30], [34], [54], [55]. The benchmark consists of 10
properties. Properties 1,2,3,4,7and8are reachabil-
ity properties, while 5,6,9, and10are traditional class
robustness properties. All 10 properties have hyper-rectangles
constraints over the inputs and are fully supported by our
property reduction.
The next benchmark is from the evaluation of the Planet
veriÔ¨Åer. First is the Collision Avoidance benchmark, which
consists of 500 safety properties that check the robustness of
a network that classiÔ¨Åes whether 2 simulated vehicles will
collide, given their current state. All 500 properties are L r
properties, and are all fully supported. Second is a set of 7
properties on an MNIST network. The Ô¨Årst 4 of these are
GR properties, while the next 2 are L r properties, and the
Ô¨Ånal property is an L r property. In addition to restricting the
amount of noise that can be added to each pixel in the input
image, the Ô¨Ånal property constrains the difference in the noise
between neighboring pixels. DNNF currently supports 6 of
these properties, while the Ô¨Ånal is supported by Algorithm 1.
The Neurify veriÔ¨Åer was evaluated on the ACAS Xu bench-
mark and on properties of 4 MNIST networks, 3 android
app malware classiÔ¨Åcation networks, and 1 self-driving car
network. The evaluation on MNIST used 500 L r properties
across 4 networks, all of which we support. Neurify was also
evaluated on 3 networks trained on the Drebin dataset [5] to
classify apps as benign or malicious. This benchmark also in-
cludes 500 L r properties, which are fully supported. Finally,
Neurify was evaluated on local reachability properties for a
modiÔ¨Åed version of the DA VE self-driving car network [10].
This benchmark consists of 200 local reachability properties,
with 4 different types of input constraints (50 properties
of each type). The Ô¨Årst type of input constraint is an L1
constraint, which is equivalent to a hyper-rectangle constraint.
The second type of input constraint is an L1constraint, which
can be written as a halfspace polytope constraint. The third
and fourth type of input constraint is an image brightness and
contrast, which can also be written as a halfspace polytope
constraints. DNNF currently supports the Ô¨Årst 50 of these
properties and the remainder are supported by Algorithm 1.
The DeepZono abstract domain of the ERAN veriÔ¨Åer used
in our study [46], was evaluated on 3300 L r properties
applied to a set of 24 MNIST networks and 13 CIFAR10
networks. All of the properties in this benchmark are fully
supported by our approach.
The ReluDiff veriÔ¨Åer was designed to support differential
properties in order to show equivalance between two net-works [42]. The veriÔ¨Åer was evaluated on L D properties.
Each property was deÔ¨Åned over a network, Nand a modiÔ¨Åed
version of the same network with quantized weights, N0. The
property checked whether jN(x) N0(x)j<  held in a
local region of the input space. 14 of these properties were
veriÔ¨Åed over networks from the ACAS Xu benchmark [29],
200 properties on networks trained with the MNIST dataset,
and 100 properties on a network trained for Human Activity
Recognition [3]. All 314 differencing properties are fully
supported by our approach.
The recent VNN-Comp competition used 3 benchmarks.
The Ô¨Årst is a benchmark with properties applied to networks
with piecewise linear activation functions. This benchmark
consists of the ACAS Xu benchmark [29] with 4 L r prop-
erties and 6 L R properties, as well as a set of 50 local
robustness properties with hyper-rectangle input constraints
applied to 3 MNIST networks. All of these properties are
supported by our approach. The second is a set of 300 local
robustness properties with hyper-rectangle input constraints
applied to convolutional neural networks trained on MNIST
and CIFAR10. All of these properties are supported by our
approach. The Ô¨Ånal benchmark is a set of 32 local robustness
properties with hyper-rectangle input constraints applied to
neural networks with non-linear activation functions ( sigmoid
andtanh ) trained on MNIST. All of these properties are
supported by our approach.
Several DNN veriÔ¨Åers have been introduced recently. The
nnenum veriÔ¨Åer [6] and an abstraction-reÔ¨Ånement approach
for DNN veriÔ¨Åcation [22] were evaluated on the ACAS Xu
benchmark. The reachability set representation of ImageS-
tars [52] was evaluated on two benchmarks of local robustness
properties applied to MNIST and ImageNet networks. The
benchmark on the MNIST networks used a version of 900
local robustness where pixels could be independently dark-
ened, enabling input constraints to be represented as hyper-
rectangles. The benchmark on the ImageNet networks uses 6
properties created from an original image and a corresponding
adversarial example. The properties specify that for a given re-
gion along the line between the original image and adversarial
example, all inputs along the segment are classiÔ¨Åed as the cor-
rect class. While the MNIST benchmark is supported by our
current reduction implementation, the ImageNet benchmark
requires polytope constraints in the input space and is therefore
supported just by Algorithm 1. The NNV veriÔ¨Åer [53] also
introduced a benchmark with an adaptive cruise control (ACC)
system. It checks a temporal property not currently supported
by Algorithm 1, but we see the potential to support such
properties through unrolling in future work.
Overall, we Ô¨Ånd that the property speciÔ¨Åcations accepted
by Algorithm 1 are rich enough to express 7 of the 8
property types found in the explored benchmarks.
When considering the listed benchmarks, Algorithm 1 fully
supports 16 of the 17 benchmarks. Our current implementation
completely supports the properties from 13 of the 17 bench-
280TABLE I: Property types of existing benchmarks and their support by reduction. The property type names use the following
encoding: the Ô¨Årst symbol indicates a global (G) or local (L) property; the second symbol indicates whether the input constraint
can be represented as a hyper-rectangle ( ) or not ( ); the third symbol indicates the property class as robustness (r), reachability
(R), or differential (D). Bolded benchmarks are used later in the study to evaluate RQ2 and RQ3.
Benchmark # of Property of Each Type Support
Lr Lr GR LR LR G D LD Other Algorithm 1 Implementation
ACAS Xu [29] 4 6 10 10
Collision Avoidance [21] 500 500 500
Planet-MNIST [21] 2 1 4 7 6
Neurify-MNIST [54] 500 500 500
Neurify-Drebin [54] 500 500 500
Neurify-DA VE [54] 50 150 200 50
ERAN-MNIST [46] 1700 1700 1700
ERAN-CIFAR [46] 1600 1600 1600
ReluDiff ACAS [42] 14 14 14
ReluDiff-MNIST [42] 200 200 200
ReluDiff-HAR [42] 100 100 100
VNN-COMP-CNN [34] 300 300 300
VNN-COMP-PWL [34] 54 6 60 60
VNN-COMP-NLN [34] 32 32 32
ImageStars-MNIST [52] 900 900 900
ImageStars-ImageNet [52] 6 6 0
NNV-ACC [53] 2 0 0
GHPR 20 20 20
CIFAR-EQ 91 200 291 291
marks, and supports a subset of the properties in 2 additional
benchmarks. Our results also show that the current space of
DNN properties has limited diversity, with most benchmarks
consisting primarily of local robustness properties. This points
to the value added of the new benchmarks we introduce. It is
also expected, as has happened in the veriÔ¨Åcation community
in the past, that as veriÔ¨Åcation and falsiÔ¨Åcation techniques
improve, developers will want to apply them to reason about
a broader range of correctness properties. The proposed algo-
rithm will enable them to do that, even if veriÔ¨Åers and falsiÔ¨Åers
do not directly support them.
B. RQ2: On the Cost-Effectiveness of Reduction-Enabled Fal-
siÔ¨Åcation
To evaluate the cost-effectiveness of falsiÔ¨Åcation enabled
by the proposed reduction, we identify a set of falsiÔ¨Åers
and veriÔ¨Åers to compare their complementary performance,
problem benchmarks, and metrics that constitute the basis for
the studies around RQ2 and RQ3.
1) Setup: FalsiÔ¨Åers. As falsiÔ¨Åcation methods, we will use
several common adversarial techniques, as well as a DNN
fuzzing tool. For adversarial attacks, we choose a subset of the
methods from two surveys [2], [62]. We select the methods
common to both surveys with L1input constraints (which
matches our implementation) and with implementations avail-
able in the cleverhans tool [41]. The chosen adversarial
attacks are LBFGS [50], FGSM [26], Basic Iterative Method
(BIM) [32], and DeepFool [37]. Of these attacks, none use
random initialization, and thus will produce the same result
over multiple runs. In order to observe the potential beneÔ¨Åts
of random initialization, we also include Projected Gradient
Descent (PGD) [36], which was only included in one of the
surveys. Therefore, we run each attack, except PGD, once,
and if no adversarial example is found, we return an unknown
result. For PGD, if no adversarial example is found, we tryagain, until one is found, or the given time limit is reached.
We use the default parameters for each attack, as speciÔ¨Åed by
cleverhans. For DNN fuzzing, we use TensorFuzz [39] for its
easily accessible implementation [38]. TensorFuzz requires the
deÔ¨Ånition of an oracle for recognizing property violations. We
provide a version of TensorFuzz with an oracle that identiÔ¨Åes
violations by checking whether N(x)0N(x)12.
VeriÔ¨Åers. For comparison to veriÔ¨Åcation, we select four veri-
Ô¨Åers: Reluplex [29], Planet [21], ERAN using the DeepZono
abstract domain [46], and Neurify [54]. Neurify and ERAN
have been shown to be fastest and most accurate in recent
studies [61], and all four veriÔ¨Åers are supported by DNNV ,
which makes them easy to run and allows us to use a
common property speciÔ¨Åcation for all veriÔ¨Åers and falsiÔ¨Åers.
For differential properties we also consider ReluDiff [42] since
it is currently the only veriÔ¨Åer built to handle such properties.
Portfolios. In addition to the individual falsiÔ¨Åers and veriÔ¨Åers,
we simulate portfolios of these methods, which run analyses
in parallel and return the Ô¨Årst result. We use 3 portfolios: All
FalsiÔ¨Åers , which includes the 6 falsiÔ¨Åers described above; All
VeriÔ¨Åers which includes all veriÔ¨Åers run on each benchmark;
Total which includes all methods used in this study. To
simulate running each portfolio, we take the union of the
violations found by each method in the portfolio, and consider
the time to Ô¨Ånd each violation to be the fastest time among
the methods in the portfolio which found that violation.
Problem Benchmarks. We evaluate our approach on two
common and representative benchmarks from the veriÔ¨Åcation
literature, and two created for this work to provide a range of
networks and property types. Our selection criteria was meant
to achieve two objectives. First, we wanted to select enough
benchmarks to explore all property types with hyper-rectangle
input constraints. Second, we wanted to select benchmarks
2https://github.com/dlshriver/tensorfuzz
281(a) ACAS Xu
 (b) Neurify-DA VE
(c) GHPR MNIST
 (d) GHPR DroNet
(e) CIFAR-EQ
Fig. 3: The number of violations found by each falsiÔ¨Åer and veriÔ¨Åer, reduced by the total number of potentially falsiÔ¨Åable
properties. The number above each bar gives the total number of violations found. An exclamation point indicates that a veriÔ¨Åer
could not be run on a property due to the structure of the network.
with networks that varied in both size and structure since these
factors have been shown to affect veriÔ¨Åer performance [61].
From the veriÔ¨Åcation literature, we select ACAS Xu , the most
commonly used benchmark, and a slightly modiÔ¨Åed version of
theNeurify-DAVE benchmark. For Neurify-DA VE, we select
the 50 L R properties supported by our current implemen-
tation, and we augment the benchmark with an additional
network. The new network is the original DA VE DNN on
which the smaller network in the benchmark was based. While
the small DNN has 10277 neurons, the original DA VE network
that we add has 82669 neurons, which will allow us to explore
the scalability of reduction and falsiÔ¨Åcation. The two networks
in this benchmark are convolutional networks and are much
larger than the networks in the ACAS Xu benchmark.
We developed 2 new benchmarks to cover property types
that are not yet covered by existing benchmarks. The GHPR
benchmark is a new DNN property benchmark that contains
GR properties applied to several network architectures of
varying size and structure. It consists of 30 correctness prob-
lems, 20 of which are 10 GHPR properties applied to 2 MNIST
networks, and 10 of which are GHPR properties applied to the
DroNet DNN described previously. The DroNet DNN is one of
the largest in our study, with more than 475,000 neurons. The
MNIST properties are of the form: for all inputs, the output
values for classes aandbare closer to one another than either
is to the output value of class c. The DroNet properties are
of the form: for all inputs, if the probability of collision is
betweenpmin andpmax, then the steering angle is within d
degrees of 0. These properties are described in more detail in
the supplementary material3.
The CIFAR-EQ benchmark is a new DNN property bench-
mark with differential properties applied to large networks
with complex structures. It contains a mix of both global
and local equivalence properties. It is the only benchmark to
contain G D properties, which were absent in the property
benchmarks that we found. It consists of 291 properties:
3https://github.com/dlshriver/DNNF/blob/main/docs/ static/appendix.pdf91 global equivalence properties and 200 local equivalence
properties. Of the global properties, 1 is untargeted, while the
other 90 are targeted equivalence properties. Of the 200 local
properties, 20 are untargeted, while the other 180 are targeted
equivalence properties. The properties are applied to a pair of
neural networks trained on the CIFAR dataset [31]. The Ô¨Årst
network is a large convolutional network with 62,464 neurons
and the second is a ResNet-18 network with over 588,000
neurons. These properties are described in more detail in the
supplementary material. Because the veriÔ¨Åers do not support
the multiple computation path structure formed during network
composition, we do not run them on this benchmark.
Metrics. For each veriÔ¨Åcation and falsiÔ¨Åcation approach, we
will measure the number of property violations found and
the total time to Ô¨Ånd each violation. The total time to Ô¨Ånd
a violation includes both the time to transform the property,
as well as to run the falsiÔ¨Åer on the resulting properties.
Computing resources. Experiments were run on compute
nodes with Intel Xeon Silver 4214 processers at 2.20 GHz and
512GB of memory. Jobs were allowed to use up to 8 processor
cores, 64GB of memory, with a time limit of 1 hour.
2) Results: Figure 3 shows the number of violations found
by each veriÔ¨Åer and falsiÔ¨Åer method on the Ô¨Åve benchmarks.
The y-axis is the proportion of non-veriÔ¨Åed properties for
which the techniques could Ô¨Ånd violations. We eliminated
correctness problems that were known to be unfalsiÔ¨Åable.
For ACAS this leaves 37 correctness problems, and does not
reduce any of the other benchmarks. The number above each
bar in the plots indicates the number of violations found. An
exclamation point indicates that the veriÔ¨Åer could not be run
due to the architecture of the networks being veriÔ¨Åed.
The ACAS Xu benchmark with its simple and small DNN
models, often used in veriÔ¨Åer evaluation, showcases where ver-
iÔ¨Åers perform best today. However, even in this benchmark we
notice that falsiÔ¨Åcation can complement veriÔ¨Åcation, Ô¨Ånding an
additional 3 violations.
On the Neurify-DA VE benchmarks, the veriÔ¨Åers Ô¨Ånd only
33 violations from the 100 DNN correctness problems, while
282(a) ACAS Xu
 (b) Neurify-DA VE
 (c) GHPR MNIST
 (d) GHPR DroNet
 (e) CIFAR-EQ
Fig. 4: The times, in seconds, to Ô¨Ånd violations for each veriÔ¨Åer and falsiÔ¨Åer. An exclamation point indicates that a veriÔ¨Åer
could not be run on a property due to the structure of the network.
the falsiÔ¨Åers Ô¨Ånd 82 violations, subsuming the 33 violations
from the veriÔ¨Åers. The best performing falsiÔ¨Åcation method
on this benchmark was BIM, with 74 violations found. PGD
and FGSM follow closely with 73 and 69 violations found, re-
spectively. TensorFuzz, the top performing falsiÔ¨Åcation method
on the ACAS benchmark, does not Ô¨Ånd any violations. We
conjecture that this is due to the much larger input space.
While the ACAS Xu networks have an input dimension of 5,
the DA VE networks have an input dimension of 30000, which
is more difÔ¨Åcult to cover by random fuzzing.
On the GHPR MNIST benchmark, the veriÔ¨Åers can Ô¨Ånd 17
violations for the 20 properties, while 3 falsiÔ¨Åers, BIM, PGD,
and TensorFuzz, can Ô¨Ånd violations for every property.
On the GHPR DroNet benchmark, the veriÔ¨Åers cannot
Ô¨Ånd any violations, due to not supporting the residual block
structures present in the DroNet network. Many of the falsiÔ¨Åers
also struggle on these properties, except for PGD and BIM,
which can Ô¨Ånd violations to all 10 properties.
Finally, on the CIFAR-EQ benchmark, the veriÔ¨Åers did not
Ô¨Ånd any violations because they could not be run. Reluplex,
Planet, ERAN, and Neurify do not support properties over
multiple networks or networks with multiple computation
paths, while ReluDiff is limited to networks with only fully-
connected layers. Additionally, while PGD Ô¨Ånds the most
violations, it is complemented by the other falsiÔ¨Åcation ap-
proaches, with BIM, DeepFool, and TensorFuzz each Ô¨Ånding
violations for at least 1 unique property. We conjecture that
much of PGD‚Äôs success is due to its random initialization,
which allows it to be run multiple times with different results,
increasing the chance of Ô¨Ånding a violation.
Note that the Planet and ERAN veriÔ¨Åers Ô¨Ånd no violations
for any benchmark. For these benchmarks ERAN cannot Ô¨Ånd
violations since its algorithmic approach focuses on proving
that a property holds, which suggests its complementarity with
falsiÔ¨Åcation methods. Planet fails to Ô¨Ånd violations due to the
complexity of the problem, and internal tool errors that cause
Planet to crash on almost 20% of the correctness problems.
We also see that the Reluplex veriÔ¨Åer only Ô¨Ånds violations
for the ACAS Xu benchmark. It cannot Ô¨Ånd violations on the
other benchmarks, since it does not support the architecturesof the networks in those benchmarks.
Overall, we Ô¨Ånd that falsiÔ¨Åers can detect many property
violations usually complementing those found by veri-
Ô¨Åcation, that applying them in a parallel portfolio can
leverage their unique strengths, and that they successfully
scale to more complex benchmarks.
Box plots of the distributions of time to Ô¨Ånd violations for
each method are shown in Figure 4. Figure 4a shows that
the veriÔ¨Åers can be effective on the ACAS Xu benchmark,
with Neurify often out performing the falsiÔ¨Åers. This is likely
due to the extremely small size of the ACAS Xu networks
enabling veriÔ¨Åcation to run efÔ¨Åciently. These plots also show
the efÔ¨Åciency struggle of the veriÔ¨Åers as the network get larger.
For example, on the Neurify-DA VE benchmark, even when the
veriÔ¨Åers can Ô¨Ånd a property violation, the falsiÔ¨Åers can Ô¨Ånd
violations an order of magnitude faster. For more complex
benchmarks, the veriÔ¨Åers cannot Ô¨Ånd violations within the
timeout, so we only report the time for the falsiÔ¨Åers.
We Ô¨Ånd that falsiÔ¨Åcation can efÔ¨Åciently Ô¨Ånd property
violations even for the most complex benchmarks, with
a median time to Ô¨Ånd a violation across all benchmarks
and falsiÔ¨Åers of 16 seconds.
Figures 3 and 4 also reveal that no single falsiÔ¨Åer always
outperforms the others. While PGD performs well for the
benchmarks studied here, we can still increase the number
of violations by running mutliple falsiÔ¨Åers. Additionally, the
falsiÔ¨Åers that Ô¨Ånd the most violations, do not necessarily
always Ô¨Ånd them the fastest. Based on these two observations,
we recommend using a portfolio approach, running many
falsiÔ¨Åers in parallel and stopping as soon as a violation is found
by any technique, such as the All FalsiÔ¨Åers method shown
in the previous Ô¨Ågures. This approach Ô¨Ånds all the violations
found by the veriÔ¨Åers as quickly as the fastest falsiÔ¨Åer. We
also recommend using falsiÔ¨Åers in conjunction with veriÔ¨Åers,
since while falsiÔ¨Åers can often quickly Ô¨Ånd violations, they
cannot prove when a property holds.
283(a) Small DA VE
 (b) Large DA VE
 (c) Small DA VE
 (d) Large DA VE
Fig. 5: The number of violations and time to Ô¨Ånd each violation for the Neurify-DA VE benchmark. The number above each
bar gives the total number of property check results in the bar below it. An exclamation point indicates that a veriÔ¨Åer could
not be run on a property due to the structure of the network.
C. RQ3: On the Scalability of Reduction-Enabled FalsiÔ¨Åcation
1) Setup: To explore the scalability of falsiÔ¨Åcation with
reduction, we want to evaluate a set of properties across
networks that vary in size. To do this we applied the Neurify-
DA VE properties to both the small DA VE network [54] and
the original larger DA VE network [10]. This will allow us to
see how performance of the veriÔ¨Åers and falsiÔ¨Åers change with
respect to the size of the network being veriÔ¨Åed.
2) Results: We present the results of checking the proper-
ties in Figures 5a and 5b, as well as the box plots of the times
to Ô¨Ånd violations for each method in Figures 5c and 5d.
On the smaller DA VE network, the veriÔ¨Åers struggle to
verify the properties. Reluplex does not run at all, due to its
lack of support for convolutional layers, while Planet does
run, but reaches the timeout for all properties. The ERAN
veriÔ¨Åer does not timeout on the small network, but cannot
verify any of the properties. Neurify was the only veriÔ¨Åer that
returned accurate results on the small network, successfully
falsifying 33 of the 50 properties, and reaching the time limit
on the other 17. While only a single veriÔ¨Åer was able to falsify
any properties, 4 of the 6 falsiÔ¨Åcation approaches were able
to falsify properties, all of them Ô¨Ånding more violations than
Neurify. The falsiÔ¨Åers were also faster than Neurify, Ô¨Ånding
violations almost an order of magnitude faster than Neurify
on the small DA VE network.
While one veriÔ¨Åer was able to Ô¨Ånd violations on the smaller
network, none of the veriÔ¨Åers were able to Ô¨Ånd violations
on the larger DA VE network, which has more than 8 times
more neurons. Similar to the small network, Reluplex does
not support the network structure, while Planet reaches the
time limit for all properties. However, ERAN and Neurify both
perform slightly differently. While ERAN was previously able
to Ô¨Ånish its analysis on the small network, it reaches the time
limit for 34 properties on the large network, indicating that it
could not scale to the larger network size. Similarly, while
Neurify previously found property violations for the small
network, it reaches the memory limit on the large network
before any violations are found. The falsiÔ¨Åers on the otherhand still perform well, with 3 of the 6 veriÔ¨Åers Ô¨Ånding
property violations. Surprisingly, the DeepFool falsiÔ¨Åer goes
from 44 violations found on the small network, to 0 violations
on the large DA VE network. We conjecture that this may
be due to the use of the default parameters for DeepFool,
and that adjusting these parameters may yield better results.
Additionally, the falsiÔ¨Åers show only a minor increase in the
time needed to Ô¨Ånd a violation, from a median time of 20.2
seconds to 20.7 seconds.
Overall we Ô¨Ånd that, on the benchmarks explored here,
DNN property reduction scales well to larger networks,
and enables the application of scalable falsiÔ¨Åcation ap-
proaches such as adversarial example generation.
V. C ONCLUSION
In this work we present an approach for reducing DNN
correctness problems to facilitate the application of falsiÔ¨Åers,
in particular adversarial attacks, for Ô¨Ånding DNN property
violations. We implement our approach and apply it to a
range of correctness problem benchmarks and Ô¨Ånd that 1) the
reduction approach covers a rich set of properties, 2) reducing
problems enables falsiÔ¨Åers to Ô¨Ånd property violations, and 3)
since falsiÔ¨Åers tend to have different strengths, a portfolio
approach can increase the violation Ô¨Ånding ability. In future
work we plan to extend DNNF to support the full range of
properties supported by our algorithmic approach, perform a
systematic evaluation of what factors may inÔ¨Çuence falsiÔ¨Åer
performance, and explore how reduction can also broaden the
applicability of veriÔ¨Åers.
DATA AVAILABILITY
We make DNNF available at https://github.com/dlshriver/
DNNF, and we provide an artifact containing the tool, as well
as the data and scripts required to replicate our study at https:
//doi.org/10.5281/zenodo.4439219.
ACKNOWLEDGMENTS
This material is based in part upon work supported by
National Science Foundation awards 1900676 and 2019239.
284APPENDIX
A. Proofs
Lemma 1. Letbe a conjunction of linear inequalities over
the variables xifor i from 0ton 1. We can construct an
H-polytopeH= (A;b)with Alg. 2 s.t. (Axb),(xj=).
Proof. Letf(x) =Pn 1
0aixiWe Ô¨Årst show that every lin.
ineq. in the conjunction can be reformulated to the form
f(x)b. It is trivial to show the ineq. can be manipulated
to have variables on lhs and a constant on rhs, that can
be manipulated to an equivalent form with , and>can be
manipulated to become <. The<comparison can be changed
to acomparison by decrementing the rhs constant from b
tob0whereb0is the largest representable number less than
b. We prove ineq. with <can be reformulated to use by
contradiction. Assume either f(x)< b andf(x)> b0or
f(x)bandf(x)b0. Eitherb0<f(x)<b, a contradiction,
sincef(x)cannot be both larger than the largest representable
number less than band also less than b.4Orbf(x)b0, a
contradiction, since b0<bby deÔ¨Ånition.
Given a conjunction of lin. ineq. in the form f(x)b,
Alg. 2 constructs Aandbwith a row in Aand value in b
corresponding to each conjunct. There are two cases: (Ax
b)!(xj=)and(xj=)!(Axb).
We prove case 1 by contradiction. Assume (Axb)and
(x6j=). By construction of Hin Alg. 2, each conjunct of 
is exactly 1 constraint in H. IfAxb, then all constraints
inHmust be satisifed, and thus all conjuncts in must be
satisÔ¨Åed and xj=, a contradiction.
We prove case 2 by contradiction. Assume (xj=)and
(Ax6b). By construction of Hin Alg. 2, each conjunct of
is exactly 1 constraint in H. Ifxj=, then all conjuncts
inmust be satisÔ¨Åed, and thus all constraints in Hmust be
satisifed and Axb, a contradiction.
Lemma 2. LetH= (A;b)be an H-polytope s.t. Axb.
Alg. 4 constructs a DNN, Ns, that classiÔ¨Åes whether inputs
satisfyAxb. Formally,x2H,N s(x)0N s(x)1.
Proof. There are 2 cases:
1)x2H!N s(x)0N s(x)1
2)Ns(x)0N s(x)1!x2H
We prove case 1 by contradiction. Assume x2Hand
Ns(x)0>Ns(x)1. From Alg. 4, each neuron in the hidden
layer ofNscorresponds to one constraint in H. The weights
of each neuron are the values in the corresponding row of A,
and the bias is the negation of the corresponding value of b.
If inputxsatisÔ¨Åes the constraint, then the neuron value will
be at most 0, otherwise it will be greater than 0. After the
ReLU, each neuron will be equal to 0 if the corresponding
constraint is satisÔ¨Åed by xand greater than 0 otherwise. The
Ô¨Årst output neuron sums all neurons in the hidden layer, while
the second has a constant value of 0. If x2H, then all
neurons in the hidden layer after activation must have a value
of 0 since all constraints are satisÔ¨Åed. However, if all neurons
4We discuss the assumption that such a number exists in Appendix B.have value 0, then their sum must also be 0, and therefore
Ns(x)0=Ns(x)1, a contradiction.
We prove case 2 by contradiction. Assume Ns(x)0
Ns(x)1andx62H. Ifx62H, at least one neuron in the hidden
layer must have a value greater than 0 after the ReLU since at
least one constraint is not satisÔ¨Åed. Because some neuron has
a value greater than 0, their sum must also be greater than 0,
and thereforeNs(x)0>Ns(x)1, a contradiction.
Lemma 3. LetH= (A;b)be an H-polytope s.t. Axb.
Alg. 3 constructs a DNN, Np, that maps values from the n-dim.
unit hypercube to the axis aligned hyperrectangle that mini-
mally bounds H. The range of this mapping does not exclude
anyxs.t.Axb. Formally,8x2H:9z2[0;1]n:x=Np(z).
Proof. The proof is by contradiction. Let the axis aligned
hyperrectangle that minimally bounds Hbe speciÔ¨Åed by lower
bounds~lband upper bounds ~ubs.t.8x2H:8i:xi2[lbi;ubi].
Alg. 3 constructs a DNN, Np, that computesNp(z) =Wz+b,
whereW= diag(ub lb)andb=lb. This function is
invertible:N 1
p(x) =W 1(x b) =W 1x W 1b. Assume
9x2H:9i:(z=N 1
p(x))^((zi<0)_(zi>1)). From
the def. ofN 1
p, we getN 1
p(lb)iziN 1
p(ub)iand
W 1
i;i(lbi) W 1
i;i(lbi) = 0ziW 1
i;i(ubi) W 1
i;i(lbi) =
(1
ubi lbi(ubi) 1
ubi lbi(lbi)) = 1 . Therefore (lbixi
ubi)!(0zi1), a contradiction.
Theorem 2. Let =hN;ibe a correctness problem with its
property deÔ¨Åned as a formula of disjunctions and conjunctions
of linear inequalities over the inputs and outputs of N.
Property Reduction (Alg. 1) maps  to an equivalid set of
correctness problems reduce ( ) =fhN1;1i;:::;hNk;kig.
Nj= ,8hN i;ii2reduce ( ):Nij=i
Proof. A model that satisÔ¨Åes any disjunct of DNF (:)
falsiÔ¨Åes. Ifis falsiÔ¨Åable, then at least one disjunct of
DNF (:)is satisÔ¨Åable.
Alg. 1 constructs a correctness problem for each dis-
junct. For each disjunct, Alg. 1 constructs an H-polytope,
H, which is used to construct a preÔ¨Åx network, Np, and
sufÔ¨Åx network,Ns. The algorithm then constructs networks
N0(x) =concat (N(x);x)andN00(x) =Ns(N0(Np(x))).
Alg. 1 pairs each constructed network with the property
=8x:x2[0;1]n!N00(x)0>N00(x)1. A violation occurs
only whenN00(x)0N00(x)1. By Lemmas 1, 2, and 3, we
get thatN00(x)0N00(x)1if and only ifN0(x)2H. If
N0(x)2HthenN0(x)satisÔ¨Åes the disjunct and is therefore
a violation of the original property.
B. On Existance of a Bounded Largest Representable Number
Our proof that property reduction generates a set of ro-
bustness problems equivalid to an arbitrary problem relies on
the assumption that strict inequalities can be converted to non-
strict inequalities. To do so we rely on the existance of a largest
representable number that is less than some given value. While
this is not necessarily true for all sets of numbers (e.g., R), it is
true for for most numeric representations used in computation
(e.g., IEEE 754 Ô¨Çoating point arithmetic).
285REFERENCES
[1] Arvind Adimoolam, Thao Dang, Alexandre Donz ¬¥e, James Kapinski,
and Xiaoqing Jin. ClassiÔ¨Åcation and coverage-based falsiÔ¨Åcation for
embedded control systems. In International Conference on Computer
Aided VeriÔ¨Åcation , pages 483‚Äì503. Springer, 2017.
[2] N. Akhtar and A. Mian. Threat of adversarial attacks on deep learning
in computer vision: A survey. IEEE Access , 6:14410‚Äì14430, 2018.
[3] Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra, and
Jorge Luis Reyes-Ortiz. A public domain dataset for human activity
recognition using smartphones. In 21st European Symposium on
ArtiÔ¨Åcial Neural Networks, ESANN 2013, Bruges, Belgium, April 24-
26, 2013 , 2013.
[4] Yashwanth Annpureddy, Che Liu, Georgios Fainekos, and Sriram
Sankaranarayanan. S-taliro: A tool for temporal logic falsiÔ¨Åcation for
hybrid systems. In International Conference on Tools and Algorithms
for the Construction and Analysis of Systems , pages 254‚Äì257. Springer,
2011.
[5] Daniel Arp, Michael Spreitzenbarth, Malte Hubner, Hugo Gascon, and
Konrad Rieck. DREBIN: effective and explainable detection of android
malware in your pocket. In 21st Annual Network and Distributed System
Security Symposium, NDSS 2014, San Diego, California, USA, February
23-26, 2014 . The Internet Society, 2014.
[6] Stanley Bak, Hoang-Dung Tran, Kerianne Hobbs, and Taylor T. Johnson.
Improved geometric path enumeration for verifying relu neural networks.
In Shuvendu K. Lahiri and Chao Wang, editors, Computer Aided Veri-
Ô¨Åcation , pages 66‚Äì96, Cham, 2020. Springer International Publishing.
[7] Osbert Bastani, Yani Ioannou, Leonidas Lampropoulos, Dimitrios Vy-
tiniotis, Aditya V . Nori, and Antonio Criminisi. Measuring neural net
robustness with constraints. In Proceedings of the 30th International
Conference on Neural Information Processing Systems , NIPS‚Äô16, pages
2621‚Äì2629, USA, 2016. Curran Associates Inc.
[8] Armin Biere, Alessandro Cimatti, Edmund M Clarke, Masahiro Fujita,
and Yunshan Zhu. Symbolic model checking using sat procedures
instead of bdds. In Proceedings of the 36th annual ACM/IEEE Design
Automation Conference , pages 317‚Äì320, 1999.
[9] Mariusz Bojarski, Davide Del Testa, Daniel Dworakowski, Bernhard
Firner, Beat Flepp, Prasoon Goyal, Lawrence D. Jackel, Mathew Mon-
fort, Urs Muller, Jiakai Zhang, Xin Zhang, Jake Zhao, and Karol Zieba.
End to end learning for self-driving cars. In NIPS 2016 Deep Learning
Symposium , 2016.
[10] Mariusz Bojarski, Davide Del Testa, Daniel Dworakowski, Bernhard
Firner, Beat Flepp, Prasoon Goyal, Lawrence D. Jackel, Mathew Mon-
fort, Urs Muller, Jiakai Zhang, Xin Zhang, Jake Zhao, and Karol Zieba.
End to end learning for self-driving cars. CoRR , abs/1604.07316, 2016.
[11] Akhilan Boopathy, Tsui-Wei Weng, Pin-Yu Chen, Sijia Liu, and Luca
Daniel. Cnn-cert: An efÔ¨Åcient framework for certifying robustness of
convolutional neural networks. In AAAI , Jan 2019.
[12] Elena Botoeva, Panagiotis Kouvaros, Jan Kronqvist, Alessio Lomuscio,
and Ruth Misener. EfÔ¨Åcient veriÔ¨Åcation of relu-based neural networks
via dependency analysis. In The Thirty-Fourth AAAI Conference on
ArtiÔ¨Åcial Intelligence, AAAI 2020, The Thirty-Second Innovative Ap-
plications of ArtiÔ¨Åcial Intelligence Conference, IAAI 2020, The Tenth
AAAI Symposium on Educational Advances in ArtiÔ¨Åcial Intelligence,
EAAI 2020, New York, NY, USA, February 7-12, 2020 , pages 3291‚Äì
3299. AAAI Press, 2020.
[13] Rudy R. Bunel, Ilker Turkaslan, Philip H. S. Torr, Pushmeet Kohli, and
Pawan Kumar Mudigonda. A uniÔ¨Åed view of piecewise linear neural
network veriÔ¨Åcation. In NeurIPS , pages 4795‚Äì4804, 2018.
[14] Nicholas Carlini and David A. Wagner. Towards evaluating the robust-
ness of neural networks. CoRR , abs/1608.04644, 2016.
[15] F. Codevilla, M. Miiller, A. L ¬¥opez, V . Koltun, and A. Dosovitskiy.
End-to-end driving via conditional imitation learning. In 2018 IEEE
International Conference on Robotics and Automation (ICRA) , pages
1‚Äì9, May 2018.
[16] Cas JF Cremers. The scyther tool: VeriÔ¨Åcation, falsiÔ¨Åcation, and analysis
of security protocols. In International conference on computer aided
veriÔ¨Åcation , pages 414‚Äì418. Springer, 2008.
[17] Jeffrey De Fauw, Joseph R. Ledsam, Bernardino Romera-Paredes,
Stanislav Nikolov, Nenad Tomasev, Sam Blackwell, Harry Askham,
Xavier Glorot, Brendan O‚ÄôDonoghue, Daniel Visentin, George van den
Driessche, Balaji Lakshminarayanan, Clemens Meyer, Faith Mackinder,
Simon Bouton, Kareem Ayoub, Reena Chopra, Dominic King, Alan
Karthikesalingam, C ¬¥ƒ±an O. Hughes, Rosalind Raine, Julian Hughes,Dawn A. Sim, Catherine Egan, Adnan Tufail, Hugh Montgomery, Demis
Hassabis, Geraint Rees, Trevor Back, Peng T. Khaw, Mustafa Suleyman,
Julien Cornebise, Pearse A. Keane, and Olaf Ronneberger. Clinically
applicable deep learning for diagnosis and referral in retinal disease.
Nature Medicine , 24(9):1342‚Äì1350, Sep 2018.
[18] Tommaso Dreossi, Alexandre Donz ¬¥e, and Sanjit A Seshia. Compo-
sitional falsiÔ¨Åcation of cyber-physical systems with machine learning
components. Journal of Automated Reasoning , 63(4):1031‚Äì1053, 2019.
[19] Souradeep Dutta, Susmit Jha, Sriram Sankaranarayanan, and Ashish
Tiwari. Output range analysis for deep feedforward neural networks.
InNFM , volume 10811 of Lecture Notes in Computer Science , pages
121‚Äì138. Springer, 2018.
[20] Krishnamurthy Dvijotham, Robert Stanforth, Sven Gowal, Timothy
Mann, and Pushmeet Kohli. A dual approach to scalable veriÔ¨Åcation
of deep networks. In Proceedings of the Thirty-Fourth Conference
Annual Conference on Uncertainty in ArtiÔ¨Åcial Intelligence (UAI-18) ,
pages 162‚Äì171, Corvallis, Oregon, 2018. AUAI Press.
[21] R ¬®udiger Ehlers. Formal veriÔ¨Åcation of piece-wise linear feed-forward
neural networks. In Automated Technology for VeriÔ¨Åcation and Analysis
- 15th International Symposium, ATVA 2017, Pune, India, October 3-6,
2017, Proceedings , pages 269‚Äì286, 2017.
[22] Yizhak Yisrael Elboher, Justin Gottschlich, and Guy Katz. An
abstraction-based framework for neural network veriÔ¨Åcation. In Shu-
vendu K. Lahiri and Chao Wang, editors, Computer Aided VeriÔ¨Åcation -
32nd International Conference, CAV 2020, Los Angeles, CA, USA, July
21-24, 2020, Proceedings, Part I , volume 12224 of Lecture Notes in
Computer Science , pages 43‚Äì65. Springer, 2020.
[23] Andre Esteva, Brett Kuprel, Roberto A. Novoa, Justin Ko, Susan M.
Swetter, Helen M. Blau, and Sebastian Thrun. Dermatologist-level
classiÔ¨Åcation of skin cancer with deep neural networks. Nature ,
542(7639):115‚Äì118, Feb 2017.
[24] T. Gehr, M. Mirman, D. Drachsler-Cohen, P. Tsankov, S. Chaudhuri, and
M. Vechev. Ai2: Safety and robustness certiÔ¨Åcation of neural networks
with abstract interpretation. In 2018 IEEE Symposium on Security and
Privacy (SP) , pages 3‚Äì18, May 2018.
[25] Patrice Godefroid and Pierre Wolper. Using partial orders for the
efÔ¨Åcient veriÔ¨Åcation of deadlock freedom and safety properties. In
International Conference on Computer Aided VeriÔ¨Åcation , pages 332‚Äì
342. Springer, 1991.
[26] Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining
and harnessing adversarial examples. In Yoshua Bengio and Yann Le-
Cun, editors, 3rd International Conference on Learning Representations,
ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track
Proceedings , 2015.
[27] Gerard J. Holzmann. The model checker spin. IEEE Transactions on
software engineering , 23(5):279‚Äì295, 1997.
[28] Xiaowei Huang, Marta Kwiatkowska, Sen Wang, and Min Wu. Safety
veriÔ¨Åcation of deep neural networks. In CAV (1) , volume 10426 of
Lecture Notes in Computer Science , pages 3‚Äì29. Springer, 2017.
[29] Guy Katz, Clark W. Barrett, David L. Dill, Kyle Julian, and Mykel J.
Kochenderfer. Reluplex: An efÔ¨Åcient SMT solver for verifying deep
neural networks. In Computer Aided VeriÔ¨Åcation - 29th International
Conference, CAV 2017, Heidelberg, Germany, July 24-28, 2017, Pro-
ceedings, Part I , pages 97‚Äì117, 2017.
[30] Guy Katz, Derek A Huang, Duligur Ibeling, Kyle Julian, Christopher
Lazarus, Rachel Lim, Parth Shah, Shantanu Thakoor, Haoze Wu, Alek-
sandar Zelji ¬¥c, et al. The Marabou framework for veriÔ¨Åcation and analysis
of deep neural networks. In International Conference on Computer
Aided VeriÔ¨Åcation , pages 443‚Äì452, 2019.
[31] Alex Krizhevsky and Geoffrey Hinton. Learning multiple layers of
features from tiny images. 2009.
[32] Alexey Kurakin, Ian J. Goodfellow, and Samy Bengio. Adversarial
examples in the physical world. In 5th International Conference on
Learning Representations, ICLR 2017, Toulon, France, April 24-26,
2017, Workshop Track Proceedings . OpenReview.net, 2017.
[33] Changliu Liu, Tomer Arnon, Christopher Lazarus, Clark W. Barrett, and
Mykel J. Kochenderfer. Algorithms for verifying deep neural networks.
CoRR , abs/1903.06758, 2019.
[34] Changliu Liu and Taylor T. Johnson. Vnn-comp.
https://sites.google.com/view/vnn20/vnncomp.
[35] Antonio Loquercio, Ana Isabel Maqueda, Carlos R. Del Blanco, and
Davide Scaramuzza. Dronet: Learning to Ô¨Çy by driving. IEEE Robotics
and Automation Letters , 2018.
286[36] Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris
Tsipras, and Adrian Vladu. Towards deep learning models resistant
to adversarial attacks. In 6th International Conference on Learning
Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May
3, 2018, Conference Track Proceedings . OpenReview.net, 2018.
[37] Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and Pascal
Frossard. Deepfool: A simple and accurate method to fool deep neural
networks. In 2016 IEEE Conference on Computer Vision and Pattern
Recognition, CVPR 2016, Las Vegas, NV , USA, June 27-30, 2016 , pages
2574‚Äì2582. IEEE Computer Society, 2016.
[38] Augustus Odena, Catherine Olsson, David Andersen, and Ian Goodfel-
low. TensorFuzz, 2019. https://github.com/brain-research/tensorfuzz.
[39] Augustus Odena, Catherine Olsson, David Andersen, and Ian Good-
fellow. TensorFuzz: Debugging neural networks with coverage-guided
fuzzing. In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors,
Proceedings of the 36th International Conference on Machine Learning ,
volume 97 of Proceedings of Machine Learning Research , pages 4901‚Äì
4911, Long Beach, California, USA, 09‚Äì15 Jun 2019. PMLR.
[40] Kurt M. Olender and Leon J. Osterweil. Interprocedural static analysis of
sequencing constraints. ACM Trans. Softw. Eng. Methodol. , 1(1):21‚Äì52,
January 1992.
[41] Nicolas Papernot, Fartash Faghri, Nicholas Carlini, Ian Goodfellow,
Reuben Feinman, Alexey Kurakin, Cihang Xie, Yash Sharma, Tom
Brown, Aurko Roy, Alexander Matyasko, Vahid Behzadan, Karen Ham-
bardzumyan, Zhishuai Zhang, Yi-Lin Juang, Zhi Li, Ryan Sheatsley,
Abhibhav Garg, Jonathan Uesato, Willi Gierke, Yinpeng Dong, David
Berthelot, Paul Hendricks, Jonas Rauber, and Rujun Long. Technical
report on the cleverhans v2.1.0 adversarial examples library. arXiv
preprint arXiv:1610.00768 , 2018.
[42] Brandon Paulsen, Jingbo Wang, and Chao Wang. Reludiff: Differential
veriÔ¨Åcation of deep neural networks. In Proceedings of the 42nd
International Conference on Software Engineering, ICSE 2020 , 2020.
[43] Aditi Raghunathan, Jacob Steinhardt, and Percy Liang. CertiÔ¨Åed
defenses against adversarial examples. In ICLR . OpenReview.net, 2018.
[44] Wenjie Ruan, Xiaowei Huang, and Marta Kwiatkowska. Reachability
analysis of deep neural networks with provable guarantees. In IJCAI ,
pages 2651‚Äì2659. ijcai.org, 2018.
[45] David Shriver, Dong Xu, Sebastian G. Elbaum, and Matthew B. Dwyer.
Refactoring neural networks for veriÔ¨Åcation. CoRR , abs/1908.08026,
2019.
[46] Gagandeep Singh, Timon Gehr, Matthew Mirman, Markus P ¬®uschel,
and Martin Vechev. Fast and effective robustness certiÔ¨Åcation. In
S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi,
and R. Garnett, editors, Advances in Neural Information Processing
Systems 31 , pages 10802‚Äì10813. Curran Associates, Inc., 2018.
[47] Gagandeep Singh, Timon Gehr, Markus P ¬®uschel, and Martin T.
Vechev. An abstract domain for certifying neural networks. PACMPL ,
3(POPL):41:1‚Äì41:30, 2019.
[48] Robert E. Strom and Daniel M Yellin. Extending typestate checking
using conditional liveness analysis. IEEE Transactions on Software
Engineering , 19(5):478‚Äì485, 1993.
[49] Jiawei Su, Danilo Vasconcellos Vargas, and Kouichi Sakurai. One pixel
attack for fooling deep neural networks. CoRR , abs/1710.08864, 2017.
[50] Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna,
Dumitru Erhan, Ian J. Goodfellow, and Rob Fergus. Intriguing properties
of neural networks. In Yoshua Bengio and Yann LeCun, editors,
2nd International Conference on Learning Representations, ICLR 2014,
Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings ,
2014.
[51] Vincent Tjeng, Kai Y . Xiao, and Russ Tedrake. Evaluating robustness
of neural networks with mixed integer programming. In International
Conference on Learning Representations , 2019.
[52] Hoang-Dung Tran, Stanley Bak, Weiming Xiang, and Taylor T. Johnson.
VeriÔ¨Åcation of deep convolutional neural networks using imagestars.
In Shuvendu K. Lahiri and Chao Wang, editors, Computer Aided
VeriÔ¨Åcation - 32nd International Conference, CAV 2020, Los Angeles,
CA, USA, July 21-24, 2020, Proceedings, Part I , volume 12224 of
Lecture Notes in Computer Science , pages 18‚Äì42. Springer, 2020.
[53] Hoang-Dung Tran, Xiaodong Yang, Diego Manzanas Lopez, Patrick
Musau, Luan Viet Nguyen, Weiming Xiang, Stanley Bak, and Taylor T.
Johnson. NNV: the neural network veriÔ¨Åcation tool for deep neural
networks and learning-enabled cyber-physical systems. In Shuvendu K.
Lahiri and Chao Wang, editors, Computer Aided VeriÔ¨Åcation - 32nd
International Conference, CAV 2020, Los Angeles, CA, USA, July 21-24,2020, Proceedings, Part I , volume 12224 of Lecture Notes in Computer
Science , pages 3‚Äì17. Springer, 2020.
[54] Shiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, and Suman
Jana. EfÔ¨Åcient formal safety analysis of neural networks. In NeurIPS ,
pages 6369‚Äì6379, 2018.
[55] Shiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, and Suman
Jana. Formal security analysis of neural networks using symbolic
intervals. In USENIX Security Symposium , pages 1599‚Äì1614. USENIX
Association, 2018.
[56] X. Wang, Y . Peng, L. Lu, Z. Lu, M. Bagheri, and R. M. Summers.
Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on
weakly-supervised classiÔ¨Åcation and localization of common thorax
diseases. In 2017 IEEE Conference on Computer Vision and Pattern
Recognition (CVPR) , pages 3462‚Äì3471, 2017.
[57] Tsui-Wei Weng, Huan Zhang, Hongge Chen, Zhao Song, Cho-Jui Hsieh,
Luca Daniel, Duane S. Boning, and Inderjit S. Dhillon. Towards
fast computation of certiÔ¨Åed robustness for relu networks. In ICML ,
volume 80 of Proceedings of Machine Learning Research , pages 5273‚Äì
5282. PMLR, 2018.
[58] Eric Wong and J. Zico Kolter. Provable defenses against adversarial ex-
amples via the convex outer adversarial polytope. In ICML , volume 80 of
Proceedings of Machine Learning Research , pages 5283‚Äì5292. PMLR,
2018.
[59] W. Xiang, H. Tran, and T. T. Johnson. Output reachable set estimation
and veriÔ¨Åcation for multilayer neural networks. IEEE Transactions on
Neural Networks and Learning Systems , 29(11):5777‚Äì5783, Nov 2018.
[60] Xiaofei Xie, Lei Ma, Felix Juefei-Xu, Minhui Xue, Hongxu Chen, Yang
Liu, Jianjun Zhao, Bo Li, Jianxiong Yin, and Simon See. Deephunter:
A coverage-guided fuzz testing framework for deep neural networks. In
28th ACM SIGSOFT International Symposium on Software Testing and
Analysis , 2019.
[61] Dong Xu, David Shriver, Matthew B. Dwyer, and Sebastian Elbaum.
Systematic generation of diverse benchmarks for dnn veriÔ¨Åcation. In
Computer Aided VeriÔ¨Åcation CAV , 2020.
[62] X. Yuan, P. He, Q. Zhu, and X. Li. Adversarial examples: Attacks and
defenses for deep learning. IEEE Transactions on Neural Networks and
Learning Systems , 30(9):2805‚Äì2824, 2019.
287