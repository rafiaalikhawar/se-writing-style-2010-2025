Automatic Testing and ImprovementofMachine Translation
Ze
yuSun
Key Laboratory of HCST
Peking University,MoE
szy_@pku.edu.cnJie M.Zhang∗
UniversityCollegeLondon
jie.zhang@ucl.ac.ukMark Harman
FacebookLondon
UniversityCollegeLondon
mark.harman@ucl.ac.uk
Mike Papadakis
Universityof Luxembourg
mike.papadakis@gmail.comLuZhang
Key Laboratory of HCST
Peking University, MoE
zhanglucs@pku.edu.cn
ABSTRACT
This paper presents TransRepair, a fully automatic approach for
testingandrepairingtheconsistencyofmachinetranslationsys-
tems.TransRepaircombinesmutationwithmetamorphictesting
todetectinconsistencybugs(withoutaccesstohumanoracles).It
thenadoptsprobability-referenceorcross-referencetopost-process
thetranslations,inagrey-boxorblack-boxmanner,torepairthe
inconsistencies. Our evaluation on two state-of-the-art translators,
GoogleTranslateandTransformer,indicatesthatTransRepairhasa
highprecision(99%)ongeneratinginputpairswithconsistenttrans-
lations.Withthesetests,using automaticconsistencymetrics and
manualassessment,wefindthatGoogleTranslateandTransformer
have approximately 36% and 40% inconsistency bugs. Black-box
repair fixes 28% and 19% bugs on average for Google Translate and
Transformer. Grey-box repair fixes 30% bugs on average for Trans-
former.Manualinspectionindicatesthat thetranslationsrepaired
by our approach improve consistency in 87% of cases (degrading it
in 2%), and that our repairs have better translation acceptability in
27%ofthe cases(worse in 8%).
KEYWORDS
machine translation,testingandrepair,translation consistency
ACMReference Format:
Zeyu Sun, Jie M. Zhang, Mark Harman, Mike Papadakis, and Lu Zhang.
2020. Automatic Testing and Improvement of Machine Translation. In 42nd
International Conference on Software Engineering (ICSE ’20), May 23ś29,
2020, Seoul, Republic of Korea. ACM, New York, NY, USA, 12 pages. https:
//doi.org/10.1145/3377811.3380420
1 INTRODUCTION
Machinelearninghasbeensuccessfulinprovidinggeneral-purpose
naturallanguagetranslationsystems,withmanysystemsableto
∗Corresponding and co-first author.
HCST: HighConfidenceSoftwareTechnologies.
Permissionto make digitalor hard copies of allorpart ofthis work for personalor
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACM
mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,
topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissionsfrom permissions@acm.org.
ICSE’20, May 23ś29,2020, Seoul, Republic ofKorea
©2020 Associationfor Computing Machinery.
ACM ISBN 978-1-4503-7121-6/20/05...$15.00
https://doi.org/10.1145/3377811.3380420translatebetweenthousandsofpairsoflanguageseffectivelyinreal
time [19]. Nevertheless, such translation systems are not perfect
and the bugs that users experience have a different character from
thoseontraditional,non-machinelearning-based,softwaresystems
[2, 26, 27, 56].
The consequences of mistranslation have long been studied and
their effectshave been showntobe serious.For example,the infa-
mous historicmistranslation of Article17of the Treaty of Uccialli
reportedly ledto war[ 11]. Such trulyprofound and far-reaching
consequences of mistranslation are also reportedly becoming a
seriousandpotentsourceofinternationaltensionandconflict[ 31].
The consequences of mistranslation through machine-based
translatorshavealsobeenshowntobeserious.Forexample,ma-
chine translations have been shown to exhibit pernicious fairness
bugsthatdisproportionatelyharmspecificuserconstituencies[ 34].
Wehavefoundsuchexamplesoffairnessbugsinwidelyusedin-
dustrialstrengthtranslationsystems.Figure1showsseveralsuch
GoogleTranslateresultsforthelanguagepair(English →Chinese)1.
Ascanbe seenfromthefigure, Google Translatetranslates‘good’
into ‘hen hao de’ (which means ‘very good’) when the subject is
‘men’or‘malestudents’.However,interestingly,butalsosadly,it
translates ‘good’ into ‘hen duo’ (which means ‘a lot’) when the
subjectis ‘women’ or‘femalestudents’2.
Such inconsistency may confuse users, and is also clearly unfair
to female researchers in computer science; producing ‘a lot’ of
researchisclearlyamorepejorativeinterpretation,whencompared
toproducing‘verygood’research.Toavoidsuchunfairtranslations
(atscale),weneedtechniquesthatcanautomaticallyidentifyand
remedy such inconsistencies.
To tackle this problem, we introduce a combined testing and
repairapproachthatautomaticallygeneratestestsforreal-world
machine translation systems, and automatically repairs the mis-
translationsfoundinthetestingphase.Asweshowinthispaper,
weneedtorethinktheconventionalapproachestobothtestingand
repairin order to apply themto naturallanguagetranslation.
Existingworkhastestedwhethermachinetranslationsystems
provide stable translations for semantically-equal transformations,
suchassynonymreplacement(e.g.,buy →purchase)[ 5]orabbrevia-
tionreplacement(e.g.,what’s →whatis)[36].However,noprevious
1Thefourtranslationswereobtainedon23rdJuly,2019.Theseexamplesarepurely
for illustration purposes, and are not intended as a criticism of Google Translate. It is
likely that othermainstream translation technologies will havesimilarissues.
2Similar issues also exist in translations between other languages. With a cursory
check, wealreadyfoundacase with German→Chinese.
9742020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE)
ICSE ’20, May 23–29, 2020,Seoul,Republicof Korea Sun andZhang,et al.
English Ch inese (Google Translation) Notes
Mendo goodresearch in 
computer science.Nanrenzaij isuanji kexuefangmian zuole
henhaodeyanjiu
男人在计算机科学方面做了很好的研究good→
henhaode
(very good)
Women do goodresearch 
in computer science.Nüxingzaij isuanji kexuefangmian zuole
henduoyanjiu
女性在计算机科学方面做了很多研究good→
henduo
(a lot)
Malestudents do good
research in computer 
science.Nanx uesheng zaijisuanjikexuefangmian
zuolehen hao deyanjiu
男学生在计算机科学方面做了很好的研究good→
henhaode
(very good)
Femalestudents do good
research in computer 
science.Nüxuesheng za ijisuanjikexuefangmian
zuolehenduoyanjiu
女学生在计算机科学方面做了很多研究good→
henduo
(a lot)
Figure1:Examplesoffairnessissuesbroughtbytranslation
inconsistency
(fromGoogle Translate)
work has focused on the testing and repair of translation inconsis-
tencyregardingcontext-similartransformation;thetransformation
between sentences that have similar word embeddings [ 12] yet
sharecontextinthecorpus(e.g.,simplegender-basedtransforma-
tions,such as boys→girls).
Inordertotacklethetestingproblem,weintroduceanapproach
thatcombinesmutation[ 22,32,54,55]withmetamorphictesting
[3,52].Theapproachconductscontext-similarmutationtogenerate
mutated sentences that can be used as test inputs for the translator
undertest.Whenacontext-similarmutationyieldsabove-threshold
disruptiontothetranslationofthenon-mutatedpart,theapproach
reports an inconsistencybug.
Traditional approaches to‘repairing’ machinelearning systems
typicallyusedataaugmentationoralgorithmoptimisation.These
approaches can best be characterised as to “improvež the overall
effectivenessofthemachinelearner,ratherthanspecificrepairsfor
individual bugs; they also need data collection/labelling and model
retraining,whichusually have ahigh cost.
Traditional approaches to ‘repairing’ software bugs are white
box,becausethetechniquesneedtoidentifytheline(s)ofsource
code that need(s) to be modified in order to implementa fix. Such
approaches inherently cannot be applied to fix software for which
sourcecode is unavailable,such as third-partycode.
Our insight is that by combining the results of repeated (and
potentiallyinconsistent)outputfromasystem,wecanimplementa
light-weight black-box repairtechniqueasakindof‘post-processing’
phase that targets specific bugs. Our approach is the first repair
technique to repair a system in a purely black-box manner. We
believethatblack-boxrepairhasconsiderablepotentialbenefits,be-
yondthe specificapplicationof machinetranslationrepair.Itisthe
onlyavailableapproachwhenthesoftwareengineerispresented
withbugsin systemsfor whichnosourcecode is available.
We demonstrate not onlythat black-box repair isfeasible,but
that it can scale to real world industrial-strength translation sys-
tems,suchasGoogleTranslate.Wealsopresentresultsforgrey-box
repairfor whichthe predictive probability isavailable.
TransRepairisevaluatedontwostate-of-the-artmachinetransla-
tion systems, Google Translate and Transformer [ 46]. In particular,
we focus on the translation between the top-two most widely-
spokenlanguages:EnglishandChinese.Theselanguageseachhaveover one billion speakers worldwide [ 8]. Nevertheless, only 10 mil-
lion people in China (less than 1% of the population) are able to
communicateviaEnglish[ 47,48].Sincesofewpeopleareableto
speakbothlanguages,machinetranslationisoftenattractiveand
sometimes necessary andunavoidable.
Our results indicate that TransRepair generates valid test inputs
effectivelywithaprecisionof99%;2)TransRepairautomaticallyre-
portsinconsistencybugseffectivelywiththelearntthresholds,with
ameanF-measureof0.82/0.88forGoogleTranslate/Transformer;
3)BothGoogleTranslateandTransformerhaveinconsistencybugs.
Automated consistency metrics and manual inspection reveal that
Google Translatehas approximately36% inconsistent translations
on our generatedtestinputs.4)Black-box repair reduces28% and
19% of the bugs of Google Translate and Transformer. Grey-box
reduces 30% ofthe Transformer bugs. Manual inspectionindicates
that the repaired translations improve consistency in 87% of the
cases(reducingitinonly2%),andhavebettertranslationaccept-
ability3in27%ofthe cases(worse in only 8%)
2 APPROACH
Thissectionintroducestheoverviewandthedetailsofeachstep
for TransRepair.
2.1 Overview
A high level view of TransRepair is presented in Figure 2. From
this Figure it can be seen that TransRepair automatically tests
andrepairstheinconsistencyof machinetranslationbased onthe
following three majorsteps:
1)Automatictestinputgeneration. Thisstepgeneratestrans-
formed sentences (test inputs) to be used for consistency testing.
Foreachsentence,TransRepairconductssentencemutationsvia
context-similar word replacement. The generated mutant candi-
dates are filtered using a grammar check. The mutants that pass
thegrammarcheckarethenregardedasthefinaltestinputsforthe
machinetranslatorunder test. Detailsare presentedinSection 2.2.
2)Automatictestoraclegeneration. Thisstepintroducesthe
generationoforacles,whichareusedforidentifyinginconsistent
translations(bugs).Inthisstep,werelyonthemetamorphicrela-
tionshipbetweentranslationinputsandtranslationoutputs.The
idea is that translation outputs from both the original sentence
anditscontext-similarmutant(s)shouldhaveacertaindegreeof
consistencymodulothemutatedword.Weusesimilaritymetrics
that measure the degree of consistency between translated outputs
as test oracles. Details of this step are presented in Section 2.3. We
explore four similarity metrics, which are described in Section 3.2.
3) Automatic inconsistency repair. This step automatically
repairs the inconsistent translation. TransRepair applies black-box
and grey-box approaches, which transform the original translation
basedonthe besttranslation among themutants. We explore two
waysofchoosingthebesttranslation,oneusingpredictiveproba-
bility, the other using cross-reference. Details of this step are given
in Section 2.4.
3Weuse“acceptabilityžtocapturethepropertythatatranslationmeetshumanassess-
mentof a reasonable (aka acceptable)translation
975Automatic TestingandImprovementof MachineTranslation ICSE ’20, May 23–29, 2020,Seoul,Republic of Korea
context-similar 
m
utation
structural 
filteringsimilarity 
analysis
probability or 
 cross referencemachine 
translator
automatic test input generation automatic test oracle generation  automatic inconsistency repair
word
vectorword pair
librarymutant 
candidates
filtered 
mutantsoriginal 
translation
mutant 
translationsfinal 
translationInconsistency?
Yes
best 
translationoriginal 
sentence
Wikipedia, 
GigaWord, 
OntoNotes
text 
corporamachine 
translator
translation 
mapping
Figure 2:Overview ofhow TransRepair tests and repairs machinetranslation inconsistencies.
2.2 AutomaticTestInput Generation
The inputgeneration processcontains the following steps.
2.2.1 Context-similarityCorpusBuilding. Toconductcontext-similar
wordreplacement,thekeystepistofindaword(s)thatcanbere-
placed with other(s) (similar ones) without hurting the sentence
structure.Thenewsentencegeneratedviawordreplacementshould
yieldconsistent translations withthe original.
Word vectors capture the meaning of a word through their con-
text[35].Tomeasurethesimilarity,weusewordvectorstrained
from text corpora. In our approach, the word similarity between
two words w1andw2, denoted by sim(w1,w2), is computed by the
formula below,where vxdenotesthe vector ofthe word x.
sim(w1,w2)=vw1vw2
|vw1| |vw2|(1)
Toconstructareliablecontext-similarcorpus,wetaketwoword-
vector models and use the intersection of their trained results. The
first model is GloVe [ 35], which is trained from Wikipedia 2014
data [49] and GigaWord 5 [ 38]. The second model is SpaCy [ 40],
which is a multi-task CNN trained on OntoNotes [ 1] including
thedatacollectedfromtelephone conversations, newswire,news-
groups,broadcastnews,broadcastconversation,andweblogs.When
twowordshaveasimilarityof over0.9 forboth models,wedeem
the word pair to be context-similar and place it in the context-
similarity corpus. In total, we collected 131,933 word pairs using
this approach.
2.2.2 TranslationInputMutation. We introduce wordreplacement
andstructuralfiltering respectively in the following.
Word replacement. For each word in the original sentence, we
searchtodeterminewhetherthereis amatchinourcorpus.Ifwe
find a match, we replace the word with its context-similar one and
generate the resulting mutated input sentence. Compared with the
originalsentence,eachmutatedsentencecontainsasinglereplaced
word.Toreducethepossibilityofgeneratingmutantsthatdonot
parse,we only replace nouns, adjectives, andnumbers.
Structural filtering. The generated mutated sentence may fail to
parse, because the replaced word may not fit the context of the
newsentence.Forexample,“onežand“anotheržarecontext-similar
words, but “a good onež parses, while “a good anotherž does not.
Toaddresssuchparsingfailures,weapplyadditionalconstraints
to sanity check the generated mutants. In particular, we apply
structural filtering, based on the Stanford Parser [ 30]. Suppose theoriginalsentenceis s=w1,w2,...,wi,...,wn,themutatedsentence
iss′=w1,w2,...,w′
i,...,wn, wherewiinsis replaced with w′
iin
s′. For each sentence, the Stanford Parser outputs l(wi), the part-
of-speech tag of each word used in the Penn Treebank Project [ 44].
Ifl(wi)/nequall(w′
i), we remove s′from the mutant candidates because
the mutation yieldschanges in the syntactic structure.
We manually inspect the quality of the generated inputs and
report results in Section 4.
2.3 Automatic TestOracle Generation
Toperformtestingweneedtoaugmentthetestinputswegenerate
with test oracles, i.e., predicates that check whether an inconsis-
tencybughasbeenfound.Todoso,weassumethattheunchanged
parts of the sentences preserve their adequacy and fluency modulo
themutatedword.Adequacymeanswhetherthetranslationcon-
veysidenticalmeaning,whetherthereisinformationlost,added,
ordistorted;Fluencymeanswhetherthe outputis fluentandgram-
maticallycorrect[7, 15].
Lett(s)andt(s′)be the translations of sentences sands′that
were produced by replacing the word w(ins) withw′(ins′). Thus,
wewouldliketocheckthesimilaritybetween t(s)andt(s′)when
ignoringthetranslationsforwords wandw′.Unfortunately,itis
noteasytostriptheeffectof wandw′,becausea) wandw′may
change the entire translation of the sentences, and b) it is not easy
to accurately map the words wandw′with their respective one(s)
in the translatedtext.
To bypass this problem, we calculate the similarity of subse-
quencesof t(s)andt(s′),andusethelargestsimilaritytoapprox-
imate the consistency level between t(s)andt(s′). Algorithm 1
showstheprocess.For t(s)andt(s′),wefirstapplyGNUWdiff[ 10]
to get the difference slices (Line 1). GNU Wdiff compares sentences
onwordbasis,andisusefulforcomparingtwotextsinwhichafew
words have been changed [ 10]. With Wdiff, the difference slices of
twosentences“ ABCDFžand“BBCG HF"arerepresentedas
“Až,“Dž and“Bž,“G Hž for the twosentences, respectively.
Thediffslicesof t(s)andt(s′)aresavedtoset BsandBs′4.We
then delete a slice from the translations, one at a time (Line 5
andLine9).Eachslicecorrespondstoonesubsequencewiththis
slice deleted. For the example above, “ AB CDFž will have two
subsequences:“BCDFž(deleting“Až)and“ABCFž(deleting“Dž).
4Long slices are unlikely to correspond to the mutated word, we thus only keep slices
that arenolonger than 5 words.
976ICSE ’20, May 23–29, 2020,Seoul,Republicof Korea Sun andZhang,et al.
Thesenewsubsequencesof t(s)/t(s′)areaddedintoset To/Tm(Line
6 andLine10).
For each element in set To, we compute its similarity5with each
element in the set Tm(Line 15). Thus, we get |To| ∗ |Tm|similarity
scores, where |To|and|Tm|is the size of ToandTm. We then use
the highest similarity as the result of the final consistency score
(Lines 16).
Thisconfigurationreducestheinfluenceofthemutatedword,
andhelpsto selectan inconsistencyupper bound. Even if the two
subsequenceswiththelargestsimilaritycontainthereplacedword,
othersentencepartshaveworsesimilarity,soitisunlikelythatthis
caseis biasedbythe replacedword (leads to false positives).
Detailsabouttheexperimentalsetupandtheresultsofthethresh-
oldsetuparediscussedinSection4.2.Additionally,weevaluatethe
effectiveness ofourconsistency measurementsvia manualinspec-
tion.Theseresults are presented inSection 4.2.
Algorithm 1: Pr ocessof obtaining consistency score
Data:t(s): translation ofthe originalsentence; t(s′):translation of
the mutant
Result:ConScore:Consistency scorebetween t(s)andt(s′)
1Bs,Bs′=Wdiff(t(s),t(s′))
2To={t(s)}
3Tm={t(s′)}
4foreachsubsequence bs∈Bsdo
5r=DeleteSub( t(s),bs)
6To=To∪
{r}
7end
8foreachsubsequence bs′∈Bs′do
9r′=DeleteSub( t(s′),bs′)
10Tm=Tm∪
{r′}
11end
12ConScore= -1
13foreachsentence a∈Todo
14foreach sentenceb∈Tmdo
15 Sim =ComputeSimilarity( a,b)
16 ConScore=Max( ConScore ,Sim)
17end
18end
19returnConScore
2.4 Automatic Inconsistency Repair
Wefirstintroducetheoverallrepairprocess,thenintroducetwomu-
tanttranslationrankingapproaches(probabilityandcross-reference).
2.4.1 Overall Repair Process. First, we repair the translation of the
original sentences and then we seek to find a translation for the
mutant, whichmustpass our consistency test.
Algorithm2showstherepairprocess.For t(s)whichhasbeen
revealed to have inconsistency bug(s), we generate a set of mu-
tants and get their translations t(s1),t(s2),...,t(sn). These mutants
andtheirtranslations,togetherwiththeoriginalsentenceandits
translation,areput intoadictionary, T(Line1).Wethenrankthe
5Weexplorefourtypesofsimilaritymetricsinthispaper(seefulldetailsinSection3.2).Algorithm 2: Pr ocessof automaticrepair
Data:s: asentence input; t(s):translation of s;s1,s2, ...,sn:
mutants of s;t(s1),t(s2), ...,t(sn): translations of the mutants;
Result:NewTrans: repairedtranslation for s
1T={(s,t(s)),(s1,t(s1)),(s2,t(s2)), ...,(sn,t(sn))}
2OrderedList=Rank(T)
3a(s)=wordAlignment( s,t(s))
4NewTrans=t(s)
5foreachsentenceanditstranslation sr,t(sr) ∈OrderedList do
6ifsr==sthen
7 br eak
8end
9a(sr)=wordAlignment( sr,t(sr))
10wi,wr
i=getReplacedWord( s,sr)
11t(wi)=getTranslatedWord( wi,a(s))
12t(wr
i)=getTranslatedWord( wr
i,a(sr))
13ifisnumeric( wi)!=isnumeric( t(wi))or
isnumeric( wr
i)!=isnumeric( t(wr
i))then
14 continue
15end
16tr(sr)=mapBack(t(s) ,t(sr),s,sr,a(s),a(sr))
17ifnot(isnumeric( wi)andisnumeric( wr
i))then
18 ifstructur e(tr(sr))!=structure(t(sr))then
19 continue
20 end
21end
22ifisT
est(s)then
23 so,t(so)=getRepair edResult(s)
24 ifnotisConsistent (t(so),tr(sr))then
25 continue
26 end
27end
28Ne
wTrans= tr(sr)
29break
30end
31returnNewTrans
elementsin T,indescendingorder,usingthepredictiveprobabil-
ityorcross-reference,andputtheresultsin OrderedList (Line2).
The details of probability and cross-referenceranking are given in
Section 2.4.2andSection 2.4.3.
Next, we apply word alignment to obtain the mapped words
between sandt(s)asa(s)(Line 3). Word alignment is a natural
languageprocessingtechniquethatconnectstwowordsifandonly
iftheyhaveatranslationrelationship.Inparticular,weadoptthe
technique proposedbyLiuet al. [ 29],whichusesalatent-variable
log-linear model for unsupervised word alignment. We then check
whetherasentencepair (sr,t(sr))inOrderedList canbeadopted
torepairtheoriginaltranslation.Wefollowtherankingorder,until
we find one mutant translation that is acceptable for inconsistency
repair.
Ifsris the original sentence ( sr==s), it means the original
translationisdeemedabetterchoicethanothermutanttranslations
and so we will not touch it (Lines 6-8). Otherwise, we do the same
alignment to s1andt(s1)as tosandt(s). The variables wi,wr
i
977Automatic TestingandImprovementof MachineTranslation ICSE ’20, May 23–29, 2020,Seoul,Republic of Korea
denote the replaced words in s,srand we get the translated words
t(wi),t(wr
i)throughthe alignment(Lines 9-12).
Word alignment is not 100% accurate. If we directly map the
translation by replacing t(wr
i)witht(wi), it may lead to grammati-
calerrorsorcontextmismatches.Weadoptthefollowingstrategies
to judge whether the replacement is acceptable. 1) We constrain
thatwi,wr
iandt(wi),t(wr
i)must belong to the same type (i.e., nu-
meric or non-numeric) (Line 13-15). 2) If the replaced words are of
the non-numeric type, we apply Stanford Parser to check whether
the replacementwouldleadto structuralchanges (Line 17-21).
Whenrepairingthetranslationofthemutatedinput(Line22),
wegettherepairedresultoftheoriginalsentence(Line23),then
checkwhetherthetranslationsolutioncandidateisconsistentwith
therepairedtranslation ofthe originalsentence(Line24-26). Ifnot,
we proceedby checking otherrepaircandidates.
2.4.2 Translation Ranking based on Probability. For a sentence s
and its mutants S=s1,s2,...sn, lett(s)be the translation of s, let
t(si)be the translation of mutant si. This approach records the
translation probability for each t(si), and chooses the mutant with
the highest probability as a translation mapping candidate. The
translation of the corresponding mutant will then be mapped back
togeneratethefinalrepairedtranslationfor susingwordalignment.
Thisisagrey-boxrepairapproach.Itrequiresneitherthetraining
datanorthesourcecodeofthetrainingalgorithm,butneedsthe
predictive probability provided by the machine translator. We call
this grey-box because implementors may regard this probability
information as an internalattribute of the approach, not normally
intendedto be available to end users.
2.4.3 TranslationRankingbasedonCross-reference. Forasentence
sanditsmutants S=s1,s2,...sn,lett(s)bethetranslationof s,and
lett(si)bethetranslationofmutant si.Thisapproachcalculatesthe
similarityamong t(s),t(s1),t(s2),...t(sn),andusesthetranslation
that maps the best (with the largest mean similarity score) with
other translations to map back and repair the previous translation.
Thisisablack-boxrepairapproach.Itrequiresonlytheability
to executethe translator under test andthe translation outputs.
3 EXPERIMENTALSETUP
In this section, we introduce the experimental setup that evaluates
the test input generation, translation inconsistency detection, and
translation inconsistencyrepair.
3.1 Research questions
We start our study by assessing the ability of TransRepair to
generate valid and consistent test inputs that can be adopted for
consistency testing.Hence we ask:
RQ1: How accurate are the testinputs of TransRepair?
We answer this question by randomly sampling some candidate
pairs and checking (manually) whether they are valid. The answer
to this question ensures that, TransRepair, indeed generates inputs
that are suitable for consistency checking.
Given thatwe found evidence that TransRepair generates effec-
tivetestpairs,weturnourattentiontothequestionofhoweffective
these pairsare at detecting consistency bugs.Therefore we ask:
RQ2: What isthebug-revealing ability ofTransRepair?ToanswerRQ2wecalculateconsistencyscoresbasedonsimilar-
ity metrics to act as test oracles (that determine whether a bug has
been detected). Toassess the bug-revealing abilityofthe TransRe-
pair, we manually check a sample of translations and compare the
resultingmanual inspection results withautomatedtest results.
Havingexperimentedwithfaultrevelation,weevaluatethere-
pair ability of TransRepair to see how well it repairs inconsistency
bugs.Thus, we ask:
RQ3: What isthebug-repairability ofTransRepair?
To answer this question, we record how many inconsistency
bugs are repaired (assessed by consistency metrics and manual
inspection). We also manually examine the translations repaired
by TransRepair,andcheckwhethertheyimprovetranslationcon-
sistency as well as quality.
3.2 ConsistencyMetrics
Weexplorefourwidely-adoptedsimilaritymetricsformeasuring
inconsistency.Foreaseofillustration,weuse t1todenotethetrans-
lation outputof the original translation input; we use t2to denote
the translation outputof the mutatedtranslation input.
LCS-based metric .It measures the similarity via normalised
length ofalongestcommon subsequence between t1andt2:
MLCS=len(LCS(t1,t2))
Max(l en(t1),len(t2))(2)
Inthisformula, LCSisafunctionthatcalculatesalongestcommon
subsequence[ 21]between t1andt2thatappearinthesamerelative
order. For example, an LCS for input Sequences “ABCDGHž and
“AEDFHRžis “ADHžwithalength of 3.
ED-basedmetric .Thismetricisbasedontheeditdistancebe-
tweent1andt2.Editdistanceisawayofquantifyinghowdissimilar
two strings are by counting the minimum number of operations
requiredtotransformonestringintotheother[ 37].Tonormalise
theeditdistance,weusethefollowingformulawhichhasalsobeen
adoptedin previous work [16,53].
MED=1−ED(t1,t2)
Max(l en(t1),len(t2))(3)
In this formula, EDis a function that calculates the edit distance
betweent1andt2.
tf-idf-based metric .tf-idf(term frequencyśinversedocument
frequency) can be used to measure similarity in terms of word
frequency.Eachword whasaweightingfactor,whichiscalculated
based on the following formula, where Cis a text corpus (in this
paper we use the training data of Transformer), |C|is the sentence
number in C,fwisthe number of sentences that contain w.
widf=log((|C|+1)/(fw+1)) (4)
Wethenrepresenteachsentencewiththebag-of-wordsmodel[ 57],
which is a simplified representation commonly used in natural
language processing. In this model, the grammar and the word
order is disregarded, only keeping multiplicity (i.e., “A B C Až is
representedas“Až:2,“Bž:1,“Cž:1,namely[2,1,1]invector).Each
dimension of the vector is multiplied with its weight widf. We
calculate the cosine similarity (Equation 1) of the weighted vectors
oft1andt2as theirfinal tf-idf-basedconsistency score.
978ICSE ’20, May 23–29, 2020,Seoul,Republicof Korea Sun andZhang,et al.
BLEU-based metric .The BLEU (BiLingual Evaluation Under-
study)isanalgorithmthatautomaticallyevaluatesmachinetransla-
tion quality via checking the correspondence between a machine’s
output and that of a human. It can also be adopted to compute the
similarity between the translation of the original sentence and the
translationofamutant.Details,description,andmotivationforthe
BLEUscorecanbefoundinthetranslationliterature[ 33].Dueto
lack of spacewe only providean overview here.
BLEUfirstcountsthenumberofmatchedsubsequencesbetween
sentences and computes a precision pn(which is called modified
n-gramprecision[ 33],wherenmeansthesubsequencelength).For
example,in sentences“AABCž( s1)and“ABBCž ( s2)thereare
three 2-gram subsequences in s2:AB,BB, andBC. Two of them are
matchedwiththosefrom s1:ABandBC.Thus,p2is2/3.
As well as pn, the calculation of BLEU score also requires an
exponential brevity penalty factor BP(to penalise overaly short
translations),whichisshownbyFormula5. cdenotesthelengthof
t(si)andristhe length of t(s).
BP=/braceleftbigg1 if c>r
e(1−r/c)ifc≤r(5)
The BLEU score is finally computed by Formula 6, where wn=1
N
(
we useN=4 inthis paper) isthe uniform weights.
BLEU=BP·exp/parenleftBiggN/summationdisplay.1
n=1wnlogpn/parenrightBigg
. (6)
Since BLEU is unidirectional (i.e., BLEU(s,s′)/nequalBLEU(s′,s)), we
use the higher score for measuring the similarity between sand
s′.ThisisconsistentwithourintentioninAlgorithm1:togetan
upper bound of the consistency, thereby avoiding false positive
claims abouttranslation bugs.
3.3 Machine Translators
Ourexperimentconsidersbothindustrialandstate-of-the-artresearch-
orientedmachinetranslators.OneisGoogleTranslate[ 14](abbrevi-
atedasGTintheresultssection),awidelyusedmachinetranslation
servicedevelopedbyGoogle.TheotherisTransformer[ 46],atrans-
latorstudiedby the research community.
We use Google translate, because it is an example of a system
thatforcesustoperformblack-boxrepairs;wehavenoaccesstothe
training data nor the code of thetranslation system, and therefore
anyimprovements,bydefinition,canonlyhavebeenachievedby
a black-box approach. Also, of course, it is a production-quality
mainstreamtranslationsystem,makingtheresultsmoreinteresting.
We use the default setup to train Transformer. Transformer
is trained based on three datasets: the CWMT dataset [ 6] with
7,086,820 parallel sentences, the UN dataset [ 59] with 15,886,041
parallel sentences, and the News Commentary dataset [ 50] with
252,777 parallel sentences as the training data. The validation data
(tohelptunehyper-parameters)isalsofromtheNewsCommentary
andcontains2,002parallelsentences.Transformerrunswiththe
Tensor2Tensordeeplearninglibrary[ 45].Togetamoreeffective
translator,we trainthe modelfor 500,000 epochs.3.4 TestSet
Following previous machine translationresearch [ 17,18], we use
a test set from the News Commentary [ 50] dataset for both Google
Translate and Transformer. The test set contains 2,001 parallel
sentences and are different from the training set and validation
set.TheChinesesentencesinourexperimentsareintheformof
characters. set6.
Our experiments were conducted on Ubuntu 16 .04 with 256GB
RAMandfourIntelE5-2620v4CPUs(2 .10GHz),whichcontains
32coresalltogether.Theneuralnetworksweusedwerealltrained
onasingleNvidiaTitan RTX (24 GB memory).
4 RESULTS
This section reports the results that answer our research questions.
4.1 Effectiveness on Input Generation (RQ1)
We start by answering RQ1. For each test sentence, we generate
mutantsandcheckwhethertheypassthestructuralfiltering(see
more in Section 2.2.2). In particular, for each sentence we generate
upto5mutantsthatpassthroughthefilter(westudytheinfluence
ofthenumberofmutantsinSection5).Forthe2,001testsentences,
21,960mutantcandidatesaregenerated,with17,268discardedby
structuralfiltering.Intherestofourexperimentweusetheremain-
ing 4,692 mutants, which are paired with 1,323 sentences, as test
inputs.
To manually assess whether these test inputs are qualified for
detectingtranslationinconsistency,werandomlysampled400of
them.Thefirsttwoauthorsmanuallycheckedthevalidityofthe
inputs,i.e.,whetherthereplacedwordinthemutantleadstogram-
matical errors and whether the mutant ought to have consistent
translationswiththe originalsentence.Thisvalidationstepreveals
three invalid mutants: 1) He was a kind spirit with a big heart : kind
→sort; 2)Two earthquakes with magnitude 4.4 and 4.5 respectively :
Two→Six;3)Itis in itselfagreat shame : great→good.
Theremaining397ofthe400meetthetwovaliditycriteria,indi-
catingaprecisionof99%.Weconcludethatourtwostrategiesfor
theintersectionoftwoword2vecmodels,andtheuseofStanford
Parserasafilterhaveahighprobabilityofyieldingvalidtestsen-
tences. The 400 mutants and the manual assessment results can be
foundonthe TransRepairhomepage [43].
In the next section we use the 4,692 mutants (from the 1,323
originalsentences)toexaminethetesttranslationconsistencyof
machine translation systems.
Answer to RQ1: TransRepair has good precision (99%) for
generatingtestsentencesthataregrammaticallycorrect
andyieldconsistent translations.
4.2 Inconsistency-revealing Ability of
TransRepair (RQ2)
ThissectionanswersRQ2,i.e.,investigatestheinconsistency-revealing
abilityofTransRepair.Toanswerthisquestion,weinvestigate:1)
6TheChinese sentencesin ourexperimentsarein the form of characters.
979Automatic TestingandImprovementof MachineTranslation ICSE ’20, May 23–29, 2020,Seoul,Republic of Korea
LCS Tf−idfBLEU ED
0.2 0.4 0.6 0.8 1.0 0.2 0.4 0.6 0.8 1.00200400600
0200400600
Consistency metric valuesCount
Figure3:Histogramofmetricscores.Alargenumberofmu-
tant
translations have similarity scores lower than one, in-
dicating many inconsistent translations(RQ2).
the consistency metric values between the mutant and the original
translations; 2) the manual inspection results of translation incon-
sistency. We also explore how close the consistency metrics and
manual inspection are in evaluating inconsistency.
ConsistencyMetricValues. Wetranslatethe4,692generatedin-
puts with Google Translate and Transformer, and compare them
with the translations of the original sentences, following the steps
of Algorithm 1. For each mutant, we calculate four consistency
scores, each one corresponding to one of the similarity metrics
(outlinedin Section 3.2).
Figure 3 shows the histogram of consistency scores that are
lower than 1.0. As can be seen from the figure, different metric
values have different distributions, yet overall, all the four metrics
reportalargenumberoftranslations(i.e.,around47%ofthetotal
translations) with a score below 1.0, indicating the presence of
translation inconsistency.
Table1showstheresultsofthereportedinconsistenttranslations
withdifferentmetricthresholds.FromTable1,wecanseethatbugs
remaineven for highly permissive consistency thresholds.
Table1:Numberofreportedinconsistencybugswithdiffer-
entthresholdsbetween1.0and0.6.Witha1.0thresholdthe
translation is deemed buggy if there is any detected incon-
sistency.Thelowerthethreshold,themorepermissiveisthe
criteriafordeemingbuggy.Ascanbeseen,bugsremaineven
forhighlypermissive consistency thresholds (RQ2).
Thresh. 1.0 0.9 0.8 0.7 0.6GTLCS 2,053 (44%) 865 (18%) 342 (7%) 123 (3%) 57 (1%)
ED 2,053 (44%) 913 (19%) 401 (9%) 198 (4%) 101 (2%)
Tf-idf 2,459 (52%) 548 (12%) 208 (4%) 71 (2%) 21 (0%)
BLEU 2,053 (44%) 1,621 (35%) 911 (19%) 510 (11%) 253 (5%)TransformerLCS 2,213 (47%) 1,210 (26%) 634 (14%) 344 (7%) 184 (4%)
ED 2,213 (47%) 1,262 (27%) 700 (15%) 428 (9%) 267 (6%)
Tf-idf 2,549 (54%) 851 (18%) 399 (9%) 188 (4%) 112 (2%)
BLEU 2,213 (47%) 1,857 (40%) 1,258 (27%) 788 (17%) 483 (10%)
ManualInspectedInconsistency. Inaddition,werandomlysample
300 translations of the mutants. Two of them do not parse so weusetheremaining298translationsforanalysis.Foreachmutant,
the first two authors manually inspected its translation and the
translationoftheoriginalsentence.Aninconsistencyisreported
whenanyofthefollowingcriteriaaremet:Apartfromthemutated
substitute word, the two translations 1) have different meanings; 2)
have differenttones;3)use differentcharacters for proper nouns.
Manual inspection reveals 107 (36%) inconsistent translations
for Google Translate, and 140 (47%) inconsistent translations for
Transformer7.
Correlation between Metrics and Manual Inspection. We compare
metric scores and human consistency assessment results. We split
the298human-labelledtranslationsintotwogroupsbasedonman-
ual inspection. One is labelled as consistent translations, the other
islabelledasinconsistenttranslations.Wethencheckthemetric
valuescores in eachgroup.
●●●●●●●●●●●
●●●●
●●●●●●
●●●●●●●●●●●
●●●●
●●●●
●●●●●
●●●●●●●
●●
●●●●
●●●
●●●●●●●●
●●●●●●●●●●
●●●●
●●●●●
●●
●
●●●●
●●●●●●●●●●●●●●●●●●●●●●●
●●●●●
●●●●●●●●●●●●●●
●●●
●●
●●●●●●●●●●●●●●●
●●●●●●
●●●●●
●●●●●●●●
●●●●●●●●
●●●
●●
●●
●
●●
●●
●●
●●●●
●●
●
●●●
●●
●
●●
●
●
●●
●●●
●●
●●●
●●
●●
●
●
●●●
●●●
●●●●●
●●●●
●●
●●
●
●
●●●
●
●●
●●●
●●●●
●●●
●●
●●
●●
●
●●●●
●●●●
●●
●●
●●
●
●●
●
●●●
●●
0.40.60.81.0LCS score
Manual check: consistent Manual check: inconsistent
Figure 4: Comparison of metric scores and manual inspec-
tion
of translation consistency. There is a good agreement
between metricscore valuesand humanassessment (RQ2).
Figure4showstheresults8.Thepointsontheleft/rightofthe
dotted vertical line depict the metric values for the translations
manually labelled as consistent/inconsistent. We observe that most
points(82.2%)intheleftsectionhaveascoreof1.0.Theleftsec-
tiongenerallyhashigherscorevalues(withameanvalueof0.99)
than the right part (with a mean value of 0.86). These observations
indicatethatthemetricvaluesandmanualinspectiontendtoagree
ontranslationinconsistency.ItisworthnotingthatFigure4also
showssomelowmetricvaluesontheleftsectionandhighmetric
values on the right section, which indicates the presence of false
positives and false negatives of using metrics to assess consistency.
We analyse false positives and false negatives in more detail below:
Threshold Learning. Metric scores are continuous values. To au-
tomaticallyreportinconsistency,weneedtosetathresholdforeach
metric. In thispaper, we choosea thresholdthat lets metric-value
judgement best resemble manual inspection results. To do this, we
randomly sampled another 100 translations from Google Translate
andmanuallylabelthemasconsistentornot.Wethenusedthese
7TheCohen’sKappais0.96/0.95forGoogleTranslate/Transformer,indicatingthatthe
inspectionresultsarehighlyconsistent.
8Thisfigureshows only the LCSmetric. Fullresultsareonourhomepage[43].
980ICSE ’20, May 23–29, 2020,Seoul,Republicof Korea Sun andZhang,et al.
100 labels to choose a threshold (from 0.8 to 1.0 with a step of 0.01)
with the largest F-measure score for each similarity metric. The
best thresholds for LCS, ED, tf-idf, and BLEU identified in this way
are 0.963, 0.963, 0.999, 0.906 withF-measure scores 0.81,0.82, 0.79,
0.82,respectively.Whenametricvaluefallsbelowtheso-identified
threshold,our approach willreport an inconsistencybug.
To know how well the chosen thresholds capture the boundary
betweenconsistencyandinconsistency,wetestthethresholdsus-
ingthe298previouslysampledtranslations,onGoogleTranslate
and Transformer respectively. The resultsare shown in Table2. A
false positive (FP in thetable) means thethreshold judges atrans-
lationasinconsistentbutmanualinspectionisconsistent.Afalse
negative (FN in the table) means the threshold judges a translation
as consistent but manual inspection is inconsistent. From the table,
theproportionoffalsepositivesandfalsenegativesareallbelow
10%,whichwe deem to be acceptable.
After a manual check of FPs and FNs, we found that an FN may
happen when there is a minor character difference, but with a
different meaning or tone. For example, in our results, one mutant
translation has an extra er(means “Butž) which does not exist
in the original translation. Manual inspection deemed this to be
inconsistent, while metrics did not. An FP may happen when there
are many different words in the two translations, but they share
the same meaning. For example, Chinese phrases shang wei and
hai mei you both mean “not yetž, but the characters that express
eachphraseare totallydifferent.
The harm that an FP in the testing process may bring lies in
the possibility that our approach may make the translation worse.
Section 4.3.2explores this possibility.
Table 2:Precision/recallforinconsistency revealing (RQ2)
Metric TN FN FP TP Precision Recall F-meas.GTLCS 169(57%) 16 (5%) 22 (7%) 91 (31%) 0.81 0.85 0.83
ED 169(57%) 16 (5%) 22 (7%) 91 (31%) 0.81 0.85 0.83
tf-idf 162 (54%) 12 (4%) 29 (10%) 95 (32%) 0.77 0.89 0.82
BLEU 171(57%) 20(7%) 20 (7%) 87 (29%) 0.81 0.81 0.81TransformerLCS 142(48%) 22 (7%) 16 (5%) 118(40%) 0.88 0.84 0.86
ED 142(48%) 21 (7%) 16 (5%) 119(40%) 0.88 0.85 0.87
tf-idf 141 (47%) 11 (4%) 17 (5%) 129(43%) 0.88 0.92 0.90
BLEU 147(49%) 23(8%) 11 (4%) 117(39%) 0.91 0.84 0.87
Overall Number of Inconsistency Issues. After identifying the
thresholds,weapplythemtothetranslationsofthe4,592generated
inputs9, and check how many of them fall below the threshold.
It turns out that for Transformer, the inconsistent translation re-
sultsareLCS:1,917(42%);ED:1,923(42%);tf-idf:2,102(46%);BLEU:
1,857(40%).Thus,overall,abouttwofifthsofthetranslationsfall
below our chosen consistency thresholds. For Google Translate,
the inconsistent translation results are LCS: 1,708 (37%); ED: 1,716
(37%);tf-idf: 1,875(41%);BLEU: 1,644(36%). Thisalsoshows that
GoogleTranslate isslightlybetter than Transformer withrespect
to consistency.
9We removed those 100 translations used for threshold learning from our test set and
used the remaining4,592inputsto conduct testing.Table 3:Numberand proportionof repaired bugs(RQ3).
Metric Probability Cross-reference
GTLCS ś 493 (28%)
ED ś 503 (29%)
tf-idf ś 478 (25%)
BLEU ś 484 (29%)
TransformerLCS 583 (30%) 374 (19%)
ED 581 (30%) 389 (20%)
tf-idf 640 (30%) 400 (19%)
BLEU 565 (30%) 380 (20%)
Answers to RQ2: The metrics have an F-measure of
0.82/0.88 when detecting inconsistency bugs for Google
Translate/Transformer.Bothmetricsandmanualinspec-
tionrevealthatGoogleTranslatehasapproximately36%
inconsistenttranslations onTransRepairtest inputs.
4.3 Bug-repair Ability (RQ3)
4.3.1 Improvement Assessed by Metrics. We apply our repair ap-
proachesto allthe inconsistenttranslations, and check how many
translations can be repaired with our approach. For each sentence,
we generate 16 mutants for repair (we study the influence of the
number of mutants for repairinSection 5).
Table3showstheresults, whereeachcellcontainsthenumber
andproportionofinconsistencybugsthattherepair approachre-
pairs.TheColumn“Probabilityžrepresentstheresultsforprobability-
reference(grey-box repair);the Columns“Cross-referencež repre-
sents the results for cross-reference (black-box repair); For Google
translate, since the grey-box approach is not applicable, we only
present the results for the black-box approach.
Fromthetable,TransRepairreduces,onaverage,28%ofbugsfor
theblack-boxapproachinGoogleTranslate.FortheTransformer
model,we cansee the grey-box approach repairs 30% of bugs, the
black-boxonerepairs19%to20%ofbugs.Theseexperimentalre-
sultsshowthatthegrey-boxandblack-boxapproachesareeffective
at repairing inconsistencybugs.
4.3.2 Improvement Assessed by Human. Program repair studies
typically include a manual assessment process [ 24,39,51] in order
to validate their findings. Following a similar practice, the first two
authors(manually)checkedtherepairedresultsofthepreviously
labelled298sampledtranslations.Thegoalwasto checkwhether
thechangesintranslationspatchedbyourrepairapproachimprove
translationconsistency.Sinceourrepairmayalsoimprovetrans-
lationacceptability,wealsocheckwhetherthechangesbringany
translationacceptabilityimprovement.Forcross-referencebasedre-
pair,wemanuallyassessedonlytheLCSmetricsinceour(previous)
results showedsimilar results among the othermetrics.
Amongthe 298sentence pairs,113/136 ofthem arereported as
having translation inconsistency on Google Translate/Transformer
by metrics. Our repair thus targets all these sentence pairs, includ-
ingthetranslationsofboththeoriginalsentenceandthemutant.
Theprobability-basedrepairapproachfinallychanged58(outof
981Automatic TestingandImprovementof MachineTranslation ICSE ’20, May 23–29, 2020,Seoul,Republic of Korea
136) pairs for Transformer; The cross-reference-based repair ap-
proach finally changed 39/27 (out of 113/136) pairs for Google
Translate/Transformer.
ForthetranslationpairsthathavebeenmodifiedbyTransRepair,
thefirsttwoauthors thenmanuallycomparedtwo dimensions:1)
the translation consistency before and after repair; 2) the accept-
ability of the translations (for both the original sentence and the
mutant) before and after repair. For each dimension, the authors
gave labels of “Improvedž,“Unchangedž,or“Decreasedž,consider-
ingbothadequacyandfluency(seeexplanationsofthesetwoterms
in Section 2.3)10.
Table 4 shows the results. The first four rows are for Google
Translate. The remaining rows are for Transformer. The rows with
“overallž show results of translation acceptability improvement
among the translations for both original sentences and mutant
sentences. The rows with “originalž/“mutantž show the translation
repairresults for original/mutantsentences.
WeobservethatTransRepairhasagoodeffectivenessinimprov-
ingtranslationconsistency.Forexample,onaverage,87%transla-
tion pairs improve the consistency for Google Translate and Trans-
former, while all together we observe only 3 translation consis-
tencydecreases.Wecheckedthesedecreased-consistencyrepairs
and foundthat, for one case, theoriginalsentence translation has
beenimprovedbutnotforthemutanttranslation,andthusafter
repair,theimprovedtranslationoftheoriginalsentencedoesnot
match well with the unimproved translation of the mutant. The
remainingtwocasesarisebecausetherepairsoftheoriginalsen-
tences decreased, while our approach did not touch the mutant
translations.
Themainpurposeofourrepairapproachistoimprovetransla-
tionconsistency.Translationacceptabilityimprovementisa“bonusž
ofourapproach.FromTable4,perhapstooursurprise,therepair
approach improves the translation acceptability for around one
fourth (27%) repairs. There are 8% repairs with decreased accept-
ability.Basedonourmanualinspection,thereasonfordecreased
acceptability is that occasionally, the repair approach may trade
quality for consistency.
Answers to RQ3: Black-box repair reduces on average
28%/19% bugs for Google Translate/Transformer. Grey-
boxrepairreducesonaverage30%bugsforTransformer.
Human inspection indicates that the repaired translations
improve consistency in 87% of the cases (reducing it in
2%),andhavebettertranslationacceptabilityin27%ofthe
cases(worse in 8%).
5 EXTENDED ANALYSISAND DISCUSSION
This section providesfurther details andanalysis.
ExampleofRepairedTranslations .Table5givessomeexam-
ples of our improvement of mistranslation. The first column is the
translationinput;thesecondcolumnshowstheoriginaltranslation
10The mean Kappa score is for labelling translation consistency between the two
humanlabels,0.97forlabellingthetranslationoftheoriginalsentence,and0.81for
labelling the translation of the mutantsentence.Table 4:Improvement Based on Manual Inspection (RQ3)
Aspect Improved Unchanged DecreasedGT.LCSTranslation consistency 33 (85%) 4 (10%) 2 (5%)
Translation acceptability:overall 22 (28%) 48 (62%) 8 (10%)
Translationacceptability: original 10(26%) 23(59%) 6 (15%)
Translationacceptability: mutant 12(31%) 25(64%) 2 (5%)Trans.LCSTranslation consistency 24 (89%) 3 (11%) 0 (0%)
Translation acceptability:overall 15 (28%) 37 (69%) 2 (4%)
Translationacceptability: original 7 (26%) 19(70%) 1 (4%)
Translationacceptability: mutant 8 (30%) 18(67%) 1 (4%)Trans.ProbTranslation consistency 51 (88%) 6 (10%) 1 (2%)
Translation acceptability:overall 30 (26%) 76 (66%) 10(9%)
Translationacceptability: original 15(26%) 36(62%) 7 (12%)
Translationacceptability: mutant 15(26%) 40(69%) 3 (5%)
output(convertedtoPinyin),where wordsin italic explainthe mis-
translated parts;the last column shows our improvedtranslation.
Effectiveness and Efficiency of Data Augmentation .Previ-
ousworkhasadopteddataaugmentationtoimprovetherobustness
of machine learning models [ 5,36]. In our work, concerning trans-
lators whosesourcecode isknown, training data augmentationis
alsoacandidate solution to increasetranslation consistency.
To investigate this option, we designed experiments to study
whetheraddingmoretraining datawouldyieldbettertranslation
consistency.Wecontrolledthetrainingdatasizeandused10%,20%,
..., and 90% of the original training data to build Transformer re-
spectively.Figure5showstheresults.Whenthesizeofthetraining
data ratio is between 0.7 and 1.0, we did not observe a decreas-
ingtrend.Thisindicatesthataugmentingtrainingdatamayhave
limited effectiveness inimprovingtranslation inconsistency.
●
●
●●
●●
●●
●●●
●
● ●●●
●●●●●
●●●
●●
●●
● ●●
●
●●
●●
●●
●●
0.400.450.50
0.2 0.4 0.6 0.8 1.0
Ratio of training dataRatio of bugs
Figure5:Ratioofinconsistencybugswithdifferenttraining-
data
size forTransformer.
Dataaugmentationneedsmodelretraining.Wefoundthatusing
100% training data to train the translator model took as much as
19hoursunderourcurrentexperimentalconfiguration(seemore
details in Section 3). In practice, data collection, labelling, and pro-
cessing also needs time. All together, we find little evidence that
augmentation is a complete solution to this translation repair prob-
lem.
Comparedwithmodelretrainingapproachesliketrainingdata
augmentation, TransRepair has the following advantages: 1)Tran-
sRepair require neither the source code nor training data, and is
982ICSE ’20, May 23–29, 2020,Seoul,Republicof Korea Sun andZhang,et al.
Table 5: Examples ofRepaired Translations.
Input Original translation Repairedtranslation
Femalestudentsdo goodresearchincomputerscience. nüxueshengzaijisuanjikexuefangmianzuole hen-
duoyanjiu[Bug:łgoodž →ła lotž.]nüxueshengzai jisuanji kexue fangmian zuole hen-
haodeyanjiu
Ifyouneedhelp,youcanenjoytimelyservicesbypress-
inganearby oneofthe41call buttonsin thestation.ruguonixuyaobangzhu,nikeyitongguoanfujin
de41gehujiaoanniuxiangshoujishidefuwu. [Bug:
łone ofžisnot translated.]ruguonixuyaobangzhu,nikeyitongguoanfujinde41
ge hujiao anniu zhong de yige lai xiangshou jishi de
fuwu.
OriginalTitle:CanadaPoliceKill ISSupporters:Prepa-
rationsforHomemadeBombDowntownAttackNear
theEnd.yuanshi biaoti: jianada jingcha sha le wo de
zhichizhe:weihemazhizaobaozhadezhunbei. [Bug:
łISž→łmyž.]yuanshibiaoti: jianadajingchashalu ISzhichizhe: wei
hema zhizaozhadan dezhunbei.
Banpoliticalcampaignersandactivistsfromhandling
completed postalvotesandpostalvote envelopes.jinzhi zhengzhi jingsuanzhe he huodongfenzi chuli
wande youzheng xuanpiao he youzheng xuanpiao
xifeng[Bug:łcompletedžismistranslated.]jinzhizhengzhijingsuanzhehehuodongfenzichuli yi
wancheng deyouzhengxuanpiaoheyouzhengxuan-
piao xifeng.
Table6:Numberofdetectedandrepairedbugswithdifferent
numb
erofmutants.
MetricMutantnumber for testing Mutantnumber for repair
1 3 5 4 8 16
LCS 535 1,345 1,917 490 551 583
ED 536 1,349 1,923 488 549 581
tf-idf 583 1,467 2,102 534 600 640
BLEU 513 1,300 1,857 483 538 565
either completely black-box or requires only predictive probability
(grey-box); 2)TransRepair can have lower repair cost since it does
not need additional data and does not require model retraining;
3)TransRepairismoreflexible,becauseitenablestherepairofa
specific bugwithouttouchingotherwell-formed translations.
Efficiency of TransRepair .The cost of TransRepair includes
bothtestingand repair.Underourcurrentexperimentalconfigu-
ration(seemoredetailsinSection3),themeantimefortestingis
0.97spersentence;themeantimeforrepairis2.68spersentence
fortheprobability-basedapproach,and2.93sper sentence forthe
cross-reference-basedapproach.Thus,withcurrentexperimental
configuration,whenusingTransRepairtooptimisethereal-timeon-
line machine translation, for a sentence that is deemed non-buggy,
it wouldtakeless than 1second for theend usertoreceiveafinal
translation. For a sentence that is deemed buggy, it would take less
than4 seconds(testing andrepair) to getafinal translation.
Influence of Mutant Number .We generate mutants during
bothinconsistencytestingandrepair.Forthetest/repairprocess,
our default configuration generates atmost 5/16mutantsfor each
sentence. To investigate how the number of mutants affects the
testing and repair performance, we repeat our experiments with 1
or3 mutantsfortest generation,andwith4or8 mutantsforrepair.
Wethencomparethenumberofrevealedinconsistencybugsand
the number of bugs that our approaches repair. For repair, we only
present results of grey-box repair approach in the paper due to
space reason, as shown by Table 6. The full results are available
on our homepage [ 43]. We observe that during testing, using more
mutants helps to reveal more inconsistency bugs. It is the same for
repair, but using 4 mutants during repair also has an acceptable
effectiveness.Application Scenario .TransRepaircanbeappliedendtoend.
Givenatranslationinputandamachinetranslator,ourapproach
will automatically test and repair the translation output, and give a
new translation outputto the end user.
6 RELATED WORK
Software testing research has typically targeted traditional (non-
machine-learning-based) software systems. However, the recent
rise in the real-world importance of machine learning has resulted
inaconcomitantriseinthelevelofresearchactivityinsoftware
testing for machine learning [ 56]. At the same time, software re-
pairconceptsandtechniques[ 23,25,28]remainrelativelyunder
explored formachine learning systems.In this section,we review
therelationshipofourproposedmachinetranslationtestingand
repairwithpreviousworkontestingandrepairmachinetranslation
systems,whichmainly focusontranslation robustness.
Translation Robustness Testing .To test translation robust-
ness,researchershaveexploredhowperturbationsonthetestin-
puts affect translations. Heigold et al. [ 20] studied three types of
character-level noisytestinputsthataregeneratedviacharacter
swapping, word scrambling, and character flipping. They found
that machine translation systems are very sensitive to slightly per-
turbed sentences that do not pose a challenge to humans. Belinkov
and Bisk [ 2] had a similar conclusion, not only on synthetic noise,
but also on natural noise (naturally occurring errors like typos and
misspellings).Tohavemorediversetestcasesforrobustnesstesting,
Zhaoetal.[ 58]usedGenerativeAdversarialNetworks(GANs)[ 13].
They projected theinput sentence to a latent space,which is then
usedfor searching for test sentences close to the input.
Theseworktargetsrobustnesstesting.Thetestinputsaresyn-
thetic errors or naturally-occurring errors. The test oracles are
usually BLEU scores, which are bounded with human oracles. Our
approachtargetstranslation consistency,andwe generateconsis-
tent test inputs by context-similar word replacement, instead of
involvingerrors.Ourapproachalsodoesnotrequirehumanoracles
duringtesting.
SunandZhou[ 42]proposedmetamorphicrelationsformachine
translation.Therearetwomajordifferencesbetweenourworkand
theirs:1)theirworkconcernstestingonly;wealsorepair;2)their
testinput generationmerely replaceshumannamesbefore “likesž
or “hatesž and brands after them; our approach is comparatively
more exhaustive.
983Automatic TestingandImprovementof MachineTranslation ICSE ’20, May 23–29, 2020,Seoul,Republic of Korea
Translation Robustness Improvement .To improve transla-
tionrobustness,previousworkrelieslargelyondataaugmentation,
i.e., to add noisy data into the training data and to retrain the
model.Someworkusedmodel-independentdatageneration(also
called black-box data generation). Heigold et al. [ 20], Belinkov and
Bisk[2],andSperberetal.[ 41]usedsyntheticnoisetoretainthe
model.Karpukhinetal.[ 26]evaluatedtheimpactofpercentages
of syntheticnoiseto the training set.
Someworkusesmodel-dependentdatageneration(white-box
datageneration).Ebrahimietal.[ 9]introducedanapproachthat
relies on an atomic flip operation. This operation generates tests
byswappingcharactersbasedonthegradientsoftheinputvectors.
Cheng et al. [ 4] proposed a gradient-based method to generate
adversarial sentences byconductingwordreplacement.
There is also work on improving robustness via optimising
the learning algorithms. Belinkov and Bisk [ 2] proposed to use
a structure-invariant representation for synthetic noise in the net-
work.TheyfindthatacharacterCNNrepresentationismorerobust
thanothers.Chengetal.[ 5]introducedstabilitytrainingbyadding
anewcomponentfordiscriminatingthenoiseinthetrainingset.
Thiscomponentreducestheimpactofthenoise,andyieldsmore
stable translations when makingsynonymousperturbations.
These previous approaches target overall robustness improve-
mentforalltranslations,ratherthanfixingspecificmistranslations.
7 CONCLUSION
In this paper, we presented TransRepair, the first approach that
automaticallytestsandimprovescontext-similartranslationconsis-
tency.TransRepairtakesasentenceandappliesacontext-similar
mutation to generate slightly altered (mutated) sentences, to be
usedtotestmachinetranslationsystems.Testingisperformedby
translatingandcomparingtheoriginalwiththemutatedsentences.
Tojudgeconsistency,TransRepaircalculatesthesimilarityofthe
translation subsequences. When context-similar mutations yield
above-thresholddisruptiontothetranslationoftheunchangedpart,
TransRepairdeemsthis tobe apotentialbug. Inadditionto testing,
TransRepairalsoautomaticallyrepairsinconsistenciesinablack-
box or grey-box manner, which post-processes the translations
withreference to the translations ofmutatedsentences.
ACKNOWLEDGEMENT
ZeyuSunandLuZhangaresupportedbytheNationalKeyResearch
andDevelopmentProgramofChinaunderGrantNo.2017YFB1001803.
JieM.ZhangandMarkHarmanaresupportedbytheERCadvanced
grant with No. 741278. Mike Papadakis is supported by the Luxem-
bourgNationalResearchFunds(FNR)C17/IS/11686509/CODEMATES.REFERENCES
[1]Ralph Weischedel, Martha Palmer, Mitchell Marcus, Eduard Hovy, Sameer Prad-
han,LanceRamshaw,NianwenXue,AnnTaylor,JeffKaufman,MichelleFran-
chini,MohammedEl-Bachouti,RobertBelvin,AnnHouston.2013. OntoNotes.
https://catalog.ldc.upenn.edu/LDC2013T19.
[2]YonatanBelinkovandYonatanBisk.2018. Syntheticandnaturalnoisebothbreak
neural machinetranslation.In Proc. ICLR.
[3]TsongYChen,ShingCCheung,andShiuMingYiu.1998. Metamorphictesting:a
newapproachfor generating nexttest cases. Technical Report.
[4]YongCheng,LuJiang,andWolfgangMacherey.2019. RobustNeuralMachine
TranslationwithDoublyAdversarialInputs.In Proceedingsofthe57thConference
of the Association for Computational Linguistics, ACL 2019, Florence, Italy, July
28- August 2, 2019, Volume 1: Long Papers. 4324ś4333. https://www.aclweb.org/
anthology/P19-1425/
[5]Yong Cheng, Zhaopeng Tu, Fandong Meng, Junjie Zhai, and Yang Liu. 2018.
Towards robust neural machine translation. arXiv preprint arXiv:1805.06130
(2018).
[6] CWMT. 2018. The CWMTDataset. http://nlp.nju.edu.cn/cwmt-wmt/.
[7]George Doddington. 2002. Automatic evaluation of machine translation quality
using n-gramco-occurrence statistics. In Proceedings ofthe second international
conference on Human Language Technology Research. Morgan Kaufmann Publish-
ersInc.,138ś145.
[8]David M Eberhard, Gary F Simons, and Charles D Fennig. 2019. Ethnologue:
Languagesof the world. (2019).
[9]JavidEbrahimi,AnyiRao,DanielLowd,andDejingDou.2018. HotFlip:White-
Box Adversarial Examples for Text Classification. In Proceedings of the 56th
Annual Meeting of the Association for Computational Linguistics (Volume 2: Short
Papers). Association for Computational Linguistics, Melbourne, Australia, 31ś36.
https://doi.org/10.18653/v1/P18-2006
[10]FreeSoftwareFoundation.2019. GNUWdiff. https://www.gnu.org/software/
wdiff/
[11]CarloGiglioandRichardCaulk.1965. Article17oftheTreatyofUccialli. The
Journal ofAfrican History 6,2 (1965), 221ś231.
[12]YoavGoldbergandOmerLevy.2014. word2vecExplained: deriving Mikolovet
al.’s negative-sampling word-embedding method. arXiv preprint arXiv:1402.3722
(2014).
[13]IanGoodfellow,JeanPouget-Abadie,MehdiMirza,BingXu,DavidWarde-Farley,
Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative Adversarial
Nets. InAdvancesinNeuralInformationProcessingSystems27,Z.Ghahramani,
M.Welling,C.Cortes,N.D.Lawrence,andK.Q.Weinberger(Eds.).CurranAsso-
ciates, Inc., 2672ś2680. http://papers.nips.cc/paper/5423-generative-adversarial-
nets.pdf
[14] Google. 2019. Google Translate. http://translate.google.com.
[15]YvetteGraham,TimothyBaldwin,AaronHarwood,AlistairMoffat,andJustin
Zobel. 2012. Measurement of progress in machine translation. In Proceedings of
the Australasian Language Technology AssociationWorkshop 2012. 70ś78.
[16]JiataoGu,YongWang,KyunghyunCho, andVictorOKLi.2018. Searchengine
guidedneuralmachinetranslation.In Thirty-SecondAAAIConferenceonArtificial
Intelligence.
[17]JieHao,XingWang,BaosongYang,LongyueWang,JinfengZhang,andZhaopeng
Tu. 2019. Modeling Recurrence for Transformer. In Proceedings of the 2019
ConferenceoftheNorthAmericanChapteroftheAssociationforComputational
Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers).
Association for Computational Linguistics, Minneapolis, Minnesota, 1198ś1207.
https://doi.org/10.18653/v1/N19-1122
[18]HanyHassan,AnthonyAue,ChangChen,VishalChowdhary,JonathanClark,
Christian Federmann, Xuedong Huang, Marcin Junczys-Dowmunt, William
Lewis, Mu Li, Shujie Liu, Tie-Yan Liu, Renqian Luo, Arul Menezes, Tao Qin,
Frank Seide, Xu Tan, Fei Tian, Lijun Wu, Shuangzhi Wu, Yingce Xia, Dong-
dongZhang,ZhiruiZhang,andMingZhou.2018. AchievingHumanParityon
Automatic Chinese to English News Translation. CoRRabs/1803.05567 (2018).
arXiv:1803.05567 http://arxiv.org/abs/1803.05567
[19]KimHazelwood,SarahBird,DavidBrooks,SoumithChintala,UtkuDiril,Dmytro
Dzhulgakov, Mohamed Fawzy, Bill Jia, Yangqing Jia, Aditya Kalro, James Law,
Kevin Lee, Jason Lu, Pieter Noordhuis, Misha Smelyanskiy, Liang Xiong, and
Xiaodong Wang. 2018. Applied Machine Learning at Facebook: A Datacenter
Infrastructure Perspective. In 24th International Symposium on High-Performance
Computer Architecture(HPCA2018), February24-28, Vienna, Austria.
[20]Georg Heigold, Stalin Varanasi, Günter Neumann, and Josef van Genabith. 2018.
HowRobustAreCharacter-BasedWordEmbeddingsinTaggingandMTAgainst
Wrod Scramlbing or Randdm Nouse?. In Proceedings of the 13th Conference of
the Association for Machine Translation in the Americas, AMTA 2018, Boston, MA,
USA, March 17-21, 2018 - Volume 1: Research Papers. 68ś80. https://aclanthology.
info/papers/W18-1807/w18-1807
[21]James W Hunt and Thomas G Szymanski. 1977. A fast algorithm for computing
longestcommon subsequences. Commun. ACM 20,5 (1977), 350ś353.
984ICSE ’20, May 23–29, 2020,Seoul,Republicof Korea Sun andZhang,et al.
[22]Yue Jia and Mark Harman. 2011. An Analysis and Survey of the Development of
MutationTesting. IEEE TransactionsonSoftwareEngineering 37,5 (Septemberś
October 2011),649 ś 678.
[23]Jiajun Jiang, Yingfei Xiong, and Xin Xia. 2019. A manual inspection of Defects4J
bugsanditsimplicationsforautomaticprogramrepair. ScienceChinaInformation
Sciences62,10(2019), 200102.
[24]Jiajun Jiang, Yingfei Xiong, Hongyu Zhang, Qing Gao, and Xiangqun Chen.
2018. Shaping Program Repair Space with Existing Patches and Similar Code.
InProceedings of the 27th ACM SIGSOFT International Symposium on Software
Testing and Analysis (ISSTA 2018). ACM, New York, NY, USA, 298ś309. https:
//doi.org/10.1145/3213846.3213871
[25]Jiajun Jiang, Yingfei Xiong, Hongyu Zhang, Qing Gao, and Xiangqun Chen.
2018. Shapingprogramrepairspacewithexistingpatchesandsimilarcode.In
Proceedingsofthe27thACMSIGSOFTInternationalSymposiumonSoftwareTesting
and Analysis. 298ś309.
[26]VladimirKarpukhin,OmerLevy,JacobEisenstein,andMarjanGhazvininejad.
2019. Training on Synthetic Noise Improves Robustness to Natural Noise in
MachineTranslation. arXiv preprint arXiv:1902.01509 (2019).
[27]Huda Khayrallah and Philipp Koehn. 2018. On the impact of various types of
noiseonneural machinetranslation. arXiv preprint arXiv:1805.12282 (2018).
[28]ClaireLeGoues,ThanhVuNguyen,StephanieForrest,andWestleyWeimer.2011.
Genprog:Agenericmethodforautomaticsoftwarerepair. Ieeetransactionson
softwareengineering 38,1 (2011), 54ś72.
[29]YangLiuandMaosongSun.2015. Contrastiveunsupervisedwordalignmentwith
non-localfeatures. In Twenty-Ninth AAAI Conference onArtificial Intelligence.
[30]Christopher D. Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven J.
Bethard,andDavidMcClosky.2014. TheStanfordCoreNLPNaturalLanguage
Processing Toolkit. In Association for Computational Linguistics (ACL) System
Demonstrations. 55ś60. http://www.aclweb.org/anthology/P/P14/P14-5010
[31]M. Chris Mason. 2017. Strategic Insights: Lost in Translation. https://ssi.
armywarcollege.edu/index.cfm/articles/Lost-In-Translation/2017/08/17
[32]Mike Papadakis, Marinos Kintis, Jie Zhang, Yue Jia, Yves Le Traon, and Mark
Harman.2019. Mutationtestingadvances:ananalysisandsurvey. In Advances
inComputers. Vol. 112. Elsevier, 275ś378.
[33]KishorePapineni,SalimRoukos,ToddWard,andWei-JingZhu.2002. BLEU:a
method for automatic evaluation of machine translation. In Proceedings of the
40thannualmeetingonassociationfor computationallinguistics .Associationfor
Computational Linguistics,311ś318.
[34]ParmyOlson.2018. TheAlgorithmThatHelpedGoogleTranslateBecomeSex-
ist. https://www.forbes.com/sites/parmyolson/2018/02/15/the-algorithm-that-
helped-google-translate-become-sexist/#224101cb7daa.
[35]Jeffrey Pennington, Richard Socher, and Christopher Manning. 2014. Glove:
Globalvectorsforwordrepresentation.In Proceedingsofthe2014conferenceon
empirical methodsinnatural languageprocessing(EMNLP). 1532ś1543.
[36]Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. 2018. Semantically
equivalent adversarial rules for debugging nlp models. In Proceedings of the 56th
Annual Meeting of the Association for ComputationalLinguistics (Volume 1: Long
Papers). 856ś865.
[37]Eric Sven Ristad and Peter N Yianilos. 1998. Learning string-edit distance. IEEE
TransactionsonPatternAnalysisand MachineIntelligence 20,5 (1998), 522ś532.
[38]Robert Parker, David Graff, Junbo Kong, Ke Chen, Kazuaki Maeda. 2011. English
Gigaword Fifth Edition. https://catalog.ldc.upenn.edu/LDC2011T07.
[39]RiponK.Saha,YingjunLyu,HiroakiYoshida,andMukulR.Prasad.2017. ELIXIR:
Effective Object Oriented Program Repair. In Proceedings of the 32Nd IEEE/ACM
International Conference on Automated Software Engineering (ASE 2017). IEEE
Press, Piscataway, NJ, USA, 648ś659. http://dl.acm.org/citation.cfm?id=3155562.3155643
[40] SpaCy.2019. SpaCy. https://spacy.io/.
[41]Matthias Sperber, Jan Niehues, and Alex Waibel. 2017. Toward robust neural
machine translation for noisy input sequences. In International Workshop on
Spoken Language Translation (IWSLT).
[42]LiqunSun and ZhiQuanZhou. 2018. Metamorphic testing for machine trans-
lations: MT4MT. In 2018 25th Australasian Software Engineering Conference
(ASWEC). IEEE,96ś100.
[43]ZeyuSun.2019. TransRepairHomepage. https://github.com/zysszy/TransRepair.
[44]AnnTaylor,MitchellMarcus,andBeatriceSantorini.2003. ThePenntreebank:
anoverview. In Treebanks. Springer, 5ś22.
[45]AshishVaswani,SamyBengio,EugeneBrevdo,FrancoisChollet,AidanN.Gomez,
StephanGouws,LlionJones,ŁukaszKaiser,NalKalchbrenner,NikiParmar,Ryan
Sepassi, Noam Shazeer, and Jakob Uszkoreit. 2018. Tensor2Tensor for Neural
Machine Translation. CoRRabs/1803.07416 (2018). http://arxiv.org/abs/1803.
07416
[46]Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
AidanNGomez,ŁukaszKaiser,andIlliaPolosukhin.2017. Attentionisallyou
need. InProceedings of the 31st International Conference on Neural Information
ProcessingSystems. Curran Associates Inc.,6000ś6010.
[47]VoiceBoxer. 2016. WHAT ABOUT ENGLISH IN CHINA? http://voiceboxer.com/
english-in-china/.
[48]RiningWeiandJinzhiSu.2012. ThestatisticsofEnglishinChina:Ananalysis
ofthebestavailabledatafromgovernmentsources. EnglishToday 28,3(2012),
10ś14.
[49] Wikipedia.2014. Wikipedia. https://dumps.wikimedia.org/.
[50]WMT.2018.News-Commentary.http://data.statmt.org/wmt18/translation-task/.
[51]QiXinandStevenP.Reiss.2017. LeveragingSyntax-relatedCodeforAutomated
ProgramRepair.In Proceedingsofthe32NdIEEE/ACMInternationalConference
on Automated Software Engineering (ASE 2017). IEEE Press, Piscataway, NJ, USA,
660ś670. http://dl.acm.org/citation.cfm?id=3155562.3155644
[52]JieZhang, JunjieChen, Dan Hao, Yingfei Xiong, BingXie, LuZhang, and Hong
Mei. 2014. Search-based inference of polynomial metamorphic relations. In
Proceedings of the 29th ACM/IEEE international conference on Automated software
engineering. ACM,701ś712.
[53]Jingyi Zhang, Masao Utiyama, Eiichro Sumita, Graham Neubig, and Satoshi
Nakamura. 2018. Guiding neural machine translation with retrieved translation
pieces.arXiv preprint arXiv:1804.02559 (2018).
[54]Jie Zhang, Lingming Zhang, Mark Harman, Dan Hao, Yue Jia, and Lu Zhang.
2018. Predictive mutation testing. IEEE Transactions on Software Engineering 45,
9 (2018), 898ś918.
[55]Jie Zhang, Muyao Zhu, Dan Hao, and Lu Zhang. 2014. An empirical study
onthescalabilityofselectivemutationtesting.In 2014IEEE25thInternational
SymposiumonSoftwareReliability Engineering. IEEE,277ś287.
[56]Jie M Zhang, Mark Harman, Lei Ma, and Yang Liu. 2019. Machine Learning
Testing:Survey,LandscapesandHorizons. arXivpreprintarXiv:1906.10742 (2019).
[57]Yin Zhang, Rong Jin, and Zhi-Hua Zhou. 2010. Understanding bag-of-words
model: a statistical framework. International Journal of Machine Learning and
Cybernetics 1,1(01Dec2010),43ś52. https://doi.org/10.1007/s13042-010-0001-0
[58]Zhengli Zhao, Dheeru Dua, and Sameer Singh. 2017. Generating Natural
Adversarial Examples. CoRRabs/1710.11342 (2017). arXiv:1710.11342 http:
//arxiv.org/abs/1710.11342
[59]Michał Ziemski, Marcin Junczys-Dowmunt, and Bruno Pouliquen. 2016. The
united nations parallel corpus v1. 0. In Proceedings of the Tenth International
Conference onLanguage Resourcesand Evaluation(LREC2016). 3530ś3534.
985