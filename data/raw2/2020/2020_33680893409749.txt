eQual: Informing EarlyDesign Decisions
ArmanShahbazian
Universityof SouthernCalifornia& Google
LosAngeles,CA,USA
shahbazian@google.comSuhridKarthik
Universityof SouthernCalifornia
LosAngeles,CA,USA
skarthik@usc.edu
Yuriy Brun
Universityof Massachusetts Amherst
Amherst,MA, USA
brun@cs.umass.eduNenad Medvidovic
Universityof SouthernCalifornia
LosAngeles,CA,USA
neno@usc.edu
ABSTRACT
When designing a software system, architects make a series of
design decisions that directly impact the system’s quality. The
number of available design alternatives grows rapidly with system
size,creatinganenormousspaceofintertwineddesignconcerns
that renders manual exploration impractical. We present eQual,
a model-driven technique for simulation-based assessment of ar-
chitecturaldesigns. Whileitisnotpossibletoguaranteeoptimal
decisionssoearlyinthedesignprocess, eQualimprovesdecision
quality.eQualiseffectiveinpracticebecauseit(1)limitstheamount
ofinformationthearchitectshavetoprovideand(2)adaptsopti-
mizationalgorithmstoeffectivelyexploremassivespacesofdesign
alternatives. We empirically demonstrate that eQualyields designs
whose quality is comparable to a set of systems’ known optimal
designs. A user study shows that, compared to the state-of-the-art,
engineers using eQualproduce statistically significantly higher-
qualitydesignswithalargeeffectsize,arestatisticallysignificantly
more confident intheirdesigns,andfind eQualeasier to use.
CCS CONCEPTS
·Software and its engineering →Software design engineer-
ing;Software implementation planning .
KEYWORDS
Software design,designdecisions, optimization, designanalysis
ACMReference Format:
Arman Shahbazian, Suhrid Karthik, Yuriy Brun, and Nenad Medvidovic.
2020. eQual: InformingEarlyDesignDecisions. In Proceedingsofthe28th
ACMJointEuropeanSoftwareEngineeringConferenceandSymposiumonthe
FoundationsofSoftwareEngineering(ESEC/FSE’20),November8ś13,2020,
Virtual Event, USA. ACM, New York, NY, USA, 13pages.https://doi.org/10.
1145/3368089.3409749
Permissionto make digitalor hard copies of allorpart ofthis work for personalor
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
onthefirstpage. Copyrightsforcomponentsofthisworkownedbyothersthanthe
author(s)mustbehonored. Abstractingwithcreditispermitted. Tocopyotherwise,or
republish,topostonserversortoredistributetolists,requirespriorspecificpermission
and/or a fee. Request permissions from permissions@acm.org.
ESEC/FSE ’20, November 8ś13, 2020, Virtual Event, USA
©2020 Copyright heldby the owner/author(s). Publicationrightslicensed to ACM.
ACM ISBN 978-1-4503-7043-1/20/11...$15.00
https://doi.org/10.1145/3368089.34097491 INTRODUCTION
Formostsoftwaresystems,architecturaldecisionsareintroduced
incrementally,assysteminformationbecomesavailable. Somede-
cisions are made quite early, but have long-lasting impact. Making
suboptimal decisions can lead to system inefficiency or to a costly
redesignlaterinthedevelopmentprocess. Thispaperintroduces
eQual, a technique that helps make better-informed design deci-
sionsthroughouttheprocessbyusingsimulationtohelparchitects
understand the implications of specific design choices using the
partialinformation available at the time the decisions are made.
Consistently making optimaldecisions early in the process may
beimpossiblebecauseonlypartialinformationaboutthesystem
is known at that time. eQual’s goal is to compute relevant infor-
mation that helpsmake betterdecisions thanispossible using the
state-of-the-arttechniques. Infact,inSection 4,inacontrolleduser
study with 15 engineers, we demonstrate engineers using eQual
producestatisticallysignificantly( p<0.001)higher-qualitydesigns
thanthosewhouseastate-of-the-arttechnique[ 29]andthosewho
do not use specialized tools. The effect size of the treatment is
large,meaningthedesignstheyproduceusing eQualareofmuch
higherquality. Wefurthershowthat eQualusersarestatistically
significantly( p<0.05)moreconfidentin theirdesignsandprefer
eQual’susability. Appliedtoabenchmarkofsystemswithprevi-
ously published ground-truth key design choices [ 81,82], we show
thateQualrecommendsvariantsthatareeitheroptimalorareof
essentially the same quality as the optimal solutions. Finally, we
show that eQualiseasier to use than prior tools. Overall, we show,
either directly and by transitivity via prior studies,that eQualout-
performsexistingtechniqueswithinitsproblemscope,including
GuideArch[ 29],ArchDesigner[ 1],ArcheOpterix[ 2],ATAM[ 17],
CBAM[45], Doyle[ 25], andNoppen etal.[ 66].
Theproblem eQualtacklesishardbecauseinanyreal-worldsys-
tem,therearecountlessdesigndecisionstobemade[ 80,85,89,90],
early architectural designs exhibit significant uncertainties [ 13,29,
50], andthedecisions intertwine manyfactorsandtrade-offs that
mustbeconsidered[ 15,16,69]. Ideally,architectscarefullyassess
the individual choicesto make viable designdecisions that satisfy
a system’s requirements. However, this is frequently not done
in practice [ 20]. A well publicizedexample isthe Healthcare.gov
(a.k.a.łObamacarež)portal,whichwasmarredwithseriousprob-
lems [54,65,88] due to flawed architectural decisions [ 89,90]:
itsdevelopmentcosts,originallyestimatedat ∼$100M,surpassed
1039
ESEC/FSE ’20, November8ś13,2020,VirtualEvent, USA Arman Shahbazian, Suhrid Karthik, YuriyBrun, andNenadMedvidovic
$1.5B [51]. The root cause of such failures is known: evaluating de-
sign options is exceedingly complex. The space of system variants
rapidly eclipses human capabilities [ 36]. A solution that appears to
makesenseintuitivelymayturnouttobewildlyoffthemarkor,
inthe bestcase,suboptimal.
Architectural design decisions span diverse concerns: system
structure, behavior, interaction, deployment, evolution, and non-
functionalproperties(NFPs)[ 85]. Everydecisionisaselectionof
one of several possible alternatives for a given variation point in
a system. For example, in a system that may have multiple au-
thenticationservers,e.g.,forscalability,theserverscomprisethe
variationpoint,andthespecificnumberisanalternative. During
the design of a system, an architect must make many such deci-
sions, for example, how many replicated data stores to use, how
to implement each data store (e.g., different relational or NoSQL
database implementations and their relevant parameters), what
implementation framework to use(e.g., different MVC-based Web
frameworks and their parameters), what architectural styles to use
(e.g.,layeredclient-serverthatmayyieldann-tieredarchitecture
vs. event-based that may result in distributed peers), what data
cachingstrategiestouse,etc. Anarchitecture variantisthesetof
design decisions that result in the selection of an alternative for
eachvariationpointinasystem;inotherwords,avariantresults
inacompletearchitecture for the system.
eQualisamodel-driventechniqueforsimulation-basedexplo-
ration and assessment of architectural designs on the cloud. We
initially proposed eQualspecifically to help make well-informed
design decisions [ 79].eQual’s goal is to help compute the impli-
cationsof design decisions, even when only partial informationis
availableearlyintheprocess,suggestinganorderingonpossible
variantswithrespecttospecificqualityconcerns. The ideaisthat
whileknowninformationmaybeinsufficientto makeoptimalde-
cisions, some alternatives can be shown to be better than others,
and that information can help engineers to explore huge spaces of
design decisions to improve their choices. eQualasks a bounded
numberofrelativelystraightforwardquestionsaboutthesystem
under design and the engineers’ preferences for the system and
thenautomaticallybuildsthe requisitesystemmodels, distributes
andrunssimulationsinthebackground,anddeliverstheranked
list of variants that respect the engineers’ already-made design
choices. Engineers can accept eQual’s recommendations or adjust
theirpreferences andexplore othervariants.
eQualtakestwoinputs: (1)asoftwaresystemmodeland(2)archi-
tects’answers to a set ofquestions abouttheparameterscaptured
inthe model. The systemmodelis anartifactthat typicallyalready
exists as part of the normal design process [ 85]. The questions are
designed to be relatively simple to answer, and optional. Examples
ofquestionsarełWhatistheappropriateinteractionmechanism
for the selected components?ž and łWhat is the maximum number
ofauthenticationserversinthesystem?ž eQualprovidesinterac-
tive facilities for creating the system model in a domain-specific
language (DSL). eQual’s questions (1) bound the search space of
variantseQualwill explore, and (2) identify the NFPs of interest.
eQualdoes not assume the architects will be able to answer the
questions (e.g., because of insufficient knowledge about the sys-
tem) orthatsystemparameterscanberank-ordered (e.g.,becausetheparametersarequalitative). Ifthearchitectchoosesnottoan-
swer the questions, eQualmay explore an unbounded search space.
eQualuses the system model and the specified bounds to generate
variants, intelligently distributes those variants on a set of cloud
nodes for simulation, and collects and processes the data using our
novel Bipartite Relative Time-series Assessment (BRTA) algorithm.
eQualrepeats this process until it arrives at a set of satisfactory
variants basedonthe of-interestproperties.
This paper’s primary contributionsare:
(1)Amethodforautomaticallygeneratingarchitecturalassessment
models from simpleinputsthat architectsprovide.
(2)The BRTA algorithm for analyzing simulation data to solve the
previouslyprohibitivelyinefficientvariant-assessmentproblem.
(3)An architecture for seamlessly distributing and parallelizing
simulations to multiple computational (e.g.,cloud) nodes.
(4)Anabilitytoquicklyexploreandvisualizemanydifferentdesign
alternatives until asatisfactory solution isreached.
(5)Anevaluationof eQual’sscope,easeofuse,effectiveness,and
scalability onreal-world systems.
(6)Anopen-source eQualimplementation,allevaluationscripts,
anddata,andexperimental replication package [ 78].
In the rest of our paper, Section 2introduces Hadoop, used to
help describe and evaluate eQual. Section 3describes eQualand
Section4evaluatesit. Section 5places ourresearchinthe context
ofrelatedwork. Finally,Section 6summarizes our contributions.
2 FOUNDATION
Wefirstexplainourchoiceoftoolstowhichwecompareourap-
proach. We then introduce a simplified version of a widely used
system,whichwe willuse to illustrate the approach inthis paper.
2.1 ChoiceofState-of-the-Art Comparison
Software system design is a richresearchfield. Architects’ experi-
ence,knowledgeofarchitecturalstylesandpatterns,priordesign
of similar systems, understanding of the deployment environment,
and many more attributes play a role in successful design. Existing
tools can help augment the architects’ knowledge to help produce
betterdesigns. Thismakesevaluating eQualchallenging: itisnot
feasible to compare eQualto all different architecture tools in a
singleconferencepaper. Werestrictourcomparisonheretotools
thattacklethesameproblemscopeas eQual. Ourfocusisneitherto
develop a tool thatprovides all theuseful typesofinformationfor
architects,nortoclaimthatthetoolcanproduceoptimaldesigns.
Instead,eQual’s goal is to help make betterdecisions than using a
particularsetoftoolsdesignedto tackle the same problem scope.
We directly compare eQualto GuideArch [ 29] for three reasons.
First,GuideArchmatches eQual’sproblemscopebyaimingtocom-
pute the same type of information architects use in making design
decisions. Second, prior work has demonstrated that GuideArch
outperforms a large number of existing techniques in this problem
scope,includingArchDesigner[ 1],ArcheOpterix[ 2],ATAM[ 17],
CBAM [45], Doyle [ 25], and Noppen et al. [ 66]. By comparing
directly with GuideArch in the same dimensions, we can be con-
fidenteQualoutperforms these techniques as well. Third, since
GuideArch’s publication, despite improvement attempts [ 13,30,50,
76],GuideArchhasremainedthestateoftheart. GuideArchuses
1040eQual: InformingEarly DesignDecisions ESEC/FSE ’20, November8ś13,2020,VirtualEvent, USA
Leave
poolComputation Split computation into tasksTask scheduler
Machine pool
Get next job from queue
Select a machine
Assign job to machine
Gather results , or create 
new jobsJob
queue
Perform 
jobReturn 
to poolCreate jobs for tasks
Figure 1: Model of the Hadoop system in DomainPro, a
domain-specificlanguage [ 11].
fuzzymathematicalmethodstoautomaticallyselectasetofnear-
optimaldecisionsfromalargedesignspace[ 29]. Letieretal.[ 13,50]
built on GuideArch to reason about uncertainty in early require-
mentsanddesignsusingstatisticaldecisionanalysis. However,that
approachonlyapplieswhenthedesignspacesarereasonablysmall
andamenabletoexhaustivesearch. Ourexperienceandalargebody
of literature show that real systems’ designs have massive decision
spacesthatgrowrapidlywiththesystems’complexity(e.g.,[ 36,80ś
82,85]). Sedaghatbaf et al. [ 76] used evolutionary algorithms to
explore the effects of varyingthe numbersof systemresources and
of reallocating software components across hardware hosts. These
very concerns have already been considered by GuideArch (and by
aGuideArchpredecessor[ 56]),andultimatelytheresultingfacil-
itiesimproveneitherGuideArch’sapplicabilitynoritsscalability.
Fahmidehetal.[ 30]appliedGuideArch’sfuzzy-mathapproachto
find an optimal set of design decisions in another domainÐdesign-
exploration of manufacturing systemsÐbut did not improve the
underlyingGuideArchcapabilities. Asaresult,GuideArchhasre-
mainedthestate-of-the-artapproachwithrespecttoalargenumber
ofcompetitors[ 1,5,13,21,27,30,50,56,58,76,77].
Atthesametime,GuideArchhasfacedtwoobstaclestoadoption.
First,itrequiresthatarchitectssupply potentiallylargeamountsof
information, some of which they may not readily have. Second, its
effectiveness and scalability claims have only been evaluated via a
casestudyusedtoillustrateitsfeatures[ 29]. Toaddresstheselimita-
tions,wehavedevelopedandextensivelyevaluated eQual,amodel-
driven,simulation-based techniquethattacklesthesame problem
spaceof early architectural design for large systems, but aims to
improve GuideArch’s ease ofuse ,effectiveness ,andscalability .
What our paper demonstrates is that eQualcan improve the
processofmakingdesigndecisionsascomparedtothetoolswithin
its problem scope. It is likely that other tools that provide other
types of information useful for making design decisions can be
complementary to eQual, as Section 5describes. This paper pro-
videssignificantevidencethat eQualcanbeapartofthesolutiontoVariation Point Lower Bound UpperBound
Computation Size 500 2000
Redundancy Level 1 5
Pool Size 10 100
Machine Reliability 0.5 0.9
ProcessingPower 0.5 2
Figure 2: A selection of Hadoop’s variation points and their
representative bounds [ 11,12].
making better, informed design decisions, but future work will cer-
tainly demonstrate ways to combine different kinds of information
witheQual’sto further improve the process.
2.2 Using eQualon anExample System
We use a simplified model of Hadoop from prior work [ 11,12] as a
running example throughout the paper. In this model (shown in
Figure1), acomputation is the problem being solved, consisting
of many computational tasks. Tasks can be replicated, e.g., for
reliability [ 12]. Ajobis an instance of a task (i.e., one replica of
a task) and machines execute these jobs. A task scheduler breaks
upacomputationintotasks,createsjobsasreplicasoftasks,and
assigns jobs to machines in the machine pool. After returning a
response to the task scheduler, a machine rejoins the machine pool
andcan be selectedfor anewtask.
Although eQualhasbeenusedtoanalyzeHadoop’sentiredesign
space (over 100 design decisions [ 80]), for simplicity of exposition,
we highlight five variation points that affect Hadoop’s key NFPs:
(1)ComputationSize ,thenumberoftasksrequiredtocompletea
computation;(2) RedundancyLevel ,thenumberofmachinesthat
run identical jobs;(3) Pool Size,the number of available machines;
(4)MachineReliability ,theprobabilityofamachinereturningthe
correctresult; and(5) ProcessingPower ofeachmachine. Wewill
discussother,non-numericalvariationpointsbelow. Figure 2de-
pictsrepresentativeboundsforthefivevariationpointsobtained
from the previously publishedanalysis[ 11,12].
TouseeQual,anarchitectspecifiesadesignmodel(thesemodels
typicallyalreadyexistaspartofnormaldesignactivities[ 71,85])
andanswersasetofsimpledesignquestions,suchasłWhatarethe
the lower and upper bounds on the number of system’s Pool Size?ž
eQualprovidesinteractivefacilitiesforspecifyingthismodelandan-
swers. Next, eQualautomaticallygeneratesasetofsystemvariants
andusesdiscrete-eventsimulationtoevaluatetheirimpactonqual-
itymeasures(specifiedbythearchitectaspartofthemodel). The
results inform eQual’s selection of a next set of variants to explore.
eQualiteratesthiswayuntilitarrivingatalistofvariantsthatopti-
mizedesirablequalitymeasures,andpresentsthearchitectwiththe
list to help understand the impact of the explored design decisions.
3 THE eQualAPPROACH
eQualexploresasystem’sdesignspaceviafoursteps: (1)modeling,
(2)preparation,(3)selection,and(4)assessment. Steps(1)and(2)
are interactive and help the architect generate eQual’s inputs: a
design model and answers to a set of design-related questions.
Steps(3)and(4)areautomatedandproducealistofrankedsystem
variants. Steps (1) and (3) adapt existing solutions, while (2) and (4)
1041ESEC/FSE ’20, November8ś13,2020,VirtualEvent, USA Arman Shahbazian, Suhrid Karthik, YuriyBrun, andNenadMedvidovic
Variant 
Visualization
Preparation 
InterfaceRanked 
Variants
Questions
Answers
Simulation Pool ConnectorGlobal 
Assessment
Selection
PreparationAnalysis 
Reports
Sim
 Configs.Sim 
Configs.Ranked VariantsAnalysis
Reports
System DesignSystem Design
Questions,
Ranked 
VariantsAnswers,
System 
DesignSystem Design
Controller Connector
QuestionsAnswers
224
4Client ConnectorDesign Environment1
Ranked 
Variants
3
Local 
Assessment Node ConnectorUpdates
Analysis
ReportsSimulation DataSim Configs.
Simulation 
Engine
Figure3: eQual’sarchitecture. The DesignEnvironment andSimulationEngine componentsareprovidedbyDomainPro[ 77].
arenewcontributionsintroducedby eQual. Steps(3)and(4)take
place iteratively: outputs of assessment feed back into selection,
helpingeQualto choose better alternatives, thereby generating
improvedvariants. Figure 3showseQual’sarchitecture,withthe
componentsperformingthe foursteps denoted.
Critically, eQual’s inputs are types of artifacts architects must
considerand/orcreateaspartoftheirregulartasks. Softwarede-
velopmenttypicallyinvolvesmodelingofthesystem’sarchitecture
(eQual’sstep 1), even if informally [ 71,85]. Likewise, theanswers
toquestions eQualasks(eQual’sstep2),whichresultinspecifica-
tions of the desired behavioral properties in a system, are concerns
architects have to analyze regardless of whether they use eQual.
The remainderofthis section details eachof eQual’sfoursteps.
3.1 Modeling
eQual’s first input is a system’s architectural model amenable to
dynamicanalysis. Severalapproachescreatesuchmodels,including
ArchStudio [ 21], XTEAM [ 27], PCM [ 58], and DomainPro [ 77].
Any of these would suit our purpose. For eQual’s implementation,
we selected DomainPro [ 24,77] because of its simple interface,
integratedsupportforofevent-drivensimulation,andmodel-driven
architecture(MDA)approach[ 64]thatallowsarchitectstodefine
variationpointsintheirmodelsandtrydifferentalternatives(albeit
completely manually).
AsiscommoninMDA,asystemisdesignedinDomainProintwo
phases. First, an engineer must create a metamodel using Domain-
Pro’seditor orreusea previously defined metamodel. Second, the
systemisdesignedbyspecializingandinstantiatingelementsofthis
metamodel. A metamodelisacollectionofdesignbuildingblocks
relevanttomodelingsystemsofcertainkindsorincertaindomains
thatdefinesaDSL.DomainProinvokestheappropriatemodeltrans-
formation tool (a metainterpreter) to derive the implementation
semantics of the DSL types from the metamodel. Subsequently,
DomainProgeneratesadomain-specificmodeleditor,simulation
generator (as well as a code generator, which we do not use in
eQual), allconfiguredwiththe DSL’scustomsemantics.
DomainPro provides a built-in metamodel for component-based
architectures[ 62]. TheHadoopmodelinFigure 1showsthespe-
cializationandinstantiationofthismetamodel’selementsandtheirdepictionintheresultingvisualDSL[ 77]. AComputation isaDo-
mainPro Operation depictedasacircle;eachactivityinthe Task
Scheduler Component isaDomainPro Taskdepictedasanoval; Ma-
chine Pool is a DomainPro Resource depicted as the cloud shape
containing the filled-in circles; data-flows are DomainPro Links
represented with wide arrows; and so on. Figure 1omits the Do-
mainProParameter s of each modeling element for clarity; several
key parametersare showninFigure 2.
Weusethisexampleforillustration. DetailsofDomainProand
Hadoop’s visual DSL from Figure 1are not necessary for under-
standing eQualandare beyondthe scope of this paper.
3.2 Preparation
eQual’s second input consists of answers to a set of questions that
fallintwocategories: thesystem’s(1)variationpointsand(2)prop-
ertiesofinterest(e.g.,performance). eQualformulatestheseques-
tionsintermsofthesystem’smodelanditsparameters,presenting
specific choicesintendedto be straightforwardfor architects.
3.2.1 QuestionsRegardingVariationPoints. eQualdividesvariation
pointsinto(1)systemparametersthatarenumericalorcanberank-
orderedand(2)systemparametersthatareinherentlyqualitative.
Foravariationpoint Vfromthefirstcategory, eQualasksarchitects
three questions:
(i) Whatis V’slower bound?
(ii) Whatis V’supper bound?
(iii) Whatisthe desiredfunction for exploring V?
The lower and upper bounds capture acceptable ranges of alterna-
tivesforeachvariationpoint. Explorationfunctionsenablearchi-
tects tocustomize how eQualsamplesthe specified ranges during
design exploration (Sections 3.3,3.4). For example, in Hadoop, the
Pool Size variation point’s lower bound is 10 and upper bound is
100(Figure 2).eQual’sprototypeprovides12explorationfunctions:
Uniform, Poisson, Gamma,etc.
eQualalsoallowsarchitectstoprovidelistsofconcretevaluesin-
steadofranges. Thisreducesthesearchspaceifspecificpreferences
forcertainnumericalandrank-orderedparameters(category1)are
knownapriori. Thisoptionis necessary inthecaseofqualitative
parameters (category 2): Architects must enumerate all relevant
1042eQual: InformingEarly DesignDecisions ESEC/FSE ’20, November8ś13,2020,VirtualEvent, USA
alternatives for each qualitative parameter; in turn, eQualmust
selecteveryalternative(Section 3.3)andassesseachresultingar-
chitectural modelfor propertiesofinterest(Section 3.4).
Forexample,letusassumethatanarchitectwishestoexplore
different RPCmechanisms inHadoop viathree qualitative design
parametersassociatedwithDomainPro’s Links: (1)InvocationType ,
whichcan be explicit orimplicit; (2) Synchrony , whichcan be syn-
chronous, time-out-synchronous, or aynchronous; and (3) Delivery
Guarantees , which be at-least-once, at-most-once, exactly-once, or
best-effort. Inthegeneralcase, eQualmustexplore2 ×3×4=24
combinations of alternatives for these three parameters for each
combinationofalternativesselectedforthecategory1variationpoints .
Notethatthisgrowthinthedecisionspacecanbestemmedifar-
chitectsareabletoidentifyspecificpreferreddesignchoices. For
example, a decision to configure Hadoop’s ipc.Client module to
supportexplicit, asynchronous callswith at-most-once semantics
wouldrequirethatthearchitectseliminatefromthe eQualmodel
theundesiredalternativesforthethreeparameters,whichwould
reduce the number ofcombinationsofalternatives from 24 to 1.
A prior analysis [ 80] identified well over 100 design decisions
madeduringpartofHadoop’sdevelopment. Hadoop’sarchitects
considered 2ś8 alternatives per variation point. The resulting deci-
sionspacequicklyeclipseshumanabilities. Forexample,aminor
versioninvolvingonly4newdesigndecisionsand5alternatives
per decision will have over 500 variants. By contrast, the entire
burdeneQualplacesonarchitectsistoanswer4 ×3=12questions
aboutthe variation points.
Wedonotexpectarchitectstobeabletoanswertheaboveques-
tionsrightaway. eQualallowsseveralpossibilities: (1)Architects
may know the exact answer to a question. (2) They may be able
toprovideonlya partialanswer, such as avariation point’slower
bound. (3)Theymaybeunabletoansweraquestion,leavingthe
range ofalternatives unbounded.
3.2.2 Questions Regarding Non-Functional Properties. eQual’s sec-
ondsetofquestionsdealswiththesystem’sNFPs,whicharethe
basisforassessingdesignalternatives(Section 3.4). TheNFPsarede-
terminedfromsystemrequirementsanddomaincharacteristics. For
example, in Hadoop, prior work identified four properties [ 11,12]:
(1)Reliability (ratiooftasksthathavetoberestartedtoalltasks),
(2)Machine Utilization , (3)Execution Time , and (4)Cost(total num-
berofexecutedjobs). Eachpropertyhastobetiedtoanaspectofthe
outputof thesystem’s dynamic analysis. In DomainPro and other
approachesthatusediscrete-eventsimulation(e.g.,Rhapsody[ 43]),
system stateis capturedat thetimesof eventoccurrences. Hence,
the outputisasetoftime-seriesobjects.
For anon-functionalproperty P,eQualasks three questions:
(i) Whattime-seriesobjectisofinterest?
(ii) IsPdirectlyorinverselyrelatedto overallsystemquality?
(iii) Whatis P’simportancecoefficient?
For example, in the case of Hadoop’s Machine Utilization , the
relevant time-series object captures idle capacity of the machine
poolinthemodeldiscussedabove. Thedirectionoftherelationship
is inverse (lower idle capacity means higher utilization); and the
importance coefficient may be set to 3 (an ordinal value between 1
and5,thatwouldtreat MachineUtilization asmoreimportantthan,
e.g.,Costwhose coefficient is 1, and less important than Reliabilitywhose coefficient is 5). Thus, for the above example of a minor
version with 4 variation points, given Hadoop’s 4 properties of
interest, an architect using eQualwould have to answer a total
of 24 questions: 12 questions each for the variation points and
properties.
eQual’saimisto elaboratetheinformationarchitectsalreadymust
takeintoaccount . Inpractice,architectsoftenignore,accidentally
omit, indirectly consider, or incorrectly record information cap-
tured by these questions [ 85]. By (1) strictly bounding the number
ofquestions,(2)consolidatingthemintooneplace,and(3)giving
them a standard format, eQualaims to convert this frequently hap-
hazard process into methodical design. As the architects explore
the design alternatives and gain a better understanding of the sys-
tem, they are able to go back and add, remove, or change their
answers.
3.3 Selection
Thesystem’sdesignmodel(Section 3.1)andtheanswerspertain-
ing to the system’s variation points and properties (Section 3.2)
areinputsoftheselectionstep,whoseobjectiveistoexplorethe
space of designvariants intelligently and tractably. Forexample, in
Hadoop,thiscanhelpengineersexploretheeffectsofnon-trivialde-
cisions, such as: What yields better reliability at an acceptable cost,
agreater numberof less-reliablemachinesor fewermore-reliable
machines?
Selectionbeginsbygeneratinganinitialsetofvariants,i.e.,by
making an initial selection of alternatives for the system variation
points usingthe informationprovided byarchitects duringprepa-
ration (Section 3.2). We call this initial set seed variants , and the
processeQualuses to pick the seed and later variants selection
strategy. Seed variants feed into assessment (Section 3.4), where
eQualcomparatively analyzes them. Assessment feeds its ranking
of variants back to selection (recall Figure 3), which uses this in-
formation to generate an improved set of variants during the next
iteration.
Two factors determine selection’s effectiveness: (1) how seed
variantsaregeneratedand(2)howinformationfromassessment
is used to generate subsequent variants. In principle, eQualallows
any selection strategy. The goal is to enable an architect to control
the selection step’s number of iterations and generated variants
to fit her needs, specific context, and available computational re-
sources.
Our prototype implements two selection strategies based on the
geneticevolutionary-algorithmparadigm: randomandedge-case
seeding. Randomseedingchoosesseedvariantsrandomly. Edge-
caseseedingaimstogeneratevariantscontainingeithersideofa
boundary condition provided to eQual. For example, variants in
Hadoop would be generated by selecting all lower-bound values
from Figure 2(500, 1, 10, 0.5, 0.5), all upper-bound values (2000,
5, 100, 0.9, 2), and combinations of upper-bound values for some
variationpointsandlower-boundvaluesfortheremainingvariation
points, e.g., (2000, 5, 100, 0.5, 0.5). Note that edge-case seeding is
not possible with options that are nominal, i.e., do not have binary
ornumerical values.
Both strategies quickly prune the space of variants and arrive at
good candidate designs (see Section 4). We aim to preserve Pareto
1043ESEC/FSE ’20, November8ś13,2020,VirtualEvent, USA Arman Shahbazian, Suhrid Karthik, YuriyBrun, andNenadMedvidovic
optimal[14]solutionsateachstepasthisprovidesanintuitiveway
to explore extreme effectsofdecisions.
3.4 Assessment
Toassess a variant’s quality, eQualdynamically analyzes itvia sim-
ulation. Wechosesimulation-basedanalysisbecausesimulations
are representative of a system’s real behavior due to their inherent
nondeterminism[ 46].eQualreliesondiscrete-eventsimulations,
generatingoutputsintheformoftime-seriesobjects. Comparing
different variants thus requires an analysis of their simulation-
generated time-series. Although there are dozens of similarity
metrics,inmostdomains(e.g.,robotics,speechrecognition,soft-
wareengineering)DynamicTimeWarping(DTW)hasbeenshown
to perform betterthanthe alternatives [ 23]. We thus use DTW.
For each design variant, eQualgenerates a single time-series
objectforeachNFP.ForHadoop,thatmeansfourtime-seriesper
variant,correspondingto the system’s(1) Reliability ,(2)Execution
Time,(3)MachineUtilization ,and(4)Cost. Eachdatapointinatime-
series corresponds to the computed value for the given property at
the given time.
Depending on the direction of the relationship of a property
with overall system quality, we aim to find the variant that has
yielded the time-series with the highest (direct relationship, e.g.,
forReliability ) or lowest (inverse relationship, e.g., for Cost) values
forthatproperty. Tothisend,weneedtocompareeachtime-series
with theoptimum time-series . The optimum time-series for a given
NFP is a constant time-series each of whose data points is equal
to the highest (or lowest) value of the property achieved across
all simulations. This comparison requires having access to all of
the simulation-generated data in one place, and computing the
global optimum and distances from it. This may entail transferring
hundredsofmegabytesofdatapervariant,andhavingtoredoallof
thecalculationseachtimeanewvariantchangestheoptimumtime-
series. Suchasolutionwouldbeprohibitivelycostlyinscenarios
withmultiple iterations involving thousandsofvariants.
To address this problem, we devised the Bipartite Relative Time-
series Assessment technique (BRTA), which distributes the time-
series analysis. As indicated in Figure 3, multiple nodes are tasked
with assessing different subsets of variants via simulation. Each
nodebehavesinthemannerdescribedabove: itperformsadiscrete-
event simulation of the design variants with which it is tasked,
computesanoptimumtime-series,andusesDTWtocomparethe
individualtime-serieswiththeoptimum. Notethattheoptimum
time-seriesisa localoptimum sincetheothernodeswillperform
the sametasks on theirvariants. In addition, for eachnode, BRTA
calculates the range (minimum-to-maximum) for the time-series
computedlocally,aswellasthenormalizeddistance(distancedi-
videdbythe number ofpointsinthe time-series).
Instead of returning all simulation-generated data to the assess-
mentnode(recallFigure 3),BRTAonlysendsasummarycontaining
the above measurements. The global assessment algorithm gathers
these summaries and calculates the distance to the global optimum
time-seriesfor eachtime-seriesas follows:
Dд=/braceleftbiggMaxд−Ol+Dl(if direct)
Ol−Minд+Dl(if inverse )
Reliability
Cost
UtilizationExecution
Time
Figure 4: eQual’s radar diagram for two candidate Hadoop
variants,showingtheirrespectivevaluesforfourproperties
ofinterest.
Dдis distance to the global optimum; Olis the local optimum; Dl
is distance to the local optimum; Maxд(Minд) is the global max
(min) value among all time-series of a NFP. We formally prove this
formula’s correctness in our experimental replication package [ 78].
BRTA’s reduction in the amount of transferred data directly
facilitates eQual’s support for exploring many design alternatives.
The updated BRTA summaries include the globally normalized
values for each time-series in each variant and, are used to rank
the variants. To use the Dдvalues of different NFPs to calculate
theoverallutilityofadesignvariant,welinearlyrescalethemto
a value between 0 and 1. The overall quality of the system, then,
istheaverage,weightedbytheimportancecoefficientsprovided
by the architects (as described in Section 3.2), among all of these
values.
Whenmultiplevariantshavecomparablequalities, eQualalso
allows architects to visually compare them. Figure 4shows an
example of such a visualization: the architects may use this visual-
izationtodecidebetweenthevariantthatemphasized Reliability
andthe variantthat balancedthe NFPsmore evenly.
4 EVALUATION
Wehaveimplemented eQualontopofDomainPro[ 77],resulting
in4.7KC#and1.0KJavaScriptSLoCaddedtoDomainPro. Toaid
ineQual’s evaluation, we also built a utility totaling an additional
1.0KC#and0.2KMATLAB SLoC, as detailedinSection 4.2.
We conductanalytical andempiricalevaluationsof eQual’star-
getedproblem scope ,usability,effectiveness infinding high-quality
solutions,and scalability ;andacontrolleduserstudyfurthertar-
getingeQual’s scope, usability, and effectiveness. We especially,
butnotexclusively,focuson eQual’scomparisontoGuideArch,the
state-of-the-art approach for exploring early architectural designs.
4.1eQual’sScope& Usability
Our usability evaluation measures how easy eQualis to apply in
practice. We present an analytical argument for eQual’s usabil-
ity and results of its empirical evaluation. We also illustrate that
eQual’sproblem scope matches GuideArch’s.
4.1.1 Analytical Argument. Section3.2discussed the questions
eQualasks ofarchitects. Letus assume that a system has Nvvari-
ation points and Npproperties. For each of them, eQualasks a
three-partquestion. Themaximumnumberoffieldentries eQual
requires an architect to make is thus 3 × (Nv+Np). Recall that
thearchitect has theoption ofnot answering some(orany) ofthe
questions.
1044eQual: InformingEarly DesignDecisions ESEC/FSE ’20, November8ś13,2020,VirtualEvent, USA
As discussed above, our analysis of Hadoop has relied on previ-
ously identified four critical NFPs [ 11,12]. Prior research suggests
thatthereareusually4ś6NFPsofinterestinasoftwareproject,and
rarely more than 10 [ 4]. Moreover, a recent study [ 80] showed that
thenumberofvariationpointsperHadoopversionrangedbetween
1and12[ 80]. Takingthelargestnumberofvariationpointsfora
singleHadoopversionandthefourproperties,anarchitectusing
eQualwouldhavetoprovidenomorethan48answerstoexplore
the 4-dimensionaldecision spaceofat least212systemvariants.
Notably,eQualassumesneitherthat NFPscanbe rank-ordered
(unlike GuideArch [ 29] and its predecessor [ 56]), nor that archi-
tectscanprovidespecificfitnessfunctionsforthem(unlikeprior
work [81ś83]). Section 4.2will more formally define and discuss
fitness functions.
4.1.2 EmpiricalComparisontotheState-of-the-Art. Wemodeled
Hadoop in GuideArch. We considered other approaches, but found
them unsuitablefor directcomparison. Beyondapproaches already
discussedintheIntroduction,model-drivensolutions[ 31,40]target
design-spaceexploration,butrequiremanualspecificationofmodel-
transformation rules and tackle challenges such as finding the best
orchestrations of the rules. Several solutions for optimizing cyber-
physicalsystems[ 6,41,59]relyonsimulationsbutareintimately
tied to the underlying domain. For example, AutoFocus [ 10,41]
targets reactive systems,in whichmodelingelements are domain-
specificabstractions(e.g.,electroniccontrolunit)andconstraints
are linked to the domain’s semantics (e.g., traffic-light behavior).
As another example, OpenMDAO [ 35,59] numerically optimizes
designs of multidisciplinary systems suchas aircraft, and relies on
theavailabilityofmathematicalmodelsforpropertiessuchaslift,
thermodynamics, etc.
We compared eQualand GuideArch models in terms of num-
bers of field entries and time required to complete them. We
usedHadoopbecausethedetailsofthecasestudypublishedwith
GuideArch’sauthorsarenolongeravailable. GuideArchhelpsarchi-
tects make decisions using fuzzy math [ 93] to deal with uncertain-
tiesaboutsystemvariationpoints. GuideArchusesthree-pointesti-
mates: architectsmustprovide(1)pessimistic,(2)mostlikely,and(3)
optimistic values to describe the effects of their decisions on NFPs.
For instance, in the case of Hadoop’s Processing Power , for each
decision (e.g., using machines with 2GHz CPUs) architects have to
specifythe three valuesfor Utilization ,ExecutionTime ,andCost.
GuideArchdoesnotrequirethecreationofasystemmodel. How-
ever,GuideArch’susefulnessiscontingentontheaccuracyofits
inputs, which requires in-depth knowledge of the system’s domain
andbehavior. Itsauthorsacknowledgethat,evenforarchitectswho
areintimatelyfamiliar withasystem,itmaybechallengingtoac-
curately estimate, e.g., the pessimistic value of resource Utilization
or the most likely system Reliability . For this reason, GuideArch’s
authors recommend that architects obtain this information by ana-
lyzingpriordata,lookingatsimilarsystems,studyingmanufacturer
specifications, and consulting publications [ 29]. These are non-
trivial tasks,likely to rival the modelingeffortrequiredby eQual.
ThespecificationofNFPsinGuideArchissimilarto eQual. How-
ever, as discussed above, the specification of variation points is
different, which, in turn, impacts the modeling and analysis ofavailable options. GuideArch requires that all options be specified
discretely,andcannotexplore ranges.
Wehighlightanexperimentrepresentativeoftheside-by-side
use of the two techniques: We selected five options for each of
Hadoop’svariationpointsfromFigure 2,totaling25alternatives.
For example, instead of simply specifying the range 10ś100 for
Pool SizeÐwhich is allowed by eQualbut not by GuideArchÐwe
explicitly provided10, 25, 50,75, and100astheoptions. The next
stepwastospecifyhoweachdecisionaffectsthesystem’sNFPs. In
doingso,wehadtofillina25 ×12matrixinGuideArch. For eQual,
wehadtoanswer27questions: 3 ×5forthefivevariationpoints,
and 3×4 for the four NFPs. Overall, it took one of this paper’s
authors more than four hours to complete over 350 mandatory
fields in GuideArch. By contrast, it took the same author under six
minutesto answer the 27 questionsrequiredby eQual.
Thisdiscrepancyonlygrowsforlargerproblems(e.g.,morevari-
ationpointsormore optionswithinavariationpoint). In general,
ifTfisthenumberoffieldentriesinGuideArch, NPthenumberof
properties, NVthe number of variation points, and aithe number
ofalternatives for variation point vi,then
Tf=3NPNV/summationtext.1
i=1ai
The number of GuideArch field entries grows quadraticallyin the
number of properties and variation points. The number of field
entriesin eQualgrowslinearly: 3 ×(Nv+Np). Thisresultsinafoot-
printforeQualthatisordersofmagnitudesmallerthanGuideArch’s
when appliedto large systems.
4.2eQual’sScope& Effectiveness
Mostotherapproachesconcernedwithdesignquality(e.g.,[ 5,21,27,
58,77])focusonsinglevariantsanddonotexploredesign-decision
spaces(seeSection 5forfurtherdetails). Priorwork[ 28]hasshown
thatthosetechniquesthataidengineerswitharrivingateffective
designs (e.g., ArchDesigner [ 1]) underperform GuideArch in the
qualityoftheirtop-rankeddesigns. Forthesereasons,weevaluated
eQual’seffectivenessbydirectlycomparingitwithGuideArchas
theleadingcompetingapproach. Wethenseparatelyassessedthe
qualityof eQual’sresultsonsystemswithknownoptimalconfig-
urations, in the process further highlighting eQual’s scope. Our
results indicate that eQualproduces effective designs, of higher
qualitythancompeting work.
4.2.1 Head-to-Head Comparison with State-of-the-Art. BotheQual
andGuideArchuseknownoptimizationmethods. Theirabsolute
effectivenessisdifficulttodetermineasitrequiresthatthemodeled
systems’ ground-truth results be known, but we can compare their
effectiveness relative to one another.
Tothatend,weanalyzedtheHadoopmodelscreatedwith eQual
andGuideArchasdescribedinSection 4.1andcomparedthetop-
rankedvariantstheyreturned. Forexample,intheexperimenthigh-
lighted in Section 4.1, both tools produced Hadoop variants that
were equally reliable (94%), had equal machine utilization (99%),
and comparable cost (17 for GuideArch vs. 19 for eQual). How-
ever,eQual’stop-rankedvariantwasnearly7.5timesfasterthan
GuideArch’s (154s vs. 1,135s.). In fact, we observed that GuideArch
consistently selects variants with lower machine reliability but
higher redundancythanthoseselectedby eQual.
1045ESEC/FSE ’20, November8ś13,2020,VirtualEvent, USA Arman Shahbazian, Suhrid Karthik, YuriyBrun, andNenadMedvidovic
System Domain Var. Points Terms Size
Apache WebServer 11 9106
BDBC Berkeley DB C 9 10105
BDBJ Berkeley DB Java 6 8106
Clasp AnswerSetSolver 10 171015
LLVM CompilerPlatform 7 8107
AJStats Analysis Tool 3 4107
Figure 5: Systems used to evaluate eQual’s effectiveness.
Var. Points is number of variation points; Termsis number
oftermsinsystems’fitnessmodels; Sizeisnumberofdesign-
spacevariants.
We acknowledge that we are intimately familiar with eQual.
However, the author who performed the analysis has extensive ex-
periencewithGuideArch. Moreover,wehaveagoodunderstanding
ofHadoopand made everyeffort touseGuideArchfairly, consult-
ing its authors regularly. Ultimately, the quality of the variants
GuideArchrecommendsdependsheavilyonthearchitect’sability
to predict the effects of thedesign decisionson the system’s NFPs,
anon-trivialtaskregardless ofone’sfamiliarity withGuideArch.
4.2.2 Evaluation on Systems with Known Optimal Designs. We fur-
ther evaluated eQual’s effectiveness against known fitness models
of six real-world systems, summarized in Figure 5. Fitness mod-
els describe the NFPs of a system using its variation points and
their interactions. These models were obtained by Siegmund et
al. [81,82] and shown to accurately predict the NFPs of highly
configurable systems. The fitness models aim to detect interac-
tionsamongoptions(orfeatures)andevaluatetheirinfluenceon
thesystem’snon-functionalattributes. Eachhas beenobtained by
numerous measurements of different variants of a software sys-
tem. Wedecidedtousethesemodelsbecausetheyareanalogous
to our objective in eQual, despite being applied to systems that
arealreadydeployed. Furthermore,thesubjectsystems’resulting
decision spaces rangefrom 100Kto 1quadrillion variants, making
themattractive for testing eQual’srange ofapplicability.
A fitness model is a function from variants to a fitness mea-
surement Ω:C→R, where fitness canbe an aggregationofany
measurableNFPthatproducesinterval-scaleddata. Themodelisde-
scribedasasumoftermsovervariationoptionvalues. Themodel’s
individualtermscanhavedifferentshapes,suchas n·c(X),n·c(X)2
orn·c(X)·/radicalbig
c(Y)[81]. Forillustration,aconfigurableDBMSwith
optionsencryption(E),compression(C),pagesize(P),anddatabase
size (D) mayhave the following fitness model:
Ω(c)=50+20·c(E)+15·c(C)−0.5·c(P)+2.5·c(E)·c(C)·c(D)
In general, the fitness models are ofthe following form:
Ω(c)=β0+/summationdisplay.1
i..j∈OΦ(c(i)..c(j))
β0representsaminimumconstantbasefitnesssharedbyallvariants.
Eachtermoftheform Φ(c(i)..c(j))capturesanaspectoftheoverall
fitness ofthe system.
Becauseonlyaggregatefitnessmodelswereavailabletous,with-
outlossofgenerality,wetreatedeachtermasanindividualNFP
ofagiven system,andtranslatedits coefficients into eQual’scoef-
ficients. Then, using the formula of each term, we generated theRandom Edge-Case
System Default Mean σMean σ
Apache 0.264 0.3110.1460.8990.163
BDBC 0.763 0.5640.3250.9830.035
BDBJ 0.182 0.5170.4081.0000.000
Clasp 0.323 0.3520.1740.8590.179
LLVM 0.253 0.2350.2340.9020.219
AJStats 0.856 0.7800.2690.9630.048
Overall 0.440 0.4600.5920.9340.107
Figure 6: Comparison between the two seeding strategies
employedby eQual,andthequalityofsolutionscommonly
selected by architects ( Default, from [81].)Meanlists the
mean fitnessscore.
correspondingconstanttime-seriesrepresentingtheterm. These
time-series were subsequently passed to eQualfor exploration. To
measureeQual’seffectiveness,wenormalizedeachvariant’sfitness
and calculated the fitness of the best variant found by eQualusing
the ground-truth fitness models. We then calculated that variant’s
distancefromtheglobaloptimum. Wecallthisthe OptimalProx-
imity. These steps were accomplished via an extension to eQual
totaling1KC#SLoCandanadditional0.2KMATLABSLoCtotune
andvisualizethe resulting eQualmodels.
Figures6and7depicttheresultsofapplying eQualonoursix
subjectsystemsusingthetwostrategiesdiscussedinSection 3.3:
random seeding and edge-case seeding. Figure 6compares eQual’s
two strategies against the solutions yielded by using the default
values suggested by the six systems’ developers [ 81]. These results
wereobtainedbysettingthecross-overratioforthegeneticalgo-
rithmto 0.85andthemutation rateto0.35,using 4generationsof
size200. Thesehyper-parameterswereobtainedovernearly30,000
testexecutions,byusinggrid-searchtofindthemostsuitablepa-
rameters on average. The results in Figure 6show that, in most
cases,eventhepurelyrandomseedingstrategyfor eQualisatleast
aseffectiveasthedefaultvaluessuggestedbythedevelopers. On
the other hand, the edge-case strategy finds superior variants that
onaverageexhibitover93%oftheglobaloptimum. Figure 7pro-
videsadditional detail, showing thedistribution of running eQual
onthesixsubjectsystems100timesusingtheedge-casestrategy,
withgenerationsizesof50,100,and200. Notethat,withalarger
numberofgenerations, eQualisabletoproducevariantsthat,on
average,tendtomatchthereportedglobaloptimumforeachsys-
tem; in the case of Clasp, the lone exception, the quality of eQual’s
suggestedvariantwasstillover 90%of the globaloptimum.
4.3 Scope,Usability,& Effectiveness User Study
We conducteda within-subjectcontrolledexperiment with 15par-
ticipants using eQualand GuideArch to measure (1) whether users
weremorelikelytoproducehigher-qualitydesignsusingGuideArch,
eQual, or without any toolsupport,and (2)whether the userspre-
ferredusing GuideArch, eQual,orneither tool.
Allparticipantshadindustrialexperiencedevelopingsoftware
systems,workingforcompaniessuchas,Google,Facebook,Sam-
sung, and Cloudera. On average, the participants had 11 years
of programming experience (minimum 4, maximum 24) and 6.5
1046eQual: InformingEarly DesignDecisions ESEC/FSE ’20, November8ś13,2020,VirtualEvent, USA
Figure7: OptimalProximity distributionofthebestvariantgeneratedby eQualusinggenerationsizesof50,100,and200. Each
box plot comprises100 executionsof eQual’sexploration function usingtheedge-casestrategy.
years of software design experience (minimum 1, maximum 15).
Additionally, 60% of participants work on software design tasks
łsomewhat regularlyž or łalwaysž. Two-thirds of participants re-
ported that they use models to describe their software łsomewhat
regularlyžorłalwaysž.
Each participant was asked to work with three systems selected
fromthesetinFigure 5: ApacheHTTPD(anHTTPserver),Berkeley
DBC(anembeddeddatabaselibrary),andLLVM(acompilerinfras-
tructure). For each system, participants were given a performance
objective and variation points for which they had to determine the
optimaloptions. Theparticipantswereprovidedwithdocuments
thatdescribedeachsystem,itsvariationpointsunderconsideration,
andonlineresourceswithmore information aboutthe system.
Each participant took part in three treatments: using no tool
(thecontrol),GuideArch,and eQual. Theorderoftreatmentswas
randomized,aswastheassignmentoftreatmentstosubjectsystems.
Participantsweregivenatleastonehourtocompletethestudy,but
wereallowedtokeepworkinguntiltheyfinished. Theyanswered
questions about each treatment as they progressed through the
experiment. At the end, participants were asked to compare the
differenttreatments.
In their assessment of eQual, we provided the participants with
screenshotstodescribeaspectsofthesystemmodelsthatdepended
on DomainPro [ 77]. The objective was to minimize the impact
on the study’s results of DomainPro’s details incidental to eQual
(e.g., metamodeling features). For GuideArch, participants used the
online version of the tool [ 37]. Finally, in the control treatment,
they performedthe tasksmanually.
We compared the top-ranked solution for each treatment sub-
mitted by the participants. We normalized the results to determine
their distance from the respective global optimum, resulting in
a quality score between 0 and 1. We compared the distributionsof the qualities of the designs produced for the three treatments.
The median resulting system quality was 0.872 (mean 0.755) for
theGuideArchgroup, 1.0(mean0.999) for eQual, and0.879(mean
0.719) forcontrol. We appliedthe Mann-WhitneyU Testand found
the difference between median system qualities for GuideArch and
eQualto be statistically significant ( p=0.00014) and the effect
size large ( r=0.70). Likewise, the difference between median
systemqualitiesforthecontrolgroupand eQualwasstatistically
significant ( p<0.00001) andthe effectsize large ( r=0.85).
ParticipantsreportedconfidenceintheirsolutionsonaLikert
scale [53], from Very Unsure (1) to Very Confident (5). eQualusers
had a mean confidence of 4.07, GuideArch users 3.07, and con-
trol group 3.14. Student’s t-tests pairwise comparing eQualvs.
GuideArchand eQualvs.controlgroupshowedstatisticalsignifi-
cance,withrespective p valuesof 0.03and0.02.
Participantsalsoratedtwousabilityaspectsofeachtreatment
on a Likertscale. They rated each treatment’s required effort, rang-
ing from Very Intensive (1) to Very Easy (5). The mean scores
fortheeQual,GuideArch,andcontrolgroupswere4.00,2.46,and
2.07, respectively. Student’s t-tests pairwise comparing eQualvs.
GuideArchand eQualvs.controlgroupshowedstatisticalsignifi-
cance, with respective p values of 0.0028 and 0.00037. Additionally,
participants rated the user friendliness of each treatment, rang-
ing from Very Challenging (1) to Very Friendly (5). The mean
scoresforthe eQual,GuideArch,andcontrolgroupswere4.53,2.67,
and 2.71, respectively. Again, Student’s t-tests pairwise compar-
ingeQualvs.GuideArchand eQualvs.thecontrolgroupshowed
statistical significance, with respective p values of 0.00021 and
0.0012.
Theseresultsshowthatparticipantssawvalueinusing eQual
andfoundits interfacemore intuitive thanGuideArch’s.
1047ESEC/FSE ’20, November8ś13,2020,VirtualEvent, USA Arman Shahbazian, Suhrid Karthik, YuriyBrun, andNenadMedvidovic
4.4eQual’sScalability
Toevaluate eQual’sscalability,weusedGoogleComputeEngine
(GCE) with Hadoop. We created 16 n1-standard-1 nodes (the most
basic configuration available in GCE, with 1 vCPU and 3.75 GB
RAM)assimulationnodes,andasinglen1-standard-2node(2vCPU
and 7.5 GB RAM) as the central controller node. All nodes were
located in Google’s us-central1-f datacenter. We used the variation
pointsandNFPsdescribedinSection 3.
NumberofNodes. Weevaluated eQual’sobservedspeed-upwhen
increasingthenumberofsimulationnodes. Weusedthegeneral
genetic algorithmfor 8generations and thegeneration sizeof256
variants, totaling 2,048 variants. We did this with 2, 4, 8, and 16
nodes, and for three values of the Computation Size variation point
(denotedwithCinFigure 8). AsshowninFigure 8(a),theexecution
timewasinverselyproportionaltothenumberofnodes,suggesting
thatourapproachcanbescaledupoptimallybyaddingmorenodes.
Using more powerful nodes can further speed up the computation.
NotethateachdatapointinFigure 8(a)consistsof2,048simulations.
Overall,we simulatedmore than24,500designvariants.
Number of Events. We also measured the impact of increasing
the number of events generated during a simulation. This is in-
dicative of how well eQualperforms on larger models. The total
numberofeventsgeneratedinHadoopisnondeterministic. How-
ever, based on the characteristics of the model, we hypothesized
thatincreasingthe ComputationSize shouldincreasethenumberof
eventsroughlylinearlyifothervariationpointsremainunchanged.
We evaluated this hypothesis by using the average sizes of the
time-seriesobjectfilesgeneratedduringsimulationasareasonable
proxyforthenumberofevents. Figure 8(b)showsthat,onaverage,
the total number of events is directly proportional to Computation
Size. Coupledwiththeperformancethat eQualdemonstratedfor
the same values of Computation Size (Figure8(a)), this is indicative
ofeQual’sscalability as numbers ofsimulation eventsgrow.
Number of Variants. Finally, we studied eQual’s performance as
the numbersofdesign variantsincrease. We modifiedthe genetic
algorithm configurations to use five generation sizes: 16, 32, 64,
128, and 256. For each size, we ran eQualfor 8 generations, on 4, 8,
and 16nodes. Figure 8(c)showsthat eQualis abletoanalyzeover
2,000designvariantsin ∼120min. on4nodes,withaspeed-upthat
islinearinthe number ofnodes, downto ∼30 min. on16 nodes.
4.5 Threatsto Validity
WhileeQual’sevaluationfindsitiseasytouse,scaleswell,hasa
small footprint, and finds accurate solutions, we take several steps
to mitigate possible threatsto our work’svalidity.
The controlled experiment had two potential validity threats
thatarosefrompracticalconsiderations. Webelievethesedonot
impactthedesignqualityorusabilityresults. Thefirstconsidera-
tion is the participants’use of existing ground-truth models, rather
than creating their own. This was necessary to enable objective
comparisonbetweentheuser-generatedsolutions. Moreover,these
models were produced by a third party [ 81,82]. The second threat
stemmed from having to execute the study in a limited amount
of time. Recall from Section 4.3that we relied on screenshots of
previously developed architectural models to explain the full scope
ofeQual(notablyitsDomainPromodelingsubstrate). Furthermore,
C=500 C=1000 C=2000
CRPSXWaWiRQ Si]e (C)050100 SiPXOaWiRQ DaWa (MB)
02000400060008000
0 500 1000 1500 2000TRWaO E[HcXWLRQ TLPH
NXPbHU RI AOWHUQaWLYHVQ=4 Q=8 Q=16
Number of AlternativesTotal Execution Time (s)05000100001500020000
2 4 8 16TRWaO E[HFXWLRQ TLPH
NXPbHU RI SLPXOaWLRQ NRGHVC=500 C=1000 C=2000
Number of Simulation NodesTotal Execution Time (s)
(c)(b)(a)Total Execution Time (s)   Total Execution Time (s)   
Simulation Data (MB)  
Computation Size (C)   Number of Simulation Nodes
Number of Alternatives  
Figure 8: eQual’s scalability with number of (a) simulation
nodes,(b)events,and(c) variants.
we summarized subject systems to enable participants to under-
stand thesalient aspectsofeachsystemrelativelyquickly. Finally,
weaskedtheparticipantstoconsideronlyasingleNFP.Webelieve
that the cumulative effect of thus simplified scenarios may have
workedinfavorofthecontrolgroups. At thesametime,weposit
that the net effect on eQualand GuideArch was mostly neutral:
the reduction in modeling effort, which favored eQual, is balanced
out by providing a system łdigestž and focusing on a single NFP,
favoring GuideArch.
Twoconstituentpartsof eQualhelpmitigatethethreatstoits
construct validity : (1) the dynamic analysis of system designs by
simulationand(2)creatingassessmentmodelsbasedonDTW.In
thepast,thesetwosolutionshavebeenextensivelyusedtogreat
success. Discreteeventsimulationshavebeenusedinaplethoraof
domains (e.g., avionics, robotics, healthcare, computer networks,
1048eQual: InformingEarly DesignDecisions ESEC/FSE ’20, November8ś13,2020,VirtualEvent, USA
finance, etc.) [ 84,86], and the bedrock of our assessment mod-
els, DTW, is so prevalent that it is łdifficult to overstate its ubiq-
uityž [23,70]. DTW also subsumes Euclidean distance [ 23] as a
special case [ 70], which increases eQual’s range of applicability.
The threat to the external validity of our work is mitigated by
the incorporation of an MDA-based approach (namely, Domain-
Pro). MDAsolutionshavebeenshowntobesufficientlyrobustand
scalable,andare widely usedinresearchandindustry [ 42,47].
5 RELATED WORK
eQualbuilds on a large body or work that has explored support for
making design decisions via static or dynamic analysis of software
models [45,69]. Static analyses (e.g., [ 8,34,60]) tend to require
architectstodevelopcomplexmathematicalmodels,imposingsteep
learningcurves,modelingeffort,andlimitsonsystemscalability.
Depending on the mathematical models they rely on (e.g., Markov
chains[33],eventcalculi[ 48],orqueueingnetworks[ 9]),thesetech-
niquesareconfinedtospecifickindsofsoftwaresystemmodels[ 2].
While they come with shortcomings of their own (e.g., false
negatives, long execution times), dynamic analysis techniquesÐi.e.,
architecturalmodel simulations [27,55]Ðaremorecapableofcap-
turingthenondeterminismreflectiveofreality[ 46]. Despitenotable
efforts, especially in domains with well understood properties (e.g.,
stream-based systems [ 22], reactive hybrid systems [ 10,41,87],
numericaloptimizationofaircraftdesigns[ 35,59])simulationsof
softwarearchitectural models[ 57,91]have notbeenemployedas
widelyasstaticanalyses[ 2],foratleastfourreasons. First,creating
simulatable system design models is difficult[27]. Second, running
simulations is time consuming, mandating that scalability be ex-
plicitlyaddressed[ 68]. Third,quantitativeassessmentofvariants
is acomplexcomputational problem because of the involved trade-
offs [61]. Finally, analysis and understanding of massive datasets
may be necessary to assess system behavior. eQualhas built-in
features to explicitly dealwitheachoftheseproblems.
Rule-based approaches identify problems in a software model
and rules to repair them. MOSES uses stepwise refinement and
simulation for performance analysis [ 19]. ArchE helps meet the
quality requirements during thedesign phase by supporting modi-
fiabilityandperformanceanalysis[ 60]. DeepCompassreliesona
Paretoanalysistoresolveconflictinggoalsofperformanceandcost
between different embedded-system architecture candidates [ 7].
PUMA facilitates communication between systems designed in
UML and NFP prediction tools [ 92]. FORMULA aims to reduce the
design-space size by removingcandidates based ona user-defined
notionofdesignequivalence[ 44]. Unlike eQual,eachoftheseap-
proachesislimitedbyitspredefinedrulesandcannotexplorethe
complete designspace.
Metaheuristic approaches treat architecture improvement as an
optimization problem. ArcheOpterix [ 2], PerOpteryx [ 49], and
DeSi[56] useevolutionary algorithms to optimize system deploy-
ment with respect to quality criteria. PerOpteryx offers predefined
degreesoffreedomforoptimizingdeployment. Theoptimization
strategy PerOpteryx uses can be incorporated into eQual, with
allowances for eQual’s broader scope. AQOSA supports modeling
based on AADL and performance analysis tools, and evaluates de-
sign alternatives based on cost, reliability, and performance [ 52].SASSYtargetsSOAs,selectingservicesandapatternapplicationto
fulfillqualityrequirements[ 63]. Metaheuristicsimulationhasbeen
usedtoreconfigurealegacyapplicationforthecloud[ 32]. Linear
programminghasbeen usedtofind minimum-costconfigurations
onthecloud[ 3]. DESERTexploresdesignalternativesbymodel-
ing variations in a tree and using Boolean constraints to eliminate
infeasible solutions [ 26]. DESERT-FD automates constraint genera-
tion and design exploration [ 26]. GDSE uses meta-programming
of domain-specific design exploration problems and expresses con-
straints for solvers to generate solutions [ 72].eQualuses meta-
heuristic search to find solutions within large design spaces, but
focuses onNFPsandloweringthe burden onarchitects.
Software ProductLines(SPLs) supportconfiguringsoftware ar-
tifacts for a set of requirements [ 18,39,74,83]. Unlike SPLs, eQual
neither adds nor removes features in a product. SPLs can use ge-
neticalgorithmstooptimizefeatureselection[ 38],butthisrequires
developerstocreateobjectivefunctionstomeasurevariants’fitness.
Optimizingconfigurablesystems,despitebeingaimedatalready
deployed systems, has clear relations to eQual. Among these tech-
niquesweusedthestudiesbySiegmundetal.[ 81,82]toevaluate
theeffectivenessof eQual. Ohetal.[ 67],andSayyadetal.[ 73]have
devised techniquesto more efficientlyexplore the spaceof system
configurations,whichcancomplement eQual’sexplorationstrate-
gies. SPLscanalsobemodeledasacombinationofacoremodel,
representing one variant (product) and a set of ∆-models for the
differences with other variants [ 75].∆-modeling is a way to model
feature variability, whereas eQualemploys search-based strategies
on an underlying architectural model of a system to explore its
designvariants.
6 CONTRIBUTIONS
Ourworkprovidesanimportantstepin narrowingthechasmbe-
tween the needed and available support for making and evaluating
earlyarchitecturaldesigndecisions. Ourapproach, eQual,guides
architectsinmakinginformedchoices,byquantifyingtheconse-
quencesoftheirdecisionsthroughoutthedesignprocess. Critically,
eQualprovides structure and automated support to the architects’
alreadyexisting tasks.eQualdoessowhilebeingabletonavigate
efficientlythroughmassivedesignspaces. eQualisableto simul-
taneously match orbetter the state-of-the-artin terms of four key
dimensions: problem scope, usability, effectiveness, and scalability.
Whileourresultsshowpromise,furtherworkisneededtoim-
proveeQual’spracticaleffectiveness. Thusfar,wehaveassumed
thatarchitectsknowtherelativeimportanceofNFPsintheirsys-
tems. Our goal is to actively guide architects in design hot-spot
identification and to help their understanding of the NFPs’ relative
importance. Moreover, combining eQualwith software architec-
ture recovery will extendits applicability to existing systems with
legacyarchitectures. Oursuccessfulapplicationof eQualtosystems
withknownfitness models [ 81,82]supports this idea’s viability.
ACKNOWLEDGMENTS
This work is supported by the U.S. National Science Foundation
undergrantsCCF-1453474,CCF-1618231,CCF-1717963,andCNS-
1823354, and by the U.S. Office of Naval Research under grant
N00014-17-1-2896.
1049ESEC/FSE ’20, November8ś13,2020,VirtualEvent, USA Arman Shahbazian, Suhrid Karthik, YuriyBrun, andNenadMedvidovic
REFERENCES
[1]TariqAl-Naeem,IanGorton,MuhammedAliBabar,FethiRabhi,andBoualemBe-
natallah. 2005. A quality-driven systematic approach for architecting distributed
software applications. In International Conference on Software Engineering (ICSE) .
244ś253.
[2]Aldeida Aleti, Barbora Buhnova, Lars Grunske, Anne Koziolek, and Indika Mee-
deniya.2013.Softwarearchitectureoptimizationmethods: Asystematicliterature
review.IEEE Transactions onSoftwareEngineering (TSE) 39,5 (2013), 658ś683.
[3]Danilo Ardagna, Giovanni Paolo Gibilisco, Michele Ciavotta, and Alexander
Lavrentev.2014. Amulti-modeloptimizationframeworkforthemodeldriven
design of cloud applications. In Search-Based Software Engineering . Springer,
61ś76.
[4]JagdishBansiyaandCarlGDavis.2002. Ahierarchicalmodelforobject-oriented
design quality assessment. IEEE Transactions on Software Engineering (TSE) 28, 1
(2002), 4ś17.
[5]SteffenBecker,HeikoKoziolek,andRalfReussner.2009. ThePalladiocomponent
modelformodel-drivenperformanceprediction. JournalofSystemsandSoftware
82,1 (2009), 3ś22.
[6]TorstenBlochwitz,MartinOtter,MartinArnold,ConstanzeBausch,Christoph
Clauß,HildingElmqvist,AndreasJunghanns,JakobMauss,ManuelMonteiro,
Thomas Neidhold, Dietmar Neumerkel, Hans Olsson, Jörg-Volker Peetz, and Su-
sannWolf.2011. Thefunctionalmockupinterfacefortoolindependentexchange
ofsimulationmodels.In InternationalModelicaConference .Dresden,Germany,
105ś114. https://doi.org/10.3384/ecp11063105
[7]Egor Bondarev, Michel RV Chaudron, and Erwin A de Kock. 2007. Exploring
performancetrade-offsofaJPEGdecoderusingtheDeepCompassframework.
InInternationalWorkshop onSoftwareand performance . 153ś163.
[8]BasBoone,SofieVanHoecke,GregoryVanSeghbroeck,NielsJoncheere,Viviane
Jonckers,FilipDeTurck,ChrisDevelder,andBartDhoedt.2010. SALSA:QoS-
aware load balancing for autonomous service brokering. Journal of Systems and
Software83,3 (2010), 446ś456.
[9]AleksandrAlekseevichBorovkov.1984. Asymptoticmethodsinqueuingtheory .
John Wiley& Sons.
[10]ManfredBroy,JorgeFox,FlorianHölzl,DagmarKoss,MarcoKuhrmann,Michael
Meisinger, Birgit Penzenstadler, Sabine Rittmann, Bernhard Schätz, Maria
Spichkova,andDorisWild.2008. Service-OrientedModelingofCoCoMEwith
FocusandAutoFocus.In TheCommonComponentModelingExample ,Andreas
Rausch,RalfReussner,RaffaelaMirandola,andRaffaelaPlášil(Eds.).Springer-
Verlag, 177ś206. https://doi.org/10.1007/978-3-540-85289-6_8
[11]Yuriy Brun, George Edwards, Jae young Bang, and Nenad Medvidovic. 2011.
Smart redundancyfor distributed computation. In International Conferenceon
DistributedComputingSystems(ICDCS) (20ś24).Minneapolis,MN,USA,665ś676.
https://doi.org/10.1109/ICDCS.2011.25
[12]Yuriy Brun, Jae young Bang, George Edwards, and Nenad Medvidovic. 2015.
Self-Adapting Reliability in Distributed Software Systems. IEEE Transactions on
SoftwareEngineering(TSE) 41,8(August2015),764ś780. https://doi.org/10.1109/
TSE.2015.2412134
[13]SaheedA.BusariandEmmanuelLetier.2017. RADAR:ALightweightToolfor
Requirements and Architecture Decision Analysis. In Proceedings of the 39th
InternationalConferenceonSoftwareEngineering(ICSE) .BuenosAires,Argentina,
552ś562. https://doi.org/10.1109/ICSE.2017.57
[14]Yair Censor. 1977. Pareto optimality in multiobjective problems. Applied Mathe-
matics & Optimization 4,1 (1977), 41ś59.
[15]Jane Cleland-Huang, Raffaella Settimi, Oussama BenKhadra, Eugenia Berezhan-
skaya,andSelviaChristina.2005. Goal-centrictraceabilityformanagingnon-
functional requirements. In International Conference on Software Engineering
(ICSE). 362ś371.
[16]Jane Cleland-Huang, Raffaella Settimi, Xuchang Zou, and Peter Solc. 2007. Auto-
matedclassification ofnon-functional requirements. Requirements Engineering
12,2 (2007), 103ś120.
[17]PaulClements,RickKazman,andMarkKlein.2001. EvaluatingSoftwareArchi-
tectures: Methodsand CaseStudies . Addison-WesleyProfessional.
[18]Thelma Elita Colanzi, Silvia Regina Vergilio, Itana Gimenes, and Willian Nalepa
Oizumi. 2014. A search-based approach for software product line design. In
InternationalSoftwareProductLineConference , Vol. 1.237ś241.
[19]VittorioCortellessa,PierluigiPierini,RominaSpalazzese,andAlessioVianale.
2008. MOSES: MOdeling Software and platform architEcture in UML 2 for
Simulation-based performance analysis. In Quality of Software Architectures.
Modelsand Architectures . Springer, 86ś102.
[20]Marco D’Ambros, Alberto Bacchelli, and Michele Lanza. 2010. On the impact of
design flaws on software defects. In International Conference on Quality Software
(QSIC). 23ś31.
[21]EricDashofy,HazelAsuncion,ScottHendrickson,GirishSuryanarayana,John
Georgas,andRichardTaylor.2007. Archstudio4: Anarchitecture-basedmeta-
modelingenvironment.In InternationalConferenceonSoftwareEngineering(ICSE)
Demotrack . 67ś68.
[22]Pablo de Oliveira Castro, Stéphane Louise, and Denis Barthou. 2010. Reduc-
ing memory requirements of stream programs by graph transformations. InInternational Conference on High Performance Computing and Simulation (HPCS) .
171ś180.
[23]Hui Ding, Goce Trajcevski, Peter Scheuermann, Xiaoyue Wang, and Eamonn
Keogh.2008. Queryingandminingoftimeseriesdata: experimentalcomparison
of representations and distance measures. Proceedings of the VLDB Endowment 1,
2 (2008), 1542ś1552.
[24]Christoph Dorn, George Edwards, and Nenad Medvidovic. 2012. Analyzing
design tradeoffs in large-scale socio-technical systems through simulation of
dynamiccollaborationpatterns.In OTMConfederatedInternationalConferences
łOn the MovetoMeaningfulInternet Systemsž . 362ś379.
[25]GeraldSDoyle.2011. Amethodologyformakingearlycomparativearchitecture
performanceevaluations . Ph.D. Dissertation. GeorgeMasonUniversity.
[26]BrandonKEames,SandeepKNeema,andRohitSaraswat.2010.Desertfd: Afinite-
domainconstraintbasedtoolfordesignspaceexploration. DesignAutomation
for EmbeddedSystems 14,1 (2010), 43ś74.
[27]George Edwards, Yuriy Brun, and Nenad Medvidovic. 2012. Automated analysis
and code generation for domain-specific models. In Joint Working IEEE/IFIP
ConferenceonSoftwareArchitecture(WICSA)andEuropeanConferenceonSoftware
Architecture(ECSA) . 161ś170.
[28]NaeemEsfahani.2014. Managementofuncertaintyinself-adaptivesoftware . Ph.D.
Dissertation. GeorgeMasonUniversity.
[29]NaeemEsfahani,SamMalek,andKavehRazavi.2013. GuideArch: Guidingthe
exploration of architectural solution space under uncertainty. In International
Conference onSoftwareEngineering (ICSE) . 43ś52.
[30]Mahdi Fahmideh and Ghassan Beydoun. 2019. Big data analytics architecture
design Ð An application in manufacturing systems. Computers & Industrial
Engineering 128(2019), 948ś 963. https://doi.org/10.1016/j.cie.2018.08.004
[31]MartinFleck,JavierTroya,andManuelWimmer.2015. Marryingsearch-based
optimizationandmodeltransformationtechnology.In NorthAmericanSearch-
BasedSoftwareEngineering Symposium(NasBASE) . Elsevier, 1ś16.
[32]SörenFrey,FlorianFittkau,andWilhelmHasselbring.2013. Search-basedgenetic
optimization for deployment and reconfiguration of software in the cloud. In
InternationalConference onSoftwareEngineering (ICSE) . 512ś521.
[33] WalterR Gilks. 2005. Markov chainmonte carlo . WileyOnlineLibrary.
[34]Swapna S Gokhale. 2004. Software application design based on architecture, reli-
abilityand cost.In InternationalSymposiumonComputers andCommunications
(ISCC), Vol. 2.
[35]JustinGray,KennethMoore,andBretNaylor.2010. OpenMDAO:AnOpenSource
Framework for Multidisciplinary Analysis and Optimization. In AIAA/ISSMO
Multidisciplinary Analysis Optimization Conference .https://doi.org/10.2514/6.
2010-9101
[36]Lars Grunske,Peter Lindsay, EgorBondarev,YiannisPapadopoulos,andDavid
Parker. 2007. An outline of an architecture-based method for optimizing de-
pendability attributes of software-intensive systems. In Architecting Dependable
SystemsIV . Springer, 188ś209.
[37]GuideArch V1.0 2012. GuideArch V1.0. http://mason.gmu.edu/~nesfaha2/
Projects/GuideArch/ .
[38]JianmeiGuo,JulesWhite,GuangxinWang,JianLi,andYinglinWang.2011. A
geneticalgorithmforoptimizedfeatureselectionwithresourceconstraintsin
softwareproductlines. JournalofSystemsandSoftware 84,12(2011),2208ś2221.
[39]SveinHallsteinsen,MikeHinchey,SooyongPark,andKlausSchmid.2008. Dy-
namicsoftwareproductlines. Computer 41,4 (2008).
[40]ÁbelHegedüs,ÁkosHorváth,andDánielVarró.2015. Amodel-drivenframework
forguideddesignspaceexploration. AutomatedSoftwareEngineering 22,3(2015),
399ś436.
[41]FlorianHölzlandMartinFeilkas.2010. 13AutoFocus3ÐAScientificToolProto-
type for Model-Based Development of Component-Based, Reactive, Distributed
Systems.In Model-BasedEngineeringofEmbeddedReal-TimeSystems .Springer
Berlin Heidelberg, Dagstuhl, Germany, 317ś322. https://doi.org/10.1007/978-3-
642-16277-0_13
[42]John Hutchinson, Jon Whittle, Mark Rouncefield, and Steinar Kristoffersen. 2011.
EmpiricalassessmentofMDEinindustry.In InternationalConferenceonSoftware
Engineering (ICSE) . 471ś480.
[43]IBM. [n.d.]. IBM Rationale Rhapsody. http://www-03.ibm.com/software/
products/en/ratirhapfami .
[44]EunsukKang,EthanJackson,andWolframSchulte.2011. AnApproachforEf-
fectiveDesignSpaceExploration.In FoundationsofComputerSoftware.Modeling,
Development, and Verification of Adaptive Systems , Radu Calinescu and Ethan
Jackson(Eds.).SpringerBerlin Heidelberg, Berlin, Heidelberg, 33ś54.
[45]RickKazman,JaiAsundi,andMarkKlein.2001.Quantifyingthecostsandbenefits
of architectural decisions. In International Conference on Software Engineering
(ICSE). 297ś306.
[46]W David Kelton and Averill M Law. 2000. Simulation modeling and analysis .
McGrawHillBoston.
[47]Anneke G Kleppe, Jos Warmer, Wim Bast, and MDA Explained. 2003. The model
drivenarchitecture: practiceandpromise . Addison-WesleyLongmanPublishing
Co., Inc.,Boston, MA.
1050eQual: InformingEarly DesignDecisions ESEC/FSE ’20, November8ś13,2020,VirtualEvent, USA
[48]RobertKowalskiand MarekSergot. 1989. Alogic-based calculusofevents. In
Foundations of knowledge base management . Springer BerlinHeidelberg, 23ś55.
[49]Anne Koziolek. 2014. Automated improvement of software architecture models for
performanceand other qualityattributes . Vol. 7. KITScientific Publishing.
[50]Emmanuel Letier, David Stefan, and Earl T. Barr. 2014. Uncertainty, Risk, and
InformationValueinSoftwareRequirementsandArchitecture.In International
Conference on Software Engineering (ICSE) . Hyderabad, India, 883ś894. https:
//doi.org/10.1145/2568225.2568239
[51]Daniel R. Levinson. 2014. An Overview Of 60 Contracts That Contributed To
The Development And Operation Of The Federal Marketplace, OEI-03-14-00231.
http://oig.hhs.gov/oei/reports/oei-03-14-00231.pdf .
[52]Rui Li, Ramin Etemaadi, Michael TM Emmerich, and Michel RV Chaudron.
2011. An evolutionary multiobjective optimization approach to component-
based software architecture design. In Congress on Evolutionary Computation
(CEC). 432ś439.
[53]RensisLikert.1932. Atechniqueforthemeasurementofattitudes. Archivesof
psychology (1932).
[54]FMSLukeChung.2013. Healthcare.govisaTechnologicalDisaster. http://goo.
gl/8B1fcN .
[55]JiefeiMa, FranckLe,AlessandraRusso,andJorgeLobo.2016. DeclarativeFrame-
workforSpecification,SimulationandAnalysisofDistributedApplications. IEEE
Transactions onKnowledgeand Data Engineering 28,6 (2016), 1489ś1502.
[56]Sam Malek, Nenad Medvidovic, and Marija Mikic-Rakic. 2012. An extensible
frameworkforimprovingadistributedsoftwaresystem’sdeploymentarchitec-
ture.IEEE Transactions onSoftwareEngineering (TSE) 38,1 (2012), 73ś100.
[57]Marzio Marseguerra, Enrico Zio, and Luca Podofillini. 2007. Genetic algorithms
andMonteCarlosimulationfortheoptimizationofsystemdesignandoperation.
InComputationalIntelligenceinReliability Engineering . Springer, 101ś150.
[58]AnneMartens,HeikoKoziolek,SteffenBecker,andRalfReussner.2010. Auto-
matically improve software architecture models for performance, reliability, and
costusingevolutionaryalgorithms.In InternationalConferenceonPerformance
Engineering (WOSP/SIPEW) . 105ś116.
[59]JoaquimR.R.A.MartinsandAndrewB.Lambe.2013. Multidisciplinarydesign
optimization: A surveyof architectures. AIAA Journal 51,9 (2013).
[60]JohnDMcGregor,FelixBachmann,LenBass,PhilipBianco,andMarkKlein.2007.
Usingarcheintheclassroom: Oneexperience . TechnicalReport.DTICDocument.
[61]GianantonioMe,CoralCalero,andPatriciaLago.2016. Architecturalpatterns
and quality attributes interaction. In IEEE Workshop on Qualitative Reasoning
about SoftwareArchitectures(QRASA) .
[62]Nenad Medvidovic and Richard N Taylor. 2000. A classification and comparison
frameworkforsoftwarearchitecturedescriptionlanguages. IEEETransactionson
SoftwareEngineering (TSE) 26,1 (2000), 70ś93.
[63]Daniel A Menascé, John M Ewing, Hassan Gomaa, Sam Malex, and João P Sousa.
2010. Aframeworkforutility-basedserviceorienteddesigninSASSY.In Joint
WOSP/SIPEW InternationalConference onPerformance Engineering . 27ś36.
[64]Joaquin Miller and Jishnu Mukerji (Eds.). 2003. MDA guide. Object Management
Group(2003).
[65]Tim Mullaney. 2013. Demand overwhelmed HealthCare.gov. http://goo.gl/
k3o4Rg.
[66]JoostNoppen,PimvandenBroek,andMehmetAkşit.2008. Softwaredevelop-
mentwith imperfect information. Softcomputing 12,1 (2008), 3.
[67]Jeho Oh, Don Batory, Margaret Myers, and Norbert Siegmund. 2017. Finding
Near-optimal Configurations in Product Lines by Random Sampling. In Joint
MeetingonFoundationsofSoftwareEngineering(ESEC/FSE2017) .ACM,Paderborn,
Germany, 61ś71. https://doi.org/10.1145/3106237.3106273
[68]CarloPoloniandValentinoPediroda.1997. GAcoupledwithcomputationally
expensive simulations: tools to improve efficiency. Genetic Algorithms and
EvolutionStrategies inEngineering and Computer Science (1997), 267ś288.
[69]PasqualinaPotena.2007. Compositionandtradeoffofnon-functionalattributesin
software systems: research directions. In Joint Meeting of the European Software
Engineering Conference and ACM SIGSOFT Symposium on the Foundations of
SoftwareEngineering (ESEC/FSE) . 583ś586.
[70]ThanawinRakthanmanon, BilsonCampana,AbdullahMueen,GustavoBatista,
Brandon Westover, Qiang Zhu, Jesin Zakaria, and Eamonn Keogh. 2013. Ad-
dressing big data time series: Mining trillions of time series subsequences under
dynamic time warping. ACM Transactions on Knowledge Discovery from Data
(TKDD)7,3 (2013), 10.
[71]M.P.RobillardandN.Medvidovic.2016. DisseminatingArchitecturalKnowledge
onOpen-SourceProjects: ACaseStudyoftheBook"ArchitectureofOpen-SourceApplications".In InternationalConferenceonSoftwareEngineering(ICSE) .476ś487.
https://doi.org/10.1145/2884781.2884792
[72]Tripti Saxena and Gabor Karsai. 2010. MDE-based approach for generalizing
designspaceexploration. In ModelDrivenEngineeringLanguagesandSystems .
Springer, 46ś60.
[73]Abdel Salam Sayyad, Joseph Ingram, Tim Menzies, and Hany Ammar. 2013.
Scalable product line configuration: A straw to break the camel’s back. In
International Conference on Automated Software Engineering (ASE) . 465ś474.
https://doi.org/10.1109/ASE.2013.6693104
[74]Abdel Salam Sayyad, Tim Menzies, and Hany Ammar. 2013. On the value of
user preferences in search-based software engineering: a case study in software
productlines.In InternationalConferenceonSoftwareEngineering(ICSE) .492ś501.
[75]Ina Schaefer. 2010. Variability Modelling for Model-Driven Development of
Software Product Lines. In International Workshop on Variability Modelling of
Software-IntensiveSystems(VaMoS) , Vol. 10.Linz,Austria,85ś92.
[76]Ali Sedaghatbaf and Mohammad Abdollahi Azgomi. 2019. SQME: A framework
for modeling and evaluation of software architecture quality attributes. Software
&SystemsModeling 18,4(Aug.2019),2609ś2632. https://doi.org/10.1007/s10270-
018-0684-3
[77]ArmanShahbazian,GeorgeEdwards,andNenadMedvidovic.2016. Anend-to-
end domain specific modeling and analysis platform. In Proceedings of the 8th
InternationalWorkshop onModelinginSoftwareEngineering . 8ś12.
[78]Arman Shahbazian, Suhrid Karthik, Yuriy Brun, and Nenad Medvidovic. 2020.
ReplicationpackageforłeQual: Informingearlydesigndecisionsž. https://doi.
org/10.5281/zenodo.3905131 .
[79]Arman Shahbazian, Youn Kyu Lee, Yuriy Brun, and Nenad Medvidovic. 2018.
Poster: Making Well-Informed Software Design Decisions. In Poster Track at the
International Conference on Software Engineering (ICSE) . Gothenburg, Sweden,
262ś263. https://doi.org/10.1145/3183440.3194961
[80]ArmanShahbazian,YounKyuLee,DucLe,YuriyBrun,andNenad Medvidovic.
2018.RecoveringArchitecturalDesignDecisions.In IEEEInternationalConference
onSoftwareArchitecture(ICSA) .
[81]NorbertSiegmund,AlexanderGrebhahn,SvenApel,andChristianKästner.2015.
Performance-influenceModelsforHighlyConfigurableSystems.In JointMeeting
onFoundationsofSoftwareEngineering (Bergamo,Italy) (ESEC/FSE2015) .ACM,
NewYork, NY, USA,284ś294. https://doi.org/10.1145/2786805.2786845
[82]Norbert Siegmund, Sergiy S. Kolesnikov, Christian Kästner, Sven Apel, Don
Batory,MarkoRosenmüller,andGunterSaake.2012. Predictingperformancevia
automated feature-interaction detection. In International Conference on Software
Engineering (ICSE) . 167ś177. https://doi.org/10.1109/ICSE.2012.6227196
[83]NorbertSiegmund,MarkoRosenmüller,MartinKuhlemann,ChristianKästner,
Sven Apel, and Gunter Saake. 2012. SPL Conqueror: Toward optimization of
non-functional properties in software product lines. Software Quality Journal 20,
3-4 (2012), 487ś517.
[84]Ghanem Soltana, Nicolas Sannier, Mehrdad Sabetzadeh, and Lionel C Briand.
2015. A model-based framework for probabilistic simulation of legal policies.
InInternationalConferenceonModelDrivenEngineeringLanguagesandSystems
(MODELS) . 70ś79.
[85]Richard N. Taylor, Nenad Medvidovic, and Eric M. Dashofy. 2009. Software
architecture: Foundations,Theory, and Practice . WileyPublishing.
[86]AtulThakur,AshisGopalBanerjee,andSatyandraKGupta.2009. Asurveyof
CAD model simplification techniques forphysics-basedsimulation applications.
Computer-AidedDesign 41,2 (2009), 65ś80.
[87]Nikola Trčka, Martijn Hendriks, Twan Basten, Marc Geilen, and Lou Somers.
2011. Integratedmodel-driven design-spaceexploration for embeddedsystems.
InInternationalConference onEmbeddedComputer Systems(SAMOS) . 339ś346.
[88]United States Government Accountability Office. 2015. Report to Congressional
Requester, GAO-15-238. http://www.gao.gov/assets/670/668834.pdf .
[89]US Centers for Medicare and Medicaid Services. 2013. McKinsey and Co. Presen-
tationonHealthCareLaw. http://goo.gl/Nns9mr .
[90]USDepartmentofHealthandHumanServices.2013. HealthCare.govProgress
and Performance Report. http://goo.gl/XJRC7Q .
[91]AndreeaVescan.2009. Ametrics-basedevolutionaryapproachforthecompo-
nentselectionproblem.In InternationalConferenceonComputerModellingand
Simulation (UKSIM) . 83ś88.
[92]Murray Woodside, Dorina C Petriu, Dorin B Petriu, Hui Shen, Toqeer Israr,
andJoseMerseguer.2005. Performancebyunifiedmodelanalysis(PUMA).In
Proceedingsofthe5thInternationalWorkshoponSoftwareandPerformance .1ś12.
[93]Hans-Jürgen Zimmermann. 2011. Fuzzy set theory and its applications . Springer
Science & BusinessMedia.
1051