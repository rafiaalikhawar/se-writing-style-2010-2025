Detection of Hidden Feature Requests from Massive Chat
Messages via Deep Siamese Network
Lin Shi1,¬ß, Mingzhe Xing1,2,¬ß, Mingyang Li1,2, Yawen Wang1,2, Shoubin Li1,2, Qing Wang1,2,3‚àó
1Laboratory for Internet Software Technologies, Institute of Software Chinese Academy of Sciences, Beijing, China
2University of Chinese Academy of Sciences, Beijing, China
3State Key Laboratory of Computer Science, Institute of Software Chinese Academy of Sciences, Beijing, China
{shilin,shoubin,wq}@iscas.ac.cn, mingzhe@itechs.iscas.ac.cn, {mingyang,yawen}@nfs.iscas.ac.cn
ABSTRACT
Online chatting is gaining popularity and plays an increasingly
significant role in software development. When discussing func-
tionalities,developersmightrevealtheirdesiredfeaturestoother
developers. Automated mining techniques towards retrieving fea-
turerequestsfrommassivechatmessagescanbenefittherequire-
ments gathering process. But it is quite challenging to perform
such techniques because detecting feature requests from dialogues
requiresathoroughunderstandingof thecontextualinformation,
and it is also extremely expensive on annotating feature-request
dialogues for learning. To bridge that gap, we recast the traditional
text classification task of mapping single dialog to its class into
thetaskofdeterminingwhethertwodialoguesaresimilarornot
by incorporating few-shot learning. We propose a novel approach,
namedFRMiner,whichcandetectfeature-requestdialoguesfrom
chat messages via deep Siamese network. We design a BiLSTM-
baseddialogmodel thatcanlearnthe contextualinformationofa
dialoginbothforwardandreversedirections.Evaluationonthereal-
worldprojectsshowsthatourapproachachievesaverageprecision,
recallandF1-scoreof88.52%,88.50%and88.51%,whichconfirms
that our approach could effectively detect hidden feature requests
fromchatmessages,thuscanfacilitategatheringcomprehensive
requirements from the crowd in an automated way.
KEYWORDS
FeatureRequests,RequirementsEngineering,DeepLearning,Siamese
Network
ACM Reference Format:
Lin Shi1,¬ß, Mingzhe Xing1,2,¬ß, Mingyang Li1,2, Yawen Wang1,2, Shoubin
Li1,2, Qing Wang1,2,3. 2020. Detection of Hidden Feature Requests from
MassiveChatMessagesviaDeepSiamese Network.In 42ndInternational
ConferenceonSoftwareEngineering(ICSE‚Äô20),May23‚Äì29,2020,Seoul,Re-
publicofKorea. ACM,NewYork,NY,USA,13pages.https://doi.org/10.1145/
3377811.3380356
‚àóCorresponding author.
¬ß Both authors contributed equally to this research.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ICSE ‚Äô20, May 23‚Äì29, 2020, Seoul, Republic of Korea
¬© 2020 Association for Computing Machinery.
ACM ISBN 978-1-4503-7121-6/20/05...$15.00
https://doi.org/10.1145/3377811.3380356
'HVLUHGIHDWXUHVRPHWKLQJOLNHQJWUXHYDOXHQJIDOVHYDOXHIRU
UHDFWLYHFKHFNER[HV
'HVLUHGIHDWXUHWKHDQJXODUFOLFDQSXWDOOP\VHUYLFHVLQWRD VHUYLFHV
IROGHU3'RZHKDYHVRPHWKLQJOLNHQJWUXHYDOXHQJIDOVHYDOXHIRUU HDFWLYH
FKHFNER[HV",RQO\VHHPWRJHWWUXHIDOVHRXWRIWKHPUHJDUGOH VVRIYDOXH
DWWULEXWH
6KPGRQ
WWKLQNVREXW\RXFDQHDVLO\VROYHWKLVLQ\RXUFRP SRQHQW
3WUXHEXWLWZRXOGEHQLFHWREHDEOHWRXVHWKHYDOXHVGLUH FWO\LW¬çVDIRUP
DUUD\RIFKHFNER[HV
),VWKHUHDZD\WRWHOOWKHDQJXODUFOLWRSXWDOOP\VHUYLFH VLQWRDVHUYLFHV
IROGHU"
+WKHFOLLVH[SHFWLQJ\RXWRGRLWIURPURRWHYHU\WLPH
+QJJHQHUDWHFVVHUYLFHVVHUYLFHQDPH LVZKDW\RXKDYHWRGR
+%XWWKLVLVVRUWRIIL[DEOHE\DOLDVHVLQ\RXUWHUPLQDO)<HDKWKDW
VWRRPXFKZRUNIRUDOLDVHVVSHOOLQJRXWWKHGLUH FWRU\ZRUNV
ILQH,VXSSRVHWKDQNV),IHHOOLNHLWZRXOGEHDXVHIXOFOLIHDWXUHWRMXVWVSHFLI\ WKDW,ZDQWDOO
VHUYLFHVLQDVHUYLFHVIROGHU
Figure 1: Example chat message from AngularJS project,
whererequeststodesiredfeaturesareburiedinthemassive
chat history.
1 INTRODUCTION
Recentstudiesreportedthattheusageofonlinechattingisgaining
popularity and plays an increasingly significant role in software
development, having replaced emails in some cases [ 35,56,57].
Developers are turning to public workplace chat platforms, such
as Slack, IRC, HipChat, Gitter, and Freenode to share opinions andinteresting insights, discuss how to resolve defects as well as what
features to implement in future [9].
Although developers reveal their desired features when commu-
nicatingwithotherdevelopers,theopenandcrowdingnatureof
online chatting makes these feature-request dialoguesget quickly
floodedbynewlyincomingmessages.Typically,thefeaturerequests
discussedinonlinechattingarelikelytobeburiedandignoredif
theyarenotdocumented.TakenthechatmessagesfromAngularJS
project as an example (Figure 1), developer P and F posted their
questions in online chatting. In the beginning, their intentions are
asking for help from other developers to seek feasible solutionsto problems. After chatting with other developers, they realized
thattheexistingsystemcouldnotbehavethewaytheywant.Then
6412020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE)
their intentions shift from asking for solutions to requesting fea-
tures. P requestsfor ‚Äúsomething like ng-true-value/ng-false-value
for reactive checkbox‚Äù, and F requests that ‚Äúthe angular cli can put
all my services into services folder‚Äù. In this work, we consider dia-
logues that contain requests for new functionalities/enhancements
as feature-request dialogues. In practice, the release team monitors
avarietyofcommunicationchannelstohavemultiplesourcesof
information that could be relevant to the next release [ 51,61]. If
the release team could acknowledge those hidden feature requests
fromchatmessages,theirnextreleaseplanningmayhavetheop-
portunity to maximize the stakeholder satisfaction by considering
more feature requests [50].
Automatedminingtechniquestowardsretrievingvaluableinfor-
mationfrommassivechatmessagesarebadlyneededforgathering
comprehensivefeaturerequestsfromalargenumberofusers,which
contribute to requirements elicitation and release planning, andin turn, promote the success of software development [
6,21,25].
Althoughthechatmessagescouldbealargevolumeandembed-
ded with feature requests over time, it is quite challenging to mine
massive chat messages due to the following barriers.
Dialog-wiseanalysis .Analyzingdialoguesfromchatmessages
differsfromregulartextminingtasksinthatitneedstoconsider
contextual information among the dialog-wise scope when un-derstanding one single sentence. Therefore, existing studies onsentence-wise feature request detection [
13,25,55] cannot be di-
rectly utilized for this task. For example, the sentence ‚ÄúWe need
toaddverticalNavbaroption‚Äùisclassifiedasafeaturerequestby
sentence-wisetechniques.Butwhenpostedinonlinechat,following-
up conversation pointed out the existing functionality can fulfillthat request in an alternative way. Moreover, the sentence-wise
detectionresultswillbeinaccurateasalargenumberofoff-topic
sentenceswillbeidentifiedasfeaturerequestsinthechatmessages,
e.g., ‚ÄúI really need to get my programming skills back.‚Äù, ‚ÄúI would
like to get some coffee and cookies.‚Äù
Extremelyexpensiveannotation .Thechatmessagesaretyp-
icallylargeinsize.Findingthefeaturerequestsdialoguesamong
themassivechatmessagesislikelookingforaneedleinahaystack.
It is extremely expensive to annotate feature requests from chat
messagesduetothehighvolumecorpusandalowproportionof
ground-truth data. Only a few labeled chat messages are catego-rized into feature request types. How to make the maximum useof the few labeled data to accurately classify the unlabeled chat
messages becomes a critical problem.
Entangled andnoisy data .Chatmessagesaretypicallyhigh-
volume and contain informal conversations covering a wide range
of topics. Two or more developers synchronously interact with
each other where their utterances are largely entangled in the chat
messages. Moreover, there exist noisy utterances such as dupli-
cateandoff-topicmessagesinchatmessagesthatdonotprovide
any valuable information. The entangled and noisy data poses a
difficulty to analyze and interpret the communicative dialogues.
Inthiswork,wetakethefirststeptowardsdialog-wisetechnique
that aims to automatically detect hidden feature requests postedinchatmessages.weproposeanovelapproach,namedFRMiner,
which can detect feature-request dialogues from chat messages
via deep Siamese network. To better understand the contextual
informationinthedialog-wisescope,wefirstbuildacontext-awaredialog model based on a bidirectional LSTM (BiLSTM) structure
thatcandeeplylearnthecontextualinformationofadialoginboth
forwardandreversedirections.Inspiredbythefew-shotlearning
techniques that aim to build performance prediction models by uti-
lizinginsufficientlabeledresources,werecastthetraditionaltext
classification task of mapping single dialog to its class into the taskof determining whether two dialogues belong to the same or differ-entclass.Hence,wecombinecontext-awaredialogmodelswiththeSiamesenetworktolearnthesimilaritybetweenapairofdialogues
rather than the patterns of a specific class. The prediction result
ofafeature-request dialogcanbeinferredbasedon thesimilarity
predictionandtheobservedclassofitspartnerdialoginthepair.Toevaluatetheproposedapproach,weannotate1,035dialoguestaken
from three popular open-source projects. The experimental results
show that our approach significantly outperforms two sentence-
wiseclassifiersandfourtraditionaltextclassificationapproaches
withaverageprecision,recallandF1-scoreof88.52%,88.50%,and
88.51%. The results confirm that our approach could effectively de-
tect hidden feature requests from chat messages, thus can facilitate
gathering comprehensive requirements from a large number of
users in an automated way.
The major contributions of this paper are as follows.
‚Ä¢Wearethefirsttopromotedetectinghiddenfeaturerequestsfrom massive chat messages that can benefit comprehensive
requirements gathering.
‚Ä¢We introduce a solution that can effectively predict feature-
request dialogues based on limited labeled data by incor-
poratingSiamese Network,which significantlyrelieves theburden of annotating supervised data.
‚Ä¢
Weevaluateourapproachonthreeactiveopen-sourceprojects,
and an empirical comparison shows that the proposed ap-
proach outperforms existing studies and four text classifica-
tion approaches.
‚Ä¢Publicly accessible dataset and source code1to facilitate the
replicationofourstudyanditsapplicationinothercontexts.
2 BACKGROUND
This section describes three key technologies related to this re-
search:TextCNN,BiLSTM,andfew-shotlearningtechniques.We
includethemherebecauseourworkisbasedonthesetechnologies.
2.1 TextCNN
Dialoguesinchatmessagesaretheformoftextualsentencesrecorded
in the chronological order that were discussed by a community of
developers during online communications. Modeling sentence rep-
resentationisthefoundationofhigh-leveldialoganalysis.Inthis
paper,werepresentsentencesbyusingTextCNN[ 30],whichhasan
advantageoverlearningoninsufficientlabeleddataasitemploys
concise network structure and a small number of parameters.
TextCNN is a classical method for sentence modeling which
usesashallowConvolutionNeuralNetwork(CNN)[ 32]tomodel
sentence representation. CNN is one kind of deep learning models
thathasbeenwidelyusedincomputervision.Itusesseveralcon-
volution kernels to capture local information as the receptive field,
1https://github.com/FRMiner/FRMiner
642thentheglobalrepresentationisproducedwiththeselocalinfor-
mation. Analogously, in Natural Language Processing (NLP), CNN
canaggregaten-graminformationandmodelsentencerepresen-
tation. TextCNN takes the pre-trained or random generated word
embeddingasaninput.Thedimensionofitsoutputdependsonthe
numberandthesizeofconvolutionkernels.A n-lengthsentence
canberepresentedasamatrixwithashapeof n√ód,wheredisthe
dimension of word embedding. Each kernel w‚ààRkd, wherekis
thesizeofconvolutionkernel,isappliedtoawindowof kwordsto
be mapped into a new one-dimension vector. Let Xi:i+krepresents
the concatenation of k-gram words in the original sentence, and
thenaconvolutionoperationwillbeperformedonit.Theoutput
of the convolution layer can be computed as oi=f(w¬∑Xi:i+k+b)
wherebis a bias term and fis an activation function. Given the
lengthlof a sentence and the convolution kernel size k, we can
get the representation of the sentence, whose size is l‚àík+1. The
convolution layer is followed by a max polling layer, which can
capture the key information with the highest value.
To obtain more sufficient semantic information ensembled by
different scales of local information, multiple convolution kernels
with different sizes are applied to the sentence. Hence, for a sen-
tence,given n√ómconvolutionkernels,where nisthenumberof
different sizes of kernels, and mis the number of kernels of each
size, we can get the sentence representation with size of n√óm,
whichencodesthedifferentscalesoflocalinformationintoaglobal
representation of the sentence.
2.2 Bidirectional LSTM
Analyzingdialoguesfromchatmessagesisahigh-leveltextmin-
ing task as it needs to consider contextual information among
the dialog-wise scope when understanding one single sentence.In this paper, we utilize the Bidirectional Long Short Term Mem-ory network (BiLSTM), regarding the sentences of dialogues as
sequential items, to capture the contextual information, where the
representationsofsentencesareembeddedbyTextCNN.BiLSTM
wasproposedbyGravesetal.[ 20]tolearnbidirectionalinforma-
tionforthesequencelearningtask.BiLSTMstackstwostandardLong Short Term Memory network (LSTM) [
23] layers with op-
posite directions to learn the one-way representation respectively.
Then it combines the forward and backward representations as
the bidirectional embedding. Long Short Term Memory network
(LSTM)isanoptimizedRecurrentNeuralNetwork(RNN)structure
based on gate mechanism that was proposed by Hochreiter et al.
[23].LSTMutilizesgatemechanismtofilterkeyinformationand
passthemdowntothelongsequence.AnLSTMcellcomposesof
inputgate,forgetgate,cellstate,andoutputgate.Theoutputsof
LSTM cell gates can be specified as follows:
‚é°‚é¢‚é¢‚é¢‚é¢‚é¢‚é¢‚é£i
t
ft
Àúct
ot‚é§‚é•‚é•‚é•‚é•‚é•‚é•‚é¶=‚é°‚é¢‚é¢‚é¢‚é¢‚é¢‚é¢‚é£œÉ
œÉ
tanh
œÉ‚é§‚é•‚é•‚é•‚é•‚é•‚é•‚é¶/parenleftbigg
W/bracketleftbiggx
t
ht‚àí1/bracketrightbigg
+b/parenrightbigg
ct=Àúct‚äôit+ct‚àí1‚äôft
ht=ot‚äôtanh(ct)
where xtis theithtoken in the input sequence; Wis the weight
matrix of LSTM cells; bis the bias term; œÉdenotes logistic sigmoidactivationfunction,and tanhdenoteshyperbolictangentactivation
function; ‚äôdenotes element-wise multiplication.
Hence, the final representation of BiLSTM can be formed as
h=[‚àí ‚Üíh‚äï‚Üê ‚àíh], where‚àí ‚Üíhand‚Üê ‚àíhdenote the outputs of two LSTM
layers respectively, and ‚äïis concatenate operation.
2.3 Few-shot learning
Deep learning has gained significant success both in the field of
computervisionandNLP.Butitreliesonadequatevolumeoftrain-
ing data heavily, and has difficulty in performing well when the
labeledresourceisinsufficient.Automatedmininginchatmessages
also faces the insufficient labeled resource problem. In online chat-
ting, a large community of developers create plenty of discussions
in a short time. It is extremely time-consuming to annotate a large
number of dialog data for learning effective models since they are
not only long but also require domain knowledge to thoroughly
understand. Few-shot learning approaches are proposed to over-
come these constraints [ 64]. The few-shot learning approaches can
be classified into the followingthree categories [ 10]. Model-based
approaches aim at learning projectors from few labeled data to
taxonomies through model designing. Optimizer-based approaches
adjustthetraditionalgradientdescentoptimizermethodtofitthe
data.Metric-basedapproachesclassifysamplesthroughlearning
similarity metric functions.
Inthispaper,weleverageametric-basedfew-shotlearningtech-
nique,namedSiamesenetwork[ 8],whichiswidelyusedtomea-
surethesemanticsimilarityamongtextsorimages[ 45].Traditional
classificationmodelsaretryingtolearnamappingfromasingle
instance to its class, but they cannot always work well when there
islowlabeledresourcedataavailable.Differentfromthetraditional
approaches, Siamese network takes pairs of instances as inputs,
aiming at learning key characteristics that determine whether the
two instances belong to the same or different class. It consists of
two identical sub-components that not only share model structure
butalsoparameterstoencodethepairsofinstancesrespectively.
Intuitively,itiseasierforustodeterminewhethertwodialogues
aresimilar rather thangiventheexact classforeachdialog. Since
Siamese network takes pairs as inputs, the dataset is convertedfromelement-wisetopair-wise,andcanbeaugmentedwithper-
mutations.
3 APPROACH
Figure 2 demonstrates the overall framework of our approach. We
construct the training dataset by disentangling dialogues in the
chat messages. Then we build a hierarchical context-aware dialog
modelforeachdialogue.Thecontext-waredialogmodelencodes
dialogues by BiLSTM structure which uses TextCNN-based sen-
tence embedding as inputs. After that, we build a Siamese network
withtwoidenticalcontext-awaredialogmodels.Finally,weinfer
thepredictiveclassbasedontheprobabilitiesproducedbySiamese
network and the actual labels of golden dialogues in the paired
instance.
3.1 Dialogues Disentanglement
Chatting channels is one type of synchronous textual communica-
tion among a community of developers. Messages in chats form
stream information, with conversations often entangling such as a
single conversation thread is interleaved with other conversations.
643Dialogues 
for trainingChat messages
3.1 Dialog
DisentanglementDialog1
Dialog2Sentences 
embedding1
Sentences 
embedding2Dialog 
embedding1
Dialog 
embedding2Class 
InferenceFeature dialog
Non-Feature 
dialogs1
s2
sn‚Ä¶‚Ä¶3.2 Context-aware Dialog Model 1
s1
s2
sn‚Ä¶‚Ä¶d1
d23.2 Context-aware Dialog Model 23.3 Siamese Dialog Classification Network
Softmax
Sharing   Weights‚Ñé‡¨µ
‚Ñé‡Ø°‚Ñé‡¨∂
‚Ñé‡Øú
‚Ñé‡¨µ
‚Ñé‡Ø°‚Ñé‡¨∂
‚Ñé‡Øú3.4 Infer class probability
p
1-pSimilarity
Measure
Figure 2: The Overview of FRMiner
Dividing chat messages into a set of distinct conversations is an
essentialprerequisiteforany kindofhigh-leveldialogueanalysis.
We leverage the state-of-the-art technique for conversation disen-
tanglement proposed by Kummerfeld et al. [ 33]. Their model is
trained from 77,563 manually annotated messages of disentangled
dialogues from online chatting. It is a feedforward neural network
with 2 layers, 512 dimensional hidden vectors, and softsign non-
linearities.Theinputofthemodelisa77dimensionalvector,where
each element is a numerical feature extracted from the original
conversationtexts,thatinclude,timeintervalfrompreviouschat
messages posted by the current user, is there a target user in the
chat content,do twochat textscontain thesame wordsand soon.
Figure 3 is a demonstration of the dialogues before and after disen-
tanglement. The model can achieve relatively good performance
with 74.9% precision and 79.7% recall.
Figure3:Exampleofdialoguesbeforeandafterdisentangle-
ment [33]. These curves with different colors represent thelinks of different dialogues after disentanglement.3.2 Build Context-aware Dialog Model
Wedesignahierarchicalcontext-waredialogmodelthatcancapture
thecontextualinformationaswellasthesemanticmeaningofeachsentenceinadialog.AsshowninFigure4,thecontext-awaredialogmodelconsistsoffourlayers:inputlayer,sentenceembeddinglayer,
dialog embedding layer, and output layer.
Input layer. We first tokenize thesentences into tokens as the
basicterms.Toobtainabetterperformance,weutilizethe50dimen-
sion Glove word embeddings [ 49] that are pre-trained on 6 billion
words of Wikipedia and Gigword corpus as the initial vectors of
the corresponding words. Moreover, inspired by previous works
[58][55],wenoticethat part-of-speec h(POS)patternsortemplates
obviously exist in feature-request texts. Intuitively, the POS tag
can benefit semantic understanding by introducing explicit lexical
information.Therefore,weaddPOStaginformationintowordrep-resentationtoenhanceitsfeature.Specifically,eachtypeofPOStag
willbeinitializedasarandomvectorwithuniformdistributionand
optimized during training. Hence, each word can be represented
aswi=[wei‚äïposi],whereweidenotesthecorrespondingword
embeddingand posidenotestheembeddingofthePOStagofthe
word.
‡°ø‡´ö
 ‡°ø‡´õ
 ‡°ø‡´ú
 ‡¢î‡°øxxxxxxLSTM 
CellLSTM
CellLSTM 
CellLSTM 
CellLSTM 
CellLSTM 
CellLSTM 
CellLSTM 
Cell
xxxxxxxxxxxxbackward
forwardSoftmax
‡¢é‡´ö ‡¢é‡´õ ‡¢é‡´ú ‡¢î‡¢éOutput layer
Dialog 
Embedding layer
Sentence 
Embedding layer
Input layer
Figure 4: Hierarchical Context-aware Dialog Model
644Sentence embedding layer. After transforming the original
sentence into a matrix stacked with word embedding and POS tag
embedding, we feed the embedding matrix into TextCNN to obtain
thesentencerepresentation.Detailsofrepresentingsentencesby
TextCNN have been introduced in Section 2.1.
Dialog embedding layer. In the dialog embedding layer, we
use a sequence of sentence embeddings to represent a dialog. Each
embedded sentence acts as a token when inputting the BiLSTM
encoder according to their sequences in the dialog. After encoding
BiLSTM, the bidirectional contextual information of the dialog will
be learned.
Outputlayer. Intheoutputlayer,wecombinethetwodirection
representations‚àí ‚Üíhand‚Üê ‚àíhencoded by BiLSTM as the output vector
of the dialog, which can be presented as h=[‚àí ‚Üíh‚äï‚Üê ‚àíh].
3.3 Construct Siamese Dialog Classification
Network
Inorder toalleviatetheinsufficient labeleddataproblem,we con-
struct the Siamese dialog classification network that can augment
the dataset by recasting the traditional text classification task of
mapping single dialog to its class into the task of determining
whether two dialogues belong to the same or different classes. For
thepurposeofclarity,wewilluse featuredialog andnon-feature
dialogin the rest of this paper to refer to the dialogues that are
requesting features and dialogues that are not requesting features.
Thedashedboxof‚Äò3.3‚ÄôinFigure2presentsthedetailedarchi-
tecture. The Siamese dialog classification network contains two
context-awaredialogmodelsthatsharestructureandparameters
to encode a pair of dialogues to d1andd2respectively. We use the
combination forms of d1andd2,[d1‚äïd2], as representations of
the relation between the two dialogues. Then the representation of
therelationbetweenapairofdialoguesisprojectedfromthedia-
log embedding to a similarity metric. Due to explicit equations for
similaritymeasures,suchasCosineSimilarity[ 24]andEuclidean
Distance [ 24], usually used to measure the closeness between vec-
tors in linear space, they are not suitable for complex dialog in
semanticspace.Therefore, weemploy similarityfunctionlearned
during training neural network. As the diff or same label of twodialogues can be obtained, we can train a similarity layer in theneural network. It is like a black-box component. The inputs areembedded representations of two dialogues with ‚Äòsame‚Äô or ‚Äòdiff‚Äô
labels, the outputs are their similarity.
WetraintheSiameseDialogClassificationNetworkaccording
tothefollowingsteps.(1)Wedividethedatasetintotrainingand
testingdatasetrandomly. Train_distheoriginaldatasetthatem-
ploysdialogueswithlabel‚Äòfeature‚Äôor‚Äònon-feature‚Äôasentries.(2)
Typically, the size of labeled dialogues is insufficient for training
effectivelearning-basedmodels.Toovercomethatissue,weaug-mentTrain_dintoTrain_pby sampling a pair of dialogues from
Train_dwith label ‚Äòsame‚Äô or ‚Äòdiff‚Äô as one entry of Train_p. More
specifically, for each dialog in training dataset, we randomly select
a positive partner with ‚Äòfeature‚Äô label, and a negative partner with
‚Äònon-feature‚Äô label from training dataset Train_d. For example, if
the two dialogues are all feature dialog ornon-feature dialog,w e
will assign the pair with label-‚Äò same‚Äô, otherwise ‚Äò diff‚Äô. Due to the
one-positive-one-negativesamplingpolicy,ourtrainingdatacanbebalancednaturally.Besides,supposewehave mfeaturedialogues
andnnon-feature dialogues inTrain_d, we can augment the origin
data set to size of/parenleftbigm
2/parenrightbig+/parenleftbign
2/parenrightbig+m√óninTrain_p. Finally, since each
pair of dialogues belongs to either ‚Äòsame‚Äô class or ‚Äòdiff‚Äô class, theoutput of similarity measure is a 2-length vector
[score1,score2]
that represents the scores of the two classes, where score i‚ààR.W e
perform softmax on the 2-length vector, which can be specified as
Softmax(socre i)=escore i
/summationtext.12
j=1escore j
Thenthe[score1,score2]canbenormalizedtoprobabilities [p,1‚àíp],
wherep‚àà[0,1].
3.4 Infer Class Probability
The output of Siamese dialog classification network is the prob-
abilities that indicating whether two dialogues are sameordiff.
But what we need is the probabilities that indicating whether adialog is a feature dialog or not, thus, we need to infer the labelof a dialog based on the probabilities and the actual label of an-other dialog in the pair instance. For example, we sample a pair
<Dialo–¥1,Dialo–¥2>, whereDialo–¥1is the golden dialog sampled
from train dataset with observed ‚Äònon-feature dialog‚Äò label, and
Dialo–¥2istheunknowndialogtobepredicted.Weinputthepair
of them into the Siamese dialog classification network, then a pre-
diction for deciding the two dialogues are sameordiffis made.
Suppose the prediction is diff, then we can infer that the class of
Dialo–¥2isafeaturedialog.Iftheactuallabelof Dialo–¥2isafeature
dialog,itindicatesthatthispredictionmadebyourmodelistrue
positive. Otherwise, we get a false positive prediction. To obtain
a more reliable predictresult, we employ the vote strategyduring
predicting phrase. For each unknown dialog, we construct kpaired
instancesbysampling kdifferentgoldendialogues.Afterpassing
these pairs into FRMiner, we can get linstances which indicate the
unknownoneisafeaturedialogand k‚àílinstanceswhichindicate
itis anon-featuredialogbased onthepredictionsof FRMinerand
thelabelsofgoldendialogues.If lisgreaterthank
2,thenweassign
the predicted dialog with ‚Äòfeature dialog‚Äô label, vice versa.
3.5 Tool Implementation
We implement our proposed approach, FRMiner, using Allennlp
[16] which is an open-source NLP library built on PyTorch [15].
Implementation details. For these hyper-parameters, we use
gridsearch[ 7]astheparameterselectionmethodtoobtainthebest
performance. The dimension of POS tag embedding is 50, the same
as word embedding. Then, we can use s=[w1,w2...wn]as the
representation of sentences, where wi=[wei‚äïposi]. To obtain
more sufficient semantic information ensembled by different scales
of local information, multiple convolution kernels with differentsizes are applied to the sentence. We set 4 different kernel sizes
whichare2,3,4,5respectivelyand25featuremapsforeachkernel.
TheoutputdimensionofBiLSTMis300(150foreachdirection).We
usealinearlayerasthesimilaritylayertoprojectthe300dimension
vector to two values that represent the probability scores of two
classes.Sincethetaskcanberegardedasaclassificationproblem,
we use cross-entropy as the loss function.
645Optimization . In addition, to avoid the over-fitting problem,
we apply dropout [ 59] on the input embeddings with 0 .1 drop rate,
which means, 10% neuron cell will be randomly masked to reduce
theparametersthatneedtobetrainedineachbatchtraining.We
also use the strategy of early stopping [52]. If the performance on
the test dataset did not promote for 10 epochs, the training process
will be stopped.
4 EXPERIMENTAL DESIGN
4.1 Research Questions
Our evaluation addresses the following three research questions.
RQ1: How effective is our approach for detecting hidden
featurerequests? Toinvestigatetheeffectivenessofourapproach,
we conduct 3-fold cross-validation on detecting feature dialogues
fromchatmessagesofthreeopen-sourceprojects.Wealsocompare
the performances of two sentence-wise approaches that classify
sentencesofonlinediscussionsintofeaturerequestsandothertypes.
Weadaptthetwoapproachestoourtaskbypredictingdialogues
thatcontainfeature-requestsentencesasfeaturedialogues.Besides,
we examine the performances of four widely used classification
methodsonthelimitedlabeledresourcestoperceivethedifficulties
of automated feature request mining in chat messages.
RQ2:HowdoestheSiameseNetworkfacilitatefeaturere-
quest detection? To examine the performance enhancement in-
troduced by the Siamese Network, we construct p-FRMiner, which
isaplainFRMinerwithoutincorporatingSiameseNetworktech-
nique. Detailed difference between FRMiner and p-FRMiner will
bedescribedinSection4.3.Wethencomparetheperformanceof
p-FRMinerthataredirectlytrainedbydialog-instances,withthe
performanceofFRMinerthataretrainedbypair-instances.Then
we increasingly enlarge the size of the training pair-instances to
examine the relationship between performance enhancement and
data augment.
RQ3: Does our approach work well in cross-project vali-
dation?RQ3 examines the generalizability of our approach via
cross-project validation on three open-source projects. We itera-
tivelyusetwoprojectsfortrainingandthereservingonefortesting.
We also conduct cross-project validation on baseline approaches.
4.2 Data Preparation
Our experimental data is crawled by Scrapy [53] from three open-
source projects: AngularJS [ 17], Bootstrap [ 60], and Chromium
[18].Weselectthe threeprojectsfor thefollowingreasons. First,
theyareunderactivedevelopments.Second,largecommunitiesare
formedaroundthoseprojects.Third,developersfromtheseprojects
actively use online chatting to share opinions, interesting insights,
and discuss what features to implement in the future. For example,
in the last three years, an average of 2,823 utterances are made per
week in AnguluarJS community. Moreover, their historical chat
messages are all documented and publicly accessible [ 1], which
providerichresourcesforminingvaluableinformation.Ourdata
is collected in the following steps:
Step1:Preprocess .Wefirstnormalizenon-asciicharacterslike
emojistostandardasciistrings.Somelow-frequencytokenscannotcontributetotheresultofclassificationsuchasURL,emailaddress,code,HTMLtags,andversionnumbersinchatmessages.WereplaceTable 1: The statistic of labeled dialogues
Massive chat messages Sample
Duration #dialog #sentence #dialog #sentence #FR
AngularJS 2016.5-2019.4 38266 406553 316 9220 36
Bootstrap 2014.7-2019.5 10358 58871 379 2371 76
Chromium 2015.5-2019.7 16804 118890 340 4465 27
Total 65428 584314 1035 16056 139
themwithspecifictokens <URL>,<EMAIL>,<HTML>,<CODE>,and
<ID>respectively.WeutilizeSpacy[ 2]totokenizesentencesinto
terms. To alleviate the influence of word morphology, we then
perform lemmatization and lowercasing on terms with Spacy.
Step2: DialoguesSampling . After disentanglement, there are
a large number of identified chat dialogues. To observe the charac-
teristics of the entire dialogues population, we randomly sample
400dialoguesfromthethreeprojects.Thenweexcludedunreadable
dialogues: 1) Dialogues that are written in non-English languages;
2)Dialoguesthatcontaintoomuchcodeorstacktraces;3)Lowqual-
ity dialogues such as dialogues with many typos and grammatical
errors. 4) Dialogues that involve channel robots.
Step3:Ground-truthLabeling .Thelabeleddialoguesareused
astheground-truthdatasetformethoddefinitionandperformance
evaluation. To guarantee the correctness of the labeling results, we
builtaninspectionteam,whichconsistedtwoseniorresearchers
with four Ph.D candidates. All of them are fluent English speakers,
and have done either intensive research work with software devel-
opment or have been actively contributing to open-source projects.
Wedividedtheteamintotwogroups.Eachgroupconsistedaleader
(seniorresearcher)andtwomembers.Theleaderstrainedmembers
on how to label and provided consultation during the process. The
labeling results from the members were reviewed by the leaders
while results from the leaders were reviewed by other leaders. We
only acceptedand included dialogues toour dataset whenthe dia-
logues received full agreement among the groups. When an dialog
received different labeling results, we hosted a discussion with all
the six people to decide through voting.
Intotal,wecollected65,428dialoguesfromthreeopen-source
projects, and spent 720 person-hours on annotating 1,035 (1.6%)
dialogues. Thedetailed characteristics oflabeled dialogues arede-
scribed in Table 1. The last column ‚Äò#FR‚Äô denotes the number of
feature dialogues.
4.3 Experiment Settings
We conduct 3-fold cross-validation [ 31] on the dataset collected
from threeopen-source projects.We randomlydivide ourdataset
into3parts.Weuse2ofthosepartsfortrainingandreserveonepart
fortesting.Werepeatthisprocedure3timeseachtimereserving
a different part for testing. The experimental environment is a
desktop computer equipped with an NVIDIA 1060 GPU, intel core
i7 CPU, 16GB RAM, running on Ubuntu OS.
ExperimentI(RQ1) Toprovetheeffectivenessofourapproach,
we select two advanced sentence-wise approaches and four text
classification approaches as baselines. Detail information aboutbaselines will be introduced in section 4.4. For the two sentence-
wise approaches, we use the codes and models provided in the
publications.Forthefourtextclassificationapproaches,weusethe
codes provided by official released packages [ 19][14]. We apply
the random over-sampling [ 36] to tackle with imbalance dataset.
We extract the Term Frequency and Inverse Document Frequent
646(TFIDF)[ 27]asfeaturevectorsforeachdialog.Wetrainandfine-
tunehyper-parametersbygridsearchforthefourtextclassification
approaches to achieve their best performances.
ExperimentII(RQ2) Inthisexperiment,wecompareFRMiner
with p-FRMiner and investigate how does the data augment im-
provesperformance. Notethatp-FRMinerisdifferentwithFR-
Minerinthatp-FRMinerisaclassificationmodelforasingledialog
whichisbasedonthecontext-awaredialogmodel(introducedin
Section3.2)followingwithanadditionalclassificationlayer.The
architecture of FRMiner can be derived from p-FRMiner by the
following steps: 1) remove the top top-classification layer of p-
FRMiner;2)concatenatetheoutputsoftwop-FRMinerthatsharing
weights; 3) add a similarity layer. First, we use the same size of
datatotrainFRMinerandp-FRMiner,andobservetheperformance
enhancement.ThenweaugmentthetrainingdatasetofFRMiner
5, 10, 20, and 30 times to investigate the performance changes.
SinceFRMiner cantacklewithimbalanced datasetissueby apply-
ing the Siamese network while p-FRMiner can not, we balance the
samples by applying random over-sampling [ 36] when training
p-FRMiner. To ensure the correctness of our experiments, FRMinerandp-FRMineraretrainedwiththesamehyper-parameters,includ-
ingdimensionsforeachlayer,depthofthenetwork,andlearning
rate.
Experiment III (RQ3) To validate whether our approach is
generalizabletounfittedprojects,wetrainedtheFRMinerontwo
projects and evaluate on third projects. We also evaluate otherbaselines on the cross-project dataset with the identical hyper-
parameters of experiment II.
4.4 Baselines
To demonstrate the advantages of FRMiner, we compare FRMiner
with two advanced sentence-wise approaches as our baselines.
CNN-based Classifier (CNC) [25]. It is the state-of-the-art
learningtechniquetoclassifysentencesincommentstakenfrom
online issue reports. They proposed a convolution neural network
(CNN)basedapproachtoclassifysentencesintosevencategories
of intentions: Information Giving, Information Seeking, Feature
Request, Solution Proposal, Problem Discovery, Aspect Evaluation,
andMeaningless.WeutilizetheFeatureRequestcategorytopredict
dialogues that contain feature-request sentences as feature-request
dialogues.
Rule-basedClassifier(FRA) [55].Itisthestate-of-the-artrule-
basedtechniquetoclassifysentencesinfeaturerequestsfromonline
issue tracking systems. They proposed 81 fuzzy rules to classify
sentences into 6 types. We consider the dialogues that contain the
Intenttypeofsentencesarepredictedtobefeaturedialogues,and
dialogues do not contain the Intenttype of sentences are predicted
to be non-feature dialogues.
Machine-learning-basedClassifiers. NaiveBayesian(NB) [38]
is a simple generation model for text classification based on bag-of-words assumptions and Bayesian rules. It conducts the joint
probability of a sentence through prior probability and conditional
probability learned by the model and training data. Then, givena sentence, it can deduce the probabilities of all the taxonomies.
RandomForest(RF) [34]isanensemblemachinelearningmethod
that is constructed with several trees, and each tree can contribute
3UHFLVLRQ 5HFDOO )
Figure 5: The average performances in 3-fold validation
to the final classification result. Gradient Boosting Decision Tree
(GBDT)[29]isanotherkindofensemblemethod,andthedifference
withRFisthatitstreesaredecidedbytheresidualerrorbroughtby
theprevioustrees.WhentrainingGBDT,wesettheinitiallearning
as1.0andthemaxdepthoftreesas1.Wetrained100epochsfor
FT, and set the initial learning rate as 1 .0, the window size of input
n-gram as 2. FastText (FT) [28] is the state-of-the-art text classifica-
tion approach with a shallow neural network that is similar to the
architectureofword2vec[ 42].WhentrainingRF,wesetthemax
depth of trees as 2.
4.5 Performance Measures
WhenevaluatingtheeffectivenessofFRMinertowardsdetection
featurerequestsfromchatmessages,weusedthefollowingmetrics:
(1) Precision, which refers to the ratio of the number of correct
predictionsoffeaturedialoguestothetotalnumberofpredictionsof
featuredialogues;(2)Recall,whichreferstotheratioofthenumber
ofcorrectpredictionsoffeature dialoguestothetotalnumberof
featuredialoguesinthegoldentestset;and(3)F1-Score,whichis
the harmonic mean of precision and recall.
5 RESULTS AND ANALYSIS
5.1 Answering RQ1
Figure5presentstheaverageperformancesachievedbydifferent
approaches in 3-fold cross-validation, and Table 2 presents the de-
tailed performances for each project. The best results of precision,
recall, and F1-score are highlighted in bold. We can see that FR-
Miner achieves the best results for all the three projects, with an
averageof88.52%,88.50%,and88.51%inprecision,recall,andF1-
score. We also note that p-FRMiner performs better than all the
baselineapproaches,whichindicatesthatmemorizingcontextual
information in the BiLSTM dialog model can benefit the text classi-ficationtaskinchatmessages.Wefurtherevaluateandanalyzethe
improvement of FRMiner over p-FRMiner in section 5.2.
For the two sentence-wise approaches, the CNN based classi-
fiercanonlyachieve17.33%F1-scoreonaverage,mainlybecause
thattheCNCmodelistrainedbysufficientdatafromthedomain
of issue comments instead of feature dialogues. However, it still
achieves48.55%recallonaverage,whichindicatesthattheremight
be commonpatterns betweenthe two domains.Transfer learning
techniques might help transfer the related common knowledge
647Table 2: The performance achieved by different approaches for each project in intra-project validation
ApproachPerformance AngularJS Bootstrap Chromium
Precision Recall F1Precision Recall F1Precision Recall F1
OurapproachFRMiner 90.28% 89.73% 90.00% 86.28% 88.78% 87.52% 89.00% 87.00% 88.00%
p-FRMiner 31.71% 54.17% 40.00% 50.00% 47.80% 48.98% 14.00% 44.00% 20.00%
ExistingstudiesCNC 7.70% 44.44% 13.13% 16.38% 34.21% 22.13% 9.56% 67.00% 16.73%
FRA 13.67% 80.33% 23.35% 23.00% 48.67% 31.00% 12.00% 81.00% 20.00%
Text classificationNB 20.00% 27.67% 22.33% 25.67% 62.00% 36.00% 14.33% 44.33% 21.00%
GBDT 36.00% 22.33% 27.33% 41.67% 35.67% 38.33% 9.33% 7.33% 8.00%
RF 52.67% 11.00% 16.33% 57.00% 29.00% 38.33% 0.00% 0.00% NA
FT 23.33% 5.33% 8.67% 57.67% 29.00% 38.33% 38.00% 9.10% 15.00%
3UHFLVLRQ 5HFDOO )%RRWVWUDS
GLDORJV SDLUV
3UHFLVLRQ 5HFDOO )$QJXODU-6
GLDORJV SDLUV3UHFLVLRQ 5HFDOO )&KURPLXP
GLDORJV SDLUV
Figure 6: The comparison performances of p-FRMiner and FRMiner with the same volume of original training data.
œØœ≥œµ∆âƒÇ≈ù∆å∆êÕæ œ¥œ¨Õòœ¨œ±–π œ¥œ≠Õòœ≤œ≠–π œ¥œ¨Õòœ¥œÆ–π œ≠œ≠
œ±«Ü    œ∞œ≥
œ≠œ¨«Ü    œµœÆ
œÆœ¨«Ü    œ≠œ≥œ∞
œØœ¨«Ü    œÆœ±œ≤
œØœ∞œ¨ƒö≈ùƒÇ≈Ø≈Ω≈ê ∆êœ≠œ∞–π œ∞œ∞–π œÆœ¨–π œ≠
œØœ∞œ¨∆âƒÇ≈ù∆å∆êÕæ œ¥œØ–π œ¥œ≠–π œ¥œÆ–π œ≠œ¨œ±«Ü œ¥œ¥–π œ¥œ¥–π œ¥œ¥–π œØœ≥œ≠œ¨«Ü
   œ≤œµ
œÆœ¨«Ü    œ≠œØœ≥
œØœ¨«Ü    œÆœÆœ∞


[ [ [ [ [
PLQXWHV&KURPLXP
3UHFLVLRQ 5HFDOO ) WLPH

[ [ [ [ [%RRWVWUDS


[ [ [ [ [3HUIRUPDQFH$QJXODU-6
Figure 7: The performances of FRMiner when generating different numbers of pairs.
Table 3: The performance achieved by different approaches for each project in cross-project validation
AngularJS Bootstrap Chromium
ApproachPerformance
Precision Recall F1Precision Recall F1Precision Recall F1
FRMiner 85.23% 86.56% 85.89% 86.84% 85.89% 86.37% 85.87% 86.81% 86.34%Ourapproachp-FRMiner 31.03% 50.00% 38.30% 27.56% 69.08% 39.40% 16.00% 50.00% 24.24%
CNC 7.70% 44.44% 13.13% 16.38% 34.21% 22.13% 9.56% 67.00% 16.73%ExistingstudiesFRA 13.67% 80.33% 23.35% 23.00% 48.67% 31.00% 12.00% 81.00% 20.00%
NB 16.00% 75.00% 26.00% 27.00% 36.00% 31.00% 7.00% 26.00% 12.00%
GBDT 18.00% 14.00% 16.00% 30.00% 11.00% 16.00% 20.00% 19.00% 19.00%
RF 28.00% 14.00% 19.00% 37.00% 9.00% 15.00% 12.00% 26.00% 16.00%Text classification
FT 32.00% 19.00% 24.00% 43.00% 13.00% 20.00% 19.00% 11.00% 14.00%
from issue comments to chat messages by parameter-transfer and
fine-tuning [ 47]. Meanwhile, the rule-based classifier FRA achieves
the highest recall among the six baseline approaches. The averagerecall is 70.00%, and it achieves 80.33% and 81.00% recall on Angu-
larJSandChromiumprojectrespectively.Althoughtheprecisionis
low, prediction results of FRA contain most of the actual feature
648dialogues, which means that the feature-request sentences in chat
messagesalsocomplywithFRArules.AsFRAutilizesrulesinstead
of supervised learning, it is easier and time-saving to apply in min-
ingmassivechatmessages.Meanwhile,wecantakethehigh-recall
advantageofFRAtotacklewiththecoldstartproblemwhereno
annotated resources are provided in the beginning.
Fortextclassificationapproaches,NBseemstobethebestclassi-
fieramongallthetextclassificationbaselines.AlthoughRFachieves
thehighest27.33%F1-scoreonaverageamongthefourapproaches,
it encounters an underfitting problem on the Chromium project.
Itcanneithermodelthetrainingdatanorgeneralizetonewdata,
mainlyduetotheChromiumdataisnotlargeenoughforRFmodeltolearntherelevantpatterns.ThereasonswhyFRMinernoticeably
outperformsthefourtraditionaltextclassificationmodelsare:(1)
compared with traditional text-classifications, neural models have
alargercapacitywhichcanachievebetterperformances,especially
for the complex dialog modeling task. (2) it is easier for the model
to identify whether two dialogues belong to the same class thanclassifying every single dialog. (3) text classification algorithmsare not trained sufficiently from the small dialog datasets, whileFRMiner is a pair-wise approach that can augment the original
dataset dramatically which ensures the training to be sufficient.
Summary: FRMiner significantly outperforms two sentence-
wisebaselinesandfourtraditionaltextclassificationapproaches.
As the two sentence-wise baselines can be directly applied to chat
messages and achieve relatively good recall, they have the natural
advantages over other approaches under the cold-start situation.
5.2 Answering RQ2
Figure6demonstratestheperformanceofp-FRMinertrainingby
single-dialogueinstancesandtheperformancesofFRMinertrain-
ingbythesamesizesofpair-dialogueinstances.Thebluecolumn
denotes the size of the training dataset for p-FRMiner, which isthe size of 2 folds of data. The orange column denotes the sizeof pair-instances generated by the Siamese network. We can see
that when the sizes of training datasets are the same, FRMiner can
achieve much higher performances than p-FRMiner. The FRMiner
improves the Precision, Recall, F1-score over the p-FRMiner by
46.79%, 31.13%, 42.90% on average.
Figure 7 illustrates the relationship between performance en-
hancementandtrainingpair-instancesquantity,alongwiththetime
cost on the training phase. The initial volumes (1x) are the original
sizesoftrainingdatashowninFigure6,whichare379,316,and340
pairs. We can see that enlarging the size of training pair-instances
can moderately increase the model performances. When enlarging
the size of the training pair-instances from 1 to 30 times, the preci-
sion, recall, and F1-score increase 9.82%, 8.72%, and 9% on average.
Weobservethattheperformancesharplyincreaseswhenenlarging
thetrainingdataset5times,andslowlyincreasesfrom5timesto
30 times on all the projects. The performances of the Chromiumproject even slightly decline when enlarging by 20 times. While
thetimecostonthetrainingphaseislinearlyincreasedallthetime.
Therefore,weconsiderthatenlargingthetrainingdataset5times
might be a trade-off choice between effectiveness and efficiency.
Summary : FRMiner can better resolve the classification task
than p-FRMiner by significantly improving the Precision, Recall,F1-score by 46.79%, 31.13%, 42.90% on average. The results confirm
thatitiseasierforthemodeltorecognizewhethertwodialogues
belong to the same class rather than classifying the exact class
directlywhenlabeleddialoguesarefew.Weconsider5timestobea
trade-off choice between effectiveness and efficiency because after
enlarging the training dataset 5 times, the performances slowly
increase but the time cost rises largely.
5.3 Answering RQ3
Figure8presentstheaverageperformancesachievedbydifferent
approaches in the setting of cross-project validation, and Table3 presents the detailed performances for each project. The bestresults of precision, recall, and F1-score are highlighted in bold.Note that the performances of CNC and FRA are the same with3-foldintra-projectvalidationduetothetwoapproachesarenot
trained by feature dialogues. We repeat their results in Table 2 for
comparison and analysis purposes.
We can see that FRMiner can also perform well in cross-project
settings. Performance only slightly declines by 2.27% over average
F1-scores compared with the result in intra-project validation. We
consider that dialogues expressing feature-requests share common
linguistic patterns across domains that are typically notrelevant
with domain-specific concepts. The results show that FRMiner can
learn these common patterns and be generalized to other projects.
It indicates that developers express feature requests in a similar
way even in different communities and projects, and the feature
dialogues of different projects share similar patterns. We note that
p-FRMiner doesnot performas good aswithin-project validation.
The average F1-score declines 10.51%.
Fortextclassificationapproaches,NBachievesthehighestF1-
score of 23%, and it only slightly declines 3.44% on average com-
paredwithwithin-projectvalidation.Noneofthetextclassification
approaches encounter an underfitting problem because the size of
the training dataset for cross-project validation is larger. In addi-tion, we notice that most text classification approaches perform
betterin cross-projectevaluation thaninintra-project evaluation
forAngularandChromium.Itismainlyduetotworeasons:(1)The
cross-project training dataset involves two-project datawhile the
intra-projectonlyhas2/3dataofoneproject.Trainingwithamuch
largerdatasetresultsinamorerobustclassifier.(2)Cross-project
evaluation imports two projects for training while intra-project
evaluationonlyhasoneproject.Thewiderscopeoftrainingdataset
wouldincreasethegeneralizabilityoftheclassifierduetothebiased
knowledge introduced by different projects.
Summary : FRMiner can also achieve high performance on un-
fitted projects, which indicates that FRMiner is generalizable to
otherprojects.WealsoobservethatNBisthebestclassifieramong
all the text classification baselines towards mining chat messages.

3UHFLVLRQ 5HFDOO )
Figure 8: Average performances in cross-project validation
649,
6 DISCUSSIONS
Applicability. Ourworkcanbenefitingatheringcrowdrequire-
mentsbyconvenientlyintegratingFRMinerintotheworkflowof
therelease-teammembers.First,thereleaseteamcouldbuildachat-
message monitor or a crawler to collect the textual conversation
from the organization‚Äôs chatting platform periodically. Then an
automaticscript[ 33]isapplied topreprocessanddisentanglethe
rawchattingtext.Afterthat,byperformingtheinferenceprocess
mentionedinsection3.4onthedisentangleddialogues,FRMiner
can record all the dialogues that are likely to request features. The
releaseteamcouldalsosubscribetothemonitoringresultsasanRSS feed to receive hidden feature requests periodically. Besides,due to people expressing feature dialogues in a relatively consis-tent way, FRMiner users do not need to retrain the model quite
frequently. The retraining mainly need to be performed when the
amount or the quality of the dataset changes extraordinarily.
Extendibility. We notice that people express feature dialogues
inarelativelyconsistentway,forexample,otherthanchattingmes-sages,peoplealsousesimilarexpressionssuchas‚Äúneedimplementsth.innextrelease version‚Äùand‚Äústh.willb easolution/improvement‚Äù,
to indicate feature requests in other open-source platforms includ-
ingGithubIssuesanddevelopmentemails.Hence,wearguethat
our approach can be extended to other data sources. In addition,
FRMiner can be applied to the other languages since our deep con-
textual dialog model has a strong ability in capturing semantic
patterns. When switching to other languages, FRMiner users need
to adapt the pre-trained word embedding model to the specific
language. They also need to consider to apply extra preprocessing
accordingtothespecificlanguage,e.g.,applywordsegmentationtoChinesecorpus.AnotherlimitationofFRMineronlanguageswitch-ingisrelatedtothepre-traineddialoguesdisentanglementmodel.A
new dataset needs to be annotated for retraining the model, which
may involve a relatively high cost.
7 THREATS TO VALIDITY
ExternalValidity .Theexternalthreatsrelatetothegeneralizabil-
ityoftheproposedapproach.Allthethreesystemsexaminedinthis
workwereopen-sourceprojects,whichmightnotberepresentative
of closed-source projects. It is also possible that we accidentally
chosesystemsthathavebetterorworsethanaveragecross-projectfeaturerequestsdetectionperformance.However,thecross-project
evaluationresultsshowthatour approachisgeneralizableonthe
three studied projects, which largely alleviates the threat.
InternalValidity .Theinternalthreatsrelatetoexperimental
errorsandbiases.Threatstointernalvaliditymaycomefromthe
results of conversation disentanglement. The accuracy of disen-tangled conversations has impact on our results. To reduce thethreat, when separating single conversations in a stream of chatmessages, we employed the state-of-the-art technique proposed
byKummerfeld etal. [ 33],which outperformsprevious studiesby
achieving 73.5% F1-score and 91.5 VI2.
ConstructValidity .Theconstructthreatsrelatetothesuitabil-
ityofevaluationmetrics.Weutilizeprecisionandrecalltoevaluate
theperformance,inwhichweusethemanuallylabeleddialogues
2Variation of Information (VI) is a measure of information gained or lost when going
from one clustering to anotheras ground-truth when calculating the performance metrics. Thethreats might come from the process of manual inspection and
tagging.Weunderstandthatsuchaprocessissubjecttomistakes.
Toreducethatthreat,webuildtwoinspectionteamstoreachagree-
ments on different options.
8 RELATED WORK
Ourworkisrelatedtopreviousstudiesthatfocusedon(1)detection
of feature requests; and (2) mining development communication
artifacts. We briefly review the recent works in each category.
8.1 Detection of Feature Requests
Theamountofresearchongatheringandanalyzinginformation
fromacrowdtoderivevalidateduserrequirements/featurerequests
has increased significantly in the last years.
DiSorboetal.[ 58]proposedataxonomyofintentionstoclas-
sify sentences in developer mailing lists into six categories: feature
request,opinionasking,problemdiscovery,solutionproposal,in-
formationseeking,andinformationgiving.Althoughthetaxonomyhasbeenshowntobeeffectiveinanalyzingdevelopmentemailsand
userfeedbackfromapp reviews[ 48],Huangetal. [ 25]foundthat
itcannotbegeneralizedtodiscussionsinissuetrackingsystems,and they addressed the deficiencies of Di Sorbo et al‚Äôs taxonomy
byproposingaconvolutionneuralnetwork(CNN)-basedapproach.
Arya et al. [ 6] identified 16 information types including poten-
tial new feature requests through quantitative content analysisof 15 issue discussion threads. They also provided a supervised
classificationsolutionbyusingRandomForestwith14conversa-
tionalfeaturesthatcanclassifysentencesexpressingnewfeature
requestswith0.66F1-score.Morales-Ramirezetal.[ 43,44]identi-
fied requirement-related information in OSS issue discussion using
20speech-actrulessupportedbyNLPandlinguisticparsingtech-
niques. Merten et al.[40] investigated natural language processing
andmachinelearningfeaturestodetectsoftwarefeaturerequestsin
issue tracking systems. Their results showed that software feature
requests detection can be approached on the level of issues and
datafieldswithsatisfactoryresults.Merten etal.[41]alsoinvesti-
gatedhowrequirementscommunicatedinissuetrackingsystems
bymanuallyreviewing200issues.Theycategorizedthetextand
reportedonthedistributionofissuetypesandinformationtypes.
Theirresultsshowedthatinformationwithrespecttoprioritization
and scheduling can be found in natural language data. Herzig et
al.[22] manually examined more than 7,000 issue reports, and dis-
cussed the impact of misclassification of bugs in the bug databases
of five open source projects. Their results showed that 39% of files
marked as defective actually new features, updates to documen-
tation,orinternalrefactoring.Theauthorssuggestedthathuman
should always be involved when dealing with the posted issues.
Antoniol etal.[5]investigatedwhetherthetextoftheissuesposted
in bug tracking systems is enough to classify them into correctivemaintenanceandother kindsofactivities.They alternatedamong
various machine learning approaches such as decision trees, naive
Bayes classifiers, and logistic regression to distinguish enhance-mentapartfromother issuespostedin thesystem.Shietal.[
55]
proposed81fuzzyrulesthatcanclassifysentencesinissuesinto
six categories: intent, benefit, drawback, example, explanation, and
650trivia.Theirworkdesignedtohelpunderstandingandanalyzing
realintentsoffeaturerequests,whichcanalsobenefitthedetection
offeaturerequests.Rodeghero etal.[39]presentedanautomated
technique that extracted useful information from the transcripts
ofdeveloper-clientspoken conversationstoconstructuserstories.
Theyusedmachinelearningclassifierstodeterminewhetheracon-
versation contains user story information or not. Maalej and Nabil
[37]leveragedprobabilistictechniquesaswellastextclassification,
natural language processing, and sentiment analysis techniques to
classifyappreviewsintobugreports,featurerequests,userexpe-
riences, and ratings. Their results showed that the classification
can reach the precision between 70-95% and recall 80-90% actual
results.Otherstudieshavebeenfoundtoalsocaptureuserneeds
from app reviews automatically [ 13,26,46,62]. Vlas and Robinson
[63] proposed a grammar-based design of software automation for
the discovery and classification of natural language requirements
foundinopensourceprojectsrepositories.Cledland-Huang etal.
[12] designed an automated forum management (AFM) system,
which was used to automated detect duplicated feature requests
that have been already posted in the issue tracking systems. Shi et
al.[54] proposed an initial approach to automated identify feature
requests that ask for features that have been already implemented
by applying feature tree model. Summing up, previous approaches
differ from our work as it: identified feature requests from develop-mentemails[
25,58];identifiedfeaturerequestsfromissuetracking
systems [ 5,6,22,40,41,43,44,55]; identified user stories from
spoken conversations [ 39]; identified feature requests from app
reviews [13,37,46,48,62]; identified feature requests from project
repositories [63] detected duplicated feature requests [12] [54].
Our work differs from existing researches in that we focus on
detectinghiddenfeaturerequestsfromchatmessageswhichpost
differentchallengesaschatmessagesareinformal,unstructured,noisy and typically have insufficient labeled data than the previ-
ouslyanalyzeddocuments.Inaddition,ourworkcomplementsto
the existing studies on automated feature requests detection.
8.2 Mining Development Communication
Artifacts
Previousresearchesondevelopmentcommunicationartifactsre-
portedthattheusageofonlinechattingplayanincreasinglysignif-
icantroleinsoftwaredevelopment,andchatmessagesarearich
sourceforvaluableinformationaboutthesoftwaresystem.Linet
al. [35] conducted an exploratory study on how developers use
Slack,whichisapopularworkplacechatapp,andhowtheybenefit
fromit.TheirresearchrevealedthatdevelopersuseSlackforper-
sonal,team-wide, andcommunity-wide purposes,andSlack plays
an increasingly significant role in software development, replacing
email in some cases. Shihab et al. [ 56,57] analyzed the usage of
developer IRC meeting channels of two large open source projects
from several dimensions: meeting content, meeting participates,theircontribution,andmeetingstyles.Theirresultsshowedthat
IRCmeetingsaregainingpopularityamongopensourcedevelop-
ers,andhighlightedthewealthofinformationthatcanbeobtained
from developer chat messages. Yu et al. [ 66] analyzed the usage of
twocommunicationmechanismsinglobalsoftwaredevelopment
projects, which are synchronous (IRC) and asynchronous (mailinglist).Theirresultsshowedthatdevelopersactivelyusebothcommu-nication mechanisms in a complementary way. Chatterjee et al.[
9]
conductedanexploratorystudytoinvestigatetheusefulnessand
challengesofminingdeveloperconversationsforsupportingsoft-
waremaintenanceandevolution.Theyobservedthatdevelopers
are likely to share opinions and interestinginsights on tool usage,
best practices,and various technologiesvia instant conversations.
Theyalsoreportedthatitisfeasibletoachievehighaccuracyindis-
entanglingconversationsbyadaptingthetechniquesandtraining
sets. Alkadhi et al. [ 3,4] identified five rationale elements which
areissue,alternative,pro-argument,con-argument,anddecision
fromchatmessagesthatcollectedfromthreestudentprojects.They
developed two supervised classifiers to automated detect rationale
elements on the manually labeled data. Wood et al. [ 65] discovered
26speechacttypesinthechatconversationsduringbugrepair,and
trained a supervised classifier to automatically detect these speech
acts.ChowdhuryandHindle[ 11]implementedmachinelearning
techniquestofilteroutoff-topicdiscussionsinprogrammingIRC
channels by engaging StackOverflow discussions as positive exam-
plesandYouTubevideocommentsasoff-topicdiscussionexamples.
The findings of previous work motivates the work presented in
thispaper.Ourstudyisdifferentfromthepreviousworkaswefocusondetectingfeaturerequestshiddeninmassivechatmessagesthat
wouldbeimportantand valuableinformationforOSSdevelopers
to enhance their software.
9 CONCLUSION AND FUTURE WORK
Inthispaper,weproposedanovelapproach,namedFRMiner,which
can detect feature dialogues from chat messages via deep Siamese
network.InFRMiner,weincorporatedtwoBiLSTM-baseddialog
models with the Siamese network to learn the similarity between a
pair of dialogues rather than the class of a specific dialog. We eval-
uatedFRMineronasmallsampleof1,035dialoguestakenfromthe
high-volume chat messages of three popular open-source projects.
Theexperimentalresultsshowedthatourapproachsignificantly
outperformed two sentence-wise classifiers and four traditional
text classification approaches with average precision, recall and F1-
score of 88.52%, 88.50%. and 88.51%. FRMiner can also achieve high
performance on unfitted projects, which indicated that FRMiner is
generalizabletootherprojects.Theexperimentalresultsconfirmed
that our approach could effectively detect hidden feature requests
from chat messages. We also observed that NB seems to be the
best classifier for chat messages among the four text classification
baselines. In the future, we plan to employ NLP summarization
technologies with our approach to extract a brief summary for de-
velopers, which can reduce the effort on reading feature dialogues.
Moreover, we plan to extend this work by not only classifying but
alsorecordingfeaturerequestsinawell-designedandstructured
format from chat messages.
10 ACKNOWLEDGMENTS
This work is supported by the National Key Research and Devel-
opment Program of China under grant No.2018YFB1403400, theNational Science Foundation of China under grant No.61802374,
No.61432001, No.61602450.
651REFERENCES
[1] 2019. echelog. https://echelog.com/.
[2] Explosion AI. 2019. Spacy. https://spacy.io/.[3]
Rana Alkadhi, Teodora Lata, Emitza Guzmany, and Bernd Bruegge. 2017. Ra-
tionale in Development Chat Messages: an Exploratory Study. Mining Software
Repositories (2017), 436‚Äì446.
[4]RanaAlkadhi,ManuelNonnenmacher,EmitzaGuzman,andBerndBruegge.2018.
How do developers discuss rationale?. In 2018 IEEE 25th International Conference
on Software Analysis, Evolution and Reengineering (SANER). IEEE, 357‚Äì369.
[5]Giuliano Antoniol, Kamel Ayari, Massimiliano Di Penta, Foutse Khomh, and
Yann-Ga√´l Gu√©h√©neuc. 2008. Is It a Bug or an Enhancement?: a Text-based
ApproachtoClassifyChangeRequests.In Proceedingsofthe2008conferenceof
the centerfor advancedstudieson collaborativeresearch: meetingof minds.ACM,23.
[6]
Deeksha Arya, Wenting Wang, Jin L. C. Guo, and Jinghui Cheng. 2019. Analysis
and detection of information types of open source software issue discussions.
InProceedings ofthe41st InternationalConference onSoftware Engineering,ICSE
2019, Montreal, QC, Canada, May 25-31, 2019. 454‚Äì464.
[7]JamesBergstra andYoshua Bengio.2012. RandomSearch forHyper-Parameter
Optimization. Journal of Machine Learning Research 13, 1 (2012), 281‚Äì305.
[8]Jane Bromley, Isabelle Guyon, Yann LeCun, Eduard S√§ckinger, and Roopak Shah.
1994. Signature verification using a" siamese" time delay neural network. In
Advances in neural information processing systems. 737‚Äì744.
[9]Preetha Chatterjee, Kostadin Damevski, Lori Pollock, Vinay Augustine, and
NicholasAKraft.2019. ExploratorystudyofslackQ&Achatsasaminingsourceforsoftwareengineeringtools.In Proceedingsofthe16thInternationalConference
on Mining Software Repositories. IEEE Press, 490‚Äì501.
[10]Wei-Yu Chen,Yen-Cheng Liu,ZsoltKira,Yu-ChiangWang, andJia-BinHuang.
2019. ACloserLookatFew-shotClassification.In InternationalConferenceon
Learning Representations.
[11]Shaiful Alam Chowdhury and Abram Hindle. 2015. Mining StackOverflow to
filter out off-topic IRC discussion. (2015), 422‚Äì425.
[12]Jane Cleland-Huang, Horatiu Dumitru, Chuan Duan, and Carlos Castro-Herrera.
2009. Automated Support for Managing Feature Requests in Open Forums.
Commun. ACM 52, 10 (2009), 68‚Äì74.
[13]AndreaDiSorbo,SebastianoPanichella,CarolV.Alexandru,JunjiShimagaki,Cor-
rado A. Visaggio, Gerardo Canfora, and Harald C. Gall. 2016. What Would Users
Change in My App? Summarizing App Reviews for Recommending Software
Changes. In Proceedings of the 2016 24th ACM SIGSOFT International Symposium
on Foundations of Software Engineering. 499‚Äì510.
[14] Facebook. 2019. FastText. https://fasttext.cc/.[15] Facebook. 2019. PyTorch. https://pytorch.org/.[16]
Allen Institute for Artificial Intelligence. 2019. AllenNLP. https://allennlp.org/.
[17] Google. 2019. AngularJS. https://angularjs.org/.[18] Google. 2019. Chromium. https://www.chromium.org/.[19] Google. 2019. Scikit-Learn. https://scikit-learn.org/.[20]
Alex Graves, Abdel-rahman Mohamed, and Geoffrey Hinton. 2013. Speechrecognition with deep recurrent neural networks. In 2013 IEEE international
conference on acoustics, speechand signal processing . IEEE, 6645‚Äì6649.
[21]Eduard C Groen, Norbert Seyff, Raian Ali, Fabiano Dalpiaz, Joerg Doerr, Emitza
Guzman,MahmoodHosseini,JordiMarco,MarcOriol,AnnaPerini,etal .2017.
The Crowd in Requirements Engineering: The Landscape and Challenges. IEEE
Software34, 2 (2017), 44‚Äì52.
[22]Kim Herzig, Sascha Just, and Andreas Zeller. 2013. It‚Äôs not a bug, it‚Äôs a fea-ture: How Misclassification Impacts Bug Prediction. In Proceedings of the 2013
International Conference on Software Engineering. IEEE Press, 392‚Äì401.
[23]SeppHochreiterandJ√ºrgenSchmidhuber.1997. Longshort-termmemory. Neural
computation 9, 8 (1997), 1735‚Äì1780.
[24]Anna Huang. 2008. Similarity measures for text document clustering. In Pro-
ceedings of the sixth new zealand computer science research student conference
(NZCSRSC2008), Christchurch, New Zealand, Vol. 4. 9‚Äì56.
[25]QiaoHuang,XinXia,DavidLo,andGailC.Murphy.2018. AutomatingIntention
Mining.IEEE Transactions on Software Engineering PP, 99 (2018), 1‚Äì1.
[26]NishantJhaandAnasMahmoud.2017. MiningUserRequirementsfromApplica-
tion Store Reviews Using Frame Semantics. (2017), 273‚Äì287.
[27]Thorsten Joachims. 1996. A Probabilistic Analysis ofthe Rocchio Algorithm with
TFIDFforTextCategorization. TechnicalReport.Carnegie-mellonunivpittsburgh
pa dept of computer science.
[28]Armand Joulin, Edouard Grave, Piotr Bojanowski, Matthijs Douze, H√©rve J√©gou,
and Tomas Mikolov. 2016. Fasttext. zip: Compressing text classification models.arXiv preprint arXiv:1612.03651 (2016).
[29]
Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma,
Qiwei Ye, and Tie-Yan Liu. 2017. Lightgbm: A highly efficient gradient boostingdecision tree. In Advances in Neural Information Processing Systems . 3146‚Äì3154.
[30]YoonKim.2014. Convolutionalneuralnetworksforsentenceclassification. arXiv
preprint arXiv:1408.5882 (2014).[31]Ron Kohavi. 1995. A Study of Cross-Validation and Bootstrap for AccuracyEstimation and Model Selection. In Proceedings of the Fourteenth International
Joint Conference on Artificial Intelligence, IJCAI 95, Montr√©al Qu√©bec, Canada,
August 20-25 1995, 2 Volumes. 1137‚Äì1145.
[32]AlexKrizhevsky,IlyaSutskever,andGeoffreyEHinton.2012. Imagenetclassifica-tion with deep convolutional neural networks. In Advances in neural information
processing systems. 1097‚Äì1105.
[33]JonathanK.Kummerfeld,SaiR.Gouravajhala,JosephPeper,VigneshAthreya,
Chulaka Gunasekara, Jatin Ganhotra, Siva Sankalp Patel, Lazaros Polymenakos,
and Walter S. Lasecki. 2019. A Large-Scale Corpus for Conversation Disen-tanglement. In Proceedings of the 57th Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers).
[34]AndyLiaw,MatthewWiener,etal .2002. Classificationandregressionbyran-
domForest. Rn e w s2, 3 (2002), 18‚Äì22.
[35]BinLin,AlexeyZagalsky,Margaret-AnneD.Storey,andAlexanderSerebrenik.
2016. WhyDevelopersAreSlackingOff:UnderstandingHowSoftwareTeams
Use Slack. In Proceedings of the 19th ACM Conference on Computer Supported
Cooperative Work and Social Computing. 333‚Äì336.
[36] Charles X Ling and Chenghui Li. 1998. Data mining for direct marketing: Prob-
lems and solutions.. In Kdd, Vol. 98. 73‚Äì79.
[37]Walid Maalej and Hadeer Nabil. 2015. Bug report, Feature request, or Simply
Praise?onAutomaticallyClassifyingAppReviews.In 2015IEEE23rdinternational
requirements engineering conference (RE). IEEE, 116‚Äì125.
[38]Andrew McCallum, Kamal Nigam, et al .1998. A comparison of event models
for naive bayes text classification. In AAAI-98 workshop on learning for text
categorization, Vol. 752. Citeseer, 41‚Äì48.
[39]CollinMcmillan,CollinMcmillan,CollinMcmillan,andCollinMcmillan.2017.
Detecting User Story Information in Developer-client Conversations to Gen-erate Extractive Summaries. In Ieee/acm International Conference on Software
Engineering. 49‚Äì59.
[40]ThorstenMerten,Mat√∫≈°Falis,PaulH√ºbner,ThomasQuirchmayr,SimoneB√ºrsner,
and Barbara Paech. 2016. Software Feature Request Detection in Issue Tracking
Systems.In RequirementsEngineeringConference(RE),2016IEEE24thInternational.
IEEE, 166‚Äì175.
[41]Thorsten Merten, Bastian Mager, Paul H√ºbner, Thomas Quirchmayr, Barbara
Paech, and Simone B√ºrsner. 2015. Requirements Communication in Issue Track-
ing Systems in Four Open-Source Projects.. In REFSQ Workshops. 114‚Äì125.
[42]TomasMikolov,IlyaSutskever,KaiChen,GregSCorrado,andJeffDean.2013.
Distributed representations of words and phrases and their compositionality. In
Advances in neural information processing systems. 3111‚Äì3119.
[43]Itzel Morales-Ramirez, Fitsum Meshesha Kifetew, and Anna Perini. 2017. Analy-
sis of Online Discussions in Support of Requirements Discovery. In Advanced
Information Systems Engineering. 159‚Äì174.
[44]ItzelMorales-Ramirez,FitsumMesheshaKifetew,andAnnaPerini.2018. Speech-acts based analysis for requirements discovery from online discussions. Informa-
tion Systems (2018).
[45]JonasMuellerandAdityaThyagarajan.2016. Siameserecurrentarchitectures
for learning sentence similarity. In Thirtieth AAAI Conference on Artificial Intelli-
gence.
[46]Fabio Palomba, Mario Linares V√°squez, Gabriele Bavota, Rocco Oliveto, Massim-
ilianoDiPenta,DenysPoshyvanyk,andAndreaDeLucia.2015. UserReviews
Matter!TrackingCrowdsourcedReviewstoSupportEvolutionofSuccessfulApps.
In2015 IEEE International Conference on Software Maintenance and Evolution,
ICSME 2015, Bremen, Germany, September 29 - October 1, 2015. 291‚Äì300.
[47]Sinno Jialin Pan and Qiang Yang. 2010. A Survey on Transfer Learning. IEEE
Transactions on Knowledge and Data Engineering 22, 10 (2010), 1345‚Äì1359.
[48]Sebastiano Panichella, Andrea Di Sorbo, Emitza Guzman, Corrado Aaron Vis-
aggio,GerardoCanfora,andHaraldCGall.2015. Howcaniimprovemyapp?
Classifyinguserreviewsforsoftwaremaintenanceandevolution. (2015),281‚Äì
290.
[49]Jeffrey Pennington, Richard Socher, and Christopher Manning. 2014. Glove:
Globalvectorsforwordrepresentation.In Proceedingsofthe2014conferenceon
empirical methods in natural language processing (EMNLP). 1532‚Äì1543.
[50]Ant√¥nio Mauricio Pitangueira, Paolo Tonella, Angelo Susi, Rita Suzana Pi-tangueira Maciel, and M√°rcio de Oliveira Barros. 2017. Minimizing the Stake-
holder DissatisfactionRisk inRequirement Selectionfor NextRelease Planning.
Information & Software Technology 87 (2017), 104‚Äì118.
[51]Germ√°n Poo-Caama√±o, Eric Knauss, Leif Singer, and Daniel M German. 2017.
Herding cats in a FOSS ecosystem: a tale of communication and coordination forrelease management. Journal of Internet Services and Applications 8, 1 (2017), 12.
[52]Lutz Prechelt. 1998. Early stopping-but when? In Neural Networks: Tricks of the
trade. Springer, 55‚Äì69.
[53] Scrapinghub. 2019. Scrapy. https://scrapy.org/.[54]
Lin Shi, Celia Chen, Qing Wang, and Barry W. Boehm. 2016. Is It a New Feature
or Simply "Don‚Äôt Know Yet"?: OnAutomatedRedundant OSS Feature Requests
Identification. In 24th IEEE International Requirements Engineering Conference,
RE 2016, Beijing, China, September 12-16, 2016. 377‚Äì382.
652[55]Lin Shi, Celia Chen, Qing Wang, Shoubin Li, and Barry W Boehm. 2017. Under-
standing feature requests by leveraging fuzzy method and linguistic analysis.
automated software engineering (2017), 440‚Äì450.
[56]Emad Shihab, Zhen Ming Jiang, and Ahmed E. Hassan. 2009. On the use of
Internet Relay Chat (IRC) meetings by developers of the GNOME GTK+ project.
InProceedings of the 6th International Working Conference on Mining Software
Repositories, MSR 2009 (Co-located with ICSE), Vancouver, BC, Canada, May 16-17,
2009, Proceedings. 107‚Äì110.
[57]EmadShihab,ZhenMingJiang,andAhmedE.Hassan.2009. Studyingtheuse
of developer IRC meetings in open source projects. In 25th IEEE International
ConferenceonSoftwareMaintenance(ICSM2009),September20-26,2009,Edmonton,
Alberta, Canada. 147‚Äì156.
[58]Andrea Di Sorbo, Sebastiano Panichella, Corrado Aaron Visaggio, Massim-
iliano Di Penta, Gerardo Canfora, and Harald C. Gall. 2015. DevelopmentEmails Content Analyzer: Intention Mining in Developer Discussions (T). In
30th IEEE/ACM International Conference on Automated Software Engineering, ASE
2015, Lincoln, NE, USA, November 9-13, 2015. 12‚Äì23.
[59]Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan
Salakhutdinov.2014. Dropout:asimplewaytopreventneuralnetworksfrom
overfitting. The journal of machine learning research 15, 1 (2014), 1929‚Äì1958.
[60] Bootstrap Team. 2019. Bootstrap. https://getbootstrap.com/.[61]Jos√©Apolin√°rioTeixeiraandHelenaKarsten.2019. Managingtoreleaseearly,often and on time in the OpenStack software ecosystem. Journal of Internet
Services and Applications 10, 1 (2019), 7.
[62]LorenzoVillarroel,GabrieleBavota,BarbaraRusso,RoccoOliveto,andMassimil-iano Di Penta. 2016. Release Planning of Mobile Apps based on User Reviews. In
Proceedings of the 38th International Conference on Software Engineering. 14‚Äì24.
[63]RaduEVlasand WilliamNRobinson.2012. TwoRule-basedNaturalLanguage
StrategiesforRequirementsDiscoveryandClassificationinOpenSourceSoft-
wareDevelopmentProjects. Journalofmanagementinformationsystems 28,4
(2012), 11‚Äì38.
[64]Yaqing Wang and Quanming Yao. 2019. Few-shot learning: A survey. arXiv
preprint arXiv:1904.05046 (2019).
[65]Andrew Wood, Paige Rodeghero, Ameer Armaly, and Collin McMillan. 2018.
Detectingspeech acttypesindeveloperquestion/answerconversationsduring
bugrepair.In Proceedingsofthe2018ACMJointMeetingonEuropeanSoftware
EngineeringConferenceandSymposiumontheFoundationsofSoftwareEngineering,
ESEC/SIGSOFT FSE. 491‚Äì502.
[66]Liguo Yu,Srini Ramaswamy, AlokMishra, andDeepti Mishra. 2011. Communi-cationsinGlobalSoftware Development:AnEmpiricalStudyUsingGTK+OSS
Repository. In Proceedings of the 2011th Confederated International Conference on
the Move to Meaningful Interest Systems, OTM‚Äô11 . 218‚Äì227.
653