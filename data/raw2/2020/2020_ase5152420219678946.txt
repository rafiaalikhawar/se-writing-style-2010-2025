Adversarial Attacks to API Recommender Systems:
Time to Wake Up and Smell the Coffee?
Phuong T. Nguyen, Claudio Di Sipio, Juri Di Rocco
University of L‚ÄôAquila, Italy
{phuong.nguyen, claudio.disipio, juri.dirocco}@univaq.itMassimiliano Di Penta
University of Sannio, Italy
dipenta@unisannio.itDavide Di Ruscio
University of L‚ÄôAquila, Italy
davide.diruscio@univaq.it
Abstract ‚ÄîRecommender systems in software engineering pro-
vide developers with a wide range of valuable items to help
them complete their tasks. Among others, API recommendersystems have gained momentum in recent years as they becamemore successful at suggesting API calls or code snippets. Whilethese systems have proven to be effective in terms of predictionaccuracy, there has been less attention for what concerns suchrecommenders‚Äô resilience against adversarial attempts. In fact,by crafting the recommenders‚Äô learning material, e.g., data fromlarge open-source software (OSS) repositories, hostile users maysucceed in injecting malicious data, putting at risk the softwareclients adopting API recommender systems. In this paper, wepresent an empirical investigation of adversarial machine learn-ing techniques and their possible inÔ¨Çuence on recommendersystems. The evaluation performed on three state-of-the-art APIrecommender systems reveals a worrying outcome: all of themare not immune to malicious data. The obtained result triggersthe need for effective countermeasures to protect recommendersystems against hostile attacks disguised in training data.
Index T erms‚ÄîRecommender systems; API Mining; Adversar-
ial Machine Learning; Adversarial Attacks
I. I NTRODUCTION
In recent years, several recommender systems for software
engineering (RSSE) have been conceptualized to support de-
velopers in their task and, possibly, reduce the increasinginformation overload originating from the availability of datafrom various sources [13], [20], [34], [35], [39], [46]. Arelevant example of RSSE is represented by API recommendersystems, which provide developers with function calls and/orcode snippets being beneÔ¨Åcial to their coding tasks [33],[40], [49]. Such systems learn their recommendations (of codesnippets or APIs) from external sources such as code bases,e.g., GitHub or communication channels, e.g., Stack OverÔ¨Çow.Since these sources are open for changes and contributionsby the crowd, the recommenders‚Äô learning material mightbe exposed to malicious attacks [63]. In other words, thesesources can be exploited to fool API recommender systems.
Adversarial attempts generate perturbations to deceive and
disrupt systems by causing a malfunction, compromising theirrecommendation capabilities. For instance, an adversarial at-tack to recommender systems, depending on the intent, canfavor or defame an item, thus creating a negative impact onthe Ô¨Ånal recommendations [21]. Similarly, by manipulatingtraining data available in OSS platforms, hostile users mayrender recommender systems vulnerable to harmful artifacts.If a recommender is trained to provide malicious APIs orsnippets, this can trigger disruptions to a software system.For example, a recent work [60] shows that there have beenattempts using toxic code to secretly force Android apps toopen ports, allowing for unauthorized access.
Research on Adversarial Machine Learning [24], [56]
(AML) studies security issues in Machine Learning systemsas well as general-purpose recommender systems [12]. So far,AML has been investigated in different domains, e.g., onlinesystems [31], image classiÔ¨Åcation [37], and addresses boththreats and countermeasures [2], [59]. However, to the best ofour knowledge, the issue of AML in recommender systemsremains unexplored in software engineering.
In this paper, we provide a Ô¨Årst empirical investigation into
the relevance and effects of AML in RSSE. First, througha literature analysis on 14 premier venues in software engi-neering, we show that there has been no work to study theissue of AML in RSSE. Afterwards, we present a qualitativeanalysis of state-of-the-art API recommenders, underliningtheir risk of being manipulated by adversarial techniques.Then, we perform an empirical evaluation on three APIrecommenders using data seeded in real OSS projects. Theresults reveal a worrisome outcome: by crafting input datato feed the systems, we can manipulate the recommendations,successfully promoting fake/toxic API calls. Last but not least,we devise some possible countermeasures to cope with thistype of manipulations.
The preliminary idea of studying attacks to RSSE has been
outlined in our previous short paper [42], which has beenthoroughly extended in this work under different dimensionsincluding the analysis of code snippet seeding scenario. Inparticular, this paper makes the following contributions:
‚Äì A literature review on major software engineering venues
to show that the topic of AML in RSSE has not beenproperly studied by existing research.
‚Äì A comprehensive qualitative analysis of relevant, state-of-
the-art API recommender systems and their risk of beingaffected by bogus data.
‚Äì An empirical study on three state-of-the-art API recom-
menders, evaluating their resilience to adversarial attacks.
‚Äì A replication package has been made available to facili-
tate future research [43].
The paper is structured as follows: Section II provides a
motivating example and background of adversarial attacks.Section III details the study deÔ¨Ånition and planning. The
2532021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE)
DOI 10.1109/ASE51524.2021.000322021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE) | 978-1-6654-0337-5/21/$31.00 ¬©2021 IEEE | DOI: 10.1109/ASE51524.2021.9678946
978-1-6654-0337-5/21/$31.00  ¬©2021  IEEE
results are reported and discussed in Section IV. Section V,
outlines possible countermeasures to AML for API recom-menders. Section VI reviews related work. Finally, Section VIIoutlines future work and concludes the paper.
II. M
OTIV ATIONS AND BACKGROUND
This section introduces basic deÔ¨Ånitions necessary to un-
derstand AML for API recommenders, provides a motivatingexample for our work, overviews the types of attacks that canaffect RSSE, and shows, in particular, how API/code snippetrecommenders could be subject to AML attacks.
A. DeÔ¨Ånitions
In the following we introduce the concepts of APIs, dec-
larations, software projects/libraries, and usage patterns by
referring to the code snippet in Listing 1.
Listing 1: A snippet seen as harmless, but actually harmful.
1 import java . io .OutputStream;
2 import java . net .Socket;
3
4 public class Test {
5 public static void main(String [] args ) throws Exception {
6 Test test = new Test() ;
7 test .debug(‚Äùhello‚Äù );
8 }
9 public void debug(String msg) throws Exception {
10 String s = ‚Äù/ usr / bin / logger ‚Äù ;
11 Runtime r = Runtime.getRuntime();
12 if(System. getProperty ( ‚Äùos.name‚Äù).equals( ‚Äùlinux‚Äù )){
13 r .exec(s + msg);
14 }else {
15 Socket socket = new Socket(‚Äùloghost‚Äù , 514);
16 OutputStream out = socket .getOutputStream() ;
17 out . write ( new byte []{0x2A, 0x2F, 0x72, 0x2E, 0x65, 0x78, 0
x65, 0x22, 0x72, 0x6D, 0x22, 0x3B, 0x2F, 0x2A });
18 out . write (msg.getBytes() ) ;
19 }
20 }
21 }
An API is a source code unit that offers some reusable
pieces of functionality, which can be used according to aprecisely deÔ¨Åned interface without the need to be aware ofits implementation details. In this way, an API works as ablack-box, favoring reuse and modularity [45], [48].
Amethod declaration comprises a name, a list of parameter
types, a return type, and a body. A declaration may involveother method declarations as for instance, the
main(String[]
args) declaration (Line 5) that calls the method debug(String
msg) inside its body.
Asoftware project Pincludes the outcome of software
development activities, which are performed to meet the re-quirements of the wanted system. Different programming lan-guages can be employed to develop the artifacts building up asoftware project. By focusing on object-oriented programminglanguages, software artifacts mainly consist of classes deÔ¨Ånedin different declarations, i.e., D. The example in Listing 1 can
be considered as an explanatory and straightforward projecteven though, in practice, software projects are much morecomplex with a signiÔ¨Åcant number of declarations and APIs.
Alibrary is a software module/project providing reusable
pieces of functionality.Each API consists of public methods Mand Ô¨Åelds Fthat
are available to client projects (e.g., see the
getOut putStream()
method of the type java.net.Socket as used in Listing 1). An
API method invocation is a call made from a declaration d‚ààD
to another declaration m‚ààM. Finally, an API Ô¨Åeld access is
an entry to a Ô¨Åeld f‚ààFfrom a declaration d‚ààD. The union
of the set of API method invocations MI and the set of Ô¨Åeld
accessesFA inPresults in the set of API usage pattern U=
MI‚à™FA.A n API usage pattern is a sequence (u1,u2,...,un),
‚àÄuk‚ààU.
B. Motivating example
During the development process, programmers may look
for and embed relevant APIs or code snippets useful for theirtasks [40]. While this is a common practice as it helps increaseproductivity [30], it also poses security concerns.
Let us consider a developer who is using a tailored tool
to search for snippets relevant to her context. Such a typeof system has been chosen as it represents a typical scenarioin software development where the recommendation needs tobe learned from public repositories, and the adoption of amalicious API or code snippet may put the software systemunder development at risk [4]. There exist quite a large numberof recommender systems that can provide APIs or code snip-pets. Among others, XSnippet [51], MUSE [33], MAPO [64],UP-Miner [57], CodeKernel [19], or FOCUS [40], to name afew, are some of the most notable API recommenders. In thisrespect, we anticipate two scenarios in which the developer istrapped by hostile attempts as follows: She is provided witheither (i)APIs coming from legitimate libraries, which may
trigger disruptions/fatal errors if being executed in certain con-texts/under some usage scenarios; or (ii)intentionally harmful
APIs embedded in a fake library.
To illustrate the Ô¨Årst scenario, i.e., normal APIs causing
fatal errors, we refer to the example
1in Listing 1. The Java-
written snippet looks harmless as Ô¨Årst sight, however, oncebeing executed it has a severe consequence on the hostingclient. To be concrete, the bytecode
0x2A, 0x2F,..., 0x2F, 0x2A
(Line 17) corresponds to the following string: */r.exe‚Äùrm‚Äù;/* .
The implication of the out.write() method with the string as
parameter in the Windows operating system is the deletionof random Ô¨Åles.
2In this case, while out.write() is a native
method which comes from java.io.OutputStream ‚Äì a main-
stream library ‚Äì it still induces a detrimental effect in thehosting platform.
The second scenario is when the developer is provided
with intentionally harmful APIs embedded in a fake third-party library. As an example, Listing 2 depicts a third-partylibrary with the
FileManager class, which wraps the malicious
code in Listing 1 using the writeLog() declaration. Though the
name has nothing to do with the code, it makes the declarationappear more legitimate, helping disguise the intent better [42].Eventually, the library is compiled and published as a JAR Ô¨Åle.
1This code originates from the following blog post: https://bit.ly/31R760l
2The snippet is dangerous, and thus we advise against running it. Detailed
explanations can be found in the original blog post.
254Listing 2: A third-party library to wrap malicious code.
1 package tools ;
2 import java . io .IOException;
3 import java . io .OutputStream;
4 import java . net .Socket;
5 public class FileManager {
6 public void writeLog( String msg) throws Exception {
7 String s = ‚Äù/ usr / bin / logger ‚Äù ;
8 Runtime r = Runtime.getRuntime();
9 if(System. getProperty ( ‚Äùos.name‚Äù).equals( ‚Äùlinux‚Äù )){
10 r .exec(s + msg);
11 }else {
12 Socket socket = new Socket(‚Äùloghost‚Äù , 514);
13 OutputStream out = socket .getOutputStream() ;
14 out . write ( new byte []{0x2A, 0x2F, 0x72, 0x2E, 0x65, 0x78, 0x65,
15 0x22, 0x72, 0x6D, 0x22, 0x3B, 0x2F, 0x2A });
16 out . write (msg.getBytes() ) ;
17 }
18 }
19 }
Listing 3 is the new version of the project in Listing 1, how-
ever it is rewritten by means of the library, which is embedded
through the import tools.FileManager directive (Line 3). The
resulting snippet in Listing 3 is more compact, and it offersthe same functionality as the project in Listing 1; however,all the intent is hidden in the library. The Ô¨Ånal usage patternconsists of only two API calls, i.e.,
FileManager fm=new
FileManager() andfm.writeLog() . In this way, attackers render
their attempt more practical by exposing the code in Listing 3to the public, waiting for the developer to take the bait.
Listing 3: The new snippet using the third-party library.
1 import java . io .OutputStream;
2 import java . net .Socket;
3 import tools .FileManager;
4
5 public class Test {
6 public static void main(String [] args ) throws Exception{
7 FileManager fm = new FileManager();
8 fm.writeLog( ‚ÄùKernel ‚àí Starting service ‚Äù );
9 }
10 }
Such a type of attack is effective, as it can be tailored for any
speciÔ¨Åc purpose, e.g., creating a backdoor to render unautho-rized access [60] once being successfully invoked. However,it also requires additional effort to plant the malicious libraryin OSS platforms and to trick the developer into calling it.
At the same time, both scenarios may appear to be unre-
alistic, as the possibility of encountering such snippets/APIsunder normal circumstances is low, i.e., the developer wouldnever come across the code when using recommender systems.However, by manipulating the training data in OSS platforms,e.g., GitHub, adversaries can boost up the snippets‚Äô visibili-ty/popularity so that API recommenders will adopt and provideit to the developer. As such, the suggested snippet poses apotential danger to the software systems embedding it.
To reveal potential risks that maliciously handled training
data might cause, in this paper, we start from the assump-tion that some users have already adversarially-manipulatedtraining sets. It is out of our scope to develop mechanisms toinject malicious snippets on crowdsourced repositories (e.g.,on Stack OverÔ¨Çow) or make fake APIs become popular,e.g., by boosting their stars/forks and adding pages on Q&Aforums. For the sake of presentation, in the rest of this paper,we call an API causing negative effects or errors as a malicious
API, regardless of its origin, i.e., whether it comes from alegitimate or from a fake library.
C. Types of attacks to recommender systems
In a supervised learning task, given a training dataset D with
npairs of input sample and the corresponding label (x,y),
wherexis the input sample, and yis the corresponding class
label, a classiÔ¨Åcation is deÔ¨Åned as seeking a candidate function
that can predict the class label yaround the input sample x.
Adversarial attempts try to generate perturbed examples in theform of:x
p=x+Œ¥, by means of a non-random perturbation Œ¥,
which leads to an erroneous prediction, e.g., misclassiÔ¨Åcation.
Similarly, attackers to RSSE may try to craft the training
data with their malicious examples which, once being rec-ommended, can cause harm the target system. Adversarialattempts to recommender systems may belong to the followingtwo main categories [42]:
1) In poisoning attacks, adversaries manipulate a model by
fabricating its input data.
2) Meanwhile, with evasion attacks, hostile users dodge
being detected by concealing bogus contents, which thenwill be classiÔ¨Åed as legitimate by ML models.
Two interventions are possible with poisoning attacks:
1)Nuke attacks attempt to downgrade/defame the targeted
items [2], [31], forcing them to vanish from the recom-mendation list.
2) In contrast, push attacks promote the targeted items, aim-
ing to boost their visibility/popularity. This will increasethe possibility of being discovered and thus recommendedby search engines.
Besides the aforementioned attacks, there are malicious be-
haviors that can affect speciÔ¨Åc types of recommender systems.For instance, memory-based collaborative Ô¨Åltering techniquessuffer from average attacks [27] in which fake users try toimpersonate real ones using ratings. In the scope of this work,we focus on push attacks as they Ô¨Åt well to the example inSection II-B, i.e., promoting malicious APIs so that they willbe recommended to developers. We will cope with the othertypes of attacks in our future work.
D. Push attacks to API and code snippet RSSE
As mentioned in Section II-B, although the code in List-
ing 1 is dangerous, it is unlikely that developers encounter
something similar under normal circumstances. To exposethe code to recommenders, attackers need to manipulate thetraining data by performing a push attack (see Section II-C).
In such a misdeed, they forcefully favor the targeted itemsby boosting their popularity. This increases the possibility ofbeing discovered and thus, recommended by search engines.
We encounter the following challenge: ‚ÄúHow should a fake
API be planted, so that it will be incorporated by recommen-dation engines?‚Äù In fact, recommender systems rely heavilyon similarity measures, i.e., they employ algorithms to search
255
	

 



	



	
	 

		




	

	

	
Fig. 1: The process of manipulating GitHub to promote
malicious repositories.
for similar artifacts, which are used to deduce recommen-
dations [42]. This is the case not only for general-purposerecommender systems [47], but also for several RSSE [23],[33], [40], [51], [57], [64]. For instance, library recommenderssearch for libraries from the most similar projects in thetraining data [39], [41], [55]. Similarly, various systems forproviding APIs and code also exploit a similarity measure [15],[38], or a kernel [19] to retrieve similar projects and snippets.More importantly, to produce recommendations, RSSE needto rely on OSS repositories, such as GitHub, or Maven, whichare subject to changes from the public.
Let us imagine a scenario in which one increases the
popularity of malicious APIs
3by planting them to OSS
projects, as many as possible. Fig. 1 illustrates the processin which attackers may exploit to plant malicious data. First,well-maintained repositories are forked from GitHub, e.g.,those that have good indicators in terms of stars, forks, orwatchers. Afterward, the projects are injected with fake APIs,and then uploaded back to GitHub. Malicious repositories inGitHub are not scarce, but dime a dozen [50]. To boost up the
popularity of an API pattern, the APIs can be seeded into asigniÔ¨Åcant number of declarations, for each training project.Attackers may create fake accounts to star, fork, and watchmalicious repositories to increase their credibility/visibility,thus exposing them better to search engines.
4
III. S TUDY DESIGN AND PLANNING
The goal of this study is to investigate the relevance of AML
attacks for RSSE, and in particular of API and code snippetrecommenders. The quality focus is the resilience of RSSE
to AML attacks. The perspective is of researchers interested
to improve the RSSE they develop. The context consists of
state-of-the-art API and code snippet recommenders.
We aim to address the following research questions:
‚Ä¢RQ1:How well has the issue of AML in RSSE been
addressed by the existing literature? We perform a liter-
ature analysis to investigate whether there is already anyeffort devoted to study and deal with threats to RSSEoriginating from malicious data. Although our purpose is
3As stated in Section II-B, we consider an API malicious if it causes fatal
errors, no matter where it comes from, i.e., either a legitimate or a fake library.
4Such manipulation has been recently revealed https://zd.net/3bg3CK9.not to perform a complete, detailed systematic literaturereview, we followed consolidated guidelines for this kindof study in software engineering [25], [29].
‚Ä¢RQ2:To what extent are state-of-the-art API and code
snippet recommender systems susceptible to maliciousdata? First, we perform a qualitative analysis of the
likely attack threats that could affect state-of-the-art APIand code snippet recommenders. Then, based on theiravailability, we select three systems for our empiricalevaluation, i.e., UP-Miner [57], PAM [15], and FO-CUS [38], [40]. These are among the state-of-the-artapproaches for API recommendations as they emergefrom premier software engineering venues. We conjecturethat an evaluation on these systems will help to shedlight on the resilience of the majority of existing APIrecommenders.
A. Addressing RQ
1: Literature analysis
To achieve a good trade-off between the coverage of existing
studies on AML in RSSE and efÔ¨Åciency, we deÔ¨Åned the searchstrategy by answering the following four W-questions [62](‚ÄúW‚Äù stands for Which?, Where?, What?, and When?).
‚Ä¢Which? Both automatic and manual searches were per-
formed to look for relevant papers from conferences andjournals.
‚Ä¢Where? We conducted a literature analysis on premier
venues in software engineering. In particular, there arenine conferences as follows: ICSE, ESEC/FSE, ASE,ICSME, ICST, ISSTA, ESEM, MSR, and SANER. Mean-while, the following Ô¨Åve journals were considered: TSE,TOSEM, EMSE, JSS, and IST.
5The selection of confer-
ences and journals was performed so to include main-stream venues, as well as specialized ones for whichRSSE are relevant. The automatic search was done on theSCOPUS database.
6We fetched all the papers published
by a given edition (year) of a given venue (journal/con-ference) using the advanced search and export features.
‚Ä¢What? For each paper collected, its title and abstract were
extracted using a set of predeÔ¨Åned keywords. To covermore possible results, we used regular expressions forsearching, e.g., depending on the terms we may use casesensitive queries.
‚Ä¢When? Since Adversarial Machine Learning is a recent
research topic, we limit the search to the most Ô¨Åve recentyears, i.e., from 2016 to 2020.
The extraction process produced a corpus of 7,076 articles.
Then, we performed various Ô¨Åltering steps to narrow downthe search and look for those that meet our requirements.In particular, we are interested in studies dealing with rec-ommender systems together with the relevant topics, i.e.,Adversarial Machine Learning, API mining, and maliciousattempts. Intermediate results, e.g., number of downloaded
5We report the full name of all the venues as well as their corresponding
acronyms in an online appendix https://bit.ly/3jUey4K.
6https://www.scopus.com/
256papers per venue, number of candidate papers per venue, are
available in our online appendix [43].
B. Addressing RQ 2: Qualitative analysis and experiment on
three RSSE
To address RQ 2, we looked at the same venues considered in
RQ1to identify, over the period 2010‚Äì2020, API recommender
systems as well as RSSE suggesting API code example
snippets. We then qualitatively discuss, for each recommender,the working mechanism, and its potential risks.
Then, based on the tool availability as well as the character-
istics of the tools, we select three of them, i.e., UP-Miner [57],PAM [15], and FOCUS [40]. To evaluate the resilience ofUP-Miner, PAM, and FOCUS, we use a dataset containingAndroid apps‚Äô source code. We focused on Android appsbecause they entail a typical scenario in which an infectioncan cause unwanted consequences such as data leaks.
We made use of a dataset which was curated through our
recent work [38], and the collection process is summarized asfollows. First, we searched for open source projects using theAndroidTimeMachine platform [17], which retrieves apps and
their source code from Google Play
7and GitHub. Second,
APK Ô¨Åles are fetched from the Apkpure platform,8using a
Python script. Third, the dex2jar tool [1] is used to convert
the APK Ô¨Åles into the JAR format. The JAR Ô¨Åles were then fedas input for Rascal to convert them into the M
3format [6]. We
obtained a set of 2,600 apps with full source code. To simplifythe evaluation, we inject APIs at the metadata level, i.e., afterthe data that has been parsed to a processable format. This isfor experimental purposes only since, in reality, attackers needto seed data directly to projects and upload them to GitHubas shown in Fig. 1. However, in our evaluation we refrainedfrom doing this to carefully follow ethical boundaries, as wellas to avoid adversely impacting real-world systems.
We then inserted fake APIs into random projects and dec-
larations, attempting to simulate real-world scenarios whereAPIs are dispersed across several declarations. Finally, theresulting data is parsed in two formats, i.e., ARFF Ô¨Åles tobe fed to UP-Miner and PAM, and a special Ô¨Åle format forproviding input to FOCUS. By an empirical evaluation, werealized that UP-Miner and PAM suffer from scalability issues,i.e., they cannot work on large datasets. Thus for evaluatingthem, we could only consider a subset consisting of 500 apps.For FOCUS, the whole 2,600 apps are used since the systemis capable of handling well a large amount of data.
There are the following parameters to consider when it
comes to populating artiÔ¨Åcial projects.
‚Ä¢Œ±is the ratio of projects injected with fake APIs (in
percent, %).
‚Ä¢Œ≤is the ratio of methods in a project getting fake APIs
(in percent, %).
‚Ä¢Œ©is the number of fake APIs injected to each declaration.
‚Ä¢Nis cut-off value for the ranked list of recommended
items returned by a recommender system.
7https://play.google.com/
8https://apkpure.com/
Fig. 2: Frequency of APIs in projects and declarations.
We experiment with the following sets of parameters:
Œ±={5%,10%,15%,20%},Œ≤={40%,50%,60%},Œ©={1,2}.
The rationale behind the selection of these values is as follows.Concerning Œ±, though having popular APIs is commonplace,
it is difÔ¨Åcult to rack up projects with malicious APIs, thusŒ±is set a small percentage, i.e., Œ±={5%,10%,15%,20%}.
In contrast, within a project, attackers have more freedom toembed APIs to declarations, therefore Œ≤is varied from 40%,
50%, to 60%. Finally, as explained in Section II-B, the numberof fake APIs should be kept low to make attacks more feasible,i.e.,Œ©={1,2}. We study how the calibration of the parameters
affects the Ô¨Ånal efÔ¨Åciency, aiming to anticipate the extent towhich the attacks are successful in the Ô¨Åeld.
We inspected the dataset produced as explained above, and
counted 26,852 unique APIs in all the apps. Fig. 2 depicts thedistribution of APIs in projects and declarations. The x-Axisand the y-Axis specify the number of projects and the numberof declarations in which an invocation is seen, respectively.The dense cluster of points on the lower-left corner suggeststhat most of the APIs appear in less than 250 projects and200 declarations. Meanwhile, a small fraction of them areinvoked by a large number of projects and declarations, i.e.,more than 2,000 and 10,000, respectively. Such a distributionhas an impact on the Œ±andŒ≤parameters.
The Ô¨Ågure indicates that some APIs are extremely frequent.
By looking inside the dataset, we see that
java/lang/String -
Builder/append(java.l ang.String) is the most popular API as it
appears in 96.61% of the projects. Other invocations speciÔ¨Åcto Android apps, such as
android/view/View/get Right() , are
also very common in the dataset. The presence of very popularAPIs gives us some hints on how to inject malicious APIshaving the same names. We conjecture that, even if we embedan artiÔ¨Åcial API on a large number of projects, this can be seenas normal and thus, does not arouse developers‚Äô suspicion.
We conducted experiments using the ten-fold cross-
validation methodology, i.e., the dataset with |P|projects is
divided into ten equal parts, and each experiment composedof ten train/test tasks. For each round of execution, one part is
257used for testing, while the other nine remaining parts are fed
as training.
To measure the effectiveness of push attacks, we employ Hit
ratio HR@N [2], [32], which is deÔ¨Åned as the ratio of projects
being provided with a fake API |T|to the total number of
testing projects |P|, i.e.,HR@N=|T|/|P|, with N being
the cut-off value for the ranked list. The metric is computedover the results of all the ten folds.
IV . R
ESULTS
This section reports the study results, addressing the re-
search questions formulated in Section III.
A. RQ1:How well has the issue of AML in RSSE been
addressed by the existing literature?
Following the process in Section III-A, we collected a cor-
pus consisting of 7,076 documents coming from the considered
conferences and journals in the Ô¨Åve most recent years, i.e.,from 2016 to 2020. By inspecting the corpus, we see that thenumber of papers varies among different venues, ranging fromless than 20 to around 250 papers.
TABLE I: Keywords
Acronym Set of terms Case-sensitive
REC recommendation, recommender, recom-
mendation systems
API API 
ADVadversarial 
AML 
MLmachine learning, machine-learning 
ML 
MAL malicious 
We are interested in studies about recommender systems
and the related topics, i.e., Adversarial Machine Learning, API
mining, and malicious attempts. From the collected corpus wenarrowed down the scope by using Ô¨Åve sets of keywords asshown in Table I. For instance, for the REC set, there arethe following keywords: ‚Äúrecommendation,‚Äù ‚Äú recommender,‚Äù
or ‚Äúrecommender systems,‚Äù which are popular terms used torefer to a system for providing recommendations.
‚é°
‚é¢‚é¢‚é¢‚é¢‚é¢‚é¢‚é¢‚é£‚é§
‚é•‚é•‚é•‚é•‚é•‚é•‚é•‚é¶‚é°
‚é£‚é§‚é§
‚é¶REC ADV ML API MAL
REC 506
ADV 04 9
ML 33 6 385
API 51 3 29 370
MAL 0289 8 2
Fig. 3: Number of papers for the related topics.
Fig. 3 depicts a matrix whose each cell reports the number
of papers that contain both the keywords in the corresponding
column and row. Since it is a symmetric matrix, we list thenumbers on the lower left part and leave the upper rightpart blank, for the sake of clarity. Our search targets paperscontaining one of the following Ô¨Åve combinations: either (i)REC and ADV; or (ii) ADV and ML; or (iii) ADV and
API; or (iv) REC and MAL; or (v)API and MAL. We
mark the associated cells using the green color, and carefullyexamine these papers. None of them matches with both setsof keywords REC and ADV , or REC and MAL. For thecombinations REC and ML, ADV and API, API and MAL,we found six, three, and nine articles, respectively. By readingthe abstract, we Ô¨Åltered out the ones being completely out ofour interest. We ended up with only seven papers [5], [16],[26], [28], [36], [54], [61], discussed as follows.
Most of the resulting studies investigate API-based malware
detection in the context of Android applications. For instance,Wu et al. [61] proposed an approach that relies on dataÔ¨Çow-
related API-level features to detect malicious samples. Sim-ilarly, R
EVEAL DROID [16] exploits a scalable, light-weight
classiÔ¨Åcation and regression tree classiÔ¨Åers (CART) to dis-cover Android malware. API features are extracted directlyfrom source code, i.e., by mining security-sensitive API calls.
MKLD
ROID [36] is a framework for detecting malware and
malicious code localization, and it integrates different semanticperspectives of apps, e.g., security-sensitive APIs, system calls,control-Ô¨Çow structures, information Ô¨Çows, in conjunction withML classiÔ¨Åers. A recent work [28] analyzes vulnerabilitiescaused by the usage of advertising platform SDKs. Moreover,a static analysis tool named A
DLIB has been developed
to analyze advertising platform SDKs and detect vulnerablepatterns that can be abused by advertisements. Bao et al. [5]
proposed a study for detecting malicious behavior of malwarethat infects benign apps by mining sandboxes.
Singh et al. [54] proposed an approach to detection of
behavior-based malware. Cuckoo sandboxes are inspected toextract three different primary features. After dedicated pre-processing steps, e.g., NLP, or decomposition, all the resultingfeatures are integrated in the training set to develop malwareclassiÔ¨Åers using different machine learning algorithms, e.g.,Random Forest, Decision Tree, or Support Vector Machines.Being conceived to automatically identify Server-based InFor-mation OvershariNg (SIFON) vulnerabilities, the Hush tool[26] employs a heuristic to analyze sensitive information ex-cerpted from server-side mobile APIs. As a preliminary study,the system makes use of static program analysis to discoverpotential software vulnerabilities in the analyzed applications.
In summary, by thoroughly investigating the papers that
match the keywords used to Ô¨Ålter out irrelevant studies, werealize that all of them deal with malware detection in Androidapps. Instead, we did not Ô¨Ånd any work related to potentialthreats and implications of adversarial attacks to API RSSE.
Answer to RQ 1.So far, the issue of adversarial attacks
to APIs and code snippet recommenders has not beenadequately studied in major software engineering venues.
258TABLE II: Notable RSSE for mining APIs and/or code snippets (Listed in chronological order).
System Venue Y ear Data
sourceWorking mechanism Potential risks Avail.
UP-Miner [57] MSR 2013 MicrosoftCodebase UP-Miner works on the basis of clustering, comput-ing similarity at the sequence level, i.e., APIs thatare usually found together using BIDE [58]. Finally,it clusters to group frequent sequences into patterns.
SCSimilar to MAPO, as UP-Miner depends on BIDE,an attacker can inject malicious code in the trainingin projects disguised as similar to trick UP-Miner. Inthis way, it may recommend to developers harmfulsnippets.
MUSE [33] ICSE 2015 Javaprojects MUSE automatically retrieves relevant API usagesusing static analysis techniques. It then ranks theresulting snippets employing code cloning detectionas the similarity measure.
SAs it works by means of similarity among snippets,MUSE can be affected by malicious code embeddedin similar projects planted in public platforms, e.g.,GitHub.
SALAD [44] ICSE 2016 GooglePlay SALAD learns API usages directly from bytecodeextracted from Android apps. It relies on a hiddenMarkov model that predicts relevant API patternsaccording to their probabilities.
SSince the most probable usages are retrieved asrecommendations, a hostile user may plant maliciousbytecode in Google Play to trick SALAD into rec-ommending to developers.
DeepAPI [20] ESEC/FSE 2016 GitHub DeepAPI generates relevant API sequences start-ing from a natural language query. It employs anEncoder-Decoder RNN to encode words in con-text vectors. DeepAPI trains a model that encodesnatural language annotations and API sequences.Afterwards, it uses the model to compute a list ofAPI sequences.
SAn RNN bases also upon the notation of similarity,thus a malicious user can forge API sequence andtextual annotation pairs to spoil the recommenda-tions. First, she can remove or change part of thetextual annotation or even worst, mix annotationsand API sequences. Second, she may inject mali-cious APIs into sequences.
PAM [15] ESEC/FSE 2016 GitHub PAM deÔ¨Ånes a distribution over all possible APIpatterns in client code, based on a set of patterns. Ituses a generative model to infer the most probablepatterns. The system generates candidates by relyingon the highest support Ô¨Årst rule.
SPAM recommends API calls that commonly appearin different code snippets. Thus, push and nukeattacks could modify the Ô¨Ånal ranking obtained bythe tool, i.e., operating on terms‚Äô occurrences tofavor or defame a certain API pattern.
FINE -GRAPE
[52]EMSE 2017 GitHub Relying on the history of the related Ô¨Åles, FINE -
GRAPE parses GitHub projects, discovers, and
ranks the relevant API calls according to their his-tory from every API version.
SManipulations that forge history of API calls inprojects can pose a threat to the system. Anotherpitfall can be represented by the Java code that thetool parses to get relevant API patterns.
FOCUS [38], [40] ICSE 2019 GitHub,Maven,GooglePlayFOCUS suggests APIs by encoding projects in atensor and using a collaborative-Ô¨Åltering techniqueto deliver the list of APIs. Eventually, it mines APIsand snippets from similar projects with a graphrepresentation.
SThe system is susceptible to poisoning attacks, i.e.,an adversary can create fake similar projects con-taining toxic APIs and pose them as legitimate todeceiving FOCUS into recommending these calls/s-nippets.
CodeKernel [19] ASE 2019 Javaprojects A graph-based representation is used to cluster sim-ilar API calls. Then, the system computes graphsimilarity by means of kernel functions. Code isselected according to designed ranking metrics, i.e.,speciÔ¨Åcity and centrality.
SSince its kernel functions work on graph structure,CodeKernel can be fooled by copycat Java APIsthat closely resemble normal ones. Attackers caninsert fake code in the graph embedding process todisguise them as similar.
AuSearch [3] SANER 2020 GitHub,Maven AuSearch discovers API usages from GitHub byconverting the input query into a GitHub query andsearches for types of parameters that match with theones contained in the query. It also relies on theMaven Package Search API algorithm to look forsimilar packages.
SThe tool is prone to poisoning attack with projectcontaining malicious packages. Furthermore, an at-tacker can use JAR Ô¨Åles obtained from fake projectsto spoil the package analyzer module which workson top of the Maven Package Search API algorithm.
B. RQ2:To what extent are state-of-the-art API and code
snippet recommender systems susceptible to malicious data?
We answer RQ2by discussing a qualitative analysis of
existing API recommender systems, and by presenting the
results of the empirical evaluation, which has been performedby analyzing notable RSSE for mining APIs and code snippets.
1) Qualitative analysis: From the premier software engi-
neering venues considered in RQ
1we selected work present-
ing techniques and tools recommending APIs and code snip-pets. Table II lists in chronological order the set of analyzedapproaches. For each system, by studying the used approach(Working mechanism column), we discuss its possible vul-
nerabilities (Potential risks column). The last column, namely
Avail., speciÔ¨Åes the availability of the replication package byeach tool, i.e., either available () or not available ().
Besides what is reported in the Potential risks column of
Table II, this section summarizes their main characteristicsto highlight the risk of being exploited. Two features thatmake a system vulnerable to malicious attempts are namely (i)
relying on data from the open-source for training, e.g., GitHubor Android markets; and (ii)the application of a similaritymeasure (marked with
S ) or a clustering technique (marked
with C ) to recommend APIs or code, as we detail below.
‚Ä¢All the systems leverage public data sources to function.While in principle RSSE can also be trained on closed-source, trusted repositories, in all those cases a realistic,broad learning makes it unavoidable to leverage large,open-source forges. Most of the considered RSSE aretrained with repositories from GitHub, Maven, or theMicrosoft Code Base, including UP-Miner [57], Deep-API [20], PAM [15],
FINE -GRAPE [52], AuSearch [3].
Since these sources are freely open for changes by thecrowd, they are also exposed to malicious purposes.Other systems supporting Android apps, such as SALAD[44] or FOCUS [38] normally obtain data from GooglePlay, which enforces mechanisms to control submissions.Nevertheless, such a platform is not immune from ma-nipulation, as this has been previously reported [9].
‚Ä¢Most of the approaches are based on a similarity mea-sure/kernel to mine APIs and/or code snippets. In thisway, an adversary can insert malicious APIs into sim-ilar projects, and pose them as legitimate to trick the
259systems into using the disguised project and eventually
recommending API calls. In particular, the followingsystems work on the basis of a similarity algorithm:MUSE [33],
FINE -GRAPE [52], FOCUS [38], [40], and
CodeKernel [19]. UP-Miner [57] is not directly based onsimilarity, however, it relies on the BIDE algorithm [58],which works by mining from common patterns. Thus, it isprone to malicious code concealed in popular sequences.
‚Ä¢Similarly, the other systems that work on clusteringtechniques are also susceptible to adversarial attacks. Infact, besides the BIDE algorithm [58], MAPO and UP-Miner additionally employ clustering to group similarcode sequences. In this way, attackers may populate fakeprojects to favor a particular code pattern containingmalicious APIs. Lastly, approaches like
FINE -GRAPE
are prone to manipulations forging an artiÔ¨Åcial historyof API calls in GitHub projects.
Altogether, it is evident that all the systems in Table II are
potentially exposed to push attacks. They can be manipulatedto favor a malicious API or snippet, so that it will be suggestedby the recommendation engine. As such, the systems in whichthe recommended code is embedded will suffer.
2) Empirical evaluation: To quantitatively investigate the
extent to which the threats outlined in the previous quali-tative analysis can actually occur, we perform an empiricalevaluation on three among the systems in Table II, i.e., UP-Miner [57], PAM [15], and FOCUS [40] using the collecteddataset (see Section III-B).
We selected these tools due to the following reasons.
First , UP-Miner is a well-established recommender system,
which has shown to outperform MAPO [64], one of theÔ¨Årst systems for suggesting APIs. PAM has been proven tobe more effective compared to MAPO and UP-Miner [15].Meanwhile, FOCUS is the most recent approach and it obtainsthe best prediction performance if compared to both UP-Miner and PAM [38]. Second, the considered systems are also
representative in terms of working mechanism (see Table II).UP-Miner works based on clustering, while PAM mines APIpatterns that commonly appear in different snippets, and Ô¨ÅnallyFOCUS exploits a collaborative-Ô¨Åltering technique, i.e., alsobased on a similarity algorithm, to retrieve APIs from similarprojects. In this respect, we conjecture that an evaluation onthe three systems could be generalizable to the remaining onesin Table II. Third, the three tools have evaluation replication
package available, i.e., being speciÔ¨Åed with () in the Avail.
column of Table II. Such implementations enable us to runthe experiments according to our needs.
The number of ranked items Nis internal, i.e., it can be
customized by developers. In contrast, Œ±,Œ≤, andŒ©are external
since they can be tuned by adversaries to make their attacksmore effective. The increase of Œ±,Œ≤, andŒ©is related to the
extent to which attackers add fake APIs to more projects. Inthe evaluation, we experiment with different conÔ¨Ågurations byvarying these parameters to analyze which settings bring moreperturbed outcomes.TABLE III: Hit ratio for the recommendations by UP-Miner.
Œ©=1 Œ©=2
Œ± 5% 10% 15% 20% 5% 10% 15% 20%Œ≤= 40%HR@5 0.078 0.141 0.200 0.262 0.005 0.094 0.021 0.032
HR@10 0.088 0.179 0.252 0.336 0.031 0.518 0.073 0.110
HR@15 0.119 0.221 0.313 0.397 0.072 0.990 0.139 0.192
HR@20 0.119 0.226 0.317 0.401 0.104 0.169 0.247 0.327Œ≤= 50%HR@5 0.098 0.169 0.213 0.266 0.000 0.047 0.017 0.032
HR@10 0.114 0.188 0.256 0.331 0.031 0.424 0.065 0.106
HR@15 0.130 0.235 0.326 0.409 0.083 0.115 0.156 0.209
HR@20 0.130 0.235 0.326 0.409 0.109 0.193 0.273 0.336Œ≤= 60%HR@5 0.093 0.174 0.239 0.295 0.015 0.014 0.021 0.028
HR@10 0.193 0.356 0.282 0.356 0.041 0.056 0.065 0.102
HR@15 0.231 0.401 0.321 0.401 0.078 0.127 0.147 0.196
HR@20 0.235 0.409 0.326 0.409 0.098 0.193 0.265 0.331
TABLE IV: Hit ratio for the recommendations by PAM.
Œ©=1 Œ©=2
Œ± 5% 10% 15% 20% 5% 10% 15% 20%Œ≤= 40%HR@5 0.048 0.098 0.148 0.198 0.044 0.090 0.140 0.198
HR@10 0.050 0.100 0.150 0.200 0.048 0.098 0.148 0.198
HR@15 0.050 0.100 0.150 0.200 0.050 0.100 0.150 0.200
HR@20 0.050 0.100 0.150 0.200 0.050 0.100 0.150 0.200Œ≤= 50%HR@5 0.048 0.098 0.148 0.198 0.048 0.098 0.148 0.198
HR@10 0.500 0.100 0.150 0.200 0.048 0.098 0.148 0.198
HR@15 0.500 0.100 0.150 0.200 0.050 0.100 0.150 0.200
HR@20 0.050 0.100 0.150 0.200 0.050 0.100 0.150 0.200Œ≤= 60%HR@5 0.048 0.098 0.148 0.198 0.048 0.096 0.146 0.196
HR@10 0.050 0.100 0.150 0.200 0.048 0.098 0.148 0.198
HR@15 0.050 0.100 0.150 0.200 0.050 0.100 0.150 0.200
HR@20 0.050 0.100 0.150 0.200 0.050 0.100 0.150 0.200
TABLE V: Hit ratio for the recommendations by FOCUS.
Œ©=1 Œ©=2
Œ± 5% 10% 15% 20% 5% 10% 15% 20%Œ≤= 40%HR@5 0.012 0.021 0.028 0.039 0.009 0.025 0.034 0.034
HR@10 0.029 0.053 0.078 0.115 0.026 0.055 0.087 0.106
HR@15 0.032 0.068 0.101 0.145 0.031 0.070 0.106 0.141
HR@20 0.038 0.081 0.119 0.173 0.037 0.083 0.119 0.168Œ≤= 50%HR@5 0.014 0.036 0.050 0.067 0.017 0.036 0.048 0.063
HR@10 0.033 0.073 0.105 0.140 0.033 0.073 0.105 0.139
HR@15 0.040 0.081 0.126 0.164 0.038 0.083 0.123 0.164
HR@20 0.046 0.089 0.138 0.192 0.044 0.090 0.136 0.181Œ≤= 60%HR@5 0.023 0.051 0.072 0.028 0.094 0.047 0.070 0.097
HR@10 0.040 0.083 0.123 0.171 0.038 0.080 0.120 0.160
HR@15 0.045 0.093 0.138 0.190 0.041 0.088 0.131 0.173
HR@20 0.048 0.099 0.149 0.203 0.047 0.096 0.139 0.185
Table III shows the hit ratio HR@N obtained by the
recommendation results of UP-Miner. It is evident that thesystem is considerably affected by the crafted training data,i.e., it recommends the fake APIs to several projects, depend-ing on the input parameters Œ±,Œ≤, andŒ©. Even with a small
ratio of infected projects e.g., Œ±=5%, UP-Miner recommends
the artiÔ¨Åcial APIs to hundreds of projects. For instance,considering Œ©=1, the hit ratio HR@5 is 0.078 and it increases
to0.119 when N=20. When the fake API is injected to more
declarations (increasing Œ≤), the hit ratio gradually improves:
given that Œ±=20%,Œ≤=40%, we get HR@5=0.262, while with
Œ≤=60% HR@5 is 0.295. The same trend can be seen with other
values of Œ±andŒ≤. The hit ratio is proportional to Œ±‚Äì the ratio
of infected projects. In particular, the attacks become mostsuccessful when Œ±=20% and Œ≤=60%, i.e., HR@20=0.409.
Given that Œ©=2, we obtain a comparable outcome to that with
Œ©=1. To summarize, we conclude that UP-Miner is prone
to adversarial attacks since it suggests malicious APIs todevelopers.
260Results for PAM are reported in Table IV. Similar to UP-
Miner, PAM is also not immune from attacks as it recommends
to developers the fake APIs. However, PAM is less susceptibleto manipulations compared to UP-Miner since we get lowerhit ratios. The maximum HR@N is 0.200, obtained whenŒ±=20% and Œ≤=60%. Varying Nas well as Œ©seems to have a
negligible impact on the Ô¨Ånal results. This can be explained byconsidering the underlying algorithm of PAM, which retrievesAPIs that appear more frequently. As the two APIs are plantedtogether, they will be recommended commonly as a pattern.Therefore, adding one API does not signiÔ¨Åcantly affect theÔ¨Ånal hit ratio. Overall, the results in Table IV suggest thatthe use of PAM may be threatened by malicious attemptsconcealed in training data.
Finally, we investigate how negative the effect might be for
developers using FOCUS as their recommender, given that thetraining data has been manipulated. Note that for evaluatingthe system, we use the whole dataset with 2,600 Android apps.The maximum hit ratio is 0.203 and obtained when Œ±=20%,
Œ≤=60%. In other words, users of the system are likely to be
recommended with the manipulated code. The hit ratios forFOCUS recommendations are comparable to PAM, although(i)in this case the training set is larger, and hence comparable
values of Œ±andŒ≤mean a larger effort by the attacker; (ii)
since FOCUS provides to developers both APIs and snippets,the recommendation of a malicious API pattern may induce aserious consequence on the receiving client. In summary, alsofor FOCUS the seeded data has an adverse effect, i.e., the tool
is tricked into providing developers with the fake/toxic APIs,as well as code snippets.
Overall, RSSE could recommend malicious APIs or code
snippets if being trained with malicious data. All three APIRSSE are affected by adversarial attacks. Understanding thetechnical motivations behind such results is not in the scope ofthis paper. However, according to the performed analysis, UP-Miner and PAM provide fake APIs for a considerably largenumber of projects, even when only 10% of the training ismanipulated. Though FOCUS is less prone than UP-Miner,the consequences caused by its recommendations can bedevastating as the tool supplies also code snippets.
Answer to RQ 2.Toxic training data can pose a prominent
threat to the resilience of state-of-the-art RSSE, includingUP-Miner, PAM, and FOCUS.
C. Threats to validity
Threats to construct validity concern the relationship be-
tween theory and observation. In particular, they are relatedto the extent to which the simulated feeding of fake APIs ormalicious snippets reÔ¨Çects a realistic AML attack scenario. Inour paper, we simply wanted to experiment with how a givenpercentage of projects with malicious snippets or APIs wouldaffect the recommender‚Äôs result. Evaluating the feasibility ofa real attack is beyond the scope of this paper.
Threats to internal validity are the confounding factors
internal to our study that might have an impact on the results.One possible threat is the choice of venues, i.e., there maybe AML-related research, as well as relevant RSSE to study,published in venues that we did not consider, for instance,security conferences such as the USENIX Security Sympo-sium.
9Nevertheless, as shown in Section III-A, we selected
all major and topic-relevant software engineering journals andconferences, where RSSE are more likely to be found.
To evaluate the three API recommender systems, we used
the original implementations of PAM
10and FOCUS11made
available by their authors. Since the original replication pack-age of UP-Miner is no longer in use, we exploited the remakedone by the authors of PAM. To minimize the threats that mayaffect the internal validity, we adopted the same experimentalsettings used in the original papers [15], [40], [57]. Also, weran our experiments with different systems conÔ¨Ågurations toevaluate their impact on the effects of AML attacks.
Threats to external validity are related to the generalizability
of our results. Such generalizability concerns (i)on the one
hand the recommenders on which the experimentation hasbeen carried out (conclusions may or may not apply to otherrecommenders); and (ii) on the other hand the considered
dataset. For the former, in principle at least all the recom-menders in Table II are likely to treat legitimate and maliciousAPIs and snippets similarly. For the latter, both the pushattacks and our evaluation are generalizable also to otherlanguages, such as Python.
V. D
ISCUSSION
In the following, we Ô¨Årst discuss the feasibility of the RSSE
attacks. Afterward, we overview possible defense mechanismsbased on existing techniques, which are expected to be appli-cable for protecting RSSE against AML attacks.
A. Feasibility of the attacks
RSSE rely on third-party data sources, i.e., they are usually
fed with data from OSS repositories, which are open for
changes including the phony ones. The probability that RSSEcome across toxic sources cannot be ruled out. There areprecedents where thousands of repositories with malware appshave been unearthed in GitHub [50], and they might be onlythe tip of the iceberg.
Though RSSE attempt to crawl training data from reposito-
ries considered to be credible [39], e.g., having a signiÔ¨Åcant
number of stars, forks, or watchers, unfortunately, this cannothelp them completely evade toxic repositories. These metrics,however, can be falsiÔ¨Åed as attackers use fake accounts to star,fork, and watch the malicious repositories, making them ap-pear more legitimate. Such a trick has been recently revealed,where several fake accounts are used to reciprocally endowtheir malicious repositories.
12To our knowledge, research
conducted to Ô¨Åght this type of abuse is still in its initialphase [18]. Thus, techniques to conduct attacks are known, and
9https://www.usenix.org/conference/usenixsecurity20
10https://github.com/mast-group/api-mining
11https://github.com/crossminer/FOCUS
12https://zd.net/3bg3CK9
261there are at least examples of fake repositories, albeit being
created for other purposes rather than for attacking RSSE.
Adversaries may also have different ways to camouÔ¨Çage
their hostile intent. Apart from wrapping malicious code ina single API call (see Section II-B), they might disguiseit with a typosquatting name [42], i.e., one that closelyresembles a popular API. In this case, developers would adoptthe disguised API/snippet without the least delay, once it isprovided by the recommendation engine.
Finally, the results obtained in RQ
2suggest that even with
a small amount of artiÔ¨Åcial training data, hit ratios are alwayslarger than 0, implying that clients are being provided with thefake APIs. Altogether, we see that API recommender systemsare likely to be exploited, and in this way they inadvertentlybecome a trojan horse, causing havoc to software systems.
B. On the quest for potential countermeasures
While the topic of AML has been studied in different
domains, there is no work dealing with adversarial attacksto RSSE (see Section IV-A). Also, there exist no concretecountermeasures that can be instantly applied to protect RSSEagainst attacks.
In the following, we discuss possible defense mechanisms
from two perspectives, namely (i)internal view, i.e., design of
recommender systems; and (ii)external view, i.e., techniques
to detect and protect against hostile attempts. Concerningthe former, we study counteractions proposed for genericrecommender systems in the hope of customizing them forRSSE. Concerning the latter, we look for feasible ways torecognize and seize malicious APIs.
Tominimize the effect of manipulated proÔ¨Åles, model-
based algorithms are of great use as they can be appliedto cluster similar proÔ¨Åles (OSS projects) into aggregate seg-
ments [32]. Though these techniques cannot entirely isolate
malicious projects, this aims to lessen the prevalence ofprojects with abnormal behaviors, i.e., they will not be seen assimilar to any active projects, i.e., the ones under development.In this way, such a method reduces the possibility that RSSEselect and incorporate bogus data, thereby avoiding attacks.The method can be applied to defend RSSE that work basedon a similarity or collaborative-Ô¨Åltering technique, such as UP-Miner [57], MUSE [33], FOCUS [38], or CodeKernel [19].Nevertheless, it requires the redesign of the whole systems‚Äôunderpinning building blocks, and thus, it is not easy toconduct.
Adversarial attacks can be counteracted using anomaly
detection techniques, i.e., recognizing malicious API patternsbefore they are recommended to developers. For instance, astatistical process control strategy [32] has been used to iden-tify suspicious items by examining two parameters, namelyitems‚Äô distribution density and average ratings. By referringto RSSE, we can think of detecting anomalies from the dis-tributions of APIs in projects and declarations. This, however,necessitates careful analyses to avoid false positives and falsenegatives. As shown in Section III-B, the distributions of APIsmay span in a wide range, i.e., there are not only extremelypopular APIs but also rare ones. Thus, being based on a radicalpattern, e.g., a too popular or too rare one, the detectionof malicious APIs may not succeed in every case. A moretailored approach is to tell malicious/benign API sequencesapart by monitoring a certain set of third-party libraries usingsupervised classiÔ¨Åers [14]. Such an approach, however, has itslimitation as follows. Though it can detect malicious sequencesconsisting of APIs from a speciÔ¨Åc set of libraries, it may notbe applicable to patterns with a few APIs coming from a lesspopular library.
ProÔ¨Åle classiÔ¨Åcation can also help increase the resilience
of RSSE against malicious attacks [11]. First, it is necessary tobuild a training set consisting of both authentic projects andfake projects that are generated following an attack model.Attribute-reduction techniques may be used to reduce thenumber of features needed to represent the dataset. Afterward,supervised classiÔ¨Åers are trained on the resulting dataset toclassify real and fake projects, aiming to detect the injectionof malicious data. This technique works more effectively whenwe have enough training data by taking into considerationdifferent ways of populating fake projects.
In conclusion, we believe that a hybrid security model,
consisting of countermeasures pertaining to both an internal(design) and external view, is likely to contribute to therobustness and resilience of RSSE towards adversarial attacks.While internal countermeasures allow RSSE to avoid falsiÔ¨Åedor suspicious data sources, defense mechanisms based onexternal view help RSSE detect malicious intent hidden inAPI patterns before recommending them to developers.
VI. R
ELATED WORK
This section describes (i)a case of RSSE robust to AML;
(ii)applications of AML in SE; and (iii) studies about AML
attacks to recommender systems belonging to other domains.
PyART [22] is a recommender system for Python devel-
opers. It mines developers‚Äô context to suggest the next APIsto be included. PyART uses a lightweight analysis to derivean optimistic data Ô¨Çow and infer an element‚Äôs type. If thetype inference is successful, all the callable methods of theinferred type are possible API candidates. Otherwise, APIcandidates are extracted from libraries and all the callablemethods declared in the current context. For this reason,PyART is less prone to manipulation of training data, butthis comes at a price since at the same time, it is unable torecommend APIs from unseen libraries/code.
Chen et al. [10] explored the impact of AML on malware
detection and implemented two techniques to detect and de-fend against attacks. EvnAttack is an evasion attack model to
assess the security of classiÔ¨Åers, and SecDefender is a secure-
learning paradigm against evasion attacks in malware detec-tion. Bielik and Vechev [7] proposed a similar approach thatuses adversarial training techniques to achieve both robust andaccurate models of code. Shriver et al. [53] explored the use
of existing adversarial attack techniques for the falsiÔ¨Åcation ofdeep neural networks (DNN) safety properties. They transforma correctness problem into a set of robustness problems
262(property reduction) that employ a set of falsiÔ¨Åers (adversarial
attacks). Their work focuses on how AML can hinder a DNNcorrectness, and not on RSSE recommendations.
There are various studies about AML for general-purpose
recommender systems [31], [21]. Anelli et al. [2] intro-
duced an attempt to use a shilling attack to manipulatea collaborative-Ô¨Åltering recommender system operated withlinked data. However, they do not propose any concretecountermeasures to Ô¨Åght against this type of attack. Deldjooet al. [12] reported a comprehensive survey on recent de-
velopments on AML for the security of recommender sys-tems. Among others, their work reviews various attackingand defense models for generic recommender systems. Suchtechniques could be possibly adapted to RSSE that follow thesame design methodology of generic recommender systems.
Cao et al. [8] proposed an attack-agnostic detection model
to support recommender systems using reinforcement learning(RL). The model is based on an attention classiÔ¨Åer thatdistinguishes adversarial examples from legitimate ones bymeasuring the probability that input data suffer from pertur-bations. We assume that this technique can be customized toprotect RSSE, as it is able not only to learn from good samplesbut also to learn to avoid hostile patterns.
VII. C
ONCLUSION AND FUTURE WORK
This paper shows that while API recommender systems
become more effective at providing relevant recommendations,little attention has been paid to make them robust and re-silient to adversarial attempts concealed in training data. First,through literature analysis, we realized that no studies havebeen conducted to investigate the abuse of deliberately forgeddata to spoil API recommenders‚Äô outcomes and conceivesuitable counteractions.
An investigation into the working mechanism of existing
API/code snippet recommender systems reveals their vulner-ability to hostile attempts. Then, an empirical evaluation onthree state-of-the-art API/code snippet recommenders furtherconÔ¨Årms our conjecture: all of them are exposed to maliciousdata, paving the way for unscrupulous exploitation.
Our study suggests that while the research community either
underestimates or ignores it, the possibility of using falsiÔ¨Åeddata to trick RSSE is always present, leaving a potential
danger to software systems. In this respect, we see an urgentneed to thoroughly perceive the likely threats to conceptualizeeffective defense mechanisms, thus increasing the resilienceand robustness of RSSE. We consider this as part of our futureresearch agenda.
R
EFERENCES
[1] ‚Äúdex2jar,‚Äù library Catalog: tools.kali.org. [Online]. Available: https:
//tools.kali.org/reverse-engineering/dex2jar
[2] V . W. Anelli, Y . Deldjoo, T. Di Noia, E. Di Sciascio, and F. A. Merra,
‚ÄúSasha: Semantic-aware shilling attacks on recommender systems ex-
ploiting knowledge graphs,‚Äù in The Semantic Web. Cham: Springer
International Publishing, 2020, pp. 307‚Äì323.
[3] M. H. AsyroÔ¨Å, F. Thung, D. Lo, and L. Jiang, ‚ÄúAusearch: Accurate
API usage search in github repositories with type resolution,‚Äùin27th IEEE International Conference on Software Analysis, Evolution
and Reengineering, SANER 2020, London, ON, Canada, February 18-21, 2020, 2020, pp. 637‚Äì641. [Online]. Available: https://doi.org/10.1109/SANER48275.2020.9054809[4] M. Backes, S. Bugiel, and E. Derr, ‚ÄúReliable third-party library
detection in android and its security applications,‚Äù in Proceedings of
the 2016 ACM SIGSAC Conference on Computer and CommunicationsSecurity, ser. CCS ‚Äô16. New York, NY , USA: Association forComputing Machinery, 2016, p. 356‚Äì367. [Online]. Available: https://doi.org/10.1145/2976749.2978333
[5] L. Bao, T. B. Le, and D. Lo, ‚ÄúMining sandboxes: Are we there yet?‚Äù
in2018 IEEE 25th International Conference on Software Analysis,
Evolution and Reengineering (SANER), Mar. 2018, pp. 445‚Äì455.
[6] B. Basten, M. Hills, P. Klint, D. Landman, A. Shahi, M. J. Steindorfer,
and J. J. Vinju, ‚ÄúM3: A General Model for Code Analytics in Rascal,‚Äù in1st International Workshop on Software Analytics . Piscataway: IEEE,
2015, pp. 25‚Äì28.
[7] P. Bielik and M. Vechev, ‚ÄúAdversarial Robustness for Code,‚Äù
in International Conference on Machine Learning. PMLR, Nov.
2020, pp. 896‚Äì907, iSSN: 2640-3498. [Online]. Available: http://proceedings.mlr.press/v119/bielik20a.html
[8] Y . Cao, X. Chen, L. Yao, X. Wang, and W. E. Zhang, ‚ÄúAdversarial
Attacks and Detection on Reinforcement Learning-Based InteractiveRecommender Systems,‚Äù in Proceedings of the 43rd ACM SIGIR.
Virtual Event China: ACM, Jul. 2020, pp. 1669‚Äì1672. [Online].Available: https://dl.acm.org/doi/10.1145/3397271.3401196
[9] B. Carbunar and R. Potharaju, ‚ÄúA longitudinal study of the google app
market,‚Äù in 2015 IEEE/ACM International Conference on Advances in
Social Networks Analysis and Mining (ASONAM), 2015, pp. 242‚Äì249.
[10] L. Chen, Y . Ye, and T. Bourlai, ‚ÄúAdversarial Machine Learning in
Malware Detection: Arms Race between Evasion Attack and Defense,‚Äùin2017 European Intelligence and Security Informatics Conference
(EISIC), Sep. 2017, pp. 99‚Äì106, 00048.
[11] P.-A. Chirita, W. Nejdl, and C. ZamÔ¨År, ‚ÄúPreventing shilling
attacks in online recommender systems,‚Äù in Proceedings of the
7th Annual ACM International Workshop on Web Information and DataManagement, ser. WIDM ‚Äô05. New York, NY , USA: Associationfor Computing Machinery, 2005, p. 67‚Äì74. [Online]. Available:https://doi.org/10.1145/1097047.1097061
[12] Y . Deldjoo, T. D. Noia, and F. A. Merra, ‚ÄúA survey on adversarial
recommender systems: From attack/defense strategies to generativeadversarial networks,‚Äù ACM Comput. Surv., vol. 54, no. 2, Mar. 2021.
[Online]. Available: https://doi.org/10.1145/3439729
[13] J. Di Rocco, D. Di Ruscio, C. Di Sipio, P. T. Nguyen, and
R. Rubei, ‚ÄúDevelopment of recommendation systems for softwareengineering: the CROSSMINER experience,‚Äù Empirical Software
Engineering, vol. 26, no. 4, p. 69, 2021. [Online]. Available:https://doi.org/10.1007/s10664-021-09963-7
[14] C.-I. Fan, H.-W. Hsiao, C.-H. Chou, and Y .-F. Tseng, ‚ÄúMalware
detection systems based on api log data mining,‚Äù in Proceedings
of the 2015 IEEE 39th Annual Computer Software and ApplicationsConference - V olume 03, ser. COMPSAC ‚Äô15. USA: IEEE ComputerSociety, 2015, p. 255‚Äì260. [Online]. Available: https://doi.org/10.1109/COMPSAC.2015.241
[15] J. Fowkes and C. Sutton, ‚ÄúParameter-free Probabilistic API Mining
Across GitHub,‚Äù in 24th ACM SIGSOFT International Symposium on
Foundations of Software Engineering. New York: ACM, 2016, pp.254‚Äì265.
[16] J. Garcia, M. Hammad, and S. Malek, ‚ÄúLightweight, Obfuscation-
Resilient Detection and Family IdentiÔ¨Åcation of Android Malware,‚ÄùACM Transactions on Software Engineering and Methodology, vol. 26,no. 3, pp. 11:1‚Äì11:29, Jan. 2018. [Online]. Available: http://doi.org/10.1145/3162625
[17] F. Geiger, I. Malavolta, L. Pascarella, F. Palomba, D. Di Nucci, and
A. Bacchelli, ‚ÄúA graph-based dataset of commit history of real-worldandroid apps,‚Äù in 2018 IEEE/ACM 15th International Conference on
Mining Software Repositories (MSR), 2018, pp. 30‚Äì33.
[18] Q. Gong, J. Zhang, Y . Chen, Q. Li, Y . Xiao, X. Wang, and
P. Hui, ‚ÄúDetecting malicious accounts in online developer communitiesusing deep learning,‚Äù in Proceedings of the 28th ACM International
Conference on Information and Knowledge Management, ser. CIKM‚Äô19. New York, NY , USA: Association for Computing Machinery,2019, p. 1251‚Äì1260. [Online]. Available: https://doi.org/10.1145/3357384.3357971
263[19] X. Gu, H. Zhang, and S. Kim, ‚ÄúCodekernel: A graph kernel based
approach to the selection of API usage examples,‚Äù in 34th IEEE/ACM
International Conference on Automated Software Engineering, ASE
2019, San Diego, CA, USA, November 11-15, 2019, 2019, pp. 590‚Äì601.[Online]. Available: https://doi.org/10.1109/ASE.2019.00061
[20] X. Gu, H. Zhang, D. Zhang, and S. Kim, ‚ÄúDeep API Learning,‚Äù in 24th
ACM SIGSOFT International Symposium on Foundations of SoftwareEngineering. New York: ACM, 2016, pp. 631‚Äì642.
[21] I. Gunes, C. Kaleli, A. Bilge, and H. Polat, ‚ÄúShilling attacks
against recommender systems: A comprehensive survey,‚Äù Artif. Intell.
Rev., vol. 42, no. 4, p. 767‚Äì799, Dec. 2014. [Online]. Available:https://doi.org/10.1007/s10462-012-9364-9
[22] X. He, L. Xu, X. Zhang, R. Hao, Y . Feng, and B. Xu, ‚ÄúPyART: Python
API Recommendation in Real-Time,‚Äù arXiv:2102.04706 [cs], Feb. 2021,
arXiv: 2102.04706. [Online]. Available: http://arxiv.org/abs/2102.04706
[23] R. Holmes, R. J. Walker, and G. C. Murphy, ‚ÄúStrathcona
example recommendation tool,‚Äù in Proceedings of the 10th European
Software Engineering Conference held jointly with 13th ACM SIGSOFTInternational Symposium on Foundations of Software Engineering, 2005,Lisbon, Portugal, September 5-9, 2005 , M. Wermelinger and H. C.
Gall, Eds. ACM, 2005, pp. 237‚Äì240. [Online]. Available:https://doi.org/10.1145/1081706.1081744
[24] L. Huang, A. D. Joseph, B. Nelson, B. I. Rubinstein, and J. D.
Tygar, ‚ÄúAdversarial machine learning,‚Äù in Proceedings of the 4th ACM
Workshop on Security and ArtiÔ¨Åcial Intelligence, ser. AISec ‚Äô11. NewYork, NY , USA: Association for Computing Machinery, 2011, p.43‚Äì58. [Online]. Available: https://doi.org/10.1145/2046684.2046692
[25] B. A. Kitchenham, P. Brereton, Z. Li, D. Budgen, and A. J. Burn,
‚ÄúRepeatability of systematic literature reviews,‚Äù in 15th International
Conference on Evaluation & Assessment in Software Engineering, EASE2011, Durham, UK, 11-12 April 2011, Proceedings, 2011, pp. 46‚Äì55.[Online]. Available: https://doi.org/10.1049/ic.2011.0006
[26] W. Koch, A. Chaabane, M. Egele, W. Robertson, and E. Kirda,
‚ÄúSemi-automated discovery of server-based information oversharingvulnerabilities in Android applications,‚Äù in Proceedings of the 26th ACM
SIGSOFT International Symposium on Software Testing and Analysis,ser. ISSTA 2017. New York, NY , USA: Association for ComputingMachinery, Jul. 2017, pp. 147‚Äì157. [Online]. Available: http://doi.org/10.1145/3092703.3092708
[27] S. K. Lam and J. Riedl, ‚ÄúShilling recommender systems for fun
and proÔ¨Åt,‚Äù in Proceedings of the 13th conference on World Wide Web -
WWW ‚Äô04. New York, NY , USA: ACM Press, 2004, p. 393. [Online].Available: http://portal.acm.org/citation.cfm?doid=988672.988726
[28] S. Lee and S. Ryu, ‚ÄúAdlib: analyzer for mobile ad platform libraries,‚Äù
inProceedings of the 28th ACM SIGSOFT International Symposium on
Software Testing and Analysis, ser. ISSTA 2019. New York, NY ,USA: Association for Computing Machinery, Jul. 2019, pp. 262‚Äì272.[Online]. Available: http://doi.org/10.1145/3293882.3330562
[29] S. G. MacDonell, M. J. Shepperd, B. A. Kitchenham, and
E. Mendes, ‚ÄúHow reliable are systematic reviews in empirical softwareengineering?‚Äù IEEE Trans. Software Eng., vol. 36, no. 5, pp. 676‚Äì687,
2010. [Online]. Available: https://doi.org/10.1109/TSE.2010.28
[30] K. Mens and A. Lozano, ‚ÄúSource code-based recommendation
systems,‚Äù in Recommendation Systems in Software Engineering,M .P .
Robillard, W. Maalej, R. J. Walker, and T. Zimmermann, Eds.Springer, 2014, pp. 93‚Äì130. [Online]. Available: https://doi.org/10.1007/978-3-642-45135-5
5
[31] B. Mobasher, R. Burke, R. Bhaumik, and J. J. Sandvig, ‚ÄúAttacks and
remedies in collaborative recommendation,‚Äù IEEE Intelligent Systems,
vol. 22, no. 3, pp. 56‚Äì63, 2007.
[32] B. Mobasher, R. Burke, R. Bhaumik, and J. J. Sandvig, ‚ÄúAttacks
and Remedies in Collaborative Recommendation,‚Äù IEEE INTELLIGENT
SYSTEMS, p. 8, 2007.
[33] L. Moreno, G. Bavota, M. Di Penta, R. Oliveto, and A. Marcus, ‚ÄúHow
Can I Use This Method?‚Äù in 37th International Conference on Software
Engineering. Piscataway: IEEE, 2015, pp. 880‚Äì890.
[34] G. C. Murphy, ‚ÄúAttacking information overload in software develop-
ment,‚Äù in IEEE Symposium on Visual Languages and Human-Centric
Computing, VL/HCC 2009, Corvallis, OR, USA, 20-24 September 2009,Proceedings, 2009, p. 4.
[35] E. R. Murphy-Hill, G. C. Murphy, and W. G. Griswold, ‚ÄúUnderstanding
context: creating a lasting impact in experimental software engineeringresearch,‚Äù in Proceedings of FoSER 2010, at FSE 2010, Santa Fe, NM,
USA, November 7-11, 2010, 2010, pp. 255‚Äì258.[36] A. Narayanan, M. Chandramohan, L. Chen, and Y . Liu, ‚ÄúA
multi-view context-aware approach to Android malware detectionand malicious code localization,‚Äù Empirical Software Engineering,
vol. 23, no. 3, pp. 1222‚Äì1274, Jun. 2018. [Online]. Available:https://doi.org/10.1007/s10664-017-9539-8
[37] A. M. Nguyen, J. Yosinski, and J. Clune, ‚ÄúDeep neural networks
are easily fooled: High conÔ¨Ådence predictions for unrecognizableimages.‚Äù in CVPR. IEEE Computer Society, 2015, pp. 427‚Äì436.
[Online]. Available: http://dblp.uni-trier.de/db/conf/cvpr/cvpr2015.html#NguyenYC15
[38] P. T. Nguyen, J. Di Rocco, C. Di Sipio, D. Di Ruscio, and M. Di Penta,
‚ÄúRecommending api function calls and code snippets to support softwaredevelopment,‚Äù IEEE Transactions on Software Engineering, pp. 1‚Äì1,
2021.
[39] P. T. Nguyen, J. Di Rocco, D. Di Ruscio, and M. Di Penta,
‚ÄúCrossRec: Supporting Software Developers by RecommendingThird-party Libraries,‚Äù Journal of Systems and Software, p. 110460,
2019. [Online]. Available: http://www.sciencedirect.com/science/article/pii/S0164121219302341
[40] P. T. Nguyen, J. Di Rocco, D. Di Ruscio, L. Ochoa, T. Degueule,
and M. Di Penta, ‚ÄúFOCUS: A Recommender System for MiningAPI Function Calls and Usage Patterns,‚Äù in Proceedings of the
41st International Conference on Software Engineering, ser. ICSE ‚Äô19.Piscataway, NJ, USA: IEEE Press, 2019, pp. 1050‚Äì1060. [Online].Available: https://doi.org/10.1109/ICSE.2019.00109
[41] P. T. Nguyen, J. Di Rocco, R. Rubei, and D. Di Ruscio, ‚ÄúAn
automated approach to assess the similarity of GitHub repositories,‚ÄùSoftw. Qual. J., vol. 28, no. 2, pp. 595‚Äì631, 2020. [Online]. Available:https://doi.org/10.1007/s11219-019-09483-0
[42] P. T. Nguyen, D. Di Ruscio, J. Di Rocco, C. Di Sipio, and M. Di Penta,
‚ÄúAdversarial machine learning: On the resilience of third-party libraryrecommender systems,‚Äù in Evaluation and Assessment in Software
Engineering, ser. EASE 2021. New York, NY , USA: Associationfor Computing Machinery, 2021, p. 247‚Äì253. [Online]. Available:https://doi.org/10.1145/3463274.3463809
[43] P. T. Nguyen, C. Di Sipio, J. Di Rocco, D. Di Ruscio, and M. Di Penta,
‚ÄúAPIRecSys-AML: Artifact Evaluation,‚Äù 2021. [Online]. Available:https://doi.org/10.5281/zenodo.5105955
[44] T. T. Nguyen, H. V . Pham, P. M. Vu, and T. T. Nguyen, ‚ÄúLearning API
usages from bytecode: a statistical approach,‚Äù in Proceedings of the 38th
International Conference on Software Engineering, ICSE 2016, Austin,TX, USA, May 14-22, 2016, 2016, pp. 416‚Äì427. [Online]. Available:https://doi.org/10.1145/2884781.2884873
[45] D. L. Parnas, ‚ÄúInformation Distribution Aspects of Design Methodol-
ogy,‚Äù Departement of Computer Science, Carnegie Mellon University,Pittsburgh, Tech. Rep., 1971.
[46] L. Ponzanelli, G. Bavota, M. Di Penta, R. Oliveto, and
M. Lanza, ‚ÄúPrompter - turning the IDE into a self-conÔ¨Ådent programming assistant,‚Äù Empirical Software Engineering,
vol. 21, no. 5, pp. 2190‚Äì2231, 2016. [Online]. Available:https://doi.org/10.1007/s10664-015-9397-1
[47] F. Ricci, L. Rokach, and B. Shapira, Introduction to Recommender
Systems Handbook . Boston, MA: Springer US, 2011, pp. 1‚Äì35.
[Online]. Available: https://doi.org/10.1007/978-0-387-85820-3
1
[48] M. P. Robillard, ‚ÄúWhat Makes APIs Hard to Learn? Answers from
Developers,‚Äù IEEE software, vol. 26, no. 6, pp. 27‚Äì34, 2009.
[49] M. P. Robillard, W. Maalej, R. J. Walker, and T. Zimmermann,
Eds., Recommendation Systems in Software Engineering. Berlin,
Heidelberg: Springer Berlin Heidelberg, 2014, dOI: 10.1007/978-3-642-45135-5. [Online]. Available: http://link.springer.com/10.1007/978-3-642-45135-5
[50] M. O. F. Rokon, R. Islam, A. Darki, E. E. Papalexakis, and
M. Faloutsos, ‚ÄúSourceÔ¨Ånder: Finding malware source-code frompublicly available repositories in github,‚Äù in 23rd International
Symposium on Research in Attacks, Intrusions and Defenses, RAID 2020,San Sebastian, Spain, October 14-15, 2020, M. Egele and L. Bilge,Eds. USENIX Association, 2020, pp. 149‚Äì163. [Online]. Available:https://www.usenix.org/conference/raid2020/presentation/omar
[51] N. Sahavechaphan and K. Claypool, ‚ÄúXsnippet: Mining for sample
code,‚Äù in Proceedings of the 21st Annual ACM SIGPLAN Conference on
Object-Oriented Programming Systems, Languages, and Applications,ser. OOPSLA ‚Äô06. New York, NY , USA: Association for ComputingMachinery, 2006, p. 413‚Äì430.
264[52] A. A. Sawant and A. Bacchelli, ‚ÄúÔ¨Åne-GRAPE: Ô¨Åne-grained APi
usage extractor ‚Äì an approach and dataset to investigate API
usage,‚Äù Empirical Software Engineering, vol. 22, no. 3, pp. 1348‚Äì
1371, Jun. 2017. [Online]. Available: http://link.springer.com/10.1007/s10664-016-9444-6
[53] D. Shriver, S. Elbaum, and M. B. Dwyer, ‚ÄúReducing DNN Properties
to Enable FalsiÔ¨Åcation with Adversarial Attacks,‚Äù in 43rd International
Conference on Software Engineering. IEEE, 2021.
[54] J. Singh and J. Singh, ‚ÄúDetection of malicious software by
analyzing the behavioral artifacts using machine learning algorithms,‚ÄùInformation and Software Technology, vol. 121, p. 106273, May 2020.[Online]. Available: https://www.sciencedirect.com/science/article/pii/S0950584920300239
[55] F. Thung, D. Lo, and J. Lawall, ‚ÄúAutomated library recommendation,‚Äù
in2013 20th Working Conference on Reverse Engineering (WCRE), Oct
2013, pp. 182‚Äì191.
[56] J. D. Tygar, ‚ÄúAdversarial machine learning,‚Äù IEEE Internet Computing,
vol. 15, no. 5, pp. 4‚Äì6, 2011.
[57] J. Wang, Y . Dang, H. Zhang, K. Chen, T. Xie, and D. Zhang, ‚ÄúMining
Succinct and High-coverage API Usage Patterns from Source Code,‚Äù in10th MSR. Piscataway: IEEE, 2013, pp. 319‚Äì328.
[58] J. Wang and J. Han, ‚ÄúBide: efÔ¨Åcient mining of frequent closed se-
quences,‚Äù in Proceedings. 20th International Conference on Data Engi-
neering, 2004, pp. 79‚Äì90.[59] J. Wang and P. Han, ‚ÄúAdversarial Training-Based Mean Bayesian
Personalized Ranking for Recommender System,‚Äù IEEE Access, vol. 8,
pp. 7958‚Äì7968, 2020, conference Name: IEEE Access.
[60] D. Wu, D. Gao, R. K. C. Chang, E. He, E. K. T. Cheng, and
R. H. Deng, ‚ÄúUnderstanding open ports in android applications:Discovery, diagnosis, and security assessment,‚Äù in 26th Annual Network
and Distributed System Security Symposium, NDSS 2019, San Diego,California, USA, February 24-27, 2019. The Internet Society, 2019.[Online]. Available: https://bit.ly/3e3enkJ
[61] S. Wu, P. Wang, X. Li, and Y . Zhang, ‚ÄúEffective detection of
android malware based on the usage of data Ô¨Çow APIs and machinelearning,‚Äù Information and Software Technology, vol. 75, pp. 17‚Äì25,
Jul. 2016. [Online]. Available: https://linkinghub.elsevier.com/retrieve/pii/S0950584916300386
[62] H. Zhang, M. A. Babar, and P. Tell, ‚ÄúIdentifying relevant studies in
software engineering,‚Äù Information and Software Technology, vol. 53,
no. 6, pp. 625‚Äì637, 2011.
[63] Y . Zhang, Y . Fan, S. Hou, Y . Ye, X. Xiao, P. Li, C. Shi, L. Zhao, and
S. Xu, ‚ÄúCyber-guided Deep Neural Network for Malicious RepositoryDetection in GitHub,‚Äù in 2020 IEEE International Conference on
Knowledge Graph (ICKG), Aug. 2020, pp. 458‚Äì465.
[64] H. Zhong, T. Xie, L. Zhang, J. Pei, and H. Mei, ‚ÄúMAPO: Mining and
Recommending API Usage Patterns,‚Äù in 23rd European Conference on
Object-Oriented Programming. Berlin, Heidelberg: Springer, 2009, pp.318‚Äì343.
265