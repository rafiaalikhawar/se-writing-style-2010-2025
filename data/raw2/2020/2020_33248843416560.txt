NeuroDiff: Scalable Differential Verification of Neural
Networks using Fine-Grained Approximation
Brandon Paulsen
University of Southern California
Los Angeles, California, USAJingbo Wang
University of Southern California
Los Angeles, California, USA
Jiawei Wang
University of Southern California
Los Angeles, California, USAChao Wang
University of Southern California
Los Angeles, California, USA
ABSTRACT
As neural networks make their way into safety-critical systems,
where misbehavior can lead to catastrophes, there is a growing
interest in certifying the equivalence of two structurally similar
neural networks – a problem known as differential verification.
For example, compression techniques are often used in practice fordeployingtrainedneuralnetworksoncomputationally-andenergy-constraineddevices,whichraisesthequestionofhowfaithfullythe
compressednetworkmimicstheoriginalnetwork.Unfortunately,
existing methods either focus on verifying a single network or relyon loose approximations to prove the equivalence of two networks.
Due to overly conservative approximation, differential verification
lacks scalability in terms of both accuracy and computational cost.
Toovercometheseproblems,weproposeNeuroDiff,a symbolic
andfine-grained approximationtechniquethatdrasticallyincreases
the accuracy of differential verification on feed-forward ReLU net-
workswhileachievingmanyorders-of-magnitudespeedup.Neu-
roDiff has two key contributions. The first one is new convex
approximationsthatmoreaccuratelyboundthedifferenceoftwo
networks under all possible inputs. The second one is judicioususe of symbolic variables to represent neurons whose difference
bounds have accumulated significant error. We find that these two
techniques are complementary, i.e., when combined, the benefit is
greater than the sum of their individual benefits. We have evalu-
ated NeuroDiff on a variety of differential verification tasks. Our
results show that NeuroDiff is up to 1000X faster and 5X more
accurate than the state-of-the-art tool.
1 INTRODUCTION
There is a growing need for rigorous analysis techniques that can
compare the behaviors of two or more neural networks trained for
thesametask.Forexample,suchtechniqueshaveapplicationsin
better understandingthe representations learnedby different net-
works [46], and finding inputs where networks disagree [52]. The
need is further motivated by the increasing use of neural network
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ASE ’20, September 21–25, 2020, Virtual Event, Australia
© 2020 Association for Computing Machinery.
ACM ISBN 978-1-4503-6768-4/20/09...$15.00
https://doi.org/10.1145/3324884.3416560compression[ 14]–atechniquethataltersthenetwork’sparame-
terstoreduceitsenergyandcomputationalcost–wherewe expect
the compressed network to be functionally equivalent to the origi-
nalnetwork.Insafety-criticalsystemswhereasingleinstanceof
misbehaviorcanleadtocatastrophe,having formalguarantees on
the equivalence of the original and compressed networks is highly
desirable.
Unfortunately,mostworkaimedatverifyingortestingneural
networks does not provide formal guarantees on their equivalence.
Forexample,testingtechniquesgearedtoward refutation canpro-
videinputswhereasinglenetworkmisbehaves[ 22,31,42,44,51]or
multiple networks disagree [ 23,34,52], but they do not guarantee
theabsenceofmisbehaviorsordisagreements.Whiletechniques
geared toward verification can prove safety or robustness prop-
erties of a single network [ 7–9,15,18,25,38,41,47], they lack
crucial information needed to prove the equivalence of multiple
networks.OneexceptionistheReluDifftoolofPaulsenetal.[ 33],
which computes a sound approximation of the difference of two
neuralnetworks,aproblemknownas differentialverification.While
ReluDiffperformsbetterthanothertechniques,theoverlycon-
servative approximation it computes often causes both accuracy
and efficiency to suffer.
Toovercometheseproblems,weproposeNeuroDiff,anew sym-
bolicandfine-grained approximationtechniquethatsignificantly
increasestheaccuracyofdifferentialverificationwhileachieving
many orders-of-magnitude speedup. NeuroDiff has two key con-
tributions.Thefirst contributionisthedevelopmentof convexap-
proximations,afine-grainedapproximationtechniqueforbound-
ing the output difference of neurons for all possible inputs, which
drasticallyimprovesoverthecoarse-grained concretizations used
byReluDiff.Thesecondcontributionisjudiciouslyintroducing
symbolicvariablestorepresentneuronsinhiddenlayerswhosedif-
ference bounds have accumulated significant approximation error.
Thesetwotechniquesarealsocomplementary,i.e.,whencombined,
the benefit is significantly greater than the sum of their individual
benefits.
The overall flow of NeuroDiff is shown in Figure 1, where it
takes as input two neural networks fandf/prime, a set of inputs to the
neural networks Xdefined by box intervals, and a small constant ϵ
thatquantifiesthetolerancefordisagreement.Weassumethat f
andf/primehave the same network topology and only differ in the
numerical values of their weights. In practice, f/primecould be the
compressed version of f, or they could be networks constructed
using the same network topology but slightly different training
7842020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE)
Inputs NeuroDiff
Forward
Analysis
Convex
Approximation
Intermediate
Variables CheckϵYesVerifiedPartition
X
Nof f/prime
X⊆RnϵX1
X2
Proven?
Figure 1: The overall flow of NeuroDiff.
data.Wealsonotethatthisassumptioncansupportcompression
techniques such as weight pruning [ 14] (by setting edges’ weights
to 0) and even neuron removal [ 10] (by setting all of a neuron’s
incoming edge weights to 0). NeuroDiff then aims to prove ∀x∈
X.|f/prime(x)−f(x)|<ϵ. It can return (1) verifiedif a proof can be
found, or (2) undetermined if a specified timeout is reached.
Internally,NeuroDifffirstperformsaforwardanalysisusing
symbolic interval arithmetic to bound both the absolute value
ranges of all neurons, as in single network verification, and the dif-
ferencebetweentheneuronsofthetwonetworks.NeuroDiffthen
checksifthedifferencebetweentheoutputneuronssatisfies ϵ,and
if so returns verified. Otherwise, NeuroDiff uses a gradient-based
refinement topartition Xinto twodisjoint subregions X1andX2,
and attempts the analysis again on the individual regions. Since X1
andX2form independentsub-problems, wecan do theseanalyses
inparallel,hencegainingsignificantspeedup.
The new convex approximations used in NeuroDiff are signifi-
cantlymoreaccuratethannotonlythecoarse-grained concretiza-
tionsinReluDiff[ 33]butalsothestandardconvexapproximations
in single-network verification tools [ 39,40,47,54]. While these
(standard) convex approximations aim to bound the absolute value
range ofy=ReLU(x), wherexis the input of the rectified linear
unit(ReLU)activationfunction,ournewconvexapproximations
aim to bound the difference z=ReLU(x+Δ)−ReLU(x), where
xandx+ΔareReLUinputsoftwocorrespondingneurons.This
issignificantlymorechallengingbecauseitinvolvesthesearchof
bounding planes in a three-dimensional space (defined by x,Δand
z) as opposed to a two-dimensional space as in the prior work.
Thesymbolicvariableswejudiciouslyaddtorepresentvaluesof
neuronsinhiddenlayersshouldnotbeconfusedwiththesymbolicinputsusedbyexistingtoolseither.Whiletheuseofsymbolicinputs
is well understood, e.g., both in single-network verification [ 39,40,
47,54] and differential verification [ 33], this is the first time that
symbolic variables are used to substitute values of hidden neurons
duringdifferentialverification.Whiletheimpactofsymbolicinputs
often diminishes after the first few layers of neurons, the impactof these new symbolic variables, when judiciously added, can be
maintained in any hidden layer.
We have implemented the proposed NeuroDiff in a tool and
evaluated it on a large set of differential verification tasks. Ourbenchmarks consists of 49 networks, from applications such as
aircraftcollisionavoidance,imageclassification,andhumanactivityrecognition.WehaveexperimentallycomparedwithReluDiff[
33],
the state-of-the-art tool which has also been shown to be superior1.9
1.1
-1.9
1.02.1
0.9
1.1-1.01.0
-1.0n0,1
n0,2 n1,2n1,1 n2,1
n2,2n3,1x1∈[ −2,2]
x2∈[ −2,2]-2.01.02.0
1.0-1.01.02.0
1.01.0
-1.0
Figure 2: Motivating example.
to ReluVal [ 48] and DeepPoly [ 40] for differential verification.
Our results show that NeuroDiff is up to 1,000X faster and 5X
more accurate. In addition, NeuroDiff is able to prove many ofthe same properties as ReluDiff while considering much larger
input regions.
To summarize, this paper makes the following contributions:
•We propose new convex approximations to more accurately
boundthedifferencebetweencorrespondingneuronsoftwo
structurally similar neural networks.
•We proposea methodfor judiciouslyintroducing symbolic
variables to neurons in hidden layers to mitigate the propa-
gation of approximation error.
•We implement and evaluate the proposed technique on alarge number of differential verification tasks and demon-
strate its significant speed and accuracy gains.
The remainder of this paper is organized as follows. First, we
provide a brief overview of our method in Section 2. Then, weprovide the technical background in Section 3. Next, we present
thedetailedalgorithmsinSection4andtheexperimentalresultsinSection 5. We review the relatedwork in Section6. Finally, we give
our conclusions in Section 7.
2 OVERVIEW
Inthissection,wehighlightourmaincontributionsandillustrate
the shortcomings of previous work on a motivating example.
2.1 Differential Verification
WeusetheneuralnetworkinFigure2asarunningexample.The
network has two input nodes n0,1,n0,2, two hidden layers with
two neurons each ( n1,1,n1,2andn2,1,n2,2), and one output node
n3,1. Each neuron in the hidden layer performs a summation of
their inputs, followed by a rectified linear unit (ReLU) activation
function,definedas y=max(0,x),wherexistheinputtotheReLU
activation function, and yis the output.
Letthisentirenetworkbe f,andthevalueoftheoutputnodebe
n3,1=f(x1,x2),wherex1andx2arethevaluesofinputnodes n0,1
andn0,2,respectively. Thenetwork canbeevaluated onaspecific
input by performing a series matrix multiplications (i.e., affine
transformations) followed by element-wise ReLU transformations.
For example, the output of the neurons of the first hidden layer is
/bracketleftbiggn1,1
n1,2/bracketrightbigg
=ReLU/parenleftBigg/bracketleftbigg1.9−1.9
1.01.1/bracketrightbigg
·/bracketleftbiggx1
x2/bracketrightbigg/parenrightBigg
=/bracketleftbiggReLU(1.9x1−1.9x2)
ReLU(1.1x1+1.0x2)/bracketrightbigg
785Differential verification aims to compare fto another network
f/primethat is structurally similar. For our example, f/primeis obtained by
rounding the edge weights of fto the nearest whole numbers,
anetworkcompressiontechniqueknownas weightquantization.
Thus,f/prime,n/prime
k,jandn/prime
3,1=f/prime(x1,x2)are counterparts of f,nk,jand
n3,1=f(x1,x2)for 0≤k≤2 and 1≤j≤2. Our goal is to prove
that|f/prime(x1,x2)−f(x1,x2)|islessthansomereasonablysmall ϵfor
all inputs defined by the intervals x1∈[ −2,2]andx2∈[ −2,2]. For
easeofunderstanding,weshowtheedgeweightsof finblack,and
f/primein light blue in Figure 2.
2.2 Limitations of Existing Methods
Naively,onecouldadaptanystate-of-the-art,single-networkverifi-
cationtoolforourtask,includingDeepPoly[ 40]andNeurify[ 47].
Neurify, in particular, takes a neural network and an input region
of the network, and uses interval arithmetic [ 27,48] to produce
soundsymboliclowerandupperboundsforeachoutputnode.Typ-
ically, Neurify would then use the computed bounds to certify the
absence of adversarial examples [43] for the network.
However,forourtask,theboundsmustbecomputedforbothnet-
worksfandf/prime.Then,wesubtractthem,andconcretizetocompute
lower andupper boundson f/prime(x1,x2)−f(x1,x2). Inour example,
theindividualboundswouldbe(approximately,duetorounding)
[LB(f),UB(f)]=[−0.94x1−0.62x2−6.51,0.71x1−2.35x2+7.98]and
[LB(f/prime),UB(f/prime)]=[−0.94x1−0.44x2−6.75,0.75x1−2.25x2+8.00]
for nodes n3,1andn/prime
3,1, respectively. After the subtraction, we
would obtain the bounds [LB(f/prime)−UB(f),UB(f/prime)−LB(f)]=
[−1.65x1+1.9x2−14.73,1.68x1−1.63x2+14.5]. After concretiza-
tion, we would obtain the bounds [−21.83,21.12]. Unfortunately,
the bounds are far from being accurate.
The ReluDiff method of Paulsen et al. [ 33] showed that, by
directlycomputinga differenceinterval layer-by-layer,theaccuracy
canbegreatlyimproved.Fortherunningexample,ReluDiffwould
firstcomputeboundsonthedifferencebetweentheneurons n1,1
andn/prime
1,1,whichis [0,1.1],andthensimilarlycomputeboundsonthe
differencebetweenoutputsof n1,2andn/prime
1,2.Then,theresultswould
be used to compute difference bounds of the subsequent layer. The
reason it is more accurate is because it begins computing part of
the differencebound beforeerrors haveaccumulated, whereasthe
naive approach first accumulates significant errors at each neuron,
andthencomputesthedifferencebound.Inourrunningexample,
ReluDiff[ 33]wouldcomputethetighterbounds [−3.1101,2.5600].
While ReluDiff improves over the naive approach, in many
cases,ituses concretevaluesfortheupperandlowerbounds.Inprac-
tice,thisapproachcansufferfromsevereerror-explosion.Specifi-
cally, whenever a neuron of either network is in an unstablestate –
i.e.,whenaReLU’sinputintervalcontainsthevalue0–ithasto
concretize the symbolic expressions.
2.3 Our Method
ThekeycontributioninNeuroDiff,ournewmethod,isa symbolic
andfine-grained approximation technique that both reduces the
approximationerrorintroducedwhenaneuronisinanunstable
state,andmitigatestheexplosionofsuchapproximationerrorafter
it is introduced.2.3.1 ConvexApproximationfortheDifferenceInterval. Ourfirst
contributionisdevelopingconvexapproximationstodirectlybound
thedifferencebetweentwoneuronsaftertheseReLUactivations.
Specifically,foraneuron ninfandcorrespondingneuron n/primeinf/prime,
wewanttoboundthevalueof ReLU(n/prime)−ReLU(n).Weillustrate
the various choices using Figures 3, 4, and 5.
The naive way to bound this difference is to first compute ap-
proximations of y=ReLU(n)andy/prime=ReLU(n/prime)separately, and
then subtract them. Since each of these functions has a single vari-
able, convex approximation is simple and is already used by single-
network verification tools [ 40,47,49]. Figure 6 shows the function
y=ReLU(n)and its bounding planes (shown as dashed-lines) in
a two-dimensional space (details in Section 3). However, as we
havealreadymentioned,approximationerrorswouldbeaccumu-
latedintheboundsof ReLU(n)andReLU(n/prime)andthenamplifiedby
theinterval subtraction.Thisisprecisely whythenaiveapproach
performs poorly.
TheReluDiffmethodofPaulsenetal. [33]improvesuponthe
new approximation by computing an interval bound on n/prime−n, de-
noted Δ, thenrewriting z=ReLU(n/prime)−ReLU(n)asz=ReLU(n+
Δ)−ReLU(n), and finally bounding this new function instead. Fig-
ure 3 shows the shape of z=ReLU(n+Δ)−ReLU(n)in a three-
dimensional space. Note that it has four piece-wise linear subre-
gions,definedbyvaluesoftheinputvariables nandΔ.Whilethe
bounds computed by ReluDiff [ 33], shown as the (horizontal)
yellow planes in Figure 4, are sound, in practice they tend to be
loosebecausetheupperandlowerboundsarebothconcretevalues.
Such eager concretization eliminates symbolic information that Δ
contained before applying the ReLU activation.
In contrast, our method computes a convex approximation of z,
shownbythe(tilted)yellowplanesinFigure5.Sincethesetilted
bounding planes are in a three-dimensional space, they are sig-nificantly more challenging to compute than the standard two-dimensionalconvexapproximations(showninFigure6)usedbysingle network verification tools. Our approximations have the
advantage of introducing significantly less error than the horizon-
tal planes used in ReluDiff [ 33], while maintaining some of the
symbolic information for Δbefore applying the ReLU activation.
We will show through experimental evaluation (Section 5) that
our convex approximation can drastically improve the accuracy of
thedifferencebounds,andareparticularlyeffectivewhentheinput
region being considered is large. Furthermore, the tilted planes
showninFigure5areforthegeneralcase.Forcertainspecialcases,
we obtain even tighter bounding planes (details in Section 4). In
therunningexample,usingournewconvexapproximationswould
improve the final bounds to [−1.97,1.42].
2.3.2 SymbolicVariablesforHiddenNeurons. Oursecondcontri-
bution is introducing symbolic variables to represent the output
valuesofsomeunstableneurons,withthegoaloflimitingtheprop-
agationofapproximationerrorsaftertheyareintroduced.Inthe
running example, since both n1,1andn/prime
1,1are in unstable states,
i.e.,theinputintervalsoftheReLUscontainthevalue0,wemay
introduceanewsymbol x3=ReLU(n/prime
1,1)−ReLU(n1,1).Inallsub-
sequentlayers,wheneverthevalueof ReLU(n/prime
1,1)−ReLU(n1,1)is
needed, we use the bounds [x3,x3]instead of the actual bounds.
786Figure 3: The shape of z=ReLU(n+Δ)−ReLU(n).
 Figure 4: Bounding planes computed by ReluDiff [33].
Figure5:Boundingplanescomputedbyournewmethod.LB(n) UB(n)UB(ReLU(n))
LB(ReLU(n))
Figure 6: Bounding planes computed by Neurify [47].
The reason why using x3can lead to more accurate results is
because, even though our convex approximations reduce the error
introduced,thereisinevitablysomeerrorthataccumulates.Intro-
ducingx3allows this error to partially cancel in the subsequent
layers. In our running example, introducing the new symbolic vari-
ablex3would be able to improve the final bounds to [−1.65,1.18].
While creating x3improved the result in this case, carelessly
introducing new variables for all the unstable neurons can actually
reduce the overall benefit (see Section 4). In addition, the computa-
tionalcostofintroducingnewvariablesisnotnegligible.Therefore,
inpractice,wemustintroducethesesymbolicvariablesjudiciously,
to maximize the benefit. Part of our contribution in NeuroDiff is
in developing heuristics to automatically determine when to create
new symbolic variables (details in Section 4).
3 BACKGROUND
In this section, we review the technical background and then intro-
duce notations that we use throughout the paper.
3.1 Neural Networks
Wefocusonfeed-forwardneuralnetworks,whichwedefineasa
functionfthat takes an n-dimensional vector of real values x∈X,
whereX⊆Rn, and maps it to an m-dimensional vector y∈Y,
whereY⊆Rm.Wedenotethisfunctionas f:X→Y.Typically,eachdimension of yrepresentsa score,such asaprobability,that
the input xbelongs to class i, where 1 ≤i≤m.
A network with llayers has lweight matrices, each of which
is denoted Wk,for 1≤k≤l. For each weight matrix, we have
Wk∈Rlk−1×lkwherelk−1isthenumberofneuronsinlayer (k−1)
and likewisefor lk, andl0=n. Eachelement in Wkrepresents the
weight of an edge from a neuron in layer (k−1)to one in layer
k. Letnk,jdenote the jthneuron of layer k, andnk−1,idenote
theithneuronof layer (k−1).W euseWk[i,j]todenote theedge
weight from nk−1,itonk,j. In our motivating example, we have
W1[1,1]=1.9 andW1[1,2]=1.1.
Mathematically, the entire neural network can be represented
byf(x)=fl(Wl·fl−1(Wl−1·...f1(W1·x)...)), wherefkis the
activation function of the kthlayer and 1 ≤k≤l. We focus on
neural networks with ReLU activations because they are the most
widelyimplementedinpractice,butourmethodcanbeextended
to other activation functions, such as siдmoidandtanh, and other
layer types, such as convolutional and max-pooling. We leave this
as future work.
3.2 Symbolic Intervals
To compute approximations of the output nodes that are sound for
all input values, we leverage interval arithmetic [ 27], which can be
viewed as an instance of the abstract interpretation framework [ 5].
It is well-suited to the verification task because interval arithmetic
787is soundly defined for basic operations of the network such as
addition, subtraction, and scaling.
LetI=[LB(I),UB(I)]beanintervalwithlowerbound LB(I)and
upper bound UB(I). Then, for intervals I1,I2, we have addition and
subtractiondefinedas I1+I2=[LB(I1)+LB(I2),UB(I1)+UB(I2)]
andI1−I2=[LB(I1)−UB(I2),UB(I1)−LB(I2)], respectively. For
a constant c, scaling is defined as c×I1=[c×LB(I1),c×UB(I1)
whenc>0, andc×I1=[c×UB(I1),c×LB(I1)]otherwise.
While interval arithmetic is a sound over-approximation, it is
not always accurate. To illustrate, let f(x)=3x−x, and say we
are interested in bounding f(x)whenx∈[ −1,1]. One way to
boundfis by evaluating f(I)whereI=[−1,1]. Doing so yields
3×[ −1,1]−[ −1,1]=[−4,4]. Unfortunately, the most accurate
bounds are [−2,2].
Thereare(atleast)twowayswecanimprovetheaccuracy.First,
we can soundly refine the result by dividing the input intervals
into disjointpartitions,performing theanalysis independentlyon
each partition, and then unioning the resulting output intervals
together. Previous work has shown the result will be at leastas
precise[48],andoftenbetter.Forexample,ifwepartition x∈[ −1,1]
intox∈[ −1,0]andx∈[0,1], and perform the analysis for each
partition, the resulting bounds improve to [−3,3].
Second,thedependencebetweenthetwointervalsarenotlever-
aged when we subtract them, i.e., that they were both xterms and
hence could partially cancel out. To capture the dependence, we
canusesymbolic lowerandupperbounds[ 48],whichareexpres-
sions interms ofthe input variable,i.e., I=[x,x]. Evaluating f(I)
thenyieldstheinterval If=[2x,2x],forx∈[ −1,1].Whenusing
symbolic bounds, eventually, we must concretize the lower and
upperboundequations.Wedenoteconcretizationof LB(If)=2x
andUB(If)=2xasLB(If)=−2 and UB(If)=2, respectively.
Compared to the naive solution, [−4,4], this is a significant im-
provement.
When approximating the output of a given function f:X→Y
overaninputinterval X⊆X,onemayprovesoundnessbyshowing
that the evaluation of the lower and upper bounds on any input
x∈Xare always greater than and less than, respectively, to the
true value of f(x). Formally, for an interval I, letLB(I)(x)be the
evaluationofthelowerboundequationoninput x,andsimilarlyfor
UB(I)(x).Then,theapproximationisconsideredsoundif ∀x∈X,
we have LB(I)(x)≤f(x)≤UB(I)(x).
3.3 Convex Approximations
Whilesymbolicintervalsareexactforlinearoperations(i.e.theydo
notintroduceerror),thisis notthecasefornon-linearoperations,
such as the ReLU activation. This is because, for efficiency reasons,
thesymboliclowerandupperboundsmustbekeptlinear.Thus,de-
veloping linear approximations for non-linear activation functions
hasbecomeasignifciantareaofresearchforsingleneuralnetwork
verification[ 40,47,49,54].Wereviewthebasicsbelow,butcaution
that they are different from our new convex approximations in
NeuroDiff.
WedenotetheinputtotheReLUofaneuron nk,jasSin(nk,j)and
theoutputas S(nk,j).Theapproachusedbyexistingsingle-network
verification tools is to apply an affine transformation to the upper
bound of Sin(nk,j)such that UB(Sin(nk,j))(x)≥0, where x∈X,andXis the input region for the entire network. For the lower
bound,thereexistseveralpossibletransformations,includingthe
one used by Neurify [ 47], shown in Figure 6, where n=Sin(nk,j)
and the dashed lines are the upper and lower bounds.
Weillustratetheupperboundtransformationfor n1,1ofourmoti-
vatingexample.AftercomputingtheupperboundoftheReLUinput
UB(Sin(n1,1))=1.9x1−1.9x2, wherex1∈[ −2,2]andx2∈[ −2,2],
itcomputestheconcretelowerandupperbounds.Wedenotethese
asUB(Sin(n1,1))=−7.6and UB(Sin(n1,1))=7.6.Werefertothem
aslandu,respectively, forshorthand. Then,itcomputesthe line
that passes through (u,u)and(0,l). Letting y=UB(Sin(n1,1))
be the upper bound equation of the ReLU input, it computes the
upper bound of the ReLU output as UB(S(n1,1))=u
u−l(y−l)=
0.95x1−0.95x2+3.81.
When considering a single ReLU of a single network, convex
approximation is simple because there are only three states thatthe neuron can be in, namely active, inactive, and unstable. Fur-thermore, in only one of these states, convex approximation is
needed.Incontrast,differentialverificationhasto considerapair
of neurons, which has up to nine states to consider between the
twoReLUs.Furthermore,differentstatesmayresultindifferentlin-
ear approximations, and some states can even have multiple linear
approximationsdependingonthedifferenceboundof Δ=n/prime−n.
AswewillshowinSection4,therearesignificantlymoreconsider-
ations in our problem domain.
4 OUR APPROACH
We first present our baseline procedure for differential verification
offeed-forwardneuralnetworks(Section4.1),andthenpresentour
algorithms for computing convex approximations (Section 4.3) and
introducing symbolic variables (Section 4.4).
4.1 Differential Verification – Baseline
We build off the work of Paulsen et al. [ 33], so in this section we
reviewtherelevantpieces.WeassumethattheinputtoNeuroD-
iff consists of two networks fandf/prime, each with llayers of the
same size.Let n/prime
k,jinf/primebe theneuron paired with nk,jinf. This
implicitly creates a pairing of the edge weights between the two
networks. We first introduce additional notation.
•Wedenotethedifferencebetweenapairofneuronsas Δk,j=
n/prime
k,j−nk,j. For example, Δ1,1=0.1 under the input x1=
2,x2=1 in our motivating example shown in Figure 2.
•Wedenotethedifferenceinapairofedgeweightsas WΔ
k[i,j]=
W/prime
k[i,j]−Wk[i,j]. For example, WΔ
1[1,1]=2.0−1.9=0.1.
•We extend the symbolic interval notation to these terms.
Thatis,Sin(Δk,j)denotestheintervalthatbounds n/prime
k,j−nk,j
beforeapplyingReLU,and S(Δk,j)denotestheintervalafter
applying ReLU.
Giventhatwehavecomputed S(nk−1,i),S(n/prime
k−1,i),S(Δk−1,i)for
every neuron in the layer k−1, now, we compute a single S(Δk,j)
in the subsequent layer kin two steps (and then repeat for each
1≤j≤lk).
First,wecompute Sin(Δk,j)bypropagatingtheoutputintervals
from the previous layer through the edges connecting to the target
788(x−l)u−l/prime
u−l+l/prime
(x−u)u/prime−l
u−l+u/primel
u
Figure 7: Illustration of Lemmas 4.1 and 4.2.
neuron. This is defined as
Sin(Δk,j)=/summationdisplay.1
i/parenleftbigg
S(Δk−1,i)×W/prime
k[i,j]+S(nk−1,i)×WΔ
k−1[i,j]/parenrightbigg
Weillustratethiscomputationonnode Δ1,1inourexample.First,
we initialize S(Δ0,1)=[0,0],S(Δ0,2)=[0,0]. Then we compute
Sin(Δ1,1)=[0,0]×2.0+[x1,x1]×0.1+[0,0]×−2.0+[x2,x2]×−0.1=
[0.1x1−0.1x2,0.1x1−0.1x2].
Forthesecondstep,weapplyReLUto Sin(Δk,j)toobtainS(Δk,j).
Thisiswhereweapplythenewconvexapproximations(Section4.3)
to obtain tighter bounds. Toward this end, we will focus on the
following two equations:
z1=ReLU(nk,j+Δk,j)−ReLU(nk,j) (1)
z2=ReLU(n/prime
k,j)−ReLU(n/prime
k,j−Δk,j) (2)
WhilePaulsenetal.[ 33]alsocomputeboundsofthesetwoequa-
tions,theyuse concretizations insteadof linearapproximations,thus
throwingawayallthesymbolicinformation.Fortherunningexam-
ple, their method wouldresult in the bounds of S(Δ1,1)=[−.4,.4].
In contrast, our method will be able to maintain some or all of the
symbolic information, thus improving the accuracy.
4.2 Two Useful Lemmas
Before presenting our new linear approximations, we introduce
two useful lemmas, which will simplify our presentation as well as
our soundness proofs.
Lemma4.1. Letxbea variablesuchthat l≤x≤uforconstants
l≤0and0≤u. For a constant l/primesuch that l≤l/prime≤0, we have
x≤(x−l)∗u−l/prime
u−l+l/prime≥l/prime.
Lemma4.2. Letxbea variablesuchthat l≤x≤uforconstants
l≤0and0≤u. For a constant u/primesuch that 0≤u/prime≤u, we have
u/prime≥(x−u)∗u/prime−l
u−l+u/prime≤x.
WeillustratetheselemmasinFigure7.Thesolidbluelineshows
the equation y=xfor the input interval l≤x≤u. The upper
dashed line illustrates the transformation of Lemma 4.1, and the
lower dashed line illustrates Lemma 4.2. Specifically, Lemma 4.1
shows a transformation applied to xwhose result is always greater
thanboth l/primeandx.Similarly,Lemma4.2showsatransformation
applied to xwhose resultis always lessthan both u/primeandx. These
lemmas will be useful in bounding Equations 1 and 2.4.3 New Convex Approximations for S(Δk,j)
Now,wearereadytopresentournewapproximations,whichare
linear symbolic expressions derived from Equations 1 and 2.
We first assume that nk,jandn/prime
k,jcould both be unstable, i.e.,
theycouldtakevaluesbothgreaterthanandlessthan0.Thisyieldsboundsforthegeneralcaseinthattheyaresoundinallstatesof
nk,j
andn/prime
k,j(Sections 4.3.1 and 4.3.2). Then, we consider special cases
ofnk,jandn/prime
k,j,inwhicheventighterupperandlowerboundsare
derived (Section 4.3.3).
Tosimplifynotation,welet n,n/prime,andΔstandinfor nk,j,n/prime
k,j,
andΔk,jin the remainder of this section.
4.3.1 UpperBoundfortheGeneralCase. Letl=UB(Sin(Δ))and
u=UB(Sin(Δ)). The upper bound approximation is:
UB(S(Δ))=⎧⎪⎪⎪ ⎨
⎪⎪⎪⎩UB(Sin(Δ)) UB(Sin(Δ)) ≥0
0 UB(Sin(Δ)) ≤0
(UB(Sin(Δ))−l)∗u
u−lotherwise
Thatis,whentheinput’s(delta)upperboundisgreaterthan0forall
x∈X,wecanusetheinput’supperboundunchanged.Whenthe
upperboundisalwayslessthan0,thenewoutput’supperbound
is then 0. Otherwise, we apply a linear transformation to the upper
bound, which results in the upper plane illustrated in Figure 5. We
prove all three cases sound.
Proof.Weconsidereachcaseaboveseparately.Inthefollowing,
weuseEquation1toderivethebounds,butwenoteasymmetric
proof using Equation 2 exists and produces the same bounds.
Case1: UB(Sin(Δ)) ≥0.Wefirstshowthat,accordingtoEqua-
tion 1, when 0 ≤Δwe have z1≤Δ. This then implies that, if
UB(Sin(Δ)) ≥0, thenz1≤UB(Sin(Δ))(x)for allx∈X, and hence
it is a valid upper bound for the output interval.
Assume 0 ≤Δ. We consider two cases of n. First, consider 0 ≤n.
Observe 0 ≤n∧0≤Δ=⇒0≤n+Δ. Thus, the ReLU’s of
Equation 1 simplify to z1=n+Δ−n=Δ=⇒z1≤Δ. When
n<0, Equation 1 simplifies to z1=ReLU(n+Δ). Sincen<0,
we have n+Δ≤Δ∧0≤Δ=⇒ReLU(n+Δ)≤Δ. Thus,
z1=ReLU(n+Δ)≤Δ, so the approximation is sound.
Case 2: UB(Sin(Δ)) ≤0.This case was previously proven [ 33],
but we restate it here. UB(Sin(Δ)) ≤0⇐⇒n/prime≤n=⇒
ReLU(n/prime)≤ReLU(n)⇐ ⇒ReLU(n/prime)−ReLU(n)≤0.
Case 3.By case 1, any UB(S(Δ))that satisfies UB(S(Δ))(x)≥0
andUB(S(Δ))(x)≥UB(Sin(Δ))(x)for allx∈Xis sound. Both in-
equalitiesholdbyLemma4.1,with x=UB(Sin(Δ)),l=UB(Sin(Δ)),
u=UB(Sin(Δ))andl/prime=0.
/square
We illustrate the upper bound computation on node n1,1of our
motivating example. Recall that UB(Sin(n1,1))=0.1x1−0.1x2.
Since UB(Sin(n1,1))=−0.4 and UB(Sin(n1,1))=0.4, we are in
the third case of our linear approximation above. Thus, we have
UB(Sin(n1,1))=(0.1x1−0.1x2−(−0.4))∗0.4
0.4−(−0 .4)=0.5x1−0.5x2+
0.2.This istheupperboundingplaneillustratedin Figure5.The
volume under this plane is 50% less than the upper bounding plane
of ReluDiff shown in Figure 4.
7894.3.2 Lower Bound for the General Case. Letl=LB(Sin(Δ))and
u=LB(Sin(Δ)), the lower bound approximation is:
LB(S(Δ))=⎧⎪⎪⎪ ⎨
⎪⎪⎪⎩LB(Sin(Δ)) LB(Sin(Δ)) ≤0
0 LB(Sin(Δ)) ≥0
(LB(Sin(Δ))−u)∗−l
u−lotherwise
That is,whenthe inputlower boundis alwaysless than0, wecan
leaveitunchanged.Whenitisalwaysgreaterthan0,thenewlower
boundisthen0.Otherwise,weapplyatransformationtothelower
bound, which results in the lower plane illustrated in Figure 5. We
prove all three cases sound.
Proof.Weconsidereachcaseaboveseparately.Inthefollowing,
weuseEquation1toderivethebounds,butwenoteasymmetric
proof using Equation 2 exists and produces the same bounds.
Case 1: LB(Sin(Δ)) ≤0.We first show that according to Equa-
tion 1, when Δ≤0 we have Δ≤z1. This then implies that, if
LB(Sin(Δ)) ≤0, we have LB(Sin(Δ))(x)≤z1for allx∈X, and
hence it is a valid lower bound for the output interval.
Assume Δ≤0. We consider two cases of n+Δ. First, let 0 ≤
n+Δ. Observe 0 ≤n+Δ∧Δ≤0=⇒0≤n,s ow ec a n
simplify Equation 1 to z1=n+Δ−n=Δ=⇒Δ≤z1. Second,
letn+Δ<0⇐⇒ Δ<−n. Then, Equation 1 simplifies to
z1=−ReLU(n)=−max(0,n)=min(0,−n). Now observe Δ<
−n∧Δ<0=⇒Δ<min(0,−n)=z1.
Case 2: LB(Sin(Δ)) ≥0.This case was previously proven sound
[33], but we restate it here. LB(Sin(Δ)) ≥0⇐⇒n/prime≥n=⇒
ReLU(n/prime)≥ReLU(n)⇐ ⇒ReLU(n/prime)−ReLU(n)≥0.
Case 3.By case 1, any LB(S(Δ))that satisfies LB(S(Δ))(x)≤0
andLB(S(Δ))(x)≤LB(Sin(Δ))(x)for allx∈Xwill be valid. Both
inequalities hold by Lemma 4.2, with x=LB(Sin(Δ)),u/prime=0,l=
LB(Sin(Δ)),andu=LB(Sin(Δ)).
/square
We illustratethe lowerboundcomputation onnode n1,1ofour
motivatingexample.Recallthat LB(Sin(n1,1))=0.1x1−0.1x2.Since
LB(Sin(n1,1))=−0.4 and LB(Sin(n1,1))=0.4, we are in the third
case of our linear approximation. Thus, we have LB(S(n1,1))=
(0.1x1−0.1x2−(−0.4))∗−(−0 .4)
0.4−(−0 .4)=0.05x1−0.05x2−0.2.Thisis
thelowerboundingplaneillustratedinFigure5.Thevolumeabove
this plane is 50% lessthan the lower bounding plane of ReluDiff
shown in Figure 4.
4.3.3 Tighter Bounds for Special Cases. While the bounds pre-
sented so far apply in all states of nandn/prime, under certain con-
ditions,weareabletotightentheseboundsevenfurther.Toward
thisend,werestatethefollowingtwolemmasprovedbyPaulsen
etal.[33],whichwillcomeinhandy.Theyarerelatedtoproperties
of Equations 1 and 2, respectively.
Lemma 4.3. ReLU(n+Δ)−n≡max(−n,Δ)
Lemma 4.4. n/prime−ReLU(n/prime−Δ)≡min(n/prime,Δ)
Theselemmasprovideboundswhen nandn/primear epr o v edtobe
linear based on the absolute bounds that we compute.
Figure 8: Tighter upper bounding plane.
Figure 9: Tighter lower bounding plane.
Tighter Upper Bound When n/primeIs Linear. In this case, we have
UB(S(Δ))=UB(Sin(Δ)),whichisanimprovementforthesecond
or third case of our general upper bound.
Proof.Byourcaseassumption,Equation2simplifiestotheone
in Lemma 4.4. Thus, z2=min(n/prime,Δ)=⇒z2≤Δ. /square
TighterUpperBoundWhen nIsLinear, UB(Sin(Δ)) ≤−LB(Sin(n))
≤UB(Sin(Δ)).Weillustratethe z1planeundertheseconstraints
in Figure 8. Let l=UB(Sin(Δ)), and letu=UB(Sin(Δ)), andl/prime=
−LB(Sin(n)),weuseLemma4.1toderive UB(S(Δ))=(UB(Sin(Δ))−
l)∗u−l/prime
u−l+l/prime.ThisresultsintheupperplaneofFigure8.Thisimproves
over the third case in our general upper bound because it allows
the lower bound of UB(S(Δ))to be less than 0.
Proof.Byourcaseassumption,Equation1simplifiestotheone
inLemma4.3.ByLemma4.1,wehaveforall x∈X,UB(S(Δ))(x)≥
−LB(Sin(n))andUB(S(Δ))(x)≥UB(Sin(Δ))(x).Thesetwoinequal-
ities imply UB(S(Δ)) ≥max(−n,Δ). /square
Tighter Lower Bound When nIs Linear. Here, we can use the
approximation LB(S(Δ))=LB(Sin(Δ)). This improves over the
second and third cases of our general lower bound.
Proof.Byourcaseassumption,Equation1simplifiestotheone
in Lemma 4.3. Thus, z1=max(−n,Δ)=⇒z1≥Δ. /square
TighterLowerBoundwhen n/primeisLinear, LB(Sin(Δ))≤LB(Sin(n/prime))
≤LB(Sin(Δ)).We illustrate the z2plane under these constraints
in Figure 9. Here, letting l=LB(Sin(Δ)),u=LB(Sin(Δ)), andu/prime=
LB(Sin(n/prime)), we can use Lemma 4.2 to derive the approximation
LB(S(Δ))=(LB(Sin(Δ))−u)∗u−l/prime
u−l+u/prime.Thisresultsinthelower
plane of Figure 9. This improves over the third case, since it allows
the upper bound to be greater than 0.
790Proof.By our case assumption, Equation 2 simplifies to the
one shown in Lemma 4.4. By Lemma 4.2, we have for all x∈
X,LB(S(Δ))(x)≤LB(Sin(Δ))(x)andLB(S(Δ))(x)≤LB(Sin(n/prime)).
These two inequalities imply LB(S(Δ))(x)≤min(n/prime,Δ). /square
4.4 Intermediate Symbolic Variables for S(Δ)
WhileconvexapproximationsreducetheerrorintroducedbyReLU,
even small errors tend to be amplified significantly after a few
layers. To combat the error explosion, we introduce new symbolic
terms to represent the output values of unstable neurons, which
allow their accumulated errors to cancel out.
We illustrate the impact of symbolic variables on n1,1of our
motivatingexample.Recallwehave S(Δ1,1)=[0.05x1−0.05x2−0.2,
0.05x1−0.05x2+0.2].Afterapplyingtheconvexapproximation,we
introduce anew variable x3such that x3=[0.05x1−0.05x2−0.2,
0.05x1−0.05x2+0.2].Thenweset S(Δ1,1)=[x3,x3],andpropagate
thisintervalasbefore.Afterpropagatingthrough n2,1andn2,2and
combining them at n3,1, thex3terms partially cancel out, resulting
in the tighter final output interval [−1.65,1.18].
In principle, symbolic variables may be introduced at any unsta-
ble neurons that introduce approximation errors, however there
areefficiencyvs.accuracytradeoffswhenintroducingthesesym-
bolic variables. One consideration is how to deal with intermediate
variables referencing other intermediate variables. For example,
if we decide to introduce a variable x4forn2,1, thenx4will have
anx3term in its equation. Then, when we are evaluating a sym-
bolic bound that contains an x4term, which will be the case for
n3,1,wewillhavetorecursivelysubstitutetheboundsofthepre-
viousintermediatevariables,suchas x3.Thisbecomesexpensive,
especially when it is used together with our bisection-based refine-
ment[33,48].Thus,inpractice,wefirstremoveanyback-references
to intermediate variables by substituting in their lower bounds and
upperboundsintothenewintermediatevariable’slowerandupper
bounds, respectively.
Given that we do not allow back-references, there are two ad-
ditional considerations. First, we must consider that introducinga new intermediate variable wipes out all the other intermediate
variables. For example, introducing a new variable at
n2,1wipes
outreferencesto x3,thuspreventingany x3termsfromcanceling
atn3,1. Second, the runtime cost of introducing symbolic variables
is not negligible. The bulk of computation time in NeuroDiff is
spentmultiplyingthenetwork’sweightmatricesbytheneuron’s
symbolicboundequations,whichisimplementedusingmatrixmul-
tiplication. Since adding variables increases the matrix size, this
increases the matrix multiplication cost.
Based on these considerations, we have developed heuristics for
adding new variables judiciously. First, since the errors introduced
by unstable neurons in the earliestlayers are the most prone to
explode,andhencebenefitthemostwhenwecreatevariablesfor
them, we rank them higher when choosing where to add symbolic
variables.Second,weboundthetotalnumberofsymbolicvariables
that may be added, since our experience shows that introducing
symbolicvariablesfortheearliest Nunstableneuronsgivesdrastic
improvementsin bothrun timeandaccuracy. Inpractice, Nisset
to a number proportional to the weighted sum of unstable neuronsin all layers. Formally, N=ΣL
k=1γk×Nk, whereNkis the number
of unstable neurons in layer kandγk=1
kis the discount factor.
5 EXPERIMENTS
We have implemented NeuroDiff and compared it with ReluD-
iff [33], the state-of-the-art tool for differential verification of
neural networks. NeuroDiff builds upon the codebase of ReluD-iff [32], which was also used by single-network verification tools
such as ReluVal [ 48] and Neurify [ 47]. All use OpenBLAS [ 55]t o
optimize the symbolic interval arithmetic (namely in applying the
weightmatricestothesymbolicintervals).WenotethatNeuroDiff
usesthealgorithmfromNeurifytocompute S(nk,j)andS(n/prime
k,j),
whereasReluDiffusesthealgorithmof ReluVal.SinceNeurifyis
known to compute tighter bounds than ReluVal [ 47], we compare
to both ReluDiff, and an upgraded version of ReluDiff which
usestheboundsfromNeurifytoensurethatanyperformancegainis due to our optimizations and not due to using Neurify’s bounds.
WeusethenameReluDiff+torefertoReluDiffupgradedwith
Neurify’s bounds.
5.1 Benchmarks
Our benchmarks consist of the 49 feed-forward neural networks
usedbyPaulsenetal.[ 33],takenfromthreeapplications:aircraft
collision avoidance, image classification, and human activity recog-
nition. We briefly describe them here. As in Paulsen et al. [ 33], the
second network f/primeis generated by truncating the edge weights of
ffrom 32 bit to 16 bit floats.
ACAS Xu [ 16].ACAS (aircraft collision avoidance system) Xu
is a set of forty-five neural networks, each with five inputs, six
hidden layers of 50 units each, and five outputs, designed to advise
a pilot (the ownship) how to steer an aircraft in the presence of an
intruder aircraft. The inputs describe the position and s peed of the
intruder relative tothe ownship, and the outputs representscores
fordifferentactionsthattheownshipshouldtake.Thescoresrangefrom
[−0.5,0.5].Weusetheinputregionsdefinedbytheproperties
of previous work [17, 48].
MNIST[21].MNISTisastandardimageclassificationtask,where
the goal is to correctly classify 28 ×28 pixel greyscale images of
handwritten digits. Neural networks trained for thistask take 784
inputs (one for each pixel) each in the range [0,255], and compute
tenoutputs–onescoreforeachofthetenpossibledigits.Weuse
threenetworksofsize3x100(threehiddenlayersof100neurons
each), 2x512, and 4x1024 taken from Weng et al. [ 49] and Wang et
al.[47]. All achieve at least 95% accuracy on holdout test data.
Human Activity Recognition (HAR) [ 1].The goal for this task
is to classify the current activity of human (e.g. walking, sitting,
layingdown)basedonstatisticsfromasmartphone’sgyroscopic
sensors.Networkstrainedonthistasktake561statisticscomputed
from the sensors and output six scores for six different activities.
We use a 1x500 network.
5.2 Experimental Setup
Our experiments aim to answer the following research questions:
(1) Is NeuroDiff significantly faster than state-of-the-art?
791Figure 10: Comparing the execution times of NeuroDiff
and ReluDiff+ on all verification tasks.
(2) Is NeuroDiff’s forward pass significantly more accurate?(3) Can NeuroDiff handle significantly larger input regions?(4)
How much does each technique contribute to the overall
improvement?
To answer these questions, we run both NeuroDiff and ReluD-
iff/ReluDiff+ on all benchmarks and compare their results. Both
NeuroDiff and ReluDiff/ReluDiff+ can be parallelized to usemultithreading,soweconfigureamaximumof12threadsforall
experiments.OurexperimentsarerunonacomputerwithanAMD
Ryzen Threadripper 2950X 16-core processor, with a 30-minute
timeout per differential verification task.
While we could try and adapt a single-network verification tool
toourtaskasdonepreviously[ 33],wenotethatReluDiffhasbeen
showntosignificantlyoutperform(byseveralordersofmagnitude)
this naive approach.
5.3 Results
Intheremainderofthissection,wepresentourexperimentalresults
in two steps. First, we present the overall verification results on all
benchmarks. Then, we focus on the detailed verification results on
the more difficult verification tasks.
5.3.1 Summary of Results on All Benchmarks. Our experimental
results show that, on all benchmarks, the improved ReluDiff+
slightly but consistently outperforms the original ReluDiff due to
itsuseofthemoreaccuratecomponentfromNeurifyinsteadof
ReluValforboundingtheabsolutevaluesofindividualneurons.
Thus, to save space, we will only show the results that compare
NeuroDiff (our method) and ReluDiff+.
WesummarizethecomparisonbetweenNeuroDiffandReluD-
iff+ using a scatter plot in Figure 10, where each point represents
adifferentialverificationtask:thex-axisistheexecutiontimeof
NeuroDiffinseconds,andthey-axistheexecutiontimeof ReluD-
iff+ in seconds. Thus, points on the diagonal line are ties, while
points above the diagonal line are wins for NeuroDiff.
The results show that NeuroDiff outperformed ReluDiff+ for
most verification tasks. Since the execution time is in logrithmic
scalethespeedupsof NeuroDiffaremorethan1000Xformany
oftheseverificationtasks.WhiletherearecaseswhereNeuroDiff
is slower than ReluDiff+, due to the overhead of adding symbolic
variables, the differences are on the order of seconds. Since theyTable 1: Results for ACAS networks with ϵ=0.05.
PropertyNeuroDiff (new) ReluDiff+Speedupproved undet. time (s) proved undet. time (s)
φ1 45 0 522.6 44 1 4800.6 9.2
φ3 42 0 2.3 42 0 4.1 1.8
φ4 42 0 1.7 42 0 2.8 1.7
φ5 1 0 0.2 1 0 0.2 1.4
φ6 2 0 0.6 2 0 0.4 0.7
φ7 1 0 1404.4 0 1 1800.0 1.3
φ8 1 0 132.2 1 0 361.8 2.7
φ9 1 0 0.6 1 0 2.3 3.7
φ10 1 0 0.9 1 0 0.7 0.8
φ11 1 0 0.2 1 0 0.3 1.6
φ12 1 0 2.8 1 0 360.9 129.4
φ13 1 0 5.8 1 0 5.1 0.9
φ14 2 0 0.5 2 0 95.9 196.2
φ15 2 0 0.6 2 0 65.0 113.2
Table 2: Results for ACAS networks with ϵ=0.01.
PropertyNeuroDiff (new) ReluDiff+Speedupproved undet. time (s) proved undet. time (s)
φ1 41 4 11400.1 15 30 55778.6 4.9
φ3 42 0 14.3 35 7 13642.2 957.2
φ4 42 0 3.8 37 5 9115.0 2390.1
φ5 1 0 0.3 0 1 1800.0 5520.5
φ16 2 0 1.0 2 0 0.8 0.8
φ7 0 1 1800.0 0 1 1800.0 1.0
φ8 1 0 1115.9 0 1 1800.0 1.6
φ9 1 0 2.4 0 1 1800.0 738.2
φ10 1 0 1.6 1 0 1.1 0.7
φ11 1 0 0.3 0 1 1800.0 5673.8
φ12 1 0 132.2 0 1 1800.0 13.6
φ13 1 0 15.9 1 0 14.8 0.9
φ14 2 0 1589.3 0 2 3600.0 2.3
φ15 2 0 579.4 0 2 3600.0 6.2
are all on the small MNIST networks and the HAR network that
are very easy for both tools, we omit an in-depth analysis of them.
Intheremainderofthissection,wepresentanin-depthanalysis
of the more difficult verification tasks.
5.3.2 ResultsonACASNetworks. ForACASnetworks,weconsider
twodifferentsetsofproperties,namelytheoriginalpropertiesfromPaulsenetal.[
33]whereϵ=0.05,andthesamepropertiesbutwith
ϵ=0.01.Weemphasizethat,whileverifying ϵ=0.05isuseful,this
means that the output value can vary by up to 10%. Considering
ϵ=0.01 means that the output value can vary by up to 2%, which
is much more useful.
Our results are shown in Tables 1 and 2, where the first column
shows the property, which defines the input space considered. The
nextthreecolumnsshowtheresultsforNeuroDiff,specificallythe
number of verified networks (out of the 45 networks), the number
of unverified networks, and the total run time across all networks.
Thenextthreeshowthesameresults,butforReluDiff+.Thefinal
column shows the average speedup of NeuroDiff.
The results show that NeuroDiff makes significant gains in
bothspeedand accuracy.Specifically,thespeedupsareuptotwo
andthreeordersofmagnitudefor ϵ=0.05and0.01,respectively.In
addition, at the more accurate ϵ=0.01 level, NeuroDiff is able to
complete53moreverificationtasks,outofthetotal142verification
tasks.
792Figure11:Percentageofverificationtaskscompletedon
the MNIST 4x1024 network for various perturbations.
Figure12:Accuracycomparisonforasingleforwardpasson the MNIST 4x1024 network with perturbation of 8.
5.3.3 Results on MNIST Networks. For MNIST, we focus on the
4x1024network,whichisthelargestnetworkconsideredbyPaulsen
et al. [33]. In contrast, since the smaller networks, namely 3x100
and 2x512 networks, were handled easily by both tools, we omit
their results. In the MNIST-related verification tasks, the goal is to
verifyϵ=1forthegiveninputregion.Weconsiderthetwotypesof
inputregionsfromthepreviouswork,namelyglobalperturbations
and targeted pixel perturbations, however we use input regions
that are hundreds of orders of magnitude larger.
First, we look at the global perturbation. For these, the input
space is created by taking an input image and then allowing a per-
turbation of +/- pgreyscale units to all of its pixels. In the previous
work, the largest perturbation was p=3. Figure 11 compares Neu-
roDiff and ReluDiff+ on p=3 all the way up to 8, where the
x-axis is the perturbation applied, and the y-axis is the percentage
of verification tasks (out of 100) that each can handle.
The results show that NeuroDiff can handle perturbations up
to+/-6units,whereasReluDiff+beginstostruggleat4.Whilethe
differencebetween4and6,mayseemsmall,thevolumeofinput
space for a perturbation of 6 is 6784/4784≈1.1×10138times larger
than 4, or in other words, 138 orders of magnitude larger.
Next,we showacomparison oftheepsilon verifiedbya single
forward pass for a perturbation of 8 on the MNIST 4x1024 network
in Figure 12. Points above the blue line indicate NeuroDiff per-
formed better. Overall, NeuroDiff is between two and three times
more accurate than ReluDiff+.
Finally, we look at the targeted pixel perturbation properties.
For these, the input space is created by taking an image, randomly
choosing npixels,andsettingthereboundsto [0,255],i.e.,allowing
arbitrary changes to the chosen pixels. We again use the 4x1024
MNISTnetwork.TheresultsaresummarizedinTable3.Thefirst
columnshowsthenumberofrandomlyperturbedpixels.Wecan
againseeverylargespeedups,andasignificantincreaseinthesize
of the input region that NeuroDiff can handle.
5.3.4 ContributionofEachTechnique. Here,weanalyzethecon-
tribution of individual techniques, namely convex approximations
and symbolic variables, to the overall performance improvement.
In Table 4, we present the average ϵthat was able to be verified
after a single forward pass on the 4x1024 MNIST network for each
of the four techniques: ReluDiff+ (baseline), NeuroDiff withTable 3: Results of the MNIST 4x1024 pixel experiment.
Num.
PixelsNeuroDiff (new) ReluDiff+Speedupproved undet. time (s) proved undet. time (s)
15100 0 236.5 100 0 1610.2 6.8
18100 0 540.8 88 12 34505.8 63.8
21100 0 1004.0 30 70 145064.5 144.5
24 99 1 7860.1 1 99 179715.9 22.9
27 83 17 49824.0 0 100 180000.0 3.6
Table 4: Evaluating the individual contributions of convex
approximation and symbolic variables using the MNIST
4x1024 global perturbation experiment.
PerturbAverageϵVerified
ReluDiff+ Conv. Approx. Int. Vars. NeuroDiff
3 0.59 0.42 (+1.39x) 0.43 (+1.38x) 0.20 (+2.93x)
4 1.02 0.70 (+1.46x) 0.87 (+1.18x) 0.36 (+2.85x)
5 1.60 1.06 (+1.52x) 1.47 (+1.09x) 0.56 (+2.87x)
6 2.29 1.47 (+1.55x) 2.19 (+1.04x) 0.79 (+2.90x)
7 3.02 1.92 (+1.58x) 2.96 (+1.02x) 1.04 (+2.91x)
8 3.80 2.39 (+1.59x) 3.77 (+1.01x) 1.30 (+2.93x)
onlyconvexapproximations,NeuroDiffwithonlyintermediate
variables, and the full NeuroDiff.
Overall, the individual benefits of the two proposed approxima-
tiontechniquesareobvious.Whileconvexapproximation(alone)
consistently provides benefit as perturbation increases, the ben-efit of symbolic variables (alone) tends to decrease. In addition,
combining the two providesmuch greater benefit than the sum of
their individual contributions. With perturbation of 8, for example,
convex approximations alone are 1.59 times more accurate than
ReluDiff+,andintermediatevariablesaloneare1.01timesmore
accurate. However, together they are 2.93 times more accurate.
Theresultssuggesttwothings.First,intermediatesymbolicvari-
ables perform well when a significant portion of the network is
already in the stable state. We confirm, by manually inspecting the
experimental results, that it is indeed the case when we use a per-
turbationof3and8intheMNISTexperiments.Second,theconvex
approximations provide the most benefit when the pre-ReLU delta
intervalsare(1)significantlywide,and(2)stillcontainasignificant
793amount of symbolic information. This is also confirmed by man-
ually inspecting our MNIST results: increasing the perturbation
increases the overall width of the delta intervals.
6 RELATED WORK
Aside from ReluDiff [ 33], the most closely related to our work
arethosethatfocusonverifyingpropertiesofsinglenetworksas
opposedtotwoormorenetworks.Theseverificationapproaches
can be broadly categorized into those that use exact, constraint
solving-based techniques and those that use approximations.
Ontheconstraintsolvingside,severalworkshaveadaptedoff-
the-shelfsolvers[ 2–4,7,45],orevenimplementedsolversspecif-
ically for neural networks [ 17,18]. On the approximation side,
many use techniques that fit into the framework of abstract inter-
pretation [ 5]. For example, many works have leveraged abstract
domainssuchasintervals[ 16,48,49,54],polyhedra[ 39,40],and
zonotopes [9, 41].
In addition, these verification techniques have also been com-
bined[15,41,47],orentirelydifferentapproaches[ 6,12,38],suchas
bounding a network’s lipschitz constant, have been studied. These
verification techniques can also be integrated into the training
process to produce more robust and easier to verify networks [ 8,
25,26,50]. These works are orthogonal, though we believe their
techniques can be adapted to our domain.
A related but tangential line of work focuses on discovering
interestingbehaviorsofneuralnetworks,thoughwithoutanyguar-
antees. Most closely related to our work are differential testing
techniques[ 23,34,52],whichfocusonfindingdisagreementsbe-
tweenasetofnetworks.However,thesetechniquesdonotattempt
to prove the equivalence or similarity of multiple networks.
Other works are more geared towards single network testing,
and use white-box testing techniques [ 22,31,42,44,51], such as
neuron coverage statistics, to assess how well a network has been
tested,andalsoreportinterestingbehaviors.Bothofthesecanbe
thoughtofasadaptingsoftwareengineeringtechniquestomachine
learning.
In addition, many works use machine learning techniques, such
as gradient optimization, to find interesting behaviors, such as
adversarialexamples[ 19,24,28,29,53].Theseinterestingbehaviors
can then be used to retrain the network to improve robustness [ 11,
36]. Again, these techniques do not provide guarantees, though we
believe they could be integrated into NeuroDiff to quickly find
counterexamples.
Finally, our work draws inspiration from classic software en-
gineeringtechniques,suchasregressiontesting[ 37],differential
assertionchecking[ 20],differentialfuzzing[ 30],andincremental
symbolicexecution[ 13,35],whereoneversionofaprogramisused
asan“oracle”,tomoreefficientlytestorverifyanewversionofthesameprogram.Inourcase,
fcanbethoughtofastheoracle,while
f/primeis the new version.
7 CONCLUSIONS
We havepresented NeuroDiff,a scalabledifferential verification
techniqueforsoundlyboundingthedifferencebetweentwofeed-
forwardneuralnetworks.NeuroDiffleveragesnovelconvexap-
proximations,whichreducetheoverallapproximationerror,andintermediate symbolic variables, which control the error explosion,
to significantly improve efficiency and accuracy of the analysis.
OurexperimentalevaluationshowsthatNeuroDiffcanachieve
upto1000Xspeedupandisuptofivetimesasaccurate.
ACKNOWLEDGMENTS
ThisworkwaspartiallyfundedbytheU.S.OfficeofNavalResearch
(ONR) under the grant N00014-17-1-2896.
794REFERENCES
[1]Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra, and Jorge L. Reyes-
Ortiz. 2013. A Public Domain Dataset for Human Activity Recognition Using
Smartphones. 21st European Symposium on Artificial Neural Networks, Computa-
tional Intelligence and Machine Learning (2013).
[2]Teodora Baluta, Shiqi Shen, Shweta Shinde, Kuldeep S Meel, and Prateek Saxena.
2019. Quantitativeverificationofneuralnetworksanditssecurityapplications.In
Proceedingsofthe2019ACMSIGSACConferenceonComputerandCommunications
Security. 1249–1264.
[3]Osbert Bastani, Yani Ioannou, Leonidas Lampropoulos, Dimitrios Vytiniotis,
Aditya V. Nori, and Antonio Criminisi. 2016. Measuring Neural Net Robustness
with Constraints. In Annual Conference on Neural Information Processing Systems.
2613–2621.
[4]NicholasCarliniandDavidA.Wagner.2017. TowardsEvaluatingtheRobustness
of Neural Networks. In IEEE Symposium on Security and Privacy. 39–57.
[5]Patrick Cousot and Radhia Cousot. 1977. Abstract Interpretation: A Unified
LatticeModelforStaticAnalysisofProgramsbyConstructionorApproximation
of Fixpoints. In ACM SIGACT-SIGPLAN Symposium on Principles of Programming
Languages. 238–252.
[6]Krishnamurthy Dvijotham, Robert Stanforth, Sven Gowal, Timothy A. Mann,and Pushmeet Kohli. 2018. A Dual Approach to Scalable Verification of DeepNetworks. In International Conference on Uncertainty in Artificial Intelligence.
550–559.
[7]Rüdiger Ehlers. 2017. Formal Verification of Piece-Wise Linear Feed-Forward
NeuralNetworks.In AutomatedTechnologyforVerificationandAnalysis-15th
International Symposium, ATVA 2017, Pune, India, October 3-6, 2017, Proceedings.
269–286.
[8]Marc Fischer, Mislav Balunovic, Dana Drachsler-Cohen, Timon Gehr, Ce Zhang,
and Martin T. Vechev. 2019. DL2: Training and Querying Neural Networks with
Logic. In International Conference on Machine Learning. 1931–1941.
[9]Timon Gehr, MatthewMirman, DanaDrachsler-Cohen, PetarTsankov, Swarat
Chaudhuri, and Martin T. Vechev. 2018. AI2: Safety and Robustness Certification
of Neural Networks with Abstract Interpretation. In IEEE Symposium on Security
and Privacy. 3–18.
[10]SumathiGokulanathan,AlexanderFeldsher,AdiMalca,ClarkBarrett,andGuy
Katz. 2019. Simplifying Neural Networks with the Marabou Verification Engine.
arXiv preprint arXiv:1910.12396 (2019).
[11]Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. 2015. Explaining
andHarnessingAdversarialExamples.In InternationalConferenceonLearning
Representations.
[12]Divya Gopinath, Guy Katz, Corina S. Pasareanu, and Clark W. Barrett. 2018.DeepSafe: A Data-Driven Approach for Assessing Robustness of Neural Net-
works. In Automated Technology for Verification and Analysis - 16th International
Symposium, ATVA 2018, Los Angeles, CA, USA, October 7-10, 2018, Proceedings.
3–19.
[13]ShengjianGuo,MarkusKusano,andChaoWang.2016. Conc-iSE:Incremental
Symbolic Execution of Concurrent Software. In IEEE/ACM International Confer-
ence On Automated Software Engineering.
[14]Song Han, Huizi Mao, and William J. Dally. 2016. Deep Compression: Compress-
ing Deep Neural Network with Pruning, Trained Quantization and Huffman
Coding. In International Conference on Learning Representations.
[15]Xiaowei Huang, Marta Kwiatkowska, Sen Wang, and Min Wu. 2017. Safety
Verification of Deep Neural Networks. In International Conference on Computer
Aided Verification. 3–29.
[16]Kyle D. Julian, Mykel J. Kochenderfer, and Michael P. Owen. 2018. Deep Neu-ral Network Compression for Aircraft Collision Avoidance Systems. CoRR
abs/1810.04240 (2018). arXiv:1810.04240 http://arxiv.org/abs/1810.04240
[17]GuyKatz,ClarkW.Barrett,DavidL.Dill,KyleJulian,andMykelJ.Kochenderfer.
2017. Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks. In
International Conference on Computer Aided Verification. 97–117.
[18]Guy Katz, Derek A. Huang, Duligur Ibeling, Kyle Julian, Christopher Lazarus,
RachelLim,ParthShah,ShantanuThakoor,HaozeWu,AleksandarZeljic,DavidL.
Dill, Mykel J. Kochenderfer, and Clark W. Barrett. 2019. The Marabou Frame-
work for Verification and Analysis of Deep Neural Networks. In International
Conference on Computer Aided Verification. 443–452.
[19]AlexeyKurakin,IanJ.Goodfellow,andSamyBengio.2017. Adversarialexamples
in the physical world. In International Conference on Learning Representations.
[20]ShuvenduKLahiri,KennethLMcMillan,RahulSharma,andChrisHawblitzel.
2013. Differential assertion checking. In Proceedings of the 2013 9th Joint Meeting
on Foundations of Software Engineering. ACM, 345–355.
[21]YannLecun,LeonBottou,YoshuaBengio,andPatrickHaffner.1998. Gradient-
based learning applied to document recognition. Proc. IEEE 86, 11 (1998), 2278–
2324.
[22]LeiMa,FelixJuefei-Xu,FuyuanZhang,JiyuanSun,MinhuiXue,BoLi,Chunyang
Chen, Ting Su, Li Li, Yang Liu, et al .2018. Deepgauge: Multi-granularity testing
criteria for deep learning systems. In IEEE/ACM International Conference On
Automated Software Engineering. ACM, 120–131.[23]ShiqingMa,YingqiLiu,Wen-ChuanLee,XiangyuZhang,andAnanthGrama.
2018. MODE: automatedneuralnetworkmodeldebuggingvia statedifferential
analysis and input selection. In Proceedings of the 2018 ACM Joint Meeting on
European Software Engineering Conference and Symposium on the Foundationsof Software Engineering, ESEC/SIGSOFT FSE 2018, Lake Buena Vista, FL, USA,
November 04-09, 2018. 175–186.
[24]Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
AdrianVladu.2018.Towardsdeeplearningmodelsresistanttoadversarialattacks.
International Conference on Learning Representations (2018).
[25]Matthew Mirman, Timon Gehr, and Martin T. Vechev. 2018. Differentiable
AbstractInterpretationforProvablyRobustNeuralNetworks.In International
Conference on Machine Learning. 3575–3583.
[26]MartinVechevMislavBalunovic.2020. AdversarialTrainingandProvableDe-
fenses: Bridging the Gap. International Conference on Learning Representations.
[27]Ramon E Moore, R Baker Kearfott, and Michael J Cloud. 2009. Introduction to
interval analysis. Vol. 110. Siam.
[28]Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and Pascal Frossard. 2016.DeepFool: A Simple and Accurate Method to Fool Deep Neural Networks. In
IEEE Conference on Computer Vision and Pattern Recognition. 2574–2582.
[29]AnhMaiNguyen,JasonYosinski,andJeffClune.2015. Deepneuralnetworksare
easily fooled: High confidence predictions for unrecognizable images. In IEEE
Conference on Computer Vision and Pattern Recognition. 427–436.
[30]ShirinNilizadeh,YannicNoller,andCorinaS.Pasareanu.2019. DifFuzz:differ-
entialfuzzingforside-channelanalysis.In InternationalConferenceonSoftware
Engineering. 176–187.
[31]AugustusOdenaandIanGoodfellow.2018. Tensorfuzz:Debuggingneuralnet-
works with coverage-guided fuzzing. arXiv preprint arXiv:1807.10875 (2018).
[32]BrandonPaulsen.2020. ReluDiff-ICSE2020-Artifact. https://github.com/pauls658/
ReluDiff-ICSE2020-Artifact.
[33]Brandon Paulsen, Jingbo Wang, and Chao Wang. 2020. ReluDiff: Differential
Verification of Deep Neural Networks. International Conference on Software
Engineering (2020).
[34]Kexin Pei, Yinzhi Cao, Junfeng Yang, and Suman Jana. 2017. DeepXplore: Au-tomated Whitebox Testing of Deep Learning Systems. In ACM symposium on
Operating Systems Principles. 1–18.
[35]SuzettePerson,GuoweiYang,NehaRungta,andSarfrazKhurshid.2011. Directed
Incremental Symbolic Execution. In ACM SIGPLAN Conference on Programming
Language Design and Implementation. ACM, New York, NY, USA, 504–515.
[36]Aditi Raghunathan, Jacob Steinhardt, and Percy Liang. 2018. Certified Defenses
against Adversarial Examples. In International Conference on Learning Represen-
tations.
[37]GreggRothermelandMaryJeanHarrold.1997. Asafe,efficientregressiontest
selection technique. ACM Transactions on Software Engineering and Methodology
(TOSEM) 6, 2 (1997), 173–210.
[38]Wenjie Ruan, Xiaowei Huang, and Marta Kwiatkowska. 2018. Reachability
AnalysisofDeepNeuralNetworkswithProvableGuarantees.In International
Joint Conference on Artificial Intelligence. 2651–2659.
[39]Gagandeep Singh, Rupanshu Ganvir, Markus PÃĳschel, and Martin Vechev. 2019.
Beyond the Single Neuron Convex Barrier for Neural Network Certification. In
Advances in Neural Information Processing Systems (NeurIPS).
[40]Gagandeep Singh, Timon Gehr, Markus Püschel, and Martin T. Vechev. 2019.
An abstract domain for certifying neural networks. ACM SIGACT-SIGPLAN
Symposium on Principles of Programming Languages (2019), 41:1–41:30.
[41]Gagandeep Singh, Timon Gehr, Markus Püschel, and Martin T. Vechev. 2019.
BoostingRobustnessCertificationofNeuralNetworks.In InternationalConference
on Learning Representations.
[42]Youcheng Sun, Min Wu, Wenjie Ruan, Xiaowei Huang, Marta Kwiatkowska, and
DanielKroening.2018. Concolictestingfordeepneuralnetworks.In Proceedings
ofthe33rdACM/IEEEInternationalConferenceonAutomatedSoftwareEngineering,
ASE 2018, Montpellier, France, September 3-7, 2018. 109–119.
[43]ChristianSzegedy,WojciechZaremba,IlyaSutskever,JoanBruna,DumitruErhan,
Ian Goodfellow, and Rob Fergus. 2013. Intriguing properties of neural networks.
arXiv preprint arXiv:1312.6199 (2013).
[44]Yuchi Tian, Kexin Pei, Suman Jana, and Baishakhi Ray. 2018. DeepTest: Auto-
mated testing of deep-neural-network-driven autonomous cars. In International
Conference on Software Engineering. 303–314.
[45]VincentTjeng,KaiXiao,andRussTedrake.2019. Evaluatingrobustnessofneuralnetworkswithmixedintegerprogramming. InternationalConferenceonLearning
Representations (2019).
[46]Liwei Wang, Lunjia Hu, Jiayuan Gu, Zhiqiang Hu, Yue Wu, Kun He, and John
Hopcroft.2018. Towardsunderstandinglearningrepresentations:Towhatextentdodifferentneuralnetworkslearnthesamerepresentation.In AdvancesinNeural
Information Processing Systems. 9584–9593.
[47]Shiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, and Suman Jana. 2018.
EfficientFormalSafetyAnalysisofNeuralNetworks.In AnnualConferenceon
Neural Information Processing Systems. 6369–6379.
795[48]Shiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, and Suman Jana. 2018.
FormalSecurityAnalysisofNeuralNetworksusingSymbolicIntervals.In USENIX
Security Symposium. 1599–1614.
[49]Tsui-Wei Weng, Huan Zhang, Hongge Chen, Zhao Song, Cho-Jui Hsieh, Luca
Daniel,DuaneS.Boning,andInderjitS.Dhillon.2018. TowardsFastComputa-
tionofCertifiedRobustnessforReLUNetworks.In InternationalConferenceon
Machine Learning. 5273–5282.
[50]Eric Wong and J. Zico Kolter. 2018. Provable Defenses against Adversarial
ExamplesviatheConvexOuterAdversarialPolytope.In InternationalConference
on Machine Learning. 5283–5292.
[51]XiaofeiXie,LeiMa,FelixJuefei-Xu,MinhuiXue,HongxuChen,YangLiu,Jianjun
Zhao,BoLi,JianxiongYin,andSimonSee.2019. DeepHunter:acoverage-guidedfuzztestingframeworkfordeepneuralnetworks.In Proceedingsofthe28thACM
SIGSOFT International Symposium on Software Testing and Analysis. 146–157.[52]Xiaofei Xie, Lei Ma, Haijun Wang, Yuekang Li, Yang Liu, and Xiaohong Li. 2019.
Diffchaser: Detecting disagreements for deep neural networks. In Proceedings
of the 28th International Joint Conference on Artificial Intelligence. AAAI Press,
5772–5778.
[53]Weilin Xu, Yanjun Qi, and David Evans. 2016. Automatically Evading Classifiers:
A Case Study on PDF Malware Classifiers. In Network and Distributed System
Security Symposium.
[54]Huan Zhang, Tsui-Wei Weng, Pin-Yu Chen, Cho-Jui Hsieh, and Luca Daniel.
2018. Efficientneuralnetworkrobustnesscertificationwithgeneralactivation
functions. In Advances in neural information processing systems. 4939–4948.
[55]XianyiZhang,QianWang,andYunquanZhang.2012. Model-drivenLevel3BLAS
Performance Optimization on Loongson 3A Processor. In 18th IEEE International
ConferenceonParallelandDistributedSystems,ICPADS2012,Singapore,December
17-19, 2012. 684–691.
796