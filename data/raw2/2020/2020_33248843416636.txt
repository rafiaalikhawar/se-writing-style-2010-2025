Where Shall We Log? Studying and Suggesting Logging
Locations in Code Blocks
Zhenhao Li
l_zhenha@encs.concordia.ca
Concordia University
Montreal, Quebec, CanadaTse-Hsun (Peter) Chen
peterc@encs.concordia.ca
Concordia University
Montreal, Quebec, CanadaWeiyi Shang
shang@encs.concordia.ca
Concordia University
Montreal, Quebec, Canada
ABSTRACT
Developerswriteloggingstatementstogeneratelogsandrecord
system execution behaviors to assist in debugging and software
maintenance.However,decidingwheretoinsertloggingstatements
is a crucial yet challenging task. On one hand, logging too little
may increase the maintenance difficulty due to missing important
systemexecutioninformation.Ontheotherhand,loggingtoomuch
mayintroduceexcessivelogsthatmasktherealproblemsandcausesignificantperformanceoverhead.Priorstudiesproviderecommen-
dationsonlogginglocations,butsuchrecommendations areonly
forlimitedsituations(e.g.,exceptionlogging)oratacoarse-grained
level (e.g., method level). Thus, properly helping developers decide
finer-grained logging locations for different situations remains an
unsolvedchallenge.Inthispaper,wetacklethechallengebyfirst
conductingacomprehensivemanualstudyonthecharacteristics
of logging locations in seven open-source systems. We uncover six
categories of logging locations and find that developers usually in-
sert logging statements to record execution information in various
types of code blocks. Based on the observed patterns, we then pro-
pose a deep learning framework to automatically suggest logging
locationsat theblocklevel.Wemodel thesource codeatthe code
blocklevelusingthesyntacticandsemanticinformation.Wefind
that: 1) our models achieve an average of 80.1% balanced accuracy
whensuggestinglogginglocationsinblocks;2)ourcross-system
logging suggestion results reveal that there might be an implicitlogging guideline across systems. Our results show that we may
accurately provide finer-grained suggestionson logginglocations,
and such suggestions may be shared across systems.
ACM Reference Format:
ZhenhaoLi,Tse-Hsun(Peter)Chen,andWeiyiShang.2020.WhereShall
We Log? Studying and Suggesting Logging Locations in Code Blocks. In
35th IEEE/ACM International Conference on Automated Software Engineering
(ASE’20),September21–25,2020,VirtualEvent,Australia. ACM,NewYork,
NY, USA, 12 pages. https://doi.org/10.1145/3324884.3416636
1 INTRODUCTION
Logsplayanimportantroleinmaintainingsoftwaresystemsand
diagnosing issues that happen during runtime. Developers rely
onlogsforvariousmaintenanceactivities,suchasdebugging[ 25,
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ASE ’20, September 21–25, 2020, Virtual Event, Australia
© 2020 Association for Computing Machinery.
ACM ISBN 978-1-4503-6768-4/20/09...$15.00
https://doi.org/10.1145/3324884.341663669,71], testing [ 13–15,47], and system comprehension [ 50,51].
Developersinsertloggingstatementsinthesourcecodewithdif-
ferentverbositylevels(e.g., trace,debug,info,warn,error,andfatal)
to record system execution information and values of dynamic
variables. For example, in the logging statement: log.warn(“Invalid
groupingKey:”, + key) , the static text message is “Invalid group-
ingKey:”, and the dynamic message is the value of the variable
key.Theloggingstatementisatthe warnlevel,whichisthelevel
for recording information that may potentially cause system oddi-
ties [3].
The great value of logs results from proper logging decisions
thataremadebypractitionersduringsoftwaredevelopment[ 39].
Theloggingdecisionsareoftenmadeinordertobalancethebenefit
and cost from logs [ 39]. On one hand, inserting too few logging
statements may increase the maintenance difficulty due to missing
important systemexecution information fordebugging and analy-
sis [78]. On the other hand, inserting too many logging statements
may increase system performance overhead and produce excessive
trivial logs which increase the difficulty of log analysis [ 39,66,78].
However,such acrucial task ofmaking loggingdecisions remains
challengingduetothelackofconcreteloggingspecificationand
guidelines [ 25]. As a result, developers have to rely on their in-
tuitionsandexperiencestocompose,review,updateandevenfix
logging statements in an ad-hoc manner [11, 29, 41, 44, 45, 70].
To address the challenge of making logging decisions, prior
studies [20,25,38,67,78] provide automated recommendations
on logging locations. However, there exist two main limitations in
prior research: 1) Such recommendations are often only for a very
limited number of situations. Approaches from prior research may
onlyprovidesuggestionsforexceptionhandlingblocksandmethodreturnvalues[
25,78].2)Thelogginglocationsarerecommendedat
acoarse-grainedlevel,e.g.,methodlevel[ 38];whilepractitioners
stillneedtodecidethespecificlocationtoplacealoggingstatementinside a method. As a result, in many cases, practitioners often stillfacechallengeswhenmakingdecisionsonlogginglocations,despite
the advance from recent research outcomes.
In this paper, we conduct a study to uncover guidelines and
provide suggestions on logging locations (i.e., where do developers
log)atafiner-grainedlevel(i.e.,blocklevel)byanalyzinglogging
statementsandtheirsurroundingcode.Throughamanualstudyontheloggingstatementsfromsevenopensourcesystems,wefindthat
thedecisionsoflogginglocationareofteninfluencedbyboththe
syntacticand semanticinformationin thesource code.Moreover,
the logging statements often record execution information related
to the block in which they reside. Driven by our manual studyresults, we extract syntactic (e.g., nodes in abstract syntax trees)and semantic (e.g., variable names) information from the source
3612020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE)
codeandproposeanautomateddeeplearningbasedapproachto
suggest logging locations at the block level. We find that our deep
learningmodelsoutperformthebaseline,andthesyntacticblock
featureachievesthebestresults(anaveragebalancedaccuracyof
80.1%)comparedtosemanticandfused(afusionofsyntacticand
semantic) features. Moreover, syntactic information of blocks may
be leveraged to provide general logging guidelines across different
software systems. In summary, this paper makes the following
contributions:
•We uncover six categories of logging locations, which are
exceptionloggingin catchblocks,branchlogginginblocks
associated with decision-making statements, program itera-
tionlogging,loggingthestartortheendofamethod,and
function logging in domain-specific methods. We also dis-
cuss the common types of information that is recorded in
each category.
•Weproposeadeeplearningbasedapproachtosuggesting
logginglocationsattheblocklevelbyleveragingsyntactic,
semantic and fused block features extracted from the source
code1.Wefindthatmodelstrainedusingthesyntacticfea-
tures have the highest balanced accuracy (80.1%) among thethree types of features. Although there are some differences
in the suggestionresults among the threefeatures, syntactic
features can capture around 80% of all the suggested truepositives. Our finding shows that most logging decisions
may be related to the syntactic structure of the code.
•The cross-system suggestion results achieve an average bal-
ancedaccuracyof67.3%.Wealsofindthatthereisamoderate
to substantial agreement among the cross-system modelstrained using the syntactic features, which shows that de-
velopers of different systems may follow certain implicit
guidelines on deciding logging locations.
Paper organization Section 2 discusses the background and re-
latedworkofourstudy.Section3describesthesetupofourmanual
study and the categories of logging locations we find. Section 4discusses how do we extract block-level features and describes
ourdeep-learningbasedapproach.Section5presentstheevalua-
tionmetricsandtheresultsbyansweringtworesearchquestions.
Section6discussestheFalsePositivesandFalseNegativesinour
suggestion results. Section 7 discusses the threats to validity of our
study. Section 8 concludes the paper.
2 BACKGROUND AND RELATED WORK
Developersinsertloggingstatementsintothesourcecodetorecord
system runtime information and use the generated logs to assistin software debugging and maintenance. For example, as shown
in thesimplified codesnippet fromZookeeper below, thelogging
statement is at the errorlevel, contains the static message “Missing
countnode forstat”,and recordsthe dynamicvalue ofthe variable
statNode.
DataNode node = nodes.get(statNode);
if(node == null){
// should not happenLOG.error("Missing count node for stat {}", statNode);return;
}
1We share the replication package of this paper at: https://github.com/SPEAR-SE/
ASE2020_Logging_Location_Data.The logging statement is closely related to the specific value
ofthe DataNode objectandrecordsanunexpectedexecutionbe-
haviorinan ifblockwhenthevalueofthenodeis null.Helping
developers decide where to log is an on-going research problem.
Fu et al. [ 25] studied where do Microsoft developers add logging
statements in their projects written in C# and focused on studying
the characeristics of logging in some specific code snippets (i.e.,catch blocks and return value checks). They found that develop-ers often add logging statements to check the returned value of
amethodandrecordexceptions.Zhuetal.[ 78]furtherextended
theworkbyprovidingatoolforsuggestinglogplacementinthe
twoabove-mentionedcases.Lietal.[ 38,41]providesuggestions
onwhetheramethodorcommitrequiresaloggingstatement.In
short, prior studies either only target a limited number of logging
locations or provide a coarse-grained suggestion. Therefore, in thispaper,weexplorethepotentialofprovidingafiner-grainedsupportondecidinggenerallogginglocationsthroughamanualstudy(Sec-tion 3) and propose an automated deep-learning based approach to
suggest logging locations at the code block level (Section 4).
Below, we further discuss the related works of this paper.
Studies onLogging Practices. There are several studies on char-
acterizingtheloggingpracticesinsoftwaresystems.Yuanetal.[ 70],
Chen et al. [ 9], and Zeng et al. [ 72] conducted quantitative charac-
teristics studies on log messages in large-scale open source C/C++,
Java systems, and mobile applications. Chen et al. [ 12] studied the
loggingutilities,andZhietal.[ 77]studiedtheloggingconfigura-
tions in Java. They found that logs are essential for debugging and
maintenance.
Giventheimportanceoflogs,otherstudiestrytohelpdevelopers
improveloggingpractices.Chenetal.[ 10]foundthatdevelopers
commonly make some mistakes when writing logging statements
(e.g., logging objects whose values may be null) and concluded five
categoriesof logginganti-patterns fromcode changes.Hassaniet
al.[29]identifiedsevenroot-causesofthelog-relatedissuesfrom
log-related bug reports and found that inappropriate log messages
and missing log statements are the most common issues. Li et
al. [43,46] uncovered potential problems with logging statements
thathavethesametextmessageanddevelopedanautomatedtooltodetecttheproblems.Yuanetal.[
71]proposedanapproachthatcan
automaticallyinsertadditionalvariablesintologgingstatements
to enhance the error diagnostic information. Li et al. [ 40] propose
the use of prediction models to suggest the log level of a newly
addedloggingstatement.Liuetal.[ 48]proposedadeeplearning
framework to suggest the variables that should be recorded in
logging statements.
Different from prior studies, this paper focuses on studying log-
ginglocationsin thepurposeofprovidingsuggestionsandguide-
lines on the decisions of logging locations. The findings and ap-
proaches in thispaper can complement prior studies inproviding
more comprehensive logging supports to developers.
ApplyingDeepLearninginSoftwareEngineeringTasks. Due
to the advances in deep learning, recent research starts to inves-tigate source code representation and apply deep learning mod-els in software engineering tasks. Zhang et al. [
74]p r o p o s e da n
AST-based neural network for source code representation. They
evaluated their approach on several software engineering tasks,
362Table 1: An overview of the studied systems.
System Version LOC NOL #LB #NLB %LB
Cassandra 3.11.4 432K 1.3K 1.0K 25.0K 3.8%
ElasticSearch 7.4.0 1.50M 2.5K 1.9K 54.0K 3.4%
Flink 1.8.2 177K 2.5K 2.4K 27.5K 8.0%
HBase 2.2.1 1.26M 5.5K 4.1K 81.1K 4.8%
Kafka 2.3.0 267K 1.5K 1.0K 9.0K 10.0%
Wicket 8.6.1 216K 0.4K 0.3K 9.1K 3.2%
Zookeeper 3.5.6 97K 1.2K 0.9K 5.2K 14.8%
Note: LOCrefers to the lines of code, NOLrefers to the number of logging statements, #LBand#NLBrefers to the
number of loggedandnon-logged blocks respectively, %LBrefers to the percentage of loggedblocks over all the blocks.
such as source code classification and code clone detection, and
the results outperformed existing approaches. Tufano et al. [ 58]
evaluateddifferentrepresentationofsourcecode(e.g.,abstractsyn-
taxtreeandcontrolflow graph)andtheireffectonapplyingdeep
learningmodelsinSEtasks.Huetal.[ 32]proposedadeeplearn-
ingbasedapproachtoautomaticallygeneratecommentsforJava
methods. Nghi et al. [ 52] applied deep learning models to identify
the programming language used in an algorithm. Different from
priorstudies,wefocusonextractingsourcecodefeaturestosuggest
whichblocksneedtobelogged.Weconductacomprehensiveman-
ual study on the characteristics of logging locations and propose a
deep learning based approach to provide automated suggestions.
3 STUDYING THE CHARACTERISTICS OF
LOGGING LOCATION IN CODE BLOCKS
To better understand developers’ logging decisions and provide
more concrete logging suggestions, in this section, we manuallyinspect the logging statements and their surrounding code. We
examineifthereexistfiner-grained(e.g.,atcodeblocklevels)im-
plicit or explicit common characteristics of the locations where
developers insert logging statements.
StudiedSystems. Weconductamanualstudyonsevenlarge-scale
opensourceJavasystems:Cassandra,Elasticsearch,Flink,HBase,
Kafka,Wicket,andZooKeeper.Table1showsanoverviewofthe
systems.Thestudiedsystemscoverdifferentdomains(e.g.,message
broker,searchengine,anddatabase),havehighqualityloggingcode,
and are commonly used in prior log-related studies [ 10,11,38,46].
The size of the studied systems ranges from 97K to 1.5M LOC, and
they contain from 0.4K to 5.5K logging statements.
ManualStudySetup. Ourgoalistomanuallyinspectthelogging
statements and their surrounding code to study the characteristics
of logging locations. To prepare the data for our manual study,
weextracttheloggingstatementsfromthesourcecodebyimple-
menting a static code parser. Our parser identifies every logging
statement that invokes common logging libraries (e.g., Log4j [ 3]
and SLF4J [ 5]) in the code. Then, for each logging statement, we
extract its static message and dynamic variables, its verbosity level,itslocation(i.e.,thefileandmethodthatcontainstheloggingstate-
ment), and its surrounding code (i.e., the method that contains the
logging statement). After getting all the logging statements andthe extracted information, we randomly sample 375 out of 14.9K
loggingstatementsbasedona95%confidenceleveland5%confi-
denceinterval[ 8].Foreachsampledloggingstatement,westudy
its structural informationand data flow of the surrounding code,
inordertoseethepotentialfactorstakingpartinthedecisionof
inserting the logging statements in a block. Specifically, the firsttwoauthorsofthispaper(i.e.,A1andA2)followanopencoding-
likeprocesssimilartopriorstudies[ 21,36,46,73],andinvolvein
the following three phases to conduct the manual study:
PhaseI:A1studies100randomlysampledloggingstatements
andtheirextractedinformation,andrecordthecharacteristicsof
theirdataflow,structural,andsemanticinformation(e.g.,thede-
pendencyofvariables,controlflow,andthebusinesslogicofthe
code).A1furtherderivesadraftlistofcategoriesofloggingloca-
tionsbasedontheinformationrecorded.ThenA1andA2follow
thedraftlisttolabelthe100samplescollaboratively.Duringthis
phase, the categories are revised and refined.
PhaseII:A1andA2independentlyassignthecategoriesderived
in Phase I to the rest of the 375 sampled logging statements. There
is no new category derived in this phase.
PhaseIII:A1andA2comparetheassignedcategoriesinPhaseII.
Anydisagreementofthecategorizationisdiscusseduntilreachinga
consensus.Nonewcategoriesareintroducedduringthediscussion.
The results in this phase have a Cohen’s Kappa of 0.86, whichis a
substantial-level of agreement [56].
Categories of Logging Locations. In our manual study, we un-
coversixcategoriesoflogginglocationsthatareassociatedwith
four different types of blocks (i.e., try-catch, branching, looping,
andmethoddeclaration).Inparticular,wefindthatthreecategories
areassociatedwithtry-catch,branching,andloopingblocks;and
three categories are associated with method declaration blocks
that record method execution information. Below, we discuss each
category in detail with an example.Category 1 (Try-Catch Block):
Exceptioninformationloggingincatch
blocks (122/375, 32.5%). Exceptions are widely used to capture er-
rors.Developersrely onlogsfordebugginganderror diagnostics
when exceptions occur [ 25,68]. The code snippet below shows
an example of logging statements in this category. Similar to aprior study [
25], we find that a large number of sampled logging
statementsresidein catchblocks.Mostofthemareat error(52/122,
42.6%)or warn(46/122,37.7%) level.Theloggingstatementsoften
recordmessagesorexecutioninformationrelatedtotheprior try
block.
try{
listener.onCache(shardId, fieldName, fieldData);
}catch(Exception e) {
logger.error("Failed to call listener on atomic field data loading", e);
}
Category 2 (Branching Block): Branch logging in blocks associated
withdecision-makingstatements(139/375,37.1%). Wefindthatmany
sampledloggingstatementsresideinblocksassociatedwithdecision-
making statements [ 4] (e.g., if-elseandswitch) to record the execu-
tion information in different branches. The variable or the invoked
methodintheconditionofthedecision-makingstatement(e.g.,theargumentsinthe ifstatement)areprocessedordefinedintheprior
code.Among thelogging statementsin thiscategory, aroundhalf
of them (68/139, 48.9%) record the occurrence of an unexpected
execution behavior (e.g., an error or a failure) with a warnlevel or
above (e.g. error), as shown in the code snippet below. The remain-
ing cases record the occurrence of a normal execution behavior
with an info, debug,o r tracelevel for system comprehension or
debugging purposes.
finalTaskId id = partitionsToTaskId.get(tp);
...
363if(id !=null){
taskIds.add(id);
}else{
log.error("Failed to lookup taskId for partition {}", tp);
}
Category 3 (Looping Block): Programiterationlogging(25/375,6.7%).
Wefindthatsomesampledloggingstatementsresideinblocksthat
are associated with looping statements [ 4,65] (e.g., code blocks
thatareassociatedwith for,while,and do-while statements).These
loggingstatementsoftenrecordtheexecutionstateduringiterating
(e.g., recording the ithexecution inside a forblock) or variables
thatareprocessedordefinedinpriorblocks.Wealsofindthatno
logging statements under this category are at errororfatallevel.
All logging statements are at the level of info(13/25, 52.0%), debug
(6/25, 24.0%), or trace(6/25, 24.0%). In short, developers are more
likely to add logging statements in such blocks for debugging and
recording program execution.
IndexStatistics[] stats = getIndexStatistics(total);
...for(IndexStatistics s : stats) {
LOG.info(" Object size " + s.itemSize() + " used=" + s.usedCount());
}
Category 4 (Method Declaration Block): Loggingthestartofamethod
(33/375,8.8%). Wefindthatsomesampledloggingstatementsreside
at the beginning of a method, mostly for recording the program
executionstateordebuggingpurposes.Theseloggingstatements
recordthestartofthemethodexecution(e.g., “Starttobuildthepro-
gram from JAR file.”) at the info(21/33, 63.6%), debug(8/33, 24.3%),
ortrace(4/33,12.1%)level.Differentfromothercategories,wedo
not find the location of logging statements in this category depend
onpriorcodeinthemethod.However,wefindthattheselogging
statements record the execution of some methods of which the
process is important to know and with some specific semantics in
the code (e.g., recovery(), perform(), and queue()), as shown in the
code snippet below.
public void perform() throwsException
{
LOG.info(String.format("Performing action: Rolling batch restarting {} of
region servers",( int)(ratio * 100)));
List<ServerName> selectedServers = selectServers();
Queue<ServerName> serversToBeKilled = newLinkedList<>(selectedServers);
...//code for performing server-killing related tasks...
}
Category 5 (Method Declaration Block): Loggingtheendofamethod
(27/375, 7.2%). In this category, the logging statements reside at
the end of a method, recording the successful method execution
(e.g.,“Removed job graph from ZooKeeper”, as shown in the code
snippet below). We find that most of them (22/27, 81.5%) are at
theinfolevel, and the rest are in debug(3/27, 11.1%), trace(1/27,
3.7%)and warn(1/27,3.7%)level,whichmayshowthatsuchlogs
are mostly for debugging and recording program execution. Thelogging statement may record variable values that are declaredor modified in prior blocks when the method execution finishes.Similarto Category5,wefindthattheloggingstatementsinthis
categorymightresideinsemanticallysimilarmethodsofwhichthe
execution is important to be recorded (e.g., shutdown(), delete(),
andremove()).
public void removeJobGraph(JobID jobId) throwsException
{
checkNotNull(jobId, "Job ID");
String path = getPathForJob(jobId);...
addedJobGraphs.remove(jobId);//code for removing ZooKeeper job graph...LOG.info("Removed job graph {} from ZooKeeper.", jobId);
}
Category 6 (Method Declaration Block): Functionlogging indomain-
specificmethods(29/375,7.7%). Wefindthatdeveloperssometimes
insert logging statements in some domain-specific methods (e.g.,
handling a specific request) to record the execution of this method.
We also find that these methods are usually very short (i.e., within
10 lines of code). As shown in the example below, in the method
handleResponse() inElasticsearch’s JoinHelper.java,thereareonlya
fewlinesoffunctionalcodestatementsbuthasaloggingstatement
recordingtheexecutionbehaviorofthismethod.Amongthelog-
ging statements in this category,21/29 (72.4%) are at the infolevel
or below (i.e., debugortracelevel) to record the methods handling
normalrequests,andtherest8/29(27.6%)loggingstatementsare
at thewarnorerrorlevel to record the methods handling abnormal
situations (e.g., onFailure()). We also find that these short methods
might be semantically similar based on our manual observation
(e.g., share many common words such as handleandexecute).
public void handleResponse(Empty response) {
pendingOutgoingJoins.remove(dedupKey);logger.debug("successfully joined {} with {}", destination, joinRequest);lastFailedJoinAttempt.set(null);
}
Insummary,ourfindingsshowthattheremaybeanimplicitlog-
ging guideline that developers follow in the studied systems. Both
syntactic andsemantic informationareimportantconsiderations
insuchloggingguidelines.Inparticular,wefindthat76.3%(286/375,
combining Category1, Category2 andCategory3)ofthesampled
logging statementsare relatedto recording informationin blocks
associated with syntactic information of the source code (e.g., try-
catch,branching,orloopingblocks).Theseloggingstatementsalso
oftenrecord information(e.g.,variable valuesorexecution states)
that isrelated to priorblocks. We find that23.7% (89/375, combin-
ingCategory 4, Category 5 andCategory 6) of the sampled logging
statements may be inserted based on the semantic information
(i.e., business logic) of the method inside the method declaration
block.Theseloggingstatementsoftenrecordthestartandendof
methodexecution,orrecordtheexecutionofsomedomain-specific
methods (e.g., request handling or task execution).
Byuncoveringsixcategoriesof logginglocations,wefindthat
bothsyntactic andsemantic information are important con-
siderations in such logging guidelines. 76% of the sampled
logging statements are related to recording exception, branch-
ing, and program iteration; while 24% are related to recording
the start, end, or execution of certain methods.
4 AUTOMATICALLY SUGGESTING LOGGING
LOCATIONS AT THE CODE BLOCK LEVEL
AswefindinSection3,developersusuallyinsertloggingstatements
torecordthebehaviororstateoftheprograminblocks(e.g.,excep-
tionhandlingin catchblocksorbranchloggingin if/elseblocks).
We also find that some logging locations may be related to the
semantics of a method (e.g., recording the start of a certain method
execution).Hence,suchsyntacticandsemanticinformationmay
364composeimplicitloggingguidelinesthatdevelopersfollowwhen
decidingonlogginglocations.Inthissection,weseektoexplorethe
potentialofautomaticallysuggestinglogginglocationsattheblock
level. Such an automated approach might further assist developers
inmakingloggingdecisionsandimprovingloggingpractice.Below,
we describe our approaches that extract block features and build a
deep learning model to suggesting logging locations.
4.1 Extracting Block Features
Identifying Logged Blocks. Our goal is to provide suggestions
ondecidingblocksthatrequireloggingstatements.Wechooseto
provideasuggestionattheblocklevelbecauseaswefindinSec-
tion3thatmanyloggingstatementsarerecordingthebehaviour
or state of the program in blocks. In addition, blocks provide a
finer-grandsuggestionwhichmaybemoreactionablecompared
to coarse-grand suggestions (e.g., method or file level) [ 61,62]. We
analyzethesourcecodebyparsingtheabstractsyntaxtree(AST)
of every method in the studied systems. Then, we identify the AST
nodesinamethodthatrepresentblocks,suchastheblocknodes
thatareassociated with if,for,and catch.Hence,eachmethodmay
contain multiple blocks. For the block nodes that we identified, we
thenlabelthemaseither loggedblockornon-logged blockbyanalyz-
ingiftheblockcontainsatleastoneloggingstatement.Specifically,onlytheblockthatdirectlycontainsaloggingstatementislabelledasaloggedblock.Forexample,asshowninFigure1,block B0(line3
-6)islabelledasa loggedblockbecausethereisaloggingstatement
in line 4. Block B1is labelled as a non-logged block, because the
logging statement in line 4 is not directly contained by block B1.
Table1showsthestatisticsofblocksinthestudiedsystems.#LB
referstothenumberof loggedblocks,#NLBreferstothenumberof
non-logged blocks, and %LB is the percentage of loggedblocks over
alltheblocks.Notethattheremightbemultipleloggingstatementsinablock,sothenumberof loggedblockissmallerthanthenumber
of logging statements in each system. In general, we find that only
a small portion, i.e., 3.2% to 14.8% of the blocks contain logging
statements.Hence, accuratelysuggesting logginglocations at
the block level is a challenging task.
As we find in Section 3, the locations of logging statements
may be influenced by either the syntactic, semantic, or both types
of information in source code. In order to obtain the features for
trainingdeeplearningmodelsandtofurtherstudytheeffectiveness
ofthesefeaturesinsuggestinglogginglocations,wethenextract
thesyntactic,semantic,andfusedblock-levelfeatureswhenweare
analyzing the source code of each block.
Extracting Block Features. In our manual study, we find that
logging statements often have dependencies with the preceding
code in the same method. For example, the arguments in the if
statementareprocessed ordefinedintheprior code(asshownin
Section3).Asalsofoundinpriorstudies[ 25,54],developersmay
insert logging statements based on the execution flow prior to the
logging point.
Therefore, for each identified block, we analyze the source code
from the start of the method, in which the code block is located, to
the end of the block. This could also reflect developers’ sequential
workflow by suggesting whether or not a block needs a logging
statementwhendevelopersfinishimplementingtheblock[ 23].For
Figure 1: An example of how we label code blocks and ex-tract the tokens for generating the features. We illustratethe tokens extracted from Code Block B0.
example,inFigure1,forblock B0,weconsiderthecodestatements
fromline1toline6.Similarly,forblock B1,weconsiderthecode
statements from line 1 to line 8. Specifically, for each code blockin a studied system, we find all the AST nodes from the start of
themethodtotheendofthisblock.ThenforeachASTnode,we
record its type (e.g., MethodInvocation, VariableDeclaration, or
CatchClause),theassociatedsemanticinformation(e.g.,thename
of the variable declared in the VariableDeclaration node) as wellas the location (i.e., class and method, and the start line and end
line). We then extractthree types of code block featuresusing theabove-mentioned information from these AST nodes.
Below,wediscusstheapproachesthatweusetoextractsyntactic,
semantic, and fused block features, respectively.
Syntactic Block Features: Weextractthesyntacticfeaturesthat
representthestructuralinformationfromtheASTnodesincode
blocks. We capture the syntactic information by extracting the
AST nodes that are related to the control flow of the code. We
exclude AST nodes, such as SimpleName (i.e., identifier name) and
SimpleType(i.e.,identifiertype),whichdonotcontainstructural
informationofthecode.Foreachblock,wecounttheoccurrence
ofeachASTnodeintheblockandallprecedingcodeinthesame
method. At the end of the syntactic feature extraction, for eachblock, we obtain a vector that represents the occurrence of eachstructural AST node in the block and its preceding code. We call
eachelementinthevectorasatoken.Figure1showsanexample
ofthesyntacticfeaturesforthe B0block,whereweextracttheAST
nodes from the feature scope.
Semantic Block Features: We extract the semantic features from
the textual information inside the code blocks. Prior studies found
that information such as variable names may capture the semantic
information of the code [ 16,17,33,78]. Therefore, we process
variable names and invoked methods in the block as plain text.
For each block, we consider all the semantic information in the
block and in the preceding code in the same method. Note that we
excludeallreservedkeywordsintheprogramminglanguages,such
365Source Code[[[[......1
01
......
0100
......
0
Code Block Features
(Integer Representation)
Word Embedding Layer......
RNN Layer
(LSTM)RNN
Cell
RNN
Cell
RNN
Cell......RNN
Cell
Dropout Layer......Output Layer
Figure 2: The overall architecture of our approach.
asif,else, and for, to avoid capturing structural information. We
follow common source code preprocessing techniques: splitting
the words using camel case, converting all words to lower case,
and applying stemming [ 16,48]. Figure 1 shows an example of the
semantic block features of the B0block.
Fused Block Features: Developers may add logging statements
based on both the syntactic and semantic of the code. Therefore, in
addition tobuilding separatemodels usingthe above-mentionedsyntactic and semantic features, we also combine both types of
information together (i.e., fused features). To obtain fused features
ofcodeblocks,webuildanunifiedcorpuscontainingbothsyntactic
andsemanticinformationofthesourcecodebyfollowingaprior
study[42].Specifically,wemergethesyntacticandsemanticfea-
turesinablocktogether,whilekeepingtheoriginalordersofthose
AST nodes in the source code. Then, for each fused code block, we
obtain the vector representation similar to the process discussed
in other types of features. Figure 1 shows an example of the fused
code block features of the B0block.
4.2 Deep Learning Framework and
Implementation
Weformulatetheprocessofsuggestinglogginglocationsasabi-
nary classification problem. Given a block, we apply deep learning
modelstosuggestwhetherornottheblockshouldcontainalogging
statement. In this subsection, we discuss the overall architecture
and implementation of our deep learning model.
Overall Architecture. Figure 2 shows the overall architecture
of our approach. We first map our input vectors (i.e., syntactic,
semantic, and fused features) through an embedded layer. The
embeddedlayerlearnstherelationshipandsimilarityamongthe
vectorsineachblockfeatureandprocesseseachvectorbasedon
integer encoding to probabilistically distributed representations.
We then employ a recurrent neural network (RNN) layer to model
the relationship between the logging decision of a block and the
vectorsreturnedfromtheembeddinglayer.Finally,theoutputlayer
of our deep learning model is a one-dimension dense layer with
the sigmoid activation function to suggest whether a block should
be logged or not. Below, we discuss the details of each layer.
Embedding Layer. Afterextractingthesyntactic,semantic,and
fusedfeatures(i.e.,intheformsofvectors,asillustratedinFigure1),
we feed them to the embedding layer. The embedding layer cap-
turesthelinearrelationshipsamongtokensintheinputvector,and
outputsasetofnewvectors,calledwordembeddings[ 49,59].Com-
pared to simple integer encoding or one-hot encoding which does
not consider the relationship among the tokens, word embeddings
can learn the similarities among tokens and return probabilisti-
callydistributedrepresentationsofthewords(e.g., runandexecute
might be similar in vector space).RNN Layer. Since source code provides instruction on system
execution, there are dependencies between consecutive lines of
sourcecode.Forexample,aswediscussedinourmanualstudy,the
condition variable in IfStatement may have dependency on prior
source code, because the variable is defined or processed priorly.Hence, we follow prior studies [
19,27,52,75] and model source
codeassequentialdata(i.e.,weconsidertheorderofthesourcecodetokensinthedata).WeincludealayerofLongShortTermMemory
(LSTM) in the deep learning model, which is a variant of RNN that
includes a memory cell and gate mechanisms in the recurrent unit
to preserve long term dependencies of the code [22, 28, 31, 35].
OutputLayer. Afterthepreviouslayers,theblockfeaturesarestill
high-dimensional vectors. In order to make a binary suggestion of
whether a block is loggedornon-logged, we use a one-dimensional
dense layer with sigmoid activation function as the output layer of
our approach. This layer takes all outputs from the previous layer
toitsuniqueneuron,thentheneuronprovidesthefinalsuggestion
(i.e.,loggedornon-logged) of this block.
Implementation and Training We use Keras [ 2] to implement
our deeplearning model.For theembedding layer,we adoptSkip-
gramfromWord2vec[ 1]andsetthedimensionto100[ 48]toobtain
the word embeddings of each type of the three features separately.
FortheRNNlayer,wesetthedimensionofhiddenstatesas128and
attach a dropout layer with a 0.2 dropout rate in order to reduce
the potential impact of overfitting and immoderate reliance on the
trainedsystem[ 30,57,76].Wetrainourmodelfor100epochson
each studied system and set the batch size to 24. Because there is a
noticeableimbalancebetweenthenumberof loggedblocksand non-
loggedblocks(overallonly3.2%to14.8%blocksare loggedblocks,
as shown in Section 4), for each studied system and each type of
code block features, we apply stratified random sampling [ 55] (i.e.,
ensuretherandomsamplehasthesamedistributionofclassesas
the original data) to split the block features into training set (60%),
validation set (20%) and testing set (20%) [ 48,75].Note that we
remove the log-related statements when we are generating
the features to avoid biases in the suggestion results. Finally,
we upsample the loggedblock features in the training set after the
splitting process to mitigate the impact of data imbalance [7, 53].
5 EVALUATION
In this section, we evaluate our approach by introducing the evalu-
ation metrics and answering two research questions.
5.1 Evaluation Metrics
Given the features of a code block as inputs, our deep learning
modelsuggestsifthisblockis loggedornon-logged.Toevaluatethe
performanceofourmodel,weuseBalancedAccuracy,Precision,
Recall, and F-measure as our evaluation metrics.
Balanced Accuracy. Balanced accuracy is widely used by prior
studiestoevaluatemodelperformanceonimbalanceddata[ 41,78].
It calculates the average of True Positive Rate (i.e., how many sug-
gestedloggedblocks are correct) and True Negative Rate (i.e., how
many suggested non-logged blocks are correct). Balanced accuracy
is computed as:
BalancedAccuracy =(TP
TP+FN+TN
TN+FP)/2
366Table 2: The results of suggesting logging locations using syntactic (Syn.), semantic (Sem.), and fused (Fus.) block features.
Balanced Accuracy Precision Recall F1
Systems Syn. Sem. Fus. RG. Syn. Sem. Fus. RG. Syn. Sem. Fus. RG. Syn. Sem. Fus. RG.
Cassandra 83.0 65.8 65.2 49.8 51.7 37.1 31.8 3.0 56.6 33.7 33.2 3.5 54.0 35.3 32.5 3.2
Elasticsearch 81.9 67.7 69.9 50.1 52.0 29.7 24.3 3.6 55.6 38.6 44.7 3.7 52.9 33.6 31.5 3.6
Flink 83.0 74.2 75.0 50.0 58.9 36.0 37.6 5.6 70.9 54.4 55.6 8.7 64.3 43.3 44.9 6.8
HBase 80.5 69.7 72.9 49.9 56.1 45.2 43.2 4.8 63.4 41.9 49.1 5.0 59.5 43.5 45.9 4.9
Kafka 74.4 68.3 67.5 50.1 41.5 30.8 37.4 9.5 58.2 48.5 49.0 11.0 47.3 37.7 42.5 10.2
Wicket 84.7 76.6 72.2 50.0 45.7 28.1 26.9 3.7 72.3 58.5 49.2 3.2 56.0 37.9 34.8 3.4
Zookeeper 72.9 64.6 70.5 49.8 48.3 39.6 47.5 12.8 55.6 39.2 50.3 16.8 51.7 39.4 48.9 14.5
Average 80.1 69.6 70.5 50.0 50.6 35.2 35.6 6.1 61.8 45.0 47.3 7.4 55.1 38.7 40.2 6.7
Note: RG.represents the result of the baseline. For each system and for each evaluation metric, the block feature that yields the best performance is marked in bold. All the numbers represent percentage.
whereTP,TN,FPandFNrefertoTruePositive,TrueNegative,False
Positive(i.e.,suggestedasa loggedblockbutisactuallya non-logged
block) and False Negative (i.e., suggested as a non-logged block but
isactuallya loggedblock),respectively.A highbalancedaccuracy
means both the majority class (i.e., non-logged block) and minority
class (i.e., loggedblock) are accurately suggested.
Precision. In our study, precision represents the ability of our
approach to correctly suggest loggedblocks (i.e., how many logged
blockssuggested byourmodelare correct).Specifically,precision
is defined as:
Precision =TP
TP+FP
Note that only positive labels (i.e., loggedblock) are considered for
thismetric(i.e.,theperformanceon non-logged datadoesnotaffect
ourcalculationofprecision).Hence,ahighprecisionmeansthat
most of the suggested loggedblocks are indeed logged.
Recall.Recall representsthe abilityof finding loggedblocksfrom
the data set (i.e., how many loggedblocks can be suggested by our
approach). It is computed as:
Recall=TP
TP+FN
Sameasprecision,onlypositivelabelsareconsideredforthismetric.
Ahigherrecallmeansthatwecanidentifymorecodeblocksthat
need to be logged.
F1 Score. F1 score is a metric that considers both precision and
recall. It is computed as:
F1=2∗(Precision ∗Recall
Precision +Recall)
F1 score balances the use of precision and recall and provides a
morerealisticmeasureoftheperformancebyusingbothofthem.
A high F1 score means that we can both accurately and sufficiently
suggestloggedblocks.
5.2 Case Study Results
Inthissubsection,wepresenttheresultsforourresearchquestions
(RQs). For each RQ, we describe the motivation, approach, and
results and discussions.RQ1: How effective are different block features when sug-
gesting logging locations?Motivation.
Deciding where to log is a challenging practice [ 25,
41,78]. As we find in our manual study, there exist some common
characteristics of where developers insert logging statements. Log-
ginglocation mightberelated toeitherthe syntacticinformation,
semanticinformationofthecode,orboth.InthisRQ,weinvesti-
gatetheperformanceofourdeeplearningmodelsandhoweach
block feature performs in suggesting logging location. Our findingmayhelpvalidateourmanualstudyresultsthattheremaybean
implicit logging guideline that developers follow, and identify the
important features in suggesting logging location. Specifically, we
split this RQ into three sub-RQs:RQ1.1:
What is the performance of the three block features when
suggesting logged blocks?RQ1.2:Do different block features capture different information?
RQ1.3:
What are the suggestion accuracies for different categories
ofloggedblocks?
Approach. We train our deep learning framework on the training
databyfollowingtheprocessdiscussedinSection4.Weconductourexperiments on the same systems that we used in our manual anal-ysis.Foreachstudiedsystem,wetrainthreemodelsusingdifferent
types of block features (i.e., syntactic, semantic, and fused). Finally,
we evaluate the model performance on the testing set using the
above-mentioned evaluation metrics. Note that we pre-determined
thetraining(60%),validation(20%),andtesting(20%)datasetbefore
extractingtheblockfeatures.Hence,weusethesamesetofcode
blocksforeachsystemwhenevaluatingthesyntactic,semanticand
fused blocks features.RQ 1.1:
What is the performance of the three block features when
suggesting logged blocks? To evaluate the effectiveness of our mod-
els, we compare the results of the models trained using three blockfeatures with a baseline. Since there is no prior study that suggests
logging locations at the block level, we use Random Guess (RG) as
ourbaseline,whichiscommonlyusedbypriorstudies[ 18,26,46,
48,60,63,64]. Given a block in a studied system, Random Guess
suggests whether this block should be a loggedblock ornon-logged
blockbasedontheproportionof loggedblockinthissystem.For
example,10%ofthecodeblocksinKafkaare loggedblockasshown
in Table 1. Then, for each code block being tested, there is a 10%chance for Random Guess to suggest it as a loggedblock and a
90% chance to suggest it as an non-logged block. We repeat the
Random Guess 30 times (as suggested by previous studies [ 18,26])
for each system to reduce the biases. We report the average values
ofthefourevaluationmetricscomputedbasedonthe30timesof
iterations as the result of Random Guess.RQ 1.2:
Dodifferentcodeblockfeaturescapturedifferentinformation?
Tofurtherinvestigateifdifferentblockfeaturescapturedifferent
information in the source code, we examine the overlap and dif-
ferences of the results generated from the models trained by using
three block features. For each type of block feature, we collect the
prediction results on the testing data of seven studied systems,analyze the True Positives, True Negatives, False Positives, and
False Negatives, and compute the percentage of overlap among the
syntactic, semantic and fused block features.
367(a) True Positive (b) True Negative
(c) False Positive (d) False Negative
Figure 3: Venn diagrams of TP, TN, FP and FN of the three
block features. Each number represents the percentage ofthe corresponding intersecting set out of the union set.
RQ 1.3:
What are the suggestion accuracies for different categories of
loggedblocks? Sincethreecodeblockfeaturesmaycapturedifferent
informationinthesourcecode,theymighthavevariedperformance
when predicting different categories of loggedblocks. Hence, we
further evaluate the performance of thethree block features on the
different categories of logging statements (Section 3). We report
the suggestion results based on the type of blocks that the logging
statement is associated with (i.e., try-catch block, branching block,
looping block, and method declaration block).Results and Discussions.RQ 1.1.
Table 2 presents the results of the models built using the
Syntactic(Syn.),Semantic(Sem.)andFused(Fus.)codeblockfea-
tures, and the baseline Random Guess (RG.). Overall, for all the
evaluation metrics, models trained by using the block features out-
performthebaseline.TheprecisionofRGrangesfrom3.0%to12.8%,
recall ranges from 3.2% to 16.8%, and the balanced accuracy ranges
from 49.8% to 50.1%. Note that RG makes suggestion based on the
distribution of training data, the distribution of loggedandnon-
loggedblocks in the testing data is the same as the original data (as
showninTable1).Therefore,givensufficienttrails,thebalancedac-curacyofRGwillbecloseto50%.Wefindthatmodelstrainedusing
thesyntacticblockfeatureshavethebestperformancecompared
to other block features across all studied systems. In particular,
the balanced accuracy of semantic and fused features ranges from
64.6% to 76.6%, while for syntactic feature it is over 72.9% on allthe studied systems (with an average of 80.1%). The average pre-
cisionrangesfrom24.3%to47.5%whenusingsemanticandfused
blockfeatures,andtheaveragerecallrangesfrom33.2%to58.5%.
Incomparison,theaverageprecisionandrecallonsyntacticfeature
are50.6%and61.8%,respectively.Theresultsshowthatsyntactic
information might play an important role in logging decisions and
may be leveraged to suggest logging locations.RQ 1.2.
Figure 3 shows the percentage overlap on (a) True Posi-
tive, (b) True Negative, (c) False Positive, and (d) False Negative(a) Balanced Accuracy (b) Precision
(c) Recall (d) F1
Figure4:The(a)BalancedAccuracy,(b)Precision,(c)Recall,and (d) F1 of the models trained from three block features
when applied on different types of blocks.
among the models trained using syntactic, semantic, and fused
block features. Note that Red, Green, and Blue circle represents the
suggestion results of syntactic, semantic, and fused block features,
respectively. Eachnumber representsthe percentageof thecorre-
sponding intersecting data set (e.g., for TP, 42.0% represents the
commonsetofTruePositiveamong Syn., Sem.andFus.)outofthe
entireset(e.g.,forTP,theentiredatasetisthesetthatcombines
the TP from syntactic, semantic and fused altogether across all
studiedsystems).Thereisa42.0%overlapinTPamongthethree
features,whilesyntacticcoversmostoftheTPs(79.9%outofallthe
TPs)comparedtosemantic(62.3%)andfused(66.5%)blockfeatures.
Only 20.1% of the TPs are missed by syntactic but captured by two
otherblockfeatures.ForTNs(i.e.,correctlysuggestas non-logged
block), almost all (93.9%) are overlapping among the three block
features.Theresultsshowthatthereisahighlevelofagreement
among the models when suggesting the non-logged blocks. For FPs,
thereisnoconsiderableoverlapamongthethreefeatures(13.3%).
For FNs, syntactic has the lowest number of FNs (63.2% of the FNs
arecoveredbysyntactic,comparedto80.2%coveredbysemantic
and 76.2% covered by combined feature). The results show that
differentblockfeaturesmightcapturedifferentinformationfrom
source code. As semantic and fused block features still capture TPs
thataremissedbysyntacticblockfeature(20.1%),futureworkcould
further investigate how to better combine the two sources of infor-
mationtoprovideasufficientandaccuratesuggestion.Moreover,
wemanuallyinvestigateasampleofFPsandFNs.Weidentifytheir
characteristics and find that many of them are not indeed FPs and
FNs (details in Section 6).RQ 1.3.
Figure 4 shows the (a) Balanced Accuracy, (b) Precision, (c)
Recall,and(d)F1ofthemodelswhensuggestingondifferenttypes
ofblocksassociatedwiththecategoriesinSection3.Overall,the
threeblockfeatureshaveasimilartrendfortheresultsondifferenttypesofblocks.Syntacticfeatureshavethebestresultsforalltypes
of blocks on all the evaluation metrics. Among the four types of
368Table 3: The results of cross-system logging locations suggestion using syntactic block features.
Balanced Accuracy Precision Recall F1 Fleiss’ Kappa
Systems Within Cross Ratio Within Cross Ratio Within Cross Ratio Within Cross Ratio logged non-logged
Cassandra 83.067.8 (σ3.0) 81.7 51.7 37.5 (σ9.1) 72.6 56.641.9 (σ7.8) 74.1 54.039.1 (σ7.3) 72.5 0.47(Mod.) 0.90 (Sub.)
Elasticsearch 81.965.5 (σ4.5) 80.0 52.036.2 (σ11.5) 69.7 55.642.0 (σ5.2) 75.6 52.937.8 (σ7.0) 71.5 0.45(Mod.) 0.90 (Sub.)
Flink 83.070.2 (σ3.0) 84.6 58.9 30.5 (σ8.8) 51.8 70.949.2 (σ9.1) 69.4 64.336.7 (σ7.6) 57.1 0.46(Mod.) 0.91 (Sub.)
HBase 80.567.5 (σ2.3) 83.9 56.1 37.5 (σ4.8) 66.9 63.441.8 (σ6.7) 66.0 59.540.5 (σ4.6) 68.1 0.49(Mod.) 0.92 (Sub.)
Kafka 74.465.7 (σ4.1) 88.4 41.5 32.0 (σ4.2) 77.2 58.242.5 (σ6.8) 73.1 47.336.2 (σ3.9) 76.6 0.42(Mod.) 0.88 (Sub.)
Wicket 84.767.8 (σ3.3) 80.1 45.7 40.3 (σ5.2) 88.2 72.342.1 (σ8.0) 58.3 56.040.8 (σ4.7) 72.9 0.43(Mod.) 0.85 (Sub.)
Zookeeper 72.966.8 (σ2.7) 91.7 48.3 33.6 (σ6.2) 69.6 55.644.8 (σ5.6) 80.6 51.738.3 (σ5.8) 74.1 0.37(Fair) 0.81 (Sub.)
Average 80.1 67.3 84.0 50.6 35.4 70.0 61.8 43.5 70.4 55.1 38.6 70.0 0.44(Mod.) 0.88 (Sub.)
Note: Withinshows the results of within-system suggestion. Crossshows the average results and the standard deviation ( σ) when applying the models trained using other systems. Ratioshows the
percentage of Crossover Within. Fleiss’ Kappa shows the degree of agreement on the suggestion result of the cross-system models on loggedandnon-logged blocks.Mod.andSub.represent moderate and
substantial agreement [37], respectively.
blocks,loggingstatementsassociatedwithtry-catchblockshave
the best results on all the evaluation metrics (85.8% balanced ac-
curacy, 75.2% precision, 79.1% recall and 77.2% F1 for syntactic).
Asalso foundinprior studies[ 25,78],logging statementsinsuch
blocks may be better defined. We also find that logging statements
associatedwithbranchingblockshaveagoodoverallsuggestion
result. Incontrast, the resultsof suggesting logging statementsas-
sociated with looping and method declaration blocks are relatively
lower(balancedaccuracyrangesfrom63.2%to69.0%,andF1rangesfrom 22.1% to 23.8%). Although the three block features have a sim-
ilartrend ofresults ondifferenttypes ofblocks, syntacticfeatures
arebetterthantheothertwoforsuggestinglogginglocationsonall
thestudied typesofblocks.Moreover,ourstudy showsthatthere
isaclearerpatternofinsertingloggingstatementsintry-catchand
branching blocks (i.e., higher precision and recall). Practitionersmay prioritize reviewing and deciding the given logging sugges-
tionsinsuchblocks.Inaddition,futureresearchmayinvestigate
other sources of information in order to better assist in making
logging decisions for looping and method declaration blocks.
All the trained models noticeably outperform the baseline.
Among the three types of block features, models trained using
syntactic block features achieve the best results on all the
evaluationmetrics.Theresultsshowthatsyntacticinformation
might be leveraged to suggest logging locations.
RQ2: Are the trained models transferable to other systems?Motivation.
When working on a new system, developers may en-
counterdifficultieswhendecidinglogginglocations.Differentfrom
matured systems with a long period of development and mainte-
nancehistory, developersworkingonnew systemsmaynothave
sufficientknowledgeondecidingwheretolog.Therefore,inthis
RQ,weinvestigatewhetherdifferentsystemssharesimilarimplicitguidelines of logging locations. Our findings may provide evidence
on the existence of common logging characteristics across systems
and help future research derive a universal logging guideline. In
particular, we study two sub-RQs:RQ2.1:
Whatistheeffectivenessofcross-systemloggingsugges-
tion?RQ2.2:
What is the level of suggestion agreement on cross-system
models?
Approach. In this RQ, we study if loggedblocks share similar syn-
tactic block features by doing a cross-system transferable learning.
Namely, we study if a model that is trained using the syntactic
featuresfromonesystemcanbeusedtosuggestlogginglocation
in another system. We choose to study syntactic block featuresbecause they are extracted from the AST nodes in the source code,
which are common across all Java systems, and they have the best
performancecomparedtotheothertwoblockfeaturesasshown
in RQ1. Moreover, since the syntactic block features capture theunderlying code structure [
33], a high cross-system suggestion
accuracymayshowthepotentialofderivingaloggingguideline
based on code structure in future studies.RQ 2.1:
What is the effectiveness of cross-system logging suggestion?
Foreachstudiedsystem,webuildamodelusingthesyntacticblock
features and apply the model on each of the other systems. For
example,wetrainamodelusingthesyntacticblockfeaturesinCas-
sandra,andapplythemodelonsixotherstudiedsystems.Finally,
wecomputeandreporttheaveragebalancedaccuracy,precision,
recall, and F-measure of the cross-system logging suggestion.RQ 2.2:
What is the level of suggestion agreement on cross-system
models?Tostudywhetherthemodelstrainedusingdifferentsys-
tems capture similar information (i.e., the relationship between the
syntactic features and logging location), we analyze the agreement
levelofcross-systemsuggestionresults.Weseparatelyexaminethe
suggestion agreement of the cross-system models on loggedblocks
andnon-logged blocks. Namely, for each studied system, we apply
themodelstrainedusingothersystems,andstudythesuggestion
results of the cross-system models on the truelogged blocks and
thetruenon-logged blocks, respectively. In particular, we compute
Fleiss’s Kappa to study the agreement among the suggestion re-
sultsfromcross-systemmodels[ 24].Fleiss’sKappacomputesthe
inter-rateragreementamongafixedsetofraters(i.e.,suggestion
resultsfromdifferentcross-systemmodels).Ahigherlevelofagree-
ment may show that the syntactic block features have very similar
relationships with logged or non-logged blocks across all studied
systems.Results and Discussions.RQ 2.1.
Table3showstheresultsofourcross-systemsuggestions
usingsyntacticblockfeatures.Ingeneral,wefindthattheresultsofcross-systemsuggestionsarelowerthanwithin-systemsuggestions
usingsyntacticblockfeatures.However,theresultsarestillcom-
parable to within-system suggestions using semantics and fused
blockfeatures.Forbalancedaccuracy,thecross-systemsuggestions
achieveover80%(i.e., RatiocolumninTable3)of thecorrespond-
ing within-system suggestion using syntactic block features. Onaverage, the balanced accuracy ranges from 65.5% to 70.2%, with
standard deviations range from 2.3 to 4.5. For precision, recall, and
F1,thecross-systemsuggestionsachieve51.8%to88.2%ratioofthe
within-systemsuggestionresults.Inshort,eventhoughwefindthat
theresultsofcross-systemsuggestionareslightlylowerthanthose
ofwithin-system,wemaystillachieveareasonableperformance.
369Similar to RQ1, we also manually study a sample of FPs and FNs
from the results of RQ2 (details in Section 6).
RQ 2.2.Table 3 also shows the Fleiss’s Kappa [ 24] for each studied
system. For loggedblocks, the agreements are moderate in six stud-
iedsystems.TheagreementlevelisfairinZookeeper,butthevalueisalsoclosetothethresholdofamoderateagreement(i.e.,0.41[
24]).
Our results show that the models trained using the syntactic block
features may share certain underlying properties. Namely, there
aresomecommonalitiesinthecodestructureonhowdevelopers
decidelogginglocationsacrossthestudiedsystems.For non-logged
blocks,theagreementsaresubstantialacrossallstudiedsystems.
Inshort,ourfindingsshowthatdevelopersareratherconsistenton
decidingwhichblocks donotneedloggingstatements.Although
there are some inconsistencies across the studied systems, we may
stillapplycross-systemmodelstohelpsuggestlogginglocations
in other systems.
Wefindthatcross-systemlogginglocationsuggestionachieves
a reasonable performance compared to within-system sugges-
tion(i.e.,84%ofthewithin-systembalancedaccuracy).Wealso
findthatthecross-systemmodelshavemoderateagreements
onloggedblocks and substantial agreements on non-logged
blocks. Ourresults show that developersin different systems
may follow certain implicit guidelines on deciding logging
locations.
6 DISCUSSION
As shown in the RQs, our models can provide promising results of
suggesting logging locations. To further inspire future studies and
betterassistpractitioners,weconductamanualstudytounderstand
the FPs and FNs in the suggestion results. For each studied system
inRQ1andforeachofthethreemodels(i.e.,Syntactic,Semantic,
and Fused, simplified as Syn., Sem.andFus.), we select the top-
fiveFPsandFNsforourmanualstudy,rankedbytheirsuggested
probabilitiesofbeing loggedandnon-logged,respectively(atotalof
105 FPs and 105 FNs). For the cross-system models in RQ2, we also
select the top-five FPs and FNs from each system (a total of 35 FPs
and 35 FNs).
FalsePositives. ForSyn.in RQ1, we find that 25/35 of the studied
FPs are actually TP. The code block either contains some other
types of print statements to record the execution information (e.g.,
System.out.print()), or contains only one child block and has no
other code statements, and the child block contains a logging state-
ment. For Sem., Fus., and cross-system models, we also find 15/35,
16/35,and18/35casesthatbelongtothiscategory,respectively.For
theremainingstudiedFPs,thesuggestionsaremadewhenthecode
block is at the beginning of a method (9 cases for Syn., 12 for Sem.,
10for Fus.,16forcross-systemmodels),orincomplexcodewith
multiple nested blocks (1 case for Syn., 8 for Sem., 9 for Fus., 1 for
cross-system models).FalseNegatives.
Wefindthat15/35ofthestudied Syn.FNsmay
nottrulybeFN.SimilartothesituationinFPthatacodeblockonly
containsa loggedchildblockandhasnoothercodestatements,the
child block is suggested as a non-logged block and thus becomes
an FN. For Sem., Fused.and cross-system models, we find 7/35,
6/35, and 15/35 cases that belong to this category. We also find thatfor 4/35, 3/35, 3/35 and 5/35 of the studied FNs from Syn., Sem.,
Fus.andcross-systemmodels,theyareblocksthathavemanyvery
similar sibling blocks nearby (e.g., many similar ifblocks having
similarstructures),whileonlytheFNcasesherecontainlogging
statements. For the remaining studied FNs, similar to what we find
inFPs,theylocateatthebeginningofamethod(15casesfor Syn,18
forSem.,14for Fus.,14forcross-systemmodels),orincomplicated
code structure with multiple nested code blocks (1 case for Syn.,7
forSem., 12 for Fus., 1 for cross-system models).
Our findings show that the actual performance of our model
may be even better due to the diverse nature of how developers
write logging code. We also find that it may be more difficult to
suggest a logging statement at the beginning of a method due to
the lack of prior information in the code block.
7 THREATS TO VALIDITY
ConstructValidity. Ourapproachpresumesthatthetrainingdata
has high-quality source code and follow good logging practice.However, there exist no industrial standards guiding developers
towriteloggingstatements.Inthispaper,wechoosesevenlarge-
scale, well-maintained systems with different sizes, across various
domains to conduct the study. They are commonly used in priorlog-relatedstudiesandareconsideredasfollowinggoodlogging
practice[10,11,38,46].Weevaluateourmodelsonthetestdataset
of each studied system. Different test data set might lead to very
differentresults.Tomitigatethefluctuationcausedbydifferenttest
dataset,weapplystratifiedrandomsamplingbyfollowingprior
studies[48,55,75]tosplitthedatasetandensureeachrandomly
sampled data set has the same distribution of labels as the original
data.
Internal Validity. Weconductmanualstudiestoinvestigatethe
characteristics and uncover the categories of logging locations. To
avoidbiases,theauthorsexaminethedataindependently.Formost
of the cases, the authors reach an agreement. Any disagreement
is discussed until a consensus is reached with a substantial-levelagreement (Cohen’s Kappa 0.86) [
56]. Involving third-party log-
gingexpertstoverifyourresultsmightfurtherreducethisthreat.
Differentparametersusedintheneuralnetworksmightaffecttheef-fectivenessofthetrainedmodels.Wefollowpriorstudies[
48,75]to
settheparametersforourdeeplearningmodels.Themodelstrainedusingourapproachmightnotbeoptimalonsomeoftheevaluation
metrics (e.g., an average F1 score of 66.7 on syntactic code blockfeatures). Future study may further improve the performance of
ourapproachandprovideamorecomprehensiveperspectiveofthesuggestionresultsbysurveyingsoftwareengineeringpractitioners.
We use word embeddings [ 49,59], which is widely used by prior
studies [48,75] as the distributed representations of source code.
Futurestudymayconsiderothercoderepresentationapproaches
(e.g.,code2vec[ 6,34])toexaminetheperformanceonsuggesting
logging locations.
External Validity. Weconductedourstudyonlyonsevenlarge-
scaleopensourcesystems.However,weselectedthestudiedsys-
temsinvariousdomainsandsizes(from97Kto1.5MLOCasshown
inTable1)inordertoimprovetherepresentativenessofourstud-
ied systems. Our studied systems are all implemented in Java. The
results and models may not be transferable to systems in other
370programming languages. Future studies should validate the gen-
eralizabilityofourfindingsandthetransferabilityofourmodels
in systems that are implemented written in other programming
languages.
8 CONCLUSION
Inthispaper,weaimtotacklethechallengesthatdevelopersmight
encounterwhendecidinglogginglocationsbyfirstconductinga
comprehensivemanualstudy.Weuncoversixcategoriesoflogging
locationsandfindthatdevelopersusuallyinsertloggingstatements
torecordexecutioninformationthathappensinvarioustypesof
codeblocks.Weproposeadeeplearningbasedapproachtoprovide
finer-grained(i.e.,atthecodeblocklevel)suggestionsonlogging
locations. Our approach achieves promising results on suggesting
logginglocationsinbothwithin-projectandcross-projectpredic-
tions.Ourresultshighlightthepotentialofprovidingfiner-grained
suggestions on logging locations by leveraging syntactic informa-
tioninthesourcecode,andsuchsuggestionsmaybesharedacrosssystems.Futurestudiescouldexploreamoreadvancedwayofcom-
bining syntactic and semantic information in the source code, in
order to provide better suggestions on logging locations.
REFERENCES
[1][n.d.]. gensimWord2vecembeddings. https://radimrehurek.com/gensim/models/
word2vec.html. Last checked Feb. 2020.
[2][n.d.]. Keras: The Python Deep Learning library. https://keras.io/. Last checked
Feb. 2020.
[3] [n.d.]. Log4j. http://logging.apache.org/log4j/2.x/.
[4][n.d.]. OracleJava Documentation. https://docs.oracle.com/javase/tutorial/java/
nutsandbolts/flow.html. Last checked Mar. 2020.
[5][n.d.]. SimpleLoggingFacadeforJava(SLF4J). http://www.slf4j.org. Lastchecked
Feb. 2018.
[6]UriAlon,MeitalZilberstein,OmerLevy,andEranYahav.2019. code2vec:learning
distributedrepresentationsofcode. Proc.ACMProgram.Lang. 3,POPL(2019),
40:1–40:29.
[7]HaraldAltinger,SteffenHerbold,FriederikeSchneemann,JensGrabowski,and
Franz Wotawa. 2017. Performance tuning for automotive Software Fault Predic-
tion. InIEEE 24th International Conference on Software Analysis, Evolution and
Reengineering, SANER 2017, Klagenfurt, Austria, February 20-24, 2017. 526–530.
[8]S. Boslaugh and P.A. Watters. 2008. Statistics in a Nutshell: A Desktop Quick
Reference. O’Reilly Media.
[9]BoyuanChenandZhenMing(Jack)Jiang.2017. Characterizingloggingpractices
in Java-based open source software projects – a replication study in Apache
Software Foundation. Empirical Software Engineering 22, 1 (Feb 2017), 330–374.
[10]Boyuan Chen and Zhen Ming (Jack) Jiang. 2017. Characterizing and Detect-
ingAnti-patternsintheLoggingCode.In Proceedingsofthe39thInternational
Conference on Software Engineering (ICSE ’17). 71–81.
[11]Boyuan Chen and Zhen Ming (Jack) Jiang. 2019. Extracting and studying the
Logging-Code-Issue- Introducing changes in Java-based large-scale open source
softwaresystems. EmpiricalSoftwareEngineering 24,4(01Aug2019),2285–2322.
[12]Boyuan Chen and Zhen Ming (Jack) Jiang. 2020. Studying the Use of Java
Logging Utilities in the Wild. In Proceedings of the 42nd International Conference
on Software Engineering, (ICSE 2020).
[13]BoyuanChen,JianSong,PengXu,XingHu,andZhenMing(Jack)Jiang.2018.
An automated approach to estimating code coverage measures via execution
logs. InProceedings of the 33rd ACM/IEEE International Conference on Automated
Software Engineering, ASE 2018. 305–316.
[14]Tse-HsunChen,WeiyiShang,AhmedE.Hassan,MohamedNasser,andParminderFlora.2016.CacheOptimizer:HelpingDevelopersConfigureCachingFrameworksforHibernate-basedDatabase-centricWebApplications.In Proceedingsofthe24th
ACMSIGSOFTInternationalSymposiumonFoundationsofSoftwareEngineering
(FSE 2016). 666–677.
[15]Tse-Hsun Chen, Mark D. Syer, Weiyi Shang, Zhen Ming Jiang, Ahmed E. Hassan,
Mohamed Nasser, and Parminder Flora. 2017. Analytics-driven Load Testing:
An Industrial Experience Report on Load Testing of Large-scale Systems. In
Proceedingsofthe39thInternationalConferenceonSoftwareEngineering:Software
Engineering in Practice Track (ICSE-SEIP ’17). 243–252.
[16]Tse-Hsun Chen, Stephen W. Thomas, and Ahmed E. Hassan. 2016. A Survey on
the Use of Topic Models when Mining Software Repositories. Empirical Software
Engineering 21, 5 (2016), 1843–1919.[17]Tse-Hsun Chen, S. W. Thomas, Meiyappan Nagappan, and A.E. Hassan. 2012.
ExplainingSoftwareDefectsUsingTopicModels.In Proceedingsofthe9thWorking
Conference on Mining Software Repositories (MSR ’12).
[18]Tse-Hsun Chen, Shang Weiyi, Zhen Ming Jiang, Ahmed E. Hassan, MohamedNasser, and Parminder Flora. 2014. Detecting Performance Anti-patterns for
Applications Developed using Object-Relational Mapping. In Proceedings of the
36th International Conference on Software Engineering (ICSE). 1001–1012.
[19]Zimin Chen, Steve Kommrusch, Michele Tufano, Louis-Noël Pouchet, Denys
Poshyvanyk,andMartinMonperrus.2019. SequenceR:Sequence-to-Sequence
Learning for End-to-End Program Repair. CoRRabs/1901.01808 (2019).
[20]Rui Ding, Hucheng Zhou, Jian-Guang Lou, Hongyu Zhang, Qingwei Lin, Qiang
Fu,DongmeiZhang,andTaoXie.2015. Log2:ACost-AwareLoggingMechanismforPerformanceDiagnosis.In 2015USENIXAnnualTechnicalConference,USENIX
ATC ’15,. 139–150.
[21]ZishuoDing,JinfuChen,andWeiyiShang.2020. TowardstheUseoftheReadily
Available Tests from the Release Pipeline as Performance Tests. In Proceedings of
the 42nd International Conference on Software Engineering, (ICSE 2020).
[22]XiaoningDu,XiaofeiXie,YiLi,LeiMa,YangLiu,andJianjunZhao.2019. AQuan-
titativeAnalysisFrameworkforRecurrentNeuralNetwork.In 34thIEEE/ACM
International Conference on Automated Software Engineering, ASE 2019. 1062–
1065.
[23]Ekwa Duala-Ekoko and Martin P. Robillard. 2007. Tracking Code Clones in
EvolvingSoftware.In 29thInternationalConferenceonSoftwareEngineering(ICSE
2007). 158–167.
[24]JosephL.Fleiss.1971. MeasuringNominalScaleAgreementamongManyRaters.
Psychological Bulletin 76, 5 (1971), 378–382.
[25]Qiang Fu, Jieming Zhu, Wenlu Hu, Jian-Guang Lou, Rui Ding, Qingwei Lin,
DongmeiZhang,andTaoXie.2014. WhereDoDevelopersLog?AnEmpirical
StudyonLoggingPracticesinIndustry.In Proceedingsofthe36thInternational
Conference on Software Engineering (ICSE-SEIP ’14). 24–33.
[26]Andy Georges, Dries Buytaert, and Lieven Eeckhout. 2007. Statistically rigorous
javaperformanceevaluation.In Proceedingsofthe22ndAnnualACMSIGPLAN
ConferenceonObject-OrientedProgramming,Systems,Languages,andApplications,
OOPSLA. 57–76.
[27]X.Gu,H.Zhang,andS.Kim.2018. DeepCodeSearch.In 2018IEEE/ACM40th
International Conference on Software Engineering, ICSE 2018. 933–944.
[28]QianyuGuo,SenChen,XiaofeiXie,LeiMa,QiangHu,HongtaoLiu,YangLiu,
JianjunZhao,andXiaohongLi.2019. AnEmpiricalStudyTowardsCharacterizing
Deep Learning Development and Deployment Across Different Frameworks and
Platforms. In 34th IEEE/ACM International Conference on Automated Software
Engineering, ASE 2019. 810–822.
[29]MehranHassani,WeiyiShang,EmadShihab,andNikolaosTsantalis.2018. Study-
ing and Detecting Log-Related Issues. Empirical Software Engineering (2018).
[30]Thong Hoang, Hoa Khanh Dam, Yasutaka Kamei, David Lo, and Naoyasu
Ubayashi.2019. DeepJIT:anend-to-enddeeplearningframeworkforjust-in-time
defectprediction.In Proceedingsofthe16thInternationalConferenceonMining
Software Repositories, MSR 2019. 34–45.
[31]Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long Short-Term Memory.
Neural Computation 9, 8 (1997), 1735–1780.
[32]Xing Hu, Ge Li, Xin Xia, David Lo, and Zhi Jin. 2018. Deep code commentgeneration. In Proceedings of the 26th Conference on Program Comprehension,
ICPC 2018. 200–210.
[33]Yuan Huang, Xinyu Hu, Nan Jia, Xiangping Chen, Yingfei Xiong, and Zibin
Zheng.2020. LearningCodeContextInformationtoPredictCommentLocations.
IEEE Trans. Reliability 69, 1 (2020), 88–105.
[34]Hong Jin Kang, Tegawendé F. Bissyandé, and David Lo. 2019. Assessing the
GeneralizabilityofCode2vecTokenEmbeddings.In 34thIEEE/ACMInternational
Conference on Automated Software Engineering, ASE 2019. 1–12.
[35]Jeremy Lacomis, Pengcheng Yin, Edward J. Schwartz, Miltiadis Allamanis, ClaireLeGoues,GrahamNeubig,andBogdanVasilescu.2019.DIRE:ANeuralApproach
to Decompiled Identifier Naming. In 34th IEEE/ACM International Conference on
Automated Software Engineering, ASE 2019. 628–639.
[36]Maxime Lamothe and Weiyi Shang. 2020. When APIs are Intentionally By-passed:AnExploratoryStudyofAPIWorkarounds.In Proceedingsofthe42nd
International Conference on Software Engineering, (ICSE 2020).
[37]J.R.LandisandG.G.Koch.1977. Themeasurementofobserveragreementfor
categorical data. Biometrics 33 (1977), 159–174.
[38]Heng Li, Tse-Hsun (Peter) Chen, Weiyi Shang, and Ahmed E. Hassan. 2018.
Studyingsoftwareloggingusingtopicmodels. EmpiricalSoftwareEngineering
(Jan 2018).
[39]Heng Li, Weiyi Shang, Bram Adams, Mohammed Sayagh, and Ahmed E. Hassan.
2020. A Qualitative Study of the Benefits and Costs of Logging from Developers’
Perspectives. IEEE Transactions on Software Engineering (2020), 1–17.
[40]Heng Li, Weiyi Shang, and Ahmed E. Hassan. 2017. Which log level should
developers choose for a new logging statement? Empirical Software Engineering
22, 4 (Aug 2017), 1684–1716.
[41]HengLi,WeiyiShang,YingZou,andAhmedE.Hassan.2017. Towardsjust-in-
time suggestions for log changes. Empirical Software Engineering 22, 4 (2017),
3711831–1865.
[42]Xiaochen Li, He Jiang, Yasutaka Kamei, and Xin Chen. 2020. Bridging Seman-
tic Gaps between Natural Languages and APIs with Word Embedding. IEEE
Transactions on Software Engineering (2020).
[43]ZhenhaoLi.2019. Characterizinganddetectingduplicateloggingcodesmells.InProceedings of the 41st International Conference on Software Engineering: Compan-
ion Proceedings, ICSE 2019. 147–149.
[44]ZhenhaoLi.2020. StudyingandSuggestingLoggingLocationsinCodeBlocks.
InProceedings of the 42nd International Conference on Software Engineering: Com-
panion Proceedings, ICSE 2020.
[45]Zhenhao Li. 2020. Towards Providing Automated Supports to Developers on
Writing Logging Statements. In Proceedings of the 42nd International Conference
on Software Engineering: Companion Proceedings, ICSE 2020.
[46]Zhenhao Li, Tse-Hsun (Peter) Chen, Jinqiu Yang, and Weiyi Shang. 2019.DLFinder: characterizing and detecting duplicate logging code smells. In Pro-
ceedingsofthe41stInternationalConferenceonSoftwareEngineering,ICSE2019.
152–163.
[47]QingweiLin,HongyuZhang,Jian-GuangLou,YuZhang,andXueweiChen.2016.
Log Clustering Based Problem Identification for Online Service Systems. In Pro-
ceedings of the 38th International Conference on Software Engineering Companion
(ICSE ’16). 102–111.
[48]Z. Liu, X. Xia, D. Lo, Z. Xing, A. E. Hassan, and S. Li. 2019. Which Variables
Should I Log? IEEE Transactions on Software Engineering (2019). Early Access.
[49]Tomas Mikolov,Kai Chen,Greg Corrado, and Jeffrey Dean. 2013. Efficient Esti-
mation of Word Representations in Vector Space. In 1st International Conference
on Learning Representations, ICLR 2013.
[50]MeiyappanNagappan,KeshengWu,andMladenA.Vouk.2009. Efficientlyex-
tracting operational profiles from execution logs using suffix arrays. In ISSRE’09:
Proceedings of the 20th IEEE International Conference on Software Reliability Engi-
neering. IEEE Press, 41–50.
[51]KarthikNagaraj,CharlesEdwinKillian,andJenniferNeville.2012. Structured
ComparativeAnalysisofSystemsLogstoDiagnosePerformanceProblems.In
Proceedings of the 9th USENIX Symposium on Networked Systems Design and
Implementation (NSDI ’12). 353–366.
[52]Bui D. Q. Nghi, Yijun Yu, and Lingxiao Jiang. 2019. Bilateral Dependency Neural
NetworksforCross-LanguageAlgorithmClassification.In 26thIEEEInternational
Conference on Software Analysis, Evolution and Reengineering, SANER 2019. 422–
433.
[53]Jeff H. Perkins, Sunghun Kim, Samuel Larsen, Saman P. Amarasinghe, Jonathan
Bachrach, Michael Carbin, Carlos Pacheco, Frank Sherwood, Stelios Sidiroglou,
Greg Sullivan, Weng-Fai Wong, Yoav Zibin, Michael D. Ernst, and Martin C.
Rinard. 2009. Automatically patching errors in deployed software. In Proceedings
of the 22nd ACM Symposium on Operating Systems Principles 2009, SOSP 2009.
87–102.
[54]He Pinjia, Zhuangbin Chen, Shilin He, and Michael R. Lyu. 2018. Characterizing
the Natural Language Descriptions in Software Logging Statements. In Proceed-
ings ofthe 33rd IEEEinternational conference onAutomated software engineering.
1–11.
[55]HeidarPirzadeh,SaraShanian,AbdelwahabHamou-Lhadj,andAliMehrabian.
2011. The Concept of Stratified Sampling of Execution Traces. In The 19th IEEE
International Conference on Program Comprehension, ICPC 2011. 225–226.
[56]Julilus Sim and Chris C. Wright. 2005. The Kappa Statistic in Reliability Studies:
Use,Interpretation,andSampleSizeRequirements. PhysicalTherapy 85,3(March
2005), 257–268.
[57]NitishSrivastava,GeoffreyE.Hinton,AlexKrizhevsky,IlyaSutskever,andRuslan
Salakhutdinov.2014. Dropout:asimplewaytopreventneuralnetworksfrom
overfitting. J. Mach. Learn. Res. 15, 1 (2014), 1929–1958.
[58]Michele Tufano, Cody Watson, Gabriele Bavota, Massimiliano Di Penta, Martin
White, and Denys Poshyvanyk. 2018. Deep Learning Similarities from Different
RepresentationsofSourceCode.In Proceedingsofthe15thInternationalConference
on Mining Software Repositories (MSR 2018). 542–553.
[59]PeterD.TurneyandPatrickPantel.2010. FromFrequencytoMeaning:Vector
Space Models of Semantics. J. Artif. Intell. Res. 37 (2010), 141–188.
[60]Harold Valdivia Garcia and Emad Shihab. 2014. Characterizing and Predict-
ingBlockingBugsinOpenSourceProjects.In Proceedingsofthe11thWorking
Conference on Mining Software Repositories (MSR 2014). 72–81.[61]MingWen,RongxinWu,andShing-ChiCheung.2016. Locus:locatingbugsfrom
softwarechanges.In Proceedingsofthe31stIEEE/ACMInternationalConference
on Automated Software Engineering, ASE 2016. 262–273.
[62]Ming Wen, Rongxin Wu, Yepang Liu, Yongqiang Tian, Xuan Xie, Shing-ChiCheung, and Zhendong Su. 2019. Exploring and exploiting the correlations
between bug-inducing and bug-fixing commits. In Proceedings of the ACM Joint
Meeting on European Software Engineering Conference and Symposium on the
Foundations of Software Engineering, ESEC/SIGSOFT FSE 2019. 326–337.
[63]XinXia,DavidLo,EmadShihab,XinyuWang,andXiaohuYang.2015. ELBlocker:
Predicting blocking bugs with ensemble imbalance learning. Information &
Software Technology 61 (2015), 93–106.
[64]XinXia,EmadShihab,YasutakaKamei,DavidLo,andXinyuWang.2016. Predict-ingCrashingReleasesofMobileApplications.In Proceedingsofthe10thACM/IEEE
International Symposium on Empirical Software Engineering and Measurement,
ESEM 2016. 29:1–29:10.
[65]XiaofeiXie,BihuanChen,LiangZou,YangLiu,WeiLe,andXiaohongLi.2019.
Automatic Loop Summarization via Path Dependency Analysis. IEEE Trans.
Software Eng. 45, 6 (2019), 537–557.
[66]KundiYao,GuilhermeB.dePádua,WeiyiShang,CatalinSporea,AndreiToma,
and Sarah Sajedi. 2020. Log4Perf: suggesting and updating logging locations for
web-based systems performance monitoring. Empirical Software Engineering 25,
1 (2020).
[67]KundiYao,GuilhermeB.dePádua,WeiyiShang,SteveSporea,AndreiToma,and
Sarah Sajedi. 2018. Log4Perf: Suggesting Logging Locations for Web-based Sys-
tems’PerformanceMonitoring.In Proceedingsofthe2018ACM/SPECInternational
Conference on Performance Engineering (ICPE ’18). 21–30.
[68]DingYuan, YuLuo, XinZhuang, GuilhermeRennaRodrigues, XuZhao, Yongle
Zhang,PranayU.Jain,andMichaelStumm.2014. SimpleTestingCanPrevent
MostCriticalFailures:AnAnalysisofProductionFailuresinDistributedData-
intensive Systems. In Proceedings of the 11th USENIX Conference on Operating
Systems Design and Implementation (OSDI’14). 249–265.
[69]Ding Yuan, Haohui Mai, Weiwei Xiong, Lin Tan, Yuanyuan Zhou, and Shankar
Pasupathy. 2010. SherLog: Error Diagnosis by Connecting Clues from Run-time
Logs. InProceedings of the 15th International Conference on Architectural Support
for Programming Languages and Operating Systems (ASPLOS). 143–154.
[70]DingYuan,SoyeonPark,andYuanyuanZhou.2012. Characterizingloggingprac-
tices in open-source software. In ICSE 2012: Proceedings of the 2012 International
ConferenceonSoftwareEngineering (Zurich,Switzerland).IEEEPress,Piscataway,
NJ, USA, 102–112.
[71]Ding Yuan,Jing Zheng, SoyeonPark, YuanyuanZhou, and StefanSavage. 2011.
Improving software diagnosability via log enhancement. In ASPLOS ’11: Proceed-
ings of the 16th international conference on Architectural support for programming
languages and operating systems. ACM, 3–14.
[72]YiZeng,JinfuChen,WeiyiiShang,andTse-Hsun(Peter)Chen.2019. Studying
thecharacteristicsofloggingpracticesinmobileapps:acasestudyonF-Droid.
Empirical Software Engineering (2019), 1–41.
[73]H. Zhang, S. Wang, T. Chen, and A. E. Hassan. 2019. Reading Answers on Stack
Overflow: Not Enough! IEEE Transactions on Software Engineering (2019).
[74]JianZhang,XuWang,HongyuZhang,HailongSun,KaixuanWang,andXudong
Liu.2019. Anovelneuralsourcecoderepresentationbasedonabstractsyntax
tree. InProceedings ofthe 41stInternational Conferenceon SoftwareEngineering,
ICSE 2019. 783–794.
[75]JianZhang,XuWang,HongyuZhang,HailongSun,KaixuanWang,andXudong
Liu.2019. Anovelneuralsourcecoderepresentationbasedonabstractsyntax
tree. InProceedings ofthe 41stInternational Conferenceon SoftwareEngineering,
ICSE 2019. 783–794.
[76]Tianyi Zhang, Cuiyun Gao, Lei Ma, Michael R. Lyu, and Miryung Kim. 2019. An
EmpiricalStudy ofCommon Challengesin DevelopingDeep LearningApplica-
tions.In30thIEEE InternationalSymposiumonSoftware ReliabilityEngineering,
ISSRE 2019. 104–115.
[77]ChenZhi,JianweiYin,ShuiguangDeng, MaoxinYe,MinFu,andTaoXie. 2019.
An Exploratory Study of Logging Configuration Practice in Java. In 2019 IEEE
International Conference on Software Maintenance and Evolution, ICSME 2019.
459–469.
[78]Jieming Zhu, Pinjia He, Qiang Fu, Hongyu Zhang, Michael R. Lyu, and Dongmei
Zhang.2015. LearningtoLog:HelpingDevelopersMakeInformedLoggingDeci-
sions. InProceedings of the 37th International Conference on Software Engineering
(ICSE ’15). 415–425.
372