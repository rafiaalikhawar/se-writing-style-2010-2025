Evaluating Representation Learning of Code Changes for
Predicting Patch Correctness in Program Repair
Haoye Tian
haoye.tian@uni.lu
University of Luxembourg
LuxembourgKui Liu∗
kui.liu@nuaa.edu.cn
Nanjing University of Aeronautics
and Astronautics
ChinaAbdoul Kader Kaboré
Anil Koyuncu
{abdoulkader.kabore,anil.koyuncu}@uni.lu
University of Luxembourg
Luxembourg
Li Li
li.li@monash.edu
Monash University
AustraliaJacques Klein
jacques.klein@uni.lu
University of Luxembourg
LuxembourgTegawendé F. Bissyandé
tegawende.bissyande@uni.lu
University of Luxembourg
Luxembourg
ABSTRACT
A large body of the literature of automated program repair de-
velops approaches where patches are generated to be validated
againstanoracle(e.g.,atestsuite).Becausesuchanoraclecanbe
imperfect, the generated patches, although validated by the oracle,
may actually be incorrect. While the state of the art explore re-
search directions that require dynamic information or that rely on
manually-crafted heuristics, we study the benefit of learning code
representations in order to learn deep features that may encode
the properties of patch correctness. Our empirical work mainly
investigates different representation learning approaches for code
changes to derive embeddings that are amenable to similarity com-
putations.Wereportonfindingsbasedonembeddingsproduced
by pre-trained and re-trained neural networks. Experimental re-
sultsdemonstratethepotentialofembeddingstoempowerlearning
algorithmsin reasoningabout patchcorrectness:a machinelearn-
ingpredictorwithBERTtransformer-basedembeddingsassociated
withlogisticregressionyieldedanAUCvalueofabout0.8inthe
predictionofpatchcorrectnessonadeduplicateddatasetof1000la-beledpatches.Ourinvestigationsshowthatlearnedrepresentations
canleadtoreasonableperformancewhencomparingagainstthe
state-of-the-art,PATCH-SIM,whichreliesondynamicinformation.
Theserepresentationsmayfurtherbecomplementarytofeatures
that were carefully (manually) engineered in the literature.
CCS CONCEPTS
•Software and its engineering →Software testing and de-
bugging.
∗Corresponding author.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ASE ’20, September 21–25, 2020, Virtual Event, Australia
© 2020 Association for Computing Machinery.
ACM ISBN 978-1-4503-6768-4/20/09...$15.00
https://doi.org/10.1145/3324884.3416532KEYWORDS
Program Repair, Patch Correctness, Distributed Representation
Learning, Machine learning, Embeddings
ACM Reference Format:
Haoye Tian, Kui Liu, Abdoul Kader Kaboré, Anil Koyuncu, Li Li, Jacques
Klein, and Tegawendé F. Bissyandé. 2020. Evaluating Representation Learn-
ingofCodeChangesforPredictingPatchCorrectnessinProgramRepair.In
35th IEEE/ACM International Conference on Automated Software Engineering
(ASE’20),September21–25,2020,VirtualEvent,Australia. ACM,NewYork,
NY, USA, 12pages.https://doi.org/10.1145/3324884.3416532
1 INTRODUCTION
Automation in software engineering has recently reached new
heights with the promising results recorded in the research di-
rection of automated program repair (APR) [ 27,42]. While a few
techniques try to model program semantics and synthesize execu-
tion constraints towards producing quality patches, they often fail
toscaletolargeprograms.Instead,thelargemajorityofresearch
contributions[ 43]exploresearch-basedapproacheswherepatch
candidates are generated and then validated against an oracle.
Intheabsenceofstrongprogramspecifications,testsuitesrepre-
sentaffordableapproximationsthatarewidelyusedastheoraclein
APR.Intheirseminalapproachtotest-basedAPR,Weimer etal.[55]
consideredthatapatchisacceptableassoonasitmakesthepro-
gram pass all test cases in the test suite. Since then, a number of
studies [46,49] have explored the overfitting problem in patch vali-
dation:agivenpatchissynthesizedtopassatestsuiteandyetis
incorrect with respect to the intended program specification. Since
limitedtestsuitesonlyweaklyapproximateprogramspecifications,
a patched program can indeed satisfy the requirements encoded in
thetestcases,andpresentabehavioroutsideofthoseteststhatare
significantlydifferentfromthebehaviorinitiallyexpectedbythe
developer.
Overfittingpatchesconstituteakeychallengeingenerate-and-
validate APR approaches. Recent evaluation campaigns [ 16,20,21,
32–35,48,52,56] on APR systems are stressing on the importance
of estimating the correctness ratio among the valid patches that
canbefound.Toimprovethisratio,researchersareinvestigating
several research directions. We categorize them in three main axes
that focus on actions before, during or after patch generation:
9812020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE)
•test-suite augmentation: Yanget al.[62] proposed to generate
better test cases toenhance the validation of patches, whileXin
and Reiss [58] opted for increasing test inputs.
•post-processingofgeneratedpatches: LongandRinard[ 37]studied
some heuristics to discard patches that are likely overfitting.
•curation of repair operators: approaches such as CapGen [ 56] suc-
cessfullydemonstratedthatcarefully-designed(e.g.,fine-grained
fixingredients)repairoperatorscanleadtomorecorrectpatches.
Ourworkisrelatedtothelatterthrust.Sofar,thestate-of-the-art
workstargetingtheidentificationofpatch correctnessaremainly
implemented based on computing the similarity of test case execu-
tiontraces[ 59].Yeetal.[63]followedupbypresentingpreliminary
resultssuggestingthatstatically-extractedcodefeaturesatthesyn-
taxlevelcouldbeusedtopredictoverfittingpatches.Whilesuch
an approach is appealing, the feature engineering effort can behuge when researchers target generalizable approaches. To cope
with this problem, Csuvik et al.[
8] have proposed a preliminary
small-scale study on the use of embeddings: leveraging pre-trained
naturallanguage sentenceembeddingmodels, theyclaimto have
been able to filter out 45% incorrect patches generated for 40 bugs
from the QuixBugs dataset [64].
Thispaper. Embeddingshavebeensuccessfullyappliedtovari-
ouspredictiontasksinsoftwareengineeringresearch[ 1,29,50,51].
For patch correctness prediction, the literature does not yet pro-
videextensiveexperimentalresultstoguidefutureresearch.Our
work fills this gap. We investigate in this paper the feasibility of
leveraging advances in deep representation learning to produce
embeddings that are amenable to reasoning about correctness.
We investigate different representation learning models adapted
tonaturallanguagetokensandsourcecodetokensthataremorespecializedtocodechanges.Ourstudyconsidersbothpre-trained
models and the retraining of models.
Weempiricallyinvestigatewhether,withlearnedrepresentations,
thehypothesisofminimalchangesincurredbycorrectpatches
remainsvalid:experimentsareperformedtocheckthestatistical
differencebetweensimilarityscoresyieldedbycorrectpatches
and those yielded by incorrect patches.
Werunexploratoryexperimentsassessingthepossibilitytoselectcutoffsimilarityscoresbetweenlearnedrepresentationsofbuggy
codeandpatchedcodefragmentsforheuristicallyfilteringout
incorrect patches.
Finally, we investigate the discriminative power of deep learned
features in a classification training pipeline aimed at learning to
predict patch correctness.
2 BACKGROUND
Our work deals with various concepts and techniques from thefields of program repair and machine learning. We present the
relevant details in this section to facilitate readers’ understanding
of our study design and the scope of our experiments.
2.1 Patch Plausibility and Correctness
Defining patch correctness is a non-trivial challenge in automated
program repair. Until the release of empirical investigations bySmithet al.[
49], actual correctness (w.r.t. program behavior in-
tended by developers) was seldom used as a performance criterionof patch generation systems. Instead, experimental results were
focusedonthenumberofpatchesthatmaketheprogrampassall
testcases.Suchpatchesareactuallyonly plausible .Qietal. [46]
demonstrated in their study that an overwhelming majority ofplausible patches generated by GenProg [
26], RSRepair [ 45] and
AE[54])areoverfittingthetestsuitewhileactuallybeingincorrect.
To improve the probability of program repair systems to generate
correctpatches,researchershavemainlyinvestedinstrengthening
thevalidationoracle(i.e.,thetestsuites).Opad[ 62],DiffTGen[ 58],
UnsatGuided[ 66],PATCH-SIM/TEST-SIM[ 59]generatenewtest
inputs thattrigger behavior cases which are not addressed byAPR-
generated patches.
Morerecentworks[ 8,63]arestartingtoinvestigatestaticfea-
tures and heuristics (or machine learning) to build predictive mod-els of patch correctness. Ye et al.[
63] presented the ODS approach
whichrelatestoourstudysinceitinvestigatedmachinelearning
with static features extracted from Java program patches. Their
approachhoweverbuildsoncarefullyhand-craftedfeatures,which
may not generalize to other programming languages or even to
varied datasets. The study of Csuvik et al.[8] is also closely re-
latedtoourssinceitexploresBERTembeddingstodefinesimilarity
thresholds.Theirworkhoweverremainspreliminary(itdoesnot
investigate the discriminative power of features) and has been per-
formedataverysmallscale(singlepre-trainedmodelon40one-line
bugs from simple programs).
2.2 Distributed Representation Learning
Learning distributed representations have been widely used to ad-
vance several machine learning tasks. In particular, in the field
of Natural Language Processing embedding techniques such as
Word2Vec [ 22],Doc2Vec [22] andBERT[9] have been success-
fullyappliedfordifferentsemantics-relatedtasks.Bybuildingon
the hypothesis of code naturalness [ 2,12], a number of software
engineering research works have also leveraged the aforemen-
tioned approaches for learning distributed representations of code.
Alonetal.[3]havethenproposed code2vec ,anembeddingtech-
nique that explores AST paths to take into account structural in-
formation in code. More recently, Hoang et al.[13] have proposed
CC2Vec, which further specializes to code changes.
Ourworkexploresdifferenttechniquesacrossthespectrumof
distributed representation learning. We therefore consider four
variantsfromtheseemingly-leastspecializedtocode(i.e.,Doc2Vec)
to the state of the art for code change representation (i.e., CC2Vec).
2.2.1Doc2Vec. Doc2Vec[ 22]isanunsupervisedframeworkmostly
used to learn continuous distributed vector representations of sen-
tences,paragraphs anddocuments,regardless oftheirlengths. It
worksontheintuition,inspiredbythemethodoflearningwordvec-
tors[41],thatthedocumentrepresentationshouldbegoodenough
to predict the words in the document Doc2Vec has been applied in
varioussoftwareengineeringtasks.Forexample,WeiandLi[ 53]
leveragedDoc2Vectoexploitdeeplexicalandsyntacticalfeatures
forsoftwarefunctionalclonedetection.Ndichu etal.[44]employed
Doc2Vec to learn code structure representation at AST level to
predict JavaScript-based attacks.
2.2.2BERT.BERT [9] is a language representation model that
has been introduced by an AI language team in Google. BERT is
982devotedtopre-traindeepbidirectionalrepresentationsfromunla-
belledtexts.Thenapre-trainedBERTmodelcanbefine-tunedto
accomplishvariousnaturallanguageprocessingtaskssuchasques-
tion answering or language inference. Zhou et al.[67] employed
aBERTpre-trainedmodeltoextractdeepsemanticfeaturesfrom
codenameinformationofprogramsinordertoperformcoderec-
ommendation.Yu etal.[65]evenleveragedBERTonbinarycode
to identify similar binaries.
2.2.3code2vec. code2vec [ 3] is an attention-based neural code
embeddingmodeldevelopedtorepresentcodefragmentsascon-
tinuous distributed vectors, by training on AST paths and code
tokens. Its embeddings have notably been used to predict the se-
manticpropertiesofcodefragments[ 3],inorder,forinstance,to
predict method names. In a recent work, however, Kang et al.[18]
reported an empirical study, which highlighted that the yielded to-
kencode2vecembeddingsmaynotgeneralizetoothercode-relatedtaskssuchascodecommentgeneration,codeauthorshipidentifica-tionorcodeclonedetection.code2v ecremains howeverthestateof
theartincodeembeddings:Compton etal.[7]recentlyleveraged
code2vectoembedJavaclassesandlearncodestructuresforthe
task of variable naming obfuscation.
2.2.4CC2Vec. CC2Vec[13]isaspecializedhierarchicalattention
neural network model which learns vector representations of code
changes(i.e.,patches)guidedbytheassociatedcommitmessages
(which is used as a semantic representation of the patch). As the
authorsdemonstratedintheirinlargeempiricalevaluation,CC2Vec
presentspromisingperformanceoncommitmessagegeneration,
bug fixing patch identification, and just-in-time defect prediction.
3 STUDY DESIGN
First,weoverviewtheresearchquestionsthatweinvestigate.Then
wepresentthedatasetsthatareleveragedtoanswertheseresearch
questions.Finally,wediscusstheactualtrainingof(oruseofpre-
trained) models for embedding the code changes.
3.1 Research Questions
RQ1:Do different representation learning models yield compara-
ble distributions of similarity values between buggy code and
patched code? A widespread hypothesis in program repair is
thatbugfixinggenerallyinduceminimalchanges[ 5,6,15,16,
31,33,34,40,55,56,60]. We propose to investigate whether
embeddings can be a reliable means for assessing the ex-tent of changes through computation of cosine similarity
between vector representations.
RQ2:To what extent similarity distributions can be generalized
for inferring a cutoff value to filter out incorrect patches? Fol-
lowing up onRQ1, We propose inthis research question to
experiment ranking patches based on cosine similarity of
theirvectorrepresentations,andrelyonnaively-definedsim-
ilaritythresholdsto decideonfilteringofincorrectpatches.
RQ3:Canwelearntopredictpatchcorrectnessbytrainingclassifiers
with code embeddings input? We investigate whether deep
learned features are indeed relevant for building machine
learning predictors for patch correctness.3.2 Datasets
We collect patch datasets by building on previous efforts in the
community. An initial dataset of correct patches is collected by
using five literature benchmarks, namely Bugs.jar [ 47], Bears [38],
Defects4J[ 17],QuixBugs [ 28]and ManySStuBs4J[ 19].These are
developerpatchesascommittedinopensourceprojectrepositories.
We also consider patches generated by APR tools integrated
intothe RepairThemAll framework.Weuseallpatchsamples
releasedbyDurieux etal.[10].Thisonlyincludessamplepatches
that make the programs pass all test cases. They are thus plausible.
However,novalidationinformationoncorrectnesswasgiven.In
this work, we proceed to manually validate the generated patches,
among which we identified 900 correct patches. The correctness
validation follows the criteria defined by Liu et al.[36].
Inarecentstudyontheefficiencyofprogramrepair,Liu etal.[36]
released a labeled dataset of patches generated by 16 APR systems
fortheDefects4Jbugs.Weconsiderthisdatasetaswellasthelabeled
dataset that was used to evaluate the PATCH-SIM [ 59] approach.
Overall,Table 1summarizesthedatasetsthatweusedforour
experiments. Each experiment in Section 4has specific require-
mentsonthedata(e.g.,largepatchsetsfortrainingmodels,labeled
datasets for benchmarking classifiers, etc.). For each experiment,
we will recall which sub-dataset has been leveraged and why.
Table 1: Datasets of Java patches used in our experiments.
Subjectscontains
incorrect
patchescontains
correct
patcheslabelled
dataset# Patches
Bears[38] No Yes - 251
Bugs.jar [47] No Yes - 1,158
Defects4J [17]†No Yes - 864
ManySStubBs4J [ 19]No Yes - 34,051
QuixBugs [28] No Yes - 40
RepairThemAll [10] Yes Yes No‡64,293
Liuet al.[36] Yes Yes Yes 1,245
Xionget al.[59] Yes Yes Yes 139
Total 102,041
†Thelatest version 2.0.0 of Defects4J is considered in this study.
‡The patches are not labeled in [ 10]. We support the labeling effort in this
studybycomparingthegeneratedpatchesagainstthedeveloperpatches.The2,918patchesforIntroclassJavain[
10]arealsoexcludedfromourstudysince
IntroClassJavaisalab-builtJavabenchmarktransformedfromtheCprogrambugsinsmallstudent-writtenprogrammingassignmentsfromIntroClass[
25].
3.3 Model input pre-processing
Samplesinourdatasetsarepatchessuchastheonepresentedin
Figure1extractedfromtheDefects4Jdataset.Ourinvestigations
with representation learning however require input data about the
buggy and patched code. A straightforward approach to derivethose inputs would be to consider the code files before and afterthe patch. Unfortunately, depending on the size of the code file,the differences could be too minimal to be captured by any simi-
larity measurement. To that end, we propose to focus on the code
fragmentthatappearsinthepatch.Thus,torepresentthebuggy
codefragment(cf.Figure 2),wekeepallremovedlines(i.e.,starting
with‘-’)aswellasthepatchcontextlines(i.e.,thosenotstarting
with either ‘-’, ‘+’ or ‘@’). Similarly, the patched code fragment (cf.
Figure3)isrepresentedbyaddedlines(i.e.,startingwith‘+’)aswell
983−−−source/org/jfree/chart/renderer/category/AbstractCategoryItemRenderer.java
+++ source/org/jfree/chart/renderer/category/AbstractCategoryItemRenderer.java
@@−1795,6 +1795,6 @@ public abstract class AbstractCategoryItemRenderer
int index = this.plot.getIndexOf(this);CategoryDataset dataset = this.plot.getDataset(index);
−if (dataset != null) {
+ if (dataset == null) {
return result;
}
Figure 1: Example of a patch for the Defects4J bug Chart-1.
1:a/source/org/jfree/chart/renderer/category/AbstractCategoryItemRenderer.java
2:intindex =this.plot.getIndexOf(this);
3:CategoryDataset dataset = this.plot.getDataset(index);
4:if (dataset != null) {
5: returnresult;
6:}
Figure 2: Buggy code fragment associated to patch in Fig. 1.
1:b/source/org/jfree/chart/renderer/category/AbstractCategoryItemRenderer.java
2:intindex =this.plot.getIndexOf(this);
3:CategoryDataset dataset = this.plot.getDataset(index);
4:if (dataset == null) {
5: returnresult;
6:}
Figure3:PatchedcodefragmentassociatedtopatchinFig. 1.
as the same context lines. Since tool support for the representation
learningtechniquesBERT,Doc2Vec,andCC2Vecrequireeachinput
sample to be on a single line, we flatten multi-line code fragments
into a single line.
IncontrasttoBERT,Doc2Vec,andCC2Vec,whichcantakeas
inputsomesyntax-incompletecodefragments,code2vecrequires
the fragment to be fully parsable in order to extract information
onAbstractSyntaxTreepaths.Sincepatchdatasetsincludeonly
text-based diffs, code context is generally truncated and is likely
notparsable.However,asjustexplained,weopttoconsideronly
theremoved/addedlinestobuildthebuggyandpatchedcodeinput
data.Bydoingso,wesubstantiallyimprovedthesuccessrateofthe
JavaExtractortoolusedtobuildthetokensinthecode2vecpipeline.
3.4 Embedding models
Whenrepresentationlearningalgorithmsareappliedtosometrain-
ing data, they produce embedding models that have learned to map
asetofcodetokensinthevocabularyofthetrainingdatatovectors
of numerical values. These vectors are also referred to as embed-
dings.Figure 4illustratestheprocessofembeddingbuggycodeand
patched code for the purpose of our experiments.
The embedding models used in this work are obtained from
different sources and training scenarios.
•BERT.In the first scenario, we consider an embedding model
thatinitiallytargetsnaturallanguagedata,bothintermsofthe
learning algorithm and in terms of training data. The network
structureofBERT,however,isdeep,meaningthatitrequireslarge
datasetsfor training theembeddingmodel. Asitisnow custom
intheliterature,weinsteadleverageapre-trained24-layerBERT
model, which was trained on a Wikipedia corpus.
•Doc2Vec. In the second scenario, we consider an embedding
model that is trained on code data but using a representation
learning technique that was developed for text data. To that end,
patchCode representation
buggy code
patched code
buggy code 
vector
patched code 
vectorBert, Doc2Vec or Code2Vec
embedding model
Preprocessing
Figure 4: Producing code fragment embeddings with BERT,
Doc2Vec and code2vec.
we have trained the Doc2Vec model with code data of 36,364
patches from the 5 repair benchmarks (cf. Table 1).
•code2vec. Inthethirdscenario,weconsideranembeddingmodel
that primarily targets code, both in terms of the learning algo-rithm and in terms of training data. We use in this case a pre-trained model of code2vec, which was trained by the authors
using ~14 million code examples from Java projects.
•CC2Vec. Finally,in thefourthscenario,weconsider anembed-
dingmodelthatwasbuiltinrepresentationlearningexperiments
for code changes. However, the pre-trained model that we lever-
agedfromtheworkofHoang etal.[13]isembeddingeachpatch
into a single vector. We investigate the layers and identify the
middleCNN-3Dlayerasthesweetspottoextractembeddings
for buggycode and patched codefragments. Figure 5illustrates
the process.
4 EXPERIMENTS
Wepresenttheexperimentsthatwedesignedtoanswertheresearch
questions of our study. For each experiment, we state the objective,
overview the execution details before presenting the results.
4.1 [Similarity Measurements for Buggy and
Patched Code using Embeddings]
Objective: We investigate the capability of different learned
embeddings to capture the similarity/dissimilarity between code
fragments.Theexperimentsareperformedtowardsprovidingan-
swers for two sub-questions:
RQ-1.1Is correct code actually similar to buggy code based on
learned embeddings?
RQ-1.2To what extent is buggy code more similar to correctly-
patched code than to incorrectly-patched code?
Experimental Design: We perform two distinct experiments
with available datasets to answer RQ-1.1 and RQ-1.2.
[Experiment ]Using the four embedding models considered in
ourstudy(cf.Section 3.4),weproducetheembeddingsforbuggy
Trained CC2vec model
patch3D CNN 
layer 
Lookup embeddingFully connected
layerOutput 
layer
buggy code 
vector
patched code 
vectorCC2Vec code representation
Figure 5: Extracting code fragment embeddings fromCC2Vec pre-trained model.
984and patched code fragments associated to 36k patches from five
repair benchmarks shown in Table 2. In this case, the patched code
fragmentrepresentscorrectcodesinceitcomesfromlabeledbench-
mark data (generally representing developer fix patches). Given
thoseembeddings(i.e.,coderepresentationvectors),wecompute
the cosine similarity between the vector representing the buggy
codefragment andthevectorrepresentingthepatchedcode frag-
ment.
Table2:Patchdatasetsusedforcomputingsimilarityscores
between buggy code fragments and correct code fragments.
Bears Bugs.jar Defects4J
ManySStuBs4JQuixBugsTotal
# Patches 251 1,158 864 34,051 40 36,364∗
∗Due to parsing failures, code2vec embeddings are available for 21,135 patches.
[Experiment ]To compare the similarity scores of correct code
fragmentvsincorrectcodefragmenttothebuggycode,weconsider
combiningdatasetswithcorrectpatchesanddatasetswithincorrectpatches.Notethat,allpatchesinourexperimentsareplausiblesince
we are focused on correctness: plausibility is straightforward to
decide based on test suites. Correct patches are provided in bench-
marks.However,incorrectpatchesassociatedtoallbenchmarkbugs
are not available. We rely on the dataset released by Liu et al.[36]:
674 plausible but incorrect patches generated by 16 repair tools for
184 Defects4Jbugs areconsidered from thisdataset. Those 674in-
correct patches are selected within a larger set of incorrect patches
by adding the constraint that the incorrect patch should be chang-
ing the samecode location as the developer-provided patch in the
benchmark: such incorrect patch cases may indeed be the most
challenging to identify with heuristics. We propose to compare the
similarityscoresbetweentheincorrectcodeandbuggycodeassoci-
ated to the dataset with the similarity scores between correct code
andbuggyassociatedtoallbenchmarks,allDefects4Jbenchmark
data, or only the subset of Defects4J that corresponds to the 184
patches for which relevant incorrect patches are available.
Results: Figure6presentstheboxplotsofthesimilaritydistribu-
tions with different embedding models and for samples in different
datasets. Doc2Vecand code2vecmodels appearto yieldsimilarity
values that are lower than BERT and CC2Vec models.
Model
BERT
CC2Vec
code2VecDoc2Vec    


                                          
 

                        
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
                                                                                                                                                                                                                                                                                                                                                                                                                                                     
                                       
              
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           
   

020406080100
Defects4J Bugs.jar Bears QuixBugs ManySSSimilarity (%)
Figure 6: Distributions of similarity scores between cor-
rect and buggy code fragments. “ManySS” stands for
“ManySStuBs4J”.
Figure7zooms in the boxplot region for each embedding model
experiment to overview the differences across different benchmark
   
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       
 
99100
D4J Bj Bears QB MSSSimilarity (%)
           
    
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  

99 99 99 99 99100 100 100 100 100 100
D4J Bj Bears QB MSSSimilarity (%)



                                                                                                                                                                                                                                                         

708090100
D4J Bj Bears QB MSSSimilarity (%)


                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   
    
406080100
D4J Bj Bears QB MSSSimilarity (%)(a) BERT. (b) CC2Vec.
(c) Doc2Vec. (d) code2vec.
Figure 7: Zoomed views of the distributions of similarity
scores between correct and buggy code fragments.
data.Weobversethat,whenembeddingthepatcheswithBERT,the
similaritydistributionforthepatchesinDefects4Jdatasetissimi-
lartoBugs.jarandBearsdataset,butisdifferentfromthedataset
ManySStBs4JandQuixBugs.TheMann-Whitney-Wilcoxon(MWW)
tests [39,57] confirm that the similarity of median scores for De-
fects4J, Bugs.jar and Bears is indeed statistically significant. MWW
testsfurtherconfirmsthestatisticalsignificanceofthedifference
between Defects4J and ManySStBs4J/QuixBugs scores.
Defects4J, Bugs.jar and Bears include diverse human-written
patches for a large spectrum of bugs from real-world open-source
Java projects. In contrast, ManySStuBs4J only contains patches for
single statement bugs. Quixbugs dataset is further limited by its
size and the factthat the patches are built by simply mutating the
code of small Java implementation of 40 algorithms (e.g., quicksort,
levenshtein, etc.).
While CC2Vec and Doc2Vec exhibit roughly similar patterns
withBERT(althoughatdifferentscales),theexperimentalresults
with code2vec present different patterns across datasets. Note that,
due to parsing failures of code2vec, we eventually considered only
118Bearspatches,123Bugs.jarpatches,46Defects4Jpatches,20,840
ManySStuBs4J patches and 8 QuixBugs. The change of dataset size
could explain the difference with the other embedding models.
RQ1.1 /trianglerightsldLearned representations of buggy and correct code
fragments exhibit high cosine similarity scores. Median scoresaresimilarforpatchesthatarecollectedwithsimilarheuristics
(e.g., in the wild patches vs single-line patches vs debugging ex-
ample patches). The pre-trained BERT natural language model
capturesmoresimilarityvariationsthantheCC2Vecmodel,which
is specialized for code changes./triangleleftsld
Inthesecondexperiment,wefurtherassesswhetherincorrectly-
patchedcodeexhibitsdifferentsimilarityscoredistributionsthan
985correctly-patched code.Figure 8shows thedistributions ofcosine
similarity scores for correct patches (i.e., similarity between buggy
codeandcorrectcodefragments)andincorrectpatches(i.e.,sim-
ilarity between buggy code and incorrect code fragments). The
comparison is done with different scenarios specified in Table 3.
Figure 8: Comparison of similarity score distributions for
code fragments in incorrect and correct patches.
Table 3: Scenarios for similarity distributions comparison.
Scenario Incorrect patches Correct patches
Imbalance d-al∗674incorrect patchesallcorrect patches from 5
benchmarks in Table 2.
Imbalance d-Defects4J by16 APR tools [36]allcorrect patches from
Defects4J.
Balanced-Defects4J for184 Defects4J bugsallcorrect patches for the 184
Defects4J bugs.
∗ExceptforDefects4J,therearenopublicly-releasedincorrectpatchesforAPRdatasets.
The comparisons do not include the case of embeddings for
code2vec. Indeed, unlike the previous experiment where code2vec
wasabletoparseenoughcodefragments,fortheconsidered184
correctpatchesofDefects4J,code2vecfailedtoparsemostofthe
relevantcodefragments.Hence,wefocusthecomparisononthe
other three embedding models (pre-trained BERT, trained Doc2Vec
and pre-trained CC2Vec). Overall, we observe that the distribution
of cosine similarity scores is substantially different for correct and
incorrect code.
Weobservethatthesimilaritydistributionsofbuggycodeand
patchedcodefromincorrectpatchesaresignificantlydifferentfromthesimilaritiesforcorrectpatches.Thedifferenceofmedianvalues
isconfirmedtobestatisticallysignificantbyanMWWtest.Note
that thedifferenceremains high for BERT, Doc2Vec andCC2Vec
whetherthecorrectcodeisthecounterpartoftheincorrectones
(i.e., the scenario of Balanced-Defects4J) or whether the correct
codeisfromalargerdataset(i.e.,Imbalanced-allandImbalanced-
Defects4J scenarios).
RQ1.2 /trianglerightsldLearnedrepresentationsofcodefragmentswithBERT,
CC2VecandDoc2Vecyieldsimilarityscoresthat,givenabuggy
code, substantially differ between correct code and incorrect code.
Thisresultsuggeststhatsimilarityscorecanbeleveragedtodis-
criminate correct patches from incorrect patches./triangleleftsld
4.2 [Filtering of Incorrect Patches based on
Similarity Thresholds]
Objective: Followinguponthefindingsrelatedtothefirstre-
searchquestion,weinvestigatetheselectionofcut-offsimilarityscores to decide on which APR-generated patches are likely incor-
rect.Resultsfromthisinvestigationwillprovideinsightstoguide
the exploitation of code embeddings in program repair pipelines.
Experimentaldesign: To select threshold values, we consider
thedistributionsofsimilarityscoresfromtheaboveexperiments
(cf.Section 4.1).Table 4summarizesrelevantstatisticsonthedis-
tributions on the similarity scores distribution for correct patches.
Given the differences that were exhibited with incorrect patches in
previousexperiments,weuse,forexample,the1stquartilevalue
as an inferred threshold value.
Table 4: Statistics on the distributions of similarity scores
for correct patches of Bears+Bugs.jar+Defects4J.
SubjectsMin.1st Qu. Median 3rd Qu. Max. Mean
BERT 90.8499.47 99.73 99.86 100 99.54
CC2Vec 99.3699.91 99.95 99.98 100 99.93
Doc2Vec 28.4985.80 92.60 96.10 99.89 89.19
code2vec 2.6481.19 93.63 98.87 100 87.11
Given our previous findings that different datasets exhibit dif-
ferent similarity score distributions, we also consider inferring a
specificthresholdfortheQuixBugsdataset(cf.statisticsinTable 5).
We do not compute any threshold based on ManySStuBs4J since it
has not yet been applied to program repair tools.
Table 5: Statistics on the distributions of similarity scores
for correct patches of QuixBugs.
SubjectsMin.1st Qu. Median 3rd Qu. Max. Mean
BERT 95.6399.69 99.89 99.95 99.97 99.66
CC2Vec 99.6099.94 99.99 100 100 99.95
Doc2Vec 55.5189.56 96.65 97.90 99.72 91.29
code2vec 81.1698. 53 100 100 100 97.06
Our test data is constituted of 64,293 patches generated by 11
APR tools in the empirical study of Durieux et al.[10]. First, we
usethefourembeddingmodelstogenerateembeddingsofbuggy
code and patched code fragments and compute cosine similarity
scores.Second,foreachbug,werankallgeneratedpatchesbased
on the similarity score between the patched code and the buggy,
where we consider that the higher the score, the more likely the
correctness. Finally, to filter incorrect candidates, we consider two
experiments:
(1)Patches that lead to similarity scores that are lower to the in-
ferredthreshold(i.e.,1stQuartileinpreviousexperimentaldata)
will be considered as incorrect. Patches where patched code ex-
hibit higher similarity scores than the threshold are considered
likely correct.
(2)Another approach is to consider only the top-1 patches with
the highest similarity scores ascorrect patches. Other patches
are considered incorrect.
In all cases, we systematically validate the correctness of all
64,293 patches to have the correctness labels, for which the dataset
authorsdidnot provide(allplausiblepatches havingbeenconsid-
ered as valid). First, if the file(s) modified by a patch are not the
same buggy files in the benchmark, we systematically consider
itasincorrect:withthissimplescheme,33489patchesarefound
incorrect. Second, with the same file, if the patch is not making
changesatthesamecodelocations,weconsiderittobeincorrect:
26386 patches are further tagged as incorrect with this decision
986Table 6: Filtering incorrect patches by generalizing thresholds inferred from Section 4.1.Results.
Dataset #CP # IP ThresholdBERT CC2Vec Doc2Vec
#+CP # -IP +Recall -Recall #+CP # -IP +Recall -Recall #+CP # -IP +Recall -Recall
Bears,Bugs.jar
and Defects4J89361,9321stQu. 5748,846 6.4% 78.9% 79719,499 89.2% 31.5% 79425,192 88.9% 40.7%
Mean 4951,783 5.5% 83.6% 78923,738 88.4% 38.3% 77133,218 86.3% 53.6%
QuixBugs 71,4611stQu. 41,387 57.1% 94.9% 41,198 57.1% 82.0% 71,226 100% 83.9%
Mean 41,378 57.1% 94.3% 41,255 57.1% 85.9% 71270 100% 86.9%
∗“#CP”and“#IP”standforthenumberofcorrectandincorrectpatches,respectively.“ #+CP”meansthenumberofcorrectpatchesthatcanberankeduponthethreshold,
while “#-IP” means the number of incorrect patches that can be filtered out by the threshold. “ +Recall” and “-Recall” represent the recall of identifying correct patches
and filtering out incorrect patches, respectively.
(cf.ThreatstovalidityinSection 5).Finally,fortheremaining4418
plausible patches in the dataset, we manually validate correctness
by following the strict criteria enumerated by Liu et al.[36]t o
enable reproducibility. Overall, we could label 900 correct patches.
The remainders are considered as incorrect.
Results: By considering the patch with the highest (top-1) simi-
larityscorebetweenthepatchedcodeandbuggycodeascorrect,
we were able to identify a correct patch for 10% (with BERT), 9%
(withCC2Vec)and10%(withDoc2Vec)ofthebugcases.Overallwe
also misclassified 96% correct patches as incorrect. However, only
1.5% of incorrect patches were misclassified as correct patches.
Giventhatagivenbugcanbefixedwithseveralcorrectpatches,
thetop-1criterionmaynotbeadequate.Furthermore,thiscriterion
makes the assumption that a correct patch indeed exists among
the patch candidates. By using filtering thresholds inferred from
previous experiments (which do not include the test dataset in this
experiment),wecanattempttofilterallincorrectpatchesgenerated
by APR tools. Filtering results presented in Table 6show the recall
scores that can be reached. We provide experimental results when
we use 1stQuartile and Mean values of similarity scores in the
“training”setasthresholdvalues.Thethresholdarealsoappliedby
takingintoaccountthedatasets:thresholdslearnedonQuixBugs
benchmark are applied to generated patches for QuixBugs bugs.
RQ2/trianglerightsldBuilding on cosine similarity scores, code fragment
embeddings can help to filter out between 31.5% with CC2Vec and
94.9% with BERT of incorrect patches. While BERT achieves the
highestrecalloffilteringincorrectpatches,itproducesembeddingsthatleadtoalowerrecall(at5.5%)atidentifyingcorrectpatches.
/triangleleftsld
4.3 [Classification of Correct Patches with
supervised learning]
Objective: Cosinesimilaritybetweenembeddings(whichwas
used in the previous experiments) considers every deep learned
feature as having the same weight as the others in the embedding
vector. We investigate the feasibility to infer, using machine learn-
ing, the weights that different features may present with respect
to patch correctness. We compare the prediction evaluation results
with the achievements of related approaches in the literature.
Experimentaldesign: Toperformourmachinelearningexper-
iments, we first require a ground-truth dataset. To that end, werely on labeled datasets in the literature. Since incorrect patches
generatedbyactualAPRtools are onlyavailablefortheDefects4J
bugs, we focus on labeled patches provided by two independent
teams(Liu etal.[36]andXiong etal.[59]).Veryfewpatchesgener-
atedbythedifferenttoolsareactuallylabeledascorrect,leading
toanimbalanceddataset.Toreducetheimbalanceissue,wesup-
plement the dataset with developer (correct) patches as supplied inthe Defects4J benchmark. Eventually, our dataset shown in Table 7
included 1000 patches after removing duplicates to avoid data bias.
Table7:DatasetforevaluatingML-basedpredictorsofpatch
correctness.
Correct patches Incorrect patches Total
Liuetal.[36] 137 502 639
Xiongetal.[59] 30 109 139
Defects4J (developers) [17] 356 0 356
Wholedataset 523 611 1134
FinalDataset (deduplicated) 468 532 1000
Ourgroundtruthdatasetpatchesarethenfedtoourembedding
modelstoproduceembeddingvectors.Asforpreviousexperiments,
the parsability of Defects4J patch code fragments prevented the
applicationofcode2vec:weusepre-trainedmodelsofBERT(trained
withnaturallanguagetext)andCC2Vec(trainedwithcodechanges)
as well as a retrained model of Doc2Vec (trained with patches).
Since the representation learning models are applied to code
fragments inferred from patches (and not to the patch themselves),
wecollecttheembeddingsofbothbuggycodefragmentandpatched
codefragmentforeachpatch.Thenwemustmergethesevectors
back into a single input vector for the classification algorithm. We
follow an approach that was demonstrated by Hoang et al. [ 13]i n
a recent work on bug fix patch prediction: the classification model
performsbestwhenfeaturesof patchedcodefragmentandbuggy
codefragmentarecrossedtogether.Wethusproposeaclassificationpipeline(cf.Figure 9)wherethefeatureextractionforagivenpatch
isdonebyapplyingsubtraction,multiplication,cosinesimilarityand euclidean similarity to capture crossed features between the
buggycodevectorandthepatchedcodevector.Theresultingpatchembeddinghas2*n+2dimensionswherenisthedimensionofinputcodefragmentembeddings.ThevaluesofthedimensionnforBERT,
Doc2Vec and CC2Vec are set as 1024, 64 and 64, respectively.
Feature extractor
Cc2vec
patches
buggy code
fragments
patched code
fragmentsp
PreprocessingInputcode representation learning method
Bert
Doc2vecnFeature crosses
nTrain & testClassifiers
Logistic regression
Decision tree
Naive BayesEb
Ep 2*n+2
istic regr sub
multicosine Euclidian
Figure 9: Feature engineering for correctness classification.
Results: We compare the performance of different predictors
(varyingtheembedingmodels)usingdifferentlearners(i.e.,classifi-
cationalgorithms).ResultspresentedinTable 8areaveragedfroma
5-foldcrossvalidationsetup.Allclassicalmetricsusedforassessing
987Figure 10: Performance of ML patch correctness predictor
using BERT/Logistic Regression: Test set from [59].
predictors are reproted: Accuracy, Precision, Recall, F1-Measure,
AreaUnderCurve(AUC).LogisticRegression(LR)appliedtoBERT
embeddingsyieldthebestperformancemeasurements:0.720forF1
and 0.808 for AUC.
Table8:EvaluationofBertrepresentationonthreeMLclas-
sifiers.
Classifier Embedding Acc. Prec. Recall. F1 AUC
DecisionTreeBERT 63.6 62.0 57.3 59.6 0.632
CC2Vec 69.0 66.9 68.0 67.2 0.690
Doc2Vec 60.2 57.4 57.7 57.5 0.600
Logistic regressionBERT 74.4 73.8 70.3 72.00.808
CC2Vec 73.9 72.5 72.0 72.0 0.788
Doc2Vec 66.3 65.3 59.9 62.3 0.707
Naive bayesBERT 60.3 55.6 77.0 64.5 0.642
CC2Vec 58.0 65.4 22.7 28.5 0.722
Doc2Vec 66.3 69.4 49.8 57.9 0.714
RQ3.1 /trianglerightsldAn ML classifier trained using Logistic Regression
withBERTembeddingsyieldverypromisingperformanceonpatch
correctness prediction (F-Measure at 72.0% and AUC at 80.8%). /triangleleftsld
[Comparisonagainstthestateoftheart].Therearetwo
relatedworksforpatchpredictionwhichwerebothevaluatedon
139 patches released by Xiong et al.[59]. PATCH-SIM [ 59] com-
pares execution traces of patched programs to identify correctness.
ODS [63] leverages manually-crafted features to build machine
learning classifiers.
Weconsiderthe139patchesastestsetandtheremainderinour
dataset (870 =1000−1301) for training. Note that the 139 patches
areassociatedtobugcaseswhererepairtoolscangeneratepatches.
These patches may thus be substantially different from the rest
in our dataset. Indeed our best learner (Logistic Regression with
BERTembeddings)yieldsanAUCof0.765.TheReceiverOperating
Characteristic (ROC) curve is presented in Figure 10.
InthevalidationofPATCH-SIM[ 59],theauthorsaimedforavoid-
ingtofilteroutanycorrectpatches.Eventually,whenguaranteeingthatnocorrectpatchisexcluded,theycouldstillexclude62(56.3%)
incorrect patches. If we constrain the threshold of our predictor to
avoid misclassifying any correct patch (threshold value = 0.219),
ourpredictorisabletoexcludeupto43(39.4%)incorrectpatches,
which represents a reasonably promising achievement since no
19patchesinthegroundtruthdatasetbyXiongetal.[ 59]wereduplicates(e.g.,
Patch151 ≡Patch23).Table 9: Comparison of incorrect patch identification be-
tween PATCH-SIM (uses dynamic information) and BERT+LR (uses embeddings statically inferred from patches).
Ground Truth PATCH-SIM BERT + LR
ProjectIncorrect Correct Incorrect Correct Incorrect Correct
excluded (%) excluded excluded (%) excluded
Chart 23 3 14(60.9%) 0 16(69.6%) 0
Lang 10 5 6(54.5%) 0 1(10%) 0
Math 63 20 33(52.4%) 0 23(36.5%) 0
Time 13 2 9(69.2%) 0 3(23.1%) 0
Total 109 30 62(56.3%) 0 43(39.4%) 0
Table 10: Confusion matrix of ML predictions based on
BERT embedddings with different thresholds.
Learners AUCThresholds
0.10.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
LR 0.765#TP30 30 24 19 16 12 10 6 4
#TN13 37 61 79 85 95 100 106 108
#FP96 72 48 30 24 14 9 3 1
#FN006 1 1 1 4 1 8 2 0 2 4 2 6
RF 0.751#TP30 30 29 26 20 12 4 2 0
#TN1 1 6 32 79 102 107 108 109
#FP108 108 103 77 30 7 2 1 0
#FN0 0 1 4 10 18 26 28 30
Table 11: Confusion matrix of ODS predictions with differ-
ent thresholds.
Learners AUCThresholds
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
LR 0.705#TP 27 27 27 27 27 27 27 27 27
#TN 50 50 50 50 50 51 51 52 52
#FP 60 60 60 60 60 59 59 58 58
# F N 222222222
RF 0.841#TP 29 29 29 29 29 29 25 23 14
#TN 20 33 36 43 51 60 68 81 101
#FP 90 77 74 67 59 50 42 29 13
# F N 000000461 5
dynamicinformationisused(incontrasttoPATCH-SIM).Table 9
overviews the prediction results comparison.
Wealsocomparethepredictivepowerofourmodelsagainstthat
of ODS [63], which builds on manually engineered features. We
directly compare against the results reported by the authors on the
139testpatches.Whilethepre-trainedBERTmodelassociatedwith
Logistic Regression(LR) achievesbetter AUCthan ODSLR-based
model(0.765vs0.705),ODSRandomForest-basedmodelachievesa
higher AUC at 0.841. Note however that ODS has been trained on
over 13 thousand patches (including patches for bugs associated to
thetestsetpatch),ourtrainingdatasetincludesonly870patches
(i.e.,∼1/20thof their dataset).
Tables10and11provide confusion matrices for different cut-off
thresholds of the classifiers for ODS and our BERT embeddings-
based classifiers: TP (true positives) represent correct patches that
were classified as such; TN (true negatives) represent incorrect
patchesthatwere classifiedassuch;FP(falsepositives)represent
incorrect patches that were classified as correct; and FN (false neg-
atives)representcorrectpatchesthatwereclassifiedasincorrect.
Overall,theBERT-basedpredictorisverysensitivetothecut-offthresholds while ODS is less sensitive. We also note that BERT
embeddings applied to Random Forrest does not yield good perfor-
mance: decision trees are indeed known to be good for categorical
data and request large datasets for training. In our case, the data
setis small,whileODS hasa trainingdatasetthat isabout 20times
988larger. The hand-crafted features of ODS may also help split the
patchesintocategorieswhileourdeeplearnedfeaturesarebased
on a large vocabulary of natural language text.
WeobserveneverthelessthatLRclassifiersfedwithBERTem-
beddingsareabletorecallhighnumbersofincorrectpatches(#TNis
highand#FPislowonthreshold>0.5).IncontrastODSconsistently
recallscorrectpatches(howeverwithhighfalsepositives).These
experimental results suggest that both approaches can be used in a
complementary way. In future work, we will propose an approach
thatcarefullymergesdeeplearnedfeaturestohand-craftedfeatures
towards yielded a better predictors of patch correctness.
RQ3.2 /trianglerightsldML predictors trained on learned representations ap-
peartoperformslightlylesswellthanstateoftheartPATCH-SIMapproachwhichreliesondynamicinformation.Ontheotherhand,
deepcoderepresentationsappeartobecomplementarytohand-
crafted features engineered for ODS. Overall, we recall that our
experimentalevaluationsareperformedinazero-shotscenario,
i.e.,withoutfine-tuningtheparametersofany ofthepre-trained
models.Furthermore,thetrainingdatasetoftheclassifiersisan
order of magnitude smallerathan the one used by most closely-
related work (i.e., ODS) and may further not be representative to
best fit the test set./triangleleftsld
aWe were not able to collect or reconstitute the training dataset used in ODS
to train our model.
5 DISCUSSIONS
We enumerate a few insights from our experiments with represen-
tation learning models and discuss some threats to validity.
5.1 Experimental insights
[Code-orientedembeddingmodelsmaynotyieldthebestembeddings
for training predictors. ] Our experiments have revealed that the
BERTmodelwhichwaspre-trainedonWikipediaisyieldingthe
best recall in the identification of incorrect patches. There are sev-
eralpossiblereasonstothat:Bertimplementsthedeepestneural
networkandbuildsonthelargesttrainingdata.Itsperformancesug-geststhatcode-orientedembeddingsshouldaimforbeingaccurate
withsmalltrainingdatasetsinordertobecomecompetitiveagainst
BERT.Whilewewerecompletingtheexperiments,apre-trainedCodeBERT [
11] model has been released (on April 27). In future
work,wewillinvestigateitsrelevanceforproducingembeddings
that may yield higher performance in patch correctness prediction.
In any case, we note that CC2Vec provided the best embeddingsfor yielding the best recall in identifying correct. patches (usingsimilarity thresholds). This suggests that future research should
investigate the value of merging different representations or com-
biningtheeventualpredictionprobabilitiestoimproveperformance
onbothidentifyingcorrectpatchesandexcludingmostincorrect
patches.
[Thesmallsizesofthecodefragmentsleadtosimilarembeddings.].
Figure11illustratesthedifferentcosinesimilarityscoresthatcan
be obtained for the BERT embeddings of different pairs of short
sentences.Althoughthesentencesaresemantically(dis)similar,thecosinesimilarityscoresarequiteclose.Thisexplainswhyrecallingcorrectpatchesbasedonasimilaritythresholdwasafailedattempt(∼5% for APR-generated patches for. Defects4J+Bears+Bugs.jar
bugs). Nevertheless, experimental results demonstrated that deep
learned features were relevant for learning to discriminate.
"our", "grandpa", "has", "a",
"very", "handsome", "look""computer", "science",
"is", "difficult""his", "spouse", "is",
"lovely"
0.919 0.914 0.869
Figure11:Closecosinesimilarityscoreswithsmall-sizedin-puts for BERT embedding model.
[Embeddings are most suitable when applied to simple ML algo-rithms.] Because embeddings are yielded from neural networks,
they areactually formed bycomplex crossed features.When they
arefedtoacomplexdiscriminantmodelsuchasRandomForrest,
it may lead to overfitting with small datasets. Our experiments
howevershowthatsimpleLogisticRegressionyieldsthebestAUC,
suggesting that this learner was able to better identifying discrimi-
nating features for the prediction task.
5.2 Threats to validity
Our empirical study carries a number of threats to validity that we
have tried to mitigate.
ThreatstoExternalValidity. Thereareavarietyofrepresenta-
tion learning models in the literature. A threat to validity of ourstudy is that we may have a selection bias by considering only
fourembeddingmodels.Wehavemitigatedthisthreatbyconsid-
eringrepresentativemodelsindifferentscenarios(pre-trainedvs
retrained, code change specific vs natural language oriented).
Another threat to validity is related to the use of Defects4J data
in evaluating the ML classifiers. This choice however was dictated
by the data available and the aim to compare against related work.
Finally,withrespecttotheexploredmodels,theattentionsys-
tem of CC2Vec requires some execution parameters to perform
well.Sincetherelevantcodewasnotavailable,weuseuseanon-
attention version instead, potentially making CC2Vec embeddings
be under-performing. We release the artifacts for future compar-
isons by the research community.
ThreatstoInternalValidity. Amajorthreattointernalvalidity
lies in the manual assessment heuristics that we applied to the
RepairThemAll-generateddataset.Wemayhavemisclassifiedsomepatchesduetomistakesorconservatism.Thisthreathoweverholds
for all APR work that relies on manual assessment. We mitigatethis threat by following clear and reproducible decision criteria,
andbyfurtherreleasingourlabelleddatasetsforthecommunityto
review2.
Threats to Construct Validity. For our experiment, the con-
sidered embedding models are not perfect and they may have
been under-trained for the prediction task that we envisioned. For
thisreason,theresultsthatwehavereportedarelikelyanunder-
estimationof thecapability ofrepresentationlearningmodels to
2see:https://github.com/SerVal-DTF/DL4PatchCorrectness
989capture discriminative features for the prediction of patch correct-
ness. Our future studies on representation learning will address
this threat by considering different re-training experiments.
6 RELATED WORK
Analyzing Patch Correctness: Toassesstheperformanceof
fixingbugsofrepairtoolsandapproaches,checkingthecorrectness
of patches is key, but not trivial. However, this task was largely ig-
noredorunconcernedinthecommunityuntiltheanalysisstudyof
patchcorrectnessconductedbyQi etal.[46].Thankstotheirsystem-
aticanalysisofthepatchesreportedbythreegenerate-and-validate
program repair systems (i.e., GenProg, RSRepair and AE), theyshownthattheoverwhelmingmajorityofthegeneratedpatches
arenotcorrectbutjustoverfitthetestinputsinthetestsuitesof
buggy programs. In another study, Smith et al.[49] uncover that
patches generated with lower coverage test suites overfit more.
Actually, these overfitting patches often simply break under-tested
functionalities, and some of them even make the “patched” pro-
gram worsethan theun-patched program. Sincethen, theoverfit-
ting issue has been widely studied in the literature. For example,Leet al.[
24] revisit the overfitting problem in semantics-based
APR systems. In [ 23], they further assess the reliability of authors
and automated annotations in assessing patch correctness. They
recommendtomakepubliclyavailabletothecommunitythepatch
correctness evaluations of the authors. Yang and Yang [ 61] explore
the difference between the runtime behavior of programs patched
with developer’s patches and those by APR-generated plausible
patches.TheyunveilthatthemajorityoftheAPR-generatedplausi-blepatchesleadstodifferentruntimebehaviorscomparedtocorrect
patches.
Predicting Patch Correctness: To predict the correctness of
patches, one of the first explored research directions relied on the
idea of augmenting test inputs, i.e., more tests need to be proposed.
Yanget al.[62] design a framework to detect overfitting patches.
This framework leverages fuzz strategies on existing test cases
inordertoautomaticallygeneratenewtestinputs.Inaddition,it
leveragesadditionaloracles(i.e.,memory-safetyoracles)toimprove
the validation of APR-generated patches. In a contemporary study,
Xin and Reiss [58] also explored to generate new test inputs, with
thesyntacticdifferencesbetweenthebuggycodeanditspatched
code, for validating the correctness of APR-generated patches. As
complemented by Xiong et al.[59], they proposed to assess the
patch correctness of APR systems by leveraging the automated
generation of new test cases and measuring behavior similarity of
the failing tests on buggy and patched programs.
Throughanempiricalinvestigation,Yu etal.[66]summarized
twocommonoverfittingissues:incompletefixingandregression
introduction.Toassistalleviatingtheoverfittingissueforsynthesis-
based APR systems, they further proposed UnsatGuided that
reliesonadditionalgeneratedtestcasestostrengthenpatchsynthe-
sis, and thus reduce the generation of incorrect overfitting patches.
Predictingpatchcorrectnesswiththankstoanaugmentedsetof
testcasesheavilyreliesonthequalityoftests.Inpractice,testswith
highcoveragemightbeunavailable[ 63].Inourpaper,wedonot
relyonanynewtestcasestoassesspatchcorrectness,butleveragerepresentation learning techniques to build representation vectors
for buggy and patched code of APR-generated patches.
TopredictoverfittingpatchesyieldedbyAPRtools,Ye etal.[63]
proposeODS,anoverfittingdetectionsystem.ODSfirststatically
extracts4,199codefeaturesattheASTlevelfromthebuggycode
andgeneratedpatchcodeofAPR-generatedpatches.Thosefeatures
are fed into three machine learning algorithms (logistic regression,
KNN, and random forest) to learn an ensemble probabilistic model
forclassifyingandrankingpotentiallyoverfittingpatches.Toevalu-atetheperformanceofODS,theauthorsconsidered19,253training
samples and 713 testing samples from the Durieux et al.empir-
ical study [ 10]. With these settings, ODS is capable of detecting
57% of overfitting patches. The ODS approach relates to our study
since both leverage machine learning and static features. However,
ODS only relies on manually identified features which may not
generalize to other programming languages or even other datasets.
Inarecentwork,Csuvik etal.[8]exploitthetextualandstruc-
turalsimilaritybetweenthebuggycodeandtheAPR-patchedcode
withtworepresentationlearningmodels(BERT[ 9]andDoc2Vec[ 22])
byconsideringthreepatchcoderepresentation(i.e.,sourcecode,abstract syntax tree and identifiers). Their results show that the
source code representation is likely to be more effective in correct
patch identification than the other two representations, and thesimilarity-based patch validation can filter out incorrect patches
forAPRtools.However,toassesstheperformanceoftheapproach,
only 64 patches from QuixBugs [ 64] have been considered (includ-
ing 14 in-the-lab bugs). This low number of considered patches
raisesquestions aboutthe generalization oftheapproach forfixing
bugsinthewild.Moreover,unlikeourstudy,newrepresentation
learning models (code2vec [ 3] and CC2Vec [ 13]) dedicated to code
representation have not been exploited.
RepresentationLearningforProgramRepairTasks: Inthe
literature, representation learning techniques have been widely ex-
plored to boost program repair tasks. Long and Rinard explored
the topic of learning correct code for patch generation [ 37]. Their
approach learns code transformation for three kinds of bugs from
their related human-written patches. After mining the most recent
100 bug-fixing commits from each of the 500 most popular Java
projects, Soto and Le Goues [ 50] have built a probabilistic model
to predict bug fixes for program repair. To identify stable Linuxpatches, Hoang et al.[
14] proposed a hierarchical deep learning-
based method with features extracted from both commit messages
and commit code. Liu et al.[30] and Bader et al.[4]p r o p o s e dt o
learn recurringfix patternsfrom human-written patchesand sug-gestfixes.Ourpaperisnotaimingatproposinganewautomated
patch generation approach. We indeed rather focus on assessingrepresentation learning techniques for predicting correctness of
patches generated by program repair tools.
7 CONCLUSION
In this paper, we investigated the feasibility of statically predicting
patch correctness by leveraging representation learning modelsand supervised learning algorithms. The objective is to provide
insightsfortheAPRresearchcommunitytowardsimprovingthe
quality of repaircandidates generated byAPR tools. To that end,
we, first investigated the use of different distributed representation
990learning to capture the similarity/dissimilarity between buggy and
patched code fragments. These experiments gave similarity scores
thatsubstantiallydifferforacrossembeddingmodelssuchasBERT,
Doc2Vec,code2vecandCC2Vec.Buildingontheseresultsandin
order to guide the exploitation of code embeddings in program
repair pipelines, we investigated in subsequent experiments the
selectionofcut-offsimilarityscorestodecidewhichAPR-generated
patchesarelikelyincorrect.Thisallowedustofilteroutbetween
31.5% and 94.9% incorrect patches based on brute cosine similarity
scores.Finally,weinvestigatedthediscriminativepowerofthedeep
learned features by training machine learning classifiers to predict
correctPatches.DecisionTree,LogisticRegressionandNaiveBayes
are tried withcode embeddings from BERT,Doc2Vec and CC2Vec.
LogisticRegressionwithBERTembeddingsyieldedverypromising
performanceonpatchcorrectnesspredictionwithmetricslikeF-
Measureat0.72%andAUCat0.8%onalabeleddeduplicateddataset
of 1000 patches. We further showed that the performance of these
models on static features is promising when comparing againstthe state of the art (PATCH-SIM [
59]), which uses dynamic exe-
cution traces. Experimental results suggests that the deep learned
featurescanbecomplementarytohand-craftedfeatures(suchas
those engineered by ODS [63]).
Availability. Allartifactsofthisstudyareavailableinthefollowing
public repository:
https://github.com/SerVal-DTF/DL4PatchCorrectness
ACKNOWLEDGEMENTS
ThisworkwasmainlysupportedbytheLuxembourgFindsNational
delaRecherche(FNR)underProjectCHARACTERIZEC17/IS/11693
861. This work was also partially supported by the Project 1015-
YAH20102,theNationalNaturalScienceFoundationofChina(Grant
No.61802180), the Natural Science Foundation of Jiangsu Province
(Grant No.BK20180421), the National Cryptography Development
Fund (Grant No.MMJJ20180105) and the Fundamental Research
Funds for the Central Universities (Grant No.NE2018106).
REFERENCES
[1]Miltiadis Allamanis, Earl T. Barr, Christian Bird, and Charles A. Sutton. 2014.
Learningnaturalcodingconventions.In Proceedingsofthe22ndACMSIGSOFT
International Symposium on Foundations of Software Engineering. ACM, 281–293.
https://doi.org/10.1145/2635868.2635883
[2]Miltiadis Allamanis, Earl T. Barr, Premkumar T. Devanbu, and Charles A. Sutton.
2018. A Survey of Machine Learning for Big Code and Naturalness. Comput.
Surveys51, 4 (2018), 81:1–81:37. https://doi.org/10.1145/3212695
[3]UriAlon,MeitalZilberstein,OmerLevy,andEranYahav.2019. code2vec:learning
distributed representations of code. Proceedings of the ACM on Programming
Languages 3, POPL (2019), 40:1–40:29. https://doi.org/10.1145/3290353
[4]JohannesBader,AndrewScott,MichaelPradel,andSatishChandra.2019. Getafix:
learning to fix bugs automatically. Proceedings of the ACM on Programming
Languages 3, OOPSLA (2019), 159:1–159:27. https://doi.org/10.1145/3360585
[5]EarlT.Barr,YuriyBrun,PremkumarT.Devanbu,MarkHarman,andFederica
Sarro. 2014. The plastic surgery hypothesis. In Proceedings of the 22nd ACM
SIGSOFT International Symposium on Foundations of Software Engineering. ACM,
306–317. https://doi.org/10.1145/2635868.2635898
[6]Junjie Chen, Alastair F. Donaldson, Andreas Zeller, and Hongyu Zhang. 2017.
TestingandVerificationofCompilers(DagstuhlSeminar17502). DagstuhlReports
7, 12 (2017), 50–65. https://doi.org/10.4230/DagRep.7.12.50
[7]RhysCompton,EibeFrank,PanosPatros,andAbigailKoay.2020.EmbeddingJava
Classes with code2vec: Improvements from Variable Obfuscation. In Proceedings
of the 17th Mining Software Repositories. ACM.
[8]ViktorCsuvik,DánielHorváth,FerencHorváth,andLászlóVidács.2020.Utilizing
SourceCodeEmbeddingstoIdentifyCorrectPatches.In Proceedingsofthe2nd
International Workshop on Intelligent Bug Fixing. IEEE, 18–25. https://doi.org/10.
1109/IBF50092.2020.9034714[9]JacobDevlin,Ming-WeiChang,KentonLee,andKristinaToutanova.2019. BERT:
Pre-trainingofDeepBidirectionalTransformersforLanguageUnderstanding.InProceedingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociation
for Computational Linguistics: Human Language Technologies. 4171–4186. https:
//doi.org/10.18653/v1/n19-1423
[10]Thomas Durieux, Fernanda Madeiral, Matias Martinez, and Rui Abreu. 2019.
EmpiricalReviewofJavaProgramRepairTools:ALarge-ScaleExperimenton
2,141 Bugs and 23,551 Repair Attempts. In Proceedings of the 27th ACM Joint
Meeting on European Software Engineering Conference and Symposium on theFoundations of Software Engineering. ACM, 302–313. https://doi.org/10.1145/
3338906.3338911
[11]Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, MingGong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, et al
.2020. CodeBERT:
APre-TrainedModelforProgrammingandNaturalLanguages. arXivpreprint
arXiv:2002.08155 (2020).https://arxiv.org/abs/2002.08155
[12]AbramHindle,EarlT.Barr,ZhendongSu,MarkGabel,andPremkumarT.De-
vanbu. 2012. On the naturalness of software. In Proceedings of the 34th Inter-
nationalConferenceonSoftwareEngineering.IEEE,837–847. https://doi.org/10.
1109/ICSE.2012.6227135
[13]Thong Hoang, Hong Jin Kang, Julia Lawall, and David Lo. 2020. CC2Vec: Dis-tributed Representations of Code Changes. In Proceedings of the 42nd Interna-
tional Conference on Software Engineering. ACM, 518–529. https://doi.org/10.
1145/3377811.3380361
[14]ThongHoang,JuliaLawall,YuanTian,RichardJayadiOentaryo,andDavidLo.
2019. PatchNet:HierarchicalDeepLearning-BasedStablePatchIdentificationfor
the Linux Kernel. CoRRabs/1911.03576 (2019). http://arxiv.org/abs/1911.03576
[15]Jiajun Jiang, Luyao Ren, Yingfei Xiong, and Lingming Zhang. 2019. Inferring
Program Transformations From Singular Examples via Big Code. In Proceedings
ofthe34thIEEE/ACMInternationalConferenceonAutomatedSoftwareEngineering.
IEEE, 255–266. https://doi.org/10.1109/ASE.2019.00033
[16]Jiajun Jiang, Yingfei Xiong, Hongyu Zhang, Qing Gao, and Xiangqun Chen.
2018. Shapingprogramrepairspacewithexistingpatchesandsimilarcode.In
Proceedingsofthe27thACMSIGSOFTInternationalSymposiumonSoftwareTesting
and Analysis. ACM, 298–309. https://doi.org/10.1145/3213846.3213871
[17]RenéJust,DarioushJalali,andMichaelDErnst.2014. Defects4J:Adatabaseof
existing faults to enable controlled testing studies for Java programs. In Proceed-
ings of the 23rd International Symposium on Software Testing and Analysis. ACM,
437–440. https://doi.org/10.1145/2610384.2628055
[18]Hong Jin Kang, Tegawendé F. Bissyandé, and David Lo. 2019. Assessing theGeneralizability of Code2vec Token Embeddings. In Proceedings of the 34th
IEEE/ACM International Conference on Automated Software Engineering . IEEE,
1–12.https://doi.org/10.1109/ASE.2019.00011
[19]Rafael-Michael Karampatsis and Charles A. Sutton. 2020. How Often Do Single-
Statement Bugs Occur? The ManySStuBs4J Dataset. In Proceedings of the 17th
Mining Software Repositories. IEEE. http://arxiv.org/abs/1905.13334
[20]AnilKoyuncu,KuiLiu,TegawendéF.Bissyandé,DongsunKim,JacquesKlein,
Martin Monperrus, and Yves Le Traon. 2020. FixMiner: Mining relevant fixpatterns for automated program repair. Empirical Software Engineering 25, 3
(2020), 1980–2024. https://doi.org/10.1007/s10664-019-09780-z
[21]Anil Koyuncu, Kui Liu, Tegawendé F. Bissyandé, Dongsun Kim, Martin Monper-
rus,JacquesKlein,andYvesLeTraon.2019. iFixR:BugReportdrivenProgram
Repair. In Proceedings of the 27the ACM Joint European Software Engineering
Conference and Symposium on the Foundations of Software Engineering. ACM,
314–325. https://doi.org/10.1145/3338906.3338935
[22]Quoc V. Le and Tomas Mikolov. 2014. Distributed Representations of Sentences
andDocuments.In Proceedingsofthe31stInternationalConferenceonMachine
Learning. JMLR.org, 1188–1196. http://proceedings.mlr.press/v32/le14.html
[23]Xuan-Bach D Le, Lingfeng Bao, David Lo, Xin Xia, Shanping Li, and Corina
Pasareanu.2019. Onreliabilityofpatchcorrectnessassessment.In Proceedingsof
the 41st International Conference on Software Engineering. IEEE, 524–535. https:
//doi.org/10.1109/ICSE.2019.00064
[24]XuanBachDLe,FerdianThung,DavidLo,andClaireLeGoues.2018. Overfitting
insemantics-basedautomatedprogramrepair. EmpiricalSoftwareEngineering
23, 5 (2018), 3007–3033. https://doi.org/10.1007/s10664-017-9577-2
[25]Claire Le Goues, Neal Holtschulte, Edward K Smith, Yuriy Brun, PremkumarDevanbu, Stephanie Forrest, and Westley Weimer. 2015. The ManyBugs and
IntroClassbenchmarksforautomatedrepairofCprograms. IEEETransactions
onSoftwareEngineering 41,12(2015),1236–1256. https://doi.org/10.1109/TSE.
2015.2454513
[26]ClaireLeGoues,ThanhVuNguyen,StephanieForrest,andWestleyWeimer.2012.
GenProg: A generic method for automatic software repair. IEEE Transactions on
Software Engineering 38, 1 (2012), 54–72. https://doi.org/10.1109/TSE.2011.104
[27]Claire Le Goues, Michael Pradel, and Abhik Roychoudhury. 2019. AutomatedProgramRepair. Commun.ACM 62,12(2019),56–65. https://doi.org/10.1145/
3318162
[28]Derrick Lin, James Koppel, Angela Chen, and Armando Solar-Lezama. 2017.
QuixBugs:Amulti-lingualprogram repairbenchmarksetbasedontheQuixey
991Challenge. In Proceedings Companion of the 2017 ACM SIGPLAN International
ConferenceonSystems,Programming,Languages,andApplications:Softwarefor
Humanity. ACM, 55–56. https://doi.org/10.1145/3135932.3135941
[29]KuiLiu,DongsunKim,TegawendéF.Bissyandé,Tae-youngKim,KisubKim,Anil
Koyuncu,SuntaeKim,andYvesLeTraon.2019. Learningtospotandrefactor
inconsistent method names. In Proceedings of the 41st International Conference on
Software Engineering. IEEE, 1–12. https://doi.org/10.1109/ICSE.2019.00019
[30]Kui Liu, Dongsun Kim, Tegawendé F Bissyandé, Shin Yoo, and Yves Le Traon.
2018. Mining fix patterns for findbugs violations. IEEE Transactions on Software
Engineering (2018).https://doi.org/10.1109/TSE.2018.2884955
[31]KuiLiu,DongsunKim,AnilKoyuncu,LiLi,TegawendéFBissyandé,andYves
Le Traon. 2018. A closer look at real-world patches. In Proceedings of the 34th
InternationalConference onSoftwareMaintenance andEvolution.IEEE, 275–286.
https://doi.org/10.1109/ICSME.2018.00037
[32]Kui Liu, Anil Koyuncu, Tegawendé F Bissyandé, Dongsun Kim, Jacques Klein,
andYvesLeTraon.2019. Youcannotfixwhatyoucannotfind!aninvestigationof
faultlocalizationbiasinbenchmarkingautomatedprogramrepairsystems.In Pro-
ceedings of the 12th IEEE International Conference on Software Testing, Verification
and Validation. IEEE, 102–113. https://doi.org/10.1109/ICST.2019.00020
[33]KuiLiu,AnilKoyuncu,DongsunKim,andTegawendéFBissyandé.2019.AVATAR:Fixingsemanticbugswithfixpatternsofstaticanalysisviolations.In Proceedings
of the 26th IEEE International Conference on Software Analysis, Evolution and
Reengineering. IEEE, 456–467. https://doi.org/10.1109/SANER.2019.8667970
[34]Kui Liu, Anil Koyuncu, Dongsun Kim, and Tegawendé F. Bissyandé. 2019. TBar:
Revisiting Template-based Automated Program Repair. In Proceedings of the 28th
ACM SIGSOFT International Symposium on Software Testing and Analysis. ACM,
31–42.https://doi.org/10.1145/3293882.3330577
[35] Kui Liu, Anil Koyuncu, Kisub Kim, Dongsun Kim, and Tegawendé F. Bissyandé.
2018. LSRepair:Livesearchoffixingredientsforautomatedprogramrepair.In
Proceedingsofthe25thAsia-PacificSoftwareEngineeringConferenceERATrack.
IEEE, 658–662. https://doi.org/10.1109/APSEC.2018.00085
[36]KuiLiu,ShangwenWang,AnilKoyuncu,KisubKim,TegawendéF.Bissyandé,
DongsunKim,PengWu,JacquesKlein,XiaoguangMao,andYvesLeTraon.2020.
On the Efficiency of Test Suite based Program Repair: A Systematic Assessment
of16AutomatedRepairSystemsforJavaPrograms.In Proceedingsofthe42nd
InternationalConferenceonSoftwareEngineering.ACM,625–627. https://doi.org/
10.1145/3377811.3380338
[37]Fan Long and Martin Rinard. 2016. Automatic patch generation by learning
correctcode.In Proceedingsofthe43rdAnnualACMSIGPLAN-SIGACTSymposium
on Principles of Programming Languages, Vol. 51. ACM, 298–312. https://doi.org/
10.1145/2837614.2837617
[38]Fernanda Madeiral, Simon Urli, Marcelo Maia, and Martin Monperrus. 2019.
BEARS: An Extensible Java Bug Benchmark for Automatic Program Repair Stud-
ies. InProceedings of the 26th International Conference on Software Analysis, Evo-
lutionandReengineering.IEEE,468–478. https://doi.org/10.1109/SANER.2019.
8667991
[39]Henry B Mann and Donald R. Whitney. 1947. On a Test of Whether One of
Two Random Variables Is Stochastically Larger than the Other. The Annals
of Mathematical Statistics 18, 1 (1947), 50–60. https://doi.org/10.1214/aoms/
1177730491
[40]MatiasMartinezandMartinMonperrus.2015. Miningsoftwarerepairmodelsfor
reasoning on the search space of automated program fixing. Empirical Software
Engineering 20, 1 (2015), 176–205. https://doi.org/10.1007/s10664-013-9282-8
[41]Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient
estimationofwordrepresentationsinvectorspace. arXivpreprintarXiv:1301.3781
(2013).
[42]MartinMonperrus.2018. Automaticsoftwarerepair:Abibliography. Comput.
Surveys51, 1 (2018), 17:1–17:24. https://doi.org/10.1145/3105906
[43]Martin Monperrus. 2018. The living review on automated program repair. In
HAL/archives-ouvertes. fr, Technical Report.
[44]SamuelNdichu,Sangwook Kim,SeiichiOzawa,Takeshi Misu,andKazuoMak-
ishima. 2019. A machine learning approach to detection of JavaScript-basedattacks using AST features and paragraph vectors. Applied Soft Computing 84
(2019).https://doi.org/10.1016/j.asoc.2019.105721
[45]Yuhua Qi, Xiaoguang Mao, Yan Lei, Ziying Dai, and Chengsong Wang. 2014.
The strength of random search on automated program repair. In Proceedings
of the 36th International Conference on Software Engineering. ACM, 254–265.
https://doi.org/10.1145/2568225.2568254
[46]Zichao Qi, Fan Long, Sara Achour, and Martin Rinard. 2015. An analysis ofpatch plausibility and correctness for generate-and-validate patch generation
systems.In Proceedingsofthe24thInternationalSymposiumonSoftwareTesting
and Analysis. ACM, 24–36. https://doi.org/10.1145/2771783.2771791
[47]Ripon Saha, Yingjun Lyu, WingLam, Hiroaki Yoshida, and Mukul Prasad. 2018.
Bugs.jar: A large-scale, diverse dataset of real-world java bugs. In Proceedings
ofthe15thIEEE/ACMInternationalConferenceonMiningSoftwareRepositories.
ACM, 10–13. https://doi.org/10.1145/3196398.3196473[48]Seemanta Saha, Ripon K Saha, and Mukul R Prasad. 2019. Harnessing evolution
formulti-hunkprogramrepair.In Proceedingsofthe41stInternationalConference
on Software Engineering. IEEE, 13–24. https://doi.org/10.1109/ICSE.2019.00020
[49]Edward K Smith, Earl T Barr, Claire Le Goues, and Yuriy Brun. 2015. Is the cure
worse than the disease? overfitting in automated program repair. In Proceedings
of the10th Joint Meetingon Foundationsof Software Engineering. ACM, 532–543.
https://doi.org/10.1145/2786805.2786825
[50]Mauricio Soto and Claire Le Goues. 2018. Using a probabilistic model to predict
bugfixes.In Proceedingsofthe25thInternationalConferenceonSoftwareAnalysis,
EvolutionandReengineering.IEEE,221–231. https://doi.org/10.1109/SANER.2018.
8330211
[51]Song Wang, Taiyue Liu, and Lin Tan. 2016. Automatically learning semantic
features for defect prediction. In Proceedings of the 38th International Conference
onSoftwareEngineering.ACM,297–308. https://doi.org/10.1145/2884781.2884804
[52]Shangwen Wang, Ming Wen, Bo Lin, Hongjun Wu, Yihao Qin, Deqing Zou,
XiaoguangMao,andHaiJin.2020. AutomatedPatchCorrectnessAssessment:
HowFarareWe?.In Proceedingsofthe35thIEEE/ACMInternationalConference
on Automated Software Engineering. ACM.
[53]HuihuiWeiandMingLi.2017. SupervisedDeepFeaturesforSoftwareFunctionalCloneDetectionbyExploitingLexicalandSyntacticalInformationinSourceCode.
InProceedingsofthe26thInternationalJoint ConferenceonArtificialIntelligence.
Morgan Kaufmann, 3034–3040. https://doi.org/10.24963/ijcai.2017/423
[54]WestleyWeimer,ZacharyPFry,andStephanieForrest.2013. Leveragingprogram
equivalence for adaptive program repair: Models and first results. In Proceedings
ofthe28thIEEE/ACMInternationalConferenceonAutomatedSoftwareEngineering.
IEEE, 356–366. https://doi.org/10.1109/ASE.2013.6693094
[55]WestleyWeimer,ThanhVuNguyen,ClaireLeGoues,andStephanieForrest.2009.
Automatically finding patches using genetic programming. In Proceedings of the
31st International Conference on Software Engineering. IEEE, 364–374. https:
//doi.org/10.1109/ICSE.2009.5070536
[56]Ming Wen, Junjie Chen, Rongxin Wu, Dan Hao, and Shing-Chi Cheung. 2018.Context-aware patch generation for better automated program repair. In Pro-
ceedings of the 40th International Conference on Software Engineering. ACM, 1–11.
https://doi.org/10.1145/3180155.3180233
[57]F. Wilcoxon. 1945. Individual Comparisons by Ranking Methods. Biometrics
Bulletin1, 6 (1945), 80–83.
[58]Qi Xin and Steven P Reiss. 2017. Identifying test-suite-overfitted patchesthrough test case generation. In Proceedings of the 26th ACM SIGSOFT Inter-
national Symposium on Software Testing and Analysis . ACM, 226–236. https:
//doi.org/10.1145/3092703.3092718
[59]Yingfei Xiong, Xinyuan Liu, Muhan Zeng, Lu Zhang, and Gang Huang. 2018.
Identifying patch correctness in test-based program repair. In Proceedings of the
40th International Conference on Software Engineering. ACM, 789–799. https:
//doi.org/10.1145/3183519.3183540
[60]Yingfei Xiong, Jie Wang, Runfa Yan, Jiachen Zhang, Shi Han, Gang Huang, and
LuZhang.2017. Preciseconditionsynthesisforprogramrepair.In Proceedings
of the 39th IEEE/ACM International Conference on Software Engineering. IEEE,
416–426. https://doi.org/10.1109/ICSE.2017.45
[61]Bo Yang and Jinqiu Yang. 2020. Exploring the Differences between Plausible and
Correct Patches at Fine-Grained Level. In Proceedings of the 2nd International
Workshop on Intelligent Bug Fixing. IEEE, 1–8. https://doi.org/10.1109/IBF50092.
2020.9034821
[62]Jinqiu Yang, Alexey Zhikhartsev, Yuefei Liu, and Lin Tan. 2017. Better test cases
for better automated program repair. In Proceedings of the 11th Joint Meeting on
Foundations of Software Engineering. ACM, 831–841. https://doi.org/10.1145/
3106237.3106274
[63]He Ye, Jian Gu, Matias Martinez, Thomas Durieux, and Martin Monperrus. 2019.
Automated Classification of Overfitting Patches with Statically Extracted Code
Features. CoRRabs/1910.12057 (2019). http://arxiv.org/abs/1910.12057
[64]He Ye, Matias Martinez, Thomas Durieux, and Martin Monperrus. 2019. A
ComprehensiveStudyofAutomaticProgramRepairontheQuixBugsBenchmark.
InProceedingsofthe1stInternationalWorkshoponIntelligentBugFixing.IEEE,
1–10.https://doi.org/10.1109/IBF.2019.8665475
[65]ZepingYu,RuiCao,QiyiTang,SenNie,JunzhouHuang,andShiWu.2020. OrderMatters:Semantic-AwareNeuralNetworksforBinaryCodeSimilarityDetection.
InProceedings of the AAAI Conference on Artificial Intelligence. AAAI, 1145–1152.
https://doi.org/10.1609/aaai.v34i01.5466
[66]ZhongxingYu,MatiasMartinez,BenjaminDanglot,ThomasDurieux,andMartin
Monperrus.2019. Alleviatingpatchoverfittingwithautomatictestgeneration:
a study of feasibility and effectiveness for the Nopol repair system. Empirical
Software Engineering 24, 1 (2019), 33–67. https://doi.org/10.1007/s10664-018-
9619-4
[67]Shufan Zhou, Beijun Shen, and Hao Zhong. 2019. Lancer: Your Code Tell Me
What You Need. In Proceedings of the 34th IEEE/ACM International Conference on
Automated Software Engineering. IEEE, 1202–1205. https://doi.org/10.1109/ASE.
2019.00137
992