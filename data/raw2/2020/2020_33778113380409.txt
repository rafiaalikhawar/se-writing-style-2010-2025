Gang of Eight : A Defect Taxonomy for Infrastructure as Code
Scripts
Akond Rahman
Tennessee Tech University
Tennessee, USA
arahman@tntech.eduEffat Farhana
NC State University
North Carolina, USA
efarhan@ncsu.eduChris Parnin
NC State University
North Carolina, USA
cjparnin@ncsu.eduLaurie Williams
NC State University
North Carolina, USA
lawilli3@ncsu.edu
ABSTRACT
Defects in infrastructure as code (IaC) scripts can have serious
consequences, for example, creating large-scale system outages. A
taxonomy of IaC defects can be useful for understanding the na-
ture of defects, and identifying activities needed to fix and prevent
defectsinIaCscripts. Thegoalofthispaperistohelppractitioners
improvethequalityofinfrastructureascode(IaC)scriptsbydevel-
oping a defect taxonomy for IaC scripts through qualitative analysis.
WedevelopataxonomyofIaCdefectsbyapplyingqualitativeanal-
ysis on 1,448 defect-related commits collected from open source
software(OSS)repositoriesoftheOpenstackorganization.Wecon-
duct a survey with 66 practitioners to assess if they agree with the
identified defect categories included in our taxonomy. We quantify
the frequency of identified defect categories by analyzing 80,425
commits collected from 291 OSS repositories spanning across 2005
to 2019.
Our defect taxonomy for IaC consists of eight categories, includ-
ing a category specific to IaC called idempotency (i.e., defects that
leadtoincorrectsystemprovisioningwhenthesameIaCscriptis
executedmultipletimes).Weobser ve the surveye d66practitioners
toagreemostwithidempotency.Themostfrequentdefectcategory
isconfigurationdatai.e.,providingerroneousconfigurationdata
inIaCscripts.Ourtaxonomyandthequantifiedfrequencyofthe
defectcategoriesmayhelpinadvancingthescienceofIaCscript
quality.
CCS CONCEPTS
•Software and its engineering →Software defect analysis;
KEYWORDS
bug, category, configurationas code, configurationscripts, defect,
devops, infrastructure as code, puppet, software quality, taxonomy
ACM Reference format:
Akond Rahman, Effat Farhana, Chris Parnin, and Laurie Williams. 2020.
Gang of Eight : A Defect Taxonomy for Infrastructure as Code Scripts. In
Proceedings of 42nd International Conference on Software Engineering, Seoul,
Republic of Korea, May 23–29, 2020 (ICSE ’20), 13 pages.
https://doi.org/10.1145/3377811.3380409
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ICSE ’20, May 23–29, 2020, Seoul, Republic of Korea
© 2020 Association for Computing Machinery.
ACM ISBN 978-1-4503-7121-6/20/05...$15.00
https://doi.org/10.1145/3377811.33804091 INTRODUCTION
Infrastructureascode(IaC)isthepracticeofautomaticallymain-
taining system configurations and provisioning deployment envi-
ronments using source code [ 26]. IaC scripts are also known as
configuration as code scripts [ 59], or configuration scripts [ 68]. In-
formationtechnology(IT)organizationsusetools,suchasChef1
and Puppet2to implement the practice ofIaC. The use of IaC has
yielded benefits for IT organizations, such as General Motors (GM)
andtheEuropeanOrganizationforNuclearResearch(CERN).Using
Chef, GM increased software deployment frequency by a factor of
21[20].CERNusesPuppettomanage15,000serversandtoprocess
2,000terabytesofdataeveryday[ 7].PuppethashelpedCERNto
minimize service disruptions and reduce deployment time [2].
Despite the above-mentioned benefits, defects with serious con-
sequencescanappearinIaCscripts.Forexample,adefectinanIaC
scriptcreatedanoutageresultinginbusinesslossesworthof150
million USD for Amazon Web Services [ 23]. Other example con-
sequences of defects in IaC scripts include outage for GitHub [19]
anddeletionofuserdirectoriesfor ∼270usersincloudinstances
maintained by Wikimedia Commons [12].
A defect taxonomy for IaC scripts can help practitioners un-
derstand thenature ofdefects, and identifypossible development
activities for defect mitigation. Figure 1 presents an example of
a security defect, which exposes users’ passwords in logs3. The
defect is mitigated by adding ‘secret =>true’, which prevents the
password getting exposed in logs3. Identification of certain defect
categories, such as security defects similar to Figure 1, can helppractitioners to make informed decisions on what development
activities could be adopted to improve the quality of IaC scripts.
The importance of defect categorization has been recognized
by the research community [ 6,39,83,86]. For example, Linraes-
Vásquez et al. [ 39] stated categorizing vulnerabilities can help An-
droiddevelopers“infocusingtheirverification&validation(V&V)
activities”.Accordingto Catolinoetal.[6],“understandingthebug
type represents the first and most time-consuming step to performin the process of bug triage, since it requires an in-depth analysis ”.
AdefecttaxonomyforIaC,anareathatremainsunexplored,can
help practitioners in understanding the nature of defects, and help
in improving IaC script quality through activities such as triaging
defects, prioritizing V&V efforts, and measuring IaC script quality.
We observe practitioners asking about defect categories for IaC
scriptsinonlineforumssuchasReddit:“IwanttoadoptPuppetinmyorganization.BeforeadoptionIwanttobeawareofthequalityissues
that may arise in Puppet scripts. Can someone give me some pointers
1https://www.chef.io/
2https://puppet.com/
3https://bugs.launchpad.net/puppet-ceilometer/+bug/1328448
7522020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE)
glance_cache_config{
‘DEFAULT/ auth_url ’ :value=>$auth_url;
‘DEFAULT/admin_tenant_name ’ : value=>$keystone_tenant;
‘DEFAULT/admin_user ’ :value=>$keystone_user;
-‘DEFAULT /admin_password ’:value =>$keystone_password ;
+’DEFAULT /admin_password ’:value =>$keystone_password ,secret =>true ;
}
Figure 1: Example of a security-related defect where a pass-
word is exposed in logs. The defect is mitigated by adding
‘secret= >true’.
on what type of bugs/defects appear for Puppet scripts? ”[16]. While
theforummembersofferedsuggestionsonpossiblecategoriesof
defects, e.g., syntax-related defects, these suggestions lack substan-
tiation. We hypothesize that through systematic empirical analysis
we can develop a taxonomy, and derive defect categories for IaC
using open source software (OSS) repositories.
Thegoalofthispaperistohelppractitionersimprovethequalityof
infrastructure as code (IaC) scripts by developing a defect taxonomy
for IaC scripts through qualitative analysis.
We answer the following research questions:
•[Categorization]RQ 1:Whatcategoriesofdefectsappearinin-
frastructure as code scripts?
•[Perception] RQ 2:How do practitioners perceive the identified
defect categories for infrastructure as code scripts?
•[Frequency] RQ 3:Howfrequentlydotheidentifieddefectcate-
gories appear in infrastructure as code scripts?
We derive a defect taxonomy for IaC by applying descriptive
coding[65]on1,448defect-relatedcommitmessagescollectedfrom
OSSrepositoriesmaintainedbytheOpenstackorganization[ 44].
Wesurvey66practitionerstoassesshowpractitionersperceivethe
identified defect categories. To automatically identify IaC defect
categories, we develop a tool called Automated Categorizer of
Infrastructure as code Defects (ACID), and apply ACID on 80,415
commits collected from 291 OSS repositories hosted by GitHub,
Mozilla [42], Openstack [45], and Wikimedia Commons [13].
We list our contributions as following:
•A taxonomy that includes eight defect categories for IaC scripts
(Section 3.2);
•An evaluation of how practitioners perceive the identified defect
categories (Section 3.3.2);
•An analysis of how frequently the identified defect categories
occur (Section 5.3.2); and
•A tool called ACID that automatically identifies instances of
defect categories from repositories with IaC scripts (Section 4).
We organize rest of the paper as following: we discuss back-
ground and related work in Section 2. We describe the defect cate-
goriesandsurveyresultsinSection3.Wedescribetheconstruction
and evaluation of ACID in Section 4. We describe our empirical
study in Section 5. We discuss our findings and limitations respec-
tively, in Sections 6 and 7. We conclude the paper in Section 8.
2 BACKGROUND AND RELATED WORK
Here, we provide necessary background and discuss related work.#An example Puppet script
include server
class sample($service_flag)
{
$service_ﬂag = true
if $service_ﬂag {
$path_var = '/var/www/html/'
}else {
$path_var = '/var/www/html/pages/'
}
service {‘apache2’:
ensure => running,
enable => true,path => $path_var
}
}Comment
Refer dependentclass ‘server’Variable‘service_ﬂag’
If-else block
Specifying ‘apache2’service
Attribute ’enable’of ‘apache2’service
Figure 2: Annotation of an example Puppet script.
2.1 Background
Puppetscriptsareanalyzedinourresearchstudy.Typicalentities
ofPuppetincludemanifests[ 36].Manifestsarewrittenasscripts
thatusea.ppextension.Inasinglemanifestscript,configuration
data can be specifiedusing variables and attributes. Programming
constructs, such as the ‘service’ resource, are also available to spec-
ifyservices.WeprovideasamplePuppetscriptwithannotationsin
Figure2.InFigure2,aservicewiththetitle‘apache2’isspecified.
Configurationdataarespecifiedusing‘ =>’and‘=’respectively,for
attributes and variables.
2.2 Related Work
Our paper is closely related to prior research on software defectcategories. Chillarege et al. [
9] proposed eight defect categories:
algorithm,assignment,build,checking,documentation,function,
interface,and timing.Categoriesproposed byChillaregeet al.[ 9]
wereusedbyCinqueetal.[ 10]tocategorizedefectsforairtraffic
control software. Wan et al. [ 80] investigated defects in blockchain
systems and observed that semantic defects are the most dominant
runtime defect categories. Linares-Vasquez et al. [ 39] provided a
taxonomy to categorize vulnerabilities for Android-based systems.
Zheng et al. [ 84] studied 579 defects collected from the Openstack
cloud management system, and observed that 66.1% of the studied
defectsinvolveincorrectoutput.Islametal.[ 30]studied2,716Stack
Overflow posts related to deep learning libraries and observed
configuration data to be the most frequent category.
Theabove-mentioneddiscussionshowsthatdefectcategoriza-
tionofspecializedsoftwaresuchasAndroidanddeeplearningpro-
videvaluetotheresearchcommunity.However,similarresearch
efforts are absent for IaC. Sharma et al. [ 68] and Bent et al. [ 78] in-
vestigated code maintainability aspects of Chef and Puppet scripts.
JiangandAdams[ 31]investigatedtheco-evolutionofIaCscripts
and other software artifacts, such as build files and source code.
RahmanandWilliamsinseparatestudiescharacterizeddefective
IaC scriptsusing text mining[ 60], andby identifying sourcecode
properties [ 61]. Hanappi et al. [ 21] proposed a model-based test
frameworktoautomaticallytestconvergenceofIaCscripts.Rah-
man et al. [ 58] identified 21,201 occurrences of security smells i.e.,
codingpatternsindicativeofsecurityweaknessesthatalsoincluded
1,326 occurrences of hard-coded passwords. The above-mentioned
753discussion highlights the lack of studies that investigate defect
categories for IaC and motivate us further to investigate defect
categories of IaC.
3 DEFECT TAXONOMY FOR
INFRASTRUCTURE AS CODE SCRIPTS
In this section, we answer RQ 1:What categories of defects ap-
pear in infrastructure as code scripts? . First, we describe our
methodology, then we present the identified defect categories.
3.1 Methodology to Develop Defect Taxonomy
Qualitative Analysis : We use descriptive coding [ 65] on 1,448
defect-relatedcommits. Defect-relatedcommits havecommit mes-
sages that indicate an action was taken related to a defect [ 60]. We
derivedefect-relatedcommitsbymanuallyinspecting7,808com-
mits that map to 1,386 Puppet scripts. While determining defect-
related commits a rater inspected if the commit message expressed
an action that was taken to remove or repair an error while devel-
oping an IaC script.
We collect the set of 7,808 commits from 61 OSS repositories
maintained by the Openstack organization [ 45], as Openstack pro-
vides cloud-based infrastructure services, and our assumption is
thatananalysisofcommitscollectedfromOpenstackcouldgive
us insights on defect categories. We use commits because commits
summarize changes that are made to a script and could identify
the types of changes that are being performed on a script. Descrip-
tive coding is a qualitative analysis technique that summarizes the
underlyingthemefromunstructuredtext[ 65].Weselectdescrip-
tive coding because we can obtain (i) a summarized overview of
thedefect categoriesthat occurforIaC scripts;and (ii)contexton
howtheidentifieddefectcategoriescanbeautomaticallyidentified.
WeusePuppetscriptstoconstructourdatasetbecausePuppetis
considered as one of the most popular tools for configuration man-
agement[ 31][67],andhasbeenusedbycompaniessince2005[ 40].
We extract commit message text from the 1,448 defect-related
commits, as well as any existing identifier to a bug report in the
commit message. We combine the commit message with any exist-
ingbugreportdescriptionandrefertothecombinationasenhanced
commitmessage(ECM).Ifnobugidentifierispresentinthecom-
mit message, then the commit message becomes the ECM. We use
ECMstoderivedefectcategoriesasfollowing:firstweidentifytextpatternsthatdescribeareasonand/orasymptomofadefect,where
defectisdefinedas—animperfectionthatneedstobereplacedor
repaired [ 28]. Figure 3 provides an example of our qualitative anal-
ysis process. We first analyze the ECM for each commit where an
IaC script is modified, and extract snippets that correspond to areasonorsymptomofadefect.Fromthesnippetprovidedinthe
bottomleftcorner,weextractrawtext:‘fixconfigoptions’.Next,
we generate the initial category e.g., we generate ‘fixing config. op-
tions’ from this raw text. Finally, we determine the defect category
‘Configuration Data’ by combining initialcategories. We combine
thesetwoinitialcategories,asbothcorrespondtoacommonpat-
tern of fixing configuration data defects. Multiple defect categories
can be identified in an ECM.
The first and second author, individually, conduct a descriptive
coding processon 1,448defect-related ECMs. Uponcompletion ofthis process, we record the agreements and disagreements for the
identified defect categories. The first and second author, respec-
tively, identified eight and ten categories. The Cohen’s Kappa [ 11]
is 0.8, which according to Landis and Koch [ 37] is ‘substantial
agreement’.Thesecondauthoridentifiedtwoadditionalcategories:
hard-codedvaluesandnetworksetting.Upondiscussion, thefirst
and second authors agreed that both hard-coded values and net-
work setting can be merged with the category ‘configuration data’,
as defects related to configuration data include both.
3.2 Answer to RQ 1: Defect Taxonomy for IaC
Ourdevelopedtaxonomyincludeseightdefectcategories.Weob-
serve one category, idempotency, to be unique to IaC, whereas,
the other defect categories have been observed for other software
systemsasreportedinpriorliterature[ 6,30,80,84].Wereporteach
defect category in an alphabetical order, with examples below:
Conditional : This category represents defects that occur due
toerroneouslogicand/orconditionalvaluesusedtoexecuteone
ormultiplebranchesofanIaCscript.Conditionallogicdefectsalso
appear for other types of software systems such as, machine learn-
ing [76], relational databases [ 15], [51], text editor software [ 15],
and deep learning software [30].
Example:Conditional logic defects can lead to erroneous status
output. For example, for a Wikimedia Commons project ‘cdh’ [ 82],
whencheckingthestatusofmysqladmin,aconditionallogicdefect
causedtheoutputtobe‘0(zero)’,bothinthecaseofsuccessand
failure of mysqladmin’s ‘ping’ command.
ConfigurationData :Thiscategoryrepresentsdefectsthathap-
penduetoerroneousconfigurationdatathatresideinIaCscripts.
An example configuration data defect downloaded from an OSS
repository [ 46]i s‘$config_dir=“/etc/$service_name”’, where wrong
configuration data is provided. The fix is ‘$config_dir=“/etc/hekad”’.
PractitionershavereportedconfigurationdatadefectsinIaCscriptstocausedeploymentproblemsfortheGoogleAppEngine[
52],and
inavailabilityofStackExchange[ 72],anonlinequestionandanswer
platform [ 71]. ‘Configuration data’ includes five sub-categories: (i)
data for storage system such as MySQL, MongoDB, and SQLite;
(ii)dataforfilesystemsuchasspecifyingfilepermissionsandfile
names;(iii)datafornetworksetupsuchasTCP/DHCPportsand
addresses, MAC addresses, and IP table rules; (iv) data for usercredentials such as usernames; and (v) data for caching systems
such as Memcached.
Priorresearchhasobservedconfigurationdatadefectstoappear
for machine learning software [ 76], build systems [ 83], blockchain
software[ 80],Eclipsesoftwareprojects[ 6],andMozillaprojects[ 6].
Example:Configurationdata-relateddefectscausedeployment
failures: in the case of Openstack Bug#15928424, value of an at-
tribute‘host_ip’wasnotsettothecorrectIPaddress,whichleadto
a deployment task to fail. Other example consequences of configu-
rationdatadefectsincludeprovisioningerrorsforobjectstorage
systems such as Openstack Swift5.
Dependency : This category represents defects that occur when
executionofanIaCscriptisdependentuponanartifact,whichis
either missing or incorrectly specified. The artifact can be a file,
4https://bugs.launchpad.net/fuel/+bug/1592842
5https://bugs.launchpad.net/tripleo/+bug/1532352
754Enhanced Commit Message Raw Text Initial Category Defect Category
ﬁx conﬁguring Cinder Multiback-
end; ﬁx conﬁguration of CinderMultibackend: set every backendto his own section.
ﬁx conﬁguration of listen ad-dresses Heat’s services
ﬁx conﬁg options deprecated inJunoﬁx conﬁguring
ﬁx conﬁguration of Cinder Multi-
backend
ﬁx conﬁguration of listen ad-dresses
ﬁx conﬁg optionsFixing conﬁguration
data
Fixing conﬁgurationoptions provided asconﬁguration dataConﬁguration
Data
Figure 3: An example to demonstrate the process of deriving IaC defect categories using descriptive coding.
class, package, Puppet manifest, or a module. Previously, practi-
tionershavereportedthatmanagingdependenciesinIaCscripts
leadstocomplexity,statingdependencymanagementasa‘night-
mare’[22],becauseincorrectlyspecifieddependenciescouldlead
to execution of IaC scripts in the wrong order. Dependency-related
defects have been reported for machine learning [ 76], and audio
processing software [15].
Example:Dependency defects cause deployment errors6.A c -
cording to the bug report6, a user faces an error when installing an
Openstack project called ‘Neutron’ [ 49], which provides network-
ing as a service in Debian and Ubuntu. The error occurred because
ofspecifyinganincorrectpackageasadependency.Dependency
defects can also cause installation errors [56].
Documentation : This category represents defects that occur
whenincorrectinformationaboutIaCscriptsarespecifiedinsource
code comments, in maintenancenotes, and in documentation files
suchasREADMEfiles.Documentation-relateddefectshavebeen
reported in prior studies: Chillarege et al. [ 9] identified documenta-
tionasoneoftheeightdefectcategoriesforODC.Storeyetal.[ 73]
and Tan et al. [ 75] have reported that erroneous information ex-
pressed in source comments can lead to defects in source code.
Example:Accordingtoabugreport7,theformatofspecifying
policies for the Openstack Nova project is incorrectly specified in
thecommentsofanIaCscript,whichcanleadtoPuppetruntime
errors.Otherexamplesofdocumentation-relateddefectsarepro-
viding incompatible license information in comments, and missing
licenseheaders[ 56],whichcanhavenegativeimplicationsonthe
distribution of software [79].
Idempotency : This category represents defects that violate the
idempotency property for IaC scripts. For IaC, idempotency is the
property whichensures thateven after nexecutions, where n>1,
theprovisionedsystem’senvironmentisexactlythesameasitwasafter thefirst executionof therelevant IaCscripts. We usea Reddit
post8to explain further. In the post, the user mentions that a new
string is appended every time the IaC script is executed. Such exe-
cution becomes problematic when the script is run multiple times,
because the desired behavior is that the new string will only be
6https://bugs.launchpad.net/puppet-neutron/+bug/1288741
7https://bugs.launchpad.net/puppet-nova/+bug/1409897
8https://www.reddit.com/r/Puppet/comments/679dze/addedonceatthefirstexecutionofthescript.Idempotency-related
defectshavenotbeenreportedinpriorresearchrelatedtodefect
categorization for non-IaC software. However, in IaC-related pub-
lications,researchershavereportedtheexistenceofidempotency
defects for Chef scripts [27] and for CFEngine scripts [4].
Example:Anidempotencydefectcausedunwantedchangesto
artifacts that should not be modified9. Idempotency-related de-
fects can cause file backup problems, package update problems,database setup problems, logging problems, and network setup
problems [56].
Security:Thiscategoryrepresentsdefectsthatviolateconfiden-
tiality,integrityoravailabilityfortheprovisionedsystem.Examplesecurity-relateddefectsincludeexposingsecretsinlogs;specifying
SSL certificates that lead to authentication problems; and hard-coding secrets, such as passwords [
56]. Prior research on defect
categorization has also observed security-related defects to appear
in other types of software systems e.g., in blockchain projects [ 80],
video game software [ 50], cloud management software [ 84], and
OSS Apache, Linux, and Mozilla projects [6] [74].
Example:SettingupuseraccountsiscommoninIaCscripts[ 60],
but in the process user confidentiality may be breached. For ex-
ample,thesecuritydefectfromSection1islistedinabugreport[ 85].
Thedefectleakspasswordsusingvariablessuchas rabbit_password
in Puppet logs. The defect impacts seven Openstack projects and isfixedbyaddingthe‘secret’attribute
10.Anotherexampleiskeeping
atokenaliveindefinitely,whichprovidesaccesstoanyonewithout
authentication and lasts indefinitely if not disabled11.
Service: This category represents defects related to improper
provisioning and inadequate availability of computing services,
suchasloadbalancingservicesandmonitoringservices.Service-
relateddefectscanbecausedbyimproperspecificationofattributes
whileusingthe‘service’resourceforPuppet[ 36],orChef[ 8],orthe
‘service’ module for Ansible [ 3]. Service-related defects have previ-
ouslyreportedforcloudmanagementsoftware[ 84].Rahmanand
Williams[ 60]reportedprovisioningofwebserviceanddatabase
services to appear in defective IaC scripts.
9https://bugs.launchpad.net/fuel/+bug/1572789
10https://review.opendev.org/#/c/106529/3/manifests/init.pp
11https://bugs.launchpad.net/fuel/+bug/1582893
755Example:Service related-defects can cause provisioned services
to stop unexpectedly, as it happened for a provisioned MySQL
service12. The defect occurred as the provisioned service was not
workingwithatitleprovidedasinput.Otherexamplesofservice-
related defects include not being able to start monitoring services,
such as Nagios, and load balancing services, such as HAProxy [ 56].
Syntax:ThiscategoryrepresentsdefectsrelatedtosyntaxinIaC
scripts. Syntax-defects have also been reported in prior research
studies: Ray et al. [ 63] and Pascarella et al. [ 50] in separate studies
identifiedgenericprogrammingdefectsforOSSGitHubprojects,
whichincludedprogrammingsyntaxerrors.Islametal.[ 30]also
identified syntax-related defects for deep learning projects.
Example:TheOpenstackFuelplugindevelopmentworkflow[ 47]
usesacontinuousintegrationpipeline,whichgenerateserrorsifIaC
scriptsfailstylechecks.Otherexamplesofsyntax-relateddefects
include specifying wrong types for variables [56].
Answer to RQ1 : Defect taxonomies can shape tool develop-
ment,testingandverificationefforts,andeducationaboutsoftware
development.AsdiscussedinSection2.2,thedomainofIaClacksadefecttaxonomy,andthustheabilitytoprioritizetooldevelopment,
testingandverificationefforts,anddisseminatesoftwaredevelop-
ment knowledge in the classroom could be limited. Answer to RQ1
contributes to the above-mentioned needs by providing (i) a defect
taxonomy, and (ii) a discussion related to consequences for each
defect category.
3.3 RQ 2: Practitioner Perception
WepresentthemethodologyandfindingsforRQ 2:Howdopracti-
tionersperceivetheidentifieddefectcategoriesforinfrastruc-ture as code scripts?
3.3.1 Methodology for RQ 2.Practitioner agreement with the
identifieddefectcategoriesinSection3.2canindicatetherelevance
of the eight categories. We answer RQ 2by deploying an online
survey to practitioners. In the survey, we ask practitioners howmany years they worked with IaC scripts. Then, we provide def-initions and examples for each category. We wanted to assess if
practitionersagreethatourcategoriesareinfactIaC-relateddefectcategories.Weasked“Wehaveidentifiedeightdefectcategoriesfor
IaC(Puppet)scripts.Eachofthesecategoriesarelistedbelow.To
which extent do you agree with our list?”. We construct the survey
following Kitchenham and Pfleeger’s guidelines [ 34]: (i) use Likert
scaletomeasureagreementlevels:stronglydisagree,disagree,neu-
tral,agree,andstronglyagree;(ii)addexplanationsrelatedtothe
purposeofthestudy,howtoconductthesurvey,preservationof
confidentiality,andanestimateofcompletiontime;and(iii)conductapilotsurveytogetinitialfeedback.Fromthefeedbackofthepilot
survey,weaddedanopen-endedtextboxsothatsurveyedpracti-
tioners can further respond. The survey questionnaire is available
and included in our verifiability package [57].
We offered a drawing of two 50 USD Amazon gift cards as an
incentive for participation following Smith et al. [ 69]’s recommen-
dations on incentivizing surveys. We deploy the survey to 750
12https://bugs.launchpad.net/fuel/+bug/155092912%
15%
9%
12%1%
14%
1%
12%79%
73%
73%
70%70%
68%
52%
50%9%
12%
18%
18%20%
18%
38%
38% ServiceDocumentationConditionalSyntaxSecurityDependencyConfig.DataIdempotency
0 2 55 07 5 1 00
Percentage
Response Strongly disagree Disagree Neutral Agree Strongly agree
Figure 4: Findings from survey. Practitioners mostly agree
with idempotency.
practitionersfromApril19,2019toAugust15,2019.Wedistributed
the survey to practitioners via e-mail following the Internal Re-
view Board (IRB) protocol#16813. We collect practitioner e-mail
addresses from the OSS repositories used in our empirical analysis.
3.3.2 Answer to RQ 2.Of the 750 practitioners, 66 responded.
We observethe eight categories to have relevanceamongst practi-
tioners:50% ∼79%ofthe66surveyrespondentsagreewithoneof
the eight categories. Respondents agree most with idempotency,
withanagreementrateof79%.Theleastagreeduponcategoryis
service.DetailsofoursurveyresultsislistedinFigure4,wherethe
defectcategoriesaresortedfromtoptobottombasedonagreementrate.Thepercentageofrespondentswhoagreedorstronglyagreed
with each category is listed on the right.
Weacknowledgethesurveyresponseratetobelow(8.8%).How-
ever, low survey response rates are not uncommon in software en-
gineering research: Smith et al. [ 69] reported software engineering
surveyresponseratetovaryfrom6%to36%.Fromemailresponses
we observe the following reasons for low response: inactive or
undeliverable email addresses of practitioners, practitioners ask-ing for full confirmation on receiving monetary incentives, and
practitioners not using Puppet in recent years.
Practitioners provide reasoning on why they agree, disagree, or
remainneutral.Forexample,onepractitionerconsideredsyntax-
relateddefectstobelessimportant,assyntax-relateddefectsshouldbefound“duringinitialtesting ”.Thepractitioneridentifiedidempo-
tencyandconditionaldefectsas“twokeyones ”.Anotherpractitioner
highlightedtheimportanceofidempotency,statingidempotency
defects “may not produce functional issues, but can cause product
indirectissues ”.Wenoticecontraryviewsrelatedtoidempotency
as well. One practitioner stated “I have never run into defects in
Puppet’sidempotencymechanisms ”,insteadthepractitionerclaimed
dependency-related defectsto beprevalent stating“Debugging de-
pendency loops is tricky and happens often ”. Another practitioner
indicated limitations of IaC tools as a possible explanation on why
dependencydefectscouldbefrequent“theproblem[is]withthese
[IaC] tools it is not clear how to do it [dependency management] ”.
For practitioners who provided neutral responses, the presence of
defects is more relevant than the category “I am more concerned
aboutthedefectitselfratherthanitscategory.IfIhavethatinfo,it
will be good, but it is not mandatory ”.
Practitioners also reported defect categories not included in our
taxonomy:‘learningcurve’,‘maintainability’,‘parallelism’,‘scala-
bility’,‘support’,and‘usability’.‘Parallelism’and‘scalability’are
756performance-related features of IaC tools. ‘Learning curve’, ‘main-
tainability’, ‘support’, and ‘usability’ are related to user experience
of IaC tools.
Answer to RQ2 : We observe our identified defect categories to
have relevance amongst practitioners. Surveyed practitioners have
varyingopinionsonwhatdefectcategoriesaremorefrequentinIaC
development, which are possibly formed by their own experiences.
Furthermore,practitionershavereportedwhatadditionalIaCdefect
categories may exist that is not included in our taxonomy.
4 AUTOMATED CATEGORIZER FOR
INFRASTRUCTURE AS CODE DEFECTS
Catgegorization of IaC defects using raters is resource-consuming.
In prior research, Huang et al. [ 25] emphasized the importance
of determining defect categories using an automated technique
stating the process of manual software defect categorization as
“at besta mundane, mind numbing activity ”. Anautomated tool to
detect IaC defect categories can be useful to (i) analyze reposito-ries with IaC scripts at scale, (ii) mitigate recall bias common in
incident reviews [ 14,17] e.g., practitioner bias in recalling defects
in IaC scripts13, and (iii) provide groundwork for future defect-
relatedtoolsforIaC.Researcherscanusesuchautomatedtoolto
automatically identify which script includes what defect category.
Weconstructanautomatedtoolcalled Automated Categorizer
forInfrastructureasCode Defects(ACID)toautomaticallyidentify
IaC defect categories at scale. ACID analyzes each ECM and deter-
mineswhetherornotanyofthe eight identifieddefectcategories
canbeidentifiedfromtheECM.ACIDtakesoneormultiplereposi-
toriesasinput,andasoutputreportsthedefectcategoryforeach
ECM.Ifnoneoftheeightcategoriesareidentified,ACIDreports
‘NODEFECT’,indicatingnodefectisidentified.ACIDcanreport
anECMtobelongtomultipledefectcategories.ACID’sdesignis
language-independent.ACIDusesrules,whichusesdependency
parsing [32] and pattern matching to detect defect categories with
ECMs.
We first describe how we construct the rules used by ACID
to detect defect categories. Next, we use a running example toillustrate the components of ACID, and how ACID determines a
defectcategory.Finally,weevaluatetheaccuracyofACIDbyusing
an oracle dataset.
Rules used by ACID : We construct rules needed for ACID by
abstracting patterns that appear in the 1,448 ECMs and their corre-
spondingdiffs,obtainedfromthe61OpenstackOSSrepositories.
Our hypothesis is that we can abstract patterns from the 1,448
ECMs and their corresponding diffs to automatically detect defect
categories for other datasets.
We use Table 1 to demonstrate our approach. The ‘ECM’ col-
umn presents a set of ECMs that include ‘fix’, a string pattern that
represents a defect-related action. The ‘Dependent’ column shows
the string patterns upon which the defect-related action is applied.
For example, for ‘fix catalog compilation when not configuring
13https://community.pagerduty.com/t/incidents-as-we-imagine-them-versus-how-
they-actually-are-with-john-allspaw/2708Table1:AnExampleofIdentifyingDependentsinECMsfor
Rule Construction
ECM Dependent
fixcatalog compilationwhennot configuringendpoint compilation
fix spurious warning in pipeline check warning
fix puppet lint 140 characters lint
typo fix typo
endpoint’,‘fix’is appliedupon‘compilation’.Wecanabstractpat-
ternsusing‘fix’andtokensinthe‘Dependent’columntoconstruct
a rule to identify a defect category. For example, in Table 1, the
keywords‘compilation’,‘warning’,‘lint’and,‘typo’islinkedwith
‘fix’.Thefirstauthorlookedintothesetof1,448ECMstodetermine
whatstringpatternsneedtobecapturedasdependentstoconstruct
rules.
Some ECMs such as ‘Varioussmall fixes’, which is downloaded
fromanOSSrepositorycalled‘fuel-plugin-contrail’14,indicatethat
a defect-related action occurred but do not clearly express whatdefectcategorycouldbeidentified.Weaddressthischallengeby
inspecting diffs of ECMs, in addition to dependency parsing. From
thediffsofECMswecanidentifycodeelementsandusethemin
rules for any of the eight categories. As an example, in Figure 5
we present the changeset for the ECM ‘Various small fixes’. We
observe that configuration data are changed using three variables
‘network_scheme’, ‘cidr’, and ‘netmask’.
An ECM can include a sentence that expresses defect-related
actions for multiple defect categories. For example, for ‘Fix depen-
denciesandvarioustypos’,whichisdownloadedfromanOSSrepos-itory[
48],weobserveactionstakentoresolvetwodefectcategories:
dependency defect and syntax defect. For ECMs with one or multi-
ple sentences,ACID maps an ECMto multiple defectcategories if
multiplerulesaresatisfied.TherulesACIDusestodetecteachoftheeightdefectcategoriesislistedinTable2.InTable2,the‘Category’
and ‘Rule’column respectively presents thedefect categories, and
correspondingrulestodetectthecategory.Thepresentedrulesusefunctions.Thefunctionsusestringpatternmatchingtocheckifsen-tencesand/ordiffsofanECMsatisfyacertaincondition.AmappingofthefunctionsandstemmedstringpatternsareprovidedinTable3.
Forexample,the hasDefect (x.sen)functionreturnstrueifanyof
the provided string patterns listed in Table 3, appear for a sentence
in an ECM x.sen. In Table 2, functions chanдedInclude (x.dif f),
chanдedComment (x.dif f), andchanдedService (x.dif f), identify
if the diff of ECM xconsists of changes in include statements, com-
ments, andservice resources, respectively. dataChanдed (x.dif f)
identifies if the diff includes a change in configuration data. Except
for function hasDefect (), string patterns for all other functions
are derived from our qualitative analysis process. We derive string
patternsfor hasDefect ()frompriorwork[ 63][62],listedinTable3.
Forfourcategories(conditional,idempotency,security,andsyntax)
ACID does not use diff content because our qualitative analysis
didnot identifyany Puppet-specific codeelement inthediffs that
express the defect category of interest.
Execution of ACID : We construct ECMs using Git, Mercurial,
andbugreportAPIs,andfeedtheECMsasinputtoACID.ACID
14https://opendev.org/x/fuel-plugin-contrail
757- $network_scheme = hiera(‘network_scheme’)
- $cidr = $settings[‘contrail_private_cidr’]- $netmask=cidr_to_netmask($cidr)- $netmask_short=netmask_to_cidr($netmask)+ $network_scheme = hiera_hash(‘network_scheme’,{})+ $cidr = pick(get_network_role_property(‘neutron/mesh’,‘cidr’),
/arrowhookleft→get_network_role_property(‘contrail/vhost0’,‘cidr’))
+ $netmask = pick(get_network_role_property(‘neutron/mesh’,‘
/arrowhookleft→netmask’),get_network_role_property(‘contrail/vhost0’,‘
/arrowhookleft→netmask’))
+ $netmask_short = netmask_to_cidr($netmask)
Figure 5: Diff of ECM ‘Various small fixes’. Configuration
dataarechangedinthediffindicatingtheECMtoberelated
with category ‘configuration data’.
Table 2: Rules to Detect Defect Categories
Category Rule
Conditional hasDefect (x.sen)∧hasCond (x.sen .dep)
Configuration
DatahasDefect (x.sen)∧((hasStorConf (x.sen .dep)
∨ hasFileConf (x.sen .dep)
∨ hasNetConf (x.sen .dep)∨
hasUserConf (x.sen .dep)∨
hasCachConf (x.sen .dep)) ∨
dataChanдed (x.diff))
Dependency hasDefect (x.sen)∧(hasDepe (x.sen .dep)∨
chanдedInclude (x.diff))
Documentation hasDefect (x.sen)∧ (hasDoc(x.sen .dep)∨
chanдedComment (x.diff))
Idempotency hasDefect (x.sen)∧hasIdem (x.sen .dep)
Security hasDefect (x.sen)∧hasSecu (x.sen .dep)
Service hasDefect (x.sen)∧ (hasServ (x.sen .dep)∨
chanдedService( x.diff))
Syntax hasDefect (x.sen)∧hasSynt (x.sen .dep)
Table 3: String Patterns Used for Functions in Rules
Function String Pattern
hasDefect ()‘error’, ‘bug’, ‘fix’, ‘issu’, ‘mistake’, ‘incorrect’, ‘fault’, ‘defect’,
‘flaw’
hasCond () ‘logic’, ‘condit’, ‘boolean’
hasStorConf ()‘sql’, ‘db’, ‘databas’
hasFileConf ()‘file’, ‘permiss’
hasNetConf ()‘network’, ‘ip’, ‘address’, ‘port’, ‘tcp’, ‘dhcp’
hasUserConf ()‘user’, ‘usernam’, ‘password’
hasCachConf ()‘cach’
hasDepe () ‘requir’, ‘depend’, ‘relat’, ‘order’, ‘sync’, ‘compat’, ‘ensur’, ‘in-
herit’
hasDoc() ‘doc’, ‘comment’, ‘spec’, ‘licens’, ‘copyright’, ‘notic’, ‘header’,
‘readm’
hasIdem () ‘idempot’
hasSecu () ‘vulner’, ‘ssl’, ‘secr’, ‘authent’, ‘password’, ‘secur’, ‘cve’
hasServ () ‘servic’, ‘server’
hasSynt () ‘compil’,‘lint’,‘warn’,‘typo’,‘spell’,‘indent’,‘regex’,‘variabl’,
‘whitespac’
uses four steps to identify a defect category: sentence tokenization,
text pre-processing, dependency parsing, and rule matching. Weuse Table 4 to describe how ACID processes an example ECM
“Update incorrect comment about nova-network status. The network
manifestcontainedacommentthatsaidthatnova-networkwasno
longer receiving any patches. That’s not actually the case; so replace
the comment with a new description that describes the current state ”,
which is downloaded from the ‘puppet-nova’ repository15. The
ECM also includes a change in comment, as shown in Figure 6.
15https://opendev.org/openstack/puppet-nova# [*enabled*]
# (optional) Whether the network service should be enabled.
-# Defaults tofalse
+# Defaults totrue
Figure6:DiffofECMusedasrunningexamplewheresource
code comments are changed.
Table 4: Example to Demonstrate ACID’s Execution
Step #1 Step #2 Step #3 Step #4
Update incorrect
comment aboutnova-network
statusupdat incorrectcomment aboutnova network
statuHEAD:[updat],
DEPE:[comment]Rule matchedfor documenta-tion defect as
per Table 2
The network man-ifest contained acomment that saidthat nova-network
was no longer
receiving any
patches.network man-ifest containcomment thatsaid that novanetwork was no
longerreceivani
patchHEAD:[contain],DEPE:[comment] No match
That’s not actuallythe case; so replacethe comment witha new descriptionthat describes the
current state.that not actualcase so replaccomment with
newdescriptthat
describ current
stateHEAD:[replac],
DEPE:[comment]No match
Step#1-Sentencetokenization :Weapplysentencetokenization[ 33]
oneachECMtosplitanECMintomultiplesentences.Inthecaseof
Table 4, the ECMincludes three sentences, and upon application of
Step #1, we obtain three individual sentences: (i) ‘Update incorrect
commentaboutnova-networkstatus’,(ii)‘Thenetworkmanifest
containedacommentthatsaidthatnova-networkwasnolonger
receiving any patches’, and (iii) ‘That’s not actually the case; soreplace the comment with a new description that describes the
current state’.
Step#2-Text Pre-processing : From each ECM, we remove English
stopwords,suchas‘a’,‘the’and‘by’.Next,weremovespecialchar-
actersandnumericliterals.Then,weapplyporterstemming[ 53]
oneachwordforeachECM.ACIDwillapplytextpre-processing
for each of the individual sentences for the ECM provided in Ta-
ble 4. The output of text pre-processing is provided in the ‘Step #2’
column.
Step#3-Dependencyparsing :Usingdependencyparsing[ 32]w e
identify heads and dependents for output obtained from Step#2.
Dependency parsing identifies a ‘head’, an action item, and ‘depen-
dents’ i.e. the words in the sentence which are dependent upontheactionitem.Forexample,inTable4weobservethekeyword
‘updat’ to be a head. The dependent for ‘updat’ is ‘comment’. To
identifydependentsandheads,weusetheSpacyAPI[ 70],which
leveragesdatasets,whereheadsanddependentsareannotatedby
human raters for the English language [ 32]. Using this annotation,
dependency parsing identifies what tokens in a sentence are heads
anddependents.Weusetheidentifiedheadsanddependentsinthe
next step. Output after Step #3 for our example ECM is listed in
‘Step #3’ of Table 4.
Step#4-RuleMatching :FromdependencyparsingoutputofStep#3,
weapplyrulematchingtodetermineadefectcategory.Therules
arelistedinTable2.IfasentenceforanECMsatisfiesanyofthe
rules,thecorrespondingdefectcategoryisassignedtothatECM.
For our running example, we observe the rule ‘ hasDefect (x.sen)
758Table 5: ACID’s Accuracy for Oracle Dataset
Category Occurr. Precision Recall
Conditional 6 0.75 1.00
Configuration Data 29 0.91 1.00
Dependency 3 0.75 1.00
Documentation 6 0.75 1.00
Idempotency 3 0.75 1.00
Security 1 1.00 1.00
Service 13 0.85 0.85
Syntax 6 0.86 1.00
No defect 65 0.96 0.82
Average 0.84 0.96
∧(hasDoc(x.sen.dep)∨chanдedComment (x.dif f))’issatisfiedas
(i) the ECM satisfies ‘ hasDefect (x.sen)’, as the keyword ‘incorrect’
appearsin‘updatincorrectcommentaboutnovanetworkstatu’,(ii)
the sentence ‘updat incorrect comment about nova network statu’
includesadependent‘comment’,whichsatisfies‘ hasDoc(x.sen.dep)’,
and(iii)asshowninFigure6,commentsarechangedinthedifffor
theECM,so‘ chanдedComments (x.dif f)’issatisfied.Fortheother
sentences no rules are matched (‘No match’ in column ‘Step#4’).
Therefore, the ECM belongs to ‘documentation’.
Evaluation of ACID : We use raters who are not authors of
the paper to construct an oracle dataset to evaluate ACID. To con-
struct the oracle dataset, raters perform closed coding [ 65], where
they map each assigned ECM to any of the categories identified
inSection3.2.Themappingtaskwasmadeavailableusingaweb-
site16. Each rater was provided the IEEE Standard Classification
for Software Anomalies [ 28] and a handbook on Puppet [ 36] for
reference.
We recruit raters from a graduate-level class of 60 students,
where 22 students volunteered to participate in constructing the
oracle dataset. The graduate class is focused on DevOps principles.
We used balanced incomplete block design [ 18] to select and dis-
tribute the132 ECMs amongst the22 raters, so thateach ECM is
reviewedbyatleasttworaters.Uponcompletionofthemapping
task,weobservetheagreementratetobe71.9%,andCohen’sKappatobe0.61,whichis‘substantialagreement’accordingtoLandisand
Koch [37]. The first author resolved disagreements.
Uponcompletionofconstructingtheoracledataset,weevaluate
ACID by computing the precision and recall of ACID for the oracle
dataset. Precision refers to the fraction of correctly-identified cate-
goriesamongthetotalidentifieddefectcategories,asdetermined
by ACID. Recall refers to the fraction of correctly-identified defect
categories that have been retrieved by ACID over the total amount
ofdefectcategories.Wereporttheprecisionandrecallvaluesfor
eachdefectcategoryinTable5.Weobservetheaverageprecision
and recall to be respectively 0.84 and 0.96 across all categories.
We notice that false negatives occur when the dependency pars-
ing technique incorrectly identify tokens in the ECM that have no
relationshiptoadefectcategoryoridentifiestokensthatarerelated
toanincorrectcategory.Forexample,fortheECM‘fixfollowing
warnings’, instead of ‘warnings’ dependency parsing incorrectly
identifies‘following’asthedependent.Weobservekeywordmatch-
ingtocontributetofalsepositives,forexampleACIDincorrectly
identifiestheECM‘Bug1085520-Supportinstance-storebacked
16http://13.59.115.46/joybangla/login.phpTable 6: OSS Repositories Satisfying Curation Criteria
GHB MOZ OST WIK
Initial Repo. Count 14,856,957 1,858 2,120 2,031
Criteria-1 (11% IaC Scripts) 6,088 2 67 11
Criteria-2 (Not a Clone) 4,040 2 61 11
Criteria-3 (Commits/Month ≥2) 2,710 2 61 10
Criteria-4 (Contributors ≥10) 218 2 61 10
Final Repo. Count 218 2 61 10
AMIs for builders. Add new secrets.’ as a security-related defect,
even though the ECM corresponds to adding a new feature.
Verifiability : All constructed datasets and ACID’s source code
are available online [ 57]. ACID is also available as a Docker image
for use17.
5 EMPIRICAL ANALYSIS
In this section, we provide the methodology and findings for theresearch question:
RQ3:How frequently do the identified defect
categories appear for infrastructure as code scripts?
Table 7: Attributes of the Four Datasets
Attribute GHB MOZ OST WIK
Repo. Type Git Mercurial Git Git
Tot. Repos 218 2 61 10
Tot. Commits 434,234 14,449 44,469 71,795
Tot. Puppet Scripts 10,025 1,596 2,845 3,143
Tot. Puppet-related Commits 40,286 6,836 12,227 21,066
Time Period 01/2005-
04/201905/2011-
04/201909/2011-
04/201901/2006-
04/2019
5.1 Datasets
We conduct our empirical analysis with four datasets of Puppet
scripts.WeconstructthreedatasetsfromtheOSSrepositoriesmain-
tained by three organizations: Mozilla [ 42], Openstack [ 45], and
Wikimedia Commons [ 13]. We select repositories from these three
organizationsbecausetheseorganizationscreateorusecloud-based
services. We construct the other dataset from OSS repositorieshosted on GitHub, as companies tend to host their popular OSS
projectsonGitHub[ 35][1].InourcollectedrepositoriesIaC-related
ECMs correspond to defects that have been previously reported by
respective practitioners.
Munaiahetal.[ 43]advocatedforcurationofOSSrepositories
before conducting empirical analysis. We apply the following crite-
riatocuratethecollectedrepositories: Criteria-1:Atleast11%of
the files belonging to the repository must be IaC scripts. Jiang and
Adams[31]reportedthatinOSSrepositoriesIaCscriptsco-exist
withothertypesoffiles,suchassourcecodefiles.Theyobserved
a median of 11% of the files to be IaC scripts. By using a cutoffof 11% we assume to collect repositories that contain sufficientamount of IaC scripts. Criteria-2 : The repository is not a copy of
another repository. Criteria-3 : The repository must have at least
two commits per month. Munaiah et al. [ 43] used the threshold of
at least two commits per month to determine which repositories
have enough software development activity. We use this threshold
tofilterrepositorieswithlimitedactivity. Criteria-4 :Therepository
hasatleast10contributors.Ourassumptionisthatthecriteriaof
17https://hub.docker.com/r/akondrahman/acid-puppet
759Table 8: Sanity Checking ACID’s Accuracy
Category Occurr. Precision Recall
Conditional 15 0.88 0.93
Configuration Data 99 0.90 0.96
Dependency 59 0.86 0.93
Documentation 32 0.91 0.94
Security 23 0.88 0.91
Service 54 0.85 0.93
Syntax 74 0.93 0.93
No defect 1644 0.99 0.98
Average 0.90 0.94
atleast10contributorsmayhelpustofilteroutirrelevantreposi-
tories. Previously, researchers haveused thecutoff of atleast nine
contributors[ 55][1]asacurationcriterion.AsshowninTable6,
291repositoriesmetourfilteringcriteria.Attributesofthecollected
repositories are available in Table 7.
5.2 Sanity Check for ACID
BeforeapplyingACIDforalldatasets,weapplyasanitycheckto
assess ACID’s detection performance for ECMs not included in the
oracledataset. Thefirst authorrandomlyselected 500ECMsfrom
each of the four datasets, and applied ACID on 2,000 ECMs. We
report the precision and recall in Table 8. We observe the recall for
alldefectcategoriesis >=0.91,whichindicatesACID’sabilityto
detect mostexisting defectcategories, butgenerate falsepositives.
5.3 RQ 3: Frequency of Defect Categories
Inthissection,weanswer How frequently do the identified de-
fect categories appear in infrastructure as code scripts?.
5.3.1 Methodology for Defect Category Frequency. Weanswer
RQ3byreporting‘defectproportion’and‘scriptproportion’values,
as well as, temporal frequency for each defect category. ‘Defect
Proportion’ refers to the percentage of commits in the dataset that
belong to a defect category, similar to Hindle et al. [ 24]. The defect
proportion metric provides a summarized view of defect category
frequency across the whole dataset, whereas, ‘script proportion’
refers to the proportion of scripts that are modified in commits
thatinclude atleastonecategory. Practitionerscanfind‘script pro-
portion’valuesuseful,asthemetricquantifieshowmanyscripts
include at least one defect category. ‘Defect/Year’ shows how each
category of defects evolve with time, and summarizes temporal
trends.WereportthetemporalfrequencyforeachyearusingEqua-
tion 1, where we calculate the metric ‘Defect/Year’ for a certain
category xthat occurs in year y.
Defect/Year( x,y)%=
# of ECMs in year yand marked as defect category x
total ECMs in year y∗100%
(1)
5.3.2 Answer to RQ 3: How frequently do the identified defect
categories appear in infrastructure as code scripts? We report defect
proportion and script proportion values for the eight categoriesin Table 9. Configuration data defects is the most frequently oc-
curringcategorybasedonthedefectproportionmetric.Network
is the most frequent subcategory: 75.3% ∼88.2% of the identifiedTable 9: Defect and Script Proportion for Defect Categories
Defect Prop. (%) Script Prop. (%)
Categ. GHB MOZ OST WIK GHB MOZ OST WIK
Cond. 0.3 0.04 0.3 0.1 1.9 0.3 1.8 1.4
Conf.Data 9.5 3.8 11.5 7.2 29.2 23.5 33.9 29.6
Depe. 1.8 1.3 2.4 1.7 10.6 12.4 16.3 17.1
Docu. 1.7 0.8 1.6 1.5 13.7 7.2 14.0 13.6
Idem. 0.1 0.01 0.3 0.01 1.0 1.6 3.5 0.1
Secu. 0.1 0.5 0.5 0.1 0.9 5.5 2.8 1.1
Serv. 1.4 2.6 1.8 3.0 4.9 23.1 9.3 12.4
Synt. 2.8 1.7 2.3 2.4 16.3 9.2 19.2 17.4
Total 16.6 10.9 18.7 15.2 43.6 47.4 48.6 49.2
configurationdatadefectsarenetworkdefects.Frequencyofsub-
categories for configuration data defects is available online [ 57].
We observe 23.5% ∼33.9% scripts to be modified in commits related
to configuration data, which is the highest across all defect cate-
gories. As reported in the ‘Total’ row in Table 9, we observe 16.6%,
10.9%, 18.7%, and 15.2% of all commits to include at least one of the
eightdefectcategories,respectively,forGitHub,Mozilla,Openstack,
and Wikimedia. Also, we observe 43.6%, 47.4%, 48.6%, and 49.2%of all scripts to include at least one defect category respectively,
forGitHub,Mozilla,Openstack,andWikimedia.Similartodefect
proportion, based on script proportion values, we observe configu-
rationdata-relateddefectstobethedominantcategoryacrossall
four datasets.
InFigure7,thex-axispresentsyears,andthe y-axispresents de-
fect/year valuesfor eachyear.From Figure7, over timewe observe
defectstobereportedacrossalldatasetsasindicatedby‘TOTAL’.
Forconfigurationdata-relateddefects,thedefect/yearvaluedoes
notreducetozero,indicatingconfigurationdatadefectstobere-
ported throughout the entire lifetime period for all four datasets.
Ourdefectcategoriescancorrelate.Correlatingcategoriesare
detectable:ifrulesformultiplecategoriesaresatisfiedthenACID
will report an ECM belonging to multiple categories. ECMs that
tested positive for two categories were 1.01%, 0.05%, 1.72%, and
0.82%,respectively,forGitHub,Mozilla,Openstack,andWikimedia.
ECMs that tested positive for three categories were 0.09%, 0.00%,
0.12%, and 0.04%, respectively, for GitHub, Mozilla, Openstack, and
Wikimedia.ForanyofthedatasetswedonotobserveECMsthat
tested positive for four or more defect categories.
AnswertoRQ3 :Configurationdataisthemostdominantdefect
category.Ouridentifieddefectcategoriescancorrelate,forexample,
ECMs that tested positive for two categories were 0.05% ∼8.01%
across four datasets.
6 DISCUSSION
We discuss our findings in this section.
PractitionerPerceptionandObservedEvidence :According
to Srikanth and Menzies [ 5], “documenting developer beliefs should
bethestart,nottheend,ofsoftwareengineeringresearch.Oncepreva-lentbeliefsarefound,theyshouldbecheckedagainstreal-worlddata ”,
suggestingresearcherstocomplementsurveydatawithsoftware
repository data. We too have complemented survey data with anal-
ysisofOSSdata.Wehavereportedvaryingpractitionerperceptions
for the identified categories in Section 3.3.2. We notice congruence
760●●
●●●●●●●●●●●●●●●●●●●●●●●●●●●●
●
●
●
●●●●
●●●●●●
●●
●
●
●
●●
●●●●●●●
●
●●
●●●●
●●●●●●●●●
●●
●●●●●●●●●●●●●●
●
●
●●
●●●●●●●●●●
●
●
●●
●●●●●●●●●●
●●●●●●●●●●●●●●● ●●●●●●●●●●●●●●● ●●●●●●●●●●●●●●● ●●●●●●●●●●●●●●● ●●
●●●●●●●●●●●●●●●●●●●●●●●●●●●●●
●●●●
●●
●●●●●●● ●●●●
●●●●●●●●●
●
●
●●●●
●●●
●
●●
●●
●
●●●●●
●●●
●
●●
●CONDITION CONF_DATA DEPEND DOCUMENT IDEMPOT SECURITY SERVICE SYNTAX TOTAL
2005200720102013201620182005200720102013201620182005200720102013201620182005200720102013201620182005200720102013201620182005200720102013201620182005200720102013201620182005200720102013201620182005200720102013201620180102030
YearDefect/Year(%)GITHUB
a
● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●●●●
● ● ●●●
●●●
● ● ●●●
●●
●
●● ●●●
●●
●
●● ●●●
●●●
● ●● ●●
●●●
● ●● ●●
● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●●
●●● ● ● ●●●
●●● ● ● ●●
●●●
● ●
● ●
●●●●
● ●
● ●
●●
●●
●●●●●●
●●
●●●●●●● ●
● ●
●
●●●● ●
● ●
●
●●CONDITION CONF_DATA DEPEND DOCUMENT IDEMPOT SECURITY SERVICE SYNTAX TOTAL
20112012201320142015201620172018201120122013201420152016201720182011201220132014201520162017201820112012201320142015201620172018201120122013201420152016201720182011201220132014201520162017201820112012201320142015201620172018201120122013201420152016201720182011201220132014201520162017201805101520
YearDefect/Year(%)MOZILLA
b
● ●● ● ● ● ● ● ● ● ●● ● ● ● ● ● ●●●●
●
●●●●
●●●●
●
●●●●
● ● ● ●●●
● ●● ●● ● ●●●
● ●● ●●●●● ● ● ●●
●●●●● ● ● ●●
●● ● ● ● ● ●● ● ● ● ● ● ● ● ●● ● ● ● ● ●● ● ● ●●
●● ● ●● ● ● ●●
●●●●●●
● ● ● ●
●●●●●
● ● ● ●
●●●
●●● ● ●
● ●●●
●●● ● ●
●●●●
●●
●
●●
●
●●●
●●
●
●●
●CONDITION CONF_DATA DEPEND DOCUMENT IDEMPOT SECURITY SERVICE SYNTAX TOTAL
2011201220132014201520162017201820192011201220132014201520162017201820192011201220132014201520162017201820192011201220132014201520162017201820192011201220132014201520162017201820192011201220132014201520162017201820192011201220132014201520162017201820192011201220132014201520162017201820192011201220132014201520162017201820190102030
YearDefect/Year(%)OPENSTACK
c
● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ●●●●●
●
●
●● ●●●●●
●
●
●
● ●●●●● ● ●
●
● ●●●●● ● ●
●
●● ●●●●●
● ●
●● ●●●●●
● ●
● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●●● ● ● ●●● ● ● ●● ● ● ●●● ● ●●● ●●●●●● ●
●● ●●●●●● ●
●
●●●●
●
●●
●●
●●●●
●
●●
●●
●●●●●
●
●
●
●
●●●●●
●
●
●CONDITION CONF_DATA DEPEND DOCUMENT IDEMPOT SECURITY SERVICE SYNTAX TOTAL
20112012201320142015201620172018201920112012201320142015201620172018201920112012201320142015201620172018201920112012201320142015201620172018201920112012201320142015201620172018201920112012201320142015201620172018201920112012201320142015201620172018201920112012201320142015201620172018201920112012201320142015201620172018201905101520
YearDefect/Year(%)WIKIMEDIA
d
Figure 7: Evolution of defect proportion for eight categories; GitHub: 7a, Mozilla: 7b, Openstack: 7c, and Wikimedia: 7d. For
each dataset, ‘Total’ presents the proportion of commits, which includes at least one category of defect.
for two categories: configuration data and dependency are the sec-
ond most agreed upon category and also frequently occurs in OSS
datasets. On the other hand, service defects are least agreed upon,
but they are more frequent than idempotency, the defect category
surveyed practitioners most agreed upon.
In the Reddit post [ 16] mentioned in Section 1, practitioners
reported only one defect category–syntax. Along with syntax, our
taxonomyincludessevenotherdefectcategories.Suggestionsfromonlineforumscouldbeinconclusive,andpractitionerscanfindour
taxonomy helpful.
Mitigation :Companiescanmitigatetheoccurrenceofdefects
by incorporating tools that target one or more of the identifiedcategories during IaC development. For example, companies can
adopt ‘rspec-puppet’ [ 64] to reduce conditional and service defects.
761Tools such as Tortoise [ 81], ‘librarian-puppet’ [ 38], and ‘puppet-
strings’ [29] might be helpful respectively, in mitigating configura-
tiondata,dependency,anddocumentationdefects.Staticanalysis
tools such as SLIC [ 58] and ‘puppet-lint’ [ 54] might respectively,
be helpful in mitigating security and syntax defects. Mitigation of
idempotency defects might be possible through early detection of
idempotency with Hummer et al. [ 27]’s approach that uses model-
based testing [77] to detect idempotency.
Implications :Ourpapercanbehelpfulinthefollowingmanner:
•betterunderstandingofdefects :useofdefinitionsandexamples
in Section 3.2 to understand the consequences of IaC defect cate-
gories, and activities needed to mitigate each defect category;
•triaging defects : using our taxonomy, practitioners can find what
IaC-relateddefectcategoriesarebeingreportedforalongperiod,
helping them make informed decisions on defect triaging;
•measuringIaCscriptquality :useourreportedfrequencyinTa-
ble 9 as a reference;
•saving manual effort : Zou et al. [ 86] identified three reasons why
practitioners find automated defect categorization important:
better resource allocation, saving manual work in classifying
defects, and facilitating postmortem analysis. For automated cat-
egorization of IaC defectsACID canbe helpfulfor practitioners.
Manual analysis of one ECM on average has taken 75 seconds
perrater,whereas,ACIDtakes0.09secondsona‘macOSMojave’
laptop with 1.4 GHz Intel Core i5 processor and 16 GB memory.
ACIDcouldbeusefulforteamsthatdon’thaveraterstoperform
postmortem analysis using qualitative coding; and
•constructing IaC-relatededucation materials : educatorswho con-
ductIaC-relatedcoursesattheundergraduateandgraduatelevel,
can use Section 3.2 to showcase what types of quality issues can
arise while developing IaC scripts.
FutureWork :Researcherscan investigateifabove-mentioned
recommendations can actually reduce defects in IaC scripts. The
coding patterns that ACID use, could be further leveraged in inves-
tigating if defect categories for IaC, such as configuration data, can
be detected at compile time.
7 THREATS TO VALIDITY
We briefly describe the limitations of our paper in this section.
Conclusion Validity : The derived defect categories and the
oracledatasetaresusceptibletoraterbias.Inbothcases,wemitigate
rater bias by allocating multiple raters. Also, we use the content of
commitmessagestodeterminethedefectcategoriesforIaCscripts,
which is limiting as commit messages do not always express a
defect-related action. Practitioners may use other keywords that
we did not include. We mitigate this limitation by using a set of
defect-relatedkeywords,derivedfrompriorresearch,andshowntobeadequateindetectingdefect-relatedcommits[
63][62][41].Also,
ACID uses dependency parsing that relies on annotated datasets
mined from news articles [ 32], which can be limiting to capture
dependencies.
External Validity : We have not analyzed proprietary reposito-
ries,andourfindingsarelimitedtoOSSdatasetswithPuppetscripts.
WemitigatethislimitationbyminingOSSrepositoriesfromGitHub
and three organizations. We conduct our empirical study with one
IaCtoolcalledPuppet.Weacknowledgethatourfindingsmaybelimited to Puppet. However, evidence demonstrates our categories
toexistacrosslanguages:e.g.,idempotencyappearsforChef[ 27]
andCFEngine[ 4].Consideringfrequencyandcategory,Schwarzet
al.[66]foundconfiguration-relatedcodesmellstogeneralizeacross
multiplelanguages,whichsuggeststhatourfindingsrelatedtocon-
figuration data defects may generalize too. Furthermore, ACID’sdesign is language-independent. ACID uses dependency parsing
and pattern matching to detect defect categories.
InternalValidity :Thedefectcategorylistisnotcomprehensive,
as the derivation process is dependent on the collected commits
andraterjudgment.Wemitigatethislimitationwith1,448ECMs
and two raters to derive defect categories. We acknowledge the
limitations of the rules presented in Table 2, as the construction is
dependentupontheECMsanddiffsofthecollectedcommits,along
withthefirstauthor’sjudgment.Practitionerscanusecertainstring
patternstodescribeacategorythatwedidnotlist.Wemitigatethis
limitation by inspecting 1,448 ECMs and diffs to derive the used
string patterns.
8 CONCLUSION
DefectsinIaCscriptscanhaveseriousconsequences.Defectcatego-
rization can help practitioners to make informed decisions on how
to mitigate IaC defects. We applied qualitative analysis on 1,448
defect-related commits to identify defect categories for IaC scripts.
Wesurveyed66practitionerstoassessifpractitionersagreewith
theidentified defectcategories.Next, weconstructeda toolcalled
ACID and apply ACID on 80,415 commits from 291 repositories to
automatically identify defect categories in IaC scripts.
Ourderivedtaxonomyconsistsofeightdefectcategoriesthatin-
cluded idempotency, a category specific to IaC. Amongst 66 survey
respondents, 79% of the practitioners agreed with idempotency-
related defects,and 49% ∼79% ofthe practitionersagreed with one
of the identified defect categories. We observe configuration data-
related defects to be the most frequent defect category, whereas
idempotencyistheleastfrequentlyoccurringdefectcategory.Us-
ing our reported defect category frequency results, practitioners
can prioritize V&V efforts by fixing configuration data defects that
occur in 23.5%∼33.9% of IaC scripts.
Our research can be helpful for practitioners to improve IaC
scriptquality,astheycanuseACIDtoidentifydefectcategoriesau-tomatically,anduseourdefinitionsandexamplesofeachidentified
defect category to assess the importance of the identified defect
categories.OurtaxonomyofIaCdefectscanhelppractitionersin
understanding the nature of defects and guide them in triaging
defects, prioritizing V&V efforts, and measuring IaC script quality.
We hope our findings will facilitate further research in the domain
IaC script quality.
ACKNOWLEDGMENTS
We thank the anonymous practitioners for participating in our
survey. We thank the RealSearch group at NC State University and
theanonymousreviewersfortheirvaluablefeedback.Ourresearch
was partially funded by the NSA’s Science of Security Lablet at NC
State University.
762REFERENCES
[1]Amritanshu Agrawal, Akond Rahman, Rahul Krishna, Alexander Sobran, and
TimMenzies.2018. WeDon’tNeedAnotherHero?:TheImpactof"Heroes"on
Software Development. In Proceedings of the 40th International Conference on
SoftwareEngineering:SoftwareEngineeringinPractice (ICSE-SEIP’18).ACM,New
York, NY, USA, 245–253. https://doi.org/10.1145/3183519.3183549
[2]Marc Ambasna-Jones. 2018. Automation key to unravelling myster-
ies of the universe at CERN. https://www.computerweekly.com/feature/
Automation-key-to-unravelling-mysteries-of-the-universe-at-CERN. [Online;
accessed 17-August-2019].
[3]Ansible. 2019. Ansible Documentation. https://docs.ansible.com/. [Online;
accessed 19-August-2019].
[4]Mark Burgess. 2011. Testable System Administration. Commun. ACM 54, 3
(March 2011), 44–49. https://doi.org/10.1145/1897852.1897868
[5]Shrikanth N. C. and Tim Menzies. 2019. Assessing Developer Beliefs: A Re-plyto"Perceptions,Expectations,andChallengesinDefectPrediction". CoRR
abs/1904.05794 (2019). arXiv:1904.05794 http://arxiv.org/abs/1904.05794
[6]GemmaCatolino,FabioPalomba,AndyZaidman,andFilomenaFerrucci.2019.
Not all bugs are the same: Understanding, characterizing, and classifying bug
types.Journal of Systems and Software 152 (2019), 165 – 181. https://doi.org/10.
1016/j.jss.2019.03.002
[7]CERN. 2018. Key Facts and Figures CERN Data Centre. http:
//information-technology.web.cern.ch/sites/information-technology.web.
cern.ch/files/CERNDataCentre_KeyInformation_01June2018V1.pdf. [Online;
accessed 17-August-2019].
[8]Chef. 2019. Chef Docs. https://docs.chef.io/. [Online; accessed 19-August-2019].
[9]Ram Chillarege, Inderpal Bhandari, Jarir Chaar, Michael Halliday, Diane Moebus,
Bonnie Ray, and Man-Yuen Wong. 1992. Orthogonal defect classification-a
concept for in-process measurements. IEEE Transactions on Software Engineering
18, 11 (Nov 1992), 943–956. https://doi.org/10.1109/32.177364
[10]Marcelo Cinque, Dominico Cotroneo, Raffaele D. Corte, and Antonio Pecchia.2014. Assessing Direct Monitoring Techniques to Analyze Failures of Criti-cal Industrial Systems. In 2014 IEEE 25th International Symposium on Software
Reliability Engineering. 212–222. https://doi.org/10.1109/ISSRE.2014.30
[11]Jacob Cohen. 1960. A Coefficient of Agreement for Nominal Scales. Educational
and Psychological Measurement 20, 1 (1960), 37–46. https://doi.org/10.1177/
001316446002000104 arXiv:http://dx.doi.org/10.1177/001316446002000104
[12]Wikimedia Commons. 2017. Incident documentation/20170118-Labs. https:
//wikitech.wikimedia.org/wiki/Incident_documentation/20170118-Labs. [Online;
accessed 27-Jan-2019].
[13]WikimediaCommons.2019. Project:GerritWikimedia. https://gerrit.wikimedia.
org/r/#/admin/projects/
[14]Richard I Cook. 1998. How complex systems fail. Cognitive Technologies Labora-
tory, University of Chicago. Chicago IL (1998).
[15]Domenico Cotroneo, Roberto Pietrantuono, and Stefano Russo. 2013. Testing
TechniquesSelectionBasedonODCFaultTypesandSoftwareMetrics. J.Syst.
Softw.86, 6 (June 2013), 1613–1637. https://doi.org/10.1016/j.jss.2013.02.020
[16]Csebuetian. 2019. Defect Categories for Puppet Scripts. https://www.reddit.com/
r/Puppet/comments/becwq3/defect_categories_for_puppet_scripts/. [Online;
accessed 20-August-2019].
[17]Sidney W.A. Dekker. 2002. Reconstructing human contributionsto accidents:
thenewviewonerrorandperformance. Journalofsafetyresearch 33.3(2002),
371–85.
[18]Joseph L. Fleiss. 1981. Balanced Incomplete Block Designs forInter-Rater Reliability Studies. Applied Psychological Measurement
5, 1 (1981), 105–112. https://doi.org/10.1177/014662168100500115
arXiv:https://doi.org/10.1177/014662168100500115
[19]James Fryman. 2014. DNS Outage Post Mortem. https://github.blog/
2014-01-18-dns-outage-post-mortem/. [Online; accessed 20-August-2019].
[20]Jeanne Gu. 2019. GM Extract, Transform and Load Platform as a Ser-
vice. https://pages.chef.io/rs/255-VFB-268/images/Chef_GM_ETL_Platform_
as_a_Service.pdf. [Online; accessed 18-August-2019].
[21]Oliver Hanappi, Waldemar Hummer, and Schahram Dustdar. 2016. Asserting
Reliable Convergence forConfigurationManagement Scripts. SIGPLAN Not. 51,
10 (Oct. 2016), 328–343. https://doi.org/10.1145/3022671.2984000
[22]Russel Harrison. 2013. How to Avoid Puppet Depen-dency Nightmares With Defines. https://blog.openshift.com/how-to-avoid-puppet-dependency-nightmares-with-defines/. [Online;
accessed 22-Jul-2019].
[23]Rebecca Hersher. 2017. Incident documentation/20170118-Labs.https://www.npr.org/sections/thetwo-way/2017/03/03/518322734/
amazon-and-the-150-million-typo. [Online; accessed 27-Jan-2019].
[24]Abram Hindle, Daniel M. German, and Ric Holt. 2008. What Do Large Commits
Tell Us?: A Taxonomical Study of Large Commits. In Proceedings of the 2008
InternationalWorkingConferenceonMiningSoftwareRepositories(MSR’08).ACM,
New York, NY, USA, 99–108. https://doi.org/10.1145/1370750.1370773
[25]Liguo Huang,Vincent Ng,Isaac Persing,Mingrui Chen,Zeheng Li,Ruili Geng,
and Jeff Tian. 2015. AutoODC: Automated Generation of Orthogonal DefectClassifications. Automated Software Engg. 22, 1 (March 2015), 3–46. https:
//doi.org/10.1007/s10515-014-0155-1
[26]JezHumbleandDavidFarley.2010. ContinuousDelivery:ReliableSoftwareRe-
leases Through Build, Test, and Deployment Automation (1st ed.). Addison-Wesley
Professional.
[27]WaldemarHummer,FlorianRosenberg,FábioOliveira,andTamarEilam.2013.
TestingIdempotenceforInfrastructureasCode.In Middleware2013,DavidEyers
and Karsten Schwan (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg, 368–
388.
[28]IEEE. 2010. IEEE Standard Classification for Software Anomalies. IEEE Std 1044-
2009(RevisionofIEEEStd1044-1993) (Jan2010),1–23. https://doi.org/10.1109/
IEEESTD.2010.5399061
[29]Puppet Inc. 2019. puppet-strings. https://rubygems.org/gems/puppet-strings.
[Online; accessed 22-Aug-2019].
[30]Md Johirul Islam, Giang Nguyen, Rangeet Pan, and Hridesh Rajan. 2019. A
ComprehensiveStudyonDeepLearningBugCharacteristics.In Proceedingsof
the201927thACMJointMeetingonEuropeanSoftwareEngineeringConference
and Symposium on the Foundations of Software Engineering (ESEC/FSE 2019).
AssociationforComputing Machinery,NewYork,NY, USA,510âĂŞ520. https:
//doi.org/10.1145/3338906.3338955
[31]Yujuan Jiang and Bram Adams. 2015. Co-evolution of Infrastructure and Source
Code: An Empirical Study. In Proceedings of the 12th Working Conference on
MiningSoftwareRepositories (MSR’15).IEEEPress,Piscataway,NJ,USA,45–55.
http://dl.acm.org/citation.cfm?id=2820518.2820527
[32]DanielJurafskyandJamesH.Martin.2009. SpeechandLanguageProcessing(2Nd
Edition). Prentice-Hall, Inc., Upper Saddle River, NJ, USA.
[33]Bryan Jurish and Kay-Michael Wurzner. 2013. Word and Sentence Tokenization
with Hidden Markov Models. JLCL28, 2 (2013), 61–83.
[34]Barbara A. Kitchenham and Shari L. Pfleeger. 2008. Personal Opinion Surveys.
Springer London, London, 63–92. https://doi.org/10.1007/978-1-84800-044-5_3
[35]Rahul Krishna, Amritanshu Agrawal, Akond Rahman, Alexander Sobran, and
Tim Menzies. 2018. What is the Connection Between Issues, Bugs, and En-
hancements?: Lessons Learned from 800+ Software Projects. In Proceedings of
the 40th International Conference on Software Engineering: Software Engineer-ing in Practice (ICSE-SEIP ’18). ACM, New York, NY, USA, 306–315. https:
//doi.org/10.1145/3183519.3183548
[36]PuppetLabs.2017. PuppetDocumentation. https://docs.puppet.com/. [Online;
accessed 19-August-2019].
[37]Richard Landis and Gary Koch. 1977. The Measurement of Observer Agreement
for Categorical Data. Biometrics 33, 1 (1977), 159–174. http://www.jstor.org/
stable/2529310
[38]Librarian puppet. 2019. librarian-puppet. http://librarian-puppet.com/. [Online;
accessed 22-Aug-2019].
[39]MarioLinares-Vásquez,GabrieleBavota,andCamiloEscobar-Velasquez.2017.
AnEmpiricalStudyonAndroid-relatedVulnerabilities.In Proceedingsofthe14th
InternationalConferenceonMiningSoftwareRepositories (MSR’17).IEEEPress,
Piscataway, NJ, USA, 2–13. https://doi.org/10.1109/MSR.2017.60
[40]James Turnbull McCune and Jeffrey. 2011. Pro Puppet (1 ed.). Apress. 336 pages.
https://doi.org/10.1007/978-1-4302-3058-8
[41]AudrisMockusandLawrenceG.Votta.2000. IdentifyingReasonsforSoftware
Changes Using Historic Databases. In Proceedings of the International Conference
on Software Maintenance (ICSM’00) (ICSM ’00) . IEEE Computer Society, Washing-
ton, DC, USA, 120–. http://dl.acm.org/citation.cfm?id=850948.853410
[42] Mozilla. 2019. Mercurial Repositories Index. https://hg.mozilla.org/[43]
NuthanMunaiah,StevenKroh,CraigCabrey,andMeiyappanNagappan.2017.
CuratingGitHubforengineeredsoftwareprojects. EmpiricalSoftwareEngineering
(2017), 1–35. https://doi.org/10.1007/s10664-017-9512-6
[44]Openstack.2018.OpenStackgitrepositorybrowser.http://git.openstack.org/cgit/.
[Online; accessed 12-September-2018].
[45] Openstack. 2019. Explore-OpenDev. https://opendev.org/explore/repos[46]
Openstack. 2019. fuel-plugin-lma-collector. https://opendev.org/x/
fuel-plugin-lma-collector. [Online; accessed 22-August-2019].
[47]Openstack.2019. OpenstackFuelPlugin. https://wiki.openstack.org/wiki/Fuel/
Plugins#Example_jobs. [Online; accessed 19-August-2019].
[48]Openstack. 2019. puppet-ceilometer. https://opendev.org/openstack/
puppet-ceilometer. [Online; accessed 23-August-2019].
[49]Openstack. 2019. Welcome to Neutron’s documentation! https://docs.openstack.
org/neutron/latest/. [Online; accessed 22-August-2019].
[50]LucaPascarella,FabioPalomba,MassimilianoDiPenta,andAlbertoBacchelli.
2018. HowisVideoGameDevelopmentDifferentfromSoftwareDevelopment
inOpenSource?.In Proceedingsofthe15thInternationalConferenceonMining
Software Repositories (MSR ’18). ACM, New York, NY, USA, 392–402. https:
//doi.org/10.1145/3196398.3196418
[51]AntonioPecchiaandStefanoRusso.2012. DetectionofSoftwareFailuresthrough
EventLogs:AnExperimentalStudy.In 2012IEEE23rdInternationalSymposium
onSoftwareReliabilityEngineering.31–40. https://doi.org/10.1109/ISSRE.2012.24
[52]GoogleCloudPlatform.2018. GoogleComputeEngineIncident#17007. https:
//status.cloud.google.com/incident/compute/17007#5659118702428160. [Online;
763accessed 20-August-2019].
[53]MFPorter.1997.ReadingsinInformationRetrieval.MorganKaufmannPublishers
Inc.,SanFrancisco,CA,USA,ChapterAnAlgorithmforSuffixStripping,313–316.
http://dl.acm.org/citation.cfm?id=275537.275705
[54]Puppet lint. 2019. puppet-lint. http://puppet-lint.com/. [Online; accessed
22-Aug-2019].
[55]Akond Rahman, Amritanshu Agrawal, Rahul Krishna, and Alexander Sobran.
2018. Characterizing the Influence of Continuous Integration: Empirical Results
from 250+ Open Source and Proprietary Projects. In Proceedings of the 4th ACM
SIGSOFT International Workshop on Software Analytics (SWAN 2018). ACM, New
York, NY, USA, 8–14. https://doi.org/10.1145/3278142.3278149
[56]AkondRahman,EffatFarhana,ChrisParnin,andLaurieWilliams.2019. Refer-
ences to Defect-related Consequences. http://tiny.cc/defect-result-source. [On-
line; accessed 22-Aug-2019].
[57]Akond Rahman, Effat Farhana, Chris Parnin, and Laurie Williams. 2019. Verifia-
bility Package for Paper. https://figshare.com/s/b2633bd4b1929267a451
[58]AkondRahman,ChrisParnin,andLaurieWilliams.2019.TheSevenSins:Security
Smells in Infrastructure As Code Scripts. In Proceedings of the 41st International
Conferenceon SoftwareEngineering (ICSE ’19).IEEEPress,Piscataway,NJ,USA,
164–175. https://doi.org/10.1109/ICSE.2019.00033
[59]Akond Rahman, Asif Partho, Patrick Morrison, and Laurie Williams. 2018. What
QuestionsDoProgrammersAskAboutConfigurationAsCode?.In Proceedingsof
the 4th International Workshop on Rapid Continuous Software Engineering (RCoSE
’18). ACM, New York, NY, USA, 16–22. https://doi.org/10.1145/3194760.3194769
[60]Akond Rahman and Laurie Williams. 2018. Characterizing Defective Config-uration Scripts Used for Continuous Deployment. In 2018 IEEE 11th Interna-
tionalConferenceonSoftwareTesting,VerificationandValidation(ICST).34–45.
https://doi.org/10.1109/ICST.2018.00014
[61]Akond Rahman and Laurie Williams. 2019. Source Code Properties of Defective
Infrastructure as Code Scripts. Information and Software Technology (2019).
https://doi.org/10.1016/j.infsof.2019.04.013
[62]Baishakhi Ray, Vincent Hellendoorn, Saheel Godhane, Zhaopeng Tu, Alberto
Bacchelli, and Premkumar Devanbu. 2016. On the "Naturalness" of Buggy Code.
InProceedings of the 38th International Conference on Software Engineering (ICSE
’16).ACM,NewYork,NY,USA,428–439. https://doi.org/10.1145/2884781.2884848
[63]BaishakhiRay,DarylPosnett,VladimirFilkov,andPremkumarDevanbu.2014.
A Large Scale Study of Programming Languages and Code Quality in Github. In
Proceedingsofthe22NdACMSIGSOFTInternationalSymposiumonFoundations
ofSoftwareEngineering (FSE2014).ACM,NewYork,NY,USA,155–165. https:
//doi.org/10.1145/2635868.2635922
[64]Rspec puppet. 2019. rspec-puppet. https://rspec-puppet.com/. [Online; accessed
22-Aug-2019].
[65] Johnny Saldana. 2015. The coding manual for qualitative researchers. Sage.
[66]J. Schwarz, A. Steffens, and H. Lichter. 2018. Code Smells in Infrastructureas Code. In 2018 11th International Conference on the Quality of Information
and Communications Technology (QUATIC). 220–228. https://doi.org/10.1109/
QUATIC.2018.00040
[67]RianShambaugh,AaronWeiss,andArjunGuha.2016.Rehearsal:AConfiguration
Verification Tool for Puppet. SIGPLAN Not. 51, 6 (June 2016), 416–430. https:
//doi.org/10.1145/2980983.2908083
[68]Tushar Sharma, Marios Fragkoulis, and Diomidis Spinellis. 2016. Does YourConfigurationCodeSmell?.In Proceedingsofthe13thInternationalConference
onMiningSoftwareRepositories (MSR’16).ACM,NewYork,NY,USA,189–200.
https://doi.org/10.1145/2901739.2901761
[69]EdwardSmith,RobertLoftin,EmersonMurphy-Hill,ChristianBird,andThomas
Zimmermann. 2013. Improving developer participation rates in surveys. In
20136thInternationalWorkshoponCooperativeandHumanAspectsofSoftware
Engineering (CHASE). 89–92. https://doi.org/10.1109/CHASE.2013.6614738[70]SpaCy. 2019. spaCy: Industrial-Strength Natural Language Processing. https:
//spacy.io/. [Online; accessed 20-August-2019].
[71]StackExchange. 2019. Tour-Stack Exchange. https://stackexchange.com/tour.
[Online; accessed 22-August-2019].
[72]StackExchange Status. 2014. Outage Post-Mortem: August 25th, 2014. https:
//stackstatus.net/post/96025967369/outage-post-mortem-august-25th-2014. [On-
line; accessed 20-August-2019].
[73]Margaret-Anne Storey, Jody Ryall, R. Ian Bull, Del Myers, and Janice Singer.2008. TODO or to Bug: Exploring How Task Annotations Play a Role in the
WorkPracticesofSoftwareDevelopers.In Proceedingsofthe30thInternational
ConferenceonSoftwareEngineering(ICSE’08).ACM,NewYork,NY,USA,251–260.
https://doi.org/10.1145/1368088.1368123
[74]LinTan,ChenLiu,ZhenminLi,XuanhuiWang,YuanyuanZhou,andChengxiang
Zhai. 2014. Bug Characteristics in Open Source Software. Empirical Softw. Engg.
19, 6 (Dec. 2014), 1665–1705. https://doi.org/10.1007/s10664-013-9258-8
[75]LinTan,DingYuan,GopalKrishna,andYuanyuanZhou.2007. /*Icomment:Bugs
or Bad Comments?*/. In Proceedings of Twenty-first ACM SIGOPS Symposium
on Operating Systems Principles (SOSP ’07). ACM, New York, NY, USA, 145–158.
https://doi.org/10.1145/1294261.1294276
[76]FerdianThung,ShaoweiWang,DavidLo,andLingxiaoJiang.2012. AnEmpirical
Study of Bugs in Machine Learning Systems. In 2012 IEEE 23rd International
SymposiumonSoftwareReliabilityEngineering.271–280. https://doi.org/10.1109/
ISSRE.2012.22
[77]MarkUtting,AlexanderPretschner,andBrunoLegeard.2012. ATaxonomyof
Model-based Testing Approaches. Softw. Test. Verif. Reliab. 22, 5 (Aug. 2012),
297–312. https://doi.org/10.1002/stvr.456
[78]Eduard vander Bent,Jurriaan Hage, JoostVisser, andGeorgios Gousios.2018.
How good isyourpuppet? An empirically defined andvalidated quality model
for puppet. In 2018 IEEE 25th International Conference on Software Analysis, Evo-
lutionandReengineering(SANER).164–174. https://doi.org/10.1109/SANER.2018.
8330206
[79]Christopher Vendome, Daniel German, Massimiliano Penta, Gabriele Bavota,
MarioLinares-Vásquez,andDenysPoshyvanyk.2018. ToDistributeorNotto
Distribute? Why Licensing Bugs Matter. In 2018 IEEE/ACM 40th International
Conference on Software Engineering (ICSE). 268–279. https://doi.org/10.1145/
3180155.3180221
[80]Zhiyuan Wan, David Lo, Xin Xia, and Liang Cai. 2017. Bug Characteristics
inBlockchainSystems:ALarge-ScaleEmpiricalStudy.In 2017IEEE/ACM14th
International Conference on Mining Software Repositories (MSR). 413–424. https:
//doi.org/10.1109/MSR.2017.59
[81]Aaron Weiss, Arjun Guha, and Yuriy Brun. 2017. Tortoise: Interactive System
Configuration Repair. In Proceedings of the 32Nd IEEE/ACM International Confer-
enceonAutomatedSoftwareEngineering (ASE2017).IEEEPress,Piscataway,NJ,USA, 625–636. http://dl.acm.org/citation.cfm?id=3155562.3155641
[82]
GerritWikimedia.2019. Projectoperations/puppet/cdh. https://gerrit.wikimedia.
org/r/#/admin/projects/operations/puppet/cdh. [Online; accessed 21-August-
2019].
[83]Xin Xia, Xiaozhen Zhou, David Lo, and Xiaoqiong Zhao. 2013. An Empirical
StudyofBugsinSoftwareBuildSystems.In 201313thInternationalConference
on Quality Software. 200–203. https://doi.org/10.1109/QSIC.2013.60
[84]WeiZheng,ChenFeng,TingtingYu,XibingYang,andXiaoxueWu.2019.Towards
understandingbugsinanopensourcecloudmanagementstack:Anempirical
studyofOpenStacksoftwarebugs. JournalofSystemsandSoftware 151(2019),
210 – 223. https://doi.org/10.1016/j.jss.2019.02.025
[85]StefanoZilli.2014. Hidesecretsfrompuppetlogs. https://bugs.launchpad.net/
puppet-ceilometer/+bug/1328448. [Online; accessed 19-August-2019].
[86]Weiqin Zou, David Lo, Zhenyu Chen, Xin Xia, Yang Feng, and Baowen Xu. 2018.
How Practitioners Perceive Automated Bug Report Management Techniques.
IEEETransactionsonSoftwareEngineering (2018). https://doi.org/10.1109/TSE.
2018.2870414
764