Intelligent Change Operators
for Multi-Objective Refactoring
Chaima Abid1, James Ivers2, Thiago do N. Ferreira1, Marouane Kessentini1, Fares E. Kahla1and Ipek Ozkaya2
1University of Michigan-Dearborn, Dearborn, USA
2Carnegie Mellon University Software Engineering Institute, Pittsburgh, USA
{cabid, thiagod, marouane}@umich.edu, {jivers, ozkaya}@sei.cmu.edu and benkahlafares@gmail.com
Abstract ‚ÄîIn this paper, we propose intelligent change oper-
ators and integrate them into an evolutionary multi-objective
search algorithm to recommend valid refactorings that addressconÔ¨Çicting quality objectives such as understandability andeffectiveness. The proposed intelligent crossover and mutationoperators incorporate refactoring dependencies to avoid creatinginvalid refactorings or invalidating existing refactorings. Further,the intelligent crossover operator is augmented to create offspringthat improve solution quality by exchanging blocks of validrefactorings that improve a solution‚Äôs weakest objectives. Weused our intelligent change operators to generate refactoringrecommendations for four widely used open-source projects. Theresults show that our intelligent change operators improve thediversity of solutions. Diversity is important in genetic algorithmsbecause crossing over a homogeneous population does not yieldnew solutions. Given the inherent nature of design trade-offs insoftware, giving developers choices that reÔ¨Çect these trade-offs isimportant. Higher diversity makes better use of developers timethan lots of incredibly similar solutions. Our intelligent changeoperators also accelerate solution convergence to a feasiblesolution that optimizes the trade-off between the conÔ¨Çictingquality objectives. Finally, they reduce the number of invalidrefactorings by up to 71.52% compared to existing search-basedrefactoring approaches, and increase the quality of the solutions.Our approach outperformed the state-of-the-art search-basedrefactoring approaches and an existing deterministic refactoringtool based on manual validation by developers with an averagemanual correctness, precision and recall of 0.89, 0.82, and 0.87.
Index T erms‚Äîrefactoring dependencies, intelligent change op-
erators, multi-objective refactoring recommendation.
I. I NTRODUCTION
Even for the most competent organizations, building and
maintaining high performing software applications with high
quality is a challenging and expensive endeavor [45]. Workingin fast-paced environments that demand frequent releasesacross several products and deployment environments oftenforces developers to compromise high quality standards infavor of meeting deadlines [24]. As software systems continueto grow in size and complexity, their maintenance continuesto become more challenging and costly [20], [11]. To improvethe quality and maintainability of software systems, developerstake advantage of refactoring as a means to improve thestructure of code without affecting its external behavior [16].
Manual refactoring is generally a labor-intensive, ad hoc,
and potentially error-prone process [32]. To improve this gap,a wide range of work has focused on automating refactoringrecommendations using a variety of techniques that includetemplate/rule-based tools [44], [43], static and lexical anal-ysis [7], [12], and search-based software engineering [25].Recent surveys show that search-based software engineeringhas been increasingly used to Ô¨Ånd refactoring recommenda-tions [31], [25] to address the trade-offs among conÔ¨Çictingquality metrics and the large search space of potential refac-toring strategies. For instance, O‚ÄôKeeffe et al. [42] compareddifferent local search-based algorithms such as hill climbingand simulated annealing to generate refactoring recommen-dations that improve static quality metrics [6]. Harman etal. [19] proposed using multi-objective search for refactoringsthat improve coupling and reduce cohesion. Ouni et al. [40]and Mkaouer et al. [30] proposed multi-objective and many-objective techniques to balance conÔ¨Çicting quality metricswhen Ô¨Ånding refactoring recommendations. Hall et al. [17]and Alizadeh et al. [4] improved the state-of-the-art of search-based refactoring by enabling interaction with developersand learning their preferences. More detailed descriptions ofexisting search-based refactoring studies can be found in thefollowing surveys [25], [31]. Despite the promising resultsof search-based refactoring on both open-source and industryprojects, several limitations that reduce their effectivenessremain unaddressed. While these limitations apply, in general,in most applications of search-based reasoning approaches tosoftware engineering problems [2], [18], [41], we focus onsearch-based refactoring in this paper.
Existing refactoring recommendation tools, including those
that use non-search-based approaches, routinely generate so-lutions that include invalid refactorings because they do notaccount for dependencies among refactorings. Manually apply-ing a sequence of refactorings is common practice in existingtools [9], [32], [8], however these tools treat each refactoringin the sequence in isolation. For instance, Cinn√©ide et al. [33]investigated the impact only of individual refactorings onquality attribute metrics, such as using Move Method to reducethe coupling of a class, without studying the impact of asequence of refactorings. Figure 1 shows an example of therefactoring recommendations generated by JDeodorant [47]where, similar to other refactoring recommendation tools, thedependencies between the refactorings are not apparent, thusleaving the challenging task of dealing with invalid refac-torings to developers. Consequently, developers often prefermanually applying refactorings to using such tools. A keycontributor to this problem is that search-based refactoring
7682021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE)
DOI 10.1109/ASE51524.2021.000732021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE) | 978-1-6654-0337-5/21/$31.00 ¬©2021 IEEE | DOI: 10.1109/ASE51524.2021.9678519
978-1-6654-0337-5/21/$31.00  ¬©2021  IEEE
approaches employ random change operators (e.g., crossover
and mutation) to evolve solutions without considering thedependencies among refactorings. Without detecting whichrefactoring dependencies exist, the change operators used byalgorithms routinely invalidate solutions by breaking refactor-ing dependencies or introducing refactorings whose dependen-cies are not satisÔ¨Åed. Furthermore, refactoring dependenciesprovide clues that could be exploited in more intelligentcrossover operations to improve decisions on which part(s)of solutions to exchange to produce higher quality offspring.
Fig. 1: Sample refactoring recommendations from JDeodorant.
In this paper, we propose intelligent change operators
and integrate them into a multi-objective search algorithm,based on NSGA-II [13], to recommend valid refactoringsthat address conÔ¨Çicting quality objectives such as Reusability,understandability, and effectiveness. The proposed intelligentcrossover and mutation operators use: i) the dependenciesdetected among refactorings to decompose a solution intoblocks of refactorings; and ii) the effects of these blocks onobjectives to identify good genes from parents to generatehigh-quality offspring. A refactoring dependency exists whenone refactoring cannot be successfully applied without Ô¨Årstapplying another. Partitioning refactorings into blocks suchthat no dependencies span blocks allows change operatorsto use blocks as the unit of change to avoid invalidatingrefactorings. Our tool calculates the effect of each block withina solution on the objectives and uses this data to select whichblocks to exchange between solutions to improve the Ô¨Årstsolution‚Äôs weaknesses (e.g. the objective with smallest values).
We applied our intelligent change operators to generate
refactoring recommendations for four widely used open-sourceprojects and compared this approach to Ô¨Åve existing refac-toring techniques in terms of the diversity of the solutions,number of invalid refactorings, and the quality of generatedsolutions. We also conducted a survey with 14 developersto evaluate the correctness and relevance of the refactoringsgenerated by the different algorithms for these projects.
The results show that our technique performed signiÔ¨Å-
cantly better than the four existing search-based refactoringapproaches [29], [19], [42], [38] and an existing refactoringtool not based on heuristic search, JDeodorant [46], with anaverage manual correctness, precision and recall of 0.89, 0.82,and 0.87, respectively. We used these Ô¨Åve refactoring toolsand open source projects because: i) they are representativeof automated multi-objective search-based refactoring recom-mendation techniques; ii) they are publicly available (includingthe non search-based tool); and iii) the familiarity of theparticipants with these open source systems.
Replication Package. All material and data used in our
study are available in our replication package [5].
II. D
EPENDENCY -AWA R E REFACTORING
RECOMMENDA TION SYSTEM
A. Background: Multi-Objective Refactoring Using NSGA-II
Multi-objective optimization has been widely applied to
refactoring problems to Ô¨Ånd trade-offs when searching for so-lutions. Non-Dominated Sorting Genetic Algorithm II (NSGA-II) [13] (Algorithm 1) is the dominant multi-objective opti-mization algorithm that has been used in search-based softwareengineering, including for search-based refactoring [19], [42],[40], [3], [4], [30]. NSGA-II is designed to Ô¨Ånd a set of non-dominated solutions (a Pareto-front) in which each solution isa sequence of refactorings that provides a compromise amongconÔ¨Çicting objectives (e.g., quality metrics).
Algorithm 1: NSGA-II algorithm.
Input: System to evaluate and list of refactoring types
Output: Non-dominated refactoring solutions
1Generate a random population Pand evaluate the objectives;
2while the stopping condition is not reached do
3 Select individuals M from Pusing Binary Tournament
Selection;
4 Apply crossover operation on M to generate the offspring
population O;
5 Apply mutation operation on O;
6 Update Pby combining the parent and offspring populations;
7end
8return P;
Initially, a starting population Pis created using a random
procedure. These solutions then undergo crossover and muta-tion, producing offspring O, and the process is repeated until
the stopping condition is reached (in our case, a maximumnumber of generations). The objective values of the solutionsare computed and change operators are applied to create thenext generation. In most of existing adaptations, including thispaper, the algorithm Ô¨Ånds non-dominated solutions balancingseveral conÔ¨Çicting objectives, such as the six QMOOD qualitymetrics [6]. The different objectives can be normalized if theyhave different scales. Each objective can be written as follow:
Objective i=Qafter
i‚àíQbeforei
Qbeforei(1)
whereQbefore
i andQafteriare the values of the
quality_metrics ibefore and after applying a solution
(or sequence of refactorings), respectively.
The search space explored by NSGA-II consists of differ-
ent refactoring operations applied to different code locations
where each operation is represented by a refactoring type (e.g.,Move Method) and its parameters (e.g., source class, targetclass, attributes). In this paper, we selected 14 refactoringtypes that are frequently used in practice based on existingstudies [22], [32], [10]: Encapsulate Field, Decrease FieldSecurity, Decrease Method Security, Increase Field Security,
769Increase Method Security, Pull Up Field, Pull Up Method,
Push Down Field, Push Down Method, Extract Sub Class,Extract Super Class, Extract Class, Move Field, and MoveMethod. A vector in which each element represents a refactor-ing operation is used to represent a solution. Each refactoringoperation must satisfy a set of pre- and post-conditions deÔ¨Ånedby Opdyke [36] to maintain the behavior of the system.
The most common change operators used in search-based
refactoring approaches are the random crossover and muta-tion operators. In these operators, refactorings are selectedrandomly from solutions for exchange or replacement withothers, which can generate invalid refactorings or invalidateother refactorings (e.g., by removing a refactoring another onedepends on). We developed three components to improve thechange operators used in the NSGA-II algorithm: i) a refactor-ing dependency detection algorithm; ii) an intelligent crossoverthat factors in dependency correctness and the implicationsof collections of refactorings on Ô¨Åtness functions; and iii) adependency-aware mutation. Finally, we note that the proposedapproach, as described later, can be integrated for both NSGA-II and NSGA-III as they are using the same change operators.The difference between them is that NSGA-III uses a set ofreference directions (identiÔ¨Åed via a nitching function), whileNSGA-II uses a more adaptive scheme through its crowdingdistance operator for the same purpose. This difference doesnot affect our goal of comparing the impact of our intelligentchange operators on the Ô¨Ånal Pareto-front.
B. Refactoring Dependency Theory
Our dependency-aware refactoring recommendation tech-
nique relies on an ordering dependency between pairs of
refactorings. SpeciÔ¨Åcally, an ordering dependency (rf
2/mapsto‚Üí
rf1)between two refactorings (rf 1andrf2) exists when rf2
can only be successfully applied after rf1has been applied.
That is, rf1makes a change to code that is necessary in
order to apply rf2. This condition can be evaluated based on
the combination of pre- and post-conditions of the types ofrefactorings involved and the parameters of each refactoring.For example, to apply Move Method (a type of refactoring)to move method m
1from class c1to classc2(m1,c1, andc2
being the parameters of the refactoring), several pre-conditionsmust hold (e.g., m
1,c1, andc2must all exist and m1must
be deÔ¨Åned on c1). The pre- and post-conditions of each type
of refactoring are described in our online appendix [5] andwere extensively validated for correctness and completenessin current literature [39], [34], [15], [26].
Figure 2 shows a simpliÔ¨Åed example of a refactoring so-
lution that is composed of refactoring operations that dependon each other. Three of the refactorings (#3, #4, #5) dependon another refactoring (#2) because the Extract Super Classrefactoring (#2) creates a new class (Client), on which refac-torings #3, #4, and #5 operate. If the new class is not createdÔ¨Årst, then refactorings #3, #4, and #5 will fail. Thus, thereexists an ordering dependency from each of #3, #4, #5 to #2.
Refactoring solutions have traditionally been represented
as a sequence, likely originating with the common vector–Ωœ´
*1 $ '
0. -)( 
**' )$./
–ò–ô
–ò–ô
–Ωœ≠
*1 $ '
'$ )/
1 )/% /
–ò!$ ' '$($/ -–ô
–ò–ô–ΩœÆ
0''+$ '
- $/-
'$ )/
–ò/ 3/ '$($/ -–ô
–ò–ô–ΩœØ
0''+ /#*
- $/-
'$ )/
–ò–ô
–ò- / "*-4/. /–ô–Ωœ¨
3/-/0'..
- $/-
'$ )/
–ò!$ ' '$($/ -–ô
–ò 3/-/*2 4)/–ô !/*-$)"
 + ) )4
Fig. 2: A simpliÔ¨Åed example of refactorings that depend oneach other.
representation used in many genetic algorithms. In some cases,
a solution could be appropriately represented as a set ofsequences, but only if the refactoring graphs are simplistic
enough. A refactoring graph is a weakly connected directed
acyclic graph composed of refactoring vertices and orderingdependency edges. In practice, there are many examples wherea sequence vs. graph representation is misleading. For exam-ple, if two refactorings (rf2 and rf3) both depend on a commonrefactoring (rf1), we have a graph for which a sequencerepresentation would be misleading. rf1 must precede rf2 andrf3, but there is no dependency between rf2 and rf3. <rf1, rf2,rf3> would be as acceptable as <rf1, rf3, rf2>. A sequencerepresentation indicates an ordering, and the choice of a graphover a sequence allows us to unambiguously indicate only‚Äúreal‚Äù dependencies. As for the initial refactoring sequence, itis true that the order in that sequence does shape the originalgraphs. However, the initial sequence is generated randomlyfor each solution in the population, much as if random graphswere generated.
Using the ordering dependencies as the basis for forming
refactoring graphs, Algorithm 2 results in a set of graphs withthe following traits:
‚Ä¢Each refactoring in a solution is an element of exactlyone refactoring graph.
‚Ä¢Some graphs contain a single refactoring because thatrefactoring is independent of all others. We call thesetrivial graphs.
‚Ä¢The remaining graphs contain multiple refactorings, eachof which is part of one or more dependencies. We callthese non-trivial graphs.
‚Ä¢Each refactoring graph is independent of every othergraph in the solution.
The dependencies, as described in Algorithm 2, are detected
based on comparisons between pre- and post-conditions ofrefactorings. The algorithm takes a list of refactorings as inputand generates a set of refactoring graphs as output.
Line 1 initializes the lists of refactorings (nodes, V)
and refactoring dependencies (edges, E). Then, the post-
conditions of each refactoring of the solution C(collection of
refactorings) are evaluated for matching with the remainingrefactorings in C(Lines 2‚Äì12). SpeciÔ¨Åcally, the algorithm
looks for any match between predicates of pre- and post-conditions. That is, if any predicate of the post-condition ofone refactoring (any element of P) matches any predicate of
770Algorithm 2: Dependency Detection Algorithm.
Input: Refactoring solution C={r1,r2,r3,...,r n}
Output: Set of refactoring graphs F={f1,f2,f3,...,f m}
1V‚Üê‚àÖ,E‚Üê‚àÖ ;
2foreach ri‚ààCdo
3 V‚ÜêV‚à™ri;
4 P‚Üêpost_conditions(r i);
5 foreach rj‚ààC|j>i do
6 Q‚Üêpre_conditions(r j);
7 M‚ÜêP‚à©Q;
8 if|M|/negationslash=0then
9 E‚ÜêE‚à™{rj,ri};
10 end
11 end
12end
13G‚Üê(V,E );
14F‚Üêpartition(G );
15return F
the pre-condition of another refactoring (any element of Q),
then a dependency has been detected and an edge is added to
the graph between those refactorings (Lines 4‚Äì11). We repeatthis process until all the refactorings have been visited.
C. Proposed Intelligent Change Operators
1) Dependency-aware Crossover: We developed a baseline
dependency-aware crossover that only preserves the dependen-
cies among refactorings (e.g., without Ô¨Åxing the weaknesses ofrefactoring solutions). This version, as shown in Algorithm 3,reduces the occurrence of invalid refactorings in solutionsbecause it preserves refactoring dependencies.
Algorithm 3: Dependency-Aware Crossover
Algorithm.
Input: population S={s1,s2,s3,...,s n}and a probability P
Output: offspring population S/prime={s/prime
1,s/prime
2,s/prime
3,...,s/prime
n}
1S/prime‚Üê‚àÖ ;
2fori‚Üê1to|S|/2do
3{sa,sb}‚Üê select random solutions from S;
4 ifrandom_number ‚â§Pthen
5 Ba‚Üêgroup refactorings of sainto blocks;
6 Bb‚Üêgroup refactorings of sbinto blocks;
7 {s/prime
a,s/prime
b}‚Üê apply single point crossover on {B a,Bb};
8 S/prime‚ÜêS/prime/uniontext{s/prime
a,s/prime
b};
9 else
10 S/prime‚ÜêS/prime/uniontext{sa,sb};
11 end
12end
13return S/prime;
We start by randomly selecting two solutions, saandsb,
as parents for new offspring (Line 3). Then, we group therefactorings of s
aandsbinto blocks (Lines 5‚Äì6) based
on the dependencies detected by Algorithm 2. Each blockcontains a single trivial or non-trivial graph. We then performa single-point crossover (Line 7) that exchanges blocks ofrefactorings rather than individual refactorings, which avoidsinvalidating refactorings because all dependencies are isolatedwithin blocks. This results in two offspring, each with geneticinformation from both parents.2) Intelligent Crossover: Our intelligent crossover operator
is an improvement over random crossover in two ways: it usesrefactoring dependencies to reduce the occurrence of invalidrefactorings and it chooses blocks of refactorings for exchangethat will improve a solution‚Äôs weaknesses, producing higherquality offspring. The pseudo-code of our proposed intelligentcrossover operator is presented in Algorithm 4.
Algorithm 4: Intelligent Crossover Algorithm.
Input: Population S={s1,s2,s3,...,s n}and a probability P
Output: Offspring population S/prime={s/prime
1,s/prime
2,s/prime
3,...,s/prime
n}
1S/prime‚Üê‚àÖ ;
2fori‚Üê1to|S|/2do
3{sa,sb}‚Üê select random solutions from S;
4 ifrandom_number ‚â§Pthen
5 sbest‚Üêhigher quality solution of saandsb;
6 sworst‚Üêlower quality solution of saandsb;
7 Bbest‚Üêgroup refactorings of sbest into blocks;
8 Bworst‚Üêgroup refactorings of sworst into blocks;
9 Wbest‚Üêget all weaknesses of sbest ;
10 ifWbest =‚àÖthen
11 Wbest‚Üêget the objective that improves the least
with sbest ;
12 end
13 I‚Üêsort the blocks of Bworst based on potential
improvement to Sbest ;
14 I/prime‚Üêselect the blocks from Ithat improve Sbest ;
15 n‚Üêselect random number between 0and|I/prime|;
16 {s/prime
best,s/prime
worst}‚Üê apply single point crossover,
exchanging nblocks between Bbest andI;
17 S/prime‚ÜêS/prime/uniontext{s/prime
best,s/prime
worst};
18 else
19 S/prime‚ÜêS/prime/uniontext{sa,sb};
20 end
21end
22return S/prime;
In essence, the intelligent crossover operator mixes the best
genes of the weaker solution with random genes of the bettersolution (Figure 3). First, we randomly select two solutions,s
aandsb(Line 3). We then determine the better solution by
computing how much each solution improves the objectives(using a weighted sum) of the project to be refactored (Lines5‚Äì6). As before, we group refactorings of both solutions intoblocks (Lines 7‚Äì8) to preserve refactoring dependencies duringcrossover. We then determine which objectives are consideredthe weaknesses of the better solution S
best (Lines 9‚Äì12) (part
a in Figure 3). Any objectives that are worse after applyingthe better solution are considered weaknesses (e.g. objective 2in Figure 3 part a). If no objectives are worse after applying thebetter solution, we select the objective that improves the leastafter applying the solution as the sole weakness. Then, we sortthe blocks of the weaker solution B
worst based on how each
would impact the objectives (using a weighted sum) of thebetter solution S
best (Line 13) (part b in Figure 3). In part c
of Algorithm 4, We pick a random number between 1 and thenumber of blocks in the weaker solution that would improvethe better solution (Line 15) to determine the number of blocksfor crossover. Finally, we create two offspring using singlepoint crossover (Line 16) that moves the nblocks from the
weaker solution with the best impact on the stronger solution‚Äôs
771objectives to the stronger solution and nrandom blocks from
the stronger solution to the weaker solution.
3) Dependency-aware Mutation: Our proposed
dependency-aware mutation operator is deÔ¨Åned in
Algorithm 5 and illustrated in Figure 4. We modiÔ¨Åedthe random mutation operator to preserve refactoringdependencies. For each solution S, we randomly select a
Ô¨Çoating-point value. If this value is less than the mutationprobability (Line 1), we detect refactoring dependencies (Parta in Figure 4) and identify mutable refactorings (Line 2) (Partb in Figure 4). A mutable refactoring must satisfy at leastone of the following:
‚Ä¢it does not participate in any dependencies (e.g., Eand
Cin Figure 4).
‚Ä¢it is part of a non-trivial graph, but no other refactoringsdepend on it (e.g., G,IandHin Figure 4).
‚Ä¢it is part of a non-trivial graph, but it has an unsatisÔ¨Åedpre-condition and is already invalid (e.g., Ain Figure 4).
Then, we chose a random number between 1 and the number
of mutable refactorings (Line 3). This number represents thenumber of refactorings that we will mutate in refactoringsolution S. Finally, we replace N refactorings in Swith
random refactoring operations and parameters (Line 4‚Äì7) (Partc in Figure 4).
Algorithm 5: Dependency-aware Mutation Algorithm.
Input: Solution S={r1,r2,r3,...,r n}and a probability P
Output: Mutated solution S
1ifrandom_number ‚â§Pthen
2 M‚Üêdetect mutable refactorings from S;
3 N‚Üêrandom number between 1 and |M|;
4 fori‚Üê0toNby1do
5 rj‚Üêrandom refactoring from M;
6 replace rjinSwith a random refactoring;
7 end
8end
9return S;
III. E MPIRICAL STUDY
A. Research Questions
The following research questions guide the evaluation of
our proposed approach:
RQ1. Correctness. To what extent can our approach re-
duce the number of invalid refactorings compared toother multi-objective refactoring recommendation tech-niques?
RQ2. Quality. To what extent can our approach generate
refactoring solutions with better diversity, convergence,and quality improvement compared to other multi-objective refactoring techniques?
RQ3. Relevance. How do developers evaluate the impact of
our approach in practice?
To answer item RQ1, we chose the algorithm proposed by
Mkaouer et al. [29] based on NSGA-III, because it outper-forms the existing multi-objective techniques [19], [42], [38]that use random change operators. Please note that NSGA-II and NSGA-III are using the same change operators asexplained in the previous section. We also considered twooperation-variants of NSGA-II that optimize the same qualityobjectives as summarized in Table I.
TABLE I: The three operation-variants of the NSGA-II
algorithm.
Algorithm DeÔ¨Ånition
NSGA-IINSGA-II with random Single Point crossover and Bit
Flip mutation (Mkaouer et al. [29])
Dep-NSGA-IINSGA-II with dependency-aware change operators(Sections II-C1 and II-C3)
Intel-NSGA-IINSGA-II with intelligent crossover and dependency-aware mutation (Sections II-C2 and II-C3)
We selected four open-source Java projects (show
in Table II) that were used in the work of Mkaouer et al. [29].
These projects are from different domains and have differentsizes along with a signiÔ¨Åcant number of contributors over morethan 10 years. Furthermore, the selected projects are widelyused and extensively involved over time which may justify theneed for refactoring.
Also, we checked the validity of pre- and post-conditions
of all refactorings in all solutions in each generation for allthree algorithms on the four projects. We measured the totalnumber of conÔ¨Çicts for each generation as the percentage ofinvalid refactorings among all refactorings in all solutions inthat generation. We also measured the percentage of invalidrefactorings per solution in each generation to see the distri-bution of invalid refactorings across solutions.
TABLE II: Open-source projects studied.
System Release # of Classes KLOC
ArgoUML v0.3 1358 114
JHotDraw v7.5.1 585 25
GanttProject v1.11.1 245 49
Apache Ant v1.8.2 1191 112
To answer item RQ2, we compared the three algorithms
in terms of execution time, performance indicators, and im-provement in quality metrics of the Pareto-front solutions.Due to the stochastic and non-deterministic nature of meta-heuristic algorithms, different runs of the same algorithmsolving the same problem typically give different outcomes.For this reason, we performed 30 runs for each algorithmon each project to make sure that the results are statisticallysigniÔ¨Åcant.
Finally, to answer item RQ3, we conducted a survey with
a group of 14 active developers to identify and manuallyevaluate the relevance of the refactorings generated by ourapproach. At the top of the criteria mentioned above, theprojects used for answering item RQ1 were selected since
the participants are familiar with them so they can providerelevant feedback given their knowledge.
B. Evaluation Metrics
We validate our results using the following metrics.
772 ./
 / /- !/*-$)" + ) )$ .
-/œ∂- +-* ..$)"/*$(+-*1  ./-/œ∂- +-* ..$)"2*-./	  


	
 

   !/*-$)""-+#.
 ./-*0+- !/*-$)".$)/*'*&.
	
  
% /$1 œ¨ % /$1 œ≠ % /$1 œ´'0'/ 2 &) .. .œ∑$)/#$.. 
*)'4*% /$1 œ¨$.2 &) ..2*-./
 / /- !/*-$)" + ) )$ .  
 

 
 !/*-$)""-+#.
2*-./-*0+- !/*-$)".$)/*'*&.
  *-/'*&.. *) #'*&–Ä.
+*/ )/$'/*$(+-*1 *% /$1 œ¨$) ./ ./
 -!*-(.$)"' 
+*$)/-*..*1 -
*!)'*&.
-/œ∂# $)/ ''$" )/-*..*1 -	
  
  
  
	
  –Ä ./
–Ä2*-./
$&-)*(
)0( - /2  )œ´
)/# )0( -*!
'*&.*!
–Äœ∑
œ¨$)/#$.. 


–Ä
Fig. 3: An illustration of the intelligent crossover.

-/œ∂ / /- !/*-$)" + ) )$ .	  


	
 

 !/*-$)""-+#. !/*-$)""-+#.
-/œ∂ / /(0/' - !/*-$)".

	
 

	  
,QYDOLGUHIDFWRULQJ

)*('4. ' /(0/' 
- !/*-$)".–ñœ≠$)/#$.
$''0./-/$*)–ó)(0// /# (
-/œ∂0// -)*((0/' - !/*-$)".0// 
	  'HSHQGVRQ
	
  
0XWDEOH
UHIDFWRULQJV00XWDEOH
UHIDFWRULQJV0
Fig. 4: An illustration of the dependency-aware mutation.
For item RQ1, we want to estimate the correctness of
the solutions generated by the three algorithms. For that, we
compute the percentage of invalid refactorings in each gen-eration by inspecting the validity of pre- and post-conditionsof each refactoring operation. These conditions are discussedby Opdyke et al. [36]. The exhaustive list can be found inthe online appendix [5]. We also computed the percentage ofinvalid refactorings per refactoring solution generated by thethree algorithms at each generation.
For item RQ2, we use the following three metrics as
performance indicators to evaluate the quality of solutionsgenerated by the three algorithms:
‚Ä¢Contributions (IC) [14] measures the proportion of solu-
tions that lie on the reference front (RS) [28]. The higherthis proportion, the better the quality of solutions.
‚Ä¢Inverted Generational Distance (IGD) [48] is a conver-
gence measure that corresponds to the average Euclideandistance between the approximate Pareto-front providedby an algorithm and the reference Pareto-front. Smallvalues are desirable.
‚Ä¢Hypervolume (IHV) [52] measures the volume covered
by members of a Pareto-front in objective space delimitedby a reference point. An important feature of this metricis its ability to capture diversity and convergence ofsolutions. A higher hypervolume value is desirable.We also calculated another metric based on QMOOD that
estimates the quality improvement for the project by compar-ing the quality before and after refactorings generated by thethree algorithms. For each refactoring solution S, the quality
improvement after applying Sis estimated as:
QS=6/summationdisplay
i=1Qqiwhere Q qi=q/prime
i‚àíqi (2)
whereqiandq/prime
irepresent the value of QMOOD quality
attribute ibefore and after applying S, respectively. For
each algorithm, we average the normalized quality improve-ments across solutions in the Pareto-front generated by eachalgorithm and we compare them. In addition, we compute theexecution time of each generation using the three algorithms.
Finally, for item RQ3, we validated the generated refactor-
ing solutions quantitatively and qualitatively. For qualitativeassessment, we compared our solutions to a baseline of solu-tions generated by other multi-objective techniques [19], [42],[38], [29] and by JDeodorant [46], a tool not based on heuristicsearch. All the search-based refactoring techniques are basedon multi-objective search, but each uses different objectivesand solution representations. All use the same random changeoperators, which helps to conÔ¨Årm whether good recommenda-tions result from using our intelligent change operators. The
773current Eclipse plug-in version of JDeodorant identiÔ¨Åes some
types of design defects using quality metrics and proposesa list of refactorings to Ô¨Åx them. For the comparison withJDeodorant, we limited the comparison to the same refactor-ing types supported by both our approach and JDeodorant.For the quantitative assessment, we calculated precision andrecall scores by comparing the refactorings recommended byeach of the multi-objective algorithms and JDeodorant withthose refactoring manually suggested by the participants (theexpected refactorings).
P recision =Recommended Refactorings ‚à©Expected Refactorings
Recommended Refactorings
(3)
Recall =Recommended Refactorings ‚à©Expected Refactorings
Expected Refactorings
(4)
After the developers manually suggested refactorings for the
projects, we asked them to evaluate the tools‚Äô recommenda-tions since their suggestions may not be the only reasonablesolution. We asked the participants to assign 0 or 1 toevery refactoring solutions generated by the multi-objectivealgorithms and JDeodorant. A 0 means that the refactoringis not relevant or invalid, and 1 means that the refactoring ismeaningful and relevant.
We computed manual correctness as the number of mean-
ingful refactorings divided by the total number of recom-mended refactorings. Meaningful refactorings were identiÔ¨Åedby considering the majority opinion across participants foreach refactoring.
Manual Correctness =|Meaningful Refactorings|
|Recommended Refactorings|(5)
C. Parameters Tuning
In order to fairly compare the results among the three
algorithms in Table I and the multi-objective algorithms usedin our survey [19], [42], [38], [29], we performed the samenumber of evaluations per run (3k) and used the same initialpopulation size (100). We used the maximum number ofevaluations as our stopping criterion. The crossover and mu-tation probabilities are set to 0.95 and 0.02 respectively. Theminimum and maximum number of refactorings per solutionsare set to 100 and 200, respectively.
D. Subjects
We evaluated our approach with 14 active industry devel-
opers who volunteered to participate in our survey as part
of an industry-sponsored research collaboration. We selectedindividuals with extensive experience applying refactorings inindustry and using the selected open source projects in theirwork. Each Ô¨Ålled out a pre-study survey that collects back-ground information, such as their programming experience andtheir role within their companies.
We divided the participants into four groups balancing
skill level and familiarity with the open source projects. Thedetails of the participants and the projects they evaluated arefound in Table III. We gave participants a two-hour lectureabout software quality assessment and refactoring. Duringthe two-hour lecture, we did not reveal to the participantswhich refactorings were generated by which app to avoidany possible bias. We provided general knowledge regardingrefactoring and showed them how to read and interpret therefactoring solutions and focused on explaining the requiredsteps to complete the survey.
We assessed their knowledge on the open source projects
and their performance in evaluating and suggesting refactoringsolutions. The participants were asked to assess the correctnessand relevance of the refactorings recommended by the multi-objective algorithms [19], [42], [38], [29] and JDeodorant [46]on all four projects. They were shown refactoring recommen-dations per project without knowing where the recommenda-tions came from.
Since the multi-objective algorithms generate many refac-
toring solutions in the Pareto-front, it was not feasible toask the participants to evaluate all the solutions. Therefore,to perform meaningful and fair comparisons for each projectand algorithm, we selected the solution using a knee-pointstrategy [50]. The knee point corresponds to the solution withthe maximal trade-off among the objectives, which could beseen as the mono-objective solution with equally weightedobjectives if the objectives do not conÔ¨Çict. Thus, we selectedthe solution with the median hypervolume IHV value. Theaverage number of refactorings evaluated by each participantis 58. We ensured that each refactoring was evaluated by twodevelopers, and we considered it relevant if both agreed (theoverall Cohen‚Äôs kappa was 0.91).
TABLE III: Participant Details.
System#o f
SubjectsAvg. Prog.
Experience (Y ears)Refactoring
Experience
ArgoUML 4 10 High
JHotDraw 3 11.5 V ery High
GanttProject 3 10.5 High
Apache Ant 4 12 V ery High
E. Results
1) RQ1: Correctness: Figure 5 shows the percentage of
invalid refactorings across all solutions in each generation foreach algorithm for each open source project. All algorithmshave 100 non-dominated solutions in the Ô¨Ånal Pareto-front.
The highest percentages of invalid refactorings for all
projects was produced by NSGA-II, though it does reducethe percentage of invalid refactorings by a negligible amountas generations progress. Dep-NSGA-II reduces the percentageof invalid refactorings compared to regular NSGA-II [29] by44.34%, 34.42%, 39.77%, and 37.29% for Ant, ArgoUML,Gantt, and JHotDraw, respectively. Intel-NSGA-II, however,outperformed the other algorithms and reduces the percentageof invalid refactorings compared to NSGA-II [29] by 71.52%,61.15%, 67.43%, and 61.95% for Ant, ArgoUML, Gantt,and JHotDraw, respectively. Intel-NSGA-II also reduces the
774 0 0.05 0.1 0.15 0.2 0.25 0.3
 0 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30% of Invalid Refactorings
GenerationsNSGA-II Dep-NSGA-II Intel-NSGA-II
(a) ArgoUML. 0 0.05 0.1 0.15 0.2 0.25 0.3
 0 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30% of Invalid Refactorings
GenerationsNSGA-II Dep-NSGA-II Intel-NSGA-II
(b) Ant.
 0 0.05 0.1 0.15 0.2 0.25 0.3
 0 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30% of Invalid Refactorings
GenerationsNSGA-II Dep-NSGA-II Intel-NSGA-II
(c) Gantt. 0 0.05 0.1 0.15 0.2 0.25 0.3
 0 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30% of Invalid Refactorings
GenerationsNSGA-II Dep-NSGA-II Intel-NSGA-II
(d) JHotDraw.
Fig. 5: Percentage of invalid refactorings across all solutions per generation for NSGA-II, Dep-NSGA-II, and Intel-NSGA-II.
 0 0.1 0.2 0.3 0.4
 0  2  4  6  8 10  12  14  16  18  20  22  24  26  28  30% of Invalid Refactorings
 in Refactoring Solutions
GenerationsNSGA-II DEP-NSGA-II Intel-NSGA-II
(a) ArgoUML 0 0.1 0.2 0.3 0.4
 0  2  4  6  8 10  12  14  16  18  20  22  24  26  28  30% of Invalid Refactorings
 in Refactoring Solutions
GenerationsNSGA-II DEP-NSGA-II Intel-NSGA-II
(b) Ant
 0 0.1 0.2 0.3 0.4
 0  2  4  6  8 10  12  14  16  18  20  22  24  26  28  30% of Invalid Refactorings
 in Refactoring Solutions
GenerationsNSGA-II DEP-NSGA-II Intel-NSGA-II
(c) Gantt 0 0.1 0.2 0.3 0.4
 0  2  4  6  8 10  12  14  16  18  20  22  24  26  28  30% of Invalid Refactorings
 in Refactoring Solutions
GenerationsNSGA-II DEP-NSGA-II Intel-NSGA-II
(d) JHotDraw
Fig. 6: Percentage of invalid refactorings in refactoring solutions using NSGA-II, Dep-NSGA-II, and Intel-NSGA-II.
percentage of invalid refactorings more quickly than the other
algorithms at the population level.
Also, Figure 5 reveals that NSGA-II generates a roughly
constant percentage of invalid refactorings equal to or greaterthan 25%. By introducing the dependency-aware change op-erators, Dep-NSGA-II reduced the number of invalid refac-torings to roughly 15% in the 30th generation. Figure 5 alsoreveals a major decrease in the number of invalid refactorings
775caused by Intel-NSGA-II in the Ô¨Årst 12 generations; then it
becomes roughly constant and equal to less than 10%. Thus,the number of generations to reach a stable fraction of invalidrefactorings is almost the same per algorithm independentlyfrom the evaluated project.
Finally, we examined the impact of our proposed change
operators at the solution level. Figure 6 shows the distributionof the percentage of invalid refactorings within solutions. Intel-NSGA-II achieves the lowest percentage of invalid refactoringsin solutions across all generations for all projects followed byDep-NSGA-II and NSGA-II, respectively.
·Ωë1Key Ô¨Åndings: Intel-NSGA-II reduces the percentage
of invalid refactorings in the population and refactoringsolutions by an average of 65.51% and 43.71% comparedto NSGA-II [29] and Dep-NSGA-II, respectively.
TABLE IV: Performance indicators results for NSGA-II, Dep-NSGA-II, and Intel-NSGA-II.
System Algorithm IC IGD IHV
ArgoUMLNSGA-II 0.0172 0.0343¬±0.0342 0.0222¬±0.0205
Dep-NSGA-II 0.3172 0.0303¬±0.0081 0.0349¬±0.0186
Intel-NSGA-II 0.6655 0.0262¬±0.0078 0.0801¬±0.0855
AntNSGA-II 0.0041 0.0242¬±0.0049 0.0176¬±0.0205
Dep-NSGA-II 0.1632 0.0205¬±0.0047 0.0329¬±0.0119
Intel-NSGA-II 0.8326 0.0122¬±0.0035 0.1080¬±0.0555
GanttProjectNSGA-II 0.0036 0.0205¬±0.0027 0.0218¬±0.0111
Dep-NSGA-II 0.1749 0.0193¬±0.0037 0.0302¬±0.0209
Intel-NSGA-II 0.8215 0.0103¬±0.0024 0.1191¬±0.0536
JHotDrawNSGA-II 0.1044 0.0253¬±0.0050 0.0266¬±0.0214
Dep-NSGA-II 0.0413 0.0225¬±0.0040 0.0349¬±0.0175
Intel-NSGA-II 0.8544 0.0136¬±0.0036 0.1341¬±0.0635
2) RQ2: Quality: Table IV shows the average IC,IGD, and
IHV of the 30 runs of the three algorithms. The values in bold
are the best values achieved for each performance indicator perproject. Intel-NSGA-II achieved the highest I
HV andICand
the lowest IGD for all projects. Dep-NSGA-II was able to
improve the IHV,IC,IGD compared to NSGA-II by up to
86.93%, 4758.33%, and 15.28%, respectively. Intel-NSGA-IIwas able to improve the I
HV,IC,IGD compared to NSGA-
II by up to 513.63%, 22719.44%, and 49.75%, respectively.This shows that Intel-NSGA-II produces better convergence
and diversity than the other algorithms.
Table V shows the average quality improvement of solu-
tions, as well as their standard deviations. The bold values arethe best values obtained for each metric for each project. Intel-
NSGA-II produced the best quality improvement in almost all
cases. NSGA-II produced the lowest quality improvement in 18
out of 24 cases. Dep-NSGA-II was able to improve the Effec-
tiveness, Extendibility, Flexibility, Functionality, Reusability,and Understandability compared to NSGA-II by an average of
13.31%, 51.89%, 5.61%, 2.07%, 2.28%, 9.54%, respectively.Intel-NSGA-II was able to improve the Effectiveness, Ex-
tendibility, Flexibility, Functionality, Reusability, and Under-standability compared to NSGA-II by an average of 17.86%,
46.94%, 83.96%, 64.94%, 57.87%, and 3.54%, respectively.This demonstrates that our intelligent crossover strategy thattargets Ô¨Åxing a solution‚Äôs weaknesses leads to higher qualitysolutions in the Ô¨Ånal Pareto-front. There is, however, a per-formance penalty for the extra work performed by intelligentchange operators; on average, execution time doubled. In mostcases, this is a more than acceptable trade-off for higher qualityrefactoring recommendations.
We noticed that NSGA-II never produced the best quality
improvement in any cases, which means that the dependency-aware change operators play a signiÔ¨Åcant role in improvingthe quality of the Pareto-front. In addition, whenever Intel-NSGA-II does not produce ‚Äúthe best quality improvement‚Äù,the difference between the quality values of Intel-NSGA-II andDep-NSGA-II is very small. Indeed, the quality improvementsrate depends on the number of code smells, size and evolutionof the analyzed projects. In our future work, we are planningto validate our approach using more projects to have a clearerunderstanding of when and why Intel-NSGA-II does notproduce ‚Äúthe best quality improvement‚Äù.
·Ωë1 Key Ô¨Åndings: Intel-NSGA-II outperforms the other
algorithms in terms of diversity, convergence, and qualityimprovement of the Pareto-front using the different evalu-ation metrics I
C,IGD, andIHV by at least 50% with a
modest sacriÔ¨Åce in execution time.
3) RQ3: Relevance: Figure 7 presents the results of man-
ual correctness, precision, and recall for our Intel-NSGA-IIalgorithm and state of the art refactoring techniques. Thedetailed responses of the 14 participants can be found in ourappendix [5]. Intel-NSGA-II achieved better manual evaluationscores than [29] and existing approaches in all the metrics forall projects. Indeed, the average manual correctness, precisionand recall of our algorithm compared to that of Mkaoueret al. [29] are 0.89, 0.82, and 0.87 to 0.67, 0.56, and 0.67respectively and much better than the remaining tools. Thus,the participants found our refactoring recommendations appli-cable and consistent with the source code and their designissues. All participants agreed on the beneÔ¨Åts of consideringdependencies among refactorings when generating refactoringsolutions. They mentioned that Intel-NSGA-II increases theirtrust in refactoring tools and would save them time and efforton Ô¨Åltering out invalid refactorings.
·Ωë1Key Ô¨Åndings: Intel-NSGA-II provided more relevant
and meaningful refactorings than state of the art refactoringrecommendation techniques based on manual evaluation ofrecommended refactorings.
IV . T HREA TS TO VALIDITY
Conclusion validity. We used Design of Experiments
(DoE) [23] to mitigate the threat related to parameter tuning.DoE is a methodology for systematically applying statisticsto experimentation and is one of the most efÔ¨Åcient techniquesfor tuning parameter settings of evolutionary algorithms. Eachparameter has been uniformly discretized in intervals. Tomitigate the stochastic nature of the search algorithms, we
776TABLE V: Average quality improvement of the solutions generated by NSGA-II, Dep-NSGA-II, and Intel-NSGA-II.
System Algorithm Effectiveness Extendibility Flexibility Functionality Reusability Understandability
ArgoUMLNSGA-II 0.0557¬±0.0147 0.1484¬±0.0335 0.0077¬±0.0077 0.0077¬±0.0042 0.0130¬± 0.0051 0.0260¬± 0.0099
Dep-NSGA-II 0.0615¬±0.0112 0.1639¬±0.0297 0.0109¬±0.0084 0.0082¬±0.0045 0.0129¬±0.0054 0.0255¬±0.0098
Intel-NSGA-II 0.0646¬±0.0174 0.1798¬±0.0332 0.0094¬±0.0104 0.0115¬±0.0045 0.0206¬±0.0035 0.0302¬±0.0095
Apache AntNSGA-II 0.0177¬±0.0049 0.0296¬±0.0112 0.0073¬±0.0088 0.0070¬±0.0046 0.0086¬±0.0021 0.0125¬±0.0074
Dep-NSGA-II 0.0214¬±0.0050 0.0362¬±0.0098 0.0086¬±0.0085 0.0083¬±0.0046 0.0099¬±0.0020 0.0136¬±0.0072
Intel-NSGA-II 0.0230¬±0.0054 0.0338¬±0.0098 0.0164¬±0.0111 0.0123¬±0.0055 0.0139¬±0.0022 0.0119¬±0.0083
GanttProjectNSGA-II 0.0285¬±0.0077 0.0677¬±0.0168 0.0045¬±0.0093 0.0059¬±0.0048 0.0080¬±0.0029 0.0098¬±0.0080
Dep-NSGA-II 0.0340¬±0.0077 0.0775¬±0.0166 0.0046¬±0.0107 0.0067¬±0.0052 0.0094¬±0.0026 0.0124¬±0.0095
Intel-NSGA-II 0.0335¬±0.0097 0.0710¬±0.0195 0.0120¬±0.0153 0.0123¬±0.0073 0.0147¬±0.0033 0.0093¬±0.0124
JHotDrawNSGA-II 0.0451¬±0.0074 0.1028¬±0.0175 0.0138¬±0.0109 0.0122¬±0.0047 0.0141¬±0.0028 0.0126¬±0.0117
Dep-NSGA-II 0.0463¬±0.0079 0.1058¬±0.0191 0.0084¬±0.0102 0.0085¬±0.0054 0.0109¬±0.0040 0.0132¬±0.0084
Intel-NSGA-II 0.0487¬±0.0111 0.1062¬±0.0193 0.0169¬±0.0176 0.0154¬±0.0084 0.0180¬±0.0041 0.0136¬±0.0137
MC-Intel-NSGA-II
MC-Mkaouer et al.
MC-Harman et al.
MC-Ouni et al.
MC-Mel et al.
MC-JDeodorant
PR-Intel-NSGA-II
PR-Mkaouer et al.
PR-Harman et al.
PR-Ouni et al.
PR-Mel et al.
PR-JDeodorant
RC-Intel-NSGA-II
RC-Mkaouer et al.
RC-Harman et al.
RC-Ouni et al.
RC-Mel et al.
RC-JDeodorant
 0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1  1.1  1. 2ArgoUML
JHotDraw
GanttProject
Apache Ant
Fig. 7: Manual evaluation of refactoring recommendations
generated by the existing multi-objective techniques [19], [42],[38], [29] and the JDeodorant Eclipse plugin [46]).
performed 30 runs per project and algorithm and analyzed the
mean results along with the appropriate statistical tests usingthe Wilcoxon test with a 95% conÔ¨Ådence level (Œ±< 5%).
Internal validity. V alidation exercise participants had dif-
ferent programming skills and familiarity with refactoringtools. To counter this, we assigned developers to groupsaccording to their experience to reduce the gap between thegroups and we adopted a counter-balanced design. Asking theparticipants to evaluate the refactoring recommendations forall projects would be too much work for them and wouldreduce the quality of the survey responses. For this reason, wedivided the participants into four groups balancing skill leveland familiarity with the open-source projects and we askedeach one of them to evaluate a single project. We groupedthe participants based on their familiarity with the projectsto be evaluated. Indeed, it is critical that the participants areknowledgeable about the code of the evaluated projects sothey can make accurate judgment about the recommendedrefactorings. Also, the relatively small number of participantscould also be considered a threat to validity. We selected 14developers to participate in our validation, targeting developerswith knowledge of the studied projects. In-depth interviewswith a relatively small number of developers familiar withthe studied projects yields deep, quality insights that are moreuseful than those extracted using an online survey with randomparticipants who are not familiar with the studied projects.
Construct validity. Developers might have different opin-
ions about the relevance of recommended refactorings, whichmay impact our results. Some might think that it is importantto refactor, while others might think otherwise. To mitigatethis threat, we ensured that each refactoring was evaluated bytwo developers, and we considered it relevant if both agreed.The overall Cohen‚Äôs kappa was 0.91 which conÔ¨Årms that thereis a signiÔ¨Åcant consensus among developers.
External threats. External threats concern the generaliza-
tion of our Ô¨Åndings. Our validation includes only four projects.One reason for this is to attract more quality responses fromsurvey participants. The more tedious the task that participantsmust complete, the lower the quality of their responses. Thesecond reason is that running all of the algorithms on all ofthe projects 30 times takes considerable time.
V. R
ELA TED WORK
A. Search-Based Software Refactoring
Many studies have used search-based techniques to au-
tomate software refactoring by optimizing different sets ofquality metrics [19], [18], [33], [42], [38], [29]. Kessentini etal. [21] proposed a single-objective combinatorial optimiza-tion using a genetic algorithm to Ô¨Ånd the best sequence ofrefactoring operations that improve the quality of the code byminimizing as much as possible the number of design defectsin the source code. Harman and Tratt [19] were the Ô¨Årst touse the concept of Pareto optimality in search-based softwarerefactoring to address conÔ¨Çicting quality objectives such ascoupling and cohesion. They showed that their multi-objectivetechnique generates better results than a mono-objective ap-proach. Cinn√©ide et al. [33] also proposed multi-objectivesearch-based refactoring to conduct an empirical investigationto explore relationships between several structural metrics.
777They used different search techniques, such as Pareto-optimal
search and semi-random search guided by a set of cohesionmetrics. Ouni et al. [37] presented a multi-objective refactoringapproach to minimize the number of detected defects andmaximize the semantic similarity of code elements.
All the above studies used traditional random change op-
erators (e.g. 1-point crossover, random mutation, etc.) thatcan destroy relevant patterns inside good refactoring solutionswhen applied randomly, as illustrated in the validation section.
B. Refactoring Dependencies
Chavez et al. [10] investigated how refactoring types affect
Ô¨Åve quality attributes based on the version history of 23
open source projects. They found that 94% of refactorings areapplied to code with at least one low quality attribute value,with 65% of refactorings improving attributes and 35% of allrefactorings being neutral on the system. Similarly, Cinn√©ide etal. [33] studied the impact of individual refactorings on qualityattributes, such as using Move Method to reduce the couplingof a class. None of these studies considered the impact of asequence of refactorings on quality attributes.
Bibiano et al. [9] analyzed batch refactoring characteristics
and their effects on code smells in open and closed sourceprojects and concluded that 57% of batches/patterns are simplecompositions of only two types of refactorings. They high-light lack of tool support to automatically detect refactoringdependencies as a barrier. However, this study is based onthe assumption that refactorings are only related if applied tothe same code location, which often is not the case for typesof refactorings that modify multiple code fragments. Menset al. [27] analyzed dependencies at the model-level workingwith UML. Our work is at the code-level working directly withtransformations on the code rather than on UML models wherethe type of refactorings are different and simpliÔ¨Åed whencompared to the code-level refactorings. Overall, existing stud-ies mainly deÔ¨Åne what might be better considered similarityrelations, such as a collection of refactorings that have similareffects (Ô¨Åxing a code smell) or similar context (applied bythe same developer or to the same code location) [26], [49].None of the existing studies rigorously deÔ¨Åne refactoringdependencies to integrate them into recommendation tools,including search-based refactoring.
C. Genetic Operators in Search-Based Software Engineering
Search-based software engineering studies proposed few
studies on improving the change operators in order to optimize
the performance and convergence of search algorithms as wellas the quality of generated solutions. However, none of themaddressed the refactoring problem or designed new changeoperators to deal with the issues of solution correctness orthe impact of random change operators on solution quality.Oliveira et al. [35] propose a reformulation of program repairoperators such that they explicitly traverse three subspaces thatunderlie the search problem (i.e. Operator, Fault Space, andFix Space). They implemented new crossover operators thatrespect the subspace division.Zhu et al. [51] propose two mechanisms to avoid premature
convergence of genetic algorithms: i) dynamic application ofcrossover and mutation operators; and ii) population partialre-initialization. They implemented two crossover and twomutation operators and, dynamically choose one crossover andone mutation operators to apply in each generation, based ona selection probability that is dependent on average progress.Abido et al. [1] propose improved crossover and mutationalgorithms to directly devise feasible offspring chromosomes.
VI. C
ONCLUSION
To improve the correctness and quality of refactoring rec-
ommendations and increase developer trust in search-basedrefactoring recommendation tools, we proposed a dependency-aware multi-objective refactoring approach with intelligentchange operators that Ô¨Ånd a balance among quality objec-tives while reducing the number of invalid refactorings. Weevaluated this approach on four open-source projects. Wecompared our results to existing refactoring techniques that userandom change operators, as well as to a dependency-awaretechnique, to understand the impact of considering refactoringdependencies and Ô¨Åxing quality weaknesses in refactoringsolutions. The comparisons show that our proposed approachperforms signiÔ¨Åcantly better than the baselines in terms ofconvergence, diversity, and correctness with a reasonable costin terms of increased execution time. The survey with 14practitioners conÔ¨Årmed the relevance of our approach.
For future work, we plan to validate this study with ad-
ditional programming languages, developers, and projects togeneralize our results. We also plan to implement an intel-ligent mutation operator that targets Ô¨Åxing quality objectivesin refactoring solutions. Also, we intend to investigate howmany refactoring operations actually depend on each other andhow many operations can be executed independently. Anotherresearch direction could be to explore further techniques toimplement the change operators and compare them with eachother. In fact, there are multiple ways of how we choose therefactorings that participate in the mutation and the crossoverprocesses as well as how we perform the change opera-tors. There is a practical balance to study between smartermutations (more expensive, but more reliable) vs. simpler,more error prone mutations (faster, but not guaranteed). Thisoperation shows beneÔ¨Åts from introducing modest constraintsin the selection of mutable refactorings. There are certainlyother variants that explore different trade-offs between speedand error reduction and that is just for mutating a singlerefactoring at a time.
A
CKNOWLEDGEMENTS
This material is based upon work funded and supported by
the Department of Defense under Contract No. FA8702-15-D-0002 with Carnegie Mellon University for the operation ofthe Software Engineering Institute, a federally funded researchand development center. DM21-0720
778REFERENCES
[1] M. A. Abido and A. Elazouni. Improved crossover and mutation
operators for genetic-algorithm project scheduling. In 2009 IEEE
Congress on Evolutionary Computation, pages 1865‚Äì1872. IEEE, 2009.
[2] W. Afzal, R. Torkar, and R. Feldt. A systematic review of search-based
testing for non-functional system properties. Information and Software
Technology, 51(6):957‚Äì976, 2009.
[3] V . Alizadeh and M. Kessentini. Reducing interactive refactoring effort
via clustering-based multi-objective search. In Proceedings of the 33rd
ACM/IEEE International Conference on Automated Software Engineer-
ing, pages 464‚Äì474, 2018.
[4] V . Alizadeh, M. Kessentini, W. Mkaouer, M. Ocinneide, A. Ouni,
and Y . Cai. An interactive and dynamic search-based approach tosoftware refactoring recommendations. IEEE Transactions on Software
Engineering, 2018.
[5] Anonymous Authors(s). Study appendix, 2021. https://sites.google.com/
view/asedependency.
[6] J. Bansiya and C. G. Davis. A hierarchical model for object-oriented
design quality assessment. IEEE Transactions on Software Engineering,
28(1):4‚Äì17, 2002.
[7] G. Bavota, A. D. Lucia, A. Marcus, and R. Oliveto. Recommending
refactoring operations in large software systems. In Recommendation
Systems in Software Engineering, pages 387‚Äì419. Springer Berlin Hei-delberg, Berlin, Heidelberg, 2014.
[8] G. Bavota, A. D. Lucia, M. D. Penta, R. Oliveto, and F. Palomba. An
experimental investigation on the innate relationship between quality andrefactoring. Journal of Systems and Software, 107:1‚Äì14, 2015.
[9] A. C. Bibiano, E. Fernandes, D. Oliveira, A. Garcia, M. Kalinowski,
B. Fonseca, R. Oliveira, A. Oliveira, and D. Cedrim. A quantitativestudy on characteristics and effect of batch refactoring on code smells.InProceedings of 13th the ACM/IEEE International Symposium on
Empirical Software Engineering and Measurement (ESEM ‚Äô19), pages1‚Äì11, Porto de Galinhas, Brazil, 2019. IEEE.
[10] A. Ch√°vez, I. Ferreira, E. Fernandes, D. Cedrim, and A. Garcia.
How does refactoring affect internal quality attributes? a multi-projectstudy. In Proceedings of the 31st Brazilian Symposium on Software
Engineering (SBES ‚Äô17), pages 74‚Äî-83, Fortaleza, Brazil, 2017. ACM.
[11] S. Das, W. G. Lutters, and C. B. Seaman. Understanding documentation
value in software maintenance. In Proceedings of the 2007 Symposium
on Computer human interaction for the management of informationtechnology, pages 2‚Äìes, 2007.
[12] M. C. de Oliveira, D. Freitas, R. Bonif√°cio, G. Pinto, and D. Lo.
Finding needles in a haystack: Leveraging co-change dependencies torecommend refactorings. Journal of Systems and Software, 158:110420,
2019.
[13] K. Deb, A. Pratap, S. Agarwal, and T. Meyarivan. A fast and
elitist multiobjective genetic algorithm: Nsga-ii. IEEE transactions on
evolutionary computation, 6(2):182‚Äì197, 2002.
[14] F. Ferrucci, M. Harman, J. Ren, and F. Sarro. Not going to take this
anymore: multi-objective overtime planning for software engineeringprojects. In 2013 35th International Conference on Software Engineer-
ing (ICSE), pages 462‚Äì471. IEEE, 2013.
[15] M. Fowler. Refactoring: Improving the Design of Existing Code.
Addison-Wesley Longman Publishing Co., Inc., Boston, MA, USA,1999.
[16] M. Fowler. Refactoring: Improving the Design of Existing Programs.
Addison-Wesley Professional, 1 edition, 1999.
[17] M. Hall, N. Walkinshaw, and P . McMinn. Supervised software mod-
ularisation. In 2012 28th IEEE International Conference on Software
Maintenance (ICSM), pages 472‚Äì481. IEEE, 2012.
[18] M. Harman and P . McMinn. A theoretical and empirical study of search-
based testing: Local, global, and hybrid search. IEEE Transactions on
Software Engineering, 36(2):226‚Äì247, 2009.
[19] M. Harman and L. Tratt. Pareto optimal search based refactoring at the
design level. In Proceedings of the 9th annual conference on Genetic
and evolutionary computation, pages 1106‚Äì1113, 2007.
[20] G. Huang, H. Mei, and Q.-x. Wang. Towards software architecture at
runtime. ACM SIGSOFT Software Engineering Notes , 28(2):8, 2003.
[21] M. Kessentini, W. Kessentini, H. Sahraoui, M. Boukadoum, and A. Ouni.Design defects detection and correction by example. In 2011 IEEE
19th International Conference on Program Comprehension, pages 81‚Äì90. IEEE, 2011.[22] M. Kim, T. Zimmermann, and N. Nagappan. An empirical study of
refactoring challenges and beneÔ¨Åts at Microsoft. IEEE Transactions on
Software Engineering, 40(7):633‚Äì649, 2014.
[23] J. Koehler and A. Owen. Computer experiments. handbook of statistics.
Elsevier Science, pages 261‚Äì308, 1996.
[24] M. Kuutila, M. M√§ntyl√§, U. Farooq, and M. Claes. Time pressure in
software engineering: A systematic review. Information and Software
Technology, 121:106257, 2020.
[25] T. Mariani and S. R. V ergilio. A systematic review on search-based
refactoring. Information and Software Technology, 83:14‚Äì34, 2017.
[26] H. Melton and E. Tempero. Identifying refactoring opportunities by
identifying dependency cycles. In Proceedings of the 29th Australasian
Computer Science Conference (ACSC ‚Äô06), pages 35‚Äì41, Australia,2006. ACM.
[27] T. Mens, G. Taentzer, and O. Runge. Detecting structural refactoring
conÔ¨Çicts using critical pair analysis. Electronic Notes in Theoretical
Computer Science, 127(3):113‚Äì128, 2005.
[28] H. Meunier, E.-G. Talbi, and P . Reininger. A multiobjective genetic
algorithm for radio network optimization. In Proceedings of the 2000
Congress on Evolutionary Computation. CEC00 (Cat. No. 00TH8512),volume 1, pages 317‚Äì324. IEEE, 2000.
[29] M. W. Mkaouer, M. Kessentini, S. Bechikh, M. √ì. Cinn√©ide, and
K. Deb. On the use of many quality attributes for software refactoring: amany-objective search-based software engineering approach. Empirical
Software Engineering, 21(6):2503‚Äì2545, 2016.
[30] M. W. Mkaouer, M. Kessentini, M. √ì. Cinn√©ide, S. Hayashi, and K. Deb.
A robust multi-objective approach to balance severity and importance ofrefactoring opportunities. Empirical Software Engineering, 22(2):894‚Äì
927, 2017.
[31] M. Mohan and D. Greer. A survey of search-based refactoring for
software maintenance. Journal of Software Engineering Research and
Development, 6(1):3, 2018.
[32] E. Murphy-Hill, C. Parnin, and A. P . Black. How we refactor, and how
we know it. IEEE Transactions on Software Engineering, 38(1):5‚Äì18,
2012.
[33] M. √ì Cinn√©ide, L. Tratt, M. Harman, S. Counsell, and
I. Hemati Moghadam. Experimental assessment of software metricsusing automated refactoring. In Proceedings of the ACM-IEEE
international symposium on Empirical software engineering andmeasurement, pages 49‚Äì58, 2012.
[34] M. O‚ÄôKeeffe and M. O. Cinn√©ide. A stochastic approach to automated
design improvement. In Proceedings of the 2nd International Conference
on Principles and Practice of Programming in Java (PPPJ ‚Äô03), pages59‚Äì62, Kilkenny City, Ireland, 2003. ACM.
[35] V . P . L. Oliveira, E. F. Souza, C. Le Goues, and C. G. Camilo-
Junior. Improved crossover operators for genetic programming forprogram repair. In International Symposium on Search Based Software
Engineering, pages 112‚Äì127. Springer, 2016.
[36] W. F. Opdyke. Refactoring object-oriented frameworks. PhD thesis,
University of Illinois at Urbana-Champaign Champaign, IL, USA, 1992.
[37] A. Ouni, M. Kessentini, H. Sahraoui, and M. S. Hamdi. Search-
based refactoring: Towards semantics preservation. In 2012 28th IEEE
International Conference on Software Maintenance (ICSM), pages 347‚Äì356. IEEE, 2012.
[38] A. Ouni, M. Kessentini, H. Sahraoui, K. Inoue, and K. Deb. Multi-
criteria code refactoring using search-based software engineering: Anindustrial case study. ACM Transactions on Software Engineering and
Methodology (TOSEM), 25(3):1‚Äì53, 2016.
[39] A. Ouni, M. Kessentini, H. Sahraoui, K. Inoue, and K. Deb. Multi-
criteria code refactoring using search-based software engineering: anindustrial case study. ACM Transactions on Software Engineering and
Methodology, 25(3):23, 2016.
[40] A. Ouni, M. Kessentini, H. Sahraoui, K. Inoue, and M. S. Hamdi.
Improving multi-objective code-smells correction using developmenthistory. Journal of Systems and Software, 105:18‚Äì39, 2015.
[41] A. Ouni, R. G. Kula, M. Kessentini, T. Ishio, D. M. German, and
K. Inoue. Search-based software library recommendation using multi-objective optimization. Information and Software Technology, 83:55‚Äì75,
2017.
[42] M. O‚ÄôKeeffe and M. O. Cinn√©ide. Search-based refactoring for software
maintenance. Journal of Systems and Software, 81(4):502‚Äì516, 2008.
[43] F. Palomba, G. Bavota, M. Di Penta, R. Oliveto, A. De Lucia, and
D. Poshyvanyk. Detecting bad smells in source code using changehistory information. In 2013 28th IEEE/ACM International Conference
on Automated Software Engineering (ASE), pages 268‚Äì278. IEEE, 2013.
779[44] R. Terra, M. T. V alente, K. Czarnecki, and R. S. Bigonha. Recom-
mending refactorings to reverse software architecture erosion. In 2012
16th European Conference on Software Maintenance and Reengineering,
pages 335‚Äì340. IEEE, 2012.
[45] E. Tom, A. Aurum, and R. Vidgen. An exploration of technical debt.
Journal of Systems and Software, 86(6):1498‚Äì1516, 2013.
[46] N. Tsantalis, T. Chaikalis, and A. Chatzigeorgiou. Jdeodorant: IdentiÔ¨Åca-
tion and removal of type-checking bad smells. In 2008 12th European
Conference on Software Maintenance and Reengineering, pages 329‚Äì331. IEEE, 2008.
[47] N. Tsantalis and A. Chatzigeorgiou. IdentiÔ¨Åcation of move method
refactoring opportunities. IEEE Transactions on Software Engineering,
35(3):347‚Äì367, 2009.
[48] D. A. V an V eldhuizen and G. B. Lamont. Multiobjective evolutionary
algorithm research: A history and analysis. Technical report, Citeseer,1998.
[49] N. Y oshida, Y . Higo, T. Kamiya, S. Kusumoto, and K. Inoue. On
refactoring support based on code clone dependency relation. InProceedings of the 11th IEEE International Software Metrics Symposium(METRICS ‚Äô05), pages 10‚Äìpp, Como, Italy, 2005. IEEE.
[50] X. Zhang, Y . Tian, and Y . Jin. A knee point-driven evolutionary
algorithm for many-objective optimization. IEEE Transactions on
Evolutionary Computation, 19(6):761‚Äì776, 2014.
[51] F.-l. Zhu, H.-w. Deng, F. Li, and S.-g. Cheng. Improved crossover
operators and mutation operators to prevent premature convergence. Sci
Technol Eng, 10(6):1540‚Äì1542, 2010.
[52] E. Zitzler and L. Thiele. Multiobjective evolutionary algorithms:
a comparative case study and the strength pareto approach. IEEE
transactions on Evolutionary Computation, 3(4):257‚Äì271, 1999.
780