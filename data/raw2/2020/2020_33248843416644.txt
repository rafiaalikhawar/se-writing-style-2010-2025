Subdomain-Based Generality-Aware Debloating
Qi Xin
Georgia Institute of Technology
qxin6@gatech.eduMyeongsoo Kim
Georgia Institute of Technology
wardballoon@gatech.edu
Qirun Zhang
Georgia Institute of Technology
qrzhang@gatech.eduAlessandro Orso
Georgia Institute of Technology
orso@cc.gatech.edu
ABSTRACT
Programs are becoming increasingly complex and typically contain
an abundance of unneeded features, which can degrade the perfor-
mance and security of the software. Recently, we have witnessed a
surge of debloating techniques that aim to create a reduced version
of a program by eliminating the unneeded features therein. To de-
bloat a program, most existing techniques require a usage profile of
the program, typically provided as a set of inputs ğ¼. Unfortunately,
these techniques tend to generate a reduced program that is over-
fitted toğ¼and thus fails to behave correctly for other inputs. To
address this limitation, we propose DomGad, which has two main
advantages over existing debloating approaches. First, it produces a
reduced program that is guaranteed to work for subdomains, rather
than for specific inputs. Second, it uses stochastic optimization to
generate reduced programs that achieve a close-to-optimal trade-
off between reduction and generality (i.e., the extent to which the
reduced program is able to correctly handle inputs in its whole
domain). To assess the effectiveness of DomGad, we applied our
approach to a benchmark of ten Unix utility programs. Our results
are promising, as they show that DomGad could produce debloated
programs that achieve, on average, 50% code reduction and 95%
generality. Our results also show that DomGad performs well when
compared with two state-of-the-art debloating approaches.
CCS CONCEPTS
â€¢Software and its engineering â†’Software maintenance tools .
KEYWORDS
debloating, generality-aware, stochastic optimization
ACM Reference Format:
Qi Xin, Myeongsoo Kim, Qirun Zhang, and Alessandro Orso. 2020. Subdomain-
Based Generality-Aware Debloating. In 35th IEEE/ACM International Con-
ference on Automated Software Engineering (ASE â€™20), September 21â€“25,
2020, Virtual Event, Australia. ACM, New York, NY, USA, 13 pages. https:
//doi.org/10.1145/3324884.3416644
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
ASE â€™20, September 21â€“25, 2020, Virtual Event, Australia
Â©2020 Association for Computing Machinery.
ACM ISBN 978-1-4503-6768-4/20/09. . .$15.00
https://doi.org/10.1145/3324884.34166441 INTRODUCTION
Todayâ€™s programs are complex and provide an abundance of fea-
tures [ 31]. Typically, however, only a small fraction of these features
are commonly accessed by users [ 23], and the presence of unneces-
sary features can harm program performance, waste power, and in-
troduce security issues [ 64]. For this reason, debloating techniques,
which aim to remove unneeded features from a program and create
a reduced version of it, are becoming increasingly popular.
Given a program ğ‘ƒto be reduced, existing debloating techniques
(e.g., [ 22,41,45,55,57]) usually require a usage profile ofğ‘ƒ, typically
provided as a set of inputs ğ¼. These techniques tend to remove as
much code in ğ‘ƒas possible and generate a minimal program ğ‘ƒğ‘‘ğ‘’ğ‘
that behaves correctly for inputs in ğ¼. Because the resulting program
is only guaranteed to work for ğ¼, it is likely to be overfitted to ğ¼and
to fail for other inputs. We argue that a program that is guaranteed
to only work for specific inputs is not generally usable, as it is rarely
the case that one can provide a completely accurate usage profile.
To address this limitation of existing approaches, we propose
DomGad, a novel debloating approach that has two main advan-
tages over the state of the art. First, it produces reduced programs
that are guaranteed to handle subdomains of inputs, rather than
specific inputs; that is, DomGad produces programs that behave
correctly for every possible input that belongs to these subdomains.
Moreover, for any input that does not belong to a handled subdo-
main, the reduced programs would block the execution to avoid
unexpected behaviors (e.g., crashes), so as to achieve enhanced
robustness. In contrast, because reduced programs produced by
an input-based approach are only guaranteed to behave correctly
for specific inputs, the only way they have to avoid unexpected
behaviors is to block the execution for anyunknown input. Second,
unlike existing approaches that take reduction as the only goal for
debloating, DomGad also accounts for generality â€”the extent to
which a reduced program could correctly handle inputs in its whole
domain. Because there is a tension between reducing the size of a
program and preserving its generality, DomGad aims to strike a
balance between these two competing needs.
In our approach, we use a path ğœ‹to characterize a subdomain
of programğ‘ƒ, and use the notation D(ğœ‹)to indicate all the inputs
ofğ‘ƒthat belong to that subdomain (i.e., all the inputs that follow
the same path ğœ‹). In order to produce a reduced program ğ‘ƒâ€²that
handles a subdomain D(ğœ‹), and behaves correctly for all the inputs
in it, DomGad conservatively includes in ğ‘ƒâ€²all the code executed
along pathğœ‹. The overall goal of DomGad is to generate a reduced
programğ‘ƒâ€²that handles the set of subdomains of ğ‘ƒthat achieves
2242020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE)
ASE â€™20, September 21â€“25, 2020, Virtual Event, Australia Qi Xin, Myeongsoo Kim, Qirun Zhang, and Alessandro Orso
the best tradeoff between reduction and generality. Intuitively, as-
suming the inputs are uniformly distributed across the program
domain, this would correspond to producing a program that is as
small as possible while being able to handle as many inputs as
possible in the domain.
To achieve this goal, we formulate debloating as an optimization
problem. Specifically, given a reduced program ğ‘ƒâ€²forğ‘ƒ, we (i)
quantify its reduction ğ‘Ÿand generality ğ‘”, and (ii) define an objective
function that computes an objective score based on ğ‘Ÿandğ‘”, so as to
make the tradeoffs between those two values explicit. We then try
to identify, among all possible reduced programs ğ‘ƒâ€²in the search
space, the one with the highest objective score ( ğ‘ƒğ‘‘ğ‘’ğ‘).
While quantifying the reduction achieved by ğ‘ƒâ€²by measuring
how much code has been removed from ğ‘ƒis relatively straightfor-
ward, quantifying its generality is extremely challenging. Concep-
tually, one could identify every possible path ğœ‹inğ‘ƒâ€², and exactly
count the number of inputs that follow that path using model count-
ing [ 19]. Unfortunately, however, this is typically infeasible, as the
number of paths within ğ‘ƒâ€²is generally unbounded, and model
counting is complex and has conceptual limitations [ 19]. We there-
fore propose a practical technique that is based on the key insight
that it is possible to model the underlying input distribution of
ğ‘ƒâ€™s domain and leverage a sampling-based approach. Specifically,
DomGad (i) draws samples from the input distribution trying to
identify a finite set of paths Î that can cover a significant fraction
of inputs in the entire domain (i.e., it makes sense to focus on Î 
when debloating ğ‘ƒ) and (ii) estimates the size of the subdomain
corresponding to each path ğœ‹âˆˆÎ based on the number of sampled
inputs that result in that path. Although our sampling-based ap-
proach can only compute an approximation of the generality of a
givenğ‘ƒâ€², it is possible to bound the error of the computed solution.
Therefore, given enough samples, our approach can yield results
with an estimation error being arbitrarily small.
Our overall debloating process works as follows. DomGad takes
as inputs a program ğ‘ƒand an input sampler ğ¼ğ‘†that models the
inputs distribution in ğ‘ƒâ€™s domain and generates input samples.
Given these inputs, DomGad performs three main steps: (1) path
identification, (2) path quantification, and (3) stochastic optimization.
In the first step, DomGad invokesğ¼ğ‘†to generate input samples and
identify a finite set of paths Î that cover, with high confidence,
a fraction of inputs in the domain whose combined probability
is no less than a given lower bound. In the second step, DomGad
invokesğ¼ğ‘†again to generate additional input samples, which it uses
to estimate, for each ğœ‹âˆˆÎ , the size of the subdomain characterized
byğœ‹. Based on these estimates, DomGad computes, for any reduced
programğ‘ƒâ€²it generates that preserves a subset of paths of Î , the
generality of ğ‘ƒâ€². In this step, DomGad also computes the reduction
forğ‘ƒâ€², by comparing its size and attack surface (measured in terms
of ROP gadgets [ 54]) with those of the original program ğ‘ƒ. Finally,
in the third step, DomGad applies an MCMC-based approach [ 18]
to perform stochastic optimization, with the goal of producing a
debloated program ğ‘ƒğ‘‘ğ‘’ğ‘that achieves an optimal tradeoff between
reduction and generality.
To assess the usefulness of DomGad, we implemented the tech-
nique in a prototype tool and applied it to a benchmark of ten
Unix utility programs used in previous work [ 11]. We compared
DomGad with Debop [61], a generality-aware debloating techniqueTable 1: Paths identified for program chown.
Path Input PathProb
0 uid:sudo sf 0.146
1 -h uid:uid f 0.14
2 -h uid:uid sf 0.147
3 uid:uid d/d/d/f 0.29
4 uid:uid f 0.139
5 -R uid:sudo f 0.139
uid: user id; sf: symbolic file; f: file; d: directory.
that we developed in previous work, and Chisel [22], a state-of-
the-art debloating technique that focuses exclusively on reduction.
Our results are promising. DomGad was able to produce a reduced
program that achieves, on average, 50% code reduction and 95%
generality. Moreover, DomGad outperformed Debop in terms of
generating programs with better tradeoffs between reduction and
generality. Finally, DomGad was able to achieve reduction results
comparable to those of Chisel, which does not consider generality.
The main contributions of this paper are:
â€¢A new subdomain-based, generality-aware debloating tech-
nique, DomGad, that uses stochastic optimization to gener-
ate debloated programs that achieve good tradeoffs between
reduction and generality.
â€¢An empirical evaluation that shows the effectiveness of
our technique and confirms that it is possible to perform
generality-aware debloating.
â€¢A prototype implementation of DomGad that is publicly
available, together with our experiment infrastructure (see
https://sites.google.com/view/domgad/).
2 ILLUSTRATIVE EXAMPLE
In this section we show, as an example, how DomGad debloats
chown (v.8.2), a Unix utility that changes the user and group own-
ership of a file. chown is one of the benchmark programs [ 11] we
used to evaluate DomGad (see Section 5.2). To apply DomGad on
chown, we developed an input sampler based on the usage profile
(i.e., set of inputs) associated with the program and provided at [ 11]
(see Section 5.2.2 for more details).
To debloat chown (ğ‘ƒ),DomGad first uses the input sampler ğ¼ğ‘†to
identify a set of paths Î that cover, with high confidence, a fraction
of inputs in the domain whose combined probability is no less than
a given lower bound ( ğ‘=0.95), as explained in Section 4.2. This
implies that the execution of ğ‘ƒbased on a random input would
yield a path in Î with a 95%probability. For chown, a significant
fraction of inputs follow a small number of paths, so the result of
this step is the selection of only six paths, shown in Table 1 together
with the inputs used to identify them.
In the second step (Section 4.3), DomGad uses again sampling
to compute the path probability ğ‘(ğœ‹)for eachğœ‹, which it uses to
estimates the size of the subdomain characterized by ğœ‹. For chown,
DomGad generates a total of ğ‘=8321 input samplesâ€”a number
of samples that allows DomGad to have an estimation error bound
within a small range ( Â±0.03) and with a high statistical confidence
(0.95). Then, for each ğœ‹,DomGad counts the number ğ‘›of sampled
inputs that exercise ğœ‹and computes ğ‘(ğœ‹)asğ‘›/ğ‘. The last column
of Table 1 shows the resulting path probability for each path in our
example.
225Subdomain-Based Generality-Aware Debloating ASE â€™20, September 21â€“25, 2020, Virtual Event, Australia
A reduced program ğ‘ƒâ€²produced by DomGad preserves a subset
of paths Î â€²âŠ†Î .DomGad computes the value of reduction ğ‘Ÿfor
ğ‘ƒâ€²in terms of size (measured as number of statements) and attack
surface (measured as number of ROP gadgets [ 54]). Conversely,
DomGad computes the value of generality ğ‘”forğ‘ƒâ€²as the sum
of the path probabilities for all paths in Î â€². As an example, the
generality of a reduced program that preserves paths Nos. 1 and
3 is0.43(0.14+0.29). Givenğ‘Ÿandğ‘”,DomGad uses an objective
function defined as (1âˆ’ğ‘˜ğ‘”)Â·ğ‘Ÿ+ğ‘˜ğ‘”Â·ğ‘”, whereğ‘˜ğ‘”âˆˆ[0,1]is a weight.
In the third step, defined in Section 4.4, DomGad uses an MCMC-
based approach to sample a number of reduced programs and iden-
tifyğ‘ƒğ‘‘ğ‘’ğ‘with the highest objective score. For chown, using ğ‘˜ğ‘”=0.3,
DomGad produces ağ‘ƒğ‘‘ğ‘’ğ‘that preserves five of the six paths (all but
path No. 5) and has ğ‘Ÿ=0.63andğ‘”=0.86; that is,ğ‘ƒğ‘‘ğ‘’ğ‘contains 37%
of the code in the original program and covers 86% of its domain,
according to the distribution modeled by ğ¼ğ‘†.
Changing the value of ğ‘˜ğ‘”allows DomGad to explore different
tradeoffs between reduction and generality. Using ğ‘˜ğ‘”=0.7, for
instance, which gives more weight to generality, DomGad produces
ğ‘ƒğ‘‘ğ‘’ğ‘that preserves all the six paths, achieving lower reduction
(ğ‘Ÿ=0.56) but higher generality ( ğ‘”=1).
3 PRELIMINARY DEFINITIONS
3.1 Subdomain and Subdomain Quantification
Given a program ğ‘ƒ, its entire input domain D, and a pathğœ‹ofğ‘ƒ, we
defineD(ğœ‹)as the subdomain of inputs that exercise ğœ‹. We assume
that the inputs of ğ‘ƒinDfollow a probability distribution with
probability density function ğ‘‘. For an input ğ‘–,ğ‘‘(ğ‘–)âˆˆ[ 0,1]measures
the likelihood of the occurrence of ğ‘–. By definition, Î£ğ‘–âˆˆDğ‘‘(ğ‘–)=1.
We use path probability ğ‘(ğœ‹)to quantify the size of D(ğœ‹), and
defineğ‘(ğœ‹)as the sum of the density values for all inputs in D(ğœ‹).
More formally, we have
ğ‘(ğœ‹)=Î£ğ‘–âˆˆD(ğœ‹)ğ‘‘(ğ‘–).
Assuming inputs in Dare uniformly distributed, ğ‘(ğœ‹)can be sim-
plified asğ‘(ğœ‹)=#D(ğœ‹)/#D,where #D(ğœ‹)is the number of inputs
that belong toD(ğœ‹)and#Dis the total number of inputs.
3.2 Reduction
We measure the reduction for a program in terms of its size and
attack surface. Given a program ğ‘ƒand its reduced version ğ‘ƒâ€², we
define the size reduction ğ‘ ğ‘Ÿğ‘’ğ‘‘ as
ğ‘ ğ‘Ÿğ‘’ğ‘‘(ğ‘ƒ,ğ‘ƒâ€²)=ğ‘ ğ‘–ğ‘§ğ‘’(ğ‘ƒ)âˆ’ğ‘ ğ‘–ğ‘§ğ‘’(ğ‘ƒâ€²)
ğ‘ ğ‘–ğ‘§ğ‘’(ğ‘ƒ),
whereğ‘ ğ‘–ğ‘§ğ‘’(Â·)measures the size of a program. Similar to [ 22], we
defineğ‘ ğ‘–ğ‘§ğ‘’(ğ‘ƒ)as the number of statements contained in ğ‘ƒ. We
define the attack surface reduction ğ‘ğ‘Ÿğ‘’ğ‘‘ as
ğ‘ğ‘Ÿğ‘’ğ‘‘(ğ‘ƒ,ğ‘ƒâ€²)=ğ‘ğ‘¡ğ‘¡ğ‘˜ğ‘ ğ‘¢ğ‘Ÿğ‘“(ğ‘ƒ)âˆ’ğ‘ğ‘¡ğ‘¡ğ‘˜ğ‘ ğ‘¢ğ‘Ÿğ‘“(ğ‘ƒâ€²)
ğ‘ğ‘¡ğ‘¡ğ‘˜ğ‘ ğ‘¢ğ‘Ÿğ‘“(ğ‘ƒ),
whereğ‘ğ‘¡ğ‘¡ğ‘˜ğ‘ ğ‘¢ğ‘Ÿğ‘“(Â·)measures the attack surface of a program. Similar
to [22,41], we define ğ‘ğ‘¡ğ‘¡ğ‘˜ğ‘ ğ‘¢ğ‘Ÿğ‘“(ğ‘ƒ)as the number of ROP (Return-
Oriented Programming ) gadgets [ 54] inğ‘ƒâ€™s executable. An ROP
gadget is a sequence of machine instructions that ends with a re-
turn instruction and is relevant because an attacker could take
advantage of a vulnerability in the program (e.g., a buffer-overflow)to overwrite a gadgetâ€™s return address, hijack the control-flow, and
execute malicious code [ 6]. Finally, we define the overall reduction
ğ‘Ÿğ‘’ğ‘‘for a program as the weighted sum of ğ‘ ğ‘Ÿğ‘’ğ‘‘ andğ‘ğ‘Ÿğ‘’ğ‘‘ ,
ğ‘Ÿğ‘’ğ‘‘(ğ‘ƒ,ğ‘ƒâ€²)=(1âˆ’ğ‘˜ğ‘Ÿ)Â·ğ‘ ğ‘Ÿğ‘’ğ‘‘(ğ‘ƒ,ğ‘ƒâ€²)+ğ‘˜ğ‘ŸÂ·ğ‘ğ‘Ÿğ‘’ğ‘‘(ğ‘ƒ,ğ‘ƒâ€²),
whereğ‘˜ğ‘Ÿâˆˆ[0,1]is the weight.
3.3 Generality
Given a reduced program ğ‘ƒâ€², we define generality as the measure
of its ability to correctly handle inputs in D. We say that ğ‘ƒâ€²can
handle an inputğ‘–ifğ‘ƒâ€²can produce the same output as ğ‘ƒforğ‘–. We
compute the generality ğ‘”ğ‘’ğ‘›forğ‘ƒâ€²as the sum of path probabilities
for the paths preserved in ğ‘ƒâ€², formally defined as
ğ‘”ğ‘’ğ‘›(ğ‘ƒâ€²)=Î£ğœ‹âˆˆÎ âˆ§ğ‘†(ğœ‹)âŠ†ğ‘†(ğ‘ƒâ€²)ğ‘(ğœ‹),
where Î is a set of paths, ğ‘†(ğœ‹)is the set of statements executed
along pathğœ‹, andğ‘†(ğ‘ƒâ€²)is the set of statements contained in ğ‘ƒâ€².
In theory, Î should include all paths of ğ‘ƒ. To make the approach
practical, however, in the first step of our technique we select a
finite subset of paths that cover a fraction of inputs in the domain
whose combined probability is no less than a given lower bound.
3.4 Objective Function
To quantify the tradeoff between reduction ğ‘Ÿğ‘’ğ‘‘and generality ğ‘”ğ‘’ğ‘›,
we define an objective function Othat computes an objective score
as the weighted sum of ğ‘Ÿğ‘’ğ‘‘andğ‘”ğ‘’ğ‘›, formally defined as
O(ğ‘ƒ,ğ‘ƒâ€²)=(1âˆ’ğ‘˜ğ‘”)Â·ğ‘Ÿğ‘’ğ‘‘(ğ‘ƒ,ğ‘ƒâ€²)+ğ‘˜ğ‘”Â·ğ‘”ğ‘’ğ‘›(ğ‘ƒâ€²),
whereğ‘˜ğ‘”âˆˆ[0,1]is the weight applied to ğ‘Ÿğ‘’ğ‘‘andğ‘”ğ‘’ğ‘›.
3.5 Subdomain-Based Debloating
Given a program ğ‘ƒ, a set of paths Î , and the two weights ğ‘˜ğ‘Ÿandğ‘˜ğ‘”,
the goal of subdomain-based debloating is to produce a reduced pro-
gramğ‘ƒğ‘‘ğ‘’ğ‘that preserves a subset of paths Î â€²âŠ†Î and maximizes
O. Formally, we have
ğ‘ƒğ‘‘ğ‘’ğ‘=arg max
Î â€²âŠ†Î O(ğ‘ƒ,ğ‘ğ‘œğ‘šğ‘ğ‘œğ‘ ğ‘’(ğ‘ƒ,Î â€²)),
whereğ‘ğ‘œğ‘šğ‘ğ‘œğ‘ ğ‘’(ğ‘ƒ,Î â€²)is the reduced program that preserves all the
paths in Î â€². Note that one can use ğ‘˜ğ‘Ÿandğ‘˜ğ‘”to obtain reduced pro-
grams with different tradeoffs between ğ‘ ğ‘Ÿğ‘’ğ‘‘ andğ‘ğ‘Ÿğ‘’ğ‘‘ and between
ğ‘Ÿğ‘’ğ‘‘andğ‘”ğ‘’ğ‘›.
4 OUR TECHNIQUE: DOMGAD
Figure 1 provides an overview of DomGadâ€™s debloating process. We
first discuss the input sampler used by DomGad and then present
the three steps of the technique.
4.1 Input Sampler
DomGad relies on an input sampler to generate sampled inputs
for path identification and quantification. An input sampler ğ¼ğ‘†is
a probabilistic program that uses a set of pre-defined sampling
functions to generate random values. To be used within DomGad,
anğ¼ğ‘†must provide the following four functions:
â€¢getUniformInt (intğ‘š, intğ‘›): returns a random integer be-
tweenğ‘šandğ‘›, selected from a uniform distribution.
226ASE â€™20, September 21â€“25, 2020, Virtual Event, Australia Qi Xin, Myeongsoo Kim, Qirun Zhang, and Alessandro Orso
Figure 1: High-level overview of DomGad.
â€¢getUniformReal (doubleğ‘š, doubleğ‘›): returns a random
real number between ğ‘šandğ‘›, selected from a uniform dis-
tribution.
â€¢getNorm (doubleğ‘šğ‘’ğ‘ğ‘› , doubleğ‘ ğ‘‘ğ‘’ğ‘£): returns a random real
number selected from a normal distribution defined by the
given mean ( ğ‘šğ‘’ğ‘ğ‘› ) and standard-deviation ( ğ‘ ğ‘‘ğ‘’ğ‘£).
â€¢getBinomial (intğ‘›, doubleğ‘): returns a random integer that
represents the number of trials for which heads occur when
flipping a biased coin. The total number of trials is ğ‘›, and
the bias of the coin is determined by ğ‘.
Although these functions do not directly produce boolean, char-
acter, or string values, it is possible to generate such values using
these functions. For example, to get a random character between â€˜aâ€™
and â€˜zâ€™, we can call getUniformInt to generate an integer between
97 and 122 and convert it to a character.
DomGad relies onğ¼ğ‘†to obtain a sufficient set of sampled inputs
for effective subdomain identification and quantification. In this
first instance of our approach, we assume that the user is familiar
with the usage of the program and can provide a reasonable sampler.
As discussed in Section 7, in future work we plan to investigate
automated approaches for synthesizing an input sampler, possibly
based on a provided usage profile.
4.2 Path Identification
DomGad performs this step to identify a finite set of paths Î that
cover, with high confidence, a fraction of inputs in ğ‘ƒâ€™s domain
whose combined probability is no less than a given domain coverage
lower bound ğ‘âˆˆ(0,1). In other words, the sum of path probabilities
for the paths in Î should be no smaller than ğ‘:Î£ğœ‹âˆˆÎ ğ‘(ğœ‹) â‰¥ğ‘.
To identify Î ,DomGad performs a statistical, simulation-based
approach that is analogous to the one used in [ 51] and is described
in Algorithm 1.
The algorithm starts by computing parameter ğ¾, which it uses
to decide when to terminate the computation, and by initializing
the set of paths ğ‘ƒğ¼to the empty set (lines 1â€“2). It then enters its
main loop (lines 4â€“11) and, in each iteration of the loop, it generates
sample input ğ‘–and computes the path ğ‘ğ‘–exercised by ğ‘–(lines 5â€“6).
If the path is already in ğ‘ƒğ¼, the algorithm increments counter ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡
(line 8). Otherwise, it resets ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡ to0and addsğ‘ğ‘–toğ‘ƒğ¼(lines 10-11).
The loop terminates if no new paths are identified for ğ¾subsequent
iterations.
As explained in [ 51], a suitable ğ¾can be computed based on
parametersğ‘andğµthrough a Bayesian factor test [ 25]. Specifically,
ğ¾can be computed as ğ¾â‰¥lâˆ’logğµ
logğ‘m
. By tuning ğ‘andğµ,DomGadAlgorithm 1 Path identification.
Input:ğ‘ƒ: original program
Input:ğ¼ğ‘†: input sampler
Input:ğ‘: domain coverage lower bound
Input:ğµ: confidence parameter
Output:ğ‘ƒğ¼: a list of paths
1:ğ¾â†ğ‘ğ‘œğ‘šğ‘ğ‘¢ğ‘¡ğ‘’ğ¾(ğ‘,ğµ)
2:ğ‘ƒğ¼â†{}
3:ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡â†0
4:whileğ‘ğ‘œğ‘¢ğ‘›ğ‘¡ <ğ¾do
5:ğ‘–â†ğ¼ğ‘†.ğ‘”ğ‘’ğ‘¡ğ‘‚ğ‘›ğ‘’ğ‘†ğ‘ğ‘šğ‘ğ‘™ğ‘’ ()
6:ğ‘ğ‘–â†ğ‘”ğ‘’ğ‘¡ğ‘ƒğ‘ğ‘¡â„(ğ‘ƒ,ğ‘–)
7: ifğ‘ğ‘–âˆˆğ‘ƒğ¼then
8:ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡â†ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡+1
9: else
10:ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡â†0
11:ğ‘ƒğ¼â†ğ‘ƒğ¼âˆªğ‘ğ‘–
12:returnğ‘ƒğ¼
could generate Î that achieves a higher coverage with higher con-
fidence [ 51]. For example, given ğµ=100andğ‘=0.95,ğ¾â‰¥90.
This means that, if DomGad does not identify new paths for 90
subsequent iterations, the resulting set of paths Î would cover, with
high confidence, a set of inputs in the domain with a combined
probability that is at least 0.95.
4.3 Path Quantification
In this step, DomGad performs sampling to estimate the path prob-
ability for each path in Î . For a given ğœ‹âˆˆÎ , an input sample ğ‘–
drawn from the underlying distribution either (i) exercises or (ii)
does not exercise ğœ‹. Therefore, a sample can be considered the
instance of a random variable ğ‘‹ğ‘–following the Bernoulli distribu-
tionğ‘‹ğ‘–âˆ¼ğµğ‘’ğ‘Ÿğ‘›ğ‘œğ‘¢ğ‘™ğ‘™ğ‘–(ğ‘(ğœ‹)), whereğ‘(ğœ‹)is the path probability to
be estimated. Let ğ‘‹=ğ‘‹1+ğ‘‹2+Â·Â·Â·+ğ‘‹ğ‘›be the random variable
representing the sum of ğ‘›independent samples ( ğ‘‹is known to
follow the Binomial distribution). We define Ë†ğ‘(ğœ‹)asğ¸(ğ‘‹)=ğ‘‹/ğ‘›,
the expectation of ğ‘‹. To compute Ë†ğ‘(ğœ‹), the estimation of ğ‘(ğœ‹),
DomGad performs a sequence of ğ‘›Bernoulli trials to get ğ‘›sampled
inputs. Among these inputs, DomGad counts how many exercise
ğœ‹,ğ‘›ğœ‹, and computes Ë†ğ‘(ğœ‹)=ğ‘›ğœ‹/ğ‘›.
DomGad performs acceptance sampling [ 50,65] to bound errors.
To do this, we define the following error-bounding constraint:
ğ‘ƒğ‘Ÿ(Ë†ğ‘(ğœ‹)âˆˆ[ğ‘(ğœ‹)âˆ’ğœ–,ğ‘(ğœ‹)+ğœ–])â‰¥ 1âˆ’ğ›¼.
This constraint contains two error-bounding parameters, an accu-
racy parameter ğœ–and a confidence parameter ğ›¼, and specifies that
the estimated Ë†ğ‘(ğœ‹)will deviate from the real ğ‘(ğœ‹)by at mostğœ–
with probability 1âˆ’ğ›¼. By tuningğœ–andğ›¼to small values, Ë†ğ‘(ğœ‹)gets
closer toğ‘(ğœ‹)with high confidence. Given specific ğœ–andğ›¼, we use
the two-sided Chernoff bound [ 9,50] to compute a lower bound ğ‘›ğ‘™ğ‘
for the sampling number ğ‘›asğ‘›ğ‘™ğ‘=2+ğœ–
ğœ–2ln2
ğ›¼. This means that, if
227Subdomain-Based Generality-Aware Debloating ASE â€™20, September 21â€“25, 2020, Virtual Event, Australia
Algorithm 2 Path probability estimation.
Input:ğ‘ƒ: original program
Input:ğ¼ğ‘†: input sampler
Input:ğ‘ƒğ¼: set of previously identified paths
Input:ğœ–: accuracy parameter for error-bounding
Input:ğ›¼: confidence parameter for error-bounding
Output:ğ‘ğ‘–ğ‘šğ‘ğ‘ : a map that maps a path to its estimated path probability
1:ğ‘›ğ‘™ğ‘â†ğ‘”ğ‘’ğ‘¡ğ‘†ğ‘ğ‘šğ‘ğ‘™ğ‘’ğ‘ğ‘¢ğ‘š(ğœ–,ğ›¼)
2:ğ‘ğ‘–ğ‘šğ‘ğ‘â†{}
3:forğ‘ğ‘–âˆˆğ‘ƒğ¼do
4:ğ‘ğ‘–ğ‘šğ‘ğ‘.ğ‘ ğ‘’ğ‘¡(ğ‘ğ‘–,0)
5:
6:ğ‘–â†0
7:whileğ‘–<=ğ‘›ğ‘™ğ‘do
8:ğ‘–ğ‘›â†ğ¼ğ‘†.ğ‘”ğ‘’ğ‘¡ğ‘‚ğ‘›ğ‘’ğ‘†ğ‘ğ‘šğ‘ğ‘™ğ‘’ ()
9:ğ‘ğ‘–â†ğ‘”ğ‘’ğ‘¡ğ‘ƒğ‘ğ‘¡â„(ğ‘ƒ,ğ‘–ğ‘›)
10: ifğ‘ğ‘–âˆˆğ‘ƒğ¼then
11:ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡â†ğ‘ğ‘–ğ‘šğ‘ğ‘.ğ‘”ğ‘’ğ‘¡(ğ‘ğ‘–)
12:ğ‘ğ‘–ğ‘šğ‘ğ‘.ğ‘ ğ‘’ğ‘¡(ğ‘ğ‘–,ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡+1)
13:ğ‘–â†ğ‘–+1
14:
15:forğ‘ğ‘–âˆˆğ‘ƒğ¼do
16:ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡â†ğ‘ğ‘–ğ‘šğ‘ğ‘.ğ‘”ğ‘’ğ‘¡(ğ‘ğ‘–)
17:ğ‘ğ‘–ğ‘šğ‘ğ‘.ğ‘ ğ‘’ğ‘¡(ğ‘ğ‘–,ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡/ğ‘›ğ‘™ğ‘)
18:returnğ‘ğ‘–ğ‘šğ‘ğ‘
we useğ‘›ğ‘™ğ‘samples to estimate ğ‘(ğœ‹), the estimated Ë†ğ‘(ğœ‹)will satisfy
the error-bounding constraint specified by ğœ–andğ›¼.
Given program ğ‘ƒ, the input sampler ğ¼ğ‘†, the set of paths ğ‘ƒğ¼pre-
viously identified, and the error-bounding parameters ğœ–andğ›¼,
DomGad uses Algorithm 2 to compute path probability Ë†ğ‘(ğ‘ğ‘–)for
eachğ‘ğ‘–âˆˆğ‘ƒğ¼. The algorithm generates ğ‘ğ‘–ğ‘šğ‘ğ‘ , which maps each
pathğ‘ğ‘–to its estimated path probability. The algorithm starts by
computing the number of input samples ğ‘›ğ‘™ğ‘based onğœ–andğ›¼(line
1) and initializing ğ‘ğ‘–ğ‘šğ‘ğ‘ by setting a key for each ğ‘ğ‘–âˆˆğ‘ƒğ¼and
mapping it to a value 0(lines 2â€“4). It then iteratively generates a
total ofğ‘›ğ‘™ğ‘samples and updates ğ‘ğ‘–ğ‘šğ‘ğ‘ by counting the number of
samples each path covers (lines 7â€“13). A path ğ‘ğ‘–covers a sample ğ‘–ğ‘›
if runningğ‘ƒwithğ‘–ğ‘›exercisesğ‘ğ‘–. Finally, the algorithm computes
the path probability for each ğœ‹based on its count and updates
ğ‘ğ‘–ğ‘šğ‘ğ‘ (lines 15â€“17). Note that DomGad does not need to generate
an independent set of ğ‘›ğ‘™ğ‘samples to estimate path probability for
eachğ‘ğ‘–âˆˆğ‘ƒğ¼. This is because paths are disjoint, that is, a sampled
input exercises at most one path. Therefore, the random variables
representing each path are independent.
4.4 Stochastic Optimization
Because there is a tension between reducing the size of a program
and preserving its generality, we formulate debloating as an opti-
mization problem. Our goal is to generate an optimally reduced
program that achieves the best tradeoff between reduction and gen-
erality. Since it is generally infeasible to enumerate every reduced
program in the search space, given its exponential size, DomGad
performs stochastic search, using an MCMC-based approach, to
find a close-to-optimal solution. We first summarize the MCMC ap-
proach we use, to make the paper self contained, and then present
our stochastic optimization algorithm.
4.4.1 MCMC and Metropolis-Hastings Algorithm. An MCMC-based
approach is a sampling-based approach that is commonly used for
estimating properties, such as mean and variance, of a given proba-
bility distribution (whose probability density function is known).
The approach performs a sequential process to draw samples from
the distribution, where the generation of a new sample only de-
pends on the previous sample.Algorithm 3 Simplified Metropolis-Hastings algorithm.
Input:ğ‘“: probability density function
Input:ğ‘: number of samples to be generated
Output:ğ‘†: a set of samples
1:ğ‘ğ‘¢ğ‘Ÿğ‘Ÿ _ğ‘ â†initialize a sample
2:ğ‘›â†0
3:whileğ‘›<ğ‘do
4:ğ‘›ğ‘’ğ‘¤ _ğ‘ â†mutateğ‘ğ‘¢ğ‘Ÿğ‘Ÿ _ğ‘ by adding random noise
5:ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘œâ†ğ‘“(ğ‘›ğ‘’ğ‘¤ _ğ‘ )/ğ‘“(ğ‘ğ‘¢ğ‘Ÿğ‘Ÿ _ğ‘ )
6:ğ‘Ÿğ‘›â†get a uniform random number âŠ²ğ‘Ÿğ‘›âˆˆ[0,1)
7: ifğ‘Ÿğ‘›<ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘œ then âŠ²accept the new sample
8:ğ‘†â†ğ‘†âˆªğ‘›ğ‘’ğ‘¤ _ğ‘ 
9:ğ‘ğ‘¢ğ‘Ÿğ‘Ÿ _ğ‘ â†ğ‘›ğ‘’ğ‘¤ _ğ‘ 
10:ğ‘›=ğ‘›+1
11:returnğ‘†
An algorithm commonly used for performing MCMC-based sam-
pling is the Metropolis-Hastings (MH) algorithm, which generates
new samples through mutation, by adding random noise to the
current sample. A simplified version of the MH algorithm is shown
as Algorithm 3. It is simplified because we assume that the mutation
used for generating a new sample is symmetric (i.e., the probability
of generating a sample ğ‘ ğ‘—based onğ‘ ğ‘–is the same as that of generat-
ingğ‘ ğ‘–based onğ‘ ğ‘—). As we will show in Section 4.4.2, DomGad uses
symmetric mutations to generate samples of reduced programs.
The algorithm takes as input a probability distribution defined
by a probability density function ğ‘“and a maximum number of sam-
ples to be generated ğ‘. It starts by initializing the current sample
ğ‘ğ‘¢ğ‘Ÿğ‘Ÿ_ğ‘ (line 1) and setting the current number of samples ğ‘›to0(line
2). Next, it iteratively generates new samples (lines 3â€“10). In each
iteration, it generates a new sample ğ‘›ğ‘’ğ‘¤_ğ‘ by adding random noise
toğ‘ğ‘¢ğ‘Ÿğ‘Ÿ_ğ‘ . To decide whether to accept ğ‘›ğ‘’ğ‘¤_ğ‘ or not, it computes a
density ratio ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘œ and generates a random number ğ‘Ÿğ‘›(lines 5â€“6). If
ğ‘Ÿğ‘›is smaller than ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘œ , the algorithm accepts ğ‘›ğ‘’ğ‘¤_ğ‘ . This implies
that, whenğ‘›ğ‘’ğ‘¤_ğ‘ is of higher density value, the algorithm always
acceptsğ‘›ğ‘’ğ‘¤_ğ‘ . Otherwise, when ğ‘›ğ‘’ğ‘¤_ğ‘ has a lower density, it can
still acceptğ‘›ğ‘’ğ‘¤_ğ‘ based on its relative density drop (determined
byğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘œ ). Intuitively, by accepting samples this way, the algorithm
is able to collect more samples from higher-density regions of the
distribution, while still occasionally visiting and collecting samples
from lower-density regions. This explains why the MH algorithm
can generate samples that effectively approximate the given distri-
bution. When a new sample ğ‘›ğ‘’ğ‘¤_ğ‘ is accepted, the algorithm adds
it to the sample set ğ‘†, updatesğ‘ğ‘¢ğ‘Ÿğ‘Ÿ_ğ‘ , and increases ğ‘›(lines 8â€“10).
4.4.2 DomGadâ€™s Stochastic Approach. DomGad uses the MH algo-
rithm to perform stochastic optimization and produce a reduced
program with the highest objective score. Following existing ap-
proaches [ 52,61], we define a program distribution whose probabil-
ity density function ğ‘“is defined based on the objective function O.
Specifically, for a program ğ‘ƒand its reduced version ğ‘ƒâ€², we define
the probability density function ğ‘“(ğ‘ƒ,ğ‘ƒâ€²)as
ğ‘“(ğ‘ƒ,ğ‘ƒâ€²)=1
ğ‘ğ‘’ğ‘¥ğ‘(ğ‘˜Â·O(ğ‘ƒ,ğ‘ƒâ€²)),
whereğ‘˜is a constant, and ğ‘is the normalizing factor that ensures
that the sum of density values for all programs is 1[18, 52].
Bit-vector representation. A reduced program ğ‘ƒâ€²in the search
space preserves a subset of paths Î â€²âŠ†Î previously identified by
DomGad. We represent this using a bit-vector. Specifically, a bit-
vectorğ‘ğ‘–ğ‘¡ğ‘£ğ‘’ğ‘â€²forğ‘ƒâ€²indicates which paths are preserved in ğ‘ƒâ€²,
whereğ‘ƒâ€²preservesğœ‹if it contains all the statements executed
alongğœ‹. A bitğ‘â€²inğ‘ğ‘–ğ‘¡ğ‘£ğ‘’ğ‘â€²represents a path ğœ‹â€²âˆˆÎ . Ifğ‘â€²is1, this
228ASE â€™20, September 21â€“25, 2020, Virtual Event, Australia Qi Xin, Myeongsoo Kim, Qirun Zhang, and Alessandro Orso
1 if (x) { s0 } else { s1 }
2 if(y) { s2 } else { s3 }1 pi_a : x->s1 ->y->s3
2 pi_b : x->s0 ->y->s2
3 pi_c : x->s1 ->y->s2
Figure 2: An example of program composition.
means that ğ‘ƒâ€²preservesğœ‹â€², and thusğœ‹â€²is selected to compose
ğ‘ƒâ€². Conversely, a value 0forğ‘â€²indicates that ğœ‹â€²is not part of
ğ‘ƒâ€². It is worth noting that ğ‘ƒâ€²may preserve ğœ‹â€²even ifğœ‹â€²is not
explicitly used to compose ğ‘ƒâ€², if the code added to preserve other
paths happens to include the code for ğœ‹â€². Figure 2 illustrates this
situation with an example: if the programs on the left preserved
the two paths ğ‘ğ‘–_ğ‘andğ‘ğ‘–_ğ‘, it would also "accidentally" preserve
pathğ‘ğ‘–_ğ‘.DomGad accounts for these accidentally preserved paths
when computing the generality of a reduced program.
Sample mutation. DomGad mutatesğ‘ƒâ€²to generate a new sam-
pleğ‘ƒâ€²â€²by randomly selecting a bit ğ‘â€²inğ‘ƒâ€²â€™s bit-vector and flipping
it. By doing so, DomGad adds and removes entries from the set of
preserved paths used to compose ğ‘ƒâ€²â€². This mutation is symmetric,
as each path has the same chance of being selected (or not selected).
DomGadâ€™s algorithm. Algorithm 4 describes DomGadâ€™s sto-
chastic optimization approach. The algorithm takes as input (1) a
programğ‘ƒ, (2) a set of previously identified paths ğ‘ƒğ¼, (3) a map
ğ‘ğ‘–ğ‘šğ‘ğ‘ that maps each path ğ‘ğ‘–âˆˆğ‘ƒğ¼to its path probability, (4) a
timeout value ğ‘¡ğ‘–ğ‘šğ‘’ğ‘œğ‘¢ğ‘¡ , (5)ğ‘˜ğ‘Ÿandğ‘˜ğ‘”, used to compute the objec-
tive score, and (6) ğ‘˜, used to compute the density score. Given ğ‘ƒ
and a reduced program ğ‘ƒâ€², we define the density score ğ‘‘(ğ‘ƒ,ğ‘ƒâ€²)as
ğ‘“(ğ‘ƒ,ğ‘ƒâ€²)Â·ğ‘, which is equal to ğ‘’ğ‘¥ğ‘(ğ‘˜Â·O(ğ‘ƒ,ğ‘ƒâ€²)).DomGad does
not have to compute the density value and can instead use the
density score to decide the acceptance of a new sample. This is
because, when computing density ratio, the normalizing factor ğ‘is
a common factor and can be simplified.
The algorithm starts by generating a program with no paths
(line 1), that is, a program that has an empty body for each defined
function. It then computes scores for this program (lines 2â€“4) and
initializesğ‘ğ‘¢ğ‘Ÿğ‘Ÿğ·ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’ ,ğ‘ğ‘’ğ‘ ğ‘¡ğ·ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’ , andğ‘ğ‘’ğ‘ ğ‘¡ğ‘†ğ‘ğ‘šğ‘ğ‘™ğ‘’ , which repre-
sent the current and highest density scores and the sample holding
the highest score (lines 5â€“7). The algorithm also converts ğ‘ƒğ¼into a
listğ‘ğ‘–_ğ‘™ğ‘–ğ‘ ğ‘¡, obtains its size, and creates a bit-vector ğ‘ğ‘–ğ‘¡ğ‘£ğ‘’ğ‘ with all
bits set to 0(lines 9â€“13).
The algorithm then generates samples iteratively (lines 15â€“48).
In each iteration, it randomly flips a bit in ğ‘ğ‘–ğ‘¡ğ‘£ğ‘’ğ‘ (lines 16â€“17), com-
putes the set ğ‘†of statements executed along the preserved paths
(lines 18â€“21), and generates a reduced program ğ‘ƒâ€²(i.e., a sample)
accordingly (line 22). Next, the algorithm computes, for the gen-
erated program, the reduction ğ‘Ÿğ‘’ğ‘‘(line 24), generality ğ‘”ğ‘’ğ‘›(lines
25-35), and density score ğ‘‘ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’ (line 36) values. Note that, for com-
putingğ‘”ğ‘’ğ‘›, it would be insufficient to only consider paths explicitly
selected for composing ğ‘ƒâ€². As we mentioned above, the algorithm
also checks for paths not selected, yet accidentally preserved in ğ‘ƒâ€².
After generating a new sample, the algorithm computes the
density ratio to decide whether to accept the new sample (line 39).
If the sample is accepted, the algorithm updates ğ‘ğ‘¢ğ‘Ÿğ‘Ÿğ·ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’ and,
if needed,ğ‘ğ‘’ğ‘ ğ‘¡ğ·ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’ andğ‘ğ‘’ğ‘ ğ‘¡ğ‘†ğ‘ğ‘šğ‘ğ‘™ğ‘’ (lines 42â€“45). Otherwise, it
reverts the bit flipped (line 47). Finally, it returns ğ‘ğ‘’ğ‘ ğ‘¡ğ‘†ğ‘ğ‘šğ‘ğ‘™ğ‘’ , the
sample with the highest density and objective scores (line 49).Algorithm 4 DomGadâ€™s stochastic algorithm.
Input:ğ‘ƒ: original program
Input:ğ‘ƒğ¼: set of identified paths
Input:ğ‘ğ‘–ğ‘šğ‘ğ‘ : path probability map
Input:ğ‘¡ğ‘–ğ‘šğ‘’ğ‘œğ‘¢ğ‘¡ : timeout value (in hours)
Input:ğ‘˜ğ‘Ÿ: weight for computing reduction
Input:ğ‘˜ğ‘”: weight for computing objective score
Input:ğ‘˜: constant for computing density value
Output:ğ‘ğ‘’ğ‘ ğ‘¡ğ‘†ğ‘ğ‘šğ‘ğ‘™ğ‘’ : resulting debloated program
1:ğ‘ƒâ€²â†a program with no path preserved
2:ğ‘Ÿğ‘’ğ‘‘â†ğ‘”ğ‘’ğ‘¡ğ‘…ğ‘’ğ‘‘ğ‘¢ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’ (ğ‘ƒ,ğ‘ƒâ€²,ğ‘˜ğ‘Ÿ)
3:ğ‘”ğ‘’ğ‘›â†0
4:ğ‘‘ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’â†ğ‘”ğ‘’ğ‘¡ğ·ğ‘’ğ‘›ğ‘ ğ‘–ğ‘¡ğ‘¦ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’(ğ‘Ÿğ‘’ğ‘‘,ğ‘”ğ‘’ğ‘›,ğ‘˜,ğ‘˜ğ‘”)
5:ğ‘ğ‘¢ğ‘Ÿğ‘Ÿğ·ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’â†ğ‘‘ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’
6:ğ‘ğ‘’ğ‘ ğ‘¡ğ·ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’â†ğ‘‘ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’
7:ğ‘ğ‘’ğ‘ ğ‘¡ğ‘†ğ‘ğ‘šğ‘ğ‘™ğ‘’â†ğ‘ƒâ€²
8:
9:ğ‘ğ‘–_ğ‘™ğ‘–ğ‘ ğ‘¡â†ğ‘¡ğ‘œğ¿ğ‘–ğ‘ ğ‘¡(ğ‘ƒğ¼)
10:ğ‘ğ‘–_ğ‘™ğ‘–ğ‘ ğ‘¡_ğ‘ ğ‘–ğ‘§ğ‘’â†ğ‘ğ‘–_ğ‘™ğ‘–ğ‘ ğ‘¡.ğ‘ ğ‘–ğ‘§ğ‘’()
11:ğ‘ğ‘–ğ‘¡ğ‘£ğ‘’ğ‘â†new int[ğ‘ğ‘–_ğ‘™ğ‘–ğ‘ ğ‘¡_ğ‘ ğ‘–ğ‘§ğ‘’]
12:forintğ‘–=0;ğ‘–<ğ‘ğ‘–_ğ‘™ğ‘–ğ‘ ğ‘¡_ğ‘ ğ‘–ğ‘§ğ‘’;ğ‘–++do
13:ğ‘ğ‘–ğ‘¡ğ‘£ğ‘’ğ‘[ğ‘–]=0
14:
15:do
16:ğ‘–ğ‘‘ğ‘¥â†ğ‘”ğ‘’ğ‘¡ğ‘…ğ‘ğ‘›ğ‘‘ğ‘œğ‘šğ¼ğ‘›ğ‘¡(0,ğ‘ğ‘–_ğ‘™ğ‘–ğ‘ ğ‘¡_ğ‘ ğ‘–ğ‘§ğ‘’) âŠ²ğ‘–ğ‘‘ğ‘¥âˆˆ[0,ğ‘ğ‘–_ğ‘™ğ‘–ğ‘ ğ‘¡_ğ‘ ğ‘–ğ‘§ğ‘’)
17:ğ‘ğ‘–ğ‘¡ğ‘£ğ‘’ğ‘[ğ‘–ğ‘‘ğ‘¥]â† 1âˆ’ğ‘ğ‘–ğ‘¡ğ‘£ğ‘’ğ‘[ğ‘–ğ‘‘ğ‘¥] âŠ²Flip a bit
18:ğ‘†â†{} âŠ²A set of statements
19: forintğ‘–=0;ğ‘–<ğ‘ğ‘–_ğ‘™ğ‘–ğ‘ ğ‘¡_ğ‘ ğ‘–ğ‘§ğ‘’;ğ‘–++do
20: ifğ‘ğ‘–ğ‘¡ğ‘£ğ‘’ğ‘[ğ‘–]==1then
21:ğ‘†â†ğ‘†âˆªğ‘”ğ‘’ğ‘¡ğ‘†ğ‘¡ğ‘šğ‘¡ğ‘ (ğ‘ğ‘–_ğ‘™ğ‘–ğ‘ ğ‘¡.ğ‘”ğ‘’ğ‘¡(ğ‘–))
22:ğ‘ƒâ€²â†ğ‘”ğ‘’ğ‘¡ğ‘…ğ‘’ğ‘‘ğ‘¢ğ‘ğ‘’ğ‘‘ğ‘ƒğ‘Ÿğ‘œğ‘”(ğ‘ƒ,ğ‘†)
23:
24:ğ‘Ÿğ‘’ğ‘‘â†ğ‘”ğ‘’ğ‘¡ğ‘…ğ‘’ğ‘‘ğ‘¢ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’ (ğ‘ƒ,ğ‘ƒâ€²,ğ‘˜ğ‘Ÿ)
25:ğ‘”ğ‘’ğ‘›â†0
26: forintğ‘–=0;ğ‘–<ğ‘ğ‘–_ğ‘™ğ‘–ğ‘ ğ‘¡_ğ‘ ğ‘–ğ‘§ğ‘’;ğ‘–++do
27:ğ‘ğ‘Ÿğ‘’ğ‘ ğ‘’ğ‘Ÿğ‘£ğ‘’ğ‘‘â†ğ‘“ğ‘ğ‘™ğ‘ ğ‘’
28: ifğ‘ğ‘–ğ‘¡ğ‘£ğ‘’ğ‘[ğ‘–]==1then
29:ğ‘ğ‘Ÿğ‘’ğ‘ ğ‘’ğ‘Ÿğ‘£ğ‘’ğ‘‘â†ğ‘¡ğ‘Ÿğ‘¢ğ‘’
30: else
31:ğ‘†â€²â†ğ‘”ğ‘’ğ‘¡ğ‘†ğ‘¡ğ‘šğ‘¡ğ‘ (ğ‘ğ‘–_ğ‘™ğ‘–ğ‘ ğ‘¡.ğ‘”ğ‘’ğ‘¡(ğ‘–))
32: ifğ‘–ğ‘ ğ‘†ğ‘¢ğ‘ğ‘ ğ‘’ğ‘¡ğ¸ğ‘ğ‘¢ğ‘ğ‘™(ğ‘†â€²,ğ‘†)then
33: ğ‘ğ‘Ÿğ‘’ğ‘ ğ‘’ğ‘Ÿğ‘£ğ‘’ğ‘‘â†ğ‘¡ğ‘Ÿğ‘¢ğ‘’
34: ifğ‘ğ‘Ÿğ‘’ğ‘ ğ‘’ğ‘Ÿğ‘£ğ‘’ğ‘‘ then
35:ğ‘”ğ‘’ğ‘›+=ğ‘ğ‘–ğ‘šğ‘ğ‘.ğ‘”ğ‘’ğ‘¡(ğ‘ğ‘–_ğ‘™ğ‘–ğ‘ ğ‘¡.ğ‘”ğ‘’ğ‘¡(ğ‘–))
36:ğ‘‘ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’â†ğ‘”ğ‘’ğ‘¡ğ·ğ‘’ğ‘›ğ‘ ğ‘–ğ‘¡ğ‘¦ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’(ğ‘Ÿğ‘’ğ‘‘,ğ‘”ğ‘’ğ‘›,ğ‘˜,ğ‘˜ğ‘”)
37:
38:ğ‘ğ‘ğ‘ğ‘’ğ‘ğ‘¡â†ğ‘“ğ‘ğ‘™ğ‘ ğ‘’
39: ifğ‘Ÿğ‘ğ‘›ğ‘‘ğ‘œğ‘š()<ğ‘‘ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’/ğ‘ğ‘¢ğ‘Ÿğ‘Ÿğ·ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’ then âŠ²ğ‘Ÿğ‘ğ‘›ğ‘‘ğ‘œğ‘š()âˆˆ[ 0,1)
40:ğ‘ğ‘ğ‘ğ‘’ğ‘ğ‘¡â†ğ‘¡ğ‘Ÿğ‘¢ğ‘’
41: ifğ‘ğ‘ğ‘ğ‘’ğ‘ğ‘¡ then
42:ğ‘ğ‘¢ğ‘Ÿğ‘Ÿğ·ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’â†ğ‘‘ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’
43: ifğ‘‘ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’ >ğ‘ğ‘’ğ‘ ğ‘¡ğ·ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’ then
44:ğ‘ğ‘’ğ‘ ğ‘¡ğ‘†ğ‘ğ‘šğ‘ğ‘™ğ‘’â†ğ‘ƒâ€²
45:ğ‘ğ‘’ğ‘ ğ‘¡ğ·ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’â†ğ‘‘ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’
46: else
47:ğ‘ğ‘–ğ‘¡ğ‘£ğ‘’ğ‘[ğ‘–ğ‘‘ğ‘¥]â† 1âˆ’ğ‘ğ‘–ğ‘¡ğ‘£ğ‘’ğ‘[ğ‘–ğ‘‘ğ‘¥] âŠ²Revert the bit
48:whileğ‘¡ğ‘–ğ‘šğ‘’ğ‘œğ‘¢ğ‘¡ is reached
49:returnğ‘ğ‘’ğ‘ ğ‘¡ğ‘†ğ‘ğ‘šğ‘ğ‘™ğ‘’
5 EVALUATION
To assess the usefulness of DomGad, we implemented it in a pro-
totype tool and applied it to a benchmark of ten programs. We
compared DomGad to two baselines: Debop, our previous approach
that also performs optimization-based debloating, and Chisel [22],
a state-of-the-art, reduction-oriented technique. Specifically, we
investigated four research questions:
â€¢RQ1 : How does DomGad perform in terms of path identifi-
cation and quantification?
â€¢RQ2 : How does DomGad perform in terms of stochastic
optimization?
â€¢RQ3 : How does DomGad compare with Debop in terms of
the reduction-generality tradeoffs achieved by the debloated
programs they generate?
â€¢RQ4 : How does DomGad compare with Chisel in terms of
size and attack-surface reduction?
229Subdomain-Based Generality-Aware Debloating ASE â€™20, September 21â€“25, 2020, Virtual Event, Australia
Table 2: Benchmark programs used in our evaluation.
Program LOC #Func #Stmt
bzip2-1.0.5 11782 97 6154
chown-8.2 7081 122 3765
date-8.21 9695 78 4228
grep-2.19 22706 315 10977
gzip-1.2.4 8694 91 4049
mkdir-5.2.1 5056 43 1804
rm-8.4 7200 135 3835
sort-8.16 14264 233 7805
tar-1.14 30477 473 13995
uniq-8.16 7020 65 2086
5.1 Implementation Details
We developer our prototype tool using a combination of C++, Java,
and Bash scripts. The tool takes as inputs a program, an input
sampler, and a set of parameters ( ğ‘,ğµ,ğœ–,ğ›¼,ğ‘¡ğ‘–ğ‘šğ‘’ğ‘œğ‘¢ğ‘¡ ,ğ‘˜ğ‘Ÿ,ğ‘˜ğ‘”, and
ğ‘˜), and generates a debloated program. To record paths and the
statements covered in that path, our prototype uses the llvm-cov
tool [ 37]. We relied on Clang [ 13] (v.9.0.0) for building the abstract
syntax tree (AST) of a program and used the AST to record the
starting and ending positions of the functions and statements in
the program. The tool produces a reduced program based on these
recorded positions and on the coverage report generated by llvm-
cov. To measure the number of statements in a program, our tool
leverages a utility provided by Chisel [10]. Finally, to compute
attack surface reduction, the tool compiles the program using Clang
and measures the number of ROP gadgets in the resulting executable
using the ROPgadget tool [48].
5.2 Experiment Setup
5.2.1 Benchmark Programs. As benchmark, we used the ten Unix
utility programs (the all-in-one-file versions) provided in the bench-
mark repository [ 11]. We selected these programs because they
have been extensively used for evaluating debloating techniques
in related work [ 22,41,61]. Table 2 shows the statistics of these
programs in terms of size, number of functions, and number of
statements.
5.2.2 Sampler Programs. For each benchmark program, we created
an input sampler based on its usage profile, that is, based on the set
of inputs associated with the program and provided in [ 11]. The
sampler reflects how the benchmark program is used according
to its usage profile. Specifically, to generate an input, the sampler
randomly selects an option used in the usage profile, where an
option could be an empty option, a single option (e.g., â€œ-câ€), or a
combination of individual options (e.g., â€œ-r -fâ€). We computed the
probability of selecting an option based on its usage frequency. For
example, if an option â€œ-câ€ was used in seven out of the ten inputs
within a usage profile, the selection probability of the option would
have been 0.7.
These options, or the program in general, may require values or
inputs of a specific type to operate, and the sampler must be able to
provide these values and inputs. When a numeric or enumeration
value is required, the sampler generates a random value from a
pre-defined range of values. For example, since a permission value
is needed for the â€œ-mâ€ option for mkdir-5.2.1, the sampler choosesa random value between 000and 777. Similarly, in the case of
program date-8.21, the sampler generates a random date or time
value. When a text file is needed, the sampler produces a random
file that contains ğ‘lines, where ğ‘is a random number between
1and100, and each line contains ğ‘€ASCII characters, where ğ‘€
is also a random number between 1and100. When a compressed
file is needed (for bzip2-1.0.5, gzip-1.2.4, and tar-1.14 ), the sampler
generates a random text file, and then invokes the corresponding
utility to generate its compressed version. Finally, if a directory is
needed, the sampler generates a directory that mirrors the structure
of directories in the usage profile but contains random files.
In addition, some programs require inputs with specific char-
acteristics and relations among them. grep, for instance, is a Unix
utility for identifying patterns within files. The sampler we devel-
oped for grep-2.19, does not generate a random query pattern and
uses instead patterns that appear in the provided usage profile. As
the target file for grep-2.19, the sampler first generates a random
text file. Then, depending on whether the query can be found in
the original input or not, the sampler will either insert the query in
the target file or remove it if present.
In summary, we carefully designed the sampler programs so as
to make sure they simulated how the benchmark programs are
used in their usage profiles. We provide a detailed description of
the sampler programs at [49].
5.2.3 Parameters. DomGad uses a set of parameters for debloating.
For path identification, we set the domain coverage lower bound
toğ‘=0.95, and the confidence parameter ğµto100(as suggested
in [51]). With these settings, DomGad would only terminate if it
does not identify any new paths for ğ¾=90subsequent iterations.
We set 10000 as the maximum number of iterations for path identifi-
cation. For path quantification, we set accuracy parameter ğœ–to0.03,
and confidence parameter ğ›¼to0.05. With these settings, DomGad
must sample ğ‘›ğ‘™ğ‘=8321 inputs to satisfy the error-bounding con-
straint. It is worth noting that there is a tradeoff between accuracy
and efficiency for both path identification and quantification. One
could decrease the value of ğ‘to sample a smaller number of inputs
needed for path identification, and vice versa. Similarly, one could
increase the values of ğœ–andğ›¼to sample less inputs to satisfy the
error-bounding constraint for path quantification, and vice versa.
With the current settings, it took DomGad 42.5 hours to finish
path identification and quantification for all programs. We did not
investigate how sensitive are the debloating results to the values of
ğ‘,ğœ–, andğ›¼, but we plan to do it in future work.
When performing stochastic optimization, we used different
values of the two weights used for computing the objective score
(ğ‘˜ğ‘Ÿandğ‘˜ğ‘”). Specifically, to study how ğ‘˜ğ‘”affects the debloating
result, we set ğ‘˜ğ‘Ÿto0.5and experimented with five values for ğ‘˜ğ‘”:0.1,
0.3,0.5,0.7, and 0.9. Similarly, to study how ğ‘˜ğ‘Ÿaffects the results, we
setğ‘˜ğ‘”to0.5and experimented with three values for ğ‘˜ğ‘Ÿ:0.25,0.5, and
0.75. For each benchmark program, we therefore ran DomGad for
a total of seven trials. In each trial, DomGad produced a debloated
program, using a timeout of six hours. This resulted in a total of
420 hours of machine time to finish all trials for all programs. To
compute a density score, we followed the approach used in [ 61]
and setğ‘˜to50.
230ASE â€™20, September 21â€“25, 2020, Virtual Event, Australia Qi Xin, Myeongsoo Kim, Qirun Zhang, and Alessandro Orso
5.2.4 Setup for Debop. We compared DomGad with Debop us-
ing its implementation available at [ 14]. Unlike DomGad, Debop
is an input-based technique and requires a program and a set of
inputs. To perform a fair comparison, we provided Debop with a
programğ‘ƒÎ that preserves all the paths Î identified by DomGad
(asDomGad would only generate reduced versions of ğ‘ƒÎ ).Dom-
Gad leverages a set of sampled inputs ğ¼to quantify each path in Î ,
and performs stochastic optimization based on the quantification
result. For comparison, we provided Debop with a set of inputs
ğ¼â€²âŠ†ğ¼that only contains inputs that exercise paths in Î . We did
not provide Debop withğ¼, as there might be inputs in ğ¼that execute
paths that are not in Î and are not actually used by DomGad for
quantification.
For each input, Debop needs an oracle to decide whether a pro-
gramğ‘ƒâ€²executes correctly for that input. Therefore, for each sam-
plerğ¼ğ‘†we developed, we also wrote a program that automatically
generates an oracle for every possible input that ğ¼ğ‘†generates. The
oracle works by comparing the output of ğ‘ƒâ€²against that of its
original program ğ‘ƒ. Specifically, the oracle checks a programâ€™s exit
value and each output produced by the program, including files and
directories. Specifically, for bzip2-1.0.5, gzip-1.2.4, and tar-1.14, if the
program generates a text file, the oracle directly checks its content.
Otherwise, if the generated file is compressed, the oracle invokes
the corresponding utility to decompress it, and then checks the
decompressed files. Finally, if a directory is generated, the oracle
checks the files it contains. For chown-8.4, the oracle checks the
ownership of files/directories. For rm-8.4, the oracle checks the ex-
istence of files/directories. For mkdir-5.2.1, in addition to checking
the existence of the generated directories, the oracle also checks
their permissions.
Debop assigns to a program that executes correctly for all the
provided inputs generality 1. This is problematic (for comparison),
as such a program would not be considered able to handle all inputs
(in the whole domain) by DomGad. To address this problem, we
slightly modified the implementation of Debop so that it takes as
input a generality factor ğ‘”ğ‘“âˆˆ[0,1]. Then, we provided Debop with
a generality factor that is computed as the generality of ğ‘ƒÎ (the
sum of the path probabilities for all the paths in Î ). In this way, for
a programğ‘ƒâ€², the generality score computed by Debop becomes the
product of (i) ğ‘”ğ‘“and (ii) the number of inputs for which ğ‘ƒâ€²executes
correctly over all provided inputs. We also configured Debop so
that it quantifies reduction in the same way DomGad does.
We applied Debop to the benchmark programs using the same
parameter values for ğ‘˜ğ‘Ÿ,ğ‘˜ğ‘”, andğ‘˜thatDomGad uses, the same
number of trials, and the same timeout per trial.
5.2.5 Setup for Chisel. Chisel is also input-based and thus re-
quires a set of inputs for debloating. Similar to Debop, for each
benchmark program, we provided Chisel with program ğ‘ƒÎ . Be-
cause Chisel is not an optimization-based technique, we did not
provide the set of inputs ğ¼â€²thatDebop uses. Instead, we logged the
exact set of paths Î â€²â€²preserved in the debloated program generated
byDomGad, and obtained the set of inputs ğ¼â€²â€²âŠ†ğ¼used for quanti-
fying paths in Î â€²â€². Becauseğ¼â€²â€²corresponds to the set of inputs that
can be correctly handled by the programs debloated by DomGad,
we provided Chisel withğ¼â€²â€². For each input in ğ¼â€²â€², we generated an
oracle using the same approach described in Section 5.2.4. For eachTable 3: Results of path identification and quantification.
ProgramPath Identification Path Quantification
#Paths MaxK Time (Hour) #Inputs PathProb Time (Hour)
bzip2-1.0.5 729 90 3.2 8321 0.938 2.6
chown-8.2 6 90 <0.1 8321 1 2.6
date-8.21 401 90 1.5 8321 0.949 2.7
grep-2.19 1290 77 6.7 8321 0.935 2.9
gzip-1.2.4 373 90 1.1 8321 0.929 2.5
mkdir-5.2.1 361 90 1.3 8321 0.952 2.3
rm-8.4 252 90 0.5 8321 0.918 2.5
sort-8.16 276 90 1.2 8321 0.96 2.8
tar-1.14 20 90 0.1 8321 0.999 3.6
uniq-8.16 31 90 0.1 8321 0.991 2.3
Table 4: Reduction (Red), generality (Gen), objective score
(OScore) size reduction (SizeRed), and attack surface reduc-
tion (AttkSurfRed) of the debloated programs generated by
DomGad andDebop (averaged over all programs).
kr kgRed Gen OScore
DomGad Debop DomGad Debop DomGad Debop
0.5 0.1 0.82 0.5 0.06 0.93 0.74 0.54
0.5 0.3 0.7 0.5 0.56 0.95 0.66 0.63
0.5 0.5 0.5 0.49 0.95 0.96 0.72 0.72
0.5 0.7 0.49 0.5 0.96 0.96 0.82 0.82
0.5 0.9 0.49 0.49 0.96 0.96 0.91 0.91
kr kgSizeRed AttkSurfRed Red
DomGad Debop DomGad Debop DomGad Debop
0.25 0.5 0.67 0.67 0.31 0.31 0.58 0.58
0.5 0.5 0.67 0.67 0.33 0.31 0.5 0.49
0.75 0.5 0.67 0.67 0.32 0.32 0.41 0.4
Table 5: Size reduction (SizeRed), attack surface reduction
(AttkSurfRed), and reduction (Red) of the debloated pro-
grams generated by DomGad andChisel (averaged over all
programs).
kr kgSizeRed AttkSurfRed Red
DomGad Chisel DomGad Chisel DomGad Chisel
0.5 0.1 0.99 0.92 0.64 0.69 0.82 0.81
0.5 0.3 0.87 0.87 0.52 0.67 0.7 0.77
0.5 0.5 0.67 0.68 0.33 0.43 0.5 0.56
0.5 0.7 0.67 0.68 0.3 0.44 0.49 0.56
0.5 0.9 0.67 0.68 0.3 0.44 0.49 0.56
0.25 0.5 0.67 0.68 0.31 0.43 0.58 0.62
0.5 0.5 0.67 0.68 0.33 0.43 0.5 0.56
0.75 0.5 0.67 0.68 0.32 0.44 0.41 0.49
trial performed by DomGad, we obtained the corresponding pro-
gram and inputs and ran Chisel on those, using the same timeout
we used for DomGad.
5.2.6 Experiment Environment. We ran all of the experiments on a
machine with a 260GB RAM, 32 AMD-Opteron 1.4GHz processors,
and running Ubuntu-18.04.
5.3 Results
5.3.1 RQ1: DomGadâ€™s performance in terms of path identification
and quantification. Table 3 presents a summary of DomGadâ€™s path
identification and quantification results. From left to right, the table
shows the benchmark program (Program ), the number of paths
identified (#Paths ), the largest ğ¾achieved during path identifica-
tion (MaxK ) (this is the largest number of subsequent iterations
for which no new paths were identified), the time taken for path
identification (Time (Hour), 4-th column), the number of sampled
inputs used for path quantification (#Inputs ), the sum of path prob-
abilities for the paths identified (PathProb ), and the time taken for
path quantification (Time (Hour), last column).
The results show that, for all programs but grep-2.19, DomGad
was able to identify a set of paths Î that achieved ğ‘€ğ‘ğ‘¥ğ¾ =90,
thus satisfying the domain coverage constraint specified by the
231Subdomain-Based Generality-Aware Debloating ASE â€™20, September 21â€“25, 2020, Virtual Event, Australia
00.020.040.060.080.10.120.140.160.18
0
27
54
81
108
135
162
189
216
243
270
297
324
351
378
405
432
459
486
513
540
567
594
621
648
675
702bzip2 -1.0.5
00.050.10.150.20.250.30.35
0 1 2 3 4 5chown -8.2
00.010.020.030.040.050.060.070.08
0
15
30
45
60
75
90
105
120
135
150
165
180
195
210
225
240
255
270
285
300
315
330
345
360
375
390date -8.21
00.0050.010.0150.020.0250.030.0350.04
0
47
94
141
188
235
282
329
376
423
470
517
564
611
658
705
752
799
846
893
940
987
1034
1081
1128
1175
1222
1269grep -2.19
00.050.10.150.20.25
0
14
28
42
56
70
84
98
112
126
140
154
168
182
196
210
224
238
252
266
280
294
308
322
336
350
364gzip -1.2.4
00.050.10.150.20.250.30.350.40.45
0
13
26
39
52
65
78
91
104
117
130
143
156
169
182
195
208
221
234
247
260
273
286
299
312
325
338
351mkdir -5.2.1
00.020.040.060.080.10.120.140.16
0
9
18
27
36
45
54
63
72
81
90
99
108
117
126
135
144
153
162
171
180
189
198
207
216
225
234
243rm-8.4
00.050.10.150.20.25
0
10
20
30
40
50
60
70
80
90
100
110
120
130
140
150
160
170
180
190
200
210
220
230
240
250
260
270sort -8.16
00.020.040.060.080.10.120.140.16
012345678910111213141516171819tar-1.14
00.010.020.030.040.050.060.070.080.09
0123456789101112131415161718192021222324252627282930uniq -8.16
Figur
e 3: Path probability.
lower bound ğ‘=0.95and the confidence parameter ğµ=100. This
provides initial evidence that our approach is feasible, and that it is
often possible to identify a finite number of paths to achieve a high
coverage of the domain (as modeled by the input sampler).
Column PathProb shows the sum of the probabilities for the paths
inÎ . For all programs, this sum is higher than 0.9. For grep-2.19,
in particular, although set Î does not satisfy the domain coverage
constraint, the estimated path probability reaches 0.935, which is
only slightly lower than 0.95. For certain programs (e.g., bzip2-1.0.5 ),
although Î satisfies the domain coverage constraint, the estimated
probability is still lower than 0.95. This can happen, as the path
probability for ğœ‹âˆˆÎ is estimated, and the sum could therefore be
either slightly lower or slightly higher (than 0.95). Nevertheless,
the average path probability over all benchmark programs is 0.957,
which is fairly close to 0.95and which indicates that DomGadâ€™s
quantification is effective.
Figure 3 presents the distribution of path probabilities for the
paths identified by DomGad. For many of the programs considered,we can observe a small number of â€œhot pathsâ€ whose probabilities
are much higher than those of other paths. This implies that it
should be possible to produce, by preserving a small number of
suitable paths, debloated programs that achieve good tradeoffs
between reduction and generality.
5.3.2 RQ2: DomGadâ€™s performance in terms of stochastic optimiza-
tion. Table 4 shows a summary of DomGadâ€™s stochastic optimiza-
tion results. (Full results are available at on our companion website,
at https://sites.google.com/view/domgad/.) The table shows the
scores of the debloated programs generated by DomGad for dif-
ferentğ‘˜ğ‘Ÿandğ‘˜ğ‘”values, averaged over all programs. Specifically,
forğ‘˜ğ‘Ÿ=0.5, andğ‘˜ğ‘”ranging from 0.1to0.9, the table shows, from
left to right, reduction (Red ), generality (Gen ), and objective score
(OScore ) for the programs generated by DomGad (and Debop). Sim-
ilarly, forğ‘˜ğ‘”=0.5andğ‘˜ğ‘Ÿranging from 0.25to0.75, the table shows,
from left to right, size reduction (SizeRed ), attack surface reduction
(AttkSurfRed ), and reduction (Red ) for the programs.
232ASE â€™20, September 21â€“25, 2020, Virtual Event, Australia Qi Xin, Myeongsoo Kim, Qirun Zhang, and Alessandro Orso
Whenğ‘˜ğ‘Ÿandğ‘˜ğ‘”are both 0.5(i.e., equal weights for size reduction
and attack surface reduction, and equal weights for reduction and
generality), DomGad produced a debloated program that achieves
(on average) 50% reduction (67% size reduction and 33% attack
surface reduction) and 95% generality. This result indicates that
DomGad is able to generate, by preserving paths that achieve a high
domain coverage, a reduced program that is significantly smaller
(in size and attack surface), yet is highly general.
Withğ‘˜ğ‘Ÿ=0.5andğ‘˜ğ‘”going from 0.1to0.9(i.e., with increasingly
higher weight given to generality and increasingly lower weight
given to reduction), DomGad produced debloated programs with
increasing generality (from 0.06to0.96) and decreasing reduction
(from 0.82to0.49). This confirms that DomGad is indeed able to
explore the space of solutions and produce debloated programs
with different tradeoffs.
Whenğ‘˜ğ‘”=0.5,DomGad achieves a high generality (0 .95), but
whenğ‘˜ğ‘”changes from 0.5to0.9, the generality only increases
slightly (0.01). Whenğ‘˜ğ‘”=0.5, we observe that, for seven benchmark
programs (all but date-8.21, grep-2.19, and gzip-1.2.4 ), the debloated
programs preserve all the paths identified. The reason for this result
is that DomGad, in its first step, successfully identified a small set
of paths Î that achieve high domain coverage. Even a reduced
program that preserves all these paths is still much smaller than the
original program, achieving a 0.49reduction on average. Therefore,
when reduction is not heavily weighed, DomGad tends to produce
a reduced program that preserves most of the paths in Î .
Whenğ‘˜ğ‘”is small (i.e., reduction is heavily weighed), DomGad
tends to produce a debloated program that preserves only a few
â€œhotâ€ paths, so as to reduce code as much as possible. As an example,
whenğ‘˜ğ‘”=0.1,DomGad produced a debloated program for mkdir
that preserves only three paths that have high probability (i.e.,
Nos. 0, 1, and 319 in Figure 3), achieving a reduction of 0.67and a
generality of 0.55.
Considering Table 4, we can observe that, when ğ‘˜ğ‘”is0.5and
ğ‘˜ğ‘Ÿranges from 0.25to0.75,DomGad does not indeed produce de-
bloated programs with different tradeoffs between size reduction
and attack-surface reduction. As we previously discussed, when
ğ‘˜ğ‘”is not extremely small, DomGad tends to produce a program
that preserves all the paths, and therefore does not explore differ-
ent reduction-generality tradeoffs. In future work, we will investi-
gate how these tradeoffs vary using different values of ğ‘˜ğ‘”, possibly
smaller than 0.5.
5.3.3 RQ3: Comparison between DomGad andDebop. Table 4 also
presents Debopâ€™s results. As the table shows, Debop produced de-
bloated programs with almost identical scores for reduction (about
0.5) and generality (about 0.95) whenğ‘˜ğ‘”varied from 0.1to0.9. In
these cases, therefore, Debop failed to produce debloated programs
with different tradeoffs between reduction and generality.
The reason why Debop only produced programs with high gen-
erality (even when ğ‘˜ğ‘”is as low as 0.1) is that its debloating process
starts with a program that handles all the provided inputs, and thus
preserves all the paths identified by DomGad. We observed that
Debopâ€™s stochastic search is not effective at exploring the search
space. The number of iterations that Debop performs (on average)
for its stochastic search is 29, which is insufficient for an effective
exploration.In contrast, in the same amount of time (i.e., six hours), Dom-
Gad performed over 6000 iterations. Note that, when ğ‘˜ğ‘”was not
extremely low (e.g., ğ‘˜ğ‘”=0.5),Debop produced debloated programs
with scores similar to those generated by DomGad. This result
is due to the fact that Debop happens to start with the programs
thatDomGad eventually identifies as optimally reduced (i.e., the
programs with all paths preserved). When ğ‘˜ğ‘”is low (i.e., less than
0.5), however, Debop could only generate debloated programs with
lower objective scores.
We believe that there are two main reasons why Debop has lim-
ited effectiveness. First, its search space is extremely large. Debop
reduces a program at the statement level, and the average number
of statements in its search space is 1105, which is larger than the
number of paths in DomGadâ€™s search space (374). Second, Debop,
as an input-based technique, has to run the entire set of inputs to
evaluate generality for every reduced program it generates, which
is expensive.
It is also worth noting that we provided Debop with a reduced
program that preserves all the paths identified by DomGad. Al-
though this allows for a fair comparison between DomGad and
Debop, it also makes Debopâ€™s debloating job easier, as Debop starts
from the partially debloated program that DomGad generates.
5.3.4 RQ4: Comparison between DomGad andChisel. Table 5
presents Chiselâ€™s result. As we stated above, because Chisel is a
reduction-oriented technique, we provided Chisel with the exact
inputs that DomGadâ€™s programs could correctly handle and only
compared the two techniques in terms of reduction.
Our results show that DomGad andChisel produce debloated
programs with similar size-reduction scores, but DomGad achieves
slightly higher size reduction on average. This implies that, even
using an aggressive approach that focuses only on reduction, Chisel
is not able to outperform DomGad and produce debloated programs
with a smaller size.
In terms of attack-surface reduction, however, DomGad does
not perform as well as Chisel. The reason for this is that DomGad
uses a path-based approach and only eliminates statements within
function bodies. Conversely, in addition to removing statements,
Chisel also reduces global variables and function declarations. This
helps Chisel produce a reduced program with a smaller binary
size, and hence a smaller attack surface. Based on these findings,
in future work we plan to investigate code-removal techniques
for non-executable statements, which should improve DomGadâ€™s
size-reduction performance.
It is worth noting that, since Chisel is a reduction-oriented
technique, we provided it with the inputs that DomGad could
correctly handle (similar to what we did for Debop). On the one
hand, this allowed for a fairer comparison between Chisel and
DomGad. On the other hand, however, it basically gave Chisel the
advantage of operating on an already partially-debloated program.
5.4 Threats to Validity
Like all evaluations, our empirical assessment of DomGad could
suffer from issues of internal and external validity. To account for
possible threats to internal validity, we thoroughly tested and spot-
checked our code. DomGad relies on an input sampler for path
identification and quantification, which we developed (and which
233Subdomain-Based Generality-Aware Debloating ASE â€™20, September 21â€“25, 2020, Virtual Event, Australia
took about a day of work). To reduce bias, we designed the sampler
so that they simulate how the benchmark program is used, accord-
ing to its usage profile. For the two techniques we used as baseline,
we leveraged the implementation provided by their authors [ 10,14].
As for threats to external validity, we evaluated the approaches on
ten Unix utility programs, and our results may not generalize to
more complex programs (e.g., programs involving user interactions,
database connections, and network communications) for which (1)
developing effective samplers would be more challenging and (2)
path identification and quantification and stochastic optimization
would be more expensive and difficult. As we will discuss in Sec-
tion 7, we envision a number of ways in which we could improve
DomGad to address possible issues that may arise when applying
it to larger and more complex benchmarks.
6 RELATED WORK
Program debloating .DomGad is related to a set of reduction-
oriented techniques that rely on a usage profile for debloating [ 22,
41,45,55,57]. TRIMMER [ 55] performs aggressive compiler op-
timization for code reduction. OCCAM [ 38] achieves reduction
through partial evaluation [ 28]. C-Reduce [ 45], Perses [ 57], and
Chisel [22] are reduction techniques based on delta-debugging [ 66].
J-Reduce [ 20] improves delta-debugging by leveraging dependency
information for effective reduction. The reduction approach adopted
byRazor [41] is based on code coverage, inference, and binary
rewriting. Unlike all these techniques, DomGad performs subdomain-
based debloating and produces reduced programs by focusing on
subdomains, rather than specific inputs. Moreover, unlike most of
these techniques, DomGad is not purely reduction-oriented; it also
accounts for generality while debloating and performs stochastic
optimization to strike a balance between reduction and general-
ity.Debop [61] is a technique that we developed in previous work
and that also performs optimization for debloating. Unlike Dom-
Gad, however, Debop is input-based and operates at the statement,
rather than path, level. As our empirical results show, this nega-
tively affects Debopâ€™s performance in terms of both reduction and
efficiency. DomGad is also related to techniques that perform static
analysis to remove dead or unused code [ 1,24,26,27,29,42] and
techniques that perform reduction either for specific applications
(e.g., containers [ 44] and web applications [ 3]) or for special pur-
poses (e.g., safety checking [ 15]). More broadly, DomGad is related
to approaches for detecting bloat [ 4,62,63], identifying unneces-
sary code [ 21], and identifying code of interest through program
slicing [ 60]. It would be interesting to investigate whether and how
DomGad could be combined with some of these techniques, and in
particular slicing.
Model counting and probabilistic analysis . Because Dom-
Gad performs statistical sampling for path identification and quan-
tification, it is related to model counting techniques [ 2,7,32], which
aim at quantifying the number of models that satisfy a given for-
mula. For similar reasons, it is also related to approaches for prob-
abilistic software analysis [ 5,16,51], which aim to quantify like-
lihood of the occurrence of certain probabilistic events. Finally,
DomGad is related to statistical model checking techniques [ 35],
which aim at verifying probabilistic properties through statistical
methods. For path quantification, DomGad performs a hit-or-misssampling method. Like the previous set of techniques, these ap-
proaches are mainly orthogonal to DomGad and may be interesting
to investigate for identifying possible synergies.
MCMC and optimization .DomGad uses an MCMC-based ap-
proach for stochastic optimization, so it is tangentially related to
techniques that leverage MCMC to tackle other problems, such as
optimization [ 52], bug finding [ 8,33], model-based GUI testing [ 56],
and program obfuscation [ 36]. Finally, DomGad is loosely related
to optimization techniques for resource adaptation [ 12], energy re-
duction [ 53], program repair [ 34], and, more broadly, for software
improvement [40].
7 CONCLUSION AND FUTURE WORK
Existing debloating techniques are prone to producing programs
that are overfitted to the specific user profile (i.e., set of inputs)
used to drive the debloating process and are therefore likely to fail
for most other inputs. To address this problem, we propose Dom-
Gad, a subdomain-based, generality-aware debloating technique.
Unlike most existing debloating approaches, which only consider
program-size reduction, DomGad also accounts for generalityâ€”a
programâ€™s ability to correctly handle inputs in its whole domain.
To do so, DomGad focuses on preserving specific paths, rather than
individual statements, within the original program, thus producing
reduced programs that are guaranteed to behave correctly for the
input subdomains characterized by these paths. In order to strike
a balance between reduction and generality, DomGad performs
stochastic optimization using an objective function that combines
these two conflicting measures and can achieve close-to-optimal
tradeoffs. Our evaluation of DomGad, performed on a benchmark
of ten Unix utility programs, shows that our technique can produce
debloated programs that achieve significant code reductions (50%
on average), while preserving high generality (95% on average).
Our results also show that DomGad performs well when compared
against two state-of-the-art debloating techniques.
In future work, we will first extend our evaluation by (1) applying
DomGad to a broader set of programs, to assess whether our cur-
rent results generalize, and (2) performing a user study, to measure
the value of generality in a more realistic context. Second, we will
investigate ways to improve the efficiency of path identification
and quantification. In particular, we will consider approaches such
as stratified sampling [ 47] and sequential sampling [ 58], as well as
study the possibility of performing path identification and quan-
tification simultaneously based on shared input samples. Third, we
will consider other stochastic approaches, such as those based on
Gibbs Sampling [ 17], to improve our optimization results. Finally,
we will research ways to infer the input distribution of a program,
possibly based on a usage profile, and build input samplers automat-
ically. To do this, we will consider approaches based on probabilistic
program synthesis [ 39], probability density estimation [ 59], distri-
bution estimation [30], and deep generative models [43, 46].
8 ACKNOWLEDGMENTS
We thank the authors of Chisel [22] for making their tool available.
Ravi Mangal provided helpful feedback on the approach. This work
was partially supported by NSF, under grant CCF-1563991, ONR,
under contract N00014-17-1-2895, and gifts from Facebook, Google,
and Microsoft Research.
234ASE â€™20, September 21â€“25, 2020, Virtual Event, Australia Qi Xin, Myeongsoo Kim, Qirun Zhang, and Alessandro Orso
REFERENCES
[1]Ioannis Agadakos, Di Jin, David Williams-King, Vasileios P Kemerlis, and Geor-
gios Portokalidis. 2019. Nibbler: debloating binary shared libraries. In Proceedings
of the 35th Annual Computer Security Applications Conference (ACSAC). 70â€“83.
[2]Abdulbaki Aydin, William Eiers, Lucas Bang, Tegan Brennan, Miroslav Gavrilov,
Tevfik Bultan, and Fang Yu. 2018. Parameterized model counting for string
and numeric constraints. In Proceedings of the 2018 26th ACM Joint Meeting on
European Software Engineering Conference and Symposium on the Foundations of
Software Engineering (ESEC/FSE). 400â€“410.
[3]Babak Amin Azad, Pierre Laperdrix, and Nick Nikiforakis. 2019. Less is more:
quantifying the security benefits of debloating web applications. In 28th USENIX
Security Symposium (USENIX Security 19). 1697â€“1714.
[4]Suparna Bhattacharya, Kanchi Gopinath, and Mangala Gowri Nanda. 2013. Com-
bining concern input with program analysis for bloat detection. In Proceedings of
the 2013 ACM SIGPLAN international conference on Object oriented programming
systems languages and applications (OOPSLA). ACM, 745â€“764.
[5]Mateus Borges, Antonio Filieri, Marcelo dâ€™Amorim, Corina S PÄƒsÄƒreanu, and
Willem Visser. 2014. Compositional solution space quantification for probabilis-
tic software analysis. In Proceedings of the 35th ACM SIGPLAN Conference on
Programming Language Design and Implementation (PLDI). 123â€“132.
[6]Erik Buchanan, Ryan Roemer, Hovav Shacham, and Stefan Savage. 2008. When
good instructions go bad: Generalizing return-oriented programming to RISC. In
Proceedings of the 15th ACM conference on Computer and communications security
(CCS). ACM, 27â€“38.
[7]Supratik Chakraborty, Kuldeep S Meel, Rakesh Mistry, and Moshe Y Vardi. 2016.
Approximate probabilistic inference via word-level counting. In Thirtieth AAAI
Conference on Artificial Intelligence (AAAI).
[8]Yuting Chen, Ting Su, and Zhendong Su. 2019. Deep differential testing of JVM
implementations. In Proceedings of the 41th International Conference on Software
Engineering (ICSE). 1257â€“1268.
[9]Herman Chernoff. 1952. A measure of asymptotic efficiency for tests of a hy-
pothesis based on the sum of observations. The Annals of Mathematical Statistics
(1952), 493â€“507.
[10] Chisel 2020. Chisel. https://github.com/aspire-project/chisel (accessed on
September 2020).
[11] ChiselBench 2020. ChiselBench. https://github.com/aspire-project/chisel-bench
(accessed on September 2020).
[12] Arpit Christi, Alex Groce, and Rahul Gopinath. 2017. Resource adaptation via test-
based software minimization. In 11th International Conference on Self-Adaptive
and Self-Organizing Systems (SASO). 61â€“70.
[13] Clang 2020. Clang: a C language family frontend for LLVM. https://clang.llvm.org/
(accessed on September 2020).
[14] Debop 2020. Debop: Program Debloating via Stochastic Optimization. https:
//sites.google.com/view/debop19 (accessed on September 2020).
[15] Kostas Ferles, Valentin WÃ¼stholz, Maria Christakis, and Isil Dillig. 2017. Failure-
directed program trimming. In Proceedings of the 2017 11th Joint Meeting on
Foundations of Software Engineering (ESEC/FSE). 174â€“185.
[16] Antonio Filieri, Corina S PÄƒsÄƒreanu, Willem Visser, and Jaco Geldenhuys. 2014.
Statistical symbolic execution with informed sampling. In Proc. of the ACM
SIGSOFT Intl. Symposium on Foundations of Software Engineering (FSE). 437â€“448.
[17] Stuart Geman and Donald Geman. 1984. Stochastic relaxation, Gibbs distributions,
and the Bayesian restoration of images. IEEE Transactions on Pattern Analysis
and Machine Intelligence (TPAMI) (1984), 721â€“741.
[18] Walter R Gilks, Sylvia Richardson, and David Spiegelhalter. 1995. Markov chain
Monte Carlo in practice. Chapman and Hall/CRC.
[19] Carla P Gomes, Ashish Sabharwal, and Bart Selman. 2006. Model counting: A
new strategy for obtaining good bounds. In Conference on Artificial Intelligence
(AAAI). 54â€“61.
[20] Christian Gram Kalhauge and Jens Palsberg. 2019. Binary reduction of depen-
dency graphs. In Proceedings of the 27th ACM Joint Meeting on European Software
Engineering Conference and Symposium on the Foundations of Software Engineering
(ESEC/FSE). ACM, 556â€“566.
[21] Roman Haas, Rainer Niedermayr, Tobias Roehm, and Sven Apel. 2020. Is Static
Analysis Able to Identify Unnecessary Source Code? ACM Transactions on
Software Engineering and Methodology (TOSEM) (2020), 1â€“23.
[22] Kihong Heo, Woosuk Lee, Pardis Pashakhanloo, and Mayur Naik. 2018. Effective
Program Debloating via Reinforcement Learning. In Proceedings of the 2018 ACM
SIGSAC Conference on Computer and Communications Security (CCS). 380â€“394.
[23] Curt Hibbs, Steve Jewett, and Mike Sullivan. 2009. The art of lean software
development: a practical and incremental approach. "Oâ€™Reilly Media, Inc.".
[24] Jianjun Huang, Yousra Aafer, David Perry, Xiangyu Zhang, and Chen Tian. 2017.
UI driven Android application reduction. In Proceedings of the 32nd IEEE/ACM
International Conference on Automated Software Engineering (ASE). IEEE, 286â€“296.
[25] Sumit K Jha, Edmund M Clarke, Christopher J Langmead, Axel Legay, AndrÃ©
Platzer, and Paolo Zuliani. 2009. A bayesian approach to model checking bio-
logical systems. In International conference on computational methods in systems
biology (CMSB). 218â€“234.[26] Yufei Jiang, Qinkun Bao, Shuai Wang, Xiao Liu, and Dinghao Wu. 2018. RedDroid:
Android application redundancy customization based on static analysis. In Pro-
ceedings of the 29th International Symposium on Software Reliability Engineering
(ISSRE). IEEE, 189â€“199.
[27] Yufei Jiang, Dinghao Wu, and Peng Liu. 2016. JRed: Program Customization and
Bloatware Mitigation Based on Static Analysis. In Proceedings of the 40th Annual
Computer Software and Applications Conference (COMPSAC). IEEE, 12â€“21.
[28] Neil D Jones, Carsten K Gomard, and Peter Sestoft. 1993. Partial evaluation and
automatic program generation. Peter Sestoft.
[29] Hyungjoon Koo, Seyedhamed Ghavamnia, and Michalis Polychronakis. 2019.
Configuration-Driven Software Debloating. In Proceedings of the 12th European
Workshop on Systems Security (EuroSec). ACM.
[30] Pedro LarraÃ±aga and Jose A Lozano. 2001. Estimation of distribution algorithms:
A new tool for evolutionary computation. Kluwer Academic Publishers.
[31] James R Larus. 2009. Spending Mooreâ€™s dividend. Commun. ACM (2009), 62â€“69.
[32] LattE 2020. LattE. https://www.math.ucdavis.edu/~latte/software.php
[33] Vu Le, Chengnian Sun, and Zhendong Su. 2015. Finding deep compiler bugs via
guided stochastic program mutation. In Proceedings of the 2015 ACM SIGPLAN
international conference on Object oriented programming systems languages and
applications (OOPSLA). 386â€“399.
[34] Claire Le Goues, ThanhVu Nguyen, Stephanie Forrest, and Westley Weimer. 2011.
GenProg: A generic method for automatic software repair. IEEE Transactions on
Software Engineering (TSE) (2011), 54â€“72.
[35] Axel Legay, BenoÃ®t Delahaye, and Saddek Bensalem. 2010. Statistical model check-
ing: An overview. In International conference on runtime verification. Springer,
122â€“135.
[36] Han Liu, Chengnian Sun, Zhendong Su, Yu Jiang, Ming Gu, and Jiaguang Sun.
2017. Stochastic optimization of program obfuscation. In 2017 IEEE/ACM 39th
International Conference on Software Engineering (ICSE). 221â€“231.
[37] llvm-cov 2020. llvm-cov. https://llvm.org/docs/CommandGuide/llvm-cov.html
[38] Gregory Malecha, Ashish Gehani, and Natarajan Shankar. 2015. Automated
software winnowing. In Proceedings of the 30th Annual ACM Symposium on
Applied Computing (SAC). ACM, 1504â€“1511.
[39] Aditya V Nori, Sherjil Ozair, Sriram K Rajamani, and Deepak Vijaykeerthy. [n.d.].
Efficient synthesis of probabilistic programs. In Proceedings of the 36th ACM SIG-
PLAN Conference on Programming Language Design and Implementation (PLDI).
[40] Justyna Petke, Saemundur O Haraldsson, Mark Harman, William B Langdon,
David R White, and John R Woodward. 2017. Genetic improvement of software:
a comprehensive survey. IEEE Transactions on Evolutionary Computation (TEVC)
(2017), 415â€“432.
[41] Chenxiong Qian, Hong Hu, Mansour Alharthi, Pak Ho Chung, Taesoo Kim,
and Wenke Lee. 2019. RAZOR: A Framework for Post-deployment Software
Debloating. In Proceedings of the 28th USENIX Conference on Security Symposium
(USENIX Security). 1733â€“1750.
[42] Anh Quach, Aravind Prakash, and Lok Yan. 2018. Debloating software through
piece-wise compilation and loading. In Proceedings of the 27th {USENIX}Security
Symposium ({USENIX}Security). 869â€“886.
[43] Alec Radford, Luke Metz, and Soumith Chintala. 2015. Unsupervised representa-
tion learning with deep convolutional generative adversarial networks. arXiv
preprint arXiv:1511.06434 (2015).
[44] Vaibhav Rastogi, Drew Davidson, Lorenzo De Carli, Somesh Jha, and Patrick
McDaniel. 2017. Cimplifier: automatically debloating containers. In Proceedings
of the 11th Joint Meeting on Foundations of Software Engineering (ESEC/FSE). ACM,
476â€“486.
[45] John Regehr, Yang Chen, Pascal Cuoq, Eric Eide, Chucky Ellison, and Xuejun
Yang. 2012. Test-case reduction for C compiler bugs. In Proceedings of the 33rd
ACM SIGPLAN Conference on Programming Language Design and Implementation
(PLDI). ACM, 335â€“346.
[46] Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. 2014. Stochastic
backpropagation and approximate inference in deep generative models. arXiv
preprint arXiv:1401.4082 (2014).
[47] Christian Robert and George Casella. 2013. Monte Carlo statistical methods.
Springer Science & Business Media.
[48] ROPgadget 2020. ROPgadget. https://github.com/JonathanSalwan/ROPgadget
[49] Sampler 2020. Detailed Description of the Sampler Programs. https://drive.google.
com/open?id=1D6-RurlAOu7RMpBxXEdGNV9pCtbu8Xuh
[50] Adrian Sampson, Pavel Panchekha, Todd Mytkowicz, Kathryn S McKinley, Dan
Grossman, and Luis Ceze. 2014. Expressing and verifying probabilistic assertions.
InProceedings of the 35th ACM SIGPLAN Conference on Programming Language
Design and Implementation (PLDI). 112â€“122.
[51] Sriram Sankaranarayanan, Aleksandar Chakarov, and Sumit Gulwani. 2013. Static
analysis for probabilistic programs: inferring whole program properties from
finitely many paths. In Proceedings of the 34th ACM SIGPLAN conference on
Programming language design and implementation (PLDI). 447â€“458.
[52] Eric Schkufza, Rahul Sharma, and Alex Aiken. 2013. Stochastic superoptimization.
InEighteenth International Conference on Architectural Support for Programming
Languages and Operating Systems (ASPLOS). 305â€“316.
[53] Eric Schulte, Jonathan Dorn, Stephen Harding, Stephanie Forrest, and West-
ley Weimer. 2014. Post-compiler software optimization for reducing energy.
235Subdomain-Based Generality-Aware Debloating ASE â€™20, September 21â€“25, 2020, Virtual Event, Australia
InProceedings of the 19th international conference on Architectural support for
programming languages and operating systems (ASPLOS). 639â€“652.
[54] Hovav Shacham et al .2007. The geometry of innocent flesh on the bone: return-
into-libc without function calls (on the x86).. In ACM conference on Computer
and communications security. ACM, 552â€“561.
[55] Hashim Sharif, Muhammad Abubakar, Ashish Gehani, and Fareed Zaffar. 2018.
TRIMMER: application specialization for code debloating. In Proceedings of the
33rd ACM/IEEE International Conference on Automated Software Engineering (ASE) .
ACM, 329â€“339.
[56] Ting Su, Guozhu Meng, Yuting Chen, Ke Wu, Weiming Yang, Yao Yao, Geguang
Pu, Yang Liu, and Zhendong Su. 2017. Guided, stochastic model-based GUI
testing of Android apps. In Proceedings of the 25th ACM Joint Meeting on European
Software Engineering Conference and Symposium on the Foundations of Software
Engineering (ESEC/FSE). 245â€“256.
[57] Chengnian Sun, Yuanbo Li, Qirun Zhang, Tianxiao Gu, and Zhendong Su. 2018.
Perses: Syntax-guided program reduction. In Proceedings of the 40th International
Conference on Software Engineering (ICSE). ACM, 361â€“371.
[58] Abraham Wald. 1945. Sequential tests of statistical hypotheses. The annals of
mathematical statistics (1945), 117â€“186.
[59] Edward J Wegman. 1972. Nonparametric probability density estimation: I. A
summary of available methods. Technometrics (1972), 533â€“546.
[60] Mark Weiser. 1984. Program slicing. IEEE Transactions on software engineering
(TSE) (1984), 352â€“357.[61] Qi Xin, Myeongsoo Kim, Qirun Zhang, and Alessandro Orso. 2020. Program
debloating via stochastic optimization. In Proceedings of the 42st International
Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER).
65â€“68.
[62] Guoqing Xu, Matthew Arnold, Nick Mitchell, Atanas Rountev, and Gary Sevitsky.
2009. Go with the flow: profiling copies to find runtime bloat. In Proceedings
of the 30th ACM SIGPLAN Conference on Programming Language Design and
Implementation (PLDI). ACM, 419â€“430.
[63] Guoqing Xu, Nick Mitchell, Matthew Arnold, Atanas Rountev, Edith Schonberg,
and Gary Sevitsky. 2014. Scalable runtime bloat detection using abstract dynamic
slicing. ACM Transactions on Software Engineering and Methodology (TOSEM)
(2014).
[64] Guoqing Xu, Nick Mitchell, Matthew Arnold, Atanas Rountev, and Gary Sevitsky.
2010. Software bloat analysis: finding, removing, and preventing performance
problems in modern large-scale object-oriented applications. In Proceedings of
the FSE/SDP workshop on Future of software engineering research. ACM, 421â€“426.
[65] HÃ¥kan LS Younes. 2006. Error control for probabilistic model checking. In
International Workshop on Verification, Model Checking, and Abstract Interpretation .
Springer, 142â€“156.
[66] Andreas Zeller and Ralf Hildebrandt. 2002. Simplifying and isolating failure-
inducing input. IEEE Transactions on Software Engineering (TSE) (2002), 183â€“200.
236