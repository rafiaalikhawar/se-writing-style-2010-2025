API-Misuse Detection Driven by Fine-Grained API-Constraint
Knowledge Graph
Xiaoxue Renâˆ—â€ 
Zhejiang University
China
xxren@zju.edu.cnXinyuan Ye
Australian National University
Australia
u6296255@anu.edu.auZhenchang Xingâ€¡
Australian National University
Australia
zhenchang.Xing@anu.edu.au
Xin XiaÂ§
Monash University
Australia
xin.xia@monash.eduXiwei Xu
Data61, CSIRO
Australia
Xiwei.Xu@data61.csiro.auLiming Zhu/pilcrow
Data61, CSIRO
Australia
Liming.Zhu@data61.csiro.au
Jianling Sun
Zhejiang University
China
sunjl@zju.edu.cn
ABSTRACT
API misuses cause significant problem in software development.
ExistingmethodsdetectAPImisusesagainstfrequentAPIusage
patterns mined from codebase. They make a naive assumptionthat API usage that deviates from the most-frequent API usageis a misuse. However, there is a big knowledge gap between API
usagepatternsandAPIusagecaveatsintermsofcomprehensive-
ness, explainabilityandbest practices.In thiswork, wepropose a
novelapproachthatdetectsAPImisusesdirectlyagainsttheAPI
caveat knowledge, rather than API usage patterns. We developopen information extraction methods to construct a novel API-constraint knowledge graph from API reference documentation.
ThisknowledgegraphexplicitlymodelstwotypesofAPI-constraint
relations(call-orderandcondition-checking)andenrichesreturn
and throw relations with return conditions and exception triggers.
It empowers the detection of three types of frequent API misuses -
missing calls, missing condition checking and missing exceptionhandling, while existing detectors mostly focus on only missingcalls. As a proof-of-concept, we apply our approach to Java SDK
API Specification. Our evaluation confirms the high accuracy of
the extracted API-constraint relations. Our knowledge-driven API
âˆ—Also with Ningbo Research Institute.
â€ Also with PengCheng Laboratory.
â€¡Also with Data61, CSIRO.
Â§Corresponding author.
/pilcrowAlso with University of New South Wales.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ASE â€™20, September 21â€“25, 2020, Virtual Event, Australia
Â© 2020 Association for Computing Machinery.
ACM ISBN 978-1-4503-6768-4/20/09...$15.00
https://doi.org/10.1145/3324884.3416551misusedetectorachieves0.60(68/113)precisionand0.28(68/239)
recall for detecting Java API misuses in the API misuse benchmark
MuBench. This performance is significantly higher than that of
existing pattern-based API misused detectors. A pilot user study
with12developersshowsthatourknowledge-drivenAPImisuse
detectionisverypromisinginhelpingdevelopersavoidAPImisuses
and debug the bugs caused by API misuses.
CCS CONCEPTS
â€¢Software and its engineering â†’Softwarelibrariesandreposi-
tories.
ACM Reference Format:
XiaoxueRen,XinyuanYe,ZhenchangXing,XinXia,XiweiXu,LimingZhu,
and Jianling Sun. 2020. API-Misuse Detection Driven by Fine-Grained API-
ConstraintKnowledgeGraph.In 35thIEEE/ACMInternationalConference
onAutomatedSoftwareEngineering(ASEâ€™20),September21â€“25,2020,Virtual
Event, Australia. ACM, New York, NY, USA, 12 pages. https://doi.org/10.
1145/3324884.3416551
1 INTRODUCTION
SoftwarelibrariesprovidereusablefunctionalitiesthroughAppli-
cation Programming Interfaces (APIs). APIs often come with usage
caveats, such as constraints on call order or value/state conditions.
For example, when using the Iteratorin Java, one should check
that hasNext() returnstrue(i.e.,theiterationhasmoreelements)
beforecalling next(),toavoid NoSuchElementExcpetion.Applica-
tions that fail to follow these caveats (i.e., misuse APIs) may suffer
from bugs. [ 3,9â€“11,24,37]. There are many pattern-based tools
for detecting API misuses by static code analysis [ 2,17,18,24â€“
26,30,41â€“44].AllthesemethodsmineAPIusagepatternsfroma
codebase,andmakeanaiveassumptionthatanydeviationswith
respect to these patterns are potential misuse [4].
The systematic evaluation by Amann et al. [ 4] reveals that all
pattern-based API-misuse detectors, no matter which form of API
4612020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE)
patterns they adopt (call pairs/sequences [17, 44], program depen-
dencygraph[ 25,29,42],statemachine[ 26]),sufferfromlowpreci-
sion(0-11%)andrecall(0-20%)inpractice.Someapproachesattempt
to improve detection results by obtaining larger codebase through
code search engine [ 41], adopting more informative usage repre-
sentation [ 25,38], or building more robust probabilistic models of
deviation[ 26].However,noneoftheseimprovementsgobeyond
the naive assumption of pattern-based API-misuse detection.
In this paper, we propose a knowledge-driven approach, which
detectsAPImisuseagainstanovelAPI-constraintknowledgegraph,
rather than against API usage patterns that may not reliably man-
ifest API usage caveats (see Section 2 for the discussion on the
knowledgegapbetweenAPIusagepatternsandAPIusagecaveats).
Existing static code linting tools like FindBugs [ 28], Pylint [ 40]
cover only general programming anti-patterns (e.g., null reference,
useless control flow) that may cause program errors, but not usage
caveatsofhundredsorthousandsofspecificAPIs.Compilersreport
onlycompilationerrors(e.g.,unhandledexception)basedonAPI
declaration,buttheyareunawareofAPIusageconstraints,suchas
proper call order, prerequisite state, or value range.
API documentation is an important knowledge source of API
usage caveats [ 16,20]. Although IDEs provide direct access to API
documentation, API documentation, at least in their current semi-
structureddocumentform,areinsufficienttodirectlysolvetheAPI
misuse problem [ 1,16,27]. To improve the accessibility of API-
caveat knowledge, Li et al. [ 16] used Natural Language Processing
(NLP) techniques to construct a API-caveat knowledge graph from
API documentation. This knowledge graph supports API-centric
search of caveat sentences. The extracted natural language caveat
sentencesareusefulforlinkingAPIcaveatswitherroneouscode
examples or explaining controversial API usage on Stack Over-
flow [32,33]. However, caveat sentences cannot be directly used to
detect API misuses in source code in their natural language form.
In this paper, we propose a API-constraint knowledge graph:
the entities represents API elements and value literals, and the
edges represent declaration relations and four types of constraints
(call-order,condition-checking,return-condition,exception-trigger)
between APIs (see Section 3.1). Different from existing API knowl-
edge graphs [ 16,19] that capture only declaration relations and
simply link API-caveat sentences to an API as its attributes, we
develop NLP techniques to transform API-caveat sentences intospecific API constraint relations. For example, by analyzing thereturn description â€œtrue if the iteration has more elementsâ€ of It-
erator.hasNext() and the throws description â€œNoSuchElementEx-
cpetion - if the iteration has no elementsâ€ of Iterator.next(),w e
infer a state-checking relation from next()tohasNext() with the
expectedstate true,andtheconsequence NoSuchElementException
of violating this expected state, as shown in Figure 2(b). Compared
withexistingmethodsthatinferspecificationsfromtext[ 39,48,49],
ourapproach infersmore types ofand moreinformativeAPI con-straints.Givenagraphrepresentation(e.g.,AbstractSyntaxTree)
ofaprogram,welinktheprogramelementswiththeAPIentities
in our API-constraint knowledge graph. By analyzing the API con-
straints in the knowledge graph that the linked program elements
violate, our approach reports API misuses and explain the detected
misused by relevant API caveats (see Figure 6 for an example).Asaproofofconcept,weapplyourapproachtoJavaSDKAPI
Specification and construct a knowledge graph which contains
1,938call-orderrelationsand74,207condition-checkingrelations
among 21,910 methods and 8,632 parameters, and 8,215 return-
value conditions and 12,477 exception trigger clauses. Using the
statistical sampling method [ 35], two developers independently
annotatetheaccuracyoftheextractedAPI-constrainedrelations.
The annotation results confirm the high accuracy ( >85%) of the
extractedinformationwithsubstantialtoalmostperfectagreementbetweenthetwoannotators.Forthe239APImisusesinthe54Java
projects in the MuBench [ 3], our API misuse detector achieves 60%
inprecisionand28%inrecall.Asacomparison,existingpattern-
baseddetectorsachieveabout0-11.4%inprecisionand0-20.8%in
recall according to the systematic evaluation of these detectors [ 4].
Weconductapilotuserstudywith12juniordeveloperswhoare
askedtofindandfixthebugsinsixAPImisusescenariosderived
from the MuBench. The developers, assisted by our API misuse
warnings, find and fix bugs much faster and more correctly than
those using standard IDE support. The developers rate highly (4 or
5 in 5-point likert scale) the relevance and usefulness of our API
misuse warnings, not only for debugging API misuses but also for
potentially avoiding them in the first place.
This paper makes the following contributions:
â€¢WeanalyzetheknowledgegapbetweenAPIusagecaveats
and API usage patterns, and how a knowledge graph ap-
proach may bridge the gap.
â€¢We constructthefirstAPI-constraint knowledgegraphwith
four types of API constraint relations, and build the first
knowledge-graph based API misuse detector.
â€¢Our manual analysis confirms the high quality of the con-
structedknowledgegraph,andourbenchmarkevaluation
anduserstudydemonstratetheeffectivenessandusefulness
of our knowledge-graph based API misuse detection.
2 MOTIVATION EXAMPLES
To overcome the limitations of pattern-based API misuse detection
identifiedin[ 4],weanalyzetheknowledgegapbetweenAPIusage
caveats and API usage patterns. We focus on API usage caveats
specifying call order and condition checking, as violations of these
caveats represent the most frequent API misuses [ 4]. We illustrate
thegapwithtypicalexamplesandAPIusagepatternsintheform
of call sequences, but the observed knowledge gap is not restricted
totheseexamplesorspecificformsofAPIpatterns.WediscusshowaAPI-constraintknowledgegraphcanbridgethegap(seeSection3
for knowledge graph schema and construction method).
2.1 Comprehensiveness
APIpatternsmaycoveronlysomeAPIusagecaveats,depending
on API usage frequencies. Figure 1(a) shows a code example of
Java Swing APIs which satisfies the call-order constraint â€œthe add()
method changes layout-related information ... the component hier-
archy must be validated thereafter in order to reflect the changesâ€.
If there are enough code snippets like the one in Figure 1(a) in a
codebase, add()â†’validate() can be mined as an API pattern, which
helps to detect calling add()without validate() as a misuse. Besides
add(),therearemanyotherlayout-changingmethodslike remove()
462(a)
    
   	


 
  	 
 
	
              
                      
(b)
Figure 1: Example of Java Swing APIs
(a)
!" #$ %" &$'% ( ) # *" +,) # *" + ,
$ #- & . #+ ,/0 1 23 4 51 2 6783 3 9: 4 3; 5 4 5 9< = > 9? 51 2 6 @
A4
B C95
A2
DA4
B C95
A2
DE> 43 3 2F
D9F G/? F 9> 9
D9@/0 1 23 4 51 26 7H 2; I>
A<3 9
C9 65 < => 9? 5 1 2 6@
E
B5 4 5 9
J>
A9>
K1 6 :G/< =? 9> 5 9
D; 5 45 97 5 F I9 @H 2; I>
A<3 9
C96 5 < => 9? 51 2 6 83 3 9: 4 3; 5 4 5 9< = > 9? 51 2 6
A4
B C95
A2
D
(b)
Figure 2: Example of Java Collections APIs
which have the same call-order constraint. However, if the API call
sequence panel.remove(); panel.validate() isnotfrequentenough
inthecodebase, remove()â†’validate() willnotminedasapattern,
and consequently cannot detect missing validate() after remove().
If we model API usage caveats themselves, rather than how
frequenttheymanifestinacodebase,wecanachievemorecompre-
hensive coverage of API usage caveats. For example, by analyzing
the call-order constraint of all layout-changing methods, we can
constructaknowledgegraphlikeFigure1(b),whichcapturesthe
<call-order >[follow]relations from the method validate() to all
layout-changing methods (only add()andremove() is shown for
the clarify). Based on this knowledge graph, even there is no prior
use of remove() at all in the codebase, we can still detect calling
remove() without validate() as a misuse.
2.2 Explainability
APIpatternsrepresenttheoutcomesoffollowingAPIusagecaveats
incode,butoftencannotdistinguishwhysuchoutcomesemerge.
Figure 2(a) shows a code example of Java Collection APIs: check
that hasNext() returns true, then get the next element in the itera-
tion and finally remove this element. Some patterns can be mined
from such frequent use of collection APIs, such as hasNext() â†’
next(),next()â†’remove(), or even hasNext() â†’next()â†’remove(). Su-
perficially,theyalllooklikecall-orderconstraints.However,unlike
add()â†’validate() discussed in Section 2.1, there are no constraints
about calling next()(orremove()) after hasNext() (ornext()).
Theactualconstraintresultsinthepattern next()â†’remove()is
next()mustprecede remove(),otherwise remove() throws IllegalSta-
teException.Theactualconstraintresultsinthepattern hasNext()â†’
next()isthatoneshouldcall hasNext() tocheckthestateoftheiter-
ation before calling next(), because if the iteration has no elements,
(a)
L MN OP QOP
R S TU V WOP M
X YZ [ YMN OP Q
WOP M
X \SP QM
] WX[SQO P
^P
R S T_SQ
`MO
a S
bc
d e fg hi d j k d ef g hi d j kd ef g hi d j kd e fl e m eg hi hm
nfi ei h
o pd h
pq r s tuvw xl h
pi hk
yi ei h
zn {v|
rj } ei
rj
s z~
skh
x Â€i  ÂÂ‚ j Â€
sk f
wx phl i
rj
s{~
sk h
xÂ€ i ÂÂ‚ j Â€
sk f
wx phl i
rj
snf i ei h
o pd h
pq r st uv wxl h
pi hk
yi ei h
zÂƒ Â„
{v|
rj } ei
rj
sz~
sk h
x Â€ i ÂÂ‚ j Â€
sk f
wx phl i
rj
s{
m hi Â€ m
svrÂi d h
pd e m e
pm hmkj hf
sj ij
p pÂ€ m
{
(b)
Figure 3: Example of Java String APIs
(a)
Â… Â†Â‡ Â… ÂˆÂ‰ ÂŠ Â‹ÂŒ ÂˆÂ Â Â
Â
Â…Â‘
Â‰Â‰Â’
Â…Â† Â‹Â† Â Â
Â
Â…Â‘
Â‰ Â“ Â‰Â”Â• Â‰ ÂˆÂ
Â…Â‘
Â‰ Â“Â‰ Â” Â•Â‰ ÂˆÂÂ– Â‹Âˆ Â… Â— Â˜ Â
ÂˆÂ‰ Â” Â• Â ÂÂ™Âš Â›Â’
ÂŠÂ‰ Âœ Â‹Â… ÂŒÂ—
Â
Â…Â‘
Â‰Â
Â”ÂŸ
Â‰
Â  Â¡Â¢ Â£ Â¤ Â¥ Â Â¦ Â§Â  Â¡ Â¢Â£ Â¤Â¥ Â Â¦ Â§Â  Â¡Â¢ Â£ Â¤ Â¥ Â Â¦ Â§Â¥Â¨ Â©Âª Âª
Â¤Â¨Â«Â¬ Â¡Â­ Â­ Â¦Â¥ Â® Â¤Â¦ Â¯ Â¤Â­ Â¤Â§Â° Â¦Â¨Â¨
Â¤ Â¡Â§Â©
Â­Âª
Â±
Â¥Â¨ Â©Âª Âª
Â¤Â¨Â«Â¡ Â­ Â² Â³ Â´Â¤Â¨ Â¨
Â¦Â¨
Â¦Â¬ Â¬ÂµÂ¨
Â¢Â±
Â¶ Â¢Â¥ Â¡Â¥ Â¤Â· Â¬Â  Â¤ Â¬Â¸Â©
Â­Âª
Â¹Â«ÂºÂ»
Â¯Â¤ Â¬Â¥ Â¤Â§Â¼
Â¥ Â¡Â¥ Â¤Â½
Â¥Â¨
Âµ Â¤Â±Â«Â¾Â©
Â¦Â¿ Â¡ Â¥Â©
Â¦Â­Â½Â½
Ã€Â©
Â¿Â¤ ÃÂ¦ Â¥ Ã€ Â¦Âµ Â­ Â§ÂºÂ»
Â¬Â¤ Â¯Â¥Â©
Â¦Â­ Â±Â¶ Â¢Â¥ Â¡Â¥ Â¤Â· Â¬ Â Â¤ Â¬Â¸Â©
Â­Âª
Â¹Â«ÂºÂ»
Â¯ Â¤ Â¬Â¥ Â¤Â§Â¼
Â¥ Â¡Â¥ Â¤Â½
Â° Â¡ Â¿Â¢ Â¤ Â±Â«Â¾Â©
Â¦ Â¿Â¡ Â¥Â©
Â¦Â­Â½
Ã€Â©
Â¿Â¤ ÃÂ¦ Â¥ Ã€ Â¦Âµ Â­ Â§ÂºÂ»
Â¬ Â¤Â¯Â¥Â©
Â¦Â­ Â±Â±
Â  Â¡ Â¢Â¯ Â¡Â¨
Â¡Â£ Â¤Â¥ Â¤Â¨Â
Â…Â‘
Â‰Â
ÂŒÂ‹Â
ÂŒÃ‚
Â—Â• Â›Â’
ÂŠÂ‰ Âœ Â‹Â… ÂŒ Â—
Â Â¡ Â¢Â£ Â¤ Â¥ Â  Â¦Â§Ã€Â©
Â¿Â¤ ÃÂ¦ Â¥ Ã€ Â¦Âµ Â­Â§ÂºÂ»
Â¬ Â¤ Â¯Â¥Â©
Â¦Â­Ã€Â©
Â¿Â¤ ÃÂ¦ Â¥ Ã€ Â¦Âµ Â­ Â§ÂºÂ»
Â¬ Â¤Â¯Â¥Â©
Â¦Â­
(b)
Figure 4: Example of Java IO APIs
next()throws NoSuchElementException.APIpatternscannotdistin-
guishsuchfinedetailsofAPIcaveats.Graph-basedpatterns[ 25,38]
aremoreinformativethancallsequences,butitisnotstraightfor-
ward to infer all fine details of API caveats from code.
In contrast, we can analyze the natural language descriptions
of API caveats to distinguish different types of API constraints
and extract their fine details, as shown in the knowledge graphin Figure 2(b). Due to the clear semantics of the state-checking
andcall-orderrelations,wewillnotreportcalling (hasNext()) (or
next())withoutthefollowing next()(orremove())asamisuse.More
important, we can provide specific explanation of detected API
misuses,suchasmissingstatecheckingversusmissingpreceding
call, as well as the expected state and violation consequences.
2.3 Best Practices
API patterns fundamentally assume frequencies reflect the ratio-
nality of API usage, but this rationality may not correspond to the
bestpracticesofhandlingAPIcaveats. Figure3(a)showsacodeex-ampleofJavaStringAPIs: substring(indexOf()).ThisAPIchaincall
is frequent in code, but it lacks a sanity checking of the indexOf()â€™s
returnvalue,because indexOf() returns-1ifthechardoesnotoccur
in the string, and substring() throws IndexOutOfBoundsException
if its beginIndex argument is negative. As another example, Fig-
ure4(a)showsacodeexampleofJavaIOAPIs:enclosefileopenand
read operations in a try-catch to handle IOException, which is also
very common in code. However, this way of handling IOException
doesnotconsiderthespecificcausesoftheexception:â€œthefiledoes
not exist, or the file is a directory or an IO error occursâ€.
By analyzing the description of return value conditions, pa-
rameterconstraints,exceptioncausesandAPIfunctionalities,we
can model and reason about the complex constraint relations be-
tween APIs in the knowledge graphs in Figure 3(b) and Figure 4(b).
For example, by examining the chain call substring(indexOf())
463464graphisthesameasthegenericAPIknowledgegraphin[ 16,19],
we adopt their tested web page parser to extract API elements, API
namesanddescriptions,anddeclarationrelationsasrequiredinour
knowledgegraph(seeSection3.1).Inthiswork,weusethebrief
introduction sentences of each method in the method summary
section as that methodâ€™s functionality description.
To detect the API misuses related to API chain calls (e.g., sub-
string(indexOf())),weextendtheoriginalparserin[ 16,19]toe x-
tract more fine-grained return relations. The return section of a
methodmayhavemorethanonesentencetoexplaindifferentre-
turn values in different situations, for example, String.indexOf()
returns â€œthe index of the first occurrence of the character in the
charactersequenceâ€orâ€œ-1ifthecharacterdoesnotoccurâ€.Based
ontheobservationofthereturnsectionof1,000randomlysampled
methods,wedefineavaluegazetteerandasetofPart-Of-Speech
(POS)tagpatternstorecognizespecificvalues(e.g.,-1,true,false)
or ranges (e.g., negative, [0, 9]) mentioned in the return-value sen-
tences.Ifareturn-valuesentencecontainsaspecificvalueorrange,
we link the return relation to a value-literal entity (may need to
becreatedifitisnotyetintheknowledgegraph).Otherwise,we
create a return-value entity with that sentence as its description
and link the return relation to this return-value entity.
3.4 Deriving API Constraint Relations
DifferentfromexistingAPIknowledgegraphs[ 16,19]thatcapture
only declaration relations, our API-constraint knowledge graphcontainscall-orderandcondition-checkingrelationsbetweenre-
lated APIs, and constraint-enriched return and throw relations. We
usetheAPI-caveatsentencepatternsdevelopedin[ 16]toextract
twocategoriesofAPI-caveatsentences: temporal andconditional.
Differentfrom[ 16]thatsimplylinksAPI-caveatsentencestoAPI
elementsastextualattributes,wedevelopsentenceparsingandAPI
linking techniques to derive four types of API constraint relations
from API caveat sentences.
3.4.1 Extracting API-Caveat Clauses. As this work focuses on API-
methodusageconstraints,welimittheextractiontothemainde-
scriptionofeachmethod(excludingthefunctionalitydescription
sentence of the method entity) and the description in the methodâ€™s
return and throws section. Each extracted caveat sentence is asso-
ciated with its corresponding method or return/throw relation. We
processtheextractedcaveatsentencesintofine-grainedAPI-caveat
clauses by the following three steps, to facilitate the subsequent
API linking and constraint relation inference.
Co-referenceresolution. APIelementsareoftenmentionedby
pronouns in API-caveat sentences, for example, â€œIf the SecureRan-
domSpi() constructoris overriddenin animplementation, it(refer
toSecureRandomSpi())willalwaysbecalledwheneveraSecureRan-
dom is instantiatedâ€. We use co-reference resolution technique (as
implementedbyStanfordCoreNLP[ 21])toresolvethepronounsin
aAPI-caveatsentencetotheAPIsthatthepronounsrepresentin
the paragraph from which the sentenceis extracted. Furthermore,
theAPImethodsbeingexplainedarecommonlyreferredtoasâ€œthis
methodâ€ in its description, For example, â€œThis method is generally
called...ifafatalerrorhasmadetheconnectionunusableâ€inthe
descriptionof javax.sql.PooledConnection.Co-referenceresolutiontools cannot resolve this type of co-reference because the corre-
spondingAPIdoesnotappearinthesurroundingtexts.Weusethe
declaration-based heuristic [ 16] to resolve such co-reference to the
API method being explained.
Splitting sentencesinto clauses API-caveat sentences can be
rather complex. For example, â€œFileReader(String fileName) throws
FileNotFoundException if the named file does not exist, is a di-rectory or for some other reason cannot be opened for readingâ€.
This sentence has a result clause and a long if clause that has three
conditionclauses.Toderivefine-grainedAPIconstraints,weuse
POS tagging and dependency tree analysis (as implemented by
Standford CoreNLP [ 21]) to parse the whole sentence into several
fine-grained clauses. A conditional sentence is split into a result-
clauseandoneormoreconditionclauses.Wealsotrytoidentify
subject, verb-phrase and object in each clause using semantic role
labeling[ 15].Forexample,wecanextractSubject-Verb-Objectin
theresult-clauseasfollows:FileReader(StringfileName)[subject]
throws [verb-phrase] FileNotFoundException [object]. Note that
themissing subject(e.g., â€œthenamed fileâ€for the2ndand 3rdcon-
ditions) can be inferred by dependency tree analysis.
Similar clause clustering. One API caveat may be mentioned
indifferentpartsofamethodinthesameorsimilarway.Forexam-
ple, the main description of String.indexOf() has a conditional sen-
tenceâ€œifnosuchcharacteroccursinthisstring,then-1isreturnedâ€,
and the return section of indexOf() has another conditional sen-
tence â€œindexOf()returns -1if the characterdoes notoccurâ€. These
two sentences correspond to the same caveat. Furthermore, a class
may declare several overloading or similar-functionality methods
which often have the same or partially overlapping caveat sen-
tence. For example, both String.indexOf() andString.lastIndexOf()
have the caveat â€œreturn -1 if the character does not occurâ€. The
overloadingmethods substring(int beginIndex, int endIndex) and
substring(int beginIndex) havethesamecaveatclauseâ€œthebeginIn-
dex is negativeâ€ but also other different clauses.
We cluster similar caveat clauses by the word-embedding based
sentence similarity (see Section 3.4.2) which has been shown tobe effective in matching software text [
6,13,32,33]. The cluster-
ing is done progressively, first within method, then within class,and finally within package. Clustering within-method considersallcaveatclausesofamethod(nomattertheirdocumentsection
origin),but clusteringwithin-classorwithin-package groupsonly
the caveat clauses from the same type of document section. We
selectthecentroidsentenceinaclusterastherepresentativeofthe
cluster. If the cluster has only two sentences, we select the shorter
one.Clusteringsimilarcaveatclauseshavetwobenefits.First,we
canassociateacaveatclausetoamorespecificAPIelement/relation.
For example, we can know that the conditional clause from the
maindescriptionof String.indexOf() isactuallyrelatedtothereturn
relation, because a very similar clause is in the return section of
indexOf().Second,wecansignificantlyreducethenumberofcaveat
clauses to be analyzed in the subsequent API linking step.
3.4.2 Linking Caveat Clauses to API Elements. Givenacaveatde-
scription (a clause or its subject/object phrase) associated with a
methodorathrowrelation,weinfermethodsorparameterswhose
functionality descriptions match the caveat description. For exam-
ple, for the exception trigger clause â€œthe named file does not existâ€
465Table1:RulesforCreatingCall-orderorCondition-checkingRelations (p: paramter; vl: value literal; m: method; e: parameter
or method; mc: method of concern; v-c: value-checking; s-c: state-checking; c-o: call-order)
Clause Subject Object Value Type Relation Example
1- p - vl - [p,v-c,vl] [beginIndex, =, negative] â€œthe beginIndex argument is negativeâ€
2- p e - - [p,v-c,e][index,!<,String.length()]â€œtheindexargumentisnotlessthanthelength
of stringâ€
3m p - - - [p,s-c,m] [filename, true, File.exists()] â€œthe named file does not exisâ€
4- m1 m2 - - [m1,c-o,m2][setSystemId(String),precede,startDocument()]â€œsetSystemId(String)must
be called before the startDocument eventâ€
5- m - - temporal [m,c-o,mc][next(),precede,remove()]â€œifnext()hasnotyetbeencalledâ€intheremove()â€™s
throws section
6- m - - conditional [m,s-c,mc][undo(), true, canUndo()] â€œif canUndo() returns falseâ€ in undo()â€™s throws
section
7m - - - temporal [m,c-o,mc][validate(), follow, add()] â€œthe container must be validated thereafterâ€ in the
main description of Container.add()
8m - - - conditional [m,s-c,mc][next(),true,hasNext()]â€œiftheiterationhasnomoreelementâ€inthenext()â€™s
throws section
ontherelation [FileReader(String),throw,FileNotFoundException],
the subject â€œthe named fileâ€ matches the description â€œthe name
ofthefiletoreadfromâ€ofthe FileReader(String)â€™sparameter file-
Name, and the whole clause matches the functionality description
ofFile.exists() which states â€œtests whether the file or directory de-
notedbythisabstractpathnameexistsâ€.Basedonsuchmatches,we
linkthecaveatclauseoritssubject/objecttomethodsorparameters
that are referred to by the clause or its subject/object, or whose
functionality can fulfill or check the clause or its subject/object.
We perform the matching progressively, first match parameters
withinmethod,thenmatchmethodswithinclass,andfinallymatch
methodswithinpackage.Thematchingisdoneforthecaveatclause,
its subject phrase and object phrase respectively. The whole clause
may match a method, and the subject or object phrase may match
a parameter or a method. If a subject or object phrase containsannotated code element (e.g., in
<code>or<href>), we directly
link the subject or object to the corresponding API element byname matching. Otherwise, we match a caveat description withthe functionality description of API elements by text similarity.
We select the API element whose functionality description has
the highest similarity with the given caveat description within the
current matching context. If this highest similarity is above thesimilarity threshold (0.8 in this work), a matching is found. If a
matching is found within the current context, the matching stops.
Considering the sentence characteristics of caveat and func-
tionalitydescriptions,wecombineJaccardcoefficientandsentence-embeddingsimilaritytomatchthem.Wedenoteacaveatdescription
asğ‘ğ‘‘andafunctionalitydescriptionas ğ‘“ğ‘‘.BeforecomputingJac-
cardcoefficient,weconverteachsentenceintoabagofwords( ğµğ‘Šğ‘ğ‘‘
andğµğ‘Š ğ‘“ğ‘‘)usingthestandardtextprocessingprocedure(i.e.,tok-
enization,stopwordremovalandlemmatization).Then,theJaccardcoefficientof
ğ‘ğ‘‘andğ‘“ğ‘‘is:ğ‘ ğ‘–ğ‘š ğ‘—ğ‘ğ‘ğ‘ğ‘ğ‘Ÿğ‘‘=ğµğ‘Šğ‘ğ‘‘âˆ©ğµğ‘Š ğ‘“ğ‘‘/ğµğ‘Šğ‘ğ‘‘âˆªğµğ‘Š ğ‘“ğ‘‘.
Tocomputesentence-embedding,welearndomain-specificword
embeddings with the corpus of API text descriptions from API ref-
erence documentation using the continuous skip-gram model [ 22].
We use domain-specific word embeddings because recent stud-
ies[5,45]showthatdomain-specificwordembeddingsoutperforms
generalwordembeddingsforsoftwaretextmatching.Wesettheword embedding dimension at 200, as this setting has the best per-
formanceonsimilarAPItextcorpus[ 6].Wecomputeasentence
embeddingby averagingtheword embeddingsofall wordsinthe
sentence. Let ğ‘†ğ¸ğ‘ğ‘‘andğ‘†ğ¸ğ‘“ğ‘‘are the sentence embedding of ğ‘ğ‘‘and
ğ‘“ğ‘‘respectively.Thesentence-embeddingsimilarityof ğ‘ğ‘‘andğ‘“ğ‘‘is
the cosine similarity of ğ‘†ğ¸ğ‘ğ‘‘andğ‘†ğ¸ğ‘“ğ‘‘, i.e.,ğ‘ ğ‘–ğ‘š ğ‘ ğ‘’=ğ‘ğ‘œğ‘ (ğ‘†ğ¸ğ‘ğ‘‘,ğ‘†ğ¸ ğ‘“ğ‘‘).
Finally,weaverage ğ‘ ğ‘–ğ‘š ğ‘—ğ‘ğ‘ğ‘ğ‘ğ‘Ÿğ‘‘andğ‘ ğ‘–ğ‘š ğ‘ ğ‘’asthesimilarityofacaveat
description and a functionality description.
3.4.3 Creating API Constraint Relations. Given a caveat clause, we
analyze its API linking results and create a call-order or condition-
checking relation according to the heuristic rules in Table 1. These
heuristics rulesare summarizedbased onthe observation ofran-
domlysampled1,000caveatclauses.ForallotherAPIlinkingresults,
for example, none of the clause, subject phrase or object phrase is
linked to an API element (e.g., â€œan IO error occursâ€ associated withthe relation [FileReader.read(), throw, IOException] ), or only the sub-
jectphraseislinkedtoaparameterofthemethod(e.g.,â€œthenamed
file for some other reason cannot be opened for readingâ€ associ-
atedwiththerelation [FileReader(String),throw,FileNotFoundExcep-
tion], thecaveat clause remains intact withits originally associated
method or throw relation. The first three rows in Table 1 cover the
caveat clauses that describe the value or state validity of the pa-
rameters. Such caveat clauses are converted into value-checking orstate-checkingrelationsbetweenaparameterandavalueliteral,be-
tween two parameters, or between a parameter and a method. The
4throwcoversthecaveatclausesthatexplicitlymentiontwometh-
odsanddescribecall-orderconstraints,e.g.,â€œsetSystemId(String)
must be called before the startDocument eventâ€.
It is common that a caveat clause mentions only one method in
its subject (the 5th and 6th rows) or the whole clause corresponds
to one method (the 7th and 8th rows). In such cases, the other
method that is implicitly referenced is the method of concern (i.e.,
the method that this clause is associated with), for example, the
caveatâ€œifnext()hasnotyetbeencalledâ€forthe Iterator.remove()
method, or â€œthe container must be validated thereafter in order
todisplaytheaddedcomponentâ€forthe Container.add() method.
Therefore, we create a constraint relation between the explicitly
mentioned method and the method of concern for the cases in
rows5/6/7/8.Dependingonwhetherthecaveatclauseisatemporal
466or conditional clause, we create either a call-order relation or a
state-checking relation. Value literals are extracted by the value
gazetteerandPOStagpatternswedevelop.Never-seenvalueliterals
will be added to the knowledge graph. We also develop POS tag
patternstoextractfrequently-usedvalue-checkingexpressionsand
convert them into mathematical formula (e.g., â‰¥,<,=,â‰ ,âˆˆ[...])
as the expected expressions of the value-checking relations. If the
caveat clause is associated with a throw exception, we use thenegation of the formula as the expected expression. If the clausedoes not have such frequently-used value-checking expressions,
we use the verb-phrase of the clause as the expected expression.
For state-checking relation, if the linked method has some specific
returnvaluewhosereturn-conditionmatchesthecaveatclause,we
use this specific return value as the expected state, such as true
forhasNext() checking before calling next(). Otherwise, we use
the verb-phrase of the clause as the expected state. For the call-order relation, if the temporal clause has some guard condition
clause,e.g.,â€œifthecontainerhasalreadybeendisplayedâ€forcalling
validate(), we use this condition clause as the condition of the
call-orderrelation.Ifthecaveatclauseisassociatedwithathrow
relation, the violation attribute of the created constraint relation
references to the exception entity of the throw relation.
3.5 API Misuse Detection
Wedevelopaknowledge-drivenAPImisusedetectorthatexamines
the API usage in a program against the constructed API-constraint
knowledgegraph.Inthiswork,thedetectorperformsstaticcode
analysis on the Abstract Syntax Tree (AST) of the program. Foreach API method used in the program (denoted as
ğ‘ğ‘ğ‘–ğ‘), it first
linksğ‘ğ‘ğ‘–ğ‘toanAPImethodintheknowledgegraph(denotedas
ğ‘ğ‘ğ‘–ğ‘˜ğ‘”) by matching their fully-qualified names. Then, it collects all
call-order, condition-checking, and throw relations of ğ‘ğ‘ğ‘–ğ‘˜ğ‘”.
For the call-order relation, the detector examines if the required
preceding or following method is called before or after calling
ğ‘ğ‘ğ‘–ğ‘. For the condition-checking relation, the detector examines
if the required value or state checking is performed before call-ing
ğ‘ğ‘ğ‘–ğ‘. If the required checking is found in the program and
the expected expression or state of the condition-checking rela-tion involves specific values/states and mathematical formulas,the detector further examines if the expected expression or statecan be satisfied by the program. Let
ğ‘’ğ‘¥ğ‘ ğ‘andğ‘’ğ‘¥ğ‘ ğ‘˜ğ‘”be the for-
mula of the corresponding condition checking in the program and
in the knowledge graph respectively. The detector examines if
(ğ‘’ğ‘¥ğ‘ ğ‘âˆ§Â¬expğ‘˜ğ‘”)âˆ¨(Â¬ğ‘’ğ‘¥ğ‘ ğ‘expğ‘˜ğ‘”)issatisfiablebyaSATsolver[ 8].
If a violation of the required call-order or condition-checking is
detected, the detector reports not only an API misuse, but also the
consequence of API misuse, the relevant API to fix the misuse, and
the original API caveat sentence as the explanation of the API mis-
use.Ifthecompilerdetectsanunhandledexception ğ‘¢ğ‘’forğ‘ğ‘ğ‘–ğ‘,our
detectorlocatesthespecificthrowrelationfor ğ‘¢ğ‘’inourknowledge
graph and reports the associated exception trigger.
Empowered by the API-constraint knowledge graph, our API
misuse detector can perform fine-grained analysis of API usage in
the program. For example, for the code in Figure 6, the compiler
reports an â€œUnhandled exception: FileNotFoundExceptionâ€ for new
FileReader(file), and an â€œUnhandled exception: IOExceptionâ€ for
Figure 6: Our API Misuse Detection Capability
reader.read(). ReadingAPI documentmay not clearlyidentify spe-
cific cause(s) for FileNotFoundException, because it can be caused
by three conditions â€œthe file does not existâ€, â€œthe file is a directoryâ€,
or â€œthe file for some other reason cannot be opened for readingâ€.
AdeveloperoftensimplyenclosestheAPIcallsbytry-catchlike
the one in Figure 4(a). Actually, the code checks if(file.exists()),
which satisfies the state-checking relation [file, true, File.exists()].
Therefore,ourdetectordoesnotreportanyissueforthefirstcondi-
tion. But our detector reports the missing of the second condition
basedonthestate-checkingrelation [file,false,File.isDirectory()],
andrecommendsusing File.isDirectory() toperformthismissing
checking.Asthefirsttwoconditionsareeitherhandledorreported
as missing, our detector reports the third condition as a specific
causefor FileNotFoundException.SuchdetailedAPImisusereports
and suggestions can enable more robust API usage.
OurdetectorcheckstheissuesrelatedtoAPIchaincalls,such
assubstring(indexOf()) inFigure3(a).Itanalyzesthedefinition-use
information inthe programto collectthe APIs ğ‘ğ‘ğ‘–ğ‘‘whose return
valuesareusedastheparameters ğ‘ğ‘ğ‘Ÿğ‘ğ‘šofğ‘ğ‘ğ‘–ğ‘.Ifğ‘ğ‘ğ‘–ğ‘‘returnsspe-
cificvaluesundercertainconditions(e.g., [indexOf(),return,-1] with
theconditionâ€œthecharacterdoesnotoccurâ€),thedetectorexaminesifthisspecificreturnvalueviolatessomevalue-checkingrelationsof
ğ‘ğ‘ğ‘Ÿğ‘ğ‘š.Forexample,the beginIndex parameterof substring(int) has
a value-checking relation [beginIndex, <value-checking >[!=], nega-
tive], which is violated by the return-1 of indexOf(). Therefore, our
detector reports a missing-value-checking for substring(indexOf()),
with the condition â€œthe character does not occurâ€ and the violation
consequence IndexOutOfBoundsExcpetion.
4 TOOL IMPLEMENTATION
We construct a API-constraint knowledge graph for Java APIs. Us-
ingthe web pageparserdevelopedLiu etal.[ 19],weextract72,337
API elements (including 59,991 API methods, 11,334 parameters
and1,012exception),and64,400APIdeclarationrelations(includ-
ing45,247returnrelationsand18,999throwrelations).Usingthe
API-caveat sentence patterns developed by Li et al. [ 16], we ex-
tract97,462conditionalandtemporalAPI-caveat sentences.From
theseAPI-caveatsentences,ourapproachcreates1,938call-order
relations, 74,207 condition checking relations, and enrich 8,215return relations with return-value conditions and 12,477 throwrelations with exception triggers. These API-constraint relationsinvolve 21,910 methods, 8,632 parameters, and 8,215 return and
12,477 throw relations. We develop an IntelliJ IDE plugin which
detects API misuses in Java programs based on the constructed
API-constraint knowledge graph (see Figure 6).
4675 QUALITY OF KNOWLEDGE GRAPH
We first want to evaluate the quality of the constructed knowl-
edge graph. As we use tested tools [ 16,19] to extract API ele-
ments and declaration relations from API documentation and to
extract API-caveat sentences, we do not repeat the evaluation of
these information extraction steps. We focus our evaluation on the
fourtypesofAPIconstraintrelations,whichdistinguishourAPI-
constraint knowledge graph from existing general API knowledge
graphs [16, 19] .
5.1 Experiment Setup
As our knowledge graph contains large numbers of API constraint
relations, we use a statistical sampling method [ 35] to examine
ğ‘€ğ¼ğ‘[35]randomlysampledinstancesofeachtypeofconstraint
relation.ğ‘€ğ¼ğ‘inthisworkwhichensurestheestimatedaccuracy
is in 0.05 error margin at 95% confidence level. For conditionedreturn relations, we examine two checkpoints: the accuracy of
value-literals and the accuracy of condition clauses. For throw rela-
tions, weexamine twocheckpoints:the accuracy of triggerclauses,andifthetriggerclauseshouldbeconvertedintospecificcall-order
or condition-checking relations, rather than remaining as an ex-ception trigger. For call-order and condition-checking relations,
we examine three checkpoints: if the corresponding API caveat
clause should be modeled as a call-order or condition-checking
relation, the accuracy of API linking, and the accuracy of relevant
attributes(expectedexpression,expectedstate,condition,violation).
Thetwodevelopers(whoarenotinvolvedinthisstudyandhave
more than 3 years Java development experience) independently
perform the examination and all decisions are binary. We compute
Cohenâ€™sKappa[ 14]toevaluatetheinter-rateragreement.Forthe
datainstancesthatthetwoannotatorsdisagree,theyhavetodis-
cussandcometoaconsensus.Basedontheconsensusannotations,
we evaluate the quality of the created API constraint relations.
5.2 Results
Table2showstheexaminationresults.SeeSection5.1fortheex-
planation of checkpoints. The columns ğ´ğ‘ğ‘1 andğ´ğ‘ğ‘2 show the
accuracybythetwoannotatorsindependently.Thecolumn ğ´ğ‘ğ‘ğ¹
isthefinalaccuracyafterresolvingthedisagreements.ThecolumnKap.istheKappainter-rateragreement.Theaccuraciesofalltypes
of extracted information are above 85% The Cohenâ€™s Kappa are all
above0.60,whichindicatessubstantialtoalmost-perfectagreement
between the two annotators.
Thetriggerclausesonthrowrelationhave100%accuracy,which
is unsurprising because these exception triggers extracted fromthe throws section of a method. Exception clauses describe the
exception-handlingknowledgeinnaturallanguagesentences.In
our work, we want to covert as many exception clauses as possible
to call-order or condition-checking relations, because call-orderand condition-checking relations represent exception-handlingknowledge in a more fine-grained, structured way and supportsmore fine-grained API usage analysis. However, the should-not-
be-trigger row shows that 15% of the examined exception triggers
shouldbeconvertedintocall-orderorcondition-checkingrelations,
butnot.Theprimaryreasonisthatourapproachfailstolinkthe
clauseoritssubject/objectphrasestorelevantAPIelements.Forexample, the trigger clause â€œif the calling thread does not have
permission to create a new class loader.â€ for the relation [check-
CreateClassLoader(),throw,SecurityExceptio] shouldbemodelasa
state-checking relation [checkCreateClassLoader(), true, checkPer-
mission(Permission)].However,asthefunctionality descriptionof
checkPermission(Permission) isnotsimilartothistriggerclause,
our method fails to make the link.
Although our method may miss some API links,the API links
it makes are very accurate (95.3% for call-order and 94.3% for
condition-checking). Many API elements that are mentioned in
thecaveatclausesarewithinmethodorclass,andtheseelements
are easy to match within local context. For those API elements
outside the class, they are usually annotated by the API hyperlink,
from which API elements can be directly inferred. Our methodalso achieves high accuracy (
>98%) for extracting value-literals,
return-condition clauses and attributes of call-order and condition-
checkingrelations.Thisisbecausethesetypesofinformationare
extractedbythegazetteerandsentencepatternswecarefullydefine.
Our API-constraint knowledge graph contains highly accurate API-
constraintrelations,whichcansupportpracticaluse.Theextraction
of call-order and condition-checking relations can be further en-
hanced by more robust API linking methods.
6 EFFECTIVENESS EVALUATION
Next,weevaluatetheeffectivenessofourknowledge-drivenAPI
misuse detection using the API misuse benchmark MuBench [3].
6.1 Experiment Setup
MuBenchhasbeenactivelymaintained.ThelatestversionofMuBench
contains 269 instances of intra-method API misuses in 69 software
projects. For each API misuse, MuBench identifies API(s) involved,
provides a brief description of the misuse, and reference to thesource code that contains the misuse. As our current knowledge
graph supports only Java SDK APIs, we use Java SDK API misuses
inthe54Javaprojects.Wedownloadtheprojectsourcecodeand
make it compilable. We collected in total 239 instances of API mis-
uses in these 54 projects, including 114 missing call, 107 missing
condition checking and 18 missing exception handling. These API
misusesinvolve30APImethods,andviolates104APIusagecaveats
described in Java SDK API documentation.
WeapplyourAPImisusedetectortothemethodsthatcontain
theAPImisuses,andexaminehowmanyofthe239APImisuses
canbedetectedbyourdetector.Wealsoexamineiftheexplanation
that our tool provides for the detected misuse matches the misuse
description in the benchmark. As determining the precision of the
detected API misuses requires in-depth project-specific knowledge,
we only make an estimation of the lower bound of the detection
precision. Thatis, we assume thatonly API misusesthat match the
ground-truth misuses are correct, but all others are incorrect.
6.2 Results
Our detector reports 113 API misuses, including 66 missing call,
42missingconditioncheckingand5missingexceptionhandling.
Amongthese113APImisuses,68areconfirmedbytheMuBench,
including 37 missing call, 29 missing condition checking and 2missing exception handling. The caveat descriptions of these 68
468Table 2: Accuracy of the API-Constraint Relations
Relations Check Points Acc1 Acc2 AccF Kap.
Conditioned
Returnvalue-literal 98.7% 99.2% 99.0% 0.60
condition clause 99.7% 99.7% 99.7% 1.00
Trigger on
Throwtrigger clause 100.0% 100.0% 100.0% 1.00
should not be trigger? 88.0% 85.7% 85.9% 0.87
Call-orderAPI linking 95.1% 96.4% 95.3% 0.84
attribute 97.1% 98.7% 98.2% 0.62
Should be call-order? 90.4% 91.7% 90.9% 0.86
Condition-
checkingAPI linking 96.4% 94.3% 94.3% 0.77
attribute 99.5% 99.2% 99.5% 0.80
Should be cond-checking? 95.3% 96.4% 95.6% 0.74
Table 3: Six API Misuse Scenarios in Our User Study
Task Involved API Misuse reason Difficulty
T-1java.util.Arrays Condition-checking Easy
T-2java.util.List,
java.util.ArrayListCondition-checking Easy
T-3java.io.FileReader,java.io.File,java.util.Scanner
Condition-checking Medium
T-4javax.swing.JFrame,javax.swing.JButton,javax.swing.JPanel
Call-order Difficult
T-5java.util.ArrayList,java.util.Iterator,java.util.List
Missing call Medium
T-6javax.swing.JFrame,java.awt.DimensionMissing call Difficult
confirmed API misuses are consistent with the corresponding API
misuse descriptions in the MuBench. Our detection precision is
60.18% overall, 56% for missing call, 69% for missing condition
checking and 40% for missing exception handling. Note that these
precision are lower bound estimations, as we assume that all non-
confirmed 45 (113 âˆ’68) API missuses are incorrect. According to
our observation, some non-confirmed API misuses reported by our
detector, for example some missing value or state checkings, could
be API misuses. MuBench does not consider them, because they do
not yet cause any bugs in the program. But adding these condition
checkings could make the program more robust.
Thelowerboundprecisionofourdetectorisstillmuchhigher
than the precisions achieved by the best pattern-based API misuse
detector, which is only 11% according to the evaluation of all popu-
larpattern-baseddetectors[ 4].Suchlowprecisionistheprimary
barrierforadoptingthesedetectorsinpractice.Accordingto[ 4],
there are two correlated reasons for such low precisions. First, the
APIusagepatternsminedbythesedetectorscoveronlythemost
frequent usage, but they miss many uncommon and alternative
usage.Second,thesedetectorsmakeanaiveassumptionthatadevi-ation from the mined patterns correspond to a misuse. In Section 2,
weillustratedthesetworeasonswithfourexamples.Readersare
referredto[ 4]forthedetailedanalysisofthesetworeasons.Incon-
trast,ourdetectionisbasedontheAPIcaveatknowledgeextracted
fromAPIreferencedocumentation,whichhasnothingtodowith
whether an API is used and how frequent it is used in code.The recallof ourdetectionis 28.45%(68 /239),which is on-par
with the conceptual recall upper bound that all existing pattern-
based API misuse detector could achieve (by feeding them suffi-ciently examples of correct usage corresponding to the misusesin question) [
4]. The actual recalls of pattern-based API misuse
detectors are much lower (0-20%). Our detector does not need to
learn from code examples,but it islimited bythe knowledge cover-
age of the underlying knowledge graph. In fact, this is the primary
reasonfortheAPImisusesthatourdetectorfailstodetect,account-
ing for 86.55% (148 /171) misses. Our knowledge graph currently
covers four types of API-constraint relations, but there are othertypes of API usage knowledge, for example, multiplicity (e.g., It-
erator.remove() canonlybecalledonceafter Iterator.next()),API
equivalence(e.g., isEmpty(), size()=0and hasNext() forcollection
APIs),no-effectAPIcalls(e.g.,thecalltosomeAPIisignoredunder
certaincondition),orclass-levelusage(e.g.,The CharsetEncoder
class should be used when more control over the encoding process
is required). We leave the extension of our knowledge graph to
accommodate these types of API usage knowledge as future work.
TherestofmissedAPImisuses(13.45%)areduetothelimitation
ofourcurrentprogramminganalysisanddetectionheuristics,as
these API misuses demand advanced pointer analysis, data flow
analysis or expression evaluation.
Ourknowledge-graphbasedAPImisusedetectioncandetectmissing
calls,missingconditioncheckingandmissingexceptionhandling
with good precision. To improve the recall of our detection, more
types of API usage knowledge should be extracted and added to the
underlying knowledge graph, and some advanced programming
analysis should be supported.
7 USEFULNESS EVALUATION
7.1 User Study Design
We select six API misuse scenarios from the webtend project in
MuBench[ 3].Notethatsimilarscenariosalsooccurinotherprojects
in MuBench. As summarized in Table 3, these six scenarios involve
misuses of Java Swing, IO and Collections APIs: two about missing
call,oneabouterroneouscallorder,andthreeaboutmissingcon-
ditionchecking.Foreachmisusescenario,wecreateamethodto
simulatethecoreprogramlogicandAPIusage(notjustthemisused
API) in the original method involved in the scenario. We do not
use the original method because they have project-specific code
elements which demand certain project-specific knowledge, while
our study focuses on finding and fixing API misuses. Ho wever, the
createdmethodsarestillrealistic,executableprograms.Ourtoolre-
ports potential API misuses for all APIs in a method, among which
developers have to identify the API misuse leading to the bug.
We recruit 12 master students from our school. None of these
studentsareinvolvedinourwork.Thesestudentshavebasicknowl-
edge of Java SDK APIs, but do not use Java in their daily work. As
ourAPImisusescenariosdonotinvolveadvancedJavaAPIs,we
believe these students are qualified for our study. Furthermore,
theyalsosimulatethetargetaudiencethatourtoolaimstoassist,
i.e., developers who may lack relevant knowledge in finding andfix API misuses. Based on a pre-study survey of these studentsâ€™
Javaprogrammingexperience,werandomlyallocatethemintotwo
469Table 4: Results of User Study
Metric T-1T-2T-3T-4T-5T-6Aveg.
AccuracyG11.001.001.000.330.670.500.75
G21.001.001.001.000.830.830.94
Imp.0.00%0.00%0.00%203%24%66%49%
Time (min)G12.922.535.089.334.377.505.29
G21.581.922.833.582.334.172.74
Imp.-46%-24%-44%-62%-47%-44%-45%
Error
PronenessG12.002.504.174.173.334.173.39
G21.672.173.173.502.333.332.70
Imp.-17%-13%-24%-16%-30%-20%-20%
WarningRelevanceG11.001.003.331.001.001.501.47
G24.334.334.334.174.173.004.06
Imp.333%333%30%317%317%100%238%
WarningUsefulnessG11.001.003.001.001.001.501.42
G24.004.174.504.334.333.674.17
Imp.300%317%50%333%333%144%194%
equivalentgroups:thecontrolgroup(G-1)usesthestandardIntelliJ
IDEtocompletethetasks,whiletheexperimentalgroup(G-2)uses
the IntelliJ IDE with our API misuse detection plugin.
Theparticipantsaregiven10minutesforeachtask.Eachtask
includes a buggy method and describes the expected program out-
put.TheparticipantscanuseanyIDEfeatureslikeaccessingAPI
document and debugging. They can also search the Internet and
readanyinformationtheyfeelusefulforthetask.Iftheparticipants
believe they fix the API misuse in the task method, they submit
thefixedcodewhichsignalthetaskcompletion.Theparticipants
fill in a short survey for each task. The survey asks the partici-
pants to rate: the error proneness of the API misuses if developers
were given our API misuse warnings (or standard IDE warnings if
any),therelevanceofourdetectedAPImisuses(orstandardIDE
warnings if any) to the task method, and the usefulness of our API
misusewarnings(orstandardIDEwarningsifany)forfixingthe
misuse.Allratingsare5-pointlikedscale(1beingleastand5being
most).Aftertheexperiment,wecollectthetaskcompletiontime
and examine if the submitted code actually fixes the API misuses.
7.2 Results
Our tool can report more than one API misuse warnings duringthe completion of theeach tasks. However, by examining thede-scription of API misuse warnings (see the examples in Figure 6),participants can quickly filter out warning irrelevant to the bug.So their task completion does not seem to be interfered with by
multiple API misuse warnings. Furthermore, the irrelevance to the
bug does not necessarily mean the API misuse warnings are false-
positivewarnings.AsdiscussedinSection6.2,somewarnings,if
adopted, could improve the overall robustness of the code. That is
why such â€œirrelevantâ€ API misuses does not lower the ratings of
warning relevance and usefulness.
Table 4 shows our study results with five metrics: answer cor-
rectness,taskcompletiontime,errorproneness,warningrelevance,andwarningusefulness.Weaveragethemetricsforthecontroland
experimentalgrouprespectively.Forthethreemissing-condition-
checking tasks Task-1/2/3, both groups achieve 1.0 answer cor-
rectness.Thatis,alltheparticipantssuccessfullyfindandfixthe
bugs in these three tasks. This is because missing condition check-
ings are relatively easy to spot, when analyzing the unexpectedprogram outputs. In Task-1/2/3, the standard IntelliJ IDE does not
provideanywarningsforthebuggymethods.Infact,IntelliJpro-
videverylittlesupportfortheconcernedAPImisusesinalltasks
except Task-3. That is why the control group generally give theleast rating (1) to warning relevance and usefulness. In contrast,the experimental group highly rate (mostly 4 or 5) the relevance
and usefulness of our API misuse warnings. With the guidance of
our API misuse warnings, the experimental group find and fix the
bugsinTask-1/2/3inamuchshortertimethanthecontrolgroup.
Furthermore,theexperimentalgroupratethebugsinTask-1/2/3
less error prone if developers were given our API misuse warnings,comparedwiththeerror-proneratingsbythecontrolgroup.While
theparticipantsmodifythecodeinTask-3,IntelliJreportsanun-
handled FileNotFoundException and suggest to use try-catch to fix
the problem. Therefore, Task-3 obtains the best warning relevance
and usefulness scores among the six tasks for the control group.
Task-4hasthelargestdifferenceinanswercorrectnessbetweenthe
twogroups.OnlytwoparticipantsinthecontrolgroupfindandfixthebuginTask-4inthegiven10minutestimeslot.Eventhesetwoparticipantsspendabout8minutestocompletethetask.Incontrast,allsixparticipantsintheexperimentalgroupsuccessfullycomplete
the task, with the average completion time 4 minutes. Task-4 isa erroneous call order problem ( validate() should be called after
add()). It is much harder to find the root cause of this call-order
problemthanmissingcondition-checking.Task-5andTask-6are
missing-call problems. The difference of the answer correctness
between the two groups are in between that of the easy Task-1/2/3
and the difficult Task-4. The experimental group still complete the
Task-5/6 in shorter time than the control group, and rate the error
proneness lower and the warning relevance/usefulness higher.
Ourpilotuserstudydemonstratesthatourknowledge-drivenAPI
miuse detection is promising in assist developers in avoiding poten-
tial API misuses and debugging bugs caused by API misuses.
8 THREATS TO VALIDITY
AsourapproachextractsAPIcaveatknowledgefromAPIdocumen-
tation,thequalityofAPIdocumentationaffectstheeffectivenessof
ourapproach.Ourapproachisinspiredbythestudies[ 16,19,36]
showingthathigh-qualitydocumentationexist,especiallyformajor
SDKs, and they are an important source of information referenced
for resolving API misuses [16, 32, 33].
Our approach has been tested on Java SDK 13. Other SDKs may
describetheAPIknowledgeindifferentdocumentstructuresand
sentence variants. Our experiments identify other types of APIusage knowledge that should also be covered. As the schema ofour API-constraint knowledge graph and our open information
extractionpipelinearegeneric,wecanadapt,extendandtestour
knowledgegraphonotherlibrariesandothertypesofAPIusage
knowledge.WecanalsoextendourknowledgegraphtomodelAPI
caveats from multiple versions of a SDK, which may support novel
evolution analysis of API caveats/misuses.
Ourapproachachievesthestart-of-the-artdetectionaccuracyon
MuBench.However,furtherexperimentsarerequiredtoconfirm
thegeneralizabilityofourapproachonmoreAPIsandtheirmisuses,
and unknown bugs beyond the benchmark. Furthermore, some ad-
vancedprogramanalysiscouldbeintegratedinourtooltoboost
470the detection recall. Our user study demonstrates the promising
usefulness of our knowledge-driven API misuse detection. How-ever, the scale of user study is small and in a control setting. In
future,wewouldalsoliketouseexistingprojectstoevaluateour
tool.additionally,wewillworkwithindustrypartnerstotestthe
practicality of our approach and tool in real-world software devel-
opment context, especially the usefulness of â€œnon-bugâ€ related API
misuse warnings, regarded as false positives in this work.
9 RELATED WORK
APImisusesareinevitablenotonlyinsourcecode[ 3,31]butalsoin
programming discussionforums [ 1,7,32,33]. To reduce therisk of
APImisuses, manypattern-basedAPImisuse detectorshavebeen
proposed[ 23,25,43,44].Accordingtothesystematicevaluationof
the 12 detectors [ 4], most of them focus on detecting missing calls.
Onlyfour[ 2,25,30,41]candetectmissingconditioncheckingor
missingexceptionhandlingunderspecialconditions.Incontrast,
ourknowledgegraphbaseddetectorcandetectallthreetypesof
API misuses. Furthermore, Amann et al. [ 4] show that existing
detectorsachievevery lowprecisionandrecall.A recentdetector
MUDETECT [ 38] mines API usage graphs from cross-project code
examples,whichimprovessignificantlytheperformanceofpattern-
based API misuse detectors. But its performance is still lower than
ourknowledge-graphbaseddetection,exceptfortherecallachieved
by mining cross-project code examples. The recall of our approach
can be improved by adding more types of API constraints in theknowledge graph. Readers are referred to Section 2 for the gap
analysis of pattern-based and our knowledge-based methods.
Knowledgegraphhasemergedasanovelwayofrepresenting
andreasoning softwareengineeringknowledge [ 12,47].Two gen-
eral API knowledge graphs [ 16,19] have been constructed from
API reference documentation and one task-oriented knowledge
graph[36]hasbeenconstructedfromprogrammingtutorials.These
knowledgegraphssupportentity-centricsearchofAPIcaveatsandprogrammingtasks.Renetal.[
32,33]usetheextractedAPI-caveat
sentences to distill erroneous code examples or explain controver-
sial API usage on Stack Overflow. All these existing works treat
API caveats as natural language sentences. In contrast, we develop
sentenceparsingandAPI linkingtechniquestoinferfine-grained
API-constraint relations from API-caveat sentences.
Robillardetal. [ 34]providesa surveyonAPIproperty inference
techniques,includingDoc2Spec[ 48]whichinfersrulesfromtext.
Doc2Spec [ 48] and a similar work iComment [ 39] focus on call-
orderrules,whileourapproachinfersnotonlycallorderbutalso
conditionchecking,returnconditionandexceptiontrigger.Arecent
work by Zhou et al. [ 49] infer simple parameter value and type
restrictionsfrommethodcomments.OurmethodinfersmuchmoresophisticatedparameterandexceptionconstraintsfromAPIcaveatsentences(seeFigure3(b)andFigure4(b)).Finally,differentfromthe
toolsFindBugs[ 28],Pylint[ 40]thatdetectgeneralprogramming
anti-patterns, our tool detects misuses of specific APIs.
10 CONCLUSION AND FUTURE WORK
Thispaperpresentsthefirstknowledge-graphbasedAPImisuse
detection method. Unlike existing pattern-based API misuse detec-
tors,ourmethoddoesnotinferAPImisusesagainstAPIpatternsincode.Instead,itdetectsAPImisusesagainstfourtypesofAPI-
constraint relations in a novel knowledge graph, derived from API
referencedocumentationusingNLPtechniques.Thisknowledge
graph advances the start-of-the-art in API misuse detection, and
outperformexistingpattern-baseddetectorsbyalargemarginin
precision and recall. The usefulness of our knowledge-graph based
API misuse detection has also been demonstrated. In the future,
we will enrich our knowledge graph with more types of API us-
age knowledge, support the chain effect analysis of API caveats,
and support advanced program analysis to boost its recall. We will
also evaluate the ability of our approach to battle the issues of API
misuses, from prevention to detection to fixing.
11 ACKNOWLEDGEMENTS
ThisresearchwaspartiallysupportedbytheNationalKeyR&DPro-
gramofChina(No.2019YFB1600700),NSFCProgram(No.61972339),theAustralianResearchCouncilâ€™sDiscoveryEarlyCareerResearcher
Award (DECRA) (DE200100021), ANU-Data61 Collaborative Re-
search Project(CO19314), and Alibaba-Zhejiang University Joint
Institute of Frontier Technologies.
REFERENCES
[1]Yasemin Acar, Michael Backes, Sascha Fahl, Doowon Kim, Michelle L Mazurek,
andChristianStransky.2016. Yougetwhereyouâ€™relookingfor:Theimpactof
informationsourcesoncodesecurity.In 2016IEEESymposiumonSecurityand
Privacy (SP). IEEE, 289â€“305.
[2]Mithun Acharyaand Tao Xie. 2009. Mining API error-handling specifications
from source code. In International Conference on Fundamental Approaches to
Software Engineering. Springer, 370â€“384.
[3]Sven Amann, Sarah Nadi, Hoan A Nguyen, Tien N Nguyen, and Mira Mezini.2016. MUBench: a benchmark for API-misuse detectors. In Proceedings of the
13th International Conference on Mining Software Repositories. 464â€“467.
[4]Sven Amann, Hoan Anh Nguyen, Sarah Nadi, Tien N Nguyen, and Mira Mezini.
2018. Asystematicevaluationofstaticapi-misusedetectors. IEEETransactions
on Software Engineering 45, 12 (2018), 1170â€“1188.
[5]Chunyang Chen, Zhenchang Xing, and Ximing Wang. 2017. Unsupervised
software-specificmorphologicalformsinferencefrominformaldiscussions.In
Proceedings of the 39th International Conference on Software Engineering. IEEE
Press, 450â€“461.
[6]GuibinChen,ChunyangChen,ZhenchangXing,andBowenXu.2016. Learningadual-languagevectorspacefordomain-specificcross-lingualquestionretrieval.In
2016 31st IEEE/ACM International Conference on Automated Software Engineering
(ASE). IEEE, 744â€“755.
[7]Mengsu Chen, Felix Fischer, Na Meng, Xiaoyin Wang, and Jens Grossklags. 2019.
How reliable is the crowdsourced knowledge of security implementation?. In
2019IEEE/ACM41stInternationalConferenceonSoftwareEngineering(ICSE).IEEE,
536â€“547.
[8]NiklasEÃ©nandNiklasSÃ¶rensson.2003. AnextensibleSAT-solver.In International
conference on theory and applications of satisfiability testing. Springer, 502â€“518.
[9]Manuel Egele, David Brumley, Yanick Fratantonio, and Christopher Kruegel.2013. An empirical study of cryptographic misuse in android applications. In
Proceedingsofthe2013ACMSIGSACconferenceonComputer&communicationssecurity. 73â€“84.
[10]
Sascha Fahl, Marian Harbach, Thomas Muders, Lars BaumgÃ¤rtner, Bernd
Freisleben,andMatthewSmith.2012. WhyEveandMalloryloveAndroid:An
analysis of Android SSL (in) security. In Proceedings of the 2012 ACM conference
on Computer and communications security. 50â€“61.
[11]MartinGeorgiev,SubodhIyengar,SumanJana,RishitaAnubhai,DanBoneh,and
VitalyShmatikov.2012. Themostdangerouscodeintheworld:validatingSSL
certificatesinnon-browsersoftware.In Proceedingsofthe2012ACMconference
on Computer and communications security. 38â€“49.
[12]Zhuobing Han, Xiaohong Li, Hongtao Liu, Zhenchang Xing, and Zhiyong Feng.
2018. Deepweak: Reasoning common software weaknesses via knowledge graph
embedding. In 2018 IEEE 25th International Conference on Software Analysis,
Evolution and Reengineering (SANER). IEEE, 456â€“466.
[13]QiaoHuang,XinXia,ZhenchangXing,DavidLo,andXinyuWang.2018. API
methodrecommendationwithoutworryingaboutthetask-APIknowledgegap.InProceedingsofthe33rdACM/IEEEInternationalConferenceonAutomatedSoftware
Engineering. ACM, 293â€“304.
471[14]JRichardLandisandGaryGKoch.1977. Anapplicationofhierarchicalkappa-
typestatisticsintheassessmentofmajorityagreementamongmultipleobservers.
Biometrics (1977), 363â€“374.
[15]WoongKiLee,YeonSuLee,Hyoung-GyuLee,WonHoRyu,andHaeChangRim.
2012. OpenInformationExtractionforSOVLanguageBasedonEntity-Predicate
Pair Detection. In Proceedings of COLING 2012: Demonstration Papers. 305â€“312.
[16]Hongwei Li, Sirui Li, Jiamou Sun, Zhenchang Xing, Xin Peng, Mingwei Liu, and
XuejiaoZhao.2018. Improvingapicaveatsaccessibilitybyminingapicaveats
knowledge graph. In 2018 IEEE International Conference on Software Maintenance
and Evolution (ICSME). IEEE, 183â€“193.
[17]Zhenmin Li and Yuanyuan Zhou. 2005. PR-Miner: automatically extracting
implicitprogrammingrulesanddetectingviolationsinlargesoftwarecode. ACM
SIGSOFT Software Engineering Notes 30, 5 (2005), 306â€“315.
[18]ChristianLindig.2015. Miningpatternsandviolationsusingconceptanalysis.
InThe Art and Science of Analyzing Software Data. Elsevier, 17â€“38.
[19]Mingwei Liu, Xin Peng, Andrian Marcus, Zhenchang Xing, Wenkai Xie, Shuang-
shuangXing,andYangLiu.2019. Generatingquery-specificclassAPIsummaries.
InProceedings of the 2019 27th ACM Joint Meeting on European Software Engi-
neeringConferenceandSymposiumontheFoundationsofSoftwareEngineering.
120â€“130.
[20]WalidMaalejandMartinPRobillard.2013.PatternsofknowledgeinAPIreference
documentation. IEEE Transactions on Software Engineering 39, 9 (2013), 1264â€“
1282.
[21]Christopher D Manning, Mihai Surdeanu, John Bauer, Jenny Rose Finkel, Steven
Bethard, and David McClosky. 2014. The Stanford CoreNLP natural languageprocessing toolkit. In Proceedings of 52nd annual meeting of the association for
computational linguistics: system demonstrations. 55â€“60.
[22]TomasMikolov,IlyaSutskever,KaiChen,GregSCorrado,andJeffreyDean.2013.
DistributedRepresentationsofWordsandPhrasesandtheirCompositionality.
arXiv: Computation and Language (2013).
[23]Martin Monperrus, Marcel Bruch, and Mira Mezini. 2010. Detecting missingmethod calls in object-oriented software. In European Conference on Object-
Oriented Programming. Springer, 2â€“25.
[24]Martin Monperrus and Mira Mezini. 2013. Detecting missing method calls as
violationsofthemajorityrule. ACMTransactionsonSoftwareEngineeringand
Methodology (TOSEM) 22, 1 (2013), 1â€“25.
[25]Tung Thanh Nguyen, Hoan Anh Nguyen, Nam H Pham, Jafar M Al-Kofahi, and
Tien N Nguyen. 2009. Graph-based mining of multiple object usage patterns.
InProceedings of the 7th joint meeting of the European Software Engineering
Conference and the ACM SIGSOFT symposium on the Foundations of Software
Engineering. 383â€“392.
[26]Tam TheNguyen, Hung VietPham, Phong MinhVu, andTungThanh Nguyen.
2015. Recommending API usages for mobile apps with hidden markov model. In
2015 30th IEEE/ACM International Conference on Automated Software Engineering
(ASE). IEEE, 795â€“800.
[27]â€œArtifactPageâ€.2017. [Online]. Available:http://www.st.informatik.tu-darmstadt.
de/artifacts/mustudy/.
[28]BillPughandDavidHovemeye.2015.FindBugs.http://findbugs.sourceforge.net/.
[29]Murali Krishna Ramanathan, Ananth Grama, and Suresh Jagannathan. 2007.
Path-sensitive inference of function precedence protocols. In 29th International
Conference on Software Engineering (ICSEâ€™07). IEEE, 240â€“250.
[30]Murali Krishna Ramanathan, Ananth Grama, and Suresh Jagannathan. 2007.
Static specification inference using predicate mining. ACM SIGPLAN Notices 42,
6 (2007), 123â€“134.
[31]Anastasia Reinhardt, Tianyi Zhang, Mihir Mathur, and Miryung Kim. 2018. Aug-
menting stack overflow with API usage patterns mined from GitHub. In Pro-
ceedingsofthe201826thACMJointMeetingonEuropeanSoftwareEngineeringConference and Symposium on the Foundations of Software Engineering. 880â€“883.
[32]XiaoxueRen,JiamouSun,ZhenchangXing,XinXia,andJianlingSun.[n.d.]. De-
mystify Official API Usage Directives with Crowdsourced API Misuse Scenarios,
Erroneous Code Examples and Patches. ([n.d.]).
[33]Xiaoxue Ren, Zhenchang Xing, Xin Xia, Guoqiang Li, and Jianling Sun. 2019.
Discovering, Explaining and Summarizing Controversial Discussions in Commu-
nityQ&ASites.In 201934thIEEE/ACMInternationalConferenceonAutomated
Software Engineering (ASE). IEEE, 151â€“162.
[34]Martin P Robillard, Eric Bodden, David Kawrykow, Mira Mezini, and Tristan
Ratchford.2012.AutomatedAPIpropertyinferencetechniques. IEEETransactions
on Software Engineering 39, 5 (2012), 613â€“637.
[35]RavindraSingh andNaurangSinghMangat. 2013. Elementsof surveysampling.
Vol. 15. Springer Science & Business Media.
[36]Jiamou Sun, Zhenchang Xing, Rui Chu, Heilai Bai, Jinshui Wang, and Xin Peng.
[n.d.]. Know-How in Programming Tasks: From Textual Tutorials to Task-OrientedKnowledgeGraph.In 2019IEEEInternationalConferenceonSoftware
Maintenance and Evolution (ICSME). IEEE, 257â€“268.
[37]Joshua Sushine,James DHerbsleb,and JonathanAldrich. 2015. Searchingthestate space: A qualitative study of API protocol usability. In 2015 IEEE 23rd
International Conference on Program Comprehension. IEEE, 82â€“93.
[38]Amann Sven, Hoan Anh Nguyen, Sarah Nadi, Tien N Nguyen, and Mira Mezini.
2019. Investigating next steps in static API-misuse detection. In 2019 IEEE/ACM
16th International Conference on Mining Software Repositories (MSR). IEEE, 265â€“
275.
[39]Lin Tan, Ding Yuan, Gopal Krishna, and Yuanyuan Zhou. 2007. /* iComment:
Bugs or bad comments?*. In Proceedings of twenty-first ACM SIGOPS symposium
on Operating systems principles. 145â€“158.
[40] Sylvain Thenault et al. 2006. PylintÃ‚Â¡Ã‚ÂªCode Analysis for Python.[41]
SureshThummalapenta andTaoXie. 2009. Alattin:Mining alternativepatterns
fordetectingneglectedconditions.In 2009IEEE/ACMInternationalConferenceon
Automated Software Engineering. IEEE, 283â€“294.
[42] Suresh Thummalapenta andTao Xie. 2009. Mining exception-handlingrules as
sequenceassociationrules.In 2009IEEE31stInternationalConferenceonSoftware
Engineering. IEEE, 496â€“506.
[43]Andrzej Wasylkowski and Andreas Zeller. 2011. Mining temporal specifications
from object usage. Automated Software Engineering 18, 3-4 (2011), 263â€“292.
[44]Andrzej Wasylkowski, Andreas Zeller, and Christian Lindig. 2007. Detectingobject usage anomalies. In Proceedings of the the 6th joint meeting of the Euro-
peansoftwareengineeringconferenceandtheACMSIGSOFTsymposiumonThe
foundations of software engineering. 35â€“44.
[45]Bowen Xu, Deheng Ye, Zhenchang Xing, Xin Xia, Guibin Chen, and Shanping Li.2016. Predictingsemanticallylinkableknowledgeindeveloperonlineforumsvia
convolutional neural network. In Proceedings of the 31st IEEE/ACM International
Conference on Automated Software Engineering. ACM, 51â€“62.
[46]XinYe,HuiShen,XiaoMa,RazvanBunescu,andChangLiu.2016. Fromword
embeddings to document similarities for improved information retrieval in soft-
ware engineering. In Proceedings of the 38th international conference on software
engineering. ACM, 404â€“415.
[47]XuejiaoZhao,ZhenchangXing,MuhammadAshadKabir,NaoyaSawada,JingLi,
and Shangwei Lin. 2017. HDSKG: Harvesting domain specific knowledge graph
from content of webpages. (2017), 56â€“67.
[48]HaoZhong,LuZhang,TaoXie,andHongMei.2009. Inferringresourcespecifica-
tions from natural language API documentation. In 2009 IEEE/ACM International
Conference on Automated Software Engineering. IEEE, 307â€“318.
[49]YuZhou,RuihangGu,TaolueChen,ZhiqiuHuang,SebastianoPanichella,and
HaraldGall.2017. AnalyzingAPIsdocumentationandcodetodetectdirective
defects. In 2017 IEEE/ACM 39th International Conference on Software Engineering
(ICSE). IEEE, 27â€“37.
472