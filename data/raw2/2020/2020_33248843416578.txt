Retrieve and Refine: Exemplar-based Neural
Comment Generation
Bolin Wei
Key Lab of High Confidence Software
Technology, MoE (Peking University)
Beijing, China
bolin.wbl@gmail.comYongmin Li
Key Lab of High Confidence Software
Technology, MoE (Peking University)
Beijing, China
liyongmin@pku.edu.cnGe Liâˆ—
Key Lab of High Confidence Software
Technology, MoE (Peking University)
Beijing, China
lige@pku.edu.cn
Xin Xia
Faculty of Information Technology
Monash University, Australia
xin.xia@monash.eduZhi Jinâˆ—
Key Lab of High Confidence Software
Technology, MoE (Peking University)
Beijing, China
zhijin@pku.edu.cn
ABSTRACT
Codecommentgenerationwhichaimstoautomaticallygenerate
naturallanguagedescriptionsforsourcecode,isacrucialtaskin
the field of automatic software development. Traditional comment
generationmethodsusemanually-craftedtemplatesorinformation
retrieval (IR) techniques to generate summaries for source code.
In recent years, neural network-based methods which leveraged
acclaimed encoder-decoder deep learning framework to learn com-
mentgenerationpatternsfromalarge-scaleparallelcodecorpus,
haveachievedimpressiveresults.However,theseemergingmeth-
ods only take code-related information as input. Software reuse is
commonintheprocessofsoftwaredevelopment,meaningthatcom-
ments of similar code snippets are helpful for comment generation.
Inspired by the IR-based and template-based approaches, in this
paper,weproposeaneuralcommentgenerationapproachwhere
weusetheexistingcommentsofsimilarcodesnippetsasexemplars
to guide comment generation. Specifically, given a piece of code,
we first use an IR technique to retrieve a similar code snippet and
treat its comment as an exemplar. Then we design a novel seq2seq
neural network that takes the given code, its AST, its similar code,
and its exemplar as input, and leverages the information from the
exemplartoassistinthetargetcommentgenerationbasedonthese-manticsimilaritybetweenthesourcecodeandthesimilarcode.Weevaluateourapproachonalarge-scaleJavacorpus,whichcontains
about 2M samples, and experimental results demonstrate that our
model outperforms the state-of-the-art methods by a substantial
margin.
âˆ—Corresponding authors.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ASE â€™20, September 21â€“25, 2020, Virtual Event, Australia
Â© 2020 Association for Computing Machinery.
ACM ISBN 978-1-4503-6768-4/20/09...$15.00
https://doi.org/10.1145/3324884.3416578CCS CONCEPTS
â€¢Computing methodologies â†’Artificial intelligence ;â€¢
Softwareanditsengineering â†’Softwaremaintenancetools .
KEYWORDS
Comment generation, Deep learning
ACM Reference Format:
BolinWei,YongminLi,GeLi,XinXia,andZhiJin.2020.RetrieveandRefine:
Exemplar-basedNeuralCommentGeneration.In 35thIEEE/ACMInterna-
tionalConferenceonAutomatedSoftwareEngineering(ASEâ€™20),September
21â€“25,2020,VirtualEvent,Australia. ACM,NewYork,NY,USA,12pages.
https://doi.org/10.1145/3324884.3416578
1 INTRODUCTION
Code comments provide a clear natural language description for
a piece of the source code, which can help software developers
understandprogramsquicklyandcorrectly[ 37].Previousstudies
showed that during software maintenance, program comprehen-
siontakesmorethanhalfofthetime[ 6,9,22,44].Althoughproper
commentsareveryhelpful forsoftwaremaintenance,theyareab-
sentorout-datedinmanysoftwareprojects[ 7].Ontheotherhand,
manually writing comments is very time-consuming and labor-intensive, and the comments should be updated as the softwareis upgraded. Therefore, automatic comment generation becomes
greatly crucial for software development and maintenance.
Creating manually-crafted templates is a common way to gener-
ate comments automatically [ 31,37]. These methods defined differ-
ent templates for differenttypes of programs to generate readable
text descriptions. Sridhara et al. [ 37] used Software Word Usage
Modelandheuristicstoselectimportantcodestatements,defined
templatesforeachcodestatement,andgeneratedcorresponding
comments.Morenoetal.[ 31]predefinedheuristicrulestoextract
information from source code, and defined templates for different
typesofinformationtohelpgeneratecodesummaries.Manually-
craftedtemplatesareintroducedintheseapproachestoextractkeyinformationinthesourcecodeintocomments,helpingimprovethe
readability and comprehensibility of comments. However, defining
atemplateisatime-consumingtaskandrequiresextensivedomain
knowledge. Also, different projects might use different kinds of
templates.
3492020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE)
Asanalternative,informationretrieval(IR)techniquesarewidely
used in automatic comment generation [ 8,11,42,43]. Some re-
searchersusedIRtechniquestoselecttermsfromsourcecodeto
generateterm-basedcomments[ 8,11].Haiducetal.[ 11]applied
theVectorSpaceModelandLatentSemanticIndexingtoretrieve
the appropriate terms, while Eddy et al. [ 8] introduced a hierarchi-
cal topic model for comment generation. Based on the idea that
softwarereuseiscommon[ 20,21],otherresearchersleveragedcode
clonedetectiontechniquestodetectsimilarcodesnippetsandused
their corresponding comments for comment generation. Note that
similarcodesnippetscanberetrievedfromexistingopen-source
software repositories in GitHub or software Q&A sites such as
StackOverflow[ 42,43].However,codesnippetsmaycontainsome
informationthatisinconsistentwiththecontentincommentsof
their similar code snippets.
In recent years, more and more researchers have focused on
applyingneuralmachinetranslationmodelsforcommentgenera-tion and viewedthe processof generatingcomments fromsource
code as a language translation task (e.g., translating English to
German)[ 14,16,25].Theseresearchworkshaveadoptedthemain-
stream encoder-decoder framework of neural machine translation,
withsourcecodeasinputandcommentsasoutput,andachieved
state-of-the-artperformanceonthecommentgeneration.Themain
difference between these works is the source code encoding meth-
ods.Iyeretal.[ 16]directlymodeledthesourcecodeasasequenceof
tokens, while Huet al. [ 14] used the traversal sequence of Abstract
Syntax Tree (AST) tokens as the model input. LeClair et al. [ 25]
integrated previous work and used two different ways to representsource code. By virtue of the naturalness of the source code [
2,12],
theseneuralmodelscanminepatternsforgeneratingcomments
fromlargecorpora,buttheyonlyreliedonsourcecodeinformation,
such as tokens or structures of source code, to create comments.
Notethattheseaforementionedcommentgenerationmethods
have their own advantages. The comments generated based on
themanually-craftedtemplatemethodsareusuallyfluentandin-
formative;theIR-basedmethodscantakeadvantageoftokensin
comments of similar code snippets; the neural-based methods can
learnthesemanticconnectionbetweennaturalandprogramming
languages. Although the neural-based methods have achieved the
bestperformance[ 14,16,25],ittendstogeneratehigh-frequency
wordsincommentsor"losecontrol"sometimes.Forexample,ac-
cording to LeClair et al.â€™s study [25], 21% comments in the test set
contain tokens with the frequency of less than 100. Conversely,
only7%commentspredictedbytheirproposedapproachcontain
tokens with the frequency of less than 100. Besides, more than two
thousandgeneratedcommentsevendonothaveanormalend-of-
sequence </s> token. Specifically, the comments generated by the
neural model suffer a loss in readability and informativeness. This
phenomenon also appears in the use of neural models in machine
translation[ 23].Therefore,wearguethatitisnotenoughforthe
neural model to generate comments only based on the source code.
Inspired by the template-based methods and IR-based methods,
weassumethatcommentsofsimilarcodesnippetscanberetrieved
as templates to guide the process of neural comment generation.
These templates, onthe one hand, provide reference examplesfor
generating comments, and on the other hand, may contain low-
frequencywordsrelatedtothesourcecode,enhancingtheneuralmodelâ€™sabilitytooutputlow-frequencywords.Consideringthedif-ferencesbetweencommentsofsimilarcodesnippetsandmanually-craftedtemplates,wecallexistingsimilarcommentsas
exemplars .
Due to the strong pattern recognition capabilities of neural net-
works [2], we argue that encoder-decoder neural networks can be
combined with traditional template-based and IR-based methods.
Therefore, in this paper, we propose a novel comment genera-
tionframework,namelyRe2Com,whichconsistsoftwomodules:
aRetrieve module and a Refine module. In the Retrieve module,
givenaninputcodesnippet,weexploitIRtechniquestoretrieve
themostsimilarcodesnippetfromalargeparallelcorpusofcode
snippetsandtheircorrespondingcomments,andtreatthecomment
of the similar code snippet as an exemplar. In the Refine module,
we apply a novel seq2seq neural network to learn patterns for gen-
eratingcomments.Morespecifically,theencodertakesthegiven
codesnippet,thesimilarcodesnippet,andtheexemplarasinput,
andthedecodergeneratesthe tokensequenceofacomment.Itis
worth noting that the similar code snippet retrieved may not be se-
mantically similar to the given code snippet. With the similar code
snippetasinput,wecanperformasemanticcomparisonthrough
a neural network and decide whether to use the exemplar basedon the degree of similarity. Furthermore, we adopt the attention
mechanism [ 3] to focus on the important parts of the input. In the
testing phase, given a new piece of code snippet without a com-
ment, our approach retrieves a similar code snippet and comment
pair from the corpus, utilizes the trained neural model to generate
anannotation,andselectstokenswiththehighestprobabilityin
thevocabularyastheoutput.Inthisway,weleveragetheadvan-
tages of template-based and IR-based methods, and model them
intotheneuralnetworktoimprovetheperformanceofcomment
generation.
To train and evaluate our approach, we conduct experiments on
a real-world Java dataset. The dataset comes from the Sourcerer
repository1andhasbeenprocessedbyLeClairetal.[ 25],including
removing duplicates, dividing into training, validation, and test
sets by projects. We employthe evaluation metrics BLEU score in
machinetranslationtoevaluatethegeneratedcommentsandalso
performahumanevaluation.Experimentalresultsshowthatour
methodperformssubstantiallybetterthantheIR-basedmethodand
outperforms the state-of-the-art approaches. Besides, experimental
results also show that our proposed modules are orthogonal to
other techniques, i.e., applying the Retrieve and Refine modules to
other neural models can improve the performance of the models.
The contributions of our work are shown as follows:
â€¢We propose an exemplar-based neural comment generation
method, which combines traditional template-based and IR-
basedmethodswithneuralmethods.Weusecommentsof
similar code snippets as exemplars to assist in generating
comments.
â€¢Weconductextensiveexperimentstoevaluateourapproach
onalarge-scaledatasetofJavamethods.Theexperimental
results show that our Retrieve and Refine modules substan-
tially improve the performance of the neural model and
achieve the state-of-the-art results.
1https://www.ics.uci.edu/ lopes/datasets/
350! (
(
!! ( #!        "
$( #!     "
 *  !( #!    %!"# +,-

) ! + 
 )%!  +,,'
 "  ! / ) ! +,)  +,'
	 $  /# !! )$  +,'
+$  &/!,-
$  )%+,'
.
 ) ! +,)   +"  ! ,'
.
! " # +,-

) ! + 
 )%!  +,,'
    ! / ) ! +,)  +,'
	   /#  !! )$  +,'
#+  &/!,-
  )%+,'
  /#  !! )$  +,'
.
 ) ! +,)   +   ! ,'
.
(a) An example of the retrieved similar code snippet and the
input code that are semantically similar.
&
&
	& !# 
"&  
(& !#  #  ) +,#*-
#-
')*%
')!#
 )#**%
.) "  *-
'	)*%
.
.
 ) #+,$$*!
" -
#-
" +"	,') #$$*%
.) "  *-
" ! /!" )')**%
! ') *%
!! %
.
.
(b) An example of retrieved similar code snippet and input
code that are not semantically similar.
Figure1:Examplesofexemplar-basedcommentgeneration.
Sametokensingroundtruths,exemplarsandpredictionsofast-attendgruaremarkedinred.Sametokens(splitoncamelcase)intheinputcodeandthesimilarcodearealsomarkedin red.
PaperOrganization
.Therestofourpaperisorganizedasfollows.
Section 2 describes motivating examples. Section 3 presents our
proposed method. Section 4 and Section 5 describe the experiment
setup and results. Section 6 and Section 7 discuss some results and
describetherelatedwork,respectively.Finally,Section8concludes
the paper and points out future directions.
2 MOTIVATING EXAMPLES
To explainwhywe usethecomment ofthe retrievedsimilarcode
snippet as an exemplar to guide the neural model to generate acomment, we selecttwo representativeexamples fromthe dataset
usedintheevaluation,asshowninFigure1.Theinputcodeandthe
similar code are Java methods,and we also display the comments
predicted by the ast-attendgru model [25] for the input code. For
theinputcode,weleveragetheopen-sourcesearchengineLucene2
to retrieve the most similar code snippet from the training corpus.
The retrieval technique is based on the lexical level similarity of
the source code, which will be explained in detail in Section 3.1.
Comment generation methods based on neural networks are
difficulttogeneratelow-frequencytokens,whereascommentsof
similar code snippets selected based on IR-based methods may
containlow-frequencytokens.Forexample,inFigure1a,wecan
observethatthespecificphrase"sleepingonthisconditionvariable"
appearsinboththegroundtruthandtheexemplar,meaningthat
the input code and the similar code are semantically similar. In
addition, "sleeping" is a low-frequency token in the corpus, which
appearsonly71times.Thisisoneofthereasonsthattheprediction
of the ast-attendgru ignores the token. Although the prediction
of the neural network is very close to the ground truth, it still
lacks some key information in the source code. Therefore, with the
exemplarasinputtotheneuralmodel,thelow-frequencytokens
willaffectthecommentgenerationprocess,andtheneuralnetwork
will generate more informative comments.
However,itisnotenoughtoonlytakeanexemplarasadditional
input,andthesimilarcoderetrievedbysearchenginesisnotnec-
essarily semantically similar, which is partly due to the fact that
there isno realsourcecode reusein thecorpus, and partlydue to
thelimitationsoftheretrievaltechnique.Forinstance,inFigure1b,
eventhoughtheinputcodeandthesimilarcodehavesomesame
tokens(Tokensinthesourcecodearesplitoncamelcase.),theyare
not similar in semantics and behavior. In this case, the exemplar is
unsuitableforguidingthecommentgenerationprocessofneural
networks.Incontrast,ast-attendgrucangenerateacommentthatisclosetothegroundtruthwithouttheexemplar.Forthisreason,wearguethatitisnecessarytousethesimilarcodeandtheinputcode
asthe inputoftheneural networkatthe sametime,andcalculate
thesemanticsimilaritybetweenthesimilarcodeandtheinputcode
throughtheneuralmodel,anddeterminethedegreeofusingthe
exemplaraccordingtothesemanticsimilarity.Wedesignanovel
network structure to implement this idea, the details of which will
be described in Section 3.2.
In view of the many discussions on the effectiveness of deep
learning methods in the field of software engineering in recentyears [
17,27], we think that our study may be a good starting
point,combiningtraditionalmethodsonspecifictaskswithdeep
learning methods. Previous methods applied neural networks tosolve tasks in software engineering. Although specific input for
specific tasks was proposed, such as AST and control flow graphs,
previous researchers did not analyze the existing problems of deep
learningmethods,e.g.,overfitting(whichtendstogeneratehigh-
frequencyterms).Therefore,webelievethattraditionalmethods
can be modeled into neural networks to improve performance.
2https://lucene.apache.org/
351
	 




 


 


 



			
		
		 
	 	 
	 

	
  

Figure 2: An overview of our approach for exemplar-based comment generation.
3 PROPOSED APPROACH
In this work, we propose the exemplar-based comment generation
method (Re2Com), modeling traditional IR-based and template-
basedmethodsintotheneuralmethod.DifferentfromtheIR-based
methods,weemployaneuralnetworktomodifythecommentofthesimilarcodetoconformtothesemanticsoftheinputcode.Differentfromthetraditionaltemplate-basedmethod,whichrequiresmanual
definitionofthetemplate,wetreatthecommentoftheretrievedcode as an exemplar. Re
2Com consists of two parts: a Retrieve
module and a Refine module. The Retrieve module uses the IRtechnique to explore the similar code and extract its comment
fromaparallelcorpus,whiletheRefinemoduleisanovelneural
network based on a seq2seq network with an attention mechanism
to generate a comment.
The overall framework is illustrated in Figure 2. The data pre-
processingstepreferstotheextraction,cleaning,andpartitionof
thedataset,andthetrainingandteststepreferstotheRe2Com.We
useamassivetrainingsetasaretrievalcorpuswhiletrainingthe
Refine module. The details of the Retrieve module are describedin Section 3.1. To take advantage of the structure information of
inputcode,wenotonlyusethetokensequencerepresentationof
the code but also use the AST of the code as an input of the Refine
module. The details of this part will be described in Section 3.2.
3.1 Retrieve Module
Consideringthatsoftwarereuseiswidespreadinsoftwaredevel-opment, a similar code snippet usually has a similar comment.
Furthermore, as we analyzed in Section 2, there are some potential
problemswiththepreviousneural-basedmethods.Therefore,we
arguethatitisbeneficialfortheneuralnetworktouseanexemplar
asareferencewhengeneratingnewcomments.Inpractice,devel-
opershavesimilarexperiencesduringsoftwaredevelopment.For
example,whenaddingacommenttoapieceofsourcecode,they
willrefertothecommentofasimilarcodesnippet.Inourframe-
work, the goal of the Retrieve module is to retrieve similar code
from a retrieval corpus given the input code and treat its comment
as an exemplar.
Toidentifywhichpieceofcodeintheretrievalcorpusismost
similar to the input code, we need to define and calculate the simi-
larity between two pieces of code snippets. In this work, we chose
the similarity of the lexical level of the source code to measure thecode similarity, which was inspired by [ 20,27,35]. Specifically, we
adoptBM25asthesimilarityevaluationmetric,whichisabag-of-
words retrieval function to estimate the relevance of documents to
agivensearchqueryinIR.Givenaqueryandadocument,basedon
TF-IDF,the BM25scoringfunctioncalculatesthetermfrequency
in the document of each keyword in the query and multiplies it by
the inverse document frequency of this term. The more relevant
two documents are, the higher the value of BM25score is.
We leverage the open-source search engine Luceneto build our
Retrieve module. Since the size of the training set is quite large
(over1.9M),weuseitastheretrievalcorpus,i.e.,giventheinput
codesnippet,wesearchforthemostsimilarcodefromthetraining
set. The Retrieve module contains two parts, creating the indexand searching. We first tokenize the source code and comments,
usingWhitespaceAnalyzer inLucene.Thenweprocesseachcode
and comment pair into a document, add it to the index library, and
store it on disk. In the search phase, for each query code, we get
similar code sequences arranged in descending order of similarity,
choose the first-ranked similar code (when training, we choose the
second-ranked), and use its comment as an exemplar. We keep the
default settings of BM25in Lucene.
3.2 Refine Module
Oncewehaveanexemplar,astraightforwardwayistotreatitas
acomment forthe inputcode. However, dueto thenon-existence
of software reuse or the limitation of retrieval technology, thereisa certaindifferencebetweenthe semanticof theexemplar and
the semantic of the input code. Especially, the similar code usually
contains information that is inconsistent with the input code, such
asdifferentAPIcallsandoperations.Therefore,weusetheexemplarasasoft-templateandrefineitaccordingtothesemanticdifference
betweenthesourcecodeandthesimilarcode.Basedonawidely
usedseq2seqneuralnetwork[ 34,38,39],wedesignanovelnetwork
structure that can learn the semantic similarity between the input
code and the similar code, refine the exemplar, and generate a
comment.
TheRefinemodulecontainsthreecomponents,fourencoders,
a decoder, and an attention mechanism module between encoders
and the decoder. Figure 3 illustrates the detailed Refine module.
3.2.1 Encoders. The four encoders take a token sequence of the
input code x, an AST traversal sequence of the input code t,a
352tokensequenceofthesimilarcode sandtheexemplar rasinput,
respectively. Amongthem,the inputcode xandits ASTtraversal
sequence tconstitute the Input Code Representation in Figure 2.
We use the Structure-based Traversal (SBT) method [ 14] to obtain
the traversal sequence of AST to utilize the structural information
oftheinputcode.Thereisnodifferenceinthestructureofthefour
encoders. Take the input code xas an example.
Theencoderoftheinputcodefirstmapstheone-hotembedding
of a token ğ‘¤ğ‘–into a word embedding ğ‘¥ğ‘–:
ğ‘¥ğ‘–=ğ‘Š/latticetop
ğ‘’ğ‘¤ğ‘– (1)
whereğ‘Šğ‘’isatrainableembeddingmatrix.Thentoleveragethecon-
textualinformation,weuseabidirectionallongshort-termmemory
(LSTM)[13]toprocessthesequenceofthewordembeddings,which
isexplicitlydesignedtoavoidthelong-termdependencyproblem.
Ateachtimestep ğ‘¡,thehiddenstateoftheforwardLSTMâˆ’ â†’â„ğ‘¡can
be represented by:
âˆ’ â†’â„ğ‘¡=LSTM(ğ‘¥ğ‘¡,âˆ’ â†’â„ğ‘¡âˆ’1) (2)
The hidden states of the backward LSTM can be obtained with
anotherLSTM. Weconcatenatehidden statesfromtwo directions
as the representation of the ğ‘¡-th token â„ğ‘¡in the input code, i.e.,
â„ğ‘¡=[âˆ’ â†’â„ğ‘¡;â† âˆ’â„ğ‘¡]. For the traversal sequence of AST, the similar code,
and the exemplar, we get their respective hidden states as â„ğ‘¡,â„ğ‘ ,
andâ„ğ‘Ÿinthesameway.Wedenotethehiddenstatesoftokensof
theinputcodeas â„ğ‘¥.Notethatinourexperiments,weusedfour
separate LSTMs to encode different input sequences.
Then we explore the difference between the input code and
the similar code using a nonlinear sigmoidfunction to obtain a
semantic similarity score ğ‘ ğ‘–ğ‘š:
ğ‘ ğ‘–ğ‘š=ğœ(ğ‘Šğ‘ ğ‘–ğ‘š[â„ğ‘¥
âˆ’1;â„ğ‘ 
âˆ’1]) (3)
whereğ‘Šğ‘ ğ‘–ğ‘šare trainable weights, ğœstands for the sigmoidfunc-
tion,andtheindex"-1"standsforthelasthiddenstate.Accordingto
previousworkinthenaturallanguageprocessingcommunity[ 3],
thisstructureperformswellintherelevancemeasurement.Alarger
valueofthescore ğ‘ ğ‘–ğ‘š(rangesfrom0to1)indicatesthattheseman-
tics of the input code and the retrieved code is more similar.
3.2.2 Attention. Attention is a component that allows the decoder
to focus and place more "attention" on the relevant parts of the
input sequence as needed. It is useful to introduce this mechanism
intothecommentgenerationmodel.Forexample,whendevelopers
writecomments,theyusethetoken"get"becausetheynoticethe
token"return"inthesourcecode.Therefore,wearguethatdifferent
parts of the comment are related to different parts of the source
code. Similarly, after the introduction of the exemplar, the decoder
can also focus on some parts of the exemplar when generating
comments. The attention mechanism in the Refine module is built
by the classic method of Bahdanau et al. [3].
Takethe attentionbetweenthetarget commentandtheinput
code as an example. Specifically, for each target token ğ‘¦ğ‘–,w eu s e
thehiddenstateofitsprevioustoken â„/prime
ğ‘–âˆ’1tocalculatetheattention
		



	 
 


Figure 3: The structure of the Refine module. The calcula-
tion details of the "sim" block and the "combination" blockare Equation 3 and Equation 8, respectively. The dashedlines represent information used to initialize the decoderand to calculate the context vector.
weights as,
/tildewideğ›¼
ğ‘–ğ‘—=ğ‘(â„/prime
ğ‘–âˆ’1,â„ğ‘¥
ğ‘—) (4)
ğ›¼ğ‘–ğ‘—=exp{/tildewideğ›¼ğ‘–ğ‘—}/summationtext.1
ğ‘˜exp{/tildewideğ›¼ğ‘–ğ‘˜}(5)
whereğ‘is an alignment model which scores how well the input
around position ğ‘—and the output at position ğ‘–match. We use a
Multi-Layer Perception (MLP) [ 32] unit as the alignment model.
Then the context vector ğ‘ğ‘¥
ğ‘–is computed as a weighted sum of all
hidden states of the input code:
ğ‘ğ‘¥
ğ‘–=/summationdisplay.1
ğ‘—ğ›¼ğ‘–ğ‘—â„ğ‘¥
ğ‘—(6)
Theattentionweightsandcontextvectorfortheexemplar ğ‘ğ‘Ÿ
ğ‘–and
the AST traversal sequence ğ‘ğ‘¡
ğ‘–can be computed in the same way.
3.2.3 Decoder. Thepurposeofthedecoderistogeneratethetarget
comment ğ‘¦.Whengeneratingthe ğ‘¡-thtokeninthecomment,the
decoder first uses an LSTM to get the ğ‘¡-th hidden state â„/prime
ğ‘¡:
â„/prime
ğ‘¡=LSTM(â„/prime
ğ‘¡âˆ’1,ğ‘¦ğ‘¡âˆ’1) (7)
Theinitialstateofthedecoderisacombinationoftheinputcode
representation and the last hidden state of the exemplar:
â„/prime
0=â„ğ‘âˆ—(1âˆ’ğ‘ ğ‘–ğ‘š)+â„ğ‘Ÿ
âˆ’1âˆ—ğ‘ ğ‘–ğ‘š (8)
whereâ„ğ‘is the feature vector of the input code, which is obtained
byconcatenatingthelasthiddenstateof xandthelasthiddenstate
oftand performing an affine transformation:
â„ğ‘=ğ‘Šğ‘[â„ğ‘¥
âˆ’1;â„ğ‘¡
âˆ’1]+ğ‘ğ‘ (9)
whereğ‘Šğ‘andğ‘ğ‘aretrainableparameters.Thepurposeofthecom-
bination in Eqn. 8 is that if the input code is different semantically
from the similar code, that is, the value of the similarity score is
low, then the decoder should pay more attention to the content of
353the input code. We can obtain the context vector ğ‘ğ‘¡in the same
way:
ğ‘/prime
ğ‘¡=(ğ‘Šğ‘[ğ‘ğ‘¥
ğ‘¡;ğ‘ğ‘¡
ğ‘¡]+ğ‘ğ‘)âˆ—(1âˆ’ğ‘ ğ‘–ğ‘š)+ğ‘ğ‘Ÿ
ğ‘¡âˆ—ğ‘ ğ‘–ğ‘š (10)
Then the probability of a token ğ‘¦ğ‘¡is conditioned on the context
vectorğ‘ğ‘¡and its previous generated tokens ğ‘¦1,...,ğ‘¦ğ‘¡âˆ’1, i.e.,
ğ‘(ğ‘¦ğ‘¡|ğ‘¦ğ‘¡âˆ’1,...,ğ‘¦1,ğ‘¥,ğ‘¡,ğ‘ ,ğ‘Ÿ)=ğ‘”(ğ‘¦ğ‘¡âˆ’1,â„/prime
ğ‘¡,ğ‘ğ‘¡) (11)
whereğ‘”is a MLP layer with the softmaxactivation function.
ThetrainingobjectiveoftheRefinemoduleistominimizethe
cross-entropy:
ğ»(ğ‘¦)=âˆ’1
ğ‘ğ‘/summationdisplay.1
ğ‘–/summationdisplay.1
ğ‘—logğ‘(ğ‘¦ğ‘–
ğ‘—|ğ‘¦ğ‘–
<ğ‘—,ğ‘¥ğ‘–,ğ‘¡ğ‘–,ğ‘ ğ‘–,ğ‘Ÿğ‘–)(12)
whereğ‘isthetotalnumberoftrainingsamples,and ğ‘¦ğ‘–
ğ‘—meansthe ğ‘—-
thtokeninthe ğ‘–-thsample.Throughgradientdescentoptimization
methods, the parameters of the Refine module can be estimated.
Duringinference,weuseabeamsearch[ 38]togeneratecomments.
Specifically, the decoder generates the comment token by token
fromleft-to-rightwhilekeeping ğµ-bestcandidatesateachtimestep
whereğµis the beam size.
4 EXPERIMENT SETUP
Dataset. We evaluate our approach on the dataset provided by
LeClairetal.[ 25].TheoriginaldatasetcomesfromLopesetal.[ 29],
containing 5.1 million Java methods from the Sourcerer repository.
Because the original dataset contains a large number of samples
thatarenotsuitableforevaluatingneuralmodels,suchasrepeated
and auto-generated code, LeClair et al. preprocessed the data.
More specifically, they first extracted Java methods and com-
ments from the code repository. Assuming the first sentence of the
Javadoc summarizes the methodâ€™s behavior [ 24], the authors ex-
tracted the first sentence or line from the Javadoc as a comment of
the method and filtered out non-English samples. Considering that
the auto-generated and duplicate code (due to name changes, code
cloning,etc.)willhaveanegativeimpactonneuralmodelevalua-
tion, the authors removed these samples using heuristic rules [ 36]
andaddedunique,auto-generatedcodetothetrainingsettoensure
that no testing was performed on these samples. After splitting
camel case and underscore tokens, removing non-alpha charac-
ters,andsettingtolowercase,theauthorsdividedthedatasetby
project into training, validation and test set, meaning that all meth-
ods in one project are grouped into one category. They argue that
the preprocessing of the dataset is necessary for evaluating theperformanceofneuralmodels.Withoutthesepreprocessing,theevaluation results of neural models will be inflated. For example,
in the ICPCâ€™18 paper [ 14], the reported BLEU score of DeepCom is
about 38, while the result on this dataset is only about 19.
Aftergettingtheprocesseddataset,theauthorsusedthe srcml[5]
tool to parse the source code into AST, and traversed the ASTthrough the SBT [
14] method to convert the AST into a token
sequence.Tosimulatemorecomplicatedscenarios,suchasmissing
keywordsinthesourcecode(duetopoorly-writtencodeorsome
scenarioswithonlybytecode),theyreplacedalltokensinthesource
code with a <OTHER> token and got a token sequence called SBT-
AOforSBTASTonly.Insuchcases,onlythestructureofASTisTable 1: Statistics of datasets
Dataset Train Valid Test
Count 1,954,807 104,273 90,908
Avg. tokens in comment 7.594 7.710 7.654
Avg. tokens in code 29.67 29.68 30.17Avg. tokens in SBT-AO 218.3 217.3 222.8
(a) Code length distribution (b) Comment length distribution
Figure 4: Length distribution of test data
preserved.Thentheauthorscreatedtwodatasetstoevaluatethe
performance of neural models.
â€¢Thestandarddataset containsthreeelementsforeachsam-
ple,acodesequenceoftheJavamethod,anSBT-AOsequence
of Java method, and a comment.
â€¢Thechallengedataset containstwoelementsforeachsam-
ple, an SBT-AO sequence of Java method, and a comment.
Thechallengedatasetisusedtoevaluatetheperformanceofneural
modelswhenonlytheASTstructureisavailable.Inourexperimen-
talsetup,theretrievalcorpusisconstructedusingsourcecodetoken
sequence and comment pairs from the training set. For training
and evaluation, we select the second-ranked (since the first-ranked
similar code is itself) and top-ranked retrieved code as the similar
code,respectively.Thestatisticalresultsofthedatasetareshown
in Table 1. Figure 4 shows the length distribution of source code
and comment on the test data.
TrainingDetails. OurmodelisimplementedbasedontheTensor-
flow framework. We set token embeddings and LSTM states to 100
dimensionsand256dimensionsrespectively.Theout-of-vocabulary
tokensarereplacedby UNK.TomaximizetheutilizationofGPU
memory,wesetthebatchsizeto256.Wechoosethewidely-used
stochastic gradient descent to optimize all parameters with the ini-
tiallearningrateof0.2.Thelearningrateisdecayedwithafactorof
0.95 every epoch. To mitigate overfitting, we use dropout with 0.2.
Andtopreventexplodinggradient,weclipthegradientsnormby
5. According to the statistics of the dataset in Figure 4, we limit the
maximum length of the encoder LSTM to 100 and the maximum
length of the decoder to 13. Training runs for about 20 epochs, and
thebestparametersareselectedaccordingtotheperformanceof
the validation set. During the test, the beam size ğµis set to 5. Each
experiment is run three times, and the average results are reported.
WeconductourexperimentsonaLinuxserverwiththeNVIDIA
GTX TITAN Xp GPU with 12 GB memory.
EvaluationMetrics. Followingthepreviouscommentgeneration
work[14,16,25],weevaluatedifferentapproachesusingthemetric
BLEU [33]. BLEU measures the quality of generated comments and
354canrepresentthehumanâ€™sjudgment,whichcalculatesthesimilarity
betweenthegeneratedcommentsandreferences.Itisdefinedas
thegeometricmeanof ğ‘›-grammatchingprecisionscoresmultiplied
by a brevity penalty to prevent very short generated sentences:
ğµğ¿ğ¸ğ‘ˆ =ğµğ‘ƒÂ·exp(ğ‘/summationdisplay.1
ğ‘›=1ğ‘¤ğ‘›logğ‘ğ‘›) (13)
whereğ‘ğ‘›is theğ‘›-gram matching precision scores, ğ‘is set to 4
in our paper, and ğµğ‘ƒis a brevity penalty to prevent very short
generated sentences.BLEU score rangesfrom 0 to 100;the higher
thescore,themore thecandidate correlatestothe reference.This
evaluation metric is also widely used in various tasks of automatic
softwareengineering.Liuetal.[ 27]introducedBLEUtoevaluatethe
quality of the generated commit message. Gu et al. [10] employed
it to evaluate the accuracy of the generated API sequence. Jiang et
al.[19]exploitedittoevaluatethegeneratedsummariesforcommit
messages.TheirexperimentsshowthatitisreasonabletouseBLEU
to evaluate the quality of comments. In our experiments, we report
a composite BLEU score in addition to BLEU 1through BLEU 4.
5 RESULTS
To evaluate our approach, in this section, we will answer the fol-
lowing research questions:
â€¢RQ1: How does the Re2Com perform compared to the state-
of-the-art neural models?
â€¢RQ2: How effective is the exemplar to all neural models?
â€¢RQ3: How does the Re2Com perform compared to the IR
methods?
In the challenge dataset, all models have no source code tokens
as input, which is an experimental scenario to evaluate the ability
ofthemodeltouselimitedinformation.Incontrast,thestandard
datasetisclosetothereal-worldscenariowherealltheinformation
of the source code is available. Hence we evaluate our approach
andallbaselinesonthestandarddatasetinthissectionanddiscuss
the experimental results on the challenge dataset in the Section 6.
5.1 RQ1: Re2Com vs. Neural Baselines
5.1.1 Baseline. To answer this research question, we compare our
approach to four state-of-the-art neural methods.
â€¢CODE-NN [16]isthefirstdeeplearningmodelandthefirst
end-to-end encoder-decoder framework for comment gener-
ationtask.Itencodesthesourcecodesequenceintotoken
embeddings, then uses an LSTM as a decoder to generate
comments,andemploystheattentionmechanismtointro-
duce information on the encoder side. Note that CODE-NN
only uses token embedding as the encoder, not the LSTM.
â€¢attendgru [25] is a standard attentional seq2seq model,
where the encoder and the decoder are both gated recur-
rent unit (GRU). GRU is similar to LSTM and is a variant
of RNN. For a fair comparison, we replace GRU with LSTM
in the model. Hence, the difference between this model and
CODE-NN is whether the encoder uses an RNN.
â€¢ast-attendgru [25]isalsoanattentionalseq2seqmodel.Dif-
ferentfromattendgru,itintroducesthestructureinformation
of the source code and uses a new encoder to process theTable2:Theperformanceofourmodelcomparedwithneu-
ral baselines.
Methods Params B B1 B2 B3 B4
CODE-NN 36.3M 12.54 32.23 14.71 8.558 6.090
DeepCom 37.9M 14.21 31.88 16.02 10.10 7.491
attendgru 37.7M 19.42 39.00 22.02 14.87 11.27
ast-attendgru 39.7M 19.67 39.32 22.19 14.98 11.42
Re2Com 28.4M24.42 41.69 25.78 19.70 16.79
traversalsequenceofAST.Itconcatenatestheinformation
fromthetwoencodersasinputtothedecoderandgenerates
comments. In our experiments, we used LSTMs as encoders
for a fair comparison.
â€¢DeepCom [14]isaseq2seqmodelthatusesLSTMsasthe
encoder and the decoder, and also utilizes the attention
mechanism.Itisthefirstcommentgenerationmodelusing
ASTâ€™straversalsequenceasinputandproposedthetraversal
method SBT.
We set the embedding size and LSTM states of all baselines to
256 dimensions, which can ensure that the number of Re2Comâ€™s
parameters is less than the number of baselinesâ€™ parameters. As in
theICSEâ€™19paper[ 25],wedidnotcompareourmodelwithother
baselinesinthefieldofnaturallanguageprocessing,becausethe
tricksintroducedbythosemodelswouldmakeitdifficulttocompare
exactly which part of the model played a key role. Compared with
theabovefourbaselines,itcannotonlyexplaintheeffectiveness
of our model but also show that the components of our model arehelpful.
5.1.2 Results. We calculate the gap between the comments gener-
ated by different methods and the ground truth. The experimental
results are shown in Table 2. The BLEU scores of the best baseline
ast-attendgruarecomparabletothosereportedinthestudy[ 25],
althoughwemadesomemodificationstotheirencoders.Thisre-
sult shows that the performance difference of an LSTM and a GRU
on this task is very limited. Although ast-attendgru introduces
structuralinformationofthesourcecodecomparedtoattendgru,
it does not substantially improve the results. The phenomenon
also appears in the paper [ 25], explaining that after excluding cus-
tom identifiers in the AST, the structural information of the source
codehaslimitedhelpingeneratingcomments,andtheinformation
containedinthetokensequenceofsourcecodeissufficient.Theperformance of DeepCom is much lower than the results in [
14],
indicatingthattheirdatapreprocessinghaspotentialproblems.The
auto-generated and duplicate code has agreat negative impact on
the experimental results. The similar conclusion was reached in
theAllamanisâ€™spaper[ 1].ThedifferencebetweenDeepComand
attendgruisonlyintheinputinformation,whiletheformerisabout5pointsworsethanthelatter.OnereasonisthattheASTâ€™straversal
sequenceprocessedbyDeepComisabout7timeslongerthanthe
tokensequenceprocessedbyattendgru,whichmightcontainmoreuselessandredundantinformation.KoehnandKnowles[
23]found
that encoder-decoder frameworks have low generation quality on
verylongsentences.FromTable2,wealsonoticethatCODE-NN
performsworstcomparedwithothermethods sinceitdoesnotuse
anRNNtoprocessthetokensequence,whichmakesitunableto
graspthesemanticinformationofthesourcecodecontext.Fromthe
355Table 3: Effectiveness of exemplar on all neural methods.
Methods Params BB 1B 2B 3B 4
CODE-NN +E . 63.0M 14.72 33.14 16.39 10.65 8.120
DeepCom + E. 64.4M 18.90 33.51 19.21 15.50 13.32
attendgru + E. 64.2M 22.60 39.01 23.48 18.17 15.68
ast-attendgru + E. 66.2M 22.81 39.55 23.77 18.29 15.74
Re2Com 28.4M24.4241.69 25.78 19.70 16.79
results,wecanalsoobservethatBLEU 1toBLEU 4areindescending
order.BLEU 1isveryhighcomparedtoBLEU 4onallmodels,reveal-
ing that the matching accuracy of the 4-grams between comments
generated by neural networks and gold references is slightly lower.
From the table, we can see that Re2Com substantially outper-
forms all neural methods on the standard dataset, and improves
ast-attendgru(thebestbaseline)by24.15%.Inparticular,theBLEU 4
improvement achieves by Re2Com is 47.02%, which is not only due
to the similar code retrieved and the exemplar providing abundant
information for comment generation but also due to the ability of
the Refine module to integrate the code and the exemplar. Since
thewordvectorsofRe2Comare100-dimensional,thenumberof
parametersofRe2Comisthesmallestamongallmethods.However,
Re2ComcanstillachievethehighestBLEUscore.Inaddition,we
evaluateRe2Comwithcompletelyrandomexemplarsonthetest
set. The model achieves 14.61 BLEU score, which shows that the
improved performance of Re2Com is due to the exemplar.
For a code snippet in the test set, the Retrieve module averagely
takes48.91mstoretrievethemostsimilarcode,andtheRefinemod-
uletakesanaverageof99.27mstogeneratecomments.However,
the best baseline ast-attendgru takes 199.1ms to generate a com-
mentforagivensample.Therefore,ourmodelnotonlyimproves
the results, but also improves efficiency.
5.2 RQ2: Effectiveness of Exemplar
We further explore whether exemplar is effective for all neural
models,i.e.,whentheneuralmodelbecomessimple,orwhenthe
model does not have the structure information of the source code,
will the exemplar still be effective? To reach a conclusion, we first
add the exemplar as input on all baselines. Then we apply the
similarity score (Eqn. 3) and the combination block (Eqn. 8) in our
Refine module to each baseline for calculating the initial state and
contextvectorofthedecoder.Finally,wetraineachbaseline,and
the evaluation results are shown in Table 3.
Itcanbeseenfromtheexperimentalresultsthatexemplarcan
bringstableimprov ementtoallneuralmodels.Forallofthebaseline
models, their BLEU scores are increased after adding the exemplar.
Observing the improvement of BLEU 1to BLEU 4, we can find that
theexemplarhasthebiggestimprovementonBLEU 4onallmodels.
This indicates that retrieved exemplars improve the accuracy of
continuoustokensinpredictedcommentsintheneuralnetwork,
whichalsoeffectivelyimprovesthequalityofgeneratedcomments.
In addition, the number of trainable parameters of Re2Com is less
than all the methods. Exemplarâ€™s improvement of all the modelsalso shows that the exemplar is orthogonal to the tricks used by
otherdeepmodels,andcanbringindependentimprovements.Takeast-attendgruandDeepComasexamples.WecanseefromthetablethatthereisstillacertaingapbetweenthetwomodelsafteraddingTable 4: The performance of our model compared with IR
baselines.
Methods BB 1B 2B 3B 4
Retrieve Module 18.04 32.06 17.83 14.39 12.87
LSI 17.19 31.38 17.05 13.48 12.07
VSM 17.76 31.91 17.52 14.02 12.70
NNGen 18.89 33.48 18.86 14.99 13.44
Re2Com 24.42 41.69 25.78 19.70 16.79
exemplars, which is caused by the token sequence of the sourcecode as an input of ast-attendgru. Overall, experimental results
showthattheexemplariseffectiveforallneuralmodelsgenerating
comments,andstill,ourproposedmodelRe2Comshowsthebest
performance.
5.3 RQ3: Re2Com vs. IR Baselines
5.3.1 Baseline. To answer this research question, we compare our
approach with four IR-based baselines.
â€¢RetrieveModule isacomponentofRe2Com,whosedetails
aredescribedinSection3.1.Weusetheretrievedexemplar
as a comment directly.
â€¢Latent Semantic Indexing (LSI) is an IR technique to ana-
lyze the semantic relationship between terms in documents,
which is used by Haiduc et al. [ 11] to extract important
termsinsourcecode.Foragivencodesnippet,weuseLSI
to retrieve the similar code from the training set and use its
comment as a target. The similarity is the cosine distance of
the 500-dimensional LSI vector of the code.
â€¢Vector Space Model (VSM)representsthesourcecodeas
a feature vector and is applied to some IR-based comment
generationmethods[ 8,11].Werepresentthesourcecodeas
avectorusingTermFrequency-InverseDocumentFrequency
(TF-IDF)andusecosinesimilaritytoretrievethecomment
of the most similar code from the training set.
â€¢NNGen[27]isanapproachforproducingcommitmessages
based on nearest neighbors. It first encodes code changes
intoaformof "bagofwords",thenuses thecosinedistance
to select the closest ğ‘˜code changes, and finally chooses the
message of the code change with the highest BLEU score as
thefinalresult.Wereplacecodechangeswithcodesnippets,
leverage this method to generate comments, and set ğ‘˜as 5.
5.3.2 Results. Weevaluate thequality ofcommentsgenerated by
different IR-based methods, and the results are shown in Table 4.
AlthoughourRetrievemoduleachieveshighBLEUscores,itdoes
notperformaswellasRe2Com,whichprovestheimportanceofthe
Refine module. Besides, the performance of the Retrieve module is
not substantially different from that of common IR-based methods,
illustrating that our Retrieve module is reasonable and effective.
LSI andVSM leverage differentmethods (LSI vectorsand TF-IDF)
torepresentsourcecodeasvectors,buttheirperformanceissimilar.
NNGen chooses the comments with the highest BLEU score andthusperformsbetterthanotherIR-basedmethods.Notethatthe
IR-basedbaselinesperformverywellonBLEU 4,evensurpassing
the neural network-based baselines in Table 2, i.e., the IR-basedmethods can achieve a high matching precision score of 4-gram,
356Table 5: The results (standard deviation in parentheses) of
human evaluation
Methods Informativeness Naturalness Similarity
NNGen 1.555 (1.31) 3.560 (0.70) 1.205 (1.37)
ast-attendgru 2.575 (0.93) 3.425 (0.86) 2.215 (1.11)
Re2Com 2.930(1.06) 3.820(0.64)2.640(1.29)
indicatingthatthesecommentsareinformativeandhaveagood
readability.ThephenomenonalsoexplainswhyRe2Comcanim-
prove more on BLEU 4. Surprisingly, IR methods outperform some
neural-based methods on BLEU scores, such as CODE-NN and
DeepCom,showingthatinmorestringentandmorerealisticsce-
narios(noduplicateandauto-generatedcode),neuralnetworksare
not necessarily better than IR methods. Combining the advantages
of neural networks and traditional methods, our Re2Com achieves
the best performance.
5.4 Human Evaluation
Although BLEU scores can evaluate the gap between the gener-
ated comments and references, it cannot truly reflect the seman-
ticsimilarity.Therefore,weperformahumanevaluationtomea-
surethequalityofcommentsgeneratedbyNNGen,Re2Com,and
ast-attendgru on the standard dataset. We follow the previous
work [15,16,27,28] to design a human evaluation, and measure
three aspects, including the similarity of generated comments and
references, naturalness (grammaticalityandfluencyofthegener-
atedcomments)and informativeness (theamountofcontentcarried
over from the input code to the generated comments, ignoring flu-
encyofthetext).Specifically,weinvite12volunteerswith3-5years
ofJavadevelopmentexperienceandexcellentEnglishabilityfor30
minutes each to evaluate the generated comments in the form of a
questionnaire.Similarto[ 15],werandomlyselect300prediction
results and their references from the test set (100 from NNGen,
100 from Re2Com and 100 from ast-attendgru). The 300 samples
are then evenly divided into six groups, with each questionnaire
containingonegroup.Werandomlylistthecommentpairsandthecorrespondinginputcodeonthequestionnaireandremovetheirla-
bels to ensure that participants cannot distinguish which comment
isgeneratedbyNNGen,Re2Com,orast-attendgru.Eachparticipant
isaskedtorateeachsamplefromtheabovethreeaspects.Allthreescoresareintegers,rangingfrom0to4.Eachgroupisevaluatedby
two volunteers, and the score of a pair of comments is the average
of two evaluations. Participants are allowed to search the Internet
for related information and unfamiliar concepts.
The evaluation results are shown in Table 5. Re2Com surpasses
NNGenandast-attendgruinthreeaspects.Inparticular,theNNGencangeneratemorefluentcommentsthantheast-attendgru,because
its comments are all retrieved from the training set. The difference
instandarddeviationofthethreemethodsisverysmall,indicating
that their scores are about the same degree of concentration. Inter-
estingly,thescoresofinfomativenessofallthreemodelsarehigherthanthoseofsimilarity,indicatingthatthegeneratedcommentsare
more relevant to the input code than to the references. Since some
references contain information about the context of Java methods,
such as member variables in the class, it is not possible to generateTable 6: The number of correctly generated low-frequency
tokens
Methods â‰¤10â‰¤20â‰¤50â‰¤100
Reference 12,145 15,253 21,622 28,425
ast-attendgru 262 624 1,575 2,801
Re2Com 422 1,093 2,808 4,886
Figure 5: BLEU scores for different code and commentlengths.
the information for all three models with only Java methods as
input.
6 DISCUSSION
In this section, we further compare Re2Com and the best base-
lineast-attendgru.Thenwediscusssituationswhereourmethod
performs well and threats to validity.
6.1 Performance on Low-frequency Tokens
94.8% of tokens in the comment vocabulary of the standard dataset
have a frequency of less than 100. As we described in Section 1
and 2, previous methods perform poorly on low-frequency tokens.
ToevaluatetheresultsoftheRe2Comonlow-frequencytokens,we
collectallcorrectlygeneratedtokensthatappearinbothpredictionandreferenceonthetestset,calculatethefrequencyofthesetokensonthetrainingset,andcountthetokenswithfrequencieslessthan
10, 20, 50, and 100. We conduct the same analysis on ast-attendgru
and count the number of low-frequency tokens in the reference on
the testset. Table6 shows thestatistical resultson low-frequency
tokens.TheresultsshowthatRe2Comcanpredictmorecorrectlow-
frequency tokens than ast-attendgru, which indicates that Re2Com
cantackletheproblemofpredictinglow-frequencytokens.Theabil-itytopredictmoretokensthatappearlessfrequentlyalsoindicates
that our Re2Com has better generalization capabilities.
6.2 Performance for Different Lengths
Here, we further analyze the prediction accuracy of the Re2Com
and the ast-attendgru on different code and comment lengths. We
calculatetheBLEUscoreforeachsampleonthetestsetandthen
average the scores by length. Figure 5 shows the evaluation results.
From the figures, we can observe that the Re2Com outperforms
the ast-attendgru with different code and comment lengths. When
the code and comments are very long, the performance of bothmodels decreases to some extent, but Re
2Com is still better than
ast-attendgru.TheimprovementofRe2Comisstableoncodeand
comments of different lengths.
357Table7:Theperformanceofourmodelandast-attendgruon
the challenge dataset
Methods BB 1B 2B 3B 4
ast-attendgru 9.334 25.79 11.05 6.027 4.418
Re2Com 10.50 27.41 12.26 7.014 5.182
Table 8: Examples of generated comments
Case ID Example
1public void resume() {
Enumeration e = actuators.elements();
while (e.hasMoreElements()) {
((Actuator) (e.nextElement())).resume();
}
e = sensors.elements();
while (e.hasMoreElements()) {
((Sensor) (e.nextElement())).resume();
}
}
Human-written: resume all actuators and sensors in this mechanism
NNGen: suspend all actuators and sensors on a mechanism
ast-attendgru: resumes all actuators
Re2Com: resume all actuators and sensors in this mechanism
2public double function( double x,double y) {
if(y >= 0) {
return Math.pow(x, y);
}
else {
return 1/Math.pow(x, -y);
}
}
Human-written: calculates x to the power of y
NNGen: get the norm of the vector squared
ast-attendgru: returns the function value of thexyc oo r dinate
Re2Com: method for x to the power of y
3public boolean equals(String rawSQL) {
return TextUtil.removeLin eBreaks(rawSQL).equals(
_singleLineText);
}
Human-written: check if the current element matches a given sql string
NNGen: get the value of sql text
ast-attendgru: returns true if the given sql string is equal to the given
Re2Com: check if the current element matches a given sql string
6.3 Performance on the Challenge Dataset
Here,weevaluatetheRe2Comandtheast-attendgruonthechal-
lengedataset.Becausesource codetokeninformationisnotavail-
ableinthedataset,weusetheRetrievemoduletoretrievethemost
similar SBT-AO and treat its comment as an exemplar. The results
are shown in Table 7. From the table, we can see that the BLEU
scoreofourmodelisimprovedby12.49%comparedtoast-attendgru.
However, compared to the results on the standard dataset, we find
thatourRe2Comonthechallengedatasetdoesnotperformaswell
as on the standard dataset, which is due to the limitation of the
Retrieve module. The Retrieve module calculates the token-levelsimilarity, and we remove all tokens from in the code to obtainthe SBT-AO (details are in Section 4), resulting in poor retrieval
resultsforsimilarSBT-AO.Therefore,Re2Comdoesnotperform
wellonthechallengedataset.Butintheabsenceofcodeasinput,
it is very difficult to achieve such an improvement, and when com-
paring Re2Com with ast-attendgru, it still proves that the Re2Com
is helpful for generating comments.6.4 Qualitative Analysis and Visualization
We perform a qualitative analysis on the generated comments. We
presentthreeJavamethodswithitscommentsfromthetestsetandthecommentsgeneratedbydifferentmethods,asshowninTable8.
We can see from the table that, thanks to the useful information
provided by exemplars, the comments generated by the Re2Com
and the human-written comments are very close in semantics, and
the Re2Com performs better than other methods.
6.5 Threats to Validity
One threat to validity is that we only evaluated our framework
onaJavadataset.AlthoughJavamaynotberepresentativeofall
programming languages, the dataset is large and safe enough to
showthatourmodeliseffective.Besides,theRe2Comcanbeeasily
applied to comment generation for other programming languages.
Thesecondthreattovalidityisourhumanevaluation.Wecannot
guaranteethateachscoreassignedtoeverycommentpairisfair.Tomitigatethisthreat,weevaluateeachcommentpairbytwohuman
evaluators,andweusetheaveragescoreofthetwoevaluatorsas
the final score.
AnotherthreattovalidityisthattheRetrievemoduleusesthe
lexical-level similarity of the source code, which may cause thecode retrieved by the module to be semantically dissimilar. We
recommendincreasingthescaleoftheretrievalcorpustoavoidthis
threat.However,intheRe2Com,weintroducetheRefinemodule
tocalculatethesemanticsimilarityanddecidewhethertousethe
exemplar based on the similarity score.
7 RELATED WORK
CodeSummarization. Automaticcommentgenerationapproaches
vary from manually-crafted templates [ 30,31,37], IR [8,11,42,43]
to neural models [14, 16, 25].
Comment generation based on manually-craft templates was
one of the common methods for generating comments. Sridhara
etal.[37]developedtheSoftwareWordUsageModel(SWUM)to
capturetheoccurrencesoftermsinsourcecodeandtheirlinguistic
andstructuralrelationshipsandthendefineddifferenttemplates
fordifferentsemanticsegmentsinsourcecodetogeneratereadablenaturallanguage.Morenoetal.[
31]definedheuristicrulestoselect
relevant information in the source code, and then divided the com-
ments into four parts, and defined different text templates for each
parttogeneratenaturallanguagedescriptions.McBurneyetal.[ 30]
also used the SWUM model to extract the keywords in the Java
method, employed the PageRank algorithm to select the importantmethods in the given methodâ€™s context, and used a template-based
text generationsystemto generatecomments. Theseframeworks
have achieved good results on Java classes and methods.
IR techniques have been widely used in comment generation
task.Haiducetal.[ 11]usedtwoIRtechniques,VectorSpaceModel
and Latent Semantic Indexing, to retrieve relevant terms from asoftware corpus, and then organized these terms into comments.Eddy et al. [
8] used hierarchical PAM, a probabilistic model that
selectedrelevanttermsfromthecorpusandincludedthemtothe
comments. Unlike the first two research works, Wong et al. [ 43]
proposed that code snippets and their descriptions on the Q&A
sitescanbeusedtogeneratecommentsforapieceofcode.They
358used a token-based code clone detection tool SIMto detect similar
code snippets and used their comments as target comments. Wong
et al. [42] further thought that the resources of the Q&A sites were
limitedandproposedtousetoken-basedcodeclonedetectiontools
to retrieve similar code snippets from GitHub and leverage the
information obtained from their comments to generate comments.
Recently many neural networks have been proposed for com-
ment generation. With large-scale corpora for training, neural-
basedapproachesquicklybecamestate-of-the-artmodelsonthis
task. Iyer et al. [ 16] first introduced the seq2seq model from neural
machine translation into comment generation, whose encoder is
the token embedding and decoder is an LSTM. Their model out-
performs traditional methods on C# and SQL summaries. Inspired
by the difference between natural language and programming lan-
guage, Hu et al. [ 14] proposed a neural model named DeepCom to
capturethestructuralinformationofsourcecode.Theyproposed
a structure-based traversal method, using one LSTM to processthe ASTâ€™s traversal sequence, and the other LSTM to generate
commentsforJavamethods.LeClairetal.[ 25]proposedaneural
method to predict the comment by combining the sequence infor-
mationandstructureinformationofthesourcecodewithtwoGRU
encoders. In addition, they reconstructed the benchmark datasetfor this task, removed duplicate and auto-generated code in the
dataset,anddividedthedatasetintotraining,validation,andtest
by project.
Our proposed Re2Com combines the advantages of the three
methods, retrieves asimilarcode snippetfrom thetraining set,and
uses its comment as the exemplar to guide the neural model for
comment generation, improving performance over baselines.
CodeCloneDetection. Codeclonedetectionthatmeasurescode
similarityisacommonprogramcomprehensiontaskinsoftware
engineering. Existing researches mainly measure the similarity be-
tweencoderepresentationvaryingfromlexical[ 20,35]tosyntacti-
cal [18] representations. Specifically, CCFinder [ 20] and Sourcer-
erCC [35] are code clone detection tools based on bag of tokens,
while DECKARD [ 18] detects code clones based on AST. Recently,
deep learning models are proposed to learn the implicit similarity
betweencodesnippets[ 4,26,40,41,45,46].Thesemethodsusea
variety of neural networks: RtNN [ 41], DNN [26,46], ASTNN [ 45]
and AST-based RNN [ 4,40] to represent source code as feature
vectors, and use feature vectors to calculate the similarity between
source code snippets. Although we can use deep learning-based
codeclonedetectiontoolstoretrievesimilarcodesnippets,these
tools need to be trained on the labeled dataset. In our Retrieve
module, we prefer to use a lightweight search engine and then
exploit the Refine module to correct the retrieved exemplar. There-
fore, we argue that the similarity at the lexical level is sufficient to
find similar code snippets to assist in comment generation, and the
experimental results also prove our idea.
8 CONCLUSION
In this paper, we propose an exemplar-based comment generation
framework namedRe2Com thattakes advantage ofthree types of
methodsbasedonneuralnetworks,templates,andIR.Ourframe-
workcontainstwomodules,aRetrievemoduleforretrievingthemost similar code snippet, and a Refine module that uses the com-
mentofthesimilarcodesnippetasanexemplartogenerateatarget
comment. In order to verify the effectiveness of our framework,
we evaluated the Re2Com on a large-scale Java method dataset.
Theexperimental resultsshow thatthe Re2Comhas asubstantial
improvementovertheneural-basedbaselinesandtheIR-basedbase-
lines.Furtheranalysisoftheexperimentalresultsshowsthatthe
Re2Com performs well not only on low-frequency tokens but also
oncodeandcommentsofdifferentlengths.Infuturework,weplan
toexploretheimpact ofmore complexcoderetrievaltechniques
on the Re2Com.
ACKNOWLEDGMENTS
This research is supported by the National Key R&D Program
under Grant No. 2018YFB1003904, the National Natural Science
Foundation of China under Grant Nos. 61832009, 61620106007 and
61751210,andtheAustralianResearchCouncilâ€™sDiscoveryEarly
CareerResearcherAward(DECRA)fundingscheme(DE200100021).
REFERENCES
[1]Miltiadis Allamanis. 2019. The adverse effects of code duplication in machine
learningmodelsofcode.In Proceedingsofthe2019ACMSIGPLANInternational
SymposiumonNewIdeas,NewParadigms,andReflectionsonProgrammingand
Software, Onward! 2019, Athens, Greece, October 23-24, 2019. 143â€“153. https:
//doi.org/10.1145/3359591.3359735
[2]Miltiadis Allamanis, Earl T. Barr, Premkumar T. Devanbu, and Charles A. Sutton.
2018. ASurveyofMachineLearningforBigCodeandNaturalness. ACMComput.
Surv.51, 4 (2018), 81:1â€“81:37. https://doi.org/10.1145/3212695
[3]Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015. Neural Machine
Translation by Jointly Learning to Align and Translate. In 3rd International
Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9,
2015, Conference Track Proceedings. http://arxiv.org/abs/1409.0473
[4]Lutz BÃ¼ch and Artur Andrzejak. 2019. Learning-Based Recursive Aggregation of
Abstract Syntax Trees for Code Clone Detection. In 26th IEEE International Con-
ferenceonSoftwareAnalysis,EvolutionandReengineering,SANER2019,Hangzhou,
China, February 24-27, 2019, Xinyu Wang, David Lo, and Emad Shihab (Eds.).
IEEE, 95â€“104. https://doi.org/10.1109/SANER.2019.8668039
[5]MichaelL.Collard,MichaelJohnDecker,andJonathanI.Maletic.2011. Light-
weight Transformation and Fact Extraction with the srcML Toolkit. In 11th
IEEE Working Conference on Source Code Analysis and Manipulation, SCAM 2011,
Williamsburg, VA, USA, September 25-26, 2011. 173â€“184. https://doi.org/10.1109/
SCAM.2011.19
[6]ThomasA.Corbi.1989. ProgramUnderstanding:Challengeforthe1990s. IBM
Systems Journal 28, 2 (1989), 294â€“306. https://doi.org/10.1147/sj.282.0294
[7]Sergio Cozzetti B. de Souza, Nicolas Anquetil, and KÃ¡thia MarÃ§al de Oliveira.
2005. Astudyofthedocumentationessentialtosoftwaremaintenance.In Pro-
ceedingsofthe23rdAnnualInternationalConferenceonDesignofCommunication:
documenting & Designing for Pervasive Information, SIGDOC 2005, Coventry, UK,
September 21-23, 2005. 68â€“75. https://doi.org/10.1145/1085313.1085331
[8]Brian P. Eddy, Jeffrey A. Robinson, Nicholas A. Kraft, and Jeffrey C. Carver. 2013.
Evaluatingsourcecodesummarizationtechniques:Replicationandexpansion.
InIEEE 21st International Conference on Program Comprehension, ICPC 2013, San
Francisco,CA,USA,20-21May,2013.13â€“22. https://doi.org/10.1109/ICPC.2013.
6613829
[9]R. K. Fjeldstad and W. T. Hamlen. 1982. Application program maintenance study
- reports to our respondents.
[10]XiaodongGu,HongyuZhang,DongmeiZhang,andSunghunKim.2016. Deep
APIlearning.In Proceedingsofthe24thACMSIGSOFTInternationalSymposium
on Foundations of Software Engineering, FSE 2016, Seattle, WA, USA, November
13-18, 2016. 631â€“642. https://doi.org/10.1145/2950290.2950334
[11]SoniaHaiduc,JairoAponte,LauraMoreno,andAndrianMarcus.2010. Onthe
UseofAutomatedTextSummarizationTechniquesforSummarizingSourceCode.
In17th Working Conference on Reverse Engineering, WCRE 2010, 13-16 October
2010, Beverly, MA, USA. 35â€“44. https://doi.org/10.1109/WCRE.2010.13
[12]AbramHindle,EarlT.Barr,MarkGabel,ZhendongSu,andPremkumarT.De-
vanbu.2016. Onthenaturalnessofsoftware. Commun.ACM 59,5(2016),122â€“131.
https://doi.org/10.1145/2902362
[13]Sepp Hochreiter and JÃ¼rgen Schmidhuber. 1997. Long Short-Term Memory.
Neural Computation 9, 8 (1997), 1735â€“1780. https://doi.org/10.1162/neco.1997.9.
8.1735
359[14]Xing Hu, Ge Li, Xin Xia, David Lo, and Zhi Jin. 2018. Deep code comment
generation. In Proceedings of the 26th Conference on Program Comprehension,
ICPC 2018, Gothenburg, Sweden, May 27-28, 2018. 200â€“210. https://doi.org/10.
1145/3196321.3196334
[15]Xing Hu, Ge Li, Xin Xia, David Lo, and Zhi Jin. 2019. Deep code comment
generationwithhybridlexicalandsyntacticalinformation. EmpiricalSoftware
Engineering (2019), 1â€“39.
[16]Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, and Luke Zettlemoyer. 2016.
Summarizing Source Code using a Neural Attention Model. In Proceedings of the
54thAnnualMeetingoftheAssociationforComputationalLinguistics,ACL2016,
August 7-12, 2016, Berlin, Germany, Volume 1: Long Papers. https://www.aclweb.
org/anthology/P16-1195/
[17]Lin Jiang, Haiwen Liu, and He Jiang. 2019. Machine Learning Based Recommen-
dation of Method Names: How Far are We. 2019 34th IEEE/ACM International
Conference on Automated Software Engineering (ASE) (2019), 602â€“614.
[18]LingxiaoJiang,GhassanMisherghi,ZhendongSu,andStÃ©phaneGlondu.2007.
DECKARD: Scalable and Accurate Tree-Based Detection of Code Clones. In 29th
InternationalConferenceonSoftwareEngineering(ICSE2007),Minneapolis,MN,
USA, May 20-26, 2007. 96â€“105. https://doi.org/10.1109/ICSE.2007.30
[19]Siyuan Jiang, Ameer Armaly, and Collin McMillan. 2017. Automatically generat-
ing commit messages from diffs using neural machine translation. In Proceedings
ofthe32ndIEEE/ACMInternationalConferenceonAutomatedSoftwareEngineering,
ASE 2017, Urbana, IL, USA, October 30 - November 03, 2017, Grigore Rosu, Massi-
milianoDiPenta,andTienN.Nguyen(Eds.).IEEEComputerSociety,135â€“146.
https://doi.org/10.1109/ASE.2017.8115626
[20]Toshihiro Kamiya, Shinji Kusumoto, and Katsuro Inoue. 2002. CCFinder: A
MultilinguisticToken-BasedCodeCloneDetectionSystemforLargeScaleSource
Code.IEEETrans.SoftwareEng. 28,7(2002),654â€“670. https://doi.org/10.1109/
TSE.2002.1019480
[21]Miryung Kim, Vibha Sazawal, David Notkin, and Gail C. Murphy. 2005. Anempiricalstudy ofcodeclone genealogies.In Proceedingsofthe 10thEuropean
Software Engineering Conference held jointly with 13th ACM SIGSOFT Interna-
tional Symposium on Foundations of Software Engineering, 2005, Lisbon, Portugal,
September 5-9, 2005. 187â€“196. https://doi.org/10.1145/1081706.1081737
[22]A. J. Ko, Brad A. Myers, Michael J. Coblenz, and Htet Htet Aung. 2006. An
Exploratory Study ofHow Developers Seek, Relate, and CollectRelevant Infor-
mation during Software Maintenance Tasks. IEEE Trans. Software Eng. 32, 12
(2006), 971â€“987. https://doi.org/10.1109/TSE.2006.116
[23]PhilippKoehnandRebeccaKnowles.2017. SixChallengesforNeuralMachine
Translation.In ProceedingsoftheFirstWorkshoponNeuralMachineTranslation,
NMT@ACL 2017, Vancouver, Canada, August 4, 2017. 28â€“39. https://www.aclweb.
org/anthology/W17-3204/
[24]DouglasKramer.1999. API documentationfromsource codecomments: acase
study of Javadoc. In Proceedings of the 17th annual international conference on
Documentation,SIGDOC1999,NewOrleans,Louisiana,USA,September12-14,1999.
147â€“153. https://doi.org/10.1145/318372.318577
[25]Alexander LeClair, Siyuan Jiang, and Collin McMillan. 2019. A neural model for
generatingnaturallanguagesummariesofprogramsubroutines.In Proceedings
of the 41st International Conference on Software Engineering, ICSE 2019, Montreal,
QC, Canada, May 25-31, 2019. 795â€“806. https://doi.org/10.1109/ICSE.2019.00087
[26]Liuqing Li, He Feng, Wenjie Zhuang, Na Meng, and Barbara G. Ryder. 2017.CCLearner: A Deep Learning-Based Clone Detection Approach. In 2017 IEEE
International Conference on Software Maintenance and Evolution, ICSME 2017,
Shanghai, China, September 17-22, 2017. 249â€“260. https://doi.org/10.1109/ICSME.
2017.46
[27]ZhongxinLiu,XinXia,AhmedE.Hassan,DavidLo,ZhenchangXing,andXinyu
Wang. 2018. Neural-machine-translation-based commit message generation:
howfararewe?.In Proceedingsofthe33rdACM/IEEEInternationalConference
on Automated Software Engineering, ASE 2018, Montpellier, France, September 3-7,
2018. 373â€“384. https://doi.org/10.1145/3238147.3238190
[28]Zhongxin Liu, Xin Xia, Christoph Treude, David Lo, and Shanping Li. 2019. Au-
tomatic Generation of Pull Request Descriptions. In 34th IEEE/ACM International
Conference on Automated Software Engineering, ASE 2019, San Diego, CA, USA,
November 11-15, 2019. 176â€“188. https://doi.org/10.1109/ASE.2019.00026
[29]C. Lopes, S. Bajracharya, J. Ossher, and P. Baldi. 2010. UCI Source Code Data
Sets. https://www.ics.uci.edu/~lopes/datasets/
[30]Paul W. McBurney and Collin McMillan. 2016. Automatic Source Code Sum-
marizationofContextforJavaMethods. IEEETrans.SoftwareEng. 42,2(2016),
103â€“119. https://doi.org/10.1109/TSE.2015.2465386
[31]LauraMoreno,JairoAponte,GiriprasadSridhara,AndrianMarcus,LoriL.Pollock,andK.Vijay-Shanker.2013. Automaticgenerationofnaturallanguagesummaries
for Java classes. In IEEE 21st International Conference on Program Comprehension,
ICPC 2013, San Francisco, CA, USA, 20-21 May, 2013. 23â€“32. https://doi.org/10.
1109/ICPC.2013.6613830
[32]Sankar K. Pal and Sushmita Mitra. 1992. Multilayer perceptron, fuzzy sets,and classification. IEEE Trans. Neural Networks 3, 5 (1992), 683â€“697. https:
//doi.org/10.1109/72.159058[33]Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. Bleu: a
Method forAutomatic Evaluation ofMachine Translation.In Proceedings ofthe
40thAnnualMeetingoftheAssociationforComputationalLinguistics,July6-12,
2002,Philadelphia,PA,USA.311â€“318. https://www.aclweb.org/anthology/P02-
1040/
[34]Alexander M. Rush, Sumit Chopra, and Jason Weston. 2015. A Neural Attention
ModelforAbstractiveSentenceSummarization.In Proceedingsofthe2015Confer-
enceonEmpiricalMethodsinNaturalLanguageProcessing,EMNLP2015,Lisbon,
Portugal, September 17-21, 2015. 379â€“389. https://doi.org/10.18653/v1/d15-1044
[35]HiteshSajnani,VaibhavSaini,JeffreySvajlenko,ChanchalK.Roy,andCristinaV.Lopes.2016. SourcererCC:scalingcodeclonedetectiontobig-code.In Proceedings
ofthe38thInternationalConferenceonSoftwareEngineering,ICSE2016,Austin,
TX, USA, May 14-22, 2016. 1157â€“1168. https://doi.org/10.1145/2884781.2884877
[36]Kento Shimonaka, Soichi Sumi, Yoshiki Higo, and Shinji Kusumoto. 2016. Identi-
fyingAuto-GeneratedCodebyUsingMachineLearningTechniques. 20167th
InternationalWorkshoponEmpiricalSoftwareEngineeringinPractice(IWESEP)
(2016), 18â€“23.
[37]Giriprasad Sridhara, Emily Hill, Divya Muppaneni, Lori L. Pollock, and K. Vijay-
Shanker.2010. TowardsautomaticallygeneratingsummarycommentsforJava
methods. In ASE. ACM, 43â€“52.
[38]Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. 2014. Sequence to SequenceLearningwithNeuralNetworks.In AdvancesinNeuralInformationProcessing
Systems 27: Annual Conference on Neural Information Processing Systems 2014,
December 8-132014, Montreal,Quebec, Canada.3104â€“3112. http://papers.nips.cc/
paper/5346-sequence-to-sequence-learning-with-neural-networks
[39]Oriol Vinyals and Quoc V. Le. 2015. A Neural Conversational Model. CoRR
abs/1506.05869 (2015). arXiv:1506.05869 http://arxiv.org/abs/1506.05869
[40]HuihuiWeiandMingLi.2017. SupervisedDeepFeaturesforSoftwareFunctional
Clone Detection by Exploiting Lexical and Syntactical Information in Source
Code.InProceedingsoftheTwenty-SixthInternationalJointConferenceonArtificial
Intelligence,IJCAI2017,Melbourne,Australia,August19-25,2017,CarlesSierra
(Ed.). ijcai.org, 3034â€“3040. https://doi.org/10.24963/ijcai.2017/423
[41]MartinWhite,MicheleTufano,ChristopherVendome,andDenysPoshyvanyk.
2016. Deeplearningcodefragmentsforcodeclonedetection.In Proceedingsof
the31stIEEE/ACMInternationalConferenceonAutomatedSoftwareEngineering,
ASE 2016, Singapore, September 3-7, 2016. 87â€“98. https://doi.org/10.1145/2970276.
2970326
[42]Edmund Wong, Taiyue Liu, and Lin Tan. 2015. CloCom: Mining existing source
codeforautomaticcommentgeneration.In 22ndIEEEInternationalConference
on Software Analysis, Evolution, and Reengineering, SANER 2015, Montreal, QC,
Canada, March 2-6, 2015. 380â€“389. https://doi.org/10.1109/SANER.2015.7081848
[43]Edmund Wong, Jinqiu Yang, and Lin Tan. 2013. AutoComment: Mining question
and answer sites for automatic comment generation. In 2013 28th IEEE/ACM
International Conference on Automated Software Engineering, ASE 2013, SiliconValley, CA, USA, November 11-15, 2013. 562â€“567. https://doi.org/10.1109/ASE.
2013.6693113
[44]Xin Xia, Lingfeng Bao, David Lo, Zhenchang Xing, Ahmed E. Hassan, andShanping Li. 2018. Measuring Program Comprehension: A Large-Scale FieldStudy with Professionals. IEEE Trans. Software Eng. 44, 10 (2018), 951â€“976.
https://doi.org/10.1109/TSE.2017.2734091
[45]JianZhang,XuWang,HongyuZhang,HailongSun,KaixuanWang,andXudong
Liu.2019. Anovelneuralsourcecoderepresentationbasedonabstractsyntax
tree. InProceedings ofthe 41stInternational Conferenceon SoftwareEngineering,
ICSE2019,Montreal,QC,Canada,May25-31,2019.783â€“794. https://doi.org/10.
1109/ICSE.2019.00086
[46] Gang Zhao and Jeff Huang. 2018. DeepSim: deep learning code functional simi-
larity.InProceedingsofthe2018ACMJointMeetingonEuropeanSoftwareEngi-
neeringConferenceandSymposiumontheFoundationsofSoftwareEngineering,
ESEC/SIGSOFTFSE2018,LakeBuenaVista,FL,USA,November04-09,2018.141â€“151.
https://doi.org/10.1145/3236024.3236068
360