DIFFBASE: A Differential Factbase for Effective Software
Evolution Management
Xiuheng Wu
Nanyang Technological University
Singapore
xiuheng001@e.ntu.edu.sgChenguang Zhu
The University of Texas at Austin
USA
cgzhu@utexas.eduYi Li
Nanyang Technological University
Singapore
yi_li@ntu.edu.sg
ABSTRACT
Numerous tools and techniques have been developed to extract
and analyze information from software development artifacts. Yet,
there is a lack of effective method to process, store, and exchange
information among different analyses. In this paper, we propose
differential factbase, a uniform exchangeable representation sup-
porting efficient querying and manipulation, based on the existing
concept of program facts. We consider program changes as first-
class objects, which establish links between intra-version facts of
single program snapshots and provide insights on how certain arti-
facts evolve over time via inter-version facts. We implement a series
of differential fact extractors supporting different programming
languages and platforms, and demonstrate with usage scenarios
the benefits of adopting differential facts in supporting software
evolution management.
CCS CONCEPTS
â€¢Software and its engineering â†’Software evolution ;Soft-
ware reverse engineering ;Maintaining software ;Software ver-
sion control .
KEYWORDS
Software evolution, reverse engineering, program facts, software
maintenance.
ACM Reference Format:
Xiuheng Wu, Chenguang Zhu, and Yi Li. 2021. DIFFBASE: A Differential
Factbase for Effective Software Evolution Management. In Proceedings of the
29th ACM Joint European Software Engineering Conference and Symposium
on the Foundations of Software Engineering (ESEC/FSE â€™21), August 23â€“28,
2021, Athens, Greece. ACM, New York, NY, USA, 13 pages. https://doi.org/
10.1145/3468264.3468605
1 INTRODUCTION
Real software is seldom created â€œall at onceâ€ and changes are in-
evitable [ 60]. Software developers often take advantage of the
knowledge and insights they gain over time to repair, enhance
and optimize earlier versions of the system through incremental up-
dates. The software artifacts accumulated during the development
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece
Â©2021 Association for Computing Machinery.
ACM ISBN 978-1-4503-8562-6/21/08. . . $15.00
https://doi.org/10.1145/3468264.3468605process have become crucial resources for understanding and ana-
lyzing software systems from an evolutionary point of view. These
include not only the source code written, but also the â€œby-productsâ€
produced such as code change histories, log messages, and test
run results. Many tools and techniques have been developed to
harvest useful information and use it to support different software
evolution management tasks. For example, trends and patterns ob-
served in the past changes can be used to estimate quality of new
changes [ 42], characterize architectural evolution [ 64,73], optimize
development process [ 11], identify high-level software functionali-
ties [ 47,48], and discover project-specific API usage patterns [ 54]
as well as developer expertise [16, 58].
These evolution management tasks require not only a clear un-
derstanding about each program version, but also insights about
the longitudinal evolution of program elements introduced by in-
cremental changes. Such understanding and insights are now being
produced by different analysis techniques, and can potentially be
shared and reused. But there still does not exist an effective way
to process, store and exchange information among different analy-
ses. Software Configuration Management systems (SCMs), such as
Git [26] and SVN [ 61], are widely used in the development practices,
where incremental changes are manually grouped by developers
to form commits (a.k.a. change sets ). Yet, the main goal of SCMs
is to support development activities, e.g., recording, examining,
and reverting changes, rather than analysis tasks, e.g., inferring
high-level program properties from changes and establishing re-
lationship among individual changes. The information embedded
in change sets goes beyond lines added and removed. When com-
bined with the understanding of language syntax and semantics,
much richer information can be obtained and analyzed about the
evolution of software.
Inspired by the program fact extraction techniques [ 1,2,7,33]
which generate facts about a single version of the software arti-
facts, we propose differential facts , a uniform representation of
software changes consolidating relevant information across multi-
ple versions of the same artifacts. Program facts can be any desired
information about the software artifactsâ€” structural relations such
as â€œmethod Ais contained in class Câ€ and semantic relations such as
â€œmethod Ais called by another method Bâ€, all could be considered
facts. Differential facts go beyond just a single program version,
and consider program changes, which highlight differences and
linkage between multiple versions, as first-class objects. Fig. 1 is an
illustration of the meta-model of differential facts, which demon-
strate only a subset of the possible fact types. These include the
intra-version facts capturing the containment, calling, and referenc-
ing relations between code entities at the same version; there are
also the inter-version facts which include the code-level insertion,ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece Xiuheng Wu, Chenguang Zhu, and Yi Li
callref
containupdate
insert
delete
new versionold version
Figure 1: An example meta-model of differential facts.
deletion, and update changes between the old and new versions as
well as the dependencies [48] between commits.
The inter-version facts are tightly connected to the intra-version
facts through common entity nodes, making it possible to reason
about facts across multiple versions. For example, we represent vari-
ous types of differential facts in a common exchangeable format and
store them in a differential factbase . Then by querying the factbase,
we could answer questions such as â€œwhat are the functions whose
bodies get changed but the signatures stay constant in an upgradeâ€
and â€œwhat are the tests potentially be affected by this upgradeâ€. The
differential factbase supports standard Tarski relational algebra [ 62]
operations such as union, intersection, composition, and transitive
closure. Existing languages and tools, such as JGrok [ 65], can be
used to query and manipulate facts. To support more complex anal-
ysis tasks and ease the implementation of analysis scripts, Datalog
is also supported so that one can also run inference on differential
factbase using Datalog engines such as SoufflÃ© [37].
Using differential facts to manage evolving software artifacts has
several benefits. First, the factbase serves as an abstraction of the
artifacts and their change histories. It hides all the complex details of
different programming languages as well as change representations
and provides a unified queryable interface for downstream analyses.
Second, the differential facts produced during offline fact extraction
can be shared and reused by many online analyses, thus saving
overall computation resources. Furthermore, with the versioning
information encoded, differential facts support the lifting of analysis
tasks from a single version to multiple versions, and again improves
analysis efficiency. Finally, the fact extractors are relatively light-
weight and built on top of existing tool chains. For instance, facts
can be stored in any relational database for persistent storage and
efficient processing.
We re-implemented several software maintenance tasks with
Diffbase , demonstrating its advantages in efficiency and interoper-
ability. These include a 44% time cost reduction in semantic history
slicing, similar precision without safety violations compared with
the state-of-the-art static regression test selection tools, and about
80% time and space usage reduction in lifted pointer analysis.
Contributions. In this paper, we make the following contributions.
â€¢We present differential facts, a uniform exchangeable representa-
tion of incremental software changes, supporting efficient query-
ing, manipulation, and reuse.
â€¢We implement several differential fact extractors targeting dif-
ferent fact types, programming languages, and platforms. The
prototype tools are open-source and additional results are avail-
able at the companion website: https://d-fact.github.io.ğ‘¦âˆˆğ‘‰(ğ‘Ÿ)Ins((ğ‘¥,ğ‘›,ğ‘£),ğ‘¦)ğ‘‰(ğ‘Ÿâ€²)â†ğ‘‰(ğ‘Ÿ)âˆª{ğ‘¥}Parent(ğ‘¥)â†ğ‘¦
ğ‘–ğ‘‘(ğ‘¥)â†ğ‘› ğœˆ(ğ‘¥)â†ğ‘£
ğ‘¥âˆˆğ‘‰(ğ‘Ÿ)Del(ğ‘¥)ğ‘‰(ğ‘Ÿâ€²)â†ğ‘‰(ğ‘Ÿ)\{ğ‘¥}ğ‘¥âˆˆğ‘‰(ğ‘Ÿ)Upd(ğ‘¥,ğ‘£)ğœˆ(ğ‘¥)â†ğ‘£
Figure 2: Types of atomic changes [23].
â€¢We apply differential facts in three evolution management tasks,
namely semantic history slicing [48],change impact analysis [5],
andregression test selection [67].
â€¢We evaluate our approach on real open-source software projects
and demonstrate the benefits of adopting differential facts over
existing techniques.
2 BACKGROUND
This section introduces the necessary background and terminology.
2.1 Program Change Histories
A valid program ğ‘can be parsed as an abstract syntax tree (AST),
denoted by Ast(ğ‘). Formally,ğ‘Ÿ=Ast(ğ‘)is a rooted tree with
a set of nodes ğ‘‰(ğ‘Ÿ). The root of ğ‘Ÿis denoted by Root(ğ‘Ÿ)which
represents the compilation unit, i.e., the program ğ‘.
Each entity node ğ‘¥has an identifier and a value, denoted by
ğ‘–ğ‘‘(ğ‘¥)andğœˆ(ğ‘¥), respectively. In a valid AST, the identifier for each
node is unique (e.g., fully qualified names in Java) and the values
are canonical textual representations of the corresponding entities.
We denote the parent of a node ğ‘¥byParent(ğ‘¥). The children are
unorderedâ€”the ordering of child nodes is insignificant. Therefore,
each program has its unique AST representation.
LetÎ“be the set of all ASTs. Now we define changes, change sets
and change histories as AST transformation operations.
Definition 1 (Atomic Change [ 48]).An atomic change opera-
tionğ›¿:Î“â†¦â†’Î“is a partial function which transforms ğ‘ŸâˆˆÎ“producing
a new ASTğ‘Ÿâ€²such thatğ‘Ÿâ€²=ğ›¿(ğ‘Ÿ). It can be either an insert ,delete or
update (see Fig. 2).
An insertion Ins((ğ‘¥,ğ‘›,ğ‘£),ğ‘¦)inserts a node ğ‘¥with identifier ğ‘›and
valueğ‘£as a child of node ğ‘¦. A deletion Del(ğ‘¥)removes node ğ‘¥from
the AST. An update Upd(ğ‘¥,ğ‘£)replaces the value of node ğ‘¥withğ‘£.
A change operation is applicable on an AST if its preconditions are
met. For example, the insertion Ins((ğ‘¥,ğ‘›,ğ‘£),ğ‘¦)is applicable on ğ‘Ÿif
and only ifğ‘¦âˆˆğ‘‰(ğ‘Ÿ). Insertion of an existing node is treated the
same as an update.
Definition 2 (Change Set). Letğ‘Ÿandğ‘Ÿâ€²be two ASTs. A change
setÎ”:Î“â†¦â†’Î“is a sequence of atomic changes âŸ¨ğ›¿1,...,ğ›¿ğ‘›âŸ©such
thatÎ”(ğ‘Ÿ)=(ğ›¿ğ‘›â—¦Â·Â·Â·â—¦ğ›¿1)(ğ‘Ÿ)=ğ‘Ÿâ€², whereâ—¦is standard function
composition.
A change set Î”=Î”âˆ’1â—¦ğ›¿1is applicable to ğ‘Ÿifğ›¿1is applicable
toğ‘ŸandÎ”âˆ’1is applicable to ğ›¿1(ğ‘Ÿ). Change sets between two ASTs
can be computed by tree differencing algorithms [12].
Definition 3 (Change History). A history of changes is a se-
quence of change sets, i.e., ğ»=âŸ¨Î”1,...,Î”ğ‘˜âŸ©.
2.2 Program Facts as Typed Graphs
Querying and analyzing program facts (relations) requires a spe-
cialized data structure and a set of operators to manipulate the facts.DIFFBASE: A Differential Factbase for Effective Software Evolution Management ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece
ğ¶3attrB
A::g()AB::f()
B::ycontain
ğ¶2attrB
A::g()AB::f()
B::y
ğ¶1attrB
A::g()AB::f()
B::y
ğ¶0attrB
A::g() AB::f()
B::yA::x
A::xA::h()call
refref
A::h()
ref
B::u A::x
B::uinsert
delete
updateParentParentParent Hunk
Figure 3: A typed graph illustrating source code and changes
between four consecutive versions.
Now we define typed graph (also known as edge-colored graph),
which is a graph with a fixed number of edge types .
Definition 4 (Typed Graph [ 33]).Letğ‘‡be a non-empty set of
types. We say that a directed graph ğº=(ğ‘‰,ğ¸,ğ‘‡)is a typed graph
with vertex-set ğ‘‰and edge-set ğ¸âŠ†ğ‘‰Ã—ğ‘‰Ã—ğ‘‡.
We denote edges(ğ‘£1,ğ‘£2,ğœ)âˆˆğ¸by(ğ‘£1,ğ‘£2):ğœ. Ahomogeneous
typed graph ğºof typeğœis a typed graph ğº=(ğ‘‰,ğ¸,{ğœ})whose
edges are all the same type ğœ. Graphs in the classic graph theory
are equivalent to homogeneous typed graphs and thus just special
cases of typed graphs.
Definition 5 (Typed Sub-Graph). Letğº1=(ğ‘‰1,ğ¸1,ğ‘‡1)be a
typed graph. ğº2=(ğ‘‰2,ğ¸2,ğ‘‡2)is a typed sub-graph of ğº1, denoted by
ğº2âŠ†ğº1, if and only if ğ‘‰2âŠ†ğ‘‰1,ğ¸2âŠ†ğ¸1, andğ‘‡2âŠ†ğ‘‡1.
Definition 6 (Type-Induced Sub-Graph). Letğº=(ğ‘‰,ğ¸,ğ‘‡)be
a typed graph and ğ‘‡â€²âŠ†ğ‘‡. We define the type-induced sub-graph of ğº,
denoted byğº[ğ‘‡â€²], as the typed sub-graph (ğ‘‰â€²,ğ¸â€²,ğ‘‡â€²)ofğºsuch that
ğ¸â€²={(ğ‘£1,ğ‘£2,ğœ)|ğœâˆˆğ‘‡â€²}andğ‘‰â€²={ğ‘£|(ğ‘£,_,_)âˆˆğ¸â€²or(_,ğ‘£,_)âˆˆğ¸â€²}.
Essentially, each type of facts is represented using a separate
edge type (details discussed in Sec. 3.1).
Example. For instance, a simple program with four versions are
shown as a typed graph in Fig. 3. (More details, including the textual
differences between versions and associated facts of this same ex-
ample are provided in Sec. 3.2.) Each of the four rectangles indicates
a version sub-graph, where solid arrows connecting code entities
within rectangles are edges representing static dependencies and
dashed arrows connecting code entities across different rectanglesa : = new A ( ) ;
b : = a ;PointTo ( a , o1 )
Assign ( a , b )
Figure 4: Example source code and its corresponding facts.
are edges representing atomic changes. For example, in the sub-
graph associated with ğ¶3,A::h() calls B::f() andreferences field
A::x . Member methods and fields are all contained within corre-
sponding classes. The circles positioned at the left of the rectangles
are commit entities connected by commit dependency edges. In
this example, the commit history is linear, with ğ¶0being the oldest
ancestor and ğ¶3hunk depends onğ¶2(cf. Sec. 3.1).
Different sub-graphs can interact by sharing common nodes. For
example, A::x is on edges of â€œinsertâ€, â€œcontainâ€, and â€œrefâ€ types.
Nodes and edges can have attributes too. For instance, the commit
nodesğ¶ğ‘–in Fig. 3 are connected to each rectangle as attributes,
indicating the versions those program facts hold. There could also be
other purely informational attributes, such as source code locations.
Algebraic Operators. The list of operators for manipulating typed
graph follow the classic Tarskiâ€™s relational calculus [ 62], which
include identity (ğ¸0),inverse (ğ¸âˆ’1), basic set operations: union (ğ¸1âˆª
ğ¸2),intersection (ğ¸1âˆ©ğ¸2),substraction (ğ¸1\ğ¸2), composition( ğ¸1;ğ¸2),
transitive closure ( ğ¸+), and reflexive transitive closure ( ğ¸âˆ—). Inspired
by projection operator used in JGrok [ 65], we useâ—¦to denote this
variant of composition operation, which takes a set and a relation:
ğ‘‰â—¦ğ¸={ğ‘£2|ğ‘£1âˆˆğ‘‰,(ğ‘£1,ğ‘£2)âˆˆğ¸},ğ¸â—¦ğ‘‰={ğ‘£1|ğ‘£2âˆˆğ‘‰,(ğ‘£1,ğ‘£2)âˆˆğ¸}.
For producing a set (vertices) from a relation (edges), selecting
columns by index is represented as ğ¸[ğ‘–]andğ‘–starts from 1.
2.3 Datalog
To provide inference capability on top of program facts, i.e., the
ability to generate new facts based existing ones, we may choose
to represent typed graphs using Datalog, which is a declarative
logic programming language with syntax similar to that of Pro-
log. Datalog extends relational calculus with recursion and can
be manipulated according to inference rules instead of low-level
relational algebra operations, thus improving both usability and
expressiveness.
Two constructs in Datalog are facts andrules . Rules are defined
as Horn clauses of predicates, usually written in the following form.
ğ‘Ÿ0(ğ‘‹1,ğ‘‹2,...,ğ‘‹ğ‘˜):âˆ’ğ‘Ÿ1(ğ‘Œ1,ğ‘Œ2,...,ğ‘Œğ‘ ),...,ğ‘Ÿğ‘›(ğ‘1,ğ‘2,...,ğ‘ğ‘¡).
whereğ‘Ÿğ‘–is a predicate and the arguments, ğ‘‹ğ‘–,ğ‘Œğ‘–,ğ‘ğ‘–, are variables
or constants. Considering the existing ambiguity in Datalog defini-
tions, the following concepts used in this paper are defined.
â€¢ğ‘Ÿ1(ğ‘1,...,ğ‘ğ‘ )is a fact if all of its arguments ( ğ‘1,...,ğ‘ğ‘ ) are con-
stants. As shown in Fig. 4, a,b,o1on the right are constants
representing the concrete source elements on the left ( o1is for
the object allocated by new A() ).
â€¢Predicates defined a priori by facts can only appear on the right
hand side of rules, which form schema of the extensional database
or EDB and those predicates are called EDB predicates. EDB is
defined as the set of facts of EDB predicates.
â€¢Predicates appeared on the left are defined by rules, which form
schema of intensional database or IDB and those predicates are
called IDB predicates. ğ‘Ÿ0is an IDB predicate. IDB is defined as
the combination of a set of rules and facts of IDB predicates.ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece Xiuheng Wu, Chenguang Zhu, and Yi Li
0SCHEME TUPLE :
1Upd Prog Prog
2Del Prog Prog
3Ins Prog Prog
4
5Contain Prog Prog
6Call Prog Prog
7Ref Prog Prog
8
9Coverage Test Prog
10Hunk Commit Commit
11Parent Commit Commit
12
13SCHEME ATTRIBUTE :
14( Upd ) { commit }
15( Del ) { commit }
16( Ins ) { commit }
(a) General fact schema.0SCHEME TUPLE :
1$INHERIT jProg Prog
2$INHERIT jClass jProg
3$INHERIT jFunc jProg
4$INHERIT jVar jProg
5$INHERIT jCtor jFunc
6$INHERIT jMethod jFunc
7$INHERIT jStaticMethod jMethod
8$INHERIT jEnum jClass
9
10Contain jProg jProg
11Call jFunc jFunc
12Ref jProg jProg
13Inherit jClass jClass
(b) Java extended schema.
Figure 5: Fact schema written in TA language.
A Datalog engine consumes EDB and IDB, then produce instances
of IDB predicates according to the rules in IDB. Program facts
can be stored as Datalog facts, with each type-induced sub-graph
representing facts of one predicate.
Example. In a simplified Anderson-style pointer analysis [ 4], an
assignment operation ğ‘¦:=ğ‘¥marks all objects pointed-to by ğ‘¥also
pointed-to by ğ‘¦, which is expressed by the following Datalog rule:
PointTo ( y , z ) : âˆ’PointTo ( x , z ) , Assign ( x , y ) .
Here, PointTo andAssign are IDB and EDB predicates, respec-
tively. Following the rule above and the two facts in Fig. 4, a Datalog
engine can produce all facts of IDB predicates, i.e., PointTo(a,o1)
andPointTo(b,o1) .
3 DIFFERENTIAL FACTS
In this section, we first present the general schema framework for
differential facts which applies to most of the languages and plat-
forms. We then describe the architecture of Diffbase with various
differential fact extractors and support for fact reusing in specific
tasks. Finally, we describe how analysis lifting is made possible by
the application of differential facts.
3.1 General Schema Framework
We construct the differential factbase as a typed graph with typed
nodes. This is to differentiate various types of entities in program
facts. Let the set of all node types be ğ‘‡ğ‘£. Then the fact schema is
described by, ğ‘€âŠ†ğ‘‡ğ‘£Ã—ğ‘‡ğ‘£Ã—ğ‘‡.
Similar to the relation declarations in Datalog and the fact scheme
in the TA language [ 32], the fact schema describes the meta-model
of a differential factbase. What follow are the fact instances , which
represent the edges of the graph, following the rules described by
the schema. The rules can be explicitly written as, âˆ€(ğ‘£1,ğ‘£2,ğœ)âˆˆ
ğ¸Â·(ğ‘¡(ğ‘£1),ğ‘¡(ğ‘£2),ğœ)âˆˆğ‘€, whereğ‘¡(ğ‘£)is the type of the node ğ‘£.
Fig. 5a shows the general schema for differential facts, written in
TA language. The general schema only defines the core entities and
generic entity relations, which are not specific to any programming
language or version control system. The entity types, Prog,Commit ,
andTest(Lines 1â€“3) are defined to represent AST nodes, commit
objects, and test cases, respectively. Based on these entity types,
we define four classes of relations, namely, the static dependency ,
coverage ,atomic changes , and commit dependency .HistoryAtomic
ChangesStatic
DependencyCode
CoverageC/C++
Java
more languagesGit RepoSource Code
(multiple
versions)Source Code
(multiple
versions)Static
Analyzer
Output(Dynamic)
Coverage
Information
Factbase Analysis Scripts
... SoufflÃ© Grok Query Engine Analysis Results
Figure 6: An overview of Diffbase architecture.
Letğºbe the typed graph containing all differential facts. Each
class of relations can be viewed as a type-induced sub-graph,
ğº[ğ‘‡ğ‘ ]=ğº[{Call,Ref,Contain}] (static dependency)
ğº[ğ‘‡ğ‘]=ğº[{Cov}] (coverage)
ğº[ğ‘‡ğ‘‘]=ğº[{Ins,Upd,Del}] (atomic changes)
ğº[ğ‘‡â„]=ğº[{Hunk,Parent}] (commit dependency)
ğº[ğ‘‡ğ‘ ]captures the dependency relations between Prog, namely,
Call,Ref, and Contain , with their standard semantics. ğº[ğ‘‡ğ‘]cap-
tures the coverage relations between Test and Prog, denoted by
Cov, and the relation holds when a test run covers the given code
entity.ğº[ğ‘‡ğ‘‘]captures three types of atomic changes, namely, Ins,
Upd, and Del.1Finally,ğº[ğ‘‡â„]captures two types of dependencies
between commits, namely the hunk dependency [48] and the his-
tory dependency , denoted by Hunk andParent respectively. For
instance, there are history dependencies from a parent commit to
all its children. Among those sub-graphs, commit dependencies and
atomic changes lead to inter-version facts, while facts describing
static dependencies and coverage information are intra-version . For
intra-version facts, we designate the commit to which an atomic
change belongs, as an attribute of the corresponding fact.
The general schema can be extended for specific types of artifacts
by adding new schema rules. Fig. 5b shows a simplified specific
extension for Java. They key extension is a hierarchy of language-
specific types (Lines 1â€“8). With those language-specific types, the
typing information in relations can be refined (Lines 10â€“12) and
new relations can be added (Line 13). For example, parameters of
Call are now jFunc instead of the generic type Prog; and Inherit is
added to represent the inheritance relations between jClass types.
Since facts we use are low-level, any structured data with a well-
defined schema can be encoded and extended similarly. Examples
include architecture diagram, E-R diagram, and other UML models.
In this paper, we focus on facts extracted from source code and
commit histories.
3.2 Extraction of Differential Facts
The overall architecture of Diffbase â€™s fact extraction and query
engine is shown in Fig. 6. We implement Diffbase as a general
framework supporting different tasks with the help of multiple fact
extractors and analysis scripts. In practice, Diffbase can be inte-
grated with IDE and version control tools or services (e.g., GitHub),
accumulating facts incrementally with the evolution of software.
1For readability and simplicity, edge types will be used to represent edge sets of
corresponding types when there is no ambiguity, i.e., Insmeansğ¸[Ins].DIFFBASE: A Differential Factbase for Effective Software Evolution Management ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece
v0.2
ğ¶3
ğ¶2
ğ¶1
ğ¶0
v0.1class B {
- double u;
+ public:
+ const static int y = 0;
+ static int f(int x){
+ return x-1;}
};class A {
+ int x;
public:
- int g() {return 0;}
+ int g() {
+ return B::y + 1;
+ }
};class A {
int x;
public:
+ int h() { return B::f(x);}
int g() {
return B::y + 1;
}
};
Ins B::static-int-f-int class-B
{commit: f992f4e}
Ins B::static-int-y class-B
{commit: f992f4e}
Del B::double-u class-B
{commit: f992f4e}Upd A::int-g {return B::y+1}
{commit: 0c94630}
Ins A::int-x class-A
{commit: 0c94630}Ins A::int-h class-A
{commit: bf574d7}
Figure 7: Example change history.
The rectangles at the top represent data sources, including Git
repositories, source code versions, and coverage information ob-
tained from test runs. These are either raw inputs or easily derived
by running existing tools such as compilers. The rounded rectan-
gles below represent basic facts, extracted from corresponding data
sources, where the fact extraction processes are represented by
incoming double arrows. The factbase is where the basic facts are
organized and stored, and analysis scripts are executed to derive
theanalysis results in the form of new facts.
To perform an empirical evaluation on the various applications of
differential facts, we implemented several fact extractors supporting
different programming languages and platforms. (1) We developed
inter-version fact extractors for C/C++ and Java. We replaced the
C/C++ back-end of the AST differencing tool, GumTree [ 21], with
our own AST emitter based on Clang [ 13] to ensure maximal com-
patibility. The Java version is implemented based on ChangeDis-
tiller [ 24]. (2) We developed extractors for test coverage facts based
on existing code coverage toolsâ€”Gcov [ 25] for C/C++ and JaCoCo
Code Coverage Library [ 35] for Java. (3) We used ClangEx [ 3] and
Apache BCEL [ 6] to extract intra-version static dependency facts,
for C/C++ and Java, respectively. (4) We developed a language-
neutral extractor for commit dependencies based on CSlicer [48].
(5) We built a tool for merging version annotated facts to support
lifted analyses. The implementation of these fact extractors is rela-
tively simple thanks to the existing open source tools. The support
of new fact types and programming languages in the future is also
straightforward.
Facts are mainly stored in the format of Tuple-Attribute files.
For example, intra-version dependency facts of each version are
stored in a separate text file and each line represents a â€œdepends
onâ€ relation between two program entities. JGrok [ 65] is used to
query facts in TA language. Facts in the lifting experiments are
represented in Datalog, where facts for each relation is stored in a
separate file. The Datalog engine we used is SoufflÃ© [37].
Example. To give a more detailed view on the typed-graph model
and inter-version fact extraction from software change histories,
we provide a walk-through of the example illustrated in the typed
graph (Fig. 3) with textual differences and associated facts. As shownin Fig. 7, the short history includes changes on two simple classes,
A and B. There are four commits shown, from ğ¶0toğ¶3, among
whichğ¶0is the initial commit and its text diff is left out. Alongside
the commit history represented by the line in the middle are unified
diff and the corresponding differential facts.
In change set ğ¶1, a member declaration B::u was removed, re-
placed by another member B::y and a member function B::f()
was added. According to Defs. 1 and 2, the changes can be described
as a change set Î”1including three AST transformations:
â€¢Del(B::u@C0)
â€¢Ins((B::y@C1, B::static-int-y, 0),B))
â€¢Ins((B::f@C1, B::static-int-f-int, {return x-1}),B)
Accordingly, three facts reflecting the changes are produced, as
shown on the opposite sides of textual diffs in the figure. Code
entities in facts are represented as a string containing entity names,
types, other modifiers if exist, and version numbers. For simplicity,
ğ¶0,...,ğ¶ 3are used instead of the commit hashes and attributes
enclosed in brackets are written right below the relations they
belong to, to avoid duplication of relation texts. Each Insoperation
can be converted to an Insert fact, using the idfield as its second
operand, while the first operand is a special code entity denoted by
NULL . Actual contents of the inserted entities defined as value are
left out in facts. Meanwhile, the parent node can be found with the
help of intra-version facts as shown in Fig. 3. A Delete fact can be
deduced by using the only parameter of Deloperation as its first
operand, while keeping the second one as NULL .
Then inğ¶2, a member declaration A::x was inserted and the
body of A::g() was changed. Î”2includes two atomic changes
displayed as follows.
â€¢Ins((A::x@C2, A::int-x, nil),A))
â€¢Upd(A::int-g@C1, {return B::y+1;})
TheUpdate facts are also produced from the Upd operations with-
out the value , and a string representation of the AST node names
and the version information are used as the two operands.
Finally, inğ¶3, a member function B::h() was added, which calls
B::f() and references A::x .
â€¢Ins((A::int-h@C3, A::int-h, {return B::f(x);}),A))
One limitation of this approach is that users must define the
scope of their desired analyses beforehand and then configure Diff-
base and the corresponding fact extractors on how fine-grained
the facts and queries should be. The evolution analysis tasks pre-
sented in this paper operate at the method-level , so facts extracted
do not contain more fine-grained information, such as the orders of
statements. If users decide that changes on individual statements
are important to them, e.g., to perform data-flow analysis, then
extractors have to be reconfigured and facts are to be regenerated.
3.3 Reusing of Differential Facts
Differential factbase not only supports storage, exchange, and ma-
nipulation of facts, but also enables reusing of facts in different ways.
Many complex software analysis tasks require information from
various sources, which may be used more than once in subsequent
analyses. This creates opportunities for performance improvement
if repeatedly used information is persisted and reused. However,ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece Xiuheng Wu, Chenguang Zhu, and Yi Li
Î”ğµ1Î”ğµ2Î”ğµ3ğ¹ğ‘
1ğ¹ğ‘
2ğ¹ğ‘
3ğ¹ğ‘
ğ‘‡ğ´ğ‘‡ğ´ğ‘‡ğ´
(a) Cross-runğ¹ğ‘ğ¹ğ‘ğ¹ğ‘
Î”ğµ1 Î”ğµ2ğ‘‡ğ´1ğ‘‡ğ´2Analysis 1Analysis 2
(b) Cross-analysis
Figure 8: Fact reusing between sub-tasks.
intermediate analysis results are often not explicitly exposed or rep-
resented in non-standard formats, which makes reusing challenging
when performing new tasks.
We propose to separate the creation and the usage of facts: Diff-
base serves as an intermediate layer providing uniformed data
format to the downstream analysis scripts. This enables efficient
and flexible reuse of both the data and the analysis logic. We first de-
fine necessary terminology, before illustrating the possible venues
of reusing.
Definition 7. (Analysis Task). Let ğ¹be a set of facts and ğ´be
an analysis script with a set of operations. We define ğµ=ğ‘‡ğ´(ğ¹)as
an analysis task taking ğ¹as the input and producing ğµas the results,
whereğ¹âŠ†ğµ.
An analysis task grows the set of known facts and it can com-
prise several sub-tasks. Some sub-tasks depend on others, while
independent sub-tasks can be executed in parallel. For simplicity, a
task is represented as a linearized composition of sub-tasks.
Definition 8. (Analysis Sub-Task). Let âŸ¨ğ‘‡ğ´1,...,ğ‘‡ğ´ğ‘›âŸ©be a se-
quence of tasks. We say {ğµğ‘–+1=ğ‘‡ğ´ğ‘–(ğ¹ğ‘–)âˆªğµğ‘–|ğ‘–âˆˆ [1,ğ‘›]}are
sub-tasks of ğ‘‡ğ´(ğ¹)if and only if ğ‘‡ğ´(ğ¹)=ğ‘‡ğ´ğ‘›â—¦Â·Â·Â·â—¦ğ‘‡ğ´1(ğ¹).
With the completion of more sub-tasks, the set of facts available
for consumption, i.e., ğµğ‘–, is also growing. The amount of growth
is defined as Î”ğµğ‘–+1=ğµğ‘–+1âˆ’ğµğ‘–. The set of facts consumed by a
sub-task is only a subset of the facts available at the moment, i.e.,
ğ¹ğ‘–âŠ†ğµğ‘–.
There are various scenarios where reuse can happen with the
support of Diffbase . We first discuss the cases where facts can be
shared among multiple analysis tasks. These include the cross-run
and the cross-analysis fact reusing. Note that this is not a unique
feature for differential facts and applies for other program fact-
based approaches as well.
Cross-Run Fact Reusing. One common scenario for fact reusing
is when the same analysis task is repeatedly performed with only
part of the input data varying every time. For example, in Fig. 8a,
an analysis task ğ‘‡ğ´is executed three times, but on different inputs
sharing common facts, where ğ¹ğ‘–=ğ¹ğ‘
ğ‘–âˆªğ¹ğ‘. Here onlyğ¹ğ‘
ğ‘–needs to
be created across different runs and ğ¹ğ‘can be reused. A real-world
example is Semantic history slicing [46,48,72] and an in-depth
analysis of this scenario can be found in Secs. 4.1 and 4.2.
Cross-Analysis Fact Reusing. Similar to the cross-run reusing,
two different analysis tasks can share information through per-
sistent facts. As shown in Fig. 8b, two tasks, ğ‘‡ğ´1andğ‘‡ğ´2, require
{ğ¹ğ‘,ğ¹ğ‘}and{ğ¹ğ‘,ğ¹ğ‘}as inputs, respectively. Because they both
requireğ¹ğ‘as a part of their inputs, ğ¹ğ‘needs only be created once,
but can be used many times subsequently.If we were to perform both history slicing ( ğ‘‡ğ´1) and regression
test selection [ 20] (ğ‘‡ğ´2) on the same software project within the
same history range, then we would be able to reuse differential
facts across the two analyses. In particular, intra-version facts in-
cluding the test dependencies and inter-version facts (i.e., change
information) can be reused. Experimental results and more detailed
discussions on cross-analysis fact reusing can be found in Sec. 4.3.
Analysis Script Reusing. Apart from reusing facts, Diffbase
also enables the reusing of analyses. Analysis scripts implementing
inference logic can be reused on different input data. The analysis
script reusing can be viewed as a special case for cross-run reusing.
When the same analysis task ğ‘‡ğ´is executed multiple times on
disjoint input facts, not being able to reuse facts, we may still reuse
the analysis script ğ´. This is made possible with the hierarchical
design of our schema framework, which is general enough to be
compatible with different types of input facts. For example, the core
analysis script needs only written once using the basic schema, and
specific extensions can be added accordingly. We demonstrate this
with a case study on history slicing (Sec. 4.1.1), where the fact usage
becomes language- and platform-agnostic.
3.4 Analysis Lifting on Differential Facts
The differential fact schema presented so far represents extracted
facts as a typed graph and supports querying using relational al-
gebra as defined in Sec. 2.2. This is sufficient to support many
rudimentary analysis tasks concerning about only the structural
information represented by the graph. Examples include history
slicing, change impact analysis, and regression test selection, which
will be discussed in detail in Sec. 4.1.
More importantly, we show that, when combined with infer-
ence rules, differential facts can support analysis lifting [59], which
greatly improves the efficiency. Analysis lifting is the process of
adapting a single-version analysis task to a lifted analysis which
works on multiple versions simultaneously. For example, a points-to
analysis, which determines the set of objects potentially pointed to
by a program expression, can be lifted to multiple versions of the
same program. Instead of applying a brute-force approach, where
each version is analyzed separately, the lifted points-to analysis
would take the differential facts of ğ‘›versions and produces the
expected results for all versions. Analysis lifting creates new op-
portunities for reusing of the intermediate analysis results, which
will be discussed more in Line 15.
The lifting of analyses largely depends on the version anno-
tated facts. Inspired by Shahin et al.â€™s lifting algorithm [ 59] on
software product lines, version annotated facts have an additional
version tag after usual fact terms. The tag is a sequence of version
strings, following an â€œ@â€ symbol and separated by commas, in-
dicating the set of versions on which the facts hold. For example,
â€œfn-a fn-b @v1,v2 â€ in an input file Call.facts means that the
fact, fn-a calling fn-b , holds on both v1andv2.
Algorithm 1 shows the modified Datalog inference algorithm
to properly handle version annotated EDB facts and generate IDB
facts with correct annotations. It takes basic facts ( ğ¸) generated
from fact extractors and Datalog programs ( ğ‘ƒ) which specify how
to generate new facts from existing ones as input. The basic facts
are tagged with versions and merged into a compact representation.DIFFBASE: A Differential Factbase for Effective Software Evolution Management ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece
Input: annotated EDB facts ğ¸and IDB facts ğ¼, Datalog program ğ‘ƒ
Output: updated IDB facts ğ¼
1repeat
2 fixpointâ†true;
3 foreach ruleğ‘…=(ğ‘Ÿ0:âˆ’ğ‘Ÿ1,...,ğ‘Ÿğ‘›)âˆˆğ‘ƒdo
4 foreachâŸ¨(ğ‘“1,ğ‘£1),...,(ğ‘“ğ‘›,ğ‘£ğ‘›)âŸ©âˆˆğ¸âˆªğ¼,ğ‘Ÿğ‘–(ğ‘“ğ‘–)istruedo
5 ğ‘“0â†ğ‘…(ğ‘“1,...,ğ‘“ğ‘›);
6 ğ‘£ğ‘”â†Ã‘
ğ‘–ğ‘£ğ‘–;
7 ifğ‘£ğ‘”â†âˆ… then continue;
8 ifâˆƒ(ğ‘“0,ğ‘£0)âˆˆğ¼then
9 ifğ‘£ğ‘”â‰ ğ‘£0then
10 fixpointâ†false;
11 Updateğ¼:(ğ‘“0,ğ‘£0)â†(ğ‘“0,ğ‘£ğ‘”âˆªğ‘£0);
12 else
13 fixpointâ†false;
14 ğ¼â†ğ¼âˆª(ğ‘“0,ğ‘£ğ‘”);
15until fixpoint ;
Algorithm 1: Lifted Datalog inference algorithm ( Ë†â„) on differ-
ential facts.
ğ¹1ğ¹ğ‘›
Î”ğµ1 Î”ğµğ‘›ğ‘‡ğ´ğ‘‡ğ´. . .
ğ¹(1..ğ‘›)ğ¹1 ğ¹ğ‘›. . .
Î”ğµ(1..ğ‘›)Î”ğµ1 Î”ğµğ‘›. . .
ğ‘‡ğ‘€1
ğ‘‡ğ´
Figure 9: Analysis reusing enabled by lifting.
The algorithm first sets the fixpoint variable to true and iterates
over the rules from ğ‘ƒ(Lines 3 to 14). The condition â€œ ğ‘Ÿğ‘–(ğ‘“ğ‘–)is True â€
on Line 4 indicates that ğ‘“ğ‘–is a fact on the predicate ğ‘Ÿğ‘–. For each set of
existing facts in EDB which satisfies the predicates on the right hand
side of the rule, i.e., âŸ¨(ğ‘“1,ğ‘£1),...,(ğ‘“ğ‘›,ğ‘£ğ‘›)âŸ©, the annotated version
labels are intersected with the existing ones (Line 6) and a new fact
ğ‘“0is generated by applying the rule. (On Line 5, ğ‘“0â†ğ‘…(ğ‘“1,...,ğ‘“ğ‘›)
means applying the rule ğ‘…on facts(ğ‘“1,...,ğ‘“ğ‘›)to generate a new
factğ‘“0.) If the computed intersection is empty (Line 7), then we
know that this new fact does not hold at any version.
Otherwise, we search the IDB facts for ğ‘“0. If there already exists
a factğ‘“0with a different version label set, we set the fixpoint vari-
able to false and update IDB by replacing the version annotation
(Line 11). If ğ‘“0is not already in IDB, this new found fact is added
with its version annotation (Line 14) and in this case, fixpoint is also
set to false. The algorithm terminates when a fixpoint is reached,
and the resulting IDB facts ( ğ¼) contains the analysis results anno-
tated with the correct version labels. The correctness of Algorithm 1
is given in Theorem 1 and we provide the proof on the companion
website.
Theorem 1. Letâ„andË†â„be the unlifted and lifted inference algo-
rithms, respectively. Given an EDB ğ¸annotated with version strings
from a setğ‘‰and a Datalog program ğ‘ƒ, we haveâˆ€ğ‘£âˆˆğ‘‰:Ë†â„(ğ¸,ğ‘ƒ)|ğ‘£=
â„(ğ¸|ğ‘£,ğ‘ƒ), whereÂ·|ğ‘£selects facts which are valid on version ğ‘£.
Lifting-Enabled Reusing. When a complex analysis task consists
of multiple similar sub-tasks, intermediate results produced by ear-
lier sub-tasks may be reused by the latter ones. This is not possible
if the sub-tasks are implemented as standalone black-boxes. Algo-
rithm 1 automatically enables the sharing of intermediate results:
instead of performing an analysis on ğ‘›versions of a project sepa-
rately, we can run it once on the consolidated differential facts. Fig. 9Table 1: Summary of experiments and RQs answered.
History Slicing CIA RTS Lifting
Sections Secs. 4.1.1 and 4.2 Sec. 4.1.2 Sec. 4.3 Sec. 4.4
RQs RQ1,2 RQ1,3 RQ4
âŸ²ğº[ğ‘‡ğ‘ ]â‡‹ğº[ğ‘‡ğ‘ ]â‡‹ğº[ğ‘‡ğ‘ ] â†• intra-version facts
Facts âŸ²ğº[ğ‘‡ğ‘‘]â‡‹ğº[ğ‘‡ğ‘‘]â‡‹ğº[ğ‘‡ğ‘‘]
(Re)used âŸ²ğº[ğ‘‡â„]
ğº[ğ‘‡ğ‘]
illustrates this process. The left side shows the case where the task
ğ‘‡ğ´is executed on ğ‘›versions individually, i.e., âŸ¨ğ‘‡ğ´(ğ¹1),...,ğ‘‡ğ´(ğ¹ğ‘›)âŸ©.
Whenğ‘‡ğ´is lifted, the new analysis process includes three sub-tasks,
âŸ¨ğ‘‡ğ‘€1,ğ‘‡ğ´(ğ¹(1..ğ‘›)),ğ‘‡ğ‘€2âŸ©, whereğ‘‡ğ‘€1merges{ğ¹1,...,ğ¹ğ‘›}intoğ¹(1..ğ‘›),
ğ‘‡ğ´runs on the merged facts, and ğ‘‡ğ‘€2consolidates the results with
the correct version labels. Essentially, the lifted ğ‘‡ğ´enables the
reusing of the analysis sub-tasks common to all versions.
4 EVALUATION
In this section, we aim to answer the following research questions
through the empirical evaluation. RQ1 : how does differential facts
support evolution management tasks? RQ2 : how significant is the
efficiency improvement brought by fact reusing? RQ3 : how well
does differential facts support cross-analysis reusing? RQ4 : how
significant is the efficiency improvement brought by lifting enabled
analysis reusing?
The mappings between the experiments and RQs answered
are shown in Table 1. In Sec. 4.1, two case studies, history slic-
ingandchange impact analysis (CIA) are conducted to answer RQ1.
Then in Sec. 4.2 we answer RQ2 by demonstrating that cross-run
facts reusing saves time in history slicing. To answer RQ3, we
re-implement regression test selection (RTS) based on differential
facts and validate cross-analysis reusing in Sec. 4.3. Finally, Sec. 4.4
answers RQ4 with a lifting-enabled reusing for pointer analysis.
In Table 1, we also summarize the facts reused in each experiment
using the graph notations from Sec. 3.1, i.e., ğº[ğ‘‡ğ‘ ]corresponds to
static dependency facts, ğº[ğ‘‡ğ‘‘]represents atomic changes, ğº[ğ‘‡â„]
represents commit dependencies and ğº[ğ‘‡ğ‘]captures coverage in-
formation. Symbols before each type of facts indicate how facts are
reused: cross-run reusing is prefixed by âŸ², cross-analysis reusing
is prefixed by â‡‹, andâ†•means lifting-enabled reusing.
The following experiments were conducted on a 6-core Intel(R)
Xeon(R) CPU E5-1650 v3 @ 3.50GHz machine with 16 GB RAM,
running Debian sid, with OpenJDK 1.8.0_151 and Python 3.7.4. The
fact extractor implementations, analysis scripts, and raw data are
available as supplemental materials at: https://d-fact.github.io.
4.1 Case Study: Diffbase in Evolution Tasks
Diffbase serves as an infrastructure for storing, exchanging, and
manipulating multi-version program relations embedded in soft-
ware change histories, which enables a wide range of evolution
management tasks. We conducted case studies on two of such tasks,
namely, semantic history slicing andchange impact analysis .
4.1.1 History Slicing with Differential Facts. The state-of-the-art
history slicing technique, CSlicer [48], relies on static analysis of
dependencies between atomic changes to decide which commits toESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece Xiuheng Wu, Chenguang Zhu, and Yi Li
keep in the history slices, in order to pass certain tests. It first ana-
lyzes the latest program version to collect test coverage information
and then computes an over-approximated set of atomic changes
touching the covered elements. Then, through change dependency
analysis [48], it includes additional changes required for proper
compilation of the program. Finally, the identified atomic changes
are mapped back to the commits in the original change history. The
produced history slices are guaranteed to not causing any merge
conflict, and the resulting program is guaranteed to compile and
pass the tests.
The original CSlicer was implemented as a monolithic appli-
cation which only works on Java projects. In this case study, we
re-implement it with Diffbase in order to achieve better reusing
and support for multiple programming languages.
ğ‘…ğ‘“=ğ¶;(InsâˆªUpdâˆªDel) (1)
ğ·=ğ¶â—¦(CallâˆªRefâˆªContain)+(2)
ğ‘…ğ‘‘=ğ·;(InsâˆªDel) (3)
The aforementioned history slicing process can be described as
algebraic operations on typed graphs. Each slicing criteria defined
by a group of tests is a set of vertices ğ‘‡in the sub-graph Cov,
where each edge connects two vertices, namely, a test entity and
a code entity. To find the affected code entities by one specific
slicing criteria, we find the corresponding code entities from its test
entities, denoted by ğ¶=ğ‘‡â—¦Cov. The atomic changes touching the
covered elements are equivalent to the subset ğ‘…ğ‘“=(ğ‘£,_)âŠ†ğ¸[ğ‘‡ğ‘‘]
whereğ‘£âˆˆğ¶, thus can be calculated by applying composition on ğ¶
and all three types of atomic changes relation, as shown in Eq. (1).
Next is to calculate the set of all code entities depended on by
ğ¶. This can be done by traversing the static dependency graph
ğº[ğ‘‡ğ‘ ]starting from the vertices in ğ¶. We use the transitive closure
operator to collect all vertices reachable from ğ‘£in the dependency
graphğº[ğ‘‡ğ‘ ], and produce the resulting code entities by projecting ğ¶
through the closure (Eq. (2)). Moreover, the atomic changes touching
code entities in ğ·is captured by the subset ğ‘…ğ‘‘=(ğ‘£,_)âŠ†ğ¸[Ins]âˆª
ğ¸[Del], whereğ‘£âˆˆğ·. Hence, we derive ğ‘…ğ‘‘from the composition
shown in Eq. (3). Upd is excluded in the calculation of ğ‘…ğ‘‘, since
modifications to program entities only appearing in ğ·shall not
affect compilations. But insertions and deletions of entities in ğ·are
essential to avoid compilation errors.
ğ‘…ğ‘“andğ‘…ğ‘‘contains all the atomic changes which should be
kept in the history slice. Therefore, the resulted history slice is
the set of commits associated with change set ğ‘…ğ‘“âˆªğ‘…ğ‘‘. We were
able to verify the correctness of our implementation by comparing
with the original CSlicer on a number of C/C++ and Java projects,
which demonstrates Diffbase â€™s support for interoperability. We
also perform a performance evaluation in Sec. 4.2.
4.1.2 Change Impact Analysis with Differential Facts. It is also pos-
sible to implement change impact analysis [ 5,56] using the same
set of facts as in Sec. 4.1.1. From the high-level, we would like to
identify the set of code entities potentially affected by a commit.
This can be derived by first mapping the changed entities from the
given commit and storing them in ğ‘‹.
ğ‘‹=(UpdâˆªDelâˆªIns)[1] (4)
ğ·=(CallâˆªRefâˆªContain)âˆ—â—¦ğ‘‹ (5)Then we derive the set of affected entities ( ğ·in Eq. (5)) by finding
all entities that transitively depend on the elements of ğ‘‹. This is
realized by projecting the reflexive transitive closure of the union
of all dependency relations onto ğ‘‹.
The change impact analysis query can be further applied in a
library upgrade scenario, where we try to find out the client classes
affected by a library upgrade. When an original version of the
libraryğ‘™ğ‘–ğ‘upgrades to the upgraded version ğ‘™ğ‘–ğ‘â€², the fact set ğ‘‹â€²in
Eq. (6) captures all the updates and deletions between ğ‘™ğ‘–ğ‘andğ‘™ğ‘–ğ‘â€².
Note that we leave out insertions, because client cannot depend on
program entities which do not exist in the original version of the
library.
ğ‘‹â€²=(UpdâˆªDel)[1] (6)
Taking a client ğ‘ğ‘™ğ‘–as input, the depedency graph ğº[ğ‘‡ğ‘ ]captures
allcall,contain ,reference relations between entities within ğ‘ğ‘™ğ‘–, as
well as calland reference fromğ‘ğ‘™ğ‘–toğ‘™ğ‘–ğ‘. Therefore, using Eq. (5)
onğ‘‹â€², we can find out all program entities in the client which
directly or indirectly depend on the modified or deleted library
entities. In practice, ğ·can be used to guide the test generator to
more efficiently generate tests. After executing those tests with
bothğ‘™ğ‘–ğ‘andğ‘™ğ‘–ğ‘â€², any test failure reveals an incompatibility caused
onğ‘ğ‘™ğ‘–, brought by the upgrade of ğ‘™ğ‘–ğ‘. This effectively implements a
light-weight solution for the client-specific upgrade checking prob-
lem [ 49]. We implemented this task with the same fact extractors
used in Sec. 4.1.1 and more results are presented on the companion
website.
4.2 Experiment: Cross-Run Fact Reusing
In this experiment, to demonstrate the efficiency improvement
brought by cross-run fact reusing, we compare our differential facts
based history slicing technique with CSlicer , a state-of-the-art
semantic history slicing tool.
4.2.1 Subjects. Since CSlicer does not work on C/C++ projects,
the performance evaluation was conducted on Java projects. To
evaluate how fact reusing can improve the efficiency of history
slicing, we use a benchmark consisting of 37 functionalities selected
from the DoSC dataset [ 71]. Each functionality is identified by a
unique key which refers to its corresponding issue key on the
JIRA issue tracker [ 36] and is accompanied by a set of tests. DoSC
includes the starting and ending commit of the software history
which determine the life cycle of the development of a functionality.
We selected functionalities from eight open source projects,
namely, Compress [ 14], Configuration [ 15], CSV [ 17], Flume [ 22],
IO [34], Lang [ 43], Maven [ 52], and Net [ 53]. All of these projects
are written in Java and have publicly accessible change histories. Ini-
tially, five functionalities were randomly selected from each project
available in DoSC . We then removed functionalities that are cur-
rently not supported by CSlicer (e.g., those that include changes
that modify non-Java files, because CSlicer does not handle such
files). In the end, our experiments used 10 different history ranges
and 37 functionalities from eight projectsâ€”see Table 2 (the first
column) for their unique keys. In Table 2, each ID corresponds to a
history range marked by the SHA-1 of the Start andEndcommits,
as well as the number of commits (i.e., Length ). Those subjects from
the same projects with different history ranges are distinguished
by suffixes (e.g., â€œ-1â€ and â€œ-2â€).DIFFBASE: A Differential Factbase for Effective Software Evolution Management ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece
Table 2: Subjects used in the history slicing experiment.
ID ProjectsHistory# CriteriaStart End Length # Edited Files LOC(+) LOC(-)
COMPRESS Apache Commons Compress 99bc508 b29395d 148 144 4,644 2,006 5
CONFIG Apache Commons Configuration 89428f1 9fb4ad8 50 34 1,201 655 2
CSV Apache Commons CSV b230a6f5 7310e5c6 79 28 1,640 713 4
FLUME-1Apache Flumecda3bd10 31d45f1b 101 181 14,742 3,097 3
FLUME-2 f7560038 5e400ea8 100 428 17,341 8,187 3
IO Apache Commons IO 8de491fc b1b9f1af 136 182 5,647 1,681 5
LANG Apache Commons Lang 24767d6 76cc69c 262 146 6,741 2,076 8
MAVEN-1Apache Mavenb175144 308d4d4 51 78 1,816 713 3
MAVEN-2 b7e3ce2 ea8b2b0 97 160 4,431 4,144 2
NET Apache Commons Net d483631 abd6711 269 233 6,845 2,393 2
LANGIOFLUME-2FLUME-1CSVCONFIGCOMPRESS
35.2510.0710.558.785.2711.7317.52CSlicer Static
Test Query
141.0625.2525.4812.437.767.7235.81
NETMAVEN-2MAVEN-1
22.2920.8613.15
53.0925.8914.43
Figure 10: Comparison of the time costs (in seconds) between
Diffbase andCSlicer .
4.2.2 Results. The efficiency improvement of the fact-based his-
tory slicing, implemented using Diffbase , come from the reusabil-
ity of facts. With our approach, when there exist slicing tasks which
operate on the same fragment of history differed only in slicing cri-
teria, all facts except coverage facts are generated once and stored
for reusing, while CSlicer does repeated work. We compare the
total time used by our approach and CSlicer on all subjects and
also on the basis of each unique history segment, defined by the
3-tuple (Project, HistoryStart, HistoryEnd) in Table 2. As shown in
Fig. 10, each pair of bars represent the time costs of Diffbase and
CSlicer , respectively. The time costs of Diffbase are divided into
three parts: static dependency fact extraction (â€œStaticâ€, recorded per
history segment), test coverage fact extraction (â€œTestâ€, recorded per
functionality), and query processing (â€œQueryâ€). Our approach per-
forms consistently better than CSlicer . The one exception where
it performs worse is CONFIG, which has the shortest history and
fewest LOC in all projects. Therefore, time saved from storing differ-
ential facts is counteracted by the time costs of querying, depicted
by a larger portion of query processing time shown in the stacked
part of the bar plot.
Answer to RQ1 & RQ2: In all experiments, differential facts
based history slicing can produce correct slices, matching the
results of the state-of-the-art tools. It also operates on multiple
languages. On average, we reduce 44% of the time cost by re-
using differential facts. It performs worse in only one subject,
while it runs 75% faster in the best case.
4.3 Experiment: Cross-Analysis Fact Reusing
In this experiment, to evaluate the effectiveness of cross-analysis
fact reusing, we implemented the regression test selection (RTS)technique proposed by Yoo et al. [ 67] based on differential facts,
and compared it with three state-of-the-art RTS tools.
We implemented our fact-based RTS by reusing the facts col-
lected from the change impact analysis experiment in Sec. 4.1.2.
Specifically, for a given commit, we first extracted the set of pro-
gram entities affected by it ( ğ·in Eq. (5)), then intersected these
entities with the set of test entities to obtain the set of tests affected
by the commit ( ğ‘…in Eq. (7)). From a queryâ€™s perspective, given the
set of test entities ğœ,ğ‘…is the intersection of ğœandğ·.
ğ‘…=ğœâˆ©ğ· (7)
The resulting set ğ‘…contains the selected regression tests that needs
to be rerun on this new commit. This implementation demonstrates
how differential facts are used, in a cross-analysis manner, to sup-
port reusing intermediate results across different evolution man-
agement tasks.
4.3.1 Experiment Setup. To evaluate our fact-based RTS, we use
the DefectsEP component proposed in [ 70], a state-of-the-art frame-
work for evaluating RTS tools. DefectsEP uses 151 real-world bugs
from three Java projects as evaluation subjects, which were selected
from the Defects4J dataset [ 38]. Table 3 shows the original project
IDs and bug IDs of these subjects in Defects4J. The bug IDs are
consecutive and inclusive, e.g., â€œ28-53â€ means the bugs No.28, No.53,
and all others falling in between.
In DefectsEP, for each bug, two consecutive revisionsâ€” ğ‘‰bugand
ğ‘‰fixâ€”of the program are provided in the dataset, such that there is
at least one triggering test fails atğ‘‰bugand passes at ğ‘‰fix. Given a
set of RTS tools as input, for each bug, DefectsEP runs each tool on
both versions in the order ğ‘‰fixâ†’ğ‘‰bug, and collects the number of
selected and failing tests on ğ‘‰bugof each tool. In the end, for each
RTS tool under test, DefectsEP contrasts its result with other tools
and RetestAll (a baseline strategy that always runs all tests) and
uses a set of rules to detect abnormal behaviors. For each identified
abnormal behavior, it reports a violation to the user. By default,
DefectsEP evaluates safety, precision, and generality of each tool.
In our experiment, we focus on safety and precision, as they are
fundamental properties of RTS tools [70].
To evaluate safety, we compare the number of newly failing tests
onğ‘‰fixselected by that tool versus RetestAll, i.e., applying the rule
R1 in [ 70]. The rationale is that a safe RTS tool should never miss
a newly failing test, as the test is for sure affected by the changes
inğ‘‰fixâ†’ğ‘‰bug. If on a subject, a tool misses any newly failing
test, then the subject is counted as a safety violation of the tool.
To evaluate precision, we compare the number of tests selected byESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece Xiuheng Wu, Chenguang Zhu, and Yi Li
Table 3: Experimental results of the RTS experiment.
Projects Bug IDsSelected Test Methods (Avg. %)
Clover Ekstazi STARTS FACTS
LANG 28-53 10.4% 26.4% 53.9% 54.1%
MATH 5-104 9.5% 12.8% 20.0% 16.7%
TIME 1-20,22-26 100.0% 47.8% 100.0% 100.0%
# Safety Violations 16 1 1 0
each tool. Given RTS tools ğ‘…1andğ‘…2, if both tools do not violate
safety, i.e., do not miss newly failing tests, ğ‘…1is considered to be
more precise than ğ‘…2ifğ‘…1selects fewer tests than ğ‘…2.
We compare our fact-based RTS with all the three state-of-the-art
RTS tools evaluated in [ 70]: Clover [ 55], Ekstazi [ 27], and STARTS [ 45].
Clover is developed by industry, while Ekstazi and STARTS are de-
veloped by researchers. We run DefectsEP on the four tools on
all 151 subjects, comparing their numbers of safety violations and
numbers of selected tests (for precision).
4.3.2 Results. Table 3 shows the results of the comparison. The
numbers of safety violations are shown on the â€œ# Safety Violationsâ€
row in Table 3, while the percentage of the selected test methods are
measured on average over all the subjects of a project. For example,
on project commons-lang [ 43] (LANG in the table), Clover selects
10.4% tests on average over bugs 28-53; on all the subjects, Clover
has 16 safety violations in total.
According to the results, our fact-based RTS is the only tool
having no safety violations. Both Ekstazi and STARTS have one
violation and Clover has 16 violations.
For precision, the results indicate that our fact-based RTS has
similar precision as STARTS, though it is less precise than Ekstazi
and Clover. This is expected, because Ekstazi and Clover perform
test selection based on dynamic analysis. Using runtime informa-
tion, they can further refine their dependency analysis by reducing
the set of code entities that are not covered by tests. Still, our fact-
based RTS has comparable precision as STARTS, a state-of-the-art
static RTS tool. This further demonstrates the effectiveness and
applicability of our approach.
Most facts used by our RTS technique are pre-computed and
shared among different tasks (e.g., case studies in Sec. 4.1), including
inter-versions facts representing atomic changes and intra-version
facts depicting static dependencies between program entities. This
is another example for the benefit of reusing facts across analyses.
Answer to RQ3: On the 151 subjects of DefectsEP, our fact-
based RTS technique outperforms all other state-of-the-art
RTS tools in safety, and obtains similar precision as STARTS,
the most recent static RTS tool. The experiment results con-
firm the applicability of our fact-based RTS tool and the effec-
tiveness of cross-analysis fact reusing.
4.4 Experiment: Lifting Enabled Reusing
In this experiment, we evaluate time and space savings brought by
lifting enabled analysis reusing. For this purpose, we conducted a
one-call-site heap-sensitive pointer analysis on Java projects using
Doop [ 9]. We used six out of the eight projects in Table 2 as the
subjects. Maven and Flume were excluded because they contain
multiple modules, currently not supported by our tooling. For eachTable 4: Time and space savings brought by analysis lifting.
ProjectBefore Lifting After Lifting
ğ‘‡(ms)ğ‘†(MB)ğ‘‡â€²(ms) Î”ğ‘‡ ğ‘†â€²(MB) Î”ğ‘†
CSV 49129 40.26 5287 89.65% 4.88 87.88%
IO 53752 360.92 7085 86.82% 25.87 92.83%
CONFIG 91421 887.32 15751 82.77% 81.10 90.86%
COMPRESS 48581 486.84 11554 76.28% 81.51 83.26%
LANG 72892 614.19 11641 84.03% 75.98 87.63%
NET 60736 313.62 8750 85.59% 41.62 86.73%
project, ten versions before the Endversion were used and the same
analysis was conducted with two different approaches. Without
lifting, Doop was repeatedly ran on each version and the results
were collected. With lifting, a modified version of Doop was first
invoked on each version with the stop-at-facts mode (i.e., sub-task
ğ‘‡ğ‘€1in Fig. 9) so that version annotated facts were generated, which
were then consolidated in Diffbase . During the consolidation pro-
cess, duplicated facts were removed and each fact was annotated
with a set of version labels. Finally, Doop was invoked again in the
start-after-facts mode, which consumes the consolidated differential
facts and generates the results following Algorithm 1 (sub-tasks ğ‘‡ğ´
andğ‘‡ğ‘€2in Fig. 9).
Table 4 shows the results of the experiments. The project names,
time taken (in milliseconds), and space taken for storing the facts (in
MBs), before and after the analysis lifting, are listed in the columns.
Columns â€œğ‘‡â€ and â€œğ‘‡â€²â€ list the time costs, while Columns â€œ ğ‘†â€ and
â€œğ‘†â€²â€ list the space usage. ğ‘‡â€²includes the time spent on merging,
which shows that the time gain brought by reusing outweighs the
overhead of lifting computation. The percentage reductions are
listed in Columns â€œ Î”ğ‘‡â€ and â€œ Î”ğ‘†â€, respectively. For most projects,
lifting introduces about 80% savings on both time and space.
Answer to RQ4: Analysis lifting powered by differential facts
brings significant savings (more than 80% reduction in aver-
age) in both space and time through the reusing of intermedi-
ate analysis results.
4.5 Threats to Validity
Subjects used in our evaluation may not be representative. To miti-
gate this threat, we used the published dataset from prior research
on both history slicing and regression test selection; these subjects
were taken from large open-source projects covering diverse do-
mains. We ran all the experiments on a single machine, and our
findings related to execution time might differ on another machine.
During the implementation of our tools, we have used several ma-
chines and observed similar trends on these machines. The observed
results in our evaluation may be affected by errors in implemen-
tations. Our fact extractors, analysis scripts, as well as scripts for
running the experiments, may contain bugs. Two of the authors
worked closely on the implementation of the tool and frequently
reviewed code together. We have also checked for various outliers
in our results, which helped in discovering and fixing several bugs.
5 RELATED WORK
Our work intersects with a few research areas and is mostly related
toprogram fact extraction andsoftware evolution management .DIFFBASE: A Differential Factbase for Effective Software Evolution Management ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece
Fact Extraction. Fact extractors are custom, human-defined ana-
lyzers that automatically scan structured software artifacts to pull
out pertinent details to be included in a resultant factbase. The idea
of reverse engineering programs and representing relevant infor-
mation as facts is not new. The existing work on fact extraction can
be broadly categorized into the intra-version andinter-version ones.
Intra-version fact extraction focuses on a single version of the
program artifacts. Fact extractors for different programming lan-
guages and platforms have been built, including Javax [2] for Java,
Cppx [1] and ClangEx [3] for C/C++, and ASX [18] for assembler,
objects, dynamic libraries and executables. We have developed our
own fact extractor for Java and modified ClangEx for C/C++ to
generate intra-version facts of the format compatible with the rest
of the differential facts. There are also many downstream analyses
performed on the intra-version facts for architecture understand-
ing [7], visualization and redocumentation [39].
Inter-version fact extraction relies on sophisticated structural
differencing [8,12,21] and code change classification [23,24,30]
algorithms. The former is used to compute an optimal sequence of
atomic edit operations that can transform one AST into another,
and the latter is used to classify atomic changes according to their
change types. Examples of AST differencing algorithm include
ChangeDistiller [ 24] and GumTree [ 21]. They both use individual
statements as the smallest AST nodes and categorizes source code
changes into elementary tree edit operations, for instance, insert,
delete, move and update. ChangeDistiller only works on Java while
GumTree works on a number of different languages. GumTree con-
verts a source file into a language-agnostic tree format and is able
to export the tree differences into various formats. We built our
inter-version fact extractor based on GumTree by implementing a
specialized tree exporter to the TA format. We use canonical identi-
fiers for entity nodes to ensure the proper linkages between inter-
and intra-version facts. The key difference of our approach is the
emphasis on the reusing of facts, which was not explicitly estab-
lished in the previous work. We also retain versioning information
as edge attributes to allow commit-level history-related analyses.
Inter-version facts can go beyond structural differences. Kim et
al. [40,41] proposed to infer rules from systematic structural differ-
ences between versions, which be viewed as logical summarizations
of changes. Le and Pattison [ 44] introduced the Multiversion Inter-
procedural Control Flow Graphs (MVICFG) to integrate and compare
control flow of multiple versions of programs. Albeit their differ-
ences in the representations chosen, the results from these analyses
can all be encoded as the lower-level differential facts and consumed
by other downstream analyses.
Evolution Management. There is a large body of work on ana-
lyzing and understanding software histories. The basic research
goals are retrieving useful information from change histories to
help understand development practices [ 11,50,51,57], localize
bugs [68, 69] and features [48], and support predictions [31, 74].
The problem of classifying changes and identifying change im-
pacts widely present in many evolution management tasks. Brito et
al. [10] proposed a tool, named APIDiff , to identify API breaking
and non-breaking changes between two versions of a Java library.
APIDiff defines rules to classify changes based on their types, e.g.,
the breaking types (e.g., removal) and non-breaking types (e.g.,addition). Yokomori et al. [ 66] studied the evolution of an applica-
tion and its underlying libraries or frameworks, by analyzing the
evolution of their use relationship. They use component ranking
to identify core components of a library, and analyze the impact
of a change based on the use relationship between the changed
component and the core components. Gyori et al. [ 28] evaluated
regression test selection (RTS) opportunities in the Maven Central
ecosystem by changing a library and running RTS techniques on
all its transitive clients. In the case studies presented in Sec. 4.1.2,
we performed similar change impact analysis between the library
changes and the client code with the help of differential facts. Our
analysis can easily be ported to support other tasks with minimal
modifications to the query scripts.
Incremental Datalog-Based Analysis. Incremental code queries
based on Datalog have been used for analysis of evolving software
systems. Hajiyev et al. [ 29] implemented CodeQuest , a source code
querying tool for program understanding, which incrementally
updates its database when program changes occur. They compiled
Datalog to SQL to improve scalability and achieve incremental
updates by only re-compiling changed source code and replac-
ing affected facts. Eichberg et al. [ 19] created a domain-specific
language based on Datalog for continuously checking structural
dependencies between program entities. While we adopted similar
incremental strategies for extracting facts, our approach enables
querying across multiple versions as well as analysis lifting, through
customized storage and query engines for differential facts.
Analysis Lifting. Various attempts on optimizing analysis with
declarative methods has been made. Shahin et al. [ 59] lifted a Dat-
alog engine so that it can analyze all the product variants of a
software product line at once. The way we represent differential
facts enables lifting in a similar style, which is otherwise not possi-
ble without the feature models available in product lines. However,
the effectiveness of lifting on version history has not been studied
before. Visser et al. [ 63] proposed a results caching mechanism to
reuse SMT query results across multiple runs and analyses. Their
work is specific to SMT constraints and does not answer the ques-
tion on how to uniformly represent knowledge about software
development artifacts, especially inter-version facts.
6 CONCLUSION
In this paper, we proposed Diffbase , a simple yet powerful repre-
sentation of pertinent information in evolving software artifacts.
The inter-version changes are treated as first-class objects and facil-
itate effective cross-version fact querying. The resultant differential
factbase allows efficient storage, querying, and manipulation of
facts. We demonstrated the applications of Diffbase in supporting
evolution management tasks such as history slicing and regression
test selection. The experimental results highlight the benefits of our
approach in terms of sharing and reusing of intermediate analysis
results as well as cross-language/platform interoperability.
ACKNOWLEDGMENTS
This research is supported by the Ministry of Education, Singapore,
under its Academic Research Fund Tier 2 (MOE2019-T2-1-040).ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece Xiuheng Wu, Chenguang Zhu, and Yi Li
REFERENCES
[1]2001. Cppx - Open Source C++ Fact Extractor. http://www.swag.uwaterloo.ca/
cppx.
[2] 2010. Javex - Java Fact Extractor. http://www.swag.uwaterloo.ca/javex.
[3]2018. ClangEx â€“ A Fast C/C++ Fact Extractor. https://github.com/bmuscede/
ClangEx.
[4]Lars Ole Andersen. 1994. Program Analysis and Specialization for the C Program-
ming Language . Ph.D. Dissertation. University of Cophenhagen.
[5]Robert S. Arnold. 1996. Software Change Impact Analysis . IEEE Computer Society
Press, Los Alamitos, CA, USA.
[6]BCEL 2015. Apache Commons Byte Code Engineering Library. https://commons.
apache.org/proper/commons-bcel.
[7]Dirk Beyer, Andreas Noack, and Claus Lewerentz. 2003. Simple and Efficient
Relational Querying of Software Structures. In Proceedings of the 10th Working
Conference on Reverse Engineering . 216â€“225.
[8]Philip Bille. 2005. A Survey on Tree Edit Distance and Related Problems. Theo-
retical Computer Science 337, 1-3 (June 2005), 217â€“239.
[9]Martin Bravenboer and Yannis Smaragdakis. 2009. Strictly declarative specifica-
tion of sophisticated points-to analyses. In Proceedings of the 24th ACM SIGPLAN
conference on Object oriented programming systems languages and applications .
243â€“262.
[10] Aline Brito, Laerte Xavier, AndrÃ© C. Hora, and Marco Tulio Valente. 2018. APIDiff:
Detecting API breaking changes. In International Conference on Software Analysis,
Evolution and Reengineering . 507â€“511.
[11] Yuriy Brun, Reid Holmes, Michael D. Ernst, and David Notkin. 2013. Early
Detection of Collaboration Conflicts and Risks. IEEE Transactions on Software
Engineering 39, 10 (Oct. 2013), 1358â€“1375.
[12] Sudarshan S. Chawathe, Anand Rajaraman, Hector Garcia-Molina, and Jennifer
Widom. 1996. Change Detection in Hierarchically Structured Information. In
Proceedings of the 1996 ACM SIGMOD International Conference on Management of
Data . 493â€“504.
[13] Clang 2019. Clang: a C language family frontend for LLVM. https://clang.llvm.
org.
[14] Compress 2018. Apache Commons Compress Library. https://commons.apache.
org/proper/commons-compress.
[15] Configuration 2019. Commons Configuration Library. https://commons.apache.
org/proper/commons-configuration.
[16] Catarina Costa, Jair Figueiredo, Anita Sarma, and Leonardo Murta. 2016. TIP-
Merge: Recommending Developers for Merging Branches. In Proceedings of the
24th ACM SIGSOFT International Symposium on Foundations of Software En-
gineering (Seattle, WA, USA). ACM, New York, NY, USA, 998â€“1002. https:
//doi.org/10.1145/2950290.2983936
[17] CSV 2017. Apache Commons CSV Library. https://commons.apache.org/proper/
commons-csv.
[18] I. J. Davis and M. W. Godfrey. 2010. From Whence It Came: Detecting Source
Code Clones by Analyzing Assembler. In 2010 17th Working Conference on Reverse
Engineering . 242â€“246. https://doi.org/10.1109/WCRE.2010.35
[19] Michael Eichberg, Sven Kloppenburg, Karl Klose, and Mira Mezini. 2008. Defining
and continuous checking of structural program dependencies. In Proceedings of
the 30th international conference on Software engineering . 391â€“400.
[20] Emelie EngstrÃ¶m, Per Runeson, and Mats Skoglund. 2010. A Systematic Review
on Regression Test Selection Techniques. Information and Software Technology
52, 1 (Jan. 2010), 14â€“30. https://doi.org/10.1016/j.infsof.2009.07.001
[21] Jean-RÃ©my Falleri, FlorÃ©al Morandat, Xavier Blanc, Matias Martinez, and Martin
Monperrus. 2014. Fine-Grained and Accurate Source Code Differencing. In
ACM/IEEE International Conference on Automated Software Engineering, ASE â€™14,
Vasteras, Sweden - September 15 - 19, 2014 . 313â€“324. https://doi.org/10.1145/
2642937.2642982
[22] Flume 2019. Flume. https://flume.apache.org.
[23] Beat Fluri and Harald C. Gall. 2006. Classifying Change Types for Qualifying
Change Couplings. In Proceedings of the 14th IEEE International Conference on
Program Comprehension . IEEE, 35â€“45.
[24] Beat Fluri, Michael Wuersch, Martin Pinzger, and Harald Gall. 2007. Change
Distilling: Tree Differencing for Fine-Grained Source Code Change Extraction.
IEEE Transactions on Software Engineering 33, 11 (Nov. 2007), 725â€“743.
[25] GCov 2019. GCov. https://gcc.gnu.org/onlinedocs/gcc/Gcov.html.
[26] Git 2016. Git Version Control System. https://git-scm.com.
[27] Milos Gligoric, Lamyaa Eloussi, and Darko Marinov. 2015. Practical regression test
selection with dynamic file dependencies. In Proceedings of the 2015 International
Symposium on Software Testing and Analysis . 211â€“222.
[28] Alex Gyori, Owolabi Legunsen, Farah Hariri, and Darko Marinov. 2018. Eval-
uating Regression Test Selection Opportunities in a Very Large Open-Source
Ecosystem. In International Symposium on Software Reliability Engineering . 112â€“
122.
[29] Elnar Hajiyev, Mathieu Verbaere, and Oege De Moor. 2006. Codequest: Scalable
source code queries with Datalog. In European Conference on Object-Oriented
Programming . Springer, 2â€“27.[30] Masatomo Hashimoto and Akira Mori. 2008. Diff/TS: A Tool for Fine-Grained
Structural Change Analysis. In Proceedings of the 15th Working Conference on
Reverse Engineering . IEEE, Antwerp, 279â€“288.
[31] Kim Herzig and Andreas Zeller. 2013. The Impact of Tangled Code Changes. In
Proceedings of the 10th Working Conference on Mining Software Repositories (San
Francisco, CA, USA). IEEE Press, Piscataway, NJ, USA, 121â€“130.
[32] Ric Holt. 1997. TA: The Tuple Attribute Language . Technical Report. University
of Waterloo.
[33] Richard C Holt. 1998. Structural Manipulations of Software Architecture Using
Tarski Relational Algebra. In Proceedings Fifth Working Conference on Reverse
Engineering (Cat. No. 98TB100261) . IEEE, 210â€“219.
[34] IO 2017. Apache Commons IO Library. https://commons.apache.org/proper/
commons-io.
[35] Jacoco 2016. JaCoCo Java Code Coverage Library. http://www.eclemma.org/
jacoco.
[36] JIRA 2017. JIRA Software. https://www.atlassian.com/software/jira.
[37] Herbert Jordan, Bernhard Scholz, and Pavle SubotiÄ‡. 2016. SoufflÃ©: On synthesis
of program analyzers. In International Conference on Computer Aided Verification .
Springer, 422â€“430.
[38] RenÃ© Just, Darioush Jalali, and Michael D Ernst. 2014. Defects4J: A database of ex-
isting faults to enable controlled testing studies for Java programs. In Proceedings
of the 2014 International Symposium on Software Testing and Analysis . 437â€“440.
[39] Holger M. Kienle and Hausi A. MÃ¼ller. 2010. Rigi â€“ An Environment for Software
Reverse Engineering, Exploration, Visualization, and Redocumentation. Science
of Computer Programming 75, 4 (April 2010), 247â€“263. https://doi.org/10.1016/j.
scico.2009.10.007
[40] Miryung Kim and David Notkin. 2009. Discovering and Representing Systematic
Code Changes. In Proceedings of the 31st International Conference on Software
Engineering . IEEE Computer Society, Washington, DC, USA, 309â€“319. https:
//doi.org/10.1109/ICSE.2009.5070531
[41] Miryung Kim, David Notkin, Dan Grossman, and Gary Wilson Jr. 2013. Identifying
and Summarizing Systematic Code Changes via Rule Inference. IEEE Transactions
on Software Engineering 39, 1 (Jan. 2013), 45â€“62. https://doi.org/10.1109/TSE.
2012.16
[42] Sunghun Kim, E. James Whitehead, Jr., and Yi Zhang. 2008. Classifying Software
Changes: Clean or Buggy? IEEE Transactions on Software Engineering 34, 2 (March
2008), 181â€“196. https://doi.org/10.1109/TSE.2007.70773
[43] Lang 2018. Apache Commons Lang Library. https://commons.apache.org/proper/
commons-lang.
[44] Wei Le and Shannon D. Pattison. 2014. Patch Verification via Multiversion
Interprocedural Control Flow Graphs. In Proceedings of the 36th International
Conference on Software Engineering (Hyderabad, India). ACM, New York, NY,
USA, 1047â€“1058. https://doi.org/10.1145/2568225.2568304
[45] Owolabi Legunsen, Farah Hariri, August Shi, Yafeng Lu, Lingming Zhang, and
Darko Marinov. 2016. An extensive study of static regression test selection
in modern software evolution. In Proceedings of the 2016 24th ACM SIGSOFT
International Symposium on Foundations of Software Engineering . 583â€“594.
[46] Yi Li, Chenguang Zhu, Julia Rubin, and Marsha Chechik. 2016. Precise Semantic
History Slicing through Dynamic Delta Refinement. In Proceedings of the 31st
IEEE/ACM International Conference on Automated Software Engineering . Singapore,
Singapore, 495â€“506.
[47] Yi Li, Chenguang Zhu, Julia Rubin, and Marsha Chechik. 2017. FHistorian:
Locating Features in Version Histories. In Proceedings of the 21st International
Systems and Software Product Line Conference - Volume A (Sevilla, Spain). ACM,
New York, NY, USA, 49â€“58. https://doi.org/10.1145/3106195.3106216
[48] Yi Li, Chenguang Zhu, Julia Rubin, and Marsha Chechik. 2017. Semantic Slicing
of Software Version Histories. IEEE Transactions on Software Engineering 44, 2
(Feburary 2017), 182â€“201.
[49] Federico Mora, Yi Li, Julia Rubin, and Marsha Chechik. 2018. Client-Specific
Equivalence Checking. In Proceedings of the 33rd ACM/IEEE International Confer-
ence on Automated Software Engineering (Montpellier, France) (ASE 2018) . ACM,
New York, NY, USA, 441â€“451. https://doi.org/10.1145/3238147.3238178
[50] KivanÃ§ MuÅŸlu, Luke Swart, Yuriy Brun, and Michael D. Ernst. 2015. Develop-
ment History Granularity Transformations. In Proceedings of the 30th IEEE/ACM
International Conference on Automated Software Engineering . Lincoln, NE, USA,
697â€“702.
[51] Emerson Murphy-Hill, Chris Parnin, and Andrew P. Black. 2012. How We
Refactor, and How We Know It. IEEE Transactions on Software Engineering 38, 1
(Jan 2012), 5â€“18.
[52] Mvn 2015. Apache Maven Project. https://maven.apache.org.
[53] Net 2017. Apache Commons Net Library. https://commons.apache.org/proper/
commons-net.
[54] Anh Tuan Nguyen, Michael Hilton, Mihai Codoban, Hoan Anh Nguyen, Lily
Mast, Eli Rademacher, Tien N. Nguyen, and Danny Dig. 2016. API Code Rec-
ommendation Using Statistical Learning from Fine-grained Changes. In Proceed-
ings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of
Software Engineering (Seattle, WA, USA). ACM, New York, NY, USA, 511â€“522.
https://doi.org/10.1145/2950290.2950333DIFFBASE: A Differential Factbase for Effective Software Evolution Management ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece
[55] Marek Parfianowicz. 2017. Open Clover. https://openclover.org.
[56] Xiaoxia Ren, Fenil Shah, Frank Tip, Barbara G. Ryder, and Ophelia Chesley. 2004.
Chianti: A Tool for Change Impact Analysis of Java Programs. In Proceedings
of the 19th aAnual ACM SIGPLAN conference on Object-oriented Programming,
Systems, Languages, and Applications . ACM, New York, NY, USA, 432â€“448.
[57] Francisco Servant and James A. Jones. 2011. History slicing. In Proceedings of
the 26th IEEE/ACM International Conference on Automated Software Engineering .
452â€“455.
[58] Francisco Servant and James A. Jones. 2012. WhoseFault: Automatic Developer-
To-Fault Assignment Through Fault Localization. In Proceedings of the 34th Inter-
national Conference on Software Engineering (Zurich, Switzerland). IEEE Press,
Piscataway, NJ, USA, 36â€“46.
[59] Ramy Shahin, Marsha Chechik, and Rick Salay. 2019. Lifting datalog-based
analyses to software product lines. In Proceedings of the 2019 27th ACM Joint
Meeting on European Software Engineering Conference and Symposium on the
Foundations of Software Engineering . 39â€“49.
[60] Ian Sommerville. 2004. Software Engineering (7th Edition) . Pearson Addison
Wesley.
[61] SVN 2016. Apache Subversion (SVN) Version Control System. http://subversion.
apache.org.
[62] Alfred Tarski. 1941. On the Calculus of Relations. The Journal of Symbolic Logic
6, 3 (1941), 73â€“89.
[63] Willem Visser, Jaco Geldenhuys, and Matthew B Dwyer. 2012. Green: reducing,
reusing and recycling constraints in program analysis. In Proceedings of the ACM
SIGSOFT 20th International Symposium on the Foundations of Software Engineering .
1â€“11.
[64] Byron J. Williams and Jeffrey C. Carver. 2010. Characterizing Software Architec-
ture Changes: A Systematic Review. Information and Software Technology 52, 1
(Jan. 2010), 31â€“51. https://doi.org/10.1016/j.infsof.2009.07.002
[65] Jingwei Wu. 2004. JGrok: A query language for reverse engineering. https:
//www.swag.uwaterloo.ca/jgrok.[66] Reishi Yokomori, Harvey P. Siy, Masami Noro, and Katsuro Inoue. 2009. Assessing
the impact of framework changes using component ranking. In International
Conference on Software Maintenance . 189â€“198.
[67] Shin Yoo and Mark Harman. 2012. Regression Testing Minimization, Selection
and Prioritization: A Survey. Software Testing, Verification & Reliability 22, 2
(March 2012), 67â€“120.
[68] Andreas Zeller. 1999. Yesterday, My Program Worked. Today, It Does Not. Why?.
InProceedings of the 7th European Software Engineering Conference Held Jointly
with the 7th ACM SIGSOFT International Symposium on Foundations of Software
Engineering (Toulouse, France). Springer-Verlag, London, UK, UK, 253â€“267.
[69] Andreas Zeller and Ralf Hildebrandt. 2002. Simplifying and Isolating Failure-
Inducing Input. IEEE Transactions on Software Engineering 28, 2 (2002), 183â€“200.
[70] Chenguang Zhu, Owolabi Legunsen, August Shi, and Milos Gligoric. 2019. A
Framework for Checking Regression Test Selection Tools. In 2019 IEEE/ACM 41st
International Conference on Software Engineering . IEEE, 430â€“441.
[71] Chenguang Zhu, Yi Li, Julia Rubin, and Marsha Chechik. 2017. A Dataset for
Dynamic Discovery of Semantic Changes in Version Controlled Software His-
tories. In Proceedings of the 14th International Conference on Mining Software
Repositories (Buenos Aires, Argentina). IEEE Press, Piscataway, NJ, USA, 523â€“526.
https://doi.org/10.1109/MSR.2017.49
[72] Chenguang Zhu, Yi Li, Julia Rubin, and Marsha Chechik. 2020. GenSlice: Gener-
alized Semantic History Slicing. In 2020 IEEE International Conference on Software
Maintenance and Evolution . 81â€“91. https://doi.org/10.1109/ICSME46990.2020.
00018
[73] Thomas Zimmermann, Stephan Diehl, and Andreas Zeller. 2003. How History
Justifies System Architecture (or Not). In Proceedings of the 6th International
Workshop on Principles of Software Evolution . IEEE Computer Society, Washington,
DC, USA, 73â€“83.
[74] Thomas Zimmermann, Peter WeiÃŸgerber, Stephan Diehl, and Andreas Zeller.
2004. Mining Version Histories to Guide Software Changes. In Proceedings of the
26th International Conference on Software Engineering . IEEE Computer Society,
Washington, DC, USA, 563â€“572.