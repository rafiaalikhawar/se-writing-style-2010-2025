A Study on the Prevalence of Human Values
in Software Engineering Publications, 2015 – 2018
Harsha Perera
Monash University
Clayton, Australia
harsha.perera@monash.eduWaqar Hussain
Monash University
Clayton, Australia
waqar.hussain@monash.eduJon Whittle
Monash University
Clayton, Australia
jon.whittle@monash.edu
Arif Nurwidyantoro
Monash University
Clayton, Australia
arif.nurwidyantoro@monash.eduDavoud Mougouei
Monash University
Clayton, Australia
davoud.mougouei@monash.eduRifat Ara Shams
Monash University
Clayton, Australia
rifat.shams@monash.edu
Gillian Oliver
Monash University
Clayton, Australia
gillian.oliver@monash.edu
ABSTRACT
Failure to account for human values in software (e.g., equality 
and fairness) can result in user dissatisfaction and negative socio-
economic impact. Engineering these values in software, however, 
requires technical and methodological support throughout the de-
velopment life cycle. This paper investigates to what extent top 
Software  Engine ering (SE) conferences and journals have included 
research on human values in SE. We investigate the prevalence 
of human values in recent (2015 – 2018) publications in these top
venues. We classify these publications, based on their relevance 
to di erent values, against a  widely used value structure adopted 
fr
om the social sciences. Our results show that: (a) only a small 
proportion of the publications directly consider values, classified 
as directly relevant publications ; (b) for the majority of the values, 
very few or no directly relevant publications were found; and (c) 
the prevalence of directly relevant publications was higher in SE
conferences compared to SE journals. This paper shares these and 
other insights that may motivate future research on human values
in software engineering.
KEYWORDS
Human Values, Software Engineering, Paper Classification
ACM Reference Format:
Harsha Perera, Waqar Hussain, Jon Whittle, Arif Nurwidyantoro, Davoud 
Mougouei, Rifat Ara Shams, and Gillian Oliver. 2020. A Study on the Preva-
lence of Human  Values in Software Engineering Publications, 2015 – 2018. 
In 42nd International Conference on Software Engineering (ICSE ’20), May 
23–29, 2020, Seoul, Republic of Korea. ACM, New York, NY, USA, 12 pages. 
https://doi.org/10.1145/3377811.3380393
ICSE ’20, May  23–29, 2020, Seoul, Republic of Korea
© 2020 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-7121-6/20/05.
https://doi.org/10.1145/3377811.33803931 INTRODUCTION
Ignoringhumanvalueswhileengineeringsoftwaremayresultin
violating those values [ 14,26] and subsequent dissatisfaction of
users.Thismayleadtonegativesocio-economicimpactssuchas
financiallossandreputationaldamage.Arecentexample,which
made news headlines, is the price gouging on airline tickets during
Hurricane Irma [ 30]. After a mandatory evacuation order, the cost
of airline tickets rose six fold, due to supply and demand pricing
systems, thus disadvantaging evacuees. Arguably, this occurred
because of insufficient consideration of valuing compassion during
software designfor thosesuffering ina naturaldisaster.A second
exampleissoftwareusedbyAmazontodeterminefreeshippingby
zip code, which turned out to discriminate against minority neigh-
bourhoods[ 20].TheCOMPASsystem,usedbyUSparoleboardsto
predictre-offenders, hasbeenshownto sufferfromracialbias [ 2].
Indeed, the negative impacts of ignoring values can go as far as
risking human life: the tragic suicide of the British teenager Molly
Russell [4] has been partially attributed to Instagram’s personalisa-
tion algorithms, which flooded Molly’s feed with self harm images.
Following public outrage, Instagram has now banned such images.
Asawarenessabouthumanaspectsofsoftwaregrows,thepublic
isincreasinglydemandingsoftwarethataccountsfortheirvalues.
See,forexample,thoseaccusingFacebookoftakingadvantageof
users’ data to influence the USelections [ 37]. Public demand has
alsomotivatedsoftwarevendorstotakepreemptivemeasurestoavoid violating human values. Google, for instance, has pledgednot to use its AI tools for surveillance conflicting with human
rights [10].
Though such initiatives are promising, we question whether
softwareengineeringresearchandpracticecurrentlypayssufficient
attention to human values. Whilst some values (such as privacy,
security,andaccessibility)arewellembeddedinSEmethods,others
(suchasintegrity,compassion,andsocialjustice)havereceivedless
attention. This may be due to the lack of adequate methodological
and technical support for engineering some kinds of values in
software [26].
4092020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE)
This work is licensed under a Creative Commons Attribution-NonCommercial-
ShareAlike International 4.0 License.
In this paper, we investigate to what extent research in top-tier
SEconferencesandjournalshasconsideredthefullrangeofhuman
values. In particular, we classified publications in the International
Conference on Software Engineering (ICSE), the ACM Joint Eu-
ropeanSoftwareEngineeringConferenceandSymposiumonthe
Foundations of Software Engineering (ESEC/FSE), the IEEE Trans-
actions on Software Engineering (TSE), and the ACM Transactions
on Software Engineering and Methodology (TOSEM) from 2015
to 2018, based on their relevance to different values. Whilst we
acknowledgethat other(sub-)disciplines,such asHCIor Require-
ments Engineering, may contain work on SE and human values,
classifying such venues is out of the scope of this paper and would
warrant further study.
Thispaperinvestigatesthepublicationsfromthosevenuesgener-
allyconsideredtobetopgeneralSEvenues.Forthisreasonspecial-
ist journals such as Empirical Software Engineering (ESE), focused
on empirical SE, was considered out of scope of this study. We
argue that if the top venues do not address human values, then the
SEfieldmaywanttofindwaystolifttheprominenceofresearch
on values in SE. The paper addresses the following three research
questions:
(RQ1)To what extent do publications in top SE venues address
human values in software?
(RQ2)Which values are commonly considered in publications in
top SE venues?
(RQ3)Howarethosepublicationsaddressinghumanvaluesdis-
tributed across venues?
OurapproachwastoreadtheabstractsofpapersinICSE,FSE,
TSEandTOSEMfrom2015-2018(1350papersintotal)andmanu-
ally classify each paper (using multiple raters) as either “directly
relevant”or“notdirectlyrelevant”tooneormorehumanvalues.
Classificationbasedonabstractsisawell-acceptedmethodinthe
SEliterature[ 35,41].Foradefinitionofhumanvalues,weuseda
widelyadoptedvalueframework(Figure1),Schwartz’stheoryof
humanvalues[ 31,34],whichiswell-acceptedinthesocialsciences
and defines 58 human values. A paper was classified as directly
relevantto a particular value if its main research focus is to define,
refine,measure,orvalidateaparticularvalue,orproposeasolution
(e.g., a tool, technique or methodology) to address one or more
human values in software. We use “direct relevance” rather thansimply “relevance” because papers often make broad statements
intheirintroductorytextaboutthebenefitoftheworktosociety
but such claims may not be the main research focus nor have been
validated. “Direct relevance” was assigned only to those papers
withamainfocusonhumanvalues.Multipleraterswereusedto
cometoconsensusontheclassification.Thereisinevitably,how-
ever, some degree of subjectivity in the classification. We therefore
followedrecommendedpracticeinsocialsciencetomitigatethreats
to validity.
Theresultsofourstudyshowedthat:(a)only16%ofpublications
weredirectlyrelevanttohumanvalues;(b)for60%ofhumanvalues,
therewerenodirectlyrelevantpublications;(c)for79%ofhuman
values, the number of directly relevant publications was ≤2; only
21%ofvalueshadonaverage2directlyrelevantpublications,and(d)
88% of directly relevant publications were found in SE conferences
rather than journals.2 BACKGROUND
ChengandFleischmannsummarizesevendifferentdefinitionsof
humanvaluesas“guidingprinciplesofwhatpeopleconsiderim-
portantinlife”[ 9].Humanvalueswithanethicalandmoralimport
such as equality, privacy and fairness have been studied in technol-ogydesignandHCIformorethantwodecades[
16–18].Meanwhile,
the rapid popularization of artificial intelligence (AI) and its poten-
tialnegativeimpactonsocietyhaveraisedtheawarenessofhuman
valuesinAIresearch[ 7,12,28].Consequently,humanvaluesare
getting renewed research focus.
There has been some recent (but isolated) research in SE related
tohumanvaluessuchasvalues-basedrequirementsengineering
[42],Values-FirstSE[ 14]andValues-SensitiveSoftwareDevelop-
ment[1].However,therehasbeennopreviousworkthatmeasures
to what extent human values have been considered in SE research.
Motivatedbythisresearchgap,wefollowaclassificationapproach,
similar to that used in previous SE research to map topic trends[
24,35,40], but with a different purpose, to measure values rele-
vance.Therearenocurrentclassificationschemesforhumanvalues
in SE. Therefore, we take inspiration from the social sciences.
Social scientists have been searching for the most useful way
toconceptualizebasichumanvaluessincethe1950s[ 33].In1973,
Rockeach captured 36 human values and organized them into 2categories [
29]. In 1992, Schwartz introduced his theory of basic
humanvalues(henceforthreferredtoasSchwartz’sValuesStruc-
ture (SVS)) which recognized 58 human values grouped into 10
value categories [ 31,32]. While these two value structures remain
the most well recognized ways of representing values, there areat least ten other value classifications [
9]. In this paper, we use
Schwartz’stheory,whichisthemostcitedandmostwidelyapplied
classification in the social sciences [ 42]. It has also been applied in
numerouscomputerscience[ 5,27]andSEstudies[ 15].Forexample,
SchwartzwasusedtoincorporatevaluesintheSEdecisionmakingprocess[
14],tomeasurethevaluesofsoftwaredevelopers[ 47]and
to predict movie genres for certain personality types [27].
In SVS, Schwartz introduced 10 motivationally-distinct value
categoriesrecognizedacrossmorethan20cultures[ 31].Eachvalue
categoryhasunderlyingdistinctmotivationalgoals(seeTable1),
which relate to one or more of three fundamental needs of human
existence, namely, ‘needs of individuals as biological organisms’,
‘requisites of coordinated social interaction’, and ‘survival and wel-
fare needs of groups’ [31, 34].
Schwartz subdivided each value category into a set of closely
related values [ 31]. These 10 value categories and 58 values are
arranged in a circular motivational structure as shown in Figure
1. Value categories located close to each other are complementary
whereasthosefurtheraparttendtobeintensionwitheachother.
Section 3 discusses how we applied SVS in our classification study.
3 METHODOLOGY
We manually classified publications from SE conferences and jour-
nals,generallyconsideredtobethetopgeneralSEvenues.Theaim
was to assess the prevalence of human values in publications in
these leading venues.
410Figure 1: Schwartz Values Structure [31] (adopted from [8]). Words in black boxes are values categories, each
subdivided into values.
Table 1: Value categories and descriptions [34]
Value Category Description (motivational goals)
Self-direction Independentthoughtandaction–choosing,creating,
exploring
Stimulation Excitement, novelty, and challenge in life
Hedonism Pleasure or sensuous gratification for oneself
Achievement Personal success through demonstrating compe-
tence according to social standards
Power Socialstatusandprestige,controlordominanceover
people and resources
Security Safety, harmony, and stability of society, of relation-
ships, and of self
Conformity Restraintofactions,inclinations,andimpulseslikely
toupsetorharmothersandviolatesocialexpecta-
tions or norms
Tradition Respect, commitment, and acceptance of the cus-
toms/ideas that one’s culture or religion provides
Benevolence Preserving and enhancing the welfare of those with
whom one is in frequent personal contact
Universalism Understanding, appreciation, tolerance, and protec-
tion for the welfare of all people and for nature
Holistic View Humanvaluesconsideredholisticallywithoutfocus-
ing on predetermined valuesLeadingvenueswereidentifiedasICSE,ESEC/FSE,TSE,andthe
TOSEM. These venues are historicallyaccepted in the SE commu-
nityasthetoptwogeneralSEconferencesandjournals;thisisalso
backed up by metrics (e.g., guide2research which rates ICSE and
ESEC/FSE as the top SE conferences based on h-index, and Robert
Feldt’sjournalranking[ 13]whichhasTSEas1st andTOSEMas
3rd–EmpiricalSoftwareEngineeringis2ndbutisamorespecialist
journal and so was not included in our classification).
To classify papers against values, we followed a methodology
similar to that of prior classification work in SE [ 24,35,40]. As
withpriorstudies,ourswasbasedonmanualclassificationofpa-
perabstractsbymultipleraters.Classificationbasedonabstracts,
ratherthanreadingthefullpaper,issub-optimalbutstrikesabal-
ancebetweenaccuracyandtimeneededforthestudy.Allpapers
had multiple raters and inter-rater agreement was measured using
Fleiss’ Kappa [ 23]. In total, we employed seven raters (5M/2F) with
varying levels of experience in SE research, ranging from PhD stu-
dents to professors. Note that this is a relatively high number of
raters compared to similar studies [6, 44].
Whenconductingsuchastudy,thereareanumberofkeyexper-
imentaldesigndecisionsthatneedtobetaken,including:(i)how
to define relevance to human values, given the imperfect and high-
level nature of values definitions in the literature; (ii) how many
raterstoassigntoeachpaper,and(iii)howtoresolvedisagreements
between raters. To make choices about these design decisions, we
411first carried out a pilot study before carrying out the main study.
Both the pilot and main study assumed SVS as the classification
scheme.AllratershadreasonableknowledgeaboutSVSandhad
conducted research on socio-technical aspects in SE.
3.1 Pilot Study
Thepilotstudyhadthreesteps:(i)Paperselectionandallocation
of papersto raters,(ii) Paper classification,and (iii) Calibration of
classification decisions made by different raters. The aim of the
pilotstudywasnottomeasurerelevanceofpaperstovalues;rather,
we had the following objectives:
•TotesttheappropriatenessofSVSastheclassificationscheme
for SE publications
•Todevelopacommonunderstandingregardingthemeaning
of human values in SE contexts
•To collect insights from raters to feed into the experimental
design of the main study
(i) Paper selection and allocation of papers to raters. We randomly
selected49papersfromICSE2018asourpilotstudydataset.These
were equally allocated among the seven raters, with three raters
per paper. Common practice is to assign two raters per paper [ 6,
44];threewereassigned inthepilottogeta betterunderstanding
of how to map papers to values. ICSE was chosen as it has thebroadest coverage of SE research [
6]. We chose the most recent
ICSE proceedings – 2018 at the time of the study.
(ii)Paperclassification. Ratersclassifiedpapers,independently,
based on the title, abstract and keywords which is an approach
usedinsimilarclassificationstudiesinSE[ 6,19,35].Raterswere
instructedtodecideifapaperwas“relevant”or“notrelevant”to
human values: relevance was deliberately left ill-defined as one of
the objectives of the pilot was to influence the definition of this
terminthemainstudy.Forrelevantpapers,raterswereaskedto
classifythepapersintoonevaluecategory(e.g. Power),andthen
into one value within the category such as WealthorAuthority
(see Figure 1). Raters were not mandated to follow the hierarchical
structure of SVS: that is, they could classify a paper into value X
andvaluecategoryYevenifXdidnotbelongtocategoryY.The
raters however, followed a common protocol for this as part of the
calibrationinthepilotstudy.Thiswastogiveusawaytoassess
the appropriateness of the hierarchy in SVS.
(iii)Calibration. Afterclassification,allsevenratersmettodis-
cusstheclassificationdecisions.Themainobjectivewastocalibrate
decisionsandusethistorefinethedefinitionofvaluesrelevance.
The intention was notto decide which rater picked the correct
classification.
Following the pilot study, we made a number of observations
which were fed into experimental design of the main study.
•Observation 1: Raters found that almost every paper could be
classified into a small number of values such as Helpfulness, Wis-
domorInfluence because,ingeneral,allresearchtriestoadvance
knowledge. Thus, an indirect argumentcould almost always be
madewhyapaperisrelevanttohelpfulness(e.g.,apaperontest-ingishelpfultotesters),wisdom(anypaperadvancesknowledge,
thus leading to greater wisdom), or influence (e.g., a paper on
animprovedsoftware processinfluenceshowsoftware isdevel-
oped). This observation illustrated the difficulty of working withvaguelydefinedconceptssuchasvalues,butalsotheimportance
of a better definition of relevance.
Decision1: Itisbeyondthescopeofthispapertofullyandfor-
mally define all the values; hence, it was decided in the main
study to use inter-rater agreement as evidence that a value was
sufficiently understood in the context of a particular paper to
provideconfidenceintheresults.Thedefinitionofrelevancewas,
however,refined forthemain study.Raterswere instructednot
to make indirect arguments why a paper might be relevant toavalue.Instead,inthemainstudy,classificationwasbasedon
“direct relevance” – a paper is defined as directly relevant to a
valueifitsresearchfocusistodefine,refine,measure,orvalidate
a particular value or propose a solution (e.g. a tool, technique or
methodology)aimedataddressingahumanvalue.Thisrevised
definition places emphasis on those papers with a main research
contribution of a particular value, not merely a broad statement
about relevance to a value.
•Observation2: Ratersobservedthatsomepapersaddressedvalues
as a generalconcept rather than considering any specific value.
Anexamplewouldbeapaperthatpresentsamethodologyfor
refiningvaluesintoasoftwarearchitecture.Thesepapersshould
not be classified into any particular value category or value.
Decision 2: To facilitate classification of such papers, we intro-
duced a new value category in the main study, named Holistic
View. A paper classified under Holistic View relates to values
generally without focusing on any specific value (Table 1).
•Observation3: Ratersfoundthatsomepapers,giventheirbroader
coverage of values, should be classified under more than one
value.
Decision3: Toaccommodatesuchpapersinthemainstudy,raters
were allowed to select up to three values. This decision allowed
raters to appropriately link a paper with the number of values it
addressed rather than being obliged to pick just one category as
done in similar studies [6].
•Observation4: Thepilotstudygaveusanopportunitytomeasure
howlongittookraterstoratepapers.Wefoundthat,onaverage,
each rater spent four minutes per abstract. Given the number of
papers in the main study (1350 – see Table 2), assigning three
raters per paper would be infeasible.
Decision 4: Out of necessity, we reduced the number of raters
in the main studyto two. This is consistent withthe number of
raters in similar studies [6, 19, 44].
3.2 Main Study
Similar to the pilot study, the main study also had three phases:
(i) Paper selection and allocation of papers to raters, (ii) Paper
classification and (iii) Disagreement resolution. The final stage was
different to the pilot study because rather than calibrating ratings
toinformexperimentaldesign,ratersindisagreementmettotry
and reach a consensus.
(i) Paper selection and allocation of papers to raters. For the main
study, we selected papers from ICSE, FSE, TSE and TOSEM over
thelastfouryears.Thesearethesamevenuesusedinsimilarpa-
per classification studies [ 6,19]. We selected all papers in TSE and
TOSEM.ForFSE,weusedallpapersfromthemaintrack,andfor
ICSE, we used all papers from the main track, from the Software
412Table 2: Classified publications by venue/track and year
Venue & Track 2015201620172018Total
ICSE–Main Track 8310168153405
ICSE–SEIP 25283035118
ICSE–SEIS 9791136
ESEC/FSE–Main Track123143124122512
TSE 62616131215
TOSEM 2216121464
Total 3243563043661350
EngineeringinPractice(SEIP)track,andfromtheSoftwareEngi-
neering in Society (SEIS) track. SEIP was included to acknowledge
theprominenceofthisindustry-focusedtrackatrecentICSEs.SEIS
wasincludedasithasaspecificfocusonsocialandsocietalaspects
of software engineering. In total, there were 1350 papers published
inthechosenvenuesovertheyears2015–2018(seeTable2).Thisis
ahighsamplesizecomparedtosimilarstudies(e.g.,976inBertolinoetal.[
6]and369inGlass[ 19]).Thepaperswererandomlyallocated
amongthesevenraters,tworatersperpaper.Eachraterreceived
around400paperstoclassify.Wemanuallyextractedlinksforeach
ofthe1350papersfromdigitaldatabases,providedaspreadsheet
with these links as well as values and value categories for raters to
select from.
(ii) Paper classification. Similar to the pilot study, raters were
askedtoclassifypapersonthebasisofthetitle,abstractandkey-
words. However, the main study used a different definition of rele-
vance,assuggestedbythepilotstudy.Raterswereaskedtoclassify
papers as directly relevant or not directly relevant, where the defi-
nitionofdirectrelevanceisasgiveninSection3.1.Papersfounddirectlyrelevanttovalueswerefurtherclassifiedintoacategory
and then to a specific value(s). Throughout the process, raters com-
plied with the decisions made during the calibration step in the
pilot study.
(iii)Disagreementresolution. Giventhesubjectivenatureofthe
classification, raters sometimes disagreed. This could arise at three
levels: (a) relevance level, where raters disagreed on whether a
paper wasdirectly relevantor not; (b)value categorylevel, where
ratersdisagreedonthechoiceofvaluecategory;and(c)valuelevel,
where raters disagreed on the choice of value.
To attempt to resolve these disagreements, raters met to discuss
their views about why the paper in question was classified in a
certainway.Iftheraterscouldnotcometoanagreement,athird
rater was introduced as an arbiter. The arbiter facilitated a second
round of discussion, sharing his or her own views, to facilitate a
consensus.However,ifthedisagreementpersisted,thearbiterdid
not force a decision.
Alignedwithpreviousstudies[ 6],wecalculatedinter-rateragree-
mentusingFleiss’Kappa,onceattemptsatresolvingdisagreements
had taken place. The results of the Kappa measure are interpreted
according to the agreement strengths introduced by Landis andKoch [
23]. We achieved almost perfect agreements on relevance
levelandcategorylevelwithKappavaluesequalto0.92and0.87,
respectively. The agreement of value level was found as substantial
with Kappa value equal to 0.79. The results from the main study
are further discussed in Section 4.4 RESULTS
This section presents the results of the main study described in
Section3.2.Asareminder,weinvestigatethefollowingresearch
questions:
(RQ1)To what extent do publications in top SE venues address
human values in software?
(RQ2)Which values are commonly considered in publications in
top SE venues?
(RQ3)Howarethosepublicationsaddressinghumanvaluesdis-
tributed across venues?
4.1 RQ1: human values prevalence in
publications in top SE venues
Toanswer RQ1,thissectionreportsourfindingsontheextentto
whichhumanvaluesarecoveredintopSEvenues.Figure2demon-
strates the prevalence of human values in classified publications.
Weobserved(Figure2)thatthemajorityofthepublications(82%)
wereclassifiedasnotdirectlyrelevanttoSchwartzvalues,which
constitutes 1105 out of 1350 papers.
16%
(216 papers)82%
(1105 papers)
2%
(29papers)
Directly Relevant
Not Directly Relevant
Undecided
Figure 2: Relevance of SE publications to human values
Table 3 gives an example of a paper classified as not directly
relevant (row 1) – the paper does not directly focus on addressing
any particular Schwartz value. 16% of the publications (216 papers)
werefoundtobedirectlyrelevanttovalues.Theremaining2%of
publications (29 papers)were classified as undecided,because the
raters could not agree on a classification.
To investigate if there were any trends in the prevalence of
values in these SE venues over time, we compared the percentages
ofthedirectlyrelevantpublicationsfrom2015to2018(Figure3):
no significant trends were observed.
4.2 RQ2: Which human values are most
commonly considered?
To answer RQ2, this section reports our findings on the most com-
monlyconsideredhumanvaluesintopSEpublications.Ourresults
showthatoutofthe58SchwartzvaluesinFigure1,theonesthat
413Table 3: Examples of paper classification at different levels (direct relevance, value category, and value)
Classification Extracts from Abstract
Not Directly Rele-
vant...system calls provide us with a window into the development process and design decisions that are made for the Linux kernel
...presents the result of an empirical study of the changes (8,770) that were made to the system calls during the last decade (i.e., from
April 2005 to December 2014) ...As of December 2014, 396 system calls existed in the Linux kernel. They can be categorized into 10
groups (process management, signal processing, and so on) ...[3]
Privacy Network traffic data contains a wealth of information for use in security analysis and application development. Unfortunately, it also
usuallycontainsconfidentialorotherwisesensitiveinformation,...WepresentPrivacy-EnhancedFiltering(PEF),amodel-driven
prototype framework that relies on declarative descriptions of protocols and a set of filter rules ...[11]
Helpful ...However,newcomersfacemanybarrierswhenmakingtheirfirstcontributiontoanOSSproject,leadinginmanycasestodropouts.
Therefore, a major challenge for OSS projects is to provide ways to support newcomers during their first contribution. In this paper,
we propose and evaluate FLOSScoach, a portal created to support newcomers to OSS projects. ...[38]
ProtectingtheEn-
vironment...Thebatterypowerlimitationofmobiledeviceshaspusheddevelopersandresearcherstosearchformethodstoimprovetheenergy
efficiencyofmobileapps.Weproposeamultiobjectiverefactoringapproachtoautomaticallyimprovethearchitectureofmobileapps,
while controlling for energy efficiency ...[25]
Holistic View ...TheaimofthispaperistogivemorevisibilitytotheinterrelationshipbetweenvaluesandSEchoices.Tothisend,wefirstintroduce
the concept of Values-First SE and reflect on its implications for software development. Our contribution to SE is embedding the
principles of values research in the SE decision making process and extracting lessons learned from practice ...[14]
0%10%20%30%40%50%60%70%80%90%100%
2015 2016 2017 2018
Undecided Not Directly Relevant Directly Relevant
Figure 3: Relevant Publications per year
were found in the publication sample of this study, had on average
2 directly relevant publications.
As shown in Figure 5, however, the frequency of the directly
relevantpublicationsvariedsignificantlyfordifferentvalues.Fig-
ure 4 shows the level of attention given to the 58 human values in
SVS. It can be seen that for the majority of the values (79%), the
number of directly relevant publications was ≤2 while for 60%
(35 out of 58) of the values, no directly relevant publications were
found (Figure 4).
Also,forsomevalues,e.g., EnjoyingLife andHonoringofParents
andElders,onlyonedirectlyrelevantpublicationwasfound(Fig-
ure5).ItcanalsobeseeninFigure4thatonlyfor21%(12outof58)
of the values, e.g. Helpful and Privacy, the number of the relevant
publicationswasaboveaverage( >2).Whilebeingcautiouswith
generalizing,thesefindingsarehighlysuggestiveofnegligibleorlimitedattentionpaidbythetopSEresearchvenuestothemajority
of human values.
Intheattempttounderstandwhichvaluesaremostcommonly
considered,wefound(Figure5)thatthenumberofpublicationsrel-
evant toHelpful,Privacy, and Protecting the Environment, were the
highest.ExamplesofsuchpublicationsaregiveninTable3.With38
relevant papers, the value Helpfulwas the most frequently consid-
eredvalue.Publicationsthatcontributedsoftwaretools,techniques
or methodologies developed to enhance the welfare of others were
classified by the raters as directly relevant to the value Helpful.
Thesecondhighestnumberofdirectlyrelevantpublicationswas
observedfor Privacy(Figure5).Thisgroupcontainedpapersthat
directly considered user privacy. Also, Protecting the Environment,
thethirdmostcommonlyfoundvalue,appearedinpublicationsthatdirectlyconsideredsustainabilityandenergyefficiencyinsoftware.
It can be observed from Figure 6 that 80 papers (41% of the
relevantpublications)wereclassifiedasdirectlyrelevantto Security,
which made Securitythe most prevalent value category. This is
not surprising as security is a well-recognized quality aspect ofsoftware, for which there is a great demand from stakeholders.
The second and third most highly prevalent value categories were
Benevolence andUniversalism,whichconstituted20%and16%ofthe
valuespublications,respectively.Ontheotherhand,nopublications
werefoundtoberelevanttothecategories Tradition, Stimulation,
andHedonism. Moreover, 8% of the relevant papers were classified
underthecategory HolisticView,whichdoesnotexistinSVS–this
category was introduced based on the raters’ feedback from the
pilotstudy(Section3.1)toaccountforpublicationsthatconsidered
values in general.
4.3 RQ3: Differences between venues
Toanswer RQ3,thissectionreportsourfindingsonthedistribution
of values-relevant publications across the four venues. Figure 7
demonstrates, for each venue/track, the proportion of the directly
relevant publications in 2015-2018.
414Figure 4: The level of attention given to 58 values in the Schwartz Value Structure
Figure 5: The number of directly relevant publications per
value
Theproportionofdirectlyrelevantpublicationsineachvenue/track.
We observed (Figure 7) that the proportion of directly relevant
publicationsinthetwoSEjournals,namelyTOSEM(about5%)and
TSE (about 11%), is lower than the proportion in the main tracks
ofICSE(about18%)andFSE(about13%),andsignificantlylower
Figure 6: Directly Relevant publications per value category
thanthe proportion intheSEIP(21%) andSEIS(about81%) tracks
ofICSE. Inparticular,theproportionof values-relevant paperswas
significantlyhigherinSEIS. Thisisnotsurprisinggiventhefocus
ofthetrackonthe“ ...technologicaladvancesthatareimpactingthe
economic, political, environmental, social, and technical aspects of
society" [21].
Thedistributionofdirectlyrelevantpublicationsbyvenue/track.
Figure 8 shows the distribution of relevant publications across the
41565 72 24 29 3 23433 324 88 7 61 192
0%10%20%30%40%50%60%70%80%90%100%
FSE-Main
TrackICSE-Main
TrackICSE-SEIP ICSE-SEIS TOSEM TSEPercentage of Papers
Directly Relevant Not Directly Relevant
Figure7:Differencesindirectlyrelevantpublicationsacross
venues/tracks. Labels on the bars denote the number of pa-
pers in each category.
venues/tracks. From all 216 publications that directly considered
values,58%werepublishedindifferenttracksofICSE:maintrack
(33%),SEIS(14%),andSEIP(11%).Thehighestprevalenceofdirectly
relevant publications was in the main tracks of ICSE (33%) and FSE
(30%). As such, it was concluded that about 88% of the publications
that directly considered values were published in the SE confer-
ences: ICSE(58%) andFSE (30%).On theother hand,SE journals,
TSE (11%) and TOSEM (1%), constituted only 12% of the directly
relevant publications (Figure 8).
The distribution of directly relevant publications by values and
venues. Figure 9 shows how the publications directly relevant to
differentvaluesaredistributedacrossdifferentvenues/tracks.We
observed that only 23 out of 58 values in SVS were present. Forsomevalues,publicationswerefoundacrossmostvenues/tracks.
Forexample,publicationsdirectlyrelevantto Helpfulwerefoundin
5outof6venues/tracks.ButforthemajorityofthevaluesinFigure9
(15outof23),thenumberofthevenues/tracksthatpublishedpapers
forthosevaluesdidnotexceed2.Forinstance,publicationsdirectly
relevant to Social justice andNational security were found only
in the main tracks of FSE and ICSE. Also, publications relevanttoEnjoying life, Honoring of the parents and elders , andA world
at peaceappeared only in the main track of ICSE. Publications
for certain values, e.g., Equality, Social justice, and Healthy, were
onlypresentinconferencepapersbutnotinjournals.Wefurther
observedthatforthemajorityofvalues(19of23valuesinFigure9),
relevantpublicationswerefoundinthemaintrackofICSEwhile
publications in TOSEM only considered Privacy.
Thedistributionofdirectlyrelevantpublicationsbyvaluecategories
and venues. Publications relevant to 7 out of 10 value categories
inSVSwerefoundacrossdifferentvenues/tracks(Figure10).We
further found publications relevant to the category Holistic view,
which was introduced based on our pilot study. Publications di-
rectly relevant to all these 8 value categories were found in the
maintracksofFSEandICSE (Figure10). Also,publications directly
relevant to Security were found inall SE venues. Moreover, publi-
cations that directly considered Benevolence andUniversalism were
found across most venues/tracks. Publications directly relevant toFSE-Main Track
30% (65papers)
ICSE-Main Track
33% (72 papers)ICSE-SEIP
11% (24 papers)ICSE-SEIS
14% (29 papers)TOSEM
1% (3 papers)TSE
11% (23 papers)
Figure 8: Directly relevant publications per venue/track
Universalism weremoreprevalentintheSEIStrackofICSE.Pub-
licationsinTOSEMonlyconsideredSecuritybutnotothervalue
categories. It was also interesting to see that, compared to other
venues/tracks,theSEIStrackofICSEcontainedthehighestpropor-
tion of publications relevant to Conformity.
5 DISCUSSION
OurresultsindicatequitestronglythattopSEresearchconferences
and journals pay only limited attention to human values in soft-
ware.Furthermore,ofthosepapersclassifiedasconsideringhuman
values(16%),asignificantproportion(41%)relatedto Security,thus
implying that even where consideration of human values exists, it
often tends to be about security issues.
It would be premature to conclude that SE research ignores
humanvalues.ItmaybethatworkonhumanvaluesinSEexistsin
other SE conferencesand journals, or indeed in otherdisciplinary
areas, such as HCI or Information Systems. Nevertheless, we argue
that the lack of human values in leading general SE venues is
problematicasitsuggestseitherthatSEresearchersarenotpayingsufficientattentiontotheimportanceofhumanvalues,orthatthey
are,butsuchworkisnotappearingintheleadingSEvenues,and
hence, arguably not receiving the most visibility.
Thereare,however,twofurtherconsiderationswhichaffecthow
our results should be interpreted.
Firstly,oneshouldnotexpectallSEpaperstobedirectlyrelevant
to values. For example, a paper describing a new static analysis
techniqueisconcernedchieflywithadvancingthestateoftheartinstatic analysis not with broader questions of human values. Indeed,
one might argue that most SE papers are of this ilk, and hence one
should only aimfor a relatively lowpercentage of values-relevant
papers. Whilst valid, this argument begs the question as to what is
the“target”percentageofvaluespapersthatthecommunityshouldaimfor?Thisisanopenquestion,butwewouldarguethatitshould
be higher than the current number because, as demonstrated inSection 4, 60% of human values were not considered at all. Thismeans that 60% of values generally deemed to be important insociety are ignored in leading SE research. Furthermore, if it is
4160% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100%A world at peaceCapableCreativityEnjoying lifeEqualityHealthyHelpfulHonoring of parents and eldersIndependentInfluentialNational securityPrivacyProtecting the environmentResponsibleSense of belongingSocial justiceSocial orderSocial powerSocial recognitionSuccessfulUnity with natureWealthWisdom
FSE-Main Track ICSE - Main Track ICSE - SEIP ICSE - SEIS TOSEM TSE
Figure 9: The distribution of directly relevant publications by venue/track: directly relevant
publications were found only for 23 out of 58 Schwartz values (Figure 1)
0%10%20%30%40%50%60%70%80%90%100%
FSE-Main Track ICSE - Main Track ICSE - SEIP
ICSE - SEIS TOSEM TSE
Figure10:Publicationsdirectlyrelevanttodifferent
value categories across SE venues/tracks
indeed the case that the reason for a low percentage of values
papers is because most SE papers are deeply technical ones where
broader human values are irrelevant, then this could be seen asa poor reflection of the community – should the community not
strive to be more societally relevant?Secondly, it can be argued that some of the Schwartz values are
simply not relevant to software engineering. For example, it has of-tenbeencommentedthatvalueslikeMatureLoveorObedienceare
outside the scope of SE. We argue the contrary. Software pervades
every aspect of our society and increasingly, with the advent of
artificialintelligence,makesdecisionsonourbehalf.Surely,then,
allvaluesarerelevanttosoftware.Evenvaluesthatmayseemat
firsttobefarfromtraditionalSE,suchasMatureLove,arerelevant
if we are to design software systems that promote or support love.
Ifindeedthatisthegoal,thenitneedstobecapturedinsoftware
requirements, designed for, and tested.
TheSchwartzValuesStructure(SVS)isjustonemodelofhuman
values.Itwasusedinourresearchasitisbyfarthemostwidely
adoptedframeworkacrossanumberofdisciplines.Itisanatural
question to ask, however, whether the Schwartz model is the most
appropriateinaSEcontext.Therearetworeasonstoinvestigate
whether Schwartz could be adapted to SE. Firstly, some of the
nomenclatureusedinSchwartziseitherdifferenttothatusedby
software engineering researchers or is unfamiliar to them. Mature
Love,forexample,couldperhapsberephrasedtospeakmoreeasilytosoftwareengineers(cf.Google’s“Don’tbeevil”).Or,wefoundinourstudythatmanySEpapersnowtalkaboutSustainability,which
417doesnotappeardirectlyintheSchwartzmodel,butmustinstead
be captured as Protecting the Environment orUnity with Nature.
Secondly,wefoundthatthevaluecategory/valuehierarchydidnot
always fit well with SE notions: for example, software engineers
typically think of privacy as coming under a banner of security,
whereas in Schwartz, Privacycomes under Self-Direction. As future
work,therefore,itcouldbeinterestingtolookatadaptingand/or
refining the Schwartz model to SE. Note that as our raters were
not constrained by the Schwartz hierarchy, any concerns about the
hierarchy’s relevance to an SE context do not affect our overall
results. Note also that extreme care needs to be taken if attempting
to adapt Schwartzfor SE. The Schwartz modelhas been validated
fordecadesbymanyresearchersacross20differentcultures;itis
far from a trivial task to create a new values theory.
Tosummarize,webelievethatourresultsindicatethattheSE
communitymightwanttothinkaboutbroadeningitsfocus.Thisisnotmeanttobeajudgementonthecommunitybutaspurtowards
considering more the social aspects of SE, in the same way thatother areas of computer science, such as machine learning, are
adapting their focus.
6 THREATS TO VALIDITY
Inthissectionwediscusslimitationsofthisresearchcategorized
asInternal,ExternalandConstruct validity threats.
Construct Validity :choosingaclassificationschemesuitedfor
thesoftwareengineeringdomainwasoneofthemainchallenges
forthisresearch.IntheabsenceofanSE-specificschemetoclassify
human values, we selected SVS, a well established theory fromsocial sciences to study and explain human values [
42] that has
been successfully applied in SE [ 14,27,46]. SVS was adopted in
this research as an independent classification scheme, instead of
developing our own, to mitigate the risk of introducing researcher
bias. The definition of ‘directly relevant’ was crucial to the clas-sification of selected publications. The definition was therefore,
carefullydevelopedasacriteriatoallowclassificationofresearch
mainlyfocusedonaddressinghumanvaluesbutatthesametime
avoid classifying almost every paper as ‘relevant’ merely on the
premise that ‘all research is helpful or useful’.
Similar toGlass etal. [ 19], lackof mutualexclusion was achal-
lengeforourclassificationscheme.Itwasoftenpossibletoclassifyapaperasrelatingtomorethanoneindividualvalue.Thiswebelieve
was more to do with the ill-defined nature of human values than a
limitation of the chosen classification scheme. Still, the potentialthreat was mitigated by using an iterative process and conduct-ing rater training to better understand and clarify relationships
between values and their categories.
Insomecases,theratersfoundthatcertainpaperswererelatedto
humanvaluesingeneralratherthantoanyparticularvalue.Forcing
such papers into a single value category would have influenced
results. To mitigate this, we added a new Holistic View category to
ourclassificationscheme.ThiscategoryisneededforSEbecause
some papers develop general values methods rather than a specific
value. We classified such papers in Holistic View.
Internal Validity threatsforthisstudyarisefromthecomplex-
ities of categorizing papers into the selected classification scheme.
It is possible that the raters’ own expertise in understanding theschemecategoriesanddefinitionsofvaluesmayhaveinfluenced
paperclassifications.Thisriskwasmitigatedastheclassification
process forced random assignment of each paper to two raters and
incaseofadisagreementanindependentarbiterwasintroduced
tofacilitateagreement.Somedisagreements(2%,seeFigure2)re-
mainedevenafterthearbiter’sintervention.Insuchcaseswedid
not force consensus.
Whileadetailedreviewoftheentirepapers(ratherthanjustthe
abstract, title and keywords) could have provided more accurate
results,weadoptedaproceduresimilartothoseusedinprevious
studies [6,35] published in a top SE conference (ICSE) and a re-
spected SE journal (JSS).
External validity threatsmay arisefrompotentiallimitations
of our choice of publication venues and the block of time periodunder study (i.e., 2015-2018). The chosen venues are widely ac-knowledged as the top-tier venues of SE research; however, weaccept that the results may be different if other more specialist
conferences/journals had been considered.
Generalizabilityofresultsbasedona subsetofpapersisoften
aconcernforempiricalstudies.Inourresearch,thisriskwasmit-
igated by using 1350 papers published in the last 4 years which
canbeconsideredagoodrepresentationoftrendsinSEresearch
as suggested in [ 6]. The findings of this study, however, may be
biased towards ICSE and FSE as they published more papers in the
selected period compared to journals (ICSE 559, FSE 512 vs. TSE
215 and TOSEM 64).
7 RELATED WORK
Classification of papers has been widely adopted in the SE liter-ature [
24,35,40,44,46] as a way of providing insights on trends
anddirectionsinSEresearch.Suchfindings,thoughnotconclusive,
can indicate the general attitude of SE researchers as well as the
priorities in SE research. Paper classification helps to highlight the
gaps and the needs for further research in specific SE domains.Mary Shaw [
35], for instance, analyzed the abstracts of research
papers submitted and accepted to ICSE 2002 to identify differentresearch types, trends in research questions, contribution typesand validation approaches. The author also studied the program
committee discussions regarding the acceptance or rejection of the
papers. Another example is the work by Vessey et al. [ 44] who
categorizedsamplesofSEpaperspublishedfrom1995to1999in
six journals based on topic,method, and approach. Another study
by Williams et al. [ 46] classified ICSE publications from 2015-2017
using a framework developed in psychology and sociology as alens to understand how SE research captures human and social
perspectives.
However, paper classification methods rely on classification
schemes, that can be general or specific depending on the pur-
poseoftheclassification.ToclassifydifferentSEpapers,Montesi
and Lago [ 24] presented a classification approach based on the
call for papers of top-tier SE conferences and journals included
intheJournalCitationReportsandtheinstructionstoauthorsof
relevantjournalsandpublishedworks.Also,Ioannidisetal.[ 22]
categorized the meta-research discipline into five main thematic
fields corresponding to how to conduct, report, verify, correct and
418rewardscience.Therehavealsobeeneffortstodevelopspecificclas-
sificationschemes.Forinstance,Wieringaetal.[ 45]developeda
classificationschemetoidentifypapersthatbelongtoRequirements
Engineering as a subdomainin SE. Sjoberg et al. [36]surveyed SE
papers in nine journals and three conferences from 1993 to 2002
with the aim to characterize controlled experiments in SE by char-
acterizing thetopics ofthe experimentsand theirsubjects, tasks,
and environments.
Moreover, some paper classifications have identified gaps in SE
practice.AnexampleistheworkbyStolandFitzgerald[ 39],where
the authors observed the lack of a holistic view in SE research.
The work contributed a framework for positioning a holistic set
of research strategies and showed its strengths and weaknesses in
relation to various research components. Also, Zelkowitz and Wal-
lace[49]classified,accordingtoa12-modelclassificationscheme,
around 600 SE papers published over a period of three years to
provide insights on the use of experimentation within SE. Theyidentified a gap in SE research with respect to validation and ex-
perimentation.AnotherexampleisanempiricalstudyofSEpapers
performed by Zannier et al. [ 48] to investigate the improvement of
the quantity and quality of empirical evaluations conducted within
ICSE papers over time. The authors compared a random sample of
papersintwoperiods,1975–1990and1991–2005,andfoundthat
the quantity of empirical evaluation has grown, but the soundness
of evaluation has not grown at the same pace.
Lastbutnotleast,somepaperclassificationshaveprovidedin-
sights on SE venues in relation to the papers published in those
venues.AnexampleistheworkbySystaetal.[ 40]thatinvestigated
the turnover of PC compositions and paper publication in six SE
conferences.TheworkwaslaterextendedbyVasilescuetal.[ 43]
byproposingawidercollectionofmetricstoassessthehealthof
11 SE conferences over a period of more than 10 years.
8 CONCLUSIONS AND FUTURE WORK
Repeated incidents of software security and privacy violations con-
tinuetoattractresearchers’attention.Inthispaper,however,we
investigated the prevalence of a broader range of human values
including Trust,EqualityandSocial Justice in software engineering
research. Using the Schwartz Values Structure as our classification
scheme,whichidentifies58humanvalues,weclassified1350pa-
pers recently published (2015–2018) in top-tier SE conferences and
journals. We conclude that only a small proportion of SE research
in leading venues directly considers human values. While Security
andPrivacystand out as the main focus in SE research, a broad
rangeofhumanvaluesremaininadequatelyaddressedinleading
SEvenues.Finally,wefoundthatleadingSEconferencespublish
more values relevant research compared to leading SE journals.
In the future, we want to extend this study using a machine
learningapproach.Manuallylabelleddatafromthisstudywillbe
usedfortrainingmachinelearningalgorithmstoclassifylargersets
ofpublicationswiththeaimtobettervisualizehowSEaddresses
humanvalues.Wealsoplantoutiliseourmanuallylabelleddata
captured from various SE contexts to develop definitions of human
valuesthatarerelativelyeasyforpractitionerstounderstandand
implement.Finally,weplantocarryoutcasestudiesinsoftware
organizations to investigate whether SE research related to human
values has actually made an impact on SE practice.REFERENCES
[1]HuibAldewereld,VirginiaDignum,andYao-huaTan.2015. DesignforValues
in Software Development. Handbook of Ethics, Values, and Technological Design:
Sources, Theory, Values and Application Domains (2015), 831–845.
[2]JuliaAngwin,JeffLarson,LaurenKirchner,andSuryaMattu.2016. MachineBias.
https://www.propublica.org/article/machine-bias-risk-assessments-in-crimin
al-sentencing
[3]Mojtaba Bagherzadeh, Nafiseh Kahani, Cor-Paul Bezemer, Ahmed E Hassan,
JuergenDingel,andJamesRCordy.2018. AnalyzingadecadeofLinuxsystem
calls.Empirical Software Engineering 23, 3 (2018), 1519–1551.
[4]NickBaker.2019. MollyRussell:InstagramBansGraphicSelf-HarmImagesAfter
Suicide of UK Teen. https://www.sbs.com.au/news/molly-russell-instagram-ba
ns-graphic-self-harm-images-after-suicide-of-uk-teen
[5]JuanABarceló,FlorenciaDelCastilloBernal, RicardoDelOlmo,LauraMameli,
FJ Miguel Quesada, David Poza, and Xavier Vilà. 2014. Social Interaction in
Hunter-Gatherer Societies: Simulating the Consequences of Cooperation and
Social Aggregation. Social Science Computer Review 32, 3 (2014), 417–436.
[6]Antonia Bertolino, Antonello Calabrò, Francesca Lonetti, Eda Marchetti, and
BrenoMiranda. 2018. ACategorizationSchemefor SoftwareEngineeringCon-
ferencePapersanditsApplication. JournalofSystemsandSoftware 137(2018),
114–129. https://doi.org/10.1016/j.jss.2017.11.048
[7]Corinne Cath, Sandra Wachter, Brent Mittelstadt, Mariarosaria Taddeo, and
Luciano Floridi.2018. Artificial Intelligenceand the ‘GoodSociety’: the US,EU,and UK Approach. Science and Engineering Ethics 24, 2 (2018), 505–528.
[8]
CommonCause.2011. TheCommonCauseHandbook-AGuidetoValuesand
FramesforCampaigners,CommunityOrganisers,CivilServants,Fundraisers,
Educators, Social Entrepreneurs, Activists, Funders, Politicians, and everyone in
between. Public Interest Research Centre, Machynlleth, Wales (2011).
[9]An-ShouChengandKennethR.Fleischmann.2010. DevelopingaMeta-InventoryofHumanValues. ProceedingsoftheAmericanSocietyforInformationScienceand
Technology 47, 1, 1–10. https://doi.org/10.1002/meet.14504701232
[10]PareshDave.2018. GoogleBarsUsesofitsArtificialIntelligenceTechinWeapons.
https://www.reuters.com/article/us-alphabet-ai/google-bars-uses-of-its-artif
icial-intelligence-tech-in-weapons-idUSKCN1J32M7
[11]Roel van Dijk, Christophe Creeten, Jeroen van der Ham, and Jeroen van denBos. 2017. Model-driven Software Engineering in Practice: Privacy-EnhancedFiltering of Network Traffic. In Proceedings of the 2017 11th Joint Meeting on
Foundations of Software Engineering. ACM, 860–865.
[12]Amitai Etzioni and Oren Etzioni. 2017. Incorporating Ethics into Artificial Intel-
ligence.The Journal of Ethics 21, 4 (2017), 403–418.
[13]Robert Feldt. 2016. ISI SE Journals (Ranked). http://www.robertfeldt.net/advice
/sevenues/
[14]Maria Angela Ferrario, Will Simm, Stephen Forshaw, Adrian Gradinar, Mar-cia Tavares Smith, and Ian Smith. 2016. Values-first SE: Research Principlesin Practice. In Companion Proceedings of the 38th International Conference on
Software Engineering (ICSE Companion 2016). ACM, 553–562.
[15]Maria Angela Ferrario, Will Simm, Peter Newman, Stephen Forshaw, and Jon
Whittle. 2014. Software Engineering for ‘Social Good’: Integrating Action Re-
search, Participatory Design, and Agile Development. In Companion Proceedings
of the 36th International Conference on Software Engineering (ICSE Companion
2014). ACM, New York, NY, USA, 520–523. https://doi.org/10.1145/2591062.2591
121
[16]MaryFlanagan,DanielC.Howe,andHelenNissenbaum.2005. ValuesatPlay:
DesignTradeoffsinSocially-OrientedGameDesign.In ProceedingsoftheSIGCHI
Conference on Human Factors in Computing Systems. ACM, 751–760.
[17] Batya Friedman. 1996. Value-sensitive Design. Interactions 3, 6 (1996), 16–23.
[18]BatyaFriedmanandPeterH. KahnJr.2007. HumanValues,Ethics,andDesign.
InThe Human-computer Interaction Handbook. CRC Press, 1223–1248.
[19]Robert L. Glass, Iris Vessey, and Venkataraman Ramesh. 2002. Research in
SoftwareEngineering:AnAnalysisoftheLiterature. InformationandSoftware
technology 44, 8 (2002), 491–506.
[20]PrestonGralla.2016. AmazonPrimeandtheRacistAlgorithms. https://www.co
mputerworld.com.au/article/599661/amazon-prime-racist-algorithms
[21]ICSE. 2018. ICSE - Software Engineering in Society. https://www.icse2018.org/t
rack/icse-2018-Software-Engineering-in-Society
[22] John P.A. Ioannidis, Daniele Fanelli, Debbie Drake Dunne, and Steven N. Good-
man.2015. Meta-Research:EvaluationandImprovementofResearchMethods
and Practices. PLoS Biology 13, 10 (2015).
[23]J. Richard Landis and Gary G. Koch. 1977. The Measurement of Observer Agree-
ment for Categorical Data. Biometrics (1977), 159–174.
[24]MichelaMontesiandPatriciaLago.2008. SoftwareEngineeringArticleTypes:
An Analysis of the Literature. Journal of Systems and Software 81, 10 (2008),
1694–1714.
[25]RodrigoMorales,RubénSaborido,FoutseKhomh,FranciscoChicano,andGiu-
lianoAntoniol.2018. Earmo:AnEnergy-AwareRefactoringApproachforMobile
Apps.IEEE Transactions on Software Engineering 44, 12 (2018), 1176–1206.
419[26]Davoud Mougouei, Harsha Perera, Waqar Hussain, Rifat Shams, and Jon Whittle.
2018. Operationalizing Human Values in Software: A Research Roadmap. In
Proceedingsofthe201826thACMJointMeetingonEuropeanSoftwareEngineering
ConferenceandSymposiumontheFoundationsofSoftwareEngineering-ESEC/FSE
2018. 780–784. https://doi.org/10.1145/3236024.3264843
[27]Md. Saddam Hossain Mukta, Euna Mehnaz Khan, Mohammed Eunus Ali, and
JalalMahmud.2017. PredictingMovieGenrePreferencesfromPersonalityand
Values of Social Media Users. In Eleventh International AAAI Conference on Web
and Social Media.
[28]MarkO.RiedlandBrentHarrison.2016. UsingStoriestoTeachHumanValues
toArtificialAgents.In WorkshopsattheThirtiethAAAIConferenceonArtificial
Intelligence.
[29] Milton Rokeach. 1973. The Nature of Human Values. Free Press.
[30]JustinSablich.2017. ‘PriceGouging’andHurricaneIrma:WhatHappenedand
What to Do. https://www.nytimes.com/2017/09/17/travel/price-gouging-hurric
ane-irma-airlines.html
[31]Shalom H. Schwartz. 1992. Universals in the Content and Structure of Values:
Theoretical Advances and Empirical Tests in 20 Countries. In Advances in Exper-
imental Social Psychology. Vol. 25. Elsevier, 1–65.
[32]Shalom H.Schwartz.2005. Basic HumanValues: TheirContent andStructure
Across Countries. Valores e Comportamento nas Organizações (2005), 21–55.
[33]Shalom H Schwartz. 2006. Basic Human Values: An Overview. Recuperado de
http://www. yourmorals. org/schwartz (2006).
[34]ShalomH.Schwartz.2012. AnOverviewoftheSchwartzTheoryofBasicValues.Online Readings in Psychology and Culture 2, 1 (2012). https://doi.org/10.9707/23
07-0919.1116
[35]Mary Shaw. 2003. Writing Good Software Engineering Research Papers. InProceedings of the 25th International Conference on Software Engineering. IEEE,
726–736.
[36]Dag I.K. Sjøberg, Jo Erskine Hannay, Ove Hansen, Vigdis By Kampenes, Amela
Karahasanovic,N.-K.Liborg,andAnetteC.Rekdal.2005. ASurveyofControlledExperimentsinSoftwareEngineering. IEEETransactionsonSoftwareEngineering
31, 9 (2005), 733–753.
[37]David Smith. 2018. Zuckerberg Put on Back Foot as House Grills Facebook CEO
over User Tracking. https://www.theguardian.com/technology/2018/apr/11/zuc
kerberg-hearing-facebook-tracking-questions-house-back-foot
[38]IgorSteinmacher,TayanaUchoaConte,ChristophTreude,andMarcoAurélio
Gerosa. 2016. Overcoming Open Source Project Entry Barriers with a Portal
forNewcomers.In Proceedingsofthe38thInternationalConferenceonSoftware
Engineering (ICSE ’16). ACM, New York, NY, USA, 273–284. https://doi.org/10.1
145/2884781.2884806
[39]Klaas-Jan Stol and Brian Fitzgerald. 2015. A Holistic Overview of Software Engi-
neeringResearchStrategies.In Proceedingsof theThird InternationalWorkshop
on Conducting Empirical Studies in Industry. IEEE Press, 47–54.
[40]Tarja Systä, Maarit Harsu, and Kai Koskimies. 2012. Inbreeding in Software
Engineering Conferences. http://citeseerx.ist.psu.edu/viewdoc/summary?doi=1
0.1.1.361.7040
[41]Christopher Theisen, Marcel Dunaiski, Laurie Williams, and Willem Visser. 2017.
WritingGoodSoftwareEngineeringResearchPapers:Revisited.In Proceedingsof
the 39th International Conference on Software Engineering Companion . IEEE Press,
402–402.
[42]Sarah Thew and Alistair Sutcliffe. 2018. Value-based Requirements Engineering:
Method and Experience. Requirements Engineering 23, 4 (2018), 443–464.
[43]BogdanVasilescu,AlexanderSerebrenik,TomMens,MarkG.J.vandenBrand,
and Ekaterina Pek. 2014. How Healthy are Software Engineering Conferences?
Science of Computer Programming 89 (2014), 251–272.
[44]Iris Vessey, Venkataraman Ramesh, and Robert L Glass. 2002. Research in In-formation Systems: An Empirical Study of Diversity in the Discipline and its
Journals. Journal of Management Information Systems 19, 2 (2002), 129–174.
[45]RoelWieringa,NeilMaiden,NancyMead,andColetteRolland.2006. Require-
ments Engineering Paper Classification and Evaluation Criteria: A Proposal and
a Discussion. Requirements Engineering 11, 1 (2006), 102–107.
[46]CourtneyWilliams,Margaret-AnneStorey,NeilAErnst,AlexeyZagalsky,and
EiriniKalliamvakou.2019. MethodologyMatters:HowWeStudySocio-Technical
Aspects in Software Engineering. arXiv preprint arXiv:1905.12841 (2019).
[47]Emily Winter, Steve Forshaw, and Maria Angela Ferrario. 2018. MeasuringHuman Values in Software Engineering. In Proceedings of the 12th ACM/IEEE
International Symposium on Empirical Software Engineering and Measurement .
ACM, 48.
[48]Carmen Zannier, Grigori Melnik, and Frank Maurer. 2006. On the Success of
EmpiricalStudiesintheInternationalConferenceonSoftwareEngineering.In
Proceedingsofthe28thInternationalConferenceonSoftwareEngineering.ACM,
341–350.
[49]Marvin V. Zelkowitz and Dolores Wallace. 1997. Experimental Validation in
SoftwareEngineering. InformationandSoftwareTechnology 39,11(1997),735–
743.
420