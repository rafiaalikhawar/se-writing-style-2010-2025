Supporting Automated Vulnerability Analysis Using 
Formalized Vulnerability Signatures  
Mohamed Almorsy, John Grundy , and Amani S. Ibrahim  
Computer Science & Software Engineering, Faculty of Information & Communication Technologies  
Swinburne University of Technology, Hawthorn, Victoria, Australia  
[malmorsy, jgrundy, aibrahim]@swin.edu.au  
 
ABSTRACT  
Adopting  publicly accessible platforms such as cloud computing  
model to host IT systems has become a leading trend . Although 
this helps to minimize cost and inc rease availability and 
reachability of applications, it has serious implications on 
applications’  security. H ackers can easily exploit vulnerabilities in 
such publically accessible services. In addition to, 75% of the total 
reported application vulnerabili ties are web application specific . 
Identifying such known  vulnerabilities as well as newly discovered 
vulnerabilities is a key challenging security requirement. However, 
existing vulnerability analysis tools cover no more than 47% of the 
known vulnerabilit ies. We introduce a new solution that support s 
automated vulnerability analysis using formalized vulnerability 
signatures . Instead of depending on formal methods to locate 
vulnerability instances where analyzers have to be developed to 
locate specific vuln erabilities , our approach incorporates a formal 
vulnerability signature described using OCL. Using this formal 
signature, we perform  program analysis of the target system  to 
locate signature matches (i.e. signs of possibl e vulnerabilities). A 
newly –discove red vulnerability can be easily identified in a target 
program provided  that a formal signature  for it  exists . We have 
developed a prototype static vulnerability analysis tool  based on 
our for malized vulnerability signatures specification approach . We 
have  validated our approach in capturing signatures of the OWSAP 
Top10 vulnerabilities and applied these signatures in analyzing a 
set of seven  benchmark applications.   
Categories and Subject Descriptors  
F.3.1 [ Specifying and Verifying and Reasoning about 
Programs ]: Semantics of Programming Languages  - Program 
analysis ; K.6.5 [Security and Protection] : Verification.  
General Terms  
Algorithms, Design, Security, Languages, Verification  
Keywords  
Software security; Vulnerability analysis; Formal vulnerability 
speci fication; Common weaknesses enumeration  (CWE)  
1. INTRODUCTION  
New computational paradigms such as Cloud Computing and 
Service -Oriented Architectures (SOA) depend on outsourcing IT 
systems for hosting on third -party platforms outside of the 
enterprise network  perimeter (usually on the internet).  
 This increases the possibility  of hackers attacking and exploiting 
vulnerabilities in such applications.  In addition,  the number of 
newly discovered vulnerabilities is increasing rapidly. Delays in 
discovering and m itigating such vulnerabilities increase the 
probability of successful application attacks and security breach.  
Web applications have become the prominent application delivery 
model used in such platforms as they do not require client 
deployment or configur ation, and can be centrally updated and 
managed. However, web application vulnerabilities continue to 
make up the largest percentage of the total reported vulnerabilities 
in software applications. Web applications vulnerabilities 
constitute 75% on average of the total reported vulnerabilities over 
the last three years. Of these reported vulnerabilities, well -known 
vulnerabilities such as  Cross  site scripting  (XSS) represents 28%, 
while SQL Injection (SQLI) vulnerabilities represent 20%. 
Reported vulnerabili ties are usually recorded in commonly 
available vulnerability databases such as NVD  or CVEdetails .com . 
Vulnerabilities/weaknesses definitions are maintained in the 
Common Weaknesses Enumeration (CWE) database . This 
database is used as a reference framework  by application 
developers, deployment engineers and sec urity engineers to help 
identifying  possible weaknesses to attack in software applications.  
However, a key problem with CWE is that recorded vulnerabilities 
are almost specified informally. Thus, eac h security vendor 
develop s their security analysis tools  based on their own 
understa nding of such vulnerabilities.  
Commercial vulnerability scanners such as AppScan, Web inspect, 
Cenzic, McAfee focus on black -box vulnerability analysis to avoid 
being limit ed to specific programming languages or platforms. 
However, n one of these scanners cover all known vulnerability 
types  [2]. Moreover, they are limited in discovering stored forms 
of XSS and SQLI  vulnerability. To achieve good results with 
vulnerability analysis, multiple scanners should be applied [1].  
Existing research efforts [4; 5; 9; 10; 12; 15] focus on specific 
vulnerability types. Most  focus on SQLI [7; 11], XSS [11; 18; 19], 
or input sanitization [1; 8]. These efforts use static analysis with 
many variations [6; 10], dynamic analysis [11], or hybrid of static 
and dynamic techniques [16; 21]. However, they focus on specific 
vulnerabilities  only. Thus , new vulnerabilities cannot be 
incorporated for checking  unless we have new algorithms .  
A key problem with both industrial and academic effort s is that 
they are not comprehensive enough to co ver known  vulnerabilities 
or extensible  to incorporate  new vulnerabilities. Many tools  
depend on their own encoded representations of vulnerabilities, 
which are suitable for their own analysis approaches. From our 
investigation in these efforts, we reached  a conclusion that the key 
problem really lies in the vulnerability definitions and not in 
introducing new analysis techniques  (most of the existing 
approaches  use similar techniques with various  combinations) . 
Moreover, t he various existing vulnerabilitie s databases, while 
useful, are not directly utilized by vulnerability analysis tools due 
to their informality ; however, we figured out that different security   Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ASE’12, September 3–7, 2012, Essen, Germany
Copyright 2012 ACM 978-1-4503-1204-2/12/09 ...$15.00
100
analysis tasks including vulnerability analysis, attack analysis, and 
threat analysis can be faci litated if we have a formal vulnerability 
definition. Our analysis of the vulnerability analysis domain leads 
us to following research questions : 
- What details do we need to capture to fully describe a given 
vulnerability?  
- How can we formalize  the signature s of possible security 
vulnerabilities ? 
- How can we effectively use such formal vulnerability 
specifications in automating the vulnerability analysis process?  
In this paper, we introduce a new, comprehensive  vulnerability 
specification schema. This schema c aptures formal rich details  of a 
given application vulnerability /weakness including categor ies, 
preconditions, consequences, signature s, etc. A key entry that we 
focus on in this schema is the vulnerability signature. This 
signature specifies a set of inva riants , when matched;  it means that 
the given vulnerability exists. We adopt Object Constraint 
Language (OCL ) in capturing such signatures . OCL  is a 
declarative and formal language  [3] based on first order logic and 
set theory. Vulnerability  signatures are validated against a 
comprehensive system description model that covers most  program 
entities including classes, methods, statements, inputs, sources, 
outputs, targets, etc. Furthermore, it helps in developing more 
abstract signature s not coupled with specific programming 
langu age or platform .  
As an initial step in validating our vulnerability schema and 
signature specification approach , we have developed an OCL -
based static application Vulnerability Analysis tool . This tool uses 
a new static vulnerability detection approach th at performs 
program analysis looking for matches for vulnerability signatures , 
defined in OCL, in a given program source code . Then, it produces  
an overall vulnerability assessment report for the target 
application . This vulnerability analyzer will be exte nded to support 
dynamic analysis as well using  vulnerability analysis workflow 
engine. A Key difference between  our static vulnerability analysis 
tool and existing tools is that it uses our formal vulnerability 
specifications to detect source code vulnerab ilities , while working 
on an abstract system representation. Moreover, it analyzes 
programs for any (new) vulnerability that has defined signature(s). 
This is compared to existing efforts that have specific (built -in) 
algorithms to discover certain vulnera bility types  only. We have 
developed a prototype tool supporting  our approach and evaluated 
it in capturing the well -known TOP10 vulnerabilities reported by 
OWSAP. We have  validated our toolset in locating these 
vulnerabilities in  a set of open source web applications.  
In section 2, we analyze the existing secu rity vulnerabilities and 
map this analysis on the Top10  OWSAP  vulnerabilities. Section 3 
describes our vulnerability definition schema, the vulnerability 
signature specification, and our OCL -based sta tic vulnerability 
analysis tool. Section 4  describes our prototype implementation 
details. In section 5, we discuss our experimental evaluation and 
results. Section 6 discusses the implications of our work and  key 
directions for  further research.  Section 7  reviews related work.  
2. BACKGROUND  
To understand the root causes of security vulnerabilities we 
analyzed different system structures, components, and deployment 
models.  We applied this analysis on the Top10 vulnerabilities 
reported by OWSAP.  We summarize ou r conclusions as follows:                                                                                                   
2.1 Analysis of Security Vulnerabilities  
A given software system,  whether  desktop, web, or even 
embedded  is based on a hosting service – e.g. web server, operating system, virtual server, etc. (Figure 1). A hosting service 
provides a set of APIs that the hosted system can use to read inputs 
from possible input sources (users, files, memory, database, etc.) 
or write outputs to possible outp ut targets. Any vulnerability in the 
hosting service implies that an attacker can control inputs and/or 
outputs of the target system. The hosting media is a place where 
the hosted system runs – e.g. a process in case of web server, or 
memory in case of OS.   If the hosting media breache d, it may be 
used to control the hosted system inputs, output s, or even 
processing (overrid ing kernel data using buffer overflow) . 
However, t hese entities are out of the software system control.  
Function Storage Channel
Component
Hosting Media
Hosting ServiceE
P/S/T
X
(a) (b)
 
Figure 1 . An overview of the host -system -component relations  
Any target system is composed of a set of components. These 
components may be subsystems, composite components, or simple 
components. System components may be hosted on the same 
hosting service in stance or different instances (different servers). 
In the latter  case, they have to communicate through 
communication channels, which may be unsecure (an attacker may 
eavesdrop, or intercept messages). A system component may be an 
active component , a compo nent that can take actions or perform 
operations such as system functions. Active components are able 
to secure themselves and their processed data – e.g. authenticating 
users, authorizing users, encrypting data , etc. Or alternatively, a 
passive component , a component that cannot take actions to 
change data it maintains, such as storage components 
(databases/files) or transmission components (communication 
channels). Passive components cannot secure themselves e.g. a file 
or table cannot enforce security ac cess on its contents by itself. 
They depend  on other components, such as the hosting service 
(OS, DBMS ), or active system component s to manage/secure such 
components. This is a big open issue  in data security area - e.g. 
data leak age protection - where confidentiality of data moving  
between different applications with different security levels may 
be threaten ed. Both active and passive components may be 
breached by the hosting service e.g. read data in memory, files, or 
on communication channel s.  
Each comp onent, regardless of its type, has a set of entry points 
(E) and set of exit, output points (X), and is used in processing (P ), 
as a storage ( S), or as a communication channel ( T). These entry 
and exit points can be compromised by an attacker who has contr ol 
on the hosting service to read/write/modify/delete the data. Usually 
the number of entry points and exit points – the “attack surface”  -
is used as a security metric when assessing systems  security  [14]. 
Furthermore, an active component may have vulnerabilities related 
to inputs  (input validation - input coming from a user passin g by 
the hosting service), outputs  (output validation and exceptions – 
outputs may depend on malicious/modified inputs  or passed 
through a vulnerable hosting service), or processing  (logical errors 
– e.g. race conditions , malicious data corruption, service  
overloading).  We use this analysis in categorizing vulnerabilities 
according to the source of vulnerability , such as input validation, 
output validation, processing, and hosting service  vulnerabilities . 
This helps in deciding which types of vulnerabilitie s can be 101identified by static analysis, dynamic analysis, etc.  Moreover, it 
helps in deciding the mitigation actions that can be applied to 
block such vulnerabilities.  
2.2 OWSAP Top10 Security Vulnerabilities  
 Before we discuss how we formalize software system  
vulnerability definitions , we give an overview of the OWSAP 
Top10 web application vulnerabilities . OWSAP (Open Web 
Security Application Project) is a community effort to define and 
share knowledge about web application security approaches.  We 
discuss thes e Top 10 vulnerabilities and signature s we deduce from 
the vulnerabilities recorded in NVD and CWE.  These signatures 
are used by our vulnerability analysis  tool; however, they can be 
further revised by experts to get more accurate results.  
Injection Flaw s: This type of vulnerabilit ies includes  several well -
known attacks intended to compromise application inputs in order 
to gain control or modify data, such  as SQLI, OS command 
injection, LDAP query injection, and XPath query injection. All 
arise from input validation problems . “All external inputs are 
untrusted” is a well -known security principal  that should be realize 
in securing systems . These vulnerabilities occur  whenever a 
system trusts an input from the user – first order injection  – or 
from a reposito ry – stored or second order injection  – and uses it 
to build dynamic queries that run  OS or database  commands  
without sufficient  input sanitization or validation. An attacker can 
use this type of vulnerabilities  to execute malicious commands or 
gain privil eged access  to the system  under attack . Fig ure 2 shows  
code vulnerable to SQLI. For example, a password argume nt of the 
form “’ OR (1=1) OR ‘’=‘ ” allow s access to any specified 
username e.g. ‘admin’ or ‘root’. The signature of these 
vulnerabilities is a dynamic query statement that uses external 
inputs without  proper  sanitization.  
 
public  bool  LogUser( string  username, string  password) {  
  string  query = “SELECT username FROM Users WHERE       
              UserID =‘” username “ ‘ AND Password = ‘” +  passwo rd + “’”;   
Figure 2 . A code snippet vulnerable to SQLI a ttack  
Cross -Site Scripting Flaw s: This is a two -step vulnerability. First, 
an attacker uses the application to store malicious data. When ever 
a victim  sends a request  to resource X, the web server responds 
with data containing “malicious code” without being encoded . This 
malicious code executes on the victim browser causing disclosure 
of her confidential information to the attacker. This vulnerability 
type may be from stored data (e.g. from  a database ) or reflected 
(from user input). This is very common attack in applications that 
use user i nputs for search or discussion s. The signature of these 
vulnerabilities is to call output functions using external  or stored  
inputs without sanitization or encoding . 
Broken Authentication and Session Management Flaw s: This is 
a common problem with security authentication. It includes attacks 
such as : authentication bypassing via external inputs (depend  on  
external input to bypass authenticating the  current requester ); 
authentication checking  not included in critical functions;  using 
hard-coded credentials ; using an easy to guess  password ; or 
session timeouts  not set  or checked . This enables unauthenticated 
users to maliciously access and use system resources.   
Figure  3 shows a code  snippet  vulnerable to improper 
authentication attack, where a user can modify their cookie  to 
bypass the authentication check.  The signature of these 
vulnerabilities is that every publicly accessible function should not 
trust external inpu ts to bypass (by conditional statement) triggering 
the authentication function .  
if( Request.Cookies["Loggedin"] != true ) { 
    if(  !AuthenticateUser(Request.Params["username"],      
                                            Request.Params["password"] ) ) 
              throw  new  Exception("Invalid user");  
} 
DoAdministrativeTask (); 
Figure 3 . A code snippet  vulnerable to authentication Bypass  
Insecure Direct Object Reference Flaw s: authenticated users can 
send malicious in puts to access unauthorized data . Figure 4 shows 
an example where attacker sends  custID  = XYZ  instead of custID = 
ABC . This enables the attacker to access other customers ’ data. 
The signature of these vulnerabilities is that user inputs are not 
authorized before used in business function s. 
 
if( !AuthenticateUser( Request.Params["username"],  
                             Request.Params["password"] ) )  
          throw  new  Exception("Invalid user");  
updateCustomerBalance(Request.QueryString["custID"], nBalance);  
Figure 4 . A code snippet vulnerable to improper authz  
Cross -Site Request Forgery (CSRF) Flaw s: an attacker deceives 
an authorized  user by sending a forged request to the  user’s 
application to perform  malicious action s. This attack requires the 
victim to have a valid session or cookie  with the application 
(already authorized). The signature of these vulnerabilities is that 
requests’ origins are not validated or that responses are usually 
predictable or have  fixed URL format. It is usually difficult to 
identify CSRF using static analysi s techniques because it is  usually  
managed by the web server . 
Security Misconfiguration Flaw s: the system is not securely 
configured. This includes exposing information through 
exceptions ; system executing with higher privileges than required ; 
system files  are accessible to unauthenticated users ; or resources 
have misconfigured permissions. Some of these vulnerabilities can 
be discovered from the exception handlers whether they expose 
system details  or not. Others need to be ex amined by application 
response s for unauthorized actions  using dynamic analysis . 
Unvalidated Redirect  and Forward Flaw s: the application 
redirects requests to a target URL that is concatenated  from user 
inputs “ Response.Redirect(userInput)”. This type of vulnerability  
is similar to the  injection vulnerabilities  where  web redirect  
functions use external inputs to build the redirect URL.  
Failure to Restrict URL Access Flaw s: an application does not 
perform access control on resources or URLs. These vulnerabilities 
can be easily examined b y checking webpage methods for 
authorization function calls. Dynamic analysis is required to check 
application responses for unauthorized URLs.  
Insufficient Transport Layer Protection Flaw s: sensitive data 
including credentials and customer data are transm itted in plain 
text. The signature of these vulnerabilities is that output data are 
transmitted without passing by encryption functions. Dynamic 
analysis is required to examine application responses (if the 
protection is done on the transport layer).  From this analysis, we 
deduce d two points: (i) Top10 vulnerabilities reflect categorization 
we introduce in Section 2.2 – i.e. input validation such as SQLI, 
URL redirection, CSRF; output  validation such as XSS, 
information exposure; and hosting service such as  security 
misconfiguration and insufficient transport layer protection; and 
(ii) many  of these Top10 vulnerabilities can be discovered using 
static source code analysis (vulnerabilities related to the program 
itself) , while  other require dynamic analysis ( vulnerabilities related 
to the hosting service or configurations).  1022.3 Why Formal ized Vulnerability Definition?  
The s ecurity analysis for a given system includes different tasks 
that are usually performed at different stages of the system 
implementation. Threa t analysis  is conducted at early stages of the 
system development usually during the system design phase. Here 
the software development team work together to identify possible 
problems that may arise from using specific platforms, 
architectures, languages,  and the expected deployment model. A 
formal vulnerability definition, as shown in Figure  5, facilitates  
identifying possible weaknesses in a given platform or language. 
Vulnerability analysis  is applied during system development or 
after development has b een completed. It targets identifying 
security -compromising  errors in the system implementation. A 
formal vulnerability definition helps in automating vulnerability 
analysis as we will show later  in this paper.  Attack  analysis  is 
applied after the system h as been deployed or when  a detailed 
deployment model becomes available. It focuses on identifying 
possible attack vectors on system resources given the networked 
system. A formal definition helps identifying preconditions and 
consequences for each  vulnerab ility instance found in the program.  
Threat AnalysisVulnerability Definition Vulnerability Analysis
Attack Analysis
 
Figure 5. Vulnerability definition and security analysis tasks  
3. OUR APPROACH  
We base our security analysis approach on (i) a formal 
vulnerability definition schema that captures every detail  related to 
a given vulnerability. This helps in every security analysis task , as 
discussed above ; (ii) a formal vulnerability signature specification 
approach that can capture security vulnerability signatures;  and 
(iii) an extensible vulnerability analys is tool that perform 
signature -based program analysis. Here , we introduce a static 
analysis component only . We are working on an integrated 
vulnerabilit y analyzer that performs static and  dynamic analysis.  
Figure 6. Weakness definition schema  
 
3.1 Vulnerabili ty Definition Schema  
We studied the  various  security analysis tasks (vulnerability, attack 
and threat analysis) to identify the key items required in these tasks 
that should be included in a vulnerability definition schema, shown 
in Figure 6. These vulnera bilities’ definitions should be managed 
by security experts (may be used as extension of CWE  database) . 
Vulnerability ID:  Every discovered vulnerability instance, as in 
the NVD database, should have a reference to its parent weakness 
or vulnerability defin ition. This helps retrieving  vulnerability 
details e .g. preconditions, consequences . 
Category:  Many categorization -schemas for software 
vulnerabilities  do exist. Each categorization schema helps 
understanding weaknesses from a specific point of view e.g. 
developers or researchers . A categorization based on the root cause  
or source of the weakness, shown in Figure 1, helps in vulnerability analysis, mitigation, and even avoidance. Thus, we 
propose to categorize vulnerabilities as input validation, processing  
logic, output validation, hosting service, hosting media, 
communication channel, storage, and security control 
vulnerabilities.  
Language/platform:  specifies the language(s) that a given 
vulnerability applies to - i.e. many languages have language -
specifi c vulnerabilities such as C, C++, C#, Java, etc. We also use 
this to describe the technology or architecture paradigm inherent 
with the vulnerability - e.g. client -server, web -based, service -
oriented, or multi -tier, along with the underlying environment e. g. 
web server, client, application server, database server. This helps 
in threat analysis to identify possible vulnerabilities that may exist  
and start taking precautions to avoid such vulnerabilities . 
Preconditions:  This attribute aids both vulnerability analysis and 
attack analysis.  Preconditions are a  list of the capabilities that an 
attacker should possess, or the list of system configurations that 
need to  be present in order  to exploit this vulnerability e.g. to 
exploit a  specific vulnerability, an attacker might have to  have root 
access, user access, remote root access, public access, etc.  
Consequences:  if a given vulnerability exploited, what will be the 
benefits achieved by the attackers e.g. disclosure of system 
information, invalid processing, inva lid results, execute an 
unauthorized function, elevate permission, bypass security, crash, 
or D enial -of-Service - DOS. This can be used in planned attacks 
e.g. using vulnerability V1 will help the attacker to obtain a set of 
privileges. The se privileges may be preconditions of vulnerability 
V2. The consequence of V2 may be the  actual  goal of the attacker.  
Impacted resources:  this specifies the resources that will be 
impacted if the given vulnerability exploited  including memory, 
configuration files, registr y, customer  data, credentials, 
cryptography keys.  
Likelihood:  The probability  that the given vulnerability is 
exploited  by an attacker may be low, medium, or high. This 
depends on the complexity of the given vulnerability and attacker 
capabilities as defi ned in the vulnerability preconditions.  
Vulnerability signature:  A vulnerability signature describes 
patterns  that when matched in a target program mean it is  likely to 
have  the given vulnerability. This may be signature of code 
snippets, or signature of  system response for request s with specific 
signatures . Every single vulnerability may have different 
signatures that capture  different forms (scenarios ), or that are 
applicable with different vulnerability  analysis techniques.  
Prevention:  a list of precauti ons to be followed or checked during 
code review . These might  be rules to check  during system 
development  or deployment ; combinations of architectures ; 
languages and platforms to use or not to use .   
Mitigations:  Indicates how we can  modify the vulnerable system 
entities to block a discovered vulnerability. This may require 
modification of  the vulnerable code parts ; changing system 
configurations ; or even changing system architecture.  
3.2 Vulnerability Signature Specification  
Existing software security weakne ss, or vulnerability  definitions, 
in the Common Weakness Enumeration (CWE) database help  in 
understanding the nature of a given vulnerability . However they  do 
not directly help in locating such vulnerabilities in target  systems. 
Formalizing these descripti ons helps vulnerability analysis tools in 
automating the vulnerability analysis process. Ideally a  formal 
vulnerability signature, specified by security experts, should be 
specified on an abstract level far from the source code and 
programming language det ails, enabling locating possible 
vulnerability instances in different programs written in different 
programming languages.  
Vulnerability
Name
ID
SignaturePreconditions Consequences
Impacted resources
LikelihoodDescription
Mitigation ActionsPrevention ActionsCategoryLanguage/Platform103  
 
Figure 7.  Our system description class diagram used by our OCL -based vulnerability signature approach  
 
We use OCL as a well -known, extensible, and formal language to 
specify semantic rather than syntactical signatures of security 
weaknesses. To support specifying and validating OCL -based 
signatures, we have developed a system -description model, shown 
in Figure  7. This model is inspired from our analysis of security 
vulne rabilities (S ection  2). It captures main entities  in an object -
oriented program including components, classes, instances, inputs, 
input sources, output, output targets, methods, method bod y, 
method statements e.g. if -else statements, loops, new objects, etc.  
Moreover, it captures security concepts  such as authenticat ion, 
authorization, audit , etc. and other system details such as hosting 
service, deployment descriptors, etc.  Each  entity has  a set of 
attributes such as method name, accessibility, variable name, 
variable type, method call name, etc. This enables specifying 
OCL -based vulnerability signatures on different system entities 
other than source code entities (classes, methods, code -blocks) 
such as deployment descriptors (configuration files), hosting 
services (web server), storage, output targets, or input sources. Of 
course, this requires developing different parsers other than code 
parsers that can read such entities . Moreover,  this requires a 
comprehensive vulnerability analyzer that support s locating 
signatures in such entities as well  as source code .  
The vulnerability analysis tool should have different profiles for 
different languages  and platforms  (ASP.Net, PHP, C#, Java, etc.).  
Thus vulnerabilities with signatures containing input source or 
output target security authentication, authorization, sanitization 
and other functions can be interpreted differently based on the 
program platform or programming language  used. If the  system  
uses custom sanitization or security functions, developers have to 
mark their security functions  in the resulting system model .   
Table1 shows some  vulnerability signatures specified in OCL 
using  our system description model (Figure 7 ), For example : 
SQLI Signature:  any method that has method call statement “S” 
where the callee function is “ExecuteQuery”  and one of the 
parameters  passed to it is previous assigned to untrusted identifier  
coming from one of the input sources. This initial signature can be 
revised to incorporate taint analysis  checking . Taint analysis can 
be defined as an OCL function  that adds every variable assigned 
to a user input parameter to a suspected list.  In this case we update 
the vulnerability signature to use “Method.SuspectedList() . 
Contains(X) ” instead of X.Contains(InputSource) ” as in Table1 . Table1.  Examples of  OCL -specified  vulnerability signatures  
Vul. Vulnerability Signature  
SQLI  Method.Contains( S : MethodCall | S.FnName  =   
      “ExecuteQuery” AND S.Arguments.Contains( X  :   
          IdentifierExpression |  X.Contains(InputSource)))  
XSS  Method.Contains(S : AssignmentStatement |  
     S.RightPart.Contains(InputSource) AND     
     S.LeftPart.Contains(OutputTarget))  
Improper 
Authn.   Method.IsPublic == true AND Method.Co ntains( S :   
   MethodCall | S.IsAuthenitcationFn == true AND   
   S.Parent == IFElseStmt AND  
   S.Parent.Condition.Contains(InputSource))  
Improper 
Authz.  Method.IsPublic == true AND Method.Contains( S :  
   Expression | S.Contains(X: InputSource  |    
   X.IsSanitized == False OR X.IsAuthorized == False)  
 
XSS Signature: any method statement “S” of type assignment 
statement where left part is of type “ output target ” e.g. text, label, 
grid, etc. and right part uses input from the tainted input sources.  
Improper Authentication Signature : any public method that has 
statement “ S” of type “ method call ” where the callee method is 
marked as Authentication function while this method call can be 
skipped using user input as part of the bypassing condition.  
Imprope r Authorization Signature : any public method that has 
statement “S” of type “expression” – i.e. any statement - where 
“S” uses data X without being sanitized, authorized, or simply 
taint data (Method.SuspectedList().Contains(X) == true).  
A key problem with  these signatures is that we do not consider 
security solutions applied beyond the system source code either 
using proxies to filter SQL queries or using security controls 
deployed on the web server as an http handler.  These can be 
handled by appending a d ynamic signature forming a sequence of 
OCL constraints to be checked on system responses to malicious 
requests. Another issue is that we may have different signatures 
with different complexities for the same vulnerability. We expect 
security experts to dev elop strong and complete signatures. Weak 
signatures mean more false positives, which may annoy 
developers, or more false negatives, which harm customers.  
3.3 OCL -Based Static Vulnerability Analyzer  
Given that vulnerability signatures are now  formalized (in O CL), 
the static vulnerability analysis component become s a program 
analysis tool that traverse s the given program looking for code 104snippets that match the given vulnerability signatures. Figure  8 
describes the architecture of our static vulnerability analy zer 
based on the formalized vulnerability signature concept.   
Program Source codeProgram 
Representation 1
Abstract Syntax 
Tree
Program 
Representation n……
Signature LocatorOCL 
FunctionsPlatform 
Profile
Vulnerability ListWeaknesses 
Signatures 
(OCL)
 
Figure 8 . OCL -based static vulnerability analysis tool  
Program source code:  the program to be analysed  can be either a 
source code or even program binaries (dlls, exes). In the latter 
case, we use de -compilation techniques to reverse engineer the 
source code of the given program.  
Abstract Program Representation:  to avoid being specific to 
programs written in a specific programming language or with a 
specific coding style, we transform the given system code into an 
abstract syntax tree (AST) representation. The program AST 
abstracts  most of the source code details away from specific 
language constructs. Extracting source code AST requires using 
different language pars ers (we currently support C++, VB.Net and 
C#). Then, we perform more abstraction by transforming this AST 
to our system description model , shown in Figure 7 . We support 
specifying signatures on other system aspects including  features, 
architecture, etc. Fo r example  one may check for vulnerability 
signatures of code that realize specific features. This also helps in 
combining static  analysis and dynamic analysis where  results of 
the static analysis used to drive  black -box testing scenarios.  
Signature locato r: This is the main component in our 
vulnerability analysis tool. It receives the abstract system 
representation and generates a list of possible  vulnerabilities in the 
given system along with their locations in code . At analysis time, 
it loads the platfor m profile based on the details of the program 
under analysis. Then, it loads the defined  weaknesses in the 
weaknesses’ signatures database (specified in OCL ), based on the 
target program platform/language. The signature locator 
transforms these signatures into constraints and checks on 
program entities - i.e. code snippets that match  the specified 
signatures. The OCL functions represent a library of predefined 
functions that can be used in specifying vulnerability  signatures 
and in identifying possible matc hes. This includes control flow 
analysis, data flow analysis, string analysis, taint -analysis, etc. 
The developed Weaknesses’ signatures are compiled using OCL 
compiler and validated against our system description model 
before getting stored in the weaknes ses’ signatures database.  
To locate vulnerability  matches, the signature locator translates 
every vulnerability OCL -signature in a visitor  class , as in Figure9, 
which has a handler (method)  for every concept used in the OCL -
signature – e.g. if the signatur e checks that the method is public, 
then the visitor class will have a handler for s ystem entities  of 
type method  definition . This handler contains a set of checks 
based on the given OCL -signature. The visitor class traverses the 
target program entities. I f a visited node has a handler, this 
handler is triggered  – e.g. a visitor for SQLI signature ( Figure  9), 
has handlers for “method definition” and “method call” nodes. In 
the method call handler , it will have  a condition to check the 
called  method. If it i s “ExecuteQuery” , it mark s this entity and 
contin ues to visit its arguments. Otherwise, it skips for another 
system entity . The signature locator generates a list of discovered 
vulnerabilities along with code locations thought to have these vulnerabilities . We use Application Vulnerability  Description 
Language  - AVDL - to represent the identified vulnerabilities in 
XML format to support interoperability with existing vulnerability 
databases such as NVD.  
4. IMPLEMENTATION  
We briefly describe some implementation  details of our formal 
static vulnerability analysis tool. First , we developed a UI 
component to assist security experts in capturing vulnerability 
signatures’ in OCL. This provides vulnerability specification and 
signature editing including checking valid ity of OCL statements 
and test ing of specifications on sample source code . We use an 
existing OCL parser [22] to parse and validate signatures against 
our system description model ( Figure 7). Once validated, the 
vulnerability signature is stored in the signatures database . 
Next,  to parse the given program source code and generate a 
system abstract model, we use an existing .Net parser  NReFactory  
Library, which supports VB.Net and C#. Moreover we have used 
a C parser written in python called pycparser . Thus we now 
support locating vulnerabilities in C#, VB.Net, C, and C++. We 
are working on parsers for PhP and Java. For a  system with  
binaries only available  - we use an existing de -compilation tool  
ILSPY  to generate code from binaries. This is currently suppor ted 
for C# and VB.Net only. Third,  we developed a class library to 
transform the generated AST into a more abstract (summarized) 
representation as specified in our system description model. This 
reduces its size and complexity to reflect  only necessary details 
required in signature s’ matching, reduce complexity and make  our 
technique more scalable than if a full AST was used. Other system 
models such as system features, architecture, etc. can be specified 
by the system provider and added to our AST mode l. Fourth,  our 
signature locator has an OCL translator that translates a given 
OCL signature into a visitor  class. This visitor class is used to 
traverse system representation entities.  For each entity , it performs 
customized checks as determined in the OCL si gnature.  
 
public  class  SQLIV isitor  : AbstractAstTransformer {  
  public  override  object VisitMethodCall(InvocationExpression S)  {   
          if(S.FnName == "ExecuteQuery")  {  
               foreach  (Statement X in S.Arguments) {  
                   if(X.AcceptVisitor(this) != null)  {  
     count++;  
     list.Items.Add(S.StartLocation + S.EndLocation);  
}  … 
 public  override  VisitIdentifierExpression(IdentifierExpression X) {  
        if( OCLLibrary.IsTainted(X.Identifier) == true  )   
               return  true; … 
Figure 9. Sample of the SQL injection Visitor class  
Figure 9 shows a sample visitor class generated from the simple 
SQL injection signature specified in Table 1. The SQLI Visitor 
class implements a set of predefined functions based on each part  
in the SQL injection signature e.g. the VisitMethodCall function is 
related to the condition “ Method.Contains( S : MethodCall )”, etc.  
  
context Method:: SuspectedList(): Collection(Identifier)  
    Let userInputs: Collection(Identifier) = Method. Parameters  
    Post: result = Method.Body ->select (stmt:AssignmentStmt |  
       RightPart.Contains(userInputs) ->select(id: IdentifierExp) )  
Figure 10 . Sample of the tainted -data analysis function  
Our OCL functions library has a set of functions required during 
the analy sis phase. This includes control -flow analysis (CFA), 
data-flow analysis (DFA), Tainted -data analysis, etc. These 
functions are defined in OCL and can be extended with further 
static analysis functions based on future vulnerability analysis 105needs. An OCL t o C# transformer performs a transformation for 
these functions as well as new OCL signatures once defined. 
Program slicing and taint analysis techniques (core techniques in 
program and security analysis area) can be easily captured in 
OCL . Figure 10 shows a sample tainted -data analysis function 
defined in OCL. This can be extended to filter sanitized variables 
(variables processed by sanitization function s). 
<Profile  platform="ASP.Net">  
      <InputSources > 
            <Source> Web.HttpRequest.get_QueryStri ng</Source>  
           <Source>Web.HttpRequest.get_Cookies</Source>  … 
    <OutputTargets > 
           <Target>System.Web.HttpResponse.Write</Target>           
           <Target> UI.WebControls.TextBox.set_Text</Target>  
          <Target> WebControls.Hyp erLink.set_NavigateUrl</Target> … 
Figure  11. Sample of the platform profile for ASP.Net  
Our vulnerability analyzer depends on platform profile s to set the 
analysis context. Platform profile is an XML document that 
contains information about a specific platf orm. It is used to set  the 
context of the signature locator according to the target system 
implementation platform. Figure  11 shows an example of a 
platform profile for ASP.Net. This is different from Java or PHP 
profiles. These functions are used by the s ignature locator as 
values for the abstract concepts ( i/p sources, o /p targets, etc.).  
5. EVALUATION  
In this section we summarize our experimental evaluation we have  
performed to assess the capabilities of our approach in capturing 
as well as identified secur ity vulnerabilities. We apply the OCL -
based vulnerability signatures illustrated  in Section 3. 
Table  2. Summary of benchmark applications statistics  
Benchmark  Downloads  KLOC  Files  Classes  Method  AST  
Galactic  - 16.2 99 101 473 187 
SplendidCRM  >400  245 816 6177  6107  765 
KOOBOO  >2,000  112 1178  7851  5083  78 
BlogEngine  >46,000  25.7 151 258 616 163 
BugTracer  >500  10 19 298 223 93 
NopCommerce  >10 Rel.  442 3781  5127  9110  484 
Webgoat  - 15 105 125 165 150 
5.1 Benchmark Applications  
We have selected a set of seven  web-based, open source web 
applications developed ASP.N ET as a benchmark to evaluate our 
approach.  These applications cover a wide business spectrum 
including: Galactic is an ERP system developed internally in our 
group for testing purposes. SplendidCRM i s an open source CRM 
that is developed with the same capabilities of the well -known 
open source SugarCRM. It has  a commercial and community 
versions.  KOOBOO is an open source Enterprise CMS used in 
developing websites. BlogEngine is an open source ASP.NET  4.0 
blogging engine. BugTracer is an open -source, web -based bug 
tracking and general purpose issue tracking application. 
NopCommerce is an open -source eCommerce solution  with more 
than 10 releases. Webgoat is developed by OWSAP for security 
testing purpos es. Except for Galactic, we did not have experience  
with these applications security . Table 2 summarizes statistics of 
these applications including: known No. download, size, KLOC, 
files, classes, methods, and AST build time (msec).  
5.2 Metrics Used 
To assess t he effectiveness of our approach in discovering security 
vulnerabilities using static program analysis, we use a set of 
metrics to measure the soundness and completeness of the 
analysis technique . These metrics are precision rate, recall rate, and F -measur e. The precision metric is used to assess the 
soundness of the approach. A high precision means that the 
approach returns more valid results (true positive - TP) than 
invalid results (false positive - FP). Thus the maximum  precision 
is achieved when no fal se positives (see Equation 1 below).  The 
recall metric is used to assess the completeness. A high recall 
means that the approach returns most of the valid results (true 
positive - TP) than missed valid results (false negative - FN), see 
Equation 2 . The F -measure metric combines both precision and 
recall. It is used to measure the overall effectiveness of the 
approach (weighted harmonic mean). This metric depends on the 
importance of the recall rate and the precision rate e.g. if we are 
interested in high pr ecision (more valid vulnerabilities) then we 
will give precision factor high weight, and vice -versa. In our 
evaluation, we assume that the importance of the precision rate 
and recall rate is equal, see Equation 3 . 
            Eq. 1  
               Eq. 2  
                       Eq. 3  
 
 
Table 3. Experimental results of applying OCL -based vulnerability 
analysis tool on  benchmark applications. D: discovered vulnerability, 
FP: false positives, and FN: false negatives. Columns represent IDs of 
the benchmark applications: [1] Galactic, [2] Splendid, [3] KOOBOO, 
[4] BlogEngine, [5] BugTracer, [6 ] NopCommerce, and [7] Webgoat.  
 
Vuln.  [1] [2] [3] [4] [5] [6] [7] Tot. 
SQLI  D 2 12 14 3 9 19 8 67 
FP 0 2 2 0 0 2 0 6 
FN 0 2 2 1 3 1 1 10 
Authn.  
Bypass  D 2 2 1 0 0 0 2 7 
FP 0 0 0 0 0 0 0 0 
FN 0 0 0 0 1 0 1 2 
Authz.  
Bypass  D 2 3 11 4 0 0 3 23 
FP 1 0 2 0 0 0 0 3 
FN 0 0 2 0 2 3 0 7 
XSS D 3 5 10 2 0 4 5 29 
FP 0 1 1 0 0 0 1 3 
FN 1 2 2 1 2 1 0 9 
CSRF  D 5 6 13 10 0 12 3 49 
FP 1 0 1 0 0 1 0 3 
FN 0 1 2 0 4 1 0 8 
Info.  
Expo.  D 3 0 0 10 0 0 3 16 
FP 0 0 0 0 0 0 0 0 
FN 0 0 0 0 2 1 0 3 
URL   
Redir  D 1 0 2 8 0 6 0 17 
FP 0 0 0 0 0 0 0 0 
FN 0 0 0 0 3 1 0 4 
Total  D 18 28 51 37 9 41 24 208 
FP 2 3 6 0 0 3 1 15 
FN 1 5 8 2 17 8 2 43 
 
01020304050607080
D FP FN D FP FN D FP FN D FP FN D FP FN D FP FN D FP FN
SQLI Authn.
BypassAuthz.
BypassXSS CSRF Info.
ExposureURL
RedirectNumber of Vulnerabilities
Vulnerability type7
6
5
4
3
2
1
Chart 1. Discovered vulnerabilities per vulnerability type  1060102030405060
URL
Redirect
Info.
Exposure
CSRF
XSS
Authz.
Bypass 
Chart 2. Discovered vulnerabilities per application  
 
0%20%40%60%80%100%120%
Precision
Recall
F-Measure
Chart 3. Our achieved precision, recall, and F -measure rates  
 
1248163264128
XSS
CSRF
URL Redirect.
Authz. Bypass
Info. Expos.
SQL
Chart 4. Performance of our approach per vulnerability  
 
5.3 Experimental Results  
Table 3 summarizes results of our experiments. We used our 
approach to analyse applications in the benchmark suite to 
identify seven of the Top10 web applications vulnerabilities (from 
the OWSAP2010 report). Other vulnerabilities could not specify 
static signatu res (use static program analysis). However, 
specifying dynamic signatures for these vulnerabilities is easy. 
Table  3 summarizes , for each application and each vulnerability 
analysed , the total time taken, number of vulnerabilities in the 
code base found, FPs (analyser thought vulnerability but there is  
not on manual analysis), and FNs (manual code analysis indicates 
a vulnerability but our tool did not discover it).   
Chart 1 shows the number of discovered vulnerabilities grouped 
by vulnerability type.  The  SQLI represents the most frequent 
vulnerability in all applications, th en cross site reference forgery 
(CSRF) vulnerability. After that, cross site scripting (XSS) and 
authorization bypassing vulnerabilities are relatively equal. This is 
mostly conforming  to the ranking reported by OWSAP2010.  
Chart 2 shows the number of vulnerabilities identified in every 
application. It is clear that nopCommerce and KOOBOO are the 
most vulnerable applications. However, if we consider the 
application size factor, we see that the ratio of vulnerabilities 
discovered per compared to application size is  about  equal. 
Moreover, some applications such as BlogEngine use Microsoft 
membership for access control, which eliminates the 
authentication bypassing vulnerabilities.  Chart 3 s hows the precision, recall, and F -measure rates for each 
vulnerability type. This chart shows that we achieve a high 
precision rate for most of the vulnerability types. The precision 
metric is on average (93%). This means that for each identified 
(100) vulnerabilit ies we have (7) false positives. This chart also 
shows a good recall rate, although it is relatively lower than 
precision rate we achieved. The recall metric is on average (82%). 
This means that in every (100) vulnerability instances, we can 
corre ctly identify (82) and we miss 18 instances. This value could  
be improved if we use a hybrid dynamic and static analysis 
approach. The overall effectiveness of the approach (F -measure) 
is around (87%). A key result from this chart is that the recall 
metric  is higher in SQLI, XSS, Information disclosure, and URL 
redirection than in the other vulnerabilities. This justifies our 
initial supposition  that although we succeeded in developing  a 
static signature for these signature s (CSRF, authorization and 
authn.  bypass), it is difficult to achieve a high correct detection 
rate without dynamic analysis.  
5.4 Performance Evaluation  
Chart 4 shows the time (in sec) required to analyse the benchmark 
applications to locate the existing vulnerabilities’ instances for the 
given set of vulnerability signatures. It is clear that the SQLI 
vulnerability takes much more time to identify than XSS and 
authorization bypassing. The authentication bypass takes the 
lowest time. The time required to identify a given vulnerability 
depends o n number and complexity of specified OCL signatures.  
6. DISCUSSION  
In this research we introduce a formal vulnerability definition 
schema; signature specification approach based on OCL; and 
static vulnerability analyser. Vulnerability definition schema 
cover s most of the details required in security analysis tasks 
(attack, threat and vulnerability analysis tasks). Vulnerability 
signature is specified on an abstract system representation. This 
allows applying the same signature on different systems 
developed w ith different languages. Use of OCL allows 
formalizing and easing of signatures validation and testing. 
Moreover, a new vulnerability can be easily located in the target 
system as far as we have a formal signature for it.  
We succeeded in producing a vulner ability analysis tool that can 
work online without a need for new algorithms, modules, or 
patches. The current static analyser achieves a precision rate of 
93% and recall rate of 82%. Although we are usually interested in 
high recall rate which implies les s false negatives i.e. less number 
of vulnerabilities that could not be detected by the analyser, in the 
current tool we focused on high precision rate where number of 
reported vulnerabilities that are false positives i.e. not a real 
vulnerability, are les s. The reason behind this decision was that 
static analysers are usually used by system developers who are 
interested in getting less false positives to mitigate. Another 
reason is related to the nature of security vulnerabilities.  From 
our experiments, w e determined that not all vulnerabilities can be 
captured using static analysis, and the same applies using dynamic 
analysis. Vulnerabilities related to source code such as SQLI and 
XSS can be described and located using static analysis. 
Vulnerabilities su ch as CSRF are difficult to use static signatures.  
From our experience in developing signatures of the TOP10 
vulnerabilities and our experiments we determined that: (i) it is 
better to use dynamic analysis tools with certain vulnerabilities, 
such as CSRF, because these vulnerabilities can be handled by the 
web server. This means that we have a high false positive if we 
use static analysis tool to locate these vulnerabilities; (ii) some 
vulnerabilities can be easily identified and located by static 107analysis such as SQL Injection and XSS vulnerabilities; (iii) some 
vulnerabilities such as DOM -based SQL and XSS vulnerabilities 
need a collaborating static and dynamic analysis to locate them. 
We believe that combining static and dynamic analysis is needed 
to incr ease the precision and recall rates.  
A key problem with static analysis tools is the use of aspect -
oriented security techniques, where security is weaved within the 
system at runtime. In this case we will have a high false positive 
rate because we report v ulnerabilities that are already mitigated by 
the aspect -based security. The same will occur if external security 
controls are used, such as in database engines to filter SQL 
queries, using DB proxies to filter queries, using web server’s 
deployed security controls such as encryptions, authentication, 
and authorization, or even provided by the platform through 
configurations such as ASP.NET membership or other anti -CSRF/ 
anti-XSS security controls. These can be discovered using 
dynamic vulnerability analysis  extensions.  
The lack of system engineers’ annotations of the system security 
functions may lead to high false positive. However, this problem 
can be solved by employing dynamic vulnerability analysis. 
Dynamic vulnerability analysis approaches cannot help in locating 
specific code snippets where vulnerabilities exist. Moreover, they 
cannot help testing code coverage. Thus, a hybrid approach of 
static and dynamic analysis is required. We are extending our 
analyser to support both. We use a workflow engine to  define the 
analysis sequence, using different approaches, to locate a given 
vulnerability. This increases the recall rate of the overall 
approach. Moreover, we plan to include confidence level with 
reported vulnerabilities. This helps developers to priori tize based 
on criticality and importance.  
Our OCL -based signatures and vulnerability analysis tool can be 
used in different program analysis problems such as aspect 
mining, refactoring – locating “bad -smells”, or reengineering 
“impact analysis”. In these c ases system engineers have to specify 
signatures they want to locate in their programs.  
7. RELATED WORK  
Existing efforts in vulnerability analysis can be categorized into 
static analysis, dynamic analysis, and hybrid analysis based 
approaches. Most of these e fforts designed for specific 
vulnerability types mainly SQLI, XSS. Jimenez  et al. [20] review 
various  software vulnerability prevention and detection 
techniques . Broadly, static  program analysi s techniques work on 
the source code level. This includes pattern matching that searches 
for a given string inside source code, tokens extracted from source 
code, or system byte code e.g. calls to specific functions. Data 
flow and taint analysis identify  data coming from untrusted 
sources to mark  as tainted  i.e. should not be used before being 
sanitized or filtered. Model checking to detect vulnerabilities 
depends on extracting a system model from the source code and 
developing a set of constraints on the m odel that should not occur . 
An issue is that model  checking approaches often suffer from a 
state explosion problem and generate only a counterexample. 
Dynamic analysis techniques analyse a system as a black box , 
avoiding  being overwhelmed with system detai ls. Fuzzy testing  
provides random data as input to the application in order to 
determine if the application can handle it correctly or not. 
Dynamic techniques are however limited in code coverage.   
Static analysis approaches:  NIST [17] has been conducting a 
security analysis tools assessment project (SAMATE). A part of 
this project is to specify a set of weaknesses that any source code 
security analysis approach should support including SQL injection, XSS, OS command injection, etc. They have also 
developed a set of test cases that help in assessing the capabilities 
of a security analysis tool in discovering such vulnerabilities. 
Halfond et al.  [7] introduce a new SQL injection vulnerability 
identification  technique base on positive tainting. They identify 
“trusted” strings in an application and only these trusted strings to 
be used to create certain parts of an SQL query, such as keywords 
or operators. Lei et al.  [13] trace the memory size of  buffer -
related variables and instrument the code with corresponding 
constraint assertions before t he potential vulnerable points by 
constraint based analysis. They used model checking to test for 
the reachability of the injected constraints. Dasgupta et al.  [4] 
introduce a framework for analysing database application binaries 
to automatically identify security, correctness and performance 
problems especially SQLI vulnerabilities. They adopt data and 
control flow analysis techniques as wel l as identifying SQL 
statements, parameters, tables and conditions and finally analyse 
such details to identify SQLI vulnerabilities. Martin et al [12; 15] 
introduce a program query language PQL that can be used to 
capture definition of program queri es that are capable to identify 
security errors or vulnerabilities. PQL query is a pattern to be 
matched on execution traces. They focus on Java -based 
applications and define signatures in terms of code snippets. This 
limits their capabilities in locating vulnerabilities’ instances that 
matches semantically but not syntactically. Wassermann et al.  
[18] introduce an approach to finding XSS vulnerabilities based 
on formalizing security policies based on W3C recommendation. 
They conduct a string -taint analysis using context free grammars 
to represent sets of possible string values. They then enforce a 
security policy that the generated web pages include no untrusted 
scripts. Jovanovic et al.  [9] introduce a static analysis tool for 
detecting web application vulnerabilities. They adopt ﬂow -
sensitive, inter -procedural and context -sensitive data ﬂow 
analysis. They target identifying XSS vulnerabilities only. Ganesh 
et al [6; 11] introduce a string constraint solver to check if a given 
string can have a substring with a given set of constraints. They 
use thi s to conduct white box and dynamic testing to verify if a 
given system is vulnerable to SQLI attacks.  
Dynamic analysis approaches:  Bau et al [2] perform an analysis 
of black box web vulnerability scanners. They conducted an 
evaluation of a set of eight leading commercial tools to assess the 
supported classes of vulnerabilities and the ir effectiveness against 
these target vulnerabilities. A key conclusion of their analysis is 
that all these tools have low detection rates of advanced and 
second -order XSS and SQLI. The average percentage of 
discovered vulnerabilities equals 53%. The analy sis shows that 
these tools achieve 87% in session management vulnerabilities 
and 45% in the cross site scripting vulnerabilities. Kals et al [10] 
introduce a vulnerability scanner that uses a black -box to scan 
web sites for the presence of exploitable SQLI and XSS.  They do 
not depend on a vulnerability signature database, but th ey require  
attacks to be implemented as classes t hat satisfy certain interfaces. 
Weinberger et al [8; 19] introduce an analysis of a set of 14 
frameworks that provide XSS sanitizatio n techniques. They 
identify limitations including lack of context -sensitive sanitization 
that result in developing custom sanitizer that need to be validated 
for their correctness, and supporting client -side code “DOM -based 
XSS”. Felmetsger et al [5] use an approach for automated logic 
vulnerabilities detection in web applications. They depend on 
inferring syst em specifications of a web application’s logic by 
analysing system execution traces. They then use model checking 
to iden tify speciﬁcation violations. The extraction of properties  108specifications to be validated  is a key limitation in this approach . 
They assume that these traces represent correct system behaviour.  
Hybrid analysis approaches:  Monga et al [16] introduce a 
hybrid analysis framework that blends static and dynamic 
approaches to det ect vulnerabilities in web applications. The 
application code is translated into an intermediate form. The 
resulting static model is filtered to focus only on dangerous 
statements. This reduces  model size where dynamic analysis will 
be conducted, mitigatin g the performance overhead of the 
dynamic taint analysis approach. This approach, as most taint 
analysis approaches (either static or dynamic), targets only 
injection -related vulnerabilities. Balzarotti et al [1] introduce 
composition of static and dynamic analysis approaches “Saner” to 
help validating sanitization functions in web applications. The 
static analysis is used to identify sensitive sources/sinks methods. 
Dynamic analysis used to analyse the id entified suspected paths.   
Compared to existing efforts , our approach achieves scalable, 
extensible and powerful signature -based vulnerability analysis not 
coupled to specific vulnerability, analysis technique, or 
language/platform. Our approach is based on formalizing 
vulnerability definition including the vulnerability signature part.  
8. SUMMARY  
We introduce a new automated formal vulnerability analysis 
approach. Our approach is based on formalized vulnerability 
definition schema. A part of this schema is t he formal 
vulnerability signature. This signature specifies a set of invariants 
that confirm the existence of a given vulnerability in the target 
program. We adopt OCL in specifying vulnerability signatures. 
We developed a static vulnerability analysis too l that uses our 
formally specified vulnerabilities signatures to locate possible 
matches in the target system. A new vulnerability can be easily 
identified provided that it has a formal signature. We validated our 
approach on a set of seven open source app lications from different 
domains, different sizes and different development models. Our 
experimental results show that our OCL -based static analysis tool 
achieves (93%) precision rate and (82%) recall rate. This means 
that we achieve a good FP rate (7%) an d a fair FN rate (18%). We 
are currently working on a dynamic analysis extension based on 
our formal signatures  approach that yields better rates.  
9. ACKNOWLEDGEMENTS  
The authors are grateful to Swinburne University of Technology 
and the FRST SPPI project for  support for this research.  
10. REFERENCES  
[1] BALZAROTTI, D., COVA, et al, 2008. Saner: Composing 
Static and Dynamic Analysis to Validate Sanitization in 
Web Applications. In Proc. of 2008 IEEE Symposium on 
Security and Privacy , 387 -401.  
[2] BAU, J., BURSZTEIN, E., GUPTA, D., and MITCHELL, 
J., 2010. State of the Art: Automated Black -Box Web 
Application Vulnerability Testing. In Proc. of 2010 IEEE 
Symposium on Security and Privacy , 332 -345.  
[3] CENGARLE, M.V. and KNAPP, A., 2004. OCL 1.4/5  vs. 
2.0 Expressions Formal semantics and expressiveness. 
Software and Systems Modeling 3 , 1, 9 -30.  
[4] DASGUPTA, A., NARASAYYA, V., and SYAMALA, M., 
2009. A Static Analysis Framework for Database 
Applications. In Proc. of 2009 IEEE Int. Conf. on Data 
Engineering , 1403 -1414.  [5] FELMETSGER, V., et al , 2010. Toward automated 
detection of logic vulnerabilities in web applications. In 
19th USENIX Conf. on Security , Washington, DC.  
[6] GANESH, V., et al , 2011. HAMPI: a string solver for 
testing, analysis and v ulnerability detection. In Proc. of 23rd 
Int.  Conf. on Computer aided verification  Springer -Verlag, 
Snowbird, UT, 1 -19. 
[7] HALFOND, W.G.J., ORSO, A., and MANOLIOS, P., 2006. 
Using positive tainting and syntax -aware evaluation to 
counter SQL injection att acks. In 14th ACM Int.  symposium 
on Foundations of software engineering , Oregon , 175 -185.  
[8] HOOIMEIJER, P., et al , 2011. Fast and precise sanitizer 
analysis with BEK. In  20th USENIX Conf. on Security  (San 
Francisco, CA2011).  
[9] JOVANOVIC, N., KRUEGEL,  C., et al, 2006. Pixy: a static 
analysis tool for detecting Web application vulnerabilities. 
In 2006 IEEE Symposium on Security and Privacy , 258 -263. 
[10] KALS, S., et al, 2006. SecuBat: a web vulnerability scanner. 
In 15th Int. Conf. on World Wide Web . Edinburgh  , 247 -256.  
[11] KIEYZUN, et al , 2009. Automatic creation of SQL 
Injection and cross -site scripting attacks. In Proc. of 31st 
Int.Conf. on Software Engineering , 199 -209. 
[12] LAM, M.S., MARTIN, M., LIVSHITS, B., and WHALEY, 
J., 2008. Securing web applications with static and dynamic 
information flow tracking. In  2008 ACM SIGPLAN 
symposium on Partial evaluation and semantics -based 
program manipulation , California, USA, 3 -12.  
[13] LEI, W., QIANG, Z., and PENGCHAO, Z., 2008. 
Automated Detection of Code Vulnerabilities Based on 
Program Analysis and Model Checking. In 8th IEEE Int.  
Conf. on Source Code Analysis and Manipulation , 165 -173. 
[14] MANADHATA, P.K. and WING, J.M., 2011. An Attack 
Surface Metric. IEEE Transactions on Sof tware 
Engineering 37 ,3, 371 -386. 
[15] MARTIN, M., LIVSHITS, B., and LAM, M.S., 2005. 
Finding application errors and security flaws using PQL: a 
program query language. In 20th annual Conf. on Object -
oriented programming, systems, languages, and 
application s ACM, CA, USA, 365 -383.  
[16] MONGA, M., PALEARI, R., and PASSERINI, E., 2009. A 
hybrid analysis framework for detecting web application 
vulnerabilities. In Proc. 2009 ICSE Workshop on Software 
Engineering for Secure Systems , 1656378, 25 -32.  
[17] NIST, M ay 2007, Accessed 2011. Source Code Security 
Analysis Tool Functional Specification Version 1.1.  
[18] WASSERMANN, G. and SU, Z., 2008. Static detection of 
cross -site scripting vulnerabilities. In Proc. 30th Int.  Conf. 
on Software engineering  ACM, Leipzig,  Germany, 171 -180.  
[19] WEINBERGER, J., SAXENA, P., et al, 2011. A systematic 
analysis of XSS sanitization in web application frameworks. 
In 16th European Conf. on Research in computer 
security ,Belgium, 150 -171. 
[20] WILLY JIMENEZ, A.M., ANA CAVALLI 2009.  Software 
Vulnarabilities, Prevention and Detection Methods: A 
Reviw. In  2009 European Workshop on Security in Model 
Driven Architecture , Enschede, The Netherlands, 6 —13. 
[21] ZHANG, R., HUANG, S., et al , 2012. Static program 
analysis assisted dynamic tain t tracking for software 
vulnerability discovery. Computers & Mathematics with 
Application 63 , 2, 469 -480.  
[22]  VAJK, T., MEZEI, G., and LEVEDOVSZKY T., 2008. An 
Incremental OCL Compiler for Modelling Environments. In 
Electronic Communications of the EASS T, vol. Volume 15: 
OCL Concepts and Tools . 109