DRAFTGraph-Based Pattern-Oriented, Context-Sensitive Source Code Completion
Anh Tuan Nguyen, Tung Thanh Nguyen, Hoan Anh Nguyen
Ahmed Tamrawi, Hung Viet Nguyen, Jafar Al-Kofahi, Tien N. Nguyen
Electrical and Computer Engineering Department
Iowa State University
{anhnt,tung,hoan,atamrawi,hungnv,jafar,tien }@iastate.edu
Abstract —Code completion helps improve developers’ pro-
gramming productivity. However, the current support for code
completion is limited to context-free code templates or a single
method call of the variable on focus. Using software libraries
for development, developers often repeat API usages for certain
tasks. Thus, a code completion tool could make use of API
usage patterns. In this paper, we introduce GraPacc, a graph-
based, pattern-oriented, context-sensitive code completion ap-
proach that is based on a database of such patterns. GraPacc
represents and manages the API usage patterns of multiple
variables, methods, and control structures via graph-based
models. It extracts the context-sensitive features from the code
under editing, e.g. the API elements on focus and their relations
to other code elements. Those features are used to search and
rank the patterns that are most ﬁtted with the current code.
When a pattern is selected, the current code will be completed
via a novel graph-based code completion algorithm. Empirical
evaluation on several real-world systems shows that GraPacc
has a high level of accuracy in code completion.
Keywords -pattern-based code completion; API usage pattern
I. I NTRODUCTION
Code completion, which is a built-in support in many
integrated development environments (IDEs), aims to help
improve programming productivity. However, most of the
state-of-the-art code completion tools [1], [2] can help in the
completion of only a single method call or a single object
declaration/initialization. For example, Eclipse provides an
alphabetical-order list of available methods for the variable
under editing. The user then has to go through a long list
of unranked options. For better auto-completion, several
approaches [2], [3], [4] have been proposed to rank such
a suggested list of method calls. However, the volume of
auto-completed code is still limited to a single method call.
Aiming to provide more auto-completed code, some IDEs
recommend the templates for common program constructs
(e.g. for,while) and popular classes/methods (e.g. Iterator ).
However, they do not consider the context of the code under
editing, thus do not predict well users’ editing intention.
Using software libraries, developers follow the API spec-
iﬁcations to perform their tasks with some intended func-
tionality. Other developers may also repeat those tasks via
the same API usages. The correct and repeated ways of
using APIs are often called API usage patterns . The patterns
include the usages of variables, method calls, and controlstructures, with speciﬁc control and data dependencies and
the orders among them. Thus, to support better API usages
and provide more auto-completed code, a code completion
tool can rely on API usage patterns. Moreover, a developer
uses the APIs to achieve a different goal in the context of his
own program. Thus, such a tool should predict his intention
based on the current context of the code under editing (e.g.
current API elements) to provide best ﬁtted patterns.
This paper introduces GraPacc, a graph-based, pattern-
oriented, context-sensitive code completion method and tool
that performs code completion based on a collected database
of API usage patterns. Each pattern is represented as a
graph-based model [5] that is able to capture the usages
of multiple variables in different types, method calls in
multiple libraries, control structures, and their data/control
dependencies. GraPacc extracts the context-sensitive features
from the code under editing, e.g. the API elements being on
focus or under modiﬁcation and their relations to other code
elements. The features are then used to search and rank the
patterns that are best matched with the current code. When
a pattern is chosen by a user, GraPacc will ﬁll in the code
based on that pattern with proper replacements of program
elements in the current context of the program.
We conducted an empirical evaluation on GraPacc’s cor-
rectness. The evaluation results on 24 real-world systems
show that, GraPacc can achieve up to 95% precision, 92%
recall, and 93% f-score in code completion. We found that
on average 71% of an API’s usage in a project is covered by
usage patterns. The key contributions of this paper include:
1. A formulation and algorithms for graph-based feature
extracting ,searching andranking of API usage patterns that
are best matched with the context of the current code,
2. A novel algorithm for graph-based code completion ,
3. GraPacc, a graph-based, context-sensitive code comple-
tion tool that takes into account the current editing context
and makes use of API usage patterns, and
4. A comprehensive empirical evaluation method that
shows the correctness and usefulness of GraPacc.
Section II presents motivating examples. Sections III-VI
describe our model and algorithms. Our empirical evaluation
is presented in Section VII. Related work is discussed in
Section VIII. Conclusions appear last.DRAFT1Display display = new Display();
2Shell shell = new Shell(display);
3...
4Button button = new Button(shell, SWT.PUSH);
5button.setText(”OK”);
6button.setSize( new Point(40,20));
7button.setLocation( new Point(200,20));
8...
9shell .pack();
10shell .open();
11while (! shell .isDisposed()) {
12 if(! display.readAndDispatch())
13 display.sleep();
14}
15display.dispose();
Figure 1. SWT Usage Example 1
II. M OTIVATING EXAMPLES
API Usage Patterns. Figure 1 shows a portion of code
using SWT, a graphical user interface (GUI) library, to
create a window containing “OK” button. According to SWT
documentation, creating a window involves two types of
objects. A Display object is responsible for managing the GUI
events and related resources between SWT and the operating
system. A Shell object represents a GUI window, which is
associated with the Display object and acts as a container for
other GUI elements such as buttons, text boxes, etc. After
aDisplay object ( display ) is created, a Shell object ( shell) is
created to form a top-level window (lines 1-2). It then starts
to receive and process the events via display until object shell
is disposed (lines 9-14). Finally, object display is disposed.
According to SWT documentation, this usage of those
SWT elements (the classes Display ,Shell, and their methods)
is a correct way to perform the task of creating a top-level
GUI window in SWT. Thus, this API usage (lines 1-2 and
9-15) occurs very frequently in Java code that uses SWT
library. We call this correct usage an API usage pattern (or
a pattern for short).
This example shows a common practice in which devel-
opers reuse existing software components via libraries and
their APIs. Such API elements are intended to be used in
some speciﬁc usage procedure (i.e. an usage pattern) in order
to accomplish a speciﬁc task. Thus, when using libraries,
developers usually follow the corresponding usage patterns
to achieve their goals.
Aiming to reduce developers’ burden in remembering
exact API elements and their usages as well as providing
more auto-completed code, a code completion tool could be
based on API usage patterns. With the knowledge on usage
patterns, it could recommend the appropriate pattern that ﬁts
with the current context of code under editing. For example,
if a developer ﬁnishes the ﬁrst two lines in Figure 1, a
pattern-oriented code completion tool should recognize that
(s)he is using two SWT variables of types Display and Shell,
which belong to the window creation pattern. Then, it could
predict that (s)he intends to create a window, and ﬁll in the1Button button = new Button(shell, SWT.PUSH);
2button.setText (”OK”);
3FormData bData = new FormData();
4button.setLayoutData (bData);
Figure 2. SWT Usage Example 2
remaining part of the pattern (lines 9-15). Providing higher
volume of code, such a pattern-oriented tool could help to
complete code faster than the single-method suggestions.
Alternative Patterns. Figure 1 (lines 4-7) illustrates an
SWT usage pattern for creating a Button object. A Button
object can be instantiated with two parameters: one for its
SWT window container, and one for the button style. Then,
other properties of the button could be set including its
textual label (via method setText ), its size (via setSize ), and its
location (via setLocation ). SWT also provides another pattern
in which the layout (e.g. size and location) of a button
is controlled indirectly via a FormData object. In Figure 2,
instead of calling setSize and setLocation , one can specify
the layout information via a FormData object (line 3), and
associate it with the button (line 4).
This example shows that there exist multiple usage pat-
terns for a speciﬁc task (called alternative patterns ). Alter-
native patterns can share or involve different API elements
(classes/methods). Thus, a pattern-oriented code completion
tool must be context-sensitive , i.e. consider the context of the
code under editing such as the currently used API elements.
For example, assume that a developer wrote the code to
create a Button object and ﬁnished lines 1-3 (Figure 2). Due
to the existence of a FormData , the tool could predict that
(s)he intends to use the pattern of creating a button with a
layout object. Thus, the tool should recommend toward the
pattern with layout, i.e. ranking it higher than its alternative.
Interleaving Patterns. Figure 1 also illustrates a common
case that a developer can use multiple usage patterns whose
code is interleaved with one another (e.g. creating a window
and a button). This implies that a pattern-oriented, context-
sensitive code completion tool could use the current focus
position as context information to guess the user’s editing
intention. Then, the tool should switch between those pat-
terns for code completion depending on the current focus
cursor. For example, if (s)he is in the middle of editing line 2
(Figure 1), the tool must recognize that the usage pattern for
SWT window creation is the most relevant and suggest that
pattern (lines 9-15). Assume that during ﬁlling the details
of that pattern, (s)he switches to create a new Button as in
line 4: new Button(...) . The tool must recognize the switching
and suggest the button creation pattern.
Graph-based Patterns. As seen, some API elements have
strict usage orders, while others do not. For example, in the
button creation pattern (lines 4-7, Figure 1), the constructor
ofButton must be called before other methods setText ,setSize ,DRAFT1Display display = new Display();
2Shell shell = new Shell(display);
3...
4Button button = new Button(shell, SWT.PUSH);
5FormData formData = new FormData();
6button.
Figure 3. SWT Query Example
and setLocation . However, there is no required order among
those setters. The existence of such partial control/data
dependencies suggests that, the patterns and the context
should be modeled via graph-based structures, rather than
sequences [6] or sets of method calls [2] as in existing work.
III. I MPORTANT CONCEPTS
We develop GraPacc, a Graph-based Pattern-oriented,
Context-sensitive tool for Code Completion. It takes as an
input a database of usage patterns and completes the code
under editing based on its context and those patterns.
Deﬁnition 1 (Pattern): An API usage pattern is a set of
API elements (i.e. classes/variables/method calls) and con-
trol structures (i.e. condition/repetition) with speciﬁc control
and data dependencies. A usage pattern speciﬁes a correct
usage of API elements to perform a programming task.
Figure 1 (lines 1-2, 9-15) shows an instance of SWT win-
dow creation pattern. An instance is concrete code realizing
that pattern. A pattern contains the usage of the classes (via
variables), methods (via method calls), and control structures
(e.g. while,if), with speciﬁc orders and inter-dependencies. A
pattern could be a composite one built from multiple sub-
patterns. The patterns could be interleaved with each other.
Deﬁnition 2 (Query): A query is a code fragment under
editing, i.e. a sequence of textual tokens written in a pro-
gramming language.
A query is generally incomplete (in term of the task that
is intended to achieve) and might not be parsable. Figure 3
illustrates a code fragment as a query. The character
denotes the editing cursor where a developer invokes the
code completion tool during programming.
We developed a graph-based model, called Groum [5]
to represent object usage patterns. GraPacc uses Groum to
represent API usage patterns and queries as follows.
Deﬁnition 3 (Groum): A Groum is a graph-based
model, in which the nodes represent actions (i.e. method
calls), data (i.e. objects/variables), and control points (i.e.
branching points of control structures such as if,while,for,
etc). The edges represent the control and data dependencies
between the nodes. Labels of the nodes are built from the
corresponding names of classes/methods/control structures.
Figure 4 illustrates the usage patterns in Section II as
Groum models. For clarity purpose, we label the nodes using
the simple names of classes and methods. In the actual im-
plementation, nodes’ labels have their fully qualiﬁed names.Display.new
Shell.new
Shell.pack
Shell.open
Shell.isDisposed
Display.readAndDispatch
Display.sleep
Display.disposeIFWHILEDisplay Shelldata
dependencycontrol dependency
data node
action node
control nodeButton.new
Button.setText
Button.setSize
Button.setLocationButton
Button.new
Button.setTextButton
Button.setLayoutDataFormData.new FormDataa. b.
c.
Figure 4. SWT Usage Patterns
As seen, two data nodes labeled Display and Shell represent
two variables display and shell. Action nodes such as Dis-
play.new ,Display.readAndDispatch , and Shell.open represent the
method calls. An edge from data node Display to action node
Shell.new represents the data dependency, while an edge from
Display.new toShell.new represents their control ﬂow order.
GraPacc matches the patterns to the code under editing via
their features extracted from their Groums and associated
context-sensitive information. Moreover, because a query
might be incomplete or not fully parsable, the corresponding
Groum might not contain all necessary information or might
not even be available. Thus, GraPacc also extracts the
features from the texts of the query. There are two types
of features: graph-based features andtoken-based features .
Deﬁnition 4 (Feature): A graph-based feature is a sequ-
ence of the textual labels of the nodes along a path of a
Groum. A token-based feature is a lexical token extracted in
a query.
Thesizeof a graph-based feature is deﬁned as the number
of elements in its corresponding sequence. Thus, in a Groum,
a node has a corresponding graph-based feature of size 1,
and an edge has a graph-based feature of size 2. Larger
features can be built from a path in the Groum. In Figure 4a,
there are a size-1 graph-based feature [Shell.new] , a size-
2 graph-based feature [Shell.new, Shell.pack] , a size-3 graph-
based feature [Shell.pack, Shell.open, Shell.isDisposed] , etc.
In GraPacc, a token-based feature always has its size equal
to 1 and is used to represent the usage of a class , amethod ,
or a control structure in the current (incomplete) code. For
example, the query for (Iterator is incomplete and can not
be parsed into an AST. However, GraPacc still extracts two
tokens forand Iterator , and uses them to match this query
to the patterns that have the usages with a forloop and an
Iterator variable.DRAFTTo measure the similarity of any two features, GraPacc
deﬁnes a function sim that compares their textual similarity
and the orders of their elements (see Section IV for details).
To compare a query against a pattern via features, Gra-
Pacc also takes into account the context information of
the query. Such information is modeled via the context-
sensitive weights associated with the features. That is,
context-sensitive weights measure the signiﬁcance of the
features in a query based on the relations of the features
to the focus editing position (user-based factor) and based
on the structure of the query’s Groum (structure-based
factor). Based on the similarity of the features and their
corresponding context-sensitive weights, GraPacc deﬁnes a
relevance measure fitbetween a query and a pattern, in
order to rank the candidate patterns to a query. The details
of function fitand weights are presented next.
IV. Q UERY PROCESSING AND FEATURE EXTRACTION
GraPacc analyzes the query Q(i.e. the code under editing)
and extracts its context-sensitive features and weights in four
main steps: 1) tokenizing the input Qto extract lexical to-
kens, which could be used as token-based features; 2) using
Partial Program Analysis (PPA) tool [7] to parse the input
code into an AST; 3) building the corresponding Groum
from the AST; and 4) extracting the graph-based features
from that Groum, collecting the token-based features from
the un-parsable tokens (i.e. the tokens without associated
AST node), and determining the context-sensitive weights
for the extracted features.
1) Tokenizing: GraPacc breaks the code Qwithin
the current method into lexical tokens, records their loca-
tions, and computes their distances to the editing cursor.
After tokenizing, GraPacc keeps the keywords related to the
control structures (e.g. while,if,for,case, etc) and object
instantiation ( new). Unrelated keywords (e.g. public ,class,
void, etc) are not used in query formulating but kept for
later code completing.
2) Partial Parsing: If the current code under editing is not
parsable by Eclipse’s Java parser, GraPacc will use the PPA
tool [7] to handle the query. The PPA tool, as an Eclipse’s
plugin, accepts a portion of code and returns an AST with
all possible type binding information. However, in some
cases, there might exist some unresolved nodes, for example,
their types are undeterminable in the query. Thus, they are
assigned with an UNKNOWN type.
3) Groum Building: GraPacc constructs the correspond-
ing Groum from the AST provided by PPA in the previ-
ous step using the constructing algorithm from our prior
work [5]. Due to the incompleteness of the query code, the
unresolved nodes in the AST are discarded. They are consid-
ered as tokens and used to extract token-based features. The
data nodes corresponding to the variables of the data types
that are not resolved to fully qualiﬁed names are kept with
only simple names. Figure 5 shows the Groum built for theDisplay.new
Shell.new Display Shell
Button.new Button
FormData.new FormDatafocus node
Figure 5. Graph-based Usage Model of Query in Figure 3
query example in Figure 3. As seen, the objects shell,button ,
bData , and display are resolved to the data nodes labeled with
their types Shell,Button ,FormData , and Display , respectively.
Node Button is denoted as the focus node , because the token
closest to the editing cursor is button .
4) Feature Extracting and Weighting: In this step, Gra-
Pacc extracts the graph-based features from the Groum built
for the query, and other features for the retained tokens.
Feature Extracting . GraPacc ﬁrst maps each node in the
Groum built in the previous step back to the tokens built in
the Tokenizing step. For example, data node Button in the
Groum drawn in Figure 5 is mapped to three tokens of the
query listed in Figure 3: Button (line 4), button (line 4), and
button (line 6). The ﬁrst token denotes the type annotation
of the variable button corresponding to that data node, and
the two other tokens are the two references of that variable.
After the mapping, any token that does not correspond to
any node in the Groum is selected as a token-based feature.
Next, different features are extracted from various paths in
the Groum. Since there might be a large number of paths,
only the paths with limited sizes ( L≤3) are considered.
This limit were determined experimentally in our prior work
to achieve high accuracy in Groum matching [5]. Moreover,
using large-size features reduces performance signiﬁcantly
because the number of features increases exponentially to the
maximum size of features. From now on, we use the graph-
based feature and its corresponding path interchangeably.
Feature Weighting . When a feature (graph-based/token-
based) is extracted, its weight representing its context-
sensitive signiﬁcance is also computed as follows:
w(q) = (ws(q)+wc(q))×wf(q) (1)
a.ws(q)indicates the structure-based factor of feature q
via its size (from 1 to 3): ws(q) = 1+size(q). That is, a
longer feature represents more information, and is assigned
with higher weight. The rationale is that a long feature al-
lows GraPacc to capture stricter dependencies among several
nodes in the path for that feature. The addition of 1 aims to
reduce the relative difference between features of different
sizes, e.g. if minsize =1,maxsize =3, then (3+1)/(1+1) <
3/1, thus, making the effect of the size feature on the ﬁnal
weight in formula (1) smoother.DRAFTb.wc(q)models the structure-based factor of feature q
via the centrality of the corresponding nodes in the Groum.
The rationale is that if a node has high centrality in a
Groum, it plays an important role and can be better used
for matching. For example, feature Button.new is considered
to be more important than FormData.new in the query of
Figure 5 because the corresponding node for Button.new has
more dependencies to other nodes. Thus, if feature qhas
sizesand the nodes of the path corresponding to qhaven
neighbors, wc(q) =n/s.
c.wf(q)models the user-based factor of qvia its relation
to the current editing position, i.e. the focus node. For
example, Button is the focus node. Thus, feature Button.new
is considered to be more important than Shell.new .wf(q)is
computed based on the distance dbetween the focus node
and the path from which feature qis extracted: wf(q) =
1/(d+1) .dis computed as the length of the shortest path
from the focus node to a node in that path. Thus, if that path
contains the focus node, dis 0, and wf(q)is maximized. If
the path contains only the neighbors of the focus node, d
is 1, and wf(q)is 0.5.
Ifqis a token-based feature, its size is 1, thus, its size-
based weight wsis the same as the weight of a graph-based
feature of size 1. Its centrality-based weight wcis 0, because
no structural information is available. Its focus-based weight
wfis1/(d+1), withdbeing its distance to the token closest
to the focus editing point in the Groum.
In the formula (1), ws(q)andwc(q)are added together
whilewf(q)is multiplied since ws(q)andwc(q)represent
structure-based factors (feature’s size and centrality) and
wf(q)is for user-based factor (distance to the focus point).
They are context-sensitive information in different spaces.
V. P ATTERN MANAGING , SEARCHING AND RANKING
Pattern Management. The patterns can be automatically
imported from the mining results of the pattern mining tool,
GrouMiner [5], or be manually provided by the users. Each
pattern is stored as a Groum along with a textual template
code fragment [5]. A parameter Pr(P)is stored to represent
the popularity of pattern P. For the patterns mined from
codebase, GraPacc uses their occurrence frequencies in the
codebase for Pr(P). For user-provided patterns, the user can
either specify this parameter or a default value is assigned.
To support efﬁcient searching of patterns based on fea-
tures, GraPacc uses an inverse indexing mechanism. It
extracts the graph-based features from a pattern, and for
each feature p, it stores the list L(p)of patterns from which
featurepcould be extracted. For each extracted feature p,
GraPacc uses a weight s(p,P)to represent its signiﬁcance in
each pattern Pcontaining the feature p. The weight s(p,P)
is computed based on the Tf-Idf weighting scheme [8]:
s(p,P) =Np,P/NP.(logN−logNp)
Np,Pis the number of occurrences of feature pinP,NPis the total number of features in P,
Npis the number of patterns containing feature p, and
Nis the total number of patterns in the pattern database.
The inverse indexing list of patterns for each feature is
sorted according to those weights.
Searching and Ranking . Another crucial task is to search
and rank a list of relevant patterns for the code under editing
(i.e. a query). The core step is to compute the relevance
degrees of the candidate patterns to that query based on
the features and context-sensitive factors/weights computed
from the query. However, there are two following challenges:
a. Due to the incompleteness of the query, there might
be some extracted features that do not exist in the pattern
database (e.g. the features for the nodes whose types are un-
resolvable to fully qualiﬁed names). Thus, the features in the
pattern database (called pattern features ) might not exactly
match to the features in the query (called query features ).
b. The number of patterns in a database is often large, it is
inefﬁcient to compute the relevance degrees for all patterns.
For issue a, GraPacc uses the similarity function sim,
which will be explained next, to ﬁnd the features existing
in the pattern database that are best-matched to the query
features. If pis a pattern feature, qis a query feature, and
sim(p,q)≥δ, withδbeing a pre-chosen threshold, then p
is added to the set Fof the mapped features for q. GraPacc
uses this set to solve issue b. For each pattern feature p∈
F, the top- nranked patterns in its ranked inverse indexing
listL(p)are added to the list of candidate patterns Cfor
the relevance computation for q. After this step, GraPacc
computes the relevance measure function fit(P,Q)of each
candidate pattern P∈Cto the query Q, ranks them based
on those relevance degrees, and returns the ranked list of
patterns. Let us describe the functions sim andfit.
1) Feature Similarity sim.Function sim computes the
similarity between two features. Both graph-based features
and token-based features could be considered as a sequence
of labels/names, thus their similarity is computed mainly
based on the names of those labels. GraPacc deﬁnes the
similarity only for two features of the same size . The
similarity of two features p,qof sizekis computed as:
sim(p,q) =k∏
i=1nsim(pi,qi) (2)
in which nsim is the name-based similarity measure, and
piandqiare thei-th element of pandq, respectively. The
similarity degree of features with different sizes is zero.
In GraPacc, a standard label pihas the following form
X.Y.Z , in which Xis the qualiﬁed name of the package, Y
andZare the simple names of the class/method, respec-
tively.X,Y, orZmight be empty. For example, for a
data node, Zis empty. Sometimes, Xis empty since the
package name is unresolvable in the query. Thus, for twoDRAFTlabelsX.Y.Z andX′.Y′.Z′, its name-based similarity nsim
is deﬁned as
α×wsim(X,X′)+β×wsim(Y,Y′)+γ×wsim(Z,Z′)
α+β+γ
(3)
in which α,β, andγare weighting parameters, and wsim is
a word-based similarity value. If in a label, two correspond-
ing parts are missing, the corresponding term in formula (3)
is discarded. For example, if neither labels have the Xparts,
the ﬁrst term and its weight parameter αare discarded.
To compute the word-based similarity wsim of two
stringsXandX′, GraPacc ﬁrst breaks them into single
words using Camel convention. For example, StringBuffer is
broken into two words String and Buffer . Then, the similarity
of two labels, viewed as two sequences of words L(x)and
L(y), is deﬁned as Lo/Lm, in which Lois the length of their
longest common subsequence, and Lmis the average length
of two sequences. This scheme enables GraPacc to support
incompletely-typed and non-exact matched entity names.
GraPacc considers a token-based feature T(size 1) as
comparable to a graph-based feature of size 1 (with some
labelX.Y.Z ), because a token could be the name of a
variable or a method in the query and should be comparable
to the label of a Groum’s node of a pattern. In this case,
nsim is deﬁned as
max(wsim(T,X),wsim(T,Y),wsim(T,Z)) (4)
Themax function is used since a token in the current code
could be the name of either a package, class, or method.
2) Pattern Matching. GraPacc models two patterns P
andQas two sets of features, each feature has its own
signiﬁcance weight, and each pair of features has the
similarity measured by function sim. Thus, the relevance
measurement between PandQis based on the weighted
maximum bi-partite matching , i.e. matching each feature of
Pto a feature of Qin order to maximize the total similarity
and signiﬁcance between all matched pairs of features in
PandQ. The relevance degree between a pair of features
p∈P,q∈Qis computed as:
relevance (p,q) =s(p,P)×sim(p,q)×w(q) (5)
•s(p,P): the signiﬁcance of feature pin pattern P
according to the Tf-Idf scheme,
•w(q): the context-sensitive signiﬁcance of qin queryQ,
•sim(p,q): the similarity of two features.
The maximal weighted match for PandQis a map M
for each feature pofPto an unique feature qofQsuch
that the total weight of matched pairs
SM(P,Q) =∑
p∈P,q=M(p)relevance (p,q) (6)
is maximal among all possible maps. Because GraPacc also
considers the popularity Pr(P)of a candidate pattern, therelevance degree of the pattern Pto the query Qis computed
as follows:
fit(P,Q) =SM(P,Q)×Pr(P) (7)
VI. P ATTERN -ORIENTED CODE COMPLETION
If the user chooses a pattern Pin the recommended list,
GraPacc will complete the code in the query Qaccording to
patternP. Generally, to do that, GraPacc ﬁrst matches the
code inPandQto ﬁnd the code in Pthat has not appeared
inQ. Then, it ﬁlls such code into Qin accordance with the
context in Q, i.e. at the appropriate locations in Qand with
the proper names.
Let us ﬁrst explain the general idea via an example. Let
us revisit the query example in Figure 5 (the corresponding
code is in Figure 3) and assume that a user selects pattern
c) in Figure 4 (the corresponding code is in Figure 2).
GraPacc ﬁrst determines that the two Button.new nodes, the
two FormData.new nodes, the two Button nodes, and the two
FormData nodes in the two Groums are respectively matched.
That is, two object initializations and the assignment to the
variables for Button and FormData already existed in the query.
Compared with pattern P, the nodes that have not used
include Button.setText and Button.setLayoutData . Thus, GraPacc
uses the code corresponding to those nodes to ﬁll in Q.
The code completing task is done via creating the cor-
responding sub-trees in the AST of Qat the appropriate
positions and with the proper names for the ﬁelds and
variables. For example, to ﬁll in Button.setLayoutData , it ﬁrst
needs to create that method call and ﬁnd its position in the
AST ofQ(not shown). In this case, the position is next
to the variable node button in the AST of Q. Since in the
pattern, Button.setLayoutData has a parameter of type FormData
(Figure 4c), GraPacc must ﬁll in that parameter with a proper
name. From pattern P, that parameter must be from the
FormData node (Figure 4c), which is matched to FormData in
Q(Figure 5). It in turn corresponds to the variable formData
inQ(Figure 3). Thus, GraPacc chooses the name formData
and ﬁlls in line 6 of Figure 3. Similar process is used for
Button.setText , which is added between lines 4-5 of Figure 3.
Therefore, the ﬁnal result is:
1Button button = new Button(shell, SWT.PUSH);
2button.setText( );
3FormData formData = new FormData();
4button. setLayoutData(formData);
Let us describe the algorithm in details.
A. Matching Groum Nodes in Pattern and Query
GraPacc performs code matching on QandPon their
Groums, i.e. for each node vinP, it determines the best
matched node uinQ(Figure 6). To do so, it retrieves
two sets of features F(u)andF(v)corresponding to the
paths through uandv, respectively. It then runs a weightedDRAFT1function GroumNodeMatching( GQ,GP)
2foreach node uinGQ
3foreach node vinGP
4 // ﬁnding best matching between two sets of features
5 BipartiteMatching( F(u),F(v), relevance( p,q)) withp∈F(u),
q∈F(v)
6 match(u,v) = max(∑{relevance( p,q)})//matching level for (u,v)
7// ﬁnding the sets of best −matched nodes in PandQ
8BipartiteMatching( GQ,GP,match (u,v))
9Return the mapping Mforthe nodes in GQandGP
Figure 6. Groum Node Matching between Pattern Pand Query Q
bipartite matching algorithm with the weights being mea-
sured via relevance function (line 5). The matching degree
betweenuandvis measured by the sum of the relevance
degrees corresponding to the best matching (line 7). After
computing all matching degrees for all uandv, GraPacc
performs bipartite matching to ﬁnd maximal aligned sets of
nodes in QandP(line 9). Then, it returns the mapping
M, i.e.M(v) =umeans that v∈Pis matched to
u∈Q, andM(v) =null ifvis not matched to any
node inQ. For example, while matching the Groums for
Qin Figure 5 and for Pin Figure 4c, it determines that
Button.new ,FormData.new ,Button , and FormData have matches.
Button.setText and Button.setLayoutData are unmatched nodes.
B. Completing the Query Code
After having the mapping, GraPacc performs code com-
pleting (Figure 7). It traverses the un-matched nodes in the
Groum of pattern Pin a breadth-ﬁrst order and for such a
node, it ﬁnds the corresponding AST’s subtree at that node
in the AST of pattern Pvia the stored template code of P.
Then, it clones that sub-tree (line 4) and updates the name
attributes of the nodes of that sub-tree in accordance with
the code in Q(line 5). After that, it ﬁnds the proper position
for that sub-tree in the AST of Q(line 6) and attaches it to
the AST via Eclipse’s AST editing support (line 7).
1) Finding Appropriate Names for Variables before
Filling-in ( updateName ):Since variables in PandQgener-
ally are named differently, to be able to ﬁll in a variable in P
intoQ, GraPacc needs to update its name accordingly. For
example, although two data nodes FormData in Figure 4c and
Figure 5 are matched, the corresponding variables in ASTs
arebData and formData . To ﬁnd such proper name, GraPacc
uses the mapping M: if node v∈Pis matched to u∈Q,
then the relevant name for the variable involving vwill be
u’s name; if vis unmatched, but is the reference/declaration
of a variable corresponding to a matched node v′∈P, the
relevant name for the variable involving vwill bev′’s name.
Otherwise, the relevant name for vwill be kept the same as
inP. However, to avoid accidental duplicate names in P
with those in Qas the code is ﬁlled in at the next step, for
all nodes that are not matched and not renamed, if they have
the same names with any nodes in Q, they are renamed with
new indexes being added.1function CodeCompletion( M,P,Q)
2 // cloning AST nodes ofthe unmatched nodes from PtoQ
3 foreach node vsuch that M(v) =null :
4T= clone(ASTP,v)
5 updateName( T,M)
6 pos = ﬁndPosition ( ASTQ,T)
7 updateQueryCode( T,ASTQ, pos)
Figure 7. Code Completion from Pattern Pto Query Q
Table I
TRAINING DATA FOR JAVA UTILITY PATTERNS
Project Files Methods using Java Util Mined Patterns
EclipseME 137 619 28
AspectJ 1,053 5,859 155
Codehaggis 20 52 4
Unitmetrics 34 103 10
2) Finding the Position for an Unmatched Node vinP
within the AST of Q(ﬁndPosition ):Its position is determined
via the relative position of vwith respect to the matched
nodes in its neighbors in P. For example, to ﬁnd the location
to ﬁll Button.setText intoQ, GraPacc determines that in P,
that node follows Button.new . According to the sequential
order in the code of P(Figure 2), it comes before FormData .
With the mapping for those nodes, its location is determined
as between two AST nodes corresponding to line 4 and line
5 of Figure 3. The following neighboring relations of vin
a pattern are used to determine the relative positions:
•vis the initialization of a variable declaration,
•vis a parameter of a method invocation,
•vis in a conditional expression or the body of an ifnode,
•vis a control node/ method call having the matched nodes.
•vis a node having a sequential order with matched nodes.
If GraPacc cannot ﬁnd the relative position for v(e.g. no
matched node as a pivot), the current focus point is used.
Note that GraPacc’s code completion can be invoked on
demand at any point in the currently edited code. It can
search for a pattern that appears non-contiguously since it
captures control/data dependencies among the elements in an
API usage backward and forward from the invoking point.
Thus, it can support both programming styles: writing line-
by-line, and creating code skeleton and then ﬁlling in.
VII. E MPIRICAL EVALUATION
This section presents our experimental studies to evaluate
GraPacc’s accuracy in code completion. GraPacc is realized
as an Eclipse plug-in. All experiments were carried out on a
machine with CPU AMD Phenom II 3.0 GHz, 8GB RAM.
A. Experiment Setting
Java SDK Utility (java.util, java.io) [9] was chosen since it
contains a rich set of usages and many open-source systems
have used its APIs. We collected a total of 28 open-source
Java projects using Java Utility library. We then used our
pattern mining tool, GrouMiner [5], to collect API patternsDRAFT1Scanner scanner = new Scanner( new File (”C:/sample.dat”));
2ArrayList <String>list = new ArrayList <String>();
3while (scanner.hasNext()) {
4 list .add(scanner.next());
5}
6StringBuffer strBuf = new StringBuffer();
7Iterator itr = list . iterator () ;
8while ( itr .hasNext())
9{
10 String str = itr .next() + ” : ” ;
11 strBuf.append (str);
12}
13System.out.println(strBuf. toString () ) ;
Figure 8. An Example of a Test Method
of Java Utility from a set of 4 Java projects, which were
used as the tool’s knowledge (Table I). Other 24 projects
were used for evaluation (Table II). Eventually, we had 197
patterns in our database with 1,288 features.
We built an automatic evaluation tool and for each subject
project, we ﬁrst used it to collect all methods using Java
Utility. For such a method, we simulated a real programming
situation. We assumed that a developer partially ﬁnished
his/her coding in that method and requested the help from
GraPacc. Thus, we divided the code of the method under
testing (called a test method ) into two parts: the ﬁrst part
was used as a query, and the second for evaluation.
We followed a similar automatic evaluation process for a
code completion tool as in Bruch et al. [2]. Let us explain
the procedure of handling a test method via an example
in Figure 8. Our evaluation tool ﬁrst collected from the
test method all occurrences of the API elements including
method calls, object creation, data variables, and control
structures that are related to Java Utility. It sorted them in
the order of their occurrences in the test method. The one
at the middle position of that sorted list was chosen as the
cut point (focus point). The ﬁrst part of the test method
from its beginning to the cut point was used as a query for
evaluation. The rationale for this way of selecting a focus
point at the middle point is to avoid the cases in which no
Java Utility API element appears in the ﬁrst part or none
of them is left in the second part of the test method. For
Figure 8, the query is as follows:
...
StringBuffer strBuf = new StringBuffer();
Iterator itr =
B. Evaluation Metrics
For each given query, GraPacc was invoked and it returned
a ranked list of patterns. Assume that a pattern was selected,
and GraPacc would complete the code. Let us use OandR
to denote the original and the resulting code (from GraPacc)
in the second half of the test method, respectively. As
explained, there might be no speciﬁc order between two
API elements. If we compared directly RtoObased on theirtexts, the evaluation would be imprecise since a correct result
from GraPacc might not match exactly the writing order of
API elements in O. Moreover, the goal was to evaluate how
well GraPacc completed for Java Utility elements (rather
than other elements). Thus, we compared the Groum of the
resulting code Rwith that of the original code O.
Let us call their respective Groums GRandGO. If a
node inGRmatches with a node in GO, we count it as
ancorrectly suggested node. If a node in GRdoes not
occur inGO, we count it as an incorrect noden(because a
user would need to delete the corresponding code from the
recommended code). If a node in GOdoes not occur in GR,
we consider this as a missing nodem(i.e. the user would
need to manually add the corresponding code after code
completion). Note that, the original method Omight use API
elements that do not belong to Java Utility, in which GraPacc
has no knowledge. Thus, we counted only the missing nodes
inGOrelevant to that library.
Accuracy is measured via precision ,recall , and f-score .
Precision is deﬁned as the ratio of the number of cor-
rectly recommended nodes over the total number of all
recommended nodes. Recall is the ratio of the number of
correctly recommended nodes over the total number of
completion-needed nodes. We also computed f-score, a
harmonic average of precision and recall: f-score = 2 / (1/
precision + 1/recall) . Higher f-score means better accuracy.
C. Experiment Procedure
Our evaluation tool ran GraPacc on each test method
and a ranked list of patterns was returned. To simulate a
real coding situation in which a user would choose the
desired pattern (i.e. the most similar one), our evaluation
tool selected the pattern with the highest f-score in the top-
5 list of the recommended patterns returned by GraPacc.
A method under test mmight contain multiple Java Utility
API patterns. Thus, in practice, a user might need to invoke
GraPacc multiple times to get sufﬁcient recommendations
to complete the second half of m. To simulate that, our
evaluation tool iteratively invoked GraPacc at multiple focus
points in the second half of m. At each iteration, the tool
selected an additional focus point, invoked GraPacc and
picked the pattern with highest f-score in the top-5 patterns,
and counted the numbers of (in)correct/missing nodes. The
process continued until all API elements in the second
half were completed or no new API elements/nodes can be
correctly added (i.e. alladded API elements are incorrect).
This second condition simulates the case where the user
does not ﬁnd the correct API elements returned by GraPacc
and continues coding. In each iteration, for the process to
continue, at least one of API elements must be ﬁlled. Thus,
the maximum number of iterations is equal to the number
of API elements in the second part of m.
The selection mechanism for the additional focus points
with multiple iterations is based on the variables that existedDRAFTTable II
CODE COMPLETION ACCURACY RESULT
System Methods Patterns Variables Calls Controls Correct Incorrect Missing Precision Recall F-score
anyedittools 81 95 151 251 74 200 22 58 90.1% 77.5% 83.3%
apache-axiom 598 689 801 1,386 415 1,084 269 509 80.1% 68.0% 73.6%
apache-ivy 1,400 1,923 2,121 4,291 1,620 4,480 580 1,482 88.5% 75.1% 81.3%
apache-roller 1,443 1,738 1,879 3,378 1,147 3,205 536 1,501 85.7% 68.1% 75.9%
Aribaweb 1,866 2,344 4,000 7,057 2,173 5,538 1,340 2,967 80.5% 65.1% 72.0%
cayene 4,476 4,653 5,305 8,072 2,598 6,391 1,560 3,537 80.4% 64.4% 71.5%
cvsgrapher 39 55 57 99 38 95 8 32 92.2% 74.8% 82.6%
dom4j-1.6.1 565 660 764 1,324 415 1,274 107 375 92.3% 77.3% 84.1%
dvsl 46 53 56 67 28 69 4 19 94.5% 78.4% 85.7%
geronimo 92 114 273 398 142 356 88 128 80.2% 73.6% 76.7%
jibx 843 949 1,046 1,675 514 1,412 299 569 82.5% 71.3% 76.5%
Jlibrary 474 612 676 1,253 464 1,385 170 384 89.1% 78.3% 83.3%
jnormalform 194 450 582 1,178 348 1,184 156 254 88.3% 82.3% 85.2%
OPENWFE 1,331 1,687 1,957 4,052 1,256 3,993 598 1,139 87.0% 77.8% 82.1%
PetriEditor 37 50 53 106 49 137 10 12 93.2% 91.9% 92.6%
quack 36 46 67 81 32 64 13 37 83.2% 63.4% 72.0%
RONEditor 366 436 446 838 350 878 144 320 85.9% 73.3% 79.1%
schemaeditor 149 209 262 574 211 606 32 105 95.0% 85.2% 89.8%
sdiff 506 673 943 2,609 1,123 2,405 412 1,131 85.4% 68.0% 75.7%
syper 112 167 191 419 212 375 90 187 80.1% 66.7% 72.9%
varia 158 256 436 949 274 854 128 298 87.0% 74.1% 80.0%
VOCL 189 214 461 733 266 583 66 183 89.8% 76.1% 82.4%
xaware 161 212 222 491 274 498 93 232 84.3% 68.2% 75.4%
xmlrpc 26 28 29 55 35 56 9 33 86.1% 62.9% 72.7%
15,188 18,313 22,778 41,336 13,990 37,122 6,734 15,492 84.6% 71.0% 77.0%
in the query Oand the newly added variables via code
completion. The evaluation tool maintains a priority queue
Dof variables. For the ﬁrst cut point, this queue Dwas
initialized with all variables in the ﬁrst half of the test
method. The variables with shorter distances to that focus
point were placed in the front of D. If a variable appears
multiple times, the distance of only its last occurrence is
measured to the current focus point. Thus, the list Dcontains
a variable at most once. For example, for Figure 8, initially,
D=[itr,strBuf ,scanner ,list]. GraPacc completed the code at
the ﬁrst iteration as follows:
...
StringBuffer strBuf = new StringBuffer();
Iterator itr = list . iterator () ;
while ( itr .hasNext()) {
itr .next() ;
}
To select a new focus point, the evaluation tool considered
all variables of any types in the newly added code recom-
mended by GraPacc. It ﬁrst added those variables in the front
of the queue D, based on their distance to the current focus
point. If a variable exists in the queue, it will be moved to
the front. Finally, the variable that was just processed will be
put at the tail of the queue. For example, the queue Dwas
updated as follows: 1) listwas moved to the front because
it was the only added element, and 2) itrwas placed at the
tail ofD. Thus,D=[list,strBuf ,scanner ,itr]. The variable at
the front of Dwas then selected to be processed next, i.e.
the variable list. The last occurrence of that variable in the
new code after completion at this iteration was chosen to
be the next focus point because its prior occurrences might
not provide as much context to expand a new pattern. In the
example, the next focus point was at Iterator itr = list.iterator(); .This scheme of selecting a new focus point simulates the
real situation in which a user would focus on the variable
that was most recently completed by GraPacc. This proce-
dure is applied to each test method. The numbers of (in)-
correct/missing elements are accumulated for all test meth-
ods and iterations. Precision, recall, and f-score are compu-
ted from the accumulated numbers for entire subject system.
D. Accuracy Result
We ran our evaluation tool with the above procedure. The
parameters are chosen as follows: γ=0.6,β=α=0.2,δ=0.9.
They are not representative and were chosen after ﬁne tuning
for this experiment. Column Methods in Table II shows the
number of test methods. Columns Patterns ,Variables ,Calls,
and Controls show the number of the recommended patterns
and the numbers of involved variables, method calls, and
control nodes in those patterns, respectively. Columns Cor-
rect,Incorrect , and Missing display the numbers of (in)correctly
recommended and missing API elements. As seen, GraPacc
suggested 18,313 API patterns with 22,778 variables, 41,336
calls, and 13,990 control nodes. At each iteration, GraPacc
ﬁlled in one pattern. In total, it ﬁlled in 18,313 patterns
for 15,188 methods (Table II). Thus, it took on average
1.2 iterations to converge. It achieves very high accuracy,
with up to 95% precision, 92% recall, 93% f-score. The
accumulated result shows that precision, recall, and f-score
values are 84.6%, 71%, and 77%, respectively. Interestingly,
the average recall of 71% suggests that about 71% of an
API’s usage in a project is covered by API usage patterns.
We also analyzed the incorrect and missing cases and
found a few sources of inaccuracy. First, a usage scenario
requires an extra API call. This affects GraPacc’s accuracy,DRAFThowever, in practice, users can easily customize usage pat-
terns. The second cause is due to the missing patterns in our
evaluation database. The third cause is when an API usage
spans two methods and GraPacc’s suggestion is redundant.
Time Efﬁciency. In this experiment, we used GrouMiner [5]
to mine the patterns from all 28 subject systems to col-
lect 977 usage patterns in 7 libraries (6,378 API elements,
4,905 distinct features). We ran GraPacc on the same set of
15,188 test methods (Table II). The time for each query with
handling, searching, and ranking the candidate patterns, and
code ﬁlling is about 0.7s. Thus, it is very time efﬁcient.
Threats to Validity. We used a simulation for users’ editing
actions, rather than true editing. The focus point selection
might not reﬂect well users’ editing. Another threat is the
insufﬁcient patterns mined from GrouMiner.
VIII. R ELATED WORK
Code Completion. Bruch et al. [2] propose three code
completion algorithms to suggest the method call for a single
variable under editing based on code examples in a database.
The ﬁrst one, FreqCCS, suggests the method that is most
frequently used in the database. The second one, ArCCS,
mines the associate rules A→Bin which if method Ais
used, method Bis often called and will be suggested.
In contrast to mining a single, most frequently used
method call in FreqCCS and the most frequent pair of
method calls in ArCCS, GraPacc suggests the usage pat-
terns (i.e. most frequently used graph-based API usages),
which contain all involved method calls, variables, and
control structures of the usages. Thus, GraPacc represents
better the current context . Such context is important in
code completion (Section II). The features in FreqCCS and
ArCCS correspond to individual nodes (for method calls)
and individual edges (for pairs of calls) in our Groum.
Importantly, GraPacc can handle multiple variables in one
ormultiple types , while they focus only on completing the
method call for the single variable under editing.
The third algorithm, BMN (best-matching neighbors),
adapts k-nearest-neighbor algorithm to recommend for a
variablev. BMN encodes the current context and the exam-
ples in the database as binary feature-occurrence vectors [2].
The features for a context are the un-ordered set of method
calls ofvin the currently edited code and the names of the
methods that use v. The set of vectors of examples with
the same smallest Hamming distance to the query vector is
called the BMN set. Then, BMN ranks the methods based
on their frequencies in the examples in the BMN set.
In comparison, GraPacc has several key advances over
BMN. First, GraPacc captures richer contextual information
of the code under editing, with all ordered method calls,
multiple variables , and control structures in API usages,
while BMN represents a context by an un-ordered set of
method calls of a single variable . Second, with the use
of API patterns (i.e. correct usages) as a guidance forcode completion, GraPacc can make better context-sensitive
method call completion when there exist alternative patterns
(Section II). Importantly, it can handle multiple variables in
different types in a usage. Finally, with API usage patterns,
GraPacc recommends more code elements .
Hill and Rideout [4]’s code completion approach relies
on code clones. It matches the fragment under editing with
small similar-structure code clones, and then performs trans-
formations for code completion. GraPacc leverages code
similarity at the API-usage level. Robbes and Lanza [3]
propose 6 strategies to improve code completion using recent
histories of modiﬁed/inserted code during an editing session.
GraPacc has an advance in supporting code completion for
multiple variables in different types, while their approach
focuses on a single method call. Eclipse [1] and other
IDEs [10], [11] complete for the call of a variable. Eclipse
supports template-based completion for common construct-
s/APIs ( for/while,Iterator ) without considering the context.
Example Code Search. MAPO [6] mines and indexes
API usage patterns and recommends the associated code
examples . It does not support auto-completion. Its pattern
is sequential rules of method calls. It does not progressively
update resulting patterns as context changes. Strathcona [12]
extracts the structural context of the code under editing
and ﬁnds its relevant examples. It does not aim for code
completion. Structural context includes inheritance relation-
ships, overridden methods, and caller/callee methods of
current code. Mylyn [13], a code recommender, learns from
a developer’s personal usage history and suggests related
methods. Personal usage history and structural context could
provide the useful guide for GraPacc.
Code searching techniques based on program analysis in-
clude Prospector [14], XSnippet [15], PARSEWeb [16],
Reiss [17]’s. Other approaches use information retrieval [18],
[19], [20], [21]. Static analysis is used to extract API patterns
into ﬁnite state machine [22], pairs of calls [23], [24], [25],
partial orders of calls [26]. Other pattern mining approaches
include [27], [28], [29], [30], [31], [32], [33], [34], [35].
IX. C ONCLUSIONS
We introduce GraPacc, a code completion tool that helps
complete the code under editing based on a database of us-
age patterns. It extracts the context features from the current
code and uses them to search and rank the patterns that are
best-ﬁtted. As a pattern is chosen, it ﬁlls in the code with
proper code elements. Empirical evaluation results show that
GraPacc can achieve high accuracy in code completion up
to 95% precision, 92% recall, and 93% f-score. GraPacc’s
video demo and tool information can be found at [36].
ACKNOWLEDGMENT
This project is funded by US National Science Foundation
(NSF) CCF-1018600 grant. It was also funded in part by
Vietnam Education Foundation for the ﬁrst and ﬁfth authors.DRAFTREFERENCES
[1] “Eclipse,” www.eclipse.org.
[2] M. Bruch, M. Monperrus, and M. Mezini, “Learning from
examples to improve code completion systems,” in ESEC/FSE
’09. ACM, 2009, pp. 213–222.
[3] R. Robbes and M. Lanza, “How program history can improve
code completion,” in ASE ’08 . IEEE CS, 2008, pp. 317–326.
[4] R. Hill and J. Rideout, “Automatic method completion,” in
ASE ’04 . IEEE CS, 2004, pp. 228–235.
[5] T. T. Nguyen, H. A. Nguyen, N. H. Pham, J. M. Al-Kofahi,
and T. N. Nguyen, “Graph-based Mining of Multiple Object
Usage Patterns,” in ESEC/FSE ’09 . ACM Press, 2009.
[6] H. Zhong, T. Xie, L. Zhang, J. Pei, and H. Mei, “Mapo:
Mining and recommending api usage patterns,” in ECOOP
2009 . Springer-Verlag, 2009, pp. 318–343.
[7] B. Dagenais and L. Hendren, “Enabling static analysis for
partial java programs,” in OOPSLA ’08 . ACM, 2008, pp.
313–328.
[8] G. Salton and C. Yang, “On the speciﬁcation of term values
in automatic indexing,” Journal of Documentation , vol. 29,
no. 4, pp. 351–372, 1973.
[9] “Java sun,” java.sun.com.
[10] “Intellisense,” http://blogs.msdn.com/b/vcblog/archive/tags/
intellisense/.
[11] “Informer,” http://javascript.software.informer.com/download-
javascript-code-completion-tool-for-eclipse-plugin/.
[12] R. Holmes and G. C. Murphy, “Using structural context to
recommend source code examples,” in ICSE ’05 . ACM,
2005, pp. 117–125.
[13] M. Kersten and G. C. Murphy, “Using task context to improve
programmer productivity,” in SIGSOFT ’06/FSE-14 . ACM,
2006, pp. 1–11.
[14] D. Mandelin, L. Xu, R. Bod ´ık, and D. Kimelman, “Jungloid
mining: helping to navigate the api jungle,” in PLDI ’05 .
ACM, 2005, pp. 48–61.
[15] N. Sahavechaphan and K. Claypool, “XSnippet: mining For
sample code,” in OOPSLA ’06 . ACM, 2006, pp. 413–430.
[16] S. Thummalapenta and T. Xie, “Parseweb: a programmer
assistant for reusing open source code on the web,” in ASE
’07. ACM, 2007, pp. 204–213.
[17] S. P. Reiss, “Semantics-based code search,” in ICSE ’09 .
IEEE CS, 2009, pp. 243–253.
[18] “Koders,” www.koders.com.
[19] “Google Code Search,” www.google.com/codesearch.[20] M. Grechanik, C. Fu, Q. Xie, C. McMillan, D. Poshyvanyk,
and C. Cumby, “A search engine for ﬁnding highly relevant
applications,” in ICSE ’10 . ACM, 2010, pp. 475–484.
[21] Y . Ye, G. Fischer, and B. Reeves, “Integrating active infor-
mation delivery and reuse repository systems,” in SIGSOFT
’00/FSE-8 . ACM, 2000, pp. 60–68.
[22] A. Wasylkowski, A. Zeller, and C. Lindig, “Detecting object
usage anomalies,” in ESEC-FSE ’07 . ACM, 2007, pp. 35–44.
[23] D. Engler, D. Chen, S. Hallem, A. Chou, and B. Chelf, “Bugs
as deviant behavior: a general approach to inferring errors in
systems code,” in SOSP ’01 . ACM, 2001, pp. 57–72.
[24] B. Livshits and T. Zimmermann, “Dynamine: ﬁnding com-
mon error patterns by mining software revision histories,”
SIGSOFT Softw. Eng. Notes , vol. 30, no. 5, pp. 296–305,
2005.
[25] C. C. Williams and J. K. Hollingsworth, “Automatic mining of
source code repositories to improve bug ﬁnding techniques,”
IEEE Trans. Softw. Eng. , vol. 31, no. 6, pp. 466–480, 2005.
[26] M. Acharya, T. Xie, J. Pei, and J. Xu, “Mining api patterns
as partial orders from source code: from usage scenarios to
speciﬁcations,” in ESEC-FSE ’07 . ACM, 2007, pp. 25–34.
[27] M. Gabel and Z. Su, “Javert: fully automatic mining of gen-
eral temporal properties from dynamic traces,” in SIGSOFT
’08/FSE-16 . ACM, 2008, pp. 339–349.
[28] J. Yang, D. Evans, D. Bhardwaj, T. Bhat, and M. Das,
“Perracotta: mining temporal api rules from imperfect traces,”
inICSE ’06 . ACM, 2006, pp. 282–291.
[29] G. Ammons, R. Bod ´ık, and J. R. Larus, “Mining speciﬁca-
tions,” in POPL ’02 . ACM, 2002, pp. 4–16.
[30] S. Shoham, E. Yahav, S. Fink, and M. Pistoia, “Static speci-
ﬁcation mining using automata-based abstractions,” in ISSTA
’07. ACM, 2007, pp. 174–184.
[31] M. K. Ramanathan, A. Grama, and S. Jagannathan, “Path-
sensitive inference of function precedence protocols,” in ICSE
’07. IEEE CS, 2007, pp. 240–250.
[32] D. Lo and S. Maoz, “Mining scenario-based triggers and
effects,” in ASE ’08 . IEEE CS, 2008, pp. 109–118.
[33] R. Alur, P. ˇCern ´y, P. Madhusudan, and W. Nam, “Synthesis of
interface speciﬁcations for java classes,” in POPL ’05 . ACM,
2005, pp. 98–109.
[34] T. A. Henzinger, R. Jhala, and R. Majumdar, “Permissive
interfaces,” in ESEC’05/FSE-13 . ACM, 2005, pp. 31–40.
[35] C. Liu, E. Ye, and D. J. Richardson, “Software library usage
pattern extraction using a software model checker,” in ASE
’06. IEEE CS, 2006, pp. 301–304.
[36] http://home.engineering.iastate.edu/%7Eanhnt/Research/
GraPacc/.