To be presented at ICSE 2010 ( http://www.sbs.co.za/ICSE2010/ ). 
  Hazeline U. Asuncion, Arthur U. Asuncion, Ri chard N. Taylor.  Software Traceability 
with Topic Modeling.  ACM/IEEE 32
nd International Conference on Software 
Engineering.  May 2010 (to appear). SoftwareTraceabilitywithTopic Modeling
HazelineU. Asuncion
InstituteforSoftware
Research
University of California, Irvine
hasuncio@ics.uci.eduArthur U.Asuncion
Center forMachine Learning
and Intelligent Systems
University of California,Irvine
asuncion@ics.uci.eduRichard N.Taylor
Institutefor Software
Research
University of California,Irvine
taylor@ics.uci.edu
ABSTRACT
Software traceability is a fundamentally important task in
software engineering. The need for automated traceability
increases as projects become more complex and as the num-
ber of artifacts increases. We propose an automated tech-
nique that combines traceability with a machine learning
technique known as topic modeling. Our approach auto-
matically records traceability links during the software de-
velopment process and learns a probabilistic topic model
over artifacts. The learned model allows for the semantic
categorization of artifacts and the topical visualization of
the software system. To test our approach, we have im-
plemented several tools: an artifact search tool combining
keyword-based search and topic modeling, a recording tool
that performs prospective traceability, and a visualization
tool that allows one to navigate the software architecture
and view semantic topics associated with relevant artifacts
and architectural components. We apply our approach to
several data sets and discuss how topic modeling enhances
software traceability, and vice versa.
Categories andSubjectDescriptors
D.2.7 [Software Engineering ]: Distribution, Maintenance,
and Enhancement— Documentation ; D.2.9 [ Software En-
gineering ]: Management; G.3 [ Mathematics of Com-
puting ]: Probability and Statistics— Probabilistic algorithms ;
H.3.3 [ Information Systems ]: Information Storage and
Retrieval— Information Search and Retrieval
GeneralTerms
Documentation, Management
Keywords
Software Traceability, Topic Model, Latent Dirichlet Allo-
cation, Software Architecture
Permission to make digital or hard copies of all or part of this w ork for
personal or classroom use is granted without fee provided th at copies are
not made or distributed for proﬁt or commercial advantage and th at copies
bearthisnoticeandthefullcitationontheﬁrstpage. Tocop yotherwise, to
republish,topostonserversortoredistributetolists,re quirespriorspeciﬁc
permission and/orafee.
ICSE’10, May2-82010,CapeTown, SouthAfrica
Copyright2010ACM 978-1-60558-719-6/10/05...$10.00.1. INTRODUCTION
Large-scale industrial projects are often comprised of thou-
sands of software development artifacts, such as require-
ments documents, design documents, code, bug reports, and
test cases. The goal of software traceability is to discover re-
lationships between these artifacts to facilitate the eﬃcient
retrieval of relevant information, which is necessary for many
software engineering tasks [4]. While fully manual traceabil-
ity approaches are typically only feasible for small projects,
automated techniques also encounter diﬃculties in practice
due to the lack of accuracy and the high level of false posi-
tive trace links generated [15, 24]. In this paper, our main
contribution is a scalable approach to traceability based on a
combination of automated link capture and topic modeling.
The traceability problem can be tackled both retrospec-
tively and prospectively. In retrospective traceability, ar-
tifact relationships are inferred ex post facto from a static
set of artifacts. Automated approaches such as information
retrieval techniques generally perform traceability retrospec-
tively. In contrast, prospective traceability generates trace
linksin situ , as artifacts are being created and modiﬁed dur-
ing the development process. Prospective capture is the cre-
ation of putative links between artifacts based upon directly
observed actions of the user on those artifacts. While we dis-
cuss the application of topic modeling in the retrospective
setting, we mainly focus on the combination of prospective
traceability and topic modeling in this paper.
There are several key beneﬁts of the prospective approach.
Prospective traceability allows for links to be captured in an
online fashion, incrementally improving the system’s trace-
ability and allowing developers to immediately beneﬁt from
the trace links created [9]. Another beneﬁt of prospective
traceability is the presence of additional captured informa-
tion, such as the temporal sequence of user actions in the
design environment, which can be used to automatically gen-
erate trace links to heterogeneous artifacts.
Machine learning and information retrieval techniques have
been used in the past to automatically generate traceabil-
ity links [23, 25]. In particular, Latent Semantic Indexing
(LSI) [20] has made signiﬁcant inroads into the area of au-
tomated traceability [27, 41]. More recently, probabilistic
topic models such as Latent Dirichlet allocation (LDA) [12]
have been used for source code analysis [30, 31, 46]. LDA is
an unsupervised machine learning technique that facilitates
the automatic learning of semantic topics from the set of ar-
tifacts without requiring previous training data with train-
ing labels. Usually, these approaches have exclusively fo-
cused on retrospective traceability. In contrast, we proposeincorporating the LDA model into the task of prospective
traceability. Another diﬀerence from previous LDA-based
work is that we do not focus solely on source code analysis
but rather investigate an architecture-centric approach [44]
which creates trace links for all types of artifacts produced
in the software development life cycle.
We argue that a positive symbiosis exists between prospec-
tive capture and topic modeling. Prospective link capture
helps to identify a larger amount of potentially related arti-
facts (through observation of user actions), which gives rise
to a more diverse and semantically-coherent set of “learned”
topics. Meanwhile, these learned topics enhance the process
of prospective capture through the visualization of the topi-
cal content of the software architecture and the eﬃcient re-
trieval of semantically-similar artifacts. Furthermore, while
topic modeling cannot be applied to certain types of arti-
facts (like sound or video ﬁles), prospective link capture can
still trace to these artifacts by taking advantage of recorded
temporal user actions. Conversely, prospective link capture
is inadequate at determining the semantic nature of arti-
facts, a task at which topic modeling excels. Thus, these
two techniques tightly complement each other. Note that
existing retrospective machine learning techniques can also
complement our prospective approach.
In the next section, we discuss the current state of soft-
ware traceability research and discuss strategies for eﬀec-
tive traceability. We then provide a brief overview of topic
modeling techniques. We detail our approach of combining
prospective traceability with topic modeling. Then we de-
scribe several tools that demonstrate the feasibility of our
approach and show results on several data sets. We then
conclude with future research directions.
2. SOFTWARETRACEABILITY
The practical realization of software traceability is known
to incur high overhead, and thus there has been a concerted
eﬀort to automate the generation of trace links. We high-
light the current state of the art in both retrospective and
prospective traceability, and we also discuss insights into ef-
fective traceability which guide our approach.
2.1 Retrospective traceability
Most automated traceability techniques fall under the cat-
egory of retrospective traceability. Information retrieval tech-
niques such as the Vector Space Model and Latent Semantic
Indexing have been used to automatically generate candi-
date links based on textual similarity between artifacts [15,
19, 25, 27]. Other machine learning techniques have also
been combined with program analysis and run-time moni-
toring to automatically link source code to use cases [23].
Probabilistic topic models like Latent Dirichlet Allocation
have been used to mine semantic topics from source code.
In particular, LDA has been used to automatically catego-
rize code [46], and LDA topics have been interpreted to be
analogous to cross-cutting concerns in aspect-oriented pro-
gramming [10]. We discuss LDA in depth in Section 3.
Visualization techniques have been proposed to support
the eﬃcient identiﬁcation of correct links. Duan and Cleland-
Huang use cluster-based techniques to group candidate trace
results that are presented to the user [22]. Other visual-
ization techniques include tag clouds to graphically display
term frequencies and a tree structure to represent the hierar-
chical structure in a requirements document [14]. Visualiza-tion is an important aspect of traceability as it allows users
to verify the quality of trace links. As we will see later in
the paper, topic modeling provides useful semantic informa-
tion that can be used to visualize the semantic relationships
between the traced artifacts and software architecture.
2.2 Prospectivetraceability
Prospective traceability approaches have largely been man-
ual or minimally-automated until recently. Such techniques
include embedding related artifact IDs into source code [34]
and only automating peripheral traceability tasks, such as
maintaining consistency between artifacts [8]. Tools like
PRO-ART and TOORS support the online recording of links
based on pre-speciﬁed user information. PRO-ART requires
a process model to be manually speciﬁed prior to the record-
ing of traces between artifacts [39]. TOORS requires train-
ing in formal speciﬁcations in order to mathematically ex-
press the relations between classes of artifacts [38]. Once
these relations have been speciﬁed in the database, auto-
mated tracing between artifacts is possible.
Other research communities have also developed meth-
ods for prospectively capturing relations between artifacts.
In the aspect-oriented research community, code is auto-
matically related to concerns by requiring users to spec-
ify a concern prior to making code changes [37]. Model
driven approaches use transformation techniques to auto-
matically create links between source and target models [28,
32]. These approaches may require the speciﬁcation of the
meta-model and the transformation program or the speciﬁ-
cation of the transformation rule prior to the link capture.
More recently, lightweight approaches to tracing between
artifacts have been proposed in the program comprehension
research community. Online recording of user interaction
has been used to associate source code to tasks [29] as well
as source code to team collaboration [1]. Prospectively cap-
turing links between artifacts during an experiment lifecycle
has also been used extensively in e-Science [3].
In previous work [9], we investigated an approach for au-
tomated prospective capture that utilizes open hypermedia
techniques [5] and rules. Tool-speciﬁc adapters record user
actions over heterogeneous platforms while users generate or
access artifacts during software development. Rules are used
to associate links with a relationship type. Developing these
adapters and custom rules requires only a one-time overhead
setup. The overhead of using this approach involves turn-
ing the record mode on or oﬀ, optionally applying rules for
each recording session, and deleting extraneously recorded
links which were not caught by the ﬁlters. The approach,
however, suﬀers from the fact that prospective capture lacks
insight into the semantic nature of the artifacts being linked.
For instance, if a developer is multi-tasking and working on
two diﬀerent projects at once, prospective capture based on
the recorded temporal sequence of actions may generate ir-
relevant trace links. Semantically sifting through artifacts
is important for this task, and thus, we explore the use of
topic modeling in prospective traceability.
2.3 Insightsfor effective traceability
Based on our experience with implementing a successful
software traceability framework in an industrial setting [8]
and our observations of traceability techniques within e-
Science [9], our approach is guided by the following general
insights.Source code Consistent Architecture (Structural View) 
Class foo {...} 
Class bar {...} 
Module B Module C Module A 
Req. 
Specs Wiki Pages Bug Reports Use Cases Sequence 
Charts 
Figure 1: Architecture-centric traceability, where
software artifacts are linked to speciﬁc modules.
Understand the limits of automation. As we have ob-
served in previous work [8], it is important to distinguish
between automatable traceability tasks and tasks that re-
quire human intervention. Thus, we aim to use automation
techniques that minimize the manual tasks of artifact search
and trace link post-analysis. As we detail later in the paper,
our technique generates links prospectively as users perform
development tasks. The generated links are then automati-
cally categorized by semantic topics and visually represented
to the user to facilitate link analysis. In addition, users can
navigate to the artifacts in the context of their native editors
to aid users in determining the correctness of the links.
Traceability must support user work practices. Both our
previous work [8] and literature [21] suggest that perform-
ing traceability tasks should be a side eﬀect to the users’
development tasks in order to gain wide adoption. In addi-
tion, the traced information should provide direct beneﬁts
to the users. Our prospective capture approach seeks to cap-
ture links in the background while users perform their de-
velopment tasks. The online improvements to the system’s
traceability and the visual representation of trace links can
provide immediate beneﬁts to users.
The traceability approach must be scalable. The litera-
ture reports that one of the diﬃculties with transferring
traceability techniques to industry is that the examples are
too small [43]. Thus, it is important that approaches for
both capturing links and presenting the linked information
to users be scalable. In the prospective setting, scalability is
achievable due to the incremental capture and maintenance
of trace links. Furthermore, advances in probabilistic infer-
ence algorithms have made topic modeling very scalable, as
we will show later in the paper.
Traceability must be bounded. Literature suggests that it
is infeasible to create links to every single artifact. With n
artifacts, there are`n
2´
possible pairwise links between these
artifacts, making it generally infeasible to evaluate and man-
age each of these potential links. The “trace for a purpose”
strategy states that trace links should only be captured if
there is a direct usage of the traced information [15]. In addi-
tion, creating direct links between line-level source code and
high-level concepts can produce an unmanageable amount
of links that make it diﬃcult to analyze and use the links.
We posit that centering links at the system’s architecture
level bounds the scope of traceability links to be captured.
Figure 1 depicts architecture-centric [44] traceability. Arti-
facts are linked to particular architectural components, and
there is the assumption that source code is generally consis-
tent with the architectural description. Many design factors
such as domain constraints, user requirements, and govern-
mental regulations are addressed at the architectural level.αnd Znd Xtφ
dθT
DNdβ
Figure 2: Graphical model for Latent Dirichlet
Allocation. Unshaded/shaded circles denote hid-
den/observed variables, boxes denote parameters,
and plates denote replication over indices.
Since architecture forms the nexus between artifacts in the
problem space (e.g. requirements) and artifacts in the solu-
tion space (e.g. code, tests), the conceptual gap between the
architecture and the other artifacts is smaller than, for ex-
ample, the conceptual gap from source code to requirements.
Finally, the fact that architecture is a high-level abstraction
of the source code supports impact analysis, software evo-
lution, and system comprehension, and these are tasks that
software traceability aims to support as well.
3. TOPICMODELING
Topic modeling is a widely-used machine learning tech-
nique for automatically inferring semantic topics from a text
corpus. In order to provide a foundation for our topic-
enhanced traceability approach, we brieﬂy introduce Latent
Dirichlet Allocation and discuss applications and limitations
of topic modeling.
3.1 LatentDirichlet Allocation
Automatically discovering the underlying structure of the
data is an important problem in machine learning which has
spurred the development of dimensionality reduction tech-
niques. Latent Semantic Indexing (LSI), also known in the
literature as Latent Semantic Analysis [20], is one such tech-
nique that attempts to address this problem. LSI has been
utilized extensively in software engineering, since it can be
easily applied to text corpora. In LSI, each document in the
corpus is represented as a word count vector of length W,
where Wis the number of words in the corpus vocabulary.
When the vectors of all Ddocuments are placed side by side,
one obtains a W×Dmatrix of counts, which LSI decom-
poses by singular value decomposition in order to map the
documents to a lower dimensional latent space. Hofmann
proposed Probabilistic Latent Semantic Indexing (PLSI), a
probabilistic version of LSI which is able to achieve better re-
sults [26]. Improving upon PLSI, a fully generative Bayesian
model known as Latent Dirichlet Allocation (LDA) was in-
troduced by Blei et al. [12]; LDA deals with overﬁtting issues
associated with PLSI and can achieve better results than
PLSI. In this paper, the topic model that we use is LDA.
The graphical model of LDA is displayed in Figure 2. Each
topic tis deﬁned to be a probability distribution φt(over W
words) drawn from a Dirichlet distribution with parameter
β. Furthermore, each document dis associated with a prob-
ability distribution θd(over Ttopics) drawn from a Dirich-
let with parameter α. Note that a sample obtained from a
Dirichlet distribution is precisely a discrete distribution it-
self. A topic assignment variable zndis associated to each
individual word token nin each document dand is sampledfromθd. The actual word token xndis sampled from its re-
spective topic φtwhere t=znd. Since these word tokens are
observed data (which can be represented as a W×Dmatrix
of counts), we can use Bayesian probability calculus to invert
the generative model given observed data and automatically
learn the hidden variables φtfor each topic t, andθdfor each
document d. It is important to note that LDA is an unsu-
pervised machine learning framework, which means that no
previous training data with training labels is required. The
only required input to LDA is the set of documents (con-
verted to a sparse W×Dmatrix after removing stopwords
and performing stemming) and the desired number of topics
Tto be learned.
Recent advances in Bayesian inference for topic models
have made it possible to learn an LDA model in near real-
time on a moderately-sized set of documents. We use an ef-
ﬁcient zeroth-order collapsed variational Bayesian inference
algorithm (CVB0), in which an underlying variational dis-
tribution q(znd) over Ttopics is associated with each topic
assignment znd. The algorithm consists of iteratively per-
forming the following variational updates in a systematic
scan over tokens,
q(znd=t)∝N¬nd
wt+β
N¬nd
t+Wβ“
N¬nd
td+α”
where N¬nd
wk,N¬nd
k, and N¬nd
kdare expected counts derived
fromq(z). For more details, see Asuncion et al. [7].
While other algorithms such as fast collapsed Gibbs sam-
pling can also be used [40], CVB0 is very fast – later in the
paper we will show timing results when applying CVB0 to
software artifacts. Furthermore, topic modeling can easily
scale to hundreds of thousands of artifacts, especially when
combined with distributed computing [6, 35]. We take ad-
vantage of the eﬃciency of CVB0 inference in our traceabil-
ity tools.
3.2 Applications of LDA
Once an LDA model is learned on a corpus, one can use
the learned probability distribution over words φtto display
a list of Wwords, sorted by decreasing probability, for each
topic t. For instance, if topic 1 has high-probability words
“school teach student book ”, one can assume this topic
to be about academics. Thus, the semantic content of the
entire corpus can be summarized by displaying these topics1.
One can also use document d’s distribution θdover topics
to determine the topical content of the document. For in-
stance, if there are 4 topics and if θd= [0.5,0.1,0.05,0.35],
then one can infer that document dis mainly comprised of
a combination of topics 1 and 4. Note that θdcan also be
compared against other θ′
d(using a similarity measure such
as Kullback-Leibler divergence or cosine distance) in order
to obtain a ranked list of topically-similar documents. Thus,
LDA is useful for ﬁnding related documents as well as visual-
izing the topical content of each document. We incorporate
these abilities into our traceability tools.
LDA has been applied to a variety of problems, includ-
ing information retrieval [47] and entity resolution [36]. As
mentioned earlier, LDA has also been used to ﬁnd topics
in source code [30, 31]. The main diﬀerences between our
approach and previous LDA-based work are (1) we mainly
1For a brief demo of topic modeling on news articles, see:
http://asuncion.ics.uci.edu/demofocus on prospective traceability (2) we do not perform topic
modeling on code, but rather on text-based artifacts (such as
requirements/design documents) generated during the soft-
ware lifecycle. Thus, our approach is complementary with
other LDA-based work on source code analysis.
3.3 Limitations ofLDA
While LDA is very useful for analyzing text data, it is im-
portant to note the limitations of LDA. The ﬁrst limitation
is that the number of topics, T, needs to be pre-deﬁned by
the user. If Tis small, then the topics are more general in
nature and are more distinguishable from each other. If Tis
large, then nuanced topics may appear and topics may begin
to overlap semantically. One way to address this problem is
to learn multiple models using various Tand visually inspect
the topics. Alternatively, a non-parametric model known as
Hierarchical Dirichlet Processes [45] extends LDA and seeks
to learn the optimal Tautomatically.
Another limitation is that the visualization of LDA topics
is limited to displaying the high-probability words and so
the interpretation of the actual semantic nature of the topic
is left to the user (e.g., for the topic“ school teach student
book”, there is no automatic label denoting that this is an
“academic” topic). Note that there has been some recent
work that seeks to provide topic labels automatically [33].
4. OUR COMBINEDAPPROACH
We have reviewed the problem of traceability and the ben-
eﬁts that topic modeling brings. We believe that traceability
can beneﬁt from the application of topic modeling to soft-
ware development artifacts. We outline how topic modeling
can be eﬀectively applied to prospective traceability.
Topic modeling enhances prospective capture by provid-
ing semantic information about the artifacts. Recall that
our prospective traceability approach is centered on the ar-
chitecture [44]. While a developer is working on a particular
architectural component, our technique captures the devel-
oper’s actions, such as opening a requirements speciﬁcation,
visiting a Wiki page, or modifying a bug report. The arti-
facts that the developer visits are then automatically linked
to the architectural component on which the developer is
working. Once these artifact links are recorded, the list of
artifacts related to a component can be visualized by the
developer by simply navigating to the particular component
in the architectural graph. Topic modeling enhances the
prospective capture by providing a learned set of topics that
can help the developer to ﬁnd artifacts or other relevant on-
line documentation. For instance, if the developer needs to
search through the project’s entire set of artifacts, the devel-
oper can use the learned semantic topics to ﬁlter the artifact
search. Furthermore, the developer can easily ﬁnd similar
artifacts by comparing θdand ﬁnding the closest matches.
Prospective 
Traceability 
Topic 
Modeling Semantic 
categorization 
and visualization Expansion of 
artifact base 
Figure 3: Symbiosis between prospective traceabil-
ity and topic modeling.ACTS : Architecture- Centric 
Traceability for Stakeholders 
TRASE : Topically-Rich 
Artifact Search Engine TEAM : Topic-Enhanced 
Architecture Mashup User interaction 
with TRASE 1 2Captured links with 
semantic information 
Figure 4: Tool support for our combined approach.
Topic modeling can also enhance the visualization of the
system. Artifacts that have been gathered via prospective
capture are now connected to the corresponding architec-
tural component. When the developer views the component,
the developer can view the artifacts along with a graphical
depiction of the topic distributions ( θd). Furthermore, the
components themselves are now associated with the topics of
their artifacts. We can deﬁne each component c’s topic dis-
tribution Θ cto be an average of the topic distributions of ar-
tifacts associated with the component: Θ c=1
Nd∈cP
d∈cθd.
Thus, we have a topic-enhanced bird’s eye view of the entire
system, and one can ﬁnd which artifacts and components
are related to particular semantic topics. This feature is
important for system comprehension.
Not only is prospective capture enhanced by topic model-
ing, but the quality of the topics is enhanced by the prospec-
tive capture of new artifacts. As more artifacts and other
online documentation are prospectively linked to the archi-
tecture, the quality of the topic model improves, as we will
see later in the paper. The topics become more semantically
coherent and interpretable, since the collection of underlying
artifacts becomes larger and more diverse. As depicted in
Figure 3, there appears to be a beneﬁcial symbiosis between
prospective capture and topic modeling.
There are other potential beneﬁts to applying topic mod-
eling to prospective traceability. False positives in auto-
matic link generation can be minimized by comparing the
θddistributions; if the diﬀerence is greater than a threshold,
then that candidate traceability link can be treated as noise
and be discarded. Furthermore, artifacts can be clustered
together in groups based on semantic topic similarity and
displayed to the developer, which aids in artifact retrieval
and allows for automated recommendation of similar arti-
facts. Finally, extensions to the LDA topic model, such as
the Author-Topic model [42] and the Dynamic Topic [11]
model can give an indication of which topics developers are
working on as well as the temporal evolution of topics, both
of which are of interest to project management.
5. TOOL SUPPORT
We implemented several diﬀerent tools that can be used to
collectively perform prospective traceability with topic mod-
eling. Figure 4 shows the high-level interplay between our
topic-based artifact search engine (TRASE), our prospec-
tive capture tool (ACTS), and our topic-enhanced architec-
ture visualization tool (TEAM). The user’s interaction with
TRASE can be prospectively recorded with ACTS, which
produces trace links. These trace links are then augmented
with topical information and are visualized within TEAM.
We provide details for each tool and discuss the application
of our approach on ArchStudio [16, 17], a mature software
project at UC Irvine.
Figure 5: TRASE tool which performs LDA in real-
time on the results of artifact search.
5.1 TRASEtool
To investigate our idea of improving prospective capture
with topic modeling, we created the Topically-Rich Artifact
Search Engine (TRASE). TRASE is a search engine over the
artifacts of the project which dynamically learns an LDA
topic model on the search results in real-time.
We implemented TRASE using a combination of Perl,
AJAX, and Lucene technologies. Lucene provides keyword-
based search results over the set of artifacts. Since our topic
model inference algorithm (CVB0) is very fast (on the order
of a few seconds), TRASE dynamically learns a new topic
model over the artifacts returned by Lucene and displays the
high-probability words of the learned topics ( φ) as well as
the distribution over topics ( θd) for each artifact dreturned
by Lucene. As shown in Figure 5, each topic is represented
by a diﬀerent color, and the distribution θdis depicted as a
color-bar underneath each search result. Thus, it is easy to
visually determine the topical composition of each artifact.
TRASE also includes functionality for ordering the results
by topic as well as by similarity to another document. Thus,
the developer can ﬁlter by desired topic or ﬁnd artifacts
with the most similar topic proportions. For instance, if the
developer wants artifacts similar to result #4, clicking on
“Similar Pages” would order the results by similarity to #4,
where the similarity measure used is KL-divergence.
As long as the prospective capture of ACTS is activated,
each artifact that the developer visits via the TRASE tool is
recorded as a trace link to the speciﬁc component on which
the developer is working. Note that this LDA-based search
technique can also be applied to general web pages on the
Internet. TRASE is a topic-enhanced way to search for ar-
tifacts that enables prospective traceability to be more eﬃ-
cient and accurate.5.2 ACTS tool
To capture links, we use our previously-built ACTS trace-
ability tool on top of ArchStudio 4 [9]. ACTS prospectively
captures links by recording the user interaction with the ar-
chitecture and other artifacts. We center our links to the
architecture and our ﬁrst class n-ary links are stored in an
XML Architecture Description Language (xADL) ﬁle [18].
ACTS combines prospective capture with the use of rules
and open hypermedia adapters. The tool-speciﬁc recording
adapters capture all the user actions on the artifacts and
have been implemented for applications such as the Mozilla
Firefox browser, MS Word, MS Excel, MS Powerpoint, and
Adobe Acrobat. Rules are then applied to these recorded ac-
tions to determine traceability links, ﬁlter extraneous links,
and assign link semantics. For instance, if a user visits URLs
from the TRASE search results (or any other web site), the
Firefox-recorder would capture links to these URLs.
Figure 6 shows the end of a recording session which lists
the artifacts visited during that session. After performing
some rule-based ﬁltering, these artifacts are then associated
with a particular component. Note that ACTS can capture
links to artifacts of varying media types, such as images like
.png ﬁles. This ability to capture links to non-text artifacts
is an advantage to performing prospective traceability.
5.3 TEAMtool
To visualize our architecture with traceability links, we
built the Topic-Enhanced Architecture Mashup (TEAM) tool.
This tool aggregates the linked information from ACTS and
overlays this information on top of the software architec-
ture. TEAM also takes the results of the topic model and
graphically renders the topical information of both the archi-
tectural components and the artifacts. As shown in Figure
7, TEAM allows one to view the entire system and iden-
tify which components are related to a particular topic. In
order to semantically classify component c, we use the com-
ponent’s topic distribution Θ cwhich was deﬁned in Section
4. If the component’s probability for topic t is greater than
a threshold (i.e. Θ ct>0.25, a threshold we set arbitrar-
ily), we associate the component with that topic. Note that
TEAM displays the high-probability words of each topic on
the left pane. When a topic is clicked, the components as-
sociated with that topic are highlighted in the topic’s color.
Thus, it is easy to determine the topical makeup of various
sections of the architecture. One can also zoom in on an
individual component and view the topic distributions θd
of the component’s related artifacts, as shown in Figure 8.
This visual information allows the user to quickly locate an
artifact of interest, and once the user clicks on an artifact,
the artifact is displayed in its native editor. Thus, at both
the system-level view and the component-level view, users
can identify at a glance both the trace and topic information
and navigate to desired artifacts.
6. EVALUATION
To evaluate our traceability approach, we apply our tech-
niques to the ArchStudio software project and we perform a
feature comparison between our traceability tools and other
tools in the literature. We also report timing and accuracy
results when applying Latent Dirichlet Allocation to Arch-
Studio artifacts, and we compare the precision-recall scores
of LDA and LSI on the EasyClinic data set [13].
Figure 7: TEAM tool which provides a mashup of
topical information over the software architecture.
6.1 Case studyon ArchStudio
We conducted a case study on the ArchStudio 4 system [16,
17]. The latest version of ArchStudio consists of 56 compo-
nents and 42 connectors, which corresponds to more than
85KLOC. The system comes with a heterogeneous set of
artifacts: tutorials in PDF, presentations in PowerPoint,
project speciﬁcations in Word, archived emails in an online
mailing list, Wiki pages and bug reports in Trac, ArchStu-
dio web pages, research publications in PDF, and developer
notes in various ﬁle formats.
We followed the scenario of understanding the unfamiliar
parts of the ArchStudio system. In the process of under-
standing each component, we navigated to various ArchStu-
dio artifacts and web sites while prospective capture was
enabled in ACTS; thus, links were being captured as we in-
vestigated each component. Since the architecture already
has a consistent mapping with the underlying code (i.e. the
system will not run if an inconsistency exists), it was not
necessary to create links to the source code.
To make our set of artifacts amenable to topic modeling,
we converted our artifacts to plain text ﬁles. A few docu-
ments were very long, and thus we broke these documents
(by section) into separate ﬁles. All the other preprocess-
ing steps (such as removing stop words and stemming) are
automated within our topic modeling algorithm.
We tested the capability of our TRASE tool on our set of
ArchStudio artifacts by querying various component names.
We ﬁnd that the tool performs very eﬃciently (returning re-sults in a few seconds) and that the displayed semantic infor-
mation is accurate. Figure 5 displays the results of querying
“ArchEdit”, which is a tool within the ArchStudio frame-
work. We see that various ArchStudio-related topics are
found: an XML schema topic (T1), a UCI email topic (T2),
a BNA tree topic (T3), a Java/Eclipse topic (T4), a compo-
nent/connector topic (T5), a similar Myx framework topic
(T6), and an Archlight test topic (T7). In each of the re-
turned results, the yellow topic appears since ArchEdit and
Archlight terms are collocated in these documents. We also
see the presence of the email topic (in olive-green) in results
#2, #3, and #4 because these speciﬁc results are precisely
the artifacts from email archives. Also note that result #2
is an email about the Myx framework with relationships to
Archlight, which conﬁrms the accuracy of the learned topic
distribution that is displayed.
Once we captured our links through the ACTS prospective
capture tool, we performed topic modeling on our set of arti-
facts, generating topic proportions for both the artifacts and
related architectural components. We then rendered this
information within the TEAM mashup tool. As depicted
in Figure 7, we clicked on the ﬁrst topic (about “change
sets”) and the resulting highlighted components (in red) were
all related to this topic: ChangeSet Relationship Manager,
ChangeSet ID View, ChangeSet Status View, ChangeSet Id
Relationships, and ChangeSet Status Relationships.
Figure 8 displays the artifacts related to the Archipelago
component, which is the visual editor within ArchStudio.
Most of the linked artifacts are related to topic T6 which is
about Archipelago or its visual elements. Topic T2 (the olive
green topic), is found among the email artifacts. This result
makes sense because the high-probability words within topic
T2 are typically found in emails. As with the TRASE tool,
the width of the color in the color-bar indicates the strength
of its relation to the topic. The artifact in the fourth row
is largely comprised of topic T5, which is the “Myx” topic.
When we examined the artifact, we found that it is indeed
largely about the Myx architectural style. The topic with
the second-highest probability for this artifact is topic T4
(about “xADL”), and when we examined the artifact, we
found that it also discusses xADL elements. Through these
examples, we see how TEAM allows one to quickly identify
the topics of a component’s related artifacts.
When we presented our TEAM tool to the ArchStudio de-
velopers, the response was largely positive. One developer
stated that topics aid in system comprehension. This devel-
oper recounted his previous experience of having to manually
go through source code when he was initially learning Arch-
Studio, and he stated that this topic-based tool would have
saved him time and eﬀort in understanding ArchStudio:
“[TEAM] provides me a central access to all the avail-
able materials, so that I don’t have to go to diﬀerent places
searching for the same topic, and possibly get overwhelmed
by lots of unrelated materials. At this point, I believe the
mashup tool not only saves users’ time, but also improves
the usability of existing technical materials.”
In addition, the topic visualization also aided the devel-
opers in analyzing the correctness of the related artifacts.
The visualization enabled the developers to quickly identify
whether the captured links were correct and whether we
were missing some links. The developers generally thought
that the captured links were accurate.
The developers also gave several suggestions for improve-Table 1: Feature comparison between tools
Feature Our
Combined
ApproachRetro.
Trace.
[20, 23, 25,
27, 41]Prosp.
Trace.
[3, 28, 29,
32, 38, 39]
Generates candidate
links based on tex-
tual similarityX X
Generates links
based on user
interactionX X
Generates links
across heteroge-
neous artifacts (i.e.
non text-based)X
Uses fully proba-
bilistic interpreta-
tion of semantic
topicsX
Adds links in an
online, incremental
fashionX X X
Detects topics from
artifacts automati-
callyX X
Visualizes semantic
topics on architec-
tural mashupX
ment. One suggestion is to provide topics at ﬁner levels of
granularity to minimize the number of components to ex-
amine. Another suggestion is to make the representation of
topics more clear, since there were similar high-probability
words that appeared in more than one topic.
6.2 FeatureComparison
Table 1 shows a feature comparison between our approach
and the existing retrospective and prospective traceability
techniques in the literature. The table shows that our ap-
proach provides capabilities that are not currently supported
in other tools, such as generating traceability links across a
wider range of artifacts including graphic and media ﬁles,
using a fully probabilistic interpretation of semantic top-
ics, and visualizing topics on top of the architecture graph
through the use of mashups.
6.3 Accuracyand timingresultsfor LDA
In this section, we brieﬂy discuss accuracy and timing re-
sults when applying Latent Dirichlet Allocation to software
artifacts. In Figure 9, we see that the test perplexity of
the model decreases as the number of artifacts increases.
Perplexity is a widely-used metric for topic models that in-
dicates the quality of the model (and a lower perplexity in-
dicates a better model) [7]. This unsurprising result sug-
gests that it is beneﬁcial to expand the artifact base for
topic modeling, suggesting that the prospective capture of
artifacts can beneﬁt topic modeling just as topic modeling
beneﬁts prospective traceability.
In Figure 10, we show the amount of time it takes to learn
a topic model for diﬀerent settings of the number of topics
T, as a function of the number of artifacts to model. We
see that there is only a linear increase in computation time0 20 40 60 80 300 400 500 600 700 800 900 
Artifacts modeled Perplexity LDA, T=10 
LDA, T=20 
LDA, T=30 
Figure 9: As the number of ArchStudio artifacts
increases, a higher-quality topic model is learned.
1002003004005006007008009000102030405060
Artifacts modeledTime (in seconds)LDA, T=10
LDA, T=20
LDA, T=30
Figure 10: Timing results for LDA on ArchStudio
artifacts.
as the number of artifacts increases. Note that the timing
results are measured seconds and that we used a single-core
1.6Ghz machine to run these experiments. With a multi-core
processor, one can perform topic modeling on a moderately-
sized data set in near real-time, suggesting the scalability
of our approach. We also note that the other facets of
our approach are also scalable: ACTS is scalable since it
performs link capture incrementally, and TEAM is scalable
since mashup visualizations can be done on large-scale data
with the appropriate tools (e.g. Google Maps API).
In Figure 11, we compare the precision-recall scores of
LDA vs. LSI on the EasyClinic data which was used in the
TEFSE 2009 traceability challenge [2]. Note that the preci-
sions are generally low since we clumped the four diﬀerent
artifact types in the challenge into one global set of artifacts.
For this data set, we see that LDA performs better than LSI,
perhaps due to the fact that LDA is fully probabilistic and
includes priors on θandφwhich can act as regularization.
This result is somewhat expected, since Hofmann discovered
that PLSI generally outperforms LSI [26] and since LDA is
a fully Bayesian version of PLSI. Nonetheless, it is reassur-
ing to know that in the realm of software artifacts, LDA
performs as well or better than LSI on this data.
6.4 Discussion
Our ArchStudio case study suggests that combining topic
modeling with prospective traceability provides useful re-
sults. Our task of learning the unfamiliar parts of the Arch-0 0.2 0.4 0.6 0.8 10.0780.080.0820.0840.0860.0880.090.0920.0940.096
RecallPrecisionLDA, T=10
LSI, T=10
Figure 11: LDA perform better than LSI on the
EasyClinic data set, in terms of precision-recall.
Studio system was supported by our traceability tools. We
found that the learned semantic topics corresponded well
with the actual content within the artifacts, and these top-
ics allowed us to eﬃciently ﬁnd and evaluate artifacts. The
ArchStudio developers were also able to easily verify the
traceability links by using the semantic information visual-
ized by the TEAM tool. Our empirical results also suggest
that LDA is competitive or superior to LSI and that our
approach can scale to handle larger numbers of artifacts.
There are limitations to our approach. First, we assume
the existence of an architecture, since we center our trace-
ability links to the architecture. This is not an unrealistic
assumption, since we believe that every system has an un-
derlying architecture, whether or not it is explicitly docu-
mented. In the event that the architecture is not explicitly
documented (or incomplete), we can create virtual compo-
nents to correspond to the source code. Secondly, we per-
form our topic analysis on text-based artifacts. The non-text
artifacts were ignored by the topic model algorithm. In the
future, we plan to use text metadata associated to non-text
artifacts in order to include them in the topic model.
7. CONCLUSIONS
Automated approaches for generating traceability links
have largely focused on recovering trace links retrospectively.
This paper builds upon our previous work of capturing links
prospectively, while the artifacts are generated or accessed
in the context of a development task. In this work, we em-
ploy topic modeling in order to aid users in analyzing the
semantic nature of artifacts as well as the entire software
architecture. Our approach is scalable since the trace links
are incrementally captured, the problem space is bounded by
tracing to the architecture, and the topic model algorithm
is very eﬃcient.
This paper marks the initial investigation into combin-
ing prospective link capture with machine learning tech-
niques, and there are many open research questions: Can
prospective link capture be successfully combined with ret-
rospective IR techniques? Is it possible to relate the au-
tomatically generated topics to high-level concepts such as
features, non-functional properties, or concerns? Is it possi-
ble to successfully perform topic modeling on long artifacts
by section? Our results suggest that the combination of
prospective traceability with topic modeling is a promising
area of research that can be useful in practice.8. ACKNOWLEDGMENTS
We thank the INF117 students, A. Marron, S. Cutler, and
D. Kwok, for providing software for the visualization tool,
and D. Purpura for the ACTS user-interface. We thank Y.
Zheng and S. Hendrickson for evaluating the captured links
rendered in the visualization tool. This eﬀort is supported
by the US National Science Foundation under grants IIS-08-
08783, CCF-0917129, and by an NSF graduate fellowship.
9. REFERENCES
[1] The Jazz Project. http://jazz.net.
[2] TEFSE traceability challenge, 2009.
http://web.soccerlab.polymtl.ca/tefse09/Challenge.h tm.
[3] I. Altintas, O. Barney, and E. Jaeger-Frank. Provenance
collection support in the Kepler Scientiﬁc Workﬂow
System. In Proc of the IPAW , 2006.
[4] K. M. Anderson, S. A. Sherba, and W. V. Lepthien.
Towards large-scale information integration. In ICSE, 2002.
[5] K. M. Anderson, R. N. Taylor, and J. Whitehead. Chimera:
Hypermedia for heterogeneous software development
environments. ACM TOIS , 18(3), July 2000.
[6] A. Asuncion, P. Smyth, and M. Welling. Asynchronous
distributed learning of topic models. In Advances in Neural
Information Processing Systems 21 , 2009.
[7] A. Asuncion, M. Welling, P. Smyth, and Y. W. Teh. On
smoothing and inference for topic models. In Uncertainty
in Artiﬁcial Intelligence (UAI) , 2009.
[8] H. Asuncion, F. Fran¸ cois, and R. N. Taylor. An end-to-en d
industrial software traceability tool. In Proc of 6th Joint
Meeting of the ESEC/FSE , pages 115–124, 2007.
[9] H. Asuncion and R. N. Taylor. Capturing custom link
semantics among heterogeneous artifacts and tools. In Int’l
Workshop on TEFSE , Vancouver, British Columbia, 2009.
[10] P. Baldi, C. Lopes, E. Linstead, and S. Bajracharya. A
theory of aspects as latent topics. In OOPSLA , 2008.
[11] D. Blei and J. Laﬀerty. Dynamic topic models. In Int’l
Conf on Machine Learning , 2006.
[12] D. Blei, A. Ng, and M. Jordan. Latent Dirichlet Allocatio n.
Journal of Machine Learning Research , 3:993–1022, 2003.
[13] G. Capobianco, A. De Lucia, R. Oliveto, A. Panichella, a nd
S. Panichella. On the role of the nouns in IR-based
traceability recovery. In Proc of 17th Int’l Conf on Program
Comprehension (ICPC) , 2009.
[14] J. Cleland-Huang and R. Habrat. Visual support in
automated tracing. In Int’l Workshop on Requirements
Engineering Visualization , 2007.
[15] J. Cleland-Huang, R. Settimi, E. Romanova, B. Berenbach,
and S. Clark. Best practices for automated traceability.
Computer , 40(6):27–35, June 2007.
[16] E. Dashofy. Supporting Stakeholder-Driven, Multi-View
Software Architecture Modeling . Ph.D. (Info and Comp
Science), Univ of Calif, Irvine, 2007.
[17] E. Dashofy, H. Asuncion, S. Hendrickson,
G. Suryanarayana, J. Georgas, and R. N. Taylor.
ArchStudio 4: An architecture-based meta-modeling
environment. In 29th ICSE, Comp Vol , 2007.
[18] E. Dashofy, A. van der Hoek, and R. N. Taylor. A
comprehensive approach for the development of XML-based
software architecture description languages. ACM TOSEM ,
14(2):199–245, April 2005.
[19] A. De Lucia, R. Oliveto, and G. Tortora. Assessing
IR-based traceability recovery tools through controlled
experiments. Empirical Software Engr , 14:57–92, 2009.
[20] S. Deerwester, S. Dumais, T. Landauer, G. Furnas, and
L. Beck. Improving information retrieval with latent
semantic indexing. In Annual Meeting of the American
Society for Info. Science 25 , 1988.
[21] R. D ¨omges and K. Pohl. Adapting traceability
environments to project speciﬁc needs. CACM ,
41(12):54–62, 1998.[22] C. Duan and J. Cleland-Huang. Clustering support for
automated tracing. In Proc of ASE , 2007.
[23] M. Grechanik, K. S. McKinley, and D. E. Perry. Recoverin g
and using use-case-diagram-to-source-code traceability
links. In Proc of 6th Joint Meeting of the ESEC/FSE , 2007.
[24] J. H. Hayes and A. Dekhtyar. Humans in the traceability
loop: Can’t live with ’em, can’t live without ’em. In Int’l
Workshop on TEFSE , 2005.
[25] J. H. Hayes, A. Dekhtyar, and S. K. Sundaram. Advancing
candidate link generation for requirements tracing: The
study of methods. IEEE TSE , 32(1):4–19, 2006.
[26] T. Hofmann. Unsupervised learning by probabilistic la tent
semantic analysis. Machine Learning , 42(1):177–196, 2001.
[27] H. Jiang, T. Nguyen, I. Chen, H. Jaygarl, and C. Chang.
Incremental latent semantic indexing for eﬀective,
automatic traceability link evolution management. In Proc
of Automated Software Engineering (ASE) , 2008.
[28] F. Jouault. Loosely coupled traceability for ATL. In Proc
ECMDA Workshop on Traceability , 2005.
[29] M. Kersten and G. C. Murphy. Mylar: A degree-of-interes t
model for IDEs. In Aspect-oriented Soft Dev , 2005.
[30] E. Linstead, P. Rigor, S. Bajracharya, C. Lopes, and
P. Baldi. Mining concepts from code with probabilistic
topic models. In Proc of ASE , 2007.
[31] G. Maskeri, S. Sarkar, and K. Heaﬁeld. Mining business
topics in source code using latent dirichlet allocation. In
Proc of India Software Engineering Conf , 2008.
[32] N. Medvidovic, P. Gruenbacher, A. Egyed, and B. W.
Boehm. Bridging models across the software lifecycle.
Journal of Systems and Software , 68(3), 2003.
[33] Q. Mei, X. Shen, and C. Zhai. Automatic labeling of
multinomial topic models. In KDD, 2007.
[34] C. Neum ¨uller and P. Gr ¨unbacher. Automating software
traceability in very small companies - a case study and
lessons learned. In Proc of ASE , 2006.
[35] D. Newman, A. Asuncion, P. Smyth, and M. Welling.
Distributed inference for Latent Dirichlet Allocation.
Advances in Neural Info Processing Systems , 20, 2007.
[36] D. Newman, C. Chemudugunta, and P. Smyth. Statistical
entity-topic models. In KDD, 2006.
[37] E. Nistor. Concern-Driven Software Evolution . Ph. D.
Thesis (Info and Comp Science), Univ of Calif, Irvine, 2009.
[38] F. Pinheiro and J. Goguen. An object-oriented tool for
tracing requirements. IEEE Software , 13(2):52–64, 1996.
[39] K. Pohl. PRO-ART: Enabling requirements
pre-traceability. In Proc Requirements Engineering , 1996.
[40] I. Porteous, D. Newman, A. Ihler, A. Asuncion, P. Smyth,
and M. Welling. Fast collapsed Gibbs sampling for Latent
Dirichlet Allocation. In 14th ACM SIGKDD , 2008.
[41] D. Poshyvanyk, A. Marcus, V. Rajlich, Y.-G. Gueheneuc,
and G. Antoniol. Combining probabilistic ranking & latent
semantic indexing for feature identiﬁcation. In ICPC , 2006.
[42] M. Rosen-Zvi, T. Griﬃths, M. Steyvers, and P. Smyth. The
author-topic model for authors and documents. In UAI,
2004.
[43] D. I. K. Sjoberg, B. Anda, et al. Conducting realistic
experiments in software engineering. In Int’l Symp on
Empirical Software Eng , 2002.
[44] R. N. Taylor, N. Medvidovic, and E. Dashofy. Software
Architecture: Foundations, Theory, and Practice . John
Wiley & Sons, 2010.
[45] Y. W. Teh, M. Jordan, M. Beal, and D. Blei. Hierarchical
dirichlet processes. Journal of the Am Stat Assoc ,
101(476):1566–1581, 2006.
[46] K. Tian, M. Revelle, and D. Poshyvanyk. Using latent
dirichlet allocation for automatic categorization of soft ware.
InMining Software Repositories , 2009.
[47] X. Wei and W. B. Croft. LDA-based document models for
ad-hoc retrieval. In SIGIR Conf. , 2006.Figure 6: The ACTS prospective capture tool automatically traces between the architectural components on
which the developers are working and the artifacts that the de velopers access.
Figure 8: Clicking on an individual architectural component w ithin the TEAM tool opens a list of relevant
artifacts, each displaying a set of topic proportions.