BLITZ : Compositional Bounded Model Checking
for Real-World Programs
Chia Yuan ChoyxVijay D‚ÄôSilvaxDawn Songx
xUniversity of California, Berkeley, USA
yDSO National Laboratories, Singapore
fchiayuan, vijayd, dawnsong g@cs.berkeley.edu
Abstract ‚ÄîBounded Model Checking ( BMC ) for software is a
precise bug-Ô¨Ånding technique that builds upon the efÔ¨Åciency of
modern SAT and SMT solvers. BMC currently does not scale
to large programs because the size of the generated formulae
exceeds the capacity of existing solvers. We present a new,
compositional and property-sensitive algorithm that enables BMC
to automatically Ô¨Ånd bugs in large programs. A novel feature of
our technique is to decompose the behaviour of a program into
a sequence of BMC instances and use a combination of satisfying
assignments and unsatisÔ¨Åability proofs to propagate information
across instances. A second novelty is to use the control- and
data-Ô¨Çow of the program as well as information from proofs
to prune the set of variables and procedures considered and
hence, generate smaller instances. Our tool B LITZ outperforms
existing tools and scales to programs with over 100,000 lines
of code. B LITZ automatically and efÔ¨Åciently discovers bugs
in widely deployed software including new vulnerabilities in
Internet infrastructure software.
I. I NTRODUCTION
Software Bounded Model Checking ( BMC ) is a powerful
technique for Ô¨Ånding bugs in bounded program executions.
The technique constructs a formula, called a BMC instance ,
that encodes the behaviour of a program up to a user-speciÔ¨Åed
bound. BMC instances can capture bit-level operations and
the memory model, and so generate precise information about
bugs. However, existing BMC tools exhaust memory or time
on programs containing a few thousand lines of code [11].
In this paper, we ask: is it possible solve a large instance
by only solving instances that Ô¨Åt in memory . SpeciÔ¨Åcally, we
seek to design a compositional BMC algorithm. An analysis
technique is compositional if it can decompose a large problem
into smaller problems, and solve only a small problem at a
time. For example, Hoare logic is compositional because it
allows for proving a statement about a program by proving
statements about its parts. Several static analysis techniques
are compositional because they propagate information through
a program one block at a time.
Decomposing BMC instances is challenging because de-
pendencies between constraints are lost if the formula is
decomposed. Imagine a procedure bar() which calls a proce-
dure foo( int x)with argument 2. If the assertion is never
violated, no formula that includes the behaviour of both foo
andbar will be satisÔ¨Åable. If we decompose the problem
and reason about bar() andfoo( int x)separately, the
assertion may be violated because there is no constraint on the
input variable x. More generally, decomposing a BMC instancemay render an unsatisÔ¨Åable formula satisÔ¨Åable because the
context in which the code executes is not taken into account.
We do not wish to report that an assertion may be violated
because we lose the appealing property that BMC reports
precise information about bugs.
Compositional Bounded Model Checking
We use two ideas to address the problems sketched above.
First, we consider preconditions for violation , which are
conditions under which a program is guaranteed to violate
an assertion. Computing such preconditions precisely would
involve the expensive step of quantiÔ¨Åer elimination while over-
approximating preconditions leads to spurious bug reports. We
compute the underapproximate preconditions for a violation,
and weaken them iteratively. We use information from proofs
generated by SATsolvers to expand the set of error states that
must lead to a violation. As a result, we can decompose a
BMC instance, consider multiple inputs to a piece of code,
and preserve the accuracy of BMC with respect to bugs.
Our second idea is to incrementally generate BMC instances
using information from proofs generated by SAT solvers.
Solvers reason about semantic relationships between variables
when they construct proofs, so proofs provide relevance
heuristics [14] for tuning program analyses. By constructing
BMC instances relevant to variables and operations appearing
in a proof, we dramatically reduce the number of instances that
must be considered. Our approach is closely related to the use
of Craig interpolants in veriÔ¨Åcation [17] and the formulae we
construct also satisfy the interpolation criteria. Consequently,
our technique is not only compositional, but like interpolation
techniques, is property-driven.
Our tool B LITZ implements a compositional BMC tech-
nique that combines underapproximate preconditions with
incremental construction of BMC instances. Both steps are
guided by unsatisÔ¨Åability proofs generated by SATsolvers. We
have evaluated B LITZ on vulnerability benchmarks containing
unmodiÔ¨Åed real-world programs and found that B LITZ faces
no capacity problems and can Ô¨Ånd bugs in programs of
approximately 100KLOC. In addition, we applied B LITZ to
check critical Internet infrastructure software from the Internet
Systems Consortium and found multiple new vulnerabilities.
Content and Contributions
We present an algorithm and tool for compositional BMC
that boosts the capacity of BMC and can discover bugs in real-world programs with about 100KLOC. We make the following
contributions.
1) We present a new BMC algorithm that achieves composi-
tionality by computing underapproximate preconditions,
and improves scalability by proof-guided incremental
instance construction.
2) We demonstrate that the technique extends the state of
the art of BMC by applying our tool B LITZ to real-world
benchmarks containing up to about 100KLOC.
3) We deploy B LITZ on critical Internet infrastructure
software and Ô¨Ånd multiple new vulnerabilities.
The paper is organised as follows: We revisit the terminology
ofBMC in Section III, where we also recall notions from pro-
gram analysis. Our compositional BMC algorithm is presented
in Section IV and evaluated in Section V. We discuss related
work in Section VI and conclude in Section VII.
II. T ECHNIQUE OVERVIEW
We present a run of B LITZ on a simple program. The
example is intentionally simple to facilitate presentation.
Goal. The program in Figure 1 begins execution in main
and contains calls to four procedures foo,baz,bar andqux.
The procedures baz andqux have no side effects and are not
shown. The goal is to determine if the assertion at line 18of
baris violated. The standard BMC procedure will take as input
a parameter kand construct an instance Mkin which loops
and recursive procedures are unwound ktimes and procedure
calls are inlined. This approach leads to large formulae.
Formula construction :The Ô¨Årst novelty of B LITZ is that
we only generate formulae for small code fragments rather
than the entire program. B LITZ begins by generating a formula
for the behaviour of baras shown in Figure 2. Observe that the
variables have been labelled with subscripts so that a variable
has different indices as its value changes in the lifetime of the
program. Technically the formula corresponds to Single Static
Assignment ( SSA) form. The values of bandc, being inputs,
are unknown and denoted , as is the value of f, because the
body of qux is not considered.
Underapproximate preconditions :The formula for bar
is satisÔ¨Åable so a SAT solver can generate a satisfying as-
signment. This satisfying assignment may not correspond to
a feasible execution because the calling context for bar does
not appear in the formula. The second novelty of B LITZ is to
use a satisfying assignment to Ô¨Årst generate an unsatisÔ¨Åable
formula and then use a proof of unsatisÔ¨Åability to obtain
aprecondition for assertion violation . In this case, B LITZ
generates the precondition (b1<‚Äôb‚Äô), where ‚Äôb‚Äô denotes the
ASCII value of the character b. This means that the assertion
is violated if the value of the variable b1is strictly less than
the ASCII value of the character b.
There are two differences between the precondition com-
puted by B LITZ and that of standard techniques. It is common
to compute weakest preconditions with respect to a correctness
property. Instead, we compute preconditions with respect to
an assertion violation. The second difference is that we do
not necessarily compute weakest preconditions. The Dijkstraweakest precondition with respect to the assertion violation
condition (d<‚Äôd‚Äô)is the formula
(2c1= 1) =)(c1<‚Äôd‚Äô)
^:(2c16= 1) =)(b1+ 2<‚Äôd‚Äô)
which simpliÔ¨Åes to
(2c1= 1) =)(c1<‚Äôd‚Äô)
^:(2c16= 1) =)(b1<‚Äôb‚Äô):
The precondition generated by B LITZ is an underapproxi-
mation of the weakest precondition. The practical beneÔ¨Åt of
our formula is that it is smaller and contains fewer Boolean
operations, hence is easier for a solver to manipulate. This
simplicity translates to signiÔ¨Åcant performance beneÔ¨Åts for
larger formulae. The trade-off of this performance beneÔ¨Åt is
that B LITZ may miss bugs (produce false negatives) because
it uses underapproximation. False negatives are mitigated by
using a reÔ¨Ånement strategy that weakens preconditions.
Incremental Instance Construction :Next, B LITZ has to
determine if bar can be called in a context satisfying (b1<
‚Äôb‚Äô). Standard BMC and recent techniques like C ORRAL [11]
and A LTER [21] consider the callers and callees surrounding a
procedure to generate such constraints. This approach would
result in qux andbaz being added to the instance.
BLITZ uses data-Ô¨Çow information in the program and only
considers contexts that affect the underapproximate precondi-
tion. In the example, we can skip qux andbaz and consider
the call to foo at line 3. Solving an instance with the body
offoo generates the precondition (a0<‚Äôa‚Äô), which is
a sufÔ¨Åcient precondition for the assertion violation. Solving
this formula provides an input value to trigger the asser-
tion violation. We have found that incrementally generating
BMC instances by combining data-Ô¨Çow with underapproximate
preconditions signiÔ¨Åcantly reduces the number and size of
instances we consider.
Fine-Grained Decomposition :In the example above, we
have argued at the level of procedures. Sometimes a procedure
(or its unwinding) is too large to Ô¨Åt in memory. B LITZ supports
decomposing BMC instances at different levels of granularity
up to single statements. At the Ô¨Ånest level, we start with
a single statement directly preceding an assertion violation
and incrementally compute necessary preconditions for single
statements. We only work at this level of granularity when
required or when conÔ¨Ågured by the user.
To complete the overview, Figure 2 (b) illustrates the
formula constructed if we inline bar inmain . Suppose B LITZ
is run with a statement-level granularity, it will generate
an underapproximate precondition for individual statements.
Since data-Ô¨Çow is taken into account, statements not affecting
the approximate preconditions are ignored.
III. T ERMINOLOGY AND PRELIMINARIES
We introduce background and notation about BMC and
program analysis. The details of BMC included here are re-
quired later for correctness proofs and to clarify the differences
between our technique and existing ones.1: void main(unsigned char a) 11: void bar(unsigned char b, c)
2:f 12:f
3: char b = foo(a); 13: char d = b + 2;
4: char c = baz(b); / *some function */ 14: char e = c *2;
5: bar(b,c); 15: char f = qux(d,e); / *some function */
6:g 16: if (e == 1)
7: char foo(unsigned char a) 17: d = c;
8:f 18: assert(d >= ‚Äôd‚Äô);
9: return a + 1; 19: g
10:g
Fig. 1: An example program.
b1=;
c1=;
d1=b1+ 2;
e1=c12;
f1=;
d2= (e1= 1) ?c1:d1;
d2<‚Äôd‚Äô
(a)b1=a0+ 1; a0<‚Äôa‚Äô
c1=baz(b1); ‚Äì
d1=b1+ 2; b1<‚Äôb‚Äô
e1=c12; d1<‚Äôd‚Äô
f1=qux(d1;e1); ‚Äì
d2= (e1= 1) ?c1:d1;d1<‚Äôd‚Äô_(e1= 1^c1<‚Äôd‚Äô)
d2<‚Äôd‚Äô d2<‚Äôd‚Äô
(b)
Fig. 2: Formulae generated by B LITZ (a) The BMC formula generated for bar. (b) The left column shows the formula generated for
the program and the right column shows the preconditions computed if B LITZ is run at the granularity of statements. Statements that are
bypassed are indicated by ‚Äò‚Äì‚Äô.
A. Syntax and Semantics of Programs
For simplicity of presentation, the formalisation here fo-
cuses on a small subset of C. Our technique and tool both
apply to full ANSI C and are not subject to these restrictions.
Syntax: LetVar be a set of variables. We use the
symbol *to denote a non-deterministic value. Let Exp be
a set containing expressions in C and the *symbol. Similarly,
BExp is a set containing Boolean expressions in C and the *
symbol. A statement is an assignment, assumption, assertion,
sequential composition of statements or a procedure call. The
set of statements Stmt is deÔ¨Åned inductively below.
st::=x = tjassume (b)jassert (b)jcall P()
jst;stjif(b)st else stjwhile (b)st
Semantics: The semantics of programs is given by states
and state transitions. A program state consists of the values
of the program counter, global variables, and contents of the
stack and the heap. Let State be the set of states.
The semantics of a program is given by a relation. A
statement stdeÔ¨Ånes a transition relation TstStateState
that contains a pair (r;s)if executing stin the staterresults
in the states. An assignment changes the value of a variable in
a state and leaves all other states unchanged. The semantics of
assume (bexp) is a relation that contains (s;s)ifssatisÔ¨Åes
bexp . The semantics of assert (bexp) is similar except that
ifsdoes not satisfy bexp there is a transition (s;e)to an
error statee. The semantics of sequential composition p;q
is the relational composition TpTq. We writeTPto be the
transition relation of a program P.
Error Reachability: Program properties such as assertion
violations can be formulated as reachability of states in atransition system. A state sisreachable in a program if there
is an execution whose last state is s. The error reachability
problem is to determine if an error state is reachable.
An error reachability technique is sound if whenever the
technique reports an error, the error is reachable. An error
reachability technique is complete if whenever the technique
reports that the error is not reachable the error is indeed not
reachable. Our deÔ¨Ånitions of soundness and completeness are
given with respect to reachability and differ from the notions
used in the correctness literature.
B. Bounded Model Checking
Bounded Model Checking ( BMC ) is a technique for Ô¨Ånding
bugs in bounded program executions. It operates by unwinding
a program, translating the unwinding into a logical formula,
and solving the formula.
Unwinding: This material is based on [5]. A k-
unwinding of a program Pfor a non-negative kis a program
unwind (P;k)deÔ¨Åned inductively below.
unwind (x = t;k) ^ =x = t
unwind (assume (b);k) ^ =assume (b)
unwind (if(b)p else q;k) ^ =if(b)unwind (p;k)
else unwind (q;k)
unwind (while (b)p;0) ^ = if(b) assume (false)
unwind (while (b)p;k+ 1) ^ = if(b){ p;
unwind (while (b)p;k)}
The deÔ¨Ånition of the unwinding for other C constructs is
similar. Recursive procedures are handled by inlining. An
input variable in a BMC unwinding is one that is neverassigned. Input variables are the source of non-determinism
in an unwound program.
Translation to Logic: Statements in an unwinding are
translated to formulae. An assignment x=x+1 (where =is
assignment) cannot be written as a formula x=x+ 1(where
=represents mathematical equality) because xmust have the
same value on both sides of the equality in the formula.
The statement x=x+1 is rewritten to x1 = x0 + 1 to make
explicit that xmay have different values before and after the
assignment. This statement is then translated to a formula
x1=x0+ 1. More generally, a program is in Single Static
Assignment ( SSA) form if every variable is assigned exactly
once in the program. Unwindings are translated to SSA form.
Ak-unwinding of PinSSA form is translated into two
logical formulaeB(P)andE(P). The behavioural constraint
B(P)encodes program executions. The error constraintE(P)
encodes error conditions such as out-of-bounds array accesses,
double frees, and assertion violations. If Bimplies:E, no
execution of a k-unwinding leads to an error. Conversely, a
k-unwinding contains an error if B^E is satisÔ¨Åable. The
satisÔ¨Åability condition can be checked using a SAT solver.
The behaviour formula B(st)and error condition E(st)
for a statement stas deÔ¨Åned in [5] are recalled below. We
write form (t)for the logical expression corresponding to a C
expression t.
stB(st)E(st)
x=t x=form (t) true
assume (b) form (b) true
assert (b) true :form (b)
P;QB(P)^B(Q)E(P)^E(Q)
All statements except assertions modify the behaviour con-
straint. The property is only modiÔ¨Åed by assertions. A BMC
instance is satisÔ¨Åable ifB^E is satisÔ¨Åable. A BMC instance
is generated by traversing the control Ô¨Çow graph ( CFG) of
unwind (P;k)in topological order starting from the initial
vertex init. Ifxis an input variable of unwind (P;k), we
say that form (x)is ainput variable of of the BMC instance.
We illustrate the construction of a BMC instance below.
Example 1. A programPis given on the left below with an
unwinding on the right.
while (x < y)
x = x + 1;
assert (x >= y); !if(x < y){
x = x + 1;
if(x < y){
x = x + 1;
if(x < y)
assume (false);
}
}
assert (x >= y);
The unwinding is translated into the formulae below.
B^ =x1= (x0<y 0) ? (x0+ 1) :x0
^x2= (x0<y 0^x1<y 0) ? (x1+ 1) :x1
^:(x0<y 0^x1<y 0^x2<y 0)
E^ =x2<y 0If the arithmetic and comparison operations and the memory
model respect the semantics of C, the unwinding contains an
assertion violation exactly if B^E is satisÔ¨Åable.
Bit-vector logic is typically used to model numeric variables
in C. Let var(')be the set of variables in a formula '. Let
Bbe the set of values that variables can take. An assignment
to a formula is a function :var(')!B.
C. Backward Reachability Computation
A classic approach to reasoning about programs is to
approximate the set of reachable states. We recall reachabil-
ity analysis because B LITZ combines BMC with ideas from
reachability analysis.
Asymbolic encoding is a representation of sets of states by
data structures such as logical formulae. Let Pbe a program
with a transition relation T, a set Init of initial states and a
setErr of error states. We write xfor a sequence of variables.
The initial and error states are represented symbolically by the
formulae Init(x)andErr(x). The transition relation generates
a formulaT(x;y), in which xandyare of equal length.
The precondition transformer deÔ¨Åned below maps a formula
S(x)to a formula, called a precondition representing the
predecessors of states represented by S(x).
pre:Form!Form pre (S(x)) ^ =9x:T(y;x)^S(x)
The set of backward reachable states BReach (S(x))contains
those that lead to a state in S(x). Below, we use the notation
f0for the identity function and fi+1for the function mapping
xtof(fi(x)). The backward reachable states have the well
known characterisation below.
BReach (Err(x))()_
i2Nprei(Err(x))
The equivalence suggests a na ¬®ƒ±ve approach to computing states
that lead to an error. The iterative computation terminates
when a predicate that is a Ô¨Åxed point is reached. A Ô¨Åxed point
ofReach is a predicate F(x)satisfying the condition:
Reach (F(x))()F(x)
A formula Q(x)is an underapproximate precondition if
Q(x) =)pre(S(x)). The notions for overapproximations
are similarly deÔ¨Åned.
IV. C OMPOSITIONAL BOUNDED MODEL CHECKING
In this section we present an approach for Ô¨Ånding deep
bugs by combining BMC with approximate preconditions. An
obstacle to scalability of BMC is that the size of a BMC instance
grows beyond the capacity of solvers as the unwinding depth
is increased. Reachability analysis with quantiÔ¨Åer elimination
faces similar computational obstacles. We combine BMC in-
stances with underapproximate preconditions to scale BMC
without producing false alarms about bugs.A. Underapproximating Precondition Computation
We describe the use of SAT solvers to underapproximate
preconditions with respect to a BMC instance and an error
condition. Suppose we have a procedure Pand a condition  
that should hold after Pexecutes. The formula  represents
a set of states from which an error state can be reached. The
set of predecessors pre( )represents all states that lead to a
state in through P. Computing this set is expensive, so we
compute an approximation. Program analysers typically over-
approximate postconditions and may produce spurious results
about bugs. We compute underapproximate preconditions to
avoid spurious outcomes.
Our Ô¨Årst observation is that the values of input variables in
a satisfying assignment to a BMC instance dictate the value
of other variables in the formula. Suppose a BMC instance
B(P)^E(P)has four variables w;x;y;z , with the input
variables being xandy. A satisfying assignment of the form
below can be viewed as a formula and this formula implies the
sub-formula that ranges only over input variables (abbreviating
true andfalse astand frespectively).
(w:t;x:f;y:f;z:f) w^:x^:y^:z=) :x^:y
Even though the sub-formula over input variables is weaker
than the assignment, it is sufÔ¨Åcient to constrain the values of
all other variables, and hence is a precondition for an error .
For the example above, the formula
:x^:y^B(P)^E(P)
has only one satisfying assignment because the values of x
andyconstraint the values of all other variables. The lemma
below states this observation formally. We treat an assignment
also as a formula and write inp()for the sub-formula of
that contains only input variables.
Lemma 1. IfB(P)^E(P)is satisÔ¨Åed by an assignment ,
the formula inp()^B(P)^E(P)has a unique satisfying
assignment. Consequently, the formula inp()^B(P)^:E(P)
is unsatisÔ¨Åable.
Proof. Consider the satisfying assignment and the formula
B(P). The semantics of inp()^B(P)is equivalent to re-
placing every input variable in B(P)by its truth value in .
After such a replacement, only non-input variables remain,
which by deÔ¨Ånition occur on the left-hand sides of assignment
statements. Since the formula is generated by a program in
SSA form, each non-input variable is assigned only once, and
hence has a unique value for the whole formula. It follows
thatinp()^B(P)^E(P)has a unique satisfying assignment.
For the second part, observe that satisÔ¨ÅesE(P)and so
does not satisfy:E(P). The constraints on input variables
are determined by B(P)soinp()^B(P)must be uniquely
satisÔ¨Åed by , so the conjunction inp()^B(P)^:E (P)is
unsatisÔ¨Åable.
The practical value of Lemma 1 is that we can derive
an unsatisÔ¨Åable formula from a satisÔ¨Åable formula. A proof-
generating SAT solver can generate a resolution refutation forAlgorithm 1: UNDERAPPROXIMATE PRECONDITION
approx-pre (F: a code fragment
 : a postcondition for F
: a satisfying assignment to B(F)^ E(F)^ 
w: a weakening parameter )
i:= 0
0:=inp(;B(F))
repeat
:=0
(res;) := solve(^ B(F)^ E(F)^ : )
0:=generalise (;)
i:=i+ 1
until0=ori=w
return
solve(': a formula )
if'is satisÔ¨Åable then
Letbe a satisfying assignment
return (sat;)
else
Letbe a proof of unsatisÔ¨Åability
return (unsat;)
a formula that is unsatisÔ¨Åable. The refutation makes explicit
what properties of the program are used to prove unsat-
isÔ¨Åability and this information has numerous applications.
SpeciÔ¨Åcally, if an input variable does not appear in a refutation,
the value of that variable does not affect the satisÔ¨Åability of
the restricted formula. We can use information from proofs to
derive an underapproximation of a precondition that is more
general than restricting an assignment to input variables.
To return to the example, suppose the constraint over input
variables is:x^:yand the variable xdoes not occur in the
refutation (with or without negation). We know that xis not
required to prove unsatisÔ¨Åability of :x^:y^B(P)^:E(P), so
we can conclude that :y^B(P)^:E (P)is also unsatisÔ¨Åable.
Recall that if A^Bis unsatisÔ¨Åable, then Aimplies:B. In
this example:y^B(P)impliesE(P), meaning that the set
of states represented by :yonly leads to states that contain
the error. Since:x^:yimplies:y, we have generalised the
precondition for the error.
The idea above is used to underapproximate preconditions.
The reasoning we have sketched above does not require us to
start with an assignment. It can be used to take a set of states
that lead to an error and derive a larger set that only contains
paths to an error. The restriction to states leading to an error
is important to avoid spurious results about bugs.
The algorithm for underapproximate precondition computa-
tion is shown in Algorithm 1. We encapsulate interaction with
the SAT solver by the method solve which takes as input a
formula'and returns a pair (res;), where resis the result
of the satisÔ¨Åability check. If 'is satisÔ¨Åable, res=satand
is a satisfying assignment. Otherwise, res=unsat andis a
proof of unsatisÔ¨Åability.
The procedure approx-pre takes as input a program fragment
F, a postcondition that Fmust satisfy in order to reach an error,
a satisfying assignment to the formulaB(F)^E(F)^ and a
parameterw. An underapproximate precondition is a formulaAlgorithm 2: ADJUSTABLE ,INCREMENTAL BMC INSTANCE
CONSTRUCTION
next-inst (F: a code fragment
 : a condition for error
d: a decomposition parameter )
Frag :=prev-code (F;d)
nObj :=;
repeat
foreach fragment GinFrag do
Remove Gfrom Frag
ifGdeÔ¨Ånes variables in  then
AddGtonObj
else
Frag :=Frag[prev-code (G;d)
until Frag =;
return nObj
prev-code (F: a code fragment, d: a decomposition parameter )
Frag :=;
ifd=proc then
Add callers of Fin the call graph to Frag
else ifd=stmt then
Add statements before Fin the CFG toFrag
return Frag
satisfying the condition:
^B(F)^E(F) =) 
Every execution through Fthat starts in a state in leads to a
state in . The procedure approx-pre returns an underapprox-
imate precondition. The condition is approximate because it
may not be the weakest such . Since is a condition for
reaching an error, the formula is a precondition for reaching
an error.
The parameter wis used to weaken an underapproximate
precondition. If wis0, the underapproximate precondition
isinp(). Ifwis1, the formula inp()is weakened using
information from an unsatisÔ¨Åability proof. We have considered
two variants for the procedure generalise . One variant is to
weakenby removing all variables that do not occur in the
proof . To do this, we Ô¨Årst walk the proof backwards to elimi-
nate unnecessary deductions. Further techniques for computing
minimal unsatisÔ¨Åable cores of unsatisÔ¨Åable formulae can also
be used [13].
Lemma 2. The formula approx-pre (P; ;;w )is an underap-
proximate precondition of Pwith respect to  .
Proof. The invariant of the loop in the algorithm is that
^B(F)^E(F)^: is unsatisÔ¨Åable. This is because the
generalisation step only reduces an unsatisÔ¨Åable formula to a
smaller unsatisÔ¨Åable formula and projects out the portion of 
in this smaller formula. It follows that ^B(F)^E(F)implies
 , sois a precondition of  .
B. Incremental, Data-Flow-Based Instance Construction
If a BMC instance is satisÔ¨Åable, we use approx-pre to
construct an underapproximate precondition. To determine if
there is indeed a bug, we need to propagate the preconditionto the entry point of the program. The standard approach
to propagate facts through a program is to use the Control
Flow Graph ( CFG). Propagation is wasteful if information is
propagated through code not relevant for reaching an error.
We use the term fragment for a piece of code that is either a
procedure or a conÔ¨Ågurable number of sequential statements.
BMC instances are generated incrementally using a granularity
speciÔ¨Åed by the user. A code fragment FdeÔ¨Ånes a variable x
ifxoccurs on the left-hand side of an assignment in Fand
uses the variable if the variable occurs in an expression. In
program analysis, a use-def graph makes data-Ô¨Çow explicit.
We combine both data- and control-Ô¨Çow information to
prune the number of instances that are generated. Given a
condition for an error, we only use fragments that deÔ¨Åne
variables in that condition to generate BMC instances. We
show in the experiments section that this seemingly simple
optimisation has signiÔ¨Åcant impact on the number of instances
generated, and consequently on the size of programs that can
be analysed.
Instances are incrementally constructed using Algorithm 2.
The procedure prev-code takes as input a fragment Fand
a parameter dwhich speciÔ¨Åes the granularity of fragment.
It returns a set of fragments that execute before F. At the
granularity of procedures, we return the nodes before Fin the
call graph of the program. At the granularity of statements,
we return statements preceding Fin the CFG.
The procedure next-inst takes as input a fragment Fthat has
already been analysed, a formula  , which is a precondition
forFto reach an error, and a decomposition parameter d,
which speciÔ¨Åes the granularity of fragments. It returns a set
of fragments that precede Fand which deÔ¨Åne variables in  .
It is implemented by iteratively calling prev-code until only
fragments manipulating variables in  are obtained.
C. The BLITZ Algorithm
BLITZ combines underapproximate precondition computa-
tion with incremental construction of BMC instances to decom-
pose the problem of Ô¨Ånding a bug in a large instance to that of
solving a sequence of smaller BMC instances. The advantage
is that every instance Ô¨Åts in memory and that a smaller number
of instances is considered than generating instances based
on control Ô¨Çow. The algorithm is parameterised, so that the
user may Ô¨Åne-tune the settings used for decomposition and
precondition computation using domain-speciÔ¨Åc knowledge or
data from benchmarks.
The procedure BLITZ in Algorithm 3 takes as input a pro-
gram Pwhich contains assertions, an unwinding bound kfor
loops and recursive procedures, a weakening parameter wfor
precondition approximation, and a decomposition granularity
d. The algorithm returns an input vector vif there exists an
execution of Pwith values speciÔ¨Åed by vthat leads to an
assertion violation. If no violation is found it may be because
no error exists in kunwindings, or because relevant states
were missed by the underapproximation.
The main data-structure in BLITZ is a set of obligations
Obj. An obligation contains a fragment Fand a formula  Algorithm 3: THE BLITZ ALGORITHM
BLITZ (P: a program,
k: a bound for BMC
w: a weakening parameter
d: a decomposition granularity )
Obj:=;//B M C obligations
foreach fragment Fcontaining an assertion do
Add(F;E(F))toObj
repeat
Remove (F; )from Obj
(res;) := solve(B(F)^ E(F)^ )
ifFis the program entry point then
return ‚ÄúViolation triggered by input inp()‚Äù
else if res=satthen
':=approx-pre (F; ;;w )
Obj:=Obj[next-inst (F;';d)
until Obj is empty
representing a condition for an error. The initial value of  
is the set of assertion violations possible in a program. BLITZ
proceeds by solving the instance generated by each fragment
inObj. In addition to the behaviour and error constraint, we
also use the precondition  as an error constraint.
If a BMC instance is unsatisÔ¨Åable, it is eliminated from Obj
because its behaviour is no longer relevant for Ô¨Ånding a bug.
Otherwise, the instance could be satisÔ¨Åable either because the
error is reachable or because the context in which the fragment
Fexecutes is not taken into account. We Ô¨Årst underapproximate
the error precondition of Fusing the method given earlier
and then propagate this precondition to other fragments in
the program. The subsequent fragments are determined by
following the control- and data-Ô¨Çow of the program.
There are two outcomes which make BLITZ terminate. If
the entry point of the program is reached and the precondition
obtained is satisÔ¨Åable, a satisfying assignment deÔ¨Ånes an
input vector inp()which can be used to trigger an error. The
other outcome is an empty set of obligations. This can occur
either if no assertion is violated, or if the underapproximations
have lost information about states leading to an error. In the
latter case, there is nothing conclusive to report.
The precondition weakening approach proposed in Algo-
rithm 1 can be viewed as an eager weakening approach that
eagerly weakens each precondition up to a pre-determined
boundw. We extend B LITZ with a lazy approach that avoids
having to guess the appropriate weakening bound. The lazy
approach starts by weakening each precondition once. If the
entry of the program is reached with inconclusive results,
BLITZ increments wand backtracks to further weaken a
previously computed precondition. The weakening sites are
chosen based on data-Ô¨Çow and only applied if a precondition
is not the weakest precondition.
Theorem 1. IfBLITZ (P;k;w;d )returns an input vector, an
assertion violation is reachable in P.V. I MPLEMENTATION AND EVALUATION
A. Implementation and Comparison to Other Tools
We implemented B LITZ within the CProver framework,
which is the basis of the bounded model checker C BMC , which
targets ANSI-C [5]. To extract proofs of unsatisÔ¨Åability, we use
a proof-logging version of the SAT solver M INISAT [7].
Our implementation uses several practical optimisations to
improve upon the compositional BMC algorithm we presented.
For one, we interleave unwinding and formula generation, to
avoid storing large structures in memory. This optimisation
inÔ¨Çuences the architecture of implementation. We try to avoid
recomputing information about procedures whenever possible.
When a procedure has different callees, we also try to reuse
preconditions that were computed earlier, if relevant. This
optimisation is a rather weak form of procedure summarisation
used in program analysis.
We compare B LITZ to other tools at a conceptual level.
Tools with the similar goal of bug-Ô¨Ånding and which we
compare with are C BMC , ESBMC and C ORRAL . Architec-
turally, C BMC and E SBMC are similar ‚Äî both tools inline all
procedures into a single BMC instance. Like B LITZ , CORRAL
combines bounded model checking with nondeterminism to
bound the scope of analysis, and is competitive with the state-
of-the-art [11]. Unlike B LITZ , CORRAL inlines procedures on
demand, instead of propagating preconditions. For solvers,
CORRAL and E SBMC use Z3 [6], an efÔ¨Åcient SMT solver;
CBMC and B LITZ use the C PROVER framework, which directly
reduces a BMC instance to SAT and solves it with a SAT
solver. Section VI contains a more detailed discussion of the
algorithmic content of these tools.
B. Benchmarks
We evaluate B LITZ on the Bugbench data set to measure
its performance in detecting known vulnerabilities. Bugbench
is an independent benchmark suite for systematic evaluation
of bug detection tools [12]. It aims to be a representative
collection of real-world C programs with known bugs. In our
evaluation, we used the vulnerability subset of the suite that
focuses on memory safety violations, the most critical type of
bugs. Our results are in Section V-C.
We also applied B LITZ to production software from the
Internet Systems Consortium to search for unknown vulner-
abilities. The ISC develops and distributes critical Internet
infrastructure software to Internet providers worldwide1. We
found new vulnerabilities in multiple production releases of
ISC programs, currently deployed in the Internet. We discuss
these results in Section V-D.
In Section V-E, we evaluate B LITZ under conÔ¨Ågurations
regarding propagation (control vs data-Ô¨Çow) and precondition
weakening. We Ô¨Ånd that data-Ô¨Çow based propagation is key
to B LITZ ‚Äôs scalability. We also Ô¨Ånd that the lazy approach to
weakening preconditions works better than the eager approach.
All experiments were performed on Intel Xeon 2.93 GHz
machines with 32GB RAM.
1ISC software is deployed by over 80% of Internet providers worldwide
(http://www.isc.org/).C. Evaluation on the Bugbench Vulnerability Benchmarks
The vulnerability benchmarks in Bugbench consist of
7 programs polymorph, ncompress, man, gzip,
bc, squid andcvs. All benchmarks are labelled with the
location and type of vulnerability: stack overÔ¨Çow, global over-
Ô¨Çow, heap overÔ¨Çow and double free. We list these programs
in Table I with the labels B1-8, and indicate their sizes and
type of vulnerability they contain.
Into each program, we inserted an assertion that if violated
would trigger the vulnerability. We also statically determined
the minimum unwinding krequired to reach the vulnerability.
This value is shown in the table and the same value was used
with all tools. We then used C BMC , ESBMC , CORRAL and
BLITZ to check for assertion violations. C BMC and E SBMC
support slicing, which reduces the size of BMC instances. We
ran these tools with slicing turned on. All tools terminate
once an assertion violation is found, or report no violation
on termination. We used a timeout of 24 hours (86400s).
As listed in the table, an unwinding bound of 1-3was
sufÔ¨Åcient to Ô¨Ånd most vulnerabilities. The only exception was
B2, where an unwinding of k= 2048 was required to reach a
buffer overÔ¨Çow. This was the number of iterations to traverse
a buffer of that size. We ran B LITZ with data-Ô¨Çow driven
propagation and lazy weakening of preconditions. We also
Ô¨Åxed the granularity of each analyzed code fragment in B LITZ
at the level of a procedure in all our experiments. Thus, each
analyzed BMC instance corresponds to a single procedure.
The evaluation results are in rows B1-8 of Table I. C BMC
and E SBMC produced similar results, so we omit E SBMC from
Table I to conserve space.
All tools Ô¨Ånd a vulnerability in benchmarks B1, B3, B4 and
B5, with B LITZ requiring the least amount of time. B LITZ is
the only tool that does not time out and Ô¨Ånds vulnerabilities
in B2, B6, B7 and B8. The maximum time required by B LITZ
was 35.47 minutes to Ô¨Ånd a double-free vulnerability in cvs.
The time and memory required by B LITZ increases with the
size of the benchmark and unwinding bound but we did not
observe a timeout or memory exhaustion.
The experiments demonstrate the utility of underapprox-
imate preconditions for bug-Ô¨Ånding. The underapproximate
preconditions did not usually require more than one weak-
ening, with the exception of B6, where B LITZ backtracked to
weaken the precondition 11 times. The results suggest that our
compositional BMC approach is effective for Ô¨Ånding violations
on real-world programs of signiÔ¨Åcant sizes.
CBMC and B LITZ have similar performance on the smallest
benchmark (B1). Both tools also found the bug in B3. On
benchmarks B2, B4, B5 and B6, C BMC runs out of memory
memory, and on benchmarks B7 and B8, C BMC exceeded the
24-hr timeout.
CORRAL has performance similar to B LITZ on benchmarks
B1, B3, B4 and B5, and outperforms C BMC on benchmark B3.
However, C ORRAL exceeded the 24-hr timeout on benchmarks
B2, B6 and B7, and terminated prematurely without Ô¨Ånding
the vulnerability on the largest benchmark B8.D. Evaluation on ISC Programs
We now evaluate B LITZ on open-source production soft-
ware from the Internet Systems Consortium (ISC). We
use the current production release of aftr v1.1 and
sntp v4.2.6p5 . The Address Family Translation Router
(aftr ) plays a central role in transitioning the global Internet
from IPv4 to IPv6 ‚Äî it provides backwards compatibility
to transport IPv4 trafÔ¨Åc over IPv6 carrier infrastructure. The
transitioning process was launched on June 6, 20122and
is currently ongoing, using the version of aftr in this
evaluation. The program sntp is a reference implementation
of the Simple Network Time Protocol that provides clock
synchronisation over the Internet.
We focus on Ô¨Ånding Null pointer dereference vulnerabilities,
which are not represented in Bugbench. To check for Null
pointer dereferences, we use the default Null pointer deref-
erence assertions inserted by C PROVER . Since we have no
knowledge of any vulnerability in the ISC programs, we used
an unwinding depth of k= 1 for all the tools.
The results are rows I1-2 of Table I. Again, E SBMC pro-
duces similar results to C BMC . CBMC quickly ran out of mem-
ory on these programs. C ORRAL and B LITZ separately found
the same vulnerabilities within minutes. We manually veriÔ¨Åed
the results and have conÔ¨Årmed these vulnerabilities with the
ISC, who will be patching their software for redistribution to
affected Internet providers worldwide.
We brieÔ¨Çy describe the two vulnerabilities in the following
paragraphs.
aftr .A pointer ss1 is dereferenced after a function call
ss1 = stdio open() . The function stdio open()
calls fileno(stdin) in its body, and returns NULL if
fileno(stdin) returns -1 on stream failure. An attacker
with control over the program‚Äôs environment stdin will be
able to exploit the Null pointer dereference.
sntp .A pointer bcastaddr is dereferenced after being
allocated a buffer through a call to realloc . However,
realloc could return NULL when memory allocation fails.
An attacker who is able induce memory allocation failure will
be able to exploit the Null pointer dereference.
E. Evaluation of B LITZ Features
We now evaluate B LITZ using different conÔ¨Ågurations for
propagation and precondition weakening. First, we compare
the effect of using data-Ô¨Çow for propagating preconditions to
that using control-Ô¨Çow on performance. Second, we compare
the performance of an eager and a lazy weakening strategy.
In eager weakening, preconditions are weakened several times
before propagation, while in lazy weakening, all propagation
is performed Ô¨Årst and preconditions are weakened only if an
inconclusive result is obtained at the entry of the program. The
timeout for the experiments was 24 hours (86400s).
Data vs Control-Ô¨Çow Propagation: Fig. 3 compares the
running time between using precondition-guided data-Ô¨Çow
propagation and control-Ô¨Çow based propagation. In 6 of 10
2The Internet Society declared June 6, 2012 the World IPv6 Launch day.L. Program KLOC Vulnerability CBMC CORRAL BLITZ
k Time Mem. Bug Time Mem. Bug #W #R Time Mem. Bug
(s) (MB) (s) (MB) (s) (MB)
Known Vulnerabilities ‚Äî BugBench Benchmark
B1 poly 0.7 Stack OverÔ¨Çow 1 1 21X 2 10X 1 2 1 18X
B2 poly 0.7 Global OverÔ¨Çow 2048 2427 >32768 7>86400 8828 7 1 3 959 10165 X
B3 ncomp 1.9 Stack OverÔ¨Çow 1 12 258X 6 32X 1 3 6 506X
B4 man 4.7 Global OverÔ¨Çow 2 1692 >32768 7 16 119X 1 3 8 156X
B5 gzip 8.2 Global OverÔ¨Çow 1 1567 >32768 7 20 384X 1 3 5 67X
B6 bc 17.0 Heap OverÔ¨Çow 1 4733 >32768 7>86400 212 7 11 10 258 2563 X
B7 squid 93.5 Heap OverÔ¨Çow 1>86400 15462 7>86400 22715 7 1 4 1664 9024X
B8 cvs 114.5 Double Free 3>86400 4301 7 203 56 7 1 30 2128 3871 X
Discovered New Vulnerabilities ‚Äî ISC Programs
I1 aftr 13.3 Null Ptr Deref. 1 664 >32768 7 85 482X 1 2 74 959X
I2 sntp 42.1 Null Ptr Deref. 1 5479 >32768 7 25 136X 2 3 14 227X
TABLE I: Comparison of C BMC , CORRAL and B LITZ on benchmarks. Rows B1-8 contain the evaluation results on known vulnerabilities
in the Bugbench benchmark, while rows I1-2 contain the evaluation results on programs from the Internet Systems Consortium (ISC), where
BLITZ and C ORRAL discovered new vulnerabilities. The ‚ÄúL.‚Äù column lists the benchmark labels. The ‚ÄúKLOC‚Äù column indicates the size
of each benchmark program in thousands of lines of code. The ‚Äú k‚Äù column lists the (statically determined) minimum number of (loop and
recursion) unwindings required to trigger the violation condition in each benchmark. The ‚ÄúTime(s)‚Äù column indicates the length of time
for which the tool ran with >86400 indicating that the tool exceeded the 24-hour timeout. The ‚ÄúMem.(MB)‚Äù column shows the maximum
amount of memory used by the tool in MB. We write >32768 to indicate that the tool exceeded 32GB of memory. The ‚ÄúBug‚Äù column
indicates whether the vulnerability was found by the tool on termination. The ‚Äú#W‚Äù column indicates the number of precondition weakening
passes used in B LITZ , detected automatically using the lazy approach. The ‚Äú#R‚Äù column shows the number of procedure reÔ¨Ånements in the
propagation chain that found the bug.
benchmarks, control-Ô¨Çow based propagation leads to a time-
out. Barring one benchmark on which the two techniques per-
form equally, data-Ô¨Çow based propagation is always superior.
The results suggest data-Ô¨Çow based propagation is key to
scalability of B LITZ . Existing tools such as C ORRAL [11]
and A LTER [21] follow control-Ô¨Çow and inline procedures
on demand. Using information in preconditions to construct
instances allows B LITZ to sidestep code that is irrelevant for
detecting a violation. For example, in one of the largest pro-
grams ( squid ), a single call to the procedure comm close
would have required the analysis of up to 715 million unique
procedure instances if control-Ô¨Çow-based inlining was used.
BLITZ however did not analyze the comm close procedure.
Lazy vs Eager Weakening: We compare lazy and eager
weakening of underapproximate preconditions. A lazy ap-
proach starts the analysis using a weakening bound 1. When
BLITZ terminates with an inconclusive result, the weakening
bound is incremented, and B LITZ backtracks to the Ô¨Årst com-
puted precondition on the data-Ô¨Çow path that is not equivalent
to the weakest precondition. We conÔ¨Ågured the eager approach
to use 11 passes, since this was the upper bound detected by
the lazy approach (see Table I).
Fig. 4 compares the effect of lazy and eager weakening on
running time. The lazy approach leads to shorter running times
because weakening a precondition twice sufÔ¨Åces to discover a
bug in most benchmarks.
VI. R ELATED WORK
This paper lies at the intersection of model checking and
program analysis. Of several techniques to automatically com-
pute information about a program, SLAM is notable for its
success as a software model checker [3]. SLAM requires
repeated calls to a theorem prover to construct abstractions and
reÔ¨Ånes the abstraction using counterexamples. One reÔ¨Ånement100101102103104105100101102103104105
Control-Ô¨Çow propagation running time (s)Data-Ô¨Çow propagation running time (s)Comparison of Running Times
Fig. 3: A comparison of B LITZ running times with data-Ô¨Çow
against control-Ô¨Çow propagation, with 24-hr timeout.
strategy uses weakest preconditions, but these are computed
over single paths, unlike program fragments as in our case.
The compositional approach to system analysis is key for
overcoming the complexity of any real-world system. We
focused on composition deÔ¨Åned with respect to sequential
composition and procedure calls, as in Hoare logic [9]. Com-
positionality is exploited in program analysis [8] and symbolic
execution [1], but we are not aware of it being used in BMC to
date. The B LITZ algorithm is composition in the same sense,
but differs from these above approaches because it uses data-
Ô¨Çow to further reduce the decomposition of the program.100101102103104105100101102103104105
Eager weakening running time (s)Lazy weakening running time (s)Comparison of Running Times
Fig. 4: A comparison of B LITZ running times with lazy against
eager weakening of preconditions, with 24-hr timeout.
A key technique for relevance-driven program analysis is
Craig interpolation, which has numerous applications in formal
veriÔ¨Åcation. Interpolation was applied to over-approximate
reachable states in hardware model checking in [15], to infer
preconditions in [16], [10], and to learn annotations from failed
explorations to improve backtracking efÔ¨Åciency [17], [21]. We
do not use standard techniques for computing interpolants
from proofs because these lead to large formulae and consume
more memory. The preconditions we generate do satisfy the
interpolation condition and can be viewed as a restricted type
of interpolants that have compact representations in addition
to satisfying the usual vocabulary and implication conditions.
Our approach of generalising satisfying instances is in
the same spirit as IC3. IC3 is a technique for incremental
construction of inductive proofs for modular analysis [4].
Unlike IC3, B LITZ only seeks to discover assertion violations
and does not attempt proofs of correctness.
There are two main strategies to apply scope-bounded
analysis. One strategy partitions a program into multiple sub-
programs at the outset (each with a subset of paths), and solve
all of them in parallel [20]. Though amendable to a parallel ar-
chitecture, it may generate a prohibitively large number of sub-
programs. Another strategy is to overapproximate behaviour
outside the scope of bounded analysis, and iteratively reÔ¨Åne it.
Called ‚Äòstructural abstraction‚Äô in C ALYSTO [2], it also used in
CORRAL [11] and A LTER [21]. DC2 further uses a lightweight
static analysis to infer pre- and post-conditions to model the
behavior of procedures outside the scope of analysis, but its
scope expansion is not automatic. C ORRAL automates forward
(callee) scope expansion with stratiÔ¨Åed inlining of procedures
and selective variable abstraction. A LTER alternates between
eager forward (callee) and lazy backward (caller) expansion,
and uses interpolation to learn procedure preconditions that
lead to failed scope expansions, to prevent re-exploration onbacktracking. B LITZ recasts satisfying assignments to obtain
unsatisÔ¨Åable formulae, and then derives intermediate precondi-
tions from unsatisÔ¨Åability proofs. Unlike existing approaches
where the size of a BMC instance grows as more procedures
areinlined , BLITZ can bound the size of instances.
Slicing is commonly used to reduce the size of BMC in-
stances by removing variables that are syntactically irrelevant
to a property (e.g., [19], [18]). It is also known as ‚Äòcone
of inÔ¨Çuence‚Äô reduction, where the set of relevant variables
expands with the size of the slice, diminishing its effectiveness
(e.g., despite slicing, C BMC and E SBMC frequently run out of
time/memory). Beyond syntactic relevance, B LITZ also uses
proofs of unsatisÔ¨Åability to reason about semantic relevance
on small code fragments at a time, producing an overall cone
with much smaller base.
VII. C ONCLUSIONS AND FUTURE WORK
We presented B LITZ , a new, compositional bounded model
checking algorithm for software and showed that it scales BMC
to real-world programs. B LITZ is capable of Ô¨Ånding all known
vulnerabilities in a known data set and has also discovered
new vulnerabilities in widely deployed software. The new
discoveries have led to bug Ô¨Åxes which will soon be deployed.
BLITZ works by constructing a series of BMC instances that
when composed lead to a violation. A novel feature of our
algorithm is the use of underapproximate preconditions in the
context of BMC . The underapproximations are computed using
information from resolution refutations generated by a SAT
solver. The underapproximation guarantees that the tool does
not generate false alarms about the existence of bugs and the
proofs guarantee that the approximation is not too restricted by
considering only facts relevant for the violation. Our procedure
is parametric, allowing for the preconditions to be iteratively
weakened to eventually derive Dijkstra‚Äôs weakest precondition,
if resources permit. The size of code fragments analysed is
conÔ¨Ågurable and can range from a single statement to an entire
procedure, depending on code-size and memory available.
There are several directions to explore. We did not use Craig
interpolation over proofs because the formulae were large.
An interesting question is whether proofs can be manipulated
to yield interpolants that have compact representations and
whether this improves performance. A second question is how
one may guess the optimal conÔ¨Åguration of the algorithm
(unwinding, weakening, granularity) by a preliminary analysis
of the code. Third, concrete and symbolic representations have
been combined in symbolic execution with great success but
such an approach has not been applied to BMC . We anticipate
that combining concrete values with BMC may provide new
opportunities for decomposition.
ACKNOWLEDGMENTS
We thank the anonymous reviewers for their valuable feed-
back. This work is partially supported by NSF under grant
0831501 CT-L; by AFOSR under MURI award FA9550-09-
1-0539; by ONR under MURI grant N000140911081; and by
DARPA under award HR0011-12-2-005.REFERENCES
[1] Saswat Anand, Patrice Godefroid, and Nikolai Tillmann. Demand-
driven compositional symbolic execution. In Conference on Tools and
algorithms for the construction and analysis of systems , TACAS, pages
367‚Äì381, Berlin, Heidelberg, 2008. Springer-Verlag.
[2] Domagoj Babic and Alan J. Hu. Calysto: scalable and precise extended
static checking. In Proceedings of the 30th international conference on
Software engineering , ICSE ‚Äô08, pages 211‚Äì220, New York, NY , USA,
2008. ACM.
[3] Thomas Ball, Rupak Majumdar, Todd Millstein, and Sriram Rajamani.
Automatic Predicate Abstraction of C Programs. In PLDI‚Äô01: Proc. of
the ACM SIGPLAN 2001 Conf. on Programming Language Design and
Implementation , volume 36 of ACM SIGPLAN Notices , pages 203‚Äì213.
ACM Press, 2001.
[4] Aaron R. Bradley. SAT-based model checking without unrolling. In
Proceedings of the 12th international conference on VeriÔ¨Åcation, model
checking, and abstract interpretation , VMCAI‚Äô11, pages 70‚Äì87, Berlin,
Heidelberg, 2011. Springer-Verlag.
[5] Edmund Clarke, Daniel Kroening, and Karen Yorav. Behavioral con-
sistency of c and verilog programs using bounded model checking. In
Proceedings of the 40th annual Design Automation Conference , DAC
‚Äô03, pages 368‚Äì371, New York, NY , USA, 2003. ACM.
[6] Leonardo de Moura and Nikolaj Bj√∏rner. Z3: An efÔ¨Åcient SMT solver.
InTACAS‚Äô08: Proc. of the 14th Int. Conf. on Tools and Algorithms for
the Construction and Analysis of Systems , volume 4963 of Lecture Notes
in Computer Science , pages 337‚Äì340. Springer, 2008.
[7] Niklas E ¬¥en and Niklas S ¬®orensson. An extensible SAT-solver. In Enrico
Giunchiglia and Armando Tacchella, editors, SAT, volume 2919 of
Lecture Notes in Computer Science , pages 502‚Äì518. Springer, 2003.
[8] Patrice Godefroid, Aditya V . Nori, Sriram K. Rajamani, and Sai Deep
Tetali. Compositional may-must program analysis: unleashing the power
of alternation. SIGPLAN Not. , 45(1):43‚Äì56, January 2010.
[9] C. A. R. Hoare. An axiomatic basis for computer programming.
Commun. ACM , 12(10):576‚Äì580, October 1969.
[10] Daniel Kroening and Georg Weissenbacher. Interpolation-based software
veriÔ¨Åcation with wolverine. In Proceedings of the 23rd international
conference on Computer aided veriÔ¨Åcation , CA V‚Äô11, pages 573‚Äì578,
Berlin, Heidelberg, 2011. Springer-Verlag.[11] Akash Lal, Shaz Qadeer, and Shuvendu K. Lahiri. A solver for
reachability modulo theories. In Proceedings of the 24th international
conference on Computer Aided VeriÔ¨Åcation , pages 427‚Äì443, Berlin,
Heidelberg, 2012. Springer-Verlag.
[12] Shan Lu, Zhenmin Li, Feng Qin, Lin Tan, Pin Zhou, and Yuanyuan
Zhou. Bugbench: Benchmarks for evaluating bug detection tools. In In
Workshop on the Evaluation of Software Defect Detection Tools , 2005.
[13] In ÀÜes Lynce and Jo Àúao P. Marques Silva. On computing minimum
unsatisÔ¨Åable cores. In Conference on Theory and Applications of
SatisÔ¨Åability Testing . Online Proceedings, 2004.
[14] K. L. McMillan. Relevance heuristics for program analysis. In
Symposium on Principles of programming languages , pages 145‚Äì146.
ACM, 2008.
[15] Kenneth L. McMillan. Interpolation and SAT-based model checking.
InConference on Computer Aided VeriÔ¨Åcation , pages 1‚Äì13, Berlin,
Heidelberg, 2003. Springer-Verlag.
[16] Kenneth L. McMillan. Lazy abstraction with interpolants. In Confer-
ence on Computer Aided VeriÔ¨Åcation , CA V‚Äô06, pages 123‚Äì136, Berlin,
Heidelberg, 2006. Springer-Verlag.
[17] Kenneth L. McMillan. Lazy annotation for program testing and
veriÔ¨Åcation. In Computer Aided VeriÔ¨Åcation , pages 104‚Äì118, 2010.
[18] Bruno Cuervo Parrino, Juan Pablo Galeotti, Diego Garbervetsky, and
Marcelo F. Frias. A dataÔ¨Çow analysis to improve sat-based bounded
program veriÔ¨Åcation. In Proceedings of the 9th international conference
on Software engineering and formal methods , SEFM‚Äô11, pages 138‚Äì154,
Berlin, Heidelberg, 2011. Springer-Verlag.
[19] Danhua Shao, Divya Gopinath, Sarfraz Khurshid, and Dewayne E.
Perry. Optimizing incremental scope-bounded checking with data-
Ô¨Çow analysis. In Proceedings of the 2010 IEEE 21st International
Symposium on Software Reliability Engineering , ISSRE ‚Äô10, pages 408‚Äì
417, Washington, DC, USA, 2010. IEEE Computer Society.
[20] Danhua Shao, Sarfraz Khurshid, and Dewayne E. Perry. An incremental
approach to scope-bounded checking using a lightweight formal method.
InProceedings of the 2nd World Congress on Formal Methods , FM ‚Äô09,
pages 757‚Äì772, Berlin, Heidelberg, 2009. Springer-Verlag.
[21] Nishant Sinha, Nimit Singhania, Satish Chandra, and Manu Sridha-
ran. Alternate and learn: Ô¨Ånding witnesses without looking all over.
InProceedings of the 24th international conference on Computer
Aided VeriÔ¨Åcation , CA V‚Äô12, pages 599‚Äì615, Berlin, Heidelberg, 2012.
Springer-Verlag.