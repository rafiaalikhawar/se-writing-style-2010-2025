Practical and Effective Symbolic Analysis for Buffer
Overﬂow Detection
Lian Li Cristina Cifuentes Nathan Keynes
Sun Labs, Oracle
Brisbane, Australia
{lian.li,cristina.cifuentes,nathan.keynes}@oracle.com
ABSTRACT
Although buﬀer overﬂow detection has been studied for more
than 20 years, it is still the most common source of security
vulnerabilities in systems code. Diﬀerent approaches using
symbolic analysis have been proposed to detect this vul-nerability. However, existing symbolic analysis techniques
are either too complex to scale to millions of lines of code
(MLOC), or too simple to eﬀectively handle loops and com-
plex program structures.
In this paper, we present a novel symbolic analysis algo-
rithm for buﬀer overﬂow detection that applies simple rulesto solve relevant control and data dependencies. Our ap-
proach is path-sensitive and eﬀectively handles loops and
complex program structures. Scalability is achieved by us-ing a simple symbolic value representation, ﬁltering out ir-
relevant dependencies in symbolic value computation and
computing symbolic values on demand.
Evaluation of our approach shows that it is both practi-
cal and eﬀective: the analysis runs over 8.6 MLOC of theOpenSolaris
TMOperating system/Networking (ON) code-
base in 11 minutes and ﬁnds hundreds of buﬀer overﬂows
with a false positive rate of less than 10%.
Categories and Subject Descriptors
D.2.5 [ Software Engineering ]: Testing and Debugging–
Symbolic execution
General Terms
Reliability, Security
1. INTRODUCTION
Although buﬀer overﬂow detection has been studied for
more than 20 years, it is still the most common source ofsecurity vulnerabilities in systems code. In a study of bugs
that lead to publicly reported vulnerabilities, MITRE re-
ports that 19% of all security vulnerabilities over the period2001-2006 were due to buﬀer overﬂows [6]. Diﬀerent ap-proaches have been proposed to detect this vulnerability,
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies arenot made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.FSE-18, November 7–11, 2010, Santa Fe, New Mexico, USA.
Copyright 2010 ACM 978-1-60558-791-2/10/11 ...$10.00.including both dynamic [26, 25, 20] and static [12, 32, 10,
17] techniques.
Symbolic analysis [16] is a static analysis technique that
represents the values of program variables and computations
with symbolic values. Recently, diﬀerent symbolic analysis
approaches [29, 4, 32, 14, 10, 15, 31, 1, 2, 17, 22, 5] have been
proposed to detect buﬀer overﬂows and promising results
were reported. However, these approaches are still eithertoo complex to scale to millions of lines of code (MLOC), or
too simple to eﬀectively handle loops and complex program
structures.
Complex approaches that do not scale well to MLOC in-
clude [4, 1, 22, 5]. These approaches exhaustively traverseall possible execution paths and use an external constraint
solver or a theorem prover to try to solve all data and con-
trol dependencies on each path. Although they can be very
precise, these approaches are hard to scale to large applica-tions due to the unbounded number of execution paths and
the complexity of solving all dependencies on each path. As
a result, they are mostly used in unit testing [22, 5, 23].
Simpler approaches that trade precision for scalability in-
clude: not being path-sensitive and only providing very lim-ited support for control dependencies [29, 14], only support-ing very limited computation between symbolic values [12,32], i.e., limited support for data dependencies, or using sim-
ple heuristics to handle loops and complex control structures
[32, 2]. These tradeoﬀs not only miss many bugs, they mayalso introduce numerous false alarms.
In this paper, we propose a new symbolic analysis tech-
nique for buﬀer overﬂow detection. Here buﬀer overﬂow
refers to buﬀer bounds violation via both read and write
accesses. Compared to previous approaches, we apply sim-
ple rules to solve relevant data and control dependenciesiteratively. The analysis is path-sensitive and handles loops
and complex program structures eﬀectively. Scalability is
achieved by using a simple symbolic value representation,ﬁltering out irrelevant dependencies in symbolic value com-putation, and computing symbolic values on demand.
Our demand-driven algorithm has been implemented in
Parfait [8], a scalable bug-checker built on top of LLVM [18].As shown in Section 6, our experimental results against large
systems code show that it is both practical and eﬀective.
In summary, this paper makes the following contributions:
•We propose a new symbolic analysis technique for buﬀeroverﬂow detection. The technique is simple yet eﬀec-
tive. It can be easily implemented and integrated withother analysis techniques.
317
•We develop a new demand-driven symbolic analysis
algorithm to compute the symbolic value of a variableeﬃciently.
•We evaluate our implementation using several large
applications, including the OpenSolaris
TMOperating
system/Networking (ON) consolidation. Experimental
results show that this technique is practical and eﬀec-
tive. It analyzes 8.6 MLOC of the OpenSolaris ONcodebase in 11 minutes on an Intel E8600 3.33GHz
processor and identiﬁes hundreds of buﬀer overﬂows
with a false positive rate of less than 10%.
The rest of the paper is organized as follows. Section 2
reviews related work. In Section 3, we show an example
to motivate our approach. The symbolic analysis technique
is described in Section 4 and the algorithm is presented in
Section 5. We evaluate the scalability and eﬀectiveness ofour approach in Section 6 and Section 7 concludes the paper.
2. RELATED WORK
Symbolic analysis was introduced in the ’70s [16] and has
recently been applied in many approaches to detect buﬀer
overﬂows [29, 14, 24, 10, 32, 15, 17, 2, 22, 5]. In symbolic
analysis, the program is executed with symbolic values asinput. During symbolic execution, values of program vari-
ables are computed as symbolic expressions by manipulating
program expressions involving symbolic values, i.e., solving
data dependencies symbolically. Control statements such as
branch instructions are executed by (conceptually) follow-ing both branches, and maintaining the control predicateinformation, i.e., control dependencies , on each branch.
Existing symbolic analysis techniques diﬀer from each other
in their diﬀerent representations of symbolic values and howthe symbolic values are computed. In [29, 14], the symbolic
values are simpliﬁed as integer ranges and the authors map
the range analysis problem into an integer linear program-
ming (ILP) problem, which is exponential. Rugina and Ri-nard [24] reduce the ILP problem to a linear programming
problem by using a diﬀerent symbolic representation: the
symbolic value of a variable is abstracted as a linear functionof the set of input variables, then a linear constraint solver
is used to solve the linear representation for each variable.
However, for large applications with millions of LOC, it willbe very time-consuming for the linear constraint solver to
solve the representations of all program variables together.
These approaches are not path-sensitive in that control de-pendencies are either not used at all or are discarded at in-
structions where diﬀerent execution paths merge, leading to
imprecision in the buﬀer overﬂows reported (i.e., high false
positive rate).
Xie et al. [32] use linear derivations of a single symbol to
represent symbolic values, which are then computed by in-terpreting the program. In their approach, computations be-tween symbolic values are not supported and loops with non-
constant iterations are handled by simply unrolling them
once and terminating them with an assumption that theloop test has failed. This simpliﬁcation in handling loops,
although adopted in various approaches [13, 31, 2], can miss
many bugs and may cause some false positives as well. In [10],the authors formalized symbolic analysis as a special case of
abstract interpretation [9]. They deﬁned a set of abstract
domains to represent symbolic values at diﬀerent levels ofprecision and the users can select which abstract domain touse. The more precise the abstract domain is, the more ex-
pensive the analysis will be. Their approach can scale totens of thousand LOC as described in the paper. The
technique described in this work can be integrated as a dif-
ferent abstract domain in their frameworks.
Compared to the above approaches, symbolic analysis as
applied in unit testing [1, 22, 5] is often more precise byexhaustively traversing all possible execution paths and us-
ing an external constraint solver or theorem prover to solveall data and control dependencies on each path, where con-
trol dependencies are often represented as extra constraints
on each path. Given that the number of possible executionpaths is unbounded in the presence of loops, and that the
execution path can be very long, restrictions are often in-
troduced to limit the number of iterations to traverse a loopand the number of constraints on each execution path.
The authors in [17] improve the scalability of the above
approaches by being demand-driven: instead of symbolicallyexecuting the program, they exhaustively traverse all pos-
sible execution paths backwards from each buﬀer access in-
struction. During the backward traversal, extra data depen-
dencies and control dependencies are analyzed incrementallyby an external constraint solver, allowing for the analysis of
hundreds of thousand LOC. As in [1, 22, 5], loop bounds
and path restrictions are applied.
In this paper, we use a diﬀerent tradeoﬀ for precision and
scalability by iteratively solving relevant data dependencies
and control dependencies when computing the symbolic val-
ues of a program variable. Instead of exhaustively traversingall execution paths, we only consider linearly-related control
dependencies which can be eﬃciently solved. Since the val-
ues of array index variables often only depend on data andlinearly-related control dependencies, it is very eﬀective in
ﬁnding buﬀer overﬂows. As a result, our approach is both
scalable and eﬀective as shown in our experimental results,
scaling well to millions LOC.
3. A MOTIVATING EXAMPLE
We present the C-code fragment in Figure 1(a) to illus-
trate our approach. The function tosunds strproduces a new
string by adding a letter CAPCHAR in front of every capital
letter in the input string. It ﬁrstly creates a new buﬀer buf
with size n(lines 5 and 6). Then, in the forloop (lines 8
- 13), every letter in the input string stris processed and
copied to buf, where a letter CAPCHAR will be inserted in
front of the processed letter if it is in uppercase. After the
forloop, the null string terminator will be appended at the
end of bufas shown in lines 14 - 16.
In the above example, a buﬀer overﬂow may occur at line
11 as highlighted in the shadow box. The forloop exits in
line 12 if the index variable jis larger than or equal to the
buﬀer size n. However, the loop will keep executing if jis
equal to n-1. In that case, in the next iteration of the loop,
the assignment to bufin line 11 may overﬂow.
3.1 The Intermediate Representation
Figure 1(b) shows the control ﬂow graph (CFG) and the
single static assignment (SSA) representation [11] for the
program in Figure 1(a), where each instruction is given a
unique label and only relevant basic blocks are shown. In
SSA form, all variables have a single deﬁnition and at join
points, where diﬀerent paths in the CFG merge, a phiin-
struction is introduced as the new deﬁnition of a variable
318/* Puts CAPCHAR in front of uppercase characters
* For example (assuming CAPCHAR = ’%’):
*i fs t r=A B c ,i tr e t u r n s% A % B c* /
1 char * tosunds str(char * str) {
2 int i, j, n;
3 char * buf;4 ...;
5n = ...; //n is deﬁned by external function
6 buf = malloc(n * sizeof(char));7j = 0 ;8f o r ( i = 0 ; i <strlen(str); i++) {
9 if (isupper(str[i]))
10 buf[j++] = CAPCHAR;
11buf[j++] = str[i];
12 if (j >= n) break;
13 }
14 if (j+1 >=n)
15 j = n-1;
16 buf[j] = ’ \0’;
17 return buf;
18}P2i0 = phi(0,i1);
P3j0 = phi(0, j3);
P4pred0 = (i0<strlen(str));
P5if (¬pred0) goto bb5;
P6  pred1 = isupper(str[i0]);
P7if (¬pred1) goto bb3;
P8buf[j0] = CAPCHAR;
P9 j1 = j0+1;
P10 j2 = phi(j1, j0);
P12 j3 = j2+1;
P13 pred2 = (j3 >=n);
P14 if (pred2) goto bb5;
P15 i1 = i0+1;
P16  goto bb0;P17  j4= phi(j3, j0)
P18  pred3 = (j4+1 <n);
P19  if (pred3) goto bb7;
P20  j5 = n-1;
P23  return buf;bb5
bb7bb6bb4bb3bb2bb1bb0P0n = …;
P1buf = malloc(n*sizeof(char));
P21  j6 = phi(j4,j5);
P22  buf[j6] = `\0`;P11  buf[j2] = str[i0];
(a) The code snippet (b) The intermediate representation (IR) for the example code in (a)
Figure 1: A motivating example abstracted from usr/src/cmd/fs.d/autofs/ns ldap.c in OpenSolaris ON.
if it has been deﬁned along distinct paths. For example, in
bb3in Figure 1(b), where the buﬀer overﬂow is located (line
11 in Figure 1(a)), a phi instruction j2is introduced at P10
to represent the new deﬁnition of index variable j.
As is common practice in modern compilers such as GCC
and LLVM, only scalar variables whose addresses are never
taken are represented in SSA form. Variables which may be
referenced by pointers are accessed via load and store in-structions. Program values include constants and variablesdeﬁned by SSA or load instructions.
For illustration purposes, we explicitly label each control
predicate as a separate instruction at P4, P6, P13 and P18
in Figure 1(b). Control predicates are those conditional ex-
pressions used in instructions that alter the ﬂow of control,
i.e., the conditional branch instructions at P5, P7, P14 and
P19. All control predicates are normalized as relational ex-
pressions in the form pred
=(Op1∼Op2), where predis the
label of the control predicate, Op1andOp2are the left and
right hand operands and ∼is a relational operator.
3.2 Data and Control Dependencies
In our intermediate representation, each variable is de-
ﬁned by a unique instruction. For a variable V, letDVbe
the unique instruction where Vis deﬁned. At diﬀerent in-
structions, the possible values of Vcan be diﬀerent (due to
control dependencies of the instruction), and we use SV,P
to represent the symbolic value of Vat instruction P.F o r
buﬀer overﬂow detection, at each instruction Pwhere Vis
used as an index variable into a buﬀer, we will try to com-
puteSV,Pto detect buﬀer overﬂows.
Both data and control dependencies need to be considered
to compute SV,P. Data dependencies refer to the incoming
operands of the instruction by which Vis deﬁned. Control
dependencies refer to those control predicates that need tobe satisﬁed for Pto be executed.
Consider our motivating example. To detect the buﬀer
overﬂow in line 11 in Figure 1(a), we need to compute thevalue of index variable j2, i.e.,S
j2,P11. The data dependencies
between variables j3, j0, j1, and j2, and the control depen-dency pred2 atP13need to be considered. Note that these
dependencies form a cycle and need to be solved iteratively.
The control predicate pred2=(j3>=n)must be false to allow
the use of j3atP3inbb0to be executed. As a result, we
haveSj3,P3andSj0,P3must be less than n. Then the values
ofj1, j2, and j3can be iteratively computed and the buﬀer
overﬂow at P11(line 11 in Figure 1 (a)) via index variable
j2can be identiﬁed.
The example shows that both data and control dependen-
cies need to be considered in computing the symbolic value
of a variable at an instruction. Those dependencies often
form a cycle and we need to iteratively compute the valuesof program variables to address cyclic dependencies. How-
ever, not all dependencies are useful in the computation.
For example, pred0 atP4inbb0,pred1 atP6inbb1are not
useful in computing S
j2,P11. The key therefore is to deter-
mine which dependencies need to be considered and how the
value of a program variable can be computed based on those
dependencies.
4. SYMBOLIC ANALYSIS
Based on the observations in Section 3, we have developed
a new technique to compute values of program variables
symbolically. We use symbolic ranges to represent values
of program variables at each instruction. The bounds of the
symbolic ranges are deﬁned in a simple symbolic expressiondomain as explained in Section 4.1.
The simple symbolic expression domain enables us to com-
pute the symbolic ranges of program variables at each in-
struction very eﬃciently. In Section 4.2, simple rules are
introduced for computing the symbolic ranges of program
variables according to various control and data dependen-cies. The symbolic ranges of program variables can then becompared with buﬀer sizes to detect buﬀer overﬂows.
4.1 Symbolic Value Representation
Symbolic ranges are introduced to represent the values of
program variables at each instruction. The symbolic range
319for variable Vat instruction P,SV,P, is deﬁned by its lower
and upper bound, denoted as SV,PminandSV,Pmax,r e s p e c -
tively. Both SV,PminandSV,Pmaxare symbolic values de-
ﬁned in a simple symbolic expression domain as explained
below.
4.1.1 A Simple Symbolic Expression Domain
The set of symbolic expressions Eincludes a set of atomic
symbols and their aﬃne functions as derivations. The sym-
bolic expression set Ehas the following property:
Property 1.Every symbolic expression EinEis an
aﬃne function of an atomic symbol in E.
Constant value 0 is regarded as an atomic symbol from
which all constant values are derived. Property 1i se n -
forced by how symbolic expressions are introduced into E.
Initially the set is ∅. During the analysis, new atomic or
derived symbolic expressions may be introduced into Eto
represent computations between symbolic expressions. A
new atomic symbol will be introduced if the computationresults cannot be represented as an aﬃne function of exist-
ing atomic symbols in E. For example, if we try to add two
symbolic expressions E
1=X+1a n d E2=2Y+3 ,w h e r e X
andYare atomic symbols, a new atomic symbol Z=X+2Y
will be introduced intoEif no existing atomic symbol is aﬃne
toZ.
This simple strategy in performing computation between
symbolic expressions is very eﬃcient and easy to implement.
However, it is also very eﬀective in ﬁnding buﬀer overﬂows
as demonstrated in our experimental results in Section 6.
The symbolic expression set Eis partially ordered by ≺,
where for any two symbolic values E1andE2inE,E1≺E2iﬀ
their subtraction E1−E2is no larger than 0. By convention,
/latticetopand⊥are introduced in E.∀E∈E,w eh a v e ⊥≺Eand
E≺/latticetop.T h et w oo p e r a t i o n sm e e t /intersectionsqand join /unionsqare deﬁned as
follows:
E1/intersectionsqE2=8
><
>:E1ifE1≺E2
E2ifE2≺E1
⊥otherwiseE1/unionsqE2=8
><
>:E2ifE1≺E2
E1ifE2≺E1
/latticetopotherwise
(1)
4.1.2 Symbolic Ranges
The symbolic range of variable Vat instruction P,SV,P=
[SV,Pmin,SV,Pmax], is deﬁned by its lower bound SV,Pmin
and upper bound SV,Pmax.B o t h SV,PminandSV,Pmaxare
symbolic expressions deﬁned in Eand it implicitly implies
that at instruction P,w eh a v e SV,Pmin≺SV,Pmax.T h es y m -
bolic range SV,Prepresents the set of all symbolic expres-
sions EinEsuch that SV,Pmin≺EandE≺SV,Pmaxmay
be true. The set is ∅if no symbolic expression in Esatis-
ﬁes such condition and we use [ /latticetop,⊥] to represent an empty
range. The union and intersect of two symbolic ranges can
be computed as follows:
S1∪S2=[S1min/intersectionsqS2min,S1max/unionsqS2max]
S1∩S2=[S1min/unionsqS2min,S1max/intersectionsqS2max](2)
LetBbe the size of the buﬀer and let Vbe the index vari-
able, a buﬀer overﬂow will be reported if SB,Pmax≺SV,Pmax
orSV,Pmin≺-11. A buﬀer access cannot overﬂow if
1We assume that the accessed buﬀer is indexed from 0, as
for C.Symbolic Range Algebra S1•S2
S1+S2=[S1min+S2min,S1max+S2max]
S1−S2=[S1min−S2max,S1max−S2min]
S×E=[Smin×E,Smax×E]∪[Smax×E,Smin×E]
S1×S2=S1×S2min∪S1×S2max
S÷E=[Smin÷E,Smax÷E]∪[Smax÷E,Smin÷E]
S1÷S2=(
[⊥,/latticetop]0 ∈S2
S1÷S2min∪S1÷S2max otherwise
S%E=8
><
>:[1 +E/intersectionsq1−E,0] Smax≺0
[0,E−1/unionsq−1−E]0 ≺Smin
[1 +E/intersectionsq1−E,E−1/unionsq−1−E]o t h e r w i s e
S1%S2=(
[⊥,/latticetop]0 ∈S2
S1%S2min∪S1%S2max otherwise
Figure 2: Simple integer arithmetic operations between
symbolic ranges. Erepresents a symbolic expression in
Eand•represents an integer arithmetic operation.
SV,Pmax≺SB,Pmin−1a n d0 ≺SV,Pmin. Note that such buﬀer
accesses are guaranteed to be within buﬀer bounds since the
symbolic ranges are computed conservatively as described in
Section 4.2. Otherwise, we consider the buﬀer access to beapotential buﬀer overﬂow , that is our analysis cannot de-
termine with certainty whether or not a vulnerability exists.Potential buﬀer overﬂows are not reported as bugs.
4.2 Computing Symbolic Ranges
We support common integer arithmetic computations, in-
cluding + ,−,×,÷and %, between two symbolic ranges.
The resulting range represents the set of symbolic expres-
sions obtained by computing the operation over any two
symbolic expressions selected from each input range:
∀E1∈S1,∀E2∈S2→E1•E2∈S1•S2
where •represents an arithmetic operation.
Figure 2 shows the simple algebraic equations. The equa-
tions for + and −are self-explanatory. For the operation
×, let us ﬁrst look at the simple case of applying the mul-
tiplication operator to a symbolic range Sand a symbolic
expression E,S×E. The product could be in the range
[Smin×E,Smax×E]o r[Smax×E,Smin×E], depending on
whether Eis positive or negative. Then the range of S1×S2
can be computed as shown in Figure 2. Similar equations
are derived for the ÷operator. Note that we conservatively
assume that any range divided by 0 will result in the sym-
bolic range [ ⊥,/latticetop], which includes all symbolic expressions
inE. In the equation for S%E,w h e r e Sis a symbolic
range and Eis a symbolic expression, the remainder will
carry the same sign as the dividend as speciﬁed in the C99
standard. The equation for applying the modulo operationto two symbolic ranges is derived in the same way.
Given the simple symbolic range algebra, S
V,P,t h es y m -
bolic range for variable Vat instruction P, is then computed
according to data and control dependencies. Two steps are
involved in computing SV,P. Firstly we compute the sym-
bolic range of V,SV, according to data dependencies. Then
SV,Pis computed by reﬁning SVwith relevant control de-
pendencies. We call SVthedeﬁne range ofV,a n d SV,Pthe
use range ofVatP. Note that variable Vwill have diﬀer-
ent use ranges SV,P1andSV,P2at instructions P1andP2,i f
diﬀerent control dependencies are considered.
In this section, we explain how to select the relevant de-
pendencies and introduce the simple rules for computing
320symbolic ranges according to those dependencies. The com-
puted symbolic range is conservative in that for each vari-able, its symbolic ranges are always a superset of its possi-
ble values. More precise symbolic ranges can be computed
if more accurate dependency information is provided, either
via compiler analysis or user annotation.
4.2.1 Data Dependencies
Data Dependencies Deﬁne Ranges SV
V=Op1•Op2 SOp1,DV•SOp2,DVV=phi(Op1,Op2) SOp1,DV∪SOp2,DV
V=Load(A, I) [A[SI,DVmin].../intersectionsq... A[SI,DVmax],
(Ais constant
aggregate) A[SI,DVmin].../unionsq... A[SI,DVmax]]
V=Input [V.Type.min, V.Type.max ]
V=Unsolved [V,V]
Figure 3: The rules for computing the deﬁne range of V,
SV,a c c o r d i n gt od a t ad e p e n d e n c i e s . DVis the instruc-
tion where Vis deﬁned, •represent an arithmetic in-
struction. V.Type.min and V.Type.max represent the min-
imal and maximal value that could be represented by the
type of V, i.e., V.Type . The instruction V=Unsolved rep-
resents the set of instructions that will not be handledby our analysis.
Figure 3 outlines the rules to compute the deﬁne range of
variable V,SV, according to data dependencies. For vari-
ables deﬁned by arithmetic instructions + ,−,×,÷and %,
their deﬁne ranges are computed according to the symbolic
range algebra in Figure 2. Similar rules with small exten-sions can be applied to variables deﬁned by arithmetic shift
instructions. The deﬁne range of a phi instruction is the
union of the use ranges of all its operands from their cor-
responding incoming blocks, assuming that it can hold any
value from its incoming operands.
Memory dependencies are solved only if the variable is
loaded from a constant buﬀer. Its deﬁne range will be com-
puted by checking the range of the index variable and all pos-
sible values in the buﬀer. This may sound restrictive. How-
ever, it is eﬀective in detecting vulnerabilities such as buﬀer
overﬂows, where index variables are often either scalars or
loaded from constant arrays (as indirect array accesses). Fi-
nally, the deﬁne range of a variable deﬁned by user inputincludes any value that can be represented by its type.
Note that we do not try to solve the data dependencies
for all variables. Instead, for a variable whose deﬁne rangecannot be solved ( V=Unsolved ), such as library call returns
or bit-mask operations, we introduce a unique atomic symbol
into the symbolic expression set Eand the deﬁne range of
the variable is deﬁned by the introduced symbol as both itslower and upper bound.
For illustration, Figure 3 only shows the rules for comput-
ing data dependencies intra-procedurally. However, theserules can be easily extended to inter-procedural analysis by
propagating the values of function actual arguments to callee
functions and function return values to caller functions.
4.2.2 Control Dependencies
At instruction P, the use range SV,Pis computed by re-
ﬁning the deﬁne range of Vaccording to relevant control
dependencies such that Pmay be executed given any value
ofVinSV,P. A control dependency will be considered incomputing SV,Pif it controls both the execution of instruc-
tionPand the value of V. We conservatively deﬁne that a
predicate predcontrols the execution of instruction Pif 1)
predstrictly dominates P, i.e., every path from the entry
of the CFG to Pincludes pred,a n d2 ) Pis only reachable
from one successor of the conditional branch instruction that
usespred. Then the outcome of predmust be true or false
depending on which successor can reach P.
Control
Dependencies Use Ranges SV,P
pred=
Op1=Op2 SV∩C1×SOp2,pred+C2
Op1≤Op2 SV∩[⊥,C1×SOp2,predmax+C2]
Op1≥Op2 SV∩[C1×SOp2,predmin+C2,/latticetop]
Op1/negationslash=Op28
><
>:SV\{SVmin}V=SVmin→Op1=Op2
SV\{SVmax}V=SVmax→Op1=Op2
SV otherwise
Figure 4: The rules for computing SV,Paccording to
direct control dependencies. Control predicates are in
the form of pred=(Op1∼Op2), where Op1and Op2are
the left and right hand operands and ∼is a relational
operator. The predicates are normalized in such a way
that V=C1×Op1+C2and C1>0.
Control predicates are in the form of pred=(Op1∼Op2),
where ∼is a relational operator. A control predicate may
control the value of Vdirectly or indirectly, depending on
how its operands relate to V.Op1isdirectly related toVif it
is deﬁned as an aﬃne function of V, i.e.,Op1=C1×V+C2
where both C1andC2are constants, or if Vis deﬁned as an
aﬃne function of Op1.Op1isindirectly related toVifOp1is
loaded from a buﬀer with the index variable directly related
toV,o ri f Vis loaded from a buﬀer with the index variable
directly related to Op1. Accordingly, those dependencies
are called direct orindirect control dependencies. Similarly
to memory data dependencies, indirect control dependen-
cies can be transformed to direct control dependencies by
examining the content of the buﬀer.
Figure 4 shows how to compute SV,Paccording to direct
control dependencies. All control predicates are normalized
in such a way that Op1is directly related to V. The deﬁne
range SVis intersected with a range deﬁned by the aﬃne
function between Op1andV, the relational operator ∼and
the use range SOp2,pred. If multiple control predicates need
to be considered in computing SV,P,t h e n SVwill be reﬁned
multiple times according to the rules described in Figure 4.
4.3 Enhancements
Our analysis can be improved if more detailed dependency
information is provided, either via compiler analysis or user
annotation. Here we introduce two important compiler anal-
ysis enhancements.
4.3.1 Loop Induction Variable Analysis
Loop induction variables refer to those variables whose
values take on a simple progression in successive iterations
of a loop. Loop induction variable analysis [3] tries to repre-
sent such variables as functions to the loop iteration number,thus dependencies between induction variables and loop it-
eration numbers can be considered when computing their
symbolic ranges. This analysis is important for buﬀer over-
ﬂow detections since induction variables commonly appear
321as loop indices and in subscript computations. In our anal-
ysis, we only consider induction variables which are aﬃnefunctions of the loop iteration number.
4.3.2 Path Sensitive Analysis
The analysis so far is predicate-aware but it is not fully
path sensitive. We have considered the control dependen-
cies of a variable’s uses, but have not considered the control
dependencies of its deﬁnitions. At a phi instruction, wherevalues deﬁned along diﬀerent paths merge, path-sensitive
analysis will check from which paths a deﬁnition will reach
the phi instruction. Then the deﬁne and use ranges of a phi
instruction can be more precisely computed by also consider-ing the control dependencies along the paths of its incoming
deﬁnitions.
We compute gated single assignment (GSA) [21] form for
path-sensitive analysis as needed. In GSA form, the phi in-struction V=phi(V1,V2) is extended to a binary decision
tree called a γtree. The incoming deﬁnitions V1a n d V2
are leaf nodes in the γtree with predicate nodes as internal
nodes in the tree to guide which deﬁnition to choose. When
computing the symbolic range for a phi instruction, we re-cursively traverse the γtree and compute the use ranges of
its incoming operands according to the control dependenciesof the phi instruction as well as those control predicates intheγtree. By only computing the GSA form on demand
for relevant phi instructions, the runtime overhead is mini-
mized.
5. THE DEMAND-DRIVEN ALGORITHM
Algorithm 1 Compute the use range SV,P
1:procedure ComputeUseRange (V,P)
2: ComputeDefRange( V)
3: SV,P:=RefineDefRange( V,P)
4:end procedure
As explained in Section 4, the use range SV,Pis deter-
mined by ﬁrstly computing the deﬁne range SVaccording
to data dependencies, then reﬁning it with relevant control
dependencies. Algorithm 1 outlines the procedure, where we
ﬁrst call ComputeDefRange to compute SVthen reﬁne it
inRefineDefRange .
ComputeUseRange works in a demand-driven fashion.
SV,Pis computed only when ComputeUseRange is invoked
with variable Vand instruction Pas the two input argu-
ments. We use a data structure to cache all deﬁne rangesthat have been computed. At instruction P, the use range
S
V,Pcan then be eﬃciently computed on the ﬂy by reﬁning
the cached deﬁne range of Vwith relevant control depen-
dencies.
When computing the deﬁne range SV, for all operands
that deﬁne V, we need to compute their use ranges at DV
as shown in Figure 3. Similarly, when reﬁning SVaccording
to the predicate pred=(Op1∼Op2), we need to compute the
use range of Op2atpred,SOp2,pred, as shown in Figure 4. If
those dependencies form a cycle, our algorithm will recognize
those cyclic dependencies and will iteratively solve them.
5.1 Iteratively Solving Data Dependencies
The data structure SymTab is introduced to cache the
computed deﬁne range SVfor each variable V. Initially it
is set to ∅.W h e n SVis to be computed, SVand all deﬁneAlgorithm 2 Compute the deﬁne range SV
SymTab :=∅
NewValSet :=∅
1:procedure ComputeDefRange (V)
2:ifVhas an entry in SymTab then return
3:end if
4: NewValSet :=NewValSet ∪{V}
5: SymTab [V]: =[⊥,/latticetop]
6:foreach operand Opiused to compute Vdo
7: ComputeUseRange( Opi,DV)
8:end for
9: Compute SVa c c o r d i n gt oF i g u r e3
10: SymTab [V]: =SV
11: UpdateDefRange( V)
12: NewValSet :=NewValSet \{V}
13:end procedure
14:procedure UpdateDefRange (V)
15: forW∈NewValSet do
16: ifSWis dependent on SVthen
17: foreach operand Opito compute SWdo
18: ComputeUseRange( Opi,DW)
19: end for
20: Compute SWaccording to Figure 3
21: SymTab [W]: =SymTab [W]∩SW
22: ifSymTab [W] has been updated then
23: UpdateDefRange( W)
24: end if
25: end if
26: end for
27:end procedure
ranges required to compute SV(if not computed yet), de-
noted as SW, will be computed on demand and inserted into
SymTab . Note that SWmay be used directly in comput-
ingSVas data dependencies, or it could be used as control
dependencies to reﬁne a deﬁne range that will be used incomputing S
V. There are cyclic dependencies if SVis re-
quired to compute SW.
LetNewValSet be the set of variables whose deﬁne ranges
are inserted into SymTab when computing the deﬁne range
SVfor variable V. We have the following property:
Property 2.Cyclic dependencies can only exist between
Vand variables in NewValSet .
If a deﬁne range is already cached in SymTab ,t h e n SV
is not required to compute it. Similarly, if a variable has
no entry in SymTab afterSVhas been computed, then its
deﬁne range is not required to compute SV.I ne i t h e rc a s e ,
there is no cyclic dependency in between.
In algorithm 2, the procedure ComputeDefRange re-
turns if SVhas already been computed (lines 2 and 3). Oth-
erwise, ComputeUseRange will be recursively invoked to
compute the required use ranges as data dependencies (lines
6 - 8). The deﬁne range SVcan then be computed and
cached in SymTab (lines 9 and 10). In line 11, we invoke
UpdateDefRange to iteratively solve cyclic dependencies
(if there are any) until a ﬁxed point is reached.
InUpdateDefRange , we recompute SWif it is depen-
dent on SV(lines 16 - 21). Recall that SVm a yb eu s e d
directly in computing SWas data dependencies, or it could
be used as control dependencies to reﬁne a range that is used
directly in computing SW.I fSWhas been updated, then
UpdateDefRange is recursively invoked to update those
symbolic ranges dependent on SW(lines 22 - 24). The al-
gorithm terminates when no more updates can be made to
SymTab . At this point, we have reached a ﬁxed point for
SVand all deﬁne ranges required to compute SV.T h e s e
322ranges will be cached in SymTab and they do not need to
be recomputed thereafter. Since we only update SymTab if
a smaller symbolic range can be computed, the algorithm is
guaranteed to terminate.
5.2 Computing Control Dependencies
Algorithm 3 Reﬁne the deﬁne range SVat program point
P
1:procedure RefineDefRange (V,P)
2: SV,P:=SymTab [V]
3: LetPredSet be the set of predicates that controls
both the execution of Pand value of V
4:forevery pred=(Op1∼Op2)i nPredSet do
5: ComputeUseRange( Op2,pred)
6: Reﬁne SV,Paccording to Figure 4
7:end for
8: return SV,P
9:end procedure
The function RefineDefRange (Algorithm 3) computes
the use range SV,Pby reﬁning the deﬁne range SVaccording
to control dependencies. As stated in Section 4, a control
predicate will be considered only if it controls both the ex-
ecution of instruction Pand the value of V(line 3).
The use range SV,Pwill be computed by reﬁning the deﬁne
range SVwith all predicates in PredSet (lines 4 - 7). In our
implementation, when reﬁning a deﬁne range with the range
deﬁned by a control dependency, a simple rule is applied if
the bounds of the two symbolic ranges are not compara-
ble. The constant bound is selected ﬁrst. Otherwise, if thedeﬁne range is unsolvable, the bound of the range deﬁned
by the control dependency will be used. When reﬁning the
range according to a predicate pred
=(Op1∼Op2),Compu-
teUseRange will be recursively invoked to compute the use
range SOp2,pred(line 5). The deﬁne range SOp2,i fn o tc a c h e d
yet, will be computed on demand and inserted into SymTab .
IfSVis used in computing SOp2, those cyclic dependencies
are iteratively solved as shown in UpdateDefRange .
The control predicate predalways strictly dominates in-
struction Pby deﬁnition and only those control predicates
that strictly dominate pred will be used in computing
SOp2,pred. As a result, the algorithm is guaranteed to progress.
5.3 The Motivating Example
Figure 5 shows the relevant dependencies for our moti-
vating example in Figure 1 as well as how they are solved
inComputeUseRange . In our algorithm, data dependen-
cies are cached in SymTab while control dependencies are
solved on the ﬂy. As shown in Figure 5, data dependencies
are grouped into gray boxes. Each box is given a number,
representing the order of when they are computed.
The computation order is essentially a topological order in
the reduced dependency graph (including only relevant de-
pendencies) with all cyclic dependencies being reduced into
a single node. The deﬁne range of nwill be solved ﬁrst since
it is not dependent on any other values. The deﬁne range of
j0, j1, j2 and j3form a cycle which is control dependent on
n. They will be iteratively solved together. Then the deﬁne
range of j4and j5are computed one by one. Note that this
order is implicitly enforced in our algorithm by recursively
calling ComputeUseRange to compute all dependencies on
demand.P3j0 = phi(0, j3)
P9  j1 = j0+1P0n = …;
P10 j2 = phi(j1, j0)
P12 j3 = j2+1P13 pred2' = (j3 < n)
P17  j4= phi(j3, j0)P13 pred2 = (j3 >=n)P20  j5 = n-1
P21  j6 = phi(j4,j5)P18  pred3 = (j4+1 <n)1
2
34
5
Figure 5: Reduced dependency graph (including only
relevant dependencies) for the motivating example in
Figure 1. All data dependencies are highlighted in ovalboxes and control dependencies are placed in white rect-
angular boxes on the path from the deﬁnition of a vari-
able to the instruction where it is used. Dashed linesdenote that the dependency is used in computing con-
trol dependencies. Solid lines denote data dependencies.
6. EXPERIMENTAL RESULTS
We implemented our algorithm for buﬀer overﬂow detec-
tion in Parfait [8], a scalable bug checker built on top of
LLVM. Parfait processes an application in two steps:
1. Source C/C++ ﬁles are parsed by the LLVM front-
end, which generates LLVM bitcode ﬁles. The LLVM
linker is used to link bitcode ﬁles, as any normal linker
would do.
2. Bitcode ﬁles are loaded into memory, a few simple opti-
mizations are applied on the code (e.g., constant prop-
agation), and our analysis is applied to the bitcode
representation to ﬁnd buﬀer overﬂows.
The results reported in this paper use LLVM bitcode ﬁles as
the starting point. The runtime includes the time in loading
bitcode ﬁles to memory, performing simple optimizations, as
well as the time in performing our analysis.
BenchmarkNC-LOC (lines of code) Bitcode
C C++ Total ﬁles
Asterisk 1.6.0.3 292K 6K 298K 25MB
OpenJDKTM7b 5 1 406K 492K 898K 2.39GB
OpenBSD 4.4 1.72M 01.72M 129MB
OpenSolaris ON b105 8.5M 87K 8.6M 1.44GB
Table 1: Summary of the benchmark data.
Several large open source system applications are used
in our experiment as shown in Table 1. OpenSolaris ON
and OpenBSD (kernel only) are general-purpose operating
systems, OpenJDK is an implementation of the JavaTMvir-
tual machine and Asterisk [28] is the implementation of a
telephone private branch exchange (PBX). For each bench-
mark, we list its version or build number, the number of non
commented lines of C/C++ code as reported by the SLOC-
Count [30] tool, and the size of the bitcode ﬁles generatedby the LLVM front-end.
323We evaluate our implementation of the symbolic analysis
algorithm in the following ways: Section 6.1 evaluates the
precision of our algorithm, Section 6.2 reports the perfor-
mance of the algorithm, Section 6.3 reports on our attempts
to compare the precision of the analysis against other bug
checking tools, and Section 6.4 studies the limitations of ouranalysis by reporting the percentage of buﬀer accesses that
cannot be solved by our analysis.
6.1 Precision
We manually veriﬁed all bugs reported by our tool, com-
puting the true positive (i.e., bugs that are correctly re-
ported) and the false positive (i.e., bugs that are incorrectly
reported) rates. All the true positives were reported to the
maintainers of each application, who further veriﬁed our re-ports and in turn ﬁled bugs into their bug tracking system.
Some bugs have already been ﬁxed while others are in the
process of being ﬁxed.
Benchmarks #Reports #TP FP (%)
Asterisk 1.6.0.3 35 30 14.3%
OpenJDK 7 b51 9 8 11.1%
OpenBSD 4.4 38 23 39.5%
OpenSolaris ON b105 378 351 7.14%
Total 460 412 10.4%
Table 2: Precision results of our tool. #Reports is the
number of total reports, #TP is the number of correctly
reported bugs and FP (%) is the false positive rate.
Table 2 summarizes the precision of the symbolic analysis
implementation. Overall, our tool is able to ﬁnd 412 true
bugs with a false positive rate of 10.4%. The false positive
rate is less than or close to 10% for all applications except
OpenBSD, where we have observed a false positive rate ofclose to 40%. The false positives reported in OpenBSD, as
well as in other benchmarks, are due to the limitation of
our implementation in handling pointer types and memorydependencies, which are explained next. These limitations
are currently being addressed in our implementation.
False Positives
struct sockaddr un{ struct sockaddr {
safamily ts u n family; safamily ts a family;
char sun path[108]; char sa data[14];
}; };
300 static int
301 convert sockaddr( struct sockaddr * addr, socklen t* l e n ,
302 struct sockaddr *inaddr, socklen ti n l e n )
303 {
...
355 if (inlen >sizeof (struct sockaddr un))
356 return;
...
386 orig len = inlen - sizeof(addr- >safamily) -1;
387 for (i = 1; i <orig len + 1; i++) {
...
390addr->sadata[i]
=’’;
391 }
...
Figure 6: False positive example from OpenSolaris ON,
ﬁle usr/src/lib/brand/lx/lx brand/common/socket.c
In Figure 6, the buﬀer access addr->sadata[i] in line 390 is
reported as buﬀer overﬂow as highlighted in the shadow box.
The upper bound of the loop index iand orig lencan be com-
puted as 107, while the buﬀer size for addr->sadatais only
14. However, the type sockaddr is eﬀectively a polymorphictype. In this case, the object that addrpoints to is actually
of type sockaddr unand the buﬀer access to addr->sadata
cannot overﬂow. To recognize such false positives, we need
very precise points-to information. Such information is not
provided in the LLVM infrastructure. Alternatively, we can
rely on user annotations as in [12, 15, 31]. For this exam-ple, a simple cast to struct sockaddr
unwould be the obvious
annotation, and would improve the code readability. Many
of the false positives in OpenBSD were reported due to this
reason2.
struct ieee80211 rateset {
unsigned char rs nrates;
unsigned char rs rates[15];
};
2424 void
2425 pgt objbss2scanres(struct pgt softc *sc,
2426 struct wi scan res *scanres, uint32 tn o i s e ) {
2428 struct ieee80211 rateset *rs;
2429 struct wi scan res ap;
...
2432 rs = &sc- >scic.ic suprates[IEEE80211 MODE AUTO];
2442 n = 0;2443 for (i = 0; i <16; i++) {
...
2445 if (
i>rs->rsnrates ) break;
2447 ap.wi srates[n++] = ap.wi rate =rs->rsrates[i]
;
...
2450 }
...
Figure 7: False positive example from OpenBSD, ﬁle
usr/src/sys/arch/dev/ic/pgt.c
In Figure 7, the buﬀer access rs->rsrates[i] in line 2447
is falsely reported as a bug. The range of index variable i
is computed as [0,15] and the buﬀer size of rs->rsratesis
15. When computing symbolic range of i,t h ec o n t r o ld e -
pendency (i>rs->rsnrates) is not considered since the value
rs->rsnrates cannot be computed. In this case, rs->rsnrates
is at most 8 and the reported buﬀer overﬂow will not be ex-
posed. Similar to the example in Figure 6, precise points-to
information is required to be able to compute these memory
dependencies. Note that although it is classiﬁed as a falsepositive, it can be argued that the loop exit condition shouldbei<15instead of i<16.
From our experience in verifying results against the vari-
ous system applications, the majority of false positives were
reported due to the above two cases. Usually, these false
positives require very precise points-to information to elim-
inate them.
6.2 Performance
BenchmarkTime #Max #Max
(min:sec) Variables Predicates
Asterisk 1.6.0.3 0:28 18 4
OpenJDK 7 b51 9:10 26 3
OpenBSD 4.4 1:18 34 10
OpenSolaris ON b105 10:37 80 77
Table 3: Performance results of our tool. #Max Vari-
ables is the number of variables in the largest cycle that is
iteratively solved. #Max Predicates is the largest num-
ber of predicates used when computing the use range of
a variable on the ﬂy.
Table 3 summarizes the analysis times for diﬀerent bench-
marks on an Intel E8600 3.33GHz processor with 8GB of
2If we consider these type violations as true bugs, the false
positive rate for OpenBSD would be 21%.
324RAM. For each benchmark, we report its analysis time (Col-
umn 2), the number of variables in the largest cycle thatis iteratively solved (Column 3) and the largest number of
control predicates used when computing the use range of a
variable on the ﬂy (Column 4). The analysis time includes
the time to load the bitcode ﬁles, build the representationin memory, perform the symbolic analysis, and report the
results. For each benchmark, we ran our analysis 10 times
and the user time of the slowest run is reported.
The symbolic analysis time is less than 11 minutes for
OpenSolaris ON with 8.6 MLOC. OpenJDK is the secondmost time-consuming application, despite the fact that it ismuch smaller than OpenBSD (see Table 1). This is due to its
extensive use of C++ templates, which are expanded in the
LLVM bitcode ﬁles. As a result, the total size of all LLVM
bitcode ﬁles in OpenJDK is actually much larger than thatin OpenBSD (see Table 1).
Overall, the performance of the algorithm is largely due to
the fact that we compute only relevant dependencies on de-mand, and use simple symbolic expression representations.
As shown in Column 3 and Column 4 in Table 3, the largest
cycle that is iteratively solved in ComputeDefRange in-
cludes at most 80 variables and the largest number of con-
trol dependencies that is computed on the ﬂy in RefineDe-
fRange is 77.
6.3 Comparison with Other Tools
Since we do not have access to existing commercial tools,
only open source tools were considered for comparison. Of
the tools available, four of them (LLVM/Clang Static Ana-
lyzer [19], Saturn [31], Uno [27] and Splint [12]) are underactive development and therefore used in our testing. The
LLVM/Clang Static Analyzer mainly reports bugs that deal
with Objective C errors, as such, it does not report any
buﬀer overﬂow bugs in C code. Saturn is a system for static
analysis for C programs. Its existing analysis assumes in-
bound array accesses, as such, Saturn does not report buﬀeroverﬂow bugs at present.
We tried to run Splint and Uno over the applications in
Table 1. In our experience, Splint produces a large numberof error reports and Uno produces very few reports. For
Asterisk alone, Splint generates around 800 out-of-bounds
errors and Uno reports 8 which look to be false positives.
We estimate that to verify all the reports against the givenapplications in Table 1 would require many months of ded-
icated eﬀort, even at a rate of 100 per day.
#Reports #TP #Misses FP (%) FN (%)
Splint 1113 592 647 46.8% 52.2%
Uno 462 454 785 1.7% 63.4%
Parfait 914 914 325 0% 26.2%
Table 4: Precision results of diﬀerent tools on the Beg-
Bunch suite. #Reports is the number of total reports,
#TP is the number of correctly reported bugs, #Missesis the number of bugs present in the code but not re-
ported. FP (%) is the false positive rate and FN (%) is
the false negative rate.
Therefore, we evaluated our buﬀer overﬂow detection im-
plementation against other bug checking tools for C/C++
using the BegBunch benchmarking suite [7]. The BegBunch
suite includes a set of bug kernels extracted from existingopen source applications and existing bug checking bench-marks. Each bug kernel has been manually inspected by the
authors of [7] and the bug location is marked. It allows us toevaluate both precision and performance of our tool, as wellas checking how many bugs are missed (i.e., false negatives).
Table 4 summarizes the results of diﬀerent tools on the
BegBunch suite. For the total 1239 buﬀer overﬂow bug ker-
nels in the BegBunch suite, our tool reported 914 bugs, all
of which were correctly reported with an overall 26.2% false
negative rate. For this dataset, our tool is signiﬁcantly bet-ter than Splint and Uno. It is able to ﬁnd all true bugs that
are reported by the other two tools, with a much better
false positive and false negative rates. The bugs that weremissed by our tool are mostly due to our limitation in han-
dling memory dependencies, which require precise points-to
analysis or user annotations. It is worthwhile noting thatSplint’s false positive and false negative rates can also beimproved by adding annotations to the code to be analyzed.
6.4 Limitations
Recall that in our analysis, we only report a bug if
SB,Pmax≺SV,PmaxorSV,Pmin≺-1, where Vis the index
variable and Bis the size of the accessed buﬀer. In addi-
tion, a buﬀer access is guaranteed to be within buﬀer bounds
only if SV,Pmax≺SB,Pmin−1a n d0 ≺SV,Pmin. Otherwise
the buﬀer access is a potential buﬀer overﬂow that cannot
be solved by our analysis. In this section, we report on thepercentage of potential buﬀer overﬂows, which suggests the
limitations of our approach and gives us a hint about howmany buﬀer overﬂows may be missed.
Benchmark Potential buﬀer overﬂows (%)
Asterisk 1.6.0.3 25.1%
OpenJDK 7 b51 42.9%
OpenBSD 4.4 27.0%
OpenSolaris ON b105 31.1%
Table 5: The percentage of potential buﬀer overﬂows
that cannot be solved by our analysis.
Table 5 summarizes the percentage of potential buﬀer
overﬂows for all applications. For Asterisk, OpenBSD and
OpenSolaris ON, close or below 30% of all buﬀer accesses
were potential buﬀer overﬂows that could not be solved by
our analysis. The percentage increased to just over 40%for OpenJDK. We manually looked into some of the po-tential buﬀer overﬂows and found that most of them were
not solved due to the same limitation of our implementa-
tion in handling pointer types and memory dependencies.This also suggests the worst behavior in OpenJDK, where
precise points-to information is harder to get because of its
extensive usage of C++ templates.
7. CONCLUSION
In this paper, we presented a new symbolic analysis tech-
nique for buﬀer overﬂow detection and evaluated it using
large systems applications. We demonstrated that the sim-
ple symbolic value representation is eﬀective for buﬀer over-ﬂow detection and symbolic values could be precisely com-
puted by iteratively solving data dependencies and linearly-
related control dependencies together. We also showed that
by being demand-driven and using simple algebraic rules,
the symbolic values could be computed very eﬃciently.
Our experimental results against large systems applica-
tions suggested that this technique is simple yet eﬀective –
325it was easy to implement and found hundreds of buﬀer over-
ﬂows in large, well-tested codebases with a false positive rateof around 10%. This makes the technique feasible for imple-
mentation in existing compilers, to identify vulnerabilities
at the earliest stage of software development.
In addition to buﬀer overﬂows, our analysis can be ap-
plied to detect other important vulnerabilities such as inte-ger overﬂows. It can also be applied to analyze the bounds
of shared memory regions to detect potential data races.
8. REFERENCES
[1] S. Anand, C. S. Pasareanu, and W. Visser. JPF-SE: A
symbolic execution extension to Java pathﬁnder. In
International Conference on Tools and Algorithms forConstruction and Analysis of Systems , pages 134–138,
Braga, Portugal, March 2007.
[2] D. Babic and A. J. Hu. Calysto: scalable and precise
extended static checking. In Proceedings of the 30th
International Conference on Software Engineering , pages
211–220. ACM Press, 2008.
[3] J. Birch, R. van Engelen, K. Gallivan, and Y. Shou. An
empirical evaluation of chains of recurrences for array
dependence testing. In Proceedings of the 15th
international conference on Parallel Architectures and
Compilation Techniques , pages 295–304. ACM Press, 2006.
[4] W. R. Bush, J. D. Pincus, and D. J. Sielaﬀ. A static
analyzer for ﬁnding dynamic programming errors.
Software—Practice & Experience , 30:775–802, 2000.
[5] C. Cadar, D. Dunbar, and D. R. Engler. Klee: Unassisted
and automatic generation of high-coverage tests for
complex systems programs. In Proceedings of the 8th
symposium on Operating Systems Design andImplementation , pages 209–224. USENIX Association,
2008.
[6] S. Christey and R. A. Martin. Vulnerability type
distributions in CVE. Technical report, The MITRE
Corporation, May 2007. Version 1.1.
[7] C. Cifuentes, C. Hoermann, N. Keynes, L. Li, S. Long,
E. Mealy, M. Mounteney, and B. Scholz. BegBunch:
Benchmarking for C bug detection tools. In Proceedings of
the 2009 international workshop on Defects in large
software systems , July 2009.
[8] C. Cifuentes and B. Scholz. Parfait – designing a scalable
bug checker. In Proceedings of the ACM SIGPLAN Static
Analysis Workshop , pages 4–11, 12 June 2008.
[9] P. Cousot and R. Cousot. Abstract interpretation: a
uniﬁed lattice model for static analysis of programs byconstruction or approximation of ﬁxpoints. In Proceedings
of the 4th symposium on Principles of Programming
Languages , pages 238–252. ACM Press, 1977.
[10] P. Cousot, R. Cousot, J. Feret, L. Mauborgne, A. Min´ e,
D. Monniaux, and X. Rival. The ASTR ´EE analyser. In
Proceedings of the 2005 European Symposium on
Programming , pages 21–30. Springer, April 2005.
[11] R. Cytron, J. Ferrante, B. K. Rosen, M. N. Wegman, and
F. K. Zadeck. Eﬃciently computing static single
assignment form and the control dependence graph. ACM
Transactions on Programming Languages and Systems ,
13(4):451–490, October 1991.
[12] D. Evans and D. Larochelle. Improving security using
extensible lightweight static analysis. IEEE Software , pages
42–51, January/February 2002.
[13] C. Flanagan, K. R. M. Leino, M. Lillibridge, G. Nelson,
J. B. Saxe, and R. Stata. Extended static checking for
Java. In Proceedings of the 2002 conference on
Programming Language Design and Implementation , pages
234–245. ACM Press, 2002.
[14] V. Ganapathy, S. Jha, D. Chandler, D. Melski, and
D. Vitek. Buﬀer overrun detection using linear
programming and static analysis. In Proceedings of the10th conference on Computer and Communications
Security , pages 345–354. ACM Press, 2003.
[15] B. Hackett, M. Das, D. Wang, and Z. Yang. Modular
checking for buﬀer overﬂows in the large. In Proceeding of
the 28th International Conference on Software
Engineering , pages 232–241. ACM Press, 2006.
[16] J. C. King. Symbolic execution and program testing.
Communications of ACM , 19(7):385–394, 1976.
[17] W. Le and M. L. Soﬀa. Marple: a demand-driven
path-sensitive buﬀer overﬂow detector. In Proceedings of
the 16th international symposium on Foundations ofSoftware Engineering , pages 272–282. ACM Press, 2008.
[18] LLVM. Low Level Virtual Machine. http://www.llvm.org ,
detail on website.
[19] LLVM/Clang Static Analyzer.
http://clang.llvm.org/StaticAnalysis.html .L a s t
accessed: 1 December 2008.
[20] S. Nagarakatte, J. Zhao, M. M. Martin, and S. Zdancewic.
Softbound: highly compatible and complete spatialmemory safety for C. In Proceedings of the 2009 conference
on Programming Language Design and Implementation ,
pages 245–258. ACM Press, 2009.
[21] K. J. Ottenstein, R. A. Ballance, and A. B. MacCabe. The
program dependence web: a representation supportingcontrol-, data-, and demand-driven interpretation of
imperative languages. In Proceedings of the 1990
conference on Programming Language Design and
Implementation , pages 257–271. ACM Press, 1990.
[22] M. Y. Patrice Godefroid and D. Molnar. Automated
whitebox fuzz testing. In Proceedings of the 11th Network
and Distributed System Security Symposium , pages
159–169, 2008.
[23] C. S. Pˇ asˇareanu, P. C. Mehlitz, D. H. Bushnell,
K. Gundy-Burlet, M. Lowry, S. Person, and M. Pape.
Combining unit-level symbolic execution and system-levelconcrete execution for testing NASA software. InProceedings of the International Symposium on Software
Testing and Analysis , pages 15–26. ACM Press, 2008.
[24] R. Rugina and M. Rinard. Symbolic bounds analysis of
pointers, array indices, and accessed memory regions. In
Proceedings of the 2000 conference on Programming
Language Design and Implementation , pages 182–195.
ACM Press, 2000.
[25] O. Ruwase and M. S. Lam. A practical dynamic buﬀer
overﬂow detector. In Proceedings of the 11th Network and
Distributed System Security Symposium , pages 159–169,
2004.
[26] J. Seward and N. Nethercote. Using valgrind to detect
undeﬁned value errors with bit-precision. In Proceedings of
the annual conference on USENIX Annual Technical
Conference , pages 2–2. USENIX Association, 2005.
[27] Uno Tool Synopsis. http://spinroot.com/uno/ .L a s t
accessed: 26 October 2007.
[28] J. Van Meggelen, J. Smith, and L. Madsen. Asterisk: the
future of telephony, 2nd edition . O’Reilly, 2007.
[29] D. Wagner, J. S. Foster, E. A. Brewer, and A. Aiken. A
ﬁrst step towards automated detection of buﬀer overrunvulnerabilities. In Proceedings of the 7th Network and
Distributed System Security Symposium , pages 3–17, 2000.
[30] D. A. Wheeler. SLOC Count User Guide.
http://www.dwheeler.com/sloccount/ . Last accessed: 16
March 2009.
[31] Y. Xie and A. Aiken. Saturn: A scalable framework for
error detection using boolean satisﬁability. ACM
Transactions on Programming Languages and Systems ,
29(3):16, 2007.
[32] Y. Xie, A. Chou, and D. Engler. Archer: using symbolic,
path-sensitive analysis to detect memory access errors. InProceedings of the 11th international symposium on
Foundations of Software Engineering , pages 327–336. ACM
Press, 2003.
326