Model Checking Distributed Systems by Combining
Caching and Process Checkpointing
Watcharin Leungwattanakit∗,C y r i l l eA r t h o†,M a s a m iH a g i y a∗,Y o s h i n o r iT a n a b e‡and Mitsuharu Yamamoto§
∗Graduate School of Information Science and Technology
The University of Tokyo, Tokyo, Japan
Email: {watcharin, hagiya}@is.s.u-tokyo.ac.jp
†Research Center for Information Security, AIST, Tsukuba, J apan
Email: c.artho@aist.go.jp
‡National Institute of Informatics, Tokyo, Japan
Email: y-tanabe@nii.ac.jp
§Chiba University, Chiba, Japan
Email: mituharu@math.s.chiba-u.ac.jp
Abstract —Veriﬁcation of distributed software systems by
model checking is not a straightforward task due to inter-
process communication. Many software model checkers only
explore the state space of a single multi-threaded process. Recent
work has proposed a technique that applies a cache to capture
communication between the main process and its peers, and
allows the model checker to complete state-space explorati on.
Although previous work handles non-deterministic output i n
the main process, any peer program is required to produce
deterministic output.
This paper introduces a process checkpointing tool. The com -
bination of caching and process checkpointing makes it poss ible
to handle nondeterminism on both sides of communication. Pe er
states are saved as checkpoints and restored when the model
checker backtracks and produces a request not available in t he
cache. We also introduce the concept of strategies to contro l
the creation of checkpoints and the overhead caused by the
checkpointing tool.
Index Terms —software model checking; caching; software
veriﬁcation; distributed systems; checkpointing;
I. I NTRODUCTION
Networked software is usually implemented as a concur-
rent program using multiple threads to handle connections.
Threads are execution units within a given process [1]. The
interleaving among threads, i.e. thread scheduling, is tak en
care of by an operating system, thus it is beyond the con-
trol of programmers. As a result, software testing [2] may
miss some failures under a certain sequence of interleaving ,
because it cannot cover all possible thread schedules in one
run. Chess [3] remedies this disadvantage by executing a
test case repeatedly to ﬁnd concurrent failures and ensurin g
that every run takes a different interleaving. More program
behaviors are tested by this technique. Model checking [4]
is a more powerful veriﬁcation technique that takes every
possible schedule into account. Some software model checke rs
such as Java PathFinder (JPF) [5] execute real application
code at runtime and are applied in the implementation phase
of a software development. In this paper, the main process
to be veriﬁed is called the system under test (SUT) .T h e
system under test is backtracked by a model checker duringveriﬁcation to analyze multiple outcomes of non-determini stic
decisions, such as thread scheduling and variable input dat a.
The combination of decisions increases exponentially over
the number of instructions. As a result, the program state
space is usually too large to be explored exhaustively withi na
reasonable amount of time. This limitation is called the state
explosion problem ,w h i c hi so n eo ft h ef u n d a m e n t a lp r o b l e m s
for model checking. Partial order reduction [6] is a techniq ue
to relieve the state explosion by atomically executing a gro up
of program instructions that do not affect any other threads .
This method reduces the number of thread interleavings, and
thus the size of the state space.
Verifying a distributed system [7] with a model checker
is not a straightforward process. The distributed system is
composed of several computational entities that exchange d ata
and interoperate with one another through a network. Each
process may run on a different environment, increasing syst em
complexity. Most software model checkers only handle a
single process at a time and cannot be applied simulatenousl y
to all processes of the distributed system. When a process in
the system is executed, as the SUT, by the model checker, the
other processes are running as peer processes in the normal
execution environment. Since the peer processes are not und er
model checker control, they cannot be backtracked in tandem
with the SUT. After the SUT backtracks, it may try to interact
with the peers, which are not in a state to respond correctly.
Several techniques [8], [9], [10] have been established to
automate the veriﬁcation of such systems. Some of them are
brieﬂy introduced in Section II. Our previous work [11], [12 ]
has shown that an I/O cache can interact with the SUT on
behalf of the peer.
A. Cache-based Veriﬁcation
Fundamentally, dynamic software veriﬁcation can be carried
out by two approaches: testing and model checking. Figures 1 a
and 1b compare the conﬁgurations of both approaches in the
veriﬁcation of a distributed application. Testing execute sb o t h
the SUT and peers in the normal execution environment. OnlySUT
Peer 1Peer 2(a) Software testing setup.Model
CheckerPeer 1
Peer 2C
a
c
h
eSUT(b) Cache-based model checking setup.Model
Checker
Check pointing EnvironmentPeer 1 Peer 2C
a
c
h
eSUT(c) Checkpointing support setup.
Figure 1: Three conﬁgurations: testing, cache-based model
checking, and model checking with checkpointing support.
one execution path of the SUT is exercised for each run in this
conﬁguration. On the other hand, model checking executes
the SUT inside an environment where the program state may
be rolled back. Thus, the SUT can be systematically driven
through every possible execution path. In case of a multi-
process application, the I/O cache is required to interact w ith
the SUT on behalf of the peers [11], [12]. The I/O cache
intercepts every request packet ,ad a t ap a c k e ts e n tb yt h e
SUT, and stores it in an internal data structure. Similarly,
response packets coming back from the peers are stored in
the I/O cache as well. Each request packet is matched with
its corresponding response packet, if any. The I/O cache use s
this information to imitate peer behaviors. As a result, the SUT
experiences the same interaction with the I/O cache that wou ld
encounter with the actual peers. The single-process model
checker then can complete the exploration of the SUT state
space. In doing so, it avoids an expensive analysis of the ful l
state space of each peer. Similar to a partial-order reducti on,
this reduces the state space signiﬁcantly. By analyzing the full
state space of the SUT combined with only a few (rather than
all) peer executions, cache-based veriﬁcation allows syst ems
to be analyzed that were previously out of reach for model
checking [11], [12].
In this research, determinism of programs is deﬁned to be
based on the output they produce with respect to input on
acommunication channel .N o t et h a tm u l t i t h r e a d e dp r o g r a m s
whose thread schedules are non-deterministic can still pro duce
deterministic output by this deﬁnition. We do not impose a
restriction on “internal” non-determinism of programs. Fu r-thermore, the term “deterministic output” means that the
output solely depends on the input trace of the communicatio n
peer. A program with deterministic output may still produce
ad i f f e r e n to u t p u tp a t t e r ni fi tr e c e i v e sad i f f e r e n ti n p u tt race.
The initial implementation of the I/O cache assumed deter-
minism of the SUT output [11]. However, this assumption is
not always true. Some kinds of programs serve clients with
dynamic data, e.g. web servers and database servers. Their
outcomes do not only depend on the response from a peer but
also on their internal state. Therefore, the I/O cache may ob -
serve multiple patterns of request packets from such progra ms
running as SUT. We can say that the SUT behaves in a non-
deterministic way from the perspective of the I/O cache. To
handle programs with non-deterministic output, the I/O cac he
creates, for each distinct request pattern, a new instance o ft h e
peer. Each instance of the peer is responsible for one reques t
pattern. While non-determinism on the SUT side is taken
into account, previous work [12] assumes deterministic out put
from peers. Previous work restores a peer state by replaying
previously recorded communication to a new instance of the
peer [12]; non-deterministic peer systems cannot be handle d
in this way.
B. Extension for Non-deterministic Peers
This paper proposes a method to support non-deterministic
output from both SUT and peers with the help of process
checkpointing .P r o c e s sc h e c k p o i n t i n gi sat e c h n i q u et h a tr u n s
ag r o u po fp r o c e s s e si na ne n v i r o n m e n tt h a tk e e p st r a c ko f
the process states. This environment is called a checkpointing
environment .F i g u r e1 cs h o w st h ec o n ﬁ g u r a t i o no fc a c h e -
based model checking with a checkpointing environment. The
checkpointing environment creates a checkpoint of the peer s
when requested by the I/O cache. When the I/O cache needs to
synchronize the state of the SUT and peers, the checkpointin g
environment restarts the peers from an appropriate checkpo int.
This avoids replaying peer actions that may cause the pre-
viously executed non-deterministic transition to be repea ted.
Thus, the SUT only observes one peer behavior for each SUT
output trace. This method eliminates false positives cause db y
different instances of peers interacting with the SUT under
one execution path.
Nondeterminism inside a peer can be divided into two types
by its source: thread scheduling and external input. Thread
scheduling is controlled by an operating system. Even thoug h
ap e e ri sl o a d e df r o mac h e c k p o i n t ,t h e r ei sn og u a r a n t e e
that the peer will execute under the same thread schedule.
Accordingly, we assume peer output of each communication
channel is independent of thread scheduling.
Checkpointing a process is an expensive operation. Doing
it naively would incur extremely high overhead. We propose
strategies to prevent the model checker from creating unnec es-
sary checkpoints. The contribution of this work is as follow s:
•The application of process checkpointing to software
model checking.
•Support for distributed applications that produce non-
deterministic output.
2•Introducing checkpointing strategies.
•Am o d e lc h e c k e re x t e n s i o nt h a ti m p l e m e n t st h ep r o p o s e d
algorithm.1
C. Outline
Section II shows related work to verify distributed appli-
cations. Section III presents how to make use of process
checkpointing in software model checking. Section IV gives
the implementation details of the model checker extension
that supports peers with non-deterministic output. Sectio nV
presents and analyzes experimental results of the checkpoi nt-
supported I/O cache on several systems under test. Section V I
concludes the paper and proposes future work.
II. R ELATED WORK
Several approaches have been presented to automate veriﬁ-
cation of distributed systems. The Centralization technique [8],
[9] offers automatic uniﬁcation of processes. It collects a ll
processes in an application and transforms each process to a
thread. All threads start inside a process called a centralized
process ,w h i c hc a nb ea u t o m a t i c a l l yg e n e r a t e db yat o o l .A
single-process model checker runs the centralized process ,
which starts all threads at the beginning, and veriﬁes the
entire system at once. Since all processes must be wrapped
into one process, they must be written in the same pro-
gramming language and be compiled on the same platform.
These requirements are not always fulﬁlled. The centraliza tion
approach does not scale well since exploring the interleavi ngs
of all processes in the system yields very large state space.
Implementing a multi-process model checker is one of the
solutions. This idea was proposed in [13]. The extension of
User-mode Linux [14] called ScrapBook can save and restore
the state of a system running inside a virtual environment. A
SUT is executed inside the virtual environment. Note that th ere
is no peer process in this approach, because every process is
inside the virtual environment. Each process of the applica tion
is controlled by an instance of GDB (GNU Debugger) [15].
Given a set of breakpoints, GDB suspends the process. A user
speciﬁes these breakpoints beforehand. ScrapBook works as
am o d e lc h e c k e ri nt h es e n s et h a ti tc a ns a v ea n dr e v e r tt h e
system state. Since the state of the entire system must be sav ed
and restored during veriﬁcation, this approach is not scala ble
as well.
Verisoft [16] is another model checking tool that veriﬁes
concurrent processes. It deals directly with the implement ation
of a target system, which may comprise multiple processes.
However, it could not handle multi-threaded processes and d id
not maintain states of ﬁle descriptors for ﬁles and sockets
that the system would open. Therefore, modern applications
composed of multiple threads cannot be directly veriﬁed by
the tool.
1http://babelﬁsh.arc.nasa.gov/trac/jpf/wiki/projects /net-iocacheIII. P ROCESS CHECKPOINTING SUPPORT
This section explains how process checkpointing is applied
to veriﬁcation of distributed systems. This idea is built on the
concept of the I/O cache, which is reviewed in Section III-A.
Some checkpointing tools are brieﬂy introduced in Sec-
tion III-B. We use process checkpointing to capture consist ent
behaviors of peer processes. Without process checkpointin g,
the I/O cache may store inconsistent data, which causes the
model checker to report false positives. Such a situation is
shown in Section III-C. We propose an optimization method
in Section III-D in order to reduce the number of checkpoints
and control the overhead caused by the checkpointing tool.
A. Fundamentals of the I/O Cache
The I/O cache is a software module that controls data
packets transferred between a SUT and a peer. It captures
the messages sent by the SUT and matches them to the
corresponding messages from the peer. A message from the
SUT is called a request message while one from the peer is
called a response message .Ar e q u e s tm e s s a g ew i l lb es t o r e d
in an internal data structure if the I/O cache receives it for
the ﬁrst time. In this case, the I/O cache will poll the peer
process for a response message. If a response message is
available, the I/O cache will match it with the most-recent
request message [11]. On the other hand, if the I/O cache
receives a request message it has received before, it will se nd
the response message associated with that request message t o
the SUT.
Figure 2 demonstrates how the I/O cache works on a
two-thread SUT. Let WandRbe threads that produce an
output trace and receive an input trace, respectively. Thre ad
Wrandomly produces string ‘01’ or ‘02’. In the ﬁrst schedule,
Thread Wwrites ‘0’, denoted by W(0).T h ec a c h em e m o r i z e s
the data block transferred and shades the block to indicate t hat
the SUT has passed through. Then, the I/O cache sends the
request message to the peer and polls a response message.
The response message is saved in the next block (Figure 2a).
Note that the response message is not shaded, because the
SUT has not read it yet. In the next step, thread Rattempts to
read a message and receives the previously cached response
message. The I/O cache shades the read block to mark that the
SUT has already received this message (Figure 2b). Suppose
that thread Wproduces ‘1’ in the next step, the I/O cache
becomes like Figure 2c. When the SUT backtracks to state 2,
the I/O cache restores the shade position, but the cached dat a
remains permanent (Figure 2d). The model checker executes
another possibility in which Wproduces ‘2’. At this time,
the peer is restarted from the beginning to handle the new
request messages ‘02’ (Figure 2e). The SUT backtracks to
state 1. Thread Wmay execute at this point with two options,
writing ‘1’ or ‘2’. Suppose that it writes ‘1’, the I/O cache
in fact does not write this message to the peer since the
message is already in the cache. Instead, it only shades the
associated data block to remember the state of the data strea m
(Figure 2f). The model checker continues running until the
30
1
2
end3W(0)
W(1)
R(B)R(A)
4W(2)
R(C)5W(1)0
1
2
end3
(c) (d)
(e) (f)0
1W(0)ROOT
A
(a)0
1
2ROOT
(b)0W(0)
R(A)
W(0)
W(1)
R(B)0
A
R(A)ROOT
A0
1
B0
1
2
end3W(0)
W(1)
R(B)R(A)
4W(2)ROOT
A0
1
B
0
1
2
end3W(0)
W(1)
R(B)R(A)
4W(2)
R(C)ROOT
A0
1
B2
CROOT
A0
1
B2
CFigure 2: Evolution of the partial state space and cached tra ces. Two different communication traces are represented by solid
lines and dashed lines. Rectangular nodes represent reques tm e s s a g e s .C i r c l e dn o d e sr e p r e s e n tr e s p o n s em e s s a g e s .
whole state space is explored with the help of the I/O cache,
which interacts with the SUT as a peer.
B. Checkpointing Environments
Process checkpointing is a technique to create a snapshot
of a group of processes. The snapshot stored in non-volatile
memory is referred to as a checkpoint .Ac h e c k p o i n tc a nb e
loaded later on to recreate the process group in a certain sta te.
After checkpointing, the recreated processes can continue
running from where they were suspended as if they had not
stopped running.
Most virtualization tools [17], [18], [19] provide check-
pointing functions save and restore .H o w e v e r ,v i r t u a l -
ization consumes a large amount of system resources since
it applies those functions on the entire system. Initially, we
implemented our approach by using Kernel-based Virtual
Machine (KVM) [18]. It took a few seconds merely to create
one snapshot of a system, rendering it impractical.
Al i g h t w e i g h tc h e c k p o i n t i n gp a c k a g es u c ha s MTCP [20]
can be used as a replacement in certain circumstances where
ap e e ri sas i n g l e - p r o c e s sp r o g r a m .T h ec h e c k p o i n t i n gp a c k a ge
takes care of the state of a single process, unlike the virtua l-
ization tools. It approximately takes 200-300 millisecond so naverage in order to create a checkpoint, which is acceptable .
Distributed MultiThreaded CheckPointing (DMTCP) [21] is
an extended version of MTCP, which manages a group of
processes connected by network connections or parent-chil d
relations. This work employs DMTCP as the checkpointing
environment to support the I/O cache. All peer processes are
controlled by DMTCP.
Checkpointing environments introduce a new method to
synchronize a SUT and a peer. Model checkers save SUT
states in order to backtrack it to any previously visited poi nt
in the state space. A checkpointing tool can do the same
with peer processes. When the I/O cache has detected a new
communication trace from the SUT, it restores the peer proce ss
from a checkpoint saved prior to the equivalent state instea d
of restarting the peer from the beginning. In the extreme
case, we may create a peer checkpoint for each SUT state. In
practice, the peer does not have to be checkpointed as often
as the SUT. Some peer checkpoints may be omitted under
ac e r t a i nc o n d i t i o n .A no p t i m i z a t i o nm e t h o di sd i s c u s s e di n
Section III-D.
4ROOT
0
A
12
C FS00/A
0/B1/C,
2/E
1/D,
2/FS
S1
2B?ROOT
0
A
12
C EFigure 3: (Left) State transition diagram of a peer that prod uces
non-deterministic output. (Middle) One possibility of inc orrect
cached data. (Right) Correct cached data.
C. Support for Non-deterministic Peer Output
In this paper, we propose an approach to cope with non-
deterministic peer output. An example of such a peer is shown
in Figure 3 (left). The peer may change state and produce
output differently (‘A’ and ‘B’) in each run, although it rec eives
the same data ‘0’ as shown in the transitions from S0to
S1andS2.T h eI / Oc a c h ea p p r o a c hw i t h o u tc h e c k p o i n t i n g
restarts the peer process when the SUT produces a different
trace after backtracking [12]. This technique does not work if
the peer also produces non-deterministic output, which may
cause inconsistency in the cached data. Suppose that the pee r
moves from S0toS1,t h eI / Oc a c h er e c e i v e s‘ A ’a n d‘ C ’
from the peer. After backtracking the SUT produces a new
trace (‘02’), request message ‘2’ is added into a new branch,
forcing the peer to restart. The new peer may move from state
S0to state S2after receiving message ‘0’. The transition to
S2emits ‘B’, which differs from the existing cache content
‘A’. The I/O cache may handle a mismatch by: (1) aborting the
process, or (2) giving a warning and continuing. If it contin ues,
it will receive ‘F’ as a response for ‘2’. The cache contents
in Figure 3 (middle) indicate that the SUT receives response
message ‘AF’ for request message ‘02’, which is an incorrect
behavior. According to the state transition diagram in Figu re 3
(left), the peer obviously never produces ‘A’ and ‘F’ in the
same run. The I/O cache may return an incorrect response
message, because the new peer does not stay in the same state
as its previous instance did. As a result, the model checker
would report a false positive due to the communication trace
that the SUT never receives in a normal environment.
This inconsistency can bring about a serious problem if the
communication between two programs depends on the results
of non-deterministic peer operations. For example, a SUT an d
ap e e rm a yp e r f o r m key exchange [22] by generating random
values required to build a shared secret key. If the I/O cache
restarts the peer later, the peer will generate a new random
value for building the key. The key obtained from the new
random value is different from what the SUT is holding. As
ar e s u l t ,b o t hp r o g r a m sc a n n o td e c r y p tm e s s a g e sf r o mt h e
opponent after the peer has restarted.
This issue can be solved by running a peer in a checkpoint-
ing environment, which can save and revert the peer state. AS0
1
2 34
6 5C
S S
S S S S0
C C C2 3 6 C5C1 C4
Figure 4: (Left) SUT state space. Dashed lines represent
transitions without network I/O operations. (Right) Peer c heck-
point space. Solid-line circles represent physical checkp oints.
Dashed-line circles represent logical checkpoints.
peer checkpoint is created as the SUT changes state. States
S0andS1are saved for the example in Figure 3. When the
SUT needs the peer in a certain state, the peer is restarted in a
way that it will produce outcomes consistent with the cached
contents. In this case, the peer is restarted from state S1.T h e
peer continues running from that point and correctly sends
response message ‘E’ for request message ‘2’. The correct
cache contents are shown in Figure 3 (right). By this method,
only one behavior of the peer is revealed to the SUT as if the
peer produced deterministic output.
D. Checkpointing Strategies
Checkpointing every single peer state is not always neces-
sary and not efﬁcient since the I/O cache can replay cached
messages in most cases. Instead, we introduce a concept of
logical checkpoints ,w h i c hd on o to c c u p yd i s ks p a c e .T h e y
are created as the model checker discovers new states of a
SUT. Figure 4 shows checkpoint space as compared to SUT
state space. State Siassociates with logical checkpoint Ci.
Acheckpointing strategy deﬁnes how to maintain the bal-
ance of the checkpoint creation overhead with the possibili ty
of restoring a previous state directly. It decides whether t o
create a physical checkpoint ,w h i c ho c c u p i e ss t o r a g es p a c e ,
over the corresponding logical checkpoint. When the SUT
needs the peer at a speciﬁc state, the model checker restores
the corresponding logical checkpoint. If it lacks a physica l
checkpoint, the peer will be instead restored from the most-
recent physical checkpoint on a path to that logical checkpo int.
After that the model checker must replay communication data
from there, up to the designated logical checkpoint.
Generally, creating two identical checkpoints is pointles s.
We assume that a peer does not change state signiﬁcantly
if it performs no network I/O operation, e.g. connect ,
accept ,send ,a n d recv .F o l l o w i n gt h i sa s s u m p t i o n ,t h e
peer should be checkpointed only after a network I/O operati on
is performed. Using this strategy, an example of the resulti ng
checkpoint space is shown in Figure 4. States S1,S4,a n d
S5come from transitions without network I/O operations, so
physical checkpoints are not created at C1,C4,a n d C5.I f
the SUT needs the peer at C5,w em u s ts t a r tf r o mp h y s i c a l
checkpoint C0and replay network I/O operations, by using the
cache contents, until it reaches C5.Av a r i a n to ft h i ss t r a t e g y
is to only checkpoint after operation connect oraccept .
5S2t1
Loading checkpoint Peer restartS3t2t0
SS
Ct10
32C1
C3t2C1t0C0
Figure 5: Two options : loading a checkpoint or starting a new
peer.
In this case, the I/O cache must replay I/O operations from
the beginning of the connection up to point where the peer is
synchronized with the SUT again.
Ac h e c k p o i n t i n gs t r a t e g yt a k e se f f e c ta f t e re a c hS U Ts t a t e
transition to decide whether the current peer state should
be saved. In addition to that, if the I/O cache receives a
notiﬁcation from the checkpointing environment about a non -
deterministic operation, it will always saves the state of t he
peer. The I/O cache must do this in order to preserve the resul t
of the non-deterministic operation. This method requires a
way to detect non-deterministic peer “actions” at runtime. Our
solution is to build wrapper functions for standard functio ns
that may cause non-determinism such as time andread ;
see Section IV. When one of these functions is called with a
certain argument, the wrapper function sends a notiﬁcation to
the I/O cache. Receiving the notiﬁcation, the I/O cache save s
the peer state after the current SUT transition is completed .
Note that we must wait until the transition is completed in
order to create a checkpoint synchronized with the SUT state
as shown in Figure 4.
When a SUT needs a peer in one of the previous states, the
I/O cache may either restore a peer from a checkpoint or start a
new peer from the beginning. Figure 5 compares these options .
The SUT moves from state S1toS3,p r o d u c i n gah i t h e r t o
unseen request message. Ciis the peer state associated with
SUT state Si.L o a d i n gac h e c k p o i n tt a k e st i m ei nc r e a t i n g
ap r o c e s sa n dt h ee x e c u t i o no ft r a n s i t i o n t2.R e s t a r t i n gt h e
peer takes time in creating a new process and the execution of
transitions t0andt2.C h e c k p o i n t i n gs t r a t e g i e ss h o u l dp r o v i d ea
way to estimate and compare cost in each choice. In the curren t
implementation, the model checker always restores the peer
from a checkpoint, assuming that loading the program space
from a checkpoint is faster. In this case, the initial peer st ate
(C0)m u s ta l w a y sh a v eap h y s i c a lc h e c k p o i n ts i n c ei tc a nb ea
starting point to go to any logical checkpoints. Implementa tion
of other checkpointing strategies constitutes future work .
E. Restrictions
Ac h e c k p o i n t i n gt o o lc a n n o tf o r c eap e e rp r o c e s st op r o d u c e
output in a speciﬁc non-deterministic branch. The I/O cache
uses the checkpointing tool only to make sure that the SUTreceives peer output from a certain branch. However, the pee r
output captured by the I/O cache may be different in each
run. As a result, only part of the SUT state space of the
SUT is checked. In Figure 3, once the peer moves to state
s1,t h eS U Tw i l ln e v e rr e c e i v em e s s a g e‘ B D ’o r‘ B F ’d u r i n g
the veriﬁcation, although these messages are possible in a r eal
run.
The introduction of checkpointing technology intervenes i n
the execution of a peer process in the sense that the peer
must run in a special environment. In contrast to the pure
cache-based approach, the behavior of the peer process in th e
new environment may differ from the original behavior. This
limitation also implies that one must have a permission to se t
up a checkpointing environment on the machine that runs the
peer process.
IV . I MPLEMENTATION ARCHITECTURE
Java PathFinder (JPF) [5] is a model checker for programs
written in Java. It is used as the model checker and the
run-time environment for SUT in this work. The pure I/O
cache approach without checkpointing functions was devel-
oped as an extension of JPF called net-iocache [11], [23]
for verifying networked applications. This work introduce s
process-checkpointing support by applying the tool called
DMTCP [21] to suppress non-deterministic behaviors of peer
processes. DMTCP runs a group of connected nodes ,i . e .
peer processes, in a special environment where some standar d
functions are wrapped in order to gain information to create
system checkpoints. DMTCP has the DMTCP coordinator
process that manages the execution of all nodes and handles
external commands. When the DMTCP coordinator receives
acheckpoint command, it captures the state of each node
in the group, including connection information, in checkpo int
ﬁles. One checkpoint ﬁle represents the state of one node, so
for each checkpoint command, the number of checkpoints
created is equal to the number of nodes currently running.
The checkpoint ﬁles contain sufﬁcient information to resta rt
the group of processes at a state where each process is
communicating with one another. In order to make DMTCP
work with the I/O cache, we modify some part of DMTCP
and register callback functions to capture the events insid et h e
peer process.
A. Connection with the Model Checker
DMTCP is a checkpointing tool for a group of connected
processes. Users can add a process into the group by starting it
with command dmtcp_checkpoint .A n o t h e rw a yt oa d da
process into the process group is creating a new process usin g
thefork -family functions. Every child created by a process
in the group automatically becomes a member of the group.
DMTCP saves the entire state of the process group including
connections among the internal processes when receiving th e
checkpoint command. Similarly, it restarts all processes i n
ag r o u pf r o mag i v e nc h e c k p o i n tw h e nr e c e i v i n gt h er e s t a r t
command. The SUT state is controlled by JPF while the peer
state is controlled by DMTCP as shown in Figure 6. Since the
6DMTCP
Model
Checkercheckpoint
restart
Figure 6: The state of a SUT and a group of peers is managed
by the model checker and DMTCP, respectively, but the
connection between them is not subject to checkpointing.DMTCP
Model
CheckerProxyC
a
c
h
e
DMTCP Wrapper Functions
ND NotificationCommand
Result (+ FD)Proxy Command Channel
ND Notification ChannelSUTPeerPeer
PeerFigure 7: The proxy process represents the SUT inside the
DMTCP environment. The I/O cache has two communication
channels connected to DMTCP.
SUT is not a process in the group, the connection between the
SUT and peers is not subject to checkpointing. As a result,
the connection is closed when the I/O cache kills the group
of peers before loading a new one from a checkpoint. When
restarting, the I/O cache must provide a way to restore this
connection so that the SUT and peer can communicate with
each other again.
In our implementation, we create a proxy process that
represents a SUT in the DMTCP environment. The proxy
process runs similar to other peer processes as shown in
Figure 7. When the SUT performs an operation that establishe s
ac o n n e c t i o n ,t h eI / Oc a c h es e n d st h ec o r r e s p o n d i n gc o m -
mand to the proxy process. Currently, the proxy supports ﬁve
commands: create_socket ,connect ,accept ,bind ,
andclose .T a b l eIs h o w sam a p p i n gb e t w e e nt h en e t w o r k
operations called by SUT and the proxy commands. The proxy
performs the requested operation and sends the result back t o
the I/O cache. Some operations may return a ﬁle descriptor
that represents a network socket. The I/O cache can use the ﬁl e
descriptor it receives to communicate with the peer directl y. In
order to transfer ﬁle descriptors between processes, the SU T
and proxy use a pair of Unix domain sockets to communicate
with each other.
Table I: Supported Java methods and their associated proxy
commands.
Java Method
 Proxy Command
 FD
Returned?
new Socket()
 create_socket
 yes
Socket.connect()
 connect
 no
Socket.close()
 close
 no
new ServerSocket()
 bind
 no
ServerSocket.accept()
 accept
 yes
B. DMTCP Modiﬁcation
Our checkpointing-based approach requires a mechanism
that notiﬁes the I/O cache whenever a peer executes an
instruction that causes non-deterministic behaviors. In o rder to
implement such a mechanism, we need to watch calls to some
functions of the peer program. In the current implementatio n,
functions time andread are specially treated as they may
produce non-deterministic results. Function time may be
called obtain the current time, which varies across executi ons.
This value is often used as a seed to generate a sequence of
pseudo-random numbers such as function srand .W h e nf u n c -
tiontime is called, the I/O cache is notiﬁed. As for function
read ,t h eI / Oc a c h ew i l lb en o t i ﬁ e di ft h eﬁ l ed e s c r i p t o ra r g u -
ment is associated with the system random number generator
device /dev/random or/dev/urandom .T h e s ed e v i c e s
are non-deterministic data sources supplied by the operati ng
system.
DMTCP provides a set of wrapper functions that collects
necessary information for checkpointing before calling th er e a l
version of the functions. The wrapped functions include bot h
standard C libraries and system calls. In a similar way, we
add one wrapper function ( time )a n dm o d i f ya ne x i s t i n g
one ( read ). When either of these functions detects non-
determinism (ND), it sends a ND notiﬁcation to the I/O cache.
C. Cache-DMTCP Private Communication
During veriﬁcation, the I/O cache and DMTCP must have
aw a yt oc o m m u n i c a t ew i t he a c ho t h e r .T h eI / Oc a c h es e n d s
commands to the proxy process inside the DMTCP environ-
ment, as mentioned in Section IV-A. In addition to that, it
must be ready to receive a notiﬁcation when a peer process
performs a non-deterministic operation.
We set up two communication channels between the I/O
cache and DMTCP: the proxy command channel and the
non-determinism notiﬁcation channel ,i l l u s t r a t e di nF i g u r e7 .
When veriﬁcation starts, the proxy process connects to the I /O
cache using a Unix-domain socket, which allows the proxy to
transfer ﬁle descriptors to the I/O cache. This connection i s
called the proxy command channel. It must be cut off before
checkpointing, otherwise DMTCP will try to save the state of
the process at the other side of the connection, i.e., the mod el
checker. JPF does not run inside the DMTCP environment and
should never be dumped into a checkpoint. The proxy com-
mand channel is re-established after checkpointing/resta rting.
We register the pre/post-checkpoint callback functions to
DMTCP that are responsible for cutting off and repairing thi s
connection, respectively.
The I/O cache recognizes non-deterministic operations on
the peers by creating a worker thread that waits for ND
notiﬁcations. The worker thread binds a TCP server socket
to a ﬁxed port number. Every time a peer executes a non-
deterministic function, the corresponding DMTCP wrapper
function asynchronously sends a ND notiﬁcation packet to
the worker thread as shown in Figure 7. If the I/O cache
receives a notiﬁcation during a transition, it will create a peer
checkpoint at the end of the transition. Note that we must wai t
7Group of
Peers(1)(2)
(4) (3)
PipeI/O CacheShell
ScriptDMTCP
CoordinatorFigure 8: Communication between the model checker and
DMTCP during checkpointing and restarting.
until the current transition is completed in order to genera te
the checkpoint state space that maps on the SUT state space
one-to-one as shown in Figure 4.
When the I/O cache dispatches the checkpoint/restart com-
mand to DMTCP, it must be blocked until the peers are ready
again. In the current implementation, the proxy process not iﬁes
the I/O cache via a named pipe (FIFO) as shown in Figure 8.
The I/O cache executes a shell script (1) that dispatches a
command to the DMTCP coordinator, an interface of the
peer processes (2). After the operation has been completed,
DMTCP notiﬁes the I/O cache by putting a message in
ap i p e( 3 ) .W a i t i n go nt h ep i p e ,t h es h e l ls c r i p tr e c e i v e s
the message and returns the control to the I/O cache (4).
This procedure makes sure that the I/O cache only continues
running when the peer side is ready. All processes must run
on the same Linux machine in order to use the named pipe.
Otherwise, another synchronization method must be provide d.
Currently, DMTCP supports only Linux-based operating sys-
tems, so our implementation adds no extra limitation.
V. E XPERIMENTS AND DISCUSSION
This section compares the time and the number of states
generated in the model checking process between the pure I/O
cache approach and the checkpointing approach with several
checkpointing strategies. The experiment was run on an 8-co re
Mac Pro workstation with 24GB of physical memory, running
Ubuntu 8.04, JPF 6 (changeset 382:4f9c3fc91a2f ), and
DMTCP (revision 967). The time limit for each case was set
to one hour. Table II shows the experimental results2.C o l u m n
“no CP” denotes the I/O cache approach with no checkpointing
support. Three checkpointing strategies were applied in th e
experiment.
1)always save :C r e a t eac h e c k p o i n ti ft h ep e e ri sa l i v e .
2)after I/O :C r e a t eac h e c k p o i n ta f t e rat r a n s i t i o ni n v o l v e d
an e t w o r k e dI / Oo p e r a t i o n .
3)after ND :C r e a t eac h e c k p o i n ta f t e rat r a n s i t i o nd u r i n g
which a ND notiﬁcation is received.
In the alphabet application, a multi-threaded client sends num-
bernto the server and receives the nth letter of the English
alphabet as a response, for a speciﬁed number of times. The
alphabet client randomly sends a number of messages from set
{0,1,..., 9}while the alphabet server randomly sends either
small or capital letters. Deterministic versions of the pee rs
2The veriﬁcation time and the number of states are higher than the results
in a previous publication [12] due to a change in JPF to cover m ore thread
schedules.were used in the “no CP” case. Non-deterministic versions
were used in the other cases. Note that the number of states
explored by JPF is the same, regardless of determinism of
peer output, since our approach captures one of the possible
responses of the peer. The model checking process then runs
as if the peer produced deterministic output.
The HTTP client simply requests a ﬁle from a server via
HTTP. It generates worker threads to request multiple ﬁles i n
parallel. thttpd [24] is a small-size HTTP server, used in th e
experiment without modiﬁcation. It sends static contents, thus
deterministic output, according to client requests. Jget [ 25]
creates multiple threads that each download a portion of a ﬁl e
in parallel from a server.
ScpTo is an example program in the Java Secure Channel
(JSch) package [26], which copies a local ﬁle to a remote host
via a secure channel. Both the client and server can produce
non-deterministic output. ScpTo and the server generate a
random value in the process of building a secret shared
key [22]. As explained in Section III, checkpointing suppor t
is essential in this case. The GUI code in the program is
removed before doing the experiment with Dropbear [27], a
SSH server. The I/O cache with checkpointing has found a
fault in ScpTo that involves a race condition. ScpTo creates
as e s s i o nt h r e a dt or e c e i v ep a c k e t sf r o mt h es e r v e rw h i l et h e
main thread sends packets to the server. Both threads are not
synchronized properly so that a race condition happens unde r
ac e r t a i nt h r e a ds c h e d u l e .I ft h em a i nt h r e a dm a k e sp r o g r e s s
much faster than another thread and reaches the point where a
required packet has not been received, it throws an exceptio n3.
Another version of ScpTo is bug-ﬁxed and further abstracted
in order to ﬁnish the veriﬁcation within reasonable time. An
abstract SSH server runs as a peer for this version of ScpTo.
Both versions were veriﬁed in the experiment together with
other applications.
The performance of the checkpointing approach with the
“ND” strategy is not much different from the pure cache
approach (no CP) since it only creates a checkpoint if nec-
essary. It also provides support for non-deterministic pee rs,
making it more powerful than the previous version of the
I/O cache. The “I/O” strategy is slightly slower than “ND”,
because it creates more checkpoints. However, it would be
useful when the peer takes a long time in I/O operations since
it prevents re-execution of those operations. The “always”
strategy excessively creates checkpoints, so its performa nce
is not practically useful. Its results are presented for the sake
of comparison.
VI. C ONCLUSIONS AND FUTURE WORK
Software model checkers cannot be applied directly to a
program that interacts with external processes. Cache-bas ed
model checking allows a single-process model checker to ver -
ify such a program against an external process. This approac h
scales well, but imposes some requirements on the target
system. In particular, previous work required peer process es to
3This bug has been acknowledged by the developer.
8Table II: Experimental results
SUT
 Peer
 #conn
 #msg
 time (mm:ss)
 #states
 #checkpoints
always
 I/O
 ND
 no CP
 always
 I/O
 ND
2
 27:45
 0:11
 0:10
 0:05
 7572
 3438
 6
 4
2
 3
 >1 h
 0:26
 0:24
 0:14
 33.3K
 -
 12
 7
ND alphabet
 ND alphabet
 4
 -
 1:18
 1:12
 0:53
 147.5K
 -
 24
 13
client
 server
 2
 -
 4:22
 4:20
 4:08
 525.3K
 -
 10
 6
3
 3
 -
33:40
 33:22
 32:38
 4581.9K
 -
 20
 11
4
 >1 h
2
 2:14
 0:11
 0:10
 0:01
 299
 277
 9
 8
2
 3
 3:55
 0:16
 0:16
 0:02
 499
 491
 15
 14
4
 5:53
 0:21
 0:20
 0:03
 747
 739
 20
 19
2
 33:59
 0:18
 0:18
 0:04
 4269
 4241
 15
 13
ND alphabet
 ND alphabet
 3
 3
 >1 h
 0:28
 0:27
 0:07
 8775
 -
 24
 22
server
 client
 4
 -
 0:37
 0:37
 0:10
 15.5K
 -
 32
 30
2
 -
 0:48
 0:47
 0:29
 57.8K
 -
 21
 18
4
 3
 -
 1:35
 1:34
 1:05
 143.1K
 -
 33
 30
4
 -
 2:50
 2:48
 2:09
 295.2K
 -
 44
 41
2
 -
 7:06
 7:06
 6:34
 746.4K
 -
 27
 23
5
 3
 -
20:07
 19:59
 18:59
 2209.1K
 -
 42
 38
4
 -
47:08
 47:03
 44:58
 5295.8K
 -
 56
 52
2
 2:57
 0:05
 0:04
 0:02
 415
 415
 3
 1
HTTP
 3
 46:42
 0:51
 0:50
 0:48
 6675
 6675
 4
 1
client
 thttpd
 4
 >1 h
 23:12
 23:07
 22:10
 112.5K
 -
 5
 1
5
 >1 h
Jget
 2
 N/A
 41:54
 0:15
 0:15
 0:11
 5984
 5984
 4
 3
3
 >1 h
 45:48
 45:48
 45:43
 839.8K
 -
 6
 4
ScpTo1
Dropbear
 1
 7:56
 0.15
 0:15
 ✘
 1027
 1026
 9
 9
ScpTo
 Abstract
 1
 1:15
 0:05
 0:05
 ✘
 167
 167
 6
 2
(bug ﬁxed)
 SSH Server
 2
 >1 h
 9:21
 9:19
 ✘
 557.7K
 -
 8
 3
✘:T h eI / Oc a c h ew i t h o u tc h e c k p o i n t i n gd o e sn o ts u p p o r tt h e s e cases.
1Ab u gi sf o u n di nt h i sc a s e .
be deterministic. In this work, the class of veriﬁable progr ams
has been expanded to cover non-deterministic peers, which
are controlled by process checkpointing. Our extension cre ates
checkpoints of a peer program according to a checkpoint
strategy. The experiment has shown that the overhead caused
by the checkpointing tool is acceptable if an appropriate
strategy is used.
Future work includes development and analysis of check-
pointing strategies. The shell scripts that communicate wi th
DMTCP will be replaced with a library in the I/O cache to
eliminate the platform dependency. We also have a plan to run
each peer process under a model checker. The model checker
could be modiﬁed so that it controls low-level peer behavior s
such as thread scheduling. Furthermore, the model checker
may store peer states in memory rather than non-volatile
storage, reducing the I/O operation overhead. Being able to
control thread scheduling, we could analyze the peer behavi ors
and selectively perform the ones that would potentially rev eal
faults in the SUT. We will consider how the model checker
engines communicate with each other as well.
Acknowledgment
This work was supported by KAKENHI (23300004 and
23240003).
REFERENCES
[1] A. Tanenbaum, Modern operating systems .P r e n t i c e - H a l l , 1 9 9 2 .
[2] G. J. Myers, The art of software testing .N e w Y o r k : W i l e y , 1 9 7 9 .[3] T. Ball, S. Burckhardt, K. E. Coons, M. Musuvathi, and S. Q adeer,
“Preemption sealing for efﬁcient concurrency testing,” in TACAS’ 10 ,
2010, pp. 420–434.
[4] E. Clarke, O. Grumberg, and D. Peled, Model Checking .M I T P r e s s ,
1999.
[5] W. Visser, K. Havelund, G. Brat, S. Park, and F. Lerda, “Mo del checking
programs,” Automated Software Engineering Journal ,v o l .1 0 ,n o .2 ,p p .
203–232, 2003.
[6] P. Godefroid, Partial-Order Methods for the Veriﬁcation of Concurrent
Systems: An Approach to the State-Explosion Problem ,J .v a nL e e u w e n ,
J. Hartmanis, and G. Goos, Eds. Secaucus, NJ, USA: Springer- Verlag
New York, Inc., 1996.
[7] S. Ghosh, Distributed Systems: an Algorithmic Approach .B o s t o n :
Twayne Publishers, 2006.
[8] S. D. Stoller and Y . A. Liu, “Transformations for model ch ecking
distributed Java programs,” in SPIN ’01: Proceedings of the 8th in-
ternational SPIN workshop on Model checking of software .N Y , U S A :
Springer-Verlag New York, Inc., 2001, pp. 192–199.
[9] C. Artho and P. Garoche, “Accurate centralization for ap plying model
checking on networked applications,” in Automated Software Engineer-
ing Conf. ,T o k y o ,J a p a n ,2 0 0 6 ,p p .1 7 7 – 1 8 8 .
[10] E. D. Barlas and T. Bultan, “NetStub: A framework for ver iﬁcation of
distributed Java applications,” in Automated Software Engineering Conf. ,
Georgia, USA, 2007, pp. 24–33.
[11] C. Artho, W. Leungwattanakit, M. Hagiya, and Y . Tanabe, “Efﬁcient
model checking of networked applications,” in Proc. TOOLS EU-
ROPE 2008 ,s e r .L N B I P ,v o l .1 9 . Z u r i c h ,S w i t z e r l a n d :S p r i n g e r ,2 0 0 8 ,
pp. 22–40.
[12] C. Artho, W. Leungwattanakit, M. Hagiya, Y . Tanabe, and M. Ya-
mamoto, “Cache-based model checking of networked applicat ions: From
linear to branching time,” in Proceedings of the 2009 IEEE/ACM
International Conference on Automated Software Engineeri ng,s e r .A S E
’09. Washington, DC, USA: IEEE Computer Society, 2009, pp. 4 47–
458.
[13] Y . Nakagawa, R. Potter, M. Yamamoto, M. Hagiya, and K. Ka to, “Model
checking of multi-process applications using SBUML and GDB ,” in
Workshop on Dependable Software: Tools and Methods ,Y o k o h a m a ,
Japan, 2005, pp. 215–220.
9[14] J. Dike, User Mode Linux .P r e n t i c e H a l l P T R , 2 0 0 6 .
[15] R. Stallman, R. Pesch, and S. Shebs, Debugging with GDB : the GNU
source-level debugger ,9 t he d . B o s t o n ,M A:F r e eS o f t w a r eF o u n d a t i o n ,
2002.
[16] P. Godefroid, “Software model checking: The VeriSoft a pproach,” Form.
Methods Syst. Des. ,v o l .2 6 ,n o .2 ,p p .7 7 – 1 0 1 ,2 0 0 5 .
[17] “OpenVZ documentation,” http://wiki.openvz.org.
[18] Red Hat, Inc., “KVM,” http://www.linux-kvm.org.
[19] Oracle, “Virtualbox,” http://www.virtualbox.org/.
[20] M. Rieker and J. Ansel, “Transparent user-level checkp ointing for the
native POSIX thread library for Linux,” in In Proc. of PDPTA-06 ,2 0 0 6 ,
pp. 492–498.
[21] J. Ansel, K. Aryay, and G. Coopermany, “Dmtcp: Transpar ent check-
pointing for cluster computations and the desktop,” in Proceedings of
the 2009 IEEE International Symposium on Parallel & Distrib utedProcessing .W a s h i n g t o n , D C , U S A : I E E E C o m p u t e r S o c i e t y , 2 0 0 9 ,
pp. 1–12.
[22] W. Difﬁe and M. E. Hellman, “New directions in cryptogra phy,” IEEE
Transactions on Information Theory ,v o l .2 2 ,n o .6 ,p p .6 4 4 – 6 5 4 ,
November 1976.
[23] W. Leungwattanakit, C. Artho, M. Hagiya, Y . Tanabe, and M. Ya-
mamoto, “Verifying networked programs using a model checke re x t e n -
sion,” in ICSE Companion proceedings ,V a n c o u v e r ,C a n a d a ,2 0 0 9 ,p p .
409–410.
[24] ACME Laboratories, “thttpd - tiny/turbo/throttling H TTP server,” http:
//www.acme.com/software/thttpd/.
[25] S. Paredes, “Jget,” http://www.cec.uchile.cl/~spar edes/jget/.
[26] JCraft, Inc., “JSch - Java Secure Channel,” http://www .jcraft.com/jsch/.
[27] M. Johnston, “Dropbear SSH server and client,” http:// matt.ucc.asn.au/
dropbear/dropbear.html.
10