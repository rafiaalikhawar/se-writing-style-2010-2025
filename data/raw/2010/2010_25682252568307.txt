Detecting Memory Leaks through Introspective Dynamic
Behavior Modeling using Machine Learning
Sangho Lee
College of Computing
Georgia Institute of
Technology
Atlanta, GA 30332-0250, USA
slee431@cc.gatech.eduChanghee Jung
Department of Computer
Science
Virginia Tech
Blacksburg, VA 24061, USA
chjung@cs.vt.eduSantosh Pande
College of Computing
Georgia Institute of
Technology
Atlanta, GA 30332-0250, USA
santosh@cc.gatech.edu
ABSTRACT
This paper expands staleness-based memory leak detection
by presenting a machine learning-based framework. The
proposed framework is based on an idea that object stal-
eness can be better leveraged in regard to similarity of ob-
jects; i.e., an object is more likely to have leaked if it shows
signicantly high staleness not observed from other similar
objects with the same allocation context.
A central part of the proposed framework is the modeling
of heap objects. To this end, the framework observes the
staleness of objects during a representative run of an ap-
plication. From the observed data, the framework generates
training examples, which also contain instances of hypothet-
ical leaks. Via machine learning, the proposed framework
replaces the error-prone user-denable staleness predicates
used in previous research with a model-based prediction.
The framework was tested using both synthetic and real-
world examples. Evaluation with synthetic leakage work-
loads of SPEC2006 benchmarks shows that the proposed
method achieves the optimal accuracy permitted by staleness-
based leak detection. Moreover, by incorporating alloca-
tion context into the model, the proposed method achieves
higher accuracy than is possible with object staleness alone.
Evaluation with real-world memory leaks demonstrates that
the proposed method is eective for detecting previously re-
ported bugs with high accuracy.
Categories and Subject Descriptors
D.2.4 [ Software Engineering ]: Software/Program Veri-
cation| Reliability, Statistical methods ; D.2.5 [ Software
Engineering ]: Testing and Debugging| Debugging aids,
Monitors, Tracing ; D.3.4 [ Programming Languages ]: Pro-
cessors| Memory Management, Run-time environments
General Terms
Languages, Measurements, Performance, Reliability
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proÔ¨Åt or commercial advantage and that copies
bear this notice and the full citation on the Ô¨Årst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciÔ¨Åc
permission and/or a fee.
ICSE ‚Äô14, May 31 - June 7 2014, Hyderabad, India
Copyright 2014 ACM 978-1-4503-2756-5/14/05 ...$15.00Keywords
Memory leak detection, Machine learning, Runtime analysis
1. INTRODUCTION
For unmanaged programming languages, memory leaks
are a common bug that undermines the quality of the pro-
gram. A memory leak occurs when an application omits
the deallocation of an allocated memory object that has no
future use. Because memory leaks gradually exhaust avail-
able system memory, they are often the root cause of per-
formance degradation and a sudden hang/crash failure of
software systems. Moreover, memory leaks can be inten-
tionally exploited by adversaries to launch denial-of-service
attacks [31].
One notable example showing the severity of memory leak-
age is the Amazon web services outage [32]. In 2012, Ama-
zon replaced a data collection server. Unfortunately, this
seemingly harmless maintenance action caused an incorrect
conguration of some servers, which led to memory leaks.
Due to the failure of a monitoring alarm, the memory leaks
went out of control eventually, and the aected servers came
to a stop. Consequently, millions of users were aected by
the memory leaks.
What makes memory leaks hard to detect and x at an
early stage of development is their input and environmental
sensitivity. Since the number of possible execution paths is
potentially innite, covering every possible execution path
and conguration is not plausible even for extensive in-house
testing. As a result, only the obvious leaks are discovered
and xed during the testing stage. The remaining leaks,
therefore, are highly susceptible to the execution environ-
ment and are highly elusive. The Amazon memory leak in-
cident is a clear demonstration of how tricky memory leaks
are.
In response to the insidious nature of memory leaks, re-
searchers have proposed low overhead dynamic memory leak
detection techniques. These techniques are based on object
staleness , which represents how long an object remains un-
accessed during program execution. Staleness-based leak
detection relies on an intuition that leaking objects must be
stale, whereas live objects with pending uses are unlikely to
remain unaccessed for a long period of time. In light of this,
the leak detection method assumes that memory leaks can
be eectively identied by using a proper staleness predi-
cate, which decides whether an object has leaked based on
the staleness of the object.Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proÔ¨Åt or commercial advantage and that copies bear this notice and the full citation
on the Ô¨Årst page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior speciÔ¨Åc permission and/or a
fee. Request permissions from Permissions@acm.org.
ICSE‚Äô14 , May 31 ‚Äì June 7, 2014, Hyderabad, India
Copyright 2014 ACM 978-1-4503-2756-5/14/05...$15.00
http://dx.doi.org/10.1145/2568225.2568307
814
This work is an extension of staleness-based memory leak
detection in that it also leverages object staleness as an in-
dication of memory leaks. However, this work obviates us-
ing object staleness as is and use of user-denable staleness
predicates, unlike previous research. Instead, the memory
leak detection framework proposed in this work is based on
introspective reasoning about how leaking objects may be-
have (or how stale the objects would be) and on modeling
the behavior using machine learning.
The key idea behind using machine learning is that a leak-
ing object is discernible by observing the lifetimes of other
similar objects. That is, an object can be regarded as having
leaked when it accrues a high degree of staleness that is not
observed from other supposedly similar objects, i.e., objects
with the same allocation context. To make matters easier,
once expected behavior of an object is known, introspect-
ing what may happen if the object has leaked is surprisingly
easy; i.e., the object becomes only more and more stale. This
leads to a key insight of this work that memory leaks can be
eectively addressed by observing/modeling the behavior of
heap objects.
In light of this, this paper presents a machine learning-
based memory leak detection framework, which is intended
to be used throughout the development cycle. The pro-
posed framework enables observation of heap objects during
the testing phase (e.g., regression testing) and application
of this knowledge during the production phase. To this end,
the framework runs an application during testing with a
memory access sampling to store the heap activity samples.
The framework then uses a trace simulation to replay the
heap activities and to generate training examples. By using
these examples, which also contain hypothetically injected
leaks, the framework constructs a model. The framework
uses this model during the production run to detect anoma-
lous behavior indicating a memory leak.
The machine learning-based framework has several advan-
tages over the previous approach relying solely on staleness
predicates. First, because the new approach is a framework,
it can be congured to use any memory access sampling
method for estimating staleness. Depending on the runtime
requirement, e.g., a custom memory allocator is not allowed,
an alternative sampling method can be used with no change
to the whole framework. Also, compared to the previous
approach, the machine learning-based approach, by virtue
of being application tailored, oers automation of staleness
predicate determination. Moreover, the new approach pro-
vides increased accuracy by incorporating allocation context
information into leak detection.
The proposed framework was rst evaluated on synthetic
leakage workloads, which were generated by dynamically
removing 5% of deallocations during the execution of the
SPEC CPU2006 benchmark suite. The results on the work-
loads show that the proposed framework achieves the best
accuracy permitted by staleness-based leak detection and
improves upon it by additionally incorporating allocation
context into input features of the trained model. For 4 appli-
cations out of 9 applications tried, the addition of allocation
context achieved meaningful accuracy improvement.
In addition to the synthetic leakage workloads, the pro-
posed framework was also tested on 2 publicly available
open-source programs, lighttpd-1.4.19 and bash-4.0, to demon-
strate how the machine learning-based leak detection frame-
work can be applied to real world scenarios. The empiricalevaluations show that the proposed framework achieves very
accurate results and succeeds in correctly identifying the re-
ported memory leaks of the tested programs.
Contributions of this work include:
Memory leak modeling using machine learning,
Encoding scheme for object staleness for use in ma-
chine learning,
Incorporation of allocation context into input features
to improve accuracy of leak detection,
Evaluation of the proposed method on synthetic leak-
age,
Demonstration of the technique on 2 real world exam-
ples; lighttpd-1.4.19 and bash-4.0.
The rest of this paper is structured as follows: Section 2
lays out the motivation of this work. Section 3 describes the
machine learning-based memory leak detection framework,
and section 4 evaluates performance of the proposed frame-
work on both synthetic leakage and on real world examples.
Section 5 discusses related work. Finally, section 6 concludes
with the lessons learned from the work.
2. MOTIVATION
Memory leaks are distinct from any other program bugs in
that they do not aect program behavior directly by inu-
encing the execution path. Only accumulated leaks, through
a form of performance degradation, are visible to the out-
side world. Due to this non-interactivity with program se-
mantics, predicting what may happen to leaking objects is
relatively easy; i.e., once memory objects become lost, they
cannot be accessed any more by a program. In fact, a re-
cent generation of dynamic memory leak detection technique
based on staleness tracking is an exploitation of this idea [14,
8, 30, 6, 7, 26].
Staleness-based leak detection is an intuitive view of the
memory leakage problem, which attributes stale objects as
the symptom of memory leaks. The leak detection method
is built around the idea that leaking objects must be neces-
sarily stale, whereas other objects that are currently in use
are unlikely to be so. Leaking objects, by denition, do not
get accessed after they become lost to an application, and
become stale. Objects that are in use, on the other hand,
are likely to be accessed frequently to utilize their memory
space usage (otherwise the objects bloat the memory foot-
print, which wise programmers avoid through various ways).
Figure 1 is an illustration of how the staleness assumption
relates to memory leak detection. Initially, 3 objects are
allocated at a program point simultaneously. At a later time,
the leak detection method takes a heap snapshot to query
whether any object residing in memory has leaked. Object
1 is deallocated prior to the heap snapshot point, and is
irrelevant to the leak query. Object 2 is a normal object
that has accrued a certain degree of staleness since its last
access. Object 3, unlike the previous 2 objects, becomes
unreachable long before the snapshot point and is highly
stale at the point. Using a staleness threshold that is higher
than the degree of staleness of object 2 and smaller than the
degree of staleness of object 3, staleness-based leak detection
can successfully identify the leaking object.815Allocation  
Staleness  Snapshot  
Object 2  
Object 3  Allocation  Became unreachable  Last accessed  Allocation  
Object 1  Deallocation  
Time  Leak?  Leak?  
Staleness  ‚ãØ Figure 1: Staleness assumption: leaking objects are
more likely to be stale than others.
In previous research, this assumption is encoded as a user-
denable predicate; e.g., the user may specify that an object
has leaked if it remains idle for 100 million memory accesses.
However, relying on staleness predicates for accurate detec-
tion suers from 2 shortcomings of the approach. For one
thing, appropriateness of a predicate heavily depends on be-
havior of an application. Hence, the user has to nd a proper
staleness predicate for every new application. For another,
staleness estimation methods are usually based on sampling.
It is unrealistic to assume that the user can account for sam-
pling factor in conguring a predicate.
To work around this, this work takes inspiration from pre-
vious research on object lifetime prediction [4, 20]. Accord-
ing to these works, the lifetime of an object is strongly cor-
related with its allocation context. Since the staleness of an
object is bounded by its lifetime, object staleness is tran-
sitively correlated with allocation context. For example, it
becomes more convincing that object 3 in gure 1 has leaked
if the other objects are from the same allocation context, and
if they are supposed to be similar in their behavior. With
this in mind, this work assumes that an object can be con-
sidered to have leaked (with high probability), if it shows a
signicantly high degree of staleness not observed from other
similar objects, which have the same allocation context.
To leverage this insight, the leak detection framework pro-
posed in this work observes behavior of heap objects from
a representative run of an application. The observed pat-
terns are then modeled using supervised learning to con-
struct a model, which bases the decision whether an object
has leaked or not on the similarity/dissimilarity of objects in
terms of their lifetimes and staleness behaviors. With this
approach, the proposed framework replaces user-denable
staleness predicates with a model-based prediction.
A central question that needs to be addressed in using su-
pervised learning is how to obtain training examples. That
is, a supervised learning algorithm is essentially a process of
iteratively rening a model by using both positive and nega-
tive examples. Therefore, to train a model of leaking objects
and live objects with pending uses, instances of both cases
exhibiting their dierences has to be supplied to a learn-
ing algorithm. However, getting an instance of a leaking
object is, in general, extremely dicult because no a priori
information is given during testing of an application; i.e., an
execution path that can trigger a potential memory leak is
not yet identied at this stage (otherwise, it should have al-
ready been xed). On the contrary, a testing environment is
supposed to be a representative usage scenario of an applica-
tion. Hence, the objects observable during testing show only
how normal objects will/should behave during production.
Time  Allocation  Deallocation  
What -if-leak staleness  Last access  Snapshot  Figure 2: What-if-leak staleness corresponds to the
time interval between last access point of an object
and the heap snapshot point.
The solution comes from the characteristic of memory
leaks; i.e., they do not alter the execution of a program.
Suppose an object is deallocated prior to a specic time,
when the heap state is examined. Since the only side eect
of a memory leak is in object staleness, the only thing that
may have happened if the deallocated object had been lost
is a higher degree of staleness of the object. In this work,
this hypothetical staleness of an object is termed what-if-leak
staleness (gure 2). Using instances of hypothetically leak-
ing objects with what-if-leak staleness as training examples,
therefore, works as an approximate solution.
The model trained using instances of hypothetically leak-
ing objects is a model of what may happen if an object has
leaked. As such, the trained model is able to handle almost
all possible leakage scenario by reecting what-if-leak stale-
ness of all objects observed during testing. As long as the
testing environment remains a representative of the produc-
tion run, the model must be an accurate classier of leaking
objects.
3. MACHINE LEARNING-BASED
LEAK DETECTION FRAMEWORK
This section presents the machine learning-based memory
leak detection framework. As machine learning is the central
part of the framework, this section discusses background in-
formation on support vector machines (SVMs) and relevant
details, such as encoding object staleness as input features,
with respect to memory leak detection.
3.1 Overview
Figure 3 is an overview of the machine learning-based
memory leak detection framework. In the envisioned us-
age scenario, the framework is deployed during the testing
phase, and runs a target application with a memory access
sampling method congured by the user to generate heap ac-
tivity traces. In turn, a trace simulator uses the generated
traces and outputs training examples that are comprised of
both non-leaking objects, at a point of a heap snapshot,
and hypothetically leaking objects with what-if-leak stale-
ness. With the training examples, the framework trains
multiple SVM models to probe inuence of SVM parameters.
Among the constructed models, the framework selects one,
which is expected to achieve the best accuracy according to
its cross-validation score. During the production phase, the
selected SVM model is applied to heap snapshots at which
leak reports are requested.
3.2 Trace Simulation and Training Example
Generation
The proposed framework relies on trace simulation to gen-
erate training examples from a specic heap snapshot, which
the user marks as the representative of a target application816Application  
Machine  
Learning  
Algorithm  Feature  
Vectors  
SVM  
Model  
Leak 
Report  Heap  
Activity  
Sampling  
Trial Run  
Heap  
Activity  
Sampling  
Production 
Run  
Heap  
Activity  
Traces  
Heap  
Activity  
Replay   
Hypothetical  
Leaks  
Feature  
Vectors  
 
Normal  
Objects  
 
Leak?  During the 
Testing Phase  
Trace  
Simulator  
During the 
Production Phase  Figure 3: Overview of the machine learning-based
memory leak detection framework.
Trace 
Simulator  
Time  Event  Address  
0x10  malloc  0x80  
0x11  read  0x41  
0x20  write  0x40  
0x21  free 0x40  
‚ãÆ Heap Activity 
Traces  Training 
Examples  
* Heap state is represented as a search tree  [0x40, 0x50]  
[0x30, 0x34]  [0x60, 0x64]  
[0x25, 0x29]  [0x36, 0x39]  
Figure 4: Trace simulation replays sampled heap ac-
tivities to obtain training examples for model con-
struction.
heap state. Trace simulation provides extra exibility by en-
abling replay of the heap activities happened during a trial
run of an application without running it again.
Figure 4 shows how the trace simulation works. After a
testing run of an application, malloc /free traces and sam-
pled memory accesses are stored on the disk in chronological
order. The trace simulator reads these traces and replays the
operations. In doing so, the trace simulator represents cur-
rent heap state as a binary search tree, where each node cor-
responds to a currently live object. Each event in the traces
causes an operation on the tree. A malloc event triggers
an insertion of a new node into the tree. Likewise, a free
event triggers a deletion of the corresponding node from the
tree. Each memory access forces the degree of staleness of
the accessed object to 0. For other unaccessed objects, their
degrees of staleness increase by the amount of time lapsed
Allocation  Snapshot  
Object 2  Last access  Allocation  
Object 1  Deallocation  
Staleness  What -if-leak staleness  
Future access  Staleness: 0  Figure 5: Training example generation by the trace
simulator from a deallocated object and a live ob-
ject.
between each operation. For ecient mapping of an address
to the corresponding object, the tree data structure imple-
ments the range query with a typical binary search1.
Figure 5 shows how training examples are generated by
the trace simulator given a heap snapshot point. For an
object that was deallocated prior to the snapshot point, 2
training examples are generated to account for 2 facts: 1) the
object is supposed to be deallocated prior to the snapshot
point, and 2) if the object were leaking, the what-if-leak
staleness is the time interval between the last access of the
object and the snapshot point. For an object that is still
live at the snapshot, the trace simulator generates only one
example to represent that an object less stale than the live
object is not likely to have leaked.
Although the training examples are generated at a spe-
cic snapshot point, choosing the point is not a hurdle to
the user. The kinds of applications staleness-based leak de-
tection targets are long running applications, e.g., servers
or interactive games [14]. Since such applications tend to
perform repetitive computations over a long period of time,
taking a representative heap snapshot or specifying a snap-
shot point should come naturally to the user.
3.3 Support Vector Machines
Among many supervised learning algorithms/models, this
work selected SVMs [16] as the key part of the framework.
SVMs are machine learning models that represent linearly
separating hyperplanes. For example, when the dimension-
ality of an input data is 2, a SVM model corresponds to
a line that divides the input space into 2 mutually disjoint
regions; i.e., data points that lie above the line are classied
as one category, whereas data points that lie below the line
are classied as the other category. Applied to memory leak
detection, a SVM model is conceptually a staleness pred-
icate, which bisects the input space representing staleness
of allocated objects into 2 regions, respectively for leaking
objects and innocent objects.
The choice of SVMs among various machine learning mod-
els is due to the computational capability of the models.
With more complex models such as articial neural net-
works, this work found that there is a danger of learning
a contradictory function; i.e., the trained model may iden-
tify a lowly stale object as non-leaking, a modestly stale
object as leaking, and a highly stale object as non-leaking.
3.4 Input Features
1We implement the data structure using a specially mod-
ied RedBlack tree whose asymptotic complexities remain
the same, i.e., O(logN) time [21]. This fast range search is
essential for accelerating simulation.817(a) staleness + allocation time   (b) staleness only  
00.20.40.60.81
0 0.2 0.4 0.6 0.8 1NTstaleness  
NTallocation  00.20.40.60.81
0 0.2 0.4 0.6 0.8 1NTstaleness  
NTallocation  Figure 6: 2 examples of memory leak indicator func-
tions that can be expressed using the normalized in-
put features. If an object falls on the shaded area,
it is regarded as having leaked.
Instead of using absolute staleness values, the framework
encodes staleness of an object as 2 input features to nor-
malize the input range to be from 0 to 1. Without normal-
ization or scaling, input features in greater numeric ranges
dominate those features in smaller numeric ranges, and may
jeopardize the overall accuracy [19]. The input features for
an object oare as follows.
NTallocation (o) =Tallocation (o)
Tsnapshot
NTstaleness (o) =8
<
:0, ifois deallocated prior to Tsnapshot
Tsnapshot Tlast accessed (o)
Tsnapshot Tallocation (o), otherwise
where Tallocation (o) represents the allocation time of o,
andTlast accessed (o) represents the last access time of o2.
Both features have the range of 0 to 1, and express rela-
tive allocation time or relative staleness as percentiles of the
execution time or the lifetime of an object.
Figure 6 shows 2 examples of memory leak indicator func-
tions that can be expressed using the normalized input fea-
tures. Due to the computational capability of SVMs, these
functions are linear classiers. The rst leak indicator func-
tion uses the 2 input features. For this function, even a small
NTstaleness is enough evidence for an object, which was allo-
cated early, to be declared to have leaked. For an object that
was allocated late, the indicator function is more lenient by
permitting a higher degree of staleness. On the other hand,
the second indicator function uses only the normalized stal-
eness. It declares an object to have leaked if NTstaleness
is above some threshold regardless of the allocation time.
These functions roughly correspond to the staleness predi-
cates used in the previous work [14].
Using the normalized input features requires special care,
however, because the features are relative to a snapshot
point, i.e., Tsnapshot . Since the absolute value of Tsnapshot
is dierent for each snapshot taken during production runs,
adjusting for that fact is necessary. Otherwise, if Tsnapshot of
a heap snapshot is much larger than Tsnapshot of the train-
ing examples, the input features may look insignicant to
the model; i.e., even if an object has the same degree of
staleness and the same lifetime, the object may be seen as
less stale/old if it was observed during a longer run. The
purpose of using the relative input features is to normalize
the ranges, not to distort the scale.
To address this issue, the framework performs time scaling
using a polynomial function. The scaling function maps a
2They are in units a congured staleness estimation method
uses, e.g., the number of memory accesses observed.
00.51
0 1 2 3 4 5 6 7 8 9 10Snapshot 1 Snapshot 4 Snapshot 7 Snapshot 10Figure 7: Scaling execution time of production runs
using polynomials for the heap snapshots.
time of an event during a production run to a likely time
when the same event might have happened during a trial
run. The polynomial function is dened as,
r=Tsnapshot
Ttrain snapshot
TS(t) =Ttrain snapshot(t
Tsnapshot)r
Note that the slope of TSatTsnapshot is 1. Therefore,
for events that happened near the heap snapshot point, the
scaling factor is 1; i.e., original scale is preserved. On the
other hand, for events that happened much earlier, the scal-
ing factor is very small, which makes the events look as if
they happened very early.
Figure 7 depicts a situation where 4 snapshots are taken
during a production run. For the heap access events that
happened along the x-axis, their respective times of occur-
rences are scaled by the respective polynomial for each snap-
shot. For snapshot 1, the original scale is preserved because
the execution time is equal to that of the trial run. On the
other hand, moderate compaction of time occurs for snap-
shot 2 and 3 as the execution time becomes longer. For
snapshot 10, since the execution time is 10 times longer, the
time is highly compacted with some level of scale preserva-
tion near the end.
To express similarity of objects based on allocation con-
text, the framework uses allocation site and allocation size
as additional input features. Much the same way as in en-
coding object staleness, allocation size is normalized using
the maximum object size observed during a trial run.
NSize (o) =Size(o)
max obj2objects Size(obj)
Encoding allocation site, on the other hand, uses a vector
of binary variables. Formally, the vector NSite (o) is dened
as,
NSite (o) = (Site 1(o); Site 2(o); :::; Site n 1(o); Site n(o))
Site k(o) =(
1 if ois allocated from allocation site k
0 otherwise
3.5 Polynomial Kernel
Inclusion of allocation context into input features is based
on the assumption that the context has a correlation with
the estimated staleness. However, using the input features as
they are does not express this relationship; i.e., the features
are independent. To handle this issue, the framework uses a
kernel trick, which conceptually maps the input features into
a higher dimension where the interaction can be expressed.818The polynomial kernel is a commonly used method in con-
junction with SVMs. When input data are vectors in R2, the
polynomial kernel with degree 2 maps an input vector to a
vector in R3using the following mapping [10].
(x) =0
@x2
1
x1x2
x2
21
A
Since NSite (o) is a vector of binary variables, applying
the polynomial kernel results in a conceptual feature vector,
where most of the elements are zero and only the terms
representing normalized staleness or the terms expressing
interaction between allocation context of oand staleness of
oare given non-zero values.
Using the polynomial kernel is purely for the sake of com-
putational eciency. Instead of using the kernel trick, the
input features can be explicitly mapped into a higher dimen-
sion. Compared to explicit mapping, the kernel trick has one
drawback. Terms like x2
1introduced by the polynomial ker-
nel distort the shape of the indicator functions; i.e., they
become curves, not lines. However, the framework prefers
using the kernel trick in favor of reducing the computational
load, which is expensive even with the trick.
3.6 Cross-validation and Grid-search
SVMs have a handful of parameters that inuence the
accuracy of the trained model. One recommended way to
determine the parameters is to use cross-validation and grid-
search [19].
Given a specic set of parameters, cross-validation com-
putes a predicted accuracy of a model trained using the pa-
rameters. In v-fold cross-validation, the training set is rst
divided into vsubsets of equal size. Subsequently, one sub-
set is used as a testing set while the classier is trained on
the other subsets. The process takes turns until all inputs
are used as a testing instance once. The averaged accuracy
obtained thus is the expected accuracy of a model given a
set of SVM parameters. The cross-validation procedure has
a benet of preventing the over-tting problem, which oc-
curs when a model ts itself to the training data too much
instead of learning the general trend in the data.
To provide a set of model parameters for cross-validation,
the framework uses the grid-search. The grid-search is a
naive method that enumerates all the possible sets of param-
eters given the ranges of individual parameters. Although
there are several advanced methods that may save compu-
tation cost, the methods are not necessarily more accurate.
Additionally, the grid-search has a benet of being highly
amenable to parallelization.
4. EVALUATION
This section discusses the design and results of the exper-
iments that were performed to test the machine learning-
based memory leak detection framework.
4.1 Accuracy Metrics
To measure and compare the accuracy of the proposed
method, this work uses the classication accuracy as well
as the precision and recall that are the standard metrics
capturing performance of an information retrieval system.
In the context of memory leak detection, they are dened as
follows.accuracy =jcorrectly identified objects j
jobjectsj
precision =jreported leaks\realleaksj
jreported leaksj
recall =jreported leaks\realleaks
jrealleaksj
Since the classication accuracy is the metric used during
the cross-validation, it is the primary metric in comparing
the accuracy of the proposed framework. The precision and
recall are of special importance because the leak report is
given to the user who has to examine the cause. The rst pri-
ority of memory leak detectors is to provide precision while
still identifying many true instances of memory leaks.
4.2 Implementation
To evaluate the performance of the proposed method, this
work implemented adaptive burst tracing (ABT). ABT is
the memory access sampling method proposed by Chilimbi
and Hauswirth in their work called SWAT, which pioneered
the category of staleness-based memory leak detection [14].
However, unlike the original implementation, ABT was im-
plemented using the LLVM infrastructure as an IR pass,
and it was modied to write a log of sampled heap ac-
tivities onto the disk (for both trial and production runs).
The ABT implementation used the default conguration for
SWAT, which was reported to have less than 5% of run-
time overhead [14]. To train SVM models, this work used
LIBSVM [12] with 5-fold cross-validation.
4.3 Synthetic Leakage
Generally, evaluating accuracy of staleness-based leak de-
tection is a daunting task for 2 reasons. For one thing, there
is no standard set of applications containing memory leaks
with which the accuracy can be measured and compared.
For another, a staleness predicate can be applied on a set
of allocated objects at any time during the execution. This
means the accuracy is snapshot point dependent.
This work addresses the rst problem by synthetically in-
jecting leaks during the execution of SPEC CPU2006 bench-
marks to generate leakage workloads. Among the total 19
C/C++ application in the benchmark suite, this work se-
lected 9 applications, based on the number of objects during
the application execution as well as the object deallocation
pattern, in order to prevent misleading results. Addition-
ally, this work also took into consideration heap snapshot
size for ease of training and experiment.
In generating leakage workloads, the leakage percentage
was an important factor in designing such workloads. Too
much leakage tends to inate the precision of the resulting
detection. If the portion of the leaks is too large compared to
the portion of innocent objects at a program point, blindly
identifying an object as leaking becomes probabilistically a
correct decision; e.g., if there are 999 leaking objects and
1 innocent object, even an inaccurate leak detector, which
identies every object as leaking, attains a very high preci-
sion.
On the other hand, workloads with too little leakage also
end up with a bias result. For example, if there is only 1
leaking object and 999 innocent objects, even an inaccurate81900.20.40.60.811.2Accuracy (higher is better)  Manual Base Model Full ModelFigure 8: Accuracy of the machine learning-based
memory leak detection framework on the synthetic
leakage workloads.
leak detector, which identies no object as leaking, attains
a high accuracy. Thus, both very high and very low per-
centage of leaks endangers evaluation of leak detection by
producing biased results. Considering such impact of the
leak percentage on the accuracy of a leak detection method,
we decided to inject leaks by randomly removing 5% of the
total deallocations for each application.
To address the second problem, this work xed 95% of the
execution as the snapshot point to account for the fact that
the applications eventually terminate. Unlike long-running
applications such as server applications that are the targets
of staleness-based leak detection, the benchmark applica-
tions pass through several program phases, which may also
interact with model training. Using a model that trained on
examples gathered during a specic program phase may be
inadequate to detect leaks during a dierent program phase.
In consideration of this, this work gathered the heap snap-
shots from the 95% of the execution points from the runs
of the applications on train inputs, and applied the trained
model on the corresponding execution point from the runs
of the applications on reference inputs.
To see how well the machine learning-based framework
works, this work additionally conducted experiments on the
synthetic leakage workloads to obtain the optimal accuracy
achievable by using the previously used approach; i.e., we
used several staleness predicates based only on object stal-
eness, and picked the highest accuracy attained. Moreover,
this work also constructed base models, which use only the
normalized allocation time and the normalized staleness to
see whether leveraging similarity of objects via allocation
context improves the detect accuracy. The full model, as
opposed to the base model, was trained on the training data
including allocation context.
Figure 8 is the resulting accuracy of using the machine
learning-based framework. It shows the classication accu-
racies of the 3 methods. Except for h264ref , the accuracy of
the base model matches that of the manual staleness pred-
icate selection. This result matches the intuition that the
accuracy of a machine learning model is only as good as the
predictive power of the input features of the model. Close
inspection of the result on h264ref revealed that the trial
run on train input was not representative of the production
run on reference input; i.e., even the best staleness predi-
cates were dierent for the 2 runs. This resulted in a biased
model, and impacted the leak detection accuracy.
00.20.40.60.811.2Precision (higher is better)  Base Model Full Model
00.20.40.60.811.2Recall (higher is better)  Base Model Full ModelFigure 9: The precision and recall of the machine
learning-based memory leak detection framework on
the synthetic leakage workloads.
Compared to the base model, the full model achieved bet-
ter results in 4 applications, i.e., milc,h264ref ,gcc,libquan-
tum. These results are a evidence showing usefulness of
leveraging allocation context in memory leak detection.
Figure 9 shows the resulting precision and recall of the ma-
chine learning-based leak detection framework. Notably, the
recalls are almost perfect for both the base and full models.
However, due to the staleness over-approximation of ABT
as discussed in [14, 26], the precision is limited for h264ref
andastar . The objects allocated in these applications tend
to have relatively longer lifetime compared to other appli-
cations. Such objects impacted the accuracy. Compared to
the base model, the full model achieves better precision by
incorporating allocation context as shown in milc,h264ref ,
libquantum . The drastic precision gain in libquantum is be-
cause the heap snapshot contained very few leaking objects,
and the base model reported a few additional false positives.
4.4 Case Studies
To demonstrate how the proposed memory leak detection
technique applies to real world leakage detection problem,
we experimented the technique on 2 open source applica-
tions, lighttpd andbash. These applications have reported
memory leaks that can be triggered only through a certain
conguration/input. We compiled the applications stati-
cally to obtain the allocation context information for their li-
braries. The alternative is to instrument the dynamic loader
(ld.so) so that it can leave the information in which the li-
braries are loaded [23]. And we used synthesized inputs for
both applications. The inputs for model construction exer-
cise relevant functionalities of the applications, but do not
introduce memory leaks. On the other hand, the inputs for
testing the proposed technique periodically trigger execu-8201 p c r e f r e e ( l i s t ) ;
2 hctx = h a n d l e r c t x i n i t ( ) ;
3 con >plugi n ctx [ p >id ] = hctx ;
4i f( rule >once )
5 hctx >s t a t e = REWRITE STATE FINISHED;
6
7return HANDLER COMEBACK;
mod rewrite.c
Figure 10: lighttpd mod rewrite memory leak.
tion paths that cause memory leaks. All features described
in section 3 were used for the experiments.
4.4.1 lighttpd-1.4.19
lighttpd is a popular web-server that is optimized for low
memory footprint [2]. In version 1.4.19, lighttpd has a mem-
ory leak that can be triggered by a tricky conguration using
mod rewrite [3].
Figure 10 is the source code related to the memory leak.
At line 2, mod rewrite creates a memory object that stores
current context information. Reference to the temporary
context object is stored at line 3. However, this code re-
gion can be visited multiple times during a processing of a
request if url.rewrite-repeat rule intervenes. When visited
again, mod rewrite creates another context object that is re-
dundant at line 2, and overwrites reference to the old context
object by a reference to the newly created one. Since the
reference to the old context object is lost by the rewriting,
this results in a memory leak.
One plausible explanation why the developers failed to
see the leak inducing execution path is because mod rewrite
is a plug-in that is usually executed only once per service
request. So, the developers may have assumed that the life-
time of a handler context object is nished after processing
amod rewrite rule, and have also assumed that the object
will be deallocated with a connection object when the con-
nection is reset.
To catch the leaks, we ran lighttpd for about an hour, and
let it process random service requests during the time frame
for generation of training examples. Among the requests,
we included URLs that would be processed by mod rewrite .
However, no leak inducing URLs were given to lighttpd . So,
the heap activities observed contained only the expected op-
erations. On the other hand, we triggered the leak inducing
execution path during the testing run. Only 1 out of every
10000 requests contained a harmful URL.
Figure 12 is the accuracy achieved by the machine learning-
based detection framework. The accuracy measures are av-
erages (geometric means) of the metrics at 5 heap snapshots
that were taken after lighttpd had been run for a long enough
amount of time, i.e., longer than the trial run. The precision
is above 90% and almost perfect recall was achieved (with-
out using the time scaling, the precision drops by about
16%). Obviously, the machine learning-based memory leak
detection framework captured the developer's assumption
by learning that the lifetime of a handler context must be
short, and should not span multiple service requests. Group-
ing the reported objects by allocation context, and ranking
the allocation contexts revealed the problematic allocation
site (line 2) as the potential cause of the mismatch with the
trained model.1 t o f r e e = NULL;
2i f(i n p u t s t r i n g )
3f
4 t1 = i n p u t s t r i n g ;
5 t = get word from string (
6 &i n p u t s t r i n g , . . . ) ;
7 i f(i n p u t s t r i n g == 0)
8 t o f r e e = i n p u t s t r i n g = t ;
9 elsef
10 i n p u t s t r i n g =
11 s t r i p t r a i l i n g i f sw h i t e s p a c e (
12 t1 , . . . ) ;
13g
14g
15
16i f( saw escape )
17f
18 t = de q uote s tr ing (
19 i n p u t s t r i n g ) ;
20 var = b i n d r e a d v a r i a b l e ( . . . ) ;
21 x f r e e ( t ) ;
22g
23else
24 var = b i n d r e a d v a r i a b l e (
25 . . . , i n p u t s t r i n g ) ;
26 . . .
27 FREE ( t o f r e e ) ;
read.def
Figure 11: Bash read built-in memory leak.
4.4.2 Bash-4.0
Bash -4.0 has a memory leak in the read built-in when the
number of elds read from an input is not the same as the
number of variables passed as arguments to the built-in [1].
Figure 11 is the relevant part of the source code that binds
the last variable with the remaining input string. At line 5,
a temporary memory object is created inside getword from
string , and input string is advanced to the next character
in the original input string to check for the end. If the next
character is null, the reference to the temporary object is
stored in tofree (line 8), and the object gets deallocated at
line 27. However, if the next word is not null (line 9), the
temporary object tgets lost.
To model the staleness pattern of objects created at line 5,
we ran a Bash script that exercises the readbuilt-in by taking
synthesized inputs. The inputs for training were all well-
formed, and had matching number of elds as the number
ofreadvariables. Thus, no memory leak was observed during
the trial run. During the testing run, we supplied dierent
inputs to a Bash script. The inputs were crafted so that
5% of them contain more elds than the number of read
variables to trigger the execution path that causes memory
leaks.
Figure 12 is the accuracy of the machine learning-based
leak detection. The achieved precision is 93%, and the re-
call is 88% (without using the time scaling, the recall drops
by about 2%). Although the detection accuracy is high
enough, because the allocation site of the leaked object is in-
sidegetword from string , tracking down the cause involved
more labor. Manual inspection of the source code revealed82100.20.40.60.81
lighttpd-1.4.19 Bash-4.0Precision (higher is better)  
00.20.40.60.81
lighttpd-1.4.19 Bash-4.0Recall (higher is better)  Figure 12: Accuracy of the machine learning-based
memory leak detection on 2 real-world examples.
that among the 2 callers of getword from string , only the
part listed in gure 11 has a potential memory leak.
4.5 Limitations
One limiting factor of the machine learning-based memory
leak detection framework is the training time. During the
experiments, the longest training time took several days.
There are several unexplored solutions to this. The rst
one is to parallelize the learning algorithms [11, 17]. Ad-
ditionally, sampling training examples to reduce the size of
the training data is also a viable option. Lastly, instead of
the naive grid-search, a guided search through the space of
SVM parameters may be used to reduce the training time.
5. RELATED WORK
There is a large body of existing research addressing the
issue of memory leaks. Memory leaks are of two types: (1)
unreachable memory, i.e., references to the allocated objects
are lost, and (2) dead memory, i.e., it is reachable, but the
program will never use it again, thus it is not live. The
unreachable leaks can be eectively addressed by garbage
collection [5] and static analysis [18, 33, 27, 13, 24, 29] tech-
niques. However, the dead leaks are much trickier, since it is
in general undecidable to determine if certain memory will
not be accessed in the remainder of the program execution.
This diculty leads to the advent of those memory leak de-
tection tools based on dynamic analysis techniques [28, 8,
30, 35, 6, 7, 15, 9, 34, 25, 22].
Since our interest is in hard-to-detect memory leaks, we
limit our discussion to dynamic analysis techniques such as
staleness-based memory leak detection, that can detect both
types ( dead/live ) of memory leaks, conducted to date for
C/C++ programs. In particular, this section categorizes
the related works by the sampling method they leverage to
keep track of heap memory accesses without causing too
much overhead. All of the methods can be plugged into the
framework proposed in this work.
Path-Biased Code Sampling: Chilimbi and Hauswirth
were the rst to propose the staleness based leak detectionin their pioneering system called SWAT [14]. The staleness
update relies on code instrumentation of memory access in-
structions. To reduce the overhead, SWAT uses path-biased
sampling in tracking heap accesses. It samples each program
path at a dierent rate; the sampling rate is in inverse pro-
portion to the execution frequency. That way SWAT can
reduce the overhead, since instructions on a hot path rarely
get sampled. However, the sampling can result in overesti-
mating the staleness of the objects in hot paths, thus lead-
ing to false positives. Thus, the eort to reduce the runtime
overhead may end up undermining the quality of the leak
detection.
Page-Protection-Based Data Sampling: Novark et
al. present a system called Hound that removes the heavy-
weight instrumentation for the staleness updates using a
page-level sampling [26]. The basic idea is to employ a
memory protection mechanism of an OS kernel to detect the
accesses of the objects. Hound periodically protects every
page and updates the last access time of all objects on the
same page to the protection time. Once a page fault occurs,
Hound catches the signal and unprotects it for a performance
reason; here, Hound does not update the last access time of
all objects on that page until it gets protected again. That
is, actual staleness updates are always delayed to the pro-
tection time. The resulting staleness is underestimated and
this poses a risk of false negatives.
Another cause of false negatives is that Hound works at
the granularity of a page; it is possible that a page contains
both live and dead objects, and a single access to a live
object can cause a reset to the staleness of dead objects in
that page. To mitigate that, Hound changes the underlying
memory allocator to perform an age-based segregation of the
objects, which can end up degrading the performance of the
memory allocator. Nevertheless, the page-level false sharing
can still occur depending on memory allocation patterns.
A recent extension of Hound addresses the accuracy prob-
lem with context-aware data sampling that takes into ac-
count an allocation-call-path for the segregation of heap ob-
jects [25]. Here, heap objects are allocated in a dierent
page according to their allocation contexts, i.e., call path
to the malloc (new) . This approach has more potential to
get those objects with a similar access pattern allocated in
the same page than a naive allocation-site-based segrega-
tion. However, no accuracy results compared to Hound's
age-based segregation are presented in the paper.
ECC Protection Based Sampling: Qin et al. present
a dierent approach called SafeMem [28]. It rst groups
heap objects according to their size and the calling contexts
of the allocation site, and measures the lifetime of each ob-
ject. SafeMem relies on the observation that the maximal
lifetime of objects in the same group remains stable and is
thus anticipatable. The underlying assumption is that if the
lifetime of a certain object is much longer than the expected
lifetime of the group it belongs to, then the object is likely
to be a leak. To reduce false positives, SafeMem monitors
the access to such suspicious objects using an ECC memory
protection mechanism. I.e., the heap data is scrambled and
stored in the memory, and the rst access to data, which is
recognized by the ECC fault, leads to a conclusion that it is
not a leak.
However, such a method arrives at a premature conclusion
in that the object can end up with a leak even after multi-
ple accesses. To avoid the false negatives, SafeMem keeps822watching some objects even their rst access by having the
ECC fault handler update metadata such as the lifetime and
its maximum of the group. Whenever such objects become
suspicious, i.e., the lifetime is longer than some threshold,
the ECC monitoring is periodically enabled. Thus, SafeMem
compromises the memory reliability.
6. CONCLUSION AND FUTURE WORK
As seen from the Amazon example, memory leaks are still
a major source of program instability and service interrup-
tion. Unfortunately, detecting memory leaks remains a dif-
cult problem as memory leaks take a long time to mani-
fest, and often do so non-deterministically based on a racing
event.
To address the issue of detecting memory leaks, this paper
presents a machine learning-based framework that can be
used with previously developed staleness estimation meth-
ods. The proposed framework is built around an idea that
an object can be considered to have leaked if the object
shows high staleness not observed from other similar ob-
jects. To leverage this insight, the framework is intended to
be deployed during the testing phase of the development cy-
cle. From a representative run of an application, the frame-
work observes behavior of heap objects, and constructs a
model using machine learning. With this model, the pro-
posed framework replaces staleness predicates used in pre-
vious research with a model-based detection.
The model-based memory leak detection has 2 obvious
benets over the previous approach. First, as a trained
model is reective of observed behavior of heap objects, the
model is tailored for the target application. As such, the
model-based leak detection removes the error-prone user in-
tervention, and achieves the best possible results permitted
by a staleness-based approach. Second, the model-based
leak detection also improves the detection accuracy by lever-
aging more data, i.e., allocation context.
Although this work explored using object staleness as the
only primary input features, there are more aspects of pro-
gram execution that can be additionally modeled through
machine learning. One such dynamic behavior is coexistence
of memory objects. In many cases, lifetimes of objects are
usually linked together so that when a deallocation happens,
objects are destroyed in bulk, e.g., transactions. Incorporat-
ing such features has a potential of improving accuracy of
dynamic leak detection further.
7. ACKNOWLEDGMENTS
The authors would like to thank Christopher M. Porter,
Vincent Ni, Kaushik Ravichandran for proofreading the pa-
per. This work was supported by the National Science Foun-
dation under grants CNS-1320752 and CCF-1018544. Any
opinions, ndings, and conclusions or recommendations ex-
pressed in this material are those of the author(s) and do not
necessarily reect the views of the National Science Foun-
dation.
8. REFERENCES
[1] Bash patch report. http://ftp.gnu.org/gnu/bash/
bash-4.0-patches/bash40-033 .
[2] lighttpd - y light. http://www.lighttpd.net/ .
[3] lighttpd issue tracker.
http://redmine.lighttpd.net/issues/1775 .[4] D. A. Barrett and B. G. Zorn. Using lifetime
predictors to improve memory allocation performance.
InProceedings of the ACM SIGPLAN 1993
Conference on Programming Language Design and
Implementation , PLDI '93, pages 187{196, New York,
NY, USA, 1993. ACM.
[5] H. J. Boehm. Space ecient conservative garbage
collection. SIGPLAN Not. , 39:490{501, April 2004.
[6] M. Bond and K. McKinley. Tolerating memory leaks.
InProceedings of the 23rd ACM SIGPLAN OOPSLA .
ACM, 2008.
[7] M. D. Bond and K. McKinley. Leak pruning. In
Proceeding of the 14th ASPLOS , pages 277{288. ACM,
2009.
[8] M. D. Bond and K. S. McKinley. Bell: bit-encoding
online memory leak detection. In Proc. of the 12th
ASPLOS , New York, USA, 2006.
[9] D. Bruening and Q. Zhao. Practical memory checking
with dr. memory. In Proc. of the 9th CGO , pages
213{223, 2011.
[10] C. J. Burges. A tutorial on support vector machines
for pattern recognition. Data mining and knowledge
discovery , 2(2):121{167, 1998.
[11] B. Catanzaro, N. Sundaram, and K. Keutzer. Fast
support vector machine training and classication on
graphics processors. In Proceedings of the 25th
international conference on Machine learning , ICML
'08, pages 104{111, New York, NY, USA, 2008. ACM.
[12] C.-C. Chang and C.-J. Lin. LIBSVM: A library for
support vector machines. ACM Transactions on
Intelligent Systems and Technology , 2:27:1{27:27,
2011. Software available at
http://www.csie.ntu.edu.tw/~cjlin/libsvm .
[13] S. Cherem, L. Princehouse, and R. Rugina. Practical
memory leak detection using guarded value-ow
analysis. In Proc. of 28th PLDI'07 .
[14] T. M. Chilimbi and M. Hauswirth. Low-overhead
memory leak detection using adaptive statistical
proling. In Proc. of 11th ASPLOS'04 .
[15] J. Clause and A. Orso. Leakpoint: pinpointing the
causes of memory leaks. In Proc. of the 32nd ICSE ,
New York, NY, USA, 2010.
[16] C. Cortes and V. Vapnik. Support-vector networks.
Machine Learning , 20(3):273{297, 1995.
[17] H. P. Graf, E. Cosatto, L. Bottou, I. Dourdanovic, and
V. Vapnik. Parallel support vector machines: The
cascade svm. In Advances in neural information
processing systems , pages 521{528, 2004.
[18] D. L. Heine and M. S. Lam. A practical ow- and
context-sensitive c/c++ memory leak detector. In
Proc. of the 23rd PLDI , 2003.
[19] C.-W. Hsu, C.-C. Chang, and C.-J. Lin. A practical
guide to support vector classication, 2010.
[20] H. Inoue, D. Stefanovic, and S. Forrest. On the
prediction of java object lifetimes. Computers, IEEE
Transactions on , 55(7):880{892, July 2006.
[21] C. Jung and N. Clark. Ddt: design and evaluation of a
dynamic program analysis for optimizing data
structure usage. In MICRO 42: Proceedings of the
42nd Annual IEEE/ACM International Symposium on823Microarchitecture , pages 56{66, New York, NY, USA,
2009. ACM.
[22] C. Jung, S. Lee, E. Raman, and S. Pande. Automated
memory leak detection for production use. In
Proceedings of the 36th International Conference on
Software Engineering , 2014.
[23] C. Jung, D.-K. Woo, K. Kim, and S.-S. Lim.
Performance characterization of prelinking and
preloading for embedded systems. In Proceedings of
the 7th ACM & IEEE international conference on
Embedded software , EMSOFT '07, pages 213{220,
New York, NY, USA, 2007. ACM.
[24] Y. Jung and K. Yi. Practical memory leak detector
based on parameterized procedural summaries. In
Proc. of the 7th ISMM , 2008.
[25] W. Lim, S. Park, and H. Han. Memory leak detection
with context awareness. In Proceedings of the 2012
ACM Research in Applied Computation Symposium ,
RACS '12, pages 276{281, New York, NY, USA, 2012.
ACM.
[26] G. Novark, E. D. Berger, and B. G. Zorn. Eciently
and precisely locating memory leaks and bloat. In
Proc. of the 30th PLDI , 2009.
[27] M. Orlovich and R. Rugina. Memory leak analysis by
contradiction. In In Proceedings of the 13th
International Static Analysis Symposium , pages
405{424, 2006.
[28] F. Qin, S. Lu, and Y. Zhou. Safemem: Exploiting
ecc-memory for detecting memory leaks and memorycorruption during production runs. In Proc. of the
11th HPCA , 2005.
[29] Y. Sui, D. Ye, and J. Xue. Static memory leak
detection using full-sparse value-ow analysis. In
Proceedings of the 2012 International Symposium on
Software Testing and Analysis , ISSTA 2012, pages
254{264, New York, NY, USA, 2012. ACM.
[30] Y. Tang, Q. Gao, and F. Qin. Leaksurvivor: towards
safely tolerating memory leaks for garbage-collected
languages. In Proc. of USENIX 2008 Annual
Technical Conference .
[31] J. Whittaker. How to Break Software Security .
Addision Wesley.
[32] A. Williams. Amazon web services outage caused by
memory leak and failure in monitoring alarm.
http://techcrunch.com/2012/10/27/amazon-web-
services-outage-caused-by-memory-leak-and-
failure-in-monitoring-alarm/ , 10 2012.
[33] Y. Xie and A. Aiken. Context- and path-sensitive
memory leak detection. In Proc. of ESEC/FSE 2005 .
ACM Press, 2005.
[34] G. Xu, M. D. Bond, F. Qin, and A. Rountev.
Leakchaser: helping programmers narrow down causes
of memory leaks. In Proc. of the 32nd PLDI , 2011.
[35] G. Xu and A. Rountev. Precise memory leak detection
for java software using container proling. In Proc. of
the 30th ICSE , 2008.824