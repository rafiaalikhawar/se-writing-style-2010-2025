See discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/221554132
Using information fragments to answer the questions developers ask
Conf erence Paper    in  Proceedings - Int ernational Conf erence on Softw are Engineering  · May 2010
DOI: 10.1145/1806799.1806828  · Sour ce: DBLP
CITATIONS
159READS
1,255
2 author s:
Thomas F ritz
Univ ersity of Z urich
81 PUBLICA TIONS    3,153  CITATIONS    
SEE PROFILE
Gail Murphy
Univ ersity of British Columbia
197 PUBLICA TIONS    14,800  CITATIONS    
SEE PROFILE
All c ontent f ollo wing this p age was uplo aded b y Gail Murphy  on 04 June 2014.
The user has r equest ed enhanc ement of the do wnlo aded file.Using Information Fragments to Answer the Questions
Developers Ask
Thomas Fritz and Gail C. Murphy
Department of Computer Science
University of British Columbia
Vancouver, BC, Canada
{fritz,murphy}@cs.ubc.ca
ABSTRACT
Each day, a software developer needs to answer a variety of
questions that require the integration of di®erent kinds of
project information. Currently, answering these questions,
such as \What have my co-workers been doing?", is tedious,
and sometimes impossible, because the only support avail-
able requires the developer to manually link and traverse the
information step-by-step. Through interviews with eleven
professional developers, we identi¯ed 78 questions develop-
ers want to ask, but for which support is lacking. We intro-
duce an information fragment model (and prototype tool)
that automates the composition of di®erent kinds of infor-
mation and that allows developers to easily choose how to
display the composed information. In a study, 18 profes-
sional developers used the prototype tool to answer eight of
the 78 questions. All developers were able to easily use the
prototype to successfully answer 94% of questions in a mean
time of 2.3 minutes per question.
Categories and Subject Descriptors
D.2.6 [ Software Engineering ]: Programming Environments;
H.3.3 [ Information Storage and Retrieval ]: Information
Search and Retrieval
General Terms
Human Factors, Design
Keywords
Information fragments, Human-centric software engineering,
Programming tools
1. INTRODUCTION
A typical day of work requires a software developer to
answer a variety of questions (e.g., [9, 14]). Some of these
questions are easy to answer because they focus on one kind
of information and have little ambiguity. An example of one
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ICSE ’10, May 2-8 2010, Cape Town, South Africa
Copyright 2010 ACM 978-1-60558-719-6/10/05 ...$10.00.of these questions is \Where is this method called [...]?" [14],
which focuses on source code and typically has a well-de¯ned
meaning. Other questions are harder to answer because they
require integrating multiple kinds of information and can be
interpreted in many di®erent ways. An example of one of
these question is \What have my coworkers been doing?"[9].
Depending upon the developer asking the question, an an-
swer may involve only information from a revision system
to determine what code is changing or it may also involve
information from a bug repository to help explain why the
change is occurring.
From our own experience talking with developers, we be-
lieved that a number of the questions of interest are of the
second form. To investigate the range of questions that span
multiple kinds of information, we interviewed eleven profes-
sional software developers (Section 3), ¯nding 78 questions
of interest to them that have the characteristic of requiring
multiple kinds of information to answer. We also found that
even though many of these 78 questions sound similar, there
can be substantial variation in how a developer interprets a
question.
Although developers want to ask these questions, existing
approaches provide little support for answering them (Sec-
tion 2). Consider the question \What have my coworkers
been doing?". To answer this question, existing develop-
ment environments require a developer to explicitly follow
links that exist between pairs of the kinds of information
of interest; each kind of information is displayed in its own
view. Speci¯cally, a developer has to select select a bug
that describes ongoing work in one view, follow the link to
a set of changes that describe what work was done shown in
another view and then ¯nally bring up the changed source
code in a third view to know speci¯cally what work was con-
ducted. These steps must be iteratively performed for each
change set associated with the bug. By the time the devel-
oper follows all desired links, it is quite possible that he has
forgotten the question of interest! More importantly, only
one chain of linked information can be followed at a time;
if multiple chains are needed to answer the question, such
as the one we are considering that is oriented at multiple
members of a team, the burden is placed on the developer
to mentally and manually correlate the information reached.
An alternate solution is to provide a query language that
allows a developer to specify explicitly how the information
should be integrated (e.g., [12, 8]). The problem with this
solution is that the developer must know or learn the query
language and must express explicitly how the information
should be integrated. These approaches mean that the de-veloper needs to know about and express in the query how
the bug information maps to the change set information and
how the change set information maps to the source code.
We introduce a model that automates the integration of
di®erent kinds of project information by using the structure
of the information (Section 4). Our model has two advan-
tages. First, the integration of information, which we call
composition, is automated; as a result, a developer need only
indicate which information to integrate rather than how to
integrate it. Second, our model separates the composition
from the presentation of information. This separation allows
the developer to express a large variety of questions and to
tailor the composed information to his personal interpreta-
tion of the question at hand. Using our model, we have
been able to express all 78 questions determined through
the interview study.
Expressibility of a large set of questions is necessary to
make the model useful. To ensure the model can be applied
by developers, we implemented a prototype tool (Section 6)
and conducted a case study (Section 7) involving 18 profes-
sional developers. We found that without needing to know
the details of how the composition of the information occurs
in the model, the developers were able to easily use the pro-
totype to successfully answer 94% of eight questions posed
in a mean time of 2.3 minutes per question.
This paper makes three contributions.
²It presents 78 questions that developers ask; these ques-
tions reveal the range of interpretations developers de-
sire for compositions of project information.
²It introduces the information fragment model that sim-
pli¯es the answering of these 78 questions compared to
previous approaches.
²It demonstrates that the model can be easily used by
developers through a study with 18 professional devel-
opers.
2. RELATED WORK
A variety of approaches have been developed to help users
navigate through complex information spaces by following
information links. Feldspar allows a user to follow associ-
ation links between di®erent kinds of information, such as
emails and ¯les, to ¯nd information of interest [2]. Haystack
lets a user specify views for di®erent kinds of information,
but still requires the user to step manually across the views
to correlate information [13]. JQuery provides support spe-
ci¯c for software development, allowing a developer to step
through structural links between source code elements within
a single view, one at a time [7].
Other approaches to helping retrieve information support
the user in expressing, rather than following, information
links. These approaches involve a query language that re-
quires the user to explicitly form links between the infor-
mation. Some, such as the relational views by Linton [11]
and the approach by Paul and Prakash [12], are based on
a relational algebra. Others, such as CodeQuest [5] pro-
vide a logic-based query language. Kiefer and colleagues [8]
broaden the range of information that can be retrieved, cov-
ering source, revision and bug information, with the use of
the iSPARQL query language that is based on a ¯xed ontol-
ogy. All of these approaches require the user to express as
part of the query how the information links together.Alternatively, some systems have automatically linked dif-
ferent kinds of software development project information.
Hipikat uses a ¯xed schema to mine information from soft-
ware project repositories and provides a developer multiple
entry points into the created web of information [15]. The
STeP IN system extends Hipikat by including information
on programmers [16]. Deep Intellisense automatically dis-
plays information relevant to a selected source code element
such as change events and the people involved[6]. These
approaches are oriented at accessing one view of integrated
information. Hipikat, for instance, can recommend artifacts
related to a provided starting artifact. In contrast, our ap-
proach focuses on allowing the user to compose and view
di®erent kinds of project information to support the many
questions that arise during a work day.
Ferret by de Alwis and Murphy [3] supports the com-
position of di®erent perspectives|called spheres in their
approach|on similar information. For example, a sphere
representing source code can be composed with a sphere
representing dynamic information about the system to help
a developer investigate such properties as which calls be-
tween methods are actually occurring in a run of the sys-
tem. Their approach focuses on matching similar elements
between spheres whereas our approach aims to support the
composition of di®erent kinds of information for which links
can be automatically determined. Our model also supports
the user in varying the presentation of composed informa-
tion to enable a suitable interpretation for the task at hand.
The work presented in this paper augments and extends
concepts we presented earlier [4] with empirical evidence for
both the problem and the e®ectiveness of our approach and
by presenting details of the underlying model.
3. DEVELOPERS’ QUESTIONS
Earlier studies have considered questions developers ask
during a software development project. Four recent stud-
ies provide the most comprehensive question catalogs. Two
of these catalogs focus largely on questions about source
code. Sillito and colleagues described 44 questions that de-
velopers ask when programming [14]. De Alwis and Murphy
identi¯ed 36 questions from literature, blogs and their own
experience that deal largely with source code [3].
The other two studies discuss questions about a broader
set of software development activities. Ko and colleagues
report on 21 types of questions determined by shadowing
professional developers at work [9]. LaToza and colleagues
propose 19 problems from their own experience as software
developers and present the results of a survey of professional
developers about the seriousness of each problem. A num-
ber of these question types and problems require multiple
kinds of information to answer and have multiple possible
interpretations. Neither of these two studies talks about the
ambiguity that lies in the interpretation of questions such as
\What have my coworkers been doing?". While abstraction
helps in understanding the question space, it is the detailed
questions that the developer needs answered.
To determine the speci¯c questions developers need an-
swered that span di®erent kinds of information, we inter-
viewed eleven experienced software developers. We learned
about 78 questions that the developers face and about the
di®erences in the interpretation of very similar questions. To
ease presentation, we use the term domain in the remainderof the paper to refer to information of a particular kind, such
as the domain of bug reports or the domain of source code.
3.1 Subjects and Interview Process
We conducted open interviews with eleven professional
developers from three di®erent sites of one company. These
developers represented a spectrum of roles and experience.
The roles ranged from junior developer to team leads. The
experience of these developers ranged from 1 to 22 years.
In a pilot for this study, we asked developers directly about
questions requiring information from multiple domains that
occur for them during development. Through the pilot, we
found that the developers had di±culty understanding the
kinds of questions that might meet this criteria.
Thus, we changed the interview method to start with a
brief demonstration of a small tool we built that enabled
the composition of source code, change sets, work items1
and team information. Our intent in showing this prototype
was to stimulate developers to think about questions that
might arise when such composition is possible. We asked
the developer to describe such questions and how he would
want them answered. Throughout the interview, we adapted
our questions to the scenarios the developer described.
Each interview session was between 15 and 60 minutes de-
pending on the developer's availability and responsiveness.
Throughout each session, the interviewer (the ¯rst author
of this paper) took handwritten notes. We parsed our notes
looking for the questions developers stated, as well as the
meaning of the questions to the developers.
3.2 Interview Results
From the eleven interviews, we determined 78 questions
that span across multiple domains. Only one of the 78 ques-
tions was stated by two di®erent developers, the other 77
questions were stated by one developer each. For space rea-
sons, Table 1 lists 46 of the 78 questions.2These questions
span eight domains of information: source code (SC), change
sets (CHS), teams (T), work items (WI), web sites and wiki
pages (WW), comments on work items3(CO), exception
stack traces (ST) and test cases (TC). Table 1 shows which
domains, based on developer statements, are needed to an-
swer each question. For ease of reading, we have grouped
the questions into categories that roughly correspond to the
domains needed to answer the questions. Some questions
are annotated with a *, which denotes questions explicitly
stated by at least one developer. All other questions are
interpretations we have made as the interviewed developer
either gave a long statement to describe the scenario or more
context was needed to be able to state the question. The
majority of the questions (51 of the 78) are based on the
domains we presented in our demonstration at the start of
the interview; the remaining questions incorporate a domain
we did not present.
In our interviews, we focused on the variety and richness of
questions rather than their frequency. From the interviews,
we determined that some of these questions are looked at
a couple of times a day, such as \What classes have been
changed?"(21). On other questions, developers spend a lot
more time. One developer stated that he spends 70% of his
1Work items are similar to bugs, issues or tasks.
2http://www.cs.ubc.ca/labs/spl/projects/infofrags.html
3Based on the developers' statements, we considered emails
as being equivalent to comments.time on the question \Which conversations in work items
have I been mentioned?"(46) to make sure he does not block
other developers from working. Without an extensive ¯eld
study it is not possible to measure exactly how often each of
these questions arises throughout a work day or week, or how
much time a developer spends on each of these questions.
Some of the questions sound very similar in their word-
ing, but their answer di®ers depending on the individual
interpretation of the developer. For example, even though
the two questions \Who is working on what?"(1) and \What
have people been working on?"(6) seem very similar, the an-
swer to question (1) uses the four domains SC, CHS, T and
WI, whereas the answer to question (6) uses only the two
domains T and WI.
A lot of the questions also require the same domains to
be answered. However, the developers expressed wanting
the presentation of the answer in di®erent ways. \Who
is working on what?"(1) and \What classes has my team
been working on?"(11), both require information on SC,
CHS, T, and WI to lead to a meaningful answer. How-
ever, based on developers' statements, \Who is working on
what?" should display the team members ¯rst and the work
they have done below with the changed source code last,
whereas \What classes has my team been working on?", the
developer wanted to see the elements in the opposite order.
In Table 1, (1)-(4) and (8)-(13) are two blocks of such ques-
tions, where the questions require the same domains but
di®erent presentations.
A last subtlety comes with the selection of the actual in-
formation. Similar questions often just di®er in small details
of the information of relevance. However, this di®erence in-
°uences the size of the result and the ease of interpreting
it. For example, \What has changed between two builds
and who has changed it?"(14) as well as \Who has made
changes to my classes?"(15) require information from the
same domains. The latter question is however only looking
for classes the developer is working on, whereas the ¯rst (14)
refers to all classes of the project.
3.3 Threats
Because of di±culties we had getting subjects to articulate
questions involving multiple domains, in this study, we stim-
ulated developers to think about such questions by demon-
strating a very early version of the tool we subjected to later
testing (Section 6). This demonstration may have biased
developers to state questions answerable with our approach.
We believe this threat to validity is small as other researchers
have found similar questions (e.g., [9, 10]), adding credence
to these being questions developers ask when working. The
list of questions we present is partial and is not represen-
tative of all multi-domain questions a developer may ask.
4. INFORMATION FRAGMENT MODEL
To enable a developer to answer the wide range of ques-
tions that can arise, we introduce a model that supports the
composition and presentation of information fragments.
4.1 Example of Use
We introduce our model by showing how it can be used
to answer the question, \What have people been working
on?"(Question 6 in Table 1). We use a simpli¯ed version of
this example to present our approach succinctly.Table 1: Developers' Questions and the Operators and Domains for Desired Answers (* :question explicitly
stated by a developer; id:identifier matching; t:text matching )
Question
Operator
Source Code
Change Sets
Teams
Work Items
Comments
Web/Wiki
Stack Traces
Test Cases
Who is working on what (people speci¯c)
1. Who is working on what?¤idXX X X
2. What are they [coworkers] working on right now?¤idXX X X
3. How much work [have] people done?¤idXX X X
4. Who changed this [code], focused on person?¤idXX X X
5. Who to assign a code review to? / Who has the knowledge to do the code review? idXX X X
6. What have people been working on?¤id XX
7. Which code reviews have been assigned to which person?¤id XX
Changes to the code (code speci¯c)
8. What is the evolution of the code? idXX X X
9. Why were they [these changes] introduced?¤idXX X X
10. Who made a particular change and why? idXX X X
11. What classes has my team been working on?¤idXX X X
12. What are the changes on newly resolved work items related to me? idXX X X
13. Who is working on the same classes as I am and for which work item? idXX X X
14. What has changed between two builds [and] who has changed it?¤idXX X
15. Who has made changes to my classes? idXX X
16. Who is using that API [that I am about to change]?¤idXX X
17. Who created the API [that I am about to change]?¤idXX X
18. Who owns this piece of code? / Who modi¯ed it the latest?¤idXX X
19. Who owns this piece of code? / Who modi¯ed it most?¤idXX X
20. Who to talk to if you have to work with packages you haven't worked with? idXX X
21. What classes have been changed?¤idXX
22. [Which] API has changed (to see which methods are not supported any more)?¤idXX
23. What's the most popular class? [Which class has been changed most?]¤idXX
24. Which other code that I worked on uses this code pattern / utility function? idXX
25. Which code has recently changed that is related to me? idXX
26. How do recently delivered changes a®ect changes that I am working on?¤idXX
27. What code is related to a change? idXX
Work item progress
28. What is the recent activity on a plan item? id X X
29. Which features and functions have been changing?¤id X X
30. Has progress been made on blockers (blocking work items) in your milestone? id X X
31. Is progress (changes) being made on plan items? id X X
Broken builds
32. What caused this build to break? (Which change caused the stack trace?) idXX X
33. Who caused this build to break? (Who owns the broken tests?) idXX X X
34. Who changed the test case most recently that caused the build to fail? idXX X X
35. Which changes caused the tests to fail and thus the build to break? idXX XX
Test cases
36. Who owns a test case? (Who resolved the last work item that ¯xed the test case?) idXX X X X
37. How do test cases relate to packages/classes? idX X
References on the web
38. Which API has changed (check on web site)? tX X
39. [Is an entry] in newsgroup forum addressed to me because of the class mentioned?¤tX X
40. What is coming up next week [for my team]? [What is my team doing?]¤t X X
41. What am I supposed to work on [plan on wiki]?¤t X X
Other Questions
42. How is the team organized?¤idXX X
43. Who has made changes to [a] defect?¤id X X X
44. Who has made comments in defect?¤id XX X
45. [What is] the collaboration tree around a feature?¤id XX X
46. Which conversations in work items have I been mentioned?¤t,id XX XJulie
id: Julie
David 
id: David 
Allen 
id: Allen 
D 303: Popup can not be cancelled 
id:              303
Creator:    Paul
owner:      David WI 315: Can’t cancel prompt
id:              315
creator:    Julie
owner:      David 
WI 317: Empty entries in history
id:              317
Creator:    Steve
owner:      PaulWI 316: Create reusable ac/g415ons 
id:              316
creator:    Julie
owner:      Julieduplicate of Julie
David 
Allen WI 316 
D 315 
D 303 
WI 317 duplicate of 
ownerowner creator creator , 
owner 
(a) Team Fragment 
(b) Work Item Fragment 
(WI = work item, D = defect)(c) Composed Fragment (d) Fragment Presentation (T-WI) 
(e) Fragment Presentation (WI-T) 
Figure 1: Approach to Answer the Question \What have people been working on?"
Consider a software developer Sue who gets back to work
after a week of holidays. When she starts working, she
wants to know what other developers have been working on
while she was away. For this question, Sue is interested in
two di®erent information domains: teams and work items.
From these two domains, Sue is interested in certain sub-
sets, which we refer to as information fragments . One in-
formation fragment consists of the developers of her team
(Figure 1(a)), and the second consists of the work items on
which people have been working (Figure 1(b)). In our ap-
proach, information fragments are modeled as graphs with
nodes and edges. Nodes represent uniquely identi¯able items
with properties; at least one property is speci¯ed as a unique
identi¯er. For example, a work item includes an identi¯er,
a creator and an owner property. Edges represent relation-
ships between items, such as a \duplicate-of" relationship
between two work items, stating that a work item is a du-
plicate of another work item.
Each fragment in isolation is not meaningful to Sue. How-
ever, by composing these two fragments, Sue can create the
context that allows her to answer the question at hand.
Our approach provides composition operators to compose
information fragments. When Sue composes the two in-
formation fragments using ­ida new information fragment
(Figure 1(c)) is created from the input fragments with new
edges introduced between nodes based on the nodes' prop-
erties. For example, in the new information fragment, a new
\owner" edge is created between David and the defect 303,
because the owner property of the node representing defect
303 matches the identi¯er of the node representing David.
Another edge is created between Julie and work item 316
because Julie is the owner and creator of 316.
As the answer to her question, Sue likes to see the work
items ordered by developers. Therefore, she chooses a pre-
sentation that orders nodes of the team fragment ( t) above
the ones from the work item fragment ( wi); this presenta-
tion is referred to as a projection ( Á(t; wi)). Figure 1(d)
shows the result of this projection. In this presentation, her
teammate Allen does not show up in the ¯nal presentations
as he did not work on, and is thus not connected to, any
work item.Alternatively, Sue might be interested in seeing her team
members in context of the work items on which they have
been working. In this case, she would use a projection
Á(wi; t). This projection shows the work items her fellow
team members have been working on ¯rst and the develop-
ers below (Figure 1(e)). By separating the presentation from
the composition of the information, either interpretation of
the question is easily supported.
4.2 Information Fragments
An information fragment is a subset of development in-
formation for the system of interest. In our model, an infor-
mation fragment is modeled as a graph F= (V; E; l F), with
a set of labeled nodes V, a set of directed labeled edges E
and a function lF:V7!FSthat assigns each node a set of
information fragments FS.
Each node represents a uniquely identi¯able item of infor-
mation, such as defect 303 or team member Julie. Each node
also has a type, such as defect, work item or team member,
and, based on the type, a set of properties that describe the
node. Finally, each node belongs to a domain , such as work
items or teams, where a domain is a set of types with type
sets of di®erent domains being disjoint. At present, each
type of a domain has the same properties. An exemplary
list of domains, types and properties, is given in Table 2; for
instance, a defect of the work item domain has an identi-
¯er and information on the creator and owner of the defect,
among others.
Edges represent relationships between these uniquely iden-
ti¯able items. An edge can be explicit, such as a method call,
or implicit, such as a relationship between a work item and
a team member that can be inferred from the nodes. An
edge can also contain properties that describe the edge; for
instance, an edge based on textual similarity between two
work items can have the amount of similarity of the two
nodes as a property.
A base fragment is a special case of an information frag-
ment that contains nodes of one domain only. The fragments
in Figure 1(a) and (b) are each a base fragment. In this case,
the function lFmaps each node to the base fragment itself
(lF:v7! fFg). Other information fragments are compo-Table 2: Sample Node Domains, Types & Properties
Domain Types Properties
source code (SC) class,
method,
¯eldidenti¯er (id), referenced
elements
work items (WI) defect,
work item,
plan itemid, creator, owner, linked
change sets, linked com-
ments
change sets (CHS) change set id, author, changed ele-
ments
teams (T) team, team
memberid, name
comments (CO) comment id, text, author
web/wiki (WW) web page id, text, last updated
sitions of several base fragments. In this case, the function
lFmaps each node to the set of base fragments it is part
of (lF:v7! fF1; :::; F ngwith Fi= (Vi; Ei)andv2Vifor
i= 1; ::n).
4.3 Composition Operators
Formally, a composition operator ­:F1£F27!F0
takes two information fragments F1= (V1; E1; lF1)andF2=
(V2; E2; lF2)and creates a new information fragment F0=
(V0; E0; lF0). The new information fragment consists of the
union of nodes ( V0=V1[V2).lF0maps each node vto the
union of lF1(v)andlF2(v).E0is the union of E1andE2and
a set of newly created directed, labeled edges E¤between
two nodes, one from V1and one from V2. The creation of
new edges is based on node properties and is unique to the
speci¯c composition operator being used. Each composition
operator is commutative. Thus, the order of the input frag-
ments does not matter. This constraint is important for the
separation of composition and presentation.
Based on the questions derived from the interviews, we
determined that only two generic composition operators are
needed to support answering the questions: an identi¯er
matching and a text based matching composition operator.
ID Matching.
This composition operator, denoted by ­id, creates a new
edge when the identi¯er property (id) of one node exactly
matches a property of another node. For example, the id
of a team member node matches the creator property of a
work item node. The label of the newly created edge is
determined by the name of the property that is not the id.
In our example, the newly created edge between the team
member and the defect is labeled creator.
Text Matching.
The text matching operator, denoted by ­t, creates new
edges when there is a textual match between the identi¯er
property of one node with a textual property in another
node. The similarity of the identi¯er on the one side and
the textual match on the other side can be based on some
text matching measure and a threshold for similarity can be
used. Consider a team member and a comment node. If the
identi¯er property of the team member has a textual match
in the text property of the comment with a high enoughsimilarity, a new edge will be created. This new edge be-
tween the team member and the comment has properties
that describe the match, such as the similarity value and
the location of the match in the comment.
4.4 Presentation
Our interviews identi¯ed variations in the ways develop-
ers would like a composed information fragment to be pre-
sented. To support this variety, our approach provides a pro-
jection function that transforms an information fragment (a
graph) into a set of trees. Speci¯cally, given an information
fragment F= (V; E; l F)composed of base fragments at the
lowest level, and an ordering (bf1; :::; bf n)of these base frag-
ments, a projection denoted by Á(bf1;:::;bf n)creates a set of
trees, TS. All tree roots are nodes of base fragment bf1for
which a path to nodes of base fragment bfnexists, so that
the nodes on the path follow the given order. Formally, for
each path (v1; :::; v n)through a created tree T= (VT; ET)
with T2TS,VTµVandETµEthe following holds:
vi2VTfori= 1; :::; n ,(vi; vi+1)2ETfori= 1; :::; n¡1,
bfi2lF(vi)fori= 1; :::; n¡1and there is no other tree
T¤2TSthat contains the path. In our example, Á(t;wi)
creates two trees (shown in Figure 1(d)) that represent all
possible paths of length two from a node of the team frag-
ment to a node of the work item fragment.
Sometimes, a developer needs to count nodes on a partic-
ular level in the presentation for a summary. For instance,
several questions are about the relative occurrences of com-
posed information, such as \What's the most popular class"
(Question 23 in Table 1). Therefore, our model provides a
counting function, denoted by ¾(levelOf (bf)), that counts all
nodes on the level of a base fragment bfin the set of trees.
For example, to ¯nd out how many work items each team
member worked on in our example, a developer can count
the nodes of the team fragment level ( ¾(levelOf (t))) in Fig-
ure 1(e). This tells him that Julie and David each occur
twice in the trees and thus worked on two work items. For
simplicity, we shortly denote the counting function as ¾(bf).
5. APPLYING THE MODEL
We have applied our model to answer the 78 questions
determined by interviewing developers. Table 1 shows the
domains and composition operators needed to answer each
question as it was intended by the developers who stated
the question. Space does not allow us to show the use of the
model to answer each question. Instead, we focus on showing
how the model can be used to answer 5 of the 78 questions
selected to present di®erent properties of the model.
What have people been working on? (6).
As an answer, the developer who stated this question
wanted to see the list of his team members with work items
on which they have been active beneath the relevant team
member. Applying our model, we ¯rst need access to the
information fragments of interest:
T1the team members of the developer,
WI1work items resolved recently and in progress.
We then apply the composition operator that matches iden-
ti¯ers ( ­id). The composition of these fragments can be
expressed as
T1­idWI1.As the composition is commutative, the order in which the
composition takes place does not matter.
To display the composed information as desired by the
developer we apply a suitable projection (i.e., team ¯rst and
then work items)
Á(T1;WI1).
Overall, the answer to the question is
Á(T1;WI1)(T1­idWI1).
Who is working on what? (1).
This question is similar to the one above, but the devel-
oper who stated it, wanted to also see the changes made to
the code. The additional information fragments are:
CHS 1change sets recently delivered,
SC1source code of the project.
To reach the answer with our model, we use:
Á(T1;WI1;CHS 1;SC1)(SC1­idCHS 1­idWI1­idT1).
What classes has my team been working on? (11).
Answering this question requires the same information
fragments as question (1). However, the developer's focus
for this question was on the code and he wanted to see the
work items and team members in the context of his current
project. Compared to question (1), the answer di®ers only
in the order of the projection:
Á(SC1;CHS 1;WI1;T1)(SC1­idCHS 1­idWI1­idT1).
Who owns/modiﬁed this piece of code most? (19).
Answering this question requires three information frag-
ments:
T2all team members on the project,
CHS 2all change sets for the last couple of months, and
SC2source code of interest.
To ¯nd out who made most changes over the last couple of
months, the composed information is projected and then the
occurrences of the team members are counted:
¾(T2)(Á(SC2;CHS 2;T2)(T2­idCHS 2­idSC2)).
Which conversations in work items have I been men-
tioned? (46).
The developer wanted to see the comments he is men-
tioned in ordered by work items.
T3the developer,
CO3comments recently created,
WI3work items of interest.
As textual matches of the developer in the comments are
of interest, the team fragment is composed using the text
matching composition operator ( ­t). Overall, with work
items ¯rst and comments second, this results in:
Á(WI3;CO3;T3)(T3­tCO3­idWI3).
6. PROTOTYPE
We have implemented a prototype that supports our model.
Our prototype extends the IBM Rational Team Concert
(RTC)4, a team collaboration platform on top of the Eclipse
IDE5.
4jazz.net , veri¯ed 03/09/09
5www.eclipse.org , veri¯ed 03/09/096.1 Information Fragments
Our prototype supports four domains of information: work
items, source code (Java packages, classes, methods and
¯elds), change sets and teams (teams and team members).
We enhanced existing views for these four domains in RTC
to support the creation of an information fragment from ele-
ments selected in the view. We did not use this functionality
in the evaluation we performed (Section 7); the next phase
of our research will focus on better support for selecting
fragments.
6.2 Composition
With the prototype, a developer can compose information
fragments by adding them to the composed viewer . Fig-
ure 2(a) shows the answer to \Who is working on what?"
(Question 1 in Table 1) in the composed viewer. The answer
was created by adding the team, work item, change set and
source code fragments described in Section 5 to the viewer.
The composition operator is applied automatically when in-
formation is placed into the composed viewer. Currently,
the prototype supports only the identi¯er matching compo-
sition operator. As discussed in Section 8, the text matching
composition operator can also be applied automatically.
6.3 Presentation
The prototype supports projection and counting of our
model as well as a feature for hiding certain information.
Figure 2(a) displays the answer to\Who is working on what?"
as described in Section 5. The projection order of the base
fragments is represented by the icons in the fragment bar
in the upper right corner of the view (see the highlighted
rectangle in Figure 2(a)). If the developer is interested in
a code-centric interpretation of the same question, he only
has to change the order of the original base fragments by
dragging and dropping the icons in the fragment bar into
the appropriate order. This changes the projection; the un-
derlying composed information fragment does not change.
The resulting view is shown in Figure 2(b).
Answering a question such as which of the team mem-
bers made most changes requires a count. A developer can
perform this count using the drop down menu of the teams
icon in the fragment bar. The count functionality counts the
occurrences of nodes of a particular base fragment, in this
case the team fragment, presented in the view. The devel-
oper can also count the children of a speci¯c element. For
example, he can count the team members that changed a
speci¯c Java package by right-clicking on the Java package
in the view and selecting the \Count Team Members" action
in the context menu.
As an additional feature for eliding information in the
view, the prototype supports a hide action that allows the
developer to hide nodes of a certain level. This functionality
is again accessible through the drop down menus of each icon
in the fragment bar.
With the above mentioned functionality our prototype
supports 51 of the 78 questions mentioned in Section 3.
7. EV ALUATION
To be useful, a developer must be able to easily apply
the information fragment model to answer questions of in-
terest about the software development. We considered two
research questions to gain evidence about this statement:(a) \Who is working on what?"
 (b) Code Centric Presentation
 (c) Base Fragments
Figure 2: Views of the Prototype
(1)Can developers use the information fragment model to
answer questions that previous developers have posed?
(2)Can developers use the model e®ectively without requir-
ing a detailed understanding of how the model works?
We conducted a study in which 18 developers used our pro-
totype tool that supports the model to answer eight ques-
tions selected from those described in Table 1. Our study
setup was an embedded, multiple-case, replication design.
We chose not to perform a comparative study as the only
available approach is to follow links in a development envi-
ronment, an obviously time-consuming approach.
7.1 Subjects
We originally recruited 21 developers from two di®erent
locations of a multi-national company and four di®erent
teams. Seven of these 21 developers also participated in the
earlier interviews. To be eligible to participate in the study,
a developer had to use the RTC client in his daily work. To
solicit participation, we randomly asked people at the two
locations. We report on 18 of the participants: ten from one
location (S1-S10) and eight from the other (T1-T8). The
remaining three individuals had di±culty with the exper-
imental situation. The roles of the 18 developers ranged
from junior developer to team lead and also included one
student. The professional experience ranged from 7 months
to 23 years. Three of the developers (T6,T7,T8) had never
used the source control mechanism in our study before.
7.2 Study Method
We selected a set of eight questions (Q1-Q8) from the
78 original questions for our study. We chose these eight to
cover domains of interest as can be seen from the correspond-
ing questions in Table 1 (second column in Table 3 shows
the number of the original question). Each question was
made more speci¯c for two reasons: 1) to reduce the range
of interpretations of the questions so that we could compare
the approaches of participants to answering the questions
and 2) to match the data available in our study setup. For
example, we adapted the question
(11) \What classes has my team been working
on?"to
(Q5) Yesterday, on which classes (of the SCM
code) have Alex and Allen on the SCM team been
working on and why? For each developer, name
one class and the reason for the change.
These changes to the question re°ect the desire of the de-
veloper stating question 11 to see the reason for the changes
in terms of work items and re°ect the speci¯cation of the
scope of the team, code and timespan of interest.
We narrowed Q5 to ask about one class for each developer
to allow us to determine when a participant's given answer
was correct. For Q5, we considered an answer correct if the
participant mentioned, for each of Alex and Allen, a class
which the respective developer changed yesterday and the
work item requiring that change.
The version of the prototype used in the study was adapted
with a view to show ten prede¯ned base fragments, such as
\all SCM source code" or \work items worked on yesterday"
(see Figure 2(c)). We prede¯ned these base fragments to
focus the study on the core parts of the model: the com-
position and projection of information fragments. The data
used for these base fragments was prepared from the history
of the RTC development from a year ago, with developer
names changed.
At the start of each study session, a participant worked
through a 10-15 minute, two-page tutorial about the proto-
type's features: composition, reordering, counting and hid-
ing. The examples used in this tutorial were straightforward,
such as relying on the well-known fact that change sets con-
tain links to their authors and, as a result, can be composed
with team information. After ¯nishing the tutorial, a par-
ticipant was given time to read the eight questions (Q1-Q8)
and ask clari¯cation questions. A participant had the choice
to answer these eight questions in whichever order he pre-
ferred, but was told that the questions were ordered from
easier to more di±cult ones.
Participants were then given time to work on the ques-
tions. If a participant spent ¯ve minutes on a question and
was still not close to an answer we provided a hint. This
situation only occurred for Q5 and Q8. For Q5, two partic-
ipants required a hint about ordering; one participant who
had not used the source control system needed a hint aboutTable 3: Developer's Results
Question Time (in minutes) and Success per Question for each Developer
(orig. dev.
question)X= success,¥= failure, ?= hint given
S1 S2 S3 S4 S5 S6 S7 S8 S9 S10 T1 T2 T3 T4 T5 T6 T7 T8 Mean
Q1 (21) 1:1X0:7X2:2X1:8X1:9X1:1X3:2X1:4X1:1X0:6X1:1X0:6X1:5X1:9X0:6X2:6X5:7X1:1X1:7
Q2 (15) 2:9X0:6X1:0X2:1X1:2X1:7X2:1X0:7X1:3X0:8X5:1X0:7X1:6X2:5X0:5X2:5X3:9X4:9X2:0
Q3 (14) 2:0X1:5X2:2X2:1X1:3X5:9X1:0X3:0X2:3X1:5X0:9X1:7X4:0X1:9X1:0X1:5X6:6X5:4X2:5
Q4 (6) 1:1X0:8X0:6X0:4X0:8X0:7X0:8X1:0X1:3X1:0X0:8X0:8X1:7X2:1X1:0X1:7X1:3X0:4X1:0
Q5 (11) 1:5X5:6X3:4X4:2?6:1X3:3X5:8X1:8X5:0X1:7X7:2X6:8?7:2X5:5X2:8X7:0X6:5?1:4X4:4
Q6 (23) 1:0X0:8X0:9X0:7X0:7X1:8X3:0X0:6X5:0X1:2X1:7X0:6X2:9X1:6X0:8X1:5X1:6X3:5X1:7
Q7 (19) 2:7X2:6X3:2X2:6X4:9X3:4X1:3X1:5X2:2X2:0X2:3X3:5X2:9X2:5X1:8X5:2X1:9X1:6X2:7
Q8 (26) 1:7X2:1X4:3X3:1X{¥5:3X8:1?1:2X3:3X2:0X6:5?{¥5:4X5:3X2:6X7:8?{¥2:7X3:3
Mean 1:81:82:21:82:42:92:51:42:71:32:71:33:42:91:43:13:52:62:3
work items containing links to change sets. Six participants
for Q8 were given a hint about what the question meant. If
a participant was not done with a question after ten minutes
we stopped him and asked him to move to another question.
After a participant ¯nished all eight questions, we inter-
viewed the participant about the experience of using the
tool.
7.3 Data Analysis
For each participant, we captured screen videos as the
participant worked and took written notes. From our notes,
we determined, for each question, the worst case time that
it took the participant to get to the correct answer based
on our interpretation of correctness. Only for Q5 was there
a distinct di®erence between our notion of correctness and
the participant's notion of correctness. For Q5, eight par-
ticipants (S3,S6,S7,S10,T3,T4,T6,T8) interpreted the reason
for a change as the one-line description of the change set, and
did not consider work items. When directed by the exper-
imenter to consider work items, the participants continued
working on the question, taking, on average, an extra three
minutes to get to the correct answer. We used only these
worst case times for our analysis.
We used the video to analyze the interaction of a partici-
pant with the features of the tool.
7.4 Results
To evaluate our ¯rst research question\Can developers use
the information fragment model to answer questions that
previous developers have posed?", we consider how many
of the eight questions participants were able to answer cor-
rectly. If our model is usable, we expect participants to
succeed in answering most questions within the ten minutes
time limit. For our model to improve on a query approach,
participants should succeed in answering most questions in
¯ve minutes as studies of SQL have shown that users, af-
ter substantial training (1.5 hours), can write queries that
join elements from two domains in a mean time of 5.1 min-
utes citecsw97a.
Table 3 shows, for each question in the study, the time
and success per developer, the mean time needed for each
question in the last column and the mean time per question
for each developer in the bottom-most row. The data in the
table shows that in 135 of the 144 cases (94%), participants
answered the questions successfully without any hint andwith a mean of 2.3 minutes per question; in computing the
mean, we did not include cases (shown in italics in Table 3)
in which a hint was given or the ten minutes time limit was
exceeded. We consider that this data shows strong support
for the usefulness of our model.
In only 23 cases (16%), participants required more than
¯ve minutes to answer the question and a hint was given in
six cases. In one case (S4), a hint was given before the 5
minutes as the subject was under time pressure. Two of the
three subjects (T6-T8) that did not have any prior knowl-
edge of the source control mechanism in use had the highest
mean time for answering a question. However, even these
participants successfully completed almost all questions with
a mean time of less than ¯ve minutes per question. These
results support the statement that developers can use the
information fragment model to answer questions they face.
To evaluate our second research question \Can developers
use the model e®ectively without requiring a detailed under-
standing of how the model works?", we consider how much
information we needed to provide a participant while work-
ing on a question and how a participant used the model to
answer questions. In terms of information provided to par-
ticipants, we gave participants only ten to ¯fteen minutes
of training on the model; in comparison, in a study of SQL,
Chan and colleagues trained participants for an hour and a
half [1]. Despite this low amount of training, for 135 cases
(94%) this training was su±cient for the participants to use
the model to answer questions correctly. In only 9 cases
(6%), an additional hint was given by the experimenter.
Considered alongside a mean time of only 2.3 minutes per
question for successful answers, this data provides support
for the statement that our model can be used e®ectively
without understanding the details of the model.
We also considered how a participant used the model
to answer questions. By analyzing the screen captures of
the participants working, we found that the participants
reordered the information shown in the composition view
more often (277 times) than the participants restarted the
composition (213 times). Participants stated in follow-up
interviews that the ability to change the projection of the
composition through reordering was \de¯nitely helpful" as
\you can really do it in two steps"(S10), that \I throw every-
thing in it [the view], reorder it [...] and see if it seems rea-
sonable"(S2), and even that it was \great" (T8). The higher
number of reorderings compared to restarts and commentsof the participants provide further evidence that the par-
ticipants understood enough features of the model to use it
e®ectively without extensive training.
When asked explicitly, all developers stated that, if avail-
able, they can imagine and would use the prototype. Some
developers even stated without us asking that it was \pretty
nifty"(S4),\pretty cool"(S3),\cool"(S7,S6), a\neat tool"(T2),
\really really cool"(T8) and that \it is answering questions
that I don't think we can answer right now"(T1).
7.5 Threats
We prede¯ned the information fragments available for use
in the study. As these information fragments were tailored
towards the questions asked, participants may have had to
spend less time than otherwise to answer a question of in-
terest. On the other hand, these prede¯ned fragments also
made it more di±cult for a participant to restrict the infor-
mation shown to what he desired seeing.
8. DISCUSSION
Automatic Composition.
Our prototype supports the answering of 51 of the 78 ques-
tions with the use of only the id matching operator. Since
our study used eight of these 51 questions, a developer did
not have to specify an operator, rather it was chosen auto-
matically. For the 27 remaining questions that also involve
the text matching operator, it can be shown that the compo-
sition operator can again be chosen automatically. Whether
or not future operators that are added for additional ques-
tions can also be chosen automatically is an open question.
Information Fragment Selection.
We have focused our attention to date on the composi-
tion and presentation of information fragments, using sim-
ple mechanisms or pre-de¯ned fragments in the prototype
tool we have developed. A future research question is how
best to support a developer in selecting fragments of inter-
est. It may be that it is possible to prede¯ne fragments for
such a large number of questions to make sophisticated se-
lection mechanisms unnecessary. We leave this investigation
to future work.
9. CONCLUSION
Software development involves working with many di®er-
ent kinds of artifacts and coordinating work with others.
These activities lead to questions about the development
that span multiple sources of information, such as bug re-
ports, source code, team membership and others. In this
paper, we have introduced the information fragment model
that supports the composition of information from multiple
sources and that supports the presentation of composed in-
formation in °exible ways. We have shown that this model
can support 78 questions software developers want to ask
about a development project and that, for these questions,
the composition can be chosen automatically by a tool sup-
porting the model. Finally, we have demonstrated that 18
professionals, with minimal training, were able to use the
model, as supported by the prototype tool, easily and e®ec-
tively.10. ACKNOWLEDGMENTS
Thanks to Annie Ying and Emerson Murphy-Hill for help-
ful comments. This work was supported in part by IBM and
in part by NSERC. We thank all the developers who partic-
ipated in the interviews and case study.
11. REFERENCES
[1]H. Chan, K. Siau, and K.-K. Wei. The e®ect of data
model, system and task characteristics on user query
performance: an empirical study. SIGMIS Database ,
pages 31{49, 1997.
[2]D. H. Chau, B. Myers, and A. Faulring. What to do
when search fails: ¯nding information by association.
InProc. of CHI '08 , pages 999{1008, 2008.
[3]B. de Alwis and G. C. Murphy. Answering conceptual
queries with ferret. In Proc. of ICSE'08 , pages 21{30,
2008.
[4]T. Fritz and G. C. Murphy. Search, stitch, view:
Easing information integration in an IDE. In
SUITE'09 , pages 9{12, 2009.
[5]E. Hajiyev, M. Verbaere, and O. de Moor. Codequest:
Scalable source code queries with datalog. In Proc. of
ECOOP'06 , pages 2{27, 2006.
[6]R. Holmes and A. Begel. Deep intellisense: a tool for
rehydrating evaporated information. In Proc. of
MSR'08 , pages 23{26, 2008.
[7]D. Janzen and K. D. Volder. Navigating and querying
code without getting lost. In Proc. of AOSD'03 , pages
178{187, 2003.
[8]C. Kiefer, A. Bernstein, and J. Tappolet. Mining
software repositories with isparql and a software
evolution ontology. In ICSEW '07 , page 10, 2007.
[9]A. J. Ko, R. DeLine, and G. Venolia. Information
needs in collocated software development teams. In
Proc. of ICSE'07 , pages 344{353, 2007.
[10]T. D. LaToza, G. Venolia, and R. DeLine. Maintaining
mental models: a study of developer work habits. In
Proc. of ICSE'06 , pages 492{501, 2006.
[11]M. A. Linton. Implementing relational views of
programs. In Proc. of SDE 1 , pages 132{140, 1984.
[12]S. Paul and A. Prakash. A query algebra for program
databases. IEEE Trans. Softw. Eng. , pages 202{217,
1996.
[13]D. Quan, D. Huynh, and D. R. Karger. Haystack: A
platform for authoring end user semantic web
applications. In Proc. of ISWC'03 , pages 738{753,
2003.
[14]J. Sillito, G. C. Murphy, and K. D. Volder. Questions
programmers ask during software evolution tasks. In
Proc. of FSE'06 , pages 23{34, 2006.
[15]D.·Cubrani¶ c, G. C. Murphy, J. Singer, and K. S.
Booth. Hipikat: A project memory for software
development. IEEE Trans. Softw. Eng. , pages
446{465, 2005.
[16]Y. Ye, Y. Yamamoto, and K. Nakakoji. A
socio-technical framework for supporting
programmers. In Proc. of ESEC-FSE'07 , pages
351{360, 2007.View publication stats