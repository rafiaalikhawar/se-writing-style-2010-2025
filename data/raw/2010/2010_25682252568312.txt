ConLock: A Constraint -Based Approach to  Dynamic 
Checking on Deadlocks in Multithreaded Programs  
Yan Cai Shangru Wu W. K. Chan 
Department of Computer Science  
City University of Hong Kong  
Hong Kong , China  
ycai.mail@gmail. com Department of Computer Science  
City University of Hong Kong  
Hong Kong , China  
shangru .wu@my. cityu.edu.hk  Department of Computer Science  
City University of Hong Kong  
Hong Kong , China  
wkchan @cityu.edu.hk  
ABSTRACT  
Many predictive  deadlock detection techniques analyze multi-
threaded programs to suggest  potential deadlocks  (referred to as 
cycles  or deadlock warnings ). Nonetheless, many of such cycles 
are false posit ives. On checking these cycles, existing dynamic 
deadlock confirmation techniques may frequently encounter 
thrashing  or result in a low confirmation probability . This paper  
present s a novel technique entitled ConLock  to address these pro b-
lems. ConLock  firstly analyzes a given cycle and the execution 
trace that produces the cycle . It identifies a set of thread schedu l-
ing constraints  based on a novel should -happen -before  relation . 
ConLock  then manipulates a confirmation run with the aim to not 
violat e a reduced  set of scheduling constraints  and to trigger an 
occurrence of the deadlock if the  cycle  is a real deadlock. If the 
cycle is a false positive, ConLock  report s scheduling violation s. 
We have validated  ConLock  using  a suite  of real-world  program s 
with 11 deadlocks. The result shows that among all 741 cycles  
reported by Magiclock , ConLock  confirm s all 11 deadlocks with a 
probabilit y of 71%−100%. On the remaining 730 cycles, ConLock  
reports scheduling violation s on each . We have systematically 
sampled 87  out of the 730 cycles  and confirmed that all the se 
cycles are false positives.  
Categories and Subject Descriptors  
D.2.4 [Software Engineering] : Software/Program Verification  – 
reliability , correctness  proofs , validation . D.2.5 [ Software Eng i-
neering ]: Testing and Debugging  – testing  tools . D.4.1 [ Gen-
eral]: Processing Management – concurrency , deadlocks . 
General Terms  
Reliability,  Verification  
Keywords  
Deadlock, confirmation , should -happen -before relation.  
1. INTRODUCTION  
Many multithreaded programs use various locking mechanisms  
[32] to coordinate  how their threads produce the program outputs . 
Improper sequence s of lock acquisition s and releases  performed  
by these threads may result in  concurrency bugs such as data races 
[11][14][46], atomicity violation s [30], or deadlock s [5][7][15] 
[25]. A deadlock  [15][25] occurs  when every thread in a thread 
set waits for acquir ing a lock that another thread  in the same set is holding . Each occurrence of a deadlock  stops  the threads involved 
in it from making further progress.  Deadlock is a critical failure . 
Once a deadlock has occurred in an execution trace, it is not diff i-
cult to report the occurrence and reproduce it [45]. In general, 
deadlocks rarely occur in the program executions of real -world 
programs, but may reveal their presence s in some other execution 
traces . To suggest potential deadlocks, many static techniques 
(e.g., [40][43]) and dynamic techniques (e.g., [5][12][34]) have 
been proposed. Static techniques analyze the program code  to 
infer the existence of cyclic lock acquisition (i.e., cycles ) among 
threads  as potential deadlocks. They generally suffer from repor t-
ing many  false positives. For instance , the experiment in  [43] 
reported  more than 100,000 potential cases  when analyzing the  
Java JDK ; and yet  only 7 of them could  finally be confirmed as 
real deadlocks  (after applying v arious unsound heuristics ). Dy-
namic  predictive techniques [7][8] also suffer from reporting false 
positives, albeit less serious than the static counterparts . Tracking 
the happened -before relations [29] or constructing a segmentation 
graph [7] on the corresponding execution trace may eliminate 
some kinds of false positive s, but may also eliminate certain true 
positives due to different thread schedules [25], which is risky . 
Confirming each given cycle to be a real deadlock or not by ex e-
cuting the program with respect to the cycle  is desirable . 
Latest t echniques that can automatically  confirm  cycles as real 
deadlocks include DeadlockFuzzer  [25] and MagicScheduler  [15]. 
A minor adaptation of PCT  [9] is also an alternative. However , in 
Section 5, our experiment shows  that they either are unable to 
confirm a real d eadlock at all or can only achieve a low confirm a-
tion probability. Besides, existing dynamic techniques  such as  
[15][25] have  no strategy to handle cycles that are false positives . 
To ease our presentation, we refer to an execution used to suggest  
cycle s as a predictive run . Similarly, we refer to an execution that 
is used to confirm whether a suggested cycle  c is a real deadlock 
or not  as a confirmation run . We also suppose that cycle s have 
been suggested by a predictive technique on a predictive run.  
In this paper, we prop ose ConLock , a novel constraint -based a p-
proach to dynamic confirmation of deadlocks  and handling false 
positive s. ConLock  consists of two phases : (1) In Phase I, ConLock  
analyzes the predictive run , and generates a set of scheduling  
constraints  with respect to the given  cycle  c. Each constraint spe c-
ifies the order of a pair of lock acquisition /release  events  in a 
confirmation run between  the corresponding pair of threads  in-
volved in the cycle  c. (2) In Phase II, ConLock  manipulates a  con-
firmation run with the attempt to not viola te the reduced set of 
constraints produced  in Phase I  so as to trigger the deadlock if the 
cycle c is a real deadlock;  or else, it reports a scheduling  violation  
against  the given set of constraints , which indicat es that the cu r-
rent run is no longer meaningful to confirm the cycle  c. In either 
case,  ConLock  terminates the current confirmation run. Permission to make digital or hard copies of all or part of this work for 
personal or classroom use is granted without fee provided that copies are 
not made or distributed for profit or commercial advantage and that  copies 
bear this notice and the full citation on the first page. To copy otherwise, 
to republish, to post on servers or to redistribute to lists, requires prior 
specific permission and/or a fee.  
ICSE'14, May 31 – June 7, 2014, Hyderabad, India . 
Copyright 2014 ACM 978 -1-4503 -2756 -5/14/05... $15.00.  Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a
fee. Request permissions from Permissions@acm.org.
ICSE’14 , May 31 – June 7, 2014, Hyderabad, India
Copyright 2014 ACM 978-1-4503-2756-5/14/05...$15.00
http://dx.doi.org/10.1145/2568225.2568312
491
We have implemented a prototype of ConLock  to validate  ConLock  
on a suite of real-world programs . We compare d ConLock  with 
Magic Scheduler  [15], DeadlockFuzzer  [25], and PCT  [9] in terms 
of confirmation probability, consistency in confirmation, and the 
amount of time taken to check against all given cycles . In the 
experiment, ConLock  achieved a consistently higher probability 
(71%–100%) in confirming all 11 real deadlocks; whereas, other 
techniques either missed to confirm 5 to 7 cycles as real deadlocks 
in every confirmation run or only achieved a lo wer probability on 
remaining real deadlock cases . We systematically sampled a sub-
set (87 cycles in total)  of the remaining  730 cycles  (on which 
ConLock  reported scheduling violations)  for careful manual code 
inspection , and confirm ed that they were all false positives . 
The main contribution of this paper is threefold:  
 This paper propose s ConLock , a novel dynamic constraint -
based deadlock confirmation technique to isolating real dea d-
locks from the given set of cycles with a high probability  and 
a low slowdo wn overhead .  
 To the best of our knowledge, ConLock  is the first technique 
that can terminate confirmation runs on false positive cycles 
by reporting scheduling violations .  
 We report an experiment , which confirm s that ConLock  can 
be effective and efficient.  
In the rest of this paper , Section 2 revisits the preliminaries of this 
work . Section 3 motivates our work by an example. Section 4 
present s the ConLock  algorithm. Section 5 describes a validation 
experiment , and reports the experimental results . Section 6 re-
views the closely related work . Section 7 concludes this  paper.  
2. PRELIMINARIES  
2.1. Events and Trace s 
Our model monitors a n execution trace  over a set of critical oper a-
tions  = {acq, rel} performed on locks, where acq represents 
lock acqui sition  and rel represents lock release . The extension to 
handle other synchronization primitives (e.g., barriers) is straigh t-
forward [11][14][20]. 
Definition 1.  An event  e = t, op, m@s, ls denotes that a thread t 
performs an operation op   on a lock m, which occurs at the 
site s, and at the same time , t is holding a set of locks (called 
lockset ) ls, each of which is associated with the site where  t ac-
quires the corresponding lock.  
Definiti on 1 extends the definition of lock dependency  in [15][25] 
by including  lock release  rel in . A site is an execution context 
[16][25] (e.g., the triple call stack , statement  number , the latest 
occurrence count of the couple call stack, statement number  can 
be used to denote an execution context ).  
An execution  trace  of a program p is a sequence of events, and 
t is the projection of a trace  on a thread t of the same trace . 
2.2. Cycle  as Potential Deadlock  
Definition 2.  A sequence of  k events denoted by c = e1, e2, …, 
ek, where ei = ti, acq, mi@si, lsi for 1 ≤ i ≤ k, is called a  cycle 
[15] if both of the following two conditions are satisfied:  
(1) for 1  ≤ i ≤ k - 1, mi  lsi+1, and mk  ls1; and, 
(2) for 1 ≤ i < j ≤ k, ti ≠ tj, mi ≠ mj, mi lsi, and lsi ∩ lsj =∅. 
A cycle  models  a potential deadlock : The site si in the event ei 
involved in a cycle c is referred to as a deadlocking site  of the thread ti. The lock  mi of an  event ei is the lock that the thread ti 
waits to acquire.   
For instance , Figure 1(b) (to be described in Section 3) depicts  
that a  thread t1 is holding the lockset { a, p, m } and is waiting to 
acquire  the lock n at site  s08; and a thread  t2 is holding  the lockset 
{n}, and is waiting to acquire the lock p at site s16. The four boxed 
operations represent a deadlock  bug that has not been triggered in 
the scenario ; and this deadlock can be modeled as a cycle c0 = 
t1, acq, n@s08, {a@s03, p@s06, m@s07}, t2, acq, p@s16, {n@s15}.  
We denote the set { mi | ei = ti, acq, mi@si, lsi  ei  c} by WLOCKc. 
It means that each lock in WLOCKc is a lock waiting  to be acquired 
by a thread  involved in the cycle  c at its deadlocking site. Simila r-
ly, we denote the set of all locks, each of which is being  held by a 
thread involved in c at the deadlocking site, by the set HLOCKc (i.e., 
HLOCKc = {nj | ei = ti, acq, mi@si, lsi  ei  c  nj@sj  lsi for 
some site sj}). Moreover, t he site to acquire a lock m  WLOCKc (n 
 HLOCKc, respectively)  is denoted by WSITEc(m) (HSITEc(n), re-
spectively ). For the above cycle c0 in Figure 1(b), we have 
WLOCKc0 = {n, p}, WSITEc0 (n) = s08, WSITEc0 (p) = s16, HLOCKc0 = {n, 
p, a, m}, HSITEc0 (n) = s15, HSITEc0 (p) = s06, HSITEc0 (a) = s03, 
and HSITEc0 (m) = s07.  
3. MOTIVATING EXAMPLE  
Figure 1(a) shows a bug that can be triggered  by using two 
threads operating on four locks . The  operations  acq(x) and rel(x) 
in the figure depict  a lock acquisition event and a lock release 
event on the lock x, respectively.  The program in Figure 1(a) 
illustrates a deadlock  bug as shown by the four boxed operations .  
Execution  1, depicted in Figure 1(a), passes  through the path s13, 
s14, s01, s02, s03, s04, s05, s06, s07, s15, resulting in  a deadlock occu r-
rence: Specifically, t he thread t2 firstly acquires the lock a at the 
site s13 and then releases  the lock  a at the site  s14. When  the thread  
t2 is about to acquire the lock n at the site s15, the thread t2 is sus-
pended. Then, the  thread t1 execute s the operations  at sites  s01 to 
s07 to acquire three locks a, p, and m, at the sites s03, s06 and s07, 
respectively.  When t1 is about to  acquire the lock n at the site s08, 
it is suspended , and the thread  t2 is resumed to successfully a c-
quire the lock n at the site s15. Then , the thread  t2 is suspended 
when it is about to acquire  the lock p at the site s16 because the 
lock p is being held by t1 at this moment.  As such , the thread  t1 
resumes  its execution. Nonetheless , the thread  t1 has to wait for  
the thread  t2 to release the lock n so that the thread  t1 can acquire 
this lock n. The two threads now mutually wait for each other to 
release  their waiting locks. The execution triggers a deadlock.   
Execution  2, depicted in Figure 1(b), passes through the path s13, 
s14, s15, s16, s17, s18, s01, s02, s03, s04, s05, s06, s07, s08, s09, s10, s11, s12, 
failing to trigger  any deadlock:  Suppose that the thread t2 has 
acquired the lock n at the site s15 (which is different from the Exe-
cution  1), and is about to acquire  the lock p at the site s16. At this 
moment, the thread t2 is suspended , and the thread t1 is resumed. 
However, the thread t1 cannot successfully acquire the lock n at 
the site s01 because the thread t2 is holding the lock n. Hence , t1 is 
suspended. The thread t2 is then resumed , and acquires the lock p. 
It finally releases the  two locks p and n at the s ites s17 and s18, 
respectively . Next, the thread t1 is resumed , and completes its 
remaining execution . No deadlock has been triggered .  
Existing dynamic predictive  techniques (e.g., [15][25][34]) may 
analyze Execution  2 to suggest  the cycle c0 = t1, acq, n@s08, 
{a@s03, p@s06, m@s07}, t2, acq, p@s16, {n@s15}. However, 
without confirm ing the cycle c0, this cycle c0 is unknown to be a 492real deadlock or just a false positive.  Manually confirming every 
such cycle can be tedious  and error prone.  
The latest state-of-the-art techniques on automatic confirmation  of 
cycles  as real deadlocks  include DeadlockFuzzer  [25] and Mag-
icScheduler  [15]. PCT  [9] is not designed for deadlock confirm a-
tion, but it provides a probabilistic guarantee to detect real dea d-
locks if they exist. We review them to motivate our work.  
MagicScheduler  (MS) [15]: MS is the latest dynamic deadlock 
confirmation technique. It uses a heuristic to random ly schedule 
each individual thread in a given program against a set of given 
cycles  and suspend a threa d if the thread holds a set of  locks and 
requests  another lock  at the deadlocking site of this thread  speci-
fied by a given cycle  [15]. Consider the example  in Figure 1(b). 
MS aims  to suspend the thread t1 when t1 is right before executing 
the operation at the site s08, and suspend the thread t2 when t2 is 
right before executing the operation at the site s16.  
Directly applying the above heuristic can be challenging  to sche d-
ule the two threads in a confirmation run to trigger  a real dea d-
lock. Suppose that MS firstly suspend s the thread  t2 right before 
executing the operation at the site s16 (after the thread t2 has a c-
quired the lock n at the site s15). To trigger the deadlock with r e-
spect to the cycle c0, MS aims to wait for  the thread  t1 to be su s-
pended at the site  s08. This target is  nonetheless impossible to 
achieve because  the thread  t1 has been blocked  at the site s01 (or 
the site s04) as the lock n is being held by t2, and yet t2 has been 
suspended . This kind of problem is known as thrashing  [25]. To 
resolve this occurrence of thrashing, MS resume s the thread  t2, 
which runs to complete the execution of the  operation s up to the 
site s18 and release s the lock n. Nonetheless , the deadlocking site 
s16 for t2 has been passed . So, the cycle  c0 could not be confirmed.  
Execution  2 starts with the thread  t2 at the site s13. On Execution  2, 
according  to the scheduling strategy of  MS, MS always results in  
thrashing and fails to trigger  the cycle c0 as a real  deadlock. An 
execution scenario that starts with the thread t1 would still result 
in thrashing caused by MS. For instance, suppose that MS has 
successfully suspended  the thread  t1 at the site s08 (before  acqui r-
ing the lock n), and then the thread t2 starts. The thread t2 cannot 
acquire the lock a at s13 because  t1 is still holding  the lock  a. As a result, thrashing occurs. MS resumes t1 to acquire the lock n. As 
such, no deadlock could be trigger ed. This also  illustrates that 
merely applies the active  thread schedul ing at the sites  s08 and s16 
is unlikely to trigger the deadlock bug with a high probability.   
DeadlockFuzzer  (DF) [25] uses a heuristic strategy that is identical  
to MS except that DF tries to confirm one cycle per run instead of 
a set of cycle s per run. The running example has only one cycle . 
DF suffers from the same problem experienced by MS. 
Probabilistic  Scheduler : PCT  [9] probabilistically generates a 
sequence of priority changing points. From the probabilistic the o-
ry, PCT  can generate a  thread  schedule (e.g., Execution  1 in Fig-
ure 1(a)) that results in triggering a deadlock occurrence . Accor d-
ing to [9], its guaranteed probability is 1 / (n  k d-1) for a concu r-
rency bug of depth d involving  n threads that execut es a total of k 
steps . For the running example, the guaranteed probability is 1 / 
(2182-1) or 0.02778 , which is low, despite that PCT  can detect 
the deadlock bug without needing any predictive run or any in-
formation about  a given cycle.  
In the next section, we present ConLock  and illustrate how Con-
Lock confirm s the cycle c0 in Figure 1.  
4. CONLOCK  
4.1. Overview  
ConLock  is a novel constraint -based dynamic approach to dead-
lock checking . It consists of two phases  with respect  to a given 
cycle [5][7][15] as depicted in Figure 2. 
A predictive technique firstly suggests a cycle c (as depicted in 
Figure 2(a)). ConLock  then starts its two phases.  
In Phase I,  given a cycle from  a predictive run , ConLock  generates 
a set of constraints   (as depicted in Figure 2(b)). The generation 
of the constraint set  is based on the novel  should -happen -before 
relation  (proposed in Section 4.2.1 ).  
In Phase II, ConLock  actively schedules a confirmation run with 
respect to  a subset of constraint s , and produces  two important 
consequences : (1) if the given cycle is a real deadlock  (as depicted 
in Figure 2(c)), ConLock  tries to  confirm it . As shown in our e x-
periment, its confirmation probability is high ; (2) if the given 
cycle is a false positive  (as depicted in Figure 2(d)), ConLock  
reports a scheduling violation. The two consequences significan t-
ly distingui sh ConLock  from the existing techniques .  
4.2. Phase I: Generation  of Constraint Set  
and Scheduling Points  
To schedule a confirmation run that successfully confirms a given 
cycle as a real deadlock, each  thread involved in a cycle should be 
precisely suspended at its deadlock ing site. Many e xisting dyna m-
ic active testi ng techniques  [15][25] have used  this insight  to ex-
tract information from a predictive run to guide the manipulation 
of a confirmation run. Moreover, we observe that at the same time, 
a confirmation technique shoul d avoid occurrences of thrashing as 
much as possible. Hence, our goal is that each thread involved in 
a cycle should not be artificially blocked by any other thread i n-
volved in the same cycle before the former thread is about to a c-
quire the lock at its deadlocking site  as much as possible.  
Based on the above two observations , we formulate a novel rel a-
tion entitled the  should -happen -before  relation  to (1) effectively 
prevent occurrence of thrashing and (2) precisely suspend each 
thread involved  in a cycle at its deadlocking site.  We note that the 
thread t1 thread t2
s01
s02
s03
s04
s05
s06
s07
s08
s09
s10
s11
s12acq(n)
rel(n)
acq(a)
acq(n)
rel(n)
acq(p) 
acq(m)
acq(n)
rel(a)
rel(p)
rel(m)
rel(n)s13
s14
s15
s16
s17
s18acq(a)
rel(a)
acq(n) 
acq(p)
rel(p)
rel(n)thread t1 thread t2
s01
s02
s03
s04
s05
s06
s07
s08
s09
s10
s11
s12acq(n)
rel(n)
acq(a)
acq(n)
rel(n)
acq(p) 
acq(m)
acq(n)
rel(a)
rel(p)
rel(m)
rel(n)s13
s14
s15
s16
s17
s18acq(a)
rel(a)
acq(n) 
acq(p)
rel(p)
rel(n)⃝=⃝=: waiting to acquire the lock 
: deadlocking site. Actual case in (a ) and Predictive case in (b )
: thread execution : interleaving among threads
(a) Execution 1
(scenario with deadlock)(b) Execution 2
(scenario without deadlock) 




⃝i: the execution order Figure 1. Example deadlock adapted  from JDBC  Connector  5.0 [2] 
(Bug ID: 2147).  The acronym n, a, p, and m are Connection , 
Statement , ServerPreparedStatement , and Connec-
tion.Mutex , respectively.  493should -happen -before  relation  is a relation between two events in 
the execution trace  of a predictive run  (where the run itself has no 
deadlock occurrence ). It denotes that the two related events  
should  occur in a specified  order in the confirmation run .  
4.2.1 Should -Happen -Before Relation  
We firstly revisit the happened -before -relation . We use ↣ to de-
note the happened -before  relation  between two events .  
In our problem context, t he happened -before  relation  [29] de-
scribes a relation between two events over the given execution 
trace  of the predictive run . The happened -before relation [29] is 
defined as follows : (i) Program order : if two events e1 and e2 are 
performed by the same thread , and e1 appeared before e2 in the 
execution  trace , then e1 ↣ e2. (ii) Lock a cquire and release : if (1) 
er is a lock release on a lock m by a thread t1, (2) ea is a lock a c-
quisition on the same lock m by a thread t2, where t1  t2 and (3) er 
appears prior to ea in the execution trace,  then er ↣ ea. (iii) Trans i-
tivity : if e1 ↣ e2 and e2 ↣ e3, then e1 ↣ e3.  
We proceed to present the de finition of should -happen -before  
relation.  We use ⇝ to represent this relation over two events. To 
ease our subsequent presentation, sometimes, we refer to  the event 
ei by the thread ti involved in the cycle  c as (c, ti), and use the site 
of an event e to denote e when describing the ⇝ and ↣ relations.  
Definition 3.  Given an execution trace , a cycle c on , suppose 
that t, t, and t are threads involved in the cycle c, where t  t 
and t  t, the should -happen -before  relation  is defined as:  
Rule  1: Suppose that  e and e are two events performed by two 
threads t and t, respectively, and they both operate on the same 
lock m. If the three conditions (1) m  WLOCKc, (2) e ↣ (c, t), 
and (3) e= (c, t) are satisfied , then e ⇝ e. 
Rule  2: Suppose that e and e are two events performed by two 
threads t and t, respectively, and they both operate on the same 
lock n. If the three conditions (1) n  HLOCKc, (2) e ↣ (c, t), 
and (3) e = t, acq, n@HSITEc(n), ls for some ls are sati s-
fied, then e ⇝ e. (Note  that e  (c, t) and e ↣ (c, t).) 
Rule 1 def ines a condition to prevent  predictable  thrashing to 
occur on these locks in the set  WLOCKc. Figure 3(a) uses Execution  
2 to illustrate this rule  via the lock p and the cycle c0. In Figure 
3(a), the lock p is in WLOCKc0, the site s16 is the deadlocking site for 
the thread t2 (i.e., t in the Rule 1) that operates on this lock p, and 
the deadlocking site for the thread t1 (i.e., the thread t in Rule 1) is 
the site  s08. Rule 1 specifies  that any lock acquisition  or release  
event on this lock p performed by the thread  t1 (e.g., the event e at 
the site s06) that happened -before the event (c0, t1) at the site s08 
should -happen -before  the event ( i.e., e) performed by the thread  
t2 at its deadlocking site s16. Thus , by Rule 1, we get s06 ⇝ s16.  Similarly, Rule 2 defines a condition that prevents predictable 
thrashing on these  locks in the set  HLOCKc. Figure 3(b) uses Exec u-
tion 2 to illustrate this rule via the lock n. In Figure 3(b), the lock 
n is in HLOCKc0, and the thread t2 (i.e., the thread t in Rule 2) holds 
a lockset { n@s15} when t2 is about to acquire the lock p at its 
deadlocking site s16. We also recall that  the deadlocking site for 
the thread t1 (i.e., the thread  t in Rule 2) is the site s08. Rule 2 spec-
ifies that any lock acquisition  or release event on  n performed by 
t1 that happened -before the event occurred at its deadlocking site 
s08 should -happen -before the lock acquisition event on n at site s15 
(i.e., the event e). Thus , by Rule 2, we get s05 ⇝ s15. The lock n 
has also been acquired or released by the thread t1 at sites s01, s02, 
and s04. So, we get s01 ⇝ s15, s02 ⇝ s15, and s04 ⇝ s15, accordingly . 
The Whole Set of Should -Happen -Before Relations  in the 
Running Examples : We now apply Rule 1 and Rule 2 to identify 
a complete set of should -happen -before relations with respect to  
the cycle c0. We recall that Execution  2 in Figure 1(b) operates on 
four locks { n, a, p, m}. The cycle c0 has two deadlocking sites s08 
of the thread t1 and s16 for the thread t2. WLOCKc0 is {n, p}, and 
HLOCKc0 is {n, a, p, m}.  
The lock m is only acquired once . There is no should -happen -
before  relation  on it (because  the should -happen -before  relation  is 
defined over two events  performed by different threads ).  
Consider the lock n. We have applied Rule 2 on it to have ident i-
fied s01 ⇝ s15, s02 ⇝ s15, s04 ⇝ s15, and s05 ⇝ s15 in the above 
illustration of Rule 2. The thread t1 performs the event on the lock 
n at its deadlocking site s08, which is also denoted by (c0, t1). For 
the thread t2, there is only one event e = t2, acq, n@s15, {} oper-
ating on the lock n and e ↣ (c0, t2). By Rule 1, we get s15 ⇝ s08. 
Consider  the lock p. We  have applied Rule 1 on this lock  to have 
identified s06 ⇝ s16. We recall that HSITEc(p) is the site  s06, but  
there is no event operating on the lock p by the thread t2 that hap-
pened -before the event (c0, t2) at the site s16. Thus , Rule 2 pro-
duces no further should -happen -before relation for the lock p.  
○
○
○
○
○
○
○
○○
○
○
○○
○
○
○
○
○
○
○○
○
○
○○
○
○
○
○
○
○
○○
○
○
○
(a) A predictive run suggests a cycle c (c) Deadlock confirmed (b) : The s et of constraints? 
………………t1 t2 t1 t2 t1 t2ConLock Existing Work
○
○
○
○
○
○
○
○○
○
○
○
(d) Scheduling violation reported
……t1 t2
or Predictive Phase Phase I Phase II 
Figure 2. An o verview of ConLock . 
 
t1ast t2 ast
s01
s02
s03
s04
s05
s06
s07
s08acq(n)
rel(n)
acq(a)
acq(n)
rel(n)
acq(p) 
acq(m)
acq(n)s13
s14
s15
s16acq(a)
rel(a)
acq(n)
acq(p)t1ast t2 ast
s01
s02
s03
s04
s05
s06
s07
s08acq(n)
rel(n)
acq(a)
acq(n)
rel(n)
acq(p) 
acq(m)
acq(n)s13
s14
s15
s16acq(a)
rel(a)
acq(n) 
acq(p)
(a) Rule 1on the lock p:s06⇝s16 (b) Rule 2 on the lock n:s05⇝s15e:e:e:
e:: Happened -before : Should -happen -before Deadlocking site 
(c0,t1): (c0,t1):
 
 
Figure 3. Examples of Rule  1 and Rule  2 on Execution  2. 
 
 
 494Consider the lock a. Rule 1 gives no should -happen -before rel a-
tion on this lock  because  the lock  a is not in  WLOCKc0. In the cycle 
c0, the lock a is in a lockset of an event for thread t1. By Rule 2, 
any lock acquisition  or release event on  the lock a that happened -
before (c0, t2) should -happen -before the lock acquisition event on  
a performed by the thread t1 at the site s03. As for  the thread  t2, s13 
↣ (c0, t2) and s14 ↣ (c0, t2), we get s13 ⇝ s03 and s14 ⇝ s03. 
In total , based on Execution  2 and the cycle c0, we identify a set of 
eight  should -happen -before relations {s01 ⇝ s15, s02 ⇝ s15, s04 ⇝ 
s15, s05 ⇝ s15, s06 ⇝ s16, s13 ⇝ s03, s14 ⇝ s03, s15 ⇝ s08}. They are 
depicted  as dotted arrows in Figure 4(a).  
Execution  2 fails to trigger the deadlock , and its execution path is 
s13, s14, s15, s16, s17, s18, s01, s02, s03, s04, s05, s06, s07, s08, s09, s10, s11, 
s12. This path violates 5 out of these eight  should -happen -before  
relations  (each has been highlighted in the last paragraph ). In fact, 
any other execution path violating  at least one of these eight 
should -happen -before relations miss es to trigger  the deadlock.  
Execution  1 triggers a d eadlock occurrence, and its execution path 
is s13, s14, s01, s02, s03, s04, s05, s06, s07, s15 before deadlocking at  
the site  s08 for the thread  t1 and the site  s16 for the thread  t2. We 
observe that this execution path satisfies all eight should -happen -
before relations.  
In Section 3, we have illustrated an occurrence of thrashing 
suffered by both MS and DF. This thrashing occurrence is due to  
the thread  t2 having acquired the lock n at the site  s15 before  the 
thread  t1 attempts to acquire the same lock at  the site  s01, and yet  
the thread  t2 is actively suspended by the technique (e.g., MS) at 
the site  s16. The above set of should -happen -before relation s has 
pointed out  that the execution under active scheduling has already 
violated the relation s01 ⇝ s15, irrespective to whether or not the 
technique suspends t2 at s16. 
ConLock  can identify all such should -happen -before relat ions 
before scheduling a confir mation run. As such,  it has the ability to 
guide a thread scheduler  to avoid occurrence of thrashing .  
4.2.2 Generat ion of  Should -Happen -Before Relation s 
ConLock  treats each identified should -happen -before relation  as a 
scheduling  constraint  in a confirmation run . Algorithm  1 shows 
the constraint  set generat ion algorithm (-Generator for short) .  
Given an execution trace  and a cycle c, Algorithm  1 firstly 
identifies all the locks in  WLOCKc and HLOCKc and all threads in c as 
Threads (c) (lines 02–06). Then , it checks each event in the pro-
jection  t of the trace  over each thread  t in the reversed  program  
order starting from the deadlocking site of the thread t (lines 09–
11) with respect to the two rules (lines 12–27). The set 
Threads (c) at line 8 keeps all the threads involved in the cycle c 
(computed at line 03).  For each event e = t, op, l@s, ls from t, the 
algorithm checks whether the lock l is in the set WLOCKc (line 12). 
If this is the case , the algorithm further checks e against e to 
determine whether the  pair of events e and e forms  a should -
happen -before relation  based on Rule 1 (lines 13–14). If this is the 
case, it adds the relation e ⇝ e into the set  (line 15).  Next, the 
algorithm checks whether the lock l is in the set HLOCKc (line 19 ). 
If this is the case , it checks  whether or not there is an  event e 
operating on the lock  l such that l@s of the event e is in the 
lockset ls' of (c, t) (lines 20–22), which indicates the site  s is 
HSITEc(l). If there is such an event e, the algorithm  adds the rel a-
tion e ⇝ e into  (line 23) based on Rule 2.  ConLock  can schedule a confirmation run with the aim of not vi o-
lating any constraint  thus produced . However, if the size of the set 
constraint  is large, scheduling a program  execution against such 
a large set of constraints from the  beginning  may incur a high 
runtime overhea d. In the following two subsections, we present a 
precise constraint reduction algorithm and an optimization by 
selecting a nearest scheduling point  for each thread .  
4.2.3 Reduction of Constraint s 
We first give two properties  of the should -happen -before  relation:  
Property  1 (Transitivity ): If the constraint set  has included  
both e1 ⇝ e2 and e2 ⇝ e3, then  needs not to include e1 ⇝ e3 
because  the event order specified  by e1 ⇝ e3 has been  impli c-
itly and jointly specified by the relations e1 ⇝ e2 and e2 ⇝ e3.  
Property  2 (Program Locking Order ): If the constraint set  
has included ea ⇝ ex and er ⇝ ex such that  ea is the corr e-
sponding lock acquisition event of er performed by the same 
thread  t, then  needs not to include ea ⇝ ex because  ea ⇝ ex 
is enforced by the program order of the  thread t and er ⇝ ex. 
Applying both properties  produces a smaller but equivalent set of 
constraints generated by Algorithm  1. The reduction algorithm is 
straightforward:  recursively applying the two properties on every 
triple of constraints until no more constraint can be reduced .  
For the running example, applying these two properties  on the 
constraint  set produced by Algorithm  1 removes  the following  
four constraints from the original constraint set : s01 ⇝ s15, s02 ⇝ 
s15, s04 ⇝ s15, s13 ⇝ s03 (see Figure 4(b)). 
4.2.4 Identifying  Scheduling  Point s 
Lu et al.  [32] empirically conclude  that a concu rrency bug in real -
world large -scale multithreaded programs  usually needs a "short Algorithm  1: -Generator  
 
 
 
01 
02 
03 
04 
05 
06 
07 
08 
09 
10 
11 
12 
13 
14 
15 
16 
17 
18 
19 
20 
21 
22 
23 
24 
25 
26 
27 Input :  : an execution trace  
Input : c : a cycle  
Output :  : a constraint set with respect to c on  
 := , WLOCKc:= , HLOCKc:=  
for each  event t, req, m@s, ls in c do  
│ WLOCKc := WLOCKc  {m}, Threads( c) := Threads( c)  {t} 
│ for each n@sn  ls 
│ │ HLOCKc := HLOCKc  {n} 
│ end for 
end for  
for each  t  Threads  (c) do  
│ let i := p such that t[p] = (c, t)  
│ while  i -- > 0 do  
│ │ let t[i] be e = t, op, l@s, ls //e ↣ (c, t), op  {acq, rel} 
│ │ if l WLock  then //By Rule 1 
│ │ │ for each e = t, acq, m@s, ls = (c, t)  t  t do 
│ │ │ │ if l = m  then // m  WLOCKc 
│ │ │ │ │  :=   {e ⇝ e} 
│ │ │ │ end if  
│ │ │ end for  
│ │ end if 
│ │ if l  HLOCKc then  //By Rule 2 
│ │ │ let e = t, acq, l@s, ls where  t  t  
│ │ │ let (c, t) = t, acq, m@s', ls' //the deadlocking site of  t 
│ │ │ if l@s  ls' then  //thus, we have  s= HSITEc(l)  
│ │ │  │  :=   {e ⇝ e} 
│ │ │ end if 
│ │ end if 
│ end while  
end for  
 495depth " to manifest itself  in an execution . In other words, it is e m-
pirically enough to explicitly schedule only part s of an execution 
to manifest a deadlock . This indicat es the existence of a set of 
points (events) from which ConLock  can start to schedule the in-
volved threads. (Such a point may be the beginning of each thread  
in the worst case .) We refer to such a point as  a scheduling  point .  
A scheduling point  should -happen -before the deadlocking site of 
the same thread . Besides, the lockset held by a thread at such a 
point must be  empty ; otherwise, suspending a thread at its sche d-
uling point  may prevent other threads to acquire locks at their 
corresponding scheduling points ( ,which is akin  to the occurren c-
es of thrashing). In general, a  threa d may have  one or more 
scheduling points. ConLock  select s the scheduling point nearest to 
the deadlocking site of the same thread. We formulate a schedu l-
ing point as an event and denote all scheduling points  and the 
nearest one  of a thread t in  as sp(t) and nsp(t), respectively. 
Figure 4(c) shows four scheduling points (two for the thread t1 
and two for the thread t2) denoted by the horizontal arrows .  
The algorithm to select the nearest scheduling point for each 
thread t (i.e., nsp(t)) can be revised from Algorithm  1 by inserting 
the following four lines ( z1  z4) to the position in between line 25 
and line 26 in Algorithm  1. For brevity  and owing to its simplic i-
ty, we do not show th e whole  revised algorithm here . 
z1 
z2 
z3 
z4 if ls =  then  
│ nsp(t) := e 
│ break  while  
end if 
For the running example, Figure 4(d) shows an execution sched-
ule fragment that starts from the nearest scheduling point of each 
thread and satisfies the constraints in Figure 4(c). In the confirm a-
tion run  for the program  in Figure 1, ConLock  is able to confirm 
the cycle c0 predicated from Execution  2 (Figure 1(b)) as a real 
deadlock with a certainty, and produces no thrashing occurrence.  
4.3. Phase I I: ConLock  Scheduler  
4.3.1 Confirmation Algorithm  
ConLock  accepts a program p, a cycle c, a set of nearest schedu l-
ing point s nsp (one for each thread in c), and a set of constraints   
as inputs. It  firstly executes the program using randomized sche d-
uling , and monitors the events until any thread , say t, involved in 
c reaches (i.e., is the same as) its scheduling point. Then , ConLock  
suspends t (without executing the event) , and waits for other 
threads  involved in c to reach their corresponding  nearest schedu l-
ing points.  Next , ConLock  schedule s all subsequent event s with the aim of not violat ing the reduced  constraints set , and checks 
for deadlock occurrence.  It stops the current confirmation run  
immediately whenever it detects a scheduling  violat ion. We pro-
ceed to  present a few auxiliary concepts before presenting the 
scheduling algorithm of ConLock . 
State of a constraint . Given a constraint h = ea ⇝ eb, the state of  
the constraint  h (denoted as State(h)) is one of the following s: 
 Idle : if both ea and eb are not  executed .  
 Active : if eb is about to be executed , and ea is not  executed . 
 Used : if ea is executed .  
State of a thread . Given a thread t, the state of  the thread  t (de-
noted as State(t)) is one of the following s: 
 Enabled : if t can be scheduled  to execute its next event . 
 Waiting : if t is waiting on a constraint . (Note : if t is about to 
execute an event e, but there is a constraint, say, h = e' ⇝ e 
on which  e' has not been executed. To  avoid violating  the 
constraint  h, ConLock  suspend s the thread  t until the event  e' 
has been executed. In such cases, we say that  the thread  t is 
waiting  on the constraint h, and is in the Waiting  state. ) 
 Suspended : if t is suspended by ConLock . 
 Disabled : if t has terminated  or suspended by OS .  
Definition 4.  A scheduling violation  occurs in a confirmation run 
with respect  to a cycle c if the two conditions below are satisfied:  
 ∄ t  Threads(c), such that State(t) = Enabled , and , 
  t  Threads(c), such that State(t) = Waiting .  
A schedul ing viol ation means that no any thread  in Threads(c) is 
in the  Enabled  state, and each thread  in Threads(c) is either 
Disabled  or Waiting  on a constraint . Each Waiting  thread  t 
waits on a constraint , say e' ⇝ e, to be fulfilled  (i.e., the event e' 
from a different thread (i.e.,  t) should  be executed  before  the 
execution  of the event e by t). Because there is no  thread in the  
Enabled  state, no any event  can be further executed . To continue 
the whole execution, at least one constraint will be violated  in the 
current scheduling  (or else a deadlo ck has been triggered) . Be-
cause a constraint  has been violat ed, the current confirmation run 
is no longer meaningful to be further scheduled not to violate 
other constraints in view of triggering the deadlock with respect to 
the given cycle. Hence, we can terminate the confirmation run . 
Algorithm  2 presents the confirmation scheduler of ConLock . It 
takes a program p, a cycle c, a set of constraints , and a set of 
nearest scheduling points nsp (one for each thread involved in c) 
t1 t2
s01
s02
s03
s04
s05
s06
s07
s08○
○
○
○
○
○
○
○○
○
○
○s13
s14
s15
s16t1 t2
s01
s02
s03
s04
s05
s06
s07
s08○
○
○
○
○
○
○
○○
○
○
○s13
s14
s15
s16t1 t2
s03
s04
s05
s06
s07
s08○
○
○
○
○
○○
○s15
s16t1 t2
s01
s02
s03
s04
s05
s06
s07
s08○
○
○
○
○
○
○
○○
○
○
○s13
s14
s15
s16
(a)The original set of 
should -happen -before
relations(b) The reduced set of 
should -happen -before
relations(c) Scheduling points, and the set of 
should -happen -before relation after 
the nearest scheduling points(d) A confirmation run that does not
violate the should -happen -before
relations shown in (c)sp(t1)
nsp(t1)
nsp(t2)nsp(t1)
nsp(t2)sp(t2) 
 
Figure 4. Reduction of constraints and selection of nearest scheduling points with respect to  the cycle c0 and Execution  2  
 496as inputs. The schedu ler firstly initializes the state of each con-
straint as Idle  (line 01) . It also updates the state of each thread as 
Enabled  (lines 02 –03). Then, it uses OS scheduling  to execute 
the operation of a randomly  selected instruction (lines 04–12). If a 
thread t is about to execute an event  that is the nearest scheduling 
point of the same thread , the scheduler suspends t, moves  t from 
EnabledSet into Suspended Set, and sets State(t)= Sus-
pended  (lines 07−08). Otherwise, the instruction is executed (line 
10).  After all these threads reach their corresponding nearest schedu l-
ing points (by checking whether Threads(c)  Suspended Set 
(line 04)), ConLock  enables all these threads  (lines 1 3, 14, and 16 ).  
In order to check for the occurrence of a real deadlock, ConLock  
maintain s some necessary data  for each thread . These data are 
three maps : from a thread t to a lockset  as LS(t), from t to its 
requested lock as Req(t), and from t to its requested site as 
Site(t), which are all initialized to be empty (line 1 7).  
Next , ConLock  starts its guided scheduling (lines 1 9–43). It ran-
domly  fetches the next  event  e from a random and Enabled  
thread (line 20). Before executing the event e, ConLock  checks e 
against each constraint in  that is not in the Used state,  and 
determines the state s of both the selected constraint and the cu r-
rent thread  t (lines 21–32) such that no constraint is violated . 
There are three cases  to consider :  
 If there is any constraint h = ea ⇝ eb such that State(h) = 
Idle  and the current event  e = eb, the execution of event e 
will be postponed until ea has been  executed . ConLock  sets 
State(h) = Active  and State(t) = Waiting  on h (lines 
22). It then checks whether any scheduling violation occurs, 
and reports the violation if any (lines 2 3–26). 
 If there is a ny constraint h = ea ⇝ eb and State(h) = Ac-
tive , such that the current event e = ea, ConLock  sets 
State(h) = Used  and updates the state of every thread (say 
t') that is Waiting  on h to be Enabled  (lines 2 8–29). At line 
29, we use Notify(h) to indicate the change of the state of  
each thread  (say t') waiting on  this constraint  h from Wait-
ing to Enabled.  
 If there is a ny constraint h = ea ⇝ eb and State(h) = Idle , 
such that the current event e = ea, ConLock  sets State(h) = 
Used  (lines 30–31).  
Next, ConLock  checks the type of the event e, and perform s a 
corresponding action.  If e is a lock acquisition, ConLock  updates 
the three maps Req, Site , and LS, and call s the function Check-
Deadlock ()(lines 3 6–38). If e is a lock release, ConLock  updates 
the map LS only (line 40). For any other event, ConLock  directly 
executes the event . Algorithm  2 then handles the next instruction.  
If the function CheckDeadlock() (lines 4 4–49) finds any cycle  
according to Definition 2 , ConLock  reports the occurrence of a real 
deadlock , and terminates the confirmation run .  
4.3.2 Discussion s  
ConLock  can report both real deadlock  occurrences and scheduling 
violations. This feature  makes ConLock  significantly different 
from existing active randomized schedulers.  
Take confirming a cycle on the MySQL  database server as an e x-
ample. MySQL  is a server  program that accept s a query and return s 
a dataset . However, after serving this query , the program  will wait 
for the next input  instead of program termination. As such, there 
is always at least one active thread  once MySQL  has been started.  
Existing  schedulers (e.g.,  MagicSch eduler  and DeadlockFuzzer ) will 
not terminate the confirmation run  by their algorithmic design . 
We also recall from the motivating example that once an occu r-
rence of thrashing happens, they will activate a previously su s-
pended thread. Because the deadlocking site for the previously 
suspende d thread has been passed in the run, the given cycle 
could no longer be confirmed.  Algorithm 2: ConLock Scheduler  
 
 
 
 
01 
02 
03 
04 
05 
06 
07 
08 
09 
10 
11 
12 
13 
14 
15 
16 
17 
18 
19 
20 
 
21 
22 
23 
24 
25 
26 
27 
28 
29 
30 
31 
32 
33 
34 
35 
36 
37 
38 
39 
40 
41 
42 
43 
44 
45 
 
46 
47 
48 
49 Input : p – a program  
Input : c – a cycle  
Input :  – a set of constraints  
Input : nsp – the nearest scheduling point s 
for each  h  , State (h) := idle 
for each  thread t in p, State (t) := Enabled  
EnabledSet := all threads in p, SuspendedSet  :=  
while  EnabledSet     Threads (c)  SuspendedSet  do 
│ e := the next event  from a thread t 
│ if e = nsp(t) then 
│ │ SuspendedSet  := SuspendedSet   {t}, State (t) := Suspended . 
│ │ EnabledSet  := EnabledSet  \ {t}. 
│ else 
│ │ execute  (e) 
│ end if 
end while  
EnabledSet := EnabledSet   SuspendedSet  //resume all threads  
SuspendedSet  :=  
for each  thread t do 
│ State (t) := Enabled  
│ LS(t) := , Req(t) := , Site (t) :=   
end for 
while   t  Threads (c)  State (t) = Enabled  do 
│ let e := t, op, m@s, ls be the next event  of the thread  t 
│ //check e against each constraint in  
│ if  h = ea ⇝ eb , eb = e  State (h) = Idle then 
│ │ State (h) := Active , State (t) := Waiting  on h 
│ │ if a scheduling violation occurs by Definition  4 then 
│ │ │ print  "A scheduling violation occurs."  
│ │ │ halt //Early termination of confirmation run  
│ │ end if 
│ │ continue  
│ else if   h = ea ⇝ eb , ea = e  State (h) = Active  then 
│ │ State (h) := Used , Notify(h) //State (t'): = Enabled  
│ else if   h = ea ⇝ eb , ea = e  State (h) = Idle then 
│ │ State (h) := Used   
│ end if 
│ //else execute e and check for deadlock  
│ switch  (op) 
│ │ case acq: 
│ │ │ Req(t) := m, Site (t) := s 
│ │ │ call CheckDeadlock () 
│ │ │ Req(t) := , LS(t) := LS(t)  {m@s} 
│ │ case rel: 
│ │ │ LS(t) := LS(t) \ {m@s'} for some s' 
│ end switch  
│ execute  (e) //other event, e.g., thread termination  
end while  
Function  CheckDeadlock () 
│ if  a sequence of events e1, e2, …, en, where ei =ti, acq, 
Req(ti)@Site(ti), LS(ti) for 1 i  n, is a cycle by Definition  2 then  
│ │ │ print  "a deadlock occurs ." 
│ │ halt 
│ end if 
end Function  
 4975. EXPERIMENT  
5.1. Implementation  and Benchmarks  
Implementation . We implemented ConLock  to handle both Java 
and C/C++ programs. The Java implementation  used ASM 3.2 [1] 
to identify all "synchronized " operations of each loaded class 
and wrap them to produce events . Following the mechanism in 
Java, we take  each "Object " as a loc k instance . The C/C++ i m-
plementation was based on Pin 2.10 (45467) [33] on Linux. We 
used the Probe mode of Pin because  the analysis of deadlock is a 
high level pr oblem and there is no need to monitor any low level 
memory access in our case ; besides, the Probe mode provide s 
almost native execution performance [33]. ConLock  via Pin i n-
strument ed a C/C++ binary program to produce events by wra p-
ping the Pthread library functions.   
We implemented PCT  [9], MagicScheduler  (MS) [15], Deadloc k-
Fuzzer  (DF) [25], and ConLock  (CL) on the same framework. Al t-
hough Deadloc kFuzzer  is available from the current release of 
Calfuzzer  [23], yet this tool is for Java programs  and cannot ha n-
dle C/C++ benchmarks ; and when we tried it on Java benchmark 
(i.e., JDBC  Connector ), it only instrumented the test harness 
programs but not the library files (i.e., the program code that co n-
tains the deadlock s) to prevent us from profiling any event to 
detect the deadlocks. W e finally chose to faithfully implement DF 
based on [25] and Calfuzzer  [23] (to include all its optimizations) 
instead of modifying Calfuzzer . We note here that according to  the 
experiment in  [25], DF was able to  confirm deadlocks in the  Java 
library List  (i.e., ArrayList , LinkedList , and Stack ) and 
Map (i.e., HashMap , WeakHashMap , LinkedHashMap , Identi-
tyHashMap , and TreeMap ) with 100%  and 53% probabilities, 
respectively. The original  tools of PCT  were  unavailable  for 
download ing at the time of cond ucting this experiment . Thus,  we 
implemented its scheduling algorithms  for deadlocks according to 
[9]. We have  assured  our implementation by a few  programs .  
Benchmarks . We selected a suite of widely -used real -world Java 
and C/C++ programs, including  JDBC  connector  [2], SQLite  
[4], and MySQL  Database  Server [3]. These benchmarks have 
been used in previous deadlock related experiments  (e.g., [15] 
[26]) and are available online . All o ur test cases on these benc h-
marks are taken from [26] or their Bugzilla repositories.  
Site. We use d the existing Object Frequency Abstraction [16] to 
model the site (of an object or an even t). The same site of each 
object or event is used by all techniques (i.e., PCT , MS, DF, CL).  
5.2. Experimental Setup  
We ran the experiment on Ubuntu Linux 10.04 configured with a 
3.16GHz Duo2 processor and 3.25GB physical memory, Ope n-
JDK 1.6, and GCC 4.4.3. For each benchmark, we used 
Magic Lock [15] to generate the set of cycles based on the collected execution trace s. We then inputted each cycle  (and other inputs 
needed by Algorithm  2 if any) to each  technique ( i.e., PCT , MS, 
DF, and CL) for each test case  to run 100 times  [15][25]. PCT  is 
insensitive to a given cycle. Hence, if a benchmark sho ws the 
presence of k cycles, we ran PCT  for 100  k times.   
Table 1 shows the descriptive statistics of the benchmarks used in 
the experiment. The column "Benchmark ", "Bug  ID", and "SLOC " 
show  the benchmark name , the available bug report number , and 
the size of each benchmark  in terms of SLOC , respectively . The 
"Deadlock Description " column shows the functions or ope r-
ations that can lead to the corresponding deadlock  state. The next 
three columns show the number  of threads and the number of 
locks ("# of threads/locks "), the total number of cycles (" # of 
cycles"), and the cycle ID for each real deadlock ("# of real  
deadlocks  (cycle  ID)"). The last two columns show the num-
ber of data races  ("# of data races ") detected by LOFT  
[11][14] configured with FastTrack  [20] and the number of events 
("# of events ") on the predicative runs, respectively .  
5.3. Data Analysis  
Table 2 shows the experimental results for all 11 real deadlocks  
summarized  in Table 1. The first column shows the cycle ID 
("Cycle  ID"), followed by the number of threads  and the number 
of locks  ("# of threads /locks  in the cycle ") and the number 
of constraints ( "# of constraints ") before and after constraint 
reduction generated by ConLock  on each cycle . (Note that all the 
constraints before the nearest scheduling points are not counted.)  
The next three major columns show the confirmation probability 
("Probability "), the number of thrashing ( "# of thrashing "), 
and the time consumption (" Time ") by each technique  to confirm 
each cycle , respectively . Note the time consumption is that co n-
sumed by each technique to successfully confirm the correspon d-
ing cycle as a real deadlock or the confirmation run has resulted in 
a preset  timeout for each run (i.e., 60 seconds)  as indicated by " -". 
On cycles c7c11, we cannot precisely collect the normal exec u-
tion time and the time need ed by PCT  because these cycles are on 
MySQL  Server  which is non-stopping  according to the test ha r-
ness used . We also use " -" to indicate these cases.  
The confirmation probability is computed using the formula: sc  
rt, where sc is the number of runs successful ly confirm ing the 
cycle , and rt is the total number of confirmation runs . Note that 
the number of thrashing  occurrence may  not be directly related to 
the confirmation probability  [25].  
Table  3 lists the total number of real deadlocks in each benchmark 
("# of real  deadlocks ") and the total number of such dea d-
locks confirmed by each technique ( "Confirmed ") by at least one  
confirmation run.  Table 1. Descriptive s tatistics and execution stat istics of the benchmarks  (Note: * the # of locks is the # of objects)  
Benchmark  Bug ID  SLOC  Deadlock Description  # of 
threads/  
locks # of  
cycles  # of real  
deadlocks  
(cycle ID)  # of  
data 
races  # of  
events  Java JDBC  
Connector  
5.0  14927  
36,300  Connection .prepareStatement () and Statement .close () 3 / 131* 10 1 (c1) 0 5,050  
31136  PreparedStatement .executeQuery () and Connection .close () 3 / 134* 16 1 (c2) 0 5,080  
17709  Statement .executeQuery () and Conenction .prepareStatement () 3 / 134* 18 2 (c3, c4)  0 5,090  C/C++  SQLite 3.3.3  1672  74,000  sqlite3UnixEnterMutex () and sqlite3UnixLeaveMutex () 3 / 3 2 2 (c5, c6)  1 16 
MySQL  
Server 6.0.4  34567  1,093,600  Alter  on a temporary table and a non -temporary table  17 / 292  322 4 (c7– c10) 405 15,670  
37080  Insert  and Truncate  on a same table using falcon engine  17 / 211  373 1 (c11)  241 15,170  
 4985.3.1 Effectiveness  on Real Deadlocks  
Table  3 shows that PCT  only confirmed 4 out of 11 cases as real 
deadlocks ; MS and DF both confirmed 6 real deadlocks ; and,  
ConLock  confirmed all 11 deadlocks.   
Table 2 shows that ConLock  confirm ed 11 cycles as real deadlocks 
with a probability from  71% to 100% . On confirming cycles c1 to 
c7, ConLock  can always confirm each of these  cycle s as a real 
deadlock in every run; whereas, the other techniques were signif i-
cantly less effective in confirming these cycles as real deadlocks. 
On confirming cycles c8 to c10, all techniques except ConLock  
can only achieve a quite low or zero confirmation probability. 
Specifically , PCT , MS, and DF each had a very low  probability to 
confirm 5 to 7 cycles as real deadlocks , and we highlight the co r-
responding cells in Table 2 to ease readers to reference .  
It is worth noting that PCT  does not rely on any given cycle to 
detect it as a real deadlock. Hence, the comparison with PCT  
should be considered as for reference only.   
The column entitled "# of thrashing " shows that both MS and 
DF encountered thrashing quite frequently. On confirming each of 
c1c4, both MS and DF each encountered thrashing in 44–58 
runs out of 100 runs.  On each of c5c7, they even guide d the 
corresponding confirmation runs to experience  thrashing  with 
very high probabilities . On confirming c8c10, their thrashing 
probabilities are 0. 67 to 0.92, respectively. On confirming c11, 
the number  of thrashing ( 13 occurrences) seems acceptable.  
The MySQL  Server  is the largest benchmark we used in the e x-
periment that has 1,093,600 SLOC. On confirming cycles for this 
benchmark, ConLock  encountered  almost no occurrence of thras h-
ing in the entire experiment  except one on confirming c10. How-
ever, MS and DF encounter ed thrashing much more frequently.  From Table 2, we observe that the number  of constraints after 
reduction ranges from 2 to 6.  This is consistent with an empirical 
study result that a concurrency bug usually needs a "short depth" 
to manife st it [32]. We note that e ven though there  were 2 con-
straints for each of 6 cycles , unlike MS and DF, ConLock  did not 
suffer from thrashing  on confirming these cycles as real dea d-
locks .  
5.3.2 Effectiveness on  False Positives  
To validate the ability of ConLock  on cycles that are false pos i-
tives, w e sampled 87 cycles  out of all 730 cycles  for manual ver i-
fication.  The 87 cycles were sampled by the following rules : (1) 
We selected all 40 ( i.e., 9+15+16) remaining cycles  on JDBC  
Connector . (2) On SQLite , there is not false cycle. (3) On 
MySQL  Server , we selected 1 out of every 15 consecutive cycles  
reported by Magic Lock, which resulted in a total of 47 cycles.  We 
manually inspected and verified that all these 87 cycles were false 
positives , which had already took us about one whole week  to 
complete this manual task . As such  we did not manually verify 
whether the remaining 643 cycles are false positives.   
Table 4 shows the mean  performance of ConLock  on handling the 
87 sampled cycles . The first two column s show the benchmark  
and the bug ID, respectively. The next column  ("# of false  
positives inspected ") shows the average number of false 
positives reported by ConLock  as scheduling violations that we 
manual verified . The last two columns ("Avg.  # of thrashing ") 
and ( "Avg.  Time ") show the mean number of thrashing and the 
mean time for each technique on confirmation run s, respectively.   
From Table 4, to confirm against cycles that were false positives , 
MS and DF were very likely to result in thrashing in the exper i-Table  3. The # of real deadlocks confirmed by each t echnique  
Benchmark  Bug  
ID # of real  
deadlocks  Confirmed  
PCT  MS DF CL 
JDBC  
Connector  
5.0 14927  1 1 1 1 1 
31136  1 0 1 1 1 
17709  2 1 2 2 2 
SQLite 3.3.3  1672  2 2 0 0 2 
MySQL  
Server 6.0.4  34567  4 0 1 1 4 
37080  1 0 1 1 1 
Total  - 11 4 6 6 11 
 Table 2. Experimental results comparisons among  PCT, MagicScheduler  (MS), DeadlockFuzzer  (DF), and ConLock  (CL) 
Cycle  
ID # of  
threads  / locks  
in the cycle  # of constraints  
before / after  
reduction  Probability  # of thrashing  Time (in seconds)  
PCT  MS DF CL PCT  MS DF CL Native  PCT  MS DF CL 
c1 2 2 2 2 0.13 0.47 0.42 1.00 - 53 58 0 0.93 1.49 1.66 1.74 1.60 
c2 2 5 2 2 0.00 0.43 0.43 1.00 - 57 57 0 0.97 - 1.55 1.51 1.52 
c3 2 4 4 2 0.00 0.56 0.55 1.00 - 44 45 0 0.92 - 1.70 1.49 1.51 
c4 2 4 2 3 0.13 0.51 0.49 1.00 - 49 51 0 0.92 1.43 1.44 1.57 1.52 
c5 2 2 4 3 0.19 0.00 0.00 1.00 - 100 100 0 2.00 2.56 - - 2.06 
c6 2 2 4 3 0.13 0.00 0.00 1.00 - 100 100 0 2.00 2.76 - - 2.07 
c7 2 3 2,100  2 0.00 0.00 0.00 1.00 - 95 100 0 - - - - 2.36 
c8 2 3 2,102  2 0.00 0.16 0.22 0.71 - 78 67 0 - - 2.65 2.15 3.81 
c9 2 3 2,086  3 0.00 0.00 0.00 0.75 - 91 80 0 - - - - 4.62 
c10 2 3 2,088  6 0.00 0.00 0.00 0.88 - 92 78 1 - - - - 2.65 
c11 2 8 58 2 0.00 0.86 0.85 0.90 - 11 13 0 - - 0.91 0.84 0.86 
 
Table 4. Average performance of ConLock  on false positives 
(Note: there is no false warning on SQLite ; "-" means time out in 
every  run. PCT  is excluded due to its insensitiveness to a given cycle ) 
Benchmark  Bug  
ID # of false  
positives 
inspected  Avg. # of  
thrashing  Avg. Time  
(in seconds)  
MS DF CL MS DF CL 
JDBC  
Connector  
5.0 14927  9 100 100 0 - - 1.66 
31136  15 100 100 0 - - 1.74 
17709  16 100 100 0 - - 1.68 
MySQL  
Server 6.0.4  34567  22 91 83 2 - - 7.85 
37080  25 95 91 0 - - 5.34 
 499ment; whereas ConLock  only encountered a small number (e.g., 2 
in the row entitled MySQL  Server ) of thrashing .1  
5.3.3 Performance  
From  the column  entitled "Time " in Table 2, the runtime ove r-
heads incurred by MS, DF, and CL on successful confirmations 
are quite close to one another, and the absolute time needed are all 
practical. Note that there are much more number s of thrashing 
occurrences incurred by  MS and DF than CL on each row,  and on 
confirming cycles c5-c6, MS and DF simply suspend ed some 
threads until the timeout was reached.  
From Table 4, we observe that CL can terminate a confirmation 
run against a false positive much earlier than MS and DF. We also 
found that CL can report a scheduling violation in each case, ex-
cept in one confirmation run where a thrashing has occurred.   
We have experimented to configure CL using  the whole set of 
constraints without  reduction  and scheduling points . However, on 
large -scale programs (i.e., MySQL ), this configuraiton encountered 
many thrashing occurrences and incurred significant slowdown .  
5.4. Threats to Validity  
We have not manually validated all identified cycle s on MySQL  
Server  due to our time and effort constraints . The probability, 
the ratios of thrashing , and the time taken by the techniques may 
be different if different numbers of runs, different benchmarks, 
and tool implementations were used to conduct the experiment.  
Our im plementation is based on binary instrumentation. An 
implementation  of ConLock  through symbolic execution  [10][31] 
might produce more effective result s (e.g., higher confi rmation 
probability)  as the constraints can be determined more precisely . 
However, symbolic execution is still not scalable to  handle  large -
scale programs as noted in [17] that "the largest programs that 
can be symbolically executed today are on the order of thousands 
of lines of code ". In our benchmarks, MySQL Server  has millions 
of source lines of codes  (i.e., SLOC) , which is far out of the 
ability of state-of-the-art symbolic execution engine s to handle.  
6. RELATED WORK  
Many predictive deadlock detection techniques  [5][12][18][24] 
[36][40][43] have been proposed . MagicLock  [12][15] is the state -
of-the-art dynam ic technique. They all suffer from reporting false 
positives. Real deadlocks of them should be isolated . Kahlon et al. 
[28] proposed a static theor etical model for analysis of concurre n-
cy bugs in programs with well nested lock acquisitions and r e-
leases. However, the lock acquisitions and releases in modern 
real-world programs (e.g., Java and C/C++) are usually not well -
nested and there exists a huge gap between static model s and the 
modern programming languages [21]. Hence, unlike ConLock , 
their model cannot handle the occurrence of thrashing. Marino et 
al. [35] proposed a static approach for detecting deadlocks in o b-
ject-oriented programs with data -centric synchronizations. Their 
approach needs manual annotations to identify the ordering b e-
tween atomic -sets. ConLock  is a fully automated dynamic a p-
proach.  
DeadlockFuzzer  [25] is the first technique that proposes to use the 
lock dependencies  (i.e., a variant of  event  in this paper)  to detect  
cycles  and to schedule the program execution to confirm cycles  as 
 
1 We note that on the remaining 643 cycles (which we have not manually 
verified them to be false positives), ConLock  reported scheduling viol a-
tions in at least 60 runs out of 100 on each cycle, and did not report any 
deadlock occurrence on checking them in a ny confirmation run.  real deadlocks . MagicScheduler  (the third phase of MagicFuzzer  
[15]) advances DeadlockFuzzer  by allowing multiple cycles to be 
confirmed in the same run.  We have intensively reviewed these 
two schedulers and compared them with our ConLock  technique.   
In [13], we proposed  ASN , the first constraint based real deadlock 
confirmation technique.  ASN  extracts constraints from  the given 
cycle s and formulates them as barriers . However, ASN  cannot 
handle false positive s. ConLock  is able to detect scheduling viol a-
tion to terminate an execution with respect to  false positive s; on 
real deadlocks, like ASN , it is also able to confirm them with high 
probabilities  and low slowdown overheads .  
Java Path Finder (JPF) has the potential to  explore all possible  
schedules  from a single input . These schedules can  be integrated 
with a deadlock detector to find deadlocks . However, these tech-
niques  are unable to handle large -scale multithreaded programs  
(e.g., MySQL ) even with the use of symbolic execution [17]. Syn-
chronization coverage techniques [22][39][44] may e xplore mu l-
tiple schedules of the same input, but they do not handle infeas i-
ble coverage requirements adequately.  
Dimmun ix [26][27] prevent s the re -occurrence of each previously 
occurred deadlock  through online monitoring . Gadara  [42] inserts 
deadlock avoidance code at the gate position of each deadlock  
warning via static analysis  and then  prevent s deadloc k occurrence  
at runtime . Nir-Buchbinder et al. [37] used an execution serializ a-
tion strategy for deadlock healing. These techniques develop and 
utilize no constraints  among different threads  and do not choose 
any nearest scheduling point  (needed by ConLock ). Besides, Dim-
munix  and Gadara  suffer from false positives; deadlocking healing 
may introduce new deadlocks  [37].  
ESD  [45] synthesizes an executio n from a  core dump of a prev i-
ous execution  with deadlock occurrence . ConLock  can take a cycle 
(irrespective of whether it is a deadlock) as an input. Both Con-
Test [19] and CTrigger  [38] inject noise to a run to increase the 
probability to trigger concurrency bugs. ConLock  is not complet e-
ly an active randomized scheduler, and need s not to adopt such a 
strategy.  PENELOP E [41] also synthesizes an execution and uses 
a scheduling strategy similar to DeadlockFuzzer  and MagicSche d-
uler to detect real atomicity violation s. It does not use constraints 
to avoid thrashing . ConLock  uses constraints and scheduling point s 
and is able to detect false positives .  
Replay  techniques (e.g., [6]) are able to reproduce runs that co n-
tain concurrency bugs. However, they are unable to turn a run 
containing a suggested cycle into a run containing a real deadlock.   
7. CONCLUSION  
ConLock  analyzes a given execution trace and a cycle on this trace 
to generate  a set of constraints and a set of nearest scheduling 
points. It schedules a confirmation run with the aim to not violat e 
a reduced  set of constraints from the chosen nearest scheduling 
points . ConLock  not only confirms real deadlocks, but also report s 
schedul ing violations if the given cycles are false positives. The 
experimental results show that ConLock  can be both effective and 
efficient . We will generalize  ConLock  to confirm other types of 
concurrency bugs  effectively and efficientl y in the future . 
8. ACKNOWLEDGMENTS   
We thank anonymous reviewers for their invaluable comments 
and suggestions. This work is supported in part by the General 
Research Fund and the Early Career Scheme of the Research 
Grant Council of Hong Kong (project nos. 111313 and 123512).  5009. REFERENCES  
[1] ASM 3.2, http://asm.ow2.org . 
[2] JDBC Connector 5.0, http://www.mysql.com . 
[3] MySQL Database Server 6.0.4, http:// www.mysql.com . 
[4] SQLite 3.3.3, http://www.sqlite.org . Bug ID: 1672.  
[5] R. Agarwal, L. Wang, and S. D. Stoller. Detecting potential 
deadlocks with static analysis and run -time monitoring . In 
Proceedings of  the 2005 IBM Veriﬁcation Conference , 2005.  
[6] G. Altekar and I. Stoica. ODR: output -deterministic replay 
for multicore debugging. In Proc. SOSP , 193 –206, 2009.  
[7] S. Bensalem and  K. Havelund . Scalable dynamic deadlock 
analysis of multi -threaded program s. In PADTAD , 2005.  
[8] S. Bensalem, J.C. Fernandez, K. Havelund, and L. Mounier. 
Confirmation of deadlock potentials  detected by runtime 
analysis. In Proc. PADTAD , 41−50, 2006.  
[9] S. Burck hardt, P. Kothari, M. Musuvathi, and S. Nagar a-
katte. A randomized scheduler with probabilistic guarantees 
of finding bug s. In Proc. ASPLOS , 167 –178, 2010.  
[10] C. Cadar , D. Dunbar, D. Engler, KLEE: unassisted and a u-
tomatic generation of high -coverage tests for  complex sy s-
tems programs. In Proc. OSD I, 209 –224, 2008.  
[11] Y. Cai and W.K. Chan. Lock trace reduction for multithrea d-
ed programs. IEEE Transactions on Parallel and Distributed 
Systems  (TPDS ), 24(12) : 2407−2417, 2013.  
[12] Y. Cai and W.K. Chan. Magiclock: scalable  detection of 
potential deadlocks in large -scale multithreaded programs . 
IEEE Transactions on Software Engineering  (TSE), 201 4. 
http://dx.doi.org/10.1109/TSE.2014.2301725 . 
[13] Y. Cai, C.J. Jia, S.R. Wu, K. Zhai, and W.K. Chan. ASN: a 
dynamic barrier -based appr oach to confirmation of dea d-
locks from warnings for large -scale multithreaded programs. 
IEEE Transactions on Parallel and Distributed Systems  
(TPDS ), 2014. 
http://dx.doi.org/10.1109/TPDS.2014.2307864 . 
[14] Y. Cai and W.K. Chan. LOFT: redundant synchronization 
event removal for data race detection . In Proc. ISSRE , 160 –
169, 2011.  
[15] Y. Cai and W.K. Chan. MagicFuzzer: scalable deadlock 
detection for large -scale application s. In Proc. ICSE , 606 –
616, 2012.  
[16] Y. Cai, K. Zhai, S.R. Wu, and W.K. Chan. TeamWork: syn-
chronizin g threads globally to detect real deadlocks for mu l-
tithreaded programs.  In Proc. PPoPP , 311–312, 2013.  
[17] V. Chipounov, V. Georgescu, C. Zamﬁr, and G. Candea. 
Selective symbolic execution. In Workshop on Hot Topics in 
Dependable Systems , 2009.  
[18] J. Deshmukh, E.  A. Emerson, and S. Sankaranarayanan. 
Symbolic deadlock analysis in concurrent libraries and their 
clients . In Proc. ASE, 480 –491, 2009.  
[19] E. Farchi, Y. Nir -Buchbinder, and S. Ur. A cross -run lock 
discipline checker  for Java. In PADTAD , 2005.  [20] C. Flanagan and  S. N. Freund. FastTrack: efficient and pr e-
cise dynamic race detection. In Proc. PLDI , 121 –133, 2009.  
[21] A. Gupta. Verifying concurrent programs: tutorial talk. In 
Proc. FMCAD , 1, 2011.  
[22] S. Hong, J. Ahn, S. Park, M. Kim, and M.J. Harrold. Testing 
concurrent pr ograms to achieve high synchronization cove r-
age. In Proc. ISSTA , 210 –220, 2012.  
[23] P. Joshi, M. Naik, C.S. Park, and K.  Sen. CalFuzzer: an ex-
tensible active testing framework for concurrent progr ams. In 
Proc. CAV , 675 –681, 2009.  
[24] P. Joshi, M. Naik, K . Sen, and  D. Gay. An effective dynamic 
analysis for detecting generalized deadloc ks. In Proc. FSE, 
327–336, 2010.  
[25] P. Joshi, C.S. Park, K. Sen, amd M. Naik. A randomized 
dynamic program analysis technique for detecting real dea d-
locks. In Proc. PLDI , 110 –120, 2009 . 
[26] H. Jula, D. Tralamazza, C. Zamfir, and G. Candea. Deadlock 
immunity: enabling systems to defend against deadlocks . In 
Proc. OSDI , 295 –308, 2008.  
[27] H. Jula, P. Tozun, G. Candea. Communix: A framework for 
collaborative deadlock immunity . In Proc. DSN , 181 –188, 
2011.  
[28] V. Kahlon, F. Ivančić, and A. Gupta. Reasoning about 
threads communicating via locks. In Proc . CAV , 505 –518, 
2005.  
[29] L. Lamport. Time, clocks, and the ordering of events in a 
distributed system . Communications of the ACM , 21(7):  558–
565, 1978.  
[30] Z.F. La i, S.C. Cheung, and W.K. Chan, Detecting atomic -set 
serializability violations for concurrent programs through a c-
tive randomized testing. In Proc. ICSE , 235 –244, 2010.  
[31] C. Lattner , V. Adve, LLVM: A Compilation Framework for 
Lifelong Program Analysis & Trans formation. In Proc. 
CGO , 7588, 2004.  
[32] S. Lu, S. Park, E. Seo, Y.Y. Zhou. Learning from mistakes: a 
comprehensive study on real world concurrency bug chara c-
teristic s. In Proc. ASPLOS , 329 –339, 2008.  
[33] C.-K. Luk, R. Cohn, R. Muth, H. Patil, A. Klauser, G. Lo w-
ney, S. Wallace, V. J. Reddi, and K. Hazelwood. Pin: build-
ing customized program analysis tools with dynamic instr u-
mentat ion. In Proc. PLDI , 191 –200, 2005.  
[34] Z.D. Luo, R. Das, and Y. Qi. MulticoreSDK: a practical and 
efficient deadlock detector for real -world applic ations. In 
Proc. ICST , 309 –318, 2011.  
[35] D. Marino, C. Hammer, J. Dolby, M. Vaziri, F. Tip, and J. 
Vitek. Detecting deadlock in programs with data -centric sy n-
chronization. In Proc. ICSE , 322 –331, 2013.  
[36] M. Naik, C.S. Park, K. Sen, and D. Gay. Effective  static 
deadlock detection . In Proc. ICSE , 386 –396, 2009.  
[37] Y. Nir -Buchbinder, R. Tzoref, and S. Ur. Deadlocks: from 
exhibiting to healing . In Proc. RV, 104 –118, 2008.  501[38] S. Park, S. Lu, and Y.Y. Zhou. CTrigger: exposing atomicity 
violation bugs from their hidi ng pla ces. In Proc. ASPLOS , 
25–36, 2009.  
[39] N. Rungta, E.G. Mercer, W. Visser. Efficient testing of co n-
current programs with abstraction -guided symbolic exec u-
tion. In Proc. SPIN , 174 –191, 2009.  
[40] V.K. Shanbhag. Deadlock -detection in java -library using 
static -analysis.  In Proc. APSEC , 361 –368, 2008.  
[41] F. Sorrentino, A. Farzan, and P. Madhusudan. PENELOPE: 
weaving threads to expose atomicity violations. In Proc. 
FSE, 37–46, 2010.  
[42] Y. Wang, T. Kelly, M. Kudlur, S. Lafortune, and S. Mahlke. 
Gadara: dynamic deadlock avoidance for multithreaded pr o-
gram s. In Proc. OSDI , 281 –294, 2008.  [43] A. Williams, W. Thies, and M.D. Ernst. Static  deadlock d e-
tection for java libraries.  In Proc. ECOOP , 602 –629, 2005 . 
[44] J. Yu, S Narayanasamy, C. Pereira, and G. Pokam. Maple: a 
coverage -drive n testing tool for multithreaded programs. In 
Proc. OOPSLA , 485 –502, 2012.  
[45] C. Zamfir and G. Candea. Execution synthesis: a technique 
for automated software debuggin g. In Proc. EuroSys , 321 –
334, 2010.  
[46] K. Zhai , B.N. Xu, W.K. Chan, and T.H. Tse. CARISMA: a 
context -sensitive approach to race -condition sample -instance 
selection for multithreaded applications. In Proc.  ISSTA , 
221–231, 2012 . 
 502