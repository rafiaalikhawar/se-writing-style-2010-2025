Studying Task Allocation Decisions of Novice Agile Teams
with Data from Agile Project Management Tools
Jun Lin1,2, Han Y u1, Zhiqi Shen1, and Chunyan Miao1
1School of Computer Engineering, Nanyang T echnological University, Singapore
2School of Software, Beihang University, Beijing, China
1{jlin7, han.yu, zqshen, ascymiao}@ntu.edu.sg,2linjun@buaa.edu.cn
ABSTRACT
Task allocation decisions are critical for the success of Agile
teamsyetnotwellunderstood. Traditionalsurvey/interviewbased methods limit the scale and level of details of datacollection. As agile project management (APM) tools areincreasingly adopted, they oﬀer a mechanism for unobtru-sively collecting behavior data to support research. In thispaper, we demonstrate the advantage of APM tool basedmethod of studying task allocation decision-making in ag-ile software engineering compared to survey/interview basedmethods. Through the proposed HASEonline APM tool,
we conducted a study involving 20 novice Agile teams con-sisting of 119 undergraduate software engineering studentsover an 8 week period. Analysis of the collected data pro-vides insight into the eﬀects of novice Agile team members’competence and the diﬃculty of the tasks assigned on themon their workload variation, their conﬁdence, and the time-liness of completion of these tasks. These ﬁndings can beuseful in designing situation-aware task allocation decisionsupport systems to serve Agile teams.
Categories and Subject Descriptors
D.2.8[Software Engineering ]: Metrics—performance mea-
sures
Keywords
Agile project management tool; unobtrusive data collection;task allocation decision-making
1. INTRODUCTION
In recent years, Agile software development (ASD) is s-
tarting to be used not only by small development team-s, but also large software companies [2]. Among the ASDmethodologies, Scrumand its variants are the most wide-
ly used (adopted by over 70% of agile teams [1]). Scrumis an iterative and incremental ASD methodology. It con-sists of six phases as shown in Figure 1: 1) conceptualiza-
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributedfor proﬁt or commercial advantage and that copies bear this notice and the full cita-tion on the ﬁrst page. Copyrights for components of this work owned by others thanACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-publish, to post on servers or to redistribute to lists, requires prior speciﬁc permissionand/or a fee. Request permissions from permissions@acm.org.ASE’14, September 15-19, 2014, V asteras, Sweden.
Copyright 2014 ACM 978-1-4503-3013-8/14/09 ...$15.00.http://dx.doi.org/10.1145/2642937.2642959.tiondeﬁnes the high level deliverables and project roadmap;
2)release planning assigns deliverables into diﬀerent releas-
es; 3)sprint planning breaks down selected deliverables into
technical tasks; 4) in each sprint(e.g., a 7 day period), soft-
ware development tasks are to be completed by ASD team
members; 5) in sprint review/retrospective , team members
demonstrate the product increments and reﬂect on experi-ence gained from the last sprint; and 6) during releasethe
working software is delivered to the customers [3].
The sprint planning phase is crucial for the success of a
project. Task need to be allocated to team members whiletaking into account task precedence, balancing team mem-bers’ workload, and ensuring quality. Compared to tradi-tional methods of software development, decision making byASD teams often exhibit diﬀerent characteristics. In [7, 8],the advantages for providing automated decision support toASD teams during the sprint planning phase to help themmake eﬀective workload-quality trade-oﬀs when allocatingtasks have been illustrated. These systems can be especiallybeneﬁcial for novice teams who are new to the agile practice.Inordertobringsuchdecisionsupportsystemsintopractice,understanding the decisions making tendencies exhibited byagile teams is important.
Recently, a number of studies have been conducted to in-
vestigate the decision-making process of ASD teams [4, 5,11]. However, these studies mostly gather data through in-terviews and surveys. This often limits the scale of the studyand lack detailed data reﬂecting the ASD teams’ task alloca-
Conceptualization
Release Planning
Sprint Planning
Sprint
Sprint Review/
Retrospective
Release
Figure 1: The Scrum agile software development
process.
689
tiondecisiontendencies. Nevertheless, onerecenttrendASD
project management has laid the foundation to signiﬁcant-ly improve researchers’ understanding of the task allocationdecision tendencies of ASD teams. An increasing percentageof ASD teams are using agile project management (APM)tools [1] such as Scrumwise
1. These software tools provide
intuitive interfaces for decisions regarding each phase of theASD process be easily expressed by team members. Thedecisions, together with their eﬀects on ASD team perfor-mance, can be recorded in detail to facilitate data-drivenunderstanding of task allocation decision-making.
In order to investigate how useful data from such tools
can be for for studying the ASD process, we designed anonline APM tool - the Human-centred Agile Software En-gineering (HASE )p l a t f o r m
2. It helps ASD teams manage
their projects while unobtrusively tracking data generatedduring the ASD process to support research in this domain.To understand how valuable data collected from APM toolscan be to studying ASD task allocation decision tendencies,we used the HASE platform to conduct a study involving 20novice ASD teams consisting of 119 undergraduate softwareengineering students over a period of 8 weeks. To the bestof our knowledge, this study is the ﬁrst large scale studyof task allocation behaviors exhibited by novice ASD team-s. By analyzing task allocation decisions made for over 700software engineering tasks by the participants through theExploratory Data Analysis (EDA) approach [9], we demon-strate the scientiﬁc research potential of APM tools by iden-tifying three signiﬁcant tendencies exhibited by novice ASDteams when allocating tasks.
2. RELATED WORK
Studies about the decision-making process of ASD team-
s started to emerge in recent years. In [11], the authorsinvestigated decisions related to software designs. They em-ployed content analysis and explanation building to extractqualitative and quantitative results from interviews with 25software designers. The study ﬁnds that the structure ofthe design problem determines the designers choice betweenrational and naturalistic decision making.
Thestudyin[4]focusedondecision-makingbyASDteam-
s. It examined decisions made across the four stages of thesprint cycle: sprint planning, sprint execution, sprint reviewand sprint retrospective. The authors employed the tech-nique of focus group study with 43 Agile developers andmanagers to determine what decisions were made at diﬀer-ent points of the sprint cycle. In another publication by thesame research group [5], interviews with an additional 18professional Agile practitioners from one global consultingorganization, one multinational communications company,two multinational software development companies, and onelarge museum organization were analyze to identify six keyobstacles facing decision making in Agile teams.
Nevertheless, thetechniquesusedbyexistingstudiesmain-
ly involve interviews and surveys. This limited the scaleof the study as well as the level of details of the collecteddata. As a result, the form of ﬁndings from such studiestend to be qualitative in nature. For instance, in [4], someobstacles facing agile teams during sprint decision-makingcan“people are unwilling to commit to a decision”,“lack of
1https://www.scrumwise.com/
2http://www.linjun.net.cn/hase/ownership” and “lack of empowerment”. There is a lack ofquantitative results indicating the extent of each obstaclefacing agile team members with diﬀerent competence levels.Furthermore, existing studies focused on ASD teams whoare already proﬁcient in applying agile development meth-ods. They did not provide insight into the decision-makingtendencies exhibited by novice ASD teams who are more inneed of automated decision support.
3. THE HASE PLATFORM
HASE is an online APM tool. It provides ﬁve main fea-
tures to support agile project management which cover thesprint planning ,sprint,a n dsprint retrospective phasesshown
in Figure 1:
1.Registration : In order to build user proﬁles, HASE
requires registrants to specify their self-assessed com-petence levels in diﬀerent areas of expertise such as fa-miliarity with speciﬁc programming languages, systemdesign methodologies, and user interface (UI) designtools, etc.
2.Team and Role Management : HASE supports the cre-
ation of teams, the selection of product owners andstakeholders into the teams, and the assignment of d-iﬀerent roles within a team (e.g., programmers and UIdesigners).
3.Task Management : Task information including task
description, skills required for the task, under whichdeliverable each task belongs to, and the person whoproposed each task is displayed for all team membersto view. The diﬃculty value (Diff
τ)o fe a c ht a s kτ ,
is recorded using an 11-point Likert scale [6] (with 0denoting“extremely easy”and 10 denoting“extremelyhard”). Team members can determine the diﬃcultyvalue of each task together and input the value intothe HASE platform.
4.Sprint Planning : HASE records the teams’ decisions
on which tasks are assigned to which team member.Once assigned, the status of the task becomes “As-signed”. The assignee iinputs his/her conﬁdence val-
ue (Conf
i
τ)f o re a c ht a s kτ on an 11-point Likert scale
(with 0 denoting“not conﬁdent at all”and 10 denoting
“extremely conﬁdent”). The assignees also record the
estimated required time (Test
τ) to complete each task
( i nn u m b e ro fd a y s ) .
5.Sprint Retrospective : Once a task is completed, the
assignee changes its status in the HASE platform to
“Completed”. This action will trigger HASE to record
the actual number of days (Tact
τ) used to complete this
task. HASE also provides functions for team membersto peer review the quality ( Qual
τ)o fe a c hc o m p l e t e d
taskτ.T h eq u a l i t yo fac o m p l e t e dt a s ki sr e c o r d e di n
the platform as either 0 (“unsatisfactory”) or 1 (“satis-factory”).
The input data to the HASE platform required from ASD
teams are generated as a result of their activities followingthe Scrum methodology. In this way, users of HASE can be-have as if they are using any APM tool without expendingadditional eﬀort. Thus, the data collection process remain-s unobtrusive to the ASD team members. Over time, the
690user proﬁle information, task information, task allocation
decisions, and the timeliness and quality of completed taskscan reveal insight into ASD teams’ behavior patterns that isuseful for building automated task allocation decision sup-port systems.
4. RESEARCH DESIGN
In order to demonstrate the potential for APM tools in
providing new insight into the behavior patterns of AS-D teams, we conducted a study involving 119 undergrad-uate software engineering students in the Beihang Univer-sity (BUAA), China in 2013 using the HASE platform. Aspart of their curriculum, they were required to complete asoftware engineering project using the Scrum agile develop-ment methodology over a period of 8 weeks. The studentswere introduced to the concept of agile software engineer-ing during lecture sessions of the same course. They hadno hands-on experience with the Scrum methodology beforethe coursework project.
The students were asked to form into teams of ﬁve to
s e v e np e r s o n se a c hb yt h e i ro w nc h o i c e . E a c ht e a mw a srequired to produce a working software system at the endof the project. The project proposals were reviewed andapproved by the course instructor to ensure that they wereof similar scale and complexity across all teams. The projectwasdividedinto8 sprints. Eachsprint lasted7 days. Duringa sprint, each team analyzed their own proposed project toidentify tasks that need to be completed in order to producethe required software. Tasks were divided among the teammembersatthebeginningofeachsprintbasedondiscussionswithin each team. Each participant may be assigned 0, 1, ormultiple tasks during each sprint. A total of 732 tasks wereproposed by all the teams during this study. The percentageof all tasks being rated as each of the 11 diﬃculty values areshown in Figure 2. Tasks with diﬃculty values from 5 to 8forms the majority of all tasks (i.e. 57.87%).
Apart from these contextual data, we use the task quality
evaluation data and the task completion time data obtainedfrom the sprint retrospective phase to compute an estima-tor for each team member’s competence. This estimator isreferred to as a team member’s competence score (Comp
i).
0 1 2 3 4 5 6 7 8 9 1002468101214161820
Task Difficulty% of All Tasks
Figure 2: The distribution of task diﬃculty values.It is computed using the BRSEXT method [10] as follows:
Comp i=αi+1
(αi+1)+(βi+1)(1)
whereαiandβiare calculated as:
αi=/summationdisplay
τ∈φ(i )1[Tactτ−Testτ≤0andQualτ=1](2)
βi=/summationdisplay
τ∈φ(i )1[Tactτ−Testτ>0orQualτ=0] (3)
1[condition ]equals to 1 if “condition” is true. Otherwise,
1[condition ]equals to 0. In essence, αirepresents the total
number of tasks that have been completed on time with sat-isfactory quality by a team member i, whereas β
irepresents
the total number of tasks that have not been completed ontime or with unsatisfactory quality by the team member i.
In this way, Comp
ican be interpreted as the probability of
icompleting a given task on time with satisfactory quali-
ty.Comp i∈(0,1) where 0 indicates that iis completely
incompetent, and 1 indicates that iis completely compe-
tent. During initialization when ihas no past record (i.e.
αi=βi=0 ) ,Comp iequals to 0.5 indicating that i’s com-
petence is uncertain.
5. RESULTS AND DISCUSSIONS
With the dataset on participants’ task allocation decisions
collected, we adopt the Exploratory Data Analysis (EDA)approach [9] to understand whether new insight into noviceagile teams’ task allocation behavior can be derived. EDAis an approach to summarize the main characteristics of adataset. Speciﬁcally, we investigate three aspects of task al-location decision-making which traditional interview/surveybased studies have diﬃculty investigating. They are: 1)how team members’ competence inﬂuences their workload;2) how team members’ competence inﬂuences their conﬁ-dence on tasks with various diﬃculty values; and 3) howteam members’ competence inﬂuences the timeliness of com-pleting tasks with diﬀerent diﬃculty values. In this section,we discuss the analysis results.
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 10510152025
Competence Score% of PopulationTeams adopting CA
Teams adopting EA
Figure 3: The distribution of team members’ com-petence scores.
6910 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 10510152025303540
Team Member Competence ScoresTotal Number of Tasks Assigned to Each Team Member
(a) Total workload distribution under CA2468
0.40.60.8100.511.52
WeekCompetenceAverage No. of Tasks per Person
(b) Workload distribution under CA by week
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 10510152025303540
Team Member Competence ScoresTotal Number of Tasks Assigned to Each Team Member
(c) Total workload distribution under EA2468
0.40.60.8100.511.52
WeekCompetenceAverage No. of Tasks per Person
(d) Workload distribution under EA
Figure 4: Results reﬂecting relationships between ASD team members’ competence scores and their workload.
5.1 Competence and Workload
At the end of the study, participants were asked to state
the approaches adopted by their teams when determining
how to distribute tasks among team members. The teamscan be divided into those who adopted a Competence-based
Approach (CA), and those who adopted an Equality-based
Approach (EA). Teams who reported that they allocated
tasks evenly among team members are classiﬁed under theEA group, while those who reported that they attemptedto allocate more tasks to more capable team members areclassiﬁed under the CA group. Since the team members’competence scores were computed after the study was ﬁn-ished, participants in the CA group did not have access tothis information and relied on their own experience to de-termine each others’ competence. The CA group consists of58 people while the EA group consists of 61 people. Thepercentage distributions of participants with diﬀerent com-petence scores for the CA and the EA groups are illustratedinFigure3. Itcanbeobservedthatthetwogroupsconsistofmembers with similar competence score distributions. TheCA and EA approaches allow the teams to make relativelysimple trade-oﬀs between team members’ competence andthe fairness of task distribution. This helped the teams tosimplify their discussions about task allocation during sprintplanning meetings.
Figure 4(a) and Figure 4(c) illustrate the total workload
over the 8 weeks for team members in the CA and EAgroup respectively against their competence scores. The to-tal workload is measured by the number of tasks allocat-ed to each individual. The Pearson Correlation Coeﬃcient
(PCC) between team members’ total workload values andcompetence scores under CA is 0.343 indicating that morecompetent members tend to be assigned more task; whilethat under EA is only 0.077 indicating almost no correlationbetween team members’ competence and their workload.
The average number of tasks per individual with diﬀer-
ent competence scores during each week of the courseworkunder CA and EA are plotted in Figure 4(b) and Figure4(d) respectively. It can be observed from Figure 4(b) thatinitially in Week 1 and Week 2, there were two prominentpeaks coinciding with participants with competence scoresaround 0.8 and 0.5. At this time when the team memberswere not yet familiar with each other, they relied on teammembers’ self-reported competence to direct task allocationdecisions. As the team members became more familiar witheach other over the weeks, especially with the help of sprintretrospective meetings during which team members’ perfor-
692mance were assessed, more workload was being assigned to
team members with higher competence. As participants didnot use any systematic method to keep track of their com-petence scores, the workload distributions are not monoton-ically increasing with competence scores. From Figure 4(d),it can be seen that for EA teams, the task distributions re-main relatively unchanged over the eight week period of thestudy. The average number of tasks per person under EA is0.998 with a standard deviation value of 0.051.
5.2 Competence, Difﬁculty and Timeliness
Figure 5(a) shows the relationship between participants’
competence scores, the normalized diﬃculty values of thetasks assigned to them, and their estimated time requiredto complete the given tasks (in number of days). In this ﬁg-ure, the x-axis represents the value of
Comp i
Diffτ. In the dataset,
no task was rated by participants as having a diﬃculty valueof 0. Thus,
Comp i
Diffτ∈(0,10). IfComp i
Diffτ>1, it means that
an ASD team member iis assigned a task τwith a normal-
ized diﬃculty value lower than i’s competence score. In this
case,iis more likely to be able to complete this task on time
10010101234567
Team Member Com petence Scores / Normalized Task Difficult yEstimated Time Required (Days)
(a) Estimated time required v.s. competence scores
and normalized task diﬃculty values
−6 −4 −2 0 2 4 60102030405060708090100
(Estimated Required Time − Actual Time Taken) (Days)% of All Tasks in Each Sub−groupCompetence Score/Task Difficulty <= 1.0
Competence Score/Task Difficulty > 1.0
(b) Timeliness v.s. competence scores and normalizedtask diﬃculty values
Figure 5: Results reﬂecting novice Agile team mem-
bers’ behavior in estimating required time.with satisfactory quality. IfComp i
Diffτ≤1,iis assigned a task
τwith a normalized diﬃculty value higher than or equal
toi’s competence score. In this case, iis less likely to be
able to complete this task on time with satisfactory quality.From Figure 5(a), it can be observed that when
Comp i
Diffτ>1,
the PCC value between the estimated required time and
Comp i
Diffτis−0.477, which indicates a signiﬁcant negative cor-
relation. The average estimated required time is 3.91 days.The higher the value of
Comp i
Diffτ, the shorter the estimated
required time. However, whenComp i
Diffτ≤1, the PCC value
between the estimated required time andComp i
Diffτis reduced
signiﬁcant to −0.146. The average estimated required time
also increases signiﬁcantly to 5.64 days.
To investigate the eﬀect of theComp i
Diffτvalue on the time-
liness of completing tasks (i.e. whether tasks are completedbefore the estimated required time), we use another metric-t h eearly completion days. It is the diﬀerence between theestimated number of days required and the actual numberof days used to complete a given task (i.e. T
est
τ−Tact
τ).
IfTest
τ−Tact
τ=0 ,t h et a s k τis completed “on time”; if
Test
τ−Tact
τ>0,τis said to be completed“ahead of time”;
otherwise, τis said to be “overdue”. From Figure 5(b), in
cases whereComp i
Diffτ>1, more than 50% of the tasks were
c o m p l e t e do nt i m e ,w h e r e a sw h e nComp i
Diffτ≤1, less than 30%
of the tasks were completed on time. The average early com-pletion days for cases where
Comp i
Diffτ>1i s0 . 4 7d a y sw h e r e a s
in the cases whereComp i
Diffτ≤1, it is -0.09 days.
5.3 Competence, Difﬁculty and Conﬁdence
Figure 6 shows the participants’ self-reported conﬁdence
for the tasks assigned to them. They reported the highestlevel of conﬁdence (i.e., 10) for over 50% of all tasks dur-ing the study. Intuitively, the more competent a participantis, and the less diﬃcult the task assigned to him/her, themore conﬁdent he/she should be about the assigned task.To test this intuition, we normalized the self-reported conﬁ-dence by all participants into the range of [0,1] and plottedthem against their competence scores for tasks with diﬀer-ent diﬃculty values in Figure 7. The tasks are divided intothree groups based on their diﬃculty values as assessed by
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 10102030405060708090100
Normalized Self −Reported Confidence% of All Tasks
Figure 6: The distribution of team members’ self-reported conﬁdence values for all tasks.
6930 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 100.10.20.30.40.50.60.70.80.91
Team Member Competence ScoresNormalized Self −reported Confidence
(a) For Tasks with EasyDiﬃculty0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 100.10.20.30.40.50.60.70.80.91
Team Member Competence ScoresNormalized Self −reported Confidence
(b) For Tasks with Medium Diﬃculty0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 100.10.20.30.40.50.60.70.80.91
Team Member Competence ScoresNormalized Self −reported Confidence
(c) For Tasks with HardDiﬃculty
Figure 7: Results reﬂecting novice Agile team members’ behavior in estimating risk.
the teams: 1) easy tasks (0≤Diffτ≤3); 2)medium tasks
(4≤Diffτ≤7); and 3) hard tasks (8≤Diffτ≤10).
The relationship between team members’ competence s-
cores and their normalized conﬁdence for easy, medium, and
hard tasks are illustrated in Figures 7(a), 7(b), and 7(c)respectively. For easy tasks, the PPC value between nor-malized conﬁdence and team members’ competence scoresis 0.667, which indicates a strong positive correlation (i.e.the more competent a team member is, the more conﬁden-t he/she is about an easy task assigned to him/her). Thiscorrelation becomes only weakly positive (i.e. PPC = 0.159)withregardtomediumtasks. Whenassignedhardtasks, thecorrelation becomes weakly negative (i.e. PPC = −0.179).
In this case, team members with high competence scores be-camemorereservedandreportedlowerconﬁdencevalues. Incontrast, team members with low competence scores tend tobe over conﬁdent when assigned tasks with medium or harddiﬃculty values.
6. CONCLUSIONS AND FUTURE WORK
As APM tools are increasingly adopted by ASD teams,
they oﬀer researchers a new source of unobtrusively collect-ed behavior data that provide insight into the characteristic-s and eﬀects of decision-making which cannot be extractedfrom traditional survey and interview based study methods.Through a study involving 119 student participants over 8weeks with the proposed HASE APM tool, we demonstratethe scientiﬁc research potential of APM tools. This mannerof data collection occurs during normal usage of the APMtool and does not introduce additional overhead to the ASDteams. In addition, as team members are not put into aformal situation in which they know they are being studied,the behavior patterns captured by such data is more likelyto reﬂect their real behavior. Through this study, we discov-ered eﬀects of novice ASD team members’ competence andthe diﬃculty of the tasks assigned to them on their workloadvariation, their conﬁdence, and the timeliness of completionof these tasks. The ﬁndings based on unobtrusively collect-ed behavior data from APM tools are quantitative in natureand can help future research construct computational taskallocationdecisionmodelsusefulforbuildingautomatedAS-D task allocation decision support systems.
In future, we plan to enhance the HASE Platform to en-
able more detailed and larger scale studies about other im-portant aspects of the ASD process to be eﬀectively carriedout. With more in-depth understanding of the characteris-ticsanddynamicsoftaskallocationdecision-makinginASE,we aim to design situation-aware decision support system-s to help ASD teams make more eﬃciently task allocationdecisions with global consideration.
7. ACKNOWLEDGMENTS
This research is supported in part by Interactive and Dig-
ital Media Programme Oﬃce, National Research Founda-tion hosted at Media Development Authority of Singapore(Grant No.: MDA/IDM/2012/8/8-2 VOL 01).
8. REFERENCES
[1] 8th annual state of agile survey. Technical report,
VersionOne, Inc., 2013.
[ 2 ]A .W .B r o w n ,S .A m b l e r ,a n dW .R o y c e .A g i l i t ya t
scale: Economic governance, measured improvement,and disciplined delivery. In Proceedings of the 35th
International Conference on Software Engineering(ICSE’13) , pages 873–881, 2013.
[3] T. Chow and D. B. Cao. A survey study of critical
success factors in agile software projects. Journal of
System and Software, 81:961–971, 2008.
[4] M. Drury, K. Conboy, and K. Power. Decision making
in agile development: A focus group study of decisionsand obstacles. In Proceedings of the Agile Conference
(AGILE’11) , 2011.
[5] M. Drury, K. Conboy, and K. Power. Obstacles to
decision making in agile software development teams.Journal of Systems Software , 85(6):1239–1254, 2012.
[6] R. Likert. A technique for the measurement of
attitudes. Archives of Psychology , 22(140), 1932.
[7] J. Lin. Context-aware task allocation for distributed
agile team. In Proceedings of the 28th IEEE/ACM
International Conference on Automated SoftwareEngineering (ASE’13), pages 758–761, 2013.
[8] A. Szoke. Decision support for iteration scheduling in
agile environments. In Proceedings of the 10th
International Conference on Product Focused SoftwareProcess Improvement (PROFES’09), pages 156–170,2009.
[9] J. W. Tukey. Exploratory Data Analysis .
Addison-Wesley, 1977.
[10] H. Yu, Z. Shen, C. Leung, C. Miao, and V. R. Lesser.
A survey of multi-agent trust management systems.IEEE Access, 1(1):35–50, 2013.
[11] C. Zanniera, M. Chiassonb, and F. Maurer. A model
of design decision making based on empirical results ofinterviews with software designers. Information and
Software Technology , 49(6):637–653, 2007.
694