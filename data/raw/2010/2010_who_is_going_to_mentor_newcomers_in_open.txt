Who is Going to Mentor Newcomers
in Open Source Projects?
Gerardo Canfora1, Massimiliano Di Penta1, Rocco Oliveto2, Sebastiano Panichella1
1University of Sannio, Via Traiano, 82100 Benevento, Italy
2University of Molise, Contrada Fonte Lappone, 86090 Pesche (IS), Italy
canfora,dipenta@unisannio.it, rocco.oliveto@unimol.it, spanichella@unisannio.it
ABSTRACT
When newcomers join a software project, they need to be
properly trained to understand the technical and organi-
zational aspects of the project. Inadequate training could
likely lead to project delay or failure.
In this paper we propose an approach, named Yoda ( Yo-
ung and newc OmerDeveloper Assistant) aimed at iden-
tifying and recommending mentors in software projects by
mining data from mailing lists and versioning systems. Can-
didate mentors are identiﬁed among experienced developers
who actively interact with newcomers. Then, when a new-
comer joins the project, Yoda recommends her a mentor
that, among the available ones, has already discussed topics
relevant for the newcomer.
Yoda has been evaluated on software repositories of ﬁve
open source projects. We have also surveyed some devel-
opers of these projects to understand whether mentoring
was actually performed in their projects, and asked them
to evaluate the mentoring relations Yoda identiﬁed. Results
indicate that top committers are not always the most appro-
priate mentors, and show the potential usefulness of Yoda as
a recommendation system to aid project managers in sup-
porting newcomers joining a software project.
Categories and Subject Descriptors
D.2.9 [Software Engineering ]: Management— Program-
ming teams.
Keywords
Developer Mentoring, Mining Software Repositories, Empi-
rical Studies.
1. INTRODUCTION
In the Star Wars imaginary Universe, Yoda1is known to
have trained a large number of young Jedi ( youngling ). Such
1http://starwars.wikia.com/wiki/Yoda
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
SIGSOFT’12/FSE-20, November 11–16, 2012, Cary, North Carolina, USA.
Copyright 2012 ACM 978-1-4503-1614-9/12/11 ...$15.00.a skill is equally important in software projects, where train-
ing new developers is a crucial activity. When a newcomer
joins a project, she needs to be trained from many diﬀerent
points of view, such as project architecture and implemen-
tation details, development guidelines, and organizationa l
aspects. Training is often performed by one or more men-
torsthat, during the early stages of project participation for
a newcomer, help her in the work and actively discuss with
her project details. Once the newcomer has been trained,
she can continue to work autonomously. A relatively similar
process may occur in open source projects, where, in most
cases, the interaction between the mentor(s) and the new-
comer occurs through electronic means, e.g., mailing lists or
issue tracking systems. A newcomer would likely ﬁrst start
participating to discussion actively, and then would gradu-
ally start to commit changes in the source code repository.
Previous studies surveying software projects indicated that
mentoring of project newcomers is highly desirable [14]. Dif-
ferently from the problem of bug triaging—which requires
to determine a developer who solved in the past a similar
task [2]—mentoring requires to ﬁnd developers having the
ability to eﬀectively communicate and train other people.
Hence,a good mentor is someone that (i) has enough exper-
tise about the topic of interest for the newcomer, and that
(ii) demonstrated to have enough ability to help other peopl e.
In this paper we propose Yoda ( Young and newc Omer
Developer Assistant) an approach to identify likely mentors
in software projects by mining data from software reposito-
ries, and to support the project manager in recommending
possible mentors when a newcomer joins a project. Yoda
is inspired by the ArnetMiner2search engine for academic
researchers in computer science, which identiﬁes relations
between students and advisors, based on a series of heuris-
tics [20]. Shortly, given a pair of researchers JimandAlice,
ArnetMiner suggests that Jimcould have been the mentor
ofAlicebased on four factors: f1:JimandAlicepublished
together a large number of papers, f2:Jimhas more pub-
lications than Alice,f3:Jimis older than Alicein terms of
activity, and f4:JimandAlicestarted to publish together
as soon as Alicestarted her activity. Even if the student-
advisor relationship in academia is one-to-one, the metrics
employed by ArnetMiner allow to also identify one-to-many
relationships.
To identify candidate mentors in the past history of a soft-
ware project, we consider as potential indicators on mentor-
ship cases where (i) the mentor and the newcomer exchange
a large number of emails in the ﬁrst phases of the newcomer
2http://arnetminer.orgactivity, (ii) the mentor has performed a larger activity in
the project than the newcomer in terms of exchanged emails,
(iii) the mentor has a longer experience in the project than
the newcomer, (iv) the mentor and the newcomer start to
exchange emails as soon as the newcomer joins the project,
and (v) the mentor is very active in terms of performed
commits. The set of indicators above deﬁned is inspired to
theArnetMiner , although metrics being used are diﬀerent:
for example, co-authorship is replaced by level of commu-
nication; plus, diﬀerently from ArnetMiner , Yoda needs to
account both communication activity (measured in terms
of exchanged emails) and technical activity (measured in
terms of commits). Once being able to identify likely men-
tors in the past history of a software project, Yoda recom-
mends mentors each time a newcomer joins the project, by
selecting, among the candidate mentors previously identi-
ﬁed, those who discuss similar topics to what the newcomer
is discussing.
We have evaluated Yoda on data from ﬁve open source
projects, Apache httpd, the FreeBSD kernel, PostgreSQL,
Python, and Samba. First, we investigated which factors or
combination of factors provide more accurate indicator of
mentoring. Then, we evaluated the accuracy of Yoda when
recommending mentors for a newcomer. Finally, we also
present the results of a preliminary survey conducted with
some people involved in the suggested mentoring relation-
ships of the ﬁve projects to understand (i) whether what
we identiﬁed was actually true, and (ii) to understand how
mentoring was performed (and if it was performed) in that
project.
The paper is organized as follows. Section 2 describes
Yoda, the approach proposed to identify and recommend
mentors. Section 3 describes the empirical study aimed at
evaluating Yoda on the ﬁve open source projects. Section 4
reports the study results. Section 5 provides a qualitative
discussion of the empirical study performed, while Section 6
discussesthelimitationsandthreatstovalidityofbothYod a
andofthestudy. Finally, Section8concludesthepaperafter
a discussion of the related literature (Section 7).
2. HOW TO IDENTIFY MENTORS
To recommend mentors, Yoda ﬁrst identiﬁes a list of avail-
able mentors by mining mailing lists and versioning systems.
Then, it analyzes the requests for help issued by a newcomer
and identiﬁes a list of candidate mentors that could help her.
The next sections detail the approach we use to (i) identify
mentors from historical data of existing projects; and (ii) to
recommend mentors when a newcomer joins a project.
2.1 Who could be a good mentor?
To identify mentors in software projects, we deﬁne factors
inspired by the ones ArnetMiner uses. However, we replace
the activity of co-authoring a paper with the activity of ex-
changing emails and, in addition, we consider the technical
activity of a candidate mentor, in terms of number of com-
mits:
•f1: captures whether, after a newcomer joins a project,
she mainly collaborates with a speciﬁc person. We
measure this as the percentage of emails a newcomer
exchanges with an older project member in the ﬁrst
period (we set this to one month) after joining theproject, out of the total number of emails exchanged
in that period.
•f2: captures the diﬀerence of the amount of discus-
sion activity carried out by mentors and newcomers in
terms of the number of emails exchanged.
•f3: captures the “age” diﬀerence between the new-
comer and the likely mentor, i.e., the diﬀerence (in
months) between the date when the newcomer exchan-
ged her ﬁrst email in the project and the date when
the likely mentor did.
•f4: tells whether the mentor is one of the people the
newcomer starts to collaborate ﬁrst. It is deﬁned in
terms of time diﬀerence (in months) between the ﬁrst
email exchanged by a newcomer, and the ﬁrst email
the newcomer exchanged with the likely mentor.
•f5: considers the number of commits performed by a
candidate mentor, as an indicator of the past technical
activity performed by the candidate mentor.
To allow aggregating the ﬁve factors, we normalize them in
the interval [0 ...1], and then aggregate them into a score
deﬁned as
5/summationdisplay
i=1wi·fi (1)
wherewiis the importance (weight) attributed to fi. De-
termining appropriate weights wiforfi—and, as a conse-
quence, also whether each of the fiis considered or not—is
part of the empirical evaluation and will be detailed in Sec-
tion 3.1. By using the score deﬁned above, it is possible—
from the past history of a project—to rank all other devel-
opers with the aim of identifying the list of available mentors
that can be suggested to newcomers. The higher the rank,
the higher the likelihood that the developer played the role
of mentor for the considered newcomer. Once the developers
have been ranked, a threshold is used to cut the ranked list
and identify the top related developers that represent the
candidate mentors.
Deﬁning a“good”threshold a priori to cut the ranked list
is challenging, because a newcomer could have one or more
mentors. Thus, weuseascaledthreshold t—usedinprevious
work on traceability recovery [1]—based on the values of the
factors computed considering the newcomer iand the top
developers in the ranked list ti=λ·TOPi,whereTOPiis
the value of the factor between the newcomer iand the top
developer in the ranked list, while λ∈[0,1]. The deﬁned
threshold is used to remove from the ranked list developers
that have a factor value lower than λ% of the factor value
between the newcomer and the top ranked developer.
2.2 Building the project committers’ commu-
nication network
We identify communication between developers by ana-
lyzing mailing lists and by linking names/email in mailing
lists to committer IDs extracted from the versioning repos-
itory. The link to versioning repositories is needed since we
are interested to select people who committed changes to
the project repository.
Given two mailing list contributors TomandJohn, we as-
sume a social interaction between them if the mailing listcontributor Tomsends at least one email to Johnthrough
the mailing list. For the purpose of our study, other than
just extracting the network, we also need to keep track
of all messages exchanged by mailing list contributors over
time. Mailing list contributors and their social interactions
are extracted from mailing list messages by identifying the
sender name and email address and, whenever available, the
recipient/reply-to name and email address. Clearly, since
messages can be sent to a mailing list rather than to single
addresses, we assume that (i) TomandJohncommunicate
if there is a direct message with Tomas sender and John
as recipient or vice versa , or (i) if Johnanswers, even if
replying to the mailing list to a thread initiated by Tom, or
to which Tomhas previously replied.
Whenbuildingthecontributors’network, weneedtounify
the names belonging to the same person, i.e., cases of people
referring themselves diﬀerently, e.g., John Fitzgerald Smith ,
John F. Smith ,John Smith , orJ. Smith. Weuseanapproach
similar to the one proposed by Bird et al.[6] that we also
applied to analyze mailing lists for a diﬀerent research [10].
We use similar heuristics to map versioning system IDs to
mailing list names/emails, which could be straightforward in
cases where the committer ID is a full name and/or an email
(e.g., in projects adopting Git as versioning system), while
it is less obvious when short IDs are used (such in the case
of many CVS repositories). Speciﬁcally, we use heuristics to
match IDs composed of initials to contributor names—e.g.,
mapping, where this does not induce ambiguities, jfktojohn
ﬁtzgerald kennedy —or ﬁnding mailing list contributor names
tobelinkedtocommitterIDslike johnsmith orjsmith, trying
to compose mailing list contributors ﬁrst and last names, or
ﬁrst/middle name initials and last name. Further details
can be found in a previous paper by Canfora et al.[10].
2.3 Recommending mentors
When a contributor joins a project, she needs to become
knowledgeable on a speciﬁc (set of) topic(s). The project
manager needs to ﬁnd a mentor for this newcomer, that is a
contributor that (a) demonstrated already to be a mentor in
the past, and (b) actually worked/discussed topics related
to those the newcomer is going to work. As for requirement
(a), we use the method deﬁned in Section 2.1 to identify
available mentors in the past project history. Turning to
requirement (b), we need to select among the available con-
tributors that demonstrated to be mentors in the past, the
ones that had enough expertise on the topic(s) which the
newcomer is going to work on. Rather than proposing a
novel approach to identify the most appropriate mentor for
a given topic, we use approaches similar to what proposed
in the past for bug triaging [2, 9, 19], which proposed to
assign a bug to a developer that in the past worked on a
bug having a (textually) similar bug report.
Speciﬁcally, let us suppose a newcomer pjoins the project
at time tx, and let us consider the set of nmentors
M={m1,...m n}identiﬁed using the method described
in Section 2.1 in the period before tx. We instantiate an
Information Retrieval (IR) [5] process to rank the available
mentors, where each document diwithi= 1...nconsists of
the union of the text of all emails exchanged by the mentor
mibeforetx, while the query qpis represented by a request
for help submitted by the newcomer p.
In a live setting—when Yoda would be instantiated as a
tool—the request for help can be explicitly submitted by thenewcomer when she joins the project. For the purpose of our
empiricalstudy, sinceweareworkingonpastdatafromopen
source projects, we simulated the query by considering the
union of the emails sent by the newcomer during the ﬁrst
week when she joined the project, i.e., within one week after
the ﬁrst email. We consider a week as a time span on the
one hand long enough for a newcomer to send emails and
precisely ask what kind of help she needs (e.g., taking the
ﬁrst email only could be considered too vague), on the other
hand not so long to have an unrealistic scenario.
Both documents and query are processed by removing En-
glish stop words, performing stemming using Porter stem-
ming [16], and indexing the text corpus using word frequen-
cies. We use raw frequencies ( tf) [5] rather than the widely
usedtf-idf[5] as our aim is to mach similar corpus rather
than to discriminate diﬀerent documents, reason for what
tf-idfresults useful. Then, we compare the query qpwith
eachdiusing the asymmetric Dice coeﬃcient [5]:
Dicep=/summationtextN
j=1tfjqp·tfjdi/summationtextN
j=1tfjqp·tfjqp
whereNis the size of the vocabulary of all words contained
in our documents, tfjqpandtfjdiare the raw frequencies of
thejthdictionary term in the query and di, respectively. In
other words, the asymmetric Dice coeﬃcient captures how
much text of the newcomer’s request for help is covered by
the mentor’s emails. We use it instead of the cosinecoeﬃ-
cient because the Dice coeﬃcient does not penalize mentors
having email corpus that contains much text not contained
in the newcomer’s request.
3. EMPIRICAL STUDY DEFINITION
Thegoalof this study is to evaluate the performances
of Yoda in identifying mentors in software projects, and in
recommending mentors for project newcomers. The quality
focusis concerned with the capability to precisely identify
andrecommendmentorsthat(i)hadamentoringexperience
in the past and (ii) have discussed topics related to the new-
comer needs. The contextconsists of discussions extracted
frommailinglistsandchangesextractedfromversioningsys-
temsforﬁveopensourceprojects, namelyApachehttpd, the
FreeBSD kernel, PostgreSQL, Python, and Samba.
The ﬁve projects are diﬀerent in terms of size and applica-
tion domain. Apache httpd is an open-source HTTP server,
FreeBSD is a free, open source Unix operating system, Post-
greSQL is a database management system (DBMS), Python
isawell-knownscriptinglanguage, andSambaacross-opera-
ting system layer for printer and ﬁle sharing. The top part
of Table 1 reports key information about the ﬁve projects
and, above all, of their mailing lists and versioning systems ,
namely project URL, time period analyzed, size range in
KLOC, number of mailing list contributors ( Mc), number
of committers in the versioning systems ( Cm), their inter-
section ( Mc∩Cm), and number of emails exchanged by
Mc∩Cm, i.e., by the set of project contributors we consid-
ered.
3.1 Study Procedure
The study addresses the following research questions:
•RQ1:How can we identify mentors from the past his-
tory of a software project? This question aims at inves-
tigating whether particular combinations of the factorsTable 1: Characteristics of the ﬁve projects analyzed, and o f the training and test sets for evaluating Yoda.
Variable Apache httpd FreeBSD PostgreSQL Python Samba
Project URL http://httpd.apache.org http://www.freebsd .org http://www.postgresql.org http://www.python.org h ttp://www.samba.org
Period considered 08/2001-12/2008 11/1998-10/2008 10/19 98-03/2008 05/2000-12/2008 04/1998-12/2008
Size range (KNLOC) 271-850 3,552-7,853 223-522 464-683 156-1,157
Mailing list contribs ( Mc) 6,726 23,872 2,935 20,827 3,411
Committers ( Cm) 108 640 34 147 229
Mc∩Cm 66 393 29 147 226
Emails exchanged by Mc∩Cm 135,243 2,246,425 44,244 7,479 19,073
Period (training set) 08/2001-03/2002 11/1998-02/2000 10 /1998-05/2001 05/2000-05/2001 04/1998-09/2000
Period (test set) 04/2002-12/2008 03/2000-10/2008 06/200 1-03/2008 06/2001-12/2008 10/2000-12/2008
# of mentors (training set) 19 65 10 28 17
# of newcomers (training set) 13 33 8 32 33
# of newcomers (test set) 13 33 7 31 33
f1–f5described in Section 2.1 can be used to identify
mentors, and how good are such combinations com-
pared with some baselines, e.g., using as mentors the
project managers or the top project contributors.
•RQ2:To what extent would it be possible to recom-
mend mentors to newcomers joining a software project?
This research question investigates how accurately
could Yoda recommend a mentor—among those iden-
tiﬁed in RQ1—for a newcomer that joins the project
and is willing to work on a certain topic, and how such
a prediction compares with a baseline alternative, i.e.,
suggesting owners/top committers of artifacts traced
to the ﬁrst emails the newcomer sends when joining
the project.
To address RQ1, we use diﬀerent combinations of f1–f5to
identify—for each newcomer joining a project—a ranked list
of candidate mentors, and then we evaluate them manually.
It is worthwhile to recall that such a metrics combination
suggests a ranked list of candidate mentors for each new-
comer by observing the past project history, without how-
ever requiring a training set (the approach is unsupervised)
and that, in the context of RQ1we are only interested to
see whether the f1–f5metrics can identify good mentors,
without checking whether the mentor has appropriate skills
required by the newcomer (we deal with such an issue in
RQ2).
First, we perform a calibration of the weights in equa-
tion (1). We consider diﬀerent possible combinations of f1–
f5, i.e., all ones with equal weight, single factors alone, all
possible pairs, all groups of three, and four factors. It is
important to note that, by considering f5(normalized num-
ber of commits) alone, we provide a sort of baseline for our
technique, because the number of commits is a metric often
used to identify experts—or at least code ownership [8]—in
software projects [17].
Then, we give varying weights to the ﬁve factors, with
the aim of investigating whether there are factors that are
more important than others. For example, for combinations
of three factors, say f1,f2,f3, we consider, other than the
combination with equal weights, i.e., 0 .33·f1+ 0.33·f2+
0.33·f3, the following cases: (i) one factor weighted more
than the others, e.g., 0 .5·f1+0.25·f2+0.25·f3, and similarly
forf2andf3; and (ii) two factors weighted more than the
other, e.g., 0 .4·f1+0.4·f2+0.2·f3, and similarly for ( f1,f3)
or (f2,f3).
To validate the candidate newcomer-mentor pairs, one of
the authors and another PhD student (not aware of how
Yoda works) manually inspected (independently, discussing
cases where they disagreed) the communication between the
newcomer and the mentor. The pair mentor-newcomer isclassiﬁed as a true positive if there is a clear evidence of
cases in which the newcomer asked help to—and received
help from—the mentor, otherwise it is classiﬁed as a false
positive.
To address RQ2, we split the project history into two pe-
riods, a ﬁrst period ( training set ) in whichwe identify the set
Mof people who have been identiﬁed as candidate mentors
using the most suitable combination of factors determined
inRQ1, and a second period ( test set) for which we aim
at recommending mentors for project newcomers. For each
project, we have chosen training and test set in order to
have a balanced number of newcomers in the two sets (see
the bottom part of Table 1).
For each newcomer iidentiﬁed in the test set, we identify
the topkmentors ( mj∈M) that exhibit the most similar
discussion to the newcomer request for help. For each pos-
sible newcomer, we produce a ranked list of krecommended
mentors3, as in realistic scenarios it can happen that the
most suitable mentor is not available, and one has to choose
the second-best, the third-best, and so on. Since in the con-
text of a post-mortem analysis of data from open source
projects like the one we are doing we do not have avail-
able other sources of requests for help, we assume that the
topic on which a newcomer requires helps is contained in the
ﬁrst emails she exchanges in the project. We deﬁne below,
in the study settings, how the number of emails has been
chosen. Then, for each newcomer iin the test set, we iden-
tify mentor(s) using the approach described in Section 2.3,
manually validate it, compare with the recommended men-
tor, and report the number and percentage of pairs for which
the recommendation was correct or incorrect.
In addition to such a manual validation, we consider—also
forRQ2—a baseline, i.e., an alternative way of suggesting
experts. To this aim, we trace the textual corpus of the new-
comer early emails onto source code ﬁles, using an approach
proposed by Bacchelli et al.[4]. Brieﬂy, such approach aims
at matching ﬁle names (or class names) in the email text. In
some cases (37 out of 117 times in our study) the mapping is
straightforward because the emails contain a ﬁle name, in-
cluding extension and even in some cases a complete path.
In other 14 cases, the email only contained one or more
words that were also ﬁle names, which could lead to possi-
ble imprecisions (e.g., the word“main”might not refer to a
ﬁle). To deal with this imprecision, the resulting 37+14=51
traceability links were also manually validated. After that,
we took the list of top committers for the ﬁles traced onto
the emails, and consider such a list as an alternative way of
recommending mentors.
3In Section 4.2 we report results for k= 1 and k= 2, while
the Appendix also reports results for k= 3 and k= 4.0%	  10%	  20%	  30%	  40%	  50%	  60%	  70%	  80%	  90%	  100%	  
17	  18	  19	  20	  21	  22	  23	  24	  25	  Precision	  (%)	  
Number	  of	  newcomer-­‐mentor	  pairs	  
(a) Apache httpd
0%	  10%	  20%	  30%	  40%	  50%	  60%	  70%	  80%	  90%	  100%	  
22	  24	  26	  28	  30	  32	  34	  36	  38	  40	  42	  Precision	  (%)	  
Number	  of	  mentors	  iden>ﬁed	  
(b) FreeBSD
0%	  10%	  20%	  30%	  40%	  50%	  60%	  70%	  80%	  90%	  100%	  
10	  11	  12	  13	  14	  15	  16	  17	  18	  19	  20	  21	  22	  23	  24	  Precision	  (%)	  
Number	  of	  mentors	  iden>ﬁed	  
(c) PostgreSQL
0%	  10%	  20%	  30%	  40%	  50%	  60%	  70%	  80%	  90%	  100%	  
22	  24	  26	  28	  30	  32	  34	  36	  38	  40	  42	  44	  46	  48	  50	  Precision	  (%)	  
Number	  of	  mentors	  iden>ﬁed	  
(d) Python
0%	  10%	  20%	  30%	  40%	  50%	  60%	  70%	  80%	  90%	  100%	  
29	  30	  31	  32	  33	  34	  35	  36	  37	  38	  39	  40	  41	  42	  43	  Precision	  (%)	  
Number	  of	  mentors	  iden>ﬁed	  
(e) Samba
Figure 1: Mentor identiﬁcation performances for the
best combinations of f1–f5and for the baseline ( f5).3.2 Surveying project developers
As a further evaluation, after having identiﬁed candidate
pairs of mentor-newcomer, we surveyed these developers by
sending them an email, explaining them the purpose of our
research activity, and asking them to complete an on-line
survey questionnaire—built using SurveyMonkey4(an ex-
ample of which is reported in the Appendix)—asking ques-
tions about: (i) the experience as project contributor, and
whether the contributor is still active; (ii) whether the per-
son mentored a project newcomer and, if yes, how important
was the mentoring perceived; (iii) whether the person was
mentored when she joined the project, and how important
was the mentoring in the decision to stay in the project; and
(iv) which are the characteristics of a good mentor (e.g., ex-
perience, communication skills, project knowledge).
In addition, the survey page showed to respondents a list
of people that Yoda highlighted in the mentor-newcomer
candidatepairs, askingthemtotell, foreachperson, whether
the respondent (i) was actually the person indicated there,
(ii) was a mentor for that person, (iii) was advised by that
person, or (iv) never got in touch with that person. We
invited to the survey 23 developers from Apache httpd, 37
from FreeBSD, 15 from PostgreSQL, 27 from Python, and
37 from Samba. The questionnaire was completed by 6 de-
velopers from Samba, 3 from FreeBSD, 2 from PostgreSQL,
and 1 from Python.
4. RESULTS
This section reports the results of the empirical study.
The experimental package (with raw data) is available for
replication purposes5.
4.1 RQ1: How can we identify mentors from
the past history of a software project?
Figure 1 and Table 2 report, for the ﬁve projects we an-
alyzed, the performances of Yoda in detecting mentors for
all newcomers joining the project during the entire analyzed
time interval. In each subﬁgure of Figure 1, the x-axis in-
dicates the number of mentors that the approach can rec-
ommend when achieving a precision shown on the y-axis.
As described in Section 3.1, we evaluated the performance
of Yoda for all combinations of f1–f5, as well as for com-
binations having varying weights. Due to space limitations,
Table 2 only reports a subset of the analyzed combinations
(complete tables can be found in the Appendix), and specif-
ically:
•f1, i.e., the percentage of exchanged emails between
newcomer and mentor. We noticed that, if considering
each of the f1–f5factors alone, such a factor is the one
that produces the best performances.
•f5, i.e., the normalized number of commits performed
by the candidate mentor. We use this factor as a base-
line, to determine whether an obvious choice of men-
tors, i.e., top committers, could be appropriate.
•0.33·f1+0.33·f2+0.33·f3and0.33·f1+0.33·f2+0.33·f4,
because we considered that the combination of f1and
f2with either f3orf4produces the best results among
combinations obtained weighting all factors similarly.
4www.surveymonkey.com
5http://www.rcost.unisannio.it/mdipenta/mentoring-
data.tar.gzTable 2: Precision (%) and number of newcomer-mentor pairs iden tiﬁed for diﬀerent values of λ.
System Formula λ= 100 λ= 90 λ= 80 λ= 70 λ= 60 λ= 50
Apache httpdf1 83% 18 83% 18 83% 18 84% 19 84% 19 86% 21
f5(baseline ) 56% 18 53% 19 55% 20 55% 20 52% 21 54% 26
0.33·f1+ 0.33·f2+ 0.33·f383% 18 85% 20 82% 22 83% 24 80% 25 77% 26
0.33·f1+ 0.33·f2+ 0.33·f478% 18 75% 20 77% 22 77% 22 77% 22 78% 23
0.5·f1+ 0.25·f2+ 0.25·f389% 18 89% 18 81% 21 83% 23 79% 24 77% 26
0.5·f1+ 0.25·f2+ 0.25·f478% 18 79% 19 79% 19 76% 21 78% 23 75% 24
FreeBSDf1 26% 27 26% 27 26% 27 26% 27 25% 28 26% 31
f5(baseline ) 17% 23 17% 23 17% 23 17% 24 17% 24 21% 29
0.33·f1+ 0.33·f2+ 0.33·f317% 23 17% 24 17% 24 17% 24 19% 26 23% 31
0.33·f1+ 0.33·f2+ 0.33·f430% 23 25% 28 20% 35 20% 35 21% 39 20% 40
0.5·f1+ 0.25·f2+ 0.25·f313% 23 13% 23 17% 24 15% 27 20% 30 24% 33
0.5·f1+ 0.25·f2+ 0.25·f435% 23 31% 26 24% 33 22% 37 21% 38 20% 41
PostgreSQLf1 83% 12 85% 13 79% 14 79% 14 80% 15 80% 15
f5(baseline ) 50% 12 50% 12 50% 12 56% 16 62% 21 64% 22
0.33·f1+ 0.33·f2+ 0.33·f383% 12 76% 17 75% 20 65% 23 62% 26 55% 29
0.33·f1+ 0.33·f2+ 0.33·f483% 12 77% 13 73% 15 76% 21 73% 22 70% 23
0.5·f1+ 0.25·f2+ 0.25·f383% 12 77% 13 79% 14 75% 20 73% 22 70% 23
0.5·f1+ 0.25·f2+ 0.25·f483% 12 79% 14 79% 14 79% 14 80% 20 76% 21
Pythonf1 88% 24 88% 24 88% 25 82% 28 74% 31 70% 33
f5(baseline ) 58% 26 58% 26 59% 27 59% 27 59% 27 59% 27
0.33·f1+ 0.33·f2+ 0.33·f362% 26 68% 31 66% 32 64% 36 63% 40 61% 41
0.33·f1+ 0.33·f2+ 0.33·f473% 26 75% 28 74% 34 63% 40 60% 45 57% 47
0.5·f1+ 0.25·f2+ 0.25·f369% 26 71% 28 66% 32 64% 33 62% 39 60% 43
0.5·f1+ 0.25·f2+ 0.25·f481% 26 81% 26 75% 32 65% 37 62% 42 58% 48
Sambaf1 87% 31 84% 32 84% 32 80% 35 80% 35 78% 37
f5(baseline ) 53% 30 52% 33 52% 33 53% 34 53% 36 50% 42
0.33·f1+ 0.33·f2+ 0.33·f377% 30 72% 32 69% 35 69% 36 66% 38 64% 42
0.33·f1+ 0.33·f2+ 0.33·f473% 30 70% 33 68% 34 67% 36 63% 40 63% 41
0.5·f1+ 0.25·f2+ 0.25·f377% 30 77% 31 69% 35 69% 35 68% 37 65% 40
0.5·f1+ 0.25·f2+ 0.25·f480% 30 78% 32 78% 32 76% 33 72% 36 71% 38
•0.5·f1+0.25·f2+0.25·f3and 0.5·f1+0.25·f2+0.25·f4,
i.e., again considering f1andf2withf3orf4, weight-
ingf1twice than the other factors. These are the
combinations able to achieve the best performances.
Note that Figure 1 contains exactly the same information of
Table 2 (except that we do not report the combination of
f1,f2, andf3orf4with equal weights since they are less
interesting to be compared), and has the purpose of better
allowing the comparison of diﬀerent combinations, whereas
Table 2 provides precise ﬁgures.
In summary, the obtained results indicate that:
•f5(number of commits) is not a good indicator of men-
torship. Also, f5does not even provide a useful contri-
butionifusedincombinationwithotherfactors. While
it is true that a very active committer can be expert
on a particular topic, she might not be very willing (or
able) to exchange ideas and/or instruct other people.
•0.5·f1+ 0.25·f2+ 0.25·f3and
0.5·f1+0.25·f2+0.25·f4achievethebestperformances,
withaprecisionover70%andinmanycaseswellabove
80%. Also, it can be noticed that such a precision does
not decrease when decreasing λ, which means that the
chosen combinations are able to recommend a wider
set of candidate mentors without sacriﬁcing the preci-
sion.
•f1alone tend to be as precise as the other combina-
tions, and in some cases (Python and Samba) even
moreprecisethanthecombinationsabove. However, it
isonlyabletorecommendalimitedsetofmentorseven
when decreasing λ. Although, in the practice, a singlementor would suﬃce, having a good recall is desirable
because (i) not all candidate mentors may be available
when needed, and (ii) among the candidate mentors,
we need to select those having the expertise required
by the newcomer. Hence, to obtain a good balance be-
tween precision and number of mentors (which as said
above does not mean to accept a very low precision),
it is necessary to combine f1(having however a higher
weight) with f2(rewarding mentors in general very ac-
tive in discussions) and f3(mentor/newcomer project
age diﬀerence) or f4(the newcomer mainly collaborate
with the mentor in her early stages). In summary, the
percentage of exchanged emails per seis not enough
to identify a large set of candidate mentors.
The results achieved also indicate that on FreeBSD Yoda
exhibits low performances (precision around 30%) while for
all other systems results are pretty consistent. Our interpre-
tation is that such a result does not depend on the system
size and on its number of project contributor. In fact, on
other systems having a high number of contributors (such as
Python or Samba), Yoda exhibits good performances. We
believe that this can be due to the nature of the discus-
sion occurring in the FreeBSD mailing lists. By inspecting
the emails we realized that most of the discussion is one-
to-many, i.e., people posting issues or suggestions to many
other people or to the whole mailing list. Although the way
we analyze mailing lists allow to treat—with some approxi-
mation many-to-many communications—the FreeBSD com-
munication did not always exhibit dominant persons (po-
tential mentors). This, clearly, makes the identiﬁcation of
pairwise collaborations less precise.Table 3: Number and percentage of correct and in-
correct top 1 and top 2 mentor recommendations for
newcomers in the test set.
Top 1 Top 2
System Correct Wrong Correct Wrong
Apache 11 (85%) 2 (15%) 21 (81%) 5 (19%)
FreeBSD 10 (30%) 23 (70%) 16 (24%) 50 (76%)
PostgreSQL 7 (100%) 0 (0%) 14 (100%) 0 (0%)
Python 20 (65%) 11 (35%) 48 (77%) 14 (23%)
Samba 31 (94%) 2 (6%) 54 (82%) 12 (18%)
It is possible to identify mentors—with a precision of
70%orabove—inthepasthistoryofasoftwareproject
by using the combinations of factors 0 .5·f1+ 0.25·
f2+0.25·f3or 0.5·f1+0.25·f2+0.25·f4. Considering
top committers is not a precise and reliable metric to
identify mentors.
4.2 RQ2: To what extent would it be possi-
ble to recommend mentors to newcomers
joining a software project?
To evaluate the recommendation method, we split the his-
tory of each project in a training set and test set. The bot-
tompartofTable1reports, foreachprojectthetimeinterval
of training and test sets, the number of mentors identiﬁed
in the training set, and the number of newcomers in the
training set and test set.
Table 3 reports the accuracy of Yoda in recommending
mentors for the newcomers of the test set. We recommend
mentors among those identiﬁed—in the training set—using
0.5·f1+ 0.25·f2+ 0.25·f3, which as explained in RQ1
exhibits in most cases the best performances. The left-side
of each column in the table reports the number and percent-
age of correct and incorrect top 1 mentor recommendations
for each newcomer (ranked according to Dice asymmetric
similarity), while the right-side reports the number and per-
centage of correct and incorrect top 2 recommendations.
As the table shows, the percentage of correct top 1 rec-
ommendations is very high, above 85% except for Python,
where it is 65%, and for FreeBSD, where it is 30% (for the
reasons explained in RQ1). Even when we consider the
top 2 recommendations, the correctness remains high, 71%
or above—including this time Python where it increases to
77%—and again with the exception of FreeBSD where it is
24%. In the Appendix we also report results for top 3 and
top 4 recommendations, which nevertheless only slightly in-
crease or decrease with respect to top 1 and to top 2. As
explained in Section 3.1, results of Table 3 are obtained by
considering as newcomer query (to identify recommenders)
emails sent during the ﬁrst week in the project. As shown
in the Appendix, results do not substantially vary if consid-
ering a longer period (up to four months), which is however
less realistic because we cannot expect the newcomer would
wait so long to get a mentorship.
For 51 out of the 117 newcomers for which it has been
possible to trace the ﬁrst-week emails onto source code ﬁles,
Table 4 reports the precision in the recommendation in the
same way as for Table 3. As the table shows, the precision is
quite low: always below 10%, with the exception of Samba
where is 35%, and top 2 for PostgreSQL where is 25%.Table 4: Precision in the recommendation of men-
tors among top committers of ﬁles traced onto new-
comers emails.
Top 1 Top 2
System Correct Wrong Correct Wrong
Apache 0 (0%) 6 (100%) 1 (8%) 11 (92%)
FreeBSD 1 (6%) 15 (94%) 1 (3%) 31 (97%)
PostgreSQL 1 (50%) 1 (50%) 1 (25%) 3 (75%)
Python 0 (0%) 7 (100%) 1 (7%) 13 (93%)
Samba 7 (35%) 13 (65%) 14 (35%) 26 (65%)
Yoda is able to recommend mentors with a correctness
of about 65% or above for the top 1 recommendations
and 71% or above for the top 2 recommendations for
all systems except FreeBSD, where the percentages
decrease to 30% and 24%, respectively. Top commit-
ters or ﬁles related to newcomer early emails cannot
be used to recommend mentors.
5. DISCUSSION
In the following, we provide additional, qualitative in-
sights to the quantitative study reported in Section 4.
5.1 Hints collected from project contributors
This section reports results we collected surveying project
developers. Since we collected a limited number of answers
(12), we report aggregate data only for the purpose of ex-
plaining how the respondents perceived the importance of
the mentoring process.
Figure 2(a) indicates that, out of 12 developers, 11 admit-
ted to have been mentors, and 7 indicated that they were
mentoredbysomeoneelse. Figure2(b)reportstheperceived
importance of mentoring when respondents performed men-
toring themselves or when they were mentored. The eﬀect
was perceived very important (3) or important (5) for de-
velopers performing mentoring, while when developers re-
ceived mentoring, 2 developers indicated that such activity
is very important and 4 that it is important. In summary,
developers indicated that mentoring is important, although
it seems that developers are more likely to admit that they
performed mentoring than they were mentored. Also, men-
toring seems to be perceived more important by developers
that performed it rather than by developers that received it.
Figure 2(c) reports what factor developers indicated to be
important for good mentoring. The respondents suggested
it is mainly matter of communication skills (11) and project
knowledge (10), while only 5 developers indicated that ex-
perience can play an important role. However, one of the
respondents said “Maybe good communication skills is the
least important of the three above, if one is working closely
together.” , thus the importance of communication skills de-
pends of the cohesiveness of the project team.
Some developers added comments to the survey to indi-
cate that they performed/received mentoring using commu-
nication means diﬀerent from emails. For example, they
added comments like “Suggested work they can do. But
mostly over IRC.” , or“Not only mailing lists, but also IRC
and direct communication.”
By classifying developers in the list we provided, the re-
spondents indicated us a set of 23 mentor-newcomer pairs.
We identiﬁed 10 of them correctly (the remaining 13 were
not identiﬁed), while we identiﬁed 3 pairs for which respon-
dents indicated that mentoring did not occur. Thus, with11	  7	  
1	  5	  
0	  2	  4	  6	  8	  10	  12	  Did	  mentoring?	  Had	  a	  mentor?	  
YES	  NO	  
(a) Done/received mentoring
2	  4	  5	  0	  0	  
3	  5	  1	  0	  0	  
0	  1	  2	  3	  4	  5	  6	  Very	  important	  Important	  Neutral	  Not	  important	  Useless	  at	  all	  
Eﬀect	  of	  mentor	   Eﬀect	  on	  newcomer	  
(b) Perceived importance of mentoring
5	  11	  10	  0	  
0	  2	  4	  6	  8	  10	  12	  Experience	  Communica5on	  skills	  Project	  knowledge	  Others	  
(c) What makes a good mentor
Figure 2: Survey questionnaire answers: generic questions on mentoring activity and its importance.
respect to the answers provided in the survey questionnaire,
our approach has a precision of 10/(10+3)=77% and a recall
of 10/23=43%.
5.2 Examples of cases where Yoda worked well
and where not
In the following we report some examples of collabora-
tions and fragments of emails indicating cases in which Yoda
worked well to identify mentors ( RQ1) and cases where it
did not. Cases of true positives —conﬁrmed by respondents
of our survey—were made evident by exchanges of email in
which the newcomer clearly asked for help.
Figure 3 shows an example of newcomer (Bjoern)-mentor
(James) network found in Samba, when the newcomer ap-
proachedtheprojectbysendinghisﬁrstemails(Figure3(a)),
and after one year (Figure 3(b)). Note that edges are labeled
with the number of exchanged emails. James had already a
three-years experience (with 150 commits performed) when
Bjoern approached him. As it can be seen from the net-
work, James has a high degree (=13), and Bjoern mainly
exchanges emails (4 emails exchanged) with James rather
than with other people. After one year, the social impor-
tance of James increase, as well as (to some extent) the one
of Bjoern, which however still has James as main contact
(18 emails exchanged). The mentoring relationship is also
evident from fragments of their communication: “Hi James,
maybe you can bring some light into the dark here: I did
some tests with ...”
Another example (conﬁrmed by the survey respondent) is
the one in Samba where Kai asked Jeremy6help because she
wanted to contribute to the project “As you might know, I’m
a...student implementing NTLMSSP signing/sealing in
Wine. I’ve worked on basic NTLM authentication for Wine
last year, using ntlm auth....I decided to give Samba4’s
GENSEC subsystem a try.” . Then, Jeremy responded with
a detailed list of instructions answering Kai speciﬁc techni-
cal questions, e.g. “This is the quickest way to make this
work (IMHO).” ,“Probably second best solution.” (where Kai
proposed two possible implementations), or even discourag-
ing Kai to implement some features “this will be a long long
road to walk...”
One example of false negative is when the newcomer asked
for help and the mentor never (or seldom) responded. An
instance of such a case was reported as a true mentoring in
our survey, however Yoda did not detect it because of the
low value of f1.
One example of false positive concerns the collaboration
6We do not report last names for conﬁdentiality reasons.between Ivan and Robert in FreeBSD. Robert helped Ivan
to deal with some performance problem of the SSH protocol
implementation. Although also from the email it appeared
clear that Robert—indicated as candidate mentor by our
approach—was the expert giving suggestions, very likely he
helped to solve a speciﬁc problem only, so to be considered
as someone who helped Ivan, while not really Ivan’s mentor.
Now we report hereby one case where mentoring recom-
mendation ( RQ2) worked and one when it did not. When
Lucien joined the Apache httpd project, he asked informa-
tion about proxy handling “I’m translating mod proxy.xml,
and I don’t understand what the term worker means ...”.
Then, after he received information about the meaning of
this term, he checked whether he correctly understood: “So,
say we have this proxy conﬁguration: ProxyPass path1 ser-
ver1, ProxyPass path2 server2 ...”. In summary, Lucien
seems to be interested to work on tasks related to proxy.
Yoda recommended him Joshua as a mentor, which in the
past helped someone else (Laurent) on a problem related to
proxy:“ProxyPassReverse only rewrites Location: headers
....”. That is, the email referred several times to the terms
ProxyandPass, also contained in the early email sent by
Lucien.
An example of false positive is between Takashi (new-
comer) and Joshua (candidate mentor). Both the early
emails of Takashi and previous emails of Joshua contained
some common terms, such as “3D”, contained in XML and
HTML fragments, e.g., “<note type=3D”warning” >”in the
earlyemailbyTakashiand “<meta name=3D”generator” / >”
in previous emails by Joshua. However, the technical con-
tent of the emails was not very similar.
6. YODA LIMITATIONS AND THREATS
TO V ALIDITY
This section describes the limitations of Yoda and the
threats to validity of the study we performed. We are aware
that Yoda is limited for the following reasons:
•It identiﬁes mentor-newcomer pairs mainly based on
their activity on mailing lists. We are aware, however,
as also reported in a paper by Aranda and Venolia [3],
that developers can communicate also outside mailing
lists, e.g., using a chat. One of the developers that
responded to our survey “I’ve asked questions person-
ally in private chats.” and when we asked if he helped
someone else, he answered “Yes, suggested work they
can do. But mostly over IRC.” .
•It does not account for the availability of mentors.James
JelmerVolkerZackJeremy
BjoernGerald
Love
Steve
Andrew
Herb
Stefan
DmitryRishi1616118
47
2
4
3
1
4111
1
Lars1Christopher
1
2
(a) One week after Bjoern approached the project
GeraldJames VolkerJeremyStefanChristopherJelmerAlexanderDerrellZack
BjoernSteve
Nadezhda
Corinna
Tim
Steven
Love
Michael
Richard
Andrew
Kai
Shirish
Ed
HerbDmitryTimurRonnieRishiAminDavid62716912726211
1812163
1
2
4
1
8
52121111312
11
Lars1
41
3
Karolin1
(b) One year after
Figure 3: Example (from Samba) of developers’ net-
work involving a newcomer (Bjoern) and a mentor
(James).
However, since Yoda proposes a list of mentors for a
newcomer, the project manager can easily assign to
the newcomer a mentor that is currently available.
•It matches the expertise required by the newcomer
with the expertise of possible mentors by comparing
the early emails of the newcomer with all emails of
the mentor. However, as we explained in Section 2.3,
it is not the purpose of this paper to propose a bet-
ter method to identify expertise, as others have been
proposed already in the past [2, 9, 19].
Threats to construct validity concern the relation between
the theory and the observation, and in this work are mainly
due to the measurements we performed. First, there could
be imprecisions in the way we mapped mailing list names
with versioning system IDs. However, we manually val-
idated this mapping. In addition, for systems using git
(Apache httpd, Samba, PostgreSQL, Python) the mapping
is straight-forward in that full names and emails are used as
git IDs. The“age”of a developer is computed by observing
the ﬁrst email exchanged, which might have occurred way
before (or way after) the person joined the project. Anotheraspect of our validation that is inherently subject to impre-
cision is the manual validation of Yoda recommendations.
We limited the degree of error-proneness and subjectiveness
by having two diﬀerent people performing the inspection in-
dependently.
Threats to internal validity concern external factors, we
did not consider, that could aﬀect the variables being inves-
tigated. The factors we considered, f1–f5, are only a partial
view of the mentor and newcomer experiences, and of their
inter-communication. There can be other factors we did not
consider. Future work will be devoted to consider other fac-
tors aiming at mitigating such a threat.
Threats to external validity concern the generalization of
our ﬁndings. We have performed our study on data from
ﬁve diﬀerent systems belonging to diﬀerent domains and
having diﬀerent size in terms of code base and number of
developers. Further evaluation is however necessary, espe-
cially in industrial environments where there can be a tacit
knowledge—within an organization, but not encoded in the
communications—of who can be a good mentor and who
not.
7. RELATED WORK
There have been several researchers investigating what
happens when a newcomer joins a software project, and
which are the factors for her growth, including mentoring.
Our work falls in the general area of those aimed at relating
social relations among developers with technical aspects of
the project they are working on. For example, Cataldo et
al.related the communication activity with software qual-
ity [12], and developers’ productivity [11].
Dagenais et al.[14] studied, by surveying 18 IBM develop-
ers, what happens when someone moves into a new“project
landscape”, making for her necessary to get acquitted with
the new environment. Among the factors they found impor-
tant, it is worthwhile to mention the need for early prac-
ticing, the availability of feedback for their work, and the
need for getting initial guidance . The latter is totally in
agreement with what we collected from our small survey,
and motivates approaches like Yoda. Fronza et al.[15] stud-
ied how newcomers join agile projects, ﬁnding that pair-
programming is used to initiate newcomers to a project.
Zhou and Mockus [22] investigated, on three industrial
and three open source projects, how the sociality level of a
project in a particular moment inﬂuences the likelihood for
newcomers to become long-term contributors. They found
that it is more likely that this happens when the project
sociality is low, because senior developers have more time
to train the newcomers. Zhou and Mockus concluded sug-
gesting the need for proper training plans for newcomers in
open source projects: this requires to identify appropriate
mentors. Zhou and Mockus [21] also identiﬁed challenges in
a software market where oﬀshoring, outsourcing and open
source development are increasing fast: understanding cul-
tural diﬀerences, analyzing how developers grow their exper-
tise, and providing tools to facilitate newcomers’ learning , as
Yoda does.
A diﬀerent perspective of developers’ growth in software
projects was studied by Sinha et al.[18] who investigated, on
the Eclipse project, how project contributors become com-
mitters, and found that this depends on having contributed
patches/source code of the project, being active in other
open source projects, or being part of the project organi-zation. Also, Bird et al.[7] investigated the phenomenon
of “immigration” in software projects, explaining the who,
how and when in the process of providing to newcomers the
authority to commit in the project repository.
In summary, while all these works highlighted the need for
supporting newcomers when they join a software project,
to the best of our knowledge this is the ﬁrst paper aimed
at proposing an approach to identify mentors in software
projects and to recommend them to newcomers.
In the past and recent years, other kinds of recommenders
have been proposed to support developers—especially junior
ones. Among others, Hipikat [13] provides recommendations
about components relevant for the current coding context of
the developer. As discussed in Section 2.3, identifying men-
tors also requires the selection of people having speciﬁc ex-
pertise. This has been done by Anvik et al.[2], by Canfora
and Cerulo [9], and by Tamrawi et al.[19] who proposed
approaches—based on machine learning, IR, and fuzzy clus-
tering respectively—for bug triaging, i.e., to determine the
most suited developers able to ﬁx an incoming bug.
8. CONCLUSIONS AND FUTURE WORK
Mentoring is particularly important to make software pro-
ject newcomers knowledgeable of various aspects of the pro-
jectonwhichtheyarecontributing, suchastechnicaldetails,
coding guidelines, and organizational rules. As part of our
studywecontactedcontributorstoopensourceprojects, one
ofwhichmentioned “My general view is that it is very impor-
tant that mentor and mentee share at least the mindset and
the same passions. My primary mentors have been ...and
they both had a very strong technical background, something
I deﬁnitively wanted to match.”
This paper proposed Yoda, an approach to identify men-
tors by relying on historical data from a software project,
andthenrecommendthemwhenanewcomerjoinstheproject.
Being inspired by ArnetMiner —a tool that analyzes aca-
demic collaborations—Yoda identiﬁes mentoring when the
newcomer exchanges most of her emails with the mentor,
and the mentor has a higher social importance and project
agethanthementor. Then, whenanewcomerjoinsaproject,
her early discussion is used to identify the expertise she is re-
quiring, and Yoda recommends, among the candidate men-
tors previously identiﬁed, those who exhibited a discussion
(textually) similar to the newcomer early discussion.
Yoda has been evaluated on data from ﬁve open source
projects, Apache httpd, the FreeBSD kernel, PostgreSQL,
Python, and Samba. Results of the study indicate that, ex-
cept for FreeBSD, Yoda is able to identify candidate pairs
of mentor-newcomer with a precision in most cases higher
than 80%, and recommend them with a precision greater
than 70%. Instead, relying on top committers as an al-
ternative to Yoda does not produce as accurate results as
those of Yoda. Comments collected from project developers
indicated us that mentoring is important and depends on
project knowledge and communication skills more than on
experience.
Work-in-progress is directed towards diﬀerent directions.
We plan to further improve Yoda by considering factors able
to better capture the technical skills of mentors. Also, we
plan to replicate the study on further projects. Finally, we
plan to develop an assessment technique for developers’ net-
work aimed at automatically identifying cases—such as the
one of FreeBSD in your study—where Yoda is not applica-ble as such, and if possible identify countermeasures for such
scenarios.
Acknowledgments
We would like to thank the contributors of FreeBSD, Post-
greSQL, Python, and Samba who responded to our survey.
We would also thank Annibale Panichella for his help in the
manual validation of the results.
9. REFERENCES
[1] G. Antoniol, G. Canfora, G. Casazza, A. De Lucia,
and E. Merlo. Recovering traceability links between
code and documentation. IEEE Transactions on
Software Engineering , 28(10):970–983, 2002.
[2] J. Anvik and G. C. Murphy. Reducing the eﬀort of
bug report triage: Recommenders for
development-oriented decisions. ACM Trans. Softw.
Eng. Methodol. , 20(3):10, 2011.
[3] J. Aranda and G. Venolia. The secret life of bugs:
Going past the errors and omissions in software
repositories. In 31st International Conference on
Software Engineering, ICSE 2009, May 16-24, 2009,
Vancouver, Canada, Proceedings , pages 298–308, 2009.
[4] A. Bacchelli, M. Lanza, and R. Robbes. Linking
e-mails and source code artifacts. In Proceedings of the
32nd ACM/IEEE International Conference on
Software Engineering - Volume 1, ICSE 2010, Cape
Town, South Africa, 1-8 May 2010 , pages 375–384.
ACM, 2010.
[5] R. Baeza-Yates and B. Ribeiro-Neto. Modern
Information Retrieval . Addison-Wesley, 1999.
[6] C. Bird, A. Gourley, P. T. Devanbu, M. Gertz, and
A. Swaminathan. Mining email social networks. In
Proceedings of the 2006 International Workshop on
Mining Software Repositories, MSR 2006, Shanghai,
China, May 22-23, 2006 , pages 137–143, 2006.
[7] C. Bird, A. Gourley, P. T. Devanbu, A. Swaminathan,
and G. Hsu. Open borders? immigration in open
source projects. In Fourth International Workshop on
Mining Software Repositories, MSR 2007,
Minneapolis, MN, USA, May 19-20, 2007,
Proceedings , page 6. IEEE Computer Society, 2007.
[8] C. Bird, N. Nagappan, B. Murphy, H. Gall, and P. T.
Devanbu. Don’t touch my code!: examining the eﬀects
of ownership on software quality. In SIGSOFT/FSE’11
19th ACM SIGSOFT Symposium on the Foundations
of Software Engineering and 13rd European Software
Engineering Conference, Szeged, Hungary, September
5-9, 2011 , pages 4–14. ACM, 2011.
[9] G. Canfora and L. Cerulo. Supporting change request
assignment in open source development. In
Proceedings of the 2006 ACM Symposium on Applied
Computing (SAC), Dijon, France, April 23-27, 2006 ,
pages 1767–1772. ACM, 2006.
[10] G. Canfora, L. Cerulo, M. Cimitile, and M. Di Penta.
Social interactions around cross-system bug ﬁxings:
the case of FreeBSD and OpenBSD. In Proceedings of
the 8th International Working Conference on Mining
Software Repositories, MSR 2011 (Co-located with
ICSE), Waikiki, Honolulu, HI, USA, May 21-28,
2011, Proceedings , pages 143–152, 2011.[11] M. Cataldo, J. D. Herbsleb, and K. M. Carley.
Socio-technical congruence: a framework for assessing
the impact of technical and work dependencies on
software development productivity. In Proceedings of
the Second International Symposium on Empirical
Software Engineering and Measurement, ESEM 2008,
October 9-10, 2008, Kaiserslautern, Germany , pages
2–11. ACM, 2008.
[12] M. Cataldo, P. Wagstrom, J. D. Herbsleb, and K. M.
Carley. Identiﬁcation of coordination requirements:
implications for the design of collaboration and
awareness tools. In Proceedings of the 2006 ACM
Conference on Computer Supported Cooperative Work,
CSCW 2006, Banﬀ, Alberta, Canada, November 4-8,
2006, pages 353–362, 2006.
[13] D. Cubranic, G. C. Murphy, J. Singer, and K. S.
Booth. Hipikat: A project memory for software
development. IEEE Trans. Software Eng. ,
31(6):446–465, 2005.
[14] B. Dagenais, H. Ossher, R. K. E. Bellamy, M. P.
Robillard, and J. de Vries. Moving into a new software
project landscape. In Proceedings of the 32nd
ACM/IEEE International Conference on Software
Engineering - Volume 1, ICSE 2010, Cape Town,
South Africa, 1-8 May 2010 , pages 275–284. ACM,
2010.
[15] I. Fronza, A. Sillitti, and G. Succi. An interpretation
of the results of the analysis of pair programming
during novices integration in a team. In Proceedings of
the Third International Symposium on Empirical
Software Engineering and Measurement, ESEM 2009,
October 15-16, 2009, Lake Buena Vista, Florida,
USA, pages 225–235, 2009.
[16] M. F. Porter. An algorithm for suﬃx stripping.
Program , 14(3):130–137, 1980.
[17] G. Robles, J. M. Gonz´ alez-Barahona, and I. Herraiz.Evolution of the core team of developers in libre
software projects. In Proceedings of the 6th
International Working Conference on Mining Software
Repositories, MSR 2009, Vancouver, BC, Canada,
May 16-17, 2009 , pages 167–170. IEEE, 2009.
[18] V. S. Sinha, S. Mani, and S. Sinha. Entering the circle
of trust: developer initiation as committers in
open-source projects. In Proceedings of the 8th
International Working Conference on Mining Software
Repositories, MSR 2011, Waikiki, Honolulu, HI, USA,
May 21-28, 2011, Proceedings , pages 133–142. IEEE,
2011.
[19] A. Tamrawi, T. T. Nguyen, J. M. Al-Kofahi, and
T. N. Nguyen. Fuzzy set and cache-based approach for
bug triaging. In SIGSOFT/FSE’11 19th ACM
SIGSOFT Symposium on the Foundations of Software
Engineering and 13rd European Software Engineering
Conference, Szeged, Hungary, September 5-9, 2011 ,
pages 365–375. ACM, 2011.
[20] C. Wang, J. Han, Y. Jia, J. Tang, D. Zhang, Y. Yu,
and J. Guo. Mining advisor-advisee relationships from
research publication networks. In Proceedings of the
16th ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, Washington,
DC, USA, July 25-28, 2010 , pages 203–212, 2010.
[21] M. Zhou and A. Mockus. Growth of newcomer
competence: challenges of globalization. In
Proceedings of the Workshop on Future of Software
Engineering Research, FoSER 2010, at the 18th ACM
SIGSOFT International Symposium on Foundations
of Software Engineering, 2010, Santa Fe, NM, USA,
November 7-11, 2010 , pages 443–448, 2010.
[22] M. Zhou and A. Mockus. Does the initial environment
impact the future of developers. In Proceedings of the
33rd International Conference on Software
Engineering, ICSE 2011, Waikiki, Honolulu , HI,
USA, May 21-28, 2011 , pages 271–280. ACM, 2011.