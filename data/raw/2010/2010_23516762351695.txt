An Automated Approach to Forecasting QoS Attributes
Based on Linear and Non-linear Time Series Modeling
Ayman Amin
Faculty of Information and
Communication Technologies
Swinburne University of
Technology
Hawthorn, VIC 3122, Australia
aabdellah@swin.edu.auLars Grunske
Software Engineering: AG
AQUA
University of Kaiserslautern
Kaiserslautern,67653,
Germany
grunske@cs.uni-kl.deAlan Colman
Faculty of Information and
Communication Technologies
Swinburne University of
Technology
Hawthorn, VIC 3122, Australia
acolman@swin.edu.au
ABSTRACT
Predicting future values of Quality of Service (QoS) attrib utes
can assist in the control of software intensive systems by pr e-
venting QoS violations before they happen. Currently, many
approaches prefer Autoregressive Integrated Moving Aver-
age (ARIMA) models for this task, and assume the QoS
attributes’ behavior can be linearly modeled. However, the
analysis of real QoS datasets shows that they are character-
ized by a highly dynamic and mostly nonlinear behavior to
the extent that existing ARIMA models cannot guarantee
accurate QoS forecasting, which can introduce crucial prob -
lems such as proactively triggering unrequired adaptation s
and thus leading to follow-up failures and increased costs. To
address this limitation, we propose an automated forecast-
ing approach that integrates linear and nonlinear time seri es
models and automatically, without human intervention, se-
lects and constructs the best suitable forecasting model to
ﬁt the QoS attributes’ dynamic behavior.Using real-world
QoS datasets of 800 web services we evaluate the applica-
bility, accuracy, and performance aspects of the proposed
approach, and results show that the approach outperforms
the popular existing ARIMA models and improves the fore-
casting accuracy by on average 35.4%.
Categories and Subject Descriptors
D.2 [Software Engineering ]: Subjects— Software conﬁgu-
ration management
General Terms
Algorithms, Performance
Keywords
Quality of Service (QoS), Runtime Adaptation, Automated
QoS Forecasting, Time Series Models
Permission to make digital or hard copies of all or part of thi s work for
personal or classroom use is granted without fee provided th at copies are
not made or distributed for proﬁt or commercial advantage an d that copies
bear this notice and the full citation on the ﬁrst page. To cop y otherwise, to
republish, to post on servers or to redistribute to lists, re quires prior speciﬁc
permission and/or a fee.
ASE’12, September 3-7, 2012, Essen, Germany
Copyright 2012 ACM 978-1-4503-1202-8/12/04 ...$10.00.1. INTRODUCTION
The current trend towards run-time adaptable and recon-
ﬁgurable systems that include dedicated Quality of Service
(QoS) management and control components [9] has led to
a need for automatic detection of QoS problems during the
system operation. Action can then be taken to ameliorate
underperformance subject to the range of regulation or re-
conﬁguration capabilities and strategies available to the sys-
tem. To detect if a QoS attribute misses a predeﬁned QoS
goal, runtime monitoring approaches [5, 22, 23] enriched
with statistical decision procedures [2, 4, 15, 16] are used .
However, any adaptation to solve the QoS problem is al-
ways in response to a violation that has already occurred,
thus system users have to live with the QoS problem until
the remedial action has been applied.
Recently, QoS forecasting based on time series modeling
[7, 3] has been presented as a promising technique to predict
future QoS values in order to support and improve proactive
QoS management [21, 24, 28, 29, 30] and QoS-based service
selection and composition [10, 14, 19] in dynamic environ-
ments. These approaches assume that historical QoS mea-
sures can be linearly modeled, and use time series ARIMA
models to ﬁt these measures and predict their future val-
ues. Researchers [10, 14] argue that studying the dynamic
characteristic of QoS attributes and proposing an eﬃcient
forecasting approach is an urgent need to improve proactive
management and service selection. In addition, our analy-
sis of real QoS datasets shows that they are characterized
by a high dynamic and mostly nonlinear behavior to the
extent that existing ARIMA models cannot guarantee ac-
curate QoS forecasting where these models are based on a
linearity assumption [7]. This can introduce crucial prob-
lems such as proactively triggering unrequired adaptation s
which may lead to follow-up failures and increased costs.
To address this limitation, we propose an automated fore-
casting approach which integrates linear and nonlinear tim e
series models and automatically, without human interven-
tion, selects and constructs the best suitable forecasting
model to ﬁt the QoS dynamic behavior and provide accu-
rate forecasts. The approach uses ARIMA as a linear model
and Self Exciting Threshold ARMA (SETARMA) as a non-
linear model, because these models together are very eﬃ-
cient and can correctly model the complicated and dynamic
QoS behavior [26]. This approach basically consists of two
components; one for constructing the forecasting model andPermission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ASE’12, September 3–7, 2012, Essen, Germany
Copyright 2012 ACM 978-1-4503-1204-2/12/09 ...$15.00
130
the other for continuously forecasting future QoS values an d
evaluating the accuracy of this forecasting.
The main contributions of this paper include:
1. We propose an automated approach for runtime QoS
forecasting based on integrating linear and nonlinear
time series models. In addition, we illustrate how the
proposed approach checks for the time series mod-
els’ assumptions, and if they are not satisﬁed how it
searches for and performs suitable remedies.
2. Based on QoS datasets of 800 real-world web services,
we evaluate the satisfaction of time series models’ as-
sumptions in reality and the most suitable remedies
in the case of dissatisfaction. In addition, we apply
the proposed approach to these datasets, especially re-
sponse time and time between violations, to evaluate
the accuracy and performance of our automated ap-
proach.
The rest of the paper is organized as follows. Section
2 introduces time series models background and their as-
sumptions. The proposed approach is discussed in Section
3. Evaluation study of the proposed approach is reported in
Section 4. Section 5 discusses the related work. Section 6
concludes the paper and outlines directions for future work .
2. TIME SERIES MODELING BACKGROUND
In this section, we present time series models, especially
ARIMA and SETARMA, and then discuss their main as-
sumptions.
2.1 Time Series Models
2.1.1 ARIMA Models
AutoRegressive Integrated Moving Average (ARIMA) mod-
els were originally proposed by Box and Jenkins [7], and they
are commonly used in practice to model time series data to
forecast the future values. Simply, a time series {yt}is said
to be modeled by an ARMA model of orders pandq, de-
noted by ARMA( p,q), if it satisﬁes
φp(B)yt=θq(B)εt (1)
where, {εt}is a sequence of independent normal errors with
zero mean and variance σ2. The backshift operator B is
deﬁned as Bxt=xt−1. The autoregressive polynomial is
φp(B) =/parenleftbig
1−φ1B−φ2B2− · · · − φpBp/parenrightbig
with order p and
θq(B) =/parenleftbig
1 +θ1B+θ2B2+· · ·+θqBq/parenrightbig
is the moving aver-
age polynomial with order q. The autoregressive and mov-
ing average coeﬃcients are φ= (φ1, φ2,· · ·, φp)Tandθ=
(θ1, θ2,· · ·, θq)Trespectively. The model (1) can be simpli-
ﬁed and written as
yt=p/summationdisplay
i=1φiyt−i+q/summationdisplay
i=1θiεt−i+εt (2)
where, ytis the current stationary observation, yt−ifor i =
1, ..., p are the past stationary observations, εtis the current
error, and εt−ifori= 1, ..., q are the past errors.
Ifddiﬀerences have been done to transform the original
non-stationary time series {zt}into the stationary one {yt},
then{zt}is said to be generated by an Autoregressive Inte-
grated Moving Average (ARIMA) model of orders p,d, and
qand denoted by ARIMA( p,d,q).2.1.2 SETARMA Models
Self Exciting Threshold ARMA models (SETARMA) were
introduced by Tong and Lim [27] and studied in details by
Tong [25, 26]. The basic idea of these models is to start
with a linear model and then allow the model parameters to
vary according to the past values of the time series process.
In other words, the time series process is assumed to follow
one of a ﬁnite set of diﬀerent linear models with thresholds
for the passage from one member of this set to another. A
SETARMA model of order ( l;p1, p2,· · ·, pl;q1, q2,· · ·, ql) or
SETARMA ( l;p1, p2,· · ·, pl;q1, q2,· · ·, ql) can be written in
the form:
yt=µ(j)+pj/summationdisplay
i=1φ(j)
iyt−i+qj/summationdisplay
i=0θ(j)
sεt−iif r j−1≤yt−dp< rj
(3)
where, dpis a positive integer known as the delay parameter,
φ(j)
i, θ(j)
s(i= 1,2,· · ·, pj;s= 1,2,· · ·, qj;j= 1,2,· · ·, l) are
model parameters, and/braceleftbig
εj
t/bracerightbig
(j= 1,2,· · ·, l) are a sequence
of iid random variables with mean zero and variance σ2<
∞, each being independent of one another and of {yt}. The
ordered constants −∞=r0< r 1<· · ·< rl=∞are known
as the thresholds.
When qj= 0 ( j= 1,2,· · ·, l) the SETARMA model is
reduced to the self exciting threshold autoregressive mode l,
SETAR( l;p1, p2,· · ·, pl). Similarly, the self exciting thresh-
old moving average model, SETMA( l;q1, q2,· · ·, ql) is a spe-
cial case of SETARMA when pj= 0 ( j= 1,2,· · ·, l). If
the autoregressive orders and moving average orders are the
same for all regimes and equal to p and q respectively, the
SETARMA model (3) takes the form:
yt=µ(j)+p/summationdisplay
i=1φj
(i)yt−i+q/summationdisplay
i=0θ(j)
iεt−i if r j−1≤yt−dp< rj,
(4)
which is SETARMA( l, p, q ) where pand qare repeated l
times.
2.2 Assumptions of Time Series Models
The main assumptions of time series models are serial de-
pendency, normality, stationarity, and invertibility [7] :
1.Serial dependency: In order for time series data to
be eﬀectively characterized using time series models,
it should be serially dependent (autocorrelated) over
time. If the time series data is random (e.g.white
noise) time series models cannot be used to forecast
future values and other forecasting methods should be
investigated to be used for this task.
2.Normality: Time Series models assume that the given
time series data is normally distributed, as all the com-
putations of identifying, estimating, and evaluating its
parameters are based on a normal distribution. In the
case of non-normally distributed time series data, it
can be approximated to normal distribution using spe-
ciﬁc power transformations [6].
3.Stationarity: Roughly speaking, stationarity means the
time series has constant mean and variance, no trend
and same variation, over time. When a time series has
no trend, it is called stationary in the mean; and when
it has same variation over time, it is called stationary
in the variance. However, if the original time series is131non-stationary, it can be transformed into a stationary
in the mean using diﬀerences and into a stationary in
the variance using power transformations.
4.Invertibility: Time series models that are used to fore-
cast the future values should be invertible. This means,
error terms can be expressed as a weighted sum of cur-
rent and prior observations and prior errors to enable
forecasting. For example, in the simplest case, MA(1),
error terms can be written as: εt=yt−θεt−1, and
it can be proved that they are equivalent to: εt=
yt−/summationtext∞
i=1θiyt−i. This model cannot be used to fore-
cast future errors except that εthas a ﬁnite value which
requires that θto be less than one, and this is called
the invertibility concept.
Investigating whether the given time series data satisﬁes
these assumptions is crucial task, as unsatisﬁed assumptio ns
leads to incorrect time series models which in turn will pro-
vide inaccurate forecasts. In section 3 we discuss in detail
how these assumptions can be veriﬁed, and if they are not
satisﬁed how we can deal with this issue through a running
example.
3. THE PROPOSED APPROACH
The proposed forecasting approach integrates ARIMA and
SETARMA models to capture the dynamic behaviour of
QoS attributes and accurately forecast their future values .
In brief summary, based on the given software system be-
haviour in terms of QoS attributes our approach selects and
constructs an appropriate time series model and uses it to
describe how well the software system behaves and then
gives accurate forecasts for that behaviour. Technically,
it uses the collected QoS data to construct the time series
model and continuously using the new obtained QoS data
to update this model and provide accurate QoS forecasts.
This approach consists of two components; one for con-
structing the time series model and the other for forecastin g
future QoS values and evaluating the accuracy of this fore-
casting, as explained in Figure 1. For more illustration how
this approach works, the functionalities of each component
will be explained in the following with a running example of
a response time data set (which is referred as WS 1(RT)) of a
web service ”Lodge”used by Messagenet1to allow customers
to send and receive SMS, MMS, and eFax.
3.1 Time Series Model Construction Process
The main task of this component is to construct the time
series model. It is achieved through seven phases:
3.1.1 Data Preparation (P1)
Before constructing any time series model, the given time
series data should satisfy the underlying assumptions of ti me
series models which are described above. Consequently in
this phase, the main task is to check for these assumptions,
and if they are not satisﬁed, try to ﬁnd the suitable trans-
formation to approximately fulﬁll the assumptions.
The proposed approach uses statistical tests to check for
the assumptions. First, the approach checks for serial depe n-
dency using the runs test [13]. If this condition is satisﬁed ,
it checks for normality using the Kolmogorov-Smirnov (K-S)
test [13] and for stationarity using the KPSS test [18].
1http://messagenet.com.au/Time Series Model Construction Process
Continuous Forecasting ProcessCollected
QoS Data
New
QoS Data          (P9)
Evaluate Forecasting
         Accuracy          (P8)
Compute Forecast
   and ResidualsIs It 
OK?No
Yes         (P1) 
 Check & Satisfy
  Assumptions          (P2)
Identify Model Order          (P3)
Test For NonLinearity
          (P5)
Specify Adequate
         Models         (P6)
Estimate Specified
        Models         (P7)
Check Diagnostics and
Select The Best ModelNon-
Linear?               (P4)
Identify Delay Parameter
  and Threshold Values
NoYes
Forecasts
Figure 1: The proposed forecasting approach
For achieving normality and stationarity in the variance,
power transformations, especially Box-Cox transformatio ns
[6], can be used. For explanation, the Box-Cox transforma-
tion yt(λ)of a time series ztis given as follows:
yt(λ)(zt) =(zλ
t−1)
λ, λ ≥0 (5)
where the value of λis chosen to reduce the variation of the
time series ztand to achieve normality and stationarity in
the variance. Regarding stationarity in the mean, diﬀerenc es
of non-stationary time series can be used and produce a
stationary one. For example, let {zt}be the original time
series, and it is non-stationary in the mean, but it has a
trend over time. It can be transformed into a stationary one
{yt}using the ﬁrst diﬀerence, yt=zt−zt−1.
Example ⊲The proposed approach veriﬁes whether WS 1
(RT) satisﬁes the assumptions as follows:
Serial dependency: To verify the serial dependency, the
approach uses a runs test [13] to test the null hypothesis tha t
the time series are mutually independent. If this hypothesi s
is rejected that means our time series data is serially depen -
dent. The approach has applied the runs test to WS 1(RT)
and concluded that it is signiﬁcantly serially dependent wi th
a p-value <0.05.
Normality: To check whether the data is normally dis-
tributed, the approach uses the K-S test [13] to test the null
hypothesis that the data is drawn from a normal distribu-
tion. If this hypothesis is rejected, the approach will sear ch
for a suitable transformation for the data to be (approxi-
mately) normally distributed. The approach has applied K-
S test to WS 1(RT) and concluded that it is not normally dis-
tributed; however, the log transformation provided approx -
imately normally distributed data (referred as WS 1(LRT))
where the p-value of the K-S test equals to 0.521.
Stationarity: Our approach has used the KPSS test [18]
to test whether the time series WS 1(LRT) is stationary, and
found that it is not stationary where the p-value equals to1320.028 ( <0.05). Using the ﬁrst diﬀerence, the approach con-
cluded that the diﬀerenced data (referred as WS 1(DLRT) is
stationary (where p-value = 0.481). Therefore, the output
of this phase is the dataset WS 1(DLRT) that satisﬁes the
assumptions and can be used in the next phases. ⊳
3.1.2 Model Order Identiﬁcation (P2)
After preparing the time series data, the model order
identiﬁcation phase starts. This phase selects the best sui t-
able parameters pandqfor the time series model. This is
mainly based on an evaluation of the autocorrelation func-
tion (ACF) and the partial autocorrelation function (PACF)
[7] and achieved as follows: If the ACF curve decays and the
PACF curve cuts oﬀ (after plags), an AR or SETAR model
(of order p) is adequate to model the processed data. In con-
trast, if the ACF curve cuts oﬀ (after qlags) and PACF curve
decays, an MA or SETMA model (of order q) is adequate.
In addition, if both ACF and PACF curves cut oﬀ after q
andplags respectively, an ARMA( p,q) or SETARMA( p,q)
models are adequate. Identifying the values of pandqis
important for the next phase (P3) to test the nonlinearity
and decide what model class is statistically preferred to be
used, i.e. ARIMA or SETARMA.
Example ⊲The ACF and PACF of the prepared data,
WS 1(DLRT), are computed and plotted in Figure 2. From
this Figure it can be seen that ACF decays and PACF cuts
oﬀ after 2 lags. Therefore, the identiﬁed order of a time
series model is p= 2 and q= 0. ⊳
Figure 2: ACF and PACF values of WS 1(DLRT)
3.1.3 Non-Linearity Test (P3)
In this phase the approach uses the Hansen test [17] to
test for the nonlinearity. Basically, the approach tests th e
null hypothesis that the given QoS data can be modeled
by a linear ARIMA model against the alternative hypoth-
esis that it is statistically recommended to be modeled by
a SETARMA model. The main inputs for this test are the
parameter p, which is identiﬁed in P2, and the delay param-
eter dp. As the value of the delay parameter is unknown,
the approach uses all its possible values which are less than
the parameter pand this value can be reﬁned later based on
the test statistic values. Based on the outcome of this test
the approach speciﬁes the type of time series modeling, i.e.
it is ARIMA or SETARMA.Example ⊲Because the approach found in P2 that p= 2,
it runs the Hansen test two times with inputs ( p= 2 and
dp= 0) and ( p= 2 and dp= 1) and concludes that this
dataset has signiﬁcantly (p-values <0.05) nonlinear behav-
ior and requires to be modeled by SETARMA model. ⊳
3.1.4 Delay Parameter and Thresholds Identiﬁcation
(P4)
The delay parameter and thresholds values can be iden-
tiﬁed from the output of the Hansen test, and they are the
values that correspond the largest statistic value.
Example ⊲The output of the Hansen test is depicted in
Table 1. It is clear from this Table that the delay parameter
dp= 0 and the threshold value is 85. ⊳
Table 1: Hansen test results
Delay Threshold Statistic
Value Estimate Value P-Value
0 85.69 4.45 0.019
1 86.25 4.01 0.023
3.1.5 Adequate Models Speciﬁcation (P5)
After specifying the order and type of the time series
model, the proposed approach speciﬁes a combination of
adequate models for the given QoS dataset. This combina-
tion is based on the dependency structure of the given QoS
dataset and under-estimation and over-estimation methods .
Example ⊲As the identiﬁed model order is p= 2 and
q= 0 and the model type is SETARMA, then based on
the under-estimation and over-estimation methods the iden -
tiﬁed models for WS 1(DLRT) are: SETARMA(1,1,0), SE-
TARMA(1,2,0), and SETARMA(1,3,0). ⊳
3.1.6 Models Estimation (P6)
In the model estimation phase, values of the parameters
of the speciﬁed adequate models in phase P5 are analysed
to provide the best ﬁt to the given time series data. Maxi-
mum likelihood estimation (MLE) [7] and conditional least
squares (CLS) [26] are the most commonly used methods
to estimate ARIMA and SETARMA models respectively.
Therefore, these two methods are recommended to be used
by our proposed approach.
Example ⊲After identifying the adequate SETARMA
models in P5, the approach has used the CLS method for
each model to estimate the parameters and the estimates
are depicted in Table 2. ⊳
3.1.7 Models Checking and The Best Model Selec-
tion (P7)
Model checking involves testing the diagnostics of the time
series models to identify whether they are satisﬁed. If one
or more diagnostics are not satisﬁed, the current model is
inadequate and it is necessary to be removed from the set
of models speciﬁed in P5. The following diagnostics can be
performed to check the ﬁtted time series models:
1. Estimates Signiﬁcance Test Each estimate is tested
to check whether it is statistically signiﬁcant using the t- test.
If all the estimates are signiﬁcant, they are retained in the133model; and otherwise, the model requires a recalculation
using only the signiﬁcant estimates.
2. Invertibility and Stationarity Conditions Satis-
faction In the model checking phase, invertibility and sta-
tionarity conditions can be checked as follows: (1) Station -
arity Condition: sum of the coeﬃcients of the AR model
should be less than one, it means that/summationtextp
i=1φi<1; and
(2) Invertibility Condition: sum of the coeﬃcients of the MA
model should be less than one, it means that/summationtextp
i=1θi<1.
3. Residuals Randomness Residuals of the well ﬁtted
model will be uncorrelated. For this condition, residuals
can be analyzed and a hypothesis test, i.e. the Box-Pierce
test [8], can be performed to make a statistically signiﬁcan t
decision regarding this condition.
Once the speciﬁed models have been estimated and checked,
the best model is selected based on Akaike’s information cri -
terion (AIC) [1] where the best model is the one that has
the minimum AIC value.
Example ⊲The approach computed the t-test for all the
estimates and its p-values are depicted in Table 2. It is clea r
that all the estimates of the ﬁrst two models are signiﬁcant,
and the third one has insigniﬁcant estimates. Therefore,
our algorithm will ignore the third model and focus only
on the ﬁrst two models, and it is evident from Table 2 that
these models satisfy invertibility and stationarity condi tions.
To analyze the residuals, the approach has used Box-Pierce
test [8] and concluded that the two models’ residuals are
uncorrelated. Now based on AIC value the approach needs
to select the best model of these two. The AIC values for
the models are: 470.57 and 467.04 respectively. Accordingl y,
the second model, SETARMA(1,2,0) is the best model to
forecast the future values of WS 1(RT). ⊳
Table 2: Estimation of the identiﬁed models
Model Regime Parameter Estimate P-value
ILow SETAR(1) -0.610 0.000
High SETAR(1) 0.075 0.019
IILowSETAR(1) -0.658 0.000
SETAR(2) -0.098 0.043
HighSETAR(1) 0.070 0.023
SETAR(2) 0.099 0.031
IIILowSETAR(1) -0.752 0.000
SETAR(2) -0.058 0.026
SETAR(3) 0.143 0.381
HighSETAR(1) 0.067 0.025
SETAR(2) 0.087 0.041
SETAR(3) -0.032 0.519
3.2 Continuously Forecasting Process
This component uses the best selected model and the new
obtained QoS data to continuously forecast the future QoS
values (through phase P8). Additionally through phase P9,
it computes forecasting errors and uses the Box-Pierce test
[8] to evaluate the forecasting accuracy. If the forecasts a re
inaccurate, the approach will return back to P5 to re-specif y
other adequate models based on the new QoS data and the
information obtained from the forecasting errors analysis .
Example ⊲The constructed SETARMA(1,2,0) model is
used to forecast the future values of WS 1(TR), and the one-step-ahead forecasts of the last 100 observations are depic ted
in Figure 3. ⊳
Figure 3: Actual vs. predicted values of WS 1(RT)
4. EV ALUATION
In this section we investigate various applicability, accu -
racy, and performance aspects of the proposed approach,
and then discuss threats to validity of our work.
4.1 Experiment Setup
To investigate the applicability, performance, and accu-
racy aspects of the proposed approach, we identify the main
research questions as follows.
RQ1 : To what extent the real-world QoS datasets satisfy
the time series models’ assumptions, and what are the most
suitable remedies where the data does not satisfy these as-
sumptions?
RQ2 : Is the proposed approach able to capture the dynamic
behavior of QoS attributes and improve the forecasting ac-
curacy comparing to ARIMA models?
RQ3 : What time is required for the approach to automati-
cally construct and use the forecasting model?
RQ4 : Do the approach’s accuracy and performance depend
on the given number of QoS observations?
In order to address RQ1 , we have invoked 800 real-world
web services using the tool Ws-dream [31] and computed
their response time and time between violations (TBV). The
response time is computed by measuring the time taken be-
tween sending a request to a service and receiving a response .
On the other hand, the TBV is computed as the time be-
tween two violations of a predeﬁned response time’s con-
straint. The description of all these real-world web servic es
and their response time datasets are available on-line1, and
the description of a sample of these services is reported in
Table 3. We analyzed the statistical characteristics of the se
response time datasets and their satisfaction for time seri es
models assumptions.
In order to answer RQ2 , we apply the proposed fore-
casting approach and ARIMA models to the response time
and TBV datasets. For each dataset prediction we compute
1http://mercury.it.swin.edu.au/g_archeopterix/
experiments/AFoQoS/RealWSsResponseTimes.rar134Table 3: Characteristics of the monitored real web services
WS idWS Name Description Provider Name RTC1(ms)
WS1Lodge Used by Messagenet to allow customers to send and receive SMS ,
MMS, and efaxmessagenet.com.au 90
WS2ABRXMLPubSub Used by Australian Business Register (ABR) to download or
return a list of published ﬁles of registered businessbusiness.gov.au 60
WS3E-CommServices Used by Stratapay to return a dataset with approved payments
and statusstratapay.com.au 100
WS4Login Used by Tabcorp organization to validate the username and
password and return a key passed with all other web service
requeststabcorp.com.au 50
WS5SupplierList Public service to retrieve Supplier Information pharmx.com.au 50
WS6SharepointEmailWS Used by Genome forums to allow members to create, modify
and delete contactgenom-e.com 700
WS7PayService Basic routines to accomplish users needs to interact with th e
DanDomain’s online payment service.dandomain.dk 700
WS8ArticlesSecure Provides access to articles, accessible for authorized use rs fossware.com 900
WS9ChinaTV-Program WS Provides online access to Chinese television stations webxml.com.cn 800
WS10WeatherWebService Reports weather information for major cities in china webxml.com.cn 600
WS11ExchangeRateWebService Provides real time foreign exchange rate for world currenci es webxml.com.cn 800
WS12ChinaStockWebService Reports timely Chinese stock market data (stock name, price ,
...)webxml.com.cn 1000
WS13WeatherWS Monitors the current state of air quality in Prague premis.cz 1200
WS14HydrologyWS Monitors the watercourses parameters premis.cz 2000
WS15MeteorologyWS Monitors the meteorological parameters premis.cz 4000
1 Response Time Constraint in milliseconds
mean absolute percentage errors (MAPE) as follows:
MAP E =1
nn/summationdisplay
t=1|yt−ˆyt
yt| ×100 (6)
where ytand ˆ ytare the real and predicted values respec-
tively. We analyze these errors using boxplots and descrip-
tive statistics. To test whether the proposed approach sig-
niﬁcantly outperforms ARIMA models in terms of forecast-
ing accuracy, we use the non-parametric Mann-Whitney test
[13]. Additionally, we measure the relative forecasting ac cu-
racy improvement (RAI) deﬁned as:
RAI =MAP E ARIMA −MAP E Ours
MAP E ARIMA×100 (7)
where MAP E Ours andMAP E ARIMA refer to the MAPE
values produced by our proposed approach and ARIMA-
model-based approach respectively.
To address RQ3 , the time needed for the approach to au-
tomatically construct and use the forecasting model for the
given response time and TBV datasets (through the diﬀerent
phases depicted in Figure 1) was computed.
To answer RQ4 , we apply the proposed approach to the
response time and TBV datasets with varying size from 50 to
1,000 observations with an increment of 50 observations, an d
then compute the MAPE values and the time needed for the
approach to automatically construct and use the forecastin g
model as metrics for the approach’s accuracy and perfor-
mance respectively. As a platform for our experiments, we
used a Windows-based PC equipped with a 3.00 GHz dual-
core processor and 4GB main memory.
4.2 Results
RQ1. The satisfaction of time series models assump-
tions in reality:
The analysis results of the statistical characteristics of the
response time datasets and their satisfaction for time seri es
model assumptions are presented in Table 4 and discussed
as follows:1. Serial dependency: We found about 94.6% of the real
datasets are serially dependent. That means, in 94.6%
of the real cases time series models are suitable to be
used to forecast the future software system response
times.
2. Normality: The analysis concludes that most of the
datasets are non-normally distributed ( >99%). How-
ever, using the Box-Cox power transformation can trans-
form the data to be normally distributed, and we expe-
rienced that 95% of these Box-Cox transformation val-
ues are in the interval (-2, 2). This result implies that
normality assumption can be achieved using power trans-
formation; and based on our practical experience, we
can report that the logarithmic transformation can be
used in most of the cases and provides symmetric if
not always normally distributed data.
3. Stationarity: Based on our analysis, we can report that
about 71.6% of the real datasets are stationary and do
not require any transformations or preparation activ-
ities. Of the non-stationary real datasets 21.76% and
6.68% can be transformed to be stationary using the
ﬁrst and the second diﬀerences respectively.
4. Linearity: We applied the Hansen test [17] to these re-
sponse time datasets, and found that about 26.4% can
be linearly modeled; However for the majority (73.6%),
it is statistically recommended to be modeled by SE-
TARMA models.
Based on this empirical analysis, we can conclude that
most of the real response time datasets are serially depen-
dent and can be transformed to be stationary and normally
distributed. This implies that time series models, especia lly
SETARMA, can be used to forecast the future QoS values
with some suitable transformations and preparation activi -
ties for the original datasets to satisfy their assumptions .135Table 4: The satisfaction of time series models’ assumption s
Serial Normality Stationarity
Assum. Depend. Original Transformed 0 Diﬀ. 1 Diﬀ. 2 Diﬀs. Lin earity
Satis. (%) 94.57 0.76 95.0 71.56 21.76 6.68 26.4
RQ2. The forecasting accuracy of the proposed ap-
proach comparing to ARIMA models:
The boxplots of the relative prediction errors are depicted in
Figure 4, while MAPE values of the proposed approach and
ARIMA models are reported separately for each dataset in
Table 5. The boxplots indicate that the proposed approach
can provide more accurate forecasts than ARIMA model,
where the prediction errors exhibited by this approach are
signiﬁcantly lower than those of ARIMA models. This result
is conﬁrmed by the Mann-Whitney test (p-value <0.05).
More precisely, the proposed approach produces a MAPE
= 10.55 compared to 16.32 produced by an ARIMA model,
this is a forecasting accuracy improvement of about 35.4%.
The boxplots show another observation that the variation
of prediction errors exhibited by the proposed approach is
signiﬁcantly lower than that of ARIMA models. Where, 50%
of the prediction errors are within (3.3, 15.4) with range
= 12.1 for the proposed approach, and within (6.2, 26.5)
with range = 20.3 for ARIMA models. This indicates that
the proposed approach’s forecasting accuracy is more stabl e
across diﬀerent QoS datasets than that of ARIMA models.
For each web service, the results in Table 5 show that
11 of the 15 web services’ response datasets have a nonlin-
ear behavior and require SETARMA models to be modeled
and predicted, and it is clear that the proposed approach
outperforms ARIMA models in these cases. This result is
conﬁrmed by the Mann-Whitney test with all the p-values <
0.05. The lowest and highest accuracy improvement of the
approach compared to an ARIMA models are in the cases of
WS 2(TBV) where the RAI is about 20.7% and WS 11(RT)
where the RAI is about 52.3%, respectively. In general, we
can conclude that the proposed approach in 73.6% of the
cases provides much more accurate forecasts than those of
the popular existing ARIMA models with accuracy improve-
ments, while in the other cases (26.4%) both approaches give
the same forecasting accuracy.
Figure 4: Boxplots of relative prediction errorsRQ3. The time required for the approach to automati-
cally construct and use the forecasting model:
The time required for the approach to automatically con-
struct and use the forecasting model for the response time
and TBV datasets is computed and reported in Table 5.
This table indicates that the time required for the approach
to automatically construct the forecasting model is on the
average about 2.86 seconds. As a comparison between the
proposed approach and ARIMA model, the time needed to
automatically construct only an ARIMA model is computed
and reported in Table 5. As expected, results show that
ARIMA models need less time than the proposed approach,
and this is because the approach involves more computa-
tions to check for nonlinearity. It is worth mentioning that
the construction of the forecasting model is done only in
the beginning or after triggering adaptations. On the other
hand, the time required to use the constructed model to
forecast future QoS values is very small and the same for
both the proposed approach and ARIMA model (about 12
milliseconds), where the constructed model is used by only
substituting the new obtained QoS value in the equation
without more computations.
RQ4. Dependency of the approach’s accuracy and per-
formance on the number of observations:
The time needed to automatically construct the forecast-
ing model and the MAPE value produced by the approach
with respect to diﬀerent number of observations are com-
puted and depicted in Figure 5. It is clear from this Figure
that the approach’s accuracy (in terms of the MAPE value)
and performance (in terms of the required time to construct
the forecasting model) depend on the number of observa-
tions used to construct the model. The Figure shows that
the MAPE value is a decreasing function of the observa-
tions number, and on the other hand the required time is
an increasing function. Consequently, a trade-oﬀ between
the approach’s accuracy and performance levels is required .
This trade-oﬀ is shown in Figure 5; and we can conclude
that 350 observations give acceptable levels of accuracy an d
performance, where MAPE = 9.1% and required time =
2.89 seconds. Regarding the time required to use the con-
structed model to forecast the future QoS values, it is worth
mentioning that it does not depend on the number of ob-
servations as it is only substituting the new obtained QoS
value in the constructed model’s equation. We compute the
required time to use the constructed models and we ﬁnd it
varies from 5 to 20 milliseconds regardless the number of
observations.
4.3 Threats to Validity
The threats to internal validity include the QoS datasets
being used to evaluate the proposed approach and statis-
tical tests being used to analyze forecasting results. To re -
duce the impact of these threats we have considered response
time measures of real-world web services to reﬂect a realis-
tic situation of QoS attributes. In addition, we have used136Table 5: MAPE and RAI values and required time to construct an d use the forecasting model
MAPE Value RAI Time to Construct (s) Time to Use (ms)
WSidQoS Our Approach ARIMA Value Our Approach ARIMA Our Approach ARIMA
WS 1RT 16.17 20.43 20.85 3.65 1.60 11 9
TBV 18.21 23.32 21.91 2.88 1.15 10 9
WS 2RT 8.34 10.82 22.91 3.66 1.46 6 7
TBV 9.62 12.13 20.69 1.32 0.77 15 16
WS 3RT 6.55 10.09 35.08 3.35 1.34 11 10
TBV 8.25 11.61 28.94 1.05 0.54 7 6
WS 4RT 5.14 8.03 35.90 3.91 1.56 16 9
TBV 7.01 10.26 31.68 1.20 0.68 13 14
WS 5RT 8.85 17.69 50.00 3.33 1.33 9 8
TBV 10.22 20.17 49.33 4.46 1.78 11 13
WS 6RT 5.33 11.00 51.53 3.71 1.49 16 15
TBV 6.98 11.75 40.60 1.41 0.86 14 17
WS 7RT 14.58 29.88 51.22 3.86 1.54 8 5
TBV 15.51 30.12 48.51 1.11 0.64 11 15
WS 8RT 12.05 23.23 48.12 3.46 1.38 20 11
TBV 13.96 22.89 39.01 1.14 0.76 12 8
WS 9RT 6.12 6.12 - 3.03 1.21 13 14
TBV 8.42 8.42 - 2.16 0.86 9 14
WS 10RT 13.83 28.20 50.96 3.42 1.37 16 16
TBV 15.12 29.51 48.76 2.43 0.97 13 7
WS 11RT 10.00 20.96 52.30 3.64 1.49 13 17
TBV 13.85 21.34 35.10 3.46 1.38 16 10
WS 12RT 9.49 19.37 50.98 3.65 1.46 8 6
TBV 11.29 20.85 45.85 2.49 1.00 11 11
WS 13RT 9.13 9.13 - 3.15 1.26 8 7
TBV 12.09 12.09 - 2.85 1.14 20 15
WS 14RT 11.12 11.12 - 3.09 1.24 17 18
TBV 14.52 14.52 - 2.91 1.16 8 19
WS 15RT 6.35 6.35 - 3.18 1.27 11 10
TBV 8.27 8.27 - 2.91 1.16 12 12
Average 10.55 16.32 35.39 2.86 1.20 12.17 11.60
Figure 5: Required time (to construct the model)
and MAPE value vs. sample size
non-parametric tests to analyze the results and address the
research questions, where no constraints are imposed on the
datasets distribution.
On the other hand, external validity is threatened if ob-
tained results cannot be generalized. Although we have ap-
plied the approach for the response time datasets of 800 real -world web services belonging to diﬀerent domains, further
applications to other software systems and web services are
desirable. Additionally, we focus only on response time and
time between violations, and the generalizations to other
QoS attributes should be considered in future studies. For
example, similarly to the time between violations, the ap-
proach can be straightforwardly applied to the time between
failures as a reliability metric.
5. RELATED WORK
As the scale and complexity of software systems continue
to grow, research on adaptive software systems has recently
shifted onto QoS attributes prediction. This QoS predic-
tion is exploited to support and improve proactive runtime
adaptation and service selection and composition.
Nobile et al. [21] propose an architecture of QoS proxy
for RT-RPCs (Real Time Remote Procedure Calls) that uses
ARIMA models in order to predict future traﬃc character-
istics of RT-RPCs that pass through the proxy. The ar-
chitecture is based on allowing the anticipated allocation of
the necessary resources to attend the predicted demand and
the choice of policies aimed at the adaptation of the proxy
to the states of its network environment. In [32], Zhu et
al. present a Grid-based framework that uses a time se-
ries prediction algorithm to forecast the future performan ce137of parallel/distributed discrete event simulation (PDES) to
proactively evaluate and optimize QoS of PDES programs.
Recent work [24, 28, 29] exploits performance prediction
to build proactive adaptation of software systems. Zeng et
al. [28] have investigated that performance metrics can be
predicted based on their historical data and using time seri es
models. Their work introduces the design and implementa-
tion of an event-driven QoS prediction system which can
process operational service events in a real-time fashion, in
order to predict or reﬁne the prediction of performance met-
rics. Zeng et al. [29] propose a predictive approach based
on ARIMA models to optimize the I/O performance of stor-
age subsystems. This approach improves the availability of
the storage subsystem eﬀectively and decreases TCO (Total
Cost of Ownership) by proactively decreasing the possibil-
ity of I/O bottlenecks. Recently, Solomon and Litoiu [24]
present a dynamic predictive model based on linear regres-
sion and ARIMA models to predict with more conﬁdence
system performance degradations. They also propose a feed-
back based evolution architecture that can proactively, us ing
these performance degradations predictions, tune and opti -
mize software systems.
Current studies [11, 12, 30] propose failure prediction tec h-
niques to enable and enhance proactive failure management
by avoiding possible failures. In [11, 12], Fu and Xu develop
a spherical covariance model with an adjustable timescale
parameter to quantify the temporal correlation and a stocha s-
tic model to characterize spatial correlation. They cluste r
failure events based on their correlations and predict thei r
future occurrences using autoregressive time series model s.
In addition, Zhang and Fu [30] propose a framework for au-
tonomic failure management with failure prediction func-
tionality to achieve proactive self-management of failure s
and resources in networked computer systems. This frame-
work analyzes node, cluster and system wide failure behav-
iors and forecasts the prospective failure occurrences usi ng
linear time series models, especially autoregressive mode ls,
and based on quantiﬁed failure dynamics. Recently, Met-
zger [20] discusses how accurate proactive adaptations can
be achieved by improving the failure prediction techniques
that trigger the adaptations and by dynamically estimating
the accuracy of the predicted failures at runtime. However,
this work uses the arithmetic average as a simple predic-
tion model, it recommends using the advanced time series
prediction models in the future work.
In the domain of QoS-based service selection and composi-
tion, Li et al. [19] propose a web service selection algorith m
based on QoS prediction mechanism. This algorithm uses
time series modeling based on structural equations to ﬁt QoS
values of web services, and dynamically predicts their futu re
changes to support adaptive services selection. Godse et al .
[14] propose a method that combines monitoring and extrap-
olation methodologies based on ARIMA models to predict
service performance. This method is used to support au-
tomating dynamic service selection methodology which is
robust in the face of varying QoS. Recently, Cavallo et al.
[10] present an empirical study aimed at comparing diﬀerent
approaches for QoS forecasting, namely the use of average
and current values, linear models, and ARIMA models. The
study is performed on QoS data obtained by monitoring the
execution of ten 10 real services for 4 months. It concludes
that the use of ARIMA forecasting has the best compro-
mise in ensuring a good prediction error, being sensible tooutliers, and being able to predict likely violations of QoS
constraints.
In these existing QoS forecasting approaches, researchers
conclude that initially time series ARIMA models are a good
statistical tool to model the dynamic behaviours of QoS at-
tributes and forecast their future values. However, Godse
et al. [14] report that studying the dynamic characteristic
of QoS attributes and proposing an eﬃcient forecasting ap-
proach is a crucial need to support proactive management
and service selection. Moreover, Cavallo et al. [10] con-
clude based on their empirical study that a good forecasting
of QoS violations is still a challenging issue and further ap -
proaches able to better deal with this issue should be invest i-
gated. In addition, Our analysis of real QoS datasets shows
that they are characterized by a high dynamic and mostly
nonlinear behavior to the extent that existing ARIMA mod-
els cannot guarantee accurate QoS forecasting. In our cur-
rent work we propose an automated forecasting approach
that addresses this limitation by integrating linear and no n-
linear time series models, and improves the forecasting ac-
curacy of QoS attributes.
6. CONCLUSION AND FUTURE WORK
In this paper we have proposed an automated QoS fore-
casting approach based on integrating linear and nonlinear
time series models that is able to correctly capture and
model the dynamic QoS behavior and improve the fore-
casting accuracy. This approach basically consists of two
components; one for constructing the forecasting model and
the other for continuously forecasting future QoS values an d
evaluating the accuracy of this forecasting.
The proposed approach was applied to real-world QoS
datasets of 800 web services, especially response time and
time between violations; and results demonstrate its accu-
racy and performance in forecasting QoS measures. In ad-
dition, we concluded that most of the real QoS datasets are
serially dependent and can be transformed to be stationary,
normally distributed; which implies that time series mod-
els, especially SETARMA models, are most likely suitable
to model QoS measures and forecast their future values.
Therefore, this new automated QoS forecasting approach
can be integrated at runtime into the existing approaches to
improve proactive QoS management and QoS-based service
selection and composition.
As a future work, the overhead of the proposed approach
needs to be carefully evaluated. Similarly, to reduce the co n-
sumed memory a sliding window approach for the observed
QoS attributes values needs to be investigated.
7. REFERENCES
[1] H. Akaike. A new look at the statistical model
identiﬁcation. IEEE transactions on automatic
control , 19(6):716–723, 1974.
[2] A. Amin, A. Colman, and L. Grunske. Using
Automated Control Charts for the Runtime
Evaluation of QoS Attributes. In Proceedings of the
13ht IEEE International High Assurance Systems
Engineering Symposium , pages 299–306. IEEE
Computer Society, 2011.
[3] A. Amin, A. Colman, and L. Grunske. An Approach
to Forecasting QoS Attributes of Web Services Based
on ARIMA and GARCH Models. In Proceedings of the13819th International Conference on Web Services , pages
74–81. IEEE, 2012.
[4] A. Amin, A. Colman, and L. Grunske. Statistical
Detection of QoS Violations Based on CUSUM
Control Charts. In Proceedings of the 3rd ACM/SPEC
International Conference on Performance
Engineering , pages 97–108. ACM, 2012.
[5] H. Barringer, A. Goldberg, K. Havelund, and K. Sen.
Rule-based runtime veriﬁcation. In B. Steﬀen and
G. Levi, editors, Proceedings of the 5th Intern.
Conference on Veriﬁcation, Model Checking, and
Abstract Interpretation , volume 2937 of Lecture Notes
in Computer Science , pages 44–57. Springer, 2004.
[6] G. E. P. Box and D. R. Cox. An analysis of
transformations. Journal of the Royal Statistical
Society. Series B (Methodological) , 26(2):211–252,
1964.
[7] G. E. P. Box and G. M. Jenkins. Time Series
Analysis: Forecasting and Control . HoldenDay, San
Francisco, 1976.
[8] G. E. P. Box and D. A. Pierce. Distribution of residual
autocorrelations in autoregressive-integrated moving
average time series models. Journal of the American
Statistical Association , 65(332):1509–1526, 1970.
[9] R. Calinescu, L. Grunske, M. Z. Kwiatkowska,
R. Mirandola, and G. Tamburrelli. Dynamic qos
management and optimization in service-based
systems. IEEE Trans. Software Eng. , 37(3):387–409,
2011.
[10] B. Cavallo, M. D. Penta, and G. Canfora. An
empirical comparison of methods to support
QoS-aware service selection. In Proceedings of the 2nd
International Workshop on Principles of Engineering
Service-Oriented Systems , pages 64–70. ACM, 2010.
[11] S. Fu and C.-Z. Xu. Exploring event correlation for
failure prediction in coalitions of clusters. In
Proceedings of the ACM/IEEE conference on
Supercomputing , pages 1–12. ACM Press, 2007.
[12] S. Fu and C.-Z. Xu. Quantifying event correlations for
proactive failure management in networked computing
systems. Journal of parallel and distributed computing ,
70(11):1100–1109, 2010.
[13] J. D. Gibbons and S. Chakraborti. Nonparametric
statistical inference . CRC, 2003.
[14] M. Godse, U. Bellur, and R. Sonar. Automating QoS
Based Service Selection. In Proceedings of the IEEE
International Conference on Web Services , pages
534–541. IEEE, 2010.
[15] L. Grunske. An eﬀective sequential statistical test fo r
probabilistic monitoring. Information and Software
Technology , 53(3):190 – 199, 2011.
[16] L. Grunske and P. Zhang. Monitoring probabilistic
properties. In H. van Vliet and V. Issarny, editors,
Proceedings of the 7th joint meeting of the European
Software Engineering Conference and the
International Symposium on Foundations of Software
Engineering , pages 183–192. ACM, 2009.
[17] B. Hansen. Testing for linearity. Journal of Economic
Surveys , 13(5):551–576, 1999.
[18] D. Kwiatkowski, P. Phillips, P. Schmidt, and Y. Shin.
Testing the null hypothesis of stationarity against thealternative of a unit root. Journal of Econometrics ,
54:159–178, 1992.
[19] M. Li, J. Huai, and H. Guo. An Adaptive Web
Services Selection Method Based on the QoS
Prediction Mechanism. In Proceedings of the
International Conference on Web Intelligence and
Intelligent Agent Technology , pages 395–402. IEEE,
2009.
[20] A. Metzger. Towards accurate failure prediction for
the proactive adaptation of service-oriented systems.
InProceedings of the 8th workshop on Assurances for
self-adaptive systems , pages 18–23. ACM, 2011.
[21] P. N. Nobile, R. R. F. Lopes, C. E. Moron, and L. C.
Trevelin. QoS proxy architecture for real time RPC
with traﬃc prediction. In Proceedings of the 11th
IEEE International Symposium on Distributed
Simulation and Real-Time Applications , pages
261–267. IEEE Computer Society, 2007.
[22] G. Rosu and K. Havelund. Rewriting-based techniques
for runtime veriﬁcation. Autom. Softw. Eng ,
12(2):151–197, 2005.
[23] J. Simmonds, Y. Gan, M. Chechik, S. Nejati,
B. O’Farrell, E. Litani, and J. Waterhouse. Runtime
monitoring of web service conversations. IEEE T.
Services Computing , 2(3):223–244, 2009.
[24] A. Solomon and M. Litoiu. Business process
performance prediction on a tracked simulation model.
InProceeding of the 3rd international workshop on
Principles of engineering service-oriented systems ,
pages 50–56. ACM, 2011.
[25] H. Tong. Threshold models in non-linear time series
analysis , volume 21. Springer, 1983.
[26] H. Tong. Non-linear time series: a dynamical system
approach , volume 6. Oxford University, 1993.
[27] H. Tong and K. Lim. Threshold autoregression, limit
cycles and cyclical data. Journal of the Royal
Statistical Society. Series B (Methodological) , pages
245–292, 1980.
[28] L. Zeng, C. Lingenfelder, H. Lei, and H. Chang.
Event-driven quality of service prediction. In
Proceedings of the 6th International Conference on
Service-oriented Computing , pages 147–161.
Springer-Verlag, 2008.
[29] L. Zeng, Y. Zhang, and X. Zhao. Storage performance
optimization based on arima. In Proceedings of the
First International Workshop on Database Technology
and Applications , pages 377–381. IEEE, 2009.
[30] Z. Zhang and S. Fu. Failure prediction for autonomic
management of networked computer systems with
availability assurance. In International Symposium on
Parallel & Distributed Processing, Workshops and Phd
Forum (IPDPSW) , pages 1–8. IEEE, 2010.
[31] Z. Zheng, Y. Zhang, and M. Lyu. Distributed qos
evaluation for real-world web services. In ICWS , pages
83–90. IEEE, 2010.
[32] S. Zhu, Z. Du, Y. Chen, X. Chai, and B. Li. QoS
Enhancement for PDES Grid Based on Time Series
Prediction. In Proceedings of the 6th International
Conference on Grid and Cooperative Computing ,
pages 423–429. IEEE, 2007.139