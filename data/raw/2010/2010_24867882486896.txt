Dynamic Injection of Sketching Features into GEF
Based Diagram Editors
Andreas Scharf
Software Engineering Research Group
University of Kassel
Kassel, Germany
andreas.scharf@cs.uni-kassel.deTill Amma
Software Engineering Research Group
University of Kassel
Kassel, Germany
till.amma@cs.uni-kassel.de
Abstract ‚ÄîSoftware Engineering in general is a very creative
process, especially in the early stages of development like re-
quirements engineering or architectural design where sketching
techniques are used to manifest ideas and share thoughts. On
the one hand, a lot of diagram tools with sophisticated editing
features exist, aiming to support the engineers for this task.
On the other hand, research has shown that most formal tools
limit designer‚Äôs creativity by restricting input to valid data.
This raises the need for combining the Ô¨Çexibility of sketch-
based input with the power of formal tools. With an increasing
amount of available touch-enabled input devices, plenty of tools
supporting these and similar features were created but either they
require the developer to use a special diagram editor generation
framework or have very limited extension capabilities. In this
paper we propose Scribble: A generic, extensible framework
which brings sketching functionality to any new or existing GEF
based diagram editor in the Eclipse ecosystem. Sketch features
can be dynamically injected and used without writing a single
line of code. We designed Scribble to be open for new shape
recognition algorithms and to provide a great degree of user
control. We successfully tested Scribble in three diagram tools,
each having a different level of complexity.
Index Terms ‚ÄîSketching, recognition, modeling, graphical ed-
itor
I. I NTRODUCTION
People use hand-drawn sketches on a day-to-day basis in
many different and heterogeneous Ô¨Åelds. There are different
reasons why people sketch [1]: Sharing as a major part of
communication and externalizing internal thoughts, ground-
ingto clarify ambiguous interpretations of a conversation,
manipulating to support the collaboration part among team
members after sharing and brainstorming to reveal unintended
interpretations as well as to enhance creativity. While the
medium for sketching ranges from pen & paper to whiteboards
or Ô¨Çip charts the problem of insufÔ¨Åcient editing Ô¨Çexibility
remains and is Ô¨Åxed to edit operations such as adding and
removing elements. It is not possible to copy/paste, rotate
or resize any drawn elements [2]. Since sketch-input enabled
hardware like Tablet PCs, Smartphones and Smartboards be-
come more and more available, there is a shift from solely
analog mediums to digital hand-drawn sketches. Now it is
possible to e.g. rearrange, copy/paste, scale and rotate the
drawn content or even work with distributed teams [3]. A
lot of research has already been done to further support andincrease user experience during sketching on digital devices
[2], [4]‚Äì[6]. Calico [7] e.g. enhances the plain white surface
with several concepts to easily create and modify sketches.
However, most of these tools focus on creating informal
sketches which of course enables the user to draw and modify
arbitrary content in a very Ô¨Çexible way. But especially in early
phases in the software engineering process like requirements
engineering or system design, developers often use dedicated
diagram types like UML use case diagrams, composite struc-
ture diagrams or class diagrams [1], [4]. The tool support for
creating and modifying the mentioned diagram types is large,
e.g. [8]‚Äì[11]. In general, these diagram types have a strict syn-
tax and most tools restrict editing operations to valid data. This
limits the users creativity and breaks the design Ô¨Çow which is
one of the reasons, why developers fall back to informal tool
support [12]. As a consequence, much work in these early
phases is done several times: First prototypes and ideas are
captured on a (analog) whiteboard and later ‚Äúportrayed‚Äù in a
computer-aided software engineering (CASE) tool to beneÔ¨Åt
from sharing, validation, code generation facilities, and more.
To combine the strengths of informal sketching with the
power of software engineering tools, current research tries to
integrate sketching capabilities into new and existing tools.
Until now, several tools already support freehand sketch
functionality along with recognition of drawn content [13]‚Äì
[16]. As Grundy and Hosking already state in [17], the
technique used to implement the sketch functionality is either
unique for a given tool or lacks user control over recog-
nition and formalization of drawn content. Therefore they
integrated sketching features into their meta-toolset called
Marama [18] which allows any diagram-centric design tool
generated by Marama to beneÔ¨Åt from generic sketching-based
input. However they also admit that this approach only works
for diagram tools generated with Marama. Beside Marama,
we are only aware of one other framework which uses a
similar approach: SKETCH [19]. SKETCH aims to bring
sketch features into new and already existing diagram editors
based on the Eclipse Graphical Editing Framework (GEF).
Using a small set of conÔ¨Ågurations the developer can specify
the elements that should be recognized by SKETCH. However,
a code review has shown that the extension capabilities and the
extent the user can control the recognition process are limited.978-1-4673-3076-3/13/$31.00 c2013 IEEE ICSE 2013, San Francisco, CA, USA822
Furthermore, the development seems to be stuck.
We propose the Scribble framework: A generic, extensible
framework which brings scribble functionality to any new or
existing GEF based diagram editor in the Eclipse ecosystem.
Scribble is generic because it can augment diagram editors
with scribble features on-the-Ô¨Çy requiring the developer to
write no code at all. On the other hand, it is extensible to
a great degree for instance by allowing users to add new
recognition algorithms and train the recognizer by providing
new templates. Unlike other similar frameworks, Scribble is
aware of the editor type under modiÔ¨Åcation and thus can
build a context between the editor type, drawn scribbles and
available tokens. This context can be shared in an online
database to take advantage of a larger community.
In the next section we discuss our motivation for creating
Scribble. Section III delivers insight into the background of the
scribble domain and discusses related work. In Section IV we
outline requirements a good sketching framework should have.
We describe the Scribble framework in detail and show the
current implementation status in section V. We continue with
an evaluation in section VI and Ô¨Ånally Ô¨Ånish with conclusions
and future work.
II. M OTIVATION AND APPROACH
Looking at the shortcomings of existing approaches outlined
previously, the main research question is: Is it possible to
seamlessly augment existing complex diagram editors to sup-
port sophisticated sketching functionality? This rather broad
and ambiguous question includes but is not limited to the
following problems: Is it possible to integrate (parts of) the
framework into different environments by providing common
components? What are meaningful places concerning exten-
sibility and adaptability? How can different input methods
like single-, multi-touch and speech input be addressed? Can
sketched content be formalized incrementally and can both co-
exist? To what extent can and should end-users have inÔ¨Çuence
on the learning and recognition process? How much training
is required to get suitable recognition results? And Ô¨Ånally:
Are sketch-based techniques accepted by users of graphical
editors?
As a Ô¨Årst step to answer the above questions, we propose
Scribble: A generic and extensible framework for adding
sketch features to any GEF based diagram editor. Scribble
allows the user to ad-hoc equip their diagram editor with
sketch features by simply installing the framework which
requires the user to not write any code at all. Scribble then
recognizes and tracks GEF based diagram editors and dynam-
ically injects the scribble tool and some new layers to hold
hand-drawn scribbles. The framework automatically extracts
elements supported by the diagram editor by analyzing the
editor‚Äôs tool palette. We integrated the $N algorithm and the
approach used in SKETCH which is based on the Levenshtein
distance [20] for shape recognition but Scribble is open for any
new algorithm by simply using the Eclipse extension point
mechanism. If no training data is available for the editor in
question, Scribble supports online training to incrementallytrain the recognizer. A connection to an online service already
containing training material for different editors is created right
now and will be available soon.
III. B ACKGROUND
Sketching is used by people for plenty of reasons. It is often
used as a problem solving technique where thoughts and ideas
are written down which enables the human brain to concentrate
on the next step rather then keeping ‚Äúthe big picture‚Äù in mind
all the time. It serves as a communication medium in a team
and ensures that everybody is talking about the same thing on
the one hand while still have enough room for creativity on
the other hand. The scrawly informal style encourages users
to perform modiÔ¨Åcations at any time instead of sticking to a
possibly awkward design what often happens when dealing
with more formal and ‚ÄúbeautiÔ¨Åed‚Äù material.
Sketchpad was the Ô¨Årst system which presented a man-
machine graphical communication system in 1963 [21]. Al-
though this dates back a lot of years, adding sketch-input to
hardware as well as any type of software system remains an
open and quite active research area. Sketching and the required
computational technology is an interdisciplinary research area
where Ô¨Åelds like human-computer interaction (HCI), cognitive
science, computer science and artiÔ¨Åcial intelligence (AI) come
together. Johnson et al. [22] recently published a review which
is helpful in getting an overview of the current state of
research.
There has already been done a great amount of work
in nearly all sketch related areas. In the Ô¨Åeld of low level
sketch support, plenty of algorithms and a few toolkits have
been developed. A well-known feature-based single-stroke
recognizer was introduced by Rubine [23] and has been
used and evaluated many times. Other algorithms use neural
networks to recognize handwritten text [24]. $N [25] is a more
recent algorithm for recognizing multi-strokes by using only
simple geometry and trigonometry. Hse and Newton created
the HHReco library [26]: A recognition system for multi-
stroke text- and shape recognition which is used in several
tools and frameworks, e.g. [18], [27].
A remarkable amount of tools and frameworks where
created in the last two decades which often make use of
the mentioned algorithms and libraries. SILK [27] was one
of the Ô¨Årst tools to support the creative process in user-
interface design and is able to transform sketches into an
operational interface. A similar tool is DENIM [28] which
supports web designers in the early stages of design. InkKit
[29] is another tool aiming to reduce the development effort
to support sketching in speciÔ¨Åc types of diagrams.
Whereas these tools try to solve a sketch related problem for
a speciÔ¨Åc domain and were designed with little or no reuse in
mind, a few frameworks arose recently to address this problem.
The frameworks most related to the work we present in this
paper are Marama [18] and SKETCH [19] which both build
upon the Eclipse IDE [30] and provide sketch input features to
new and existing diagram editors based on GEF. Eclipse along823with the large set of available plugins and the vast community
support is often used to create any kind of open source tool.
Marama is a set of meta-tools enabling the user to create
complex diagram editors with sketch support. Marama Sketch
supports different approaches regarding the recognition mode
whereby it is possible to sketch only (no recognition is
performed at all) or even mix sketched and recognized content.
As Grundy et al. state themselves, one of Marama Sketch‚Äôs
weaknesses is that it only supports Marama based diagram
editors. Also no information about extension mechanisms to
e.g. integrate additional recognition algorithms are provided.
Sangiorgi and Barbosa recently proposed the SKETCH
framework [19]. Like Marama, SKETCH is implemented as
a set of Eclipse based plugins and attempts to extend GEF
based diagram editors. The main difference between Marama
and SKETCH is that Marama only works for diagram editors
generated by Marama whereas SKETCH basically supports
any kind of GEF based diagram editor. This certainly is a
great beneÔ¨Åt because most diagram editors in the Eclipse
environment are either pure GEF editors or generated with
help of the Eclipse Graphical Modeling Framework (GMF).
SKETCH also supports a beautiÔ¨Åed and a sketched mode
and allows to switch between these two modes. Although
SKETCH theoretically provides a chain of recognition algo-
rithms, only one algorithm is integrated at the moment and a
short code review did reveal any information if and how any
custom algorithm could be integrated. Furthermore, neither
Marama nor SKETCH support any interchange of training data
and thus needs every user to re-train the recognizer.
IV. F RAMEWORK REQUIREMENTS
A perfect sketch-based framework works with every dia-
gram editor without bothering a developer to implement a
series of interfaces into their framework. But from the other
point of view, the sketch framework should not make any
assumption on the editor it is going to be attached to (the
client framework). To get both frameworks to work together
a contract has to be agreed upon. In this contract the client
framework gives the sketch framework a list of token objects
that it knows how to handle. These tokens resemble labels
for recognized shapes. Once a shape has been recognized the
appropriate token is passed to the client framework which
initiates the element creation process.
The process of sketching on a sheet of paper should be
emulated as close as possible. This means that minimal
assumptions on the input device have to be made. The most
basic device would be one with single-touch without pressure
recognition. The graphical user interface has to be enhanced
to perform tasks like resizing, moving, or deleting because
they could not be distinguished from actual sketching. Thus,
there must be some sort of mode change via a gesture, like a
long press to initiate moving or double tab for resize. If a lot
of auxiliary modiÔ¨Åcations are possible one will eventually run
out of gestures. In that case a graphical aid is more useful,
for instance an overlay that annotates existing elements with
needed element manipulation facilities.Users have to be able to participate on the internal processes
of the sketching framework. This includes active roles such as
labeling of sketched shapes on demand. But also useful output
of the framework to give an understanding of the internal
decision process could be a beneÔ¨Åt.
The framework needs to be extensible. Users may want
to exchange a recognition algorithm or need multiple shape
recognizers that perform better on unique subsets of shapes.
Therefore, the framework has to provide support to extend its
features.
During diagram creation not only new strokes of user input
have to be investigated, but rather all strokes have to be re-
evaluated each time a new one is drawn. Imagine a couple of
elements are drawn and diagram elements are created on-the-
Ô¨Çy. A stroke is added with the intention to change an already
created object. When only new strokes are passed through the
recognition process the intended solution cannot be found.
Finally, responses of the framework should be in real-time.
Capturing time-outs or calculations that delay responses on
user input disrupt the natural sketching Ô¨Çow and make the use
of the framework awkward and unpleasant.
V. T HESCRIBBLE FRAMEWORK
In this section we describe the present state of an implemen-
tation of a sketching framework with regards to the previously
described vision ‚Äì Scribble.
In the following passages we will use the terms stroke and
scribble. The basic elements of this framework are strokes.
Strokes are a collection of points which are annotated with
time stamps. A scribble is a collection of strokes and has at
least one corresponding element on the diagram of the client
framework.
A. Injecting Scribble into GEF
GEF is a framework that provides developers with high-
level support to create editors in the Eclipse environment. GEF
makes use of a series of well-known design patterns such as
Request, Command and Model-View-Controller and contains
predeÔ¨Åned editor stubs featuring a palette with tools (shown
in Fig. 1) and other constructs that can be utilized to achieve
a generic sketching framework. Furthermore, Eclipse includes
an extension point mechanism that is designed to allow third-
party developers to enhance the functionality of a plugin.
The Scribble framework is able to automatically connect
to a GEF diagram editor if it is implemented using a Graph-
icalEditor and has a palette. The scribble tool can then be
injected into the palette by a single button click. To create
the contract tokens described in section IV the framework
analyzes the entries of the palette and generates token objects
based on found information. To gain more control over the
contracting between the frameworks the Eclipse extension
point mechanism can be employed to deÔ¨Åne tokens for editors.
The principle internal workÔ¨Çow for standard GEF editors
is: A tool (e.g. ‚ÄúCreate Rectangle‚Äù) builds a request and sends
it to an EditPart which in turn asks its EditPolicies to create
a command for the request. The command is returned and824RootEditPart
ClientDiagramEditPart
ScribbleEditPartFactory
EditPartFactoryScribbleBoardEditPart
Scribble Tool
Attach Scribble Tool
PaletteFig. 1. SimpliÔ¨Åed overview of the Scribble architecture. Blue elements refer to the client framework, red elements to the Scribble framework.
subsequently the command‚Äôs execution is triggered by the tool.
For commands that create diagram elements a CreationFactory
is provided via tool and request.
The implemented version of the token enhances the concept
of it being a single arbitrary object as envisioned in the re-
quirements. To leverage the available tool mechanisms of GEF
the token mimics a tool. Once an element should be created a
request is issued containing the token‚Äôs CreationFactory. When
tokens are deÔ¨Åned via extension point the deÔ¨Åned contract
object is wrapped into a generic CreationFactory to ensure the
standard GEF mechanisms can be utilized.
Besides adding the scribble tool into the palette of the client
editor an additional layer is injected to show a pane with
scribbles and strokes. The reason for this additional layer is of
visual nature. By having several layers it is possible to easily
toggle visibility for strokes and scribbles on and off without
altering the client framework.
During EditPart creation GEF will walk through all Edit-
Parts to retrieve the proper parent element. The last EditPart
to be asked is the RootEditPart that forwards the request to its
content, the sole child element, which is the client framework‚Äôs
main EditPart, usually the one reÔ¨Çecting the diagram. The
client framework does not know how to create strokes or
scribbles. To achieve a proper segregation on the RootEditPart
level more than one child element has to be present: One for
the client framework and one for the Scribble framework.
Therefore, a switch has to be created in the RootEditPart.
Because a RootEditPart is designed to hold only a single child
it is necessary to use reÔ¨Çection to inject children into the
RootEditPart. GEF then initiates the creation of the visualsand loading of model elements for both, the client and the
Scribble framework. For commands that are intended for
either framework a switch is created via an EditPolicy in the
RootEditPart.
Another point where GEF relies on special framework
knowledge is the EditPartFactory where, for a given model
element, a corresponding EditPart is created. Here the same
argument as above holds true: the client framework does not
know how to handle Scribble objects. Our solution is to wrap
the EditPartFactory of the client framework once Scribble is
enabled for the editor. Strokes, scribbles, et cetera are handled
by the wrapping factory. "‚ÄòUnknown"‚Äô objects are passed to
the client EditPartFactory.
For each editor instance the Scribble framework generates
a context with a registry for tokens and a ScribbleBoard,
containing all strokes and scribbles for this editor as well as
the current solution from the recognition process. This allows
to switch between editors in the workbench without losing
information. The token registry is a container for a mapping
of tokens to a list of scribbles. It also serves as the point
to retrieve information on token themselves and stores user
training data. When a user explicitly labels a scribble with a
token the scribble is appended to the appropriate list in the
token registry.
For sketching on paper only one tool is necessary: a pen.
Diagram editors rely on multiple tools to create elements and
connections, to select, move, resize, and so forth. The scribble
tool combines the simplicity of real-life sketching with the
beneÔ¨Åts of manipulating drawn elements on digitally created
diagrams.825We implemented an overlay to tackle the above mentioned
problems. With the scribble tool selected a simple ‚Äùclick‚Äú or
‚Äùtouch‚Äú, that does not exceed a number of points determined
by a threshold, is interpreted to trigger the overlay instead of
initiating a stroke. The overlay annotates the targeted element
with a series of buttons as shown in Fig. 5 (c). With the buttons
the element can be moved, deleted and resized. The overlay
makes it possible to interact with diagram elements making
the selection of a different tool from the palette superÔ¨Çuous
while also keeping in mind a very simplistic input device.
Even though one can achieve any kind of modiÔ¨Åcation
through the scribble tool one might change back to other tools
to manipulate elements. Generally, side-effects that change a
client diagram without direct interaction have to be addressed.
This circumstance makes it inevitable to track client elements
for scribbles to change accordingly. We implemented a series
of EditPolicies and listeners to register client element modiÔ¨Å-
cation. Especially moving elements from one parent element
to another is no trivial task, because elements get deleted
and recreated within the new parent. Therefore, whenever an
element is moved also the element under the cursor has to
be tracked in order to register a creation of an object. Also,
moving or deleting a stack of elements should be mentioned.
GEF treats locations of elements relative to their parents‚Äô
location and does not trigger an event for its child elements.
So, not only the parent of an element has to be tracked, but
also all its ancestors to be able to track locations for scribbles.
A scribbles nature is to be transparent so clicks on the diagram
pane are not captured by the scribble EditPart but by the
underlying client EditPart and are recognized by the scribble
through the attached listeners and EditPolicies.
B. Scribble Core
In the previous sections we mainly focused on how the
Scribble framework is integrated into a client framework. This
section deals with the actual process from sketching something
over recognition to transformation.
Sketching in the Scribble framework starts by selecting the
scribble tool and drawing a line on the editor pane as shown
in Fig. 1. Once the tool recognizes a button-up event the tool
passes the drawn stroke to the core, where it is added to the
board and gets analyzed. Scribble‚Äôs core is divided into three
different modules: Evaluator, Decider, Transformator (depicted
in Fig. 2); each of which encapsulates a unique step from the
input of a stroke to Ô¨Ånally creating a scribble and asking the
client framework to execute changes.
The evaluation module takes care of the classical recogni-
tion task. Our generic approach supports the use of multiple
recognition algorithms. If an algorithm masters one task it
could be bad in another: Algorithms could be optimized to
recognize a special set of shapes, another one could be focused
on the recognition of connections. Thus, we introduce the
Recognizer as extensible parts for the Evaluator.
A Recognizer is a classical recognition algorithm wrapped
into a slim API. It takes a set of strokes as input and returns
a list of ResultContributions. A ResultContribution comprises
TransformatorDeciderEvaluator
ResultContributions
winning ResultContribu tionCoreScribble Tool
new Stroke
new ScribbleRecognizer1
...Classificator1
ClassificatorN...
Strategy1
StrategyN...RecognizerNFig. 2. Scribble core modules with input and results
the stroke combination itself and the token calculated as a
result together with an info string and a Ô¨Çoat value representing
the recognizers certainty concerning this result.
Currently we employ two recognition algorithms already
using the recognizer API. The Ô¨Årst one calculates the Lev-
enshtein distance between strokes. SKETCH features this
recognition technique and we ported it to use our Recognizer
interface. We also implemented the $N algorithm. $N, in
contrast to Levenshtein, is able to handle multiple strokes. For
the Levenshtein algorithm multiple strokes of a multi-stroke
sketch are connected into one single stroke.
The amount of required training data depends on the used
recognition algorithm. For instance the $N algorithm has an
error quote of 3% while having one template for a certain
shape [25]. Training data like templates for template based
recognition algorithms can be retrieved in several ways: The
user can provide new data during diagram modiÔ¨Åcation. An-
other way could be the import of already existing training data
from an online service.
All ResultContributions over all participating Recognizers
are aggregated in the Evaluator. But this is not the sole task
of the Evaluator. Imagine a vast amount of strokes have
been drawn and a new evaluation process is triggered. The
naive approach is to let the Recognizers Ô¨Ånd results on every
possible combination of strokes. This implies a power set over
all strokes. With every new stroke sketched each Recognizer826Strokes Token Certainty #Strokes Source
Triangle 0.5 2 Recognizer1
Line 0.9 1 Recognizer1
Reactangle 0.3 2 Recognizer2
Triangle 0.5 1 Recognizer2
TriangleNr.
1
2
3
4
5 0.8 1 Recognizer1Fig. 3. Drawn strokes and ResultContributions produced by two Recognizers
has to check for matches on each combination to Ô¨Ånd the
best possible solution. The effect of this is the loss of real-
time reactions to user inputs, an undesirable circumstance.
To circumvent this situation the Evaluator generates a subset
of ‚Äúinteresting‚Äù strokes to speed up the recognition process
by sacriÔ¨Åcing precision in the solution. At the moment two
classiÔ¨Åactors are implemented to evaluate strokes on how
‚Äúinteresting‚Äù they are: time and location. Both classiÔ¨Åcactors
use the last drawn stroke as a reference to check whether other
strokes are close. The time criterion is obviously the difference
of time between one stroke‚Äôs end and the next stroke‚Äôs start.
A threshold on this difference determines if they should be
considered to be counted as one shape or not. For the location
classiÔ¨Åcator a bounding box around the stroke is calculated.
Every stroke intersecting this bounding box is considered part
of the shape. Additional classiÔ¨Åcators can be introduced into
the Scribble framework using an Eclipse extension point.
Assume a triangle is drawn in two strokes; Multiple Result-
Contributions are created, like shown in Fig. 3. The results
differ in the found token for a given set of strokes, the certainty
and number of used strokes. This set consist of contradictory
results (identical stroke sets pointing to different tokens; results
1 and 3 in Fig. 3) or inconsistencies (stroke sets using the
same stroke for different results; results 1 and 2 in Fig. 3).
Those problems are targeted in the decision module. The
Decider tries to Ô¨Ånd the best solution within all available
ResultContributions using strategies to determine which result
is best. The Ô¨Årst strategy is ‚Äútrust‚Äù. Each Recognizer can
have a level of trust that is given as a certainty threshold.
If the result of a Recognizer is located beyond its threshold
the result is discarded. Another binary strategy is focused
on the token itself and its context. By analyzing the token‚Äôs
context it can be determined whether it makes sense to create
an object described by the result. Analyzing a context for a
given token is done by probing an EditPart. A set of strokes
has a point of reference (top-left corner of the bounding box)which is used to Ô¨Ånd a target EditPart on the client framework
via GEF mechanisms. This target EditPart is then asked to
return a command for a creation request based on the token
of interest. Whether the returned command is executable or not
indicates the tokens validity for creation and also the results
validity. Other strategies are consulted to give a logical order
to ResultContributions using certainty and number of strokes.
Of course, the result with the higher certainty is favored. But
in situations where the certainty can be considered equal (see
results 1 and 4 in Fig. 3) another criterion has to be addressed
to Ô¨Ånd a winner. In this case we choose the result that
comprises the most strokes. The reason for this is to minimize
stray strokes on the board. The Decider can be extended with
additional strategies. Summarized, the procedure of Ô¨Ånding the
best result is:
1) pick a ResultContribution;
2) check whether the certainty is beyond the one given as
‚Äútrust‚Äù for the Recognizer;
3) check whether the token is viable in the location of the
diagram;
4) check whether the new candidate has a better certainty
or combines a larger number of strokes as the previously
selected;
5) remember winning stroke set;
6) do steps 1 - 5 until all ResultContributions have been
checked.
In the Ô¨Ånal step of the core, the client diagram has to
be adjusted based on the result of the previous step - this
happens in the Transformator. A transformation is actually the
deletion and recreation of elements indicated by the picked
ResultContribution. During a transformation all previous ob-
jects that are connected to strokes of the winning stroke set are
destroyed. This happens by asking the client framework for an
appropriate deletion command for the EditPart referenced by
the strokes. After the execution of the delete command the
creation of the new scribble comprised by the winning stroke
set is handled in the same manner. The reason why this process
is divided into two disjoint commands is caused by how GEF
retrieves commands. When combining both commands they
are created Ô¨Årst, then executed. As mentioned the creation
process asks for a target EditPart at the location of the stroke
sets location point. If that target EditPart is resolved before the
old element is deleted a wrong parent element is returned and
the create command will execute with an unintended result.
Since the client framework should not be bothered to handle
the connection process, the connection between scribble and
client element is established using a trick. Because GEF hides
the actual creation of EditParts in its framework the client
element is not available through the command. The only way
to retrieve a reference of the client EditPart is to monitor the
EditPartRegistry during command execution. A snapshot of
the registry is taken before and after the creation command.
The difference between the snapshots resembles the required
client EditParts.827Fig. 4. Screenshot of the provided debug perspective
C. Development Support
To provide the user with further information about the
internal state of the framework we provide the debug per-
spective shown in Fig. 4. The contained views give the user
insight and control over the token registry of the currently
active editor, an interface to select and label strokes without
the scribble tool and a comprehensive listing of the latest
ResultContributions. Also, we included a special view to
illustrate various information speciÔ¨Åc for the $N recognizer
about a selected scribble. The developed views are intended
to facilitate the process of developing new algorithms and
understanding the scribble framework but their use is not
mandatory.
VI. S CRIBBLE IN ACTION
We evaluated the Scribble framework by injecting it in
editors with different complexity. The Ô¨Årst candidate is the
Shapes editor which is shipped with the GEF examples. It is a
fairly simple editor featuring two types of elements, rectangles
and ellipses as well as two types of connections, solid and
dashed. Injecting Scribble into standard editors is a two-step
procedure:
1) Open the editor in question
2) Click on the Attach Scribble Tool button in the toolbar
(see Fig. 5 (a))
A new tool will be available in the editor‚Äôs palette pro-
viding the Scribble features as shown in Fig. 5 (b). Afterselecting the scribble tool, arbitrary sketches can be added
to the diagram. Recognition is performed in the background
and transformation into corresponding diagram elements is
done automatically if possible. If the drawn element was
not recognized at all or incorrectly recognized, it is easy to
reassign the correct diagram element. Selecting an element in
the diagram dynamically populates an overlay with several edit
operations and the possibility for reassigning the correct model
element as shown in Fig. 5 (c). The drawn element will now
be added to the list of templates used by the recognizers which
increases the probability of recognizing the element correctly
for any subsequent drawings.
The second tool tested is the Logic editor, also shipped
with the GEF examples. It is able to construct and visualize
simple logic circuits. Available creation tools amongst others
are circuits, leds and several gates. Injecting Scribble needs
exactly the same steps as described above. Worth to mention
are similar looking elements within a diagram editor: Circuits
and leds both have roughly the same rectangular shape which
makes it hard for Scribble to determine the difference between
those two elements while performing the recognition. There-
fore, the user can specify an arbitrary shape which can be
associated with the given diagram element. We deÔ¨Åned simple
rectangles to represent circuit elements and rectangles with a
contained ‚ÄúL‚Äù to represent leds. Fig. 4 visualizes this example.
The last and most complex candidate is the class diagram
editor of UML Lab [10] shown in Fig. 5. As in the two828Fig. 5. Screenshot of UML Lab showing Scribble in action
examples shown above, injecting Scribble needs just one click.
Since class diagrams by deÔ¨Ånition basically contain simple
boxes and lines, Scribble has to be trained with differently
looking shapes for the recognizer to work correctly. We used
a simple rectangle for classes, a rectangle containing an ‚ÄúI‚Äù
for interfaces and a rectangle containing a ‚ÄúD‚Äù for data types
as shown in Fig. 5 (d). This approach is natural for class
diagrams since the difference between classes and interfaces
is the keyword ¬´interface¬ª which would also need to be
written when using pen and paper. However, there might
be cases where additional information has to be speciÔ¨Åed
to solve possible disambiguation between multiple similar
looking shapes.
We did not modify any code of the evaluated diagram tools
to get Scribble working. While it may not be surprising that
our approach performs well for simple diagram editors which
where explicitly developed to show any GEF speciÔ¨Åc best
practices, it is worth mentioning that even complex diagram
editors having an unknown internal behavior are supported.
VII. C ONCLUSIONS AND FUTURE WORK
In this paper we presented a Ô¨Årst prototype of the Scribble
framework: A generic but also extensible framework which
augments any new or existing GEF based diagram editor with
sketch features. For standard editors which make use of default
GEF features like the tool palette, the user does not have to
write a single line of code to integrate Scribble. This kindof editor type constitutes the majority of diagram editors in
the Eclipse environment. If no palette is available and thus
Scribble cannot analyze possible elements to create, an Eclipse
extension point can be used to tell Scribble what elements are
available.
We evaluated our framework by augmenting three different
diagram editors: Two relatively simple editors shipped with the
GEF examples, namely the Shapes and the Logic editor. To
also evaluate the framework in a more complex environment,
we injected Scribble into the UML class diagram editor of
UML Lab. No code changes were made to any of the three
editors and we only used Scribbles generic features to analyze
all diagram editors. While it may not be very surprising that
our approach works great for simple editors like the Shapes or
Logic editor, it is remarkable that the injected Scribble features
also work in sophisticated diagram editors like UML Lab.
We found the $N algorithm for shape recognition perform-
ing considerably better than the one based on the Levenshtein
distance. One reason is $N‚Äôs Ô¨Çexibility concerning rotation
invariance. Another is the freedom in drawing multi-stroke
shapes in different stroke order. In most cases we achieved
good recognition results with only four to six training tem-
plates using the $N algorithm.
Scribble along with some guidance on how to install and
use it can be accessed online1. However, Scribble is still in an
early stage of development and there still is much to do:
1http://seblog.cs.uni-kassel.de/projects/scribble/829A major issue is the recognition of edges since we can not
use standard template based recognition algorithms here.
A single edge type may have an arbitrary shape and the
challenge is to Ô¨Ånd appropriate features along the edges
path for identiÔ¨Åcation.
We plan to integrate handwriting recognition. Even if the
integrated algorithms for shape recognition would be able
to perform basic single letter recognition, a sophisticated
word recognition engine which supports handwriting is
still missing. For example Microsofts Ink Recognition
API [31] could be wrapped into a service and then
integrated into our framework.
We plan to integrate automatic label detection: If an editor
contains elements which can be edited, it would be nice
to be able to edit these labels by using Scribble and hand-
writing recognition support. Scribble could automatically
detect editable labels and provide a special label input
Ô¨Åeld which is triggered by a curved arrow gesture, for
instance.
Connection to the online service to automatically down-
load training data is currently integrated.
We will provide persistence of sketches. Each time the
user closes the editor, sketched content is lost which
might not be desirable. The reason why no persistence is
currently performed is that the process of recreating the
connection between a scribbled element and the correct
element within the diagram editor is not very clear.
One possible generic solution would be to search for
the correct diagram element for each scribble using a
location based approach. If that fails (which might be
the case if the diagram was modiÔ¨Åed by some external
tool), Scribble could provide an identiÔ¨Åer interface which
clients could implement to return a unique identiÔ¨Åer for
a given scribble.
Currently we assume the use of a single-touch input
device without any pressure information. Using more
advanced input devices like multi-touch capable Smart-
boards or Tablets, familiar gestures for moving or mag-
nifying could be used to enhance user experience.
The Scribble prototype answers some of the questions listed
in section II, especially the technical ones. It is possible to
dynamically inject sketch-based input methods into existing
graphical diagram editors without the need to write a lot of
code. However, further research has to be done to answer the
question if common components can be created to be shared
with other environments beside Eclipse. A potential candidate
would be Visual Studio, although there seems to be no standard
diagram creation framework like GEF for Eclipse.
To address the question if sketch-based input techniques
are accepted by users of diagram editors, a larger end-user
evaluation is required. Due to the prototype status of the
presented approach, a comprehensive user study is missing.
We plan to evaluate Scribble in one of our lectures, namely
programming methodologies, in the upcoming winter term.
There, students get Ô¨Årst contact to modeling tools and makeuse of UML class diagram editors. We would like to evaluate
if the use of more natural input methods supported by modern
devices as well as the not required switches between different
tools of a palette lead to a better user experience.
ACKNOWLEDGMENT
We would like to thank Prof. Albert Z√ºndorf for reviewing
an early draft of this paper.
REFERENCES
[1] G. V . R. D. Mauro Cherubini and A. J. Ko, ‚ÄúLet‚Äôs go to the whiteboard:
how and why software developers use drawings,‚Äù in Proceedings of the
SIGCHI conference on Human factors in computing systems , 2007, pp.
557‚Äì566.
[2] M. SteÔ¨Åk, D. G. Bobrow, G. Foster, S. Lanning, and D. Tatar, ‚ÄúWysiwis
revised: early experiences with multiuser interfaces,‚Äù ACM Trans. Inf.
Syst, vol. 5, no. 2, pp. 147‚Äì167, 1987.
[3] W. Ju, A. Ionescu, L. Neeley, and T. Winograd, ‚ÄúWhere the wild things
work: capturing shared physical design workspaces,‚Äù in Proceedings of
the 2004 ACM conference on Computer supported cooperative work ,
ser. CSCW ‚Äô04. ACM, 2004, pp. 533‚Äì541.
[4] F. Guimbreti√®re, M. Stone, and T. Winograd, ‚ÄúFluid interaction with
high-resolution wall-size displays,‚Äù in Proceedings of the 14th annual
ACM symposium on User interface software and technology , ser. UIST
‚Äô01. ACM, 2001, pp. 21‚Äì30.
[5] E. D. Mynatt, T. Igarashi, W. K. Edwards, and A. LaMarca, ‚ÄúFlatland:
new dimensions in ofÔ¨Åce whiteboards,‚Äù in Proceedings of the SIGCHI
conference on Human factors in computing systems: the CHI is the limit ,
ser. CHI ‚Äô99. ACM, 1999, pp. 346‚Äì353.
[6] W. Ju, B. A. Lee, and S. R. Klemmer, ‚ÄúRange: exploring implicit
interaction through electronic whiteboard design,‚Äù in Proceedings of the
2008 ACM conference on Computer supported cooperative work , ser.
CSCW ‚Äô08. ACM, 2008, pp. 17‚Äì26.
[7] N. Mangano, A. Baker, M. Dempsey, E. Navarro, and A. van der
Hoek, ‚ÄúSoftware design sketching with calico,‚Äù in Proceedings of the
IEEE/ACM international conference on Automated software engineer-
ing, ser. ASE ‚Äô10. ACM, 2010, pp. 23‚Äì32.
[8] (2012) IBM Rational Software. IBM. [Online]. Avail-
able: http://www-01.ibm.com/software/rational/?pgel=ibmhzn&cm_re=
masthead-_-products-_-sw-rational
[9] (2012) Papyrus. Eclipse. [Online]. Available: http://www.eclipse.org/
modeling/mdt/papyrus/
[10] (2012) UML Lab Modeling IDE. Yatta Solutions GmbH. [Online].
Available: http://www.uml-lab.com
[11] (2012) Enterprise Architect. SPARX Systems. [Online]. Available:
http://www.sparxsystems.com.au/
[12] S. Jarzabek and R. Huang, ‚ÄúThe case for user-centered case tools,‚Äù
Commun. ACM , vol. 41, no. 8, pp. 93‚Äì99, 1998.
[13] C. H. Damm, K. M. Hansen, and M. Thomsen, ‚ÄúTool support for
cooperative object-oriented design: gesture based modelling on an
electronic whiteboard,‚Äù in Proceedings of the SIGCHI conference on
Human factors in computing systems , ser. CHI ‚Äô00. ACM, 2000, pp.
518‚Äì525.
[14] Qi Chen, John Grundy, and John Hosking, ‚ÄúAn e-whiteboard application
to support early design-stage sketching of uml diagrams,‚Äù in In Proceed-
ings of the 2003 IEEE Conference on Human-Centric Computing . IEEE
CS Press, 2003, pp. 219‚Äì226.
[15] J. Wu and T. C. N Graham, ‚ÄúThe software design board: a tool
supporting workstyle transitions in collaborative software design,‚Äù in
Collaborative Software Design. In Proceedings of EHCI/DSV-IS‚Äô 2004 ,
2004, pp. 92‚Äì106.
[16] B. Plimmer, H. C. Purchase, and H. Y . Yang, ‚ÄúSketchNode: intelligent
sketching support and formal diagramming,‚Äù in Proceedings of the 22nd
Conference of the Computer-Human Interaction Special Interest Group
of Australia on Computer-Human Interaction , ser. OZCHI ‚Äô10. ACM,
2010, pp. 136‚Äì143.
[17] J. Grundy and J. Hosking, ‚ÄúSupporting Generic Sketching-Based
Input of Diagrams in a Domain-SpeciÔ¨Åc Visual Language Meta-
Tool,‚Äù in Software Engineering, 2007. ICSE 2007. 29th International
Conference on , 2007, pp. 282‚Äì291. [Online]. Available: http:
//ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4222590830[18] J. Grundy, J. Hosking, Nianping Zhu, and Na Liu, ‚ÄúGenerating Domain-
SpeciÔ¨Åc Visual Language Editors from High-level Tool SpeciÔ¨Åcations,‚Äù
in21st IEEE/ACM International Conference on Automated Software
Engineering, 2006. ASE ‚Äô06. , 2006, pp. 25‚Äì36.
[19] U. B. Sangiorgi and S. D. Barbosa. (2010) SKETCH: Modeling Using
Freehand Drawing in Eclipse Graphical Editors. [Online]. Available:
http://www.ics.uci.edu/~tproenca/icse2010/Ô¨Çexitools/papers/papers.zip
[20] A. Coyette, S. Schimke, J. Vanderdonckt, and C. Vielhauer, ‚ÄúTrainable
sketch recognizer for graphical user interface design,‚Äù in Proceedings
of the 11th IFIP TC 13 international conference on Human-computer
interaction , ser. INTERACT‚Äô07. Springer-Verlag, 2007, pp. 124‚Äì135.
[Online]. Available: http://dl.acm.org/citation.cfm?id=1776994.1777013
[21] I. E. Sutherland, ‚ÄúSketchpad: a man-machine graphical communication
system,‚Äù in Proceedings of the May 21-23, 1963, spring joint computer
conference , ser. AFIPS ‚Äô63 (Spring). ACM, 1963, pp. 329‚Äì346.
[22] G. Johnson and L. Szerb, Computational support for sketching in design:
A review . Hanovar and Mass: Now, 2009.
[23] D. Rubine, ‚ÄúSpecifying gestures by example,‚Äù SIGGRAPH Comput.
Graph , vol. 25, no. 4, pp. 329‚Äì337, 1991.
[24] James A. Pittman, ‚ÄúRecognizing handwritten text,‚Äù in Computer Human
Interaction , 1991, pp. 271‚Äì275.
[25] L. Anthony and J. O. Wobbrock, ‚ÄúA lightweight multistroke recognizer
for user interface prototypes,‚Äù in Proceedings of Graphics Interface2010 , ser. GI ‚Äô10. Canadian Information Processing Society, 2010,
pp. 245‚Äì252. [Online]. Available: http://dl.acm.org/citation.cfm?id=
1839214.1839258
[26] H. Hse and A. Newton, ‚ÄúSketched symbol recognition using Zernike
moments,‚Äù in Pattern Recognition, 2004. ICPR 2004. Proceedings of
the 17th International Conference on , vol. 1, 2004, pp. 367 ‚Äì 370 V ol.1.
[27] J. A. Landay and B. A. Myers, ‚ÄúInteractive sketching for the early
stages of user interface design,‚Äù in Proceedings of the SIGCHI con-
ference on Human factors in computing systems , ser. CHI ‚Äô95. ACM
Press/Addison-Wesley Publishing Co, 1995, pp. 43‚Äì50.
[28] James Lin, Mark W. Newman, Jason I. Hong, and James A. Landay,
‚ÄúDENIM: Ô¨Ånding a tighter Ô¨Åt between tools and practice for Web site
design,‚Äù in Computer Human Interaction , 2000, pp. 510‚Äì517.
[29] B. Plimmer and I. Freeman, ‚ÄúA toolkit approach to sketched
diagram recognition,‚Äù in Proceedings of the 21st British HCI
Group Annual Conference on People and Computers: HCI...but
not as we know it - Volume 1 , ser. BCS-HCI ‚Äô07. British
Computer Society, 2007, pp. 205‚Äì213. [Online]. Available: http:
//dl.acm.org/citation.cfm?id=1531294.1531323
[30] (2012) Eclipse. The Eclipse Foundation. [Online]. Available: http:
//www.eclipse.org
[31] Microsoft. (2012) About pen input, ink, and recognition. [Online].
Available: http://msdn.microsoft.com/en-us/library/ms839535831