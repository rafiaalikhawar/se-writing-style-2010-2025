Heap Cloning: Enabling Dynamic Symbolic
Execution of Java Programs
Saswat Anand
Georgia Institute of Technology
Atlanta, U.S.A.
saswat@cc.gatech.eduMary Jean Harrold
Georgia Institute of Technology
Atlanta, U.S.A.
harrold@cc.gatech.edu
Abstract —The dynamic symbolic-execution technique can au-
tomatically perform symbolic execution of programs that use
problematic features of Java, such as native methods. However,
to compute precise symbolic execution, the technique requires
manual effort to specify models for problematic code. Further-
more, existing approaches to perform symbolic execution either
cannot be extended to perform dynamic symbolic execution or
incur signiﬁcant imprecision. In this paper, we present a novel
program-transformation technique called heap cloning. Heap
cloning transforms a program in such a way that dynamic
symbolic execution of the transformed program results in the
same path constraints as dynamic symbolic execution of the orig-
inal program. However, symbolic execution of the transformed
program produces feedback on where imprecision is introduced,
and that feedback can reduce the manual effort required to build
models. Furthermore, such transformation can enable existing
approaches to perform symbolic execution systems to overcome
their limitations. In this paper, we also present a system, called
Cinger, that leverages heap cloning, and that we used to perform
an empirical evaluation. The empirical evaluation shows that
Cinger can compute precise path constraints, and requires little
(if any) manual effort for a set of large real-world programs.
I. INTRODUCTION
Symbolic execution [15] is a program-analysis technique
that interprets a program using symbolic inputs along a path,
and computes a constraint, called a path constraint , for that
path over those symbolic inputs. If the path constraint is
satisﬁable, any solution of the constraint represents a program
input that exercises the path. Although in theory, computing
path constraints is well-understood, in practice, it is still
challenging to automatically compute precise1path constraints
for real-world programs.
To be able to automatically compute path constraints for
any program written in a particular programming language, a
symbolic-execution system must support every feature of that
language. If a symbolic-execution system does not support
some language features, manual effort is required to specify
models for those parts of a program that use those features.
For Java, native methods and features such as reﬂection that
are dependent on the internals of a Java virtual machine
(JVM) complicate the implementation of a symbolic-execution
system. However, these features are widely-used in real-world
Java programs. One study [3] shows that the number of times
1A path constraint of a path pisprecise if any solution of the path constraint
represents program inputs that cause the program to take path p.native methods are called by programs in the SPEC JVM98
benchmark ranges from 45 thousand to 5 million. Native
methods are written in languages such as C, and thus, they
do not have Java bytecode representations. One approach to
implementing a symbolic-execution system that supports those
features extends a standard JVM (e.g., Oracle’s JVM) that
already supports all features of Java. However, none of the
existing symbolic-execution systems for Java are based on
this approach. This approach is difﬁcult to implement, and
also difﬁcult to maintain because the addition of new language
features to the Java language and changes or additions to Java’s
standard library may require modiﬁcations to the JVM and the
symbolic-execution system.
To address the difﬁculty of implementing a symbolic-
execution system, researchers have developed the dynamic
symbolic-execution ( DSE) technique, also known as concolic
execution [9], [22]. Under the DSE technique, the problematic
code of a program, which cannot be symbolically executed, is
executed only concretely,2and the rest of the program is exe-
cuted both symbolically and concretely. For Java, problematic
code, such as native methods and code that uses reﬂection,
can be executed concretely on a standard JVM that already
supports those features.
However, two problems arise in DSE. The ﬁrst problem
arises because native methods are executed only concretely.
This concrete execution leads to the computation of imprecise
path constraints because the effects of those methods on the
path constraint and the program state are ignored. Whenever a
native method updates the value of a memory location, failure
to update the symbolic value corresponding to that memory
location can introduce imprecision. In general, manually-
speciﬁed models, which model effects of native methods,
are necessary for eliminating such imprecision. However,
an automatic method for identifying native methods whose
side-effects may introduce imprecision, and thus, need to be
modeled, can signiﬁcantly reduce the required manual effort.
Existing approaches for implementing DSE [9], [22] do not
address this problem.
The second problem arises from limitations of the two
current approaches that are used to implement (dynamic)
2Concrete execution refers to normal execution of a program with non-
symbolic values.978-1-4577-1639-3/11/$26.00 c2011 IEEE ASE 2011, Lawrence, KS, USA33
symbolic-execution systems for Java. These approaches either
cannot incorporate the DSE technique or incur imprecision.
The ﬁrst approach uses a custom interpreter that interprets a
program according symbolic-execution semantics. Under this
approach, a standard JVM cannot execute the problematic code
of a program because the program’s state, which is managed
by the interpreter, is unfamiliar to the JVM. The second ap-
proach instruments a program, and executes the instrumented
code on a standard JVM such that the instrumentation code
computes the path constraints. Under this approach, although
the program can be executed concretely by the JVM, computed
path-constraints can be imprecise because of problems in
instrumenting Java’s standard library classes. These problems
are illustrated in Section II.
To address the two above-mentioned problems, we de-
veloped, and present in this paper, a novel program-
transformation technique, which we call heap cloning . The
heap-cloning technique transforms the subject program Pso
that the transformed program P/primehas two properties. First,
P/primeuses copies of the original classes produced by the heap-
cloning technique. Second, during execution of P/prime, the heap
consists of two partitions: a “concrete heap” consisting of ob-
jects of the original classes, and a “symbolic heap” consisting
of objects of the copied classes. Native methods of the original
classes operate on the “concrete heap” and Java methods of
the copied classes operate on the “symbolic heap.”
One important beneﬁt of heap cloning is that it can de-
termine the side-effects of native methods by comparing the
value of a memory location in the “symbolic heap” with the
value of the corresponding location in the “concrete heap.”
Thus, a system that leverages heap cloning can reduce the
manual effort required to specify models of native methods
by automatically identifying the subset of methods that must
be modeled. Another important beneﬁt of heap cloning is that
it addresses the problems that arise in implementing DSEusing
custom-interpreter and instrumentation approaches. Under the
custom-interpreter approach, heap cloning enables execution
of native methods on a standard JVM using the concrete heap.
In the instrumentation approach, heap cloning eliminates the
imprecision that arises due to problems with instrumenting
Java’s standard library classes because the transformed pro-
gram use copies of library classes.
In this paper, we also present C INGER (Concolic IN put
GEneratoR ), a system we developed that implements heap
cloning, along with the results of empirical studies we
performed using C INGER to evaluate the effectiveness of
the heap-cloning technique. C INGER uses the program-
instrumentation based approach to symbolic execution, and
leverages another technique, which we developed in our prior
work [1], that aims to improve the efﬁciency of computing
path constraints. We performed our studies on ﬁve real-world
example programs that extensively use Java’s standard library
classes and other language features, such as reﬂection and
native methods. The ﬁrst study shows that the imprecision
that arises in the instrumentation approach can be eliminated
by leveraging heap cloning. The second study shows that1class L{
2 intf;
3 L( intv){this.f = v; }
4 native void complex();
5}
6class A{
7 L l;
8 A( intv){this.l =new L(val); }
9 public static void main(String[] args) {
10 init();
11 inti = intInput();
12 A a = new A(i);
13 L x = a.l;
14 intj = x.f + 3;
15 if(j<0)
16 x.complex();
17 if(x.f<0) error();
18 }
19 }
Fig. 1. Example Java program.
heap cloning can reduce the manual effort required to specify
models for native methods that possibly introduce imprecision
and that a symbolic-execution system that uses the custom-
interpreter approach can be applied automatically to a larger
set of programs by leveraging heap cloning.
The main contributions of the paper are
•A novel program-transformation technique, heap cloning,
that reduces the manual effort required to write models
for native methods, and addresses the problem that arise
in implementing DSE using the two existing approaches.
•A practical DSE system, C INGER that leverages the
heap-cloning technique and an optimized instrumentation
approach developed in our prior work [1].
•An empirical evaluation of the technique that demon-
strates that it is possible to efﬁciently compute precise
path constraints for programs, which may use native
methods and Java’s standard library classes, with little
(if any) manual effort.
II. B ACKGROUND AND MOTIVATION
In this section, we ﬁrst introduce the example that we use
throughout the paper. We then illustrate the problems that
arise in DSE using the example.
Example. Figure 1 gives an example Java program P, which
consists of two classes: AandL.Pinputs an integer (line 11),
and performs several simple operations. The native method
complex , which is invoked in line 16 of Figure 1, reads
the current value of the ﬁeld f, and stores its corresponding
absolute value back into ﬁeld f. For the purpose of discussion,
suppose that the following Java code is equivalent to the code
of the complex method.
void complex() {
int i = this.f;
if(i < 0) i = -i; this.f = i; }
Effects of native methods on precision. Suppose the program
is executed with input -10. The intraprocedural path through34themain method that is executed with this input is the
sequence of all statements in that method. In DSE, suppose we
introduce a symbol Ito represent the symbolic program input,
and symbolically execute along the path. As the concrete input
value (i.e., -10) propagates through the program variables, the
symbolic value is propagated similarly. For example, because
the concrete input value is stored in the ﬁeld fat line 13,
the memory location corresponding to the ﬁeld is mapped to
symbolic value I.
X+ 3<0∧X < 0∧ −X > = 0 is the correct path con-
straint for this path. The ﬁrst and third conjuncts3correspond
to the branching statements of lines 15 and 17, respectively.
The second conjunct corresponds the branching statement
inside the complex method. Note that the third conjunct
accounts for the side-effects of the native method complex ,
which on the current path reads the value (i.e., -10) of the
ﬁeldfat the time of its invocation, and then stores the absolute
value (i.e., 10) into the ﬁeld f.
However, it is difﬁcult to automatically compute the cor-
rect path constraint because symbolic execution of native
methods is challenging, if not impossible. As a result, a
DSE engine would ignore the update to ﬁeld fthat is made
inside complex , and incorrectly compute the path constraint
X+ 3<0∧X > = 0. This path constraint is incorrect be-
cause (1) it is missing the conjunct corresponding to the branch
incomplex method, and (2) the second conjunct in this
path constraint is different from the third conjunct of the
correct path constraint, even if both conjuncts are added to
the respective path constraints as a result of execution of the
statement in line 17.
To eliminate this imprecision, the user must provide a
model for the complex method. Although, writing such
models cannot be automated because it requires manual
analysis of native methods, in many cases, it is possible to
automatically identify methods whose side-effects introduce
imprecision in computed path constraints. In this example,
an automatic technique such as heap cloning can determine
that ignoring the update to ﬁeld finside complex method
can introduce imprecision because the memory location
corresponding to the ﬁeld is mapped to some symbolic value.
Custom interpreter approach for DSE.This approach, which
is used in JFuzz [12], Symbolic Pathﬁnder [17], Kiasan [6],
and symbolic-execution systems used in References [20], [24],
uses a custom interpreter that executes the program according
to the semantics of symbolic execution. It is problematic to use
this approach to implement DSE because native methods can-
not be concretely executed by a standard JVM . The interpreter
manages the program’s state and thus, a JVM cannot operate on
such an external representation of program’s state. Although
recent work [18] demonstrated how this approach can con-
cretely execute side-effect free native methods, handling native
methods with side-effects still remains problematic.
3Aconjunct is an atomic constraint that is generated as a result of different
program statements that update the path constraint, such as a branch whose
outcome depends on symbolic values.For example, consider the native method complex in the
program shown Figure 1. Recall that complex reads and
updates ﬁelds of the receiver object on which the method is
invoked. Because the method reads and writes to the program
heap, it would not be possible to perform DSEusing a custom-
interpreter approach.
One potential solution to this problem is to translate the
program state before an invocation of a native method to a
representation that is familiar to a standard JVM, and after the
invocation, translate the program state to the representation
that the custom-interpreter uses. However, this solution may
not scale well in general because, even “well-behaved”
native methods can access not only the program heap that
is reachable from their arguments, but also parts of heap
that are reachable from any static ﬁelds. As a result, for this
solution to work in general, signiﬁcantly large portions of
program’s heap must be translated before and after calls to
native methods.
Imprecision in instrumentation approach. Under this ap-
proach, a program is instrumented so that the instrumentation
code maintains the symbolic program state and computes path
constraints. Because the instrumented code can be executed
on a standard JVM, this approach facilitates DSE. Two existing
techniques are based on this approach. The ﬁrst technique [14]
is used in existing symbolic-execution systems such as JPF-
SE [2], S TINGER [1], Juzi [8], and the system used in
Reference [16]. The second technique is used in existing
systems such as JCUTE [21], LCT [13], and TaDa [10].
The main difference between the two techniques is the type
of instrumentation they perform. However, each suffers from
the imprecision problem for the same reasons. Under this
approach, the instrumentation code tracks the symbolic values
as they ﬂow through the program. Thus, when symbolic values
ﬂow into Java’s standard library classes, the approach requires
those classes to be instrumented like the user-deﬁned classes.
However, two problems make it difﬁcult to instrument
those library classes, and without such instrumentation, the
path constraints can be imprecise. First, standard JVMs make
implicit assumptions about the internal structures of the core
library classes, such as java.lang.String . Thus, any
instrumentation that violates those assumptions can cause the
virtual machine to crash. For example, Sun’s virtual machine
will crash when ﬁelds of user-deﬁned types are added to
java.lang.String or when types of any ﬁelds of the core
classes are changed. Second, if library classes are transformed
to use some user-deﬁned classes, those user-deﬁned classes
must not use library classes. Otherwise, the result may be
non-terminating recursive calls. For example, suppose Lis
a library class, and the transformed Luses a non-library
class Expression . IfExpression internally uses class
L, it will lead to non-terminating recursive calls. Although in
theory, classes such as Expression can be written without
using any library classes, it is cumbersome to do in practice.35Object class
[ [class Object {•K;M}] ]=interface ObjectI
HC(1)
=class Object HCimplements ObjectI
HC{Object shadow; [ [K] ];[ [M] ]} (2)
Other classes

class C extends D
implements I{
Ef;
K;
M
}

=class C HCextends D HCimplements IHC{ (3)
EHCfHC; (4)
[ [K] ],CHC(){r=new C; r .C(null ); this.shadow =r;} (5)
,CHC(C s){this.shadow =s;}; (6)
[ [M] ] (7)
} (8)
=class C extends D implements I,Wrapper; { (9)
Ef; (10)
K,C (Dummy HCd){super (d);}; (11)
M,C HCwrap (){r=new C HC; r.CHC(this ); return r; } (12)
} (13)
Constructor
[ [C(Dx){S}] ] =void CK
HC(CHCy,DHCx){[ [S] ]}(14)
Non-native method
[ [D m(Cx){S}] ] =DHCmHC(CHCx){[ [S] ]} (15)
Native method
[ [native D m (Cx);] ]=DHCmHC(CHCx){ (16)
r=m(shadow (x)); (17)
return r .wrap ();} (18)
Allocation
[ [v=new C ] ] =v=new C HC (19)
Constructor invocation
[ [v.C(Dx)] ] =CK
HC(CHCv,DHCx) (20)
Non-static method invocation
[ [v.m(Dx)] ] =v.mHC(DHCx) (21)
Static method invocation
[ [C.m(Dx)] ] =CHC.mHC(DHCx) (22)Store
[ [v1.f=v2] ] =v1.fHC=v2; (23)
σ(v1).f=π(v2); (24)
Load
[ [v1=v2.f] ] =v=v2.fHC; (25)
vs=σ(v2).f; (26)
if(v == v s)goto l; (27)
v2.fHC=vs.wrap (); (28)
l:v1=v2.fHC; (29)
Assignment
[ [v1=v2] ] =v1=v2 (30)
[ [v=null ] ] =v=null (31)
Reference equality/bracketleftbigg /bracketleftbiggif(v1==v2)
goto l/bracketrightbigg /bracketrightbigg
=if(π(v1) == π(v2)) (32)
goto l (33)
Cast
[ [v1= (C)v2] ] =v1= (CHC)v2 (34)
Auxiliary functions:
σ(v) =/braceleftbiggnull v ==null
v otherwiseπ(v) =/braceleftbiggσ(v)v is of reference type
v otherwise
Fig. 2. Heap-cloning transformation rules. The numbers in the parentheses shown next to the rules are used to refer to corresponding lines.
III. H EAP-CLONING TECHNIQUE
In this section, we ﬁrst present the notation that we use, and
then we present the heap-cloning technique. Throughout the
section, we use Pto represent the original program and P/primeto
represent the transformed program produced by applying heap
cloning to P.
Figure 2 presents the transformation rules of the heap-
cloning technique. Our notation is inspired by that used in
the speciﬁcation of Featherweight Java [11]. Because of space
constraints, we (1) present rules for only a representative
subset of the Java language that is relevant to heap cloning
and (2) do not present the syntax of the subset language.
We write Cas shorthand for a possibly empty sequence
C1, . . . ,Cn, and similarly for F,x,S, etc. We write the empty
sequence as •and denote concatenation of sequences usinga comma. We abbreviate operations on pairs of sequences by
writing “ Cf” for “ C1f1, . . . ,Cnfn”. The meta-variables C
andDrange over class names; franges over ﬁeld names; m
ranges over method names; xandvranges over variables.
The class declaration “ class C extends D
implements I 1,I2{Df; K; M}” represents a
class named C.DisC’s superclass, and Cimplements
interfaces I1andI2. The class has ﬁelds fwith types D, a
single constructor K, and a suite of methods M. The method
declaration “ D m( Cx){return e; }” introduces a
method named mwith result type Dand parameters xof
types C. The body of the method is the single statement
return e; .this represents a special variable that store
the reference to the receiver of a non-static method call.
In rest of this section, we refer to the transformation rules
in Figure 2 by the numbers shown in parentheses next to the36L
f = 10A
a xl
LL
f = 10A
A
a xf   = 10ll
shadow shadow
(b) heap snapshot for P' (a) heap snapshot for Ps1 s2
o1 o2
HC HC HC
HCFig. 3. Snapshots of the heaps at line 15 of (a) the original program P
(Figure 1) and (b) the transformed program P/prime, when the programs are
executed with input 10.
rules. Those numbers are shown as superscripts in parentheses
(e.g., text(100)) in the text describing the rule.
A. Creating New Classes
The heap-cloning technique creates a new class (interface)
AHC, which we call the Heap Cloning (abbreviated HC) class,
corresponding to every class (interface) Aof the original
program P(3−8). Like other regular classes, the heap-cloning
technique also creates HC classes corresponding to Java’s
built-in array classes. For example, a regular class char[] HC
is created corresponding to a one-dimensional array of char-
acters. In rest of the paper, we use the following convention:
names of HC classes have HC as subscripts, and the HC class
corresponding to an original class Ais named AHC.
Heap cloning aims to minimize the dissimilarity between the
class hierarchy consisting of original classes and interfaces of
Pand the hierarchy consisting of HC classes and interfaces.
The similarity between the two hierarchies facilitates type-safe
transformation of the program. The inheritance relationship of
HC classes and interfaces is based on the two rules(3): (1) if
a class Ais a subclass of B,AHCis a subclass of AHC; (2) for
each interface Ithat a class Aimplements, AHCimplements
the interface IHC.
Figure 4 shows an example of the way in which the heap-
cloning technique transforms the class hierarchy of a program.
Figure 4(a) shows the original class hierarchy, consisting of
a class A, the built-in character array class char[] , and
the class Object . Figure 4(b) shows the class hierarchy
consisting of the generated HC classes. A solid arrow from a
classAto a class Bmeans that class Aextends class B. A dotted
arrow from a class or interface Ato an interface Bmeans that
Aimplements B.ObjectI
HCis a special interface introduced
by heap cloning. Every HC interface and the Object HC
implement this special interface(2).
For every ﬁeld, f, of an original class A, heap cloning adds
a ﬁeld fHCtoAHC(4). If the type of fcorresponds to class
X, then fHChas type of class XHC(4). For each method mof
an original class A, the heap-cloning technique adds a method
mHCtoAHC(14,15,16). Ifmhas a method body, then m’s body is
copied into mHC(15). Ifmis a native method, then mHCdelegates
the calls to m(16−18). We discuss this delegation in the next
section.
AI
   
A
(b) HC hierarchyObject Object
Object
char[]I
(a) original hierarchychar[]Object
HC HC
HC HCHCIFig. 4. Class hierarchy before and after the heap-cloning transformation.
Heap cloning transforms every invocation statement in the
HC classes so that it will invoke methods of the HC classes.
Thus, when the transformed program is executed, Java meth-
ods of the HC classes, and only native methods and static class
initializers of the original classes, are executed.
B. Concrete and Symbolic Heap Partitions
For every object of a class Acontained in the heap of Pat
some program point during the execution of P, the heap of P/prime
contains one object osof class A. The heap of P/primealso contains
at least one object oof class AHCat the corresponding program
point in P/prime’s execution. We refer to osas the shadow object
ofo. We call the partition of the heap during P/prime’s execution
that consists of objects of the original class (i.e., shadow
objects) the concrete heap partition . We call the partition of
the heap that consists of objects of HC classes the symbolic
heap partition .
During P/prime’s execution, for an object oand its ﬁeld fHC, the
value of the heap location o.fHCremains consistent with the
value of the heap location os.f, where osis the shadow object
ofoandfis the shadow ﬁeld of fHC. The value, vofo.fHC
isconsistent with the value vsofos.fif (1) fis of primitive
type and v=vs, or (2) fis of non-primitive type and vsis
shadow object corresponding to v.
Recall that during P/prime’s execution, some code, such as native
methods and class initializers, of the original classes of Pget
executed. Because the two heap partitions are kept consistent,
that code can read from and write to the concrete heap
partition. Heap cloning handles native methods as follows. If
mis a native method, then mHCdelegates the calls to mwith
arguments that are the shadow objects corresponding to the
HC objects that it receives as parameters. Also, if mreturns
an heap object, mHCwraps it as an object of corresponding HC
class, and returns the wrapped object. Wrapping operation is
discussed later in this section. In contrast to native methods,
handling class initializers do not require any method delegation
because those methods are implicitly invoked by a JVM.
Heap cloning adds a special ﬁeld shadow toObject HC
that stores the shadow object corresponding to an object
of a HC class(2). The object ostores a reference to its
shadow object osin a designated ﬁeld shadow . The program
is transformed such that when an object oof a HC class
AHCis allocated, a shadow object osof the corresponding
original class Ais also allocated, and is stored in the special37ﬁeldshadow ofo(5). To allocate the shadow object, a new
constructor is added to the original class A(11).
To illustrate, consider program Pshown in Figure 1. P
allocates an object of class L(line 8) and an object of class
A(line 12). Figure 3(a) shows the snapshot of P’s heap just
before execution of line 15, when Pis executed with input
10. In Figure 3, each rectangle (shown with a dotted divider)
represents a heap object. The label (if there is one) shown near
the upper right corner of each rectangle refers to the object
that it represents. Ovals represent program variables, and
arrows emanating from ovals represent values of reference-
type variables. For an object, the name of the class of the
object is shown above the divider, and values of the primitive-
type ﬁelds (if any) of the object are shown below the divider.
The value of a reference-type ﬁeld of an object is represented
by an arrow labeled with the ﬁeld name and originating from
the rectangle representing the object.
Figure 3(b) shows the snapshot of P/prime’s heap just before
execution of line 15, when P/primeis executed with input 10. For
every object that exists in P’s heap, P/prime’s heap contains two
objects: one object oof a HC class and the other object of the
original class that is the shadow object of o. For example,
objects s1ands2are the shadow objects of o1ando2,
respectively. Note that the value of the heap location o2.fHC
(i.e.,10) is consistent with the value of s2.f(i.e.,10) because
the ﬁeld fis of int type, and the two values are identical.
Similarly, the value (i.e., the reference to o2) of o1.lHCis
consistent with the value (i.e., the reference to s2) of s1.l
because the ﬁeld lis of reference type and s2is the shadow
object of o2.
C. Handling Side-effects of Uninstrumented Code
Side-effects of uninstrumented code (e.g., native methods)
manifest as inconsistencies between the concrete and symbolic
heap partitions. In heap cloning, two values–one in concrete
heap and another in symbolic heap–are stored corresponding to
every heap location. Instrumented Java methods update values
corresponding to a heap location in both partitions. In contrast,
uninstrumented code update the value corresponding to a
heap location only in the concrete partition. As a result, any
inconsistency in values of a heap location in the two partitions
is an indication that the heap location was updated inside
uninstrumented code. Such inconsistency is detected when
the value of the concerned heap location is later read after
execution of the problematic code. If such an inconsistency
is detected and the concerned heap location is mapped to
a symbolic value at the time of read, a symbolic execution
system that leverages heap cloning can notify the user that an
imprecision might have been introduced.
To illustrate, recall that the native method complex , which
is invoked in line 16 of Figure 1, reads the current value
of the ﬁeld f, and stores its corresponding absolute value
back into the ﬁeld f. Suppose the transformed program
is executed with input -10. The in-lined ﬁgure shows the
potential heap snapshot of the transformed program at line 17
in this execution. In the ﬁgure, note that the value of o2.fHCis
LL
f = 10A
A
a xf   = -10ll
shadow shadow
Inconsistent heaps1 s2
o1 o2
HC HC HC
HCnot consistent with the value
ofs2.fbecause, s2.fis up-
dated inside the complex
native method.
If consistency between
two heap partitions is not
maintained, the transformed
program produced by the
heap-cloning technique may
behave differently from the
original program for some inputs. For example, in this pro-
gram, method error will never be called because at line
17, the value of the heap location x.f is always non-
negative. However, in the transformed program produced by
heap cloning, if the above-mentioned inconsistency is not
eliminated, the error method will be called because at line
17, the value of the heap location o2.fHC(i.e., -10) will be used
to decide which branch is taken. The heap-cloning technique
eliminates the potential inconsistency in this example, by
copying the value of s2.f(i.e., 10) in the heap location o2.fHC,
before the branch decision is made. Following paragraphs
present the transformation rules concerning load and store
statements. Those rules ensure consistency between the two
heap partitions.
InP/prime, an update of a non-static ﬁeld fHCof an object
oto a new value v, is accompanied by an update to heap
location os.f, where osis the shadow object corresponding to
o(23,24). If the ﬁeld fis of primitive type, values of both heap
locations, o.fHCandos.fare updated to the new value v. If
fis of reference type, then the values of o.fHCandos.fare
updated to vandvs, respectively, where vsis shadow object
corresponding to v.
The transformation rule for a load statement handles cases
in which a ﬁeld value in the concrete heap partition is changed
outside the methods of HC classes (e.g., native methods). In
P/prime, a load from ﬁeld fHCof an object oinvolves three steps:
1) Read the current values vandvsof both heap locations
o.fHCandos.f, respectively(25,26).
2) If vandvsare consistent, return v(27).
3) If vandvsare inconsistent, update the value of the heap
location, o.fHCto a value vnewthat is consistent with
vs(28), and return vnew. For primitive type values, vnew
isvs. For reference type values, vnewis obtained from
wrapping vs.
D. Wrapping Concrete Objects
In two cases, it is necessary to wrap objects of original
classes as objects of HC classes. The ﬁrst case concerns values
returned from native methods. For example, a native method
mof a class Xmay return an object of a class A. The method
mHCinXHCthat corresponds to m, delegates the call to m, and
thus, must wrap the object that mreturns as an object of AHC.
The second case concerns situations where a ﬁeld value of a
heap object is updated outside the methods of the HC classes
(e.g., native methods).38To support the wrapping operation, the technique performs
two transformations.
•Every original class, except Object , is transformed to
implement an interface Wrapper , which deﬁnes only
one method wrap(9). The implementation of wrap in an
original class A, wraps the receiver object as an object of
the corresponding HC class AHC(12).
•A special constructor is added to every HC class AHCthat
is used in the wrap implementation of the original class
A(6).
Note that, as a result of wrapping an object of the original
class as described above, one object of an original class Acan
be the shadow object of multiple objects of the HC class AHC.
This may cause the transformed program to behave differently
from the original program. Speciﬁcally, the difference in
behavior may arise because of program operations, such as
reference equality check, use of the hashcode method of
theObject class, and use of monitors for thread synchro-
nization that explicitly or implicitly compares identities of two
objects. However, the heap-cloning technique eliminates this
potential problem. In P/prime, shadow objects as operands to these
problematic operations, instead of objects of HC classes(32).
E. Eliminating Imprecision in the Instrumentation Approach
In the instrumentation approach, the inability to ﬂexibly
instrument Java’s standard library classes leads to imprecision.
However, this inability to instrument library classes does not
lead to any imprecision while symbolically executing the
transformed program P/primeproduced by heap cloning because
P/primedoes not use the original library classes. Instead, with
a few exceptions, P/primeuses the HC classes corresponding to
the library classes. As a result, symbolic values cannot ﬂow
into original library classes in the transformed program, and
thus, it is not necessary to instrument library classes for
symbolic execution. In the exceptional cases, native methods
and static class initializers of the library classes are executed,
and thus, can potentially lead to computation of imprecise
path constraints. This issue of precision is further explained
in Section III-G.
However, heap cloning instruments the original library
classes to maintain concrete heap partition. There are sev-
eral types of minor instrumentation that are applied to
these classes: (1) addition of getter and setter methods to
read and update ﬁelds of those classes, (2) addition of a
constructor(11), (3) making each of those classes (except
Object ) implement the interface Wrapper(9)and the addition
of the method wrap()(11). However, such instrumentation
is not fundamental to heap cloning—it can be avoided using
features, such as reﬂection or low-level API classes (e.g.,
sun.misc.Unsafe ). However, compared to those alter-
natives, instrumentation provides efﬁciency and portability
across JVM’s, and at the same time, in our experience, such
instrumentations have not caused any problem in the JVM’s
operation.F . Enabling DSE in Custom-interpreter Approach
In the custom-interpreter approach, DSE cannot be per-
formed: a standard JVM cannot execute native methods be-
cause the program’s state is managed by the interpreter, and
theJVM cannot operate on an external representation of pro-
gram’s state. By leveraging heap cloning, a custom-interpreter
based symbolic-execution system can perform DSE on the
transformed program P/primeby maintaining the concrete heap
partition internal to a standard JVM as the custom interpreter
interprets P/prime. The interpreter maintains the symbolic heap par-
tition. When a native method is invoked during interpretation,
because the heap-cloning technique guarantees that at that
point concrete heap partition is consistent with symbolic heap
partition, the native method can be safely executed concretely
on the JVM. During its execution, the native method reads
from and writes to the concrete heap partition. After the native
method returns, the interpreter continues interpreting the rest
ofP/prime. If the native method updates a heap location in the
concrete heap partition, as described in Section III-B heap
cloning ensures that the update is reﬂected onto the symbolic
heap partition when the value of that location is later read.
The remaining issue is how the interpreter can maintain the
concrete heap partition on a standard JVM . For a concise,
yet concrete description of the idea, we will describe how
this can be done in a custom-interpreter based symbolic-
execution system that uses Java Pathﬁnder ( JPF).4We chose
JPFbecause two existing symbolic-execution systems, Sym-
bolic Pathﬁnder [17] and JFuzz [12] are implemented using
JPF. We leverage following three characteristics of JPF.
•JPFitself is written in Java, and thus, executes on top of
a standard JVM, which we call the host JVM.
•JPFsupports Model Java Interface ( MJI)APIthat can be
used to intercept invocations of methods of the subject
program, and then execute arbitrary code on the host JVM
in place of the invoked method. The interception code can
also update the subject program’s heap that JPFmanages.
•JPFsupports data annotation feature [17] that allows
attaching metadata to every piece of data that the subject
program operates on.
Using JPF, the concrete heap can be maintained internal to
JPF’s host JVM as follows.
•Two types of operations of the transformed program P/prime
are executed on the host JVM using MJI: (1) operations
that read or update ﬁeld values of objects in the concrete
heap partition, (2) allocation of a shadow object in the
concrete heap partition.
•The mapping from a HC object to its corresponding
shadow object is maintained using JPF’s data annotation
feature.
•The feature that MJI code can allocate objects in the
subject program’s heap is leveraged to allocate objects
of HC classes. The need for this arises to wrap an object
of an original class as an object of the corresponding HC
class.
4http://babelﬁsh.arc.nasa.gov/trac/jpf39Program
P
Heap-cloning
transformationSelective
transformation
Execute P''Concrete
input I
Concrete
outputPath
constraintP'
P''12
3Fig. 5. The C INGER dynamic symbolic-execution system.
G. Improving Precision of Path Constraints
There are two important issues related to the precision of
path constraints. The ﬁrst issue is whether heap cloning can
always automatically compute precise path constraints. Heap
cloning can automatically compute precise path constraints of
a path only if the precision of the path constraint is not affected
by side-effects of methods (e.g., native methods) that are
only concretely executed. If imprecision is introduced because
some of those methods update memory locations that have
symbolic values corresponding to them, heap cloning detects,
and notiﬁes to the user of such updates. Such notiﬁcation
can help the user to identify the problematic methods. To
ensure computation of precise path constraints, the user can
then provide models of those methods such that those models
update the symbolic values of updated memory locations.
The second issue is whether the increase in precision is
beneﬁcial. The beneﬁts of increased precision depends on
the speciﬁc application of symbolic execution. One example
where precision of path constraints is important is a recent
technique [5] that anonymizes user inputs that lead to software
failures in the ﬁeld using symbolic execution. Given one
set of inputs I, the technique uses symbolic execution to
generate another set of inputs Iathat are different from I,
but that cause the program to take the same path as I. The
software developers then use Iato reproduce the failure. In
this application of symbolic execution, if the computed path
constraint is imprecise, then a new set of inputs Iaobtained
from solving the path constraints may not take the same path
asI. As a result, the technique may not be able to reproduce
the failure.
IV. E MPIRICAL EVALUATION
In this section, we ﬁrst discuss our implementation of
CINGER , then we describe our subject programs, and ﬁnally,
we present the results of our two studies.
A. Cinger Dynamic Symbolic-Execution System
CINGER contains approximately 10,000 lines of Java code,
and uses the Soot framework [25]. To compute path con-
straints, C INGER transforms all types of Java constructs and
operators, such as bitwise operations, array accesses, arraysTABLE I
SUBJECT PROGRAMS FOR THE STUDIES .
Subject Methods Classes Lines of Code
User Library User Library User Library
NanoXML 87 709 15 161 1,230 14,604
JLex 136 717 27 158 6,566 13,702
Sat4J-Dimacs 292 789 45 190 3,908 17,195
Sat4J-CSP 329 1,486 51 339 4,125 39,617
BCEL 112 614 45 149 2,321 12,659
Lucene 942 1,852 215 409 20,821 56,622
with symbolic length, and type conversion of primitive-type
values.
Figure 5 shows a dataﬂow diagram5of C INGER . CINGER
inputs a program Pand a concrete input (i.e., non-symbolic
program input) I. CINGER transforms PtoP/prime/prime, and executes
P/prime/primewith input Ion a standard JVM . Execution of P/prime/primeproduces
(1) the same output as the output produced by executing the
original program Pwith input Iand (2) the path constraint
of the path that Ptakes for I.
Transformation of PtoP/prime/primeinvolves two program-
transformation steps. In Step 1, the Heap-cloning transforma-
tion technique transforms PtoP/prime. Recall that P/primeconsists
of original classes of Palong with HC classes produced
by the heap-cloning technique. In Step 2, only the HC
classes of P/primeare further transformed to produce the ﬁnal
transformed program P/prime/prime. Step 2 uses a variation of the
program-transformation technique that we developed in our
prior work [1], Selective transformation , which is a static
analysis that identiﬁes parts of the program that may operate
on symbolic values, and transforms only those parts. Such
selective transformation ensures that the overhead of symbolic
execution is not incurred for program parts that do not operate
on symbolic values.
B. Subjects
We used six publicly available Java programs as subjects for
our studies: NanoXML, JLex, Sat4J (2 versions), BCEL, and
Lucene. For each subject, we created a test suite consisting of
test cases that we gathered from the web or created manually.
Table I provides details about the subjects. The ﬁrst column
lists the name of the subject. For each subject, the second
column shows the number of methods that were covered by
the test suite. The third and fourth columns show the number
of classes containing at least one covered method and the
number of lines of code corresponding to all covered methods,
respectively. Additionally, each column shows the numbers of
corresponding entities belonging to user-deﬁned (User) classes
and Java’s standard library classes (Library). For example, for
JLex, 136 user-deﬁned methods and 717 library methods are
covered by the set of test cases. Our subjects are signiﬁcantly
larger than subjects used in prior works that applied symbolic
execution to Java programs at the whole-program level.
5In a dataﬂow diagram , rectangles represent input data, ovals represent
processing elements, and labels on edges represent the ﬂow of data between
elements.40TABLE II
RESULTS OF STUDY 1.
Average Percentage of
Average Number of Conjuncts Generated
Subject of Conjuncts Inside Library Classes
NanoXML 19,582 25.24%
JLex 65,068 17.47%
Sat4J-Dimacs 60,351 0.0%
Sat4J-CSP 629,078 66.90%
BCEL 34,161 89.76%
Lucene 47,248 0.0%
C. Study 1: Increase in Precision in Instrumentation Approach
The goal of this study is to assess the increase in precision
that a symbolic-execution system based on the instrumentation
approach would achieve by leveraging the heap-cloning tech-
nique. Path constraints computed using this approach can be
imprecise because computed path constraints may not contain
conjuncts that arise from symbolic execution of library code
that may not be instrumented due to problems described in
Section II.
To do this assessment, we performed three steps.
1) We symbolically executed each subject program using
CINGER to compute path constraints corresponding to
paths that the programs took for each test case in the
subject’s test suite.
2) We computed the number of conjuncts in those path
constraints, and computed the average over all these
conjuncts.
3) We computed the percentage of conjuncts that are gener-
ated inside the library classes, and computed the average
over these percentages.
Table II shows the results of the study. In the table, for
each subject, the second column shows the average number
of conjuncts in path constraints over different inputs. The
third column shows the average percentage of all conjuncts
of a path constraint generated inside methods of HC classes
corresponding to Java’s standard library classes.
The table shows that the percentage of conjuncts gener-
ated inside library classes varies widely across the subjects.
For BCEL, approximately 90% of the conjuncts on a path
constraint are generated inside library classes, whereas, for
Sat4J-dimacs and Lucene, no conjuncts are generated inside
library classes. The number of conjuncts generated inside
library classes depends on whether the library classes operate
on symbolic values. Lucene and Sat4J-Dimacs use their own
input processing front-ends (e.g., scanner), and thus, symbolic
input values do not ﬂow into the library classes.
In summary, the results of this study show that a signiﬁcant
percentage of conjuncts on path constraints are indeed gen-
erated inside Java’s standard library classes, and C INGER is
able compute them precisely.
D. Study 2: Reduction in Required Manual Effort to Specify
Models
The goal of this study is to assess whether heap cloning can
reduce the manual effort required to specify models for native
methods that introduce imprecision.TABLE III
RESULTS OF STUDY 2.
Subject Number of Covered Native Methods
NanoXML 4
JLex 6
Sat4J-Dimacs 0
Sat4J-CSP 9
BCEL 4
Lucene 33
We performed this assessment in three parts. In the ﬁrst
part, we estimated the number of native methods that would
need to be modeled if the user did not know which native
methods could introduce imprecision. To do this, for each
subject program we counted the number of unique native
methods that are executed and have at least one reference-type
parameter. We counted only native methods with reference-
type parameters because performing DSE in the presence
of native methods that take only primitive-type (e.g., int)
parameters is straight-forward. The number of counted native
methods is a lower limit on the number of methods for which
the user may have to provide models because there could be
other native methods that accessed program’s heap through
static ﬁelds.
Table III shows the results of this part. For each subject,
the second column shows the number of such native methods
that are executed for at least one input of the corresponding
test suite. The data in the table show that each of our
subjects, except Sat4J-Dimacs, calls at least one problematic
native method. Thus, if the user did not know which native
methods could introduce imprecision, then she would have to
model each of those methods. Although the number of the
problematic methods is small, it may still require signiﬁcant
manual effort to create models for those methods.
In the second part, we assessed whether the user must write
models for one or more of the above-mentioned problematic
methods if a DSE system that used JPFis used. We chose JPF
because models for a large number of native methods and other
problematic classes (e.g., java.lang.Class ) are already
available for JPF. We estimated whether the user would need
to write new models in addition to those that are already
available. To do this, we implemented a symbolic-execution
system, J AZZ, on top of JPF. We applied J AZZ to our subjects
to compute path constraints for each path that corresponds to
a test case for the subjects.
JAZZ could not automatically handle all our selected
subjects because of the lack of models for some native
methods. For Sat4J and BCEL, we manually removed those
statements of the program that called the problematic native
methods—removal of those statements did not affect the
functionality of the programs. As an example, for Sat4J-
Dimacs and Sat4J-CSP, we removed the code that output
a banner at the beginning of the application. For Lucene,
we did not use this approach because of our unfamiliarity
with the Lucene program and the problematic native methods
(of java.lang.management.ManagementFactory
class). Thus, we could not apply Jazz to Lucene.41In the third part, we enabled C INGER to generate a notiﬁ-
cation whenever it detected an update to a memory location
such that (1) the update occurred inside uninstrumented code,
and (2) that memory location was mapped to some symbolic
value. Those notiﬁcations pointed to only one native method
arraycopy in the class java.lang.System that per-
formed such updates, and this meant that only this method
needed to be modeled.
In summary, without knowing which methods introduced
imprecision, the user must write models for each method that
is counted in Table III. Even the set of models that is currently
available for JPFis not sufﬁcient for our subjects, and thus,
the user must write models for additional methods. In contrast,
if heap cloning identiﬁes only one method that introduced
imprecision, the user has to specify a model for that method.
V. R ELATED WORK
The requirement to transform Java’s standard library classes
arises in a number of domains, such as distributed computing
and software testing. Thus, a number of domain-speciﬁc tech-
niques (e.g., [19], [23]) have been presented that address the
problem by leveraging domain-speciﬁc knowledge, and thus,
they are not suitable for symbolic execution. Prior work [4], [7]
presents general techniques to address this problem. Our heap-
cloning technique builds on the Twin Class Hierarchy ( TWH )
approach [7], in which copies of the classes are used instead
of the original classes. However, for native methods, TWH
requires manually-speciﬁed conversion routines that convert
objects of original classes to objects of copy classes, and vice
versa. In heap cloning, because a concrete-heap partition is
kept consistent with the symbolic-heap partition, native meth-
ods can be executed on the concrete-heap partition without
requiring any conversion routines. Compared to the technique
presented in Reference [4], heap cloning is a more general
solution (i.e., not speciﬁc to an API), and allows arbitrary
instrumentation (e.g., adding ﬁelds) of library classes.
VI. C ONCLUSION
In this paper, we presented a novel program-transformation
technique—heap cloning—that can be used to automatically
identify native methods whose side effects can introduce
imprecision in path constraints. Thus, it can reduce the manual
effort required to apply DSE to real-world programs. Heap
cloning enables implementation of DSE using the custom-
interpreter approach, and eliminates the imprecision of path
constraints that is incurred in the instrumentation approach.
In this work, we assumed that only native methods cannot
be symbolically executed. In future work, we plan to allow
the user to annotate any method to be outside the scope of
symbolic execution, and let the user provide models. Heap
cloning can then detect whether such annotated methods cause
side effects that introduce imprecision, and thus, reduce the
burden of writing models. We believe that the path explo-
sion problem from which symbolic execution suffers can be
addressed by using models of library (e.g., Java’s standard
library) or framework (e.g., Google’s Android) classes thatare used by a large number of application. Currently, we are
working to make the C INGER system available to the research
community.
ACKNOWLEDGEMENT
This research was supported in part by NSF CCF-0725202
and CCF-0541048 and IBM Software Quality Innovation
Award to Georgia Tech. The reviewers provided many helpful
suggestions that improved the paper’s presentation.
REFERENCES
[1] S. Anand, A. Orso, and M. J. Harrold. Type-dependence analysis and
program transformation for symbolic execution. In TACAS , pages 117–
133, 2007.
[2] S. Anand, C. S. Pasareanu, and W. Visser. JPF-SE: A symbolic execution
extension to Java Pathﬁnder. In TACAS , pages 134–138, 2007.
[3] W. Binder, J. Hulaas, and P. Moret. A quantitative evaluation of the
contribution of native code to Java workloads. In IISWC , pages 201–
209, 2006.
[4] W. Binder, J. Hulaas, and P. Moret. Advanced Java bytecode instrumen-
tation. In PPPJ , pages 135–144, 2007.
[5] J. A. Clause and A. Orso. Camouﬂage: automated anonymization of
ﬁeld data. In ICSE , pages 21–30, 2011.
[6] X. Deng, J. Lee, and Robby. Bogor/kiasan: A k-bounded symbolic
execution for checking strong heap properties of open systems. In ASE,
pages 157–166, 2006.
[7] M. Factor, A. Schuster, and K. Shagin. Instrumentation of standard
libraries in object-oriented languages: the twin class hierarchy approach.
InOOPSLA , pages 288–300, 2004.
[8] I. Garc ´ıa. Enabling symbolic execution of Java programs using bytecode
instrumentation. Master’s thesis, Univ. of Texas at Austin, 2005.
[9] P. Godefroid, N. Klarlund, and K. Sen. Dart: Directed automated random
testing. In PLDI , pages 213–223, 2005.
[10] M. Grechanik, C. Csallner, C. Fu, and Q. Xie. Is data privacy always
good for software testing? In ISSRE , pages 368–377, 2010.
[11] A. Igarashi, B. C. Pierce, and P. Wadler. Featherweight Java: a minimal
core calculus for Java and GJ. TOPLAS , 23(3):396–450, 2001.
[12] K. Jayaraman, D. Harvison, V. Ganeshan, and A. Kiezun. A concolic
whitebox fuzzer for Java. In NFM , pages 121–125, 2009.
[13] K. Kahkonen, T. Launiainen, O. Saarikivi, J. Kauttio, K. Heljanko, and
I. Niemel. LCT: An open source concolic testing tool for Java programs.
InBYTECODE , pages 75–80, 2011.
[14] S. Khurshid, C. Pasareanu, and W. Visser. Generalized symbolic
execution for model checking and testing. In TACAS , pages 553–568,
2003.
[15] J. C. King. A new approach to program testing. In Programming
Methodology , pages 278–290, 1974.
[16] X. Li, D. Shannon, I. Ghosh, M. Ogawa, S. P. Rajan, and S. Khurshid.
Context-sensitive relevancy analysis for efﬁcient symbolic execution. In
APLAS , pages 36–52, 2008.
[17] C. S. Pasareanu, P. C. Mehlitz, D. H. Bushnell, K. Gundy-Burlet, M. R.
Lowry, S. Person, and M. Pape. Combining unit-level symbolic execu-
tion and system-level concrete execution for testing NASA software. In
ISSTA , pages 15–26, 2008.
[18] C. S. Pasareanu, N. Rungta, and W. Visser. Symbolic execution with
mixed concrete-symbolic solving. In ISSTA , pages 34–44, 2011.
[19] D. Saff, S. Artzi, J. H. Perkins, and M. D. Ernst. Automatic test factoring
for Java. In ASE, pages 114–123, 2005.
[20] R. A. Santelices, P. K. Chittimalli, T. Apiwattanapong, A. Orso, and
M. J. Harrold. Test-suite augmentation for evolving software. In ASE,
pages 218–227, 2008.
[21] K. Sen and G. Agha. CUTE and jCUTE: Concolic unit testing and
explicit path model-checking tools. In CAV, pages 419–423, 2006.
[22] K. Sen, D. Marinov, and G. Agha. CUTE: A concolic unit testing engine
for C. In ESEC/SIGSOFT FSE , pages 263–272, 2005.
[23] E. Tilevich and Y. Smaragdakis. Transparent program transformationsin
the presence of opaque code. In GPCE , pages 89–94, 2006.
[24] A. Tomb, G. P. Brat, and W. Visser. Variably interprocedural program
analysis for runtime error detection. In ISSTA , pages 97–107, 2007.
[25] R. Vall ´ee-Rai, L. Hendren, V. Sundaresan, P. Lam, E. Gagnon, and P. Co.
Soot - A Java optimization framework. In CASCON , pages 125–135,
1999.42