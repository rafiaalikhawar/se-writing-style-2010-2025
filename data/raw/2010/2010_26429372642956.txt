An Empirical Study on Reducing Omission Errors in
Practice
Jihun Park
Korea Advanced Institute of
Science and Technology
Daejeon, Korea
jhpark@se.kaist.ac.krMiryung Kim
The University of Texas at
Austin
Austin, TX USA
miryung@ece.utexas.eduDoo-Hwan Bae
Korea Advanced Institute of
Science and Technology
Daejeon, Korea
bae@se.kaist.ac.kr
ABSTRACT
Since studies based on mining software repositories sparked
interestsintheﬁeldofguidingsoftwarechanges, manychangerecommendation techniques have been proposed to reduceomission errors. While these techniques only used existing
software commit data sets to evaluate their eﬀectiveness,
we use the data set of supplementary patches which correctinitial incomplete patches to investigate how much actualomission errors could be prevented in practice. We ﬁnd thatwhile a single trait is inadequate, combining multiple traits
is limited as well for predicting supplementary change loca-
tions. Neither does a boosting approach improve accuracysigniﬁcantly, nor ﬁltering based on developer or package spe-ciﬁc information necessarily improves the accuracy. Devel-opers rarely repeat the same mistakes, making the potentialvalue of history-based change prediction less promising. We
share our skepticismthatomission errors are hardtoprevent
in practice based on a systematic evaluation of a supplemen-tary patch data set.
Categories and Subject Descriptors
D.2.7[ Software Engineering ]: Distribution,Maintenance,
and Enhancement
Keywords
omission error; supplementary patch; mining version history
1. INTRODUCTION
About ten years ago, Zimmermann et al. and Ying et
al. [16, 18, 19] sparked interests in the promise of guid-ing software changes based on version histories. Over the
past decade, many change recommendation systems have
been proposed to identify additional change locations to re-duce omission errors. For example, FixWizard [8] identiﬁed
additional change locations using cloning based similarity,
and Hassan and Holt [2] investigated several change propa-gation heuristics, ﬁnding that historical change coupling is
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributedfor pro ﬁt or commercial advantage and that copi es bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-publish, to post on servers or to redistribute to lists, requires prior speci ﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
ASE’14, September 15-19, 2014, Vasteras, Sweden.
Copyright 2014 ACM 978-1- 4503-3013-8/14/ 09 ...$15.00.
http://dx.doi.org/10.1145/2642937.2642956.more accurate than structural dependency relationships for
predicting co-changed program entities. In addition to theaforementioned approaches, many change recommendationsystems[3, 4, 6, 7, 17] havebeendeveloped toﬁndadditionalchange locations based on version histories.
These approaches suggested ways to predict supplemen-
tary change locations; however, they evaluated their accu-
racy on existing software commit data only. They groupedcommits into a set of transactions, and then predicted theremaining entities of a transaction based on a subset of thetransaction. We use a supplementary patch data set to pre-
dict additional change locations for real-world omission er-
rors. The supplementary patch data set was created in our
prior work [9] to study the feasibility of reducing omissionerrors, where developers applied supplementary patches tocorrect or complete original incomplete bug ﬁxes.
We investigate how the supplementary change locations
can be predicted based on the initial change locations. To
represent the relationship between them, we propose a newgraphrepresentationcalled change relationship graph (CRG) .
The CRG uses packages, classes, and methods as graph
nodes, and represents the relationship between graph nodesbased on structural dependency, historical co-change, code
clone, and name similarity relationships. We then develop
a path generalization algorithm based on the CRG to ﬁndthe frequently occurring relationship between the initial andsupplementary change locations.
Based on a comprehensivestudy, wehavedetermined that
it is inherently challenging to predict supplementary change
locations based on initial change locations and then we share
our skepticism that reducing omission errors based on a sys-tematic evaluation of a supplementary patch data set is verydiﬃcult in practice. Our comprehensive study on the sup-plementary patch data set ﬁnds that neither a speciﬁc rela-tionship nor a pattern exists between the initial and supple-
mentary change locations.
2. RELATED WORK
Zimmermann et al. [19] and Ying et al. [16] showed the
early promise for guiding software changes based on ver-
sion histories. They used association rule mining to identify
additional change locations. They evaluated whether their
tool could identify the other entities based on one entity ofa transaction. Zimmermann et al.’s approach showed 33%of precision and 29% of recall on average. The precision andrecall of Ying et al.’s approach were in the range of 30% to50%, and 10% to 30%, respectively. Even though they eval-
uated their approaches according to whether the approach
121
was able to guide software changes of the transaction data
set during the implementation phase, they did not evalu-
ate how the approach could prevent omission errors, basedon a real-world supplementary patch data set. In addition,the overall accuracy was not high enough to be pragmatic;our investigation ﬁndsthat theaccuracy becomes even lowerwhen the historical co-change pattern analysis is applied to
a real-world supplementary patch data set.
Robillard [11] and Saul et al. [12] used structural depen-
dency in order to make a suggestion set for program in-
vestigation. These two approaches showed that structuralrelationships can identify relevant program entities, but the
portion of omission errors that structural dependency can
identify was not evaluated using a real data set.
FixWizard of Nguyen et al. [8], identiﬁed a group of pro-
gram entities ( code peer ) that should be changed together.
To ﬁnd the code peers, they identiﬁed methods that share
similar object usages. Because only a few supplementarypatches have a content similar to the initial changes [9], the
tool cannotbe generalized to real-world omission errors from
the supplementary patch data.
Herzig and Zeller [3] mined cause-eﬀect-chains from ver-
sion histories, which are represented in CTL (ComputationTree Logic). The change coupling, which is generalized byCTL, can represent a causal relationship between two lo-
cations within a predeﬁned time interval. They evaluated
how well their approach could predict additional change lo-cations. Our investigation results show that only a smallportion of omission errors can be predicted using this kindofmining technique; the majority of the patterns between ini-
tial and supplementary change locations appear only once.
Hassan and Holt [2] assessed diﬀerent kinds of change
propagation heuristics, andthensuggested ahybridapproach.
The hybrid approach combined historical co-change patternand code layout based methods, and it showed 49% averageprecision and 51% average recall.
Malik and Hassan [6] improved Hassan and Holt’s work[2]
using adaptive change heuristics based on the best heuris-
tic table, showing the possibility that managing prior pre-
diction information for each entity can improve the predic-tion accuracy. (64% precision and 78% recall) Their hybridapproaches showed high recall and precision at predicting
co-changed entities; however, the evaluation was only con-
ducted on a transaction data set. We also ﬁnd that a boost-ing technique based on past prediction accuracy informationdoes not signiﬁcantly improve the prediction accuracy.
Park et al. [9] investigated the characteristics of supple-
mentary changes and how omission errors can be reduced.
They found that a signiﬁcant portion of bugs required sup-
plementary patches. They also found that structural de-pendency and code clone analysis were limited at predictingsupplementary change locations. In this paper, our investi-gation based on a graph representation (CRG) includes not
only a single relationship between the program entities, but
also a combination of the relationships, a boosting approachbased on the past prediction accuracy, package or developerﬁltering based predictions, and repeated patterns betweeninitial and supplementary change locations.
3. BACKGROUND
3.1 Supplementary patch data set
The supplementary patch data set was created in our
prior work [9] to study the characteristics of supplementarypatches and how we could reduce omission errors. In this
paper, we use the supplementary patch data set to study
the feasibility of several prediction approaches for reducingreal-world omission errors. The supplementary patch dataset comprisesinitial patchesandsupplementarypatches. Aninitial patch represents an initial ﬁx attempt to ﬁx a bug;the ﬁx then turned out to be incomplete or incorrect later.
Supplementary patches are applied later to complete or cor-
rect theinitial patch. This data set and analysis source codeare available on the ﬁrst author’s web page.
1
We use three open source projects as study subjects—Ec-
lipse JDT core, Eclipse SWT, and Equinox p2. We identify
the supplementary patch data set in the same way as we
did in our prior work [9]. We connect commit logs with bug
IDs by parsing the logs considering every integer sequenceas potential bug IDs. We then ignore if the number is out ofa pre-deﬁned range; the minimum value is 3000 (to ignoresmall numbers), and the maximum value is 214100, 259850,and 298700 corresponding to bug ID at 2007/12, 2008/12,
and 2009/12 in the three projects, respectively.
After connecting commits with bug IDs, we categorize the
bugs into two groups. (1) Type I bugs are the bugs that are
ﬁxed only once, and (2) Type II bugs are the bugs that are
ﬁxed more than once in the study period. We call the ﬁrst
ﬁx of Type II bugs the initial patch; the subsequent ﬁxes are
supplementary patches.
We consider the bugs reported in 2002/01 to 2007/12,
2002/01 to 2008/12, and 2006/10 to 2010/01, to make sure
that the bugs are completely resolved. Among 3803, 4673,and 1783 of bugs, we ﬁnd that 23%, 26%, and 26% of them
require supplementary patches in Eclipse JDT core, Eclipse
SWT, and Equinox p2, respectively.
3.2 Building a change relationship graph
To express a path between the initial and supplemen-
tary change locations, we develop a graph representationcalled the Change Relationship Graph (CRG). The CRGuses packages, classes, and methods as graph nodes, andstructural dependency, historical co-change, code-clone andname similarity relationships as graph edges.
The CRG is the ﬁrst representation that allows reasoning
about multiple traits of change relationship; the multipletraits include structural dependency, historical co-change,code clone, and name similarity relationships.Identifying graph nodes. We deﬁne program entities,
such as packages, classes, and methods as graph nodes. We
extract structural information from each version of the pro-
gram ﬁlesusingthePPA(Partial Program Analysis)tool[1].We utilize the PPA tool to generate AST only from changedﬁles, not from the whole program corresponding to each re-vision. We track the version history of each program entityto identify the added revisions and deleted revisions.
Identifying structural dependency relationship edges.
Weuse containment, inheritance, and method invocation re-lationshipedgesasstructuraldependencyrelationshipedges.They are created based on the AST, generated by the PPAtool.
Identifying historical co-change relationship edges.
Wecreateco-changerelationshipedgesbetweenmethodnodesthatarechangedwithinthesamerevision. Byparsingpatchescorrespondingtoeachrevision, weidentifyco-changedmethod
1http://se.kaist.ac.kr/jhpark
122nodes, and then we create a co-change edge between every
pair of the methods.
Identifying code clone relationship edges. We create
code clone relationship edges between method nodes that
have similar content in their method body. The similar con-tents are identiﬁed using CCFinderX [5] with a minimumtoken size of 40. We identify code clones every 4000 revi-
sions, andthenwemapthecodeclonepairstomethodnodes
by parsing patches to make a code clone relationship edge.Identifying name similarity relationship edges. We
create name similarity relationship edges between methodnodes that have similar names. We use the same similaritymeasure as that used in UMLDiﬀ [15]. Because calculating
the name similarity between every method node takes too
much time and makes the number of name similarity edgeshuge, we make a name similarity edge when the followingconditions hold: 1) two method nodes belong to the samepackage. 2) the containing classes of two method nodes havename similarity larger than 0.5. 3) the names of two meth-
ods have name similarity larger than 0.7.
3.3 Evaluating a prediction method
We evaluate how accurately a prediction method predicts
supplementary change locations based on initial change lo-
cations. Our measures for assessing a prediction method areits precision, recall, and feedback. Precision andrecallare
common accuracy metrics. Precision evaluates whether thesuggestion set accurately predicts actual supplementary lo-cations; recall evaluates whether the actual supplementarylocations are covered by the predicted set. Where Prep-
resents the predicted suggestion set and Srepresents the
actual supplementary change locations excluding the initial
change locations, precision and recall are deﬁned as follows:
precision =|P∩S|
|P|,recall=|P∩S|
|S|.I fo n eo f PandSis
an empty set, we do not count the prediction in the result
for the calculation.
Because we disregard cases in which a prediction method
suggestsanemptysetasacandidateofsupplementarychange,
weshouldcompensatetoassess what portion of initial changes
can obtain at least one suggestion. We use the feedback
measure, introduced by Zimmermann et al. [19] to evaluate
whether aprediction method or arule can be generally used.
Where the predicted suggestion set, {Pm
b}, is derived using
a prediction method mfor bug b, the feedback is deﬁned as
follows:
feedback =|{b∈TypeIIbugs |1≤| {Pm
b}| } |
|{TypeIIbugs }|
The numerator represents the number of Type II bugs for
which the prediction method suggests at least one candi-date of supplementary change location. The denominatorrepresents the total number of Type II bugs.
4. OBSERVATIONS
4.1 Observation 1: While a single trait is in-
adequate, combining multiple traits is lim-
ited as well.
To investigate whether repeated patterns of relationship
exist between the initial and supplementary change loca-
tions, we identify frequently occurring paths between them,which can generalize the relationship. For bugs that are
ﬁxed more than once (Type II bugs), we parse the initialand supplementary patches to identify corresponding loca-tions at the method level granularity to match them to cor-
responding method nodes in the CRG.
For the initial and supplementary change locations, we
ﬁrst investigate whether they can be connected with one
hop of structural, historical, code clone, or name similar-ity relationships. The one hop relationships can represent
existing change recommendation approaches. For example,
two locations connected by a code clone edge means thatthe relationship between the two locations can be identiﬁedby code clone analysis.
We ﬁnd that only 20%, 14%, and 10% of supplementary
change locations can be reached within one hop from the
initial changelocations. Thisresultsindicate thatremaining
80%, 86%, and 90% of supplementary change locations arenot predictable using existing approaches in Eclipse JDTcore, Eclipse SWT, and Equinox p2, respectively.
We also investigate the accuracy of prediction rules that
are made using one relationship edge predicting supplemen-
tary change locations. We calculate the feedback, precision,
and recall values of the rules made by one relationship edge,by applying them to the initial change locations of TypeII bugs in order to predict corresponding supplementarychange locations. Table 1 shows the results. Overall, thehighest precision is only 8%, 9%, and 7% and the highest
recall isonly 17%, 22%, and9%, in EclipseJDT core, Eclipse
SWT, and Equinox p2, respectively. These low accuraciesindicate that a single trait is not adequate for predictingsupplementary change locations.
Table 1: Feedback, precision, and recall of predic-
tion rules made by one relationship edge
RelationshipEclipse JDT core
feedback precision recall
calls 94.2% 1.9% 11.2%
called by 70.6% 7.7% 10.7%
code clone 29.2% 3.5% 1.1%
name similarity 84.8% 5.9% 16.4%
co-change 83.3% 4.2% 13.4%
RelationshipEclipse SWT
feedback precision recall
calls 93.2% 0.8% 6.7%
called by 58.2% 7.0% 6.3%
code clone 51.3% 2.1% 1.7%
name similarity 82.8% 8.8% 11.2%
co-change 88.5% 6.0% 22.3%
RelationshipEquinox p2
feedback precision recall
calls 97.3% 1.6% 8.5%
called by 82.1% 6.9% 8.5%
name similarity 72.9% 2.9% 2.9%
co-change 68.4% 2.5% 6.9%
The relationship between the initial and supplementary
change locations also can be represented using a combina-
tion of the CRG edges. For example, when an initial changelocation calls method X, and the method X has a code clonewith a supplementary change location, the CRG can rep-resent the relationship between them with a callsedge and
acode clone edge. To investigate whether the combination
of relationship edges can connect the initial and supplemen-
tary change locations, we study the number of supplemen-tary change locations that are covered within nedges from
corresponding initial change locations. Table 2 shows that
our CRG can identify 30% to 33%, 24% to 33%, 16% to 19%,and 2% to 11% of supplementary change locations with two,
three, four, and ﬁve relationship edges, respectively. Al-
123Table 2: The portion of supplementary change lo-
cations that are covered within nedges from corre-
sponding initial change locations.
# of edges Eclipse JDT core Eclipse SWT Equinox p2
1 769 (20.0%) 1371 (13.5%) 240 (10.2%)
2 1270 (33.1%) 3170 (31.3%) 702 (29.7%)
3 906 (23.6%) 3353 (33.1%) 564 (23.9%)
4 626 (16.3%) 1961 (19.3%) 458 (19.4%)
5 196 (5.1%) 194 (1.9%) 260 (11.0%)
over 5 69 (1.8%) 94 (0.9%) 138 (5.8%)
though there are 2%, 1%, and 6% of supplementary change
locations that cannot be connected within ﬁve edges from
initial change locations, 98%, 99%, and 94% of them can berepresented within ﬁve edges in Eclipse JDT core, EclipseSWT, and Equinox p2, respectively.
We investigate the feedback, precision, recall, and f-score
of the rules made by one to three relationship edges. F-
score is a common measure assessing the predictive power
which considers both precision and recall, and it is deﬁnedby 2∗(precision ∗recall)/(precision +recall). We apply the
rulestotheinitialchangelocationsofTypeIIbugstopredictcorresponding supplementary change locations. Overall, thef-score is at most 9%, 10%, and 8% with the precision value
of 8%, 9%, and 5% and the recall value of 11%, 11%, and
20% in Eclipse JDT core, Eclipse SWT, and Equinox p2,respectively. These low f-scores indicate that combining ofmultiple traits does not predict supplementary change loca-tions based on initial change locations any more accuratelythan single traits.
4.2 Observation 2: A boosting approach does
not signi ﬁcantly improve the accuracy.
To improve the prediction accuracy, we hypothesize that
combining the past accuracy information may improve the
accuracy of future prediction. We divide the supplementarypatch data set into a training set and an evaluation set asTable 3 shows. The training set is used to calculate theprediction accuracy of each rule. Based on the accuracy
information of the training set, we use a boosting approach
to predict supplementary change locations.
Table 3: The period of the training set and evalua-
tion set
Training period Evaluation period
Eclipse JDT core 2002/01 ∼2006/08 2006/09 ∼2007/09
Eclipse SWT 2002/01 ∼2006/08 2006/09 ∼2007/09
Equinox p2 2006/10 ∼2008/10 2008/11 ∼2009/11
Boosting is a machine learning technique, that combines
weak learners to create a strong learner [13]. To classify a
new item, the boosting technique combines a set of resultsthat are generated from weak learners by weighting them
based on the accuracy of the weak learners in the training
set. We develop a boosting approach that uses predictionrules as weak predictors. For a given initial change location,our boosting approach calculates a prediction score for each
connected node within three edges of the initial change loca-tion. The prediction score is calculated by summing up the
trained precision of theprediction rulescorresponding tothe
pathstoeachnodefromtheinitialchangelocation. Thecan-didate locations are ranked with the prediction score; then,our boosting approach suggests top Nnodes.
Table 4 shows the accuracy of the boosting approaches
with diﬀerent top Nvalues. The results show that the pre-
cisions are 7%, 5%, and 6% and the recalls are 5%, 7%,and 10% in Eclipse JDT core, Eclipse SWT, and Equinox
p2, respectively, even when we suggest only the three nodes
that have the highest prediction score. We conclude thatthis boosting approach based on the past prediction accu-racy also cannot accurately predict supplementary changelocations.
Table 4: The accuracy of a boosting approach
top N Eclipse JDT core Eclipse SWT Equinox p2
value prec. recall prec. recall prec. recall
3 6.93% 4.77% 5.21% 7.35% 6.40% 9.93%
5 7.01% 8.65% 4.38% 9.89% 5.28% 12.80%
10 6.75% 14.58% 4.69% 16.20% 3.76% 16.29%
50 4.23% 21.05% 2.06% 29.47% 1.66% 29.18%
100 2.96% 29.01% 1.38% 38.20% 1.23% 33.70%200 2.09% 51.23% 0.94% 49.48% 0.95% 40.21%
4.3 Observation 3: There is no package or de-
veloper speci ﬁc pattern.
We hypothesize that ﬁltering prediction approaches us-
ing package or developer speciﬁc information can improve
the accuracy of the prediction. Package speciﬁc rules canimprove the prediction accuracy when the packages have arepeated pattern of relationships between initial and supple-mentary change locations. Similarly, if a developer makessimilar types of mistakes repeatedly, developer speciﬁc rules
can improve the prediction accuracy.
We deﬁne package speciﬁc rules using a pre-condition and
a relationship, as shown in the example below:
Pre-condition :if the initial change location is in org-
.eclipse.jdt.core.util
Relationship :suggest locations that have been co-
changed with the initial change location.
Developer speciﬁc rules are deﬁned in the similar way; the
pre-condition forms if the initial change is committed by the
developer Tom.
We ﬁrstly identify every package and developer speciﬁc
rule that appears at least once in the training set. To make
package and developer speciﬁc prediction rules, we gatherthe pre-conditions of the initial changes (package names and
committer names) and identify the relationship between the
initial and supplementary change locations of Type II bugsin the training set. We then calculate the accuracy of theprediction rules in the training set.
Figure1plotsthefeedbackandprecisionofthethreekinds
of prediction rules in Eclipse JDT core. We ﬁnd that gen-
eral rules show high feedback but low precision, and de-
veloper/package speciﬁc rules show low feedback but highprecision in all of the study subjects. This is quite natu-ral, because when we ﬁlter the information according to aspeciﬁc package or developer, the rules can precisely predict
supplementary change locations for fewer applicable initial
change locations.
Based on the trained accuracies, we develop boosting ap-
proaches similar to those in the previous section. We ﬁnd
that the boosting approaches based on package and devel-oper speciﬁc rules do not improve the prediction accuracy;
indeed, their accuracy is even lower than that of the boost-
ing approach based on general rules in some cases. Over-all, the highest improvements of the accuracy (in terms off-score) compared to the boosting approach based on gen-eral rules are 1.24%, 1.02%, and 0.78% for the boosting ap-proach based on package speciﬁc rules, and 0.92%, 0.44%,
and1.20% for theboostingapproachbased on developerspe-
124General rules
 Package specific rules
 Developer specific rules0 2 04 06 08 0 1 0 00102030405060
Precision (%)
Feedback (%)
Figure 1: Feedback vs. precision on three kinds of
prediction rules (in Eclipse JDT core)
ciﬁc rules in Eclipse JDT core, Eclipse SWT, and Equinox
p2, respectively.
Our sub-conclusion here is that no developer or package
speciﬁc pattern between initial and supplementary changelocations exists.
4.4 Observation 4: There is no repeated mis-
take.
Although we cannot ﬁnd a repeated pattern of relation-
ship between initial and supplementary change locations ba-sed on existing structural dependency, historical co-change,
code clone, and name similarity relationship, there might be
an uncovered relationship which can result in repeated pat-terns. In this section, we investigate the patterns betweeninitial and supplementary change locations.
In a similar association rule mining approach of previous
work [3, 16, 19], but applying them to the supplementary
patch data set, we can represent the pattern between initial
and supplementary change locations as a rule:— “IfmethodA
is changed in an initial change, then testMethodA is changed
in the supplementary change.”
We investigate whether there is a repeated pattern of the
initialandsupplementarychangelocationpairs. Iftheinitial
change locations are {A, B}and the supplementary change
locations are {X, Y}, we can make the following pattern
rules—( A→X),(A→Y),(B→X),(B→Y). We identify
the number of occurrence for each pattern.
The results shown in Table 5 indicate that the majority of
patterns (78%, 96%, and 95% in Eclipse JDT core, Eclipse
SWT, and Equinox p2, respectively) appear only once, andunder 2% of patterns appear more than three times in thestudy subjects. This result indicates that we cannot gener-ate an appropriate suggestion based on the majority of thepatterns, because they have occurred only once.
In addition, we also ﬁnd that the same location does not
require supplementary ﬁxes repeatedly. Table 6 shows the
portion of initial change locations appearing ntimes. 69%,
71%, and 84% of initial change locations appear only once in
the version history in Eclipse JDT core, Eclipse SWT, andEquinox p2, respectively. These results indicate that devel-
opers rarely make repeated mistakes at the same location;version history based pattern mining cannot be accurate atﬁnding supplementary change locations.
Table 5: The number of patterns between initial and
supplementary change locations appearing ntimes
Number Eclipse JDT core Eclipse SWT Equinox p2
1 73455 (77.5%) 116601 (96.0%) 32715 (94.9%)
2 19412 (20.5%) 4383 (3.6%) 1765 (5.1%)3 755 (0.8%) 312 (0.3%) 11 (0.0%)
4 948 (1.0%) 45 (0.0%) 0 (0.0%)
over 4 207 (0.2%) 127 (0.1%) 0 (0.0%)
Table 6: The number of initial change locations ap-
pearing ntimes
Number Eclipse JDT core Eclipse SWT Equinox p2
1 2704 (68.8%) 2877 (71.3%) 1988 (84.2%)
2 810 (20.6%) 680 (16.9%) 302 (12.8%)
3 235 (6.0%) 243 (6.0%) 45 (1.9%)
4 77 (2.0%) 114 (2.8%) 23 (1.0%)
over 4 106 (2.7%) 119 (3.0%) 3 (0.1%)
5. DISCUSSION
We consider how the supplementary change locations can
be identiﬁed when the initial change is given. The accuracy
predictingthesupplementarychangelocation is already low,but the problem can be more diﬃcult in practice, because
we need to identify the changes that require supplementary
patches. We can identify incomplete patches based on ma-chine learning techniques (e.g., SVM), by investigating thecharacteristics of the incomplete patches (e.g., date, com-mitter, contents of the patch, etc.).
We do not compare prediction rules to see which one is
superior to the others, because the overall accuracies of therules are low. We ﬁnd that called by relationship is more
accurate than the other relationships (see Table 1). This
result implies that called by relationship is harder for pro-
grammers to detect than theother relationships. For a given
initial change location, developers should trace the call hier-
archy to ﬁnd caller method of a method in an initial changelocation. Becausedevelopersaremorelikelytomisstheenti-ties connected by called by relationship to the initial change,
the relationship occurs more frequently between initial andsupplementary changes than other relationships.
Regarding threats to validity, diﬀerent experimental set-
tings can aﬀect our prediction accuracy. For example, in-
stead of using all history data as a training set of the boost-ing approach, we can use only recent information as a train-ing set to limit the eﬀect of the old data. In addition, fuzzylogic, random forests, or neural network can be used in-
stead of a boosting approach. Furthermore, we use only
sub-projects of the Eclipse project as our study subjectswhich are written mostly in Java. Diﬀerent experimentalsettings might improve prediction accuracy, but we doubtthat there is a silver bullet that can resolve this problem ofreducing omission errors.
6. CONCLUSION
Since about ten years ago, when guiding software changes
basedonminingversionhistoriesshowedearly promise, many
changerecommendationsystemshavebeenproposedtoiden-tify additional change locations given an existing changeset. Our study is the ﬁrst systematic and comprehensiveinvestigation of a real-world supplementary patch data set,where developers missed updating the entities together with
the initial change. In this paper, using the supplementary
125change data set, we develop a novel representation, called
change relationship graph (CRG) , that allows us to investi-
gate the relationship between two program locations based
on a combination of structural, historical, name similarity,and code clone relationships. Based on the CRG, we inves-tigate why it is inherently challenging to predict supplemen-tary change locations given initial change locations.
Through a comprehensive study, we observe that while no
single rule is adequate, combining multiple rules is limited
as well. A boosting approach using the rules does not showa high accuracy; rather, it shows that past accuracy infor-mation on a training set does not improve future predictionaccuracy in the evaluation set. Beyond this, neither devel-
opernorpackagespeciﬁcinformation isfound toimprovethe
accuracy. Moreover, there is no repeated pattern betweeninitial and supplementary change locations, and developersdo not make omission errors at the same locations repeat-edly. As researchers who participated in the communityof mining software repository, we share our skepticism that
reducing real-world omission errors based on a systematic
evaluation of a supplementary patch data set is inherentlychallenging.
7. ACKNOWLEDGEMENT
This work was partly supported by the IT R&D program
of MSIP/KEIT [10041313, UX-oriented Mobile SW Plat-form]. This work was supported in part by the National Sci-ence Foundation under gra nts CCF-1149391, CCF-1117902,
SHF-0910818, CCF-1018271, CCF-0811524, CNS-1239498,and a Google Faculty Award.
8. REFERENCES
[1] B. Dagenais and L. Hendren. Enabling static analysis
for partial java programs. In Proceedings of the 23rd
ACM SIGPLAN conference on Object-oriented
programming systems languages and applications,
OOPSLA ’08, pages 313–328, New York, NY, USA,2008. ACM.
[2] A. E. Hassan and R. C. Holt. Predicting change
propagation in software systems. In ICSM ’04:
Proceedings of the 20th IEEE International
Conference on Software Maintenance , pages 284–293,
Washington, DC, USA, 2004. IEEE Computer Society.
[3] K. Herzig and A. Zeller. Mining cause-eﬀect-chains
from version histories. In Software Reliability
Engineering (ISSRE), 2011 IEEE 22nd International
Symposium on , pages 60–69. IEEE, 2011.
[4] H. Kagdi, S. Yusuf, and J. I. Maletic. Mining
sequences of changed-ﬁles from version histories. InMSR ’06: Proceedings of the 2006 international
workshop on Mining software repositories , pages
47–53, New York, NY, USA, 2006. ACM.
[5] T. Kamiya, S. Kusumoto, and K. Inoue. Ccﬁnder: a
multilinguistic token-based code clone detectionsystem for large scale source code. Software
Engineering, IEEE Transactions on , 28(7):654–670,
2002.
[6] H. Malik and A. E. Hassan. Supporting software
evolution using adaptive change propagationheuristics. In Software Maintenance, 2008. ICSM
2008. IEEE International Conference on , pages
177–186. IEEE, 2008.[7] S. Mirarab, A. Hassouna, and L. Tahvildari. Using
bayesian belief networks to predict change propagation
in software systems. In Program Comprehension,
2007. ICPC’07. 15th IEEE International Conference
on, pages 177–188. IEEE, 2007.
[8] T. T. Nguyen, H. A. Nguyen, N. H. Pham,
J. Al-Kofahi, and T. N. Nguyen. Recurring bug ﬁxes
in object-oriented programs. In ICSE ’10: Proceedings
of the 32nd ACM/IEEE International Conference onSoftware Engineering , pages 315–324, New York, NY,
USA, 2010. ACM.
[9] J. Park, M. Kim, B. Ray, and D.-H. Bae. An empirical
study of supplementary bug ﬁxes. In MSR ’12: 9th
IEEE Working Conference on Mining Software
Repositories , pages 40 –49, Washington, DC, USA,
june 2012. IEEE Computer Society,.
[10] M. K. Ripon Saha, Ray Qiu and D. Perry. A
graph-based framework for reasoning about
relationships among software modiﬁcations. Technical
report, 2014.
[11] M. P. Robillard. Automatic generation of suggestions
for program investigation. In ESEC/FSE-13:
Proceedings of the 10th European SoftwareEngineering Conference held jointly with 13th ACM
SIGSOFT International Symposium on Foundationsof Software Engineering , pages 11–20, New York, NY,
USA, 2005. ACM.
[12] Z. M. Saul, V. Filkov, P. Devanbu, and C. Bird.
Recommending random walks. In Proceedings of the
the 6th joint meeting of the European softwareengineering conference and the ACM SIGSOFTsymposium on The foundations of softwareengineering , pages 15–24. ACM, 2007.
[13] R. E. Schapire. The strength of weak learnability.
Machine learning , 5(2):197–227, 1990.
[14] M. Song and M. Kim. A query-by-example approach
for searching related software revisions. Technical
report, 2014.
[15] Z. Xing and E. Stroulia. Umldiﬀ: an algorithm for
object-oriented design diﬀerencing. In ASE ’05:
Proceedings of the 20th I EEE/ACM International
Conference on Automated Software Engineering, pages
54–65, New York, NY, USA, 2005. ACM.
[16] A. T. T. Ying, G. C. Murphy, R. Ng, and
M. Chu-Carroll. Predicting source code changes by
mining change history. IEEE Transactions on
Software Engineering , 30(9):574–586, 2004.
[17] Y. Zhou, M. Wursch, E. Giger, H. Gall, and J. Lu. A
bayesian network based approach for change coupling
prediction. In Reverse Engineering, 2008. WCRE’08.
15th Working Conference on , pages 27–36. IEEE,
2008.
[18] T. Zimmermann, P. Weisgerber, S. Diehl, and
A. Zeller. Mining version histories to guide softwarechanges. In ICSE ’04: Proceedings of the 26th
International Conference on Software Engineering ,
pages 563–572, Washington, DC, USA, 2004. IEEE
Computer Society.
[19]
T. Zimmermann, P. Weißgerber, S. Diehl, and
A. Zeller. Mining version histories to guide softwarechanges. IEEE Transactions on Software Engineering ,
31(6):429–445, 2005.
126