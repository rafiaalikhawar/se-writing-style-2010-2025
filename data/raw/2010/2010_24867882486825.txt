Comparative Causality: Explaining the Di ﬀerences
between Executions
William N. Sumner Xiangyu Zhang
Department of Computer Science, Purdue University, USA
{wsumner,xyzhang }@cs.purdue.edu
Abstract —We propose a novel ﬁne-grained causal inference
technique. Given two executions and some observed di ﬀerences
between them, the technique reasons about the causes of such
diﬀerences. The technique does so by state replacement, i.e.
replacing part of the program state at an earlier point to
observe whether the target di ﬀerences can be induced. It makes
a number of key advances: it features a novel execution model
that avoids undesirable entangling of the replaced state and
the original state; it properly handles di ﬀerences of omission
by symmetrically analyzing both executions; it also leverages a
recently developed slicing technique to limit the scope of causality
testing while ensuring that no relevant state causes can be missed.
The application of the technique on automated debugging shows
that it substantially improves the precision and e ﬃciency of
causal inference compared to state of the art techniques.
I. Introduction
Explaining why something happened is a subtle task;
philosophers have debated the notion of causation for cen-
turies [1]–[3]. One common thread among the myriad ap-
proaches is that they involve comparing a world in which
that something happened to others in which it did not. Many
software engineering techniques take similar approaches i n
explaining software behavior. For example, in probabilist ic
fault localization, a set of failing runs is contrasted with a
set of passing runs [4], [5] to provide probabilistic insigh ts
into the cause of the failures. Compared to techniques that d o
not rely on comparison to explain software behavior, such as
program slicing [6], these techniques are more precise as th ey
use comparison to trim unnecessary information.
One classic ﬁne-grained comparative technique for identif y-
ing causes when one execution (e.g., a buggy execution) di ﬀers
from another (e.g. a similar correct execution) is Zeller’s
delta debugging approach [7]. It is capable of reasoning
about causality at the granularity of individual instructi ons
and variables, generating much more informative and precis e
failure explanations compared to other techniques [8]. The
technique involves replacing part of the state in the correc t
execution with that from the buggy execution and determinin g
whether such replacement induces the failure in the modiﬁed
execution. However, due to the complexity of program state
(e.g. inter-connected data structures in the heap, pointer s, and
external resources), it faces many problems in practice. In
particular, entangling the states from both executions all ows
them aﬀect each other in undesirable and unexpected ways,
leading to poor failure explanations. More discussion of th e
limitations of the technique can be found in Section II.In this paper, we propose a novel ﬁne-grained causal in-
ference technique. Given two executions and some observed
diﬀerences between them, the technique can precisely reason
about the causes of such di ﬀerences. While the technique
reasons about causality through state replacement, it make s
three key advances. It features a novel execution model that
avoids undesirable entangling of the replaced state and the
original state such that the precision of causal inference c an
be substantially improved. It is capable of handling execut ion
omission errors by analyzing both executions symmetricall y.
It also leverages an existing slicing technique called dual
slicing [9] to limit the scope of causality testing while ens uring
no relevant state di ﬀerences can be missed. As a result, the
eﬃciency is substantially improved.
Our main contributions are highlighted as follows.
•We ﬁrst thoroughly discuss the limitations of the state of
the art ﬁne-grained causal inference technique that has bee n
used for many years. We especially study the problems in
state replacement.
•We propose a novel causal inference model that is symmet-
ric and comparative. We declare the goals of the model,
which reﬂect the user’s intention when reasoning about
software behavior by comparison.
•We propose a novel realization of the model. It leverages
dual slicing to ensure relevance of the causes and limit
the scope of causality testing. While it makes use of state
replacement to determine causality, a novel execution mode l
and its approximation are developed to avoid the undesirabl e
entangling of the state from both executions.
•We implement and evaluate a prototype. We apply the causal
inference engine toward failure explanation for 15 real
world bugs, including all the reported bugs for tar,make ,
andgrep in a one year period. Comparison against the
causal inference engine from the most recent improved
delta debugging [8] and dual slicing techniques shows that
our technique has substantially improved the e ﬃciency and
eﬀectiveness of failure explanation.
II. Causal StateMinimizationin DeltaDebugging
Delta debugging is a classic debugging technique that can
minimize failure inducing inputs [10] or the faulty interna l
program state essential to reproducing a failure [7], [11]. The
original work ﬁrst contrasts a buggy execution with a simila r
correct execution to determine state di ﬀerences [7], [11]. It
then performs Causal State Minimization (CSM) to determine978-1-4673-3076-3/13/$31.00 c2013 IEEE ICSE 2013, San Francisco, CA, USA272
1x←input ()
2y←input ()
3z←input ()
4ify>1 & z<6:
5 y←5
6else: y←y+1
7print (y)
(a)x←1
y←1
z←3
if False :
y←2
print (2)
(b)x←0
y←2
z←6
if False :
y←3
print (3)
(c)1
2
3
4
6
7/braceleftBigg
y/mapsto→2
z/mapsto→6/bracerightBigg
(d)1
2
3
4
6
7
(e)
Fig. 1: (a) A program. (b-c) executions with di ﬀering input. (d) CSM. (e) dual
slice. Symbols /Diamondand/Diamondsoliddenote the cause point and e ﬀect point, respectively.
The set in (d) represents the causal state set.
the minimal subset of state di ﬀerences essential to reproducing
the failure. CSM involves performing the correct execution up
to a point of interest preceding the failure, called the cause
point , replacing a subset of program state with state from
the buggy execution, and continuing this patched execution
to determine whether the failure can be induced. If so, the
subset is called a causal state set orcause set . The technique
makes use of a generalized binary search to enumerate and
test diﬀerent subsets until it identiﬁes the minimal cause set.
Sumner et al. recently combined delta debugging with more
precise execution alignment techniques [8], [12] to improv e
its robustness, precision, and e ﬃciency. By applying CSM
inductively, a causal chain or summary of a failure can be
computed, comprising a sequence of the minimal causal state
sets computed for a sequence of execution points leading fro m
the root cause to the failure [8], [13].
Example. Consider the simple program presented in Fig. 1.
This program reads three integers, re-deﬁnes one of them, an d
then prints it. In the execution of (b), the user inputs 1, 1,
3 and the program prints 2. In contrast, in the execution (c),
the user inputs 0, 2, 6 and the program prints 3. Suppose that
execution (c) is buggy. Given the buggy output 3 on line 7,
called the eﬀect point , we apply CSM to determine what state
on line 4, called the cause point , actually caused the buggy
output. The cause and e ﬀect points are respectively marked in
the ﬁgure as empty and ﬁlled diamonds in (d).
Note, here the term “ buggy ” is a generalized notion as there
is not a faulty statement per se. Any behavioral diﬀerence
between the executions may be considered buggy and we are
interested in what caused these di ﬀerences. The discussion and
the technique are universally applicable for cases where tr ue
faults cause the behavioral di ﬀerences.
CSM repeatedly replays execution (b) up to line 4. Each
time, it then replaces a subset of state with state from execu tion
(c) to identify a subset su ﬃcient to produce y/mapsto→3 within execu-
tion (b). For instance, replacing (on line 4) the variable /value
mappings y/mapsto→1 and z/mapsto→3 in execution (b) with y/mapsto→2 and z/mapsto→6
from execution (c) yields y/mapsto→3 on line 7. Thus, the process
identiﬁes that the values of yand zare buggy on line 4 in
execution (c), leading to the buggy output. Fig. 1d presents
the causal state set on line 4 along with relevant program
dependences for comprehension. The computation continues
in order to determine whether a smaller causal set can be
identiﬁed. If not, the identiﬁed minimal set will be reporte d.
If we desire a summary of the failure, the current causepoint becomes the new e ﬀect point and the identiﬁed causal
state set becomes the new target buggy state. The algorithm
then continues to compute the causal state set for a precedin g
new cause point, until no such sets can be computed [8].
Limitations. Delta debugging [7], [11] and its recent im-
provements [8], [13] all use CSM. While prior research
demonstrated the e ﬀectiveness of these techniques, we ﬁnd
that inherent limitations of CSM often lead to low quality
failure summaries. Next, we discuss these limitations in de tail
and motivate the need for a new causal inference engine.
Confounding caused by partial state replacement: The
ﬁrst problem with CSM is that replacing only a subset of
the state in an execution can induce new behavior that was
not present in either of the original executions . We call this
problem the confounding of partial state replacement . The
introduced new behavior can a ﬀect the validity of a causality
test. Particularly, a causal chain may terminate premature ly
because key buggy state is excluded due to confounding, or it
may contain additional state that does not pertain to the fai lure.
In the worst case, the entire chain may not even be relevant
for explaining the failure. From our experiments, 11 of the 1 5
real bugs suﬀered from this problem.
For example, consider the program presented in Fig. 1. Pre-
viously, we showed that CSM can determine that {y/mapsto→2,z/mapsto→6}
is the causal state set on line 4. Suppose CSM further conside rs
a smaller subset {y/mapsto→2}. When replacing the value of yin
execution (b) with that from (c), the condition of the if
statement becomes True. This redeﬁnes yon line 5, rendering
the target state y/mapsto→3 uninducible. Because of that condition,
CSM ﬁnds replacing the values of both yand znecessary.
However, zis unrelated to the original behavioral di ﬀerence.
The only contribution of zin both executions is its use on line
4, which had the value False inboth executions. Ideally, only
the deﬁnition of y/mapsto→2 should be blamed for the failure.
1x←input ()
2y←input ()
3ifx<3:
4y←y−3
5ifx>y:
6x←3
7print (x)
(a)x←5
y←3
ifFalse :
ifTrue :
x←3
print (3)
(b)x←1
y←9
ifTrue :
y←6
ifFalse :
print (1)
(c)1
2
3
4
5
7{x/mapsto→1}{x/mapsto→1}
(d)
Fig. 2: Missing causes by execution omission. (a) program. (b-c) exec utions
with diﬀering input. (d) CSM result.
Execution omission: The second problem is that CSM
may miss important causal state in the presence of execution
omission errors [14] , where the buggy target state is produced
because statements were not executed due to the bug. In such
cases, the computed failure summaries are usually incomple te.
The root cause of the problem is that CSM is asymmetric ,
meaning the buggy and correct executions have asymmetric
roles in the process: CSM reasoning is based on modifying
state only in the correct execution; its ﬁnal results only in clude
information from the buggy execution.
Fig. 2 presents an example. The correct execution in (b)
follows the False branch of line 3, then the True branch of line2735, and prints 3, whereas the “buggy” execution in (c) follows
theTrue branch of line 3, then the False branch of line 5, and
prints 1. Suppose that initially the e ﬀect point is line 7 and
the cause point is line 5. CSM determines that replacing the
value of xis suﬃcient to induce the buggy target state in (b),
so it identiﬁes x/mapsto→1 as the only buggy state at the cause point.
However, the buggy output x/mapsto→1 on line 7 in (c) is due to the
undesirable omission of line 6, which is partially determin ed
by the buggy state of y/mapsto→6. Missing y/mapsto→6 in the cause set leads
to an incomplete summary of the failure.
Suppose the computation continues backward with a new
eﬀect point on line 5 and new cause point on line 3. CSM
determines that replacing the value of xon line 3 is suﬃcient
to induce the buggy target state x/mapsto→1 on line 5. Fig. 2d shows
the result of this analysis. This implies x/mapsto→1 is the sole root
cause of the bug. However, replacing the value of xon line
3 in (b) cannot induce the ﬁnal failure although it can induce
x/mapsto→1 on line 5, because line 3 evaluates to True in the patched
execution. Hence, line 4 produces y/mapsto→0 and leads to to x/mapsto→3.
In our experiments, 5 of the 15 real bugs face this problem.
Eﬃciency: CSM may demand a large number of reexecu-
tions. The number of state di ﬀerences can be as large as the
size of the allocated memory [8]. The number of possible
subsets that need to be tested for causality is potentially
combinatorial in terms of the full set. To combat this, exist ing
approaches use delta debugging [7] to perform a generalized
binary search over the subsets. However, the number of
reexecutions can still be quadratic in the size of all used
memory. Even the most recent implementation of CSM [8]
may take a few hours to reason about a failure while the
original execution time is just a few milliseconds.
III. Comparative Causality
In this paper, we propose a more e ﬀective and precise
causal inference model called comparative causality (CC).
This model focuses on symmetrically reasoning about two
executions, one buggy and one correct1, in order to explain
why they both diﬀer from eachother. It also enables e ﬃcient
and practical implementation. In the following, we ﬁrst deﬁ ne
a number of notations and concepts. Then we study the
intended properties of the new model. Here we assume we
can properly align the control ﬂow and the variables /memory
regions of the two executions for ﬁne-grained comparison
using existing work [8], [12].
•Execution point: We use a superscripted label leto denote a
point in execution e. Symbol l(e1,e2)denotes a point that appears
in both executions e1and e2, determined by the given control
ﬂow alignment [12]. It is also called an aligned point .
•State diﬀerence: we use{x/mapsto→(v1,v2)}to denote that a variable x
has value v1ine1and value v2ine2, with v1/nequalv2.
Problem Statement: Given a set of state di ﬀerences∆at an
aligned execution point l(e1,e2)
/Diamondsolidand a preceding aligned point
l(e1,e2)
/Diamond , we want to ﬁnd a set of state di ﬀerences at l(e1,e2)
/Diamond that
isrelevant ,suﬃcient , and minimal for inducing∆.
1How to acquire a correct execution given only the buggy execu tion can
be found in a survey [15].The preceding execution point is the cause point and the
latter one the eﬀectpoint. We demand aligned points because
state comparison is not meaningful at non-aligned points. A n
inducing state diﬀerence in the cause point is called a cause ;
a state diﬀerence in∆is called an eﬀect.
A. Property One: Relevance
The causes identiﬁed by CC must be relevant to the target
eﬀects. Intuitively, a di ﬀerence dis relevant to a later dif-
ference dsifdsis (transitively) produced from dthrough a
sequence of diﬀerences. It represents the notion that “buggy
state must be derived from preceding buggy state (except at
the root cause)”.
Consider the example presented in Fig. 1. The state di ﬀer-
ence{z/mapsto→(3,6)}on line 3 is not relevant to {y/mapsto→(2,3)}on line
7 even though there is a dynamic dependence path from line
3 to line 7, because the di ﬀerence of zis neutralized on line
4, which yields False in both runs. In contrast, The di ﬀerence
{y/mapsto→(1,2)}on line 2 is relevant to {y/mapsto→(2,3)}on line 7.
The formal deﬁnition is as follows:
Deﬁnition 1 (Relevance): A state diﬀerenceδ/Diamondatl(e1,e2)
/Diamond isrelevant
to a target state di ﬀerenceδ/Diamondsolidat a later eﬀect point l(e1,e2)
/Diamondsolid if either
of the following conditions is satisﬁed.
1) There exists a dynamic program dependence path from δ/Diamondsolidtoδ/Diamond
ine1(e2) where all the statement computations along the path
yield diﬀerent results from the other execution e2(e1).
2) There exists a state di ﬀerenceδxin an aligned point in between
l(e1,e2)
/Diamond andl(e1,e2)
/Diamondsolid such thatδ/Diamondis relevant toδxandδxis relevant
toδ/Diamondsolid.
Condition (1) expresses the requirement that a di ﬀerence
cannot be neutralized within an execution in order to be rele -
vant. Note that it is symmetric to both executions as relevan ce
can be determined by a dependence path in either execution.
It allows us to precisely capture relevance in the presence
of execution omission. Consider the example in Fig. 2, state
diﬀerence{y/mapsto→(3,6)}on line 5 is relevant to {x/mapsto→(3,1)}on
line 7, due to the dependence path y@5←True @5←6←7
in (Fig. 2b). Observe that there is no dependence between
y@5 and x@7 in the failing execution (Fig. 2c) due to
the omission of line 6. The intuition is that omission is
an asymmetric concept regarding one execution. An omitted
statement regarding one execution implies that it appears i n the
opposing execution. With our symmetric deﬁnition, omissio ns
are conceptually precluded.
Condition (2) expresses that relevance can be transitive,
even across the two executions.
B. Property Two: Su ﬃciency
The identiﬁed set of causes must su ﬃciently induce the
target eﬀect of each of the two executions within its opposing
execution. This inducement acts as a new causality test and
witnesses the causal relationship between the identiﬁed ca uses
and the target state.
The property is symmetric as it requires the set of e ﬀects
in either execution to be induced by the causes. It means that
if for all the variables in the cause set, we copy their values
from execution e1toe2, we can induce the target e ﬀect of e1
at the eﬀect point in e2,and vice versa .274Consider the example in Fig. 2. State di ﬀerences{y/mapsto→(3,6),
x/mapsto→(5,1)}on line 5 form a su ﬃcient set regarding the e ﬀect
{x/mapsto→(3,1)}on line 7. In contrast, the di ﬀerence{x/mapsto→(5,1)}itself
is insuﬃcient because although replacing x’s value 5 with 1 in
(b) can induce the e ﬀect{x/mapsto→1}on line 7, replacing x’s value
1 with 5 in (c) cannot induce the e ﬀect{x/mapsto→3}. This symmetry
ensures that we capture relevance due to execution omission .
More formally,
Deﬁnition 2 (Suﬃciency): A cause set∆/Diamondatl(e1,e2)
/Diamond issuﬃcient for
a given target eﬀect set∆/Diamondsolidat a later eﬀect point l(e1,e2)
/Diamondsolid if and only
if, in the absence of confounding, copying the state of e2in∆/Diamondto
e1at the cause point induces the e ﬀect of e2in∆/Diamondsolidin execution e1
at the eﬀect point, and vice versa.
One key condition is that reexecution should be
confounding-free. Unfortunately, normal program executi on
cannot guarantee this. The remainder of this subsection foc uses
on discussing confounding.
What is confounding? Determining suﬃciency involves re-
placing part of the state in one execution with values from th e
opposing execution. However, the continuation of the modiﬁ ed
execution has state from both original executions entangle d,
aﬀecting each other and inducing undesirable and unexpected
results in causal inference.
Recall in Fig. 1, we saw that partially changing the state of
execution (b) with the single desired cause variable yyielded
output diﬀerent than in either execution (b) or (c). In addition,
we found that including zas a cause along with ywould yield
the target state, although zis not relevant to the output. Both
of these are unexpected results that we call confounding from
partial state replacement . These confounding e ﬀects do not
just have the ability to include arbitrary state within the set
of identiﬁed causes, they can exclude arbitrary state, as well.
Examples are omitted due to the space limitations.
At a high level, these unexpected results occur because
partial state replacement created new behaviors that did not
exist in either of the original executions .
Deﬁnition 3 (Confounding): Given executions e1ande2as well as
a patched execution epconstructed from them, a causality test using
episconfounded if either of the following conditions are satisﬁed:
1) An execution point in epis not present in e1ore2.
2) A data dependence in epis not exercised in e1ore2
Condition (1) corresponds to control ﬂow confounding and
(2) to data ﬂow confounding , which means confounding can
occur without exhibiting any new control ﬂow.
1x←[0, 1, 2, 3]
2y←input ()
3z←input ()
4x[z]←5
5print (x[y])x←...
y←1
z←2
x[2]←5
print (1)x←...
y←2
z←3
x[3]←5
print (2)1
2
3
4
5{y/mapsto→(1,2),
z/mapsto→(2,3)}
(a) (b) (c) (d)
Fig. 3: Data ﬂow confounding example. (a) program. (b-c) executions w ith
diﬀering input. (d) confounded explanation.
Consider the example in Fig. 3. This time, the target state
is{x[y]/mapsto→(1,2)}with cause and eﬀect points at lines 4 and 5
respectively. Observe that in each execution, the read from and
written to elements of xare diﬀerent. Thus, the only identiﬁedcause for the diﬀerent output should be the di ﬀering values of
y, which provides the index read from the list. However, when
only the value of yis replaced on line 4 in (b), the patched
execution reads the new value written to the list on line 4.
Thus, the target state is not induced. Observe that in this ca se,
a new data dependence from line 5 to line 4 is exercised.
In later sections, we will examine new execution models
that can avoid/mitigate confounding.
We argue that the two properties, together with the minimali ty
requirement, are essential for understanding execution di ﬀer-
ences. They precisely express the programmer’s intentions .
IV . Realizing Comparative Causal Inference
In this section, we discuss the realization of CC. Given a
target eﬀect set and a cause point, we leverage a technique
called dual slicing to compute a set of candidate causes and
only apply causality testing on the candidate set. Dual slic ing
is a symmetric slicing technique that works on two execution s.
It ﬁrst determines control ﬂow and value di ﬀerences in the
two executions through trace comparison and then performs
slicing on these di ﬀerences (in and across both executions).
The beneﬁts of using dual slicing are twofold. First, it en-
sures relevance of the candidates. Second, it is more e ﬃcient
because causality testing only needs to enumerate subsets o f
the candidates instead of the full set of state di ﬀerences as in
CSM [7], [8].
After acquiring the dual slice, we then symmetrically min-
imize the causes included in the slice to a minimal subset
suﬃcient for inducing the target state within both executions.
During the minimization process, one key step is to perform
causality testing by state replacement. In order to avoid
confounding, we devise an execution model that harnesses a
patched execution in such a way that it respects the control
ﬂow and dependences in the two original executions while
allowing ﬂexibility for reasoning about the e ﬀects of state
replacement.
A. Background: Dual Slicing
Dual slicing was ﬁrst introduced to study concurrency
bugs [9] and software vulnerabilities [16].
Algorithm 1 Dual Slicing
dualSlice (l(e1,e2)
/Diamondsolid)
Input: l(e1,e2)
/Diamondsolid- the slicing criterion
Output:D- the dual slice, a set of deps in either execution
1:ife1/nequal⊥then
2: for each data dep dd← { l(e1,e2)
/Diamondsolidx− −→
e1l(e1,e′
2)
/Diamond}do
3: ife′
2≡⊥ orxhas diﬀerent values on l/Diamondthen
4:D ← D∪ dd∪dualSlice (l(e1,e′
2)
/Diamond )
5: control dep cd← { l(e1,e2)
/Diamondsolid= =⇒
e1l(e1,e′
2)
/Diamond}
6: ife′
2≡⊥ orl/Diamondhas diﬀerent branch outcomes then
7:D ← D∪ cd∪dualSlice (l(e1,e′
2)
/Diamond )
8:ife2/nequal⊥then
9:/* operations symmetric to when e1/nequal⊥*/
10:returnD275Algorithm 1 presents the basic dual slicing algorithm. Al-
though it is not part of this paper’s contributions, we prese nt
a simpliﬁed version of the algorithm for completeness.
Given a slicing criterion, an execution point that exhibits
a state diﬀerence, the algorithm returns its dual slice, a set
of dynamic dependences from both executions denoting the
causality of the di ﬀerence. Lines 1-7 describe the process
of slicing in execution e1. It ﬁrst ensures that the current
criterion l/Diamondsolidis present in e1(line 1). Here, l(⊥,e2)
/Diamondsoliddenotes that
l/Diamondsolidis not present in e1. Lines 2-4 traverse each dynamic data
dependence edge of the criterion in e1with x, the variable
involved, denoted as l(e1,e2)
/Diamondsolidx− −→
e1l(e1,e′
2)
/Diamond . We use variable e′
2to
show that l/Diamondmay or may not be in the second execution,
disregarding the value of e2. On lines 3-4, if l/Diamondis exclusively
ine1(i.e, e′
2≡⊥) and thus is a control ﬂow di ﬀerence, or
even if it is not exclusive but variable xhas diﬀerent values in
the two executions, the data dependence is added to the slice .
The dual slice of l/Diamondis recursively computed and added to the
slice too (line 4). Thus, when l/Diamondis present in both executions
and produces the same value, it is not added because it cannot
induce the criterion. In lines 5-7, the algorithm traverses the
control dependence edge in e1, denoted as “= =⇒
e1”. Similarly,
if the guarding predicate is exclusive or has di ﬀerent branch
outcomes, the edge gets added and the dual slice of the
predicate is recursively computed. Lines 8-9 are symmetric
to lines 1-7, describing the process of slicing in execution e2.
1t←input ()
2x←input ()
3y←input ()
4z←input ()
5ifx + y + z>3:
6z←−10
7ifx + y + z>0:
8z←5
9ifz<0andy>0:
10 z←t
11else:print (z)
(a)t←0
x←1
y←0
z←4
ifTrue :
z←−10
ifFalse :
if False :
print (-10)
(b)t←1
x←1
y←1
z←1
ifFalse :
ifTrue :
z←5
if False :
print (5)
(c)y←input ()
z←input ()
if1+y+z>3:
z←−10
if1+y+z>0:
z←5
print (z)
(d)
3
4
5
6
7
8
11✘ ✘✘ ✘
(e)4
5
6
7
8
11{z/mapsto→(4,1)}
{z/mapsto→(-10,1)}
{z/mapsto→(-10,5)}
(f)
Fig. 4: (a) program. (b-c) two runs. (d) program from the dual slice. ( e) dual
slice. (f) CC explanation.
Example. Consider the program in Fig. 4a. The dual slice
of the two executions, (b) and (c), is presented in Fig. 4e
(including the crossed-out dependences). Part of the compu -
tation is represented as follows. We use dS() as a shorthand
fordualSlice() . The superscripts of execution points are elided
for brevity when explicit from the context. The box in a step
denotes that the next step is to execute the recursive call in side.dS(11(b,c))={11z− −→
b6}∪dS(6(b,⊥))∪{11z− −→
c8}∪dS(8(⊥,c)) [1]
={11z− −→
b6,6= =⇒
b5}∪dS(5(b,c))∪{11z− −→
c8}... [2]
={11z− −→
b6,6= =⇒
b5,5z− −→
b4,5z− −→
c4,...}... [3]
At step [1], the control dependence to line 9 is not involved
as it has the same branch outcome in the two runs. Also, dual
slicing line 6 of execution (b) in step [1] entails slicing li ne
5 in both executions (step [2]). Line 1 is not included, even
though it denotes a di ﬀerence, as it is not reachable from the
criterion. The dual slice captures the behavioral di ﬀerences
of the two executions related to the criterion.
B. Dual Slices Are Relevant but Not Ideal
Dual slices are represented in terms of dependences,
whereas causal inference is conducted on program state.
Hence, we ﬁrst introduce a projection from a dual slice to
the corresponding set of state di ﬀerences at a given execution
point so that we can discuss the properties of dual slicing
in our context. These properties are unique to the proposed
technique and have not been studied before.
Given a dual slice and a cause point l(e1,e2), which is an
aligned point, we deﬁne the cut of the dual slice with respect
to the point as follows.
C(D,l(e1,e2))={x/mapsto→(v1,v2)|let
/Diamondsolidx− −→
etlet
/Diamond∈D,
with l/Diamond≺etl≺etl/Diamondsolidorl/Diamondsolid≡l,
andx/mapsto→(v1,v2) on lwith v1/nequalv2}
It denotes the set of state di ﬀerences involved in the dual
slice on the given cause point. It essentially denotes the se t
of variables when we cut the dual slice on the cause point.
Symbol la≺etlbdenotes laprecedes lbin execution et.
Consider the dual slice in Fig. 4e. The cut on line 7 is
the following.C(D,7(b,c))={z/mapsto→(-10,1), y/mapsto→(0,1)}. Note that
{t/mapsto→(0,1)}is not in the cut.
Theorem 1: All the causes in a cut C(D,l(e1,e2)) are relevant to
the slicing criterion. All relevant causes on l(e1,e2)) are included
in its cut.
The proof is omitted due to space limitations. The property
suggests that dual slices cover all the causes the programme r
needs to inspect.
Unfortunately, a dual slice cut may not su ﬃciently induce
the slicing criterion given the confounding-prone regular ex-
ecution model. That is, replacing the state of all causes in a
cut may not induce the failure. Let us revisit the example in
Fig. 1. The dual slice is shown in Fig. 1e. Its cut on line 4 has
only y. However, from the discussion in Section II, we know
that replacing y/mapsto→1 with y/mapsto→2 in execution (b) does not lead
to the target eﬀect due to the confounding from z.
A cut may also not be minimal. It may contain causes that
are not essential for inducing the target e ﬀect. In Fig. 4e,
the cut on line 7 is {z/mapsto→(-10,1), y/mapsto→(0,1)}, but the minimal
suﬃcient set is just{z/mapsto→(-10,1)}.
These limitations motivate us to realize the proposed CC by
performing confounding-free minimization on dual slices.276C. The Basic Algorithm
In this subsection, we introduce the basic minimization
algorithm, assuming a confounding-free execution model. W e
will discuss the execution model in the next subsection.
Algorithm 2 Minimizing Causes
inferCauses (D,l(e1,e2)
/Diamond ,l(e1,e2)
/Diamondsolid,∆/Diamondsolid)
Input:D- the dual slice l/Diamond- the cause point
l/Diamondsolid- the eﬀect point∆/Diamondsolid- the target state
Output: causes of target at l/Diamond
1:∆← C (D,l/Diamond)
2:∆min←∆
3:for each s⊂∆by delta debugging do
4: if|s|<|∆min|
∧Ee1[s↓e2/s↓e1]l/Diamond
l/Diamondsolid/leadsto∆/Diamondsolid↓e2
∧Ee2[s↓e1/s↓e2]l/Diamond
l/Diamondsolid/leadsto∆/Diamondsolid↓e1then
5:∆min←s
6:return∆min
Algorithm 2 presents the basic approach. Given a precom-
puted dual slice, the cause and e ﬀect points, and the target
state, the algorithm returns a minimal set of causes su ﬃcient
to induce the target state. The algorithm starts by computin g
a dual slice cut at the cause point, which is essentially the
set of relevant causes. Lines 3-6 minimize the set to only
those suﬃcient for inducing the observed target state of
each execution in the other. We leverage the delta debugging
algorithm to enumerate subsets of the relevant causes and te st
their causality. Symbol Ee1[s↓e2/s↓e1]l/Diamond
l/Diamondsolidmeans executing e1
up to the cause point l/Diamond, replacing its variable /value mappings
inswith those from e2, and continuing the execution up to
the eﬀect point l/Diamondsolid. Symbol s↓e1denotes the projection of state
diﬀerences son execution e1. If the variables in the target state
have the values from e2, we say that the target state of e2was
induced, written /leadsto∆/Diamondsolid↓e2.
Note, in contrast to existing CSM approaches [7], [13],
our minimization algorithm performs two symmetric causality
checks. This is necessary to include causes via omission.
D. Confounding Free Execution Model
Recall that confounding occurs when new control ﬂow or
data dependences not in either original execution occur in
a patched execution. By Theorem 1, we know that all the
relevant causes are included by the dual slice. This suggest s
we only need to perform causality testing within the dual slice.
Conceptually, the essence of our new execution model is
to construct a program containing only the behavior of the
dual slice and all reexecutions for causality testing occur on
the constructed program. Statement executions not in the du al
slice should be prevented in order to minimize confounding.
Illustrative Example. Consider the example in Fig. 4. Assume
we start by using the target state {z/mapsto→(-10,5)}at line 11.
Assume the cause point is line 7 and we apply Algorithm 2
to minimize the causes at this point. The cut of the dual
slice (Fig. 4e) involves variables yand z. When we consider
variable zwith a regular execution model, we reexecute (c)
up to the cause point and replace the value of zwith -10. It
induces the false branch outcome on line 7 but the true branch1) When lis not a conditional with l/nelementD, skips l.
2) When lis a conditional and it was in both executions with
branch (Te1,l)≡branch (Te2,l), unconditionally continue with
the same branch as in the original executions.
3) When lis a conditional and it was in both executions with
branch (Te1,l)/nequalbranch (Te2,l) or lis in only one execution,
evaluate the statement according to Rule 4) and follow the
computed branch.
4) When lis not a conditional with l∈D, validate that all the
operands involved in some data dependence in Dhave the same
data dependence as they did in the original executions, otherwise
terminate and report confounding; For any operand not in any
dependences inD, denoted as x, set its value to val(Tex,l,x),
and continue.
Fig. 5: Semantics ofE[].
outcome on line 9, which is di ﬀerent than execution (b). Hence,
{z/mapsto→(-10,1)}is not considered a valid cause set.
With our new execution model, conceptually, we construct
a program representing the dual slice, as in Fig. 4d, in which
lines 1, 2, 9, and 10 are precluded as they are not in the slice.
Also, line 11 is no longer guarded by any predicate. Operands
that are in the slice and have identical values in both execut ions
are concretized (e.g. xon lines 5 and 7).
Again, let us determine the causality of variable zon line 7.
We reexecute (c) up to the cause point using the original
program. We replace the value of zwith -10, then continue
execution with the program in Fig. 4d . Since lines 9 and
10 are not in the program, we avoid confounding and can
induce the desired target state. Hence {z/mapsto→(-10,1)}}is the
minimal inducing cause set. Observe that it allows us to prun e
the relevant but not necessary cause {y/mapsto→(0,1)}}. Applying
Algorithm 2 transitively, we acquire a more concise failure
explanation as shown in Fig. 4f. /Box
Semantics of the New Execution Model. In the following, we
discuss the semantics that allows achieving the e ﬀect of exe-
cuting exclusively within the dual slice without construct ing a
new program. During minimization, we ﬁrst reexecute the
original program with normal semantics up to the cause
point and then continue executing the program with the new
semantics after state replacement until the e ﬀect point.
In the semantics, we assume the runtime availability of the
dual sliceDand the traces of the original two executions,
denoted byTe1/2. Without losing generality, we assume we
are patching e1using information from e2. The value of a
variable xat a point le1in the original execution e1can be
queried from the trace by val(Te1,l,x). If an execution point
le1is a conditional statement, branch (Te1,l) queries its branch
outcome in execution e1. The semantics is presented in Fig. 5.
Statement executions not in the dual slice are skipped when
they are not conditional statements (Rule 1). When executing
conditional statements, we cannot simply skip as we need to
select a branch to proceed. Rules 2-3 specify the cases for
conditional statements.
In Rule 3, if a conditional had di ﬀerent branch outcomes
originally or was present in only one execution, the semanti cs
evaluates the predicate and follows the computed branch. Th e
essence is to allow the ﬂexibility to take either branch base d on
the predicate evaluation in order to reason about the e ﬀect of2771) Rule 2 from Fig. 5.
2) When lis a conditional and it was in both executions with
branch (Te1,l)/nequalbranch (Te2,l), evaluate the statement normally
and follow the computed branch.
3) When lis a conditional and it was in only one execution ex,
follow the branch that was taken in ex.
4) Otherwise, evaluate las in a regular execution model.
Fig. 6: Semantics of the Approximate Execution Model.
state replacement when it is in the dual slice. If the stateme nt
is not in the dual slice, it does not matter which branch is tak en
because all non-conditional statements inside the branche s
must be skipped according to Rule 1. These statements must
not be in the dual slice; otherwise, the conditional would ha ve
been in the slice according to the dual slicing algorithm.
Rule 4 handles non-conditional statement execution in the
dual slice, for all the operands not involved in any dependen ces
in the slice, implying that they must have identical values
in the two executions, we concretize them with values from
the traces to achieve isolation. For operands involved in so me
dependence, we ensure no data ﬂow confounding.
This new model will not allow any confounded executions
to go through, as can be inferred from the semantic rules.
Theorem 2: A dual slice cut is su ﬃcient within the new execution
model.
This theorem ensures that Algorithm 2 must be able to ﬁnd
a minimal suﬃcient set of causes inducing the target state be-
cause in the worst case, the cut is the minimal set. Informall y,
the theorem holds because reexecution is exclusively withi n
the dual slice and hence replacing all the state in a cut leads to
a reexecution equivalent to the part of the dual slice belong ing
to the opposing execution, and hence the target state.
A Practical Approximation. Unfortunately, the semantics in
Fig. 5 demands a prohibitively expensive implementation. I t
requires collecting traces with dependences and values. Th e
traces and the dual slice have to be accessed during each
reexecution. Each statement has to be instrumented to decid e
if it is in the dual slice (Rule 1) or perform complex control
(Rules 2-4). The overhead could easily be many orders of
magnitude, not aﬀordable for repeated reexecutions.
In practice, we observe that control ﬂow confounding is the
dominant confounding factor and data ﬂow confounding can
only aﬀect the execution by causing control ﬂow confounding
in most cases. We hence propose a practical approximation th at
can completely prevent control ﬂow confounding and mitigat e
data ﬂow confounding. The approximate model ensures a
patched execution can only follow dynamic branches taken
by at least one of the original executions. Consequently, it en-
forces a control ﬂow path composed of segments that occurred
in either execution. What we do here is essentially construct ing
guard rails for the execution so that it can never deviate fro m
the dual slice’s control ﬂow. Since data dependences heavil y
depend on control ﬂow, the approximation can also mitigate
data ﬂow confounding. The semantics is presented in Fig. 6.
Observe that the semantics does not require the runtime
of the dual slice or dependence /value traces for runtime
checking, but rather just the control ﬂow trace. This can be
very eﬃciently represented and accessed by using bit streamsthat simply record the sequence of boolean branch outcomes.
It does not skip statements. It hence avoids instrumenting a ll
statements to decide if one can be skipped at runtime.
Theorem 3: The approximate execution model is free of control
ﬂow confounding.
The theorem can be inferred from the semantic rules. We
implemented the approximate semantics and in practice it wa s
able to suppress all confounding in our experience.
V . Evaluation
We implemented our technique using LLVM 3.0. We have
also implemented the CSM and dual slicing approaches [7]–
[9], [13] for comparison. Both implementations reﬂect the
latest published designs [8], [9]. The evaluation is in the
context of automated debugging. The techniques contrast
buggy and correct executions, using explanations for their
diﬀerent behavior as explanations of bugs. First, we compute
explanations for a set of real world bugs by chaining togethe r
the computed causes. We contrast the explanations computed
by the three diﬀerent techniques. Second, we examine in depth
how the problems that CSM faces a ﬀect its results in practice.
We used real world bugs taken from the repositories of
open source programs. They include all deterministic bugs
fromtar,grep , andmake in a one year period that we
were able to reproduce. All the bugs in our study were non-
crashing, semantic bugs that produce incorrect outputs. Ta ble I
presents the full set of programs and bugs. The ﬁrst three
columns identify the buggy program, bug ID, and the version
of the program that actually contains the bug. The SSLOC
column contains the static source lines of code computed
withsloccount . The Alt. column identiﬁes how a second,
correct execution was selected. We used a correct input when
the bug report also provided it, otherwise, we used predicat e
switching [17] to automatically synthesize a correct execu tion
from the failing one. More information on acquiring a correc t
execution from a given failing execution resides in Sumner’ s
survey paper [15]. We performed all experiments on a 64-bit
2.4GHz CPU with 12GB RAM using one core.
A. Full Explanation Comparison
Our ﬁrst experiment uses each of the three techniques to
compute an explanation for each bug. For each bug, we ﬁrst
identify the last observable failure and use that as the init ial
target state. CC and CSM select the last preceding deﬁnition
of a target eﬀect as the cause point to compute the causes.
They also proceed transitively, using the computed causes a s
the new target state and the current cause point as the new
eﬀect point until there are no more causes to identify (e.g. the
two executions have no state di ﬀerences).
We contrast the results of the di ﬀerent techniques through
their quality, scale, and e ﬃciency. We measure quality through
precision and recall with respect to a relevant, su ﬃcient, and
minimal explanation of why the correct and buggy executions
diﬀered. This is manually checked at each step of the computa-
tion. Precision (P) is the proportion of the dynamic stateme nts
in the computed explanation for a technique that coincide wi th278the statements in the correct explanation. Recall (R) is the pro-
portion of the dynamic statements in the correct explanatio n
that are also identiﬁed by the computed explanation. We have
to resort to manual inspection due to the lack of an automated
oracle to tell us the ideal explanations for execution di ﬀerences.
As we show later, such ideal explanations are small enough
for line by line human inspection.
We have done the following to mitigate threats to validity.
First, we cross referenced the computed explanations with
the root causes identiﬁed by the bug ﬁxes or reports. Second,
we calibrated our system using the Siemens suite before
our experiments. We computed the explanations for the over
10,000 failing runs in Siemens using the corresponding pass ing
executions of the provided correct versions and validated
that these explanations capture the injected faulty statem ents
as the root causes. The results are publicly available at
https://www.sites.google.com/site/explainedbugs/ .
Third, we also release the experimental results of the real
world bugs at the same site for interested readers.
We measure the scale of a technique by the number of dy-
namic statements (Stmts) in the computed explanation. Fina lly,
we measure eﬃciency in three ways: the number of steps or
rounds of causal inference, the clock time required in secon ds,
and the number of reexecutions needed. Note that the clock
time of CC includes dual slicing time. Table I shows the resul ts.
From these, we make several observations.
CC consistently yields the highest quality explanations.
Dual slicing generally has good recall but poor precision
because it doesn’t minimize. CSM is unpredictable because i t
can arbitrarily include or exclude causes, however, it freq uently
fails to identify causes for even a single step of an executio n.
We shall explore the unpredictability of CSM further in the
next section. In contrast, CC yields high precision and high
recall for every computed explanation. For the bugs, it capt ures
11 of 15 root causes whereas CSM fails to do so in 11 of 15
cases. Where CC failed to identify root causes, denoted by
-, it still explained why the two executions diﬀered, thus the
precision and recall. In those cases, the second execution w as
too diﬀerent to meaningfully explain the bugs as well.
The extra reexecutions for CSM make it slower than
CC, even when it computes fewer steps. On average, CSM
takes 13.8 minutes to compute an explanation, even though
it produces less of the correct explanation. In contrast, CC
takes 2.6 minutes on average because the extra dual slice inf or-
mation allows it to avoid considering all memory di ﬀerences
as potential causes. This reduces the number of necessary
reexecutions by up to two orders of magnitude.
CC produces more concise explanations than dual slicing.
The precision numbers show that CC is more precise than dual
slicing, 1.0 vs 0.14. On average, CC produces explanations
of 35 dynamic statements, while dual slicing produces 330
statements.
This experiment illustrates that CC produces superior expl a-
nations in terms of quality, e ﬃciency, and scale.B. Why and how CSM fails
A single incorrect cause at any point of the full chain
computation can cascade through the rest of the computation ,
causing more incorrect causes. It is hence di ﬃcult to determine
the reasons behind the incorrectness by simply looking at th e
full chains. Our second experiment examines why and how
CSM missed or erroneously included causes on a per-step
basis. Note that CC does not encounter these problems for the
given benchmarks, and dual slicing does not do minimization .
Thus, we focus only on CSM for this experiment.
We ﬁrst computed the causes for each step using CSM as
in the ﬁrst experiment. For each step, we also supply the
same (CSM) target state and the same cause point to CC and
compare the resulting causes from the two approaches. This
allows us to quickly observe any e ﬀects from confounding.
In this per-step fashion, we checked the results of CSM for
missing causes (M), extra causes (E), or failure to identify any
causes (F). These are the ways that the technique can fail. We
also checked why these failures occurred, including control
ﬂow confounding (CFC), data ﬂow confounding (DFC), and
execution omission (O). Table II contains these results.
CSM suﬀers from all three problems. It misses causes
in almost all benchmarks (12 out of 15), has extra causes in
8 out of 15, and fails to produce any causes for a step in 6
out of 15 cases. These failures resulted both from omission
and from confounding, although confounding was the more
frequent cause.
Control ﬂow confounding causes errors in most of the
CSM explanations. In 11 out of 15 cases, the CSM explana-
tions are directly impacted by control ﬂow confounding. Thi s
shows that control ﬂow confounding is a real world challenge
that we must address.
Data ﬂow confounding does not directly impact CSM.
While close inspection indicates that some data ﬂow confound -
ing occurs, it impacts the executions only through control ﬂ ow
confounding. As CC prevents control ﬂow confounding, the
impact of the corresponding data ﬂow confounding is also
suppressed. For example, data ﬂow confounding may lead to
an incorrect branch, but CC forces the execution back to the
correct branch through its execution model.
Together, these ﬁne grained comparisons allow us to see
that omission and confounding do indeed impact existing
techniques. Furthermore, taken with the results in Table I t hey
show that CC is resilient when faced with them.
C. Example of Resulting Explanations
Next, we demonstrate a failure explanation generated by
CC and explain how CSM fails to compute that explanation.
This chain is for bug 13. Version 1.22.90 of tar has a bug
when using the--backup option. When extracting ﬁles from
an archive, this option copies any already existing ﬁles int o a
backup directory, preventing these ﬁles from being overwri tten.
When extracting a directory that already exists, however, it
appears to incorrectly prevent ﬁles from being extracted.
We used predicate switching to dynamically patch the buggy
execution and derive a correctly behaving execution. Both t he
buggy and the switched executions ﬁrst extract some ﬁles279TABLE I: Comparison of full explanations. Averages are arithmetic exc ept for P & R, which are geometric. - means that the root cause cou ld not be captured.
Program IDVersion SSLOC Alt.CC CSM Dual Slicing
Steps Time Tests Stmts PRRoots Steps Time Tests Stmts P RRoots Stmts P R
ﬁnd 14.5.7 73k switch 7 12 15 61.01.0 X 1 253 1260 0 0 0 - 185 0.03 1.0
gnuplot 24.5.0 144k switch 11 44 33 10 1.01.0 X 11 141 469 10 1.0 1.0 X 148 0.06 1.0
gnuplot 34.4.0 139k input 35 200 323 48 1.01.0 X 1 51 208 0 0 0 - 464 0.07 1.0
gnuplot 44.2.4 134k input 146 961 337 129 1.01.0 - 127 950 1888 121 0.97 0.91 - 368 0.33 1.0
gnuplot 54.2.4 134k switch 24 140 130 33 1.01.0 - 31 931 3012 38 0.87 1.0 - 237 0.14 1.0
grep 62.5.4 12k switch 59 114 186 62 1.01.0 - 24 8263 1012 23 0.96 0.35 - 153 0.51 1.0
grep 72.5.4 12k switch 45 156 327 69 1.01.0 - 33 183 1734 32 1.0 0.46 - 109 0.62 1.0
grep 82.5.4 12k switch 27 49 78 27 1.01.0 X 24 168 1546 23 0.96 0.81 - 95 0.26 1.0
make 93.81.90 30k switch 27 342 62 27 1.01.0 X 18 416 543 17 1.0 0.63 - 38 0.66 1.0
tar101.22.90 20k switch 5 22 8 31.01.0 X 5 50 221 3 1.0 1.0 X 3 1.0 1.0
tar111.22.90 24k input 30 124 125 48 1.01.0 X 1 110 332 0 0 0 - 61 0.79 1.0
tar121.22.90 20k input 9 53 121 20 1.01.0 X 1 66 296 0 0 0 - 1239 0.01 1.0
tar131.22.90 20k switch 11 43 28 10 1.01.0 X 6 439 2117 5 1.0 0.5 - 1270 0.01 1.0
tar14 1.23 21k input 17 80 87 23 1.01.0 X 5 165 709 15 0.73 0.48 X 25 0.92 1.0
tar15 1.23 21k switch 5 22 15 41.01.0 X 5 228 1283 4 1.0 1.0 X 557 0.01 1.0
Average 30.5 157.4 125 34.6 1.01.0 - 19.53 827.6 1108.7 19.7 0.22 0.26 - 330.1 0.14 1.0
TABLE II: CSM diﬃculties. This includes symptoms: (M)issing causes,
(E)xtra causes, and complete (F)ailure. It also lists reason s why: control and
data ﬂow confounding (CFC /DFC) or (O)mission.
ID M E F CFC DFC O
1 X - X X - -
2 - - - - - -
3 X X X X - -
4 X X - X - X
5 X X - X - -
6 X - X X - X
7 X - - - - X
8 X X - X - X
9 X X - X - X
10 - - - - - -
11 X X X X - -
12 X X - X - -
13 X - X X - -
14 X X X X - -
15 - - - - - -
before trying to extract a directory that already exists. Th e
switched execution renames the extracted directory so that it
does not conﬂict with the existing one, and it correctly extr acts
ﬁles to the new directory without error. However, the buggy
execution appears to have not extracted any ﬁles at all, even
the previously extracted ones.
Fig. 7 shows a simpliﬁed version of the relevant code, as
well as the explanation by CC, which is slightly shortened
for readability. First, predicate switching renames one of the
extracted directories from ”dir2” to”dir”. Next, a call to mkdir()
fails in the buggy execution, returning −1because ”dir2” already
exists. In contrast, the call succeeds in the switched execu tion
and returns 0. This diﬀerence ( 0vs.−1) gets propagated
through the variable status back into extract archive() , where it
makes the condition on line 18 True only in the failing execu-
tion, indicating an error when extracting ”dir2” . So the buggy
execution calls undo last backup() . This actually replaces all
of the extracted ﬁles with the original backups. As a result,
all of the ﬁles extracted before ”dir2” appear to never have
been extracted, even though they were. In fact, the original
bug reports for this failure assumed the ﬁles had not beenCode Summary
1int read header primitive():
2ﬁlename = ”dir” vs.”dir2”
3
4int extract dir(ﬁle name):
5tmp = mkdir(ﬁle name)
6...
7status = tmp
8ifstatus:
9 iferrno == EEXIST && IS DIR(ﬁle name):
10 pass
11 elif!maybe recoverable(ﬁlename):
12 mkdir error(ﬁle name);
13 return status
14
15void extract archive():
16 ...
17 status = extract dir(ﬁle name)
18 ifstatus && backup option:
19 undo last backup()
Explanation
At 2, ﬁle name is”dir” vs.”dir2” .
At 5, tmp is0vs.-1.
At 7, status is0vs.-1.
At 13, the return value is0vs.-1.
At 17, extract dir returns is0vs.-1.
At 18, (status && backup option) isFalse vs.True .
So”undo last backup()” iscalled, overwriting the extracted
ﬁles with the original ones.
Fig. 7: Example of a derived explanation using our technique
extracted, as well, but our generated explanation clearly s hows
that they were ﬁrst extracted and then incorrectly overwrit ten.
The root cause is that extract dir() should not fail even if
mkdir() fails due to the existence of the directory, because
extracting to an existing directory should not cause proble ms.
Atar developer can see this from the computed explanation
(on the bottom of Fig. 7) and know how to construct a ﬁx.
Indeed, the applied ﬁx set status to0on line 10.
Note, CSM cannot construct this explanation. On line 13,
confounding prevents further analysis of the bug. First, th e
condition on line 9 only executes in the failing execution,280where it is True. CSM replaces the value of tmp at line 7
to produce the failing status at line 13, but the condition on
line 9 evaluates to False this time because it also requires
a failing value for errno . Hence, CSM proceeds to line 12,
which reports an unrecoverable error and terminates. This
confounding prevents the identiﬁcation of tmp alone as the
cause. Additional confounding not shown here also prevents
replacing both errno and tmpfrom inducing the failing status .
D. Threats and Limitations
We have shown that CC is e ﬀective at explaining why two
executions are diﬀerent, but there are limits to the technique,
our evaluation, and what may be inferred from it.
We ﬁrst note that explaining why a buggy and correct
execution diﬀer does not always provide a useful explanation
of a bug, as observed in 27% of our generated explanations.
Also, manual examination of execution di ﬀerences risks
human error. Most of the explanations generated by CC are
short enough that we can be conﬁdent of our inspection.
Finally, again, comparative causality is presently limite d to
examining deterministic bugs. This inherently follows fro m
exploiting reexecution within the technique.
VI. Related Work
The most relevant work is causal state minimization (CSM)
that was originally introduced by Zeller [7], and subsequen tly
improved by others [8], [11], [13]. In contrast to CSM, our
SCC model avoids confounding, handles execution omission
by symmetric analysis, and is much more e ﬃcient.
Recently, R ¨oßler et al. also noted problems with Zeller’s
original approach, although they did not delve into what
these problems were [18]. They also produce a technique for
explaining bugs, but it is based on test generation and requi res
a strong oracle to evaluate each new test.
Traditional dynamic slicing [19] is a technique that captur es
dynamic data and control dependences. It has been extensive ly
examined for its usefulness in debugging [20]. Dynamic slic es
are usually problematically large and su ﬀer from execution
omission. Dual slicing is a kind of dynamic slicing techniqu e
thatcompares two executions and extracts the diﬀering depen-
dencies between the two [9], [16]. It forms the initial basis
of our technique. In contrast, our computed explanations ar e
much smaller due to state replacement and minimization.
Several satisﬁability based techniques also strive to prec isely
explain failures, either within a single program [21], [22] or
when comparing correct and incorrect versions [23], [24]. T he
present limitations in constraint solving, however, have t hus far
mostly limited these techniques to programs of a few thousan d
lines of code. In contrast, our technique explains failures in
programs with well over 100K lines.
Our technique requires that the executions of interest be
reproducible. Tools that aid failure reproduction, for ins tance,
can make this more feasible in practice [25],
VII. Conclusions
We presented a novel causal inference technique called
comparative causality. It allows precise and concise expla tions
for the diﬀerences between two executions at a very ﬁne
granularity. It advances the state of the art in three aspect s:it improves robustness of underlying state replacement tech-
niques by preventing confounding through novel execution
models; it handles execution omission errors by analyzing
two executions symmetrically; and it substantially improv es
eﬃciency by leveraging dual slicing. Evaluation on a set of rea l
world bugs shows that the proposed technique can generate
high quality explanations at low cost.
VIII. Acknowledgements
We would like to thank the anonymous reviewers for their
insightful comments. This research is supported in part by
the National Science Foundation (NSF) under grants 0917007 ,
0845870, and 1218993. Any opinions, ﬁndings, and conclu-
sions or recommendations in this paper are those of the autho rs
and do not necessarily reﬂect the views of NSF.
References
[1] I. Douven, “Abduction,” in The Stanford Encyclopedia of Philosophy ,
E. N. Zalta, Ed.
[2] J. Klein, “Francis bacon,” in The Stanford Encyclopedia of Philosophy ,
E. N. Zalta, Ed.
[3] P. Menzies, “Counterfactual theories of causation,” in The Stanford
Encyclopedia of Philosophy , E. N. Zalta, Ed.
[4] J. A. Jones, M. J. Harrold, and J. Stasko, “Visualization of test informa-
tion to assist fault localization,” in ICSE , 2002.
[5] G. K. Baah, A. Podgurski, and M. J. Harrold, “Mitigating t he confound-
ing eﬀects of program dependences for e ﬀective fault localization,” in
FSE, 2011.
[6] X. Zhang and R. Gupta, “Cost e ﬀective dynamic program slicing,” in
PLDI , 2004.
[7] A. Zeller, “Isolating cause-e ﬀect chains from computer programs,” in
FSE, 2002.
[8] W. N. Sumner and X. Zhang, “Memory indexing: canonicalizin g ad-
dresses across executions,” in FSE ’10 , 2010.
[9] D. Weeratunge, X. Zhang, W. N. Sumner, and S. Jagannathan, “Analyz-
ing concurrency bugs using dual slicing,” in ISSTA ’10 , 2010.
[10] A. Zeller and R. Hildebrandt, “Simplifying and isolatin g failure-inducing
input,” TSE, vol. 28, no. 2, pp. 183–200, 2002.
[11] H. Cleve and A. Zeller, “Locating causes of program fail ures,” in ICSE ,
2005.
[12] B. Xin, W. N. Sumner, and X. Zhang, “E ﬃcient program execution
indexing,” in PLDI , 2008.
[13] W. N. Sumner and X. Zhang, “Algorithms for automatically co mputing
the causal paths of failures,” in FASE , 2009.
[14] X. Zhang, S. Tallam, N. Gupta, and R. Gupta, “Towards loca ting
execution omission errors,” in PLDI , 2007, pp. 415–424.
[15] W. N. Sumner, T. Bao, and X. Zhang, “Selecting peers for ex ecution
comparison,” in ISSTA , 2011.
[16] N. M. Johnson, J. Caballero, K. Z. Chen, S. McCamant, P. Po osankam,
D. Reynaud, and D. Song, “Di ﬀerential slicing: Identifying causal
execution diﬀerences for security applications,” in IEEE S&P, 2011.
[17] X. Zhang, N. Gupta, and R. Gupta, “Locating faults throu gh automated
predicate switching,” in ICSE , 2006.
[18] J. Roessler, G. Fraser, A. Zeller, and A. Orso, “Isolati ng failure causes
through test case generation,” in ISSTA , 2012.
[19] B. Korel and J. Laski, “Dynamic program slicing,” Inf. Process. Lett. ,
vol. 29, no. 3, 1988.
[20] F. Tip, “A survey of program slicing techniques,” J. Prog. Lang. , vol. 3,
no. 3, 1995.
[21] M. Jose and R. Majumdar, “Cause clue clauses: error local ization using
maximum satisﬁability,” in PLDI , 2011.
[22] A. Groce, S. Chaki, D. Kroening, and O. Strichman, “Error explanation
with distance metrics,” STTT , vol. 8, no. 3, pp. 229–247, 2006.
[23] D. Qi, A. Roychoudhury, Z. Liang, and K. Vaswani, “Darwi n: an
approach for debugging evolving programs,” in FSE, 2009.
[24] A. Banerjee, A. Roychoudhury, J. A. Harlie, and Z. Liang , “Golden
implementation driven software debugging,” in FSE, 2010.
[25] S. Artzi, S. Kim, and M. D. Ernst, “Recrash: Making softwa re failures
reproducible by preserving object states,” in ECOOP , 2008.281