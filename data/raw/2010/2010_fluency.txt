Developer Fluency: AchievingTrue Mastery in Software
Projects
Minghui Zhou
School ofElectronics Engineering and Computer
Science,Peking University
Key Laboratory of HighConﬁdenceSoftware
Technologies, Ministry ofEducation
Beijing 100871, China
zhmh@sei.pku.edu.cnAudris Mockus
AvayaLabs Research
233MtAiry Rd,Basking Ridge,NJ
audris@avaya.com
ABSTRACT
Outsourcing and oﬀshoring lead to a rapid inﬂux of new de-
velopers in software projects. That, in turn, manifests in
lower productivity and project delays. To address this com-
mon problem we study how the developers become ﬂuent
in software projects. We found that developer productiv-
ity in terms of number of tasks per month increases with
project tenure and plateaus within a few months in three
small and medium projects and it takes up to 12 months
in a large project. When adjusted for the task diﬃculty,
developer productivity did not plateau but continued to in-
crease over the entire three year measurement interval. We
also discovered that tasks vary according to their impor-
tance(centrality) to a project. The increase in task cen-
trality along four dimensions: customer, system-wide, tea m,
and future impact was approximately linear over the en-
tire period. By studying developer ﬂuency we contribute
by determining dimensions along which developer expertise
is acquired, ﬁnding ways to measure them, and quantifying
the trajectories of developer learning.
Categories andSubject Descriptors
D.2.8 [Software Engineering ]: Metrics— process metrics ;
D.2.9 [Software Engineering ]: Management— productiv-
ity
General Terms
Measurement, Performance, Human Factors
Keywords
Developer ﬂuency, developer learning, productivity, task dif-
ﬁculty, task centrality
1. INTRODUCTION
Outsourcing and oﬀshoring are supposed to reduce prod-
uct costs because of lower development expenses in the oﬀ-
Permission to make digital or hard copies of all or part of thi s work for
personal or classroom use is granted without fee provided th at copies are
not made or distributed for proﬁt or commercial advantage an d that copies
bear this notice and thefull citation on the ﬁrstpage. Tocop y otherwise, to
republish, topostonserversortoredistribute tolists,re quires priorspeciﬁc
permission and/or afee.
FSE-18,November 7–11, 2010, Santa Fe,New Mexico, USA.
Copyright 2010 ACM 978-1-60558-791-2/10/11 ...$10.00.shore locations. Therefore, in such scenarios it makes eco-
nomicsense toreplace thedevelopersas fast aspossible. Bu t
a rapid inﬂux of new and less experienced developers tends
to introduce a number of problems. From the interviews
of development managers we heard complaints that the de-
velopers in oﬀshore locations were not able to cope with
the most complex tasks. Some managers argued that there
was no perceptible cost-saving from the oﬀshoring, or in one
manager’s words: having deliveries bounce back and forth be-
tween oﬀshoring development company and us . The results
of outsourcing appear similar to the outcomes in Brook’s
law: productivity drops and projects get delayed. Our mo-
tivation was provided by the following basic questions that
oﬀshoring or outsourcing software projects commonly ask:
•Do we have developers with suﬃcient skills to handle
all tasks in a project?
•How to adjust project schedule when facing an inﬂux
of new developers?
•How to use the experiences of the most productive de-
velopers to improve the training of new developers?
These questions highlighted several gaps in the research li t-
erature. In particular, the ﬂuency of developers in a soft-
ware project has not been studied. We deﬁne ﬂuency in
a software project as the ability to complete project tasks
rapidly and accurately independent of task diﬃculty or im-
portance. The concept of ﬂuency can be illustrated by a
recurring theme from our interviews that developers even
with a few years of project experience were not capable of
completing some of the project’s tasks. Paradoxically, the
same respondents considered developers to become produc-
tive after a few months of project experience. This sug-
gests that becoming ﬂuent is not perceived to be the same
as becoming productive. Because each project has tasks of
varying types and complexity, we want to understand and
quantify the diﬀerences among tasks, and how developers
gain experience and become ﬂuent. Therefore we propose
the following research questions: does ﬂuency exist? Can it
be measured? How long it takes for an average developer to
become ﬂuent?
To answer these questions we need to model the increase
in developer skill and expertise, leading to the following
research question: is developer learning additive (a ﬁxed
amount of knowledge or experience is gained per unit time)
multiplicative (knowledge increases by a ﬁxed fraction of
existing knowledge or experience per unit time), reaches
a plateau, or has some other functional form? Answeringthis question has profound practical consequences. If lear n-
ing is multiplicative, the seniority is extremely valuable for
the projects, because expertise would increase exponentia lly
withexperience; iflearningisadditive, thediﬀerencesin skill
between novice and experienced developers would be less
pronounced. If learning plateaus rapidly, there are no ad-
vantages to seniority beyondthetime horizon of theplateau .
We started our investigation from an attempt to under-
stand what was perceived to be a productivity problem fac-
ing oﬀshored projects which have replaced their original de -
velopers. We borrow insights from studies of learners who
initially are getting faster through practice but have grad -
ually diminishing improvements with further practice [22] .
The development managers claimed that it takes only a few
months for the developer to become ”fully productive” in
their projects. However, the same managers wouldn’t al-
low these nominally “fully productive” developers to take
on complicated tasks, thus raising a question: what are the
diﬀerences between developers with a 6 month and 3 year
tenure with the project? After all, both groups are already
on the same “productive”plateau. Interviews we have con-
ducted reveal the variations in the nature and complexity of
development tasks these two groups undertake. We discov-
ered two dimensions involving the diﬃculty and the central-
ity of the tasks, in addition to the well-known variations in
developer skill. We found four dimensions of development
task centralitydetermined bythe importance ofatask based
on its long-term impact and on its potential to aﬀect a cus-
tomer, the product, or the development team. Through a
quantitative study we found that the learning measured as
the number of tasks completed each month plateaus after
approximately 6-7 months in three small and medium scale
projects, andafter 12monthsinalarge project. Thatclosel y
matched the perceptions of how long it takes for developers
to become productive obtained from the development man-
agers of these projects. Furthermore, the developer ﬂuency
is measured via productivity adjusted for task diﬃculty and
task centrality. The results indicate that the developers’
productivityadjusted for task diﬃcultyand theaverage tas k
centrality do not plateau but continue to increase over the
entire three-year measurement interval. This provides ev-
idence that project ﬂuency exists or, in other words, that
developers continue improving beyond an apparent plateau
in performance by increasing the diﬃculty and centrality of
the tasks they undertake.
The main contributions of this study include: separating
dimensions of developer expertise, ﬁnding ways to measure
them, and quantifying the learning curves that describe how
each type of expertise is acquired. Furthermore, the knowl-
edge of the learning curve has practical implications. The
oﬀshoring schedule has to accommodate longer training pe-
riods. The need to implement the most complex tasks and
to provide mentoring, may require retaining some existing
experienced staﬀ. The additive increase in average task cen -
trality implies that it may take a long time to replace senior
developersinaproject andclariﬁes some oftheserious issu es
facing projects that attempt to do that.
In Section 2 we review related work. The project context
and the methodology are described in Section 3. Section 4
presents our ﬁndings and Section 4.3 summarizes the key in-
sights. Weconsiderthelimitations inSection5andconclud e
in Section 6.2. RELATED WORK
The studies of learning that are the most closely related
to our work can be roughly classiﬁed into studies of human
learning and studies of learning in software development. I n
human learning theories, the learning trajectories over ti me
vary among diﬀerent types of tasks [2], most tasks take less
time to accomplish with practice [22], and practice makes
the diﬀerence between traditional mastery (accuracy) and
true mastery [3] (i.e. ﬂuency, accuracy + speed). Practice
has been considered very important for learning. For exam-
ple, theLegitimate PeripheralParticipation (LPP)approa ch
argues that the learners’ participation of practice is at ﬁr st
legitimately peripheral but increases gradually in engage -
ment and complexity [13]. Informal and incidental learning
emphasizes the learner-centered focus and the lessons that
can be drawn from personal life experiences, and is said to
be at the heart of adult education [14]. These general stud-
ies can be applied in many domains. For example, Ye et al.
used LPP to investigate how Open Source Software (OSS)
members change their roles with gradual participation [28] .
In our study, we assume that the practice is the most im-
portant way to learn in software development projects.
The studies of learning in software developmenthave tried
to borrow insights from psychology and cognitive science to
explore software development issues. For example, Curtis
et al. [6] discussed the theoretical and practical contribu -
tions to software engineering under two of the psychologi-
cal paradigms: individual diﬀerences and cognitive scienc e
(consideringapractical questionofhiringthebest person for
the job). Robillard [23] tried to bridge the gap between the
viewpoints of cognitive scientists and software practitio ners
regarding knowledge and outlined the characteristics of re -
lated concepts in software methodologies and approaches.
Other researchers focused on practical issues, in particul ar,
on how developers new to the project learn. For example,
a grounded theory study with 18 developers in IBM by Da-
genias et al [7] listed a number of obstacles facing devel-
opers joining new projects. Von Krogh et al. [26] looked
at the strategies and processes by which newcomers join
the existing OSS community, and how they initially con-
tribute code. Begel and Simon [1] discovered the types of
tasks such novices engage in, and found that communication
and product knowledge pose serious challenges for the new-
comers because they have not been trained for such tasks
through their formal education. Sim and Holt [24] identiﬁed
seven patterns in the naturalization process of newcomers,
for example, mentors are an eﬀective, thoughineﬃcient, way
to teach immigrants.
Presently, the issues caused by oﬀshoring and outsourcing
highlight the importance of understanding how developers
become ﬂuent in a project: does the oﬀshore team have the
right skills for the project and, in particular, how long it
takes for an average developer to gain enough experience
to become productive. Oﬀshoring and outsourcing issues
have been extensively studied. For example, Mockus [16]
found that one highly experienced developer may need up
to six new replacement developers in large software project s,
Herbsleb et al. [10] found that the time it takes to complete
distributed tasks is almost three times longer than for co-
located tasks. However, the above-mentioned studies do not
quantifyhow developers become ﬂuentwith tenure, nor they
investigate or quantify how developer expertise changes as
developer becomes more experienced.3. METHODOLOGY
As desribed earlier, the research questions we try to ad-
dress include:
•Does ﬂuency exist and can it be measured?
•How long does it take for an average developer to be-
come ﬂuent?
•How soon after joining the project the increases in de-
veloper ﬂuency slow down or stop (plateau)?
•Is developer learning additive, multiplicative, reaches
a plateau, or has some other functional form?
In order to answer these questions, we used qualitative and
quantitative approaches on a set of projects that varied in
scale, domain, and organization. Qualitative investigati on,
i.e., interviews, were used to drive and verify the quanti-
tative measures. Quantitative study was done on the data
of project repositories, and used to model the developers’
learning. We start from describing the context of our study
in Section 3.1, present the interview investigation in Sec-
tion 3.2, introduce the data ﬁltering approach in Section 3. 3,
and the statistical methods in Section 3.4.
3.1 Context
Table 1 shows the years, the scale, the domain, and the
sites of the projects. Most projects were completely oﬀ-
shored and some were partly oﬀshored. Projects were pri-
marily from a large US corporation, with some projects from
a small Chinese corporation. We focused on one large-scale
project (Project D) to do the quantitative study – because
it had the longest history, and, more importantly, the rich
high-quality data. We validated our ﬁndings on Projects
A, B, and C that had less detailed records. We used the
remaining projects only for interviews.
3.2 Interview approach
We conducted semistructured interviews based on the fol-
lowing steps as described in [12]: clarifying the purpose, d e-
signing questions and subjects, interviewing and transcri b-
ing, analyzing, validating/verifying, and reporting. In t his
study interviews were used to identify the main themes to
deﬁne the quantitative measures, e.g, identify the varia-
tions among software project tasks, and verify the quantita -
tive measures, e.g, to make sure the developers we selected
through inﬂuence measure below were really inﬂuential in
the projects.
We constructed a set of semi-structured questions related
to the topics we are interested in, focusing on the involve-
ment, task assignment and task variation, and the diﬀer-
ences among tasks of developers. The questions we asked
changed slightly over time as we learned more about the
nature of how developers learn.
Table 1 lists the participants we interviewed, including
their roles and locations. Overall we interviewed 35 devel-
opers andmanagers. Weselected the interviewsubjects who
had the most inﬂuence on other developers in the project, in
order to get the most information from a limited number of
interviewees. What is known about experts is important not
because all learners are expected to become experts, but be-
cause the knowledge of expertise provides valuable insight s
into what the results of eﬀective learning look like [4]. In
Projects A, B, C, D, I and J we selected three develop-
ers with the highest inﬂuence measure using the following
procedure. First we constructed a graph of mentor-follower
relationships based on the modiﬁcations to the same sourcecode ﬁles as proposed in [17]. Using that graph we selected
several developers with the largest number of followers and
selected a subset of developers who were still working on
the project. We conducted one hour interviews with the
three developers in each project. We also interviewed the
development managers in all the projects as well as the out-
sourcing managers in Projects D, E, F, G and H, and the
quality managers in Projects D and F. Due to availability,
the interviews with managers were conducted one-on-one,
over extended period of time, each lasting less than 30 min-
utes. All interviews were transcribed during interviewing .
In the later analysis we iteratively went through the tran-
scriptions, looked for the information to answer the resear ch
questions we wanted to address, and tried to abstract the
answers.
We also had less formal repeated interactions both before
and after interviews both with the interview subjects and
with other project participants. These repeated interacti ons
helped us to ensure that our understanding of the interview-
based information was correct and toclarify additional que s-
tions we had as we proceeded with the study. Moreover,
these interactions were used to generalize our ﬁndings and
to reﬁne our hypothesis.
3.3 Data ﬁltering approach
We obtained data from version control systems and prob-
lem tracking systems of Projects A, B, C, and D. While
data quality and richness varied, the basic attributes that
had reasonable quality in all projects included developer l o-
gin, date of change, and ﬁle changed. The tight link be-
tween modiﬁcation requests (MRs) in the problem tracking
system and code modiﬁcations in the version control sys-
tem was available only for Project D. This careful tracking
was probably driven by product’s large size, long history,
importance to the business, and higher experience of the de-
velopers. To obtain the information about each developer,
including the site they worked at and how long they have
worked for the company, we used information from company
directory systems and human resources (HR) departments.
The attributes include HR identiﬁers, contact information
(including site address), and the date of hire. As described
in, for example, [15], we iterate over the following steps to
increase the quality of data: ﬁrst we retrieve the raw data,
then perform initial cleaning and processing, create mea-
sures to answer our research questions, perform analysis of
these measures, and ﬁnally validate the results. The valida -
tion step often lead to revisiting and modifying assumption s
made in the earlier steps resulting in an additional iterati on.
Table 2 lists several attributes of the validated data we
used. Every observation is a task-related modiﬁcation to an
individual source code ﬁle made by a developer. We refer to
it as delta. A task is an MR, which might be a new feature
or a bug ﬁx. In Project D there were 85 developers who
had started on the project after January 2004 and stayed
with the project for at least three years. To avoid tenure-
related bias, we excluded developers who stayed less than
three years in the project.
The 85 developers made 20544 modiﬁcations to the source
codewithintheirﬁrstthreeyearsontheproject. Thesmalle r
scale of Projects A, B and C required us to select developers
who stayed at least 12 months with the project. There were
too few developers who stayed at least three years. As a
result, our sample had 69 individual developers who madeTable 1: Attributes of projects and participants
Projects YearsNCSL
(Million)Domain Sites# of Par-
ticipantsParticipant role:location
A >154M Call center US oﬀshored to India 4 3 dvlprs:India, DM:India
B >102.3M Dialer US oﬀshored to India 43 developers: India, DM:
India
C >101M Voice Response US oﬀshored to India 43 developers: India, DM:
India
D >155M Core telephonyUS partly oﬀshored
to India63 developers: US, DM: US,
OM: US, QM: US
E >105MEmbedded tele-
phony: endpointsUS oﬀshored to India 2 DM: India, OM: India
F >73MEmbedded core
telephonyUK partly oﬀshored
toIndiaandRomania3DM: UK, OM: Romania,
QM: UK
G >157.5M MessagingUK and US partly
oﬀshored to India2 DM: UK, OM: UK
H >51M Contact CenterUS partly oﬀshored
to India2 DM: US, OM: US
I 3 0.19M Middleware China 43 developers: China, DM:
China
J 2 2.2MA web-based
development
platformChina 43 developers: China, DM:
China
˚DM is development manager, OM is outsourcing manager, QM is q uality manager
Table 2: Attributes of the modiﬁcations
Attribute
nameMeaning
id The HR identiﬁer of the developer
frY The date the developer was hired
toY The date the developer left
t The date the modiﬁcation was made
f The ﬁle changed
mod The module changed
modchgThenumberof modiﬁcationswhichhavebeen
made on the module
modloginThe numberof logins whichhave touchedthis
module
tenureThe tenure developer has since she joined the
project until the day she made a particular
modiﬁcation (months are on a year scale, e.g,
the ﬁrst month is 0, the fourth month is 0.25,
and so forth)
mr The MR number for the modiﬁcation
nmrf The number of ﬁles relating to the MR
nmrlogin The number of logins relating to the MR
ﬁeld Customer reported bug or not
13081 modiﬁcations within 12 months of joining the project
for the three Projects A, B and C.
3.4 Methods
A learning curve is also known as a power law of practice.
It has been investigated extensively in the past for various
kinds of tasks. A speciﬁc parametric form of the learning
curve was proposed by Ritter and Schooler [22]:
T=CTrials−Ctask, (1)
whereTis the time it takes to perform a task, Trialsis
the number of times a person has performed that task, Cisa constant, and Ctaskis a task-speciﬁc constant. The shape
of the curve shows how performing more trials (practice)
leads to reduced performance time. In our study, we borrow
this basic idea of learners getting faster through practice .
However, considering the complexity of tasks and the diﬃ-
culty of calculating the performance time for each task in
software development, we don’t use the performance time
to measure the learning achievement. Instead, we use the
number of tasks (represented by modiﬁcations in this study)
performed per unit time, i.e., productivity, as the measure of
developer performance. As discussed below, this productiv -
ity measure does not completely reﬂect the true mastery of a
developer in a project, i.e., ﬂuencyon complex tasks. There -
fore we consider developer ﬂuencyas a theoretical construc t,
and measure its change over time in various ways, including
the number of tasks completed per unit time, the number
of tasks adjusted for their diﬃculty, and average task cen-
trality (explained in the next section). The questions we tr y
to answer relate to how long it would take a developer to
become ﬂuent in a project, therefore our focus is on how
developers increase their ﬂuency over time, or, simply, how
fast they learn.
The learning curve tends not to be linear as exempliﬁed
by Equation 1, therefore we can not use multiple linear re-
gression to model our response variables. Instead, to esti-
mate developer learning curve we ﬁt a generalized additive
model(GAM) [9] implemented byWood [27] in R [21]. GAM
is a variation of the linear regression:
y=C+f1(x1)+...+fm(xm)+error ,
wherefi,i= 1,...,maretypicallysmoothingfunctionssuch
as splines1. The basic idea of GAM is to ﬁt an unknown
1Smoothing splines allow ﬁtting a regression to a curve of
unknownshape: itprovidesagraphicalillustration ifalin ear
model is appropriate and, if not, it gives the shape of that
nonlinear relationship [21].shape with a minimal number of parameters. Thus, a trade-
oﬀ between the best ﬁt and fewest parameters (smoothness)
is obtained. If the observed data can be reasonably ex-
plained through a linear relationship between predictors a nd
the response, the ﬁtted smoothing function will simply be a
straight line makingit equivalent to a multiple regression . A
variety of methods can be used to attain a balance between
the best ﬁt and smoothness. We used default parameters of
function gamin R package mgcv. In our case we use smooth-
ing function for a single predictor: Tenure, or time spent in
the project that we measure in calendar years. In particular
our models are of the form:
logL=C+CID+x1+...+xm+S(Tenure),(2)
where L is some measure of learning achievement (i.e., de-
veloper ﬂuency), CIDis a constant for each developer iden-
tiﬁerID, andx1,...,x iare additional predictors of learning
achievement. Sis the smoothing function used in GAM.
We transformed the response (learning achievement mea-
suresL) via a logarithmic transformation because it tended
to be highly skewed and, thus, needed a transformation to
stabilize the variance. In all models we include a separate
predictor for each developer CIDbecause of the well-known
variation in developer performance [8, 5]. Such adjustment
is called ﬁxed-eﬀects model(because each developer is repr e-
sented by a separate constant or a“ﬁxed eﬀect”).
In brief, we ﬁt and interpret models according to the fol-
lowing steps.
1. Fit the model in Equation 2 with the proposed re-
sponse and predictors. The ﬁtted functional shape of
S(Tenure)determinesthelearningcurve(therelation-
ship between learning achievement LandTenure) em-
pirically. For example, we could see the learning curve
increases and plateaus when we ﬁt Las the number
of modiﬁcations the developer made per month as de-
scribed in Section 4.2.1.
2. Transform Tenureby logarithms to make interpreta-
tion of the learning curve more straightforward. In
particular, in the simplest case when Sis linearS(x) =
c+pX, by exponentiating we obtain
L=C(x,ID)Tenurep.
TheC(x,ID) =eC+CID+x1+...+xm+cdoes not depend
onTenure. In such linear case we can also determine
pby ﬁtting the following linear regression model:
logL=C+CID+x1+...+xm+logTenure, (3)
wherepwould then be the estimated coeﬃcient for
thepredictorlog Tenure. Thevalueof pwouldprovide
evidence about the nature of the relationship between
tenure and the learning achievement L:
(a) Ifp= 1,L=K×Tenure, the learning achieve-
ment increases linearly with tenure;
(b) Ifp∈(0,1),L=K×Tenurep, the learning
achievement increase slows with tenure;
(c) Ifp >1, the learning achievement increase speeds
up with tenure.
4. RESULTS
We start by providing qualitative empirical evidence that
developer ﬂuency exists and show that the paradox of the
”fully productive”developers’ inability toperform all pr oject
tasks can be at least partially attributed to the diﬃculty
and centrality of the tasks in Section 4.1. In Section 4.2.1we present quantitative evidence that the developer produc -
tivity plateaus within a time frame that is consistent with
opinions expressed in manager interviews. In Section 4.2.2
and Section 4.2.3 we examine how developer’s productivity
adjusted for task diﬃculty and task centrality increases wi th
developer’s experience. Finally, in Section 4.2.4 we obser ve
that the developer ﬂuency is additively increasing at least
in the ﬁrst three years on the project.
4.1 Existence ofﬂuency
The evidence for the existence of developer ﬂuency as an
aspect of developer capability that can not be explained by
their productivity alone is best illustrated by the followi ng
paradox we observed. The development managers, when
asked how long it takes for the developers to become pro-
ductiveintheir projects, wouldclaim thatit takesonly afe w
months. However, they would not even consider assigning
some development tasks to developers that have been less
than a few years with the project. Speciﬁcally, on one hand,
when being asked how long it would take the newcomers to
be productive in their projects, managers in small/medium
Projects A, B, C, E, F, G, H, I, and J responded that 2-6
months was enough and the manager in the large Project D
responded that around 12 months was suﬃcient. Most also
notedlarge diﬀerences amongdevelopers inhowlongit takes
to reach productivity; On the other hand, when the man-
agers were asked if they would assign the critical customer
issues to developers with 2-6 months of experience, they re-
sponded that it takes several years to become competent in
such important tasks. Furthermore, all projects we investi -
gated would not assign mentoring tasks to developers with
less than two years of project experience. Project D require s
mentors to have at least three years of project experience,
because, as described by one manager,“ we had attempted to
assign mentoring tasks to developers with only two years of
experience, but had unsatisfactory results .”
Binder et al. [3] considered ﬂuency as True Mastery: ac-
curacy + speed, and argued that it is easier to attain ﬂuency
on small, achievable chunks or components of a larger task
than to attain mastery of the whole thing at once. For ex-
ample, even though basic commands in UNIX are simple
and easy to understand, learning how to combine them into
shell scripts to accomplish more complex tasks may take
much more time. Similarly, in software projects there exist
simpler tasks that take less time to learn and some criti-
cal tasks that are much more diﬃcult to master. Therefore
a newcomer in a project may be able to master the sim-
plest tasks quickly and reach ﬂuency for such tasks, but she
may still need more time to master more diﬃcult tasks, as
suggested by [29]. Accordingly if a developer is ﬂuent in a
project, she must have the ability to complete most project
tasks rapidly and accurately independent of task complex-
ity. In order to understand the properties that make a task
complex, we asked the following questions in Projects A-J:
1. What tasks did you get when joining your project, and
what tasks are you working on now? What are the
most important diﬀerences between them? (Projects
A, B, and C)
2. How does your project assign tasks for the seniors and
novices? What are the diﬀerences between the way
tasks are assigned? (Projects D, E, F, G, H, I, and J)
Through analyzing the interviews we found that the dif-
ferences between tasks assigned to or undertaken by seniorand novice developers have two dimensions: task diﬃculty
andtaskcentrality. Taskdiﬃcultywas most frequentlymen-
tioned by developers. The task centrality was usually im-
plicit and embedded in the importance or value developers
and managers assigned to the task. We draw the distinction
between diﬃculty and centrality, as the development man-
ager of Project G commented: “ the eﬀort to complete an MR
is not a factor in assessing the importance of the MR .”More
speciﬁcally, task diﬃculty implies the eﬀort to complete a
task and primarily hampers the developer progress, while
task centrality illustrates the value of the results obtain ed
by completing the task and primarily represents developer
performance.
Task diﬃculty was most frequently noted as the diﬀerence
embodied in the following dimensions we have observed:
1. Technology, for example, “Java is easier than C++”
mentioned several times by developers from Project I.
2. Domain (or application). In a product, some domains
are considered to be more diﬃcult than others. This
has been observed before, for example, Graves and
Mockus [8] found that modiﬁcations to subsystems be-
lieved to be more complex required measurably more
eﬀort. Or, in words of a developer of Project J regard-
ing his module: “this forge module is a mess, it has too
many relationships with other modules.”
3. Working relationships. A task which requires commu-
nications with more people is considered to be more
complicated, asaseniortesterofProject Dcommented:
“it’s always easier to do something that doesn’t involve
lots of people.”
4. Customer related issues. According to a manager from
Project G:“A developer found defect is always simpler
to ﬁx than a bug found by customers.”
Task centrality represents the importance of the task to
theproject, whichwe borrowfrom theconceptdeﬁnedinthe
organizational socialization theory [25]. We discovered f our
dimension of centrality in Projects A-J: customer impact,
system impact, team impact, and future impact.
1. Customer impact. Tasks which are the most impor-
tant to satisfy customer requirements and thereby to
sell the product are most valuable in a commercial set-
ting. Inparticular, resolvinghighseverityproblemsre-
ported by important customers is an example of such
central activity. For example, in Project D,“customer
escalation trumps everything”, in Project I,“the most
experienced developers are sent to the customers to re-
solve their problems.” In some open source products
the tasks that aﬀect more users tended to be ﬁxed
much faster than tasks aﬀecting few users [18].
2. System-wide impact. Tasks that require changes or
depend on a large number of modules were consid-
ered more important. In other words, the impact was
gaged by the extent to which task dependencies were
distributed over the module structure. For example, in
Project J,“there are two most important modules, one
is the common library, all the other modules would in-
voke them; the other is the forge module, which needs
to invoke all the other modules and show them to the
users.”3. Team impact. Tasks which inﬂuence more members
of the team (not only the current developers, but also
the later developers) appear to be more valued by the
team and are more likely to have a wide and long-
term impact. In particular, the team beneﬁts from the
maintainability of the code, but that requires extra
eﬀort, and it beneﬁts from the mentoring of the ex-
perienced developers, but that reduces mentors’ per-
formance. E.g, writing comments is a job the team
can beneﬁt from, but it requires additional eﬀort. In
Project J, “once I found some developer who didn’t
write comments in their committing changes, I would
go to them and ask them to add them and do that in
the future.”
4. Future impact, i.e., the tasks implementing strategic
decisions. For example, tasks which lead to major
changes to the system architecture or changes aﬀecting
the ability to create new features. Both types of tasks
determine how customers will be able to use the sys-
tem, and thus they are more central in the customer
dimension as well. It appears that the high level devel-
oper/manager has more concern about this, e.g, a top
developer of D commented: “I see a sense of urgency
for our team in terms of skill acquisition so the team
is equipped to address the next generation of software
and product technologies.”
These observations lead to:
Hypothesis 1.In a software project tasks vary in terms
of diﬃculty and centrality. Diﬀerent tasks require diﬀerent
degrees of project ﬂuency.
4.2 Quantifying ﬂuency
In this section we quantify how the developers become
ﬂuent in software projects. We start by quantifying devel-
oper’s learning curve through her productivity calculated as
the number of modiﬁcations she made per staﬀ-month in
Section 4.2.1, as was done in, e.g, [17]. Because the tasks
vary in diﬃculty and centrality, and more ﬂuent developers
handle more diﬃcult and central tasks, we may be able to
measure developer ﬂuency as well by measuring and adjust-
ing for task diﬃculty and task centrality. To accomplish
that we ﬁrst model how developer productivity increases
with tenure adjusted for the task diﬃculty as described in
Section 4.2.2. However, by embodying the importance or
value in the project, the task centrality is an even more di-
rect representation of developer performance. Therefore w e
consider the centrality as a potential measure of ﬂuency, an d
model how the average centrality of the tasks increases with
developer tenure in Section 4.2.3. For these three models we
use GAMs as speciﬁed in Equation 2.
4.2.1 Developers’productivityplateaus
To estimate developer learning curve we ﬁt a GAM, in
which the learning achievement Lis the developer produc-
tivity measured by the number of modiﬁcations a developer
completed per staﬀ-month, and the predictor is the devel-
oper tenure measured in years.
logModifications
Month=CID+S(Tenure)
Figure 1 shows the ﬁtted curve in Project D. There are 3060
observations each representing a developer-month. Months0.5 1.0 1.5log Modifications ~ ID + Tenure
Tenure (months)Modifications/Month for average Devlpr
1 2 3 4 5 6 7 8 9 11 13 15 17 19 21 23 25 27 29 31 33 35
Figure 1: Developer productivity grows over time
were counted for each developer separately, starting from
the date she joined the project. The response is the number
of modiﬁcations a developer completed that month. The R2
is 0.25. The solid line represents the estimated curve S, and
the two dashed lines represent the conﬁdence bands. From
the curve we can see that a developer who spends more time
ontheproject wouldbecomemoreproductive, andgradually
reaches a plateau of productivity after more than one year,
in accordance with the ﬁnding in, for example [20], where
new developers reach full productivity in approximately 12
months. It also agrees with the interview-derived data from
Project D.
We also used several additional measures to triangulate
our results: evidence is stronger where analyses using dis-
tinct measures concur. In particular, we used two addi-
tional metrics to measure productivity: the number of mod-
ules modiﬁed per staﬀ-month and the number of completed
MRs per staﬀ-month. Both alternatives result in the similar
learning curve as shown in Figure 1.
Moreover, applying the same model for Project A, B and
C we get a similar curve that plateaus earlier: only after 6-7
months. The earlier plateau agrees with the results of the
interviews in Projects A, B, and C. This demonstrates that
the productivity in the considered projects was increasing
over time and took longer to plateau in the large project.
This suggests that project scale provides a mediating eﬀect
on the learning speed. One possible explanation of this me-
diating eﬀect is that the simple tasks in a large-scale proje ct
are more diﬃcult to learn than in smaller projects, thus the
practically achievable level of methodology improvement,
i.e., plateau, takes more time to reach. Therefore,
Hypothesis 2.Developers’ productivity plateaus within
6-7 months in small and medium projects and it takes up to
12 months in large projects.
4.2.2 Developerproductivityadjustedfor difﬁculty
We observed four dimensions for task diﬃculty, but in a
speciﬁc project there might be only a subset of these dimen-
sions that matter, depending on the characteristics of the
project. For example, Project J uses similar technologies
across the project and has few customers, therefore the ap-
plication domain is the primary driver of diﬃculty, with no
other obvious diﬃculty components. But in Project D that
has many customers, the tasks related to customer issues
are the most diﬃcult. Accordingly, in the following modelof Project D we adopt two measures which reﬂect“customer
related issue”and“domain”to measure task diﬃculty.
0.4 0.6 0.8 1.0 1.2log Modifications ~ ID  + AvgFiles + FractionCust + Tenure
Tenure (months)Modifications/Month for average Devlpr
1 2 3 4 5 6 7 8 9 11 13 15 17 19 21 23 25 27 29 31 33 35
Figure 2: Developer productivity adjusted for diﬃ-
culty grows over time
Equation 4 shows the model that adjusts the productivity
by the diﬃculty of the tasks. The response is the number
of modiﬁcations made by a developer each month, and the
predictors are developer indicators, the two measures of ta sk
diﬃculty, and developer tenure. The task diﬃculty is repre-
sented by the number of ﬁles modiﬁed by an MR averaged
over all MRs the developer completed that month (# Files)
which we consider as the ”domain diﬀerence” dimension of
task diﬃculty. The second measure of task diﬃculty is the
percentage of customer reported MRs over all MRs com-
pleted by the developer that month (% Cust) which repre-
sents the ”customer related issues” dimension as described
above.
logModifications
Month=CID+#Files+
%Cust+S(Tenure) (4)
Figure 2 shows the ﬁtted learning curve for Project D.
The ﬁtted coeﬃcients were 0 .039 for # Fileswith the stan-
dard deviation of 0 .001, 0.81 for % Custwith the standard
deviation of 0 .07, and both were signiﬁcantly diﬀerent from
zero with a p-value <2e−16. The R2was 0.59. From the
curve we can see that the dveloper productivity adjusted for
diﬃculty keeps growing with the tenure. We also ﬁt a GAM
transforming Tenureby logarithms. Because the resulting
curve was a straight line we proceeded to ﬁt the linear re-
gression model as speciﬁed in Equation 3:
logModifications
Month=CID+#Files+
%Cust+logTenure (5)
The results of the linear regression show that the estimated
coeﬃcient for log Tenureis 0.16 with the standard deviation
of 0.02 (p-value= 1 .17e−15), the coeﬃcients for # Filesand
%Custaresimilar totheGAMabove. The R2= 0.72. Based
on the discussion in Section 3.4 the learning achievement
does not plateau but it slows down with tenure in the shape
of the polynomial Tenure0.16.Therefore:
Hypothesis 3.Developers take longer to reach full pro-
ductivity if we adjust for the diﬃculty of tasks.4.2.3 Developerﬂuencymeasuredviataskcentrality
As for task centrality, each dimension (customer, system-
width, team, andfutureimpact) is usuallyimportantand of-
ten can be measured. In particular, the rich data of Project
D enabled us to explore several dimensions of task central-
ity. We chose four diﬀerent measures, each of them reﬂect-
ing at least one dimension. Each measure is calculated for a
particular developer/month pair by averaging the followin g
quantities over all modules modiﬁed and all MRs completed
by a developer during that month:
1. The number of past modiﬁcations to the module. The
modules with a long history have been in the system
from the beginning and modules with more modiﬁca-
tions are likely to be changed in the future, both in-
dications of long-term impact and, thus, centrality to
the system’s architecture.
2. The number of other developers who have modiﬁed
the module in the past. A module changed by many
developers is likely to be important from multiple per-
spectives and, therefore, is more important to the sys-
tem’s adaptation to the changing environment, thus
reﬂecting the centrality of the module.
3. The number of developers involved in an MR. MRs
with more developers involved are more likely to be
important from multiple perspectives: reﬂecting team
and system-wide dimensions of centrality.
4. The number of releases the MR has been submitted to.
MRsforissuesthatneedtobeaddressedinmultiplere-
leases, are more likely to reﬂect long-term impact and
are also more likely to aﬀect more customers. There-
fore it’s more likely to be central in the long-term and
customer dimensions.
We denote the four centrality measures as Ctr#delta/mod ,
Ctr#dvlprs/mod ,Ctr#dvlprs/MR , andCtr#releases/MR . Fig-
ure 3 shows the results of the GAM in Equation 6 for the
centrality curve in which the response is the ﬁrst central-
ity measure Ctr#delta/mod and the predictors are developer
identities, and developer tenure. The R2= 0.69.
logCtr#delta/mod =CID+S(Tenure) (6)7.0e+07 7.5e+07 8.0e+07 8.5e+07 9.0e+07 9.5e+07log(Centrality) ~ ID + Tenure
Tenure (months)Centrality for Avg Devlpr
1 2 3 4 5 6 7 8 9 11 13 15 17 19 21 23 25 27 29 31 33 35
Figure 3: Centrality grows over time
We can see that the centrality is linearly going up with
tenure for the entire three year period. By transformingTenureusing logarithms we also obtain a straight line. As
described in Section 3.4 we ﬁt the linear regression model in
Equation 7:
logCtr#delta/mod =CID+logTenure, (7)
Theresultsshowthattheestimatedcoeﬃcientforlog Tenure
is 1.13 with a standard deviation of 0 .09 (p-value <2e−16,
R2= 0.56). This means that the average task centrality
does not plateau, but keeps growing approximately linearly
with tenure over the entire observed period of three years.
For triangulation we also model the remaining three mea-
sures of centrality, and they all show a similar continually
growing relationship between centrality and Tenure, though
not linearly. This appears to agree with the observation in
learning curve studies that the eﬀort to achieve signiﬁcant
progress andsuﬃcientskilltostartusingatool maybefairl y
predictable, but achieving real mastery requires much more
time and eﬀort [22]. Therefore:
Hypothesis 4.Developers do not become ﬂuent for at
least three years in large projects.
4.2.4 Developersincreaseﬂuencyadditively
The estimated coeﬃcient at log Tenure in Equation 7 is
not signiﬁcantly diﬀerent from one. It means that the av-
erage task centrality is approximately linear with respect
toTenure. In other words, the average task centrality in-
creases by a ﬁxed amount over each-ﬁxed length time pe-
riod, i.e., developers learn additively. In particular, de vel-
opers gain approximately 30 points of centrality per year,
and that increase is independent of what they have already
achieved. This ﬁnding may serve as a hint for development
managers: if developers increase their ﬂuencyadditively, the
diﬀerencesbetweennoviceandexperienceddeveloperswoul d
be less pronounced than if learning is multiplicative, ther e-
fore the road for a novice to become more central might not
be as hard as in the situation where increase in skill is pro-
portional to existing skills. However, it is much harder tha n
in a situation where increase in skill is inversely proporti onal
toexistingskill as proposedinsome learningcurvemodels o r
in cases where learning plateaus early. The additive growth
in ﬂuency might reﬂect the concerns of outsourcing manager
of Project F, who said, “ we want as many senior engineers
as possible ”, also of the senior developer of Project D, who
was quite upset: ” I know people who have had to tell staﬀ [in
the oﬀshore location] the line and code that has to be typed
in.”
Hypothesis 5.Increases in developer ﬂuency as mea-
sured by task centrality are additive with respect to the tim e
spent on the project.
4.3 Insights
Ourﬁndingsshowthatwhenadeveloperstartsinaproject,
she learns very rapidly, and gets ﬂuent on basic tasks over
a relatively short period of time. Once she becomes pro-
ductive at basic tasks, the number of tasks she completes
per unit time stays approximately the same. However, the
learning does not stop, because she faces more diﬃcult and
more central tasks, and her ﬂuency keeps growing linearly
up to at least three years that we measured. Therefore, we
can hypothesizeHypothesis 6.The true mastery of a large scale project,
i.e, being able to complete most tasks of a project accu-
rately and quickly, needs more than three years of experienc e,
though it might take less time in smaller projects.
Hypothesis 7.The diﬀerence between seniors and novices,
or the gap in ﬂuency from basic tasks to craftsmanship,
might lie in the ability to combine and apply what is learned
to perform more complex activities creatively and in new sit -
uations, which is considered to be ﬂuency by both informal
experience and by scientiﬁc research [3].
These ﬁndings suggest that programming might not be
simply an engineering issue, but a delicate act of craftsman -
ship. Consequently, it might be helpful for a newcomer if
the project could provide documents, courses, and mentors
to explain what she may expect to experience in order to
become ﬂuent. Such understanding may help developers get
motivated to get more engaged in the project. It also ap-
pears that the best strategy would be to start from simple
tasks, as suggested by interviews in all the projects we stud -
ied. Also, as work by Binder et al [3] revealed – one of the
most important ways to achieve ﬂuency in anything is to
ﬁnd a way to practice and ﬁrst master its basic elements or
tasks.
Furthermore, the ﬁndings suggest the plans for outsourc-
ing shouldn’t expect developers with one year of experience
to reach full productivity; it’s important to retain at leas t
some very experienced developers for a longer period. On
one hand, they need to handle the tasks that require high
ﬂuency. On the other hand, that might help the newly hired
developers to accelerate the progress in becoming more pro-
ductive through being mentored by a senior developer, as
suggested by the outsourcing manager of G: ” it used to take
6-8 months for a new employee to come on board and be pro-
ductive. Now that we have a core set of senior developers,
new developers are mentored when they arrive and are able
to come on board in about 3 months .” The ﬁndings also sug-
gest that the learning may happen additively or the amount
of additional skill in terms of task centrality is proportio nal
to the amount of additional time spent on the project and
is independent of developer seniority.
5. LIMITATIONS
Toaddressexternalvalidityconcernsweinvestigateproje cts
ofvariousscales andindiﬀerentdomains. However, theﬁnd-
ings may not generalize toprojects of larger or smaller scal es
than considered here or to other domains. One of the main
threats to validity in this study comes from the nature of
the data sources that is typical of mining software reposito -
ries. We have tried diﬀerent ways to validate the data we
used. First, we collected data from diﬀerent sources and lo-
cated the inconsistencies (e.g, multiple IDs in the company
directory that can be matched to the same address, phone
number, and email probably identify the same person). Sec-
ond, we used triangulation by conﬁrming the same ﬁnding
via multiple diﬀerent measures. E.g, when measuring the
developer productivity, we used numbers of modiﬁcations,
modules, and MRs per staﬀ-month as various approxima-
tions of productivity. When measuring the centrality, we
also used multiple measures: the average number of modiﬁ-
cations to a module, the average number of logins touching
a module, and the average number of logins involved in anMR. When multiple metrics point to the same result, we
assume it’s more likely to match the reality. Furthermore,
we have described the details we believe are suﬃcient to re-
produce our ﬁndings by other researchers in other contexts.
Additional threats to validity come from the interviews.
We have two concerns: to what extent the interviewees have
the representative understandingof the topics we study, an d
to what extent the answers provided by the interviewees
match the reality of the projects they represent. To address
the ﬁrst issue, we have tried to sample the candidates to ob-
tain people knowledgeable about the project. In particular ,
we selected the developers that had the strongest mentor-
ship signature using a quantitative approach described in
Section 3.2. Regarding the second issue, because of human
tendency to remember what she believes, not what really
happened [11], we need to interpret the interview results
with caution. The best way to reduce this potential bias is
to interview multiple individuals in a project for multiple
projects.
Finally we took into account the individual diﬀerences
among developers in our quantitative analysis, because as a
senior developer of Project D commented: “achieving exper-
tise depends on the area and the person.” Also, the quality
manager of Project D even believed there are some people
who“plateau and don’t get any better.” That’s why it is im-
portant to use a categorical predictor representing each de -
veloper in statistical models to adjust for the possible (an d
likely) individual diﬀerences among developers.
6. CONCLUSION
By studying developer ﬂuency we have separated diﬀerent
aspects of how developer expertise increases, found ways to
measure them, and discovered the learning curve that de-
scribes how each type of expertise is acquired. In particu-
lar, simple measures of productivity plateau fairly rapidl y,
and the diﬃculty-adjusted productivity and the measures
of centrality do not plateau within three years. In fact
the developer ﬂuency measured in terms of centrality in
a large project increased approximately linearly over the
entire three year measurement interval. Furthermore, our
observation showed that the simple measures of productiv-
ity plateau because developers achieve ﬂuency starting fro m
practicing simple tasks and gradually move to more compli-
cated and central tasks. All these ﬁndings not only agree
with the tenets of learning theory, but also provide a quan-
tiﬁcation of ﬂuency for software development.
Our ﬁndings can directly help managing oﬀshoring and
outsourcing of a software project. The long time needed to
reach ﬂuency implies that the oﬀshoring schedule has to ac-
commodate longer training periods. The need to complete
the most complex tasks and to provide mentoring, may re-
quire retaining some existing senior staﬀ. Finally, the ad-
ditive increase in average task centrality clariﬁes some of
the serious issues facing projects that attempt to replace
experienced developers. Moreover, the approach could be
applicable to a wide range of development in general, not
only oﬀshoring.
In the future, we would like to extend our work to in-
vestigate the kinds of experiences that lead to ﬂuency, and
how to accelerate the ﬂuency-acquisition process. We plan
to study how tools aiding learning in software projects, e.g ,
the Expertise Browser [19] that shows the relationships be-tween developers and source code, can help the developers
improve their performance.
Moreover, we need to learn more about the interface be-
tween learning at the individual, team, and organizational
levels. What are the nuances, the diﬀerences between and
among these levels? What happens at the intersection of
individual and team, of team and organization?
7. ACKNOWLEDGMENTS
The authors would like to thank all the interviewees, all
the people who helped. In particular, to thank Hong Mei
and David Weiss for their support of this work, James Herb-
sleb for his valuable comments, and R. Hackbarth and J.
Palframan for help with the interviews. Also thank the
National Basic Research Program of China under Grant
No. 2009CB320703, the Science Fund for Creative Research
Groups of China under Grant No. 60821003 and the Nature
Science Fundation of China under Grant No. 60603038.
8. REFERENCES
[1] A. Begel and B. Simon. Novice software developers, all
over again. In International Computing Education
Research Workshop , Sydney, Australia., 2008.
[2] A. G. Bills. General Experimental Psychology .
Kessinger Publishing, 1934. 197-206.
[3] C. Binder, E. Haughton, and B. Bateman. Fluency:
Achieving true mastery in the learning process.
Technical report, University of Virginia Curry School
of Special Education, 2002. Professional Papers in
Special Education.
[4] J. Bransford, A. Brown, and R. Cocking. How People
Learn: Brain, Mind, Experience and School . National
Academy Press, Washington, D.C., 2003.
[5] B. Curtis. Substantiating programmer variability. In
Proceedings of the IEEE 69 , July 1981.
[6] B. Curtis. Fifteen years of psychology in software
engineering: Individual diﬀerences & cognitive science.
InICSE’84 , pages 97–106, 1984.
[7] B. Dagenais, H. Ossher, R. K. E. Bellamy, M. P.
Robillard, and J. P. de Vrie. Moving into a New
Software Project Landscape. In ICSE2010 , Cape
Town, South Africa, May 1-8, 2010.
[8] T. Graves and A. Mockus. Identifying productivity
drivers by modeling work units using partial data.
Technometrics , 43(2):168–179, May 2001.
[9] T. J. Hastie and R. J. Tibshirani. Generalized Additive
Models. Chapman & Hall, 1990.
[10] J. D. Herbsleb and A. Mockus. An empirical study of
speed and communication in globally-distributed
software development. IEEE Transactions on Software
Engineering , 29(6):481–494, June 2003.
[11] D. A. Kahneman. A perspective on judgment and
choice: Mapping bounded rationality. American
Psychologist , 58:697–720, 2003.
[12] S. Kvale and S. Brinkman. InterViews: Learning the
craft of qualitative research interviewing (2nd Ed.) .
Thousand Oaks, CA: Sage Publications, CA, USA,
2007.
[13] J. Lave and E. Wenger. Situated Learning. Legitimate
Peripheral Participation . Cambridge University Press,
Cambridge, 1991.[14] V. J. Marsick and K. E. Watkins. Informal and
incidental learning. New Directions for Adult and
Continuing Education , 89:25–34, 2001.
[15] A. Mockus. Software support tools and experimental
work. In V. Basili and et al, editors, Empirical
Software Engineering Issues: Critical Assessments and
Future Directions , volume LNCS 4336, pages 91–99.
Springer, 2007.
[16] A. Mockus. Organizational volatility and developer
productivity. In ICSE Workshop on Socio-Technical
Congruence , Vancouver, Canada, May 19 2009.
[17] A. Mockus. Succession: Measuring transfer of code
and developer productivity. In 2009 International
Conference on Software Engineering , Vancouver, CA,
May 12–22 2009. ACM Press.
[18] A. Mockus, R. F. Fielding, and J. Herbsleb. A case
study of open source development: The apache server.
In22nd International Conference on Software
Engineering , pages 263–272, Limerick, Ireland, June
4-11 2000.
[19] A. Mockus and J. Herbsleb. Expertise browser: A
quantitative approach to identifying expertise. In 2002
International Conference on Software Engineering ,
pages 503–512, Orlando, Florida, May 19-25 2002.
ACM Press.
[20] A. Mockus and D. M. Weiss. Globalization by
chunking: a quantitative approach. IEEE Software ,
18(2):30–37, March 2001.
[21] R Development Core Team. R: A Language and
Environment for Statistical Computing . R Foundation
for Statistical Computing, Vienna, Austria, 2008.
ISBN 3-900051-07-0.
[22] F. E. Ritter and L. J. Schooler. International
Encyclopedia of the Social and Behavioral Sciences ,
chapter The learning curve, pages 8602–8605.
Pergamon, Amsterdam, 2002.
[23] P. Robillard. The role of knowledge in software
development. Communications of the ACM ,
42(1):87–92, 1999.
[24] S. E. Sim and R. C. Holt. The ramp-up problem in
software projects: A case study of how software
immigrants naturalize. In ICSE 1998 , pages 361–370,
1998.
[25] J. Van Maanen and E. Schein. Towards a theory of
organizational socialization. In B. Staw, editor,
Research in organizational behavior , volume 1, pages
209–264. JAI Press, Greenwich, CT, 1979.
[26] G. von Krogh, S. Spaeth, and K. R. Lakhani.
Community, joining, and specialization in open source
software innovation: a case study. Research Policy ,
32(7):1217–1241, July 2003.
[27] S. Wood. Fast stable direct ﬁtting and smoothness
selection for generalized additive models.
J.R.Statist.Soc.B , 70(3):495–518, 2008.
[28] Y. Ye and K. Kishida. Toward an understanding of
the motivation open source software developers. In
ICSE 2003 , pages 419–429, Portland, Oregon, 2003.
[29] M. Zhou, A. Mockus, and D. Weiss. Learning in
oﬀshored and legacy software projects: How product
structure shapes organization. In ICSE Workshop on
Socio-Technical Congruence , Vancouver, Canada, May
19 2009.