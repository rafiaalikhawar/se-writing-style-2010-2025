A Path-Sensitively Sliced Control Flow Graph
Joxan Jaffar
National University of Singapore, Singapore
joxan@comp.nus.edu.sgVijayaraghavan Murali
National University of Singapore, Singapore
m.vijay@comp.nus.edu.sg
ABSTRACT
We present a new graph representation of programs with speci-
Ô¨Åed target variables. These programs are intended to be processed
by third-party applications querying target variables such as testers
and veriÔ¨Åers. The representation embodies two concepts. First, it
is path-sensitive in the sense that multiple nodes representing one
program point may exist so that infeasible paths can be excluded.
Second, and more importantly, it is sliced with respect to the tar-
get variables. This key step is founded on a novel idea introduced
in this paper, called ‚ÄúTree Slicing‚Äù, and on the fact that slicing is
more effective when there is path sensitivity. Compared to the tra-
ditional Control Flow Graph (CFG), the new graph may be bigger
(due to path-sensitivity) or smaller (due to slicing). We show that
it is not much bigger in practice, if at all. The main result however
concerns its quality: third-party testers and veriÔ¨Åers perform sub-
stantially better on the new graph compared to the original CFG.
Categories and Subject Descriptors
D.2.5 [ Software Engineering ]: Testing and Debugging‚Äî symbolic
execution
General Terms
Algorithms, Reliability, VeriÔ¨Åcation
Keywords
Symbolic execution, program slicing, program transformation
1. INTRODUCTION
We present a new intermediate graph representation for C pro-
grams with speciÔ¨Åed target variables. These programs are intended
to be processed by third-party applications such as veriÔ¨Åers and
testers. The representation embodies two concepts. First, it is path-
sensitive in the sense that there may be multiple nodes representing
one program point so that infeasible symbolic execution paths can
be excluded. Second, and more importantly, the graph is sliced
with respect to the target variables.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proÔ¨Åt or commercial advantage and that copies
bear this notice and the full citation on the Ô¨Årst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciÔ¨Åc
permission and/or a fee.
FSE‚Äô14 , November 16‚Äì22, 2014, Hong Kong, China
Copyright 2014 ACM 978-1-4503-3056-5/14/11 ...$15.00.We begin with a promotional example: consider the C program
if(c) p = 1; else p = 0;
x = 0;
if(p > 0) x = 1;
if(x == 0) z = 1;
TARGET: {z}
Note that no static slicing is effective on this program because each
statement and variable affects the target zalong at least one path.
However, we can transform this program into an equivalent one:
if (!c) z = 1;
which produces, on any given input, the same values for zas the
original program. Clearly this transformed program would be more
efÔ¨Åcient when input to a veriÔ¨Åer or tester which seeks properties of
z. We arrived at this transformation as follows. Let S denote the
program fragment comprising of all but the Ô¨Årst if-statement of the
original program. Now consider slicing S in the contextp= 1(the
‚Äúthen‚Äù body of the Ô¨Årst if-statement). Clearly S would not modify
the variable zbecause only the statements x=0 andx=1 would
be executed in this context. Next consider the alternative context
p= 0(the ‚Äúelse‚Äù body). Now S would execute the statements x=0
andz=1, from which the former can be sliced away. Hence we get
the transformed program.
In other words, we arrived at this new program by Ô¨Årst consid-
ering path-sensitivity, and more speciÔ¨Åcally, the original program‚Äôs
symbolic execution (SE) tree . The general idea is that slicing of
a program fragment can be much more effective when it is done
with a given context. The SE tree in fact displays the context of a
program fragment as it unfolds through the various paths that bring
execution to this fragment. Now consider the example:
if(c) p = 1; else p = 0;
S
TARGET: {z}
where S now represents a program fragment which cannot be sliced
by restricting consideration of the values of zat the end of the pro-
gram. That is, all symbolic execution paths in S produce some
(different) output value in zat the end, regardless of the initial val-
ues of corp. Here, by being path-sensitive, we would produce a
CFG that corresponds to the program:
if(c) { p = 1; S; }
else { p = 0; S; }
This new program is effectively twice the size of the original pro-
gram due to the duplication of S, and yet there is no beneÔ¨Åt from
using this enlarged representation.
It is folklore that a fully path-sensitive representation of sym-
bolic execution is simply intractable, for the representation doublesin size for each branch statement encountered. The only alternative
is to have some form of merging where, at some stages in the con-
struction of the graph, certain paths in the graph transition into the
same node. If the merging is performed at every opportunity, the
original CFG would be obtained. If not performed at all, the full,
possibly intractable, SE tree would be obtained. The big question
is, therefore, how much merging is needed?
In this paper, we present a method for producing a path-sensitive
CFG by constructing a SE tree but merging nodes exactly when the
merge does not hide any information that affects slicing. That is,
when our algorithm merges a node in the tree with another, it guar-
antees that had the node been symbolically executed instead, one
would obtain precisely the same slicing information as that of the
node it‚Äôs being merged with. A key step involved in the construc-
tion of our CFG, which we call the Path-Sensitively Sliced CFG
orPSS-CFG , is ‚ÄúTree Slicing‚Äù, a powerful technique to merge and
slice arbitrarily different SE sub-trees under certain conditions.
Our main result is that the PSS-CFG, when ‚Äúdecompiled‚Äù (or
transformed) into regular programs that can be directly used by ap-
plications which query target variables (e.g., a concolic tester that
targets the program‚Äôs outputs, or a veriÔ¨Åer with a safety property),
produces signiÔ¨Åcant improvement in terms of time usage as com-
pared to using the original program. The strength of the PSS-CFG
is that it can be used ‚Äúout-of-the-box‚Äù by a wide number of third-
party software engineering applications. We consider two main ap-
plications - program testing and veriÔ¨Åcation, and show in Section 6
how they can beneÔ¨Åt from the PSS-CFG to gain in performance.
2. RELATED WORK
With regards to performing an ‚ÄúofÔ¨Çine‚Äù program transforma-
tion for general use, our closest related work is [3], performing
a path-sensitive transformation with an aim to ‚Äúimprove the path-
insensitive analysis used inside the F-S OFT tool to obtain the ef-
fects of path-sensitive analysis‚Äù. The main difference is that their
transformation only removes infeasible paths from the CFG with-
out performing slicing. As a result, it is not clear how the per-
formance of a veriÔ¨Åer or tester could be improved because they
are themselves path-sensitive and would not consider the infeasible
paths anyway. Hence, their target application is a path-insensitive
analyser within F-S OFTthat can beneÔ¨Åt from the removal of infea-
sible paths, as it would spuriously consider them otherwise. Nev-
ertheless we share with them the high level goal of performing an
‚ÄúofÔ¨Çine‚Äù program transformation that helps an external application.
Since program transformation is a speciÔ¨Åc area, we also discuss
related work that do not perform transformation but still provide
beneÔ¨Åts of path-sensitivity for external consumption. In this regard,
another related work is [6] that discards irrelevant tests in concolic
testing by tracking values read and written by executed program
statements. Then, when two states differing only in program val-
uesnot subsequently read are visited, the exploration of the second
state can be pruned. The main difference is that they use live range
information of variables to make the decision about pruning paths,
which results in lesser pruning compared to our method that uses
slicing (speciÔ¨Åcally, dependency information). Moreover they do
not perform program transformation themselves, but work with the
concolic tester to discard certain tests during execution. Thus, they
are dependent on the external application, whereas we perform an
ofÔ¨Çine transformation that is independent of the application.
Another related work is [17] that performs slicing of paths, but
their goal is to reduce the size of the counterexample path generated
by CEGAR-based veriÔ¨Åers during their process. As a result, they
do not work with the entire program‚Äôs CFG and hence, they are not
concerned with splits and merges in the CFG. However a programtransformation algorithm like ours needs to work with the whole
CFG to decide where to split or merge. Slicing as a precursor to
model checking has also been shown to be effective in [12].
The recent work [18] performs dynamic state merging during
symbolic execution in order to combine paths. While reducing the
number of paths, the formulas corresponding to merged states are
more complicated. They showed that their chosen heuristic for de-
ciding which states are merged produced signiÔ¨Åcant speedups. A
similarity to our paper here is that we also perform state merging
but we do so by learning when different states need not be explored.
Also, [18] does not consider slicing, but our algorithm merges only
when it can guarantee lossless-ness of slicing (dependency) infor-
mation. State merging in the context of dynamic symbolic execu-
tion has also been studied in a more recent work [2].
We will see in Section 5 that our method uses interpolation to
perform state merging. Interpolation has been used in program
testing and veriÔ¨Åcation [19, 16, 20, 13] to reduce state space and
contain ‚Äúpath-explosion‚Äù. However the similarity with our paper is
only in the use of interpolation for state merging. Our method has
to additionally guarantee that the merging is lossless , something
that is inapplicable to these works. Also, in Section 6, we exper-
imentally evaluate the PSS-CFG using applications of testing and
veriÔ¨Åcation, which may be another source of confusion with these
works. The fundamental difference is that these works involve di-
rectly performing the testing or veriÔ¨Åcation process on the program.
We simply evaluate the PSS-CFG on third-party testing and veriÔ¨Å-
cation tools to show that they beneÔ¨Åt in performance (in fact, [19]
is one of the veriÔ¨Åers we use). But the PSS-CFG is a much more
generic object not limited to just testing and veriÔ¨Åcation.
We Ô¨Ånally mention the work [15] which performed static slicing.
The technical approach there was to Ô¨Årst generate a path-sensitive
symbolic execution tree which then was used to determine which
primitive program statements could be sliced. It performed slicing
on the program, using the symbolic tree to slice a statement that
does not affect the target anywhere in the tree. In contrast, here we
perform slicing on the tree itself to transform it into a new tree us-
ing the transformation rules. Our method allows the same program
statement to be sliced form one part of the tree but not another, a
scenario in which [15] simply cannot slice the statement from the
program at all. This fundamental difference will be exposed in the
example in Section 3. Moreover, a key technical slicing step of our
method, called ‚ÄúTree slicing‚Äù, involves slicing a compound state-
ment from a tree , a problem not relevant to [15]: in general, the
symbolic execution subtrees rooted at what corresponds to the end
of a compound statement may not be identical. A main theoret-
ical result of this paper, concerning the correctness of the trans-
formation (Theorem 2), is that under certain conditions formalised
in Theorem 1, we can correctly slice away the entire compound
statement, and merge the following subtrees even though they are
different, while still retaining the necessary equivalent behavior of
the original program on the target variables.
3. BASIC IDEA
Consider the program in Fig. 1, where a read call signals a
concolic tester to generate an input, and the target of interest is the
variable zin the end. The program has two inputs canddwhich
decide the control Ô¨Çow and 8 paths to traverse. At the outset, note
that no static slicers, even path-sensitive ones like [15] or the well-
known Frama-C [8], are effective on this program because each
statement along some path affects the target.
Our algorithm has two steps: Ô¨Årst, it performs symbolic execu-
tion to generate the SE tree annotated with dependency information
at each node (Fig. 1(b)). The goal here is to be as path-sensitiveif(read(c)) flag=1
elseflag=0
x=2
if(read(d)) y=4
elsey=5
if(flag) z=y+x
elsez=x+1
TARGET(z)
c
flag=1
x=2
d
y=4
flag
z=y+x!d
y=5
!flag!c
<flag=1,{y,x}><flag=1,{d,x}>flag=0
x=2
d !d
y=4 y=5
flag !flag
z=x+1<flag=0
{x}><flag=0
{x}>
<true,{z}> <true,{z}><false,{}>
c
x=2
d
y=4
z=y+x!d
y=5!c
x=2
z=x+1if(read(c)) {
x=2
if(read(d))
y=4
else
y=5
z=y+x
}
else {
x=2
z=x+1
}Figure 1: (a) A program (b) its symbolic execution tree (c) its PSSCFG and (d) the corresponding decompiled program
as possible since it makes dependency information more precise.
However since path-sensitivity also makes the SE tree exponential
in the number of branches, we try to keep its size in check by merg-
ingwhile ensuring this does not cause imprecision of dependencies.
In the second step, transformation rules are applied on the SE tree
to get the Ô¨Ånal PSS-CFG (Fig. 1(c)). These rules take advantage of
the precise dependency information obtained in the Ô¨Årst step.
In Fig. 1(a), our algorithm Ô¨Årst encounter a branch on c. To
be path-sensitive, it splits symbolic execution into two ‚Äì one with
context cand the other with context !c. In a DFS fashion, it
Ô¨Årst explores the context c, symbolically executing the statements
flag=1 andx=2 and as usual, carrying these path constraints in
a logic formula. Upon reaching the next branch, it again splits into
two ‚Äì with context dand!d. Continuing along the context dit
executes y=4 and reaches the Ô¨Ånal branch. Again it splits into two
‚Äì with context flag and!flag , following the former and Ô¨Ånally
executing z=y+x before reaching the terminal point.
At this point the path formula is represented by the constraints:
c^flag = 1^x= 2^d^y= 4^flag^z=y+x1which is satisÔ¨Å-
able, meaning the path is feasible. Our algorithm now generates the
backwards dependency information for this feasible path, resulting
in the dependency set fzg, the target at the terminal point. This
is then propagated back to the branch point on flag by applying
Weiser‚Äôs formulas [23], resulting in the set fy;xg. In addition to
the dependency set, our algorithm also computes the witness path
for each variable in the set. A witness path for a variable at a par-
ticular node in the SE tree is a path from that node along which the
variable affects the target in the end, i.e., it is a ‚Äúwitness‚Äù for the
variable affecting the target. The witness path for the set fy;xgis
the path executing flag andz=y+x , corresponding to the formula
flag^z=y+x. To avoid cluttering, we do not show the witness
paths in Fig 1(b). Witness paths are needed to ensure there is no
loss of dependency information when we merge two nodes later.
Next, our algorithm backtracks and explores the other context
from the last split point: !flag . The path formula c^flag =
1^x= 2^d^y= 4^:flag is unsatisÔ¨Åable, hence the path is
infeasible. Now it computes an interpolant , a formula that captures
the essence of infeasibility of the path at the branch point. The
purpose of the interpolant is to exclude irrelevant information per-
taining to the infeasibility so that merging of another node with the
1We omitted the read calls, which only the tester understands.current one is more likely to happen in future. For the above path,
one possible interpolant at the branch point is flag = 1 which is
enough to capture the inconsistency with :flag . There are numer-
ous methods to compute interpolants (e.g., weakest preconditions)
and the quality of the interpolant will affect the amount of merging
performed by our algorithm. The interpolant at a terminal node is
true and the interpolant at an infeasible node is false , as shown.
In summary, our method computes at each node in the SE tree:
(a) the dependency sets (b) witness paths from feasible paths (c)
interpolants from infeasible paths. At the branch point on flag ,
these arefy;xg,flag^z=y+xandflag = 1, respectively.
The astute reader might have noticed that our algorithm did not
include the variable flag in the dependency set, whereas a tradi-
tional slicer such as [8, 15] would have included it due to control
dependency. The reason is that along this particular path only one
branch, the one where flag is true (non-zero), is feasible and the
other is infeasible. That is, flag is always true at this point along
this path. Hence the value of flag does not affect the execution
of the statement z=y+x , therefore it is not control-dependent on
flag . However, flag being true is needed to preserve the infea-
sibility of that branch and this is captured in the interpolant.
Next our algorithm backtracks again to the previous split point
to explore the other branch: !d. It executes the statement y=5 and
reaches the branch on flag , this time under the different context
!d. Now, the most important step of checking whether the current
context of the branch can be merged with the previously explored
context is performed. First, our algorithm makes sure the merging
iscorrect by checking if current path formula c^flag = 1^x=
2^:d^y= 5 implies the interpolant flag = 1. This check
succeeds, meaning that this context can be merged soundly with the
previous one2. Next it makes sure the merging will incur no loss of
precision by checking if the witness path from the previous context
flag^z=y+xis feasible in the current context. Indeed it is,
as the current path formula is consistent with the witness formula.
Therefore, the current context of the branch on flag is merged
with the previous context without any loss of precision. This is
formalised in Theorem 1, that says if both checks succeed, then by
exploring the current context of the node one would obtain exactly
the same dependency information as the node it‚Äôs being merged
with. The merging is denoted by the green dashed arrow in Fig 1(b).
2The concept of soundness is formalised later in Lemma 1.Our algorithm now propagates backwards the dependency sets,
interpolants and witness paths to the previous branch on d, re-
sulting in the setfd;xg, interpolant flag = 1, and witness path
d^y= 4^flag^z=y+x. Note that this time, it consid-
ered the control-dependence of yondas both paths from the d
branch were feasible, thus adding dto the dependency set. It then
backtracks to the Ô¨Årst split point on cand explores the other branch
!c. Upon reaching the branch on dagain, it tries to merge with
the previous context of the branch by checking if the current path
formula:c^flag = 0^x= 2implies the interpolant flag = 1.
It does not, so the merging cannot be performed and so it proceeds
to explore the rest of the tree under the node, resulting in the Ô¨Å-
nal SE tree as shown in Fig. 1(b). We do not explain the process
again as it is very similar to the left half of the SE tree. How-
ever there are a few important things to note in the Ô¨Ånal tree. The
branch on dis duplicated due to the split at the previous branch
onc. However under the context !c, the dependency set at the
branch point on flag is onlyfxgas opposed tofy;xgunder the
context c, because here there is no data-dependency of zony.
This is the advantage of path-sensitivity ‚Äì we have obtained a more
precise dependency information at a different context of the same
program point by considering the contexts separately, although at
the price of duplication of the dbranch. However we will see soon
that because of the more precise information, the duplication can
be controlled by slicing.
In phase two of our algorithm, we apply three transformation
rules that will process the SE tree annotated with dependency infor-
mation to transform it into the Ô¨Ånal PSS-CFG. We give an informal
description of each rule here, as they are formalised in Section 5.2.
Rule 1 , the traditional slicing rule, states if the LHS of an
assignment statement does not occur in the dependency set
after it, the statement can be removed.
Rule 2 states that if a branch point has only one feasible path
arising from it, the branch point can be removed. The rea-
soning is that if a branch point has only one feasible path
from it, then in that particular context the branch condition
can be deterministically evaluated to true (or false). Thus it
can simply be replaced with the ‚Äúthen‚Äù (or ‚Äúelse‚Äù) body.
Rule 3 (called ‚ÄúTree Slicing‚Äù), which is more powerful in
reducing the PSS-CFG‚Äôs size, states that an entire branch is
irrelevant to the target and can be removed if both the ‚Äúthen‚Äù
and ‚Äúelse‚Äù bodies contain no statement that is included in the
slice. This rule is more complicated than it seems at Ô¨Årst
because working with trees, a problem arises when we re-
move a branch point: conceptually there could be twosub-
trees whose parent, the branch point, is about to be removed.
The two sub-trees could be arbitrarily different because of
the different contexts leading into them. Which one should
be linked to the branch point‚Äôs parent? The rule guarantees
that regardless of which sub-tree is picked, the transforma-
tion is still sound, provided that our algorithm declared the
sub-trees to be merged. This important non-trivial result is
formalised in Section 5.2, and is one of the many fundamen-
tal differences between our transformation method and static
slicing methods, that slice on the program, not the tree.
Note that in general, the rules are not limited to the above three, and
one can indeed formulate more sophisticated rules. For instance,
amorphous slicing [11] can be applied to further elide statements
from the SE tree, where it is more likely to be useful compared
to applying on the original CFG, as the SE tree exposes differentsymbolic paths leading to a program point. For our benchmarks,
however, the above three rules were sufÔ¨Åcient to provide beneÔ¨Åt.
These rules are applied on the SE tree until none of them can be
applied any more, and the resultant graph is the PSS-CFG.
In our example, applying Rule 1 on the SE tree removes the state-
ments flag=1 andflag=0 . Applying Rule 2 removes the two
branches on flag that have an infeasible path. More interesting
is the application of Rule 3. It cannot be applied on the dbranch
under the context cbecause in that context, y=4 andy=5 are in-
cluded in the slice (the dependency set after the branch is fy;xg).
However, it can indeed be applied on the dbranch under the con-
text!cbecause neither y=4 nory=5 is included in the slice (the
dependency set after the branch in this context is only fxg), and our
algorithm had merged the symbolic state after its ‚Äúthen‚Äù and ‚Äúelse‚Äù
body. Thus, Rule 3 removes the dbranch under the context !cbut
not in the context c, to get the Ô¨Ånal PSS-CFG in Fig. 1(c). This re-
duction of the graph due to slicing complements the blow-up due to
path-sensitivity, and is critical to maintaining the PSS-CFG‚Äôs size.
Finally, note that Rule 3 cannot be applied on the top-level cbranch
because the two subtrees after its ‚Äúthen‚Äù and ‚Äúelse‚Äù body have not
been merged. This means the split due to the cbranch is causing
some differences in the two subtrees related to the target, and so re-
moving the branch could make the PSS-CFG incorrect. Indeed, the
cbranch assigns different values to flag which ultimately causes
different values to be assigned to the target z. Thus the branch must
be kept to preserve the original program‚Äôs semantics.
Finally, as a third step of our algorithm, we produce an equiva-
lent C program from the PSS-CFG by ‚Äúdecompiling‚Äù it. The de-
compilation process is quite straightforward so we do not detail it
here. It is done primarily so that external off-the-shelf applications
can be executed on the PSS-CFG. The decompiled program for our
example is shown in Fig. 1(d). At the outset, one can notice that the
decompiled program has only 3 paths compared to 8 paths in the
original program. Moreover, information that cannot be captured
from the original program can be captured by the decompiled pro-
gram. For instance, a concolic tester on the original program will
always generate a value for dregardless of the value generated for
c. However in the decompiled program, if the value of cwas gen-
erated to be 0, the tester would not generate the value of dbecause
it will not affect the target z. It can also be seen that the variable
flag , which was mainly used for control Ô¨Çow between different
parts of the code, is not even present in the decompiled program.
This information cannot be captured by static slicers like [8, 15],
which cannot statically remove the assignments to flag or the
branch on flag from the program without becoming unsound.
Remark. One might wonder if our complete algorithm to pro-
duce the PSS-CFG is equivalent to simply expanding the paths of
the original program producing a semantically equivalent program,
deleting the infeasible paths, and applying standard slicing wrt the
target. Even though conceptually it may be similar, there are many
practical differences with our method. Without the merging per-
formed by our algorithm, one would run into exponential blowup of
paths during symbolic execution, before even producing the seman-
tically equivalent program. Even if a merging mechanism is used
to contain the blowup, without the guarantee of lossless merging
provided by our algorithm, one could obtain imprecise dependency
information thereby keeping irrelevant statements in the new pro-
gram. However, our algorithm provides the right balance between
precision and performance of such a target-based transformation.
Thus, the process of constructing the SE tree and the process of de-
pendency computation are closely intertwined and cannot be sepa-
rated and outsourced to an external slicer.4. BACKGROUND
Syntax . We restrict our presentation to a simple imperative pro-
gramming language where all basic operations are either assign-
ments or assume operations, and the domain of all variables are
integers. The set of all program variables is denoted by Vars. An
assignment x := e corresponds to assign the evaluation of the ex-
pression eto the variable x. In the assume operator, assume (c), if
the boolean expression cevaluates to true, then the program contin-
ues, otherwise it halts. The set of operations is denoted by Ops. We
then model a program by a transition system . A transition system is
a quadrupleh;I; !;Oiwhere is the set of states and I
is the set of initial states.  ! Ops is the transition
relation that relates a state to its (possible) successors executing
operations. This transition relation models the operations that are
executed when control Ô¨Çows from one program location to another.
We shall use `op   !`0to denote a transition relation from `2to
`02executing the operation op2Ops. We shall also use a simi-
lar notationop   !0to denote a transition from the symbolic state
to0corresponding to their program locations. Finally, O
is the set of Ô¨Ånal states.
Symbolic Execution . Asymbolic state is a tripleh`;s;i. The
symbol`2corresponds to the current program location. We
use special symbols for initial location, `start2I, and Ô¨Ånal lo-
cation,`end2O. The symbolic store sis a function from pro-
gram variables to terms over input symbolic variables. The eval-
uation JcKsof a constraint expression cin a storesis deÔ¨Åned as:
JvKs=s(v)(ifvis a variable), JnKs=n(ifnis an integer),
Jeope0Ks=JeKsopJe0Ks(wheree;e0are expressions and opis
a relational or arithmetic operator).
Finally, is called path condition , a Ô¨Årst-order formula over
the symbolic inputs that accumulates constraints which the inputs
must satisfy in order to follow the corresponding path. The set of
Ô¨Årst-order formulas and symbolic states are denoted by FOL and
SymStates , respectively. Given a transition system h;I; !;Oi
and a stateh`;s;i2SymStates , the symbolic execution of
`op   !`0returns another symbolic state 0deÔ¨Åned as:
0,8
<
:h`0;s;^JcKsi ifopassume (c) and
^JcKsis satisÔ¨Åable
h`0;s[x7!JeKs];iifopx := e(1)
Note that Equation (1) queries a constraint solver for satisÔ¨Åability
checking on the path condition. We assume the solver is sound but
not necessarily complete. That is, the solver must say a formula is
unsatisÔ¨Åable only if it is indeed so.
Abusing notation, given a symbolic state h`;s;iwe deÔ¨Åne
JK:SymStates!FOL as the formula (V
v2VarsJvKs)^
where Vars is the set of program variables.
Asymbolic path 01:::nis a sequence of symbolic
states such that8i1inthe stateiis asuccessor ofi 1. A
symbolic state 0h`0;;iis a successor of another h`;;iif
there exists a transition relation `op   !`0. A path01:::n
isfeasible ifnh`;s;isuch that JKsis satisÔ¨Åable. If `2O
andnis feasible then nis called terminal state. Otherwise, if
JKsis unsatisÔ¨Åable the path is called infeasible andnis called
aninfeasible state. If there exists a feasible path 01:::n
then we sayk(0kn) isreachable from0ink steps .
We also deÔ¨Åne a (partial) function MergePoint :SymStates!
SymStatesSymStates that, given a symbolic state h`;;iif
there is an assume statement at (i.e.,`corresponds to a branch
point), returns a tuple h1h`0;;i;2h`0;;iisuch1and
2are reachable from , and`0is the nearest post-dominator of`. In other words, 1and2are the symbolic states at the merge
point reached through the ‚Äúthen‚Äù and ‚Äúelse‚Äù body respectively.
Asymbolic execution tree contains all the execution paths ex-
plored during the symbolic execution of a transition system by trig-
gering Equation (1). The nodes represent symbolic states and the
arcs represent transitions between states.
Dependency computation via Abstract Interpretation . The back-
ward dependency computation process starts from `endwith a set of
‚Äútarget variables‚ÄùV Vars, for which the program transformation
is being performed. To compute the dependencies, we follow the
dataÔ¨Çow approach described by Weiser [23] reformulated as an ab-
stract domainDf?g[P (Vars)(whereP(Vars)is the powerset
of program variables) with a lattice structure hv;?;t;u;>i, such
thatv ,t[ , andu\ are conveniently lifted to consider
the element?.
We say2D is the approximate set of variables at the sym-
bolic statethat may affect variables in V.Backward data de-
pendencies can then be formulated as follows. Given a transition
relationop   !0we deÔ¨Åne def(op) and use(op) as the sets of vari-
ables written to and read during the execution of op, respectively.
Then,
,
(0ndef(op))[use(op) if0\def(op)6=;
0 otherwise(2)
where0=Vif0h`end;;i. In the Ô¨Årst case of Eqn. 2, we
say thatop   !0is ‚Äúincluded in the slice‚Äù.
Backward control dependencies can also affect variables in V. A
transition relation op   !0where opassume (c) is in-
cluded in the slice if any transition relation from to its nearest
post-dominator is included in the slice3. Then,
,0[use(op) (3)
Finally, a function dpre(0;op)that returns the pre-stateafter
executing backwards the operation opwith the post-state0is
deÔ¨Åned using Eqs. (2,3).
Tree transformation rules . The SE tree produced by our algo-
rithm, together with the dependency information of each symbolic
state, is represented using the set Soffacts of the following types:
edge (op   !0), denoting a feasible edge from to0
inf_edge (op   !0), denoting an infeasible edge from to
0
merged (;0), denoting that has been merged with 0
(will be formalised later)
in_slice (op   !0), denoting that the transition from to0
is included in the slice due to Eqs. 2,3.
Note that we do not explicitly store the dependency information
at each state, but rather just the fact whether a transition from the
state is included in the slice or not (denoted by the in_slice fact).
In Section 5.2, the transformation of the SE tree into the Ô¨Ånal PSS-
CFG will be modelled using certain rules that act upon these facts.
3We assume a function INFL ()that returns the set of transitions
fromto its nearest post-dominator ‚Äì the set of transitions ‚ÄúinÔ¨Çu-
enced‚Äù by.5. ALGORITHM
We describe our algorithm in two phases: in phase one (Sec-
tion 5.1), we explore symbolic paths in the program to generate
the symbolic execution (SE) tree annotated with dependencies. In
phase two (Section 5.2), we transform this tree by removing edges
and sub-trees, to Ô¨Ånally produce the PSS-CFG.
At a high level, our algorithm performs forward symbolic execu-
tion in a depth-Ô¨Årst manner interleaved with backward dependency
computation. Symbolic execution avoids the exploration of infeasi-
ble paths, thus increasing the precision of the computed dependen-
cies. However, it allows multiple copies of the same program point
to exist as different symbolic states , along different symbolic paths.
Thus an important challenge to overcome is to avoid this inherent
exponential blowup of symbolic execution.
Our solution is to merge different symbolic states provided cer-
tain conditions are met. These ‚Äúmerging conditions‚Äù guarantee that
the merge does not incur any loss of slicing information. To for-
malise these conditions, we deÔ¨Åne two key concepts:
DEFINITION 1 (I NTERPOLANT ).Given a pair of Ô¨Årst order
logic formulas AandBsuch thatA^Bisfalse , aninterpolant [7]
is another formula 	such that (a) Aj=	, (b)	^Bis false, and
(c)	is formed using common variables of AandB.
Interpolation has been prominently used to reduce state space blowup
in program veriÔ¨Åcation [20, 16] and testing [13]. Here we use it for
a similar purpose ‚Äì to merge states and thereby avoid redundant
exploration. However, in addition to merging states, we must also
guarantee lossless merging . Thus, we deÔ¨Åne:
DEFINITION 2 (W ITNESS PATHS & F ORMULAS ).Given a sym-
bolic stateh`;;iannotated with the set of dependency vari-
ables, awitness path for a variable v2is a feasible sym-
bolic path:::endsuch thatendh`end;;iand there
exists v 12V such that v 1is control- or data-dependent on v along
the path. We call JendKthewitness formula of v, denoted !v.
Intuitively, a witness path for a dependency variable at a symbolic
state is a path arising from it along which the dependency variable
affects the target variables at the end. The witness formula is the
path condition of its witness path.
To accommodate witness formulas in our abstract domain Dwe
redeÔ¨Åne it as follows: D,f?g[P (VarsFOL), i.e., set of pairs
of the formhx;!xiwherexis a variable and !xis its witness for-
mula. The abstract operations tandvstill stand for[and,
but the pre-operator dpreis slightly modiÔ¨Åed to propagate back wit-
ness formulas: the dependency variable xis still computed using
Eqs. 2,3 as before, while the pre-state witness formula for xis the
computed as the conjunction of the post-state witness formula for
xwith the logical constraint from the transition operation op. We
now formalise our merging conditions:
DEFINITION 3 (M ERGING CONDITIONS ).Given a current sym-
bolic stateh`;s;iand an already annotated symbolic state
0h`;s0;0isuch that 	0is the interpolant generated for 0
and0are the dependencies at 0, we sayismerged with0if
the following conditions hold:
(a) JKj=	0
(b)8hx;i209hx;!xi20s:t
JK^!xis satisÔ¨Åable(4)
Note importantly that both and0must correspond to the same
program point `in order to be merged. The condition (a) affectssoundness and it ensures that the set of feasible symbolic paths
reachable from is a subset of those from 0. This is a necessary
condition for two states to be merged.
LEMMA 1.Given states h`;s;iand0h`;s0;0i, let
	0be the interpolant for 0. If JKj=	0, the set of feasible
paths fromis a subset of those from 0.
PROOF .(By contradiction). Assume there exists a feasible path ,
with path condition , frombutis infeasible from 0. Ifis
infeasible from 0then J0K^is unsatisÔ¨Åable, and by deÔ¨Ånition
of interpolant, 	0^is unsatisÔ¨Åable. Since JKj=	0, it
follows that JK^is unsatisÔ¨Åable. However, since is feasible
from,JK^cannot be unsatisÔ¨Åable.
The intuition is that the interpolant 	0represents the reason of
infeasibility of all infeasible paths arising from 0. If JKj=	0,
any infeasible path under 0is also infeasible under . In other
words, any feasible path under is also feasible under 0.
The condition (b) is the witness check which essentially states
that for each variable xin the dependency set at 0, there must be
at least one witness path with formula !xthat is feasible from .
This affects accuracy and ensures that the merging of two states
does not incur any loss of precision. This is formalised as follows.
THEOREM 1.Given states h`;s;iand0h`;s0;0i,
let0be the dependencies and witness formulas associated with
0. Ifcan be merged with 0then by exploring there cannot be
produced a set of dependencies such that6=0.
PROOF .Assume that although can be merged with 0(i.e., both
conditions of Eqn. 4 are satisÔ¨Åed), it is instead symbolically ex-
plored and a dependency set is obtained.
Proof that0:Sincecan be merged with 0, by con-
dition (b) of Eqn. 4, 8hx;i20, there is a witness path, say x,
with formula !xsuch that JK^!xis satisÔ¨Åable. That is, xis
feasible from . By the deÔ¨Ånition of a witness path (DeÔ¨Ånition 2),
9v12V s.tv1is control- or data-dependent on xalong the path
x, which is feasible from . Thereforexmust be in.
Proof that0:(by contradiction) Assume 9x2s.t
x =20. Then, the witness path for x,xwith formula !xmust
be such that JK^!xis satisÔ¨Åable but J0K^!xis unsatisÔ¨Åable
(otherwise from the deÔ¨Ånition of a witness path, xwould have been
included in0). That is,xis feasible from but infeasible from
0. From Eqn. 4 condition (a) and Lemma 1, this is impossible.
5.1 Generating the SE Tree Structure with De-
pendencies
The purpose of our main algorithm, G ENPSSCFG (Fig. 2), is
to generate a Ô¨Ånite symbolic execution tree annotated with depen-
dency information at each symbolic state. As mentioned in Sec-
tion 4, the tree is represented using a set of facts that are added
to the setS, which is assumed to be a global variable to the al-
gorithm. G ENPSSCFG requires the program to have been trans-
lated to a transition system h;I; !;Oiin SSA form, and ac-
cepts a symbolic state as argument. It is initiated with the state
h`start;;truei. GENPSSCFG implements a mutually recur-
sive algorithm with a few other procedures.
First, the most important decision of whether to merge a sym-
bolic state with another is taken by G ENPSSCFG at line 1. It at-
tempts to Ô¨Ånd another symbolic state 0such thatand0satisfy
the two merging conditions in Equation 4. If yes, it merges with
0by calling the procedure M ERGE at line 2. If such a 0does
not exist, G ENPSSCFG decides whether to split the symbolic ex-
ecution ofor not by checking if corresponds to a branchingGENPSSCFG (h`;s;i)
1:if90h`;s0;0is.t.and0satisfy Eqn. 4
2: then MERGE (,0)
3:else ifis at a branch point then
4: S PLIT()
5:else
6: S YMEXEC ()MERGE (,0)
1:	:=	0
2::=0
3:S:=S[merged (;0)
SPLIT (h`;s;i)
1:	:= true
2:foreach transition`assume(c)      !`0do
3: if(is a loop header) then
4:0,h`0;;invariant ()^JcKsi
5: else
6:0,h`0;s;^JcKsi
7: if0is infeasible state then
8:S:=S[inf_edge (assume(c)      !0)
9: 	0:= false,0:=;
10: else
11:S:=S[edge (assume(c)      !0)
12: G ENPSSCFG (0)
13:	:=	^dwlp(	0,assume(c) )
14::=tdpre(0,assume(c) ,s)
15: ifassume(c)      !0satisÔ¨Åes Eqn. 3 then
16:S:=S[in_slice (assume(c)      !0)SYMEXEC (h`;s;i)
1:if@transition relation `x:=e  !`0then
2:	:=true,:=V
3:else
4:0,h`0;s[x7!JeKs];i
5:S:=S[edge (x:=e  !0)
6: if0is not a loop header
7: G ENPSSCFG (0)
8:	:=dwlp(	0,x:=e )
9::=dpre(0,x:=e )
10: ifx:=e  !0satisÔ¨Åes Eqn. 2 then
11:S:=S[in_slice (x:=e  !0)
Figure 2: Symbolic execution interleaved with dependency computation to produce the SE tree
point in the program (line 3). If yes it calls the procedure S PLIT
at line 4 which, as we will see, forks the symbolic execution of
different branches from . If both the above cases do not match,
GENPSSCFG simply continues the symbolic execution by calling
the procedure S YMEXEC with. G ENPSSCFG is in essence the
high level backbone of our method.
The procedure M ERGE , given a current symbolic state and an
already explored state 0, merges the former with the latter by set-
ting the interpolant and dependency set of to those of0. Recall
that Theorem 1 guaranteed such a merge to have no loss of preci-
sion. That is, had been explored instead of being merged with 0,
the resulting dependency set at would be exactly 0. Finally the
procedure adds the fact merged (;0)toSto record the merge
between the two states.
The procedure S PLIT is used to fork the symbolic execution of
a state from which multiple transitions are possible (typically a
branch point). Given a symbolic state with program point `and
path condition , it Ô¨Årst initialises its interpolant 	to true at
line 1. At line 2 it iterates its main body over each transition pos-
sible from. Now there is an issue: if the current state is a loop
header (line 4), then symbolically executing the loop could result
in an unbounded tree, which we want to avoid. Therefore, we need
to execute the loop with a loop invariant to make the tree Ô¨Ånite.
Our method to compute a loop invariant is simple but effective:
from the loop header‚Äôs symbolic state , we only keep the con-
straints that are unchanged through the loop, and delete the rest.
For instance, if x>5holds at the loop header and xis only incre-
mented in the loop, then x>5is unchanged through the loop. This
widened state at ultimately forms a loop invariant. This technique
provides a balance between getting the strongest invariant ‚Äì whichis needed to maximise path-sensitivity ‚Äì and efÔ¨Åciency. We found
experimentally that this technique preserves most of the important
information through the loop. Nevertheless, we remind the reader
that no matter what the invariant is, it does not affect the guaran-
tee of lossless-ness of dependency information during our merging,
and the correctness of our transformation as stated by Theorem 2.
We assume a function invariant that given a symbolic state ,
returns a FOL formula representing the loop invariant. With this
invariant, the next state is constructed by augmenting it with JcKs
where cis the branching condition of the assume statement (line 4).
If not,0is constructed (line 6) by augmenting the path condition
with JcKs. At line 7 an important check is performed: if 0is an
infeasible state (i.e., the augmented path condition is unsatisÔ¨Åable),
it means symbolic execution has encountered an infeasible path.
Therefore it adds to Sthe fact that the transition from to0is
infeasible (line 8), and sets the interpolant and dependency set of
0to false and;respectively (line 9) to signify that the state is
unreachable. Otherwise it adds a normal edge to Sat line 11 and
(mutually) recursively calls G ENPSSCFG with 0.
In either case, 0would have been annotated with an interpolant
	0and dependency set 0. Now it computes the same informa-
tion forat lines 13-14. The interpolant 	is supposed to gen-
eralise the SE tree below while preserving its infeasible paths.
For this, the procedure dwlp:FOLOps!FOL is called that
ideally computes the weakest liberal precondition [9], the weakest
formula on the initial state ensuring the execution of assume(c)
results in the state 	0. In practice we approximate wlpby making
a linear number of calls to a theorem prover following techniques
described in [16], usually resulting in a formula stronger than the
weakest liberal precondition. The dependency set is computedRULE 1 (S TRAIGHT LINE SLICING )
E1edge (0op   !1)2SE2edge (1x:=e  !2)2S in_slice (1x:=e  !2)=2S
S:=SnfE1;E2g[f edge (0op   !2)g
RULE 2 (I NFEASIBLE PATH REMOVAL )
E1edge (0op   !1)2SE2edge (1assume(c 1)      !2)2SE3inf_edge (1assume(c 2)      !3)2S
S:=SnfE1;E2;E3g[f edge (0op   !2)g
RULE 3 (T REE SLICING )
edge (0op   !1)2S edge (1assume(c 1)      !2)2S edge (1assume(c 2)      !3)2S26=3
in_slice (1assume(c 1)      !2)=2S in_slice (1assume(c 2)      !3)=2S hk;0
kiMergePoint (1) merged (k;0
k)2S
S:=Snf edge (0op   !00)j0op   !002INFL (1assume (c1)      !2)_0op   !002INFL (1assume (c2)      !3)g[f edge (0op   !k)g
Figure 3: Transformation rules to produce the Ô¨Ånal PSS-CFG
by applying the pre-operation dpreon0and joining with any ex-
isting set (across different iterations of the main loop).
Finally, in lines 15-16 of S PLIT, it checks if any transition from
to its nearest postdominator is included in the slice (Eqn. 3). If
yes, it adds an in_slice fact toSwith the transition from to0.
The Ô¨Ånal procedure S YMEXEC is called by G ENPSSCFG when
the current symbolic state corresponding to program point `can-
not split (typically an assignment statement). Initially, at line 1, it
checks if there exists a program transition from `to any other `0.
If not, symbolic execution has reached the end of a (feasible) path
whose Ô¨Ånal state is . In other words, it has reached a terminal
node. Hence it sets the interpolant 	to true and its dependency
settoV(recall that the target variables are speciÔ¨Åed at `end) at
line 2.
If there exists a transition from `to say`0with the assignment
x:=e , it constructs the next symbolic state (line 4) 0by setting in
the storesthe value of xtoJeKsand adds toSthe appropriate
edge fact (line 5). Then, if 0is not a loop header, it recursively
calls G ENPSSCFG with 0(line 7). If0is a loop header, then
there is no need to explore it again since it would have already been
explored with the loop invariant (at S PLIT line 4). Our algorithm
thus makes the symbolic execution Ô¨Ånite. In S YMEXEC line 8 and
9, it sets the interpolant (and dependency set) of by callingdwlp
(anddpre) on the interpolant (and dependency set) of 0. Finally, at
lines 10-11, if xcontains a variable in 0(Eqn. 2) it adds toSthe
fact that the transition from to0is included in the slice.
To perform the Ô¨Åxpoint computation at the highest level, we keep
making calls to G ENPSSCFG until there is no change in S. This is
the simplest way to describe the Ô¨Åxpoint computation but in prac-
tice we can optimise it by calling G ENPSSCFG with the symbolic
state of the loop header in which the change was detected.
5.2 Transformation of the Annotated SE Tree
The algorithm described so far produces a symbolic execution
tree represented as a set of facts S. Now we present certain rules
in Fig. 3 that act upon Sto modify it, in essence modelling the
transformation of the SE tree into the Ô¨Ånal PSS-CFG. The rules
are presented in a declarative fashion and can be implemented con-
veniently in a rule-based programming language (e.g., Constraint
Handling Rules).
STRAIGHT LINE SLICING states that if there is a transition (or
edge ) from state 0to1and an assignment transition from 1
to2such that the latter is not included in the slice, then both tran-sitions can be removed and replaced with one linking 0directly to
2. This is the typical rule for slicing assignment statements using
dependencies.
INFEASIBLE PATH REMOVAL states that if there is a transition from
state0to1, and1is abranch point such that there is branch-
ing edge ( edge ) from1to2and an infeasible branching edge
(inf_edge ) from1to another3, then all three edges can be re-
moved and0can be directly linked to the feasible state 2.
TREE SLICING is more complicated and the most powerful in terms
of reducing the symbolic state space of the PSS-CFG. It states that
if there is a transition from 0to1, and1is a branching point
with branching transitions to 2(with condition assume(c 1)) and
3(with condition assume(c 2)) such that neither transition is in-
cluded in the slice, then we can remove all transitions 0op   !00
that occur either in the dynamic range of inÔ¨Çuence (given by INFL )
of1   !2or1   !3. In other words, we can remove all
transitions that occur in the ‚Äúthen‚Äù or ‚Äúelse‚Äù body of the branch at
1. But there is a problem: since we are working on a symbolic
tree, removing the branch point 1would conceptually leave two
different subtrees ‚Äúhanging‚Äù without a parent. The question arises
as to which subtree should we link to the node 0. T REE SLIC -
INGguarantees that if the symbolic states at the end of the branch
hk;0
ki(as returned by MergePoint (1)) are merged by our al-
gorithm (i.e., merged (k;0
k)exists), the differences in the trees
do not affect the target variables. Hence it simply adds a transition
directly linking 0to one of the symbolic states k.
We explain the reasoning behind the above rules by deÔ¨Åning our
correctness statement for the transformation of the SE tree into the
PSS-CFG and providing a proof outline for it. First let two CFGs
be deÔ¨Åned equivalent wrt target variables Vif for any input, the
programs corresponding to both CFGs produce the same values for
all variables inV.
THEOREM 2.(Correctness of transformation) An application
ofRULE 1,RULE 2orRULE 3to a CFGGproduces a transformed
CFGG0such thatG0is equivalent to Gwrt target variables V.
PROOF OUTLINE . The correctness of S TRAIGHT LINE SLICING
follows directly from the correctness of slicing assignment state-
ments using dependency information, formalised in Eqn. 2. As for
INFEASIBLE PATH REMOVAL , for any input that executes a path
inGleading to the state 1, the condition c1will evaluate to trueBenchmark Lines of code Blow PSS #Rule Triggers
Orig St.slice PSS up Time Rul1 Rul2 Rul3
cdaudio 1817 1599 4452 2.78 24s 2685 1101 169
diskperf 937 706 2967 4.20 18s 1594 1132 73
Ô¨Çoppy 1005 766 2086 2.72 7s 1062 651 99
Ô¨Çoppy2 1513 1250 3507 2.81 16s 1514 819 120
kbÔ¨Åltr 549 275 170 0.62 1s 111 46 7
kbÔ¨Åltr2 782 492 410 0.83 1s 249 69 23
tcas 286 227 311 1.37 2s 138 204 47Testing Time Speed #Solver calls
St.slice PSS up St.slice PSS
1m30s 43s 2.1 16k 7k
900m 34m 26.5 26mil 1mil
9m6s 24s 22.8 260k 4k
525m 429m 1.2 613k 479k
2s 1s 2 63 52
22s 6s 3.7 7k 2k
4s 1s 4 1.5k 188
23h56m 7h44m 3.1 26.9mil 1.5mil
(a) (b)
Table 1: (a) Statistics about the PSS-CFG (b) Experiments on the PSS-CFG for concolic testing
andc2will evaluate to false. Moreover, an assume statement does
not modify any variable in the program state. Thus, both checks
assume(c 1)andassume(c 2)are useless because we determin-
istically know their outcomes, and hence can be replaced with a
transition linking 0to the next feasible state 2to produceG0.
The correctness proof of T REE SLICING is as follows. Assume
that some input executes a path in Gstarting from startto0and
then reaches 1. W.l.o.g, assume that the condition c1holds at1,
therefore it chooses to follow 2, reaches the merged point kand
continues to eventually reach the terminal state end. Let us call this
executed path G. InG0, obtained by applying T REE SLICING on
G, thereby removing the entire branch at 1, the same input would
follow a path, say G0, such thatG0is the exact same path as G
starting from starttill0, thus having the same symbolic state at
0. At this point, G0differs fromGby implicitly ‚Äúskipping‚Äù the
execution of the branch at 1and instead directly reaches k.
Sincekand0
kwere merged, the dependency sets at both points
are the same. Now, since the transition 1assume (c1)      !2inGwas
not included in the slice, it means that no statement ‚Äúskipped‚Äù by
G0affected the dependency information at k. This implies that
the symbolic state of the path G0atkis the same as the sym-
bolic state of the path Gatkas far as the dependency variables
atkare concerned . To be precise, the values of the dependency
variables atkare the same in both GandG0. Since these are
the only variables affecting the target variables Vatend, it is suf-
Ô¨Åcient to preserve their values to ensure that G0will produce the
same values forVasG. Of course G0may produce different
values thanGfor variables notinV, but we are not interested in
those variables.
The three rules are applied until Ô¨Åxpoint is reached (i.e., none of
them can be applied anymore). Termination of rule applications is
guaranteed from the initial Ô¨Åniteness of the set Sand the fact that
all three rules remove more edges from Sthan they add. Sound-
ness of individual rule applications is guaranteed from Theorem 2.
Transitiveness of the rules is also guaranteed by Theorem 2 since
each new CFG is equivalent to the previous CFG. Once Ô¨Åxpoint is
reached, the Ô¨Ånal PSS-CFG structure can be extracted from S.
Thus, Theorem 2 guarantees that the PSS-CFG is equivalent to
the original program wrt the target variables V. Therefore, any
analysis of the original program concerned only with Vcan be ap-
plied on the PSS-CFG instead to take advantage of its beneÔ¨Åts. We
will see two such applications: program testing and veriÔ¨Åcation.
6. EXPERIMENTAL EV ALUATION
We evaluate the PSS-CFG using applications of program testing
and veriÔ¨Åcation to show considerable increase in their performance.We implemented the algorithm on the TRACER [14] framework for
symbolic execution. Our proof-of-concept implementation models
the heap as an array. A Ô¨Çow-insensitive pointer analysis provided
by Crystal [22] is used to partition updates and reads into alias
classes where each class is modelled by a different array. Given
the statement *p=*q the set defcontains everything that might be
pointed to by pand the set useincludes everything that might be
pointed to by q. This coarse modelling of heaps does introduce im-
precision in the analysis, but it is orthogonal to our main contribu-
tion. Functions are inlined during symbolic execution and external
functions are modelled as having no side effects and returning an
unknown value.
We used device drivers from the ntdrivers-simpliÔ¨Åed category
of SV-COMP 2013 [4] and a trafÔ¨Åc collision avoidance program
called tcas as benchmarks, and chose the target variables from the
safety properties of the programs. All programs had multiple target
safety properties on several variables, all of which were included
in our slicing criteria. For practically applying external tools on the
PSS-CFG structure, we used its equivalent decompiled program.
Since both the original and decompiled programs are in C, we can
easily measure how external tools beneÔ¨Åt from our transformation.
For all our experiments we compare the PSS-CFG4with a static
slice of the benchmark program on the target variables. Comparing
with a static slice is more challenging as some statements would
have already been sliced away from the original program. We ob-
tained the static slice through the well-known state-of-the-art slicer
Frama-C [8, 1]. Frama-C is a path-sensitive static slicer that can
detect infeasible paths through techniques such as constant prop-
agation, constant folding and abstract interpretation. Also, before
the target variables are provided and our algorithm is initiated, we
process the program and store an intermediate representation (IR).
This processing involves computing information about infeasible
paths in the program and is completely independent of the target
variables. Then, when the target variables are provided, our algo-
rithm is invoked and it uses information from this IR. All experi-
ments were run on an Intel 3.2 Ghz system with 2GB memory.
Now, we provide statistics about the PSS-CFG and its construc-
tion in Table 1(a). The Lines of code column shows the number
of non-commented lines of code in the original ( Orig ) program, its
static slice ( St.slice ) and its decompiled program ( PSS ) respec-
tively. In the column Blowup we show the ratio of the LOC of
PSS-CFG compared to the static slice. The blowup is a result of the
balance between the splits introduced by path-sensitivity, and the
merges and slicing from our algorithm. It is clear that the blowup
is manageable, sometimes even smaller than the program, being
on average around 2. In the column PSS Time we show the time
4We use ‚Äúdecompiled program‚Äù and ‚ÄúPSS-CFG‚Äù interchangeably.IMPACT ARMC CPA -CHECKER
Benchmark
cdaudio
diskperf
Ô¨Çoppy
Ô¨Çoppy2
kbÔ¨Åltr
kbÔ¨Åltr2
tcas
TotalVeriÔ¨Åcation Time Speed
St.Slice PSS up
95s 14s 6.8
146s 18s 8.1
34s 8s 4.3
39s 13s 3.0
4s 1s 4.0
8s 2s 4.0
3s 1s 3.0
329s 57s 5.8VeriÔ¨Åcation Time Speed
St.Slice PSS up
T/O 21s N/A
T/O 6s N/A
259s 6s 43.17
T/O 17s N/A
3s 1s 3.00
13s 2s 6.50
3s 1s 3.00
T/O 54s N/AVeriÔ¨Åcation Time Speed
St.Slice PSS up
26s 14s 1.86
7s 6s 1.17
6s 5s 1.20
10s 8s 1.25
3s 2s 1.50
4s 2s 2.00
2s 1s 2.00
58s 38s 1.53
(a) (b) (c)
Table 2: Experiments on the quality of PSS-CFG for veriÔ¨Åcation times of different veriÔ¨Åers
taken in seconds for our algorithm to produce the PSS-CFG given
the target variables, which is modest. In the Ô¨Ånal column #Rule
Triggers we show the number of times each transformation rule
was triggered during PSS-CFG construction. Although R ULE 3
is shown to be triggered fewer number of times than R ULE 1 or
RULE 2, it is the most powerful rule in reducing the search space
of the PSS-CFG. In tcas we see R ULE 2 triggering more frequently
than R ULE1 due to its large number of infeasible paths.
Note that the PSS-CFG construction is only performed once for
a given set of target variables. The resulting program can however
be subjected to an innumerable number of properties to be veriÔ¨Åed
or tested. For example, using the same PSS-CFG, one can verify
different bounds on a target variable depending on different pre-
conditions to the program.
6.1 Testing (white-box)
We consider software testing an important application for the
PSS-CFG to be used. For this, we consider the typical DART [10]
methodology that performs concolic testing , i.e., executing the pro-
gram with both concrete and symbolic inputs and symbolically
negating branches to explore new paths. We chose the publicly
available concolic tester CREST , an implementation of DART for C
programs. Since the statically sliced and decompiled programs are
in C, the experiment was simply to run the concolic testing process
on both programs and measure the time taken to complete, i.e., time
taken to test all feasible paths in the program.
In Table 1(b), we show the measures of the experiment. The sec-
ond and third columns ( St.slice andPSS ) show the time taken to
complete the concolic testing process on the statically sliced and
decompiled programs respectively. The third column shows the
Speedup obtained by using the PSS-CFG, i.e., the ratio of the
columns St.slice andPSS . It is immediately apparent that the PSS-
CFG provides speedup in all benchmarks. In programs diskperf
andÔ¨Çoppy the speedup is exceptionally high around 22-26, re-
ducing the concolic testing time from, for instance, 900 minutes
(15 hours) to just 34 minutes. On the other hand, in Ô¨Çoppy2 the
speedup of 1.2 is not that high, but still the absolute beneÔ¨Åt in time
can be seen ‚Äì around 96 minutes or 1.5 hours. Ultimately, the to-
tal time taken for concolic testing to run on all our statically sliced
programs was almost 24 hours, whereas it took less than 8 hours
to run on the decompiled programs, providing a net beneÔ¨Åt in time
of a magnitude of 3.1. Although it is understood that in practice
concolic testing may not terminate by exploring all paths, we gave
a huge timeout (24 hours) for the process to terminate simply to see
how much beneÔ¨Åt the PSS-CFG can provide in timing. From the
table, it is clear that the PSS-CFG can make the difference between
termination and timing-out of the concolic testing process.In addition to time, we also measured the number of calls made
byCREST to its underlying solver. This measure, shown in the col-
umn#Solver calls , gives an idea of how the PSS-CFG would still
beneÔ¨Åt the concolic tester even if a different, faster solver was used.
Again we see several magnitudes of less solver calls for all bench-
marks when CREST was run on the PSS-CFG. The maximum bene-
Ô¨Åt is in diskperf where 26 million calls were made for the statically
sliced program, compared to only 1 million for the decompiled pro-
gram. This is in-line with the speedup in time for diskperf , around
26. This indicates that even if a faster solver is used, the relative
speedup in time for this benchmark would still be around 26, al-
though the absolute timings may be faster. Ultimately, this table
shows that concolic testing would deÔ¨Ånitely beneÔ¨Åt by using the
PSS-CFG instead of the statically sliced program.
6.2 VeriÔ¨Åcation
Another important application for the PSS-CFG is program veri-
Ô¨Åcation. In Table 2 we compare the veriÔ¨Åcation times of the bench-
marks across three different state-of-the-art veriÔ¨Åers: IMPACT [19],
ARMC [21] and CPA-CHECKER [5]. We chose this set of veri-
Ô¨Åers because they come from different approaches to veriÔ¨Åcation ‚Äì
interpolant-based, CEGAR -based and SMT-based. Since IMPACT is
not publicly available, we use CPA-CHECKER ‚Äôs implementation of
theIMPACT algorithm. In each table, the second and third columns
show the veriÔ¨Åcation time (in seconds) of the statically sliced pro-
gram ( St.Slice ) and the PSS-CFG ( PSS ), respectively. In the third
column Speedup , we show the ratio of St.slice toPSS .
For all three veriÔ¨Åers, it can be clearly seen that the PSS-CFG is
veriÔ¨Åed in a much faster time than the static slice. For IMPACT , ver-
ifying all statically sliced programs in our suite took 329 seconds
whereas verifying the respective PSS-CFGs took only 57 seconds.
Thus, the speedup across all programs on aggregate is 5.8. As for
ARMC , it was unable to terminate its veriÔ¨Åcation of the statically
sliced programs for cdaudio ,diskperf andÔ¨Çoppy2 with a time-
out of 10 minutes, whereas it was able to verify each of their re-
spective PSS-CFGs in less than 30 seconds, thus providing a huge
beneÔ¨Åt to ARMC . For CPA-CHECKER , the beneÔ¨Åt was relatively
smaller, providing on average a speedup of 1.5. The reason is be-
cause CPA-CHECKER is a more sophisticated veriÔ¨Åer than the other
two, but still the fact that the PSS-CFG provides a speedup for CPA-
CHECKER is to be considered noteworthy. Thus, we believe that the
PSS-CFG is quite a useful object in general for veriÔ¨Åcation.
7. ACKNOWLEDGEMENT
We would like to thank Jorge Navas for his contributions to this
work while at NUS.8. REFERENCES
[1] Frama-C Software Analyzers. http://frama-c.com/ .
[2] T. Avgerinos, A. Rebert, S. K. Cha, and D. Brumley.
Enhancing Symbolic Execution with Veritesting. ICSE,
2014.
[3] G. Balakrishnan, S. Sankaranarayanan, F. Ivancic, O. Wei,
and A. Gupta. SLR: Path-Sensitive Analysis through
Infeasible-path Detection and Syntactic Language
ReÔ¨Ånement. In SAS, 2008.
[4] D. Beyer. Second Competition on Software VeriÔ¨Åcation. In
TACAS , 2013.
[5] D. Beyer and M. E. Keremoglu. CPAchecker: A Tool for
ConÔ¨Ågurable Software VeriÔ¨Åcation. In CAV, 2011.
[6] P. Boonstoppel, C. Cadar, and D. R. Engler. RWset:
Attacking Path Explosion in Constraint-Based Test
Generation. In TACAS , pages 351‚Äì366, 2008.
[7] W. Craig. Three uses of Herbrand-Gentzen theorem in
relating model theory and proof theory. Journal of Symbolic
Computation , 22, 1955.
[8] P. Cuoq, F. Kirchner, N. Kosmatov, V . Prevosto, J. Signoles,
and B. Yakobowski. Frama-C: A Software Analysis
Perspective. In Proceedings of the 10th International
Conference on Software Engineering and Formal Methods ,
SEFM‚Äô12, 2012.
[9] E. W. Dijkstra. A Discipline of Programming . Prentice-Hall
Series in Automatic Computation. Prentice-Hall, 1976.
[10] P. Godefroid, N. Klarlund, and K. Sen. DART: Directed
Automated Random Testing. In PLDI , pages 213‚Äì223, 2005.
[11] M. Harman and S. Danicic. Amorphous Program Slicing.
WPC, 1997.[12] J. Hatcliff, M. B. Dwyer, and H. Zheng. Slicing Software for
Model Construction. Higher Order Symbol. Comput. , 2000.
[13] J. Jaffar, V . Murali, and J. Navas. Boosting Concolic Testing
via Interpolation. In FSE, 2013.
[14] J. Jaffar, V . Murali, J. Navas, and A. Santosa. TRACER: A
Symbolic Execution Tool for VeriÔ¨Åcation. In CAV 2012 ,
pages 758‚Äì766, 2012.
[15] J. Jaffar, V . Murali, J. A. Navas, and A. E. Santosa.
Path-Sensitive Backward Slicing. In SAS, pages 231‚Äì247,
2012.
[16] J. Jaffar, A. E. Santosa, and R. V oicu. An Interpolation
Method for CLP Traversal. In CP, 09.
[17] R. Jhala and R. Majumdar. Path Slicing. In PLDI , 2005.
[18] V . Kuznetsov, J. Kinder, S. Bucur, and G. Candea. EfÔ¨Åcient
State Merging in Symbolic Execution. In PLDI , 2012.
[19] K. L. McMillan. Lazy Abstraction with Interpolants. In
CAV ‚Äô06 , pages 123‚Äì136.
[20] K. L. McMillan. Lazy Annotation for Program Testing and
VeriÔ¨Åcation. In T. Touili, B. Cook, and P. Jackson, editors,
22nd CAV , volume 6174 of LNCS , pages 104‚Äì118. Springer,
2010.
[21] A. Podelski and A. Rybalchenko. ARMC. In PADL‚Äô07 .
[22] R. Rugina, M. Orlovich, and X. Zheng. Crystal: A Program
Analysis System for C.
http://www.cs.cornell.edu/projects/crystal, 2007. [Online;
accessed 09-July-2011].
[23] M. Weiser. Program Slicing. In ICSE ‚Äô81 , pages 439‚Äì449,
1981.