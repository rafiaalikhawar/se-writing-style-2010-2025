Concurrent Transformation Components using Contention
Context Sensors
Erik Österlund
Software Technology Group
Linnaeus University
Växjö, Sweden
erik.osterlund@lnu.seWelf Löwe
Software Technology Group
Linnaeus University
Växjö, Sweden
welf.lowe@lnu.se
ABSTRACT
Sometimes components are conservatively implemented as
thread-safe, while during the actual execution they are onlyaccessed from one thread. In these scenarios, overly conser-vative assumptions lead to suboptimal performance.
The contribution of this paper is a component architec-
ture that combines the beneﬁts of diﬀerent synchronizationmechanisms to implement thread-safe concurrent compo-nents. Based on the thread contention monitored at run-time, context-aware composition and optimization select theappropriate mechanism. On changing contention, it revisesthis decision automatically and transforms the componentsaccordingly. We implemented this architecture for concur-rent queues, sets, and ordered sets. In all three cases, ex-perimental evaluation shows close to optimal performanceregardless of the actual contention.
As a consequence, programmers can focus on the seman-
tics of their systems and, e.g., conservatively use thread-safecomponents to assure consistency of their data, while defer-ringimplementationandoptimizationdecisionstocontention-context-aware composition at runtime.
Categories and Subject Descriptors
D.1.3 [Software ]: Programming Techniques— Concurrent
Programming ;E . 1[Data]: Data Structures
Keywords
context aware composition, concurrent components
1. INTRODUCTION
Parallel programs and concurrent components that can
run safely in concurrent, i.e. contended contexts are increas-ingly important with the rise of symmetric multiprocessing(SMP) architectures. A common problem programmers faceis that the level of runtime contention of a component isunknown at development time. If multiple layers of applica-tion programming interfaces (APIs) depend on one another,
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributedfor proﬁt or commercial advantage and that copies bear this notice and the full cita-tion on the ﬁrst page. Copyrights for components of this work owned by others thanACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-publish, to post on servers or to redistribute to lists, requires prior speciﬁc permissionand/or a fee. Request permissions from Permissions@acm.org.ASE ’14 September 15 - 19 2014, Västerås, Sweden
ACM 2014 978-1-4503-3013-8/14/09 ...$15.00.http://dx.doi.org/10.1145/2642937.2642995.it becomes increasingly diﬃcult to know which level of con-
tention a component will be exposed to. Often, a conserva-tive approach is taken. A thread-safe component is pickedif there is a possibility that an API is used in a parallel con-text, e.g., by a multi-threaded application. However, if thecontention was known, alternative component variants maybe preferable.
Thedreamofnothavingtomanuallypickcomponentvari-
ants based on assumed contention traces back to old classeslike Vector in the Java class library. All methods were syn-chronized so that programmers could assume thread-safetyalways. Unfortunately, the approach led to bad sequentialperformance, and unscalable parallel performance due to theuse of locks. Therefore, the dream was abandoned in latergenerations of the class library, and the responsibility ofpicking the appropriate component variant became a bur-den for programmers again. The burden got worse with theadvent of lock-free components. Now in addition to know-ing whether thread-safety is needed or not, the componentvariant picked also depends on assumed level of contention.
Universal constructions like, e.g., transactional memory
(TM) [13] based on either software (STM) [12, 8, 27] orhardware (HTM) [2, 11] provide good scalable performanceand ease of use. Lock-free components [23, 18, 14, 9] provideeven better concurrent performance, while coarse grainedbiased locking [26] is the fastest in absence of concurrency.
There is no single best synchronization mechanism. In-
stead of trying to ﬁnd the ultimate synchronization mech-anism combining the pros of all existing approaches, thispaper seeks to ﬁnd a way of implementing and composingcomponents using diﬀerent synchronization mechanisms andpick the appropriate one automatically.
This paper proposes a novel methodology inspired by con-
text-aware composition [25, 16] and adaptive spin locks [26].Its goal is simple: provide the optimal uncontended perfor-mance and the optimal concurrent performance at the sametime. The idea is to start with optimistic biased locks thatare essentially for free in terms of performance. At signsof actual contention, adapt and break the lock by eitherswitching to a more ﬁne-grained locking scheme that scalesbetter or transform into a completely lock-free solution formaximum scalability.
This methodology extends context-aware composition to
use components in a concurrent context, where before onlythe components could split work to be done in parallel.
Adaptive spin locks are great at sensing diﬀerent con-
tention and adapting the time to spin before yielding to theOS. This paper goes even further and provides an API sig-
223
nalling into the application that there is a lock bottleneck.
This allows arbitrary user deﬁned action to deal with theproblem. This paper contributes with: 1) contention-awarecomposition, a methodology for dealing with overhead andscalability problems of concurrent components under stati-cally unpredictable contention. 2) contention-aware compo-sition applied to Java concurrency data structures. 3. evalu-ations running on our own modiﬁed OpenJDK showing thattheseconcurrentcomponentsperform(almost)aswellastheb e s tk n o w nc o m p o n e n tf o re a c hc o n t e n t i o nc o n t e x t .
The paper is organized as follows: Section 2 introduces
three standard synchronization mechanisms: locks, lock-freealgorithms, andTM.Section3introducestransformingcom-ponents using context-aware composition at runtime basedon contention as a context property. Section 4 shows howcontentioncanbemonitoredeﬃcientlywhileSection5showsthat an implementation of the actual component transfor-mation can be implemented eﬃciently. Section 6 introducesthe Java concurrency data structures used in evaluation,highlights some implementation details and ﬁnally describesthe evaluation and the evaluation results. Finally, Section 7discusses the related work and Section 8 concludes the pa-per.
2. SYNCHRONIZATION MECHANISMS
We refer to concurrent components as data structures im-
plementing an API whose instances are consistent in a con-current executiton context. In object-oriented languages,concurrent components are instances of classes that are con-sistent even if accessed by several threads concurrently.
We describe three diﬀerent synchronization mechanisms
used to implement concurrent components: 1) locks, 2) lock-free synchronization using atomic instructions like compare-and-swap (CAS), 3) TM. We argue they all have their weak-nesses and strengths, speciﬁcally, for our main concern inthispaper: performance . Wediscussthetheoreticalprosand
cons of each synchronization mechanism in both (almost) se-quential and (highly) concurrent execution contexts.
2.1 Locks
Alockcanbeacquiredbyoneandonlyone(owner)thread
thatmaycontinuewithitsexecution. Itblocksotherthreadstrying to acquire the lock until the owner releases it again.Locks are arguably the most common synchronization mech-anism because of their availability and ease of use. They arealso ﬂexible in the sense that the locking granularity canbe varied to achieve scalability. Problems such as deadlockswill not be discussed here as we are only interested in perfor-mance and not in programming and veriﬁcation eﬃciency.
Sequential Context: In an (almost) sequential execu-
tion context, coarse grained locks and sequential algorithmsimplementing an API tend to always win. If it can be stat-ically proven that objects never escape a thread (by man-ual or automated escape analysis), locks can even be elidedcompletely and the sequential code can run at no additionaloverhead. Even when it is not provable statically that a lockbelongs to a single thread exclusively, the lock may opti-mistically assume so using biased locking [26]. Therefore, itinstalls the presumed owner thread the ﬁrst time it is lockedusing CAS. If the owner stays the same, locking and unlock-ing is performed simply by writing 1 and 0 correspondingly,a n di sv e r yf a s t .Concurrent Context: Inconcurrentexecutioncontexts,
locks suﬀer from problems predicted by Amdahl’s law [1].Since locks fundamentally only allow one thread to executeat a time, locked programs do not scale very well when thesequential parts dominate the concurrent parts.
There are ways to mitigate this bottleneck by using a dif-
ferent locking scheme. One solution is to use ﬁne-grainedlocking where only some objects of a complex componentlocal to a change are locked instead of locking the wholecomponent instance. For instance, only some nodes in atree are locked instead of locking the whole tree. Anothersolution is to use readers-writer locks that allow multiplereaders but only one writer at a time.
Conclusion: Locking is superior for sequential execution
but may not be the best candidate for concurrent use.
2.2 Lock-Free Synchronization
Lock-free algorithms [23, 18, 14, 9] were introduced to
deal with the problems of locks. Synchronizing instructionsare used only on memory locations where there are actualdata conﬂicts. They read and remember values from thememory locations, perform calculations and write the resultback to these locations. Using operations like CAS, theydetect conﬂicts, i.e., if another thread has changed the valuein between. Then they try again (in a biased loop withbranch prediction optimized for the success, and not thetry again branch). This allows concurrent modiﬁcation ofcomponents as long as there are no data conﬂicts and, thus,somehow mitigates the problems of Amdahl’s law.
Due to the inherent complexity of these algorithms, not
allsequentialdatastructureshavelock-freeimplementationsyet. Also, a truly lock-free algorithm requires the underlyingexecutionenvironment, includingthememorymanagertobelock-free to retain its progress guarantee, which is diﬃcult toassure. It requires, e.g., lock-free garbage collection [29] orhazard pointers [22]. However, this paper is not concernedwith guaranteeing true lock-freedom or real-time properties.Our interest is only the scalable performance characteristicsof this class of algorithms for concurrent components.
Sequential Context: The performance of such lock-free
algorithms greatly depend on the hardware and how fast itsCAS instruction is compared to normal memory accesses.
Historically, x86 implemented LOCK CMPXCHG (CAS) by
locking the whole memory bus globally during the execu-tion of the instruction. Newer implementations, however,lock only the cache line where the CAS is executed.
AstrongCASrequiresacquirereleasesemanticsandhence
needs to issue a full memory fence. In certain architecturesthis might be a relatively expensive operation, requiring allwrite buﬀers and caches to be serialized.
In the case of x86 (which is considered strongly consis-
tent), all aligned memory accesses already have acquire re-lease semantics, and the LOCK CMPXCHG instruction already
implicitly issues a complete memory fence for free.
In other architectures such as POWER (which is weakly
consistent) the cost is higher. Here, enforcing the acquire re-leasesemanticsrequires: (1)anexpensiveheavyweight sync
memory fence instruction, (2) a lwarx(load link) and stwcx
(store conditional) in a loop until the instruction can returna valid result free from spurious failures, (3) a lightweightisyncfence to serialize all writes.
224Lock-free algorithms can also rely on volatile memory
accesses with acquire release semantics whose performance
may similarly depend on which architecture it runs on.
Additionally, even if the volatile memory accesses (includ-
ing CAS) are as fast as non-volatile memory accesses, lock-freealgorithmsarestilltypicallyslowerbecausetheyarefun-damentally designed to handle data conﬂicts, e.g., branchesfor loops retrying committing their changes, which is nevernecessary in a sequential execution. Moreover, simple com-ponent attributes such as the size of a collection are typi-cally computed on demand in a lock-free implementation inorder to reduce cache clashes. In the example of the size at-tribute, this leads to an O(n)o p e r a t i o ni n s t e a do fa n O(1)
operation of a corresponding sequential data structure thatsimply maintains a size counter because it does not need tooptimize for concurrency.
Concurrent Context: is where the merits of lock-free
programming becomes visible. Lock-free components com-mit changes at linearization points [15] using CAS and op-tionally lazily (asynchronously on any subsequent opera-tions) update references not necessary for consistency, butfor improving time complexity. Therefore, only true dataconﬂicts violating consistency of the component require op-erations to be restarted. Other data conﬂicts not necessaryforlinearizationcanbetoleratedand belazilyhandled. Thismakes lock-free algorithms very scalable in terms of perfor-mance and typically the best option if available.
Conclusion: Even though CAS is implemented more or
less eﬃciently by diﬀerent hardware vendors, the perfor-mance of lock-free components is still inherently slower thantheperformanceof itssequentialcounterpartsin theabsenceofconcurrency. However, whenthereiscontention, thisclassof algorithm provides the most ﬁne-grained synchronizationﬁne-tuned by clever implementers.
2.3 Transactional Memory
Analogous to database transactions, Transactional Mem-
oryguarantees sequences of load and store instructions to
execute in an atomic way. It is a universal construction forturning any sequential algorithm into a lock-free [28] andeven wait-free [24] algorithm without any deadlocks. De-spite this theoretical beneﬁt, TM failed to become adoptedin practice mainly due to performance reasons discussed be-low. Additionally and not discussed here in detail, specu-lative TM (performing in-place writes) cannot always guar-antee that a transaction will ever end in case of contentionsince a speculative load could cause an inﬁnite loop neverreaching the commit operation.
Sequential Context: STM typically performs signiﬁ-
cantly worse in a sequential environment compared to a nor-mal sequential solution.
Performance depends on whether the algorithm uses write
buﬀering versus undo logging, pessimistic versus optimisticconcurrency, cache line based versus object based versusword based conﬂict detection etc. An evaluation of the tradeoﬀs was done by Saha et al. [27].
HTM can accelerate for instance write buﬀering in hard-
ware and allows to elide locks. It can reduce the cost com-pared to STM, but relies on hardware which may or maynot exist. Biased locking already shows better performancecharacteristicswithoutspecialhardwaresupportinthiscase.
Concurrent Context: The idea of a universal construc-
tion that transforms sequential code into concurrent codeautomatically without the need to re-engineer or re-designfails because sequential code typically has sequential datadependencieseverywhere(sinceitwasnotoptimizedforcon-current use) that, in turn, causes rollback storms.
STM is considered to have higher constant cost but better
scalability than coarse grained locking. In previous publica-tions, the break even point seems to be approximately fourconcurrent threads [4].
HTM has the same scalability properties as STM but pro-
vides better constants as long as the hardware write buﬀersare large enough for the operations, lowering the break evenpoint to two concurrent threads [4].
However, carefully implemented lock-free algorithms typi-
cally outperform TM. The problem is that TM aborts trans-actions for all data conﬂicts. A lock-free algorithm, con-versely, may know that a speculatively loaded value maybecome invalid or a lazily updated reference may not bewritten, but it does not matter for the consistency of thealgorithm. Therefore, the lock-free algorithm may continuewhereas the TM based code has to restart the transaction.
Conclusion: TM does exhibit good concurrent scalabil-
itywhenthereisnoknownlock-freecomponentvariant. TMprovides decent sequential performance if hardware supportis available. However, when there is no hardware support ora lock-free algorithm exists, other options are better.
3. TRANSFORMATION COMPONENTS
Research in ﬁnding the ultimate synchronization mecha-
nism combining the best of them all has not found a con-clusion yet. We must admit that the best synchronizationmechanism depends on the context including both the ap-plication context and runtime context. The application con-text includes read to write ratio, the number of threads, andthe actual contention. The runtime context includes prop-erties of hardware, operating system, and language runtimeenvironment such as the memory consistency of the archi-tecture, the number of cores (and, hence, the need for scal-ability) whether there is a single chip system or multiplechip system, the number of hyper threads for cheaper con-text switching, the fairness of the scheduler, the fairnessof the potential locking protocol (unfairness yields higherperformance since TLB caches are already populated whenreacquiring the lock), the availability of HTM, the size ofits write buﬀers, the speed of CAS operations, the size ofcaches, how caches are shared, what cache coherence proto-col they employ, the speed of the memory bus etc. Some ofthe properties are known at compilation time, some at de-ployment time, and yet some vary dynamically at runtime.
Since there is no single silver bullet that provides the
best possible performance in all contexts, our approach is tobridge the gap between diﬀerent solutions of diﬀerent syn-chronization mechanisms by adapting to the actual contextdynamically. We present contention sensors and transforma-tioncomponentsasnovelsolutionstodetectingtheproblemsand dealing with the problems respectively.
This work builds on the previous work by Andersson et
al. [3] introducing context-aware composition and by ¨Oster-
lund et al. [25] introducing dynamically transforming datastructures and a framework for reasoning about them.
Atransformation component consists of an abstract data
representation and a set of abstract operations ooperating
on this data. The abstract data representation allows fordiﬀerent data representation variants , specialized for cer-
225tain contexts. Each abstract operation oof a component
also allows for diﬀerent algorithm variants .I ng e n e r a l ,t h e
same operation could come in diﬀerent algorithm variants
using the same data representation, each optimized for dif-ferentcontexts. Inourapproach, eachrepresentationvariantmatches one-to-one an algorithm variant for each o.
Transformation components follow a general design pat-
tern for data structures with changable representation andalgorithm variants as proposed in [20]. It uses a combinationof the well-known bridgeand strategy design patterns [10].
The special case of our approach is depicted in Figure 1.The component has a reference to the current representa-tion variant. It could be any representation variant that isan instance of the abstract representation.
All state information of a component is contained in data
representation variants. There must exist a state transfor-mation from a data representation variant atobto allow
a component transformation. Transformation could use aclone()method accepting the current (unknown, abstract)
representation as a parameter or any other read/write it-eration of the contents that is complete and homomorphicw.r.t. the operations o.
The changeTo() operation invalidates the previous rep-
resentation variant so that accesses to it will be trapped,creates a new representation variant of a new type and pop-ulates it using the clone()method.
For each operation the component also holds references
to the current algorithm variant implementing an operationcorresponding to the current representation variant. Algo-rithm variants are classes specializing an abstract operationclass. The abstract class provides an execute method imple-mentedbyallsubclasses. Callstoanoperationaredelegatedto the current algorithm variant.
Since in the current paper, representation variants and
algorithm variants are always connected, we additionally in-troduce component variants comprising both a representa-
tion variant and its associated set of algorithm variants.
Based on the changing contention context, i.e., the con-
currency a component is exposed to, we strive to select thebest performing component variant including the best syn-chronization mechanism and the algorithm variant with thelowest time complexity. Contention is the only dynamicallychanging context attribute that we consider here. The ratio-nale is that whenever there is contention, the system expe-riences a massive slow down that typically outweighs otherattributes. A more complex biasing would employ more con-text attributes like size of data, application proﬁle, hard-ware, and scheduling. Since, the eﬀects of these contextattributes have been researched before [3, 16, 25], we focuson the contention context here.
We propose a single contention manager object for each
transformation component object. It receives input fromthe speciﬁc active implementations in completely diﬀerentways. The contention manager is invariant of how it getsits information. It listens to contention level changes. Ifthe current component variant is considered inappropriatefor the current level of contention, it is invalidated and anew equivalent and hopefully more appropriate componentvariant is instantiated.
Therefore, we need to address three issues: (i) we need
to assess the contention context, (ii) we need to be ableto transform representation variant and algorithm variantssafely, (iii), we need to learn, which changes in the con-tention level ought to trigger transformation. At least (i)and (ii) need to be performed online and contribute to theruntime overhead of transforming components. Hence, eﬃ-ciency of context assessment and transformation is an issue.The issues (i)–(iii) will be addressed in the subsequent threesections.
4. CONTINUOUS CONTEXT FEEDBACK
We address issue (i) by introducing continuous context
feedback for contention and call it a contention sensor.I ti s
implemented diﬀerently for the three diﬀerent synchroniza-tion mechanisms and provides a general interface, in essencehooks to user deﬁned code in the contention manager, deal-ing with adaptation when contention levels change.
For each contention sensor implementation, it is beneﬁcial
to log only the baduses of a certain synchronization mecha-
nism. For instance, a lock would only notify the contentionm a n a g e ro fb a du s e so fl o c k ss u c ha sw h e nb l o c k i n gi sn e c e s -sary, rather than that it successfully acquired a biased locklocal to one thread. Such a message would never lead to anychange, and hence the message would only be an unneces-sary overhead. The same principle applies to the contentionsensors for all synchronization mechanisms described below.
Notethatsignsofhighcontentionaremonitoredpromptly
so that components can eagerly transform into concurrentvariants. The reason is that locks could be bottlenecks ham-pering global progress of the system, requiring immediatetransformation into a concurrency friendly component.
Conversely, signalling low contention and transforming
back into the lock based component variant is deferred untilthere is suﬃcient evidence that contention has indeed de-creased to a single thread for a signiﬁcant amount of time.The transformation is typically not necessary to prevent aserious performance bottleneck in the sense that scalabilityis prevented. It may however provide better performance ifexecuted frequently.
4.1 Locks
The contention sensor for locks is quite important as locks
tend to be the biggest bottlenecks in concurrent programs.Therefore, we must take extra care of minimizing the costof this contention monitoring.
Modern virtual machines (VMs) employ adaptive locking
schemes with support for biased locking. We will assumean ideal solution for us, presented by Pizlo et al. [26], thatperforms better when locking is done from a single thread,and adaptively spins when there is actual contention. Wehereby deﬁne three levels of contention for a lock: 1) biased,2) unbiased spin-lock, 3) blocking lock. Each level has itsown type of lock that needs to be installed.
Level 1 is referred to as biased locking. The ﬁrst owner
is established using compare-and-swap. Once it has beenestablished that the lock is biased towards a thread, it maylock and unlock simply by ﬂagging 1 (locked) or 0 withoutatomic instructions. If another thread attempts to enterthe critical section, it calls for bias revocation by invoking alocal safepoint that freezes the owning thread and promotesits lock to level 2.
Level2isreferredtoasspin-locks. Theyspinforabounded
amount of time, waiting for the lock to be released. This isfaster on SMP systems than blocking if the lock will soonbe released. If, however, spinning does not end in time, thelock gets promoted to level 3.
226OperationXAlgorithm 
<<abstract>>  
+ execute(…) 
OperationXVariant 1 
+ execute(…) OperationXVariant k + execute(…) operationXAlgorithm Representation + clone(Representation) 
representation 
this Transformation Component  
- changeTo(repr) 
 
- setOperationXAlgorithm() 
+ operationX(…) 
 representation :=  
repr -> clone(representation) Representation Variant 1 
+ clone(Representation ) Representation Variant k + clone(Representation) 
this 
Figure 1: Transformation Component. UML diagram of the conceptual design pattern. Implementationdesign could be diﬀerent to optimize performance.
Level 3 is referred to as blocking lock. If spinning for a
bounded number of times was not enough, the thread blocksuntil it may be acquired again. On this level, it additionallysignals wether blocking was necessary or not. This comes atno additional cost since the cost of blocking is signiﬁcantlyhigher than the monitoring code.
Contention sensors allow monitoring changes between dif-
ferent contention levels. Fortunately, since each contentionlevel corresponds to a new type of lock being installed intothe cell header, the performance cost of such contentionmonitoring is insigniﬁcant since it does not get invoked foreach lock operation (especially fast paths), but only for theslow paths when locks are promoted due to contention ordemoted due to lack of contention.
4.2 Lock-Free
In a lock-free component, sensing the absence of con-
tention would be useful. In order to do this, we piggybackon a garbage collector (GC) and use a similar idea as normallock deﬂation, i.e., adaptive locking that decides to demoteal e v e l3t y p el o c ka n dt oi n s t a l lal o w e rl e v e l . T h eV Mnormally aggressively deﬂates locks that are not held duringgarbage collection. Similarly, the lock-free component cre-ates a probe object which is garbage on creation (no refer-ences to it). It has a ﬁnalizer which can check the ownershipof a lock-free component when the probe becomes ﬁnalizedby the garbage collector at the next GC cycle. If the com-ponent indeed was exclusively owned by a single thread, theprobe did not sense any contention.
Deciding this exclusive ownership when the probe ﬁnalizes
can be done in two ways. In the ﬁrst approach, accurate
probing, threads read a special volatile ﬁeld of a lock-free
component for determining its owner thread. For each op-eration the component checks if the owner is NONE.I fs o ,
the thread could attempt to install itself as owner safelyus-
ing CAS. If the CAS fails or the owner was not NONE, then
MULTIPLE is written to the owner ﬁeld, symbolizing that the
component is used by multiple threads. Now the probe cansee, when triggered by the GC ﬁnalizer, that the status is ei-ther NONE, a single thread or MULTIPLE. This value stabilizes
quickly and its cache line can be shared with no conﬂicts.
In practice, since monitoring is only providing hints for
when to transform, the ﬁeld can be updated using normalmemory accesses for increased performance. This approxi-mation could be a victim of data races and hence provideinaccurate hints. However, that does not aﬀect the consis-tencyofthecomponent, onlythehintsusedforoptimization.
The second approach, random probing ,a l w a y sd e c i d e st o
transform back to the single-thread optimized variant re-gardless of the actual contention, for a chance to eventu-ally revise the assumption that contention is high. Obvi-ously, this could be the wrong decision, causing an imme-diate (and unnecessary) transformation back to the concur-rency favoured variant again. However, this only happensinfrequently (once every GC cycle), and the amortized costof such bad transformations is low.
4.3 Transactional Memory
Monitoring contention in TM is particularly trivial: sim-
ply count the number of transactions free from data conﬂicts(which must be tracked anyway) and feed it into the con-tention manager.
5. SAFE COMPONENT INVALIDATION
Knowing that a particular component variant is not suit-
able is not enough; we also need to address issue (ii) andconvert to a new variant safely and eﬃciently. We proposecomponent variant invalidation asamechanismtoinvalidate
thepreviousunsuitablecomponentvariantsinthesensethatno operation (read or write) may complete nor harm theconsistency of the component once invalidation has ﬁnished.We provide safe component variant invalidation mechanismsfor each synchronization mechanism.
Note that in order to instantiate and initialize a new more
suitable component variant, it must still be possible to readthe state of the invalidated component variant. If all readingmethods throw exceptions it becomes impossible to read thelast valid state, hence installing a new component variant is
227notpossibleeither. Thereforeeverycomponentvariantmust
provide a special yet general read-only version, e.g., a read-iterator, which is only used when the component variantis rendered invalid and does not need protection. The ap-proach we chose is to provide readable clone methods, Rep-
resentation readableClone() , for every representation variant.
5.1 Locks
The general solution makes lock invalidation a part of the
locking protocol. That is, a lock can be permanently invali-dated requiring one extra bit for the locking protocol state.A slow path can be executed when it is entered and invalid,causing an exception to be thrown to the component whichhandles this accordingly. If integrated into the locking pro-tocol’s slow path, this operation is free of charge when usingthe fast paths which need to be optimized.
For the locking, readableClone() returnsanewobjectwrap-
perwiththesameinternaldata, butwithanewlockallowingaccess to the representation variant.
5.2 Lock-Free
For discussing lock-free algorithms we ﬁrst need to diﬀer-
entiate linearizing CAS operations from not linearizing CASoperations. A linearizing CAS is a CAS that atomicallycommits the change made by an operation at a linearizationpoint [15] and either fails to commit due to contention (andhence making the wanted change not visible at all to otherthreads) or succeeds (and hence making the new state of thecomponent completely visible to all other threads). TheremaybeothernotlinearizingCASoperationsthatupdatethecomponent lazily and if not successful, they do not hamperthe consistency of the component.
Our main idea is the following: Lock-free components are
built using our own invalidatable IAtomicReference <T>that
has a special linearizingCAS() operation. This class blocks
linearization points in lock-free algorithms from committingits changes after an invalidation of a reference. Instead itthrows an exception to signal that it has been invalidated.A load of the reference, get(), will also throw an exception.
How it works in detail: The generic type argument Tis
required to be a subclass of Object. An internal atomic ref-
erence assumes the Objecttype, and get()casts the internal
load from ObjecttoT. Instances of a special internal class In-
validated<T> representinvalidatedreferences, and get()will
trigger a class cast exception (since Invalidated<T> is not a
T) indicating that the reference has become invalid. Simi-larly, the linearizingCAS() operation returns immediately if
the internal CAS worked, otherwise it checks if it failed dueto invalidation by loading the current value and checking ifit is an Invalidated<T> object. Any normal non-linearizing
CAS operation does not need to throw such exceptions asthe consistency of the data structure is not harmed by themaccording to the algorithm speciﬁcation.
Invalidation of a reference is performed by installing an
Invalidated<T> object containing the original value using
CAS in a loop that terminates when CAS succeeds.
Like with the other solutions, there must be a read-only
variant that will not throw exceptions, allowing copying ofthe old invalidated representation variant and create a newone. This is done with a special T loadLastValid() method
implemented in IAtomicReference <T>, which is also used to
implement the readableClone() methods of the representa-
tion variants.To invalidate a component variant, it is traversed using
T loadLastValid() a n dt h e nc a l l s invalidate() on all existing
references. When the whole representation variant has beentraversed, itiscertainthatthecomponentvariantislogicallyinvalidated in the sense that any linearization point for anyoperation will fail and throw an exception.
5.3 Transactional Memory
Implementing safe component variant invalidation for TM
is done by simply inserting a data dependency in the begin-ning of the transactions, checking a ﬂag if the representationvariant is invalid; if so it throws an exception, otherwise itcontinues executing. When the component variant is invali-dated, the ﬂag is set causing current transactions to fail. Ina strongly consistent TM the ﬂag is set normally, while ina weakly consistent TM the setting of the ﬂag is wrappedin a transaction. If the ﬂag checking operation’s transactionfailed it checks if the invalid ﬂag is set, and if so throws anexception like the locking approach. Unlike the locking in-validation, we do not know how to make this free of chargein the common case as infusing a data dependency is integralfor making the transaction fail.
Assumingwrite-buﬀeredTM, readableClone() methodsare
implemented by using plain memory read operations.
5.4 Safe Component Transformation
Now we can, for all synchronization mechanisms, sense in-
appropriate component variants due to changing contentionand safely invalidate them for any synchronization mecha-nism. In order to complete the transformation there mustbe a way of handling transformation races. We simply solvethat uniformly for all synchronization mechanisms by wrap-ping the actual transformation in a synchronized block witha lock owned by the contention manager. We argue that ifcontention for transformation is so heavy that this becomesa bottleneck, choosing to transform is probably a bad de-cision in the ﬁrst place and the contention manager shouldsimply not trigger such excessive transformations.
6. EVALUATION
In this section we assess transformation components in
diﬀerent contention contexts and compare them to compo-nents using a single, monolithic synchronization mechanism.This will also address the issue (iii), i.e. the question, whichchanges in the contention level ought to trigger transfor-mation since we observe the monolithic champion variantin each contention context. It turns out that the lock-free solutions outperform the lock-based solutions already iftwo threads are working concurrently in all observed cases.Hence, our transformation components switch to these solu-tions as soon as contention is detected.
6.1 Implementation Deviations
In Section 4, we deﬁned the adaptive locking protocol for
promoting and demoting monitors. However, our implemen-tation was integrated into OpenJDK 8 that follows a slightlydiﬀerent locking scheme. First locks are biased towards onethread as before. When it turns out that the lock was notexclusively used by a single thread, a local safepoint is is-sued to rebias the lock towards another thread or to revokethe bias. OpenJDK supports bulk rebiasing where everyinstance of a class gets its lock bias revoked.
228In OpenJDK, it can happen that a lock is allocated on
the stack, e.g., of an interpreter. When the code needs to
be optimized by the JIT-compiler such stack allocated locksget inﬂated when on-stack-replacement (OSR) is performedto replace the current stack frame with a new native stackframe. This can lead to bulk revocation of all biases of allcurrently held locks, not due to contention, but due to mi-gration from the interpreter frame to JIT-compiled frames.Of course, this is not an inherent problem; it was simplyeasier exploiting the given environment. A locking protocolcould indeed be implemented without false lock promotion.
Asaworkaroundtonotaﬀectthebenchmarks, thebench-
marks have a warming up phase that makes sure everythinggets JIT-compiled and that no OSR will disrupt the results.
Finally, we did not use transactional memory. We were
only interested in high performance in this paper, not intransactional composition of concurrent components. Com-bining the beneﬁts of transactional composition with othersynchronization mechanisms using transformations is possi-ble but evaluation of this is outside the scope of this paper.
6.2 Components and their Variants
Three diﬀerent components – queues, sets, and ordered
sets were implemented. OpenJDK already comes with im-plementations of these in the concurrency package: Concur-
rentLinkedQueue ,ConcurrentHashMap andConcurrentSkipList ,
all implemented by Doug Lea. We added transformationcomponents of these and evaluated them experimentally inSection 6.3.
6.2.1 Queue
Concurrent queues are used in many applications. There-
fore, we chose to evaluate the performance of a transformingconcurrent queue as one of our candidates. Initially, it as-sumes little contention using a coarse-grained lock and anormal LinkedList implementation. At the ﬁrst blocking op-
eration for the lock, it transforms into a lock-free queue, i.e.,aConcurrentLinkedQueue . A transformation back to the nor-
mal LinkedList is optionally supported using invalidatablereferences combined with random or accurate probing.
The lock-based solution uses a double-linked list for per-
formance improvements. By using a cyclic linked list witha sentinel header node connecting the endpoints, branchescan be omitted to check for null endpoints.
The lock-free queue is based on [23] and uses CAS for
synchronization. It is only single-ended because maintain-ing double-ended linked lists is diﬃcult (although not im-p o s s i b l e ) . T h ec o r ei d e ai st oC A St h en e x tr e f e r e n c e so fthe linked list as linearization point, and then CAS the taillazily using helper methods. Nodes are logically removed bychanging the element of an internal node to null. It is then
lazily removed physically from the linked list.
6.2.2 Set
The second data structure we tried is sets. In particular,
w efocusedonhashtables.TheConcurrentHashMap fromthe
Javaconcurrencypackage, splitsmultiplelocksovermultiplebuckets. The size of the table is scaled up by the numberofexpected threads (which is 16 unless otherwise stated) to
make cache interference and synchronization less common.
Although memory footprint was not a constraint of this
paper and is not shown in benchmark results, keep in mindthat they use signiﬁcantly more memory. The hash table issplit into diﬀerent segments, each individually functioninglike a hash table. The segment is locked when inserting anddeleting. Therefore, this implementation is not lock-free butmore ﬁne-grained in its locking scheme for scalable perfor-mance. When a thread performs contains() on a segment, it
tries a bounded number of times without locking and thenresorts to locking the segment.
6.2.3 OrderedSet
The last example is ordered sets. For the single thread
optimized implementation, we used normal red black treeswith a coarse grained lock (synchronized TreeSet).
There is an inherent diﬃculty of making lock-free algo-
rithms for trees since they have two children that may mu-tate arbitrarily. Therefore, the tree-like skip list was pickedinstead for the concurrent case ( ConcurrentSkipList ). The
ConcurrentSkipListMap is lock-free and based on CAS for lin-
earizationpoints. Itbasicallyworksasamulti-levellock-freelinked list where the number of levels picked for each nodeinserted is picked from a random distribution rather thandeterministically balanced. The concurrent skip list insertsdummy marker nodes to denote a node has been logicallydeleted and are then lazily deleted physically.
The transforming variant starts as a red black tree, and
then transforms into a ConcurrentSkipList for improved con-
currency at signs of actual contention.
6.3 Experimental Setup
All benchmarks were run on a MacBook Pro with 4 Intel
i7 CPU cores, 8 hyperthreads, 256 KB L2 cache (per core),6 MB L3 cache (shared), 2 x 8 GB DDR3 1600 MHz RAM,running on Mac OS X 10.9.1. Benchmarks were run on ourown modiﬁed OpenJDK 8.
Threads 1 to 4 get exclusive CPU cores. Threads 5 to 8
get hyperthreads. Threads 9 to 16 have no such beneﬁts.
By default biased locking would not get activated until
the benchmark is over. Therefore it was forced to startimmediately. Escape analysis was disabled because usingstatic analysis to elide locks in the benchmarks would beunfair. In practice, our transformation components wouldbeneﬁt from such optimizations. The JVM arguments were-XX:+UseBiasedLocking -XX:BiasedLockingStartupDelay=0-XX:-DoEscapeAnalysis.
Time is measured as the net of the wall time across all
threads, invariantoflockspinningandsimilaroptimizations.The elements in all benchmarks are random integers.
Note that for the sequential scenario, the single thread
favoured implementations would win even more if the size()
method was run since they only return the loaded value ofa ﬁeld. Concurrent components have to traverse the datastructure and calculate the total size. This makes trans-formation even more motivated. Yet, we chose not to showsuch benchmarks because the gain is proportional to the sizeof the data structure. Such a biased benchmark is of littlevalue. To be more objective, we focus on the constants.
6.4 Case 1: Concurrent Queues
In order to evaluate the performance of our queue, a micro
benchmark was used. A number of threads ppick operations
enqueueanddequeueaccording to a random distribution and
execute them ntimes. The results for one thread are shown
in Figure 2 and the corresponding benchmark results formultiple threads are shown in Figure 3.
22923023123210. REFERENCES
[1] G. M. Amdahl. Validity of the single processor
approach to achieving large scale computing
capabilities. In Proceedings of the April 18-20, 1967,
Spring Joint Computer Conference ,A F I P S’ 6 7
(Spring), pages 483–485. ACM, 1967.
[2] C. S. Ananian, K. Asanovic, B. C. Kuszmaul, C. E.
Leiserson, and S. Lie. Unbounded transactionalmemory. In High-Performance Computer Architecture,
2005. HPCA-11. 11th International Symposium on,pages 316–327. IEEE, 2005.
[3] J. Andersson, M. Ericsson, C. W. Keßler, and
W. L¨owe. Proﬁle-guided composition. In Software
Composition, pages 157–164, 2008.
[4] P. Damron, A. Fedorova, Y. Lev, V. Luchangco,
M. Moir, and D. Nussbaum. Hybrid transactional
memory. SIGPLAN Not., 41(11):336–346, Oct. 2006.
[5] P. Damron, A. Fedorova, Y. Lev, V. Luchangco,
M. Moir, and D. Nussbaum. Hybrid transactionalmemory. In ACM Sigplan Notices, volume 41, pages
336–346. ACM, 2006.
[6] D. Dice, O. Shalev, and N. Shavit. Transactional
locking ii. In Distributed Computing , pages 194–208.
Springer, 2006.
[7] D. Dig, J. Marrero, and M. D. Ernst. Refactoring
sequential java code for concurrency via concurrentlibraries. In Proceedings of the 31st International
Conference on Software Engineering , pages 397–407.
IEEE Computer Society, 2009.
[8] P. Felber, C. Fetzer, and T. Riegel. Dynamic
performance tuning of word-based softwaretransactional memory. In Proceedings of the 13th ACM
SIGPLAN Symposium on Principles and practice ofparallel programming , pages 237–246. ACM, 2008.
[9] M. Fomitchev and E. Ruppert. Lock-free linked lists
a n ds k i pl i s t s .I n Proceedings of the twenty-third
annual ACM symposium on Principles of distributedcomputing , pages 50–59. ACM, 2004.
[10] E. Gamma, R. Helm, R. Johnson, and J. Vlissides.
Design Patterns – Elements of ReusableObject-Oriented Software. Addison-Wesley, 1995.
[11] L. Hammond, V. Wong, M. Chen, B. D. Carlstrom,
J. D. Davis, B. Hertzberg, M. K. Prabhu, H. Wijaya,C. Kozyrakis, and K. Olukotun. Transactionalmemory coherence and consistency. In ACM
SIGARCH Computer Architecture News, volume 32,page 102. IEEE Computer Society, 2004.
[12] M. Herlihy, V. Luchangco, M. Moir, and W. N.
Scherer III. Software transactional memory fordynamic-sized data structures. In Proceedings of the
twenty-second annual symposium on Principles ofdistributed computing, pages 92–101. ACM, 2003.
[13] M. Herlihy and J. E. B. Moss. Transactional memory:
Architectural support for lock-free data structures,volume 21. ACM, 1993.
[14] M. Herlihy, N. Shavit, and M. Tzafrir. Hopscotch
hashing. In Distributed Computing , pages 350–364.
Springer, 2008.
[15] M. P. Herlihy and J. M. Wing. Linearizability: A
correctness condition for concurrent objects. ACM
Transactions on Programming Languages and Systems(TOPLAS), 12(3):463–492, 1990.[16] C. Kessler and W. L ¨owe. Optimized composition of
performance-aware parallel components. Concurrency
and Computation: Practice and Experience ,
24(5):481–498, 2012.
[17] F. Kjolstad, D. Dig, G. Acevedo, and M. Snir.
Transformation for class immutability. In Proceedings
of the 33rd International Conference on Software
Engineering, pages 61–70. ACM, 2011.
[18] A. Kogan and E. Petrank. Wait-free queues with
multiple enqueuers and dequeuers. ACM SIGPLAN
Notices, 46(8):223–234, 2011.
[19] A. Kogan and E. Petrank. A methodology for creating
fast wait-free data structures. In ACM SIGPLAN
Notices, volume 47, pages 141–150. ACM, 2012.
[20]W.
L¨owe, R. Neumann, M. Trapp, and
W. Zimmermann. Robust dynamic exchange of
implementation aspects. In TOOLS (29) ,p a g e s
351–360, 1999.
[21] M. M. Michael. High performance dynamic lock-free
hash tables and list-based sets. In Proceedings of the
fourteenth annual ACM symposium on Parallelalgorithms and architectures , pages 73–82. ACM, 2002.
[22] M. M. Michael. Hazard pointers: Safe memory
reclamation for lock-free objects. Parallel and
Distributed Systems, IEEE Transactions on ,
15(6):491–504, 2004.
[23] M. M. Michael and M. L. Scott. Simple, fast, and
practical non-blocking and blocking concurrent queuealgorithms. In Proceedings of the ﬁfteenth annual
ACM symposium on Principles of distributedcomputing , pages 267–275. ACM, 1996.
[24] M. Moir. Transparent support for wait-free
transactions. In Distributed Algorithms,p a g e s
305–319. Springer, 1997.
[25] E. Osterlund and W. Lowe. Dynamically transforming
data structures. In Automated Software Engineering
(ASE), 2013 IEEE/ACM 28th InternationalConference on , pages 410–420. IEEE, 2013.
[26] F. Pizlo, D. Frampton, and A. L. Hosking.
Fine-grained adaptive biased locking. In Proceedings of
the 9th International Conference on Principles andPractice of Programming in Java, pages 171–181.ACM, 2011.
[27] B. Saha, A.-R. Adl-Tabatabai, R. L. Hudson, C. C.
Minh, and B. Hertzberg. Mcrt-stm: a highperformance software transactional memory systemfor a multi-core runtime. In Proceedings of the ele venth
ACM SIGPLAN symposium on Principles and practiceof parallel programming , pages 187–197. ACM, 2006.
[28] N. Shavit and D. Touitou. Software transactional
memory. Distributed Computing , 10(2):99–116, 1997.
[29] H. Sundell. Wait-free reference counting and memory
management. In Parallel and Distributed Processing
Symposium, 2005. Proceedings. 19th IEEEInternational, pages 24b–24b. IEEE, 2005.
[30] S. Timnat, A. Braginsky, A. Kogan, and E. Petrank.
Wait-free linked-lists. In Principles of Distributed
Systems, pages 330–344. Springer, 2012.
[31] G. Xu. Coco: Sound and adaptive replacement of java
collections. In 27th European Conference, Montpellier,
France, July 1-5, 2013. Proceedings , pages 1–26.
Springer Berlin Heidelberg.
233