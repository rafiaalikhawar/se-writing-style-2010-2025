Synthesisof Live Behaviour Models∗
Nicolás D’Ippolito†∗Victor Braberman∗Nir Piterman†Sebastián Uchitel†∗
†Imperial College London
London, United Kingdom
{npiterma, su2}@imperial.ac.uk∗Universidad deBuenos Aires,
Buenos Aires, Argentina
{ndippolito, vbraber}@dc.uba.ar
ABSTRACT
We present a novel technique for synthesising behaviour
models that works for an expressive subset of liveness prop-
erties and conforms to the foundational requirements en-
gineering World/Machine model, dealing explicitly with as -
sumptions on environment behaviour and distinguishing con -
trolled and monitored actions. This is the ﬁrst technique
that conforms to what is considered best practice in re-
quirements speciﬁcations: distinguishing prescriptive a nd
descriptive assertions. Most previous attempts at using sy n-
thesis of behavioural models were restricted to handling on ly
safety properties. Those that did support liveness were in-
adequate for synthesis of operational event based models as
they did not include the bespoke distinction between system
goals and environment assumptions.
Categories andSubject Descriptors
D.2 [Software Engineering ]
General Terms
Design, Algorithms
Keywords
controller synthesis, behavioural modelling
1. INTRODUCTION
Automated construction of event-based operational mod-
els of intended system behaviour has been extensively stud-
ied in the software engineering community for some time.
Synthesis of such models from scenario-based speciﬁcation s
(e.g. [32, 7, 5]) allows integrating a fragmented, example-
based speciﬁcation into a model which can be analysed via
∗This work was partially supported grants PICT-PAE 2272
37229, ERC PBM-FIMBSE, UBACyT X021, CONICET and
PIP112-200801-00955. NP is supported by grant UK EP-
SRC EP/E028985/1
Permission to make digital or hard copies of all or part of thi s work for
personal or classroom use is granted without fee provided th at copies are
not made or distributed for proﬁt or commercial advantage an d that copies
bear this notice and thefull citation on the ﬁrstpage. Tocop y otherwise, to
republish, topostonserversortoredistribute tolists,re quires priorspeciﬁc
permission and/or afee.
FSE-18,November 7–11, 2010, Santa Fe,New Mexico, USA.
Copyright 2010 ACM 978-1-60558-791-2/10/11 ...$10.00.model checking, simulation, animation and inspection, the
latter aided by automated slicing and abstraction techniqu es.
Synthesis from formal declarative speciﬁcation (e.g. temp o-
ral logics) has also been studied with the aim of providing an
operational model on which to further support requirements
elicitation and analysis.
Behaviour model synthesis is also used to automatically
construct plans that are then straightforwardly enacted by
some software component. For instance, synthesis of glue
code and component adaptors has been studied in order to
achieve safe composition at the architecture level [2], and
in particular in service oriented architectures [4]. More r e-
cently, there has been an increasing interest in self-adapt ive
systems [11] which must be capable of designing at run-
time adaptation strategies. Consequently, such systems re ly
heavily on automated synthesis of behaviour models that
will guarantee the satisfaction of requirements under the
constraints enforced by the environment and the capabili-
ties oﬀered by the self-adaptive system.
A limitation that existing behaviour model synthesis tech-
niques have is that they are restricted to safety properties
and do not support liveness. Hence, synthesis can be posed
as a backward error propagation variant where a behaviour
model is pruned by disabling controllable actions that can
lead to undesirable states.
In many domains, and particularly in the realm of reactive
systems [25], liveness requirements can be of importance an d
having synthesis techniques capable of dealing with them
is desirable. However, very few approaches to behaviour
model synthesis that support liveness have been proposed,
notably [13, 31], which have been applied in self-adaptive
systems. The problem with these approaches is that the
distinction between controlled and monitored actions [26] ,
and between descriptive and prescriptive behaviour [17] is
not made explicit. As a consequence, the behaviour models
they synthesise in order to enact self-adaptation, may not b e
realisable by the self-adaptive system or unexpected resul ts
may be obtained when the self-adaptive system interacts
with its environment due to non-valid assumptions that were
not made explicit.
Making assumptions explicit is crucial, and even more so
with liveness system goals. Jackson [17], and others (e.g.,
[21, 26]) have argued the importance of distinguishing be-
tween descriptive and prescriptive assertions, between so ft-
ware requirements, system goals and environment assump-
tions, and the key role that the latter play in the valida-
tion process. When dealing with liveness, assumptions play
an even more prominent role: Typically, reasoning aboutliveness in behaviour models is performed under speciﬁc
assumptions which correspond to liveness properties them-
selves. For instance, it is common to reason under some
general notion of fairness or some domain speciﬁc property
regarding the responsiveness of the environment to certain
stimuli. Given the central role that liveness assumptions
have for reasoning about liveness requirements, the use of
approaches to synthesis [3, 31] that leave such assumptions
implicit and do not allow for user tailored liveness assump-
tions entails some important risks and limitations for user s.
In this paper we propose a technique for synthesising be-
haviour models that works for an expressive subset of live-
ness properties, that distinguishes between controlled an d
monitored actions, and diﬀerentiates between system goals
and environment assumptions. The technique adapts and
extends recent advances [27] in synthesis of controllers fo r
discrete event systems [29].
More speciﬁcally, we adapt the controller synthesis tech-
nique GR(1) [27] to work in the context of event-based spec-
iﬁcations using LTS semantics, parallel composition and to
support safety properties as part of the speciﬁcation. The
synthesis procedure, given a descriptive speciﬁcation of t he
environment in the form of an LTS and a set of controllable
actions, constructs a behaviour model that when composed
with the environment satisﬁes a given FLTL [12] formula of
the form /BCI∧(Vn
i=1
/BC /BDAi→Vm
j=1
/BC /BDGj) where/BCIis a safety system goal, /BC /BDAirepresents a liveness
assumption on the behaviour of the environment, /BC /BDGj
models a liveness goal for the system and AiandGjare
non-temporal ﬂuent expressions [12], while Iis a system
safety goal expressed as a Fluent Linear Temporal Logic
formula [12].
Technical contributions of this paper include (i)the pre-
sentation of the event-based control problem which gives a
high level description of a certain kind of controller synth esis
problems which aims to work under a theoretical framework
adequate for event-based models; (ii)the grounding of the
event-based control problem for Labelled Transitions Sys-
tems and parallel composition in the deﬁnition of the LTS
control problem ;(iii)the deﬁnition of a restricted LTS con-
trol problem, named SGR(1) LTS that supports safety and
GR(1)-like properties; (iv)the restrictions that an event-
based setting requires in order to guarantee correctness of
the synthesis procedure and to avoid anomalous controllers .
Interestingly, and perhaps not surprisingly, the restrict ions
to achieve the latter correspond to following the methodolo g-
ical and theoretical guidelines dictated by the goal-orien ted
requirements engineering approach [21].
This paper is organised as follows. In Section 2 we present
our running example and provide an overview of the ap-
proach from a black box perspective. We provide the neces-
sary background in Section 3 to then present the LTS con-
trol problems in Section 4 where we also discuss anomalous
controllers and links to the notion of realisability in requ ire-
ments engineering. We show how SGR(1) LTS control can
be solved in Section 5. We ﬁnish with a short description of
a case study, discussion, related work and conclusions. Due
to lack of space proofs are omitted.
2. OVERVIEW
In this section we provide a black-box overview of our ap-
proach. Technical details are provided in the next sections .12
3put.drill [id: 0..Max ] drill.process [id]
get.drill [id]
Figure 1: Drill.
Consider the following variation of the Production Cell
case study [23]: A factory manufactures several kinds of
products each of which requires a production process which
involves diﬀerent tools applied in a speciﬁed order. The fac -
tory production system is expected to adapt its production
process depending on a number of factors such as the avail-
able tools (which is subject to change when a tool breaks or a
new instance of an existing tool type is introduced for exam-
ple), the speciﬁcation of how to process each product type
(which can change because the production requirements for
a product type changes), and other constraints (for exam-
ple, an energy consumption requirements that constrains th e
concurrent use of certain tools). Given its potential for co n-
current processing, the production should be scheduled in
such a way that no product type is indeﬁnitely postponed.
In addition to the tools, the factory has an in tray, an out
tray and a robot arm. The robot arm is used to move prod-
ucts to and from tools and trays. Raw products arrive on the
in tray, the robot arm must process them according to their
speciﬁcation and place the ﬁnished products on the out tray.
The trays can hold products of any kind simultaneously.
To simplify the presentation, assume that the factory must
produce two types of products, namely AandB, with three
diﬀerent tools: an oven, a drill and a press. Products of
typeArequire using the oven, then the drill and ﬁnally the
press, while products of type Bare processed in the following
order: drill, press, oven. In addition, there is a constrain t
on concurrent use of tools: the drill and the press cannot
be used simultaneously. Finally, a liveness condition on th e
production of products of type AandBis also required, that
is, the production of one kind of product cannot postpone
indeﬁnitely the production of products of the other kind.
We now describe how these requirements can be speciﬁed
in our approach and comment on the production strategy au-
tomatically generated by our controller synthesis algorit hm.
The environment model is the result of the parallel com-
position of LTSs modelling the robot arm, the tools, and the
products being processed.
In Figure 1 we show the behaviour model for the drill
tool: Any product (i.e. idfrom 0 toMax), can be putinto
the drill tool by the robot arm ( put.drill [id: 0..Max ]) and,
subsequently, that product is processed ( drill.process [id])
by the drill and can then be taken from the drill by the
robot arm ( get.drill [id]).
In Figure 2 we show a model that describes how raw prod-
ucts can be processed. A product is idleuntil it appears in
the in tray ([ id].inTray ), then it is picked up by the robot
arm ([id].getInTray ), subsequently, it can be freely placed
and picked up from any tool (resp. put.[t:Tools][id] and
get.[t:Tools][id]) until the product processing is ﬁnished
and the product is placed in the out tray ([ id].putOutTray ).
For simplicity, we model that an instance of a product can
be reprocessed, hence, once put on the out tray, the product12
3 4[id].inTray [id].getInTray
idle[id][id].putOutTrayput.[t:Tools][id]
get.[t][id]
Figure 2: Products.
1 2 3[p].getInTray
[p].putOutTrayput.[t:Tools][p]
get.[t][p]
Figure 3: Robot arm.
model is at the initial state again. Note that idrepresents a
particular product and Tools the available tool set.
We do not include in the models of the products the re-
quirements related to the order in which tools must be ap-
plied. This is because, as proposed in [17], we avoid mix-
ing the description of how the environment behaves with
the prescription stating how the environment should behave
once the controller is in place.
The model describing the robot arm (Figure 3) shows how
the arm can pickup any product from any position (in tray,
out tray, and tools) and then place that same product in
another position. It can only hold one product at a time. To
simplify we assume that the in and out trays are repositories
of unbounded size and that the in tray does not enforce an
ordering of products.
The environment model can be built as the parallel com-
position of a model for each tool, a model for the robot arm
and a model for each product: (PRODUCT A[1]||...||PROD-
UCT A[MAX] ||PRODUCT B[1]||...||PRODUCT B[MAX] ||
DRILL ||OVEN ||PRESS ||ARM) . The LTS for this compo-
sition is too big to be shown, it can be constructed using the
modiﬁed MTSA tool and data available at [10].
What remains now is to deﬁne the set of actions that
the controller-to-be can control and the speciﬁcation that it
must satisfy when it is composed with the environment.
The controlled actions must be a subset of the actions
of the environment model and we deﬁne them to be the
actions of the robot arm. In other words, we aim to build
a controller that restricts the behaviour of the arm so that
the way the arm moves the products satisﬁes the production
requirements.
The system speciﬁcation consists of a safety and a liveness
part. The safety part is twofold. On one hand, the order
in which tools will process raw products is encoded with
a model describing the expected processing order for each
type of products. In Figure 4 we show how to model the
processing requirements for products of type A, a temporal
logic representation of such requirement is also possible ( and
can be constructed automatically from Figure 4) but more
cumbersome. We omit it here but assume that ̺captures
the requirements for products of type AandB.
On the other hand, the drill and press cannot be used
simultaneously. This can be easily encoded with the follow-
ing temporal logic property: ψ= /BC(¬∃x,y∈Products ·
Processing (drill,x )∧Processing (press,y )) where /BCme-
ans“always in the future”and Processing (t,p) is a predicatewhich is true when tool tis processing product p. Thus, the
safety goal for the system is I=̺∧ψ.
The liveness part of the system speciﬁcation must capture
the requirement of not indeﬁnitely postponing the produc-
tion of any product type. Such requirement can be for-
malised in temporal logic as follows:
G=V
type∈{A,B}
/BC /BD(WMAX
id=0AddedToOutTray (type, id ))
where AddedToOutTray (t, i)is true if the product has just
been added to the out tray.
If we attempt to build a controller for the arm such that it
guarantees /BCI∧ /BC /BDGwhen composed with the model of
the environment, our approach will indicate that such con-
troller is not possible. This is true, as there is no guarante e
of producing an inﬁnite number of products of type Aand
of typeBif the environment does not guarantee that it will
provide the raw products to be processed.
Consequently, we must assume that the environment will
produce an inﬁnite number of raw products of type AandB:
As=V
type∈{A,B},0≤id≤MAX( /BC /BDAddedToInTray (type, id ))
where given a product with id equal to iand of type t
AddedToInTray (t,i) is true if the product has just been
added to the in tray.
If we attempt to build a controller that guarantees I∧
As⇒Gour approach successfully builds one. In other
words, we will obtain a controller that guarantees when com-
posed with its environment that the products are processed
by applying tools in the correct order ( ̺), that the drill and
press are not used simultaneously ( ψ) and that if the envi-
ronment provides inﬁnitely many raw products of both types
(As) both types of products will be produced ( G).
It is interesting to note that a controller for the robot arm
that satisﬁes the speciﬁcation above when composed with
the model of the environment cannot be produced by simply
pruning the environment model (as controller synthesis tec h-
niques for safety properties do). This is because, in order t o
fulﬁll the liveness part of the speciﬁcation, a controller m ust
“remember”if it has been postponing one type of product for
too long. Say products of type Ahave been postponed for
too long, the controller must stop processing the other com-
ponent type, B, giving way to the production of Aproducts.
How much the controller waits before switching type could
vary from one controller to another, but all controllers mus t
have some sort of memory in order to achieve the liveness
condition. This memory is not encoded in the state space of
the environment and hence a controller cannot be achieved
through its pruning.
In Section 5 we describe the procedure of synthesising con-
trollers that satisfy the speciﬁcation described above, an d
hence capable of, among other things, identifying the con-
troller’s need for memorising speciﬁc aspects of the system
behaviour in order to satisfy liveness properties.
3. BACKGROUND
We use Labelled Transition Systems as deﬁned below.
6 5 41 2 3[a].inTray [a].getInTray
put.oven [a]
put.drill [a] put.press [a]put.OutTray [a]
Figure 4: Speciﬁcation for products of type A.Definition 3.1. (Labelled Transition Systems) ALabel-
led Transition System (LTS) isP= (S, L, ∆, s0), whereS
is a ﬁnite set of states, L⊆Actis itscommunicating alpha-
bet,∆⊆(S×L×S)is a transition relation, and s0∈S
is the initial state. We denote ∆(s) ={s′|(s,a,s′)∈∆}
andtraces (P)the set of traces t=s,ℓ,s′,ℓ′,· · ·ofP. We
say an LTS is deterministic if (s,ℓ,s′)and(s,ℓ,s′′)are in
∆impliess′=s′′.
The following deﬁnition is based on that of Interface Au-
tomata andLegal Environment presented in [8].
Definition 3.2. (Legal Environment) GivenM= (SM,
LM,∆M,sM0)andP= (SP,LP,∆P,sP0)LTSs, where LM
=LMc∪LMu,LMc∩LMu=∅,LP=LPc∪LPuandLPc∩
LPu=∅. We say that Mis a legal environment for Pif the
interface automaton M′=/a\}bracketle{tSM,{sM0},LMu,LMc,∅,∆M/a\}bracketri}ht
is alegal environment for the interface automaton P′=
/a\}bracketle{tSP,{sP0}, LPu,LPc,∅,∆P/a\}bracketri}ht.
We describe speciﬁcations (i.e. goals) using Fluent Linear
Temporal Logic (FLTL) [12]. Linear temporal logics (LTL)
are widely used to describe behaviour requirements [12, 22,
19]. The motivation for choosing an LTL of ﬂuents is that
it provides a uniform framework for specifying state-based
temporal properties in event-based models [12]. FLTL is a
linear-time temporal logic for reasoning about ﬂuents. A
ﬂuent ﬂ is deﬁned by a set of initiating actions Iﬂ, a set of
terminating actions Tﬂ, and an initial value Initially ﬂ. That
is,ﬂ=/a\}bracketle{tIﬂ,Tﬂ/a\}bracketri}htinitiallyﬂ, whereIﬂ,Tﬂ⊆ActandIﬂ∩Tﬂ=∅.
When we omit Initially ﬂ, we assume the ﬂuent is initially
false. We use ﬂℓas short for the ﬂuent deﬁned as ﬂ=
/a\}bracketle{tℓ,Act\ {ℓ}/a\}bracketri}ht.
Given the set of ﬂuents Φ, an FLTL formula is deﬁned in-
ductively using the standard boolean connectives and tem-
poral operators X(next), U(strong until) as follows: ϕ::=
ﬂ| ¬ϕ|ϕ∨ψ|Xϕ|ϕUψ, where ﬂ∈Φ. As usual we
introduce ∧, /BD(eventually), and /BC(always) as syntactic
sugar.
Let Π be the set of inﬁnite traces over Act. Forπ∈Π,
we writeπifor the suﬃx of πstarting at ai. The suﬃx πi
satisﬁes a ﬂuent ﬂ, denotedπi|=ﬂ, if and only if one of the
following conditions holds:
-Initiallyﬂ∧(∀j·0≤j≤i⇒aj/∈Tﬂ)
-∃j·(j≤i∧aj∈If)∧(∀k∈N·j <k ≤i⇒ak/∈Tﬂ)
From the FLTL deﬁnition it follows that many results for
LTL can be easily extended to FLTL.
Definition 3.3. (Two-player Game) ATwo-player Ga-
me(Game) isG= (Sg,Γ−,Γ+,sg0,ϕ), whereSgis a ﬁnite
set of states, Γ−,Γ+⊆Sg×Sgare transition relations, sg0∈
Sgis the initial state, and ϕ⊆Sω
gis a winning condition.
We denote Γ−(sg) ={s′
g|(sg,s′
g)∈Γ−}and similarly for
Γ+. A statesgisuncontrollable ifΓ−(sg)/\e}atio\slash=∅andcontrol-
lableotherwise. A playonGis a sequence p=sg0,sg1,....
A playpending insgnis extended by the controller choos-
ing a subset γ⊆Γ+(sgn). Then, the environment chooses a
statesgn+1∈γ∪Γ−(sgn+1)and addssgn+1top.
Astrategy with memory Ω for the controller is a pair
of functions (σ,u)where,σ: Ω×Sg→2Sgsuch that
σ(̟,s g)⊆Γ+(sg)andu: Ω×Sg→Ωsuch that Ωis
some memory domain with a designated start value ̟0. In-
tuitively,σtells controller which states to enable as possible
successors and utells controller how to update her memory.IfΩis ﬁnite, we say that the strategy uses ﬁnite memory.
A ﬁnite or inﬁnite play p=sg0,sg1,...isconsistent with
(σ,u)if for every nwe havesgn+1∈σ(̟n,sgn)∪Γ−(sgn),
where̟i+1=u(̟i,sgi+1)for alli≥0. A strategy (σ,u)
for controller is winning if every maximal play consistent
with(σ,u)is inﬁnite and in ϕ. We say that controller wins
the gameGif it has a winning strategy.
We refer to checking whether controller wins a game Gas
solving the gameG. The controller synthesis problem is to
produce a winning strategy for controller. It is well known
that if controller wins a game Gandϕisω-regular she can
win using a ﬁnite memory strategy [28]. We now deﬁne the
class of winning conditions ϕthat is of our interest.
Definition 3.4. Generalised Reactivity(1) [27] Given an
inﬁnite sequence of states p, letinf(p)denote the states that
occur inﬁnitely often in p. Letφ1,...,φ nandγ1,...,γ mbe
subsets ofS. Letgr((φ1,...,φ n),(γ1,...,γ m))denote the
set of inﬁnite sequences psuch that either for some iwe
haveinf(p)∩φi=∅or for alljwe haveinf(p)∩γj/\e}atio\slash=∅.
A GR(1) game is a game where the winning condition ϕis
gr((φ1,...,φ n),(γ1,...,γ m)).
4. EVENT BASED CONTROLSYNTHESIS
4.1 Control Problems
We now present a high level description of an event-based
control problem following the world-machine model [17]. We
distinguish between software requirements, system goals a nd
environment assumptions. We then deﬁne the LTS control
problem which grounds the event-based control problem by
ﬁxing a speciﬁc formal speciﬁcation framework: Labelled
Transition Systems and the Linear Temporal Logic of Flu-
ents. Finally, given the computational complexity of the
general LTS control problem, we deﬁne SGR(1) LTS Con-
trol, a restricted LTS control problem for expressive subse t
of temporal properties that includes liveness and allows fo r
a polynomial solution. In the next section, we show how
such polynomial solution can be achieved.
The problem of control synthesis is to automatically pro-
duce a controller that restricts the events it controls. Whe n
deployed in a suitable environment such a controller will
ensure the satisfaction of a given set of system goals. Sat-
isfaction of these goals depends on the satisfaction of pre-
scriptive assumptions by the environment. In other words,
we are given a speciﬁcation of an environment, assumptions,
system goals, and a set of controllable actions. A solution f or
theEvent-Based control problem is to ﬁnd a machine whose
concurrent behaviour with an environment that satisﬁes the
assumptions satisﬁes the goals.
We adopt labelled transition systems (LTS) and parallel
composition in the style of CSP [15] as the formal basis for
modelling the environment and the controller to be synthe-
sised, and FLTL, with its corresponding satisﬁability noti on,
as a declarative speciﬁcation language to describe both en-
vironment assumptions and system goals.
We ground the problem of control synthesis in event-based
models as follows: Given an LTS that describes the be-
haviour of the environment, a set of controllable actions,
a set of FLTL formulas as the environment assumptions and
a set of FLTL formulas as the system goals, the LTS control
problem is to ﬁnd an LTS that only restricts the occurrenceof controllable actions and guarantees that the parallel co m-
position between the environment and the LTS is deadlock
free and that if the environment assumptions are satisﬁed
then the system goals will be satisﬁed too.
Definition 4.1. (LTS Control) Given a speciﬁcation for
an environment in the form of an LTS E, a set of con-
trollable actions Ac, and a set Hof pairs (Asi,Gi)where
AsiandGiare FLTL formulas specifying assumptions and
goals respectively, the solution for the LTS control proble m
L=/a\}bracketle{tE,H,A c/a\}bracketri}htis to ﬁnd an LTS Msuch thatMwith
controlled actions Acand uncontrolled Acis a legal envi-
ronment for E,E||Mis deadlock free, and for every pair
(Asi,Gi)∈Hand for every trace πinM||Ethe following
holds: ifπ|=Asithenπ|=Gi.
The problem with using FLTL as the speciﬁcation lan-
guage for assumptions and goals is that, just like in tradi-
tional (i.e. state-based) controller synthesis, the synth esis
problem is 2EXPTIME complete [28]. Nevertheless, restric-
tions on the form of the goal and assumptions speciﬁcation
have been studied and found to be solvable in polynomial
time. For example, goal speciﬁcations consisting uniquely of
safety requirements can be solved in polynomial time, and
so can particular styles of liveness properties such as [1] a nd
GR(1). The latter can be seen as an extension of [1] to a
more expressive liveness fragment of LTL.
We now deﬁne the SGR(1) control, computable in polyno-
mial time. It builds on the GR(1) and safety control prob-
lems but is set in the context of event-based modelling. We
require the model of the environment Eto be a determin-
istic LTS, and Hto be {(∅,I),(As,G)}, whereIis a safety
invariant of the form /BCρ, the assumptions Asare a con-
junction of FLTL sub-formulas of the form /BC /BDφ, the goal
Ga conjunction of FLTL sub-formulas of the form /BC /BDγ,
andφ,ρandγare Boolean combinations of ﬂuents.
Definition 4.2. (SGR(1) LTS Control) An LTS control
problem L=/a\}bracketle{tE,H,A c/a\}bracketri}htis SGR(1) if Eis deterministic, and
H={(∅,I),(As,G)}, whereI= /BCρ,As=Vn
i=1
/BC /BDφi,
G=Vm
j=1
/BC /BDγj, andφi,ρandγjare Boolean combina-
tions of ﬂuents.
Consider the SGR(1) LTS control problem R=/a\}bracketle{tE,H,A c/a\}bracketri}ht,
whereEis the LTS in Figure 5(a), Ac={c1,c2,c3,c4,g1,g2},
H={(∅,I),(As,G)},I= /BC¬ﬂw,As= /BC /BDﬂaand
G= /BC /BDﬂg1∧ /BC /BDﬂg2. Recall that ﬂℓis a ﬂuent that
becomes true when ℓoccurs and becomes fals when any other
action occurs.
The LTSC1,C2andC3of Figures 5(b) to 5(d) are some
of the possible solutions to R:C1/bardblEhas no traces satisfying
the assumptions As, hence it is not obligated to satisfy G;
all traces in C2/bardblEsatisfyAsand alsoG; and traces in C3/bardblE
either do not satisfy Asor satisfy both AsandG. We will
discuss in the next subsection the diﬀerences between these
solutions. For now, it is interesting to note that neither C2
norC3can be obtained only by pruning E. Both models
introduce new states which allow the controller to “remem-
ber”which is the next goal that must be acheived ( g1 org2).
The automated construction of these “memory” states will
be described in detail in section 5.3.
The SGR(1) control problem restricts the form of the envi-
ronment assumptions and system goals. Thus, a valid con-
cern is the impact of this restriction on expressiveness in2 1 4
7 3 6 5c3 c1
a{g1,g2}ℓ
c3ac4c2
a w
(a)
1 2c3ℓ
(b)1 23
4
5c1ag1
ag2
(c)
2 1 34
5
6c3ℓc1ag1
ag2
(d)
Figure 5: (a) Environment Model E(b) Controller
C1(c) Controller C2(d) Controller C3
practice. A closer look at the family of liveness formulas
reveals it is not arbitrary: they are designed to capture a
Buchi acceptance condition. More concretely, any liveness
property speciﬁable by a deterministic Buchi automaton can
be handled by the proposed approach. The trick is, basically ,
to compose the Buchi automaton structure with the original
plant LTS and then use assumptions and goals to express
that their acceptance conditions will/should (respective ly)
be visited inﬁnitely often. Typical responsiveness assump -
tions and goals (e.g. /BC(φ→ /BDψ)) could be treated in
this way [27]. An example of a responsiveness goal that
does not ﬁt the syntactic requirements of SGR(1) but could
be dealt with by means of this encoding is that if a product
is waiting to be processed by the cell (i.e. it has been placed
on the in tray and not yet picked up by the arm), then it
will eventually be put onto the out tray (VMAX
id=0V
type∈{A,B}/BC(WaitingForProcessing (type, id )→ /BDput.OutTray (type,
id))where WaitingForProcessing (type,id )are ﬂuents initi-
ated by events [ type].[id].inTray and terminated by events
[type].[id].getInTray .
4.2 Assumptions and AnomalousControllers
A valid concern is if there are semantic restrictions for
what is called an assumption in a control problem. In other
words, can any assertion be provided as an assumption? or
the fact that it is deemed assumption implies that it should
have speciﬁc semantic properties? This question can also be
posed for the speciﬁc case of SGR(1) LTS control: are fur-
ther semantic restrictions needed to ensure that the formul a
As=Vn
i=1
/BC /BDφican be interpreted as an assumption on
the environment? We now answer this question.
Consider the LTS controller C1discussed in the previous
section.C1solves the SGR(1) control problem Rby simply
ensuring that for all trace π∈traces (E/bardblC1)π/\e}atio\slash|=As. Such
a solution, from an engineering perspective is unsatisfact ory:
C1should “play fair” by trying to achieve GwhenAsholds
rather than trying to avoid As. In this sense, C2andC3
are more satisfactory. The best eﬀort controller deﬁnitionprovided below formalises this preference by requiring the
following: if the controller forces Asnot to hold after a
sequenceσ, no other controller that achieves Gcould have
allowedAsafterσ.
Definition 4.3. (Best Eﬀort Controller) Given an
SGR(1) LTS control problem Lwith assumptions Asand
an LTSMsuch thatMis a solution for L, we say that M
is abest eﬀort controller forLif for all ﬁnite traces σ∈
traces (E/bardblM)if there is no σ′whereσ.σ′∈traces (E/bardblM)
andσ.σ′|=Asthen there is no other solution M′toLsuch
thatσ∈traces (E/bardblM′)and there exists σ′such thatσ.σ′∈
traces (E/bardblM′)andσ.σ′|=As
ControllerC1is not a best eﬀor controller as ǫ, the empty
trace inE/bardblC1cannot be extended in E/bardblC1to satisfyAs,
yet it can be extended by σ′=c1,2,a,3,g1,4,a,5,g2,· · ·
inE/bardblC2such thatǫ.σ′satisﬁes /BC /BDAs. On the other
hand, given that there are no traces in E/bardblC2violatingAs,
C2is aBest Eﬀort controller for R.C3is also a Best Eﬀort
controller as the only ﬁnite trace violating AsinC3isσ=
c3,· · ·and there are no extension of σsatisfyingAsandG.
Note that controller C3also could be argued to be anoma-
lous from an engineering perspective: Although C3does play
fair when choosing action c1to state 3, it can also choose
actionc3to state 2 taking E/bardblC3to a state in which assump-
tions are no longer possible. This can motivate a stronger
criterion than Best Eﬀort: the controller should never pre-
vent the environment from achieving its assumptions.
Definition 4.4. (Assumption Preserving Controller) Gi-
ven an SGR(1) LTS control problem Lwith assumptions As
and an LTS Msuch thatMis a solution for L, we say
thatMis an assumption preserving controller forLif for
all ﬁnite traces σ∈traces (E/bardblM)if there is no σ′where
σ.σ′∈traces (E/bardblM)andσ.σ′|=Asthen there does not
existσ′such thatσ.σ′∈traces (E)andσ.σ′|= (I∧As)
Property 4.1.Given an SGR(1) LTS control problem
RandMan LTS controller for R, ifMis aAssumption
Preserving controller then Mis aBest Eﬀort controller.
Property 4.1 and the fact that C1is not best eﬀort it
follows that C2is not an assumption preserving controller.
AlthoughC3is best eﬀort, it is not an assumptions preserv-
ingcontroller because the trace σ=c3,c3,a,c3,· · ·inE
is a valid extension to σ=c3,· · ·inC3/bardblEwhich satisﬁes
Aswhile violating G. On the other hand, given that ev-
ery inﬁnite trace in C2satisﬁes both AsandG,C2is an
assumptions preserving controller.
Note that the Best Eﬀort criterion compares two con-
trollers while Assumption Preserving compares the behavior
of the controlled environment against the environment.
Now, given an SGR(1) problem it is useful to know whe-
ther all solutions of an SGR(1) LTS control problem are as-
sumption preserving or best eﬀort. Interestingly, a suﬃcie nt
condition for this can be achieved by restricting the relati on
between the assumptions Asand the environment E. The
essence of this relation is based on the notion of realisabil ity
and the fact that the environment is the agent responsible
for achieving the assumptions as introduced in [22].
The notion of realisability requires that an agent respon-
sible for an assertion be capable of achieving it based on
its controlled actions regardless of what happens with theactions is does not control. In our setting, this notion can
be used to formalise a suﬃcient condition for guaranteeing
assumption preserving and best eﬀort controllers.
The condition requires the environment be capable of achi-
evingAsregardless any choice it may make and the be-
haviour of any controller that it might be composed with.
This is ensured by checking that for every state1inEthere
is no strategy for the controller to falsify As.
Definition 4.5. (Environment Assumption Compatibil-
ity)Given an SGR(1) LTS control problem L=/a\}bracketle{tE,H,A c/a\}bracketri}ht
andH={(∅,I),(As,G)}, we say that the Asis compat-
ible withEif for every state sinEthere is no solution
for the SGR(1) LTS control problem /a\}bracketle{tEs,H′,Ac/a\}bracketri}htandH′=
{(∅,I),(As,false)}, whereEsis the result of changing the
initial state of Etos.
Hence, when the assumptions of an SGR(1) LTS control
problem are compatible with the environment, it is guaran-
teed that anomalous controllers (such as those that are not
best eﬀort and assumption preserving) will not be produced.
Property 4.2.Given an SGR(1) LTS control problem L
with assumptions Asand environment E, ifAsis compatible
withEthen all solutions to Lare best eﬀort and assumption
preserving.
Note that the running example Rviolates Deﬁnition 3.2
and hence, has anomalous controllers such as C1, which is
notBest Eﬀort norAssumption Preserving , orC3which is
Best Eﬀort but not Assumption Preserving .
Also note that the assumptions for the example in Sec-
tion 2 are not compatible with the environment described in
the same section. This is because we modelled the environ-
ment so to “reuse” products once they have been processed.
In other words, rather than modelling an inﬁnite number
of products to be processed (which would lead to an inﬁ-
nite state environment) we modelled that a product, once
it has been fully processed becomes available once again
to be put as raw on the in tray. As the assumptions re-
quireAddedToInTray (t,i) inﬁnitely often, the environment
needs the robot to cooperate by processing the products in-
ﬁnitely often. Hence, the environment cannot guarantee the
assumptions independently and a solution to the running
example could be a robot that does absolutely nothing. A
more appropriate assumption, which would guarantee non-
anomalous controllers, is one that states that the environ-
ment reacts to products being placed in the out tray by
eventually placing them back on the in tray:/BC(AddedToOutTray (t,i)→ /BDAddedToInTray (t,i)).
Such a formula can, as mentioned previously and discussed
in [27], be encoded into our framework.
Summarising the latter part of this section, best eﬀort
and assumption preserving controllers explain technicall y
the sort of anomalies that might arise if requirement en-
gineering practices such as ensuring realisability of assu mp-
tions by the environment are violated.
In the next section we present how to solve SGR(1) LTS
problems. The synthesis algorithm we implemented does not
require environment-assumption compatibility. However, as
explained above, such a condition is desirable.
1The adds no computational complexity to the control problem5. SOLVINGSGR(1)CONTROL
In this section we explain how a solution for the SGR(1)
control problem can be achieved by building on existing
(state-based) controller synthesis techniques, namely GR (1).
The construction of the machine for an SGR(1) LTS con-
trol problem has two steps. Firstly, a GR(1) game Gis cre-
ated from the environment model E, the assumptions As,
the goalsGand the set of controllable actions Ac(Section
5.1). Secondly, a solution ( σ,u) to the GR(1) game is used
to build a solution M(i.e. an LTS controller) for L(Section
5.2). We also show that our approach is sound and complete.
That is, a solution to the SGR(1) LTS control problem L
exists if and only if a solution to the GR(1) game Gexists.
Furthermore, the LTS controller Mbuilt from ( σ,u) is a
solution to L.
The reader not interested details of the mapping of SGR(1)
into GR(1) can skip directly to Section 5.3 where we com-
ment on the implementation of the synthesis technique and
show a controller for a reduced version of the Production
Cell case study.
5.1 SGR(1)LTS control to GR(1)games
We convert the SGR(1) LTS control problem into a GR(1)
game. Given a SGR(1) LTS control problem L=/a\}bracketle{tE,As,G,
Ac/a\}bracketri}htwe construct a GR(1) game G= (Sg,Γ−,Γ+,sg0,ϕg)
such that every state in Sgencodes a state in Eand a val-
uation of all ﬂuents appearing in AsandG.
More precisely, consider an SGR(1) LTS control prob-
lemL=/a\}bracketle{tE,As,G,A c/a\}bracketri}ht, where,E= (Se,L,∆e,se0),As=Vn
i=1
/BC /BDφiandGis separated in G= /BCρandVm
j=1
/BC /BDγj. Let ﬂ={ﬂ1,...,ﬂk}be the set of ﬂuents
used inAsandGandﬂi=/a\}bracketle{tIﬂi,Tﬂi/a\}bracketri}htinitiallyi. The game
G= (Sg,Γ−,Γ+,sg0,ϕg) is constructed as follows.
We buildSgfromEsuch that states encode a state in
Eand truth values for all ﬂuents in ϕ: Let Sg=Se×Qk
i=1{true,false}. Consider a state sg= (se,α1,...,α k). Gi-
ven ﬂuent ﬂi, we say that sgsatisﬁes ﬂiifαiistrueandsg
does not satisfy ﬂiotherwise. We generalise satisfaction to
Boolean combination of ﬂuents in the natural way.
We build transition relations Γ−and Γ+using the follow-
ing rules. Consider a state sg= (se,α1,...,α k). Ifsgdoes
not satisfy ρ(i.e.,sgis unsafe) we do not add successors to
sg. Otherwise, for every transition ( se,ℓ,s′
e)∈∆ewe in-
clude (sg,(s′
e,α′
1,...,α′
k)) in Γβ, whereβis + ifℓ∈Ac,β
is−ifa /∈Acand (1)α′
iisαiifℓ /∈Iﬂi∪Tﬂi, (2)α′
iistrue
ifℓ∈Iﬂiand (3)α′
iisfalseifℓ∈Tﬂi. The initial state sg0
is (se0,initially 1,...,initially k).
We build the winning condition ϕg, deﬁned to be a set of
inﬁnite traces, from ASandGas follows: We abuse notation
and denote by φithe set of states sgsuch thatsgsatisﬁes
the assumptions φiand byγithe set of states sgsuch that
sgsatisﬁes the goal γi. Letϕg⊆Sω
gbe the set of sequences
that satisfy gr((φ1,...,φ n),(γ1,...,γ m)). It follows that
G= (Sg,Γ−,Γ+,sg0,ϕg) is a GR(1) game.
It can be shown that if there is a solution to a SGR(1)
LTS control problem then there is a winning strategy for a
controller in the constructed GR(1) game (refer to Proposi-
tion 5.1).
Note that the safety part of the speciﬁcation is not en-
coded as part of the wining condition ϕgof the GR(1) game,
rather it is encoded as a deadlock avoidance problem when
constructing Γ−and Γ+. Consequently, the winning condi-
tion we realise is /BCρ∧(Vn
i=1
/BC /BDφi=⇒Vm
j=1
/BC /BDγj)1 2,ﬂc32,ﬂℓ 2,ﬂa
3,ﬂc23,ﬂa4,ﬂc1
4,ﬂg14,ﬂg25,ﬂa
6,ﬂc4
6,ﬂw 7,ﬂc3γ+γ−γ−
γ+γ−
γ−γ+γ−
γ+
γ−γ−γ+
γ−γ−γ+γ−
γ+γ−
γ+γ−
(a)
1 4,ﬂc15,ﬂa4,ﬂg1
4,ﬂg25,ﬂaγ+γ−γ+
γ−
γ+γ−
(b)
Figure 6: (a) Transition relations for the game GR
(b) Wining strategy for GR
Figure 6(a) shows the transition relations Γ−and Γ+for
GR, the game obtained by applying to Rthe procedure de-
scribed above. Transitions in Γ−and Γ+are marked as γ−
andγ+respectively. States are labelled with a state in the
original LTS model (i.e. model Ein Figure 5(a)) and the
set of ﬂuents holding in the state of the LTS model.
5.2 Translating strategies to LTS Controllers
We now show how to extract an LTS controller from a
winning strategy for the GR(1) game that was obtained from
the SGR(1) LTS control problem as shown in Section 5.1.
Intuitively, the transformation is as follows: given an
SGR(1) LTS control problem L=/a\}bracketle{tE,As,G,A c/a\}bracketri}ht, the game
G= (Sg,Γ−,Γ+,sg0,ϕg) obtained from Land a winning
strategy for G, we buildM= (Sm,L,∆m,sm0) a solution
toLby encoding in states of Sma state ofSgand a state
of the memory given by the winning strategy.
More precisely, consider an SGR(1) LTS control problem
L=/a\}bracketle{tE,As,G,A c/a\}bracketri}ht. LetE= (Se,L,∆e,se0),ﬂ={ﬂ1,...,
ﬂk}the set of ﬂuents appearing in ϕandG= (Sg,Γ−,Γ+,
sg0,ϕg) be the GR(1) game constructed from Eas above and
letσ: Ω×Sg→2Sgandu: Ω×Sg→Ω be a winning strat-
egy inG. We construct the machine M= (Sm,L,∆m,sm0)
as follows.
To buildSm⊆Ω×Sg, consider two states sg= (se,α1,...,
αk) ands′
g= (s′
e,α′
1,...,α′
k). We say that action ℓispossi-
blefromsgtos′
gif (sg,s′
g)∈Γ−∪Γ+, there is some action
ℓsuch that (se,ℓ,s′
e)∈∆eand for every ﬂuent ﬂieither (1)
ℓ /∈Iﬂi∪Tﬂiandα′
i=αi, (2)ℓ∈Iﬂiandα′
i=true, or (3)
ℓ∈Tﬂiandα′
i=false.
To build ∆ m⊂Sm×L×Sm, consider a transition ( sg,s′
g)
∈Γ−. By deﬁnition of Γ−there is an action ℓ /∈Acsuch
thatℓis possible from sgtos′
g. Ifs′
g∈σ(m,s g) then for
every action ℓsuch thatℓis possible from sgtos′
gwe add
((m,s g),ℓ,(u(m,s g),s′
g)) to ∆ g. Similarly, consider a tran-
sition (sg,s′
g)∈Γ+. By deﬁnition of Γ+there is an action
ℓ∈Acsuch thatℓis possible from sgtos′
g. Ifs′
g∈σ(̟,s g)
then for every action ℓsuch thatℓis possible from sgtos′
g
we add ((̟,s g),ℓ,(u(̟,s g),s′
g)) to ∆ g.The initial state of Mis deﬁned as sm0= (̟0,sg0) where
̟0is the initial value for the memory domain Ω. This com-
pletes the deﬁnition of M.
Consider the game GRand a strategy ( σ,u) that tries to
fulﬁll the goals at the same time the environment fulﬁlls
its assumptions. That is, a strategy that satisﬁes /BC /BDﬂa,/BC /BDﬂg1and /BC /BDﬂg1. The only possible solution to such
requirements is to have in ( σ,u), a cycle visiting (5 ,ﬂa),
(4,ﬂg1) and (4,ﬂg2) in some order. A strategy satisfying
this is shown in Figure 6(b). Note that some memory is
needed to distinguish whether state (4 ,ﬂg1) or (4,ﬂg2) has
to be visited after visiting (5 ,ﬂa). Finally, in Figure 5(c) we
show the LTS controller obtained by applying the conversion
shown above to the strategy in Figure 6(b).
In Proposition 5.2 we show that if ( σ,u) is winning strat-
egy for a GR(1) game Gconstructed from a to a SGR(1)
LTS control problem L, then the LTS Mconstructed as ex-
plained above is a solution to L. Note that to prove this
proposition environment ( E) determinism is needed.
Proposition 5.1. (Completeness) LetLbe an SGR(1)
LTS control problem, and Gbe a GR(1) game constructed
by applying the conversion shown in Section 5.1 to L. If
Mis a solution for the SGR(1) problem Lthen there exists
a strategy (σ,u)such that: (σ,u)is winning for Gand the
LTS controller obtained by applying the translation shown i n
Section 5.2 to (σ,u)is equivalent to M.
Proposition 5.2. (Soundness) LetLbe a SGR(1) LTS
control problem and Gbe a GR(1) game constructed by ap-
plying the conversion shown in Section 5.1 to L,σbe a tran-
sition relation and ube an update function. If (σ,u)is win-
ning strategy for G, andMis the LTS obtained by applying
the conversion shown in Section 5.2, then it holds that Mis
a solution for L.
5.3 Implementation
The original algorithm for solving GR(1) games [27] ma-
nipulates sets of states using a symbolic representation in
the form of BDDs. We implemented a rank-based algorithm,
that is better suited for explicit state space representati on
allowing for integration within the MTSA tool set [10].
To test our implementation we applied it to the case study
presented in Section 2. The size of the environment model
is over 2000 states, the size of the synthesised controller i s
above 1000 states and it takes 3s to compute the strategy.
Since the size of the models is too big to be depicted in this
paper, we show the controller for a smaller version, which
has only one tool (a drill) and can only process one instance
of each product type at a time. The synthesised controller
is shown in Figure 7. Note the states introduced by the
algorithm to remember the last product type processed in
order to guarantee the system goals. The controller waits
for products of type Ato be processed ﬁrst (see states 2
and 7) regardless of whether there are products of type B
ready to be processed (see state 9). It then does the same
for products of type B.
6. RELATED WORK
Our work builds on that of the controller synthesis com-
munity and particularly on the generalised reactivity synt he-
sis algorithm GR(1) proposed in [27]. The community has
largely focused on controllers for embedded systems and dig -
ital circuits, hence adopting a shared memory model: The0{a, b}[1].idle
2a[1].inTray
9b[1].inTray
1b[1].putOutTrayb[1].idle
7b[1].inTray
8a[1].getInTray
3a[1].idle
4a[1].inTray
5get.oven.b[1]
get.oven.b[1]b[1].putOutTray
a[1].inTraya[1].idle6
put.oven.b[1]17a[1].getInTrayb[1].idle
b[1].inTray
19put.oven.a[1]a[1].inTraya[1].idle
10b[1].idle
11a[1].putOutTray
12b[1].inTray
{a, b}[1].idle
13b[1].inTray
16a[1].inTray a[1].putOutTray
a[1].idle
14a[1].inTray
15b[1].getInTray
b[1].getInTray put.oven.b[1] a[1].inTraya[1].idleb[1].inTrayb[1].idle18put.oven.a[1]
get.oven.a[1]get.oven.a[1] b[1].inTrayb[1].idle
Figure 7: Controller for reduced Production Cell.
controller is aware of changes in the environment by query-
ing the state space shared with the environment. For in-
stance, GR(1) uses kripke structures, state machines with
propositional valuations on states, where the environment
and the controller update and read respectively controlled
and monitored propositions. However, in many settings such
as requirements engineering, architectural design and sel f-
adaptive systems, a message passing communication model
in the context of a distributed system is typically consider ed.
Hence, controller synthesis techniques require being adap ted
to the notion of event-based communicating machines [15].
This adaptation, speciﬁcally to Labelled Transition Syste ms
(LTS) [20] semantics and CSP-like parallel composition [15 ],
is a contribution of this paper. The change from state-based
to event-based introduces the need for determinism of the
environment to guarantee that the controller has suﬃcient
information about the state of the environment to guarantee
it satisﬁes its goals (see Deﬁnition 4.2 and Property 5.2).
The change also introduces the need for a sound method-
ological approach to the deﬁnition of assumptions in order
to avoid anomalous controllers.
Although many behaviour model synthesis techniques ha-
ve been studied (e.g. [7, 5]) these are restricted to user-
deﬁned safety requirements. The exceptions that we are
aware of relate to the self-adaptive systems and the plannin g
communities.
In the self-adaptive community many architectural ap-
proaches for adaptation have been proposed. At the heart
of many adaptation techniques, there is a component ca-
pable of designing at run-time a strategy for adapting tothe changes in the environment, system and requirements
(e.g. [6, 11]). These architectures do not prescribe the mec h-
anism for constructing adaptation strategies. The techniq ue
we propose could be used in the context of any of these ar-
chitectures. In fact, we believe, that the methodological
guidance that our approach oﬀers will help integrating the
controller synthesis techniques into these architectures in a
sound way.
Various approaches to automated construction of adapta-
tion strategies exists. Sykes et al. in [31] build on the“Pla n-
ning as Model Checking” framework [13] to construct plans
that aim to guarantee reaching a particular goal state, henc e
a certain liveness requirement must be dealt with. The ex-
ecution of the plan is restarted every time the environment
behaves unexpectedly, hence there is an implicit assumptio n
that the environment behaves “well enough” for the system
to eventually reach the goal state. Validating that the en-
vironment will behave “well enough” is not possible as the
notion is not deﬁned, hence the plans do not provide the
expected guarantees.
More generally, the planning as model checking framework
(e.g., [13]), supports CTL goals, requires a model in the for m
of a kripke structure and does not consider the problem of
composing the environment with a machine that is respon-
sible for guaranteeing the system goals. Consequently, it
does not distinguish between controllable and monitorable
actions, and the plans that are generated would not be re-
alisable by the software system.
Finally, our work is heavily inﬂuenced by the work on re-
quirements engineering by Jackson [17] van Lamsweerde [21]
and Parnas [26] who have argued the importance of distin-
guishing between descriptive and prescriptive assertions , be-
tween software requirements, system goals and environment
assumptions, and the key role that the latter play in the
validation process.
7. FURTHER EVALUATION
In this section we show the results of applying our tech-
nique to a case study originally presented in [14] in the con-
text of self-adaptive systems. The case study was performed
using an implementation of the control synthesis algorithm
described above integrated into the Modal Transition Sys-
tem Analyser. The modiﬁed tool together with the running
example and the case study are available at [10].
Consider a situation in which a two-bedroom house has
collapsed leaving only one small passage between the two
rooms (refereed to as north andsouth rooms). The en-
trance door of the house is in the south room and there is
a group of people trapped in the north room. The task of
bringing aid packages to the occupants trapped inside is too
dangerous for humans, hence, a robotic system is required.
A robot that has a wide range of movements and has an
arm capable of loading and unloading packages. The robot
has a number of sensors which can be used, among other
things to check if a loading operation, which is of a signiﬁ-
cant amount of complexity and uncertainty, is successful or
not. The situation is complicated by the presence of a door
between the two rooms. The door cannot be opened by the
Koala robot. However, although the structure is unstable,
it is assumed that the door can be opened and closed by the
trapped occupants.
A model of the environment was constructed by compos-
ing a model of the robot (with actions such as moveNorth ),its robot arm (with actions such as getPackage and sensors
(e.g.getPackageOk ,getPackageFailed ), a model of the
door (e.g. openDoor ) and the a topological model of the
house which restricts movements according to the position
of the robot and the status of the door. For instance, it de-
scribes that the robot only can be loaded near the door and
it can’t move until the loading is accomplished successfull y.
The aim is to automatically synthesise a controller for
the robot that will achieve the task of retrieving aid pack-
ages from the outside to the room where the trapped occu-
pants are trapped. Hence, the set of controllable actions is
the set of actions that correspond to the actions that can
be performed by the robot and its arm (e.g. moveNorth ,
getPackage ) excluding actions events such as openDoor or
getPackageOk .
The formalisation of the goals is divided into two parts.
The safety part Iprescribes the legal places for loading and
unloading the robot (e.g. the robot must not unloaded pack-
ages in rooms other than the north room) The liveness part
of the goal states that, inﬁnitely often, the robot must be
at the far end of north room and have just unloaded: G=/BC /BDPos4∧JustUnLoadeded .
The control problem, as deﬁned up to this point is not
solvable as the robot has no guarantees that the door will
be open for it to move freely to and from the north and
south rooms. Introducing the assumption that the door is in-
ﬁnitely often open ( As= /BC /BDDoorOpen ) is still insuﬃcient
as our implementation reports that the SGR(1) LTS control
problem cannot be solved. The problem is that the robot has
no control over the success or failure of attempting to load
an aid package using the arm. Thus, a missing assumption
stating that if the robot attempts to load a package it will
eventually succeed: /BC(getPackage ⇒ /BDGetPackageOk ).
When assumptions regarding the door being open and pack-
age loading being successful are included in the SGR(1) LTS
control problem, a solution exists and is constructed auto-
matically by the tool. It is interesting to note that the last
assumption is compatible with the environment thanks to
the topology of the plant. Consider the case in which the
robot is near to the door it’s not moving and it’s unloaded.
In such case the topological model indicates that the robot
can’t leave its position if it is not successfully loaded. Th us,
after a failed loading the robot is forced to retry. Thus, no
controller would be able to prevent the environment to fulﬁl
its promise. Nevertheless, if after a loading fail the robot
could not only to retry but also to move then the environ-
ment would not be able to fulﬁl its assumptions on its own
and would depend on the controller’s decision to retry or
not. Therefore, this illustrates how compatibility would b e
actually violated and although our algorithm yields a best
eﬀort controller that could not be taken for granted.
Comparing our approach to the original case study, note
that in [31] (i)no assumptions are explicitly given, as a result
(i)no guarantees can be given as to wether the synthesised
controller will satisfy the goal of delivering aid packages , and
(iii)although under certain conditions the synthesised plan
will work, it is not clear what those circumstances are.
8. CONCLUSIONSAND FUTUREWORK
Synthesis for liveness goals of event-based systems poses
not only algorithmic but also methodological challenges. I n
this paper, we proposed a technique that works for an ex-
pressive subset of liveness properties, that distinguishe s be-tween controlled and monitored actions [26], diﬀerentiate s
between prescriptive and descriptive [16] aspects of the sp ec-
iﬁcation of system goals, environment behaviour, and envi-
ronment assumptions.
We presented the event-based and deﬁned the LTSand
SGR(1) control problems, which are control problems set in
a theoretical framework adequate for event-based models.
The ﬁrst acts as a general deﬁnition, the second grounds
the speciﬁcation language to LTSs and FLTL, and the third
supports safety and GR(1)-like properties. We provide a so-
lution that works in polynomial time and is based on a rank
computation [18], which is more suitable for explicit state
space representation. Besides, we identify a class of anoma -
lous controllers that even correct and complete algorithms
like ours might yield if no further restrictions were requir ed
for the assertions acting as liveness assumptions on the en-
vironment. Furthermore, we identify an eﬀective condition
for assumptions that rules out those anomalies.
There are a number of avenues for future work. We aim
at relaxing the requirement on determinism for the envi-
ronment model that is currently in place for assuring the
soundness of our approach. In fact, this is closely related t o
non-observability of events controlled by the environment .
Finally, we aim to validate if our deﬁnitions of controller
anomalies are complete. In other words, if they match our
intuitions of what a good controller is.
9. REFERENCES
[1] E. Asarin, O. Maler, A. Pnueli, and J. Sifakis.
Controller synthesis for timed automata. In
Proc. SSC , pp. 469–474. 1998.
[2] M. Autili, P. Inverardi, M. Tivoli, and D. Garlan.
Synthesis of” correct” adaptors for protocol
enhancement in component-based systems.
Proc. SAVCBS , pp. 79, 2004.
[3] P. Bertoli, A. Cimatti, M. Pistore, M. Roveri, and
P. Traverso. MBP: a model based planner. In Proc.
IJCAI Workshop on Planning under Uncertainty and
Incomplete Information . 2001.
[4] A. Bertolino, P. Inverardi, P. Pelliccione, and
M. Tivoli. Automatic synthesis of behavior protocols
for composable web-services. In Proc. FSE ,
pp. 141–150, 2009.
[5] Y. Bontemps, P. Schobbens, and C. L ¨oding. Synthesis
of open reactive systems from scenario-based
speciﬁcations. Fundamenta Informaticae ,
62(2):139–169, 2004.
[6] F. Dalpiaz, P. Giorgini, and J. Mylopoulos. An
Architecture for Requirements-Driven
Self-reconﬁguration. In Proc. AISE , pp. 260.
Springer, 2009.
[7] C. Damas, B. Lambeau, and A. van Lamsweerde.
Scenarios, goals, and state machines: a win-win
partnership for model synthesis. In Proc. FSE ,
pp. 197–207, 2006
[8] L. De Alfaro and T. Henzinger. Interface automata.
ACM Software Engineering Notes , 26(5):120, 2001.
[9] N. D’Ippolito. MTSA Tool., 2010.
http://www.doc.ic.ac.uk/ srdipi/fse2010/.
[10] N. D’Ippolito, D. Fischbein, M. Chechik, and
S. Uchitel. MTSA: The modal transition system
analyser. In Proc. ASE , pp. 475–476, 2008.[11] D. Garlan, S. Cheng, A. Huang, B. Schmerl, and
P. Steenkiste. Rainbow: Architecture-based
self-adaptation with reusable infrastructure.
Computer , pages 46–54, 2004.
[12] D. Giannakopoulou and J. Magee. Fluent model
checking for event-based systems. ACM Software
Engineering Notes , 28(5):257–266, 2003.
[13] F. Giunchiglia and P. Traverso. Planning as model
checking. In Proc. ECP RAAP , pages 1–20, 2000.
[14] W. Heaven, D. Sykes, J. Magee, and J. Kramer. A
Case Study in Goal-Driven Architectural Adaptation.
InProc. SEfSAS , page 127. Springer, 2009.
[15] C. Hoare. Communicating sequential processes.
CACM , 21(8):677, 1978.
[16] M. Jackson. Software Speciﬁcations and Requirements:
a lexicon of practice, principles and prejudices .
Addison-Wesley, 1995.
[17] M. Jackson. The world and the machine. In
Proc. ICSE , pp. 283–292, 1995.
[18] M. Jurdzi´ nski. Small progress measures for solving
parity games. In Proc. STACS , LNCS 1770,
pp. 290–301, 2000. Springer-Verlag.
[19] R. Kazhamiakin, M. Pistore, and M. Roveri. “Formal
Veriﬁcation of Requirements using SPIN: A Case
Study on Web Services”. In Proc. SEFM , 2004.
[20] R. Keller. “Formal Veriﬁcation of Parallel Programs”.
CACM , 19(7):371–384, 1976.
[21] A. V. Lamsweerde. Goal-oriented requirements
engineering: A guided tour. Requirements Engineering,
IEEE International Conference on , 0:0249, 2001.
[22] E. Letier and A. Van Lamsweerde. Agent-based tactics
for goal-oriented requirements elaboration. In
Proc. ICSE , volume 24, pages 83–93, 2002.
[23] C. Lewerentz and T. Lindner, editors. Formal
Development of Reactive Systems - Case Study
Production Cell , LNCS 891. Springer, 1995.
[24] J. Magee and J. Kramer. Concurrency: state models &
Java programs . Wiley New York, 2006.
[25] Z. Manna and A. Pnueli. The temporal logic of reactive
and concurrent systems: Speciﬁcation . Springer, 1992.
[26] D. L. Parnas and J. Madey. Functional documents for
computer systems. SCP, 25(1):41 – 61, 1995.
[27] N. Piterman, A. Pnueli, and Y. Sa’ar. Synthesis of
reactive (1) designs. In Proc. VMCAI , LNCS 3855,
pp. 364-381, 2006.
[28] A. Pnueli and R. Rosner. On the synthesis of a
reactive module. In Proc. POPL , pp. 179–190, 1989.
[29] P. Ramadge and W. Wonham. The control of discrete
event systems. Proc. of the IEEE , 77(1):81–98, 1989.
[30] S. Russell and P. Norvig. Artiﬁcial intelligence: a
modern approach. New Jersey, 1995.
[31] D. Sykes, W. Heaven, J. Magee, and J. Kramer.
Plan-directed architectural change for autonomous
systems. In Proc. FSE , pp. 15–21, 2007.
[32] S. Uchitel, G. Brunet, and M. Chechik. Behaviour
model synthesis from properties and scenarios. In
Proc. ICSE , pp. 34–43, 2007.
[33] A. van Lamsweerde and E. Letier. “Handling
Obstacles in Goal-Oriented Requirements
Engineering”. Trans. on SE , 26(10):978–1005, 2000.