Static Extraction of Program Conﬁguration OptionsAriel Rabkinasrabkin@cs.berkeley.eduRandy Katzrandy@cs.berkeley.eduElectrical Engineering and Computer Science DepartmentUniversity of California, BerkeleyABSTRACTMany programs use a key-value model for conﬁguration op-tions. We examined how this model is used in seven opensource Java projects totaling over a million lines of code. Wepresent a static analysis that extracts a list of conﬁgurationoptions for a program. Our analysis ﬁnds 95% of the op-tions read by the programs in our sample, making it morecomplete than existing documentation.Most conﬁguration options we saw fall into a small numberof types. A dozen types cover 90% of options. We presenta second analysis that exploits this fact, inferring a type formost options. Together, these analyses enable more visibil-ity into program conﬁguration, helping reduce the burden ofconﬁguration documentation and conﬁguration debugging.Categories and Subject DescriptorsD.2.7 [Software Engineering]: Distribution, Maintenance,and Enhancement—Documentation,ExtensibilityGeneral TermsManagement, MeasurementKeywordsConﬁguration, documentation, experiences, static analysis1. INTRODUCTIONModern systems software often exposes a wide range ofconﬁguration options to users. By setting conﬁguration op-tions, users can control many aspects of execution. Conﬁgu-ration determines such aspects of execution as where in thelocal ﬁlesystem to store data, which ports a server shouldbind to, and even which algorithms should be used in variousparts of a large system.Program conﬁguration is often stored as a map from op-tion name to value. Some conﬁguration mechanisms, such asthe Unix system environment, use arbitrary strings as optionPermission to make digital or hard copies of all or part of this work forpersonal or classroom use is granted without fee provided that copies arenot made or distributed for proﬁt or commercial advantage and that copiesbear this notice and the full citation on the ﬁrst page. To copy otherwise, torepublish, to post on servers or to redistribute to lists, requires prior speciﬁcpermission and/or a fee.ICSEMay 21-28 2011, Waikiki, Honolulu , HI, USACopyright 2011 ACM 978-1-4503-0445-0/11/05 ...$10.00.names. Other mechanisms, such as the Windows Registry,store options hierarchically in a tree structure. Still othersystems use XML formats for conﬁguration data, where thepath to the value represents its name. This key-value styleof conﬁguration is convenient for programmers, because itmakes it easy to add new options incrementally. There is noschema or centralized list of supported options.Several kinds of errors can arise from this style of conﬁg-uration. User-written conﬁguration ﬁles can assign valuesfor options that a program never reads, either because ofa typing error or because program evolution resulted in anoption being removed or renamed. Documentation is of-ten updated separately from code, and can fall out of stepwith an evolving program [28, 29]. As we show, documenta-tion sometimes claims that an option has a particular eﬀect,when in fact that option is never used at all. Conversely,a newly added conﬁguration option does users little goodif it is not documented. The open source systems softwarewe study all have signiﬁcant undocumented conﬁgurability,suggesting that this is a widespread problem.Programmers often distrust documentation, preferring toread source code to understand program behavior [18, 29].While this attitude may be appropriate for programmers,it works less well for users and administrators. Bad doc-umentation is a signiﬁcant bar to adoption of open-sourcesoftware, as well as a considerable headache for users [19].Excess conﬁgurability and poor documentation have beenrecognized as a problem for several years [22] but solutionshave been slow to emerge.This paper argues that static analysis can compensate forthe weaknesses of this key-value style of conﬁguration man-agement. Static analysis can extract a schema for conﬁgu-ration, tying both user conﬁguration ﬁles and program doc-umentation back to the actual structure of the associatedprogram. This can be done eﬃciently for substantial exist-ing systems that would be expensive or diﬃcult to rewrite.We make three contributions. First, we document theway this key-value conﬁguration pattern is used in a rangeof open source projects. We analyzed seven open-sourceprograms, totaling well over a million lines of code and rep-resenting the work of many dozens of developers. We ob-served that conﬁguration options tend to be used in stan-dardized ways. There are modest number of use patternsthat together account for more than 90% of options. Wefound pervasive documentation errors. Every program inour sample had documentation for options that do not ac-tually exist as well as signiﬁcant numbers of undocumentedoptions.Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ICSE ’11, May 21–28, 2011, Waikiki, Honolulu, HI, USA
Copyright 2011 ACM 978-1-4503-0445-0/11/05 ...$10.00
131
These pervasive errors motivate our second contribution.We describe and evaluate a static analysis that outputs alist of conﬁguration options potentially used by a programand the program points where each option is read. Thisanalysis ﬁnds more than 95% of the options in the programswe inspected. This accuracy rate is higher than in the doc-umentation of mot of the associated programs, making theanalysis practical for ﬁnding documentation errors.The analysis can also help catch mistakes made by users.In operational experience at Yahoo!, typographic errors inoption names are a major cause of problems with Hadoopand related programs1. A Hadoop user can easily set thevalue of a non-existent option likedefault.fs.namewhenthey meant to refer to a similarly-named real option,fs.default.name, instead. There is no central list of valid op-tions that can be used as a dictionary for a “spell checkfor conﬁguration”; references to conﬁguration options arescattered throughout the code. As a result, this sort of er-ror produces few overt symptoms and can be frustrating totrack down. The developers could potentially maintain alist of valid options for use in conﬁguration checking, butthe many ﬂaws we found in program documentation suggestthat task is diﬃcult and error-prone. Automated analysis,by reducing the burden, can help.Last, we present and evaluate an additional analysis thatcan infer the domain of valid values for an option. Our ap-proach works by recognizing the speciﬁc patterns by whichdevelopers use conﬁguration. This approach ﬁnds types formost options in our sample, and has few false positives. Thisanalysis builds on the previous one, consuming the set of op-tions read by the program. It also builds on (and validates)the results of our empirical study: recognizing patterns incode makes sense because a small set of patterns covers alarge fraction of options.There are several applications for this analysis. It canbe used to produce a ﬁrst draft of program documentationfor humans. It can also produce machine-readable speciﬁ-cation for the permissible values of options. There has beenwork by the systems community on automatic performancetuning, for instance [8], and by the software engineeringcommunity on conﬁguration-aware resolution of reﬂectionin method calls [27]. Being able to automatically ﬁnd tun-able numeric parameters or class-name parameters would behelpful in these contexts.Finding constraints on option values, even on a subsetof options, would help catch additional user conﬁgurationerrors. Our analysis can automatically determine not onlythathadoop.util.hash.typeis an option, but that the onlypossible values for it are “murmer” and “jenkins”. Programsdo not consistently report conﬁguration errors [13]; often,they silently substitute a default value. Extracting con-straints on option values enables static checking for thesesorts of mistakes, potentially saving hours of user time if abad conﬁguration value causes a long batch job to go awry.This extends our “spell check for conﬁguration” to validatevalues, not just names.We opt for static, rather than dynamic analysis. Manyoptions are used only in particular program modules or as aresult of particular inputs. Hence, dynamic testing has poorprospects for ﬁnding all uses of conﬁguration options. Staticanalysis can attain high coverage much more easily. Our1Owen O’Malley, Yahoo!, Personal communication, January2010.analysis uses standard points-to and call graph constructionalgorithms. Our code bases of interest make heavy use ofreﬂection and remote procedure calls. This requires sometailoring of the analysis implementation. Those aspects ofour analysis are discussed in Section 4.2.We begin in the next section with our empirical measure-ments. In Section 3 we show how static analysis can ﬁndthe set of options used by a program. In Section 4, we de-scribe and evaluate an analysis framework for determiningthe types of conﬁguration options. Section 5 discusses howgeneral the problem and solution presented in this paperare. Section 6 describes related work. We summarize ourobservations and conclusions in Section 7.2. QUANTIFYING PROGRAM CONFIGU-RATION OPTIONSTo better understand program conﬁgurability, we lookedat the conﬁguration mechanisms in a range of existing soft-ware projects. For each program, we consulted the docu-mentation and default conﬁguration ﬁles to derive a list ofoptions. We then manually classiﬁed each option.We looked for large highly conﬁgurable open-source soft-ware packages written in Java. We restricted ourselves toJava because our static analysis implementation targets Javaand we use the results of the survey discussed here as groundtruth in evaluating the analysis. Each package includes sev-eral diﬀerent programs, sharing much of their code.The projects we analyze span a range of applications andhave a wide variety of developers. Several were developedfor industrial use by commercial developers. Hadoop is adistributed ﬁlesystem and MapReduce implementation [9]largely developed at Yahoo! and Facebook. HBase [2] is are-implementation of Google’s BigTable storage architecturedeveloped by a loose collection of open-source developersspread across several companies. Derby is an open-sourcedatabase originally developed as part of IBM’s Cloudscapeproject [1]. Cassandra is a distributed storage service devel-oped at Facebook [17]. Other projects were developed in anacademic context. FreePastry is a peer-to-peer distributedhash table intended for the wide area, originally developedat Rice [25]. JChord is a program analysis engine developedat Stanford [23]. Nachos is a model operating system envi-ronment used for undergraduate education at Berkeley [11].The code we analyze is the work of many programmers.We do not have precise counts for the number of contribu-tors to each project but in aggregate the number is surelyover 100. Derby and Hadoop together list 50 committers.Typically there are several times as many occasional con-tributors who are not individually credited. We thereforebelieve the programs in our study represent a range of pro-gramming styles and are unlikely to be unduly inﬂuenced bythe idiosyncrasies of a few individuals.2.1 A Taxonomy of Conﬁguration OptionsRather than impose a taxonomyex ante, we built oursbottom-up, describing each option as we encountered it andthen looking for patterns. We show statistics for each of theindividual programs in our study in Table 1. We also presentbackground statistics about each program. As can be seen,there is substantial variance across these programs: the ab-solute number of identiﬁers and the proportion of identiﬁersin each column varies widely. FreePastry, for instance, has132ApplicationLoCKB compiledNumericIdentiﬁerModeOtherAll optionsCassandra36,8231,96117143236Derby1,136,7187,9031617231369FreePastry175,0856,07315483910211Hadoop167,6535,44089703116206HBase104,7813,14938203364JChord35,7611,209526141257Nachos10,8964672410016Total32115912356659Table 1: Numbers of options by application, with breakdown by type of option. KB compiled = size ofcompiled binary, in kilobytes.TypeCategoryTotalTime IntervalNumeric118CountNumeric115BooleanMode104FileIdentiﬁer60SizeNumeric53Class NameIdentiﬁer38AddressIdentiﬁer28FractionNumeric28Mode nameMode18StringOther17Port numberIdentiﬁer13Internal IDOther9PasswordOther8URIIdentiﬁer7User IDOther7Network InterfaceIdentiﬁer5Other-31Total659Table 2: The most common conﬁguration optiontypes, with classiﬁcation.a very large number of controllable timers that boosts boththe total and numeric columns. Table 2 shows our list ofoption types and how many instances we found of each typeof option, summing across all the programs in our study.Several categories need explanation: acountis an integerparameter describing how many of some entity should ex-ist, such as threads in a pool, iterations of a loop, and soforth. Asizeis a quantity of memory or storage, measuredin bytes. Amode nameis a string, drawn from a small set,that selects how a program should behave from a small set ofoptions. Aninternal IDidentiﬁes some program-deﬁned en-tity, such as distributed ﬁles in the case of Hadoop. “String”and “Number” are catch-all types for string or numeric op-tions that are not used in some other well-deﬁned way bythe program. For instance, JChord can run a target programusing dynamic instrumentation; the labels used to indicateeach test run are uninterpreted strings.Most options fell into a handful of types. The top threecategories together account for slightly over half of all op-tions seen. Numeric options are very common and are pri-marily used for a small number of purposes: to controltimers, resource pool sizes, and memory allocation. Non-numeric options are overwhelmingly external identiﬁers, of-ten designating ﬁles, network addresses, or Java classes.Some options include complex structured data. Exam-ples include regular expressions, date format strings, or com-mand line arguments for a subprocess. These complex op-tions are rare in the programs we have inspected: we founda total of four options controlling process arguments andthree options with nontrivial internal semantics: one regu-lar expression and twostrftime-style date format strings.The list of option types can be further summarized. Mostoptions fall into one of three broad categories. The largestcategory of options is tunablenumeric parameters, control-ling buﬀer sizes, time-out periods, and so forth. (This in-cludes both integer and ﬂoating point options.) Anotherlarge group of options select amode of operationfrom asmall set. This includes Boolean options, as well as modenames. The last group of options consists ofexternal iden-tiﬁers: strings or numbers that refer to some entity outsidethe program, such as ﬁle names or network addresses. Javaclass names are eﬀectively also external identiﬁers, since theruntime maps them to the names of ﬁles in the Java classpath. A handful of option types remain outside this tri-partite classiﬁcation. Internal identiﬁers, opaque strings ornumbers, and a few miscellaneous types such as passwordsdo not ﬁt neatly into any of the three categories mentionedabove. These are tabulated as “other” above.While our ad-hoc approach worked reasonably well, therewere a few diﬃculties. Some options can take a list of values.We treated “Type” and “list of Type” as equivalent. Whena string is used as a suﬃx to a ﬁle path, we count it as astring, not a ﬁle name. Several Hadoop options are pathnames to ﬁles in a distributed ﬁlesystem. We consider theseto be internal identiﬁers, not ﬁle names.2.2 Conﬁguration APIsWe also looked at the structure of the code each programused for reading and processing options. Of the seven pro-grams in our sample, six had a narrow and well-deﬁned APIfor conﬁguration. In each, there was exactly one class thatexposed a key-value interface to the rest of the program,through which conﬁguration options could be read. Theseclasses oﬀer a set of methods for retrieving conﬁguration val-ues of particular types:getBoolean,getInt, and so forth.Each method takes the name of an option as parameter andoptionally a default value to be used if the option is not set.The Java System Properties API, part of the Java Platformstandard, oﬀers this interface as well. The Unix system envi-ronment is also a key-value map. We therefore conclude that133this style of interface represents a popular and widespreadprogramming abstraction.Derby was the one partial exception we saw to this pat-tern. In Derby, there are three levels of conﬁguration, con-sulted in turn: global options speciﬁed in a ﬁle, per-databaseoptions, and options speciﬁed programmatically. Each op-tion can be set in some subset of those tiers. A substan-tially more complex API is needed to manage conﬁguration.There are conﬁguration retrieval methods in several diﬀer-ent classes, diﬀering in which locations are searched for con-ﬁguration. Each of these conﬁguration retrieval methods,however, followed the standard pattern, taking a string ar-gument for the option name plus an optional default value.The concrete syntax for conﬁguration varied signiﬁcantly.Hadoop and HBase use an XML-based format containingkey-value pairs. Cassandra uses a more complex XML struc-ture, with nested elements; the program reads elements fromthis ﬁle using XPath queries in an essentially key-value style.The remaining programs use a ﬂat ASCII ﬁle with a list ofname=valuepairs.Some of the programs in our study also accept command-line arguments. In many cases, these arguments duplicatethe functionality of conﬁguration ﬁle options or are accessedvia a similar key-value interface. Hadoop largely eschewscommand line options; most of Hadoop’s component pro-grams only accept options that set conﬁguration values.3. FINDING OPTIONSIn this section, we answer two research questions aboutconﬁguration options: how good is existing conﬁgurationdocumentation and how well does static analysis do com-pared to this human standard. This is motivated by our de-sire to have automated tools check documentation, or evenproduce the authoritative version.Today, developers looking to extract a list of conﬁgurationoptions from source code would have to resort to searchingthrough the text for calls to conﬁguration read methods.This approach cannot readily ﬁnd all option names. In thecode we examined, we saw many examples of applicationmethods that take an option name as parameter. As a re-sult, there can be several function calls between the stringliteral for an option’s name and the point where that name ispassed to a system or library-deﬁned conﬁguration method.All of the programs in our study deﬁne several utility meth-ods that take an option name and return a new object cor-responding to that name. For example, in Hadoop there isa method that take an option name as parameter, read thevalue of that option, and reﬂectively creates and object ofthe class named by that value. Hence, ﬁnding which stringsare used as option names requires inter-procedural analysisto track these string constants through method calls.Simple lexical approaches would yield less precise infor-mation than our analysis. All of the software packages weexamined consist of multiple executables sharing large por-tions of code. It can be helpful to know which componentprograms will use which options, or even whether an op-tion is only read in dead code. Our technique derives thisinformation readily, but lexical techniques cannot.3.1 ApproachOur approach is outlined in Figure 1. We break the overallproblem into two major pieces: First, ﬁnding the programpoints where options are read or written; second, ﬁndingConstruct points-to and call graphs.Mark known configuration methods.Mark option-name arguments to these methods.while (not converged to fixpoint)for each method m:if an argument of m used as an option nameMark method as conf. read call.Mark argument as option name.Find possible string params at call sitesOutput option names and read points.Output methods taking option names as arguments.Figure 1: Pseudocode for analysis to ﬁnd options.the possible option names at each of these points. Thesetwo stages are somewhat independent; diﬀerent algorithmscan be used in each without disrupting the overall structureof our approach. We output both the set of program pointsthat read options and a regular expression for the optionsread at each of these points. This means that our analysisis independent of the syntactic details of conﬁguration ﬁleformat. Instead, we rely on the APIs, which tend to be moreconsistent across programs.The usual API for conﬁguration consists of a set of relatedcalls, each of which has a string-typed argument correspond-ing to the option name. We assume that we have either an-notations on these API methods, or, equivalently, a list ofmethods returning or setting conﬁguration. For this study,the annotations required were compiled into the code of theanalyzer. For each program, these consisted of a few linesof the form “include all methods in classPropertieswhosename starts with get.” These annotations also specify whichparameter is the name of the option. (This is generally theﬁrst parameter of string type, in our experience.)We expand this set of conﬁguration-reading methods byﬁnding all methods taking a string argument, where that ar-gument is passed as an option name to an already-discoveredconﬁguration method. This accounts for the common pro-gramming pattern of having wrappers around other conﬁg-uration calls to encapsulate type conversion. For example,FreePastry implements a methodgetInetSocketAddressthattakes an option name as a parameter and returns a socketcorresponding to the value of the option. Our analysis dis-covers that the method uses one of its arguments as an op-tion name. We therefore infer thatgetInetSocketAddressis itself a conﬁguration-reading method and that its returnvalue corresponds to that option name. Finding these addi-tional conﬁguration read calls lets us ﬁnd the earliest con-ﬁguration read point in a call chain. This improves theprecision of subsequent analyses, including those discussedin the next sections. Eﬀectively, we are treating conﬁgu-ration reads context-sensitively, without the expense of afull-program context-sensitive analysis.Once we have the set of option read points, we ﬁnd thestring parameters potentially passed to each read call. Mostconﬁguration options are named by compile-time constantstrings. Sometimes, however, option names are constructeddynamically. A common pattern is to construct conﬁgura-tion option names out of several components, of which justone is variable. For example, in Hadoop, the implementa-tion class used to access a ﬁlesystem of typetwill be thevalue of optionfs.t.impl.134We implemented a string analysis to capture option namesconstructed as a ﬁxed sequence of variable and constantﬁelds, using the any-string regular expression.∗to handledynamic inputs. For the example mentioned above, our codeproduces the regular expressionfs.\.*\.impl. This analy-sis captured nearly all the dynamic option name creation wesaw in our programs. This approach was scalable, easy toimplement, and integrated cleanly with out points-to frame-work. More sophisticated string analyses (such as JSA [4])could be used without changing our overall approach to ﬁnd-ing conﬁguration read points.Conﬁguration options are sometimes used by one part ofa program to aﬀect another part, rather than as a way forusers to alter the program. In these cases, the lack of doc-umentation for users is not a problem. Accounting for this,we do not report an option as undocumented if its value isset programatically. This requires that we ﬁnd written op-tions, as well as read ones. Our approach for ﬁnding writesis the same as for reads.We have implemented the above analysis for Java byte-code. Our implementation relies on the JChord programanalysis toolkit [23]. Our points-to and call graph construc-tion is context insensitive, ﬂow insensitive, and ﬁeld sen-sitive. We use the SSA-representation of the program, asadvocated by Hasti and Horwitz [10]. We resolve reﬂectionusing the cast-based technique described in [21].3.2 ResultsWe evaluated the performance of our technique by run-ning our prototype on each of the seven software packageslisted in Section 2. Our research goal was to measure thecompleteness of the technique, as compared with the exist-ing human-written documentation. When there were mis-matches between our output and the documentation, wemanually checked the code, searching for substrings of theoption names in question. Table 3 represent our best ef-fort at reaching“ground truth”on program conﬁgurability interms of both undocumented and unused options. By “un-documented” options, we mean detected options not men-tioned in any user-readable documentation associated withthe package, including its website. By unused, we mean op-tions that are never referenced anywhere in reachable code.Table 4 shows how well our analysis does at matching thismanually-generated ground truth. Our analysis found justover 96% of documented options that actually exist. Ourtool failed to ﬁnd uses for 61 documented options. For athird of these, we were able to manually ﬁnd uses of theseoptions. The remaining two-thirds appear truly unused. Insome cases, we found commented-out code referencing theseoptions, suggesting that they used to exist and have sincebeen removed.Put another way: When our automated analysis and theprogram’s documentation disagree about whether an optionexists, the automated approach is more likely to be correct.This also is true on a per-program basis. Our analysis ismore accurate than human-written documentation on ﬁveof the seven projects.Our technique will have false positives in cases where thereachability or string-ﬂow analyses are imprecise. We cannotevaluate this directly because we have no ground truth forwhether an undocumented option might potentially be read.Note that reachability is not well-deﬁned for the programsin our study, since framework code can be invoked by userProjectUnused Opts.Undocumented Opts.Cassandra2 6%3 8%Derby2 3%26 38%FreePastry24 11%12 6%HBase1 2%21 33%Hadoop6 3%34 17%JChord3 5%29 51%Nachos3 19%3 19%Table 3: Manually conﬁrmed documentation errors.Percentages are of all documented options for eachproject.ApplicationFoundTrueFalseUnusedUnusedpositivesCassandra321Derby927FreePastry24240Hadoop1064HBase918JChord330Nachos330Total:614120Table 4: Accuracy in ﬁnding unused optionscode not present at analysis time.Looking at the undocumented and unused options, we no-ticed a number of patterns by which these documentationerrors arose. Many undocumented options appear to be newand specialized features, added for some speciﬁc purposeand not yet documented. Hadoop and HBase, which areproduction systems with many users, have disproportion-ately many of these specialized and undocumented features.Many unused options relate to specialized features, addedin the past for exploratory purposes and since removed. Asa result, FreePastry, which is an academic system used asa research testbed, has a large number of these unused op-tions. In some cases, code to read the option is present butcommented out. JChord is also a research testbed. Here,though, the consequence seems to be that researchers addadditional options in their portions of the system withoutdocumenting them.2Undocumented options tended to be tunable parametersor Boolean ﬂags, not external identiﬁers. We conjecture thatdevelopers, trained to avoid hard-coding constants, intro-duce options as a way to specify a constant while retainingﬂexibility. Some options are described in the program sourcecode as “deprecated;” unexpectedly, these do not appear tobe a major source of undocumented options. These optionswere often still referenced in documentation, even if only todescribe them as deprecated.In Hadoop and Derby, we noticed an additional pattern.Undocumented options were being set in test code and readin the application code. (We ﬁlter out options that are setin the main body of a program’s code. The options we dis-2JChord does not have a formal release process; we are com-paring in-development sources to in-development documen-tation.135cuss here are set only in unit tests.) These options appear tohave been added solely for the beneﬁt of test writers. For in-stance, Hadoop has several timers controlling activity thatnormally happens hourly or daily. By setting an undocu-mented option, unit tests can make the behavior in questionoccur much more quickly. Test-only options accounted forhalf the undocumented options in Hadoop and somewhatover half for Derby.We observed the following pattern by which unused butdocumented options arise. Sometimes, an option makessense in the context of a particular implementation of a pro-gram feature. Sometimes, the feature is rewritten in such away as to make the option unnecessary or meaningless. butthe documentation is not updated.3.3 Sources of ErrorWe now discuss the reasons why our analysis does not ﬁndall option uses. By far the largest problem, accounting for 10of the 20 false positives, was code that performed signiﬁcantstring manipulation on option names. HBase and Derbybreak the key-value model slightly, iterating over a subsetof options and renaming them before use. Our analysis isnot suﬃciently sensitive to determine the set of names beingiterated over. Path sensitivity would be required to modelcode of this sort accurately. Some errors are caused by moretraditional limitations of static analysis. Four options inDerby are read in code invoked indirectly via native codein the system library, where no single-language analysis caneasily follow.Some systems, including Hadoop, do a form of macro sub-stitution for option values. In Hadoop, if the value of aconﬁguration option includes the name of another option,wrapped in braces, the value of that included option is sub-stituted. Nothing in the Hadoop code indicates that thesubstituted-in option would be read. This caused one falsepositive for our analysis. This could be handled as a specialcase in practice: any option lexically included in this way ina conﬁguration ﬁle should be marked as used.Turning from unused options to undocumented options,the biggest limitation we found was actually not a problemwith our analysis at all, but with our notion of documenta-tion. There are two signiﬁcant categories of options pickedup by our analysis that are irrelevant for documentationpurposes. While programs are expected to document theirown options, there is seldom cause to document the optionsused by included libraries. They are for client programs, notusers. Second, not all system properties are conﬁgurationoptions. Java uses system properties both for conﬁgurationand also to expose information about the running machine,such as the operating system version. These properties havetheir values set by the run-time, not by users, so there is noreason for them to be documented.These limitations are inconveniences, but are unlikely topose signiﬁcant problems in practice. Programs and librariesoften have a shared preﬁx for their options (such ashbase.*),making it reasonably easy for humans to determine whichoptions belong to which code base. The second problem,that not all system properties are conﬁguration options,could be ﬁxed by white-listing the standard JVM options.4. CATEGORIZING OPTIONSIn Section 2, we noted that the large majority of the con-ﬁguration options we encountered belong to one of a fairlysmall number of types. In the programs we inspected, thesetypes often correspond to speciﬁc programming patterns.By ﬁnding the pattern, we can infer the type of the option.We are not attempting to replace human-written docu-mentation. We have three goals: helping developers writedocumentation, helping developers spot mistakes, and pro-ducing machine-usable annotations on options to help usertroubleshooting. In all these cases, false negatives are fairlyinnocuous: an incomplete but accurate analysis is helpful,but false positives can be confusing. Consequently, our anal-ysis is tuned to return “don’t know” rather than to makewrong guesses.Option names, while often descriptive, are sometimes mis-leading. Hadoop includes an optionmapred.skip.map.auto.incr.proc.count. Despite the name, this option is actu-ally a Boolean. Printing inferred types alongside the namesof undocumented options can help remind programmers whatthe option does.Inferring types helps developers check that options arebeing used in the ways they expect. We have seen optionsthat are read, stored, and logged, but put to no substan-tive use. The analysis we present here can help developersspot these cases. If the analysis ﬁnds an unexpected typefor an option, that is suggestive of an underlying bug or in-correct documentation. One striking example concerns theij.exceptionTraceoption in Derby. This option is docu-mented as a Boolean, but our analysis was unable to deter-mine a type. On inspecting the code, we discovered thatthe value was never used at all: the true states of the optionwere “set” and “unset”. Setting any value, even “false” wouldenable the option; surely an unexpected behavior. We alsospotted several options in FreePastry that were documentedas being time intervals, but that were never used this way.They were read into the program and logged, but the codeto use them was commented out.This analysis also enables stronger automated checking ofconﬁguration ﬁles, eﬀectively a“conﬁguration spellcheck”forvalues as well as option names. This is only meaningful forsome option types. For example, almost any string is poten-tially useable as a ﬁle name or password. Fortunately, ouranalysis works well on most types for which invalid valuescan be readily ﬂagged.The approach we take is to look for patterns in how pro-grams use conﬁguration values. This helps validate ourtaxonomy of conﬁguration options, since a type that cor-responds to a well-deﬁned programming pattern is likely tobe a useful abstraction. Just as FindBugs [12] and simi-lar tools exploit a library of recognizers for various typesof bugs, we envision a separate recognizer for each type ofconﬁguration option. Because the number of common op-tion types is limited, the implementation eﬀort required isreasonable.We have implemented recognizers for most the optiontypes listed above in Table 2: Booleans, class names, ﬁles,fractions, network addresses, network interface names, modenames, and port numbers. (We refer to these as“recognized”types). Our analysis splits numeric options into“time”,“portnumber”, and “other,” rather than attempting to distinguish“counts” from “sizes. In our sample, there were 528 optionsfound by the option-ﬁnding analysis and belonging to rec-ognized types. This is the set against which we evaluate ouranalysis.1364.1 ApproachWe exploit three basic techniques in recognizing optiontypes: looking at the return types of conﬁguration reads,looking at which library methods conﬁguration data is passedto, and looking at which values are compared with one an-other. We assume the presence of a call graph, a points-toanalysis, and the results of the above analysis specifyingwhich conﬁguration options are read at each point.The simplest of our three approaches is to inspect thereturn type of the conﬁguration call. Many conﬁguration areread using typed methods, such asgetBoolean,getFloat,and so forth. If an option is exclusively read viagetBoolean,then we conclude that option can only hold Boolean values.Some programs read options as untyped strings, and thenconvert them to the correct type. Our second techniquehandles this case. Instead of looking at how values enterthe program, we look at how they leave the program: whichlibrary calls they are passed to. If a string is passed to thelibraryparseBooleanmethod, we can infer that its valueis expected to be a Boolean. This technique works well foridentiﬁers. There are a small number of common systemor library calls for opening ﬁles or resolving host names.We use approximately 30 rules to cover the option types inour classiﬁcation. These rules are stored in a simple lookuptable, mapping from called method and argument numberto inferred option type. This technique requires a dataﬂowanalysis to connect option reads with subsequent uses.Mode options, with a handful of valid values, are an im-portant special case. Here, we are often able to not onlydetermine that an option represents a mode choice, but arealso able to determine the set of valid values. We have seenonly two patterns by which programs use mode variables.Often, programmers parse these options by comparing thereturned value against a sequence of string constants. Weare able to retrieve this set of valid option names by in-specting the strings a given conﬁguration value is comparedwith. Alternatively, programmers can deﬁne an Enumera-tion class, and then use a standard library function to createobjects of this class. Here, we can retrieve the set of validvalues from the associated Enumeration class.Similarly, we can often infer the parent type that a conﬁg-urable class must have. When a conﬁgurable class name isused to create an object reﬂectively, and that object is castto some type T, we infer that the permissible values for theoptions are subtypes of T.To help distinguish time-valued options from other op-tions, we employ our third and last technique. There are ahandful of library calls for reading the value of the systemclock. If an option’s value and a known time value are usedtogether in arithmetic, we assume that the option is likewisea time value. This works well in practice: we are able to ﬁnd90% of time options, with a 10% false positive rate. Thisapproach is intrinsically imperfect: We have seen conﬁgura-tion options that are multipliers for time values. In thesecases, the multiplier should not be marked as “time” – it isa dimensionless number, not a time period.This analysis runs quickly enough to be used in the soft-ware release process. Analyzing Derby, the largest programin our set, took less than 30 minutes using a recent-modellaptop with 4 GB of RAM and a dual-core 2.2 GHz proces-sor. Most of the running time was used in the underlyingpoints-to analysis, not in the type inferenceper se.OptionsFractionReal documented opts.of recognized types528100%Success43382%All failures9518%Out of scope336%Time/not-time miss275%Wrong guess122%No guess, other reason234%Table 5: Overall success rate for type inference andpartial breakdown of errors. Percentages are of doc-umented options of recognized types found automat-ically.4.2 ImplementationAs with the previous analysis, we used JChord to im-plement our option type determination. Unlike the previ-ous analysis, ﬁnding option types requires a whole-programdataﬂow, tracking the values returned from conﬁgurationread points.To cope with the complex, reﬂection-heavy programs inour study, we made several modiﬁcations to JChord’s de-fault algorithms. Most of the programs in our sample arenetworked services, making heavy use of remote procedurecalls (RPCs). This means that much of the code in theseprograms is never invoked directly; rather, these methodsare invoked via reﬂection. We handle this by specifying alist of extra entry points for each program. These lists hadan average of three entries per program.In Java, method dispatch depends on an object’s dynamictype. Correctly modeling method calls on externally-suppliedobjects therefore required us to modify the underlying points-to analysis. We fall back on type-based alias analysis forthese objects [5]. We add an abstract object for every type.When an entry point is invoked externally, we assume thatreference arguments point to the appropriately-typed ab-stract objects. Reference-typed ﬁelds in abstract objectspoint, in turn, to other abstract objects of the appropriatetypes. In the programs we examined, RPCs are invokedon singleton “server” objects. As a result, this abstractionincurred no loss of precision.In our experience, conﬁguration options are seldom sharedbetween the program in question and component libraries.To improve performance, we exclude library code from anal-ysis. In most cases, once a value is passed into the library,it ceases to be tracked. In two cases, however, we explicitlymodel the behavior of library classes. Our points-to anal-ysis is collection aware: if an object allocated at siteh1isstored into a collection allocated at siteh2, then subsequentreads from that collection can return the object with siteh1.We also explicitly model the string-to-primitive conversionfunctions in the JVM, thus handling code that, for example,reads an option as a string, converts the string to an integer,and uses that integer as a time delay.4.3 ResultsWe compared the results of our automated analysis to themanual labels we described in Section 2. Our results aresummarized in Table 5. We look only at options found bythe option-ﬁnding analysis discussed in Section 3; we want137 0 20 40 60 80 100
BooleanFractionClass NameSpecialAddressFilePortnoNet. InterfaceSizeCountTimePercent of true totalIn-scopeFoundFalse Pos
Figure 2: Accuracy in detecting option types. Onlyincludes recognized types. In-scope means the op-tion is used within the program being analyzed, notjust in a library or external process.to measure the eﬀectiveness of type inference and optionﬁnding separately.Overall, we succeed 80% of the time. There is substantialvariation in success rate by type. Figure 2 displays thisvariance. False negatives are the gap between 100% andthe “Found” bar. False positives (where the analysis ﬁnds awrong type) are labelled explicitly.The types are ordered based on the primary means weused to recognize them. The ﬁrst two, Boolean and frac-tional, are recognized primarily based on the return typeof the conﬁguration read call; 24% of options of these typeswere recognized using called methods, our second technique.The next several columns are recognized entirely by this sec-ond technique. Time options, the last column, were foundusing our second and third techniques. Just over 80% oftime options were detected by their use in arithmetic withknown clock values; the remaining 20% were found based ontheir use as arguments to API calls such asSleep.Our analysis recognizes virtually all options whose valuesare Boolean, fractional or Java class names. It also doesreasonably well for network addresses. Performance on ﬁlesand port numbers is comparatively weak, for reasons dis-cussed below. In distinguishing times from other numericparameters, we succeed approximately 90% of the time; er-rors are roughly symmetric between false positives and falsenegatives. This imprecision accounted for 28% of misses.We found few cases where documentation incorrectly de-scribed what an option did. We posit that developers add orremove options more frequently than they change the typeof an existing option. Changing the meaning of an optionwould likely break existing conﬁgurations, a major enoughchange to trigger documentation changes. Mistakes in docu-menting an option’s type do sometimes occur, however. Thepeculiar option in Derby mentioned above where “false” istreated as true is an example. 0 20 40 60 80 100 120 140 160 180 200
CassandraHBaseNachosJChordDerbyHadoopFreePastryNumber of optionsRightNo GuessWrong Guess
Figure 3: Success by application. Includes all op-tions, not just those of recognized types.Despite its limitations, we believe this technique has prac-tical uses. Ignoring the imprecision in detecting time op-tions, incorrect type inferences happened on fewer than 3%of options. Our technique is accurate for several commontypes that have syntactic constraints. Our analysis is pre-cise enough to accurately warn users when they put a stringother than “true” or “false” for a Boolean option, or a simi-larly invalid value for numerical or class name options.4.4 Sources of ErrorThis analysis has several sources of error. Sometimes, op-tions are read and then passed to an external process beforebeing used. This was the biggest single source of imprecisionfor our analysis. These externally-used or “out of scope” op-tions accounted for 30% of all failures to infer a type, andalmost half of misses on non-numeric options. This problemshowed up primarily for identiﬁers, particularly ﬁle and hostnames. Since these refer to system abstractions, they can bereadily passed to a subprocess or a library. The meaning ofa particular class name or Boolean option is more often con-ﬁned to a single program and therefore the uses for optionsof these types are generally in-scope.String operations were another major source of impreci-sion. We do not track the contents of every string variable. Ifa conﬁguration value is stored inside a string and then laterparsed out, we do not report a type for the option. This is asigniﬁcant issue with ﬁle names, port numbers, and networkaddresses: there are standard programming idioms (such asconstructing a host:port pair) that would defeat our analy-sis. This could potentially be ﬁxed by a more sophisticatedstring analysis.Some of the imprecision in ﬁnding time options is due tothe presence of numeric utility functions. Since our analysisis context insensitive, we see time options “leak” throughthese functions. Context-sensitive analysis would help solvethis problem. Otherwise, notably, points-to and dataﬂowimprecision did not appear to be a major problem.1385. DISCUSSIONIn the previous two sections, we described how to stati-cally analyze programs to ﬁnd the set of option names in useand the types of these options. We now discuss how generalthe problem and approach are.More careful programming with attention to conﬁgura-tion could reduce the mismatch between programs and doc-umentation, and could catch more user conﬁguration errors.Current versions of Derby and in-development versions ofHadoop attempt to conﬁne option names to a small num-ber of interfaces and classes. Our analysis could help enforcethis property during development, since it is eﬃcient enoughto run every night alongside the regression test suite.We focused on key-value style conﬁguration, but there areat least two other common styles for conﬁguration manage-ment where this same observation applies. Many programshave graphical conﬁguration management interfaces. Ourtechniques are potentially applicable to these programs; of-ten, the graphical interface masks an underlying key-valuemodel and not all options are exposed via the graphical in-terface. Another common model for conﬁguration is struc-tured XML, where the program walks the DOM tree to re-trieve values. An advantage of this style for programmers isthat schema validation can catch a wide variety of user er-rors. The downside is that programming with this approachcan be more cumbersome. Retrieving an option by name oran XPath query can be done a single line; walking the DOMtree cannot.The techniques presented in this paper could be general-ized to this alternate style. The limitation in generalizingour analysis is matching program points to the DOM nodesthey retrieve. Other work has shown that static analysis canmodel the output (including output XML) from a programfragment [6, 14]; similar techniques may be applicable here.We focused primarily on large highly conﬁgurable sys-tems, with dozens or hundreds of options. Many programs,however, are small and have just a few named conﬁgurationoptions, commonly environment variables. The APIs to re-trieve environment variables fall into the key-value patternwe have shown is easy to analyze. Hence, our techniquewould be useful to extract and model environment depen-dencies in smaller programs.Our prototype implementation of our analysis was con-ﬁned to Java. However, the key-value conﬁguration modelwe focused on is also used in other contexts. While Java isa comparatively easy language to analyze, our results usedfairly simple points-to algorithms, suggesting that optimalpoints-to accuracy is not required for this domain.6. RELATED WORKWe describe three areas of related work. We automatedeﬀorts to document program behavior, conﬁguration-awareprogram analysis, and conﬁguration debugging techniques.The general topic of automatic documentation of programbehavior has been addressed previously. Rubio-Gonz´ alezand Liblit show that static analysis can catch incorrectlydocumented error code return values in the Linux kernel [26].Kremeneket al.show that static analysis can ﬁnd resourceallocation and deallocation sites in real-world systems pro-grams, without the beneﬁt of annotations [16]. Buse andWeimer show that the exceptions thrown by Java functionscan be inferred more accurately than they are currently doc-umented [3]. Static analysis approaches can also extracthigher-level properties of program behavior, such as ﬁle ornetwork packet formats [20]. Wanget al.use dynamic tainttracking to ﬁnd security-related options. [32].Our approach to conﬁguration type inference relies on thefact that many options are used in similar ways and thatprogrammer- and user-oriented descriptions of options are aclose match for program structures. Prior work has madesimilar observations about object oriented design patterns.Reverse-engineering design patterns from program code hasbeen an active area of research since at least 1996. Thiswork sought to report pattern use as a form of design doc-umentation [15, 7].Like this prior work, we are trying to use program anal-ysis to remedy deﬁciencies in documentation. Unlike thisprior work, we are deriving a comparatively high-level andinformal property. Return codes and exceptions are aspectsof program behavior that can be directly expressed in thesemantics of the associated programming language, as canmany object-oriented design patterns. Conﬁguration is alibrary-deﬁned abstraction; conﬁguration option types arean ad-hoc human concept.Another branch of related work concerns conﬁguration-aware program analysis. Reisneret al.have used symbolicexecution to model conﬁgurable programs [24]. They showthat conﬁguration options often localized eﬀects: most op-tions only aﬀect a small portion of program state. This re-sult is in accord with our ﬁndings. We observed that optionuse falls into patterns; most of the conﬁguration patterns wesaw are likely to have localized eﬀects.Some prior work would beneﬁt from the results of ouranalysis. The ever-increasing complexity of software hasmade conﬁguration debugging an important topic. The Au-toBash and Triage systems attempt to diagnose failures byrepeatedly applying potential ﬁxes and testing them usingspeculative execution [30, 31]. Knowing which options aprogram can read and how those values are used may helpdetermine which potential ﬁxes are most promising, thusreducing the time taken to diagnose an error. More pre-cise information about program option use (including optiontypes) may enable automatic generation of potential ﬁxes.7. CONCLUSIONAll of the programs we examined had documentation foroptions that were not actually present. This appeared to bethe result of error, not design. The programs we looked atalso contained undocumented options. Some undocumentedoptions appear to be intended only for unit test writers.Others might be useful to users, particularly users with atyp-ical needs. As a result, the lack of documentation is a prob-lem worth correcting.Several conclusions emerge from our work.Open-source programs are rife with stale docu-mentation for conﬁguration.Many real options are un-documented, and not all documented options exist.Conﬁguration option names are available statically.Our static analysis was able to ﬁnd the overwhelming ma-jority (more than 95%) of options in the programs we lookedat. This is more complete than existing manually-produceddocumentation.String analysis and external dependencies pose thebiggest challenges to static analysis of conﬁgurabil-ity.Points-to and call graph imprecision was not the biggest139challenge for our analysis. The chief limitations we foundwere two-fold. Values are sometimes stored inside strings,frustrating simple data-ﬂow analysis. Some options are passedto external programs before being used. This frustratessingle-program analysis.Option behavior can often be described and doc-umented automatically.For some types of options, suchas class names and Booleans, analysis can ﬁnd a high pro-portion of options, without any observed no false positives.For options drawn from small sets of strings, analysis canoften also give the set of legal values. Beyond documenta-tion, this oﬀers the possibility of catching a range of userconﬁguration mistakes, via a “spell check for conﬁguration”.AcknowledgementsWe thank Koushik Sen and David Wagner for oﬀering ad-vice and encouragement and thank Mayur Naik for extensivesupport in using JChord. We thank the anonymous review-ers for their input. This research was supported by Califor-nia MICRO, California Discovery and the following BerkeleyRAD Lab sponsors: Sun Microsystems, Google, Microsoft,Amazon, Cisco, Cloudera, eBay, Facebook, Fujitsu, HP, In-tel, NetApp, SAP, VMware, and Yahoo!.8. REFERENCES[1] Apache Derby.http://db.apache.org/derby/.[2] HBase.http://hbase.apache.org/.[3] R. P. Buse and W. R. Weimer. Automaticdocumentation inference for exceptions. InISSTA,New York, NY, USA, 2008.[4] A. Christensen, A. Møller, and M. Schwartzbach.Precise Analysis of String Expressions. InSymposiumon Static Analysis, 2003.[5] A. Diwan, K. S. McKinley, and J. E. B. Moss.Type-based alias analysis.SIGPLAN Notices, 33(5),1998.[6] K.-G. Doh, H. Kim, and D. A. Schmidt. Abstractparsing: Static analysis of dynamically generatedstring output using lr-parsing technology. InSymposium on Static Analysis, 2009.[7] J. Dong, Y. Zhao, and T. Peng. Architecture anddesign pattern discovery techniques-a review. InInternational Conference on Software EngineeringResearch and Practice (SERP), 2007.[8] S. Duan, V. Thummala, and S. Babu. Tuning databaseconﬁguration parameters with iTuned.VLDB, 2009.[9] Hadoop.http://hadoop.apache.org/.[10] R. Hasti and S. Horwitz. Using static singleassignment form to improve ﬂow-insensitive pointeranalysis. InPLDI, 1998.[11] D. Hettena and R. Cox. A guide to nachos 5.0j.http://inst.eecs.berkeley.edu/~cs162/sp07/Nachos/walk/walk.html.[12] D. Hovemeyer and W. Pugh. Finding bugs is easy.ACM SIGPLAN Notices, 39(12):106, 2004.[13] L. Keller, P. Upadhyaya, and G. Candea. ConfErr: Atool for assessing resilience to human conﬁgurationerrors. InDSN, 2008.[14] C. Kirkegaard and A. Møller. Static analysis for JavaServlets and JSP. InSymposium on Static Analysis,2006.[15] C. Kramer and L. Prechelt. Design recovery byautomated search for structural design patterns inobject-oriented software. InWorking Conference onReverse Engineering, 1996.[16] T. Kremenek, P. Twohey, G. Back, A. Ng, andD. Engler. From uncertainty to belief: inferring thespeciﬁcation within. InOSDI, 2006.[17] A. Lakshman, P. Malik, and K. Ranganathan.Cassandra: A Structured Storage System on a P2PNetwork. InSIGMOD, 2008.[18] T. Lethbridge, J. Singer, and A. Forward. Howsoftware engineers use documentation: The state ofthe practice.IEEE software, pages 35–39, 2003.[19] M. Levesque. Fundamental issues with open sourcesoftware development.First Monday:, Special Issue#2: Open Source, October 2005.[20] J. Lim, T. Reps, and B. Liblit. Extracting outputformats from executables. InWorking Conference onReverse Engineering, 2006.[21] B. Livshits, J. Whaley, and M. Lam. Reﬂectionanalysis for Java. InThird Asian Symposium onProgramming Languages and Systems, 2005.[22] M. Michlmayr, F. Hunt, and D. Probert. Qualitypractices and problems in free software projects. InProceedings of the First International Conference onOpen Source Systems, 2005.[23] M. Naik. JChord.http://jchord.googlecode.com.[24] E. Reisner, C. Song, K. Ma, J. Foster, and A. Porter.Using symbolic evaluation to understand behavior inconﬁgurable software systems. InICSE, 2010.[25] A. Rowstron and P. Druschel. Pastry: Scalable,decentralized object location, and routing forlarge-scale peer-to-peer systems. InMiddleware, 2001.[26] C. Rubio-Gonz´ alez and B. Liblit. Expect theunexpected: error code mismatches betweendocumentation and the real world. InPASTE, 2010.[27] J. Sawin and A. Rountev. Improving static resolutionof dynamic class loading in java using dynamicallygathered environment information. InAutomatedSoftware Engineering, 2009.[28] D. Schreck, V. Dallmeier, and T. Zimmermann. Howdocumentation evolves over time. InIWPSE ’07:Ninth international workshop on Principles of softwareevolution, 2007.[29] J. Singer. Practices of software maintenance. InProceedings of the International Conference onSoftware Maintenance, 1999.[30] Y.-Y. Su, M. Attariyan, and J. Flinn. Autobash:improving conﬁguration management with operatingsystem causality analysis. InSOSP, 2007.[31] J. Tucek, S. Lu, C. Huang, S. Xanthos, and Y. Zhou.Triage: diagnosing production run failures at theuser’s site. InSOSP, 2007.[32] R. Wang, X. Wang, K. Zhang, and Z. Li. Towardsautomatic reverse engineering of software securityconﬁgurations. InCCS, 2008.140