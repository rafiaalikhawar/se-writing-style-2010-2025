An Exploratory Study of Fault-Proneness in  
Evolving Aspect-Oriented Programs 
Fabiano Ferrari1, Rachel Burrows2,3, Otávio Lemos4, Alessandro Garcia2, Eduardo Figueiredo3, 
Nelio Cacho5, Frederico Lopes6, Nathalia Temudo7, Liana Silva7, 
Sergio Soares8, Awais Rashid3, Paulo Masiero1, Thais Batista6, José Maldonado1 
1 Computer Systems Department, University of São Paul o – USP, São Carlos, Brazil 
2 Informatics Department, Pontifical Catholic Univers ity of Rio de Janeiro – PUC-Rio, Rio de Janeiro, Br azil 
3 Computing Department, Lancaster University, Lancast er, United Kingdom 
4 Department of Science and Technology, Federal Unive rsity of São Paulo – UNIFESP, S.J. Campos, Brazil 
5 School of Science and Technology, Federal Universit y of Rio Grande do Norte – UFRN, Natal, Brazil 
6 Computer Science Department, Federal University of Rio Grande do Norte – UFRN, Natal, Brazil 
7 Department of Computing and Systems, University of Pernambuco – UPE, Recife, Brazil 
8 Informatics Centre, Federal University of Pernambuc o – UFPE, Recife, Brazil 
 
{ferrari,masiero,jcmaldon}@icmc.usp.br, {rachel.bur rows,e.figueiredo,marash}@comp.lancs.ac.uk, otavio. lemos@unifesp.br 
afgarcia@inf.puc-rio.br, neliocacho@ect.ufrn.br, {n mt,lsos}@dsc.upe.br, scbs@cin.ufpe.br, {fred.lopes, thais}@ufrnet.br  
 
ABSTRACT  
This paper presents the results of an exploratory s tudy on the 
fault-proneness of aspect-oriented programs. We ana lysed the 
faults collected from three evolving aspect-oriente d systems, all 
from different application domains. The analysis de velops from 
two different angles. Firstly, we measured the impa ct of the 
obliviousness property on the fault-proneness of th e evaluated 
systems. The results show that 40% of reported faul ts were due to 
the lack of awareness among base code and aspects. The second 
analysis regarded the fault-proneness of the main a spect-oriented 
programming (AOP) mechanisms, namely pointcuts, adv ices and 
intertype declarations. The results indicate that t hese mechanisms 
present similar fault-proneness when we consider bo th the overall 
system and concern-specific implementations. Our fi ndings are 
reinforced by means of statistical tests. In genera l, this result 
contradicts the common intuition stating that the u se of pointcut 
languages is the main source of faults in AOP.  
Categories and Subject Descriptors  
D.2.5 [ Software Engineering ]: Testing and Debugging – 
Diagnostics, Code Inspections; D.3.3 [ Programming 
Languages ]: Language Constructs and Features. 
General Terms  
Measurement, Experimentation, Languages, Verificati on. 
Keywords  
Aspect-oriented programming, fault-proneness, softw are testing. 
1. INTRODUCTION 
With software development becoming increasingly inc remental, 
programmers should be aware of contemporary impleme ntation 
mechanisms that are fault-prone in the presence of changes. In particular, the recent adoption of aspect-oriented programming 
(AOP) languages and frameworks, such as AspectJ [32 ] and 
Spring [23], requires a better understanding of the  fault causes in 
AOP. AOP [25] is a programming technique that aims to improve 
the modularisation and robust implementation of con cerns that cut 
across multiple software modules. Classical example s of 
crosscutting concerns usually implemented as aspect s are logging, 
exception handling, concurrency, and certain design  patterns.  
The modularisation of crosscutting concerns in AOP is achieved 
through a complementary set of programming mechanis ms, such 
as pointcut, advice, and intertype declaration (ITD ) [32]. In 
addition, a basic property associated with AOP is  obliviousness . 
This property implies that the developers of core f unctionality 
need not be aware of, anticipate or design code to be advised by 
aspects [15]. Obliviousness is also influenced by q uantification, 
i.e. the ability to declaratively select sets of po ints via pointcuts in 
the execution of a program. The more expressive a p ointcut 
language is, the more support for obliviousness it provides [31].  
New AOP models, frameworks and language extensions are 
constantly emerging, in some cases leveraging diffe rent degrees 
of obliviousness [17, 20, 26, 35]. While some resea rchers have 
been optimistic about the benefits of AOP [26], oth ers have 
shown scepticism [1, 2, 28]. For example, previous research has 
indicated that the use of certain AOP mechanisms ca n violate 
module encapsulation [1] and even introduce new typ es of faults 
[2]. In particular, some researchers claim these fa ults are likely to 
be amplified in the presence of evolutionary change s [24]. 
However, the empirical knowledge about the actual i mpact of 
AOP on fault-proneness remains very limited even fo r core 
programming mechanisms, such as pointcuts and inter type 
declarations. 
Concerned with these issues, we present a first exp loratory 
analysis on the fault-proneness of AOP properties a nd 
mechanisms. Our analysis develops in terms of the t hree 
following questions: (1) How does obliviousness inf luence the 
presence of faults in aspect-oriented (AO) programs ? (2) What is 
the impact of specific AOP mechanisms on fault-pron eness? and 
(3) Whether and how do certain characteristics of c oncern 
implementations correlate with the introduction of faults? To the 
best of our knowledge, this is the first initiative  that systematically  
Permission to make digital or hard copies of all or  part of this work for 
personal or classroom use is granted without fee pr ovided that copies are 
not made or distributed for profit or commercial ad vantage and that 
copies bear this notice and the full citation on th e first page. To copy 
otherwise, or republish, to post on servers or to r edistribute to lists, 
requires prior specific permission and/or a fee. 
ICSE '10, May 2-8, 2010, Cape Town, South Africa 
Copyright © 2010 ACM 978-1-60558-719-6/10/05 ... $1 0.00 
 tackles these questions based on the exploratory an alysis of real-
world AO systems. Previous research has mainly focu sed on 
defining fault taxonomies and testing approaches ba sed on AOP 
main concepts and current technologies [2, 3, 4, 10 , 12, 34, 36]. 
However, we can only find limited empirical evidenc e on how 
such faults occur in practice.  
To achieve our goals, we selected three AO systems from 
different application domains. We analysed fault-pro ne AOP 
mechanisms by means of various testing and static a nalysis. 
Throughout the study, faults were reported by two m eans: (1) by 
developers during system development and evolution;  then 
afterwards (2) by independent testers who reported post-releases 
faults. The main findings of our study are: 
• Obliviousness has been a controversial software pro perty since 
the early research in AOP [28, 31]. Our analysis co nfirms that 
the lack of awareness between base and aspectual mo dules 
tends to lead to incorrect implementations. Despite  the modern 
support provided by AOP-specific IDEs, uncertainty about 
module interactions still remains in the presence o f aspects 
within the system. 
• Interestingly, our findings contradict the common i ntuition 
stating that the use of pointcut languages is the m ain source of 
faults in AOP [10, 12, 29]. The main AOP mechanisms  
currently available in AspectJ-like languages – nam ely, 
pointcuts, advices and intertype declarations (ITDs ) – present 
similar fault-proneness when the overall system is considered. 
• The numbers of internal AOP mechanisms showed to be  good 
fault indicators when considering the sets of modul es within 
each concern1 implementation separately. In this case the 
number of faults associated with a concern was dire ctly 
proportional to the number of AOP mechanisms used t o 
implement that concern. 
In addition, the gathered results in our study supp ort these 
findings with statistical significance. The remaind er of this paper 
is organised as follows: Section 2 summarises the re lated research. 
Section 3 describes the study configuration. It inc ludes our 
research hypotheses and a description of the target  systems and 
evaluation procedures. Following, Section 4 brings the collected 
data. This data is analysed and discussed in Sectio n 5. Section 6 
discusses the limitations of this work. Finally, Se ction 7 presents 
our conclusion and future research. 
2. RELATED WORK 
The difficulty of performing fault-proneness evalua tion in AOP is 
mainly twofold: (i) there are not yet several relea ses and 
documented faults for AO software projects availabl e for 
analyses, and (ii) AOP has introduced new propertie s, such as 
obliviousness and quantification, and a wide range of mechanisms 
often used to implement different categories of cro sscutting 
concerns. Previous research was limited to evaluate  the benefits 
and drawbacks of aspects from different angles, suc h as design 
stability [13, 16] and system robustness [5, 9, 14] . However, the 
fault-proneness of AO programs is not yet a well-un derstood 
phenomenon.  
To date, there is limited empirical knowledge of th e impact of 
AOP on software correctness. In spite of that, we p resent pieces of 
                                                                 
1 From hereafter, we use the term “concerns” to refer  to crosscutting 
concerns in general, as defined by Kiczales et al. [25]. work that we believe are mostly related to our own.  They are 
basically distributed in two categories discussed i n the following: 
Fault taxonomies and fault-proneness of AO programs : A 
number of fault taxonomies and bug patterns for AO programs 
can be found in the recent literature [2, 4, 9, 12,  36]. Alexander et 
al. [2] proposed the first study on AOP-specific fa ults. Their main 
contribution is a characterisation of possible sour ces of faults that 
are specific to AO programs. Based on these sources , Alexander 
et al. also defined a high-level fault taxonomy for  AO software, 
mainly focusing on features of AspectJ-like languag es. Further 
fault taxonomies were built on top of it [4, 36]. T hey either 
include new fault types or refine the already exist ing ones. 
However, none of them have been empirically evaluat ed to date. 
Ferrari et al. [12] summarised these and other taxo nomies in a 
broader fault categorisation for AO software. The s tudy presented 
in this paper uses such categorisation for classify ing the AOP-
related faults found in the target systems. 
So far, we have identified a single attempt to eval uate the fault-
proneness of AOP programs. Coelho et al. [9] presen t an 
exploratory study of the robustness of AspectJ-base d systems. The 
study analyses the flow of exceptions in five mediu m-sized OO 
systems from different domains and their AO counter parts, whose 
exception-handling code have been aspectised. The r esults show 
that in all AO systems there was an increase in the  number of 
uncaught exceptions (i.e. exceptions that cross the  system 
boundaries without being handled) and also in the n umber of 
unexpected handler actions. Differently from our wo rk, Coelho et 
al. only focus their analysis on exception handling  mechanisms, 
while we focus on AOP mechanisms in general. 
Fault-proneness of crosscutting concerns : Eaddy et al. [11] 
performed an empirical study which provides evidenc e suggesting 
that crosscutting concerns cause defects. The autho rs examined 
the concerns of three medium-sized open-source Java  projects and 
found that the more scattered the implementation of  a concern is, 
the more likely it is to have defects. Their findin gs recommend the 
use of AOP techniques to modularise crosscutting co ncerns in 
order to reduce the number of faults potentially ca used by them. 
However, Eaddy et al. have not investigated the fau lt-proneness of 
AOP mechanisms as we do in this study. In our study , we also 
analyse crosscutting concerns, although from a diff erent angle. 
We aim to evaluate the impact of the specific chara cteristics of 
AO concern implementations on the system fault-pron eness. We 
also highlight that we do not contrast AO implement ations with 
OO counterparts in order to find out which approach  results in 
more or less faults related to crosscutting concern s. 
3. STUDY SETTING 
This section describes our study configuration. Sec tion 3.1 
presents our goals and hypotheses. Section 3.2 prov ides an 
overview of the target systems. Section 3.3 explain s the 
evaluation procedures we applied to each selected s ystem and the 
associated tooling support. 
3.1 Goal Statement and Research Hypotheses 
Our objective is to evaluate the fault-proneness of  AOP properties 
and mechanisms when they are applied to evolving pr ograms. We 
are particularly interested in observing the underl ying reasons of 
the introduction of faults. First, we analyse wheth er a key property 
of AOP, obliviousness, facilitates the emergence of  faults under 
software evolution conditions. Moreover, we aim at analysing 
how specific characteristics of concerns being aspectised  impact 
on the fault-proneness of AO programs. For example,  we investigate how the internal implementation details  of a concern, 
such as lines of code and use of specific AOP mecha nisms, are 
correlated with the presence of faults. Based on th ese goals, we 
defined two research hypotheses. For each of them, the null and 
the alternative hypotheses are as follows: 
Hypothesis 1 (H1) 
• H1-0: Obliviousness does not exert impact on the fa ult-
proneness of evolving AO programs; 
• H1-1: Obliviousness exerts impact on the fault-pron eness of 
evolving AO programs; 
Hypothesis 2 (H2) 
• H2-0: There is no difference among the fault-pronen ess of the 
main AOP mechanisms; 
• H2-1: There are differences among the fault-pronene ss of the 
main AOP mechanisms; 
To achieve our goals, we needed to apply a number o f evaluation 
procedures. Our analysis embraced 12 releases of th ree AO 
systems from different application domains. Such sy stems include 
a wide range of heterogeneous concerns implemented as aspects. 
The systems and evaluation procedures are following  described. 
3.2 The Target Systems 
The three medium-sized applications used in this st udy are from 
significantly different application domains. The fi rst one, called 
iBATIS [22], is a Java-based open source framework for object-
relational data mapping. It was originally develope d in 2002 and 
over 60 releases are available at SourceForge.net2 and 
Apache.org3 repositories. The second application is 
HealthWatcher (HW) [16, 27], a typical Java web-bas ed 
information system. HW was first released in 2001 a nd allows 
citizens to register complaints about health issues . The third 
evaluated system is a software product line for mob ile devices, 
called MobileMedia (MM) [13]. MM was originally dev eloped in 
2005 to allow users to manipulate image files in di fferent mobile 
devices. It has then evolved to support the manipul ation of 
additional media files, such as videos and MP3 file s.  
Every AO release of a given system has an OO counte rpart. In 
particular, iBATIS had its AO releases derived from  OO builds 
available at SourceForge.net, which were used as ba selines for 
implementation alignment. HW and MM, on the other h and, have 
evolved based on a sequence of planned changes, and  both OO 
and AO versions of given release were developed con currently 
[13, 16]. All releases have experienced exhaustive assessment 
procedures – code revision and testing (Section 3.3 ) – by 
independent developers in order to achieve function alities well 
aligned with the original Java system. 
From hereafter, we refer to the AO versions4 of the target systems 
by their simple names or abbreviations, i.e. iBATIS , HW and 
MM. Four releases of iBATIS were considered in our evaluation, 
namely iBATIS5 01, 01.3, 01.5 and 02. We also analysed four 
HW releases – HW 01, 04, 07 and 10 – and four MM re leases – 
MM 01, 02, 03 and 06. These releases were chosen be cause they 
encompass a wide range of different fine-grained an d coarse-
                                                                 
2 http://  sourceforge.net/projects/ibatisdb/files/ (03/02/201 0) 
3 http://archive.apache.org/dist/ibatis/binaries/ibat is.java/ (03/02/2010) 
4 References to OO counterparts will be made explicit  throughout the text. 
5 Such releases correspond to the original builds #15 0, #174, #203 and 
#243 found in SourceForge.net, respectively.  grained changes, such as refactorings and functiona lity increments 
or removals. Table 1 shows some general characteris tics of the 
three target systems. For more information about ea ch of them, 
the reader may refer to the respective placeholder websites or to 
previous reports of these systems [13, 16, 22]. 
Table 1. Key characteristics of the target applicat ions. 
iBATIS Health Watcher MobileMedia
Application Type data mapper
frameworkhealth vigillance
applicationproduct line
for mobile data
Code Availability Java/AspectJ Java/AspectJ Java/Aspec tJ
# of Releases 60 / 4 10 / 10 10 / 10
Selected Releases 4 4 4
Avg. KLOC 11 6 3
Avg. # of Aspects (only AspectJ) 46 23 10
Evaluation Procedure testing testinginterference
analysis  
We selected iBATIS as the main subject of illustrat ive examples 
in this paper in order to promote coherence in the discussions. 
This is the most complex target system from which w e derived the 
largest data set (e.g. number of faults) and on whi ch we mostly 
draw our analyses. However, we also refer to exampl es of the 
other systems in order to highlight recurring observ ations across 
the three systems.  The highest number of faults in  iBATIS was 
expected. The already-stable implementation of the other two 
systems yielded less fault-related data than iBATIS . Their 
implementations are more mature as they have been o riginally 
released for four years or more and underwent more corrective 
and perfective changes. HW and MM have also been ta rgeted by a 
number of previous studies focusing in other equall y-important 
quality attributes [9, 13, 14, 16, 27]. Therefore, as the AO 
implementations have different degrees of stability , the results 
originated from these systems will provide support for drawing 
more general findings. 
3.3 The Evaluation Procedures 
We followed different approaches to evaluate each t arget system. 
The evaluation procedures were defined according to  the system 
characteristics and information available at the mo ment this study 
started. In short, we aimed at identifying as many faults as 
possible given time and resource constraints, while  systematically 
avoiding bias while evaluating the three systems. 
3.3.1 iBATIS Evaluation 
Evaluation strategy:  The iBATIS system has experienced two 
testing phases: pre-release and post-release testin g. Pre-release 
testing aimed at producing defect-free code to be c ommitted to a 
CVS repository. The test sets provided with the ori ginal OO 
implementations were used as baselines in this phas e. Any 
abnormal behaviour when regressively testing the AO  version of a 
given release was investigated. When a fault was un covered, it 
should be documented in an appropriate detailed rep ort (Section 
3.3.4). Post-release testing, on the other hand, ai med at assessing 
the implementation through enhancement of the origi nal test sets. 
The enhanced tests were executed against both OO an d AO 
versions of a given release. A fault should only be reported if it 
was noticed in the AO version but not in the OO counterpart. This 
procedure ensured that only faults introduced durin g the 
aspectisation process would be reported for further  analysis. 
Tooling support:  For test case design and execution, we used 
JUnit6 and GroboUtils7, a JUnit extension that enables multi-
                                                                 
6 http://www.junit.org/ (03/02/2010)  
7 http://groboutils.sourceforge.net/ (03/02/2010)  threaded tests. To measure test coverage, we used C obertura8, a 
tool that allows for fast code instrumentation and test execution. 
3.3.2 HW Evaluation 
Evaluation strategy:  HW was tested in a single phase in our study 
as initial testing was already performed during its  development 
time. Such initial tests involved people who were u naware of 
evaluations that would be further performed. Hence,  the testing of 
the HW system was extended in this study to cover t he assessment 
phase, thereby improving the degree of test coverag e. Differently 
from iBATIS, however, no original test set was made  available. 
Thus a full test set was built from scratch based o n the system 
specification and code documentation. In order to re duce test 
effort and avoid systematic bias during test creati on, test cases 
were automatically generated with adequate tool sup port. As well 
as for iBATIS, a fault should only be reported if it was noticed in 
the AO version but not in the OO counterpart, and all uncovered 
faults were similarly reported. 
Tooling support:  We used CodePro9, an Eclipse plugin for 
automatic JUnit test case generation for Java progr ams. We also 
used Mockrunner10, a lightweight framework for testing web-
based applications. It extends JUnit and provides t he necessary 
facilities to test the servlets implemented within the HW system. 
Finally, we used Cobertura to measure the test cove rage. 
3.3.3 MM Evaluation 
Evaluation strategy:  As well as HW, MM has not been developed 
with awareness of further fault-based evaluation. M oreover, post-
release tests during system evolution and maintenan ce only 
revealed faults related to robustness (e.g. data in put validation), 
however not necessarily being related to AOP mechan isms. 
Despite this, we have evaluated MM using the Compos ition 
Integrity Framework (CIF) [6]. CIF helped us identi fy problems in 
aspect interactions established either between aspe cts and base 
code or among multiple aspects. Since MM is a softw are product 
line and includes mandatory, optional and alternati ve features, 
CIF was applied in varied configurations of MM. In doing so, we 
were able to derive a set of faults that resulted f rom a broad range 
of aspect-oriented compositions.  
Tooling support:  We used the CIF framework, which performs 
static analysis of join point shadows. CIF is able to: (i) report the 
join point shadows that are involved in a specific composition, 
and (ii) report aspect interactions which are not g overned by an 
explicit dependency, e.g. via the use of the declar e precedence 
statement.  
3.3.4 Fault Reporting 
Every fault identified either during development (i BATIS only), 
during the assessment phase (iBATIS and HW), or dur ing static 
analysis (MM) was documented in a customised report  form. 
During the assessment or static analysis phases, th e testers 
provided information as much as possible, with spec ial attention 
to the test case(s) that revealed the fault (if app licable) and the 
fault symptom. In addition, the tester provided som e hints about 
the fault location. Then, the reports were forwarde d to the original 
developers, who were in charge of concluding the fa ult 
documentation. 
                                                                 
8 http://cobertura.sourceforge.net/ (03/02/2010)  
9 http://www.instantiations.com/ (03/02/2010)  
10 http://mockrunner.sourceforge.net/ (03/02/2010)  3.3.5 Fault Classification 
After the fault documentation step, each fault was classified 
according to a fault taxonomy for AO software propo sed in our 
previous research [12]. This taxonomy includes four high-level 
categories of faults that comprise the core mechani sms of AOP: 
(1) pointcuts; (2) introductions (or intertype decl arations – ITDs) 
and other  -like structures; (3) advices; and (4) the base 
program. In order to systematically classify every fault, it was 
took into account the fault origin and not only its  side-effects. The 
classification based on the first three categories above was 
straightforward. For instance, it was relatively tr ivial to identify 
mismatching pointcuts, misuse of  -like structures or 
wrong advice types. However, base program-related f aults 
required extended analysis and reasoning about them . For 
example, base code changes that result in broken po intcuts should 
be classified as base program-related although thei r side-effects 
might be unmatched join points in the code. Section  5 analyses the 
impact of each fault category on the overall fault distribution 
considering all targeted systems. 
4.  DATA COLLECTION 
This section presents the results obtained for each  target system. 
Section 4.1 describes the results of test execution  in iBATIS and 
HW releases, and the number of aspect interaction p roblems 
identified in the MM configurations. Section 4.2 pr esents the fault 
distribution per fault category and the fault distri bution per 
concern. 
4.1 Test Execution Results 
Figure 1 shows the test execution results for iBATIS  (on the left-
hand side) and HW (on the right-hand side). The iBA TIS original 
test sets comprise 100, 103, 108 and 130 test cases  for each 
release, respectively. The final, improved test set s include 246 test 
cases for iBATIS 01, 01.3 and 01.5, and 256 tests f or release 02. 
For a given release, new test cases were either min ed from the 
successive releases in the SourceForge repository o r designed 
from scratch. According to Figure 1, the number of successful test 
cases increased across the releases, what might mea n code 
enhancement. However, as discussed in the next sect ions, this not 
necessarily means reduction in number of faults. 
HW test sets were entirely designed for this study,  with support 
from CodePro. Additionally, a few tests were manual ly 
implemented based on functional requirements. In to tal, 925, 981, 
998 and 998 tests were generated for releases 01, 0 4, 07 and 10, 
respectively. We can observe in Figure 1 that the n umber of tests 
that failed plus the tests that raised exceptions (l abelled as error  in 
the legend) increased across the releases. This sug gests that the 
number of faults increased during the system evolut ion. However, 
as we will see in Section 4.2, this not necessarily  means larger 
number of faults in successive releases.  
Figure 2 presents the coverage achieved for each re lease of 
iBATIS and HW. For iBATIS in particular, the figure  shows the 
coverage obtained with the original and enhanced te st sets. In 
spite of HW test sets being significantly larger th an the iBATIS 
ones, the yielded coverage in HW is lower than in i BATIS. This is 
due to automatically-generated redundant tests that  exercise 
common parts of the code. Nevertheless, for both sy stems, we 
focused on the creation of tests that exercise part s of the code 
affected by the aspectual behaviour. Following this  strategy, we 
were able to uncover faults not yet revealed in pre vious system 
evaluations. Figure 1.  Test case execution in iBATIS (left) and  HW (right) 
releases.  
Figure 2.  Test coverage in iBATIS (left) and HW (r ight) 
releases.  
As described in Section 3.3, the MM system was eval uated 
through static analysis using the CIF framework [6] . This activity 
yielded a list of potential faults related to aspec t interactions 
regarding advices that share common join points. In  MM, such list 
included 16 potential faults for the varied configu rations of the 
four evaluated releases. Further analysis enabled u s to identify and 
classify the real faults. The results are presented  in the next 
section.  
4.2 Fault Distribution 
This section summarises all faults we identified al ong our study. 
Faults are grouped per category (Section 4.2.1) and  per concern (Section 4.2.2). The fault categorisation is in acc ordance to the 
fault taxonomy for AO programs [12]. 
4.2.1 Fault Distribution per Fault Category 
Tables 2 and 3 respectively present the number of r eported faults 
for iBATIS and for all the systems. The reported fa ults are 
grouped per category. The lower number of faults un covered for 
HW and MM can be explained by their size – they are  smaller 
than iBATIS – and by these systems having experienc ed only 
post-release evaluation. A total of 83 faults in iB ATIS (20.8 faults 
on average per release) and 104 considering all sys tems have been 
documented. In-depth analyses of the reported fault s drive the 
discussion presented in Section 5. 
. 
Table 2. Fault distribution per category in iBATIS.  
01 01.3 01.5 02
Pointcut-related 10 2 1 5 18 4.5
ITD-related 5 2 1 6 14 3.5
Advice-related 6 4 1 4 15 3.8
Base-program related 2 1 10 23 36 9.0
Total 23 9 13 38 83 20.8iBATIS releasesFault Category Total Average
 
 
 
Table 3. Fault distribution per category in all sys tems. 
Fault Category iBATIS MM HW Total
Pointcut-related 18 1 0 19
ITD-related 14 4 6 24
Advice-related 15 4 4 23
Base-program related 36 0 2 38
Total 83 9 12 104 
 
4.2.2 Fault Distribution per Concern in iBATIS 
Table 5 presents the fault distribution per concern  in iBATIS. To 
analyse this distribution, we considered only the i BATIS data set 
because it contains the largest amount of faults. M oreover, 
iBATIS is the only system where faults appear distr ibuted over all 
the aspectised concerns. Data sets collected for th e other two 
applications, on the other hand, were limited to po st-release 
evaluations only and are not considered in this sec tion. The 
concerns listed in Table 5 are briefly described in  Table 4. Notice 
that some concerns are aspectised only in releases 01.5 and 02. 
Section 5.2 discusses how certain implementation ch aracteristics 
of a concern (e.g. required AOP mechanisms) may imp act on the 
fault-proneness of that specific concern. 
 66 64 6461
0102030405060708090100
01 04 07 10
HW releasesGenerated test set
64 63 65 6518 19 16 17
0102030405060708090100
01 01.3 01.5 02
iBATIS releases% of coverage    Original test set Improved test set868893908
885576382
98258 15
8008208408608809009209409609801000
01 04 07 10
HW releases2252282312339979129 814
200210220230240250260
01 01.3 01.5 02
iBATIS releases# of test cases  pass fail error
Table 4. Concerns implemented with aspects in iBATI S. 
Concern Description Release
Concurrency Ensures multiple activities and requests  could be executed within the framework in a consis tent manner. all
Type MappingDeals with the mapping of data into different forma ts. E.g. when data is retrieved and stored in the d atabase, the application 
checks to see if the data content is not null befor e proceeding with the transaction.all
Design Patterns Subset of the Gang-of-Four design pa tterns such as Singleton, Observer, Adapter, and St rategy all
Error ContextErrorContext object stores data about executing act ivities. This data is used and sometimes printed as  an event trace in the 
event of an exception.all
Exception Handling Mechanisms that deal with to an e rroneous execution flows (In Java this includes try /catch/throws and finally clauses). all
Connection, Session 
& TransactionDetected as three separate concerns, regards mechan isms that allow for database access and control. E. g. transaction 
managers and SQL query runners.01.5 and 02
 Table 5. Fault distribution per concern in iBATIS.  
01 01.3 01.5 02
CC- Concurrency 0 0 0 1 1 0.25
TM- Type Mapping 2 0 0 1 3 0.75
DP- Design Patterns 2 0 0 0 2 0.5
EC- Error Context 13 5 1 2 21 5.25
EH- Exception Handling 6 4 2 16 28 7
CN- Connection -- -- 7 10 17 8.5
SS- Session -- -- 3 3 6 3
TR- Transaction -- -- 0 3 3 1.5
OT- Others 0 0 0 2 2 0.5
Total 23 9 13 38 83 20.8Average ConcerniBATIS releasesTotal
 
5. DATA ANALYSIS AND DISCUSSION 
This section performs exploratory and statistical a nalyses of the 
measures presented in Section 4. We aim at identify ing AOP 
properties and mechanisms that tend to yield faulty  
implementations. Section 5.1 evaluates the H1 hypot hesis, i.e. 
how the obliviousness property impacts the correctn ess of AO 
programs in the presence of code evolution. Section  5.2 evaluates 
the H2 hypothesis in order to identify the fault-pr oneness of 
specific AOP mechanisms. We evaluate H2 from two po ints of 
view: considering the overall system implementation , and the 
implementations of specific concerns. Both analyses  for H2 are 
supported by statistical tests. 
For the statistical tests performed along section 5 .2, we used the R 
language and environment11.  We use the Pearson’s chi-square  
test to check whether or not there is a statistical ly significant 
difference between the fault counts. We assume the commonly 
used confidence level of 95% (that is, p-value thre shold = 0.05). 
The Spearman's rank correlation  test is used to check how the 
fault counts correlate with AOP mechanism counts. T his test is 
used because in our analysis the used metrics (i.e.  number of 
faults) are nonparametric. For evaluating the resul ts of the 
correlation tests, we adopted the Hopkins criteria to judge the 
goodness of a correlation coefficient [21]: < 0.1 m eans trivial, 0.1-
0.3 means minor, 0.3-0.5 means moderate, 0.5-0.7 me ans large, 
0.7-0.9 means very large, and 0.9-1 means almost pe rfect. 
5.1 H1: The Impact of Obliviousness  
Obliviousness plays a central role in AOP, but there  is little 
empirical knowledge on how this property actually a ffects the 
fault-proneness under usual development settings. W e then 
analysed its impact on the fault-proneness of AO sy stems from 
two viewpoints: (i) obliviousness and software evol ution; and (ii) 
a categorisation of obliviousness listed by Sulliva n et al. [31]. The 
results are following presented.  
5.1.1 Obliviousness and Software Evolution 
Considering the fault distribution per fault catego ry (Tables 2 and 
3) for iBATIS, the  total number of faults related to the base code 
was 36, what is at least twice as large as any othe r number of 
faults within the other three categories. From thes e, 27 faults were 
caused by either perfective or evolutionary changes  within the 
base code, what led pointcuts to break. They repres ent the largest 
number amongst all fault types reported for the iBA TIS system, 
which in turn corresponds to 33% of the total numbe r of faults. 
This problem, usually referred to as the fragile pointcuts  problem 
[29], is closely related to the quantification and obliviousness 
                                                                 
11 http://www.r-project.org/ (03/02/2010)  models implemented in AspectJ-like languages. Chang ing a 
program requires a review of the crosscut enumerati ons (i.e. the 
pointcuts) which conflicts with the idea of program s being 
oblivious to the aspects applied to them [18]. We f ound that this 
problem is magnified in realistic development scena rios as the one 
observed in iBATIS. Several developers worked in pa rallel in the 
iBATIS project, each of them refactoring and evolvi ng different 
crosscutting concerns into aspects. This means that  obliviousness 
was present not only between base code and aspects.  The aspect 
implementations were oblivious to each other as wel l. For 
example, an aspect that advises a set of join point s might not be 
aware of other aspects inserting behaviour into the  same join 
points, hence rising the risk of either misbehaviou r or pointcut 
mismatching in the event of any code change. Partia l aid currently 
provided by AOP IDEs increases the developers' awar eness of the 
aspect effects in the base code. However, uncertain ty about how 
aspects indirectly interfere in the base code still  remains.  
We noticed this problem occurred mainly in the iBAT IS system as 
faults were reported during both development and as sessment 
phases (Section 3.3.4). Evolving some functionality  necessarily 
required fixing faults identified in the existing b ase or aspect 
code. On the other hand, HW and MM implementations were 
more stable and were extensively evaluated in previ ous research 
[9, 13, 14, 16, 27]. For example, since HW had been  first released, 
a number of incremental and perfective changes took  place [16], 
what resulted in both base and crosscutting code be ing more 
stable than in iBATIS code. Due to these refinement s, HW and 
MM had proportionally fewer faults in this category , most likely 
due to the robustness of the code. Nonetheless, non e of the three 
systems have been evaluated in terms of fault-prone ness, as 
presented in this paper. 
We further analysed the MM system this using the CI F framework 
[6], and the results reinforce our findings. The ma jority of faults 
here were sourced from areas of code where aspect i nteractions 
occurred at runtime. For example, in 45% of cases ( 4 out of 9), 
faults were caused due to missing  	  
statements. These faults resulted in arbitrary exec ution order of 
advices that share the same join point. Obliviousne ss was clearly 
the main reason for the introduction of faults in t hese cases, where 
aspects were successively introduced along the deve lopment 
cycles. Considering the same scenario in Java, the developers 
were naturally enforced to make an explicit design decision on the 
order of respective pieces of behaviour within a me thod. 
5.1.2 Obliviousness Categories 
We classified all documented faults according to th e four 
categories of obliviousness listed by Sullivan et a l. [31]. The 
summary of this categorisation is presented in Tabl e 6. The goal 
was to gather further evidence about the impact of obliviousness 
on the correctness of the evaluated systems. The ob liviousness 
categories represent different types of information  hiding. We 
focused on two types of obliviousness that are rele vant for the 
purposes of this analysis, briefly described as fol lows: (i) 
Language-level obliviousness  is present when there is no local 
notation in the code about aspect behaviour that ma y be inserted 
at this point; and (ii) Feature obliviousness , which is present when 
the base code developer is unaware of the features or the in-depth 
semantics of an aspect that is advising the base co de.  
Even though it is impossible to be entirely sure of  the true causes 
of faults, we followed a set of guidelines to decid e if the collected 
faults were likely to have been caused by language- level and/or 
feature obliviousness. In short, when behaviour is inserted at join 
points via advice, we can claim that language-level  obliviousness is present. This is because there is no explicit ca ll or notation of 
this extra behaviour within the base code. We categ orised a fault 
as caused by language-level obliviousness if the fa ult was likely to 
be avoided in case such an explicit local notation was present. 
Now, let us consider a base code developer who has followed 
specific design rules to expose certain join points  or create hooks 
for an aspect developer without full knowledge of t he 
implementation details of this aspect. In this case , language-level 
obliviousness is not present, but feature oblivious ness is. We 
classify a fault as being related to feature oblivi ousness if, in order 
for the fault to have been avoided, further attenti on would need to 
be given to the aspect semantics. 
Table 6. Faults associated with obliviousness. 
Language Feature Both Language only Feature only Total
iBATIS 31 4 4 27 0 31
HW 0 3 0 0 3 3
MM 8 4 4 4 0 8
Total 8 31 3 42SystemObliviousness Category
 
The results of this categorisation show that most o f the faults 
related to obliviousness were categorised as langua ge-level. They 
represent around 70% of all base program-related fa ults (i.e. 26 
out of 38 – see Total column in Table 3). In regard  to faults 
related to feature obliviousness, they were mostly found in cases 
where aspects either directly interact within the s ame module or 
share common join points. This indicates that evolv ing code that 
is oblivious to aspects has varying impacts on the fault-proneness 
of the system. This problem was mainly observed in iBATIS, in 
which faults have been reported during the evolutio n of the 
releases. MM and HW, on the other hand, experienced  only post-
release tests. Nevertheless, 11 out of 21 faults re vealed for HW 
and MM were assigned to obliviousness at either lan guage-level, 
feature or both (see Total column in Table 6). 
To conclude, analysing the impact of obliviousness on the fault-
proneness of the evaluated systems provided us with  evidences 
that support the H1 alternative hypothesis (H1-1). That is, 
“Obliviousness exerts impact on the fault-proneness of evolving 
AO programs ”. In our study, a large amount of faults (40%) cou ld 
be directly associated with the base code being obl ivious to 
aspects. Their majority was observed in the iBATIS evolution. 
Many faults observed were also related to aspects b eing oblivious 
to other aspects. Missing 	  statements were 
responsible for 45% of the faults found in MM. Cons idering all 
faults (Table 3), 11% were categorised as feature o bliviousness-
related, although a much larger proportion were rel ated to 
language-level (i.e. 38%). This result is interesti ng because it 
might further reinforce the motivation for AOP mode ls based on 
explicit class-aspect interfaces, such as XPIs [17]  and EJPs [20].  
5.2 H2: Fault-proneness of AOP Mechanisms 
There is often an assumption that the use of pointc ut languages is 
the main source of faults in aspect-oriented progra ms [10, 12, 29]. 
However, there is limited understanding of the real  magnitude of 
pointcut faults with respect to other AOP mechanism s. The 
analysis of our second hypothesis is drawn in terms  of the fault 
categorisation presented in Section 4. The null hyp othesis (H2-0) 
states that there is no significant difference amon gst the fault-
proneness of core AOP mechanisms. 
5.2.1 Analysing the overall fault distribution 
Initially, we analyse the values presented in Table  2. Examination 
of this data indicates that there is a similarity a mong the total number of faults found in iBATIS, considering the f irst three 
categories (pointcut-, advice- and ITD-related). Th ese results 
suggest these mechanisms present similar fault-pron eness; that is, 
none of them stands out with respect to the number of faults. To 
further analyse this observation statistically, we first applied a 
Pearson's chi-square test. This test checks the pro bability of 
sample data coming from a population with a specifi c distribution. 
If we reach a probability (p-value) higher than, sa y, 0.05, we can 
assert with 95% confidence level that there is no re ason to reject 
the hypothesis that the observed data fits the give n distribution. In 
our case, at a confidence level of 95%, the result confirms the 
uniformity of the fault frequencies among each faul t category: the 
p-value is evaluated to 0.7584, significantly highe r than 0.05. This 
is easy to see since fault counts were 18, 14, and 15; very close to 
the fitted model where each category is expected to  have 
approximately the same number of faults (15.67 in t his case). We 
then applied the chi-square test to the overall fau lt set, considering 
all target systems (i.e. the total of 104 faults pr esented in Table 3). 
Again, assuming the confidence level of 95%, the re sult 
corroborates the previous finding, i.e. the faults are uniformly 
distributed over the three main AOP mechanisms, wit h p-value 
being evaluated to 0.7275, again significantly high er than 0.05. 
Contradicting the conventional wisdom, we have firs t evidence 
that supports the H2 null hypothesis (H2-0) that “ there is no 
difference among the fault-proneness of the main AO P 
mechanisms ”. This is also an interesting result as many 
researchers have strictly focused on improving the design of 
pointcut languages (e.g. providing support for more  expressive 
pointcuts [5, 18, 20]). Less attention has been giv en to support 
more robust programming with other classical AOP me chanisms. 
The next section presents a more refined analysis t hat brings 
additional evidence on the fault-proneness of such mechanisms 
from a different point of view. 
5.2.2 Analysing the fault distribution per concern 
The analysis of fault distribution per fault catego ry only took into 
account the overall number of faults per category. This section 
provides a more refined analysis about fault-pronen ess of AOP 
mechanisms. For this, we considered certain interna l details in the 
implementation of each concern. We performed a corr elation 
analysis to gather empirical evidence of a cause-eff ect relationship 
between the number of AOP mechanisms and defects. T his is 
motivated by the fact that AOP mechanisms may have individual 
impact on the fault-proneness of a module, a cluste r of modules 
(e.g. modules that implement a given concern) or th e full system. 
For this analysis, we considered only the set of fa ults identified in 
iBATIS, since it includes representatives distribut ed over all the 
aspectised concerns (Table 4). Moreover, we also co nsidered base 
program-related faults in order to measure the impa ct of AOP 
mechanisms in the system as a whole. 
Initially, we applied the Spearman's rank correlati on to check how 
the overall number of AOP mechanisms (pointcuts, ad vices and 
ITDs) per release in iBATIS (Table 7) correlates wi th the number 
of faults in the same release. The results are pres ented in Table 8. 
The correlation is generally low, considering all A OP 
mechanisms, thus contradicting the results that reg ard fault 
distribution per fault category (Section 5.2.1). 
Table 7. Number of AOP mechanisms and faults in iBA TIS. 
iBATIS release Pointcuts Advices ITDs Faults
        01 97 94 79 23
        01.3 121 118 86 9
        01.5 244 240 238 13
        02 244 238 237 38 However, while performing such an analysis based in  internal 
properties of the systems, we should take into acco unt concern-
specific characteristics. This is due to the nature  of concern 
implementations, which usually require subsets of A OP 
mechanisms to be used together. For example, aspect ising an 
exception handler usually requires three coding str uctures in 
AspectJ: a pointcut expression, a 
  statement and 
an advice. In other words, we can investigate wheth er the number 
of pointcuts, advices and ITDs (including  -like 
mechanisms) implemented for the purposes of a conce rn impact 
on the number of faults it presents. 
Table 8. Correlation between number of faults and n umber of 
AOP mechanisms in iBATIS releases. 
Metric Coefficient P-value
POINTCUTS 0.2108185 0.7892000
ADVICES 0.0000000 1.0000000
DECLARATIONS 0.0000000 1.0000000 
Hence, we checked how the number of AOP mechanisms used to 
implement a concern correlates with the fault distri bution per 
concern. We measured the maximum and the average nu mber of 
each AOP mechanism per concern across all iBATIS re leases. 
Note that, for a given concern, we considered all m odules (aspects 
and classes) that were involved in its implementati on. We applied 
again the Spearman's rank correlation to the total and average 
number of faults per concern across the releases. W e compared 
these numbers against the maximum and average numbe r of 
advices, pointcuts, and ITDs per concern across rel eases. With 
such an analysis we can observe whether and how the  usage 
frequency of each AOP mechanism seems to impact on the fault 
distribution per concern. We used the maximum and a verage 
number of mechanisms across releases because they m ight repeat 
from release to release. That is, the same pointcut  implemented in 
an exception handling aspect in one release may be present in the 
same aspect in another release  
We also chose two metrics typically applied to OO a nd AO 
programs in order to compare the results obtained i n this analysis. 
These metrics are lines of code (LOC) and weighted operations 
per module (WOM) [7]. WOM adapts the original weigh ted 
methods per class (WMC) metric [8] to count methods  inside 
classes as well as aspect operations (i.e. advices,  methods and 
intertype methods). These metrics have been reporte d as good 
fault-proneness indicators in studies that comprise d OO programs 
[19, 30]. Again, we considered their maximum and av erage values 
across releases for the clusters of modules require d for the 
implementation of each concern. Table 9 shows the statistics for the AOP mechanisms , LOC and 
WOM metrics in iBATIS. We again adopted the confide nce level 
of 95%. Tables 10 and 11 present the results of the  Spearman's 
correlation rank run against: (i) the maximum and a verage number 
of mechanisms across releases, and (ii) the total a nd average 
number of faults per concern across releases. The v alues and 
results comprising LOC and WOM metrics are also pre sented in 
these tables. 
Note that the correlation coefficient is very large  for all 
correlations that take into account the maximum and  the average 
number of pointcuts and advices. In fact, we can ob serve that the 
correlation between the maximum number of pointcuts  and advice 
and the average number of faults per concern is sig nificant. We 
observed a 99% level of confidence (Table 10). For ITDs, the 
correlation coefficient varies between 0.5 and 0.6,  what means 
moderate-to-large correlation on average if we cons ider a 
confidence level to 85%.  
Table 10. Correlation with average number of faults  per 
concern/release. 
Metric Coefficient P-value
MAX-POINTCUTS 0.8809524** 0.0072420
MAX-ADVICES 0.8742672** 0.0045120
MAX-ITDs 0.5509081 0.1570000
MAX-LOC 0.1904762 0.6646000
MAX-WOM 0.1666667 0.7033000
AVG-POINTCUTS 0.8571429* 0.0107100
AVG-ADVICES 0.8571429* 0.0107100
AVG-ITDs 0.5714286 0.1511000
AVG-LOC 0.1904762 0.6646000
AVG-WOM 0.1666667 0.7033000
** correlation is significant at the 0.01 level
* correlation is significant at the 0.05 level 
Differently from results of previous studies compri sing OO 
programs [19, 30], LOC and WOM metrics show non-sig nificant 
correlation with both average and maximum number of  faults in 
our study. These results indicate that when we cons ider the set of 
modules involved in AO implementations of crosscutt ing 
concerns, the internal number of AOP-specific mecha nisms (i.e. 
pointcuts, advices and ITDs) are good fault-pronene ss indicators. 
Moreover, they seem to be better indicators than th e traditional 
LOC and WOM metrics. 
While performing the analysis presented in this sec tion, we 
noticed that: (i) concern-specific characteristics define the set of 
AOP mechanisms that must be used in conjunction to implement 
such a concern, and (ii) given a specific concern i mplementation, 
the usage rate of each mechanism tends to be direct ly proportional 
 
Table 9. Number of AOP mechanisms, LOC and faults p er concern in iBATIS. 
Max Avg Max Avg Max Avg Max Avg Max Avg Total Avg
Concurrency 7 6.75 5 4.5 3 2.75 1,605 1,435 395 373 1 0.25
Type Mapping 2 2 2 2 3 3 496 496 298 298 3 0.75
Design Patterns 9 6 5 3.5 14 9.5 1,725 1,566 448 391 2 0.5
Error Context 42 26.75 45 29.75 1 0.5 2,109 1,926 450 404 21 5.25
Exception Handling 77 70.25 75 69 82 74.75 4,761 4,490 1,159 994 28 7
Connection 64 64 64 32 61 60.5 901 890 359 358 17 8.5
Session 46 45.5 46 22.75 25 25 331 325 208 203 6 3
Transaction 20 20 20 10 54 53.5 686 684 223 221 3 1.5LOC WOM Faults Pointcuts Advices ITDs
 to the number of faults associated with that concer n, what is 
supported by the correlation test results. These fi ndings support 
the H2 null hypothesis (H2-0) because the overall f ault 
distribution per main AOP mechanism showed to be un iform. In 
addition, the usage rate of each mechanism does not  vary 
independently. That is, it depends on the set of co ncerns 
aspectised within a system.  
Table 11. Correlation with total number of faults p er concern. 
Metric Coefficient P-value
MAX-POINTCUTS 0.8263621* 0.0114400
MAX-ADVICES 0.8192771* 0.0128300
MAX-ITDs 0.3915663 0.3374000
MAX-LOC 0.3473116 0.3993000
MAX-WOM 0.3473116 0.3993000
AVG-POINTCUTS 0.8024096* 0.0165400
AVG-ADVICES 0.8024096* 0.0165400
AVG-ITDs 0.4191692 0.3013000
AVG-LOC 0.3473116 0.3993000
AVG-WOM 0.3473116 0.3993000
* correlation is significant at the 0.05 level 
6. STUDY LIMITATIONS 
This section discusses the study limitations based on the four 
categories of validity threats described by Wohlin et al. [33]. Each 
category includes a set of possible threats for an empirical study. 
We identified the items within each category that m ight threat our 
study, which are discussed in the following. For ea ch category, we 
list possible threats and the measures we took to re duce each risk. 
Conclusion validity . We identified two categories in this case: (i) 
reliability of measures : subjective decisions were made during the 
fault classification steps, specially regarding obl iviousness levels 
(Section 5.1); besides, one of the target systems w as evaluated 
with auto-generated test cases (Section 3.3.2), wha t might have 
risked the reliability of test results; and (ii) random heterogeneity 
of subjects : evaluated systems came from different application  
domains. To reduce risk (i), we designed detailed f ault report 
forms and defined a set of guidelines that were fol lowed in order 
to systematically classify each fault (Section 3.3. 5). In regard to 
the evaluation based on auto-generated tests, this technique has 
previously yielded relevant results [37, 38], so it  should not be 
seen as a major issue. Regarding risk (ii), althoug h the 
applications’ heterogeneity is considered a threat to the conclusion 
validity, it helps to promote the external validity  of the study. 
Internal validity . We detected two possible risks: (i) ambiguity 
about direction of causal influence : the complexity of the 
aspectised concerns might have made a system releas e more 
faulty than the others; and (ii) history and maturation : HW and 
MM systems have been extensively evaluated and cont inuously 
improved through the last years, what reduced the n umber of 
uncovered faults in such systems. Risk (i) cannot b e completely 
avoided as each functionality differs from the othe rs w.r.t. 
complexity. However, it was reduced because all sys tems were 
developed and revised by experienced programmers. T hey used 
implementation guides, design patterns or specific AOP idioms, 
where applicable. Moreover, systematic regression t esting helped 
developers preserve the semantics of the OO counter parts. In 
order to reduce risk (ii), we focused our analyses on iBATIS, 
which consists in the most recent from all target s ystems and 
yielded the largest data set to be analysed.  Construct validity . We identified the following construct validity 
threats: (i) inadequate operational explanation of constructs : 
unclear procedures that should be followed in the e vent of a fault 
being uncovered might have biased the results (e.g.  should the 
fault be fixed? How should this fault be classified ?); (ii) 
confounding constructs and levels of constructs : different maturity 
levels of the investigated systems impacted the num ber of 
uncovered faults; and (iii) interaction of testing and treatment : 
iBATIS developers were aware of further system eval uation. To 
reduce risks (i) and (iii), we defined clear proced ures and roles 
that were applied throughout all study steps. In pa rticular, iBATIS 
development was strongly based on regression testin g in order to 
make only error-free code available in the CVS repo sitory. 
Although this approach made developers aware of the  system 
evaluation procedures, it was important since it en abled 
developers to collect data since the early developm ent phases. 
Risk (ii), on the other hand, could not be avoided due to the few 
options of medium-sized AO systems currently availa ble for 
evaluation. Such systems present different levels o f maturity, what 
includes varied fault rates. 
External validity . The major risk here is related to the interaction 
of setting and treatment : the evaluated systems might not be 
representative of the industrial practice. To reduc e this risk, we 
evaluated systems that come from heterogeneous appl ication 
domains and are implemented with AspectJ, which is one of the 
representatives in the state of AOP practice. The i BATIS system 
is a widely-used open source project for object-rel ational 
mapping. Even though HW and MM are smaller applicat ions, 
they are also heavily based on industry-strength te chnologies. In 
addition, both systems have been extensively used a nd evaluated 
in previous research [9, 13, 14, 16, 27]. To conclu de, the 
characteristics of the selected systems, when contr asted with the 
state of practice in AO software development, repre sent a first 
step towards the generalisation of the achieved res ults. 
7. CONCLUSIONS 
This paper presented an exploratory study of the fa ult-proneness 
of AOP mechanisms used in the implementation of evo lving AO 
programs. We analysed three systems from different application 
domains, from which we collected fault-related data  upon which 
we performed our analyses. The results revealed the  negative 
impact of obliviousness on the fault-proneness of p rograms 
implemented with AspectJ (H1 hypothesis). More rece nt methods 
and languages for AOP can help to ameliorate this p roblem. 
Examples of such approaches are aspect-aware interfa ces [26], 
Crosscut Programming Interfaces (XPIs) [17] and Exp licit Join 
Points (EJPs) [20]. Although they reduce the oblivi ousness among 
system modules, these approaches help to improve pr ogram 
comprehension by making aspect-base interaction mor e explicit. 
In particular, they tend to reduce the language-lev el obliviousness, 
which happened to be the category with the largest number of 
faults in our study. 
As far as the H2 hypothesis is concerned, we did no t confirm the 
common intuition that defining pointcuts is the mos t fault-prone 
scenario in AOP. There was no AOP mechanism that st ood out as 
the main responsible for the detected faults. We al so argue that 
this correlational study provides a good lead for m ore probing 
controlled experiments to investigate this issue fu rther. 
Nevertheless, recent research on fault taxonomies a nd testing 
approaches for AO software has mainly focused on po intcuts as 
the key bottleneck in AOP [3, 4, 10, 12]. However, the results 
obtained for the H2 hypothesis motivate more intens ive research 
on the testing support for other AOP mechanisms bey ond pointcut 
expressions, such as intertype declarations and adv ice. We believe that these study outcomes are helpful in  several ways, 
such as: (i) providing information about harmful AO P 
mechanisms; (ii) supporting testing processes by pi npointing 
recurring faulty scenarios; and (iii) enhancing the  general 
understanding towards robust AOP, so that other con trolled 
experiments can be derived in our future research. 
8. ACKNOWLEDGMENTS 
We would like to thank the iBATIS AO developers Ell iackin 
Figueiredo, Diego Araujo, Marcelo Moura and Mário M onteiro. 
We also thank Andrew Camilleri for his valuable hel p while 
analysing the MobileMedia system with the CIF frame work.  
The authors received full of partial funding from t he following 
agencies and projects: Fabiano Ferrari : FAPESP (grant 
05/55403-6), CAPES (grant 0653/07-1) and EC Grant A OSD-
Europe (IST-2-004349); Alessandro Garcia : FAPERJ (distin-
guished scientist grant E-26/102.211/2009), CNPq (p roductivity 
grant 305526/2009-0 and Universal Project grant 483 882/2009-7) 
and PUC-Rio (productivity grant); Rachel Burrows : UK EPSRC 
grant; Otávio Lemos : FAPESP (grant 2008/10300-3); Sergio 
Soares : CNPq (grant 309234/2007-7) and FACEPE (grant APQ-
0093-1.03/08); José Maldonado : EC Grant QualiPSo (IST-FP6-
IP-034763) and CNPq; Other authors : CAPES and CNPq, Brazil. 
9. REFERENCES 
[1]  Aldrich, J. 2004. Open Modules: Reconciling Extensi bility 
and Information Hiding. In: SPLAT AOSD’04 Workshop.  
[2] Alexander, R. T., et al. 2004. Towards the Systemat ic 
Testing of Aspect-Oriented Programs. Report CS-04-1 05, 
Colorado State University, Fort Collins-USA. 
[3] Anbalagan, P., and Xie, T. 2008. Automated Generati on of 
Pointcut Mutants for Testing Pointcuts in AspectJ P rograms. 
In: ISSRE’08. 239-248.  
[4] Bækken, J. S., and Alexander, R. T. 2006.  A Candid ate 
Fault Model for AspectJ Pointcuts. In: ISSRE’06. 16 9-178. 
[5] Cacho, N., Filho, F. C., Garcia, A., and Figueiredo , E. 2008. 
EJFlow: Taming Exceptional Control Flows in Aspect-
Oriented Programming. In: AOSD’08. 72-83. 
[6] Camilleri, A., Coulson, G., Blair, L. 2009. CIF: A 
Framework for Managing Integrity in Aspect-Oriented  
Composition. In: TOOLS’09. 16-26. 
[7] Ceccato, M., and Tonella, P. 2004 Measuring the Eff ects of 
Software Aspectization. In: 1st Workshop on Aspect Reverse 
Engineering (ARE). 
[8] Chidamber, S.R., and Kemerer, C.F. 1994. A Metrics Suite 
for Object-Oriented Design. IEEE Transactions on So ftware 
Engineering 20 (6). 476-493. 
[9] Coelho, R., et al. 2008. Assessing the Impact of As pects on 
Exception Flows: An Exploratory Study. In: ECOOP’08 . 
(LNCS, vol. 5142). 207-234. 
[10] Delamare, R., Baudry, B., Ghosh, S., Le Traon, Y. 2 009. A 
Test-Driven Approach to Developing Pointcut Descrip tors in 
AspectJ. In: ICST’09. 376-385. 
[11] Eaddy, M., et al. 2008. Do Crosscutting Concerns Ca use 
Defects? IEEE Transactions on Software Engineering 34 (4). 
497-515. 
[12] Ferrari, F., Maldonado, J., and Rashid, A. 2008. Mu tation 
Testing for Aspect-Oriented Programs. In: ICST’08. 52-61.  
[13] Figueiredo, E., et al. 2008. Evolving Software Prod uct Lines 
with Aspects: An Empirical Study on Design Stabilit y.  In:   
ICSE’08. 261-270. [14] Filho, F. C., et al. 2006. Exceptions and Aspects: The Devil 
is in the Details. In: FSE’06. 152-162.  
[15] Filman, R. E., and Friedman, D. 2004. Aspect-Orient ed 
Programming is Quantification and Obliviousness. In : 
Aspect-Oriented Software Development. Addison-Wesle y. 
[16]  Greenwood, P., et al. 2007. On the Impact of Aspec tual 
Decompositions on Design Stability: An Empirical St udy. In: 
ECOOP’07 (LNCS, vol.4609). 176-200. 
[17] Griswold, W. G., et al. 2006. Modular Software Desi gn with 
Crosscutting Interfaces. In: IEEE Software 23(1). 5 1-60. 
[18] Gybels, K., and Brichau, J. 2003. Arranging Languag e 
Features for More Robust Pattern-Based Crosscuts. In : 
AOSD’03. 60-69. 
[19] Gyimóthy, T., Ferenc, R., and Siket, I. 2005. Empir ical 
Validation of Object-Oriented Metrics on Open Sourc e 
Software for Fault Prediction. IEEE Transactions on  
Software Engineering 31 (10). 897-910. 
[20]  Hoffman, K., and Eugster, P. 2007. Bridging Java a nd 
AspectJ through Explicit Join Points. In: PPPJ’07. 63-72. 
[21] Hopkins, W. G. 2003. A New View of Statistics. Sport  
Science, http://www.sportsci.org/resource/stats (01 /09/2009) 
[22] iBATIS Data Mapper - http://ibatis.apache.org/ (01/ 09/2009). 
[23] Johnson, R., et al. 2007. Spring - Java/J2EE applic ation 
framework. Ref, Manual Version 2.0.6, Interface21 L td. 
[24] Kastner, C., Apel, S., and Batory, D. 2007. A Case Study 
Implementing Features Using AspectJ. In: SPLC’07. 2 23-
232. 
[25] Kiczales, G., et al. 1997. Aspect-Oriented Programm ing. In: 
ECOOP’97 (LNCS, vol. 1241). 220-242. 
[26] Kiczales, G., and Mezini, M. 2005. Aspect-Oriented 
Programming and Modular Reasoning. In: ICSE’05. 49- 58. 
[27]  Soares, S., Laureano, E., and Borba, P. 2002.  Imp lementing 
Distribution and Persistence Aspects with AspectJ. In:   
OOPSLA’02. 174-190. 
[28] Steimann, F. 2006. The Paradoxical Success of Aspec t-
Oriented Programming. In: OOPSLA’06. 481-497. 
[29] Stoerzer, M., and Graf, J. 2005. Using Pointcut Del ta 
Analysis to Support Evolution of Aspect-Oriented So ftware. 
In: ICSM’05. 653-656.  
[30] Subramanyam, R., and Krishnan, M. S. 2003. Empirica l 
Analysis of CK Metrics for Object-Oriented Design 
Complexity: Implications for Software Defects. IEEE  
Transactions on Software Engineering. 29 (4). 297-3 10. 
[31] Sullivan, K., et al. 2005. Information Hiding Interf aces for 
Aspect-Oriented Design. In: ESEC/FSE’05. 166-175. 
[32] The AspectJ Project. http://www.eclipse.org/aspectj /  
[33] Wohlin, C., et al. 2000. Experimentation in Softwar e 
Engineering - An Introduction. Kluwer Academic Publ ishers. 
[34] Xie, T., and Zhao, J. 2006. A Framework and Tool Su pports 
for Generating Test Inputs of AspectJ Programs. In:  
AOSD’06.   190-201 
[35] Huang, S. S., Smaragdakis, Y. 2006. Easy Language 
Extension with Meta-AspectJ. In: ICSE’06. 865-868 
[36] Zhang, S., and Zhao, J. 2007. On Identifying Bug Pa tterns in 
Aspect-Oriented Programs. In: COMPSAC’07. 431-438. 
[37] Csallner, C., and Smaragdakis, Y. 2005. Check 'n' c rash: 
combining static checking and testing. In: ICSE’05,  422-431. 
[38] Harman, M., et. al. 2009. Automated test data genera tion for 
aspect-oriented programs. In: AOSD’09. 185-196. 